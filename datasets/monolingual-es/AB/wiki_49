<doc id="42754" url="https://es.wikipedia.org/wiki?curid=42754" title="Fuerzas Armadas Revolucionarias de Colombia">
Fuerzas Armadas Revolucionarias de Colombia

Las Fuerzas Armadas Revolucionarias de Colombia - Ejército del Pueblo (FARC-EP) fueron una organización guerrillera insurgente y terrorista de extrema izquierda, basada en la ideología y los principios del marxismo-leninismo, y bolivarianismo en Colombia. Fundadas y activas en el Conflicto armado interno de Colombia desde 1964hasta 2016 cuando se desmovilizan por los Acuerdos de paz y en 2017 conforman el partido Fuerza Alternativa Revolucionaria del Común. Según el Centro Nacional de Memoria Histórica de los 262.197 muertos en Colombia por el conflicto armado interno entre 1958 y 2018 a las FARC-EP y otros grupos guerrilleros se les atribuye 35.683 muertos, sólo superadas por los grupos paramilitares, a quienes se les atribuye 94.754 asesinatos. Las FARC-EP violaron los Derechos humanos en Colombia con uso de minas antipersona, armas no convencionales (cilindros y artefactos bomba), ejecutando masacres, atentados terroristas, asesinatos, secuestros con fines políticos o extorsivos, y desplazamiento forzado. A partir de 1980 se involucran en el narcotráfico. y se financiaron también con minería ilegal, extorsión,robo de petróleo y contrabando.

Inicialmente estuvieron bajo el mando de Pedro Antonio Marín (conocido por los alias de "Manuel Marulanda Vélez" o "Tirofijo") desde su fundación en 1964 hasta su fallecimiento en marzo de 2008 por causas naturales. Posteriormente, su comandante en jefe fue Guillermo León Sáenz alias "Alfonso Cano", hasta que fue abatido por el Ejército Nacional el 4 de noviembre de 2011, durante la Operación Odiseo. El 15 de noviembre la organización confirmó en un comunicado, que su nuevo comandante en jefe era Rodrigo Londoño Echeverri, alias "Timochenko" o "Timoleón Jiménez", quien las dirigió hasta el 26 de septiembre de 2016 cuando se firmaron los Acuerdos de paz entre el gobierno colombiano y las FARC-EP. El 24 de agosto de 2016 finalizaron las negociaciones de los acuerdos en La Habana, que buscaban terminar el conflicto de esta guerrilla con el Estado colombiano. se firmó el acuerdo definitivo y ambas partes ordenaron el cese al fuego definitivo a partir de las 00:00 del 29 de agosto. El texto del acuerdo definitivo se publicó en Internet. El 23 de septiembre, después de terminar la Décima Conferencia Guerrillera (máxima instancia de este grupo subversivo), todos los frentes y bloques de la organización aceptaron acatar los acuerdos firmados en La Habana, además de la entrega de su armamento a la ONU y su posterior desmovilización y reincorporación a la vida civil, con excepción de una facción del Frente 1, que manifestó seguir en armas. Estos acuerdos habían de ser ratificados por el pueblo colombiano mediante un plebiscito que se celebró el 2 de octubre de 2016, el cual les habría brindado garantías para que abandonaran de manera definitiva la lucha insurgente y se convirtieran en un movimiento político. El resultado del plebiscito fue una ajustada victoria del No.Los acuerdos se renegociaron con base en los anteriores, añadiendo algunas objeciones de quienes apoyaron el No. Pero en esta segunda ocasión se buscó la aprobación del congreso, evitando un nuevo referéndum. Estos nuevos acuerdos se firmaron el 24 de noviembre de 2016, en el Teatro Colón de Bogotá (por eso estos acuerdos se conocen también como los Acuerdos del Teatro Colón) y enviados al Congreso de la República para su estudio, ratificación e implementación. Con esta ratificación e implementación en el Congreso, comenzó formalmente el proceso de desmovilización de insurgentes y de entrega de las armas a la ONU en un lapso de 180 días, desde el 1 de diciembre de 2016. La entrega de armas culminó el 14 de agosto de 2017, mes y medio después del plazo establecido en los acuerdos. El 28 de agosto de 2017 se celebró en Bogotá el congreso fundacional del nuevo partido que mantiene las siglas FARC pero con el significado Fuerza Alternativa Revolucionaria del Común.

"Para una lista de acontecimientos de este grupo guerrillero y posterior partido político véase "

Los antecedentes aparecen en el periodo de la violencia con la aparición de autodefensas armadas comunistas o guerrillas comunistas en el sur del Tolima. El antecedente político se encuentra en el Partido Comunista Colombiano en su Sexto Congreso inicia la orientación de la autodefensa en 1949. Las Ligas Campesinas de los comunistas en Chaparral crearon las estructuras de autodefensa. Cuando el gobierno buscó controlar estas bandas armadas imposibilitando su acción, las Direcciones de los grupos de autodefensa comunista de Irco, Horizonte y Chicalá deciden, a finales de 1950, organizar lo que denominaron "Columna de Marcha" o "Columna Guerrillera", una estructura de combatientes y sus familias, durante 3 meses. Los comunistas reciben la propuesta de las guerrillas liberales de Gerardo Loaiza y Leopoldo García para que una comisión de los comunistas viaje hasta su comando para que enseñen algunos métodos de acción y organización. 

Los comunistas que se unieron fueron Marco Aurelio Restrepo (fundador del Partido Comunista en Chaparral), Pedro Pablo Rumique 'Teniente Canario', los hermanos Bermúdez (Andrés Bermúdez 'Llanero'), los hermanos Valbuena, entre otros. En la región de la Quebrada de la Lindosa se encontraron comunistas y liberales en una asamblea donde crean un "Estado Mayor Unificado en el Tolima" que se integraría con ocho comunistas y siete liberales, para comandar las misiones conjuntas y destacamentos en Rioblanco (Tolima). Entre los liberales que integraban la Dirección estaban Gerardo Loaiza, sus cuatro hijos y Leopoldo García. Entre los comunistas estaban Jorge Hernández Barrios 'Olimpo', Manjarrés, Rumique,Raúl Valbuena 'Baltazar', José Alfonso Castañeda 'Richard' y Peñuela. Establecieron su campamento bajo el nombre del "Comando Davis", ""Aquí se establece la sede central de toda una cadena de destacamentos. Fue durante algún tiempo el cuartel general de las guerrillas, unidas bajo el mando del Estado Mayor Unificado"" Manuel Marulanda"." A la región comunista llegaría Isauro Yosa, que se incorporaría al Estado Mayor. Los liberales establecen su Comando Principal, en La Ocasión. Los comunistas constituyen nueve comandos para moverse hacia Chaparral (Tolima), Riogrande (Huila) y en tierras indígenas del Cauca, presentando combates y escaramuzas con comandantes como Richard, Baltazar, Gratiniano Rocha (Ave Negra), Jorge Peñuela, José Enoch Leal (Diamante), Jacobo Prías Alape' "Charro Negro'," Ciro Trujillo, Pedro Antonio Marín, alias "Manuel Marulanda Vélez" o "Tirofijo", pariente de los Loaiza y miembro de las guerrillas liberales.

El liberal Gerardo Loaiza siguiendo órdenes de la Dirección Liberal Departamental, convoca una asamblea en la que se votó por la disolución de la alianza. Después se ocasionarían enfrentamientos. En 1952, promovida por el Partido Comunista Colombiano, se celebra la Conferencia Guerrillera Nacional en Viotá (Cundinamarca). Además de los comunistas, asistieron guerrilleros liberales de Antioquia y Santander, y otros grupos liberales y comunistas de Cundinamarca y oriente del Tolima, sin contar con los delegados del comando de La Ocasión. El combate de comunistas contra los liberales continúa, con breves lapsos donde se da la tregua y se combate al gobierno. Dos hijos de Loaiza mueren en un ataque al Davis, que posteriormente sería disuelto. En 1953 el General Gustavo Rojas Pinilla llegó al poder tras un golpe de estado y buscó llevar a su fin la época de violencia. Por medio de las amnistías, cerca de 5.000 guerrilleros dejaron las armas. Varios de los grupos comunistas que seguían en armas se concentraron en Sumapaz donde, según su versión de los hechos, fueron atacados por Fuerzas Militares que usaron helicópteros y Napalm provisto por el gobierno de los Estados Unidos. En 1958 liberales y conservadores llegan a un acuerdo de reparto del poder con la intención de frenar la violencia bipartidista y se crea el Frente Nacional, en el contexto de la Guerra Fría. El conflicto se reactivó en el sur de Tolima, donde antiguos guerrilleros liberales y terratenientes locales, empezaron a hostigar a los comunistas, dando muerte a cabecillas amnistiados o inactivos. El 11 de enero de 1960 asesinado el líder comunista Jacobo Prías Alape ‘Charro Negro’ quien había sido beneficiado por la la amnistía de Rojas Pinilla (Considerado el inicio del Conflicto armado interno en Colombia). En junio de 1961 el IX Congreso del Partido Comunista, se aprobó la tesis de combinar todas las formas de lucha. El senador conservador Álvaro Gómez denuncia en el Congreso de la República la existencia de “Repúblicas Independientes” en Colombia el 25 de octubre de 1961. En enero de 1962,combates enfrentaron a las Autodefensas Campesinas de "Tirofijo" con el Ejército Nacional en Marquetalia, sur del Tolima.

Tras el asesinato de Charro Negro, Manuel Marulanda Vélez alias "Tirofijo", quien había sido objeto de amnistía y trabajaba como supervisor de obras, regresará a las montañas alzado en armas junto con algunos liberales radicales para constituir la República de Marquetalia en Planadas (Tolima). En mayo de 1964,el presidente Guillermo León Valencia decidió atacar la llamada "República de Marquetalia",donde estaba asentado un grupo de liberales y comunistas de origen campesino, y la autoridad de estado fue anulada por estas autodefensas campesinas. Este operativo se denominó como la Operación Soberanía. Otras zonas del país "liberadas" por los subversivos entre 1960 y 1964 fueron El Pato (Caquetá), Riochiquito (Cauca), Guayabero y el sudoeste de Tolima. En 1964 luego de la Operación Soberanía presentan el "Programa Agrario de los guerrilleros" donde proponen una Reforma Agraria Revolucionaria y un Frente Único del Pueblo. El 20 de mayo de 1964 durante el desarrollo de la Operación Soberanía, Manuel Marulanda y aproximadamente 300 personas envían una carta al entonces presidente Guillermo León Valencia, exigiendo el retiro de las tropas de Marquetalia y pidiendo la construcción de vías, centros de salud y escuelas, devolución de bienes y juicios públicos a los militares. La carta nunca fue respuesta, así como no fue posible la mediación de Camilo Torres Restrepo, Orlando Fals Borda entre otros para detener los combates. En 2015 la comisión del gobierno en marco de los Acuerdos de paz con las FARC-EP prometió la construcción de carreteras y un puente en Marquetalia.
Entre 1965 y 1975, ya se habían establecido cuatro núcleos de expansión de las FARC. El primer núcleo en Meta, Guaviare, Huila, Caquetá, Cundinamarca y occidente del Tolima (Futuro Bloque Oriental). El segundo, en el norte del Cauca, el sur del Tolima y el Valle del Cauca (Futuro Bloque Occidental). El tercero, en el Magdalena Medio (Futuro Bloque Magdalena Medio), y el cuarto, en el Urabá (Futuro Bloque Noroccidental). A finales de los setenta aparece un quinto núcleo de expansión en el Arauca (Frente 10). Su expansión fue significativa entre la Sexta Conferencia 1978 y la Séptima Conferencia 1982. Por las FARC pasaron hombres que después serían comandantes del M-19 como Jaime Bateman, Álvaro Fayad, Carlos Pizarro e Iván Marino Ospina, estos habían sido expulsados o desertado de las FARC debido a sus ideas sobre la necesidad de una guerra urbana.

El 18 de agosto de 1980 el Ataque a Puerto Crevo (Meta), denominado Operación Cisne Tres por 3 columnas de la guerrilla a una patrulla de 20 efectivos del Ejército, fue el primero en el que una unidad completa del Ejército es reducida por la guerrilla. Este sería el punto de inflexión, las FARC-EP pasan entonces de defensa a una estrategia ofensiva exitosa expuesta y establecida en la Séptima Conferencia, reemplazando el denominado Plan Chiquito de la Sexta conferencia. Aparece la primera disidencia en 1982 por parte de Javier Delgado y Hernando Pizarro, antiguos comandantes de las FARC: el Comando Ricardo Franco Frente-Sur en el Cauca. Las FARC contaban entonces con 3.000 hombres y 27 Frentes. En la Séptima Conferencia del 4 al 14 de mayo de 1982, realizada en Guayabero (Meta) bajo el mando del líder político Jacobo Arenas, se plantearon directrices estratégicas nuevas y se reafirmó el principio de la «combinación de todas las formas de lucha»: la lucha política y la armada. A partir de ese momento las FARC se agrega la sigla EP (Ejército del Pueblo) al nombre de las FARC «Ejército del Pueblo» (FARC-EP), se plantea el desdoblamiento de frentes (en Meta, Putumayo, Huila, Cundinamarca, Santander, Casanare, Norte de Santander, Sur de Bolívar, Antioquia, Chocó, Valle del Cauca, Cauca, Tolima y la Sierra Nevada de Santa Marta). Se fijan fechas para una futura toma efectiva del poder en los años noventa, se adoptó un plan militar inmediato, se establece la Ley 001 de Reforma Agraria Revolucionaria. Asignan cuotas de dinero a cada frente, que deberían recaudar de los grandes capitalistas, empresarios del país, y grandes barones de la droga, dando instrucciones en todo caso de que no apareciera el nombre de la organización involucrado. Se establece el cobro de impuestos a productores y a narcotraficantes como fuente de financiación, mediante el llamado «gramaje».

Acuerdos de La Uribe y la Unión Patriótica (UP)

El 28 de marzo de 1984, tras una reunión de los líderes de los 27 frentes y del Estado Mayor, se establece un alto el fuego, como parte de los acuerdos firmados con el gobierno de Belisario Betancourt.. Las FARC-EP formaron la Unión Patriótica (UP) junto a otros movimientos sociales y políticos del país. Las FARC-EP, como uno de sus actores principales, delegaba a varios líderes la función política, incluso se propuso a Jacobo Arenas como candidato presidencial después retirado por la situación de violencia. La UP tuvo éxito en las elecciones de 1986. Por lo cual se volvió un objetivo militar de la guerra sucia. .Según el informe del Centro Nacional de Memoria Histórica (CNMH) "Todo pasó frente a nuestros ojos. El genocidio de la Unión Patriótica 1984-2002." La violencia contra la Unión Patriótica dejó, por lo menos 4.153 personas asesinadas, secuestradas o desaparecidas Esta violencia sistemática fue ejecutada por alianzas entre paramilitares, narcotraficantes, empresarios, funcionarios públicos Policía Nacional y Ejército Nacional lo cual llevaría a romper el proceso de paz y a la separación de las FARC-EP del experimento político de la Unión Patriótica. Estos asesinatos de los miembros de la UP fueron declarados en 2014 por la Fiscalía General de la Nación como delitos de lesa humanidad.

Este intento de negociación fracasó debido en gran medida a dos elementos: las violaciones del cese de hostilidades por las dos partes, y la guerra sucia de sectores de la extrema derecha, financiando escuadrones privados a partir de sus propios grupos de sicarios, incluyendo la participación de asociaciones de ganaderos, terratenientes, industriales, políticos y militares reforzando los grupos paramilitares locales, así como la continuidad de acciones violentas y de enfrentamientos con narcotraficantes como Gonzalo Rodríguez Gacha y el Cartel de Medellín contra las FARC-EP.Coordinadora Guerrillera Simón Bolívar
En 1987 se conformó un grupo que pretendía unificar el accionar de varias organizaciones guerrilleras en Colombia. Su duración fue desde 1987 hasta principios de la década de 1990. La integraban las FARC-EP, la UC-ELN, el EPL, M-19,el Partido Revolucionario de los Trabajadores y el Movimiento Armado Quintín Lame. Luego de algunas acciones conjuntas como la Toma de Saiza en 1988, se desmovilizó el M-19, el Quintín Lame, el 95% del EPL, y el PRT en 1991.Las FARC-EP y el ELN continúan hasta 1994 para continuar por separado la lucha armada, posteriormente realizaron acciones conjuntas en casos específicos, y llegaron a enfrentarse entre ambas organizaciones.

A inicios de los años noventa, las FARC-EP disponían de entre 7.000 y 10.000 combatientes, organizados en 70 frentes distribuidos en todo el país. El 10 de agosto de 1990 falleció el ideólogo de las FARC-EP Jacobo Arenas en Casa Verde, el nuevo ideólogo sería Alfonso Cano. El 9 de diciembre de 1990, día de las elecciones para la Asamblea Constituyente, el Ejército Nacional realizó la Operación Casa Verde contra el principal campamento de las FARC-EP y de los pasados diálogos de paz El gobierno colombiano argumentó que tomó esa medida porque las FARC-EP habían incumplido sus compromisos, ya que todavía realizaban actividades delictivas y no se habían acogido a la negociación. Las FARC-EP se desvinculan del Partido Comunista y de la Unión Patriótica y emprenden una campaña de exterminio contra los desmovilizados del EPL que habían constituido el movimiento Esperanza, Paz y Libertad en actos como la Masacre de la Chinita.

Diálogos de paz de Tlaxcala

El 3 de junio de 1991 se reinició el diálogo entre la Coordinadora y el gobierno, en Caracas (Venezuela) y luego en Tlaxcala (México). La guerra no se detuvo y continuaron las acciones armadas por ambas partes. La negociación se rompió en 1993. La Coordinadora como tal desapareció en 1994, y los grupos guerrilleros siguieron sus actividades independientemente.

Antes de dicha ruptura, se dio a conocer una carta escrita por un grupo de intelectuales colombianos, como el Nobel de Literatura Gabriel García Márquez dirigida a la Coordinadora Guerrillera Simón Bolívar, donde se les reclamaba acerca de la forma en que están llevando a cabo su lucha y las consecuencias nefastas que ésta estaba dejando en el país. 

Guerra de Movimientos

En abril de 1993 se llevó a cabo la Octava Conferencia donde se crean los 7 Bloques conformados por casi 70 Frentes en las distintas regiones del país: Bloque Oriental, del Mono Jojoy, ‘Urias Cuéllar’ y ‘Romaña’ El Bloque Sur de Raúl Reyes, Joaquín Gómez y Fabián Ramírez. El Bloque Occidental de Alfonso Cano. El Bloque Caribe y el Bloque Magdalena Medio, con Martín Caballero y el Bloque Noroccidental de Efraín Guzmán. Además formulan la Plataforma de un Gobierno de reconstrucción y reconciliación nacional. Se pone en práctica las 'Pescas Milagrosas' o secuestros masivos en las carreteras de Colombia. Entre 1996 y 1998, las FARC-EP propinaron una serie de golpes a la Fuerza Pública , incluyendo una toma de tres días a Mitú (Vaupés), mostrando que habían cambiado la clásica guerra de guerrillas por la guerra de conquista y la de movimientos.Secuestraron un gran número de policías. Y se presentaron batallas (Batalla de la Quebrada El Billar, Batalla de Tamborales, Batalla del Nudo de Paramillo, Batalla de Gutiérrez y la Batalla de Dabeiba), combates y ataques contra la Fuerza Pública y los paramilitares. En este mismo periodo, en Colombia se expanden los cultivos ilícitos y se organizaron marchas de campesinos cocaleros, que paralizaron varias vías del sur de Colombia. Según el gobierno colombiano, las FARC-EP tuvieron influencia. En 1997 la Agencia de Inteligencia de Defensa de EE.UU, había diagnosticado con el estado de precariedad del ejército que la subversión estaba en condiciones de derrotarlo militarmente.Plan Colombia y Diálogos de paz (1998-2002)
En 1998, mediante acuerdos con el gobierno del recién elegido presidente Andrés Pastrana Arango, se creó la "Zona de distensión", una zona desmilitarizada de unos 40.000 km², (aproximadamente el tamaño de Dinamarca), entre los municipios de Mesetas, La Uribe, La Macarena, Vista Hermosa y San Vicente del Caguán (departamentos de Meta y Caquetá), para llevar a cabo un proceso de paz con este grupo armado. En dicha zona, las FARC-EP tuvieron presencia en cascos urbanos y se las acusa de efectuar violaciones a los Derechos Humanos, se afirma que las FARC-EP incrementaron la producción y tráfico de drogas, la compra de armamento ilegal y la presión sobre las autoridades locales. El "proceso de paz" duró entre 1998 y 2002. A pesar de varios avances teóricos y documentales, las FARC-EP crearon el Movimiento Bolivariano en el 2000, las tensiones, incidentes como "la silla vacía" y polémicas alrededor de la negociación no permitieron que se concretara el proceso. El 20 de febrero de 2002, la Columna Móvil Teófilo Forero, secuestró un avión de la aerolínea Aires en el que viajaba el senador Jorge Gechem, liberados ese mismo día a todos los pasajeros excepto al senador. Los profundos desacuerdos entre el Gobierno Colombiano y la guerrilla en relación a los controles aéreos, terrestres y fluviales en la zona desmilitarizada, llevaron al gobierno de Pastrana a dar por terminadas las negociaciones con las FARC-EP.

Durante todo el proceso de paz, el Gobierno Colombiano y las FARC-EP se acusaron mutuamente de impedir el normal desarrollo del proceso:





Gobierno de Álvaro Uribe (2002-2010)

Álvaro Uribe, inicia la implementación del Plan Patriota,que implicó la intensificación del combate contra las FARC-EP, sosteniendo la tesis de que en Colombia no existe un conflicto armado sino una amenaza terrorista. Por su parte, las FARC-EP decidieron promover un regreso a la estrategia de guerra de guerrillas, para conservar su estructura, y sufrir deserciones deserciones y operativos militares. Hacia 2002, el gobierno estimaba el número de guerrilleros de las FARC-EP en alrededor de 18.000, y en 2005, entre 12.000 y 13.000. En 2008, el ejército estimaba que tendrían 8.000 guerrilleros en sus filas. Las FARC-EP no solían mencionar cifras específicas, pero estiman que tendrían más de 20.000 hombres. Otras fuentes mencionan diferentes cifras. Se presentaron casos de falsos positivos (civile asesinados y presentados como guerrilleros abatidos en combate). Las FARC-EP atentaron contra el Club El Nogal el 7 de febrero de 2003.,Atentado con casa-bomba en Neiva el 14 de febrero de 2003, El 6 de mayo de 2003, asesinaron al gobernador de Antioquia Guillermo Gaviria y a Gilberto Echeverri, secuestrados un año antes, también se registraron los Atentado en Zona Rosa de Bogotá de 2003, Atentado al Palacio de Justicia de Cali en 2008 entre otras acciones.

Durante el primer periodo presidencial de Álvaro Uribe, no hubo contactos entre las FARC-EP y la administración para hablar de paz. Posteriormente, continuaron algunas esporádicas gestiones diplomáticas en pro de un acuerdo humanitario de intercambio de prisioneros o canje, entre las FARC-EP y el gobierno colombiano. Las FARC-EP pedían que se liberaran todos sus guerrilleros presos, incluidos alias «Simón Trinidad» y alias «Sonia» (extraditados a Estados Unidos acusados de narcotráfico y secuestro), Las FARC-EP liberarían a 44 secuestrados, los denominados «canjeables». Para realizar dicho intercambio, las FARC-EP reclamaron la desmilitarización de dos municipios (Pradera y Florida). Según varios observadores, lo aprovecharon con fines políticos y militares y recibió numerosas críticas de la población civil nacional e internacional. 

Acuerdo humanitario

En agosto de 2007, Uribe designó a la senadora del Partido Liberal y opositora del gobierno Piedad Córdoba como facilitadora para el Acuerdo Humanitario de prisioneros y rehenes. Posteriormente se autoriza también la participación del Presidente de Venezuela Hugo Chávez en la facilitación. Los sujetos del eventual acuerdo incluían, entre otros, a Íngrid Betancourt, tres ciudadanos estadounidense, prisioneros de las FARC-EP así como a 'Simón Trinidad' y alias «Sonia», dos integrantes de FARC-EP extraditados a los EE. UU. Las gestiones de Córdoba y de Chávez lograron que se aceptara la ciudad de Caracas como territorio neutral para las conversaciones. Los gobiernos de EE. UU, Francia, España y Suiza demostraron interés en el proceso iniciado. El Movimiento de Países No Alineados, Brasil, Bolivia, Cuba, Ecuador, Nicaragua y Uruguay respaldaron las gestiones.En noviembre, en medio de la visita de Chávez a París, el gobierno Uribe estableció como límite de las gestiones el 31 de diciembre de 2007. El 21 de noviembre de 2007 el gobierno colombiano decidió terminar con la mediación del presidente Chávez, por una conversación telefónica entre el presidente venezolano y el Comandante del Ejército Colombiano General Mario Montoya. Organizaciones de apoyo a los secuestrados y la familia de Betancourt expresaron su desacuerdo con esta decisión y pidieron que se reiniciaran las gestiones. El presidente francés Nicolas Sarkozy expresó que seguía apoyando la gestión realizada por Chávez. El martes 20 de noviembre, Chávez le había dicho al presidente francés que Betancourt estaba viva sin aportar pruebas de supervivencia, según dijo porque estas no habían podido llegar a sus manos debido a operativos militares en Colombia.

El 29 de noviembre, el ejército colombiano incautó a milicianos urbanos de las FARC-EP en Bogotá unas grabaciones en vídeo donde se muestran con vida y en precarias condiciones a varios rehenes, entre ellos la excandidata presidencial. Según Córdoba, esta era la prueba de que la gestión de Chávez y de ella iban por buen camino. La interrupción de la gestión de Chávez causó un incidente diplomático entre los dos países. Tanto 'Iván Márquez', representante las FARC-EP, como Uribe expresaron su confianza en la mediación de Sarkozy para que el proceso de canje de rehenes siguiera adelante. Las FARC-EP realizan una liberación de secuestrados unilateral el 30 de enero de 2009. Más adelante, en abril las FARC-EP anunciaron la liberación del cabo del Ejército Pablo Emilio Moncayo y la entrega a Emperatriz de Guevara de los restos de su hijo, el secuestrado fallecido en cautiverio mayor Julián Ernesto Guevara. El 18 de junio de 2007, las FARC-EP asesinaron a 11 diputados secuestrados en 2002.Marcha internacional en contra de las FARC-EP

Durante el mes comprendido entre el 4 de enero y el 4 de febrero de 2008 se organizó una marcha ciudadana contra las FARC-EP, el secuestro y la guerra. fue realizada en 4 de febrero de 2008 en más de 160 ciudades alrededor del mundo bajo la denominación: "Un millón de Voces contra las FARC" y logró convocar a más de 12 millones de personas alrededor del mundo.

Debilitamiento del Secretariado y Operación JaqueEl 1 de marzo del 2008, Luis Edgar Devia Silva, alias Raúl Reyes, muere en la Operación Fénix bombardeo de la Fuerzas Militares a un campamento guerrillero ubicado en Ecuador, cerca de la frontera colombiana. Esta incursión desencadena una crisis diplomática entre Colombia, Ecuador y Venezuela. El 7 de marzo de 2008 se anuncia que Iván Ríos miembro del secretariado de las FARC-EP: fue asesinado por su guardia personal, quienes huyeron entregándose al gobierno colombiano. El 26 de marzo de 2008, Manuel Marulanda, el fundador y jefe de las FARC-EP también muere (por causas naturales), en menos de un mes la cúpula de la organización es sacudida.

Las negociaciones por el "acuerdo humanitario" prosiguieron, hasta el 1 de julio de 2008 las Fuerzas Militares realizaron la Operación Jaque rescate de un grupo de secuestrados en poder de las FARC-EP en las selvas del Guaviare.En esta operación liberaron a la excandidata presidencial Ingrid Betancourt, junto a tres contratistas norteamericanos y once soldados y policías colombianos que llevaban entre dieciséis años secuestrados. Junto a Ingrid Betancourt también convivieron otros dos liberados: Alan Jara, ex gobernador del Meta, liberado el 3 de febrero de 2009. y Clara Rojas fue liberada el 10 de enero de 2008. Uribe se mantuvo en su posición frente al acuerdo humanitario. El 22 de diciembre de 2009, las FARC-EP asesinaron al Gobernador de Caquetá, Luis Francisco Cuéllar. En mayo de 2010, en Caquetá las FARC-EP atacaron y mueren 9 militares

Gobierno de Juan Manuel Santos (2010-2018)
Electo Juan Manuel Santos se continúo en la guerra con las FARC-EP, y en búsqueda de entablar diálogos de paz en secreto. El 22 de septiembre de 2010, el jefe militar de las FARC-EP Víctor Julio Suárez, alias Jorge Briceño o El Mono Jojoy murió en la Operación Sodoma, en el Meta. El 20 de noviembre de 2010 se realiza la Operación Némesis y es abatido Fabián Ramírez. El 9 de abril de 2011, detenido Víctor Ramón Vargas quien supuestamente buscaba apoyo de la banda terrorista española ETA para asesinar en España a dos expresidentes colombianos. El 4 de noviembre de 2011, fue abatido Guillermo León Sáenz Vargas, alias ‘Alfonso Cano’, sucesor en la comandancia de las FARC-EP de Manuel Marulanda, "Tirofijo"; en la Operación Odiseo. El 26 de noviembre de 2011 la guerrilla asesinó a 4 secuestrados de más de diez años secuestrados en Caquetá.El 3 de febrero de 2012, una oleada de atentados en el suroeste de Colombia causó al menos 19 muertos y un centenar de heridos. El 18 de marzo, otro ataque de las FARC-EP causó la muerte de 11 militares del Ejército Nacional en Arauca, cerca de la frontera con Venezuela. El 21 de marzo de 2012, el Gobierno inició el plan 'Espada de honor', el 28 de marzo, la Operación Armagedón en Vista Hermosa (Meta) dejan 36 guerrilleros muertos y tres capturados. El 5 de abril de 2013, 4 militares colombianos murieron durante los combates con la guerrilla en el norte de Cauca. El 20 de julio murieron 21 militares colombianos en dos ataques atribuidos a las FARC-EP en los departamentos de Arauca y Caquetá, 

Después de mantener conversaciones en secreto por parte del gobierno y las FARC-EP, en septiembre de 2012 se confirma por parte de Juan Manuel Santos de las negociaciones secretas, pasando a la fase pública de negociación.El 15 de abril de 2015, las FARC-EP lanzaron un ataque en la región de Cauca que costó la vida a 11 militares, rompiendo el alto el fuego iniciado en diciembre de 2014.

El 23 de junio de 2016, después de casi cuatro años de diálogos entre el Gobierno colombiano y las FARC-EP desarrollados en La Habana (Cuba), se declaró el cese temporal pero indefinido de las acciones militares de ambos bandos además de la desmovilización, entrega de armas y reinserción a la vida civil de los militantes del grupo subversivo. Era el fin de las FARC-EP como organización insurgente y alzada en armas. Esta acción fue realizada en La Habana, Cuba, donde se desarrollaron los diálogos de casi cuatro años. después de la firma oficial de los acuerdos que se realizará en Colombia, se procede con la movilización de los ahora ex insurgentes a las Zonas Veredales Transitorias de Normalización y campamentos en el país destinados a la desmovilización y la entrega del armamento a la ONU en una lapso de seis meses. El 26 de septiembre de 2016 se firma de manera oficial el Acuerdo de La Habana en la ciudad de Cartagena, con presencia de varios jefes de estado y personalidades de otros países, además del Secretario General de la ONU; Ban Ki-moon. El 24 de noviembre de 2016 se firma el acuerdo modificado en el Teatro Colón de Bogotá, tras la negativa a los acuerdos originales en el plebiscito realizado el 2 de octubre; acuerdo que es ratificado en el Congreso de la República. El 1 de diciembre de 2016 reinicia el proceso de movilización de los ex subversivos a las Zonas Veredales Transitorias de Normalización.

El 27 de junio de 2017 la ONU certifica la entrega total de armas por parte de las FARC-EP a este organismo (un total de 7.132 armas individuales, excepto las utilizadas para vigilar y proteger a los excombatientes en las zonas y campamentos), las cuales quedan embaladas en contenedores para después ser fundidas, con el objetivo de hacer tres monumentos que recuerden a las víctimas del conflicto que estarán ubicados en: Bogotá (capital del país), La Habana (sede de los diálogos) y Nueva York (sede de la ONU). El 14 de agosto de 2017 son entregadas a la ONU las últimas armas correspondientes al esquema de seguridad de las Zonas Veredales y campamentos de los ex insurgentes de las FARC-EP, completando así 8.112 armas entregada, más de un millón de cartuchos destruidos. También se incluye la destrucción por parte de la ONU de granadas, explosivos, minas antipersona y caletas con armas. De esta manera, las FARC-EP dejan de existir oficialmente como grupo beligerante. El 24 de agosto de 2017 se conoció el listado de bienes que las FARC-EP entregaron con el que se supone que ayudarían a reparar las víctimas del conflicto armado interno, las FARC-EP presentaron un listado en el que relacionaban especialmente utensilios domésticos, cirugías, carreteras, armamento y fincas. Se establece hasta el 31 de diciembre de 2020 para entrega de bienes.

Del 28 al 31 de agosto de 2017, exintegrantes de las FARC-EP fundaron el partido político Fuerza Alternativa Revolucionaria del Común.El cual conserva las iniciales de las FARC pero cambiando el nombre a Fuerza Alternativa Revolucionaria del Común. 11 de marzo En las Elecciones del Congreso de 2018, donde obtuvieron un poco más de 85.000 votos, entre Senado y Cámara de Representantes; sin embargo, en cada corporación tienen 5 escaños gracias a los Acuerdos de paz que les garantizan, de manera fija durante 8 años, estas curules en el Congreso de la República.El 27 de octubre de 2019 Julián Conrado es electo alcalde de Turbaco (Bolívar), por el partido Colombia Humana, convirtiéndose en el primer exguerrillero de las FARC-EP en ser alcalde por elección popular.

Hasta el 8 de agosto de 2020, 223 excombatientes de las FARC-EP han sido asesinados desde la firma de los Acuerdos de Paz.

En comunicados a la opinión pública, las FARC-EP afirmaron en su momento que su objetivo era acabar con las desigualdades sociales, políticas y económicas, la intervención militar y de capitales estadounidenses en Colombia, mediante el establecimiento de un Estado marxista-leninista y bolivariano. En 1964 con su fundación luego de la Operación Soberanía presentan el "Programa Agrario de los guerrilleros" donde proponen una Reforma Agraria Revolucionaria y un Frente Único del Pueblo. En 1993 a partir de su octava conferencia las FARC-EP presentan la "Plataforma de un Gobierno de reconstrucción y reconciliación nacional" en la cual proponen una doctrina militar bolivariana, un parlamento unicameral, elección por votación del procurador, que el Estado sea el administrador de los recursos energéticos, comunicaciones, y servicios públicos, así mismo proponen una inversión del 50% del presupuesto nacional en bienestar social, y del 10% en investigación científica, y un cambio en las políticas agrarias, de explotación de recursos naturales y de política exterior. Las FARC-EP dictaron 3 leyes durante su historia la primera en 1982 de la Reforma Agraria Revolucionaria, la segunda en 2000 sobre tributación y un "impuesto" y la tercera también de 2000 sobre la corrupción administrativa

La Conferencia Nacional era la máxima instancia de las FARC-EP y en la elección de sus delegados tenían derecho a participar todos los integrantes de la organización. Esta conferencia era organizada por el Secretariado y era la encargada de nombrar al Estado Mayor Central. En total tuvieron 10 conferencias: (1965, 1966, 1969,1970,1974,1978,1982,1993, 2007 y 2016):
Para el 2010, se estimaba que las FARC-EP estaban presentes y ejercían su influencia principalmente en zonas de 24 de los 32 departamentos de Colombia como Putumayo, Cundinamarca, Tolima, Huila, Meta, Casanare, Arauca, Vichada, Caquetá, Guaviare, Nariño, Cauca, Chocó, Antioquia, Santander, La Guajira, Magdalena y Valle del Cauca. El gobierno de Colombia había reportado la existencia de operaciones militares y campamentos en los países que tienen frontera con Colombia, como Venezuela, Ecuador, Panamá y Brasil.

Sus operaciones fueron intermitentes, abarcaban gran parte del territorio Colombiano y se realizaban de acuerdo a necesidades operacionales y de movilización. En los últimos años, antes de la firma del acuerdo de paz, centró su accionar en las zonas de frontera. Las FARC-EP también tenían presencia urbana (frentes urbanos, conocidos como milicias o células) en varias ciudades colombianas, donde realizaban acciones de encapuchados en universidades públicas y de terrorismo. A su vez contaban con presencia en zonas pobres o marginales urbanas, donde se disputaban los territorios con los también desmovilizados paramilitares, o donde hubiesen construido barrios. En total contaron con 7 bloques (Central, Oriental, Occidental, Noroccidental,Caribe, Sur y Magdalena Medio) conformados por 66-70 frentes, 4 frentes urbanos y 14-20 columnas móviles. En varias operaciones utilizaron medios y armas no convencionales que están prohibidas por la Convención de Ginebra y las Naciones Unidas. La estructura militar de las FARC-EP estuvo determinada hasta el año 2016, cuando firmaron los Acuerdos de Paz, que terminaron el conflicto de esta guerrilla con el Gobierno, disolviéndose como organización alzada en armas:

Número de efectivos

Su número de efectivos varía según las fuentes. En 2001 se estiman hasta en 16.000, pero después de las derrotas posteriores, el grupo se redujo. Entre 2002 y 2010 se han registrado 12.216 desmovilizados de las FARC-EP.La Consultora en Seguridad y Defensa "Decisive Point" asegura que entre 2011 y 2013 la cifra de militantes en armas de las FARC-EP pasaron de 9.075 a 6.672 por la presión de las Fuerzas Militares. En 2014 el Centro de Estudios para el Análisis de Conflictos aseguró que las FARC-EP tenían entre 6.500 y 6.700 miembros militantes en armas. Según un informe de Human Rights Watch, entre el 20% y el 30% son menores de 18 años, muchos reclutados forzosos, según información gubernamental . En 2017 La Universidad Nacional de Colombia realiza un censo socioeconómico a 10.015 guerrilleros: entre combatientes (55 %), milicianos (29 %) y privados de la libertad (16 %), pero al no ser un censo poblacional no constituyen el total de miembros que se desmovilizaron. Se estableció que 9929 eran colombianos y habían 86 extranjeros. También que 66% eran de áreas rurales, 19% urbanas y 15% mixtas. 3003 eran de grupos étnicos, 77 % son hombres y el 23 % mujeres y un alfabetismo del 90%.Las mujeres, que tuvieron presencia en la organización desde un inicio pero solo se las reconoció como guerrilleras a partir de 1970, conformaron aproximadamente el 40% de las FARC-EP.

Las FARC-EP tenían una revista donde difundieron sus comunicados, una radio clandestina en los distintos territorios donde se encontraban, llamada La voz de la resistencia. También realizaron vídeos sobre sus acciones denominados 'FARC Films' e intervinieron la señal de televisión en conjunto con el M-19.

La financiación para sus actividades tenía múltiples orígenes:


Las acciones violentas de las FARC-EP la constituyeron como un actor armado importante del Conflicto armado interno de Colombia. Sus métodos de combate incluían la guerra de guerrillas y combate regular convencional. Las Naciones Unidas, Amnistía Internacional, Human Rights Watch, entre otros, reclamaron a las FARC-EP por violaciones al derecho internacional humanitario y al Protocolo II adicional a los Convenios de Ginebra igualmente solicitaron a las FARC-EP que dejaran de usar armas no convencionales (como los cilindros bomba y armas químicas)"."

Las principales acciones violentas, y violaciones del Derecho Internacional Humanitario por parte de las FARC-EP fueron:


Las FARC-EP utilizaron carros bomba ,animales bomba, carretillas bomba , bicicletas bomba., cilindros bomba Estos hechos fueron certificados por un informe de las Naciones Unidas. Las FARC-EP dirigieron estos atentados hacia las Fuerzas Militares, entidades del gobierno, población civil y la infraestructura petrolera. Un informe afirma que entre 2003 y 2012, a las FARC-EP se les atribuyen 3.274 actos terroristas, en los que derribaron torres de energía eléctrica, atacaron oleoductos de Ecopetrol, volaron puentes, vías, asesinaron miembros de la Fuerza Pública y dañaron bienes de la sociedad civil.

En ninguno de los casos existió dudas sobre los responsables de los atentados. En varias ocasiones se llegó a acusar inmediatamente a las FARC-EP, sin haber comprobado plenamente su responsabilidad. A finales del 2006 se presentaron casos donde militares colombianos fueron investigados por la justicia colombiana por su participación en el montaje de falsos atentados en la ciudad de Bogotá durante ese año, originalmente atribuidos a las FARC-EP.

Sus principales atentados terroristas fueron: Atentado con casa bomba en El Dorado, Atentado al edificio Residencias Tequendama, Atentado al Club El Nogal, Atentado con casa-bomba en Neiva, Atentado en Zona Rosa de Bogotá de 2003, Atentado al Palacio de Justicia de Cali de 2008, Atentado al edificio de Caracol Radio de 2010.

El secuestro fue uno de varios métodos utilizados por la guerrilla. Se ha identificado que durante el periodo 1970 – 2010, las FARC-EP estuvieron involucradas como autor presunto en 9.447 secuestros y como autor confirmado en 3.325. En un informe entregado a la JEP se establece que 522 personas murieron cuando estaban secuestradas por las FARC-EP. Fueron secuestrados militares, funcionarios públicos, políticos, periodistas, empresarios, ciudadanos extranjeros Algunos de sus secuestrados, llegaron a cumplir más de 10 años en su poder. Realizaron secuestros colectivos o 'pescas milagrosas'. En varias oportunidades los secuestrados murieron en las operaciones de rescate. Uno de los casos más recordados a nivel mundial fue el secuestro de la excandidata presidencial colombiana Íngrid Betancourt, quien fue secuestrada en medio de su campaña presidencial. Según los relatos y pruebas recolectadas, cada secuestrado en poder de las FARC-EP era encadenado durante varias horas al día y supervisado por un guerrillero. 

Según el Centro Nacional de Memoria Histórica las FARC-EP están sindicadas de cometer más de 240 masacres con cerca de 1400 víctimas, solo entre el periodo 1980-2012. Algunas de las masacres registradas fueron: Masacre en el cañón del río Ata (1966),Masacre de Guaduas Negras(1975), Asaltos en Planeta Rica (Córdoba), Valparaíso (Caquetá) y Pavarando Grande (Antioquia)(1981),Masacre de La Traviata y las Palmas(1984),Masacre de Bejucales(1987),Masacre de La Chinita(1994),Masacre de Los Kunas y Masacre de Bajo del Oso(1995),Masacre de Osaka y Masacre de Alto de Mulatos y Pueblo Bello(1996), Masacre de Río Manso y Masacre de Tarazá(2001), Masacre de Bojayá(2002), Masacre de San Carlos, Antioquia(2003),Masacre de La Gabarra,Masacre de San Salvador, Tame(2004),Masacres de indígenas Awá en Nariño de 2009. 

En la Masacre de Bojayá (Chocó), ocurrida el 2 de mayo de 2002, murieron entre 74 y 119 civiles a causa de un cilindro-bomba lanzado por las FARC-EP contra una iglesia. Se trataba de civiles que se habían refugiado en la iglesia en medio de un combate entre las FARC-EP y paramilitares de las AUC, los paramilitares rodearon la iglesia para usar a los civiles como escudos humanos y evitar el fuego guerrillero. Por este hecho las FARC-EP, a través de alias "Pastor Alape", pidieron perdón a los familiares de las víctimas de esta masacre en la misma iglesia donde ocurrió, en el proceso de paz con el gobierno de Juan Manuel Santos. 
Según el informe del Centro Nacional de Memoria Histórica y el Instituto de Estudios Políticos y Relaciones Internacionales (IEPRI) de la Universidad Nacional de Colombia: "Tomas y ataques guerrilleros (1965 - 2013)" publicado en 2016, las FARC-EP fueron responsables de 1.106 tomas y ataques a poblaciones y puestos de policía, (un 63% de 1.755 incursiones guerrilleras en Colombia). Siendo los departamentos más afectados: Cauca (244 acciones), Antioquia (113), Nariño (87), Cundinamarca (74), Huila (67) y Tolima (66).

Desde su fundación en 1964, hasta su desmovilización en 2016, se registraron enfrentamientos con la Fuerza Pública de Colombia, grupos paramilitares y narcotraficantes,incluso con el ELN en medio del conflicto armado interno de Colombia, en medio de los cuales se registraron tomas guerrilleras,secuestros, masacres,emboscadas, atentados y batallas campales. Algunos de estos enfrentamientos se hicieron coordinadamente con otras guerrillas a través de la (Coordinadora Guerrillera Simón Bolívar), o en operaciones conjuntas con el ELN,el EPL, el M-19, y otros grupos guerrilleros. Los enfrentamientos hicieron parte de las diferentes fases de guerra de guerrillas y de la guerra de movimientos.

Sus principales emboscadas fueron: Emboscada de El Carmen(1966), Emboscada de La Perdiz (1967), Emboscada de La Quebrada Riecito (1987), Emboscada a grupo de Caballería(1996), Emboscada de La Carpa(1996), Emboscada de El Porroso(2005), y la Emboscada de la Carbonera(2007).

Sus principales tomas, ataques y asaltos fueron:Ataque a Puerto Crevo,Toma de Saiza, Toma de la base militar de Tarazá, Ataque a la base militar del Cerro Girasoles, Toma de Churuyaco,Toma de Ituango (Antioquia), Ataque a la Base Militar de Las Delicias, Ataque a la Base Militar del Cerro Patascoy, Toma de Miraflores, Toma de La Uribe, Toma de Mitú,Toma de Cocorná (Antioquia),Toma de Puerto Rico (Meta),Toma de Puerto Lleras (Meta),Toma de Nariño (Antioquia),Toma de San Luis (Antioquia),Toma de Granada (Antioquia),Toma del Cerro Tokio (Valle del Cauca),Ataque a la Base Militar de Coreguaje, Ataque al Cerro Montezuma (Risaralda), Asalto al edificio Miraflores, Toma de Iscuandé, Toma de San Marino, Ataque a la Isla Gorgona.

Las Fuerzas Militares de Colombia realizaron múltiples operaciones contra las FARC-EP durante los distintos gobiernos las principales fueron: Operación Soberanía (1964), Operación Casa Verde (1991), Operación Hato Corozal(1999), Operación Berlín(2000), Operación Gato Negro(2001),Operación TH Todo Honor(2002), Operación Orión(2003), Operación Libertad Uno(2003), Operación Jirafa(2003), Operación Alcatraz u Operación Aromo(2007),Operación Sol Naciente o Joya del Nilo (2007), Operación Fénix(2008), Operación Jaque(2008), Operación Fuerte(2009), Operación Dinastía(2009), Operación Camaleón(2010), Operación Sodoma(2010), Operación Némesis(2010), y la Operación Odiseo(2011).

Las FARC-EP, durante su existencia como organización militar insurgente, fueron consideradas una agrupación terrorista por diversos Estados ( Chile, Perú, Estados UnidosCanadá, Nueva Zelanda y Colombia), la Unión Europea, la cual retiró de su lista de organizaciones terroristas en 2016 tras la firma de los acuerdos de paz. Otros gobiernos latinoamericanos como Brasil o Argentina no le aplicaron esta calificación.Ecuador le otorgó el reconocimiento de "grupo irregular", Venezuela con Hugo Chávez solicitó que se le otorgue un estatus de "grupo beligerante" y no las considera terroristas. Sin embargo en agosto de 2010, manifestó que las FARC-EP no tienen futuro e igualmente les pidió liberar a los secuestrados. También dijo que las FARC-EP tienen un «proyecto político bolivariano» que en su opinión es respetado en Venezuela. Además observadores internacionales han reiterado el apoyo económico, político y militar que el gobierno del expresidente Hugo Chávez podría haber hecho a las FARC-EP. Amnistía Internacional condenó públicamente a las FARC-EP por diferentes actos de terrorismo Les pidió terminar con los actos de violación de derechos humanos contra civiles Las partes en un Conflicto armado interno tienen la obligación de respetar el DIH y este hecho no tiene ningún impacto sobre su estatuto jurídico. El CICR no tiene la competencia para reconocer el estatuto jurídico, o pronunciarse sobre el estatuto político de las partes en conflicto.Organizaciones de Derechos Humanos como Human Rights Watch y Amnistía Internacional los consideraron, al igual que a otros grupos ilegales, culpables de violar los derechos humanos, de atacar y perjudicar indiscriminadamente a civiles.A pesar de los acuerdos de paz entre el gobierno de Juan Manuel Santos y las FARC-EP, el Gobierno de los Estados Unidos todavía mantiene el estatus de agrupación terrorista, mientras que el Ejército las comparó con el Estado Islámico (EI) y Al Qaeda. Las FARC -EP estuvieron presentes a través de una Comisión internacional, y en áreas fronterizas e hicieron presencia militar en:


Como política de Estado en la lucha anticomunista en Colombia y como herencia de la violencia política en Colombia los grupos paramilitares conocidos como pájaros siguieron activos en los años 60 y como efecto de la guerra fría se conformaron grupos contrainsurgentes, luego de una visita al país del General William P. Yarborough. en febrero de 1962. El 25 de diciembre de 1965 el gobierno de Guillermo León Valencia expide el Decreto 3398 (luego Ley 48 de 1968 del gobierno de Carlos Lleras Restrepo) que permite a los militares entregar armas de uso privativo de las FF.MM a los civiles y constituir grupos armados de autodefensa coordinados por el ejército. Esta normativa fue declarada inexequible o inconstitucional por la Corte Suprema de Justicia el 25 de mayo de 1989. Desde 1969 se emitieron una serie de Manuales y Reglamentos Contraguerrillas por el Ejército Colombiano, los cuales evidenciaron la creación de grupos paramilitares bajo la aprobación del Gobierno Colombiano. En los 80's se fortalecen los grupos de autodefensas paramilitares contrainsurgentes regionales, financiados por hacendados, multinacionales, narcotraficantes colombianos, algunos sectores de la sociedad civil y miembros de instituciones estatales. En 1979 las FARC secuestraron a Jesús Castaño en Amalfi, Antioquía padre de los paramilitares Fidel,Vicente y Carlos Castaño Gil cobraron tres rescates, lo torturaron y asesinaron,esto empezó a dar origen a los grupos paramilitares, el M-19 secuestró a Martha Ochoa hermana de los Ochoa del Cartel de Medellín en 1981 que crearon el MAS (Muerte a Secuestradores). El narcotraficante Gonzalo Rodríguez Gacha, enemistado con las FARC-EP por la destrucción de algunos de sus laboratorios en el sur del país y del robo de dinero en efectivo y pasta base de coca en 1983, empezó a apoyar con recursos, entrenamiento y armas a los paramilitares de Puerto Boyacá, nombrada capital antisubversiva de Colombia. Aparecen las Autodefensas Campesinas de Córdoba y Urabá bajo el mando de Fidel y Carlos Castaño. Fueron creadas las Convivir en el Gobierno de César Gaviria Trujillo (Decreto Ley 356 de 1994), posteriormente reglamentadas por el Gobierno de Ernesto Samper Pizano Se estima que se autorizó más de 414 Convivir en todo el país, principalmente por Álvaro Uribe entonces gobernador de Antioquía. Se conforman las Autodefensas Unidas de Colombia (AUC) el 18 de abril de 1997,quienes desarrollaron una guerra en todo el país contra las FARC-EP en conjunto con el gobierno colombiano y las Fuerzas Militares. Desmovilizadas estas las FARC-EP se enfrentaron a los Grupos Armados Organizados nacientes y en algunos casos harían negocios conjuntos. Con la desmovilización de las FARC-EP en 2016 se reparten el territorio dejado por estas los GAO como el Clan del Golfo,el ELN y disidencias de las FARC-EP.

Los grupos disidentes de las FARC-EP se estiman en 1800 hombres en 23 grupos en 5 zonas del país, surgieron disidencias antes de la firma de los Acuerdos de paz, por parte de disidentes del Frente 1 de las FARC-EP. Y se sumaron distintos grupos independientes de disidencias, principalmente por el control del narcotráfico, enfrentadas entre sí. Pero la mayoría de los ex combatientes se desmovilizaron. Las principales son:


Siendo uno de los grupos armados de mayor duración en el conflicto armado interno, su impacto en la cultura y el arte es notorio en producciones literarias, documentales, crónicas, musicales, entre otras por parte de sus miembros, excombatientes o víctimas y por sus acciones. Producían música con cantautores como 'Lucas Iguaran', 'Cristian Pérez', 'Horizonte Fariano', Julián Conrado (actual alcalde de Turbaco (Bolívar) electo por elección popular en 2019), entre otros. También las mujeres farianas excombatientes realizan el documental “Nunca invisibles: mujeres farianas, adiós a la guerra”, otros excombatientes de Arauca realizan la obra de teatro “Desde el arte araucando caminos de reconciliación” y en Putumayo fundación Caracolas de Paz realiza murales en “La ruta del color y la memoria.” Artistas como Doris Salcedo en conjunto con víctimas del conflicto armado realizaron el contramonumento Fragmentos en Bogotá con armas entregadas por las FARC-EP. La exposición fotográfica de Jesús Abad Colorado retrata varios de los episodios de la guerra de este actor armado y sus implicaciones Estas y otras iniciativas culturales se realizan como reparación, memoria histórica y reconciliación. Los excombatientes de las FARC-EP han realizado también la conformación de cooperativas como Cooperativa Multiactiva de Artistas del Común (Coomunarte), y Ecomún (Economías Sociales del Común) y pequeños emprendimientos.





</doc>
<doc id="42755" url="https://es.wikipedia.org/wiki?curid=42755" title="Manuel Marulanda Vélez">
Manuel Marulanda Vélez

Pedro Antonio Marín Marín, conocido como «Manuel Marulanda Vélez» y «Tirofijo», (13 de mayo de 1930 Génova, Quindío, Colombia - 26 de marzo de 2008 Meta, Colombia) fue el guerrillero más veterano del mundo y de su tiempo. Su alias 'Tirofijo' proviene de la habilidad para acertar en el blanco al disparar con armas de fuego durante sus días de combatiente, y su alias 'Manuel Marulanda Vélez' proviene de un antiguo líder comunista asesinado durante La Violencia. Integró y comandó las Fuerzas Armadas Revolucionarias de Colombia - Ejército del Pueblo (FARC-EP) hasta su muerte.

Pedro Antonio Marín Marín nació en Génova, municipio del departamento de Caldas (actualmente pertenece al departamento del Quindío). Existe controversia sobre su fecha de nacimiento, y no está claro si tuvo lugar en mayo de 1928 o de 1930. Era hijo de campesinos liberales que vivían en Ceilán (Valle). Su padre era Pedro Pablo Marín Quinceno y su madre era Rosa Delia Rodríguez y su padrastro Ramiro Betancourt. Sus hermanos eran Rosa Helena, Jesús Antonio, Obdulia y Rosa María.

Su abuelo Ángel Marín, antioqueño de tendencias liberales, fue combatiente en la Guerra de los Mil Días. Marín cursó hasta quinto de primaria en la escuela. A los 13 años se fue de casa.

Marín trabajó como expendedor de carne, panadero, vendedor de dulces, constructor, tendero y comerciante. Como seguidor de liberales, Marín aparentemente habría participado en las revueltas del Bogotazo en 1948, luego del asesinato del líder liberal Jorge Eliécer Gaitán. Se recrudeció una ola de represión y violencia política (periodo conocido en la historia del país como "La Violencia"), dentro de la cual muchos campesinos liberales y de izquierda crearon milicias armadas para protegerse de las acciones de los elementos conservadores más violentos dentro de la clase de los terratenientes y del ejército, además de los simples bandidos oportunistas, por lo que llegaron a ser conocidos como «Los chusmeros». Estas milicias generalmente tuvieron un carácter local y restringido, pero también ejecutaron acciones más ofensivas según las circunstancias. Ambos bandos cometieron atrocidades durante esta fase del conflicto. Algunos de estos crímenes llegaron a tener nombres populares. 'El corte corbata', uno de los más conocidos, consistía en un corte transversal en el cuello, por el que extraían la lengua dejándola colgando, o 'el corte franela', que consistía en un corte alto del cuello.

Dependientes y aliados en principio con el oficialismo liberal, muchas de estas agrupaciones se desmovilizaron parcialmente durante la amnistía decretada por el gobierno militar de Gustavo Rojas Pinilla a inicios de los años cincuenta, pero varias de ellas habían roto gradualmente con la línea partidista y siguieron en armas dentro de sus propias zonas de influencia regional, cuando el país recobraba para entonces una relativa estabilidad política.

Al acercarse la época del Frente Nacional, estas comunidades rurales armadas ya habían tomado un carácter más autónomo y de una tendencia ideológica más cercana al comunismo agrario, de ahí que desde la izquierda algunos las llamaran "zonas liberadas".

Aunque eran todavía mayormente defensivas, desde el gobierno se les consideró una amenaza al ser consideradas unas "repúblicas independientes", donde no tenía influencia la autoridad y la legalidad centralista que se pretendía restaurar.

Luego del pacto entre liberales y conservadores conocido como Frente Nacional para acabar con La Violencia bipartidista, se mantuvo en el país una tensa paz entre 1958 y 1960, producto de las Autodefensas Campesinas del Sur del Tolima que silenciaron sus armas, pero se habían negado a entregarlas argumentando desconfianza hacia esta alianza bipartidista. En el año de 1960 fue asesinado, en complicidad de militares colombianos, Jacobo Prías Álape, alias "Charro Negro", líder comunista de la región de Gaitania en el Tolima; confirmando las sospechas contra la coalición del Frente Nacional, lo que generó el regreso a la lucha armada de varios combatientes comunistas del periodo de La Violencia, incluido "Tirofijo", refugiándose en este mismo territorio que se dio a conocer como la "República de Marquetalia", además de otros territorios donde la autoridad del Estado era nula. En 1964 se tomó la decisión, de parte del gobierno, de acabar definitivamente con esos reductos autónomos por la fuerza e imponer el dominio estatal, para la cual se montó operativos militares para recuperar estos territorios, el más conocido era la "Operación Soberanía" contra la República de Marquetalia, donde estaba Manuel Marulanda. Esta acción del ejército dispersó los asentamientos, obligando entonces a Manuel Marulanda y a otros campesinos partícipes de estas milicias, además de una docena de hombres a internarse en las montañas.

Poco después, estos sobrevivientes se organizarían bajo la dirección de Marulanda y de miembros del Partido Comunista para crear una fuerza subversiva conocida como las FARC (Fuerzas Armadas Revolucionarias de Colombia). A lo largo del desarrollo de la guerra en Colombia, se apartaría de la línea oficial de este partido y se fortalecería con ayuda de actividades ilícitas como el narcotráfico, el secuestro y la extorsión, hasta llegar a un número estimado de 16.000 integrantes en 2001, pero que a 2009 cayó por acciones de la Fuerza Pública a un estimado de entre 6.000 a 9.000 efectivos. Aunque existe información que implica a las fuerzas militares de Colombia, en los llamados falsos positivos o ejecuciones extrajudiciales y presentar cifras falsas de bajas a la guerrilla, existen cifras que estiman entre 4000 y 6000 falsos positivos entre 2001 y 2009. 

Diferentes observadores externos han considerado a Manuel Marulanda como una figura "mediadora" entre el brazo político y el brazo militar de las FARC, inclinándose a favor de una u otra de las tendencias dentro de esa guerrilla, según las circunstancias externas o internas que lo ameritaran.

En 1964 el gobierno colombiano presumió que en los bombardeos de Marquetalia había muerto Marín y el resto de comandantes rebeldes. Fue un rumor falso sobre su muerte acompañado de varios más, algunas veces caído en combate, enfermo por heridas gangrenadas y hasta víctima de hormigas venenosas.

En noviembre de 1970 el periódico El Espacio publicó una serie de crónicas donde se decía que Marín se había enfrentado a tropas del Ejército que le causaron una herida mortal en el pecho. Este y otros tantos relatos perdieron toda credibilidad cuando Marulanda saldría a la luz pública en varias entrevistas previamente a los diálogos de paz del electo presidente Belisario Betancur.

En 1982, el recién electo presidente Belisario Betancur lanza su anhelo y proyecto de alcanzar una paz sin la vía militar, invita a las FARC, al M-19, entre otros grupos para iniciar los diálogos de paz.

Marín acepta reunirse con la Comisión de Paz y acuerda un lugar en el municipio de La Uribe, Meta, el sitio de negociación. Tras varios meses de diálogo las FARC y el gobierno firman los Acuerdos de La Uribe.

De estos acuerdos nace la Unión Patriótica, partido y movimiento político formado no solo por miembros de la guerrilla sino por organizaciones sindicales, de los derechos humanos, etc. Marulanda no estaba muy involucrado en el asunto de la UP pero junto con Jacobo Arenas mantenía su posición de comandante de las FARC-EP, criticaba el exterminio de los militantes de la UP, pedía desmantelar el paramilitarismo en Colombia. Se recuerda una famosa frase que dijo al Comisionado de Paz John Agudelo Ríos:

El ejército por orden del presidente César Gaviria neutraliza Casa Verde, sede del secretariado, el cual logra huir del ataque.

Después de la toma de Casa Verde, las FARC-EP se reúnen con una nueva Comisión de paz luego de la toma de la Embajada de Venezuela por parte de la guerrilla. Las partes se reúnen primero en Cravo Norte, Arauca para luego trasladarse a Caracas, Venezuela, pero tras el Golpe de Estado de febrero de 1992 en Venezuela los diálogos se trasladan a Tlaxcala, México y teniendo a Alfonso Cano como negociador. No obstante, los diálogos se rompen por causa del secuestro y muerte del ex-ministro Argelino Durán Quintero a manos del EPL.

En 1995, una cadena radial informó que 'Manuel Marulanda' había muerto y que el fallecimiento lo había confirmado el miembro del secretariado de las FARC Iván Márquez a la misma emisora. Sin embargo, todo resultó falso.

Marín se reunió con el entonces candidato a la presidencia de Colombia, Andrés Pastrana y acordaron reunirse una vez esté fuera presidente de Colombia para iniciar un proceso de paz.En noviembre de 1998, las FARC-EP y el Gobierno, en reunión entre Marín y Pastrana, acordaron una zona desmilitarizada en Caquetá. Después de la Toma a Mitú, se acuerda la Zona de Distensión donde se presenta el episodio de la "silla vacía", donde Marulanda debía sentarse a representar el inicio de los diálogos de paz con Pastrana. Marulanda no asistió argumentando que iban a atentar contra su vida y que la seguridad no estaba garantizada, una excusa que nunca llegó a creerse por el gobierno y la opinión pública. Pastrana años después desmiente lo que sucedió en realidad: Marulanda no asistió porque de haberse sentado Marulanda, los colombianos creerían que la guerrilla firmó la paz mientras que los subversivos de las FARC-EP creerían que su líder se entregó al Estado Colombiano y eso le traería problemas posteriormente. Aun así se continúan los diálogos de paz sin haber un cese al fuego, el gobierno implementa el Plan Colombia para acabar con los cultivos ilícitos, el plan fue duramente criticado por las FARC, mientras que la guerrilla pone en marcha secuestros en masa (llamados irónicamente por la guerrilla como "pescas milagrosas"), minas antipersona, tomas de poblaciones a sangre y fuego, carros bomba, emboscadas a miembros de la Fuerza Pública, etc. Pastrana harto de las falsas promesas de las FARC-EP decide poner fin a la zona de distensión (irónicamente ese mismo día se había llegado a un cese al fuego) y al Proceso de paz. Tiempo después, se confirmó que la guerrilla estaba usando la Zona de Distensión para rearmarse utilizando las ganancias que le había dejado el narcotráfico en esta zona con los cultivos ilícitos y los laboratorios para el procesamiento de cocaína, que luego vendían a futuros capos de la droga como Daniel Barrera Barrera, alias "El Loco Barrera".

En febrero de 2004, la periodista Patricia Lara afirmó en la revista "Diners" que a Marín lo aquejaba un cáncer de páncreas y no le restaban más de seis meses de vida. La afirmación nunca fue desmentida. Sin embargo, las autoridades encontraron en el computador de Raúl Reyes decenas de comunicaciones dirigidas y escritas por el comandante máximo, con lo que quedó claro que por lo menos hasta finales de 2007, Marín aún estaba vivo.

El 24 de enero de 2008, el diario brasileño 'Correio Brasiliense', citando documentos atribuidos a la Agencia Brasileña de Inteligencia (ABIM), señaló que Marín tenía cáncer y que había una disputa por liderazgo en las Farc.

El 24 de mayo de 2008, la revista colombiana "Semana" publicó una entrevista con el ex ministro de Defensa de Colombia, Juan Manuel Santos en la que este mencionó que los organismos de inteligencia de Colombia presumían que Marín había muerto el 26 de marzo a las 18:30, al parecer por causas naturales o por un paro cardíaco.
Dicha información fue confirmada el 25 de mayo en un vídeo, entregado al canal Telesur, donde aparece uno de los cabecillas, Timoleón "Timochenko" Jiménez, que ratifica la muerte de Marín.

El 1 de febrero de 2009, una guerrillera desmovilizada de las FARC-EP, le entregó al Diario La Nación, de Neiva, Colombia, las primeras fotos del guerrillero muerto. Luce un camuflado nuevo, con las manos cruzadas sobre el pecho y, según las palabras de "Anayibe", guerrillera desmovilizada ""El desplazamiento fue tortuoso. El féretro improvisado estaba protegido por tres anillos de seguridad, integrado por 250 hombres. El ataúd fue desplazado en medio de una espesa selva que comunica al Guaviare con el Meta. El recorrido tardó dos semanas y se hizo en total silencio. Todos los miembros del Secretariado mantenían el secreto. La instrucción era ocultarlo hasta cuando se definiera la sucesión del mando"."

Durante su histórica alocución en la ONU, en diciembre de 1964, el comandante Ernesto "Che" Guevara se refirió a Marulanda en su contrarréplica al representante diplomático de Colombia:

Al igual que los demás bandos en la contienda, la guerrilla que Marulanda dirigía ha cometido abusos contra otros combatientes y contra la población civil a lo largo de la guerra. Organizaciones no gubernamentales calculan que su responsabilidad correspondería a alrededor del 20 por ciento (de 15 a 25 según los diferentes momentos) de los asesinatos políticos anuales en el conflicto. A las FARC-EP también se las considera responsables de un alto número de detenciones de guerra, de reclutamientos de menores, de la colocación de minas antipersonales y de actos de terrorismo. Las FARC-EP están en la lista de organizaciones consideradas como terroristas por el Departamento de Estado de los Estados Unidos y en su equivalente dentro de la Unión Europea. Las Naciones Unidas han condenado varias de sus acciones como crímenes de guerra.

Por todos estos hechos, en el 2001 Human Rights Watch le solicitó a Manuel Marulanda que tomase decisiones para corregir los abusos de sus hombres, pero el Comandante de las FARC-EP no ha respondido directamente a dichas comunicaciones.
Human Rights Watch considera que sus críticas fueron ignoradas o desviadas por la comandancia de la organización terrorista: "El Comandante Marulanda no ha respondido ni a una sola de las preocupaciones que planteamos. En lugar de tomarse en serio nuestras críticas, ha emitido una arenga que desvía la atención de los problemas reales".

Otros voceros de las FARC-EP han respondido que consideran que dichas organizaciones no los estarían juzgando correctamente y que la guerrilla como tal no estaría sujeta a la ley humanitaria internacional que uno de sus comandantes consideró como "un concepto burgués".
Ante dicha respuesta, los críticos de las FARC-EP en el área de los derechos humanos han contestado que la ley humanitaria internacional sí afecta legalmente a esa guerrilla y más aún si esta se considera parte beligerante en el conflicto.

Dentro de las muchas acusaciones en su contra está la sentencia establecida por el Tribunal Superior de Antioquia, Pedro Antonio Marín junto con la cúpula de las FARC-EP, son responsables del secuestro y muerte del exministro de defensa, Gilberto Echeverri Mejía, el exgobernador de Antioquia, Guillermo Gaviria Correa y de ocho militares.

Cuando Marulanda era dirigente de las FARC, reconoció la autoría de su grupo y se le atribuyen los siguientes crímenes, varios de ellos condenados por la comunidad internacional, la ONU, la OEA, entre otros organismos y ONG´s.

Otras condenas y repudios a las FARC:




</doc>
<doc id="42756" url="https://es.wikipedia.org/wiki?curid=42756" title="Silicosis">
Silicosis

La silicosis es la neumoconiosis producida por inhalación de moléculas de sílice, entendiendo por neumoconiosis la enfermedad ocasionada por un depósito de polvo en los pulmones con una reacción patológica frente al mismo, especialmente de tipo fibroso. Encabeza las listas de enfermedades respiratorias de origen laboral en países en desarrollo, donde se siguen observando formas graves. El término silicosis fue acuñado por el neumólogo Achille Visconti (1836-1911) en 1870, aunque desde antiguo se conocía el efecto nocivo del aire contaminado para la respiración. La silicosis es una enfermedad fibrósica-pulmonar de carácter irreversible y considerada enfermedad profesional incapacitante en muchos países. Es una enfermedad muy común en los mineros.

Las partículas respirables de sílice (menores de 5 micras) que alcanzan el parénquima pulmonar y quedan retenidas son fagocitadas por los macrófagos pasando a sus lisosomas, pero los mecanismos destructivos de que disponen éstos (enzimas, radicales oxidantes) son inútiles frente a la sílice; el macrófago acaba destruido y libera en el medio enzimas y radicales que potencian la inflamación y generan más radicales oxidantes y enzimas que no son capaces de destruir la sílice, pero sí de lesionar el propio tejido pulmonar, conduciendo a la fibrosis. De ahí que se haya propuesto una hipótesis inflamatoria en la base de la patogenia de la silicosis. Los sujetos que no controlen bien la respuesta inflamatoria podrían estar en desventaja. Al proceso patogénico se pueden incorporar factores inmunológicos e infecciosos (tuberculosis). La silicosis suele presentarse después de 10 a 20 años de exposición a sílice, a veces tiempo después de cesada la misma, pero en caso de exposición muy intensa puede aparecer precozmente. No todos los trabajadores expuestos desarrollan la enfermedad, lo que sugiere la existencia de factores de predisposición individual, por ahora insuficientemente conocidos.

La lesión elemental es el nódulo de silicosis de aspecto redondeado, con una parte central fibrosa, a veces hialinizada, rodeada de capas concéntricas de colágeno y una zona periférica con macrófagos cargados de sílice y otras células. Es característica la presencia de sílice al examen con luz polarizada. La silicosis simple produce ligeras alteraciones funcionales sin repercusión clínica significativa.

La silicosis complicada se caracteriza por la presencia en los pulmones de masas de diámetro superior a 1 centímetro llamadas masas de Fibrosis Masiva Progresiva (FMP) que al retraerse generan bullas en su periferia y distorsionan los bronquios determinando obstrucción y limitación del flujo aéreo, aparte de otras complicaciones (neumotórax, cavitación aséptica, cavitación por tuberculosis, etc). Si las masas alcanzan cierto tamaño alteran notablemente los parámetros de función pulmonar, tanto de ventilación como de intercambio de gases.

Consiste en la fibrosis nodular de los pulmones y la dificultad para respirar causadas por la inhalación prolongada de compuestos químicos que contienen sílice cristalina. Con frecuencia produce la muerte, causada por respirar polvo que contiene partículas muy pequeñas de sílice cristalina. La exposición a sílice cristalina se puede presentar durante la minería, metalurgia, industria relacionada con químicos, pinturas, cerámicas, mármol, vidrieras y con menor frecuencia las industrias de filtros, aisladores, pulimentos, tuberías, termoaislantes, construcción y mampostería. Actividades como cortar, romper, aplastar, perforar, triturar o cuando se efectúa la limpieza abrasiva de estos materiales pueden producir el polvo fino de la sílice. También puede estar en la tierra, en el mortero, en el yeso y en las ripias. Las partículas muy pequeñas de polvo de sílice pueden estar en el aire que se respira y quedar atrapadas en los pulmones. Las partículas y fibras más pequeñas son las más peligrosas dado que son las que pueden alcanzar los alveolos. Generalmente se considera que este tamaño por debajo del cual se presenta el riesgo de sufrir silicosis se da para partículas inferiores a las 5 micras. A medida que el polvo se acumula en sus pulmones, estos sufren daños y se hace más difícil respirar con el paso de los años.

A nivel celular, la exposición al polvo de sílice produce la rotura de los lisosomas, los cuales contienen numerosas enzimas que degradan componentes tanto internos (orgánulos deteriorados) como externos (proteínas captadas desde el exterior por endocitosis, por ejemplo). Estas enzimas se depositan en los pulmones, causando importantes daños en ellos.

La sílice cristalina —dióxido de silicio (SiO)— es la que ocasiona la silicosis; se encuentra en la naturaleza en forma de cuarzo, cristobalita o tridimita, siendo el cuarzo el más abundante (12 % de la corteza terrestre); de ahí que la exposición a sílice sea muy frecuente. A pesar de que hay fuentes de exposición insólitas, dada su ubicuidad, la más importante es la minería de interior, aunque en algunos países está tomando gran protagonismo la exposición en industrias relacionadas con la piedra ornamental (granito, pizarra); también hay que estar alerta ante industrias que generan o usan la sílice molida (harina de sílice). La exposición a sílice que supone riesgo para la salud se limita al ambiente laboral y son anecdóticos los casos de silicosis debidos a exposición ambiental.

Debido a que la silicosis crónica es de lento desarrollo, los signos y síntomas pueden no aparecer hasta años después de la exposición. Los signos y síntomas incluyen:

En los casos avanzados, también se puede presentar:

Existen tres tipos de silicosis:

Hay dos formas clínicas según la radiología: silicosis simple y silicosis complicada.

La silicosis simple es la forma clínica más frecuente con mucho. Muestra opacidades redondas (las más frecuentes) y/o irregulares en radiografía simple póstero-anterior de tórax (Rx). No suele producir alteraciones funcionales con significación clínica ni disminuye la esperanza de vida, siempre que no evolucione a complicada.

La silicosis complicada se caracteriza por la existencia de masas de Fibrosis Masiva Progresiva, también llamadas masa conglomeradas, con diámetro mayor de 1 cm. Es una enfermedad grave, sobre todo si las masas son de gran tamaño, y disminuye notablemente la esperanza de vida de los pacientes. La evolución de la forma simple a complicada se debe a factores muchas veces desconocidos. Entre los factores conocidos destacan: elevada exposición a sílice, abundante profusión nodular, tuberculosis y enfermedades del colágeno.

Raras veces la enfermedad puede presentarse como fibrosis pulmonar difusa, neumonía intersticial o como masa pulmonar sin nodulación aparente de fondo (silicoma).

Los pacientes con silicosis son particularmente susceptibles a la tuberculosis (TB) —conocido como silicotuberculosis—. El aumento del riesgo de incidencia es casi 3 veces mayor al de la población sana, sin tener una explicación certera. Se cree que los macrófagos llenos de sílice, disminuyen su capacidad para matar a las micobacterias. Incluso los trabajadores con exposición a la sílice prolongada, pero sin silicosis, tienen un riesgo mayor para la tuberculosis.

Las complicaciones pulmonares de la silicosis también incluyen la bronquitis crónica y limitación del flujo aéreo (indistinguible de la causada por el tabaquismo), la infección por Mycobacterium no tuberculosis, la infección pulmonar por hongos, enfisema compensatorio, y neumotórax. Hay algunos datos que revelan una asociación entre la silicosis y otras enfermedades autoinmunes, como la nefritis, la esclerodermia y el lupus eritematoso sistémico, especialmente en la silicosis aguda o acelerada.

El diagnóstico se basa en una historia laboral significativa y hallazgos típicos en Rx. La OIT (Organización Internacional del Trabajo) ha elaborado una normativa con el fin de clasificar, describir y codificar las alteraciones radiográficas, atribuibles a neumoconiosis y facilitar su comparabilidad en estudios epidemiológicos, sin pretensiones o connotaciones legales, aunque también se usa en la clínica; la edición del año 2000 se basa en la comparación de la Rx del paciente con placas modelo que aporta la organización.

Las pequeñas opacidades redondas se clasifican según su diámetro como "p" (las más pequeñas), "q" (las que exceden 1.5 mm) y r (las que exceden 3 mm y no pasan de 10 mm) y las irregulares como "s,t,u" en función de su anchura (equivalente al diámetro en las redondas). La cantidad o profusión se categoriza de 0 a 3. 
Se establece una notación combinada en función de la profusión con 12 categorías desde 0/- (pulmón completamente limpio) 3/+ (la máxima profusión imaginable); por ejemplo 1/2 q/t. La primera cifra y la primera letra serían las más probables.

La OIT clasifica las masas de FMP) según su diámetro mayor como A (exceden 10 mm), B (aisladamente o sumadas exceden 5 cm) y C (exceden un área equivalente a la de lóbulo superior derecho.

En caso de dudas diagnósticas se puede recurrir a la Tomografía Computada de Alta Resolución (TACAR) que se ha mostrado más sensible y específica para el diagnóstico. Somete al paciente a mucha más radiación que la Rx y no debe usarse como prueba diagnóstica de primer nivel sino para aclarar dudas. La TACAR permite comprobar cómo las masas de FMP se originan frecuentemente en región subpleural de zonas apicales posteriores desplazándose progresivamente de la pleura —signo del desprendimiento—.

No se deben indicar técnicas invasivas (como la biopsia) para el diagnóstico de silicosis a no ser que se sospeche otra entidad susceptible de tratamiento.

La prevención primaria tiene por objeto limitar la exposición acumulada a sílice para evitar que la incidencia de la enfermedad supere unos límites razonables y asumibles. El límite de exposición más ampliamente aceptado es 0.1 mg/m de sílice cristalina respirable (promedio en la jornada laboral), propuesto por OSHA (Occupational Safety and Health Administration).

El Instituto Nacional de Silicosis de España ha elaborado normas de prevención técnica y médica. Se establece el valor límite ambiental de exposición diaria a sílice (VLA-ED), para trabajadores de industrias extractivas, en 0.1 mg/m (0.05 en caso de cristobalita o tridimita); la fracción respirable de polvo no sobrepasará los 3 mg/m. La prevención primaria desde el punto de vista médico se basa en reconocimientos previos al trabajo con el fin de evitar la concurrencia de factores de riesgo o enfermedades pulmonares que podría potenciar el riesgo. Es preciso realizar reconocimientos periódicos a los trabajadores para retirar del riesgo a los afectados. El disponer de seguimiento radiológico facilita el diagnóstico y evita ciertas exploraciones invasivas en casos dudosos (adenopatías hiliares por exposición a sílice, FMP incipiente, etc.).

Las medidas para controlar el polvo se basan en el riego con agua para que las partículas sedimenten, utilización de medios adecuados que no vuelvan a pasar a la atmósfera y retirarlas del medio con aspiración y ventilación. En la medida que fallen estos procedimientos hay que usar medidas de protección personal. Se pueden utilizar dispositivos para filtrar y prevenir la inhalación de estos materiales cuando se realizan trabajos como la minería.

Es importante evitar el tabaco, en cualquier caso, pero especialmente en trabajadores expuestos a sílice y tomar las medidas oportunas de prevención de la tuberculosis.

No existe un tratamiento específico para la silicosis, pero es importante retirar la fuente de exposición al sílice para evitar el empeoramiento de la enfermedad. El tratamiento complementario comprende antitusígenos (fármaco empleado para tratar la tos seca irritativa), broncodilatadores y oxígeno, si es necesario. Se prescriben antibióticos para las infecciones respiratorias en la medida de lo necesario.
El tratamiento también comprende limitar la exposición a sustancias irritantes, dejar de fumar y hacerse pruebas cutáneas de rutina para tuberculosis.

El problema es preocupante porque, además de producir silicosis, la sílice parece implicada en otras enfermedades y la repercusión económica y social es importante. Se siguen observando casos graves de silicosis. Hay evidencia suficiente de que la sílice está implicada en el cáncer de pulmón, en la enfermedad pulmonar obstructiva crónica (EPOC) y en la tuberculosis pulmonar. La silicosis es considerada un problema de salud pública. Hay razones para sospechar relación con algunas colagenosis y tal vez con la sarcoidosis. La sílice ataca un órgano vital, poniendo en riesgo la vida del paciente; se espera que la exposición se perpetúe en el futuro debido a la expansión de industrias relacionadas con la piedra ornamental y a que cada vez aparecen nuevos usos industriales de la sílice (material abrasivo, harina de sílice, etc.). Los límites de exposición recomendados son difíciles de conseguir y no parecen proteger lo suficiente.



</doc>
<doc id="42757" url="https://es.wikipedia.org/wiki?curid=42757" title="Uso justo">
Uso justo

El uso justo, uso legítimo o uso razonable (fair use, en inglés) es un criterio jurisprudencial desarrollado en el sistema del derecho anglosajón (o "common law"), el cual permite un uso limitado de material protegido sin necesitar permiso del dueño de dichos derechos, por ejemplo, para uso académico o informativo. Permite la cita o incorporación, legal y no licenciada, de material protegido en un trabajo de otro autor, bajo el requerimiento de cumplir cuatro condiciones. 

El término "fair use" surgió en los Estados Unidos. Un concepto similar, el "fair dealing", existe en jurisdicciones del derecho anglosajón. Las jurisdicciones del derecho continental poseen otras limitaciones y excepciones a los derechos de autor.

En Estados Unidos, el "fair use" es una doctrina legal sobre el "copyright" (derecho de autor), que permite un uso limitado del material con derechos de autor, sin la necesidad de requerir permiso a los titulares de tal derecho. Este uso limitado atañe a cualquiera que no posea los derechos sobre el material, y comprende una licencia de uso restringida a fines didácticos o de revisión de material (tipo "review").

Esto provee un marco legal para citaciones sin licencia o incorporación de material con derecho de autor en otras obras. Esta disposición está basada en los "derechos del discurso libre" contemplados en la Primera Enmienda de la Constitución de los Estados Unidos.

En Estados Unidos, la legislación sobre marcas registradas también incorpora el "fair use" con motivo de defensa de los derechos sobre la marca. Sin embargo, hay que notar que, aunque las denominaciones son iguales, las doctrinas sí son bastante diferentes. Los tribunales de los Estados Unidos consideran cuatro factores para determinar si es válida la defensa de uso razonable:


En el caso de marcas registradas, el usuario secundario debe demostrar que no está usando una marca de nombre descriptiva, geográficamente descriptiva o personal en el sentido de las marcas registradas, sino sólo para describir sus bienes o servicios, o el origen geográfico de los mismos, o bien, para nombrar a la persona que dirige la empresa.

El uso legítimo solo describe las condiciones bajo las cuales el material protegido por derecho de autor puede ser usado sin necesidad de permiso. Por lo cual, todo aquel material liberado y sin derecho de autor, es de dominio público y no corresponde aplicar la doctrina del uso justo. Las obras de dominio público pueden ser utilizadas para cualquier propósito.

El uso razonable es considerado una de las excepciones a los derechos exclusivos de un autor sobre sus obras. En general, se considera uso razonable la utilización de una obra con propósitos de crítica, realización de comentarios descriptivos, noticias, enseñanza e investigación.

Para decidir si el uso de una obra es razonable, también se toman en cuenta algunos otros factores como los siguientes:



</doc>
<doc id="42761" url="https://es.wikipedia.org/wiki?curid=42761" title="Convenio de París para la Protección de la Propiedad Industrial">
Convenio de París para la Protección de la Propiedad Industrial

El Convenio de París del año 1883 es aplicable a la propiedad industrial en su más amplia acepción, pues incluye inventos, marcas, diseños industriales, modelos de uso práctico, nombres comerciales, denominaciones geográficas y la represión de la competencia desleal.

Las disposiciones sustantivas de la convención corresponden a tres categorías principales: trato nacional, derecho de prioridad y reglas comunes.

Bajo las disposiciones del trato nacional, la convención establece que, en relación con la propiedad industrial, cada uno de los estados que participan en un contrato debe conceder a los ciudadanos de los demás estados contratantes la misma protección que concede a sus nacionales. Los ciudadanos de estados no contratantes también estarán protegidos por la convención si están avecindados o tienen un establecimiento industrial o comercial real y efectivo en alguno de los Estados contratantes.

Esta convención dispone el Derecho de prioridad en el caso de patentes (y modelos prácticos, si los hay), marcas y diseños industriales. Este derecho significa que, sobre la base de una primera solicitud regular presentada en alguno de los estados contratantes, el solicitante podrá pedir protección en cualquiera de los otros Estados contratantes, dentro de un determinado plazo; entonces, esas últimas solicitudes serán consideradas como si hubieran sido presentadas el mismo día que la primera solicitud.

La convención establece unas cuantas reglas comunes que todos los Estados contratantes deben aplicar. Algunas de ellas son:

En relación con patentes:

Las patentes concedidas en distintos estados contratantes para un mismo invento son independientes unas de otras; la concesión de una patente en un estado contratante no obliga a los demás Estados contratantes a otorgar una patente.

El inventor tiene derecho de ser reconocido como tal en la patente.

En cuanto a marcas:

La convención no regula las condiciones para la presentación y registro de marcas, por lo cual deberán determinarse según la ley nacional de cada estado contratante.

Cuando una marca haya sido debidamente registrada en el país de origen, deberá, previa solicitud, ser aceptada para registro y protegida en su forma original en los demás estados contratantes. Sin embargo, el registro puede ser negado en casos bien definidos.

Si en un estado contratante cualquiera el uso de una marca registrada es obligatorio, el registro puede ser cancelado por falta de uso sólo después de un periodo razonable y únicamente si el dueño no logra justificar su inactividad.

Se deberá conceder protección a las marcas colectivas.

Se establece una clasificación de productos y servicios para el propósito de registrar marcas. Este sistema agrupa todos los productos y servicios en 45 clases – 34 para productos, 11 para servicios – permitiendo al usuario especificar de forma precisa y clara las clases que cubren su marca. De esta forma, cuando una persona presenta una solicitud de registro de marca en cualquiera de los países contratantes, puede utilizar el mismo sistema de clasificación, haciendo el proceso más expedito y fácil para el solicitante.

Los diseños industriales deberán ser protegidos en cada uno de los estados contratantes, y la protección no podrá invalidarse por el hecho de que los artículos a los cuales se incorpore el diseño no sean manufacturados en ese estado.

Se deberá otorgar protección a los nombres comerciales en cada uno de los estados contratantes, sin que haya obligación de presentar documentación o registrarlos.

Cada uno de los estados contratantes deberá tomar medidas contra el uso directo o indirecto de una falsa indicación sobre la fuente de los bienes o la identidad del productor, fabricante o distribuidor.

Cada estado contratante estará obligado a proveer protección eficaz contra la competencia desleal.




</doc>
<doc id="42764" url="https://es.wikipedia.org/wiki?curid=42764" title="Teoría del todo">
Teoría del todo

La teoría del todo (o ToE por sus siglas en inglés, "Theory of Everything") es una teoría hipotética de la física teórica que explica y conecta en una sola todos los fenómenos físicos conocidos. Inicialmente, el término se usó con una connotación irónica, para referirse a varias teorías sobregeneralizadas. Después se popularizó en la física cuántica al describir una teoría que podría unificar o explicar a través de un modelo simple de teorías todas las interacciones fundamentales de la naturaleza. Otros términos, no del todo sinónimos, empleados para referirse al mismo concepto son teoría unificada, gran teoría unificada, teoría de campos unificada y teoría del campo unificado.

El concepto de una "teoría del todo" está arraigado en el principio de causalidad y su descubrimiento es la empresa de acercarnos a ver a través de los ojos del demonio de Laplace. Aunque dicha posibilidad puede considerarse como determinista, en una "simple fórmula" puede todavía sobrevivir la física fundamentalmente probabilista, como proponen algunas posturas actuales de la mecánica cuántica. Esto se debe a que aun si los mecanismos que gobiernan las partículas son intrínsecamente azarosos, podemos conocer las reglas que gobiernan dicho azar y calcular las probabilidades de ocurrencia para cada evento posible. Sin embargo, otras interpretaciones de la ecuación de Schrödinger conceden poca importancia al azar: este solo se tendría importancia dentro del átomo y se diluiría en el mundo macroscópico. Otras no obstante la niegan completamente y la consideran una interpretación equivocada de las leyes cuánticas. En consecuencia, la mayor dificultad de descubrir una teoría unificada ha sido armonizar correctamente leyes que gobiernan solo un reducido ámbito de la naturaleza y transformarlas en una única teoría que la explique en su totalidad, tanto en su mundo micro como macroscópico y explique la existencia de todas las interacciones fundamentales: las fuerzas gravitatoria, electromagnética, nuclear fuerte y nuclear débil.

En el siglo pasado, hubo numerosas teorías del todo propuestas por físicos teóricos. Hasta ahora, ninguna ha sido capaz de superar una prueba experimental, han tenido tremendas dificultades para que sus teorías tengan resultados experimentales estables. El primer problema en producir una teoría del todo es que las teorías aceptadas, como la mecánica cuántica y la relatividad general, son radicalmente diferentes en las descripciones del universo: las formas sencillas de combinarlas conducen rápidamente a la "renormalización" del problema, en donde la teoría no nos da resultados finitos para datos cuantitativos experimentales.

Desde los tiempos de los antiguos griegos, los filósofos han especulado que la aparente diversidad de apariencias oculta una subyacente unidad, y por lo tanto que la lista de las fuerzas puede ser acortada, de hecho que puede tener una sola entrada. Por ejemplo, la filosofía mecánica del siglo XVII propuso que todas las fuerzas podrían en últimas reducirse a una fuerza de contacto entre pequeñas partículas sólidas. Esto se abandonó después de la aceptación de las fuerzas gravitacionales a larga distancia propuestas por Isaac Newton; pero al mismo tiempo el trabajo de Newton en su " Principia" proveyeron la primera dramática evidencia empírica de la unificación de fuerzas que en ese momento parecían diferentes: el trabajo de Galileo en la gravitación terrestre, las leyes de Kepler del movimiento planetario y los fenómenos de mareas fueron todas cuantitativamente explicadas por una simple ley, llamada de la gravitación universal.

En 1820, Hans Christian Oersted descubrió una conexión entre la electricidad y el magnetismo; muchas décadas de trabajo culminaron en la teoría del electromagnetismo de James Clerk Maxwell. También durante los siglos XIX y XX, gradualmente fueron apareciendo muchos ejemplos de fuerzas de contacto, elasticidad, viscosidad, fricción, presión- resultados de las interacciones eléctricas entre pequeñísimas partículas de la materia. A finales de 1920, la nueva mecánica cuántica mostró que los enlaces químicos entre átomos eran ejemplos de fuerzas eléctricas (cuánticas), corroborando la jactancia de Dirac que «las leyes físicas subyacientes necesarias para una teoría matemática para una gran parte de la física y toda la química [ya] son completamente conocidas». Se trataba, pues, de asociar dichas fuerzas fundamentales en un solo modelo totalizador que explicara de forma efectiva interacciones complejas de fuerzas aparentemente diversas y no correlacionadas.

Los intentos de unificar gravedad con magnetismo se remontan a los experimentos de 1849-50 de Michael Faraday. Después de la teoría gravitatoria (relatividad general) de Einstein publicada en 1915, la búsqueda de una teoría del campo unificado que combine gravedad con electromagnetismo se tornó más seria. Al mismo tiempo, se hizo plausible el decir que no existían más fuerzas fundamentales. Prominentes contribuciones fueron las otorgadas por Gunnar Nordstrom, Hermann Weyl, Arthur Eddington, Theodor Kaluza, Oskar Klein, y la más notable dada por Einstein y sus colaboradores. Ninguna de estas propuestas tuvo éxito.

La búsqueda fue interrumpida por el descubrimiento de las fuerzas débil y fuerte, que no podían ser agregadas dentro de la gravedad o el electromagnetismo. Otro obstáculo fue la aceptación que la mecánica cuántica tuvo que ser incorporada desde el inicio, no emergió como una consecuencia de la determinista teoría unificada, como Einstein esperaba. Gravedad y Electromagnetismo pueden siempre coexistir pacíficamente como tipos de fuerzas de Newton, pero por muchos años se ha observado que la gravedad no puede ser incorporada en el panorama cuántico, dejándola sola al unificarse con otras fuerzas fundamentales. Por esta razón este trabajo de unificación en el siglo XX se focalizó en entender las tres fuerzas "cuánticas": electromagnetismo y las fuerzas nucleares débiles y fuertes. Las dos primeras fueron unificadas en 1967-8 por Sheldon Glashow, Steven Weinberg, y Abdus Salam. Las fuerzas fuerte y la electrodébil coexisten en el modelo estándar de partículas, pero se mantienen distintas. Muchas teorías unificadas (o GUT por sus siglas en inglés) han sido propuestas para unificarlas. Aunque la simpleza de las GUTs han sido descartadas en la experiencia, la idea general, especialmente cuando se vincula con las supersimetrías, continúa firmemente a favor de la comunidad teórica de física.

En la corriente principal de la física actual, la Teoría del Todo podría unificar todas las interacciones fundamentales de la naturaleza, que son consideradas como cuatro: gravitación, la fuerza nuclear fuerte, la fuerza nuclear débil y la electromagnética. Dado que la fuerza débil puede transformar partículas elementales de una clase a otra, la teoría del todo debería producir una comprensión profunda de varios tipos diferentes de partículas, así como de diferentes fuerzas. El patrón previsible de las teorías es el siguiente:

Adicionalmente a las fuerzas listadas aquí, la moderna cosmología requiere una fuerza inflacionaria, energía oscura, y también materia oscura compuesta de partículas fundamentales fuera de la escena del modelo estándar.

La unificación electrodébil es una simetría rota: el electromagnetismo y la fuerza débil parecen distinguirse a bajas energías porque las partículas traen fuerzas débiles, los bosones W y Z tienen la masa de alrededor de 100 GeV/c, mientras que el fotón, que trae la fuerza electromagnética, no tiene masa. A altas energías los bosones W y Z pueden crear masa fácilmente y la naturaleza unificada de las fuerzas aparece. La teoría de la gran unificación se espera que opere de manera similar, pero las energías en el orden de 10 GeV o mucho mayores no pueden ser conseguidas por ningún acelerador de partículas en La Tierra. Por analogía, la unificación de las fuerzas GUT con la gravedad se espera que sea a una energía de Planck, alrededor de 10 GeV.

Podría ser prematuro el estar buscando la teoría del todo cuando no existe evidencia directa de una fuerza electronuclear y mientras en cualquier caso hay muchas diferentes propuestas de GUTs. En efecto el nombre deliberado está envuelto en Hibris. No obstante, muchos físicos creen que la unificación es posible, debido en parte a la historia de convergencia hacia una misma teoría. La supersimetría se ve plausible no solo por su "belleza" teórica, sino por su naturalidad al producir grandes cantidades de materia oscura, y la fuerza inflacionaria puede ser relacionada con GUT físicas (aunque no parece formar parte inevitable de la teoría). Y ahora las GUTs no son claramente la respuesta final. Tanto el modelo estándar actual como la propuesta GUT son teorías cuánticas de campos que requieren la problemática técnica de la renormalización de respuestas a campos sensibles. Es usual considerar como un signo de que hay una sola teoría de campos efectiva omitiendo fenómenos cruciales sólo a muy altas energías. Además, la inconsistencia entre la mecánica cuántica y la relatividad general implica que una de las dos debe ser remplazada por una teoría que incorpore la gravedad cuántica.

La única candidata principal a teoría del todo en el momento es la teoría de supercuerdas. Investigaciones en curso sobre la gravedad cuántica de bucles puede eventualmente jugar un rol fundamental en la teoría del todo, pero éste no es el principal objetivo. Estas teorías intentan tratar con la renormalización del problema mediante el establecimiento de algunas en el límite inferior de escalas de longitud posible. La teoría de supercuerdas y la supergravedad (se cree que ambas son casos especiales de una teoría sin definir M) suponen que el universo tiene en realidad más dimensiones que lo que puede verse a simple vista: tres espaciales y una temporal. La motivación tras este acercamiento comienza con la teoría Kaluza-Klein en donde se notó que al aplicar la relatividad general en un universo de 5 dimensiones (una dimensión más una pequeña dimensión de doblado) mantenía la equivalente a la relatividad general, de 4 dimensiones, con las leyes de Maxwell del electromagnetismo (también en 4 dimensiones). Esto ha dado lugar a esfuerzos para trabajar con teorías de muchas dimensiones en las que se espera que se puedan producir ecuaciones que sean similares a las conocidas en física. La noción de extradimensiones también ayuda a resolver el problema de la jerarquía, donde la pregunta de por qué la gravedad es más débil que cualquier otra fuerza. La respuesta común dice que la gravedad estaría en una dimensión extra a las otras fuerzas.

A finales de 1990 se notó que uno de los problemas de tener muchas candidatas a teorías del todo (pero particularmente con la teoría de cuerdas) era que éstas no contenían las características de predecir el universo. Por ejemplo, muchas teorías de la gravedad cuántica pueden crear universos con un número arbitrario de dimensiones o con arbitrarias constantes cosmológicas. Incluso la "estándar" teoría de cuerdas 10-dimensional permite a las dimensiones "espiraladas" ser compactadas en muchos diferentes caminos (uno estimado es 10 donde cada una corresponde a colecciones diferentes de partículas fundamentales y fuerzas de baja energía).

Una solución especulativa es que muchas de esas posibilidades son realizables en uno u otro de los universos posibles, pero solo un número pequeño de ellos son habitables, y por lo tanto las constantes universales fundamentales son en definitiva el resultado de un principio antrópico como consecuencia de una teoría del todo. Esta aproximación antrópica es claramente criticada en que, como la teoría es lo suficientemente flexible para abarcar casi cualquier observación, no podría hacer predicciones útiles (como originales, falsas o verificables). Desde este punto de vista, la teoría de cuerdas podría ser considerada como pseudociencia, donde una teoría infalsable es constantemente adaptada para que los resultados experimentales se ajusten a ella.

Existen varios fenómenos que una teoría del todo debería poder aclarar:


Recientemente han surgido dos teorías que podrían algún día evolucionar hasta la mencionada teoría unificada. Una es la Teoría M, una variante de la teoría de cuerdas basada en un espacio de 11 dimensiones. La segunda es la denominada teoría cuántica de bucles que postula que el propio espacio-tiempo estaría cuantizado dimensionalmente, algo que por ahora no ha sido demostrado.

El estatus de la física en la ToE está abierto a un debate filosófico. Por un momento, si lo físico es verdadero, una teoría del todo física podría coincidir con una teoría filosófica del todo. Algunos filósofos —Aristóteles, Platón, Hegel, Whitehead— han intentado construir sistemas que lo abarcan todo. Otros han tenido grandes dudas acerca de la gran posibilidad de ser un simple ejercicio.

Un pequeño número de científicos indica que el teorema de incompletitud de Gödel implica que cualquier intento de construir una teoría del todo está abocada al fracaso. El teorema de Gödel dice que cualquier teoría matemática suficientemente compleja es o bien inconsistente o incompleta. Stanley Jaki señaló en su libro de 1966 "La Relevancia de la Física" que cualquier teoría del todo deberá ser una teoría matemática consistentemente no-trivial, con lo que debe ser incompleta. Jaki considera por tanto que este hecho arruina una genuina teoría determinista del todo. Freeman Dyson por su parte ha afirmado que:

Muchos han interpretado esta cita para apoyar la posición de Jaki.

Stephen Hawking fue originariamente creyente de una Teoría del Todo, pero después de considerar el teorema de Gödel, concluyó que no podría ser obtenida. 
Esta visión ha sido argumentada en contra de Solomon Feferman y otros.

Muchos científicos y matemáticos creen que el teorema de Gödel es completamente irrelevante cuando se discute la teoría del todo. El teorema de Gödel es una declaración sobre cuáles teoremas "eventualmente" resultarían sistemas matemáticos, donde "eventualmente" significa después de un tiempo arbitrario. El teorema de Gödel no impide que un matemático compute qué ocurre después de cualquier cantidad de tiempo, o no impide a una persona que conozca las reglas para hacer los cálculos. Todo lo que el teorema de Gödel dice es que, incluso conociendo todas las reglas, sería imposible predecir qué nuevos patrones producirán eventualmente las reglas.

Para ilustrar, consideremos el libro "Juego de la Vida" de Conway. Este autómata celular está completo, significa que una variación del argumento de Gödel muestra que el comportamiento del autómata a lago plazo no podría ser predicho a partir de una configuración inicial arbitraria. Y por tanto, una criatura hipotética que viviera dentro del juego de la vida pueda conocer todas las reglas. Las reglas del autómata son la teoría del todo, y se conoce incluso para las criaturas dentro del autómata.

Ninguna teoría física al momento se cree que sea precisamente exacta. En lugar de ello, la física ha procedido por series de "aproximaciones sucesivas" permitiendo predicciones cada vez más exactas sobre una amplia gama de fenómenos. Muchos físicos creen que existen muchos errores en los confusos modelos teóricos con la naturaleza real de la realidad y sostienen que la serie de aproximaciones nunca terminará en "verdad". El mismo Einstein expreso su visión en ocasiones. Desde su punto de vista, podemos razonablemente esperar por "una" teoría del todo donde consistente -en sí misma- incorpore todas las fuerzas conocidas actualmente, pero no debemos esperar en tener la respuesta final. En cambio, estaba abierto a opinar que a pesar de la aparente complejidad matemática en cada teoría, en un sentido profundo asociado con su subyacente simetría gaugiana y al número de constantes físicas universales, las teorías se simplificarán. Si eso ocurre, el proceso de simplificación no puede continuar indefinidamente.

Hay un debate filosófico dentro de la comunidad física de la existencia o no de la teoría del todo y si debe ser llamada "la" ley fundamental del universo. Una opción es la posición reduccionista dura de que la teoría del todo es la ley fundamental y que todas las otras teorías que aplican en el universo son una consecuencia de la ley del todo. Otra visión es que las leyes emergentes (llamadas "leyes libres flotantes" por Steven Weinberg) donde gobierna un comportamiento de sistemas complejos deberían ser igualmente fundamentales. Ejemplos son la segunda ley de la termodinámica y la teoría de la selección natural. En punto comienza en que a través de nuestro universo esas leyes describen sistemas cuyo comportamiento puede ("en principio") ser predicho por una ToE, que también se realizarán en un universo con diferentes leyes de bajo nivel, sujeto sólo a algunas condiciones muy especiales. Por lo tanto no es de ayuda, ni siquiera en principio, invocar un nivel bajo de leyes para discutir el comportamiento de los sistemas complejos. Algunos argumentan que esta actitud podría violar la Navaja de Occam si es completamente válida la formulación de la teoría del todo. Si no es claro que hay cualquier punto en cuestión este debate (por ejemplo entre Steven Weinberg y Phillip Anderson que no hay derecho a aplicar la palabra "fundamental" que respete los temas de interés.

Aunque el nombre "teoría del todo" sugiera el determinismo citado de Laplace, este da una impresión muy engañosa. El determinismo queda frustrado por la probabilidad natural de las predicciones de la mecánica cuántica por la extrema sensibilidad a las condiciones iniciales que llevan al caos matemático y por la dificultad matemática extrema de aplicarla a la teoría. Por lo tanto, aunque el moderno modelo estándar de la física de partículas "en principio" prediga todos los fenómenos no gravitacionales conocidos, en la práctica sólo unos pocos resultados han sido derivados de una teoría completa (por ejemplo: las masas de unos de los simples hadrones) y esos resultados (especialmente las masas de la partícula donde son las más relevantes para la física de altas energías) son menos precisas que las actuales mediciones experimentales. Una verdadera teoría del todo difícilmente podría aplicarse. El principal motivo para investigar una ToE, a parte de la pura satisfacción de completar un siglo de búsqueda, es que todas las unificaciones predigan con éxito los nuevos fenómenos, muchos de ellos (p.e. generadores eléctricos) han probado su gran importancia práctica. Como en otros casos de teorías de reducción, la teoría del todo podría también permitirnos definir con certeza el dominio de validez y el error residual de aproximaciones de altas energías para una completa teoría de donde puedan obtenerse cálculos prácticos.





</doc>
<doc id="42765" url="https://es.wikipedia.org/wiki?curid=42765" title="Convenio de Ginebra">
Convenio de Ginebra

Convenio de Ginebra (o Tratado de Ginebra) puede referirse a:

</doc>
<doc id="42766" url="https://es.wikipedia.org/wiki?curid=42766" title="Tratado de la OMPI sobre Derecho de Autor">
Tratado de la OMPI sobre Derecho de Autor

El Tratado de la OMPI sobre Derecho de Autor fue concluido en Ginebra el 20 de diciembre de 1996. En marzo de 2002 entró en vigencia.

Cualquier parte contratante (aunque no esté obligada por la Convención de Berna) debe acatar las disposiciones sustantivas de la Ley de la Convención de Berna de 1971 (París).

En cuanto a los temas que son protegidos por medio de derechos de autor, el tratado menciona dos: 



En lo referente a los derechos de autor, el tratado se ocupa de tres de ellos: 


Cada uno de ellos es un derecho exclusivo, sujeto a ciertas limitaciones y excepciones.

El tratado obliga a las partes contratantes a proveer remedios legales contra la anulación de las medidas tecnológicas (p. ej., la codificación) que emplean los autores en el ejercicio de sus derechos y contra la remoción o alteración de información, como ciertos datos que identifican la obra de sus autores, que es necesaria para la administración (p. ej., otorgamiento de licencias, recolección y distribución de regalías) de sus derechos ("información sobre la administración de derechos").

El tratado obliga a cada una de las partes contratantes a adoptar las medidas necesarias, de acuerdo con su sistema legal, para garantizar la aplicación de dicho tratado. En particular, la parte contratante deberá asegurarse de que su ley incluya procedimientos que garanticen el cumplimiento, de modo que pueda instruirse una acción legal eficaz contra cualquier infracción de los derechos cubiertos por el tratado. Esa acción debe incluir remedios expeditos para prevenir la infracción y remedios que sean un factor disuasorio contra futuras transgresiones.

Este es un instrumento de derecho internacional que, como todos, prevalecen sobre el derecho interno de cada país contratante. Sin embargo, no todos los países cumplen rigurosamente el derecho internacional y en algunos casos hacen prevalecer sus normas internas.





</doc>
<doc id="42767" url="https://es.wikipedia.org/wiki?curid=42767" title="Tratado de la OMPI sobre Interpretación o Ejecución y Fonogramas">
Tratado de la OMPI sobre Interpretación o Ejecución y Fonogramas

El Tratado de la OMPI sobre Interpretación o Ejecución y Fonogramas fue concluido el 20 de diciembre de 1996. Está en espera de ratificación.

Este tratado se refiere a los derechos de propiedad intelectual de dos tipos de beneficiarios: (1) intérpretes (actores, cantantes, músicos, etc.) y (2) productores de fonogramas (las personas o entidades legales que toman la iniciativa y asumen la responsabilidad en relación con la grabación de esos sonidos).

En lo que se refiere a los intérpretes, el tratado les concede cuatro tipos de derechos económicos sobre sus interpretaciones grabadas en fonogramas: (1) el derecho de reproducción, (2) el derecho de distribución, (3) el derecho de alquiler y (4) el derecho de ponerlos a disposición del público. Cada uno de ellos es un derecho exclusivo, sujeto a ciertas limitaciones y excepciones.

El tratado concede a los intérpretes tres tipos de derechos económicos con respecto a sus interpretaciones no grabadas (en vivo): (1) el derecho de transmisión (salvo en el caso de retransmisiones), (2) el derecho de comunicación al público (salvo cuando la interpretación tenga lugar en una transmisión) y (3) el derecho de grabación.

El tratado concede también derechos morales a los intérpretes: el derecho de exigir que se les dé el crédito de sus interpretaciones y el derecho de oponerse a cualquier distorsión, mutilación u otra alteración que pudiera ser lesivo para su prestigio.

En lo que se refiere a los productores de fonogramas, el tratado les concede cuatro tipos de derechos (todos de carácter económico) sobre sus fonogramas: (1) el derecho de reproducción, (2) el derecho de distribución, (3) el derecho de alquiler y (4) el derecho de ponerlos a disposición del público. Cada uno de estos derechos es exclusivo y está sujeto a ciertas limitaciones y excepciones.

En lo que se refiere tanto a los intérpretes como a los productores de fonogramas, el tratado obliga a cada una de las partes contratantes a dar a los ciudadanos de las otras partes contratantes el mismo trato que a sus propios ciudadanos, en lo referente a los derechos reconocidos específicamente en el tratado.

Además, el tratado dispone que los intérpretes y los productores de fonogramas tengan derecho a una remuneración única y equitativa por el uso directo o indirecto de sus fonogramas, ya sea que éstos se editen con propósitos comerciales, para transmisión por medios electrónicos o para comunicarlos al público.

La vigencia de la protección deberá ser de 50 años por lo menos.




</doc>
<doc id="42768" url="https://es.wikipedia.org/wiki?curid=42768" title="Frente Oriental (Segunda Guerra Mundial)">
Frente Oriental (Segunda Guerra Mundial)

El Frente de Europa Oriental o Frente Oriental fue el principal frente durante la Segunda Guerra Mundial. En la Unión Soviética (y hoy en la Federación Rusa y demás repúblicas exsoviéticas) se lo denominó Gran Guerra Patria ( "Velíkaya Otéchestvennaya voyná"). Cubrió el centro y el este de Europa y fue abierto por la Alemania nazi con la Operación Barbarroja el 22 de junio de 1941 —o, desde una consideración más amplia, al invadir Polonia el 1 de septiembre de 1939 (manteniéndose inactivo temporalmente en 1940)— siendo cerrado por la Unión Soviética al capturar Berlín el 9 de mayo de 1945.

Debido a que la ideología nazi se oponía a los movimientos eslavos, judíos y comunistas, mientras que el ideario soviético era opuesto al fascismo, la guerra en el frente oriental se caracterizó por la ocurrencia de genocidios en casi todos los países ocupados, así como la constante violación de las acuerdos obtenidos en las Convenciones de Ginebra. En este frente perdieron la vida 26 millones de soviéticos, 6.5 millones de alemanes y aliados del Eje y casi 6 millones de polacos (más de la mitad eran polacos judíos), más de un 60 % de las víctimas de esa guerra en todo el mundo. Se estima que en el frente oriental murieron el 73 % de los soldados alemanes que murieron en la guerra y, en el caso de Bielorrusia, Ucrania y Polonia, más del 20 % de la población civil fue asesinada.

Tras los cercos de Minsk en julio, Kiev en septiembre y Viazma en octubre de 1941, los alemanes hicieron 3 millones de prisioneros soviéticos, que fueron los primeros en ser sacrificados en las cámaras de gas de los campos de exterminio.

Enfrentado a una guerra total, Stalin no dudó en practicar la táctica de tierra quemada ya probada contra Napoleón en 1812, en organizar una guerra de guerrillas, en trasladar todas las industrias a la retaguardia y en hacer todos los sacrificios necesarios.

Tras la paralización de la ofensiva alemana en diciembre de 1941 y con algo de ayuda de los aliados occidentales, la Unión Soviética pudo reconstruir su ejército, movilizar a todo el país en nombre de defensa de la patria, y para 1942 la producción de armamento soviética ya era superior a la alemana.

La guerra librada en Europa Oriental durante la Segunda Guerra Mundial puede dividirse en varias etapas:


Los países que enviaron cantidades importantes de sus ejércitos a este frente fueron: Alemania, Rumania, Hungría, Italia, Finlandia, Austria y Croacia. Tropas voluntarios de Bélgica, Eslovaquia, España, Francia de Vichy y otros países aliados de las Fuerzas del Eje también participaron enviando materias primas, como Suecia, Turquía, Bugaria entre otros, si bien sus contribuciones no fueron determinantes. Cabe resaltar que intereses particulares en los EE.UU, Gran Bretaña y el Imperio del Japón ayudaron a financiar la industria bélica alemana en los años 30s. Por otra parte, La Unión Soviética; en esta última se incluyen las tropas de Rusia en general, Ucrania, Bielorrusia, Kazajistán, Kirguistán, Tayikistan, Uzbeskitan, Azerbaiyán, Estonia, Letonia, Lituania, Armenia, Georgia y Mongolia como único aliado cercano. La participación de los partisanos griegos y de Yugoslavia fue muy importante, si bien solamente adquirió la naturaleza de un ejército al acercarse el final de la guerra. Tanto Gran Bretaña como los Estados Unidos enviaron cantidades industriales de armas, aviones, vehículos y materias primas pero fueron poco determinantes debido a los recursos ilimitados que poseía la U.R.S.S. que coadyuvó a la masa excesiva de producciones de tanques, cañones, aviones, entre otros tipos materiales que se fabricaban en la retaguardia de la Unión Soviética, entre los Montes Urales, el Caucaso y Moscú. Cabe destacar que miles de esas fábricas provenían de Ucrania, Bielorrusia entre otras regiones soviéticas y que fueron desmanteladas por orden de Stalin, a raíz de la invasión alemana y llevadas al extremo oriente, como se indica.

Al rendirse Alemania en la Primera Guerra Mundial y tras la disolución del Imperio Austrohúngaro, se creó en Europa central y oriental un vacío de poder que ninguna nación pudo llenar. Con la llegada al poder del comunismo y el fascismo a la Unión Soviética y Alemania respectivamente, el panorama político europeo se volvió inestable. Los nazis tenían ambiciones expansionistas y sus esfuerzos de rearme lo demostraban. Alemania llevaba la delantera, aspirando recuperar su puesto de potencia central, ya que la economía alemana estaba mostrando mejorías y su clase media estaba resurgiendo. En esta época Hitler llegó al poder y dotó de una naturaleza claramente ofensiva a ese resurgimiento de Alemania, desafiando el Tratado de Versalles e iniciando un proceso de rearme. Los gobiernos occidentales, representados por Gran Bretaña, Francia, Polonia y Checoslovaquia, empezaron entonces a formar alianzas entre ellos, intentando aislar a las dos naciones anteriores. Sin embargo, la política de apaciguamiento impulsada por el primer ministro británico Neville Chamberlain y que caracterizó a otros países europeos, le concedió a Hitler muchos logros, con los que fue ganando influencia en los países de Europa Central.

Para 1939 Alemania poseía influencia política sobre Austria, Checoslovaquia, Hungría, Rumania y varias naciones de los Balcanes. Stalin observaba impotente cómo Alemania se hacía cada vez más poderosa, mientras que la Unión Soviética parecía destinada a convertirse en el estado "paria" de Europa.

Para abril de 1939, la intención de Hitler de recuperar el territorio alemán perdido en 1918 y entregado a Polonia era evidente, ya que había renunciado al Pacto de No Agresión que había firmado con este país cinco años atrás. Stalin era consciente de que finalmente tendría que enfrentarse a Alemania, tanto como de que su ejército aún no estaba listo. Desesperada, la Unión Soviética buscó aliados en Francia y Gran Bretaña, pero este último país respondió enviando delegados en barco, a pesar de que sabían que la petición soviética era urgente. Cuando estos delegados llegaron en agosto, los soviéticos descubrieron que no poseían ningún poder especial para negociar. La opinión soviética era que las naciones occidentales no tenían deseos de evitar la invasión de Polonia, ya que podían sacrificar a este país, si esto llevaba a que finalmente Alemania y la Unión Soviética se aniquilaran entre sí.

Finalmente, en la segunda semana de agosto, las naciones occidentales dieron una respuesta positiva. Sin embargo, las negociaciones se estancaron al llegar al tema de la defensa de Polonia. El gobierno polaco no deseaba que las tropas soviéticas entraran en su territorio, a pesar de que sabían que la invasión alemana era inminente. Las naciones occidentales presionaron a Polonia para que aceptara esta condición, pero el gobierno polaco dejó claro que prefería que su país fuera invadido por Alemania antes que por la Unión Soviética. En aquel momento, Polonia confiaba plenamente en sus alianzas con Francia y el Reino Unido, por lo que no veía la alianza con su desconfiable vecino como algo esencial. Las negociaciones fueron suspendidas y la Unión Soviética se encontró sola de nuevo ante Alemania.

El 19 de agosto de 1939, el ministro de Relaciones Exteriores alemán Joachim von Ribbentrop visitó Moscú para la firma de un tratado comercial con la Unión Soviética. Una vez allí, Ribbentrop sugirió a Viacheslav Mólotov que discutieran expandir el tratado a temas relacionados con la política exterior, ya que las empresas alemanas querían tener ciertas garantías ante las futuras buenas relaciones entre ambas naciones. Se presume que esta aproximación alemana tuvo lugar solo porque Hitler también consideraba que su ejército tampoco estaba listo para ocupar la Unión Soviética, ya que la ideología hitleriana no permitía la coexistencia pacífica con este país. Finalmente, el 23 de agosto se firmó el Pacto Ribbentrop-Mólotov, que definía los límites de las esferas de influencia soviética y alemana, lo que en otras palabras se podía traducir como el reparto de Europa Oriental

El Protocolo Adicional Secreto de dicho pacto especificaba el reparto de Polonia, Rumania y países bálticos.

El 1 de septiembre de 1939 Alemania invadió Polonia, y para sorpresa de Hitler, Gran Bretaña y Francia le declararon la guerra dos días después. Una pequeña fuerza de Eslovaquia invadió también desde los montes Cárpatos al sur.

El ejército polaco no había sido movilizado completamente ni había renovado su armamento en forma satisfactoria, lo que explica que participaran cuerpos de caballería, por completo obsoletos, en la batalla. La planicie polaca era ideal para el uso de la Blitzkrieg, la nueva táctica militar alemana, que intentaba evitar el estancamiento del frente, tal como había ocurrido en la Primera Guerra Mundial. El ejército polaco no estaba listo para esta táctica y desplegó toda su fuerza a lo largo del frente, sin profundidad suficiente en sus líneas. Cuando los tanques alemanes cruzaron las líneas por distintos puntos del frente, no atacaron a las fuerzas polacas, sino que las rodearon cortando su retaguardia, dejándolas aisladas. Después llegó la infantería pesada alemana, que acabó con las bolsas polacas.

Después de la victoria alemana en la batalla de Bzura, el éxito de la invasión estuvo asegurado, y las fuerzas polacas se retiraron al este, con el objetivo de resistir allí hasta que llegase la ayuda anglo-francesa. Se intentó evacuar a la población civil hacia zonas más seguras, pero el rápido avance alemán impidió que la evacuación tuviera éxito. El 17 de septiembre, la Unión Soviética invadió Polonia desde el este, y el plan de contingencia polaco se desmoronó. Con la batalla perdida, las tropas polacas empezaron a ser evacuadas por el sur hacia Rumania.

Para el 1 de octubre Polonia fue completamente ocupada y el 6 de octubre la invasión concluyó, y en ningún momento la ayuda aliada prometida dio muestras de materializarse. Muchos soldados polacos lograron escapar y se unieron a las filas francesas y británicas, contribuyendo enormemente en la guerra. Además, en Polonia se formaron múltiples movimientos de resistencia política y militar, siendo el más conocido el Armia Krajowa, que obtuvieron resultados notables contra la ocupación nazi.

En la Polonia ocupada por Alemania la calidad de vida de los polacos se empezó a deteriorar rápidamente, especialmente la de los judíos, ya que la ideología nazi los calificaba como infrahumanos (Untermensch). En el lado soviético, la población también fue humillada, en este caso no por su raza sino por su afiliación política. En la llamada masacre de Katyn, miles de oficiales polacos fueron ejecutados en masa. Hubo fusilamientos de prisioneros de guerra, principalmente militares polacos que habían participado en la guerra polaco-soviética de 1919-1921.

Como consecuencia de la Campaña de Septiembre, la Polonia ocupada consiguió crear un poderoso movimiento de resistencia y contribuyó con fuerzas militares significativas al esfuerzo aliado durante el resto de la Segunda Guerra Mundial.

Tanto Stalin como Hitler sabían que solamente era cuestión de tiempo que el Pacto Mólotov-Ribbentrop fuera roto. Por ende, en abril de 1938 los soviéticos iniciaron negociaciones diplomáticas con Finlandia con el objetivo de desarrollar una defensa unida contra Alemania. Cuando los militares soviéticos se percataron de que la frontera finesa estaba a solo 32 kilómetros de Leningrado, siendo una potencial base para una invasión germana hacia esa ciudad, la Unión Soviética envió solicitudes a Finlandia para intercambiar territorio, solicitudes que para otoño de 1939 se habían convertido en demandas. Cuando el gobierno finés se negó a aceptar, la Unión Soviética simuló un ataque finlandés en la frontera y el 30 de noviembre de 1939 atacó a Finlandia con 23 divisiones comandadas por Kliment Voroshílov. Finlandia solo contaba con 9 divisiones comandadas por Carl Gustaf Mannerheim.

Lo que estaba destinado a ser un paseo militar soviético, se convirtió en una sangrienta batalla, donde las atrasadas tácticas de combate, la mala preparación para el clima polar y la incompetencia de los oficiales soviéticos, llevaron al Ejército Rojo a sufrir derrotas vergonzosas contra un enemigo numéricamente inferior, pero que había implementado a la perfección las tácticas de guerrilla en la nieve.

En la batalla de Suomussalmi, los soviéticos perdieron dos divisiones completas frente a una fuerza finesa minúscula, sin embargo, esta derrota marcó un cambio de rumbo en la forma que Stalin manejaba la guerra. Inmediatamente, este ordenó la remoción de sus cargos de los principales jefes militares, incluyendo a su amigo Voroshílov, que fue reemplazado por Semión Timoshenko, también amigo de Stalin.

Los reemplazos fueron oficiales más competentes pero que habían sido relegados en la Gran Purga por no pertenecer al Partido Bolchevique o a la facción liderada por Stalin. En pocas semanas, el Ejército Rojo, mejor equipado y dirigido, logró aplastar finalmente a los defensores fineses, que tuvieron que pedir un armisticio. Sin embargo, a pesar de sufrir muchas bajas, Finlandia se ganó el derecho a negociar y logró conservar su autonomía, quedando definitivamente fuera de la esfera de poder de la Unión Soviética. Finlandia perdió todo territorio alrededor del Lago Ládoga, incluyendo la ciudad de Výborg. También cedió territorios en el Norte, el centro e islas en el golfo de Finlandia.

Hitler tomó nota de la debilidad soviética, lamentablemente para él, Stalin también. La guerra de Invierno puede considerarse una lección que la Unión Soviética pagó para conocer la eficiencia de sus tropas en la guerra moderna, que hubiera sido más costosa si la guerra hubiera sido contra Alemania.

Después de la invasión de Francia, Hitler se enfocó de nuevo en la Unión Soviética. En una reunión secreta llevada a cabo el 31 de julio de 1940, el Alto Mando alemán tomó la decisión de invadir la Unión Soviética en abril de 1941, en una operación llamada "Barbarroja". El 18 de diciembre, fue confirmada la decisión en una conferencia militar secreta. Por su parte, el Kremlin confiaba en que Hitler respetaría el Pacto Ribbentrop-Mólotov por lo menos hasta 1945, por lo que el Ejército Rojo se encontraría preparado para esa fecha, sin embargo, se concentraron más de 100 divisiones durante la invasión de Francia a lo largo de la frontera con Alemania, que luego fueron reforzadas por 22 más mientras los alemanes luchaban en los Balcanes.

No obstante, la fecha de la ejecución de la Operación Barbarroja tuvo que aplazarse dos meses debido a que "Il Duce", Benito Mussolini, decidió reabrir el Frente Oriental antes que Hitler, buscando invadir Grecia. No obstante, Italia no lo lograría por sí sola, razón por la cual se desviaron tropas alemanas ya listas para iniciar la invasión de la URSS, ubicadas en Prusia, así como todo el material blindado del sector sur de la Operación Barbarroja.

Firme en su creencia de que la caída de Gran Bretaña era cuestión de tiempo, Mussolini inició su programa de expansión territorial, a pesar de que sabía que su ejército aún no terminaba de iniciar su proceso de rearme. Haciendo caso omiso del consejo de sus generales y del mismo Hitler, Mussolini empezó a preparar la ocupación de Grecia. El 28 de octubre Hitler viajó de emergencia a Roma, a convencerlo de que desistiera de su plan expansionista momentáneamente, pero cuando llegó, el dictador italiano le dijo que la invasión acababa de comenzar.

Los peores temores de Hitler se hicieron realidad, cuando las fuerzas italianas no solo no pudieron ocupar rápidamente Grecia, sino que fueron repelidas por un contraataque griego hacia Albania, que en aquel momento estaba bajo dominio italiano. Para empeorar la situación, Gran Bretaña envió fuerzas a Creta y Lemnos, mientras que la RAF entregó soporte aéreo. Como no quería empezar la guerra con la Unión Soviética con tropas aliadas al sur del frente oriental, Alemania acudió en ayuda de Italia.

La invasión de Grecia por parte de Alemania debía ocurrir para marzo de 1941, pero Yugoslavia se encontraba en medio del camino. En aquel momento, el regente, el príncipe Pablo se encontraba presionado por todos lados para que asumiera un bando pronto, por lo que decidió firmar un pacto de paz y amistad con Alemania el 24 de marzo de 1941. Entonces, ocurrió un cuartelazo el día 27 de marzo, derrocando al príncipe e instaurando un gobierno antialemán en el poder, el cual desconoció el pacto firmado tres días antes por lo que el 6 de abril Alemania bombardeó Belgrado. Para esta campaña el ejército alemán distrajo 31 divisiones de sus bases, que ya se encontraban listas para lanzar el golpe contra la URSS, enfrentándose a 42 divisiones aliadas, (23 yugoslavas, 15 griegas y 4 británicas).

El mariscal Wilhelm List dirigió al 12° Ejército en la principal embestida a través de las accidentadas montañas de Serbia cortando a Yugoslavia por el sur de los griegos y los británicos, para lo cual su 2ª División Blindada se abrió paso hasta el puerto griego de Salónica, provocando que el frente montañoso de Macedonia quedara súbitamente cercado, terminando así con lo que los Aliados esperaran que fuera un frente de gran duración. El ejército yugoslavo fue comprimido en la bolsa que se formó entre Belgrado y Skopie. Tras once días desde el inicio de la lucha (17 de abril), Yugoslavia se rindió y cayeron prisioneros 335 000 soldados. Sin perder tiempo, Alemania se dirigió rápidamente a Grecia, obligando a que el frente anglo-griego se batiera en retirada para evitar ser copado, y luego los británicos se embarcaron por los puertos en los que habían llegado, dirigiéndose a la isla de Creta. Las tropas griegas se quedaron solas, obligando a Grecia a capitular el 21 de abril después de haber perdido cerca de 233 000 prisioneros, la mayor parte en el envolvimiento de Macedonia. Después de la capitulación de Grecia, Hitler ordenó que todos los prisioneros griegos y yugoslavos fueran puestos en libertad. El 25 de abril se lanzaron paracaidistas sobre Creta, que lograron capturar la isla, si bien a un alto costo.

Con el Frente de los Balcanes calmado, Hitler estaba libre de nuevo para iniciar la Operación Barbarroja, si bien con unos meses de retraso. Pero en la Unión Soviética, la situación era de completa tranquilidad, a pesar de que el espía Richard Sorge había dado a Stalin la fecha aproximada del ataque alemán así como los criptoanalistas suecos. Solo se equivocó en dos días, al concretar que el ataque tendría lugar el 20 de junio de 1941. Stalin, considerando que la Batalla de Inglaterra estaba en su apogeo, ignoró las advertencias. Además en 1937, Stalin, sucumbiendo a las técnicas de desinformación del contraespionaje alemán, aceptó que el mariscal Mijaíl Tujachevski estaba cooperando con la Alemania nazi. Esta creencia condujo a la ejecución de Tujachevski, junto con otros eminentes militares soviéticos, en el transcurso de la Gran Purga. De esta manera, varios comandantes conocedores de las nuevas tácticas militares fueron eliminados, minando la eficacia militar soviética (véase el Caso de la Organización Militar Trotskista Antisoviética).

Siguiendo los principios establecidos en Mein Kampf, el gobierno nazi planeaba ocupar el este de Europa ya que el pueblo alemán necesitaba el Lebensraum o "espacio vital" para progresar. Hitler planeaba expulsar a la población de la Unión Soviética más allá de los Montes Urales, según él su región natural, y la población que quedase moriría por inanición, generando un superávit de producción de alimentos que estaría destinado a Alemania. Además, debido a que en Alemania existía escasez de mano de obra por la movilización del ejército, los rusos que sobrevivieran se convertirían en una especie de clase obrera esclava. Los campos agrícolas de Ucrania y los pozos petroleros del Cáucaso suministrarían al Tercer Reich todo el alimento y el combustible para su expansión. Además, al caer la Unión Soviética, Reino Unido quedaría completamente aislada en Europa, siendo obligada a firmar un armisticio.

La debilidad del ejército soviético jamás fue puesta en duda por Hitler. Este comentó: "Sólo debemos patear la puerta y toda la podrida estructura se vendrá abajo". Al haber ocupado Francia, Noruega, Yugoslavia, Holanda, Bélgica, Dinamarca y Grecia y expulsado a los ingleses de Europa en menos de un año, pocas personas pusieron en duda de que Alemania podría derrotar a la Unión Soviética.La Operación Barbarroja, planeada inicialmente para el 13 de mayo, contaba con tres millones de hombres, divididos en tres grupos: Norte (Wilhelm Ritter von Leeb), Centro (Fedor von Bock) y Sur (Gerd von Rundstedt). En total, 3.5 millones de soldados alemanes más 600 000 soldados aliados, en total 4 100 000 soldados aglutinados en 225 divisiones con 600 000 vehículos, 750 000 caballos, 4300 blindados, 7184 cañones y 4000 aviones de la Luftwaffe junto con 19 000 trenes. El Grupo de Ejércitos Centro llevaría la mayor cantidad de tanques y debería atravesar Bielorrusia e ir directo sobre Moscú. El Grupo Norte debería ocupar Leningrado con la ayuda de las tropas finlandesas para luego ir en ayuda del Grupo Centro. Mientras tanto el Grupo Sur atravesaría la poblada Ucrania, para luego dirigirse al Volga y de ahí al Cáucaso, rico en petróleo. El avance alemán de esta operación debería llegar hasta la llamada línea AA, que iba desde Arjángelsk hasta Astraján.

Por su parte, para el 1 de junio de 1941, el Ejército Rojo contaba en los sectores militares occidentales con un total de 36 divisiones acorazadas, 18 motorizadas, 7 de caballería y 88 de cazadores. La Gran Purga efectuada en el Ejército Rojo agravó mucho la situación, (más del 80 % de la oficialidad fue eliminada) Stalin acabó con tres de sus cinco mariscales, trece de sus quince jefes de Ejército, más de la mitad de los generales de división y casi idéntica proporción de los de brigada. Además, la Unión Soviética sufría una gran desorganización de los mandos en ese momento y en la fase inicial tenía una alta concentración de efectivos en la frontera; y peor aún, durante una semana imperó la orden de no provocación dada a la oficialidad soviética en la frontera.

El 22 de junio inició la invasión, la mayor operación terrestre de la historia, encontrando al Ejército Rojo completamente desprevenido. Stalin, que se hallaba de vacaciones, ordenó no contraatacar durante el primer día, con la ingenua esperanza de que todo fuera un error, o de que por lo menos todavía se pudiera encontrar una solución con el diálogo. Gran parte de la fuerza aérea soviética ubicada cerca de las fronteras fue destruida por la Luftwaffe durante el primer y segundo días de lucha, ya que se trazó un plan en el que varias escuadrillas de tres bombarderos cada una se internarían en territorio soviético abarcando un radio de 300 kilómetros volando casi a ras del suelo y sin cruzar ciudades para dirigirse contra los principales aeródromos de la URSS. En estos dos días se abatieron cerca de 2500 aviones soviéticos, en el aire y sobre todo en sus aeropuertos. La orden de ubicar los aviones tan cerca de Alemania había sido dada hacía poco por Lavrenti Beria, y fue una de las muchas causas que llevaron a su ejecución años después.

Las cifras anteriores incluyen todo el personal del ejército alemán, es decir, el servicio activo Heer, Waffen SS, fuerzas terrestres de la Luftwaffe , personal de la artillería costera naval y unidades de seguridad. En la primavera de 1940, Alemania había movilizado a 5,500,000 hombres. En el momento de la invasión de la Unión Soviética, la Wehrmacht consistía en, 3,800,000 hombres del Heer, 1,680,000 de la Luftwaffe, 404,000 de la Kriegsmarine, 150,000 de las Waffen-SS y 1,200,000 del Ejército de Reemplazo (contenía 450,400 reservistas activos, 550,000 nuevos reclutas y 204,000 en servicios administrativos, vigilias o convalecencia). La Wehrmacht tenía una fuerza total de 7,234,000 hombres para 1941. Para la Operación Barbarroja, Alemania movilizó 3,300,000 tropas de los Heer, 150,000 de las Waffen-SS y aproximadamente 250,000 personal de la Luftwaffe fueron activamente asignados.

Para julio de 1943, la Wehrmacht contaba con 6,815,000 soldados. De estos, 3.900.000 se desplegaron en Europa del Este, 180.000 en Finlandia, 315.000 en Noruega, 110.000 en Dinamarca, 1.370.000 en Europa occidental, 330.000 en Italia y 610.000 en los Balcanes. Según una presentación de Alfred Jodl , la Wehrmacht tenía hasta 7,849,000 de personal en abril de 1944. Se desplegaron 3,878,000 en Europa del Este, 311,000 en Noruega / Dinamarca, 1,873,000 en Europa occidental, 961,000 en Italia y 826,000 en los Balcanes. Alrededor del 15-20% del total de la fuerza alemana eran tropas extranjeras (de países aliados o territorios conquistados). La marca de agua alta alemana estaba justo antes de la Batalla de Kursk, a principios de julio de 1943: 3,403,000 tropas alemanas y 650,000 tropas finlandesas, húngaras, rumanas y de otros países. 

Durante casi dos años, la frontera estuvo tranquila mientras Alemania conquistó Dinamarca, Noruega , Francia, los Países Bajos y los Balcanes. Hitler siempre tuvo la intención de incumplir su pacto con la Unión Soviética, y finalmente tomó la decisión de invadir en la primavera de 1941.

Algunos historiadores dicen que Stalin temía la guerra con Alemania, o simplemente no esperaba que Alemania iniciara una guerra de dos frentes, y era reacio a hacer cualquier cosa para provocar a Hitler. Otros dicen que Stalin estaba ansioso por que Alemania estuviera en guerra con los países capitalistas. Otro punto de vista es que Stalin esperaba la guerra en 1942 (el momento en que todos sus preparativos estarían completos) y obstinadamente se negó a creer su pronta llegada.

Los historiadores británicos Alan S. Milward y M. Medlicott muestran que la Alemania nazi, a diferencia de la Alemania imperial, solo estaba preparada para una guerra a corto plazo (Blitzkrieg). Según Edward Ericson, aunque los recursos propios de Alemania fueron suficientes para las victorias en Occidente en 1940, los envíos soviéticos masivos obtenidos durante un corto período de fueron críticos para que Alemania lanzara la Operación "Barbarroja." 

Una vez que quedó claro que Hitler había decidido por fin atacar a Unión Soviética, se dictaron órdenes que revelaban la inmadurez estratégica y desconcierto del Alto Mando Soviético, la STAVKA. A las sorprendidas unidades soviéticas se les ordenó que no retrocedieran; al contrario, debían avanzar y llevar el combate a territorio enemigo. Las unidades alemanas debían de ser ""cercadas y aniquiladas"". Fruto de esta orden, las divisiones acorazadas soviéticas de la segunda línea defensiva, que debían haber sido mantenidas cuidadosamente como reserva, fueron lanzadas de forma prematura a la batalla. El 24 de junio, en varios lugares, los alemanes se habían adentrado más de 150 kilómetros en territorio soviético y las órdenes fatales habían permitido que los nazis cercasen a fuerzas soviéticas en número considerable.

Molestos por los resultados de la guerra de Invierno, los finlandeses se unieron a Alemania, y apoyadas por las fuerzas de este país, las divisiones finesas avanzaron hasta el lago Ládoga, cuyas costas habían perdido en 1940, y no se detuvieron hasta llegar al istmo de Carelia. Sin embargo, el gobierno finés se negó a seguir adelante, a pesar de que Alemania le presionaba para que participara en el asalto a Leningrado.

En un mes, el Báltico y Bielorrusia estaban en manos alemanas. Hitler envió los tanques al norte y al sur, para terminar de tomar Leningrado y Ucrania, a pesar de que sus generales le aconsejaban enviar la ofensiva directamente contra Moscú, que se encontraba a solo 400 kilómetros.

En septiembre de 1941 Kiev cayó y 665 000 soldados soviéticos fueron atrapados, y luego en Viazma otros 600 000 soviéticos también fueron aislados (ver Primera Batalla de Kiev y Bolsa de Viazma). En esos momentos las pérdidas soviéticas eran enormes, cuando más de 2 000 000 de soldados habían perdido la vida, se encontraban heridos o prisioneros. Cualquier otra nación habría solicitado la rendición estando en esas condiciones ya que la guerra parecía perdida para los soviéticos. Pero esta guerra era una lucha de subsistencia, y Stalin, recuperándose de su estado de estupefacción, se entregó de lleno a organizar los altos mandos para contener a los alemanes. En las reuniones, Stalin dejaba la iniciativa a los militares veteranos y les daba plena flexibilidad en sus propuestas, a diferencia de Hitler que al avanzar el tiempo se empeñó en ejercer el control total y absoluto de sus fuerzas.

Además ante la imposibilidad del Grupo de Ejércitos Norte de tomar Leningrado, se empezó a sitiarla. En 900 días de asedio, desaparecieron perros, gatos, ratas y palomas consumidos por sus desesperados habitantes. Lentamente un millón de personas murieron por el hambre, el frío y los bombardeos. Hubo muchos casos de canibalismo.

Durante este tiempo, los soviéticos aprovecharon para enviar toda su industria a la retaguardia, moviendo a miles de obreros de un lugar a otro. Aunque existieron graves problemas de organización, la operación cumplió su objetivo y pronto las industrias pesadas de Unión Soviética estaban funcionando de nuevo en los Urales.

El 6 de septiembre por fin Hitler permitió la toma de Moscú. Sin embargo las fuerzas alemanas habían tenido un 10 % de bajas hasta este momento, lo que significaba que 200 000 soldados del Reich estaban fuera de combate, y además el cruel invierno ruso ya estaba cerca. Debido a la extensión del frente, la reagrupación de los tanques del Grupo de Ejércitos Centro tardó un mes completo, restándole días a la campaña contra Moscú debido a la proximidad de diciembre. Sin embargo, el Alto Mando alemán estaba confiado, ya que según sus cálculos los soviéticos contaban con 60 divisiones, aunque en realidad pasaban de 200.

La Operación Tifón, como se llamó a la ofensiva contra la capital soviética, usaba de nuevo la Blitzkrieg, sin embargo, en este caso las condiciones del terreno no eran las más adecuadas para este tipo de combate. Las pésimas condiciones de las carreteras soviéticas, por las tempranas lluvias de octubre, demoraban el avance de los tanques y hacían muy difíciles de cruzar los campos, incluso en caballos. A 160 kilómetros de Moscú, la lluvia paró, pero empezaron las nevadas, que comenzaron a causar bajas entre los alemanes. El OKW había esperado una victoria rápida y no había abrigado lo suficiente a sus soldados. En Smolensko, el Ejército Centro encontró una feroz resistencia que hizo atrasar el avance a Moscú. Este retraso unido a la falta de suministros atrasó en varias semanas a los alemanes. El invierno más crudo del siglo estaba por iniciarse y también la batalla de Moscú. Los partisanos atacaban la retaguardia y las líneas de suministros alemanas, y la aviación rusa bombardeaba de noche las pistas enemigas. Una de las cosas que más llamaba la atención a los alemanes era la tremenda capacidad de resistencia del ejército soviético.

Ante los iniciales éxitos alemanes, el espía Richard Sorge avisó a Stalin de que Japón no pensaba atacar a la Unión Soviética, y éste decidió traer las divisiones que estaban en la frontera con Mongolia. Además, Stalin nombró a Georgi Zhúkov comandante en jefe del Ejército Rojo, a pesar de que hace poco lo había exiliado.

El 15 de noviembre se inició una campaña contra Moscú, intentando rodearla. El 21 de noviembre, el Cuarto Ejército Panzer llegó a 30 kilómetros de su objetivo, pero se detuvo en Jimki. Al mismo tiempo, el Segundo Ejército Panzer fracasó en su intento de tomar Tula, la única población que se interponía entre ellos y la capital soviética. Para finales de noviembre, los generales alemanes reconocieron que la resistencia moscovita y el rigor del invierno iban a hacer imposible la toma de Moscú ese año. Un contraataque soviético organizado por Zhúkov dejó mal parados a los alemanes, y por primera vez los generales de los tres grupos sugirieron una retirada. Hitler inmediatamente los cesó del mando.

El 8 de diciembre, uno de los peores inviernos (-20 a -50 °C) en la historia de Rusia convenció a Hitler para que suspendiera las operaciones militares hasta 1942.

Mientras el avance se estancaba en el Norte, en el Sur se realizó un progreso imprevisto. Después de ganar la batalla de Vorónezh, el Grupo de Ejércitos Sur siguió los ríos Don y Volga hacia el Sur. Si bien el plan original indicaba que debía primero asegurarse estos ríos antes de ir hacia el Cáucaso, donde estaban los campos de petróleo, Hitler ordenó que se dividieran las fuerzas y se tomaran ambos objetivos al mismo tiempo. De esta manera, el VI Ejército alemán fue solo a Stalingrado, mientras que el IV Ejército Panzer que debía ayudarlo se atrasó un poco porque debía asegurar el cruce de las tropas al Cáucaso por el Don. Cuando el IV Ejército Panzer llegó a Stalingrado, la resistencia soviética se había endurecido demasiado.

En junio de 1942 Sebastopol cayó en manos alemanes, además el avance alemán en el Cáucaso llegó a su punto máximo el 18 de noviembre, sin embargo, la extensión del avance con los flancos descubiertos, obligó a los Panzer a retirarse cuando fueron atacados por los soviéticos. En este punto, la artillería, los tanques (el famoso T-34) y los aviones (Shturmovik) rusos empezaron a sobrepasar en número, y luego en calidad a los carros de combate y artillería alemanes, tal cual lo había predicho Heinz Guderian en su libro Achtung Panzer. Al parecer Hitler ignoraba las cifras reales y las dimensiones bélicas enemigas, hechos que se revelaron sobre sus mapas durante la ofensiva de 1942.

En este punto la invasión alemana llegó a su máxima extensión: dentro de poco, el Ejército Rojo no solo alcanzaría las fuerzas necesarias para frenar a la Wehrmacht, sino también para enviarla de vuelta a Alemania.

La guerra de Alemania con la Unión Soviética adquirió caracteres únicos. Las penurias impuestas tanto por la guerra como por las condiciones ambientales sobrepasaron en muchas oportunidades la capacidad de sufrimiento del ser humano. El hambre, el frío extremo, la vastedad del paisaje, el polvo y los lodazales, los partisanos, la falta de misericordia y la crueldad hacia el enemigo fueron de características únicas en este escenario.

Hitler emitiría la siguiente directiva "Kommissar Befehl", que era la orden de asesinar a todos los comisarios políticos prisioneros capturados, sin previo juicio y sumariamente. Esta medida fue contraproducente, ya que alentó a la más dura de las resistencias, ya que dispuestos a no dejarse coger con vida, los comisarios políticos estimularon la resistencia a ultranza de oficiales y soldados.

Los nacionalistas ucranianos y de los países bálticos acogieron al principio a los alemanes como libertadores del yugo soviético. Pero cuando comprobaron que los nazis los trataban como a una raza inferior, la invasión perdió rápidamente este apoyo local. En cambio Stalin hizo resucitar todos los viejos mitos patrióticos y nacionalistas, superados por la revolución, para impulsar la resistencia popular. La prensa soviética bautizó la guerra como "La Gran Guerra Patria" y una nueva revista llamada "Eslavos" fue hecha circular, en un intento de unificar a todos los países eslavos contra Alemania. Esta publicación se llegó a distribuir hasta en Sudamérica.

Una situación que sorprendió a los alemanes fue el uso de perros como elementos antitanques. Estos perros eran entrenados para situarse bajo un tanque por instinto pavloviano, pues se los había entrenado colocando comida debajo de los tanques. El cánido portaba una bomba en las grupas que era accionada por una asa perpendicular que se doblaba al meterse el perro bajo el tanque y causaba la explosión del dispositivo.

Pronto los soviéticos, más aún los de las regiones de Crimea, Lituania y Ucrania comprendieron que la intención alemana era su exterminio, ya que los oficiales hacían la vista gorda con los robos a las granjas y las violaciones de las mujeres. Las matanzas de Kiev, Smolensko y otros lugares por los batallones de la muerte, los Einsatzgruppen a cargo de las SS, despejaron todas las dudas acerca del destino que los esperaba. En este punto, tantos los militares como los civiles se empezaron a defender hasta la muerte, con un empecinamiento y un espíritu de lucha que sorprendió a los alemanes. Por primera vez en la historia, los alemanes observaron soldados mujeres entre los cadáveres de los puestos defensivos destruidos. Asimismo el papel de apoyo que prestó la mujer al soldado combatiente fue vital para mantener la moral combativa de los hombres, ya fuera sirviendo como oficiales de enlace, radiotelefonistas, o bien a cargo de emplazamientos artilleros o como brigadistas de tanques.

Por otro lado, las actividades de los partisanos hacían que para los alemanes, el internarse en un bosque o servir de enlace, equivaliera a un pase a la muerte. Durante la batalla de Moscú, la actividad partisana al este de Smolensko mantuvo en jaque durante semanas a los ejércitos del Reich. A pesar de que algunos soldados soviéticos se pasaban al lado alemán (se los denominó hiwis, incluso se formaron batallones cosacos con uniforme alemán), el Ejército Rojo logró un sorprendente grado de recuperación muy superior al alemán. Este mecanismo sinérgico se debía, en parte, a la ayuda aliada a la Unión Soviética, de acuerdo a la Ley de Préstamo y Arriendo de 1941, que facilitó a Gran Bretaña y otros aliados grandes cantidades de material de guerra, como equipos, tanques y aviones estadounidenses. La determinación de defender el suelo patrio, y el ser conocedores de la más que probable suerte que los esperaría a manos alemanas fueron fundamentales para mantener motivado al Ejército Rojo y al pueblo soviético. La aparición de grandes tanques soviéticos como el KV-1 y el T-34, de diseño y blindaje superior a los Panzer IV de los alemanes fue una de las bazas de la resistencia soviética.

Durante la batalla de Stalingrado, (de agosto de 1942 a enero de 1943), el ejército alemán luchó encarnizadamente por conquistarla. La ciudad fue bombardeada hasta quedar convertida en ruinas, pero esto la convirtió en un terreno ideal para los francotiradores. El 6.º Ejército alemán ocupó las principales áreas de la ciudad hasta llegar a los límites del río Volga, pero esto no disminuyó la intensidad de la lucha. La batalla se transformó en una pelea cuerpo a cuerpo para controlar cada uno de los edificios de la ciudad, que cambiaban de manos constantemente. El 28 de julio del 1942, en medio de los más duros combates en el frente del sur, Stalin firmó su famosa orden №227 “Sobre la prohibición de la retirada de las posiciones ocupadas sin previa orden o medidas tomadas para su mantenimiento”, conocida también como la orden «Ni un paso atrás» . Este documento sirvió como medida de fuerza en un momento en que decaía la disciplina en las tropas y crecían los rumores de la decadencia del ejército soviético. En ella se apuntaba: “… Nuestros medios son ilimitados. El territorio de la Unión Soviética no es el desierto, las personas son obreros, campesinos, intelectuales, nuestros padres, madres, mujeres, hermanos, niños… Nuestro frente recibe cada vez más y más aviones, tanques, artillería, lanzaminas. ¿Qué nos falta? Nos falta el orden y la disciplina. Si queremos salvar la posición y defender a nuestra Patria, debemos establecer una disciplina férrea.” Así, se estableció una disciplina de hierro: la retirada sin previa orden se equiparó a la traición. Las consecuencias de tal normativa fueron unívocas y hasta ahora no han sido estudiadas, pero produjo el efecto tan necesario de movilizar al decaído ejército.

El 19 de noviembre se desató la Operación Urano. Los soviéticos habían estado colocando tropas en ambos lados de Stalingrado, formando una pinza alrededor de la ciudad. El 23 de noviembre esa pinza se cerró sobre Stalingrado, atrapando a trescientos mil soldados del Reich. Al mismo tiempo, la Operación Marte intentó atrapar a más soldados alemanes en Smolensk, pero fracasó.

La OKW empezó entonces a enviar tropas desesperadamente contra Stalingrado, en un intento de liberar al 6.º Ejército cercado. El 12 de diciembre tres divisiones panzer intentaron acercarse a la ciudad en la llamada Operación Wintergewitter (en alemán, Tormenta de Invierno), pero se detuvieron a sesenta y cinco kilómetros de su objetivo. En aquel momento, los soldados alemanes atrapados estaban en condiciones demasiado severas, sin abrigo y comida, como para esperar un intento de ruptura desde adentro.

El 31 de enero de 1943, noventa mil soldados alemanes supervivientes de Stalingrado se rindieron a la Unión Soviética. Además, el 2.º Ejército húngaro fue barrido también.

Stalingrado marcó varios hitos: la primera derrota alemana importante en la guerra, el punto de mayor avance en la Unión Soviética y la batalla más sangrienta de la Historia, además Friedrich Paulus fue capturado, siendo el primer mariscal de campo alemán en ser capturado vivo en la historia. Todos los historiadores están de acuerdo de que aunque todavía quedaban por delante más de dos años de guerra, Alemania empezó a perderla en Stalingrado. Stalin diría para esa fecha: «Sorge salvó a la Unión Soviética», ya que los informes que suministró a Stalin, fueron valiosísimos para la retirada de fuerzas siberianas desde los fronteras orientales para destinarlas a Moscú y Stalingrado. Estas tropas combatieron bien en ambientes extremos. La Abwehr alemana descubrió las actividades de espionaje de Sorge y fue detenido por la Kenpeitai (el equivalente japonés de la Gestapo). A pesar de las negociaciones de Stalin, Sorge fue ejecutado en la horca el 7 de noviembre de 1944.

Los rusos avanzaron quinientos kilómetros más allá de Stalingrado, ocupando Kursk y Járkov. Sin embargo, el general Erich von Manstein lanzó una contraofensiva el 20 de febrero que les permitió recuperar Járkov. Este ataque de Von Manstein al sur de la ofensiva soviética dejó un saliente en el frente, cuyo centro estaba exactamente sobre Kursk.

Con esta situación en el frente, Hitler vio la oportunidad perfecta para emprender una ofensiva que le permitiría a Alemania retomar la iniciativa en la guerra. Atacar en Kursk era una jugada peligrosa, sus generales le recomendaron a Hitler que no atacara, sino que de ahora en adelante Alemania debería luchar a la defensiva. Hitler los ignoró y empezó a mover tropas de otros frentes hacia el saliente de Kursk, con el objetivo de atrapar a los soldados enemigos que se encontraban allí. Secretamente, Zhúkov empezó a mover tropas para fortalecer el saliente, después de que la inteligencia de su país le informara de los planes alemanes.

El ataque sobre el saliente de Kursk fue llamada Operación Ciudadela, aunque hoy en día se conoce como la batalla de Kursk. Los alemanes juntaron casi un millón de hombres para esta operación, así como 2700 tanques y 10 mil cañones de artillería. Por su parte, los soviéticos casi llegaron al millón y medio, así como 3600 tanques y el doble de cañones.

Todo estaba preparado para la mayor batalla de tanques de la historia, y Alemania debía derrotar completamente al Ejército Rojo, porque no contaba con las reservas para iniciar otra ofensiva. Hitler conocía la importancia de esta operación y por eso declaró:

El ataque comenzó el 4 de julio. Por la tarde Junkers Ju 87 "Stuka" bombardearon en las líneas del norte, a la vez que se iniciaba el ataque de artillería. A las 22:30 los soviéticos replicaron con un bombardeo de la artillería que, ayudado por la lluvia torrencial, retardó el avance alemán.

El 5 de julio de 1943, los soviéticos, conociendo la hora exacta del ataque alemán, comenzaron un bombardeo masivo de la artillería sobre las líneas enemigas 10 minutos antes, seguido por un ataque masivo por parte de la aviación rusa contra la Luftwaffe en sus bases, en una tentativa de emular la táctica alemana de eliminar la aviación enemiga dentro de la primera hora de la batalla. Las horas siguientes se convirtieron en la mayor batalla aérea de la historia.
El IX Ejército Panzer en el norte se encontró casi incapaz de moverse. A los pocos minutos de avanzar fue atrapado en los campos minados.

Después de que en una semana los alemanes hubieran avanzado solamente 10 kilómetros, los soviéticos lanzaron un ataque contra el II Ejército en Orel. En el sur las operaciones iban algo mejor para los alemanes. La punta de lanza del IV Ejército Panzer, comandada por el General Hermann Hoth, llegó a Prójorovka. En este empalme ferroviario se libró entonces una batalla de mil tanques, considerada por algunos historiadores como la mayor de la historia.

Sin embargo, a pesar de la cantidad de bajas alarmante en el bando soviético, la enorme reserva de hombres ayudó a solventar fácilmente las pérdidas del Ejército Rojo. Por el lado alemán la situación era diferente, ya que a pesar de que las bajas eran inferiores, cada una era un sacrificio que Alemania no podía darse el lujo de afrontar.

Lejos aún de su objetivo, a Hitler le llegó la noticia de que tropas británicas y estadounidenses acababan de desembarcar en Sicilia el 10 de julio (ver Operación Husky), los peores temores de los generales de Hitler se hicieron realidad: acababan de perder cientos de miles de soldados y no habían ganado casi nada. Hitler ordenó suspender la ofensiva y retiró tropas del frente oriental hacia el frente de Italia, aunque muchas de estas se encontraban en el campo de batalla cuando les llegó la orden.

En la batalla de Kursk, Alemania perdió cerca de 200 mil hombres, mil tanques y 200 aviones. Por su parte, la Unión Soviética perdió 600 mil hombres y 1500 tanques, así como mil aviones. Sin embargo, este país reemplazó en poco tiempo a los soldados perdidos, pero estas pérdidas fueron insostenibles para Alemania, y nunca más volvió a realizar una ofensiva a gran escala. El impulso alemán en la Segunda Guerra Mundial se perdió para siempre, y por primera vez, muchos generales alemanes se dieron cuenta de que su país iba a perder la guerra.

Aprovechando que los alemanes estaban distraídos por su propia ofensiva, el Frente del Oeste del Ejército Rojo se lanzó contra Smolensk, que fue liberada finalmente el 25 de septiembre. Sin embargo, el avance soviético hacia el río Dniéper fue tan rápido e imprevisto, que el II Ejército al mando del mariscal de campo Walther Model casi fue aislado. Al norte del saliente de Kursk, en el Frente de Bryansk, se inició otra ofensiva soviética, tomando Oriol en una semana y haciendo retroceder a los alemanes 120 kilómetros.

El 3 de agosto, se inició la operación "Polkovodets Rumyántsev" en los frentes de Vorónezh y de la Estepa, sorprendiendo a los alemanes de nuevo, ya que su inteligencia les había informado que estos dos frentes soviéticos habían sufrido serias bajas en la batalla de Kursk. Esta información era verdadera, pero Alemania volvió a subestimar los enormes recursos humanos que poseía el Ejército Rojo. La Rumyántsev logró liberar a Bélgorod en el segundo día. El 21 de agosto, Járkov también fue liberada por segunda vez en la guerra, si bien esta vez definitivamente.

Alemania se encontró entonces enfrentando ofensivas desde todos los frentes soviéticos cuando el Frente Centro, el Frente Suroeste, y el Frente Sur iniciaron sus propias operaciones también. El 23 de septiembre, el Ejército Rojo logró cruzar el Dniéper.

Si bien las operaciones soviéticas de 1943 se anotaron una gran victoria al aislar las fuerzas alemanes en Crimea y al liberar Kiev, los alemanes pensaron que el agotamiento haría que las ofensivas se suspendieran durante el invierno. Lo que la OKW no sabía es que al mismo tiempo, en el Kremlin ya estaba planificando la liberación de Ucrania ese mismo año.

En la madrugada del 24 de diciembre de 1943 los soviéticos irrumpieron a lo largo de todo el frente al oeste de Kiev, empezando con un ataque de artillería contra el Grupo de Ejércitos Sur. El asalto de la infantería posterior logró hacer retroceder a los alemanes 32 kilómetros, sin embargo, inmediatamente se iniciaron las lluvias, con lo que se redujo bastante el ritmo soviético. De todas maneras, para el 5 de enero de 1944, se había abierto una brecha de 240 kilómetros de ancho y 80 kilómetros de profundidad, cortándose la comunicación entre el Grupo de Ejércitos Norte y Sur.

Al disminuir las lluvias, la ofensiva soviética se disparó de nuevo, y entre las ciudades de Korsun y Cherkassy, en Ucrania, se atraparon a 50 mil soldados del Reich. De esta manera, quedó cada vez más claro que la situación alemana en Ucrania era insostenible, sin embargo, Hitler se negó a ordenar una retirada general. En abril cayó Odesa y Sebastopol un mes después.

Después del desastre de Smolensk, el Grupo de Ejércitos Centro y Norte habían logrado recuperarse y habían mantenido al Ejército Rojo alejado del Dniéper en el norte. Sin embargo, en enero de 1944, los frentes del Norte se activaron de nuevo, permitiendo finalmente el levantamiento del cerco de Leningrado, aunque buena parte de los habitantes ya habían muerto para entonces. Poco después, Nóvgorod también fue liberada y en febrero el avance soviético se detuvo en la frontera con Estonia, después de haber movido 100 kilómetros el frente.

Con el frente en el sur muy aislado, el Alto Mando Soviético concluyó que lo mejor sería avanzar por Bielorrusia también, ya que si las tropas soviéticas continuaban avanzando por Ucrania extendería peligrosamente las líneas de suministros Finalmente se llegó a elaborar la Operación Bagration, cuyo objetivo sería empujar el frente más allá de Minsk. Los alemanes, por su parte, habían estado retirando tropas de Bielorrusia, ya que esperaban un ataque más al sur, frente a Leópolis.

El 6 de junio, las tropas angloamericanas por fin desembarcaron en Europa, aliviando la presión que existía en el Frente Oriental.

El 9 de junio de 1944, el Ejército Rojo logró expulsar a los finlandeses del lago Ládoga. Los alemanes en Finlandia, comandados por el General Lothar Rendulic, empezaron a prepararse para escapar de Finlandia, porque sabían que este país los traicionaría pronto. El propio Carl Gustaf Mannerheim les había advertido tiempo atrás que si los alemanes eran expulsados de Estonia, Finlandia negociaría la paz. En efecto, el 19 de septiembre la Unión Soviética y Finlandia firmaron un armisticio, y este país le declaró la guerra a Alemania poco después (véase Guerra de Laponia). En su huida, los alemanes arrasarían con varias poblaciones como medida de represalia, incluyendo Rovaniemi.

El 23 de junio, la Operación Bagration se desencadenó, y los resultados fueron palpables en menos de 24 horas. De esta manera, para el 27 de junio las fuerzas alemanas en Vítebsk habían sido derrotadas, mientras que el 9º ejército Alemán, unos 70 mil hombres, había sido capturado casi en su totalidad.

Mientras tanto, el 4º ejército alemán, batiéndose en retirada desde Orsha, se tuvo que detener en el río Beresina, porque Hitler le prohibió retroceder más. Cuando el desastre era inminente, el comandante del 4º ejército desobedeció las órdenes, e hizo cruzar las tropas, evitando un desastre mayor.

Por otro lado, el Grupo de Ejércitos Norte también fue atacado, ya que muchas tropas se retiraron al sur, hasta Minsk, donde fueron cercadas el 3 de julio. Una semana después, la ciudad caía. Inmediatamente, el Ejército Rojo avanzó hacia Lituania, tomando Vilna rápidamente.

Finalmente, el 29 de agosto, el avance soviético se detuvo. Para ese momento, el II Frente Bielorruso estaba a menos de 80 kilómetros de Prusia del Este, en aquel momento parte de Alemania. Más al sur, el I Frente Bielorruso había entrado a Polonia y cruzado el río Vístula, además parte importante del Grupo de Ejércitos Norte no se había podido retirar y había quedado aislado en Curlandia. Después de avanzar casi 600 km en un frente de 1120 km, los estados del Báltico habían sido liberados de la ocupación nazi, y solo era cuestión de tiempo para que Polonia fuera también liberada por la Unión Soviética. Además, en el sur, el avance sobre Ucrania finalmente se había completado, y el 23 de agosto, el gobierno pro-nazi de Rumania fue derrocado. El 12 de septiembre, Rumania se rindió, y los Balcanes fueron abiertos completamente al Ejército Rojo.

En total, la Operación Bagration golpeó a 16 divisiones alemanas y causó bajas a otras 50 divisiones. Con los aliados desembarcando en Francia al oeste, y habiendo perdido más de 200 mil hombres en el este en los últimos tres meses, era obvio que la Wehrmacht debería tomar medidas extraordinarias si quería evitar que los soviéticos entraran al corazón de Alemania.

Con los soviéticos a pocos kilómetros de Varsovia, los polacos del Armia Krajowa, decidieron que ya era hora de levantarse en masa contra la ocupación alemana. Sin embargo, la ofensiva soviética tuvo que detenerse por problemas de abastecimiento: los mejores pronósticos soviéticos no habían predicho tal avance y por ende las líneas de suministros se habían extendido demasiado. Además un ataque de cuatro divisiones al mismo tiempo hizo retroceder a la vanguardia soviética que ya estaba llegando a los suburbios de Varsovia. Por este u otros motivos Stalin no brindó apoyo alguno a los polacos, que por dos meses y con la ayuda lanzada por británicos y estadounidenes desde el aire, se enfrentaron contra tropas SS de élite El trágico alzamiento de Varsovia concluyó con la ejecución de 250 mil civiles, así como la destrucción de Varsovia y la disolución del movimiento de resistencia polaco como fuerza militar relevante.

El caso de Varsovia se repitió inmediatamente en Eslovaquia, la resistencia eslovaca se rebeló en masa contra la guarnición alemana en su país. Al igual que en Varsovia, el alzamiento fracasó sin la ayuda del ejército rojo, y los alemanes restablecieron su poder en Eslovaquia solo para ser expulsados por los soviéticos dos meses después.

En enero de 1945 los soviéticos llegaron finalmente a Varsovia, y con una fuerza de tanques, infantería y artillería diez veces superior a las fuerzas alemanas, reiniciaron su ofensiva, cubriendo entre 30 y 40 kilómetros por día en Polonia. La población alemana de Prusia Oriental, Danzig y Poznań fue evacuada en el marco de la Operación Aníbal. Varios barcos con civiles y militares alemanes fueron hundidos por submarinos rusos, siendo los más conocidos el Wilhelm Gustloff y el MS Goya, con 8 mil y 6 mil muertos respectivamente. El éxodo alemán llevó a miles de refugiados buscar albergue en ciudades Coblenza, Dresde y Hamburgo, las cuales serían bombardeadas por los estadounidenses y británicos con bombas de fósforo y napalm, con miles de civiles muertos incluyendo prisioneros de guerra ingleses. Solo en Dresde se contabilizaron más de 40.000 desaparecidos, cuyos cuerpos presumiblemente se desintegraron., esto como resultado de la política aliada presidida por el Mariscal del Aire, el inglés Arthur Harris, apodado correctamente Bombardero Harris.

El 27 de enero fue finalmente liberado el campo de exterminio de Auschwitzen el que se encontraron solamente 5.000 reclusos. En total se encontraron otros cinco campos de esta clase en Polonia ocupada: Belzec, Chelmno (Kulmhof), Majdanek, Sobibor y Treblinka.

Para inicios de febrero, el Ejército Rojo se encontraba desplegado a lo largo del río Oder, a unos 60 km de Berlín. Lo que quedaba del Grupo de Ejércitos Norte continuaba resistiendo en Curlandia, olvidados por Berlín, mientras que el Grupo de Ejércitos Centro también estaba aislado en Königsberg. Solo quedaba la mitad del Grupo de Ejércitos Sur (Grupo de Ejércitos A) para resguardar la entrada a Berlín, ya que muchas tropas habían sido enviadas al oeste de Alemania para intentar contener a la ofensiva angloamericana durante la batalla de las Ardenas.

Además de renombrar al Grupo de Ejércitos Norte, Grupo de Ejércitos Curlandia, Hitler nombró a Heinrich Himmler comandante del recién creado Grupo de Ejércitos Vístula, a pesar de que este no tenía ninguna experiencia comandando tropas, esta decisión fue tomada por la sencilla razón de que Hitler ya no confiaba en la Wehrmacht desde el atentado del 20 de julio (Operación Valkiria). El contraataque lanzado por Himmler el 24 de febrero fracasó, y la Pomerania, región históricamente alemana fue anexada a Polonia.

Más al sur, tres intentos alemanes de sacar a sus tropas atrapadas en Budapest, fracasaron, y la guarnición de Budapest se lanzó en una carga suicida contra los soviéticos, muriendo la mayoría, si bien algunos alemanes lograron escapar. No obstante, Hitler ordenó a sus hombres avanzar hasta el Danubio, ejecutando una ofensiva en el lago Balatón, que fracasó. Esta fue la última ofensiva importante de Alemania en el resto de la guerra.

Aprovechando el fracaso alemán, el Ejército Rojo liberó Hungría, y para el 13 de abril, Viena ya había sido también liberada. El 9 de abril, la guarnición alemana de Königsberg se rindió, sin embargo, la lucha en Heiligenbeil y Danzig continuó hasta el final de la guerra en Europa.

Para abril, todos los frentes soviéticos y polacos estaban listos para iniciar el avance final sobre Alemania. Sumaban dos millones y medio de hombres, 6250 tanques, 7500 aviones, 41 600 piezas de artillería, 3255 lanzacohetes Katyusha, y casi cien mil vehículos de transporte.

El 16 de abril, la llamada batalla de Berlín empezó, y si bien Zhúkov encontró problemas en las llamadas Colinas de Seelow, en el sur, el I Frente Ucraniano de Iván Kónev llegó sin problemas al sur de Berlín. El I Frente Bielorruso de Zhúkov se vio presionado a acelerar el paso, ya que deseaba capturar Berlín primero. Zhúkov rodeó Berlín y atacó desde el noroeste, mientras que Kónev, que se detuvo momentáneamente por órdenes de Stalin, llegó después a Berlín y atacó por el sur.

El 24 de abril, el General Helmuth Weidling, comandante del LVI Cuerpo Panzer, se dirigió al búnker de Hitler para ser fusilado después de haber sido acusado de haber escapado a Potsdam. Sin embargo, como síntoma de la inestabilidad mental que Hitler mostró en sus últimos meses, Weidling no solo no fue ejecutado, sino que fue nombrado Comandante en Jefe de las fuerzas en Berlín, ya que Goebbels, el Defensor nominal de Berlín, no tenía preparación militar. La batalla de Berlín fue dura, los nazis reclutaron a los varones entre 13 y 60 años (ver Volkssturm), por lo que era normal ver niños de las juventudes hitlerianas, así como ancianos e inválidos, en los puestos de artillería o usando Panzerfausts. Las bajas fueron muy elevadas por los 2 bandos, y los edificios de Berlín sufrieron grandes destrozos, incluyendo la Cancillería del Reich, el Reichstag y la puerta de Brandeburgo. Aquellos civiles que se negaban a luchar eran ejecutados inmediatamente por los nazis. La cantidad de prisioneros fue baja comparada con las de otras batallas, los miembros de las juventudes hitlerianas fueron de los que más ferozmente combatieron, sobreviviendo solo 2 de ellos. Hitler se negó a abandonar la capital para ir al Berchtesgaden, por lo que los altos oficiales de la Wehrmacht rehusaron rendirse, ya que todos habían tomado un juramento de lealtad al Führer.

El 30 de abril, el canciller de Alemania, Adolf Hitler, se suicidó junto con su esposa, Eva Braun. Varios personajes importantes del gobierno nazi hicieron lo mismo, incluyendo Joseph Goebbels y su esposa, que antes envenenaron a sus seis hijos. El secretario de Hitler, Martin Bormann desapareció en la batalla, si bien varios personas aseguran que lo vieron muerto con dos tiros en la espalda en una estación de metro de Berlín. Weidling rindió la ciudad a los soviéticos el 2 de mayo. El "Feldmarschall" Wilhelm Keitel fue capturado y luego participó en la firma del documento de rendición.

En la batalla murieron 75.000 soldados soviéticos y 300.000 resultaron heridos, por parte alemana las bajas se estiman en 50.000 militares y 75.000 civiles muertos. 

El almirante Karl Dönitz fue nombrado Presidente por Hitler antes de morir, y este dio permiso al general Alfred Jodl para firmar la rendición incondicional con la Unión Soviética el 7 de mayo, haciéndose efectiva al día siguiente. Los otros hombres de confianza de Hitler, Hermann Goering y Heinrich Himmler habían caído en desgracia al intentar hacer la paz por separado con los aliados. Ambos se suicidaron después de ser capturados por los estadounidenses.

El 9 de mayo, Día de la Victoria para la Unión Soviética, se convirtió en fecha festiva, y el 24 de junio se celebró un impresionante desfile en Moscú.

Las fuerzas alemanas ubicadas en Praga se negaron a rendirse, ya que tenían la esperanza de que los norteamericanos podrían capturar la ciudad antes que los soviéticos. Cuando fue obvio que los norteamericanos no tenían ninguna intención de ocupar Checoslovaquia, dejaron de luchar y escaparon al oeste. Todos los rumores que existían, asegurando que los alemanes habían construido una serie de fortalezas inexpugnables en los Alpes (Alpenfestung), resultaron ser falsos, y la mayoría de las tropas alemanas, hartas de la guerra, se rindieron en masa a los aliados occidentales.

El Frente Oriental no tuvo paralelo en Europa por su ferocidad y brutalidad. La lucha involucró a millones de soldados y civiles en el bando soviético y el bando alemán. En este frente de operaciones murieron o desaparecieron más de 5.2 millones hombres de todas las fuerzas del Eje, incluyendo 583 mil prisioneros muertos en gulag. Las muertes de civiles alemanes, debido a crímenes de guerra, en la y el es de 1.1 millón y mientras que las pérdidas soviéticas duplican o triplican estas últimas, con más de 6.8 millones de militares muertos en combate y más de 3.8 millones de prisioneros y milicianos muertos en cautiverio o en campos de exterminio alemanes. Las muertes de civiles abarcan entre 10 millones por la actividad militar y crímenes de guerra de lesa humanidad por el ejército alemán y SS, más de 4 millones debido al hambre, frío y enfermedades. La alta cifra de civiles y soldados caídos prisioneros, revela el maltrato que sufrieron ambos lados, la brutalidad que mostraron los nazis en contra los civiles en la ocupación de Europa Oriental y la Unión Soviética siguiendo las órdenes de Hitler de vaciar estas tierras de sus habitantes, a los que consideraban inferiores, "Untermenschen", para proporcionar el espacio vital que necesitaba la nación alemana, la "raza superior", de los "Ubermenschen". El uso de la táctica de la tierra quemada, ordenada por Hitler y Stalin, originó que miles murieran de frío y hambre, así como la destrucción de la infraestructura completa de muchas ciudades, Stalingrado y Varsovia por ejemplo. El progreso de la artillería y el bombardeo masivo originó que grandes masas de soldados fueran aniquiladas en minutos. En cuanto a los prisioneros, desfallecían por el cansancio debido a los trabajos forzados, el hambre, el frío y las ejecuciones en masa, cabe resaltar que el mismo trato recibieron los prisioneros del Eje en manos de los soviéticos. 
Las perdidas alemanas en general incluyen las ᛋᛋ schutzstaffel, volkssturm, juventud hitleriana, organización Todt, reichsarbeitsdienst, y policía (1 732 123).

Las pérdidas aliadas del Eje incluyen tropas del ROA (Ejército ruso de liberación) (215 000), los finlandeses (55 000), otras perdidas aliadas (44 200). Prisioneros austriacos (156 682), otros prisioneros (450 600). 
Las perdidas aliadas de la Unión Soviética incluyen a los yugoslavos (450 000) y checos (3 000). 

Las fuerzas polacas, que inicialmente consistían en refugiados tanto de la invasión alemana como de la invasión soviética de Polonia en 1939, empezaron a pelear junto al Ejército Rojo en 1943. Cuando se empezó a liberar Polonia, más polacos se unieron al combate. 

Países como Rumanía, Bulgaria y Eslovaquia fueron obligados a cambiar de bando cuando la Unión Soviética los ocupó.

Siguiendo los acuerdos obtenidos en la Conferencia de Yalta y definidos en la Conferencia de Potsdam, Polonia cedería territorio a la Unión Soviética, recuperándolo de Alemania. De esta manera, la región de Silesia, la mitad occidental de Prusia Oriental y dos tercios de Pomerania fueron obtenidos por Polonia. La otra mitad de Prusia del Este pasó a manos soviéticas, y hoy en día es administrada por Rusia bajo el nombre de Óblast de Kaliningrado. Las regiones de Lorena y Alsacia son devueltas a Francia, este país a su vez ocupa la región del Sarre, reserva de carbón de Alemania. En 1954, el Sarre es declarado zona libre europea, pero tres años después, los habitantes del Sarre se declaran alemanes de nuevo. La zona de los Sudetes es devuelta a Checoslovaquia, y Austria se convierte de nuevo en una nación independiente. Noruega y Dinamarca son desocupadas por los alemanes, aunque una provincia sureña danesa se une a Alemania de nuevo en un referendo. En total Alemania perdió 25% de su territorio antes de que empezasen las anexiones de Hitler.

Alemania es dividida en cuatro zonas de ocupación, si bien existió dudas acerca de darle una zona a Francia, considerando el poco importante papel de este país en la guerra. Posteriormente, ante la sospechosa insistencia de Stalin de unificar Alemania, en 1949, Reino Unido, Francia y los Estados Unidos unen sus zonas de ocupación bajo el nombre de Alemania Occidental, la parte ocupada por la Unión Soviética se convierte en Alemania Oriental. Alemania unificada recuperaría su soberanía en 1991.

Austria también es dividida en cuatro zonas de ocupación, pero este país recupera su soberanía poco después.

Finlandia también mantiene su soberanía. Además de restablecer las fronteras de 1940, Finlandia debió ceder toda el área alrededor de Petsamo, perdiendo definitivamente su salida al Mar de Barents, además tuvo que prestar la península de Porkkala a la Unión Soviética hasta 1956.

Las monarquías de Rumania, Bulgaria, Hungría y Yugoslavia no regresan al poder o, en caso de hacerlo, son derrocadas poco después. En Yugoslavia el comunista Josip Broz Tito llega al poder a través de elecciones.
Lituania, Estonia, Letonia, Ucrania y Bielorrusia continuaron siendo Repúblicas federadas de la Unión Soviética.
La Unión Soviética sale de la guerra como una superpotencia mundial de primera clase, con un inmenso y moderno ejército. Sin embargo, a diferencia de las potencias occidentales, este país ha sufrido daños irreparables en su infraestructura, por lo que exige fuertes indemnizaciones de guerra a la economía en bancarrota de Alemania.Después de la guerra, aquellos líderes militares o nazis de las fuerzas del Eje fueron arrestados, siendo juzgados en una serie de juicios. Los más famosos de estos fueron los llamados Juicios de Núremberg, debido a la importancia política de los juzgados. En total, pocos alemanes fueron ejecutados a través de estos juicios, si bien muchos fueron encarcelados, la mayoría saldría libre antes de la década de los 70. Ningún aliado fue responsabilizado de algún crimen de guerra.

La Cancillería del Reich fue demolida en una ceremonia en la que estuvo presente sir Winston Churchill, este luego manifestó haber visto varios alemanes llorando. Oficialmente los restos de Hitler nunca fueron hallados, pero fuentes confiables rusas aseguran que fueron parcialmente recuperados por las fuerzas soviéticas, y junto a los restos de la familia Goebbels fueron llevados a un lugar en la Alemania Oriental. En 1970, por una orden del Kremlin, fueron reducidos a cenizas los huesos de Hitler y Eva Braun, y lanzados a un río. En Moscú se conservan hasta hoy solo fragmentos de sus calaveras y dentaduras.



</doc>
<doc id="42769" url="https://es.wikipedia.org/wiki?curid=42769" title="Joe Jackson (músico)">
Joe Jackson (músico)

David Ian "Joe" Jackson (11 de agosto de 1954, Burton upon Trent, Reino Unido) es un músico británico, representante de la llamada "new wave" junto con otros como Elvis Costello.

Apareció en escena con el LP "Look Sharp!", en el que se incluyen obras como la canción "Is She Really Going Out With Him; o"tro de sus temas de este disco es "It's Different For Girls". 

Otras de sus canciones y obras más conocidas son "Steppin' Out", "I'm the man", "On your Radio", "Kinda Kunte", "Beat Crazy", "Crime Don't Pay", "The band wore blue shirt" y "You Can't Get What You Want (Till You Know What You Want)", en los que mezcla el jazz con la música new wave. 

Lleva editados más de 20 discos y varias bandas sonoras. Ha obtenido 5 nominaciones al premio Grammy, en la que resultó ganador en 2001, en la categoría por "Symphony No.1".

Joe Jackson proviene de un hogar proletario y tuvo una infancia problemática (asma, falta de lazos sociales). Después de descubrir la música gracias a una grabación de Beethoven a la edad de 14 años, primero aprendió a tocar el violín. Pero pronto, cristalizó su amor por el piano, que se convirtió en su instrumento principal. Desde los 16 años, tocó en los pubs de su ciudad natal, Portsmouth. Solicitó con éxito una beca, que le permitió estudiar composición en la Royal Academy of Music de Londres.

Aunque con talento, la perspectiva de la profesión de compositor clásico no le interesaba, por lo que persiguió sus ambiciones en el área del rock y el pop, inclinaciones que ya se remontaban a su tiempo en la academia. Su primera banda propia se llamó "Arms and Legs", la cual se separó después de dos discos "singles" fallidos.

En la segunda mitad de la década de 1970, Jackson conoció a los músicos de la posterior banda de Joe Jackson: el bajista Graham Maby, el baterista Dave Houghton y el guitarrista Gary Sanford. Con ellos comenzó a grabar cintas de demostración, a través de las cuales recibió, en 1978, un contrato de grabación con A & M Records. El primer álbum que grabó inmediatamente para este sello se llama "Look Sharp!", y fue lanzado en 1979. El álbum es especialmente conodico por la canción "Is She Really Going Out With Him?," todo un éxito comercial. Esto fue seguido por los álbumes "I'm the Man" (1979) y "Beat Crazy" (1980). La entonces banda de Joe Jackson tuvo mucho éxito, y realizó numerosos conciertos en todo el mundo, el último el 15 de diciembre de 1980. La banda se separó y Jackson pasó a otros proyectos.

En 1981, grabó un álbum que difiere significativamente del anterior, "Jumpin 'Jive" el cual contiene ritmos de swing y blues inspirados en Cab Calloway, Lester Young, Glenn Miller y, especialmente, en Louis Jordan.

El siguiente álbum "Night and Day" (1982) muestra por primera vez la diversidad compositiva de Jackson y contiene elementos de rock, pop y jazz; sus letras también se volvieron más complejas y sofisticadas. Él mismo considera este álbum como el mejor de todos. Las pistas "Real Men" y "A Slow Song" se referían tangencialmente a la cultura gay de principios de la década de 1980 en Nueva York. El éxito también bendijo a "Steppin 'Out", una canción pop muy amigable para las emisoras de radio, las cuales pasaron mucho al aire este tema de un estilo electrónico algo futurista. Con la banda sonora de la película, "Mike's Murder" Jackson entró en un nuevo territorio en 1983, pero ni la película ni la banda sonora pudieron convencer al público y a los críticos.

En 1984 Joe Jackson se mudó a Nueva York. Allíí conectó su álbum "Body and Soul" a sus éxitos anteriores. De acuerdo a las corrientes del momento usó metales, pero con ritmos sudamericanos y elementos clásicos que también se hicieron escuchar en un álbum complejo e impulsado por un sonido propio. "Happy Ending", un dúo con la cantante Elaine Caswell, se afirmó como un lanzamiento único en las listas de los más vendidos.<nowiki></ref></nowiki> Heavily influenced by pop and jazz standards and salsa, it had the US No. 15 hit single "You Can't Get What You Want (Till You Know What You Want)".

Una peculiaridad de 1986 fue la preparación de un disco larga duración en el que venía trabajando desde hacía una año y medio: "Big World". En este disco Jackson y sus compañeros músicos interpretaron todas las canciones en vivo, en un concierto frente a una audiencia, pero en condiciones como las de un estudio de grabación. El público tuvo que comprometerse a no hacer ningún ruido. Por lo tanto, "Big World" es una síntesis entre álbum en vivo y de estudio.

Después de eso, Jackson entregó una banda sonora a la película , lanzó un álbum doble en vivo con grabaciones de cuatro giras, e interpretó un álbum fuertemente intercalado de elementos clásicos estilo Will Power. Sin embargo, no se le otorgó especial atención ni tuvo éxito comercial ninguno de estos proyectos. Los fanáticos aún esperaban noticias del "verdadero" Joe Jackson, y fueron recompensados ​​con los álbumes "Blaze of Glory" (1989) y "Laughter and Lust" (1991).

Después de tres años de descanso, "Night Music" (1994) lanzó un álbum de música clásica en el que Jackson interpretaba casi todos los instrumentos él mismo. A pesar del fracaso comercial de esta producción, que tuvo un lanzamiento único, bajo el título de "Ever After," Jackson firmó en 1997 con Sony Classical. Con este sello discográfico lanzó el álbum conceptual "Heaven and Hell" (1997), en el que cantó solo algunas canciones. Por la inusual Sinfonía No.1 (1999), recibió un premio Grammy en el mismo año, pero el éxito económico fue limitado. Al mismo tiempo, publicó su autobiografía "A Cure for Gravity" (una cura para la gravedad).

Al comienzo del nuevo milenio, Jackson regresó a los escenarios del pop y el rock con un cambio radical, un disco en vivo y ambicioso "Night and Day II", donde recurrió al sonido de su banda de principios de los años ochenta.

En 2003 regresó a Londres y revivió su banda original, que se había disuelto 23 años antes, y grabó un CD muy aclamado con el "Volumen 4". El título del CD alude a los primeros tres discos de la banda y, por lo tanto, representa su secuela. La gira posterior se documentó en el álbum en vivo "Afterlife", que se lanzó en la primavera de 2004.

En el álbum de William Shatner, "Has Been" (2004), producido por Ben Folds, Jackson se escucha en dúo en una regrabación de la canción "Common People" del grupo Pulp. Debido a diferencias artísticas, en 2004 no terminó el trabajo para la banda sonora de la película del golfo "The Biggest Game of His Life". Jackson tuvo una pequeña aparición como invitado en la película.

Desde 2006, Jackson ha vivido principalmente en Berlín. En 2006, Joe Jackson también presentó nuevo material como parte de una gira europea con el bajista Graham Maby y el baterista Dave Houghton. En Berlín, los tres músicos grabaron el álbum "Rain", que fue lanzado en enero de 2008. El trío ha estado de gira desde entonces, en otoño de 2010 en Europa y Alemania. Los escenarios se enriquecieron con algunas nuevas versiones, hasta cinco canciones por noche.

En el otoño de 2012, presentó el álbum "The Duke" y luego una gira que tuvo lugar, primero en los Estados Unidos y luego en Europa. Esta vez estuvo acompañado por la Bigger Band con otros seis músicos: Regina Carter, Sue Hadjopoulos, Allison Cornell, Jesse Murphy, Adam Rogers y Nate Smith.

Como parte del lanzamiento de 2015 "Fast Forward", hubo una gira de conciertos por Europa en la primavera de 2016. En 2018 también estuvo de gira, y en enero de 2019, Joe Jackson lanzó su vigésimo álbum de estudio "Fool". Joe Jackson celebró sus 40 años de su carrera musical con una gira mundial en 2019.

A partir de 2016, el sello discográfico independiente Intervention Records comenzó a reeditar varios de los álbumes de Joe Jackson. Todas las reediciones se hicieron en vinilo de 180 gramos con carátulas de lujo. Los títulos que se volvieron a emitir son: "Night and Day", "I'm The Man", "Look Sharp!" y, por primera vez en vinilo, "Summer in the City". Todos los álbumes fueron masterizados utilizando cintas 100% analógicas, excepto "Summer in the City", que fue masterizada a partir de archivos de alta resolución.

Jackson pasó varios años viviendo en la ciudad de Nueva York, lo que le sirvió de inspiración para su canción de 1982 "Steppin 'Out". En una entrevista de 2018, Jackson dijo: "No me gusta mucho Nueva York en estos días. Es como si la ciudad y yo tuviéramos una aventura amorosa y ahora sólo somos amigos, pero aún tenemos que vernos para seguir siendo amigos". Hoy vivo en Berlín. La Nueva York que conocí a fines del 81 y 82 "se ha ido".

Jackson estuvo casado durante dos años, al que Jackson calificó de "un desastre". El matrimonio terminó en divorcio. En una entrevista de 2001 con el "Irish Independent" Jackson declaró que estaba en una relación con un hombre. Jackson ya había discutido previamente su bisexualidad, en su autobiografía "A Cure For Gravity," de 1999.




El 26 de junio de 2019 la revista dominical neoyorquina "The New York Times Magazine" incluyó a Jackson en la lista de cientos de artistas cuyo material se informó se había destruido, en el incendio que afectó al departamento de música de Universal en 2008.




</doc>
<doc id="42770" url="https://es.wikipedia.org/wiki?curid=42770" title="Washington (estado)">
Washington (estado)

Washington, también llamado estado de Washington para diferenciarlo de Washington D. C., es uno de los cincuenta estados que, junto con Washington D. C., forman los Estados Unidos de América. Su capital es Olympia y su ciudad más poblada, Seattle. Está ubicado en la región Oeste del país, división Pacífico, limitando al norte con Canadá, al este con Idaho, al sur con Oregón y al oeste con el océano Pacífico. Fue admitido en la Unión el 11 de noviembre de 1889, como el estado número 42.

Fue nombrado en homenaje al líder de las fuerzas estadounidenses de la Guerra de la Independencia de EE. UU. de 1776 y primer presidente de Estados Unidos, George Washington. Los nombres de muchas ciudades y condados de Estados Unidos rinden homenaje a diversos presidentes estadounidenses, pero el estado de Washington es el único estado en ser nombrado en homenaje a un presidente estadounidense. Para diferenciarla de la capital de Estados Unidos, Washington D. C., en Estados Unidos, se suele llamar "estado de Washington" al estado y "D. C." (abreviatura de "Distrito de Columbia", "District of Columbia" en inglés), "ciudad federal" o "ciudad de Washington" o a la capital nacional.

Washington cuenta con enormes bosques de coníferas, que le han valido el apodo de "Evergreen State" (estado siempre verde, o estado de la hoja perenne). Estos bosques hacen de Washington un líder de la industria maderera estadounidense. Se encuentra cortado por varios ríos y salpicado por varios lagos, lo que crea un terreno propicio para la instalación de presas. Aquí se localiza la mayor del país, la presa Grand Coulee, en el río Columbia. Su economía, sin embargo, se centra principalmente en el turismo y en la industria aeroespacial. El segundo mayor fabricante de aviones del mundo, Boeing, tiene su sede en este estado, así como varias de sus fábricas.

Los primeros europeos en explorar esta región fueron los castellanos, y posteriormente, los británicos fundaron los primeros asentamientos. La región formaba parte originalmente de una mayor llamada Oregon Country, un territorio disputado entre los estadounidenses y los británicos entre las décadas de 1810 y 1840. En 1846, el Tratado de Oregón establece que todas las tierras al sur del paralelo 49 del Oregon Country pasarían al control de Estados Unidos (a excepción de la isla de Vancouver). Hasta 1859, Washington formó parte del territorio de Oregón, creado a partir de la parte estadounidense del Oregon Country. En 1859, se crea el territorio de Washington, que fue nombrado en homenaje a George Washington.

En la región donde actualmente se ubica el estado de Washington ya vivían hacía varios miles de años diversas tribus nativas americanas, mucho antes de la llegada de los primeros europeos. Diversas tribus indígenas vivían en la región, y la mayoría formaba parte de dos grupos: los "salishianos" y los "penutianos". Los primeros vivían en el norte y en el litoral de Washington, mientras que los segundos vivían en el interior, a lo largo del oeste y del sur del estado.

Los primeros europeos en explorar Washington fueron los españoles, en la década de 1750. Estos exploraron intensivamente el litoral del actual estado, y reivindicaron la zona para la corona española, acorde al tratado de Tordesillas. Sin embargo, no fundaron ningún asentamiento permanente. Tales exploraciones fueron realizadas bajo el miedo de una expansión rusa —que entonces controlaba Alaska— en dirección al sur. El inglés George Vancouver suele considerarse el primer europeo en cartografiar el litoral del actual estado de Washington, durante el año 1792. No obstante, ese mismo año se había publicado un mapa de la costa noroeste estadounidense que incluye toda la zona, debido a Juan Francisco de la Bodega y Quadra, que la había recorrido en 1775. Ambos marinos intercambiaron información cartográfica y mantuvieron una amistosa relación durante la resolución del incidente de la isla de Nutca. También había explorado la zona la expedición de Alejandro Malaspina. Los ingleses, al menos en principio, tampoco se interesaron en fundar asentamientos permanentes, aunque reivindicasen la región a la corona británica.

En 1791 bajo el control español por parte de Manuel Quimper, en la bahía Nea (prácticamente en el extremo noroeste del actual "state" de Washington y en la margen sur del estratégico estrecho de Juan de Fuca), se estableció el primer asentamiento europeo a cargo del Imperio español y esto debido a la expedición del marino Salvador Fidalgo, se trataba de una posición fortificada: el Fuerte de Núñez Gaona (también llamado "Fuerte de Santa Rosalía") convirtiéndose en el primer asentamiento europeo en territorios correspondientes al actual estado de Washington y entonces correspondientes al litigado territorio del Oregón. 
Un año después, el estadounidense Robert Gray, junto con su expedición, compuesta por cazadores y comerciantes, fueron los primeros de esa nacionalidad en explorar el interior de Washington, habiendo partido de Boston, Massachusetts, bajo el mando de una compañía privada. Desembarcaron en el litoral de Washington en 1792. Estados Unidos pasó entonces a reivindicar la región. Los comerciantes y cazadores británicos y estadounidenses cazaban y comercializaban en la región del actual Washington. La Compañía de la Bahía de Hudson fundó el primer asentamiento permanente en la región, la actual ciudad de Vancouver.

La expansión estadounidense en dirección al oeste resultó en un creciente número de colonos estadounidenses que pasaban a instalarse en la región a partir de la década de 1840. Estados Unidos pasó a reivindicar para sí todas las tierras situadas al sur del meridiano 54º 40' y al oeste de las Montañas Rocosas. Los británicos habían exigido que la frontera fuese el meridiano 49º, y proseguiría en dirección al sur, acompañando el curso del río Columbia, al oeste de las Montañas Rocosas —en ese caso, gran parte del oeste del actual estado de Washington quedaría bajo control británico. En 1846, los Estados Unidos y el Reino Unido llegaron a un acuerdo, que delimitaba la frontera entre Estados Unidos y las colonias británicas de la región a lo largo del paralelo 49º.

En 1848, bajo presión de los colonos instalados en el noroeste de Estados Unidos, el gobierno estadounidense instaura el Territorio de Oregón, e implementa un gobierno en la región. Este territorio comprendía todos los actuales estados de Oregón, Idaho y Washington. Durante la década de 1850, se funda Seattle. En 1859, Oregón es elevado a la categoría de estado y el Territorio de Oregón pasa a ser el Territorio de Washington. Posteriormente, el gobierno del Territorio de Washington comenzaría a presionar a los nativos indígenas a instalarse en reservas, y así, proporcionar tierras a los colonos blancos. Tras el intento de compra de las tierras indias por parte del presidente de los EE. UU. Franklin Pierce, de especial importancia es la respuesta del jefe Seattle de la tribu de los duwamish (carta conocida como "Nosotros somos parte de la tierra" (traducción de la versión de Joseph Campbell al español), donde el jefe de la tribu presenta una particular visión del mundo y una manera de entender la naturaleza. Los salishianos aceptaron, pero no los penutianos, que entraron en guerra con los colonos blancos de la región en 1855. La guerra entre los colonos estadounidenses y los indígenas duró hasta 1858, año en que los penutianos fueron derrotados y forzados a mudarse a reservas indígenas.

A partir del inicio de la década de 1860, creció el número de colonos que pasaron a instalarse en el Territorio de Washington, gracias al descubrimiento de grandes minas de oro en la región. El crecimiento demográfico del territorio llevó a la secesión de varias áreas al oeste de Washington, para la formación del territorio de Idaho. Los límites territoriales de Washington, desde entonces, ya no cambiaron. El fuerte crecimiento demográfico de Washington seguiría en la década de 1870 y de 1880. Seattle se convirtió en un gran centro portuario. En 1883, se inaugura la "Northern Pacific Railway", que conectaba Washington con el este del país. El 11 de noviembre de 1889, el territorio fue elevado a la categoría de estado pasando a ser el cuadragésimo segundo estado de los Estados Unidos de América.

La economía de Washington, en sus primeras décadas como estado, dependía principalmente de la agricultura y de la minería. A lo largo de la década de 1890, las técnicas modernas de irrigación permitirían la práctica de la agricultura en la desértica región oriental de Washington. Allí, el ganado fue sustituido por las cosechas de trigo. Otras fuentes de ingresos importantes eran la industria maderera y la pesca.
A comienzos del siglo XX, la reputación de Washington en el país era la de una tierra peligrosa y salvaje, como el resto del oeste estadounidense, sólo que con leñadores en vez de vaqueros y bosques en vez de desiertos. En particular, la ciudad de Aberdeen tenía la reputación de ser "la ciudad más dura del oeste del Mississippi", debido al juego, a la violencia, al consumo generalizado de drogas y a la prostitución.

Seattle prosperó con la migración estadounidense rumbo a Hawái y a Alaska, y fue un centro principal de abastecimiento de Hawái durante varias décadas, e incluso hoy es el principal centro de abastecimiento de Alaska. La economía de Washington prosperó enormemente con el inicio de la Primera Guerra Mundial. Aumentó notablemente la producción de madera y alimentos. Seattle también se convirtió en una ciudad industrializada, una de las mayores fabricantes de barcos y aviones en general a lo largo de la guerra. En 1917, se funda la Boeing en Seattle. La guerra generó una mayor unión entre los trabajadores del estado, y se crearon varios sindicatos. Después del fin de la guerra, en febrero de 1919, los sindicatos de la ciudad organizaron una huelga general en Seattle, que convocó a más de 60.000 trabajadores.

La Gran Depresión, que se inició en 1929, arruinó la economía del estado. Para intentar minimizar los problemas causados por la Depresión, tales como la miseria, el desempleo y la pobreza, el estado inició la construcción de diversas obras públicas, entre ellas, varias presas, que culminó con la inauguración de la Presa Grand Coulee, en 1941, hasta hoy la mayor presa en funcionamiento de Estados Unidos.

La economía de Washington se recuperó con el inicio de la Segunda Guerra Mundial. El área metropolitana de Seattle, gracias a su proximidad con el frente de batalla del Pacífico, llegó a ser uno de los mayores fabricantes de barcos militares, y la mayor fabricante de aviones militares del país. En 1943, el gobierno estadounidense inauguró una central nuclear en el estado, el "Hanford Site". Esta central generó gran parte del combustible nuclear (plutonio) usado en las bombas atómicas de Hiroshima y Nagasaki. Washington se industrializó rápidamente, durante y después del fin de la Segunda Guerra Mundial, y la agricultura, la minería y la industria maderera perdieron mucha importancia en la economía estatal.

Durante la década de 1960, el gobierno de Washington aprobó una serie de programas destinados a la descontaminación de ríos y lagos contaminados por los desechos industriales y fecales. La ascensión de la Boeing como la mayor fabricante de aviones del mundo llevó a un gran crecimiento demográfico del área metropolitana de Seattle. En 1962, Seattle celebró la Feria Mundial de 1962. La mayor atracción de dicha feria fue la construcción de la "Space Needle", una torre de 184 metros de altura, inaugurada un año antes, en 1961. Posteriormente, en 1964, los gobiernos de Canadá y de Estados Unidos iniciaron un programa conjunto para la construcción de diversas presas a lo largo del río Columbia y sus afluentes.

El 18 de mayo de 1980, entra en erupción el Monte Saint Helens. Adormecido durante centenares de siglos, el volcán literalmente explotó, causando la destrucción total en un radio de cerca de 25 kilómetros a la redonda. En total 57 personas murieron, y los daños ocasionados ascendieron a más de 4.000 millones de dólares. La economía de Washington entró en una recesión que duró cerca de dos años. La erupción lanzó cenizas volcánicas en un radio de más de 1500 kilómetros de la explosión, principalmente en los primeros 200 kilómetros, cubriendo a varias ciudades por una gruesa capa de cenizas, de varios centímetros de espesor.

Durante su funcionamiento, el "Hanford Site" emitió varias toneladas de agua (usada como refrigerador) ligeramente radiactiva al día al río Columbia. Además de eso, los fallos a lo largo y ancho de su construcción hicieron que el suelo circundante quedase contaminado. El reactor se clausuró en 1971, y en 1989, el gobierno de Washington, junto con el de EE. UU., iniciaron un gran programa de limpieza, cuyo término está previsto para 2030.

En 1996, Gary Locke es elegido gobernador del estado. Locke fue el primer estadounidense de ascendencia china en ser elegido gobernador de un estado de EE. UU.

Washington se localiza en el noroeste de los 48 estados contiguos de los Estados Unidos de América. Limita al oeste con el océano Pacífico, al norte con la provincia canadiense de Columbia Británica, al este con Idaho y al sur con Oregón. El río Columbia forma la mayor parte de la frontera entre Washington y Oregón. Washington es un estado de contrastes. Por ejemplo, gran parte del estado está cubierto por bosques (la región boscosa de la península Olímpica está entre las más lluviosas del mundo), mientras que, por otro lado, gran parte del oriente del estado es árido, y es muy raro encontrarse con árboles. La variación de altitud es enorme, entre cero metros, a lo largo del litoral, a más de cuatro mil metros.

El litoral del estado con el océano Pacífico tiene cerca de 255 kilómetros de largo. Si contamos todas las regiones bañadas por el mar —bahías, estuarios e islas oceánicas— este total sube a 4.870 kilómetros. El principal río del estado es el río Columbia, cuyo nacimiento se localiza en la Columbia Británica. Este río atraviesa Washington de norte a sur durante cerca de 1100 kilómetros, y gira hacia el oeste en la frontera con Oregón. Las presas instaladas a lo largo del río producen la mitad de toda la electricidad generada en las centrales hidroeléctricas del país. La Presa Grand Coulee es actualmente la tercera mayor presa del mundo y la mayor del país.

Varios otros ríos cruzan el estado. La mayoría nacen en las Montañas Rocosas y discurren en dirección al océano Pacífico o al río Columbia. La mayor parte de los bosques estatales —que cubren casi la mitad del estado— se localizan en su parte oeste.

Podemos dividir Washington en seis regiones fisiográficas: 


Gracias a la proximidad de grandes masas de agua y a las corrientes marítimas cálidas del océano Pacífico, el occidente del estado de Washington tiene el clima más suave de todos los estados del norte de los 48 estados contiguos de Estados Unidos. El clima de Washington es templado, con cuatro estaciones distintas. Los veranos son frescos y menos cálidos que los de otros estados del norte del país, mientras que los inviernos son relativamente suaves, menos fríos que cualquier otro estado del norte del país. Gran parte del oeste de Washington registra tasas muy altas de precipitación media anual. Por su parte, el este del estado experimenta veranos muy cálidos e inviernos fríos, y bajas tasas de precipitación anual.

En invierno, la temperatura media es de 5 °C en el oeste y de -3 °C en el este del estado. Las medias más bajas se registran en las regiones de mayor altitud de Washington, de -8 °C en las regiones a más de 1600 metros. Las temperaturas mínimas varían entre -30 °C a 12 °C, y las máximas entre -22 °C y 18 °C. La temperatura más baja registrada en el estado, -44 °C, fue medida el 30 de diciembre de 1968, en Mazama y en Winthrop, al norte del estado.

En verano, la temperatura media es de 16 °C en el oeste y de 23 °C en el este del estado. Las medias más bajas se registran a lo largo del litoral de Washington. Las temperaturas mínimas varían entre 5 °C y 18 °C, y las temperaturas máximas entre 14 °C y 35 °C. La temperatura más alta registrada en el estado, 48 °C, fue medida el 5 de agosto de 1961, en Ice Harbor Dam, al sureste del estado.

Las tasas de precipitación media anual de lluvia varían de 100 a 350 centímetros anuales en el oeste del estado a sólo de 10 a 35 centímetros en la región centro-este. Las tasas de precipitación media anual de nieve varía entre 15 centímetros en el litoral, 130 a 200 centímetros en las regiones montañosas y 30 centímetros en la región centro-este.
 
Según el censo de 2005, Washington tenía una población estimada de 6.271.973 habitantes, lo que supone un aumento de 80.713 habitantes (o lo que es lo mismo, un 1,3%), en relación al año anterior y un aumento de 393.619 habitantes (o un 6,7%), en relación al año 2000. El aumento demográfico desde el último censo se debe a un crecimiento natural de 180.160 personas (418.055 nacimientos menos 237.895 muertes) y un incremento de la migración neta de 215.216 personas en el estado. Las migraciones externas han dado lugar a un aumento neto de 134.242 personas, mientras que las migraciones internas produjeron una pérdida neta de 80.974 personas. 

En 2004, el 10,3% de los habitantes del estado (631.500 personas) no habían nacido en Estados Unidos, de los que se estima que cien mil (1,6%) sean inmigrantes ilegales.

Cerca de un 83% de la población de Washington vive en áreas metropolitanas. La mayor de éstas es el área metropolitana de Seattle, que es la mayor ciudad del estado, con 375.000 habitantes. Su área metropolitana cuenta con cerca de 3,1 millones de habitantes, o lo que es lo mismo, cerca de dos quintos de la población del estado. La mayor parte de la población se concentra en el noroeste del estado.


Los seis mayores grupos étnicos de Washington son los alemanes (que comprenden un 18,7% de la población), los ingleses (12%) los irlandeses (11,4%), los noruegos (6,2%), los mexicanos (5,6%) y los filipinos (3,7%).

Los mexicanos se concentran principalmente en la región sureste y centro-sur, donde trabajan en los campos como mano de obra barata (muchos de estos trabajadores rurales son ilegales). El condado de Wahkiakum, así como la mayor parte de los condados del estado, alberga numerosos habitantes de origen escandinavo.

La población de ascendencia asiática de Washington es la quinta mayor del país. Dentro de ella, el mayor grupo étnico son los filipinos. Gary Locke fue elegido primer gobernador asiático-estadounidense en 1997.

Los afroamericanos son menos numerosos que los asiáticos y los hispánicos en muchas comunidades. En Seattle, se están trasladando a la parte del sur de la ciudad y a diversas áreas suburbanas, como el sur del Condado de King.

En Washington se localizan numerosas reservas indias. Muchas ciudades tienen nombres inusuales otorgados por los nativos americanos, como Seattle, Puyallup y Walla Walla.
La distribución de la población por edades en 2004 era:


Las personas de sexo femenino componen el 50,1 % de la población de Washington.

Afiliaciones religiosas de la población de Washington:

Como la mayoría de los estados del oeste estadounidense, el porcentaje de la población no religiosa de Washington es relativamente alto, mucho más alto que en el resto del país. El porcentaje de no religiosos del estado de Washington es el mayor de cualquier estado estadounidense, y las tasas de afiliaciones religiosas a iglesias u otras instituciones religiosas están entre las más bajas del país.

La economía de Washington se concentra principalmente en el sector terciario. El producto interior bruto de Washington era, en 2004, de 262.000 millones de dólares, lo que lo colocaba en el 14º puesto de la nación. La renta per cápita en 2004 era de 33.332 dólares. La tasa de desempleo se sitúa en el 6,2%. El centro económico, financiero e industrial del estado es Seattle.

El sector primario corresponde al 2% del PIB de Washington. La agricultura y la ganadería corresponden juntas a un 1,6% del PIB del estado, y emplean a cerca de 140.000 personas. El estado posee cerca de 39.000 granjas, de las cuales 13.000 dependen de técnicas de irrigación modernas para el cultivo de plantaciones. Los principales productos agrícolas y ganaderos que produce Washington son el trigo, las manzanas (el estado es el mayor productor nacional), la leche, las cerezas y la carne de vaca. En total, el valor de los productos agropecuarios producidos por el estado es de 5.400 millones de dólares. La industria maderera corresponde al 0,35% del PIB y emplea aproximadamente a 5000 personas. La pesca comprende un 0,05% del PIB de Washington, y emplea aproximadamente a 2000 personas. El valor anual total de la pesca capturada en el estado es de 100 millones de dólares.

El sector secundario corresponde a un 17% del PIB de Washington. La industria manufacturera corresponde a un 12% del PIB del estado y emplea aproximadamente a 375.000 personas. El valor total de los productos fabricados en el estado es de 35.000 millones de dólares. Los principales productos industrializados que se fabrican en Washington son aviones, barcos, software, productos electrónicos, alimentos procesados y papel y productos de la madera. La Boeing, la mayor constructora de aviones del mundo, tiene su sede en el estado (en Seattle) así como sus principales fábricas. También tienen su sede en Washington Microsoft, Amazon, Starbucks y Nintendo América. La industria de la construcción comprende un 4,6% del PIB del estado, y emplea aproximadamente a 212.000 personas. Por su parte, la minería es responsable de un 0,4% del PIB, empleando a cerca de 5000 personas. Los principales recursos naturales del estado son el carbón, el oro y la arena.

El sector terciario comprende un 81% del PIB de Washington. Cerca de un 24% del PIB del estado vienen de servicios comunitarios y personales, actividades que emplean a más de 1.100.000 personas. Washington es un gran centro financiero, siendo Seattle el principal centro económico del estado y uno de los principales de la costa oeste estadounidense. El comercio al por mayor y al por menor corresponden a un 17% del PIB, y emplean aproximadamente a 770.000 personas. Los servicios financieros e inmobiliarios corresponden a cerca de un 18% del PIB del estado, empleando aproximadamente a 270.000 personas. Los servicios gubernamentales corresponden a un 13% del PIB, y emplean aproximadamente a 553.000 personas. Por último, los transportes y las telecomunicaciones emplean a cerca de 172.000 personas y comprenden un 9% del PIB. 

Cerca de un 78% de la electricidad generada en el estado proviene de centrales hidroeléctricas. Ningún estado estadounidense produce más electricidad en centrales hidroeléctricas que Washington. El 13% de la electricidad generada en Washington se produce en centrales termoeléctricas de carbón, y el 9,5% en centrales nucleares. El 0,5% restante se generan en centrales eólicas y solares.

Washington es un estado agrícola destacado (las cifras siguientes provienen del Washington State Office of Financial Management y del Washington Agricultural Statistics Service.)

En 2003, el valor total de los productos agrícolas de Washington era de 579.000 millones de dólares, el 11º mayor en el país. El valor total de sus cosechas era de 38.000 millones, el 7º mayor. Por último, el valor total de su ganado era de 15.000 millones, el 26º mayor del país.

En 2004, el estado de Washington figuraba primero de la nación en la producción de frambuesas rojas (90,0% de producción total de EE. UU.), guisantes (80,6%), lúpulo (75,0%), aceite de hierbabuena (73,6%), manzanas (58,1%), cerezas dulces (47,3%), peras (42,6%), aceite de menta (40,3%), uvas Concord (39,3%), zanahorias (36,8%), y uvas Niagara (31,6%). Washington también figuraba en el segundo lugar de la nación en la producción de lentejas, patatas, guisantes secos, albaricoques, uvas (todas las variedades), espárragos (cerca de un tercio de la producción de la nación), maíz dulce y guisantes verdes; el tercer lugar en producción de cerezas ácidas, ciruelas, ciruelas pasas y cebollas de verano secas; el cuarto lugar en producción de cebada y trucha; y el quinto lugar en producción de trigo, arándanos y fresas.

El gobierno del estado de Washington cuenta con división de poderes: ejecutivo, legislativo y judicial.




La actual Constitución de Washington entró en vigor en 1889, creada anteriormente a la elevación de Washington a la categoría de estado. El Poder Legislativo de Washington puede proponer enmiendas a la Constitución, y para ser aprobadas, necesitan recibir al menos dos tercios de los votos del Senado y de la Cámara de los Representantes del estado, y después, otros dos tercios de los votos del electorado de Washington, a través de un referéndum. Las enmiendas también pueden realizarse a través de convenciones constitucionales, que son encuentros políticos especiales. Las enmiendas realizadas de esta forma necesitan ser aprobadas por al menos un 51% de cada Cámara del Poder Legislativo, y después, por al menos un 60% de la población electoral del estado, en un referéndum.

Washington está dividido en 39 diferentes. La mayoría de estos 39 condados están gobernados por un consejo formado por 3 miembros. Washington tiene cerca de 300 ciudades. Cualquier ciudad con más de 20.000 habitantes es libre de elegir su forma de gobierno municipal.



Tanto el Partido Demócrata como el Partido Republicano han tenido a lo largo del siglo XX una fuerte presencia en Washington. La mayoría de la población de las ciudades principales y más pobladas del estado apoyan a candidatos demócratas, mientras que el electorado de áreas rurales y de ciudades pequeñas tienden a votar a candidatos republicanos. No obstante, el estado a lo largo de su historia se ha caracterizado por ser uno de los más progresistas de todo el país.

La primera escuela de Washington fue fundada en 1832, en Vancouver, construida para la educación de los hijos de los empleados de la Compañía de la Bahía de Hudson. El estado instituyó un sistema público de enseñanza en 1895.

Actualmente, todas las instituciones educativas de Washington deben seguir ciertas reglas y patrones dictados por el Consejo Estatal de Educación de Washington. Este consejo controla directamente el sistema de escuelas públicas del estado, que está dividido en varios distritos escolares. Cada ciudad principal ("city"), diversas ciudades secundarias ("towns") y cada condado, constan al menos de un distrito escolar. En las ciudades, la responsabilidad de administrar las escuelas es del distrito escolar municipal, mientras que en las regiones menos densamente pobladas, esta responsabilidad corre a cargo de los distritos escolares que operen en el condado. Washington permite la existencia de "escuelas chárter" — escuelas públicas independientes, que no son administradas por distritos escolares, pero que dependen de presupuestos públicos para su sustentación. La escolarización es obligatoria para todos los niños y adolescentes de más de ocho años de edad, hasta la conclusión de la educación secundaria o hasta los dieciocho años de edad.

En 1999, las escuelas públicas del estado atendieron a cerca de 1.004.000 estudiantes, empleando aproximadamente a 50.400 profesores. Por su parte, las escuelas privadas atendieron a cerca de 76.900 estudiantes, empleando aproximadamente a 5.700 profesores. El sistema de escuelas públicas del estado utilizó cerca de 6.098 millones de dólares, y el gasto de las escuelas públicas fue de aproximadamente 6.600 dólares por estudiante. Cerca de un 89% de los habitantes del estado con más de 25 años de edad tiene en su haber un diploma de graduado en educación secundaria.

La primera biblioteca de Washington fue construida en 1853 en la actual capital del estado, Seattle. Actualmente, Washington posee 65 sistemas de bibliotecas públicas, que mueven anualmente una media de 9,6 libros por habitante.

La primera institución de educación superior de Washington, la Universidad de Washington, fue inaugurada en 1861. Actualmente, Washington posee 78 instituciones de educación superior, de las cuales 45 son públicas y 33 son privadas. Seattle destaca como el mayor centro educativo del estado.

Gracias a su localización estratégica, próxima a Alaska, Hawái y Asia, Seattle se ha convertido en un gran centro aeroportuario y portuario de Estados Unidos. Diversos vuelos que parten del Aeropuerto Internacional Seattle-Tacoma conectan el país con diversas ciudades de Asia, Hawái y Alaska. "Alaska Airlines" posee su centro de operaciones en este aeropuerto. El puerto de Seattle es uno de los más frecuentados de la costa oeste estadounidense. Además de eso, el estado administra la mayor compañía de ferrys del mundo, que conecta Seattle con las ciudades localizadas en islas del delta del río Columbia.

Cerca de 20 compañías ferroviarias suministran servicios de transporte de carga y pasajeros en el estado. En especial, Amtrak suministra servicios de transporte de pasajeros entre las principales ciudades del estado. En 2002, Washington contaba con 5.063 km de vías férreas. En 2003, el estado disponía con 132.391 kilómetros de vías públicas, de los cuales 1.230 eran autopistas interestatales, consideradas parte del sistema federal de autopistas de Estados Unidos.

El primer periódico publicado en Washington fue el "The Columbiam", impreso por primera vez en Olympia, en 1852. Actualmente se publican en el estado cerca de 200 periódicos, de los cuales 28 son diarios. También se imprimen cerca de 175 revistas. La primera cadena de radio de Washington fue fundada en 1920, en Everett, y la primera cadena de televisión, en 1948, en Seattle. Actualmente, Washington posee 188 cadenas de radio (de las cuales 73 son AM y 115 son FM) y 26 de televisión.

Diez barcos de la Armada de los Estados Unidos han sido llamados USS Washington, al principio en honor al presidente George Washington y después en honor al estado de Washington.

El estado de Washington tiene tres equipos profesionales de grandes ligas: los Seattle Seahawks de la National Football League, los Seattle Mariners de las Grandes Ligas de Béisbol y el Seattle Sounders FC de la Major League Soccer. Los Seahawks y Sounders juegan de local en el CenturyLink Field y los Mariners en el Safeco Field, todos ellos luego de haberse mudado del Kingdome.

Por su parte, los Seattle SuperSonics de la National Basketball Association compitieron entre 1967 y 2008, tras lo cual se mudaron de estado. Desde 2000, Seattle Storm compite en la WNBA de baloncesto femenino. Ambos equipos han jugado principalmente en la KeyArena.

Los Washington Huskies son un equipo universitario que se ha destacado en fútbol americano.

Estos son los símbolos del estado de Washington:






</doc>
<doc id="42779" url="https://es.wikipedia.org/wiki?curid=42779" title="Región de Antofagasta">
Región de Antofagasta

La Región de Antofagasta es una de las dieciséis regiones en que se divide Chile. Su capital es la homónima Antofagasta. Ubicada en el extremo norte del país —norte grande—, limita al norte con la Región de Tarapacá, al este con el departamento de Potosí en Bolivia y con las provincias de Jujuy, Salta y Catamarca pertenecientes a Argentina, al sur con la Región de Atacama y al oeste con el océano Pacífico.

Cuenta con una superficie de 126 049,1 km² y una población según el INE de 607 534 habitantes en 2017. La región está compuesta por las provincias de Antofagasta, El Loa y Tocopilla. La región cuenta con el PIB per cápita más elevado del país, superando los USD 25 000. Su principal centro urbano es la ciudad de Antofagasta con 361 873 habitantes, seguida en segundo lugar por Calama con 165 731 habitantes según el censo chileno de 2017.

Sobre el descubrimiento del salitre en Antofagasta y Tarapacá cuenta una leyenda que ocurrió cuando dos indígenas de la zona hicieron una fogata y empezó a arder la tierra que contenía caliche. Enterado el cura de Camiña, y llevando agua bendita, recoge unas muestras y reconoce que contenían Nitrato de Potasio. Otra parte de las muestras se encontraban en el patio de la casa del sacerdote y más tarde observa que las plantas se desarrollaban extraordinariamente.

En el gobierno de Andrés de Santa Cruz, en 1837, se creó el Departamento del Litoral, el cual se dividía en dos provincias: La Mar (con capital en Cobija) y Atacama (con capital en San Pedro de Atacama) y en 1868, Antofagasta sería la capital de la provincia de Mejillones.

La ciudad de Antofagasta, fue fundada por el gobierno boliviano en 1868. Desde antes de su fundación era un puerto de desembarque y un lugar de refugio y descanso sobre la costa boliviana para los exploradores chilenos. La fundación es algo que aún no ha sido establecido y aceptado oficialmente.

Previamente al poblamiento del lugar, Juan López, quien es considerado en Chile el primer habitante de la ciudad, se instaló en el sector de Peña Blanca, hoy conocido como La Chimba, donde comenzó la extracción de minerales de manera precaria.

El 10 de agosto de 1866 se firmó un Tratado de límites entre Bolivia y Chile, añadiendo además una acta adicional el 25 de agosto. En este documento se estableció como límite entre los dos países, el paralelo 24 de latitud sur. No obstante la división territorial estipulada, ambos gobiernos se comprometieron a repartir por mitad los productos provenientes de la explotación de los depósitos de guano descubiertos en Mejillones y de los demás depósitos del mismo abono por descubrir en el territorio comprendido entre los grados 23 y 25 de latitud meridional, así como también los derechos de exportación percibidos sobre los minerales extraídos en el mismo territorio ya mencionado.

El 18 de septiembre de 1866, José Santos Ossa y Francisco Puelma lograron la adjudicación legal de la concesión de terrenos salitrales, tras una solicitud enviada al gobierno boliviano. Tras una expedición liderada por José Santos Ossa, Alfredo Ossa y Hermenegildo (quien fue el guía), el cateador Juan Zuleta descubrió ricos depósitos de salitre (nitrato) en el sector de Salar del Carmen, al oriente de la actual Antofagasta. Tras el hallazgo, José Santos Ossa, Francisco Puelma y Manuel Antonio de Lama acordaron formar una Sociedad Exploradora del Desierto de Atacama.

El 19 de marzo de 1868 se constituyó la Compañía Melbourne Clark, tras la integración de intereses chilenos e ingleses. Posteriormente la compañía logró el 5 de septiembre de 1868, una ampliación de la concesión otorgada por el gobierno boliviano, esta vez por 15 años. Tras la conformación de la compañía, comenzó rápidamente a poblarse lo que se denominó La Chimba, en noviembre de 1866.

Tras el terremoto de Iquique y Cobija del 13 de agosto de 1868, fue necesario reconocer legalmente a La Chimba como un poblado minero. El 27 de agosto de 1868, el presidente de Bolivia Mariano Melgarejo encargó al prefecto del Departamento de Litoral, la fundación oficial de La Chimba, en el sector delimitado por los comisionados Hilario Ruíz y José Santos Prada. Así, el 22 de octubre de 1868 se fundó oficialmente la población y el puerto bajo el nombre de La Chimba, según consta en el acta de fundación. Posteriormente la ciudad fue renombrada como Antofagasta. El primer plano oficial de la población y puerto de Antofagasta fue diseñado por José Santos Prada, el 14 de septiembre de 1869.4 En este documento, se delimitó el terreno de la Compañía Melbourne Clark, además de 17 manzanas y una plaza principal.

El 8 de mayo de 1871, Antofagasta fue designada Puerto Mayor, abierto al comercio de todo el mundo.

El 25 de enero de 1872, tras una sesión dirigida por el Subprefecto del Departamento de Mejillones Manuel Buitrago, se fundó la Municipalidad de Antofagasta conforme a la ley boliviana de municipalidades, donde se conformó el Cuerpo de Agentes Municipales (posteriormente renombrada como Junta Municipal de Antofagasta), integrado por dos alemanes, un inglés y seis chilenos. Félix García Videla asumió como Presidente del Cuerpo de Agentes Municipales, el cual estaba compuesto por los munícipes Francisco Errázuriz, Emeterio Moreno, Salvador Reyes, Matías Rojas, Juan Vargas, Luis Lichenstein, Ernesto Wolchmar y Luis Foster. Además como medida ante el descontrol de la población, se conformó la Jefatura Policial que fue comandada por Domingo Machado, la cual se encargaba de regular al Cuerpo de Guardianes de la Guardia de Orden y Seguridad.

El 27 de noviembre de 1873, la Compañía de Salitres y Ferrocarril de Antofagasta firmó un acuerdo con el gobierno, que le autorizaba la explotación del mineral libre de derechos por 15 años, desde la bahía de Antofagasta hasta Salinas, incluyendo el Salar del Carmen.

En 1875, la Municipalidad de Antofagasta practicó un censo de población. Como resultado, se contabilizan 5384 habitantes, de los cuales 4.530 eran chilenos y 419 eran bolivianos.

Con la reforma constitucional boliviana de 1878, promulgada bajo el gobierno del presidente Hilarión Daza, y aplicada sobre la Constitución Política del Estado de 1831, se volvió a la bicameralidad, figurando Franklin Alvarado como diputado por Mejillones y Antofagasta en la Asamblea Constituyente que la aprobó.

Posteriormente, en la Constitución Política del Estado de 1880, promulgada bajo el gobierno del presidente Narciso Campero, figura Toribio Gutiérrez como diputado por Mejillones y Antofagasta en la Convención Nacional que la aprobó.

En tiempos precolombinos la línea costera estuvo poblada por bandas de pescadores-recolectores, llamados changos, de los cuales muy poco se sabe, dado a su poco contacto con los conquistadores españoles. El interior, por su parte, estaba poblado por la cultura atacameña, que se desarrolló en las vecindades del Salar de Atacama, la cuenca del río Loa y los valles y oasis esparcidos por el altiplano, siendo el más importante el actual pueblo de San Pedro de Atacama. Los atacameños fueron fuertemente influenciados por la cultura Tiwanaku y más tarde por el dominio Inca. Eran agricultores y comerciantes en rutas tan distantes como la cuenca del Amazonas y las costas del Pacífico. Con la llegada de los españoles, se da comienzo al mestizaje, que enriquece la cultura altiplánica.

A fines del siglo XVII, don Francisco de Cisternas y de la Fuente Villalobos, uno de los más acaudalados terratenientes del norte de la Capitanía General de Chile o el llamado Reyno de Chile, obtuvo por merced de tierras del 4 de julio de 1674 la encomienda de Paposo. A partir de entonces, la rada fue conocida como Hacienda de Paposo, debido a que el encomendero, aprovechando los pastos naturales del lugar, la dedicó a la crianza de ganado. El asentamiento comenzó a ser denominado "Nuestra Señora del Paposo" desde 1679.

Durante la época del Gobernador, don Ambrosio O´Higgins (1788-1796), por orden de sus autoridades locales, se apostaron en Paposo a fin de desbaratar eventuales desembarcos de corsarios ingleses que rondaban el litoral del desierto de Atacama.

Según anota Claudio Gay, el 28 de julio de 1797, el Gobernador del Reino de Chile, don Gabriel de Avilés y del Fierro, autorizó la suma de quinientos pesos de la época para la construcción de una capilla en Paposo. No contento con eso, autorizó a presbítero santiaguino, Rafael Andreu Guerrero, a trasladarse a la zona como Teniente de Cura, y se colocase a las órdenes del cura propietario de Copiapó, en el corregimiento chileno de Atacama. En 1853, el explorador Rodulfo Phillippi hacía mención de dicha capilla.

De acuerdo con el historiador peruano, Mariano Paz Soldán, el 1º de octubre de 1803, el rey Carlos IV, mediante real orden, ratificada por el mismo monarca en 1805, transfirió el puerto de Paposo a la jurisdicción del Virreinato del Perú, separándolo de la Capitanía General de Chile. No obstante, de acuerdo a la historiografía tradicional chilena, la orden no fue cumplida por el virrey español, en Lima, que continúa siendo territorio del Reino de Chile:

Durante la colonia, nace la Audiencia de Charcas, perteneciente al Virreinato del Perú, que comenzó a administrar esta zona. Tras la fundación del Virreinato del Río de la Plata, Charcas le fue transferida.

Según la historiografía chilena nunca se definió claramente que la zona del Pacífico controlada por Charcas fuese cedida al gobierno de Buenos Aires. Así, en muchos escritos de la época, se define que la Capitanía General de Chile o también llamado Reino de Chile limita al norte con el Virreinato del Perú.

Según la historiografía boliviana, peruana y argentina la Audiencia de Charcas formaba parte de los virreinatos antes citados y se llamaba efectivamente Alto Perú. Estos tres países que basan sus posturas según en el "Uti possidetis iure" de 1810 y por ende, las previas a la independencia, coinciden en que el límite norte de la Capitanía General de Chile —que era una dependencia directa del virreinato peruano hasta su autonomía económica desde 1733 al 15 de mayo de 1798, año que lograría la definitiva separación administrativa— se ubicaba en el río Salado (al sur del desierto de Atacama), separándolo conjuntamente con la cordillera andina del nuevo virreinato rioplatense desde 1776. Pero por Real Orden del 1º de octubre de 1803, el litoral del Pacífico desde el río Loa hasta el Paposo (pequeño caserío indígena), pasaría a la jurisdicción peruana. Tras la independencia de las colonias americanas a inicios del siglo XIX, el general Simón Bolívar reconoció esta zona con el nombre de Departamento del Litoral en la República de Bolivia.

En Bolivia durante el gobierno de Andrés de Santa Cruz, en 1837, se creó el Departamento del Litoral, el cual se dividía en dos provincias: La Mar (con capital en Cobija) y Atacama (con capital en San Pedro de Atacama) y en 1868, Antofagasta sería la capital de la provincia de Mejillones.
Un tratado de límites en 1866 zanjó la situación, aceptando la soberanía boliviana al norte del paralelo 24º Sur y permitiendo la explotación de recursos por parte de capitales chilenos al sur del paralelo 23º.

Exploradores chilenos como Juan López y José Santos Ossa habían descubierto ricos yacimientos de guano y salitre, lo que llevó a una masiva inmigración en la costa boliviana, naciendo el puerto de Antofagasta. Pronto creció la tensión entre los empresarios mineros y las autoridades bolivianas, hasta el estallido de la Guerra del Pacífico. Chile invadió Antofagasta el 14 de febrero de 1879, anexando la zona en cuestión hasta la Batalla de Topáter (23 de marzo de 1879).

Con el tratado de 1904 Antofagasta fue chilena. La llegada de chilenos se acrecentó, en especial de aquellos provenientes de las provincias del Norte Chico (las actuales regiones de Atacama y Coquimbo), hacia las nuevas provincias de Antofagasta y Tarapacá, el llamado Norte Grande. Nuevos pobladores llegaron también desde Europa (en especial españoles, croatas, ingleses y griegos) y desde China y los países árabes. Estos nuevos elementos junto a la cultura propia del altiplano creó la moderna cultura del Norte Grande, que presenta más elementos andinos y europeos que la propia del Valle Central. La Región de Antofagasta dependió, hasta la crisis de 1929, de la explotación y exportación de salitre. Cientos de oficinas salitreras nacieron en medio del desierto, y fueron abandonadas con posterioridad. La explotación de nitratos fue, posteriormente reemplazada por la explotación cuprífera. Capitales estadounidenses se establecieron en el interior y administraron la minería del cobre, hasta la Nacionalización, realizada por el gobierno de Salvador Allende.

La Región de Antofagasta, para efectos del gobierno y administración interior, se divide en 3 provincias:

Para los efectos de la administración local, las provincias están divididas en nueve comunas.

La Región de Antofagasta, a efectos electorales, corresponde a la circunscripción senatorial II y al distrito 3.

El gobierno de la región reside en el Intendente, designado por el Presidente de la República. Actualmente, el cargo es ejercido por Edgar Blanco Rand (RN). El gobierno y administración de las provincias corresponde a tres gobernadores, nombrados también por el presidente de la República.

La administración de la región radica en el Gobierno Regional, constituido por el Intendente y por el Consejo Regional, compuesto de 16 consejeros regionales electos por voto directo, donde 8 cupos corresponden para Antofagasta, 5 para El Loa; y 3 para Tocopilla. Para el periodo 2014-2018 el CORE está integrado por:




La administración local de cada comuna reside en la respectiva Municipalidad.

La Región de Antofagasta es representada en el Senado por Alejandro Guillier (Ind. PRSD) y Pedro Araya Guerrero (Ind. PDC), desde marzo de 2014. Para la Cámara de Diputados, la región constituye un único distrito que elige a cinco diputados. Desde 2018, los diputados por el Tercer Distrito son:

Históricamente la región ha sido una zona de tradicional tendencia izquierdista atendida por su condición minera, especialmente en la población proveniente de las oficinas salitreras. En el Plebiscito de 1988 el "NO" logró su total porcentual más alto del país (60,7%). En la elección de 2005, Michelle Bachelet superó a su opositor Sebastián Piñera por un 61,3% contra 38,7%. Pero la brecha disminuyó en 2010, ya que en el balotaje de la elección presidencial, Piñera fue derrotado por Eduardo Frei por 47,8 % contra 52,2%. Durante los últimos años, el voto en la región ha ido virando hacia la derecha, lo cual ha sido demostrado en el resultado de las elecciones municipales del 2016 donde Chile Vamos obtuvo 5 de las 9 alcaldías de la región, y para las elecciones presidenciales del 2017 , el candidato Sebastián Piñera derrotó con un 53,82% contra 46,18% al senador Alejandro Guillier, quien además es representante de la región en el Senado.

L ocupa un rango latitudinal que va desde los 20º56’ a los 26º05’ de latitud sur, y longitudinalmente, desde los 67º00’ de longitud oeste hasta el océano Pacífico. El trópico de Capricornio atraviesa la región a la altura del Aeropuerto Nacional Andrés Sabella Gálvez, unos kilómetros al norte de Antofagasta.

El relieve de la Segunda Región comparte muchas similitudes con las de su vecina del norte, Tarapacá. Las planicies litorales son más amplias y se extienden especialmente en la zona de la Península de Mejillones, posteriormente se ven interrumpidas por las altas serranías de la Cordillera de la Costa. En esta zona alcanza alturas superiores a los 2000 metros y se ubica el Cerro Vicuña Mackenna (3114 msnm), el de mayor altura de toda la cordillera, y el Cerro Paranal, donde fue instalado uno de los mayores telescopios del mundo, el Observatorio Paranal que es administrado por el Observatorio Europeo Austral (ESO).

Su hidrografía presenta un fuerte contraste entre la escasez de escurrimientos debido al predominio del clima árido, y la existencia del río Loa, el más largo de Chile y el que posee la mayor extensión. Este nace en la cordillera de los Andes y logra desembocar en el mar. Sus aguas son intensamente aprovechadas para el regadío, minería y agua potable. Por la naturaleza desértica de la región, existen numerosas cuencas cerradas o endorreicas, sobresaliendo la del Salar de Atacama, hacia donde drena el río San Pedro, el que da origen al oasis de San Pedro de Atacama.
La Depresión Intermedia es amplia y da paso al Desierto de Atacama. Hacia el sureste, esta se ve reducida en tamaño, debido a la formación de un brazo occidental de la Cordillera de los Andes, conocida como Cordillera de Domeyko, que alcanza los 4.114 metros en el Cerro Quimal. Entre la cordillera de Domeyko y la de los Andes se forma el altiplano donde se destacan la formación de la Cordillera de la Sal, una pequeña rama de la cordillera de Domeyko, el Salar de Atacama y el nacimiento del río Loa, el único que cruza las áridas llanuras atacameñas y que tiene una longitud de 440 kilómetros, siendo el más largo de Chile. Al este, se ubica la Cordillera Andina propiamente tal, altamente volcánica. Destacan los volcanes Ollagüe (5865 msnm), el Linzor (5555 msnm) y el Licancabur (5916 msnm), entre otros. La alta actividad geotérmica permite la formación de los géiseres del Tatio. En el extremo oriental de la región se forma la Puna de Atacama, otra zona de altiplano ubicada en el límite con Bolivia y Argentina.

El clima es desértico en el interior con una gran oscilación térmica, la que se acentúa a mayor altitud. En tanto, en el litoral, el clima es templado gracias a la influencia de la Corriente de Humboldt. Debido a la existencia del farellón costero, se produce la "camanchaca", una espesa niebla que permite la irrigación del desierto gracias al uso de atrapanieblas.

Su principal actividad económica es, sin lugar a dudas, la minería, que produce más del 65% del Producto Interno Regional. La extracción del Cobre ha aumentado explosivamente desde la creación de Codelco, pasando de 430 000 toneladas extraídas en 1974 a cerca de 3 millones en la actualidad. Las principales minas del país existen en la zona, destacándose los yacimientos estatales de "Chuquicamata" (la mina a tajo abierto más grande del mundo) y "Radomiro Tomic", y las privadas "La Exótica" y "La Escondida". También se extraen otros minerales como plata, molibdeno, oro, litio, salitre, hierro, yodo, carbonato de calcio y cuarzo, debido a la abundante riqueza mineral de sus suelos.

La industria pesquera ha contribuido enormemente al desarrollo económico de la región, especialmente en la producción de harina y aceite de pescado, situándose las principales plantas en las ciudades de Mejillones Y Tocopilla. Pese a la ubicación estratégica de las plantas pesqueras, estos últimos años se han visto decaídas por la sobreexplotación en la cuota de captura del pescado, llevando incluso al desmantelamiento de importantes plantas de procesamiento como fueron las pesqueras Loa y Guanaye, en la ciudad de Mejillones.

La producción agrícola en la región es casi nula y se concentra mayoritariamente en las zonas del altiplano, generalmente destinadas al consumo local, al igual que la ganadería.

El turismo ha experimentado un aumento considerable en los últimos años, especialmente debido a que San Pedro de Atacama y sus alrededores se convirtieran en lugares reconocidos internacionalmente por sus bellos parajes naturales.

Por otra parte, estas últimas décadas se han caracterizado por la alta tasa de industrialización en la región, principalmente en el ámbito energético, todo lo cual ha hecho que la Región de Antofagasta cuente con importantes centrales termoeléctricas, en funcionamiento y también en construcción, destinadas principalmente a abastecer de energía eléctrica a todo el sector minero, y que forman parte del Sistema Interconectado del Norte Grande.

En 2018, la cantidad de empresas registradas en la región de Antofagasta fue de 14.340. El Índice de Complejidad Económica (ECI) en el mismo año fue de -0,19, mientras que las actividades económicas con mayor índice de Ventaja Comparativa Revelada (RCA) fueron Reparación de Maquinaria para Industria Textil, de la Confección, del Cuero y del Calzado (42,62), Fabricación de Cojinetes, Engranajes, Trenes de Engranajes y Piezas de Transmisión (31,92) y Agencias de Noticias (27,19).

Esta región tiene el ingreso por PIB per cápita más alto de Chile.

Antofagasta es la Región de Chile con más centrales termoeléctricas, con un total de 20. También cuenta con energías renovables como parques eólicos en Calama y Taltal.

La población actual de esta región proviene en su gran mayoría de la inmigración nacional proveniente del Norte Chico y la Zona Central.

La Segunda Región, de acuerdo al último censo (2017), está poblada por un total de 607.534 habitantes. La densidad poblacional alcanza los 4,8 habitantes por kilómetro cuadrado.

De la población regional total, 315 014 habitantes son hombres (51,9%) y 292 520 son mujeres (48,1%). La población regional se concentra principalmente en las comunas de Antofagasta (361 873 habitantes), Calama (165 731) y Tocopilla (25 186 habitantes). Chuquicamata, la antigua ciudad habitada por los obreros de la mina homónima, y que llegó a ser habitada por decenas de miles de personas, actualmente, trasladada hacia la vecina Calama, debido a que, en un futuro cercano, los residuos de la mina terminará por tapar a la ciudad.

Otras localidades importantes son: Mejillones (13 467 hab.); Taltal (13 137 hab.); San Pedro de Atacama (10 996 hab.); María Elena (6457 hab.)

Actualmente en la región residen más de 104.817 inmigrantes, principalmente bolivianos, colombianos y peruanos, los cuales conforman el 17,3% del total de la población regional . 

A continuación se presenta la serie histórica de indicadores básicos de la Región de Antofagasta:



 universidad de chile

</doc>
<doc id="42781" url="https://es.wikipedia.org/wiki?curid=42781" title="Período Cuaternario">
Período Cuaternario

El período Cuaternario es una división de la escala temporal geológica que pertenece a la Era Cenozoica; dentro de esta, el Cuaternario sigue al Neógeno. Se inició hace 2,59 millones de años y llega hasta la actualidad. Hasta el año 2009, se consideraba que el Cuaternario comenzaba hace 1,81 millones de años, pero la Comisión Internacional de Estratigrafía le añadió la edad y piso Gelasiense, adelantando por tanto su comienzo. El Cuaternario se destina a cubrir el período reciente de ciclos de glaciaciones y, puesto que algunos episodios de enfriamiento y glaciación caen en el Gelasiano, esto justifica su traslado al Cuaternario.

Fue durante el Cuaternario cuando apareció el "Homo sapiens" sobre la Tierra. A su vez, se extinguieron grandes especies, tanto vegetales como animales, y fueron las aves y mamíferos los vertebrados que dominaron la Tierra. En síntesis, hubo un gran predominio de los mamíferos, una gran expansión del ser humano, y la presencia de una flora y una fauna muy parecida a la actual, por lo que también se han apuntado las migraciones de grandes mamíferos o el origen del hombre como posibles criterios. Por eso, a veces es denominada etapa Antropozoica.

El término Cuaternario fue propuesto por el geólogo italiano Giovanni Arduino en 1759 para datar los depósitos aluviales localizados en el valle del río Po, en el norte de Italia, ya que proponía que los estratos geológicos de esta región podían ser divididos en cuatro formaciones sucesivas. Posteriormente fue introducido en la geología francesa por Jules Desnoyers en 1829, que lo aplicó a los sedimentos de la cuenca del Sena, Francia, que parecían ser claramente más jóvenes que las rocas del período Terciario. Ocasionalmente se ha usado el término Neozoico (del griego νέος, "neos", ‘nuevo’ y ζωϊκός, "zoico", ‘animal’), hoy en desuso.

El período Cuaternario sigue al Neógeno y se extiende hasta el presente: cubre el lapso de tiempo de las glaciaciones clasificadas como Pleistoceno, e incluye el actual período interglacial, el Holoceno. Esto sitúa el comienzo del Cuaternario en el inicio de la glaciación del hemisferio norte, hace aproximadamente 2,6 millones de años. Antes de 2009, el Pleistoceno se definía como desde hace hasta el presente, por lo que la definición actual del Pleistoceno incluía una parte de lo que, antes de 2009, se definía como Plioceno.
Los estratígrafos del Cuaternario generalmente trabajaban con subdivisiones regionales. Desde la década de 1970, la Comisión Internacional de Estratigrafía ("International Commission on Stratigraphy", ICS) intentó hacer una única escala de tiempo geológico basada en los GSSP ("Global Boundary Stratotype Section and Point" o sección estratotipo y punto de límite global), que pudieran ser utilizadas a nivel internacional. Las subdivisiones del Cuaternario se definieron sobre la base de la bioestratigrafía en lugar de la paleoclimatología. Esto condujo al problema de que la base de la propuesta del Pleistoceno era , mucho después del inicio de las glaciaciones importantes del hemisferio norte. El ICS entonces propuso abolir el uso del nombre Cuaternario, lo que pareció inaceptable a la Unión Internacional para el Estudio del Cuaternario ("International Union for Quaternary Research", INQUA). En 2009, se decidió formalizar el Cuaternario como el período más reciente de la Era Cenozoica con su base en , incluyendo la edad Gelasiano, anteriormente última parte de la época Plioceno del período Neógeno.

El Antropoceno se ha propuesto como una nueva división del Cuaternario, ya que señala el impacto antrópico sobre el medio ambiente global a partir de la revolución industrial, o hace unos 200 años. El Antropoceno no ha sido designado oficialmente por el ICS, sin embargo, una subcomisión tiene el objetivo de completar una propuesta para la creación de una época (la tercera del Cuaternario) o edad (una subdivisión del Holoceno) para el año 2016.

El Pleistoceno, la primera y más larga época del período, se caracterizó por los ciclos de glaciaciones. Se han sucedido numerosos períodos glaciares e interglaciares alternativamente en intervalos de entre 40 000 y 100 000 años, aproximadamente. En los períodos glaciares las masas de hielo avanzan sobre los continentes cubriendo hasta un 40% de la superficie de la tierra, mientras que en los más cortos períodos interglaciares el clima se hace más suave y los glaciares retroceden. 

El Holoceno, segunda época del Cuaternario que comenzó hace unos 12 000 años y continúa en la actualidad, es un período interglaciar en el que el deshielo hizo subir unos 120 metros el nivel del mar, inundando grandes superficies de tierra.

Durante el corto espacio de tiempo que abarca este período, la deriva continental fue inferior a 100 km, lo que es en gran medida irrelevante para la paleontología. No obstante, el registro geológico se conserva en mayor detalle que en los períodos anteriores y es fácilmente relacionable en los mapas actuales, revelando una serie de extraordinarios cambios en la geografía del planeta.
Durante todo el Pleistoceno, así como en el Plioceno, existió un casquete polar en la Antártida. Hay incertidumbre si la capa de hielo de Groenlandia se mantuvo durante todos los períodos interglaciares. Durante las glaciaciones, los glaciares continentales llegaron al paralelo 40 en algunas zonas. Los glaciares continentales cubrieron gran parte de Norteamérica, Europa y Siberia.
Durante el último máximo glaciar, hace 20 000 años, en Norteamérica el Manto Laurentino cubría completamente Canadá, Groenlandia y el norte de Estados Unidos. Alaska permaneció casi libre de hielos por las condiciones de sequedad. La superficie cubierta por los hielos en esta zona se estima en 13-16 millones de km, de hasta 4 km de espesor y conteniendo unos 30 millones de km, más que la Antártida en la actualidad. En Eurasia, el Manto Finoscandinavo cubría el Norte de Europa, incluyendo las Islas Británicas, Mar del Norte, Mar Báltico, Alemania, Polonia y Rusia hasta el Oeste de Siberia. El centro y este de Siberia probablemente estaban libres de hielos debido a la falta de humedad. La superficie cubierta por los hielos se estima en 6,7 millones de km de hasta km de espesor y un volumen de hielo de unos 7 millones de km, casi cuatro veces menos que en Norteamérica.

En el Hemisferio Sur, el manto de hielo de la Antártida puede que no fuera muy diferente del que existe en la actualidad. Fuera de estas zonas, las principales capas de hielo se formaron en los Alpes y en el Himalaya. Los Andes se cubrieron de una capa de hielo al sur de la Patagonia. Hubo glaciares en Nueva Zelanda y Tasmania. En África oriental y central, los glaciares del Monte Kenia, Kilimanjaro y Ruwenzori eran mayores. Había glaciares en las montañas de Etiopía y al oeste del Atlas. Se estima que, en el máximo glaciar, el 30% de la superficie terrestre estaba cubierta por el hielo, unos 44,4 millones de km, frente al 10% de la actualidad, unos 14,9 millones de km. Además, una capa de permafrost se extendía hacia el sur desde el borde de la hoja glaciar, unos pocos cientos de kilómetros en Norteamérica y varios cientos en Eurasia. La temperatura media anual en el borde del glaciar sería de -6 °C y en el borde del permafrost, 0 °C. 

Los principales efectos de las glaciaciones fueron la erosión y deposición de materiales sobre grandes zonas de los continentes, la modificación de los sistemas fluviales, la creación de millones de lagos, los cambios en el nivel del mar, el desarrollo de lagos pluviales lejos de los márgenes del hielo, los ajustes isostáticos de la corteza y anomalías en los vientos. Cada avance de los glaciares retendría enormes volúmenes de agua en las capas de hielo continental de 1,5-3 km de espesor, lo que bajaría el nivel del mar 100 m o más sobre la totalidad de la superficie de la Tierra. Durante los períodos interglaciares, como el que estamos viviendo en la actualidad, la línea de costa retrocedió, mitigada por la reacción isostática u otros movimientos emergentes en algunas regiones.

Entre estos cambios se incluye el emergido periódico del Canal de la Mancha, formando un puente terrestre entre Gran Bretaña y el continente europeo; el cierre periódico del Estrecho de Bering, formando un puente terrestre entre Asia y Norteamérica; la unión al Continente Asiático de las Islas de Indonesia, Nueva Guinea, Japón y Taiwán; y la unión a Australia de Nueva Zelanda y Tasmania. Durante las glaciaciones, al bajar el nivel del mar, el Mar Negro y Mar Báltico se convertían en lagos de agua dulce, mientras que al subir el nivel del mar los estrechos del Bósforo y Skagerrak se abrían y los llenaban de agua salada. Otros cambios fueron las inundaciones repentinas periódicas de las Scablands en el Estado de Washington por la fusión de los glaciares. Los Grandes Lagos y otros grandes lagos de Canadá y la Bahía de Hudson, también son sólo los resultados del último ciclo y son temporales. 

En los sucesivos períodos glaciar e interglaciares hubo diferentes patrones en la distribución de los lagos y bahías. Los depósitos continentales y costeros junto a los fondos marinos nos permiten un conocimiento de los fenómenos que ocurrieron, como el desarrollo de las formaciones morrénicas, fluvioglaciares, lacustres y eólicas (loess) o la formación de los últimos relieves alpinos.

Hasta hace poco se creía que durante el Período Cuaternario las fluctuaciones en el volumen total de hielo sobre la tierra, el nivel del mar y la temperatura global se habían producido en ciclos de, inicialmente, 41 000 años y, más recientemente, de 100 000 años. Para ello se basaban en los núcleos de hielo extraídos correspondientes a los últimos 800 000 años y en los núcleos de sedimentos marinos para los períodos anteriores. Se calculaba que había habido unos 80 ciclos de glaciaciones. 

Así, se suponía que en el último millón de años se habían producido cuatro glaciaciones principales, con sus consiguientes interperíodos, denominándose (según la escuela clásica que toma como referencia Europa central con nombre de a los ríos, afluentes del Danubio, donde se determinaron las primeras observaciones): Glaciación de Günz (comienza hace 1,1 millones de años), Glaciación de Mindel (580 000 años), Glaciación de Riss (200 000 años) y Glaciación de Würm (80 000 años). Dos episodios anteriores de glaciación fueron denominados Biber (2,5 millones de años) y Donau (1,8 millones de años).

Se había asentado la idea de que actualmente, al finalizar la glaciación de Würm o Wisconsin, la tierra estaba en un período interglaciar, que marcó el comienzo de la época del Holoceno. Este habría comenzado hace unos 12 000 años, causando que la capas de hielo del último período glaciar comenzaran a desaparecer. Los remanentes de esta capa de hielo, que todavía existen en Groenlandia y la Antártida, ocupan ahora aproximadamente el 10% de la superficie terrestre. Se considera que el ciclo de glaciaciones todavía continúa y algunos investigadores creen que el próximo período glaciar podría ocurrir dentro de 50 000 años.

Pero hoy en día la definición misma de las glaciaciones en el sentido clásico (largos y estables episodios fríos seguidos de otros más cálidos) está siendo muy cuestionada. Actualmente se da por seguro que lo que hubo fueron una serie de estadios isotópicos muy numerosos y de corta duración, a los que se refieren los científicos con numeraciones pares para las fases frías e impares para las templadas. A pesar de lo cual sigue manteniéndose la terminología relacionada con las glaciaciones como referencia a la hora de fechar los acontecimientos del Cuaternario y su correspondiente Paleolítico.

Durante los máximos glaciares la temperatura en las aguas oceánicas superficiales era 4-5 °C inferior a la actual (actualmente es de ∼18 °C para las aguas subtropicales y ∼14 °C para las subpolares), al igual que en los trópicos. Durante los máximos interglaciares la temperatura pudo ser superior en 1-2 °C a la actual.

La presencia de hielo en gran parte de los continentes modificó en gran medida las pautas de circulación atmosférica. Los vientos cerca de los márgenes glaciales eran fuertes y persistentes debido a la abundancia de aire denso y frío procedente del glaciar. Estos vientos recogían y transportaban grandes cantidades de sedimentos de grano fino erosionado por los glaciares. Este polvo se acumuló como loess, formando depósitos irregulares en gran parte del valle del Río Missouri, Europa central y norte de China.

Las dunas de arena fueron mucho más amplias y activas en muchas áreas durante el período Cuaternario temprano. Un buen ejemplo es la región de las colinas de arena en Nebraska, que cubre un área de unos 60 000 km. Esta región fue una gran campo de dunas activas durante la época del Pleistoceno, pero hoy en gran parte se ha estabilizado por una cobertura de pastos.

El clima del Pleistoceno podría estar caracterizado por el fenómeno continuo de El Niño con vientos alisios en el Pacífico Sur, debilitándose o calentándose al este, aire caliente cerca de Perú, corrientes oceánicas cálidas desde el oeste del Pacífico y Océano Índico al este del Pacífico, y otros marcadores de El Niño.

Durante los períodos glaciares las lluvias fueron menos abundantes debido a la disminución de la evaporación del agua de los océanos. Por otro lado, debido a esta sequedad del clima, los desiertos serían más extensos y más secos.

Los severos cambios climáticos durante los ciclos de glaciaciones tuvieron importantes impactos sobre la fauna y la flora. Con cada avance del hielo, grandes extensiones de los continentes se despoblaron completamente, con plantas y animales retirándose hacia el sur, empujados por el avance del frente glaciar. Se produjo un fuerte estrés provocado por los drásticos cambios climáticos, la disminución del espacio vital y la reducción del suministro de alimentos. Respecto a la flora, los fósiles que han quedado ofrecen una curiosa similitud con la actual. Donde existieron más cambios fue en la fauna. A finales del Pleistoceno se produjo un gran evento de extinción de grandes mamíferos (megafauna): todos los continentes, a excepción de África y Asia perdieron la fauna de más de una tonelada de peso. La acción humana también pudo desempeñar un papel, además de los cambios climáticos. Desaparecieron especies tales como los mamuts, mastodontes, el oso de las cavernas, megaterio, gliptodonte, "Smilodon" o el megacero. Los Neandertales también desaparecieron durante este período.

Las extinciones continuaron en el Holoceno, esta vez atribuibles sin ninguna duda a la acción humana. La tasa observada de extinción se ha acelerado de manera espectacular en los últimos 50 años. Al evento de extinción del Holoceno a veces se le denomina la sexta extinción, pues en el pasado hubo otros cinco grandes eventos de extinción. En la siguiente tabla se muestra el número de géneros terrestres de más de 44 kg de peso en los últimos 100 000 años. En Australia, ocho géneros probablemente estaban ya extintos antes de la llegada de los seres humanos.
Los últimos australopitecinos (que abarcan el intervalo de 4 a 1,1 millones de años antes del presente) vivieron durante la primera mitad del Pleistoceno. Estos ya se desplazaban de manera bípeda, aunque el tamaño de su cerebro era similar al de los grandes simios actuales. El género "Homo" apareció al comienzo del Pleistoceno hace 2,4 millones de años. El "Homo habilis", la especie más antigua de este género, vivió aproximadamente de 2,5 a 1,44 millones de años atrás. El tamaño del cerebro era mayor y probablemente era capaz de la fabricación de primitivos utensilios de piedra. El "Homo erectus" vivió entre 1,8 millones y 300 000 años antes del presente. Probablemente conocía el uso del fuego y fue el primer humano que salió de África, habitó en Europa, China y alcanzó Indonesia. El "Homo neanderthalensis" (hombre de Neandertal) habitó Europa y Asia occidental desde 250 000 hasta 29 000 años atrás. Fue una especie bien adaptada al frío extremo y vivía en grupos organizados, de alrededor de treinta miembros. El "Homo sapiens" apareció en África hace unos 250 000 años y en sucesivas migraciones, aprovechando los puentes terrestres como consecuencia del bajo nivel del mar, se extendió por todos los continentes, a excepción de la Antártida, reemplazando a los neandertales en Europa.




</doc>
<doc id="42784" url="https://es.wikipedia.org/wiki?curid=42784" title="Bética">
Bética

La Bética (en latín, "Bætica") fue una de las provincias romanas que existieron en la península ibérica, llamada por los romanos Hispania. Tomó su nombre del río Betis (en latín "Bætis"), llamado en la actualidad río Guadalquivir; su capital en la época romana fue la "Colonia Patricia Corduba", la actual ciudad española de Córdoba, en Andalucía. Posteriormente, en el periodo visigodo, la capital pasó a ser "Hispalis", la actual ciudad de Sevilla.

La Bética tuvo una importante aportación al conjunto del Imperio romano, tanto económica como cultural y política. En el terreno económico fue muy significativa la extracción de minerales (oro, plata, cobre y plomo) y la agricultura, con la producción y exportación sobre todo de cereales, aceite y vino, estos dos últimos especialmente famosos en todo el Imperio junto con el "garum". En el terreno político, la Bética fue durante mucho tiempo una provincia senatorial que, debido a su alto grado de romanización, dependía del poder político del Senado, no del poder militar del emperador. En ella se libró la decisiva Batalla de Munda entre populares y optimates, partidarios de César y Pompeyo, respectivamente. Además, dio a Roma los emperadores Trajano y Adriano, naturales de Itálica, y al filósofo cordobés Séneca, entre muchos otros.

La Bética comprendía más del 75% del territorio de la actual Andalucía y una parte de Extremadura: la mayor parte de las provincias completas de Cádiz, Córdoba, Huelva, Málaga y Sevilla, la mitad occidental de las de Granada y Jaén, una quinta parte de la de Almería y parte del sur de Badajoz.

Fue dividida en cuatro "conventus iuridici": el "Conventus Cordubensis", con capital en "Córduba" que además era la capital de toda la provincia Bética; el "Conventus Astigitanus", con capital en "Astigi"; el "Conventus Gaditanus", con capital en "Gades" y el "Conventus Hispalensis" con capital en "Hispalis". Estos territorios eran partidos judiciales, en los que los principales de la comunidad se reunían anualmente bajo la dirección de un "legatus iuridicus" del procónsul para supervisar la administración de justicia.

Hacia los años 13-7 a. C. se modificaron los límites orientales de la Bética. Los distritos de "Cástulo", "Acci" y el territorio al este y norte de la actual provincia de Almería, que pertenecieron originalmente a la provincia Bética, fueron segregados por Augusto e incorporados a la provincia Tarraconense. Como la Bética era una provincia senatorial, este hecho se interpreta como un acto del emperador en pos de controlar directamente las minas de esa zona, ya que la Tarraconense era una provincia que dependía directamente del poder imperial, no del Senado.

El territorio se articulaba a través de una red de calzadas dispuestas con base en tres grandes ejes de paso naturales: La depresión Bética, el surco Intrabético y la costa. En torno a estos ejes se disponían importantes núcleos de población como "Córduba, Gades, Hispalis, Iliberris, Malaca y Ostippo", entre otros, que monopolizaban la recaudación de impuestos, el comercio y la explotación del "ager", además de ser grandes focos de penetración de la cultura romana y de su distribución por sus áreas de influencia rural. El carácter divisorio de grandes ríos como el Guadiana y el Guadalquivir, la importancia de los grandes distritos mineros como Almadén, la frontera natural que supone Sierra Morena, la importancia de grandes núcleos poblacionales y la facilidad de comunicación por el mar, son elementos que hacían de frontera y que a la vez configuraban un espacio territorial con distintas realidades pero con cierta cohesión.

Cuando Diocleciano realizó una nueva división provincial en el 298 conocida como Diocesis Hispaniarum mantuvo los límites de la Bética.

Tras la derrota de Cartago en la Segunda guerra púnica, los cartagineses abandonaron Hispania y su presencia fue sustituida por la de los romanos, quienes tuvieron que hacer frente a algunos focos de resistencia, como la sublevación de los turdetanos en el 197 a. C. Como consecuencia de la victoria romana, se crearon las provincias de Hispania Ulterior e Hispania Citerior. El año 27 a. C., con la reorganización imperial de Augusto, Hispania quedó dividida en tres provincias imperiales: la Bética, la Tarraconense y la Lusitania. La Bética fue desde entonces una provincia senatorial gobernada por un procónsul con capital en Córdoba.

La Bética era una de las provincias del imperio más dinámicas y desarrolladas económicamente, al ser rica en recursos y al estar profundamente romanizada, absorbiendo poblaciones de esclavos liberados y a una élite pudiente que permaneció como grupo social estable durante siglos, aunque no estuvo exenta de trastornos sociales, como los acontecidos en época de Septimio Severo, quien condenó a muerte a un gran número de béticos, incluyendo mujeres. La profunda romanización de la provincia se vio recompensada con la concesión por parte del emperador Vespasiano de los derechos de ciudadanía romana ("latinitas"), cuando promulgó el "ius latii minor" por medio del Edicto de Latinidad, que concedió no solo a los béticos, sino a todos los ciudadanos hispanos.

La asimilación de la cultura romana también propició una temprana cristianización, que arraigó fuertemente en las zonas costeras y que fue marcando un nuevo desarrollo cultural en toda la península ibérica. En el siglo IV el cristianismo pasó a ser tolerado en el Imperio y más adelante sería proclamada religión oficial y única permitida, celebrándose en tierras béticas el Concilio de Elvira, hito fundamental en la Historia del Cristianismo en España, al que asistieron once obispos béticos, de un total de diecinueve asistentes.

La Bética fue romana hasta que en el 411, tras la invadir el Imperio occidental, los suevos, vándalos y alanos se establecieron en la península ibérica. Los vándalos silingos (dirigidos por Fridibaldo), más poderosos que sus hermanos asdingos, recibieron la fértil provincia de la Bética, donde permanecieron hasta que fueron expulsados por los visigodos y los supervivientes se unieron a los asdingos con los que invadieron la diócesis de África. No es posible especificar en qué zonas de Andalucía se asentaron, debido a su corta permanencia y a la falta de hallazgos arqueológicos.

Con la irrupción de los visigodos en el escenario político de la península ibérica el 418, los vándalos fueron expulsados. La fuerte romanización y la fortaleza de una oligarquía territorial de la provincia, capaz de tener auténticos ejércitos propios, hizo de la Bética un territorio difícil de conquistar. Fue el último territorio controlado "de facto" por los visigodos, y el que mayor inestabilidad política presentaba. Muestra de ello es que en el año 521 el pontífice nombró vicario de la Lusitania y la Bética al obispo metropolitano de Sevilla (Salustio), dando a entender que la jurisdicción eclesiástica de Tarragona no controlaba los territorios del sur peninsular.

A partir del año 531 el rey visigodo Teudis llevó a cabo una rápida expansión hacia el sur, llegando a instalar su corte en Sevilla, para tener un mejor control de sus operaciones en el sur peninsular. Incluso llegó a dirigir una ofensiva, fracasada, contra el poder bizantino establecido en "Settem" (Ceuta). Finalmente la Bética quedó definitivamente integrada en el Reino visigodo de Toledo, si bien cuando los intereses de la oligarquía terrateniente hispanorromana peligraban, se producían rebeliones, como las de Atanagildo y Hermenegildo.

La rebelión de Atanagildo, con apoyo de la oligarquía de la Bética, supuso la entrada en acción del poder bizantino, en expansión bajo Justiniano I. Una parte importante de la Bética y la Cartaginense, dada su importancia para el comercio en el Mediterráneo, fue conquistada e incorporada por dicho emperador bajo el nombre de Provincia de Spania, que estableció su capital en la mediterránea "Malaca". Para ello, Justiniano debió contar con el apoyo fundamental de la población y élite vernácula, fuertemente romanizada, que estaba en contra de los visigodos y deseaba la vuelta al orden romano y católico. Sin embargo, la presencia bizantina en la Bética fue fugaz, ya que el Reino visigodo de Toledo siempre quiso recuperar el litoral perdido. Las campañas, primero de Leovigildo y luego de Suintila, hicieron que se creara un poder unificado en la península ibérica.

Los obispos católicos de la Bética, sólidamente apoyados por la población local, consiguieron convertir al rey visigodo arriano Recaredo y sus nobles. Durante el periodo visigodo, en lo religioso y cultural San Leandro y San Isidoro fueron personalidades fundamentales, que desempeñaron su labor principalmente en Sevilla.

La batalla del Guadalete, librada el 711 en tierras béticas por Rodrigo, rey visigodo que antes había sido duque de la Bética, fue la lucha definitiva en la pérdida de Hispania por parte del poder godo. Los musulmanes bereberes del norte de África junto a élites árabes conquistaron la Bética y la mayor parte del resto de Hispania, estableciendo primero el Emirato y posteriormente el Califato de Córdoba, cuya capital se estableció en Córdoba, la misma ciudad que lo era de la Bética, provincia que a partir de entonces dejó de existir como tal, aunque siguió siendo el centro neurálgico de al-Ándalus.

La agricultura del sur de la península ibérica era especialmente rica, exportando vinos, aceite de oliva y también una salsa de pescado fermentada llamada "garum", muy apreciada en la dieta romana. Las vastas plantaciones de olivos de la Bética proporcionaban aceite de oliva que era transportado por mar y suministrado, entre otros, a las legiones romanas en Germania. Las ánforas de la Bética han sido halladas a lo largo y ancho del Imperio romano de Occidente. Para conservar el control de estas rutas marítimas el Imperio necesitaba controlar las distantes costas de Lusitania y la costa del Atlántico al norte de Hispania. Columela, quien escribió veinte volúmenes que tratan todos los aspectos de la agricultura romana y la viticultura, procedía de la Bética.






</doc>
<doc id="42789" url="https://es.wikipedia.org/wiki?curid=42789" title="Guadalete">
Guadalete

El río Guadalete es un río del sur de España, perteneciente a la vertiente atlántica de Andalucía. Nace al norte de la sierra de Grazalema (en el peñón Grande) y desemboca en El Puerto de Santa María, en la bahía de Cádiz. Transcurre principalmente por la provincia de Cádiz y en parte por la de Sevilla. El río Guadalete, sus afluentes y su cuenca abastecen de agua de riego a una extensa vega y es también la fuente de agua potable de aproximadamente un millón de personas. Sus dos afluentes más importantes son el Río Guadalporcún, que drena el norte de la cuenca y el Río Majaceite que lleva las aguas de la cuenca meridional.

Hasta mediados del siglo XX era navegable para pequeñas embarcaciones hasta Jerez de la Frontera. Hoy en día su desembocadura es el puerto fluvial de El Puerto de Santa María. En época romana se realizó la modificación de la desembocadura del río para que discurriera hacia el "Portus Gaditanus", actual El Puerto de Santa María, quedando el cauce anterior abandonado (río San Pedro). Es uno de los ríos «anguleros» de Andalucía. Es responsable del aporte de sedimentos que han creado las costas de la Bahía de Cádiz y es también responsable de su continuo proceso de colmatación.

Parte del río está protegido como Lugar de importancia comunitaria (LIC)

Se sabe que la cuenca del Guadalete fue poblada desde la prehistoria, de hecho, el yacimiento arqueológico y paleontológico de El Palmar del Conde junto a la barriada El Portal contiene evidencias de la presencia de grandes mamíferos prehistóricos, entre ellos hipopótamos y además pobladores que les daban caza.

Existen restos que evidencian un uso intensivo del río en época romana. Destaca una estructura hidráulica de grandes dimensiones en pedanía jerezana de La Corta, incluyendo un molino romano único en Hispania.

Su nombre parece derivar de Lete (el río del olvido en la mitología griega), por una batalla entre fenicios asentados en la actual Cádiz y sus vecinos griegos asentados en la desembocadura de este río, el puerto "Menesteo" hoy conocido como El Puerto de Santa María. Esta batalla debía tener lugar en las inmediaciones del que por aquel entonces se denominaba río Criso (derivado de "Chyses", nombre dado a Gerión). Como no llegó a haber ningún enfrentamiento gracias a la diplomacia, se celebró una ceremonia de reconciliación y olvido de las pasadas ofensas. Y el río llegó a ser conocido como el río del olvido. Aún dicen que en su ribera se erigió una columna para perpetua memoria (actualmente desaparecida). No obstante, otras fuentes apuntan a la cercana ciudad de Lakka en la Junta de los Ríos (o un lago "Lacca") como origen del nombre (Wadi Lakka).

Posteriormente fue un enclave de importancia para el imperio romano ya en tiempos de Al-Ándalus se denominó "Guadaletho" ("Guada" es río en árabe), para ir derivando hasta la actualidad en Guadalete.

En sus inmediaciones se encontró un casco corintio de bronce del siglo VII a. C. que, aunque encontrado fuera de contexto y por lo tanto, con una interpretación arqueológica difícil, parece ser uno de los objetos griegos más antiguos hallados en la península ibérica.

De manera natural desembocaba en el actual Parque natural de la Bahía de Cádiz. En época imperial romana se construyó el nuevo canal de desembocadura del Guadalete, promovido por el Patricio Gaditano Lucio Cornelio Balbo el Menor, hacia el año 19 a. C.. Coincidiendo con la construcción del "Portus Gaditanus", actual ciudad de El Puerto de Santa María en el lugar donde la Via Augusta cruzaba el río.
. El 'Canal de Balbo' parece que tenía un ancho de medio estadio, por un largo de 5 estadios. Desde el antiguo puente de San Alejandro a la Antigua Pescaderia, donde salía a la playa en línea recta con el emplazamiento de la ciudad de Gades.

El río da nombre a la batalla de Guadalete, acaecida entre el 19 y el 26 de julio de 711 en una localización cercana aún desconocida y en la que los partidarios del rey don Rodrigo fueron derrotados por las fuerzas del Califato Omeya comandadas por Táriq Ibn Ziyad, en el inicio de la conquista musulmana de la península ibérica. Tras esta batalla se puso fin al reino visigodo y comenzó el período andalusí. En esta batalla murió el rey visigodo don Rodrigo. Según diversos autores, existen evidencias de que se produjera en los Llanos de Caulina.

Es famoso su puente de La Cartuja en Jerez, que ya existía en el año 1541 y que se está tramitando su declaración como Bien de Interés Cultural.. Otro puente de valor artístico era el conocido como "Puente romano de Zahara de la Sierra", que fue desmontado al crear el Embalse de Zahara con la incumplida promesa de reconstruirlo, y que algunas fuentes apuntan a un origen romano

Del siglo XVI es también un proyecto de conectar el río con el núcleo urbano de Jerez y construir un puerto, nunca realizado

En el siglo XVIII se realizaron modificaciones en el curso del río que se pueden corroborar en el mapa de Tomás López

En la Edad Moderna hubo diversos planes de modificación del río, aunque pocos llegaron a realizarse. Entre otras obras de ingeniería posteriores, destaca el acueducto de Tempul, en La Barca y la nunca utilizada central de Tablellina En 1845 Pascual Madoz describió el río en su Diccionario Geográfico de España, comentando la cantidad de peces de agua dulce y salada que se podían pescar en las riberas de Jerez. Esto era debido a la ausencia de azudes o presas.

A principios del siglo pasado fue importante su uso recreativo, destacando la playa de "La Corta" A lo largo del siglo XX empiezan las obras para embalsar el río en diferentes puntos del cauce, y dejó de usarse para pesca.

Durante las décadas de los 80 y 90 el río sufrió graves problemas de contaminación, especialmente a raíz de la construcción de una planta azucarera en El Portal. La acción de los grupos ecologistas fue clave en la detención de estos procesos y su posterior recuperación. A principios del 2010 el Guadalete tuvo una de sus mayores crecidas debido a las fuertes lluvias que se registraron en la zona, inundando así algunas pedanías de Jerez de la Frontera.

Su afluente principal es el río Majaceite, llamado en su nacimiento río El Bosque, que nace en Benamahoma. El Majaceite desemboca en el Guadalete en la llamada Junta de los Ríos. El segundo afluente principal es el río Guadalporcún que nace en el municipio de Torre Alháquime y se encuentra con el Guadalete en el término de Puerto Serrano. Cuente con otros muchos afluentes, como el Salado de Espera.

Es el segundo río más largo de Andalucía, si se considera que el río Genil es un afluente del Guadalquivir. El río está regulado mediante el embalse de Arcos, el embalse de Bornos y el embalse de Zahara de la Sierra. Los embalses de la cuenca del río Guadalete se muestran en la siguiente tabla:

Entre otras especies destacan la Globotruncana conica, Globotruncana contusa, Globotruncana stuarti o Globotruncana arca, no comunes en lejos de la costa y que tienen origen cretácico.

La angula ha disminuido su población enormemente en el río, pero se están haciendo esfuerzos para recuperarlas.

En 2019 se pone en marcha un plan para controlar la invasión de mejillón cebra

Existe constancia de desbordamientos del río desde el año 1618, así como 1881 e incluso a principios del siglo XX, cuando destruyó el puente que permitía salvar el río en Arcos de la Frontera. Aunque desde 1957 la ocupación para tareas agrícolas, ganaderas y construcciones humanas ha reducido casi en un tercio del espacio que margen de las tierras colindantes al río para absorber las crecidas.

En épocas de lluvias fuertes se producen crecidas que suelen anegar las zonas cercanas a su cauce, especialmente en pedanías del término municipal de Jerez (El Portal, Las Pachecas, La Greduela, etc). Estos son causados principalmente por el aumento de la actividad de agricultura, la actividad de 76 explotaciones de canteras para extracción de áridos cerca del río y las modificaciones en la cuenca por la construcción de embalses de gran envergadura. 

Sin llegar a los estragos que las lluvias de diciembre de 1996 causaron en toda la provincia y, especialmente, en el valle del Guadalete, apenas cuatro o cinco días de fuertes aguaceros bastaron para que los pantanos de cabecera de la cuenca se llenaran y debieran desembalsar importantes caudales. Una de las consecuencias derivadas de todo ello han sido las inundaciones que afectan a buena parte de la vega baja del río en muchos rincones de las campiñas de Arcos de la Frontera y Jerez.

Si hacemos un poco de historia, estos días nos traen a la memoria aquellos otros de la segunda quincena de diciembre de 1996 en los que, sin cesar de llover en toda la provincia, se produjeron también grandes inundaciones. El presagio de que algo especial se fraguaba lo tuvimos entonces el 14 de diciembre, cuando después de varios días de lluvia se registraron 70 litros por metro cuadrado en el aeropuerto de La Parra, en tan solo dos horas, de las 5 a las 7 de la mañana, comenzando los primeros desbordamientos en el Guadalete.
Sin dejar de llover los días siguientes, el 17 se cortaban ya las carreteras en muchos puntos de las pedanías de Jerez y el 19 se inundaban buena parte de las viviendas de la barriada rural de Las Pachecas, siendo evacuadas más de 80 familias. La situación recordó entonces a la sufrida en 1969 o a la que, con mayores problemas todavía, se vivió en 1963, cuando muchos vecinos de estos núcleos rurales debieron ser rescatados por los helicópteros de la base naval de Rota.

Como ha ocurrido estos días, también a partir del 14 de diciembre de 1996 el río Guadalete se desbordó como consecuencia de los aportes de todos los afluentes y arroyos de la cuenca y, principalmente, del desembalse de los pantanos. El 20 de diciembre, el Poblado de Doña Blanca se vio anegado por el desbordamiento del río que dejó aisladas a las barriadas rurales de El Portal y La Ina.

Recientemente, estudios de la Agencia Andaluza del Agua creen necesario cambiar el curso del río para evitar que la caída de un enorme peñón le haga salirse de su cauce provocando más inundaciones incontroladasTrabajos que ya han comenzado y que incluyen el derribo de edificaciones en los márgenes del río obstaculizando el funcionamiento de puentes

Tras estos sucesos, en 2014, delimitan las zonas inundables por el río a su paso por Jerez de la Frontera. Estas zonas constituyen el 9% del municipio, en concreto en las pedanías de Estella del Marqués, La Ina, La Corta, El Portal y El Portalillo.

El río ha sufrido por actuación de una construcción humana un drástico cambio en su cauce al poco de su nacimiento en Grazalema, que la Junta de Andalucía ha obligado a reparar gracias a un expediente sancionador de la a Confederación Hidrográfica del Guadalquivir.

Se ha construido un azud en El Portal para controlar las crecidas con una probada efectividad en las lluvias de otoño de 2014

Sin embargo, no se han demolido edificaciones en suelo "no urbanizable y de especial protección" en las inmediaciones del río

Centro de Hidrogeología de la Universidad de Málaga va a realizar un estudio a petición de la Agencia Andaluza del Agua para determinar las razones de los sistemáticos problemas de abastecimiento de agua potable de las poblaciones de la cabecera del río, analizando cómo en uno de los lugares con mayor pluviosidad del país puede darse estas situaciones.

En Zahara de la Sierra existe una playa artificial con el cauce del río.

El río cuenta con un Centro de Interpretación del Bajo Guadalete, ubicado en el Parque de Santa Teresa de Jerez de la Frontera.

En Arcos de la Frontera también se habilitó un centro de interpretación, pero actualmente está abandonado 

Se ha recuperado el "Molino del Caño" en el Puerto de Santa María para un restaurante de Ángel León. Hay otro molino en el Puente de la Cartuja.

Se está trabajando para delimitar senderos junto al río

Las administraciones públicas han aprobado un Plan Hidrológico que define la gestión del río en el periodo 2015-2021.

Mientras los ciudadanos han montado una plataforma para denunciar la situación del río y lo protejan de las distintas agresiones que sufre, incluyendo continuos vertidos. De hecho, ya han dado sus primeros frutos al eliminarse más de 21.000 eucaliptos (para reforesar con autóctonos) y retirarse 71.000 metros cúbicos de sedimentos

La Universidad de Cádiz colabora con un trabajo en el marco del proyecto RAMIP (River Delta System Analysis and Management in Practise), que financia la Unión Europea.

Recientemente la Junta de Andalucía ha aprobado la ampliación de la zona protegida del río, pasando a incluir el tramo entre La Barca de la Florida y Arcos. Y ha culminado la limpieza del río: 100.000 m³ de sedimentos retirado y 30.000 eucaliptos (especie invasora) talados, lo que se espera permita controlar futuras crecidas

Igualmente se está trabajando en el fomento del eco-turismo en torno al río, destacando la guía de itinerarios peatonales editada por la "Asociación para el Desarrollo Rural de la Campiña de Jerez" y la propuesta de Ecologistas en Acción

La bodega González Byass está estudiando utilizar los antiguos embarcaderos del río (embarcadero de la Marina junto al Rancho de la Bola y el del puerto de El Trocadero) para recrear como alternativa de ocio la travesía que hacía el vino de Jerez en barcazas por el Guadalete hasta que embarcaba para exportación.

En 2016 se inaugura en un centro (Aula) de interpretación del río en Jerez en el Parque de Santa Teresa.

En 2018 se inaugura un tramo navegable de 10 kilómetros de río.

En 2019 se llega a un acuerdo para realizar un sendero desde Jerez (La Cartuja) hasta el Puerto de Santa María.

En 2020 se anuncia una inversión de 42 millones en 15 años en el "Plan Especial Supramunicipal del Entorno del Río Guadalete", realizando cinco rutas cicloturistas además de otros 10 secundarias, embarcaderos, áreas recreativas y miradores entre otras actuaciones.



</doc>
<doc id="42792" url="https://es.wikipedia.org/wiki?curid=42792" title="Rafael Sanzio">
Rafael Sanzio

Raffaello Sanzio (Urbino, -Roma, ), también conocido como Rafael de Urbino o simplemente como Rafael, fue un pintor y arquitecto italiano del Renacimiento. Además de su labor pictórica, que sería admirada e imitada durante siglos, realizó importantes aportes en la arquitectura y, como inspector de antigüedades, se interesó en el estudio y conservación de los vestigios grecorromanos.

Hijo de un pintor de modesta relevancia, fue considerado un niño prodigio por su precoz habilidad y al quedar huérfano se formó en los talleres de varios artistas de prestigio. A los 25 años obtuvo su primer encargo oficial, la decoración de las Estancias Vaticanas, donde pintó algunos frescos como "La escuela de Atenas", considerada una de sus obras cumbre. Es célebre por la perfección y gracia de sus artes visuales, destacando en trabajos de pintura y dibujo artístico. Junto con Miguel Ángel y Leonardo da Vinci forma el trío de los grandes maestros del período.

Nació en Viernes Santo y falleció en esta misma festividad el día que cumplía 37 años. Fue un artista muy productivo, en parte gracias a que dirigió un taller conformado por numerosos colaboradores, y, a pesar de su muerte prematura, dejó una extensa obra que en gran parte aún se conserva. La mayor parte de su trabajo está alojado en los Museos Vaticanos, ya que decoró con frescos las habitaciones conocidas como las Estancias de Rafael, el principal encargo de su carrera, que quedó sin terminar a causa de su muerte y fue completado por ayudantes.

Después de sus años de juventud en Roma, gran parte de su obra, a pesar de haber sido diseñada por él, fue ejecutada por su taller, con una considerable pérdida de calidad. Ejerció gran influencia en su época; aunque fuera de Roma su obra fue conocida sobre todo a través de la producción que hicieron los talleres de grabado que colaboraban con él. Después de su muerte, la influencia de su principal rival, Miguel Ángel, se intensificó hasta los siglos XVIII y XIX, cuando las cualidades más serenas y armoniosas de Rafael fueron consideradas de nuevo como un modelo superior.

Su carrera se dividió de manera natural en tres fases y tres estilos, descritos así por Giorgio Vasari: sus primeros años en Umbría, el periodo posterior de cuatro años en Florencia (1504-1508), donde absorbió las tradiciones artísticas de la ciudad, y finalmente su último y triunfal período de doce años en Roma, trabajando para los papas y su corte.

Nació en Urbino —una pequeña ciudad de la Italia central—, en la región de Marcas, localidad pequeña, pero importante desde el punto de vista artístico, donde su padre Giovanni Santi era pintor de la corte del duque. En la pequeña corte de Urbino, Giovanni fue integrado en el círculo íntimo de la familia en un grado superior al que era habitual en otras cortes italianas, bajo un gobierno con un importante centro de cultura literaria y artística.

Crecer en el seno de esta pequeña corte le dio a Rafael la oportunidad de aprender las maneras pulidas y las habilidades sociales tan alabadas en él por Vasari. La vida cortesana de Urbino en esta época sería poco después considerada por Baldassare Castiglione, (en su obra "El Cortesano" en 1528), como modelo de virtudes de una corte humanista italiana. Castiglione se instaló en Urbino en el año 1504, cuando Rafael ya no residía en ella; sin embargo, la visitaba muy a menudo, lo que dio como resultado una extensa amistad. Otros visitantes habituales de la corte también se convirtieron en sus amigos: Pietro Bibbiena y Pietro Bembo, nombrados ambos cardenales más tarde, eran conocidos entonces como buenos escritores y vivieron en Roma al mismo tiempo que Rafael.

Se movió con comodidad en las altas esferas sociales durante toda su vida, lo que ha sido uno de los factores que han contribuido a dar una falsa impresión de una carrera artística fácil. Sin embargo, no recibió una completa educación humanística, por lo tanto no se sabe con claridad si leía fácilmente en latín.

Su madre, Magia di Battista di Nicola Ciarla, murió en 1491, y el 1 de agosto de 1494, Giovanni Santi, su padre, volvió a casarse. Con tan solo 11 años, quedó huérfano y bajo la custodia legal de su tío Bartolomeo, sacerdote, que inició un litigio con la madrastra del chico. Sin embargo, Rafael continuó viviendo con ella cuando no acudía a su aprendizaje con un maestro. Aun así, ya había dado muestra de su talento, según Giorgio Vasari, quien cuenta que había sido "una gran ayuda para su padre". Un brillante autorretrato de su adolescencia muestra su precoz talento. El taller de su padre continuó y, probablemente en compañía de su madrastra, jugó un relevante papel en su gestión desde su juventud. En Urbino tuvo la oportunidad de conocer la obra de Paolo Uccello, el precedente pintor de la corte († 1475), y de Luca Signorelli, quien hasta el año 1498 residió y trabajó en la próxima Città di Castello.

Según Vasari, su padre lo colocó en el taller del maestro de Umbria Pietro Perugino como aprendiz, «a pesar de las lágrimas de su madre». La evidencia de un periodo de aprendizaje viene solo de Vasari y de otra fuente, y ha sido discutida, porque su madre murió cuando él tenía ocho años, lo que sería demasiado pronto para comenzar a formarse. Una teoría alternativa es que recibió algún adiestramiento de Timoteo Viti, un pintor de la corte de Urbino desde 1495. Pero los historiadores modernos están de acuerdo en que Rafael trabajó al menos como ayudante de Perugino desde alrededor de 1500; la influencia de Perugino en sus primeras obras es muy evidente: "probablemente ningún otro discípulo de talento había absorbido las enseñanzas de su maestro como lo hizo Rafael, aún comparándolo con Leonardo da Vinci y Miguel Ángel", según Wölfflin. Vasari escribe que, en cuanto a este período, era imposible distinguir las obras de ambos artistas, pero muchos historiadores del arte modernos afirman haber detectado las partes que Rafael pintó como ayudante en obras de Perugino o de su taller. Aparte de la similitud estilística, sus técnicas eran también muy similares, por ejemplo, en la densa aplicación de la pintura, con el uso de un medio a base de barniz, en las sombras y los adornos oscuros, pero con una aplicación más ligera en las partes de carne. Sin embargo, el exceso de resina en el barniz ha causado a menudo grietas en áreas de las pinturas de ambos maestros. El taller de Perugino estaba activo tanto en Perugia como en Florencia, quizá con dos sucursales permanentes. Se considera que en 1501 Rafael era un "Maestro de Pleno Derecho", completamente formado.

Su primera obra documentada fue el "Retablo Baronci" —aunque hay una controversia con "La resurrección de Cristo" que fue realizada entre los años 1499 y 1501— para la Iglesia de San Nicolás de Tolentino en Città di Castello, una ciudad a medio camino entre Perugia y Urbino. Evangelista di Pian di Meleto, quien había trabajado para su padre, compartió el encargo de la obra, que data de 1500 y fue terminada en 1501; hoy en día solo quedan algunas porciones y un boceto preparatorio. Durante los siguientes años pintó obras para otras iglesias, incluyendo la "Crucifixión Mond" —alrededor de 1503— y "Los desposorios de la Virgen" de la Pinacoteca di Brera, así como obras para Perugia, como el "Retablo Oddi" —"La anunciación" , "La Adoración de los Magos" y "La coronación de la Virgen" 1501-1503—. Probablemente visitó Florencia en esta época. Se trata de obras mayores, algunas de ellas como frescos, en las que Rafael limita la composición al estático estilo de Perugino. En estos años pintó muchas pequeñas y exquisitas pinturas de caballete, la mayor parte posiblemente para amantes de la pintura de la corte de Urbino, como "Las Gracias", "El sueño del caballero" o "San Miguel", y empezó a pintar "Virgen con el Niño entronizados y santos".

En el año de 1502 fue a Siena por invitación de otro discípulo de Perugino, Pinturicchio, "al ser amigo de Rafael y conocedor de su capacidad como artista de la más elevada calidad", porque le ayudó con las obras, y muy probablemente con los dibujos, para una serie de frescos en la Biblioteca Piccolomini de la Catedral de Siena. Es evidente que en esta etapa temprana de su carrera ya era un artista solicitado.

Rafael llevó una vida de "nómada", trabajando en distintos lugares del norte de Italia, pero pasando una buena parte de su tiempo en Florencia, quizás desde el año 1504. Así, aunque se habla de su "período florentino" entre 1504 y 1508, cabe mencionar que nunca residió ahí de forma continua. En cualquier caso, tal vez de tanto en tanto, tenía que visitar la ciudad para proveerse de materiales. Existe una carta de recomendación, fechada en octubre de 1504, de la madre del siguiente duque de Urbino al confaloniero de Florencia: "El portador de ésta es Rafael, pintor de Urbino, quien ha sido dotado para esta profesión y que ha determinado pasar algún tiempo en Florencia para continuar con sus estudios. Su padre fue muy honesto y yo lo quería mucho, y el hijo es un joven sensible y pulido; tanto por una cosa como para la otra le tengo gran afecto...".

Como anteriormente con Perugino y otros, fue capaz de asimilar la influencia del arte florentino, respetando la evolución de su propio estilo. Los frescos que hizo en Perugia alrededor de 1505 muestran una nueva calidad monumental en las figuras, que podría evidenciar la influencia de Fra Bartolomeo, de quien Vasari dice fue amigo. Pero la influencia más asombrosa en este período fue la de Leonardo da Vinci, quien volvió a la ciudad entre 1500 y 1506. Las figuras de Rafael comenzaron a tomar posiciones más complejas y dinámicas, aunque todavía los temas eran mayoritariamente "reposados". Comenzó a hacer bocetos de hombres desnudos luchando, una de sus mayores obsesiones de este período florentino. Otro dibujo es el retrato de una mujer joven, utilizando la composición piramidal en tres cuartos de la reciente Mona Lisa, pero con una apariencia completamente rafaelesca. Otra de las invenciones compositivas de Leonardo, la piramidal "Sagrada Familia", se repitió en una serie de obras que se consideran entre sus más famosas pinturas de caballete. En la Royal Collection hay un dibujo de Rafael de la obra perdida de Leonardo "Leda y el cisne", de la que tomó la postura en "contrapposto" para su "Santa Catalina de Alejandría".
También perfeccionó su propia versión del "sfumato" de Leonardo, para dar más sutileza a la representación de la carne, y desarrollar el intercambio de miradas entre los grupos, aunque mucho menos enigmáticos que los conseguidos por Leonardo. Además, supo conservar en sus obras la suave y clara luz de Perugino.

Leonardo era poco menos de una treintena de años mayor que Rafael, pero Miguel Ángel, que en esa época residía en Roma, era solo ocho años mayor. Miguel Ángel detestaba a Leonardo, y en Roma empezó a detestar a Rafael incluso más aún, atribuyendo conspiraciones contra él. Rafael debió conocer sus obras en Florencia, pero sus trabajos más originales de esta época apuntan en una dirección muy diferente. En su "Santo Entierro" sitúa, al modo clásico de los sarcófagos, todas las figuras en el frente, en un arreglo complejo y no del todo exitoso. Wöllflin detecta la influencia de la Virgen de Miguel Ángel en el "Tondo Doni" en la figura arrodillada de la derecha, pero el resto de la composición se aleja mucho de su estilo, o del de Leonardo. Aunque fue obra muy considerada en su época, y mucho después retirada a la fuerza de Perugia por los Borghese, se trata de una obra aislada en su producción. Su clasicismo tomaría después una dirección menos "literal".

A finales de 1508 se trasladó a Roma, donde entró al servicio del papa Julio II, probablemente gracias a la recomendación de su arquitecto Donato Bramante, quien por entonces trabajaba en la basílica de San Pedro, era natural de Urbino y tenía alguna relación con Rafael. A diferencia de Miguel Ángel, que no realizó trabajo artístico alguno durante cierto tiempo en Roma antes de recibir los primeros encargos, el joven artista recibió rápidamente el encargo de decorar al fresco la que habría de ser la biblioteca privada del pontífice en el Vaticano.

La primera de las célebres "stanze" que comenzó a pintar, es la conocida como "Stanza della Segnatura" —por el uso que tenía en tiempos de Giorgio Vasari—, produjo un impacto extraordinario en el arte romano. Hoy día continúa siendo considerada la obra maestra del pintor, pues contiene La Escuela de Atenas, El Parnaso y La disputa del Sacramento, que son algunas de las obras más conocidas del pintor. Como consecuencia de este gran éxito, le fueron encargadas nuevas estancias, desplazando a otros artistas previamente contratados, como Perugino o Luca Signorelli. Concluyó tres de ellas, todas con pinturas en sus muros y, a menudo, también en los techos. Sin embargo, la inmensidad del trabajo asumido le obligó a delegar la ejecución práctica de sus detallados diseños (que siempre realizó en persona) en los miembros del numeroso taller que había formado. Eran estos artistas de sobrada capacidad, que con posterioridad a la muerte del propio Rafael, se encargarían de la decoración de la cuarta estancia, basándose en los diseños que el maestro había dejado. La muerte de Julio II (1513) no interrumpió los trabajos, pues su sucesor, el papa León X, un Medici, estableció una relación cercana con el artista, que continuó recibiendo encargos. El amigo de Rafael, el cardenal Bibbiena, era uno de los antiguos tutores del nuevo papa, y su íntimo amigo y consejero.

Es evidente que Rafael se dejó influir por los frescos del techo de la Capilla Sixtina de Miguel Ángel. Vasari dice que Bramante lo introdujo en dicha capilla secretamente. La bastida correspondiente a la primera sección en ser terminada fue retirada el año 1511. La reacción de los demás artistas ante la superior fuerza expresiva de Buonarroti fue la cuestión dominante en el arte italiano en las dos décadas posteriores. Rafael ya había demostrado su capacidad de asimilación de influencias externas a su propio estilo, y aceptó el reto tal vez con mayor intensidad que cualquier otro artista. Uno de los primeros y más claros ejemplos fue el retrato del mismo Miguel Ángel como Heráclito en "La Escuela de Atenas", que parece sacado directamente de las "Sibilas" o los "ignudi" del techo de la Capilla Sixtina. Otras figuras de esta y otras obras posteriores en las estancias acusan la misma influencia, pero todavía más integradas en el estilo personal de Rafael. 

Buonarroti lo acusó de plagio y unos años antes de la muerte de Rafael se quejaba en una carta del siguiente tenor: «todo lo que sabe de arte lo ha aprendido de mí», aunque en otras ocasiones se mostró más generoso.

Estas enormes y complejísimas composiciones pueden ser consideradas entre las obras supremas del Renacimiento. Proporcionan una visión extremadamente idealizada de los sujetos representados, y las composiciones, aunque ya perfectamente concebidas en dibujo, parecen sufrir de "sprezzatura", un término ideado por su amigo Baldassare Castiglione, que él definía como «una cierta indiferencia que impregna toda la obra y que nos hace pensar o decir que ha fluido sin ningún esfuerzo». Según Michael Levey, «Rafael les da a sus figuras una gracia y claridad sobrehumanas en un universo de certezas Euclidianas». La pintura es de la máxima calidad en las dos primeras estancias, pero las composiciones posteriores, especialmente las que contienen acción de tinte dramático, no son completamente perfectas por lo que atañe a la concepción, como tampoco en la ejecución de sus ayudantes.

Los proyectos en el Vaticano ocuparon la mayor parte de su tiempo, pero aun así pintó algunos retratos, incluyendo los de sus mecenas, los papas Julio II y León X, el primero de los cuales es considerado como uno de sus mejores retratos. Otros retratos fueron los de sus amigos, como Castiglione, o de personajes del círculo de los papas. Algunos gobernantes lo presionaron con hacer sus respectivos encargos, como a Francisco I de Francia que le fueron enviados dos pinturas como presente diplomático del papado. Para Agostino Chigi, el inmensamente rico tesorero del papa, Rafael pintó "La Galatea", diseñó frescos decorativos para su "Villa Farnesina" y pintó dos capillas en las iglesias de "Santa Maria della Pace" y "Santa Maria del Popolo". También diseñó parte de la decoración de la Villa Madama, sin embargo, la obra de ambas villas fue realizada por su taller.

Uno de los encargos papales más importantes fue la serie de los "Cartones de Rafael" (actualmente en el Victoria and Albert Museum), una serie de 10 cartones para tapices, de los cuales han sobrevivido 7, y que representan escenas de las vidas de San Pablo y San Pedro, hechas para la Capilla Sixtina. Los cartones fueron enviados a Bruselas para ser tejidos en el taller de Pieter van Aelst el Viejo (padre del luego famoso pintor Pieter Coecke). Es posible que Rafael viera la serie completa terminada antes de su muerte. Probablemente fueron terminados en 1520. También diseñó y pintó las Logias vaticanas, una galería larga y estrecha entonces abierta a un patio a un lado y decorada en el estilo grotesco típico de Roma. Pintó también ciertos retablos importantes, como por ejemplo el "Éxtasis de Santa Cecilia" y la "Madonna Sixtina". Su última obra, en la que estuvo trabajando hasta la muerte, fue "La Transfiguración", que en compañía de "El Pasmo de Sicilia" muestra la dirección que había tomado su arte en las postrimerías de su vida: un estilo más proto-barroco que manierista.

El cardenal Bernardo Dovizi di Bibbiena obtuvo del papa León X, a cambio del apoyo concedido para su elección, la autorización para reestructurar su apartamento en el interior de los palacios Vaticanos. Culto humanista y literato, de gustos refinados, el cardenal deseaba que su apartamento estuviese a la altura de la tradición romana y encargó el proyecto a Rafael. Corría el año 1516; Rafael, con sus ayudantes se ocupó del conjunto decorativo, inspirándose en la Villa de Adriano en Tívoli y en la Domus Aurea, alcanzando resultados de gran refinamiento y elegancia en el entrelazamiento de motivos clásicos y elementos ornamentales de gusto antiguo, que constituirán durante tiempo un imitado motivo decorativo. Igual decoración desarrolló en las Logias vaticanas (1519). La estructura del conjunto refleja la cultura y el gusto de Rafael; la ejecución es de sus alumnos: Giovanni da Udine, G. Romano y G. F. Penni.

Vasari dice que Rafael llegó a tener un taller con cincuenta pupilos y ayudantes, muchos de los cuales llegarían a ser después importantes artistas por su propio derecho. Fue, posiblemente, el mayor taller reunido bajo el magisterio de un único gran maestro de la pintura, y mucho mayor de lo habitual. Incluía destacados pintores provenientes de otras regiones de Italia, que probablemente trabajaban con sus propios equipos como subcontratistas, así como aprendices y obreros. Hay poca información sobre el taller y sobre su organización interna, aparte de las mismas obras de arte, a menudo difíciles de atribuir a la intervención de un artista concreto.

Tras la muerte de Rafael, la actividad del taller continuó, sin embargo, muchas de sus pinturas quedaron incompletas, así como algunas de sus posesiones. Los miembros más destacados fueron Giulio Romano, joven discípulo de origen romano —de 21 años—, y Gianfrancesco Penni, ya considerado un maestro, de origen florentino. Penni no alcanzó el mismo nivel de reputación personal que Giulio, y después de la muerte de Rafael, ocupó el puesto de ayudante de Giulio Romano durante la mayor parte de su carrera. Perino del Vaga, ya un maestro, y Polidoro da Caravaggio, quien supuestamente ascendió a la posición de pintor luego de ocupar el humilde oficio de trasportar materiales para los obreros, también llegaron a ser importantes pintores. Maturino da Firenze, como en el caso de Penni, fue eclipsado por la fama de su compañero Polidoro. Giovanni da Udine gozaba de un estatus más independiente, y fue responsable de la decoración en estuco y los grotescos que decoraban los principales frescos. La mayor parte de los artistas se dispersaron, y algunos de ellos tuvieron una muerte violenta a raíz del saqueo de Roma de 1527. Esto contribuyó a la difusión del estilo de Rafael por toda Italia y a lugares más lejanos.

Vasari da mucha importancia al hecho de que Rafael logró un armonioso y eficiente taller, y al igual su habilidad y paciencia en la resolución de los conflictos o disputas entre los clientes y sus ayudantes, algo que carecía Miguel Ángel con ambos colectivos. Aun así, hoy en día, es casi imposible descifrar las partes que Rafael y sus ayudantes realizaron, ya que, tanto Giulio como Penn, eran diestros, no hay duda de que muchas de las últimas obras murales de Rafael, y probablemente algunas de sus obras de caballete, destacan más por el dibujo que por la ejecución. Sin embargo, muchos de sus retratos, que se encuentran en buenas condiciones, muestran la brillante técnica de ejecución que alcanzó al final de su vida.

Otros de sus destacados discípulos y ayudantes fueron Raffaellino del Colle, Andrea Sabbatini, Bartolomeo Ramenghi, Pellegrino Aretusi, Vincenzo Tamagni, Battista Dossi, Tommaso Vincidor, Timoteo Viti—pintor de Urbino—, así como el escultor y arquitecto Lorenzetto —cuñado de Giulio Romano—. Se ha dicho que el flamenco Bernard van Orley trabajó durante un tiempo para Rafael, y que Luca Penni, hermano de Gianfrancesco, tal vez fue miembro del taller.

A lo largo de su vida realizó varios retratos donde mostró una gran medida de gracia y armonía, ejemplo de esto fue el de Baltasar de Castiglione. Las "Madonne" y los "bambini" llenos de belleza y elegancia fueron un tema recurrente tanto en sus retratos como en sus pinturas. En la "Última Cena" dio un gran protagonismo a la figura de los apóstoles. De igual manera realizó retratos de grandes personajes como: del Cardenal Bibbiena (c. 1516), el "Retrato de Andrea Navagero y Agostino Beazzano" (c. 1516), "Retrato de Bindo Altoviti" (c. 1514), "Retrato de Tommaso Inghirami" (1515-1516), "Retrato de cardenal" (1510-1511), "Retrato de Julio II" (1511-1512) y "Retrato del cardenal Alessandro Farnese" (1509-1511). Muchos de ellos se encuentran hoy dispersos en los museos y galerías de Europa.

La relación de Rafael con Leonardo da Vinci en Florencia a principios del fue muy significativa. El modelo inspirador es la Gioconda, que por el efecto emocional de su mirada y sobre todo la integración entre la figura y el paisaje constituyó un modelo de reflexión para Rafael. Pero en los retratos de Rafael la línea establece netamente las formas, que gracias a su certeza se convierten en "módulo" espacial, en equilibrio entre lleno y vacío, en medida de la relación entre lo particular y lo universal, en síntesis perfecta de las verdades de la persona. También la trayectoria de Rafael se concreta en la superación de las formas poco convencionales de Perugino, en la adquisición de una pintura autónoma, libre, que sea expresión del perfecto equilibrio existente entre el hombre y la naturaleza. Los comitentes del artista son representantes de la alta burguesía de los banqueros y los mercaderes o de la aristocracia menor, mientras la sociedad más elevada se dirige a pintores de más fama, como Ghirlandaio.

El encargo papal acrecienta enormemente la fama y el prestigio de Rafael, que entre 1509 y 1513 recibe numerosas peticiones de cardenales y nobles más o menos próximos a la curia romana. Realizaba dichos retratos al mismo tiempo que ejecutaba las estancias. En este ámbito es interesante la evolución del retrato. La novedad es que se advierte en ellos una mayor propensión a representar los rasgos como indicadores de la interioridad, más allá de la preocupación por la afirmación del estado social; además, resulta evidente la representación de la figura como presencia más cierta y consciente.

Tras la muerte de Bramante, en 1514, fue nombrado arquitecto de la basílica de San Pedro. La mayor parte de sus obras arquitectónicas han sido derrumbadas o modificadas después de su muerte y a raíz de la aceptación de los diseños de Miguel Ángel, pero, sobreviven unos pocos diseños. Para el análisis de estos, se llevó a cabo el examen de un templo que se encontraba muy oscuro, con grandes pilares a lo largo, «como un callejón» según un análisis crítico y póstumo de Antonio da Sangallo el Joven. Existe también la hipótesis de que el templo tiene un parecido con el santuario de "La expulsión de Heliodoro del templo". Rafael diseñó otros edificios, y durante un corto tiempo se le consideró el arquitecto más importante de Roma y el preferido del círculo social del papa. Julio había hecho cambios en la disposición urbanística de la ciudad, creando varias vías públicas, las cuales aparentaban esplendorosos palacios.

Un importante edificio, el Palazzo Branconio dell'Aquila del chambelán de León X, fue completamente derrumbado para hacer lugar a la plaza diseñada por Bernini para San Pedro, obra que jamás se realizó, pero se han conservado dibujos de la fachada y del patio. La fachada gozaba de una abigarrada decoración, inusual para la época, incluyendo tanto paneles pintados en el piso superior (de tres) como profusión de esculturas en el piso intermedio. El diseño básico de la Villa Farnesina no fue de Rafael, pero él diseñó y pintó la Capilla Chigi para el propietario, Agostino Chigi, tesorero del papa. Otro edificio, para el doctor del papa León, el Palazzo di Jacobo da Brescia, el cual fue trasladado en la década de 1930, y actualmente se mantiene en pie; dicho edificio fue diseñado como complemento de un palacio de la misma calle, obra de Bramante, donde el mismo Rafael residió durante un tiempo. La Villa Madama, una espléndida residencia de recreo del cardenal Julio de Médicis, posteriormente del papa Clemente VII, nunca fue terminada, pero sus planos revelan su propósito. Se hizo un diseño a partir de los planos constructivos por Antonio da Sangallo el Joven y aunque incompleta, era la villa más sofisticada diseñada hasta el momento en Italia. De este modo, influyó de manera importante en los diseños posteriores de este tipo de edificio. (este parece ser el único edificio moderno de Roma del cual Palladio hizo un dibujo medido). Solo quedan los planos de la planta baja de un gran palacio diseñado por él mismo a la nueva «Via Giulia», en el Borgo, para el cual estuvo acumulando el terreno en sus últimos años. Se encontraba en una manzana irregular cerca del río Tíber. Parece que las fachadas debían incluir una orden gigante de pilastras elevándose al menos dos plantas hasta la altura completa de la planta noble, «un estilo grandilocuente sin precedentes en un palacio de carácter privado». En 1515, le fueron otorgados poderes como "Prefecto" sobre todas las antigüedades que se desenterraran en la ciudad y hasta una milla alrededor de esta. Rafael escribió una carta al papa León sugiriendo medidas para impedir la destrucción de los monumentos antiguos, y propuso una inspección visual de la ciudad para registrar las antigüedades de manera organizada. La opinión del Papa era diferente, quería seguir reutilizando las antiguas fábricas para la construcción de San Pedro, pero quería que todas las inscripciones antiguas quedaran documentadas, así como también conservar las esculturas, antes de dar permiso para el uso de la piedra.


Entre otros

Se le considera uno de los dibujantes más finos en la historia del arte occidental y uno de los que usó ampliamente el dibujo para planear sus composiciones. Según Armerina, experta en la vida del artista, cuenta, que cuando este empezaba a planear una composición, extendía en el suelo un gran número de dibujos que conservaba archivados, y comenzaba rápidamente a dibujar, utilizando figuras de «aquí y de allá». Han sobrevivido unos cuarenta bocetos de la "Disputa" de las Estancias y probablemente haya más entre las cuatrocientas hojas que se tienen actualmente de sus pre-diseños; bien solo constituyen una parte mínima de los que realizó el artista o hizo realizar por su taller bajo su supervisión. Hizo muchos dibujos para perfilar las posturas y las composiciones, aparentemente en cantidad superior a la de otros pintores, a juzgar por la gran cantidad de variantes que han sobrevivido: «... Es así como el mismo Rafael, que tenía tanta riqueza inventiva, solía trabajar, siempre partiendo de cuatro o seis maneras diferentes de exponer la escena, cada una de ellas diferente al resto, y todas ellas llenas de gracia y finura» escribió un autor tras la muerte de este. Para John Shearman, el arte de Rafael marca «un desplazamiento de los recursos desde la producción hacia la investigación y el desarrollo».

Su obra está acompañada de un inmenso "corpus" de dibujos, que constituyen un fundamental documento de apoyo de las obras pintadas, pero que deben ser entendidos e interpretados como un ámbito de investigación autónomo y original. Han sido catalogados por Fischer como una estancia romana.

Ciertamente, desde el período umbro, el dibujo constituía una parte fundamental de su método de trabajo: se trata de esbozos o estudios principalmente al natural, útiles para enfocar un detalle de la composición, aunque debe reconocerse que los motivos del dibujo nunca son transferidos a la obra definitiva sin modificaciones ni variaciones.

Cuando estaba satisfecho con una composición a menudo la trasladaba a cartón a escala real, que posteriormente perforaba con un punzón, dejando agujeros por donde dejaba pasar un poco de hollín, de modo que quedaban líneas en la superficie final como guía. También hizo un uso exhaustivo y poco habitual, tanto en papel como en yeso, de una «aguja ciega», marcando líneas que dejaban solo una hendidura, pero ninguna marca. Estas pueden ser vistas en el muro de "La escuela de Atenas" y en muchos otros dibujos. Los "Cartones de Rafael", como diseños para tapices que eran, fueron completamente coloreados con pintura al temple, y fueron enviados a Bruselas para ser tejidos.

En las últimas obras pintadas por el taller, los dibujos son a menudo mucho mejores que la pintura. La mayor parte de sus dibujos son bastante detallados, incluso los bocetos iniciales con figuras desnudas están cuidadosamente hechos, y los posteriores dibujos de preparación tienen un alto nivel de acabado, con sombreados y, a veces, zonas iluminadas en blanco. Carecían de la libertad y la energía de algunos de los bocetos de Leonardo o de Miguel Ángel, pero siempre muy satisfactorios desde el punto de vista estético. Fue uno de los últimos artistas en utilizar de manera habitual un dispositivo metálico, aunque también supo hacer un soberbio uso de la técnica más libre del carbón rojo o negro. En sus últimos años fue uno de los primeros artistas en usar modelos femeninos para dibujos preparatorios, aunque cabe mencionar que habitualmente se usaban hombres para estudio de ambos sexos. («Garzón»).

Las técnicas son dispares: lápiz, sanguina, pluma, punta de plomo o de plata, bistre, albayalde, acuarela, trazos netos o esfumados, sobre papel blanco o coloreado.

Rafael no hizo directamente los grabados, sino que buscó la colaboración de Marcantonio Raimondi para reproducirlos a partir de sus dibujos, colaboración que dio lugar a muchos de los grabados italianos más afamados del siglo y que marcó la evolución de este arte. Este interés por los grabados no es habitual entre los grandes maestros; de sus contemporáneos, solo Tiziano, quien trabajó con Raimondi, pero de una forma menos satisfactoria. Se hicieron alrededor de cincuenta planchas, algunas copiando pinturas conocidas de Rafael, pero otras aparentemente sobre diseños originales expresamente pensados por el maestro. Parte de estos dibujos preparatorios se ha perdido, y su existencia se conoce solamente porque Raimondi los trasladó al grabado.

Los grabados originales más famosos surgidos de esta colaboración fueron "Lucrecia", el "Juicio de Paris" y "La masacre de los Inocentes" (del que fueron grabadas dos versiones prácticamente idénticas). Entre los grabados basados en pinturas cabe destacar "El Parnaso" (con diferencias considerables respecto a la original) y "Galatea". Fuera de Italia, los de Raimondi y otros fueron la principal vía de divulgación del arte de Rafael hasta el siglo XX. Baviero Carocci, llamado por Vasari «Il Baviera», un ayudante a quien Rafael confiaba su dinero, se quedó en posesión de muchas de las planchas después de la muerte del artista, y tuvo éxito en la nueva ocupación de editor de grabados.

Rafael vivía en Borgo, con bastante lujo y en un palacio diseñado por Bramante. Nunca se casó, pero en 1514 se comprometió con María Bibbiena, sobrina del cardenal Médici. Parece que su amigo, el cardenal, forzó el compromiso, y que la falta de entusiasmo del artista no hizo posible los esponsales antes de su muerte en 1520. Se ha dicho que tuvo varias relaciones amorosas, pero mientras vivió en Roma gozó de una relación permanente con Margherita Luti, «La Fornarina», llamada así por ser hija de un panadero ("fornaio" en italiano) de origen sienés llamado Francesco Luti, que vivía en la "Via del Governo Vecchio".

Fue nombrado "mayordomo" del Papa León X, lo que le daba un cierto estatus ante la corte y unos ingresos adicionales, así como también, caballero de la "Orden Papal de la Espuela Dorada". Vasari afirma que estos nombramientos, y al igual que los muchos encargos hechos por estos, pudieron ser motivo y explicación del retraso de su casamiento. Según Vasari, su prematura muerte en un Viernes Santo (6 de abril de 1520, posiblemente el día de su aniversario treinta y siete) fue debido a una noche en la cual tuvo excesivas relaciones sexuales con «La Fornarina», tras lo cual enfermó con fiebre, y al no confesarle a los doctores la verdadera causa, no le fue administrado el cuidado correcto, lo que le causó la muerte. Fuese cual fuese la causa, en la agudización de su enfermedad, que duró quince días, pudo recibir la extremaunción y puso sus cosas en orden. Dictó su testamento, mediante el cual dejó suficiente dinero para manutención de su amante, confiado a su leal sirviente Baviera, y dejó la mayor parte del contenido de su taller a Giulio Romano, a Penni y a un desconocido sacerdote de Urbino que era pariente suyo. Cumpliendo su solicitud, fue enterrado en el Panteón de Roma.

La biografía de Vasari, dice que nació en Viernes Santo, y que en 1483, ese día fue el 28 de marzo. Esto significa que si Rafael efectivamente nació y murió en Viernes Santo, en realidad no murió el día de su cumpleaños, ya que el Viernes Santo de 1520 fue 6 de abril. Su funeral fue grandioso y acudió una gran multitud. La inscripción en su sarcófago de mármol, un pareado elegíaco escrito por Pietro Bembo, dice:

Puede traducirse como "Aquí yace Rafael, por el que en vida temió ser vencida la naturaleza, y al morir él, temió morir ella".

Y el conde Baldassare Castiglione escribió sobre su muerte de esta forma:

El retrato de Rafael que copia más directamente el modelo de la "Gioconda" es el de Maddalena Doni: el mismo corte con el busto entero, la misma articulación en el espacio, la misma evidencia de las manos en primer término. Ahora bien, la lectura comparada de las dos obras evidencia una profunda distancia en la concepción. Leonardo, al regresar a Florencia, llevaba consigo el fruto de los estudios milaneses sobre la realidad fenoménica y una actitud de tipo "científico", con base en la cual la indagación sobre la realidad estaba exenta de cualquier certeza "a priori". Rafael llegaba a Florencia después de la experiencia de Urbino, que había desarrollado en él la concepción del arte como evidencia de la verdad representada en la perfección de la forma geométrica. El joven se mide con el más viejo Leonardo.

Mientras Rafael trabajaba en la estancia de la Signatura, Miguel Ángel estaba dando vida, en la bóveda de la antigua capilla Sixtina, al otro monumento fundamental de la pintura renacentista. La comparación entre las dos obras es inevitable, aunque a decir verdad ya en los años florentinos Rafael había tenido ocasión de razonar sobre la interpretación miguelangeliana de la forma, extrayendo eficaces sugerencias. Pero en Roma, algunas figuras de la bóveda de la stanza della Segnatura, en particular las personificaciones de las Virtudes, están concebidas según una monumentalidad nueva, plasmadas en gigantescos altorrelieves, articuladas en posturas construidas por líneas quebradas, alejadas del flujo armónico del ritmo clásico propio de Rafael. La cuestión es cómo el artista pudo ver la bóveda de Miguel Ángel, que fue descubierta después de la conclusión de la stanza della Segnatura. Vasari cuenta que Rafael, con la complicidad de Bramante, habría aprovechado una breve ausencia de Miguel Ángel para subir a los andamios de la Sixtina; otras versiones cuentan que el Papa Julio II permitió el acceso a Rafael a la sala. Pero el relato no es creíble; es más probable que las Virtudes fueran realizadas después de un descubrimiento parcial de la Sixtina.

La Roma de los papas, donde Rafael ocupa una posición de gran prestigio, es el escenario ideal para que la obra del pintor supere los límites de su propia actividad y llegue a otros ámbitos más lejanos. En ese sentido debe considerarse la relación con el gran pintor alemán Alberto Durero, testimoniada por una serie de documentados intercambios epistolares, fechados en 1515. Ese año Rafael envía a Durero un dibujo para la "Batalla de Ostia", sobre el que el propio Durero anota en alemán: Entre los dos artistas se produce un intercambio de ensayos; de este modo, el pintor alemán envía un autorretrato a la grisalla y algunos grabados, que despiertan el interés de Rafael por esa técnica, en la que hizo especializarse a su alumno Marcantonio Raimondi. No se han documentado relaciones más precisas, pero el análisis de algunas obras de los dos artistas revela ese intercambio recíproco.

Gozó de la admiración de sus contemporáneos, aunque su influencia en el desarrollo del arte en su siglo fue menor que la de Miguel Ángel. El manierismo, que comenzó más o menos en el tiempo de su muerte, y el barroco posterior, llevaron el arte en una «dirección completamente opuesta» a las cualidades rafaelinas; «con la muerte de Rafael, el arte clásico —el Alto Renacimiento—se hundió», según manifiesta Walter Friedlander. Sin embargo, pronto fue considerado como modelo ideal para aquellos que detestaban los excesos del manierismo:

Las composiciones de Rafael han sido siempre admiradas y estudiadas, y se han convertido en «joya» del arte académico. El período de mayor influencia se extendió desde finales del siglo XVII hasta finales del siglo XIX, en que fueron muy admirados tanto su perfecto equilibrio como su decoro. Fue visto como el modelo perfecto de la historia de la pintura, y al mismo tiempo era considerado como el más elevado de la jerarquía de géneros. "Sir" Joshua Reynolds, en su obra "Discursos", alabó su «simple, grave y majestuosa dignidad» y dijo que «se sitúa como el principal de los primeros [sobre los mejores] pintores», especialmente por sus frescos (entre los que incluía los "Cartones") , mientras que «Miguel Ángel reclama el siguiente lugar. No poseía tantas cualidades excelsas y descomunales como Rafael, pero las que poseyó eran del más alto nivel». Haciéndose eco de las opiniones del expresadas anteriormente, Reynolds concluye:

Reynolds mostraba menos entusiasmo por las pinturas de caballete de Rafael, pero la ligera sentimentalidad que desprenden las hizo muy populares durante el siglo XIX: «Nos hemos acostumbrado a ellas desde la infancia, a través de un enorme número de reproducciones, cosa jamás hecha por algún otro artista...» escribió Wölfflin, quien había nacido en 1862, sobre la obra "Las Vírgenes" del florentino. En Inglaterra, en el siglo XIX, la Hermandad Prerrafaelista reaccionó explícitamente en contra de su influencia (y también en contra de la de sus admiradores, como «Sir Sploshua»), en busca de un retorno hacia los estilos anteriores a su «nefasta» influencia. Según John Ruskin:

Todavía en el fue considerado por críticos como Bernard Berenson como el «más famoso y más querido maestro del Alto Renacimiento», pero todo indica que en este siglo fue superado en aprecio por Miguel Ángel y Leonardo.





</doc>
<doc id="42796" url="https://es.wikipedia.org/wiki?curid=42796" title="Hans Asperger">
Hans Asperger

Hans Asperger (en alemán /aspɛʁɡɐ/), (Viena, 18 de febrero de 1906 - Viena, 21 de octubre de 1980) fue pediatra, investigador, psiquiatra y profesor de medicina austríaco. Es conocido por sus tempranos estudios sobre desórdenes mentales, especialmente en niños. Sus trabajos pasaron mayormente desapercibidos en vida, excepto por unos pocos galardones en Viena, y sus estudios sobre desórdenes psicológicos solo alcanzaron reconocimiento mundial con el renovado interés en sus trabajos que tuvo lugar a principios de los años 1980 y, algo más más tarde, con las nuevas investigaciones y descripciones de los denominados trastornos del espectro autista. Una de las manifestaciones del espectro, el síndrome de Asperger, se denomina así en su honor. El papel que desempeñó en la época nazi es un asunto controvertido.

Hans Asperger nació en Viena y creció en una granja a las afueras de Viena. Fue el menor de dos hijos. Tuvo dificultades para hacer amigos, y se le consideró un niño solitario. Durante su infancia, Asperger parece haber presentado algunas de las características del síndrome con su nombre. Fue alguien dotado para el lenguaje, estando particularmente interesado en el poeta austríaco Franz Grillparzer, cuya obra recitaba frecuentemente a sus compañeros de clase. Le gustaba citar sus propias palabras, y a menudo se refería a sí mismo desde una perspectiva de tercera persona.

Asperger estudió medicina en la Universidad de Viena con Franz Hamburger y realizó prácticas en el Hospital Infantil Universitario de Viena. Se graduó como doctor en medicina en 1931 y llegó a ser director del departamento de educación especial en la clínica infantil universitaria de Viena en 1932. Se unió al Frente Patriótico austríaco, de ideología austrofascista, el 10 de mayo de 1934, nueve días después de que el Canciller Engelbert Dollfuss pasara una nueva constitución haciéndose a sí mismo dictador. Se casó en 1935 y tuvo cinco hijos.

Durante la Segunda Guerra Mundial fue un oficial médico, sirviendo en la ocupación de Croacia por parte de las potencias del Eje; su hermano menor murió en la batalla de Stalingrado. Hacia el final de la guerra, Asperger abrió una escuela para niños con la Hermana Victorine Zak. En un bombardeo, esta falleció, y la escuela fue destruida junto con gran parte de las primeras investigaciones de Asperger.

Asperger publicó una definición de psicopatía autista en 1944 que resultó básicamente idéntica a la publicada con anterioridad por la neuróloga rusa Grunya Sukhareva (Груня Ефимовна Сухарева) en 1926. En su informe, síntesis de sus estudios sobre decenas de niños, Asperger identificó en cuatro chicos un patrón de comportamiento que incluía "una falta de empatía, escasa habilidad para entablar amistad, conversaciones con uno mismo, fijación intensa hacia un determinado asunto, y movimientos torpes". Asperger denominó a estos niños con psicopatía autista "pequeños profesores" debido a su habilidad para hablar de sus intereses favoritos con gran detalle. Asperger identificó que muchos de los niños diagnosticados como autistas usaban su talento una vez adultos, y llevaban carreras exitosas. Uno de ellos llegó a ser profesor de astronomía y arregló un error en la obra de Newton que había descubierto como estudiante. Otro de sus pacientes fue la escritora y Premio Nobel de Literatura Elfriede Jelinek. 

En 1944, tras la publicación de su artículo emblemático describiendo los síntomas del autismo, encontró un puesto permanente en la Universidad de Viena. Al poco de acabar la guerra, se convirtió en director de la clínica infantil de la ciudad. Fue designado jefe de pediatría en la Universidad, puesto que conservó durante 20 años. más tarde trabajó en Innsbruck. Desde 1964, encabezó Aldeas Infantiles SOS en Hinterbrühl.

Edith Sheffer, especialista en historia europea moderna, escribió en 2018 que Asperger cooperó con el régimen nazi, incluso enviando niños a la clínica Spiegelgrund que participaba en el programa de exterminio nazi eufemísticamente denominado "eutanasia". 

Sheffer escribió un libro desarrollando su investigación titulado "Los niños de Asperger: Origen del autismo en la Viena nazi".

Otro investigador e historiador de la Universidad de medicina de Viena, Herwig Czech, escribió en un artículo de la revista "Molecular Autism" publicado en abril de 2018:

Así, mientras para algunos el hecho de que jamás haya sido miembro del partido nazi se considera una prueba suficiente de que no se trataba de un fanático, para otros justamente el hecho de que no haya tenido miltancia le garantizó que su complicidad con los criminales haya pasado inadvertida para la justicia, logrando así que su vida transcurriera sin sobresaltos tras la guerra y falleciera en paz en 1980.

Sus trabajos se publicaban exclusivamente en alemán. La investigadora británica Lorna Wing propuso el nombre en su artículo de 1981, "El Síndrome de Asperger: un relato clínico", que desafiaba el modelo previamente aceptado de autismo, presentado por Leo Kanner en 1943. No fue hasta 1991 que se realizó una traducción fidedigna de los trabajos de Asperger, llevada a cabo por Uta Frith; antes de esto, el síndrome había sido "virtualmente desconocido". Frith afirmó que algunas preguntas fundamentales sobre el diagnóstico no habían sido resueltas, y que los datos científicos para abordarlas no existían. Al contrario que Kanner, quien eclipsó a Asperger, los hallazgos de este último fueron ignorados o despreciados en el mundo de habla inglesa mientras vivió. A principios de los años 1990, la obra del austríaco alcanzó mayor relevancia debido a las investigaciones de Wing y la reciente traducción de Frith, llevando a la inclusión del nombre en el CIE-10 en 1993, y en el DSM-IV en 1994, medio siglo después de las primeras investigaciones de Asperger. El CIE-10 de la Organización Mundial de la Salud describe el síndrome como "un desorden de incierta validez nosológica", y existe un consenso mayoritario para eliminarlo gradualmente del manual de diagnóstico de la Asociación Estadounidense de Psiquiatría.

En su artículo de 1944, como tradujo Uta Frith en 1991, Asperger escribió, estamos convencidos, por tanto, que las personas autistas tienen su lugar dentro del organismo de la comunidad social. Cumplen bien con su papel, puede que mejor de lo que cualquier otro pudiera, y estamos hablando de personas que cuando fueron niños tuvieron las mayores dificultades y causaron innumerables preocupaciones a sus cuidadores.

Eric Schopler escribió en 1998:Las publicaciones de Asperger no desencadenaron investigaciones, replicaciones, o interés antes de 1980. En su lugar, supusieron un fértil campo de cultivo para la confusión de diagnósticos que ha surgido desde 1980.

El cumpleaños de Asperger, el 18 de febrero, fue declarado como Día Internacional del Síndrome de Asperger.




</doc>
<doc id="42800" url="https://es.wikipedia.org/wiki?curid=42800" title="Enciclopedia Británica">
Enciclopedia Británica

La Enciclopedia Británica (en latín: Encyclopædia Britannica) es una enciclopedia en inglés de conocimiento general, editada por Encyclopædia Britannica, Inc., una empresa privada. Los artículos de la "Britannica" están dirigidos a lectores adultos, y están escritos por un conjunto de 100 editores a tiempo completo y cerca de 4000 contribuyentes expertos, que han incluido 110 ganadores del Premio Nobel y cinco presidentes de los Estados Unidos. Estos artículos son considerados generalmente precisos, fiables y bien redactados. Es ampliamente reconocida como la enciclopedia más "erudita" de todas las editadas en inglés.

La "Britannica" es la enciclopedia en inglés más antigua todavía en edición (aunque ya no se edite en papel). Su primera edición data entre 1768 y 1771, en Edimburgo, Escocia, y rápidamente obtuvo gran popularidad y tamaño, contando en su tercera edición en 1801 con 21 volúmenes. Su gran crecimiento ayudó a reclutar eminentes contribuyentes, por lo que la novena (1875-1889) y undécima edición (1911) fueron consideradas como las más famosas por su "erudición" y estilo literario. Empezando con la undécima edición, la "Britannica" gradualmente ha ido resumiendo y simplificando sus artículos para ampliar su mercado en Norteamérica. En 1933, se convirtió en la primera enciclopedia en adoptar una política de "revisiones continuas", en la cual la enciclopedia es continuamente reimpresa y cada artículo es actualizado con un programa regular.

El 13 de marzo de 2012, los editores de la Enciclopedia Británica anunciaron que dejaba de imprimirse en papel y que se centrarían en la edición web, que debutó en 1994.

La actual edición, la decimoquinta, tiene una estructura de tres partes únicas: una "Micropædia" de 12 volúmenes de artículos cortos (que generalmente contienen menos de 750 palabras), "Macropædia" de 17 volúmenes de artículos largos (que contienen entre 2 y 310 páginas) y una "Propædia" de un único volumen que proporciona un esquema jerárquico del conocimiento humano. La "Micropædia" está pensada para una búsqueda rápida de hechos y es una guía para la "Macropædia"; a los lectores se les recomienda estudiar el esquema de la "Propædia" para entender el contexto de una materia y encontrar otros artículos más detallados.

El tamaño de la "Britannica", a grandes rasgos, ha permanecido constante en los últimos setenta años, con cerca de 40 millones de palabras en quinientos mil temas. Aunque la publicación se realiza en Estados Unidos desde 1901, la enciclopedia ha mantenido su tradicional ortografía británica al escribir, por ejemplo, "labour" ("trabajo") en lugar del término estadounidense "labor".

En el transcurso de su historia, la "Britannica" ha tenido dificultades para cosechar beneficios económicos, un problema común entre muchas enciclopedias. Algunos artículos de ediciones pasadas han sido criticados por inexactitud, parcialidad, o por haber sido redactados por contribuyentes no suficientemente cualificados. Así mismo, la precisión de algunas partes de la edición vigente ha sido cuestionada; sin embargo, esas críticas han sido rechazadas por la administración de la enciclopedia.

La "Britannica" ha cambiado de manos en numerosas ocasiones; entre los anteriores propietarios se encuentran la editorial escocesa A & C Black, Horace Everett Hooper, Sears Roebuck and Company y William Benton. El actual propietario de la empresa Encyclopaedia Britannica, Inc. es Jacqui Safra, un millonario y actor suizo. Los recientes avances en la tecnología de la información y el auge de enciclopedias electrónicas, tales como "Microsoft Encarta" (actualmente no se edita) e Internet, han reducido la demanda de enciclopedias impresas. Para seguir siendo competitivos, Encyclopædia Britannica, Inc., ha hecho énfasis en la reputación de la "Britannica", reducido su precio y los costes de producción, y desarrollado versiones electrónicas en CD-ROM, DVD y en la Web. Desde principios de los años treinta, la empresa también ha promovido trabajos derivados como obras de referencia.

Producto de la ilustración escocesa, la "Britannica" fue publicada inicialmente en Edimburgo por Adam y Charles Black. A diferencia de la "L'Encyclopédie" (enciclopedia francesa), la "Britannica" era una publicación extremadamente conservadora. Las ediciones posteriores se dedicaron generalmente al monarca de turno. Para la octava y novena ediciones, su publicación se trasladó de Escocia a Londres y se asoció con el periódico "The Times" en los años 1870. En la undécima edición la publicación se asoció con la Universidad de Cambridge. La marca comercial y derechos de publicación fueron vendidos después de su undécima edición a Sears Roebuck and Company y se trasladó a Chicago (Estados Unidos), donde permanece. Su editor actual es Encyclopædia Britannica Inc.

Hacia el año 2004, la "Britannica" poseía 75.000 artículos con más de 44 millones de palabras. Cuenta con una plantilla de 19 editores y la colaboración de 4000 expertos. Se publica en papel (en 32 volúmenes, con un costo de 1400 US dólares), y aparece en Internet (con breves resúmenes de artículos visibles sin cargo y los textos completos disponibles por un precio de diez dólares mensuales o 60 dólares anuales), en CD-ROM o DVD-ROM (50 dólares). Actualmente la XI edición de la "Encyclopædia Britannica", de 1911, se encuentra en dominio público.

La "Britannica" se ha publicado en 15 ediciones oficiales, con varios volúmenes complementarios desde la 3.ª y 5.ª edición (véase el cuadro más abajo). Para ser exactos, la 10.ª edición es sólo un complemento de la 9.ª edición, al igual que la 12.ª y 13.ª edición se complementan con la 11.ª edición. La 15.ª edición se sometió a una masiva reorganización en 1985, pero la versión actualizada es todavía conocida como la 15.ª edición.

A lo largo de su historia, la "Británica" ha tenido dos objetivos: ser un excelente libro de referencia y proporcionar material didáctico para aquellos que desean estudiar. En 1974, la 15.ª edición adoptó un tercer objetivo: el de sistematizar todos los conocimientos humanos. La historia de "Britannica" se puede dividir en cinco grandes eras, marcadas por grandes cambios en la gestión o reorganización de la enciclopedia.

En la primera era (1.ª-6.ª edición, 1768-1826), la "Britannica" fue administrada por sus fundadores originales, Colin Macfarquhar y Andrew Bell, y, por algunas de sus amistades tales como Thomas Bonar, George Gleig y Archibald Constable. La "Britannica" fue publicada por primera vez entre 1768 y 1771 en Edimburgo como la "Encyclopædia Britannica, o, un diccionario de artes y ciencias, compilado en un nuevo plan". Fue vista como una reacción y una provocación a la "Encyclopédie" francesa de Denis Diderot (publicada entre 1751-1766), que a su vez se había inspirado en la inglesa Cyclopaedia "(Diccionario Universal de las Artes y las Ciencias)". "Britannica" fue principalmente una empresa escocesa, simbolizada por un cardo como logo, emblema floral de Escocia. El fundador de la enciclopedia fue uno de los más famosos representantes de la Ilustración escocesa. En esta era, "Britannica" pasó de ser un conjunto de tres volúmenes (1.ª edición) elaborado por un joven editor William Smellie a 20 volúmenes escritos por numerosas personalidades. Aunque varias otras enciclopedias, como "Rees's Cyclopaedia" y la "Encyclopaedia Metropolitana" de "Coleridge", compitieron con la "Britannica", estos competidores se fueron a la quiebra o dejaron de publicar debido a desacuerdos entre sus editores. Al final de esta era, la "Britannica" había creado una red de colaboradores ilustres, principalmente a través de amistades personales con los editores, en particular, Constable y Gleig.

Durante la segunda era (7.ª-9.ª ediciones, 1827-1901), la "Britannica" fue administrada por la editorial de Edimburgo, A & C Black. Aunque algunos colaboradores fueron reclutados por amistad personal con los redactores jefe, más notablemente Macvey Napier, otros fueron a la "Britannica" por su creciente reputación. A menudo los colaboradores venían de otros países e incluían a las más respetadas autoridades del mundo en sus respectivos campos. Un índice general fue incluido por primera vez en la 7.ª edición, una práctica mantenida hasta 1974. El primer redactor jefe inglés fue Thomas Spencer Baynes, quien supervisó la producción de la famosa 9.ª edición; comúnmente llamada "Scholar's Edition" "(Edición erudita)" por ser la edición de la "Britannica" más dirigida al público estudiantil. Sin embargo, a finales del siglo XIX, la 9.ª edición estaba desactualizada y la "Britannica" confrontaba serios problemas económicos.

En la tercera era (10.ª-14.ª ediciones, 1901-1973), la "Britannica" estuvo bajo administración de empresarios estadounidenses, quienes introdujeron una agresiva estrategia de expansión, sirviéndose del "marketing" y de ventas por correo, para de esa forma intentar incrementar las ganancias y la rentabilidad del producto. También simplificaron los artículos de la "Britannica", disminuyendo su contenido pero volviéndola más comprensible al público en general. La 10.ª edición fue producida rápidamente como un suplemento a la 9.ª, pero la edición que es reconocida por su excelencia es la 11.ª; su propietario Horace Hooper, destinó un enorme esfuerzo para perfeccionar tal edición. Cuando Hooper y la "Britannica" cayeron en dificultades financieras, la "Britannica" pasó a manos de Sears Roebuck durante 18 años (1920–1923, 1928–1943). En 1932, el vicepresidente de la cadena Sears, Elkan Harrison Powell, asumió la presidencia de la "Britannica"; en 1936, empezó una política de revisión continua (todavía practicada en la actualidad), en donde cada artículo es revisado y actualizado al menos dos veces cada década. Esta estrategia contrasta con la práctica anterior, donde los artículos no cambiaban hasta que fuera producida una nueva edición, aproximadamente cada 25 años; incluso había artículos que se copiaban sin cambios desde ediciones previas. Powell desarrolló agresivamente proyectos educacionales para mejorar la reputación de la "Britannica" en Estados Unidos. En 1943, la presidencia pasó a William Benton, quien administró la "Britannica" hasta su muerte en 1973. Benton también creó la Fundación Benton, la cual estuvo al mando de la "Britannica" hasta 1996. En 1968 la "Britannica" celebró su bicentenario.

En la cuarta era (15.ª edición, 1974-1994), la "Britannica" introdujo su 15.ª edición, la cual fue reorganizada en tres partes: la "Micropædia", la "Macropædia" y la "Propædia". Bajo la influencia de Mortimer Adler (miembro del comité de redacción de la Encyclopædia Britannica desde 1949, y su jefe desde 1974); y director de planeación editorial de la decimoquinta edición de la "Britannica" desde 1965), la "Britannica" empezó a buscar ser no solo una referencia y herramienta educacional, sino también a sistematizar "todo el conocimiento humano". La ausencia de un índice separado y la agrupación de artículos en dos enciclopedias paralelas (la "Micro-" y "Macropædia") provocó una "tormenta de críticas" a la 15.ª edición inicial.

En respuesta, la 15.ª edición fue completamente reorganizada e indexada para un relanzamiento en 1985. Esta segunda versión de la 15.ª edición continúa siendo publicada y revisada; la última versión es la de 2010. El título oficial de la 15.ª edición es "New Encyclopædia Britannica" ("la nueva Encyclopædia Britannica"), aunque también ha sido llamada "Britannica 3".

En la quinta era (1994-presente), se inició el desarrollo de versiones digitales de la "Britannica" las cuales son distribuidas a través de discos ópticos y a través de Internet. En 1996, la "Britannica" fue comprada a la Fundación Benton por Jacqui Safra, a un precio mucho menor al estimado, debido a las dificultades económicas de la compañía. La Encyclopædia Britannica, Inc. se dividió en 1999. Una parte retuvo el nombre de la compañía y siguió desarrollando la versión tradicional (impresa); la otra parte, Britannica.com Inc., desarrolló las versiones digitales. Desde 2001, estas dos compañías han compartido un solo director ejecutivo, que originalmente fue Ilan Yeshua, quien ha continuado la estrategia de Powell para el crecimiento de la "Britannica" introduciendo nuevos productos bajo la marca "Britannica". En marzo de 2012 anunció el fin de la edición de papel quedando sólo la edición digital.

La "Britannica" fue dedicada al monarca de Gran Bretaña reinante desde 1788 hasta 1901 y luego, debido a su venta a una sociedad norteamericana, al monarca británico y al presidente de los Estados Unidos. Consecuentemente, la decimoprimera edición es «dedicada con permiso a Su majestad Jorge V, rey de Gran Bretaña e Irlanda y los dominios británicos de ultramar, Emperador de India, y a William Howard Taft, presidente de los Estados Unidos de América». El orden de las dos dedicaciones ha ido cambiando junto con el poder relativo entre el presidente de los Estados Unidos y el monarca de Gran Bretaña, y con las ventas de "Britannica" en estos países; la versión de 1954 de la decimocuarta edición es «Dedicada con permiso a los jefes de estado de los dos pueblos de lengua inglesa, Dwight David Eisenhower, presidente de los Estados Unidos de América, y Su Majestad, Reina Isabel Segunda». Continuando con la tradición, la versión 2007 de la decimoquinta edición es «Dedicada con permiso al actual Presidente de los Estados Unidos de América, George W. Bush, y a Su Majestad Reina Isabel Segunda».

Desde la tercera edición, la "Britannica" ha recibido una reputación de excelencia. Varias ediciones, desde la tercera a la novena, fueron copiadas y vendidas sin autorización en los Estados Unidos dando comienzo a la Dobson's Encyclopædia (la cual consistía prácticamente en una copia de la tercera edición de la enciclopedia “Britannica”, con un estilo más patriótico, adaptado para lectores americanos). Para el lanzamiento de la decimocuarta edición, la revista "Time" honró a la "Britannica" llamándola "Patriarca de la Biblioteca". En un anuncio relacionado, el naturalista William Beebe era citado diciendo que la "Britannica" “estaba más allá de la comparación porque no hay competidor“. Se pueden encontrar varias referencias a la "Britannica" a lo largo de la literatura inglesa, la más notable en una de las historias de Sherlock Holmes favoritas de Arthur Conan Doyle, "La Liga de los Pelirrojos". Esta historia fue destacada por el "Lord Mayor" de Londres, Gilbert Inglefield, durante el bicentenario de la "Britannica".

La "Britannica" tiene la reputación de resumir todo el conocimiento humano.
Para expandir su educación, muchos se han dedicado a leer la "Britannica" por completo, empleando entre tres y veintidós años para lograrlo. Cuando Fat'h Ali se convirtió en el Shah de Persia en 1797, le regalaron un set completo de la tercera edición de la "Britannica", la cual leyó completamente en tres años; tras esta hazaña, extendió su título de realeza agregándole "El Más Formidable Señor Y Maestro de la "Encyclopædia Britannica"". El escritor George Bernard Shaw afirmó haber leído completamente la novena edición-exceptuando los artículos científicos-, Richard Evelyn Byrd tomó a la "Britannica" como material de lectura para su estadía de cinco meses en el Polo Sur en 1934, mientras Philip Beaver la leyó durante una expedición marina. Más recientemente, A.J. Jacobs, un editor de la revista "Esquire", leyó por completo la versión 2002 de la decimoquinta edición, describiendo sus experiencias en el bien acogido libro del 2004 "The Know-It-All: One Man's Humble Quest to Become the Smartest Person in the World". Sólo se sabe de dos personas que hayan leído dos ediciones independientes: el autor C. S. Forester y Amos Urban Shirk, un empresario estadounidense, quien leyó la decimoprimera y decimocuarta edición, dedicando tres horas por noche durante cuatro años y medio para leer la decimoprimera. Probablemente varios redactores jefe de la "Britannica" han leído sus ediciones completamente, como William Smellie (1.ª edición), William Robertson Smith (9.ª edición), y Walter Yust (14.ª edición).

La "Britannica" continúa siendo galardonada en la actualidad. La "Britannica" "online" ganó el Premio Codie por "El mejor servicio de información on-line al consumidor"; este premio es otorgado por la Software and Information Industry Association en reconocimiento a los mejores productos dentro de la categoría de software. En 2006 la "Britannica" fue nuevamente finalista. Igualmente la edición CD/DVD-ROM de la "Britannica" recibió en 2004 el "Distinguished Achievement Award de la Association of Educational Publishers", y el premio Codie en 2000, 2001 y 2002.

Como enciclopedia general, la "Britannica" busca describir el rango más amplio de temas posible. Los temas son escogidos para su referencia en la "Propædia" "Outline of Knowledge" ("Esquema del Conocimiento"). El porcentaje de artículos dedicados a los principales temas está distribuido así ("Macropædia"):
Un estudio complementario determinó que en la "Micropædia" los artículos de geografía suponían el 25 % de los artículos, ciencia el 18 %, ciencias sociales el 17 %, biografías el 17 %, y todas las demás humanidades el 25 % restante. En 1992, un revisor juzgó que el "alcance, la profundidad, y la catolicidad de la cobertura de la "Britannica" es insuperable por cualquier otra enciclopedia."

La "Britannica" no detalla los temas similares de forma equivalente; por ejemplo, el budismo y la mayor parte de las demás religiones están conjugadas en un solo artículo de la "Macropædia", cuando existen 14 artículos dedicados al cristianismo, que componen cerca de la mitad de los artículos sobre religión. Sin embargo, la "Britannica" ha sido elogiada como la menos parcial de las enciclopedias comercializadas en occidente y elogiada por sus biografías sobre mujeres importantes de todas las épocas.

La "Britannica" también ha recibido críticas, especialmente cuando sus ediciones iban quedando desactualizadas. Debido a los costes económicos a la hora de producir una edición completamente nueva de la "Britannica", sus editores generalmente demoran la actualización el mayor tiempo posible, siempre y cuando sea económicamente viable (usualmente veinticinco años). A pesar de la política de revisión continua, la decimocuarta edición se había vuelto muy desactualizada en treinta y cinco años (1929-1964). Cuando el físico norteamericano Harvey Einbinder detalló sus faltas en su libro de 1964, "The Myth of the Britannica", la enciclopedia decidió lanzar la decimoquinta edición, la cual requirió de diez años de trabajo. Es difícil mantener a la "Britannica" actualizada; un crítico reciente escribió, “No es difícil encontrar artículos desactualizados o que necesitan revisión”, resaltando que los artículos más largos de la "Macropædia" probablemente están más desactualizados que los más cortos de la "Micropædia". La información en la "Micropædia" es a veces inconsistente con respecto a los artículos de la "Macropædia", debido a la falta de actualización en alguno de los dos. Las bibliografías de los artículos de la "Macropædia" han sido criticados por estar más desactualizados que los artículos mismos.
Diferentes autoridades que van desde Virginia Woolf hasta profesores académicos criticaron la 11.ª edición de la "Británica" por tener opiniones burguesas y arcaicas sobre el arte, la literatura y las ciencias sociales. Por ejemplo, se la recriminó no tratar el trabajo de Sigmund Freud. Un profesor contemporáneo de la Universidad Cornell, Edward B. Titchener, escribió en 1912, "la nueva "Britannica" no reproduce la atmósfera psicológica de su día y generación [..] A pesar del halo de autoridad y de los controles del personal, la mayor parte de los artículos secundarios de psicología general no está adaptados a los requisitos del lector inteligente."

A la "Britannica" se la crítica ocasionalmente por las decisiones tomadas por sus editores. Debido a su tamaño aproximadamente constante, la enciclopedia ha necesitado reducir o eliminar alguno de sus temas para acomodar otros, tomando algunas decisiones controvertidas. La versión inicial de la decimoquinta edición (1974-1985) fue reprochada por haber reducido drásticamente o eliminado su cobertura de literatura infantil, condecoraciones militares, y al poeta francés Joachim du Bellay; también se denunciaron otros errores editoriales, como la inconsistente ordenación de las biografías japonesas. La eliminación del índice fue condenada, como lo fue la división aparentemente arbitraria de artículos entre la "Micropædia" y la "Macropædia". Resumiendo, un crítico llamó a la decimoprimera edición inicial como un "fallo con matices… a la que le importa más jugar con su formato que preservar la información." Más recientemente, los revisores de la American Library Association se sorprendieron al encontrar que la mayoría de los artículos de educación fueron eliminados de la "Macropædia" de 1992, junto con el artículo sobre psicología.

Algunos contribuyentes de la "Britannica" se equivocan ocasionalmente, o no son científicos. Un caso notorio en los primeros años de la "Britannica" fue el rechazo de la teoría de la gravitación universal de Newton por parte de George Gleig, el redactor jefe de la 3.ª edición (1788-1797), quien escribió que la gravedad era causada por el elemento fuego. Sin embargo, la "Britannica", ha defendido el acercamiento científico a temas emotivos, como hizo William Robertson Smith en sus artículos sobre religiones en la novena edición, particularmente afirmando que la Biblia no era históricamente exacta (1875).

Los críticos han acusado a ediciones pasadas de la "Britannica" de presentar racismo y sexismo. La decimoprimera edición de 1911 describe al Ku Klux Klan como protector de la raza blanca y con un papel restablecedor del orden en el sur de EE.UU. tras la guerra civil estadounidense, citando la necesidad de "controlar a la raza negra", para "impedir cualquier mezcla de razas" y "la frecuente ocurrencia de violaciones por parte de hombres negros a mujeres blancas". De igual manera, el artículo sobre "Civilización" argumenta a favor de la eugenesia, comenzando con que es irracional “propagar los niveles bajos de inteligencia, incrementar las filas de los pobres, discapacitados y criminales… que hoy constituyen un obstáculo tan amenazador al progreso racial." La decimoprimera edición no tiene biografía de Marie Curie, a pesar de que ella ganó el Premio Nobel de Física en 1903 y el Premio Nobel de Química en 1911 (el mismo año de la publicación), aunque se la menciona brevemente en la biografía de su esposo Pierre Curie.

En 1912 el matemático Louis Charles Karpinski criticó a la "edición de 1911" por sus inexactitudes en sus artículos sobre historia de la matemática, ninguno de los cuales había sido escrito por especialistas en la materia. En 1917, el crítico Willard Huntington Wright publicó un libro, "Misinforming a Nation" ("Desinformando a una nación"), que resaltaba las inexactitudes y el sesgo inglés de la "decimoprimera edición", particularmente de los artículos de humanidades. Muchas de las críticas de Wright fueron arregladas en ediciones posteriores de la "Britannica". Sin embargo, su libro fue denunciado como polémico por sus contemporáneos; por ejemplo, el "New York Times" escribió "rencor y poca templanza... impregna el libro", mientras el "New Republic" opinó: "es desafortunado para el propósito rencoroso del Sr. Wright que procediera con un espíritu acientífico y dando tan poca justificación objetiva de sus críticas." Otro crítico, el editor inglés y exsacerdote Joseph McCabe alegó, en su libro "Lies and fallacies of the Encyclopaedia Britannica" ("Mentiras y falacias de la Encyclopaedia Britannica", 1947) que luego de la 11.ª edición la "Britannica" fue censurada bajo presión de la Iglesia católica.

La "Britannica" siempre ha reconocido que los errores son inevitables en una enciclopedia. Hablando de su 3.ª edición (1788-1797), su redactor jefe George Gleig escribió "la perfección parece ser incompatible con la naturaleza de los trabajos construidos bajo tal plan, y que abarca tal variedad de temas". Más recientemente (en marzo de 2006), la "Britannica" escribió "no queremos dar a entender que "Britannica" esté libre de errores; nunca hemos hecho tal afirmación." 

Desde 1985, "Britannica" está estructurada en cuatro partes: la Micropædia, la Macropædia, la Propædia y un índice en dos volúmenes. Los artículos propiamente dichos se encuentran en la "Micro" y la "Macropædia", abarcando 12 y 17 volúmenes respectivamente, teniendo cada uno de los volúmenes alrededor de mil páginas. La "Macropædia" de la edición de 2007 desarrolla 699 artículos en profundidad, extendiéndose cada uno de ellos entre 2 y 310 páginas, junto con las referencias y el nombre de los colaboradores. En cambio, la "Micropædia" consta de aproximadamente 65.000 artículos, la inmensa mayoría (sobre el 97 %) con menos de 750 palabras, y no contienen ni referencias ni el nombre de los colaboradores. Los artículos de la "Micropædia" tienen como función ser utilizados para una rápida comprobación de hechos y para la ayuda en la búsqueda de más información a través de la "Macropædia". Los artículos de la "Macropædia" se suponen fidedignos y un almacén de información no cubierta en ningún otro sitio. El artículo más extenso (310 páginas) es el de Estados Unidos, y resultó de la unión de cada uno de los artículos de los diferentes estados.

Los contenidos y la información de la "Britannica" se puede encontrar siguiendo las referencias cruzadas existentes tanto en la "Micropædia" como en la "Macropædia"; sin embargo, estas son escasas, habiendo como promedio sólo una por página. De ahí que a los lectores de la enciclopedia se les recomiende consultar en su lugar el índice alfabético o la "Propædia", que organiza la enciclopedia "Britannica" por temas.

El núcleo de la "Propædia" es su "Esquema del Conocimiento" que pretende dar un marco lógico de todo el conocimiento humano. Como consecuencia, este "Esquema" es consultado por los editores de "Britannica" para decidir qué artículos deben ser incluidos en la enciclopedia. El esquema tiene también la intención de ser una guía de estudio, poner los temas en una perspectiva adecuada y sugerir un listado de artículos para aquellas personas que deseen estudiar un tema en profundidad. Sin embargo, las bibliotecas afirman que se usa poco, y hay incluso críticos que han recomendado su exclusión de la enciclopedia. La "Propædia" también contiene transparencias a color de la anatomía humana y numerosos apéndices enumerando a los miembros del personal, asesores y colaboradores de las tres partes de la enciclopedia.

Juntas, la "Micropædia" y la "Macropædia" contienen hasta 40 millones de palabras y 24.000 imágenes. El índice en dos volúmenes tiene 2350 páginas listando los 228.274 temas cubiertos por la "Britannica" y las 474.675 subentradas bajo esos temas.

La enciclopedia normalmente utiliza inglés británico en lugar de inglés estadounidense. Por ejemplo, usa "colour" y no "color" ("color" en castellano), "centre" y no "center" ("centro" en castellano) y "encyclopaedia" pero no "encyclopedia" ("enciclopedia" en castellano); sin embargo, en algunas ocasiones no es así, como por ejemplo en "defense" en lugar de "defence" ("defensa" en castellano). A pesar de todo ello, en las entradas se proporcionan referencias a los deletreos alternativos comunes de la palabra, de la forma ""Color": see "Colour"".

Desde 1936, los artículos de la "Encyclopædia Britannica" se revisan regularmente, siendo como mínimo el 10% del total de ellos revisado cada año. De acuerdo con la página web de "Britannica" en 2007, el 46% de sus artículos habían sido revisados en los últimos tres años; sin embargo, de acuerdo con otra página web sobre la misma enciclopedia solo lo habían sido el 35%.

El orden alfabético de los artículos contenidos en la enciclopedia sigue reglas estrictas. Se ignoran tanto signos diacríticos como letras no existentes en el alfabeto inglés, las entradas numéricas se ordenan como si el número estuviese escrito (la entrada "1812, War of" habría que buscarla como si buscásemos "Eighteen-twelve, War of"). Los artículos con nombre idéntico están ordenados primero si hacen mención a personas, luego a lugares y por último a cosas. Los gobernantes con mismo nombre están organizados primero alfabéticamente por país y luego por cronología. Así, "Charles III of France" (Carlos III de Francia), va antes que "Charles I of England" (Carlos I de Inglaterra), ya que este último está listado como rey de Reino Unido e Irlanda, "Great Britain and Ireland" en inglés, que es alfabéticamente posterior a "France", ("Francia" en español). De la misma manera, los lugares que comparten denominación están organizados alfabéticamente por país y sucesivamente por divisiones territoriales cada vez menores.

Existen numerosas versiones abreviadas de la enciclopedia "Britannica". La más importante de todas ellas es la "Britannica Concise Encyclopædia" que consta de un solo volumen y contiene 28.000 artículos cortos condensando los 32 volúmenes de la "Encyclopædia Britannica" original.

"Compton's by Britannica", publicada por primera vez en 2007, parte de la antigua "Compton's Encyclopedia" cuyos derechos de publicación fueron adquiridos en esa fecha por "Encyclopædia Britannica", y está dirigida a adolescentes de entre 10 y 17 años, y consta de 26 volúmenes y 11.000 páginas.

Una enciclopedia para niños, "Children's Britannica", fue publicada por la oficina de Londres en 1960, su editor fue John Armitage y estaba dedicada al príncipe de Gales que contaba por aquel entonces con 12 años. Los colaboradores fueron en su gran mayoría británicos y los asesores editoriales fueron "El Director, personal y estudiantes de la Escuela de Primaria William Austin, en Luton, Bedfordshire".

También existen "My First Britannica" orientada a edades entre 6 y 12 años y "Britannica Discovery Library" para entre 3 y 6 (publicada entre 1974 y 1991).

Desde 1938, la empresa Encyclopædia Britannica, Inc. publica anualmente un libro con los hechos más destacados del año anterior. Además, son accesibles en Internet las publicaciones desde la edición de 1994. La compañía también publica numerosos trabajos especializados tales como "Shakespeare: The Essential Guide to the Life and Works of the Bard" (Wiley, 2006).

La Editorial Carenzo (Chile), ha lanzado una versión promocional de la "Britannica Concise Encyclopædia" en castellano para América Latina. Esta edición está autorizada por Encyclopædia Britannica Inc. (estando basada en su menor pero también notable "Enciclopedia Hispánica"), y según la misma editorial cumple con los mismos estándares de calidad que la edición inglesa de la Enciclopedia Británica, ya que esta edición en español habría sido revisada por los mismos editores de la edición en inglés de la Enciclopedia Británica.

Esta colección promocional consta de 20 tomos, con alrededor de 24.000 entradas y 4800 fotografías, características similares a la "Britannica Concise Encyclopædia". En Chile esta colección es ofrecida junto al periódico "El Mercurio". Otro tanto ocurre en el Perú, donde se oferta una edición semejante junto con el diario "El Comercio". En Paraguay esta edición promocional es distribuida con el diario "La Nación".

"Britannica Ultimate Reference Suite 2006 DVD" contiene más de 55 millones de palabras y algo más de 100.000 artículos. Esto incluye 73.645 artículos de la "Britannica" clásica, mientras que el resto fue obtenido de la "Britannica Student Encyclopædia", la "Britannica Elementary Encyclopædia" y la "Britannica Book of the Year" (1993–2004), además de unos pocos artículos "clásicos" de ediciones anteriores de la enciclopedia. El DVD contiene también un abanico de contenidos complementarios como mapas, videos, cortes de audio, animaciones y enlaces web. También incluye herramientas de estudio, diccionario y entradas del Tesauro del Merriam-Webster.

"Encyclopædia Britannica Online" es una página web con más de 120.000 artículos actualizados regularmente. Tiene artículos diarios, actualizaciones y enlaces al periódico en línea "The New York Times" y a la página web de la BBC. Existen subscripciones semanales, mensuales y anuales. Además, también hay disponibles suscripciones especiales que se ofrecen a escuelas, institutos y bibliotecas. Este tipo de subscripciones institucionales suponen una parte importante del negocio de la Enciclopedia. Aproximadamente el 60% de los ingresos de la enciclopedia provienen de operaciones en la página web de las cuales el 15% son de suscripciones a la propia página web.

Los artículos son accesibles en internet gratuitamente pero este acceso gratuito únicamente permite visualizar las primeras líneas de cada artículo. A principios de 2007, "Britannica" empezó a hacer que los artículos fuesen completamente accesibles si estaban enlazados desde alguna otra página web debido a que este tipo de enlaces externos mejoran la posición del artículo en los motores de búsqueda de internet.

El 3 de junio de 2008, se anunció una iniciativa que permitía y facilitaba la colaboración entre expertos en los temas a tratar y expertos en temas en línea para desarrollar el contenido de Britannica en su página web, todo ello bajo un control por parte del personal de la enciclopedia. Se reconocería a los autores de las contribuciones pero su publicación da una licencia perpetua e irrevocable a Encyclopædia Britannica, Inc. sobre esas contribuciones El 22 de enero de 2009, el presidente de Britannica, , anunció que la compañía aceptaría ediciones y añadidos en su enciclopedia en línea por parte del público en general aunque como condición se exige un registro con nombre real y la dirección del contribuyente. Todas las ediciones y aportaciones son revisadas y tienen que ser aprobadas por el personal profesional de la compañía. Este tipo de contribuciones, las de los usuarios no académicos, se encontrarán en una sección aparte del contenido aportado por los expertos contratados por "Britannica", de la misma manera que serán clasificadas las contribuciones por partes de expertos ajenos a la empresa. Los artículos creados e iniciados por usuarios, después de ser revisados y aprobados, también serán solo accesibles en una sección especial de la web, separada de los artículos generados por los profesionales contratados para ello. El material oficial de "Britannica" llevará un sello en el que diga ""Britannica checked"" para diferenciarlo del material aportado por los usuarios de la web. A pesar de todas las aportaciones de contenido que pudiera haber por este medio, la edición impresa de la enciclopedia no se verá afectada.

El 13 de marzo de 2012, la Enciclopedia anunció en su página web que dejaba de editarse en papel, tras 244 años. La edición de 2010 fue la última impresa, de la que se han vendido únicamente 8000 ejemplares en todo el mundo. En adelante se centrarán en la edición web de la enciclopedia.

La versión impresa de 2007 cuenta con 4411 colaboradores, muchos de ellos eminencias en sus respectivos campos, como por ejemplo el Premio Nobel de Economía Milton Friedman, el astrónomo Carl Sagan y el cirujano Michael DeBakey. Aproximadamente un cuarto del total de colaboradores han fallecido en la actualidad mientras que otro cuarto están retirados o son eméritos.

La mayoría (aproximadamente el 98%) contribuyen a un único artículo; sin embargo, en esta edición de 2007, 64 lo hacen en tres, 23 en cuatro de ellos, 10 aportan en cinco artículos y 8 en más de cinco. Cabe destacar una colaboradora especialmente prolífica, la Doctora Christine Sutton, de la Universidad de Oxford, que aporta en 24 artículos relacionados con Física de partículas.

Dale Hoiberg, un sinologista, es Vicepresidente Senior y redactor jefe de "Britannica". Entre sus predecesores como redactor jefe se encuentran Hugh Chisholm (1902-1924), James Louis Garvin (1926-1932), Franklin Henry Hooper (1932-1938), Walter Yust (1938-1960), Harry Ashmore (1960-1963), Warren E. Preece (1964-1968, 1969-1975), Sir William Haley (1968-1969), Philip W. Goetz (1979-1991), y Robert McHenry (1992-1997). Anita Wolff y Theodore Pappas son los actuales segundo editor y editor ejecutivo respectivamente. Algunos editores ejecutivos anteriores fueron John V. Dodge (1950-1964) y Philip W. Goetz.

La enciclopedia mantiene una plantilla editorial de cinco editores senior y nueve editores asociados, supervisados por Dale Hoiberg y otras cuatro personas. El personal editorial también ayuda en la construcción de artículos en la "Micropædia" y en algunas secciones de la "Macropædia".

"Britannica" tiene un consejo editorial de consulta, en el cual están incluidos 12 distinguidas eminencias:

En enero de 1996, la "Britannica" perteneciente a la Benton Foundation fue comprada por el multimillonario financiero suizo Jacqui Safra, quien se desempeña como actual presidente de la junta. En 1997, Don Yannias, asociado desde hace mucho tiempo y asesor de inversiones de Safra, se convirtió en CEO de la Encyclopædia Britannica, Inc. Una nueva compañía, Britannica.com Inc. se separó en 1999 para desarrollar la versión digital de la "Britannica"; Yannias asumió el papel de CEO de la nueva compañía, mientras que la Encyclopædia Britannica, Inc. permaneció vacante durante dos años. La permanencia de Yannia en Britannica.com Inc. fue marcada por errores, muchos despidos y pérdidas financieras. En 2001, Yannias fue reemplazado por Ilan Yeshua, que reunió a los dirigentes de las dos compañías. Yannias más tarde regresó a la gestión de inversiones, pero permanece en la Junta de Directores de "Britannica".

En 2003, el exconsultor de gestión Jorge Cauz fue nombrado presidente de la Encyclopædia Britannica, Inc. Cauz es el ejecutivo principal e informa directamente a la Junta de Directores de "Britannica". Cauz ha estado buscando alianzas con otras empresas y ampliar la marca "Britannica" a los nuevos productos educativos y de referencia, continuando con la estrategia iniciada por el exdirector general Elkan Harrison Powell en la década de 1930.

Bajo la propiedad de Safra, la compañía ha experimentado dificultades financieras, y ha respondido al reducir el precio de sus productos y la aplicación de drásticos recortes de costos. Según un informe de 2003 en el New York Post la administración de "Britannica" ha eliminado los empleados 401(k) y fomentado el uso de imágenes de forma gratuita. Estos cambios han tenido efectos negativos, como colaboradores independientes que han esperado hasta seis meses para los controles y el personal de britannica ha pasado años sin aumentos salariales.

Encyclopædia Britannica, Inc. ahora es dueño de marcas registradas sobre las palabras "Britannica", "Encyclopædia Británica", "Macropædia", "Micropædia" y "Propædia", así como en su logotipo cardo. Ha ejercido sus derechos de marca tan recientemente como en 2005.

Como la "Britannica" es una enciclopedia en general, no busca competir con las enciclopedias especializadas, tales como la "Enciclopedia de las matemáticas" o el "Diccionario de la Edad Media", que puede dedicar mucho más espacio para sus temas elegidos. En sus primeros años, el principal competidor de la "Britannica" fue la enciclopedia general de Ephraim Chambers y, poco después, la "Enciclopedia" de Rees y la "Enciclopedia Metropolitana" de Coleridge. En el siglo XX, los competidores exitosos incluyen Enciclopedia Collier, la Enciclopedia Americana, y la World Book Encyclopedia. Sin embargo, a partir de la 9 ª edición, la "Britannica" fue ampliamente considerada poseedora de la mayor autoridad en general de cualquier enciclopedia de idioma inglés, sobre todo debido a su amplia cobertura y autores eminentes. La versión impresa de la "Britannica" es significativamente más cara que sus competidores.

Desde principios de 1990, la "Britannica" se ha enfrentado a nuevos retos de las fuentes de información digital. La Internet, facilitado por el desarrollo de motores de búsqueda, se ha convertido en una fuente común de información para muchas personas, y ofrece fácil acceso a fuentes confiables y opiniones de expertos, en parte gracias a iniciativas como Google Libros, el lanzamiento del material educativo de la MIT y PubMed Central de la Biblioteca Nacional de Medicina. En general, Internet tiende a proporcionar una cobertura más actualizada que la prensa escrita, debido a la facilidad con que puede conseguirse material en Internet actualizado. En los campos rápidamente cambiantes, como la ciencia, la tecnología, la política, la cultura y la historia moderna, la "Britannica" ha luchado para mantenerse al día, un primer problema analizado de forma sistemática por su exeditor Walter Yust. A pesar de que la "Britannica" se encuentra disponible tanto en formato multimedia como en Internet, su supremacía está siendo desafiada por otras enciclopedias online, como Wikipedia.

La Enciclopedia Británica ha sido comparada con enciclopedias de impresión, tanto cualitativa como cuantitativamente. Una comparación muy conocida es la de Kenneth Kister, quien hizo una comparación cualitativa y cuantitativa de la Enciclopedia Británica, con dos enciclopedias comparables, la "Enciclopedia Collier" y la "Enciclopedia Americana". Para el análisis cuantitativo, diez artículos fueron seleccionados al azar (la circuncisión, Charles Drew, Galileo, Philip Glass, enfermedades del corazón, inteligencia, oso panda, el acoso sexual, Sudario de Turín y Uzbekistán) y las calificaciones en letras de la A, D o F se otorgaron en cuatro categorías: cobertura, precisión, claridad y novedad. En las cuatro categorías y para las tres enciclopedias, los cuatro grados promedio se redujo entre B- y B+, principalmente porque ninguna de las enciclopedias publicó un artículo sobre el acoso sexual en 1994. En la categoría de precisión, la "Britannica" recibió una "D" y siete "A"s, la "Enciclopedia Americana" recibió ocho "A"s, y Collier recibió una "D" y siete "A"s, por lo que la "Britannica" recibió una puntuación media de 92% de precisión, la "Americana" 95% y Collier 92%. La "Britannica" de 1994 fue criticada por publicar una historia sobre Charles Drew enardecedora, que desde hace mucho tiempo había sido desacreditada. En la categoría de la puntualidad, la "Britannica" obtuvo un promedio de un 86%; la "Americana", un 90%; y "Collier", 85%. Después de una comparación cualitativa más profunda de las tres enciclopedias, Kister recomienda la "Enciclopedia Collier" como la enciclopedia superior, sobre todo en la fuerza de su excelente redacción, presentación equilibrada y de fácil navegación.

La "Collier" no se halla en forma impresa desde 1998. La "Enciclopedia Americana" fue publicada por última vez en 2006. La "Britannica" fue publicada por última vez en 2010.

El competidor más notable de la "Britannica" entre enciclopedias digitales en CD / DVD-ROM era "Encarta", ahora suspendido, una enciclopedia moderna, multimedia que incorpora tres enciclopedias de impresión: Funk & Wagnalls, Collier y el New Merit Scholar. "Encarta" fue la más vendida de las enciclopedias multimedia, basado en las ventas totales en EE. UU. desde enero de 2000 a febrero de 2006. Ambos ocuparon la misma gama de precios, con la "2007 Encyclopædia Britannica Ultimate" CD o DVD costando US$50 y la "Microsoft Encarta Premium 2007" DVD US$45. La Enciclopedia Británica contiene 100.000 artículos y el "Diccionario Merriam-Webster y sinónimos" (solo en EE.UU.), y ofrece ediciones de primaria y secundaria. "Encarta" contiene 62.000 artículos, un navegador visual fácil de usar, herramientas de mapas interactivos, matemáticas, lenguaje y las tareas escolares, un diccionario de EE.UU. y el Reino Unido, y una edición de la juventud. Como "Encarta", la Enciclopedia Británica ha sido criticada por su sesgo hacia los Estados Unidos; en el Reino Unido los artículos se actualizan con menos frecuencia, los mapas de los Estados Unidos son más detalladas que las de otros países, y carece de un diccionario del Reino Unido. Al igual que la Enciclopedia Británica, "Encarta" estaba disponible en línea por suscripción, aunque algunos contenidos se podía acceder de forma gratuita.

Entre las alternativas online a la "Britannica" incluye Wikipedia, una enciclopedia web con contenido libre. Una diferencia clave entre las dos enciclopedias se encuentra en la autoría del artículo. Los 699 artículos Macropædia son generalmente escritos por colaboradores que están identificados, y los cerca de 65.000 artículos Micropædia son el trabajo de la redacción y consultores externos que también están identificados. Por lo tanto, un artículo de "Britannica" o bien tiene una autoría conocida, o bien un conjunto de posibles autores (el equipo editorial). Con la excepción de la redacción, la mayoría de los colaboradores de la Enciclopedia Británica son expertos en su campo, algunos son premiados con el Nobel. Por el contrario, los artículos de Wikipedia son escritos por una comunidad de editores con diferentes niveles de experiencia: la mayoría de los editores no pretenden ninguna experiencia particular, de los que lo hacen, muchos son anónimos y no tienen credenciales verificables. Otra diferencia es el ritmo del cambio del artículo: la Enciclopedia Británica publicado en forma impresa se actualiza cada pocos años, mientras que los artículos de Wikipedia es probable que actualicen con frecuencia. Robert McHenry, redactor de la Enciclopedia Británica, dijo que Wikipedia no puede aspirar a competir con esta en precisión.

El 14 de diciembre de 2005, en un estudio, la revista "Nature" escogió los artículos de ambos lugares en una amplia gama de temas y los envió a lo que calificó de "relevante" a expertos en la materia para su revisión. Los expertos comparan los artículos —uno de cada sitio en un determinado tema— al lado del otro, pero no dijeron qué artículo provino de qué sitio. "Nature" devolvió 42 comentarios útiles de su ámbito de expertos.

Al final, la revista encontró sólo ocho errores graves, como equívocos en general de los conceptos vitales, en los artículos. De ellos, cuatro vinieron de cada sitio. Ellos, sin embargo, descubrieron una serie de errores fácticos, omisiones o declaraciones engañosas. En total, Wikipedia tenía 162 problemas, mientras que en "Britannica" había 123.

El promedio es de 2.92 errores por artículo de Britannica y 3.86 para la Wikipedia. En su detallada refutación de 20 páginas, Encyclopædia Britannica, Inc. caracteriza el estudio publicado en la revista "Nature" como deficiente y engañoso y pidió una "pronta" retracción. Señaló que dos de los artículos en el estudio fueron tomadas de un anuario de "Britannica", y no de la enciclopedia, y otros dos fueron de la "Enciclopedia de Compton" (llamado la "Enciclopedia Britannica Student" en el sitio web de la compañía). La réplica llegó a mencionar que algunos de los artículos presentados a los encuestados eran combinaciones de varios artículos, y otros artículos que no eran más que fragmentos, pero fueron sancionados por omisión de hechos. La compañía también señaló que varios hechos clasificados como errores de "Nature" eran pequeñas variaciones de ortografía, y que varios de sus supuestos errores fueron materia de interpretación. "Nature" defendió su historia y se negó a retractarse, indicando que, como se compara a Wikipedia con la versión web de la Britannica, que utiliza cualquier material relevante disponible en sitio web de la Enciclopedia Británica.

Entrevistado en febrero de 2009, el director gerente de "Britannica", dijo: 

La Barsa, fundada en Brasil en 1949, hoy pertenece al grupo español Planeta. Aunque su contenido sea oriundo de la matriz original, la marca acabó adquiriendo una identidad propia, al punto de tornarse la más importante enciclopedia lusófona. Fue editada en el país sobre los auspicios de la "Encyclopaedia Britannica de Brasil Publicações Ltda." En la década de 1970, bajo la dirección del Inmortal de la ABL, Antonio Houaiss, lanzó la Enciclopedia Mirador Internacional

Algunos productos tuvieron corta existencia debido a la evolución tecnológica, como fue el caso de la "Videopedia". Dentro de los principales productos de Barsa están:

Compuesta de tres medios distintos, la enciclopedia posee actualizaciones semanales por Internet, a través de su sitio. Posee un “Consejo Académico” del cual forman parte catorce universidades.

Posee más de 122 mil entradas, de los cuales 500 son desarrollados para concentrar las informaciones temáticas, ilustrada en más de diez mil fotografías, 900 dibujos, 500 mapas y 300 tablas


La Barsa Society posee diversos lanzamientos en varios medios. Son productos como libros de Derecho, Enciclopedia Multimedia del Cuerpo humano (en 6 CD-ROM), traductores etc.

La Barsa está presente en varios países de idioma español, como Argentina, Chile, España, México y Venezuela y también en Portugal.









</doc>
<doc id="42813" url="https://es.wikipedia.org/wiki?curid=42813" title="Colonización de los Estados Unidos">
Colonización de los Estados Unidos

El período del descubrimiento de los Estados Unidos es una etapa histórica de varios siglos en los que se produjeron sucesivos cambios. Comprende el período desde la llegada de los primeros inmigrantes europeos al continente americano, a finales del sigloXV; hasta finales del sigloXVIII. Las oleadas de inmigrantes británicos que arribaron fundaron allí las Trece Colonias, que consagrarían su independencia política de la corona británica en el año 1776.

América fue descubierta -para los europeos- el 12 de octubre de 1492 por la expedición del navegante Cristóbal Colón al servicio de la Corona de Castilla. Estaba compuesta por tres naves, llamadas La Niña, La Pinta y La Santa María, referidas como carabelas en la orden del Concejo de Andalucía de Santa Fe el 30 de abril de 1492. A lo largo del siglo XV y el siguiente, la conquista española de los territorios americanos abarcó el Caribe, Centroamérica, Sudamérica y, en Norteamérica, los territorios del oeste hasta Alaska y Florida en el sudeste, territorios a los que se agregó en 1763 la Luisiana tras el Tratado de París, región que comprendía más de doce mil kilómetros de norte a sur.
Juan Ponce de León dio nombre a La Florida en 1513, cuando la tomó en nombre de la Corona de España. Hasta 1563, los españoles enviaron varias expediciones para explorarla, pero no llegaron a levantar ninguna fortificación estable. Sin embargo, la presencia en 1564 de un nutrido contingente de hugonotes franceses, que alzaron un fuerte en la desembocadura del río San Juan, supuso una seria amenaza que llevó a España a la decisión de establecer una presencia militar permanente en el área. El 28 de agosto de 1565, Pedro Menéndez de Avilés funda la ciudad de San Agustín. Es el asentamiento europeo más antiguo ocupado hoy en EE.UU. Solo San Juan (Puerto Rico) lo supera como ciudad más antigua de "los Estados Unidos".
En 1583, la Reina Isabel I de Inglaterra otorga una autorización al pirata Walter Raleigh para fundar una colonia al norte de La Florida, a la que llamaría Virginia, y que abarcaría más tarde las actuales Carolina del Sur, Carolina del Norte, Virginia, Virginia Occidental y Maine. Rápidamente se vio la posibilidad de explotar la zona con cultivos de tabaco, por lo que se creó en 1606 la Compañía de Virginia como sociedad anónima, que financió el primer establecimiento inglés.

En 1607, un grupo de colonizadores ingleses fundó una pequeña aldea en Jamestown (Virginia). Portadores de una cédula del Rey Jaime I de Inglaterra, fundaron una colonia permanente en los primeros siete meses después de su llegada. La colonia creció con el tiempo y prosperó con el cultivo de tabaco, cuyo primer envío a Inglaterra fue en 1614.
En Nueva Inglaterra, región nororiental del actual Estados Unidos, los puritanos ingleses establecieron varias colonias. Llegaron a América pensando que la Iglesia de Inglaterra había adoptado demasiadas prácticas del catolicismo. Su propósito era fundar una colonia basada en sus propios ideales religiosos. Un grupo de puritanos, conocidos como los peregrinos, cruzaron el Atlántico en un barco llamado Mayflower y se establecieron en Plymouth en 1620. Una colonia puritana mucho más grande se estableció en la zona de Boston en 1630. Para 1635, algunos colonizadores ya estaban emigrando a la cercana Connecticut.

Nueva Inglaterra también estableció otra tradición: una moralidad con frecuencia intolerante. Los puritanos creían que los gobiernos debían hacer cumplir la moralidad de Dios. Castigaban severamente a los bebedores, a los adúlteros, a los violadores del Séptimo Día y a los herejes. En las colonias puritanas, el derecho de voto se limitaba a los miembros de la Iglesia y los salarios de los ministros se pagaban de los impuestos.
Roger Williams, un puritano que no estaba de acuerdo con las decisiones de la comunidad, sostuvo que el Estado no debía intervenir en cuestiones religiosas. Obligado a salir de Massachusetts en 1635, fundó la vecina Colonia de Rhode Island y las Plantaciones de Providence, que garantizaban libertad religiosa y la separación entre Estado e Iglesia. Las colonias de Maryland (fundada en 1634 como refugio para católicos) y Pensilvania (fundada en 1681 por el dirigente cuáquero William Penn) también se caracterizaron por su tolerancia religiosa. Esta tolerancia, a su vez, atrajo a otros grupos de colonos al Nuevo Mundo.

Con el paso del tiempo, las colonias británicas de América del Norte recibieron a muchos grupos de origen no británico: los agricultores alemanes se establecieron en Pensilvania; los suecos fundaron la colonia de Delaware; y los primeros esclavos africanos llegaron a Virginia en 1619. En 1626, colonos neerlandeses compraron la isla de Manhattan a los jefes indígenas de la región y erigieron la ciudad de Nueva Ámsterdam; en 1664, los ingleses se hicieron con la colonia y la rebautizaron como Provincia de Nueva York.

En el año 1770 ya habían surgido varios centros urbanos pequeños pero en proceso de expansión y cada uno de ellos contaba con periódicos, tiendas, comerciantes y artesanos. Filadelfia, con , era la ciudad más grande, seguida por Nueva York, Boston y Charleston. A diferencia de la mayor parte de las demás naciones, Estados Unidos jamás tuvo una aristocracia feudal. En la era colonial la tierra era abundante y la mano de obra escasa, por lo que todo hombre libre tenía la oportunidad de alcanzar, si no la prosperidad, al menos la independencia económica.

Todas las colonias compartían la tradición del gobierno representativo. El monarca británico nombraba a muchos de los gobernadores coloniales, pero todos ellos debían gobernar conjuntamente con una asamblea elegida. El voto estaba restringido a los terratenientes varones blancos, pero la mayoría de los hombres blancos tenían suficientes propiedades para votar. El Reino Unido no podía ejercer un control directo sobre sus colonias estadounidenses, ya que Londres estaba demasiado lejos y los colonos tenían un espíritu muy independiente.

En 1733, los británicos habían ocupado trece colonias a lo largo de la costa del Atlántico, desde Nuevo Hampshire en el norte hasta Georgia en el sur:


Los franceses controlaban Canadá y la Luisiana francesa, que comprendían toda la vertiente del río Misisipi: un imperio vasto con pocos habitantes. Entre 1689 y 1815, Francia y Gran Bretaña sostuvieron varias guerras y América del Norte se vio envuelta en cada una de ellas. En 1756, Francia e Inglaterra contendieron en la Guerra de los Siete Años, conocida en Estados Unidos como la Guerra Francesa e Indígena. El primer ministro británico, William Pitt, invirtió soldados y dinero en América del Norte y ganó un imperio. Las fuerzas británicas tomaron las plazas fuertes canadienses de Louisburg (1758), Quebec (1759) y Montreal (1760).
El "Tratado de París", firmado en 1763, concedió a Gran Bretaña derechos sobre Canadá y toda América del Norte al este del río Misisipi. La victoria de Inglaterra condujo directamente al conflicto con sus colonias estadounidenses. Para evitar que pelearan con los nativos de la región, llamados indios por los europeos, una Proclamación real de 1763 negaba a los colonos el derecho de establecerse al oeste de los montes Apalaches. El gobierno británico empezó a castigar a los contrabandistas e impuso nuevos gravámenes al azúcar, el café, los textiles y otros bienes importados. La Ley de Alojamiento obligó a las colonias a alojar y alimentar a los soldados británicos; y con la aprobación de la Ley de Estampillas, debían adherirse estampillas fiscales especiales a todos los periódicos, folletos, documentos legales y licencias.

Estas medidas parecieron muy justas a los políticos británicos, que habían gastado fuertes sumas de dinero para defender sus colonias estadounidenses durante y después de la Guerra Francesa e Indígena. Seguramente, su razonamiento era que los colonos debían sufragar parte de esos gastos. Pero los colonos temían que los nuevos impuestos dificultaran el comercio y que las tropas británicas estacionadas en las colonias pudieran usarse para aplastar las libertades civiles que los colonos habían disfrutado hasta entonces.

En general, los temores eran infundados, pero fueron los precursores de lo que han llegado a ser tradiciones profundamente arraigadas en la política estadounidense. Los ciudadanos desconfían del "gobierno poderoso"; después de todo, millones de inmigrantes llegaron a los Estados Unidos para escapar de la represión política. 

En 1765, representantes de nueve colonias se reunieron como "Congreso sobre la Ley de Estampillas" y protestaron contra el nuevo impuesto. Los comerciantes se negaron a vender productos británicos, los distribuidores de estampillas se vieron amenazados por la muchedumbre enardecida y la mayoría de los colonos sencillamente se negó a comprar las mencionadas estampillas. El parlamento británico se vio forzado a revocar la Ley de Estampillas, pero hizo cumplir la Ley de Alojamiento, decretó impuestos al té y a otros productos y envió funcionarios aduaneros a Boston a cobrar esos aranceles. De nuevo, los colonos optaron por desobedecer, así que se enviaron soldados británicos a Boston.

Las tensiones se aliviaron cuando lord North, el nuevo Primer ministro británico, eliminó todos los nuevos impuestos salvo el del té. En 1773, un grupo de colonos respondió a dicho impuesto escenificando la Fiesta del Té de Boston: disfrazados de indígenas, abordaron buques mercantes británicos y arrojaron al agua, en el puerto de Boston, 342 cajas de té. El Parlamento promulgó entonces las «Leyes Intolerables» ("Intolerable Acts"): la independencia del gobierno colonial de Massachusetts se restringió drásticamente y se enviaron más soldados británicos al puerto de Boston, que ya estaba cerrado a los buques mercantes. En septiembre de 1774 tuvo lugar en Filadelfia el Primer Congreso Continental, reunión de líderes coloniales que se oponían a lo que percibían como opresión británica en las colonias. Estos líderes instaron a los colonos a desobedecer las Leyes Intolerables y a boicotear el comercio británico. Los colonos empezaron a organizar milicias y a almacenar armas y municiones.

La guerra comenzó oficialmente en 1775 y fue claramente de dominio inglés hasta la batalla de Saratoga, primera gran victoria americana, cuando Francia y, posteriormente España, entrarían en la guerra en apoyo de los independentistas estadounidenses. La guerra terminó en 1783 con la batalla de Yorktown. Por el Tratado de Versalles (1783), Inglaterra se vio obligada a reconocer la independencia de las trece colonias estadounidenses, tal y como éstas la habían establecido en la famosa Declaración de Independencia de los Estados Unidos de 1776.

Una vez lograda la independencia, resultó muy complicado poner de acuerdo a todas las antiguas colonias en si continuaban como estados independientes o si se reunían en una sola nación. Tras varios años de negociaciones, cincuenta y cinco representantes de las antiguas colonias se reunieron en 1787 en el Congreso de Filadelfia para redactar una constitución. Allí se acordó un gobierno federal único, con un presidente de la República y dos Cámaras Legislativas (Congreso y Senado) como solución intermedia. El Congreso redactó también la Constitución de 1787 y llamó a las elecciones por las que se invistió a George Washington como primer presidente de los Estados Unidos.




</doc>
<doc id="42815" url="https://es.wikipedia.org/wiki?curid=42815" title="Murray Gell-Mann">
Murray Gell-Mann

Murray Gell-Mann (Nueva York, 15 de septiembre de 1929-Santa Fe, 24 de mayo de 2019) fue un físico estadounidense que recibió el en 1969 por sus descubrimientos sobre partículas elementales. Fue él quien dio el nombre al quark, un nombre tomado de la novela "Finnegans Wake", de James Joyce.

Estudió en la Universidad de Yale y en el Instituto Tecnológico de Massachusetts. Fue profesor desde 1955, en el Instituto de Tecnología de California (Pasadena), donde impartió desde 1967 la cátedra de física teórica. Fue miembro de la NASA desde 1964.

Se le otorgó el en 1969 por sus descubrimientos sobre partículas elementales. La teoría de Gell-Mann aportó orden al caos que surgió al descubrirse cerca de 100 partículas en el interior del núcleo atómico. Esas partículas, además de los protones y neutrones, estaban formadas por otras partículas elementales, llamadas quarks. Los quarks se mantienen unidos gracias al intercambio de gluones. Junto con otros investigadores, construyó la teoría cuántica de quarks y gluones, llamada cromodinámica cuántica.

Además de la ciencia, al profesor Gell-Mann le interesaban otros campos, como la literatura, la historia natural, la lingüística histórica, arqueología, la historia y la psicología.

Murray Gell-Mann es el autor de "The Quark and the Jaguar, Adventures in the Simplex and the Complex" ("El quark y el jaguar. Aventuras en lo simple y lo complejo").




</doc>
<doc id="42818" url="https://es.wikipedia.org/wiki?curid=42818" title="Trece Colonias">
Trece Colonias

Las Trece Colonias eran un grupo de colonias británicas en la costa este de América del Norte, fundadas en los siglosXVII y XVIII que declararon su independencia en 1776 y formaron los Estados Unidos. Eran (de norte a sur): Provincia de la Bahía de Massachusetts, Provincia de Nuevo Hampshire, Colonia de Rhode Island y las Plantaciones de Providence, Provincia de Connecticut, Provincia de Nueva York, Provincia de Pensilvania, Provincia de Nueva Jersey, Colonia de Delaware, Provincia de Maryland, Colonia de Virginia, Provincia de Carolina del Norte, Provincia de Carolina del Sur y Provincia de Georgia.

Las trece colonias tenían sistemas políticos, constitucionales y legales muy similares, y fueron establecidas por colonos procedentes de Gran Bretaña, en su mayoría protestantes, y de habla inglesa. Formaban una parte de las posesiones de Gran Bretaña en el Nuevo Mundo, que también incluían colonias en la actual Canadá y el Caribe, así como en el este y en el oeste de la Florida. En el sigloXVIII, el gobierno británico operaba sus colonias bajo una economía basada en el mercantilismo, en la que el gobierno central administraba sus posesiones para el beneficio económico de la metrópoli. Sin embargo, las trece colonias tenían un alto grado de autonomía y con elecciones locales, y progresivamente comenzaban a resistir con mayor fuerza las demandas del gobierno británico. En la década de 1750, comenzaron a colaborar entre sí, en lugar de tratar directamente con Gran Bretaña. Estas actividades inter-coloniales cultivaron un sentido de identidad americana compartida y condujeron a las peticiones de protección de los derechos como ingleses, de los colonos, especialmente el principio de «no hay impuestos sin representación». Las quejas contra el gobierno británico llevaron a la revolución estadounidense, en la que las colonias reunidas en un Congreso Continental declararon su independencia el 4 de julio del año de 1776, desapareciendo para siempre como colonias y dando lugar tras la correspondiente victoria militar a los Estados Unidos de América.

La guerra de los siete Años, que finalizó en 1763 dejó en ellos un sentimiento independentista.

Las Trece colonias británicas de Norteamérica habían gozado de cierta autonomía, por ser menos productivas que las islas caribeñas. Cada una de estas colonias desarrolló su propio sistema de gobierno, basado en gran medida en los agricultores independientes que eran dueños de su propia tierra, votaron a favor de su gobierno local y provincial.

Al reorganizar Gran Bretaña su nuevo imperio, los colonos resintieron el control que ahora se les imponía, el cual, según percibían, vulneraba sus derechos y libertades. En algunas colonias, especialmente Virginia, las Carolinas y Georgia hubo importantes poblaciones de esclavos africanos. Tras una serie de protestas por impuestos en los años 1760 y 1770, estas colonias unidas política y militarmente en la oposición al gobierno británico lucharon en la guerra revolucionaria americana, desde 1775 hasta 1783.

En julio de 1776, se formó una nueva nación llamada «Estados Unidos de América», y declararon su independencia. La nueva nación logró esta meta, con una lucha independentista corta y poco sangrienta, porque no solo contaron con aliados —Francia, España y los Países Bajos— sino que se enfrentaron a una metrópoli con un gobierno débil, en bancarrota y aislado diplomáticamente, que terminó por reconocer la independencia en 1912.

Estados Unidos se vio beneficiado en 1789 por el desencadenamiento de los franceses, que habían mantenido a Europa en guerra por casi un cuarto de siglo. Así la nueva nación tuvo ocasión de experimentar su gobierno sin interferencia europea, absorber emigrantes expulsados por las guerras europeas, población como país neutral con colonias españolas y en 1803. Al acrecentar su territorio y población, Estados Unidos se convirtió en un país dinámico.

Además de estas trece colonias, Gran Bretaña tenía otras en el Nuevo Mundo. Las Indias Occidentales Británicas, Terranova, la provincia de Quebec, Nueva Escocia, Isla del Príncipe Eduardo, Bermuda, y el este y el oeste de Florida con eso permanecieron leales a la corona durante la guerra (aunque España reconquistó la Florida antes de que la guerra hubiese terminado). Aunque hubo un cierto grado de simpatía con la causa patriota en varios de ellos, su aislamiento geográfico y el predominio del poder naval británico impidió cualquier participación efectiva. Especialmente en el caso de Quebec y la Florida, la corona británica había adquirido recientemente esas tierras, y muchos de los problemas que enfrentan las Trece Colonias no se aplican a ellos.

Documentos contemporáneos generalmente listan las trece colonias de Norteamérica Británica en orden geográfico, desde el norte hasta el sur.


Nota: las cifras de población son estimaciones de los historiadores; que no incluyen los pueblos originarios establecidos fuera de la jurisdicción de las colonias, pero incluyen a indígenas que vivían bajo control colonial, así como los esclavos y sirvientes.

Por 1776 alrededor del 85% de la población blanca era de origen británico (inglés, irlandés, escocés o galés) con un 9% alemanes y un 4% neerlandeses. Estas poblaciones continuaron creciendo a un ritmo rápido en todo el sigloXVIII, principalmente debido a las altas tasas de natalidad y relativamente bajas tasas de mortalidad. La inmigración es un factor de menor importancia desde 1774 hasta 1830. Más del 90% eran agricultores, con varias ciudades pequeñas que también eran puertos marítimos que unen la economía colonial a la más grande Imperio Británico.

La esclavitud era legal en aquellos tiempos y se practicaba en cada una de las Trece Colonias. En la mayoría de los lugares se trataba de sirvientes de la casa o los trabajadores agrícolas. Era de importancia económica en las plantaciones de tabaco orientadas a la exportación de Virginia y Maryland, y las plantaciones de arroz y añil de Carolina del Sur. Cerca de 287000 esclavos fueron importados en las Trece Colonias, o el 2% de los 12 millones de esclavos traídos a través de África. La gran mayoría fue a colonias de azúcar en el Caribe y en Brasil, donde la esperanza de vida era corta y los números tuvieron que ser repuestos continuamente. La esperanza de vida era mucho mayor en los Estados Unidos combinado con una muy alta tasa de natalidad, los números crecieron rápidamente por los excesos de nacimientos sobre defunciones, llegando a casi 4 millones por el censo 1860. Desde 1770 hasta 1860, la tasa de crecimiento natural de los esclavos estadounidenses era mucho mayor que para la población de cualquier país de Europa, y era casi el doble de rápida que la de Inglaterra. Sin embargo, Tadman atribuye esto a muy altas tasas de natalidad: «esclavos de Estados Unidos, entonces, alcanzaron tasas similares de crecimiento natural a los blancos no porque de ningún privilegio especial, pero a través de un proceso de gran sufrimiento y privación material».

Las colonias eran religiosamente diversas. La religión era fuerte en Nueva Inglaterra y en otros puntos, pero antes del primer Gran Despertar de la década de 1740 la mayoría de los colonos eran religiosamente inactivos. La Iglesia Anglicana de Inglaterra fue establecida oficialmente en la mayor parte del Sur, pero no hubo obispos y las iglesias tuvieron papeles solamente locales. La educación fue generalizada en las colonias del norte, que habían establecido los colegios dirigidos por la Universidad de Harvard, Universidad de Nueva Jersey (Princeton), y la Universidad Yale, mientras que el Colegio de William y Mary formó la élite en Virginia. La enseñanza pública era rara fuera de Nueva Inglaterra.

El estado británico tomó un interés cada vez mayor en los asuntos de las colonias después de 1680, cuando fue evidente que estaba creciendo rápidamente en población y riqueza. En 1680, sólo Virginia era una colonia real; los gobernadores eran nombrados y estaban estrechamente ligados al gobierno de Londres. Los historiadores antes de la década de 1880 hicieron hincapié en el nacionalismo estadounidense. Sin embargo, Herbert L. Osgood, George Louis Beer, Charles McLean Andrews, y Lawrence H. Gipson dominaron la historiografía colonial en la década de 1940, e hicieron hincapié, y a menudo elogiado, la atención que Londres dio a todas las colonias; nunca hubo una amenaza (antes de la década de 1770) por la que cualquier colonia quisiera rebelarse o buscar la independencia.

Los colonos británicos no llegaron a las tierras americanas con la intención de crear un sistema democrático, pero al hacerlo sin una aristocracia terrateniente crearon un amplio electorado y un patrón de elecciones libres y frecuentes que ponen una prima sobre la participación de los votantes. Las colonias ofrecieron una franquicia mucho más amplia que el de Inglaterra o de cualquier otro país. Los hombres blancos con suficiente propiedad podrían votar por los miembros de la cámara baja de la legislatura, y en Connecticut y Rhode Island podrían incluso votar por el gobernador. La legitimidad de un votante significaba tener un «interés» en la sociedad —como la legislatura de Carolina del Sur dijo en 1716: «es necesario y razonable que ninguno, pero dichas personas tendrá un interés en la Provincia debería ser capaz de elegir a los miembros de los Comunes Cámara de la Asamblea»—. Mujeres, niños, sirvientes y esclavos fueron subsumidos bajo el interés del jefe de familia. El principal criterio legal para tener un «interés» era propiedad de los bienes, que se basa estrictamente en Gran Bretaña, y diecinueve de veinte hombres fueron controlados políticamente por sus propietarios. Londres insistió en que para las colonias, diciendo a los gobernadores de excluir a los hombres que no eran propietarios libres (es decir, no poseer tierras) de la boleta electoral. Sin embargo, la tierra fue tan ampliamente propiedad que el 50% y el 80% de los hombres blancos eran elegibles para votar.

La cultura política colonial enfatizó deferencia, de modo que los notables locales eran los hombres que corrieron y fueron elegidos. Pero a veces competían entre sí, y tuvo que apelar al hombre común de votos. No hubo partidos políticos y aspirantes a legisladores formaron coaliciones ad hoc de sus familias, amigos y vecinos. Fuera puritana Nueva Inglaterra, día de las elecciones llevó en todos los hombres de campo a la cabecera municipal para hacer fiesta, politick, estrechar la mano de los grandes, y encontrarse con viejos amigos, escuchar los discursos y todo el tostado, mientras que, de comer, el tratamiento, Tippling , juegos y apuestas. Votaron por gritar su elección a la secretaria, como partidarios aplaudieron o abuchearon. Candidato George Washington pasó £39 para los convites para sus partidarios. Los candidatos sabían que tenían que «swill los plantadores con bumbo (ron)». Las elecciones eran carnavales donde todos los hombres eran iguales por un día y las restricciones tradicionales relajados.

La tasa real de la votación varió de 20% a 40% de todos los varones blancos adultos. Las tasas fueron más altas en Pensilvania y Nueva York, donde las facciones de larga data, basado en los grupos étnicos y religiosos, partidarios movilizados a un ritmo mayor. Nueva York y Rhode Island desarrollaron sistemas de dos facciones de larga duración que celebran juntos por años a nivel colonia, pero no llegaron en los asuntos locales. Las facciones se basaron en las personalidades de unos pocos líderes y una gran variedad de conexiones de la familia, sin embargo, tuvo poca base en la política o la ideología. En otras partes de la escena política estaba en un torbellino constante, y sobre la base de la personalidad en lugar de las facciones de larga vida o serias disputas sobre cuestiones.

Las colonias eran independientes entre sí antes de 1774 como los esfuerzos dirigidos por Benjamin Franklin para formar una unión colonial a través del Congreso de Albany de 1754 habían fracasado. Todos los trece había sistemas de autogobierno y las elecciones sobre la base de los derechos de los ingleses, que estaban decididos a proteger contra la interferencia imperial bien establecida. La gran mayoría de los hombres blancos eran elegibles para votar.

El naciente Imperio británico seguía una política económica mercantilista, en la cual el objetivo era enriquecer a Gran Bretaña, en especial a su ya poderosa burguesía que ejercía el poder desde la Revolución Gloriosa. Esta política era vista con recelo por los colonos ya que los perjudicaba directamente al considerar a las colonias como meras productoras de materia prima y mercado para las producciones de la metrópoli.

La primera reacción de los productores y comerciantes americanos fue el contrabando, que se convirtió en la táctica más difundida para eludir las restricciones al comercio con los franceses, español u holandés. El mercantilismo pretendía lograr superávit comerciales, para que el oro y la plata se concentrara en Londres, las colonias, por su parte, eran mercados cautivos para la industria británica.El gobierno participaba a través de los derechos e impuestos, y el resto iba a los comerciantes ingleses. El rubro de la administración pública que más se beneficiaba era el militar, en especial la Armada Británica. 

Bretaña implementó el mercantilismo, tratando de bloquear el comercio estadounidense con los imperios francés, español u holandés utilizando las Actas de Navegación, que los estadounidenses evitarse tan a menudo como podía. Los funcionarios reales respondieron al contrabando con órdenes de registro abiertas (Orden de asistencia). En 1761, el abogado de Boston James Otis argumentó que los autos violan los derechos constitucionales de los colonos. Perdió el caso, pero John Adams escribió más tarde: «Entonces, y no el niño Independencia nació».

Sin embargo, los colonos tomaron la molestia de argumentar que no se oponen a la regulación británica de su comercio exterior, solo se opusieron a la legislación que se pensó para impactar internamente.

El 1 de diciembre de 1763, en Hanover Courthouse, Patrick Henry argumentó Causa de la Parson en la Colonia de Virginia, donde la legislatura aprobó una ley y que fue vetada por el rey. Henry argumentó, «que un rey, al no permitir actos de esta naturaleza saludable, de ser el padre de su pueblo, degeneró en un tirano y pierde todo derecho a la obediencia de sus súbditos».

Después de su victoria en la Guerra franco-india en 1763, Gran Bretaña tomó el control de las posesiones francesas en América del Norte, fuera del Caribe. El británico trató de mantener relaciones pacíficas con esas tribus indias que se habían aliado con los franceses, y mantenerlos separados de los hombres de la frontera de Estados Unidos. Con este fin, la Real Proclamación de 1763 restringe asentamiento al oeste de los Montes Apalaches, ya que fue designado Reserva India..Haciendo caso omiso de la proclamación, algunos grupos de colonos continuaron moviéndose al oeste y establecer granjas. La proclamación fue rápidamente modificada y ya no era un obstáculo para el acuerdo, pero el hecho de que había sido promulgada sin su consulta previa enfureció a los colonos.

A partir de las intensas protestas por la Ley del Sello de 1765 (o Stamp Act), los estadounidenses insistieron en el principio de «no hay impuestos sin representación», la representación se entiende en el contexto del Parlamento gravar directamente el impuesto del deber o de los impuestos especiales, y por lo tanto sin pasar por las legislaturas coloniales , que había recaudado los impuestos a las colonias en lugar del monarca antes de 1763. Argumentaron que, como las colonias no tenían representación en el Parlamento británico, que era una violación de sus derechos como ingleses por los impuestos que se impongan sobre ellos. Esas otras colonias británicas que tenían asambleas coincidieron en gran medida con los de las Trece Colonias, pero fueron controlados totalmente por el imperio británico y la Royal Navy, por lo que las protestas estaban sin esperanza.

El parlamento rechazó las protestas coloniales y afirmó su autoridad al aprobar nuevos impuestos. Trouble intensificó sobre el impuesto del té, como americanos en cada colonia boicotearon el té y en Boston tiró el té en el puerto durante el Motín del té de Boston en 1773. Las tensiones se intensificaron en 1774 como el Parlamento aprobó las leyes conocidas como las Leyes Intolerables, que, entre otras cosas, limita en gran medida la autonomía en la colonia de Massachusetts.

En respuesta, las colonias formaron cuerpos extralegales de los representantes elegidos, generalmente conocidos como los Congresos Provinciales. Los colonos hicieron hincapié en su determinación por boicotear las importaciones de mercancía británica. Más tarde, en 1774 de doce colonias enviado representantes al Primer Congreso Continental en Filadelfia. Durante el Segundo Congreso Continental de la coloniaXIII, Georgia, envió delegados. En la primavera de 1775 todos los funcionarios reales habían sido expulsados de las trece colonias. El Congreso Continental fue el gobierno nacional. Se levantó un ejército para luchar contra los británicos y llamado George Washington su comandante, hizo tratados, declaró su independencia, y recomendó que las colonias escribieran constituciones y se convirtieran en estados.

En el momento de la guerra, Gran Bretaña tenía otras siete colonias en la costa atlántica de América del Norte: Terranova, Tierra de Rupert (el área alrededor de la bahía de Hudson), Nueva Escocia, Isla del Príncipe Eduardo, Florida Oriental, Florida Occidental y la provincia de Quebec. Había otras colonias en las Américas, así, en gran medida en las Indias Occidentales Británicas. Estas colonias se mantuvieron leales a la corona.

Terranova se mantuvo leal a Gran Bretaña sin duda. Fue exentos de las Leyes de Navegación y ninguno de los agravios de las colonias continentales compartida. Fue fuertemente unida a Gran Bretaña y controlada por la Marina Real y no tenía ninguna asamblea que pudiera expresar quejas.

Nueva Escocia tenía un elemento Yankee grande que había llegado recientemente de Nueva Inglaterra, y compartió los sentimientos de los estadounidenses acerca de exigir los derechos de los hombres británicos. El gobierno real en Halifax, permitió a regañadientes a los Yankees de Nueva Escocia una especie de «neutralidad». En cualquier caso, la geografía de la isla, como y la presencia de la base naval británica importante en Halifax hicieron pensar en la resistencia armada imposible.

Quebec fue habitada por colonos católicos franceses que vinieron bajo control británico en la década anterior. La Ley de Quebec de 1774 les dio autonomía cultural formal dentro del imperio, y muchos sacerdotes temían el intenso protestantismo en Nueva Inglaterra. Las quejas estadounidenses sobre los impuestos tenían poca relevancia, y no había ninguna asamblea ni elecciones de cualquier tipo que pudieran haber movilizado cualquier queja. Aun así, los estadounidenses ofrecieron membresía en la nueva nación y enviaron una expedición militar que no pudo capturar Canadá en 1775. La mayoría de los canadienses se mantuvieron neutrales, pero algunos se unieron a la causa americana.

En las Antillas las asambleas electas de Jamaica, Granada y Barbados declararon formalmente sus simpatías por la causa americana y pidieron la mediación, pero los demás eran muy leales. Gran Bretaña evitó cuidadosamente antagonizar los ricos propietarios de plantaciones de azúcar (muchos de los cuales vivían en Londres); a su vez, una mayor dependencia de los hacendados sobre la esclavitud hizo a reconocer la necesidad de protección militar británico de posibles revueltas de esclavos. Las posibilidades de acción abierta fueron fuertemente limitadas por el abrumador poder de la Royal Navy en las islas. Durante la guerra hubo algún comercio oportunista con barcos americanos.

En las Bermudas y las Bahamas líderes locales estaban enojados con la escasez de alimentos causada por el bloqueo británico de los puertos estadounidenses. Hubo creciente simpatía por la causa americana, como el contrabando, y las dos colonias fueron considerados «aliados pasivos» de los Estados Unidos a lo largo de la guerra. Cuando un escuadrón naval estadounidense llegó a las Bahamas para apoderarse de la pólvora, la colonia dio ninguna resistencia en absoluto.

Florida del Este y el Oeste de la Florida eran territorios transferidos desde España a Gran Bretaña después de la Guerra Franco-India por un tratado. Los pocos colonos británicos no necesitan protección contra los ataques de los indios y corsarios españoles. Después de 1775, este de Florida se convirtió en una base importante para el esfuerzo de guerra británico en el sur, sobre todo en las invasiones de Georgia y Carolina del Sur. Sin embargo, España se apoderó de Pensacola en Florida Occidental en 1781, luego se recuperó ambos territorios en el Tratado de París que puso fin a la guerra en 1783. España transfiere en última instancia las provincias de Florida a los Estados Unidos en 1819.

El primer imperio británico centrado en las trece colonias americanas, que atrajo a un gran número de colonos de toda Gran Bretaña. En la década de 1900 - periodo de 1930 la «Imperial», entre ellos Herbert L. Osgood, George Louis Beer, Charles M. Andrews y Lawrence Gipson tenía una opinión favorable de los beneficios del imperio, haciendo hincapié en su integración económica exitosa.

El mercantilismo fue la política básica impuesta por Gran Bretaña en sus colonias. El mercantilismo significaba que el gobierno y los comerciantes se convirtieron en socios con el objetivo de aumentar el poder político y la riqueza privada, con exclusión de otros imperios. El gobierno protegió sus comerciantes y mantuvo otros fuera por las barreras comerciales, regulaciones y subsidios a las industrias nacionales a fin de maximizar las exportaciones y minimizar las importaciones con el reino. El gobierno tuvo que luchar contra el contrabando, que se convirtió en la técnica norteamericana favorita en el sigloXVIII para eludir las restricciones en el comercio con los franceses, españoles u holandeses. El objetivo del mercantilismo era correr superávit comerciales, por lo que el oro y la plata se vierta en Londres. El gobierno tomó su participación a través de los derechos e impuestos, y el resto va a los comerciantes en Gran Bretaña. El gobierno pasó la mayor parte de sus ingresos en un magnífico Royal Navy, que no solo protege las colonias británicas, pero amenazó las colonias de los otros imperios, ya veces se apoderó de ellos. Así, la Marina británica capturó Nueva Ámsterdam (Nueva York) en 1664. Las colonias eran mercados cautivos para la industria británica, y el objetivo era enriquecer la madre patria.

La conmoción de la derrota sufrida por el Reino Unido en 1783 provocó una revisión radical de sus políticas sobre el colonialismo, produciendo de esta manera lo que los historiadores llaman el final del Primer Imperio Británico; por supuesto Gran Bretaña aun poseía Canadá y algunas islas de las Indias Occidentales. Ashley Jackson escribe:

Gran parte de la historiografía se refiere a las razones que los estadounidenses se sublevó en la década de 1770 y rompió con éxito de distancia. Desde la década de 1960 la corriente principal de la historiografía enfatiza el crecimiento de la conciencia y el nacionalismo estadounidense, y su sistema de valores republicanos, pero se quedó en la oposición al punto de vista aristocrático de los líderes británicos. En el análisis de la llegada de la Revolución, los historiadores de las últimas décadas se han utilizado sobre todo uno de los tres enfoques. La vista historia atlántica coloca la historia de Estados Unidos en un contexto más amplio, incluyendo las revoluciones en Francia y Haití. Tendía a reintegrar a las historiografías de la Revolución Americana y el Imperio Británico. En segundo lugar el enfoque de «nueva historia social» mira a la estructura social de la comunidad para encontrar divisiones que fueron magnificados en las divisiones coloniales. Tercero es el enfoque ideológico que se centra en el republicanismo en los Estados Unidos.< El Republicanismo dictaba que no hubiera realeza o aristocracia o iglesia nacional. Se permitió la continuación del derecho consuetudinario británico, que americanos abogados y juristas entienden y aprobados y utilizados en su práctica cotidiana. Los historiadores han examinado cómo el aumento de la profesión legal estadounidense adaptó el derecho consuetudinario británico para incorporar el republicanismo por la revisión selectiva de las costumbres jurídicas y mediante la introducción de más opciones para los tribunales.







</doc>
<doc id="42820" url="https://es.wikipedia.org/wiki?curid=42820" title="Guerra de Independencia de los Estados Unidos">
Guerra de Independencia de los Estados Unidos

La guerra de Independencia de los Estados Unidos fue un conflicto bélico que enfrentó a las Trece Colonias británicas originales en América del Norte contra el Reino de Gran Bretaña. Ocurrió entre 1775 y 1783, finalizando con la derrota británica en la batalla de Yorktown y la firma del Tratado de París.

Durante la guerra, Francia ayudó a los revolucionarios estadounidenses con tropas terrestres comandadas por Rochambeau y por el Marqués de La Fayette y por flotas bajo el comando de marinos como Guichen, de Grasse y d'Estaing. España, por su parte, lo hizo inicialmente y de forma clandestina, desde la primavera y verano de 1776, gracias a Luis de Unzaga y Amézaga, luego de su cuñado Bernardo de Gálvez y de forma abierta a partir de la batalla de Saratoga, mediante las armas y los suministros proporcionados por los navíos del comerciante Diego de Gardoqui, familiar del gobernador Unzaga, y abriendo un frente en el flanco sur.

Las colonias británicas que se independizaron de Gran Bretaña edificaron el primer sistema político liberal y democrático, alumbrando una nueva nación, los Estados Unidos de América, incorporando las nuevas ideas revolucionarias que propugnaban la igualdad y la libertad. Esta sociedad colonial se formó a partir de oleadas de colonos inmigrados y no existían en ella los rasgos característicos del rígido sistema estamental europeo.

En las colonias del sur (Virginia, Carolina del Norte, Carolina del Sur y Georgia) se había organizado un sistema esclavista (con unos esclavos negros) que explotaban plantaciones de tabaco, algodón y azúcar. De este modo, la población estaba compuesta por grandes, pequeños propietarios y esclavos.

Los antecedentes a la guerra de la Independencia de los Estados Unidos se remontan a la rivalidad franco-británica en Norteamérica y a las consecuencias de la guerra de los Siete Años.

La guerra de los Siete Años terminó en 1763. El 10 de febrero, el Tratado de París ponía fin al imperio colonial francés en América del Norte y consolidaba a Inglaterra como la potencia hegemónica. En oposición solo tenía a España, que controlaba Nueva Orleans, la ciudad más importante, con unos 10 000 habitantes. Respecto a Francia, la pérdida territorial no fue sentida como algo catastrófico. Se conservaban los derechos pesqueros en Terranova y la población católica francófona recibiría un trato de respeto. Por otro lado, en el Caribe las pérdidas podían ser compensadas, pues la colonia principal francesa del Caribe, Saint-Domingue (La Española) con capital en Puerto Príncipe, producía la mitad del azúcar consumido en todo el mundo, y su comercio con África y las Antillas estaba en pleno apogeo.

Respecto a los colonos estadounidenses, la guerra modificó radicalmente el panorama anterior. Los francófonos católicos de Quebec, tradicionales enemigos de los colonos estadounidenses de las Trece colonias, recibieron un trato respetuoso por parte de las autoridades británicas. Trato que se confirmó en 1774 cuando se dotó a Canadá de un estatuto particular dentro de las colonias estadounidenses, llevándose sus fronteras hasta la confluencia del Ohio y el Misisipi. Asimismo su población conserva un derecho civil propio y la Iglesia católica es reconocida. Todos estos movimientos fueron mal aceptados por la población de las Trece colonias.

La causa inmediata de este conflicto fue el injusto trato que Gran Bretaña infligía a los colonos, pues estos aportaban riquezas e impuestos a la metrópoli pero no tenían los medios para decidir sobre dichos impuestos, por lo que se sentían marginados y no representados.

Gran Bretaña obtuvo el triunfo parcial sobre Francia en la guerra de los Siete Años (1756-1763) recibiendo gran ayuda económica y militar de las colonias, al igual que estas de la metrópoli, aunque dicha colaboración no les fue recompensada. Las medidas represivas del gobierno inglés (producidas tras sublevaciones como el Motín del té de Boston y las sanciones de las Actas Intolerables) provocaron el inicio de la guerra de independencia.

El descontento se extendió por las Trece Colonias y se organizó una manifestación en Boston en contra de los impuestos que debían pagar por artículos indispensables como el papel, el vidrio o la pintura. En esta manifestación no hubo ningún altercado y el gobierno inglés hizo oídos sordos a las peticiones de los colonos. Pero estos no iban a consentir que la situación continuara así, con lo que se reunieron junto a varios miembros de otras poblaciones para urdir una acción más propagandística que la manifestación. En 1773 los colonos se reunieron en Boston. De Gran Bretaña llegaban tres naves cargadas de cajas que contenían té. Varios miembros de la sociedad secreta se disfrazaron de indios y fueron nadando hasta alcanzar los tres barcos. Una vez allí capturaron a sus tripulantes y tiraron la mercancía por la borda. Fue la primera acción contra la represión de impuestos, lo que intranquilizó a los británicos.

En 1774 se reunió por primera vez el Congreso de los colonos en contra de la servidumbre a Londres y a favor de una patria independiente, el Primer Congreso Continental. Ya se discuten unas hipotéticas leyes. Pese al clima de enemistad contra los británicos metropolitanos en las colonias, todavía había algunos colonos que apoyaban al rey inglés Jorge III, siendo llamados "kings friends" (Cerca de 500 000 lealistas, alrededor del 19 % de la pobl. de las 13 colonias).

El 19 de abril del año 1775, soldados ingleses salieron de Boston para impedir la rebelión de los colonos mediante la toma de un depósito de armas de estos últimos en la vecina ciudad de Concord. En el poblado de Lexington se enfrentaron a 70 milicianos. Nadie sabe quién abrió fuego y comenzó de este modo la guerra de independencia. Los ingleses tomaron Lexington y Concord, pero en su regreso hacia Boston fueron hostigados por cientos de voluntarios de Massachusetts. Se producen las primeras bajas de la contienda, ocho soldados colonos. Para junio, soldados coloniales estaban sitiando Boston.

En mayo de 1775, un Segundo Congreso Continental se reunió en Filadelfia y empezó a asumir las funciones de gobierno nacional. Nombró catorce generales, autorizó la invasión de Canadá y organizó un ejército de campaña bajo el mando de George Washington, un hacendado virginiano y veterano de la guerra franco-india. Consciente de que las colonias sureñas desconfiaban del fanatismo de Massachusetts, John Adams presionó para que se eligiera a este coronel de la milicia virginiana, que tenía cuarenta y tres años como comandante en jefe. Fue una elección inspirada. Washington, que asistía al Congreso de uniforme, tenía el aspecto adecuado; era alto y sereno, con un digno aire militar que inspiraba confianza. Como dijo un congresista: «No era un tipo que actuara alocadamente, que despotricara y jurara, sino alguien sobrio, firme y calmado».

Se empezaron a reclutar soldados de entre todas las partes de las colonias. Muchos de ellos eran agricultores o cazadores, bravucones y poco entrenados en el combate. En las primeras luchas contra los británicos, George Washington llegó a decir: «hemos reclutado un ejército de generales, no obedecen a nadie».

Al principio, la guerra fue desfavorable para los colonos. En junio de 1775 ambos ejércitos se encontraron en Bunker Hill, frente a Boston. Los rebeldes se habían atrincherado en la colina y, pese a que los británicos asaltaron las posiciones continentales con violencia, los colonos consiguieron aguantar el ataque durante bastante tiempo; cuando los últimos asaltantes logran llegar a la cima las bajas británicas son de 800. Es una victoria pírrica para los ingleses. Los insurgentes, además, hicieron circular su versión de los hechos, que no era otra sino que se habían retirado simplemente por la falta de munición y no por el empuje de los casacas rojas. Después de dejar la colina Bunker Hill, los colonos se centraron en fortificar la otra colina, Dorchester Heights, que lo consiguieron gracias a los cañones que capturaron en el fuerte Ticonderoga, y que trajo en una compleja operación desde allí el joven coronel Henry Knox (esta operación de transporte se conoce como «noble tren de artillería»). El general británico William Howe, al ver esta fortificación, decidió rendirse y evacuar la ciudad de Boston el 17 de marzo de 1776 (día de la evacuación). Desde 1770 el gobernador de Luisiana Luis de Unzaga y Amézaga tenía conocimiento de los sucesos en Boston y las restantes colonias inglesas, desde finales de 1775 y en especial en la primavera y verano de 1776 Luis de Unzaga y Amézaga ayudó a los colonos norteamericanos con mercancías, atendiendo peticiones como las provenientes de Patrick Henry o el general Charles Lee, Unzaga facilitó desde Nueva Orleans toneladas de pólvora, harina y medicamentos en varias embarcaciones río arriba pasando por San Luis y ascendiendo hasta Fort Pitt (Pittsburg) a través del río Ohio; gracias a todo ello George Washington logró sus primeras victorias. 

El 2 de julio de 1776, el Congreso finalmente resolvió que: «estas Colonias Unidas son, y por derecho deben ser, estados libres y soberanos». El 4 de julio de 1776 se reunieron 56 congresistas estadounidenses para aprobar la Declaración de Independencia de los Estados Unidos, que Thomas Jefferson redactó con la ayuda de otros ciudadanos de Virginia. Se imprimió papel moneda y se iniciaron relaciones diplomáticas con potencias extranjeras. En el congreso se encontraban cuatro de las principales figuras de la independencia: George Washington, Thomas Jefferson, Benjamin Franklin y John Adams. De los 56 congresistas, 14 murieron durante la guerra. Benjamin Franklin se convierte en el primer embajador y jefe de los servicios secretos.

La unidad se extendió entonces por las Trece Colonias para luchar contra los británicos. La declaración presentó una defensa pública de la guerra de Independencia, incluida una larga lista de quejas contra el soberano inglés Jorge III. Pero sobre todo, explicó la filosofía que sustentaba la independencia, proclamando que todos los hombres nacen iguales y poseen ciertos derechos inalienables, entre ellos la vida, la libertad y la búsqueda de la felicidad; que los gobiernos pueden gobernar solo con el consentimiento de los gobernados; que cualquier gobierno puede ser disuelto cuando deja de proteger los derechos del pueblo. Esta teoría política tuvo su origen en el filósofo inglés John Locke, y ocupa un lugar prominente en la tradición política anglosajona.

Estos hechos convencieron al gobierno británico de que no se enfrentaba simplemente a una revuelta local de Nueva Inglaterra. Pronto se asumió que el Reino Unido estaba envuelto en una guerra, y no en una simple rebelión, por lo que se adoptaron decisiones de política militar dieciochesca convencional, consistente en maniobras y batallas entre ejércitos organizados.

Este cambio de estrategia forzó a los británicos a evacuar Boston en marzo de 1776 y transferir sus principales fuerzas a Nueva York, cuya población se presumía más favorable a la Corona, con un puerto más amplio y una posición central. En consecuencia, en el verano de 1776, sir William Howe, que sustituyó a Gage como comandante en jefe del ejército británico en Norteamérica, llegó al puerto de Nueva York con una fuerza de más de treinta mil hombres. Howe tenía intención de aislar Nueva Inglaterra de los otros rebeldes y derrotar al ejército de Washington en una batalla decisiva. Iba a pasar los dos años siguientes tratando de llevar a cabo este plan.

Según todas las apariencias, un enfrentamiento militar parecía muy ventajoso para Gran Bretaña, una de las potencias mundiales más poderosas, con una población de unos once millones, frente a los dos millones y medio de colonos, un quinto de los cuales eran esclavos negros. La armada británica era la mayor del mundo y casi la mitad de sus buques participaron inicialmente en el conflicto con los nacientes Estados Unidos. El ejército era una fuerza profesional bien entrenada; en 1778, llegó a tener cerca de cincuenta mil soldados estacionados solo en Norteamérica, a los cuales se añadieron más de treinta mil mercenarios alemanes durante la contienda.

Para enfrentarse a ese poder militar, los rebeldes tenían que empezar de la nada. El Ejército Continental contaba con menos de cinco mil efectivos permanentes, complementados por unidades de las milicias estatales de diferentes tamaños. En la mayoría de los casos estaban mandados por oficiales inexpertos y no profesionales. George Washington, el comandante en jefe, por ejemplo, solo había sido coronel de regimiento en la frontera virginiana y tenía poca experiencia en combate. No sabía nada de mover grandes masas de soldados y nunca había dirigido un asedio a una posición fortificada. Muchos de sus oficiales habían salido de las capas medias de la sociedad: había posaderos convertidos en capitanes y zapateros en coroneles, como exclamó, asombrado, un oficial francés. Es más, «sucede con frecuencia que los colonos preguntan a los oficiales franceses qué oficio tienen en Francia». No es de extrañar, pues, que la mayoría de los oficiales británicos pensara que el ejército insurgente no era «más que una banda despreciable de vagabundos, desertores y ladrones» incapaces de rivalizar con los casacas rojas de Su Majestad. Un general británico llegó a alardear que con mil granaderos podía «ir de un extremo a otro de Norteamérica y castrar a todos los hombres, en parte por la fuerza y en parte con un poco de persuasión».

Sin embargo, estos contrastes eran engañosos, porque las desventajas británicas eran inmensas desde el principio del conflicto. Gran Bretaña tenía que conducir la guerra desde el otro lado del Atlántico, a cinco mil kilómetros de distancia, con los consiguientes problemas de comunicaciones y logística; incluso alimentar adecuadamente era un problema casi insalvable. Al mismo tiempo, tenía que hacer una guerra absolutamente diferente a la que cualquier país hubiera librado en el siglo XVIII. La propia Norteamérica era inconquistable. La enorme extensión del territorio hacía que las maniobras y operaciones convencionales fueran difíciles y engorrosas. El carácter local y fragmentario de la autoridad en Norteamérica inhibía cualquier acción decisiva por parte de los británicos. No había ningún centro neurálgico con cuya captura se pudiera lograr aplastar la rebelión. Los generales británicos acabaron por decidir que su principal objetivo debía ser enfrentarse al ejército de Washington en una batalla, pero, como dijo el comandante en jefe británico, no sabían como hacerlo, «ya que el enemigo se mueve con mucha más celeridad de la que nosotros somos capaces».

Uno de los principales problemas para los colonos era la baja calidad de sus mosquetes, ya anticuados y que solo podían disparar a pocos metros para obtener precisión. Esto llevó a que se creara un nuevo tipo de arma más eficaz, que fue el fusil modelo "Pennsylvania", de gran precisión desde más de 80 metros. Los colonos en estos primeros combates lucharon en forma de guerrillas.

George Washington, por su parte, comprendió desde el principio que, por el lado estadounidense, la guerra tenía que ser defensiva. «En todas las ocasiones debemos evitar una acción general -dijo ante el Congreso en septiembre de 1776- o arriesgar nada, a menos que nos veamos obligados por una necesidad a la cual no deberíamos vernos arrastrados». Aunque nunca actuó como cabecilla guerrillero y se concentró todo el tiempo en crear un ejército profesional, con el cual pretendía batir a los británicos en una batalla abierta, en realidad, sus tropas pasaban buena parte del tiempo librando escaramuzas con el enemigo, acosándolo y privándole de comida y avituallamiento siempre que era posible (guerra de guerrillas). En esas circunstancias, la dependencia de los estadounidenses de unas fuerzas de la milicia no profesionales y la debilidad de su ejército organizado los convertían, como dijo un oficial suizo, en más peligrosos que «si tuvieran un ejército regular». Los británicos no comprendieron nunca a qué se enfrentaban; esto es, a una verdadera revolución que contaba con un apoyo generalizado de la población. Por ello, continuamente subestimaron el aguante de los rebeldes y sobreestimaron la fuerza de los colonos leales a la Corona. Al final, la independencia acabó significando más para los estadounidenses que la reconquista o conservación de las Trece Colonias para los ingleses.

Las cosas empezaron a cambiar en octubre de 1777, cuando un ejército británico bajo el mando del General John Burgoyne se rindió en Saratoga, en el norte del estado de Nueva York. Este fue el golpe de gracia y propagandístico que necesitaban los colonos para su independencia. Desde Canadá llegaron indios (dirigidos por Joseph Brant) a favor de los británicos porque los colonos les estaban invadiendo sus tierras cada vez más. La expedición estaba mandada por el general John Burgoyne y pretendía llegar a Albany. Sin embargo, fueron interceptados y tuvieron que presentar batalla en Freeman, cerca del río Hudson. Aquí estaban los colonos al mando de Benedict Arnold, Horatio Gates y Daniel Morgan. Este último comandaba a fusileros vestidos con pieles, muchos de ellos antiguos cazadores.

El general Burgoyne contaba con 600 mercenarios alemanes (los británicos llegaron a utilizar hasta 16 000 en toda la guerra) para tomar la granja. El 9 de septiembre Morgan tiene a sus hombres bien escondidos en un bosque contiguo a la granja y en los trigales de la misma. Una vez se acercan los mercenarios alemanes, los fusileros salen de sus escondites y disparan a los enemigos, produciendo gran sorpresa entre estos y provocando que caigan decenas. Burgoyne entonces manda otros 600 más, que también caen. Los británicos retroceden, pero Burgoyne resiste, aunque sin suministros ni víveres, y consigue poco tiempo después tomar la granja.

Horatio Gates, aunque hombre pesimista, es convencido por Morgan y Arnold para lanzar un ataque a los británicos. Con los cañones incautados a los británicos bombardean la granja y consiguen la rendición de Burgoyne. Entre el cañoneo de los colonos, un general británico, Simon Fraser, ordenó una carga de caballería totalmente desesperada por lo difícil de la situación. Esta carga fue rápidamente neutralizada por los hombres de Morgan, que consiguieron acabar con el general. Este, antes de morir, pidió ser enterrado en el campo de batalla, y para ello varios soldados británicos se reunieron, lo que llegó a confundir a los colonos. Creyendo que los enemigos se estaban reorganizando para otro ataque, empezaron a cañonear la zona en que estaban enterrando a Simon Fraser, y aunque no dieron en el blanco, sí produjeron que los que se esforzaban en la faena fueran salpicados por la arena y el polvo. Al final se le pudo enterrar entre una lluvia de balas de cañón. Este hecho produjo esta frase de un general alemán llamado Riedesel: «¡qué gran entierro para un gran guerrero!»

Alentados por la victoria de Saratoga, Francia y España, que desde 1775 ayudaban clandestinamente a través del gobernador español Luis de Unzaga y Amézaga casado con la francesa Isabel de Saint Maxent, veían la oportunidad como una ocasión de oro para lograr la revancha del desastroso Tratado de París de 1763, con el que concluyó la guerra de los Siete Años. Así, Francia tras unos meses de cierta vacilación, entró abiertamente en la guerra firmando una alianza en febrero de 1778 con los colonos. Pese a sus escasas provisiones y limitado adiestramiento, las tropas coloniales pelearon bien en general, pero podrían haber perdido la guerra si no hubieran recibido ayuda del erario francés, de la poderosa marina francesa y de las tropas enviadas por Francia.

Por su parte, España, aunque enseguida ayudó a los rebeldes con dinero, armas y municiones, se mostró reacia a la intervención directa, debido al temor de Floridablanca a las consecuencias de un conflicto armado; incluso aspiró a algo que, de momento, resultaba una verdadera utopía: la mediación entre los contendientes. Los objetivos españoles en América eran expulsar a los británicos tanto del golfo de México como de las orillas del Misisipi y conseguir la desaparición de sus asentamientos en la América Central. La ayuda española, en todo caso, fue limitada, y más interesada en obtener las metas territoriales fijadas que en favorecer la independencia de las Trece Colonias.

Después de 1778, la lucha se trasladó al sur y el conflicto ya había adquirido un cariz internacional con la entrada de Francia. Un año más tarde la realidad se impuso y España declaró la guerra a Inglaterra, pensando incluso en la posibilidad de invadir Gran Bretaña mediante el concurso de una armada franco-española, plan que resultó inviable. Para su entrada abierta en el conflicto, el Gobierno español había firmado el llamado Tratado de Aranjuez, acuerdo secreto con Francia sellado en Aranjuez el 12 de abril de 1779, por el cual España conseguía una serie de concesiones a cambio de unirse a Francia en la guerra. Esta prometió su ayuda en la recuperación de Menorca, la Mobila, Panzacola, la bahía de Honduras y la costa de Campeche y aseguró que no concluiría paz alguna que no supusiera la devolución de Gibraltar a España. Esto provocó que los británicos tuvieran que desviar a Gibraltar tropas destinadas en un principio a las colonias.

Los puertos de Tolón y Brest, en Francia, que estaban bloqueados por los británicos, fueron desbloqueados por la falta de efectivos de la Marina Real británica. Con los puertos atlánticos abiertos, los franceses pudieron llevar tropas a América al mando de La Fayette y de Rochambeau, siendo esta ayuda de gran importancia para los colonos, como se señaló más arriba. Fue decisiva la batalla del cabo de Santa María (1780) en la que una flota combinada hispano-francesa capturó un convoy inglés. En total 52 buques, 80 000 mosquetes, 3000 barriles de pólvora, gran cantidad de provisiones y la ingente suma de 1 000 000 de libras esterlinas en lingotes y monedas de oro, destinados a mantener las operaciones militares en las colonias, fueron capturados. Lo que supuso uno de los mayores desastres navales de la historia del Reino Unido y dejando insostenible su situación militar.

Más tarde Holanda también se unirá a la coalición formada por España y Francia, con ambiciones de ganar posiciones por el dominio de los mares, aunque a diferencia de sus aliadas, Holanda no aportó tropas, tan solo provisiones, armas, vestimenta, divisas y algunos buques de guerra.

En 1781, 8 000 soldados británicos al mando del general Charles Cornwallis fueron rodeados en Virginia, el último reducto, por una flota francesa y un ejército combinado franco-estadounidense a las órdenes de George Washington de 16 000 hombres. Tras el sitio de Yorktown, Cornwallis se rindió, y el gobierno británico propuso la paz. En la batalla cayeron 156 británicos, 52 franceses y 20 independentistas, siendo los últimos muertos en combate durante la Guerra de la Independencia.

En los restantes frentes entre 1779 y 1781, España sitió Gibraltar, una vez más infructuosamente, y lanzó varias campañas contra distintos puntos estratégicos del golfo de México en manos británicas, la mayor parte coronadas por el éxito (Pensacola). Por otro lado, una exitosa expedición a Menorca permitió la recuperación de la isla en febrero de 1782. El Tratado de París o Tratado de Versalles se firmó el 3 de septiembre de 1783 entre Gran Bretaña y los Estados Unidos y puso término a la Guerra de Independencia de los Estados Unidos. El hecho de que Gran Bretaña perdiese todas las posesiones en el continente americano al sur de Canadá y al norte de Florida, hacía imposible un desenlace militar favorable para los británicos, solicitando estos el cese de las hostilidades.








En general los logros alcanzados pueden juzgarse como favorables para España y en menor medida para Francia a pesar del elevado coste bélico y las pérdidas ocasionadas por la casi paralización del comercio con América, un pesado lastre que gravitaría sobre la posterior situación económica francesa. Por otra parte, el triunfo de los rebeldes estadounidenses sobre Gran Bretaña no iba a dejar de influir en un futuro próximo sobre las colonias españolas. Esta influencia vino por distintos caminos: la emulación de lo realizado por comunidades en similares circunstancias, la solidaridad de los antiguos colonos con los que aún lo eran, la ayuda de otras potencias interesadas en la desaparición del imperio colonial español, etc. Estos aspectos se manifestaron de un modo claro durante las Guerras Napoleónicas.

Una vez conquistada la independencia resultó muy complicado poner de acuerdo a todas las antiguas colonias. En 1787, 55 representantes de las antiguas colonias se reunieron en Filadelfia con el fin de redactar una constitución. Se creaba así un único gobierno federal, con un presidente de la república y dos cámaras legislativas (Cámara de Representantes y Senado). Esta constitución estaba inspirada en los principios de igualdad y libertad que defendían los ilustrados franceses y se configuró como la primera carta magna que recogía los principios del liberalismo político estableciendo un régimen republicano y democrático. La independencia y democracia estadounidense causó un notable impacto en la opinión y la política de Europa.






Enlace al diccionario biográfico de la Real Academia de la Historia: http://dbe.rah.es/biografias/35206/luis-de-unzaga-y-amezaga


</doc>
<doc id="42821" url="https://es.wikipedia.org/wiki?curid=42821" title="Constitución de los Estados Unidos">
Constitución de los Estados Unidos

La Constitución de los Estados Unidos es la ley suprema de los Estados Unidos de América. Fue adoptada en su forma original el 17 de septiembre de 1787 por la Convención Constitucional de Filadelfia (Pensilvania) y luego ratificada por el pueblo en convenciones en cada estado en el nombre de «Nosotros el Pueblo» ("We the People"). La Constitución tiene un lugar central en el derecho y la cultura política estadounidense. La Constitución de los Estados Unidos es la constitución federal más antigua que se encuentra en vigor actualmente en el mundo.

Una copia original del documento se puede encontrar en los Archivos Nacionales en Washington D. C.

En septiembre de 1786, comisionados de cinco estados se reunieron en la Convención de Annapolis para discutir sobre reformas a los Artículos de la Confederación que mejorarían el comercio. 

Invitaron a representantes de otros estados a reunirse en Filadelfia para discutir mejoras al gobierno federal. A consecuencia del debate, el Congreso de la Confederación se propuso revisar los Artículos de la Confederación el 21 de febrero de 1787. Doce de los trece estados, siendo Rhode Island la única excepción, aceptaron la invitación y enviaron delegados a la convención en mayo de 1787. La resolución que convocaba la Convención especificaba su propósito de enmendar los Artículos de la Confederación, pero la Convención decidió proponer escribir una nueva Constitución. 

La Convención de Filadelfia votó por mantener las deliberaciones en secreto y decidió redactar un nuevo diseño fundamental de gobierno que eventualmente establecía que nueve de los trece estados tendrían que ratificar la constitución para que ésta entrara en vigor para los estados participantes.

El Plan de Virginia fue la agenda no oficial de la Convención, redactada en su mayoría por James Madison. Estaba dirigida a favorecer los intereses de los estados más grandes, y entre otras propuestas estaban: 

Una propuesta alternativa, el Plan de Nueva Jersey, otorgaba a los estados iguales prerrogativas independientemente de su tamaño y fue defendida por los estados más pequeños. 

Por lo tanto, en el Plan Virginia el único titular de la soberanía sería el gobierno central, por lo que los estados serían meras divisiones administrativas. Por el contrario, en el Plan Nueva Jersey los depositarios de la soberanía de la república habrían de ser los estados, en igualdad de condiciones entre todos ellos. La primera propuesta era intolerable para los que, como el autor de la Declaración de Independencia Thomas Jefferson (quien no estuvo presente en la Convención), creían que un gobierno central fuerte suponía a la vez una traición a los ideales ilustrados de la Revolución y una amenaza para el pueblo y los estados. Además, la mayoría de estadounidenses de entonces identificaba a su estado como su entidad política preeminente. Pero el Plan Nueva Jersey, por su parte, resultaba inaceptable para los que buscaban superar realmente el modelo confederal existente y reemplazarlo por uno más centralizado y federal, como era el caso de figuras tan preeminentes de la época como Alexander Hamilton de Nueva York, o James Madison de Virginia.

Otra diferencia que parecía irreconciliable entre estos planes era que el de Virginia defendía que los estados debían estar representados en el Legislativo federal en función de su población. Como esto claramente perjudicaba a los estados más pequeños o despoblados, el Plan Nueva Jersey reclamaba una representación idéntica para cada estado. La solución adoptada en el Compromiso de Connecticut zanjaba la discusión salomónicamente: el poder legislativo de la nueva república sería bicameral, aplicándose en una de esas cámaras la propuesta de Virginia y en la otra la de Nueva Jersey. Así, en la Cámara de Representantes sus miembros serían electos según la propuesta de Virginia, en función de su población, así que a más habitantes, más representantes. Pero en la otra cámara, en el Senado, se aplicaría la propuesta de Nueva Jersey y los senadores serían electos en igual cantidad para cada estado, independientemente de su tamaño y población. Ambos principios rigen hasta el día de hoy.

Al contrario del proceso de modificación establecido en el Artículo XVI de los Artículos de la Confederación, el Congreso sometió la propuesta a los Estados y fijó los términos de representación. 

El 17 de septiembre de 1787, la Constitución fue completada en Filadelfia. A continuación Benjamin Franklin pronunció un discurso en el que hablaba de unanimidad, aunque solo se requería que nueve estados ratificaran la Constitución para que ésta entrara en vigor. 

Luego de arduas luchas para la ratificación en varios estados, Nuevo Hampshire se convirtió en el noveno estado el 2 de junio de 1788. Una vez que el Congreso de la Confederación recibió noticias de la ratificación de Nuevo Hampshire, estableció fechas para que la Constitución entrara en vigor, y el gobierno federal creado por la Constitución comenzó a operar el 4 de marzo de 1789 bajo la presidencia de George Washington. En adelante, todos los presidentes del nuevo país iniciaron sus mandatos el 4 de marzo, hasta que en 1933 la Vigésima Enmienda adelantó esa fecha al 20 de enero.

Muchas de las ideas en la Constitución eran nuevas, y un gran número de ellas se derivaron de la literatura del Republicanismo en los Estados Unidos, de la experiencia de los trece estados, y de la experiencia del Reino Unido con su forma de gobierno mixta. La influencia más importante de Europa Continental vino de Montesquieu, quien enfatizaba en tener fuerzas equilibradas que se opusieran mutuamente para prevenir la tiranía. Esto refleja la influencia del tratado de Polibio —siglo II a. C.— acerca de los frenos y contrapesos de la Constitución de la República romana. John Locke es conocido por tener una influencia mixta, y la cláusula del debido proceso de la Constitución de los Estados Unidos se basó parcialmente en el derecho anglosajón con referencias a la Carta Magna de 1215.

Es de destacar asimismo la influencia que la tradición de gobierno democrático e igualitario de la Confederación Iroquesa tuvo en Benjamin Franklin a la hora de redactar la Constitución.

La Carta de Derechos de los Estados Unidos fueron las diez enmiendas añadidas a la Constitución en 1791, tal como los proponentes de la Constitución habían prometido a los oponentes durante los debates de 1788. La Declaración de derechos inglesa de 1689 fue una inspiración para la Carta de Derechos de los Estados Unidos. Por ejemplo, ambas requerían juicios con jurado, contienen un derecho a portar armas, y prohíben las fianzas excesivas al igual que los "castigos crueles e inusuales". Muchas libertades protegidas por las constituciones estatales y la Declaración de Derechos de Virginia fueron incorporadas la Carta de Derechos de los Estados Unidos.

La Constitución tiene siete artículos originales, y veintisiete enmiendas.

El Preámbulo establece:

El Artículo I establece el poder legislativo del Gobierno, el Congreso de los Estados Unidos, incluyendo la Cámara de Representantes y el Senado. El Artículo establece la forma de elección y calificaciones de los miembros de la Cámara y del Senado. Además, estipula el debate libre en el Congreso y limita el comportamiento egoísta de miembros del Congreso, perfila el procedimiento legislativo e indica los poderes del poder legislativo.

El Artículo II describe la Presidencia (poder ejecutivo): procedimientos para la selección del presidente, los requisitos para acceder al cargo, el juramento que se debe prestar, y los poderes y deberes de la oficina. También establece la oficina del vicepresidente de los Estados Unidos, y especifica que el vicepresidente sucede en la presidencia en caso de incapacidad, muerte o dimisión del presidente, aunque no quedó claro si esta sucesión es temporal o permanente. En la práctica, esto se trató siempre como sucesión, y la 25.ª enmienda estipula explícitamente la sucesión. El Artículo II también regula el juicio político ("Impeachment") y la remoción del cargo de los oficiales civiles (el presidente, el vicepresidente, los jueces, y otros).

El Artículo III describe el sistema judicial (poder judicial), incluyendo el Tribunal Supremo de los Estados Unidos. El artículo requiere que haya una corte llamada el Tribunal Supremo. El Congreso, a su discreción, puede crear cortes inferiores, cuyos juicios y órdenes pueden ser revisados por el Tribunal Supremo. El Artículo III también requiere la participación de un jurado en todos los casos criminales, define el crimen de traición, y encarga al Congreso establecer un castigo para él.

El Artículo IV describe la relación entre los estados y el Gobierno federal y entre los propios estados. Por ejemplo, esto requiere que los estados den "total fe y crédito" a los actos públicos, registros y procesos de otros estados. Permite al Congreso regular la forma de probar tales actos, registros o actas, y los efectos de los mismos. La cláusula de "privilegios e inmunidades" prohíbe a gobiernos estatales discriminar a los ciudadanos de otros estados en favor de ciudadanos residentes (por ejemplo, imponiendo penas mayores a los residentes de Ohio condenados por crímenes cometidos en Míchigan).

El Artículo V describe el proceso necesario para reformar la constitución. Establece dos métodos de proponer enmiendas: por el Congreso o por una convención nacional solicitada por los estados. Con el primer método, el Congreso puede proponer una enmienda con los votos de dos tercios (de un cuórum, no necesariamente de toda la cámara) del Senado y de la Cámara de Representantes. Con el segundo método, los cuerpos legislativos de las dos terceras partes de los estados pueden convocar y obligar al Congreso a convocar una convención nacional, y el Congreso debe convocar esa convención con el fin de considerar las enmiendas propuestas. Hasta 2015, solamente se ha utilizado el primer método —propuesta del Congreso—. 

Una vez propuestas —bien por el Congreso o por las convenciones nacionales— las enmiendas deben ser ratificadas por las tres cuartas partes de los estados para que tengan efecto. El Artículo V otorga al Congreso la opción de requerir ratificación por los cuerpos legislativos de los estados o por convenciones especiales convocadas en los estados. El método de ratificación por convención solo se ha utilizado una vez (para aprobar la Vigesimoprimera Enmienda). El Artículo cinco actualmente solo impone una limitación al poder de enmienda-ninguna enmienda puede privar a un estado de su representación igual en el Senado sin el consentimiento de ese estado.

El nombre "enmienda" no es, en la terminología jurídica de los países del Continente europeo (Civil Law countries), significativo. En Europa, enmienda significa modificación de un proyecto de ley, que luego será admitida o rechazada por la mayoría de la cámara legisladora. Lo que los norteamericanos entienden por "amendment" es lo que en España se denomina "disposición adicional", que posteriormente puede ser integrada en el articulado de la ley, si se llega a aprobar un texto refundido. Cuando en Estados Unidos alguien dice que se acoge a una determinada enmienda constitucional, no se refiere a una propuesta alternativa, propia de un proyecto en discusión, sino a un texto adicional a la Constitución, que posee distinta numeración que los "articles" de la misma, pero no por ello pierde su vigencia. Ello tiene relación con el sistema jurídico de "Common Law", heredado durante la colonización por el Reino Unido.

Los propios "articles" de la Constitución no equivalen a los artículos de las constituciones de países como Francia, Italia, Alemania o España, sino que son enunciados normativos mucho más extensos, equivalentes en algunos casos a títulos enteros de la Constitución Española (por citar algún ejemplo).

El Artículo VI establece a la Constitución, las leyes adoptadas y tratados de los Estados Unidos concluidos de acuerdo con ella, como la ley suprema en todo el territorio nacional, y que "los jueces de todos los estados estarán vinculados por la misma, a pesar de cualquier cosa que establezcan al contrario las leyes o las constituciones de los estados". También valida la deuda nacional creada bajo los artículos de la confederación y requiere que todos los legisladores, funcionarios federales, y jueces juren o afirmen "apoyar" la Constitución. Esto significa que las constituciones y las leyes de los estados no deben estar en conflicto con las leyes de la Constitución federal; en caso de conflicto, los jueces del estado están limitados legalmente a acatar las leyes federales y la Constitución por encima de las de cualquiera estado.

El Artículo VI también indica que no se requerirá "nunca ninguna prueba o requisito religioso para acceder a cualquier oficina o dependencia pública dependiente de los Estados Unidos".

El Artículo VII fija los requisitos para la ratificación de la Constitución. La Constitución no entraría en vigor hasta que por lo menos nueve estados la ratificaran en convenciones estatales especialmente convocadas para tal objetivo.

A menudo se habla de la constitución estadounidense como la constitución más antigua todavía en vigor en el mundo. Sin embargo, es necesario puntualizar que realmente es la constitución federal escrita más antigua. Respecto a si es la constitución más antigua todavía en vigor, es necesario señalar que los Estatutos de la República de San Marino de 1600 ("Leges Statutae Republicae Sancti Marini"), que forman parte del ordenamiento jurídico fundamental de esa república, junto con la Ley Electoral de 1926 y la Declaración de Derechos de los Ciudadanos de 1974, serían más antiguos y también se señalan a menudo como la constitución más antigua vigente, aunque hay opiniones (especialmente desde el punto de vista estadounidense) que indican que no se puede hablar de dichos Estatutos como una constitución tradicional o en sentido estricto, esto es, como un único documento escrito, sino como parte del ordenamiento jurídico fundamental, no como constitución formal y, en este sentido, en algunas páginas web de la propia San Marino se indica que el país no tiene una constitución propiamente dicha. Por otra parte, si se tienen en cuenta también las constituciones de entidades subnacionales, la constitución del estado estadounidense de Massachusetts, ratificada el 15 de junio de 1780, sería siete años más antigua incluso que la de los Estados Unidos, lo que la convertiría en la constitución escrita más antigua del mundo todavía en vigor.




</doc>
<doc id="42826" url="https://es.wikipedia.org/wiki?curid=42826" title="Hermandad">
Hermandad

Los términos hermandad y confraternidad pueden hacer referencia:




</doc>
<doc id="42829" url="https://es.wikipedia.org/wiki?curid=42829" title="Caza-recolección">
Caza-recolección

Se conoce como caza y recolección al sistema de sustento del Paleolítico y Mesolítico, practicado aún por algunos pueblos.

La caza-recolección fue la primera adaptación de la humanidad que se llevó a cabo con éxito, ocupando al menos el 90% de la historia de la humanidad.

Solamente algunas sociedades contemporáneas han sido clasificadas como sociedades cazadoras y recolectoras, y complementan su actividad con la horticultura y el cuidado de los animales.

La especie humana, desde su existencia hace 5 millones de años hasta hace diez mil años, sobrevivía mediante la caza y la recolección. Aproximadamente una treintena de individuos, unidos por el parentesco, cazaban rumiantes y recolectaban frutos y semillas silvestres. Este sistema no se diferencia actualmente de la forma de vida de otras especies de mamíferos depredadores.

En esos cinco millones de años, la característica principal fue el aumento del volumen del cerebro, es decir, que la capacidad de almacenar y transmitir han sido necesarias para la supervivencia; sobrevivían los humanos con mayor cerebro, que eran los que organizaban grupos para cazar, los que informaban de algún peligro y los que diseñaban estrategias ofensivas o defensivas. Dicha capacidad de comprensión y comunicación ha sobrevivido hasta la organización de la sociedad y economía actual.

El concepto de cazador-recolector es mucho más complejo de lo que parece a simple vista, ya que no solo conlleva una serie de actividades concretas destinadas a garantizar la subsistencia de un grupo ligadas a una forma de organización económica. El conjunto de actividades de la vida cotidiana, un mundo espiritual, unos modos sociales determinados y la organización interna concreta de los cazadores-recolectores presentan algunas tendencias que frecuentemente los diferencian de las sociedades estatales basadas en el sedentarismo y la agricultura. Es decir, el concepto de cazadores-recolectores, no solo se refiere a un tipo de
organización económica.

El alcance cronológico del concepto es muy amplio. Hasta hace diez mil años, el hombre era exclusivamente cazador-recolector. Aún en nuestro tiempo, existen sociedades que hasta hace poco practicaron o siguen practicando la caza y las actividades derivadas como medio básico de subsistencia. No es por tanto, una actividad exclusivamente "prehistórica", sino que ha tenido una proyección, aunque cada vez más limitada, en el mundo moderno y contemporáneo. Los grupos de cazadores-recolectores actuales pueden llegar a guardar algún parecido con los grupos prehistóricos (toda la historiografía prehistórica basada en la comparación etnográfica lo considera así), como por ejemplo ser grupos pequeños, unidos en la mayor parte de los casos por lazos de parentesco y con redes sociales eficaces externas al grupo para fines reproductivos, principalmente, o de alianzas sobre determinadas materias. Sin embargo, el aproximarse al estudio etnográfico 

Los alimentos más comunes eran los vegetales (recolección) y la carne (caza o carroñeo). En un principio eran los únicos pueblos que existían y hoy existen todavía, a duras penas, pequeños grupos nómadas que viven de la caza de animales, de la pesca, de la recolección de frutos, semillas y setas (extracción de raíces y tubérculos), y de la recogida de miel, actividades que rara vez aportan más del 50% de su dieta alimenticia. Los grupos más conocidos son los aborígenes de Australia, los esquimales de Groenlandia, Canadá, Alaska y la zona de Siberia que linda con el estrecho de Béring y diversas etnias de la selva amazónica. Los san de Botsuana, Namibia y sur de Angola han perdido la mayor parte de sus territorios y hoy muchos viven como jornaleros. Algunos pigmeos continúan siendo cazadores activos. Existen grupos menos conocidos en Somalia, Etiopía, Kenia, Tanzania, Ruanda y Burundi; en Canadá, Estados Unidos, Brasil, Venezuela, Colombia, Bolivia y Chile, o en Rusia, India, Tailandia, Malasia, Indonesia y Filipinas.

Para los antropólogos los estudios de estos pueblos han sido muy importantes y en parte este interés ha ayudado a estas personas a mantener su modo de vida. Las investigaciones realizadas en los años 1960 entre los San, indicaban que frente a la creencia general de que las condiciones de vida eran peores que la de los pueblos que adoptaron la economía productiva de agricultura y ganadería, la esperanza de vida era superior en los pueblos primitivos y de igual modo sus condiciones de salud, al no ser azotados por las periódicas epidemias que se ceban sobre las concentraciones humanas de las aldeas, aunque debían soportar enfermedades relacionadas con el parasitismo. Habría menos estratificación social y más paridad entre sexos, además sorprende encontrar similitudes entre grupos al comparar los estudios entre los san con otros estudios realizados en culturas muy alejadas, con lo que algunos antropólogos consideran que los antepasados de las sociedades que ya han alcanzado el neolítico vivirían de esa forma.

Ted C. Lewellen (1970) ha descubierto que la caza y recolección entre los pueblos "primitivos" lejos de ser algo parasitario es un verdadero modo de producción ya que los pueblos que basan genuinamente su economía en la caza (y la pesca) y la recolección de vegetales casi siempre permiten una tasa de reproducción de sus presas.

Durante un tiempo, se pensó que el impacto ecológico de las sociedades de cazadores-recolectores era inexistente dado que no practicaban ni la agricultura ni la ganadería y poseían un desarrollo tecnológico limitado. Añadido a esto, sus actividades itinerantes limitaban su influencia en un punto concreto de su entorno. Sin embargo, se ha planteado que los cazadores-recolectores pudieron tener un importancia clave en la extinción de la megafauna y en la transformación de comunidades ecológicas por el uso del fuego. Todavía existe un debate entre la comunidad científica sobre las evidencias de estos impactos y las responsabilidad de las sociedades cazadoras-recolectoras en ellos.

El término ecosistema fue introducido en 1935 por el ecólogo inglés A. G. Tansley, que lo definía como «la unidad fundamental ecológica constituida por la interrelación entre una biocenosis y un biotopo». Es decir, está constituido por un medio físico, que bien puede ser el biotopo, el hábitat o el ambiente, por unos pobladores, que bien puede ser la biocenósis, la comunidad de seres vivos o la colectividad entre plantas y animales que viven en un espacio vital, y la interrelación entre todos ellos.

El Planeta Tierra es un ecosistema que se divide en acuático, que se diferencia en agua dulce (ríos y lagos) y en salados (mares y océanos), y en terrestre, que se diferencia en desiertos, praderas y bosques, que a su vez, el árbol del bosque puede considerarse un sistema restringido.

Muchas poblaciones interactúan entre sí en el ecosistema formando las comunidades. El medio donde se desarrollan se diferencia según su naturaleza y volumen: un edafotopo es el sustrato, un climátopo es lo característico a los climas, y un hidrótopo son los factores hidrográficos.

El hábitat es el lugar donde vive la comunidad, y el nicho es el papel funcional que desempeña una especie dentro de la comunidad, es decir, su subsistencia. Los organismos ocupan distintos nichos en un mismo hábitat, que depende del nivel de la estratificación de la comunidad: a mayor estratificación, mayores nichos.

La visión de la Antropología que predominaba en los años 60 era la idea de que los cazadores-recolectores representaban a la gente que vivía durante la Edad de Piedra. Eran una especie de fósiles vivientes. Fue en la década de 1980 cuando los investigadores y los críticos se cuestionaron este punto de vista.

Esta idea de que las poblaciones vivieran aisladas de los pueblos productores y que consumían lo que la biocenosis les proporcionaba contradecía a las hipótesis que hasta ese momento se aceptaban.

En el estudio de los pueblos primitivos, la Etnografía se aplicaba a los análisis ideográficos, que proporcionaban informes de dichos pueblos y su vida social. La diferencia entre Etnografía y Prehistoria es que la etnografía deriva su conocimiento a partir de la observación y del contacto directo con el pueblo investigado, en cambio la Prehistoria deriva su conocimiento a partir de los elementos que se encuentran dispersos.

Normalmente cultura es confundido con la forma de vida social, y los antropólogos la definen como «el proceso mediante el cual una persona adquiere contacto con otras personas, elementos materiales, conocimiento, habilidad, ideas, creencias, gustos y sentimientos.»

Existen diferentes acepciones para cultura, aunque todas tienen en común que es algo aprendido y permite al hombre adaptarse al ambiente natural. Según otras definiciones, como por ejemplo la de E. B. Tylor, «es el conjunto complejo que incluye conocimiento, creencias, arte, moral, ley, costumbre, y otras capacidades y hábitos adquiridos por el hombre como miembros de una sociedad». En otra definición, cultura es «la parte del ambiente hecha por el hombre», donde va implícito el reconocimiento de que la vida del hombre transcurre en dos escenarios, que son el natural (o hábitat) y el social.

En algunas sociedades se transmite generación tras generación dicho conocimiento según la tradición cultural. La comprensión, la utilización del lenguaje y las ideas también se transmiten.

En este sentido, la cultura es un sistema integrado por las normas de conducta aprendidas, que son características de los miembros de una sociedad. Constituye el modo de vida de los grupos sociales, y por lo tanto, es un fenómeno humano. Entre todas las criaturas del reino animal, solamente el hombre es el único capaz de elaborar, conservar y transmitir la cultura.

A lo largo de varios millones de años el hombre desarrolló culturas más complejas para modificar sus condiciones de vida. Los lugares habitados informan sobre el tamaño de las agrupaciones sociales gracias a los restos óseos, de talla, útiles o ceniza, y los modos de vida de los pueblos desaparecidos, pero no informan sobre las costumbres, actitudes y creencias que conforman la cultura. Los pueblos primitivos actuales sí pueden llegar a informar sobre la cultura debido a su capacidad de habla.

A mediados del siglo XX la etnografía comparada alcanzó gran desarrollo y se publicaron numerosos estudios. Esta ingente cantidad de trabajo llevó a tratar de comprender como pudieron ser las sociedades paleolíticas a partir de los resultados de la etnografía comparada. Esta tendencia es un punto muy polémico en la investigación social de la prehistoria.

Algunos investigadores han criticado la tendencia a recurrir a estudios que se encargan de las sociedades actuales que continúan dentro de un sistema de caza y recolección para luego establecer paralelos con los grupos prehistóricos de cazadores-recolectores, asumiendo estas similitudes como clave interpretativa. Esta práctica, muy habitual en la década de 1960 y 1970, se ha venido matizando cada vez más, debido al peligro que supone asumir estos paralelos como ciertos. En este momento se tiende a considerar este tipo de investigaciones como complemento de la actividad arqueológica.

El riesgo es debido a que en primer lugar, nos es desconocido en gran medida, al menos con una seguridad científica irrefutable, muchos aspectos de los grupos paleolíticos. Aunque, por otra parte, los estudios comparados puedan aportar datos útiles en la investigación del Paleolítico, no se debe olvidar que la arqueología es una ciencia esencialmente, al menos en una buena parte de su praxis, interpretativa, más cuando no se puede apoyar en textos escritos.

El conocimiento más completo de poblaciones paleolíticas ha llegado mediante la arqueología prehistórica, es decir, mediante la interpretación de restos materiales, industria lítica, estructuras de habitación enterramientos, etcétera; eso sin olvidar la validez como aporte extra de los estudios sobre hábitat, clima, fauna, y demás aspectos de los ecosistemas paleolíticos, que nos han aportado un marco de referencia esencial a la hora de contextualizar muchas de las actividades desarrolladas por estos grupos. El clima en el que se movían, los recursos de las diferentes zonas, la dieta (a partir de cotejar las informaciones sobre fauna con los restos hallados en yacimientos), son una parte esencial en el conocimiento de estas sociedades, debido a la estrecha relación de dependencia con el medio que presentan debido a su ausencia de producción de alimentos.

El sistema económico ha perdurado hasta las comunidades recientes. Los habitantes de la Patagonia utilizaron puntas de flecha de sílex sin pulimentar hasta el siglo XIX, y a lo largo del siglo XX se han descubierto poblaciones que desconocían estas técnicas agrícolas. Otros grupos han estado aislados geográficamente durante los últimos diez mil años.

Posiblemente se especializaría las labores por sexo y edad, es decir, los hombres cazaban y las mujeres y los niños recolectaban, y posiblemente el que presente mayor habilidad con las manualidades, dedicaría más tiempo a la fabricación de armas o al tratamiento de las pieles. Aparte de estas actividades económicas también se descubrieron minas excavadas con instrumentos paleolíticos e intercambios comerciales con la presencia de materiales como la obsidiana o conchas marinas en enterramientos a dos mil kilómetros de su origen.

Quizá la característica más destacada de estos grupos es su sistema económico, basado no en la producción (cambio fundamental con la llegada del Neolítico en el caso de los grupos prehistóricos), sino en la explotación de los recursos de un medio concreto sin llegar a agotarlos, utilizando estrategias adquiridas a partir de un exquisito conocimiento del entorno. A pesar de las limitaciones en los estudios, sobre todo en el caso de grupos paleolíticos, las comparaciones etnográficas con los grupos actuales parecen dar un papel mayor al consumo de vegetales sobre la carne. Sin embargo, otros autores han apuntado que las necesidades calóricas de un grupo pueden cambiar en función de una multiplicidad de elementos, como pueden ser el clima, la actividad, etcétera, por lo que todo parece apuntar a que factores ambientales influyen en las proporciones en la dieta de carne y vegetales. Estudios recientes afirman que los grupos cazadores-recolectores actuales presentan, en climas cálidos, una presencia de vegetales en su dieta de hasta un 80%, pero es de suponer que en climas más fríos, el porcentaje de carne en la dieta aumentaría (debido a una necesidad de aporte calórico mayor). Además, en líneas generales, estudios realizados han mostrado como los grupos cazadores-recolectores ven satisfechas todas sus necesidades con una media de trabajo semanal inferior a las 35 horas. 

Con respecto a los grupos prehistóricos, hay aspectos relativos a la subsistencia que no acaban de estar claros y los estudios comparados no terminan de alcanzar, debido a las diferencias en el entorno con grupos similares actuales. De todos modos, si parece bien conocido el camino que estas estrategias siguieron a lo largo del Paleolítico. En un primer momento, durante el Paleolítico Inferior, tenemos pequeños grupos que practican una tosca (a juzgar por las evidencias) caza, combinada con la recolección de alimentos y el aprovechamiento de carroña. Estos primeros grupos tenían un claro carácter oportunista. Durante el Paleolítico Medio, comienzan a diversificarse tanto las técnicas de caza (más complejas) como la diversidad de recursos a explotar y la manera de hacerlo, con un carácter eminentemente adaptativo que revela un gran conocimiento del medio. Ya en el Paleolítico Superior, se añaden definitivamente nuevos recursos (como la introducción de la pesca y el marisqueo).

El mundo social de los cazadores-recolectores actuales es enormemente complejo, y muy distinto en muchos aspectos al de las sociedades productoras actuales. En líneas generales se puede afirmar, sobre la base de los diversos estudios etnográficos realizados (muy especialmente los realizados con los San) que estos grupos tienden a las relaciones sociales laxas, solidarias y ausentes en buena medida de conflictos.
De este modo, en el caso de los San, el sistema de propiedad privada es radicalmente distinto al conocido hoy en día por la mayoría de las sociedades. Poniendo la caza como ejemplo, se considera que aunque la presa es del cazador que la abate, una vez satisfechas sus necesidades y las de su familia, cualquier miembro del grupo puede aprovechar el resto para su consumo, de modo que se concede una gran importancia a una ética de compartirlo todo de forma que nadie del grupo pase necesidad; las reservas de cualquier cosa no indispensable, por lo general, no existen. Del mismo modo, contemplan relaciones sociales complejas, como el divorcio (realizado por lo general de mutuo acuerdo, con un mero abandono de hogar); es curioso como se contemplan los matrimonios experimentales y como el marido pasa un periodo de prueba en el que debe probar que es capaz de alimentar a su familia.

Un aspecto general de estas sociedades es su generalizada ausencia de violencia. Los San, por ejemplo, le tienen verdadero miedo, buscando siempre soluciones alternativas, como el abandono del poblado por una de las dos partes en conflicto. Además, en caso de darse, las situaciones de violencia están alta y eficazmente ritualizadas. Del mismo modo, la educación de los niños tiende a basarse en el ejemplo, con la tutela de sus padres, sustituidos por algún otro familiar en caso de falta.

Los estudios también tienden a revelar un papel importante del prestigio y la posición social, en general mucho más valorado que la propiedad privada; muchas veces la posición social lleva implícita influencia en los semejantes (a mayor prestigio, más valiosos se consideran los consejos ofrecidos); el prestigio en estas sociedades suele adquirirse mediante el trabajo, el esfuerzo y el ayudar a los demás.

Es muy común también un altísimo grado de conocimiento del medio y las limitaciones de los recursos que les rodean por parte de estos grupos, lo que a menudo redunda en ciertas prácticas sociales de control demográfico, con una enorme variedad; es muy habitual la presencia de tabúes sociales encaminados a controlar la demografía (por ejemplo, el denominado "tabú post-parto", basado en la abstinencia), así como de un aprovechamiento de sus grandes conocimientos sobre propiedades de la vida vegetal de su entorno como métodos abortivos, habitual en algunas sociedades de Sudamérica. La identificación más global con su medio suele darse entre los aborígenes australianos, que se consideran a sí mismos como parte del paisaje.

Por lo general, la familia tiene un gran relieve en estas sociedades. Es necesaria para mantener y educar a los pequeños, con cara a su papel y vida social como futuros adultos; también suelen implicar obligaciones recíprocas entre sus miembros, e incluso estas se hacen en ocasiones extensivas a toda la comunidad, caso de los niños y ancianos, que en la mayor parte de estas sociedades nunca serán desatendidos.

Con respecto a las sociedades prehistóricas de cazadores-recolectores, nuestro conocimiento es bastante más limitado. Sobre la base de ciertas evidencias bastante sólidas, se presupone una densidad de población variable según las condiciones ambientales pero en general tendente a la baja (unas 40/60 personas de media), organizada en torno a pequeños núcleos familiares, relacionados entre sí y con otros grupos de su entorno, con el objeto de evitar caer en la endogamia. Parece evidente una alta cohesión grupal basada en la necesidad, tanto de obtención de alimentos como de mera supervivencia. Con base en elementos presentes en el arte paleolítico, se tiende a asumir cada vez más la presencia de prácticas mágicas de tipo chamánico entre estos grupos prehistóricos, pero hoy en día es aún tema de debate entre los investigadores.




</doc>
<doc id="42841" url="https://es.wikipedia.org/wiki?curid=42841" title="Francisco Salzillo">
Francisco Salzillo

Francisco Salzillo y Alcaraz (Murcia, 12 de mayo de 1707-ibídem, 2 de marzo de 1783) fue un escultor barroco español, considerado como el más representativo imaginero del español y uno de los más grandes del Barroco. Salzillo se dedicó en exclusiva a la temática religiosa y supo transmitir a su estilo los cambios que se fueron produciendo durante el , lo que se vio plasmado en una escultura de transición hacia el rococó y el neoclasicismo, así como en diversos cambios que se fueron produciendo en el taller que heredó de su padre, el también escultor e imaginero Nicolás Salzillo.

Su vida transcurrió enteramente en Murcia. Hoy día cuenta con un museo dedicado a su obra, el Museo Salzillo, que alberga algunas de sus obras más características, como el belén o los ocho pasos que procesionan el Viernes Santo en la llamada "procesión de los Salzillos".

Francisco Salzillo nació en Murcia el 12 de mayo de 1707. Su padre, Nicolás Salzillo, era un escultor italiano, procedente de Santa Maria Capua Vetere, que unos años antes se había afincado en Murcia. Tras iniciar estudios de Letras con los jesuitas, parece que entró en la Orden Dominicana como novicio, tras lo cual tuvo que hacerse cargo del taller escultórico de su padre a la muerte de este en 1727, cuando Francisco contaba con tan solo veinte años.

Era el segundo de siete hermanos, algunos de los cuales trabajarían en el taller familiar, concretamente José Antonio y Patricio, nacidos en 1710 y 1722 respectivamente, y posiblemente Inés, encargada del dorado y estofado de las imágenes realizadas en el taller familiar. En 1746 se casó con Juana Vallejo y Taibilla, matrimonio fruto del cual nacieron dos hijos: Nicolás, nacido en 1750 y muerto al año siguiente, y María Fulgencia. Toda la vida de Francisco Salzillo tuvo lugar en Murcia, donde se hizo con un nombre y una fama que trascendieron lo meramente artístico. Solamente hay documentado un viaje suyo fuera de la ciudad de Murcia, el que realizó a Cartagena para la entrega de las imágenes de los Cuatro Santos en 1755. Rechazó la invitación del Conde de Floridablanca para trasladarse a Madrid, lo que le habría servido para darse a conocer en la Corte.

Con el paso de los años, su obra fue adquiriendo fama y recibió multitud de encargos de iglesias y conventos de Murcia y de las provincias limítrofes: Alicante, Albacete y Almería. En 1755 se le nombró "Escultor Oficial del Concejo de Murcia e inspector de pintura y escultura".

Tras la muerte de su esposa en 1763, las reuniones de Salzillo con otros artistas e intelectuales murcianos se hicieron más frecuentes. En 1777 fundaron la Real Sociedad Económica de Amigos del País de Murcia, que sirvió para que en 1779 se creara la Escuela Patriótica de Dibujo, que tuvo como primer director a Salzillo. Falleció en Murcia el 2 de marzo de 1783. Fue enterrado en el desaparecido Convento de Capuchinas de Murcia, donde había profesado su hermana Francisca de Paula.

El historiador y crítico de arte ilustrado Juan Agustín Ceán Bermúdez, en su "Diccionario de los profesores de las bellas artes en España" (1800), nombraba al escultor como Francisco Salcillo y lo hacía autor de mil setecientas noventa y dos obras. Se trata de una cantidad exagerada, ya que la cifra estaba basada en una publicación en la que Luis Santiago Bado, periodista murciano contemporáneo del escultor y primer biógrafo suyo, declaraba:

Los grupos procesionales habían sido considerados como un grupo homogéneo, pero las demás obras se habían cuantificado sin medida. A pesar de ello, lo cierto es que Francisco Salzillo desarrolló una intensa actividad entre 1727 y 1783, circunstancia que el mismo Luis Santiago Bado calificaba como:

Desgraciadamente, la Guerra Civil española (1936-1939), fue marco de la destrucción de muchas de sus creaciones. De entre las que se conservan, la mayoría se distribuyen por toda la Región de Murcia y algunas provincias limítrofes.

Las producciones más destacadas de su época juvenil, en la que le tocó hacerse cargo del taller de su padre, fueron la "Dolorosa" de la parroquia de Santa Catalina, el "San José" de Santa Clara, la "Sagrada Familia" de San Miguel y la "Inmaculada" del convento de Verónicas, todas ellas presentes en la ciudad de Murcia.

A partir de 1740 empezó a apreciarse con mayor claridad su estilo personal y bien definido. Fue en este año cuando consiguió fama con "La Piedad" de la Cofradía de los Servitas de la parroquia de San Bartolomé de Murcia, modelo que repitió para Lorca, Dolores de Alicante y Yecla. Fue su primera incursión en la iconografía pasionaria, de la que se convertiría en un gran maestro. Otras obras importantes que siguieron a ésta fueron el "San Antón" de la ermita de San Antón (1746), el "San Agustín" del Convento de las Agustinas del Corpus Christi y el medallón de la "Virgen de la Leche" para la Catedral de Murcia. La influencia italiana se aprecia en obras de este período como las imágenes de "San Francisco" y "Santa Clara" del convento de Capuchinas. El movimiento y la expresión de sus manos les convierten en unas de las principales obras barrocas en el terreno de la espiritualidad y la mística.

A partir de 1765 y con Roque López, el principal de sus discípulos, trabajando ya en su taller, se puede hablar de una producción más industrializada. Son características de este período la "Virgen de las Angustias" de Yecla, la "Virgen de la Aurora" de Aledo, el "Lavatorio de los pies de Cristo al Príncipe de los Apóstoles" de las Salesas Reales de Orihuela, o la "Sagrada Familia" de la Iglesia de Santiago de Orihuela. Además destaca el "Cristo de las Isabelas o de la Buena Muerte" o "Cristo Yacente" de las Clarisas de Orihuela (1774), única escultura en toda su producción de esta temática. Destacan también los santos Dominicos de la Iglesia de Santiago de Orihuela (1775).

A partir de 1776 se observa un viraje en la producción de Salzillo incluyendo algunas notas del neoclasicismo. Son características de este periodo la imagen de Cristo del paso de "Pretorio en Casa de Pilatos" (1777) de la cofradía del Ecce-Homo de Orihuela o el "Cristo atado a la columna" (1777-1778) de la Cofradía de Jesús de Murcia

Muchas cofradías acudieron a Salzillo cuando se había convertido en maestro indiscutible en el arte escultórico en el Reino de Murcia. Sin embargo, son dos las que atesoran el mayor número de ellas: la de Nuestro Padre Jesús en Murcia, y la del Prendimiento (Cofradía California) en Cartagena.

Entre la variada producción del maestro, el Belén ocupa un lugar destacado por su calidad artística y la fina observación de la realidad campesina del siglo XVIII.

Realizado a partir de 1776 por encargo de su amigo Jesualdo Riquelme y Fontes para decorar su palacio, y culminado por Roque López, el belén es una de las obras más representativas de la obra de Francisco Salzillo. Está compuesto por 525 figuras de 25-30 centímetros (166 humanas y 364 animales) realizadas en barro cocido, madera y cartón. Además del paisaje con sus elementos naturales, hay un marco arquitectónico compuesto por 8 edificios, entre ellos el palacio de Herodes, el templo de Jerusalén, la posada...que se pueden ver amueblados con pequeños enseres. Basándose en los Evangelios de San Mateo y de San Lucas, Salzillo va relatando la historia bíblica del Nacimiento de Cristo, desde la Anunciación a la Huida a Egipto, compaginando las escenas religiosas con otras de carácter popular o costumbrista, siendo fiel reflejo de muchas de las tradiciones de la época. Basado en origen en la tradición del Pesebre napolitano, crearía una auténtica escuela de belenes que perdura en Murcia hasta nuestros días.

El escritor y erudito Javier Fuentes y Ponte fue el autor del primer catálogo descriptivo de este belén en 1897. En 1909, el belén salió de Murcia con el objetivo de ser vendido, siendo expuesto en 1914 en el Museo Arqueológico Nacional y tasado en 165 000 pesetas. La obra regresó a Murcia en 1915, cuando el Ministerio de Instrucción Pública y Bellas Artes autorizó su compra para el pueblo de Murcia por 27 000 pesetas. En un principio estuvo situado en el Museo de la Trinidad, siendo trasladado en 1956 al Museo Salzillo.

El Belén de Salzillo ha sido expuesto en dos ocasiones en la ciudad de Madrid. La primera fue en 1961 en el Museo Nacional de Artes Decorativas, y la segunda en 1998 en el Palacio Real. Asimismo, en 1999 tuvo lugar una exposición en la sala Braccio di Carlomagno de la Ciudad del Vaticano, donde se mostraron las principales figuras del mismo.

Francisco Salzillo trabajó exclusivamente la temática religiosa (procesional y no procesional), y casi siempre en madera policromada. Su obra es el resultado de un cruce de influencias y estilos. Por medio de su padre Nicolás recibió la influencia de escultores italianos como Bernini y Andrea Bolgi, aunque la obra del escultor francés Antonio Dupar y la tradición española también estuvieron presentes en su formación. La disposición de las manos en algunas de sus obras fue un rasgo significativo que heredó de su padre: la izquierda sobre el pecho y la derecha extendida, a veces invertidas. También las obras de este le sirvieron de inspiración para la escultura infantil.

No obstante, el Barroco italiano fue lo que le marcó más, mediante la estampa, el grabado y contactos directos con diferentes artistas y con sus creaciones. Con todo esto, el estilo personal de Francisco que caracterizaría sus obras destacó desde muy pronto, con técnicas como el terminado del cabello a punta de cincel o su labrado en forma de estrías muy finas. A diferencia de los grandes autores del , como Montañés o Gregorio Fernández, Francisco Salzillo no profundizaría en los aspectos dramáticos de las escenas, ahondando en conceptos naturalistas y de idealizada belleza que serán ya transición del final del Barroco al Rococó y al Neoclasicismo.

Salzillo creó escuela, la llamada "Escuela Murciana de Escultura", que trascendió a su época y que ha permanecido vigente hasta nuestros días pues, tanto sus primeros seguidores como los que se han ido sucediendo hasta la fecha, han perpetuado los modelos y tipos iconográficos y estilísticos de Francisco Salzillo.

Salzillo heredó el taller de su padre tras la muerte de este en 1727 y asumió su dirección. Empezó siendo un taller familiar, en el que trabajaban sus hermanos José Antonio y Patricio, y años más tarde se incorporaron diversos discípulos, de los que solo son conocidos los nombres de José López y Roque López. El primero entró a trabajar en 1753, cuando Salzillo estaba comenzando los trabajos de la serie pasionaria de Viernes Santo y el taller necesitaba de pupilos dispuestos para los trabajos más rudimentarios que requería la talla en madera. Por su parte, Roque López se comprometió mediante contrato en 1765, año en el que Salzillo inauguró su academia doméstica. Asimismo, es sabido que el taller de Salzillo mantuvo contactos con el arquitecto y escultor Jaime Bort, aunque únicamente en el mundo del retablo.

Francisco recibió de su padre como herencia herramientas, dibujos y obras como santos eremitas, figuras de mujer o modelos infantiles. Gracias a ellos, el autor se fue formando como escultor y fue construyendo su propio estilo. En el taller, estas piezas eran estudiadas con frecuencia para ver novedades iconográficas, soluciones espaciales, formas anatómicas, giros corporales o expresiones de rostros antes de ser llevados a la madera.

Los bocetos que se conservan en el Museo Salzillo han sido una fuente de gran valor para comprender la organización del trabajo en el taller y el proceso previo al trabajo de la madera. Tras recibir un encargo, Salzillo dibujaba en papel la idea original, con sus rasgos tridimensionales sugeridos con el empleo de tintas y sombreados. El siguiente paso era modelar el boceto, para lo cual empleaba materiales como la arcilla, el yeso o la cera. No todos los bocetos se verían plasmados en la obra definitiva, sino que a veces servirían solo como experimentación, razones por las que eran como un "libro instructivo" para oficiales y obradores durante su proceso de aprendizaje.

El trabajo en el taller estaba fuertemente jerarquizado. Salzillo, como representante legal, se encontraba al frente del mismo. Detrás contaba con la colaboración de diversos ayudantes que se encargaban de los trabajos previos a la talla de la madera y de intervenir en diversos aspectos de su proceso de ejecución.

Los miembros del taller quedaban sometidos a la disciplina de Salzillo, cuya personalidad y calidad como escultor iban trazando el estilo a seguir, con el resultado de una gran uniformidad en todas las obras que salían del mismo. Su concepto de la imagen y del color se veía reflejado en todos los pasos a seguir hasta llegar al resultado final. Aspectos como el boceto, la textura quebrada de la talla, la policromía, los matices o las veladuras reflejaban las señas diferenciales de su estilo. Este modelo salzillesco, caracterizado por la producción de imágenes en un lenguaje fácil de comprender, llevó a un aumento en el número de encargos que recibía el taller hacia la década de 1740.

En 1765, fruto de las frecuentes tertulias que el escultor mantenía con sus amigos ilustrados, nació la llamada "academia de Salzillo" en un intento de superar el modelo ya caduco del escultor solitario encargado de educar a sus discípulos. Desde la creación en 1752 de la Academia de San Fernando, diversas academias oficiales estaban sustituyendo el clásico modelo empírico y personal por un método según el cual el estudio era la base fundamental para adquirir nuevos conocimientos.

Salzillo continuó como director del taller y principal encargado de la formación de sus pupilos pero, siguiendo las corrientes de la Ilustración, pasó a preocuparse más de la educación artística impartida a los mismos.

En la ciudad de Murcia no existía un organismo encargado de la reglamentación de ese tipo de enseñanzas. Tampoco había óptimos modelos que indicasen lo que debía hacerse durante las diversas etapas del saber artístico pero, imitando lo que se hacía en otras ciudades españolas, Salzillo consiguió que empezase a producirse una completa renovación del sistema de aprendizaje, demostración de la capacidad del escultor para comprender los cambios que se fueron produciendo a lo largo del .

Francisco Salzillo es considerado una de las personas más célebres de la ciudad levantina de Murcia. El primer reconocimiento le llegó en vida, cuando fue nombrado escultor de la ciudad en 1755. Actualmente, su nombre sigue siendo recordado en numerosos puntos de la misma. Se le levantó un monumento conmemorativo en 1899 en la Plaza de Santa Eulalia de la ciudad, así como se le otorgó su nombre a una de sus arterias principales, la Gran Vía.

El Museo Salzillo, situado en la plaza murciana de San Agustín, está íntegramente dedicado a la obra del escultor. Aunque el primer intento de creación se debió a Isidoro de la Cierva en 1919, este se vio materializado por Decreto de 30 de mayo de 1941. La inauguración oficial se retrasó hasta 1960. En 1962 fue declarado Monumento Histórico-Artístico. En el interior del mismo se celebró con motivo del III centenario del nacimiento del autor, desde el 2 de marzo de 2007 hasta el 31 de julio de 2007, la exposición "Salzillo, testigo de un siglo", que fue inaugurada por Juan Carlos I, Rey de España.

Durante la Semana Santa de Murcia, fiesta declarada de Interés Turístico Internacional, salen en procesión diversos pasos en los que intervino la mano de Francisco Salzillo:










</doc>
<doc id="42845" url="https://es.wikipedia.org/wiki?curid=42845" title="Hamás">
Hamás

Hamás ( 'entusiasmo, fervor' y acrónimo de "Harakat al-Muqáwama al-Islamiya", Movimiento de Resistencia Islámico) es una organización palestina que se declara como yihadista, nacionalista e islamista. Su objetivo original, definido en su carta fundacional, fue el establecimiento de un estado islámico en la región histórica de Palestina, que comprendería los actuales Israel, Cisjordania y la Franja de Gaza, con capital en Jerusalén. Sin embargo, en 2017 publicó un nuevo documento de principios según el cual reclama "el establecimiento de un Estado de Palestina completamente soberano e independiente, con Jerusalén como capital, en las fronteras del 4 de junio de 1967" y enfatizaba su carácter nacionalista por encima del religioso, aunque sigue sin reconocer a Israel ni abandonar la lucha armada. Hamás cuenta con una serie de organizaciones dependientes que desarrollan sus actividades en muy diversos ámbitos, y abarcan desde la asimilación cultural y religiosa a los jóvenes a través de la madrasa, la asistencia social a los palestinos más necesitados (y a las familias de sus propios miembros muertos o presos en cárceles israelíes), la representación en las instituciones políticas palestinas a través de la lista Cambio y Reforma, hasta las Brigadas de Ezzeldin Al-Qassam, brazo armado de Hamás que ha sido acusado de practicar el terrorismo.

Hamás ha sido declarada organización terrorista por los Estados Unidos, Israel, Japón, Canadá y Australia; mientras que algunos países árabes, y otros como Rusia y Turquía, no la consideran como tal. La Unión Europea también la consideró organización terrorista desde 2003, aunque su Tribunal de Justicia apeló esta decisión para retirarlo de . El fallo del tribunal está pendiente del análisis del Consejo de la Unión Europea.

Aunque Israel ayudó inicialmente a la creación de Hamás, tratando con ello de debilitar a la hasta entonces hegemónica OLP de Yasir Arafat, desde su creación formal en 1987 hasta la actualidad, las distintas organizaciones que forman parte de Hamás se han convertido en objetivos prioritarios de las operaciones militares israelíes, que han terminado con la vida de importantes miembros del movimiento, incluyendo a su fundador y líder espiritual, el jeque Ahmed Yasín, y a su sucesor Ábdel Aziz ar-Rantisi, muertos en «ataques selectivos» de las fuerzas militares israelíes.La carta fundacional de Hamás exhibe la influencia de teorías conspirativas antisemitas.

La lista "Cambio y Reforma", ligada a Hamás, se presentó a las elecciones generales palestinas de 2006 obteniendo la mayoría absoluta, lo que le otorgó la potestad de formar el gobierno que lideró Ismail Haniye, que generó una serie de sanciones por parte de algunos países occidentales y árabes que consideraban terrorista a Hamás. Tras una serie de enfrentamientos y tensión creciente con su rival Fatah, en 2007 las organizaciones armadas leales a Hamás en la Franja de Gaza terminaron por expulsar del territorio a los partidarios de Fatah y se hicieron con el control total de la Franja. Desde entonces hasta 2017, Hamás asumió el gobierno de la Franja de Gaza, mientras su rival político Fatah mantenía el control de Cisjordania. En septiembre de 2017 se inició un acercamiento entre Hamas y Fatah. El 2 de octubre la Autoridad Nacional Palestina regresó a Gaza y el 12 de octubre se firmó en El Cairo el Pacto de reconciliación palestina entre Hamas y Fatah por el que se acordó la creación de un gobierno palestino de unidad, la convocatoria de elecciones generales y el traspaso del control del paso fronterizo de Rafah entre Gaza y Egipto a la Autoridad Nacional Palestina.

El Gobierno de Hamás en Gaza ha estado sometido desde 2007 a un bloqueo por parte de Israel que impide la entrada de alimentos, medicinas, material de construcción, armas y otros productos en territorio gazatí. La ANP de Hamás en Gaza fue uno de los objetivos principales de la invasión de Gaza llevada a cabo por el ejército israelí a finales de 2008; tras declarar haber alcanzado sus objetivos, el ejército israelí terminó por retirarse del territorio costero, retornando el "statu quo" anterior al conflicto y retomando Hamás el poder de la Franja. 

Distintas organizaciones de derechos humanos, como Human Rights Watch o Amnistía Internacional, han acusado a Hamás de cometer crímenes de guerra y crímenes contra la humanidad hacia las poblaciones tanto israelíes como palestinas, así como también torturas, asesinatos y secuestros contra la población palestina.

Hamás fue fundada por el jeque Ahmed Yasín en 1987, durante el curso de la primera Intifada, emitiendo su primer comunicado en diciembre de 1987. Algunos de sus grupos precursores fueron "Los coaligados de la tierra del Isrá'", y "Movimiento Islámico de Lucha". Fueron el jeque Ahmed Yasín y varios seguidores como Mahmud Al Zahhar y Ábdel Aziz ar-Rantisi quienes estructuraron y difundieron el movimiento de una forma oficial.

Su primer comunicado, señalaba:

En el artículo segundo de su carta fundacional, fechada el 18 de agosto de 1988, se presentó como una rama del movimiento internacional de los Hermanos Musulmanes, fundado en Egipto en 1928 por Hassan al-Banna, y que propugna la aplicación de la ley islámica en diversos aspectos de la vida diaria, pero la vinculación con dicho movimiento en realidad nunca excedió lo meramente ideológico, como lo han reconocido luego líderes de ambas agrupaciones.

En 1973, cuando los Hermanos Musulmanes egipcios y sirios recomenzaron la guerra contra los gobernantes seculares de aquellos países, unos seguidores del grupo del Cairo formaron la organización Yihad Islámica. Una subdivisión del grupo, formada en la Franja de Gaza, comenzó una guerra de baja intensidad contra el ejército de Israel y la administración militar y civil que dicho país ejercía en los territorios palestinos desde 1967. Tal subdivisión no mostró mucha habilidad militar, por lo que tuvo menor apoyo comparado al de Fatah y otros grupos del exilio, los cuales recibían armas de aliados árabes. 

A finales de los 1970, el jeque Ahmed Yasín, un alumno coránico parapléjico en la Ciudad de Gaza, logra crear un movimiento social (todavía sin relación con la yihad), manifestando que el verdadero enemigo del pueblo palestino no era sólo el Estado judío, sino los vicios fustigados por el islam, verdaderos "azotes de los palestinos", a saber: las prostitutas, los narcotraficantes (incluyendo a los que vendían droga solamente a israelíes), oficiales en los barrios y empresarios que colaboraban con Israel en provecho propio sin ayudar a los palestinos, e intelectuales que anteponían filosofías extranjeras al islam.

Al principio, el Shabak, uno de los servicios secretos israelíes, no vio a Yasín y sus alumnos como una amenaza. Sólo empezó a preocuparse cuando los seguidores del jeque empezaron a asaltar a colaboracionistas de Israel en los barrios de Gaza. Según Yasir Arafat, Israel incluso les habría dado cierto apoyo oficioso para que se enfrentaran a Fatah o al FPLP en Gaza y Cisjordania.

En 1984, los israelíes reconocieron en Yasín y sus alumnos a los peores predicadores del odio contra Israel. Al año siguiente se le hallaron a Yasín armas en su propia casa; preparaba una revuelta islamista en Gaza. Detenido por el Shabak, Yasin se convirtió en un famoso prisionero, conocido por la prensa como el ""terrorista en la silla de ruedas"". Mientras purgaba prisión, sus seguidores consolidaban la organización, la cual ya administraba madrazas y clinícas en los barrios, obteniendo fondos para asistencia social entre empresarios y jeques petroleros del Golfo Pérsico, los cuales querían un aliado palestino contra la izquierda laicista que amenazaba sus intereses. 

En 1987 Yasín fue encarcelado una vez más por afiliación con un grupo terrorista, pero liberado, junto con otros 70 palestinos, en el canje por los dos agentes del Mosad que fueron detenidos en Jordania tras intentar asesinar al líder de Hamas en ese país, Khaled Meshal, una operación fallida que también tuvo como consecuencia la dimisión del entonces jefe del Mosad, el general Danny Yatom. Durante el curso de la primera Intifada, Hamás emitió su primer comunicado en diciembre de 1987. Algunos de sus grupos precursores fueron "Los coaligados de la tierra del Isrá'", y "Movimiento Islámico de Lucha". Fueron el jeque Ahmed Yasín y varios seguidores como Mahmud Al Zahhar y Ábdel Aziz ar-Rantisi quienes estructuraron y difundieron el movimiento de una forma oficial. En el artículo segundo de su carta fundacional, fechada el 18 de agosto de 1988, se presentó como una rama del movimiento internacional de los Hermanos Musulmanes, fundado en Egipto en 1928 por Hassan al-Banna, que propugna la aplicación de la ley islámica en diversos aspectos de la vida diaria, pero la vinculación con dicho movimiento en realidad nunca excedió lo meramente ideológico, como lo han reconocido luego líderes de ambas agrupaciones. En 1991, Hamás declaró la fundación de las Brigadas de Izzedín al-Kassam, su brazo militar.

Hamás inició una ola de secuestros y ataques, como el homicidio del policía Nissim Toledano el 15 de diciembre de 1992 y el soldado de la Brigada Golani Nachshon Wachsman el 14 de octubre de 1994 (el asesinato de Wachsman ocurrió durante un intento infructuoso para salvarlo y rescatarlo de sus captores). El cerebro de los ataques fue el notorio Muhammad Déf, un militante radical y veterano que luego sería el jefe de BIK. A causa de los ataques, el primer ministro de Israel Isaac Rabin decidió expulsar algunos cientos de militantes del grupo al sur del Líbano. Pero ante la presión de países extranjeros, Rabín consintió en devolverles a Gaza.

Cuando Yasser Arafat e Isaac Rabin se encontraron en 1993 y 1994 y acordaron negociar el fin de la guerra palestina-israelí, Hamás denunció a Arafat y la OLP como traidores que permitirían la división de la Palestina histórica. Aunque para Arafat fue difícil convencer a los palestinos del acuerdo, y originó la decepción y el alejamiento de muchos de sus partidarios en la OLP y en Fatah, Hamás no fue debilitado, porque no era miembro de la OLP.

Sus líderes han calificado en reiteradas ocasiones los diálogos entre árabes e israelíes —incluyendo los Acuerdos de Oslo— como una "pérdida de tiempo". Respaldan la lucha armada y los ataques suicidas contra civiles como medio para el logro de sus objetivos.

Durante el traslado de la autoridad en Gaza y Jericó de la Administración Civil israelí a la nueva Autoridad Nacional Palestina (ANP), Hamás se fortaleció como el mejor grupo alternativo a Fatah. Criticó a Arafat como un "dictador corrupto" que estaba aprovechando el nacionalismo palestino para sus propios fines. Contra Hamás se formaron milicias de Fatah como Tanzim desde Marwan Barrouti en Cisjordania. Pero más despreciados por Hamás fue el Servicio de Seguridad Preventiva y su director Muhammad Dahlan. Dahlan, un militante leal de Fatah, entendió que la red social de Hamás, vigente ya durante muchos años, tenía el potencial de suplantar a la ANP como un estado dentro del estado.

Hamás empezó una campaña de atentados terroristas suicidas en 1994 con una frecuencia sin precedentes. Arafat tuvo una actuación dubitativa, sin saber si enfrentarse abiertamente a Hamas o no, pensando que el aumento de la violencia impediría obtener nuevos compromisos de Israel a favor de la causa palestina. Los oponentes derechistas israelíes, que subieron al poder con Benjamín Netanyahu, las actividades belicosas de Arafat y los hombres bomba de Hamás sabotearon las negociaciones entre Israel y la ANP. 

Aunque en aquellos tiempos Hamás no tuvo armas sofisticadas para luchar contra el ejército israelí, los jefes de BIK les reclutaron muchos parados hábiles especialmente electricistas, mecánicos, e ingenieros civiles. Uno de ellos, Yahya Ayyash, o "El Ingeniero" ('al-muhandis'), habría sido el arquitecto de la campaña de bombardeos suicidas, junto con Muhamad Déf, Nidal Farajat, Salame Jamad, Adnan Rrul, y Salaj Chejade, el triunvirato de jefes de BIK. El 5 de enero de 1996 Ayyash fue asesinado por una bomba en su teléfono celular colocada por el Shabak, pero antes de morir ya había enseñado a otros a fabricar cinturones bombas. Hamás gradualmente utilizaba los bombardeos más que otros métodos como tiroteos y secuestros. La Yihad Islámica rápidamente lo adquirió como táctica y las Brigadas de los Martíres Al-Aksa de Fatah cuando empezaron a usarlo en la segunda Intifada en septiembre de 2000. 

Aunque Hamás tenía muchos éxitos durante su campaña cuando asesinaba civiles, sufrió muchas pérdidas, como en el caso de la muerte de Allach. A continuación una lista de líderes de Hamás que han sido blanco de asesinato selectivo a manos del Estado de Israel:


Las Brigadas de Ezzeldin Al-Qassam son el brazo armado de Hamás, y han llevado a cabo desde 1993 decenas de ataques contra objetivos militares y la población civil israelí, causando centenares de víctimas. En 2004 se produjeron los últimos atentados suicidas de las Brigadas, que pasaron a atentar contra las Fuerzas de Defensa de Israel y a lanzar cohetes Qassam (y tras el inicio del Conflicto de la Franja de Gaza de 2008-2009, también los más potentes Grad y Katyusha) desde la Franja de Gaza contra el sur de Israel.

La organización Human Rights Watch denunció a Hamás (junto a otros grupos) como una organización que realiza "graves violaciones a las leyes humanitarias".

La organización Amnistía Internacional denunció a Hamás como responsable de numerosos abusos contra la población civil palestina (tortura, asesinatos, detenciones irregulares, etc) acusándolo, junto a Fatah, de ser responsable de la muerte de al menos 350 personas, así como también de cometer crímenes contra la humanidad por sus atentados suicidas. Estas denuncias de Amnistía Internacional también se repitieron en 2008.

En 2008 se generó una fuerte controversia por la intención de Hamás de promulgar una ley penal según la sharia, con penas de crucifixión, amputación de manos, o flagelación. Hamás lo negó inmediatamente.

En 2009, Amnistía Internacional denunció a Hamás por una "campaña letal de secuestros, homicidios deliberados e ilegítimos, torturas y amenazas de muerte en la Franja de Gaza contra personas que acusaban de ‘colaborar’ con Israel (…)".

En su informe de 2014 Amnistía Internacional denunció a Hamás por restringir las libertades de expresión y reunión pacífica y por llevar a cabo "una brutal campaña de secuestros, tortura y homicidios ilegítimos de palestinos", detenciones arbitrarias, torturar con impunidad y por la operación "estrangular cuellos" contra miembros de Fatah u otros disidentes.

Hamás no reconoce la legitimidad del Estado de Israel, ni acepta la resolución que la Asamblea General de las Naciones Unidas propuso el 29 de noviembre de 1947 mediante la cual se establecía la partición de Palestina en dos estados, uno árabe y otro judío. Considera que Israel fue edificado a partir de la usurpación de la Palestina histórica y no acepta ninguna reconciliación con los judíos que no incluya su renuncia a cualquier pretensión sobre Palestina, incluyendo la totalidad del actual territorio del Estado de Israel.

En múltiples ocasiones los líderes de Hamás han calificado a los diálogos entre árabes e israelíes (como los terminados en los Acuerdos de Oslo) como una pérdida de tiempo. Apoyan la lucha armada y los ataques suicidas contra civiles como medio para el logro de sus objetivos. Aparte de las operaciones violentas, Hamás mantiene también una postura política y social como el mantenimiento de hospitales y escuelas, apoyando a determinados candidatos y listas en las elecciones municipales y legislativas que se celebraron recientemente en los territorios bajo el control de la Autoridad Nacional Palestina.

En su carta fundacional, publicada el 18 de agosto de 1988, Hamás realiza una serie de acusaciones y advertencias contra Israel en particular y contra los judíos en general que han sido calificadas como antisemitas por distintos medios de comunicación.
En el Pacto de Hamás se sostiene la teoría por la cual existiría una conspiración judía que habría causado desastres al islam durante siglos. 

Además, los judíos son acusados de controlar los medios de comunicación, la riqueza del mundo, de instigar las revoluciones francesa y rusa, la Primera Guerra Mundial y la Segunda, todo lo cual sería para promover los objetivos sionistas.

A lo largo de su historia, Hamás ha recibido apoyo económico de muchas partes, incluyendo a gobiernos como los Arabia Saudí y a también gobiernos como el de Irán o Siria (pese a que estos dos últimos pertenecen a la rama chií del Islam, rival de la suní imperante en Hamás). También otros gobiernos, como el de Venezuela o el de Cuba, han sido acusados de prestarle apoyo. También algunos jeques petroleros del Golfo han contribuido personalmente a su financiamiento.

Por otra parte, Hamás está estructurada en torno a la dawa el principio musulmán de asistencia a los necesitados y a los conceptos de "azaque" (caridad) y "sadaqat" (donaciones), a través de los cuales recibe fondos de muchas organizaciones de beneficencia situadas fuera de los territorios palestinos.

Israel ha declarado como "organizaciones clandestinas" a 20 comités de beneficencia de Hamás dentro de Cisjordania y Gaza, así como a 8 entidades de caridad de fuera de los territorios, debido a su relación con Hamás.

La organización se encarga de cuidar y mantener económicamente a los familiares de sus activistas y militantes que se encuentren encarcelados en cárceles israelíes, que hayan muerto como consecuencia de ataques del ejército israelí o a causa de sus actos contra Israel, incluyendo los atentados y ataques armados. También cuenta con una amplia red de escuelas coránicas y centros de atención, y acostumbra a repartir comida entre la población en las épocas de mayor crisis económica. De esta forma, es visto por parte de la población palestina como la única organización que, a pesar de los múltiples cambios coyunturales, apoya firmemente y sostiene a su pueblo. Su amplia red de atención social le ha dado gran popularidad entre la población palestina, que sufre las consecuencias del conflicto con Israel. 

En su libro, "Hamas: politics, charity and terrorism in the service of jihad", el analista y exsubsecretario de Inteligencia del Departamento del Tesoro de los Estados Unidos y asesor del FBI, Matthew Levitt, del instituto proisraelí Washington Institute for Near East Policy, calcula que Hamás probablemente cuenta con un presupuesto de entre 70 y 90 millones de dólares, de los cuales invierten el 80 a 85 % en sus actividades políticas y a sus redes de escuelas, clínicas y obra social, mientras el resto lo dedican a sus actividades armadas. Asimismo, el académico israelí Reuven Paz, exdirector de investigación del Shabak, el servicio de seguridad general israelí, afirma que «Aproximadamente el 90 por ciento de sus actividades son sociales, de bienestar, culturales, y educativas.»

Hamás no tomó parte en la vida política de la ANP desde su formación en 1994 hasta 2006, incluyendo las elecciones del Consejo Legislativo Palestino o CLP en 1996 y la elección presidencial en 1995. Pero antes de las elecciones regionales de 2005, por el CLP en enero de 2006, Hamás declaró su preparación en las participación política. En ambas elecciones la lista de Hamás, Cambio y Recuperación, ganó con victorias arrolladoras. 

Desde las elecciones controversiales, el poder del gobierno en la ANP fue dividido entre los que apoyan al Presidente Mahmud Abbas ("Abu Mazen"), el jefe de Fatah, y los del Primer Ministro Ismail Haniya, un activista oficial por Hamás. Hay reportajes que indican que el poder real recae en Jaled Meshal, el jefe de la Oficina Estatal, la que es la rama externo del grupo en Damasco, y que siempre fue considerado uno de los dos tenientes mayores de Yasín, junto con Abdelaziz ar-Rantisi, hasta su asesinato. Aunque los israelíes creen que Mechal, una figura de línea dura en Hamás, es más peligroso que Haniya, hasta el momento no negocian ni con este segundo, ya que prefieren reconocer únicamente la autoridad de Presidente Abbas en todos los asuntos entre la ANP e Israel. Hasta ahora el gobierno de Israel solo hizo acuerdos formales con líderes regionales de Hamás, por los asuntos menores como la utilización del agua y la electricidad en ciudades especifícas como Tulkarm y Naplusa.

La reacción de Fatah a su derrota en las elecciones en enero de 2006 fue el rechazo de la oferta por Hamás para formar un gobierno de unidad nacional. Desde aquel rechazo, militantes de Fatah y Hamás lucharon muchas veces en las calles de la Franja de Gaza, y los de Fatah en Cisjordania (donde BIK es débil en relación a las Brigadas de los Mártires de Al-Aqsa y Tanzim de Fatah) asaltaron personajes de Hamás como alcaldes y miembros del CLP. Haniya y Abbas fueron objetos de intentos desde el otro lado de asesinarlos. Aunque ambos líderes son oficialmente los jefes de los dos lados, militantes extremos en cada grupo tienen influencia excesiva en los sucesos, y los mayores asesinatos internos que ocurrieron no fueron nunca ordenados ni por Abbas ni por Haniya, más bien por líderes como Muhamad Déf, que se opuso a la participación de Hamás en las elecciones.

Fatah tomó otros pasos por sublevar la autoridad del gobierno de Hamás, como declarar una huelga general contra los ministros que controlan Hamás, además de la detención de Ahmad Sa'adat, el jefe del FPLP, por Israel. La prohibición económica de la comunidad internacional ayuda a ambos lados, porque hace al gobierno quebrarse y se consolida la huelga contra ello. Entonces, Hamás responde con el establecimiento de lazos cercanos con Irán, que es un adversario implacable de los países occidentales. Mientras tanto Israel ha permitido a la guardia presidencial de Abbas introducir armas desde Jordania.

A principios de 2007 se intensificaron los enfrentamientos armados entre las facciones, lo que resultó en decenas de muertos y secuestrados de ambos bandos.

Por otro lado, la comunidad internacional se negó, desde la victoria electoral de Hamás en las elecciones palestinas del 2006, a prestar ayuda financiera o reconocimiento legítimo al gobierno de Hamás, debido a que esta organización se niega, hasta el momento, a aceptar los tres puntos básicos exigidos por la ONU para avanzar en el proceso de paz: el reconocimiento del derecho de Israel a existir, renunciar a la violencia terrorista y aceptar los Acuerdos de Oslo.

Según Amnistía Internacional, durante el Conflicto de la Franja de Gaza de 2008-2009, Hamás habría llevado a cabo una campaña de secuestros, asesinatos, torturas y amenazas de muerte contra palestinos considerados colaboracionistas, así como a gente opuesta o crítica con las acciones de Hamás.

AI, en su informe anual 2014/2015, también denunció que no existe la libertad de expresión ni de reunión y los disidentes son detenidos arbitrariamente. Durante la Operación Margen Protector, miembros de Fatah fueron secuestrados, detenidos e impunemente torturados y condenados a muerte por Hamás sin las debidas garantías a civiles.

A fines de 2006 y principios de 2007, Hamás oficialmente puso fin a su campaña de atentados terroristas contra Israel, pero al mismo tiempo se construye un arsenal grande de armas para atacar objetivos israelíes mientras que su brazo armado continua lanzando cohetes Qassam contra los poblados israelíes limítrofes a Gaza (como la ciudad de Sederot). Los atentados que se intensificaron por parte de los grupos terroristas palestinos contra objetos israelíes actualmente son perpetrados por grupos como la Yihad Islámico Palestino (YIP) o las Brigadas de los Mártires al-Aksa u otros grupos afiliados con Fatah. Grupos que no son alineados con ningún partido político, como el YIP y la FPLP, tratan de perpretar ataques contra Israel para instar a las facciones palestinas a unirse, como en el caso del atentado desde YIP y Fatah en Eilat.

Desde 2007 cuando Hamas explulsó a Fatah de Gaza se han producido diversos intentos de negociación política que se han visto truncados. Destaca la firma en mayo de 2011 de un Acuerdo Nacional de Reunificación con las diferentes facciones palestinas, el acuerdo en 2014 para la creación de un gobierno de unidad que fracasó y la firma el 12 de octubre de 2017 en El Cairo del Pacto de reconciliación palestina con Fatah. “"Esta vez, como todas las otras veces, en Hamás estamos determinados y vamos en serio. Hemos disuelto el comité administrativo (gobierno en la sombra). Hemos abierto la puerta para alcanzar esta reconciliación"”, aseguró Saleh Arouri que lideró la delegación de Hamas, después de la firma.





</doc>
<doc id="42851" url="https://es.wikipedia.org/wiki?curid=42851" title="Jack London">
Jack London

Jack London, probablemente nacido como John Griffith Chaney (San Francisco, 12 de enero de 1876-Glen Ellen, 22 de noviembre de 1916), fue un escritor estadounidense, autor de "Colmillo Blanco", "La llamada de lo salvaje" y otras novelas y cuentos.

Clarice Stasz y otros biógrafos creen que el padre biológico de Jack London fue el astrólogo William Chaney. Chaney fue un personaje distinguido de la astrología; según Stasz: "Desde el punto de vista de los astrólogos más serios de hoy, Chaney es una gran figura que ha cambiado la práctica de la charlatanería hacia un método más riguroso".

Jack London no supo de la supuesta paternidad de Chaney hasta su madurez. En 1897 le escribió a Chaney y recibió una carta de él donde indicaba: «Nunca contraje matrimonio con Flora Wellman», y que era «impotente» durante el periodo que vivieron juntos; por lo tanto, «no puedo ser tu padre».

No es posible afirmar si el matrimonio fue legalizado, ya que la mayoría de los documentos civiles de San Francisco fueron destruidos en el terremoto de 1906. Por ello, no se sabe con certeza el nombre que aparecía en el certificado de nacimiento. Stasz aclara que en sus memorias Chaney se refiere a la madre de Jack London, Flora Wellman, como «esposa». Stasz también hace hincapié en un anuncio en el cual Flora se refiere a sí misma como Florence Wellman Chaney.

Jack London nació en San Francisco (California). Esencialmente se autoeducó, proceso que llevó a cabo en la biblioteca pública de la ciudad leyendo libros. En 1883 encontró y leyó la novela "Signa" de la escritora Ouida, que relata cómo un joven campesino italiano sin estudios escolares alcanza fama como compositor de ópera. London le atribuyó a este libro la inspiración para comenzar su labor literaria.

En 1893, se embarcó en la goleta "Sophia Sutherland", que partía a la costa de Japón. Cuando regresó, el país estaba inmerso en el pánico de 1893 y Oakland azotado por disturbios laborales. Después de trabajos agotadores en un molino de yute y en una central eléctrica del ferrocarril, en 1894 se unió a la "Kelly's industrial army", una marcha de desempleados en protesta a Washington, y comenzó su vida de vagabundo.

En 1894, pasó treinta días en la penitenciaría de Erie County en Buffalo (Nueva York) por vagabundeo. En "The Road", escribió:
Después de varias experiencias como vagabundo y marinero, London regresó a Oakland, donde acudió a la Oakland High School, contribuyendo con varios artículos para la revista de la secundaria, "The Aegis". Su primera publicación fue "Typhoon off the coast of Japan", donde relató sus experiencias como marino.

Jack London deseaba desesperadamente entrar a la Universidad de California y, en 1896, después de un verano de estudio intenso, lo logró; pero los problemas financieros le obligaron a irse en 1897 y nunca se graduó. Kingman dice que "no hay ningún antecedente de que escribiera para publicaciones estudiantiles" ahí.

En 1899, London comenzó a trabajar de doce a dieciocho horas al día en la enlatadora Hickmott. Buscando una salida de su penoso trabajo, pidió un préstamo a su madre adoptiva, Jennie Prentiss, y compró la goleta "Razzle-Dazzle" a un pirata ostrero llamado French Frank, convirtiéndose a su vez en un ostrero. En su relato autobiográfico "John Barleycorn" declara haberle robado a French Frank su amante, Mamie. Después de algunos meses su goleta se dañó sin posibilidad de reparo. Se cambió al lado de la ley y se hizo miembro de la Patrulla Pesquera de California.

Mientras vivía en su casa de campo arrendada en Lago Merritt (Oakland), London conoció al poeta George Sterling y se convirtieron en buenos amigos. En 1902 Sterling ayudó a London a encontrar una casa cerca de la suya en Piedmont, California. En sus cartas London se refería a Sterling como "griego" debido a su nariz y perfil clásico, y las firmaba con el seudónimo "Lobo". London se refirió a Sterling como Russ Brissenden en su novela autobiográfica "Martin Eden" (1909) y como Mark Hall en "El valle de la luna" (1913).

Tiempo después, Jack London se distinguió en diversos campos, teniendo varios intereses y una biblioteca personal de volúmenes.

El 25 de julio de 1897, London y su cuñado James Shepard zarparon para unirse a la fiebre del oro de Klondike donde ambientaría sus primeras historias importantes. Sin embargo, el tiempo que pasó en Klondike fue perjudicial para su salud y, al igual que muchos otros que trabajaban mal alimentados en los yacimientos de oro, desarrolló escorbuto. Sus encías se hincharon, provocando la pérdida de sus cuatro dientes frontales, sufría constantes dolores en la cadera y los músculos de las piernas, y su cara se cubrió de llagas. Afortunadamente para él y todos los que estaban cayendo enfermos, el padre William Judge, "el santo de Dawson", había abierto un refugio en Dawson que les facilitaba abrigo, comida y algunas medicinas.

London sobrevivió las duras condiciones de Klondike, y esta lucha contra la muerte inspiró la que a menudo es catalogada como su mejor historia corta: "To Build a Fire". La famosa versión de esta historia fue publicada en 1908, pero antes se había publicado una totalmente distinta en 1902. Labor, en una antología, dice que "comparar las dos versiones es a su vez una lección instructiva en lo que distingue un trabajo artístico literario estupendo de una buena historia para niños". La historia trata sobre un terco e inútil buscador de oro que ignorando los peligros de la naturaleza, al final muere congelado por no ser capaz de hacer una simple fogata. London podría haberse identificado con el personaje, y debió presenciar actos parecidos en la vida real mientras estaba en Klondike.

Sus terratenientes en Dawson fueron dos ingenieros en minas llamados Marshall y Louis Bond, los cuales estudiaron en Yale y Standford. Su padre, (Juez Federal) "Judge" Hiram Bond, fue un rico inversionista de la minería. Los Bonds, especialmente Hiram, eran republicanos activos. En el diario de Marshall Bond se mencionan las amistosas luchas verbales sobre temas políticos como un pasatiempo.

Jack dejó en Oakland a un creyente del trabajo ético con conciencia social y conocimientos socialistas y se convirtió en un partidario activo del socialismo. También concluyó que sólo su fe de escapar de la trampa del trabajo fue conseguir una educación y "vender sus pensamientos". Durante toda su vida vio la escritura como un negocio, su pasaporte de salida de la pobreza, y esperaba una forma de llevar la riqueza a su propio juego.

Cuando regresó a Oakland en 1898, empezó a luchar seriamente para entrar en la impresión, una lucha memorable descrita en su novela "Martin Eden". Su primera historia publicada fue "To the Man On Trail". Cuando "The Overland Monthly" le ofreció únicamente 5 dólares por ella—y tardó en pagarle—Jack London se acercó a un punto en el que se planteó abandonar su carrera literaria. En sus propias palabras, "literal y literariamente fui salvado" cuando "The Black Cat" (en español "El Gato Negro") aceptó su novela "Un millar de muertes" pagándole por ella 40 dólares—"el primer dinero que recibí por una historia".

Jack London fue afortunado durante su carrera literaria. Comenzó simplemente con nuevas tecnologías de impresión que permitían la producción de revistas de bajo coste. Esto resultó en una revolución para las revistas populares dirigidas a un amplio público, y un mercado fuerte para las historias cortas de ficción. En el año 1900, ganó aproximadamente 2500 dólares con sus historias, el equivalente a unos dólares actualmente. Su carrera estaba encaminada hacia el éxito.

Entre las obras que vendió a las revistas se encontraba la historia corta conocida indistintamente como "Batarde" y "Diable" en dos ediciones de la misma y básica historia. Un cruel franco-canadiense que maltrata a su perro. El perro como venganza le provoca la muerte. London fue criticado por representar a un perro como la encarnación del mal. Contaría de algunas de sus críticas que las acciones del hombre son la causa principal del comportamiento de sus animales y que lo mostraría en su próxima historia corta.

La pequeña historia para el periódico "Saturday Evening Post" titulada «La llamada de la selva» fue algo larga. La historia comienza en un Estado de Santa Clara y representa un perro cruce de San Bernardo y Shepard llamado "Buck". De hecho, la primera escena es una descripción de la granja de la familia Bond y Buck está basado en el perro que le fue prestado en Dawson por sus terratenientes. London visitó a Marshall Bond en California topándose de nuevo con él en una conferencia política que tuvo lugar en San Francisco en 1901.

Jack London contrajo matrimonio con Bess Maddern el 17 de abril de 1900, el mismo día que "The Son of the Wolf" fue publicado. Bess había sido parte de su círculo de amigos durante algunos años. Stasz dice "Ambos reconocieron públicamente que no se casaban por amor, pero sí por amistad y por la creencia de que concebirían hijos fuertes". Kingman dice "ellos se encontraban a gusto juntos... Jack había dejado claro a Bessie que no la amaba, pero que le gustaba lo suficiente para tener un matrimonio satisfactorio".

Durante el matrimonio, Jack London continuó su amistad con Anna Strunsky, co-escribiendo "The Kempton-Wace Letters," una novela epistolar contrastando el romanticismo con un amor científico. Anna, escribiendo las cartas de "Dane Kempton", demostraba un punto de vista romántico frente al matrimonio, mientras que Jack, que escribía las cartas de "Herbert Wace", mostraba un punto de vista científico, basado en el Darwinismo y las mejoras provocadas en la descendencia que se podía producir.
En la novela, su personaje ficticio contrasta dos mujeres que London conocía:

[La primera era] una loca, lasciva criatura, maravillosa, inmoral y llena de vida hasta el borde. Mi sangre palpita caliente incluso ahora que la vuelvo a conjurar ... [La segunda era] una mujer de pechos soberbios, la madre perfecta, hecha primordialmente para reconocer el agarre de los labios de un hijo. Ya sabes, ese tipo de mujer. "Las madres de los hombres", las llamo. Y por tanto tiempo existen esta clase de mujeres en la tierra, quizás debamos mantener por dicho tiempo la fe en la semilla de los hombres. La lasciva era la pareja sexual, pero esta era la mujer madre, la última, más grande y sagrada en la jerarquía de la vida.
Wace declara:

Me propongo ordenar mis aventuras amorosas de una forma racional... Porque me caso con Hester Stebbins. No estoy impulsado por la locura sexual arcaica de la bestia, ni por la locura romántica obsoleta del hombre antiguo. Contraigo enlace y la razón me dice que está apoyado en la salud, en la sensatez y la compatibilidad. Mi intelecto disfrutará de este enlace.
Analizando el porqué del "fue impulsado hacia la mujer", tiene la intención de casarse, Wace dice:

Fue la anciana Madre Naturaleza la que llora por nuestra causa, cada hombre y mujer, para la progenie. Su único y eterno lamento: ¡PROGENIE! ¡PROGENIE!

En la vida real, el nombre cariñoso de Jack para Bess era "Mami-Niña" y el de Bess para Jack era "Papi-Niño". Su primera hija, Joan, nació el 15 de enero de 1901, y la segunda, Bessie (más tarde llamada Becky), el 20 de octubre de 1902.

A pie de foto en las imágenes del álbum de fotos, reproducido en parte en la memoria de Joan London, "Jack London y Sus Hijas", publicado póstumamente, muestra la felicidad inconfundible de Jack London y el orgullo en sus hijas. Pero el propio matrimonio se ponía a prueba de forma continua. Kingman, en 1979, dice que en 1903 "la ruptura... era inminente... Bessie era una buena mujer, pero eran extremamente incompatibles. No quedaba nada de amor. Incluso la compañía y el respeto se había esfumado después del matrimonio". No obstante, "Jack seguía siendo amable y gentil con Bessie, incluso cuando Cloudsley Johns fue invitado en su casa en febrero de 1903 no sospechó la ruptura de su matrimonio".

De acuerdo a Joseph Noel, 1940, "Bessie era la madre eterna. Vivía primero para Jack, corregía sus manuscritos, le ayudaba con la gramática, pero cuando nacieron sus hijas ella vivió por ellas. Este fue su gran honor y su primer error garrafal". Jack se quejaba a Noel y George Sterling que "ella es devota hasta la pureza. Cuando le digo que su moralidad es solo la evidencia de una presión baja de la sangre, me odia. Me vendería junto con mis hijos por su maldita pureza. Esto es terrible. Cada vez que regresó después de haber estado fuera de casa por una noche, ella no me permite estar en la misma habitación que ella a no ser que no haya más remedio".

El 24 de julio de 1903, Jack London le dijo a Bessie que se marchaba y se iba de casa; durante 1904 Jack y Bess negociaron los términos del divorcio, y el fallo fue concedido el 11 de noviembre de 1904.

Jack London fue acusado de plagio en numerosas ocasiones durante su carrera. Era vulnerable no solo porque fuera un excelente y exitoso escritor, sino también debido a sus métodos de trabajo. En una carta a Elwyn Hoffman escribió "expresión, como sabes —conmigo— es mucho más fácil que la invención". London se hizo con argumentos de historias cortas y novelas del joven Sinclair Lewis y usaba incidentes que aparecían en recortes de periódico como material sobre el que basar sus historias.

Egerton R. Young declaró que "La llamada de la selva" se tomó de su libro "My Dogs in the Northland". La respuesta de London fue reconocer haberla usado como fuente; declaró haberle escrito una carta a Young para agradecérselo.

En julio de 1902, dos piezas de ficción aparecieron en el mismo mes: "Moon-Face" de Jack London en el "San Francisco Argonaut" y "The Passing of Cock-eye Blacklock" de Frank Norris, en "Century". Los periódicos hicieron comparaciones paralelas de las historias, las cuales London definía como "bastante diferentes en el tratamiento, [pero] patentemente iguales en fundación y motivación". Jack London explicó que ambos escritores basaron sus historias en el mismo hecho aparecido en la prensa. En consecuencia, se descubrió que un año antes, un tal Charles Forrest McLean había publicado otro relato de ficción basado en el mismo incidente.

En 1906 el periódico "New York World" publicó columnas "terriblemente paralelas" que mostraban de una parte dieciocho pasajes del relato de London llamado "Love of Life" y por otra pasajes similares del artículo de no ficción de Augustus Biddle y J. K Macdonald titulado "Lost in the Land of the Midnight Sun" (en español "Perdido en la tierra del Sol de Medianoche"). Según Joan London, hija de London, el paralelismo "[demostrado] más allá de la pregunta de si Jack había reescrito meramente el relato de Biddle". (Jack London seguramente habría objetado acerca de la palabra "meramente".) En respuesta, London advirtió que el mundo no le acusó de "plagio", solo de "identidad temporal y de situación", para lo cual "se declaró culpable" definitivamente. London reconoció el uso del relato de Biddle, citando otras numerosas fuentes que había usado, y afirmó «Yo, en el curso de hacer girar mi vida del periodismo hacia la literatura, usé material proveniente de varias fuentes las cuales habían sido coleccionadas y narradas por hombres que hicieron tornar los aspectos de la vida en periodismo».

El incidente más serio envolvió al capítulo 7 de "El talón de hierro", titulado "La visión del obispo". El capítulo fue casi idéntico al ensayo irónico de Frank Harris, publicado en 1901, titulado "El obispo de Londres y la moralidad pública". Harris se indignó y sugirió que debería recibir la sesentava parte de los beneficios obtenidos por "El talón de hierro", el problemático material que constituía aquella fracción de la novela completa. Jack London insistió en que él había copiado una reimpresión del artículo el cual apareció en un periódico estadounidense, y lo creyó como las palabras genuinas pronunciadas por el Obispo de Londres. Joan London definió esta defensa como "poco convincente, efectivamente".

En 1910, Jack London compró un rancho de acres (4km²) en Glen Ellen, en el condado de Sonoma, California, por dólares. Escribió que "Después de mi mujer, el rancho es la cosa más querida en el mundo para mí". Deseaba desesperadamente que el rancho se convirtiera en una empresa de negocios de éxito. Escribir, siempre una empresa comercial para London, se orientaría ahora más hacia un objetivo: "Escribo un libro por añadir trescientos o cuatrocientos acres [1 o 2 km²] más a mi magnífica propiedad". Después de 1910, sus obras literarias consistieron en su mayoría en composiciones literarias de pobre calidad escritas deprisa para hacer dinero, empujado por la necesidad de generar ingresos para el rancho. Joan London escribe "Pocos críticos se molestaban siquiera en evaluar su trabajo seriamente, era obvio que Jack no se iba a esforzar más".

Clarice Stasz escribe que London "había llevado completamente al corazón la visión, expresada en su ficción agraria, de la tierra como la versión más cercana del edén en la Tierra... estudió él mismo manuales de agricultura y tomos científicos. Concibió un sistema de rancho que hoy sería elogiado por su sabiduría ecológica". Estaba orgulloso del primer silo de cemento en California, que diseñó él mismo a partir de una granja de cerdos circular. London esperaba adaptar la sabiduría de la agricultura asiática sostenible a los Estados Unidos.

El rancho fue, desde muchos puntos de vista, un fracaso colosal. Los observadores amables, como Stasz, trataron sus proyectos como potencialmente factibles, y atribuyen su fracaso a la mala suerte o a su carácter pionero para la época. Los menos amables, como Kevin Starr, sugieren que fue un mal gestor, distraído por otros negocios y perjudicado por su alcoholismo. Starr hace notar que London estuvo ausente de su rancho por año y medio entre 1910 y 1916, y dice "Le gustaba la parafernalia del poder del directivo, pero no prestaba atención a los detalles... Los trabajadores de London se rieron de sus esfuerzos por jugar a ser un ranchero y consideraron que era el hobby de un hombre rico".

El rancho es actualmente un punto de referencia histórico nacional en los Estados Unidos.

Jack London se hizo socialista a la edad de 20 años. Previamente, había estado poseído de un optimismo reprimido el cual venía de su salud y su fuerza, actuando de forma individual, trabajando duro y viendo al mundo como algo bueno. Pero tal como detalla en su ensayo, "Como me convertí en socialista", sus puntos de vista socialistas comenzaron cuando se abrieron sus ojos a los miembros de lo más bajo del foso social. Su optimismo e individualismo perdieron intensidad, y juró que nunca más trabajaría más duro de lo necesario. Escribe que su individualismo fue machacado, y que renació un socialista. London se unió primero al Partido Socialista Laboral en abril de 1896. En 1901, abandonó dicho partido y se unió al nuevo Partido Socialista de América. En 1896 el periódico llamado "San Francisco Chronicle" publicó una historia sobre el London de 20 años que en el "City Hall Park" de Oakland y de noche, dio una charla acerca de socialismo a la multitud congregada—una actividad por la cual fue arrestado en 1897. Fue presentado como alcalde de Oakland en dos ocasiones: en 1901, resultando no elegido al recibir 245 votos y en 1905, mejorando su porcentaje de votos (981 votos) pero sin alcanzar su objetivo. London hizo una gira por el país conferenciando sobre socialismo en el año 1906 y publicó colecciones de ensayos cuya temática era el socialismo ("La guerra de las Clases", 1905; "Revolución y otros Ensayos", 1910).
A menudo se despedía en sus cartas con la frase "Vuestro para la Revolución" (en inglés "Yours for the Revolution").

Stasz hace notar que "London consideraba a los "Wobblies" (miembros de "Industrial Workers of the World", en español "Trabajadores Industriales del Mundo") como una adición bien recibida a la causa socialista, aunque nunca se les unió en las pretensiones por las que establecían emplear el sabotaje". Menciona un encuentro personal entre London y Big Bill Haywood en 1912.

Es evidente un punto de vista socialista en sus obras, más notable si cabe en su novela "El talón de hierro". El socialismo de Jack London venía del corazón y de su experiencia en la vida, y no de la teoría o del socialista intelectual.

En sus años en el rancho Glen Ellen, London sintió un ligero sentimiento ambivalente hacia el socialismo. Tenía un extraordinario éxito financiero como escritor, y quería desesperadamente alcanzar el mismo éxito con su rancho Glen Ellen. Se quejó acerca de los "ineficientes trabajadores italianos" en su empleo. En 1916, renunció al capítulo que constituyó en su vida Glen Ellen en el partido socialista, pero declaró categóricamente que lo hacía "debido a su carencia de fuego y lucha, y la pérdida de énfasis en la lucha de clases".

En un retrato poco favorecedor de los días de Jack London en el rancho, Kevin Starr en 1973 se refiere a este periodo como "post socialista" y dice que "... alrededor de 1911 ... London estaba más aburrido de la lucha de clases que lo que quería admitir". Starr mantiene que el socialismo de London
"siempre tuvo una cariz elitista en él, y una buena postura de acuerdo". Le gustaba jugar a ser un intelectual de la clase trabajadora cuando era apropiado a sus propios propósitos. Invitado a una casa prominente de Piamonte, llevaba una camisa de franela, pero, según comentó alguien allí, la chapa que llevaba London en solidaridad con la clase trabajadora "parecía como si hubiera sido especialmente lavada para la ocasión". Mark Twain dijo "le serviría a London para hacer que la clase trabajadora tomara el control de las cosas. Tendría que llamar a la milicia para recolectar sus derechos de autor".

En sus "Memorias de Lenin" (1930), su mujer, Nadezhda K. Krupskaya, afirma que dos días antes de su muerte leyó "Amor a la Vida" a su marido, Vladimir Ilyich Lenin.

London compartió la preocupación de muchos californianos por la inmigración asiática y el denominado peligro amarillo, que utilizó como título de un ensayo que escribió en 1904.

Este tema fue también objeto de una historia que escribió en 1910, titulada "La invasión sin paralelo". Ambientada en 1976, London describe una China con sobrepoblación que conquista y coloniza los países vecinos, con la eventual pretensión de controlar el mundo entero. Las naciones occidentales responden bombardeando China con decenas de las enfermedades más infecciosas. El genocidio, que se describe con bastante detalle, es presentado y "la única solución posible al problema de China", y en ningún lugar se expresa ninguna objeción. Sin embargo, muchos de los cuentos de London destacan por su retrato empático de personajes mexicanos, asiáticos y hawaianos. En su correspondencia de la guerra ruso-japonesa, así como su novela inconclusa "Cherry", muestra gran admiración por las costumbres y capacidades japonesas.

Durante su corta vida, London tuvo numerosos intereses, entre los que se encontraba el boxeo. El escritor realizó varios trabajos como corresponsal cubriendo los principales hitos pugilísticos de comienzos del siglo XX. El mayor de ellos fue la llamada 'Pelea del Siglo' que enfrentó en 1910 a Jack Johnson -negro y de extremada mala reputación- contra James Jeffries, favorito del público blanco y némesis planteada por la prensa de la época. El combate acabó con victoria por KO del campeón negro, púgil al que London había acusado durante la previa del encuentro con términos racistas.

Pero además, London trasladó su pasión por el boxeo a la literatura, escribiendo una serie de cuentos que sería publicados bajo el título 'Knock Out: tres historias de boxeo'.

La muerte de Jack London está llena de controversia. Muchas fuentes antiguas la describen como un suicidio, y algunas todavía lo hacen. Sin embargo, esto parece más un rumor o una especulación apoyada en los incidentes que tienen lugar en sus escritos de ficción. Su certificado de defunción establecía como causa una uremia. Murió el 22 de noviembre de 1916. Se sabe que sufría un dolor extremo y que estaba tomando morfina, y es posible que una sobredosis de morfina, accidental o deliberada, pudiera haber contribuido a su muerte. Clarice Stasz, en una semblanza biográfica, escribe "Tras la muerte de London, por varias razones, se creó el mito biográfico en el que se le presentaba como un alcohólico mujeriego que se suicidó. Las investigaciones más recientes apoyadas en documentos de primera mano cuestionan esta caricatura".

El suicidio aparece en las historias de London. En su novela autobiográfica "Martin Eden", el protagonista se suicida muriendo ahogado. En su memoria autobiográfica "John Barleycorn", declara, como adolescente, haber tropezado en estado de embriaguez, cayendo por la borda a la Bahía de San Francisco, "algún parloteo exorbitante cuando baja la marea me obsesionó de pronto", y fue a la deriva por horas intentando ahogarse a sí mismo, casi consiguiéndolo antes de que se le pasara la borrachera y fuera rescatado por un pescador. Un hecho paralelo ocurre en el desenlace de "The Little Lady of the Big House", en el cual la heroína, enfrentada al dolor de una herida mortal e intratable causada por un disparo, experimenta un suicidio asistido por medio de la morfina. Estos hechos en sus historias probablemente contribuyeron al mito bibliográfico.

Los restos mortales de Jack London están enterrados, junto con los de su esposa Charmian, en el Parque Histórico Jack London, ubicado en Glen Ellen, California. La humilde tumba está marcada con un pedrusco mohoso.




Según una investigación de la Universidad de Stanford realizada por Earle Labor, Robert C. Leitz III y I. Milo Shepard, en 23 años de oficio Jack London publicó 197 cuentos que quedaron dispersos en archivos, revistas y una veintena de libros. Ellos realizaron la edición canónica en inglés en 1993. La traducción completa de esta edición en español, que incluye los numerosos inéditos, se empezó a imprimir en tres volúmenes en 2017: "Cuentos completos I". Madrid: Reino de Cordelia, 2017. Algunos de los más famosos son:







</doc>
<doc id="42852" url="https://es.wikipedia.org/wiki?curid=42852" title="Universidad de Princeton">
Universidad de Princeton

La Universidad de Princeton (inglés: Princeton University), localizada en Princeton, Nueva Jersey, Estados Unidos es una de las ocho universidades de la "Ivy League". Fue fundada como el College of New Jersey en 1746, y estuvo originalmente localizada en Elizabeth. Reconocida como una de las más prestigiosas universidades del mundo, la universidad fue trasladada a Princeton en 1756, manteniendo el nombre original. El nombre fue cambiado oficialmente a Universidad de Princeton en 1896. Originalmente fue una institución presbiteriana, actualmente laica.

En ella impartieron clases los matemáticos John Nash y George Dantzig (este último inventor del algoritmo simplex), el economista y Nobel Angus Deaton. El famoso físico Albert Einstein enseñaba e investigaba en el Instituto de Estudios Avanzados de Princeton, que está cerca de la Universidad.

Princeton es una de las universidades más ricas del mundo con una dotación financiera que supera los 23 000 millones de dólares. Parte de estos recursos son invertidos en su museo de arte que exhibe numerosas pinturas, esculturas y arqueología; sus fondos suman 72.000 piezas. De historia ya centenaria, este museo cuenta con pinturas de Fra Angelico, Hendrick Goltzius, Ludovico Carracci ("El prendimiento de Cristo"), Goya (una de sus raras acuarelas sobre marfil), Monet, Gauguin, Warhol y muchos otros artistas preeminentes. Cuenta también con abundantes grabados y dibujos, arte africano, porcelanas, y más.

Princeton es constantemente calificada entre las mejores universidades de EE. UU. y del mundo con siete nominaciones consecutivas al primer puesto por la revista US News & World Report; de 2001 a 2018 logró el puesto número uno 16 veces por encima de las prestigiosas Harvard, Yale, Stanford y Chicago .

El presidente de EE. UU. Woodrow Wilson fue alumno y presidente de esta universidad. Otros alumnos prominentes incluyen el CEO de Amazon Jeff Bezos, el expresidente del Perú Pedro Pablo Kuczynski, la ex Primera Dama Michelle Obama, el Senador de Tejas Ted Cruz, y la actriz Brooke Shields.

"Old Nassau" ha sido himno de la Universidad de Princeton desde 1859. Estas palabras fueron escritas ese año por un estudiante de primer año, Harlan Page Peck. Sin embargo, Old Nassau no solo se refiere al himno de la Universidad. También puede referirse a Nassau, el edificio que fue construido en 1756 bautizado en honor a Guillermo III de Inglaterra o referirse a una reacción química que es conocido como "Reacción de Nassau" porque la solución se vuelve de color naranja y negro.




</doc>
<doc id="42855" url="https://es.wikipedia.org/wiki?curid=42855" title="Arcología">
Arcología

La arcología es un tipo de arquitectura basado en estructuras de grandes dimensiones que permitan un diseño urbano de alta densidad, compacto, integrado, de bajo impacto ecológico y alta eficiencia en el uso de recursos, en oposición a la expansión ilimitada de las ciudades actuales sobre el territorio.
El término proviene de la fusión de "arquitectura" y "ecología". Fue introducido por Paolo Soleri.

Arcosanti es un pueblo experimental en construcción en el centro de Arizona. Diseñado por Paolo Soleri, su propósito primario es demostrar los principios de la arcología.

Muchas ciudades en el mundo han propuesto proyectos que se adhieren a los principios de diseño del concepto de arcología, como Tokio y Dongtan, cerca de Shanghái. La primera fase de Dongtan tiene prevista su inauguración en 2010.

Ciertas ciudades y proyectos urbanos exhiben algunas características que reflejan los principios de diseño de la arcología. Los sistemas de conexión pedestre, como el sistema +15 en los suburbios de Calgary, o el Sistema Skyway de Minneapolis son ejemplos. Son aparatos autocontenidos, con supermercados interconectados, complejos de tiendas y entretenimiento. El +15 es el sistema skywalk pedestre más grande con una longitud total de 16 km, y Minneapolis posee el sistema continuo más largo, con 13 km de longitud. Seward's Success en Alaska fue planificado pero no se llegó a construir. Hubiera sido una pequeña ciudad en las afueras de Anchorage. Co-op City en el Bronx de Nueva York es otro ejemplo, con muchos servicios provistos en el lugar.

El Las Vegas Strip exhibe características de diseño inspirado en la arcología. La mayoría de resorts de casino principales están conectados por túneles, puentes peatonales y monorailes. Es posible desplazarse del Mandalay Bay en el sur al Strip del Centro de Convenciones de Las Vegas, 5 km al norte, sin usar calles. En muchos casos, es posible desplazarse entre bastantes casinos distintos sin tener que salir a la calle.

La Base McMurdo del Programa Antártico de los Estados Unidos y otras estaciones científicas de investigación en el continente de la Antártida pueden ser más aproximadas a la concepción de una arcología como una comunidad humana avanzada tecnológicamente y autosuficiente. Aunque no sea enteramente autosuficiente (el esfuerzo de reabastecimiento "operación Deep Freeze" del ejército de EE. UU., consume 30'3 millones de litros de combustible y 5.000 toneladas de suministros y equipamiento anualmente), la base tiene un carácter muy insular como protección necesaria ante un entorno extremadamente duro, estando aislada geográficamente de las redes de soporte convencional, y deben evitar el daño al ecosistema antártico de su entorno debido al Protocolo de Protección Ambiental del Tratado Antártico. La base genera electricidad con su propio generador, y cultiva frutas y vegetales en un invernadero hidropónico, principalmente para uso limitado en invierno, cuando el reabastecimiento es inexistente. La base también está provista de un rango completo de elementos de vida y esparcimiento para los aproximadamente 3.000 personas científicas y de soporte que la visitan cada año.

Crystal Island es un proyecto de arcología propuesto en Moscú, Rusia, aunque en 2009 la construcción ha sido pospuesta indefinidamente debido a la crisis económica global.

En 2008, la firma de diseños Timelinks propuso una superestructura de carbono neutral de 2'3 km² con capacidad para 1 millón de habitantes en Dubái con muchos conceptos de arcología (ver Inhabitat » ZIGGURAT: Dubai Carbon Neutral Pyramid will House 1 Million (en) por Evelyn Lee).

A lo largo del tiempo, varios arquitectos y empresas de ingeniería han diseñado proyectos visionarios (o hipotéticos) que no están hechos para su construcción definitiva. Entre esta categoría están las construcciones más altas jamás antes diseñadas, como por ejemplo Ultima Tower, o X-Seed 4000.

Sin embargo, es en el terreno de la ciencia ficción, donde el término ha tenido mayor desarrollo. El concepto se intuye ya en Metrópolis de Fritz Lang, la novela El Mundo Interior de Robert Silverberg (1971), la novela de J.G. Ballard "Rascacielos" (1975). Aparece en "Hacia el país del Ángel eléctrico" de William Rotsler, en el libro "En el óceano de la noche" de Gregory Bendford (1976) o Juramento de Fidelidad de Jerry Pournelle y Larry Niven (1981). Aparece también descrito en "Los proyectos" de Conde Cero, en la película La fuga de Logan, Appleseed de Masamune Shirow, el edificio de la Tyrell en Blade Runner, en la primera película Star Trek de J. J. Abrams y en la última película de Juez Dredd. En estas obras de ficción se destaca su imponente apariencia física como alarde corporativo, y su población hacinada, que rara vez llega al nivel del suelo, sobre su capacidad para mantener su propia ecología.
En el ámbito de los videojuegos se encuentran ejemplos en SimCity y la ciudad de Rapture, representada en el videojuego de 2007 "BioShock". Rapture es una ciudad sumergida en la que el capitalismo salvaje y la experimentación genética han vuelto locos a sus habitantes, sumido a la ciudad en el caos y haber dejado pocos supervivientes. Un buen ejemplo de arcología extendida y detallada que ayuda mejor a entender el concepto y a plantear ciertos dilemas morales a considerar.
También en "Destiny 2" se puede encontrar la Arcología de Nuevo Pacífico, situada en Titán, el satélite más grande de Saturno.




</doc>
<doc id="42864" url="https://es.wikipedia.org/wiki?curid=42864" title="Sistema educativo de Estados Unidos">
Sistema educativo de Estados Unidos

El sistema educativo de Estados Unidos es mayoritariamente público, con control y financiación de los tres niveles de gobierno: federal, estatal y local.

La educación infantil es obligatoria. La educación Preescolar es opcional. A partir de los seis años, es decir, desde el primer grado de primaria, la educación escolar es obligatoria.

El período escolar en los Estados Unidos dura doce años. Cinco años de primaria (1.º-5.º) y otros siete de secundaria (6.º-12.º). Las escuelas estadounidenses inician el curso en septiembre después de las vacaciones de verano (julio-agosto). Un año escolar dura dos semestres: el primero, de septiembre a diciembre; y el segundo, de enero a junio. Los jóvenes asisten a escuelas públicas, que son subsidiadas por el estado desde primaria hasta secundaria. Los alumnos de secundaria tienen cuatro o cinco asignaturas y sus períodos de estudio son de una o dos horas. 

Las escuelas ofrecen actividades extracurriculares como estar en una banda musical, en una orquesta o coro, en clubs, bailes, asambleas, en obras teatrales, y deportes. Después que terminan la secundaria, cuya graduación es en el mes de junio, siendo ya egresados, van a la escuela superior, esto es, la universidad, ya sea pequeña o grande, en su propio estado o en otro. Por lo común, esta última etapa no es gratis, les toca pagar por una carrera universitaria, pero hay becas para buenos estudiantes y muchos universitarios lo solucionan buscando algún trabajo a media jornada para así pagarse sus estudios universitarios.

Un estudio sobre los 146 colegios y universidades más competitivos indica que solo el 3 % de los estudiantes admitidos proviene de familias modestas.

Según el sociólogo Rick Fantasia, hasta la Segunda Guerra Mundial, las universidades estadounidenses "operaban al servicio de la clase superior", recibiendo casi únicamente a los hijos de las familias patricias, en general, en base a "un guiño de ojo y un apretón de manos" (es decir, en función de la red de relaciones sociales). Una vez admitidos, esos hijos de familia de "sangre azul" llevaban una tranquila vida universitaria en un clima de veneración institucional y establecían con sus pares sólidos lazos que durarían toda la vida; del Rotary Club a los consejos de administración, pasando por los campos de golf (lo que aún hoy se denomina la "old boy network" o "red de muchachos de edad madura").

Las universidades que solamente imparten programas de dos años conducentes al grado de asociado son instituciones de educación superior denominadas comunitarias ("community college" en inglés) o júnior ("Junior College" en inglés). Pueden ser la base para realizar posteriormente estudios de mayor duración en otras universidades.

Ofrecen cursos de educación general, educación técnica y cursos de preparación vocacional, los cuales capacitan a los estudiantes para que puedan trabajar de inmediato.

Puesto que su meta es ofrecer educación a toda la comunidad local, generalmente las escuelas comunitarias admiten a casi todos los estudiantes que cumplen con los requisitos básicos y ofrecen una amplia gama de opciones a un costo relativamente bajo. En la mayoría, aunque no en todas, se admite a estudiantes extranjeros. Las universidades de dos años privadas ofrecen programas similares, pero a veces se hace énfasis en la preparación académica con vistas a los estudios de grado en otra universidad y no a los estudios técnicos.

Las universidades de dos años, además del título de asociado, otorgan, a veces, también certificados de mérito al término de programas técnicos más cortos.

Durante los últimos años, casi 500.000 extranjeros estudiaron en universidades de dos años en Estados Unidos. Hay varias razones por las cuales los estudiantes extranjeros ven estas escuelas como una opción atractiva durante los primeros dos años de estudios de pregrado. Con frecuencia las razones que se citan como ventajas son el bajo costo, el énfasis del profesorado en enseñar en vez de investigar y la atención a las necesidades individuales de aprendizaje.

Muchas universidades con programas de dos años ofrecen a los estudiantes extranjeros una variedad muy amplia de servicios, aunque otras apenas comienzan a desarrollar dichos servicios. Algunas ofrecen facilidades y programas para estudiantes extranjeros, incluyendo programas de inglés como segundo idioma. Puesto que la mayoría de los estudiantes viven cerca, no tienen residencias estudiantiles en sus campus. No todas estas instituciones están autorizadas para expedir el Modelo I-20 (el documento necesario para solicitar visa de estudiante). En tales casos, los estudiantes extranjeros deben ser residentes permanentes (inmigrantes) para poder asistir a estas escuelas.

Si se planea continuar estudios, más allá del grado de asociado, estudiando primero en una universidad de dos años y transfiriendo los créditos posteriormente, se debe asegurar que los créditos académicos sean transferibles a estudios de cuatro años de duración en la universidad escogida. Antes de iniciar cursos en una institución de dos años se debe averiguar en la oficina de registro de las instituciones de cuatro años a las que se desea ingresar si aceptan los créditos de los cursos que se planea tomar en la universidad comunitaria. Muchas universidades de dos años tienen acuerdos con otras universidades cercanas para garantizar que sus estudiantes sean aceptados al transferirse a un programa de grado. Aun cuando las universidades comunitarias en un estado tienen acuerdos de trasferencia con universidades públicas y con universidades dentro del mismo estado, las universidades privadas tal vez no acepten transferir todos los créditos de una universidad comunitaria. Los créditos de programas técnicos que se orientan hacia la obtención inmediata de un empleo en su mayoría no son transferibles a programas académicos.

Los términos "college", "universidad" e "instituto" se usan indistintamente en Estados Unidos para referirse a las instituciones de educación superior que ofrecen programas de grado, al igual que las cinco academias militares de Estados Unidos. No existe un control oficial o legal sobre la opción de la institución para escoger uno u otro término como parte de su nombre. Muchas instituciones cambian su nombre cuando añaden programas y niveles de estudios nuevos. 

Históricamente, un college ofrecía programas de estudios de cuatro años para la obtención del título de grado, mientras que una universidad también ofrecía programas de postgrado.

Existen más de 2.000 universidades de tres años en Estados Unidos, y cada una posee una identidad única. Cada una define sus propias metas, sus énfasis y sus normas de admisión. Las universidades de "artes liberales", por ejemplo, hacen énfasis en la excelencia de la enseñanza de temas tales como humanidades, ciencias naturales, ciencias sociales, e idiomas.

Además de las universidades de artes liberales, existen instituciones especializadas de todo tipo. Algunas universidades únicamente admiten hombres, otras solo mujeres o solo estudiantes de raza negra, pero la mayoría están abiertas a todos los estudiantes cualificados que solicitan admisión. En otras se le da especial énfasis a la religión. Las universidades que hacen hincapié en la preparación para una carrera pueden tener programas especiales de cooperación educativa o pasantías en los cuales los estudiantes tienen que trabajar medio tiempo como requisito para obtener su grado.

Las universidades pueden ser públicas o privadas. Las instituciones de alto nivel se hallan por igual entre las universidades públicas y las privadas, la diferencia estriba en el origen de sus fondos. Las instituciones públicas utilizan fondos del gobierno estatal, fondos del pago de las matrículas de los estudiantes, y donaciones. Puesto que las instituciones públicas están apoyadas por el gobierno estatal, estas dan preferencia a la inscripción y matrícula de estudiantes de su estado. El costo es menor en las instituciones públicas que en las privadas, aún para los estudiantes que no son residentes del estado.

Las universidades públicas estatales caen en dos categorías generales:



En 1862, el Congreso aprobó la Ley Morrill, por lo que se otorgaron terrenos a muchos estados para establecer universidades. Estas universidades "land grant", además de brindar una amplia variedad educativa en muchas áreas, enfatizan la aplicación de los conocimientos en áreas como la agricultura y la ingeniería. Las universidades cuyo énfasis son los conocimientos aplicados, generalmente utilizan denominaciones como "Universidad de Agricultura y Mecánica" o "Universidad Tecnológica". Otros estados las llaman "universidades estatales" ("state universities"). Más recientemente, algunas universidades estatales han sido llamadas universidades "sea grant" para enfatizar la importancia de sus estudios marítimos aplicados.

Además de los programas de grado, muchas universidades con programas de dos y cuatro años ofrecen oportunidades para estudiar cursos cortos. Los programas de verano están abiertos a estudiantes no inscritos en un programa de licenciatura, y algunas instituciones ofrecen la opción de un año de estudios en el extranjero.

En EE.UU., antes de pasar a ser médico se debe aprobar la Escuela de medicina. Para ello, un estudiante que desee optar a una escuela de medicina tiene que aprobar el MCAT «Prueba de Admisión en una Escuela de Medicina». Antes de esto, debe cursar unas asignaturas comunes, llamadas obligatorias en España; pero aparte de esto no tienen ningún tipo de «carrera» en sí misma, sino que pueden cursar asignaturas de todos los campos existentes (ya sea una asignatura de humanidades, ciencias sociales, etc.).




</doc>
<doc id="42866" url="https://es.wikipedia.org/wiki?curid=42866" title="Artes en Estados Unidos">
Artes en Estados Unidos

Las bellas artes en Estados Unidos se desarrollaron bajo condiciones muy diferentes a aquellas que se presentaron en muchas otras naciones. Estados Unidos se formó a partir de un grupo de colonias; sus fundadores provenían de diversos lugares con diferentes costumbres y tradiciones. Estas, idóneas para las necesidades de la sociedad en sus países de origen, tuvieron que adaptarse a la vida en un ambiente extraño y adverso. Una cultura propiamente estadounidense, fundada en estas tradiciones modificadas desde lejanas regiones, aunque diferente de ellas, creció y se desenvolvió solo después de convertirse Estados Unidos en una nación independiente.

Si bien el ideal de evolución artística de Adams pudo realizarse solo de manera aproximada, de hecho en Estados Unidos se ha desarrollado una robusta tradición de creatividad en el arte y la música. Su crecimiento a lo largo de los años se ha caracterizado por la pugna entre dos grandes fuerzas de inspiración: la creatividad local, en ocasiones primitiva, y el refinamiento europeo. En general, los mejores artistas han sido aquellos que han sabido combinar ambas fuerzas para crear sus propias formas originales.

Sin embargo, así como no hay un solo grupo característico étnico o cultural, tampoco se puede reconocer un estilo peculiar estadounidense en las artes. Existe, más bien, una mezcla de muchos estilos que reflejan la realidad de la sociedad. Incluso algunas generalizaciones que intentan definir lo estadounidense en el arte han sido reveladoras. Convencionalmente, el arte ha sido producido y disfrutado con un mínimo de apoyo o control directo del gobierno. En realidad, una de las cualidades que ha distinguido a la cultura ha sido su incapacidad para esperar apoyo financiero por parte del gobierno. Para sobrevivir y crecer, museos, galerías de arte, orquestas sinfónicas, sociedades de música de cámara y teatros, han tenido que depender de benefactores particulares, donaciones universitarias y venta de boletas, como sus medios principales pare obtener recursos. Sin la seguridad de los subsidios gubernamentales, que por costumbre el arte de otros países goza, en Estados Unidos las artes siempre han estado vinculadas al comercio.

No obstante, es esta misma unión la que ha contribuido a despertar el ingenio y la experimentación cultural. Tal vez estos rasgos puedan verse mejor en el desarrollo y la creatividad de la industria del cine y en la influencia mundial de la música popular. También se reflejan en el incremento de teatros regionales y compañías de ballet, galerías que exhiben el trabajo de artistas locales, y el firme crecimiento de orquestas sinfónicas menos famosas a través de todo el país. La cultura en Estados Unidos parece haber florecido precisamente debido a su independencia respecto al control gubernamental y sus subsidios.

Las artes en Estados Unidos han crecido velozmente, especialmente durante los últimos 30 años. Una tendencia importante ha sido el crecimiento de las universidades en su papel de centros para la creación y la representación artísticas. Con objeto de satisfacer la creciente demanda de adiestramiento que requieren los estudiantes, éstas han incluido en su personal compositores, músicos, pintores y otros artistas. Además, las universidades han desplegado actividades culturales fuera de sus centros acostumbrados, como Nueva York y Chicago hacia otras ciudades y regiones por todo el país.

Una mayor preparación en las artes ha aumentado el número de artistas aficionados serios. Alrededor de 53 millones de ciudadanos tocan algún instrumento musical. Otros 50 millones pintan o dibujan en su tiempo de descanso. Y las cifras de escritores, poetas, fotógrafos y bailarines aficionados son similares.

Otro desarrollo significativo, en contraste con las prácticas anteriores, ha sido una cautelosa pero creciente participación de los gobiernos federal y estatal en el apoyo a las artes, particularmente al disponer subvenciones para las instituciones culturales. El gasto de la Fundación Nacional para las Artes, una agencia gubernamental creada en 1965, superó en 1993 los US$159 millones. A esto se suman las aportaciones de las agencias de gobierno estatales para las artes. No obstante, toda esta subvención oficial sigue siendo pequeña si se la compara con las aportaciones privadas para las artes. Pero también debe recordarse que un porcentaje de tales aportaciones son deducibles de impuestos a las personas físicas. De esta forma, el gobierno proporciona gran ayuda a las artes sin comprometer la tradicional independencia de éstas respecto al control gubernamental y el respaldo directo de fuentes privadas.

La subvención pública para las artes nunca ha sido mayor. En una reciente encuesta de opinión pública se encontró que alrededor del 90% de los ciudadanos creen que las artes "hacen de la comunidad un mejor lugar", mejoran la calidad de la vida, y son un recurso importante para los "negocios y la economía" de sus comunidades. Estos números demuestran que las artes no pertenecen a una élite, sino que se hallan sólidamente en el espíritu de la vida en Estados Unidos.



</doc>
<doc id="42868" url="https://es.wikipedia.org/wiki?curid=42868" title="Música de los Estados Unidos">
Música de los Estados Unidos

La música estadounidense es un reflejo de la población multiétnica del país a través de una amplia gama de estilos. Entre los géneros de mayor reconocimiento internacional originarios del país destacan la "marcha", el "country", el "bluegrass", las llamadas músicas afroamericanas (como el "blues", "el hip hop," el góspel, el "rhythm and blues", el "jazz" y la música "house"), la música disco, el "ragtime" y el "rock and roll". Otros géneros musicales que tienen su origen en el país son el pop, el "techno", el reguetón, la salsa y el "barbershop". Además de varios subgéneros, como el "dixieland", y otras músicas regionales. Asimismo, existen variaciones como la música cinematográfica y los musicales. 

Esta rica herencia musical es fruto de numerosas influencias entre las que destaca la interacción entre las tradiciones clásicas europeas y la vitalidad de las expresiones regionales y étnicas. De hecho, muchos compositores de música clásica han trabajado sobre formas populares.

Son innumerables las canciones y composiciones escritas por estadounidenses conocidas en todo el mundo; como, por ejemplo, «Jingle Bells» (1857) y «Cumpleaños feliz» (1893), o estándares de "jazz" como «When the Saints Go Marching In» además de las que forman parte del cantante estadounidense, el Great American Songbook.

Los Estados Unidos representan el mayor mercado de la industria musical a nivel mundial, con un valor total de 4.372,9 millones de dólares. En 2011 los EE.UU. encabezaban el "ranking" mundial de ventas globales de música con el 26 % del total mundial, seguidos por Japón, con el 25 %.

La combinación que hizo MacDowell del romanticismo tradicional con nuevas formas musicales influyó significativamente en ciertos compositores que lo siguieron, incluyendo al distinguido neorromántico Samuel Barber (1910-1981). A la vez que MacDowell luchaba por divulgar la música seria entre el público común, el "ragtime", un ritmo derivado del "dixieland" y de la música sureña de taberna, levantaba los ánimos en salas y teatros de toda la nación. La primera música negra en obtener gran popularidad, el "ragtime" se creó principalmente para el piano, destacando una síncopa casi continua. El compositor más notable fue Scott Joplin (1868-1917), que escribió dos óperas en ese ritmo y confiaba en que su música resistiría la comparación con la música clásica europea. Sin embargo, desde el punto de vista histórico, el "ragtime" es quizá más importante por su asociación con el blues. Y del blues provino el "jazz", la gran contribución de los Estados Unidos al mundo de la música

El blues, cuyo origen se remonta a las canciones folclóricas de África y a la música religiosa cristiana, es un lamento con un deje de resignación y frecuente humor. Entre las primeras grandes voces que se grabaron sobresalieron las de muchas mujeres, incluyendo a Gertrude "Ma" Rainey (1886-1939) y a Bessie Smith (1900-1937). Por lo común, el blues moderno es interpretado por pequeñas bandas que destacan en primer plano la guitarra eléctrica y otros instrumentos, al igual que la voz del cantante. Entre los músicos más populares de esta vertiente se encontraban Muddy Waters (1915-1984) y BB King (1925-2015).

Cuando los músicos de "blues" y de "dixieland" depuraron sus técnicas instrumentales, nació el "jazz", que tiene como una de sus características vitales la improvisación. Por lo general, los músicos escriben una estructura armónica básica y las otras partes se crean espontáneamente basadas en la música que interpreta el resto del grupo.

Alrededor de 1920, el "jazz" se extendió desde el sur conforme los músicos negros se mudaron a Chicago y Nueva York. El más influyente de los primeros músicos de "jazz" fue el trompetista Louis Armstrong (1900-1971). Nacido en Nueva Orleans, una de las cunas del "jazz", fue el primer cantante famoso de este género y creador del "scat", un recurso que consiste en utilizar la voz como instrumento, cantando sílabas sin sentido. Otro de los más destacados jazzistas de esa generación fue Duke Ellington (1899-1974). Pianista, director de orquesta, compositor y arreglista, tuvo un enorme impacto en la composición y ejecución del "jazz".

Cada nueva generación del "jazz" ha explorado nuevas direcciones. A principios de los años 40 surgió un complicado estilo llamado "bebop", apoyado por el trompetista "Dizzy" Gillespie (1917-1993) y el saxofonista Charlie Parker (1920-1955), el improvisador más grande del "jazz".

En los años 60, músicos de "jazz" como el trompetista Miles Davis (1926-1991) y el saxofonista John Coltrane (1926-1967) experimentaron con las más variadas influencias musicales. Los más jóvenes empezaron a introducir ritmos de "rock and roll". Luego, en los años 70, muchos músicos de "jazz" experimentaron con instrumentos electrónicos y crearon una mezcla de "rock" y "jazz" llamada fusión. En los años 50, el "jazz" empezó a gozar de amplia popularidad como uno de los bienes culturales más importantes, aumentando su auditorio entre los intelectuales y los estudiantes de nivel superior. Hoy es parte de la corriente principal del espectáculo en Estados Unidos, y los conciertos de "jazz" atraen a miles de oyentes cada año.

El "jazz" ha tenido una influencia enorme sobre toda la gama de música de los Estados Unidos. En ninguna obra se puede observar más claramente tal influencia que en la de George Gershwin (1898-1937), uno de los más prestigiosos compositores de este siglo. Compositor de canciones populares, Gershwin también creó una serie de comedias musicales para los escenarios de Broadway. Sus trabajos más notables se han convertido en clásicos modernos, siendo los primeros en incorporar con éxito el "jazz" a formas tomadas de la tradición europea. Entre ellos están el concierto "Rhapsody in Blue" (1924) y la ópera "Porgy and Bess" (1935).

Desde los años 40, los compositores han tendido a desplazarse en muy diversas direcciones. Algunos recurriendo directamente a influencias tradicionales y a la cultura popular, han conseguido fama a través de sus partituras para comedias musicales. Heredera de los antiguos "minstrel shows" y la ópera ligera, la comedia musical se ha convertido en una forma original de entretenimiento donde se combinan la canción, el baile, la comedia y el drama. Entre los duetos compositor-letrista de mayor éxito se encuentran Richard Rodgers y Oscar Hammerstein, autores de "Oklahoma!" (1943) y "Carrusel" (1945).

Popularizado en sus inicios por músicos blancos, quienes durante los años 50 interpretaban una miscelánea de góspel sureño, música "country" y "rhythm and blues" negro, el "rock and roll" se convirtió muy rápidamente en una segunda lengua de la juventud. Elvis Presley (1935-1977) fue el primer "rey del rock 'n roll", con ventas que sobrepasaban los 500 millones de discos, y el primer músico de rock al que sus jóvenes admiradores en todo el mundo le otorgaron un nivel casi mitológico.

Bob Dylan (nacido en 1941) surgió como uno de los principales compositores e intérpretes durante la explosión de música folclórica que experimentaron los Estados Unidos a principios de los años 60. Sus canciones de protesta llegaron a ser himnos del cambio social, y ejerció una influencia extraordinaria sobre otros músicos y escritores. Los años 60 también fueron testigos del nacimiento del sonido "motown", el irresistible "rhythm and blues" de Detroit. Entre sus estrellas rutilantes sobresale Diana Ross (nacida en 1944). 

Otros estilo del sur que empezaron a obtener amplia popularidad fueron la música country, dominada sobre todo por los músicos establecidos en Nashville, como Willie Nelson (nacido en 1933), y el "bluegrass", una mezcla de folclore, "blues" y música "country". El "bluegrass" aumentó su auditorio gracias a las canciones de Bill Monroe (1911-1996), entre otros.

El "rock and roll" pareció perder su impulso casi revolucionario en los años 70 y 80. Aún así, algunos artistas sobresalieron, entre ellos el compositor y guitarrista Bruce Springsteen (nacido en 1949), el cantante y compositor Stevie Wonder (nacido en 1950), y el vocalista Michael Jackson (1958-2009). En 1985, millones de personas participaron de los conciertos en pro de la vida, un esfuerzo de las estrellas pop y de rock por recaudar dinero y víveres para combatir la hambruna en África.

Por último, en los años 90 el cantante Kurt Cobain revolucionó la música cuando su banda (Nirvana) lanzó el disco Nevermind en 1991, con lo que se convirtió en uno de los cantantes más importantes e influyentes de todo el mundo.

Pocos compositores han identificado tanto su obra con los temas y ritmos estadounidenses como Aaron Copland (1900-1990). Su trabajo ejemplifica la tendencia de muchos compositores modernos a escribir música para una amplia gama de propósitos: orquesta, películas, radio, sesiones de grabación, para la enseñanza elemental y la escuela superior. Algunas de sus piezas de concierto más frecuentemente interpretadas se compusieron para el ballet, como la suite "Billy the Kid" (1938) y "Primavera en los Apalaches" (1945).

Muchos otros compositores han experimentado radicalmente con música antitradicional, la cual ha no ha sido fácilmente aceptada por la mayoría del público que gusta de las orquestas. Aunque mientras vivió fue prácticamente desconocido, Charles Ives (1874-1954) es ahora reconocido como un innovador importante. Muchos críticos consideran a Elliott Carter (1908-2012) como el compositor estadounidense más destacado de su generación. John Cage (1912-1992) es notable porque deja algunos elementos de sus obras al azar, y también porque mezcla músicos vivos con aparatos electrónicos. A finales de los años 70 y ya en los 80, Philip Glass (nacido en 1937) alcanzó reconocimiento entre los más jóvenes compositores "minimalistas"; característica de su obra es la excéntrica ópera "Einstein en la playa".



</doc>
<doc id="42871" url="https://es.wikipedia.org/wiki?curid=42871" title="Arquitectura en Estados Unidos">
Arquitectura en Estados Unidos

La arquitectura en Estados Unidos tiene una historia relativamente reciente ya que sus primeros pobladores, los amerindios, no dejaron edificios tan espectaculares como los realizados en México o Perú. Estados Unidos es una nación multicultural, hogar de una amplia variedad de grupos étnicos, tradiciones y valores. Aparte de las ahora pequeñas poblaciones de nativos americanos y hawaianos, casi todos los estadounidenses o sus antepasados emigraron durante los últimos cinco siglos y su cultura común es una cultura occidental, que en gran parte proviene de las tradiciones de los inmigrantes europeos con influencias de muchas otras fuentes.

Desde la colonización europea, la arquitectura realizada en una primera etapa colonial (siglos XVI-XVIII) estuvo marcada por la influencia hispánica en el Sur e inglesa en la costa Este. La arquitectura de la nueva nación (siglo XIX) siguió apegada a las corrientes artísticas del Viejo Continente, en una época de auge del clasicismo seguida por un momento marcado por los múltiples academicismos, historicismos y eclecticismos, bien acogidos en una sociedad multiseleccional. Surgen en el siglo XIX algunas variedades estilísticas locales adaptadas al país —estilo federal y estilo Misión—y al final otras ya plenamente estadounidenses, como la Escuela de Chicago o la Prairie School. En el último cuarto de siglo, con el invento del ascensor y el desarrollo de las estructura metálicas, aparece un tipo arquitectónico plenamente estadounidense, el rascacielos, que tendrá un gran desarrollo y que se convertirá en símbolo de la modernidad y de la pujanza de la nación en el siglo XX y que espontáneamente se asocia con la arquitectura del país.

En 2006 y 2007, el American Institute of Architects patrocinó, en el marco de las conmemoraciones de su 150.º aniversario, una investigación para identificar las 150 obras más populares de la arquitectura en los Estados Unidos, que comunicó publicando la lista America's Favorite Architecture. Esa discutida lista es un buen reflejo de la arquitectura realizada en el país en los últimos tres siglos.

Los ejemplos de arquitectura más antiguos en Estados Unidos se concentran en dos núcleos principales. El primero de ellos está en la mitad oriental del país, donde se encuentran testimonios muy antiguos de la cultura de los Mound Builders (constructores de túmulos, ya que construían pirámides de tierra para enterrar a sus muertos), como la cultura Adena y la cultura misisipiana. El segundo núcleo está en el suroeste, región que habitaban civilizaciones ya desaparecidas en el momento de la llegada de Cristóbal Colón a América. Los asentamientos arqueológicos más conocidos de este segundo núcleo pertenecen a la cultura Anasazi, (Mesa Verde, Colorado) y a los indios pueblo (Monumento nacional de las Ruinas Aztecas, Nuevo México).

Cuando los europeos se instalaron en América del Norte, llevaron sus tradiciones arquitectónicas y sus técnicas de construcción. La arquitectura colonial está, por tanto, muy vinculada a las influencias occidentales. La construcción depende de los materiales disponibles allí: la madera y el ladrillo son elementos omnipresentes de los edificios ingleses de Nueva Inglaterra. Está también ligada a la lógica de colonización que da lugar a una apropiación política del espacio por la metrópoli (palacios del gobernador, fuertes). La marca del dominio europeo es tanto económica (aduanas, plantaciones, almacenes) como religiosa (iglesias, templos protestantes, misiones franciscanas y jesuitas).

La exploración española del suroeste americano comienza en los años 1540. El conquistador Francisco Vázquez de Coronado recorre esta región árida en busca de las míticas ciudades de oro de los indios Pueblos. Estos últimos construyen casas en adobe (masa de barro desecada al sol). Se sujetan gracias a vigas de madera hechas a propósito. La forma cúbica de las construciones y su enrevesada organización dan a los pueblos este aspecto tan singular, que será retomado más tarde por el americano "(estilo pueblo)".

Se imagina la decepción del conquistador ante estas modestas construcciones sin ornamentación, pero al abrigo del cual la temperatura sigue siendo constante y fresca. Los españoles finalmente conquistaron estos pueblos e hicieron de Santa Fe la capital administrativa de la región en 1609. El palacio de los gobernadores se construye entre 1610 y 1614 mezclando las influencias indias (adobe) y españolas (rejillas en hierro forjado). La obra es alargada y posee un patio. La capilla San Miguel de Santa Fe data de 1610 y emplea la técnica del adobe que da a este edificio religioso una majestuosidad y una austeridad sorprendentes.

En el siglo XVII y siglo XVIII, los españoles fundan una serie de fuertes ("presidios") desde la actual Los Ángeles a la actual San Francisco. Crean una red de misiones en la región del suroeste. El más famoso es seguramente el de San Antonio en Texas (Fuerte Álamo). Posee una iglesia en adobe, con una nave rectangular, con contrafuertes exteriores, dos campanarios simétricos y sin ornamentación. La Misión San Xavier del Bac en Arizona es un buen ejemplo del estilo churriguerense en voga en el resto de América Latina. La fachada está encuadrada por dos vueltas masivas y el pórtico tiene "estípites", columnas trabajadas que sólo sirven de ornamentación.

La soberanía española concierne también a Florida de manera discontinua de 1559 a 1821. Aquí, el "conch style" conoció un cierto éxito en Pensacola por ejemplo. Se trata de adornar las casas con balcones en hierro forjado; se encuentra esta tendencia en el barrio francés de Nueva Orleans, en Luisiana. Los españoles construyeron también fuertes como los de Pensacola y de Santa Agustina (Castillo de San Marcos, anteriormente monumento nacional Fort Marion), que son los raros vestigios arquitectónicos del siglo XVII que permanecen en los Estados Unidos.

La arquitectura colonial de las 13 colonias se caracteriza por el modelo inglés. Pero las diferencias climáticas y religiosas introducen elementos americanos. En Nueva Inglaterra, la casa de Pasteur Capen en Topsfield (Massachusetts, 1683), la posición central de la chimenea está prevista por si se precisa calor en invierno. Está cubierta con tablas y utiliza la madera para la estructura, dos características específicamente americanas. El puritanismo impone lugares de culto simples y sobrios, alejados de toda ornamentación ostentativa: los "reunión houses" (casa de reunión) hacen de oficina del templo y también de lugar de socialización. En el "Old Ship Meeting House" de Hingham (Massachusetts, 1681), el púlpito se coloca en el centro y la estructura se deja voluntariamente visible y desnuda.

En el siglo XVIII se desarrollan el estilo georgiano y el palladianismo a partir de la ciudad de Williamsburg en Virginia. El palacio del gobernador, construido en 1706-1720, se precede de una extensa pared de entrada y encima una claraboya colocada sobre una plataforma con barandilla. Respeta el principio de simetría. Asocia materiales que se encuentran en Nueva Inglaterra: el ladrillo rojo, la madera pintada en blanco y la pizarra azul para el techo de dos aguas. Sirve de modelo a las residencias de los cultivadores y ricos negociantes de la costa atlántica (véase abajo “casas aristocráticas americanas”).

En la arquitectura religiosa, los elementos comunes son la utilización del ladrillo, a veces del estuco imitando la piedra y de una única aguja que supera la altura de la entrada: la iglesia San Miguel de Charleston (1761) o la de San Pablo Chapel of Trinity de Nueva York (1766) son una buena ilustración. Los arquitectos de este período están muy influidos por los cánones del Viejo Mundo. Peter Harrison (1716 - 1755) informa en sus viajes de las técnicas europeas que se aplican en el Estado de Rhode Island: entre 1748 y 1761, construye la biblioteca Redwood y el mercado de Newport. Boston y Salem son las dos principales ciudades donde el estilo inglés se manifiesta, pero un estilo purificado y adaptado al método de vida americano. El arquitecto Charles Bulfinch dota el "Massachusetts State House" en 1795 - 1798 de una cúpula dorada original. Trabaja en la construcción de varias casas del barrio de Beacon Hill y de Louisburg Plaza en su ciudad natal de Boston.

En 1776, los miembros del Congreso declaran la independencia de las 13 colonias americanas. El Tratado de París (1783) reconoce la existencia de un nuevo país republicano, los Estados Unidos de América. Si hay ruptura con Reino Unido a nivel político, las influencias inglesas siguen señalando los edificios construidos en esta parte del Nuevo Mundo. Los pedidos públicos, filantrópicos y comerciales se desarrollan en paralelo con el crecimiento demográfico y la extensión territorial. Los edificios de las nuevas instituciones federales y judiciales adoptan el vocabulario clásico (columnas, cúpula y frontón), en referencia a la Antigüedad grecorromana. Las publicaciones relativas a la arquitectura se multiplican: en 1797, Asher Benjamin publica "The Country Builders Assistant". Los americanos pretenden afirmar su independencia en todos los ámbitos: política, económica y también cultural, con la fundación de universidades y de museos. Es al final del siglo XIX cuando esta independencia y este dinamismo se expresan mejor.

Thomas Jefferson, que fue Presidente de Estados Unidos entre 1801 y 1809, manifestó interés por varios ámbitos incluido la arquitectura. Residiendo en sucesivas ocasiones en Europa, deseó aplicar la sintaxis formal del palladianismo y de la Antigüedad a edificios públicos y privados, en las ciudades y en el campo. Contribuyó a este respecto al plan de la Universidad de Virginia, construida a partir de 1817. El proyecto, completado por Benjamin Latrobe, le permite aplicar sus concepciones arquitectónicas. La biblioteca universitaria se sitúa bajo una rotonda coronada por una cúpula que se inspira en el Panteón de Roma. El conjunto presenta una gran homogeneidad gracias a la utilización del ladrillo y la madera pintada de blanco. Para el Capitolio de Richmond en Virginia (1785 - 1796), Jefferson tomó partido por imitar la Maison Carrée de Nimes, pero eligiendo el orden jónico para sus columnas. Hombre de las Luces, Thomas Jefferson participó en la emancipación de la arquitectura del Nuevo Mundo imponiendo su visión de un arte al servicio de la democracia. Contribuyó a desarrollar el estilo federal en su país y a adaptar la arquitectura neoclásica europea a los valores republicanos nacidos de la Revolución americana.

El estilo neoclásico ejerce un verdadero atractivo sobre los arquitectos que trabajan en los Estados Unidos en la primera mitad del siglo XIX. La joven nación, liberada de la tutela británica, cree ser la nueva Atenas, es decir un foco de la democracia. La constitución, redactada en 1787, da nacimiento a nuevas instituciones que requieren edificios e imponen los principios de soberanía nacional y separación de los poderes. La arquitectura oficial e incluso civil o religiosa (lo que constituye la originalidad de los Estados Unidos), refleja esta visión y toma para modelo los edificios de la Acrópolis. Los Propileos se reproducen a otra escala delante de las casas en las campiñas de la costa oriental. Benjamin Latrobe (1764-1820) y sus alumnos William Strickland (1788-1854) y Robert Mills (1781-1855) obtienen pedidos para construir bancos e iglesias en las grandes ciudades (Filadelfia, Baltimore y Washington DC). Sobre todo, los Capitolios de los Estados federados adoptan el estilo neoclásico como en Carolina del Norte (Capitolio de Raleigh), reconstruido en 1833-1840 después de un incendio o en el de Indiana (Capitolio de Indianápolis). Uno de los ejemplos más tardíos de esta tendencia es el Capitolio de Columbus en Ohio, diseñado por Henri Walters y acabado en 1861. La fachada sobria, la cornisa continua y la ausencia de cúpula dan una impresión de austeridad y de grandeza al edificio. Presenta un plano simétrico y alberga el tribunal supremo y una biblioteca.
La capital federal de los Estados Unidos es un bello ejemplo de urbanismo homogéneo: el conjunto fue imaginado por el francés Pierre Charles L'Enfant. Este ideal de ciudad monumental y neoclásica es revivido por los mantenedores del movimiento City Beautiful. Varias ciudades quisieron aplicar este concepto, que se inscribe en la tendencia de las Bellas Artes], pero Washington D.C. parecen el de más éxito entre todos. La Casa Blanca se ha construido después de la creación de Washington D.C., por la ley del Congreso de diciembre de 1790. Después de un concurso para hacerla se eligió el diseño de un americano de origen irlandés, James Hoban, y la construcción comenzó en octubre de 1792. El edificio concebido se copió del primer y segundo piso de Leinster House, un palacio ducal de Dublín en Irlanda y que es ahora la sede del Parlamento irlandés. Pero durante la guerra de 1812, una gran parte de la ciudad se quemó, y el incendio devastó la Casa Blanca. Sólo las paredes exteriores permanecieron de pie, pero se reconstruyó. Las paredes se pintaron en blanco para encubrir los daños causados por el humo. Al principio del siglo XX, se añadieron dos nuevas alas para hacer frente al desarrollo del Gobierno. El Capitolio de los Estados Unidos de América se construyó en etapas sucesivas a partir de 1792. Poco después del final de la construcción, es parcialmente quemado por los británicos durante la Guerra de 1812. Su reconstrucción comienza en 1815 no terminarse sino en 1830. Durante los años 1850, el edificio fue agrandado de forma importante por Thomas U. Walter. En 1863, una imponente estatua, "Freedom", se colocó en la cumbre de la cúpula. El Washington Monumento es un monumento en forma de obelisco creado en honor de George Washington, el primer Presidente americano. Fue Robert Mills quien hizo los planos originales en 1838. Se puede percibir una diferencia de color hacia abajo, porque su construcción se paró debido a la falta de dinero. Con una altura de alrededor de 170 metros, se acabó en 1884 y fue abierto al público en 1888.

El Lincoln Monumento (1915 - 1922) es otro monumento de la misma serie: de mármol y de caliza blancos, el edificio retoma la forma de un templo griego de orden dórico sin frontón. Su arquitecto, Henri Bacon, formado en las ideas de la escuela de las Bellas Artes, quiso que las 36 columnas del monumento representaran a cada uno de los 36 Estados de la Unión a la muerte de Lincoln. Por fin, Jefferson Monumento es el último gran monumento construido en la tradición de las Bellas Artes, en los años cuarenta. Su arquitecto, John Russell Pope, quiso poner de relieve el gusto de Jefferson para los edificios romanos. Por lo qué decidió imitar el panteón de Roma y dotar al edificio de una cúpula espectacular, que se alzó a 39 metros sobre el suelo. Fue criticado severamente por los partidarios de estilo internacional.

El gusto por el gótico nunca ha desaparecido completamente, tanto en Europa como en América. No hay nada más que ver las distintas iglesias que aparecen en el siglo XVIII y en el siglo XIX debido al crecimiento demográfico. A partir de los años 1840, el estilo neogótico tiende a imponerse en los Estados Unidos, bajo el impulso de Andrew Jackson Downing (1815 - 1852). Se extiende en un contexto de reacción al clasicismo y desarrollo de romanticismo. Se caracteriza por una vuelta al decorado medieval: (chimeneas, frontales triangulares, almenas, ventanas ojivales, gárgolas, vidrieras…) y a la utilización de tejados de gran pendiente. Los edificios adoptan un plano complejo que se aleja de la simetría y el rigor neoclásico.
Pero el neogótico también se utilizó para la construcción de las universidades (Harvard) y de las iglesias. Richard Upjohn (1802 - 1878) se especializa en las iglesias rurales del noreste pero su obra principal queda "Trinity Church" en Nueva York. Su arquitectura en piedra roja hace referencia al siglo XIV europeo, pero se encuentra hoy ahogada en medio de los inmensos rascacielos de Manhattan.

Siempre en Nueva York, es a James Renwick Jr a quien se debe la Catedral de San Patricio, síntesis elegante de las catedrales de Reims y de Colonia. El proyecto le fue confiado en 1858 pero no estuvo completamente acabado por la construcción de las dos agujas de la fachada hasta 1888. La utilización de materiales más ligeros que la piedra permite prescindir de soportes y contrafuertes exteriores.

Renwick expresó también su talento en Washington D.C. con la construcción del Smithsonian Institución. Pero sus detractores le acusan de haber roto la armonía arquitectónica de la capital construyendo un conjunto heterogéneo (préstamos bizantinos, románicos, lombardos y añadidos personales) en ladrillo rojo. El éxito del neogótico se prolongó hasta el principio del siglo XX en numerosos rascacielos, en particular, en Chicago y Nueva York.

El eclecticismo es una tendencia en arquitectura que se manifiesta en Occidente entre los años 1860 y la Primera Guerra Mundial. Consiste en mezclar elementos diferentes prestados de tradiciones heterogéneas. Se distingue del neoclásico en que ésta construía edificios homogéneos de inspiración única (antigüedad grecorromana). La Academia de las Bellas Artes de París aplica los preceptos del eclecticismo e influencia a varios arquitectos americanos. Las iglesias también llamaron la atención de los arquitectos. Formados en la Escuela de las Bellas Artes de París, los grandes arquitectos americanos aplican al pie de la letra los principios que aprendieron en Francia: planos simétricos, edificios grandiosos y monumentales, riqueza de la decoración y grandes huecos en semicírculo. El decorado clásico se aplica a edificios completamente nuevos como las estaciones.

La iglesia de la Trinidad de Boston se cuenta entre los edificios más notables de ese tiempo. Adoptando un plano centrado, el arquitecto Henry Hobson Richardson apila varios volúmenes para dar al conjunto una configuración piramidal. Utiliza distintos materiales, como el gres y el granito. Los arcos de medio punto que encuadran las vidrieras son típicos del neorrománico. La ciudad de Nueva York es, con Washington DC, el principal campo de aplicación del estilo Bellas Artes: se personifica en la biblioteca pública ("New York Public Library"), el campus de la Universidad de Columbia, el Metropolitan Museum of Art, el American Museum of Natural History y el Museo de Brooklyn.La Gran Central Terminal, la estación más grande de Manhattan, se guía por el mismo espíritu y se acaba en 1913. Su fachada monumental se adorna con columnas y grandes huecos en curva.

El Puente de Brooklyn es emblemático del eclecticismo y de la ciudad de Nueva York. Da la imagen positiva del progreso y puede compararse con la Torre Eiffel ya que es obra de un ingeniero, John Augustus Roebling y porque fue criticado por una parte de sus contemporáneos. Los arcos en ojiva recuerdan la tendencia historicista, pero los cables de acero así como el resultado técnico (480 metros de alcance, una de las construcciones más altas de la ciudad al final del siglo XIX ) hacen de él un edificio moderno. A partir de los años veinte, el estilo Bellas Artes compite con la tendencia Art decó a pesar de las obras de Paul Philippe Cret (Detroit Institute of Artes, 1927]) y de Bertram Grosvenor Goodhue (Rockefeller Monumento Chapel, 1928; Capitolio du Nebraska, 1919-1932). Las formas neoclásicas se mantienen y siguen existiendo en la capital federal. La National Gallery of Art se inspira aún en el Panteón de Roma y se acaba en 1940, sobre los planos de John Russell Pope.

Se desarrollan sobre la costa oriental donde los ricos propietarios y los cultivadores se hacen construir residencias suntuosas y cómodas a partir del siglo XVII, que pretenden imitar a las residencias inglesas.

La difusión de los Tratados de arquitectura entre la aristocracia colonial permite afirmarse al estilo georgiano: en "Mount Pleasant" (Filadelfia), John McPherson se hace construir una residencia en 1761-1762 dotada de una entrada con frontón, sostenido por columnas dóricas. Tiene un techo con barandilla y una resolución simétrica, característica del estilo neoclásico entonces en voga en Europa. En Salem, Samuel McIntire es el arquitecto de la casa John Gardner-Pingree (1805); utiliza el tejado de poca pendiente, la barandilla y el ladrillo. Retoma la idea Palladio de conectar los edificios por un pórtico semicircular con columnas. En los años 1780, el estilo federal se aparta poco a poco del estilo georgiano y pasa a ser un estilo propiamente americano. En el momento de la guerra de independencia las casas se alejan del plano estrictamente rectangular, adoptan líneas curvas y se adornan con detalles decorativos como las guirnaldas y las urnas. Algunas aperturas son de forma elipsoidal; una o más partes son ovaladas o circulares.

Thomas Jefferson elaboró los planes de su propia casa de Monticello en Virginia, cerca de Charlottesville. Bonito ejemplo de estilo palladiano, recuerda el hotel de Salm situado en París, que Jefferson pudo contemplar cuando era embajador en Francia. Utilizó componentes antiguos como columnas dóricas, pórticos tetrástilos y una cúpula central. En Luisiana, las casas coloniales se encargan a veces con frontón neoclásico y columnas, como es el caso a "Belle Meade Plantation" en Tennessee: de paso simétrico, la residencia dispone de un porche con columnas y de ventanas estrechas. Pero la arquitectura doméstica del sur supo emanciparse del modelo clásico pues añade un balcón a media altura sobre la fachada y se olvida el frontón sobre el pórtico de entrada (Charleston, Carolina del sur; Oak Alley plantación en Luisiana). Las casas se adaptan al clima de la región y se inscriben en la economía de plantación. Tienen un decorado en estuco y en hierro fundido como en el barrio francés.

Más tarde, las grandes familias de la costa este se hicieron construir inmensos palacios y chalets de estilo neogótico, en las antípodas del neoclasicismo. Tomaron como modelo la casa inglesa de Sir Horace Walpole a Strawberry Hill. Alexander Jackson Davis (1803 - 1892) trabajó en los proyectos de chalets del valle del Hudson y los equipó de detalles caprichosos extraídos del directorio medieval. Para la residencia de George Merritt a Lyndhurst, elige construir un edificio de plano complejo y abrir varios ventanales que pueden hacer pensar en las vidrieras de las iglesias.

En la segunda mitad del siglo XIX, los arquitectos Richard Morris Hunt, Henri Hobson Richardson y Frank Furness a menudo recibieron encargos de familias ricas como los Ames o Vanderbilt y construyeron residencias de estilos neorrománico o neorrenacimiento. Los magnates de la industria o del transporte querían grandes mansiones inspiradas en los palacios europeos: el palacio Biltmore, cerca de Asheville en Carolina del Norte, era la residencia privada más grande del país. Richard Morris Hunt copió las alas Luis XII y Francisco I del castillo de Blois. Es la edad de oro de las grandes agencias como McKim, Mead & White y del estilo Bellas Artes, incluso para las construcciones privadas. La arquitectura expresa el prestigio de los notables americanos.

A principios del siglo XX, se difunden manuales poco técnicos, los "pattern books". El asentamiento del oeste de los Estados Unidos modifica las necesidades de la arquitectura. Los pioneros utilizan la técnica de la estructura-globo ("balloon frame") en el año 1840 y 1850. La primera utilización parece remontarse a 1833 para la edificación de la iglesia St Marys en Chicago. Su éxito radica en la rapidez de la construcción (tableros y clavos estandarizados) que permitía a cada uno realizar fácilmente la estructura y el esqueleto de la vivienda que se cubría a continuación de tablas. El interior de las paredes se cubría de yeso o madera. Fomentó el desarrollo rápido de las ciudades y daba una gran movilidad. Sin embargo, estas casas no ofrecían buenas condiciones sanitarias y se quemaban fácilmente en caso de incendio.

El "Stick Style" es un método americano de construcción de las casas que utiliza los muros de protección hechos de vigas de madera. Las construcciones se cierran con altos techos, y tejados empinados. El plano es asimétrico y el espacio interior se abre sobre varias galerías. El exterior no está desprovisto de decoración (consolas de gran tamaño y refinadas), aunque el objetivo principal es la comodidad. Richard Morris Hunt construyó la casa de John N. Griswold a Newport en 1862. El "Stick Style" se abandona progresivamente después de la crisis de 1873.

Luego el "Shingle Style" sustituyó al "Stick Style". Se caracteriza por la simplicidad y la búsqueda de la conveniencia. Henri Hobson Richardson construye la casa de William Watts Sherman en 1874 - 1875 dejando aparecer la estructura en madera. La casa de la Sra. F. Stoughton a Cambridge (1882-1883) y el casino de Newport (1879-1881) conservan la cobertura de tablas. En la costa occidental, que atrae cada vez más americanos y arquitectos, la arquitectura doméstica evoluciona también hacia cada vez más modernidad.

El barrio de Haight-Ashbury, en San Francisco, es representativo de las casas de estilo victoriano italianizante (1860 - 1900). Construidas gracias a la madera de secuoya, resistieron al incendio de la ciudad en 1906. Se decoran mucho y se colorean. Al tiempo, ofrecían toda la comodidad moderna: calefacción central, electricidad, agua corriente... Sus dimensiones se estandarizan: 8 metros para la fachada y 30 metros para la profundidad. Tienen varios pisos y ventanales.

El gusto para la simplificación de los volúmenes y de la decoración exterior progresa gracias a las realizaciones de Irving Gill a quien se deben varias casas californianas de techo plano en el año 1910 (casa de Walter Luther Dodge, Los Ángeles, por ejemplo). Rudolf M. Schindler y Richard Neutra adaptan el modernismo europeo al contexto californiano, en los años veinte ("Lovell Beach House", Newport Beach (California); casa "Health House" en Los Ángeles).

La segunda mitad del siglo XIX es la de la reconstrucción después de la Guerra de Secesión y del desarrollo económico de los Estados Unidos. La revolución industrial es el nacimiento de nuevos materiales de construcción (acero, hormigón). La urbanización, el crecimiento demográfico y el capitalismo suscitan convulsiones profundas en la arquitectura americana (estaciones, oficinas,…), que conocen su edad de oro. Los arquitectos obtienen un reconocimiento oficial y trabajan tanto para el Estado como para una clientela burguesa en búsqueda de la comodidad. El final de este período se caracteriza por la aparición del cine que exige nuevas construcciones garantizadas, en particular, por Thomas W. Lamb, en Nueva York.

A mitad del siglo XIX aparecen nuevos métodos de fabricación directa del acero (método Thomas-Gilchrist, hornos Bessemer y Siemens-Martin). Estos descubrimientos permiten la fabricación en masa de un acero de “calidad”. Los industriales hacen valer las calidades del metal en arquitectura: las partes estandarizadas reducen el coste de la construcción. Los riesgos de incendio se disminuyen gracias al método de ignifugación. James Bogardus (1800-1874) es uno de estos empresarios que hace publicidad de este método de construcción vinculado a la revolución industrial y llamado "cast-iron building". Varias fábricas y almacenes utilizan esta técnica en Nueva York, como el edificio Harper, construido en 1854 y que imita la fachada de un palacio del Renacimiento. Daniel Badger (1806-1884) fabrica los elementos metálicos que decoran la fachada del edificio Haughwout. Está dotado con el primer ascensor a vapor que sirve los cinco pisos. Las ventanas están encuadradas por columnas corintias y el conjunto está coronado por una cornisa minuciosamente adornada. El decorado de la fachada oculta el esqueleto metálico interno.

La arquitectura metálica está provista de vidrieras que iluminan el espacio interior: en Cleveland, los soportales de 1890 fueron diseñados por John Eisenmann sobre el modelo de la galería Victor-Emmanuel de Milán. Están formados por 1.800 paneles de vidrio y fueron financiadas por los magnates John D. Rockefeller y Marcus Hanna

Las construcciones de rascacielos fueron posibles gracias a la invención del ascensor y al progreso de la siderurgia. La planta en tablero y la especulación de la propiedad de la tierra en los centros urbanos americanos no son extraños al éxito de este método de construcción. Por fin, la agrupación de las empresas y la competición capitalista incitan a la subida vertical de los edificios.

Es difícil decir cuál fue el primer rascacielos de la Historia. Los neoyorquinos afirman que es el "Nueva York Tribuna Building", diseñado por Richard Morris Hunt (1873, 78 metros). Otros consideran que es el "Hogar Insurance Edificio" (1884 - 1885) en Chicago construido por los miembros de la Escuela de Chicago: Louis Sullivan, William LeBaron Jenney, Daniel Burnham, William Holabird y Martin Roche. Propugnan un estilo sencillo y utilitario; algunos consideran que prefiguran el movimiento racionalista.

El edificio Woolworth de Nueva York, una obra del arquitecto Cass Gilbert (1913) es uno de los rascacielos neogóticos más conseguidos. Con sus 60 pisos, le sobrepasaba entonces la Metropolitan LIFE Tower. Las tres primeras plantas son de una bonita caliza sustituida en las siguientes por terracota. La tendencia neogótica impulsó al arquitecto que debió añadir falsos contrafuertes y gárgolas. Habida cuenta del gigantismo del edificio, los elementos decorativos fueron de gran tamaño a fin de ser visibles desde la calle. En Chicago, el proyecto de la sede del Diario Chicago Tribuna se otorga a Raymond Hood y John Mead Howells. Inaugurado en 1925, es uno de los edificios emblemáticos de la ciudad y parece una catedral laica notable.

Rápidamente, varios arquitectos estadounidenses (entre los cuales se encuentra Louis Sullivan…) criticaron esta nueva arquitectura vertical. La subida vertiginosa de los edificios impide a la luz alcanzar el suelo. El plano ortogonal implica una acumulación de la circulación. Existe el riesgo de uniformar el aspecto del centro de las ciudades. Por fin, surgen nuevos problemas de seguridad, en particular, en materia de incendios. A partir de 1916, para responder a estas dificultades se adopta en Nueva York una ley sobre la subdivisión en zonas (" Zoning Law"). El Reglamento obliga a los arquitectos a adaptar la altura de los edificios en función del tamaño de la parcela. Sigue estando en vigor hasta 1961. Eso da lugar a la construcción de edificios piramidales (últimos pisos más pequeños) como el Edificio Empire State, o incluso se construye solamentesobre una parte de la parcela, como el "Seagram Building" (Ludwig Mies Van der Rohe y Philip Johnson, 1958) que proporciona unadisminución de 28 metros con relación a Park Avenida, y propone un medio original de integración del rascacielos en la ciudad. Aún hoy, este derecho al cielo se regula mucho (Tiffany vendió su derecho a Trump, permitiendo la subida del Trump Building).

En 1904 Frank Lloyd Wright se interesa también por el problema de la luz, diseña el Edificio Larkin en Buffalo al que organiza alrededor de un gran patio central iluminado por arriba y al cual dan las puertas de cada piso. El edificio se abre hacia el interior y tiene una gran sala común en el centro. Al utilizar la piedra y el ladrillo y recortar planos horizontales, Wright rechaza la normalización del rascacielos.

La "Prairie School" inaugura el periodo de la arquitectura orgánica en Estados Unidos. Louis Sullivan y Frank Lloyd Wright se consideran como sus principales representantes. La primera gran casa de la "Prairie School" es la de Highland Park en Illinois, terminada en 1902 por Ward W. Willitts. Wright aboga por un plano centrado y asimétrico, organizado en torno a la chimenea. La casa es representativa de la idea de apertura a la naturaleza y de horizontalidad. La entrada es modesta y las habitaciones son bajas de techo: en su autobiografía (1932), Wright reconoce que las calibra tomando la talla de un hombre de 1,74 m. El ejemplo más logrado de la "Prairie School" es seguramente la casa Robie situada en Chicago (1906-1909) que recuerda un alargado buque trasatlántico.

Después de una estancia en Japón, Frank Lloyd Wright vuelve a Estados Unidos y pone a punto la técnica de los "textile blocks", es decir, que recurre a bloques de hormigón estandarizados. Ello da como resultado casas de aspecto sencillo y conciso, como la casa de Alice Millard en Pasadena (1923, California). Gracias al mecenazgo de Edgar J. Kaufmann, Wright continúa sus investigaciones y construye la célebre "Casa de la Cascada" en 1936. Explota las posibilidades del voladizo y de las ventanas de ángulo.

A finales de los años 1920, la influencia del art déco se hace sentir en la arquitectura estadounidense, mezclándose con las exigencias urbanísticas locales y las fuentes de inspiración precolombinas. El partido tomado por la simplificación geométrica, la estilización y el empleo de materiales lujosos está perfectamente ilustrado en los rascacielos de Nueva York (Chrysler Building, Empire State Building, Chanin Building, etc.). Las demás realizaciones están aisladas (Board of Trade Building, Fisher Building, 1928 y Guardian Building, 1929, Detroit) o situadas en la costa Oeste (Los Ángeles: Argyle Hotel, The Eastern Building, 1929, por Claude Beelman; San Francisco: Golden Gate Bridge, 1937).

A pesar de la crisis de Wall Street en 1929, los rascacielos se elevan sobre el suelo, a veces a una velocidad impresionante como en el caso del Empire State Building, calificado de maravilla del mundo moderno. El Rockefeller Center, enorme complejo situado en el corazón de Manhattan, marca la idea ambiciosa de construir una "ciudad en la ciudad" en una época más bien sombría. Para sostener este arranque y bajar el paro en el sector de la construcción, el presidente Roosevelt invierte en una serie de grandes obras públicas. El Art déco conoció un desarrollo singular en Florida: numerosos hoteles se construyeron en Miami Beach después del huracán de 1926. Los elementos decorativos en estuco y en mármol representan la fauna y la flora locales (flamencos rosas, palmeras...) por lo que se habla de una tendencia "Tropical Art Deco", que utiliza colores pastel. La comisión de los sitios históricos ha clasificado más de 800 de estas construcciones, exuberantes en ocasiones, que se concentran en "Lincoln Road Mall" y "Ocean Drive". El Art Déco de Florida se declinará en cuatro tendencias de los años 20 a los años 40: "Zig-zag modern", "Mediterranean revival", "Streamline moderne" y "Depression modern".

La expresión "International Style" (Estilo internacional) se utiliza por primera vez en 1932 en una obra de Henry-Russell Hitchcock y Philip Johnson, redactada tras una exposición del MoMA de Nueva York titulada "Arquitectura Moderna ". El auge de las dictaduras en Europa dejó a América la iniciativa de la difusión del modernismo arquitectónico acogiendo a los arquitectos europeos emigrados, en particular alemanes y austriacos. En 1933, la escuela de la Bauhaus cerró sus puertas en Alemania por la presión de los nazis, sus artistas perseguidos duramente, huyeron a menudo a los Estados Unidos, en particular, a Chicago, mientras que sistemáticamente se destruían sus obras en Alemania.

Tres normas básicas señalan la ruptura con la arquitectura tradicional: valorizar los volúmenes con superficies externas lisas; evitar todo elemento decorativo pero cuidar los detalles arquitectónicos; finalmente seguir el principio de regularidad. El Estilo internacional se presenta pues como una tendencia resueltamente modernista.

La sede de la ONU en Nueva York es el ejemplo más notable del estilo internacional después de 1945. Se construyó a lo largo del East River en un terreno adquirido gracias a una donación de John Davison Rockefeller Junior. Fue inaugurada el 9 de enero de 1951 y se convirtió en el símbolo del internacionalismo y el progreso.

Aplica la concepción de edificios separados según su función. El rascacielos que alberga el Secretariado de las Naciones Unidas llega a 164 metros y se presenta sobre dos caras como un muro cubierto de vidrio y aluminio, mientras que los otros lados están cubiertos con placas de mármol.

El período de la posguerra se caracteriza por las obras del finlandés Eero Saarinen cuyo eclecticismo se manifiesta en el auditorio Kresge del Massachusetts Institute of Technology (MIT - 1956), el arco de San Luis (1967) o también en su trabajo sobre las terminales de los aeropuertos de Nueva York y Washington DC. El alemán Walter Gropius enseña arquitectura en Harvard y construye con Pietro Belluschi el controvertido edificio de Pan Am en Nueva York (1963). Forma a los grandes arquitectos de la generación siguiente y funda con varios jóvenes arquitectos el estudio The Architects' Collaborative. Ludwig Mies Van der Rohe llega a Estados Unidos en 1937 y aplica sus conceptos del clasicismo modernista en Nueva York (edificio Seagram, 1958), Chicago (universidad en South Side). Es el arquitecto más fértil de todos.

La corriente modernista utilizó ampliamente el hormigón, dejándolo en estado bruto en varias obras de los años sesenta y 1970: el Carpenter Center for the Visual Artes en el campus de Harvard es el único edificio diseñado por Le Corbusier en los Estados Unidos. Los representantes más famosos de la tendencia brutalismo son Paul Rudolf, Marcel Breuer, Bertrand Goldberg y Louis Kahn.

Después de la Segunda Guerra Mundial, los años de crecimiento económico ven nacer el Pop Arte que influyó sobre las realizaciones arquitectónicas. Robert Venturi y Charles Willard Moore son arquitectos que se atreven a utilizar una decoración pintoresca y variada, en total contradicción con la austeridad del estilo internacional contemporáneo. La moda de "California Crazy", utilizada por James Wines, consiste en hacer de un objeto ordinario y diario una forma arquitectónica (un snack bar con forma de hamburguesa). Los parques de atracciones utilizan esta arquitectura del ocio, criticada como una arquitectura de fachada, vulgar y transitoria. Se encuentra esta tendencia colorista, chillona y excéntrica en Las Vegas.

Los años 1970 marcan un antes y un después en la arquitectura estadounidense, a causa de la crisis del petróleo y de la puesta en consideración de la herencia patrimonial. Se asiste a la crítica del estilo internacional y de su tendencia minimalista y austera. Numerosos arquitectos retoman los estilos Beaux-Arts y art déco.

Las obras maestras del postmodernismo son el "Lincoln Center" y la "Metropolitan Opera" (Nueva York, 1962-1966). La tendencia ecléctica se expresa en los campus universitarios como el de Yale (Gordon Wu Hall, 1980, Robert Venturi). Los rascacielos de Philip Johnson se alejan de la banalidad y de la tendencia a la uniformidad ("IDS Center" en Minneapolis). Este arquitecto intenta establecer códigos, referencias al pasado y elementos totalmente modernos. El "American Telephone and Telegraph Company" de Nueva York cuenta con un arco de entrada monumental en 8 niveles y una azotea en forma de frontón inacabado; ha sido fuertemente criticado.
Por último, los museos necesitan una renovación arquitectónica durante este periodo. Se piensa en primer lugar en el Solomon R. Guggenheim Museum. El "Metropolitan Museum of Art" se dota de nuevas alas encomendadas a John Dinkeloo y Kevin Roche, que utilizan grandes vidrieras (ala Sackler, por ejemplo). Edward Larrabee Barnes adopta un atrevido plano en hélice para el "Walker Art Center" de Minneapolis (1968-1971). También trabaja para el "Dallas Museum of Art" (1984) y el "Smart Museum of Art" de Chicago. Finalmente, Ieoh Ming Pei y Richard Meier marcan con su huella varios lugares culturales en los años 1980. Para la "National Gallery of Art", Pei yuxtapone los volúmenes. Richard Meier renueva el género Le Corbusier ("Getty Center" en Los Ángeles (1985-1997), "High Museum of Art" en Atlanta (1980-1983)).

Los otros grandes representantes del postmodernismo estadounidense son Charles Willard Moore, Stanley Tigerman, Wallace K. Harrison y Robert Venturi. Algunos tienen una carrera internacional.

Los atentados del 11 de septiembre de 2001 provocaron el comienzo de una reflexión sobre los rascacielos, su simbología y su seguridad. Aparecen nuevas exigencias ecológicas (arquitectura verde) y el uso de la informática transforma el modo de entender la arquitectura. En el contexto de la globalización, se tendría la tendencia a pensar que todas las megalópolis se parecen. Sin embargo, se asiste más bien a un aumento de la diversidad gracias a los nuevos materiales (acero tensado, estructuras-membrana) y a la osadía de los arquitectos. La arquitectura del lugar tiene en cuenta las condiciones ambientales (seísmos, frío...) e intenta utilizar paneles solares (caso de California). Hoy ve la luz una nueva generación de rascacielos "verdes" (""green buildings"") en las metrópolis estadounidenses: el estudio de arquitectura con sede en Chicago Skidmore, Owings and Merrill ha diseñado el inmueble 7 World Trade Center en Nueva York, que maximiza el uso de la luz natural y el empleo de materiales reciclados. El "US Green Building Council" (USGBC) es el órgano encargado de atribuir a un edificio la etiqueta de "construcción ecológica".

Finalmente, se invita a los arquitectos estadounidenses a reflexionar, con sus colegas urbanistas, sobre la revitalización de los centros de negocios y de los barrios intermedios degradados (creación de "lofts", rehabilitación del barrio de Harlem por Roberta Wash).

Los Estados Unidos tiene la suerte de no haber sido afectados por las destrucciones ocasionadas por las dos guerras mundiales. No han conocido los bombardeos y la destrucción de ciudades como Europa o Japón. Por el contrario, el territorio presenta riesgos naturales importantes para el patrimonio: seísmos en California, ciclones alrededor del golfo de México que son particularmente devastadores. Para proteger los edificios históricos de los apetitos especulativos y privados, el Estado federal se ha dotado de varias instituciones: al principio del siglo XX, los monumentos nacionales americanos se crean para proteger lugares naturales y también realizaciones arquitectónicas (poblados amerindios, fuertes de la época colonial, misiones españolas...); desde 1935, el Servicio de parques nacionales("National Park Service" en inglés) se encarga de listar los edificios, los monumentos o los barrios de interés histórico en los Estados Unidos.

Pero el movimiento de rehabilitación de edificios antiguos se desarrolla sobre todo a partir de los años 1970. Se protesta contra las operaciones de renovación urbana destructiva (estación de Pensilvania, demolida en 1965 y Singer Building destruido en 1968. En 1975, una campaña de opinión en la que participa Jackie Kennedy salva de la destrucción la estación Grand Central Terminal de New York, construida al principio del siglo XX. En 1998, los trabajos de restauración interior hicieron reaparecer el techo en forma de estrella del hall principal.

Con ocasión del bicentenario de la Declaración de Independencia (1976), el gobierno decide renovar la herencia urbana y local de la nación. Toma conciencia de defender el patrimonio más reciente: es así como el liceo de Little Rock fue registrado como lugar histórico protegido el 6 de noviembre de 1988 por su importancia en el movimiento de los derechos cívicos a finales de los años 1950. Con la desindustrialización, la rehabilitación de antiguos almacenes o fábricas se hizo muy activa. Hay una voluntad de adaptar una vieja estructura a los nuevos usos conservando siempre su interés histórico. En fin, las asociaciones tales como «Historic New England» están atentas a preservar y mantener el patrimonio local.

La enseñanza de la arquitectura en la primera mitad del siglo XIX permanece bajo la influencia de los métodos ingleses. Por otra parte, no existen aún lugares de formación especializada. Las agencias de arquitectura y sus bibliotecas hacen las veces de escuelas. Los sketching clubes dan cursos de noche en las grandes metrópolis. Se federan en 1891 para formar la Architectural League of America.

En 1865, los primeros cursos de arquitectura se dan en MIT bajo la tutela de William Robert Ware, luego en la Universidad de Columbia en 1881. El congreso del American Institute of Architecture (AIA) se reúne por primera vez en 1867. La sociedad de los arquitectos de las Bellas Artes ( Society of Bellas Artes architects) se crea en 1894. Es necesario esperar a 1903 para que un departamento de arquitectura abra en la costa occidental, en la Universidad de Berkeley. En 1905, la academia americana abre sus puertas a Roma. Esta enseñanza se abre lentamente a las minorías (el negro William Taylor sale número uno de su promoción al MTI en 1892) y a las mujeres. La arquitecta Julia Morgan es elegida por William Randolph Hearst para construir su residencia de San Simeon. Las revistas de arquitectura contribuyen a difundir el interés por esta disciplina:una de las primeras es American Architect and Building News en Boston en 1876. En San Francisco, se puede leer el Californian Architect and Building News' a partir de 1879. La influencia de la Escuela de las Bellas Artes de París sigue siendo preponderante y se forma a los arquitectos americanos allí. El Bellas Artes Institute of Design' se crea en 1916.

La academia Cranbrook, cerca de Detroit, formó arquitectos americanos en el siglo XX. Creada por George G. Booth, un magnate de la prensa, el proyecto se confió a Eliel Saarinen. Se construye a una escuela de muchachos entre 1926 y 1930; luego viene una escuela de muchachas (1929-1931) [23]. Con su hijo, construye el Cranbrook el Instituto de las ciencias (1936-1937) y la biblioteca de la academia (1938-1942), que se inspira en palacio de Tokio en París.

Las escuelas de arquitectura más prestigiosas de Estados Unidos son:







</doc>
<doc id="42874" url="https://es.wikipedia.org/wiki?curid=42874" title="Economía de los Estados Unidos">
Economía de los Estados Unidos

Estados Unidos es el país más rico, poderoso e influyente de la Tierra. Su PIB nominal, estimado en más de 20.5 billones de dólares en julio de 2019 (20.5 "trillons" en el sistema de medición anglosajón) representa aproximadamente 1/4 del PIB nominal mundial.
En conjunto, la Unión Europea tendría un PIB mayor, pero no está considerada como nación. El PIB en paridad de poder adquisitivo estadounidense representa 1/5 parte del PIB PPA mundial.
A su vez, Estados Unidos mantiene un alto nivel de producción y un PIB per cápita (PPP) de unos 53 042 dólares, el séptimo más alto del mundo, lo que hace en estos términos a Estados Unidos, una de las naciones más ricas del mundo.
Es también el mayor productor industrial del mundo,y el país comercial más grande del mundo, teniendo como principales socios comerciales a China, Canadá y México.

La economía de Estados Unidos hace de su moneda, el dólar estadunidense, y el idioma, el inglés, los medios de comunicación y de comercio a nivel mundial.

Estados Unidos es de economía capitalista de tipo mixto que ha logrado mantener una tasa de crecimiento global del PIB estable, un desempleo moderado y altos niveles en investigación e inversión de capital. Ha sido, sin contar los imperios coloniales, la economía nacional más grande del mundo desde la década de 1890.

Actualmente, la mayor parte de la economía se basa en el sector servicios, pero al contrario que la mayoría de países post-industriales, sigue manteniendo un importante y competitivo sector industrial, especializado en la alta tecnología y sectores punteros, representando un 20 % de la producción manufacturera mundial.
De las 500 empresas más grandes del mundo, 133 tienen su sede en Estados Unidos, el doble del total de cualquier otro país en el mundo. El mercado de trabajo en los Estados Unidos ha atraído a inmigrantes de todo el mundo y su tasa neta de migración se encuentra entre las más altas del mundo. Está considerado como el país con más facilidades para hacer negocio y está situado en 4º lugar en el Índice de Competitividad Global.

Su poderosa moneda, el dólar estadounidense, representa el 60 % de las reservas mundiales, mientras que el euro representa el 24 %. Posee el mayor mercado financiero y es un país que destaca por su influencia en cualquier decisión de tipo económico y político a nivel internacional. Las inversiones extranjeras se valoraron en 2011 en 2,4 billones de dólares, ostentando el primer lugar.
Las inversiones estadounidenses en países extranjeros totalizan 3,3 billones de dólares.
Al comienzo de 2012, su deuda pública y privada ascendían a 50,2 billones de dólares, más del triple de su PIB.
De estos 50,2 billones, casi 15 billones (más del 90 % del PIB) correspondía a la deuda pública. Desde 2010, la UE es su principal socio comercial en conjunto, por delante de Canadá, China y México, sus principales socios comerciales a nivel nacional.

En 2016, el 1 % de los estadounidenses detenían el 63 % de la riqueza del país según el Boston Consulting Group, y deberían continuar viendo esta proporción aumentar para sobrepasar el 70 % en 2021.

Según Philip G. Alston, el relator sobre pobreza extrema y derechos humanos de la ONU : "Su enorme riqueza y conocimiento contrastan de forma chocante con las condiciones en las que viven grandes cantidades de sus ciudadanos. Unos 40 millones viven en pobreza, 18,5 millones en pobreza extrema y 5,3 millones viven en condiciones de pobreza extrema propias del tercer mundo".

La gran diversidad de climas y suelos permite una agricultura con toda gama de productos propios de regiones templadas y subtropicales, dotadas de las más modernas técnicas agropecuarias, lo que convierte a Estados Unidos en uno de los mayores productores mundiales de una gran variedad de productos agropecuarios. La mayor parte de la superficie agrícola se destina al cultivo de los cereales (77,83 millones de hectáreas), entre los cuales se destacan el trigo (23,35 millones de ha, 12.5 % de la producción mundial) y el maíz (27,86 millones de ha y 40 % de la producción mundial). En ambos casos, Estados Unidos es el primer productor y exportador mundial.

Entre los cultivos industriales resalta el algodón (16 % de la producción mundial de semilla y 18,5 % de fibras, con 5,19 millones de ha y cuya producción está encabezada por los estados de Texas, California, Misisipi y Arizona); la soja (23,45 millones de ha y primer productor mundial), maní, tabaco, caña de azúcar y remolacha azucarera. En la producción de frutas y hortalizas, Estados Unidos ocupa los primeros lugares en casi todos los productos, entre los que destacan manzanas, melocotones, cítricos (naranjas, pomelos y limones), uvas, tomates, papas y cebollas. California y Florida son los primeros estados hortofrutícolas.

Los datos estadísticos de la producción en el medio agrario de los EE. UU. son recogidos por el Departamento de Agricultura de los Estados Unidos, en adelante USDA por sus siglas en inglés. 

Según un estudio de la ONG británica Oxfam, publicado en 2016, la gran mayoría de los 250.000 trabajadores del sector agrícola se ven privados del derecho a usar el retrete para aumentar su productividad. Muchos de ellos se ven obligados a usar pañales para trabajar en sus empresas y "reducir su ingesta de líquidos y líquidos a niveles peligrosos". Para la ONG, esto es un deterioro de la condición humana de los empleados que ya "ganan salarios bajos y sufren altos índices de lesiones y enfermedades".

Estados Unidos ocupa el tercer lugar en producción, detrás de China y la India. Casi todo el crecimiento y la producción de fibra de algodón se produce en los estados del sur y el oeste, destacando Texas, California, Arizona, Misisipi, Arkansas y Luisiana. Más del 99 por ciento del algodón cultivado en los Estados Unidos es de la variedad "Upland", y el resto es "American Pima". La producción de algodón es una industria de 25 mil millones de dólares por año, empleando a más de 200.000 personas en total. La estimación final de la producción de algodón de EE. UU. fue en 2012 de 17.31 millones de pacas, con las cifras correspondientes para China e India de 35 millones y 26.5 millones de pacas, respectivamente.

Cuatro de los cinco principales importadores de algodón producido en los EE. UU. se encuentran en América del Norte; el principal destino es Honduras, con alrededor del 33 % del total, aunque ha disminuido ligeramente en los últimos años. El siguiente importador más importante es México, con alrededor del 18 %, una cifra que ha sido ampliamente estable, y luego la República Dominicana, aunque las exportaciones han disminuido como una proporción del total en los últimos años. China importó alrededor del 11 % del algodón de los EE. UU. El año pasado, lo que representó un fuerte aumento con respecto a temporadas anteriores, lo que le permitió superar a El Salvador, que ha importado consistentemente alrededor del 8-9% del total. Las exportaciones de algodón a China crecieron de 46 millones de dólares en 2000 a más de 2 mil millones en 2010.

Los Estados Unidos, Brasil y Argentina son los productores de soja más grandes del mundo y representan más del 80 % de la producción mundial de soja (tabla)..

En la ronda Dillon 1960 del Acuerdo General sobre Aranceles Aduaneros y Comercio (GATT), los Estados Unidos garantizaron el acceso libre de aranceles para su soja al mercado europeo. En la década de 1960, Estados Unidos exportó más del 90 % de la soja del mundo. En 2005, los principales exportadores de soja fueron Argentina (39 % de las exportaciones mundiales de soja), Estados Unidos (37 %) y Brasil (16 %), mientras que los principales importadores fueron China (41 % de las importaciones mundiales de soja), Unión Europea (22 % ), Japón (6 %) y México (6 %).

Antes de los años 20 del siglo XX, la soja era principalmente un cultivo forrajero en los EE. UU., una fuente de aceite, harina (para piensos) y productos industriales, con muy poco uso como alimento humano. Sin embargo, asumió un papel importante después de la Primera Guerra Mundial. Durante la Gran Depresión, las regiones afectadas por la sequía ("Dust Bowl") de los Estados Unidos pudieron usar soja para regenerar su suelo debido a sus propiedades fijadoras de nitrógeno. Las granjas estaban aumentando la producción para satisfacer las demandas del gobierno, y Henry Ford se convirtió en un promotor de la soja. En 1931, Ford contrató a los químicos Robert Boyer y Frank Calvert para producir seda artificial. Tuvieron éxito en hacer una fibra textil de fibras de proteína de soja hiladas, endurecidas o curtidas en un baño de formaldehído, que recibió el nombre de "Azlon". Nunca llegó al mercado comercial. El aceite de soja se utilizó para pintar los automóviles, así como el líquido para los amortiguadores. 

El tofu se introdujo en los campos de internamiento japoneses estadounidenses durante la Segunda Guerra Mundial, y gradualmente se extendió a la cocina convencional. Se desarrollaron nuevas variedades para mejorar la suavidad del aceite de soja. La contracultura en la región de San Francisco populariza los alimentos de soja. Aunque prácticamente no se pudo ver en 1900, en 2000 cubrieron más de 70 millones de acres, solo superado por el maíz, y se convirtió en el cultivo comercial más grande de Estados Unidos.

En abril de 2018 China, en pleno conflicto comercial con los EE. UU., anunció subida de aranceles para las importaciones de soja de los EE. UU.

Estados Unidos ocupa un lugar relevante en el cultivo de trigo. Ocupa la quinta posición a nivel mundial y el primer exportador. De acuerdo con los datos del USDA, los cinco principales productores de trigo, entre los que se encontraría los EE. UU., cosechan el 70 % del total mundial. Este total se aproxima a las 740 millones de toneladas, de los que EE. UU. produce 62,8 millones. Los EE. UU. cultivan dos variedades de trigo en función de la estación, invierno o primavera, dureza (duro o blando) o color (rojo o blanco). Los cinco principales estados productores en 2016 fueron: Kansas, con 62.858 toneladas, Dakota del Norte, con 12.720, Montana, con 5.788, Oklahoma, con 3.715 y Texas, con 2.438.

El cultivo de maíz se desarrolla principalmente en dos zonas: El “Medio Oeste Estadounidense” (o "Midwest" en inglés) y las planicies (o «Grandes Llanuras») que van de norte a sur destacando Dakota del Norte, Dakota del Sur, Nebraska y Kansas. La suma de estos estados se pueden denominar "Corn Belt" o «Cinturón Maicero». Los cinco principales estados productores en 2016 fueron: Iowa, con 69 millones de toneladas, Illinois, con 57 millones, Nebraska, con 43 millones, Minesota, con 39 millones, e Indiana, con 24 millones.

Los EE. UU. son los segundos productores mundiales de manzana después de China y por delante de Polonia. Los tres Estados con mayor producción son Washington, Nueva York y Míchigan. La temporada de cosecha se produce en agosto en el norte y en septiembre en el este y el oeste.

Igualmente, la ganadería de Estados Unidos es la primera del mundo no por el número de cabezas, sí no, por el elevado rendimiento obtenido en productos alimentarios y por la equilibrada integración existente entre la agricultura y la ganadería. Las principales cabañas son la vacuna, porcina y bovina. Estados Unidos es el primer productor mundial de carne, leche, mantequillas y huevos. 

En 2016 aumentó en un 2 % el censo de ganado vacuno de los EE. UU. contando a comienzos de ese año con 93,6 millones de cabezas. El ganado destinado a la producción de carne alcanza los 31,2 millones, con un incremento del 3 %. Las proyecciones para la ganadería bovina entre los años 2018-2026 son al alza, con un aumento del 12 % para la segunda fecha. Se espera un aumento continuado anual del 1 % para la producción de carne, con lo que se pasaría de 11,25 millones de toneladas en 2016 a 12,6 en 2026. Si se cumplen estas estimaciones, el país mantendrá su posición como cuarto exportador mundial, tras Australia, India, y Brasil.

En enero de 2016, el número de ovejas era de 5,3 millones. La "American Sheep Industry Association" publicó su Estudio de Impacto Económico 2017, que muestra que los 88,000 productores ovinos del país generaron volumen económico total de 5,8 mil millones de dólares en 2016.

La cabaña porcina llegó el 1 de diciembre de 2017 las 73,2 millones de cabezas, de acuerdo con el USDA. Este valor es un 2% más alto que la de finales de 2016 y la más alta desde la última década. El remonte de los precios, así como el aumento de las exportaciones de EE. UU. han favorecido el incremento de producción. La producción de carne de cerdo sería la que registraría mayor crecimiento, según las proyecciones para los años 2018-2026, alrededor de un 1,3 % anual. Se espera que crezca por un lado la demanda interna y las exportaciones gracias a la mayor competitividad del porcino estadounidense.

De acuerdo con el USDA, la Producción mundial de carne de pollo siguió creciendo en 2017 y superará los 90 millones de toneladas en 2018. Según proyecciones para los años 2018-2026, el crecimiento de la producción de carne de pollo y pavo asistirá a una desaceleración con un crecimiento inferior al 1 %, con el consiguiente aumento de los precios. EE. UU. se mantendrá como segundo mayor exportador del mundo de carne de ave tras Brasil.

La pesca tiene una importancia relativa para la economía estadounidense (6 % de las capturas mundiales) y las especies más destacadas en este rubro son salmón, atún, fletan, arenque y bonito.

Al igual que con otros países, la zona económica exclusiva (ZEE) de 200 millas náuticas (370 km) frente a las costas de los Estados Unidos confiere a su industria pesquera derechos especiales de pesca. Cubre 11.4 millones de kilómetros cuadrados (4.38 millones de millas cuadradas), siendo la zona más grande del mundo, excediendo el área terrestre de los Estados Unidos.

Según la FAO, en 2005 los Estados Unidos recolectaron 4.888.621 toneladas de pescado de las pesquerías silvestres y otras 471.958 toneladas de la acuicultura. Esto convirtió a los Estados Unidos en el quinto productor de pescado después de China, Perú, India e Indonesia, con un 3.8 por ciento del total mundial.

En la actualidad, las pesquerías continentales y las pesquerías cerca de la costa son administradas por comisiones de pesca estatales (o regionales o de condado). Las jurisdicciones estatales generalmente se extienden 3 millas náuticas (6 km) hacia el mar. Las pesquerías costeras en la ZEE más allá de las jurisdicciones estatales son responsabilidad del sistema federal. Las principales instituciones del sistema federal son ocho consejos regionales de gestión pesquera y el Servicio Nacional de Pesca Marina (NMFS), también conocido como Pesquerías NOAA.

El NMFS trabaja en asociación con los consejos regionales de gestión pesquera para evitar la sobrepesca y restablecer las poblaciones sobreexplotadas. Los objetivos son reducir la intensidad de la pesca, controlar las pesquerías e implementar medidas para reducir capturas accidentales y proteger el hábitat de la reserva marina.

El valor de los productos acuícolas aumentó de 45 millones de dólares en 1974 a aproximadamente 866 millones (de un total de 393,400 toneladas) en 2003.

La acuicultura, en los Estados Unidos, incluye el cultivo de peces y crustáceos que crecen hasta alcanzar el tamaño de mercado en estanques, tanques, jaulas o canales y se liberan en la naturaleza. La acuicultura también se utiliza para apoyar la pesca marina comercial y recreativa mejorando o reconstruyendo poblaciones de poblaciones silvestres. También incluye el cultivo de peces ornamentales para el comercio de acuarios, así como especies de plantas utilizadas en diversos productos farmacéuticos, nutricionales y biotecnológicos.

Según la FAO, en 2004 Estados Unidos ocupó el décimo lugar en producción acuícola total, detrás de China, India, Vietnam, Tailandia, Indonesia, Bangladesh, Japón, Chile y Noruega. Estados Unidos importa productos acuícolas de estos y otros países y opera un déficit comercial anual de productos del mar de más de 9 mil millones de dólares.

La producción acuícola total de EE. UU., incluidas las plantas acuáticas, es de aproximadamente 1 mil millones de dólares anuales, en comparación con la producción mundial total de aproximadamente 70 mil millones. Solo alrededor del 20% de la producción acuícola de los EE. UU. proviene de especies marinas. La NOAA estima que la producción acuícola doméstica anual de todas las especies de EE. UU. podría aumentar de alrededor de 0.5 millones de toneladas a 1.5 millones de toneladas para el año 2025.

La superficie forestal ocupa un tercio del territorio y se localiza en mayor extensión en los Apalaches, las Montañas Rocosas y la Sierra Nevada. Las especies arbóreas más abundantes son los pinos y los abetos. En la actualidad, los EE.UU destinan alrededor de 290 millones de hectáreas a actividades forestales siendo una tercera parte de esta superficie protegida. Cada año se plantan alrededor de mil millones de árboles con fines comerciales.

En la actualidad existe una importante economía maderera en los EE. UU., que emplea directamente a unas 500,000 personas en tres industrias: explotación maderera, aserradero y panel.

La producción anual en los EE. UU. es de más de 9.144.000.000 millones de tablas, convirtiendo a los EE. UU. en el mayor productor y consumidor de madera. A pesar de los avances en la tecnología y la conciencia de la seguridad, la industria maderera sigue siendo una de las industrias más peligrosas del mundo. 

Si bien existen desafíos en el mercado actual, los EE. UU. siguen siendo el segundo mayor exportador de madera en el mundo. Sus principales mercados son Japón, México, Alemania y el Reino Unido. Debido a los mayores costos de mano de obra en el país, es una práctica común exportar las materias primas, convertirlas en productos terminados e importarlas nuevamente a los Estados Unidos. Por esta razón, se exportan más productos crudos, incluidos troncos y astillas de madera para pasta, que importados, mientras que los productos acabados como madera aserrada, madera contrachapada y chapa, y productos de paneles tienen mayores importaciones que exportaciones.

Su mayor riqueza se centra en el subsuelo: Estados Unidos posee un tercio de las reservas mundiales de carbón (más de 240 000 millones de tm), produciendo el 22 % del carbón consumido a nivel mundial. Las principales cuencas están en los Grandes Lagos, vertiente occidental de los Apalaches (desde Pensilvania hasta Alabama), sector oriental de las Rocosas y en las llanuras centrales. El petróleo es abundante: los estados petroleros por excelencia son Texas (30 % de la producción nacional), Luisiana (15 %), Alaska (20 %) y California (13 %). La capacidad de refinamiento es de 15 000 millones de barriles diarios y sus reservas están calculadas en 22 300 millones de barriles (130 más grandes del mundo). Junto a las zonas petroleras hay ricos yacimientos de gas natural, principalmente en Texas y Luisiana. El uranio, del cual es el quinto productor mundial, sirve para abastecer a las 105 centrales nucleares del país.
Estados Unidos ocupa el primer lugar en la producción de carbón, uranio, molibdeno, fosfatos, magnesio, plata, oro, platino, aluminio y lugares destacados en la producción de otros (hierro, plomo, zinc, mercurio, wolframio, amianto, cadmio, entre otros). A pesar de extraer el 25 % de los minerales en el mundo, es importador neto de muchos otros tales como bauxita, estaño, manganeso, cobalto, cromo, níquel, titanio y vanadio.

Principales elementos explotados en la minería de los EE. UU. en 2015 

La extracción de carbón en los Estados Unidos es una industria en transición. La producción en 2016 cayó un 37 % desde la producción máxima de 1,162.7 millones de toneladas en 2006. El empleo de 50,000 mineros de carbón bajó desde un máximo de 883,000 en 1923. La generación de electricidad es el mayor destino del carbón y se utiliza para producir el 50 % de la energía eléctrica en 2005 y el 30 % en 2016: 1 El país es un exportador neto de carbón. Las exportaciones de carbón de EE. UU., para las cuales Europa es el cliente más grande, alcanzaron su punto máximo en 2012, y han disminuido desde entonces. En 2015, EE. UU. exportó 7.0 por ciento de carbón extraído.

El carbón sigue siendo un factor importante en los 25 estados en los que se extrae. Según la Administración de Información de Energía (EIA) de EE. UU., en 2015 Wyoming, West Virginia, Kentucky, Illinois y Pensilvania produjeron aproximadamente 639 millones de toneladas, que representan el 71 % de la producción total de carbón de EE. UU..

El carbón más duro, la antracita, originalmente utilizado para la producción de acero, la calefacción y como combustible para barcos y ferrocarriles, en el año 2000 se redujo a una porción insignificante de la producción. El carbón bituminoso más blando reemplazó al antracita para la producción de acero. Los carbones sub-bituminosos y lignitos aún más blandos superaron a los bituminosos en la década 2000-2009.

El sector afronta en la actualidad diversos problemas de solvencia. En 2015, cuatro compañías de carbón estadounidenses que cotizan en bolsa solicitaron la protección por bancarrota del Capítulo 11, incluida "Patriot Coal Corporation" y "Walter Energy". En enero de 2016, más del 25 % de la producción de carbón estaba en bancarrota en los EE. UU. incluidos los dos principales productores, "Peabody Energy" y "Arch Coal"
. Cuando "Arch Coal" solicitó la protección por bancarrota, el precio del carbón había caído un 50 % desde 2011 y tenía una deuda de 4.500 millones de dólares. El 5 de octubre de 2016, "Arch Coal" surgió de la protección contra quiebra del Capítulo 11.

La extracción de cobre en los EE. UU. ha sido una industria importante desde el surgimiento del distrito cuprífero del norte de Míchigan en la década de 1840. En 2014, Estados Unidos produjo 1,37 millones de toneladas métricas de cobre, con un valor de 9.700 millones de dólares, lo que la convierte en el cuarto mayor productor de cobre del mundo, después de Chile, China y Perú. El cobre se produjo a partir de 27 minas en los EE. UU. los principales estados productores de cobre en 2014 fueron (en orden descendente) Arizona, Utah, Nuevo México, Nevada y Montana. La producción menor también provino de Idaho y Misuri. A partir de 2014, EE. UU. tenía 35 millones de toneladas de reservas remanentes conocidas de cobre, la quinta mayor reserva de cobre conocida en el mundo, después de Chile, Australia, Perú y México.

El cobre en los Estados Unidos se utiliza principalmente en la construcción (43 %) y equipos eléctricos (19 %). En 2014, la nación produjo el 69 % del cobre que usaba, dependiendo de las importaciones de Chile, Canadá, Perú y México para el 31 % restante. La actividad de la minería del cobre aumentó a principios de la década de 2000 debido al aumento continuado en el precio. En 2013, la minería del cobre estadounidense produjo 28.500 toneladas métricas de molibdeno, por un valor de entre 700 y 800 millones de dólares, que representaron el 47 % de la producción total de los EE. UU.. En 2014, la extracción de cobre produjo alrededor de 15 toneladas métricas de oro, por un valor de 600 millones de dólares, lo que representó el 7 % de la producción de oro de los Estados Unidos. Otros subproductos del proceso de extracción de cobre incluyeron plata y cantidades menores de renio y metales del grupo del platino. El ácido sulfúrico se recupera en los fundidores de cobre.

La producción de oro de los EE. UU. aumentó enormemente durante la década de 1980, debido a los altos precios del oro y al uso de lixiviación en pilas para recuperar oro de depósitos diseminados de baja ley en Nevada y otros estados. En 2016, Estados Unidos produjo 209 toneladas de oro, valuadas en alrededor de 8.500 millones de dólares estadounidenses, y el 6,7 % de la producción mundial, por lo que es la cuarta nación productora de oro, detrás de China, Australia y Rusia. La mayoría del oro producido hoy en los Estados Unidos proviene de grandes minas de lixiviación en pilas a cielo abierto en el estado de Nevada. Estados Unidos es un exportador neto de oro.

La extracción de hierro en los Estados Unidos produjo 42,5 millones de toneladas métricas de mineral en 2015, por valor de 3.800 millones de dólares. El mineral de hierro fue el tercer metal de mayor valor extraído en Estados Unidos, después del oro y el cobre. El mineral de hierro fue extraído de nueve minas activas y tres operaciones de recuperación en Míchigan, Minesota y Utah. La mayor parte del mineral de hierro se extraía en la Cordillera Mesabi del norte de Minesota. Las exportaciones netas (exportaciones menos importaciones) fueron de 3,9 millones de toneladas. El mineral de hierro de EE. UU. representó el 2.5 % del total extraído en todo el mundo en 2015. El empleo a partir de 2014 fue de 5.750 en las minas de hierro y las plantas de tratamiento. La minería de hierro de los EE. UU. está dominada por los depósitos de formación de hierro con bandas precámbricas alrededor del Lago Superior, en Minesota y Míchigan; tales depósitos también fueron extraídos en Wisconsin. Durante los últimos 50 años, más del 90 % de la producción de mineral de hierro de EE. UU. se extrajo de los depósitos del Lago Superior.

La industria aporta el 20.3 % del PIB. Se distinguen tres grandes regiones industriales con características diferenciadas.

En el Noreste se encuentra la más potente y dinámica del mundo, que se extiende desde el Lago Erie hasta el océano Atlántico y donde se encuentra la mayor parte de la industria pesada del país. La región de Pittsburg es el núcleo principal de la siderurgia, con una producción y consumo de aluminio que tiende a sustituir al acero. En la región de sureste se encuentra la segunda gran región industrial, donde existe una considerable dispersión de los centros de fabricación. Las explotaciones mineras (hulla en los Apalaches meridionales y hierro en Alabama) y la industria ligera se han visto acompañadas en los últimos años por importantes instalaciones petroquímicas y metalúrgicas (Texas), así como por el desarrollo de numerosas empresas de material electrónico, impulsadas a raíz de las estaciones aeroespaciales como las de Houston y cabo Cañaveral en Florida.
La región industrial del oeste ha experimentado un impulso económico en los últimos 50 años hasta convertirse en uno de los polos de desarrollo de la economía nacional y mundial. Especial importancia tiene la aeronáutica (fábricas Boeing) y la fabricación de misiles, así como numerosas empresas de material electrónico e informático (Facebook, Google, Android, Microsoft, HP entre otras). La importancia de la industria estadounidense puede apreciarse por el lugar que ocupan sus empresas, entre las más importantes del mundo. De las 12 primeras, 5 son estadounidenses. El grupo más destacado es el de la industria informática y del refinado del petróleo (Exxon Mobil, Texaco, Chevron), seguido de las empresas automovilísticas (General Motors, Ford Motor Company).
En 2014, la industria del hierro y el acero en los Estados Unidos fue el tercer productor mundial de acero en bruto (después de China y Japón) y el sexto mayor productor de arrabio. La industria produjo 29 millones de toneladas métricas de arrabio y 88 millones de toneladas de acero. La mayoría del hierro y el acero en los Estados Unidos ahora está hecho de chatarra de esos mismos metales, en lugar de mineral de hierro. Los Estados Unidos también son un importante importador de hierro y acero, así como de productos siderúrgicos. El empleo del sector en 2014 fue de 149,000 personas, y 69,000 en fundiciones. El valor del hierro y el acero producido en 2014 fue de 113 mil millones de dólares. En el año 2015, las principales siderúrgicas de los Estados Unidos incluyeron: "AK Steel", "Carpenter Technology", "Commercial Metals Company", "Nucor", "Steel Dynamics" y "U.S. Steel".

La refinación de petróleo en los EE. UU. en 2013 produjo 18.9 millones de barriles por día de productos refinados de petróleo, más que cualquier otro país. Aunque EE. UU. era el mayor importador neto mundial de productos de petróleo refinado tan recientemente como 2008, el país se convirtió en un exportador neto en 2010, y en 2014 fue el mayor exportador y el mayor exportador neto de petróleo refinado. A fecha de enero de 2015, había 137 refinerías en operación en los Estados Unidos, distribuidas en 30 estados.

La mayoría de las grandes refinerías están cerca de vías navegables, especialmente puertos marítimos o puertos de los Grandes Lagos. La mayor concentración de refinerías se encuentra a lo largo de la costa del Golfo. Aunque hay refinerías en 30 estados, solo tres estados dominan la refinación estadounidense: Texas (47 refinerías), Luisiana (19) y California (18). Desde enero de 2015, estos tres estados contienen el 45 % de todas las refinerías y el 59 % de toda la capacidad de refinación del país.
La industria automotriz en los EE. UU. comenzó en la década de 1890 y, como resultado del tamaño del mercado interno y el uso de la producción en masa, rápidamente se convirtió en la más grande del mundo. Sin embargo, el país fue superado como el mayor productor de automóviles por Japón en la década de 1980, y posteriormente por China en 2008. Los EE. UU. son actualmente el segundo fabricante más grande del mundo en volumen, con aproximadamente 8-10 millones fabricados anualmente. Excepciones notables fueron 5,7 millones de automóviles fabricados en 2009 (debido a la crisis), y los niveles máximos de producción de 8-13 millones de unidades durante la década de 1970 y principios de 2000.

La industria de vehículos de motor comenzó con cientos de fabricantes, pero a fines de la década de 1920 estuvo dominada por tres grandes compañías: General Motors, Ford y Chrysler, todas con sede en el área metropolitana de Detroit. Después de la Gran Depresión y la Segunda Guerra Mundial, estas compañías continuaron prosperando, y Estados Unidos produjo casi tres cuartas partes de todos los automóviles en el mundo en 1950 (8,005,859 de 10,577,426). Comenzando en la década de 1970, una combinación de altos precios del petróleo y una mayor competencia de fabricantes de automóviles extranjeros afectó severamente a las empresas. En los años siguientes, las empresas se recuperaron periódicamente, pero en 2008 la industria estaba en crisis debido a la crisis antes mencionada. Como resultado, General Motors y Chrysler solicitaron una reorganización por bancarrota y fueron rescatados con préstamos e inversiones del gobierno federal. 

Antes de la década de 1980, la mayoría de las instalaciones de fabricación eran propiedad de Big Three (GM, Ford, Chrysler) y AMC. Su participación en el mercado de los EE. UU. ha disminuido constantemente a medida que numerosas compañías de automóviles de propiedad extranjera construyen fábricas en los EE. UU. En 2012, lo que significa una nómina total de aproximadamente 2,100 millones de dólares, en comparación con los 80,000 empleados estadounidenses de Ford que suministran sus 3,300 concesionarios. y los 71.100 empleados estadounidenses de Chrysler que suministran sus 2.328 concesionarios.

Estados Unidos dispone de una red de transporte bastante desarrollada. Los ferrocarriles estadounidenses no están nacionalizados, sino que pertenecen a compañías privadas (más de 350). La red ferroviaria cuenta ya con 278 245 km, las principales vías son las transcontinentales tales como Central Pacific, Northern Pacific y Southern Pacific. La red de carreteras es de 6 546 799 km y el número de vehículos que transitan por ellas se aproxima a los 200 millones (de ellos, 150 millones son automóviles de turismo). El transporte por ferrocarril domina el movimiento de distribución de mercancías (37,5 % del total de Estados Unidos), mientras que las carreteras absorben el 82 % del tráfico de pasajeros. Los principales puertos son los de Nueva York, Nueva Orleans, Boston, Houston, Baton Rouge, Filadelfia, Tampa, Norfolk y Baltimore. Los puertos lacustres más grandes son los de Duluth, Detroit, Chicago y Cleveland. El tráfico aéreo es muy intenso debido a las enormes distancias del país y la gran movilidad del estadounidense para buscar trabajo, aunado a las elevadas condiciones de vida del país. Los principales centros aéreos son Atlanta y Memphis, seguidos por Nueva York (que cuenta con 4 aeropuertos), Chicago, Los Ángeles, Dallas, Denver, Miami y San Francisco.

El sector servicios genera el 75 % del PIB y ocupa al 68 % de la población activa. Las actividades más importantes son la banca, seguros, enseñanza, investigación, transportes, comercio y turismo.

El sistema bancario estadounidense es el más importante del mundo. Es el más extenso y el más complejo (existen 12 tipos distintos de entidades bancarias), cuya regulación es establecida por el National Bank Act (1864) y completada por la Reserva Federal. El Sistema de Reserva Federal ejerce las funciones de Banco central (emisión de moneda, control del crédito y políticas monetarias). Existen además, otros 12 bancos regionales de la Reserva Federal con funciones de banco central dentro de su distrito. La dirección del sistema corre a cargo de la Junta de Gobernadores.

La proyección extranjera de la banca estadounidense aumento a partir de la Segunda Guerra Mundial hasta llegar a dominar más del 50 % del sistema financiero mundial. Entre los principales bancos cabe destacar los siguientes: Bank of America, JPMorgan Chase, Citigroup, Wells Fargo, entre otros. No obstante, la crisis económica del 2008 obligó al Estado a intervenir económicamente para generar salvatajes de los principales bancos (y empresas) del país, valorados en más de 750 000 millones de dólares.

Fuente

Para la economía estadounidense, el comercio exterior tiene un peso inferior al de otros países desarrollados. Las exportaciones representan el 8.5 % del PIB (el porcentaje más bajo dentro del conjunto de los países de la OCDE). Los transformados metálicos y la maquinaria industrial de todo tipo, junto con los productos agrícolas, forestales y minerales son las principales partidas de exportación, mientras que las importaciones (11 % del PIB) se hallan muy diversificadas, figurando a la cabeza las materias primas y los combustibles fósiles.

Hasta el día de hoy no existe un país que haya sobrepasado los patrones económicos generales de los Estados Unidos. El PIB de Estados Unidos es tres veces más grandes que el PIB de la tercera mayor economía del mundo, Japón, con $ 16 billones, según el FMI. El ingreso medio de las familias de este país en 2008 fue de aproximadamente 49 500 dólares. Al jubilarse, la mayoría de los trabajadores recibe pagos de seguro social más otras remuneraciones de planes privados de pensiones, además de los beneficios de sus bonos personales. Sin embargo, el 9,2 % de la población vivía por debajo de la punto establecido por el gobierno federal, que en 2008 era un ingreso de menos de 28 500 dólares anuales para una familia de cuatro personas. Las familias con ingreso menor a 28 000 reciben servicio de salud gratuito llamado Medicaid, además de diferentes beneficios, como alimentación para mujeres embarazadas, etc.

Desde la Segunda Guerra Mundial, se han incrementado la práctica de comprar bienes y servicios a crédito. Las compras importantes, como casas, coches y aparatos eléctricos, se pagan a plazos mensuales. Muchos estadounidenses también tienen tarjetas de crédito que les permiten comprar desde ropa hasta pasajes de avión a crédito, y pagar después de un tiempo conforme a una sola cuenta enviada por la compañía acreedora, que generalmente es un banco. Normalmente, el tiempo concedido para pagar es de un mes. Después se cobran intereses.

En 1994, Estados Unidos tenía cerca de 11 060 bancos con más de 70 000 oficinas, de las cuales casi 41 000 pertenecían al sistema operado por la Junta de la Reserva Federal. A través de sus bancos asociados, la Reserva Federal emite dinero, actúa como banco de liquidación financiera y establece las reservas de efectivo que los bancos deben mantener. Al aumentar y reducir estos requerimientos de reservas, y al cambiar la tasa de interés para préstamos a los bancos de los 12 bancos regionales de la Reserva Federal, la Junta de la Reserva Federal puede regular la oferta de dinero y, por ende, tratar de controlar la tasa de inflación de la economía.

Los ahorros individuales por lo general se depositan en cuentas que pagan interés en varios tipos de instituciones bancarias, en asociaciones de ahorro y préstamo, y en cooperativas de crédito creadas por grupos de empleados. Los estadounidenses también tienen la opción de colocar parte de su dinero en títulos de ahorro y certificados de tesorería emitidos por el gobierno federal, o en sociedades inversionistas privadas que invierten el dinero en el mercado de valores.

Casi todos los bancos privados y las instituciones de ahorro cuentan con un seguro proporcionado por el gobierno federal para proteger las cuentas de ahorro individuales hasta por US$100.000. La mayor parte del dinero depositado en las cuentas de ahorro es usado por los bancos para financiar la compra o construcción de casas y edificios.

No todas las personas que inician negocios sueñan con sociedades mercantiles enormes, multimillonarias y con ventas a nivel internacional. Hay muchos que sólo quieren vender bienes tales como frutas y verduras, aparatos domésticos, ropa, u ordenadores, para poder ser "sus propios jefes". Estas pequeñas empresas son parte importante de la economía. Muchas de ellas proporcionan bienes y servicios necesarios en barrios urbanos, en poblaciones pequeñas o en zonas rurales donde las grandes compañías tal vez no prestan un servicio adecuado.

En 1993, más de 700 000 empresas de este tipo iniciaron sus negocios en los Estados Unidos. Muchas cadenas grandes de tiendas empezaron con un solo establecimiento. Ese es el tipo de éxito que puede encontrarse a través de la historia de Estados Unidos.

La compañía Coca-Cola, que distribuye su gaseosa en el mundo entero, empezó cuando un farmacéutico mezcló la primera Coca-Cola y comenzó a venderla en la ciudad de Atlanta, Georgia.

Una de las compañías de alimentos más famosas de los Estados Unidos es la H. J. Heinz Co., que se especializa en encurtidos, mostaza, y salsa de tomate. Se inició cuando un adolescente empezó a vender diversos artículos comestibles de puerta en puerta y por la calle.

Antes de que un joven inventor llamado George Eastman se diera a conocer en los años 1880, las cámaras eran muy difíciles de usar y sólo un experto podía manejarlas bien. Las fotografías se hacían sobre láminas de vídeo y el equipo era muy difícil de transportar. Eastman inventó un nuevo tipo de película que era flexible y podía colocarse en un carrete. También fabricó una cámara que usara su película. Empezando en una oficina pequeña, fundó la ya enorme compañía Eastman Kodak y abrió el camino para las innumerables compañías fotográficas que existen hoy.

Los pantalones vaqueros que todos los adolescentes del mundo conocen, fueron inventados por un vendedor de telas pobre que vendió los primeros pares a los mineros en California en los años 1850. Su compañía, Levi Strauss, sigue siendo una de las mayores fabricantes de ropa estadounidenses.

Las muchas leyes y reglamentos del capitalismo estadounidense moderno no han impedido que personas con ideas y sueños inicien empresas nuevas. Un ejemplo de los años setenta es el de dos jóvenes que pensaron que podían construir una computadora nueva y mejor. Trabajaron durante meses en la fabricación de la máquina, y después empezaron a reunir dinero para financiar su producción a gran escala. Uno de ellos vendió su automóvil para obtener el capital necesario. En 1977 abrieron una compañía a la que llamaron "Apple Computer Corporation". Para finales de 1984, esa compañía era una de las mayores fabricantes de computadoras de los Estados Unidos, con un personal de cerca de 4500 trabajadores.

Historias como esta son las que crean una imagen de los Estados Unidos como lugar donde una persona puede pasar de la miseria a la riqueza, y mucha gente lo ha hecho. Sin embargo, otros han fracasado y otros más no han querido arriesgarse a ser dueños de sus propios negocios.

Uno de los cambios más importantes de las últimas décadas ha sido el paso de la producción de bienes a la prestación de servicios como característica dominante de la economía estadounidense. Mientras que antes la mayoría de los trabajadores estadounidenses producían bienes reales, desde dentífricos hasta neumáticos, hoy trabajan en el sector de la economía que se define globalmente como prestación de servicios. Las industrias de servicios comprenden el comercio al menudeo, los hoteles y los restaurantes, las comunicaciones y la educación, los espectáculos y la recreación, los gobiernos federal y local, la administración de oficinas, la banca y las finanzas, y muchos otros tipos de trabajo. Al mismo tiempo, conforme muchas empresas manufactureras tradicionales de los Estados Unidos decrecen o crecen lentamente, surgen compañías nuevas que están creando productos y servicios cibernéticos, aeroespaciales o bioquímicos de alta tecnología.

En 2016, los Estados Unidos se sitúan en el decimoséptimo rango de los países de la OCDE para la tasa de trabajo de las mujeres. Según un estudio de la Oficina del Censo de los Estados Unidos de 2014, las asalariadas ganan por término medio el 21 % menos que sus colegas hombres. La desviación se acentúa cuando son negras (el 36 % menos) o hispánicas (44 %). Los Estados Unidos cuentan entre los cuatro países - con Suazilandia, Lesoto, y Papúa Nueva Guinea - a no garantizar licencia de maternidad.

Estados Unidos pasó de ser una economía emergente a convertirse en la superpotencia dominante en todos los ámbitos a nivel mundial, ayudado en parte por la explosión de las guerras mundiales, la inmigración, y su clara apuesta por el capitalismo. No obstante, ya en los años 20 su renta per cápita había superado en promedio a la región que hoy se denomina Eurozona. De hecho, hoy en día, a pesar de su población (es el tercer país más poblado después de China y la India), Estados Unidos es el 5º país del mundo en renta individual. Además, dado que su tasa de natalidad no es excesivamente baja (fruto de la inmigración) y su crecimiento económico se mantiene firme, las perspectivas a partir de datos del Banco Mundial y el Foro Económico Mundial:

Se presentan a continuación las mercancías de mayor peso en las importaciones de Estados Unidos para el período 2010-hasta julio de 2015. Las cifras están expresadas en dólares estadounidenses valor FOB.

]En 2016 los Estados Unidos importó $2,12 billones, lo que es el importador más grande en el mundo. Durante los últimos cinco años las importaciones de Estados Unidos han disminuido a una tasa anualizada del -0,2 %, de $2,06 billones en 2011 a $2,12 billones en 2016. Las importaciones más recientes son lideradas por Coches, que representa el 8,17 % de las importaciones totales de Estados Unidos, seguido por Petróleo Crudo, que representa el 4,69 %.

Se presentan a continuación los principales socios comerciales de Estados Unidos para el periodo 2010-hasta julio de 2015.La mayoría de sus importadores están concentrados en Asia, América y Europa. Las cifras expresadas son en dólares estadounidenses valor FOB.

]En 2016 los Estados Unidos exportó $1,32 billones, lo que es el 2º exportador más grande en el mundo. Durante los últimos cinco años las exportaciones de Estados Unidos han disminuido a una tasa anualizada del -0,8 %, de $1,34 billones en 2011 a $1,32 billones en 2016. Las exportaciones más recientes son lideradas por la exportación de Aviones, helicópteros, y / o de la nave espacial, que representa el 4,47 %de las exportaciones totales de Estados Unidos, seguidas por Refinado de Petróleo, que representan el 4,33 %.
Entre 1830 y el fin de la Segunda Guerra Mundial, los derechos aduaneros estadounidenses figuraban entre los más altos del mundo. Además, el país ya gozaba de un alto grado de protección “natural” por el costo que tenía el transporte hasta la década de 1870. La industria estadounidense fue la más protegida del mundo hasta 1945.

Desde el primer cuarto del siglo XX (1925 aproximadamente), la renta per cápita nominal de los Estados Unidos superó a la de Gran Bretaña y los demás países europeos. En el período más reciente los años 1940-1975 se caracterizaron por un rápido crecimiento del PIB y la renta per cápita que afectó bastante igualitariamente a todos los niveles de ingreso. De 1980 a 2000 se ha registrado un aumento de la renta notable del 20 % de más rico, deteriorándose ostensiblemente la situación del 20 % más pobre, hecho que ha sido ampliamente discutido por economistas como Paul Krugman.

En los años 1980, la política monetaria de la administración Reagan se traduce por una fuerte subida de los tipos de interés de los Estados Unidos y el dólar es revaluado por el 50 %. Esta política genera una explosión de la deuda de los países de América latina, estos que generalmente utilizan el dólar para reembolsar las sumas debidas. En Francia, el presidente François Mitterrand también lamenta esta política: "Estados Unidos nos hace pagar por su desempleo y su déficit. Nosotros somos los que permitimos que Reagan continúe con una política que nos aplasta.

Para 2008, las ganancias corporativas cayeron en $250 000 millones de dólares, y el sector financiero disminuyó sus ganancias a $178 000 millones de dólares. Las causas son un menor gasto de los consumidores durante el segundo semestre del 2008, y una menor demanda internacional de los bienes y servicios estadounidense.

Las ventas minoristas cayeron 1,1 % en marzo con respecto al marzo anterior. Los declives se registraron desde electrodomésticos a muebles y vestido -las ventas minoristas descendieron 11 % respecto a marzo de año pasado-. Esto se debe a que los consumidores, que representan el 70 % de la actividad económica de Estados Unidos, están teniendo cautela en sus gastos ya que son afectados por la debilidad del mercado laboral y el pronunciado declive del patrimonio inmobiliaro.




</doc>
<doc id="42876" url="https://es.wikipedia.org/wiki?curid=42876" title="Río Meno">
Río Meno

El río Meno es un río de Alemania, el principal afluente del río Rin por la derecha. Con 524 km de longitud (incluyendo al Meno Blanco, 574 km), atraviesa la comarca vitivinícola de Franconia, que se encuentra en los Estados de Baviera, Baden-Wurtemberg y Hesse. 

Nace cerca de Kulmbach en la confluencia de sus dos cabeceras, el Meno rojo (') y el Meno blanco ('). Las ciudades más importantes en su curso son: Wurzburgo, Schweinfurt, Aschaffenburg, Fráncfort del Meno (también llamada simplemente Fráncfort), Rüsselsheim am Main y Maguncia.

El nombre del río Meno proviene de la época de los celtas, que denominaban al río "Moin" o "Mogin". Cuando los romanos llegaron a la zona en el siglo I a. C., latinizaron el nombre en "Moenus", así aparece en Plinio el viejo en su "Naturalis Historia", o Tácito en su obra "Germania". Existen nombres similares en Irlanda (Maoin) y Gran Bretaña (Meon del lat. maionus). Hay diversas teorías acerca de la etimología de su nombre. Por ejemplo, ciertos autores alegan que en los idiomas antiguos de Europa tiene como significado agua, de esta forma en letón "maina", lituano maiva. Otros dicen que puede provenir del latín "Muro Circular" (moenia). En la época medieval se denominó "Moyn" o "Moyne" y no fue hasta el siglo XIV cuando se empezó a denominar con el nombre que conocemos hoy en día.

En los dialectos de la zona se pronuncia de las siguientes formas:


El recorrido primero del Meno se realiza en la zona de Franconia y Baviera y a través de la parte sur de Hesse. En el sector de la ciudad de Wertheim, cuando llega a la longitud de 25 km, empieza a formar la frontera entre Baviera y Baden-Wurtemberg, de esta forma acaba desembocando en el Rin en Wiesbaden frente a la parte antigua de la ciudad de Maguncia.

La fauna del río es rica en peces y de esta forma puede observarse buenos ejemplares de anguila europea, barbo, platica, Aitel, perca de río, brema blanca, leucisco, lucio, variedades de carpas, narigudo y Rapfen.

Desde el año 1826 se están realizando mediciones exactas de los niveles del río, siendo los niveles más altos:


En los siglos XX y XXI hubo en las siguientes fechas:


El Meno es navegable para barcos de carga desde su desembocadura en Rin, cerca de Maguncia, hasta Bamberg (396 km). Desde 1992 se conecta con el río Danubio mediante el canal Rin-Meno-Danubio y el río Altmühl, altamente regulado. El río ha sido canalizado a lo largo de 34 grandes esclusas (300 m x 12 m) para permitir a embarcaciones clase CEMT V (110 m x 11.45 m) navegar la longitud total del río. Las 16 esclusas del canal Rin-Meno-Danubio y las del Danubio tienen las mismas dimensiones.


</doc>
<doc id="42879" url="https://es.wikipedia.org/wiki?curid=42879" title="Islas Vírgenes de los Estados Unidos">
Islas Vírgenes de los Estados Unidos

Las Islas Vírgenes de los Estados Unidos (USVI, por sus siglas en inglés; también conocidas como Islas Vírgenes Estadounidenses), son un grupo de islas en el Caribe y un territorio no incorporado y organizado de los Estados Unidos. Las islas forman parte geográficamente del Archipiélago de las Islas Vírgenes, ubicado en las Islas Leeward de las Antillas Menores. 

El archipiélago se compone de las islas principales de Saint Croix, Saint John y Saint Thomas; además de diversas islas menores que les rodean. El área total del territorio es de 133.73 millas cuadradas (346,36 km²). La capital del territorio es Charlotte Amalie, en la isla de Saint Thomas. 

Previamente conocidas como las Indias Occidentales Danesas del Reino de Dinamarca y Noruega, fueron vendidas a los Estados Unidos por Dinamarca por el Tratado de las Indias Danesas Occidentales de 1916. Están clasificadas por las Naciones Unidas como un territorio no autónomo. Las islas están organizadas bajo el Acta Orgánica Revisada de las Islas Vírgenes de 1954 y han organizado, desde entonces, cinco convenciones constitucionales. La última y única constitución propuesta, adoptada en 2009 por la 5ª Convención Constitucional de las Islas Vírgenes de los Estados Unidos, fue rechazada por el Congreso de los Estados Unidos en 2010, que instó a la convención de reconsiderar las preocupaciones del Congreso y la administración de Obama. La convención sostuvo reuniones en octubre de 2012, pero no fue capaz de abordar los problemas y producir una constitución modificada antes de la fecha límite del 31 de octubre. 

En 2010, la población era de 106 405, y mayoritariamente compuesta por afrocaribeños. El turismo y categorías relacionadas componen la actividad económica principal, empleando a un alto porcentaje de la fuerza de civiles no-agricultores, que contaban con 42 752 personas en 2016. El trabajo en el sector privado compone el 71 % de la fuerza laboral total.

Cristóbal Colón nombró al archipiélago como las «Islas de las Once Mil Vírgenes», en referencia a la leyenda de Santa Úrsula y las Once Mil Vírgenes; finalmente, el nombre se abrevió a las «Islas Vírgenes». Para diferenciarlas del territorio británico que constituye la mitad oriental del archipiélago (cuyo nombre oficial es simplemente "Virgin Islands"), se le añadió el título «de los Estados Unidos» al nombre oficial de las islas ("Virgin Islands of the United States").

Las islas Vírgenes estuvieron habitadas por diversos grupos indígenas, especialmente los siboneyes, los caribes y los arahuacos. El navegante Cristóbal Colón divisó estas islas en 1493 durante su segundo viaje y les dio ese nombre en honor de Santa Úrsula y sus vírgenes. En los trescientos años posteriores, la administración de estas islas recayó en diversos colonizadores europeos: España, Gran Bretaña, los Países Bajos, Francia y Dinamarca.

La Compañía Danesa de las Indias Occidentales llegó a la isla de Santo Tomás ("Saint Thomas") en 1672 y a San Juan ("Saint John") en 1694. En 1733, los daneses compraron la isla de Santa Cruz ("Saint Croix") a los franceses. En 1754, las islas se convirtieron en una colonia del Reino Danés, llamada "Jomfruøerne". La cosecha de la caña de azúcar por esclavos dominó la economía de las islas en los siglos XVIII y XIX, hasta la abolición de la esclavitud decretada por el gobernador Peter von Scholten, el 3 de julio de 1848.

En 1733, la isla de San Juan fue escenario de una de las primeras rebeliones importantes de esclavos en el Nuevo Mundo cuando los esclavos Akan-Akwamu de la Costa Dorada (la actual Ghana) se apoderaron de la isla durante seis meses. Los daneses pudieron derrotar a los esclavos africanos con la ayuda de los franceses en Martinica. En lugar de permitir que se les volviera a capturar, más de una docena de los cabecillas se dispararon a sí mismos antes de que las fuerzas francesas pudieran capturarlos. Se estima que para 1775, los esclavos superaban a los colonos daneses en una proporción de 8:1.

Después de otra rebelión de esclavos en Santa Cruz, la esclavitud fue abolida por el gobernador Peter von Scholten el 3 de julio de 1848, que ahora se celebra como el Día de la Emancipación. En los años siguientes, se implementaron varias veces estrictas leyes laborales, lo que llevó a la revuelta laboral de Santa Cruz de 1878.

Como las plantaciones ya no eran tan rentables, los colonos daneses comenzaron a abandonar sus propiedades, lo que provocó una importante disminución de la población y de la economía en general. Además, el huracán y el terremoto y el tsunami de 1867 impactaron aún más en la economía. Durante el resto del período de dominio danés, las islas no eran económicamente viables y hubo que hacer importantes transferencias del presupuesto estatal danés a las autoridades de las islas.

Durante la fase de la guerra de submarinos en la Primera Guerra Mundial, Estados Unidos, temiendo una posible captura de las Islas Vírgenes por parte del Imperio alemán para usarlas como base naval, presionaron al Reino de Dinamarca para que vendiera este territorio. Temiendo que si Alemania invadiese Dinamarca, Estados Unidos conquistaría las islas, el país nórdico aceptó la oferta. 

El Tratado de las Indias Occidentales danesas se firmó en agosto de 1916, con un referéndum sobre la venta celebrado en Dinamarca en diciembre de 1916 en el que los votantes aprobaron la decisión de vender. El trato se concretó en enero de 1917, cuando los Estados Unidos y Dinamarca intercambiaron sus respectivas ratificaciones del tratado, el territorio pasó a denominarse "Islas Vírgenes de los Estados Unidos". Todos los años se reconoce como día festivo el Día de la Transferencia, para conmemorar la adquisición de las islas por los Estados Unidos.

El 17 de enero de 1917, Estados Unidos compró oficialmente el territorio de las Indias Occidentales Danesas por 25 millones de dólares, tomando posesión el 31 de marzo. En 1927, Estados Unidos concedió la ciudadanía a todos sus habitantes.

Las islas Vírgenes de los Estados Unidos son un territorio organizado no incorporado de los Estados Unidos. A pesar de que son ciudadanos estadounidenses, no pueden votar en las elecciones presidenciales de los Estados Unidos.

Los principales partidos políticos son el Partido Demócrata de las Islas Vírgenes, el Movimiento de Ciudadanos Independientes y el Partido Republicano de las Islas Vírgenes. Candidatos adicionales se postulan como independientes.

A nivel nacional, escogen un representante al Congreso de Estados Unidos de las Islas Vírgenes de Estados Unidos. Sin embargo, el delegado elegido no tiene derecho al voto en el Congreso.

A nivel territorial, quince senadores —siete del distrito de Saint Croix, siete del distrito de Saint Thomas y Saint John, y un senador que debe ser residente de Saint John— son elegidos por un término de dos años a la Legislatura unicameral de las Islas Vírgenes de los Estados Unidos. Las islas han elegido un gobernador territorial cada cuatro años desde 1970. Antes los gobernadores eran escogidos por el Presidente de los Estados Unidos.

Las islas tienen una Corte del Distrito y una Corte Superior. Los jueces son escogidos por el presidente y el gobernador respectivamente. El Congreso de los Estados Unidos ha organizado varios referendos locales para ayudar en la autodeterminación de las islas. Como con Puerto Rico, los residentes han tenido la opción de la independencia, "statu quo", o la opción de ser Estado; sin embargo, estas medidas han fallado, y eso ha hecho que sigan con el estatus actual.

Las Islas Vírgenes están divididas en tres distritos (St. Croix, St. Thomas, St. John), que a su vez se dividen en veinte subdistritos.

Las islas Vírgenes de los Estados Unidos están localizadas entre el mar Caribe y el océano Atlántico, a 80,5 km al este de Puerto Rico. El territorio consiste de cuatro islas principales: Saint Thomas (Santo Tomás), Saint John (San Juan), Saint Croix (Santa Cruz) y Water Island, así como una docena de pequeñas islas.

Su capital es Charlotte Amalie.

Son conocidas por sus playas de arena blanca, incluyendo Magens Bay y Truk Bay, y puertos estratégicos, incluyendo Charlotte Amalie y Christiansted. Muchas de las islas, incluyendo Saint Thomas, son de origen volcánico y montañoso. El punto más alto es Crown Mountain (474 m) en Saint Thomas. Saint Croix, la más grande de las islas, se encuentra al sur y tiene un terreno plano. El Servicio Nacional de Parques posee más de la mitad de la isla de Saint John, alrededor de toda la isla Hassel, y varios acres de arrecifes de coral (véase también parque nacional Islas Vírgenes, Monumento Natural del Arrecife de Coral de las Islas Vírgenes, Monumento Nacional del Arrecife de la Isla Buck, Sitio Nacional Histórico de Christiansted y la Reserva Ecológica y Parque Nacional Histórico de la Bahía de Salt River).

Las islas se encuentran en el límite de la placa Norteamericana y la placa del Caribe. Ocurren fenómenos naturales como terremotos, huracanes y tsunamis.

El clima es tropical, la humedad es relativamente baja. En total caen 965 mm de precipitaciones por año, siendo la época más lluviosa de septiembre hasta noviembre.

Las temperaturas cambian poco a lo largo del año. En Charlotte Amalie, las temperaturas máximas rondan alrededor de 33 °C y las temperaturas mínimas rondan alrededor de 22 °C.

El turismo es la actividad económica primaria. Las islas normalmente reciben dos millones de visitantes por año, muchos de ellos vienen en crucero. 

El sector manufacturero consiste en refinación de petróleo, textiles, electrónica, destilación de ron, farmacéutica, y plantas de ensamblaje de relojes. La agricultura es reducida, esto ha llevado que los alimentos sean importados. Negocios internacionales y servicios financieros son reducidos pero está volviéndose en un componente en crecimiento de la economía. Una de las refinerías petroleras más grandes del mundo está localizada en Saint Croix.

Las islas están sometidas a tormentas tropicales y huracanes. Recientemente, los huracanes Hugo en 1989, Marilyn en 1995 e Irma en 2017 produjeron daños económicos.

El 80 % de la población es de origen africano, el 15 % son blancos estadounidenses y europeos, mientras que un 5 % de la población es de origen puertorriqueño.

El idioma oficial más extendido y desarrollado es el inglés, que comprende aproximadamente el 80 % de la población. Por su parte, el idioma español es hablado por un sector importante de la población, especialmente por inmigrantes de Puerto Rico y la República Dominicana. Existen además inmigrantes de las islas de Dominica y Santa Lucía que hablan lenguas criollas derivadas del francés. La mayoría de la población habla una lengua criolla derivada del inglés.

Como en la mayoría de los países del Caribe, el cristianismo es la religión dominante en las Islas Vírgenes. En un reflejo de territorio danés de la herencia colonial, el protestantismo es la más frecuente. También hay una fuerte presencia católica debido a la gran población hispana, así como la influencia irlandesa durante la época de la colonia danesa.

La población perteneciente al culto protestante es la mayoritaria, destacándose en esta categoría la Iglesia bautista (42 %) y la Iglesia episcopal (17 %). Entre las minorías religiosas se encuentra la Iglesia católica (siendo la más importante de las religiones minoritarias (34 %)) y la Comunión Anglicana (Iglesia episcopal en los Estados Unidos-Iglesia evangélica luterana en Estados Unidos.

El Departamento de Educación de las Islas Vírgenes sirve como la agencia de educación del territorio, y tiene dos distritos: Distrito Escolar de St. Thomas-St. John y Distrito Escolar de St. Croix.

La Universidad de las Islas Vírgenes ofrece la educación superior que conduce a los grados de asociado, licenciado, y maestro, con sedes en St. Thomas y St. Croix.

Al igual que la gran parte de los ingleses que hablan caribeano, la cultura de las Islas Vírgenes es sincrética, con influencias derivadas principalmente de África Occidental, Europa y América. Aunque los daneses controlaron las actuales Islas Vírgenes de los Estados Unidos durante muchos años, el idioma dominante desde el siglo XIX ha sido una base de inglés con criollo, y las islas siguen siendo sumamente receptivas a la cultura del idioma inglés que a cualquier otro.

Los holandeses, los franceses y los daneses también contribuyeron elementos a la cultura de las islas, como también inmigrantes del mundo Árabe, de India y otras islas del Caribe. La única influencia importante en la cultura de las Islas Vírgenes, proviene de los africanos esclavizados para trabajar cañaverales desde el siglo XVII al siglo XIX. Estos esclavos africanos trajeron consigo tradiciones de toda una franja de África, incluyendo lo que es ahora Nigeria, Senegal, la República del Congo, Gambia y Ghana.

La cultura de las Islas Vírgenes sigue experimentando una criollización, el resultado de la migración caribeña y el contacto cultural con otras islas de la región, como también con los Estados Unidos.
La migración ha alterado el paisaje social del archipiélago, pues en las Islas Vírgenes de los Estados Unidos la mayoría de los residentes nacidos en el país pueden rastrear su ascendencia a otras islas del Caribe.

El principal idioma es el inglés, aunque informalmente se habla un dialecto local, el inglés criollo de las Islas Vírgenes. El español es hablado por inmigrantes puertorriqueños y dominicanos. El 25 % de la población habla otro idioma distinto del inglés en el hogar.

En las Islas Vírgenes Estadounidenses los deportes más populares son el baloncesto, donde incluso ha obtenido logros a nivel de selección; y el béisbol, aunque no con los mismos resultados. El fútbol ocupa un lugar más abajo, en donde a nivel internacional no les ha ido bien antes de las eliminatorias hacia la Copa Mundial de Fútbol de 2014, donde llegó a la segunda ronda. En Islas Vírgenes nació Tim Duncan, jugador de baloncesto de la NBA, de la que fue 5 años campeón y 2 años jugador más valioso, retirado en 2016 y que jugó en San Antonio Spurs.




</doc>
<doc id="42885" url="https://es.wikipedia.org/wiki?curid=42885" title="Ennio Morricone">
Ennio Morricone

Ennio Morricone (Roma, 10 de noviembre de 1928-"ib.," 6 de julio de 2020) fue un compositor y director de orquesta italiano conocido por haber compuesto la banda sonora de más de quinientas películas y series de televisión. Recibió un en 2006 y ganó el en 2016 por la cinta "The Hateful Eight". En 2020 le fue otorgado el Premio Princesa de Asturias de las Artes, compartido con el también compositor John Williams.

Sus composiciones se incluyen en más de veinte películas galardonadas, además de realizar también piezas sinfónicas y corales. Destacan, entre otros, sus trabajos en películas del "spaghetti western", de la mano de su amigo Sergio Leone, como "Por un puñado de dólares" de 1964, "La muerte tenía un precio" de 1965, "El bueno, el feo y el malo" de 1966 o "Hasta que llegó su hora" de 1968. No obstante, su obra se extendió a multitud de géneros de composición, convirtiéndolo así en uno de los compositores más versátiles de la historia del cine y también de los más influyentes del siglo XX. Sus composiciones para "Days of Heaven" de 1978, "La misión" de 1986 o "Cinema Paradiso" de 1988 son catalogadas como auténticas obras maestras.

Nacido en Roma, Morricone comenzó a tocar la trompeta cuando era niño y a los seis años ya había compuesto su primera obra. Estudió en la Academia Nacional de Santa Cecilia a la edad de nueve años, donde su padre, Mario Morricone, que era músico, lo inscribió. Cuando tenía doce años entró en el conservatorio, inscribiéndose en un programa de armonía de cuatro años, que acabó en seis meses. Su diploma de trompeta lo recibió en 1946 y a partir de ese año comenzó a trabajar profesionalmente componiendo la música de "Il Mattino" "(La mañana)". Después de graduarse en 1954, empezó como escritor fantasma, componiendo música para películas, que se atribuían a famosos músicos de la época. Pronto ganó popularidad debido a la composición de música de fondo para programas de radio y poco después daría el salto a la gran pantalla.

En los años cincuenta recibió un diploma en instrumentación. También le fue otorgado por el también compositor Goffredo Petrassi un diploma en composición. En 1955, Morricone se dedicó a arreglar la música de otros compositores que ya estaban establecidos en el cine. Al poco tiempo, Sergio Leone, un amigo de la infancia de Morricone, lo requeriría para que fuese el compositor de las bandas sonoras de sus películas. Juntos crearon un punto de vista diferente del western tradicional con la película "Por un puñado de dólares" (1964), que fue más tarde conocido como el spaguetti western. En ese ámbito hicieron luego otra vez juntos varias películas más como "El bueno, el feo y el malo" (1966) y "¡Agáchate, maldito!" (1971)"."

En los años 80 y 90, Morricone continuó componiendo para Leone en películas de otro estilo como en "Érase una vez en América" (1984), por lo que podría haber tenido un Óscar, si no hubiese sido descalificada su banda sonora para ser nominada por un tecnicismo de la academia al no ver el nombre de su compositor incluido en los créditos finales, una banda sonora que muchos también catalogan como la mejor banda sonora de la historia del cine. También compuso para otros directores como Roland Joffé en "La misión" (1986), Brian de Palma en "Los intocables de Eliot Ness" (1987) o Giuseppe Tornatore en "Cinema Paradiso" (1988). Otras composiciones más recientes de carácter notable son en las películas "Malèna" (2000), "Campos de Esperanza" En el 2005 compuso la banda de sonido de la película sobre el Papa Juan Pablo II "Karol" el hombre que se hizo Papa y su segunda parte "Karol" el Papa, el Hombre. (2005) o "Baarìa" (2009).

Morricone ha recibido dos premios Grammy, tres Globos de Oro, cinco BAFTA, diez David de Donatello, once Nastro d'argento y el Premio de Música Polar en 2010, considerado este último como el Nobel de la música. En la edición de los Premios Óscar 2006 recibió el «por sus magníficas y polifacéticas contribuciones en el arte de la música de cine». En 2016 recibió el Óscar en la categoría de por la película The Hateful Eight, después de haber sido nominado seis veces en esta categoría en ediciones anteriores, convirtiéndose así en el galardonado más longevo en dicha categoría en la historia de los Premios Óscar. A lo largo de su carrera, Morricone ha vendido más de 70 millones de discos.

Morricone falleció en Roma el 6 de julio de 2020 en el hospital policlínico de la Universidad Campus Biomédico, a los noventa y un años, a consecuencia de las complicaciones producidas por una fractura de fémur tras sufrir una caída en su casa varios días antes.

Premios Óscar
Globos de Oro
Premios BAFTA
Premios Grammy

En 2009, la 'Recording Academy', agencia que entrega los premios Grammy, incluyó la banda sonora de "El bueno, el feo y el malo", de 1969, en el 'Grammy Hall of Fame'.
David de Donatello
Nastro d'argento

Entregados por el 'Sindicato Nacional Italiano de Periodistas de Cine'.









</doc>
<doc id="42891" url="https://es.wikipedia.org/wiki?curid=42891" title="Samsonite">
Samsonite

Samsonite Corporation es una empresa fabricante de maletas y equipaje fundada en 1910 en Denver, Colorado, Estados Unidos, por Jesse Shwayder, originalmente bajo el nombre de Shwayder Bros. En 2006, la compañía trasladó sus oficinas centrales desde Denver a Mansfield, estado de Massachusetts.

Su nombre se deriva de la figura bíblica Sansón. Desde 1965 se denomina Samsonite Corporation. Es la marca de maletas más conocida a nivel mundial y el mayor fabricante de equipaje del mundo.

En una clara estrategia de expansión, la compañía se ha expandido vía adquisiciones en diversos países en los cuales no tenía presencia. Recientemente compró una participación mayoritaria en el fabricante estadounidense de accesorios de lujo Lambertson Truex. También ha adquirido compañías de equipaje en Chile, Rusia y Turquía.

Tradicionalmente, Samsonite ha estado asociada a la durabilidad de sus productos más que al estilo y diseño. Sin embargo, posee una línea de lujo y diseños exclusivos: "Samsonite Black Label".

Las marcas de Samsonite Corporation son: Samsonite, Samsonite Black Label, Lambertson Truex y American Tourister.

En 2007, Samsonite Corporation fue adquirida por CVC Capital Partners, firma de capital de inversión.

Samsonite somete a cada uno de los materiales que utiliza para la elaboración de sus maletas a unos controles de calidad muy rigurosos, con la finalidad de evaluar si el modelo está preparado para entrar en el mercado y contribuir a mantener la reputación de la empresa y sus productos. Calidad, diseño y funcionalidad son los pilares de la marca, teniendo como máximo objetivo cumplir con las expectativas de sus principales usuarios y lograr fidelizar a los nuevos consumidores.

Samsonite cayó en bancarrota el 5 de septiembre de 2009 como parte de su reorganización, cerrando aproximadamente la mitad de sus cerca de 173 tiendas en Estados Unidos.

Samsonite Company Stores LLC dijo que su presentación de protección por quiebra bajo el capítulo 11, apuntó a enfocar el negocio en sus tiendas de descuento, que se desempeñaron mejor en la abrupta caída del gasto de los consumidores en viajes y placer. (Reuters)

En junio de 2011, Samsonite generó ganancias de US$ 1.250 millones durante una venta directa al público en Hong Kong.

En 2013 presentaron las ideas próximas a incluirse en mercados emergentes como es el de la India con precios similares a $50.



</doc>
<doc id="42892" url="https://es.wikipedia.org/wiki?curid=42892" title="Hoshi no Koe">
Hoshi no Koe

"Hoshi no koe" fue creada prácticamente por un solo hombre: Makoto Shinkai. Shinkai escribió, dibujó, dirigió la historia y la animó digitalmente con ayuda de su computadora a lo largo de casi un año y dos días. Incluso él y su novia pusieron las voces de los personajes en la versión original, aunque posteriormente se realizó una segunda versión con actores de doblaje profesionales. El compositor Tenmon proporcionó la música. Shinkai y Tenmon habían trabajado juntos en un estudio de videojuegos eróticos llamado minori (sic), Tenmon también puso música al corto anterior de Shinkai llamado "Kanojo to kanojo no neko" ("Ella y su gato", 1999). Después compondría su más actual "Kumo no mukō yakusoku no basho" ("Más allá de las nubes, la tierra prometida", 2004).

En Hoshi no koe, la Tierra está en guerra contra los tarsianos, una raza de alienígenas. Una chica de instituto, Mikako Nagamine, se alista en las Fuerzas Armadas de Naciones Unidas para pilotar un mecha (pronúnciese "meca") gigante. Pronto tiene que abandonar la Tierra y a su amigo Noboru Terao. A medida que el ejército sigue a los tarsianos en su retirada, Mikako se aleja cada vez más de Noboru, y por tanto los mensajes de texto que Mikako manda a la Tierra con su teléfono móvil tardan cada vez más en llegar a su destino. Al final, los mensajes tardan ocho años, pero Noboru sigue esperando la vuelta de Mikako. El argumento de Hoshi no koe se centra en el vínculo que existe entre los dos en su relación a muy larga distancia, más que en las batallas espaciales en que Mikako debe luchar.


</doc>
<doc id="42893" url="https://es.wikipedia.org/wiki?curid=42893" title="Captura electrónica">
Captura electrónica

La captura electrónica es un proceso mediante el cual un electrón atómico, normalmente de la capa K, se combina con un protón del núcleo y forma un neutrón y un neutrino electrónico. Es un proceso alternativo a la desintegración beta con emisión de positrones. Puede ser incluso el único posible cuando la energía disponible para la emisión radiactiva es inferior a 1,022 MeV, como en el caso del decaimiento del Rb-83 al Kr-83 (la energía disponible es de 0.9 MeV).

Aunque el proceso de captura electrónica no sea realmente una emisión beta, suele estudiarse conjuntamente con este tipo de emisión, ya que sigue las mismas leyes.

El producto de la desintegración suele crearse en un estado excitado, por lo que se suelen originar cascadas de radiación gamma hasta que se alcanza el estado fundamental.

ejemplos: 


</doc>
<doc id="42894" url="https://es.wikipedia.org/wiki?curid=42894" title="Extraterrestre">
Extraterrestre

En la cultura popular y en la ufología, se denomina extraterrestre a todo ser vivo originario de cualquier sitio ajeno a la Tierra. La mayor parte de las personas solo tiene en cuenta esta definición al referirse a los seres provenientes del espacio exterior. Por lo general, la vida extraterrestre inteligente se asocia al fenómeno platillo volador.

La palabra compuesta latina "alienígĕna" fue transliterada del griego ‹"all - os"›. De la raíz gr. ‹all› pasó al lat. como ‹ali›, «otro, extraño», dos lexemas como elementos componentes ("ali - gen") que en lo literal y dicho conjuntamente significarán lo «"engendrado en otra tierra"», siendo nombre común. Desde la antigüedad se usó en sentido civil para legislar lo extranjero, lo ajeno, lo extraño a un reino o nación concretos. Con morfemas se derivaron en latín una familia de palabras sintéticas de significados extensivos, concomitantes y complementarios.

Alius «"otro de muchos"» (alter es «"otro de dos"», a veces se toma por "alius"). Alienus «"desigual"». Alieno «"ageno, conmutada en ajeno: lo que no nos es propio"». Aliena «"ajeno (referido a cosas, propiedades, cualidades)"» y alieni «"ajeno (referido a personas)"». Alienígena en inglés es alien, con exacto origen y mismo significado, «ajeno» con valor civil de extranjero, alóctono, foráneo, extraño.

También es palabra compuesta extra-terrestre, donde ‹extra› significa «"fuera por contraposición a intra"» o ‹exter› «"fuera"», más propiamente se aplicaron sus derivadas ‹exterus› como «"lo nacido en el exterior, lo exterior hostil: exterae nationes & gentes... exterus hostis"» que también se presenta con valor de «"extranjero"» o ‹externus› como «"lo que es externo, foráneo: extrinsecus accedens... adventitius... externi homines... y otras frases"» o ‹extimus › como «"los cielos extremos, el cosmos: orbis coelestis extimus"»y a todo esto se le conjunta & ‹terrae›.

Con respecto a las definiciones de “alien” y “extraterrestre”, es necesario denotar que existe una diferencia entre sus definiciones. Extraterrestre, claramente, es una palabra creada para explicar en términos simples la procedencia de estos seres. En cambio, la palabra "alien" es latina y su significado es “extranjero”, “extraño”, “ajeno” o "el/lo otro" (aquí coincide con la otra palabra de origen latino "alter"). Aunque en inglés, los estadounidenses utilizan la palabra "alien" para referirse a seres extraterrestres, no es el significado original y exclusivo de la palabra.

Actualmente se conceptualiza el fenómeno extraterrestre usando diferentes perspectivas:

Los enfoques de la ufología acientífica son tan variados, como las opiniones de los que proponen las teorías. Sobra decir que dichos enfoques no gozan de ninguna aceptación científica, y solamente la astrobiología y la ufología procientífica se acercan a la noción de ciencia, sin llegar a ser aceptadas por completo en forma generalizada.

En el contexto de la astrobiología, existen esfuerzos de investigación para intentar demostrar la presencia de vida en el cosmos, por ejemplo el llamado proyecto SETI, dedicado a rastrear el espacio con radiotelescopios, a la espera de captar alguna señal no natural o mensaje proveniente de seres inteligentes.

Según los escépticos y, a pesar de que mucha gente afirme supuestamente haberlos conocido o, incluso, ser uno de ellos, no existe en la actualidad ninguna prueba fiable que confirme la existencia de vida extraterrestre. Se sostiene que la mayoría de las pruebas aportadas son testimonios de supuestos avistamientos o raptos, o fotografías, que no representan por sí mismas evidencia irrefutable; con todo, un sector variable de la población (cambiante en función del país y la cultura) a lo largo del mundo, cree en la veracidad de las afirmaciones de muchos de los llamados "testigos".

Actualmente, se asocia la idea de extraterrestre con la del fenómeno ovni, pero no siempre ha sido así. Y aunque el avistamiento de extraños vehículos y fenómenos aéreos es quizás muy antiguo (véase "foo fighters" y aviones fantasma), su asociación con los extraterrestres es históricamente muy reciente. Quizá el caso que llevó a asociar a los ovnis con los extraterrestres sea el caso de Kenneth Arnold, que afirmó haber avistado «"platillos voladores"» cerca del Monte Rainier el 24 de junio de 1947, en el estado de Washington, Estados Unidos. Luego de hacer públicas sus afirmaciones, multitud de personas informaron haber sido testigo de avistamientos en los Estados Unidos, fenómeno que no ha cesado hasta el presente, y que se extiende a lo largo y ancho del planeta.

Cabe notar que, en esa época, ya existía un rico folclore sobre extraterrestres, producto de la popularidad de obras como "La guerra de los mundos" de H. G. Wells, la adaptación y emisión de esta por la radio a cargo de Orson Welles, algunas obras de Julio Verne, pero sobre todo, los «"Pulps"», en donde escritores luego célebres, vertían sus ideas sobre la vida en otros planetas, y sobre sus posibles atributos.

En la ciencia ficción se usa con frecuencia el término alienígena (deformación del latín [alien], que significa "otro") para designar las formas de vida de origen extraterrestre, y son muy recurrentes como argumento narrativo, pues desde la época de los "Pulps" los extraterrestres pueden servir para producir en el lector maravilla, asombro, o miedo (en ese entonces, niños, adolescentes, y adultos jóvenes), al poder imaginárseles atributos imposibles para los seres humanos. El cine pronto tomó dicha predilección literaria, transformándola en múltiples sagas de películas, todas las cuales ejemplifican distintas perspectivas sobre los extraterrestres, concomitantes con las distintas ideas de los diferentes autores literarios.

Este uso del término es claramente antropocéntrico, ya que rara vez se aplica a los seres humanos nacidos fuera de la Tierra; aun cuando los humanos invaden algún otro lugar del universo en la ficción, suelen seguir empleando el término para designar a los nativos del lugar.

Es notorio el trato que le da la cultura estadounidense a la idea de "extraterrestre", al que en inglés denominan "alien", término que también se aplica a quien viene de afuera (inmigrantes). La palabra "alien" es un término legal dentro de las leyes de Estados Unidos para denotar a no ciudadanos del país. A partir de este concepto se crearon novelas consideradas políticamente correctas para hablar de inmigrantes dentro de los Estados Unidos, sin hacerlo de forma directa, a través de los extraterrestres. De hecho es notorio que en algunas obras de autores de dicho país, la cultura descrita para los extraterrestres es sacada de alguna cultura terrestre real, o la imagen que los autores y la sociedad estadounidense se hacen de dicha cultura []. Extraterrestres colectivistas donde la individualidad se sacrifica en pos del grupo, representaban veladamente al Comunismo y su falta de individualismo. Actualmente, extraterrestres con culturas teocráticas fundamentalistas hacen paralelos con la percibida amenaza terrorista de los llamados grupos islámicos.

Características asociadas a los extraterrestres
Una imagen frecuente en la cultura popular, el cine y las historietas es una de la de extraterrestres de apariencia humanoide, como los "hombrecillos verdes" de la ciencia ficción clásica o los "grises" popularizados por "Encuentros en la tercera fase" y "The X-Files".

Varias razones propician que en la cultura popular se le asocie frecuentemente una representación humanoide a una forma extraterrestre inteligente, pese a que no haya razón científica para suponerla probable. Ejemplo de ello es que en el caso de las películas, esta representación simplifica el proceso de vestuario y maquillaje necesario para la representación de uno de ellos; además, el diseño basado en rasgos y expresiones humanas reconocibles favorece la estimulación de reacciones emocionales en el espectador. En este sentido la reacción humana tiene similitudes con la que se experimenta ante los robots en cuyo caso una mayor similitud física con el ser humano genera una mayor empatía, tal como demuestra la teoría del valle inexplicable.

Es este sentido, a nivel psicológico es más fácil familiarizarse con un posible extraterrestre con características físicas reconocibles como brazos y piernas, dos ojos, una nariz y una boca, así también con aquel que posea un comportamiento reconocible tal como mostrar sus dientes en casos de enojo o realizar muecas en situaciones de sorpresa, e igualmente sea más fácil asociarlos inconscientemente como un ser inteligente, producto de la forma física similar a la nuestra que se les otorga popularmente. Igualmente destaca que mientras más sean descritos como seres semejantes a las características y apariencia humana, igualmente son descritos como seres más pacíficos y de características angelicales; en cambio, mientras más sean descritos como seres menos semejantes al ser humano, son además más descritos como seres belicosos, terroríficos, malignos, etc...

Durante el siglo XX se han incrementado anécdotas de extraños objetos en los cielos; dichos testimonios aparecen en proporciones tales, que se habla de oleadas de ovnis en lugares y fechas dispares. Esto, junto a la difusión de la ciencia (o la imagen de la ciencia) en la cultura popular, ha promovido en ciertos individuos la idea de que los extraterrestres son un fenómeno digno de estudio y de una disciplina propia. Sin embargo, estos disienten de los que consideran a los extraterrestres como un fenómeno sobre el que no hay evidencia que no pueda ser refutada y que por lo tanto no puede haber una ciencia sobre dicho tema, y realmente se interesan más en las anécdotas de los testimonios de presuntos testigos y aceptan como una verdad que los ovnis son navíos tripulados por alienígenas.

Según la opinión de los exobiólogos y también de algunos astrónomos, sí es muy probable que la vida haya surgido en otros mundos; la razón de esta afirmación es que las leyes de la física y química son las mismas en todas partes. Los fenómenos que dieron origen a la vida en la Tierra, muchos consideran que pueden repetirse en otro lugar, en donde las condiciones se parezcan lo suficiente.

Pero, debido a que no se dispone todavía de información sobre dichos lugares con condiciones similares (por ejemplo, planetas extrasolares similares a la Tierra), la pregunta sobre la existencia de vida extraterrestre permanece todavía sin una respuesta clara ni científicamente comprobada. Cabe notar que el reconocimiento de la ignorancia en este tema no es sinónimo de denegación. Y que tanto las opiniones a favor como en contra dentro de la comunidad de expertos, hasta la fecha, son opiniones informadas pero sin pruebas irrefutables que establezcan la verdad o falsedad de los hechos. También según la opinión de muchos investigadores es imposible que la Tierra sea el único planeta con vida en un Universo que se está continuamente expandiendo y en el que existen muchos trillones de planetas.

Dicho estado de cosas no impide que existan fuertes críticas hacia la ufología, tanto epistemológicas como metodológicas y semánticas, que hacen que dicha disciplina se encuentre, por consenso general, entre las llamadas seudociencias. Desde el punto de vista epistemológico, se le critica que habitualmente sus expertos hacen afirmaciones infalsificables, es decir, afirmaciones que no pueden rebatirse (por ejemplo, «los ovnis vienen de Ummo»). Desde el lado metodológico, se critica que solamente se limita a observar las reacciones de grupos humanos pero sin entender sus causas; es decir, sin tomar en cuenta que dichas reacciones pueden provenir de fenómenos de histeria colectiva, modas o bromas recurrentes. En el lado semántico, se considera como altamente dudoso que la Tierra sea tan visitada por extraterrestres («"la Tierra sería la encrucijada del Universo"», afirmaba Arthur C. Clarke en broma), como parece serlo según la ufología: considerando la extensión del cosmos, el esfuerzo necesario para viajar hasta la Tierra, y la posterior carencia de contacto hace que su presencia resulte un absurdo.

Las especulaciones sobre el aspecto de los hipotéticos extraterrestres han sido muy numerosas durante todos los tiempos.

Los numerosos supuestos testigos de toda raza, religión y posición económica y social que aseguran haber tenido algún tipo de contacto, han descrito distintos tipos de seres, que podrían clasificarse en diversas tipologías. Si estos testimonios de gente que haya tenido contacto cercano con ellos son verdaderos, entonces los extraterrestres que vienen a la Tierra serían efectivamente distintas especies.

Algunos ufólogos utilizan las hipótesis sobre la exobiología y principalmente la descripción de los supuestos testigos para indicar y clasificar a los hipotéticos visitantes según diferentes tipologías, de las cuales algunas creen que serían verdaderamente reales, mientras que otras se consideran falsos testimonios.

Los Humanoides son una tipología que describe un grupo amplio de alienígenas que son representados como una forma y/o rasgos de seres humanos. Es la tipología más mencionada en ufología, y la más popular usada en ciencia ficción debido a su aspecto antropomórfico.

Los "hombrecillos verdes" (en inglés, "Little Green Men") es una tipología que describe alienígenas humanoides de color verde y generalmente de menor tamaño que el ser humano. Es la forma característica de muchos de estos seres en los comienzos de la ciencia ficción. Es la morfología clásica asociada a los marcianos, este tipo de alienígenas es el más usado en la industria del cine clásico de ciencia ficción. Suelen representarse diversos tipos de hombrecillos verdes, algunos con antenas y otros con orejas picudas como duendes, y generalmente estas características son las más usadas en la ciencia ficción y las que han tenido mejor acogida en el folclore popular, pero algunos ufólogos sostienen que existirían seres de pequeño tamaño y piel verde, pero de características anatómicas similares a la de los "Grises" (cabeza grande y ojos oscuros, sin orejas ni antenas).

Los Grises son la forma más frecuentemente referida en los casos de abducción extraterrestre y en la cultura popular. Esta tipología describe a alienígenas humanoides de aproximadamente 90 a 150 cm de altura; piel de color gris —de ahí la denominación hecha por los ufólogos—, con cabezas grandes, brazos y piernas delgados, así como ojos negros grandes y ovalados. Se presume que son altamente inteligentes e incluso que poseen poderes psíquicos.

Algunos científicos creen que sería perfectamente posible que existan personas con estas características físicas: la piel gris y los oscuros y enormes ojos negros indicarían que el planeta natal de estos hipotéticos seres sería irradiado por una radiación solar muy débil (a falta de luz, los ojos deben agrandarse, y la pigmentación de la piel se habría atrofiado). Por otro lado, el cuerpo pequeño y la enorme cabeza indicarían la evolución intelectual de estos seres (al incrementarse la capacidad de discernimiento y la habilidad tecnológica, el cerebro se habría agrandado, y al no depender de la fuerza bruta para sobrevivir, los músculos y toda la contextura física se habría encogido).

Según las descripciones de quienes dicen haber estado en contacto con ellos, estos individuos no expresarían ningún tipo de emoción o sentimiento, lo cual es una característica que suele atribuirse al estereotipo de que, a causa de sus grandes cerebros superdesarrollados, su intelecto sería su más latente rasgo psicológico dominante y eso habría eliminado cualquier rastro de instinto o emoción humana.

Los Nórdicos son una tipología de alienígenas descrita como casi iguales a los seres humanos; pero con algunas diferencias: piel extremadamente blanca, cabello extremadamente rubio (generalmente largo) y ojos celestes, rasgados u oblicuos, según algunos supuestos testigos. Los alienígenas de esta tipología también son llamados pleyadianos o venusinos por algunas personas, aunque esos nombres son de uso popular y no son aceptados mayoritariamente por la ufología, porque se conoce científicamente que Venus y las Pléyades no son lugares habitables.

Los supuestos testigos suelen describirles con una contextura física atlética y de gran belleza, vistiendo uniformes anatómicos de una sola pieza, generalmente de color blanco. Quienes dicen haber estado en contacto con estos seres afirman que son muy inteligentes, amistosos, preocupados por la humanidad y que, en general, presentan características asociadas a seres angelicales. También se les suelen atribuir poderes psíquicos. 

Los Gigantes son seres alienígenas que, según las descripciones de sus supuestos testigos, tienen aspecto prácticamente igual al de los seres humanos, pero de enorme estatura. Su estatura promedio se describe entre 2.5 y 3 metros de altura; además, tendrían algunas diferencias notables: en muchos casos, la piel y el cabello son de coloración extremadamente blanca, según otras descripciones, su cabello es muy negro y sus ojos son de color negros o muy oscuros.

Los creyentes en la existencia de estos seres los asocian con las pinturas rupestres donde se hallan representados humanoides mucho más altos que los hombres normales, en algunos casos representados con un torso triangular y grandes cabezas que algunos se animan a decir que podrían ser cascos y trajes espaciales. Algunos los relacionan con seres descritos en la Biblia, llamados "los hijos de Dios y sus hijos los ""Nephilim"", mientras que otros también los relacionan con seres de otras mitologías antiguas, tales como los Titanes de la mitología griega.

Los Zoomórficos son una tipología que describe un grupo amplio de alienígenas que son representados como una mezcla de rasgos humanoides y de animales terrestres.

En cuanto a los "reptilianos", se dice que la mayor parte de sus supuestas apariciones provienen de los Estados Unidos, y son prácticamente nulos los informes de reptilianos en otros países. Por esta razón, la mayoría de los ufólogos consideran a los reptilianos una invención de la cultura popular estadounidense. Han sido representados en más de una ocasión en libros, series o películas. En todas ellas han sido asociados con actividades malignas, ya sea invasión, rapto de seres humanos o animales para alimentarse o devastación de los recursos.

Una supuesta criatura muy famosa asociada a este tipo de extraterrestre, es el chupacabras. Se dice que estos seres se alimentan de la sangre del ganado. Además, los presuntos testigos suelen describir a seres de pequeño tamaño, con largos colmillos, alas y cuerpo similar al de un perro. Algunos ufólogos y los criptozoólogos no consideran al chupacabras como un extraterrestre, sino como una especie animal aún no descubierta por la ciencia.

Los "Insectoides" son una tipología que describe a seres con un cuerpo de insecto, generalmente con colmillos y manos largas. En la Ciencia Ficción se les describe como seres que se alimentan de cosas desagradables y están dispuestos a destruir la raza humana. Actualmente también son muy usados en películas, como en "District 9" dirigida por Neill Blomkamp.

Los "Cefalopoides" (de "cephalos", cabeza, y "podo", pie), es la tipología de extraterrestres que se describen con tentáculos y una morfología similar a la de un pulpo o calamar. Aparentemente esta tipología es unas de las primeras en salir en novelas e historias de ciencia ficción (ejemplo de esto son los marcianos de La guerra de los mundos).

"Xenomórfico", tipología que describe un grupo amplio de alienígenas cuyas descripciones rebasan cualquier similitud con criaturas terrestres: Ejemplo de ellos serían figuras nebulosas, ameboides, vegetales, minerales, etc. Es el tipo de extraterrestre menos común que mencionan los supuestos testigos.

Estos, además, son poco difundidos y mencionados en los programas de televisión, y poco frecuentados por los ufólogos.

Algunos ufólogos, como Jacques Vallée, han notado que las descripciones parecen seguir las expectativas culturales de los individuos (y presentan un notable antropocentrismo). Por lo general, los alienígenas que más se parecen a nosotros son los que son descritos como benevolentes, mientras que los llamados "grises", zoomórficos, o los llanamente "xenomórficos" tienden a ser descritos como indiferentes o hasta hostiles, y la apariencia concuerda con la conducta que describen los que afirman ser testigos.

También se ha notado que los encuentros descritos contienen muchos elementos ya presentes en fábulas y leyendas de encuentros con seres considerados como mágicos o divinos en las culturas antiguas y que, muy probablemente, tienen un origen común. Que dicho origen común sea que las leyendas se basen en hechos reales o que los presuntos hechos reales sean manifestaciones de nuevos mitos en proceso de creación es materia de debate entre los ufólogos.

Sin embargo, los partidarios indican que cabe destacar que no en todos los casos la asociación antropomórfica corresponde a la psicología humana y a la influencia de la cultura popular, sino que en la mayoría de las descripciones presuntamente veraces los extraterrestres no comparten las características que se les atribuye en la ciencia-ficción ni el perfil psicológico típico de la humanidad; por ejemplo, la amplia variedad de emociones humanas es totalmente ajena a la psique de los grises, a los que se representa como seres emocionalmente neutros; y, en cuanto a características físicas, los alienígenas más influyentes de la ciencia ficción suelen ser extravagantes, con rasgos muy elaborados y sofisticados, como lo son los zoomórficos y xenomórficos, mientras que los alienígenas de los relatos de abducción son humanoides de distintas tipologías clásicas que no abundan en la mayor parte de las sagas de ciencia ficción.

Al referirse a las descripciones clásicas de humanoides, se dice que, si fueran verdaderas, veríamos cómo los rasgos humanos no son sólo nuestros y únicos, por lo que a algunos observadores les hace pensar que tendríamos ancestros comunes. Los ufólogos creen que es posible que compartamos nuestro fenotipo con otros seres nacidos hipotéticamente en otros sitios del Cosmos, pero eso no indicaría necesariamente un parentesco evolutivo con las especies antropomorfas, ya que lo más probable es que podría deberse al fenómeno de la evolución convergente; sin embargo, la ciencia descarta la probabilidad de la existencia de la apariencia completamente humana como evolución convergente.

Los extraterrestres como personajes están presentes en muchas historias de ciencia ficción. En ellas, suele haber civilizaciones extraterrestres muy avanzadas, que a menudo visitan la Tierra con fines que pueden ser pacíficos (pero experimentales), o bien hostiles.

Una gran parte de los libros, las películas y las series de televisión sobre extraterrestres tienen el doble sentido de hablar también sobre el racismo, entre muchas otras actitudes presentes en nuestra sociedad. Algunas de las más significativas son:

Libros

Películas

Series de televisión

Videojuegos

La creencia en seres extraterrestres adquirió auras de religión en la segunda mitad del siglo XX, cuando muchos libros pseudoufológicos y neorreligiosos se basaban en la llegada de seres de otros planetas o creadores de nuestra civilización. Las tendencias de la New Age llegaron a insinuar que Jesucristo podría ser un extraterrestre, y adjudicaron muchos hechos de los libros religiosos, especialmente la Biblia como acciones realizadas por los extraterrestres. Los nuevos descubrimientos arqueológicos y los avances de la ciencia, especialmente la astronomía, fueron desmontando muchas teorías sobre vida extraterrestre en la Luna, Venus, Marte y otros planetas de nuestro sistema planetario. Finalmente, la falta de pruebas que confirmasen que los OVNIs son de origen extraterrestre, sumado a los muchos fraudes sobre el tema hicieron perder interés en esta creencia, sin que por ello, los científicos, cada día en mayor cantidad, empiecen a dar como segura la posibilidad de otros planetas en torno a estrellas de nuestra galaxia y otras galaxias que puedan albergar vida inteligente. Hecho que se reforzó por el descubrimiento astronómico de más de cien planetas en estrellas próximas a nuestro Sol.

La ecuación de Drake estima aproximadamente la cantidad de vida extraterrestre que hay en el universo. La ecuación está basada en los siguientes parámetros:

formula_1

donde formula_2 representa el número de civilizaciones que podrían comunicarse en nuestra galaxia, la Vía Láctea. Este número depende de varios factores:





</doc>
<doc id="42896" url="https://es.wikipedia.org/wiki?curid=42896" title="Marciano">
Marciano

Marciano es el supuesto habitante del planeta Marte. Aunque carecen de evidencia científica, y se circunscriben al campo de las hipótesis, las creencias acerca de la existencia de vida extraterrestre aparecen en la antigüedad clásica y han inspirado innumerables obras de ciencia ficción.

El nombre "marciano" entonces se refiere unica y exclusivamente a los ficticios habitantes del planeta Marte. Para referirse a cualquier ente procedente del espacio exterior se debe usar el termino "extraterrestre".

Las teorías sobre civilizaciones marcianas dieron lugar en su época a numerosas especulaciones e historias de ficción sobre cómo debían ser estos supuestos habitantes del planeta rojo.

En estas historias, solía retratárselos como unos humanoides de piel verde.
Algunos de los ejemplos más característicos de estas obras literarias son "La guerra de los mundos" de H. G. Wells, donde marcianos con forma de pulpo invaden la Tierra, ya que su planeta está muriendo, o las novelas marcianas de Edgar Rice Burroughs. 
También tiene su origen en estas teorías el Detective Marciano, uno de los últimos supervivientes marcianos de DC Comics.

Igualmente, el tema dio origen a la saga de las Crónicas marcianas, una serie de relatos escritos por Ray Bradbury; los cuales narran la llegada y colonización del planeta Marte por parte de los humanos, y la caída y extinción de la civilización marciana existente. 

Este tema ha servido como inspiración para personajes como Marvin El Marciano; personaje de las famosos cortometrajes de dibujos animados Looney Tunes de la Warner Bros.




</doc>
<doc id="42898" url="https://es.wikipedia.org/wiki?curid=42898" title="Timor Occidental">
Timor Occidental

Timor Occidental es una región política que comprende la mitad de la isla Timor con la excepción del distrito de Oecussi-Ambeno (que es parte de Timor Oriental) y forma parte de la provincia indonesia de Nusatenggara Oriental (Nusa Tenggara Timur, NTT), una de las principales provincias de Indonesia. Timor Occidental ocupa un área de 15.850 km². La capital y su principal puerto es Kupang, además de la población con más habitantes de la región.


</doc>
<doc id="42901" url="https://es.wikipedia.org/wiki?curid=42901" title="Estatización">
Estatización

Estatización, estatalización o estatificación, es el conjunto de disposiciones y operaciones mediante las cuales el Estado asume, en forma variada, la administración de empresas privadas, de grupos de empresas o de la totalidad de ciertos sectores económicos manejados con anterioridad por particulares. La estatización es lo opuesto a la privatización. También se le denomina nacionalización de los medios de producción, aunque una empresa estatizada puede ser previamente tanto de propiedad nacional como extranjera. La estatización o nacionalización es una acción muy característica de ideologías como el socialismo y el nacionalismo, pero con distintos objetivos, y también del capitalismo y el neoliberalismo cuando se trata de empresas en quiebra que son asumidas por el gobierno para rescatarlas económicamente a través de deuda y capital pública'.

En el socialismo se estatiza para después lograr la socialización de los medios de producción, en la que la comunidad pasaría a ser la dueña de los medios de producción, demostrando un carácter colectivista. En el nacionalismo, se recurre a la nacionalización sin llegar a la socialización ni requerir que la propiedad sea estatal, ya que lo que el Estado debe proteger es el capital nacional, tomando en cuenta los intereses nacionales.

Algunos ejemplos de nacionalizaciones en España son las que ocurrieron a partir del 2010 durante el transcurso del Rescate bancario español o las ocurridas en 1941 con el servicio ferroviario RENFE o en 1983 con la intervención de Rumasa.



</doc>
<doc id="42904" url="https://es.wikipedia.org/wiki?curid=42904" title="Partido Independentista Puertorriqueño">
Partido Independentista Puertorriqueño

El Partido Independentista Puertorriqueño (PIP) es un partido político en Puerto Rico, que propone que el país se convierta en un país soberano. Fue fundado por don Gilberto Concepción de Gracia el 20 de octubre de 1946, en la gallera Tres Palmas del municipio de Bayamón, para servir a la lucha cívica y electoral por la independencia del país, luego de que el Partido Popular Democrático abandonara la ideología independentista al obtener el poder gubernamental. El PIP cree en la lucha cívica y electoral para lograr la independencia, ha utilizado el método de la desobediencia civil y propone un sistema económico socialdemócrata.

El PIP participó por primera vez en las elecciones generales de 1948, obteniendo alrededor del 10% de los votos. El Partido Independentista no participó de la Asamblea Constituyente de 1952 por entender que no se estaba redactando una verdadera constitución sino que simplemente se le cambiaba el nombre al mismo régimen colonial. Durante el proceso de votación se registró un fuerte abstencionismo como instrumento de protesta organizada por el PIP y otras organizaciones. 

En las elecciones generales de 1952 el partido obtuvo el 20% de los votos y eligió a quince legisladores, convirtiéndose así en el principal partido de la oposición. A finales de la década de los '50 el PIP perdió gran parte de su apoyo electoral, convirtiéndose en un partido minoritario, sin casi ninguna posibilidad de obtener una victoria electoral, ya que sus votos rondan entre 2 al 3 por ciento del total de votos en las elecciones. 

El PIP ha pasado por dos momentos de alto crecimiento, el primero ocurrió durante las elecciones de 1972 cuando lanzaron la campaña "Arriba los de abajo". Dicha campaña tenía un alto contenido de justicia social, e incluso elementos de las ideas socialistas que cobraron auge luego de la Revolución Cubana. Luego de dichas elecciones el partido sufrió una transformación radical, donde los sectores de la pequeña burguesía entraron en una lucha campal por el liderato contra sectores de la alta burguesía. Un tercer sector, liderados por las figuras de Carlos Gallizá y Luis Ángel Torres, que se llamaban a sí mismos "los terceristas" por no estar con uno u otro grupo, planteaban la creación de un partido independentista de la clase trabajadora, de corte marxista-leninista y que la dirección del partido fuera electa democráticamente. El grupo liderado por Rubén Berríos, apoyado por la base del Partido, obtuvo el apoyo mayoritario de la asamblea general. Este grupo luchaba en contra de que la cúpula fuera quien nombrara al presidente de la colectividad y se le llegó a conocer como "Rubén y los brutos" por ser gente de pueblo. Eventualmente los terceristas abandonaron o fueron expulsados del partido, quienes junto a la juventud universitaria del PIP, llamada Juventud Independentista Universitaria, comenzaron a desarrollar un trabajo independiente que culminó en la fundación del Movimiento Socialista Popular en el 1974 (organización que posteriormente se une al Partido Socialista Revolucionario para formar el Movimiento Socialista de Trabajadores). Para esa misma época, el PIP y otros ciudadanos de ideologías diferentes como el gobernador pro anexión estadounidense Pedro Rosselló lucharon en desobediencia civil que logró la salida de la Marina estadounidense de la isla-municipio de Culebra. Un sector de los líderes terceristas, especialmente los que abandonaron el proyecto del MSP y luego el Movimiento Socialista de Trabajadores, se han alineado más con el Partido Popular Democrático y sus posturas. Otro pequeño grupo regresó a las filas del PIP.

El Partido Independentista propone un sistema económico socialdemócrata. En las elecciones de 1984, el PIP sufrió una fuga de votos obteniendo sólo poco más de 60 000 sufragios. Sin embargo, para 1988 nuevamente el partido se recupera obteniendo más de 95 000 votos. Por otro lado el PIP es un propulsor de una Asamblea Legislativa unicameral, propuesta que en el año 2005 ganó el apoyo de la mayoría de los electores.

En el proceso eleccionario de 2000 el PIP obtuvo más de 100 000 votos para su candidato a la gobernación y se registró crecimiento en votos en casi todos los puestos electivos. En las elecciones de 2004 el PIP no quedó inscrito como partido político luego que no alcanzara el 3% de los votos íntegros o el 5% de los sufragios para su candidato a la gobernación. Muchos adujeron que la pérdida de la franquicia del PIP se debió al flujo del voto independentista no afiliado que cruzó filas para respaldar la candidatura de Aníbal Acevedo Vilá, como un voto en contra del entonces candidato y exgobernador, Pedro Rosselló. El partido se dedicó a recoger firmas y la re-inscripción del partido. 

En el año 2006 el Partido Independentista Puertorriqueño organizó el "Congreso Latinoamericano y Caribeño Por la Independencia de Puerto Rico" en Panamá. A este congreso se unieron los principales partidos políticos de toda América Latina y el Caribe que apoyan la independencia de Puerto Rico. Aparte de los numerosos políticos también se unieron importantes figuras latinoamericanas en apoyo a la independencia de Puerto Rico, como Gabriel García Márquez, Ernesto Sabato, Mario Benedetti, Eduardo Galeano, Ana Lydia Vega, Luis Rafael Sánchez, Mayra Montero, Pablo Milanés y Carlos Alberto Libanio Christo, entre otros.

Para las elecciones generales de 2008 el Partido Independentista presentó como candidatos al doctor en economía Edwin Irizarry Mora para la gobernación y a la Lcda. Jessica Martínez Birriel como candidata a comisionada residente. El PIP no quedó inscrito por segundo cuatrienio consecutivo luego que no alcanzara el 3% de los votos íntegros, el 5% de los sufragios para su candidato a la gobernación o un 7% de votos bajo la insignia del partido . Hasta las elecciones de 2008 el PIP poseía dos escaños por acumulación en la Asamblea Legislativa del país, sin embargo, en las elecciones generales ambos escaños fueron perdidos perdiendo el partido toda representación legislativa.

Inmediatamente después de las elecciones el Partido Independentista Puertorriqueño comenzó las gestiones para comenzar la reinscripción teniendo que llegar a los tribunales para poder iniciar el proceso de recogido endorsos. A diferencia del año 2004, el proceso del 2008 tardó cuatro meses en comparación con alrededor de tres semanas del 2004 y no contó con la participación unánime del partido cuando varios líderes y comités locales se negaron a participar del proceso, al hacer un llamado a una ¨reorganización del partido¨ previo a una reinscripción acelerada. El 6 de abril de 2009, el presidente del PIP, Rubén Berríos Martínez anunció la culminación del proceso de recogido de endosos.

En 2003, The New York Times informó lo siguiente acerca de la Oficina Federal de Investigaciones admitir públicamente que había ordenado "tremendamente destructivos" los esfuerzos contra las organizaciones, entre ellas la del Partido Independentista Puertorriqueño: 
"Ellos incluyen una Directiva de 1961 el señor Hoover para buscar información sobre 12 líderes de la independencia del movimiento, seis de las cuales operan en Nueva York," en relación con sus debilidades, la moral, antecedentes penales, esposos, hijos, vida familiar, la titulación académica y otras actividades personales que las actividades de la independencia. "Las instrucciones fueron dadas en el marco del programa de vigilancia doméstica conocido como COINTELPRO, que tenía por objeto el seguimiento agresiva contra la guerra, grupos de izquierda y otros en los Estados Unidos e interrumpiendo ellos. 
En el caso de los grupos de independencia de Puerto Rico, 1961, J. Edgar Hoover nota se refiere a «nuestros esfuerzos para interrumpir sus actividades y poner en peligro su eficacia." Los expertos dicen que los documentos proporcionan adiciones inestimable a la historia de Puerto Rico. "Espero que esta va a alterar un poco el análisis de por qué la independencia no lo ha hecho-dijo Félix V. Matos Rodríguez, director del centro en el Hunter. "En la década de 1940, la independencia fue el segundo movimiento más grande de política en la isla, (después de la ayuda para el estado libre asociado), y una alternativa real. Pero fue penalizado. 
La existencia de los documentos del FBI salieron a la luz durante una Cámara de Representantes de EE.UU. Créditos audiencia del subcomité en el año 2000, cuando el representante José E. Serrano, de Nueva York cuestionó Louis J. Freeh, entonces director del FBI, sobre el tema. Freeh dio el primer reconocimiento público de la vigilancia del gobierno federal en Puerto Rico y ofreció un mea culpa. 

«Su pregunta se remonta a un período, en particular en la década de 1960, cuando el FBI operó un programa que hizo una tremenda destrucción a muchas personas, al país y, ciertamente, el FBI, dijo Freeh, de acuerdo a las transcripciones de la audiencia. Freeh dijo que haría los archivos disponibles "y ver si podemos corregir algunas de las atroces acciones ilegales, tal vez la acción penal, que se produjeron en el pasado'.

La vigilancia del FBI de cualquier persona u organización que abogue independencia de Puerto Rico ha sido reconocido por los altos funcionarios del FBI. La vigilancia del FBI el pasado del movimiento pro-independencia se detalla en el 1,8 millones de documentos, una fracción de los cuales fueron puestos en libertad en 2000.

A continuación, el director del FBI Louis Freeh hizo un reconocimiento sin precedentes a los efectos que el FBI había desarrollado una acción atroz e ilegal de los años 1930 y 1990, muy posiblemente con la participación del FBI en crímenes generalizados y la violación de los derechos constitucionales en contra de los puertorriqueños. Algo que sorprendió a una audiencia de Presupuesto del Congreso al admitir que su agencia había violado los derechos civiles de muchos puertorriqueños durante los años y había participado en "acciones ilegales graves, tal vez la acción penal."

En el 2004, Rubén Berríos Martínez reclamó que se ha comprobado en los últimos años el pueblo de Puerto Rico ha llegado a su límite económico y como resultado se ve este estancamiento económico evidenciado. Para el tiempo había un 30% de desempleados al igual que más de 50% de familias dependían de cupones para sostenerse. 

El PIP se trataría de construir un nuevo sistema legislador y a la vez redactar la nueva constitución para luego someter esta ante los próximos comicios electorales.



En el mundo de la cultura el independentismo Puerto Rico es un tema al que varios escritores, artistas e intelectuales han mostrado su apoyo. Destacan entre ellos:

La insignia del Partido Independentista Puertorriqueño consiste de una bandera con una cruz blanca descansando sobre un fondo verde. Fueron los delegados del pueblo de Vega Alta quienes presentaron este diseño durante la Asamblea de Fundación del PIP el 20 de octubre de 1946.

La bandera independentista significa:





</doc>
<doc id="42905" url="https://es.wikipedia.org/wiki?curid=42905" title="Bandera de los Estados Unidos">
Bandera de los Estados Unidos

La bandera de los Estados Unidos de América —conocida en ese país como "the Stars and Stripes", "Old Glory" y "the Star-Spangled Banner"— consta de trece franjas horizontales de igual tamaño, siete rojas y seis blancas alternadas, y un rectángulo azul en el sector del cantón superior izquierdo con cincuenta estrellas blancas de cinco puntas. Las barras representan a las Trece Colonias originales que se independizaron del Reino Unido y las estrellas, a los cincuenta estados que forman la Unión. Presenta una gran similitud con la bandera de la Compañía Británica de las Indias Orientales, en la cual posiblemente se inspiró.

La bandera de los Estados Unidos ha sido modificada en 26 ocasiones. La versión con 48 estrellas duró 47 años, hasta que se adoptó la de 49 estrellas el 4 de julio de 1959. La marca fue batida por la actual versión de 50 estrellas, adoptada el 4 de julio de 1960. 

En el momento de la Declaración de Independencia del 4 de julio de 1776 los Estados Unidos no tenían bandera oficial. La que se llama "bandera americana" no tuvo nunca carácter oficial; fue utilizada durante la Guerra de Independencia de los Estados Unidos y sirvió de base para la futura bandera nacional. Esa bandera es muy parecida a la bandera de la Compañía Británica de las Indias Orientales (CBIA) y hay quienes opinan que se inspiró en ella. Lo cierto es que la primera bandera utilizada muy similar a la de la CBIA fue la "Grand Union Flag", llamada también "Continental Colors", "Congress Colors", "First Navy Ensign" o incluso "Cambridge Flag". Tal bandera que mantenía la versión de la Union Jack de su época (es decir una "Union Jack" con la cruz de San Jorge orlada en blanco (símbolo de Inglaterra) sobre una Cruz de San Andrés blanca sobre fondo azul (símbolo de Escocia) no tuvo estatus de oficial, aunque fue el primer emblema de la "United States Navy" antes de la declaración formal de la independencia.

Otra teoría sobre el origen de la bandera es que se inspiró en el escudo de armas de George Washington, originario de Inglaterra. El 14 de junio de 1777 el Segundo Congreso Continental aprobó la Resolución de la Bandera, determinando que "la bandera de los trece Estados Unidos sean trece barras rojas y blancas alternadas, que la unión sean trece estrellas blancas sobre campo azul, representando una nueva constelación." De hecho, el 14 de junio se celebra el Día de la Bandera. Algunos estudiosos discuten la disposición de las estrellas dentro del cantón azul. Así, Francis Hopkinson, uno de los firmantes de la Declaración de Independencia, se atribuye la autoría de la bandera que lleva su nombre, mientras otro diseño, con las estrellas en círculo se atribuye a Betsy Ross, quien supuestamente cosió una bandera para George Washington; sin embargo, ninguna tiene rigor histórico.

Primero se pusieron 13 estrellas (Nuevo Hampshire, Massachusetts, Rhode Island, Connecticut, Nueva York, Nueva Jersey, Pensilvania, Delaware, Maryland, Virginia, Carolina del Norte, Carolina del Sur y Georgia), luego fueron 15 al unirse Kentucky y Vermont en 1818. Después Indiana, Luisiana, Misisipi, Ohio y Tennessee se unieron, por tanto la bandera ya tenía 20 estrellas. En 1820 se unió Illinois; en 1822 Alabama y Maine; en 1836 Missouri. Hasta 1890 se fueron añadiendo de uno en uno hasta llegar a ser 38 estados. En 1891 se agregó Idaho, Montana, Dakota del Norte, Dakota del Sur y Washington. Después se unieron Wyoming, Utah y Oklahoma. Más tarde, en 1912 se unieron Arizona y Nuevo México, con 48 estrellas. En 1960 se unió Alaska y después Hawái. Por tanto hay 50 estrellas representando 50 estados.

El hombre acreditado como diseñador de la actual bandera estadounidense de 50 estrellas es . Tenía 17 años en ese momento y creó el diseño de la bandera en 1958 como un proyecto de clase de la escuela secundaria mientras vivía con sus abuelos en Ohio.

El diseño básico de la bandera actual se especifica en el título 4 del Código de los Estados Unidos, que incluye la adición de nuevas estrellas para representar a nuevos estados. La especificación da los siguientes valores:


Estas especificaciones están contenidas en una orden ejecutiva que, en rigor, solo regula banderas hechas por o para el gobierno federal de Estados Unidos. En la práctica, la mayoría de las banderas estadounidenses disponibles para la venta al público tienen una relación diferente entre anchura y altura. Algunos tamaños comunes son 2 × 3 metros o 4 × 6 pies (relación 2/3); 2.5 × 4 pies o 5 x 8 pies (relación 5/8); o 3 × 5 pies o 6 × 10 metros (relación 3/5).

Según el libro "Our flag" ("Nuestra bandera", en español), de la Cámara de Representantes de los Estados Unidos, ""los colores rojo, blanco y azul no tenían significado para las Barras y Estrellas cuando fue adoptada en 1777"". Sin embargo, sobre los colores del Sello de los Estados Unidos, adoptado en 1782, dice que ""el blanco simboliza pureza e inocencia, el rojo sangre y valor, y el azul el cielo, perseverancia y justicia"".


</doc>
<doc id="42906" url="https://es.wikipedia.org/wiki?curid=42906" title="André Jacques Garnerin">
André Jacques Garnerin

André Jacques Garnerin (París, Francia, 31 de enero de 1769-ibídem, 18 de agosto de 1823) fue un piloto de globos y paracaidista francés.

Garnerin nació en París. Fue hecho prisionero por tropas británicas durante la primera fase de las guerras Napoleónicas (1792–1797), entregado a los austríacos y mantenido en cautividad en Buda (Hungría) durante tres años.

Falleció el 18 de agosto de 1823 a consecuencia del golpe que le dio una viga en la cabeza mientras hacía los preparativos para un vuelo en globo dirigible.

El 22 de octubre de 1797, logró indiscutiblemente el primero de muchos saltos de exhibición en paracaídas (atestiguados) desde su globo de hidrógeno a 350 m de altitud. Su primer salto lo realizó sobre París, Francia, con miles de personas observándolo en el parque de Monceau. El paracaídas de Garnerin estaba hecho de seda y tenía un poste de sostén que hacía que se viera como un enorme paraguas reforzado. Estando parado en una cesta en el extremo del poste, Garnerin lanzaba su paracaídas que oscilaba violentamente (se agitaba de un lado a otro) porque el paracaídas no tenía orificios de ventilación, y el aire debía escapar por un lado y después por el otro.

André Jacques Garnerin es considerado como el primer paracaidista de verdad, habiendo realizado numerosos saltos y entre ellos uno de 8000 pies de altura (aproximadamente 2430 metros) sobre Londres con un paracaídas con campana de seda de unos 7 metros de diámetro.

Su esposa, Genevieve Labrosee, fue la primera mujer en saltar en paracaídas, en el año 1798. Su sobrina Elisa saltó 40 veces entre 1815 y 1836.

En 1804, el astrónomo Jerôme Lalande, que había sido testigo de los experimentos de Garnerin, ideó la válvula o abertura superior, con lo que consiguió reducir las oscilaciones.



</doc>
<doc id="42908" url="https://es.wikipedia.org/wiki?curid=42908" title="Urea">
Urea

La urea es un compuesto químico cristalino e incoloro; de fórmula CO(NH). Se encuentra en mayor proporción en la orina, en el sudor y en la materia fecal. Es el principal producto terminal del metabolismo de las proteínas en el humano y en los demás mamíferos. La orina humana contiene unos 20 g por litro, un adulto elimina de 25 a 39 g diariamente. Es uno de los pocos compuestos orgánicos que no tienen enlaces C-C o C-H.

En cantidades menores, se presenta en la sangre, en el hígado, en la linfa y en los fluidos serosos, y también en los excrementos de los peces y muchos otros animales. También se encuentra en el corazón, en los pulmones, en los huesos y en los órganos reproductivos, así como el semen. La urea se forma principalmente en el hígado como un producto final del metabolismo. El nitrógeno de la urea, que constituye el 80 % del nitrógeno en la orina, procede de la degradación de los diversos compuestos con nitrógeno, sobre todo de los aminoácidos de las proteínas en los alimentos. En los mamíferos la urea se forma en un ciclo metabólico denominado ciclo de la urea. La urea está presente también en los hongos así como en las hojas y semillas de numerosas legumbres y cereales.

Debido a su momento dipolar, la urea es soluble en agua y en alcohol, y ligeramente soluble en éter.

Se obtuvo originalmente mediante la síntesis de Wöhler, que fue diseñada en 1828 por el químico alemán Friedrich Wöhler, y fue la segunda sustancia orgánica obtenida artificialmente, luego del oxalato de amonio.

Se usa para uso industrial, la urea se produce a partir de amoníaco sintético y dióxido de carbono. Como se producen grandes cantidades de dióxido de carbono durante el proceso de fabricación de amoníaco como subproducto de los hirocarburos (predominantemente gas natural, con menor frecuencia derivados del petróleo) u ocasionalmente del carbón, las plantas de producción de urea se encuentran casi siempre adyacentes al sitio donde se fabrica el amoniaco. Aunque el gas natural es la materia prima de amoníaco más económica y más ampliamente disponible, las plantas que lo utilizan no producen tanto dióxido de carbono del proceso como es necesario para convertir toda su producción de amoníaco en urea. En los últimos años, se han desarrollado nuevas tecnologías como el proceso KM-CDR para recuperar dióxido de carbono suplementario de los gases de escape de combustión producidos en el horno de reformado cocido de la planta de gas de síntesis de amoníaco, permitiendo a los operadores de complejos de fertilizantes nitrogenados para evitar la necesidad de manejar y comercializar el amoníaco como un producto separado y también para reducir sus emisiones de gases de efecto invernadero a la atmósfera.

El proceso fundamental, desarrollado en 1922, también se denomina proceso de la urea de Bosch-Meiser en honor a sus descubridores. Diversos procesos comerciales de urea se caracterizan por las condiciones bajo las cuales se forma urea y la forma en que los reactivos no convertidos se procesan adicionalmente. El proceso consiste en dos reacciones de equilibrio principales, con conversión incompleta de los reactivos. La primera es la formación de carbamato: la reacción exotérmica rápida del amoníaco líquido con dióxido de carbono gaseoso (CO) a alta temperatura y presión para formar el carbamato de amonio (HN-COONH):
La segunda reacción es la conversión a urea : la descomposición endotérmica, más lenta, del carbamato de amonio en urea y agua:

La conversión total del NH y CO a urea es exotérmica, y el calor de reacción de la primera reacción dirige a la segunda. 

Como todos los equilibrios químicos, estas reacciones se comportan de acuerdo con el principio de Le Chatelier, y las condiciones que más favorecen la formación de carbamato tienen un efecto desfavorable en el equilibrio de conversión de urea. Las condiciones del proceso son, por lo tanto, un compromiso: el efecto negativo en la primera reacción de la alta temperatura (alrededor de 190 ° C) necesario para el segundo se compensa mediante la realización del proceso a alta presión (140-175 bar), que favorece la primera reacción. Aunque es necesario comprimir el dióxido de carbono gaseoso a esta presión, el amoníaco está disponible en la planta de amoníaco en forma líquida, que se puede bombear al sistema de forma mucho más económica. Para permitir que el lento tiempo de reacción de la formación de urea alcance el equilibrio, se necesita un gran espacio de reacción, por lo que el reactor de síntesis en una gran planta de urea tiende a ser un recipiente de presión masiva.

Debido a que la conversión de urea es incompleta, el producto debe separarse del carbamato de amonio sin modificar. En las primeras plantas "directas" de urea, esto se hizo bajando la presión del sistema a la atmosférica para permitir que el carbamato se descompusiera de nuevo en amoníaco y dióxido de carbono. Originalmente, como no era económico volver a comprimir el amoníaco y el dióxido de carbono para su reciclado, el amoniaco al menos se usaría para la fabricación de otros productos, por ejemplo, nitrato o sulfato de amonio. (El dióxido de carbono usualmente se desperdiciaba). Los esquemas de procesos posteriores hicieron que el reciclaje del amoníaco y el dióxido de carbono no utilizados fueran prácticos. Esto se logró despresurizando la solución de reacción en etapas (primero a 18-25 bar y luego a 2-5 bar) y pasándola en cada etapa a través de un descomponedor de carbamato calentado con vapor, luego recombinando el dióxido de carbono resultante y el amoníaco en una caída - condensador de carbamato de película y bombeo de la solución de carbamato en la etapa anterior.

Los derivados de la urea formados por sustitución de alguno de los hidrógenos se denominan de tres maneras:

Si hay sustituyentes en ambos nitrógenos se pueden utilizar los locantes N y N' o 1 y 3, respectivamente.

Utilizando la electrolisis para descomponer la orina se obtiene como gas (N2-K2-CO3) en el ánodo y (H2) en el cátodo.
La urea es hidrolizada enzimáticamente a dióxido de carbono y amoníaco por la enzima ureasa.



La urea fue descubierta por vez primera en la orina en 1727 por el científico neerlandés Herman Boerhaave, aunque este descubrimiento se atribuye a menudo al químico francés Hilaire Rouelle.

En 1828, el químico alemán Friedrich Wöhler obtuvo urea artificialmente mediante el tratamiento de cianato de plata con cloruro de amonio.

Esta fue la primera vez que un compuesto orgánico era sintetizado artificialmente a partir de materiales de partida inorgánicos, sin la participación de organismos vivos. Los resultados de este experimento implícitamente desacreditaron el vitalismo, la teoría de que los productos químicos de los organismos vivos son fundamentalmente diferentes de los de materia inanimada. Este descubrimiento fue importante para el desarrollo de la química orgánica. Su descubrimiento hizo que Wöhler escribiese triunfante a Berzelius: «... Debo decirle que yo puedo hacer urea sin el uso de los riñones, ni hombre ni de perro. El cianato de amonio es la urea». Por este descubrimiento, algunos consideraran a Wöhler como el padre de la química orgánica.



</doc>
<doc id="42913" url="https://es.wikipedia.org/wiki?curid=42913" title="Historia de Canadá">
Historia de Canadá

Canadá es un país con más de 38 millones de habitantes que ocupa el norte de Norteamérica. Los primeros habitantes de la región fueron diversos pueblos provenientes de Siberia, que llegaron a través del estrecho de Bering, y un poco más tarde llegaron los últimos pueblos inuit (esquimales) provenientes de Asia.

Tras la llegada de los europeos a América, otros países europeos llegaron en busca de nuevas tierras. Colonos de Inglaterra y Francia llegaron a la parte norte de América y lucharon por mantenerse allí. Francia estableció dos colonias a principios del 1600 en lo que es hoy Canadá: Canadá propiamente dicho (o "Quebec") en la margen norte del río San Lorenzo, y la colonia de Acadia (en francés Acadie), en lo que es hoy Nuevo Brunswick y Nueva Escocia. 
Después de varias batallas entre Francia e Inglaterra, estas colonias fueron conquistadas por los ingleses en el siglo XVIII. Sin embargo, pese a que la colonia de Acadie fue destruida y sus habitantes dispersados, la colonia de Québec sobrevivió con derechos reconocidos a mantener su lenguaje y leyes propias francesas, a cambio de la fidelidad al Reino Unido. 

Tras la independencia de Estados Unidos, los colonos ingleses que se mantuvieron leales a la madre patria (el Reino Unido) emigraron a Canadá. A través de tratados con las tribus aborígenes, los colonos se establecieron principalmente en lo que es hoy Ontario.

A diferencia de los Estados Unidos, que lucharon por su independencia, Canadá evolucionó de forma pacífica. A través de un tratado aceptado por la reina Victoria, Canadá se transformó en una federación con autogobierno independiente en 1867. Ahora, los canadienses celebran el «Día de la Reina Victoria» en el tercer lunes de mayo, en agradecimiento y conmemoración al segundo monarca británico de más largo reinado (1837-1901).

Los primeros canadienses fueron los antepasados de los amerindios que llegaron atravesando el estrecho de Bering antes del 20 000 a. C., durante las últimas glaciaciones del Pleistoceno, hacia el 8000 a. C. las tribus indias ya se repartían el territorio del Canadá, en el nordeste micmac, beothuk, cree y ojibwa, al sur iroqueses y hurones, al oeste de los Grandes Lagos los indios de las llanuras y en el oeste tlingit, kwakiutl, haida, tsimshiam y salish (ver amerindios de Canadá para una lista más completa).

Hacia aproximadamente el atravesaron el estrecho de Bering los antepasados de los que formarían la cultura Dorset que fue sustituida por el Thule (pueblo) hacia el año 1000 que dio como resultado a los actuales inuit. Cristóbal Colón y sus hombres no fueron los primeros europeos en pisar América, pues hacia el año 1000 un marinero Vikingo, Bjarni Herjólfsson avistó Norteamérica y tras informar de esa tierra desconocida atrajo a muchos vikingos liderados por el hijo de Erik el Rojo, Leif Eriksson, que iniciaron una Colonización vikinga en América que fue abandonada hacia el 1010 por los combates contra nativos hostiles. Hay información sobre dicha colonización en dos manuscritos de las sagas nórdicas, "La saga de los groenlandeses" y la "Saga de Erik el Rojo". Aunque los vikingos de las colonias de Groenlandia siguieron visitando el norte de Labrador durante siglos después del abandono de sus colonias en América en busca de madera y hierro, no trascendió en Europa el conocimiento de la existencia de América. Estos son algunos de los nombres que los vikingos dieron a los terrenos de América: Vinland (Tierra de vino) que correspondía al golfo de San Lorenzo, Nuevo Brunswick y Nueva Escocia, Helluland, a la isla de Baffin, Markland (Tierra de bosques) correspondía al Labrador. En 1960 se descubrieron las ruinas de un campamento vikingo por el arqueólogo Helge Ingstad en L'Anse aux Meadows, en Terranova que parece coincidir con el llamado campamento Leifsbúðir y que contiene las ruinas de tres habitáculos con capacidad para 80 personas, una herrería, una carpintería y varios talleres para reparar barcos que suman en total ocho edificios. 

La parte oriental del actual territorio de Canadá fue descrita por primera vez en 1498 por el veneciano Juan Sebastián Cabot. Poco después de dicha expedición empezaron a llegar al continente americano los primeros pescadores portugueses, ingleses, franceses y españoles que se habían enterado de la abundancia de bacalao en los bancos de Terranova gracias a la expedición de Cabot, y explorado por Jacques Cartier de 1534 a 1535, el cual navegó por el golfo de San Lorenzo, visitó los emplazamientos de las futuras Quebec y Montreal, conoció las tierras y aguas de la región por los nativos y tomó de ellos la palabra "Canadá", palabra algoquina que significaba aldea. En 1545, los libros y mapas creados por los primeros exploradores europeos comienzan a referirse a esta región como Canadá. Los exploradores ingleses Martin Frobisher en 1576 y Henry Hudson en 1609-1610 trataron de encontrar un paso hacia Asia. 

Desde el siglo XVI los territorios del Canadá recibieron muchas visitas de pescadores desde Europa. Por ejemplo hubo una significativa presencia vasca en Canadá. En 1631 Thomas James fue tras los pasos de Hudson de quien recibió nombre la bahía y escribió "El peligroso viaje del capitán Thomas James". Tras James, el oficial de la Marina Real británica "sir" William Edward Parry tomó parte en varias expediciones entre 1818 y 1824 en busca del Paso del Noroeste, el vicealmirante británico John Franklin dirigió también varias expediciones (1819, 1825, 1845) en busca de dicho paso. 

Entre 1903 y 1906 el explorador noruego Roald Amundsen conquistó el despiadado norte de Canadá y abrió el paso del Noroeste. Mientras la Costa Oeste de Canadá recibía la visita del capitán James Cook en 1778. El siguiente en tener contacto con la zona fue George Vancouver quien entre 1791 y 1795 exploró la zona y descubrió la desembocadura del río Belle Coola siete semanas antes de la llegada del escocés "sir" Alexander Mackenzie.

Los pescadores vascos (principalmente balleneros) comenzaron a pescar en los Grandes Bancos de la costa Atlántica en el siglo XV. A finales del siglo XVI ya se habían establecido 900 personas. Durante la época de mayor auge de la pesca de ballenas, 2000 personas trabajaban cada verano. Pero la operación terminó al comienzo del siglo XVII, ya que las dos especies de ballenas que eran cazadas estaban cerca de la extinción, y muchos de los barcos balleneros eran requeridos por la marina española. Los contactos entre vascos y nativos americanos alcanzaron cierta intensidad al punto que se encuentran algunos préstamos léxicos del vasco en lenguas algonquinas de la península del labrador, y existe evidencia suficiente para decir que la comunicación entre vascos e indígenas dio lugar al surgimiento de un pidgin mixto, conocido usualmente como pidgin vasco-algonquino.

El primer intento de colonizar el Canadá fracasó en 1541. Terranova fue anexionada al Imperio británico por "sir" Humphrey Gilbert en 1583. La primera colonia permanente francesa fue la de Acadia (Nueva Escocia) fundada en 1604 por Samuel de Champlain, siendo seguida en 1608 por la Colonia de Quebec. En 1627 el cardenal Richelieu fundó una compañía por acciones: la Compañía de los Cien Asociados para ser el núcleo de la civilización francesa en el Nuevo Mundo. En 1628, "sir" William Alexander estableció una colonia escocesa en la actual Nueva Escocia. Los franceses fundaron nuevos asentamientos en Trois-Rivières en 1634 y Montreal en 1642. En 1663 bajo el reinado de Luis XIV de Francia la colonia de Nueva Francia pasó a estar bajo la autoridad directa del rey, Jean-Baptiste Colbert ministro de Finanzas impulsó una nueva administración para la provincia similar a la de Francia, el comercio de pieles en Nueva Francia fue otorgado como monopolio a la Compañía de las Indias Occidentales. En 1670 se fundó la Compañía de la Bahía de Hudson para permitir al Imperio británico explotar la región pero sus bases cayeron ante una expedición francesa en 1686. Desde Nueva Francia se mandaron varias expediciones, la de Louis Jolliet y Jacques Marquette en 1673 encargada de explorar el río Misisipi y la de René Robert Cavelier en 1682 para tratar de obtener Luisiana. En 1689 las luchas dinásticas en Europa provocaron el inicio de una guerra entre las colonias inglesas y francesas de América que terminó en 1713 con el Tratado de Utrecht cediendo los franceses Terranova y la bahía de Hudson, reteniendo la isla de Cabo Bretón y la isla del Príncipe Eduardo. El tratado no impidió nuevas escaramuzas entre las potencias coloniales en 1744, los conflictos entre ambos llevaron a una guerra abierta entre los 2 países en 1754 en el valle del Ohio que se llegó al máximo en 1756 con la Guerra de los Siete Años.

La Guerra de los Siete Años consistió en una serie de conflictos comerciales y coloniales entre franceses e ingleses que dieron como resultado una guerra que afectó a Europa y a sus colonias. En América del Norte la creciente inmigración aumentó la presión de los 400 000 colonos ingleses sobre los territorios franceses, escasamente poblados por 70 000 colonos, pero fuertemente protegidos por fortines. Las constantes escaramuzas se transforman en 1754 en un conflicto armado en el valle del Ohio. Inicialmente Gran Bretaña sufrió una derrota en Fort Duquesne y fracasó al intentar tomar Crown Point en 1755. Los contraataques franceses tuvieron éxito al tomar Fort William Henry, Fort George y Fort Oswego en 1756. Pero las fuerzas francesas dirigidas por el General Louis-Josep de Saint-Véran, marqués de Montcalm no tardaron en verse incapacitadas de recibir ayuda desde la metrópolis de Francia debido al bloqueo de la Marina Real británica. Pese a todo los franceses lograron derrotar a los ingleses en Ticonderoga en 1758. Los británicos liderados por James Wolfe lograron derrotar a las tropas del marqués de Montcalm, en las llanuras de Abraham, cerca de Quebec en 1759 tomando la ciudad y muriendo el marqués de Montcalm y James Wolfe en la batalla. El 8 de septiembre de 1760 cae Montreal y los ingleses ocupan totalmente la colonia de Nueva Francia. El Tratado de París (1763) del 10 de febrero de 1763 hace que Francia abandone sus posesiones en América del Norte excepto las islas San Pedro y Miguelón y conservando derechos de pesca en las proximidades de Terranova. La mayoría de colonos franceses decidió permanecer en Quebec pese a ser una colonia inglesa.
Bajo el gobierno británico la población creció rápidamente. Durante la Guerra de Independencia de los Estados Unidos, y terminada la contienda, miles de leales a la corona se refugiaron en Canadá especialmente en Nueva Escocia, lo cual obligó a crear la colonia de Nuevo Brunswick en 1784 para acomodar a los 50 000 lealistas. Al final de la guerra en 1783 Canadá se vio forzado a ceder Míchigan a los Estados Unidos, en 1791 se divide el Canadá en Superior (Ontario) e Inferior (Quebec). El deseo de muchos ciudadanos de los Estados Unidos de expulsar de América a los ingleses y el resentimiento que sentían los leales contra la nueva nación de los Estados Unidos por su expulsión del suelo de las antiguas Trece Colonias amenazaban con una guerra que estuvo a punto de producirse en 1794 que finalmente se inició en 1812 y terminó en 1814 con la firma del Tratado de Gante en el 24 de diciembre de 1814. En 1818 se fijara la frontera entre Estados Unidos y Canadá en el paralelo 49, lo que obliga a Canadá a abandonar su colonia del Red River al sur de dicho paralelo (fundada en 1812) y obliga a llevar a cabo una ocupación conjunta de Oregón hasta su cesión a los Estados Unidos en 1846. Mientras tanto, la exploración del territorio sigue su curso y en 1789 Alexander Mackenzie llega a la cabecera del río que lleva su nombre y en 1793 llega al Pacífico por tierra, las exploraciones llevadas a cabo por Simon Fraser y David Thompson entre otros fueron permitiendo conocer grandes extensiones de lo que seria la Columbia Británica. Tras resolverse los problemas entre compañías de comerciantes de pieles en 1821 se produjo la fusión entre la Compañía del Noreste y la Compañía de la Bahía de Hudson. Llegaron muchos inmigrantes desde Gran Bretaña especialmente de Escocia a partir de 1815 y a partir del 1825 llegaron muchos del sur a través del Canal del Eire que unía los Grandes Lagos y Nueva York. En 1837 se produjeron una serie de pequeñas rebeliones :la de Louis-Joseph Papineau en Montreal y la de William Lyon Mackenzie en Toronto. Se mandó a Lord Durham (John George Lambton) a solucionar esta situación y recomendó que se aumentase el autogobierno y se unificase los dos Canadás, la unión se hizo con dificultades y finalmente se aprobó el aumento del autogobierno, dándose la misma representación a ambos territorios en la Cámara de Representantes. En 1846 se decidió trasladar el límite occidental de las montañas Rocosas al Pacífico, el descubrimiento de oro en el río Fraser en 1858 estimuló la creación de la Columbia Británica. La firma del Tratado de Reciprocidad con Estados Unidos (1854-1866) produjo un crecimiento industrial. La Guerra de Secesión de los Estados Unidos (1861-1865) parecía amenazar la supervivencia de la Norteamérica Británica, pues se creía que un Norte victorioso se vengaría del apoyo británico al Sur invadiendo las colonias británicas. Eso, unido a motivos económicos, provocó una serie de reuniones entre políticos provinciales en Charlottetown y Quebec en 1864, en el curso de los cuales se decidió crear la Confederación Canadiense que se hizo realidad en 1867 con el Acta de la Norteamérica británica, uniéndose a ella Quebec, Ontario, Nuevo Brunswick y Nueva Escocia. Canadá sufrió ataques de 1866 a 1870 por parte de la Hermandad Feniana, rama americana de la Hermandad Republicana Irlandesa, que buscaba cambiar la política británica sobre la independencia de Irlanda, su primer ataque fue en Fort Eire.

La Confederación fue llamada Dominio del Canadá y continuó sometida a la autoridad absoluta de la corona británica, en 1869 se produjo una rebelión encabezada por Louis Riel, en 1870 tras el fracaso de la revuelta se crea la provincia de Manitoba. El primer ministro, "sir" John Alexander Macdonald elegido en 1867 gobernaba según el censo de 1871 sobre 3,7 millones de habitantes, de los que las 3/4 eran población rural, Macdonald extendió Canadá añadiéndose la Columbia Británica el 20 de julio de 1871 con la condición de que en 10 años la Canadian Pacific Railway lograría que el ferrocarril atravesase la provincia, la isla del Príncipe Eduardo se unió a la Confederación en 1873. Macdonald fue vencido por los liberales liderados por Alexander Mackenzie (político) pero gracias a la crisis económica fue reelegido en 1878. El ferrocarril transcontinental se terminó en 1885, lo que provocó una rebelión en Saskatchewan liderada por Louis Riel que no tardo en ser sofocada, los primeros servicios transcontinentales empezaron en 1886. El Primer Ministro John A. Macdonald organiza una política descrita como "etnocida" hacia los amerindios de las llanuras centrales del país para apropiarse de sus tierras, causando intencionadamente hambrunas, ejecuciones arbitrarias y asimilación forzada de niños. "Sir" John Alexander Macdonald murió en el 6 de junio de 1891 dejando sin un líder eficaz a los conservadores, las elecciones de 1896 fueron ganadas por los liberales encabezados por el abogado francocanadiense Wilfrid Laurier, también en 1896 se produjo una fiebre del oro en el Yukón al descubrirse oro en el río Klondike. Canadá tuvo una participación simbólica en la Guerra de los Bóeres, en 1905 Alberta y Saskatchewan se convirtieron en provincias en 1912-1914 las compañías petrolíferas empezaron a extraer petróleo de Alberta. En 1911 se nombró nuevo primer ministro al conservador "sir" Robert Laird Borden, durante su mandato la inmigración anual aumentó hasta las 400 000 personas. A partir de 1914 nuevas cepas más resistentes de trigo permitieron a Canadá ser uno de los mayores exportadores de trigo.

El primer ministro conservador, "sir" Robert Laird Borden, respondió a la guerra en Europa movilizando a cientos de miles de voluntarios, pues de los ocho millones de habitantes 620 000 partieron a la guerra, muriendo en ella 57 000 soldados. Tropas canadienses fueron desplegadas en Rusia, Gran Bretaña, Francia, Salónica, Mesopotamia y Palestina. Terranova contribuyó con 12 000 hombres, de los que murieron 1000, y que fueron destinados a Escocia, Bélgica, Francia y Galípoli. Tropas canadienses se distinguieron durante la batalla por la cresta de Vimy al tomar la colina el 15 de abril de 1917 y en la tercera batalla de Ypres al tomar la ciudad de Passchendaele el 30 de octubre de 1917. Las tropas canadienses estuvieron bajo mando británico y formadas por voluntarios hasta 1917 en que se pusieron bajo mando canadiense y se empezó a llamar a filas, lo que motivó protestas en especial entre los francocanadienses, eso motivó disturbios en Quebec que se saldaron con cuatro muertos cuando las tropas abrieron fuego. El 18 de agosto de 1918 tropas canadienses y australianas se abrieron paso entre las líneas enemigas cerca de Amiens, obligando a los soldados alemanes a retroceder hasta Mons donde el 11 de noviembre de 1918 se rendiría el ejército de Alemania terminando con la Primera Guerra Mundial. Durante la guerra Canadá también contribuyó con 30 000 mulas y caballos a la Caballería aliada, un total de 556 barcos mercantes salieron del puerto de Halifax (Nueva Escocia) rumbo a Gran Bretaña y Canadá gastó 1670 millones de dólares.

La década del 1920 fue de gran prosperidad para el Canadá el primer ministro liberal William Lyon Mackenzie King se esforzó en conseguir que el Canadá obtuviese el mismo autogobierno que Gran Bretaña, lo cual se reconoció en la Conferencia Imperial de 1929, siendo confirmado por el Parlamento británico en el Estatuto de Westminster 1931. La Gran Depresión de 1929 afecto enormemente a Canadá, impulsada por el colapso del mercado del trigo, pues la caída del preció del trigo hizo más barato comprarlo a Argentina, Australia o la Unión Soviética, esto provocó la victoria del conservador Richard B. Bennett en 1930, el producto nacional bruto bajo de 6100 millones de dólares en 1929 a 3500 millones en 1933, la producción industrial bajó a la mitad en el mismo periodo y en 1933 el 20 % de la población activa estaba desempleada, durante ese tiempo las peores situaciones se vivieron en las Praderas donde en 1931 vientos huracanados arrancaron la capa superficial del suelo, en 1932 una plaga de langostas devoro las cosechas y 1933 señaló el inicio de una época de malas cosechas por culpa del clima, eso provoca la fundación del Cooperative Commonwealth Federation (CCF) que más tarde se transformaría en el New Democratic Party el partido socialista de Canadá. Los liberales obtuvieron una victoria aplastante en 1935 y William Lyon Mackenzie King volvió a ser primer ministro. Pese a seguir una política aislacionista durante la década de 1930 Canadá se unió a Gran Bretaña al declarar la guerra hacia Alemania el 10 de septiembre de 1939.

Al principio de la guerra el ejército canadiense constaba de 4500 soldados y 51 000 reservistas sin equipo moderno, la Aviación Real del Canadá constaba de 20 escuadrones de aviones modernos y la Marina Real de Canadá tenía 6 destructores y muchos barcos más pequeños, las fuerzas armadas canadienses fueron rápidamente a ayudar a Gran Bretaña, en diciembre de 1939 las primeras tropas ya estaban en ruta, mientras 250 000 canadienses se alistaban como voluntarios en el ejército, Canadá puso su marina al servicio de la Gran Bretaña y mando 10 escuadrones de cazas antes del fin de 1940 que tomaron parte en la batalla de Inglaterra, siendo el principal apoyo de Gran Bretaña hasta la intervención de los Estados Unidos en 1941. El puerto de Halifax (Nueva Escocia) fue el principal punto de creación de convoyes para la peligrosa travesía del Atlántico, durante toda la batalla del Atlántico la Marina Real Canadiense y la marina mercante canadiense fueron cruciales para la victoria aliada. La Marina Real Canadiense llegó a enrolar al final de la guerra a 106 500 marineros que tenían 471 naves de guerra, la marina real hundió 28 submarinos enemigos y muchos barcos enemigos, perdiendo 24 naves y 2000 marinos, 12 000 canadienses sirvieron en la marina mercante de los que murieron 1600.

En noviembre de 1941 Canadá mandó 1975 soldados a Hong Kong, el 7 de diciembre de 1941 Japón entró en la guerra y el 8 de diciembre Hong Kong, fue atacado y se vio forzado a rendirse el 25 de diciembre, muriendo 290 canadienses durante los combates y otros 300 antes del final de la guerra. 

El 19 de agosto de 1942 tropas canadienses con apoyo de comandos británicos tomaron parte en la batalla de Dieppe, el asalto fue un fracaso debido a la resistencia alemana y de Dieppe (Sena Marítimo) solo volvieron a Gran Bretaña 2110 de los 5000 canadienses que participaron. Canadá contribuyó con 300 bombarderos pesados a los bombardeos sobre Europa. 

De 1939 a 1945 la Aviación Real del Canadá enroló a 249 000 hombres y organizó 86 escuadrones, de ellos 47 en el extranjero y perdió en combate a 17 000 hombres. En abril de 1942 el gobierno federal organizó un referéndum para permitir el reclutamiento forzoso que fue aprobado pese a muchos votos en contra de los francocanadienses, uno de los que se opusieron al reclutamiento forzoso fue Pierre Elliott Trudeau que sería primer ministro del Canadá. 

No fue preciso llevar a cabo el alistamiento forzoso hasta noviembre de 1944, en 1944-1945 se reclutó a 29 000 soldados por lo que el grueso del ejército canadiense estuvo formado por voluntarios. En 1943 1,5 millones de canadienses trabajaban en las fábricas de municiones lo que les permitió terminar de recuperarse de los efectos de la Gran Depresión. Tropas canadienses tomaron parte en la invasión de Sicilia y tomaron parte en la invasión de Italia en septiembre de 1943, en diciembre las tropas canadienses toman Ortona al sur del Adriático en una batalla casa por casa. En 1944 Canadá reforzó sus tropas en Italia y creó el 1º Cuerpo de Ejército Canadiense, tropas canadienses rompieron la línea Hitler al sur de Roma y la línea Gótica más al norte. En febrero de 1945 el 1º Cuerpo de Ejército Canadiense se desplazó al noroeste de Europa, 93 000 canadienses sirvieron en Italia y 5300 murieron en ella.

Canadá tuvo un papel importante en el día D el 6 de junio de 1944, pues como parte de la batalla de Normandía 14 000 canadienses asaltaron y ocuparon la playa de Juno, la Marina Real Canadiense sostuvo el desembarco con 110 naves y 10 000 marinos y la Aviación Real del Canadá contribuyó con 15 escuadrones de cazas y cazabombarderos también hubo canadienses entre los paracaidistas que se lanzaron al este de las cabezas de desembarco, murieron 359 canadienses durante esta batalla. En el 16 de julio, tropas canadienses contribuyeron en la conquista de Caen y tomaron parte en la batalla por Falaise en que con un movimiento de pinza con los franceses y estadounidenses logrando rodear a gran parte de las tropas alemanas en la bolsa de Falaise y hacer que se rindieran en el 21 de agosto. 

En septiembre de 1944 tropas canadienses se dirigieron al norte y conquistaron Boulogne-sur-Mer y Calais, en abril de 1945 tropas canadienses liberaron gran parte de Bélgica, el 5 de mayo Oldenburg en el norte de Alemania fue ocupada por tropas canadienses. La guerra en Europa terminó el 8 de mayo de 1945 con la victoria de los aliados. Frente a la amenaza del Japón, Canadá respondió con el despliegue de 30 000 soldados, 14 escuadrones de aviación y 20 naves de guerra en la Columbia Británica. Canadá cooperó con los Estados Unidos para expulsar a los japoneses de las Aleutianas, antes de la rendición de Japón el 14 de agosto de 1945 un crucero canadiense el NCSM Uganda tomó parte en las batallas del Pacífico, diez escuadrones transportaron aprovisionamientos en la India y Birmania y especialistas en comunicaciones sirvieron en Australia. 

Durante la guerra miles de canadienses de origen japonés (15 000-22 000) fueron internados en especial los que vivían en la Columbia Británica y sus bienes fueron subastados, en 1945 se les dio a escoger entre instalarse al este de las montañas Rocosas o ser deportados a Japón, 10 000 se decidieron por la expulsión y cuando en el 1947 el gobierno canadiense cambio de idea la inmensa mayoría de los 4000 deportados escogió no volver a Canadá. 731 000 canadienses sirvieron en el ejército de los que 16 000 formaron parte de las fuerzas de ocupación de Alemania. Canadá perdió a 23 000 soldados de su ejército, 17 000 de su aviación, 2000 de su marina y 1600 de su marina mercante sobre un total de 43 600 a los que hay que sumar 700 muertos de Terranova.

Se descubrieron nuevos depósitos de petróleo en Alberta y nuevas reservas de mineral de hierro en Ungava al norte de Quebec durante la década de 1940. En la década siguiente los recursos de uranio se desarrollaron en el norte de Ontario y se construyen centrales energéticas por todo el país. Después de las elecciones de 1948 William Lyon Mackenzie King tras ser primer ministro 22 años fue sustituido por el liberal Louis St. Laurent. En 1949 Terranova y Labrador se unieron a la Confederación Canadiense. Durante 1950-1960 se dobló la población llegando a los 18 millones de habitantes en gran parte gracias a los 1,5 millones de inmigrantes que llegaron, en su mayoría europeos. En 1949 Canadá ingresó en la OTAN. Canadá lucho en la Guerra de Corea (1950-1953) bajo mandato de la ONU. En 1951 tropas canadienses fueron mandadas a Europa. Canadá tuvo un papel activo en la creación de la Fuerzas de Paz de la ONU en 1956 tras la Guerra del Sinaí al presentar el ministro de asuntos exteriores de Canadá Lester Bowles Pearson ante la Asamblea General de la ONU la propuesta de mandar un contingente de paz para solucionar el conflicto. La elección del conservador John George Diefenbaker en 1957 fue seguida de una victoria aplastante en 1958 tras unas elecciones anticipadas. En 1960 los liberales ganaron por primera vez las elecciones provinciales de Quebec siendo escogido Jean Lesage como gobernador.

Las elecciones de 1962 vieron un retroceso de los conservadores y en 1963 John George Diefenbaker fue derrotado y sustituido por el liberal Lester B. Pearson, que gobernó en minoría, durante la década de 1960 se vivió un auge del independentismo en Quebec que se tradujo en la creación del radical Front de libération du Québec (FLQ) apoyado por Francia y el moderado Parti Québécois (PQ) fundado en 1968 bajo el mando de René Lévesque. Las elecciones de 1965 no lograron aclarar la situación política. Se celebró la Exposición Universal de Montreal 1967 ese mismo año el presidente francés Charles de Gaulle visitó Quebec dando apoyo a los independentistas. Las elecciones de 1968 fueron ganadas por el liberal Pierre Elliott Trudeau, en 1969 se aprobó la Ley del Idioma Oficial que establece la igualdad entre el francés y el inglés en toda actividad gubernamental. En abril de 1970 las elecciones en Quebec arrojaron un 24 % de votos independentistas y una mayoría absoluta del Partido Liberal de Canadá. En octubre de 1970 el Front de libération du Québec secuestro al diplomático británico James Cross y al Ministro de Trabajo de Quebec, Pierre Laporte provocando la Crisis de octubre, el gobierno federal declaró la ley marcial (que estaría vigente en Quebec hasta abril de 1971) y se ilegalizo al FLQ, Pierre Laporte fue asesinado y James Cross fue liberado de mientras los terroristas huían en avión a Cuba. Tras las elecciones de 1972 el Partido Liberal de Canadá sigue en el poder aunque sin mayoría absoluta. Las elecciones de Quebec de octubre de 1973 dieron el triunfo al liberal Robert Bourassa. Los liberales recuperaron la mayoría absoluta en las elecciones anticipadas de julio de 1974. Las elecciones en Quebec del 15 de abril de 1979 dieron un gran triunfo al Parti Québécois de René Lévesque. En las elecciones del 22 de mayo de 1979 triunfó el Partido Conservador Progresista de Canadá de Joe Clark. En las elecciones del 18 de febrero de 1980 el Partido Liberal de Canadá obtuvo una gran victoria y Pierre Elliott Trudeau recuperó el cargo de primer ministro, el 20 de mayo de 1980 se votó en referéndum la opción de negociar una "soberanía asociada" para Quebec que solo cosechó un 40 % de votos a favor, eso no evitó que las elecciones de abril de 1981 en Quebec fueran ganadas por el Parti Québécois.

Entre los años sesenta y ochenta, 20.000 niños aborígenes fueron secuestrados de sus familias y colocados con familias no aborígenes.

En 1981 el Parlamento elaboró una nueva Constitución que fue proclamada en Ottawa el 17 de abril de 1982 por la reina Isabel II del Reino Unido, pero Quebec no ratifico la nueva constitución. Debido a la crisis económica Pierre Elliott Trudeau dimitió en 1984 siendo sustituido por John Napier Turner, la continuación de la crisis económica llevó al Partido Conservador Progresista de Canadá a una victoria avasalladora en las elecciones de septiembre de 1984 siendo el nuevo primer ministro Brian Mulroney. Para resolver la crisis constitucional se reunieron los gobernadores de todas las provincias y firmaron el Acuerdo del Lago Meech el 3 de julio de 1987 por el que Quebec se unía a la constitución de 1982 como "sociedad distinta", Canadá firmó el Tratado de Libre Comercio de América del Norte con Estados Unidos en 1988 que incluía la supresión de las tarifas aduaneras en 1998 como paso previo para lograr la unión económica. Las elecciones de noviembre de 1989 fueron ganadas por los conservadores y el tratado de libre comerció fue ratificado por el Parlamento en enero de 1989. Pero los problemas constitucionales se mantenían pues en el 29 de junio de 1990 Nuevo Brunswick, Manitoba y Terranova se negaban a ratificar el Acuerdo del Lago Meech que quedó en suspenso. Eso forzó a una nueva reforma constitucional para responder a las aspiraciones de todas las provincias que se concretó en el Acuerdo de Charlottetown el 22 de agosto de 1992, el cual se hizo pasar por referéndum el 26 de octubre de 1992 siendo rechazado al obtener solo el 42 % de votos a favor y obteniendo el rechazo de seis provincias, también en octubre se firmó la ampliación del Tratado de Libre Comercio de América del Norte a México. En mayo de 1992 se aprobó una decisión gubernamental para crear en los Territorios del Noroeste un espacio con gobierno propio para los Inuit.

En febrero de 1993 debido a una mezcla de problemas económicos y discordia política Brian Mulroney dimitió y fue sustituido como Primer Ministro y jefe del Partido Conservador Progresista de Canadá por Kim Campbell el 13 de junio de 1993, siendo la primera mujer en ocupar el cargo de Primera Ministra de Canadá. En las elecciones generales del 25 de octubre de 1999, el Partido Liberal de Canadá obtuvo una victoria increíble (el gobernante Partido Conservador Progresista de Canadá pasó de 153 a 2 escaños) eso permitió al liberal Jean Chrétien tomar las riendas del gobierno. Durante la década de 1990 tropas canadienses formaron parte de muchas misiones de las Fuerzas de Paz de la ONU, en Sáhara Occidental, Camboya, la antigua Yugoslavia, Haití, Timor Oriental y Sierra Leona, durante la misión de la ONU en Somalia en 1993 soldados canadienses torturaron hasta la muerte al adolescente somalí Shidane Arone produciendo el Asunto de Somalia que dio como resultado la disolución del regimiento de élite del Canadian Airbone Regiment y dañando la reputación del ejército canadiense. Las elecciones de Quebec en septiembre de 1994 dieron la victoria al Parti Québécois eso les permitió llevar a cabo un nuevo referéndum sobre la independencia de Quebec en 1995 que perdió por una diferencia del 1,12 % (50 000 votos) y registró un 93 % de participación. También en 1995 hubo un enfrentamiento pesquero con España y la Unión Europea a causa de los derechos de pesca del fletan negro en aguas del Atlántico Noroccidental, un conflicto que se saldó con una revisión de las cuotas de pesca y la retirada de una ley que otorgaba a Canadá jurisdicción más allá de las 200 millas. Las elecciones nacionales de 1997 dieron como ganador a Jean Chrétien y el Partido Liberal de Canadá. En enero de 1998 una tempestad de agua helada en Ontario, sureste de Quebec y Nuevo Brunswick dejó sin luz a centenares de miles de hogares, provocó 15 muertos, miles de damnificados e interrumpió los servicios públicos en la peor catástrofe natural de la historia de Canadá. A petición del gobierno federal el Tribunal Supremo dictaminó en el 19 de agosto de 1998 que al no ser una colonia ni estar militarmente ocupado Quebec no puede declarar unilateralmente su independencia, pero el dictamen añadió que si ante una pregunta inequívoca la mayoría de quebequeses se pronunciaba a favor de la independencia el resto de Canadá estaría obligado a negociar con Quebec. En las elecciones en Quebec del 30 de noviembre de 1998 venció el Parti Québécois de Lucien Bouchard. El 1 de abril de 1999 entró en funciones el gobierno de un nuevo territorio del Canadá, Nunavut.




</doc>
<doc id="42914" url="https://es.wikipedia.org/wiki?curid=42914" title="Bloque Nacionalista Galego">
Bloque Nacionalista Galego

El Bloque Nacionalista Galego (BNG, en castellano 'Bloque Nacionalista Gallego') es una formación política española cuya ideología se fundamenta en el nacionalismo gallego y el independentismo gallego de izquierda. Su principal ámbito territorial se circunscribe a la comunidad autónoma de Galicia aunque se ha presentado a las elecciones generales españolas ininterrumpidamente desde 1986 y a las elecciones al parlamento europeo desde 1987, en solitario o en coalición con otros partidos. El independentismo tiene amplio apoyo entre su militancia, especialmente en su sector juvenil Galiza Nova.

Adopta el enfoque de "frente", no de coalición, aunque actualmente está reconocida la participación de los partidos Unión do Povo Galego (UPG), Movemento Galego ao Socialismo (MGS) y Fronte Obreira Galega (FOGA), así como del colectivo Abrente-Esquerda Democrática Galega. No obstante, la mayor parte de la militancia (70 %) está compuesta por afiliados independientes.

Su presencia institucional actual está compuesta por 486 concejales, 15 diputados provinciales, 19 diputados autonómicos y las alcaldías de varias ciudades, como la de Pontevedra, una de las siete grandes ciudades gallegas.
En las elecciones generales de noviembre de 2019 consiguió un escaño, lo que provocó su vuelta al Congreso de los Diputados.

En la década de 1960 se fundaron la Unión do Povo Galego (UPG) y el Partido Socialista Galego (PSG), partidos nacionalistas de carácter comunista y socialista, respectivamente. En 1975 se fundó la Asemblea Nacional-Popular Galega (AN-PG), un frente impulsado por la UPG como plataforma de movilización social y base para el futuro establecimiento de una candidatura electoral nacionalista.

En octubre de 1981 se celebraron las primeras elecciones al Parlamento de Galicia, a las que UPG y el PSG concurrieron en coalición como Bloque Nacional-Popular Galego (BNPG-PSG). Las elecciones fueron ganadas por Alianza Popular (AP) y los partidos nacionalistas consiguieron un resultado bastante discreto, con tan solo tres escaños. Estos diputados se negaron a jurar la Constitución de 1978 y a la tercera negativa fueron expulsados del Parlamento.

El 26 de septiembre de 1982 tuvo lugar en La Coruña la Asamblea Constituyente del BNG, que agrupaba a la AN-PG, la UPG, el PSG y otros colectivos independientes. Sin embargo, un año después, en 1983, el PSG abandonó el BNG (no obstante, un nutrido grupo de militantes del PSG permaneció en el BNG). El PSG se fusionaría con Esquerda Galega. En las elecciones autonómicas de 1985 el BNG solo consiguió un escaño (Xosé Manuel Beiras) con 52.000 votos, mientras que Coalición Galega, un partido galleguista de centro, consiguió once escaños, con tres escaños para el Partido Socialista Galego-Esquerda Galega. Las elecciones las volvió a ganar AP bajo el nombre de Coalición Popular de Galicia.

En 1986 el BNG hizo campaña por el «no» a la OTAN. Ese mismo año, la UPG sufrió una escisión, creándose el Partido Comunista de Liberación Nacional (PCLN), de carácter independentista y comunista, el cual permaneció, sin embargo, en el BNG. En ese momento, el BNG se encontraba en una encrucijada y tuvo que escoger qué dirección política adoptar, tomando un camino más moderado. El BNG, liderado por Beiras, se alejó del radicalismo en un esfuerzo para ganar más apoyo electoral. En la III Asamblea del BNG, celebrada en 1987, el PCLN (que después formaría el Frente Popular Galega) fue expulsado del BNG por apoyar a Herri Batasuna en las elecciones al Parlamento Europeo de ese año.

En 1988 se creó la organización juvenil del BNG, Galiza Nova. En las elecciones autonómicas de 1989 consiguió por primera vez grupo parlamentario propio en el Parlamento de Galicia, con el 8 % de los votos y cinco escaños. En las mismas elecciones, ni el Partido Nacionalista Galego-Partido Galeguista (PNG-PG) ni el Frente Popular Galega (FPG) obtuvieron escaño alguno. En cambio, la coalición entre el PSG y EG consiguió dos escaños.

Durante los siguientes años el BNG experimentó un gran crecimiento en cuanto a organización y resultados electorales. Así, en 1991 el PNG-PG se unió al BNG, Esquerda Nacionalista lo hizo al año siguiente e Inzar en 1993. En las elecciones autonómicas de 1993 el BNG consiguió trece diputados, con el 18,5 % de los votos. Tras su fracaso en esas elecciones, Unidade Galega (antiguo PSG-EG) también se incorporó al BNG, que vivía su época dorada y en las elecciones generales de 1996 consiguió dos escaños en el Congreso de los Diputados. En las elecciones autonómicas de 1997 se convirtió por primera vez en la segunda fuerza política gallega, por delante del PSdeG-PSOE, con el 24,8 % de los votos y dieciocho escaños, y en las elecciones al Parlamento Europeo de 1999 llegó a obtener un eurodiputado, Camilo Nogueira Román. En las elecciones generales de 2000 fueron ya tres los diputados del BNG en el Congreso.

Sin embargo, el BNG parecía haber llegado a su techo y en las elecciones autonómicas de 2001 el BNG (22,6 % de los votos) y el PSdeG-PSOE consiguieron el mismo número de escaños: diecisiete. En la XI Asamblea del BNG, celebrada en noviembre de 2003 se produjo un cambio, relevando Anxo Quintana a Beiras como portavoz nacional y candidato a la presidencia de la Junta de Galicia.

En las elecciones generales de 2004 el BNG sufrió una crisis debida al continuo retroceso en votos, ya que solo consigue dos escaños en el Congreso de los Diputados y ninguno en el Senado (si bien por la cuota parlamentaria autonómica fue escogido senador por el BNG Francisco Jorquera). La crisis se agravó con las elecciones al Parlamento Europeo, en las que, después de presentarse en coalición con el Partido Nacionalista Vasco (PNV) y Convergència i Unió (CiU) en la coalición Galeusca, se quedó sin eurodiputados. En julio de 2004, Anxo Quintana estableció cambios en la cúpula del BNG.

Tras las elecciones autonómicas de 2005, que certifican un nuevo retroceso del BNG (obteniendo trece escaños), la pérdida de la mayoría absoluta por parte del PP de Manuel Fraga permitió la entrada del BNG en un gobierno de coalición presidido por el socialista Emilio Pérez Touriño, en el que el BNG obtuvo una vicepresidencia (que incluía las consejerías de Relaciones Institucionales y Bienestar Social), y que ocupó Anxo Quintana. Asimismo, el BNG obtuvo las consejerías de Cultura, Industria, Medio Rural y Vivienda, de nueva creación. Tras cuatro años de gestión, la posibilidad de reeditar el gobierno bipartito junto con el PSdG-PSOE se perdió tras recuperar el PP la mayoría absoluta parlamentaria en las elecciones de 2009, siendo nombrado Alberto Núñez Feijoo como nuevo presidente.

En la XII Asamblea Nacional, celebrada en Santiago de Compostela los días 2 y 3 de diciembre de 2006, se presentaron cuatro candidaturas al Consejo Nacional:

Tras la votación se llegó la un acuerdo entre las diferentes candidaturas para la repartición de los miembros de la Ejecutiva Nacional. La candidatura oficial ocupó diez de los quince miembros y los otros cinco se repartieron entre Encontro Irmandiño y "A Alternativa"; el Movemento pola Base apoyó el acuerdo a pesar de quedar fuera de la Ejecutiva. También se decidió modificar la composición de la siguiente Asamblea Nacional para que fuera por delegados y no como ahora abierta a todos los militantes.

En las elecciones municipales de mayo de 2007, el BNG obtuvo el 19,15 % de los votos. Agudiza su caída en las grandes ciudades, descenso que es compensado con contundentes victorias en localidades de tamaño medio como Carballo, Arzúa, Teo, Monforte de Lemos, Bueu, Porriño o Puentecesures, ocupando espacios rurales y sociales que va abandonando el Partido Popular. El estancamiento se compensa con perspectivas de mayor poder institucional en ayuntamientos y diputaciones provinciales (donde los socialistas presiden, con apoyo nacionalista las de La Coruña y Lugo).

En las elecciones generales de marzo de 2008, el BNG mantuvo sus porcentajes de voto y su representación institucional. Con 209.042 votos (12,07 %), frente a los 208.688 (11,37 %) de 2004, obtuvo dos diputados, uno por La Coruña y otro por Pontevedra.

En las elecciones al Parlamento de Galicia de 2009 el BNG obtuvo doce diputados (un diputado menos que los conseguidos en la anterior convocatoria), correspondientes al 16,57 % de los votos. Obtuvo cuatro diputados por La Coruña, dos por Lugo, dos por Orense y cuatro por Pontevedra. Obtuvo el peor resultado desde las elecciones de 1989, prosiguiendo el sostenido descenso desde su techo electoral obtenido en 1997, por lo que Anxo Quintana y los otros catorce miembros de la ejecutiva presentaron su dimisión conjunta ante el Consejo Nacional el 14 de marzo de 2009.

El 18 de abril de 2009 se realizaron asambleas comarcales para elegir a los delegados que acudirían a la Asamblea Nacional Extraordinaria convocada para el 10 de mayo. Hubo tres listas principales, "Alternativa pola Unidade" (ApU), "Listas Abertas" y "Máis BNG", así como otras listas en algunas comarcas puntuales, como Independentes do Val Miñor, Movemento Galego ao Socialismo, Esquerda Socialista Galega e Independentes do Ribeiro.

El 10 de mayo se celebró la Asamblea Nacioanl Extarordinaria, en la cual se presentaron cuatro candidaturas al Consejo Nacional:

En la votación a la Ejecutiva Nacional, "Encontro Irmandiño" no se presentó y "Máis Alá" apoyó la lista de ApU, siendo el resultado final 1.189 votos (55,1 % ) y ocho representantes para la lista encabezada por Guillerme Vázquez (seis de UPG, uno de "Máis Alá" y dos independientes), y 969 votos (44,9 %) y siete representantes para la lista de Carlos Aymerich; así, Guillerme Vázquez resultó elegido portavoz nacional del Bloque Nacionalista Galego, en sustitución de Anxo Quintana.

El 26 de enero de 2012 se celebró su XIII Asamblea Nacional, en la que se eligió la dirección, así como su portavoz nacional y su candidato a la Xunta. Se presentaron tres listas: "Alternativa pola Unidade" (ApU), con el apoyo de Unión do Povo Galego y con Guillerme Vázquez para portavoz y Francisco Jorquera para candidato; una lista encabezada por Máis Galiza y Encontro Irmandiño (+G-EI), con el apoyo de Colectivo Socialista, Partido Nacionalista Galego-Partido Galeguista, Esquerda Nacionalista, Inzar, Unidade Galega y Espazo Socialista Galego, con Xosé Manuel Beiras para portavoz y Carlos Aymerich para candidato; y una lista de Movemento Galego ao Socialismo, encabezada por Rafael Vilar. Finalmente Guillerme Vázquez resultó reelegido potavoz nacional con 2.123 votos frente Xosé Manuel Beiras, con 1.823 votos; y Francisco Jorquera candidato a la presidencia de la Xunta con 2.338 (53 %) frente a los 2.043 votos (46 %) conseguidos por Carlos Aymerich. La ejecutiva del partido se formó con siete miembros de ApU, siete de +G-EI y uno de MGS; asimismo, la votación del Consello Nacional obtuvo 2.164 apoyos (48 %) para ApU, 2.026 (45 %) para +G-EI y 248 (5 %) para MGS.

Tras la citada asamblea, debido a las tensiones internas e ideológicas, partidos como Encontro Irmandiño y Esquerda Nacionalista decidieron abandonar el Bloque. La corriente Máis Galiza, la segunda fuerza más votada tras UPG, y el Partido Nacionalista Galego-Partido Galeguista realizaron asambleas propias para decidir su continuidad, decantándose ambas por abandonar el BNG. Sin embargo, un sector de Máis Galiza permaneció dentro como corriente organizada.

Tras las escisiones anteriores y su consiguiente caída en votos y escaños en las elecciones al Parlamento de Galicia de 2012, pasando de doce a siete diputados (frente a los nueve de Alternativa Galega de Esquerda), el BNG celebró el 17 de marzo de 2013 su XIV Asamblea Nacional, con una UPG sin prácticamente oposición interna, siendo elegido Xavier Vence portavoz nacional con un 95,82 % de los votos, fijando la independencia como objetivo del partido. Dicha Asamblea contó con la presencia de representantes del Bloco de Esquerda, ERC, Sortu y Amaiur.

En las elecciones al Parlamento Europeo del 25 de mayo de 2014, BNG y Euskal Herria Bildu conformaron la coalición Los Pueblos Deciden, junto con Puyalón, Andecha Astur, Alternativa Nacionalista Canaria y Unidad del Pueblo. Dicha candidatura consiguió votos (2,08%), lo que le permitió obtener un eurodiputado. Fruto del acuerdo de coalición, el candidato de EH Bildu Josu Juaristi ocuparía el escaño los primeros tres años y medio de la legislatura y la candidata del BNG Ana Miranda el año y medio restante.

En las elecciones generales de España de 2015 el BNG se presentó en la coalición electoral Nós-Candidatura Galega en las cuatro provincias de Galicia. La formación principal de la coalición fue el Bloque Nacionalista Galego, acompañado del Partido Galeguista, Coalición Galega, el Partido Comunista do Povo Galego y Fronte Obreira Galega. No obtuvo representación.

El BNG surgió con la intención de aglutinar en su interior toda la amplia gama ideológica del nacionalismo gallego. Desde el principio convivieron en su seno diversos partidos nacionalistas con sus propias asambleas y sus propios secretarios generales, así como corrientes internas propias del BNG como organización y miembros independientes de todas estas organizaciones. En la actualidad, estos grupos organizados son los siguientes:


También pertenecieron al BNG otros colectivos y partidos políticos; la mayor parte de los cuales decidieron marcharse en 2012, unos para integrarse en Compromiso por Galicia (CxG) y otros en Anova-Irmandade Nacionalista.






</doc>
<doc id="42915" url="https://es.wikipedia.org/wiki?curid=42915" title="PIP">
PIP

PIP puede referirse a:





</doc>
<doc id="42916" url="https://es.wikipedia.org/wiki?curid=42916" title="Músculo extensor cubital del carpo">
Músculo extensor cubital del carpo

El músculo extensor ulnar del carpo, extensor cubital del carpo o cubital posterior (lat. "Extensor carpi ulnaris") es un músculo que se encuentra en la región posterior del antebrazo; es largo y fusiforme (en forma de huso).

Lo inerva la rama posterior del nervio radial (C6-8). Lo irriga la arteria radial posterior.

La cabeza común del músculo se origina en el epicóndilo lateral del húmero,mientras que la cabeza cubital lo hace en cara y borde posterior del cubito y aponeurosis bicipital; se inserta distalmente, por medio de un largo tendón en la parte interna del extremo superior del quinto metacarpiano.

Como su propio nombre indica realiza una extensión y desviación cubital de la muñeca.


</doc>
<doc id="42918" url="https://es.wikipedia.org/wiki?curid=42918" title="Músculo flexor cubital del carpo">
Músculo flexor cubital del carpo

El músculo flexor cubital del carpo ('), flexor ulnar del carpo o cubital anterior es un músculo largo y cilíndrico del antebrazo humano, se encuentra en la parte interna y anterior del antebrazo.

El músculo cubital anterior parte de dos haces, el humeral y el cubital, conectados por un arco tendinoso justo por debajo de donde pasan el nervio cubital y la arteria cubital.

Al final de su trayecto, se inserta en el hueso pisiforme y luego, por medio de tendones y el unciforme del hueso ganchoso y del 5º metacarpiano, actuando para flexionar y aducir la articulación de la muñeca.

El haz humeral o epitrocleo se inserta en la epitroclea del húmero, en su cara anterior y a la vez en tabiques fibrosos vecinos.
El haz cubital u olecraneano se inserta en el borde interno del olecraneon y parte superior del borde interno del cúbito.

Flexiona y desvia la muñeca en dirección cubital.

El tendón del "flexor carpi ulnaris" puede ser visto en la cara distal (distante del codo) y anterior del antebrazo. En este punto, justo por encima de la muñeca, se observan dos o tres tendones. El cubital anterior es el más medial de los tres, es decir, el que está más cercano al dedo meñique. El tendón del medio, el que le sigue al cubital anterior, es el tendón del palmar menor. El tendón siguiente, el más lateral de los tres, es el tendón del palmar mayor.

El cubital anterior es innervado por ramas musculares del nervio cubital y la irrigación sanguínea por la arteria del mismo nombre, la arteria cubital.

El músculo, como ocurre con los flexores del antebrazo, pueden ser fortalecidos con ejercicios que resistan a dicha flexión. Las pesas que permitan subir y bajar a la muñeca pueden ser usadas para ese propósito.


</doc>
<doc id="42921" url="https://es.wikipedia.org/wiki?curid=42921" title="Ácido úrico">
Ácido úrico

El ácido úrico es un compuesto orgánico de carbono, nitrógeno, oxígeno e hidrógeno. Su fórmula química es CHNO.

Es un ácido débil producido en el hígado, músculos, intestinos, riñones y endotelio vascular, como producto final del catabolismo de las purinas (adenina y guanina) mediante la acción de la enzima xantina oxidasa.

Se encuentra en la orina en pequeñas cantidades. En algunos animales, como aves, reptiles y muchos artrópodos, es el principal producto de desecho, y se expulsa con las heces; los animales que excretan mayoritariamente ácido úrico se denominan uricotélicos. El alto contenido de nitrógeno del ácido úrico es la razón por la que el guano es tan valioso como fertilizante en la agricultura.

En la sangre humana, la concentración de ácido úrico en los hombres es de 3,6 - 6,5 mg/dl y, en las mujeres, de 2,5 - 6,5mg/dL, aunque se pueden encontrar niveles más altos en las personas que consumen más azúcar.

La gota en el ser humano está asociada con niveles anormales de ácido úrico en el sistema.

La saturación de ácido úrico en la sangre humana puede dar lugar a un tipo de cálculos renales (nefrolitiasis) cuando el ácido cristaliza en el riñón. Un porcentaje considerable de enfermos de gota llegan a tener cálculos renales de tipo úrico.

El aumento de los niveles de ácido úrico en la sangre no solo puede estar relacionado con la gota, sino que puede ser simplemente una hiperuricemia, que presenta algunos de los síntomas anteriores o puede ser asintomática. Sin embargo, cuanto mayor es el aumento de ácido úrico en sangre mayores son las posibilidades de padecer afecciones renales, artríticas, etc.

Los ácidos nucleicos ya existentes en el organismo son hidrolizados por endo y exonucleasas que dan mononucleótidos, que a su vez son degradados a nucleósidos por la fosfomonoesterasa. Esta enzima libera guanosina y adenosina, dos nucleósidos que no pueden seguir exactamente la misma vía.

La adenosina debe ser desaminada previamente por la *adenosina desaminasa para formar inosina. Sobre la inosina actúa la *nucleósido-fosforilasa que la despoja de su ribosa y da hipoxantina. Esta enzima actúa directamente sobre la guanosina liberando guanina.

Desde la hipoxantina y la guanina se forma un compuesto llamado xantina, que da origen al ácido úrico. Estos dos últimos pasos son catalizados por la xantina oxidasa (ésta contiene FAD, molibdeno y hierro no hemo), lo que da lugar al ácido úrico y luego al urato monosódico.




</doc>
<doc id="42924" url="https://es.wikipedia.org/wiki?curid=42924" title="Mg">
Mg

Mg puede referirse a:

Asimismo, MG puede hacer referencia a:

Además, mg puede referirse a:


</doc>
<doc id="42928" url="https://es.wikipedia.org/wiki?curid=42928" title="Tanque (desambiguación)">
Tanque (desambiguación)

El término tanque puede referirse a los siguientes artículos:





</doc>
<doc id="42932" url="https://es.wikipedia.org/wiki?curid=42932" title="Músculo masetero">
Músculo masetero

El músculo masetero ("Masseter") es un músculo de la masticación. Es un músculo corto, cuadrilátero, capaz de ejercer una fuerza de 90 kg, y formado por dos fascículos: uno anteroexterno (superficial), y otro posterointerno (profundo). Se suele denominar comúnmente como moflete.

Se inserta en el borde inferior del arco cigomático y en la cara externa de la rama del maxilar inferior o mandíbula, uniendo ambas estructuras óseas.

El haz superficial, el más voluminoso e importante de los dos, se inserta en los dos tercios anteriores del borde inferior del arco cigomático. De ahí nacen fibras carnosas con una oblicuidad hacia abajo y atrás que van a terminar en la cara lateral de la rama mandibular y el gonion, en unos rugosidades óseas para este fin.

El haz profundo se origina por fibras, en el tercio posterior de la cara interna e inferior del arco cigomático y en la aponeurosis del músculo temporal. Desde aquí las fibras se dirigen hacia abajo y adelante y terminan en la cara lateral de la rama mandibular.

Se consideran dos caras y cuatro bordes. La cara interna está en relación con la rama de la mandíbula, con la escotadura sigmoidea (paquete vasculo-nervioso maseterino), con la apófisis coronoides y con el buccinador (bola de Bichat). La cara externa está cubierta por la aponeurosis maseterina, y después de esta se encuentran los músculos cutáneos de la cara, la arteria transversal de la cara, el conducto parotídeo o de Stenon (con la prolongación maseterina de la parótida) y las ramificaciones del nervio facial. El borde superior se corresponde con el arco cigomático. El borde inferior, con el ángulo maxilar.

El músculo masetero está irrigado por la arteria maseterina inferior y la premaseterina (ambas colaterales de la arteria facial. La arteria transversal de la cara brinda múltiples ramos para la cara externa del músculo y una colateral profunda que penetra al músculo entre sus fascículos superficial y profundo. La arteria maseterina clásica es colateral de la arteria maxilar interna, la cual aborda al músculo desde la fosa cigomática a través de la escotadura sigmoidea del hueso maxilar inferior.

El músculo masetero está inervado por el nervio maseterino, rama colateral mandibular del quinto par craneal (nervio trigémino).



</doc>
<doc id="42933" url="https://es.wikipedia.org/wiki?curid=42933" title="Carro">
Carro

Un carro es un vehículo de transporte que se desplaza sobre dos ruedas o más que se mueve por tracción animal. Tirados por caballos, mulas, burros, bueyes, otros animales o incluso personas, en función de las costumbres del lugar. Puede denominarse también carretilla, carruaje coche de caballos, diligencia, etc. En algunos lugares del norte de México, le llaman carro al automóvil. 

Carro es una voz patrimonial del latín "carrus", de origen céltico. A la misma familia etimológica latina pertenecen carrera, carretera, carril, carroza, carruaje y ferrocarril.

El carro llegó a Europa y Asia occidental en el cuarto milenio antes de Cristo, y al Valle del Indo hacia el tercer milenio antes de Cristo. A América, llegó en el siglo XV, directamente de la mano de los conquistadores españoles, así como los caballos y las mulas, ya que al carecer de animales de carga los nativos americanos cargaban las cosas a la espalda.

A lo largo de la historia se han utilizado con frecuencia carretillas o pequeñas carretas de mano. En el siglo XIX, por ejemplo, durante la migración mormona hacia el actual territorio de Utah en los Estados Unidos, entre 1856 y 1860, se utilizaron estas carretas. Los llamados "rickshaw" todavía pueden verse en la actualidad en ciudades del sureste asiático como transporte para distancias cortas.
En la antigua Roma a los enemigos derrotados se les llevaba en carretas durante la exhibición triunfal del general victorioso. Los "carros para las carreras" tenían forma de concha puesta sobre dos ruedas, más alta por delante que por detrás, con una lanza muy corta, y eran tirados por cuatro caballos de frente. Los "carros de triunfo" tenían una forma redondeada; el vencedor iba en él en pie y dirigía por sí mismo los caballos.

Los carros servían también para otras ceremonias, como llevar en ellos las imágenes de los dioses en el día de preces públicas; se ponían también en los mismos las estatuas de aquellos cuya apoteosis se hacía, e iban en ellos las familias ilustres que asistían a la fiesta. Los cónsules, al encargarse del mando, eran asimismo conducidos en ellos. Sin embargo, la historia refiere que Camilo entró triunfante en Roma de este modo, pompa que se hizo después ordinaria, pero que esta vez no cayó bien a los republicanos. Durante el gobierno consular, los carros fueron dorados; bajo los emperadores fueron de marfil y hasta de oro. Se les rociaba con sangre para darles un aire más marcial. Los "carros cubiertos" se distinguían de los otros por una cúpula cimbrada. Servían para uso de los pontífices romanos y verosímilmente para las mujeres. En Inglaterra, hasta su sustitución por los azotes, en virtud del mandato de la Reina Isabel I, se utilizaban las carretas para transportar al condenado a la picota.

Los carros de guerra más conocidos fueron los del Antiguo Egipto, de un solo eje montados por un auriga y un arquero. Aparecieron en el Imperio Nuevo por influencia de los hicsos.

También destacó el carro de guerra en la India y en Persia. En este lugar fue donde probablemente se comenzó a colocar, como prolongación de los ejes, hojas afiladas o cortantes.

Hubo carros similares a los anteriores en la Antigua Grecia y en la Antigua Roma, pero su utilidad bélica decayó, al afianzarse el modelo militar basado en formaciones de infantería. En la antigua Roma fueron utilizados en carreras en el circo romano; su denominación variaba según el número de caballos: bigas, trigas y cuadrigas.

La parte fundamental del carro es la caja, receptáculo donde se lleva la carga, sea de mercancías o personas. La caja se apoya sobre unas ruedas (dos o cuatro), directamente o mediante un sistema de suspensión más o menos complicado. En países muy fríos, en vez de ruedas la caja se apoya sobre unos patines para la nieve. 

La caja debe tener un sistema para enganchar los animales o personas que forman el tiro. El sistema más sencillo son dos varas entre las que se sitúa el animal de tiro que, mediante unos arneses, queda enganchado y, además, sujeta la caja en posición horizontal cuando está parado. Cuando para el tiro se requiere más de un animal, generalmente suelen ser por pares. Las varas se sustituyen por una sola central, con un animal a cada lado. Para los carros ligeros, a menudo para pasajeros, el enganche a la vara o lanza suele hacerse mediante arneses, el principal de los cuales es un collarín, generalmente de madera forrada de cuero con almohadillado, que es la pieza principal de apoyo en el animal para soportar el tiro. Cuando son carros de carga, tirados por animales pesados, como bueyes, al final de la lanza se dispone un yugo, que apoya en el cuello de los dos animales, con los correspondientes arneses también.







</doc>
<doc id="42935" url="https://es.wikipedia.org/wiki?curid=42935" title="Primavera de Praga">
Primavera de Praga

La Primavera de Praga (; ) fue un periodo de liberalización política y protesta masiva en Checoslovaquia como estado socialista después de la Segunda Guerra Mundial. Comenzó el 5 de enero de 1968, cuando el reformista Alexander Dubček fue elegido Primer Secretario del Partido Comunista de Checoslovaquia (KSČ), y continuó hasta el 21 de agosto de 1968, cuando la Unión Soviética y otros miembros del Pacto de Varsovia invadieron el país para reprimir las reformas.

Las reformas de la Primavera de Praga fueron un fuerte intento de Dubček para otorgar derechos adicionales a los ciudadanos de Checoslovaquia en un acto de descentralización parcial de la economía y democratización. Las libertades otorgadas incluyeron un aflojamiento de las restricciones en los medios de comunicación, la libertad de expresión y de desplazamiento. Después de la discusión nacional sobre la división del país en una federación de tres repúblicas —Bohemia, Moravia-Silesia y Eslovaquia—, Dubček supervisó la decisión de dividirse en dos, la República Socialista Checa y la República Socialista Eslovaca. Esta doble federación fue el único cambio formal que sobrevivió a la invasión.

Las reformas, especialmente la descentralización de la autoridad administrativa, no fueron bien recibidas por los soviéticos, quienes, tras negociaciones fallidas, enviaron medio millón de tropas y tanques del Pacto de Varsovia para ocupar el país. "The New York Times" citó informes de 650 000 hombres equipados con las armas más modernas y sofisticadas del catálogo militar soviético. Una gran ola de emigración barrió la nación. La resistencia se expandió a todo el país, lo que implicó un intento de fraternización, el sabotaje de las señales de tráfico, el desafío a los toques de queda, etc. Mientras que los militares soviéticos predijeron que llevaría cuatro días dominar al país, la resistencia se mantuvo durante ocho meses hasta que finalmente fue burlada por estratagemas diplomáticos (ver más abajo). Se convirtió en un ejemplo de alto perfil de la defensa basada en civiles; hubo actos esporádicos de violencia y varios suicidios de protesta por autoinmolación (el más famoso fue el de Jan Palach), pero no hubo resistencia militar. Checoslovaquia permaneció controlada por la Unión Soviética hasta 1989, cuando la Revolución de Terciopelo finalizó pacíficamente el régimen comunista. Las últimas tropas soviéticas abandonaron el país en 1991.

Después de la invasión, Checoslovaquia entró en un período conocido como "normalización": los líderes posteriores intentaron restaurar los valores políticos y económicos que habían prevalecido antes de que Dubček obtuviera el control de KSČ. Gustáv Husák, quien reemplazó a Dubček como Primer Secretario y también se convirtió en Presidente, revirtió casi todas las reformas. La Primavera de Praga inspiró música y literatura checoslovacas, incluyendo el trabajo de Václav Havel, Karel Husa, Karel Kryl y la novela de Milan Kundera "La insoportable levedad del ser".

El proceso de desestalinización en Checoslovaquia comenzó bajo Antonín Novotný a fines de la década de 1950 y principios de la década de 1960, pero progresó más lentamente que en la mayoría de los otros estados del Bloque del Este. Siguiendo el ejemplo de Nikita Khrushchev, Novotný proclamó la finalización del socialismo y, en consecuencia, la nueva constitución adoptó el nombre de República Socialista Checoslovaca. El ritmo del cambio, sin embargo, fue lento; la rehabilitación de las víctimas de la era estalinista, como las condenadas en los juicios de Slánský, puede haber sido considerada ya en 1963, pero no tuvo lugar hasta 1967.

A principios de la década de 1960, Checoslovaquia sufrió una recesión económica. El modelo soviético de industrialización se aplicó pobremente a Checoslovaquia. Checoslovaquia ya estaba bastante industrializada antes de la Segunda Guerra Mundial y el modelo soviético tuvo en cuenta principalmente las economías menos desarrolladas. El intento de Novotný de reestructurar la economía, el Nuevo Modelo Económico de 1965, también impulsó una mayor demanda de reformas políticas.

A medida que el régimen estricto flexibilizó sus reglas, la Unión de Escritores Checoslovacos comenzó a expresar con cautela el descontento, y en la gaceta de la unión, "Literární noviny", los miembros sugirieron que la literatura debería ser independiente de la doctrina del Partido.

En junio de 1967, una pequeña fracción de la unión de escritores checos simpatizaba con los socialistas radicales, específicamente Ludvík Vaculík, Milan Kundera, Jan Procházka, Antonín Jaroslav Liehm, Pavel Kohout e Ivan Klíma.

Unos meses después, en una reunión del partido, se decidió que se tomarían medidas administrativas contra los escritores que expresaron abiertamente su apoyo a la reforma. Como solo una pequeña parte del sindicato tenía estas creencias, se confió en los miembros restantes para que disciplinaran a sus colegas. El control sobre "Literární noviny" y varias otras editoriales se transfirió al Ministerio de Cultura e incluso a los miembros del partido que luego se convirtieron en importantes reformadores, incluida Dubček, respaldaron estas medidas.

Mientras el presidente Antonín Novotný estaba perdiendo apoyo, Alexander Dubček, primer secretario del regional Partido Comunista de Eslovaquia, y el economista Ota Šik lo desafiaron en una reunión del Comité Central. Novotný luego invitó al secretario general del Partido Comunista de la Unión Soviética, Leonid Brezhnev, a Praga en diciembre, en busca de apoyo; pero Brezhnev estaba sorprendido por el alcance de la oposición a Novotný y, por lo tanto, apoyó su destitución como líder de Checoslovaquia. Dubček reemplazó a Novotný como Primer Secretario el 5 de enero de 1968. El 22 de marzo de 1968, Novotný renunció a su presidencia y fue reemplazado por Ludvík Svoboda, quien más tarde dio su consentimiento a las reformas.

Los primeros signos de cambio fueron pocos. Cuando el miembro del Presidium del Partido Comunista de Checoslovaquia (KSČ), Josef Smrkovský, fue entrevistado en un artículo de "Rudé Právo", titulado "Lo que está por venir", insistió en que el nombramiento de Dubček en el Pleno de enero fomentaría los objetivos del socialismo y mantendría la naturaleza de clase trabajadora del Partido Comunista.

Sin embargo, justo después de que Dubček asumiera el poder, el erudito Eduard Goldstücker se convirtió en presidente de la Unión de Escritores Checoslovacos y, por lo tanto, en jefe del semanario comunista "Literární noviny", que anteriormente estaba lleno de leales al partido. Goldstücker probó los límites de la devoción de Dubček por la libertad de prensa cuando apareció en una entrevista televisiva como el nuevo jefe del sindicato. El 4 de febrero, frente a toda la nación, criticó abiertamente a Novotny, exponiendo todas las políticas no informadas de Novotny y explicando cómo impedían el progreso en Checoslovaquia.

A pesar de la declaración oficial del gobierno que permitió la libertad de prensa, este fue el primer juicio sobre si Dubček se tomaba en serio las reformas. Goldstücker no tuvo repercusiones, y Dubček, en cambio, comenzó a construir un sentido de confianza entre los medios de comunicación, el gobierno y los ciudadanos. Fue bajo Goldstücker que el nombre de la revista se cambió a "Literární listy", y el 29 de febrero de 1968, la Unión de Escritores publicó la primera copia de "Literární listy" sin censura. Para agosto de 1968, "Literární listy" tenía una circulación de 300 000 ejemplares, lo que la convierte en la publicación más publicada de Europa.

En el vigésimo aniversario del "febrero victorioso" de Checoslovaquia, Dubček pronunció un discurso en el que explicaba la necesidad de un cambio tras el triunfo del socialismo. Hizo hincapié en la necesidad de "imponer el papel de liderazgo del partido de manera más efectiva" y reconoció que, a pesar de las urgencias de Klement Gottwald para mejorar las relaciones con la sociedad, el Partido con demasiada frecuencia había dictado fallos en cuestiones triviales. Dubček declaró que la misión del partido era "construir una sociedad socialista avanzada sobre bases económicas sólidas... un socialismo que corresponda a las tradiciones democráticas históricas de Checoslovaquia, de acuerdo con la experiencia de otros partidos comunistas..."

Uno de los pasos más importantes hacia la reforma fue la reducción y posterior abolición de la censura el 4 de marzo de 1968. Fue por primera vez en la historia checa la abolición de la censura y también fue probablemente la única reforma completamente implementada, aunque solo para un corto periodo de tiempo. Desde el instrumento de propaganda del Partido, los medios de comunicación se convirtieron rápidamente en el instrumento de crítica del régimen.

En abril, Dubček lanzó un "Programa de Acción" de liberalizaciones, que incluía el aumento de la libertad de prensa, la libertad de expresión y la libertad de movimiento, con énfasis económico en los bienes de consumo y la posibilidad de un gobierno multipartidista. El programa se basó en la opinión de que "el socialismo no puede significar solo la liberación de los trabajadores de la dominación de explotar las relaciones de clase, sino que debe hacer más provisiones para una vida más completa de la personalidad que cualquier democracia burguesa". Limitaría el poder de la Státní bezpečnost, la policía secreta, y prevería la federalización del ČSSR en dos naciones iguales. El programa también cubrió la política exterior, incluido el mantenimiento de buenas relaciones con los países occidentales y la cooperación con la Unión Soviética y otras naciones del Bloque del Este. Habló de una transición de diez años a través de la cual las elecciones democráticas serían posibles y una nueva forma de socialismo democrático reemplazaría el "statu quo".

Los que redactaron el Programa de Acción tuvieron cuidado de no criticar las acciones del régimen comunista de la posguerra, solo para señalar las políticas que consideraban que habían dejado de ser útiles. Por ejemplo, la situación inmediata de la posguerra había requerido "métodos centralistas y directivo-administrativos" para luchar contra los "restos de la burguesía". Dado que se decía que las "clases antagónicas" habían sido derrotadas con el logro del socialismo, estos métodos ya no eran necesarios. Se necesitaba una reforma para que la economía checoslovaca se uniera a la "revolución científico-técnica en el mundo", en lugar de depender de la industria pesada, la fuerza laboral y las materias primas de la era estalinista. Además, dado que se había superado el conflicto de clases interno, los trabajadores ahora podían ser debidamente recompensados ​​por sus calificaciones y habilidades técnicas sin contravenir el marxismo-leninismo. El Programa sugirió que ahora era necesario asegurar que las posiciones importantes fueran "ocupadas por cuadros de expertos socialistas capaces y educados" para competir con el capitalismo.

Aunque se estipuló que la reforma debe proceder bajo la dirección de KSČ, la presión popular aumentó para implementar las reformas de inmediato. Los elementos radicales se hicieron más vocales: las polémicas antisoviéticas aparecieron en la prensa el 26 de junio de 1968, los socialdemócratas comenzaron a formar un partido separado y se crearon nuevos clubes políticos no afiliados. Los conservadores del partido instaron a tomar medidas represivas, pero Dubček aconsejó moderación y volvió a enfatizar el liderazgo de KSČ. En el presidium del Partido Comunista de Checoslovaquia en abril, Dubček anunció un programa político de "socialismo con rostro humano". En mayo, anunció que el XIV Congreso del Partido se reuniría en una sesión temprana el 9 de septiembre. El congreso incorporaría el Programa de Acción en los estatutos del partido, redactaría una ley de federalización y elegiría un nuevo Comité Central.

Las reformas de Dubček garantizaban la libertad de prensa, y los comentarios políticos se permitieron por primera vez en los principales medios de comunicación. En el momento de la Primavera de Praga, las exportaciones checoslovacas estaban disminuyendo en competitividad, y las reformas de Dubček planearon resolver estos problemas al mezclar las economías planificadas y de mercado. Dentro del partido, hubo diferentes opiniones sobre cómo debería proceder esto; algunos economistas deseaban una economía más mixta, mientras que otros querían que la economía siguiera siendo mayormente planificada. Dubček continuó enfatizando la importancia de la reforma económica que se desarrolla bajo el gobierno del Partido Comunista.

El 27 de junio, Ludvík Vaculík, destacado escritor y periodista, publicó un manifiesto titulado "Las dos mil palabras". Expresó su preocupación por los elementos conservadores dentro de la KSČ y las llamadas fuerzas "extranjeras". Vaculík pidió a las personas que tomen la iniciativa para implementar el programa de reforma. Dubček, el partido Presidium, el Frente Nacional y el gabinete denunciaron este manifiesto.

La relajación de la censura de Dubček marcó el comienzo de un breve período de libertad de expresión y de prensa. La primera manifestación tangible de esta nueva política de apertura fue la producción del semanario comunista de línea dura "Literární noviny", que antes se llamaba "Literární listy".

La libertad de prensa también abrió la puerta para la primera mirada honesta al pasado de Checoslovaquia por parte de la gente de Checoslovaquia. Muchas de las investigaciones se centraron en la historia del país bajo el comunismo, especialmente en el caso del período de Iósif Stalin. En otra aparición televisiva, Goldstücker presentó fotografías manipuladas de antiguos líderes comunistas que habían sido purgados, encarcelados o ejecutados y, por lo tanto, borradas de la historia comunista. La Unión de Escritores también formó un comité en abril de 1968, encabezado por el poeta Jaroslav Seifert, para investigar la persecución de escritores después de la toma de posesión comunista en febrero de 1948 y rehabilitar a las figuras literarias en la Unión, librerías y bibliotecas y el mundo literario. Las discusiones sobre el estado actual del comunismo y las ideas abstractas como la libertad y la identidad también se estaban volviendo más comunes; pronto empezaron a aparecer publicaciones que no eran parte, como el diario sindical "Prace" («trabajo»). Esto también fue ayudado por el Sindicato de Periodistas, que en marzo de 1968 ya había persuadido a la Junta Central de Publicaciones, el censor del gobierno, a permitir que los editores reciban suscripciones sin censura a los periódicos extranjeros, lo que permite un diálogo más internacional en torno a las noticias.

La prensa, la radio y la televisión también contribuyeron a estas discusiones al organizar reuniones donde estudiantes y trabajadores jóvenes podían hacer preguntas a escritores como Goldstücker, Pavel Kohout y Jan Prochazka y víctimas políticas como Josef Smrkovský, Zdenek Hejzlar y Gustav Husak. La televisión también transmitió reuniones entre los ex presos políticos y los líderes comunistas de la policía secreta o las cárceles donde se encontraban. Lo más importante es que esta nueva libertad de prensa y la introducción de la televisión en las vidas de los ciudadanos checoslovacos de todos los días trasladaron el diálogo político de la esfera intelectual a la popular.

La reacción inicial dentro del Bloque Comunista fue mixta. János Kádár, de Hungría, apoyó mucho el nombramiento de Dubček en enero, pero Leonid Brezhnev y otros se preocuparon por las reformas de Dubček, que temían podrían debilitar la posición del Bloque Comunista durante la Guerra Fría.

En una reunión en Dresde, Alemania Oriental, el 23 de marzo, los líderes de los "Cinco de Varsovia" (Unión Soviética, Hungría, Polonia, Bulgaria y Alemania Oriental) interrogaron a una delegación checoslovaca sobre las reformas planeadas, sugiriendo que cualquier charla sobre "democratización" fue un velo. Crítica de otras políticas. Władysław Gomułka y János Kádár estaban menos preocupados por las reformas en sí mismas que por las crecientes críticas formuladas por los medios de comunicación checoslovacos, y temían que la situación pudiera ser "similar al prólogo de la contrarrevolución húngara". Se puede haber elegido parte del lenguaje del Programa de Acción KSČ de abril para afirmar que no se planeó una contrarrevolución, pero Kieran Williams sugiere que Dubček quizás se sorprendió ante las sugerencias soviéticas, pero no las resintió.

El liderazgo soviético intentó detener, o limitar, los cambios en el ČSSR a través de una serie de negociaciones. La Unión Soviética aceptó conversaciones bilaterales con Checoslovaquia en julio en Čierna nad Tisou, cerca de la frontera eslovaco-soviética. En la reunión, del 29 de julio al 1 de agosto, asistieron Brezhnev, Alexei Kosygin, Nikolai Podgorny, Mikhail Suslov y otros del lado soviético y Dubček, Svoboda, Oldřich Černík, Smrkovský y otros del lado checoslovaco, Dubček defendió las propuestas del ala reformista del KSČ al tiempo que se comprometió con el Pacto de Varsovia y Comecon. Sin embargo, el liderazgo del KSČ se dividió entre reformadores vigorosos (Josef Smrkovský, Oldřich Černík y František Kriegel) que apoyaron a Dubček, y conservadores (Vasiľ Biľak, Drahomír Kolder, y Oldřich Švestka) que adoptaron una postura antirreformista.

Brezhnev decidió en el compromiso. Los delegados del KSČ reafirmaron su lealtad al Pacto de Varsovia y prometieron frenar las tendencias "antisocialistas", evitar la reactivación del Partido Socialdemócrata Checoslovaco y controlar la prensa de manera más efectiva. Los soviéticos acordaron retirar sus fuerzas armadas (aún en Checoslovaquia después de las maniobras de junio) y permitir el Congreso del Partido del 9 de septiembre.

El 3 de agosto, representantes de los "Cinco de Varsovia" y Checoslovaquia se reunieron en Bratislava y firmaron la Declaración de Bratislava. La declaración afirmaba una inquebrantable fidelidad al marxismo-leninismo y al internacionalismo proletario y declaró una lucha implacable contra la ideología "burguesa" y todas las fuerzas "antisocialistas". La Unión Soviética expresó su intención de intervenir en un país del Pacto de Varsovia si se estableciera un sistema "burgués", un sistema pluralista de varios partidos políticos que representan diferentes facciones de la clase capitalista. Después de la conferencia de Bratislava, el ejército soviético abandonó el territorio checoslovaco pero se mantuvo a lo largo de sus fronteras.

Como estas conversaciones resultaron insatisfactorias, los soviéticos comenzaron a considerar una alternativa militar. La política de la Unión Soviética de obligar a los gobiernos socialistas de sus estados satélites a subordinar sus intereses nacionales a los del "Bloque del Este" (a través de la fuerza militar si fuera necesario) se conoció como la «Doctrina Brézhnev». En la noche del 20 al 21 de agosto de 1968, los ejércitos del Bloque del Este de cuatro países del Pacto de Varsovia, la Unión Soviética, Bulgaria, Polonia y Hungría, invadieron la República Socialista Checoslovaca.

Esa noche, 200 000 tropas y 2 000 tanques entraron al país. Primero ocuparon el aeropuerto internacional de Ruzyně, donde se organizó el despliegue aéreo de más tropas. Las fuerzas checoslovacas fueron confinadas a sus cuarteles, que fueron rodeados hasta que se mitigó la amenaza de un contraataque. Por la mañana del 21 de agosto se ocupó Checoslovaquia.

Ni Rumania ni Albania participaron en la invasión. El comando soviético se abstuvo de recurrir a las tropas de Alemania Oriental por temor a revivir los recuerdos de la invasión nazi en 1938. Durante la invasión de los ejércitos del Pacto de Varsovia, 72 checos y eslovacos fueron asesinados (19 de ellos en Eslovaquia), 266 heridos de gravedad y otros 436 levemente heridos. Alexander Dubček pidió a su gente que no se resistiera. Sin embargo, hubo resistencia dispersa en las calles. Las señales de tránsito en las ciudades fueron eliminadas o pintadas, excepto aquellas que indican el camino a Moscú. Muchas aldeas pequeñas se llamaron "Dubcek" o "Svoboda"; así, sin equipo de navegación, los invasores se confundían a menudo.

En la noche de la invasión, el Presidium checoslovaco declaró que las tropas del Pacto de Varsovia habían cruzado la frontera sin el conocimiento del gobierno checoslovaco, pero la prensa soviética imprimió una solicitud sin firma, supuestamente por el partido checoslovaco y los líderes estatales, por "asistencia inmediata, incluida la asistencia con las fuerzas armadas". En el 14.º Congreso del Partido KSČ (realizado en secreto, inmediatamente después de la intervención), se hizo hincapié en que ningún miembro de la dirección había invitado a la intervención. La evidencia más reciente sugiere que los miembros conservadores del KSČ (incluidos Biľak, Švestka, Kolder, Indra y Kapek) enviaron una solicitud de intervención a los soviéticos. La invasión fue seguida por una ola de emigración nunca vista, que se detuvo poco después. Se estima que 70 000 ciudadanos huyeron inmediatamente con un total final de unos 300 000 checoslovacos.

Los soviéticos atribuyeron la invasión a la «Doctrina Brézhnev», que afirmaba que la Unión Soviética tenía derecho a intervenir cada vez que un país en el Bloque Oriental parecía estar haciendo un cambio hacia el capitalismo. Sin embargo, aún existe cierta incertidumbre sobre qué provocación, si es que ocurrió alguna, provocó la invasión de los ejércitos del Pacto de Varsovia. Antes de la invasión fue un período bastante tranquilo sin que se produjeran eventos importantes en Checoslovaquia.

En Checoslovaquia, especialmente en la semana inmediatamente posterior a la invasión, la oposición popular se expresó en numerosos actos espontáneos de resistencia no violenta. Los civiles dieron intencionalmente instrucciones equivocadas a los soldados invasores, mientras que otros identificaron y siguieron los automóviles que pertenecían a la policía secreta. El 16 de enero de 1969, el estudiante Jan Palach se quemó a lo bonzo en la Plaza de Wenceslao de Praga para protestar contra la supresión de la libertad de expresión.

La resistencia generalizada hizo que la Unión Soviética abandonara su plan original para expulsar al Primer Secretario. Dubček, que había sido arrestado la noche del 20 de agosto, fue llevado a Moscú para las negociaciones. Allí, él y varios otros líderes (incluidos todos los funcionarios de mayor rango, el Presidente Svoboda, el Primer Ministro Černík y el Presidente de la Asamblea Nacional Smrkovský) firmaron el Protocolo de Moscú, bajo la fuerte presión psicológica de los políticos soviéticos, y se acordó que Dubček permanecería en el cargo y un programa de reforma moderada continuaría.

El 25 de agosto los ciudadanos de la Unión Soviética que no aprobaron la invasión protestaron en la Plaza Roja; siete manifestantes abrieron pancartas con consignas anti-invasión. Los manifestantes fueron brutalmente golpeados y arrestados por las fuerzas de seguridad, y luego castigados por un tribunal secreto; la protesta fue apodada "antisoviética" y varias personas fueron detenidas en hospitales psiquiátricos.

Un efecto más pronunciado tuvo lugar en Rumania, donde Nicolae Ceaușescu, secretario general del Partido Comunista de Rumania, que ya era un firme opositor de las influencias soviéticas y un autoproclamado partidario de Dubček, pronunció un discurso público en Bucarest el día de la invasión, describiendo las políticas soviéticas en términos duros. Enver Hoxha sacó a Albania del Pacto de Varsovia en oposición, calificando a la invasión como un acto de "imperialismo social". En Finlandia, un país bajo cierta influencia política soviética, la ocupación causó un gran escándalo.

Al igual que los partidos comunistas italiano y francés, la mayoría del Partido Comunista de Finlandia denunció la ocupación. No obstante, el presidente finlandés, Urho Kekkonen, fue el primer político occidental que visitó oficialmente Checoslovaquia después de agosto de 1968; el 4 de octubre de 1969 recibió las máximas distinciones checoslovacas de manos del presidente Ludvík Svoboda. El secretario general comunista portugués Álvaro Cunhal fue uno de los pocos líderes políticos de Europa occidental que apoyó la invasión por ser contrarrevolucionario junto con el partido luxemburgués y las facciones conservadoras del partido griego.

La mayoría de los países ofrecieron solamente críticas vocales después de la invasión. La noche de la invasión, Canadá, Dinamarca, Francia, Paraguay, el Reino Unido y los Estados Unidos solicitaron una reunión del Consejo de Seguridad de las Naciones Unidas. En la reunión, el embajador checoslovaco Jan Muzik denunció la invasión. El embajador soviético Jacob Malik insistió en que las acciones del Pacto de Varsovia eran "asistencia fraterna" contra "fuerzas antisociales".

Una de las naciones que condenó con más vehemencia la invasión fue China, que se opuso furiosamente a la llamada «doctrina Brezhnev», que declaraba que solo la Unión Soviética tenía derecho a determinar qué naciones eran propiamente comunistas y podían invadir a aquellas naciones comunistas cuyo comunismo no contaba con la aprobación del Kremlin. Mao Zedong vio la doctrina de Brezhnev como la base ideológica para una invasión soviética de China, y lanzó una campaña de propaganda masiva condenando la invasión de Checoslovaquia, a pesar de su propia oposición anterior a la Primavera de Praga. Hablando en un banquete en la embajada rumana en Beijing el 23 de agosto de 1968, el primer ministro chino, Zhou Enlai, denunció a la Unión Soviética por "política fascista, chovinismo de gran poder, egoísmo nacional e imperialismo social", comparando la invasión de Checoslovaquia con la Guerra de Estados Unidos en Vietnam y más específicamente a las políticas de Adolf Hitler hacia Checoslovaquia en 1938-39. Zhou terminó su discurso con un llamado apenas velado para que la gente de Checoslovaquia emprendiera una guerra de guerrillas contra el Ejército Rojo.

Al día siguiente, varios países sugirieron una resolución de las Naciones Unidas que condenaba la intervención y exigía el retiro inmediato. Finalmente, se tomó una votación de la ONU con diez miembros que apoyaban la moción; Argelia, India y Pakistán se abstuvieron; la Unión Soviética (con poder de veto) y Hungría se opusieron. Los delegados canadienses presentaron de inmediato otra moción solicitando que un representante de la ONU viajara a Praga y trabajara para liberar a los líderes checoslovacos encarcelados.

Para el 26 de agosto, un nuevo representante checoslovaco solicitó que se eliminara todo el tema de la agenda del Consejo de Seguridad. Shirley Temple Black visitó Praga en agosto de 1968 para prepararse para convertirse en el Embajador de Estados Unidos para una Checoslovaquia libre. Sin embargo, después de la invasión del 21 de agosto, se convirtió en parte de un convoy de vehículos organizado por la Embajada de los Estados Unidos que evacuó a ciudadanos estadounidenses del país. En agosto de 1989, regresó a Praga como embajadora de los Estados Unidos, tres meses antes de la Revolución de terciopelo que terminó con 41 años de gobierno comunista.

En abril de 1969, Dubček fue sustituido como Secretario General por Gustáv Husák, y comenzó un período de "normalización". Dubček fue expulsado del KSČ y se le dio un trabajo como oficial forestal.

Husák revirtió las reformas de Dubček, purgó a los miembros aperturistas del partido, y destituyó de su función pública a las élites profesionales e intelectuales que abiertamente expresaron su desacuerdo con la transformación política. Husák trabajó para restablecer el poder de las autoridades policiales y fortalecer los vínculos con otros países socialistas. También trató de volver a centralizar la economía, ya que una cantidad considerable de libertad se había concedido a las industrias durante la Primavera de Praga. Los comentarios políticos de nuevo fueron censurados en los principales medios de comunicación y las declaraciones políticas de cualquier persona que no se consideraba de "plena confianza política" también fueron prohibidas. El único cambio significativo que sobrevivió fue la federalización del país, que creó la República Socialista Checa y la República Socialista Eslovaca en 1969.

En 1987, el líder soviético Mijaíl Gorbachov reconoció que sus políticas de liberalización, glásnost y perestroika, tenían una gran deuda con el "socialismo con rostro humano" de Dubček. Con la caída del socialismo en 1989, Dubček se convirtió en presidente de la Asamblea Federal durante el gobierno de Václav Havel. Cuando se le preguntó cuál era la diferencia entre la Primavera de Praga y las reformas de Gorbachov, un portavoz del Ministerio de Relaciones Exteriores respondió: "Diecinueve años".

Dubček prestó su apoyo a la Revolución de terciopelo de diciembre de 1989. Después del colapso del régimen comunista ese mes, Dubček se convirtió en presidente de la asamblea federal bajo la administración de Havel. Más tarde dirigió el Partido Socialdemócrata de Eslovaquia y habló en contra de la disolución de Checoslovaquia antes de su muerte en noviembre de 1992.

La invasión del Pacto de Varsovia incluyó ataques contra establecimientos de medios, como Radio Praga y la Televisión Checoslovaca, casi inmediatamente después de que los tanques iniciales entraran en Praga el 21 de agosto de 1968. Mientras tanto, la estación de radio y la estación de televisión lograron resistir por lo menos el tiempo suficiente. Para las transmisiones iniciales de la invasión, lo que los soviéticos no atacaron por la fuerza, atacaron al promulgar la censura del partido. Como reacción a la invasión, el 28 de agosto de 1968, todos los editores checoslovacos acordaron detener la producción de periódicos por el día para permitir un "día de reflexión" para el personal editorial. Los escritores y reporteros acordaron con Dubček apoyar una restitución limitada de la oficina de censura, siempre y cuando la institución durara solo tres meses. Finalmente, en septiembre de 1968, se celebró el pleno del Partido Comunista de Checoslovaquia para establecer la nueva ley de censura. En las palabras de la resolución aprobada por Moscú, "La prensa, la radio y la televisión son, ante todo, los instrumentos para llevar a la práctica las políticas del Partido y el Estado".

Si bien esto aún no era el fin de la libertad de los medios de comunicación después de la Primavera de Praga, fue el principio del fin. Durante noviembre, el Presidium, bajo Husak, declaró que la prensa checoslovaca no podía hacer comentarios negativos sobre los invasores soviéticos o se arriesgarían a violar el acuerdo al que habían llegado a finales de agosto. Cuando el semanario "Reporter" y "Politika" respondieron duramente a esta amenaza, incluso llegando a no criticar tan sutilmente al propio Presidium en "Politika", el gobierno prohibió a "Reporter" por un mes, suspendió a "Politika" indefinidamente y prohibió que apareciera en la radio cualquier programa político o en televisión.

Los intelectuales estaban atrapados en un "impasse"; reconocieron la creciente normalización del gobierno, pero no estaban seguros si confiar en que las medidas eran solo temporales o exigir más. Por ejemplo, todavía creyendo en las promesas de reforma de Dubček, Milan Kundera publicó el artículo "Cesky udel" («Nuestro destino checo») en "Literarni listy" el 19 de diciembre. Escribió: "Las personas que hoy están cayendo en la depresión y el derrotismo, comentando que no hay suficientes garantías, que todo podría terminar mal, que podríamos terminar nuevamente en un marasmo de censura y juicios, que esto o lo otro podría suceder, son simplemente gente débil, que puede vivir solo en ilusiones de certeza".

Sin embargo, en marzo de 1969, el nuevo gobierno checoslovaco respaldado por los soviéticos instituyó una censura total, poniendo fin de manera efectiva a las esperanzas de que la normalización llevaría a las libertades de la primavera de Praga. Se presentó una declaración ante el Presidium condenando a los medios de comunicación como cómplices contra la Unión Soviética y el Pacto de Varsovia por su apoyo a las medidas de liberalización de Dubček. Finalmente, el 2 de abril de 1969, el gobierno adoptó medidas "para asegurar la paz y el orden" a través de una censura aún más estricta, lo que obligó a la gente de Checoslovaquia a esperar hasta el deshielo de Europa del Este para el regreso de un medio de comunicación libre.

Los antiguos estudiantes de Praga, incluidos Constantine Menges, y los refugiados checos de la crisis, que pudieron escapar o reasentarse en los países occidentales continuaron abogando por los derechos humanos, la libertad religiosa, la libertad de expresión y el asilo político para los presos políticos y los disidentes checos. Muchos expresaron su preocupación por la continuación de la ocupación militar de Checoslovaquia por parte de la Unión Soviética y el Ejército Rojo en los años 1970 y 80, antes de la caída del Muro de Berlín y el colapso del comunismo en Moscú y Europa del Este.

Una década después, la Primavera de Praga "prestó" su nombre a un periodo de apertura política en China, conocido como la Primavera de Pekín. En el siglo siguiente, la opresión de La Primavera de Praga se discute en la conexión de los eventos modernos.

La Primavera de Praga profundizó la desilusión de muchos izquierdistas occidentales con visiones marxistas-leninistas. Contribuyó al crecimiento de las ideas eurocomunistas en Occidente, donde los partidos comunistas pretendían una mayor distancia con la Unión Soviética, y llevó finalmente a la disolución de muchos de estos grupos. Una década más tarde, un período de liberalización política en China se conoció como la Primavera de Pekín. También influyó en la Primavera Croata en Yugoslavia. En 1993 en una encuesta checa, el 60% de los encuestados declaró tener un recuerdo personal vinculado a la Primavera de Praga, mientras que otro 30% declaró estar familiarizado con los acontecimientos de alguna u otra forma.

El evento ha sido referenciado en la música popular, incluyendo la música de Karel Kryl, "Requiem" de Luboš Fišer y en "Music for Prague 1968" de Karel Husa. ""They Can't Stop The Spring"", una canción del cantautor y periodista irlandés John Waters, que representó a Irlanda en el Festival de Eurovisión en 2007. Waters lo ha descrito como "una especie de fiesta celta de Europa oriental y sus revoluciones y posibles resultados", citando un supuesto comentario de Dubček: ""Podrán cortar todas las flores, pero no detendrán la primavera"" (Pablo Neruda).

La Primavera de Praga también ha aparecido en la literatura. La novela de Milan Kundera "La insoportable levedad del ser" se sitúa en la Primavera de Praga. En ella se muestran las repercusiones del aumento de la presencia soviética y el dictatorial control policial de la población. Una versión cinematográfica checa fue realizada en 1988. "The Liberators", de Víktor Suvórov, es la descripción de un testigo ocular de la invasión a Checoslovaquia en 1968, desde el punto de vista del comandante de un tanque soviético. En "Rock 'n' Roll", una obra de teatro del galardonado dramaturgo Tom Stoppard, hace referencias a la Primavera de Praga, así como la Revolución de Terciopelo de 1989. Heda Margolius Kovály también termina sus memorias "Under a Cruel Star", con una vista a la Primavera de Praga la posterior invasión, y sus reflexiones sobre estos acontecimientos.

En 1971 se publicó en lengua catalana la novela "Testament a Praga", escrita a cuatro manos por Tomàs Pàmies i Pla y Teresa Pàmies, padre e hija, exiliados de la Guerra Civil española que acabaron viviendo en Praga durante muchos años y en la cual, a modo de diario y de relación epistolar, narran el proceso de concienciación política con la clase obrera desde principios del siglo XX hasta el exilio y cómo la Primavera de Praga fue defendida o denostada según las visiones particulares de cada facción, pero siempre enmarcadas en el desencanto hacia la experiencia soviética.
Una adaptación cinematográfica distinta de La insoportable levedad del ser, es también la película "Pelíšky" del director Jan Hřebejk y el guionista Petr Jarchovský, que representa a los eventos de la Primavera de Praga, aunque es más sobre el período de normalización. La película musical checa, "Rebelové" de Filip Renč, también representa los acontecimientos, la invasión y la posterior oleada de emigración.

El número 68 se convirtió en un icono en la antigua Checoslovaquia. El jugador de hockey Jaromír Jagr lleva el número debido a la importancia del año en la historia de Checoslovaquia. Una antigua casa editorial con sede en Toronto, llamada 68 Publishers, publica libros de autores exiliados checos y eslovacos y tomó su nombre del evento.




</doc>
<doc id="42936" url="https://es.wikipedia.org/wiki?curid=42936" title="Ley de masas">
Ley de masas

La ley de masas o ley de acción de masas establece que para una reacción química reversible, en equilibrio a una temperatura constante, debe existir una relación constante entre concentraciones de reactivos y productos. La ley fue enunciada en 1864 por los científicos noruegos Cato Maximilian Guldberg y Peter Waage, y debe su nombre al concepto de "masa activa", lo que posteriormente se conoció como actividad.

En una reacción química elemental y homogénea, cuando la variación de energía de Gibbs d"G" = 0, es decir, en el equilibrio, se cumple que

donde "K"° es la constante de equilibrio, "a" es la actividad de la "i"-ésima especie química en el equilibrio y "ν" es el coeficiente estequiométrico de la "i"-ésima especie química en el equilibrio.

La constante también se puede definir tal que

donde Δ"G"° es la energía de Gibbs estándar de la reacción, "R" la constante de los gases ideales y "T" la temperatura.



</doc>
<doc id="42941" url="https://es.wikipedia.org/wiki?curid=42941" title="La Anunciación (Fra Angélico, Madrid)">
La Anunciación (Fra Angélico, Madrid)

La Anunciación es un retablo realizado por el pintor toscano del Renacimiento Fra Angélico, sobrenombre de Guido di Pietro da Mugello (1400-1455). Está realizado en oro y temple sobre tabla, y (según las últimas investigaciones) fue pintado hacia 1425-1426 (antes se databa hacia 1430-1432). Consta de una escena principal, con el tema de la Anunciación a la Virgen María, y de una predela o banco con cinco pequeñas escenas más. El conjunto mide 194 cm de ancho y 194 cm de alto. Se exhibe actualmente en el Museo del Prado de Madrid.

Pintada en temple sobre tabla entre 1430 y 1432 para la iglesia del convento de Santo Domingo de Fiesole (Italia), actualmente se conserva en el Museo del Prado de Madrid. La "Guía de visita del Museo" señala que se pintó hacia 1426.

De ella comenta Vasari en su "Vite":

Vendida por los frailes a Mario Farnese en 1611 para sufragar los gastos de la construcción del campanario de la iglesia, poco después este príncipe italiano la enviaba como regalo al valido del rey Felipe III, Francisco Gómez de Sandoval, duque de Lerma. En aquella época la obra se tenía en gran estima, pero no por su estilo o autoría, sino por su tema devoto y porque la escena principal recordaba al fresco -supuestamente milagroso- de la "Annunziata" de Florencia, del que circulaban muchas copias.

Aunque el retablo se depositó en la Iglesia de los dominicos en Valladolid (Iglesia conventual de San Pablo), panteón de la Casa de Lerma, poco después se remitía al Convento de las Descalzas Reales de Madrid, posiblemente a raíz de la defenestración del duque de Lerma. Se conservó en el citado convento hasta mediados del siglo XIX. Precisamente en su claustro alto lo descubriría el pintor Federico Madrazo, a la sazón director del Museo del Prado, quien, tras no pocas gestiones conseguía que el rey consorte don Francisco de Asís se interesara por su traslado al Prado, consintiendo la priora del monasterio, que recibió a cambio otra "Anunciación" pintada por el propio Madrazo. Remitida al Museo como donación real el 16 de julio de 1861, desde ese momento se ha constituido en una de sus piezas más relevantes y conocidas.

Desarrolla en la escena principal el tema de la Anunciación, tal como aparece narrado en el Nuevo Testamento, (Lc. 1,26-38), mostrando la escena en un pórtico de mármol abierto, "all’aperto", que recuerda al Hospital de los Inocentes, construcción de un coetáneo de Fray Angélico como Brunelleschi, con arcos de medio punto que descansan sobre finas columnas blancas. Tiene bóvedas de arista, de color azul celeste sembrado de pequeñas estrellas de oro. En la fachada del pórtico hay un medallón con la figura de Dios Padre en grisalla. Al fondo del pórtico hay un cubículo con un banco.

El pórtico es de mármol, La Virgen está situada a la derecha. Parece que ante la llegada del ángel ha suspendido la lectura del libro que ahora mantiene sobre el regazo. Tanto ella como la figura del ángel, son dos personajes rubios, de blanca piel y de manos finas y alargadas. La Virgen lleva una túnica de color rosado y un manto azul ultramar. El ángel está vestido con un traje de color rosa con franjas de oro, ceñido a la cintura, que cae en grandes pliegues hasta los pies.

Se encuentra en un jardín, "hortus conclusus", representación del paraíso. En el ángulo izquierdo de la pintura se ven las manos de Dios y de ellas sale un rayo de luz dorada que viene recto hacia la derecha, en el que viaja la paloma del Espíritu Santo. El vergel que hay delante del pórtico está cuajado de florecillas y tiene una espesa vegetación con algunos árboles entre los cuales puede verse a dos personajes: Adán y Eva, en este caso vestidos con pieles. Su expresión es de sumisión y de arrepentimiento. Representa en conjunto la escena, el principio y el final del pecado, los primeros padres y la salvación del hijo de María. Un ángel vigila detrás de ellos que abandonan el paraíso.

El cuadro se completa con una predela en la que se narran otras escenas de la vida de la Virgen. La predela se compone de cinco paneles donde se representan cronológicamente los episodios: Nacimiento y Desposorios, Visitación, Adoración de los Magos, Presentación en el Templo y Tránsito.

Se trata de una obra realizada alrededor del año 1425, es decir, en un momento de transición entre la pintura gótica y el Renacimiento. De la época medieval quedan rasgos como la minuciosidad propia de la miniatura, como puede verse en la flora delante de Adán y Eva, en las detalladas alas del ángel o en su halo dorado. La luz y el color son ya renacentistas, así como la austeridad de la arquitectura. Germán Bazin publicó en París una importante monografía de Fra Angélico en 1941; atribuye la tabla del Prado a un alumno de Fra Angélico llamado Zanobi Strozzi (1412-1468), haciéndose eco de una atribución anterior a este autor por Van Marle. Actualmente la crítica no cuestiona la atribución a Fra Angélico de forma mayoritaria. Si el autor no fuera Fra Angélico, debería ser alguien más capaz que Strozzi, que hubiera querido "perfeccionar y corregir la obra del maestro" (Germán Bazin).

La obra se conserva en condiciones razonables para su antigüedad. La tabla principal (formada por cuatro tablones verticales) y la predela subsisten unidas en un marco de relieve ajedrezado pintado en azul y rojo, que puede ser el original del siglo XV. Se apoya sobre un banco o base, en forma de altar, elaborado hacia 1920 por el taller Cano de Madrid. Se ha conjeturado que el retablo pudo tener en origen columnas o imágenes verticales a los lados, ahora desconocidas.

La capa pictórica se conserva bastante bien. El daño más relevante es una grieta vertical que cruza la imagen principal desde arriba, en la unión entre las tablas segunda y tercera que forman el soporte original. En un momento indeterminado estos dos tablones se separaron, lo que causó pérdidas de pintura y de dorado que afectaron sobre todo a las alas del ángel. Por suerte, el soporte se estabilizó después y no ha generado más problemas. Las faltas de pintura fueron rellenadas y disimuladas con toques de color. 

En el año 2018, la pintura principal del retablo fue retirada de la exposición permanente para someterla a un proceso general de limpieza, consolidación y restauración, el primero en 75 años. Ya renovada, vio la luz el 8 de mayo de 2019, habiéndose limpiado por completo el cuadro y reintegrado mediante toques de color reversibles las zonas de pintura dañadas. Los detalles de pan de oro que se habían perdido fueron rehechos al modo tradicional y de acuerdo a las partes conservadas . Queda por restaurar la predela con las cinco pinturas menores.





</doc>
<doc id="42948" url="https://es.wikipedia.org/wiki?curid=42948" title="Banco de España">
Banco de España

El Banco de España es el organismo del Estado español que actúa de banco central nacional y, en el marco del Mecanismo Único de Supervisión (MUS), el supervisor del sistema bancario español junto al Banco Central Europeo.

Su actividad está regulada por la Ley de Autonomía del Banco de España. El Banco de España es además parte integrante del Sistema Europeo de Bancos Centrales (SEBC) y por tanto está sometido a las disposiciones del Tratado de la Comunidad Europea y a los Estatutos del SEBC.

Desde 1891, su sede principal está situada en la calle Alcalá, 48, junto a la plaza de Cibeles. Asimismo, cuenta con una parada de metro que toma su nombre.

El Banco de España tiene una larga tradición histórica, que hunde sus raíces en el siglo XVIII.

En 1782, el rey Carlos III creó en Madrid una sociedad por acciones, cuya propiedad correspondía a instituciones y sujetos particulares. Los principales gobernantes ilustrados de la época, como el primer secretario de Estado, el conde de Floridablanca, el secretario de Estado de Hacienda, Miguel de Múzquiz y Goyeneche, y el fiscal del Consejo de Castilla, Pedro Rodríguez de Campomanes, apoyaron la creación de este instituto bancario. Aunque no era un banco público, gozaba de la protección de la Corona, y mantenía estrechos lazos financieros con el Estado. Se llamó Banco Nacional de San Carlos.

El principal objeto del Banco Nacional de San Carlos era la reducción o descuento de vales reales a metálico. Los vales reales eran una modalidad de deuda pública, cuyos títulos, además de proporcionar una rentabilidad determinada a su poseedor, tenían capacidad liberatoria en grandes pagos, por lo que son considerados la primera manifestación de papel moneda existente en España. El creador de los vales reales fue Francisco Cabarrús, un comerciante ilustrado de origen francés, quien sería asimismo fundador del Banco Nacional de San Carlos y miembro nato de su dirección. En 1789 recibiría de Carlos IV el título de conde de Cabarrús. El Banco Nacional de San Carlos tenía también, entre otros cometidos, el descuento de letras de cambio y efectos de comercio, los préstamos con garantía y la financiación de actividades del Estado.

Al año siguiente de su institución empezó a emitir los primeros billetes llamados «cédulas». Estas cédulas garantizaban un inmediato reembolso en metálico, reembolso que efectuaría el propio banco emisor; se canjeaban al portador sin producir ningún interés, lo cual les diferenciaba de los vales reales. Este carácter de cédula o billete duró hasta la guerra civil española, por eso todos los billetes llevaban la leyenda «El Banco de España pagará al portador...». La frase sobrevivió hasta 1976, pero había perdido valor legal desde la ley de noviembre de 1939.

Sin embargo, los billetes en cuestión, las cédulas, no tuvieron ningún éxito, debido a la abundancia de moneda de plata circulante en España a finales del siglo XVIII y comienzos del XIX y a la propia existencia de los vales reales. En 1790, Francisco Cabarrús y los restantes directores fueron relevados de sus cargos, debido a la aparición de pérdidas causadas en determinadas competencias del Banco de San Carlos, y bajo la sospecha de irregularidades. Cabarrús fue procesado y encarcelado preventivamente. Al cabo de seis años se sobreseyó la causa y Cabarrús quedó reintegrado a su puesto, aunque rodeado por un equipo directivo diferente y ajeno a su voluntad.

Entre los años 1793 y 1814, España se vio implicada en una serie de guerras que arrastraron al Banco y lo situaron en serias dificultades, causadas principalmente por la considerable deuda que el Tesoro había contraído con el Banco a lo largo de esos veinte años de conflictos. Finalmente, en el año de 1829 se encontró una solución para dicho débito, gracias al ministro de Hacienda del rey Fernando VII, Luis López Ballesteros, quien además de tomar ciertas medidas financieras innovadoras, concibió la idea de dotar al Banco de San Carlos con un fondo de 40 millones de reales.

Con esta ayuda los accionistas, decidieron fundar una nueva institución con el nombre de Banco Español de San Fernando (por ser rey Fernando VII). Este nuevo banco consiguió la facultad de emitir billetes en régimen de monopolio en Madrid. A lo largo de quince años mantuvo una continua actividad bancaria en el ámbito de la capital de España, con especial dedicación a las necesidades financieras del tesoro, en unos años en que afianzaba el naciente régimen liberal, y especialmente durante la primera guerra carlista.

En 1844, el Gobierno autorizó la apertura de un nuevo banco emisor en Madrid, el Banco de Isabel II, cuyo principal inspirador fue el financiero José Salamanca y Mayol. En el mismo año fue aprobada la creación de un banco emisor en Barcelona y en 1846 la de otro similar en Cádiz. Cada uno de estos bancos tenía facultad de emitir sus propios billetes y de ponerlos en circulación en sus respectivos ámbitos locales, además de desenvolver sus restantes actividades crediticias, salvo el caso de Madrid, donde compitieron las dos entidades existentes en ella.

Al cabo de tres años, y en plena crisis financiera internacional de 1847, el Gobierno decidió resolver las dificultades por las que atravesaban los dos emisores de Madrid, principalmente el Banco de Isabel II, mediante la fusión de ambos. La entidad resultante de dicho proceso conservó el nombre de Banco Español de San Fernando. Las consecuencias de la crisis fueron duraderas, y tras diversos cambios legales, fue nombrado en 1849 gobernador del Banco Español de San Fernando el exministro de Hacienda Ramón Santillán. Santillán llevó a cabo, entre 1851 y 1856, una ejemplar labor de saneamiento financiero dentro de la entidad.

Tras la Revolución de 1854, la legislación bancaria de 1856, de inspiración netamente liberal, permitió, entre otras modificaciones, que el Banco de San Fernando pasara a llamarse Banco de España, cuyo primer gobernador siguió siendo el del Banco de San Fernando, Ramón Santillán. A pesar de la denominación de Banco de España, esta institución solo operaba entonces en Madrid, Valencia y Alicante, ciudades en que abrió sucursales en 1858. Otras diecinueve localidades españolas, entre ellas los principales centros industriales y mercantiles, como Barcelona, Bilbao, Málaga, Sevilla, Zaragoza, Valladolid o Santander, contaron con sus propios bancos de emisión y descuentos dentro del período 1856-1874.

El 19 de marzo de 1874 las acuciantes y forzosas necesidades financieras causadas por la tercera guerra carlista y por la guerra de los Diez Años, simultánea a la anterior, obligaron al entonces ministro de Hacienda en el Gobierno de la Primera República, José Echegaray, decretar la fusión de todos los bancos emisores locales con el Banco de España. No obstante, a estos últimos se les dejaba la opción de continuar con su actividad comercial y crediticia, aunque sin facultad de emitir billetes, cuyo monopolio en todo el territorio de la nación, correspondería, en adelante, al Banco de España. A dicha posibilidad solo se acogieron los Bancos de Barcelona, Bilbao, Reus, Santander y Tarragona. A cambio del privilegio emisor, el Banco de España concedió un crédito de 150 millones de pesetas.

A partir de entonces, el Banco de España estableció una densa red de sucursales en toda la nación, comenzando por los antiguos de bancos emisores absorbidos. A finales del siglo XIX, había más de cincuenta sucursales del banco en todas las capitales de provincia y ciudades de importancia mercantil. Es preciso subrayar que, en esta época, el Banco de España –que seguía siendo una sociedad por acciones de propiedad privada, aunque el gobernador y los subgobernadores eran nombrados y aprobados respectivamente por el Gobierno- simultaneaba la emisión de billetes y el crédito al tesoro público con actividades de préstamos y descuentos con particulares a través de sus oficinas en las diferentes ciudades españolas. Con la Ley de Ordenación Bancaria de 1921, el Banco de España se consagró como banco de bancos, o banco central, desarrollando –de acuerdo con el Gobierno- nuevos instrumentos de política monetaria. Tras la guerra civil española, el Banco de España perdió competencias y autonomía a favor del Ministerio de Hacienda. Entre dichos cambios los más importantes fueron:


El Banco de España siguió su andadura, aún como entidad privada, en el contexto de esta política autárquica, hasta 1962, en que una nueva Ley de Bases de Ordenación del Crédito y la Banca, más acorde en su contenido con la liberalización experimentada por la economía española, a raíz del Plan de Estabilización de 1959, devolvió algunas de sus competencias al Banco de España. Dentro de estos cambios se produjo la nacionalización del Banco de España y el cese de su actividad de banca privada.

De aquí pasamos a otras fechas clave en la historia del banco:

Estas dos leyes han otorgado al banco una gran libertad y flexibilidad gubernamental, sobre todo en lo referente a la política monetaria. En la actualidad el Banco de España está integrado en el Sistema Europeo de Bancos Centrales (desde 1998).

La crisis internacional tuvo un impacto muy significativo en la economía española. La práctica desaparición de algunos de los principales mercados de capitales mayoristas desde 2007 a 2008, como el interbancario o el de titulizaciones, dificultó la normal financiación de las entidades de crédito españolas, que en aquellos momentos presentaban cuantiosas necesidades de financiación exterior.

El papel del Banco de España en la detección y tratamiento de las crisis financiera, cuya consecuencia principal ha sido una factura de dinero público superior a los 40 000 millones, ha sido objeto de controversia y acusaciones cruzadas entre los diferentes partidos políticos desde que se formó el gobierno de Mariano Rajoy a finales de diciembre de 2011.

Existe constancia de que en fechas cruciales de la crisis, concretamente en 2008, la supervisión del Banco de España modificó las normas contables exigibles a las instituciones financieras. Estos cambios normativos tuvieron como consecuencia aliviar y diferir el apunte en los balances bancarios del crecimiento excesivo de la morosidad causado por la crisis, sobre todo en lo que se refiere a la refinanciación de préstamos. Dicho de otro modo, gracias a las instrucciones dadas por el Banco de España en el momento de mayor crudeza de la crisis, las entidades de crédito habrían podido disimular el efecto destructivo de la morosidad y diferir las correcciones necesarias.

La estrategia adoptada por el Banco de España para hacer frente a la crisis buscaba evitar la quiebra en cadena de un buen número de instituciones financieras. Esa estrategia perseguía, utilizando recursos privados y públicos y cambios legales e institucionales, evitar la contaminación de todo el sector bancario español, haciendo posible su posterior reestructuración, eliminando el riesgo de que se produjera una crisis de confianza, tanto en los mercados como entre los depositantes.

Primaron las soluciones privadas mediante el saneamiento del balance de las entidades con sus propios recursos, a través de operaciones corporativas, acudiendo al propio sector a través del FGD y, solo en última instancia, mediante la inyección de fondos públicos, incluida la ayuda europea asociada al programa de asistencia financiera firmado en 2012. No hay que olvidar que entre 2008 y 2013 las entidades de crédito españolas realizaron saneamientos por un total cercano a los 270 000 millones de euros, asumidos en su mayor parte por los accionistas de esas entidades. Hay que subrayar que los depósitos de clientes no sufrieron pérdida alguna.

De acuerdo con lo previsto en la Ley de Autonomía del Banco de España, dicha institución es una entidad de derecho público con personalidad jurídica propia y plena capacidad pública y privada, que actuará con autonomía respecto a la Administración General del Estado en el desempeño de sus funciones, con arreglo a lo previsto en el ordenamiento jurídico.

Exceptuando los casos en que actúe en el ejercicio de las potestades administrativas que le confiere la ley, el Banco de España está sometido al ordenamiento jurídico privado.

Además, la Ley de Autonomía establece que el Banco de España es parte integrante del Sistema Europeo de Bancos Centrales (SEBC) y, como tal, está sometido a las disposiciones del Tratado de la Comunidad Europea y a los Estatutos del SEBC. Así, en el ejercicio de las funciones que se derivan de su condición de parte integrante del SEBC, el Banco de España se ajusta a las orientaciones e instrucciones del Banco Central Europeo.

De acuerdo con lo previsto en el artículo 7 de la citada Ley de Autonomía, en el ejercicio de las funciones en las que el Banco de España participa como integrante del SEBC, ni el Gobierno, ni ningún otro órgano nacional o comunitario podrá dar instrucciones al Banco de España ni este podrá recabarlas o aceptarlas. Este artículo recoge el contenido del artículo 108 de Tratado Constitutivo de la Comunidad Europea.

Los órganos rectores del Banco de España son:

El gobernador del Banco de España será nombrado por el rey a propuesta del presidente del Gobierno de España, entre quienes sean españoles y tengan reconocida competencia en asuntos monetarios o bancarios. Con carácter previo al nombramiento del gobernador, el ministro de Economía y Competitividad comparecerá en los términos previstos en el Reglamento del Congreso de los Diputados ante la comisión competente, para informar sobre el candidato propuesto. Su mandato tiene una duración de seis años, sin posible renovación.

Corresponde al gobernador del Banco de España:

El subgobernador será designado por el Gobierno, a propuesta del gobernador, y deberá reunir sus mismas condiciones. El subgobernador sustituirá al gobernador en los casos de vacante, ausencia o enfermedad, en cuanto al ejercicio de sus atribuciones de dirección superior y representación del banco. Tendrá, además, las atribuciones que se fijen en el Reglamento Interno del Banco de España, así como las que le delegue el gobernador. Su mandato tiene una duración máxima de seis años, sin posible renovación.

La condición de subgobernador implica ser consejero nato en la Comisión Nacional del Mercado de Valores, presidente de la comisión gestora del Fondo de Garantía de Depósitos, vicepresidente de la comisión rectora del Fondo de Reestructuración Ordenada Bancaria y, por último, miembro del consejo de supervisión del Mecanismo Único de Supervisión del Banco Central Europeo.

La Comisión Ejecutiva estará formada por:

Asistirán a sus sesiones, con voz y sin voto, los directores generales del Banco de España. Será secretario, con voz y sin voto, el secretario general del Banco de España.

Los seis consejeros serán designados por el Gobierno, a propuesta del ministro de Economía y Competitividad, oído el gobernador del Banco de España. Deberán ser españoles, con reconocida competencia en el campo de la economía o el derecho. Los dos consejeros miembros de la Comisión Ejecutiva se designarán por el Consejo de Gobierno, a propuesta del gobernador, de entre sus miembros no natos. El Consejo de Gobierno está formado por:

Asisten al Consejo los directores generales del banco, con voz y sin voto. También asistirá un representante del personal del banco, elegido en la forma que establezca el reglamento interno del banco, con voz y sin voto.

El ministro de Economía y Competitividad o el secretario de Estado de Economía podrán asistir, con voz y sin voto, a las reuniones del Consejo cuando lo juzguen preciso a la vista de la especial trascendencia de las materias que vayan a considerarse. También podrán someter una moción a la deliberación del Consejo de Gobierno.

El Consejo de Gobierno tendrá como secretario, con voz y sin voto, al secretario general del Banco de España.

Tras los últimos nombramientos acaecidos el 28 de septiembre de 2018 seis de los diez miembros del consejo de la institución son mujeres.

Desde el 1 de enero de 1999, el Banco de España participa en el desarrollo de las siguientes funciones básicas atribuidas al Sistema Europeo de Bancos Centrales:

El Banco de España ejercerá, además, las siguientes funciones:

El 1 de enero de 2002, el euro fue puesto en circulación y reemplazó a los billetes y monedas nacionales. El Consejo de Gobierno del Banco Central Europeo (BCE) decide el volumen de billetes en euros que se emiten cada año y aprueba el valor total de las monedas que se emitirán por cada país. La puesta en circulación de billetes y monedas es responsabilidad de los bancos centrales nacionales.

El Tratado de la Comunidad Europea otorga al Banco Central Europeo (BCE), desde el 1 de enero de 1999, el derecho exclusivo de aprobar el volumen de emisión de moneda metálica que corresponde a los Estados miembros. En España, la fabricación de monedas en euros la realiza la Fábrica Nacional de Moneda y Timbre-Real Casa de la Moneda (FNMT) y es el Banco de España el que, en nombre del Estado español, pone en circulación y retira de ella las monedas en euros. El número de monedas en euros con la cara nacional española fabricadas para el lanzamiento del euro fue de 7.055 millones.

El canje de pesetas por euros en el Banco de España se puede hacer hasta el 31 de diciembre de 2020 y tiene carácter gratuito. Como norma general son canjeables los billetes en pesetas emitidos a partir de 1939. Los emitidos entre 1936 y 1939 deben ser examinados por los expertos del Banco de España para determinar su valor de canje. En cuanto a las monedas, son canjeables únicamente las correspondientes a la última acuñación, que fueron puestas en circulación en el año 1997, así como todas las monedas conmemorativas de 2.000 pesetas. Se denegará el canje de aquellas monedas en pesetas que hayan sufrido una alteración derivada de un proceso industrial o mecánico.

La Central de Información de Riesgos (CIR) es un servicio público que gestiona una base de datos en la que constan, prácticamente, todos los préstamos, créditos, avales, y riesgos en general que las entidades financieras tienen con sus clientes. Para la adecuada evaluación de la situación de empleo, ingresos, patrimonial y financiera del cliente, las entidades financieras consultarán el historial crediticio del mismo, pudiendo acudir para ello a esta división del Banco de España. Las entidades tienen que declarar mensualmente a la Central de Información de Riesgos (CIR) la práctica totalidad (hay algunas excepciones) de sus riesgos de crédito y los titulares a quienes corresponden, incluyendo los datos, características y circunstancias más significativas.

El Banco de España supervisa la solvencia y el cumplimiento de la normativa específica de los bancos, las cajas de ahorros, las cooperativas de crédito, las sucursales de entidades de crédito extranjeras, los establecimientos financieros de crédito, las entidades emisoras de dinero electrónico, las sociedades de garantía recíproca y de reafianzamiento, los establecimientos de cambio de moneda y las sociedades de tasación. En el caso de las sucursales de entidades de países de la Unión Europea (UE), sus facultades se limitan al control de la liquidez de la sucursal y del cumplimiento de las normas de interés general.

El modelo de supervisión que se aplica se compone de cuatro elementos principales:


En el desarrollo de su función, el Banco de España colabora estrechamente con las demás autoridades supervisoras nacionales y las autoridades autonómicas con competencias en el área de la supervisión financiera. También mantiene una estrecha colaboración con las autoridades supervisoras extranjeras y participa activamente en todos los foros nacionales e internacionales de supervisión.

Dentro de sus funciones de supervisión el Banco de España intervino el día 10 de marzo de 2015 el Banco Madrid.

El Banco de España en Madrid opera con entidades de crédito y ofrece los siguientes servicios al público:


Algunos servicios se encuentran ubicados en C/ Alcalá, 522, 28027 Madrid.

El Banco de España contó con diversos emplazamientos en Madrid, a lo largo del siglo XIX. El actual edificio del Banco de España fue construido con el objetivo de proporcionar al Banco Nacional una sede más acorde con la importancia de sus funciones, como era la emisión única de monedas y billetes para todo el territorio español.

El actual edificio se encuentra en la plaza de Cibeles, lugar donde se unen las calles de Alcalá y del paseo del Prado. En el momento de su construcción, el edificio se situó sobre un amplio solar formado por las antiguas parcelas del palacio del Marqués de Alcañices, Duque de Sesto, y algunos terrenos anexos, entre ellos, el correspondiente a la capilla de San Fermín de los Navarros, al jardín de la Escuela de Ingenieros de Caminos, Canales y Puertos y al de una casa propiedad del Marqués de Larios. Junto a la fuente de la Cibeles, el Banco de España está rodeado por el edificio de Correos, la Casa de América y el Círculo de Bellas Artes.

Todo lo relacionado con este nuevo edificio comienza en 1882. En este año se acuerda convocar un concurso público para la elección del proyecto arquitectónico que mejor se adapte a las nuevas necesidades del Banco y cuyas bases son redactadas por los propios arquitectos de la institución, Eduardo de Adaro, Severiano Sainz de la Lastra y José María Aguilar y Vela. Tan solo se presentan cuatro proyectos y ninguno de ellos es de la plena satisfacción de la comisión de obras, por lo que se encarga a los arquitectos del Banco que, tras estudiar los edificios de otros bancos europeos, redacten el proyecto definitivo, el cual es aprobado a finales de 1883, después de muchas incidencias. En el proyecto también colaboraron entre otros Aníbal Álvarez Bouquel, Alejandro Herrero, Amador de los Ríos, o Bernardo Asins, quien realizó las puertas de hierro. El coste, incluyendo solares y edificio, fue de unos 15.300.000 pesetas.

La primera piedra se puso el 4 de julio de 1884, en un acto al que asistió el Rey Alfonso XII. A partir de entonces se sucedieron cambios de criterio y modificaciones del proyecto que dieron como resultado el colosal edificio inaugurado en 1891. Ya en 1927 se inició otra importante ampliación con la adquisición de las casas del conde de Santamarca, situadas en la calle de Alcalá, a continuación del edificio inicial. Esta ampliación se produjo según el proyecto del arquitecto del Banco, José Yarnoz Larrosa, quien propuso la prolongación de la fachada, repitiendo la imagen externa del edificio existente y reservando tan solo al interior las novedades arquitectónicas de la época.

El inmueble adopta el doble carácter industrial y de representación propio del establecimiento. El primero se aprecia prácticamente en toda la construcción, a excepción de la planta principal, en la que se albergan los despachos más importantes y las zonas de mayor representación. Los limitados adornos escultóricos quedan reservados al chaflán de Cibeles y a las portadas principales del Paseo del Prado y de la calle Alcalá, esta última tras la ampliación de 1927. Su ejecución fue encargada, en su mayor parte, a escultores italianos, si bien siguiendo los modelos pedidos a los escultores españoles más conocidos de la época.

Ya en el interior, y en lo que al edificio de 1891 se refiere, destacan la escalera de honor y el patio que fue Caja General y que hoy es Biblioteca. La monumental escalera en mármol de Carrara, a la que se accede desde la puerta del Paseo del Prado, es una muestra de la arquitectura más tradicional, diseñada por los arquitectos del Banco y ejecutada por el bilbaíno Adolfo Areizaga. Aparece acompañada de una serie de vidrieras encargadas a la empresa alemana Mayer, que las ejecuta siguiendo un estilo simbolista e incorporando numerosas figuras alegóricas.

Por su parte, el carácter industrial del Banco se materializa en la actual Biblioteca, encargada a la Fábrica de Mieres, en la que se incorpora la estructura metálica vista de hierro fundido.

La planta está articulada a partir de la entrada por la esquina. Ello permitió al arquitecto distinguir los espacios hacia las calles del Paseo del Prado y Alcalá. La fachada por su parte es de composición cuatripartita, está compuesta por zócalo, dos plantas, cornisa y cubierta habitada.

La ampliación decidida en 1927 y terminada en 1934 incorpora, en el interior del edificio, las novedades arquitectónicas de la época a las que Yarnoz había renunciado en el exterior. Tan solo destacar el nuevo patio de operaciones, la rotonda que sirve de enlace interior entre los dos edificios y, por su singularidad, la cámara acorazada. El enorme patio de operaciones se aparta de los conceptos clásicos y recoge algún ejemplo del art déco, como la vidriera superior, o como la pieza decorativa y al tiempo funcional situada en el centro del patio. La rotonda comunica este patio de operaciones con la escalera principal y en su centro se alza una pieza escultórica en honor a Echegaray, obra de Coullaut Valera. En su interior alberga una importante colección de pintura, con obras de Goya, Mengs, Maella y Vicente López entre otros autores.

Por último señalar que a principios de 2003 el Banco de España inició las obras de reconstrucción del edificio situado en la esquina de las calles Alcalá y Marqués de Cubas, antigua sede de la Banca García-Calamarte, con lo que se logra cerrar la manzana que ocupa su sede central en Madrid. El proyecto, elaborado por el arquitecto Rafael Moneo, consolida el carácter unitario del conjunto arquitectónico, manteniendo en su fachada la continuidad formal de los planteamientos originales.

El Banco de España posee 9,1 millones de onzas troy de oro (2019), que se encuentran depositadas en sus propias cámaras acorazadas y en diferentes entidades de Londres y Nueva York. En 2004 la reserva total de este metal ascendía a cerca de 17 millones de onzas troy. En el año 2005 se finaliza con 14,7 millones; en 2006, con 13,4 millones, y en diciembre de 2007, tras la venta de una gran parte de las reservas con la reserva actual de 9,05 millones de onzas troy, equivalente a 281,5 toneladas de oro (véase gráfico). De acuerdo con datos del FMI, España ocupa el puesto 20.º dentro de las 40 mayores reservas de oro del mundo (a julio de 2015).

Las obras de construcción de la cámara acorazada para la custodia del oro se enmarcaron dentro del proyecto de remodelación del edificio del Banco de España concebido por el arquitecto José Yarnoz Larrosa. Las obras comenzaron a finales de 1932, y terminaron dos años y medio después, con 260 obreros trabajando en tres turnos. La iniciativa del proyecto partió del Subgobernador Pedro Pan, y su coste aproximado fue de 9 millones y medio de pesetas. La inauguración (junto con la del resto de la ampliación), tuvo lugar poco antes de la Guerra Civil, durante la cual sirvió como refugio contra los bombardeos a las familias que habitaban el edificio del banco. La cámara se encuentra a 48 metros de profundidad y su superficie es de 2.500 metros cuadrados. Su diseño parece inspirarse en una construcción similar de la caja acorazada de la Caja de Ahorros de Viena.

La construcción es de hormigón armado y cemento fundido. Las obras requirieron minuciosos estudios geológicos y análisis de los materiales que iban a utilizarse. En la construcción fue necesario entubar y desviar las aguas colgadas presentes en el subsuelo, a 25 m. de profundidad y que presionan las paredes de la cámara. Esta agua corresponde a los arroyos de Las Pascualas (que corre casi a nivel de superficie a lo largo de la Castellana y que fue, en su día, canalizado) y de Oropesa (subterráneo, baja por Alcalá), el mismo que alimenta la fuente de la Cibeles.

El acceso a la cámara se realiza a través de varias puertas acorazadas, la primera de las cuales pesa alrededor de dieciséis toneladas y fue fabricada en Pennsilvania, Estados Unidos, por la empresa Cofres York. Las demás puertas más pequeñas, pero también acorazadas, fueron fabricadas por la misma casa. Su peso oscila entre las quince y las ocho toneladas. El descenso de estas puertas, debido a su peso, fue muy costoso. Los cables de acero que se emplearon quedaban tan deteriorados que solo pudieron ser utilizados una vez y hubo que contratar personal especializado. La puerta acorazada tiene una tolerancia ínfima (de décimas de milímetro), por lo que cualquier impureza en el arco impide que encaje correctamente y que puedan activarse los puntos de anclaje. Además, la puerta es de acero, pero no inoxidable, por lo que hay que cuidar mucho su mantenimiento. Siempre debe estar cubierta de una fina capa de vaselina para evitar que se oxide.

Las medidas de seguridad en todos los accesos a la cámara son extremas. Además de las puertas acorazadas, hay rejas de seguridad y nunca se abre una puerta sin haber cerrado previamente la anterior. En caso de emergencia, se acciona una alarma que libera el agua subterránea que fue canalizada en la obra, inundando este acceso a voluntad. Nunca se ha utilizado este mecanismo, ya que en los ochenta años de vida de la cámara nunca ha habido un intento de acceso no autorizado.

La cámara del oro, propiamente dicha, alberga la colección numismática del Banco de España, solo comparable a las del Museo Arqueológico o de la Real Casa de la Moneda, y parte de las reservas de oro.

La mayoría de las monedas que componen esta colección proceden de las suscripciones populares realizadas durante la guerra civil (donativos, en ocasiones voluntarios) para la financiación del ejército y de los depósitos constituidos a partir del año 37, a raíz del Decreto de Nacionalización de Divisas y Oro. Este decreto obligaba a todos los ciudadanos a entregar el oro en pasta o amonedado que tuvieran en su poder para reponer las reservas de oro que el gobierno republicano había enviado a Moscú como pago por los suministros bélicos. Estas entregas se realizaron en forma de depósitos. La mayoría de ellos no son recuperables porque los depositantes optaron por cobrar en efectivo el valor en oro de sus monedas. Otros, cuyas monedas tenían un valor numismático o sentimental, prefirieron mantener el depósito con la esperanza de recuperarlas cuando lo permitiese la normativa. Aún se siguen devolviendo algunos de estos últimos, siempre que el reclamante pueda acreditar su derecho sobre el depósito.

La colección, de gran valor numismático, está formada por más de medio millón de piezas e incluye monedas de muy diversa procedencia, ya que recoge no solo la historia numismática de la península ibérica, sino que también hay piezas griegas, romanas, bizantinas, de la América hispana, francesas y británicas. Así mismo, cuenta con una completa colección de dólares de oro, acuñados desde el siglo XVII. También hay una colección, menos numerosa, de piezas de plata.

Desde junio de 2011, la red de sucursales del Banco de España está integrada por 15 delegaciones, que ofrecen sus servicios al público y a las entidades de crédito.
Están situadas en A Coruña, Alicante, Badajoz, Barcelona, Bilbao, Las Palmas, Málaga, Murcia, Oviedo, Palma de Mallorca, Sevilla, Tenerife, Valencia, Valladolid y Zaragoza.

Los beneficios del Banco de España se deben, principalmente, a los ingresos por intereses devengados por sus principales activos y a las ganancias procedentes de operaciones financieras (sobre todo, debidas a plusvalías en la venta de divisas y compraventa de valores extranjeros). Estos beneficios se ingresan, íntegramente, en el Tesoro.





</doc>
<doc id="42950" url="https://es.wikipedia.org/wiki?curid=42950" title="Banco">
Banco

Un banco, también conocido como entidad de crédito o entidad de depósito es una empresa financiera que acepta depósitos del público y crea depósitos a la vista, lo que coloquialmente se denominan préstamos; asimismo proveen otro tipo de servicios financieros. La banca, o el sistema bancario, es el conjunto de entidades o instituciones que, dentro de una economía determinada, prestan el servicio de banco. La internacionalización y la globalización promueven la creación de una Banca universal.
Al igual que la palabra española “banco”, la palabra griega (trá‧pe‧za) que se traduce como banco significa literalmente “mesa”. En un contexto financiero, como por ejemplo el trabajo de los cambistas, se refiere al mostrador para la transacción de dinero.

Hay registros existentes de préstamos en Babilonia durante el siglo XVIII a. C., realizados por sacerdotes del templo a los comerciantes. Los trapezitas eran los banqueros en la Antigua Grecia. "Trapeza" era la mesa detrás de la que estaban en las tiendas, a veces destinadas a otro tipo de actividad comercial, pero muy a menudo a las transacciones bancarias. Los bancos más importantes seguían siendo sin embargo los grandes templos, donde los sacerdotes hacían fructificar el dinero que recibían en depósito de acuerdo a los préstamos concedidos a los particulares y a las ciudades. Pythius de Lidia, en Asia Menor, a principios del siglo V a. C., fue el primer banquero individual del cual hay registros. Muchos de los banqueros de las ciudades-estado griegas eran "metecos" o residentes extranjeros. Alrededor de 371 a. C., Pasión, un esclavo, se convirtió en el banquero más rico y más famoso de Grecia. 

Hay prueba de que este tipo de operaciones posiblemente se efectuaban en tiempos de Abraham, pues los antiguos sumerios de las llanuras de Sinar tenían “un sistema singularmente complejo de prestar y recibir préstamos, mantener dinero en depósito y proporcionar cartas de crédito.” En Babilonia, como más tarde en Grecia, la actividad bancaria se centró alrededor de los templos religiosos, cuya naturaleza sacrosanta suponía una seguridad contra los ladrones.

Los bancos en la época romana no funcionaban como los modernos. La mayoría de las actividades bancarias se llevaron a cabo por particulares y no por instituciones. Las grandes inversiones fueron financiadas por los "faeneratores", mientras que quienes trabajaban profesionalmente en el negocio del dinero y el crédito eran conocidos por varios nombres, tales como "argentarii" (banquero), "nummularii" (cambista), y "coactores" (cobradores).

Durante el siglo III los bancos en Persia y otros territorios en el Imperio sasánida emitieron letras de crédito conocidas como "sakks". Se sabe que comerciantes musulmanes "Karimi" han utilizado el sistema de cheque o "sakk" desde la época del califato abasí bajo Harun al-Rashid. En el siglo IX un empresario musulmán ponía efectivo de la forma primitiva de cheque elaborado en China sobre las fuentes en Bagdad, una tradición que se ha reforzado de manera significativa en los siglos XIII y XIV, durante el Imperio mongol. De hecho, los fragmentos encontrados en la Geniza de El Cairo indican que en el siglo XII cheques muy similares a los nuestros estaban en uso, sólo que más pequeños para ahorrar costos en el papel. Contienen una cantidad que deba pagarse, de la orden de. La fecha y el nombre del emisor son igualmente evidentes.

Ferias medievales de comercio, tales como la de Hamburgo, contribuyeron al crecimiento de la banca de una manera curiosa: cambistas expedían documentos disponibles con otras ferias, a cambio de divisas. Estos documentos podían ser cobrados en otra feria en un país diferente o en una feria del futuro en el mismo lugar. Eran rescatables en una fecha futura, a menudo eran descontados por una cantidad comparable a una tasa de interés.

Comenzando alrededor de 1100, la necesidad de transferir grandes sumas de dinero para financiar las Cruzadas estimuló el resurgimiento de la banca en Europa occidental. En 1156, en Génova, se produjeron los primeras contratos de divisas conocidos. Dos hermanos tomaron prestadas 115 libras genovesas y acordaron reembolsar a los agentes del banco en Constantinopla la suma de 460 bezantes un mes después de su llegada a esa ciudad.
El primer banco moderno fue fundado en Génova, Italia en el año 1406, su nombre era Banco di San Giorgio. Los primeros bancos aparecieron en la época del renacimiento en ciudades tales como Venecia, Pisa, Florencia y Génova. 

El nombre "banco" deriva de la palabra italiana "banco", "escritorio", utilizada durante el Renacimiento por los banqueros judíos florentinos quienes hacían sus transacciones sobre una mesa cubierta por un mantel verde.

Los integrantes de la Familia Fugger o Fúcares de Augsburgo, junto con los Welser fueron los banqueros de los reyes de Carlos I y Felipe II de España. Tras el Asedio de Amberes, el centro financiero se trasladó a Ámsterdam hasta la Revolución Industrial. En 1609 fue fundado allí el banco "Wisselbank Amsterdamsche". Oficinas bancarias estaban ubicadas por los centros de comercio, los mayores de los cuales fueron durante el siglo XVII los puertos de Ámsterdam, Londres y Hamburgo. Algunas personas podían participar en el lucrativo comercio de las Indias Orientales mediante la compra de letras de crédito de los bancos.

Durante los siglos XVIII y XIX se produjo un crecimiento masivo en la actividad bancaria. Los bancos jugaron un papel clave en el movimiento de monedas de oro y plata basado en papel moneda, canjeable por sus tenencias. Para la estabilidad económica general y como garantía para los clientes se hizo necesario durante el siglo XX el establecimiento de la regulación financiera en casi todos los países, para establecer las normas mínimas de la actividad bancaria y la competencia financiera y evitar o enfrentar la posibles quiebras bancarias, especialmente durante las crisis económicas.

Desde 1980 existen bancos éticos o sociales (ver: Banca social) siendo su objetivo la financiación de proyectos sociales, ambientales y culturales rechazando cualquier tipo de especulación con dichos fondos.

Muchas de estas operaciones bancarias básicas se derivan de parámetros de los Estados Financieros secundarios y primarios creando nuevos índices para medir.

Conformadas por aquellas operaciones por las que el banco capta, recibe o recolecta dinero de las personas. 

Las operaciones de captación de recursos, denominadas operaciones de carácter pasivo se materializan a través de los depósitos. Los depósitos bancarios pueden clasificarse en tres grandes categorías:

Las cuentas, por tanto, son totalmente líquidas. La diferencia entre ambas es que las cuentas corrientes pueden ser movilizadas mediante cheque y pagaré, mientras que en los depósitos a la vista es necesario efectuar el reintegro en ventanilla o a través de los cajeros electrónicos, pero no es posible ni el uso de cheques ni pagarés. Otra diferencia es que en los depósitos a la vista, el banco puede exigir el preaviso.

Los depósitos a plazo pueden ser movilizados antes del vencimiento del plazo, a cambio del pago de una comisión, que nunca puede ser superior en importe al montante de los intereses devengados.

Estos depósitos, dependiendo del tipo de cuenta, pagan unos intereses (intereses de captación).

La colocación permite poner dinero en circulación en la economía; es decir, los bancos generan nuevo dinero del dinero o los recursos que obtienen a través de la captación y, con estos, otorgan créditos a las personas, empresas u organizaciones que los soliciten. Por dar estos préstamos el banco cobra, dependiendo del tipo de préstamo, unas cantidades de dinero que se llaman intereses (intereses de colocación) y comisiones.

De los fondos que los bancos captan es obligado mantener una parte líquida como reserva para hacer frente a las posibles demandas de restitución de los clientes, lo que recibe el nombre de encaje bancario. Tienen un carácter improductivo, puesto que no pueden estar invertidos.

El encaje es un porcentaje del total de los depósitos que reciben las instituciones financieras, el cual se debe conservar permanentemente, ya sea en efectivo en sus cajas o en sus cuentas en el banco central. El encaje tiene como fin garantizar el retorno del dinero a los ahorradores o clientes del banco en caso de que ellos lo soliciten o de que se le presenten problemas de liquidez a la institución financiera. De esta forma, se disminuye el riesgo de la pérdida del dinero de los ahorradores.

Otra parte de los recursos se destina a activos rentables. Dentro de estos activos rentables una primera parte se compone de los activos rentables en:

Se pueden desarrollar múltiples clasificaciones acerca de los préstamos:

Las cuentas de crédito son operaciones por las que el Banco concede crédito al cliente (acreditado) por un cierto plazo, (puede establecer su prórroga automática) y hasta una suma determinada que pone a disposición del cliente. El cliente viene obligado a satisfacer al Banco una comisión de apertura, a reintegrar al Banco el saldo a su favor que arroje la cuenta de crédito al tiempo de la cancelación y liquidación de la misma y a pagar intereses por las cantidades dispuestas, y otra parte menor por las cantidades no dispuestas.

El descuento de efectos, como vía de financiación a las empresas, consiste en una operación por la que un banco anticipa a una persona el importe de un crédito pecuniario que ésta tiene contra un tercero, con deducción de un interés o porcentaje y a cambio de la cesión de crédito mismo salvo buen fin.

La segunda parte de los activos rentables está constituida por la cartera de valores donde se distingue renta fija por una parte tanto pública como privada y renta variable por otra.

Un tercer tipo de operación efectuada por los bancos sería la cesión temporal de activos, constituye una modalidad en la que las entidades de crédito ceden a un cliente una parte de un activo (por ejemplo, un crédito) de su propiedad, lo que les permite recuperar de un tercero una proporción de mismo a cambio de un rendimiento.

En definitiva, el problema básico de un banco es conseguir la máxima rentabilidad, pero asegurando al mismo tiempo la liquidez suficiente y restringiendo al máximo el riesgo asegurando su solvencia. La solvencia, además, debe ser asegurada con unos recursos propios (capital y reservas) suficientes, que le permitan hacer frente a posibles situaciones de riesgo derivadas de la insolvencia de sus deudores.

Sabiendo que los bancos pagan una cantidad de dinero a las personas u organizaciones que depositan sus recursos en el banco (intereses de captación) y que cobran dinero por dar préstamos a quienes los soliciten (intereses de colocación), cabe preguntarse de dónde obtiene un banco sus ganancias. La respuesta es que los tipos de interés de colocación, en la mayoría de los países, son más altos que los intereses de captación; de manera que los bancos cobran más por dar recursos que lo que pagan por captarlos. A la diferencia entre la tasa de interés de colocación y la de captación se le denomina margen de intermediación. Los bancos, por lo tanto, obtienen más ganancias cuanto más grande sea el margen de intermediación.

Los bancos actúan como intermediarios. Su negocio es comerciar con dinero como si fuera cualquier otro tipo de bien o de mercancía.



Independiente de los tipos de bancos, estos permiten que el dinero circule en la economía, que el dinero que algunas personas u organizaciones tengan disponible pueda pasar a otras que no lo tienen y que lo solicitan. De esta forma facilita las actividades de estas personas y organizaciones y mejora el desempeño de la economía en general. De lo anterior se colige la importancia de la banca en la historia económica de la humanidad.
Dependiendo de las leyes de los países, los bancos pueden cumplir funciones adicionales a las antes mencionadas; por ejemplo negociar acciones, bonos del gobierno, monedas de otros países, etc. Cuando estas actividades las realiza un solo banco se denomina banca universal o banca múltiple. Igualmente, estas actividades pueden ser realizadas de manera separada por bancos especializados en una o más actividades en particular. Esto se denomina banca especializada. Actualmente, la prestación de servicios experimenta una revolución gracias a la influencia de las nuevas tecnologías.

Según el origen del capital:

Según el tipo de operación:

Otros:


Un banco es una institución financiera, junto con las entidades de crédito y las entidades aseguradoras.



</doc>
<doc id="42951" url="https://es.wikipedia.org/wiki?curid=42951" title="Músculo lingual inferior">
Músculo lingual inferior

El músculo lingual inferior ("Lingualis inferior") es un músculo que se encuentra en la parte inferior de la lengua. Se inserta, en las astas menores del hioides; por delante en la mucosa de la punta de la lengua. Lo inerva el nervio hipogloso y lingual. Es el depresor y retractor de la punta de la lengua.


</doc>
<doc id="42953" url="https://es.wikipedia.org/wiki?curid=42953" title="Sistema Europeo de Bancos Centrales">
Sistema Europeo de Bancos Centrales

El Sistema Europeo de Bancos Centrales (SEBC) está compuesto por el Banco Central Europeo (BCE) y los bancos centrales nacionales de los Estados miembros de la Unión Europea (UE) independientemente de si están integrados en la eurozona o no. El Tratado de la Unión Europea atribuye al SEBC las funciones de diseño y ejecución de la política monetaria de los países que conformen el área del euro. El objetivo primordial que el Tratado asigna al SEBC es el de mantener la estabilidad de precios, sin perjuicio de lo cual "apoyará las políticas económicas generales de la Comunidad". En principio se preveía que todos los estados miembros de la Unión Europea se integraran en el Euro, sin embargo al no ser así, la entidad encargada de la política monetaria en la zona euro ha pasado a ser el Eurosistema, mientras que el SEBC asumirá estas funciones en el momento en que todos los estados adopten el Euro.

El SEBC se compone de los siguientes 27 bancos nacionales junto al BCE. La primera sección es una lista de aquellos que pertenecen a la eurozona (países que han adoptado el euro como moneda única). La segunda sección contiene aquellos que mantienen su propia moneda.




</doc>
<doc id="42959" url="https://es.wikipedia.org/wiki?curid=42959" title="Pervez Musharraf">
Pervez Musharraf

Pervez Musharraf (Delhi, 10 de agosto de 1943) es un político pakistaní. Fue presidente y jefe del ejército de Pakistán entre 2001 y 2008, tras asumir el poder el 12 de octubre de 1999 mediante un golpe de estado en el que no se produjeron víctimas.

Nació el 10 de agosto de 1943 en Delhi, Raj Británico, y tras la partición del país asiático en 1947 se mudó con su familia a la ciudad de Karachi (Pakistán).

Entre 1949 y 1956, Musharraf vivió en Turquía, donde su padre fue enviado como diplomático. Allí recibió sus primeros años de educación, que luego completaría en colegios cristianos de Pakistán como el San Patricio en Karachi, y Forman en Lahore.

En 1961 ingresó en la Academia Militar de Pakistán y en 1964, tras graduarse como suboficial, fue destinado a un regimiento de artillería con el que participó en la segunda guerra indo-pakistaní de 1965, centrada en el territorio de Cachemira. Fue condecorado con la medalla al valor.

En 1971 participó en la nueva guerra con India precipitada por la secesión de Bangladés, el antiguo Pakistán Oriental, como comandante de compañía en un batallón de comandos. En 1991 fue elevado a general de brigada de infantería, en 1993 sirvió como director de operaciones militares en el cuartel general del ejército y en 1995 recibió el galón de teniente general y el mando de un prestigioso cuerpo de élite del ejército.

Participó en dos guerras contra la India a lo largo de su carrera militar y tras presidir el Alto Mando del ejército pakistaní encabezó el golpe de estado de 1999 en contra de Nawaz Sharif, al cual condenó a un arresto domiciliario. El 20 de junio de 2001 se convirtió oficialmente en el presidente de la nación y tras los atentados del 11 de septiembre de 2001 se convirtió en uno de los principales aliados de los Estados Unidos en su lucha contra el terrorismo.

Musharraf fue reelegido como presidente el 6 de octubre de 2007, según informó el gobierno local, aunque el resultado definitivo se confirmará cuando el Tribunal Supremo falle sobre la legalidad del proceso.
Un día después de ser reelegido, el 7 de octubre, atacó los santuarios talibanes del norte de Pakistán.

El 29 de noviembre de 2007, después de que el Tribunal Supremo validará las elecciones y Musharraf abandonara su cargo como Jefe de las Fuerzas Armadas, juró su cargo como Presidente del país para un mandato de cinco años.

El 3 de noviembre de 2007, Musharraf declaró el estado de excepción en el país por las «injerencias judiciales». Justificó la decisión porque «el sistema gubernamental del país estaba paralizado por las injerencias judiciales» y a causa del «choque entre las instituciones gubernamentales y el sistema judicial», por lo que se requiere de un «nuevo orden constitucional provisional». En un comunicado emitido en televisión, Musharraf afirmó que esperaba que las libertades democráticas sean restauradas tras las elecciones generales, previstas en un principio para enero de 2008. La decisión se produjo en medio del proceso del Tribunal Supremo de Pakistán que debía decidir sobre la validez de la reelección de Musharraf para un nuevo mandato presidencial de cinco años. Musharraf, se reunió previamente con los líderes del Gobierno para analizar la situación en el país.

El presidente del Tribunal Supremo de Pakistán, Iftikhar Chaudhry, fue puesto «bajo custodia» en un lugar no revelado poco después de la declaración del estado de excepción en el país, según fuentes judiciales, junto con otros ocho magistrados. Antes de su arresto, Chaudhry y los otros ocho magistrados declararon ilegal e inconstitucional el nuevo orden proclamado por el régimen de Pervez Musharraf.

El 18 de agosto de 2008, mediante un mensaje televisivo, Musharraf anunció su abandono de la presidencia de Pakistán ante el proceso de destitución iniciado por el Gobierno de Yousaf Raza Gillani y los líderes seguidores de la asesinada Benazir Bhutto. Al día siguiente, 19 de agosto, se iba a votar en la Asamblea Nacional el proceso de destitución por violación de la Constitución y la propuesta contaba con amplia mayoría parlamentaria para llegar a término. En la intervención declaró:

Tras su dimisión, fue sucedido interinamente por Muhammad Mian Soomro, siendo sustituido oficialmente por Asif Ali Zardari, viudo de Benazir Bhutto.

El hijo de la asesinada líder del Partido Popular de Pakistán (PPP), Benazir Bhutto, Bilawal Bhutto, señaló que con la marcha de Musharraf «se ha eliminado un obstáculo para la democracia». Bilawal estaba destinado a asumir el liderazgo del PPP cuando llegase a la edad de 25 años. Su formación está comprometida en restituir en sus cargos a los magistrados del Tribunal Supremo expulsados por Musharraf. Con esta opinión se alinea con su partido aliado en el Gobierno, la Liga Musulmana-N, que se mostró partidaria de restaurar «pronto» en sus cargos a los jueces.

El gubernamental Partido Popular de Pakistán (PPP), calificó la dimisión del presidente como «una victoria del pueblo ... Finalmente los pakistaníes consiguen librarse de la dictadura y es un motivo de alegría» dijo un portavoz de la secretaría de información, la más importante de las que componen el Gobierno. La fuente agregó que la salida del exgeneral traería estabilidad política al país.

La gubernamental Liga Musulmana-N, liderada por el ex primer ministro Nawaz Sharif, felicitó la dimisión del presidente, y se mostró contraria a otorgarle inmunidad. «Nuestra posición respecto a concederle una salida es clara. Musharraf ha quebrantado la Constitución y debe pagar por ello», explicó el secretario de información, Ahsan Iqbal.

El ministro pakistaní de Asuntos Exteriores, Shah Mehmud Qureshi, mostró su confianza en que la dimisión traería «estabilidad política» a Pakistán y dijo:

La Liga Musulmana-Q, formación afín a Pervez Musharraf, calificó la decisión del presidente pakistaní de dimitir como «digna y elegante» y aseguró que «fortalecerá el sistema democrático».

El 17 de diciembre de 2019 fue condenado a muerte por traición in absentia, tras una acusación que pesaba sobre él desde 2013 por haber suspendido la Constitución e impuesto el estado de emergencia en 2007. Se trataba de la primera vez en la historia del país en la que un jefe militar era declarado culpable de alta traición y, además, sentenciado a muerte. 




</doc>
<doc id="42975" url="https://es.wikipedia.org/wiki?curid=42975" title="Juan José Millás">
Juan José Millás

Juan José Millás García o Juanjo Millás (Valencia, 31 de enero de 1946) es un escritor y periodista español. Su obra narrativa se ha traducido a 23 idiomas.

Tras vivir en Valencia los primeros años de su vida, se trasladó con su numerosa familia a Madrid (1952), al barrio de la Prosperidad, ciudad donde ha vivido la mayor parte de su vida. Fue un mal aunque curioso estudiante y cursó la mayoría de sus estudios como nocturno mientras trabajaba en una caja de ahorros. En la universidad empezó Filosofía y Letras, que abandonó al tercer año. Obtuvo un trabajo como administrativo en Iberia y se consagró a la lectura y la escritura. 

Su primera novela estaba influida por Julio Cortázar y posee las lacras acumuladas del experimentalismo de esa época y de ser un autor primerizo, aunque muy original; la segunda, "Cerbero son las sombras" (1975), obtuvo el premio Sésamo y le abrió las puertas de la crítica. Gracias a un entusiasta miembro del jurado, Juan García Hortelano, pudo publicar después "Visión del ahogado" (1977) y "El jardín vacío" (1981) en la prestigiosa editorial Alfaguara. Pero su novela más popular, y también la más trascendente para su obra gracias a escribirla con la libertad de no pensar en la crítica, fue "Papel mojado" (1983), un encargo para una editorial de literatura juvenil que se vendió y sigue vendiendo mucho. Simultáneamente empezó a colaborar en la prensa con un gran éxito, nacido de su imaginación y su insobornable compromiso con los desfavorecidos, de suerte que dejó el empleo en el gabinete de prensa de Iberia y ahora vive del periodismo y la literatura. Se casó en segundas nupcias en 1987 con la psicóloga Isabel Menéndez, con quien ha tenido a su segundo hijo. 

En su numerosa obra, de introspección psicológica en su mayoría, cualquier hecho cotidiano se puede convertir en un suceso fantástico. Para ello creó un género literario personal, el "articuento", en el que una historia cotidiana se transforma por obra de la fantasía en un punto de vista para mirar la realidad de forma crítica. Sus columnas de los viernes en "El País" han alcanzado un gran número de seguidores por la sutileza y originalidad de su punto de vista para tratar los temas de la actualidad, así como por su gran compromiso social y la calidad de su estilo. En el programa "La Ventana" de la Cadena SER dispone de un espacio el que anima a los oyentes a enviar pequeños relatos sobre palabras del diccionario. En la actualidad, está construyendo un glosario con estos relatos logrando una numerosa participación. Sus obras han sido traducidas a veintitrés idiomas, entre ellos, inglés, francés, alemán, portugués, italiano, sueco, danés, noruego y holandés. En su novela de 2006, titulada "Laura y Julio" encontramos plasmadas sus principales obsesiones: el problema de la identidad, la simetría, la soledad próspera, los otros espacios habitables dentro de nuestro espacio, el amor, la fidelidad y los celos.

Millás ha recibido numerosos reconocimientos y premios, entre los que se encuentran algunos de los más importantes de España, como el Nadal, el Planeta y el Nacional de Narrativa, los dos últimos por su novela autobiográfica "El mundo", unas memorias de infancia, casi de adolescencia, que cuentan la historia de un muchacho que vive en una calle y cuyo sueño es escapar de esa calle.

En plena crisis sanitaria y económica, y bajo el gobierno de su amado PSOE, se dedicó a escribir sobre entelequias.

Juan José Millás ha encontrado en Wikipedia, concretamente en este mismo artículo, un peculiar espacio autorreferencial, muy adecuado a su concepción de la vida y la literatura. Con motivo de un vandalismo anónimo aparecido el 16 de octubre de 2008 y que se mantuvo varios días (fue corregido parcialmente el 25 de octubre y totalmente el 10 de noviembre), publicó un artículo en que lo describe con humor y amplia visión: 







</doc>
<doc id="42981" url="https://es.wikipedia.org/wiki?curid=42981" title="Estuario">
Estuario

En geografía, un estuario es la desembocadura, en el mar, de un río amplio y profundo donde se intercambia agua salada (marina) y agua dulce (fluvial), debido a las mareas. La desembocadura del estuario está formada por un solo brazo ancho en forma de embudo ensanchado. Suele tener playas a ambos lados, en las que la retirada de las aguas permite el crecimiento de algunas especies vegetales que soportan aguas salinas. En resumen, es el accidente geográfico que se genera cuando el agua dulce se mezcla con el agua salada.
Los estuarios se originan por la entrada de aguas marinas durante la pleamar, que retienen las aguas del río, mientras que durante la bajamar, todas las aguas comienzan a entrar a gran velocidad en el mar u océano, lo que contribuye a limpiar y profundizar su cauce, dejando a menudo, grandes zonas de marismas a los lados.

Las mareas de mayor amplitud en el mundo tienen lugar en los estuarios del noroeste de Francia y, sobre todo, en la costa oriental del Canadá (bahía de Fundy, unos 16 metros). El río Rance (Francia) tiene un sistema de producción hidroeléctrica, usando la fuerza de las mareas en el estuario de su desembocadura, tanto con la pleamar como cuando se produce la bajamar. Los ecosistemas de los estuarios suelen caracterizarse por una alta productividad biológica y por su gran biodiversidad.

Los estuarios en la zona ecuatorial son muy escasos, incluso en los océanos, debido a la baja amplitud de las mareas y a la gran cantidad de sedimentos que arrastran los ríos. Es así como la desembocadura del Níger, el Amazonas, el Orinoco y muchos otros ríos próximos al ecuador terrestre son deltas en vez de estuarios.

Un ejemplo de estuario es el mar de la Paja, la parte final y más ancha del río Tajo, en cuya margen se sitúa la ciudad de Lisboa. El estuario más grande del planeta es el formado, en un caso bastante atípico, por el río Paraná: después de un delta de 320km de extensión forma un estuario de más de 230 km de ancho, habitualmente considerado desde la conquista europea como un curso independiente río de la Plata, actual frontera entre la República Argentina y la República Oriental del Uruguay.
Como ya se ha dicho, los estuarios se presentan en los océanos, donde el efecto de las mareas puede ser más intenso. En cambio, en los mares donde su menor extensión limita la acción de las mareas, predominan las desembocaduras en forma de delta, como sucede en los ríos Nilo, Po, Ebro, Misisipi, Mackenzie, Yukon, Lena, Obi, Amur y muchos otros. En este caso, el agua marina se presenta como un obstáculo a la penetración del agua del mar, por lo que los sedimentos arrastrados por el río pueden acumularse formando flechas o barras litorales, que pueden encerrar a lagunas o albuferas y, por supuesto, formar deltas.
1. Existen también ríos que desembocan en el océano formando deltas, como el Níger en África, el Orinoco en América del Sur, el Ganges en Asia y otros. En estos casos, existen otros fenómenos como el abultamiento ecuatorial terrestre (que por la fuerza centrífuga limita la acción de las mareas) o la acción de las corrientes oceánicas que pueden dar origen a la formación de deltas o estuarios según sea su dirección en contra o a favor de la rotación terrestre. 

2. Otro caso atípico es la alteración de deltas en formación debido a causas naturales y, más frecuentemente, a causas de orden humano, como la construcción de represas, que pueden limitar los aportes de sedimentos a las tierras deltaicas (el ejemplo del embalse de Mequinenza para el Delta del Ebro) y como está sucediendo en el caso de la represa de Asuán, en Egipto.

3. La explotación petrolera en zonas costeras también ha dado lugar a alteraciones muy importantes en las desembocaduras de los ríos, como ha sucedido en el delta del Misisipi que ha desaparecido en gra parte por el hundimiento o subsidencia

- Información, Tipos, animales del bioma estuario. 


</doc>
<doc id="42982" url="https://es.wikipedia.org/wiki?curid=42982" title="Meronimia">
Meronimia

La meronimia es una relación semántica asimétrica entre los significados de dos palabras dentro del mismo campo semántico. Se denomina merónimo a la palabra cuyo significado constituye una parte del significado total de otra palabra, denominada ésta holónimo. 
a su vez:
Por lo tanto: 




</doc>
<doc id="42984" url="https://es.wikipedia.org/wiki?curid=42984" title="Bellota">
Bellota

La bellota (del árabe "ballūta", encina) es un fruto característico de las especies del género "Quercus" (fam. Fagaceae).

Dentro de este género, hay numerosas especies arbóreas que dan bellotas como el roble, la encina, el alcornoque, el quejigo y el melojo. Esos frutos son los preferidos para las ardillas.

En las encinas de la península ibérica se diferencian dos subespecies: ("Quercus ilex" subsp. "ilex") y ("Quercus ilex" subsp. "ballota") que tienen ligeras diferencias morfológicas y fisiológicas lo que se traduce en unos frutos diferentes, con bellotas más alargadas amargas en la primera planta y bellotas más redondeadas y dulces en la segunda.

En Extremadura y Andalucía los cerdos pastan por las dehesas aprovechando las bellotas caídas, mientras las cabras frecuentemente trepan a los árboles buscándolas. Los vacceos y otros pueblos del centro y norte de la Iberia prerromana obtenían harina panificable de ellas. Así lo sostenía Estrabón en sus escritos sobre los pueblos del norte de la península ibérica:

Allá donde se aprecia su consumo humano, el fruto se consume crudo o tostado a la brasa. También se elabora licor.


"Incluyendo los posibles híbridos (véase hibridaciones en la península ibérica en quercus)














Pelasgo mereció el reconocimiento de los arcadios por haberles enseñado a comer bellotas en lugar de hierbas silvestres. 

Bellota es uno de los frutos que Circe dio para alimentarse a los compañeros de Ulises, transformados en cerdos. 

Todos los árboles que llevaban bellotas estaban consagrados a Júpiter, en especial el nogal, llamado juglans como si dijéramos "Jovis juglans" (bellotas de Jupiter).

Mención especial merece, en la gastronomía de España y la gastronomía de Portugal, el jamón ibérico de bellota. Jamón ibérico de bellota, o terminado en «bellota», animal que se cría en dehesa, recibe una alimentación a base de hierbas y piensos (cereales y leguminosas), y en el período de montanera (engorde) (unos 2, 3 o hasta 4 meses entre noviembre y marzo) se alimenta de bellotas y pastos, alcanzando el peso óptimo de sacrificio.


</doc>
<doc id="42986" url="https://es.wikipedia.org/wiki?curid=42986" title="Literatura finesa">
Literatura finesa

El idioma finés permaneció como lengua no escrita hasta el siglo XVI pero por supuesto eso no quiere decir que durante siglos careciese de literatura, el finés gozó de una fértil literatura popular que nos ha llegado gracias a los cantores populares que a lo largo de generaciones transmitieron esos textos, lógicamente con modificaciones y en múltiples versiones.

Literatura popular

La poesía popular finesa se conserva en los archivos de la Sociedad de Literatura Finesa y solo una parte se publicó en la colección "Suomen Kansan Vanhat Runot" en 33 volúmenes publicados entre 1908 y 1948 que recogen 85.000 piezas con 1.270.000 versos.

La mayor parte de esa literatura popular se conservó en la zona más oriental del dominio lingüístico de la lengua finesa Carelia e Ingria y en menor medida en el oeste de Finlandia pero los poemas conservan trazos lingüísticos y temáticos propios del occidente del dominio lingüístico finés.

La poesía popular finesa puede ser poesía lírica, una poesía individual que se centra en la emoción y el lirismo del poema utilizando imágenes sacadas de la naturaleza y de las actividades de la vida cotidiana o poesía épica, poemas más largos y extensos, en torno a los 100 o 200 versos, que cuentan preferentemente una sucesión de acontecimientos mitológicos.
Aparte de estos dos grandes grupos hay otro tipo de poemas como las poesías para las bodas, de caza, lamentaciones.

Los encargados de conservar y cantar los poemas populares eran los cantores populares o bardos, a veces acompañados por los kantele.
En el norte eran dos los cantores, uno que recitaba primero el verso y otro que lo repetía, mientras que en el sur el cantor era generalmente una mujer acompañada por un coro.
Entre los cantores populares destacaron Arhippa Perttunen y Larin Paraske.

En 1564 se recoge el primer poema popular finés pero fueron escasos los poemas que se recogieron en parte por considerarse un fenómeno pagano y en parte por no ser el finés una lengua minorizada.
En el siglo XIX el romanticismo se va a interesar por la literatura popular y Elias Lönnrot partiendo de poemas recogidos por él y por otros entusiastas redactó la epopeya Kalevala (1835-1849) que consagró la literatura popular como una de las principales fuentes de la literatura finesa escrita.

Aunque antes de la Reforma ya existían textos religiosos en finés, no conservados, fue Mikael Agricola primer obispo protestante de Finlandia el autor de los primeros libros en finés, en 1543 publicó Abckiria, un pequeño abecedario y catecismo, "Rucouskiria" es un libro de oraciones publicado en 1544, en 1548 apareció su traducción del Nuevo Testamento fundamental en la estandarización del finés.

Epígonos de Agricola continuaron su labor como Jacobus Finno, autor de un libro de cánticos en 1583, Hemmiki Maskulainen, también autor de un libro de cánticos en 1605 y traductor de "Piae Cantiones" en 1616, Eerik Sorolainen autor de "Postilla", colección de sermones en dos volúmenes publicados en 1621 y 1625 y que se usó en las iglesias finesas por más de dos siglos.

El siglo XVIII estuvo marcado por el establecimiento de la Academia de Turku que aunque favoreció fundamentalmente al sueco, la lengua de los profesores también ejerció influencia sobre la literatura finesa, apareció el primer autor teatral, Eerik Justander que tradujo una obra sueca al finés que no se conserva.
Mattias Salamnius escribió una descripción de la vida de Jesús en métrica kaleviana "Ilo-Laulo Jesuxesta" (1690), que vio reediciones en los dos siglos siguientes.
En el seno de la Academia de Turku comenzaron a parecer hombres que se interesaron por la lengua finesa como Daniel Juslenius, autor de un diccionario trilingüe o Henrik Florinus, autor de una nomenclatura del vocabulario finés.
"Suomenkieliset" (1775-1776) fue el primer diario en finés.

El comienzo del siglo XIX coincidió con el fin del dominio sueco sobre Finlandia que quedó a partir de 1809 bajo el dominio de Rusia, como un Gran Ducado autónomo que conservó las antiguas instituciones suecas y en el que a la lengua sueca seguía siento la oficial y en el que se comenzaba a crear una conciencia nacional que llegó también a la literatura, que se expresaba mayoritariamente en sueco, a principios de siglo tan sólo algunos poetas como Samuel Gustaf Bergh apodado "Kallio" o Jacob Judén o el dramaturgo Pietari Hannikaien escribían en finés, aunque numerosos poetas populares como Vihta-paavo elaboraban una poesía local enraizada en la tradición.
Entre algunos intelectuales de lengua sueca comenzó a extenderse la consideración del finés como lengua nacional de Finlandia, entre ellos destacaron Johan Vilhelm Snellman que en 1863 consiguió un estatus legal para el finés semejante al del sueco.

Tras la publicación del Kalevala y su éxito el número de autores en finés aumentó considerablemente enriqueciéndose con nuevos géneros y temas.
Aleksis Kivi fue el creador de la primera gran novela en finés, "Seitsemän veljestä" (Los siete hermanos) publicada en 1870.
Kaarlo Kramsu introdujo en la literatura finesa la balada histórica y la poesía social.
A partir de 1880 será el realismo la corriente literaria predominante con autores como Minna Canth, Juhani Aho, Arvid Järnefelt y Teuvo Pakkala.
Con el fin de siglo aumentó en la literatura la importancia de lo imaginario y el sentimiento y los elementos nacionales van a ser omnipresentes, este nuevo estilo se denomina neorrealismo nacional y su principal representante fue Eino Leino, aunque cultivó todos los géneros de la poesía y donde más destacó, sobre todo en la serie "Helkavirsiä" (1903-1916).

Con la entrada del nuevo siglo se dejó sentir en Finlandia la influencia del simbolismo, en Otto Manninen con influencias del neorrealismo, V. A. Koskenniemi con su poesía pesimista y L. Onerva con una poesía más experimental e intimista.
Pero sobre todo el siglo XX es importante por el desarrollo de la prosa finesa, que vive una auténtica edad de oro, una prosa en la que el peso de la naturaleza es opresor, con protagonistas procedentes de la gente corriente, individualistas que reivindican la justicia social, un realismo a la vez combinado con humor.
Los más grandes prosistas son Ilmaro Kianto que describe la pobreza rural, Joel Lehtonen que dejó una de las mejores novelas finesa, "Putkinotko" (1919-1920), metáfora de la decepción que lleva el camino de dos ideales a la realidad y Volter Kilpi autor con un estilo y técnica propia que recuerda a Marcel Proust.
Con gran calidad pero sin la genialidad de los anteriores sobresalen Maiju Lassila, Maria Jotuni, Frans Eemil Sillanpää que fue el único finés en recibir el Premio Nobel (1939), Heikki Toppila, Aino Kallas, Johannes Linnankoski y Maila Talvio.

Una nueva generación aparece a comienzos de los años 20, conocidos con el nombre de los portadores del Fuego ("Tulenkantajat"), título que llevaba el álbum literario que publicaron de 1924 a 1927, con un nuevo espirito de libertad, tanto en la métrica de la poesía como en los temas, dando la espalda al pasado, Katri Vala es la autor tipo de esta generación y Olavi Paavolainen como prosista, de esa generación salieron grandes poetas, ya con otro estilo, como Mustapää con su característico estilo semierudito y que se dejaba influir por numerosas culturas.
El más conocido de los autores de los Portadores del Fuego fue Mika Waltari.
En los años treinta se abandonó la línea rupturista y se vuelven a formas más clásicas, tan sólo destaca el grupo literario Kiila, con los poetas Viljo Kajava y Arvo Turtiainen y la prosista Elvi Sinervo.
El teatro en Finlandia gozaba de una vasta red de salas pero el número de autores de calidad era escaso, destacaron Maria Jotuni, Ilmari Turja, Hella Wuolijoki, esta última de origen estonio.

La II Guerra Mundial supuso una ruptura en el panorama literario finés, surge toda una generación de autores marcados por la experiencia de la guerra, el país vio reducido su territorio y casi toda la población de Carelia pasó como refugiada a Finlandia, se cuestionan los antiguos valores, aumenta la producción literaria y la traducción de obras de otras literaturas.

Surge una nueva poesía, con un lenguaje más cercano a la lengua hablada, utilizando el verso libre, centrada en si, entre los autores destacan Lauri Viita, Helvi Juvonen, Pentti Holappa, Eeva-Liisa Manner, Eila Kivikkaho y el poeta más original Paavo Haavikko.

En la narrativa surgen dos concepciones diferentes, una más tradicional marcada por el realismo agrario o obrero con escritores como Veikko Huovinen y sobre todo Väinö Linna, su "Tuntematon sotilas" (1954), centrada en las relaciones entre oficiales y soldados rasos durante la Segunda Guerra, vendió más de un millón de ejemplares y suscitó un fuerte debate nacional por la autocrítica a la sociedad finesa.
La otra tendencia en la narrativa es la más experimental, en la búsqueda de nuevas soluciones de estilo y estructura, Veijo Meri es el autor más destacado de esta tendencia, con un sentido de lo grotesco en el que se adivina la crisis de un pueblo.
Otros autores, con es el caso de Eeva Joenpelto, combinan las dos tendencias.

En los años sesenta la lengua coloquial entra en la poesía, que se compromete con la realidad social circundante, de forma contestataria, el primero autor que rompe con la poesía de los cincuenta es Pentti Saarikoski.
En reacción a esta poesía aparecen autores que centran su obra en la vida cotidiana o en la naturaleza, rechazando el compromiso político, es el caso de Helana Anhava o buscando nuevas formas en la poesía japonesa como Veikko Polameri.

En cuanto a la prosa durante los años 60 y 70 destacan nombres como el de Hannu Salama, autor de novelas obreras de carácter épico, el ambiente obrero también se localiza en las obras de Samuli Paronen con un acento muy fuerte en el infraproletariado.
La crisis de la clase media y el conflicto de generaciones centra las obras de Kerttu-Kaarina Suosalmi y el problema de la población evacuada de Carelia está más presente en las obras de Eeva Kilpi e Iris Kähäri.
La evolución de la vida rural es otro de los grandes temas de la prosa, autores como Eino Säisä, Heikki Turunen o Kalle Päätalo.

En los años 80 se desarrolla extraordinariamente el relato, con autores como Rosa Liksom, Joni Skiftesvik o Leena Krohn.
Entre los novelistas de la última generación destacan Olli Jalonen, Matti Pulkkinen y Maarit Verronen.


</doc>
<doc id="43004" url="https://es.wikipedia.org/wiki?curid=43004" title="Demografía de Cuba">
Demografía de Cuba

La República de Cuba tiene una población de 11 167 325 habitantes en 2012, según la Oficina Nacional de Estadística e Información (ONEI), organismo estatal encargado de llevar los datos demográficos cubanos. Se trata del país más poblado del Caribe insular; sin embargo, su densidad de población (101,6 hab/km² según ONEI 2012) es menor que la de Haití, República Dominicana o Puerto Rico. Se observan elevados indicadores sociales con respecto a los demás países de Latinoamérica, como la esperanza de vida, el índice de alfabetización y baja mortalidad infantil, pobreza, pobreza extrema y desempleo. Ocupa la posición 64 entre los 178 países evaluados por el índice de desempeño ambiental y la posición 68 de 150 en el índice de desarrollo humano.

La población cubana actual es el resultado de un proceso de mestizaje de las diferentes etnias, culturas y razas inmigrantes, debido a que la mayor parte de la población indígena resultó diezmada. Las mayores fuentes de la inmigración hacia Cuba, están en Europa, en concreto España y en África occidental y central, el Congo, Guinea, etc. La inmigración china constituyó otra fuente de la nacionalidad cubana aunque en menor grado.

A la llegada de Cristóbal Colón en 1492, la isla estaba habitada por diferentes grupos poblacionales aborígenes, fundamentalmente siboneyes y taínos, que habían llegado a través de la Florida y el arco de las Antillas Menores respectivamente. Luego de un breve período de despoblamiento que siguió a la fundación de las siete primeras villas, se inició una afluencia masiva de inmigrantes españoles, sobre todo de las capas más bajas de la sociedad que comenzaron a fomentar el cultivo de plantaciones de caña de azúcar y café, entre otros. Varios cientos de miles de negros africanos fueron introducidos en la isla como mano de obra esclava. Así comenzó el proceso de mestizaje de la población, que se va a mantener durante toda la colonia y hasta nuestros días. Al instaurarse la república en 1902, oleadas masivas de gallegos, asturianos y canarios llegaron a Cuba huyendo de la pobreza y las guerras que sacudían a España y al resto de Europa durante toda la primera mitad del siglo XX. Europeos de distintas regiones también emigraron hacia la isla. Luego del triunfo de la revolución de 1959 de tipo socialista, el panorama y las características migratorias se invirtieron, la emigración hacia Estados Unidos, fundamentalmente por motivos políticos, económicos y familiares, caracterizan toda la etapa revolucionaria cubana. Aunque se dieron algunas migraciones hacia Cuba de rusos y ucranianos, la tendencia fue, y es aún, a emigrar del país.

Cuba está dividida en 15 provincias y un municipio especial, las cuales están divididas a su vez en 168 municipios. El número de municipios es variable en las diferentes regiones y va desde 8 (Cienfuegos, Camagüey y Las Tunas) hasta 15 en la capital del país.
La extensión territorial de las provincias presenta grandes diferencias: la ciudad de La Habana con poco más de 721, 01 km² es la provincia más pequeña, seguida de Mayabeque con 3 743,81 km² mientras que Camagüey es la más extensa, con 15 615,0 km².
El área de los municipios es diferente en cada provincia; mientras que Centro Habana en la provincia Ciudad de La Habana, es el de menor extensión de 2,8 km², Ciénaga de Zapata en la provincia de Matanzas el mayor con 4 520,0 km².
La población cubana se encuentra distribuida de manera desigual a lo largo de toda la nación.
La provincia de La Habana, capital del país, es por mucho la más poblada del país con más de 2.1 millones de habitantes, albergando al 20% de la población total cubana, la densidad de la población aquí es de más de 2970.8 hab/km².La ciudad es la mayor del Caribe.

Las provincias de Santiago de Cuba y Holguín y le siguen en cuanto a población total y densidad, con más de un millón de habitantes cada una.
Otra región con importantes concentraciones de habitantes es la que rodea a la capital (provincias de Artemisa y Mayabeque), una región eminentemente agrícola, aunque con varios centros urbanos. Algunas áreas de estas provincias son consideradas en algunas publicaciones como parte de la zona metropolitana de la ciudad abarcando en su conjunto a más de 3.6 millones de personas. Entre los 700 000 y poco más de 800 000 habitantes, se clasifican 4 provincias (Matanzas, Villa Clara, Camagüey y Granma).

Las provincias con menor población son Mayabeque, Cienfuegos, Artemisa, Sancti Spiritus, Ciego de Ávila y Guantánamo que tienen entre 400 000 y poco más de 500 000 habitantes, y son de las de menor extensión. Las densidades de población brutas varían entre 50,2 hab/km² en Camagüey a +2000 hab/km² en la Ciudad de La Habana.

Desde 1976 hasta el último censo efectuado en el país, el municipio menos poblado es Ciénaga de Zapata con 6 577 habitantes (9 589 habitantes en el 2011), y el más poblado Santiago de Cuba, con 492 390 habitantes, en el 2011).

En 2009 el 75,4 % de la población del país se distribuye en ciudades y pueblos de carácter urbano; las provincias con más bajos índices de urbanidad son Las Tunas (62,2 %) y Guantánamo (60,5 %), y mientras que el 100 % de población de la provincia de La Habana es urbana, seguida de Matanzas con 82,2 %. El municipio Maisí es el más rural 91,59 % en 2009.
A pesar del elevado porcentaje de población urbana, la población rural está distribuida en prácticamente todos los municipios, y se concentra en algunos que conforman espacios de particular interés. Son 32 (19 %) los municipios con más del 50 % de su población rural, y como característica histórica la mayor concentración de ellos se encuentra en las montañosas provincias orientales, Guantánamo, Granma y Santiago de Cuba, en ese orden.

No obstante, porcentajes muy altos de población rural se encuentran en municipios de llanuras de la parte occidental y centro-oriental del país. Son ejemplos de ellos los contiguos municipios tabacaleros del extremo sur-occidental de la isla de Cuba, San Juan y Martínez y San Luis con 65,46 % y 75,74 % de población rural respectivamente, y los también contiguos municipios de Najasa con 78,95 % y Jimaguayú con 83,70 % en la provincia de Camagüey.

Según el censo de 2002 existían en Cuba 593 asentamientos urbanos y 6 482 rurales. Una distribución semejante de cantidades de población se observa al unir algunos tipos de asentamientos:


En la provincia de Matanzas, se encuentra Ciénaga de Zapata, el mayor y menos poblado municipio de Cuba, con apenas 9500 habitantes, se trata de una zona pantanosa con apenas 6 hab/km².

Las poblaciones que sobrepasaban los 20.000 hab. en Cuba son consideradas estadísticamente ciudades. Se considera para este fin la población registrada concretamente en el asentamiento urbano y no en el municipio completo en el cual se encuentra ubicada la ciudad. En el último censo se reportaron 58 ciudades. De ellas una con más de 2 millones de habitantes (La Habana), 12 entre 100 y 500 mil habitantes (llamadas de primer orden), 6 entre 50 y 100 mil habitantes (segundo orden) y 39 entre 20 y 50 mil habitantes (de tercer orden). Las ciudades de primer orden son Santiago de Cuba (431.272 hab), Camagüey, Holguín, Guantánamo, Santa Clara, Las Tunas, Bayamo, Pinar del Río, Cienfuegos, Matanzas, Ciego de Ávila y Sancti Spiritus. Todas son capitales provinciales. La ciudad de Manzanillo en la provincia de Granma, con 99 mil hab. en 2012 se encuentra próxima a entrar en esta categoría. Las capitales de las otras dos provincias, creadas en 2011 (Artemisa y San José de las Lajas -provincia Mayabeque-) son ciudades de tercer orden como lo es también la cabecera del municipio especial Isla de la Juventud (Nueva Gerona). No obstante, tanto Artemisa como Nueva Gerona constituyen centros de . Las ciudades de primer y segundo orden con mayor crecimiento en el período de 2002 al 2012 fueron: Las Tunas (13.5%), Bayamo (8.5%), Ciego de Ávila (8.1%), Morón (10.9%) y Cárdenas (10.1%). Entre las ciudades de tercer orden las de mayor crecimiento fueron: San Cristóbal (12.3%), Niquero (12.1%), Bauta (11.4%), San José de las Lajas (10.3%) y Baracoa (9.9%).

Definir la composición étnica o racial más allá del color aparente de la piel y la percepción del propio individuo en un país como Cuba es una tarea prácticamente imposible y estéril. La composición racial en 2002 era de 7 271 926 blancos, 2 778 923 de mulatos y 1 126 894 de negros respectivamente. La población china en Cuba desciende en su mayoría de trabajadores contratados que llegaron en el siglo XIX para construir los ferrocarriles y trabajar en las minas. Después de terminar sus contratos, muchos de estos trabajadores se quedaron en Cuba porque no podía pagar el pasaje de vuelta a China.
La ascendencia de los cubanos blancos (65.05%) proviene principalmente de los españoles. Durante los siglos XVIII, XIX y primera parte del siglo XX, especialmente, grandes olas de canarios, gallegos, asturianos y catalanes emigraron de España a Cuba. Otras nacionalidades europeas que inmigraron incluyen: británicos, entre ellos los escoceses, rusos, polacos, portugueses, rumanos, italianos, griegos, franceses, alemanes e irlandeses. Hay un pequeño remanente de una comunidad judía. También hay afluencia significativa de etnias de diversos pueblos de Oriente Medio, especialmente libaneses, palestinos, turcos y sirios.

Los afro-cubanos componen 10,08% al 23,84% de la población. Sus orígenes son principalmente kongo, un pueblo de África Central.
Los cubanos de origen asiático representan el 1% de la población. En su mayoría son de origen chino, japonés o coreano.

De los taínos quedan pocos restos. Se dice que el 1,02% de la población cubana, establecidos en zonas apartadas de Guantánamo. Algunos indios americanos de los Estados Unidos se establecieron en Cuba en el (en particular, Cherokee, Choctaw y Seminole). No hay cifras exactas sobre sus descendientes actuales.

La población total en el censo oficial de 1953 era 5 829 029 personas. La población de Cuba tiene orígenes muy complejos y los matrimonios mixtos entre los diversos grupos es tan general que se aplicará esta norma (metodología y fuentes estadounidenses).

El ritmo de crecimiento poblacional, lleva visiblemente desde las tres últimas décadas una pendiente decreciente, la mayoría de las cifras cubanas en el aspecto social de la demografía, son comparables sólo con países europeos altamente desarrollados. De acuerdo con los últimos datos emitidos por el O.N.E. (Oficina Nacional de Estadísticas de Cuba), la tasa bruta de natalidad alcanzó la cifra en 2009 de 11,6‰, en tanto que la tasa bruta de mortalidad fue del 7,7‰ registrándose un crecimiento natural de 3,9‰. La tasa de migración viene desde hace años siendo negativa y en 2009 fue de -3,3‰, por lo tanto el crecimiento total de la población fue de apenas del 0,6‰ (0,06%).

La mortalidad infantil de 4,8‰ en 2009, fue la más baja de todo el continente americano, por debajo incluso de las tasas de Estados Unidos y Canadá. Cuba viene registrando tasas cada vez menores desde la llamada revolución cubana de 1959.

Otra de las características de la población cubana es que la tasa global de fecundidad se encuentra desde hace años, por debajo del límite de reemplazo generacional de 2,1 hijos por mujer. En 2009 la tasa fue de 1,70 hijos por mujer, la más baja de América Latina. A su vez, la esperanza de vida de Cuba, también se encuentra entre las más elevadas de la región con una tasa de 77,97 años (75,1 hombres - 79,2 mujeres) en 2009.
Las variables demográficas en Cuba tienen un comportamiento generalmente homogéneo, aunque se destacan algunas provincias y ciudades en algunos indicadores específicos. La ciudad de La Habana, con una densidad poblacional extremadamente alta, presenta, en el municipio Plaza de la Revolución, el distrito más envejecido de todo el país. La provincia de Las Tunas, en el oriente cubano es la que posee la mayor esperanza de vida de todo el país con 79,28 años, mientras que la ciudad capital presenta un indicador casi tres años menor con 76,28 años.
En cuanto a la mortalidad infantil la provincia que más se destaca es Holguín, con apenas el 3,3‰.
La tasa bruta de reproducción fue de 0,82 hijas por mujer en 2009, por debajo del valor de 1, panorama que se presenta en todas las provincias cubanas.

Distribución por edades.

Según estimaciones de la O.N.E. para 2007, la población de "65 años o más" correspondería al 11,6% del total y la de "60 años o más", al 16,3%, haciendo que Cuba sea el segundo país más envejecido de América Latina después de Uruguay. A su vez, con el correr de las décadas, se nota un paulatino descenso de la población entre "0 a 14 años", representando el 18,2%.
La edad promedio de la población es de 37,3 años, con unos 38 años para las mujeres y 36,6 para los hombres. Recientes estudios han confirmado que para el año 2025, la isla será el país más envejecido de la región y uno de los 25 más envejecidos en todo el mundo.
En la región, Cuba integra junto a la Argentina, Chile y Uruguay, el grupo de países con una transición demográfica avanzada, caracterizada por poblaciones con natalidad y mortalidad moderada o baja, lo que se traduce en un crecimiento natural bajo, del orden del 1%, aunque el crecimiento total de la población cubana rondó el 0,06% en 2009.

La pirámide de población (2007), confirma el descenso sostenido de la fecundidad a lo largo de las últimas décadas, sumada a un progresivo envejecimiento poblacional, por el aumento de la esperanza de vida. Esto último se refleja en la similitud de la base de la pirámide y la cúspide.

Distribución por sexos.
De acuerdo a datos de la Oficina Nacional de Estadísticas, en 2009 hay un 49,9% de mujeres, y un 50,1% de hombres.

Distribución urbana/rural.


Después de la fundación de la república en 1902, una considerable migración llegó desde la península ibérica a la isla, entre ellos algunos exsoldados españoles que habían participado en las guerras de independencia, y sin embargo, esto nunca fue un obstáculo para el respeto y el afecto de los cubanos, que siempre han estado orgullosos de sus orígenes hispanos.
La inmigración ha sido y es un fenómeno que ha influido de manera importante en la demografía cubana. Durante la primera mitad del siglo XX, Cuba era considerada un "país de inmigración", grandes oleadas de españoles, provenientes de regiones como Galicia, Islas Canarias y Asturias llegaron al país buscando mejoras económicas. Desde el resto del Caribe, la emigración hacia la isla fue sobre todo de jornaleros jamaicanos y haitianos en un número que rondó los 50 mil, que trabajaban durante la época de la zafra de la caña de azúcar.

Tras el triunfo de Fidel Castro, y la transformación al socialismo, el fenómeno prácticamente deja de existir y se reorienta geográficamente, pues la mayoría de los que viajaron a Cuba, para vivir en las últimas décadas del siglo, procedían fundamentalmente de países del ex-campo socialista, rusos y ucranianos mayoritariamente. En 2008 la comunidad rusa (incluyendo descendientes directos), sumaba a unas 6000 personas, que radicaban en su mayoría en la capital.

La emigración se agudizó después del triunfo de la revolución cubana de 1959. Los Estados Unidos es el hogar del mayor número de cubanos fuera de Cuba; en ese país residen alrededor de 1.52 millones, sobre todo en Miami y otras ciudades importantes de Florida, así como en Union City y Nueva York. Números más pequeños de cubanos viven en otros países alrededor del mundo, especialmente en América Latina y Europa —especialmente en España con 82 596, en Italia con 17 947 y el Reino Unido, con alrededor de 10 000—. Hay alrededor de 5000 a 10 000 en Canadá, de 6000 a 8000 en México, y en Brasil 761.

En diciembre de 2008, España comenzó a aceptar solicitudes de ciudadanía de los descendientes de personas que fueron al exilio después de su brutal Guerra civil de 1936-39, debido a una ley de 2007 destinada a abordar el doloroso legado del conflicto. Según la ley, los descendientes tendrían hasta diciembre de 2010, para presentarse en la embajada española en su país de origen y entregar la documentación que acredite sus padres o abuelos huyeron de España entre 1936 y 1955. Ellos no necesitan renunciar a su ciudadanía actual. De acuerdo con la Ley de la Memoria Histórica en el Consulado del Reino de España en La Habana se habrían presentado cerca de 200.000 solicitudes la mitad de las cuales estarían resueltas satisfactoriamente.

Al igual que en muchos países del llamado Tercer Mundo, en Cuba está presente el fenómeno de migración interna, en su mayoría del campo a la ciudad y del oriente al occidente del país. A pesar de las políticas de industrialización y desarrollo llevadas a cabo en el este de la isla. Una importante masa de personas emigra hacia el occidente, mayoritariamente hacia La Habana, en busca de mayores salarios y posibilidades de negocios. Esto se vio reflejado en el último censo de 2002, en el que se mostró que aproximadamente el 30% de la población cubana, alrededor de 3,4 millones de habitantes, reside en un lugar distinto al de su origen.
En las provincias orientales vio la luz primera el 40,7% de los cubanos, aunque 916 241 han emigrado hacia otras provincias y a la capital 327 818.

El caso de Cuba es el más preocupante del continente Americano, este es el primer país en llegar a tope del Hemisferio Occidental, en 2004 la población alcanzó los 11.3 millones y desde 2007 ya decrece con tasas que varían anualmente del -1% a -4%. Los principales factores de la disminución de la población cubana son la débil tasa de fecundidad, el envejecimiento de la población (ya notable desde 1980), y la emigración hacia Estados Unidos, se prevé que para el 2020, Miami será la ciudad con mayor número de cubanos, superando incluso a la ciudad de La Habana. Los ritmos de desaceleración según las proyecciones serán entre 2010 a 2040 variantes del -6% al -11%, y para el 2050 será la década de mayor desaceleración que variara del -12% hasta al -21%, sin embargo entre el 2070 y el 2080 se moderaran a variar de -2% y -4%, y para el 2090 se prevé que la población vuelva a aumentar con proporciones de 1% y 5% (aún se desconocen las razones), para el 2100 el país cerrara con aproximadamente 5.001.009 habitantes, de los cuales el 69% serán personas de tercera edad (disminuyendo levemente del 74% en 2080). A parte, la evolución de la población a partir de la segunda mitad del Siglo XXI, muestra resultados interesantes, con una disminución de la población total y a parte de la población de la tercera edad, lo que muestra que la población en un futuro cercano dependerá sobre las personas de tercera edad, y a medida que mueran por razones de edad, también afectara en gran medida a la disminución de la población (Porcentualmente estos van a aumentar gradualmente).

En 1492 había al menos 100 000 habitantes. El primer censo oficial, de 1774, arrojó un total de 171 620 habitantes. Recién en 1841 un censo supera el millón de habitantes.

Desde 1492 hasta 1870 fueron introducidos en la isla cerca de 702 000 negros. En 1800 había unos 130 000 negros sobre una población total de 350 000 habitantes, mientras que en 1848 había en Cuba alrededor de 400 000 esclavos.

En el estimado de la población a julio de 2010, Cuba tenía 11 477 459 de habitantes, con un crecimiento anual del 0,217% y una relación de masculinidad de 0,99 hombres por cada mujer.

Antes de 1959, el 85% de la población se consideraba católica, en la actualidad la cifra ronda el 40%, por otro lado más del 50% de los cubanos se considera no creyente o ateo. Cada vez menos aumenta el número de protestantes, de las diferentes sectas. Una religión ampliamente difundida es la santería, de raíces africanas, fundamentalmente Yoruba pero con alto grado de influencia autóctona cubana y sincretismo con el catolicismo. Es practicada por distintas capas de la población intependientemente de su origen étnico o racial.

La libertad de culto está recogida en la constitución cubana, que también establece la separación de la Iglesia del Estado. Desde la visita que realizara Juan Pablo II en 1997, las relaciones del gobierno con las autoridades eclesiásticas han mejorado ostensiblemente,muestra de ello es la recuperación del día de Navidad como festivo después de casi tres décadas de su suspesión.











</doc>
<doc id="43005" url="https://es.wikipedia.org/wiki?curid=43005" title="Geografía de Nueva Zelanda">
Geografía de Nueva Zelanda

Nueva Zelanda es un largo y estrecho país de terreno abrupto consistente en la Isla Norte y la Isla Sur (además de un pequeño grupo de islas). Cubre una superficie de 268.838 km y 1600 kilómetros de longitud. Posee una longitud un poco mayor a la del Reino Unido. Nueva Zelanda está situada en el Pacífico Sur, aproximadamente 10.400 km al suroeste de Sudamérica y a 2250 km al este de Australia.
La Isla Norte con sus playas doradas, los ancestrales bosques de Kauris, volcanes, áreas termales, y grandes ciudades (entre las que se encuentra Wellington, la capital), es la isla más poblada de las dos. La Isla Sur con sus montañas nevadas, glaciares, exuberantes bosques nativos, fiordos, es la mayor de las dos, y es llamada "la tierra principal" por los habitantes de la misma. Su ciudad más poblada es Christchurch. La pequeña Isla Stewart (1750 kilómetros cuadrados) un lugar virgen, con sus bosques llenos de pájaros nativos y sus playas paradisíacas, en el lugar más al sur del país, es uno de los lugares más cercanos a la Antártida que el hombre haya llegado jamás. Dentro de la jurisdicción territorial de Nueva Zelanda también se incluyen un grupo pequeño de islas como las Chatham, Kermadec, la Isla Campbell, Auckland, Antípodas, Las Snares, Solander, y las Islas Bounty. Se halla rodeada por el Océano Pacífico Sur en el este y del Mar de Tasmania en el oeste.

Nueva Zelanda cuenta con 2 islas principales en Oceanía ubicadas en el Pacífico Sur con centro en aproximadamente . Tiene un área total de 268.680 km (incluyendo las Islas Antípodas, Auckland, Islas Bounty, Islas Campbell, Islas Chatham, y las Islas Kermadec) siendo ligeramente menor a Italia o Japón y un poco mayor que el Reino Unido.

Nueva Zelanda tiene un total de 15.134 km de costa y cuenta con extensos recursos marinos. Reclama la séptima mayor Zona económica exclusiva del mundo, cubriendo más de 4 millones de km, más de 15 veces su área terrestre. El país no tiene fronteras terrestres.

La Isla Sur es la mayor masa terrestre y contiene alrededor de un cuarto de la población de Nueva Zelanda. La isla está dividida longitudinalmente por los Alpes del Sur, cuya cumbre es el Monte Cook o Aoraki con 3.754 msnm. Existen 18 picos que sobrepasan los 3.000 msnm en la Isla Sur. El lado oriental de la isla es hogar de los Llanuras de Canterbury mientras la costa occidental es famosa por sus abruptas costas, muy alta proporción de bosque nativo, y por los glaciares Fox y Franz Josef.

La Isla Norte es menos montañosa que la Isla Sur, pero está marcada por el vulcanismo. La mayor montaña de la isla, el Monte Ruapehu (2.797 msnm), es un volcán activo. El Lago Taupo se encuentra cerca del centro de la Isla Norte y es el mayor lago en superficie del país. El lago nace en una caldera creada después de la mayor erupción en el mundo en los últimos 70.000 años (Erupción Oruanui).

Nueva Zelanda se ubica en el límite entre dos placas tectónicas, la Placa del Pacífico y la Placa Australiana. Esto provoca el vulcanismo a través de todas las islas, especialmente la Isla Norte. El país hace uso de su moderado vulcanismo produciendo energía calórica y eléctrica en numerosas plantas hidrotermales. Nueva Zelanda es capaz de proveer toda la electricidad necesaria dada la cantidad de energía del agua en la Isla Sur y la energía volcánica en la Isla Norte. Algunos sitios volcánicos son también famosos destinos turísticos, como los géiseres de Rotorua. Las dos placas también provocan regulares terremotos aunque generalmente no son malos.

Hay muchas formaciones de rocas sedimentarias kársticas que llaman la atención turística. Entre ellas están las Cavernas de Waitomo y las Rocas Pancake. Estos monumentos contienen muchos minerales, gracias a las piedras volcánicas que deja la lava.

Nueva Zelanda consta de 16 regiones, 7 en la Isla Sur y 9 en la Isla Norte. Nueva Zelanda también tiene un número de islas apartadas que no se incluyen en los límites regionales. Las Islas Chatham no son una región, aunque su concejo opera como una región bajo el Resource Management Act. Las Islas Kermadec y las Islas subantárticas están habitadas solo por un pequeño número de miembros del Departamento de Conservación de Nueva Zelanda.

El clima en Nueva Zelanda es básicamente templado fresco a templado cálido. las temperaturas medias están entre los 8°C en la Isla Sur y los 16 °C en la Isla Norte. Enero y febrero son los meses más cálidos mientras que julio es el más frío. Nueva Zelanda no tiene un gran rango de temperaturas aunque el tiempo puede cambiar repentinamente. Condiciones subtropicales se observan en Northland (el extremo norte de la Isla Norte).

La mayor parte de las áreas del país tienen entre 600 y 1.600 mm de precipitaciones con la mayor parte de las lluvias a lo largo de la costa occidental de la Isla Sur y la menor en la costa oriental de la misma, básicamente en las Llanuras de Canterbury. Christchurch es la ciudad más seca recibiendo unos 640 mm de lluvia al año, mientras que Auckland es la más húmeda, con casi el doble.

El índice UV en Nueva Zelanda puede ser muy alto en algunos lugares y extremo en los momentos más cálidos del año en el norte de la Isla Norte. Esto se debe en parte a la relativamente baja contaminación del aire en el país, comparado con muchos otros países.

Existen tres factores principales que influyen en el clima de Nueva Zelanda:

Los recursos naturales incluyen: carbón, oro, energía hidráulica, hierro, piedra litográfica, gas natural, arena, y madera.

Uso del suelo:

Tierra irrigada: 2.850 km² (2003)


Además de la deforestación y la erosión del suelo, Nueva Zelanda padece un grave problema con las especies invasoras. Se calcula que en Nueva Zelanda hay más de 2000 especies de plantas vasculares no nativas introducidas por el hombre, entre ellas helechos, gramíneas, angiospermas, árboles y malezas, y trepadoras. Entre los mamíferos invasores más dañinos figuran las ratas, los armiños y las zarigüeyas australianas, de las que se calcula que hay unos 30-35 millones en el país. Un plan llamado Predator Free 2050 pretende acabar con los mamíferos invasores en Nueva Zelanda. Los objetivos son liberar de predadores un área de 1 millón de hectáreas y erradicarlos de todas las islas que sean reservas naturales.

En Nueva Zelanda hay 5.756 áreas protegidas que ocupan 88.464 km, el 32,81% del área terrestre del país, y 1.249.447 km de superficie marina, el 30,42% del área marina que pertenece al país, 4.106.954 km. Del total de áreas protegidas, 15 son parques nacionales, 44 son reservas marinas, 58 son reservas naturales, 74 son refugios naturales, 54 son áreas de conservación, 12 son santuarios de la naturaleza, 2 son Te Urewera (un área muy boscosa, poblada de forma dispersa en zona de colinas en el norte de Nueva Zelanda), 6 son áreas naturales, 100 son reservas científicas, 14 son áreas santuario, 1.699 son reservas escénicas, 113 son áreas ecológicas, 3 son áreas de conservación, 2.623 son áreas sostenibles según el concepto de mayordomía, 857 son áreas privadas con un acuerdo de conservación (conservation covenant), 1 es un área marina protegida (islas de Sugar Loaf), 17 son reservas gubernamentales, 12 son áreas de gestión natural, 20 son áreas bentónicas protegidas, 5 son reservas con propósitos específicos, 17 son áreas marinas restringidas (Seamount closures) y 1 es un área de protección especial (isla de Breaksea). De estas, 3 son patrimonio de la Humanidad y 6 son sitios Ramsar.




</doc>
<doc id="43009" url="https://es.wikipedia.org/wiki?curid=43009" title="Economía de Cuba">
Economía de Cuba

La economía cubana está sustentada en los recursos naturales del país, que son muy variados y van desde minerales como el níquel y el cobalto, a los paisajes tropicales que atraen a millones de turistas todos los años. El capital humano es el otro pilar fundamental de la economía del país, que cuenta con las tasas más elevadas de alfabetización, esperanza de vida y cobertura sanitaria de toda la América Latina y el Caribe.

El gobierno cubano mantiene su adhesión a los principios socialistas a la hora de organizar su economía, con una planificación, con opciones diferentes a las que serían dictadas por el mercado; aunque después del derrumbe de la URSS y de los países socialistas del este de Europa, la iniciativa privada y el papel del mercado hayan aumentado, aunque no al nivel de lo sucedido en la Europa del Este.

Por otro lado, y según datos de la ONU, Cuba sería el único país del mundo que cumple los dos criterios que, para la organización WWF, significan la existencia del desarrollo sostenible: desarrollo humano alto ( > 0,8) y huella ecológica sostenible ( < 1'8 ha/p).
Según el informe EPI de 2010, realizado por las universidades de Yale y Columbia en Estados Unidos el país está en la posición 9.ª en el mundo con mejor desempeño ambiental, con cifras solo comparables con naciones altamente desarrolladas.

La economía cubana ha estado desde su independencia en 1902 muy ligada al azúcar; que constituye desde el siglo XIX el principal producto exportado por la isla; aunque el tabaco y el cacao también fueron soportes de la economía colonial de Cuba y La Habana fue el más importante emporio del cacao en el siglo XVIII. Después de la independencia Cuba dependió del azúcar; su economía estaba muy ligada a su precio en el mercado internacional porque casi todo el azúcar que se producía estaba destinada al mercado exterior, especialmente a los Estados Unidos.

Sin embargo, entre 1920 y 1933 las exportaciones e importaciones de la isla se redujeron de un 60% al 50%. Ocurren varias desgracias para que tengan semejante bajada en poco más de 10 años: en 1920 los E.E.U.U., que hubiera estado comprando enormes cantidades para alimentar a los soldados de la Primera Guerra Mundial, deja de necesitar tanto azúcar y a partir de 1925 Estados Unidos empieza a producir azúcar de remolacha cultivada en su propio territorio que poco a poco va sustituyendo al azúcar de Cuba. Para terminar de hundir las exportaciones en 1929 se produjo el Crack del 29.

Al bajar la demanda de azúcar el precio comenzó a bajar, y la economía cubana empezó a perder ventaja en términos de intercambio: ahora necesitaba vender más toneladas de azúcar para poder importar del extranjero la misma cantidad de otro producto que antes, es decir: si en 1900 tenía que vender una tonelada de azúcar por cada coche que compraba, en 1950 tenía que vender dos toneladas para poder comprar un coche extranjero.

Tras dar un golpe de estado en 1952, el general Batista abolió la Constitución de 1940 y suspendió las garantías constitucionales, entre ellas el derecho de huelga. Buscó el apoyo de los ricos terratenientes de la isla que poseían las más grandes plantaciones de caña de azúcar y presidió una economía estancada que amplió la brecha entre cubanos ricos y pobres. El gobierno cada vez más corrupto y represivo de Batista comenzó a enriquecerse de manera sistemática explotando los intereses comerciales de Cuba y realizando lucrativos negocios con la mafia estadounidense, que controlaba los negocios de drogas, prostitución y juego de La Habana.

Esto condujo a una profunda crisis económica y social en la isla que acabó desembocando en la revolución cubana.

La mayoría de los medios de producción pertenecen al estado cubano y son administrados por el gobierno cubano y, según las estadísticas del mismo, el estado emplea alrededor de un 75 % de la mano de obra. hoy en día son más de 470.000 los cuentapropistas en toda la isla

Hacia 1985 la renta per cápita estimada de Cuba superaba a la de otros países de su entorno geográfico como República Dominicana, Haití, El Salvador, Nicaragua y Honduras.

Debido a la pérdida de los subsidios soviéticos en 1993 y 1994 el gobierno introdujo algunas reformas de orientación mercantilista, entre ellas la apertura al turismo, el permiso a la inversión extranjera, la legalización del dólar y la autorización al empleo por cuenta propia en casi 150 profesiones. Estas medidas resultaron en un crecimiento económico moderado.

A fin de ofrecer empleo a aquellos trabajadores que fueron despedidos debido a la crisis económica, y con el objetivo de suministrar servicios que el gobierno encontraba difícil ofrecer.

El gobierno mantiene un fuerte control sobre el pequeño sector privado a través de la regulación y los impuestos. Por ejemplo, los propietarios de un pequeño restaurante privado no pueden proveer asientos a más de 50 personas y deben pagar impuestos del 25% sobre el salario pagado a los trabajadores contratados más allá de cinco unidades. Las tasas mensuales se deben pagar sin consideración alguna a los ingresos, y hay inspecciones frecuentes donde se imponen multas elevadas cuando se viola cualquiera de las múltiples normas del empleo por cuenta propia.
Debido al pésimo crédito del país, la deuda de 11 mil millones de dólares en moneda dura y los riesgos asociados con las inversiones en Cuba, las tasas de interés han llegado, según ciertos informes, a niveles de hasta el 22%.
Igualmente el embargo estadounidense afecta negativamente al comercio exterior cubano impidiéndole acceder a productos estratégicos de ciertas empresas tanto estadounidenses, como finlandesas, japonesas y de otros países. El incremento de las reservas internacionales, llegó a 11 103 millones de dólares en 2014, duplicando la existente cinco años atrás.

Según el informe del gobierno cubano sobre las consecuencias del embargo de 2007 presentado ante la ONU, los daños documentables causados por el embargo llegaron a 96 mil millones de dólares en 2008.
El principal centro de atracción de inversiones extranjeras es la Zona Especial de Desarrollo de Mariel de 450 km², donde se planea crear laboratorios mixtos con empresas brasileñas para la producción y exportación de medicinas cubanas. A fines de 2014, se abrieron negocios privados en 201 actividades diferentes, especialmente en el sector de servicios, empleando a más de 476 000 ciudadanos en actividades privadas. La actividad privada que impulsa Raúl Castro, especialmente en el sector servicios, junto al desarrollo de cooperativas, ha crecido en los últimos años.
El número de trabajadores del sector privado y cuentapropistas en Cuba trepó a 489 929 a fines de febrero del año 2015.

Las exportaciones derivadas de la actividad forestal en Cuba posibilitaron el ingreso de más de 24 millones de dólares a la economía nacional en la última década. De acuerdo con datos de la Organización de las Naciones Unidas para la Alimentación y la Agricultura (FAO), Cuba es uno de los pocos países del mundo que logran anualmente crecimiento en su superficie boscosa, que representa más del 30 % de las tierras.

A mediados de la década de 1990 el turismo superó al azúcar, desde antaño el principal sostén de la economía cubana, como fuente principal de divisas. El turismo figura de manera importante en el plan de desarrollo del gobierno cubano, y un alto funcionario lo describió como el "corazón de la economía". La Habana dedica recursos importantes a la construcción de nuevas instalaciones turísticas y la renovación de estructuras históricas para el uso del sector turístico. Aproximadamente 1,7 millones de turistas visitaron Cuba en el 2000, generando unos 1.900 millones de dólares en ingresos brutos; pero las esperanzas del gobierno con respecto al crecimiento prolongado de este sector no se vieron materializadas debido a la declinación de la economía mundial en el 2001 y los efectos negativos sobre el turismo regional después del 11 de septiembre. Las cifras finales para el 2001 reflejan un crecimiento insignificante en la cantidad de turistas y ningún cambio en los ingresos brutos para el 2002. Esta situación cambió en el transcurso del decenio.

En 2008 se alcanzó la cifra de 2,3 millones de turistas y los ingresos per cápita también aumentaron. La construcción de hoteles y otras infraestructuras turísticas se disparó en 2005, y se ha mantenido el crecimiento de la llegada de turistas en medio de la crisis mundial, aunque los ingresos han disminuido un tanto. Cuba se ha convertido en el principal destino después de Europa Occidental para los turistas canadienses, llegando en 2008 a 818.246 turistas, y tiene una importante cuota del mercado español, italiano y británico.

Los principales destinos son:

El Ministerio de Turismo (MINTUR) es el organismo estatal rector del Sistema de Turismo, en el que participan otras entidades del país. El MINTUR elabora la política y controla su aplicación en las entidades que administran directamente las propiedades del sector. Cuba cuenta, además, con una nueva facultad en la Universidad de La Habana, dedicada a los estudios sobre el turismo, Facultad de Turismo.

Para llevar adelante el desarrollo integral del turismo en Cuba se ha estructurado un sistema formado por entidades hoteleras (Gran Caribe, Habaguanex S.A., Islazul, Horizontes, Grupo Gaviota, Cubanacan, etc.) y extrahoteleras (Rumbos, Cubatur, Transtur, Turarte, etc.), así como otras de carácter autónomo e independiente, que asumen funciones de apoyo al resto.

Desde el 2008 se permite la entrada y uso de instalaciones turísticas a los ciudadanos cubanos.

En 2015 se alcanzó la cifra de 3 millones 500 mil turistas extranjeros, lo que supuso un nuevo récord. Se espera un crecimiento más abrupto en 2016 con la apertura de vuelos comerciales entre Estados Unidos y Cuba, un acuerdo firmado en febrero de 2016 que permitirá 110 vuelos diarios entre Cuba y Estados Unidos divididos en 20 hacia La Habana y 10 más a cada uno de los otros nueve aeropuertos internacionales de Cuba. En 2017, arribaron a la isla 4,8 millones de turistas extranjeros.

Cuba en el período anterior a 1914 se dedicaba principalmente a la exportación de un único producto: el azúcar. Este producto es original de África y fue introducido en América por los españoles en el siglo XVII. Requiere altas temperaturas durante su crecimiento (27°C), mucha luz solar y abundantes precipitaciones (1500 mm anuales). Crece en suelos de topografía plana, profundos y bien drenados.

El proceso que utilizaban los cubanos para obtener azúcar consistía en comprimir las cañas cortadas mediante rodillos, extrayendo el líquido dulce que contienen en su interior. A continuación cocían el jugo lentamente logrando su reducción por medio de la evaporación del agua, hasta alcanzar la densidad y concentración deseadas (melaza). De ésta se obtenían los panes de azúcar y de su molienda el azúcar comercial.
Las cañas de azúcar eran recogidas por los cubanos manualmente y con la única ayuda de las vacas. De esta manera transportaban en grandes carruajes de madera las cañas de azúcar hasta el lugar donde las iban a transformar. Finalmente, una vez producido el azúcar, éste era transportado por las vacas en grandes bidones de madera hasta los puertos.

En 1835 surgió el primer ferrocarril en Cuba, hecho que les permitió avanzar un poco en su actividad económica, aunque seguía siendo insuficiente, la red construida no articuló el territorio y no sirvió para crear un mercado.
En 1890 surgió la modernización tecnológica tanto en el proceso de producción de azúcar como en el transporte. Sin embargo, a pesar de ello siguieron recogiendo las cañas a mano, ya que al estar tan extendida la esclavitud en este país la mano de obra era muy barata.

Tal era la dependencia económica que Cuba tenía de este producto que dedicaron todos sus terrenos a la plantación de cañas de azúcar. Esto se convirtió en un error: no dejaron que el campo se regenerase. Otro problema por el que atravesó el azúcar de caña cubana fue el surgimiento de la competencia en 1890 de la remolacha azucarera. A partir de entonces la producción de azúcar cubana descendió drásticamente.

Las exportaciones únicamente podían llevarse a cabo por la inversión extranjera y además los beneficios de estas exportaciones en la mayoría de los casos no se quedaron en el país, mientras que en el mejor de los casos se quedó alguna pequeña parte.

Desde el derrumbe de la URSS, el azúcar, en 1989, la producción superaba los 8 millones de toneladas, a mediados de la década de 1990 había caído hasta llegar a alrededor de 3,5 millones de toneladas. a producción azucarera creció en la zafra 2013-2014 en un 4,2%, según el balance oficial final, para alcanzar el mayor crecimiento en los últimos diez años.

En junio de 2002 el gobierno anunció su propósito de llevar a cabo una "transformación amplia" de este sector en declinación, con la llamada "Tarea Álvaro Reynoso". El plan propone igualar la producción azucarera con los precios mundiales y cerrar casi la mitad de los centrales azucareros, despidiendo a más de 100.000 trabajadores, quienes serían readiestrados en otras profesiones y recibirían empleos nuevos.

La producción azucarera lleva cinco años de crecimiento sostenido a un promedio del 13% anual. A la par se desarrollan proyectos de producción de alcoholes, energía eléctrica y alimento para la ganadería.

En los últimos años ha aumentado la diversificación agrícola hacia sectores como las frutas y las hortalizas. En Cuba se dan muchas frutas tropicales como la piña, guayaba, anón, mamey, papaya, etc.
La mayor parte de la producción agrícola de Cuba (60%), es realizada por los campesinos privados y por los cooperativistas.

El café es un producto bien dado en Cuba, gracias a un relieve montañoso donde se siembra en el suelo con sombra, principalmente en las sierras. La exportación de café es de aproximadamente 8000 toneladas.

Tabaco: A la llegada de los españoles a Cuba, la planta de tabaco se extiende por el mundo. El rey Felipe V impuso en 1717 un monopolio real del tabaco que se cultivaba en Cuba, decisión que llevaba el nombre de "Estanco del Tabaco". A finales del siglo XIX había un auge en la producción y distribución del tabaco. Fabricantes cubanos y extranjeros como Hermann Upmann fundaron fábricas en Habana (La Real Fábrica de Tabacos H. Upmann) hoy llamado José Martí, y un banco para ello: H. Upmann & Co., y llegaron a ser los más importantes del mundo. El tabaco manufacturado se le conoce como habano y es vendido a un alto costo mundialmente; en 2007 las exportaciones llegaron a los 400 millones de dólares estadounidenses.

En la época invernal donde las temperaturas son más frescas es posible cultivar intensivamente gran variedad de hortalizas y vegetales como la lechuga, la acelga, zanahoria, rábanos, etc. En un nuevo proyecto para autoabastecer a las ciudades y pueblos se creó la llamada "Agricultura urbana y suburbana", que utiliza cultivos protegidos y semiprotegidos, para tener cosechas de verduras en la época veraniega donde el calor es sofocante.

La agricultura se encuentra en la actualidad (2009) parcialmente mecanizada, debido a que muchos de los implementos son de origen soviético y están en mal estado, aunque se ha tratado en los últimos años de dar un nuevo impulso a la mecanización, sobre todo de los regadíos. Por otro lado, en Cuba no son muy utilizados los insecticidas químicos y en su lugar son utilizados los de origen animal y vegetal, incluyendo la lombricultura (uso de lombrices) para fertilizar los suelos. Este tipo de prácticas han colocado a Cuba como el único país del planeta con un desarrollo sostenible según la WWF.

El gobierno de Raúl Castro introdujo algunos cambios en el sector económico cubano, que se han orientado hacia dos vertientes fundamentales: la sustitución de importaciones (agrícolas e industriales) y la reforma en el campo, temas que su gobierno ha considerado como de "seguridad nacional". Además, desde su investidura habló de eliminar las prohibiciones innecesarias, lo que se ha visto en la práctica con el fin de la veda de los hoteles y artículos de lujo a los nacionales. En el 2009, en un discurso ante el parlamento, afirmó, que «el proceso de actualización del sistema económico cubano, debe realizarse sin apresuramientos».
te, se ha venido renegociando una parte significativa de la deuda externa, especialmente con Rusia, en el caso de la contraída con la antigua Unión Soviética, y con México, así como con favorables perspectivas para renegociar con el Club de París.

Uno de sus pilares es la entrega de tierras en usufructo gratuito para el que desee trabajarlas. Esta medida aumentó las producciones de manera relativamente rápida, aunque debió combatir las trabas burocráticas, cuya eliminación es parte también del nuevo programa gubernamental. La entrega de tierras ha sido mayor en las provincias del centro y oriente del país:
Este tema se ha visto trabajado junto con el aumento de la calidad y cantidad de los rubros exportables y está presente en todos los sectores de la economía con diferente profundidad, sobre todo en la agricultura y en la industria ligera.

Las mejoras de los precios al productor privado han incentivado algunas producciones como la leche y los frutales. Existe un programa para autoabastecer al país de leche de vaca y eliminar las importaciones de este alimento en polvo. Al cierre de 2009 se autoabastecían de leche 66 municipios de los 169 que tiene el país, en un proyecto especial que abarcó en 2009 unas 6000 bodegas (el 56%), exceptuando la capital del país.

En general la producción de leche aumentó en el sector privado y cooperativo, de esta manera:

La producción de carne porcina y vacuna se vio muy afectada debido al derrumbe de la URSS y el fin de los millonarios subsidios, la producción de piensos, etc.

El Estado ha firmado a través del Ministerio de Agricultura, convenios con productores individuales o cooperativizados para la venta a mejor precio de la carne -con la consecuente eliminación de los subsidios para aumentar la productividad- mediante los cuales el gobierno garantiza un porcentaje de pienso y el resto debe ser aportado por el campesino. La carne de vacuno pasó de valer apenas 15 centavos de dólar a casi 50 centavos de dólar, lo que ha estimulado la producción.

Las cosechas de arroz también aumentaron significativamente en 2008 y 2009.
La industria pesquera se desarrolla fundamentalmente en La Habana, Manzanillo y Matanzas. La producción de la acuicultura marina es generalmente pequeña, con un máximo de producción de 300 toneladas. La producción de la acuicultura de agua dulce está más desarrollada, en el año 2000 rondó las 90 mil toneladas. Entre las especies fundamentales que se pescan se encuentran el dorado, la lubina, la claria o pez gato, las tencas y las tilapias. También se cultivan y pescan moluscos, crustáceos como camarones, langostas para la exportación y calamares.

Cuba, además, aunque no tan desarrollada como otras industrias posee importantes minas, principalmente las de níquel (34,4% de las reservas mundiales), cobalto y cobre, entre otras. Los principales yacimientos de níquel se encuentran en el municipio de Moa, provincia de Holguín y en la provincia de Guantánamo (aunque en menor escala). Este producto de hecho se ha convertido en una importante base económica cubana.

El gobierno afirma que aumentará la producción de níquel a 80.000 toneladas al año, lo que lo hará una fuente poderosa. Durante la década de 2000 se están llevando a cabo programas para modernizar este procedimiento de extracción y constituye una importante reserva mundial. Incluso se afirma que con la construcción de una cuarta empresa niquelífera la producción ascenderá a 100.000 toneladas. Igualmente, China intenta firmar acuerdos de cooperación para la extracción de este mineral.

El cobalto es otro mineral extraído en el oriente cubano, aunque también es extraído en provincias como Villa Clara. Cuba cuenta con el 26% de las reservas mundiales (segunda mayor) produce aproximadamente el 10% de este mineral a nivel mundial y la mayor parte la exporta a China. Respecto a este asunto, Cuba firmó acuerdos con Canadá. Al igual que con el níquel, se encuentra cooperando con China y explorando nuevas reservas de este mineral en el norte del oriente cubano.
Cuba también produce 400.000 toneladas anuales de acero en las industrias de La Habana y Las Tunas.
Por su situación geográfica, Cuba extrae sales marinas del mar Caribe. Ha hecho de ellas un nuevo producto, que es exportado al mercado internacional y empleado en el consumo. La producción es aproximadamente de 250.000 toneladas en total. Las más importantes salineras están enclavadas en Puerto Padre y Guantánamo, ambas en la zona oriental del país.

El petróleo es un recurso que todavía tiene poca producción, según The World FactBook en su edición 2006 son extraídas y procesadas aproximadamente 4000.000 de toneladas anuales equivalentes de petróleo y gas (70.000 b/d sobre el 48% del consumo interno). Las reservas probadas están en torno a los 243 millones de barriles de petróleo y de 67.890 millones de metros cúbicos de gas (estimados del 2006). Este rubro tiene grandes perspectivas de crecimiento: debido a recientes estudios sismológicos se estiman grandes reservas en el Golfo de México y Cuba ha concedido licencias a grandes transnacionales para la búsqueda del preciado hidrocarburo, lo que ha despertado grandes expectativas de desarrollo y a la vez protestas de grupos ecologistas. 

Se extrae petróleo fundamentalmente en las provincias de La Habana (Canasí, Yumurí, Jaruco, Puerto Escondido) y Matanzas (Cárdenas y Varadero).

También es procesado el petróleo en Cuba mediante refinerías encontradas en cuatro provincias. La primera en La Habana, la segunda en Santiago de Cuba, la tercera en Cienfuegos y la última en Sancti Spíritus (Cabaiguan); esta última se dedica fundamentalmente a la producción de aceites básicos para la industria.
Además es procesado el petróleo importado de Venezuela a la isla en cumplimiento del tratado de PetroCaribe.
La zeolita y la sílice son abundantes y se ha comenzado un proceso de industrialización para extraer estos minerales que en 2009 son exportados a países del área como México o Colombia. En 2010 fueron iniciados los trabajos de construcción de una nueva planta de ferroniquel, que llegará en 2013 a producir más de 68 000 toneladas anuales, las labores están a cargo de la empresa mixta cubano-venezolana "Quality S.A."

El rubro de la construcción en Cuba consiste en la elaboración de materiales de construcción como cemento y ladrillos y en la remodelación y reparación arquitectónica.

Para esta última se encuentra la UNAICC, encargada de proyectos de restauración y construcción.
Los materiales de construcción son producidos en Artemisa, Mariel, Matanzas, Camagüey, Nuevitas, Cienfuegos y Santiago de Cuba.

Cuba posee pequeñas industrias de construcción de maquinarias, entre ellas algunas hidráulicas y sencillas que facilitan el trabajo laboral.
Las principales industrias de construcción están en La Habana (la capital), en Santa Clara, Sancti Spíritus, Camagüey Holguín y Santiago de Cuba.
Además se elaboran instrumentos y maquinarias agrícolas en las regiones de Holguín ("véase Empresa de Implementos Agrícolas de Holguín" y "Empresa 60 Aniversario de la Revolución de Octubre en Holguín"), Ciego de Ávila, Matanzas y La Habana. Se han presentado proyectos de reapertura de producciones de KTP. Es muy importante en la recuperación económica del país, pues en su decadencia perdió importantes fábricas, entre ellas las automotrices de ómnibus y tractores.

En industria naval, Cuba se asoció con Venezuela para construir un astillero. También se producen barcos en el astillero de Santiago de Cuba. Hay astilleros además en Matanzas y La Habana. Son conocidas las empresas estatales Fábrica Claudio Arguelles de La Habana y la Industria Automotriz de Guanajay.

En la industria alimentaria se destacan los refrescos y maltas Hatuey, Bucanero, Antillana y Manacas.
Se producen lácteos, confituras (las más importantes son producto de "La Estrella" y de la empresa cubano-italiana Papas & Co.), conservas, lácteos (incluidos el yogur de soya repartido en las Escuelas Secundarias Básicas y el dado a los menores por la Libreta de Abastecimiento), cárnicos, aceite (también dado en la libreta de abastecimiento), refrescos (destacándose "Ciego Montero"), jugos (destacándose "Tropical") y dietéticos.
Parte de esta industria se basa en la agricultura, como, por ejemplo, en la elaboración de jugos, donde hay grandes siembras de las frutas requeridas.

Constituye la industria de papel y su impresión. Las principales productoras de papel se encuentran en La Habana, Matanzas y Santiago de Cuba.
La producción textil (de tejidos, hilos y telas) se encuentra más bien en la región occidental del país, exceptuando Holguín. Las empresas productoras son de La Habana, Bauta, Alquízar, Matanzas, Güines y Holguín.

Cuba posee una desarrollada red vial para el transporte automotor que alcanza 52 202 km, de los cuales están pavimentados 17 212 km. De ellos, 11 450 son vías clasificadas como de interés nacional, incluyendo 654 km de autopistas y 400 km de otras vías expresas multicarriles y 1435 de la Carretera Central. Esta red abarca todas las provincias y ciudades del país.

El transporte en Cuba se ha visto deteriorado debido al envejecimiento y rotura de antiguos medios y la dificultad para la adquisición de nuevos de ellos por el embargo económico, financiero y comercial de Estados Unidos y la crisis económica a la que ha estado sujeto el país. Desde 2006 se han programado grandes planes para su mejoramiento integral.

En las urbes es común ver todavía automóviles estadounidenses de finales de la década de 1950. En las décadas de los años 1970 y 1980 se importaron vehículos procedentes de países socialistas, siendo muy populares los de las marcas Lada, Moskvitch y Volga. Para distribuir estos a los usuarios particulares se creó un mecanismo de asignación por prioridades, priorizando a profesionales y a trabajadores destacados. A partir de 2012 se ha liberalizado la compra-venta de automóviles entre ciudadanos

A partir de los años 90 se han comenzado a importar automóviles europeos y asiáticos modernos. Es común encontrar vehículos de marcas europeas, como Peugeot, Citroën o Mercedes-Benz, y asiáticas, como Toyota, Mitsubishi, Hyundai, Kia, aunque la inmensa mayoría son de propiedad estatal (taxis, autos de alquiler para el turismo o autos de empresas). En la década de 2000, se produjo el desembarco en la isla de automóviles de manufactura china, con marcas como Chery.

El país posee también una extensa red de ferrocarriles con 8193 km de longitud que alcanza todas las capitales provinciales y los principales puertos. La empresa estatal encargada de la red ferroviaria es (Ferrocarriles de Cuba). Para el transporte público todavía se emplean trenes de hace más de veinte años aunque al país están llegando nuevos equipos de China e Irán. Existen servicios de trenes desde La Habana a Pinar del Río y a Guantánamo, atravesando todo el país.
La aviación de Cuba es relativamente poco utilizada en el ámbito nacional aunque existen una decena de aeropuertos con vuelos regulares hacia La Habana. Los aeropuertos internacionales más importantes radicanen La Habana, Varadero, Holguín y Santiago de Cuba. Las compañías aéreas nacionales son Cubana de Aviación, Aerogaviota, AeroCaribbean, Aero Varadero y Aerotaxi.

El transporte por ómnibus es el más utilizado; existen dos empresas estatales a cargo de esta actividad: Viazul, que opera en peso cubano convertible (CUC) y Astro que opera en peso cubano (CUP). Ambas empresas cuentan con modernos ómnibus marca Mercedes-Benz y Yutong. Estas empresas se desempeñan a nivel interprovincial principalmente. En el transporte distrital y urbano se utilizan otros medios. Los autobuses rígidos se pueden observar en las principales ciudades mientras los autobuses articulados principalmente en la Habana. Los populares "Camellos" se fueron retirando progresivamente pero todavía se les puede observar haciendo rutas medias, como por ejemplo el que hace ruta Jaguey Grande - Matanzas. Para comunicar pequeños centros urbanos se utilizan minibuses algo deteriorados por el tiempo.

En 2014 se inauguró un puerto de contenedores que demandó una inversión de 700 millones de dólares y fue construido por la empresa brasileña Odebrecht en Mariel.

Para evitar las deficiencias de la electricidad producidas en las termoeléctricas, donde se lleva el combustible ya refinado, el gobierno cubano invirtió en la reparación de generadoras de energía. Una de ellas fue la más moderna y eficiente del país, la Termoeléctrica de Cienfuegos, la cual a 2009 está siendo reparada para lograr un mejor funcionamiento. Así también ocurre en otras como la de Santiago de Cuba, en la que se controlan las emisiones tóxicas a la atmósfera. También se ha realizado una importante inversión en construcción de emplazamientos de grupos electrógenos diésel y Fuel Oil diseminados por todo el país, eliminando casi por completo los apagones de los años 90.

El programa de ahorro de energía cubano conocido como "Revolución Energética" vendió con facilidades de pago a los núcleos familiares equipos electrodomésticos de cocina como refrigeradores, ollas de presión eléctricas, cocinas eléctricas, etc. para evitar el gran consumo de gas natural y otros combustibles como el keroseno. Como parte de este programa también se arreglaron postes eléctricos y cables de alta tensión para la distribución de la electricidad, se instalaron nuevos generadores y esto hizo que fueran prácticamente eliminados los ya familiares apagones.
Este programa convirtió a Cuba en el primer país del mundo en sustituir las bombillas incandescentes por bombillas de bajo consumo, ejemplo seguido después por países como Australia, Venezuela o Argentina.

Existen lugares muy intrincados del país en los cuales no fue posible llevar la luz eléctrica. No obstante, se recalcó que toda escuela tenía que tener un televisor, video y computadoras. Para obtener electricidad con la cual abastecer estos aparatos, se recurrió a la energía fotovoltaica. Esta forma de obtención de energía radica en el almacenamiento de los rayos solares y su transformación en electricidad. Esto se lleva a cabo en paneles solares, que se han hecho muy comunes principalmente en la región de Guantánamo.

Cuba cuenta con cuatro grandes parques eólicos como obtención de energía alternativa. Uno de ellos se encuentra en la Isla de la Juventud, en ampliación hasta 2009.

En la región central de Cuba, en Ciego de Ávila, existe otro parque de menor amplitud que se encuentra en ampliación.

Siendo el más reconocido y constituido por varios parques, el de Gibara, Holguín, posee una enorme capacidad. Se les fueron dados los últimos ajustes y ya comenzó a producir sus primeros Megawats.

El cuarto, que cuenta con seis aerogeneradores de la tecnología china "Goldwind", en Punta Rasa, también cerca de Gibara comenzó a producir a principios de julio de 2010. a. “Con el objetivo de incrementar la venta de electricidad al Sistema Electroenergético Nacional, se ha estudiado y proyectado la instalación de 755 MW a través de 19 bioeléctricas en centrales azucareros, con mayores parámetros de presión y temperatura para operar por más de 200 días al año con biomasa cañera y biomasa forestal, fundamentalmente marabú. Se prevé que las 19 bioeléctricas produzcan más de 1900 GWh/año, y dejen de emitir a la atmósfera aproximadamente 1 700 000 toneladas de CO2 el país cuenta con una planta productora de paneles solares fotovoltaicos de 150 y 240 Wp, ubicada en Pinar del Río, con una capacidad de producción anual de 14 MWp.

Para mantener la economía a flote, La Habana busca activamente la inversión extranjera, lo cual a menudo resulta en la formación de empresas conjuntas en las que el gobierno cubano posee la mitad del capital, así como contratos de administración de instalaciones turísticas o el financiamiento de la zafra. Un nuevo marco legal, dispuesto en 1995, les permite a los propietarios extranjeros tener mayoría en las empresas colectivas con el gobierno cubano. En la práctica, la mayoría propietaria extranjera en las empresas colectivas es casi inexistente. Hacia finales del 2000, operaban en Cuba casi 400 empresas conjuntas, lo cual representa inversiones, por parte de 46 países, de entre 42 y 45 mil millones de dólares, aunque prácticamente el 70% de las mismas no podrían considerarse inversiones extranjeras de acuerdo con el estándar internacional, ya que operan fuera del país. Gran parte de estas inversiones son préstamos o contratos de administración, suministros o servicios que, en las economías occidentales, normalmente no se consideran inversiones de capital.

Las remesas familiares de dinero desde el extranjero desempeñan un papel importante en las cuentas públicas de Cuba, y suponen entre 800 y 1.000 millones de dólares por año para una economía de 18.000 millones de dólares. La mayoría de las remesas provienen de familiares en Estados Unidos, a quienes la ley estadounidense permite enviar a la isla hasta 1.200 dólares cada año. Esto proporciona acceso a dólares a casi un 60% de la población cubana.

En 2009 el presidente de Estados Unidos, Barack Obama, permitió que todos los cubanoamericanos viajen y envíen remesas a Cuba sin restricciones. Además, posibilitó que las empresas de telecomunicaciones negocien con la nación caribeña, en medio del proceso de diálogo que viven los dos estados desde la asunción a la presidencia de Obama.

Desde el inicio de la colonia en Cuba, han existido científicos dedicados a tales temas que han contribuido con sus estudios al conocimiento de la naturaleza en Cuba. Muchos de ellos fueron coleccionistas y biólogos que donaron sus colecciones que ahora se exponen en los Museos de Historia Natural de este país.

El gobierno de Cuba en el siglo XXI ha dedicado un mayor empeño a las ciencias como la botánica, la zoología y la geología. En ellas se desarrollan científicos reconocidos actualmente que han realizado nuevos logros e investigaciones. Muchos de estos temas han sido también muy conocidos entre la población a través de los cursos como Universidad para Todos de Naturaleza Geológica de Cuba y Bosques de Cuba. En ellas, mediante videos y diapositivas explicados por especialistas, se muestran temas tan importantes de Cuba como los demás.

Cuba contó con figuras ilustres de la medicina y biotecnología cuyos descubrimientos todavía hoy son aplicables. Entre ellos se encuentra Carlos J. Finlay, que luchó contra la fiebre amarilla. En la actualidad este sector cuenta con un gran desarrollo, con centros de gran prestigio como el de Ingeniería Genética y Biotecnología, el de Hemo-Derivados y el Centro de Inmunología Molecular, todos localizados en el Polo Científico del oeste de La Habana. Estos centros cuentan con grandes logros en vacunas, como la Pentavalente, de la cual Cuba es el único país del Tercer Mundo y segundo de todo el planeta en poseerla (solo después de Francia). El Heberprot-P, un potente agente cicatrizante desarrollado en Cuba, se exporta ya a 19 países que lo han autorizado. Cuenta además con vacunas contra la Hepatitis B y el tétanos, con el interferón y con importantes ensayos clínicos en el área del cáncer.

Cuba se destaca enormemente en el sector de la sanidad gracias a la dedicación y profesionalismo de los cada vez más médicos graduados. Algunos de los mayores logros están en la biotecnología, en la elaboración de medicamentos y vacunas. Luego del periodo especial, con el embargo económico sobre Cuba, la misma comenzó a producir y perfeccionar los medicamentos y vacunas con el objetivo de evitar su escasez en el país. Además se aplica como medio alternativo la medicina verde, usada antes que los medicamentos actuales. Las vacunas son distribuidas a la población joven, gracias a productos elaborados contra enfermedades prácticamente erradicadas.

En cuanto a la informática, en febrero de 2009 comenzó a desarrollarse en Cuba una distribución GNU/Linux creada por profesores y alumnos de la Universidad de Ciencias Informáticas. Se espera que esta distribución, llamada Nova, reemplace paulatinamente al software privativo. También Cuba posee ordenadores en todos los centros educacionales, desde el nivel primario hasta el universitario; en este último se cuenta con conexión a internet e intranet, como por ejemplo Infomed, un sitio de la rama de la medicina. Se estima que solo el 1.7% de la población tiene acceso a internet, según el gobierno por las restricciones impuestas por el bloqueo de Estados Unidos, según los disidentes, es porque el gobierno no permite que el pueblo tenga acceso a un medio de información libre.

El nivel de vida al final de la década de 1990 permanecía por debajo del de 1989. Los precios más bajos para el azúcar y el níquel, las alzas en el precio del petróleo, la disminución del turismo después del 11 de septiembre de 2001 y el devastador huracán de noviembre de 2001, crearon entre todos nuevas presiones económicas para el país y amenazaron con anular las mejoras logradas a mediados y finales de los años 1990. La escasez de alimentos y combustible empeoró radicalmente.

La recuperación económica que empezó, con el nuevo siglo, continuó hasta elevar el PIB, primero con la inversión en el turismo y luego por los avances en la medicina, software, servicios y níquel. y posteriormente con un intenso programa en la agricultura (fundamentalmente la caña y la industria ganadera) el aumento de la producción para el autoconsumo. Conjuntamente con el progreso se iniciaron los servicios nacionales de CUBACEL (celulares) y el acceso a cualquier hotel que una vez fue dedicado solamente al turismo. Además se autorizó la tenencia y venta de computadoras, reproductores de DVD y otros electrodomésticos. El transporte mejoró en 2008, fundamentalmente en La Habana. Como mismo fue la modernización de los equipos de suministro de energía eléctrica y el combustible por medio de PetroCaribe, eliminándose los apagones desde 2007 con la "Revolución Energética", que repartió a créditos diferentes insumos de cocción, y bombillos ahorradores haciendo de Cuba el primer país en el mundo en realizar esta llamada "revolución verde", seguida después por Australia, Europa y Argentina, entre otros países.
Desde 2005, debido al ingreso del país en diferentes organismos regionales como el ALBA, el crecimiento del PIB se disparó, manifestándose de esta forma:

El crecimiento estimado para 2008 era mayor (de alrededor del 7%) y se comportó así en el primer semestre, con alrededor del 6%. Sin embargo, el paso por el país de tres poderosos huracanes hicieron que solo creciera en la cifra previamente expuesta.
Ese mismo año fue autorizado el pluriempleo para palear el envejecimiento poblacional, que en Cuba es similar al de naciones de Europa.
El informe del PNUD sobre calidad de vida y desarrollo humano sitúa a la isla en 2009 en el lugar 51 del planeta con más de 0,8 puntos, y como el quinto mejor país para vivir de América Latina, con una esperanza de vida de 78,5 años y una alfabetización del 99,8%, por encima de países vecinos como México, Costa Rica o Bahamas.

En 2009 la Unicef, confirmó que en el país existía un 0% de desnutrición infantil. Sin embargo datos más recientes de Unicef mantienen un 7% de desnutrición moderada y severa .

Los Objetivos de Desarrollo del Milenio, se cumplen en Cuba, de manera más rápida que en otros países de la región latinoamericana. Se relacionan, según cifras del PNUD, de la siguiente manera:

En 2009 a pesar de la recesión mundial la economía creció un 0,8% en el primer semestre y un 2% aproximadamente en el segundo, lo que redondeó en un 1.4% al final del año.
Esta situación internacional afectó al país con grandes problemas de liquidez monetaria, conduciendo a una cadena de impagos a empresas extranjeras, el mayor exponente fue la disolución de la corporación Cubalse, una gigante paraestatal, que poseía decenas de tiendas, y centros comerciales en toda la isla, sus trabajadores fueron reubicados en las corporaciones Cimex y TRD. Sin embargo gracias al crecimiento de sectores como la agricultura (4,5%), el transporte (4,6%) y los servicios (4%) y a pesar de que el sector industrial decreció un (2%) y el comercio promedio un (0%) de crecimiento, el país se mantuvo fuera del grupo que sufrió recesión y desempleo generalizado.

El bloqueo económico que los Estados Unidos impusieron sobre Cuba (lo que en EUA se conoce como "el embargo") es un bloqueo económico, comercial y financiero que sigue en vigencia desde el 7 de febrero de 1962 y es el bloqueo de mayor duración en la historia moderna.

Los inversionistas están restringidos por la ley estadounidense de Libertad y Solidaridad Democrática Cubanas (LIBERTAD), que impone sanciones a aquellos que "trafiquen" en bienes expropiados de propiedad de ciudadanos estadounidenses. Hasta agosto de 2002 se les ha impedido ingresar en Estados Unidos a 18 ejecutivos de dos compañías extranjeras. Más de una docena de empresas han abandonado Cuba o han cambiado sus planes de inversión allí debido a la amenaza de sanciones de acuerdo con la "Ley LIBERTAD".
Este sistema de sanciones incluye, varias regulaciones y trabas comerciales, entre otras están que: un barco de cualquier país que toque puerto cubano, no puede anclar en EE.UU. hasta pasados seis meses de su visita a la isla, a los Estados Unidos además no puede entrar ningún producto de Cuba, ni manufactura alguna elaborada en cualquier país con algún tipo de producto cubano, tampoco ninguna empresa del mundo está autorizada a vender al país caribeño, cualquier producto que tenga más de un 10% de componentes norteamericanos, so pena de sanciones económicas para la empresa o sus ejecutivos.

Este bloqueo o embargo es un tema en el que casi todos los países sostienen que dichas sanciones económicas contra Cuba son inútiles y contraproducentes. En 2008, tras diecisiete victorias consecutivas a favor de la isla, el bloqueo que en el mundo se conoce como "embargo", fue condenado por 187 países y solo apoyado por Estados Unidos, Israel y Palaos.

La economía en Cuba pasa por un período de recuperación, después del llamado Período especial en el que las reformas llevadas a cabo impactaron directamente en todos los sectores económicos. En el año 2008 acompañando a la crisis global, Cuba sufrió el paso de tres potentes huracanes que destrozaron cerca del 20% de su Producto Interior Bruto en el ámbito agrícola. El turismo fue uno de los sectores clave en este contexto, ya que se ha convertido junto a la agricultura en los dos pilares que sustentan el PIB del país. Un dato destacable es la tasa de crecimiento, que en el intervalo 2000-2010 se observa una contracción del 62.7%, aunque este dato no hace justicia a los excelentes años de crecimiento que presentó en el 2005 (11.2%) y 2006 (12.1%). Para el período 2000-2008 la evolución de su Producto Interior Bruto fue del 98.9% escalando hasta los 60 mil millones de dólares. En la siguiente tabla se observan el resto de indicadores socioeconómicos relevantes.




</doc>
<doc id="43010" url="https://es.wikipedia.org/wiki?curid=43010" title="Río Don">
Río Don

El río Don , «río» en la lengua de los escitas, es un río de la Rusia europea que fluye por el sudoeste de la gran llanura europea desaguando en el mar de Azov. Tiene una longitud de () y drena una cuenca de . Es el mismo río Tanais ("Τάναϊς" en griego antiguo), de las fuentes clásicas grecorromanas.

Las principales ciudades en su curso, con más de 100 000 habs., son Vorónezh, Volgodonsk y Rostov del Don. Sus afluentes principales son los ríos Donéts y Jopior, ambos con más de de longitud. Administrativamente, el río discurre, aguas abajo, por los siguientes óblast: Tula, Lípetsk, Vorónezh, Rostov y Volgogrado.

El río Don tiene todas las características de un río de llanura. Su pendiente media varía poco desde el nacimiento hasta la desembocadura, con un valor de solo (). Discurre por unas vastas llanuras aluviales en todo su recorrido, excepto en las cercanías de Kalach del Don, donde su valle se estrecha significativamente. El valle del Don, al igual que el de otros ríos de la región, presenta una morfología asimétrica, con las orillas de la derecha altas y empinadas, y las orillas izquierdas bajas y llanas.

El río Don nace cerca la ciudad de Novomoskovsk (Rusia) ( en 2002), en el óblast de Tula, a unos al sureste de Tula (), y unos al sureste de Moscú. Discurre en sus inicios en dirección sur, recibiendo por la izquierda al primero de sus afluentes de importancia, el río Nepravda y saliendo del óblast de Tula por la trifrontera entre los óblast de Tula, Lípetsk y Riazán, en el que el río no entra.

Siguiendo al sur, se adentra en el óblast de Lípetsk, pasando por las localidades de Dankov () y Lebedyan (), para recibir a continuación por la derecha al río Krasivaya Mecha y luego al río Sosna, que acaba de atravesar la ciudad de Yelets (). Sigue el Don por Zadonsk () y Kon-Kolodej, y luego llega a un tramo en el que el río forma la frontera natural entre los óblast de Lípetsk y de Voronezh.

Tras ese corto tramo, el Don entra, por su parte septentrional, en el óblast de Voronezh. Manteniendo la dirección sur, el río pasa muy cerca de la capital Vorónezh () (a unos ), donde recibe por la izquierda al homónimo río Voronezh y, por la derecha, al río Devica. Continúa hacia el sur, atravesando la localidad de Grenjacez y recibiendo por la derecha al ríos Potudan y más tarde al río Tichaja Sosna. Llega luego a la ciudad de Liski (), para después recibir, por la izquierda, al río Ikorec, al río Bitiug y luego al río Osered. Continúa por la ciudad de Pávlovsk () y luego recibe, por la izquierda, al río Chórnaya Kalitvá, un punto en el que el río vira hacia el E-SE, y en el que está a menos de de la frontera con Ucrania. El río discurre por un tramo en el que recibe, por la izquierda, al río Boguchar y, luego, por la derecha, al río Tolucheevk.

Abandona al poco el óblast de Voronezh y se adentra, por su lado occidental, en el óblast de Rostov, un corto tramo en el que recibe por la izquierda al río Peskovatka y llega después a las localidades de Kazankaya y Veshenskaya (). Entra luego en el óblast de Volgogrado, para recibir al poco, por la izquierda, al río Khoper y luego al río Medveditja. Unos kilómetros aguas abajo pasa frente a Serafimovich (), después recibe por la izquierda al largo río Ilovlya ( y una cuenca de ) y llega a Kachalino. El Don vuelve a girar hacia el suroeste, discurriendo por una región cada vez más árida y seca, y un poco antes de llegar a Kalach del Don (), el río entra en una zona embalsada, la cola del largo embalse de la presa de Tsimlyansk (), situada a más de de distancia aguas abajo. En este gran embalse el Don recibe, por la derecha, los ríos Donskaja Carica, Esaulovskij Aksái y Kurmoyarsky Aksái; y, por la izquierda, al río Liska y al río Chir. A mitad del embalse, el río Don abandona el óblast de Volgogrado y entra nuevamente en el óblast de Rostov, esta vez por su parte centrooriental.

Dejada atrás la presa, en las proximidades de la ciudad de Volgodonsk () y Tsimlyansk (), el río sigue en dirección oeste, pasando por Konstantinovks () y en Ust-Donecki recibe por la izquierda al más importante de todos sus afluentes, el río Donets. Ya en su tramo final, recibe, por la izquierda, al río Sal y al río Manych, y, por la derecha, al río Aksái, en la localidad de Aksái (). Llega luego a Rostov del Don, la principal ciudad de todo su curso () y poco después el río Don, tras un recorrido de casi , desemboca en el mar de Azov formando un amplio estuario de unos , muy cerca de la localidad homónima de Azov ().

En el primer mapa se pueden leer a lo largo de su curso los nombres de las siguientes ciudades: Новомосковск (Novomoskovsk), Данков (Dankov), Задо́нск (Zadonsk), Воронеж (Vorónezh), Ли́ски (Liski), Па́вловск (Pavlovsk), Серафимо́вич (Serafimóvich), Кала́ч-на-Дону́ (Kalach del Don), Цимля́нск (Tsimliansk), Волгодо́нск (Volgodonsk), Константи́новск (Konstantínovsk), Росто́в-на-Дону́ (Rostov del Don) y Азов (Azov).

Según la hipótesis de los kurganes, el valle del Don sería la patria de los protoindoeuropeos, pueblo imprecisamente localizado al norte entre el mar Negro y el mar Caspio, precisamente allí. En la antigüedad, el río Don era considerado la frontera entre Europa y Asia (dos de las tres partes del mundo, siendo Libia —África— la tercera, separada de Asia por el río Nilo). En el Libro de los Jubileos, se menciona el río como parte del límite, desde su punto más occidental hasta la desembocadura, de las adjudicaciones a los hijos de Noé, Jafet (norte) y Sem (sur). Se menciona que su curso era tan rápido que nunca se había congelado. Según Plutarco y Eustathius de Salónica, el nombre griego derivado de la guadaña don Dan.

Durante el tiempo de los antiguos escitas era conocido, en griego, como el río Tanais (Τάναϊς), y desde esa época ha sido una importante ruta comercial. Tanais aparece en las fuentes antiguas griegas como el nombre del río y de una ciudad de los sármatas (Tana-Azaq, la actual Azov), localizada en el sur de su boca, en la región de la laguna Meótide (Μαιῶτις λίμνη). El nombre deriva, sin embargo, del escita iranio "Dānu" 'río', similar al moderno osetio "don" 'río'.

La fortaleza jázara de Sarkel fue utilizada para dominar este punto en la Edad Media.

En tiempos modernos, la parte baja del río vivió los intensos combates durante la Operación Urano, uno de los puntos de inflexión de la Segunda Guerra Mundial.

El Don ha dado su nombre a los cosacos del Don, los cosacos que se asentaron en su fértil valle en los siglos XVI y XVII. En la literatura moderna, el Don es un tema central en las obras de Mijaíl Shólojov, escritor y premio Nobel. Su obra más famosa se titula "El Don apacible". El escritor residía en la stanitsa Vióshenskaya.

En su punto más oriental, el río Don pasa muy cerca del curso del río Volga, en las proximidades de Kalach del Don. En 1952 se inauguró el canal Volga-Don, que, tras , permite llegar al Volga cerca de Svetly Yar y luego, aguas abajo, alcanzar el mar Caspio, siendo una de las principales arterias fluviales. El nivel de agua del río Don en esta zona se alcanza gracias a la presa de Tsimlyansk, finalizada en ese mismo año, que forma el largo embalse del mismo nombre.

En los siguientes por debajo de la presa de Tsimlyansk, la profundidad de agua suficiente en el río Don se mantiene por una secuencia de tres presas y sistemas de esclusas: la clase de buques esclusa Nikoláyevsky (Николаевский гидроузел), la clase esclusa Konstantínovsky (Константиновский гидроузел) y la más conocida de las tres, la clase esclusa Kóchetovsky (Кочетовский гидроузел). La esclusa Kóchetovsky, construida en 1914–1919, se duplicó en 2004–2008, y está ubicada por debajo de la confluencia del río Séverski Donéts en el Don, y aguas arriba de Rostov, esta la esclusa Kóchetovsky. Esta instalación mantiene el nivel de agua suficiente, tanto en su sección del Don, como en el tramo inferior del Séverski Donéts. Esta es la última esclusa en el Don; aguas abajo de Kóchetovsky, la profundidad necesaria para la navegación fluvial se mantiene mediante dragado.

El río Don es navegable en casi todo su curso.

El río Don tiene un régimen nival de llanura. El río comienza a congelarse a finales de noviembre o principios de diciembre. Permanece bajo el hielo 140 días al año en el curso superior y de 30 a 90 días en el curso inferior, en la parte inferior nunca está congelado.

El río Don tiene numerosos afluentes, siendo los más importantes, siguiendo el río aguas abajo, los que recoge la tabla siguiente.

Otros afluentes menos importantes son los ríos Tsimla (Цимла) (186 km) y Kumshak (Кумшак) (121 km).



</doc>
