<doc id="15283" url="https://es.wikipedia.org/wiki?curid=15283" title="Vida extraterrestre">
Vida extraterrestre

El término vida extraterrestre se refiere al hipotético tipo de vida que pueda existir fuera del planeta Tierra y que no se haya originado en él. 

Tal vida puede variar desde simples procariotas (o formas de vida comparables) hasta seres con civilizaciones mucho más avanzadas que la humanidad.  La ecuación de Drake especula sobre la existencia de vida inteligente en otras partes del universo. La ciencia de la vida extraterrestre en todas sus formas se conoce como astrobiología.

Una porción creciente de la comunidad científica se inclina a considerar que pueda existir alguna forma de vida extraterrestre en lugares donde las condiciones sean propicias, aunque generalmente se considera que probablemente tal vida exista solo en formas básicas. Una hipótesis alternativa es la panspermia, que sugiere que la vida podría surgir en un lugar y después extenderse entre otros planetas habitables. Estas dos hipótesis no son mutuamente excluyentes. Se especula con formas de vida extraterrestre que van desde bacterias, que es la posición mayoritaria, hasta otras formas de vida más evolucionadas, que puedan haber desarrollado inteligencia de algún tipo. La disciplina que estudia la viabilidad y posibles características de la vida extraterrestre se denomina exobiología. 

Debido a la falta de pruebas a favor o en contra, cualquier enfoque científico del tema toma siempre la forma de conjeturas y estimaciones. Aunque cabe notar que el tema posee también una gran cantidad de teorías informales y paracientíficas, que exceden con facilidad los criterios de cualquier epistemología científica, por ejemplo, haciendo afirmaciones infalsables según el criterio de Popper, y son por tanto consideradas seudociencias.

Toda vida en la Tierra requiere de elementos químicos, hidrógeno, oxígeno, carbono, nitrógeno, azufre, fósforo, así como de otros muchos en menores cantidades, como ciertos minerales; requiere además de agua líquida como solvente en el cual las reacciones tienen lugar. Cantidad suficiente de carbono y demás elementos constituyentes de la vida, junto con el agua, harían posible la formación de organismos vivientes en otros planetas con una química, presión y temperatura similares a las de la Tierra. Como la Tierra y otros planetas están hechos de "polvo estelar", es muy probable que otros planetas se hayan formado con semejante composición de elementos químicos que los terrestres.
La combinación de carbono y agua en la forma de carbohidratos, como el azúcar, puede ser una fuente de energía química de la que depende la vida, mientras que a la vez provee elementos de estructura y codificación genética. 
El agua pura es útil, pues tiene un pH neutro debido a la continuada disociación entre sus iones de hidronio e hidróxido. Como resultado, puede disolver ambos tipos de iones, positivos (metálicos) y negativos (no metálicos) con igual habilidad.

Debido a su relativa abundancia y utilidad en el sostenimiento de la vida, muchos han hipotetizado que todas las formas de vida, donde quiera que se produzcan, se valdrían también de estos materiales básculas . Aun así, otros elementos y solventes pueden proveer una cierta base de vida. 
Se ha señalado al silicio como una alternativa posible al carbono; basadas en este elemento, se han propuesto formas de vida con una morfología cristalina, teóricamente capaces de existir en condiciones de alta temperatura, como en planetas que orbiten muy cercanos a su estrella.

También se han sugerido formas de vida basadas en otros solventes, pues existen compuestos químicos capaces de mantener su estado líquido en diferentes rangos de temperatura, ampliando así las zonas habitables consideradas viables. Así por ejemplo, se estudia el amoníaco como solvente alternativo al agua. La vida en un océano de amoníaco podría aparecer en un planeta mucho más lejano a su estrella. 

Técnicamente, la vida es básicamente una reacción que se replica a sí misma, por lo que bajo esta simple premisa podría surgir la vida bajo una amplia gama de condiciones e ingredientes diferentes, si bien la vía carbono-oxígeno parece la más óptima y conductiva. Existen incluso teorías sobre reacciones autorreplicantes que podrían ocurrir en el plasma de una estrella, aunque éste sería un tipo de "vida" altamente extremo y nada convencional.

Hubo un cambio dramático en el pensamiento con la invención del telescopio y el heliocentrismo. Una vez que quedó claro que la Tierra era meramente un planeta entre innumerables cuerpos en el universo, la teoría de vida extraterrestre comenzó a convertirse en un tema en la comunidad científica. Uno de los primeros fue el filósofo italiano Giordano Bruno, que argumentó en el siglo XVI que para un universo infinito en el cual todas las estrellas estuvieran rodeadas de su propio sistema planetario, habría otros mundos con "no menos virtud ni una naturaleza distinta a la de nuestra tierra" y, como la Tierra, "contienen animales y habitantes".

La posibilidad de vida extraterrestre era una trivialidad del discurso educado durante el siglo XVII, aunque en el poema "El paraíso perdido" (1667) Milton empleó cautelosamente este tema cuando el ángel sugiere a Adán la posibilidad de vida en la Luna:

Fontanelle expandió la esfera creativa del Creador, en lugar de negarla, en su obra "Conversaciones sobre la pluralidad de los mundos". Y en "La excursión"" (1728), David Mallet exclamó: "Diez mil mundos resplandecen; cada uno con su carga/De mundos poblados".

En la literatura, otro ejemplo sería "El otro mundo: las sociedades y gobiernos de la Luna", del poeta Cyrano de Bergerac, donde las sociedades extraterrestres se presentan como parodias humorísticas o irónicas de la sociedad terrena.

En 1752, Voltaire publica el cuento corto "Micromegas", que avanza muchas de las nociones que luego se ven expresadas de forma recurrente en la ciencia ficción incipiente y contemporánea. En particular, la idea de que los alienígenas pueden viajar entre las estrellas y venir a la Tierra (hasta llega a sugerir cierta propulsión luminosa, análoga a una vela solar), y que son distintos a los humanos de forma fundamental (en este caso, en talla, tiempo de vida y cantidad de sentidos).

El género de la ciencia ficción se desarrolla durante el siglo XIX con Julio Verne en "Alrededor de la Luna" (1870), que ofrece una discusión sobre la posibilidad de vida en la Luna, pero con la conclusión de que es estéril, y "La guerra de los mundos", de H. G. Wells (1898), con la idea popular de la "invasión marciana”.

Debido a que es un fenómeno que por el momento permanece esencialmente fuera del alcance de la ciencia (al no disponer de datos, y por tanto de la posibilidad de experimentar y refutar las hipótesis), no existe una disciplina "formal" que estudie la vida extraterrestre, ni ningún currículo académico que forme expertos en ello. Aquellos que se han aproximado al tema de manera científica son por lo general expertos en áreas diversas, que por interés meramente personal han elaborado hipótesis sobre las posibilidades de vida en otros mundos, y han compartido sus puntos de vista a través de algún medio. Pese a ello, ha surgido una enorme cantidad de trabajos y publicaciones serias sobre el tema, de modo que puede hablarse de una cuasi-ciencia dedicada a estudiar y teorizar sobre este fenómeno, a pesar de la ausencia de pruebas. La proto-ciencia que estudia la vida extraterrestre se llama exobiología o astrobiología, y esencialmente se dedica a especular sobre los límites en los que, según nuestros conocimientos científicos, podría darse la vida.

Hay muchas preguntas acerca de cómo puede ser la vida extraterrestre, para las que la ciencia todavía no tiene respuesta, como por ejemplo:

Los detractores de la idea de que pueda existir vida extraterrestre indican que no es científico hipotetizar sobre hechos no conocidos o probados, tales como formas de vida que no se basen en el carbono, ecosistemas avanzados que no sean ricos en gases hormonales, o planetas con biosferas significativamente distintas a la de la propia Tierra (temperatura media, tipo de estrella que orbitan, satélites, geología, etc.).

Debido a que el único ejemplo de vida que conocemos en el universo es la vida en el planeta Tierra, los que se interesan en el tema siguiendo un enfoque racional suelen seguir el principio científico de mediocridad, al afirmar que la vida en el planeta Tierra no es un caso especial, y por lo tanto la vida como la conocemos puede ser considerada un ejemplo típico de lo que la vida sería en todas partes. Esta presunción es relevante, pues determina fuertemente las acciones que emprenden los que buscan probar científicamente la existencia de la vida fuera de la Tierra.
Dicho principio de mediocridad, pese a su estatuto de conjetura, permite aventurar algunas predicciones sobre los posibles atributos de la vida extraterrestre. En particular, se admite que existen "atributos universales" de la vida. Por ejemplo, se acepta que la evolución darwiniana es universalmente válida, y que toda potencial criatura viviente debería sus características a un proceso de selección natural, tanto en la Tierra como en cualquier otro lugar del universo.

Existen otros atributos o características cuasi-universales en las especies que, al repetirse sucesivamente de diferentes formas en diferentes especies en la biosfera terrestre —un proceso caracterizado como evolución convergente—, se consideran como altamente probables en una hipotética biosfera alienígena. Entre estas características cabe destacar la aparición de los sentidos, las extremidades adaptadas para diferentes medios y, muy probablemente, la fotosíntesis cuando hablemos del reino vegetal.

En este sentido, existe una gran diversidad de formas que podría adoptar la vida extraterrestre. Existen otros atributos más particulares que muchas veces se dan por sentados, pero que según los expertos no lo serían, ya que no responden mejor que otros a una necesidad evolutiva, y no se dan en todas las especies presentes en un mismo hábitat, por lo cual éstos pueden variar o no existir, como por ejemplo órganos como la mano humana, o una posición de ojos, nariz y boca similares a la humana. También hay otros atributos, entre ellos por ejemplo el esqueleto, que aunque se consideran una necesidad para criaturas de cierta talla, podrían ser muy diferentes a lo que conocemos. Así por ejemplo la columna vertebral sería una invención terrestre, ya que no se presenta en todos los organismos del planeta Tierra.

Los detractores de esta hipótesis de la evolución convergente indican que para que ésta exista deben darse, entre otros factores, condiciones medioambientales muy similares que por estadística es muy difícil que ocurran, pues que no se conoce la existencia de planetas con biosferas significativamente similares a la de la Tierra.

En contraposición al principio de mediocridad, están los que afirman que la vida en la Tierra no es un caso mediocre, y que las condiciones necesarias para su aparición son tan únicas y particulares que bien puede ser posible que existan muy pocas, o incluso solo un planeta con vida en el universo: la Tierra.

Los defensores de esta hipótesis alegan que la vida en la Tierra, y en particular la vida humana, parecen depender de una larga y extremadamente afortunada cadena de eventos y circunstancias, que bien podrían ser irrepetibles incluso en la escala cósmica. Por ejemplo, se menciona con regularidad que sin una Luna tan grande como la que tiene la Tierra, el planeta tendería a presentar una precesión mucho más importante, cambiando drásticamente de inclinación en su rotación y afectando así de manera caótica el clima y, muy posiblemente, imposibilitando la vida como la conocemos.

Se mencionan también otras aparentes casualidades afortunadas, como el hecho de que el Sol esté en un lugar de la Vía Láctea relativamente libre de supernovas, en contraposición al centro galáctico, o que el Sol es del tamaño justo para dar energía suficiente, y durar lo suficiente, como para que la vida haya aparecido.

Otra positiva casualidad para la vida en la Tierra es la existencia de un planeta del tamaño de Júpiter, como apuntan los autores del libro "Rare Earth", en una órbita estable, casi circular y a la distancia suficiente de la Tierra para atrapar numerosos cometas y asteroides que, de otro modo, terminarían impactando con el planeta, arruinando todo tipo de vida incipiente. Esas, entre muchas otras casualidades, separadamente pueden parecer triviales, pero juntas convierten a la Tierra en un lugar cósmicamente "especial".

Sin embargo, desde fines del siglo XX, y producto de nuevos descubrimientos, tales como la existencia de moléculas orgánicas en el espacio, la presunta existencia de un océano de agua líquida en Europa, o el demostrado hecho de que los planetas extrasolares son relativamente comunes, y de que por tanto algunos de ellos podrían presentar condiciones factibles para la vida, han hecho que esta hipótesis ya no sea compartida por buena parte de la comunidad científica.

La panspermia es la teoría que sostiene que la vida en la Tierra proviene del espacio, especulando que la vida llegó de otros cuerpos celestes (quizás de planetas extrasolares) en forma de esporas, viajando en meteoros y polvo cósmico que serían arrojados al espacio por choques meteóricos. Existe una variante de esta teoría, que afirma que la vida es estrictamente originaria del sistema solar, pero que sí se difundió a la Tierra (o incluso, desde la Tierra hacia otros cuerpos) a través de esporas en meteoros; a esta teoría se le llama transpermia. Sin embargo y aceptando, por supuesto, la validez de las precitadas teorías, es preciso no perder de vista otro enfoque científico de la vida extraterrestre: su búsqueda mediante las señales de radio provenientes del espacio profundo. Durante los últimos meses, se ha dicho y escrito bastante sobre la captación de señales que provienen, supuestamente, de galaxias extremadamente lejanas. No obstante, es necesario esperar a que, mediante la Metodología de la Investigación Científica, se niegue o, bien, se corrobore que dichas señales son reales. 

La especulación sobre las posibles formas de vida extraterrestres, especialmente las inteligentes, así como sus posibles civilizaciones y relaciones con los seres humanos han sido y son tratadas también por la ciencia ficción y la ufología.

Los científicos buscan vida extraterrestre principalmente de tres maneras:

Debido a que, en la práctica, los únicos cuerpos celestes que el ser humano puede visitar son los de nuestro sistema solar, la búsqueda directa de vida extraterrestre se ha limitado a dicho sistema; principalmente a la búsqueda de vida microscópica, ya sea fósil o activa. Sin embargo no todos los cuerpos del sistema solar se consideran aptos para la presencia de vida. Actualmente se considera como posibles objetivos de búsqueda a:




Debido a la recientemente adquirida capacidad para detectar planetas extrasolares o exoplanetas orbitando estrellas distintas a nuestro Sol, entre la comunidad astronómica se ha generado un fuerte interés en descubrir mundos comparables en tamaño y propiedades a la Tierra; planetas que apenas empiezan a ser detectados. También hay un fuerte interés en la posibilidad de observar realmente tales mundos usando telescopios mucho más perfeccionados que los disponibles actualmente.
Hasta la fecha solo hay un ejemplo de observación directa de un planeta extrasolar ("véase GQ Lupi"); y aunque empieza a ser posible detectar planetas de tamaño equivalente a la Tierra ("véase Gliese 876") en otro sistemas, obtener fotografías de ellos todavía no es posible, debido a que los instrumentos disponibles no son lo suficientemente sensibles para separar el enorme brillo de la estrella del de sus planetas.
Eso puede cambiar en un futuro cercano, cuando telescopios como el Terrestrial Planet Finder de la NASA o el proyecto Darwin de la ESA entren en funcionamiento.
Entre las funciones de tales dispositivos está la de obtener fotografías de los planetas, y detectar propiedades fundamentales de los mismos, como su temperatura, o la presencia o ausencia de atmósfera, así como detalles sobre su composición (mediante espectroscopia).

Existen quienes creen que tales métodos permitirían detectar mundos paralelos donde existan procesos biológicos comparables a los presentes en la Tierra. La idea está respaldada por el hecho de que la luz que refleja nuestro planeta lleva consigo "marcas" que revelan la presencia de la vida; por ejemplo, la presencia de un alto nivel de oxígeno, y ciertas variaciones del espectro infrarrojo, que revelan la presencia de vegetación. 

Desde luego, tales métodos de detección asumen que la vida en la Tierra es un caso mediocre, y que las características de la luz reflejada por la Tierra son compartidas por todos los casos. Este método de detección tiene la ventaja de permitir la detección de mundos con vida primitiva (y que no transmiten ondas de radio como lo espera el SETI), con la condición de que dicha vida haya modificado la atmósfera, de manera análoga a como la vida ha cambiado la atmósfera terrestre desde su aparición.

Por otro lado, se ha teorizado que cualquier sociedad tecnológica estará trasmitiendo información: radiaciones electromagnéticas generadas por el ser humano son detectables en un radio de más de 50 años luz de la Tierra, y están en constante expansión. El proyecto SETI ("Search for Extraterrestrial Intelligence") o "Búsqueda de Inteligencia Extraterrestre", analiza los datos recogidos por los grandes radiotelescopios y los analiza buscando pautas artificiales utilizando superordenadores, así como un gran proyecto de computación distribuida en el mundo; "SETI@home". Hasta la fecha, no obstante, tan solo la señal Wow! ha sido reseñable en esta búsqueda.

A lo largo del tiempo se han producido también una serie de iniciativas en sentido contrario: no buscar la señal de una posible inteligencia extraterrestre, sino informar de nuestra presencia a potenciales civilizaciones que estén a la escucha. La primera fue el llamado Mensaje de Arecibo, lanzado en 1974 en dirección al cúmulo de estrellas de M13. A bordo de las sondas Pioneer 10 (en dirección a la estrella Aldebarán) y Pioneer 11 (en dirección a la constelación de Aquila) se encuentran sendos mensajes ("véase Placa de la Pioneer") destinados a una posible civilización extraterrestre que pudiese interceptar las sondas. Lo mismo ocurre en el caso del Disco de oro de las Voyager, en las sondas Voyager 1 (en dirección a la constelación de Ofiuco) y Voyager 2 (en dirección a la estrella Ross 248). Más recientemente, en 2008, un equipo de científicos ucranianos ha enviado mensajes en dirección al sistema Gliese 876. El 5 de febrero del mismo año a las 0:00 UTC la NASA transmitió la canción "Across the universe" de la banda británica The Beatles en dirección a la estrella Polaris que se encuentra a 431 años luz de la tierra, utilizando una antena de 70m en el DSN's a las afueras de Madrid con el fin de celebrar el 50 aniversario de la NASA, el 45 aniversario de la Deep Spacial Network (DSN) y el 40 aniversario de la canción.

Varios científicos del SETI han advertido que tratar de contactar con hipotéticas civilizaciones extraterrestres enviando transmisiones de radio al espacio es imprudente, acientífico, falto de ética y potencialmente catastrófico.





</doc>
<doc id="15284" url="https://es.wikipedia.org/wiki?curid=15284" title="Euskera">
Euskera

El euskera, vasco o vascuence (en euskera estándar: "euskara") es una lengua aislada, ergativa y aglutinante que tiene su origen y se habla principalmente en Euskal Herria. El euskera es oficial junto al castellano en el País Vasco y en la zona vascófona de Navarra, mientras que en Francia no tiene estatus oficial. Lingüísticamente, es una de las pocas lenguas no indoeuropeas de Europa y la única aún viva de Europa occidental. 

El euskera no tiene relación o conexión lingüística alguna con otros idiomas conocidos, aunque ha adquirido bastante léxico de otras lenguas, especialmente del español y del latín y, en menor medida, del francés. Se desconoce su origen, aunque se han propuesto múltiples hipótesis al respecto. La parte más genuina y diferenciada de su léxico y su estructura gramatical, así como su posible conexión con otras lenguas de la Europa prehistórica, han suscitado el interés de lingüistas de todo el mundo.

El euskera (o su inmediato antecesor, el euskera arcaico) fue el idioma predominante de una amplia zona a ambos lados de los Pirineos, que abarca desde el río Garona y Burdeos al norte; la sierra de la Demanda y el Moncayo al sur (incluyendo toda La Rioja y el norte de Soria); zonas de Cantabria y Burgos al oeste; y Andorra al este. Existen evidencias toponímicas y epigráficas sobre su presencia en todo este ámbito. Por ejemplo, en la zona norte de la provincia de Soria, existen decenas de topónimos vascos como Urbión, Larralde, el Acebal de Garagüeta de Arévalo de la Sierra, Garray o Narros. Según estudios epigráficos recientes, la presencia del euskera en Soria es anterior a que se impusiese una lengua céltica y después latina. Las evidencias toponímicas y epigráficas de la presencia del euskera en la zona norte de Soria, han sido respaldadas con un estudio genético elaborado en 2017 por los departamentos de Genética Humana y de Estadística de la Universidad de Oxford (Reino Unido), la Fundación Pública Gallega de Medicina Genómica de Santiago de Compostela y el Grupo de Medicina Genómica de la Universidad compostelana, que ha determinado que los sorianos de la zona norte de la provincia, en la que se incluyen las comarcas de las Tierras Altas, Almarza y Pinares, tienen cierta coincidencia en su genoma con las características genéticas de la población vasca y navarra, aunque sus similitudes son más importantes con las zonas del centro y del noreste de la península.
Desde la Baja Edad Media, el euskera viene sufriendo un declive que se debe a factores geográficos, políticos y sociológicos de diversa índole. Según el Atlas de lenguas en peligro de extinción elaborado por la Unesco, el euskera está en situación de "vulnerable". Cuando se aprobó la Constitución española de 1978, en Navarra, el euskera era hablado solo en su zona noroeste. En Álava, el retroceso fue mayor, hablándose prácticamente solo en el valle de Aramayona, y algo en los pueblos colindantes. En Vizcaya, a pesar de hablarse en casi toda la provincia, al no hablarse en las Encartaciones ni en el área metropolitana de Bilbao, que alberga entre el 85% y el 90% de la población, la extensión del euskera era también reducida. En Guipúzcoa, se hablaba en toda la provincia, aunque con focos fuertemente deseuskerizados, sobre todo en las zonas de fuerte migración desde otros lugares de España durante el . Finalmente, dentro de Francia se hablaba en la mitad aproximadamente del departamento de Pirineos Atlánticos. Desde las últimas décadas del el conocimiento del euskera ha aumentado, aunque su uso en la calle se redujo entre 2007 y 2017, situándose en un 12,6%.

En 2016 el 28,4 % de los habitantes del País Vasco, Navarra y País Vasco francés eran vascófonos. En el enclave de Treviño y el Valle de Villaverde, el porcentaje de vascoparlantes es del 22 % y 21 %, respectivamente. Del total de hablantes de euskera, el 93,2 % () vive en España y el 6,8 % () restante en Francia. Aproximadamente otras personas, el 16,4 %, son además vascoparlantes pasivos (entienden el euskera pero tienen dificultades para hablarlo). En el enclave de Treviño y en Valle de Villaverde los vascoparlantes pasivos son el 17 %. En conjunto, el porcentaje de personas que tienen algún conocimiento de euskera se eleva hasta el 40 % aproximadamente.

Los vascoparlantes no están distribuidos uniformemente, sino que se concentran en una zona geográfica continua. El porcentaje de personas que entienden el euskera es de más del 40 % en Vizcaya y Guipúzcoa, en toda Álava excepto en algunas zonas del sur y oeste, en la zona septentrional de Navarra, y en Baja Navarra, Sola y el sur de Labort; de aproximadamente el 40 % en el sur y oeste de Álava, el enclave de Treviño y el Valle de Villaverde; y menor al 20 % en el centro y sur de Navarra.

Se desconoce cuál es exactamente el origen de esta lengua. Aunque léxicamente el euskera ha tomado una gran cantidad de préstamos de las lenguas romances (especialmente del latín y del español), mantiene una estructura gramatical única. Asimismo, muchos lingüistas han sostenido que el euskera tuvo una importante influencia en las lenguas romances, especialmente en las de la península ibérica (español, catalán, asturiano y gallego).

Alrededor del año , el euskera se hablaba no solo en la totalidad de los territorios mencionados, sino más allá de sus actuales fronteras, ocupando un espacio geográfico delimitado aproximadamente por el cauce de los ríos Garona en Francia y Ebro en España. Desde entonces, lleva siglos en retroceso, desde el punto de vista geográfico, en buena medida debido a las divisiones administrativas del territorio, que llevó a su vez a la división lingüística del euskera (que hasta entonces estaba unificado) en dialectos o "euskalkis", y a la falta de reconocimiento oficial o estatal, así como por su escasa literatura (que no surge hasta el siglo XVI), que redujo en buena medida su difusión.

En Francia, el advenimiento de la Revolución francesa llevó a la proclamación de la igualdad de todos los franceses, lo que se tradujo en que todos los franceses tenían una única lengua: el francés, con la consiguiente falta de reconocimiento oficial del euskera y del resto de lenguas de ese país, que se mantiene hasta hoy día. En España, durante los siglos XIX y buena parte del XX el Estado era centralista, por lo que el euskera carecía de reconocimiento. Durante la Restauración y la dictadura de Francisco Franco, el uso del euskera en público fue estigmatizado y perseguido. A partir de la década de 1960, los esfuerzos por suprimir el euskera cesaron: el idioma volvió a utilizarse en educación, resurgieron las ikastolas y se dio un renacimiento de la literatura en euskera. Así, surge un movimiento que busca revivir el euskera y adaptarlo a los tiempos modernos, cuya máxima expresión fue la estandarización del idioma en un único conjunto de normas gramaticales y ortográficas: el euskera batúa, que es el que se utiliza en el ámbito administrativo, periodístico, literario, etc., aunque los dialectos siguen vivos en el habla cotidiana y muchos ayuntamientos han promovido la conservación de sus propias variantes dialectales del euskera.

España reconoce el euskera como un bien cultural que es objeto de especial respeto y protección. Ello, unido a la política lingüística del Gobierno Vasco, ha dado lugar a un gran aumento del número de hablantes del euskera, revirtiendo la tendencia histórica del retroceso. Actualmente, el euskera es lengua oficial y propia en el País Vasco y en la zona vascófona de Navarra. En Francia, la Constitución francesa establece que la única lengua oficial es el francés, aunque los distintos municipios que integran el País Vasco francés han tomado medidas en el ámbito de su competencia para conservar la lengua.

El euskera es la única lengua no indoeuropea de la península ibérica. El hecho de que durante la Alta Edad Media fuera hablada, además de en los territorios actuales vascoparlantes, en áreas de la Rioja Alta, la Riojilla Burgalesa y la Bureba pudo hacer que tuviera influencia en la conformación del castellano y singularmente en su sistema fonológico de 5 vocales (véase sustrato vasco en lenguas romances). Tras un periodo de prolongado declive desde la Baja Edad Media, acentuado en los siglos XVIII y XIX, que hizo que dejara de ser hablado paulatinamente en áreas de Burgos, La Rioja, Navarra y Álava, desde finales de la década de 1950 y principios de la de 1960 fueron puestas en práctica diversas iniciativas para evitar su desaparición, entre ellas la adopción de un estándar lingüístico superador de la fragmentación dialectal. Con la llegada de la democracia a España, la Constitución de 1978 facultó a las comunidades autónomas a declarar también oficiales en su territorio lenguas distintas al castellano, lo que sería materializado para el País Vasco por el Estatuto de Guernica, que recoge la cooficialidad del euskera y en donde ha logrado volver a ganar espacios de uso en la vida pública. Asimismo, en el artículo 9.2 de la Ley Orgánica de Reintegración y Amejoramiento del Régimen Foral de Navarra de 10 de agosto de 1982, se estableció también la oficialidad del euskera en la zona vascoparlante de Navarra. La posterior Ley Foral del Vascuence de 1986 reconoció al castellano y al euskera el carácter de lenguas propias de Navarra, delimitando en el marco del concepto legal del predominio lingüístico la 'Zona Vascófona' en la que el euskera es lengua cooficial. En el País Vasco francés, al igual que el resto de lenguas regionales francesas, el euskera no goza de la condición de lengua oficial y es el único de los ámbitos territoriales de la lengua en el que el conocimiento y uso del euskera entre la población disminuye hoy en día.

Se discute cuál es el origen exacto de la voz "euskara"; no obstante parece acreditada la identificación de dicho término con la identidad cultural vasca. Así, de la palabra "euskara" se deriva la palabra "euskaldun" (literalmente ‘el que posee euskara’), que designa al hablante del euskera. Asimismo, de la voz "euskara" se originó el término "Euskal Herria," originalmente denotativo del territorio en que se hablaba euskera (‘la tierra del euskera’) y que en el Estatuto de autonomía del País Vasco es utilizado como sinónimo de «pueblo vasco». El neologismo "Euskadi", creado como alternativa de la expresión "Euskal Herria" y actualmente sinónimo de País Vasco, también procede de la voz "euskara". Se discute la relación que las palabras «vasco» y «gascón» presentan con "euskara". Para designar a todos los demás idiomas, los vascohablantes usan la palabra "erdara" y a las personas no vascohablantes se les conoce genéricamente como "erdaldunak" (literalmente ‘los poseedores de otra lengua’, no vascoparlantes).

El filólogo Alfonso Irigoyen propone que la palabra "euskara" procede del verbo "decir" en vasco antiguo, reconstruida como "*enautsi" (mantenida en formas verbales como el vizcaíno "dinotzat", "yo le digo"), y del sufijo "-(k)ara", "forma (de hacer algo)". Por tanto, "euskara" significaría literalmente "forma de decir", "forma de hablar", "habla" o "lenguaje". Irigoyen presenta como evidencia para sostener esta teoría la obra "Compendio Historial" (1571), del vasco Esteban Garibay, donde el autor afirma que el nombre nativo de la lengua vasca es «enusquera». Véase también eusk- < *ausc-, del nombre del importante pueblo aquitano de los auscos (Auch, Gers).

Es tema discutido la extensión que tuvo el ámbito lingüístico euskérico en la antigüedad y Alta Edad Media. Algunos estudios apuntan a que llegó a abarcar un área territorial que se extendía desde el golfo de Vizcaya hasta el Pirineo catalán, incluyéndose en dicho ámbito los territorios de la hoy Gascuña, La Rioja, norte de Soria, este de Cantabria, norte de Huesca, nordeste de Burgos, noroeste de Zaragoza y parte de la provincia de Lérida, así como parte del actual departamento francés de los Altos Pirineos. Otras opiniones defienden que la versión primitiva del actual euskera tiene su origen en la región de Aquitania y creen que sería ya en tiempos históricos cuando se produjo su expansión a los territorios españoles en los que se habla actualmente. Durante los siglos VIII y XI se estima que el euskera vivió un segundo periodo de expansión, extendiéndose por territorios de la Rioja Alta y la provincia de Burgos, periodo del que la toponimia claramente euskérica de estas áreas (Herramélluri, Ochánduri, Bardauri, Sajazarra, etc) sería prueba.

En la actualidad, dentro de España el euskera es hablado como primera o segunda lengua en las tres provincias del País Vasco (Álava, Vizcaya y Guipúzcoa), en el enclave de Treviño (Castilla y León), en Valle de Villaverde (Cantabria) y en la Comunidad Foral de Navarra.

En la totalidad del territorio de Guipúzcoa, en el centro y oriente de Vizcaya, así como en algunos pocos municipios del norte de Álava y en el tercio septentrional de Navarra, el euskera es la lengua tradicional de la mayoría de la población. Por el contrario, en el occidente de Vizcaya (Las Encartaciones y Gran Bilbao) y en la mayor parte de Álava y Navarra, en el enclave de Treviño y en Valle de Villaverde, la lengua tradicional es el castellano.

Dentro de Francia el euskera es hablado en los territorios de Labort, Baja Navarra y Sola, comúnmente denominados en conjunto como País Vasco francés ("Iparralde" en euskera, ‘Zona Norte’) e integrantes junto a Bearne del departamento de Pirineos Atlánticos. El euskera es la lengua tradicional predominante de Baja Navarra (excepto el enclave gascoparlante de La Bastida de Clarenza), de Sola y de la mayor parte de Labort, en tanto que el extremo noroccidental de este último territorio, donde se encuentran las ciudades de Biarritz, Anglet y Bayona, es predominantemente francófono en la actualidad, y se hablaba idioma gascón anteriormente.

Para el caso del País Vasco, los datos de la VI Encuesta Sociolingüística (2016) realizada conjuntamente por el Gobierno Vasco, el Gobierno de Navarra y la Oficina Pública del Euskera del País Vasco francés, señalaba que un 33,9 % de la población mayor de 16 años era vascoparlante bilingüe (631 000 habitantes), un 19,1 % vascoparlante bilingüe pasivo (356 000) y un 47 % era castellanoparlante exclusivo (877 000). Según ese estudio, el número de vascoparlantes era mayoritario en Guipúzcoa (50,6 % de vascoparlantes bilingües, 20,4 % bilingües pasivos, 32,1 % castellanoparlantes exclusivos) y minoritario en Vizcaya (27,6 % bilingües, 17,8 % bilingües pasivos, 52 % castellanoparlantes monolingües) y Álava (19,2 % vascoparlantes bilingües, 18,4 % bilingües pasivos y 62,4 % castellanoparlantes monolingües). Los datos muestran una tendencia de aumento del número de vascoparlantes bilingües y bilingües pasivos y un descenso de monolingües castellanoparlantes en los tres territorios, especialmente en Álava (pasando del 7 % de vascoparlantes bilingües en 1991 a 19,2 % en 2016). Este incremento se debe al número de vascoparlantes entre la población joven (71,4 % entre 16 y 25 años). 

En el enclave de Treviño, según el estudio sociolingüístico realizado en 2012, el 22 % de la población del enclave es bilingüe, y el 17 % es bilingüe pasiva. En el periodo 2002-2012 el porcentaje de bilingües se ha doblado. Por rangos de edad, el bilingüismo es mayor conforme la edad disminuye: entre los menores de 15 años, el 65 % domina el euskera. El principal factor en el crecimiento del euskera en este territorio ha sido el movimiento demográfico de habitantes originarios de Álava, especialmente desde Vitoria. Es también muy satisfactoria la actitud general de los habitantes de Treviño hacia el euskera, donde en torno a un 40 % de la población manifiesta tener un gran interés por la lengua.

En Valle de Villaverde, según datos de 2002, el 20,70 % de la población del municipio era bilingüe, y el 16,98 % era bilingüe pasiva. Teniendo en cuenta que en 1986 solamente el 3,4 % sabía euskera, es de suponer que en la actualidad el porcentaje de bilingües haya aumentado. La razón principal del incremento es la desaparición de la enseñanza en el enclave debido a la falta de alumnado, ya que la mayoría de familias optan por escolarizar a sus hijos en Trucios, donde se imparte enseñanza bilingüe.

En el caso de Navarra, este último estudio sociolingüístico realizado en 2016 indicó que para el conjunto de la población de Navarra el porcentaje de vascoparlantes activos en mayores de 16 años era del 12,9 % (69 000), además de un 10,3 % (55 000) de bilingües pasivos, frente a un 76,8 % de navarros que eran exclusivamente castellanoparlantes. Los datos muestran una tendencia de aumentos de vascoparlantes activos (3,4 puntos más que en 1991) y especialmente de bilingües pasivos (5,7 puntos más que en 1991) y un descenso de monolingües castellanoparlantes (9,1 puntos menos que en 1991). Esta tendencia también se debe al número de vascoparlantes entre la población joven (25,8 % entre 16 y 25 años, frente al 10 % en 1991). 
El conocimiento del euskera en Navarra presenta realidades muy distintas en función de las zonas que estableció la Ley Foral del Vascuence en 1986. Así, en la zona de predominio lingüístico vascoparlante de Navarra hay un 61,1 % de vascohablantes activos, mientras que en la Zona Mixta es del 11,3 % y en la "Zona no vascófona" del 2,7 %. Los datos de la VI Encuesta Sociolingüística referidos a Navarra se concretarán más a mediados de este año. 

En el País Vasco francés, según datos de 2016 el 28,4 % de la población es vascoparlante y el 16,4 % vascoparlante pasivo. La tendencia ha sido de descenso en el número de hablantes debido a un mayor número de hablantes entre la población mayor, si bien se trata de un descenso ralentizado debido a cierto aumento de conocimiento entre la población joven.

Fuera de Europa, existen algunas comunidades vascohablantes en el continente americano, en las cuales se pueden encontrar vascos de segunda y tercera generación que siguen hablando la lengua en el dialecto original, e incluso híbridos de los dialectos tradicionales, resultado del encuentro de vascos de diferentes regiones. Muy llamativa es, por ejemplo, la existencia de una comunidad de origen vasco en el estado estadounidense de Idaho que ha logrado mantener vivo el idioma. De hecho existen muchas teorías no contrastadas acerca del uso del euskera por parte del ejército estadounidense durante la Segunda Guerra Mundial para impedir que sus comunicaciones internas pudieran ser interceptadas por las Potencias del Eje.

En 2009 fue mencionado en el libro rojo de la Unesco sobre lenguas en peligro como un lenguaje vulnerable.

El estatus detentado por el euskera en los territorios en los que es hablado es diverso.

Tanto España como Francia fueron signatarios en 1992 de la Carta Europea de las Lenguas Minoritarias o Regionales promovida por el Consejo de Europa. No obstante, solo España procedería a ratificar la carta por instrumento depositado en 2001 mediante el que se declara que la efectividad plena de la aplicación de los compromisos, obligaciones y garantías que se derivan de la Carta alcanzará a todas aquellas lenguas españolas declaradas cooficiales por las distintas comunidades autónomas; lo que en el caso del euskera supone su aplicación al territorio del País Vasco, por un lado, y a la zona vascófona de Navarra, por otro.

En el caso de España, la vigente Constitución de 1978 declara en el artículo 3 que el castellano es la «lengua española oficial del Estado», y que «las demás lenguas españolas serán también oficiales en las respectivas Comunidades Autónomas de acuerdo con sus Estatutos».

Así, en el País Vasco, su Estatuto de Autonomía de 1979 establece que tanto el euskera como el castellano son lenguas oficiales en todo su territorio, independientemente de la existencia de áreas tradicionalmente vascoparlantes y áreas tradicionalmente castellanoparlantes en el territorio de la comunidad autónoma. Tal declaración sería desarrollada posteriormente por la "Ley 10/1982 Básica de Normalización del uso del Euskera" que regula el régimen de oficialidad de las dos lenguas en las esferas administrativa, educativa y social, disponiendo la obligatoriedad de la enseñanza del euskera, bien como asignatura, bien como lengua vehicular.
En el caso de Navarra, el Amejoramiento del Fuero otorga al castellano el carácter de lengua oficial de Navarra y también al euskera, pero en este caso solo para las zonas vascoparlantes de la comunidad foral; disponiéndose que una ley foral sería la que delimitase de manera concreta la extensión de esa área vascoparlante en la que el euskera sería cooficial. Así, en 1986 se aprobó la Ley Foral del Vascuence que efectuó dicha delimitación de acuerdo al concepto legal de predominio lingüístico, determinando que las «zonas vascoparlantes de Navarra» a las que alude el Amejoramiento del Fuero serían las incluidas en la denominada «Zona Vascófona», área esta en la que tanto el euskera como el castellano serían lenguas cooficiales, mientras que en las zonas castellanoparlantes de Navarra (las denominadas «Zona Mixta» y «Zona No Vascófona») la única lengua oficial sería el castellano.

Para la Zona Vascófona se estableció la obligatoriedad de la enseñanza del euskera en el sistema educativo (bien como asignatura o bien como lengua vehicular), así como la regulación del uso oficial y normal de ambas lenguas. Además, la ley foral estableció que dentro de las zonas castellanoparlantes de Navarra se reconocería para una de ellas, la Zona Mixta, una regulación especial consistente en el derecho de los ciudadanos a recibir la enseñanza en euskera o del euskera de acuerdo con la demanda, así como la facultad de que los ciudadanos de esta zona pudieran «dirigirse» (aunque no relacionarse con la administración o recibir los servicios públicos en esa lengua, como sí se establece para la Zona Vascófona) a las administraciones públicas en euskera sin que la administración pudiese requerir a los ciudadanos la traducción de su escrito al castellano; dándose el hecho de que a causa de la concentración macrocefálica de la población navarra en el área metropolitana de Pamplona y el fenómeno de despoblamiento sufrido por la Montaña de acuerdo con los datos de la "Encuesta Sociolingüística de 2001" el mayor número de vascoparlantes de Navarra en términos absolutos se concentre precisamente en esta llamada "Zona Mixta".

El estatus oficial del euskera en el País Vasco francés viene determinado por la Constitución de la República Francesa, que establece que la única lengua oficial de Francia es el francés, por lo que el resto de lenguas habladas en territorio galo, como el euskera, no tienen carácter de lengua oficial, ni están incorporadas al sistema educativo. En 2001, un acuerdo entre el Gobierno nacional francés, la región de Aquitania, el departamento de Pirineos Atlánticos y un comité de cargos públicos electos del País Vasco francés permitió la creación de la Oficina Pública del Idioma Vasco ("Office Public de la Langue Basque" en francés) como entidad oficialmente reconocida para accionar una política en favor de la lengua y cultura vascas, y a la que se le atribuye la facultad de expedir los certificados acreditativos de aptitud en el idioma.

El euskera es una lengua de tipología aglutinante y genéticamente aislada, es decir, no muestra un origen común claro con otras lenguas, lo que ha llevado a diversas y múltiples teorías sobre el origen de esta lengua.

Aunque hay muchas hipótesis sobre el origen y parentescos del euskera, todas ellas carecen de fundamentos sólidos. La única probada es la que lo relaciona con el antiguo aquitano, euskera arcaico o vasquitano del cual sólo se conservan unas 400 breves inscripciones fúnebres dispersas por la actual Aquitania, Aragón, norte de Soria, La Rioja, Navarra y el País Vasco. Es por ello que el único parentesco que se considera demostrado es el del euskera con el antiguo idioma aquitano, ya desde los trabajos de Luchaire en 1877, ampliados posteriormente por Mitxelena y Gorrochategui. De hecho, los especialistas en historia del euskera consideran que el aquitano es simplemente vasco antiguo.

Tres son las teorías historiográficas principales sobre el parentesco:





Al margen de los estudios puramente lingüísticos, desde la antropología y la historiografía se ha intentado dar respuestas al origen del euskera a partir de los datos obtenidos en la investigación del origen de los vascos, siendo también tres las propuestas más conocidas en este aspecto:



Con independencia de las teorías sobre su parentesco lingüístico, la onomástica y la toponimia histórica atestiguan que la versión primitiva del euskera ocupó durante la Edad Antigua un área de extensión mayor que la que tendría posteriormente al producirse la caída del Imperio romano de Occidente, y que las sucesivas llegadas de pueblos de lengua indoeuropea desde el fin de la Edad del Bronce y el comienzo de la Edad del Hierro, supusieron para el euskera como para el resto de lenguas paleohispánicas una disminución de su área de extensión geográfica.

Es habitual la consideración de que los vascones (pueblo prerromano que las fuentes clásicas sitúan en el territorio del norte y centro de la actual Navarra, además de en las Cinco Villas aragonesas y en la desembocadura del río Bidasoa) eran de habla eúskara, así como también los aquitanos (establecidos según las fuentes romanas en el extremo suroccidental de la actual región de Aquitania); resulta polémica sin embargo la filiación lingüística que presentaban el resto de pueblos prerromanos que las fuentes clásicas sitúan en áreas limítrofes con los vascones (los iberos iacetanos y las tribus celtas de várdulos, caristios, autrigones y berones).

Con la Conquista de Hispania y la infiltración romana en el territorio de los vascones, se ha presumido que el euskera recibiría una intensa influencia de la lengua latina, contextualizándose precisamente en esta época la primera gran adopción por el euskera de palabras de raigambre latina.

Tras la caída del Imperio romano de Occidente y la conformación dos siglos después del núcleo del primitivo Reino de Pamplona el euskera viviría un periodo de expansión en el contexto de las repoblaciones que trajo consigo la Reconquista como atestiguan fuentes documentales como la "fazaña de Ojacastro".

A partir de la Baja Edad Media, en cambio, el euskera iniciaría un periodo de lenta regresión desplazado en un primer momento por el gascón y el navarro-aragonés, y en un segundo, por el castellano y el francés.

Pese a este declive, a comienzos de la Edad Moderna el euskera era todavía la lengua ampliamente predominante entre la población de Guipúzcoa, la mitad septentrional de Navarra, la práctica totalidad de Vizcaya y la mitad norte de Álava; una situación que se mantendría sin cambios sustanciales hasta los procesos sociales, económicos políticos y culturales puestos en marcha con la industrialización y el liberalismo siglo XIX que ocasionarían el gran retroceso del euskera que llevaría ya en el siglo XX a la creación de la Sociedad de Estudios Vascos y la Real Academia de la Lengua Vasca y al incremento de iniciativas en favor del euskera que conjurasen el riesgo de su desparición.

Siendo patente que una de las causas que facilitaban el retroceso acelerado del euskera en los territorios en los que todavía se hablaba era el alto grado de fragmentación dialectal que el vascuence presentaba, en los primeros años del siglo XX se fue extendiendo el convencimiento de que el euskera sólo podría tener futuro como lengua de comunicación y expresión, en tanto que se lograra superar la situación de fragmentación con la creación de un registro escrito único reconocido por todo el ámbito vascohablante. De esta manera, el proceso para la unificación literaria sería iniciado ya en 1918 con la fundación de la Real Academia de la Lengua Vasca ("Euskaltzaindia") y la presentación de distintas propuestas. Entre ellas, una corriente de opinión apostaba por utilizar como base el "labortano clásico" de Axular de acuerdo con la misma función que tuvo el toscano en la unificación de la lengua italiana, siendo Federico Krutwig el principal defensor de este modelo y seguido por personas como Gabriel Aresti y Luis Villasante. Aunque en sus inicios ganó apoyos, finalmente la propuesta acabó siendo rechazada por la mayoría de los escritores y estudiosos por encontrarse demasiado alejada de la base sociológica de la lengua. El debate sobre la unificación culminaría en 1968, en la reunión del Santuario de Aránzazu ("Arantzazuko Batzarra") en la que la Real Academia de la Lengua Vasca durante la celebración de su 50 aniversario decidió apoyar y promover formalmente el informe de las Decisiones del Congreso de Bayona ("Baionako Biltzarraren Erabakiak") de 1964 redactado por el Departamento Lingüístico de la Secretaría Vasca ("Euskal Idazkaritza") de Bayona, apoyado por distintos literatos éuskaros a través de la recién creada "Idazleen Alkartea" (Asociación de Escritores) y "Ermuako Zina" (Juramento de Ermua) de 1968. Los postulados de este informe fueron recogidos en la ponencia presentada por el académico Koldo Mitxelena, quien se encargaría de entonces en adelante y junto con Luis Villasante de dirigir el proceso de la unificación literaria.

El resultado sería el "euskera batua" (literalmente ‘euskera unificado’ o ‘euskera unido’), que es el soporte normativo (o registro) del euskera escrito. Se basa en los dialectos centrales del euskera como el dialecto navarro, dialecto navarro-labortano y el dialecto central del euskera, y se encuentra influido por el labortano clásico del siglo XVII, precursor de la literatura en euskera y lazo de unión entre los dialectos españoles y franceses.

Este registro, adoptado oficialmente a partir del reconocimiento de la autoridad normativa de la Real Academia de la Lengua Vasca por las instituciones de Navarra y el País Vasco, es el preferido y potenciado en la administración, la enseñanza y los medios de comunicación.

Desde los primeros años de la vigencia del batúa se ha desarrollado una importante polémica sobre el efecto que el batúa iba a tener sobre los dialectos del euskera real, hablado hasta esa fecha. Así, escritores como Oskillaso y Matías Múgica sostuvieron que el euskera batúa y el impulso institucional que llevaba a cabo iba a ser letal para los dialectos matando al 'euskera auténtico' en pos de la variante unificada, artificialmente creada. No obstante, otros escritores como Koldo Zuazo han venido sosteniendo que el batúa no es más que el registro destinado a ser utilizado en los ámbitos más formales (como la educación, la televisión pública, los boletines oficiales...) y viene a complementar al resto de los dialectos, no a sustituirlos; argumentó incluso que la extensión del batúa ayuda a reforzar los dialectos al incidir en la recuperación general de la lengua.

Se considera que los textos más antiguos de esta lengua encontrados hasta ahora son varias palabras aparecidas en epitafios del siglo II d. C. en Aquitania, investigadas por primera vez por Achille Luchaire, después por Julio Caro Baroja y Koldo Mitxelena, y en épocas más recientes por Joaquín Gorrochategui. En el municipio navarro de Lerga (Estela de Lerga) se encontró una estela funeraria hispanorromana con antropónimos indígenas, datada en el siglo I. Mitxelena definió el parentesco entre la inscripción de Lerga y la epigrafía aquitana, así como con las inscripciones hispánicas éuscaras que se encontraría posteriormente. Es por ello que hoy en día se considera que el aquitano es simplemente vasco antiguo o euskera arcaico.

La información disponible sobre el euskera medieval es bastante escasa y fragmentaria. La mayor parte de la información sobre el euskera medieval proviene del estudio de la toponimia y la antroponimia, además de algunas pocas palabras (como términos jurídicos del Fuero General de Navarra) y algunas frases cortas. El latín y los romances fueron las lenguas del saber, de las minorías cultas y de la administración oficial, tanto civil como eclesiástica. Pero aquellos grupos también debían de conocer la lengua de los collazos y siervos. Los escribanos utilizaban el romance para escribir, aunque la lengua de uso cotidiano fuera el euskera. Del siglo XI se cree que son las glosas halladas en el monasterio de San Millán de la Cogolla, en La Rioja, pequeñas anotaciones de traducción en un texto latino, las llamadas Glosas Emilianenses, escritas en latín y romance salvo la 31 y 42 que son frases en algún dialecto desconocido del euskera. Estas glosas son las siguientes:

No hay total acuerdo sobre el significado de esas dos glosas. Nótese que la placa conmemorativa situada en el monasterio comete el pequeño error de reproducir el texto con una grafía modernizada, utilizando la letra zeta, cuando en el texto original se observa claramente la ce cedilla. En los primeros siglos del segundo milenio de nuestra era, las referencias al uso del euskera en el área pirenaica son diversas. Así, en una escritura del siglo XI, la donación del monasterio de Ollazábal (Guipúzcoa), además de fórmulas latinas, están los detalles ofrecidos de los linderos del terreno en euskera. También se encuentran huellas de esta lengua en una guía para peregrinos de Santiago de Compostela del siglo XII y atribuida a Aimeric Picaud, que incluye un pequeño vocabulario en euskera. Así mismo en 1349, en la ciudad de Huesca se promulga un decreto que sanciona a los que hablaran en el mercado en árabe, hebreo o "basquenç" con 30 soles de multa.

A medida que avanza la Edad Media la información es más abundante, aunque no llegamos a tener textos extensos hasta los siglos XV y XVI. El fragmento original más extenso en lengua vasca se contiene en una carta bilingüe intercambiada en 1416 entre el secretario del rey navarro Carlos III y el jefe del tesoro del reino, la llamada "carta bilingüe de Matxin de Zalba". Son de gran interés los fragmentos de romances y cantares que citan las crónicas históricas, como el Cantar fúnebre de Milia de Lastur que recoge en sus "Memorias" Esteban de Garibay en 1596. "Refranes y sentencias" publicado por la misma época en Pamplona es un recopilatorio de refranes populares, probablemente del entorno de Bilbao, según Joseba Lakarra. Cartas personales y otros textos manuscritos o actas de testigos en juicios se consideran de un valor preciadísimo, como raros testimonios del euskera hablado en aquellos siglos. Entre la correspondencia personal destaca la de fray Juan de Zumárraga, primer obispo de México, que en 1537 escribió a su familia una carta redactada en dialecto vizcaíno y en castellano. Por su importancia, esta carta ha sido publicada por la revista "Euskera", órgano oficial de la Real Academia de la Lengua Vasca. Es probablemente el texto vasco en prosa más largo conocido anterior a los primeros libros en euskera.

El primer libro conocido se imprimió en 1545, con el título "Linguae Vasconum Primitiae" (‘Primicias de la lengua de los vascos’) y firmado por el sacerdote bajonavarro Bernat Dechepare. Es una colección de poemas de tema erótico, autobiográfico y religioso. Dedica también versos al euskera, y es de reseñar que el autor es consciente de que el suyo es el primer intento de llevar su lengua a la imprenta. En su poema "Kontrapas" dice lo siguiente:

Entre 1564 y 1567 Juan Pérez de Lazarraga escribe su manuscrito, recientemente descubierto y compuesto por 106 páginas. En él podemos encontrar poesías y novela pastoril renacentista.

La siguiente obra conocida es la traducción del Nuevo Testamento "(Iesu Christ Gure Iaunaren Testamentu Berria"), encargada por la reina de Navarra Juana de Albret al ministro calvinista Joanes Leizarraga, impresa en 1571 en La Rochelle.

La Contrarreforma trajo consigo una nueva «política lingüística» por parte de la Iglesia católica. Así pues, se tradujeron catecismos y otras obras de la literatura cristiana, destinados a la formación de los fieles. En el siglo XVII en el País Vasco francés hay un grupo de escritores, hoy día llamado «la escuela de Sara», que basándose en el habla de la costa de Labort (zona de gran importancia económica) desarrollará un modelo literario para la lengua vasca. El mayor exponente de estos escritores es Pedro Axular.

En el País Vasco español a partir del siglo XVII también aparecerán libros impresos en euskera, consagrando el uso literario de los dialectos vizcaíno y guipuzcoano primero, y del resto con el devenir de los siglos. Es preciso reconocer que inicialmente, en el siglo XVIII, esta labor literaria se limitó a traducciones mediocres de textos religiosos, aunque Agustín Kardaberaz destacara por la calidad de su obra religiosa y retórica.

Dejando a un lado estos antecedentes, junto con otros manuscritos encontrados en el siglo XX, el que podría considerarse el primer clásico de la literatura en euskera fue la obra ascética "Gero" (‘Después’) del también sacerdote Pedro de Agerre Azpilikueta, escrita en «labortano clásico» e impresa por primera vez el año 1643 en Pau. Su prosa fue tomada como ejemplo del buen escribir entre los escritores tanto al norte como al sur del Pirineo. Manuel de Larramendi se refiere a Axular como maestro.

Hasta muy tardíamente los escritores laicos fueron una excepción y la mayoría de las obras publicadas fueron de temática religiosa, limitándose principalmente a traducciones de doctrinas y catecismos, biografías de santos y algunos tratados teológico-filosóficos. Entre las obras que tratan temas profanos encontramos gramáticas, apologías (que pretendían demostrar la pureza y perfección de la lengua de los vascos, aunque casi todas fueron escritas en castellano), antologías de refranes y poemas, además de obras del teatro tradicional vasco o pastorales.

En el siglo XVIII, uno de los grandes dinamizadores culturales y políticos de Vasconia fue el padre jesuita Manuel Larramendi (1690-1766), quien fue autor de una gramática y un diccionario vascongado. Su influencia marcó un antes y un después en la literatura vasca. Se ocupaba de corregir los manuscritos de muchos escritores de su época antes de imprimirlos, y puede considerársele uno de los líderes o referentes en su tiempo.

En la segunda mitad del siglo XIX, la derrota en las Guerras Carlistas y los cambios que se estaban dando en la sociedad originaron cierta preocupación sobre el futuro de la lengua, lo cual motivó la fundación de asociaciones como la Sociedad Euskara de Navarra, la celebración de certámenes literarios y juegos florales y la aparición de las primeras publicaciones en euskera. La lingüística europea comenzó a interesarse por ella y empezó a estudiarse la lengua de manera científica. Floreció la literatura y los folcloristas y musicólogos se interesaron por recuperar la tradición oral. En 1918 se fundó la Sociedad de Estudios Vascos-Eusko Ikaskuntza con el patrocinio de las cuatro diputaciones vasconavarras y un año después, la Real Academia de la Lengua Vasca ("Euskaltzaindia") fue fundada por Alfonso XIII.

Por el contrario, algunos intelectuales vascos de la época como Miguel de Unamuno llamaban a aceptar con dolor y resignación la muerte del euskera, lengua con la que —según él— no podían transmitirse ideas abstractas. El filósofo llegaba a afirmar en momentos de íntimo pesimismo depresivo que los vascos debían abandonar su lengua y tradiciones para así poder entrar en la modernidad española.

Siendo esta postura, con algunas excepciones, la mayoritaria entre la izquierda y el liberalismo vascos de aquel momento, tanto en España como en Francia, los mayores defensores de la lengua fueron los sectores foralistas, tradicionalistas y nacionalistas.

Entre 1848 y 1936, se produjo el llamado "euskal pizkundea" o renacimiento vasco, cuando se encuentra la poesía cultista de autores como Nicolás Ormaetxea "Orixe", Xabier Lizardi o Esteban Urkiaga "Lauaxeta", impregnada del estilo de los poetas simbolistas. Sin embargo, la guerra civil y su desenlace pospusieron esa etapa de maduración literaria y social.

La identificación del euskera con la vida rural y por lo tanto con una idealizada Arcadia vasca, tan atractiva para muchos vascos, tuvo que durar hasta el relevo generacional de los años cincuenta y sesenta. Es entonces cuando en un ambiente de efervescencia cultural y política, el euskera empezó a oírse en boca de los jóvenes universitarios y ambientes urbanos.

El euskera aún era hablado por la mayoría de los habitantes de la zona vascoparlante (Vizcaya salvo su extremo occidental, Guipúzcoa, puntos del norte de Álava, norte de Navarra y el País vasco francés salvo el área de Biarritz-Anglet-Bayona) inmediatamente antes de la industrialización. Según los datos de 1866-1868 que maneja Ladislao de Velasco, lo hablaban 170 000 de los 176 000 habitantes de Guipúzcoa (140 000 de manera habitual), 149 000 de los 183 000 vizcaínos (de los que 6000 eran extranjeros y 28 000 vivían en el distrito de Valmaseda-Encartaciones, donde el euskera desapareció de su parte oriental a finales del siglo XVIII y principios del XIX, con el final de la Primera Guerra Carlista), 12 000 de los 120 000 alaveses, 60 000 de los 300 000 habitantes de la Navarra española y 80 000 de los 124 000 habitantes del País Vasco francés.

Tipológicamente el euskera es una lengua fuertemente aglutinante. En cuanto a la clasificación genética, actualmente se considera que el euskera es una lengua aislada, ya que carece de lenguas emparentadas. Sería sucesora directa del euskera arcaico o histórico de los siglos I a III d. C.

El euskera, por su situación geográfica, adoptó el alfabeto latino cuando comenzó a desarrollarse como lengua escrita en el siglo XVI. Generalmente se escribía según los sistemas del castellano y del francés, adaptándolas con mayor o menor éxito a la fonética vasca. El líder nacionalista Sabino Arana diseñó un particular sistema ortográfico, logrando cierto éxito entre sus seguidores. Tras la guerra civil española, el sistema aranista fue abandonándose porque las consonantes tildadas que precisaba encarecían las ediciones y resultaban muy poco prácticas.

La Academia de la Lengua Vasca fue estableciendo a partir de 1968 una normativa unificada. Actualmente el alfabeto vasco está compuesto de las siguientes letras:

En total 27 letras, las mismas que en castellano ("ü, ç, é" no se consideran letras separadas).

Asimismo, tiene los siguientes dígrafos: "dd, rr, tt, tx" (pronunciada como la «che» en español), "ts" (pronunciada como una "che" suave), "tz" (pronunciada como la «zz» italiana en «pizza»).

En el caso de algunas consonantes precedidas de la "i", cambian su sonido después de pronunciar la «i»: "il" (la "l" se pronuncia como la «ll» en España; ej.: "ilea" se pronuncia "illea"), "in" (la "n" se pronuncia como la «ñ» en español; ej.: "ikurrina" se pronuncia "ikurriña"), "is" (la "s" se pronuncia como la «x» del euskera), "its" (la "ts" se pronuncia como la «tx» en euskera).

En las variedades más orientales, en algunas palabras existe la posibilidad de aspiración después de consonante, lo que ha solido reflejarse en la literatura de estos dialectos. Ejemplos: "aphez, ithurri, kherestu, orho, alha, unhatu."

No existen las tildes o acentos ortográficos más que en préstamos y modismos de otras lenguas, ya que el acento en euskera no tiene valor fonológico, como sí ocurre en el castellano. Normalmente la sílaba fuerte en la entonación es la segunda empezando por la izquierda.



Las cinco letras c," q," v," w e y, de uso muy poco frecuente, se llaman "ze, ku, uve, uve bikoitza" e "i grekoa"; la letra modificada ç" es denominada "ze hautsia" o "zedila".

En suletino, hay vocales nasales ("õ, û") y sibilantes sonoras ("ss, zz"), pero nunca se reflejan en la escritura.

Consonantes
Vocales (euskera general)

El suletino además además incluye la vocal anterior labializada /y/ usualmente escrita como "ü".


En euskera, el acento no se representa ortográficamente pero sí que existen sílabas átonas y tónicas y es muy diferente a las lenguas románicas. La unidad de acentuación no tiene por qué estar en una palabra como sucede en castellano sino en el sintagma. Es decir, la sílaba tónica puede desplazarse dentro de una misma palabra dependiendo de lo que le acompañe.

Normalmente, en euskera, se tiende a acentuar la segunda sílaba y la última, si bien el acento de la última sílaba no se marca tanto como el de la segunda.

La morfología del euskera es muy rica en la estructura del sintagma nominal y verbal.

La forma de construir los grupos nominales y verbales es compleja, debido a la declinación, a la ergatividad (caso "nork") y a la gran cantidad de información que el verbo contiene, no solo sobre el sujeto, sino también sobre el objeto directo e indirecto. Además, en la forma de tratamiento familiar ("hika"), el verbo varía sus desinencias según el sexo de la persona a la que se habla, en la segunda persona del singular del alocutivo.

Los sintagmas nominales: la declinación

El euskera dispone de dos medios para reflejar la relación entre los sintagmas de la oración: la declinación y las posposiciones.

La declinación es el conjunto de marcas del sintagma nominal para expresar la función sintáctica que desempeña, es decir, los casos gramaticales (sujeto, complemento directo e indirecto), casos de lugar-tiempo (complementos circunstanciales) y otros complementos.

Las principales características de la declinación vasca son:

Ejemplo: dativo singular (caso "nori"), "-ari": "gizon-ari, anaia-ari, beltz-ari, katu-ari" (al hombre, al hermano, al negro, al gato). Si termina en -a: "osaba+ari" = "osaba-ri" (al tío).
Ejemplo: dativo singular: "-ari" / dativo plural: "-ei" / dativo indefinido: "-(r) i": Gizonari eman dio / Gizonei eman die / Zein gizoni eman dio? (Lo ha dado al hombre / Lo ha dado a los hombres / ¿A qué hombre(s) se lo ha dado?

Sin embargo, cuando el sintagma nominal tiene función de objeto directo, pero se encuentra en una frase interrogativa o negativa con un valor no determinado, el caso que se utiliza es el partitivo y la marca que se añade es "-(r) ik": "Ez daukat dirurik" (No tengo dinero).

Ergativo: es el caso donde el sintagma nominal cumple la función de sujeto de un verbo transitivo y la marca que se añade es "-(e) k". "Mendiek gero eta zuhaitz gutxiago dituzte" (Los montes cada vez tienen menos árboles).
Dativo: en este caso, el sintagma nominal adopta la función de objeto indirecto en aquellas oraciones con tres elementos "nor-nori-nork", o de dos elementos "nor-nori". La marca que se añade es "-(r) i", por ejemplo, "Umeari esan diot" (Se lo he dicho al niño).
Los casos de lugar: Los casos de lugar varían si se añaden a un nombre animado o a uno inanimado. "Ama-rengana joan naiz" (He ido donde la madre)/ "Etxe-ra joan naiz" (He ido a casa).
Otras declinaciones: son las correspondientes a los siguientes casos: instrumental (acerca de qué/quién; mediante qué/quién), sociativo (con qué/quién), genitivo (de quién), motivativo (a causa de qué/quién), destinativo (para quién) y prolativo ([tomado] por qué/quién). Las declinaciones empezadas por "nor" se refieren a seres vivos (a excepción de plantas); las empezadas por "zer", a objetos inanimados y a plantas.

En euskera los determinantes pueden ir incluidos en la palabra:

O también pueden ir fuera de la palabra:


Los cardinales son éstos:

1-bat, 2-bi, 3-hiru, 4-lau, 5-bost, 6-sei, 7-zazpi, 8-zortzi, 9-bederatzi, 10-hamar, 11-hamaika, 12-hamabi (diez dos), 13-hamahiru (diez tres), 14-hamalau (diez cuatro)... 18-hamazortzi o hemezortzi, 19-hemeretzi, 20-hogei, 21-hogeita bat (veinte y uno), 22-hogeita bi (veinte y dos)... 30-hogeita hamar (veinte y diez), 31-hogeita hamaika (veinte y once), 32-hogeita hamabi (veinte y diez dos), 33-hogeita hamahiru (veinte y diez tres)... 40-berrogei (doble veinte), 41-berrogeita bat (doble veinte y uno)... 50-berrogeita hamar (doble veinte y diez), 51-berrogeita hamaika (doble veinte y once), 52-berrogeita hamabi (doble veinte y diez dos)... 60-hirurogei (tres veintes), 61-hirurogeita bat (tres veintes y uno)... 70-hirurogeita hamar (tres veintes y diez), 71-hirurogeita hamaika (tres veintes y once)... 80-laurogei (cuatro veintes), 81-laurogeita bat (cuatro veintes y uno)... 90-laurogeita hamar (cuatro veintes y diez), 99-laurogeita hemeretzi (cuatro veintes y diez nueve), 100-ehun, 200-berrehun, 300-hirurehun, 400-laurehun, 500-bostehun, 600-seiehun, 700-zazpiehun, 1000-mila, 1001-mila eta bat... 1 000 000-milioi

Ordinales:

1.-lehen/aurren, 2.-bigarren, 3.-hirugarren... n-garren.

Distributivos:

1-bana (uno para cada uno), 2-bina (dos para cada uno)... 10-hamarna... n-na.

En Euskera el número ‘20’ "hogei" es un grupo numérico importante, aparentemente relacionado al número de dedos en ambas manos y pies, ya que aparece como base complementaria en la construcción de los números superiores. Comparando con otras lenguas, la construcción de números superiores en base ‘20’ es menos común que en base ‘10’, sin embargo no es inexistente ya que aparece también en otros sistemas numerales. Para los números superiores en Euskera tenemos: ‘40’ "berr-hogei ("2x20), ‘60’ "hirur-hogei ("3x20), y ‘80’ "laur-hogei ("4x20). 

Ergativo

Además del léxico patrimonial heredado del protoeuskera existen formas léxicas que son préstamos de otras lenguas, procedentes de:

En 1729, el jesuita Manuel de Larramendi publicó en Salamanca una gramática del euskera, a la que titula "El Imposible Vencido. El arte de la lengua bascongada", donde hablaba de los diversos dialectos: cita al guipuzcoano, al vizcaíno y al navarro o labortano ("que comúnmente es uno mismo", dice).
Una clasificación posterior de los dialectos fue obra del vascófilo Louis-Lucien Bonaparte, sobrino de Napoleón Bonaparte. El mapa fue revisado por el sacerdote y primer presidente de la Academia de la Lengua Vasca, Resurrección María de Azkue (1864-1951).

En 1998, el lingüista Koldo Zuazo realizó una renovación de la distribución de los dialectos, basándose en criterios desconocidos o ignorados por los anteriores autores. Esta clasificación moderna divide al euskera en seis dialectos (en euskera llamados "euskalkiak"): dialecto occidental; dialecto central; navarro, navarro oriental, navarro-labortano y suletino. Bonaparte consideraba el dialecto roncalés un subdialecto del suletino ("suletino español"), mientras que Azkue lo clasificó como dialecto diferenciado. Esta variante hablada antiguamente en los siete pueblos del valle de Roncal (Navarra), desapareció definitivamente en 1991 con la muerte de Fidela Bernat, su última hablante. Se podría hablar también de un dialecto alavés, hoy día extinto, aunque por la toponimia y los testimonios escritos que se conocen sabemos que era muy parecido al dialecto occidental. La principal fuente de información del euskera hablado en Álava es hoy día el recientemente descubierto manuscrito de Juan Pérez de Lazarraga (siglo XVI), ya que se trata del testimonio escrito más completo.

Los mapas se realizan uniendo en grupos las hablas con coincidencias generales, ya que el euskera se caracteriza por su variedad en giros y acentos. Las diferencias se pueden apreciar de una localidad a otra, e incluso de un barrio a otro. Por ejemplo, si tomamos la palabra "ogia" (el pan), a lo largo de los territorios vascohablantes encontraremos variantes de la misma palabra como "ogiya, ogiye, ogixa, ogixe, uía, uíe, uíxe, oía," etc.

Las diferencias fonológicas, morfosintácticas y léxicas entre dos dialectos geográficamente distantes pueden ser tantas como las que existen entre el catalán y el castellano. Este es el caso del vizcaíno (extremo occidental) y del suletino (extremo oriental), que se caracterizan por su lejanía respecto a los demás dialectos, y que son hablados precisamente en los dos extremos del dominio lingüístico del euskera. Aun así, para la mayoría de los vascohablantes hablar dialectos diferentes no es un obstáculo insalvable para entenderse. Por otra parte, la inteligibilidad mutua puede depender, además de la distancia geográfica, de la costumbre y el "don de lenguas" de los hablantes, además del nivel de escolarización y del consiguiente conocimiento de la propia lengua más allá del registro coloquial. Un caso ilustrativo puede ser el del vizcaíno: un vascohablante navarro, por ejemplo, puede entender sin grandes dificultades a alguien que habla una variedad occidental, gracias a que no le son extrañas las palabras que utiliza, las cuales ha podido leer en los libros y usarlas en un registro formal. Además, el vascohablante navarro puede acostumbrarse a escuchar euskera vizcaíno en los medios de difusión y hacerse entender con interlocutores vizcaínos, hablando cada uno en su respectivo dialecto, sin excesivas complicaciones. Esto, dicho está, depende de la predisposición, pronunciación, o nivel cultural de los interlocutores. Estas situaciones son habituales en lenguas que se caracterizan por su diversidad dialectal, como son los casos del alemán y el italiano.

A este respecto, el lingüista Koldo Mitxelena opina que
Muchas personas han aprendido principalmente el euskera unificado, con mayor o menor influencia del habla de su región. Aunque el euskera batúa es la versión oficial del idioma, los dialectos son muy utilizados en las radios y publicaciones locales, con el objetivo de acercarse más al lenguaje cotidiano. En los casos del dialecto occidental y del suletino, también están presentes en la enseñanza y la propia academia ha dictado normas sobre su escritura. Ello no se contrapone al uso del euskera batúa, pues se considera que la convivencia entre los dialectos y el vasco estándar es una condición indispensable para garantizar la vitalidad de la lengua.

Por las condiciones históricas en las que la literatura vasca se ha desarrollado, la comunidad lingüística no ha dispuesto de un único modelo para el uso escrito, sino varios, que no pudiendo imponerse completamente al resto, se han ido desarrollando paralelamente desde el siglo XVI. En los manuales de historia de la literatura vasca se habla de los "dialectos literarios" guipuzcoano, vizcaíno, labortano y suletino, ya que estos son los más utilizados en la producción literaria. Tanto el guipuzcoano al sur de los Pirineos, como el labortano al norte, han sido durante siglos los más utilizados como estándar, y son variedades que ganaron cierto prestigio en sus áreas de influencia, siendo referenciales a la hora de emprender el proyecto de la unificación en los años 60.

Labortano

""Alabainan Jainkoak altean du mundua maithatu, non bere Seme bekharra eman baitu, hunen baithan sinhesten duen nihor ez dadien gal, aitzitik izan dezan bethiko bizitzea""

Suletino

""Zeren Jinkoak hain du maithatü mundia, nun eman beitü bere Seme bekhotxa, amorekatik hartan sinhesten dian gizoneratik batere eztadin gal, bena ükhen dezan bethiereko bizitzia""

Guipuzcoano

""Zergatik ain maite izan du Jaungoikoak mundua, non eman duen bere Seme Bakarra beragan fedea duan guzia galdu ez dedin, baizik izan dezan betiko bizia""

La forma "euskera" (de los dialectos guipuzcoano, vizcaíno y altonavarro) es más usada que el término "vascuence" entre los hispanohablantes vascos y es la adoptada en el "Diccionario de la lengua española" en su XXIIª edición. En cambio, en batúa se le denomina únicamente "euskara" (la más común en los dialectos centrales). También, según la región, se le llama "euskala", "eskuara", "eskuera", "eskara", "eskera", "eskoara", "euskiera", "auskera", "oskara", "uskera", "uskaa", "uska" o "üskara".







</doc>
<doc id="15285" url="https://es.wikipedia.org/wiki?curid=15285" title="Valle glaciar">
Valle glaciar

Un valle glaciar, también llamado artesa glaciar, se define como aquel valle por el que circula o ha circulado un glaciar de dimensiones importantes que ha dejado una geomorfología clara de glaciarismo.

Los valles glaciares son ríos de hielo. Se forman cuando el espesor del hielo acumulado en el circo es grande. El hielo de las capas inferiores se desplaza fuera del circo y se derrama valle abajo. Los fragmentos rocosos que contienen hielo ensanchan el valle. También excavan cubetas en las zonas de roquedo menos resistente. Estas cubetas, al fundirse el hielo, se convierten en lagos.

Los valles glaciares se caracterizan por presentar un perfil transversal en "U" o artesa, considerado este en geomorfología el rasgo principal que permite diferenciar este tipo de canales por los que se desliza o deslizó una lengua de hielo. Otras características de los valles glaciares son las huellas de abrasión y sobreexcavación provocada por la fricción del hielo y el arrastre de material, existencia de canales de aludes, fondos planos con alternancia de umbrales y cubetas, vertientes muy verticales labradas que dan lugar a una ruptura de pendiente en hombrera y a la formación de valles colgados o suspendidos.

Los antiguos glaciares dieron origen a la formación de depósitos de materiales que previamente habían sido erosionados por los hielos. Dichos materiales son muy heterogéneos y forman a menudo diversos tipos de morrenas (terminales, laterales, de retroceso, etc.) en las que suelen formar lagos de origen glaciar, como los que se encuentran en el borde de los Alpes europeos (Como, Mayor, Garda, Ginebra, Constanza, etc.) o en la Suecia central y en muchas otras partes. También la sobreexcavación puede producir condiciones apropiadas para la formación de lagos de origen glaciar. En el caso de Venezuela, la Laguna de Mucubají está represada por la morrena terminal del glaciar que bajaba en el Pleistoceno desde el Páramo de Mucuñuque. En cambio, a unos 2 km hacia el SE, la Laguna Negra está represada por un umbral o dique natural de rocas resistentes precedidas por otras más débiles, las cuales fueron eliminadas por los hielos del glaciar y vaciadas formando lo que ahora es un profundo lago.

Cuando los glaciares secundarios confluyen en el fondo del valle principal por el que se desplaza o desplazó un glaciar más importante y de mayor profundidad, se producen los valles suspendidos o valles colgados. Tal es el caso, en la Sierra de Mérida (Venezuela), del valle donde se encuentra la Cascada del Sol: este valle descendió desde el Pico Bolívar pero al llegar al valle principal, excavado más de 100 metros más abajo por la mayor cantidad de hielo, decapitó al pequeño glaciar que ahora forma el valle suspendido. Es un fenómeno muy frecuente en Argentina, Alaska, Canadá, Chile, Nueva Zelanda, en la Península Escandinava, Rusia y desde luego, en las cordilleras asiáticas y en los Alpes. En el caso de los fiordos noruegos, los valles suspendidos constituyen un gran atractivo turístico, ya que producen cascadas de gran altura que caen directamente al mar en el interior de dichos fiordos.



</doc>
<doc id="15288" url="https://es.wikipedia.org/wiki?curid=15288" title="Vuelo sin motor">
Vuelo sin motor

El vuelo sin motor (también conocido como "vuelo a vela") es un deporte aéreo que consiste en pilotar un avión sin motor, llamado normalmente planeador y también velero. Para poner el avión en vuelo se emplean diferentes métodos, llamados de "lanzamiento", siendo los más usados hoy día el remolque por torno y el remolque por avión. Normalmente sus pilotos son capaces de hacer que una vez desacoplados del método de lanzamiento, el planeador pueda ganar altura, es decir elevarse sin más ayuda que los movimientos de las masas de aire en el seno de la atmósfera, siendo estos movimientos de tres tipos normalmente:, Ladera, Onda, Térmica. 

Aunque hay numerosos precedentes de vuelo planeado, se considera a Otto Lilienthal como el padre del vuelo sin motor. Sin embargo, el verdadero comienzo de este deporte se realiza en Alemania en 1920, con el primer concurso de planeadores celebrado en la Wasserkuppe. Alemania sigue siendo hoy en día el país donde más practicantes hay y donde más innovaciones técnicas se producen.

Los planeadores se lanzaban en el comienzo del deporte, en los años 20 y 30 del siglo XX, desde lo alto de una ladera ayudados por un sistema de gomas elásticas. Los veleros se elevan actualmente remolcados por un avión o por un torno, que es un motor que enrolla un cable de cientos de metros al que se une el velero y que este puede soltar al llegar a la altura deseada o a la vertical del torno. Al llegar a la altura deseada, el velero se desengancha del cable que le une al avión o al torno y prosigue su vuelo.

Un velero es una aeronave sin motor, por lo que siempre está descendiendo. Por eso, en todas las modalidades del vuelo a vela se buscan masas de aire ascendentes, que hagan elevarse al velero porque suben más que lo que baja de manera natural la máquina. Un ejemplo: imaginemos un planeador que avanza a 100 km/h y cae un metro cada segundo (1 m/s), pero el piloto se las arregla para permanecer en una corriente ascendente de 5 m/s durante 60 segundos: habrá ganado 240 metros y habrá recorrido algo más de 1,6 km.

Las modalidades básicas de vuelo a vela son el vuelo a térmica, ladera y onda de montaña. En el vuelo a térmica, corrientes térmicas producidas por el calentamiento diferencial del suelo por el Sol se elevan en la atmósfera, de tal manera que con el planeador buscamos permanecer en su interior para subir (habitualmente, girando dentro de ellas). En el vuelo de ladera, el viento que incide de manera más o menos perpendicular a una ladera se ve forzado a subir. Si la ladera tiene la suficiente dimensión y el viento está bien orientado con la fuerza suficiente, un velero situado en posición óptima puede volar apoyado en el viento sin perder altura o incluso subiendo.

Por último, la onda de montaña es un fenómeno más complejo que se produce a sotavento de cadenas montañosas sobre las que incide un fuerte viento. Este viento origina un fenómeno ondulatorio más allá de las montañas, en el que en determinadas condiciones se puede volar y alcanzar grandes alturas.

Cada país tiene su reglamentación para obtener la licencia o permiso necesarios para pilotar planeadores. Además, existen títulos o diplomas reconocidos intenacionalmente por la Federación Aéronáutica Internacional () para determinados logros. Estos empiezan en la actualidad con el "C" de plata, que requiere haber conseguido 1) una distancia en línea recta de al menos 50 kilómetros 2) una ganancia de altura de 1000 metros y 3) una permanencia en el aire de al menos 5 horas. Los antiguos títulos A, B y C cayeron en desuso hace años cuando los planeadores fueron capaces de cada vez mayores prestaciones. Otros títulos como el C de oro y los diplomas (por ejemplo de 1000 kilómetros) están pensados para reconocer vuelos más difíciles.

Una medida simple del rendimiento de un velero es el coeficiente de planeo. Se trata de una medida de la distancia máxima que puede planear un velero en condiciones óptimas, desde una altura dada. Así, un coeficiente de planeo de 30:1 indica que el velero puede (teóricamente) planear 30 kilómetros desde una altura de 1 kilómetro (1.000 metros). En la vida real hay muchos factores que influyen en esa distancia (viento a favor o en contra, estado de la atmósfera, limpieza del avión, por citar algunos). Además, tampoco es la única característica del avión interesante de cara a considerar su rendimiento. Sin embargo, es una medida fácil de utilizar y ampliamente reconocida.

Los planeadores primitivos eran de estructura de madera recubiertos de tela. Los adelantos técnicos desde el inicio del deporte se pueden resumir en tres etapas: 1) los veleros de madera con progresivamente cada vez más alargamiento y fineza aerodinámica, dotados con perfiles aerodinámicos clásicos, que culminaron a finales de los años 30 con veleros que tenían coeficientes de planeo de aproximadamente 30:1. 2) En los años 50 se aplican y desarrollan los perfiles laminares aumentando progresivamente el rendimiento de los veleros hasta coeficientes de planeo de más de 40:1. 3) A finales de los años 60 se generaliza la construcción en materiales compuestos (fibra de vidrio y plástico, posteriormente también fibras de carbono y kevlar), que permiten obtener superficies de vuelo mucho más limpias aerodinámicamente, llegando hasta los coeficientes de planeo máximos de 60-70:1 de los veleros más avanzados de hoy.

Una medida un poco más completa es la «polar» del velero, una curva que indica, para cada velocidad con respecto al viento, la tasa a la que cae el velero, por lo que indica también cuál es el coeficiente máximo de planeo. Actualmente son apreciados los veleros con una polar bastante plana, es decir, que mantienen una baja tasa de caída para velocidades altas (200 km/h o superiores).

El interés de observar la polar de un velero viene porque dos veleros distintos pueden tener un coeficiente de planeo de 30:1 a una velocidad de 90 km/h, pero si uno de ellos tiene un coeficiente de 25:1 a 150 km/h, mientras que otro tiene un coeficiente de 20:1 a esta velocidad, preferiremos el primero, ya que nos permite desplazarnos más rápido perdiendo menos altura, lo cual es muy útil, entre otras cosas, para permanecer poco tiempo dentro de corrientes descendentes.

En el transcurso de la historia del vuelo sin motor han existido tres tipos de planeadores: 

1ºPlaneadores primarios, usados para entrenamiento, tienen un armazón central al que van unidas las alas y los dispositivos estabilizadores y de control. El piloto se sitúa en un asiento desprotegido, al frente del armazón. Estos se encuentran actualmente en desuso, salvo los circuitos de planeadores antiguos. Ejemplo : Schulgleiter SG-38

2º Los veleros que se construyen como aviones ordinarios con fuselaje y con una cabina , normalmente cerrada para una o dos personas. Están diseñados para conseguir la máxima eficiencia aerodinámica. Los de dos asientos son los que normalmente se emplean para la enseñanza del vuelo. Anteriormente se construían de madera, contrachapado y tela (alas y cola) y tubos metálicos y tela (fuselaje). De estos aún siguen muchos en vuelo. Desde hace unos 40-45 años sin embargo se construyen invariablemente a base de estructuras sintéticas, Fibra de Vidrio integrada en Resinas Epoxi. Dentro de estos han aparecido en las últimas décadas versiones con motor retráctil, bien sea los llamados "turbo" (no pueden despegar por sí solos, sólo recuperarse desde baja altura o mantenerse) o los "autolanzables" o "SL"=Self-Launching que pueden despegar por sí solos, pudiendo retraer el motor en el fuselaje, normalmente por detrás de la cabina.

3º Los planeadores de carga, están diseñados para uso militar o civil. Son naves de gran tamaño diseñadas para transportar grandes pesos. Están construidos no para remontarse, sino para ser remolcados en grupos detrás de un potente avión para incrementar la carga del aeroplano. Las grandes ventajas de este tipo de planeador son su capacidad para transportar grandes cargas y su flexibilidad para aterrizar a baja velocidad que les permite descender en espacios demasiado restringidos para los aviones comunes.Estos se emplearon en grandes cantidades, sobre todo por los aliados, en la Segunda guerra mundial. Actualmente en desuso debido al helicóptero.

En la actualidad los límites del vuelo a vela se han extendido a fronteras inimaginables hace pocos años. Un ejemplo: el alemán Klaus Ohlmann superó la barrera de los 3000 km en el año 2003 (un solo vuelo, de día, sin motor) con un vuelo de distancia libre usando tres puntos de viraje, en un Schempp-Hirth Nimbus 4DM. El vuelo se realizó partiendo de Chapelco, Argentina, y volando fundamentalmente en onda. Se considera el límite práctico de la tecnología actual.




</doc>
<doc id="15289" url="https://es.wikipedia.org/wiki?curid=15289" title="Xylopia">
Xylopia

Xylopia es un género de plantas de la familia de las annonáceas, orden Magnoliales, subclase Magnoliidae, subdivisión Magnoliophytina, división Spermatophyta.
Son arbustos o árboles con hojas cartáceas a subcoriáceas, el nervio principal plano o impreso en el haz; pecíolos canaliculados. Flores solitarias o inflorescencias de pocas flores, axilares o dispuestas en las ramas viejas; sépalos valvados, connados solamente en la base o fusionados en una cúpula; pétalos 6, valvados, subiguales, carnosos, lineares a ovados; estambres numerosos, anteras con conectivos ensanchados, discoides o alargados; carpelos pocos a numerosos, ovarios incluidos en el androceo, óvulos 2–10. Fruto un fascículo de monocarpos cortamente estipitados, cilíndricos a subglobosos o claviformes, dehiscentes por medio de una sutura opuesta a la sutura carpelar; semillas negras con arilo blanco.
El género fue descrito por Carlos Linneo y publicado en "Systema Naturae, Editio Decima" 2: 1241, 1250, 1378. 1759. La especie tipo es: "Xylopia muricata" L. 




</doc>
<doc id="15290" url="https://es.wikipedia.org/wiki?curid=15290" title="Xanthophyceae">
Xanthophyceae

Xanthophyceae, Xanthophyta o algas verde-amarillas es un pequeño grupo de algas pertenecientes al filo Heterokontophyta, fundamentalmente de aguas continentales y suelo, aunque algunas especies son marinas. Los pigmentos de los cloroplastos les dan su característico color verde-amarillento. El grupo comprende unas 600 especies, algunas de las cuales son unicelulares, pero otras se agrupan en colonias.

Algunas algas verde-amarillas se presentan en formas unicelulares, a veces flageladas, aunque tienden a agruparse en colonias de filamentos simples o ramificados, también pueden aparecer estados palmeloide. No forman colonias móviles, pero pueden aparecer gametos o zoosporas flagelados. Las células son uninucleadas, si bien existen formas cenocíticas.

Las células presentan flagelos heterocontos, el más largo es mastigonemado o pleuronemático, con mastigonemas en dos filas. La pared celular es de celulosa o de pectina, en algunos géneros está formada por piezas en forma de H que encajan unas en otras.

Los cloroplastos suelen ser discoidales y presentarse en posición parietal. Presentan DNA dispuesto en forma de anillos, El número presente de membranas en el cloroplasto es de 4 originada por una segunda endosimbiósis entre dos microorganismos Eucariontes uno heterótrofo y el otro autótrofo. Almacenan lípidos y crisolaminarina (leucosina) como nutriendo de reserva, también pueden almacenar manitol y otros polisacáridos, nunca presentan almidón. Presentan clorofilas "a" y "c", β-caroteno, xantofilas, diadinoxantina (verde amarillenta), vaucherioxantina, nunca presentan fucoxantina. Los tilacoides se agrupan de tres en tres, en "Tribonema" hay una lamela periférica ceñidora, pero puede estar ausente en otros géneros. El cloroplasto puede incluir un pirenoide. 

La reproducción es por división celular y por fragmentación. Las esporas son móviles o inmóviles y algunas zoosporas son pluriflageladas. Pueden aparecer planosporas (zoosporas) o aplanosporas. La reproducción sexual solo se conoce en algunas especies. 





Las xantofitas se dividen en dos órdenes, dependiendo principalmente de las estructuras reproductivas:



A continuación se muestran distintas estructuras de "Vaucheria".


</doc>
<doc id="15292" url="https://es.wikipedia.org/wiki?curid=15292" title="OVA">
OVA

OVA, sigla de , como su nombre lo indica, son producciones animadas destinadas para su consumo en video, donde comenzaba el auge de los reproductores Beta y posteriormente el VHS. Los OVA tienen su origen en los años 1980, donde una generación de jóvenes animadores abren sus propias casas productoras "freelance" independientes después de haber trabajado para grandes o medianas empresas productoras de animación para la televisión. Así mismo, estas producciones no estaban atadas a ningún tipo de limitaciones, llámese censura de ningún tipo, y se realizaban con tanta libertad posible para expandir el mercado a sectores maduros, equivalente a las producciones en formato de historietas impresas (manga), que también satisfacía a varios sectores en el mercado. Fuera de Japón se les ha llamado OAV por su correcta pronunciación al inglés "original animation video", sin embargo en Japón se continúa llamando OVA para no llegar a confusiones con las siglas AV de "adult video".

En los comienzos de la década de 1980, cuando los reproductores de video comenzaron a hacerse populares en Japón, la industria del anime creció hasta alcanzar proporciones descomunales, la demanda del anime, como normalmente se abrevia, era masiva, hasta el punto de que los consumidores iban a los videoclubs no para alquilar, sino para comprar las últimas novedades en animación. Lo que resultó en la creación de muchas series con el objetivo de salir directamente en video. En Japón, la demanda era tan grande que se convirtió en una necesidad del mercado. Muchas series populares e influyentes como "Bubblegum Crisis" o "Tenchi Muyō!" salieron a la venta en formato OVA. Aunque el "anime" para su venta directa en un video comenzó a aparecer a finales de los años 1970, la primera serie que indicaba claramente ser un OVA fue "Dallos" (1983), dirigida por Mamoru Oshii y distribuida por Bandai. Otras compañías se sumaron rápidamente a la iniciativa, y a mediados de la década de 1980 el mercado estaba inundado de OVA. Un OVA no se ve atado a las restricciones de un capítulo de televisión, por lo que su duración puede ser la que crean necesaria, aunque generalmente si el OVA es la continuación de una serie, se respetan los tiempos. En un promedio general de duración de un OVA se diría que oscilan entre los 45 y los 60 minutos. 

Durante el auge de este revolucionario formato para video, los jóvenes animadores "freelance" explotaron al máximo su potencial en el campo de la animación, creando producciones originales con una calidad similar a las películas animadas proyectadas en los teatros de cine, y rápidamente atrajo la atención de los consumidores amantes de la animación en Japón. Los OVA contaban historias en su mayoría, meramente originales, sin llevar el adjetivo de "adaptación" de algún manga antes publicado. Esa fue su ventaja competitiva en aquel entonces, sumando la excelsa calidad visual y frescura con la que contaban. Esto conlleva a que las grandes empresas de la animación nipona subcontrataran a estos animadores independientes para grandes proyectos televisivos y ganar mayores oportunidades y fama en el medio. Es aquí donde la animación comercial expande de igual manera sus productos animados en el vasto mercado. Muchas de estas producciones animadas de formato OVA o formato TV llamaron la atención de países extranjeros como Francia y los Estados Unidos, que rápidamente compraban las licencias para difundirlas en sus respectivas naciones. Animadores de renombre obtuvieron la oportunidad de trabajar en proyectos extranjeros en esa misma década. 

La tendencia de producir OVA fue tomada por las grandes empresas japonesas para crear especiales para video de series ya populares como la famosa serie "Dragon Ball", basada en el manga de Akira Toriyama, "Saint Seiya" de Masami Kurumada, "Ranma ½" de Rumiko Takahashi, y otras series más. Esta tendencia ha perdurado hasta hoy en día. Llevan de igual manera el título "original video animation" por ser historias propias de los estudios de sus respectivas empresas, donde cronológicamente no coinciden con el argumento original del cual se ha basado la serie misma. 

Generalmente en el fandom extranjero, los OVA se confunden con capítulos especiales para la TV, pero esto es incorrecto, ya que dichos capítulos se lanzan en VHS, DVD y actualmente en Blu-Ray de una serie ya transmitida. Salen directamente a la venta, y es posible adquirir una licencia para transmitirlo por televisión, una vez pasado cierto tiempo, como en una película transmitida en cine, y, por lo general, las OVA tienen una calidad superior a una serie realizada para ese medio. Debido a la popularidad del "anime", las OVA pueden encontrarse en cualquier tienda sobre el tema. Generalmente salen a la venta ni bien es terminada, y producir un capítulo de 20 minutos (que es lo más normal) toma varios meses (por lo general tres, dependiendo de la calidad de animación y otros factores), por eso es normal esperar varios meses antes de poder seguir la historia, aunque existen algunos casos en que se hace de manera tal que la espera sea prácticamente de un mes, dando así tiempo a que la gente disfrute de una OVA antes de adquirir otra.

Tras el deterioro de la economía japonesa, a mediados de los años 1990, la salida de OVA al mercado comenzó a escasear. El hecho de que las series se empezaran a crear de 13 episodios, en lugar del estándar de 26, facilitó su comercialización, lo que restó popularidad a las OVA. Probablemente la serie de OVA más larga de la historia sea "Legend of the Galactic Heroes", contando con 110 episodios, 52 episodios de historias secundarias y 3 películas. Por último, los OVA también se usan actualmente como un medidor del impacto que tiene entre el público, con el fin de determinar su viabilidad para que una programadora haga una serie animada con su temática. Aunque en 1999 las OVA seguían siendo utilizadas como por ejemplo en la franquicia "Digimon".

Actualmente en Japón no solo se producen OVA, sino también ONA ("original net animation") que se conciben para estrenarse dentro de Internet. Estas producciones de nueva generación pueden ser vistas por los cibernautas en páginas especializadas en video, como el popular NicoNico Douga, que para acceder al evento, hay que adquirir una cuenta premium, de pago. 


</doc>
<doc id="15295" url="https://es.wikipedia.org/wiki?curid=15295" title="Ático">
Ático

El término ático puede referirse:


</doc>
<doc id="15296" url="https://es.wikipedia.org/wiki?curid=15296" title="Sueño de movimientos oculares rápidos">
Sueño de movimientos oculares rápidos

El sueño de movimientos oculares rápidos (MOR), sueño paradójico o sueño desincronizado, también conocido por sus siglas en inglés, fase REM (por "Rapid eye movement"), es uno de los dos estadios del sueño. Es una fase única del sueño de los mamíferos, algunas aves y otros animales los cuales tienen glándula pineal; caracterizado por movimientos oculares aleatorios y rápidos, tono muscular reducido en todo el cuerpo y propensión de la persona a soñar vívidamente. Sus nombres paradójico o desincronizado se deben a sus similitudes con la vigilia, entre las que se incluyen ondas cerebrales desincronizadas rápidas y de bajo voltaje.

Las actividades químicas y eléctricas que regulan esta fase parecen originarse en el tallo cerebral y se caracterizan por una abundancia del neurotransmisor acetilcolina, combinado con una casi completa ausencia de los neurotransmisores monoamínicos histamina, serotonina y noradrenalina. La neuronas corticales y talámicas del cerebro despierto o en sueño paradójico están más despolarizadas que en el sueño profundo. 

Antes y durante el sueño MOR se presentan las ondas PGO (ponto-genículo-occipitales), originadas en diversos grupos de neuronas del tallo cerebral, son explosiones de actividad eléctrica que pueden presentarse como potenciales individuales o en grupos. Estas ondas alcanzan su mayor amplitud en el núcleo geniculado lateral, la corteza visual primaria y la corteza visual de asociación. La energía cerebral, medida en términos del metabolismo de la glucosa y el oxígeno, equivale o excede a la utilizada en la vigilia. La utilizada en el sueño NMOR es entre 11 y 40% menor.

La hipótesis de que el sueño participa en la consolidación de la memoria reciente ha sido investigada mediante cuatro paradigmas:
Estos estudios confirman convincentemente la idea de que el sueño está profundamente implicado en las funciones de la memoria en humanos y animales. Sin embargo, los datos disponibles aún son demasiado escasos para confirmar o rechazar inequívocamente la recientemente expuesta hipótesis de que la consolidación de memorias no declarativa y declarativa, respectivamente, dependan de los procesos de sueño REM y NREM.

En esta etapa se presenta el sueño más ligero; los individuos a quienes se despierta durante el sueño MOR se sienten en estado de alerta y descansados. Durante el sueño MOR son comunes las erecciones del pene o del clítoris, al margen del contenido del ensueño; la frecuencia cardíaca y la frecuencia respiratoria son irregulares, y de nuevo similares a las del resto del día, y la temperatura corporal no está bien regulada y se aproxima a la temperatura ambiente. El sueño MOR puede ocurrir en los mamíferos y también en pájaros. 

El sueño MOR es fisiológicamente tan peculiar que al resto de las otras fases del sueño se les conoce colectivamente como sueño no MOR o sueño de ondas lentas (SOL), esto último debido a las lecturas en el electroencefalograma.

Durante una noche de sueño, una persona suele presentar cuatro o cinco períodos de sueño MOR, muy cortos al principio de la noche y más largos hacia el final. Es habitual despertarse durante muy poco tiempo al final de una fase MOR (unos segundos). El tiempo total de sueño MOR por noche es de entre 90 y 120 minutos compuestos de lapsos de segundos en los adultos, alrededor de 8 horas en los recién nacidos y hasta de 15 horas en los fetos.

Fisiológicamente, ciertas neuronas del tronco cerebral, conocidas como “células del sueño MOR”, están particularmente activas durante esta fase y son probablemente responsables de su creación. Durante el sueño MOR, estas neuronas propician la liberación de enzima MAO, con lo que inhiben por completo la liberación de (catalizan la oxidación de) ciertos neurotransmisores monoamínicos (noradrenalina, serotonina e histamina). Por esta razón, las neuronas motoras no resultan estimuladas por la actividad cerebral y los músculos del cuerpo no se mueven.

El sueño MOR también se observa en otros mamíferos. Parece que la cantidad de sueño MOR por noche de cada especie está muy correlacionada con el estado de desarrollo de los recién nacidos. El ornitorrinco, cuyos recién nacidos son completamente dependientes y no están desarrollados, tienen 8 horas de sueño MOR por noche. En los delfines, cuyos recién nacidos son completamente funcionales, prácticamente no hay nada de sueño MOR.

A nivel celular :


A nivel conductual:


Según una tercera teoría, el sueño MOR de los recién nacidos ofrece la estimulación neuronal necesaria para que maduren las conexiones neuronales; de ahí que los animales que nacen maduros no lo necesitan mucho. Apoya esta teoría el hecho de que la cantidad de sueño MOR decrece con la edad.



</doc>
<doc id="15299" url="https://es.wikipedia.org/wiki?curid=15299" title="Principios generales del derecho">
Principios generales del derecho

Los principales principios generales del derecho son los enunciados normativos más generales que a pesar de no haber sido integrados formalmente en los ordenamientos jurídicos particulares, recogen de manera abstracta el contenido de un grupo de ellos. Son conceptos o proposiciones de naturaleza axiológica o técnica que informan la estructura, la forma de operación y el contenido mismo de las normas, grupos normativos, conjuntos normativos y del propio derecho como totalidad. 

Estos principios son utilizados por los jueces, los legisladores, los creadores de doctrina y por los juristas en general, sea para integrar derechos legales o para interpretar normas jurídicas cuya aplicación resulta dudosa.

Los principios generales del derecho son enunciados normativos que expresan un juicio deontológico acerca de la conducta a seguir en cierta situación o sobre otras normas del ordenamiento jurídico. Cada uno de estos principios, es un criterio que expresa un deber de conducta para los individuos, el principio o un estándar para el resto de las normas. El hacer cumplir los deberes del individuo es su prioridad.

Además, se aplica en defecto de la ley o de la costumbre.

Respecto a los principios generales del derecho se ha desarrollado una polémica acerca de si ellos son extraños o externos al derecho positivo, o si son una parte de él.

Según la posición de la escuela del derecho natural racionalista de los siglos XVII y XVIII, los principios generales, serían una estructura de principios racionales separados del derecho positivo y superiores al mismo. El iusnaturalismo clásico entiende que el derecho, natural y positivo, es razonable y, por tanto, existen principios de sensatez que dan unidad y coherencia al sistema jurídico. Lo sumamente insensato o irrazonable no es derecho para esta escuela.

Según la doctrina positivista, los principios mencionados serían una parte del derecho positivo. Sin embargo, nunca podrían imponer una obligación que no fuera sancionada por el mismo ordenamiento positivo por lo que se entiende que cada ordenamiento positivo tiene sus particulares principios generales y que no existen principios jurídicos de carácter universal.

La posición racionalista escinde el derecho en dos órdenes jurídicos específicos y distintos: el natural y el positivo –el primero conforme a la razón, es decir son normas que emanan de la naturaleza y son de carácter axiólogico, y el segundo, producto de la voluntad del sistema político. Otra posición indica que el derecho, producto típicamente humano, es una obra de la inteligencia humana: ella es la que descubre, desarrolla y combina criterios que enuncian un comportamiento entendido como justo; por ello, el derecho también es llamado jurisprudencia, es decir, de lo justo, y la prudencia se entiende como un hábito de la inteligencia. Si bien el derecho, conjunto de criterios, es obra de la inteligencia, su efectivo cumplimiento, el comportarse los hombres de acuerdo a los criterios jurídicos, es obra de la voluntad.

En todo caso, es claro que los principios del derecho son de carácter racional (no son principios ontológicos). Técnicamente, "principio del derecho es una proposición lógicamente anterior sobre un punto de derecho". Esta proposición debe preceder a un juicio, a un razonamiento: puede ser, por ejemplo, el presupuesto de un efecto jurídico o la "fattispecie" por la que se sanciona. Así, del principio "pacta sunt servanda" se desprende que el leasing firmado hoy debe cumplirse mañana, y el principio "neminen laedere" justifica que las lesiones merezcan prisión. Estos principios son los primeros argumentos de los que parte el resto del razonamiento jurídico, el presupuesto de justificación de las leyes, de los derechos subjetivos, de los deberes y de los vínculos jurídicos.

Los primeros principios se extraen de la realidad que predefine el razonamiento jurídico. Y como los razonamientos más complejos no son sino composición de ideas más simples, los principios más primordiales serán un simple juicio de valor, una afirmación de lo que vale, un "pro" (algo). Así, por ejemplo, consta el "pro homine", "pro natura", que juzgan que el hombre y la naturaleza se estiman como un valor muy elevado. De ahí se derivan el "in dubio pro…", en caso de duda sobre dos normas, sobre dos interpretaciones, sobre dos penas… se estará a la más favorable a lo que se considera valioso. Y todos los principios "pro"… también han de ensamblarse con el primer principio de la razón práctica, por el que "debe hacerse el bien y evitarse el mal": en consecuencia, habrá que hacer y proteger lo bueno para Dios, para el hombre y para la naturaleza, y evitar lo que los dañe.

Según la fórmula Riofrío, los fines, valores y bienes jurídicos fundamentan y dan contenido a los primeros principios del Derecho, y, a su vez, estos principios fundamentan las normas, contratos y todo el sistema jurídico dotándoles de una base sensatez y racionalidad.​

Cada principio tiene su propio ámbito de acción y su propia efectividad, lo cual no afecta la contribución de todos al fin común de un orden interamericano justo, democrático y estable. 

Los principios generales del derecho tienen tres funciones que tienen incidencia importante en las normas del ordenamiento, estas son: la función creativa, la función interpretativa, y la función integradora.


Algunos autores solo mencionan las tres primeras funciones, integrando otros aspectos en ellas. Otros en cambio hablan de siete, ocho o nueve funciones. En todo caso, básicamente son las mencionadas funciones.

Los principios generales del derecho internacional público sirven no solo para guiar el ordenamiento sino también para situaciones donde no esté regulado, los principios como la costumbre sirven para guiar a dos países en guerra

El Art 38 del estatuto de la corte internacional de justicia habla sobre cómo aplicar las convenciones, la costumbre, los principios generales de derecho reconocidos por las naciones civilizadas y decisiones judiciales para la interpretación de las normas.

Principios de equidad, libertad, justicia, fraternidad, igualdad, inocencia, jerarquía, entre otros.

La jurisprudencia alemana, norteamericana y de la gran mayoría de países ha incluido como principios constitucionales (que, sin embargo, no siempre están expresamente en la constitución de los países) los siguientes:
en aquello que las personas y las sociedades menores son capaces de realizar de manera adecuada.


Hace referencia al obrar con honradez, veracidad, lealtad, lo que lleva implícita la creencia de que se está actuando conforme a lo que prescribe el ordenamiento jurídico.

El principio de la buena fe es de suma importancia en materia de interpretación de la ley, de los contratos, de la posesión, de la prescripción, del matrimonio.






El artículo 38.1.c del Estatuto de la Corte Internacional de Justicia considera a los principios generales del derecho una fuente formal del derecho internacional, al lado de la costumbre internacional y los tratados internacionales, por lo cual el tribunal estaría obligado a aplicarlos sin necesidad de que exista una laguna en cuanto al alcance de estas dos últimas fuentes; es decir, opera como fuente autónoma y no subsidiaria.

El antiguo Código Civil de la Nación Argentina, redactado por Dalmacio Vélez Sarsfield, consagraba -desde 1871- en su artículo 16, el siguiente enunciado: "Si una cuestión civil no puede resolverse, ni por las palabras, ni por el espíritu de la ley, se atenderá a los principios de leyes análogas; y si aún la cuestión fuere dudosa, se resolverá por los principios generales del derecho, teniendo en consideración las circunstancias del caso".
Buena parte de la doctrina iusfilosófica nacional ha entendido a este enunciado como una manifestación de la negación de las lagunas jurídicas en el derecho argentino, mientras que otros doctrinarios lo ven como una pauta dirigida al juez en casos concretos en los cuales no haya ley que rija el caso, para que llene las lagunas del derecho con base al derecho natural.

La Constitución Política Colombiana de 1991, en su artículo 230, enseña que los principios generales del derecho son criterios auxiliares en caso de insuficiencia de la ley, es decir, en caso de oscuridad o vacíos normativos, posición antiformalista que influye en la jurisprudencia colombiana desde 1936 –época de la "Corte de Oro"– en una nueva interpretación del artículo 8 de la Ley 153 de 1887, la cual, desde un punto de vista eminentemente influido por la escuela de la libre investigación científica y el conceptualismo alemán, acogió la equidad y los demás principios generales del derecho como punta de lanza para la solución justa de los conflictos jurídicos.

Según el artículo 1.1 del Código Civil, las fuentes del ordenamiento jurídico son la ley, la costumbre y los principios generales del derecho. Y en su artículo 1.4 enuncia: "Los principios generales del derecho se aplicarán en defecto de ley o costumbre, sin perjuicio de su carácter informador del ordenamiento jurídico".

En el derecho mexicano, el artículo 14 de la Constitución política vigente señala que los juicios de orden civil deberán fallarse conforme a la letra o a la interpretación de la ley, y a falta de la misma, se fundará en los "principios generales del derecho". Este reenvío, según Rafael Preciado Hernández, vincula el derecho mexicano a la mejor tradición iusnaturalista de la civilización occidental. También en la Ley Federal del Trabajo en su artículo 17, se hace un reenvío a los principios generales del derecho y a la equidad, que es uno de ellos. De igual forma, también se establecen en el Código Civil Federal, el Código de Comercio, la Ley General de Instituciones y Procedimientos Electorales, la Ley General de Salud, la Ley General de Educación, y, en prácticamente todos los ordenamientos de carácter federal y local, sean sustantivos o adjetivos.





</doc>
<doc id="15300" url="https://es.wikipedia.org/wiki?curid=15300" title="NTFS">
NTFS

NTFS (siglas en inglés de "New Technology File System") es un sistema de archivos de Windows NT incluido en las versiones de Windows NT 3.1, Windows NT 3.5, Windows NT 3.51, Windows NT 4.0, Windows 2000, Windows XP, Windows Server 2003, Windows Server 2008, Windows Vista, Windows 7, Windows 8 y Windows 10). Está basado en el sistema de archivos HPFS de IBM/Microsoft usado en el sistema operativo OS/2, y también tiene ciertas influencias del formato de archivos HFS diseñado por Apple.

NTFS permite definir el tamaño del clúster a partir de 512 bytes (tamaño mínimo de un sector) de forma independiente al tamaño de la partición. 

Es un sistema adecuado para las particiones de gran tamaño requeridas en estaciones de trabajo de alto rendimiento y servidores. Puede manejar volúmenes de, teóricamente, hasta 2–1 clústeres. En la práctica, el máximo volumen NTFS soportado es de 2–1 clústeres (aproximadamente 16 TiB usando clústeres de 4 KiB).

Su principal inconveniente es que necesita para sí mismo una buena cantidad de espacio en disco duro, por lo que no es recomendable su uso en discos con menos de 400 MiB libres.

El tamaño mínimo recomendado para la partición es de 10 GB (10240 MB). Aunque son posibles tamaños mayores, el máximo recomendado en la práctica para cada volumen es de 2 TB (Terabytes). El tamaño máximo de fichero viene limitado por el tamaño del volumen. Tiene soporte para archivos dispersos.

Hay tres versiones de NTFS: v1.2 en NT 3.51, NT 4, v3.0 en Windows 2000 y v3.1 en Windows XP, Windows Server 2003, Windows Vista y v5.1 en Windows Server 2008. Estas versiones reciben en ocasiones las denominaciones v4.0, v5.0, v5.1, v 5.2, y v6.0 en relación con la versión de Windows en la que fueron incluidas. Las versiones más recientes han incluido algunas características nuevas, tales como cuotas de disco y puntos de montaje de volúmenes.


El número de versión NTFS.sys (por ejemplo, v5.0 en Windows 2000) no se debe confundir con el número de versión en formato NTFS (v3.1, solo Windows XP).

NTFS tiene soporte para enlaces duros a archivos regulares. Esto significa que pueden tenerse varios archivos apuntando a un solo archivo real. Sobre esta característica se apoyan los Alias, implementado para el usuario final a partir de Windows Vista.

También existe otra característica de NTFS (>3.0) llamada Junction NTFS, que permite crear enlaces simbólicos sólo a directorios (no a archivos regulares), de una forma más transparente que los accesos directos a una carpeta.

Ambas características no están documentadas para el usuario final y no se recomienda utilizarlas (sobre todo JP) a menos que el usuario sepa lo que hace.
Si el vínculo no se da en el acceso directo debes buscar si el archivo existe en el disco.

Todo lo que tiene que ver con los ficheros se almacena en forma de metadatos. Esto permitió una fácil ampliación de características durante el desarrollo de Windows NT. Un ejemplo lo hallamos en la inclusión de campos de indizado añadidos para posibilitar el funcionamiento de Active Directory.

Los nombres de archivo son almacenados en Unicode (UTF-16), y la estructura de ficheros en árboles-B, una estructura de datos compleja que acelera el acceso a los ficheros y reduce la fragmentación, que era lo más criticado del sistema FAT.

Se emplea un registro transaccional (journal) para garantizar la integridad del sistema de ficheros (pero no la de cada archivo). Los sistemas que emplean NTFS han demostrado tener una estabilidad mejorada, que resultaba un requisito ineludible considerando la naturaleza inestable de las versiones más antiguas de Windows NT.

Sin embargo, a pesar de lo descrito anteriormente, este sistema de archivos posee un funcionamiento prácticamente secreto, ya que Microsoft no ha liberado su código, como hizo con FAT.

Gracias a la ingeniería inversa, aplicada sobre el sistema de archivos, se desarrollaron controladores como el NTFS-3G que actualmente proveen a sistemas operativos GNU/Linux, Solaris, MacOS X o BSD, entre otros, de soporte completo de lectura y escritura en particiones NTFS.

Microsoft provee medios para convertir particiones FAT32 a NTFS, pero no en sentido contrario, (NTFS a FAT32). Partition Magic de Symantec y el proyecto de código abierto NTFSResize son ambos capaces de redimensionar particiones NTFS.

Con la herramienta "convert" incluida en los sistemas NT (Windows NT en adelante), se puede cambiar un disco con sistema de ficheros FAT32 a NTFS sin perder ningún dato con la instrucción "convert [unidad]:/fs:ntfs" 

Por razones históricas, absolutamente todas las versiones de Windows que todavía no soportan NTFS almacenan internamente la fecha y hora como hora local, y consecuentemente los sistemas de ficheros correspondientes a esas versiones de Windows, también tratan la hora localmente. Sin embargo, Windows NT y sus sucesores almacenan la hora en formato GMT/UTC, y hacen las conversiones apropiadas en el momento de mostrar las fechas. De este modo, al copiar archivos entre un volumen NTFS y uno no NTFS, deben hacerse las conversiones "al vuelo", lo que puede originar ambigüedades si el horario de verano está activo en la copia de unos archivos y no en el de otros, pudiendo dar lugar a ficheros cuya marca de hora esté una hora desplazada.

MacOS X provee soporte de sólo lectura a particiones formateadas como NTFS. NTFS-3G es una utilidad de licencia GPL que permite lectura y escritura en particiones NTFS. Los desarrolladores de NTFS-3G también proveen una versión comercial y de alto rendimiento denominada Tuxera NTFS para Mac.

En español:

En inglés:


</doc>
<doc id="15302" url="https://es.wikipedia.org/wiki?curid=15302" title="Sorghum halepense">
Sorghum halepense

El sorgo de Alepo (Sorghum halepense) es un cereal, producto de una hibridación de introgresión con otra especie del género "Sorghum" en la familia Poaceae.

El origen del sorgo se localiza en África central (Etiopía o Sudán), pues es en esta zona donde se encuentra la mayor diversidad varietal de la especie. Esta diversidad disminuye hacia el norte de África y Asia. Existen, sin embargo, ciertas evidencias de que surgió de forma independiente tanto en África como en la India. Es precisamente en este último país de donde datan en el siglo I d.C. las primeras referencias escritas. También se encuentran en Siria esculturas que tratan el desarrollo de dicha especie.

No se sabe exactamente cuándo se introdujo la planta por primera vez en América, aunque se asume que las semillas de esta especie llegaron al Nuevo Continente en barcos que transportaban esclavos desde África. Ingresó en Estados Unidos procedente de Turquía hacia 1830. El primer informe escrito de su presencia en México es de 1913, aunque para esa fecha había llegado hasta Yucatán y era una importante maleza en Nuevo León (Alcaraz, 1913).

El nombre científico, "Shorgum halepensis" (L.) Pers. hace referencia a la ciudad de Haleb (Aleppo) en Siria.
Recibe varios nombres comunes: cañota, millaca, hierba johnson, pasto johnson, sorguillo, canuto, pasto ruso, paja johnson, zacate johnson, pasto silvestre, sorgo silvestre, sorgo de Alepo. En Argentina se lo conoce como "maicillo".





Se considera que esta maleza es autógama pero no completa, exhibiendo un 6 a 8 % de alogamia. La dispersión de las semillas puede producirse a través de distintos agentes, como es el agua de irrigación (en los sistemas bajo riego) y también por escorrentía superficial en campos con pendiente en los sistemas de producción de secano. Los herbívoros que consumen esta maleza eliminan las semillas a través de las heces, con diferente nivel de dormición, sin pérdida de viabilidad. Probablemente las aves puedan dispersar a gran distancia esta maleza.

Las dos fuentes principales de dispersión secundaria son los granos o semillas para la siembra contaminadas con esta maleza y el equipo de cosecha: muchas semillas pueden ser transportadas largas distancias desde el sitio original en los distintos enseres del equipo de cosecha (sinfines, volquetes, carros tolvas y vehículos complementarios), los que pueden incluso alojar semillas en la banda de rodamiento de sus neumáticos.

Las semillas recién dispersadas exhiben elevada viabilidad (superior al 85 %) y un alto grado de dormición. En el suelo se suelen encontrar fracciones o subpoblaciones de semillas con diferente nivel de este efecto y diferentes requerimientos para su activación. Este complejo mecanismo evolutivo permite a las semillas no sólo detectar la existencia de canopeos, sino también medir la profundidad a la que se encuentran, lo cual está muy relacionado con sus probabilidades de éxito tras la emergencia.

Los rizomas constituyen un mecanismo de propagación muy eficaz y -desde el punto de vista evolutivo- constituyen uno de los pilares de la persistencia de esta mala hierba en una gran variedad de agroecosistemas y amplias latitudes, desde que replican genotipos resistentes y adaptados. Los rizomas constituyen, en promedio, el 30 % de la biomasa total que acumula una planta durante todo su ciclo.

Si se realiza una estimación periódica de la biomasa de rizomas durante todo el año, se obtiene una función de tipo sinusoidal, la cual exhibe valores máximos hacia el fin del verano e inicios del otoño y valores mínimos hacia el fin del invierno e inicios de la primavera. Tanto el consumo de sustrato por respiración durante el invierno, como la removilización de reservas para sustentar el crecimiento de estructuras aéreas (macollas) caracterizan el segmento decreciente de la biomasa de rizomas. Los procesos involucrados en el segmento creciente comprenden a la formación de fotoasimilados y su transporte hacia el sistema subterráneo, con una tasa de acumulación elevada. Durante la etapa de acumulación de biomasa subterránea las concentraciones de los carbohidratos aumentan.

Es importante recalcar que la fracción decreciente se reinicia toda vez que el sistema aéreo se destruye; como consecuencia de la perturbación del sistema de macollas por bajas temperaturas invernales (heladas), a causa de un control mecánico durante la primavera o el verano, por la acción de herbicidas de contacto o por una pobre actividad de un herbicida sistémico.

Aunque muestra marcada preferencia por los climas cálidos, aparece igualmente en zonas más frías. De hecho, tras ser introducida en el sur de Estados Unidos de América como forrajera y comprobarse su proceso de naturalización se pensó que sólo afectaría a las regiones de clima templado-cálido, constatándose posteriormente su capacidad para colonizar áreas mucho más frías y extenderse hacia latitudes mucho más septentrionales, llegando actualmente al límite con Canadá. En España aparece tanto en estaciones ruderales como en campos de cultivo, especialmente en los viñedos, cultivos de cítricos, arrozales, campos de remolacha y de maíz, así como en cursos de agua (acequias, canales, etc.). 

a) Temperatura: en general se sabe que el desarrollo de las plantas del pasto Johnson, tanto para el crecimiento y desarrollo de la parte aérea como para el de raíces y rizomas, es óptimo a 32 °C.

Para la formación de rizomas existe un límite mínimo de 15 a 20 °C y un límite máximo de 40 °C. Para la germinación de las yemas de los rizomas el máximo es de 39, con un óptimo de 28-30 °C y un mínimo de 15 °C. Se sabe que la temperatura máxima que soportan los rizomas es de 50 a 60 °C por espacio de 3 días, cuando se localizan a 2.5 cm de profundidad en el suelo. Su tolerancia a las bajas temperaturas aumenta con la profundidad a la que se encuentran enterrados los rizomas y bajas temperaturas edáficas limitan la expansión de la especie, mientras que la floración está regulada por la temperatura y no por los factores nutricionales.

Se necesita una temperatura sostenida de -9 °C para causar la muerte de los rizomas de esta especie, sobreviviendo al frío si se localizan a 20 cm o más de profundidad en el suelo. Respecto a la germinación de semillas, esta es nula a 10-15 °C, siendo su óptimo de 39 °C.

b) Luz: se ha podido demostrar que el sorgo tiene un desarrollo óptimo con un fotoperíodo de alrededor de 12 a 13 horas. Para un fotoperíodo de 12 horas, el crecimiento de esta gramínea es óptimo a 27 °C, pese a que en las etapas iniciales el crecimiento sea óptimo a 32 °C.

En otro estudio se encontró que mediante la interrupción del periodo oscuro de 8 h, las plantas de sorgo no florecen y su producción de rizomas disminuye grandemente, sin afectar la producción de raíces, proponiendo esta estrategia como un posible medio para evitar la diseminación de la especie.

c) Profundidad y tipo de suelo: prefiere suelos profundos, sin exceso de sales, con buen drenaje, sin capas endurecidas, de buena fertilidad y un pH que varía de ligeramente ácido a alcalino.

Existen diferencias en cuanto a la producción y distribución de los rizomas de acuerdo a la textura del suelo, en un suelo franco-arenoso, la producción de rizomas fue casi el doble que en un suelo arcilloso. En un suelo franco-arcilloso-limoso la producción de rizomas fue 10% menor que en el anterior. Además se encontró que un suelo arcilloso el 80% de los rizomas se localizan en los 7.5 cm de la superficie del suelo, contrastando con el mismo estrato en un suelo franco-arenoso, siendo la emergencia de rizomas mayor en este tipo de suelos que en un suelo arcilloso.

d) Agua: Requerimiento en el ciclo:
Es fundamental que el suelo tenga una adecuada humedad en el momento de la germinación para que se dé una emergencia rápida y homogénea. Las mayores exigencias en agua comienzan unos 30 días después de emergencia y continúan hasta el llenado de los granos, siendo las etapas más críticas las de panojamiento y floración.

Con frecuencia, en una campaña se cosechan dos o tres cortes de heno; es un pasto valioso, pero las plantas jóvenes pueden contener cantidades notables de HCN, y por lo tanto debe pastarse con prudencia.

Leyenda: MS (Materia seca), PB (Proteína bruta), Cen. (cenizas), EE (extracto etéreo), ELN (extracto libre de nitrógeno), FB (fibra bruta), Ref. (Referencia)

A pesar de ser un buen forraje, como se ha mencionado presenta el inconveniente de tener un glucósido cianogénico tóxico llamado "dhurrina" que se incrementa en condiciones de sequía, helada, alto contenido de nitrógeno y bajo contenido de fósforo en el suelo, además de ser más común en plantas jóvenes. Los casos de envenenamiento son más frecuentes en ganado vacuno y se pueden evitar mediante el ensilaje, proceso en el cual la dhurrina es inactivada. Los animales afectados por su consumo en fresco presentan dolores de abdomen. Las aves pueden consumirla sin que les produzca efectos adversos.

El sorgo de Alepo es una de las 10 malas hierbas más dañinas a la agricultura mundial, ocupando esta el sexto lugar, localizándose en áreas templadas, subtropicales y tropicales del sur de Estados Unidos, México, centro y Sudamérica, zona mediterránea de Europa, África, India y Australia.

Las plantas que cuentan con este tipo de asimilación toleran altas intensidades lumínicas, altas temperaturas, baja concentración de CO y alta concentración de O en la atmósfera sin afectar su proceso fotosintético, además de que no presentan el fenómeno de fotorrespiración por lo que son altamente competitivas.

Estos sorgos son plantas C4, debiendo en gran parte su agresividad a esta cualidad. De esta forma, algunas autores afirman que una ingesta de sorgo de Alepo en maíz reduce 2/3 partes del peso seco del grano, y 60-100 kg/ha de potasio. De la misma manera, las infecciones de esta hierba parásita en maíz reducen el crecimiento y tamaño del cultivo retardando la diferenciación de los órganos vegetativos y reproductivos, y reduce el área de las hojas y el tamaño de las mazorcas, causando esterilidad de muchas flores debido a la competencia entre ambas. El pasto de Johnson puede reducir en más del 45 % los rendimientos de caña de azúcar y soya. 

Actúa como hospedante de un díptero plaga conocido como mosquito del sorgo ("Contarinia sorghicola", "Cecidomyiidae") bastante específico del sorgo cultivado que hiberna en las semillas de la mala hierba, desde donde infecta al cultivo. Se considera también un contaminante del polen del sorgo cultivado y un hospedante del virus del mosaico de la caña de azúcar (de ahí la bajada de rendimiento). Además es hospedera alternante de otras importantes plagas y enfermedades como son: el mildiú velloso ("Aclerospora sorghi") y el antracnosis ("Colletotrichum graminicolum").

Debido a que su presencia se circunscribe a entornos agrícolas es suficiente con considerar las prácticas llevadas a cabo habitualmente en este tipo de medios. Es esencial desarrollar estrategias preventivas que contemplen el uso de semillas o mezclas de éstas (como las empleadas habitualmente en la creación de céspedes forrajeros) y de sustratos absolutamente exentos de propágulos de esta especie.

El arranque manual puede efectuarse por medio de herramientas agrícolas, tales como cultivadoras azadas, arados, rotator y etc. Este tipo de control arranca la hierba a la vez que se remueve el suelo pudiendo beneficiar al cultivo al extraer los rizomas. No obstante, el uso de control mecánico en especies de malas hierbas perennes es limitado debido a que se reproducen vegetativamente. Con el sorgo de Alepo las posibilidades de éxito con este tipo de control son muy limitadas ya que se ha demostrado que una planta proveniente de semilla o rizoma, de más de 20 días de edad, soporta 8 cortes semanales consecutivos sin morir.

En algunos terrenos se acostumbra rastrear los terrenos infestados con esta maleza para exponer sus rizomas al medio y causar su muerte por desecación o daños de heladas. Sin embargo, se ha observado que los rizomas de esta especie soportan una desecación de hasta un 75% de su peso fresco sin perder su viabilidad. Además estos órganos toleran -9 °C sin morir, por lo que este tipo de prácticas no aseguran un buen control de esta maleza y pese a que pueden ser eficientes, se requiere de una cantidad extraordinaria de mano de obra, lo cual se refleja en un mayor coste.

La inundación es una opción viable en algunas zonas. Hasta el momento no se conocen agentes de control biológicos específicos y efectivos.

El estudio de ciertos biotipos de E.E.U.U. exhibe resistencia simple y cruzada a los herbicidas graminicidas tipo ACCASE, además de ALS (imidazolinonas) y dinitroanilinas (trifluralina). 

En países donde aparece como planta parásita de otros cultivos, principalmente soja, se está convirtiendo en los últimos años en un auténtico problema por los altos niveles de resistencia que presenta a herbicidas, y concretamente, a glifosato. En la siguiente publicación argentina de alertas de malezas se puede leer lo siguiente:

El control debe asentarse en el cumplimiento oportuno y sistemático de cuatro objetivos básicos:

a) Destruir la población de yemas existentes en los rizomas.
b) Impedir la formación de nuevos rizomas.
c) Impedir la producción y/o aportes de semillas.
d) Disminuir la población de semillas en el banco, y en los productores de semillas.

Los cuatro objetivos deben enmarcarse en el programa de rotaciones o secuencias de cultivos y sus respectivos barbechos, de manera de optimizar tanto las tácticas de control como la habilidad competitiva de los cultivos. La detección y eliminación temprana de los focos de invasión y la prevención constituyen las mejores inversiones, las que bajo formas y metodologías relativamente sencillas, pueden evitar la diseminación de la maleza en todo el campo.



</doc>
<doc id="15303" url="https://es.wikipedia.org/wiki?curid=15303" title="Stipa clandestina">
Stipa clandestina

Stipa clandestina, conocida como zacate picudo, esparto o hack, es una especie de pasto de la familia "Poaceae".

Es una planta perenne, amacollada, de 30 a 80 cm de altura. Tallos con uno o tres nudos glabros o pubescentes, y entrenudos glabros. Hoja con vaina de 8 a 20 cm de largo, lisa y glabra, verde claro o verde amarillenta, más larga que los entrenudos, abiertas hasta la base con el margen hialino y festoneado al menos en la zona cercana al cuello, donde está abierta en forma de “V” y en ocasiones en pilosa; lígula formada de cerdas de 2 a 3 mm de largo, blanquecina; lámina linear de 2 a 6 dm de largo y 2 a 2,5 mm de ancho, margen revoluto, por lo que su anchura es de 1 mm y con una apariencia de alambre; suave cuando es tierna, dura y punzante cuando es madura; haz escabroso, envés liso. Inflorescencia: panícula de 15 a 35 cm de largo; péndula, sus ejes secundarios flexuosos. Espiguilla unifloscular que se desarticula por encima de las glumas, la articulación es oblicua y deja un cuello barbado en el flósculo; glumas iguales o subiguales de 4 a 7 mm de largo, bordes hialinos, color verdoso o purpúreo que permanece en la inflorescencia después de que se desprende la cariópsis; flósculo tan largo o menores que las glumas, purpúreo, piloso, con una arista de 12 a 18 mm de largo, geniculada y tortuosa. Fruto presente en forma de cariópsis dispersa y envuelta en un flósculo formado por una pálea y un lema retozas, fácilmente desprendibles del cariópse. La lema muestra una arista muy larga, retorcida y frágil, el flósculo es de color verdoso o purpúreo.

Cariópsis de contorno aovado o casi aovado, de forma clavada de 2,1 a 2,7 mm de largo y de 0, a 1,2 mm de ancho, de sección transversal casi circular, aunque en ocasiones aparece como rombo levemente irregular; cara dorsal con una costilla generalmente bifurcada levemente o ensanchada hacia la mitad inferior del fruto; la cara ventral y las laterales generalmente presentan también una costilla en su parte media, pero no está bifurcada y frecuentemente es poco conspicua. Ápice del fruto con una prolongación corta, base del fruto agudo con la cicatriz de inserción a un lado; superficie casi lisa o con verruga escasamente prominente y pequeña, color verde amarillento a amarillento parduzco, con una mancha apical purpúrea presente en ocasiones.

Tiene coleóptilo alargado rasgado, con frecuencia de 3 a 15 mm, hialino, dos nervaduras convergentes conspicuas, del mismo tamaño que la vaina de la primera hoja. Primera hoja con vaina del mismo tamaño que el coleóptilo, lígula formada por cerdas blanquecinas, lámina linear de 7 a 25 mm de largo, frecuentemente incurva cuando se seca, de 0,5 mm de largo, glabra. Segunda hoja también similar, lámina de 8 a 37 mm de largo y 0,5 a 1 mm de ancho, linear, de sección acanalada, ápice segundo, con nervaduras conspicuas. No existe una descripción de las inflorescencias y frutos basales y axilares.

Planta presente en alfalfares de tres años o más donde puede ser muy abundante y difícil de controlar. Además de ruderal y pionera se encuentra en las orillas de los canales. Esta especie se asocia con alfalfares sometidos a cortes, el paso aparece sobre los bordos de las melgas y regaderas, áreas en las cuales el corte no es tan bajo, lo que permite la formación de los macollos y la producción de semillas basales.

La producción de semillas basales o cleistógamas se ha conocido como un fenómeno de polimorfismo somático. Los frutos aéreos son más pequeños y numerosos que los subterráneos y son dispersados por el viento; mientras que los frutos subterráneos nunca abandonan la planta madre muerta, germinando y emergiendo a través de sus tejidos, entonces; los frutos aéreos sirven para la dispersión de la planta hacia nuevos hábitats, mientras que los frutos subterráneos están adaptados para aumentar la supervivencia de la especie en el hábitat ya ocupado. El fenómeno de cleistogamia no es raro entre diversas familias y especie, se describe a "Stipa leucotricha" como una especie que produce abundantes espiguillas cleistógamas básales, bajo ciertas condiciones ambientales, además se consideran a la baja humedad en el suelo como una condición para la inducción a la producción de flores cleistógamas en "G. micranta.

La semilla es la unidad de reproducción sexual por excelencia en las plantas superiores, y es la encargada de propagar la especie y dispersarla espacial y temporalmente. De acuerdo con esto las semillas de plantas, y por supuesto malezas, tiene la habilidad de permanecer en estado de actividad mínima durante largos periodos, la germinación desde el punto de vista fisiológico es el proceso que se inicia con el suministro de agua a la semilla y termina cuando el crecimiento de la plántula se inicia, siendo este momento más comúnmente considerado cuando se da la salida de la radícala a través del tegumento

Existen tres fases fundamentales en el proceso de germinación de las semillas: fase de hidratación o imbibición, la cual consiste en la absorción de agua por los tejidos de la semilla y un aumento considerable en a rasa de respiración de la misma; la fase de germinación, en la que suceden profundos cambios metabólicos, en esta fase se reduce considerablemente la absorción de agua, y la fase de crecimiento, en la que suceden cambios morfológicos evidentes, como la elongación de la radícala, y se caracteriza por el constante aumento en la absorción de agua y de la respiración.

Aun cuando las condiciones ambientales sean adecuadas para la germinación de semillas, muchas de ellas no lo hacen, aunque permanezcan viables. La no-germinación de las semillas, también se conoce como latencia o letargo (Zimdahl, 1993), y está ligada a causas intrínsecas de las semillas o frutos, pero también a efectos ambientales.

El balance en la concentración de O2 y CO2 en la atmósfera del suelo, es importante en la germinación de malezas. En los suelos compactos o con deficiente drenaje, con frecuencia se tienen contenidos de O2 inferiores a los necesarios para la germinación de las semillas. Una de la razón por las que la mayoría de las semillas germinan cerca de la superficie del suelo, es la mayor concentración de oxígeno.

Existen temperaturas por debajo o encima de las cuales una semilla no germina. La temperatura óptima para la germinación de las semillas depende de la especie. Temperaturas muy bajas o muy altas, por consecuencia inducen el letargo.

La latencia es la principal causa de supervivencia de las semillas de malas hierbas en el suelo, por lo que es la razón de la infestación prolongada de los cultivos por la maleza. En los suelos agrícolas, la reserva de semillas puede ser importante, y se puede encontrar hasta 120 millones de semillas (o más) por m³ en el transcurso del siguiente año de cultivo, generalmente más del 10% de este potencial semillero aparece. Esta variabilidad de respuestas germinativas lleva a una heterogeidad de los estados latentes de las semillas que quedan en la superficie del suelo o enterradas haciendo difícil la previsión de las infestaciones en los cultivos. 

La permanencia en la superficie o en el interior de la semilla viable y capaz de germinar es provocada, generalmente, por la inhibición de la germinación y la latencia secundaria, hasta que aparecen las condiciones favorables para el establecimiento de sus plántulas.

Este es el método más frecuente utilizado para aumentar la germinación de las semillas con tegumento duro. Las técnicas de escarificación pueden eliminar parcialmente tegumento o apenas alterarlo para que la germinación suceda. Existe esencialmente dos tipos: la escarificación mecánica y la química.

La escarificación mecánica puede hacerse por medio de un escarificador eléctrico o con cualquier abrasivo que corte, perfore o raspe el tegumento. El método de escarificación química se realiza por inmersión de las semillas en ácido sulfúrico concentrado, por un tiempo el cual depende de cada especie.

Algunos factores que afectan la producción de semillas son:


Todas las "Stipa" se reconocen por tener unas aristas muy largas, en el caso de "Stipa capensis" las aristas tienen entre 5 y 10 cm, y cuando son maduras se enrollan entre ellas quedando completamente enmarañadas (esta especie también se la ha llamado "Stipa retorta" ). Es una gramínea que forma prados relativamente densos, pero nunca se levanta mucho del suelo; siempre se encuentra en zonas bastante secas y abiertas.
"Stipa clandestina" fue descrita por Eduard Hackel y publicado en "Repertorium Specierum Novarum Regni Vegetabilis" 8: 516. 1910. 
Stipa: nombre genérico que deriva del griego "stupe" (estopa, estopa) o "stuppeion" (fibra), aludiendo a las aristas plumosas de las especies euroasiáticas, o (más probablemente) a la fibra obtenida de pastos de esparto.

clandestina: epíteto latíno que significa "oculta".


</doc>
<doc id="15304" url="https://es.wikipedia.org/wiki?curid=15304" title="Lengua construida">
Lengua construida

Una lengua construida, también llamada idioma artificial o conlang, es un idioma que ha sido total o parcialmente construido, planeado o diseñado por seres humanos a partir del estudio de las lenguas naturales —los lenguajes de programación son lenguajes formales y no son considerados lenguas construidas porque no son idiomas; tampoco se considera lengua construida la evolución histórica y, por lo tanto, no planeada conscientemente de cualquier lengua natural—.

Las motivaciones que impulsan el surgimiento de estas lenguas no naturales son básicamente dos:



El término español ideolengua fue propuesto por Alex Condori en 2000 para traducir el término "conlang" (Constructed Language), aunque ha tenido muy escasa extensión en la red desde entonces. Es un término desconocido en el campo de la interlingüística. 

La mayor parte de las lenguas construidas pueden dividirse en tres grupos:



Una clasificación más detallada incluye varios factores, tales como su intención de uso, su propósito de creación y el origen del vocabulario y la gramática.

Las lenguas construidas pueden dividirse en dos grandes grupos según su intención de uso: lenguas auxiliares y lenguas artísticas. Las primeras buscan ser un medio de comunicación real entre seres humanos, mientras que las segundas son habladas por personajes ficticios surgidos de la imaginación u obra del autor de la lengua, sin pretender que sean habladas por personas reales.

Estos propósitos pueden subdividirse:



Inventar una lengua puede tener propósitos utilitarios o creativos. Entre los propósitos utilitarios se encuentran el propósito de la comunicación universal, la exploración de formas de comunicación, lenguajes secretos, la ambientación de un escenario de ficción, etc. Entre los propósitos creativos, aquellos inmersos dentro de una creación mayor (por ejemplo, las lenguas de la Tierra Media como el quenya, de J. R. R. Tolkien) o aquellos que existen "per se".

Otro buen número de lenguas ficcionales las crearon lingüistas aficionados, lo cual ha servido tanto de entretenimiento como una manera de comprender ciertos aspectos de la teoría lingüística.

Si bien las lenguas auxiliares suelen tener un propósito utilitario y los idiomas ficticios acostumbran tener un propósito creativo, esta relación dista de ser unívoca, pues una lengua auxiliar puede provenir de la intención creativa del autor.

Una diferencia entre el idioma klingon, creado por Marc Okrand para el universo de Star Trek, y el sindarin, creado por J. R. R. Tolkien para el universo de la Tierra Media, es que el primero tiene un propósito utilitario, ya que los productores querían una lengua original y diferente para los klingons, mientras que Tolkien inventó sus lenguas, características de la Tierra Media, para ambientar sus lenguajes, tal como lo describe en su carta "El vicio secreto". Esto no demerita la posible calidad artística de la obra de Okrand ni minimiza la creatividad que desarrolló en su creación.

En Eurovisión, se ha llegado a usar tres veces un idioma artificial. Dos veces, los usó Bélgica (en 2003 y 2008) aunque de distinto «idioma», nunca teniendo un vocabulario desarrollado y sólo usado en la canción, poniendo en duda algún significado concreto o traducción a algún idioma. Lo mismo sucedió con los Países Bajos en 2006.

Las lenguas auxiliares parten de un problema, el cual puede resolverse mediante un idioma diseñado para ese propósito, mientras que los idiomas ficticios surgen de la inquietud de su creador.

Las lenguas artificiales suelen dividirse en dos tipos, según el origen de su vocabulario o su gramática: lenguas a priori y lenguas a posteriori. Una lengua a priori es aquella cuya gramática y/o vocabulario se crean o se inventan sin referencia a lengua natural alguna. Una lengua a posteriori es aquella cuya gramática y vocabulario se derivan de una o varias lenguas existentes.

El lojban es una lengua con gramática y vocabulario a priori, pues si bien sus morfemas básicos proceden de elementos comunes o combinados de los cinco idiomas más hablados (chino, inglés, español, hindi y árabe), estos son reconstruidos según las normas fonéticas y gramaticales que se prescriben. Esto, junto con el hecho de que su gramática busca parecerse a la lógica simbólica, es completamente apriorístico.

La lengua universal de Sotos Ochando también es un idioma a priori, y lo mismo diversos intentos de lenguas filosóficas, como los de John Wilkins ("Essay towards a Real Character, and a Philosophical Language", 1668) y de George Dalgarno ("Ars Signorum", 1661).

Las lenguas a posteriori se pueden clasificar en esquemáticas y naturalistas. Esquemáticas son las que toman los elementos básicos de la lengua desde las lenguas naturales y son regularizados según un esquema predeterminado. Son naturalistas cuando tratan de no ser muy diferentes a las lenguas naturales, sobre todo en su vocabulario, sino algo similar para facilitar su entendimiento rápido, aun sacrificando en parte la regularidad.

El proceso de selección de vocabulario puede ser más o menos sistemático. La interlingua de IALA utiliza un proceso sistemático de selección basado en cuatro lenguas básicas y dos lenguas de control. Es adoptada toda palabra común a por lo menos tres de los idiomas básicos: español, francés, inglés e italiano y si sólo es común a dos de estos idiomas, toma el alemán y el ruso como control para decidir qué palabra adoptar.

El esperanto es también una lengua a posteriori a pesar de no tener un sistema mecánico para seleccionar el vocabulario y de que contiene varios elementos inventados o a priori.

El perciscan es un idioma creado en 2013 que tiene el objetivo de servir como medio de comunicación entre los países de lenguas romances sin necesidad de usar el inglés.

Entre las lenguas ficcionales y ficticias, existen también dos tipos de lenguas a posteriori. 

Del primer grupo es ejemplo Tolkien, quien definió una familia de lenguas partiendo de una lengua madre (a priori) y derivando lenguas hijas utilizando procesos de derivación similares a los naturales. Estas lenguas derivadas son por ello a posteriori. Este proceso de derivación se ha aplicado a lenguas existentes para crear «[idiomas del futuro]]» o lenguas ficcionales, como el brithenig, que sería la lengua que hablarían en el oeste de Inglaterra si el latín hubiese sobrevivido hasta nuestros días.

Ejemplo del otro tipo de lenguas ficcionales a posteriori es el recurso utilizado en "La Guerra de las Galaxias", que consiste en usar elementos de gramática y vocabulario de lenguas indígenas poco conocidas, para después combinarlos en formas poco reconocibles.

Un tipo especial de lenguas a posteriori son las lenguas controladas, que son adaptaciones de idiomas naturales buscando una gramática simple y un vocabulario reducido para permitir que más personas, que no sean hablantes nativos del idioma base, puedan con poco estudio leer o escuchar textos en la lengua controlada, como por ejemplo el inglés básico.
Otro ejemplo es el Anglo Rom una lengua recientemente inventada cuyo vocabulario se construye partiendo de las raíces del latín y que se rige por solo 19 reglas.

Las lenguas naturales suelen clasificarse según criterios filogenéticos y tipológicos. 
El primero de estos, el filogenético, no se aplica generalmente a las lenguas artificiales, por tratarse de creaciones humanas deliberadas y no derivar estas lenguas de ningún ancestro o protolengua común, pero en ocasiones las lenguas artificiales se crean muy deliberadamente como evoluciones de un ancestro construido, y en ese caso sí que podría aplicarse el criterio filogenético o método comparativo.
El segundo, el criterio tipológico, por el contrario, siempre es perfectamente aplicable a todas las lenguas artificiales. En ese sentido las lenguas construidas son prácticamente tan variadas como las lenguas naturales, aunque en muchas de ellas han predominado los rasgos tipológicos de las lenguas europeas e indoeuropeas, como sucede en el esperanto, el volapük, el latino sine flexione, etc. Otras lenguas construidas de éxito como el klingon uno de cuyos creadores, Marc Okrand, trabajó sobre el idioma mutsun lengua indígena de California de la familia uti, parece tener características reminiscentes de esa lengua indígena.




</doc>
<doc id="15307" url="https://es.wikipedia.org/wiki?curid=15307" title="Alpha">
Alpha

El término Alpha puede referirse a:


</doc>
<doc id="15308" url="https://es.wikipedia.org/wiki?curid=15308" title="Legión Cóndor">
Legión Cóndor

La Legión Cóndor (en alemán: Legion Condor) fue el nombre dado a la fuerza de intervención mayoritariamente aérea que el III Reich envió en ayuda de las fuerzas del dictador Franco para luchar en la guerra civil española. Adolf Hitler, canciller alemán, a sugerencia del jefe de la Luftwaffe, Hermann Göring, y con la intención de probar el arma aérea alemana en una guerra convencional, ofreció a Franco de forma secreta apoyo aéreo para su ejército terrestre. Esta ayuda consistió en apoyo logístico, transporte de tropas, suministros, carros de combate (sobre todo Panzer I) y artillería, creándose la primera escuela de carros de combate, bajo el mando del coronel del ejército alemán Wilhelm von Thoma, en el Castillo de las Arguijuelas de Arriba en las cercanías de la ciudad de Cáceres.

La intervención alemana en la Guerra Civil permitió a Hitler mejorar la calidad de sus aparatos y reparar los defectos de su arma aérea, preparándola para la ofensiva mundial que estaba planeando. Un ataque normal podía consistir en un vuelo previo de toma fotográfica. A continuación los bombarderos (unos 80 Junkers y Heinkel alemanes en 1936) eran custodiados por cazas italianos y más aviones de captura fotográfica. La precisión de sus bombas era sorprendente y revela un estudio detallado de los objetivos. Con el tiempo, se demostró como una de las piezas elementales en la victoria de Franco.

El 18 de julio de 1936 estalló una rebelión militar en el Protectorado español de Marruecos, que acabaría degenerando en una auténtica Guerra Civil. Lo cierto es que tanto los sublevados como las fuerzas gubernamentales no eran lo suficientemente fuertes como para vencer al contrario, pero el problema de los sublevados en Marruecos era mucho más grave: La flota se había mantenido fiel al gobierno y controlaba las aguas del estrecho de Gibraltar con lo que el paso a la península estaba cortado. Se necesitaba del empleo de aviones y el comandante del Ejército de África envió telegramas solicitando ayuda a los únicos líderes internacionales con posibilidad de que respondieran: Adolf Hitler y Benito Mussolini. El dictador italiano accedió al envío de una decena de aparatos de transporte y suministros militares, mientras que Hitler demoró su decisión hasta la intervención del entonces Ministro de Economía de Reich, Hermann Göring. En el Marruecos español se encontraba un importante hombre de negocios, Johannes Bernhardt, y sería él quien bajo sus influencias constituiría la figura en la sombra que tejía la ayuda alemana a Franco. Así, mediante la "Operación fuegos mágicos" ("Unternehmen Feuerzauber") se dio comienzo a los preparativos para la aventura española, en la que el III Reich utilizaría España como un particular campo de tiro. El 24 de julio Bernhardt y Adolf Langenheim, el líder local del NSDAP en el Marruecos español, aterrizaron en el aeropuerto de Berlín-Tempelhof. Rudolf Hess, secretario de Adolf Hitler, organizó una reunión con el "Führer" al día siguiente, en el Festival de Bayreuth, después de una representación de "Sigfrido" de Richard Wagner.

En la noche del 25 al 26 de julio, en Bayreuth, tuvo lugar la conversación de Hitler con Langenheim y Bernhardt, quienes transmitieron la petición de Franco del envío de aviones de transporte, y finalmente se tomó la decisión fundamental de apoyar al general español. Estaban involucrados en la decisión (además de Hitler) el ministro del Aire, Göring, y el ministro de la Guerra, Von Blomberg, quienes también estaban presentes en Bayreuth.

En los primeros momentos de la sublevación militar, Benito Mussolini había aprobado el envío de armas, equipo y pertrechos militares a los militares sublevados contra la República española, ayuda que más tarde aumentaría hasta el envío de un cuerpo de ejército bien equipado, el CTV. Hitler, aunque vaciló más en su decisión, al final lo hizo apoyando el envío de armas y suministros a Franco. Y es que, para Hitler existían una serie de hechos que le servirían en un futuro para su política expansionista y militarista:


Entre finales de julio y principios de septiembre de 1936 hubo distintos envíos de material y técnicos militares como apoyo de los militares sublevados en la guerra, destacando el envío de Junkers Ju 52 para transporte de las tropas africanas y algunos cazas Heinkel He 51 que dieron un momentáneo control de los cielos a los sublevados.

Sin embargo, el contingente de mayor importancia salió el 6 de noviembre de Alemania hacia Sevilla, el núcleo de lo que ya sería conocido como "Legión Cóndor", en una operación que recibió el nombre clave de "Rügen Winter", al mando del general Von Sperrle y con el coronel Von Richtofen como jefe de Estado mayor. El envío contenía aviones, así como artillería antitanque, artillería antiaérea, y varias secciones de carros de combate. En total, el personal de esta primitiva fuerza se elevaba a unos 3800 hombres, siendo aumentada esa cifra poco tiempo después hasta los 5000. En algunos aspectos, la Legión Cóndor era una unidad revolucionaria, aunque su equipo y armamento eran todavía muy primitivos; para empezar, sus aviones volaron casi siempre sin radio y las ametralladoras había que cargarlas a mano. Entonces, los bombarderos aún eran Junkers 52 y los cazas Heinkel 51, aparatos que, como se demostraría con posterioridad, eran mucho más pesados y lentos que sus homólogos rusos que ya empezaban a llegar desmontados a los puertos de Cartagena, Alicante y Valencia.

El grupo primitivo se encontraba apoyado por unidades de cañones antiaéreos y antitanques, así por dos unidades blindadas formadas por cuatro compañías, cada una compuesta por cuatro Panzer I. De los equipos antiaéreos, una parte fue adjuntada a las unidades de la "Luftwaffe" como defensa de los aeródromos mientras que la restante quedó como defensa antiaérea de las fuerzas terrestres. Dichas fuerzas se encontraban al mando de von Thoma, luego famoso experto en la guerra de blindados durante la Segunda Guerra Mundial, que en España se distinguiría por el uso de tácticas blindadas luego ampliamente empleadas durante dicha guerra.

A instancias suyas y otros técnicos alemanes acabaría creándose la primera escuela de carros de combate, bajo el mando de Von Thoma, en el Castillo de las Arguijuelas de Arriba en las cercanías de la ciudad de Cáceres. Los tanques Panzer I resultaron totalmente inferiores frente a los T-26 soviéticos, a pesar de que fueron enviados unos 200 tanques en total. El propio Von Thoma reconoció en un interrogatorio a los americanos (al final de la Segunda Guerra Mundial) que había participado en unas 192 acciones de carros de combate a lo largo de toda la guerra española. Durante la ofensiva de Aragón, von Thoma tuvo que intervenir ante la decisión de Franco de distribuir los tanques al modo militar tradicional. En ese momento el cuerpo blindado que mandaba Thoma, comprendía cuatro batallones, cada uno con tres compañías, de las cuales cada una estaba equipada con 15 tanques ligeros. Este cuerpo iba así mismo acompañado de treinta compañías antitanque, con seis cañones de 37 mm. cada una.

Otra pieza elemental empleada por los equipos militares (eso sí, tanto de tierra como de aire) fue el empleo del cañón Flak 18 de 88 mm, un arma que demostró sus verdaderas capacidades en la guerra de España y que lo haría aún más durante la siguiente guerra.

A las unidades aéreas y terrestres de la primitiva Legión Cóndor se unió después un Grupo del Mar del Norte formado por especialistas en artillería naval, minas y señales, que actuaban desde los acorazados de bolsillo "Deutschland" y "Admiral Scheer". A esta flota se le unirían el crucero ligero Leipzig así como algunos destructores. Así mismo dos submarinos (el "U-33" y el "U-34") salieron para el Mediterráneo para realizar misiones secretas, en realidad para entrenar a las nuevas tripulaciones de submarinos. La presencia de estos buques provocó no pocos incidentes: el U-34 sería el responsable del hundimiento del submarino republicano "C-3" en las costas de Málaga, el 13 de diciembre de 1936.

Por otro lado, en la tarde del 26 de mayo de 1937 fue bombardeado el acorazado de bolsillo "Deutschland" causándole más de una veintena de muertos y graves daños. Al ser informado de los sucesos, Hitler montó en cólera y ordenó el bombardeo de Valencia (entonces capital de la República). Asesorado por sus consejeros militares, decide el bombardeo de la ciudad de Almería. Así pues, el 31 de mayo el acorazado de bolsillo "Admiral Scheer" se presentó junto a cuatro destructores frente al puerto andaluz y realizó doscientos disparos contra la indefensa ciudad. Los daños tanto materiales como humanos fueron numerosos y Alemania resolvió a retirarse de las patrullas navales del Comité de No intervención, decisión seguida también por Italia.

En el momento clímax de la Batalla de Madrid, hacía el 6 de noviembre salió de Alemania el grueso de las fuerzas de los componentes aéreos de la Legión Cóndor la composición de las fuerzas aéreas "(Luftwaffe)" pertenecientes a la Legión Cóndor, cuya organización y composición era la siguiente:

Legión Cóndor
"Comandante superior": Generalmajor Hugo Sperrle
"Unidades aéreas" (Fuerza de 136 aviones):

Conforme avanzó la guerra, aumentó el número de aviones que componían la Legión Cóndor, pero también aumentó tanto la calidad de sus aparatos como de sus pilotos y técnicos. Después de la derrota de Franco frente a Madrid, los alemanes vieron la necesidad de aumentar los envíos de material y hombres. Ante las perspectivas de una guerra larga, enviaron su mejor armamento para probarlo en el particular "Polígono de tiro español". Al final de la guerra los alemanes habían enviado unos 600 aviones a España, entre los que se contaban 136 aviones Messerschmitt Bf 109, 125 aparatos Heinkel He 51, 93 Heinkel He 111 y 63 Junkers Ju 52. También destacaron 33 aviones Heinkel He 45 y otros 20 aparatos Heinkel He 46, así como 31 aparatos Dornier Do 17 y 5 Junkers Ju 87, el luego famoso "Stuka".


Al inicio de la batalla de Madrid, llegó el primer contingente importante de tropas y equipo de la primitiva Legión Cóndor. Una vez instalados en bases españolas (la sección de hidroaviones lo hizo en Palma de Mallorca, mientras que el resto de unidades en la península ibérica) las unidades aéreas se dedicaron a bombardeos estratégicos sobre Madrid (iniciados ya por los sublevados, ahora continuados por los alemanes) con una intensidad cada vez mayor. Lo cierto es que los asesores militares alemanes buscaban ver el comportamiento de la población madrileña ante este tipo de bombardeos y su reacción. Las operaciones posteriores al asalto a Madrid (especialmente durante los combates en el Jarama) significaron un fracaso para Franco porque no pudo doblegar la capital, pero para la Legión Cóndor supuso todo un campo de aprendizaje en el empleó a gran escala de armas modernas en una batalla terrestre que tácticamente no había cambiado mucho desde las de la Primera Guerra Mundial.

Tras la derrota italiana de Guadalajara, las escuadrillas de la Legión Cóndor se trasladarían al frente norte y solo volverían al centro con motivo del Contraataque republicano en Brunete. Aquí las tropas republicanas lograron conseguir un importante éxito inicial pero, como sería habitual en sus ofensivas, ésta se agotó después de unos días. Y al contraataque sublevado se unió la respuesta aérea de la Legión Cóndor, que con la presencia de los nuevos Messerschmitt Bf 109 y los Heinkel He 111 concedió el dominio absoluto del aire a los sublevados, y Brunete fue reconquistado de nuevo. Las pérdidas de la Legión Cóndor fueron mínimas en comparación con el daño infligido a la aviación republicana.

Madrid resultó un hueso muy duro de roer para Franco, por lo que este puso sus ojos sobre el frente norte, militarmente débil y políticamente desunido. Las escuadrillas alemanas se estaban trasladando hacia el Cantábrico cuando se produjo el bombardeo de Durango, antesala de otro en el que la futura Lutfwaffe sería partícipe.

La "Operación Rügen" —como se llamó en clave el bombardeo de Guernica— el 26 de abril de 1937 fue la primera vez que la acción de la fuerza aérea alemana causó un gran número de víctimas civiles. Los alemanes habían estado practicando nuevas técnicas («Bombardeo en alfombra») hasta entonces nunca vistas, sobre objetivos aislados como el Bombardeo de la Fabricona de Golpejar (días antes del bombardeo de Guernica).Se dieron órdenes a los pilotos de bombardear el puente de Rentería y la ciudad vasca de Guernica, poblada por 7000 habitantes. El puente, que constituía el principal objetivo militar del bombardeo aéreo, se salvó paradójicamente. La operación dio lugar a una mordaz condena internacional. Fue entonces cuando la atención internacional se centró en la participación de la Alemania nazi y la Italia fascista en el conflicto. Hasta entonces, la política alemana de ayuda militar y de personal técnico se había negado públicamente o había sido silenciada. Con el bombardeo fue comunicada públicamente, de conformidad con la posición de neutralidad que había declarado durante la firma del "Pacto de no intervención", aunque ni Francia ni Gran Bretaña hicieron reacciones al respecto.

Con posterioridad, esta destrucción ha recibido amplia cobertura mediática y ha creado una percepción internacional de lo que fue la participación alemana en el conflicto español. El régimen de Franco, ante el rechazo internacional, siempre intentó negar su participación en el bombardeo y acusó al bando republicano de ser el responsable de la destrucción de la villa vasca en clara alusión a lo ocurrido durante la batalla de Irún el año anterior. Con posterioridad reconoció que el bando republicano no había sido el responsable, aunque advirtió que "solo los oficiales alemanes son responsables del ataque", a pesar de que su personal lo había aprobado, de conformidad con las tácticas de terror de masas empleadas en Bilbao, Madrid y Barcelona. No obstante, nunca ha estado del todo aclarada la participación y el grado de conocimiento que el bando sublevado tuvo respecto a la planificación del ataque. El Gobierno vasco de la época cifró las víctimas del bombardeo en 1.654 muertos y 889 heridos —sin precedentes en bombardeos de objetivos civiles hasta el momento—. La publicación de estas cifras provocó una protesta internacional, que sería la inspiración de la pintura "Guernica" de Pablo Picasso, que desde entonces se ha convertido en icono de los horrores de la guerra. El bombardeo de Guernica muestra, de alguna manera, cómo las fuerzas fascistas del general Franco en España habían llegado a depender en gran medida de la pericia de los pilotos alemanes e italianos, pero también la independencia con que actuaban estas respecto al bando sublevado.


Johannes Bernhardt era un empresario alemán que antes de la guerra había emigrado de Alemania a España por la Gran Depresión, estableciéndose en el Protectorado español de Marruecos. Allí había hecho grandes negocios en él, extendiendo su red de influencia entre algunos sectores económicos y militares.

La Sociedad Hispano-Marroquí de Transportes (HISMA) fue una empresa fantasma constituida en Tetuán el 31 de julio de 1936, controlada por el Partido Nazi y que tenía como finalidad servir de tapadera al tráfico de armas para el bando franquista durante la Guerra Civil española. Su labor fue fundamental en la operación para transferir una parte del Ejército de África a la península ibérica. También organizó el primer contingente alemán en el bando franquista. Las ayudas de Hitler a Franco, que recibía a través de HISMA, eran compensadas por medio de exportaciones a través de otra empresa ficticia alemana creada por orden de Hermann Göring, la ROWAK (Rohstoff und Wareneinkaufgesellschaft). Sin embargo, quién verdaderamente controlaba todas las operaciones económicas en España era Johannes Bernhardt.

En 1939, los envíos alemanes se habían realizado en 180 expediciones a lo largo de toda la contienda. Las fuerzas alemanas presentes durante la Guerra Civil Española se elevaron como máximo a unos 10.000 hombres, aunque en el desfile de Berlín de mayo de 1939 participaron unos 14.000 veteranos. Los alemanes que ayudaron a los sublevados probablemente fueron más de 16.000, muchos de los cuales eran personal civil e instructores. Sin embargo, el núcleo de estos era la Legión Cóndor, y ésta siempre estuvo compuesta por un número que no superó los 5000 efectivos. De todo el conjunto, murieron a lo largo de la guerra unos 300 alemanes.

La Cruz española ("Spanienkreuz") fue la condecoración entregada a los veteranos de la "Legión Cóndor" por las autoridades nazis desde el 14 de abril de 1939. Debido a la naturaleza secreta de las actividades alemanas en España durante la guerra, hasta entonces no había sido entregada ninguna condecoración oficial por parte de las autoridades militares alemanas, aunque algunos militares alemanes habían recibido condecoraciones por parte de las autoridades franquistas en agradecimiento a sus servicios durante algunas operaciones militares. Durante el desfile de la Victoria celebrado el 19 de mayo en Madrid participaron algunos miembros de la "Legión Cóndor", al igual que en la concentración aérea que tuvo lugar en el aeropuerto de Barajas el día 12 del mismo mes. El 22 de mayo tuvieron una fastuosa despedida (la noche anterior se celebró un desfile de antorchas) en el aeródromo de La Virgen del Camino, donde marcharon cinco mil legionarios hasta terminar en la catedral de León, con la asistencia de personalidades como el jefe del Ejército del Aire Alfredo Kindelán o el obispo Carmelo Ballester. Presidió los actos el ya dictador Franco, que agradeció la ayuda de las legiones alemanas para derrotar a «la escoria comunista de Europa» en territorio español y recalcó así su importancia decisiva para la victoria:
El 24 de mayo salieron de España desde el puerto de Vigo, desfilando por las calles de la ciudad en otra espectacular parada militar al estilo fascista. Después de abandonar la península a bordo de varios buques (entre ellos, el luego famoso MV Wilhelm Gustloff), tuvieron un gran recibimiento en Alemania, especialmente durante una parada militar el 6 de junio a la que asistió el propio Hitler. Con el comienzo de la Segunda Guerra Mundial, gran parte de los voluntarios que habían luchado en España tuvieron una destacada actuación en la misma, especialmente Richthofen, Sperrle, Von Thoma o Galland. Otros, como Werner Mölders, morirían durante la guerra.

Hasta principios de los 90 no existió en la RFA un activo movimiento de recriminación por las actividades de la "Legión Cóndor" en España y la presencia de ciudadanos alemanes entre los que ejecutaron el bombardeo de Guernica. En 1997, en el 60º Aniversario de la "Operación Rügen", el entonces Presidente de la República Roman Herzog escribió una carta a los supervivientes del bombardeo donde se disculpaba públicamente en nombre del pueblo y el estado alemanes. Herzog expresó que quería tender "una mano de amistad y reconciliación" en nombre de todos los ciudadanos alemanes. Este sentimiento ha sido después ratificado por miembros del Parlamento alemán que en 1997 aprobaron eliminar a todos los miembros de la "Legión Cóndor" que fueran nombrados en los registros militares alemanes a militares heroicos.




</doc>
<doc id="15309" url="https://es.wikipedia.org/wiki?curid=15309" title="Isaac Asimov">
Isaac Asimov

Isaac Asimov (ˈaɪzək ˈæzəməf; en ruso А́йзек Ази́мов —Áyzek Azímov—, nombre original: Исаáк Ю́дович Ози́мов —Isaak Yúdovich Ozímov— Petróvichi, RSFS de Rusia, -Nueva York, Estados Unidos, ) fue un escritor y profesor de bioquímica en la facultad de medicina de la Universidad de Boston de origen ruso, nacionalizado estadounidense, conocido por ser un prolífico autor de obras de ciencia ficción, historia y divulgación científica. Asimov, asimismo, tenía un dilatado conocimiento sobre las ciencias naturales en todo su conjunto.

Su obra más famosa es la "Saga de la Fundación", también conocida como "Trilogía o Ciclo de Trántor", que forma parte de la serie del Imperio Galáctico y que más tarde combinó con su otra gran serie sobre los robots. También escribió obras de misterio y fantasía, así como una gran cantidad de textos de no ficción. En total, firmó más de 500 volúmenes y unas 9000 cartas o postales. Sus trabajos han sido publicados en 9 de las 10 categorías del Sistema Dewey de clasificación.

Junto con Robert A. Heinlein y Arthur C. Clarke, Asimov fue considerado en vida como uno de los «tres grandes» escritores de ciencia ficción. 

La mayoría de sus libros de divulgación explican los conceptos científicos siguiendo una línea histórica, retrotrayéndose lo más posible a tiempos en que la ciencia en cuestión se encontraba en una etapa elemental. A menudo brinda la nacionalidad, las fechas de nacimiento y muerte de los científicos que menciona, así como las etimologías de las palabras técnicas.

Fue miembro de Mensa durante mucho tiempo, a cuyos miembros describía como «intelectualmente combativos». Disfrutaba más de la presidencia de la Asociación Humanista Estadounidense, una organización de ideología atea.

En 1981 se nombró a un asteroide, el (5020) Asimov, en su honor.

Se considera que Isaac Asimov nació el 2 de enero de 1920 en Petróvichi, República Socialista Federativa Soviética de Rusia (desde 1929 y hasta ahora Óblast de Smolensk, Federación de Rusia, a 400 km al suroeste de Moscú y a 16 kilómetros de la frontera con Bielorrusia actual).

Sus padres, Judah Asimov y Anna Rachel Berman, de origen judeo-ruso, se trasladaron a Nueva York el 11 de enero de 1923, cuando el autor tenía tres años.

Su infancia transcurrió en el barrio neoyorquino de Brooklyn, donde el joven Isaac aprendió por sí mismo a leer a la edad de cuatro o cinco años; cabe destacar que nunca aprendió ruso. La juventud del futuro escritor transcurrió entre los estudios y el trabajo en las distintas tiendas de golosinas que su padre regentaba en el barrio de Brooklyn. Fue entre esos estantes llenos de revistas donde el joven Asimov se encontró por primera vez con la ciencia ficción. Comenzó a escribir en su adolescencia temprana y, a los 19 años, empezó a publicar sus relatos de ciencia ficción en las revistas de ficción llamadas "pulps".

Tenía tanto miedo a volar que solo viajó en avión dos veces en toda su vida, lo que le hizo pensar que podía padecer de acrofobia. Asimismo padecía claustrofilia, lo opuesto de la claustrofobia, es decir, le gustaban los lugares pequeños y cerrados.

Se graduó como bioquímico en la Universidad de Columbia en 1939. Al ser rechazado para ingresar en las escuelas de medicina de las universidades de Nueva York, regresó a Columbia y decidió hacer un postgrado de química, título que obtuvo en 1941. El siguiente año, 1942, fue particularmente significativo para Asimov; al partir hacia la ciudad de Filadelfia obtuvo un trabajo como investigador químico en los astilleros de la marina de guerra estadounidense, empleo que mantuvo durante el transcurso de la Segunda Guerra Mundial. En 1948 consiguió el doctorado en química, lo que le permitió el acceso a la Universidad de Boston donde permaneció como asociado, pero sin opción a enseñar. La universidad dejó de pagarle el salario en 1958, pero, para entonces, los ingresos procedentes de su trabajo como escritor eran mayores que los que conseguía con su labor universitaria. Asimov permaneció en la facultad como profesor asociado, y en 1979 le ascendieron a profesor titular. Sus documentos personales de los años 1965 en adelante se archivaron en la Biblioteca Mugar Memorial de la Universidad de Boston, donde ocupan 464 cajas en 71 m de estanterías. En 1985 fue elegido Presidente honorario de la Asociación Humanista Estadounidense, cargo que ocupó hasta su muerte en 1992. Su sucesor fue su amigo y colega Kurt Vonnegut. Fue también vicepresidente honorario del club Mensa hasta la muerte de su directora Margot Seitelman el 5 de noviembre de 1989.

Asimov se casó el 26 de julio de 1942 con Gertrude Blugerman, con la que tuvo dos hijos: David y Robyn, nacidos respectivamente en 1951 y 1955. Tras un largo periodo de separación se divorciaron en 1973 y a final de ese año Isaac se casó con Janet Opal Jeppson.

En 1977, Asimov sufrió un ataque cardíaco. En diciembre de 1983, se le practicó una cirugía cardiovascular en la que le realizaron un triple baipás coronario. Durante una operación, se le realizó una transfusión de sangre que resultó estar contaminada con el virus VIH. Cuando fue descubierta la infección por VIH, sus médicos insistieron en no hacer pública la información debido al prejuicio que se tenía en ese tiempo contra los infectados por dicha enfermedad.

Asimov murió en Nueva York el 6 de abril de 1992, donde fue incinerado. Le sobrevivieron su viuda Janet y los hijos de su primer matrimonio, así como sus hermanos. Su hermano Stanley informó que la causa de muerte fue insuficiencia cardíaca y renal. La familia optó por no revelar que la muerte se había debido a la enfermedad del sida, ya que dos días después del fallecimiento se produjo una gran controversia pública cuando el tenista Arthur Ashe anunció que tenía la misma enfermedad (también contraída en 1983 de una transfusión sanguínea durante una cirugía de baipás coronario). También los doctores continuaron insistiendo en mantenerlo en secreto.

En 2002, cuando muchos de los médicos que atendieron a Asimov habían fallecido, Janet y Robyn Asimov acordaron revelar que la muerte de Isaac Asimov fue debida al sida. Janet Asimov hizo pública la información previamente a la publicación de la autobiografía póstuma de Asimov "It's Been a Good Life" (2002), que la propia Janet había editado y en la que ella misma revelaba las circunstancias del contagio y de su fallecimiento.

Isaac Asimov fue un humanista y un racionalista. No se oponía a las convicciones religiosas genuinas de los demás, pero se enfrentó a las supersticiones y a las creencias infundadas.

Asimov era un progresista en temas políticos y partidario del Partido Demócrata de los Estados Unidos. En una entrevista televisiva a principios de los años 1970, respaldó públicamente a George McGovern. Se sintió muy desilusionado cuando vio las tácticas, que él consideraba irracionales, de los activistas progresistas desde finales de los años 1960 en adelante.

Su defensa de las aplicaciones civiles de la energía nuclear, sobre todo tras el accidente nuclear de la Isla de las Tres Millas, dañó sus relaciones con la izquierda. En una carta reimpresa en " Tuyo, Isaac Asimov," afirmaba que: «prefería una casa cerca de una planta de energía nuclear que en una colonia en el Canal del amor o cerca de una planta de isocianato de metilo de la Union Carbide» (referencia al desastre de Bhopal).

Publicó mucho sobre el control de la natalidad, reflejando la perspectiva articulada por Paul R. Ehrlich y en los últimos años de su vida, Asimov condenó el deterioro de la calidad de vida que percibía en la ciudad de Nueva York al reducirse las inversiones por la huida de la clase media a los suburbios. Su último libro de no ficción, "La ira de la Tierra", escrito junto con otro autor de ciencia ficción, Frederik Pohl, trata de aspectos medioambientales como el calentamiento global y la destrucción de la capa de ozono.

La carrera de Asimov puede dividirse en varios períodos. En sus primeros años el tema dominante fue la ciencia ficción, iniciándose con cuentos en 1939. En 1950 publicó su primera novela, "Un guijarro en el cielo". Esta etapa duró hasta 1958, terminando con la publicación de "El sol desnudo". Posteriormente disminuyó de manera importante su producción de libros de ficción mientras se dedicaba a otros temas y en los siguientes 25 años publicó solamente cuatro libros de ciencia ficción. A partir de 1982, se inició la segunda etapa de su actividad en la ciencia ficción con la publicación de "Los límites de la Fundación". Desde entonces y hasta su muerte, Asimov publicaría muchas secuelas de sus novelas ya escritas, dándoles un tratamiento de conjunto en una forma que seguramente él mismo no había previsto. Se estima en 429 los libros escritos por Asimov.

Asimov pensaba que sus contribuciones más duraderas serían las Tres Leyes de la Robótica y la Saga de la Fundación (véase "Yours, Isaac Asimov," p. 329). Más aun, el "Diccionario de inglés de Oxford" le da crédito al introducir las palabras "positrónico," "psicohistoria" y "robótica" en el idioma inglés. La primera de estas palabras se aplica a una tecnología enteramente ficticia, aunque basada en el nombre de la partícula subatómica de antimateria opuesta al electrón, el positrón, mientras que la segunda se utiliza con frecuencia en un sentido diferente al empleado por Asimov; sin embargo, el uso de robótica continúa aplicándose con el sentido dado por Asimov.

Durante los últimos años de la década de los cincuenta y hasta entrada la década de los sesenta, Isaac Asimov redujo sustancialmente su producción de ficción y enfocó sus intereses hacia los ensayos. Entre "El Sol Desnudo" de 1957 y "Los Límites de la Fundación" de 1982, solo publicó cuatro novelas, dos de las cuales fueron de misterio. En este mismo periodo, incrementó en gran medida su producción literaria en otras áreas, escribiendo casi siempre sobre temas científicos. El lanzamiento del Sputnik en 1957 despertó el interés del público sobre la ciencia, interés que los editores de Asimov le pidieron que cubriera con cuanto material fuera capaz de escribir. Al mismo tiempo, la revista mensual "Magazine of Fantasy and Science Fiction" le invitó a continuar su habitual columna, que había comenzado en la ya cerrada revista bimestral del mismo grupo, "Venture Science Fiction", especializada en la divulgación científica, y dio a Asimov completa libertad para publicar. La primera de las contribuciones a esta revista mensual "F&SF" apareció en noviembre de 1958 y continuó desde entonces con otras 399 colaboraciones, hasta que su estado de salud le impidió seguir. Estas columnas, coleccionadas periódicamente en libros por su principal editor, Doubleday, ayudaron a Asimov a crearse una reputación como gran divulgador de ciencia y, según él, fueron las únicas obras de divulgación que escribió en las que no tenía que suponer de sus lectores una completa ignorancia en los temas discutidos. La popularidad de su primer trabajo de gran envergadura, la "Guía de la Ciencia para el Hombre Inteligente", también le permitió desprenderse de gran parte de sus responsabilidades académicas y convertirse esencialmente en escritor a tiempo completo.

Asimov publicó la "Guía Asimov para la Biblia" en dos volúmenes que comprendían el Antiguo Testamento (1967) y el Nuevo Testamento (1969), y luego los combinó en un solo volumen de 1300 páginas en 1981. Lleno de mapas y tablas, la guía conduce a través de los libros de la Biblia en orden, explicando la historia de cada uno y las influencias políticas que les habían afectado, como también información biográfica sobre los personajes importantes.

También escribió varios ensayos sobre las convenciones sociales de su día, incluyendo "Thinking About Thinking" y "Science: Knock Plastic" (1967).

La gran variedad de información que cubren los escritos de Asimov llevaron a Kurt Vonnegut a preguntarle en una ocasión: «¿Cómo se siente sabiéndolo todo?». Asimov le respondió que él solo sabía cómo se sentía al tener esta reputación de omnisciente: inquieto (ver "In Joy Still Felt", capítulo 10). En la introducción de su colección de historias "Slow Learner", el novelista estadounidense Thomas Pynchon admitió que obtenía en las obras de divulgación científica de Asimov y en el "Oxford English Dictionary" todos sus conocimientos sobre la entropía.

La faceta como divulgador científico resaltaba en su libro de divulgación científica "El Universo" (publicado en 1966 en inglés, en español en 1971), en el que expone, sin utilizar un lenguaje muy técnico, todo el conjunto de certidumbres científicas existentes sobre el Universo a través de la descripción de diferentes hechos astronómicos y físicos.

De entre sus obras de ciencia ficción, las más conocidas pertenecen al Ciclo de Trántor o la serie de las Fundaciones. La trilogía original ("Fundación", "Fundación e imperio" y "Segunda Fundación") recibió el premio Hugo a la mejor serie de ciencia ficción de todos los tiempos. Posteriormente, escribió "Los límites de la Fundación" y "Fundación y Tierra", que siguen con los acontecimientos de "Segunda Fundación". En "Fundación y Tierra", Asimov enlaza la serie de la Fundación con las novelas de robots al introducir a uno de sus más conocidos personajes: R. Daneel Olivaw. Sus novelas de robots destacan por ser de tipo policíaco, por lo cual Asimov es considerado como un pionero en la ciencia ficción policíaca. En las novelas de robots ("Las bóvedas de acero", "El sol desnudo", "Los robots del amanecer", "Robots e Imperio") Asimov crea a otro de sus grandes personajes: Elijah Baley. En "Preludio a la Fundación" y "Hacia la Fundación", Asimov narra los orígenes de la psicohistoria, máxima creación de Hari Seldon. Estas novelas sirven también de nexo entre las novelas de robot y las de la Fundación, al presentar el encuentro de Hari Seldon con Daneel.

La obra de Asimov no es ajena al humor, en la revista "Astounding Science Fiction" publicó, en 1948, un artículo seudocientífico y humorístico titulado "Las asombrosas propiedades endocrónicas de la tiotimolina resublimada", cuyo tema era una sustancia que se disuelve exactamente 1,2 segundos «antes» de que se le agregue agua.

También destacaron sus antologías de ciencia ficción, especialmente la serie "La edad de oro de la Ciencia Ficción", en la que publicó en forma de recopilación los cuentos leídos por Asimov a los 11 años y releídos y seleccionados en su madurez, añadiendo al comienzo de ellos comentarios del autor y en qué revista se publicó.





A partir de 1965 y hasta mediados de los setenta, Asimov compagina la creación literaria de ficción con la divulgación histórica a través de varios libros que comprenden las más importantes civilizaciones y periodos históricos. Como por ejemplo la civilización egipcia, griega y romana, pasando por la Edad Media, el descubrimiento del Nuevo Mundo y la formación de Estados Unidos. El autor trata de atraer al gran público al conocimiento de la historia a través de una narración amena y sencilla. Se trata principalmente de historia político/militar.

Esta serie de obras ha sido común e informalmente denominada Historia Universal Asimov y está compuesta por 14 volúmenes, con mapas y cronología incluidos en cada uno de los mismos.

Volúmenes de la serie 

Durante las décadas de los 60 y 70, Isaac Asimov ralentizó su producción de novelas y relatos de ficción para dedicarse casi por completo a la divulgación científica. Además, desde noviembre de 1958, y hasta su muerte en 1992, publicó un ensayo científico mensual en la revista "Fantasy and Science Fiction", la mayoría de los cuales fueron posteriormente recopilados y editados. A continuación una lista de los libros de divulgación científica traducidos al español:


Asimov también escribió historias de misterio ("El negociante de muerte", "Asesinato en la convención", las historias de los Viudos Negros: "Cuentos de los viudos negros" [1971,1972,1973,1974], "Más cuentos de los viudos negros" [1976] y "El archivo de los viudos negros" [1980]) y de fantasía ("Azazel").

Hacia el fin de su vida Asimov publicó una serie de recopilaciones de "limericks" (clase popular de poemas humorísticos de cinco líneas), siendo la mayoría su propia obra, comenzando con "Versos humorísticos lascivos" (1975). "" ("Versos: Demasiado brutos"), cuyo título muestra su amor a los juegos de palabras, contiene 144 "limericks" de Asimov y un número igual del poeta John Ciardi. "Tesoros del humor de Asimov" es a la vez un libro de chistes y un tratado sobre su teoría de humor. Según Asimov, el elemento más esencial del humor es un cambio súbito de punto de vista que de repente mueve el foco desde lo importante a lo trivial, o desde lo sublime a lo ridículo.

Asimov publicó su autobiografía en dos tomos: "En la memoria todavía verde" (1979) y "En la alegría todavía sentida" (1980). Una tercera autobiografía, "", se publicó en 1994. El epílogo lo escribió su viuda, Janet Asimov, poco después de la muerte de Isaac. "Ha sido una buena vida" (2002), redactada por Janet, es una versión resumida de las tres autobiografías.

Gran parte de la ficción de Asimov se basa en el tema del paternalismo. Su primera historia de robots, "Robbie", cuenta la historia de una niñera robótica. A medida que los robots se hacen más sofisticados, sus intervenciones son más sutiles. En "Evidencia" un robot camuflado como humano consigue un cargo electo. En "El conflicto evitable", los robots le quitan el protagonismo a la Humanidad, actuando como niñeros de la especie humana.

Posteriormente, en "Robots e Imperio", un robot desarrolla lo que se llama la «Ley Cero de la robótica», que establece que «un robot no puede dañar a la Humanidad, o, por inacción, permitir que ésta se ponga en peligro». También decide que la presencia robótica está sofocando la libertad de la Humanidad, por lo que la mejor línea de acción es la desaparición por sí mismos, la de los robots. Una historia que no es de robots, "El fin de la eternidad", muestra un conflicto similar y una misma resolución.

En la serie de la Fundación, que originalmente no tenía robots, el personaje Hari Seldon desarrolla la ciencia llamada psicohistoria a través de la que podrá lograrse crear un imperio después de 1.000 años. Esta serie tiene su propia versión de los guardianes de la República de Platón en el libro "Segunda Fundación", que perfeccionan y protegen el plan. Cuando Asimov termina de escribir la serie en los años cincuenta, la Segunda Fundación eran presentados como los protectores de la Humanidad. Cuando en los años ochenta revisita la serie, le da un tono aún más explícito al tema paternalista.

En "Los límites de la Fundación" introduce el planeta «Gaia», obviamente basándose en la hipótesis Gaia. Todo animal, planta y mineral de Gaia participan de una conciencia común, formando una super-mente que trabaja conjuntamente para el bien común. Al final de esta novela, el protagonista Golan Trevize debe decidir si permite o no el desarrollo de «Galaxia», una mayor versión de Gaia que abarca toda la galaxia. Además se introduce a los robots en el universo de la Fundación.

Aun así, es en "Fundación y Tierra" donde aparecen los primeros robots de la serie que interactúan con los personajes. Y las posteriores precuelas, "Preludio a la Fundación" y "Hacia la Fundación", exploran su comportamiento con mayor detalle. Los robots se han revelado como ocultos benefactores de la humanidad.

Otro tema frecuente, tal vez el revés del paternalismo, es la opresión social. "Las corrientes del espacio" toma lugar en un planeta donde crece un fibro-vegetal único, y a los campesinos los explotan los aristócratas de un planeta cercano. El héroe de «En la arena estelar» ayuda a un planeta que es oprimido por un arrogante imperio interplanetario, los Tyrann.

Las víctimas de la opresión son muchas veces la gente de la Tierra (a diferencia de colonos en el espacio) o los robots. En «El hombre Bicentenario» un robot lucha contra el prejuicio para hacerse aceptar como humano. En "Bóvedas de acero", la gente de la Tierra siente antipatía hacia los ricos «espaciales» de otros planetas y trata a los robots (asociados con los espaciales) de una forma semejante a la de los estadounidenses blancos trataban a los negros a principios del siglo XX, por ejemplo, dirigiéndose a ellos como "muchacho". "El guijarro en el cielo" muestra una situación parecida: el Imperio Galáctico gobierna la Tierra y su gente usa términos tales como "Miserable terrícola" (Earthie-squaw), sucio terráqueo o simplemente terráqueo, pero la Tierra es una dictadura teocrática que impone la eutanasia a todos a la edad de sesenta años. Los héroes son Bel Arvardan, hidalgo galáctico que tiene que superar sus prejuicios y Joseph Schwartz, un sesentón estadounidense del siglo XX que había emigrado desde Europa, donde su pueblo fue perseguido (es bien posible que fuera judío), y se encuentra transportado en el tiempo hasta la época de Arvardan. Tiene que decidir si ayuda a una sociedad oprimida que no lo considera apto para seguir viviendo.

Otro tema frecuente de Asimov es el pensamiento racional. Fusionó el misterio policíaco con la ciencia ficción en la novela "Bóvedas de acero" (1954) y en los cuentos de "Misterios de Asimov", en los que generalmente jugaba limpio con el lector introduciendo temprano toda ciencia y tecnología involucrada en la resolución de la trama. Más tarde produjo obras de ficción policíaca, incluyendo la novela "Asesinato en la convención" y los "Cuentos de los viudos negros", en los que siguió la misma regla. Frecuentemente en toda su ficción, las escenas importantes son esencialmente debates, siendo el ganador el lado más racional, el más humanitario, o simplemente el más persuasivo.

En una entrevista en 1988 con Bill Moyers, Asimov propuso el aprendizaje electrónico, donde la gente usaría computadoras para encontrar información sobre temas en los que estaban interesados y esto haría más interesante aprender, puesto que la gente tendría la libertad de escoger qué aprender y ayudaría a difundir el conocimiento alrededor del mundo.

Las principales críticas a la obra temprana de Asimov giraban en torno a que no abordaba temas de sexualidad de sus personajes y que tampoco incluía criaturas extraterrestres, lo que a los ojos de algunos lectores dotaba a sus libros de cierta frialdad y cientifismo difícil de asimilar. Sin embargo, en sus obras más tardías intentó compensar estas críticas introduciendo este tema, ya fuese en forma jocosa, como en "Playboy y el Dios mucoso", o seriamente, como en la novela "Los propios dioses" ("The Gods Themselves"), escrita en 1972 y ganadora de los premios Hugo y Nébula, que parece haber sido escrita como una respuesta a estas críticas. En ella trata ampliamente ambas temáticas. Asimov se mostró especialmente satisfecho de esta obra y a la parte central de la novela la consideró lo mejor de sus escritos.

La razón para no incluir extraterrestres en sus obras es explicada por el propio Asimov en uno de sus libros, en uno de los comentarios previos al relato (que según el propio autor algunos lectores consideran mejores que los relatos en sí). En una de sus primeras historias, "Homo Sol", la civilización humana entra en contacto con la "Federación", compuesta por seres humanoides, que no son humanos. Los humanos, aunque más atrasados en lo tecnológico cuentan con un gran potencial de expansión y aprendizaje. Esto pareció agradar bastante a John W. Campbell (editor de Asimov y escritor anterior a la edad de oro). Sin embargo, para Campbell «humano» significaba, por defecto, occidental del norte de Europa. Este enfoque no fue del agrado de Asimov (de origen ruso-judío) y para evitar este tipo de conflictos, decidió crear galaxias únicamente humanas, en las que no se hace referencia a razas.

Otros criticaban la falta de personajes fuertes femeninos en sus obras iniciales. Asimov se excusó aduciendo su falta de experiencia inicial como escritor prácticamente juvenil. Sin embargo, a medida que avanza en su obra, los personajes femeninos ganan importancia, como Susan Calvin en "Yo, Robot", Noys Lambert en "El Fin de la Eternidad", Arkady en "Segunda Fundación", Bliss en "Fundación y Tierra", Gladia Solaria en "Los robots del amanecer" o Dors Venabili además de Bayta Darell ("Fundación e Imperio") en las secuelas de la "trilogía original de Las Fundaciones".

Durante la década de 1980, embarcado por presiones editoriales en sucesivas continuaciones de la serie "Fundación" y en pleno auge del movimiento Ciberpunk, la visión positiva de Asimov de la ciencia y la tecnología fue denostada por esta corriente literaria, más crítica hacia sus desviaciones y abusos.

Varias obras de Isaac Asimov han sido la fuente de muchas películas.

"El fin de la eternidad" tuvo una versión cinematográfica soviética ("Konets vechnosti", 1987).

"Anochecer" (1988), también conocida como "La muerte de los soles", de Paul Mayersberg. Adaptación para televisión de un relato de Asimov en el que se cuenta la historia de un planeta en el que no conocen la noche al contar con tres soles. Cuando se produce un eclipse, el caos y el miedo se apoderan de sus habitantes.
Con David Birney y Sarah Douglas.

En 1999, Chris Columbus dirigió una adaptación cinematográfica de la novela "El hombre bicentenario" protagonizada por Robin Williams, "El hombre bicentenario".

En 2004 se produce una película "Yo, robot", dirigida por Alex Proyas y protagonizada por Will Smith. Aunque se atribuye la historia a las Series de Robots del mismo nombre, "Yo, robot", en realidad está basada en un guion de Jeff Vintar, titulado "Hardwired". Algunas ideas de Asimov acerca de los robots —la más importante, las tres leyes de la robótica— fueron añadidas al guion de Vintar después de que los productores adquirieron los derechos sobre el título del libro. La película tiene también alguna semejanza con un cuento de ciencia ficción de 1939 (pre-Asimov), "Yo, robot", de Eando Blinder, que trata de un robot humanoide “inteligente”, quien es culpado de la muerte de su creador.

Asimov también colaboró en "Star Trek" como asesor científico. En los 70 y 80 fue un asiduo de las convenciones organizadas por los "fans" de la serie de televisión "Star Trek". «"Star Trek" es el programa de ciencia ficción más inteligente que se hace para televisión», declaró Asimov en una convención.

En abril de 2018, se conoció la noticia de que Apple preparaba una adaptación a televisión de la saga de "La Fundación". La serie televisiva será escrita y producida por David S. Goyer y Josh Friedman, y detrás de la producción estaría la empresa Skydance, quienes producen Grace and Frankie y Altered Carbon para Netflix y Jack Ryan para Amazon.

En honor de Asimov se nombró al asteroide, (5020) Asimov y al cráter Asimov, en el planeta Marte.

A lo largo de su dilatada trayectoria literaria recibió numerosos premios y honores entre los que destacan:

En 1965, Asimov tenía catorce doctorados honoris causa por diferentes universidades.





</doc>
<doc id="15310" url="https://es.wikipedia.org/wiki?curid=15310" title="Ficus benghalensis">
Ficus benghalensis

El baniano (Ficus benghalensis), nombre común que comparte con otras especies del género "Ficus", es un árbol endémico de Bangladés, India y Sri Lanka. 

Puede crecer hasta convertirse en un árbol gigante que se extiende por varias hectáreas. "Ficus benghalensis" produce raíces aéreas en las ramas que crecen hacia abajo como si fueran lianas. Una vez que estas raíces llegan al suelo, arraigan y se vuelven leñosas y de soporte, se vuelven raíces fúlcreas.

Recibe otros nombres más sugerentes, por ejemplo higuera de Bengala, higuerote o higuera estranguladora. Lo de higuera se debe a que ésta también es de la familia de los higos y lo de estranguladora a que empieza siendo epífito, es decir, apoyándose en otro árbol al que termina asfixiando. De este hecho procede también otro nombre de muchas especies de "Ficus" con el que se conoce en Venezuela y en otros países americanos: el de matapalo.

Esta planta es original de la India y de Ceylán (Sri Lanka). Los banianos, al igual que las distintas especies de matapalos, se reproducen fácilmente por semilla o por estaca, y a menudo se van extendiendo desde el lugar original mediante raíces aéreas que anclan en el suelo y comienzan a crecer y engrosarse hasta el punto de que se "independizan" del tronco original, logrando así "emigrar" a veces a grandes distancias, tal como se ve en la imagen tomada en Caracas. En dicha imagen puede verse como el tronco original de un baniano se inclina hacia la calle (Avenida La Salle en Caracas) desarrollando numerosas raíces que pueden soldarse y convertirse en troncos que sirven de sostén, con lo que pueden alcanzar cierta distancia hasta llegar a un lugar donde existe un mayor grado de insolación, en este caso, la propia avenida, lejos de los edificios que hay a ambos lados de la misma. Se trata de una simple adaptación a unas condiciones ecológicas muy complejas.

Es polinizado por avispas de los higos de los géneros "Pegoscapus" o "Pleistodontes".

Las semillas de los banianos pueden caer y crecer cerca de un árbol, a veces del propio árbol de donde proceden las mismas, y también suelen fructificar en alguna oquedad de un tronco o de una pared o roca. Poco a poco empiezan a crecer ya que tienen gran capacidad de apoyarse como epífitas en cualquier objeto que les sirva para ascender en busca de los rayos solares. En condiciones normales, el árbol crece hasta que alcanza un nivel donde consigue la mayor cantidad de luz solar, por lo cual su altura puede variar considerablemente. Por ello, donde este árbol predomina en un lugar, más que crecer en altura se van extendiendo en superficie, buscando los claros que quedan sin vegetación. Por lo general, la copa de este árbol se extiende sobre un diámetro bastante superior a su altura.

Muchos pueblos de Asia hacen vida social debajo de los banianos, pues les protege de los rayos del Sol. A través de sus raíces y ramas la gente pasea, construye templos, y pone mercadillos. De hecho, el nombre de baniano viene de los mercadillos. Los mercaderes ambulantes recibían el nombre de banianos. Como era habitual que pusieran sus tenderetes bajo estos árboles, se llegó a identificar el nombre de los árboles con el de los vendedores ambulantes.

Budistas e hindúes lo consideran un árbol sagrado. 
Se dice que Buda alcanzó la iluminación sentado bajo un baniano.
De sus frutos se han obtenido medicinas contra la lepra y la diabetes . El sabor del fruto no es muy atractivo para los humanos, pero hay monos a los que les encanta . Lo mismo ocurre con murciélagos y ciertas aves. Los elefantes comen sus hojas con deleite.

El baniano más famoso es el del Jardín Botánico de Calcuta. Tiene más de 230 años de edad y ocupa una superficie de 12.000 metros cuadrados; más o menos un círculo con un diámetro de 120 m. La circunferencia del tronco principal es de más de doce metros. 

A pesar de esa fama, el libro Guinness de Récords nos dice que el más grande también está en un ciudad india, en la ciudad de Kadiri. El árbol en cuestión se llama "Thimmamma Marrimanu". 

Thimmamma, según los lugareños, es el nombre de una mujer que salvó a su marido con su devoción. Una leyenda local dice que si una pareja sin hijos reza a Thimmamma bajo el árbol, al año siguiente tendrá un hijo.

En España hay buenos ejemplares de baniano, especialmente en la isla de Tenerife, aunque nada comparable a los de Calcuta o Kadiri.

En inglés se le llama "Banyan".

"Ficus benghalensis" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 1059–1060. 1753.
"Ficus": nombre genérico que se deriva del nombre dado en latín al higo.

"benghalensis": epíteto geográfico que alude a su localización en Bengala.





</doc>
<doc id="15313" url="https://es.wikipedia.org/wiki?curid=15313" title="Poliomielitis">
Poliomielitis

La poliomielitis, llamada de forma abreviada polio (del griego "πολιός", "poliós": gris; y de "µυελός", "myelós": refiriéndose a la médula espinal) o parálisis infantil, es una enfermedad infecciosa que afecta principalmente al sistema nervioso. La enfermedad la produce el poliovirus. Se llama infantil porque las personas que contraen la enfermedad son principalmente niños. Se transmite de persona a persona a través de secreciones respiratorias o por la ruta fecal oral. La mayoría de las infecciones de polio son asintomáticas. Solo en el 1 % de casos, el virus entra al sistema nervioso central (SNC) vía la corriente sanguínea. Dentro del SNC, el poliovirus preferentemente infecta y destruye las neuronas motoras, lo cual causa debilidad muscular y "parálisis aguda flácida".

La poliomielitis es más probable que ocurra en niños de 4 a 15 años en climas templados, en verano cálido e invierno un poco frío. Es una enfermedad muy infecciosa, pero se combate con la vacunación. La enfermedad afecta al sistema nervioso central. En su forma aguda causa inflamación en las neuronas motoras de la médula espinal y del cerebro y lleva a la parálisis, atrofia muscular y muy a menudo deformidad. En el peor de los casos puede causar parálisis permanente o la muerte al paralizarse el diafragma.

El 24 de octubre se celebra el Día Mundial de la Poliomielitis.

La poliomielitis fue descrita por primera vez por el alemán Jakob Heine en 1840. Durante las epidemias agudas de polio a principios del siglo XX, se definieron varias categorías de poliomielitis para clasificar la extensión y gravedad de la enfermedad. Dos patrones básicos de infección por polio se describieron: una de menor cuantía, que no afectaba el sistema nervioso central (SNC), llamado "polio abortivo", y la enfermedad mayor, con parálisis o no. 

La poliomielitis empezó a controlarse en 1949 cuando el bacteriólogo John Franklin Enders logró cultivar el virus en laboratorio dentro de tejidos. Basándose en esa técnica el epidemiólogo Jonas Edward Salk desarrolló una vacuna para los tres tipos de poliomielitis conocidos. Tras las pruebas clínicas pertinentes que demostraron que era segura, en 1954 se empezó la inoculación. La vacuna Salk, como se la conoce, es inyectable.

En 1964 se autorizó otra vacuna que había sido desarrollada por Albert Bruce Sabin. Se la llamó trivalente porque atacaba a los tres tipos de virus mencionados. A diferencia de la vacuna de Salk, esta se administraba por vía oral, por lo que muy rápidamente la Sabin sustituyó a la Salk.

En muy poco tiempo hubo campañas masivas de vacunación y como consecuencia de todo ello, el 21 de junio de 2002, la Organización Mundial de la Salud (OMS) declaró a la región europea libre del virus de la polio. Esta región está formada por cincuenta y un países y ochocientos cincuenta millones de habitantes. El último caso, en esta región, se dio en Turquía en noviembre de 1998. América, fue la primera región en el mundo en ser certificada libre de polio salvaje en 1994, al tener el último caso en Perú en 1991.

En 1988, la OMS emprendió un programa mundial de erradicación. «Cuando iniciamos la campaña de erradicación en 1988, la polio dejaba paralíticos todos los días a más de mil niños», informó la doctora Gro Harlem Brundtland, la entonces directora general de la OMS, quien añadió: «En 2001 hubo mucho menos de mil casos en todo el año». La polio ya solo está activa en menos de diez países.

En mayo de 2014, la OMS hizo pública una nota de alerta por la situación de extensión de la poliomielitis en áreas endémicas y no endémicas, en concreto Pakistán y Afganistán en Asia central, Siria e Irak en Oriente Medio, y Camerún y Guinea Ecuatorial en África central.

El 24 de octubre de 2019, la OMS confirmó la erradicación en todo el mundo de la polio tipo 3.

La Organización Mundial de la Salud declara que una zona está libre de una enfermedad cuando transcurren tres años sin que se dé ningún caso.

En 1994, la OMS consideró a la región de América (36 países) libre de polio, en el año 2000 lo hizo con la región del Pacífico (37 países, incluyendo China). En junio de 2002 se declaró a Europa zona libre de polio, lo que supone para sus 870 millones de habitantes .

La OMS empezó su campaña para erradicar la poliomielitis en 1988. En esa época seguía siendo endémica en todo el mundo, y de hecho aquel año hubo 350 000 infectados. Durante 2005, sólo unas 1880 personas en todo el mundo contrajeron la enfermedad. A comienzos de 2006, y después de haber sido erradicada de Egipto y Níger, la OMS ha declarado que sólo quedan tres países en el mundo en que la enfermedad sigue siendo endémica. Estos son Nigeria, Pakistán y Afganistán. La OMS, Unicef, los Centros para el Control y la Prevención de Enfermedades de Estados Unidos (CDC) y Rotary International han anunciado que redoblarán los esfuerzos en aquellos países, con lo cual estiman que en dos años más no se producirán nuevos casos de la enfermedad. Luego habrá que esperar tres años más para que la poliomielitis sea declarada oficialmente como erradicada.

Si se consigue será la tercera enfermedad infecciosa eliminada de la faz de la Tierra. La primera fue la viruela, y la segunda la peste bovina. No obstante, en 2014, este objetivo se ve aún no cercano, ya que se ha comprobado transmisión del virus y la presencia de la enfermedad en diversos países, como: Pakistán, Afganistán, Iraq, Siria, Nigeria, Guinea Ecuatorial, Camerún y Etiopía. Se han notificado en los 4 primeros meses de 2014 un total de 68 casos incluyendo algunos en países no endémicos (en 2013 fueron 417 casos registrados).

La poliomielitis es una infección causada por un miembro del género Enterovirus conocido como poliovirus (PV). Este grupo de virus ARN prefiere el tracto gastrointestinal e infecta y causa enfermedad solo en los seres humanos. Su estructura es muy sencilla, compuesta de un solo genoma ARN de sentido (+) encerrado en una cáscara de proteínas llamada cápside. Además de proteger el material genético del virus, las proteínas de la cápside del poliovirus permite la infección exclusiva de ciertos tipos de células en el hospedador. Se han identificado tres serotipos de poliovirus: el poliovirus tipo 1 (PV1), tipo 2 (PV2), y el tipo 3 (PV3), cada uno con una secuencia de proteínas en la cápside ligeramente diferentes. Los tres serotipos son extremadamente virulentos y producen los mismos síntomas de la enfermedad. El PV1 es la forma más común, y la más estrechamente relacionada con la parálisis causada por la poliomielitis.

Las personas expuestas al virus, ya sea por infección o por la inmunización con la vacuna contra la poliomielitis, desarrollan inmunidad protectora. Los individuos inmunes tienen los anticuerpos IgA contra la poliomielitis presentes en las amígdalas y el tracto gastrointestinal y son capaces de bloquear la replicación del virus, mientras que los anticuerpos IgG e IgM contra PV puede prevenir la propagación del virus a las neuronas motoras del sistema nervioso central. La infección o la vacunación con un serotipo de poliovirus no proporciona inmunidad contra los otros serotipos, y la inmunidad plena requiere la exposición a cada serotipo.

La poliomielitis es altamente contagiosa y se propaga fácilmente de persona a persona. En las zonas endémicas, el poliovirus salvaje es capaz de infectar prácticamente a toda la población humana. La poliomielitis es una enfermedad estacional en los climas templados, con el pico de transmisión produciéndose en verano y otoño. Estas diferencias estacionales son mucho menos pronunciadas en las zonas tropicales. El tiempo entre la primera exposición y la aparición de los primeros síntomas, conocido como el periodo de incubación, es normalmente entre 6 a 20 días, con una separación máxima de 3 a 35 días. Las partículas del virus se excretan en las heces durante varias semanas tras la infección inicial. La enfermedad se transmite principalmente a través de la ruta fecal-oral, por ingestión de alimentos o agua contaminada. A veces es transmitida a través de la ruta oral-oral, un modo especialmente visible en zonas con buen saneamiento e higiene. El virus es más infeccioso entre los días 7-10 previos de la aparición de los síntomas, pero la transmisión es posible siempre y cuando el virus permanece en la saliva o las heces. 

Los factores que aumentan el riesgo de infección por poliomielitis o que afectan la gravedad de la enfermedad incluyen la deficiencia inmune, la desnutrición, la amigdalectomía, la actividad física inmediatamente después del inicio de la parálisis, lesiones al músculo esquelético debido a la inyección de las vacunas o agentes terapéuticos, y el embarazo. A pesar de que el virus puede atravesar la placenta durante el embarazo, el feto no parece ser afectado por una infección materna o de la vacunación de la madre contra la poliomielitis. Además, los anticuerpos maternos atraviesan la placenta, proporcionando una inmunidad pasiva que protege al bebé de la infección de poliomielitis durante los primeros meses de vida.

Durante la infección activa, el Poliovirus entra en el cuerpo a través de la boca, infectando a las primeras células con las que entra en contacto a nivel de la faringe y la mucosa intestinal. Logra el ingreso a las células por medio de la unión a un receptor tipo inmunoglobulina, conocido como el receptor del poliovirus o CD155, en la superficie de la célula. El virus entonces secuestra la maquinaria propia de la célula hospedadora, y se comienza a reproducir. El poliovirus se multiplica en las células gastrointestinales durante aproximadamente una semana, desde donde se extiende a las amígdalas —específicamente las células foliculares dendríticas que residen en los centros germinales tonsilares—, el tejido linfoide intestinal, incluyendo las células M de las placas de Peyer, y los ganglios cervicales y mesentéricos profundos, donde se multiplica abundantemente. El virus es posteriormente absorbido por el torrente sanguíneo.

La presencia de virus en el torrente sanguíneo —conocida como viremia primaria— permite que sea ampliamente distribuido en todo el cuerpo. El poliovirus puede sobrevivir y multiplicarse dentro del torrente circulatorio y linfático durante largos períodos, a veces hasta las 17 semanas. En un pequeño porcentaje de los casos, se puede propagar y reproducir en otros sitios, tales como grasa parda, tejidos retículoendoteliales y musculares. Esta replicación sostenida es una de las principales causas de que haya un incremento de la viremia, y conduce a la aparición de síntomas catarrales. Raramente, la infección logra progresar de tal forma que el virus invade el sistema nervioso central, provocando una respuesta inflamatoria localizada. En la mayoría de estos casos lo que provoca es una inflamación auto-limitada de las meninges, las capas de tejido que rodean el cerebro, lo que se conoce como meningitis aséptica no-paralítica. La penetración del SNC no ofrece ningún beneficio para el virus, y es probable que no sea más que una desviación accidental de la infección gastrointestinal normal. Los mecanismos por los que la poliomielitis se propaga hasta el SNC son poco conocidos, pero parece ser ante todo un evento oportunista, en gran medida independiente de la edad o sexo de la persona.

El síndrome postpolio (PPS por sus siglas en inglés) es una afección que ataca a los supervivientes de la polio. Aproximadamente del 20 al 40 % de las personas que se recuperan de la polio pueden desarrollar PPS. El comienzo del PPS puede ocurrir en cualquier momento de 10 a 40 años después de declararse la infección y puede progresar lentamente durante diez años, produciendo síntomas como fatiga extrema, dolor muscular y atrofia muscular en nuevas fibras musculares así como en aquellas previamente afectadas.

El término "poliomielitis" se refiere para identificar la enfermedad causada por cualquiera de los tres serotipos de poliovirus. Se suelen describir dos patrones de infección de la polio: una enfermedad leve que no se asocia con el sistema nervioso central (SNC), a veces llamado la poliomielitis abortiva, y una forma que se asocia con una enfermedad grave del SNC, que pueden ser o no-paralítica. En la mayoría de las personas con un sistema inmune normal, una infección por poliovirus resulta ser asintomática. Ocasionalmente la infección produce síntomas menores, que pueden incluir infección del tracto respiratorio superior (dolor de garganta y fiebre), trastornos gastrointestinales (náuseas, vómitos, dolor abdominal, estreñimiento o, rara vez, diarrea), catarro y enfermedades similares.

El virus entra en el sistema nervioso central en torno al 3 % de las infecciones. La mayoría de los pacientes con toque del SNC no paralítico desarrollan una meningitis aséptica, con síntomas de dolor de cabeza, cuello, espalda, dolor abdominal y extremidades, fiebre, vómitos, letargo e irritabilidad. Aproximadamente 1 de cada 200 a 1 de cada 1000 casos, la enfermedad progresa a la forma paralítica, en la que los músculos se debilitan, se tornan hipotónicos y con movimientos mal controlados y, por último, completamente paralizados, condición que se conoce como la "parálisis fláccida aguda". Según el sitio de la parálisis, la poliomielitis paralítica se clasifica como espinal, bulbar, o bulbospinal. La encefalitis, una infección del tejido cerebral en sí, se puede producir en raras ocasiones y generalmente se limita a los niños. Se caracteriza por la confusión, cambios en el estado mental, dolores de cabeza, fiebre, convulsiones y con menos frecuencia la parálisis espástica.

En más del 95 % de los casos, la infección es asintomática, de modo que la enfermedad tiene en ellos un curso inaparente pero capaz de estimular una respuesta inmune formadora de anticuerpos. Otras formas mucho menos frecuentes incluyen una variedad respiratoria grave, una poliomielitis paralítica bulbar, la polioencefalitis y formas monofásicas. Con mucha más frecuencia se registran formas catarrales, pre-paralítica y paralítica. 

Seguido de un período de incubación de 7-14 días aparecen aproximadamente tres días de una enfermedad caracterizada por fiebre, dolor de garganta, fatiga y, a menudo, diarrea y vómitos. Para más de tres cuartas partes de estos pacientes, la consecuencia es la mejora, de donde proviene la palabra "abortiva": el fin del curso de la infección. Las células del sistema nervioso central (SNC) no están afectadas.

Aproximadamente el 5 % de los pacientes sintomáticos puede tener afectación del sistema nervioso central, en la que los síntomas anteriores, el pródromo instalan la enfermedad actual. Tras esa fase febril y quebrantos de aproximadamente una semana, estos pacientes desarrollan una meningitis aséptica que aparece como un complejo bifásico. La primera caracterizada por una fiebre recurrente de unos 39 °C y dolor de cabeza y rigidez en el cuello. El líquido cefalorraquídeo puede tener un leve aumento en el número de células y un ligero aumento de la concentración de proteína. La segunda fase suele cursar con irritación meníngea y afectación del sistema nervioso autónomo.

Normalmente se inicia con fiebre, que ocurre de 5 a 7 días antes que otros síntomas. Aparecen luego fatiga extrema, dolor muscular y atrofia muscular que causa parálisis flácida, proximal y asimétrica pudiendo incluso afectar la respiración y la deglución. Es un curso muy infrecuente, presentándose en 0,01 % de los pacientes sintomáticos. Pasados varios años, debido a la parálisis y la evolución de la estática de la columna vertebral, aparecen trastornos como la escoliosis y deformidades permanentes.

La poliomielitis paralítica puede ser sospechada clínicamente en individuos que experimentan la aparición aguda de la parálisis flácida en uno o más miembros con la disminución o ausencia de reflejos tendinosos en los miembros afectados, que no puede atribuirse a otra causa aparente, y sin pérdida sensorial o cognitiva.

Un diagnóstico de laboratorio se suele realizar sobre la base de la recuperación de poliovirus de una muestra de heces o un hisopo de la faringe. Los anticuerpos contra el poliovirus puede ser de utilidad diagnóstica, y en general son detectados en la sangre de pacientes infectados temprano en el curso de la infección. El análisis del líquido cefalorraquídeo (LCR), que se obtiene por medio de una punción lumbar, por lo general revela un aumento del número de glóbulos blancos (linfocitos principalmente) y un nivel ligeramente elevado de proteínas. La detección del virus en el LCR es diagnóstico de poliomielitis paralítica, pero rara vez ocurre. 

En caso de que el poliovirus sea aislado de un paciente que experimenta la parálisis flácida aguda, se hacen pruebas a través del mapeo de oligonucleótidos (genético) o, más recientemente, la amplificación por PCR, para determinar si se trata de un "tipo salvaje" (es decir, el virus encontrado en la naturaleza) o "tipo de vacunas" (derivado de una cepa de poliovirus utilizadas para producir la vacuna contra la poliomielitis). Es importante determinar la fuente del virus, porque por cada caso notificado de poliomielitis paralítica causada por poliovirus salvaje, se estima que existirían otros 200-3000 sujetos portadores asintomáticos y contagiosos del virus.

En todo el mundo, se emplean dos tipos de vacuna contra la poliomielitis. La primera fue desarrollada por Jonas Salk, probada por primera vez en 1952 y fue dada a conocer por Salk el 12 de abril de 1955. La segunda vacuna fue una vacuna oral desarrollada por Albert Sabin usando poliovirus atenuados. Los ensayos clínicos de la vacuna Sabin iniciaron en 1957 y fue autorizada en 1962.

En abril de 2013, durante la Cumbre Mundial de las Vacunas que tuvo lugar en Abu Dabi, la Organización Mundial de la Salud presentó el programa "Plan estratégico integral para la erradicación de la poliomielitis y la fase final 2013‒2019", que pretende erradicar la polio en el mundo para el 2019. Según datos de esta institución, en 1988 se reportaron 350 000 casos en al menos 125 países en donde la enfermedad era endémica, mientras que en 2016 solo se reportaron 37 nuevos infectados. El "poliovirus" tipo 2 se declaró erradicado en 1999 y el "poliovirus" tipo 3, en 2012; persistiendo desde entonces solamente el tipo 1, cuya trasmisión se da de forma natural únicamente en Afganistán y Pakistán.

Con fecha 14 mayo de 2014, según el seguimiento de la OMS, siguen registrándose casos en países endémicos (Pakistán y Afganistán) y se registra nuevos casos en zonas no endémicas (Guinea Ecuatorial, Camerún, Irak, Siria, Etiopía). Esta situación indica la peligrosa progresión de la polio que motiva la declaración de emergencia internacional.

En 1913 y con solo 6 años de edad, la pintora mexicana Frida Kahlo contrajo esta enfermedad, que la obligó a permanecer 9 meses en la cama y le dejó como secuela de por vida la pierna derecha más delgada que la izquierda. Como consecuencia de ello, se encuentran diversas obras donde la pintora refleja la soledad que sentía durante la enfermedad. Algunas de sus obras más famosas ligadas a la poliomielitis y a la soledad de su infancia son: "Cuatro habitantes de Ciudad de México" (1938), "Niña con máscara de muerte" o "Ella juega sola" (1938) y "Día de los Muertos."




</doc>
<doc id="15315" url="https://es.wikipedia.org/wiki?curid=15315" title="APL">
APL

APL ("A Programming Language)" es un lenguaje de programación que se originó a partir de la notación matemática desarrollada por Kenneth Iverson en 1957, quien lo implementó en 1962 cuando fue contratado por IBM en ese mismo año. 

El APL es un lenguaje aplicativo o un lenguaje para aplicar algo, similar a un lenguaje funcional.

Utiliza operadores parametrizables, por lo que es muy conciso. Su sintaxis está basada en pocos "operadores" y utiliza un conjunto especial de caracteres que no están presentes en el código ASCII. El conjunto de operaciones se fundamenta en álgebra lineal abstracta, por lo que es un lenguaje idóneo para trabajar con vectores y matrices. Cuenta con un repertorio de operadores que le permite componer nuevas operaciones lógicas o matemáticas. 

Al contar con productos cruz y puntos generalizados, una sola oración puede traducirse en muchas líneas de otros lenguajes, como Fortran, Basic, PL1, C, etc. Ya que, en estos, estas operaciones y otras se implementan mediante "loops" o ciclos iterativos (bucles).

Un ejemplo de ello es el lenguaje de simulación de circuitos, SIAL, que habiendo ocupado aproximadamente 25 000 oraciones en el lenguaje Fortran-Assembler, pasó al ser reescrito en APL a ocupar dos folios en su versión impresa. Por otra parte, a pesar de ser un lenguaje de tan alto nivel, también es capaz de manipular a escala de bits y tiene interfaces con lenguajes de programación de bajo nivel (C, ensamblador, etc.) mediante los llamados procesadores auxiliares.

Tiene la propiedad de que desde una rutina se puede (en tiempo de ejecución) crear, compilar y ejecutar, otras, lo que lo hace también muy apropiado para la elaboración automática de compiladores e intérpretes.

Algunas dificultades prácticas radican en que:

APL puede resolver un sistema de ecuaciones en una sola oración si lo aplicamos a un sistema de ecuaciones concreto. Por ejemplo:

7x + 4y + 2z = 4

6x + 8y + 9z = 7

4x + 2y + 1z = 2

Basta ejecutar UNA ÚNICA oración de APL, cuya sintaxis es:
4 7 2 ⌹ 3 3 ρ 7 4 2 6 8 9 4 2 1
Donde el operador ρ (rho) formatea la lista de números en una matriz de 3x3. El operador ⌹ ("dominó") calcula la inversa de la matriz y la multiplica por el vector 4 7 2, generando la solución para cada variable (x, y, z):

El programa anterior, podría utilizar bibliotecas para las operaciones con matrices, Fortran permite arreglos redimensionables, y es adecuado para el cómputo en paralelo. Pero se necesitan algunas declaraciones para los arreglos y llamar a las subrutinas, y en otros lenguajes poco flexibles para crear subrutinas con arreglos, todavía es más complicado porque se tienen que codificar mediante "loops" la inversión de la matriz y el producto, mínimo unas 20 líneas.

El APL, permite pensar directamente en las operaciones algebraicas que se pueden expresar de manera muy concisa, por ello permite tiempos de desarrollo y pruebas muy cortos. Por ello es un lenguaje muy adecuado para campos muy variados, tales como los de Matemáticas, Estadística, Negocios, Inteligencia artificial, Desarrollo de prototipos, etc.

Entre sus aplicaciones más conocidas está su uso en la película "Tron", de Walt Disney, para la generación de los efectos especiales,

Como curiosidad, en la novela "Cheap Complex Devices", de J. C. Sundman, el autor afirma que el contenido del libro ha sido escrito automáticamente por un ordenador, usando código generado en APL, lo que le valió el premio Douglas R. Hofstadter, de creación de novelas por ordenador, en 1997. Todo ello, naturalmente, es un artificio literario.

Kenneth Iverson, posteriormente, estuvo al frente del desarrollo de un lenguaje de programación, que presentaban como el sucesor de APL, llamado J. Una de las características particulares de J es lo que se ha dado en denominar programación funcional tácita, en que se considera que, para expresar programas, no es necesario nombrar variables, ni parámetros a funciones (Estos conceptos de programación tácita han sido incorporados al lenguaje Logo en la biblioteca LogoFE). En J, la variedad de las rutinas (que en APL se llaman "operadores"), es mucho mayor.

John Backus en la cátedra que dio al recibir el premio Turing, presentó FP/FFP. FP es un lenguaje funcional y FFP son formas funcionales, que se basaron en el lenguaje aplicativo APL. Un ejemplo de las formas funcionales en APL es la operación reduce codice_1 que reduce un vector aplicando el operador. codice_2 computa codice_3, en algunos lenguajes como algunos dialectos de Lisp conservó el nombre reduce, que se heredó a otros lenguajes funcionales.





</doc>
<doc id="15316" url="https://es.wikipedia.org/wiki?curid=15316" title="Huelga">
Huelga

La huelga es una forma de protesta en la que sus participantes o miembros se abstienen de realizar la actividad que realizan normalmente en perjuicio de aquellos a los que dirigen sus reclamos o sus quejas. El tipo más importante y extendido es la huelga laboral o paro que es la suspensión colectiva de su actividad por parte de los trabajadores con el fin de reivindicar mejoras en las condiciones de trabajo o manifestarse contra recortes en los queridos derechos sociales; según la Organización Internacional del Trabajo, es uno de los medios legítimos fundamentales de que disponen los ciudadanos y específicamente los trabajadores (a través del movimiento sindical y las organizaciones sindicales) para la promoción y defensa de sus intereses económicos y sociales. 

La primera "huelga" documentada ocurrió en el Antiguo Egipto, organizada por los trabajadores y artesanos de Set Maat (actual Deir el-Medina) durante el reinado de Ramsés III, hacia el año 1166 a. C.

La huelga está asociada a la demanda de mejores condiciones de trabajo, al desarrollo del movimiento sindical y a la expansión del sindicalismo internacional y, en general, a la lucha de clases. Aunque sus orígenes se remontan a la Revolución francesa de 1789 su pleno desarrollo se produce con la Revolución industrial y la generalización del trabajo asalariado a finales del siglo XVIII y principios del siglo XIX.

El origen de la huelga unido al movimiento sindical: Los primeros movimientos obreros se sitúan en Inglaterra. Allí apareció el "ludismo" conducido por Ned Ludd y conocido como el movimiento de los "rompedores de máquinas" (1810-1811). En años posteriores, 1830, aparecen las primeras organizaciones obreras de carácter gremial (trabajadores que se dedican sólo a un oficio). En Inglaterra tomaron el nombre de "trade-unions" (literalmente «agrupaciones gremiales») y más adelante, por la tendencia a abreviar en inglés, "unions" («sindicato» o «unión sindical»). 

A los movimientos sindicales de distinto signo (anarquismo, comunismo, socialismo) van también asociados al desarrollo teórico de la existencia de una clase trabajadora obligada a desarrollar una lucha de clases para el reconocimiento de valor como fuerza de trabajo en la creación de riqueza. La práctica de la huelga es considerada como una herramienta para reivindicar mejoras en las condiciones de trabajo. El derecho de huelga es otra de la reivindicaciones del movimiento sindical. En este sentido las Combination Acts (leyes inglesas que prohibían los sindicatos) no fueron derogadas hasta 1824.

El inicio del desarrollo teórico se produce básicamente por Karl Marx y Engels en el «Manifiesto Comunista» y el posterior desarrollo en libros como "El Capital" en el que se propugna, para alcanzar objetivos de la clase trabajadora, una revolución.

El desarrollo de la socialdemocracia en el siglo XX contribuyó a que la huelga laboral dejara de estar severamente penalizada. Fue entonces cuando el derecho de huelga fue reconocido internacionalmente como un derecho esencial de los trabajadores constitutivo de la libertad sindical. Se trata de uno de los derechos de segunda generación, que se reconoce en la actualidad en la mayoría de los ordenamientos internos y en tratados internacionales de alcance universal como el Pacto Internacional de Derechos Económicos, Sociales y Culturales.

Las huelgas, como modo de protesta y reivindicación, pueden clasificarse del siguiente modo:


La huelga laboral, dependiendo de sus características, puede ser:

Además, puede ser:


En algunos países como México, Argentina, Uruguay, Chile, Ecuador y Perú, se le denomina comúnmente paro. Este término se refiere generalmente al abandono de tareas laborales, aunque también comúnmente se llama paro a toda movilización, protesta, manifestación, reclamo público, abandono de tareas o actuación de piquetes.

En algunos países como Ecuador, el Derecho del Trabajo y en concreto el código de trabajo ecuatoriano en su artículo 525 indica que la "huelga" es la suspensión de actividades organizada por trabajadores y el "paro" (cierre patronal), es realizado por los empleadores.





</doc>
<doc id="15318" url="https://es.wikipedia.org/wiki?curid=15318" title="Steve Jobs">
Steve Jobs

Steven Paul Jobs (San Francisco, California; 24 de febrero de 1955-Palo Alto, California; 5 de octubre de 2011), más conocido como Steve Jobs, fue un empresario y magnate de los negocios en el sector informático y de la industria del entretenimiento estadounidense. Fue cofundador y presidente ejecutivo de Apple y máximo accionista individual de The Walt Disney Company.

Fundó Apple en 1976 junto con un amigo de la adolescencia, Steve Wozniak, con ayuda del excompañero de Jobs en Atari, Ronald Wayne, en el garaje de su casa. Aupado por el éxito del Apple II, Jobs obtuvo una gran relevancia pública, siendo portada de "Time" en 1982. Contaba 26 años y ya era millonario gracias a la exitosa salida a bolsa de la compañía a finales del año anterior. La década de los 80 supuso la entrada de potentes competidores en el mercado de los ordenadores personales, lo que originó las primeras dificultades empresariales.

Su reacción fue innovar, o mejor dicho, implementar: a principios de 1984 su compañía lanzaba el Macintosh 128K, que fue el primer ordenador personal que se comercializó exitosamente que usaba una interfaz gráfica de usuario (GUI) y un ratón en vez de la línea de comandos. Después de tener problemas con la cúpula directiva de la empresa que el mismo fundó, renunció. Jobs vendió entonces todas sus acciones, salvo una. Ese mismo año recibía la Medalla Nacional de Tecnología del presidente Ronald Reagan, cerrando con este reconocimiento esta primera etapa como emprendedor. Regresó en 1997 a la compañía, que se encontraba en graves dificultades financieras, y fue su director ejecutivo hasta el 24 de agosto de 2011. En ese verano Apple sobrepasó a Exxon como la empresa con mayor capitalización del mundo.

Durante los años 1990 transformó una empresa subsidiaria adquirida a Lucasfilm en Pixar, que revolucionó la industria de animación con el lanzamiento de "Toy Story". La integración de esta compañía en Disney, de la que era proveedor, convertiría a Jobs en el mayor accionista individual del gigante del entretenimiento. En el año de su muerte, su fortuna se valoraba en 8300 millones de dólares y ocupaba el puesto 110 en la lista de grandes fortunas de la revista "Forbes".

En su segunda etapa en Apple, también cambió el modelo de negocio de la industria musical: aprobó el lanzamiento del iPod en 2001, y en 2003 la tienda "online" de música de iTunes, que en siete años vendió más de 10 000 millones de canciones y dominó completamente el negocio de música en línea, a un precio de 0,99  USD por canción descargada. Ya en 2009 lograba acaparar el 25 por ciento de la venta de música en los Estados Unidos, y es la mayor tienda musical por volumen de ventas de la historia. Según el registro de patentes de los Estados Unidos, 323 patentes de Jobs figuran a nombre de Apple.

Steve Jobs nació en San Francisco (California) en 1955, fruto de la relación entre Abdulfattah Jandali, un inmigrante sirio musulmán, luego doctorado en ciencias políticas, y Joanne Carole Schieble, una estadounidense de ascendencia suiza y alemana, por entonces dos jóvenes estudiantes universitarios que lo entregaron en adopción a una pareja de clase media, Paul Jobs y Clara Hagopian, de origen armenio. Sus padres biológicos se casaron luego y tuvieron otra hija, la novelista Mona Simpson, a quien Steve no conocería hasta la edad adulta. En esa nueva familia Steve creció junto a su otra hermana, Patty. Su padre adoptivo, Paul Jobs, era maquinista en la compañía estatal de transporte ferroviario y su madre ama de casa.

En 1961 la familia se trasladó a Mountain View, una ciudad al sur de Palo Alto que empezaba a convertirse en un centro importante de la industria de la electrónica. Allí asistió a la escuela primaria Cupertino Middle School y a la secundaria Homestead H.S., también en Cupertino. A Jobs le interesaban bastante la electrónica y los gadgets, razón que le llevó a unirse a un club llamado "Hewlett-Packard Explorer Club", donde ingenieros de Hewlett-Packard mostraban a los jóvenes sus nuevos productos. Fue allí donde Steve vio su primera computadora, a la edad de 12 años. Quedó tan impresionado que supo de inmediato que él quería trabajar con computadores. 

Ya en la secundaria asiste a charlas de Hewlett-Packard. En una ocasión, Steve preguntó al por entonces presidente de la compañía, William Hewlett, sobre algunas partes que necesitaba para completar un proyecto de clase. William quedó tan impresionado que se las proporcionó y le ofreció realizar unas prácticas de verano en su compañía. Steve sería luego contratado como empleado veraniego, coincidiendo allí con Steve Wozniak por medio de un amigo mutuo, Bill Fernandez.

En 1972 entra en la universidad Reed College de Portland (Oregón). Asiste a ella tan solo 6 meses antes de abandonarla, debido al alto coste de sus estudios. En lugar de regresar a casa, continúa asistiendo a clases como oyente unos 18 meses más, viviendo a base de trabajos con ingresos ínfimos. Curiosamente, sus estudios en caligrafía, enseñada por Robert Palladino, le serían de utilidad cuando diseñara las tipografías del primer Mac. 

Tras dos años fuera de casa, en otoño de 1974 regresa a California con el objetivo de realizar un retiro espiritual en la India y consigue un trabajo como técnico en Atari Inc., empresa fabricante de videojuegos, donde colaboró en la creación del juego "Breakout". De la mano de Steve Wozniak comienza a asistir a las reuniones del Homebrew Computer Club, donde Wozniak le contó que estaba intentando construir un pequeño computador casero. Jobs se mostró especialmente fascinado con las posibilidades mercantiles de la idea de Wozniak y le convence para fabricar y vender uno. Steve Jobs se encarga de las ventas y negociaciones y Steve Wozniak, en secreto, de construir la máquina electrónica.

Según afirma Nolan Bushnell, luego de su regreso de la India, a donde fue acompañado por un antiguo compañero de la escuela secundaria y más tarde primer empleado de Apple, Daniel Kottke, decidió renunciar a Atari y fundar "Apple Computer". Steve ofreció a Bushnell un porcentaje de Apple, 50 000 dólares, el cual no aceptó.
Durante este tiempo, experimentó con drogas psicodélicas, LSD, llamando a sus experiencias como "una de las dos o tres cosas más importantes que había hecho en su vida".

Debido a las exigencias de su contrato con Hewlett-Packard, Wozniak tuvo que dar a conocer su intención de construir un computador personal a la empresa, que desechó la idea por considerarla ridícula. Fue así como en 1976 nació Apple Computer Company.

Tras la consecución del primer computador personal, bautizado como Apple I, Jobs se dedicó a su promoción entre otros aficionados a la informática, tiendas y ferias de electrónica digital, llegando a vender unos 200 ejemplares. A partir de entonces, el crecimiento de Apple fue notable. En tan solo 10 años, Apple se convirtió en una empresa con 4.000 empleados y Jobs, con 27 años, era el millonario más joven de 1982. 
A principios de 1983 vio la luz Lisa, el primer computador personal con Interfaz gráfica del usuario diseñado especialmente para gente con poca experiencia en informática. Su precio, más caro que el de la mayoría de ordenadores personales de la competencia, no facilitó que el nuevo producto fuese precisamente un éxito de ventas, perdiendo Apple aproximadamente la mitad de su cuota de mercado en favor de IBM.

En un intento por mantener la competitividad de la compañía, Steve Jobs, ya convertido en ejecutivo, convenció a John Sculley, director ejecutivo de Pepsi-Cola, para tomar las riendas de Apple.

En la conferencia anual de Apple del 24 de enero de 1984, Jobs presentó con grandes expectativas, el Apple Macintosh, el primer ordenador personal de Apple con ratón. Sin embargo Macintosh no alcanzó las expectativas comerciales esperadas.

Hacia finales de 1984 las diferencias entre Sculley y Jobs se iban haciendo cada vez más insalvables, hasta el punto de deteriorarse la relación, principalmente por el proyecto macintosh. En mayo de 1985, en medio de una profunda reestructuración interna que se saldó con el despido de 1200 empleados, Sculley relegó a Jobs de sus funciones como líder de la división de Macintosh.

Tras varios meses de resignación, el 17 de septiembre de 1985, Steve Jobs abandonó la compañía que él mismo había fundado.

En esa época Jobs había desarrollado un estilo gerencial agresivo y un liderazgo irrespetuoso con sus empleados; a pesar de todo, se le consideró como el empresario más exitoso de su generación.

Tras abandonar Apple en 1986, Steve Jobs compra por 5 millones de dólares la empresa The Graphics Group destinando otros 5 millones adicionales como inversión, conocida en lo sucesivo como Pixar, una subsidiaria de Lucasfilm especializada en la producción de gráficos por computador. 

Steve Jobs empezó a firmar varios acuerdos para producir películas animadas para la compañía Walt Disney. En 1995 se estrenó en los cines "Toy Story", el primer largometraje generado completamente por computadora, conseguido con su propio software de renderización, RenderMan. Toy Story fue el mayor éxito de taquilla de 1995 y la primera película del binomio Walt Disney-Pixar en ganar un premio Óscar.

En noviembre de 2001, Pixar estrena "Monsters, Inc.", recaudando con ella 780 millones de dólares en todo el mundo, convirtiéndose en la película animada más taquillera hasta ese momento. Sus éxitos siguieron con "Buscando a Nemo" (2003), "Cars" (2006), "WALL·E" (2008) y "Up" (2009), entre otras, las cuales obtuvieron la aprobación de la crítica y el público.

En los años 2003 y 2004, cuando el contrato de Pixar con Disney se estaba acabando, el director ejecutivo de Disney, Michael Eisner, intentó sin éxito negociar un nuevo acuerdo, y a principios de 2004, Jobs anunció que Pixar podría buscar un nuevo socio para distribuir sus películas después de que expirara su contrato con Disney. En octubre de 2005, Bob Iger sustituyó a Eisner en Disney y trabajó rápidamente para enmendar las relaciones con Jobs y Pixar. El 24 de enero de 2006, Jobs e Iger anunciaron que Disney había acordado comprar Pixar en una transacción de acciones por un valor de 7.400 millones de dólares. Cuando el acuerdo se cerró, Jobs se convirtió en el mayor accionista individual en la compañía de Walt Disney, con aproximadamente el siete por ciento de las acciones de la empresa. Una vez completada la fusión, Jobs recibió ese 7 % y se incorporó al Consejo de Administración como el mayor accionista individual. Después de la muerte de Jobs, sus acciones de Disney fueron trasladadas al Fideicomiso Steven P. Jobs, dirigido por Laurene Jobs.

Tras dejar Apple, a los 30 años de edad, decidió continuar su carrera empresarial en la industria de la computación y fundó la empresa NeXT Computer Inc., con una inversión de 7 millones de dólares. Reunió para el nuevo proyecto a 7 de sus antiguos empleados en Apple: Bud Tribble, George Crow, Rich Page, Susan Barnes, Susan Kare y Dan'l Lewin. En el plan de negocios se estableció que, al igual que se hacía en Apple, la compañía vendiese al cliente no solo el hardware, sino también el sistema operativo y parte del software de usuario.

La primera estación de trabajo de NeXT fue presentada el 12 de octubre de 1988. Recibiría oficialmente el nombre de NeXT Computer, si bien fue ampliamente conocida como "El Cubo" ("The Cube", en idioma inglés) por su distintiva caja de aleación de magnesio en forma de cubo. El sistema operativo de la nueva máquina fue bautizado como NeXTSTEP. 

Las ventas de los computadores de NeXT fueron relativamente modestas, con un total estimado de 50 000 unidades en los 10 años que estuvo operativa la división de hardware. Su sistema operativo orientado a objetos y entorno de desarrollo fueron, en cambio, muy influyentes. A pesar de su escasa penetración en el mercado, uno de estos equipos sirvió para que el científico Tim Berners Lee creara el concepto de World Wide Web que revolucionaría a la red Internet.

Como consecuencia, Jobs en 1993 centró la estrategia de su compañía en la producción de software, cambiando el nombre de la empresa por el de Next Software Inc. Uno de las decisiones más llamativas fue la venta de equipos NeXT construidos alrededor de los microprocesadores Intel 486 y SPARC.

Apple Computer anunció el 20 de diciembre de 1996 la adquisición de NeXT Software por 400 millones de dólares con el fin de actualizar el sistema operativo de las computadoras Macintosh, después del fracaso de la compañía con "Copland", un proyecto que nunca llegó a terminarse. Así, Steve Jobs volvió a formar parte de la compañía Apple.

La vuelta de Steve Jobs a la empresa Apple se produjo cuando la empresa se encontraba en declive, así que se decidió a recuperar el control de ésta, se ganó la confianza de la dirección de la compañía en detrimento del entonces director ejecutivo, Gil Amelio, logrando que se lo nombrara director interino el 16 de septiembre de 1997.

Algunas de las primeras medidas de Jobs en su nuevo puesto fueron firmar un acuerdo con Microsoft, por el cual esta empresa invertiría dinero en Apple a cambio de un 4 % de sus acciones, aunque este porcentaje no le diera el derecho a voto en las decisiones de la junta directiva de la empresa; el suministro del software de ofimática Office para los computadores Macintosh y el fin de las disputas por la interfaz gráfica. La noticia de esta medida no fue bien recibida.

De similar aceptación resultaron la cancelación del programa de licencias de Mac OS a otros fabricantes de hardware, como "Power Computing", empresa que sería finalmente adquirida por Apple, lo que impidió la popularización de esta plataforma informática y el descontinuar el "Apple Newton", un dispositivo de características similares a un asistente digital personal. 
Estas medidas, sin embargo, permitieron a la compañía centrar sus esfuerzos en mejorar sus productos y probar nuevas líneas de negocio, como la tienda digital de música "iTunes Store", los reproductores de audio iPod y los computadores iMac, que resultaron ser un gran éxito.

En 2006 Jobs firmó un contrato con Intel para utilizar procesadores de la arquitectura x86 en todos sus computadores de escritorio y portátiles.

En diciembre de 2009 Steve Jobs fue elegido director ejecutivo del año por la revista "Harvard Business Review" por «incrementar en 150 000 millones el valor en bolsa de Apple en los últimos 12 años».

El 24 de agosto de 2011 presentó su renuncia como CEO de Apple, y fue sustituido por Tim Cook. A partir de esta fecha y hasta su muerte, fue el presidente de la Junta Directiva de Apple.Horas después del anuncio, se redujo en 5 puntos porcentuales el valor de las acciones de Apple. Según la revista de finanzas Forbes, la renuncia afectaría negativamente a Apple y otras empresas, incluyendo Walt Disney Company donde Jobs era director. El día 24 de agosto de 2011, el valor de las acciones de Walt Disney Co. se redujo en 1,5 puntos porcentuales.

Estuvo casado desde 1991 con Laurene Powell, a quien conoció en la Universidad de Stanford. Vivieron en Palo Alto, California, con sus tres hijos. Steve tuvo además otra hija llamada Lisa, fruto de una relación de juventud con Chris Ann Brennan. Su paternidad no la reconoció sino hasta 1991. Sufrió varios problemas graves de salud. En 2004 se le diagnosticó un cáncer de páncreas, enfermedad que superó tras un tratamiento en una clínica oncológica californiana. A principios del 2009 anunció que padecía un desequilibrio hormonal y que debía apartarse necesariamente de la compañía, y delegó la mayor parte de sus responsabilidades en Timothy Cook, por entonces jefe de comunicaciones. En abril de 2009 se sometió a un trasplante de hígado, y en septiembre de ese mismo año volvió al trabajo. El 17 de enero de 2011, Jobs dejó nuevamente Apple por problemas médicos, a poco más de un mes de la presentación del iPad 2. Mientras tanto, la compañía quedó a cargo de Tim Cook.Jobs presentó públicamente el iPad 2 el miércoles 2 de marzo.No obstante, declaró que desde su residencia seguiría ocupándose de las decisiones más relevantes de la compañía, como en efecto ocurrió.

En octubre de 2003 se le diagnosticó un cáncer, y a mediados de 2004 anunció a sus empleados que tenía un tumor canceroso en el páncreas.

A principios de agosto de 2006 Jobs realizó una presentación en la Conferencia Anual de Desarrolladores de Apple (WWDC). Su aspecto demacrado y delgado y su inusual presentación apática, junto con la delegación de la exposición de partes importantes a otros participantes, suscitó una oleada de especulaciones acerca de su salud. Sin embargo, de acuerdo con un artículo de Ars Technica los asistentes a la Conferencia que vieron a Jobs dijeron que tenía buen aspecto. Después de la presentación un portavoz de Apple dijo que Steve tenía una salud de hierro.

Dos años después también surgieron preocupaciones tras la presentación de la WWDC de 2008. Los responsables de Apple afirmaron que Jobs padecía una afección corriente y que estaba tomando antibióticos, mientras que otros achacaban su estado demacrado al procedimiento Whipple aplicado en su cirugía. Durante una conferencia en julio en la que se discutía sobre los beneficios de Apple, los participantes respondieron a las preguntas sobre la salud de Jobs que era un “asunto privado”. Otros opinaron que los accionistas tenían el derecho a saber más dado el estilo personal de Jobs al dirigir la compañía. "The New York Times" 
publicó un artículo basado en una conversación telefónica “extraoficial” con Jobs en la que decía que “aunque sus problemas de salud eran más que una afección corriente, no suponían una amenaza a su vida y que no tenía ninguna reaparición de cáncer.”

El 28 de agosto de 2008 el servicio de noticias de empresa Bloomberg publicó por error un obituario de Jobs de 2500 palabras que contenía espacios para su edad y la causa de la muerte. (Las agencias de noticias suelen ir actualizando obituarios para facilitar la salida de noticias para el caso en que una persona conocida muera de forma repentina). Aunque el error se rectificó inmediatamente, muchas agencias de noticias escribieron sobre él, intensificando los rumores sobre la salud de Jobs. Jobs respondió en el discurso de apertura de “Let's Rock” de septiembre de 2008 citando a Mark Twain:
“Las noticias de mi muerte son muy exageradas”. En un acto posterior Jobs terminó su presentación con una diapositiva en la que se leía “110/70”, en referencia a su presión sanguínea, y dijo que no respondería más preguntas sobre su salud.

El 16 de diciembre de 2008 Apple anunció que el vicepresidente de marketing Philip W. Schiller daría el último discurso en la Conferencia Macworld de 2009. Esto reactivó las preguntas sobre la salud de Jobs. En una declaración del 5 de enero de 2009 en Apple.com, Jobs dijo que había estado sufriendo un desequilibrio hormonal durante varios meses.

El 14 de enero de 2009 en un memorando interno de Apple Jobs escribió que la semana anterior supo que los asuntos relacionados con su salud eran más complejos de lo que pensaba, y anunció una excedencia de seis meses hasta el final de junio de 2009 para poder centrarse en su salud. Tim Cook, que anteriormente había sido Director Ejecutivo durante la ausencia de Jobs en 2004, volvió a ser Director Ejecutivo en funciones, estando Jobs involucrado en las “decisiones estratégicas fundamentales”.

En abril de 2009, Jobs fue sometido a un trasplante de hígado en el Methodist University Hospital Transplant Institute en Memphis, Tennessee. El diagnóstico fue descrito como “excelente”.

El 17 de enero de 2011, un año y medio después de su trasplante de hígado, Apple anunció que le había concedido una excedencia por enfermedad. Jobs anunció su salida en una carta a sus empleados, afirmando que tomó su decisión “para poder centrarse en su salud”. Como en la excedencia por enfermedad de 2009, Apple anunció que Tim Cook llevaría las operaciones cotidianas y que Jobs seguiría involucrado en las decisiones estratégicas importantes. A pesar de la excedencia, tuvo apariciones en el lanzamiento del iPad 2 el 2 de marzo, la presentación WWDC introduciendo iCloud el 6 de junio, y ante el Ayuntamiento de Cupertino el 7 de junio.

Jobs anunció su renuncia como Director Ejecutivo de Apple el 24 de agosto de 2011. “Desafortunadamente, ese día ha llegado”, escribió Jobs, “porque ya no puedo cumplir mis deberes y expectativas como Director Ejecutivo de Apple”. Jobs pasó a Presidente del Consejo de Administración y nombró a Tim Cook como su sucesor. Jobs trabajó para Apple hasta el día antes de su muerte.

Steve Jobs falleció en su casa de California a las 2 de la tarde del 5 de octubre de 2011, a los 56 años, a consecuencia de un paro respiratorio derivado de las metástasis del cáncer de páncreas que le fue descubierto en 2004, por el que en 2009 había recibido un trasplante de hígado. 
El día anterior había perdido la conciencia y murió estando su esposa, hijos y hermana a su lado.
Su muerte fue anunciada por Apple con una declaración:

Jobs deja a Laurene, su esposa durante 20 años, tres hijos y a Lisa Brennan-Jobs, su hija de una relación anterior. Su familia hizo una declaración diciendo que murió en paz.

Según dijo en el funeral su hermana biológica, Mona Simpson, Jobs miró a su hermana Patty, luego a sus hijos durante un largo rato, después a su esposa Laurene. Sus últimas palabras dichas unas horas antes de su muerte fueron 

En las dos semanas posteriores a su muerte la Web de Apple presentó una página con el nombre de Jobs, su fecha de nacimiento y fallecimiento y un retrato en blanco y negro. Haciendo clic en la imagen se presentaba la nota necrológica que decía:

También Pixar dedicó a Jobs su página web. John Lasseter y Ed Catmull, escribieron un discurso que decía:

Un pequeño funeral privado tuvo lugar el 7 de octubre de 2011 cuyos detalles no han sido revelados por respeto a la familia de Jobs. 

Jobs está enterrado en Alta Mesa Memorial Park, el único cementerio no confesional de Palo Alto.

Importantes personalidades declararon su pesar por el fallecimiento de Steve Jobs, entre ellos: Barack Obama (44° presidente de los Estados Unidos), Bill Gates y Paul Allen (cofundadores de Microsoft Windows), Sergey Brin y Larry Page (cocreadores de Google), Steven Spielberg (reconocido cineasta estadounidense), Steve Wozniak (compañero cofundador de Apple) y Mark Zuckerberg (cofundador de Facebook) entre otros.

Bill Gates:
Steve Wozniak:
Steven Spielberg:
Mark Zuckerberg:

Richard Stallman es fundador del movimiento por el software libre en el mundo y de la GNUPedia, considerada como un antecedente directo de la Wikipedia: 

El pionero del software libre Richard Stallman disintió de las hagiografías mayoritarias para centrar la atención en el férreo control que Apple tuvo sobre las computadoras y los aparatos portátiles, cómo Apple restringió el acceso a los periodistas y cómo violó la privacidad continuamente: “Steve Jobs, el pionero de la computadora como una cárcel hecha atractiva, diseñada para recortar a los necios su libertad, ha muerto”.

El reportero de Silicon Valley Dan Gillmor dijo: 

Aunque los reporteros escribieron elegías elogiosas tras la muerte de Jobs, el crítico James Rainey de Los Angeles Times escribió que: 
Malcolm Gladwell en The New Yorker afirmó que: 

El día de su muerte la capitalización bursátil de "Apple" era de 350 670 millones de dólares. Cuando salió a bolsa en 1980 una acción costaba, según su precio ajustado, lo que hoy serían unos dos euros. El día en que murió, una acción valía más de 280 euros (377 dólares) incluyendo unos intereses financieros envidiables. Estos datos avalan el reconocimiento como ejecutivo que lo acompañó en la última etapa de su carrera. En palabras de Rupert Murdoch, «Steve Jobs fue simplemente el mejor consejero delegado de su generación.» Coincidía en ello con la revista "Harvard Business Review", que ya lo reconoció como tal a finales del 2009.








</doc>
<doc id="15320" url="https://es.wikipedia.org/wiki?curid=15320" title="Butano">
Butano

El butano, también llamado n-butano, es un hidrocarburo saturado, parafínico o alifático, inflamable, gaseoso que se licúa a presión atmosférica a -0,5 °C, formado por cuatro átomos de carbono y por diez de hidrógeno, cuya fórmula química es CH.También puede denominarse con el mismo nombre a un isómero de este gas: el isobutano o metilpropano.

El butano comercial es un gas licuado, obtenido por destilación del petróleo, compuesto principalmente por butano normal (60%), propano (9%), isobutano (30%) y etano (1%).

Como es un gas incoloro e inodoro, en su elaboración se le añade un odorizante (generalmente un mercaptano) que le confiere olor desagradable. Esto permite que se detecte en caso de fugas, porque al ser muy volátil puede acumularse en un recinto y provocar una explosión.

Para extinguir un fuego originado por gas butano se emplean distintos métodos, como dióxido de carbono (CO), polvo químico o niebla de agua.

La principal aplicación del gas butano (CH) es como combustible en hogares para cocinar, calentar agua, en estufas y en los encendedores de gas de bolsillo. 

En España el gas butano se transporta en la típica, bombona o garrafa de butano, que es un envase cilíndrico, de paredes de acero, normalmente de color naranja (también llamado por ello "color butano"), y que contiene 12,5 kg de butano, que en su mayor parte está en estado líquido, a presión. También existen nuevas bombonas de butano más ligeras, fabricadas con acero inoxidable en lugar de hierro fundido.

Su regulación aparece en el Real Decreto 1085/1992 de 11 de septiembre por el que se aprueba el Reglamento de la actividad de distribución de Gases Licuados del Petróleo. En su artículo 22, determina las obligaciones de los titulares de los contratos de dicho suministro. Entre ellas, se encuentra la revisión de la instalación cada cinco años por una empresa instaladora legalmente habilitada para ello.Similares medidas se han tomado en otros países.

Su fórmula estructural es:


La inhalación de butano puede causar euforia, somnolencia, inconsciencia, asfixia, trastornos del ritmo cardíaco, fluctuaciones en la presión sanguínea, pérdida temporaria de la memoria, cuando se abusa directamente de un recipiente presurizado, y puede resultar en la muerte por asfixia y fibrilación ventricular. Entra al torrente sanguíneo; y, en segundos produce intoxicación. 

El butano es la sustancia volátil más comúnmente mal utilizada en el Reino Unido y fue la causa del 52% de las muertes relacionadas con solventes en 2000. Al rociar butano directamente en la garganta, el chorro de líquido puede enfriarse rápidamente hasta −20 ºC por expansión, causando prolongado . Un "síndrome de muerte súbita", descripto por primera vez, en 1970, es la causa única más común de muerte relacionada con solventes, lo que resulta en el 55% de casos fatales conocidos.

Una pequeña cantidad de dióxido de nitrógeno, un gas tóxico, resulta de la quema de gas butano, junto con cualquier combustión en la atmósfera de la tierra, y representan un peligro para la salud humana, por calentadores y estufas a butano.




</doc>
<doc id="15321" url="https://es.wikipedia.org/wiki?curid=15321" title="Bartsia trixago">
Bartsia trixago

Bartsia trixago es una planta anual común en caminos y cunetas (rara en cultivos) originaria de Europa circum-mediterránea y Norte de África.
Se trata de una planta hemiparásita -de raíces y sin huésped específico-, en pastizales y herbazales de secano. 
Lo más llamativo de su inflorescencia es la corola bilabiada, que puede ser discolora, y sus grandes brácteas. Sus flores pueden variar de tonos blancos a rosados, pero es habitual encontrar ejemplares con flores completamente amarillas, pudiendo confundirse con "Parentucellia viscosa", de aspecto muy similar.

Llega hasta 70 cm de altura, pero normalmente no pasa de los 40-50 cm. Los tallos son erectos, simples o poco ramificados. Las hojas (14)20–60(73) por (2)4–9(12) mm, opuestas, amplexicaules, erecto–patentes, rectas o incurvas, lineares o linear–lanceoladas, remotamente aserradas, estrigosas. La inflorescencia mide 2–16 cm, en racimo espiciforme, denso y las brácteas hasta 25 por 8(12) mm, con indumento muy denso, las inferiores foliáceas, las superiores enteras, ovadas, cordadas. Las flores son zigomorfas, hermafroditas, pentámeras, subsésiles con un cáliz 4–10 mm, ventricoso, dividido en 2 labios laterales bilobados y una de corola 10–20 mm, bilabiada, puberulento–glandulosa, blanca con tonos rosados o amarilla, con labio superior galeado y tubo de 8–10 mm, más largo que el cáliz.
El fruto es una cápsula de 6–12 por 4–6 mm, ovoidea, pelosa con semillas de 0,6–0,7 por 0,4–0,5 mm, algo reniformes, pardo–claras, casi rosadas. El número de cromosomas es de 2n = 24.

Esta especie de origen circummediterráneo ha sido introducida en América, Australia y Sudáfrica. También ha llegado a colonizar las Islas Canarias y Madeira, probablemente como especie exótica invasora.

Tiene gran indiferencia edáfica, pues está ligada a la presencia de plantas que parasita, que será el único requisito para su establecimiento. Pero muestra cierta predilección por suelos básicos, zonas calizas y yesíferas.
La podemos encontrar en herbazales y pastizales efímeros, cunetas y claros de matorral, a veces con cierto comportamiento ruderal.

Crece desde el nivel del mar hasta los 1.300 metros, ocupando los pisos termo y mesomediterráneo. Ombroclima seco. 





</doc>
<doc id="15322" url="https://es.wikipedia.org/wiki?curid=15322" title="Justo José de Urquiza">
Justo José de Urquiza

Justo José de Urquiza (Talar de Arroyo Largo, hoy Arroyo Urquiza, Virreinato del Río de la Plata, 18 de octubre de 1801-Palacio San José, cerca de Concepción del Uruguay, Entre Ríos, 11 de abril de 1870) fue un militar y político argentino. Fue varias veces gobernador de la provincia de Entre Ríos, líder del Partido Federal y de la Confederación Argentina entre 1854 y 1860.

Su padre, Joseph Narciso de Urquiza y Álzaga, era un colono español que se unió en matrimonio con la infanzona María Cándida Ramón-García y Monzón, de origen luso-hispano-argentino, siendo esta una descendiente de los portugueses Inés Nunes Cabral de Melo y de su esposo Gil González de Moura.

Ambos progenitores se radicaron en la intendencia de Buenos Aires, en la actual provincia de Entre Ríos, dedicándose a la actividad rural y a la función pública. Luego de la Revolución de Mayo, en 1810, emigraron a la Banda Oriental para seguir siendo fieles al Reino de España.

Regresaron en 1812, y cinco años más tarde Justo José fue enviado al Colegio de San Carlos en Buenos Aires.

En 1819 se instaló en la pujante villa Arroyo de La China, actual Concepción del Uruguay, dedicándose a la actividad rural y comercial, para la cual demostró una enorme capacidad. Su hermano mayor, Cipriano de Urquiza, fue secretario y luego ministro del primer gran caudillo entrerriano, Francisco Ramírez.

En 1820 tuvo su primera hija extramatrimonial; más tarde tendría muchos más hijos ilegítimos. Una ley sancionada durante su presidencia legalizaría varios de ellos. Le fueron legalmente reconocidos 23 hijos por la Ley Federal N.º 41 en donde ponía en un pie de igualdad a los 11 hijos legítimos con los extramatrimoniales que tuvo de soltero (hay versiones que señalan que tuvo entre 105 y 114 hijos en toda su vida).

En la década de 1820, contando ya con una fortuna que lo respaldaba, se interesó en la política en un período especialmente turbulento en la historia de Entre Ríos. Como muchos jóvenes del interior, su partido era el Federal.

En 1826 fue elegido por los vecinos de Concepción del Uruguay para representarlos como diputado en el congreso provincial. Dirigió la oposición a la Constitución Argentina de 1826, que fue rechazada por su provincia.

Desde 1828 en adelante fue comandante militar y civil de Concepción del Uruguay. Dos años más tarde apoyó la invasión a su provincia del general unitario Juan Lavalle y de Ricardo López Jordán (padre). Tras el fracaso de esa invasión, apoyó otra en 1831 que, al fracasar también, lo obligó a refugiarse en Santa Fe, bajo la protección del caudillo Estanislao López.

Al año siguiente acompañó a Pascual Echagüe en la campaña militar que llevaría a este a la gobernación de Entre Ríos. Bajo su gobierno, Entre Ríos conoció un período de paz, reforzado por la influencia pacificadora del gobernador porteño Juan Manuel de Rosas. A partir de 1835, este gobernó como un dictador electo por el voto popular de su provincia. Extendió su dominio sobre las demás provincias, ejerciendo de hecho un poder central que no le correspondía de derecho. Echagüe hizo un gobierno progresista y se ahorró problemas apoyando a Rosas en su oposición a la sanción de una constitución nacional.

Urquiza fue nombrado comandante de toda la costa del río Uruguay, con el grado de coronel. Durante esa década se convirtió en uno de los hacendados y comerciantes más ricos del país y extendió una poderosa red de clientelismo económico, que le serviría más tarde de apoyo político.

Entre Ríos era un territorio que ocupaba una posición estratégica, ya que estaba cerca de Buenos Aires, de la conflictiva Banda Oriental, del Imperio del Brasil y de la provincia de Corrientes. En su territorio se dieron grandes batallas.

A mediados de 1838, la tranquilidad de la provincia se vio amenazada por la sublevación de Fructuoso Rivera, que derrocó al presidente uruguayo Manuel Oribe. También ese año murió Estanislao López, y Echagüe forzó la ubicación en la gobernación santafesina de su hermano Juan Pablo López.

La primera provincia en rebelarse militarmente contra Rosas fue Corrientes. Su gobernador, Genaro Berón de Astrada retiró la delegación de las relaciones exteriores a Rosas y le declaró la guerra, como así también a Echagüe. Berón tuvo que enfrentar con sus solas fuerzas el ataque que le lanzó Echagüe, uno de cuyos jefes de división era Urquiza.

Los ejércitos se encontraron en la batalla de Pago Largo, cerca de Curuzú Cuatiá, el 31 de marzo de 1839. Fue una completa victoria de los federales, en la que Urquiza tuvo una actuación destacada, y Berón resultó muerto en la persecución que siguió a la batalla. Después de la misma, centenares de prisioneros fueron ejecutados; en general, los correntinos acusaron a Urquiza por esos crímenes.

Después de colocar un gobernador federal en Corrientes, Echagüe pasó con su ejército a Uruguay. Rivera lo derrotó en la batalla de Cagancha, el 29 de diciembre, en la que la indecisión del general Lavalleja fue más importante que la brillante actuación de Urquiza. Desde ese momento, las relaciones de Urquiza con Echagüe fueron muy malas.

En su ausencia, Lavalle había invadido la provincia, pasando a continuación a Corrientes. Allí reunió un nuevo ejército, con el que a mediados de 1840 invadió Entre Ríos. Mientras Urquiza controlaba la costa del Uruguay, Echagüe lo enfrentó en dos batallas indecisas. Urquiza derrotó a uno de los coroneles unitarios en Arroyo del Animal, cerca de Gualeguay. Poco después, Lavalle pasaba hacia la provincia de Buenos Aires; allí intentaría ocupar la capital, pero sería derrotado sin lucha e iniciaría una marcha hacia el norte, encontrando la derrota en Tucumán y la muerte en Jujuy.

Algunos meses después, Echagüe invadió Corrientes, dejando a Urquiza protegiendo sus espaldas. El nuevo comandante de Corrientes era José María Paz que derrotó fácilmente a Echagüe en la batalla de Caaguazú, el 28 de noviembre de 1841.

Poco después de la derrota venció el cuarto mandato de Echagüe. El 15 de diciembre de 1841, la legislatura eligió gobernador a Justo José de Urquiza. No dejaría el poder en la provincia hasta su muerte, casi treinta años más tarde. Fue gobernador durante 18 años, a lo que hay que sumar seis años de federalización de la provincia bajo su propia presidencia, y cuatro de un empleado suyo. En total, 28 años; más que Rosas en Buenos Aires.

La situación era muy delicada; Urquiza emitió una proclama, en que decía que 

Enseguida delegó el mando en Vicente Zapata, y abandonó la capital. Días después, Paz ocupaba Paraná y Rivera Concepción del Uruguay. Urquiza se retiró a la isla del Tonelero, protegida por pantanos y arroyos, donde se puso a organizar un ejército con miles de voluntarios entrerrianos, a quienes formó militarmente. Entre ellos estaba un joven, hijo de un viejo general que estaba prisionero de Rosas por unitario: era Ricardo López Jordán. Durante un corto período se trasladó a la provincia de Buenos Aires.

Paz se hizo elegir gobernador, pero la falta de ayuda del gobernador correntino Pedro Ferré lo obligó a ir en busca de Rivera, cruzando la provincia. En el camino perdió casi todo su ejército, que pasó a engrosar el de Urquiza. Este ocupó Paraná sin oposición, y enseguida inició la campaña en el interior de la provincia.

Simultáneamente, Manuel Oribe regresaba desde el norte, donde había derrotado a Lavalle, y atacó al gobernador santafesino Juan Pablo López (que se había pasado de bando), derrotándolo con facilidad. Echagüe se hizo cargo del gobierno santafesino y Oribe cruzó el Paraná, siguiendo su marcha hacia el Uruguay.

Rivera tomó el mando del ejército unido uruguayo-unitario. Urquiza se unió a Oribe y juntos avanzaron hacia el río Uruguay, cerca del cual derrotaron completamente a sus enemigos en la batalla de Arroyo Grande, el 6 de diciembre de 1842.

Mientras Oribe continuaba su avance hacia Montevideo, ocupando la mayor parte del territorio uruguayo, Urquiza invadió Corrientes, donde colocó un gobernador federal, Pedro Cabral, y dejó una guarnición entrerriana en Goya, al mando del general José Miguel Galán.

Después acompañó el lento - demasiado lento - avance de Oribe hacia la capital uruguaya, a la que puso sitio. Así se iniciaba el período que los uruguayos llaman la "Guerra Grande".

En Corrientes, una reacción dirigida por Joaquín y Juan Madariaga tomó el poder y expulsó a los entrerrianos. Enseguida atacaron Entre Ríos; la defensa quedó a cargo del general uruguayo Eugenio Garzón, mientras una rebelión en el interior de la provincia costaba la muerte de Cipriano de Urquiza. Los correntinos evacuaron Entre Ríos, y Urquiza pudo seguir sus campañas en el Uruguay; allí derrotó a Rivera junto al río Yí, y el 27 de marzo de 1845 lo venció definitivamente en la batalla de India Muerta. Nuevamente fue acusado de haber ejecutado cientos de prisioneros.

El bloque anglo – francés y las actividades de corsarios al servicio del gobierno de Montevideo continuaron afectando al gobierno entrerriano. El capitán italiano Giuseppe Garibaldi saqueó Gualeguaychú; y a los pocos días el griego Cardassy capturó todos los barcos del puerto de Paraná.

En Corrientes, los Madariaga habían puesto al frente de su ejército al general Paz, que organizó un nuevo ejército. Urquiza invadió la provincia y derrotó a Juan Madariaga en la batalla de Laguna Limpia, tomándolo prisionero. Por su archivo se enteró de que Paz pretendía llevarlo hasta el extremo norte de la provincia, para derrotarlo en una trampa parecida a la que había usado para vencer a Echagüe. Por eso continuó avanzando, saqueó la provincia, se hizo amigos correntinos y al llegar hasta la trampa de Paz dio media vuelta y regresó a Entre Ríos.

Desde allí inició negociaciones con el gobernador correntino a través de su hermano. Paz se opuso e intentó derrocar a Madariaga, pero fracasó y terminó huyendo. Urquiza firmó el Tratado de Alcaraz con el gobierno correntino, por el cual se arreglaba la paz y se devolvía el encargo de las relaciones exteriores a Rosas, pero Corrientes quedaba liberada de la obligación de apoyar la guerra en el Uruguay, y además se preveía la pronta convocatoria a un congreso constituyente.

Rosas rechazó el tratado y, contra su voluntad, Urquiza se vio obligado a invadir nuevamente Corrientes. Derrotó a los Madariaga en la batalla de Vences o de Rincón de Vences, el 27 de noviembre de 1847. Según sus detractores, Urquiza habría perpetrado allí su peor matanza de prisioneros. Aunque es probable que ésta haya ocurrido, posiblemente se debió a sus aliados correntinos.

Los Madariaga huyeron al Brasil, y Urquiza puso en el gobierno correntino a su amigo Benjamín Virasoro. La guerra había terminado; por supuesto, aún quedaba Oribe sitiando Montevideo, pero se descontaba que la ciudad caería de un momento a otro.

Su gobierno fue paternalista, en el sentido de que gobernó sin consultar al pueblo, pero en beneficio de este. Gobernaba desde Concepción del Uruguay o desde su campamento militar de Calá. En varios sentidos fue muy similar a Rosas y a otros caudillos de la época. Protegió a la ganadería, favoreció la instalación de saladeros de carne vacuna, hizo exigir la papeleta de conchabo a todos los peones rurales, mejoró los caminos y los puertos, instaló molinos de agua, y ayudó al establecimiento de pequeñas industrias. Ejerció un poder de policía muy eficaz, pero muy cruel, ya que a la menor falta, los delincuentes eran sencillamente ejecutados.

Ordenó llevar la contabilidad con una precisión desconocida hasta entonces. Impuso un control fiscal estricto, y una dedicación intensa a los funcionarios y empleados; redujo el gasto público sin descuidar las funciones del estado, e hizo publicar mes por mes los gastos e ingresos por la prensa.

Su principal preocupación fue la educación; extendió las escuelas primarias que había fundado su antecesor y fundó nuevas escuelas secundarias, públicas y modernas. La primera que fundó fue la de Paraná, dirigida por Manuel Erausquin. Tras una serie de conflictos con el gobierno de esa ciudad, el cuerpo de profesores pasó al otro colegio fundado por Urquiza, el actual Colegio Nacional de Concepción del Uruguay. Tendría un gran auge durante el tiempo en que Buenos Aires se separara de la Confederación, bajo la dirección de Alberto Larroque, que lo transformó en el colegio secundario más moderno de su época, y por muchos años compitió en prestigio con el de Buenos Aires y el de Córdoba.

Se llegaron a publicar tres periódicos simultáneamente; se fundaron teatros, escuelas secundarias de mujeres, bibliotecas públicas, etc. Llamó a su provincia a varios emigrados ilustres, sobre todo a federales antirrosistas, como Pedro Ferré, Manuel Leiva y Nicasio Oroño, pero también a unitarios como Marcos Sastre y otros. El ambiente que se respiraba en la provincia era mucho más libre que el de Buenos Aires u otras ciudades del interior.

El ambiente de libertad, que tanto contrastaba con el de Buenos Aires, llamó la atención de los emigrados y unitarios. Muchos, como Sarmiento o el general Paz, comenzaron a pensar que Urquiza sería el elegido por la historia para convocar un congreso constituyente y derrocar a Rosas.

A pesar de que la ciudad de Montevideo estaba sitiada y en guerra con las provincias argentinas, Urquiza logró mantener abiertos los puertos de su provincia al comercio con esa plaza. Según el punto de vista de Rosas, se trataba de contrabando; pero como el gobernador porteño necesitaba a Urquiza, lo permitió de hecho.

Rosas seguía sosteniendo que, dado que el país no estaba en paz, no era tiempo aún de sancionar una constitución. Pero también es cierto que la misma política exterior de Rosas mantenía el estado de conflicto exterior constante. De hecho, Rosas fue repetidamente acusado de mantener a la Confederación en guerra, para así posponer indefinidamente la sanción de la Constitución.

A mediados de 1850, cuando la ciudad sitiada de Montevideo estaba por caer, el Imperio del Brasil decidió apoyar a los sitiados. En respuesta, Rosas inició el proceso para llegar a una guerra contra el Imperio. Varios opositores interpretaron que el gobernador porteño estaba abriendo un nuevo frente de conflicto, para seguir posponiendo el momento de la sanción de la Constitución; Urquiza se plegó a esa interpretación, pero aún no mostró ningún síntoma en ese sentido.

Rosas lo nombró comandante del ejército de operaciones contra Brasil, y le envió armamento y refuerzos. Pero, al mismo tiempo, le exigió suspender el tráfico mercantil con Montevideo.

Urquiza comenzó a contactar a los emigrados de Montevideo, y posteriormente también a los representantes del Imperio. Para lanzarse a la aventura de enfrentar a Rosas, necesitaba dinero y la seguridad de que sería apoyado. A principios del año siguiente comenzó a llegar ese dinero, en abundancia, provisto por la cancillería brasileña. Entonces Urquiza hizo su primer movimiento.

En enero de 1851 apareció en el periódico "La Regeneración" de Concepción del Uruguay titulado "El año 1851", que indicó el puntapié inicial de la ruptura con Rosas.

El 1.º de mayo de 1851, se anunció el llamado "Pronunciamiento de Urquiza". Se trató de un anuncio de la legislatura entrerriana, en que se aceptaban las repetidas renuncias de Rosas a la gobernación de Buenos Aires y a seguir haciéndose cargo de las relaciones exteriores. Reasumía también el manejo de la política exterior y de guerra de la provincia. Por último, se reemplazaba de los documentos el ya familiar "¡Mueran los salvajes unitarios!", por la frase "¡Mueran los enemigos de la organización nacional!".

Dejando de lado el eufemismo de aceptar las renuncias de Rosas, se trataba de una reacción contra la dominación política y económica de la provincia de Buenos Aires, con objetivos políticos y económicos, ocupando en principio la organización constitucional un lugar secundario.

La única provincia que apoyó el Pronunciamiento fue Corrientes; las demás condenaron en todos los documentos públicos la actitud de Urquiza y, siguiendo el modelo de la prensa porteña, lo tacharon de "loco, traidor, salvaje, unitario…"

A fines de mayo se firmó un tratado entre Entre Ríos, el gobierno de Montevideo y el Imperio del Brasil. Acordaba una alianza entre los tres para expulsar a Oribe, llamar a elecciones libres en todo el territorio uruguayo, y enfrentar juntos a Rosas, si este declaraba la guerra a una de las partes, lo que se daba por descontado.

En julio de ese año, el ejército entrerriano cruzó el río Uruguay. En el camino se le unió la mayor parte del ejército de Oribe, que se puso a órdenes del general Garzón, candidato a presidente de los aliados. Y por el norte entraron los brasileños. El ejército avanzó sin oposición hasta las inmediaciones del campamento del Cerrito, donde se iniciaron conversaciones de paz con Oribe. El 8 de octubre se firmó un pacto entre las partes, por el que las fuerzas de Oribe se incorporaban al ejército de Urquiza, y un olvido de todas las querellas, "ni vencedores, ni vencidos". Oribe se retiró a su estancia, donde moriría pocos años después.

Urquiza incorporó a su ejército, a la fuerza, las tropas argentinas que sitiaban Montevideo, pero dejó escapar a sus jefes. Entre los que se retiraron a Buenos Aires se contaban algunos jefes valiosos, como los coroneles Jerónimo Costa, Hilario Lagos y Mariano Maza.

El congreso uruguayo tuvo que firmar un tratado con el Brasil, por el que se le reconocía al Imperio el derecho de intervenir en su política interna y se le entregaba una gran franja limítrofe, hasta entonces en disputa entre los dos países, poco menos de la tercera parte de su superficie.

Rosas declaró públicamente la guerra al Brasil, lo que permitió a Urquiza firmar un nuevo tratado de alianza contra el gobernante argentino.

Urquiza regresó a Entre Ríos, donde reunió el llamado "Ejército Grande", formado por tropas entrerrianas, correntinas, los emigrados unitarios, los soldados argentinos del sitio, unidades "coloradas" del ejército uruguayo y tropas del Imperio. Con ellas cruzó el río Paraná en buques brasileños y, aprovechando la defección de varias unidades del ejército de Rosas, derrocó al gobernador santafesino Echagüe.

En camino hacia Buenos Aires ocurrió un hecho que mostraba la lealtad de los porteños hacia Rosas. Un regimiento entero se pasó a las fuerzas de Buenos Aires, asesinando al coronel unitario Pedro León Aquino y a casi todos los oficiales; eran de las fuerzas porteñas que habían sido obligadas a unirse a Urquiza en Montevideo.

Como de costumbre, Rosas puso al mando de las fuerzas de la provincia al general Ángel Pacheco; pero este no respondió como debía y dejó avanzar al ejército hacia Buenos Aires. De modo que Rosas cometió un grave error estratégico: asumió él mismo el mando de su ejército y esperó a Urquiza cerca de su campamento de Santos Lugares.

El 3 de febrero de 1852 se encontraron los 24 mil hombres de Urquiza con los 23 mil de Rosas en la batalla de Caseros. 

Tras pocas horas de batalla, la victoria fue para Urquiza. Hubo muchos ejecutados, como los coroneles Martiniano Chilavert y Martín Santa Coloma; y todos los soldados del regimiento de Aquino, que fueron colgados de los árboles del parque de Palermo.

Rosas se exilió en Inglaterra, y Urquiza asumió por sí mismo el gobierno provincial. Dos días después de la batalla nombró gobernador a Vicente López y Planes.

El 20 de febrero, el comandante brasileño anunció el desfile triunfal en Buenos Aires. Pero Urquiza recorrió la ciudad sin esperar al ejército brasileño, ya que era una humillación especialmente buscada, dado que era el aniversario de la victoria argentina de Ituzaingó.

Apenas llegada a Montevideo y a los demás países vecinos la noticia de Caseros, los emigrados emprendieron el regreso a Buenos Aires. Los rosistas, por su parte, no se resignaban a perder su lugar destacado en la sociedad. Así se formaron dos grupos políticos netamente diferenciados: por un lado, los federales o urquicistas, que defendían el proceso de organización nacional bajo un poder federal. Entre sus integrantes estaban Vicente López y Planes, su hijo Vicente Fidel López, Francisco Pico y Juan María Gutiérrez. Por su parte, el Partido Liberal –muy heterogéneo– estaba formado por los partidarios de la ruptura con la Confederación. En sus filas destacaban Valentín Alsina, Bartolomé Mitre, Dalmacio Vélez Sársfield y Domingo Faustino Sarmiento. Todos ellos se oponían a la política de Urquiza, a quien consideraban un caudillo provinciano que aspiraba a dominar a la provincia, a la capitalización de Buenos Aires, y a la nacionalización de los derechos de la aduana. Proponían el aislacionismo de la provincia y aun la secesión de la misma del Estado nacional.

Apenas entrado en Buenos Aires, Urquiza envió una misión a las provincias, para explicar sus intenciones de restablecer la vigencia del Pacto Federal y emprender la organización constitucional. Bernardo de Irigoyen cumplió eficazmente su cometido: las provincias delegaron en Urquiza el manejo de las relaciones exteriores y aceptaron el proyecto de organización nacional.

El 6 de abril, los representantes de Buenos Aires, Corrientes, Entre Ríos y Santa Fe firmaron el Protocolo de Palermo, que restablecía la vigencia del Pacto Federal, delegaba en Urquiza el manejo de las relaciones exteriores y le encargaba la reunión de un Congreso Constituyente. Para agilizar la reunión del congreso constituyente y fundamentar legalmente su autoridad, Urquiza invitó a los gobernadores de todas las provincias a una reunión que se celebraría en San Nicolás de los Arroyos.

El 31 de mayo se firmó el Acuerdo de San Nicolás. El mismo establecía –entre otros puntos– la vigencia del Pacto Federal de 1831; la reunión de un congreso general constituyente en Santa Fe a partir de agosto de ese mismo año, integrado por dos diputados por cada provincia, los cuales actuarían sin instrucciones que restringieran sus poderes; y la creación del cargo de "Director provisorio de la Confederación Argentina", que recayó en el general Urquiza, cuyas funciones no estaban claramente definidas.

El Acuerdo fue ratificado por todas las provincias, con la única excepción de la de Buenos Aires. Allí, la Sala de Representantes, reunida el 1 de mayo y en la que los liberales tenían una amplia mayoría, rechazó el acuerdo argumentando que el poder otorgado a Urquiza era dictatorial.

El gobernador López y Planes presentó su renuncia, que le fue aceptada, y en su reemplazo fue nombrado el presidente de la Legislatura, general Manuel Guillermo Pinto, con carácter provisional. Pero Urquiza —que estaba todavía en Palermo— reaccionó con rapidez: el 24 de junio ordenó a su ejército ocupar la capital, disolvió la Sala de Representantes, repuso en su puesto a López y ordenó la detención y destierro de varios opositores.

El 26 de julio, ante una nueva renuncia de López, Urquiza asumió personalmente el gobierno de Buenos Aires. En su carácter de director provisorio de la Confederación, dispuso la convocatoria al Congreso Constituyente, prohibió la confiscación de bienes en toda la Nación, abolió la pena de muerte por delitos políticos y declaró que el producto de las aduanas exteriores era un ingreso de la Nación.

También reconoció a nombre de la Confederación la independencia del Paraguay –que nunca había sido reconocida por Rosas– por medio de un convenio. A continuación declaró libre la navegación de los ríos por dos decretos de agosto y octubre de 1852.

En septiembre de 1852, Urquiza partió hacia Santa Fe para iniciar las sesiones del Congreso Constituyente, dejando como delegado al general José Miguel Galán.

El 11 de septiembre de 1852 estalló un levantamiento militar con apoyo civil contra la autoridad de Urquiza y su delegado, que se embarcó hacia Entre Ríos. Parte de las tropas correntinas tuvieron una activa participación en la revolución; incluso los antiguos rosistas se unieron a la revolución. Restablecida, la Sala de Representantes desconoció al Congreso Constituyente, ordenó el regreso de los dos diputados porteños a la misma y reasumió el manejo de sus relaciones exteriores.

En un primer momento, Urquiza ocupó San Nicolás de los Arroyos, decidido a volver a Buenos Aires. Pero allí tuvo conocimiento que el apoyo con que contaba la revolución era mayor que el esperado, y que incluso los federales se habían plegado a ella. De modo que regresó a Entre Ríos.

A partir de ese momento, el llamado Estado de Buenos Aires se manejó como un país independiente de la Confederación. Tras un breve interinato del general Pinto, en octubre fue nombrado gobernador Valentín Alsina.

El general José María Paz fue nombrado comandante de las fuerzas acantonadas en San Nicolás, con las que se planeaba invadir Santa Fe. Mientras tanto, las fuerzas correntinas fueron enviadas de regreso a su provincia, con la misión de invadir Entre Ríos en su camino. Pero las fuerzas desembarcadas en Concepción del Uruguay fueron derrotadas y debieron huir a Corrientes; y otra división se reembarcó hacia Buenos Aires. De modo que la proyectada invasión de Paz al interior fue suspendida.

Los planes del gobierno porteño de lanzarse a la guerra contra la Confederación causaron una rebelión de los oficiales del interior de la provincia, casi todos de origen rosista: el 1 de diciembre, el general Hilario Lagos se pronunció contra el gobierno de Alsina, que presentó la renuncia, y por tercera vez asumió el gobierno provisional el general Pinto.

Las tropas federales pusieron sitio a la ciudad de Buenos Aires, mientras que las escasas fuerzas del gobierno porteño en el interior de la provincia fueron derrotadas. Incluso Paz fue llamado a Buenos Aires, desguarneciendo a San Nicolás.

Urquiza se trasladó al sitio de Buenos Aires al frente de algunas divisiones entrerrianas, y la escuadra de la Confederación bloqueó la ciudad. Periódicamente había choques en los alrededores de la capital y combates navales en el Río de la Plata y el Paraná. Lagos formó un gobierno paralelo en San José de Flores e intentó normalizar un gobierno para el interior de la provincia.

El gobierno porteño resolvió la crisis por medio del soborno: primeramente coaccionó a varios jefes federales para abandonar el sitio, y luego sobornó al comandante de la escuadra de la Confederación, el norteamericano John Halstead Coe, para entregar su flota al gobierno porteño. En julio de 1853, el ejército sitiador se disolvió y Urquiza regresó a Entre Ríos.

En 1852, Justo José de Urquiza creó una comisión de 14 miembros para la redacción de los Códigos Civil, Penal, Comercial y de Procedimientos. Pero la revolución del 11 de septiembre de ese año, que culminó con la separación de la Provincia de Buenos Aires de la Confederación Argentina, impidió que el proyecto fuera concretado.

En noviembre de 1852 se inauguraron las sesiones del Congreso Constituyente en Santa Fe. Quien lo había gestado y tratado de reunir luego de incansables años de lucha, el general Urquiza, no pudo asistir debido a la invasión porteña a Entre Ríos. Los diputados habían sido elegidos por los gobernadores con la anuencia de Urquiza, y este presionó activamente sobre ellos para destrabar algunas discusiones. Algunos debieron renunciar a su representación debido a que Urquiza se negó a pagarles los sueldos.

La tarea de redactar el proyecto recayó fundamentalmente en el diputado Benjamín Gorostiaga, que presentó un texto muy parecido al proyecto de constitución que había propuesto Juan Bautista Alberdi en "Bases y puntos de partida para la organización política de la República Argentina"; el mismo estaba inspirado, a su vez, en la Constitución de los Estados Unidos de América y las constituciones argentinas de 1819 y 1826, que seguían la tradición de la Constitución española de 1812. Aunque la Constitución nombraba al país como Confederación Argentina, el régimen establecido era el de una república federal. En la práctica, durante la primera década el sistema político funcionaría como una federación de provincias, aunque unidas por un vínculo más firme que el que había existido durante el régimen rosista.

El 1 de mayo de 1853 fue sancionada la Constitución, la cual fue jurada en asambleas públicas en las capitales provinciales.

Hasta la reunión del Congreso Nacional, el Congreso Constituyente se hizo cargo del Poder Legislativo. Las principales leyes que sancionó fueron la que designaba a Paraná capital provisoria del país hasta que Buenos Aires se uniera al mismo, y otra aprobando un tratado de libre navegación de los ríos con Francia e Inglaterra, que declaraba que la navegación de los ríos interiores de la Confederación estaba sujeta a las mismas condiciones que la navegación en alta mar, completamente libre de todo control.

En el mes de junio, el sitio de Buenos Aires seguía sin solucionarse, y las fuerzas sitiadoras se desmoralizaban; de modo que el gobierno porteño resolvió la crisis por medio del soborno: primeramente coaccionó a varios jefes federales para abandonar el sitio, y luego sobornó al comandante de la escuadra de la Confederación, el norteamericano John Halstead Coe, para entregar su flota al gobierno porteño; semanas más tarde, el ejército sitiador se disolvió. Urquiza estuvo a punto de caer en manos de los porteños, pero logró embarcarse hacia Paraná en un buque inglés, mientras sus tropas huían hacia Santa Fe.

Realizadas las elecciones, fue elegido presidente Justo José de Urquiza, acompañado por el unitario sanjuanino Salvador María del Carril como vicepresidente. La capital fue establecida en forma provisional en la capital de la provincia de Entre Ríos; para ello se federalizó todo el territorio de la provincia, que pasó a estar gobernada directamente por el presidente. De este modo, Urquiza seguía gobernando su provincia, aunque las municipalidades conservaron cierta autonomía. 

Urquiza asumió la presidencia el 5 de marzo de 1854. Pocos días después viajó a Córdoba a presidir una reunión de los gobernadores de las provincias vecinas, con lo cual quiso mostrar la firme unión entre las mismas, amenazadas tanto por la política de Buenos Aires como por la reciente historia de divisiones entre ellas.

Una vez establecido en Paraná, Urquiza convocó a elecciones de diputados y senadores, inaugurando las primeras sesiones del Congreso Nacional el 22 de octubre de 1854. La organización del Poder Judicial presentó mayores dificultades debido a la escasez de personal capacitado: si bien el presidente designó a los miembros de la Corte Suprema de Justicia y sancionó la ley para la organización de las Cámaras Federales, la Justicia Federal nunca llegó a funcionar.

Nacionalizó el Colegio y la Universidad de Córdoba y el Colegio de Concepción del Uruguay; hizo construir edificios públicos en Paraná.

La Confederación no tenía recursos políticos ni económicos para llevar adelante grandes iniciativas públicas. Una de las materias en que logró más éxitos fue la conformación de un ejército nacional. Las fuerzas provinciales se mantuvieron autónomas, pero el gobierno logró organizar regiones militares que pudieran funcionar como unidades militares en el futuro.

Durante casi la mitad del tiempo de su gobierno, Urquiza no residió en Paraná, sino que gobernaba desde el Palacio San José, que se estaba construyendo cerca de Concepción del Uruguay. Durante sus ausencias lo reemplazó Del Carril, como establece la Constitución, pero este tenía muy malas relaciones con el ministro del interior, Santiago Derqui; con el tiempo, ambos terminaron liderando partidos opuestos dentro del mismo gobierno.

Se hizo un primer intento de crear un ferrocarril para unir Rosario –la ciudad de más rápido crecimiento en ese período, que pronto sería la más poblada del interior– con Chile, favoreciendo en su camino zonas desérticas. Los primeros estudios en ese sentido dieron resultados desalentadores, por lo que el gobierno pensó en combinar ese plan con un ferrocarril a Córdoba, que por sí mismo financiara la construcción del primer tramo del ferrocarril a Chile; el plan desarrollado por el ingeniero William Wheelwright no pudo ser llevado a cabo por el gobierno de la Confederación por falta de recursos financieros.

Para reemplazar al inexistente ferrocarril, las comunicaciones se modernizaron estableciendo ""mensajerías"", empresas privadas que llevaban pasajeros, correspondencia y cargas de alto valor en galeras, uniendo la mayor parte de las ciudades del país. y que también recorría el interior de la provincia de Buenos Aires.

En las provincias de la Confederación, los propietarios de tierras carecían de acceso al crédito, ya que no contaban recursos económicos ni financieros para expandirse. Por ello, el crecimiento de la producción agropecuaria en las provincias del litoral estuvo motorizado por la creación de colonias agrícolas en su territorio, atrayendo hacia ellas a inmigrantes europeos. La primera colonia agrícola exitosa fue la de Esperanza (Santa Fe), fundada por Aarón Castellanos en 1855, con inmigrantes suizos. Otras muchas colonias fueron fundadas en Santa Fe y Entre Ríos en esos años; un caso muy conocido es el de la Colonia San José, fundada por el general Urquiza en 1857. No obstante, para que el sistema se generalizara sería necesario el apoyo del ferrocarril, que solo se extendería en años posteriores.

La división entre la Confederación y Buenos Aires planteó un problema a los representantes diplomáticos acreditados en la Argentina: si bien reconocían la autoridad de Urquiza sobre todo el país, la enorme mayoría de sus intereses comerciales y sus ciudadanos residentes estaban en Buenos Aires. De modo que sostuvieron ministros plenipotenciarios en Paraná y cónsules en Buenos Aires, tratando de mediar a favor de la unión nacional.

Pese a la importancia que el gobierno nacional daba a las relaciones con las principales potencias extranjeras, su primera prioridad fue lograr el reconocimiento de la independencia argentina por parte de España. Juan Bautista Alberdi representó a la Confederación ante la corona española, logrando la firma de un tratado con España el 9 de julio de 1859, por el cual la antigua metrópoli reconocía la independencia argentina; el mismo fue rechazado por Buenos Aires, debido a que se reconocía la ciudadanía española de los hijos de españoles nacidos en la Argentina, esto es, el ius sanguinis, lo que significaba convertir a la muy necesaria inmigración en una amenaza a la nacionalidad argentina.

Gran Bretaña logró la anulación del tratado de 1849, por el cual Rosas había obligado a ese país a reconocer la soberanía argentina sobre sus ríos interiores.

También se reiniciaron relaciones diplomáticas con la Santa Sede, con la cual la Argentina no había tenido relación alguna desde las discusiones sobre el patronato eclesiástico durante la década de 1830.

Las relaciones con el Brasil estuvieron orientadas principalmente a la cuestión de la navegación de los ríos y a las relaciones de ambos países con el Paraguay. La relación con este último país —celoso defensor de todos los atributos de su soberanía— se vieron empañadas por la firme actitud del gobierno paraguayo ante las potencias extranjeras, especialmente con relación a Estados Unidos, que estuvo a punto de atacar a ese país por un incidente menor. La favorable resolución de ese problema facilitó la mediación paraguaya para resolver los conflictos entre Buenos Aires y la Confederación en 1859.

La Confederación inició su etapa constitucional con serios problemas económicos y financieros: falta de recursos, dependencia del puerto de Buenos Aires para el comercio exterior, trabas interiores derivadas de las aduanas provinciales y derechos de tránsito, dificultades en las comunicaciones y en el tránsito de mercaderías, escaso desarrollo de la agricultura y estancamiento de la industria artesanal. La organización del tesoro nacional presentó dificultades por la escasa recaudación de las aduanas exteriores de la Confederación y la falta de un sistema impositivo eficiente; de allí la penuria económica de la administración confederal. Tampoco se acertaba a crear un sistema bancario confiable, por lo que el crédito le resultaba muy costoso y los sucesivos intentos de emitir papel moneda terminaron en tantos fracasos.

Un proyecto del ministro de Hacienda, Mariano Fragueiro, llevó a la creación del Banco Nacional de la Confederación, que abrió sus puertas en 1854 y emitió papel moneda. Pero este carecía de respaldo, de modo que se debió declararlo de curso forzoso; las provincias lo rechazaron y los comerciantes se negaron a aceptarlo. El banco debió cerrar y se retiró de circulación el papel moneda.

Entonces se decidió atacar la estructura económica del país dividido, que beneficiaba a Buenos Aires: la Ley de Derechos Diferenciales –sancionada en 1856– buscó incrementar el comercio de la Confederación con las potencias extranjeras y perjudicar los intereses de Buenos Aires. La ley establecía que las mercaderías extranjeras provenientes de cabos adentro –esto es, previamente desembarcadas en otro puerto del Río de la Plata– que se introdujesen en la Confederación pagarían el doble del derecho ordinario al que estaban sujetas las que entraban directamente a los puertos de la Confederación; una ley posterior estableció derechos diferenciales a la exportación.

Sin embargo, las medidas no dieron los resultados esperados: aunque aumentó el volumen comercial en el puerto de Rosario e incluso un financista brasileño —el Barón de Mauá— fundó un banco en esa ciudad, Buenos Aires seguía siendo el centro financiero del país. La necesidad apremiante de dinero fue solucionada con nuevos empréstitos, como los contratados con Mauá, pero los intereses a que se pudo conseguir el dinero fueron excepcionalmente altos, llegando al 24%. Urquiza llegaría a la conclusión de que el único camino para terminar con los problemas económicos de la Confederación era la reincorporación de la provincia disidente a cualquier precio.

Durante la gobernación de Pastor Obligado, la provincia rebelde sancionó su propia constitución y disfrutó un rápido crecimiento económico.

Tras la derrota de Lagos, la mayor parte de los federales porteños habían emigrado a Paraná, Rosario o Montevideo, desde donde planeaban regresar por medio de la invasión de su provincia. En enero de 1854, Lagos ocupó brevemente el norte de la provincia por pocos días. En noviembre del mismo año, el general Jerónimo Costa avanzó al frente de 600 hombres, pero fue derrotado.

En diciembre de 1855 hubo un nuevo intento, cuando José María Flores desembarcó en Ensenada, mientras Costa lo hacía cerca de Zárate con menos de 200 hombres. El gobernador Obligado dictó la pena de muerte para todos los oficiales implicados en esa invasión, declarándolos oficialmente bandidos. Flores logró huir, pero Costa avanzó hacia Buenos Aires con sus escasas tropas. El 31 de enero de 1856 fue derrotado por Emilio Conesa cerca de San Justo; la mayor parte de los soldados fueron muertos cuando se rendían, y los oficiales fueron fusilados dos días más tarde.

Los federales clamaron por venganza, pero Urquiza decidió ser más prudente: firmó un Tratado de Pacificación con Buenos Aires, que permitió a ambos bandos gozar de tres años de paz.

Durante la gobernación de Valentín Alsina, elegido en 1857, el gobierno porteño adoptó una política muy agresiva, rechazando la Ley de Derechos Diferenciales, y dejando de lado los tratados de paz. Para quebrar la resistencia de la Confederación, apoyó en las provincias movimientos tendientes a integrarse en un proceso de unidad bajo su dirección. La prensa porteña se volvió aún más agresiva, incitando al gobierno porteño a la guerra contra la Confederación o a la independencia definitiva.

Las provincias interiores eran periódicamente sacudidas por revoluciones; las dos más estables eran las de Santiago del Estero y Corrientes, cuyos gobiernos eran considerados más inclinados hacia la política de Buenos Aires que a la de Urquiza.

El asesinato, en 1859, del caudillo sanjuanino Nazario Benavídez fue festejado por la prensa porteña: Sarmiento consideró su muerte como un triunfo de la "civilización" y el diario "La Tribuna" le auguró el mismo destino a Urquiza. El presidente Urquiza envió una intervención federal, que descubrió abundantes vinculaciones de los revolucionarios con el gobierno de Buenos Aires.

La intervención de los porteños en la política interna de otra provincia causó gran indignación en el gobierno de Paraná: una ley desconoció todo acto público generado por el gobierno porteño, y en mayo de 1859, el Congreso ordenó la movilización militar de la población y autorizó a Urquiza resolver el problema de la unidad nacional 

El jefe del ejército porteño, coronel Bartolomé Mitre, recibió orden de invadir la provincia de Santa Fe.

Ante la inminencia del conflicto, Estados Unidos, Reino Unido, Brasil y Paraguay trataron de interceder amistosamente. Pero ni Alsina ni Mitre aceptaban nada que no fuera la renuncia de Urquiza o la guerra. Por su parte, Urquiza –que desde 1852 había intentado negociar siempre– estaba ahora particularmente furioso por el asesinato de Benavídez y por la apología del crimen en que habían incurrido los periódicos porteños.

Los buques de guerra porteños bloquearon el puerto de Paraná, pero un motín en uno de estos barcos, que fue entregado al gobierno nacional, obligó a levantar el bloqueo. A mediados de octubre, tras un breve combate naval, la escuadra federal se presentó frente a Buenos Aires.

El ejército de la Confederación, dirigido por Urquiza, inició la campaña hacia Buenos Aires desde Rosario; estaba formado por 14 000 hombres –de los cuales 10 000 de caballería y 3 000 de infantería– con 35 cañones y obuses; varias divisiones de indígenas ranqueles figuraban como auxiliares.

El ejército porteño operaba desde San Nicolás de los Arroyos; contaba con 9000 hombres –de los cuales, 4700 infantes y 4000 jinetes– con 24 piezas de artillería,bajo el mando de Mitre, ministro de guerra. Las fuerzas porteñas estaban muy disminuidas porque gran parte de sus fuerzas debían proteger la frontera de su provincia de las invasiones de los indígenas, algunos de los cuales –como Juan Calfucurá– eran aliados de Urquiza y sus incursiones formaban parte de la estrategia de este.

El 23 de octubre se inició la Batalla de Cepeda. Antes de lanzarse al ataque, Urquiza arengó a sus tropas: 

La ventaja inicial favoreció a la infantería porteña, pero un hábil uso de la caballería por parte de Urquiza le permitió tomar la ofensiva, e incluso tres batallones porteños fueron destruidos. Una maniobra de flanco ordenada por Mitre desorganizó toda la formación, y la noche detuvo la batalla cuando la victoria de la Confederación era ya evidente.

Los porteños sufrieron muchas bajas: 100 muertos, 90 heridos y 2000 prisioneros, además de 21 cañones. Los nacionales tuvieron 300 bajas fatales. En medio de la noche, Mitre comandó una ordenada retirada hacia San Nicolás, adonde llegó pasado el mediodía siguiente con solo 2000 hombres. A continuación embarcó todo su ejército, y –tras un breve combate– logró trasladarlo a Buenos Aires.

Urquiza avanzó rápidamente sobre la ciudad; en su camino envió a la ciudad varias proclamas pacifistas, como la que decía:

Aunque hubiera podido entrar a Buenos Aires por la fuerza, prefirió acampar cerca de ella –en el pueblo de San José de Flores– desde donde inició negociaciones. Durante todas las tratativas, Urquiza mantuvo la amenaza de un inmediato asalto a la ciudad, con lo que el 8 de noviembre obtuvo la renuncia de Valentín Alsina.

Como consecuencia de complicadas negociaciones –durante las cuales ofició de mediador Francisco Solano López, hijo del presidente paraguayo– el 11 de noviembre se firmó el Pacto de San José de Flores, también llamado de Unión Nacional, entre Urquiza y el gobernador provisional Felipe Llavallol. El mismo establecía que Buenos Aires se declaraba parte integrante de la Confederación y renunciaba al manejo de sus relaciones exteriores, pero revisaría la Constitución de 1853 por medio de una convención provincial y propondría reformas a la misma. Se declaraba nacionalizada la Aduana de Buenos Aires, pero la Nación compensaría los ingresos de la provincia de Buenos Aires durante cinco años, en la medida en que fueran inferiores a los del año 1859. Una cláusula que no fue incorporada al Pacto pero que fue acordada de palabra entre las partes establecía que la reincorporación de la provincia a la Nación se haría después de finalizado el período presidencial de Urquiza.

Muchos federales del interior estuvieron en desacuerdo con el Pacto: desde su punto de vista, Urquiza había llegado a San José de Flores como vencedor, y había negociado como si él hubiera sido el vencido; en vez de castigar a la provincia por su rebeldía, se la había premiado. Uno de los críticos fue el general Ricardo López Jordán, uno de los jefes vencedores en Cepeda.

En mayo de 1860, Urquiza entregó el gobierno nacional a su sucesor, Santiago Derqui.

Poco después se dejó sin efecto la federalización de la provincia de Entre Ríos, quedando fuera de la misma la ciudad de Paraná. Y una nueva constitución provincial declaró a Concepción del Uruguay capital de la provincia. Como era de esperarse, el gobernador electo fue Urquiza, apenas 50 días después de dejar la presidencia.

Durante la presidencia de Derqui, la Confederación acordó con el Estado de Buenos Aires el Convenio Complementario del 6 de junio de 1860 y se realizó la reforma constitucional de 1860; una convención provincial propuso una serie de reformas, que fueron aceptadas en su gran mayoría sin debate por la Convención Nacional reunida al efecto. Entre las reformas introducidas se destacan la validación oficial de tres nombres oficiales para el país: Provincias Unidas del Río de la Plata, República Argentina y Confederación Argentina (art. 35); se eliminó la disposición que declaraba a Buenos Aires como capital de la Nación, ya que la misma se fijaría por una ley del Congreso; se redujeron las atribuciones del Estado Nacional y aumentó el grado de autonomía de las provincias; se estableció que las provincias se reservaban también las facultades que se hubieren reservado al tiempo de su incorporación. se suprimió la obligación de las provincias de garantizar la educación gratuita (art. 5) se prohibió establecer diferencias fiscales entre aduanas y otorgar preferencias a puertos determinados.
Continuó su política de promoción de la educación y la colonización, pero se entrometió continuamente en el gobierno de Derqui. Para sacarse de encima su tutela, este se apoyó en Mitre, pero eso solo sirvió para debilitar su gobierno.

Una serie de conflictos con Buenos Aires, incluyendo nuevos problemas en San Juan y el rechazo de los diputados por Buenos Aires por una cuestión legal, llevaron a que Mitre desconociera el Pacto de San José.

Entonces Derqui se preparó para una nueva guerra contra la provincia rebelde. Reunió un importante ejército en Córdoba y lo unió a las fuerzas de Urquiza. Este fue puesto al mando del ejército.

Pero Urquiza no quería pelear; trató por todos los medios de llegar a un arreglo con Mitre. Se sentía traicionado por el presidente dado su intento de reemplazarlo por Juan Saá, y decidió que no iba a vencer para dejarle el triunfo. Le dijo a su amigo Molinas que
Mitre se negó a cualquier trato e invadió la provincia de Santa Fe. Los ejércitos se enfrentaron en la batalla de Pavón, el 17 de septiembre de 1861. Aunque el resultado de la batalla no parecía inclinarse a favor de ninguno de los contrincantes, Urquiza se retiró, dejando la victoria en manos de Mitre. Su caballería había destrozado a la porteña, y si la infantería de Mitre pudo desplazar a la de Urquiza, fue solo porque este no la empleó a fondo; ni siquiera movió su reserva.

Sin atender los pedidos del presidente ni de sus propios comandantes de caballería, entre ellos López Jordán, Urquiza regresó a Entre Ríos. Mitre, que se había retirado derrotado a San Nicolás, tardó varias semanas en comprender que había quedado vencedor por abandono. Invadió Santa Fe, masacró a la reserva federal en Cañada de Gómez y envió un ejército a ocupar Córdoba y otro a Cuyo.

Debilitado política y económicamente, Derqui se exilió en Montevideo. Urquiza consideró caducado el gobierno nacional, en lo que fue imitado por los demás gobernadores. El vicepresidente Juan Esteban Pedernera renunció en diciembre, y declaró disuelto el gobierno.

Mitre asumió el mismo gobierno nacional que había denunciado como despótico cuando lo ejerció Urquiza en 1852, reemplazó a todos los gobiernos federales de las provincias, y meses más tarde se hizo elegir presidente de la Nación.

Urquiza mantuvo la autonomía del gobierno de su provincia y conservó el cargo de gobernador. No hubo un acuerdo explícito, pero sí un acuerdo tácito con Mitre, por el cual este nunca amenazó a Urquiza. A cambio, Urquiza se mantuvo neutral durante todas las rebeliones federales de esa década. En La Rioja, el general Ángel Vicente Peñaloza mantuvo una larga rebelión hasta que fue asesinado en 1863. Cuatro años más tarde, Felipe Varela y Juan Saá dirigieron otra rebelión en Cuyo y La Rioja, pero ésta fue aplastada. Estas y otras revoluciones federales se hicieron en nombre de Urquiza, y sus dirigentes pidieron repetidamente ayuda y órdenes al jefe natural del Partido Federal, que era Urquiza; pero Urquiza no se movió.

Gobernó una especie de autocracia patriarcal en su provincia, y su gobierno no fue tan progresista como los anteriores. Su provincia se vio beneficiada por la política librecambista de Mitre, si bien las incipientes industrias tuvieron que cerrar. Pero, a cambio, la ganadería floreció más que nunca. La provincia vivía sobre todo de la ganadería... y Urquiza era un ganadero.

Reforzó su sistema casi feudal: nadie podía vender ni campos ni hacienda sin primero darle aviso a Urquiza, que tenía el derecho de prioridad. De esa manera pudo aumentar sin riesgos su ya enorme fortuna.

En las elecciones de 1864, promovió la candidatura de José María Domínguez contra la del general López Jordán, que seguía siéndole leal, pero podía pretender actuar con autonomía. Ortiz, en cambio, gobernó como un dependiente del caudillo.

Al estallar la "Guerra Chiquita" en Uruguay, iniciada en 1863 por la invasión del general Venancio Flores, Urquiza se mantuvo también neutral. La mayor parte de los federales entrerrianos trataban de ayudar al gobierno uruguayo, pero Urquiza mantuvo su alianza con el presidente Mitre, que apoyaba abiertamente a Flores. Cuando la ciudad de Paysandú fue atacada por la flota brasileña y las fuerzas de Flores, hasta dejarla destruida, muchos federales entrerrianos y porteños – entre estos, Rafael y José Hernández – lucharon a favor de los defensores. El bombardeo se veía desde Concepción del Uruguay, y se oía desde el Palacio San José; a Urquiza le llegaron cientos de cartas invitándolo a entrar en acción, pero Urquiza no se movió.

La caída del gobierno uruguayo provocó la Guerra del Paraguay. Mitre llamó a todas las provincias a movilizarse contra el gobierno de Francisco Solano López, y Urquiza repitió el llamamiento al pueblo entrerriano. Los federales entrerrianos estaban indignados; escribían contra la guerra y a favor del gobierno paraguayo. López Jordán escribió a Urquiza: 

Pero Urquiza estaba obteniendo un gran provecho de la guerra: lo primero que hizo fue reunir la mayor parte de los caballos de la provincia y vendérselos a Brasil.

Poco después ordenó movilizar todas las fuerzas provinciales en el campamento de Calá. Curiosamente, en un gesto insólitamente racista, ordenó movilizar a todos los “pardos y morenos” entre los 20 y los 30 años. Se presentaron 8.000 voluntarios, la mayor parte de ellos convencidos de que iban a unirse a los paraguayos contra los brasileños. Fueron reunidos en cinco columnas y comenzaron a marchar hacia el norte; pero al llegar al pueblo de Basualdo, se enteraron de qué lado iban a pelear: simplemente se fueron a sus casas.

Poco después, por medio de amenazas, logró reunir otra vez a su gente, pero al llegar al campamento de Toledo, nuevamente desertaron en masa. Esta vez, Urquiza hizo fusilar a varios, pero ni aun así logró reunir un tercer contingente. Entonces envió los 800 soldados de infantería de línea de su provincia y los embarcó a la fuerza hacia el frente.

El prestigio de Urquiza estaba cayendo rápidamente. El gobierno cerró los periódicos opositores y arrestó a sus directores.

En 1868 se presentó a las elecciones presidenciales como candidato del partido federal, pero perdió por una diferencia aplastante contra el candidato de una parte del unitario: Sarmiento. En cambio, logró hacerse elegir nuevamente gobernador de su provincia, y en mayo de ese año asumió nuevamente el gobierno provincial.

En 1870 terminaba la Guerra del Paraguay; para festejarlo, Urquiza recibió en su Palacio San José, con gran despliegue de desfiles y brindis, al presidente Sarmiento, el más terrible enemigo de los federales. Era la sanción visible del acuerdo tácito del caudillo con los unitarios, y los federales lo tomaron como un insulto.

La oposición decidió no esperar más un pronunciamiento a su favor de parte de Urquiza, y decidió lanzarse a derrocarlo.

El general López Jordán organizó rápidamente la revolución; el primer objetivo era apoderarse de la persona del gobernador, para forzarlo a renunciar o expulsarlo del país. Envió en su busca al coronel Simón Luengo, un oficial cordobés que había luchado contra los porteños en el interior del país.

Una versión de historia novelada relata: En el atardecer del 11 de abril de 1870 una partida de 50 hombres armados, al mando del coronel Robustiano Vera, hicieron ruidosa irrupción en San José. Venían a apresar al gobernador y caudillo gritando: "¡Abajo el tirano Urquiza! ¡Viva el general López Jordán!" Un grupo de cinco a las órdenes del coronel Simón Luengo, cordobés y protegido del general, se encamina a las dependencias privadas del dueño de casa. Integran el grupo Nicomedes Coronel, capataz de una de las estancias de Urquiza, oriental de origen, el tuerto Álvarez, cordobés, el pardo Luna, oriental y el capitán José María Mosqueira, entrerriano, nacido en Gualeguaychú. El general sorprendido por el bullicio y, comprendiendo que se trata de un asalto, grita: "¡Son asesinos! Y corre a proveerse de un arma. Los asaltantes se acercan. ¡No se mata así a un hombre en su casa, canallas!" Les espeta, haciendo un disparo que hirió en el hombro a Luna. "Álvarez, entonces –explica el coronel Carlos Anderson, ayudante de Urquiza y jefe de la Guardia del Palacio, testigo presencial de los sucesos- le tiró con un revólver, y le pegó al lado de la boca: era herida mortal, sin vuelta. El general cayó en el vano de la puerta y en esa posición Nicomedes Coronel le pegó dos puñaladas y tres el cordobés Luengo, el único que venía de militar y que lo alcanzó cuando ya la señora Dolores y Lola, la hija, tomaban el cuerpo y lo entraban en un cuarto, en el cual se encerraron con él yendo a recostarlo en la esquina del frente, donde se conservan hasta ahora, las manchas de sangre en las baldosas".

Ese mismo día eran asesinados en Concordia también sus hijos Justo Carmelo y Waldino; los dos eran amigos íntimos de López Jordán, lo que parece probar que los asesinos no actuaron por orden de López Jordán. Antes del asesinato de Urquiza, Sarmiento se había mostrado más o menos amistoso, pero le resultaba incómoda su presencia y cuando se enteró que lo habían asesinado por razones políticas, sin averiguar los pormenores del caso, le imputó a López Jordán el homicidio que la historia oficial repetiría una y otra vez. 

Sin embargo, Juan Bautista Alberdi, en su obra “Escritos Póstumos” sugiere que Sarmiento bien puede haber sido quien ordenó la muerte de Urquiza.

Tres días más tarde, López Jordán era elegido gobernador por la Legislatura. En su discurso de asunción apoyó la revolución, y apenas mencionó de paso que
La mayor parte de los federales apoyaron la revolución, e incluso José Hernández llegó a hablar de "…su muerte, mil veces merecida."

Más tarde, López Jordán fue acusado de haber querido encabezar una rebelión contra el gobierno nacional. Un año más tarde la provincia fue sometida por la fuerza: los federales, tanto jordanistas como urquicistas, fueron proscriptos, y las garantías que Mitre había acordado tácitamente con Urquiza desaparecieron. La provincia fue ocupada militarmente y perdió la importancia que había tenido.

El asesinato de Urquiza contó con apoyo popular entre los entrerrianos. Esto se debió a las actitudes asumidas por Urquiza: la retirada de la batalla de Pavón, su neutralidad frente al bombardeo de Paysandú, su participación en la guerra contra el Paraguay, las maniobras para evitar la elección de López Jordán y la entrega de la recaudación de impuestos en manos de un particular.

En vida, Urquiza fue condecorado por Brasil con la Orden Imperial de Cristo (en 1851) y la Gran Cruz de la Orden Imperial de la Cruz del Sur (en 1856).

Sus restos descansan en la Basílica de la Inmaculada Concepción, en Concepción del Uruguay, provincia de Entre Ríos, República Argentina.Los pequeños poblados de la zona llevan nombres como: 1º de Mayo (de 1851), Pronunciamiento (01/05/1851), Caseros(por la Batalla), San Justo, San Cipriano (nombre de su hermano y uno de sus hijos).

Varias localidades de la Argentina llevan el nombre de su primer presidente constitucional: Villa Urquiza, en la provincia de Entre Ríos; General Urquiza, en la provincia de Misiones; Juan Anchorena, Estación Urquiza, en la provincia de Buenos Aires; el barrio de Villa Urquiza, en la Ciudad de Buenos Aires. También el Ferrocarril General Urquiza, varias estaciones de ferrocarril, y el Aeropuerto General Justo José de Urquiza, de la ciudad de Paraná.

Gran cantidad de localidades del país llevan su nombre en calles y plazas. En muchas de ellas existen monumentos y bustos con la imagen del general. El parque Urquiza en Rosario y el parque Urquiza en Paraná son algunos ejemplos. Además, en la Ciudad Autónoma de Buenos Aires, se encuentra la escuela secundaria "Justo José de Urquiza" con su nombre por conmemoración.




</doc>
<doc id="15323" url="https://es.wikipedia.org/wiki?curid=15323" title="Dionne Warwick">
Dionne Warwick

Marie Dionne Warrick (East Orange, Nueva Jersey, 12 de diciembre de 1940), de nombre artístico Dionne Warwick, es una cantante estadounidense de soul y pop. Hermana de Dee Dee Warwick, sobrina de Cissy Houston y prima de Whitney Houston.

El trabajo musical más elogiado de Dionne Warwick es el que realizó con los compositores Hal David y Burt Bacharach. 

Se inició en la música como cantante gospel con su familia. Su debut en solitario de la mano de Burt Bacharach en 1962 ("Don't Make Me Over") apareció por una errata de imprenta bajo el apellido "Warwick", no "Warrick"; un error que propició el nombre artístico de Dionne para toda su carrera. Este sencillo tuvo un cierto éxito, situación que no volvería a repetirse hasta 1964 con "Anyone Who Had a Heart" y "Walk on By", este último un éxito en el Reino Unido. Les sucederían otros hasta 1971 en la que abandonó el sello "Scepter" por una fuerte disputa mantenida con Bacharach.

Entre sus interpretaciones más recordadas, se pueden citar otras como "Alfie", la famosísima "I Say A Little Prayer For You", "Promises, Promises", "This Girl's In Love With You", "Endless Love" (canción que grabó con Barry White y que también ha interpretado con Tom Jones), "I Always Get Caught in The Rain", "Who Can I Turn To", "I'll Never Fall in Love Again"...

En su etapa posterior en "Warner", consiguió el éxito con el tema "Then Came You", de 1974 escrito por Thom Bell y Linda Creed e interpretado en un dueto con "The Spinners". 

En 1979 sucedió "I' ll never love this way again" (en español: "No amare de esta manera otra vez") una balada pop en inglés escrita por Richard Kerr y Will Jennings, producida por Barry Manilow, fue el éxito de 1979 y 1980, en voz de Warwick, la cual gracias a su interpretación del tema recibió un Grammy en 1980, la balada alcanzó el número 5 en los Billboard Hot 100, la canción y el álbum donde se incluía fueron calificados Oro por vender más de un millón de copias en Estados Unidos y Canadá en este segundo país la pista alcanzó el número #6 durante varias semanas consecutivas. El éxito se incluía en el álbum debut de Dionne Warwick homónimo.

En la década de los 80, y tras un nuevo cambio de sello discográfico, obtuvo un nuevo éxito con "Heartbreaker" en 1982, canción compuesta por The Bee Gees con la voz de Barry Gibb en el coro. A partir de entonces sus grabaciones se fueron espaciando, hasta un repunte de popularidad en 2006 con un álbum de duetos ("My friends & me").

En el 16 de octubre de 2002, Dionne Warwick fue nombrada Embajadora de Buena Voluntad de la Organización de las Naciones Unidas para la Agricultura y la Alimentación (FAO).

En marzo de 2013, saltó la noticia de que la cantante se había declarado en bancarrota, con deudas acumuladas de unos diez millones de dólares.




</doc>
<doc id="15324" url="https://es.wikipedia.org/wiki?curid=15324" title="Mayo de 1968 en Francia">
Mayo de 1968 en Francia

Se conoce como Mayo francés o Mayo de 1968 a la cadena de protestas que se llevaron a cabo en Francia y, especialmente, en París durante los meses de mayo y junio de 1968. 

Esta serie de protestas espontáneas fue iniciada por grupos estudiantiles contrarios a la sociedad de consumo, el capitalismo, el imperialismo, el autoritarismo, y que en general desautorizaban las organizaciones políticas y sociales de la época, como los partidos políticos, el gobierno, los sindicatos o la propia universidad. Al movimiento estudiantil inicial pronto se unieron grupos de obreros industriales, los sindicatos y el Partido Comunista Francés, aunque con objetivos principalmente laborales, no plenamente coincidentes en otros aspectos con los grupos estudiantiles. Ambos movimientos dieron como resultado la mayor revuelta estudiantil y la mayor huelga general de la historia de Francia, y posiblemente de Europa occidental, secundada por más de nueve millones de trabajadores. El movimiento estudiantil tuvo influencias del movimiento "hippie" que se extendía entonces.

La magnitud de las protestas no había sido prevista por el gobierno francés, y puso contra las cuerdas al gobierno de Charles de Gaulle, que llegó a temer una insurrección de carácter revolucionario tras la extensión de la huelga general. Sin embargo, la mayor parte de los sectores participantes en la protesta no llegaron a plantearse la toma del poder ni la insurrección abierta contra el Estado, y ni tan siquiera el Partido Comunista Francés llegó a considerar seriamente esa salida. El grueso de las protestas finalizó cuando De Gaulle anunció las elecciones anticipadas que tuvieron lugar el 23 y 30 de junio.

Los sucesos de mayo y junio en Francia se encuadran dentro de una ola de protestas protagonizadas, principalmente, por sectores politizados de la juventud, cuya ideología recorrió el mundo durante 1968. Estos sucesos se extendieron por la República Federal Alemana, Suiza, España, México, Argentina, Uruguay, Estados Unidos, Checoslovaquia e Italia, lo cual ampliaba la escala del antiguo refrán del siglo XIX afirmando que "cuando París estornuda, toda Europa se resfría".

La crisis de mayo de 1968 en Francia surge al término de una década de prosperidad económica sin precedentes. Sin embargo, desde hacía un año se manifestaban los primeros síntomas serios de un grave deterioro de la situación económica. El número de desempleados aumentaba de forma notoria, y al empezar 1968 ya eran 500.000. La juventud se veía particularmente afectada, y las circunstancias habían llevado el gobierno a crear en 1967 la ANPE ("Agence nationale pour l'emploi"). La crisis industrial amenazaba ya a muchos sectores, y la larga huelga de los mineros de 1963 había sido muestra del profundo malestar de la minería francesa ante un declive imparable. En 1968, dos millones de trabajadores cobraban el SMIG ("Salaire minimum interprofessionnel garanti", salario mínimo interprofesional) y se sentían excluidos de la prosperidad. Los sueldos reales empezaban a bajar y crecía la preocupación por las condiciones de trabajo.

En las afueras de las grandes urbes, unas extensas barriadas irregulares, los "bidonvilles", se habían extendido desde mediados de la década de 1950. El más poblado, el de Nanterre, alcanzaba los 14.000 habitantes en 1965 y se encontraba justo enfrente de la universidad donde iban a surgir los primeros movimientos contestatarios estudiantiles.

Internacionalmente, la década de 1960 vivió una serie de cambios a nivel mundial que llevaron al cuestionamiento del sistema de dominio europeo y, sobre todo, estadounidense sobre los territorios coloniales o recientemente independizados de África, Asia y América Latina. El triunfo de la Revolución cubana y el auge de movimientos izquierdistas en Latinoamérica, y especialmente la guerra de Vietnam generaron un amplio movimiento de solidaridad en gran parte de Europa y de los propios Estados Unidos que canalizaron la oposición al imperialismo.

En Francia estos movimientos tienen su génesis durante la guerra de Indochina y de Argelia, que provocaron una fuerte polarización en la sociedad francesa desde principios de la década de 1960. En octubre de 1961 una manifestación pacífica de argelinos en París acabó con una fuerte represión policial que provocó más de 200 muertos, cuyos cuerpos fueron arrojados al Sena en una acción que fue silenciada en el primero de los grandes apagones informativos de esta época. También a raíz de este suceso aparece públicamente por primera vez una corriente estudiantil radical que se manifestará contra la actuación policial a través de dos organizaciones recientemente creadas: el Comité Anticolonialista y el Frente Universitario Antifascista (FUA). Al año siguiente, en febrero de 1962, una manifestación convocada por el Partido Comunista Francés y la Confederación General del Trabajo acabó con nueve muertos aplastados en la estación de metro de Charonne. Estos dos sucesos provocaron un sentimiento de rechazo hacia los CRS (policía antidisturbios). Durante este periodo, grupos estudiantiles como el sindicato universitario Unión Nacional de Estudiantes de Francia se desplazaron hacia la izquierda en el contexto de oposición a la guerra de Argelia, al tiempo que iban surgiendo nuevos movimientos como el Comité Vietnam de Base y el Comité Vietnam Nacional (aparecidos en 1967 y 1966 respectivamente) que organizaron importantes movilizaciones antimperialistas y protagonizaron gran parte de la agitación universitaria anterior a 1968. El desarrollo de la Revolución Cultural en China también generó un nuevo referente para una parte de los sectores izquierdistas franceses, que vieron en el maoísmo una nueva base ideológica, alejada del PCF y de la Unión Soviética, y menos dogmática y mucho más innovadora con respecto al marxismo clásico soviético.

También a raíz de la guerra de Argelia surgen importantes movimientos ultraderechistas que abogaban por la defensa de la Argelia francesa, como la OAS (Organización del Ejército Secreto, por sus siglas en francés) y los grupos Occident, Ordre Nouveau o Jeune Nation. Estos movimientos se enfrentaron durante la década de los 60 con los movimientos estudiantiles y obreros izquierdistas tanto en las universidades como en las calles de las principales ciudades, generando una polarización cada vez mayor en los distintos sectores de la sociedad francesa.

En cuanto al gobierno francés, la figura del general De Gaulle, en el poder desde 1958, sufre un desgaste palpable en los resultados electorales. En las elecciones a la presidencia de la República de 1965, las primeras con sufragio universal desde 1948, De Gaulle no había logrado la mayoría absoluta requerida en la primera ronda de votaciones, seguido de cerca por François Mitterand ante la sorpresa general. En las elecciones de 1967 a la Cámara de los diputados, su mayoría había dependido de un solo escaño. La oposición seguía reprochándole la manera en la que había accedido al poder en 1958, y la legitimidad del régimen gaullista se veía cada vez más ensombrecida por acusaciones de "golpe de Estado". A pesar de la bonanza económica de los últimos años, de los éxitos políticos (fin de la Guerra de Independencia de Argelia y procesos de descolonización) y de cierta aclimatación al régimen presidencialista de la V República Francesa, las prácticas autoritarias del general De Gaulle levantaban cada vez más críticas.

Por su parte, el movimiento obrero francés va a experimentar en esta década una fuerte radicalización y cierto alejamiento de las cúpulas sindicales mayoritarias como la CGT. Desde 1961 se van a suceder huelgas violentas y ocupaciones de fábricas, en muchas ocasiones de forma más o menos espontánea y contra los acuerdos de la dirigencia sindical. En 1963 se realizó una huelga violenta de mineros en la que se rechazaron los acuerdos de los sindicatos; en 1964 hubo huelgas de los obreros de Renault (bajo la consigna "queremos tiempo para vivir") y en los astilleros de Nantes; los obreros del grupo químico Rhodiaceta de Lyon y Besançon mantuvieron una huelga durante todo el mes de diciembre de 1967 y, en enero de 1968, se produjeron disturbios en Caen en los que participaron obreros, agricultores y estudiantes y que se saldó con más de 200 heridos. Estas fueron las primeras huelgas desde 1936 en las que los obreros ocuparon las fábricas, y durante toda la década gran parte de Francia se vio afectada por este movimiento obrero. Grupos estudiantiles e intelectuales comenzaron una estrategia de acercamiento a los conflictos obreros en este periodo, comenzando a trabajar en las fábricas como parte de la actividad militante y realizando encuentros en las casas de los obreros. En este plano de acercamiento entre movimiento estudiantil y un movimiento obrero radicalizado al margen de las cúpulas sindicales se sentaban las bases para la agitación de mayo y junio.

Los años 60 en Francia - al igual que en el resto de occidente - fueron una época de acelerados cambios culturales. La época estaba caracterizada por la aceleración del éxodo rural y el surgimiento de la sociedad de consumo, cada vez más influida por los medios masivos de comunicación (mass media) que generalizaban la cultura de masas.

Es además en los años 60 cuando los jóvenes se convierten en una categoría socio-cultural logrando su reconocimiento como un actor social que establece procesos de adscripción y diferenciación entre sus opciones y las de los adultos. Estos procesos se desarrollan a través de las subculturas juveniles nacidas a partir de finales de los años 1950, dentro de movimientos contraculturales como la cultura underground y los movimientos beatnik y hippie. Esta juventud tenía sus propios ídolos musicales como los Beatles, Rolling Stones, cantautores como Bob Dylan y Léo Ferré, etc. Muchos de estos movimientos cuestionaron y criticaron el estilo de vida plástico ofrecido por el mercado de consumo y la organización capitalista de la posguerra.

En el plano filosófico varias obras y autores tuvieron gran influencia en una parte del movimiento: Wilhelm Reich, freudomarxista, cuyo manifiesto, "La revolución sexual", daba nombre a una de las consignas más repetidas; Herbert Marcuse con "El hombre unidimensional", publicado en Francia en 1964 y que tuvo que ser reeditado en el 68; Raoul Vaneigem, con el "Traité de savoir-vivre à l'usage des jeunes générations" de 1967; Guy Debord con "La sociedad del espectáculo", también del 1967. Pierre Bourdieu y Jean-Claude Passeron publicaban en 1965 "Les étudiants et leurs études" donde hacían una ácida crítica al sistema educativo francés y sus mecanismos de reproducción social, que permitían a las élites conservar su poder de generación en generación. Mientras tanto en la École Normale Supérieure, el filósofo marxista Louis Althusser formaba una generación de pensadores marxista-leninistas que fueron el embrión de las primeras organizaciones maoístas.

El 8 de enero de 1968, el ministro de Juventud y Deporte, François Missoffe, acude a la inauguración de una piscina en la Universidad de Nanterre. Los estudiantes recibieron al ministro con un sonoro abucheo a causa de su "Libro Blanco" acerca del estado de la juventud estudiantil. Durante el suceso un joven estudiante de sociología, Daniel Cohn-Bendit, provocó al ministro, reprochándole que su libro no tratara el problema sexual entre los jóvenes. Pese a que este incidente se quedó en una mera anécdota, permitió la visualización de Cohn-Bendit como una de las figuras mediáticas de los sucesos de mayo. Unos meses después, el 22 de marzo de 1968 un grupo de estudiantes se encierra en la Universidad de Nanterre en protesta por las normativas internas del centro, desocupando las instalaciones tras algunas negociaciones y la aparición de la policía. Esta acción daría origen al Movimiento 22 de marzo, el cual sería uno de los referentes de las movilizaciones de mayo y junio de ese año.

El 22 de abril de 1968, 1.500 estudiantes acudieron a una nueva protesta en Nanterre contra la detención de varios estudiantes del Comité Vietnam Nacional, acusados de atentar contra empresas estadounidenses, en la cual intervendría la policía. El 28 de ese mismo mes el decano de la Facultad ordena el cierre de la misma, al tiempo que los estudiantes anuncian el boicot a los exámenes parciales y se producen enfrentamientos con miembros de la Federación Nacional de Estudiantes de Francia, de ideología derechista, los cuales asaltarían la universidad del 2 de mayo y acusarían a los estudiantes movilizados de "terroristas". Los movimientos derechistas y ultraderechistas estudiantiles previeron que el movimiento de los estudiantes iba a desarrollarse y afirmaron que el deber de los estudiantes moderados y del gobierno era "pararlo en seco". Al mismo tiempo, miembros del grupo de extrema derecha Occident marcharon por el Barrio Latino gritando "¡Vietcongs asesinos!" con el objetivo de contrarrestar el crecimiento del movimiento.

El 3 de mayo ocho estudiantes implicados en las protestas, entre los que se encontraba Daniel Cohn-Bendit, acudieron a declarar a París mientras en la plaza de la Sorbona comenzaba a congregarse una gran cantidad de estudiantes vigilados por la policía, que finalmente cargaría contra la concentración. Ante esta situación, la Unión Nacional de Estudiantes y el Sindicato de Profesores llamaron a la huelga exigiendo la retirada de la policía y la reapertura de La Sorbona, cerrada por el decano el día anterior a consecuencia de una marcha que venía desde Nanterre, así como la liberación de los estudiantes detenidos hasta el momento, y abogando por "los ocho de Nanterre" (entre ellos Daniel Cohn-Bendit), quienes estaban por ser expulsados.

El lunes 6 de mayo los "ocho de Nanterre" acudieron a declarar ante el Comité de Disciplina de la Universidad. A su salida se realizó una nueva manifestación que concluyó con grandes enfrentamientos entre las barricadas levantadas en el Barrio Latino. La violencia de la policía provocó un sentimiento de solidaridad entre la mayor parte de la sociedad francesa (un 61% de los franceses simpatizaban en estos momentos con los estudiantes). Las manifestaciones se repiten al día siguiente, llegando hasta las inmediaciones de los Campos Elíseos.

El punto de inflexión del movimiento se da en la noche del 10 de mayo, conocida como "la noche de las barricadas". Decenas de miles de estudiantes acuden a las barricadas del Barrio Latino. Las negociaciones iniciadas con el rectorado de la Sorbona fracasan, al tiempo que las autoridades siguen sin aceptar la liberación de los detenidos. La policía disuelve las barricadas por la fuerza, produciéndose los más duros enfrentamientos de todo el mes de mayo con cientos de heridos. Al día siguiente, carros blindados se desplegaron por la capital francesa.

Ante los sucesos de los días anteriores se convocaría una huelga general para el lunes 13 de mayo. La manifestación de ese día congregó a 200.000 personas, mientras 9 millones de trabajadores en toda Francia seguían la convocatoria de huelga. Tras la misma, grupos de estudiantes marcharon a la Sorbona, que había reabierto sus puertas tras la llegada del primer ministro Georges Pompidou de un viaje por Asia Central, ocupándola. La toma de la Sorbona estará dirigida por un Comité de Ocupación que dotará a la Universidad de una serie de servicios básicos para los estudiantes alzados (enfermería, comedores e incluso guardería). Al día siguiente los trabajadores de Sud Aviation en Nantes y los de Renault en Cleon, Flins, Le Mans y Boulogne Billancourt ocuparon sus fábricas. Poco a poco la huelga se extiende, paralizando la mayor parte de la Francia industrial.

Con la transformación de un movimiento estudiantil surgido en una universidad del extrarradio en una huelga espontánea, los estudiantes tratarán de crear una unión con los trabajadores. Varios miles de estudiantes marcharon el 16 de mayo a Boulogne-Billancourt a encontrarse con los obreros encerrados en las fábricas pero, aunque se realizarán muestras recíprocas de solidaridad (ambos colectivos cantarán "La Internacional" en las puertas de las fábricas ocupadas), las verjas de los puestos de trabajo que los separaban no llegarán a abrirse. El 17 de mayo es creado el Consejo por el Mantenimiento de las Ocupaciones que apoya las huelgas salvajes y se opone a la moderación de los sindicatos.

En los días siguientes se sumarán a la huelga los controladores aéreos así como los trabajadores del carbón, del transporte, del gas y la electricidad y los periodistas de la radio y la televisión. En Nantes, los obreros y los agricultores cortaron los accesos a la ciudad y controlaron el precio de los productos ofrecidos en las tiendas, las cuales solo podían abrir con autorización del Comité de Huelga. En estos momentos, en muchos de los centros de trabajo en huelga, comienza a plantearse la cuestión del poder obrero en las empresas, poniendo verdaderamente en cuestión la autoridad del Estado y generando un auténtico vacío de poder.

Ante esta situación, el gabinete de Pompidou acepta, el 25 de mayo, el abrir negociaciones con los representantes de los obreros en huelga. Estas negociaciones se plantean a tres bandas: patronos, sindicatos y gobierno. Las negociaciones concluyen el 27 de mayo con los Acuerdos de Grenelle, en los que se recoge un incremento del 35% en el salario mínimo industrial y del 12% de media para todos los trabajadores. Sin embargo, la mayor parte de los trabajadores en huelga rechazan el acuerdo. Al día siguiente François Mitterrand, en rueda de prensa, pide al gobierno de De Gaulle su dimisión, afirmando que desde el 3 de mayo "no había Estado", y se postula como candidato a la presidencia.

El 29 de mayo De Gaulle desaparece sin llegar a asistir al Consejo de Ministros convocado para esa mañana. En las calles de París, los manifestantes que se dirigían hacia la Estación ferroviaria de San Lázaro (la "Gare Saint-Lazare"), donde se concentraban los ferroviarios en huelga bajo el lema ""Por un cambio político de progreso social y de democracia"", y gritan consignas como "¡Adiós De Gaulle!" Los gaullistas, por su parte, convocan para el 30 de mayo una manifestación ""En defensa de la República"" en los Campos Elíseos, a la que acuden más de 300.000 personas mostrando su apoyo al Presidente.

De Gaulle, por su parte, había acudido a Baden-Baden, en la República Federal Alemana, para entrevistarse con el general Charles Massu, comandante en jefe de las fuerzas francesas estacionadas en Alemania, provocando una gran inquietud ante la posibilidad de que el presidente decidiera recurrir al ejército. El mismo día 30, De Gaulle regresa a París y se dirige al país por la radio anunciando que no dimitirá, al tiempo que disuelve la Asamblea y convoca elecciones en un plazo de 40 días.

Con estas declaraciones, queda claro que la única forma de derribar al gobierno es mediante un alzamiento que ninguno de los sectores en lucha está dispuesto a llevar a cabo. Sin embargo los disturbios aún continúan, pese a que distintas empresas comienzan a retornar al trabajo tras diversas conversaciones locales que tomaban como base los Acuerdos de Grenelle, aceptándose el pago de los días de huelga. Los incidentes se trasladaron de París a los núcleos industriales donde continuaban las huelgas. El 7 de junio en Flins se produjeron violentos enfrentamientos entre los CRS, que acudieron a desalojar a los trabajadores encerrados en las fábricas, y los estudiantes y obreros en huelga. El día 10 un joven estudiante de secundaria muere en los enfrentamientos, lo que provoca nuevos disturbios en París. El 12 de junio, De Gaulle decreta la disolución e ilegalización de los grupos de extrema izquierda y prohíbe las manifestaciones callejeras durante dieciocho meses. En total una decena de colectivos izquierdistas son ilegalizados, sus publicaciones prohibidas y varios de sus líderes arrestados. El día 15 Raymond Marcellin, Ministro de Interior desde el 31 de mayo, amnistió a 50 militantes presos de la OAS condenados por asesinato, entre los que se encontraban generales de la extrema derecha como Raoul Salan (que habían conspirado para derrocar a De Gaulle) con el objetivo de crear grupos de acción ciudadana contra los "elementos incontrolables". Durante un violento mes de junio, la totalidad de los centros de trabajo vuelven a la normalidad, bien por acuerdos de los trabajadores, bien por la intervención policial.

Los días 23 y 30 de junio se celebrarían las elecciones legislativas, de las que la gaullista Unión de Demócratas por la República saldría fortalecida con un 38% de los votos y 293 diputados, contando con sus aliados. El Partido Comunista, por su parte, sufrió un fuerte descenso en su representación en la cámara, pasando del 22,51 % de los sufragios y setenta y tres representantes al 20,02 % y treinta y cuatro diputados. Idéntica suerte sufrió la Federación de la Izquierda Democrática y Socialista (FGDS, por sus siglas en francés) de François Mitterrand, que perdió la mitad de sus diputados (61 frente a los 121 conseguidos el año anterior). La radicalización de los estudiantes franceses mostraba en la práctica una fuerte simpatía por el anarquismo y un rechazo por las estructuras políticas vigentes, incluyendo los sindicatos y partidos ya existentes y cuya disciplina no era del agrado de los manifestantes. Este estado de ánimo hizo que muchos obreros y estudiantes, si bien unidos en el rechazo al autoritarismo degaullista, rechazaran el liderazgo de los partidos comunistas y socialistas, negando la validez de su autoridad.

Tras las elecciones de junio, el gobierno francés reconoció la necesidad de emprender una política de reformas profundas para hacer frente al malestar social existente en el país. En abril de 1969 se celebró un referéndum sobre el proyecto de regionalización (una de las principales reivindicaciones políticas de aquellos momentos era una mayor descentralización del Estado) y la reforma del Senado, que De Gaulle planteó como un plebiscito sobre su gestión al anunciar que abandonaría la presidencia si no triunfaba el SÍ. Sin embargo, los franceses votaron mayoritariamente por el no, provocando la retirada de De Gaulle de la escena política. Estos resultados mostraron que De Gaulle y su generación no eran, para la población francesa, los que podían llevar a cabo la reforma social y política que necesitaba el país. La derrota gaullista marca el inicio del fin de la generación de líderes políticos que habían dirigido Europa Occidental desde el fin de la II Guerra Mundial, al tiempo que enterraba el modelo de liderazgo personalista que hasta el momento había marcado la Quinta República francesa.

Por su parte, el sindicalismo comenzó en 1969 las conversaciones previstas en los Acuerdos de Grenelle. Durante los primeros años de la década de los 70 se registraron nuevos conflictos laborales, en ocasiones con carácter violento como las huelgas de Renault durante marzo y abril de 1973. También se produjeron experiencias excepcionales como la de la empresa Lip, en la que mil trabajadores ocuparon la fábrica de relojes amenazada de cierre y durante 3000 días continuaron la producción bajo control obrero, hasta conseguir un acuerdo final que salvaba los puestos de trabajo. Se va a experimentar, por tanto, un mantenimiento de la conflictividad laboral en Francia durante los años posteriores a 1968 si bien la postura de las principales centrales sindicales no va a variar sustancialmente durante los congresos confederales que se celebrarán entre 1969 y 1970.





</doc>
<doc id="15325" url="https://es.wikipedia.org/wiki?curid=15325" title="Espionaje">
Espionaje

Se denomina espionaje a la práctica y al conjunto de técnicas asociadas a la obtención encubierta de datos, de información confidencial o de cualquier género de secretos. Las técnicas comunes del espionaje han sido históricamente la infiltración y la penetración, en ambas es posible el uso del soborno y el chantaje.



De ambos métodos, las agencias de inteligencia y los diferentes servicios de espionaje prefieren la penetración, dado que es más segura y requiere un menor esfuerzo logístico que la infiltración.

La preocupación en el espionaje industrial y de personas ha llevado al diseño de las Salas Tempest y protección tempest para empresas y ordenadores, por el robo de datos de personas famosas y de empresas. Por ejemplo, esta protección está presente en los ordenadores de las consultas de la medicina pública o seguridad social en España.


En cualquier caso, dichas técnicas se basaban en la utilización de "informantes" , que como tales personas, son susceptibles de ser utilizadas y cuyos datos son acopiados por agentes de inteligencia quienes remiten informes una «central de análisis» que tiene la misión de separar los hechos concretos, de las suposiciones o aportes subjetivos del informante, comparar los datos recibidos (exactos, inexactos, completos o incompletos) con los hechos conocidos y verificados a fin de dar una clasificación sobre la exactitud de la información recibida y sobre la veracidad de la fuente.
"En el pasado del espionaje, cabe destacar el avance soviético. El espionaje internacional impartido por la Unión Soviética se basaba en varios métodos de fuente humana como:




Conexión entre Rezident y espía en general: cabe destacar aunque se aleja del tema el avance creado por la Unión Soviética. La instalación de radio por onda ultra corta (UHF) se emplea por comunicación entre los agentes y los Rezidents o entre los mismo Rezidents. Este se basa en el envío de un mensaje de voz corto. Con el fin de encontrarse o enviar su posición al compañero. Este es indetectable debido a que se usa solamente en distancias cortas y su contenido es muy bajo para ser detectado.

Con el desarrollo de las nuevas tecnologías, han aparecido técnicas que permiten obtener información objetiva como fotografías, conversaciones, etc. sin intervención humana. Así, existe hoy día una floreciente industria destinada a facilitar sofisticados medios tecnológicos, desde satélites espía hasta microcámaras, tanto para el espionaje como para la protección de la información. Laptops, computadoras y celulares también constituyen en la actualidad medios tecnológicos espías que se encargan de grabar, audio, vídeo, receptar datos, ideología y pensamiento a través del INTERNET y constituir un medio de rastreo.

El espionaje industrial es la obtención ilícita de información relativa a la investigación, desarrollo y fabricación de prototipos, mediante las cuales las empresas pretenden adelantarse a sus competidores en la puesta en el mercado de un producto novedoso. La creciente reducción de los plazos transcurridos entre la "idea" novedosa y la puesta en el mercado del producto, así como la cada día mayor obsolescencia de los productos de las nuevas tecnologías, hacen que estos sectores industriales sean el caldo de cultivo ideal para este tipo de actividades ilícitas.

Igualmente, con la aparición de los nuevos medios de transmisión de la información, del que internet es uno de los más populares exponentes, se encuentran en auge las técnicas para codificar la información, no solo técnica sino incluso privada, que dificultan la decodificación de un mensaje interceptado por un tercero.




</doc>
<doc id="15327" url="https://es.wikipedia.org/wiki?curid=15327" title="Hora media de Greenwich">
Hora media de Greenwich

El tiempo medio de Greenwich o GMT ("Greenwich Mean Time" // ) es un estándar de tiempo que originalmente se refería al tiempo solar medio en el Real Observatorio de Greenwich, en Greenwich, cerca de Londres, Inglaterra, que en 1884 fue elegido por la Conferencia Internacional del Meridiano como el primer meridiano.

Antes de la introducción del tiempo universal coordinado (UTC) el 1 de enero de 1972, el tiempo medio de Greenwich (también conocido como Hora Zulú) era la misma que la del horario universal, que es un concepto estándar astronómico que se utiliza en muchos campos técnicos. Los astrónomos ya no utilizan el término "Greenwich Mean Time".

En el Reino Unido, GMT es el tiempo oficial solo durante el invierno; en verano se utiliza el horario de verano.

Durante muchos años los relojes más precisos que existían eran el movimiento de la Tierra alrededor de su eje y alrededor del Sol. A partir de ellos se definía todo lo demás relacionado con el tiempo. Una vuelta de la Tierra alrededor del Sol era un año, una vuelta de la Tierra sobre sí misma era un día, que se dividía en 24 horas, la hora en 60 minutos y el minuto en 60 segundos. En 1900 se definió un segundo como 1/86.400 de un día solar medio.

Esto era suficientemente preciso para las actividades cotidianas, pero poco a poco se fue observando que la Tierra no era el mejor reloj. Las mareas hacen disminuir su giro con cierta regularidad pero, además, hay otras influencias que hacen que la duración de ese giro no sea constante. Las diferencias no afectan a la vida cotidiana pero sí pueden afectar a la precisión de la navegación o a la posición de los satélites artificiales, por ejemplo.

Con el avance del conocimiento del átomo se descubrió un reloj más preciso, la frecuencia de resonancia de ciertos átomos cuando pasaban de un estado a otro. En 1950, en el Laboratorio Nacional de Física un estadounidense construyó el primer reloj basado en esa propiedad de los átomos, al cual se denominó reloj atómico. En su construcción se utilizaron átomos de cesio. Su precisión era tan alta que en 1967 los organismos de normas internacionales cambiaron la definición de segundo basada en el movimiento de la Tierra por una definición basada en el átomo de cesio: el segundo, unidad de tiempo del Sistema Internacional de Unidades, es la duración de 9 192 631 770 períodos de la radiación asociada a la transición hiperfina del estado base del átomo de cesio 133, con la siguiente observación: el estado base se define con campo magnético cero.

El error de los relojes atómicos basados en el cesio es de una parte en 10. Son mucho más precisos que el giro de la Tierra y suplantaron a ésta en la definición del tiempo internacional. En 1972 se adoptó una medida universal que utiliza la definición atómica de segundo. A ese tiempo se le llama en todas las lenguas UTC (Tiempo Universal Coordinado).

Dado que el giro de la Tierra es menos uniforme que el comportamiento de los relojes atómicos, hay una cierta discrepancia entre el tiempo solar medio, base del GMT, y el UTC. Para que haya sincronía entre los dos tiempos, lo que se hace es supervisar con extrema precisión el giro de la Tierra. Se admite que UTC y GMT son correctos si no difieren en más de 0,9 segundos. Si difieren en más de esa cantidad, se añade o se quita un segundo a los relojes atómicos.

La primera vez que se hizo la adaptación fue el 30 de junio de 1972 a las doce de la noche, con lo que los tiempos UTC y GMT quedaron sincronizados el 1 de julio. Las siguientes veces que se ha hecho, hasta hoy en día, siempre ha sido añadir un segundo, pero también podría haber sido restar un segundo si la rotación de la Tierra hubiese variado de otro modo.



</doc>
<doc id="15329" url="https://es.wikipedia.org/wiki?curid=15329" title="Bormujos">
Bormujos

Bormujos es un municipio español de la provincia de Sevilla, Andalucía. Se encuentra a unos 7 km de la capital de la provincia y tiene 12,2 km². 

Los autores no se ponen todavía de acuerdo sobre el origen del nombre del pueblo. Según García de Diego, dicho nombre puede provenir del latín "Mormolium" (manania). Pero también es igualmente probable que provenga del nombre dado a una alquería musulmana, "Boromuj". De esta época quedan aún vestigios como los hallados en la hacienda de Valencinilla del Hoyo. La primera referencia a la alquería de Bormujos la proporciona la documentación medieval cristiana, en 1253, mediante las voces "Mormuios" y "Mormoios", defendiendo Antequera Luengo su raíz arábiga: "Borg-muzn" o "Borg-muhur". En este sentido, el topónimo no ha tenido asiento sino hasta tiempos modernos, con variantes, de manera que aún a fines del XVIII la localidad era conocida, también, como "Mormujos", pervivencia bajomedieval. Solo en el espacio de dos años (1787-1788) aparecen tres variantes: "Mormujos", "Borbujos" y una mezcla de ambas, Bormujos, que prosperó como producto de la disimilación de nasales.

El valle del Guadalquivir fue conquistado por Fernando III en el siglo XIII. En el repartimento firmado por su hijo, Alfonso X, aparece esta villa con el nombre de Mormojos o Mormujos. Fue concedida el 15 de septiembre de 1253, junto con las alquerías de Mairena, Paterna, Alcaudín, Malharomata y Albarat, a "doscientos cavalleros fisjosdalgo", aparte de otra serie de privilegios y propiedades, por el buen servicio que prestaron en la Reconquista.

Así rezan las concesiones:

Poco después, la villa pasó a depender del Ayuntamiento de Sevilla hasta finales del siglo XVII o principios del XVIII. En ese momento pasó a manos de los condes de Olivares (de la casa Guzmán). Esto duraría hasta la abolición de los señoríos a comienzos del siglo XIX. Desde entonces se constituyó como un municipio independiente.

En 1999 se inauguró en la localidad el primer campus universitario privado de Andalucía. Fue diseñado como una filial de la universidad madrileña CEU San Pablo.

A lo largo de los años 2000 la población se duplicó, pasando de los 8.223 en 1999 a 16.548 en 2007. El siguiente gráfico muestra la evolución en los últimos veinte años años:

Gráfica de evolución demográfica de Bormujos entre el año 2000 y 2019<graph>{
}</graph>Fuente: Instituto de Estadística y Cartografía de Andalucía 

Se trata de un edificio de la Baja Edad Media. Fue reformado entre 1678 y 1681 por Antonio Rodríguez y Francisco Romero. La portada principal y la del lateral izquierdo fueron decoradas entre 1778 y 1779 y probablemente sean obra de Pedro de Silva.

Es un edificio de planta rectangular con tres naves. Las bóvedas de las naves están sostenidas por arcos de medio punto apoyados en columnas. La capilla bautismal se encuentra en la nave izquierda, junto a la entrada principal. Al final del templo, adosada a la nave derecha, hay un edificio de planta cuadrada adosado al mismo, que es la capilla del Sagrario.

El retablo mayor cuenta es de 1770. Está decorado con temas de rocalla y flanqueando su parte central hay dos columnas estriadas. En la parte central hay un gran camarín con un grupo escultórico de la Anunciación del ángel Gabriel la Virgen y sobre él hay otro camarín más pequeño con un crucificado del siglo XVIII.

La cofradía de la Vera Cruz es la primera más antigua de la localidad. Se tienen noticias de su fundación en 1634. En 1687 se fusionó con la hermandad sacramental de su parroquia. Posteriormente desapareció y fue refundada a principios de la década de 1990. También es titular la Virgen de los Dolores. Procesiona el Miércoles Santo.

A las afueras existe un monasterio de dominicas construido en 1976. En su capilla alberga numerosas piezas antiguas de tres conventos fusionados: el de Santa María de Gracia, el de Santa María de los Reyes y el de Santa María la Real de Sevilla. Tiene un coro con decoración geométrica de mediados del siglo XVII. En la pared hay un sagrario de madera dorada de la segunda mitad del siglo XVI. A la izquierda hay una Virgen del Rosario del siglo XVIII y en el lado derecho hay un Crucificado a tamaño natural del siglo XVI. También alberga una imagen de Santo Domingo del siglo XVIII. También puede destacarse un lienzo de Santa Teresa del siglo XVII.

En la parte alta del monasterio hay un salón con diversas piezas de valor artístico, como un Juan Bautista de Juan de Mesa, una Piedad de Cristóbal Ramos, un San Miguel Arcángel de la segunda mitad del siglo XVIII y una pintura de la Inmaculada de la escuela madrileña de mediados del siglo XVIII.

Al igual que en otros muchos pueblos, e incluso en las afueras de muchas ciudades, hay ejemplos de arquitectura rural andaluza. La Hacienda de Belén se encuentra donde pudo estar el origen del pueblo. Es un edificio de arquitectura rural andaluza que hoy tiene usos municipales. La Hacienda del Cristo de la Mata se encuentra a las afueras. Antiguamente ahí había una alquería musulmana. El actual caserío data del siglo XVII. Originalmente se le llamó Hacienda de la Mata del Almíjar. Existen otras tres haciendas, aunque en mal estado de conservación: la de la Peregrina, la de Marchalomar y la de Valencinilla del Hoyo.

Hay 46 ha de cultivos herbáceos, de las cuales 20 ha son de trigo y 2 ha de avena. En cultivos leñosos hay 447 ha, de las cuales 408 ha de olivar de aceituna de mesa. Al sur del núcleo urbano está el polígono industrial Almargen y al norte el polígono industrial Aceitunillo.



</doc>
<doc id="15330" url="https://es.wikipedia.org/wiki?curid=15330" title="Espacio regional">
Espacio regional

Uno de los problemas clásicos de la geografía es determinar qué y cuál es el espacio regional, o región. Una región es un espacio que se organiza de forma homogénea y de manera diferenciada.

Según el criterio que se utilice para dar coherencia al espacio tendremos un tipo de región u otro. Estos criterios dependen de la escala, por lo que frecuentemente las regiones están solapadas. Se puede distinguir entre: región natural, histórica, económica, urbana, etc. Dado el carácter multidisciplinar de la geografía, y de las distintas escalas y espacios que utilizamos, los fenómenos se distribuyen en las regiones solapándose unos con otros. Es prácticamente imposible que a una región geográfica la podamos definir por todos los criterios. Debemos, pues, elegir un fenómeno dominante para definir las regiones en el espacio.

El estudio de la región tuvo gran importancia en la geografía de Paul Vidal de la Blache, pero su rígido concepto de región tendió a provocar anquilosamiento de su geografía.


</doc>
<doc id="15331" url="https://es.wikipedia.org/wiki?curid=15331" title="Fosfeno">
Fosfeno

Un fosfeno es un fenómeno caracterizado por la sensación de ver manchas luminosas que está causado por la estimulación mecánica, eléctrica o magnética de la retina o corteza visual. Un ejemplo de fosfeno son los patrones luminosos que se ven al frotar los párpados con bastante presión. Los fosfenos son un fenómeno entóptico.

Se ha relacionado los fosfenos con la neuritis óptica.

En 1918 Lowënstein y Borchard descubrieron que tras la estimulación eléctrica del córtex visual aparecían fosfenos. Penfield y su grupo de investigación en la década de 1950 confirmaron los fosfenos y que la estimulación eléctrica de ciertas zonas del cerebro producían imágenes (fosfenos) como sonidos, sensaciones táctiles.

Brindley y Lewin, en la Universidad de Cambridge, y un grupo de investigadores de la Universidad de Utah, dirigidos por Dobelle, estudiaron a fondo los fosfenos y establecieron los cimientos para hacer una prótesis visual basada en señales eléctricas inyectadas mediante electrodos en el córtex visual. En 1976 el grupo de Dobelle logró que ciegos de larga duración lograran ver caracteres Braille utilizando seis electrodos. La lectura era mucho más rápida que con el tacto.

Eran los primeros intentos de realizar prótesis neuronales. Hoy todavía no están bien establecidas pues sigue habiendo problemas con la implantación permanente de electrodos en el cerebro: oxidación, inflamación de las meninges, etc. 

En 2002 el Instituto de Astrofísica de Canarias desarrolló un programa de sustitución sensorial en el que se crea un espacio visual sonoro. Se crea un espacio sonoro que los ciegos pueden interpretar. Pensemos por ejemplo que todos los objetos se recubren de campanillas que suenan al mismo volumen, la distancia viene señalada por el nivel de dicho volumen.


</doc>
<doc id="15338" url="https://es.wikipedia.org/wiki?curid=15338" title="Religión mexica">
Religión mexica

Los mexicas originalmente eran una de las tribus nahuas y cuando llegaron al valle de México, traían sus propias creencias y divinidades. La más importante de sus divinidades era Huitzilopochtli, cuyo nombre puede traducirse literalmente como "colibrí izquierdo", "el colibrí zurdo" o "colibrí del sur"; sin embargo, según Laurette Séjourné, en el lenguaje esotérico náhuatl se puede traducir como "el alma del guerrero que viene del paraíso".

Al llegar al valle de México o valle del Anáhuac, los mexicas trataron de incorporar la cultura y los dioses de las civilizaciones más avanzadas que ya estaban establecidas, así como los de civilizaciones más antiguas como la tolteca; así, incluyeron a Tláloc, Tezcatlipoca y a Quetzalcóatl.

Sin embargo, algunos dirigentes mexicas (como Tlacaelel) modificaron la historia para poner a su dios tribal, Huitzilopochtli, al mismo nivel que los demás dioses nahuas.

Conforme los mexicas comenzaron a conquistar a otros pueblos, fueron aceptando nuevos dioses y enlazando sus historias con las de los dioses que ya tenían.

Estudiosos como Miguel León-Portilla sugieren que, en la época de la conquista, los mexicas estaban en un proceso de sincretización donde todos los dioses serían sólo expresiones de las potencias de una deidad principal, Ometéotl/Omecíhuatl. 

Ésta es una antigua pareja de dioses; sus nombres literalmente significan "Señor dios, Señora dios", pero usualmente se traduce como "nuestro señor/señora de la dualidad", lo que implica un dios con características femeninas y masculinas. Este dios es mucho más antiguo que la civilización nahua, y según algunas leyendas es el origen de todos los dioses. El pueblo difícilmente lo conocía, pero entre las clases superiores se le rendía una especie de culto. Otros nombre que recibía eran: "El señor del cerca y junto", "El inventor de sí mismo" y Tonacatecuhtli ("El señor de nuestra carne").

Por fuera de la religión popular, llena de dioses con complicadas historias y parentescos, producto del sincretismo de las civilizaciones nahuas y de la herencia tolteca, los sacerdotes y los tlamatinime (sabios) desarrollaron una profunda visión monista (según los eruditos más destacados, como Alfonso Caso y León-Portilla). Otros investigadores, como A. R. Sandstrom, con base en investigaciones sobre las comunidades nahuas del México actual, sostienen que la concepción era panteísta, postura que es apoyada por Hunt, Markman, Florescano y Ortiz de Montellano.

La síntesis de estas concepciones se centra en la figura de Téotl ("q.v."), y su traducción a la religión popular en el dios dual (o pareja de dioses) Ometéotl.

La cultura mexica es particularmente notable por la práctica de sacrificios humanos; los ofrecimientos a Huitzilopochtli serían hechos para restaurar la sangre que perdió, ya que el sol era confrontado en una batalla diaria. Esto prevendría el fin del mundo que podría suceder en cada ciclo de 52 años. La dedicación del gran templo en Tenochtitlán fue divulgado por los mexicas según lo referido, con un sacrificio de más de 84.000 prisioneros; sin embargo, este número probablemente fue una exageración de los mismos mexicas para infundir miedo entre sus enemigos, pues en el relato insisten en que el Tlatoani sacrificó personalmente a todas las víctimas en el curso de 4 días. Como medida de comparación, en los días finales del campo de concentración de Dachau, con tecnología moderna las 24 horas, se podía disponer de 4.500 víctimas al día.

Las víctimas sacrificadas a Xipe Tótec eran atadas a un poste y eran cubiertas por completo por flechas que les eran lanzadas. Posteriormente el cadáver sería desollado y un sacerdote se cubriría con la piel. Representan la renovación de la tierra para volver a ser fértil. La Madre Tierra, Teteoinnan, requería víctimas femeninas desolladas. Tláloc requería niños enfermos masculinos.

Los mexicas frecuentemente iniciaban guerras - las llamadas guerras floridas - con el intento de capturar prisioneros para usarlos en los sacrificios. Existen múltiples relatos de los conquistadores capturados que fueron sacrificados durante las guerras de la conquista española de México, aunque solamente Bernal Díaz afirmó ser un testigo de ello.

En ocasiones, los mexicas mataban a los cautivos más aristocráticos, notables por su valor en combate ritual: encadenaban la víctima al piso, quien vestía solamente un taparrabos, le daban un arma falsa y un escudo, y era muerto luchando contra un guerrero jaguar completamente armado. Se dice que cuando un pueblo era derrotado, los sacerdotes mexicas seleccionaban de los cautivos, al guerrero más destacado de los adversarios y lo tiraban por las escaleras del Templo Mayor. Al terminar su caída, los intestinos eran utilizados para las fieras del zoológico, y el cuerpo era entregado al guerrero. Este hervía el cuerpo y separaba la carne, se quedaba con los huesos como trofeo y partía la carne en fragmentos muy pequeños que ofrecía a los señores, incluso de otros pueblos. Los señores pretendían comerla, pero según algunos relatos, como el Códice Ramírez, y la relación del nieto de Nezahualcóyotl, la carne en sí, se consideraba que carecía de valor, por lo que era sustituida por carne de guajolote (pavo). A cambio de esta carne, el guerrero recibía grandes obsequios: Joyas, plumas ricas, mantas finas y esclavos. Este era un método para estimular a los guerreros exitosos y ayudarlos a subir en la escala social.

Tezcatlipoca requería un sacrificio voluntario. Cada año un joven era ofrecido como víctima. Durante un año lo honrarían como dios en la tierra, y entonces éste sería sacrificado. Tláloc requería niños llorones (enfermos). Xilonen requería ahogar a dos jóvenes.

A pesar de los relatos populares, los mexicas no hacían sacrificios humanos cada día. Los sacrificios se hacían sólo en los días festivos. Un día festivo por cada uno de sus 18 meses. Cada mes estaba dedicado a un dios distinto.

También se hacían sacrificios de animales, había dos razas de perros criados expresamente para ello, y la gente también hacía autosacrificio, ofrendando su propia sangre y sufrimiento a sus dioses.

En la adoración del Sol de las religiones mexica, inca y maya los sacrificios humanos eran algo común. Los aztecas celebraban unos constantes ciclos de fiestas religiosas con sacrificios humanos a sus diversos dioses, especialmente al adorar al dios-Sol Tezcatlipoca. Además, en la fiesta al dios del fuego, Xiuhtecuhtli (Huehueteotl), "a los prisioneros de guerra se les hacía danzar con sus captores y [...] se les hacía girar alrededor de un fuego intenso y entonces se les arrojaba en las brasas y se les alzaba mientras todavía estaban vivos para sacarles el corazón todavía palpitante y ofrecerlo a los dioses”.

Las formas y manifestaciones del Sol son un componente central de la cosmogonía mexica. Por lo tanto, no habrá de sorprender que sus calendarios (ver calendario azteca) sean solares y estén directamente vinculados a diversas formas religiosas. El calendario mesoamericano está integrado por 18 meses de 20 días cada uno, más 5 días nefastos.




</doc>
<doc id="15339" url="https://es.wikipedia.org/wiki?curid=15339" title="Thomas Alva Edison">
Thomas Alva Edison

Thomas Alva Edison (Milan, Ohio; 11 de febrero de 1847-West Orange, Nueva Jersey; 18 de octubre de 1931) fue un inventor, científico y empresario estadounidense. Desarrolló muchos dispositivos que han tenido gran influencia en todo el mundo, como el fonógrafo, la cámara de cine o una duradera bombilla incandescente. Apodado «El mago de Menlo Park», Edison fue uno de los primeros inventores en aplicar los principios de la producción en cadena y el trabajo en equipo a gran escala al proceso de invención, motivos por los cuales se le reconoce la creación del primer laboratorio de investigación industrial.

Edison fue un inventor prolífico que registró 1093 patentes a su nombre en Estados Unidos, además de otras en Reino Unido, Francia y Alemania. Pero más importante que sus muchas patentes fue el amplio impacto que tuvieron algunas de sus invenciones: la luz eléctrica y el suministro público de electricidad, la grabación de sonido y la cinematografía se convirtieron en nuevas y poderosas industrias en todo el mundo. Sus inventos contribuyeron en particular a las telecomunicaciones, como una máquina de voto, una batería para un automóvil eléctrico, la energía eléctrica, la grabación de música y las películas. Sus avanzados trabajos en estos campos no fueron más que una continuación de su primer trabajo como radiotelegrafista. Edison desarrolló un sistema de generación y distribución de energía eléctrica a las casas, negocios y fábricas, un avance crucial para el mundo industrializado moderno.

Hijo de Samuel Ogden Edison, Jr. (1804-1896) y Nancy Matthews Elliott (1810-1871). Sus antepasados provenían de Ámsterdam y se establecieron en el río Passaic, en Nueva Jersey. John Edison, el abuelo del inventor, se alistó en el bando de los británicos durante la Guerra de Independencia y, a final de la misma, tuvo que refugiarse en Nueva Escocia. Después de un tiempo se trasladó a Canadá para residir en Bangham, en la zona del lago Erie. Cuando estalló la rebelión canadiense en 1837, Samuel Edison (padre del inventor) se unió a los insurgentes. Una vez más la familia se vio obligada a huir a los Estados Unidos.

En 1840 Samuel Edison estableció una pequeña maderería en Milan, Ohio. Antes de que la familia se estableciera en Milan, su esposa Nancy, una canadiense de ascendencia escocesa, había tenido cuatro hijos. Posteriormente tuvo tres más, pero murieron tres de los primeros en la década de 1840 y los sobrevivientes tenían catorce, dieciséis y dieciocho años cuando el 11 de febrero de 1847, la esposa de Samuel Edison dio a luz a su séptimo hijo. Le llamaron "Thomas" por un antepasado de la familia, y "Alva" en honor del capitán Alva Bradley.

En 1855 a los ocho años y medio Edison entra a la escuela. Después de tres meses de estar asistiendo, regresó a su casa llorando, informando que el maestro lo había calificado de alumno "estéril e improductivo". Es imposible establecer si Nancy Edison tomó muy en serio la opinión de su maestro o si pensó que ella era mejor que el profesor de su hijo. El caso es que Edison recordó durante el resto de su vida el resultado del dichoso incidente. La madre de Edison sacó al niño del colegio y lo educó en casa. Después de las tareas domésticas, le enseñó a leer y escribir correctamente, además de aritmética, y comenzó a leerle algunos libros que no estaban entre lo más común del momento: La caída del Imperio Romano, Historia de Inglaterra, Historia del mundo, y a Shakespeare y Dickens. En torno a los 9 años fue cuando Edison comenzó a leer solo, en parte impulsado por su padre, Samuel, que le daba 10 céntimos cada vez que concluía un libro.

En 1859 empezó a vender diarios en el tren matutino que iba de Port Huron a Detroit, así como verduras, mantequilla y moras. En Detroit el tren hacía una parada de seis horas, las cuales aprovechaba pasándolas en el salón de lectura de la Asociación de Jóvenes (después Biblioteca Gratuita de Detroit). Ahí, comenzaba por leer el primer libro que se encontraba en el anaquel inferior y seguía por orden con los demás hasta terminar con toda la hilera.

Edison no quedaba satisfecho con solo leer, y comenzó a realizar diversos experimentos basándose en lo que leía en los libros de Ciencia. Utilizaba un vagón vacío como laboratorio, donde también instaló una pequeña prensa de mano que se agenció cuando un amigo del "Detroit Free Press" le regaló algunos tipos. El resultado fue inmediato: el "Grand Trunk Herald", semanario del que Edison tiraba cuatrocientos ejemplares.

Tras salvar a un niño en las vías del tren en Port Huron, el agradecido padre de la criatura J. U. Mackenzie (telegrafista de la estación) le enseñó código morse y telegrafía. A los quince años obtuvo su primer trabajo como telegrafista, reemplazando a uno de los operadores de telégrafo que habían ido a servir en la Guerra Civil.

A los 16 años, después de trabajar en varias oficinas de telégrafos, donde realizó numerosos experimentos, finalmente llegó con su primera auténtica invención, llamada "repetidor automático", que transmite señales de telégrafo entre estaciones sin personal, lo que permite que prácticamente cualquiera pueda traducir fácilmente y con precisión un código a su propio ritmo y conveniencia. Curiosamente, nunca patentó la versión inicial de esta idea.

Edison ideó un instrumento sencillo para el recuento mecánico de votos en 1868. Se podía colocar en la mesa de cada representante; tenía dos botones, uno para el voto en pro y otro para el voto en contra. Para tramitar la patente, Edison contrató al abogado Carroll D. Wright. El instrumento se llevó ante un comité del Congreso de Washington. Ahí el veredicto fue brusco pero honesto: "Joven, si hay en la tierra algún invento que no queremos aquí, es exactamente el suyo. Uno de nuestros principales intereses es evitar fraudes en las votaciones, y su aparato no haría otra cosa que favorecerlos".

En 1869, Edison y Franklin Pope ofrecieron sus servicios como ingenieros electricistas, una especialidad desconocida por entonces. Pero Edison se retiró porque sentía que no ganaba suficiente. En Nueva York, consiguió un empleo de condiciones muy ventajosas tras reparar una grave avería en un indicador telegráfico que señalaba los precios del oro en la Bolsa.

Trabajó en la compañía telegráfica Western Union como inventor y reparador, aunque poco después se independiza y en 1877 lleva a cabo uno de sus más importantes inventos, el fonógrafo.

En 1876, Edison se mudó de Newark a Menlo Park, Nueva Jersey, donde reunió un grupo de ayudantes y mecánicos y estableció una "fábrica de inventos". En 1887, cuando dejó Menlo Park, contaba con una lista de casi cuatrocientas patentes.

Aunque se le atribuye la invención de la lámpara incandescente, esta en realidad solo fue perfeccionada por él, quien, tras muchos intentos consiguió un filamento que alcanzara la incandescencia sin fundirse. Este filamento no era de metal, sino de bambú carbonatado. Así, el 21 de octubre de 1879, consiguió que su primera bombilla luciera durante 48 horas seguidas. En la víspera de Año Nuevo del mismo año, se hizo funcionar con éxito en Menlo Park el primer sistema de alumbrado, construido por Edison, constituido por cincuenta y tres focos.

En 1880 se asocia con J. P. Morgan para fundar la Edison Electric. Después J. P. Morgan adquiriría sus acciones para crear General Electric.

En el ámbito científico, descubrió el efecto Edison, patentado en 1883, que consistía en el paso de electricidad desde un filamento a una placa metálica dentro de un globo de lámpara incandescente. Aunque ni él ni los científicos de su época le dieron importancia, estableció los fundamentos de la válvula de la radio y de la electrónica (el denominado "efecto Edison").

Tuvo una significativa relación laboral con otro inventor que luego le equipararía en genialidad, Nikola Tesla. En junio de 1884, llegó por primera vez a los Estados Unidos, a la ciudad de Nueva York, con poco más que una carta de recomendación de Charles Batchelor, un antiguo empleado y colaborador de Edison. En la carta de recomendación, escribió, «conozco a dos grandes hombres, usted es uno de ellos; el otro es este joven» (Tesla). Edison contrató a Tesla para trabajar en su Edison Machine Works. Empezó a trabajar como un simple ingeniero eléctrico, resolviendo algunos de los problemas de la compañía. 

La compañía de Edison había instalado varias dinamos en el SS "Oregon", en aquel momento uno de los transatlánticos más rápidos y el primer barco en contar con electricidad a bordo, empleada para la iluminación del barco.
En 1884 las dinamos se dañaron, lo que retrasó la salida del buque de Nueva York. Tesla se presentó voluntario para realizar la reparación, y estuvo trabajando toda la noche para lograr hacer funcionar de nuevo las dinamos, gracias a lo cual recibió las felicitaciones de Edison a la mañana siguiente.

La relación con Tesla duraría poco, ya que en 1885 Tesla consideraba que sus aportes en el mejoramiento de las dínamos y por hacer más eficientes los motores eléctricos bien le valían un aumento de su remuneración desde los US$ 18 a la semana a US$25, como no llegaron a acuerdo y se consideró subvalorado, Tesla bruscamente renunció a la compañía de Edison para en 1886 fundar su propia compañía.

En 1886, Tesla tuvo que dejar su propia compañía y se asoció con George Westinghouse quien había fundado la Westinghouse Electric. Entre esta compañía y la de Edison se produjo la llamada Guerra de las corrientes, donde dos sistemas rivales se disputaban lo que sería el futuro del mercado eléctrico comercial. Primando los principios de Tesla, sería la corriente alterna la cual finalmente se impondría.

En 1894 los quinetoscopios de Edison llegan por primera vez a Europa; más concretamente a Francia. Dos años después, en 1896, presenta el vitascopio en Nueva York con la pretensión de reemplazar a los quinetoscopios y acercarse al cinematógrafo inventado por los hermanos Lumière.

Las aportaciones de Edison al mundo del cine también fueron muy importantes. En 1889 comercializa la película en celuloide en formato de 35 mm, aunque no la pudo patentar porque un tiempo antes George Eastman ya lo había hecho; aunque sí pudo patentar las perforaciones laterales que tiene este tipo de película.

Por último, en 1897, Edison comenzará la llamada «guerra de patentes» con los hermanos Lumière respecto al invento de la primera máquina de cine.

Murió el 18 de octubre de 1931, en West Orange, Nueva Jersey. Como homenaje póstumo, fueron apagadas las luces de varias ciudades durante un minuto.

Es uno de los inventores más prolíficos de la historia: la obtención de su última patente, la 1093.ª, fue a sus 83 años.






</doc>
<doc id="15340" url="https://es.wikipedia.org/wiki?curid=15340" title="Iglesia de Roma">
Iglesia de Roma

Iglesia romana o de Roma puede referirse a:

En contextos actuales:

En contextos históricos:

</doc>
<doc id="15342" url="https://es.wikipedia.org/wiki?curid=15342" title="Mesolítico">
Mesolítico

Mesolítico es el término que se utiliza para resumir el período de la prehistoria que sirve de transición entre el Paleolítico y el Neolítico. Significa "Edad media de la piedra" (del griego μεσος, "mesos"=medio; y λίθος,"líthos"=piedra) por contraposición al Paleolítico ("Edad antigua de la piedra") y al Neolítico ("Edad nueva de la piedra"), identificándose con las últimas sociedades de cazadores-recolectores. Los hábitos de las culturas del Mesolítico eran básicamente nómadas, con asentamientos estacionales de invierno y campamentos de verano, aunque en algunas regiones costeras europeas y en el Oriente Próximo (ahí donde encontraron recursos suficientes y regulares) comenzaron a vivir de una manera más sedentaria. Esto fue posible gracias a la ampliación del espectro alimentario, que incluyó una gran variedad de alimentos que los especializados cazadores del Paleolítico superior no consumían. Relacionado con estos cambios de dieta estaría la mayor diversificación, especialización y cantidad de utensilios líticos, así como la desaparición de la pintura rupestre figurativa paleolítica, reemplazada por un arte más abstracto.

El término Mesolítico fue acuñado por John Lubbock en su obra "Prehistoric Times", de 1865, cuando estableció la división de la Edad de Piedra anteriormente mencionada. Durante mucho tiempo fue visto únicamente como una etapa de transición, de decadencia incluso, entre los otros dos grandes períodos. Pero a principios del siglo XX se demostró que había una clara continuidad cultural, por lo que se acuñó un término nuevo para definir esta fase: Epipaleolítico ("Por encima del Paleolítico"), que no fue aceptado en todo el mundo científico. Actualmente, en el ámbito anglosajón generalmente se utilizan ambos términos como sinónimos, mientras que en el área de influencia académica francesa se suele establecer una clara diferencia entre ellos: 

Una tercera tendencia sería la de aquellos autores que identifican Epipaleolítico con las sociedades del Holoceno inicial de clara tradición paleolítica y Mesolítico con sus sucesoras.

Por último, hay quien propone un tercer término para este periodo:

El Mesolítico comenzaría con la transición del Pleistoceno al Holoceno, hace unos 12 000 años, y finalizaría con la aparición de los modos de vida productores, cuya cronología varía mucho de unas regiones a otras y de un continente a otro: mientras que en el Oriente Próximo la neolitización despuntaba sobre el 9000 a. C., a Escandinavia y ciertas áreas de la Europa atlántica no llegó hasta el 4000 a. C.

En el Oriente Próximo la dieta de espectro amplio empezó a adoptarse hacia el 12000 a. C. con los grupos natufienses, herederos de los kebarienses, que presentan las primeras muestras de urbanismo en el yacimiento de Nahal Oren. El natufiense es un complejo cultural que se extendió por todo el Levante mediterráneo y se caracteriza por la existencia de pequeñas aldeas formadas por cabañas circulares con zócalos de piedra que, en ocasiones, tienen silos anexos donde se guardaba el cereal silvestre recolectado, aunque también sirvieron como lugar de enterramiento. De forma paralela se desarrollaron los grupos de Karim Shair en el norte de Irak, los cuales recolectaban también vegetales y empezaban a ensayar la domesticación de la cabra. Hay procesos similares y contemporáneos en el Alto Egipto y Nubia. Hacia el 10300 a. C. estos comienzan a darse en el norte de India, en el estado de Uttar Pradesh. Sobre el 9000 a. C. en el sur de China, en la provincia de Yunnan, así como en Japón, México, costa peruana y valle del río Misisipi.

Esta época estuvo marcada por la finalización del último periodo glacial y la progresiva implantación de un clima templado/cálido que permitió el aumento de los bosques y la biodiversidad, aunque también provocó la inundación de amplias zonas costeras. Cambios que influyeron necesariamente en el comportamiento y en la cultura material de los humanos de la época.

La retirada de los hielos en Eurasia y América del Norte condujo a la formación de extensas praderas temporales que fueron pronto sustituidas por frondosos bosques. Alrededor de los trópicos se crearon amplias fajas esteparias y/o semidesérticas. Como consecuencia de estos cambios ecológicos y sobre todo de la presión cinegética del "Homo sapiens", la megafauna pleistocénica se extinguió, aunque mamíferos como el reno y el bisonte emigraron hacia latitudes más nórdicas. Prosperaron animales de costumbres forestales y menos gregarias, cuya caza resultaba más compleja: el ciervo, el alce o el jabalí.

Al comenzar el Holoceno, el Levante mediterráneo presentaba un variado mosaico de ecosistemas formado por llanuras costeras, una franja boscosa, estepas mesetarias y desiertos. Estos ambientes albergaban una rica fauna y flora que permitió a sus pobladores asentarse de manera más o menos estable en aldeas manteniendo una economía de caza-recolección.

Al desaparecer o emigrar los animales que suponía la base de la dieta humana en el Paleolítico superior el espectro alimentario tuvo que ser ampliado. Para cazar las especies forestales el hombre debió utilizar perros, el primer animal que domesticó, ya a finales del Paleolítico superior en Europa occidental. La dieta se diversificó enormemente, incluyendo entonces otros pequeños mamíferos y aves como los gansos, tordos, faisanes, palomas, etc. La recolección de frutos y raíces se extendió, y aumentó espectacularmente el consumo de caracoles y conchas, como lo demuestran los enormes "concheros" de la vertiente atlántica europea y los "caracoleros" de las cuevas pirenaicas. También se comenzó a desarrollar la pesca fuera de la costa, en mar abierto.

Se fabricaron trineos, en un principio tirados por hombres y luego por perros, y canoas hechas con pieles o cortezas de árboles. De la corteza del abedul extraían un producto utilizado como cola. Aunque en Europa nunca se abandonaron del todo las cuevas, se construían también chozas de troncos y ramas a orillas de los ríos, en las cuales vivían al aire libre, y de las cuales se conservan pocos vestigios, pero en cuyos emplazamientos se localizan objetos de piedra tallada; tales lugares son conocidos como "talleres de sílex". En lugares costeros ricos en pesca y marisco se establecieron los primeros asentamientos permanentes de gran tamaño.

La industria lítica muestra una clara tendencia a la fabricación de pequeños utensilios adaptados a las nuevas situaciones y usos, muy especializados, los microlitos. Estos eran utilizados para la recolección de moluscos y para su apertura, como puntas de flecha, como raspadores, buriles, etc. Las armas más abundantes fueron los arcos, hechos de madera y tendones de animales, con flechas que incorporaban en su punta microlitos de variadas formas geométricas: triángulos, trapecios, etc. También se usaron flechas manufacturadas enteramente en hueso, en asta o en madera.

En el Próximo Oriente se produjo un aumento en la densidad de la población, que comenzó claramente a hacerse más sedentaria. En la que se conoce como cultura natufiense ya se anticipaban los grandes cambios del Neolítico. Eran cazadores-recolectores altamente especializados en la caza de la gacela y en la recolección de cereales silvestres, que almacenaban en silos situados en campamentos base ocupados durante todo el año. Estos estaban formados por aglomeraciones de viviendas circulares, semiexcavadas en el suelo, de una sola habitación y probablemente construidas con troncos y ramas. Utilizaban molinos y morteros de piedra de gran tamaño (algunos de ellos decorados en sus bordes), hoces y cuchillos de hueso adornados con figuras de animales, y enterraban a sus muertos en necrópolis cercanas a los poblados (en cuevas) o bajo el suelo de las casas. En los ajuares de estos enterramientos se comienzan a apreciar diferencias sociales que pueden estar relacionadas con unas incipientes jerarquización y desigualdad sociales, inexistentes hasta el momento, pero que tendieron a aumentar en los siguientes períodos.

Al terminar el Paleolítico Superior también desaparecieron con él sus espléndidas manifestaciones artísticas, apareciendo otras nuevas, influenciadas, inevitablemente, por los cambiantes factores climáticos y los nuevos hábitos socio-económicos. El problema de este nuevo arte postpaleolítico es que resulta muy difícil de datar y los investigadores no se ponen de acuerdo acerca de su periodización. Unos opinan que representaciones como las del arte naturalista levantino son ya del Neolítico inicial, otros que es anterior. De cualquier manera el arte no desapareció y lo seguimos encontrando en abrigos rocosos (arte parietal) y en objetos personales (arte mueble).

El arte se volvió conceptual y racionalista, basado en lo geométrico y lo abstracto. La cultura aziliense de la cornisa cantábrica y del Pirineo francés nos ha deparado abundantes cantos rodados decorados con seriaciones de bandas, puntos, ramiformes, etc., de carácter abstracto, y a los que se les otorga un significado mágico/simbólico. La cultura natufiense destaca, entre otras cosas, por sus características representaciones de animales en morteros de mano, mangos de hoz o cuchillos, o sea, por su arte mueble.

En el Levante español grupos humanos dejaron pinturas que muestran una evolución del arte rupestre hacia modelos más esquemáticos, que representaban movimiento. En las paredes de los abrigos rocosos estos hombres pintaron complejas escenas de caza, de danzas y ritos mágicos. Las figuras están hechas con pigmentos negros o rojizos, y son muy estilizadas. A pesar de ello se pueden identificar personajes como hechiceros/chamanes, gracias a los tocados que les cubren la cabeza, a los bastones que llevan y a los adornos que les cuelgan de rodillas y brazos; también se aprecian hombres con plumajes y brazaletes en brazos y tobillos, mientras que las mujeres lucen largas faldas. Hay mucho movimiento (como contraste con el arte paleolítico) y las luchas entre grupos aparecen con relativa frecuencia, con batallas de arqueros que incluso llegan al cuerpo a cuerpo.

En Sierra Morena (Andalucía) se han encontrado figuras antropomórficas y teriomórficas (especialmente de cabras montesas y ciervos) muy esquematizadas, junto a signos del tipo de círculos, puntos, soles, ondulaciones. Otras representaciones importantes se han descubierto en Alpera (Albacete), Cogul (Lérida), "Barranco de los Gascones" (Teruel), Villar del Humo (Cuenca) o "Barranco de Gazulla" (Castellón).

Para ciertos autores la revolución neolítica comenzó a gestarse realmente durante el Mesolítico. Para B. Hayden y A. Testart durante este período aparecieron grupos de cazadores-recolectores especializados en unos pocos tipos de recursos abundantes y seguros, que se podían almacenar durante buena parte del año, lo que les permitió aumentar su demografía y sedentarizarse. La acumulación de bienes habría provocado las primeras desigualdades sociales y la aparición de jerarquías, encabezadas por aquellos que se habrían encargado de la gestión de los excedentes. Así habrían surgido las jefaturas, ligadas siempre en sus tomas de decisiones a los chamanes. Para Testart, la recolección y la caza intensivas de unas pocas especies, habría llevado gradualmente a una serie de mejoras técnicas que seleccionaron artificialmente aquellas, desembocando naturalmente en su posterior domesticación. Por todo ello, ambos consideran que la verdadera revolución se produjo en el Mesolítico, cuando fueron establecidas las bases económico-sociales que se desarrollaron posteriormente, durante el Neolítico.




</doc>
<doc id="15343" url="https://es.wikipedia.org/wiki?curid=15343" title="Imperio sasánida">
Imperio sasánida

El Imperio sasánida (en persa medio: , "Erānšahr" o "Iranšæhr"; tr.: "Dominios de los iranios") es el nombre que recibe el segundo Imperio persa durante su cuarta dinastía irania (226-651). La dinastía sasánida fue fundada por Ardacher I tras derrocar al último rey arsácida, Artabán IV de Partia, y terminó cuando el último Shahanshah ("Rey de reyes") sasánida Yazdgerd III (632-651) perdió una prolongada guerra de 14 años contra el primero de los califatos islámicos. El territorio del Imperio persa sasánida comprendía los actuales países de Irán, Irak, Azerbaiyán, Armenia, Afganistán y partes del este de Turquía y Siria, además de parte de Pakistán, el Cáucaso, Asia Central y Arabia. Además, durante el gobierno de Cosroes II (590-628), se anexionaron al imperio los territorios de los actuales Egipto, Jordania, Líbano y Palestina, llegando a ejercer un "protectorado" sobre territorios actualmente correspondientes a Omán y Yemen.

El periodo sasánida, que comprende todo el periodo final de la antigüedad clásica e incluso la sobrevive unos siglos, se considera uno de los periodos históricos más importantes e influyentes de la historia de Irán. En muchos aspectos, el periodo sasánida alcanzó los mayores logros de la cultura persa, y constituyó el último gran imperio iranio antes de la conquista islámica de Persia y la adopción del islam como religión en todo el territorio. La Persia sasánida fue rival de la civilización romana por el control de Oriente Próximo y Mesopotamia. Su influencia cultural se extendió mucho más allá de los territorios fronterizos de ambos imperios, llegando hasta la Europa occidental, África, China e India, y jugó un papel fundamental en la formación del arte medieval europeo y asiático. Esta influencia llegó a través del mundo islámico que adoptó muchos aspectos de su arte y protocolo. La cultura aristocrática y exclusiva de la dinastía sasánida transformó la conquista islámica de Irán en un ‘renacimiento’ persa. Gran parte de lo que posteriormente sería conocido como ‘cultura islámica’ (arquitectura, escritura y otras habilidades) fueron adopciones del amplio mundo islámico a partir de los modelos persas sasánidas.

La dinastía sasánida fue establecida por Ardacher I (226-241), descendiente de una línea de sacerdotes de la diosa Anahita en Istajr, en la provincia persa de Fars, quienes a principios del siglo III habían accedido al gobierno de la provincia. El padre de Ardacher, de nombre Papag (también conocido como ‘Papak’ o ‘Babak’) era en principio el gobernante de un pequeño pueblo llamado Jeir, pero en el año 205 depuso al último rey de los Bazrangi, Gocihr (señor local que actuaba en calidad de cliente de los arsácidas), proclamándose nuevo gobernante. Su madre, Rodhagh, era la hija del gobernador provincial de Peris. El fundador epónimo de la línea dinástica fue el abuelo paterno de Ardacher I, llamado Sasán, gran sacerdote del templo de Anahita.

Los esfuerzos de Pabag por apoderarse de la provincia escaparon a la atención del emperador arsácida Artabán IV de Partia, que en aquellos días se encontraba envuelto en un conflicto dinástico con su hermano Vologases VI en Mesopotamia. Aprovechando la oportunidad que estas circunstancias le ofrecían, Pabag y su primogénito Sapor trataron de expandir su poder sobre toda Persia. Se ignoran los acontecimientos que siguieron debido a lo incompleto de las fuentes, pero se cree que tras la muerte de Pabhag sobre el año 220, Ardacher, que era entonces gobernador de Darabgird, disputó el poder a su hermano mayor Sapor. Las fuentes nos dicen que en el 222 Sapor murió al derrumbarse el edificio donde iba a reunirse con su hermano.

En ese momento, Ardacher trasladó su capital aún más al sur de Persis, fundando una ciudad en Ardashir-Jwarrah (antiguamente conocida como "Gur" y actualmente Firuzabad). La localidad, ubicada entre altas montañas, era fácilmente defendible gracias a sus estrechos accesos, y se convirtió en el centro del poder sasánida. Estaba además rodeada por una alta muralla circular, copiada probablemente de la de Darabgid. Al norte se construyó un gran palacio del cual aún se conservan algunos restos.

Tras establecer su dominio sobre Persis, Ardacher I extendió rápidamente su territorio, exigiendo la lealtad de los príncipes locales de Fars y obteniendo el control sobre las provincias vecinas de Kermán, Isfahán, Susiana y Menese (la actual Kuwait). Esta rápida expansión llamó la atención de Artabán IV (216-224), del cual Ardacher era vasallo.

Inicialmente, Artabán ordenó al gobernador del Juzestán marchar contra Ardacher en el año 224, pero el enfrentamiento concluyó con una importante victoria de Ardacher. Posteriormente fue el mismo Artabán quien organizó una segunda campaña contra Ardacher, y ambos ejércitos se enfrentaron en Hormizdeghan, donde Artabán IV resultó muerto.

Ardacher marchó entonces a invadir las provincias occidentales del difunto emperador arsácida. En el año 226 fue coronado en Ctesifonte único señor de Persia y comenzó a utilizar el título de Shahanshah ("rey de reyes"), terminando con cuatro siglos de imperio parto y dando principio a otros tantos de gobierno sasánida.

Durante los años siguientes, y tras algunas rebeliones locales a lo largo del Imperio, Ardacher I amplió aún más su nuevo Estado hacia el este y noroeste, conquistando las provincias de Sistán, Gorgán, Jorasán, Margiana (en el actual Turkmenistán), Balj y Corasmia. Además, anexionó Baréin y Mosul a las posesiones sasánidas. Posteriores inscripciones sasánidas afirman también la sumisión de los reinos de Kushán, Turán y Mekrán a Ardacher, aunque basándose en las pruebas numismáticas es más probable que estos reinos fueran sometidos por el hijo de este, Sapor I. Al oeste, las campañas contra Hatra, Armenia y Adiabene tuvieron menos éxito.

El hijo de Ardacher, Sapor I (241-272), continuó la expansión emprendida por su padre, conquistando Bactria y Kushán, al tiempo que llevaba a cabo numerosas campañas contra Roma. Penetrando profundamente en territorio romano, Sapor I se adueñó de Antioquía, en Siria (253 o 256), y derrotó finalmente a los emperadores romanos Gordiano III (238-244), a Filipo el Árabe (244-249) y a Valeriano (253-260). Este último fue hecho prisionero en el 259 tras la batalla de Edesa, una tremenda hecatombe sin parangón en la historia romana. Sapor I celebró su victoria encargando la talla de los impresionantes relieves de Najsh-i-Rostam o Naqsh-e Rostam, así como una monumental inscripción en persa y griego en las proximidades de Persépolis. Entre 260 y 263, empero, perdió algunos de los territorios recientemente conquistados a manos de Odenato, aliado de Roma.

Sapor I tenía un intensivo plan de desarrollo. Fundó un importante número de ciudades, habitadas algunas de ellas por emigrantes procedentes de territorio romano. Entre estos inmigrantes se incluían cristianos y judíos, que podían profesar su fe libremente bajo el gobierno sasánida. En el aspecto religioso Sapor favoreció particularmente el maniqueísmo; protegió a Mani y envió misioneros maniqueos por doquier. Asimismo, trabó amistad con un rabino judío babilonio llamado Samuel, relación que fue ventajosa para la comunidad judía, ya que le dio un respiro de las opresivas leyes dictadas hasta entonces contra ella.

Posteriores reyes abandonaron la tolerancia religiosa de Sapor. Su propio sucesor, Bahram I (273-276), persiguió a Mani y a sus correligionarios. Mani fue encarcelado y Bahram I ordenó su ejecución, aunque una leyenda posterior afirma que murió en prisión mientras esperaba a ser ajusticiado.

Bahram II (276-293) continuó la política religiosa de su padre. Fue un gobernante débil que perdió numerosas provincias occidentales a manos del emperador romano Caro (282-283). Durante su reinado, la mayor parte de Armenia, que había permanecido en manos persas durante medio siglo, pasó a control de Diocleciano (284-305).

Tras el breve reinado de Bahram III en 293, Narsés (293-302) se embarcó en una nueva guerra contra Roma. Tras el éxito inicial obtenido contra el futuro emperador romano Galerio (305-311) cerca de Callinicum, junto al Éufrates en 296, Narsés fue derrotado en una emboscada mientras se encontraba con su harén en Armenia el año 297. En el tratado que concluyó esta guerra, los sasánidas cedieron todas las tierras al oeste del Tigris y acordaron no entrometerse en los asuntos de Armenia y Georgia.

Después de esta aplastante derrota, Narsés abdicó en 301; falleció un año más tarde. Su hijo Ormuz II (302-309) ascendió entonces al trono. Aunque aplastó las revueltas que estallaron en Sistán y Kushán, fue otro monarca débil e incapaz de dominar a los nobles. Fue asesinado el año 309 por unos beduinos mientras cazaba.

La muerte de Ormuz II coincidió con el principio de una serie de correrías de los árabes desde el sur, en las que estos asaltaron algunas de las ciudades meridionales del Imperio y penetraron incluso en la provincia de Fars, cuna de los reyes sasánidas. Mientras tanto, los nobles persas asesinaron al primogénito de Ormuz II, cegaron a su segundo hijo y encarcelaron al tercero (que posteriormente huyó a territorio romano). El trono se reservó para el hijo no nacido de una de las viudas de Ormuz II.

Se dice que Sapor II (309-379) podría haber sido el único rey de la historia coronado antes de nacer. De hecho, colocaron la corona sobre el vientre de su madre. El niño nació, por lo tanto, siendo ya rey. Durante su juventud, el Imperio estuvo controlado por su madre y los nobles. Al alcanzar la edad adulta, asumió el poder y demostró con rapidez que era un gobernante activo y capaz.

En primer lugar, llevó a su pequeño aunque disciplinado ejército a luchar contra los árabes; los derrotó y aseguró así las tierras meridionales del Imperio. Tras esto acometió su primera campaña contra los romanos en el oeste, en la que obtuvo al comienzo algunas victorias. Tras el asedio de Singara, sin embargo, tuvo que abandonar sus conquistas por culpa de las incursiones nómadas a lo largo de las fronteras orientales del Imperio. Estas pusieron en peligro Transoxiana, una zona estratégica y vital para el control de la Ruta de la seda. Además, las fuerzas sasánidas eran insuficientes para conservar todo el territorio conquistado en el oeste; en consecuencia, Sapor firmó una tregua con Constantino II (337-340).

Hecho esto, marchó hacia Transoxiana, al encuentro de los nómadas orientales. Aplastó a las tribus de Asia Central y se apoderó de la región, que organizó como nueva provincia. A la victoria le siguió la expansión cultural y el arte sasánida penetró en el Turquestán, llegando incluso hasta China. Sapor II, junto al rey nómada Grumbates, emprendió una nueva campaña contra los romanos en el 359, esta vez empleando todo su poderío militar y gozando de la colaboración de los nómadas. Fue una campaña tremendamente exitosa en la que los persas arrebataron a los romanos un total de cinco provincias.

Sapor II siguió una rígida política religiosa. Durante su reinado se completaron los Avesta, los textos sagrados del zoroastrismo, se castigó la herejía y la apostasía y se persiguió de nuevo a los cristianos y también a los judíos. Estas persecuciones anticristianas y también antijudías fueron parte de una reacción contra la cristianización y legalización del judaísmo en el Imperio romano efectuadas por Constantino I el Grande (324-337). Sin embargo, Sapor II (al igual que Sapor I) fue un monarca que amparó a los judíos emigrantes (quienes vivieron en relativa libertad y obtuvieron muchas ventajas durante este período, no así los conversos de origen persa).

A la muerte de Sapor II, el Imperio persa era más fuerte que nunca, habiendo derrotado a sus enemigos del este y sometido Armenia.

Desde la muerte de Sapor II y hasta la primera coronación de Kavad I, Persia disfrutó de una relativa estabilidad, con solo algunas guerras contra el Imperio bizantino. A lo largo de esta época, la política religiosa del Imperio sasánida cambió radicalmente de un rey a otro. Con la excepción de una serie de monarcas débiles, el sistema administrativo establecido por Sapor II permaneció fuerte, y el Imperio siguió funcionando con normalidad.

Sapor II dejó a su muerte en 379 el poderoso Imperio persa a su hermanastro Ardacher II (379-383), hijo de Vahram de Kushan, y posteriormente heredaría su hijo Sapor III (383-388). Ninguno de ellos demostró tener el talento de su insigne predecesor.

Ardacher II, quien fue elevado al poder por ser hermanastro del emperador, fracasó al tratar de ocupar el hueco dejado por este, siendo lo más célebre de su reinado la construcción de una nueva capital en Taq-I Bustán, y Sapor III tenía un carácter demasiado débil como para alcanzar grandes logros.

Bahram IV (388-399), aunque fue un monarca más activo que su padre, tampoco supo proporcionar al imperio logros de importancia. Durante este tiempo, Armenia fue dividida por un tratado entre los imperios romano y sasánida. Los sasánidas restablecieron su dominio sobre la mayor parte de Armenia, mientras los bizantinos obtuvieron una pequeña porción del occidente de Armenia.

Al hijo de Barham IV, Yazdegerd I (399-421) se le compara con frecuencia con Constantino I. Como él, fue un personaje fuerte, tanto física como diplomáticamente. Como su contraparte romana, Yazdegerd I uso el poder de una forma oportunista. Al igual que Constantino el Grande, Yazdegerd practicó la tolerancia religiosa y dio libertad al auge de las religiones minoritarias. Detuvo la persecución contra los cristianos, castigando a los nobles y sacerdotes que les persiguieran. Su reino abarcó una época de relativa paz. Hizo la paz con los romanos e incluso tuvo al joven Teodosio II (408-450) bajo su custodia. También se casó con una princesa judía, quien le dio un hijo llamado Narsi.

A Yazdegerd I le sucedió su hijo Bahram V (421-438), que es uno de los reyes sasánidas mejor conocidos, y héroe de numerosos mitos posteriores pues esas leyendas persistieron incluso después de la destrucción del Imperio sasánida por los árabes. Bahram V, obtuvo la corona tras la repentina muerte (o asesinato) de su padre Yazdegerd I, y ello con la oposición de la nobleza del reino, que contaba con la ayuda de Al-Mundhir, de la dinastía árabe (lajmida) de al-Hirah. La madre de Bahram V era Soshandukht, hija de exiliados judíos.

En el año 427, Bahram V aplastó la invasión de los nómadas heftalitas en el este, extendiendo su influencia por Asia Central, donde su retrato sobrevivió durante siglos en las monedas de Bujará (la actual Uzbekistán). Bahram V depuso también el reino vasallo de la Armenia persa, convirtiendo la región en otra provincia.

Bahram V es un referente en la tradición persa, que relata muchas historias sobre su valor y belleza, de sus victorias sobre romanos, turcos, hindúes y etíopes axumitas, y sobre sus aventuras en la caza y el amor. Se le llamó Bahram-e Gur (Gur significa en persa "onagro"), por su amor a la caza y en particular a la caza del onagro. Bahram V es el paradigma de un rey en la cúspide de una edad de oro. Obtuvo su corona disputándola a su hermano, y aunque pasó bastante tiempo combatiendo a sus enemigos exteriores, prefería estar de caza y organizando fiestas en la corte con su famoso grupo de damas y cortesanas. Personalizaba la prosperidad real. Durante su reinado se escribieron las mejores obras de la literatura sasánida, se compusieron notables obras musicales y deportes como el polo se convirtieron en el pasatiempo real, una tradición que continúa todavía en muchos reinos.

Yazdegerd II (438-457), hijo de Bahram V, fue un gobernante justo y moderado, aunque en contraste con Yazdegerd I, practicó una política religiosa represiva con las minorías, especialmente con los cristianos.

Al principio de su reinado, Yazdegerd II reunió un ejército integrado por varias naciones, incluyendo a sus aliados hindúes, y atacó al Imperio romano de Oriente, que estaba construyendo fortificaciones en territorio persa, cerca de Carras (una estratagema usada por los romanos para lanzar expediciones desde ellas). Los persas tomaron a los romanos por sorpresa, y de no haber sido por una fuerte inundación, Yazdegerd podría haberse internado mucho más en territorio romano. El emperador bizantino Teodosio II pidió la paz enviando a su comandante a negociar al campamento de Yazdegerd. En 441, ambos imperios se comprometían a no construir más fortificaciones en la frontera. Sin embargo, Yazdegerd II estaba en mejor situación que los bizantinos para negociar, y si no exigió más concesiones se debió a las incursiones de los kidaritas en Partia y Corasmia. Reunió sus fuerzas en Neishabur en 443, lanzando una prolongada campaña contra los kidaritas. Finalmente, y tras algunas batallas, aplastó a los kidaritas, expulsándoles más allá del río Oxus en 450.

Durante su campaña en el este, Yazdegerd II empezó a sospechar de los cristianos que componían su ejército, lo que hizo que fueran expulsados tanto del ejército como del gobierno. Entonces comenzó una persecución contra los cristianos y, en menor medida, también contra los judíos. Para restablecer el zoroastrismo en Armenia, aplastó un levantamiento de cristianos armenios en la batalla de Avarayr, en 451. Sin embargo, los armenios siguieron siendo mayoritariamente cristianos. En sus últimos años, se enfrentaría de nuevo con los kidaritas, hasta que murió en 457.

Hormizd III (457-459), el hijo menor de Yazdegerd II, ascendió entonces al trono. Durante su corto reinado luchó continuamente contra su hermano mayor Peroz, que tenía el apoyo de la nobleza, y contra los heftalitas en Bactriana. Finalmente fue asesinado en 459 por su hermano.

A principios del siglo V, los heftalitas (hunos blancos), junto con otros grupos nómadas, atacaron Persia. Al principio, Bahram V y Yazdegerd II infligieron decisivas derrotas a estos grupos, haciéndoles retroceder hacia el este. Los hunos volvieron a finales del siglo V y derrotaron a Peroz I (457-484) en el año 483. Tras esta victoria, los hunos invadieron y saquearon partes del este de Persia durante dos años, e incluso recaudaron fuertes impuestos durante varios años más tras estos saqueos.

Los ataques hunos trajeron inestabilidad y caos al reino. Peroz I intentó de nuevo expulsar a los heftalitas, pero en el camino hacia Herat, él y su ejército fueron emboscados por los hunos en el desierto. Peroz I fue asesinado, y su ejército destruido. Tras esta victoria, los heftalitas avanzaron hacia la ciudad de Herat, convirtiendo el imperio persa en un caos.

Un noble persa de la antigua familia de Karen: Zarmihr (o Sokhra), restauró un poco el orden. Elevó a Balash, uno de los hermanos de Peroz I al trono, a pesar de que la amenaza de los hunos persistió hasta el reinado de Cosroes I "Anusarvan".

Balash (484-488) fue un monarca suave y generoso, que hizo concesiones a los cristianos, aunque no tomó medidas contra los enemigos del Imperio, en especial contra los hunos blancos. Tras un reinado de cuatro años, Balash fue cegado y depuesto, y su sobrino Kavadh I fue elevado al trono.

Kavadh I (488-531) fue un gobernante enérgico y reformista. Dio su apoyo a la secta heterodoxa "comunista" fundada por Mazdak, hijo de Bamdad, quien propugnaba que los ricos debían compartir sus mujeres y propiedades con los pobres. La intención de Kavadh era, por supuesto, terminar con la influencia de los magnates y de la opulenta aristocracia. Estas reformas llevaron a su derrocamiento y su encarcelación en el "Castillo del olvido", en Susa, y su hermano menor, Djamasp fue elevado al trono en 496. Sin embargo, Kavadh escapó de prisión en 498 y encontró refugio junto al rey de los hunos blancos.

Djamasp (o Ŷamasp, 496-498) se instaló en el trono sasánida tras el derrocamiento de Kavadh I por miembros de la nobleza. Djamasp fue un buen rey que redujo los impuestos para favorecer a los campesinos y los pobres. También profesó cierta simpatía por la secta de los Mazdakitas, simpatías que a su hermano le habían costado el trono y la libertad. Su reinado duró poco, ya que su hermano Kavadh regresó al frente de un gran ejército cedido por el rey de los heftalitas. Los leales a Djamasp depusieron sus armas y restauraron en el trono sasánida a Kavadh I. No se vuelve a mencionar en las fuentes a Djamasp tras la restauración de su hermano, aunque se presume que fue bien tratado en la corte de Kavadh I.

La segunda edad de oro comenzó tras el inicio del segundo reinado de Kavadh I. Con el apoyo de los heftalitas, Kavadh lanzó una campaña contra los romanos. En el año 502 tomó Teodosiópolis (Erzurum), en Armenia. En 503 tomó Amida (Diyarbakır), junto al Tigris. En 505, una invasión de Armenia por parte de los hunos occidentales desde el Cáucaso dio lugar a un armisticio. Durante este armisticio, los romanos pagaron tributo a los persas por el mantenimiento de las fortificaciones en el Cáucaso. En el año 525, Kavadh acabó con las revueltas producidas en Lázica (al sudoeste de Georgia), y volvió a capturar Georgia. Su ejército, con ayuda de los árabes nestorianos lajmidas, de Hira un reino vasallo de los sasánidas, derrotó al ejército bizantino comandado por Belisario, el famoso general de Justiniano, en dos ocasiones: una en el año 530, en la batalla de Nísibis, y otra en el 531, en la batalla de Calinico. aunque no podía librarse del yugo de los heftalitas, Kavadh consiguió restablecer el orden dentro del Imperio y llevar a cabo exitosas campañas contra los bizantinos, fundar muchas ciudades, algunas de las cuales adoptaron su nombre, y comenzó a regular los impuestos.

Tras Kavadh I, su hijo Cosroes I, también llamado "Kusro I Anosharvan", (Alma inmortal), que gobernó entre 531 y 579, ascendió al trono de Persia. Es el más famoso de los reyes sasánidas. Cosroes I se hizo famoso por sus reformas en el aparato de gobierno sasánida. En ellas introdujo un sistema racional de impuestos basado en la inspección de las posesiones en tierras, labor que había empezado su padre, y también trató por todos los medios de incrementar la beneficencia y los ingresos de su Imperio. Los anteriores grandes señores feudales equipaban sus propios ejércitos, a sus seguidores y criados. Cosroes I desarrolló una nueva fuerza de "dekhans" o "caballeros", pagados y equipados por el gobierno central. Acercó al ejército y a la burocracia hacia el poder central, alejándolos de la influencia de los señores locales.

A pesar de que el emperador bizantino Justiniano I (527-565) había pagado la suma de cuatrocientas cuarenta mil piezas de oro para mantener la paz, en 540 Cosroes I rompìó la «paz eterna» firmada en 532 e invadió Siria, donde capturó y saqueó la ciudad de Antioquía. Durante su camino de regreso, recaudó dinero de diferentes ciudades bizantinas.

En 565 murió Justiniano I, siendo sucedido en el trono bizantino por Justino II (565-578), quien decidió dejar de pagar a los cabecillas árabes para impedir que siguieran efectuando incursiones en territorio bizantino en Siria. Un año antes, el gobernador sasánida de Armenia, de la familia Suren, había construido un templo consagrado al fuego en Dvin, cerca de la moderna Ereván, matando además a un influyente miembro de la familia Mamikonia, lo que provocó una revuelta que condujo a la masacre del gobernador persa y toda su guardia en 571. Justino II se aprovechó de la revuelta en Armenia para terminar con los pagos anuales a Khosrau I por la defensa de los pasos del Cáucaso. Los armenios fueron recibidos como aliados y se envió un ejército al territorio persa que asedió Nísibis en 572. Sin embargo, las discrepancias entre los generales bizantinos no solo llevó al abandono del asedio, sino que además el ejército bizantino fue asediado a su vez en la ciudad de Dara, que finalmente fue tomada por los persas.

Posteriormente el ejército persa saqueó Siria, provocando una nueva petición de paz por parte de Justino II. La rebelión armenia terminó con una amnistía general otorgada por Cosroes I, que devolvió a Armenia al control sasánida.

Sobre el 570, Ma al-Karib, hermanastro del rey de Yemen, pidió la intervención de Cosroes I en su país contra la intervención del reino cristiano de Etiopía, enviando Cosroes I una flota y un pequeño ejército bajo el mando de un comandante llamado Vahriz a las cercanías de la actual Adén que marchó contra la capital del país, Sanaa, la cual ocuparon. Saif, hijo de Mard-Karib, que había acompañado a la expedición, se convirtió en rey entre 575 y 577. Además, los sasánidas establecieron una base en el sur de Arabia para controlar el comercio marítimo con el este. Posteriormente, los reinos del sur de Arabia renunciaron al vasallaje que les ataba con los sasánidas, y hubo de enviarse una nueva expedición persa en el 598 que consiguió anexionarse el sur de Arabia como otra provincia del Imperio. Estas provincias se conservaron hasta la problemática época que siguió a la muerte de Cosroes II.

El reinado de Cosroes contempló el auge de los "dighans" (literalmente, "señores de las villas"), la pequeña nobleza terrateniente, que constituyeron el esqueleto de lo que luego se convirtió en la administración provincial sasánida y el sistema de recaudación de impuestos. Cosroes I fue un gran constructor que embelleció su capital, fundando nuevos barrios y construyendo nuevos edificios. Reconstruyó los canales y repuso las granjas destruidas en las guerras. También construyó poderosas fortificaciones en los pasos, y emplazó a ciertas tribus en pueblos cuidadosamente seleccionados de las fronteras para que hicieran de guardianes contra posibles invasiones. Fue un monarca tolerante con todas las religiones, a pesar de decretar la oficialidad del zoroastrismo para todo el estado. Tampoco pareció molestarse cuando uno de sus hijos se convirtiese al cristianismo.

Tras Cosroes I, Ormuz IV (579-590) tomó el trono. Ormuz IV fue un gobernante enérgico que mantuvo la prosperidad iniciada por sus predecesores. Durante el reinado de su sucesor, Cosroes II (590-628), la revuelta del general Bahram Chobin (proclamado como Bahram VI en oposición al monarca oficial) provocó una breve crisis en el reino, aunque Cosroes II consiguió restablecer su control sobre el Imperio. Además, y aprovechando la guerra civil que sacudía al Imperio bizantino, lanzó una invasión a gran escala. El sueño sasánida de restablecer el dominio persa sobre Armenia estuvo cerca de cumplirse cuando cayeron Damasco y Jerusalén. Egipto cayó poco después. en 626, Cosroes II sitió Constantinopla con la ayuda de fuerzas eslavas y ávaras, solo para contemplar, como otros antes y después también lo harían, las inexpugnables murallas de la capital bizantina.

Esta importante expansión vino acompañada de un período igualmente brillante del arte persa, de la música y de la arquitectura.

Aunque muy exitosa, la campaña de Cosroes II se realizó a costa de una importantísima presión fiscal. El emperador bizantino Heraclio (610-641) contraatacó con un movimiento táctico, abandonando su sitiada capital y navegando hasta el Mar Negro para atacar Persia desde la retaguardia. Mientras tanto, la mutua desconfianza entre Cosroes II y su general Shahrbaraz, agravadas por las cartas falsas que agentes bizantinos hicieron llegar hasta el general persa, y donde supuestamente Cosroes II planeaba su ejecución, hicieron que Shahbaraz permaneciera neutral durante este periodo crítico. Persia perdió el apoyo de uno de sus mayores ejércitos y de uno de sus mejores generales. Para mayor infortunio de Cosroes, Shanin, el otro gran sostén del ejército sasánida, que había conquistado el Cáucaso y Anatolia, murió de forma repentina, lo que acabó de desequilibrar la balanza en favor de los bizantinos.

Heraclio, con ayuda de los kázaros y otras tropas turcas, aprovechó la ausencia de Shanin y Shabaraz para obtener varias victorias devastadoras contra el estado sasánida, debilitado por quince años de guerras.

La campaña de Heraclio culminó en la batalla de Nínive, donde los bizantinos (ya sin la ayuda de los kázaros, que habían abandonado a Heraclio) derrotaron al ejército persa comandado por Rhahzadh. Entonces Heraclio marchó hacia Mesopotamia y el oeste de Persia, saqueando Tajt-e Soleimán y el palacio de Dastugerd, donde recibió noticias del asesinato de Cosroes II.

Tras el asesinato de Cosroes II en 628 se produjo el caos y la guerra civil. Durante un período de cuatro años (628-632) se sucedieron entre doce y catorce soberanos/as, incluyendo dos hijas de Cosroes II y el mismo general Shahbaraz. El Imperio sasánida se debilitó considerablemente. El poder central pasó a manos de los generales. Pasaron muchos años hasta la aparición de un rey fuerte, y desde entonces, el Imperio no volvió a recuperarse por completo.

En la primavera de 632, un nieto de Cosroes II, Yezdegard III, quien había vivido escondido, ascendió al trono y fue el último soberano sasánida. Aquel mismo año, los primeros escuadrones árabes efectuaron incursiones en territorio persa. Los años de guerra habían agotado tanto a los bizantinos como a los persas. Los sasánidas se encontraban aún más debilitados por el declive económico, los altos impuestos, los problemas religiosos, la rígida estratificación social, el creciente poder de los terratenientes y los sucesivos cambios de gobierno, factores todos ellos que facilitaron la invasión árabe.

En realidad, los sasánidas nunca opusieron una verdadera resistencia a la presión ejercida por los primeros ejércitos árabes. Yezdegard III era solo un muchacho a merced de sus consejeros, e incapaz de unir a un vasto país reducido a un grupo de pequeños reinos feudales, a pesar de que los bizantinos, sometidos a similar presión por parte de los árabes, ya no constituían una amenaza. El primer encuentro entre los sasánidas y los musulmanes árabes se produjo en la batalla del Puente de 634, que se saldó con una victoria persa que, sin embargo, no detuvo la conquista árabe. Estos reaparecieron poco después, comandados por el gran estratega Jalid ibn al-Walid, uno de los antiguos compañeros de Mahoma y jefe del ejército árabe.

Un ejército musulmán al mando del califa Úmar ibn al-Jattab derrotó al más numeroso ejército persa que mandaba el general Rostam Farrojzad en las llanuras de al-Qadisiyyah en 637; asedió luego Ctesifonte, que terminó cayendo tras un prolongado sitio. Yazdegard huyó entonces hacia el este, dejando tras de sí la mayor parte del enorme tesoro imperial.

Es presumible que, de no haberse encontrado el Imperio sasánida exhausto, dividido y sin un gobierno eficiente en el momento de la invasión árabe, la caballería "asawara" persa habría podido derrotarles con toda seguridad. Sin embargo, las fuerzas persas nunca llegaron a unirse a tiempo, y se movían bajo el vacío de poder imperante. El resultado de esta debacle fue la conquista islámica. Cierto número de gobernadores sasánidas intentaron combinar sus fuerzas para hacer retroceder a los invasores, pero estos esfuerzos resultaron baldíos debido a la falta de una autoridad central, y los gobernadores fueron derrotados en la batalla de Nihavand. A partir de entonces, el Imperio, con sus estructuras de mando militar inexistentes, sus tropas diezmadas, con sus recursos económicos destruidos y la casta de caballeros "asawara" desaparecida, se mostraba indefenso ante su invasor.

Al tener noticias de las derrotas en Nihawand y en Al-Qadisiyyah, Yezdegard III, con la mayor parte de la nobleza persa, huyó aún más hacia el noreste (huyendo de provincia en provincia de lo que quedaba de su antiguo imperio), a la provincia de Jorasán. Yezdegard fue asesinado por un molinero en Merv (Sogdiana), a finales del 651, mientras el resto de los nobles se asentaban en Asia Central (principalmente en Corasmia), donde contribuyeron en gran medida a la difusión de la cultura persa y su lengua en aquella región, estableciendo la primera dinastía nativa iraní: la dinastía samánida, que resucitó las tradiciones y la cultura sasánida tras la invasión del islam.

La abrupta caída del Imperio sasánida se completó en un periodo de cinco años, y la mayor parte de su territorio fue absorbido en el califato islámico de los omeyas. Sin embargo, muchas ciudades iraníes resistieron, luchando contra los invasores en multitud de ocasiones en las décadas siguientes. La población aceptó lentamente el islam. Miles de fieles zoroástricos huyeron hacia el este dando origen a la comunidad parsi en el noroeste de la India. Al igual que en el Oriente Próximo y el Magreb, los nobles y habitantes de las ciudades se convirtieron pronto mientras la religión tradicional persistía por más tiempo en el campo y las zonas rurales. En las apartadas zonas junto al Caspio y la Transoxiana, la cultura y religión sasánidas se mantuvieron hasta dos siglos después de la conquista musulmana. Los árabes respetaron la cultura persa y tradujeron muchos de sus libros profanos, cuentos y poesía, al árabe mientras los libros sagrados zoroástricos a veces fueron quemados.

Los sasánidas establecieron su imperio cubriendo aproximadamente el mismo territorio de los aqueménidas, con capital en Ctesifonte, en la provincia de Khvarvaran. Los gobernantes sasánidas adoptaron el título de Shahanshah (rey de reyes), convirtiéndose a un tiempo en señores supremos y en guardianes del fuego sagrado, símbolo de la religión nacional. Esta simbología se muestra en las monedas sasánidas, donde el monarca reinante, con su corona y los atributos de su cargo, aparece en una de las caras mientras ocupa el reverso de la moneda la llama sagrada. Las reinas sasánidas tenían el título de Banebshenan barebshen (reina de reinas).

A menor escala, el territorio era gobernado por gobernadores pertenecientes a la familia real sasánida, conocidos como Shahrdar (شهردار), bajo la supervisión directa del Shahanshah. El gobierno sasánida se caracterizaba por una considerable centralización, por sus ambiciosos planes urbanísticos, el desarrollo de la agricultura y la investigación tecnológica. A las órdenes del rey, una poderosa burocracia se encargaba de la mayor parte de los asuntos del gobierno. La cabeza de esta burocracia y vicecanciller era el "Vuzorg (Bozorg) Farmadar" (بزرگ فرمادار). Dentro de este aparato burocrático, los sacerdotes zoroastrianos eran inmensamente poderosos. La cabeza de la clase sacerdotal era el Mobadan (موبدان), quien junto con el comandante en jefe, el Iran (Eran) Spahbod (ايران سپهد) y el jefe del sindicato de comerciantes, "Ho Tokhshan Bod" (هوتوخشان بد), que era también ministro de agricultura "Vastrioshansalar" (واستریوشانسالار) y jefe de los granjeros eran los hombres más poderosos del estado sasánida, solo por debajo del emperador.

Los monarcas sasánidas actuaban frecuentemente como asesores de sus ministros, los cuales componían un consejo de estado. El historiador musulmán Al-Masudi alababa la «excelente administración de los reyes sasánidas, su ordenada política, el cuidado de sus súbditos y la prosperidad de sus dominios».

En tiempos normales, el cargo imperial era hereditario, aunque podía ser transmitido por el rey a un hijo menor. En dos momentos de su historia, el poder supremo estuvo en manos de sendas reinas. Cuando no existía un heredero directo disponible, los nobles y prelados elegían a un gobernante, aunque esta elección estaba restringida a los miembros de la familia real.

La nobleza sasánida era una mezcla de los antiguos clanes partos, las familias aristocráticas persas y las familias nobles de los territorios súbditos del Imperio. Tras la disolución de la dinastía parta surgieron muchas familias nobles, al tiempo que los que una vez fueron los siete clanes partos dominantes conservaban una gran importancia social. En al corte de Ardacher I, las viejas familias arsácidas de Suen-Pahlav y Karen-Pahlav, junto con numerosas familias persas, los Varazes y Andiganos, ostentaban puestos de gran honor. El sucesor de Ardacher, Sapor I, utilizó como símbolo el blasón de Gondophar (un círculo rodeado por un creciente), que podría indicar la relación de este monarca a través de su madre con la casa de Suran-Pahlav.

Por regla general, las familias de clase más alta (Bozorgan), ostentaban los cargos de mayor poder en la administración imperial, incluyendo a los gobernadores de las provincias fronterizas (Marzban, مرزبان). La mayor parte de estos cargos eran patrimoniales, y en muchos casos eran heredados dentro de la misma familia durante generaciones. A los Marzban de más veteranía se les permitía tener un trono de plata, mientras a los de las provincias de mayor importancia estratégica como el Cáucaso se les permitía un trono de oro. Durante las campañas militares, los Marzban podían actuar como mariscales de campo, mientras los menos numerosos Spahbods podían comandar los ejércitos.

Culturalmente, los sasánidas implementaron un sistema de estratificación social. Este sistema tenía su base en el zoroastrismo, establecido como la religión oficial del estado. El resto de las religiones fueron tratadas con bastante tolerancia (aunque con puntuales episodios de persecución). Los emperadores sasánidas buscaron de forma consciente resucitar las tradiciones persas, tratando de borrar la influencia cultural griega.

La columna vertebral del ejército persa (Spah) en la época sasánida estaba compuesta por la caballería pesada, evolucionada desde la época de los partos: los caballeros savaranos. Esta fuerza de caballería, compuesta por la élite de la nobleza, entrenada desde su juventud para el servicio militar, estaba apoyada por la caballería ligera, la infantería y los arqueros. Las tácticas sasánidas se centraban en la distracción y debilitamiento del enemigo mediante el uso de los arqueros, montados o a pie, para así permitir a los savaranos maximizar el poder de su carga.

Al contrario que sus predecesores partos, los sasánidas desarrollaron técnicas avanzadas de asedio. Este desarrollo le proporcionó ventaja en sus conflictos con Roma; una ventaja basada en la capacidad de asediar ciudades y puestos fortificados. Inversamente, también desarrollaron técnicas para defender sus propias ciudades de un ataque. El ejército sasánida era famoso por su caballería pesada, heredada del anterior ejército parto, aunque mucho más avanzada y letal. El historiador griego Amiano Marcelino describió a la caballería de Sapor II, manifestando su alto nivel de equipamiento:
La cantidad de dinero necesaria para mantener a un guerrero de la casta Asawara hacía necesario que estos dispusieran de tierras, y en efecto, los caballeros savaranos (asawara) las obtuvieron de la Corona. A cambio, fueron los más notables defensores de la corona en tiempos de guerra.

Los sasánidas, al igual que los partos, mantuvieron una constante hostilidad contra el Imperio romano. Tras la división del Imperio romano en el 395, el Imperio romano de Oriente, con capital en Constantinopla, reemplazó al Imperio romano como principal enemigo de Persia. Las hostilidades entre ambos imperios se hicieron aún más frecuentes. Los sasánidas, al igual que los romanos, estaban en continuo conflicto con los reinos vecinos y con las hordas nómadas. A pesar de que el peligro de las incursiones nómadas nunca llegó a ser completamente resuelto, los sasánidas tuvieron con estas más éxito del que tuvieron en su lucha contra los romanos, ya que su política militar estuvo más centrada en la coordinación de las campañas contra el peligro nómada.

En el oeste, el territorio sasánida lindaba con el extenso y estable Imperio romano, pero en el este sus vecinos más cercanos eran el Imperio kushán y tribus nómadas, como la de los hunos blancos. La construcción de fortificaciones como la ciudadela de Tus o la ciudad de Nishapur, convertida posteriormente en centro de estudios y comercio, ayudaron a defender las provincias orientales de los ataques.

Al sur, en Arabia central, las tribus beduinas corrían de forma ocasional las fronteras surorientales del Estado sasánida. El reino de al-Hirah, vasallo sasánida, se estableció a modo de estado tapón entre el territorio imperial y las tribus beduinas. La disolución del reino de al-Hirah por Cosroes II en 602 contribuyó en gran medida a la derrota sasánida frente a los beduinos árabes que acaeció al final de ese mismo siglo; las victorias de las tribus beduinas, convertidas al islam, les permitieron apoderarse del territorio del Imperio sasánida.

Al norte, los jázaros y otras tribus turcas asaltaban con frecuencia las provincias septentrionales del imperio. Estas tribus saquearon el territorio de los medos en 634. Poco más tarde, el ejército persa los derrotó y expulsó. Los sasánidas construyeron numerosas fortificaciones en la región del Cáucaso para detener estas acometidas.

Como sus predecesores partos, el Imperio sasánida mantuvo una relación exterior muy intensa con China, región a la que los embajadores persas viajaban con frecuencia. Los documentos chinos dan cuenta de trece embajadas sasánidas. El comercio terrestre y marítimo entre los dos imperios fue importante tanto para los sasánidas como para los chinos. Al sur de China se ha encontrado una gran cantidad de monedas sasánidas que corroboran el comercio marítimo entre las dos regiones.

En diferentes ocasiones, los reyes sasánidas enviaron a sus más dotados músicos y bailarines a la corte imperial china. Ambos imperios se beneficiaron del comercio a lo largo de la ruta de la seda y compartieron el interés por mantenerlo y protegerlo. Cooperaron en la custodia de las rutas de los mercaderes en Asia Central y construyeron puestos avanzados en las áreas fronterizas para mantener a las caravanas a salvo de las tribus nómadas y los bandidos.

Se conocen además los esfuerzos de sasánidas y chinos por forjar alianzas contra su enemigo común, los heftalitas. Dado el creciente control de Asia Central por parte de los nómadas de origen turco, también se produjo una colaboración entre China y el Imperio sasánida para rechazar el avance de estos.

Tras la invasión del Imperio por los árabes musulmanes, Peroz, hijo de Yazdegard III, escapó junto con algunos nobles persas y se refugió en la corte imperial china. Piroz y su hijo Narseh obtuvieron títulos de nobleza en la corte china. Al menos en dos ocasiones, la última probablemente en 670, fueron enviadas tropas chinas al mando de Peroz para que recobrase el trono, con resultados mediocres. Uno de estos intentos concluyó con un corto periodo de gobierno de Peroz en Sistán, del que se conserva un escaso registro numismático. Narseh alcanzó más tarde el cargo de jefe de la guardia imperial china, y sus descendientes vivieron en China como respetados príncipes.

Tras haber asegurado Irán y sus regiones vecinas bajo el reinado de Ardacher I, el segundo emperador, Sapor I (240-270), extendió su autoridad más aún al este, en el moderno Pakistán y la parte noroccidental de la India. Los kushán, antes autónomos, se vieron obligados a aceptar su autoridad. A pesar de que el Imperio kushán estaba en decadencia hacia el fin del siglo y fue sustituido por el gupta en el siglo , el cambio no afectó a la influencia sasánida, que siguió siendo notable en la parte noroccidental de la India durante este periodo de transición.

Persia y el noroeste indio entablaron un intercambio cultural y político durante este periodo, y ciertas prácticas sasánidas se extendieron por el territorio kushán. En particular, la influencia sasánida se plasmó en su concepto de realeza y en el comercio de la plata y los textiles. Este intercambio cultural no incluyó sin embargo las prácticas religiosas sasánidas o su actitud hacia los kushán. Mientras los sasánidas siempre tuvieron un concepto religioso ligado a la política proselitista estatal, y esporádicamente perseguían o obligaban a la conversión de las minorías religiosas, los kushán eran más tolerantes.

También tuvieron lugar durante este periodo intercambios culturales de menor nivel entre la India y Persia. Por ejemplo, los persas importaron el juego del ajedrez, cambiando el nombre del juego de "chaturanga" a "shatreng"; a cambio, los persas introdujeron el backgammon en la India.

Durante el reinado de Cosroes I se llevaron a Persia numerosos libros indios, que se tradujeron al persa medio, el idioma del Imperio sasánida. Algunos de estos volúmenes fueron luego incorporados a la literatura del mundo islámico. Un ejemplo notable de este tráfico literario fue la traducción del "Panchatantra" indio por uno de los ministros de Cosroes, Burzoe. La traducción de esta obra, conocida como el "Kelileh va Demmeh", llegó con posterioridad a Arabia y Europa. Los detalles del viaje legendario de Burzoe a la India y su atrevida adquisición del "Panchatantra" se describe con todo detalle en el "Libro de los Reyes" de Ferdousí.

La sociedad y la civilización propiciada por los sasánidas fue de las más florecientes de su tiempo. En su ámbito geográfico solo rivalizaba con la sociedad bizantina. La importancia de los intercambios científicos e intelectuales entre ambos imperios es un ejemplo de competición y cooperación de estas cunas de civilizaciones.

La diferencia fundamental entre la sociedad parta y la sasánida fue el énfasis que la última puso en conseguir un gobierno centralizado y carismático. En la teoría social sasánida, la sociedad ideal era aquella que podía mantener la estabilidad y la justicia, y el instrumento necesario para ello era una monarquía fuerte.

La sociedad sasánida era tremendamente compleja, con sistemas de organización separados gobernando numerosos grupos diferentes a lo largo del Imperio. Los historiadores consideran que la sociedad estaba dividida en cuatro clases: la sacerdotal ("Atorbanan", en persa: آتروبانان), los guerreros ("Arteshtaran", en persa: ارتشتاران), los escribas ("Debiran", en persa: دبيران) y los plebeyos o campesinos ("Vasteryoshan-Hootkheshan", en persa: هوتخشان-واستريوشان). Como centro del sistema de castas sasánida se encontraba el Shahansha, gobernando sobre todos los nobles. Las princesas reales, los pequeños mandatarios, los grandes terratenientes y los sacerdotes constituían un estamento privilegiado, y se les conocía como "Bozorgan" (بزرگان) o nobles. Al parecer, era un sistema social bastante rígido.

La pertenencia a una clase social se basaba en el nacimiento, si bien era posible de forma excepcional que una persona cambiara de clase al obtener ciertos méritos. La función del rey era asegurarse de que cada clase se mantuviera dentro de sus propios límites, es decir, que los fuertes no oprimieran a los débiles, y los débiles no derrocaran a los fuertes. Mantener este equilibrio social era la esencia de la justicia del rey, y de esta justicia dependía la glorificación de la figura del monarca sobre las otras clases.

A un nivel más bajo, la sociedad sasánida estaba dividida entre los Azatan u hombres libres (آزادان) y la masa de campesinado de origen no ario. Los azatan formaban una amplia aristocracia de administradores de bajo nivel que vivían principalmente en pequeñas propiedades, guardando celosamente su estatus de descendientres de los antiguos conquistadores arios. Militarmente, los azatan constituían la columna vertebral de la caballería sasánida.

Los reyes sasánidas fueron mecenas de las letras y la filosofía. Cósroes I dispuso de los trabajos de Platón y Aristóteles traducidos al Pahlevi y que se enseñaban en Gundishapur, e incluso él mismo los leyó. Durante su reinado fueron compilados gran cantidad de anales históricos, de los cuales solo se conserva el "Karnamak-i Artaxshir-i Papakan" (Los hechos de Ardacher), una mezcla de historia y romance que sirvió como base para la épica nacional iraní, el "Shahnama". Cuando Justiniano I cerró las escuelas de Atenas, siete de sus profesores huyeron a Persia y encontraron refugio en la corte de Cósroes. Con el tiempo, sintieron nostalgia de su tierra, y en los tratados de 533 entre Justiniano y el rey sasánida se estipuló que se permitiera a los sabios griegos regresar a su tierra libres de cualquier persecución.

Bajo Cósroes I, el colegio de Gundishapur, fundado en el siglo IV, se convirtió en "el mayor centro intelectual del mundo", acudiendo a él estudiantes y maestros de todas las partes del mundo. Incluso los cristianos nestorianistas fueron recibidos en Gundishapur, aportando las traducciones al sirio de los trabajos griegos sobre medicina y filosofía. También acudieron a Gundishapur los neoplatónicos, quienes plantaron la semilla del misticismo sufí, así como los eruditos de la India, Persia, Siria y Grecia, que se mezclaron para dar lugar al una floreciente escuela de medicina.

Artísticamente, el periodo sasánida fue testigo de los mayores avances de la civilización persa, gran parte de los cuales se fundieron con lo que se conoció como "cultura islámica", incluyendo la arquitectura y la literatura. En su punto álgido, el Imperio sasánida se extendía desde Siria hasta el norte de la India, pero su influencia llegó mucho más allá de sus límites políticos. Se han hallado motivos sasánidas en el arte de Asia Central y China, en el Imperio bizantino, e incluso en la Francia merovingia. Sin embargo, el verdadero heredero del arte sasánida fue el arte islámico, que asimiló sus conceptos y formas y al mismo tiempo, les insufló nueva vida y un vigor renovado. Como expresa el historiador americano Will Durant:

Los relieves sasánidas de Taq-e Bostan y Naqsh-e Rustam fueron en su origen policromadas, al igual que gran parte de los palacios, aunque solo se conservan trazas de aquellos colores. La literatura, en cambio, deja claro que la pintura fue un arte floreciente en la época sasánida. Se sabe que el profeta Mani fundó una escuela de pintura; Ferdousí cuenta cómo los magnates persas adornaban sus mansiones con pinturas de los héroes iraníes, y el poeta al-Buhnturi describe los murales del palacio de Ctesifonte. A la muerte de los reyes sasánidas, los mejores pintores del momento eran convocados para pintar un retrato del difunto rey para la colección del tesoro real.

La pintura, escultura, alfarería y otras formas de decoración compartieron sus diseños con el arte textil sasánida. Sedas, bordados, brocados, damasquinados, tapices, tapicerías, doseles, techados y alfombras se tejían con paciencia servil por manos maestras, y eran introducidas en tintes calientes de amarillo, azul y verde. Casi cada persa, exceptuando los campesinos y los sacerdotes, aspiraban a vestir por encima de los de su clase. Los regalos se hacían frecuentemente en forma de suntuosas prendas de vestir, y las alfombras de vistosos colores eran señal de riqueza en el este desde los días de los asirios.

Las dos docenas de tejidos sasánidas que escaparon a la acción del tiempo están entre las fabricaciones humanas más valoradas. Incluso en su tiempo, el textil sasánida era admirado e imitado desde Egipto al lejano oriente, y durante las cruzadas, estos productos paganos eran apreciados para vestir las reliquias de los santos cristianos. Cuando Heraclio capturó el palacio de Khosru Parvez en Dastagird, los delicados bordados y las inmensas alfombras estaban entre sus más preciados despojos. Era famosa la "alfombra de invierno", también conocida como "la primavera de Cósroes" (قالى بهارستان) o "Khosru Anushirvan", diseñada para hacerle olvidar el invierno con sus escenas primaverales y veraniegas: flores y frutos hechos con rubíes y diamantes, además de caminos de plata y arroyos de perlas trazados sobre un fondo de oro. Harun al-Rashid se mostraba orgulloso sobre su espaciosa alfombra sasánida, intrincadamente labrada con joyas. Los persas incluso escibieron poemas de amor acerca de sus alfombras.

La influencia de los tejidos sasánidas, además de impregnar al arte textil del Imperio bizantino, se extendió tras la caída del Imperio a manos musulmanas por todos los dominios árabes, llegando hasta Al-Andalus, en el extremo oriental de estos dominios.

Los estudios sobre los restos muestran que los reyes sasánidas utilizaron alrededor de cien tipos de coronas. Las diferentes coronas sasánidas muestran la situación cultural, económica, social e histórica de cada periodo. También muestran el carácter de cada rey. Los diferentes símbolos y signos sobre las coronas, la luna, las estrellas, el águila y la mano nos ilustran acerca de las creencias religiosas de sus propietarios.

La dinastía sasánida, al igual que la aqueménida, se originó en la provincia de Persis (Fars). Los sasánidas se veían a sí mismos como sucesores de los aqueménidas tras el interludio de dominio helenístico y parto, y estaban convencidos de que su destino último era restaurar la grandeza de Persia.

Al revivir las glorias del pasado aqueménida, los sasánidas no fueron unos meros imitadores. El arte de este periodo revela una asombrosa vitalidad, anticipándose en ciertos aspectos a las aspectos claves del arte islámico. El arte sasánida combinaba elementos del arte tradicional persa con elementos e influencias helenísticas. La conquista de Persia por Alejandro el Grande originó la expansión del arte helenístico en Asia occidental. Aunque el este aceptó estas influencias artísticas de forma externa, nunca asimiló realmente su espíritu. Incluso en el periodo parto, el arte helenístico era interpretado libremente por los pueblos del cercano oriente. Así, el periodo sasánida fue una reacción contra estas formas artísticas. El arte sasánida resucitó formas y tradiciones nativas de Persia, y ya en el periodo islámico, estas formas alcanzaron las costas del Mediterráneo. Según Fergusson:

Los palacios supervivientes ilustran el esplendor en el que vivían los monarcas sasánidas. Sirvan como ejemplo los palacios de Firouzabad y Bishapur en Fars y en la capital del Imperio en Ctesifonte, en la provincia de Khvarvaran, en Irak. Además de las tradiciones locales, la arquitectura parta ejerció también influencia sobre las características de la arquitectura sasánida. Ambas se caracterizan por las bóvedas de medio cañón, introducidas durante el periodo parto. En el periodo sasánida, éstas alcanzaron enormes proporciones, especialmente en Ctesifonte. Allí, el arco el gran salón abovedado, atribuido al reinado de Sapor I (241-272) tenía un ancho de más de veintiséis metros, alcanzando una altura de casi cuarenta. Esta magnífica estructura fascinó a los arquitectos de los siguientes siglos, y está considerada como uno de los más importantes ejemplos de la arquitectura persa. Muchos de los palacios contenían un salón de audiencias interior consistente, como en el de Firuzabad, en una cámara cubierta por una cúpula. Los persas resolvieron el problema de construir una cúpula circular sobre un edificio cuadrado empleando arcos construidos en cada esquina del cuadrado, convirtiendo a este de hecho en un octógono sobre el cual era más sencillo emplazar la cúpula. La cúpula de la cámara del palacio de Firouzabad es el ejemplo más antiguo que se conserva del uso de estos arcos, lo que sugiere que esta técnica arquitectónica es, probablemente, original de Persia.

La característica exclusiva de la arquitectura sasánida es el uso distintivo del espacio. Los arquitectos sasánidas concibieron sus edificios en términos de masas y superficies. Esto dio lugar al uso en abundancia de muros de ladrillo decorados con estuco moldeado o tallado. Las decoraciones sobre muros de estuco aparecen en Bishapur, aunque se dan mejores ejemplos de la misma en Chal Tarkhan, cerca de Rayy (del sasánida tardío o principios de la época islámica), y en Ctesifonte y Kish, en Mesopotamia. Los paneles muestran figuras animales en corro, bustos humanos y motivos geométricos o florales.

En Bishapur, algunos de los suelos fueron decorados con mosaicos que muestran escenas de júbilo, como en un banquete. Aquí, la influencia romana aparece clara, y los mosaicos podrían haber sido creados por prisioneros romanos. Los edificios fueron decorados con pinturas murales, de las que se dan buenos ejemplos en las encontradas en Kuh-i-Khwaja, en Sistan.

La industria persa bajo el gobierno sasánida se desarrolló desde el ámbito doméstico hasta el urbano. Se crearon numerosos gremios. Las vestiduras de seda fueron introducidas desde China, y las sedas sasánidas llegaron a todas partes, sirviendo como modelo para las artes textiles en Bizancio, China, Corea y Japón. La influencia de los productos textiles y la platería sasánida llegó a lugares tan lejanos como Hispania. Los mercaderes chinos llegaban a Irán para vender seda en bruto y comprar alfombras, joyas, maquillajes... Armenios, sirios y judíos conectaban Persia con Bizancio y Roma en un lento intercambio. Las buenas carreteras y puentes, bien vigilados, permitían el establecimiento de postas y caravanas de mercancías que unían Ctesifonte con todas las provincias. Se construyeron puertos en el Golfo Pérsico para facilitar el comercio con la India. Los mercantes sasánidas llegaron lejos y a muchas partes, desplazando a los romanos de las lucrativas rutas comerciales oceánicas con la India. Recientes descubrimientos arqueológicos muestran un hecho interesante: los sasánidas usaban etiquetas especiales sobre sus mercancías como forma de promocionar sus marcas y distinguir entre diferentes calidades.

Cósroes I extendió aún más la ya vasta red comercial. El Estado sasánida pretendió tomar el control monopolístico del comercio, con las mercancías lujosas asumiendo un papel primordial en el mismo, y una gran actividad en construcción de puertos, puestos de caravanas, puentes, y donde el objetivo era unir el comercio con la urbanización. Los persas dominaron el comercio internacional, tanto con el océano Índico como en Asia Central y el sur de Rusia en tiempos de Cósroes, a pesar de que la competencia con los bizantinos en aquel tiempo era intensa. Los asentamientos sasánidas en Omán y Yemen dan fe de la importancia del comercio con la India, aunque el comercio de la seda con China estuvo principalmente en manos de los vasallos de los sasánidas y de los pueblos iranios, como los sogdianos.

Las principales productos exportados por los sasánidas fueron los tejidos de seda, lana y dorados, las alfombras y tapices, las pieles y cueros y las perlas del golfo Pérsico. También hubo tráfico de mercancías procedentes de China (papel, seda) y la India (especias) sobre las que las aduanas sasánidas imponían aranceles y que eran reexportadas desde el Imperio a Europa.

Esta etapa supuso también un incremento de la producción metalúrgica, de tal forma que Irán se ganó la reputación de ser la «armería de Asia». Gran parte de los centros de minería sasánida se encontraban en la periferia del Imperio: en Armenia, en el Cáucaso, y sobre todo, en la Transoxiana. La extraordinaria riqueza mineral de las montañas de Pamir, en las fronteras orientales del Imperio, originó la leyenda sobre los tayikos, el pueblo iranio que allí habitaba y cuya leyenda aún perdura. Se dice que cuando Dios creó el mundo, viajó sobre los montes Pamir, dejando caer su jarra de minerales que se esparcieron a lo largo de la región.

La religión del estado sasánida era el zoroastrismo, si bien el zoroastrismo sasánida tenía claras diferencias sobre las prácticas reflejadas en el Avesta, el libro sagrado del zoroastrismo. El clero zoroastrista sasánida modificó la religión de forma que satisficiera sus intereses, provocando una sustancial intranquilidad religiosa. Las políticas religiosas sasánidas contribuyeron al florecimiento de numerosos movimientos reformistas religiosos, los más importantes de los cuales fueron las religiones de Mani y Mazdak.

El extremado y pronunciado dualismo constituyeron la característica más reseñable del zoroastrismo. "Ormazd" y "Ahriman", los principios del bien y del mal, eran considerados como gemelos, que vinieron en un principio para crear la vida y la muerte, y para establecer cómo sería el mundo. No había prioridad en la existencia de uno sobre el otro, y tampoco una decidida superioridad. Ambos, siendo contemporáneos, contendían desde el principio de los tiempos y seguirían haciéndolo por toda la eternidad, no siendo ninguno de ellos capaz de desbancar al otro.
Estos dos principios eran representados como personas. "Ormazd" era el creador de vida, terrenal y espiritual, creador de los cuerpos celestiales, la tierra, el agua y los árboles. "Ormazd" era bueno, sagrado, puro, verdadero. Significaba la suprema felicidad, y estaba en posesión de todas las bendiciones: salud, riqueza, virtud, sabiduría e inmortalidad. De él procedían todos los dones de los que el hombre podía disfrutar. Al igual que recompensaba la bondad, también castigaba la maldad, si bien este era un aspecto de su esencia raramente representado.

El culto zoroastrista estaba íntimamente conectado con los templos y altares dedicados al fuego. En todas las ciudades importantes del Imperio se mantenía un templo del fuego, y en cada uno de ellos se veneraba a una llama sagrada, de la que se creía que había sido encendida desde los cielos y se mantenía perpetuamente encendida por los sacerdotes. Se decía de esta llama que era "inextinguible". Es probable que los altares del fuego también existieran de forma independiente de los templos. A lo largo de la historia de los sasánidas, el altar del fuego tuvo un lugar prominente en la numismática como la más frecuente impresión del reverso de las monedas. Se representaba este altar con la llama surgiendo del mismo, y en ocasiones con una cabeza en la llama. El pie de este altar solía ornamentarse con guirnaldas o cintas, y a cada lado, como protectores o devotos, se representaban dos figuras, en ocasiones mirando la llama, y en otras vueltos de espaldas a ésta, como guardándola de los enemigos externos.

Además del zoroastrismo, coexistían en la sociedad sasánida otras religiones minoritarias, principalmente el judaísmo, el cristianismo y el budismo, las cuales fueron en muchos periodos libres de practicar sus cultos y de predicar sus creencias.

La idea heterodoxa de un Cristo Humano y Divino pero separado en dos personas se conoce como nestorianismo.Cuando tras el Concilio de Éfeso (año 431) el nestorianismo fue considerado herejía, y por tanto fue desterrado del Imperio romano, la diáspora de los cristianos nestorianos encontró refugio en el Imperio sasánida. Gran parte de los habitantes cristianos del imperio persa (en especial en Irak) y los Lajmidas abrazaron la denominación cristiana conocida en Occidente (incluyendo aquí a Siria y al Imperio Bizantino como partes del Occidente) con el citado adjetivo de "nestorianismo".

Bajo el gobierno sasánida floreció una populosa comunidad judía, cuyos centros más prósperos eran Isfahán, Babilonia y Jorasán, y con una autoridad religiosa semiautónoma establecida en Mesopotamia. Esta comunidad judía en Persia, de hecho, continuó siendo floreciente hasta la llegada del sionismo a finales del siglo XIX. Las comunidades judías sufrieron, sin embargo, persecuciones ocasionales, aunque en términos generales, disfrutaron de una relativa libertad religiosa, y gozaban de privilegios que se le negaban a otras comunidades religiosas minoritarias. Sapor I ("Shabur Malka" en arameo) fue particularmente amistoso con los judíos. Su amistad con el rabino Samuel conllevó muchas ventajas para la comunidad judía. Incluso ofreció a los judíos del Imperio sasánida un magnífico caballo, por si llegara el Mesías, de quien se pensaba que llegaría a lomos de un burro o una mula.

Sapor II, cuya madre era judía, conservó una amistad parecida con el rabino babilonio Raba. La amistad con Raba aseguró a los judíos la relajación de las opresivas leyes dictadas contra los judíos en el Imperio persa. En esta coyuntura de tolerancia, en los territorios orientales del Imperio varios lugares de adoración budista, especialmente Bamiyán, experimentaron cierto auge a medida que el budismo se hacía más popular en la región (actuales Afganistán y Pakistán).





</doc>
<doc id="15345" url="https://es.wikipedia.org/wiki?curid=15345" title="Hipótesis de Sapir-Whorf">
Hipótesis de Sapir-Whorf

La hipótesis de Sapir-Whorf es una suposición del campo de la lingüística. Fue derivada, de manera póstuma, de los escritos de Benjamin Whorf, quien atribuyó la idea a su profesor Edward Sapir. La expresión "hipótesis Sapir-Whorf" se debe a Harry Hoijer (1954). En el contexto de averiguar hasta qué punto un determinado idioma, con sus estructuras gramaticales y su léxico, determina la visión del mundo que tiene la correspondiente comunidad lingüística, esta hipótesis se puede formular diciendo que la lengua da forma al pensamiento. Muchos expertos en el tema identifican este concepto con el llamado "relativismo lingüístico". 

Se puede distinguir entre una versión fuerte y una versión débil de la hipótesis. 


La versión fuerte es la que mantuvieron algunos de los primeros lingüistas de antes de la segunda guerra mundial, mientras que la versión débil es la que tienden a defender los lingüistas contemporáneos. 

Los primeros en expresar la idea con claridad fueron los pensadores del siglo XIX, entre ellos Wilhelm von Humboldt, quienes veían la lengua como expresión del espíritu de una nación. En los escritos del matemático y lógico Gottlob Frege o del filósofo austríaco Ludwig Wittgenstein también aparecen conceptos que apuntan en el mismo sentido. Sapir estaba, en general, más bien en contra de nada que se pareciera al determinismo lingüístico. Su discípulo Benjamin Lee Whorf llegó a ser considerado el principal defensor de la idea debido a que publicó sus observaciones sobre la forma en que, en su opinión, las diferencias lingüísticas influían en la cognición y el comportamiento humano. 

Fue otro de los discípulos de Whorf, Harry Hoijer, quien acuñó la expresión, aunque aquellos a los que se les atribuía el concepto jamás plantearon ninguna hipótesis tal y ni siquiera tienen ninguna publicación firmada conjuntamente. De ahí que la expresión "hipótesis Sapir-Whorf" se considere un nombre poco afortunado. Además, es discutible si Whorf realmente entendía la hipótesis como tal (es decir, como un punto de partida para sus investigaciones, en el curso de las cuales se decidiría la validez de esta) o más bien como axioma. La distinción entre versión débil y fuerte es también un invento posterior; Sapir y Whorf nunca plantearon una dicotomía de ese tipo.En cualquier caso, la bibliografía actual se ocupa en su mayoría de la hipótesis derivada, dejando de lado los elementos axiomáticos que pudieran subyacer.

Aunque a principios de los años 90 la relatividad lingüística se había dado por muerta, posteriormente una escuela de lingüistas especializados en el tema examinó qué efectos tiene sobre la cognición el que haya diferencias en la categorización lingüística, y en contextos experimentales han visto que la versión no determinista de la hipótesis sale muy favorecida por los resultados. 

La hipótesis está compuesta por tres ideas principales:


Whorf tomó las teorías de su maestro para desarrollarlas a lo largo de la década de 1940. En su versión fuerte, la hipótesis Sapir-Whorf puede considerarse una forma de determinismo lingüístico, aunque el interés de los psicólogos por la influencia del lenguaje en el pensamiento es anterior a la formulación de la hipótesis de Sapir-Whorf como tal. Julia Penn, en su libro "Linguistic Relativity versus Innate Ideas, The Origins of the Sapir-Whorf Hypothesis in German Thought", remonta los cimientos teóricos de esta hipótesis al trabajo del pensador pietista alemán Johann Georg Hamann (1730-1788), elaborando luego una línea evolutiva para esta corriente interpretativa del lenguaje que incluiría a Johann Gottfried Herder (1744-1803), Wilhelm von Humboldt (1767-1835) y Jan Baudouin de Courtenay (1845-1929), mientras que Franz Boas (1858-1942) y Edward Sapir (1884-1935) se apartarían en una rama diferente del árbol evolutivo de la corriente. En el esquema de Penn, Benjamin Lee Whorf (1897-1941) tomaría elementos de estos pensadores, especialmente de Sapir, para elaborar la hipótesis tratada en este artículo.

Una hipótesis muy revisada de la versión «débil» de la hipótesis whorfiana es conocida como la hipótesis Whorf-Korzybski. Julia Penn considera esta hipótesis altamente probable y la define de la siguiente forma:

Penn se apoya, para contemplar esta hipótesis como posible, en los experimentos realizados por John B. Carrol y Joseph H. Casagrande con hablantes de hopi y navajo. 

La posición de que la estructura y categorías de la propia lengua materna condiciona el pensamiento fue argumentada convincentemente por Bhartrihari (siglo VI d. C.) y fue tema de siglos de debate en la tradición lingüística de la India. Nociones relacionadas en Occidente, como el principio de que el lenguaje tiene efectos de control en el pensamiento, pueden ser identificados en el ensayo de Wilhelm von Humboldt "Über das vergleichende Sprachstudium" ("Sobre el estudio comparativo de las lenguas"), y la noción ha sido asimilada de manera importante en el pensamiento occidental. Karl Kerenyi empezó su traducción de "Dionysus" al inglés en 1976 con este pasaje:

El origen de la hipótesis de Sapir-Whorf como un análisis más riguroso de esta percepción cultural familiar puede ser remontada al trabajo de Franz Boas, el fundador de la antropología en Estados Unidos. Boas fue educado en Alemania a finales del siglo XIX durante la época en la que científicos como Ernst Mach y Ludwig Boltzmann estaban tratando de entender la fisiología de la sensación.

En EE. UU., Boas encontró lenguas amerindias de diferentes familias lingüísticas, todas distintas a las lenguas semíticas e indoeuropeas estudiadas por la gran mayoría de académicos europeos. Boas se dio cuenta de lo grandes que pueden ser las diferencias entre las categorías gramaticales y formas de vida de un lugar a otro. Como resultado, Boas llegó a la conclusión de que la cultura y las formas de vida de un pueblo estaban reflejados en el lenguaje hablado por este.

Edward Sapir fue uno de los estudiantes más notables de Boas, y profundizó su argumento notando que los lenguajes eran sistemas formal y sistemáticamente completos. Así que no se trataba de que alguna palabra en particular expresara una forma de pensar o comportarse, sino de que la naturaleza sistemática y coherente del lenguaje interactuaba en un nivel más amplio con el pensamiento y el comportamiento. Aunque sus ideas cambiaron con el paso del tiempo, pareciera que hacia el final de su vida Sapir llegó a creer que el lenguaje no era un mero reflejo de la cultura, sino que el lenguaje y el pensamiento podían de hecho tener una relación de mutua influencia e inclusive de determinación. Whorf le dio todavía más precisión a esta idea al examinar los mecanismos gramaticales particulares mediante los cuales el pensamiento influía en el lenguaje.

Sapir afirmó: 

Esta expresión, que en el fondo manifiesta un prejuicio, indica que la forma de hablar de los porqueros macedónicos no era inferior a la forma de hablar de Platón, y que Confucio no tenía una capacidad sintáctica superior a la de los cazadores de cabezas de Assam. La crítica a esta hipótesis se estructurará sobre el argumento de que la forma lingüística de todos los seres humanos es equivalente.

Existen hechos que parecen difíciles de explicar si aceptamos la hipótesis Sapir-Whorf en su versión fuerte. Así, por ejemplo, se ha podido comprobar que los bebés, chimpancés e incluso las palomas son capaces de categorizar y agrupar categorías de objetos en conceptos, a pesar de carecer de lenguaje.

Sin embargo, la cuestión parece diferente cuando consideramos la hipótesis débil. Desde hace tiempo se sabe que la memoria y la percepción psicológica se ven afectadas o influidas por la disponibilidad de las palabras y de las expresiones apropiadas, por ejemplo, sustantivos de colores. Ciertos experimentos han mostrado que las memorias visuales de las personas tienden a distorsionarse con el tiempo, de modo que los recuerdos visuales terminan pareciéndose cada vez más a las categorías lingüísticas comúnmente usadas por dichas personas.

Varios experimentos recientes parecen confirmar la plausibilidad de una versión débil de la relatividad lingüística. Este es el caso de, por ejemplo, John Lucy, que ha conducido estudios comparativos con hablantes nativos de inglés y de maya yucateco, en los que mostró que los que tenían el inglés como lengua materna tendían a seleccionar los objetos por su forma, mientras que los hablantes de yucateco solían preferir el material de que estaban hechos. Así, por ejemplo, si se les pedía que eligieran un objeto parecido a una caja de cartón, los hablantes de inglés seleccionarían cajas, aunque fueran de plástico, mientras que los de yucateco elegían objetos de cartón aunque no tuvieran forma de caja. Lucy atribuyó esta diferencia en la conceptualización de objetos a la presencia, en yucateco, de unos clasificadores que deben acompañar el sustantivo siempre que éste se presente detrás de un numeral; estos clasificadores son los que indican lingüísticamente la forma de los objetos, por lo que para los hablantes de yucateco el aspecto más importante de los sustantivos no sería la forma, sino más bien la materia.

Dan Slobin también ha llevado a cabo varios experimentos en los que estudia los efectos de la gramática a la hora de conceptualizar; en concreto, defendió que dos lenguas diferentes pueden dar lugar a dos narrativas inconmensurables de un mismo evento. Su estudio versó sobre la forma en que hablantes nativos de inglés, turco y español, divididos por rangos de edad, narraban una misma sucesión de imágenes. De acuerdo con sus conclusiones, había una correlación entre la lengua hablada y aquellos aspectos de la escena que los participantes narraban; así, por ejemplo, los hablantes nativos de español tendían a destacar más el tiempo en que la acción transcurría, los hablantes de inglés solían destacar en qué dirección espacial se orientaba lo que sucedía, mientras que los hablantes de turco destacaban qué protagonistas de la escena habían contemplado lo que ocurría. Como conclusión, Slobin ha postulado la existencia de una serie de categorías mentales que son adquiridas a través del lenguaje y que son utilizadas únicamente para la expresión lingüística; se trataría, pues, de una versión de la relatividad lingüística limitada a contextos puramente lingüísticos.

Alfred Bloom también ha trabajado en el tema de las diversas narrativas, trabajando sobre el chino mandarín. Bloom condujo un experimento donde mostró a unos hablantes nativos de inglés un texto que contenía construcciones en subjuntivo, mientras mostraba a unos hablantes nativos de chino una traducción literal del mismo a su lengua, en la que esta construcción gramatical es inexistente. El resultado fue que, cuando se preguntó a los participantes si los acontecimientos narrados en el texto habían o no sucedido, los hablantes de chino fallaron en un porcentaje mucho mayor que los de inglés; la conclusión era, pues, que resulta imposible traducir literalmente de una lengua a otra, y esto debe ser debido a que cada una de ellas conceptualiza la realidad de una manera diferente. Lera Boroditsky también ha trabajado en estudios comparativos entre el inglés y el chino mandarín, y ha mostrado que los hablantes de cada una de estas concibe el tiempo de una manera distinta: mientras que el inglés asocia el transcurso del tiempo con un movimiento horizontal, el chino lo asocia a uno vertical. Ahora bien, esta autora también ha defendido la posibilidad de que los hablantes de una lengua aprendan a conceptualizar del mismo modo que los de la otra sin necesidad de aprender la otra lengua, así que aboga por una versión débil - no determinista - de la relatividad lingüística.

Hoy en día esta hipótesis está desacreditada en su forma fuerte. Los ejemplos en los que se basaron Sapir y Whorf son irreales. Por ejemplo, ellos decían que los amerindios zuñi no tenían vocablo diferente para el «amarillo» y el «naranja» y que eso tendría que condicionar su modo de pensar. La verdad es que no tienen esos vocablos, pero diferencian perfectamente lo amarillo de lo naranja. Lo que ocurre es que en su modo de vida la diferencia es irrelevante, aunque como explica Lyons, sus hábitos de memoria sí parecen afectados por la existencia de la distinción léxica.

En relación a los experimentos con colores ha habido una larga polémica que comenzó con el universalismo sobre los términos de color que comportaban los resultados de los experimentos llevados a cabo por Berlin y Kay. Estos experimentos confirman la existencia de universales lingüísticos en cuanto a los términos para nombrar los colores básicos. Así pues, la fisiología y la percepción, de carácter universal, jugarían un papel determinante a la hora de establecer la semántica de una lengua.

Una posible prueba del error de Sapir-Whorf sería el hecho de que los traductores son capaces de traducir lo que se dice en una lengua a otra. No se podría hablar por lo tanto de que el lenguaje determinase la forma en que pensamos, sería más exacto y correcto decir que influye en el pensamiento.

Los experimentos de Bloom sobre el subjuntivo han sido cuestionados por Au, quien dirigió una serie de experimentos similares a los conducidos por Bloom; según mostró, el problema de los experimentos de este último fue el hecho de que la traducción al chino que había realizado resultaba confusa por ser demasiado literal, y una vez la traducción fue adaptada a un chino más común, las diferencias que había entre los hablantes de ambas lenguas desaparecieron. Otra respuesta crítica aparece en 1985 en la revista "Cogniton".

Las principales críticas a la hipótesis del relativismo lingüístico serían, por tanto:

Steven Pinker también ha atacado con fuerza la hipótesis de la relatividad lingüística, defendiendo la universalidad del mentalés o lenguaje del pensamiento. Según defiende, el pensamiento funcionaría de manera análoga a una máquina de Turing, y por tanto resulta absurdo considerar que este esté condicionado por una lengua particular —como tampoco podría estarlo la fisiología—, por lo que el lenguaje no podría alterar nunca la percepción.

Otra crítica que se realiza a esta teoría es la visión nacionalista, o incluso racista, que podría acarrear, ya que, al distinguir el funcionamiento de la mente humana en función de la lengua del hablante, se estaría sosteniendo que los individuos tendrían capacidades intelectuales diferentes según su idioma, en caso de hablar una única lengua, por supuesto. Xabier Zabaltza escribe: «La hoy conocida como hipótesis Sapir-Whorf […] ha servido de coartada intelectual a todos los nacionalismos lingüísticos» ("Una historia de las lenguas y los nacionalismos". Xabier Zabaltza, 2006). Ahora bien, cabría decir que tanto Sapir como Whorf admitían la unidad psíquica de la humanidad, y que la relación de determinación del lenguaje no era tanto hacia la manera de razonar como hacia la cosmovisión sostenida por los hablantes.





</doc>
<doc id="15346" url="https://es.wikipedia.org/wiki?curid=15346" title="Hypericum perforatum">
Hypericum perforatum

Hypericum perforatum, también conocida como hipérico, hipericón, corazoncillo o hierba de San Juan , es la especie más abundante de la familia de las hipericáceas (Hypericaceae).

Es una planta común en los terrenos de baja y media altura. Se encuentra prácticamente en toda Europa, hasta el este de Rusia, y se ha aclimatado en numerosas partes del mundo: China, Australia, Norte de África y América.

Hipócrates la recomendó como remedio refrescante y antiinflamatorio.

Dioscórides escribe lo siguiente (con la ortografía de las traducciones antiguas): "El Hyperico, llamado Androsemo por unos, por otros Corio, y por otros Camepytis, que quiere decir Pinillo, porque su resina huele a resina de pino, es una mata ramosa, roxeta y de un palmo de alta, que produce las hojas como la ruda, y de flor amarilla: la qual frotada entre los dedos, resuda un liquor semejante a la sangre, de do vino a llamarse Androsemo que significa sangre humana. Nace el hyperico en lugares cultivados y ásperos. Tiene facultad de mover la orina y, aplicado por baxo, provoca el menstruo. Bebido con vino, extermina las tertianas y las quartanas. Su simiente bevida por una quarentena de días, cura la sciática y las hojas con la simiente aplicadas en forma de emplastro, sanan las quemaduras del fuego"

Es una hierba originaria de Europa, que se ha naturalizado en América y Australia. Los pétalos de la flor son de color amarillo dorado, con pequeñas motas negras en sus bordes, el apelativo latino "perforatum" proviene de las pequeñas perforaciones -en realidad son bolsas de aceite esencial- que pueden verse al trasluz en cada una de las hojas de esta planta. Son el doble de largos que los sépalos. Una peculiaridad de esta hierba es que, al aplastar entre los dedos alguna de sus hojitas, deja una mancha en la piel, su savia anaranjada.

En Australia y en los Estados Unidos se la considera como una maleza o una especie invasora y se la combate por medio de controles biológicos tales como los escarabajos del género "Chrysolina", que se especializan en esta planta.




"Hypericum perforatum" es una planta medicinal con múltiples aplicaciones. Por ejemplo, su aplicación tópica sirve para acelerar la cicatrización de las heridas.

Sin embargo, las propiedades de esta hierba que más han atraído a los investigadores se vinculan con su uso tradicional para el tratamiento de la depresión leve a moderada y la ansiedad. Esta indicación ha sido validada en las últimas décadas por las agencias de salud de algunos países como Alemania, donde ha sido incluida en la farmacopea oficial, y se prescribe ampliamente con ese propósito terapéutico.

Cuando el hipérico se utiliza como medicamento fitoterapéutico, generalmente se administra en forma de extractos estandarizados, con concentraciones fijas de los principios activos a los cuales se atribuyen los efectos farmacológicos; se estima que el más importante de estos es la hipericina, aunque estudios recientes reportan una mayor actividad de la hiperforina. Esta conclusión se basa fundamentalmente en un ensayo con resultado negativo llevado a cabo por el Centro Nacional de Medicina Complementaria y Alternativa de los Estados Unidos.

Para este fin (tratamiento de la depresión), la hierba de San Juan puede conseguirse en diversas presentaciones: como hierba, como gragea o cápsula, en bolsas de té o en tinturas.

El hipérico es un potente inductor enzimático del citocromo P450 (isoenzima CYP3A4) y posiblemente también de la glucoproteína P. Puede producir interacciones con otras sustancias, tales como la digoxina o anticoagulantes orales. 

Asimismo, se han documentado casos de rechazo de trasplante de corazón en dos pacientes que combinaron el tratamiento inmunosupresor (ciclosporina) y la toma de hipérico. En ambos casos, todo parece indicar que el hipérico provocó un descenso de las concentraciones plasmáticas de ciclosporina por debajo del nivel terapéutico, lo que causó el rechazo del injerto. Un estudio formal posterior demostró que el hipérico reduce la concentración plasmática de indinavir.
Debido a la importancia de estos datos, parece prudente no asociar la toma de hipérico con la de ningún fármaco de metabolismo hepático. "Véase el apartado" Tabla de interacciones con diversas sustancias.

Hypericum perforatum puede interferir con la absorción de hierro y otros minerales. El responsable de la toxicidad de esta planta, es la hipericina, se trata de un pigmento heliantrono de color rojo encarnado y fluorescente que se encuentra en las manchas negras dispersas en la superficie de las hojas y pétalos florales del vegetal. Este compuesto se encuentra presente en la planta en todo momento y persiste cuando se seca o es henificada.

La hipericina es la responsable de la foto toxicidad. Desde la antigüedad, se han observado trastornos de la piel en animales que habían comido de esta planta. Sólo en casos graves por sobrealimentación, se observaron convulsiones, crisis hemolíticas o muerte del animal. Como consecuencia de la fotosensibilización también se observan trastornos hepáticos e ictericia, al tiempo que las partes poco pigmentadas de la piel pueden necrosarse o desprenderse, dando lugar a cicatrices de curación muy lenta. Por otra parte, los animales hembras que comen de esta planta han mostrado una menor secreción láctea. En personas que hayan tomado esta planta y que se expongan al sol posteriormente, se puede presentar una pigmentación discreta de la piel (eritemas) o prurito.

Hypericum perforatum ha demostrado ser solo ligeramente tóxico tras una única dosis oral o intraperitoneal. A nivel experimental, la DL han sido las siguientes:

La administración oral repetida del extracto de Hypericum perforatum a dosis de 300, 900 y 2700 mg/kg de peso corporal diarios en ratas y perros durante un período de 26 semanas no provocó cambios específicos de la sustancia. A dosis superiores a 900 mg/kg peso corporal diarios se desarrollaron signos inespecíficos de intoxicación: peso reducido, ligeros cambios en el hemograma, cambios en la química clínica y morfológicos los cuales, causados por la alta dosis, indicaron un daño leve, por sobrecarga, en el hígado y riñones.

Los estudios se llevaron a cabo con ratas y conejos y no hubo evidencia ninguna de cambios teratogénicos hasta dosis situadas en el rango de la toxicidad materna. Los efectos embrio-fetotóxicos, aparecieron a dosis tóxicas para la madre y se observó:
En el estudio de fertilidad con ratas, no se mostraron efectos sobre las mismas. Cabe destacar que, en las ratas, la hipericina se acumula en la leche pudiendo llegar a alcanzar concentraciones superiores a las del plasma materno, pero debido al amplio margen de seguridad que muestra la hipericina es improbable que la cantidad ingerida con la leche represente peligro alguno para el niño aunque no se dispone de información suficiente en lo relativo a la lactancia. Como precaución general, no se debe emplear ni en el primer trimestre del embarazo ni durante la lactancia.

Se han llevado a cabo estudios de mutagenicidad in vitro e in vivo concluyendo la inexistencia de riesgo mutagénico para el hombre con extracto de Hypericum.

Sobre el potencial carcinogénico no se tienen suficientes datos como para concluir la existencia o no de potencial

La fotosensibilidad es el principal riesgo de toxicidad, siendo de tipo primaria puesto que se produce por absorción digestiva de la planta, pero en raras ocasiones pueden aparecer trastornos gastrointestinales, cansancio o intranquilidad

Como se ha dicho previamente, la hipericina es el causante de la fotosensibilización (un tipo de reacción alérgica) en el ganado ovino provocando un exantema o la enfermedad conocida como St. Johnsword. Estos pigmentos de la planta, son ingeridos en ocasiones de manera abundante por los ovinos en pastoreo. Posteriormente llegan a la piel desde el torrente circulatorio donde oxidan los aminoácidos, histidina, triptófano y tirosina, modificando así la estructura y permeabilidad de las células. La gravedad va a depender de la dosis, de la duración de la ingesta así como de la intensidad de la radiación solar.

La clínica aparece en zonas no pigmentadas ni revestidas de lana, es decir, en cabeza, orejas, extremidades y mama donde aparecen inflamaciones, sobre todo en la cabeza recibiendo el nombre de “cabeza hinchada”, y en las zonas de la piel, ésta, estará hinchada, caliente y edematosa; esta patología, se continua con la exudación de un líquido seroso y desprendimiento del epitelio. Como mecanismo de defensa, los animales tratan de encontrar la sombra. En etapas posteriores, pueden necrosarse partes de la piel afectada así como las puntas de las orejas.

En ocasiones, aunque no es tan frecuente, puede aparecer:
Destacar que las intoxicaciones por Hypericum se producen, fundamentalmente, en animales ovinos durante la ingesta del pasto. Suelen ser los animales jóvenes los más afectados, debido a la competencia por el alimento en el pasto así como la falta de experiencia de estos últimos a la hora de elegir los alimentos no tóxicos.

Las intoxicaciones infantiles por Hypericum, según el Servicio de Información Toxicológica, se producen ocasionalmente, dado que estos pueden llevarse a la boca los fitofármacos que contengan el extracto de Hypericum que toman sus familiares adultos o alguien que lo necesite

La Agencia Española del Medicamento considera necesario advertir que los productos que incluyen en su composición al Hypericum perforatum, tienen la capacidad de interaccionar con distintos medicamentos. Las interacciones son producto de la capacidad inductora del Hypericum perforatum sobre ciertas isoenzimas del citocromo hepático P450. Como consecuencia puede aparecer una disminución de las concentraciones plasmáticas y una pérdida del efecto terapéutico; teniendo en cuenta este mecanismo de la interacción, al dejar de administrar Hypericum perforatum puede también provocar un aumento de los niveles sanguíneos de algunos medicamentos con la consiguiente aparición de toxicidad, siendo especialmente importante en medicamentos de estrecho margen terapéutico. La interacción con los IMAO es de especial importancia debido a que conduce a una situación peligrosa porque puede dar lugar a crisis hipertensivas. Ocurre lo mismo en el caso de una ingestión de alimentos ricos en tiramina por la ingestión de esta planta.

Un ejemplo concreto es la interacción con los inhibidores de la proteasa en los cuales se produce una disminución significativa de las concentraciones plasmáticas de los mismos por la inducción de la isoenzima 3A4 del citocromo P450. Como resultado de ello, no se alcanzan concentraciones plasmáticas terapéuticas de este tipo de fármaco pudiendo desarrollarse resistencias y falta de eficacia del tratamiento.

La administración de los extractos de esta hierba es motivo de debate. Aunque existe evidencia limitada que sugiere su eficacia y seguridad, no ha sido evaluada sistemáticamente en lo que respecta a la incidencia de efectos secundarios e interacciones con otras drogas, con los riesgos que esto conlleva. Aun así, se menciona que, en el caso de algunos tratamientos, reduce su efecto como en los tratamientos para personas con VIH.

Se la considera un agente primario de la fotosensibilización en bovinos, en los cuales la hipericina se acumula en el tejido subcutáneo y reacciona con la luz solar, y provoca cuadros de inflamación de la dermis, especialmente de las partes menos pigmentadas, las cuales pueden desprenderse del animal.

Esta especie se conoce con numerosos nombres comunesen español: amnica, cientoenrama, corazón de ciervo, corazoncillo, corión, espantadiablos, hierba del agua, hierba de la sangre, hierba de las heridas, hierba de las machacauras, hierba de San Juan, hierba militar, hipericón, hipericón oficinal, hipérico, hipérico horadado, hipérico común, perforada, perforata, pericó, pericón, pericón amarillo, pericón común, pericón silvestre, perico, pericote, periquito, San Juan, sanjuanera, sanjuanes, san juanes, sanjuanines, té borde, trescalar, tresflorina, yerba de San Juan, yerbuca de San Juan.

"Hypericum perforatum" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 785. 1753.
Hipérico: nombre genérico que deriva del griego ὑπερικόν "hyperikón". Su nombre está compuesto de ὑπ- "debajo" y ἐρείκη "Erica arborea" o "brezo blanco", y por tanto significa "brezo bajo". La planta es mencionada 143 veces por los médicos grecolatinos. Es fantasioso afirmar que procede del griego ὑπέρ "por encima" y εἰκών "imagen", queriendo decir "por encima de todo lo imaginable".

perforatum: epíteto que se debe a las glándulas de aceite situadas en sus hojas y sépalos que le dan a la planta un aspecto perforado, si se observa al trasluz.
"Hypericum perforatum" ha sido designado a lo largo de la historia con distintos nombres científicos, considerados sinónimos:



nuevo
En inglés:


</doc>
<doc id="15348" url="https://es.wikipedia.org/wiki?curid=15348" title="Transiberiano">
Transiberiano

El ferrocarril Transiberiano (, pron. "Transibírskaia maguistral, Transsib") es una red ferroviaria de carga y pasaje que conecta la Rusia europea con las provincias del Lejano Oriente ruso hasta el océano Pacífico, además de Mongolia, China y Corea del Norte. La línea original, con una longitud de 9288 km, se completó en 1904. Posteriormente se han construido otras tres rutas y varios ramales más, abarcando 10.267 km. 

Operado por los Ferrocarriles Rusos (RZhD), el Transiberiano constituye el mayor sistema único de transporte terrestre del mundo y el segundo recorrido ferroviario más largo, después del complejo Madrid - Yiwu. Forma parte esencial de la llamada "Nueva Ruta de la Seda". El viaje completo en coche de pasaje requiere poco menos de una semana.

La ruta principal fue inaugurada después de trece años de trabajo, el 21 de julio de 1904. Con una extensión de 9288 km, une Moscú con la costa rusa del océano Pacífico, más precisamente con Vladivostok (localizada en el mar del Japón, y cuyo significado en ruso es “poder sobre oriente”), atravesando la mayor parte de la que fue Asia Zarista. Esta vía, que atraviesa ocho zonas horarias y cuyo recorrido demanda cerca de 7 días de viaje, constituye el servicio ferroviario continuo más largo del mundo, con excepción de la ruta que se hace dos veces al mes regularmente, y que sirve de conexión entre Moscú y Pionyang. Hay ramales a China, a través de Mongolia y Manchuria, con servicio continuo a Corea del Norte.

Otro ramal de importancia dentro de esta extensa red ferroviaria es el Transmanchuriano, cuyo recorrido coincide con el Transiberiano hasta Társkaya, unos 1000 km al este del lago Baikal. Desde la ciudad de Társkaya, el Transmanchuriano enfila al sureste hacia China, y sigue su recorrido hasta finalizar en Pekín.

La tercera de las rutas primarias es el Transmongoliano, que coincide en su traza con el Transiberiano hasta Ulán Udé, en la ribera este del lago Baikal. Desde Ulán Udé, el Transmongoliano enfila al sur hasta Ulán Bator, tras lo cual sigue en dirección sudeste hasta Pekín.

En 1991 fue completada una cuarta ruta, cuyo recorrido se encuentra más al norte, tras más de cinco décadas de obras esporádicas. Conocida como Ferrocarril Baikal-Amur, esta extensión se separa del Transiberiano varios cientos de kilómetros al oeste del lago Baikal, y lo atraviesa por su extremo norte. Esta ruta alcanza el océano Pacífico al noreste de Jabárovsk, en Sovétskaya Gavan. Si bien brinda acceso a la notable costa norte del Baikal, este ramal se caracteriza también por atravesar zonas consideradas peligrosas.

La ruta principal, recorrida por el tren N.º 1, que se conoce con el nombre de "Rossía" ('Rusia' en ruso), pasa por las siguientes ciudades:

Entre 1956 y 2001, el tren "Rossía" seguía un recorrido vía Yaroslavl en lugar de hacerlo por Nizhny Nóvgorod. Otros trenes todavía circulan por la ruta de Yaroslavl, o la ruta más sureña de Kazán.

La mayoría de los viajeros recorren en el "Rossía" tan sólo una parte del trayecto, pues este tren realiza un servicio relativamente rápido entre ciudades importantes, tales como Ekaterimburgo, Novosibirsk o Irkutsk.

El Transmanchuriano sigue el mismo recorrido que el Transiberiano entre Moscú y Chitá, para luego atravesar las siguientes poblaciones en su camino hacia China:

El Transmongoliano sigue el mismo recorrido que el Transiberiano entre Moscú y Ulán Udé, para luego atravesar las siguientes poblaciones en su camino hacia Mongolia y China:

Su construcción empezo a finales del siglo XIX, cuando el zar Alejandro lll todavía estaba en el poder. El desarrollo de Siberia se vio dificultado por las malas comunicaciones de transporte dentro de la región, así como con el resto del país. Aparte de la Ruta siberiana, no existían buenos caminos adecuados para el transporte sobre ruedas. Durante unos cinco meses del año, los ríos eran los principales medios de transporte. Durante la mitad fría del año, la carga y los pasajeros viajaron en trineos tirados por caballos sobre los caminos en invierno, muchos de los cuales eran los mismos ríos, pero cubierto de hielo.

El primer barco de vapor en el río Ob, el "Osnova" de Nikita Miasnikov, se puso en marcha en 1844. Los inicios fueron difíciles y no fue hasta 1857 que la navegación en barco de vapor comenzó a desarrollarse en el Ob de manera seria. Los barcos de vapor comenzaron a funcionar en el Yeniséi en 1863, en el Lena y Amur, en la década de 1870.

Mientras que la relativa planitud de Siberia Occidental era, por lo menos, bastante bien servida por el gigantesco sistema del río Ob-Irtysh-Tobol-Chulym, los poderosos ríos de Siberia Oriental —como el Yeniséi, el curso superior del río Angara y el Lena— eran en su mayoría navegables solo en la dirección norte-sur. Un intento de remediar en parte la situación mediante la construcción del Canal de Ob-Yeniséi no fue particularmente exitoso. Solo un ferrocarril podría ser una solución real a los problemas de transporte de la región.

Los primeros proyectos ferroviarios en Siberia surgieron después de la finalización de la línea ferroviaria San Petersburgo-Moscú en 1851. Uno de los primeros fue el proyecto de Irkutsk-Chitá, propuesto por el empresario estadounidense Perry Collins y apoyado por el ministro de Transporte Constantine Possiet con miras a conectar Moscú hasta el río Amur y, en consecuencia, con el Océano Pacífico. El gobernador de Siberia, Nikolay Muravyov-Amursky, estaba ansioso por avanzar en la colonización del Lejano Oriente ruso, pero sus planes no pudieron materializarse, siempre y cuando los colonos tuvieron que importar cereales y otros alimentos de China y Corea. Fue por iniciativa de Muravyov que se llevaron a cabo encuestas para un ferrocarril en la región de Jabárovsk.

Antes de 1880, el gobierno central ignoró prácticamente estos proyectos, debido a la debilidad de las empresas de Siberia, una burocracia torpe y miedo al riesgo financiero. En 1880, hubo un gran número de solicitudes rechazadas y futuros de autorización para la construcción de vías férreas para conectar Siberia con el Pacífico, pero no el este de Rusia. Esto preocupó al gobierno e hizo que conectase Siberia con Rusia central una preocupación apremiante. El proceso de diseño duró diez años. Junto con la ruta finalmente construida, se propusieron proyectos alternativos: una ruta del sur, a través de Kazajistán, Barnaul, Abakán y Mongolia; y una ruta del norte, a través de Tiumén, Tobolsk, Tomsk, Yeniseysk y la moderna línea Baikal-Amur o incluso a través de Yakutsk.

La línea se divide en siete secciones, sobre la totalidad o la mayor parte de las cuales se trabajó simultáneamente, utilizando una mano de obra de 90 000 hombres. El costo total se estima en 35 millones de libras esterlinas; la primera sección (de Cheliábinsk al río Ob) fue terminado a un costo de 900 000 libras esterlinas menos de lo estimado. Los ferroviarios ofrecieron sugerencias para ahorrar fondos, por ejemplo, mediante la instalación de los transbordadores en lugar de puentes sobre los ríos hasta que el tráfico se incrementó. Los diseñadores insistieron y aseguraron la decisión de construir un ferrocarril ininterrumpido.

A diferencia de los rechazados proyectos privados que pretendían conectar las ciudades existentes y que necesitaban transporte, el Transiberiano no tenía tal prioridad. Por lo tanto, para ahorrar dinero y evitar enfrentamientos con los propietarios de las tierras, se decidió establecer el ferrocarril fuera de las ciudades existentes. Tomsk era la ciudad más grande y la más desafortunada, ya que los bancos pantanosos del río Ob cerca de él fueron considerados inapropiados para un puente. El ferrocarril fue colocado a 70 km al sur (en lugar de cruzar el Ob en Novo Nikolaevsk, más tarde llamado Novosibirsk); y simplemente un ramal sin salida lo conectaba con Tomsk, privando a la ciudad del tráfico ferroviario de tránsito prospectivo y el comercio.



Otros grandes trenes relacionados con el Transiberiano:



</doc>
<doc id="15351" url="https://es.wikipedia.org/wiki?curid=15351" title="Potencial evocado visual">
Potencial evocado visual

Los potenciales evocados visuales (PEV) resultan de los cambios producidos en la actividad bioeléctrica cerebral tras estimulación luminosa. El estímulo más frecuentemente utilizado para obtener PEV, es una imagen en damero (en tablero de ajedrez), con una serie de cuadros blancos y negros, que van alternándose (PEV-pattern). Consigue evocar potenciales grandes y reproducibles. Precisa la colaboración del paciente. 

En pacientes no colaboradores o que no consiguen ver la pantalla con el damero, se utilizan otros estímulos como destellos luminosos. Estos producen respuestas evocadas con gran variabilidad inter-individual, en morfología y latencias, por lo que únicamente sirven para determinar si llega el estímulo luminoso a la corteza cerebral, y para comparar la respuesta de ambos ojos, en busca de asimetrías.
Es la única prueba clínicamente objetiva para valorar el estado funcional del sistema visual. Registra las variaciones de potencial en la corteza occipital provocada por un estímulo sobre la retina. Por esta razón puede evaluar la función retinocortical en niños, con capacidades diferentes y pacientes afásicos. También puede distinguir entre pacientes con ceguera psicológica y los que la padecen por una causa orgánica. 

Podemos explorar los PEV-pattern por hemicampos, cuando existe sospecha de lesión quiasmática, que suele comenzar por la afectación de las fibras del hemicampo visual externo.

Los potenciales evocados visuales representan una exploración neurofisiológica muy sensible, ya que se alteran en una elevada proporción de pacientes con anomalías visuales, incluso en pacientes con afección subclínica de la vía visual, como ocurre en la esclerosis múltiple. Sin embargo, es una exploración poco específica a la hora de determinar el tipo de patología, ya que cualquier problema que se interponga entre el estímulo y el registro en corteza occipital, puede provocar anomalías en los potenciales visuales siempre que cause suficiente disfunción visual (defecto de corrección óptica, catarata densa, retinopatía, glaucoma, neuropatía óptica, infarto cerebral, etc). Deben, por tanto, evaluarse con precaución y dentro de un contexto clínico. Además, debemos tener en cuenta que lesiones postquiasmáticas con disfunción visual pueden cursar sin anomalías en los PEV.

Otra característica de enorme valor de los potenciales evocados visuales, es que aportan datos cuantificables de latencia y amplitud. Esto nos permite identificar una disfunción en la vía visual, orientando si predominan los fenómenos desmielinizantes, con retraso de los potenciales (aumento de latencia) o si predomina un defecto de activación axonal en la vía visual (reducción de amplitud). Por otro lado, nos permite realizar un seguimiento evolutivo, pudiendo evaluar la posible eficacia de un tratamiento, o la progresión de una enfermedad. 

Cuando los potenciales evocados visuales muestran anomalías en un solo ojo, podemos deducir que existe patología prequiasmática en ese lado. Si las anomalías son bilaterales, no podemos definir la localización de la lesión, ya que las fibras correspondientes a la retina nasal decusan al lado contralateral en el quiasma.

Los potenciales evocados visuales se realizan situando al paciente frente a una pantalla en la que aparece un tablero de ajedrez con cuadrados blancos y negros con un punto guía en el centro del tablero. Una vez haya comenzado la estimulación dichos cuadrados alternarán rítmicamente según una frecuencia establecida, quedando fijo el punto guía en el centro de la pantalla. 

El paciente será preparado colocándole una serie de electrodos o sensores en la parte posterior de la cabeza, en la región occipital. Dichos sensores se ubican en la línea media occipital, inion, occipital izquierdo y occipital derecho tomando como referencia otro sensor situado en la zona anterior de la cabeza y común a todos los demás. Estos sensores serán los encargados de escuchar las variaciones bioeléctricas que se produzcan por cada estímulo, transmitiéndolos a un aparato que promediará y procesará las señales recogidas.

Una vez preparado el paciente y situado frente a la pantalla se le pedirá que mire fijamente al punto guía, procurando no perderlo de vista ni distraerse con el movimiento alterno de los cuadrados. El paciente deberá permanecer atento y concentrado evitando quedarse dormido.

Una vez comience la prueba los cuadrados de la pantalla comenzarán a cambiar de color de forma alterna provocando una reacción nerviosa que es trasmitida por la retina al nervio óptico y por éste hasta la zona occipital del cerebro donde serán recogidos los cambios que se produzcan por los sensores y llevados al promediador o aparato para su procesamiento.

Generalmente se evocan dos series de cien estímulos por cada ojo quedando tapado el ojo que no es estimulado y utilizando, al menos, dos frecuencias espaciales para el tablero de ajedrez, es decir, una frecuencia baja con cuadrados grandes y en menor número y una frecuencia alta con cuadrados más pequeños y en mayor número.

Se deberá realizar la exploración sin cristales correctores si bien se pueden utilizar éstos para poner de manifiesto posibles defectos de refracción o cuando se sospeche una neuropatía del nervio óptico por esclerosis múltiple.

En el PEV FLASH se utiliza un estroboscopio o flash en lugar de la pantalla con el tablero de ajedrez. Se realiza situando el estroboscopio frente al ojo a estimular y dando las series de destellos luminosos establecidas quedando el otro ojo tapado. La colocación de los sensores o electrodos en el paciente es similar al pev pattern.

Estas pruebas son del todo indoloras e inocuas y no provocan efectos secundarios importantes en los pacientes salvo, en ocasiones, cefaleas, mareos y/o somnolencia.



</doc>
<doc id="15352" url="https://es.wikipedia.org/wiki?curid=15352" title="Electroencefalografía">
Electroencefalografía

La electroencefalografía (EEG) es una exploración neurofisiológica que se basa en el registro de la actividad bioeléctrica cerebral en condiciones basales de reposo, en vigilia o sueño, y durante diversas activaciones (habitualmente hiperpnea y estimulación luminosa intermitente) mediante un equipo de electroencefalografia (producto sanitario).

Richard Birmick Caton (1842-1926), médico de Liverpool (Reino Unido), presentó en 1875 sus hallazgos sobre los fenómenos bioeléctricos en los hemisferios cerebrales de ratones y monos, expuestos por craniectomía.
En 1912 Vladimir Vladimirovich Pravdich-Neminsky publicó el primer EEG y potenciales evocados de perros.
Hans Berger (1873-1941) comenzó sus estudios sobre electroencefalografía en humanos en 1920.

Actividad de fondo
Métodos de activación

Grafoelementos específicos del sueño

Fases del sueño
"Estadiaje de Rechtschaffen y Kales"



En términos generales:

El EEG está indicado en todo fenómeno paroxístico en que se sospeche una causa de origen cerebral —y en toda situación de disfunción cerebral—, especialmente en fase sintomática. En casos en los que existen epilepsias refractarias a tratamiento y es necesaria una planificación de cirugía de epilepsia es fundamental la monitorización vídeo-EEG. Si existen dificultades para localizar el foco o la lesión no es fácilmente accesible también se pueden realizar estudios con EEG intracraneal utilizando electrodos profundos (esto se denomina estereoelectroencefalografía).

En la ciencia ficción comienzan a aparecer obras literarias centradas en la codificación neuronal y en las inmensas posibilidades con las que jugar si llegara el ser humano a ser capaz de descifrar las comunicaciones cerebrales.

La novela "El Código Sináptico" de José Luis Peñalver, publicada en marzo de 2014, abraza esta temática: un equipo de científicos investiga los impulsos motores del cerebro humano, analizando en detalle los resultados de baterías de pruebas de electroencefalografía, con la ayuda de potentes herramientas informáticas y criptográficas. El objetivo es diseñar una prótesis robótica para un paciente que ha perdido un brazo: el robot deberá decodificar las señales eléctricas provenientes de la corteza motora humana, entenderlas y moverse tal y como la persona desea, ejecutando la acción mecánica de manera similar a como lo hubiera hecho el miembro natural.

En la misma línea, la novela "77 grados Kelvin" del mismo autor y mayor éxito, utiliza la crónica como puerta de entrada a un tiempo futuro en donde el protagonista descubre que se han decodificado las percepciones eléctricas sensoriales. Un pequeño implante cerebral es capaz de entender y manipular los impulsos eléctricos que van desde los ojos o los oídos a las áreas del cerebro correspondientes. Así, las personas pueden disfrutar de contenido informático superpuesto en la visión natural, o recibir sonido directamente de la red. A su vez, lo que perciben los ojos o los oídos se puede descifrar y volcar al chip en un formato estándar de vídeo o audio, o bien compartirlo por la red. Las aplicaciones que han invadido el mercado son revolucionarias y asombrosas en el campo de la comunicación o el entretenimiento, pero no sin riesgos.




</doc>
<doc id="15353" url="https://es.wikipedia.org/wiki?curid=15353" title="Superhéroe">
Superhéroe

Un superhéroe es un personaje de ficción cuyas características superan las del héroe clásico, generalmente con poderes sobrehumanos aunque no necesariamente, y entroncado con la ciencia ficción. Generados a finales de los años 1930 en la industria del "comic book" estadounidense, que contribuyeron a levantar,han gozado de multitud de adaptaciones a otros medios, especialmente el cine. 

La historia del género puede ser dividida en las siguientes "eras" o "edades":

El concepto superhéroe se retrotrae a La Pimpinela Escarlata, serie de novelas de capa y espada en las que Emma Orczy de Orci,​ baronesa británica de origen húngaro, crea a Sir Percy Blakeney, conocido en la sociedad británica georgiana como interesado más en sus ropas que en cualquier otra cosa. Pero él lleva una vida doble como «la Pimpinela Escarlata», salvador de aristócratas e inocentes durante el Reinado del Terror después de la Revolución francesa.

Desde finales de los años 1920, el concepto se estaba incubando en las series de aventuras de grafismo realista y las "pulp magazines". Lee Falk sería el guionista de "The Phantom" (1936), que puede considerarse un precursor estético del género, cuando no su pionero.Tradicionalmente se considera, sin embargo, que el primer superhéroe de la historia fue "Superman" (1938) de DC Comics, cuyo éxito fue enorme y generó un sinfín de imitaciones que sostuvieron la industria del "comic book" durante años. Pero es imprescindible observar que, antes que los estadounidenses The Phantom y Superman, en Japón surge "Fantasmagórico" (1930 o 1931), personaje que anticipa características obvias (apariencia espectral así como la habilidad para volar) que luego se asocian con The Phantom, Superman y Batman. Hay que recordar que Fantasmagórico es el nombre castellano del héroe japonés; su nombre original es "Ōgon Bat"; "el Murciélago Dorado".

Después de Fantasmagórico, The Phantom y Superman, nacen superhéroes como Namor en abril de 1939 (primer superhéroe de Timely, predecesora de Marvel Comics), Batman en mayo de 1939, la Antorcha Humana en octubre de 1939 y al año siguiente Flash o Linterna Verde. Como señala Oscar Masotta, "no es casual que el período que va desde el "crack" del 29, pasando por los años de la guerra civil española, hasta el comienzo de la segunda guerra mundial, coincida con la aparición de Superman, Batman o Capitán Marvel".

Las primeras historias de superhéroes contenían esquemas narrativos muy parecidos a los de las más recientes tiras de aventuras: historia entre la realidad y la ficción, en forma de serie continua, basada en un protagonista carismático con doble identidad, máscara o disfraz y otros complementos. Bien visto, lo único que añadieron algunos superhéroes fueron los superpoderes, pero desde el punto de vista industrial acabarían revolucionando el mercado.

Igual que las historietas japonesas coetáneas, pronto se dejarán imbuir del espíritu bélico de la segunda guerra mundial, presentando en muchas ocasiones nombres o uniformes relacionados con sus símbolos nacionales y enfrentándose a los enemigos del país. Es el caso de The Shield de MLJ Magazines y Uncle Sam de Quality Comics, que surgieron en 1940, y la "Mujer Maravilla" de William Moulton Marston y el "Capitán América" de Joe Simon y Jack Kirby, ambos de 1941. Gracias al marco histórico en el que nacieron lograron un gran éxito comercial, pero al finalizar la guerra fueron cayendo en el olvido. Muy diferente es el renovador "The Spirit" (1940) de Will Eisner.

En Italia, Vincenzo Baggioli y Carlo Cossio crean en 1938 a "Dick Fulmine", un superhéroe autóctono, aunque carecía de poderes.
Tras la segunda guerra mundial, el éxito de las historietas de superhéroes empezó a disminuir, fueron sustituidas por todo tipo de géneros como la serie negra, historietas infantiles, románticas, de monstruos, westerns, etc. Por si esto fuera poco, el psiquiatra Fredric Wertham (en su obra "La seducción del inocente") afirmaba a finales de los años 1950 que los superhéroes creaban una distorsión de la realidad. Citaba, entre otros ejemplos, que el hecho de que Superman pudiera volar generaba falsas esperanzas, que Batman y Robin tenían una relación pedófila y que la Mujer Maravilla no podía estar como igual en un grupo de hombres como la Liga de la Justicia. Además afirmaba que todos estos ejemplos eran una mezcla volátil que daba como resultado conductas agresivas así como el desencadenamiento de la violencia juvenil/adulto.

Todo eso cambió en 1961 cuando, siguiendo la estela de la Liga de la Justicia de DC, la editorial Marvel Comics decidió crear su propio grupo de superhéroes y se lo encargó al editor y guionista Stan Lee, que trabajó con varios dibujantes.

El primer número de Los 4 Fantásticos, obra de Lee y del dibujante Jack Kirby, apareció en noviembre de 1961, y la humanidad de los personajes, sumada a la combinación de elementos de otros géneros mucho más comerciales de la época, catapultó a la serie en las listas de ventas. Azuzados por este éxito, Stan Lee, Jack Kirby y Steve Ditko se lanzaron a la creación de una gran cantidad de personajes: "Hulk", "Thor", "Spider-Man", "Daredevil" o "X-Men", todos ellos superhéroes con problemas de diferente índole (de salud, de aceptación social, económicos, etc.).

Uno de los méritos de Stan Lee es la humanización de los personajes, así como el hecho de convertir en héroes a personas con problemas. Spider-Man es un joven del que abusan sus compañeros de clase, en parte porque es impopular; Daredevil es ciego; Thor, cuando es humano, es cojo; Iron Man es un enfermo del corazón; los X-Men en sus orígenes eran jóvenes marginados, etc. En cierta medida, este universo de superhéroes es un reflejo de los cambios profundos que comenzaba a vivir EE. UU. con las luchas por los derechos civiles".

Las relaciones de tipo humano entre los superhéroes pasaron a ser más importantes, pudiendo haber enfrentamientos, o por lo menos retos, entre los buenos, como sucede entre la Antorcha Humana y Spider-Man. También hay que destacar que estos superhéroes procuran no matar cuando actúan y que sus motivaciones son principios de justicia abstractos, no venganzas personales.

En otras editoriales estadounidenses aparecieron Mr. A y The Question (1967). En Reino Unido había emergido Zarpa de Acero cinco años antes. Finalmente, en la España de Franco se prohibieron en 1964 estas series estadounidenses ""porque los poderes de estos personajes les acercaban más a dioses que a héroes.""

Las historietas de superhéroes no solo presentaban las angustias personales de sus protagonistas, sino que empezaron a reflejar los asuntos de candente actualidad. Es el caso de la reunión de Linterna Verde y Flecha Verde que Dennis O'Neil y Neal Adams realizaron en 1970. Jack Kirby, en cambio, opta por todo lo contrario, y crea las series de "El Cuarto Mundo".

La revista británica "2000 AD" (1977) será el caldo de cultivo de toda una hornada de nuevos autores británicos que a partir de 1982 vendrían a revitalizar el comic-book de superhéroes estadounidense con obras como "Watchmen" (1986), de Alan Moore/Dave Gibbons, junto a nativos como Frank Miller. La primera mostraba un futuro más negro y realista de la forma en que interactuarían los ciudadanos normales con respecto a las consecuencias de las acciones de los héroes que se suponía debían protegerlos. Destacaba la humanidad en ellos como imperfecciones y problemas sociales de sus alter ego, lo que permitía verlos como personas con dificultades normales. Trabajos como The Dark Knight Returns, de Frank Miller, en el caso de Batman, denotaron un ambiente más adulto para la historieta de superhéroes. También hay que destacar eventos como Crisis en Tierras Infinitas, que fueron la antesala a un proceso evolutivo dentro de la historieta de superhéroes.

Los artistas que fundaron Image Comics en 1992 crearon nuevas series como "Spawn" o "The Maxx".

Actualmente, el género se ha revitalizado, apareciendo nuevos autores (Mark Millar, Brian Bendis, Michael Straczynski) y recuperando a otros (Chris Claremont, Kurt Busiek, Alan Davis). Así, los superhéroes constituyen la mayor parte de la industria del cómic en los Estados Unidos.

Además, los superhéroes han sido objeto de innumerables adaptaciones cinematográficas y televisivas, facilitadas últimamente por la mejora de los efectos especiales debida a la tecnología digital. Podemos destacar películas clásicas como "" (1978), de Richard Donner, "Batman" (1989) y "Batman Returns" (1992), ambas de Tim Burton. El éxito de películas como Blade (1998), X-Men o Spider-Man (2002) ha motivado la aparición de una multitud de proyectos cinematográficos y televisivos protagonizados por superhéroes tan dispares como Daredevil, Catwoman, Hellboy o Hulk.

Como género puede considerarse el trasunto moderno de "varios estilos ancestralmente populares: los relatos mitológicos, los cuentos guerreros y las sagas familiares"con la diferencia de que el elemento religioso ha sido sustituido por la ciencia ficción.

Otras características típicas de los superhéroes son:

En 1940 ya existían parodias del género como Super Ratón (un personaje de cómic llamado "Super Mouse", y un personaje de dibujos animados llamado "Mighty Mouse").

Al ir estableciéndose los estereotipos de superhéroes, creadores de muchos campos tomaron elementos de este subgénero y lo combinaron con su propia obra. Por ejemplo, en 1969, la editorial Mondadori, responsable de las historietas de personajes Disney, dotó al pato Donald de otra identidad como "Paperinik" (en español Patomas o Superpato), influido por superhéroes como Batman y por otros personajes de ficción. Patomas actuaba a veces como un superhéroe y otras como un supervillano. Goofy también ha sido dotado de una identidad como superhéroe (Supergoofy o Supertribi), adquiriendo superpoderes semejantes a los de Superman o Marvelman al comer un tipo especial de cacahuetes.

En España, Antonio Ayné creó "El conejito atómico" en 1953 para la revista infantil "Yumbo" y seis años más tarde, el Pumby de José Sanchis se transformaba en el superhéroe de Villa Rabitos en su propia revista, "Super Pumby". En este caso, los poderes aparecían gracias al consumo de zumo de naranja (Sanchis es valenciano). Podríamos decir que más tarde o más temprano, muchos personajes han pagado su tributo a este subgénero del cómic, adquiriendo por un tiempo superpoderes (como en el cómic de Mortadelo y Filemón "Los superpoderes"). Es posible afirmar siguiendo la misma línea de razonamiento que tal conversión (aunque sea momentánea) es el resultado de la maduración de un personaje: el autor prueba con ese escenario como uno más.

En 1966 aparece la serie televisiva Batman, la cual era al mismo tiempo una serie de entretenimiento y una parodia (en estilo del teatro del absurdo) al género superheroico. Tras el éxito de esta serie (un éxito conocido como la batmanía) se masificaron definitivamente las parodias en distintos segmentos mediáticos.

Un ejemplo a nivel de esta sucesión de parodias superheroicas, en animación fue la serie Batfink de fines de los años 1960, y una de las más famosas con actores fue la realizada a principios de la década de 1970 por el mexicano Roberto Gómez Bolaños "Chespirito", llamada El Chapulín Colorado; héroe torpe, cobarde y jactancioso cuya mayor característica era su gran corazón y bondad. En la misma serie mexicana también destacó un personaje secundario llamado "SuperSam", interpretado por el actor Ramón Valdés, que parodiaba a un héroe basado en el ideal de vida estadounidense.

Las mismas editoriales que han desarrollado el cómic de superhéroes también se han dado cuenta de los aspectos absurdos y tópicos que se repiten y han publicado cómics que ridiculizan las convenciones del género. Por ejemplo, Marvel editó What the...?, serie que presentaba en cada número varias historietas paródicas cortas creadas por los mismos autores que creaban los cómics "serios" de superhéroes. Sergio Aragonés ha realizado trabajos de este tipo tanto para Marvel como para DC.

En 1973, el dibujante Jan creó a "Superlópez", que en esencia es una parodia de Superman, para la Editorial Bruguera, que lo incluía en su línea de historietas cómicas. Superlópez es el superhéroe español más leído y ya se han publicado más de 40 álbumes. En los 1990, Jan creó a "Superioribus", para Comics Forum, la editorial que publicaba las traducciones de Marvel en España. Las parodias de Superioribus eran historietas de una página que se incluían en las revistas de superhéroes "serios".

Cels Piñol también vio publicadas sus historietas paródicas breves de Fan letal en los cómics Forum, como complemento a las historietas "serias". Posteriormente ha publicado otras parodias de superhéroes y ciencia-ficción, como Fanhunter, en álbumes completos.

Por último, desde la década de 1990 y hasta la actualidad, en canales televisivos privados de animación como Cartoon Network se han vuelto frecuentes y muy populares las parodias superheroicas con personajes antiguos, como "Fantasma del Espacio de Costa a Costa", Radioactive Man (en "Los Simpsons") o Capitanazo (en "La Casa de los Dibujos").

En los 2000, con el alce de la popularidad del género de superhéroes, películas como Deadpool, series de anime como One Punch-Man y My Hero Academia y caricaturas como "Teen Titans Go!" se han encargado de homenajearlo u parodiarlo.

En Estados Unidos, la palabra "Super Hero" ("superhéroe", en inglés) es una marca registrada de forma conjunta por DC Comics y Marvel Comics, por lo que sólo ellas pueden utilizarla legalmente en sus productos y campañas comerciales. .

Al parecer, ambas editoriales solicitaron la concesión de la marca registrada en 1979, siéndoles concedida en 1981 al no haber ninguna reclamación al respecto. Según la propia solicitud original, la palabra llevaba utilizándose comercialmente al menos desde 1966.

Al tratarse de una marca registrada, y no un copyright, esto no impediría el calificar como "superhéroe" a un personaje de otra editorial en el interior de sus historias. Pero, en la práctica, muchas otras editoriales tanto estadounidenses como en el resto del mundo evitan el uso de la palabra, utilizando en su lugar términos como "metahumano" , "mutante" o simplemente "héroe" como es el caso de la serie de manga Boku no Hero Academia.

DC y Marvel han demandado en el pasado a otras empresas, o amenazado con hacerlo, por utilizar sin permiso la palabra "super hero" en sus productos; algunos ejemplos son el "Gunstar Super Heroes" de Sega o el cómic "Super Hero Happy Hour" de Dan Taylor.


 y para superheroína.


</doc>
<doc id="15354" url="https://es.wikipedia.org/wiki?curid=15354" title="Space opera">
Space opera

La space opera (traducido ocasionalmente por diferentes fuentes como aventura espacial, épica espacial, epopeya espacial, novela espacial, ópera espacial y opereta espacial) es un subgénero de la ciencia ficción donde se relatan historias acerca de aventuras tratadas de forma futurista, tecnológica y en ocasiones romántica y que en la mayor parte de los casos tienen lugar en el espacio. Se puede considerar la "space opera" como la continuación natural de las novelas de aventuras sobre escenarios propios de la ciencia ficción. Los personajes suelen pertenecer al arquetipo héroe-villano, y los argumentos típicos tratan sobre viajes estelares, batallas, imperios galácticos, exhibiendo vistosos logros tecnológicos.
El escritor Wilson Tucker utilizó por primera vez el término "space opera" de forma peyorativa en 1941 para referirse a lo que él percibía como vicios y clichés de la ciencia ficción de su tiempo, haciendo alusión al género de las "soap operas", programas de radio dramatizados populares en Estados Unidos en aquel momento. Estas mismas se llamaban así en relación a las marcas de jabón ("soap" en inglés) que solían patrocinarlas, y a las "horse operas", como se había empezado a denominar a los wésterns. De hecho algunos críticos y fanes han hecho notar que muchas tramas utilizadas en las "space operas" son una traslación directa de las historias del Oeste al contexto del espacio exterior, como parodiaba la famosa cubierta trasera del primer número de "Galaxy Science Fiction". Antes de que este término se popularizara, las historias publicadas en revistas de ciencia ficción a finales de los años 20 y principios de los 30 a menudo se denominaban "super-science epics" ('superciencia épica').

Como hacen notar David G. Hartwell y Kathryn Cramer en su antología de "space operas" titulada "The Space Opera Renaissance" (2006), «no hay consenso sobre lo que es la "space opera", qué autores son un mejor ejemplo de ella o incluso qué trabajos quedarían englobados en ella». Más aún, los autores resaltan que el género de las "space operas" ha tenido diferentes claves y definiciones a lo largo de su historia, que se han visto afectadas por la política literaria del momento. Lo que ahora se conoce como "space opera" es lo que se solía llamar "fantasía científica", mientras que aquello a lo que originalmente se conocía con el término ha dejado de existir.

En su forma más familiar, el género es un producto de las revistas "pulp" de los años 1920-1940. La ciencia ficción en general tomó del género "pulp" y de aventuras, el wéstern e historias en emplazamientos exóticos como Oriente o África, y la "space opera" no es una excepción. Existen numerosos paralelismos entre las naves tradicionales y las espaciales, entre los exploradores de la época colonialista y los exploradores del espacio, entre los piratas marítimos y los piratas espaciales, etc. La "space opera" clásica es una transposición de los viejos temas de los libros de vaqueros, o wésterns a la ciencia ficción, reemplazando el revólver Colt por la pistola láser, el caballo por la nave espacial, la fiebre del oro por los mineros de los asteroides, etcétera. El mayor auge del subgénero se dio durante la edad de oro de la ciencia ficción, en la década de 1940. En cierto modo, fue la "space opera" la que le dio mala fama a la ciencia ficción, debido a que la mayor parte de sus exponentes tenía una baja calidad literaria. 

Una novela muy temprana de proto ciencia ficción podría ser también considerada la primera "space opera". Se trata de "Edison's Conquest of Mars" de Garrett P. Serviss, publicada en 1898, que aunque precede al término "space opera" contiene todos los clichés que caracterizan al género: naves espaciales, viaje a otros planetas, coches voladores, batallas contra malvados alienígenas, armas militares de gran potencia destructiva, doncellas en apuros, e incluso una primera aparición del rayo desintegrador. 

El prototipo de space opera "pulp" es la novela de E. E. Smith "The Skylark of Space" (publicada por primera vez en "Amazing Stories" en 1928), en la que un científico construye una nave espacial y viaja con una compañera femenina en busca de civilizaciones alienígenas y a luchar contra un poderoso archienemigo. La serie más tardía de Smith, Lensman, y el trabajo de Edmond Hamilton y Jack Williamson en los 1930 y 1940 fueron muy populares entre los lectores y muy imitados por otros escritores. Fueron estos imitadores los que inspiraron a Tucker y otros fanes a usar la etiqueta para denominar a esta producción. 

La space opera entró en decadencia después de que la ciencia ficción abandonara la fijación en la aventura y en la tecnología para adentrarse en el estudio de las sociedades futuras, a partir de la nueva ola, en la década de 1960. Con el tiempo, el análisis de los mejores ejemplos del género ha llevado a una revaluación del término y a una resurrección del "space opera". Escritores como Poul Anderson y Gordon R. Dickson han mantenido el género de aventura espacial de grandes dimensiones vivo durante los 50, seguidos por —entre otros muchos— M. John Harrison y C. J. Cherryh en los 70 y Iain M. Banks, Lois McMaster Bujold, y Paul J. McAuley en los 80. Pasada la borrachera de la nueva ola, la literatura de ciencia ficción comenzó a regresar a los viejos temas (salvo por el ciberpunk), aunque con una mirada más madura. Con el tiempo el término ‹"space opera" ha dejado de tener esa connotación negativa para pasar a definir un tipo de novela concreto, aunque el subgénero sigue siendo percibido como un estereotipo de la ciencia ficción.

En el terreno cinematográfico, el final de la edad dorada del género "space opera" lo marcó la película "", mientras que "Star Wars" y "Alien" hizo volver con gloria y majestad al género, que desde entonces sigue teniendo éxitos.

Series de ciencia ficción de gran popularidad como "Star Trek", "Babylon 5", "Lexx" y "Stargate" son en general clasificadas como "space operas" siendo la exploración espacial, las guerras entre imperios galácticos y las aventuras a raíz del contacto entre civilizaciones el tema central.

Las historias suelen estar situadas en el espacio exterior o en un planeta ficticio. Para evitar que la historia se torne aburrida, los personajes de estas historias casi siempre son capaces de viajar distancias ilimitadas en relativamente muy poco tiempo, y sus naves no se ven afectadas por complicaciones como la necesidad de desacelerar antes de detener un vehículo que ha viajado a velocidades mucho mayores a la de la luz, o la necesidad de una fuente de energía capaz de proporcionar la energía necesaria a una nave para que pueda desarrollar tales velocidades (aparte de la energía necesaria para otras funciones características de esas naves, como un sistema de armamento). Los planetas que aparecen en historias de "space opera" a menudo son capaces de sostener el funcionamiento del organismo humano, y están poblados por seres exóticos. Es común encontrar civilizaciones alienígenas similares a algunas civilizaciones antiguas de la Tierra, como la civilización egipcia, griega o vikinga, pero adornadas con algunos rasgos futuristas. Estas civilizaciones extraterrestres casi siempre están formadas por seres antropomórficos o por humanos de aspecto extraño, que son capaces de hablar el idioma de los protagonistas. Algunos dispositivos típicos encontrados en estas historias son las pistolas de rayos, los vehículos voladores o naves para un tripulante, así como androides.



</doc>
<doc id="15355" url="https://es.wikipedia.org/wiki?curid=15355" title="Detección precoz">
Detección precoz

En medicina un programa de detección precoz es un programa epidemiológico de salud pública, de aplicación sistemática o universal, para detectar en una población determinada y asintomática, una enfermedad grave, con el objetivo de disminuir la tasa de mortalidad asociada.


La prevención secundaria se basa en los cribados poblacionales y para aplicar éstos, han de cumplirse unas condiciones predeterminadas definidas en 1975 por Frame y Carslon para justificar el "screening" de una patología que son:




</doc>
<doc id="15356" url="https://es.wikipedia.org/wiki?curid=15356" title="Ferrocarril">
Ferrocarril

El ferrocarril (del latín: "ferre", ‘hierro’, y carril) o transporte ferroviario es un sistema de transporte de personas y mercancías guiado sobre una vía férrea. 

Aunque normalmente se entiende que los carriles o rieles son de acero o hierro, que hacen el camino o vía férrea sobre la cual circulan los trenes, dentro de esta clasificación se incluyen medios de transporte que emplean otros tipos de guiado, tales como los trenes de levitación magnética.

Se trata de un transporte con ventajas comparativas en ciertos aspectos, tales como el consumo de combustible por tonelada/kilómetro transportada, la entidad del impacto ambiental que causa o la posibilidad de realizar transportes masivos, que hacen relevante su uso en el mundo moderno.

La primera noticia de un sistema de transporte sobre carriles fue una línea de tres kilómetros que seguía el camino Diolkos, que se utilizaba para transportar botes sobre plataformas a lo largo del istmo de Corinto durante el siglo VI a. C. Las plataformas eran empujadas por esclavos y se guiaban por hendiduras excavadas sobre la piedra. La línea se mantuvo funcionando durante 600 años.

Los transportes sobre carriles comenzaron a reaparecer en Europa tras la Alta Edad Media. La primera noticia sobre un transporte de este tipo en el continente europeo en este periodo aparece en una vidriera en la catedral de Friburgo de Brisgovia en torno a 1350. En 1515, el cardenal Matthäus Lang describió un funicular en el castillo de Hohensalzburg (Austria) llamado «Reisszug». La línea utilizaba carriles de madera y se accionaba mediante una cuerda de cáñamo movida por fuerza humana o animal. La línea continúa funcionando actualmente, aunque completamente sustituida por material moderno, siendo una de las líneas más antiguas que aún están en servicio.

A partir de 1550, las líneas de vía estrecha con carriles de madera empezaron a generalizarse en las minas europeas. Durante el siglo XVII las vagonetas de madera trasladaban el mineral desde el interior de las minas hasta canales donde se trasbordaba la carga al transporte fluvial o a carros. La evolución de estos sistemas llevó a la aparición del primer tranvía permanente en 1810, el «Leiper Railroad» en Pensilvania.

El primer ferrocarril propiamente tal (esto es, con carriles de hierro) tenía raíles formados por un cuerpo de madera recubierto por una chapa, y fue fabricado en 1768. Esto permitió la elaboración de aparatos de vía más complejos. En un principio solo existían lazos de final de línea para invertir las composiciones, pero pronto aparecieron los cambios de agujas. A partir de 1790 se utilizaron los primeros carriles completamente de acero en Reino Unido. En 1803, William Jessop inauguró la línea «Surrey Iron Railway» al sur de Londres, siendo el primer ferrocarril público de tracción de sangre (tirado por caballos). La invención del hierro forjado en 1820 permitió superar los problemas de los primeros carriles de hierro, que eran frágiles y cortos, aumentando su longitud a 15 metros. En 1857 comenzaron a fabricarse carriles de acero definitivamente.

El desarrollo del motor de vapor impulsó la idea de crear locomotoras de vapor que pudieran arrastrar trenes por líneas. La primera fue patentada por James Watt en 1769 y revisada en 1782, pero los motores eran demasiado pesados y generaban poca presión como para ser empleados en locomotoras. En 1804, utilizando un motor de alta precisión, Richard Trevithick presentó la primera locomotora capaz de arrastrar un tren en Merthyr Tydfil (Reino Unido). Realizada junto a Andrew Vivian, la prueba tuvo un éxito relativo, ya que la locomotora rompió los frágiles railes de chapa de hierro.

En 1811, John Blenkinsop diseñó la primera locomotora funcional que se presentó en la línea entre Middleton y Leeds. La locomotora, denominada "Salamanca", se construyó en 1812. En 1825, George Stephenson construyó la "Locomotion" para la línea entre Stockton y Darlington, al noreste de Inglaterra, que fue la primera locomotora de vapor que arrastró trenes de transporte público. En 1829 también construyó la locomotora "The Rocket". El éxito de estas locomotoras llevó a Stephenson a crear la primera compañía constructora de locomotoras de vapor que fueron utilizadas en las líneas de Europa y Estados Unidos.

En 1830 se inauguró la primera línea de ferrocarril interurbano, la línea entre Liverpool y Mánchester. La vía utilizada era del mismo tipo que otras anteriores, como la del ferrocarril entre Stockton y Darlington. Su ancho era de 1.435 mm, actualmente conocido como ancho internacional ya que es utilizado por aproximadamente el 60% de los ferrocarriles actuales. El mismo año se inauguró el primer tramo de la línea entre Baltimore y Ohio, la primera en unir líneas individuales en una red.

En los años siguientes, el éxito de las locomotoras de vapor hizo que las líneas de ferrocarril y las locomotoras se extendieran por todo el mundo.

Las primeras pruebas con trenes eléctricos las inició Rober Davidson en 1838, cuando construyó un carruaje equipado por baterías capaz de alcanzar 6,4 km/h. El primer ferrocarril con suministro eléctrico en la vía fue el tranvía que circulaba en 1883 entre Portrush y Giant's Causeway, al norte de Irlanda, que utilizaba alimentación por un tercer carril. Los cables de alimentación aérea a ferrocarriles se introdujeron en 1879, por Siemens en Berlín, en tranvías que hasta entonces eran arrastrados por mulas o caballos.

La primera línea de ferrocarril convencional electríficada fue la línea Roslag en Suecia. En la década de 1890 algunas grandes ciudades, como Londres, París y México, utilizaron esta nueva técnica para construir líneas de metro urbanas. En ciudades medias, los tranvías se hicieron algo común y fueron el único medio de transporte público durante varias décadas. Todas estas líneas utilizaron corriente continua, y la primera línea que utilizó corriente alterna fue inaugurada en Austria en 1904.

Las locomotoras de vapor necesitan un mantenimiento bastante elevado para funcionar. Tras la Segunda Guerra Mundial, los costes de personal se incrementaron de modo muy importante, lo que hizo que la tracción a vapor se encareciera sobre el resto. Al mismo tiempo, la guerra impulsó el desarrollo de los motores de combustión interna, que hicieron a las locomotoras diésel más baratas y potentes. Esto causó que varias compañías ferroviarias iniciaran programas para convertir todas sus locomotoras para líneas no electrificadas en locomotoras diésel.

Como consecuencia de la construcción a gran escala de autovías tras la guerra, el transporte por ferrocarril se hizo menos popular, y el transporte aéreo comenzó a ocupar el mercado de los viajes de muy larga distancia. Muchos tranvías fueron sustituidos por autobuses, mientras que la necesidad de trasbordos hizo poco rentable el traslado de mercancías en distancias medias. Además, sucesos como el Gran escándalo del tranvía de Estados Unidos hicieron que el transporte por ferrocarril se redujera considerablemente.

La crisis del petróleo de 1973 cambió la tendencia a la baja de los tranvías. Hizo que los que no se habían desmantelado, continúasen hasta nuestros días, al ser de nuevo más rentables. También la introducción de los contenedores contribuyó a mejorar la rentabilidad del transporte de mercancías por ferrocarril.

El primer tren comercial de alta velocidad fue inaugurado en 1939 en Italia con el ElettroTreno ETR 200, alcanzando el para entonces récord mundial de 204 km/h, cerca de Milán.

Actualmente se considera de Alta Velocidad el ferrocarril que supera los 250 km/h de media. En este sentido, en 1964, se inauguró en Japón la primera línea de Alta velocidad ferroviaria, llamado Shinkansen, "tren bala", para resolver el problema de transporte entre las pobladas ciudades del país. Con el tiempo, este sistema se extendió por otros países, como Francia, España y Alemania, lo que hizo recuperar al viajero interurbano.

A lo largo de los años 1970, se introdujo una automatización mayor, especialmente en el transporte interurbano, reduciendo los costes de operación. Algunas líneas de tranvía fueron transformadas en líneas de tren ligero, otras líneas se construyeron en ciudades que habían eliminado el tranvía décadas atrás. En los años 1990, el foco de atención se situó en mejorar la accesibilidad, convirtiendo el tren en la solución al transporte de los discapacitados.

La innovación en nuevos sistemas de ferrocarril continúan actualmente, especialmente en campos como la alta velocidad.

El material rodante está constituido por todos los equipos que circulan (ruedan) a lo largo de las vías del ferrocarril. Se dividen en dos grupos: el material de tracción, las locomotoras, y el material o equipos de arrastre, que son todos los que la locomotora arrastra o empuja acoplados a ella, sobre las vías. Al conjunto de equipos rodantes unidos entre sí que arrastra o empuja la locomotora, o están en la vía en espera de serlo, se denomina composición o formación. Al conjunto de la locomotora con la composición se conoce como tren. Según el tipo de servicio que prestan, los trenes se llaman: de carga, de pasajeros, de servicios, de obras o mixtos.

A su vez se puede realizar una división por estos tipos de vehículos entre: locomotoras, coches de viajeros, vagones, automotores y unidades de tren.

Serie de vagones enganchados a una locomotora. También los vagones puede llevar mercancías o pasajeros, lo cual significa que hay dos tipos de tren. Una variante más reciente es el tren autopropulsado, en el que los vagones, todos, o algunos, tienen motores en sus ruedas, sin llevar una locomotora propiamente dicha.


La infraestructura ferroviaria incluye todas las instalaciones y edificaciones necesarias para el funcionamiento del ferrocarril: estaciones, vías, puentes y túneles, sistema de señales y comunicaciones, infraestructura de bloqueo de trenes y guiado, agujas, etc.

También hay tramos de vías cuádruples. En estas los recorridos centrales son para el transporte de mercancías y las laterales o externos, para el transporte de pasajeros ya que los andenes exteriores permiten mejor acceso. Una variante es aquella en que las vías centrales se reservan a ferrocarriles de larga distancia (más rápidos, con menos paradas) y las laterales a viajes de cercanías.

Se llama ancho de vía o trocha a la distancia entre la cabeza (u hongo) interna plana de ambos rieles por los que circulan lo trenes.

La regulación del tráfico ferroviario se realiza mediante señales. Estas pueden ser fijas o móviles, manuales, mecánicas o eléctricas.

Una estación ferroviaria, o estación de ferrocarril, es el punto de acceso de viajeros y mercancías al ferrocarril.

Se denomina explotación ferroviaria al conjunto de técnicas, medios y modos que garantizan la circulación segura y fluida de los trenes, y que encamina cada tren hacia su destino según el horario establecido.

Se denomina electrificación al sistema de alimentación de tracción que utiliza energía eléctrica para alimentar las unidades de tracción ferroviaria.

El ferrocarril forma parte de una amplia gama de transporte terrestre en todo el mundo, que, en su conjunto, permite y realiza el transporte de personas y mercancías del lugar donde se encuentran al lugar donde quieren ir o donde son necesarias. En la actualidad se emplea una conjunción de medios (carreteros, ferroviarios, etc.) actuando coordinadamente para este fin.


Sentido de la circulación en las dobles vías de diversos países.









Se circula en parte por la derecha y en parte por la izquierda en:









</doc>
<doc id="15360" url="https://es.wikipedia.org/wiki?curid=15360" title="Cíborg">
Cíborg

Un cíborg o cyborg (del acrónimo en inglés "cyborg": de cyber" [‘cibernético’] y organism" [‘organismo’], ‘organismo cibernético’) es una criatura compuesta de elementos orgánicos y dispositivos cibernéticos generalmente con la intención de mejorar las capacidades de la parte orgánica mediante el uso de tecnología.

El término fue acuñado por Manfred E. Clynes y Nathan S. Kline en 1960 para referirse a un ser humano mejorado que podría sobrevivir en entornos extraterrestres. Llegaron a esa idea después de pensar sobre la necesidad de una relación más íntima entre los humanos y las máquinas en un momento en que empezaba a trazarse la nueva frontera representada por la exploración del espacio. Diseñador de instrumentación fisiológica y de sistemas de procesamiento de datos, Clynes era el director científico del Laboratorio de Simulación Dinámica de Rockland State Hospital, en Nueva York. El término apareció por primera vez en forma impresa, 5 meses antes, cuando "The New York Times" reportó sobre los aspectos psicofisiológicos del Espacio Simposio de vuelo donde Clynes y Kline presentaron por primera vez su papel: «un cíborg es esencialmente un sistema hombre-máquina en el cual los mecanismos de control de la porción humana son modificados externamente por medicamentos o dispositivos de regulación para que el ser pueda vivir en un entorno diferente al normal».

De acuerdo con algunas definiciones del término, la conexión física y metafísica de la humanidad con la tecnología, ya ha empezado a influir en la evolución futura del ser humano, al empezar a convertirnos en cíborgs. Por ejemplo, una persona a la que se le haya implantado un marcapasos podría considerarse un cíborg, puesto que sería incapaz de sobrevivir sin ese componente mecánico. Otras tecnologías médicas, como el implante coclear, que permite que un sordo oiga a través de un micrófono externo conectado a su nervio auditivo, también hacen que sus usuarios adquieran acceso a un sentido gracias a la tecnología, aproximando su experiencia a la de un cíborg. 

A finales del siglo XX, la imagen del cíborg como ser que no es ni humano ni máquina, ni hombre ni mujer, fue recuperado por autoras ciberfeministas, como Donna Haraway en su "El Manifiesto Cyborg".

El término se suele utilizar erróneamente en numerosos escritos al confundirlo con robot del tipo androide.

El concepto del híbrido hombre-máquina fue generalizado en la ciencia ficción antes de que ocurriera la Segunda Guerra Mundial. En "The Man That Was Used Up" (1839), Edgar Allan Poe, por ejemplo, describe a John A. B. C. Smith, un héroe de guerra con un cuerpo compuesto de múltiples prótesis. En 1910, el escritor francés Jean de la Hire presenta a Nyctalope (para algunos el primer superhéroe y también el primer cíborg literario) en la novela "L'homme qui peut vivre dans l'eau" (‘El hombre que puede vivir en el agua’). Por su parte, en "The Comet Doom" (1928), el estadounidense Edmon Hamilton describe exploradores espaciales cuyos cuerpos combinan partes orgánicas y mecánicas. Este mismo autor es conocido por el peculiar cerebro viviente y parlante, siempre flotando en un receptáculo transparente, que acompaña al superhéroe "Captain Future" (1939). Hamilton utiliza el término de forma explícita en el cuento "After a Judgmente Day" (1962) para referirse a los "las copias mecánicas de humanos" llamadas "Charlies", explicando que "cíborgs es como se les había llamado, desde el primero [el primer Charlie] a inicios de la década de 1960... organismos cibernéticos".

Debido a avances en las tecnologías de la información, inversionistas humanos han sido capaces de emplear computadoras para participar en operaciones a una mayor velocidad a través de fronteras nunca antes vistas. Las finanzas en la actualidad se están viendo afectadas en parte por los seres humanos y en parte por las máquinas, por lo que ahora se define como “finanza cíborg”.
El nuevo inversionista cíborg es distinto a las concepciones anteriores debido a que esta nueva concepción es más rápida, se ve una mayor orientación a los datos automatizados, a su vez una mayor cantidad de información.
Una característica clave de la “finanza cíborg” es el uso de ordenadores verdaderamente rápidos y poderosos para analizar y ejecutar oportunidades comerciales basadas en modelos matemáticos complejos.

En medicina, hay 2 tipos de cíborg: los de restauración y de mejora. Las tecnologías de restauración se encargan de “restaurar funciones perdidas, órganos y extremidades”. El aspecto clave de la “ciborgización” restaurativa es la reparación de procesos tanto rotos o faltantes para revertirlos y convertirlos a un nivel de función saludable o a un nivel promedio. No hay ninguna mejora a las facultades originales y los procesos perdidos.
Por el contrario, el cíborg encargado de mejora “sigue un principio, el principio de rendimiento óptimo, el cuan consiste en la maximización de salida y la minimización de las entradas”. Por lo tanto, un cíborg mejorado intenta superar los procesos normales o incluso adquirir nuevas funciones que originalmente no estaban presentes.
Aunque las prótesis en general suplementan cuerpos dañados o perdidos con la integración de un artificio mecánico, implantes biónicos en medicina permiten que modelos de órganos o partes del cuerpo sean capaces de imitar la función origina de una manera más exacta. Michael Chorost escribió un libro de memorias de su experiencia con implantes cocleares, u oídos biónicos, titulado “Rebuilt: How Becoming Part Computer Made Me More Human”. Jesse Sullivan se convirtió en una de las primeras personas en operar una extremidad totalmente robótica a través de un injerto de nervio-músculo, permitiéndole un rango complejo de movimientos más allá de las prótesis anteriormente utilizadas.
Para el 2004, un corazón artificial completamente funcional fue desarrollado. El continuo desarrollo tecnológico de la biónica y la nanotecnología empieza a plantear preguntas de la mejora, y las futuras posibilidades de cíborgs que sobrepasan la funcionalidad original del modelo biológico. La ética y el deseo por “prótesis mejoradas” han sido debatidas; sus proponentes incluyen el movimiento transhumanista, con su creencia respecto a que las tecnologías emergentes pueden asistir a la raza humana para el desarrollo más allá de sus presentes, limitaciones normativas como el envejecimiento y las enfermedades, así como incapacidades más generales, como lo son las limitaciones en velocidad, fuerza, resistencia e inteligencia. Los oponentes del concepto describen lo que creen respecto a los sesgos que impulsan el desarrollo y la aceptación de dichas tecnologías, a saber, un sesgo hacía la funcionalidad y eficiencia que podría obligar a asentir una perspectiva del ser humano que resta importancia al definir las características de las manifestaciones actuales sobre humanidad y la persona, a favor de la definición de términos de mejoras, versiones y utilidad.

Investigaciones de organizaciones militares se han enfocado en la utilización de cíborgs animales con el propósito de una supuesta ventaja táctica. DARPA ha anunciado su interés en el desarrollo de “insectos cíborg” para transmitir información a través de sensores implantados en el insecto durante la etapa de pupa. El movimiento se controla desde un sistema microelectromecánico (MEMS) y que posiblemente podría ser capaz de examinar el entorno o detectar explosivos y gas.
A su vez, DARPA está desarrollando un implante neural para controlar el movimiento de los tiburones. El sentido único de los tiburones podría ser explotado para proporcionar retroalimentación de información en relación al movimiento de un barco enemigo o podría revelar la presencia de explosivos bajo el agua.

El concepto de cíborg es normalmente asociado con ciencia ficción. Sin embargo, muchos artistas han intentado crear una consciencia pública de organismos cibernéticos; estos yendo desde pinturas hasta instalaciones. Algunos artistas que crearon un sinnúmero de trabajos son Neil Harbisson, Moon Ribas, Patricia Piccinini, Steve Mann, Orlan H.R. Giger, Lee Bul, Wafaa Bilal, Tim Hawkinson y Stelarc.
Las máquinas son cada vez más omnipresentes en el proceso artístico, con cuadernos de dibujo computarizados remplazando a la pluma y el papel, y cajas de ritmo volviéndose tan populares como los bateristas humanos. Esto es tal vez lo más notable en el arte y música generativos. Compositores como Brian Eno han desarrollado y utilizado software capaz de construir partituras completas con tan solo un poco de parámetros matemáticos básicos.
Scott Draves es un artista generativo cuyo trabajo es explícitamente descrito como una “mente cibernética”. Su proyecto “Oveja Electrónica” genera arte abstracto mediante la combinación de trabajo de un sinnúmero de computadoras y personas a través del internet.

Como una tecnología médica se convierte en una ciencia más avanzada, algunas técnicas e innovaciones han sido adoptadas por la comunidad de modificación del cuerpo. Si bien todavía no son cíborgs, en la definición de Manfred Clynes y Nathan Kline, los desarrollos tecnológicos como la seda electrónica de silicio implantable, y códigos QR se han ido acercando a la conexión entre la tecnología y el cuerpo humano. Tecnologías hipotéticas como la de las interfaces de tatuajes digitales podrían mezclar la estética de modificación del cuerpo con la interactividad y funcionalidad, brindando una manera de vida transhumanista en la realidad actual.

Más allá del imaginario de la ciencia ficción, Kevin Warwick es tal vez la figura más importante en el desarrollo de una verdadera unión entre el humano y la máquina. El 24 de agosto de 1998 Warwick llevó a cabo el experimento "Cyborg 1.0", en el cual se le implantó debajo de la piel un chip RFID (usando exclusivamente anestesia local) con el cual fue capaz de controlar puertas, luces, calentadores y computadoras sólo con la señal emitida por el chip. 

Un segundo experimento, todavía más importante, fue el "Cyborg 2.0" el 14 de marzo de 2004, en el cual un chip de mayor complejidad fue implantado en el sistema nervioso de Warwick por medio del cual se conectó a Internet en la Universidad de Columbia de Nueva York y logró mover un brazo robótico situado en la Universidad de Reading del Reino Unido. Además, se le implantó también a su esposa un microchip (con el objetivo de crear alguna clase de telepatía o empatía) permitiendo así la primera comunicación puramente electrónica entre dos sistemas nerviosos humanos

Después de los experimentos no se encontraron ninguna clase de daños o interferencias en el sistema nervioso, lo cual determinó su éxito.

En 2004, el artista británico Neil Harbisson, cocreó y se instaló un "eyeborg" en la cabeza para poder escuchar los colores que le rodean. El mismo año, el gobierno británico le prohibió renovar su pasaporte británico por el hecho de llevar un aparato electrónico en la cabeza. Harbisson empezó una campaña para defender sus derechos como cíborg y justificó que el ojo electrónico no es un aparato electrónico sino parte de su cuerpo y extensión de sus sentidos. Después de semanas con correspondencias, incluyendo cartas de su universidad y de su doctor, su ojo electrónico fue finalmente aceptado como parte de su cuerpo y su foto con el "eyeborg" incluida en el pasaporte.

La "Cyborg Foundation" es la primera organización internacional del mundo dedicada exclusivamente a ayudar a los humanos a convertirse en cíborgs. La fundación fue creada en 2010 por el cíborg Neil Harbisson y Moon Ribas como respuesta a la multitud de cartas y correos electrónicos recibidos de personas interesadas en convertirse en cíborg. Los principales objetivos de la fundación son extender los sentidos y las capacidades humanas creando y aplicando extensiones cibernéticas en el cuerpo, promover el uso de la cibernética en eventos culturales y defender los derechos de los cíborgs. En 2010, la fundación, establecida en Mataró (Barcelona), fue galardonada con el Premio Cre@tic otorgado por Tecnocampus Mataró.





</doc>
<doc id="15362" url="https://es.wikipedia.org/wiki?curid=15362" title="Pintura de los Estados Unidos">
Pintura de los Estados Unidos

La pintura de los Estados Unidos tiene una historia de dos siglos, a partir de la independencia del país. A finales del siglo XVIII y principios del XIX, los artistas pintaron sobre todo paisajes y retratos en un estilo realista. Las tendencias del arte moderno en Europa llegaron a los Estados Unidos a través de exposiciones en Nueva York como el Armory Show de 1913. Con anterioridad, los artistas estadounidenses habían basado la mayoría de su obra en la pintura occidental y las artes europeas. Después de la Segunda Guerra Mundial, Nueva York reemplazó a París como el centro del mundo artístico. Desde entonces, muchos movimientos estadounidenses han marcado el arte moderno y postmoderno.

Durante la época colonial y las primeras décadas de la nueva nación el único arte que se consideraba admisible, en un entorno puritano y laborioso, eran los retratos. La mayoría de los artistas de la época eran autodidactas. Hoy, los cientos de antiguos retratos que aún existen, realizados a partir de finales del siglo XVII, son altamente valorados por los coleccionistas. Entre los pintores destacados de la época cabe citar al neoyorquino Robert Feke o al escocés John Smybert. Smybert estudió con sir James Thornhill, y en 1728 acompañó al obispo Berkeley a América, con la intención de convertirse en profesor de bellas artes en la universidad que Berkeley pretendía fundar en las Bermudas, lo que nunca ocurrió. En 1731 pintó al "Decano George Berkeley y su familia", cuadro también titulado "El grupo de las Bermudas" (Galería de Arte de la Universidad de Yales); desde este famoso núcleo de las colonias lo que se pretendía era incorporar el joven arte estadounidense al ámbito más amplio del arte británico de la época. Por ello, en los años precedentes a la guerra de independencia de Estados Unidos hubo destacados artistas que viajaron a Europa y algunos de ellos se quedaron allí. John Singleton Copley es considerado como el pintor con el que comienza la escuela de pintura estadounidense. Realizó emblemáticos retratos de la clase comercial progresivamente próspera, pero marchó a Inglaterra en 1774 y allí su obra pareció perder fuerza. 
En Londres ya vivía, desde 1763, Benjamin West, quien llegó a ser pintor de la corte del rey Jorge III de Inglaterra y actuó como presidente de la Real Academia durante 28 años. A lo largo de cincuenta años, por su taller fueron pasando pintores estadounidense que buscaban formarse en Europa, por lo que a través de estos alumnos, su estilo influyó en la pintura de la nueva nación. Está considerado el primer pintor que se inspiró en la conquista del Nuevo Mundo, citándose su obra "Tratado de Penn con los indios" como un cuadro que ejerció gran influencia en la pintura de historia estadounidense posterior. 

Entre los artistas que visitaron el taller de West en Londres estuvieron Gilbert Stuart y John Trumbull, quienes desarrollaron su carrera después de la Declaración de Independencia en 1776. La nueva nación necesitaba una historia, y parte de esa historia se expresaría visualmente, tanto mediante retratos como en pintura de historia. Stuart pintó a los nuevos cargos del gobierno, siendo famoso por los numerosos retratos que hizo de George Washington, a lo que se dedicó igualmente Charles Willson Peale. Por su parte, Trumbull representó grandes escenas de batallas de la guerra de independencia, renovando el género de composiciones neoclásicas de temática patriótica.

Comienzan a surgir las primeras instituciones artísticas: la Academia de Bellas Artes de Pensilvania se fundó en 1805 en Filadelfia, mientras que la Academia Nacional vio la luz en 1825 en Nueva York. A pesar de ello, los artistas siguieron acudiendo a formarse a Europa, a lugares como Londres, París o Düsseldorf.

No tuvo gran éxito la pintura romántica estadounidense que seguía el academicismo europeo, como la pintura mitológica de Washington Allston o John Vanderlyn, suscitando escándalo este último por el desnudo de "Ariadna en Naxos" (1815). Más aceptación tenía la representación del paisaje, en todas sus formas, como los panoramas de Robert Fulton o los cosmoramas. El «recogimiento ante la naturaleza» se ha citado como uno de los rasgos de la cultura estadounidense, como se encuentra en Emerson, Thoreau o Walt Whitman. Por ello no es de extrañar que la primera escuela de pintura originalmente estadounidense se centrara, precisamente, en el paisaje. Se trata de la Escuela del río Hudson, que apareció en 1820. Los artistas percibieron que el Nuevo Mundo ofrecía temas propios y únicos. En este caso, la expansión hacia el Oeste de los asentamientos atrajo la atención de los pintores hacia la belleza trascendente de los paisajes de la frontera. Con Thomas Cole a la cabeza, los pintores del río Hudson combinaron su gran destreza técnica con el paisaje romántico. Sus pinturas eran exploraciones visuales de la luz y de las maravillas de la naturaleza. En la segunda mitad del siglo se produjo una auténtica explosión de cuadros representando el paisaje nacional en lienzos inmensos con un carácter espectacular. A esta escuela pertenecieron también John Frederick Kensett, Frederic Edwin Church y Albert Bierstadt. 
Comenzaron a surgir igualmente pinturas del Gran Oeste, que transmitían en particular el puro tamaño de la tierra y las culturas de los pueblos nativos que en ellas vivían. Artistas como George Caleb Bingham, que reflejó el Medio Oeste, o George Catlin especialista en retratar a los indios, se apartaron de la forma tradicional de presentar la tierra, que hasta entonces pretendía mostrar cuánto era propiedad del sujeto; ellos prefirieron mostrar de la manera más fiel posible el Oeste y su gente, incluidos los indios y su folklore. 

Ha de destacarse el éxito de la escena de género a partir de 1830, motivada sobre todo por la creciente ilustración, los periódicos y las revistas, que acostumbraron al público a escenas de la vida cotidiana. En esta línea sobresalió William Sidney Mount.

Después de la Guerra de Secesión se produjo una bifurcación en los caminos de la pintura estadounidense. Por un lado, estaba los artistas «estadounidensistas», que promovían una visión puramente estadounidense, interesándose por los problemas de la vida real y dotando de gran valor al ser humano. Cultivan una pintura realista, influida por el enfoque directo y la visión sencilla de la escuela del río Hudson. Winslow Homer representó al mundo rural estadounidense: el mar, las montañas y las gentes que vivían cerca de ellos. La vida urbana de clase media encontró su pintor en Thomas Eakins, un realista intransigente cuyos retratos desolados, sin artificios, se apartaban del sentimentalismo romántico que la gente «educada» de su tiempo había favorecido. Con él estudió Henry Ossawa Tanner, uno de los primeros pintores afroestadounidenses importantes. En esta línea también trabajaron George Inness, a quien llamaban el «Corot estadounidense», y el más subjetivo Albert Pinkham Ryder. Esta temática de escenas de la vida cotidiana, como ocurrió antes con la del paisaje estadounidense, tiene por origen una misma preocupación estadounidense por hacer del arte algo no exclusivo de una élite, sino que debe ser comprendido por todos y en este sentido es un arte democrático; pero además debe ensalzar también las peculiaridades de una nación, y por ello es un arte nacionalista. 

Diferente es el segundo camino, el que siguieron los pintores estadounidenses que siguieron los estilos europeos academicistas. A esta tendencia pertenece William Merritt Chase. Algunos son considerados estadounidenses, pero desarrollaron gran parte de su carrera en Europa, encontrándose con otros artistas europeos en París y Londres, como la impresionista Mary Cassatt o Whistler. A John Singer Sargent se le acaba considerando estadounidense solo por su nacionalidad al haber nacido en Florencia (Italia) de padres estadounidenses; famoso retratista, que también pintó paisajes, fue un expatriado que pasó gran parte de su vida en Europa.

La controversia pronto llegó a ser una forma de vida para los artistas estadounidenses. De hecho, al igual que Europa después de los futuristas italianos, gran parte de la escultura y la pintura en Estados Unidos desde 1900 ha sido una serie de rebeliones contra la tradición. «Al infierno con los valores artísticos», proclamó Robert Henri (1865-1929). Henri encabezó el grupo de los Ocho, lo que los críticos apodaron la escuela «del basurero» o «cubo de basura» "(Ashcan school)" o incluso «banda negra revolucionaria» porque los retratos realistas del grupo mostraban los aspectos más pobres de la vida en la ciudad. Eligieron un realismo académico describiendo escenas rurales y urbanas estadounidenses, por lo que su novedad radica más en los temas que en la técnica. Desarrollaron en sus obras una iconografía de conciencia social. Del "grupo de los Ocho" fue famoso George W. Bellows por sus temas de boxeo. 
Apenas unos años más tarde, los artistas «del basurero» fueron desplazados por la llegada desde Europa de movimientos de vanguardia como el cubismo y la abstracción, defendidos por el fotógrafo Alfred Stieglitz desde el 291 de la Quinta Avenida de Nueva York, auténtico baluarte de la vanguardia pictórica. Tras la Primera Guerra Mundial, muchos artistas estadounidenses desarrollaron las tendencias modernas que emanaban del Armory Show o «Exposición del Arsenal», que en 1913 expuso al público estadounidense obras europeas de vanguardia junto a otras autóctonas de realismo social. Artistas estadounidenses se relacionaron de manera estrecha con los nuevos artistas europeos. Así, Max Weber se relacionó con Matisse y Picasso, siendo el primer cubista estadounidense, mientras que Lyonel Feininger se integró en el Blaue Reiter. Entre ellos pueden citarse: John Marin, Arthur Dove , Arthur Bowen Davies y Georgia O'Keeffe. 

En este período de entreguerras la pintura estadounidense estuvo marcada sobre todo por el cubismo, entendido muchas veces como mera geometrización. Dentro del orfismo cabe citar a Patrick Henry Bruce, Morgan Russell y Stanton Macdonald-Wright; estos dos últimos, además, concibieron el sincronismo en París, con el estudio de la relación entre el color, la luz y la música. Joseph Stella prefirió el cubismo futurista integrando con Charles Demuth y Charles Sheeler lo que se llamó el grupo «precisionista», o los «inmaculados», que emplearon el cubismo para retratar el paisaje industrial, desarrollándose entre 1915 y la década de los treinta. Destacó en esta línea Edward Hopper, que reflejó con original realismo las ciudades y los pueblos estadounidenses. El dadaísmo tuvo como referencia a Marcel Duchamp, de nacionalidad francesa, pero nacionalizado estadounidense en los años cincuenta y que influyó tanto en París como en Nueva York, y al pintor y fotógrafo Man Ray, a quien ya en el Nueva York de 1915 puede considerársele precursor del dadá.

Después de la Primera Guerra Mundial, la terminación del ferrocarril de Santa Fe permitió a los colonos estadounidenses viajar hacia el oeste, llegando hasta la costa californiana. Nuevas colonias de artistas comenzaron a crecer alrededor de Santa Fe y Taos. La principal materia de los artistas fueron los pueblos y los paisajes del Suroeste, cuyas imágenes se hicieron populares en la publicidad, usándose de manera significativa el ferrocarril de Santa Fe para animar a los colonos a ir al Oeste y disfrutar de los «paisajes no mancillados». Entre los artistas más prolíficos del Suroeste estuvieron William Henry Jackson y Georgia O'Keeffe.

El Renacimiento de Harlem fue otro desarrollo significativo en el arte estadounidense. En los años veinte y treinta una nueva generación de afroestadounidenses apoyaron sociedades literarias y exposiciones artísticas para combatir los estereotipos racistas. Aunque este movimiento incluyó artistas de todo el país, se centró en Harlem, donde trabajaron. El artista gráfico Aaron Douglas y el fotógrafo James Van Der Zee se convirtieron en emblemas del movimiento. Entre otros, estuvieron en este movimiento Romare Bearden y Charles Alston.

Cuando estalló la Gran Depresión, el "New Deal" del presidente Roosevelt creó varios programas de arte públicos, con el propósito de dar trabajo a artistas y decorar edificios públicos, normalmente con un tema nacional. El primero de estos proyectos, el Public Works of Art Project (PWAP), fue creado después de que hicieran presión, con éxito, artistas desempleados de la Artists' Union. El PWAP duró menos de un año y produjo casi 15.000 obras de arte. Le siguió el Federal Art Project (FAP, Proyecto de Artes Federales) de la Works Progress Administration (WPA, la Administración para el Desarrollo del Trabajo) en 1935, que proporcionó recursos a algunos de los artistas estadounidenses más conocidos. Se produjo un arte de protesta social, estilísticamente similar al que promovieron algunos artistas en la Unión Soviética y los muralistas en México. En todas partes, los artistas crearon extraordinarios ataques pictóricos a los sistemas sociales en multitud de pinturas y murales públicos. En ninguna otra parte tantos artistas se pronunciaron de manera tan franca e idealista sobre lo que estaba mal en su país, a menudo viviendo a cargo del presupuesto oficial, como cuando cientos de artistas fueron incluidos en la nómina de Estados Unidos como parte del esfuerzo del gobierno federal por proporcionar empleos.

Varios movimientos separados y relacionados entre sí comienzan y se desarrollan durante la Gran Depresión, incluyendo la escena de género estadounidense, el regionalismo y el realismo social. Un renovado sentimiento nacionalista animó a los artistas a redescubrir y explorar lo que se denomina «Americana» (la colección de documentos y objetos que relatan la historia, cultura y arte de Estados Unidos). El regionalismo recordaba a la Nueva Objetividad alemana, ensalzando artísticamente el Medio Oeste y su vida provinciana; el pintor más conocido de esta tendencia es, Grant Wood, cuya obra de 1930 está considerada un icono de la cultura estadounidense del siglo XX.

En los años posteriores a la Segunda Guerra Mundial, un grupo de artistas neoyorquinos formaron el primer movimiento de arte abstracto genuinamente estadounidense: el expresionismo abstracto. Este término, que fue usado por vez primera en 1919 en Berlín, fue retomado en 1946 por Robert Coates en el New York Times, y asumido por los dos principales críticos de arte de la época, Harold Rosenberg y Clement Greenberg. Siempre se ha criticado como demasiado grande y paradójico, sin embargo la definición común implica el uso del arte abstracto para expresar sentimientos, emociones, lo que hay dentro del artista y no lo que queda fuera de él. Aunque los numerosos artistas abarcados por esta denominación tienen estilos ampliamente diferentes, los críticos contemporáneos encontraron varios puntos comunes entre ellos. Puede caracterizarse por dos elementos principales: en primer lugar, el gran tamaño de los lienzos usados, parcialmente inspirados por los frescos mexicanos y las obras que hicieron para la WPA en los años 30; en segundo lugar, el fuerte e insólito uso de pinceladas y aplicación de pintura experimental con un nuevo entendimiento de proceso. La mayor parte de los expresionistas abstractos abandonaron la composición formal y la representación de objetos reales. A menudo intentaron composiciones espontáneas, intuitivas e instintivas de espacio, línea, forma y color. 

La primera generación de expresionistas abstractos estuvo compuesta por artistas como Jackson Pollock, Willem de Kooning, Mark Rothko, Franz Kline, Arshile Gorky, Robert Motherwell, Clyfford Still, Barnett Newman, Adolph Gottlieb, Philip Guston, Ad Reinhardt, Hans Hofmann, James Brooks, William Baziotes, Mark Tobey, Bradley Walker Tomlin, Theodoros Stamos, Jack Tworkov y otros. Muchos expresionistas abstractos de la primera generación estuvieron influidos tanto por las obras cubistas, que conocieron a través de copias en blanco y negro en críticas de arte y también de manera directa, en la Galería 291 o el Armory Show; pero también por los surrealistas europeos, por Pablo Picasso y Henri Matisse.

Se distinguen dos tendencias. La primera fue la "Action Painting" o «pintura de acción», practicada por Pollock, De Kooning y Kline. Se caracteriza por la reacción espontánea, las pinceladas poderosas, la pintura goteada "(dripping)" y arrojada y los fuertes movimientos físicos usados en la producción de un cuadro. Jackson Pollock es un ejemplo de «pintor de acción»: su "proceso creativo" implicaba arrojar pintura, o gotearla desde un palo o verterla directamente de la lata; con ello revolucionó los métodos de pintura. Hay un dicho famoso de De Kooning respecto a Pollock: «rompió el hielo para el resto de nosotros». Irónicamente, las extensiones repetitivas y grandes de Pollock de campos lineales son también características de la segunda tendencia, la «pintura de los campos de color» o "Color-field painting"; así lo señaló el crítico de arte Michael Fried en su ensayo para el catálogo de "Three American painters: Kenneth Noland, Jules Olitski, Frank Stella" en el Museo de Arte Fogg en 1965. Dos de los principios aplicados a este movimiento son el énfasis e intensificación del color y las amplias superficies. Esta "colour-field painting" fue cultivada en los años cincuenta por Newman, Rothko, Still, Reinhardt, Gottlieb y Motherwell. En los sesenta, siguieron esta tendencia Jules Olitski, Kenneth Noland y Helen Frankenthaler, quienes buscaron hacer cuadros que eliminasen la retórica superflua con color amplio y plano. 

El expresionismo abstracto marca un punto decisivo de la historia de la pintura estadounidense. Renace en él la tradición abstracta a partir de finales de la década de los cuarenta. Con él surge el primer movimiento pictórico original de los Estados Unidos, en un momento en el que el centro del mundo artístico internacional pasa de París a Nueva York, coincidiendo con el fin de la Segunda Guerra Mundial, cuando los Estados Unidos aparecen como potencia hegemónica de Occidente, tanto desde el punto de vista económico como político. Desde este momento en adelante, muchos movimientos pictóricos surgen en Estados Unidos y desde allí se difunden a Europa y el resto del mundo; al mismo tiempo, otras tendencias nacidas fuera son seguidas y cultivadas en Estados Unidos.

Algunas de estas tendencias ulteriores derivaron directamente de una de las dos clases de expresionismo abstracto, como la pintura de borde duro o de perfil duro "(hard edge," cultivado por Ellsworth Kelly) o la pintura de "shaped canvas" (lienzo con formato distinto al tradicional, ejemplificada en Frank Stella). Frankenthaler y Morris Louis siguieron con la pintura abstracta aun en los años sesenta, cuando triunfaba el "pop art", con cuadros en los que predominaba el uso del color. Dentro del arte informal se pueden clasificar a Sam Francis, principal exponente del tachismo, y Mark Tobey, inclinado más bien hacia la caligrafía con un hondo significado filosófico y espiritual propio de Oriente.

Entre 1955 y 1970, aproximadamente, se desarrolló el arte pop (en inglés, "Pop art", abreviatura de "popular art") en Estados Unidos, donde arraiga con más fuerza que en ningún otro lugar, a pesar de las reticencias de algunos críticos como Harold Rosenberg, dada la fuerza que el expresionismo abstracto tenía en todas las instancias de la industria del arte. Los neodadaístas Jasper Johns y Robert Rauschenberg, que crearon arte a partir de materiales de desecho en los cincuenta se consideran precursores del "pop art". Johns usó fotos, papeles de periódico y objetos descartados en sus composiciones. Su técnica de pintar a paletazos recordaba a expresionistas abstractos como De Kooning. 

Al hacerse eco de la sociedad de consumo y sus estereotipos, este estilo se suele considerar el epítome del arte imperialista estadounidense. La iconografía pop era fácilmente asimilable como algo puramente estadounidense y esto era importante en aquel continente pues siempre, tanto artistas como coleccionistas, estaban de un cierto modo en lucha o competición con lo europeo. La confirmación de esto se produjo con la exposición titulada «El Pop Art y la tradición estadounidense» en el Milwaukee Art Center en 1965. Este aspecto nacionalista era lo único que lo acercaba a la generación de los expresionistas abstractos; en lo demás todo es opuesto: los artistas pop ironizaban sobre la caligrafía y el gesto característicos de los expresionistas (las obras de Lichtenstein en las que amplifica una pincelada esquematizada gráficamente), o los enormes cuadros de Rosenquist en los que amplifica espaguetis como recordando las nervaciones de los "drippings" («goteos») de Pollock, y en general el interés puesto en desechar de la obra toda traza de la intervención manual del artista. El grupo "pop art" lo forman Andy Warhol, Roy Lichtenstein, James Rosenquist, Jim Dine, Robert Indiana, Tom Wesselmann, Ronald Kitaj y Claes Oldenburg. En la periferia del pop estadounidense se encuadran Alex Katz y Larry Rivers. Warhol, Rivers y Lichtenstein reprodujeron, con cuidado satírico, objetos cotidianos e imágenes de la cultura popular estadounidense, como botellas de Coca-Cola, latas de sopa o tiras cómicas. Aunque todos estos artistas son pop, difieren entre sí. Warhol pretendía eliminar de la obra de arte cualquier traza o signo de manualidad; muchas de sus obras están hechas a partir de fotografías proyectadas sobre el lienzo. Lichtenstein toma sus motivos de las tiras de cómics y los amplía a enormes dimensiones dejando visibles los puntos que resultan del proceso de impresión. Dine combina objetos reales con fondos pintados. Oldenburg fabrica objetos de la vida cotidiana (hamburguesas, navajas, etc.) a tamaños descomunales que instala en ocasiones en espacios al aire libre. Indiana pinta rótulos gigantescos que reclaman la atención del espectador al tiempo que lo amonestan.

Durante los años cincuenta la pintura abstracta en los Estados Unidos evolucionó hacia movimientos como el neodadaísmo, la abstracción postpictórica o el "Op Art", aunque continuó cultivándose el expresionismo abstracto. En gran medida, muchas de estas tendencias fueron desbancadas a partir de 1960 por la aparición del minimalismo, que marcó un nuevo periodo de interés por la geometría y la estructura, del objeto consigo mismo. Toma del "pop art" las «definiciones claras y desprovistas de ambigüedad», y de la abstracción el libre empleo de los colores. Está representado en la obra de Frank Stella, Carl Andre y el artista famoso por sus instalaciones de luces fluorescentes Dan Flavin. 

Alfonso A. Ossorio es la representación estadounidense dentro del "art brut" de los años cincuenta. En esta misma década surgió, en San Francisco (California), y como reacción a la falta de objetividad del expresionismo abstracto, el "Funk art".

Más tarde surgieron otros movimientos abstractos como Fluxus y el posminimalismo (un término acuñado por vez primera por Robert Pincus-Witten en un artículo publicado en la revista "Artforum" en 1969; refiriéndose a la obra de la artista Eva Hesse, dijo que era "post minimal art" o «arte posminimalista»). Estos movimientos, como la abstracción lírica, buscaron expandir los límites de la pintura abstracta y el minimalismo centrándose en el proceso, los nuevos materiales y las nuevas vías de expresión. La abstracción lírica comparte semejanzas con la pintura de los campos de color y el expresionismo abstracto especialmente en el uso despreocupado de la pintura - textura y superficie. El dibujo directo, el uso caligráfico de la línea, los efectos de la pintura salpicada, manchada y vertida se asemejan superficialmente a los efectos vistos en el expresionismo abstracto y la pintura de los campos de color. Sin embargo los estilos son marcadamente diferentes. El posminimalismo a menudo incorporó materiales industriales, materia bruta, objetos encontrados, instalaciones, repeticiones seriales y a menudo con referencias al dadaísmo y el surrealismo está ejemplificada mejor en las esculturas de Eva Hesse. Esta artista, junto con otros «posminimalistas» como Richard Serra, se encuentran dentro de la tendencia de "arte procesual".

El realismo, a pesar del enorme éxito de movimientos no figurativos como el expresionismo abstracto, no dejó de ser popular, como prueban las ilustraciones de Norman Rockwell. Además del "Pop Art", hubo otros movimientos figurativos que reaccionaron ante la abstracción, como el movimiento figurativo de la zona de la Bahía o, en los setenta, el neoexpresionismo. En ciertos lugares el expresionismo abstracto nunca prendió. Un ejemplo de ello es Chicago, en el que el estilo artístico dominante fue un realismo grotesco y simbólico, como muestran los "Chicago Imagists", entre los que se encuentra Nancy Spero. 

Otros movimientos figurativos de la segunda mitad del siglo son el fotorrealismo y el nuevo realismo. El hiperrealismo, "photorealism" o "superrealism" realiza cuadros figurativos muy detallados y fríos; surgió en los Estados Unidos hacia 1965 y sobresalen en esta tendencia Richard Estes y Chuck Close. El "new realism" (nuevo realismo) que se desarrolló entre 1960 y 1970 tuvo en Alex Katz y Alice Neel sus máximos representantes estadounidenses. En los años ochenta se revitalizó lo figurativo, si bien a través de propuestas muy diversas que van desde Keith Haring y sus formas simples inspiradas por el "graffiti" hasta la "Bad painting" de Julian Schnabel, David Salle o Jean-Michel Basquiat. La "Bad painting" surgió a principios de la década de los ochenta; es una «mala pintura» que recuerda al "art brut" y que forma parte de un movimiento internacional más amplio (con los nuevos fauves alemanes o la transvanguardia italiana) en la que se abandonaba el intelectualismo del arte conceptual y se reivindicaba el «mal gusto» del arte marginal.

Desde mediados de los años sesenta y a lo largo de los setenta aparecieron nuevas tendencias que ampliaron los límites del arte contemporáneo. El arte conceptual, surgido en Nueva York en torno a 1965, considera que lo prioritario es el concepto, la idea, y no su realización física en un objeto artístico determinado; conceptuales son, por ejemplo, Joseph Kosuth y Dennis Oppenheim. Para finales de la década de los setenta, sin embargo, se consideró «fracasado» el arte conceptual, y se intentó un nuevo discurso artístico cuyo ejemplo inicial fue la exposición "Pictures", celebrada en Nueva York en 1977, en la que expusieron artistas como Jack Goldstein, Robert Longo y Sherrie Levine. Hubo quien recicló obras o logotipos previos, haciendo una especie de copias de copias (simulacionistas) o bien artículos de revistas de una manera que recordaba al "pop art" (apropiacionistas, entre los que se encuentra Jeff Koons).

El "Land Art" tiene como material de su obra la propia tierra, primando más que el resultado artístico los testimonios que de la obra quedan, en fotografía o vídeo; artista "land" destacado fue Robert Smithson. El videoarte surgió hacia el año 1963, simultáneamente en Estados Unidos y en Europa, y fue utilizado por las otras corrientes de la época, como fluxus o el arte conceptual. Otras novedades fueron las "performances" o el arte de instalaciones. Vito Acconci y Dennis Oppenheim cultivaron el arte corporal o "body art". 

Una de las corrientes que aportó algo nuevo fue la "pattern painting", surgido en California en 1975, que presenta de manera repetitiva motivos decorativos; son sus cultivadoras artistas femeninas que se oponen así a la severidad del minimalismo, utilizando muchas veces técnicas artesanales tradicionalmente consideradas femeninas como, por ejemplo, el "patchwork." En cierto sentido tuvo como precursor el llamado arte feminista, realizado por mujeres y teniendo como tema la condición femenina, que surge a finales de la década de los sesenta, en paralelo con el movimiento "Women's Lib." 

Todas estas vanguardias del último tercio del siglo XX se centraron en experimentar con diversos medios que la tecnología ponía a su disposición. No es ajeno a ello ni los ordenadores, que dan lugar a un arte digital, ni internet, que permite el "net.art." La informática permitió, a partir de mediados de los sesenta, que se crearan imágenes artísticas por medios digitales, esto es, imágenes generadas por ordenador. A mediados de los noventa se dio un salto cualitativo, logrando creaciones artísticas a través de la red, lo que desafía conceptos clásicos de autoría o identidad del artista.



 yessenia rebolledo

</doc>
<doc id="15363" url="https://es.wikipedia.org/wiki?curid=15363" title="Economía de Portugal">
Economía de Portugal

Portugal se ha transformado en una economía de mercado bien diversificada y basada en servicios después de entrar en la Comunidad Económica Europea en 1986. Durante los últimos dos decenios, sucesivos gobiernos privatizaron muchas compañías estatales y sectores claves de la economía, incluyendo el sector financiero y las telecomunicaciones. El país se unió a la Unión Monetaria Europea en 1998 y adoptó el euro el 1 de enero del 2002.

Durante los años noventa el crecimiento económico portugués se situó por encima de la media de la Unión Europea, pero cayó entre 2001 y 2008. Su producto interior bruto está cerca de los ⅔ de la media de la UE.

Bajo el gobierno conservador de Pedro Passos Coelho (2011-2015), Portugal se compromete en una "política de austeridad" destinada a reducir el déficit público y revitalizar el sector privado: reducción del salario mínimo y de las pensiones de jubilaciónes, aumento de los impuestos y reducción de las ayudas estatales. Sin embargo, el déficit se mantiene en el 4,4% del PIB, lo que genera amenazas de sanciones por parte de la Unión Europea, la precariedad y la pobreza aumentan en el país.


(Convertidos según paridad del poder de compra). Año 2000

17193,56 € (Tipo conversión: 1 dólar = 1,0882 € al 30/01/01)








Según datos de 1999, los porcentajes de ocupación por sectores productivos fueron:

Según los datos de la Unión Europea, la tasa de paro presentó la siguiente evolución entre 2000 y 2005:

Su moneda anterior era el escudo portugués; desde el 1 de enero de 2002 es el euro.

A pesar de su grado de desarrollo, el escaso peso demográfico de Portugal hace que su influencia específica en el contexto internacional sea menor que el de otras potencias europeas. Según datos del Banco Mundial, Portugal ocupa el puesto 30º en el ranking de mayores economías por PIB, y el puesto 24.º si el indicador que utilizamos es la Renta per Cápita. Portugal tiene una de las tasas de natalidad más bajas del mundo por (menos de un niño por mujer) lo que provocará un inminente pérdida de población si no se corrige la tendencia en las próximas décadas. Según Eurostat, la sanidad portuguesa tiene también unos indicadores muy positivos (267 médicos y 365 camas por cada 100000 habitantes). A pesar de ello, Portugal es el país europeo con mayor ratio de muertes por VIH (155 personas por cada 100000 habitantes). Por otra parte, según el Foro Económico Mundial, Portugal es el 46.º país del mundo en el Índice de Competitividad Global. En la siguiente tabla se puede analizar el contexto socioeconómico de Portugal a partir de datos del Banco Mundial, Eurostat y el Foro Económico Mundial:

Se presentan a continuación las mercancías de mayor peso en las importaciones de Portugal para el período 2010-hasta abril de 2015. Las cifras están expresadas en dólares estadounidenses valor FOB.

Se presentan a continuación los principales socios comerciales de Portugal para el periodo 2010-hasta abril de 2015. La mayoría de sus importadores están en Europa salvo Estados Unidos y Angola. Las cifras expresadas son en dólares estadounidenses valor FOB.



</doc>
<doc id="15365" url="https://es.wikipedia.org/wiki?curid=15365" title="Narrativa gótica">
Narrativa gótica

La narrativa gótica es un género literario nacido en Inglaterra a finales del siglo XVIII, relacionado con el género de terror.

Entre algunas características o tópicos del género podemos encontrar tales como su relación con el arte arquitectural gótico el cómo el entorno se encuentra en constante cambio conforme cambien las emociones del protagonista, el uso de un estilo epistolar (carta), cuenta con una intensa carga descriptiva llamada Efecto de realidad, entre otros muchos.

No puede decirse que haya existido la novela de terror sino hasta la aparición del terror gótico; estrictamente hablando, la primera novela gótica fue "El castillo de Otranto" (1764), de Horace Walpole, Entre estos autores, el género se desarrolló con obras como "Vathek", de William Beckford (1742, originalmente en francés); "Los misterios de Udolfo", de Ann Radcliffe (1794); "Las aventuras de Caleb Williams", de William Godwin (Londres, 1794); "El monje", de Matthew Lewis (1796), y "Manuscrito encontrado en Zaragoza", de Jan Potocki (1805).

Dentro del subgénero narrativo denominado novela, es preciso distinguirla de la narración popular fantástica del folklore y de los cuentos tradicionales de aparecidos, porque se desarrolla fundamentalmente desde fines del siglo XVIII a la actualidad y posee características distintas asociadas al movimiento estético conocido como Romanticismo. En algunos manuales de literatura se hace referencia a la novela gótica también como novela negra, si bien este término puede dar lugar en la actualidad a equívocos.

Las características de este género pasan en primer lugar por una ambientación romántica: paisajes sombríos, bosques tenebrosos, ruinas medievales y castillos con sus respectivos sótanos, criptas y pasadizos bien poblados de fantasmas, ruidos nocturnos, cadenas, esqueletos, demonios... Personajes fascinantes, extraños e insólitos, grandes peligros y a menudo cándidas muchachas en apuros; los elementos sobrenaturales podían aparecer directamente o solamente ser sugeridos. Estas ubicaciones y personajes, en tiempo y espacio, respondían a la demanda de temas exóticos característica de la tendencia al medievalismo, el exotismo y el orientalismo propia de la sensibilidad romántica.

Pese a que no existió un movimiento definido como en otras partes de Europa, diversos escritores rusos incursionaron también en el género aportando relatos que exhiben como tema principal las brujas, los hombres lobos y otros personajes oscuros, propios del folclore eslavo. El primer autor, y más prolífico, en dedicar su pluma a los relatos de terror es Gógol, con algunos cuentos cortos como "Viy" (que cuenta con más de una adaptación cinematográfica), "La noche de San Juan", y "La noche de mayo o la ahogada". Otros autores rusos que introdujeron historias de terror fueron, Baratynski ("El anillo"), Somov ("El hombre lobo"), Karamzin ("La isla de Bornholm") y Lermontov ("Stuss").

El adjetivo "gótico" deriva de "godo", y, en efecto, en el contexto de este subgénero literario, gran parte de las historias trascurren en castillos y monasterios medievales. En sentido estricto, el terror gótico fue una moda literaria, de origen fundamentalmente anglosajón, que se extendió desde finales del siglo XVIII hasta finales del siglo XIX, como reacción al Racionalismo. En la literatura de terror moderna los viejos arquetipos no desaparecieron totalmente.

El movimiento gótico surge en Inglaterra a finales del siglo XVIII. El renacimiento del gótico fue la expresión emocional, estética y filosófica que reaccionó contra el pensamiento dominante de la Ilustración, según el cual la humanidad sería capaz, solo en uso de la Razón, de llegar a obtener el conocimiento verdadero y la felicidad y virtud perfectas; aunque el Romanticismo demostraría que tan insaciable apetito de conocimiento dejaba de lado la idea de que el miedo podía ser también sublime.

Las ideas de orden de la Ilustración van siendo relegadas y dan paso a la afición por el gótico en Inglaterra y así se va abriendo camino para la fundación de una escuela de este tipo de literatura, derivada de modelos alemanes.

Las narrativas góticas abundan entre 1765 y 1820, con la iconografía que nos es conocida: cementerios, páramos y castillos tenebrosos repletos de misterios, villanos infernales, hombres lobo, vampiros, doppelgänger (transmutadores, o doble personalidad) y demonios, etc..

Los ingredientes de este subgénero son castillos embrujados, criptas, fantasmas o monstruos, así como las tormentas y tempestades, la nocturnidad y el simple detalle truculento, todo ello surgido muchas veces de leyendas populares. La obra fundadora del gótico es "El castillo de Otranto", de Horace Walpole (1765). Otras obras claves de esta corriente son "Vathek" (1786), de William Beckford, "Los misterios de Udolfo" (1794), de Ann Radcliffe, "El Monje", de Matthew Lewis, publicada en 1796, "Melmoth el errabundo" (1820), de Charles Robert Maturin y "Manuscrito encontrado en Zaragoza" de Jan Potocki. El Romanticismo exploró a fondo esta literatura, casi siempre inspiradora de negredor de sentimientos morbosos y angustiantes, que alcanzó su máximo esplendor en el siglo XIX, a impulsos del descubrimiento del juego mórbido con el inconsciente.

Aunque Julio Verne cultivó sobre todo los géneros de aventuras y de la ciencia-ficción, existe una novela suya poco conocida que posee las características de la novela gótica: "El castillo de los Cárpatos". Dicha novela es considerada como una "rara avis" en la producción de Verne y suele considerarse como su única incursión en el género de la novela gótica, reuniendo todos los elementos que la caracterizan: un castillo tenebroso abandonado, una bella cantante de ópera supuestamente secuestrada por un malvado noble (el Barón Gortz), un héroe enamorado dispuesto a rescatarla hasta enloquecer, supersticiones populares sobre fantasmas y aparecidos, etc... Escrita cinco años antes que "Drácula" comparte no pocos elementos con la obra de Bram Stoker.
Obras de pleno siglo XIX, como "Carmilla" de Sheridan Le Fanu, "Frankenstein" de Mary Shelley, "El corazón delator" de Edgar Allan Poe, y, más adelante, "Janet, la del cuello torcido" de R. L. Stevenson, "El Horla" de Guy de Maupassant, "Otra vuelta de tuerca" de Henry James, etc., puede decirse que superan ampliamente el terror gótico, pues o van más allá, o no reúnen las citadas características. Salvo en casos excepcionales, tienden al formato corto del cuento en menoscabo de la novela; no se recurre a las monjas ensangrentadas, ni son elementos necesarios los aullidos espectrales y los truenos, rayos y centellas de tormentas; no tienen por qué transcurrir en escenarios ruinosos, castillos y monasterios medievales; los fantasmas que presentan no están "encadenados"; apenas tienen que ver con leyendas populares... Por lo tanto pueden considerarse ya como obras plenamente representativas del terror moderno que alcanzará a nuestros días, si bien en este punto la opinión de los críticos está dividida.

En los relatos propiamente góticos se advierte un erotismo larvado y un amor por lo decadente y ruinoso. La depresión profunda, la angustia, la soledad, el amor enfermizo, aparecen en estos textos vinculados con lo oculto y lo sobrenatural. La mayoría de los autores sostiene que el gótico ha sido el padre del género de terror, que con posterioridad explotó el fenómeno del miedo con menor interés en los sentimientos de depresión, decadencia y exaltación de lo ruinoso y macabro que fueron el sello de la literatura romántica goticista, y más énfasis en otros elementos.

Fue también escritor de terror el romántico español Gustavo Adolfo Bécquer (1836-1870), quien incluyó en sus "Leyendas" algunos relatos de miedo muy meritorios como "Maese Pérez, el Organista", "El Miserere" y "El Monte de las Ánimas".

A fines del siglo XIX, Oscar Wilde tomó este subgénero con humor en su relato "El fantasma de Canterville".

"Los cantos de Maldoror", de Isidore Ducasse —conde de Lautréamont— es una obra considerada como precursora del surrealismo. No obstante, contiene elementos narrativos que permiten rastrear rasgos e influencias de obras como "Melmoth el errabundo", según señala Marcelyn Pleynet en su estudio sobre Lautréamont. En el caso de Maldoror, este es presentado como un ser que mediante la metamorfosis acecha a los hombres. Maurice Blanchot y Gaston Bachelard analizan el bestiario de las formas animales adoptadas por Maldoror; este suele denominarse a sí mismo con los apelativos de: «el vampiro», «aquel que no sabe llorar», «el montevideano», entre otros.

Ya en el siglo XX, la escritora estadounidense Anne Rice, cuyas obras mezclan lo cotidiano con historias de vampiros y de erotismo oscuro, ha tratado de revitalizar, temáticamente, el terror gótico. H. P. Lovecraft, por su parte, lograría sintetizar en las primeras décadas del siglo XX la tradición que partía de lo gótico con la ciencia ficción contemporánea. Actualmente, muy de moda nuevamente por el cine, lo gótico ha sido rescatado por autores anglosajones (al menos en determinadas obras) como Angela Carter, P. McGrath, A. S. Byatt, etc.

Según el ensayista César Fuentes Rodríguez, entre las características específicas de la novela gótica se encuentran las siguientes:








El terror moderno es la etapa de la literatura de terror que se desarrolla ya a partir de la primera mitad del siglo XIX por obra de precursores, como el estadounidense Edgar Allan Poe (1809-1849) y el irlandés Joseph Sheridan Le Fanu (1814-1873), cuyas aportaciones, especialmente el llamado terror psicológico, supusieron una profunda transformación de la literatura de terror gótico anterior, de raíces estrictamente románticas, y que, como se ha visto, utilizaba como principal recurso el "susto" y otras técnicas que hoy podrían pasar por anticuadas y rudimentarias.

Ya en las postrimerías del siglo XIX el cuento de horror o de fantasmas experimentaría nuevamente un gran avance como resultado de las aportaciones de los grandes cultivadores que encontró esta modalidad en Inglaterra (alguno sería de otra nacionalidad, como el francés Guy de Maupassant), en las épocas victoriana y eduardiana. Autores como Robert Louis Stevenson, M. R. James, Henry James, Saki (Héctor Hugh Munro) y Arthur Machen, entre otros, ejercerían una profunda renovación de estilos, temas y contenidos que, ya en pleno siglo XX, acabaría desembocando en el último autor mayor del género: el estadounidense Howard Phillips Lovecraft (1890-1937). Con él, el género macabro experimentaría nuevamente un giro de 180 grados.

Este autor, cuyo principal referente, según él mismo confesaba, era su compatriota Poe, fue el creador del llamado "cuento materialista de terror" (por oposición al "espiritualismo" a ultranza propio del relato de fantasmas tradicional). Introdujo, además, en el género elementos y contenidos propios de la naciente ciencia-ficción, lo que tendría amplias repercusiones en toda la literatura y el cine posteriores. Lovecraft, orientándose en principio a partir de las subyugantes fantasías que le proporcionaba su propio mundo onírico, supo conciliar éstas con las enseñanzas de autores de su predilección como el citado Poe, Lord Dunsany, Ambrose Bierce, Algernon Blackwood y William Hope Hodgson, lo que dio como resultado la asombrosa invención de una nueva mitología pagana en pleno siglo XX, los Mitos de Cthulhu, a través de la cual logró dar cumplida expresión a los muchos terrores y obsesiones que anidaban en su personalidad enfermiza. Con todo, desde el punto de vista estilístico, en ocasiones se ha achacado a Lovecraft un estilo encorsetado, abundante en adjetivos y fórmulas repetitivas, que hace que sus argumentos pueden predecirse con facilidad a medida que el lector asimila la técnica del autor.

Es necesario mencionar en este punto al grupo de autores que acompañó a Lovecraft en su alucinante periplo literario, publicando relatos en la famosa revista norteamericana Weird Tales, unos pertenecientes al Círculo de Lovecraft y otros independientes: Robert Bloch, Clark Ashton Smith, Fritz Leiber, Frank Belknap Long, Henry Kuttner, Seabury Quinn, August Derleth, Robert E. Howard, Donald Wandrei, etc., algunos de los cuales, a juzgar por la opinión de ciertos críticos, de valores literariamente discutibles.

Otro autor de interés en este campo, no tan conocido como las versiones cinematográficas de sus obras, es Robert Bloch, autor de la novela "Psicosis", uno de los últimos textos que se han añadido al canon de la literatura de terror. otras de sus novelas destacadas son "Cría cuervos" y "Pirómanos". Los lovecraftianos Fritz Leiber y Henry Kuttner escribieron sobre todo novelas de fantasía y ciencia ficción. La mayor contribución de August Derleth, discípulo directo de Lovecraft, ha sido la edición de los textos del mismo, aunque es autor de algún relato de mérito. Robert E. Howard centró su atención más en la fantasía épica: Conan y Sonya la Roja, entre otros personajes famosos, particularmente por las versiones cinematográficas y los cómics.

Uno de los modelos de Lovecraft es el autor inglés, ya citado, William Hope Hodgson al cual se considera precursor del género de horror cósmico creado por aquel. Nacido en 1875 y muerto en 1918, su obra "La casa en el confín de la tierra" narra en primera persona las peripecias del habitante de una pequeña aldea irlandesa que es raptado por unos seres mitad hombres, mitad bestias, y transportado a otra dimensión.

Pero el escritor que gran parte de la crítica sitúa al lado de Poe, Lovecraft y Maupassant en el panteón de ilustres cultivadores del miedo, es el estadounidense Ambrose Bierce (1842-1914?), quien a través de contundentes filigranas como "Un terror sagrado", "La ventada cegada" o "La cosa maldita" se evidenció como maestro absoluto en la recreación de tensas atmósferas desasosegantes en medio de las cuales estalla de pronto un horror absorbente y feroz.

El tópico del hombre lobo fue introducido en el género por Guy Endore, con su novela "El hombre lobo en París", de 1933, aunque hay claros antecedentes en "Capitán de lobos" de Alejandro Dumas padre.

La última hornada del género de terror cuenta con figuras literariamente controvertidas, la mayoría procedentes del mundo anglosajón, como Stephen King, Ramsey Campbell y Clive Barker, autores de gran número de best-sellers, algunos de los cuales han sido adaptados con éxito al cine. En los últimos años, la producción de este género se ha trasladado, en gran parte, desde el campo de la literatura al de la cinematografía, la historieta, la televisión y los video-juegos, dando origen a un nuevo subgénero de terror, el "gore" ('sangre espesa', 'coágulo' en inglés), caracterizado por el fácil recurso a las escenas sangrientas y la casquería barata.

Stephen King resulta muy controvertido por la enorme difusión que ha alcanzado, pero deben discriminarse, dentro de la enorme cantidad de textos que ha producido, los más literarios, como "Danza macabra", "Salem's Lot" o "Estaciones diferentes", de los decididamente comerciales, y de gran repercusión igualmente, como "El ciclo del hombre lobo". Los textos de Clive Barker frisan a veces con el "gore" más descarado. Son de gran interés por los altos vuelos de imaginación en ellos desplegados sus "Libros de sangre", con historias de horror "experimental", como "Cabal" o "En las colinas, las ciudades", y otras que han tenido gran difusión por sus versiones cinematográficas, como "Hellraiser", adaptada al cine.

Ramsey Campbell, T. E. D. Klein, Brian Lumley y Anne Rice son autores igualmente dignos de figurar en este apartado. Anne Rice (pseudónimo de Howard Allen Frances O'Brien), es famosa por la novela "Entrevista con el vampiro", y por su versión cinematográfica, además de otras obras como "Crónicas vampíricas" y "Brujas". Son continuaciones de la primera "Lestat" y "La reina de los condenados", de la que también existe una versión cinematográfica, además de "El ladrón de cuerpos". La autora últimamente ha conciliado ambas series en varias novelas.





</doc>
<doc id="15366" url="https://es.wikipedia.org/wiki?curid=15366" title="H. P. Lovecraft">
H. P. Lovecraft

Howard Phillips Lovecraft (Providence, Rhode Island; 20 de agosto de 1890-Providence; 15 de marzo de 1937), más conocido como H. P. Lovecraft, fue un escritor estadounidense, autor de novelas y relatos de terror y ciencia ficción. Se le considera un gran innovador del cuento de terror, al que aportó una mitología propia —los Mitos de Cthulhu—, desarrollada en colaboración con otros autores, actualmente en vigencia. Su obra constituye un clásico del horror cósmico, una línea narrativa que se aparta de las tradicionales historias de terror sobrenatural —satanismo, fantasmas—, incluyendo elementos de ciencia ficción como, por ejemplo, razas alienígenas, viajes en el tiempo o existencia de otras dimensiones.

Su familia provenía de una distinguida tradición burguesa venida a menos, razón que marcó, en buena medida, la personalidad elitista del autor de Providence. Su padre murió cuando este era aún muy pequeño y su madre lo sobreprotegió intentando que no se relacionara con gente que ella consideraba de clase inferior. En 1921, cuando el autor contaba con treinta y un años, la muerte de su madre le afectó profundamente. Luego, conoció a la escritora y comerciante Sonia Greene, con quien contrajo nupcias y se mudó a Nueva York, pero fracasó en su matrimonio. Tras sentir una profunda aversión por la vida neoyorquina —donde se acrecentó su racismo— Lovecraft decidió volver a su Providence natal donde vivió con sus tías hasta el fin de sus días. De su estancia en Nueva York, Lovecraft continuó intercambiando correspondencia con autores como Robert E. Howard, Robert Bloch, Clark Ashton Smith o August Derleth, para quienes trabajó como escritor fantasma con algunos de ellos formando lo que se denominó, posteriormente, el Círculo de Lovecraft. Dichos autores colaboraron en buena medida en el desarrollo de su propia literatura y salvaron la obra de Lovecraft del olvido. Daba largos paseos nocturnos y le invadía una profunda sensación de soledad y frustración. Durante esa época desarrolló sus obras más representativas como "The Call of Cthulhu" —"La llamada de Cthulhu"— (1926), "At the Mountains of Madness" —"En las montañas de la locura"— (1931) o "The Case of Charles Dexter Ward" —"El caso de Charles Dexter Ward"— (1941). En cuanto a su pensamiento político, Lovecraft siempre se mantuvo como un ultraconservador, aunque defensor de las políticas demócratas de Franklin Delano Roosevelt en su apoyo al "New Deal". Manifestaba un claro sentimiento anticomunista, sin embargo pensaba que el laborismo inglés estaba «lejos de las tentaciones bolcheviques». Creía más en el comunismo de Marx y Engels que en el sistema capitalista estadounidense de su época.

Publicó en vida varias de sus obras gracias a la revista estadounidense "Weird Tales" de género "pulp", la primera de ellas fue "Dagón". Asimismo, Lovecraft cultivó la poesía, el ensayo y la literatura epistolar. Se carteó con sus colegas de profesión durante años y dejó escrita una correspondencia que asciende a cien mil misivas. Mil de estas fueron publicadas en cinco volúmenes por Arkham House, la editorial fundada por dos seguidores de Lovecraft, August Derleth y Donald Wandrei. Su estilo literario es inconfundible y muy personal. Lo caracteriza el exceso de palabras polisílabas y de adjetivos cultos como «atávico», «numinoso», «inmemorial», «arcano». Su tono siempre serio y solemne ha sido copiado en innumerables ocasiones por muchos escritores de terror como, por ejemplo, por los autores del Círculo de Lovecraft. Sus creaciones se han vuelto muy populares, como los dioses Cthulhu, Nyarlathotep, Azathoth, el libro ficticio "Necronomicón" o personajes como Erich Zann o , que han aparecido en diversas adaptaciones cinematográficas.

El legado de Lovecraft es muy extenso, abarcando literatura, ensayo, historietas, cine, música, juegos de mesa y videojuegos. Algunos de los ejemplos más notables son, en literatura, los relatos de Stephen King basados en la mitología de Lovecraft, como "Jerusalem's Lot" y "Pesadillas y alucinaciones"; el ensayo escrito por el propio H. P. Lovecraft, "El horror sobrenatural en la literatura" —el cual es, además, uno de los mejor considerados sobre el género de terror literario—; algunos cómics guionizados por el escritor Alan Moore, como "Providence"; grupos de "rock and roll" y de "heavy metal" como Metallica o Iron Maiden, que han mencionado el nombre del autor de Providence en algunos de sus álbumes principales; juegos de rol como "La llamada de Cthulhu", publicado por la editorial Chaosium, o videojuegos como "Alone in the Dark" o "Prisoner of Ice", que han basado sus temáticas en la mitología de los Mitos de Cthulhu. Asimismo, el séptimo arte ha llevado numerosas veces la obra de Lovecraft a la gran pantalla como, por ejemplo, "Re-Animator" (1985) de Stuart Gordon, "El color del espacio exterior" (2019) de Richard Stanley e, incluso, el director Guillermo del Toro lleva queriendo adaptar desde 2006 la novela "En las montañas de la locura".

Apenas reconocido en vida, a día de hoy su obra ha sido traducida a más de veinticinco idiomas y su nombre es uno de los más relevantes en cuanto al horror de ficción se refiere. Murió en 1937, prácticamente en la pobreza, debido a un cáncer intestinal. Más allá de su obra, se le considera un genio de la literatura de terror y uno de los escritores más influyentes del género fantástico del siglo.

El psiquiatra, ensayista y traductor Rafael Llopis, principal divulgador de Lovecraft en España, escribió sobre el autor: «Educado en un santo temor al género humano —exceptuando de este a las “buenas familias” de origen anglosajón—, creía que nadie es capaz de comprender ni de amar a nadie y se sentía un extranjero en su patria. Para él “el pensamiento humano [...] es quizá el espectáculo más divertido y más desalentador del globo terráqueo”».

"The Penguin Encyclopedia of Horror and the Supernatural" —"Enciclopedia Penguin del horror y lo sobrenatural"— recoge sobre el escritor: «Algunos han criticado sus obras por su estilo ampuloso, repleto de adjetivos, pero la armonía y el equilibrio en sus mejores cuentos justifican plenamente esa práctica como deliberada». Lovecraft inició un nuevo estilo literario reformulando muchos de los clichés del género de terror y dotándoles de un nuevo significado en su particular manera de narrar. Puso gran dedicación en ello y, de sus ideas estéticas sobre los cuentos de terror, nace su ensayo "El horror sobrenatural en la literatura" (1927, revisado en 1936), el cual es un riguroso y fundamental estudio sobre los principios del relato de temática sobrenatural. En este, el autor de Providence define que en cualquier historia de terror «debe haber presente una cierta atmósfera de mortal terror inesperado a fuerzas exteriores desconocidas», describiendo el desarrollo de la novela gótica a través de las obras de Walpole, Radcliffe, Lewis y Maturin.
En su estudio "Danse Macabre" —"Danza macabra"— (1981), el escritor Stephen King afirma que Lovecraft es «el príncipe oscuro y barroco de la historia del horror del siglo ». Además, por contraposición al mal interno o psicológico, «el concepto de mal externo tiene más alcance, es más impresionante. Lovecraft así lo entendió, y es lo que hace a sus historias de extraordinaria, ciclópea maldad, tan efectivas cuando son buenas. [Sus mejores cuentos] nos hacen sentir el peso del universo suspendido sobre nuestras cabezas, sugieren fuerzas sombrías capaces de destruirnos a todos solo con gruñir en sueños».

Para su biógrafo S. T. Joshi, Lovecraft «no era un “extraño en este siglo”», como afirma de sí mismo el protagonista de su cuento "El extraño". Si se estudian detenidamente sus historias se observará en ellas algo más que los sueños escapistas de un anticuario caduco: enseguida encontramos datos como el descubrimiento de Plutón, citado en "The Whisperer in Darkness" —"El que susurra en la oscuridad"— (1930), o la entonces todavía controvertida teoría de la deriva continental, en la novela "At the Mountains of Madness" —"En las montañas de la locura"— (1931). Y ahondando más, en la ficción más tardía, nos topamos repetida y significativamente con Albert Einstein, Max Planck y Werner Heisenberg. Asimismo, las metáforas sobre el futuro desarrollo estético, político y económico de la humanidad, se transparentan en las civilizaciones alienígenas que aparecen en "The Mound" —"El montículo"— (1929-1930; publicado en 1940 como obra de Zealia Bishop), "En las montañas de la locura" (1931; publicado en 1932) y "The Shadow Out of Time" —"La sombra de otro tiempo"— (1935; publicado en 1936)"."

Según la escritora estadounidense Joyce Carol Oates, «la mística identificación de Lovecraft con sus escenarios del Massachusetts rural y las antiguas colonias de Salem, Marblehead y Providence, sugiere un trascendentalismo paródico en el que el “espíritu” reside en todas partes excepto, posiblemente, en los seres humanos». Lovecraft, en suma, como ocurre con Edgar Allan Poe desde el siglo, ha ejercido «una influencia incalculable sobre sucesivas generaciones de escritores de ficción terrorífica».

Por su parte, el novelista francés Michel Houellebecq declaró: «Yo descubrí a H.P.L. a los dieciséis años gracias a un "amigo". Como impacto, fue de los fuertes. No sabía que la literatura podía hacer eso. Y, además, todavía no estoy seguro de que pueda. Hay algo en Lovecraft que "no es del todo literario" [subrayado del autor]».

Howard Phillips Lovecraft nació el 20 de agosto de 1890 a las 9 de la mañana en el hogar familiar situado en el n.º 194 —hoy 454— de Angell Street, en Providence, capital del estado de Rhode Island. La casa fue derribada en 1961. H. P. fue el hijo único de Winfield Scott Lovecraft (1853-1898) —representante de ventas de la Gorham Silver Company, dedicada al comercio de la plata, metales preciosos y joyería— y de Sarah Susan Phillips (1857-1921), la segunda de los cuatro hijos de Whipple Van Buren Phillips y Rhoby Alzada Place. Para ambos era su primer matrimonio, aunque los dos habían superado los treinta años cuando firmaron su enlace.

Lovecraft procedía de unos ancestros distinguidos; en cuanto a su línea materna, los Phillips, se podía rastrear su linaje casi hasta el "Mayflower", ya que los antepasados maternos se remontaban a la llegada de George Phillips a Massachusetts en 1630. Cuando el autor visitó algunas de las tierras de sus ancestros al este del estado de Rhode Island, el apellido de Phillips era recordado con cariño y respeto. Su línea paterna también era de origen británico y el escritor pudo rastrear su apellido —Lovecraft o Lovecroft— hasta el siglo .
Al pequeño y solitario Howard le gustaba frecuentar parajes extraños y apartados para poder dar rienda suelta a su exaltada imaginación. En esos lugares —cuevas, arboledas alejadas, etcétera— recreaba situaciones históricas o se ensimismaba en la observación de pequeños detalles que pasaban inadvertidos al resto de las personas, pero que a él le fascinaban, como detenerse a escuchar a las hadas del bosque o imaginar lo que podría existir en el espacio exterior. Quizás una de las razones por las que le gustaba tanto evadirse era por la estricta atadura a la que lo sometía su madre, diciéndole que él no debía jugar con niños de menor categoría o insistiendo en que era feo y que nunca llegaría a triunfar.

Cuando Lovecraft tenía casi tres años, su padre sufrió una crisis nerviosa en la habitación de un hotel de Chicago, donde se encontraba alojado por motivos de trabajo. Le ingresaron en el Butler Hospital, centro psiquiátrico de Providence, y fue incapacitado legalmente debido a una serie de trastornos de índole neurológico. A partir de ese momento y durante los cinco años siguientes, permaneció ingresado en ese hospital, donde murió el 19 de julio de 1898 con el diagnóstico de paresia general, una fase terminal de la neurosífilis. Aunque algunos biógrafos afirman que al niño Lovecraft le informaron de que su padre estaba paralizado y en estado comatoso durante ese período, todas las evidencias parecen demostrar que no fue así. Con la muerte del progenitor de Lovecraft, la educación del niño recayó sobre su madre, sus dos tías —Lillian Delora Phillips y Annie Emeline Phillips— y, en especial, sobre su abuelo materno, un importante empresario llamado Whipple Van Buren Phillips; todos ellos residían en la casa familiar.

Lovecraft fue un niño prodigio. Recitaba poesía a los dos años, leía a los tres y empezó a escribir a los seis, y a los ocho años de edad ya había leído gran cantidad de libros de la biblioteca particular de su abuelo. Uno de los géneros que más le apasionó en su infancia fue el de las novelas policíacas, llevándolo incluso a formar la «Agencia de detectives de Providence» a la edad de trece años. A los quince escribió su primer relato como tal, "The Beast in the Cave" —"La bestia en la cueva"—, imitación de los cuentos de horror góticos. A los dieciséis escribió una columna de astronomía para el "Providence Tribune".

Debido a la alta alcurnia de su madre, que no quería que el pequeño Howard se mezclara con niños «inferiores» a él, la educación primaria de Lovecraft fue eminentemente autodidacta. Su abuelo materno lo alentaba a la lectura, siendo esta una de sus aficiones favoritas. En la inmensa biblioteca de su abuelo descubrió —con un ejemplar de la "Ilíada" para niños entre las manos— el paganismo grecolatino y "Las mil y una noches", aunque a una edad muy temprana —a los cinco años— se declaró ateo, convicción que mantuvo hasta su muerte. Esto ayudó a que su imaginación se desarrollase rápidamente en comparación con el resto de los chicos de su edad, lo cual le produjo una falta de adaptación con estos. Cuando ellos querían jugar con espadas o a juegos fundamentalmente físicos, él prefería llevar a cabo entretenimientos más pausados e imaginativos, como representaciones históricas.

Su falta de perseverancia y de salud hicieron que Lovecraft no asistiera al colegio hasta los ocho años y tuvo que dejarlo después de un año. Durante su absentismo escolar, seguía leyendo con voracidad. Adquirió conocimientos de química y astronomía, llegando incluso a escribir como aficionado en algunas revistas científicas. Publicó varias revistas de circulación limitada, comenzando en 1899 con "La gaceta científica". Cuatro años después, regresó a la escuela pública Hope Street, donde cursó dos años y medio en la educación secundaria, hasta que abandonó definitivamente los estudios.

En 1904 falleció su abuelo materno, Whipple Van Buren Phillips, afectando sobremanera al joven Lovecraft —de catorce años de edad—. La mala gestión de las propiedades y del dinero familiar dejó a la familia en tan malas condiciones económicas que se vieron obligados a mudarse al n.º 598 (hoy un dúplex en 598—600) de Angell Street. Lovecraft quedó tan afectado por la pérdida de su abuelo y la casa que le vio nacer, que consideró el suicidio durante un tiempo. En 1908, antes de su graduación, sufrió un colapso nervioso y no recibió su diploma. S. T. Joshi, biógrafo de Lovecraft, sugiere que este colapso pudo deberse a sus dificultades con las matemáticas, una materia que necesitaba dominar para convertirse en astrónomo profesional. Este fracaso en su educación —Lovecraft quiso estudiar en la Universidad de Brown— fue una fuente de vergüenza y desilusión hasta el final de sus días. Aunque su mentalidad respondía a un racionalismo empirista, al autor de Providence le atraía la literatura imaginativa, seguramente influido por su escepticismo; encerrado en el pesimismo de la soledad y considerando que «el pensamiento humano es el espectáculo más divertido y más desalentador de la Tierra».
Desde 1908 hasta 1913 trató principalmente la poesía, pero fue entonces cuando Lovecraft descubrió la literatura gótica de Edgar Allan Poe y escribió algunos relatos de ficción fuertemente influido por este autor, en especial, por su cuento "The Tell-Tale Heart" —"El corazón delator"—. Vivía como un ermitaño y apenas tenía contacto con el mundo exterior, a excepción de su madre y de sus tías. Esta situación cambió al escribir una carta a la revista "Argosy", quejándose sobre lo insípido de las historias de amor de uno de los escritores más populares de la publicación, Fred Jackson. El debate entre los defensores de Jackson y Lovecraft en la columna de opinión llamó la atención de Edward F. Daas, presidente de la United Amateur Press Association (UAPA), que le invitó a unirse a ellos en 1914. La UAPA infundió un nuevo vigor a Lovecraft, sacándole de su voluntaria reclusión e incitándole a contribuir con sus poemas y ensayos. Un tiempo después, se convirtió en presidente de la UAPA, e incluso llegó a ser presidente interino de la National Amateur Press Association (NAPA), la rival de la UAPA, desde 1922 a 1923.

Por esos mismos años, editó su propia revista de carácter "amateur", "The Conservative". En 1917, a petición de algunos amigos, volvió a la ficción con historias mucho más pulidas, como "The Tomb" —"La tumba"— (1922) y "Dagon" —"Dagón"— (1919). Esta última fue su primer trabajo publicado de forma profesional, apareciendo en "Weird Tales" en 1923. Sobre esta época, comenzó a formarse poco a poco una enorme red de admiradores y amigos, entre los que se encontraban Robert Bloch, Clark Ashton Smith y Robert E. Howard, este último creador de "Conan el Bárbaro". La extensión y frecuencia de sus misivas con esas amistades lo convirtieron en uno de los más prolíficos escritores del género epistolar. Según su biógrafo L. Sprague de Camp, a lo largo de su vida, Lovecraft escribió alrededor de cien mil cartas.

La muerte de su padre tuvo en el niño Lovecraft escasas repercusiones, debido a que prácticamente no pudo conocerlo. No obstante, la de su madre, en 1921, le supuso una fuerte conmoción, ya que ocurrió tras una larga enfermedad. Algunos biógrafos suelen relacionarla con la sífilis de su padre. En cualquier caso, lo cierto es que la causa inmediata fue un postoperatorio deficiente después de una intervención quirúrgica de vesícula biliar. Estuvo ingresada, como su marido antes que ella, en el Butler Hospital. Durante el mismo, escribía frecuentemente cartas a su hijo, con el que permaneció muy unida hasta su fallecimiento, el 21 de mayo de 1921. Lovecraft adoraba a su madre y, cuando esta murió, él contaba con treinta y un años.

Muchos críticos consideran a la madre de Lovecraft la causante de todos los comportamientos peculiares y un tanto extravagantes que el escritor mostró durante su existencia. Parece ser que después del óbito de su esposo Winfield, Sarah, mujer tradicional y puritana, descargó todas las frustraciones de una burguesa venida a menos sobre su único hijo, al que sobreprotegió hasta límites demenciales y trató como si fuera su único bien en la tierra. De esta manera, favoreció el desarrollo de unas determinadas características de personalidad, comunes en estos casos, que condicionaron su patrón de conducta mientras vivió. Entre otros aspectos destacados, prefirió las relaciones humanas con su pequeño entorno que le ofrecía una mayor seguridad, antes de un entorno social más amplio y desconocido que no controlaba, debido a ese déficit en habilidades sociales óptimas por falta de aprendizajes adecuados durante su infancia y adolescencia.

La muerte de su madre y el agotamiento de lo poco que quedaba en la riqueza familiar lo llevaron a abandonar la idea de llevar una vida ociosa obligándolo a trabajar en pequeños encargos como escritor fantasma y corrector de estilo para escritos de otros autores. Gracias a este tipo de trabajos conoció a muchos de los que después formarían el llamado Círculo de Lovecraft, entre ellos Robert E. Howard, Clark Ashton Smith, Robert Bloch, Frank Belknap Long, August Derleth y otros más. Para estos escritores y «amigos», Lovecraft presentaba una gran diferencia entre su personalidad de solitario introvertido y erudito a través de las cartas y su forma de ser en persona. Lo definían como entusiasta y generoso, creativo, prodigio de inteligencia y con una faceta racista que no abandonó hasta los últimos meses de su vida. 

Respecto a las mujeres, Lovecraft no había llevado una vida de muchas relaciones con el sexo opuesto. De hecho, el autor es recordado por su «aparente falta de masculinidad» tal como explica el cineasta Guillermo del Toro en el documental sobre su vida y obra "". El retrato que el citado director de cine hace del autor de Providence es el de un «tipo anglófilo que parecía haber llegado a América en el "Mayflower": un tipo raro que no se acostó con muchas mujeres».

Dos meses después de la muerte de su madre, Lovecraft acudió a una convención de escritores aficionados en Boston, donde conoció a Sonia H. Greene. Nacida en 1883, hija de inmigrantes judíos procedentes de Ucrania, era viuda y siete años mayor que él. Se casaron en 1924 y se mudaron al condado de Brooklyn, en la ciudad de Nueva York. Las tías de Lovecraft, muy tradicionales, no vieron con buenos ojos esta boda, ya que su cónyuge era una mujer de carácter fuerte, independiente, propietaria de una tienda de sombreros y escritora aficionada en la United Amateur Press Association. Inicialmente H. P. L. quedó embelesado con Nueva York, pero pronto la pareja se vio inmersa en dificultades económicas. Sonia perdió su tienda y Lovecraft no conseguía encontrar un trabajo. Se sumaron los problemas de salud de su esposa, que tuvo que mudarse a Cleveland debido a un empleo que le surgió, mientras él se quedaba en el barrio Red Hook de Brooklyn, donde comenzó a sentir una profunda aversión por la vida neoyorquina. En efecto, la desalentadora realidad sobre la imposibilidad de hallar un trabajo en un lugar cuya población mayoritaria era inmigrante, entraba en un irreconciliable conflicto con la opinión sobre sí mismo, de ser un privilegiado caballero anglosajón, por lo que su racismo se galvanizó hasta el punto del miedo.

En 1926, todavía viviendo de forma separada, acordaron un divorcio amigable, donde el escritor alegó «las grandes divergencias entre ambos y los problemas económicos», aunque nunca se llevó a cabo. Debido al fracaso de su matrimonio, algunos biógrafos han especulado con la posibilidad de que Lovecraft fuera asexual, aunque Sonia dijo años más tarde sobre él que fue un «adecuado y excelente amante».

De vuelta a Providence el 17 de abril de 1927, convivió con sus tías durante los años siguientes, en una «espaciosa y marrón casa de madera victoriana» en la calle Barnes n.º 10 —la dirección del Dr. Willett en "The Case of Charles Dexter Ward" ("El caso de Charles Dexter Ward")— hasta 1933. Allí es donde se ve superado por la sensación de fracaso que lo invade, abandonándose a la soledad y la frustración. En esta época disfruta de paseos nocturnos, que repercuten en su hundimiento personal, y crean una esfera invisible de miedos que nunca le permitirán recuperarse, si bien, paralelamente, contribuyen a su máximo esplendor literario. En estos fructíferos años escribió la gran mayoría de sus obras más conocidas, como "The Call of Cthulhu" —"La llamada de Cthulhu"— (1926), "At the Mountains of Madness" —"En las montañas de la locura"— (1931) o "El caso de Charles Dexter Ward" —compuesta en 1927, pero que no vio la luz hasta 1941—, publicadas en revistas "pulp" como "Weird Tales" y "Analog Science Fiction and Fact".

Durante esos años visitó a varios anticuarios residentes en Quebec, Filadelfia y algunos lugares de Nueva Inglaterra, como Vermont y Massachusetts, al tiempo que siguió manteniendo su enorme correspondencia. A sus viejos amigos añadió otros muchos escritores jóvenes, como D. W. Rimmel, R. H. Barlow o Robert Bloch, a los que aconsejaba y supervisaba trabajos. Mostró preocupación con las condiciones políticas y económicas de su país. Durante la Gran Depresión, mostró su apoyo a Roosevelt y se convirtió en un socialista moderado, abandonando su conservadurismo, mientras continuaba estudiando una gran variedad de temas, desde filosofía a literatura o historia de la arquitectura.

Los últimos dos o tres años de su vida fueron muy apurados económicamente. A pesar del duro trabajo y de sus esfuerzos como escritor, la pobreza en la que vivía aumentó. En 1932 su querida tía, la señora Clark, murió viéndose obligado a mudarse en 1933 a una pequeña y exigua habitación de alquiler con su otra tía, la señora Gamwell, situada en la calle College 66, detrás de la biblioteca John Hay —la dirección actual de esta casa es 65 Prospect Street—. Además, su íntimo amigo Robert E. Howard, al que nunca llegó a conocer en persona, se suicidó el 11 de junio de 1936, dejándolo desconcertado y profundamente apenado.

Sus últimas obras fueron incrementándose en longitud y en complejidad, lo que dificultaba la venta pues las revistas "pulp" rechazaban los textos largos. Debido a ello, Lovecraft se vio en la necesidad de volver a trabajar como escritor fantasma para otros autores como en "The Diary of Alonzo Typer" —"El diario de Alonzo Typer"— (1938) de William Lumley, "The Mound" —"El montículo"— (1940) de Zealia Bishop y "Winged Death" —"Muerte alada"— (1940) de Hazel Heald, así mismo en poesía y otros estilos literarios.

Sobre los problemas económicos que sufrió el escritor a lo largo de toda su vida, el novelista francés Michel Houellebecq escribió:

En sus últimos años, su naturaleza enfermiza y la desnutrición fueron minando su salud. Su anormal sensibilidad a cualquier temperatura inferior a los 20 °C se agudizó hasta el punto de que se sentía realmente enfermo a tales temperaturas. Durante el último año de su vida, sus cartas estaban llenas de alusiones a sus malestares y dolencias. A finales de febrero de 1937, cuando contaba con cuarenta y seis años, ingresó en el hospital Jane Brown Memorial, de Providence. Allí murió a primeras horas de la mañana del 15 de marzo de 1937 de cáncer intestinal complicado con la denominada enfermedad de Bright. Aunque actualmente este término no suele utilizarse, se refiere a una serie de enfermedades inflamatorias de los riñones. Es decir, parece ser que Lovecraft tuvo una complicación de su enfermedad tumoral intestinal con una grave insuficiencia renal que provocó su fallecimiento. El diagnóstico de su enfermedad tuvo lugar apenas un mes antes de su muerte.

Fue enterrado tres días después en el panteón de su abuelo Phillips en el cementerio de Swan Point; aunque su nombre está inscrito en la columna central, ninguna losa señala su tumba. Muchos años después de su muerte, en la lápida que le erigió un grupo de aficionados, puede leerse una línea tomada de una de las miles de cartas que escribió a sus corresponsales: «Yo soy Providence».

Lovecraft fue un escritor casi desconocido en su propia época. Aunque sus historias se habían hecho un lugar en publicaciones de género "pulp" como "Weird Tales", solo los aficionados a este tipo de literatura conocían su nombre. De entre ellos, mantuvo una prolífica correspondencia con otros escritores contemporáneos, como Clark Ashton Smith y August Derleth, con los que forjó una gran amistad, incluso sin haberse conocido nunca en persona. Se estima que durante su vida escribió cien mil cartas, como apunta L. Sprague de Camp. En algunas ocasiones las fechaba doscientos años antes de la fecha en que habían sido escritas, lo que las databa en la época colonial, antes de la guerra de Independencia de los Estados Unidos (una guerra que lo hería por su anglofilia). Explica que, según él, los siglos y habían sido los mejores; el primero siendo el siglo de nobleza y de gracia y el segundo de la ciencia, en tanto que el siglo , en particular la era victoriana, habría sido un error.

Este nutrido grupo de escritores llegó a conocerse como el Círculo de Lovecraft, ya que tomaban prestados elementos de las historias de H. P. L.—libros misteriosos con nombres inquietantes, panteones de dioses extraterrestres, como Cthulhu y Azathoth, y lugares como Miskatonic y Arkham— para usarlos en sus propias historias, con la bendición y ánimo del propio autor; incluso en ocasiones con su ayuda, la cual solía extralimitarse de la función de editor a la de reelaborar los relatos. Fueron los esfuerzos del Círculo —particularmente los de August Derleth y Donald Wandrei— los que evitaron que el nombre y las historias de Lovecraft desaparecieran completamente en la oscuridad tras su muerte. Para ello crearon la editorial Arkham House con la que publicaron la mayor parte de la obra del escritor de Providence. A propósito de Derleth, el estudioso lovecraftiano, Rafael Llopis, define a este autor como «no [...] solo el sampablo de la religión cthulhiana, sino también el que vende reliquias de los aledaños del gran santuario oficial».

Después de su fallecimiento, el Círculo de Lovecraft siguió contribuyendo a su leyenda. August Derleth fue, probablemente, el más prolífico de todos ellos, ya que amplió y extendió la visión del escritor. Las contribuciones de Derleth han sido objeto de mucha controversia, ya que mientras Lovecraft nunca consideró a su panteón de dioses extraterrestres más que como parte de la trama argumental, Derleth creó una cosmología completa con una guerra entre Los Antiguos o Dioses arquetípicos —como Hypnos o —, y los Dioses Primigenios —como Cthulhu, Dagón o Nyarlathotep—. Además, asoció los Dioses Primigenios a los cuatro elementos. 

Algunos seguidores de Lovecraft no han visto con buenos ojos dichas modificaciones, puesto que parecen contradecir la visión del autor de un universo desordenado y sin plan, donde los seres menos malevolentes simplemente no se interesaban en la humanidad. Muchos aficionados se preguntan si el propio H. P. L. habría aprobado las extensiones de Derleth. Se especula que era muy comprensivo sobre esta clase de adiciones y modificaciones, por lo que probablemente hubiera dado el visto bueno a Derleth, pero no lo hubiera adoptado para sus propias historias. Si había un Círculo de Lovecraft, entonces la versión de Derleth sería un añadido interesante, pero no formaría parte del mismo.

El trabajo de Lovecraft ha sido agrupado en tres categorías por algunos críticos. Mientras que Lovecraft prefirió no referirse a estas categorías él mismo, sí escribió en alguna ocasión: «Existen mis obras poeanas y mis obras dunsanianas [pero] ¿dónde están mis obras lovecraftianas?».


Algunos críticos no ven la diferencia entre el Ciclo onírico y los Mitos de Cthulhu, a menudo señalando la recurrencia del "Necronomicón" y los subsiguientes dioses. Una explicación frecuentemente argüida es el que el Ciclo onírico pertenece más a un género de fantasía en tanto que los Mitos de Cthulhu se corresponden a la ciencia ficción.

Las pesadillas que sufría Lovecraft le sirvieron de inspiración directa para su trabajo, y quizás una visión directa de su inconsciente y su simbolismo explica su continuo revuelo y popularidad. Todos estos intereses le llevaron a apreciar de manera especial el trabajo de Edgar Allan Poe, quien influyó fuertemente en sus primeras historias, de atmósfera macabra y miedos ocultos que acechan en la oscuridad. El descubrimiento de Lovecraft de las historias de Edward Plunkett, Lord Dunsany, llevó su literatura a un nuevo nivel, resultando en una serie de fantasías que tomaban lugar en la tierra de los sueños. Fue probablemente la influencia de los cuentos de Arthur Machen, sobre la supervivencia del antiguo mal y de sus creencias místicas en misterios ocultos que yacían detrás de la realidad, la que ayudó finalmente a inspirar a Lovecraft a encontrarse a sí mismo a partir de 1923.

Otra inspiración provino de una fuente insospechada: los avances científicos en áreas como la biología, la astronomía, la geología y la física, que reducían al ser humano a algo insignificante, impotente y condenado en un universo mecánico y materialista, un pequeñísimo punto en la vastedad infinita del cosmos. Estas ideas contribuyeron de forma decisiva a un movimiento llamado cosmicismo y proporcionaron a Lovecraft razones de peso para su ateísmo.

Sobre este asunto, Rafael Llopis, probablemente el mejor conocedor de la figura y la obra de Lovecraft en el contexto de la lengua española, afirma en el prólogo a la antología fundamental "Los mitos de Cthulhu":
Llopis hace notar más adelante cómo recuerda el misticismo siniestro de los mitos lovecraftianos, el «estilo bíblico, los nombres sonoros y exóticos, el irrealismo onírico, el fondo numinoso de religión arcaica» que impregna relatos poeanos como "Silence, A Sonnet" —«Silencio, un soneto»— o "Shadow, A Parable" —«Sombra, una parábola»—, o también "A Dreamer's Tales" —"Cuentos de un soñador"—, debidos a otro precursor de Lovecraft, Lord Dunsany.

Sobre este asunto, Llopis —también psiquiatra— afirma en su "Historia natural de los cuentos de miedo" (2013) que: «Así, pues, la obra de Lovecraft contiene el germen de una religión primitiva, bárbara y cruel, llena de horror primordial. Y ese horror deriva también del juego dialéctico entre la fascinación que en él ejercía el caos de la subconsciencia prehumana y su propio terror racionalista a la regresión de la mente, a la pérdida del control consciente de sus pensamientos y actos. Para su mente rígida y estrictamente lógica, el caos representaba un peligro mortal, pero a la vez era liberación de un superyó tiránico y entrega a un mundo íntimo y ancestral que le atraía como un abismo prohibido. Otra contradicción importante, íntimamente vinculada a la anterior, es la que surge en Lovecraft entre su amor y su horror al pasado».

Los Mitos de Cthulhu integran un panteón de deidades alienígenas extradimensionales y horrores que se alimentan de la humanidad y que tienen trazos de antiguos mitos y leyendas. El término «Mito de Cthulhu» fue acogido por el autor August Derleth después de la muerte de Lovecraft, mientras que el autor de Providence se refería a su mitología artificial como «Yog-Sothothería».

Sus historias crearon uno de los elementos de mayor influencia en el género del horror: el "Necronomicón", el escrito secreto del árabe Abdul Alhazred. El impacto y la fortaleza del concepto del mito ha llevado a algunos a concluir que Lovecraft basó su trabajo en mitos preexistentes y en creencias ocultistas. Ediciones apócrifas del "Necronomicón" también han sido publicadas a través de los años.

Su prosa es anticuada, y frecuentemente usaba vocabulario arcaico u ortografía en desuso, así como adjetivos de uso poco habitual como «gibosa», «ciclópeo» o «atávico», con frecuentes intentos de transcribir dialectos, que han sido calificados de imprecisos. Su trabajo, al ser Lovecraft un anglófilo, está plasmado en un inglés británico utilizando comúnmente escritura anacrónica.

Se suelen señalar en la evolución literaria de Lovecraft diversas etapas marcadas por el influjo de sus autores favoritos en esas épocas. Cada fase tuvo su periodo de apogeo, mas no es posible precisar una fecha exacta de inicio y término dado que se superponen.




Por el contrario, otros autores distinguen ciclos o proyectos narrativos más específicos agrupados por temáticas en lugar de reunirlos cronológicamente, como es el caso anterior. Los diferentes ciclos temáticos son:


En la literatura de Lovecraft —cuentos, novelas y "novelettes"— normalmente se repiten varios temas que son característicos en su obra. Por ejemplo, el conocimiento prohibido, la influencia de razas extraterrestres, la culpa atávica, la imposibilidad de escapar del destino fatal, el racismo, una cierta aversión hacia las mujeres —aunque no debe confundirse con sentimientos misóginos— y los riesgos cada vez mayores de la ciencia; dichas temáticas pasan a analizarse con más detalle a continuación:

Los protagonistas de las historias de Lovecraft siempre son conducidos a la «unión de esos disociados conocimientos», y también así comienzan muchas de sus historias. Cuando tal cosa ocurre, la mente del protagonista o investigador, por lo general, queda destruida por la abismal enormidad de lo descubierto, al ser incapaz de asimilar semejante conocimiento. Aquellos que se cruzan con manifestaciones «vivas» de lo incomprensible, se vuelven locos. Aquellos personajes que intentan hacer uso de este conocimiento están, invariablemente, condenados. Algunas veces su trabajo atrae la atención de seres malévolos; ocasionalmente, son aniquilados por monstruos de su propia creación.

Los seres de los Mitos de Lovecraft a menudo se sirven de humanos. Cthulhu, por ejemplo, es venerado bajo distintos nombres por diferentes cultos alrededor del mundo, como los inuit de Groenlandia y los practicantes del vudú de Luisiana. Los adoradores son utilizados por Lovecraft debido a motivos narrativos como ayuda en el hilo conductor de la historia. A veces intervienen de forma directa en la acción.

La mayoría de los seres de los Mitos son extremadamente poderosos para ser derrotados por humanos, y su conocimiento directo significa, normalmente, que la víctima se vuelva loca. Cuando se llega a un acuerdo con ellos, Lovecraft necesita una forma de proveer una estructura dramática para construir el hilo tensor sin llevar la historia a un final prematuro. Los adoradores le ofrecen la forma de revelar información sobre sus «dioses» en pequeñas dosis, y haciendo posible para los protagonistas ganar batallas temporales. Lovecraft, como sus contemporáneos, imaginó «salvajes» más próximos al conocimiento sobrenatural, desconocido para el hombre civilizado. 

En esa misma línea, para el autor, los dioses que plasma en sus obras son más antiguos que la propia humanidad e, incluso, que la propia Tierra y observan al ser humano con indiferencia y, en la mayor parte de ocasiones, con crueldad.

Otro tema recurrente en las historias de Lovecraft es la idea de que los descendientes en una línea de sangre nunca pueden escapar de los crímenes cometidos por sus antepasados, si estos han sido lo suficientemente atroces. Los descendientes pueden estar alejados en tiempo y en espacio —y, además, en culpabilidad— del acto en sí mismo, pero la sangre se lo revelará.

Relatos que muestran este tema son "The Rats in the Walls" —"Las ratas de las paredes"— (1924), "The Lurking Fear" —"El miedo que acecha"— (1923), "Facts Concerning the Late Arthur Jermyn and His Family" —"Hechos tocantes al difunto Arthur Jermyn y su familia"— (1921), "The Alchemist" —"El alquimista"— (1916), "The Shadow over Innsmouth" —"La sombra sobre Innsmouth" (1936)— y "The Case of Charles Dexter Ward" —"El caso de Charles Dexter Ward"— (1927, publicada 1941). Ejemplos de crímenes que Lovecraft considera lo suficientemente atroces para que tengan esta clase de consecuencias son muestras del canibalismo que hay en "The Picture in the House" —"La lámina de la casa"— (1921) y en "Las ratas de las paredes".

A menudo, en las historias de Lovecraft, el protagonista es incapaz de controlar sus propias acciones, o encuentra imposible cambiar el curso de los acontecimientos. Muchos de estos personajes escaparían del peligro si simplemente corrieran en dirección opuesta, aunque esta posibilidad nunca surge o es de alguna forma sometida por una entidad externa, como en "The Colour Out of Space" —"El color del espacio exterior"— (1927). Con frecuencia estos sujetos se encuentran bajo la influencia de algún ser malévolo u otros seres. 

Con la misma inevitabilidad que el destino del ancestro, huir o suicidarse no proporciona la completa seguridad de escapar como en "The Thing on the Doorstep" —"El ser del umbral"— (1937), "The Outsider" —"El extraño"— (1926), "El caso de Charles Dexter Ward", etcétera. 

En algunos casos, este destino se manifiesta para toda la humanidad, y no existe escape posible como en "The Shadow Out of Time" —"La sombra de otro tiempo"— (1936) y en "La sombra sobre Innsmouth". En relatos como "The Dreams in the Witch House" —"Los sueños en la casa de la bruja"— (1933), la poética de Lovecraft apunta a la imposibilidad de triunfo de los saberes populares y científicos —las leyendas y la ciencia— frente al horror de lo desconocido.

Lovecraft juega a menudo con la idea de la civilización que lucha penosamente contra elementos bárbaros y primitivos. En algunas historias esta lucha es a nivel individual; la mayoría de sus protagonistas poseen una cultura y unos estudios elevados, pero se ven gradualmente corrompidos por una influencia maligna.

En estas historias, la «maldición» es normalmente hereditaria, o por cruzarse con seres no humanos como en "Hechos tocantes al difunto Arthur Jermyn y su familia" y "La sombra sobre Innsmouth" o bien a través de cierta influencia mágica como en "El caso de Charles Dexter Ward". La degradación física y mental aparecen de forma conjunta. El tema de la «sangre corrompida» podría representar la preocupación de Lovecraft respecto la historia de su familia, particularmente la muerte de su padre debido a que Lovecraft sospechaba que fue a causa de un desorden sifilítico.

En otras historias, una sociedad al completo es amenazada por la barbarie. A veces, dicho barbarismo es representado por una amenaza externa, con una civilización destruida por la guerra como en "Polaris" (1920). De vez en cuando, un pequeño grupo de gente cae en decadencia y surge espontáneamente un atavismo como en "El miedo que acecha". Mucho más frecuentemente, tales historias involucran a una cultura civilizada que es gradualmente socavada por una clase baja marginal, sin educación ni derechos, que se halla influida por fuerzas inhumanas.

Un componente común en el trabajo inicial de Lovecraft es asociar la virtud, el intelecto, una clase elevada, civilización y racionalidad a la raza blanca, que a menudo contrapuso con el corrupto, intelectualmente inferior, incivilizado e irracional, que asoció con gente de clase baja, racialmente impura, y/o no de raza europea, de piel oscura, que frecuentemente eran los villanos en sus historias.

Algunas de sus opiniones racistas más cruentas pueden localizarse en sus primeras poesías escritas en su juventud, particularmente en "On the Creation of Niggers" y "New England Fallen", ambas de 1912. En "On the Creation of Niggers", Lovecraft plasma de una forma muy cruda sus prejuicios, caracterizando explícitamente a la gente negra como subhumanos:

En "The Call of Cthulhu" —"La llamada de Cthulhu"— (1928), Lovecraft describe a un grupo mestizo de adoradores de Cthulhu:
Lovecraft también expresó en alguna ocasión creencias racistas y etnocéntricas en su cartas personales. En una carta fechada el 23 de enero de 1920, escribió:
En "Herbert West–Reanimator" —""— (1922), Lovecraft describe a un varón afroamericano que acaba de fallecer:
En "The Horror at Red Hook" —"El horror de Red Hook"— (1927), un personaje es descrito como «un árabe con una odiosa boca negroide». En la obra "La cabellera de Medusa", escrita para Zealia Bishop, la sorpresa final de la historia —tras revelar que el villano del relato es una medusa vampírica— es que ella: 

En "El caso de Charles Dexter Ward", se presenta de forma condescendiente a una pareja afroamericana: «Conocía a la familia negra que habitaba la casa y fue cortésmente invitado a visitar el interior por el viejo Asa y su fornida esposa, Hannah.» En un claro contraste con el propietario, al parecer extranjero: «… un hombre de facciones ratoniles y acento gutural…».
Los narradores en "The Street" —"La calle"— (1920), "Herbert West: reanimador", "He" —"Él"— (1926), "La llamada de Cthulhu", "La sombra sobre Innsmouth", "El horror de Red Hook", y en muchos otras historias, expresan sentimientos que podrían ser considerados hostiles hacia los judíos. Se casó con una mujer ucraniana de ancestros judíos, Sonia Greene, quien más tarde comentó que tenía que recordarle constantemente sus raíces cuando realizaba algún comentario antisemita. «Siempre que nos encontrábamos en las calles de Nueva York, abarrotadas de personas de distintas nacionalidades y credos —escribió Greene después de su divorcio— Howard venía lívido de la rabia. Parecía que iba a perder la cabeza».

Hasta cierto punto, las ideas de Lovecraft referentes a la raza reflejaban actitudes comunes en esa época. Particularmente las leyes de segregación racial se hacían cumplir en la mayor parte del territorio estadounidense y muchos estados promulgaban leyes eugenésicas y prohibiciones en contra del mestizaje, que también eran comunes en áreas no católicas de Europa. Un movimiento popular durante la década de 1920 dio como resultado una drástica restricción de la inmigración hacia los Estados Unidos, culminando en la ley de inmigración de 1924, que ponía de manifiesto testimonios de expertos ante el Congreso de los Estados Unidos sobre la amenaza dirigida hacia la sociedad americana a causa de la asimilación de «personas de baja cultura» del este y del sur de Europa.

Lovecraft era en un principio un anglófilo confeso y sostenía que la cultura inglesa era el pináculo comparativo de la civilización. Consideraba a los descendientes de los primeros ingleses en América como una rama de segunda clase, y todos los demás, por debajo de ellos —por ejemplo, su poema ""—. Su amor por la historia y la cultura inglesa se ve a menudo reflejado en su trabajo, como la nostalgia del Rey Kuranes por Inglaterra en "The Dream-Quest of Unknown Kadath" —"La búsqueda en sueños de la ignota Kadath"— (1927, publicada en 1943).

Las ideas de Lovecraft sobre la eugenesia se extendían a menudo sobre sus personajes de raza blanca. Mostró una mayor simpatía por la raza caucásica y los grupos culturales europeos. El narrador de "Cool Air" —"Aire frío"— (1928) habla despectivamente de los pobres hispanoamericanos de su vecindario, pero respeta al rico y aristócrata Dr. Muñoz, por sus orígenes celtíberos, y porque es «un hombre de cuna, culto y de buen gusto». Los descendientes degenerados de los inmigrantes holandeses en las Montañas Catskill, «quienes corresponden exactamente con la basura blanca en el sur», como se dice en "Beyond the Wall of Sleep" —"Al otro lado de la barrera del sueño"— (1919), son elementos comunes. En "The Temple" —"El templo"— (1925), el narrador es un capitán de un U-Boot de la Primera Guerra Mundial cuya fe en su «inquebrantable voluntad germánica» y la superioridad de su patria lo llevan a ametrallar a los supervivientes que se encontraban en botes salvavidas; más tarde, asesina a su propia tripulación, mientras lo ciega la maldición que ha atraído sobre él. De hecho, según "Lovecraft: Una biografía", por L. Sprague de Camp, el autor de Providence estaba horrorizado por los informes de violencia antisemita en Alemania —antes de la Segunda Guerra Mundial, que no viviría para ver— sugiriendo que el escritor a pesar de todo, se oponía al exterminio de aquellos que consideraba «inferiores».

El racismo de Lovecraft ha sido un foco continuado de interés académico e interpretativo. S. T. Joshi, uno de los primeros eruditos en Lovecraft, observa que «no hay ninguna negación del racismo en Lovecraft, ni puede ser interpretada simplemente como «típico de su época», ya que parece que Lovecraft expresó sus opiniones más pronunciadamente —aunque generalmente no para su publicación— que muchos otros contemporáneos. Es también absurdo negar que el racismo entra en su ficción». Michel Houellebecq defiende que «el odio racial» proporcionaba la fuerza y la inspiración emocional para muchas de las mejores obras de Lovecraft.

El antagonismo racista de Lovecraft es un corolario de su noción nihilista del determinismo biológico: "En las montañas de la locura", donde los exploradores descubren pruebas de una raza totalmente extraterrestre —Antiguos— que creó seres humanos mediante bioingeniería, pero fue destruida finalmente por sus brutales esclavos, los Shoggoth. Incluso después de que varios miembros de la expedición mueran a manos de los Antiguos y los Shoggoth, se aprecia cierta simpatía por parte del narrador hacia estos seres:

Estas líneas del pensamiento en la visión del mundo de Lovecraft —racismo y una romántica defensa reaccionaria del orden cultural frente a la degeneración del mundo moderno— han conducido a algunos estudiosos a establecer una afinidad especial con el aristocráta, antimodernista y tradicionalista Julius Evola:

Por otra parte, algunos autores consideran que el racismo de Lovecraft era más que nada de índole cultural e intelectual, pasivo e introvertido —como lo evidencia el hecho de que el poeta Samuel Loveman, uno de sus mejores amigos, quien era judío y homosexual, no se enteraría del antisemitismo y homofobia de Lovecraft hasta varios años después de la muerte de este a través de Sonia Greene—, más que brutalmente biológico, proactivo y extravertido- como el de los nazis de esa época quienes ya promovían el odio y la agresión a otras razas en forma activa y despiadada- siendo que Lovecraft expresa en algunas de sus historias cierta admiración a personas de distintos orígenes que han asimilado las costumbres, buenos modales y artes anglosajonas y por el hecho de haberse casado con una judía a quien él mismo consideraba una mujer sumamente inteligente y «bien asimilada».

En sus últimos años la antipatía de Lovecraft por ciertas razas y culturas específicas se sublimó en un desprecio a la ignorancia, soberbia y egoísmo de la especie humana en general —incluyendo a los sajones— y la risible e irónica insignificancia de la humanidad y sus vicios ante la magnificencia y misterio del universo no conocido, evidente en el desarrollo y desenlace de la mayoría de sus últimas obras de horror cósmico.

Las mujeres en la obra de Lovecraft escasean y no suelen ser ni compasivas, ni comprensivas ni amables. Los pocos personajes femeninos en sus historias, como Asenath Waite —si bien de hecho era un perverso hechicero que se había apoderado del cuerpo de una inocente chica— en "El ser del umbral" y Lavinia Whateley en "The Dunwich's Horror" ("El horror de Dunwich," 1929) son, de forma invariable, sirvientas de las fuerzas del mal.

El romance se encuentra casi ausente de sus historias; cuando aparece el amor, es normalmente de forma platónica —"The Tree" ("El árbol"), "Ashes" ("Cenizas")—. Sus personajes viven en un mundo donde la sexualidad tiene connotaciones negativas; si es reproductiva, suele dar nacimientos de seres subhumanos, como en "El horror de Dunwich". En este contexto, puede ser de ayuda prestar atención a la escala del horror de Lovecraft, que es frecuentemente descrito como «horror cósmico». Operando a escalas cósmicas, tal y como operan estas historias, asignan a la humanidad un rol insignificante, por lo que no es a la sexualidad femenina a lo que estos relatos niegan su rol positivo y vital, es a la sexualidad humana en general.

Además, Lovecraft sostiene en una carta privada, enviada a una de sus amigas escritoras y poetisas, que la discriminación en contra de la mujer es una superstición oriental, de la cual los arios deberían liberarse. Dejando el racismo aparte, la carta parece excluir una misoginia consciente, como de hecho parece estar descartada de su vida privada.

Lovecraft aceptó con resignación las realidades que la ciencia iba revelando en el transcurrir de principios del siglo. La Tierra y la raza humana ocupaban un lugar infinitesimal e insignificante en el esquema cósmico del universo. Entre las diversas respuestas a la moderna e incipiente cosmología científica, Lovecraft escogió la vía del horror. Infundió incertidumbre metafísica en sus trabajos y generó una potente carga emocional al conjunto, próxima a la histeria. Lovecraft aprovechó huecos, lagunas en el conocimiento del universo, y las convirtió en tenebrosas ciénagas del horror. En la obra "El color del espacio exterior" se pone de manifiesto la incapacidad de la ciencia para comprender un extraño meteorito, lo que lleva a un paroxismo demencial.

Inmerso por tanto en su etapa de madurez, abandonó definitivamente la superstición para adoptar un lenguaje científico. Dos opiniones se han planteado respecto de su relación entre ciencia y literatura:

Lovecraft mostró un precoz interés por la ciencia, comenzando por la química con solo nueve años, al que seguiría la astronomía tres años después, principal influencia en la primera etapa de su vida. De hecho, entre 1902-1903 editó sus propios libros de texto en ambas disciplinas así como un periódico científico entre sus allegados, derivando en 1906 en columnista sobre astronomía, ya en periódicos locales. Gradualmente fue ampliando su saber enciclopédico, familiarizándose con el darwinismo y el psicoanálisis, y estuvo al día de los descubrimientos científicos de la época.

La lista de científicos aludidos en la obra de Lovecraft es cuantiosa: desde clásicos como Euclides, los químicos Van Helmont, Le Boë, Glauber, Becher o Stahl, los astrónomos Serviss y De Sitter, los geólogos Taylor y Osborn, hasta los físicos contemporáneos Einstein, Planck, Wegener y Heisenberg, el matemático Rietmann, el neurólogo Freud, los psicólogos Watson y Pavlov, el médico Adler, el psiquiatra Jung, así como los antropólogos Quatrefages, Taylor, Boule o Keith o los paleontólogos Elliot Smith, Woodward o el mencionado Sir Arthur Keith.

En una carta escrita el 9 de noviembre de 1929 dirigida a Harris Woodburn, Lovecraft especula con la comodidad que proporciona la ciencia y el riesgo que supondría que se colapsara. Es más, en una época donde el ser humano veía la ciencia como algo tremendamente poderoso e ilimitado, Lovecraft se dio cuenta de su potencial alternativo y sus tenebrosos resultados.

Lovecraft estaba muy al tanto de los nuevos y revolucionarios descubrimientos científicos, incluyendo y mencionando en su obra a numerosos representantes científicos de la época, entre los que destaca Albert Einstein. Aludido en 1920 en una carta a un grupo de corresponsales, tres años después H. P. L. reaccionaría con horror, desconcierto y estupefacción a su teoría de la relatividad. El 26 de mayo de 1923 escribió estas palabras a James F. Morton:

Sin embargo, a partir de 1929 olvidó sus ingenuos puntos de vista sobre Einstein, admitiendo que «la relatividad y el espacio curvo son realidades inmutables, sin las cuales sería imposible formarse ningún tipo de concepción verdadera del cosmos» y reconociendo su valioso apoyo al materialismo. Valorado como el científico por excelencia entre los «auténticos cerebros del mundo moderno», lo mencionaría en varios de sus relatos: "La casa evitada", "El caso de Charles Dexter Ward", "El que susurra en la oscuridad", "En las montañas de la locura", "Los sueños en la casa de la bruja" y "La sombra de otro tiempo".

De todos modos, aun aceptando la relatividad general, el tratamiento de la misma en su obra fue divergente, apareciendo «trascendida, trastocada», mezclando las leyes einstenianas con las extensiones y/o violaciones de las mismas procedentes de su imaginación.

En "La llamada de Cthulhu" se alude a que «la geometría del lugar soñado por él era anormal, no euclidiana, y de repugnantes esferas y dimensiones distintas de las nuestras». La geometría no euclidiana es el lenguaje matemático y el trasfondo de la teoría general de la relatividad de Einstein, a la que Lovecraft hace referencia repetidamente al explorar la arqueología extraterrestre.

H.P. Lovecraft no tenía en gran estima las ideas del padre del psicoanálisis, sobre todo su sistema de interpretación de los sueños. Todas las menciones al «charlatán vienés» en sus relatos y correspondencia eran de carácter peyorativo. Lovecraft leyó a Freud profusamente y concluyó en un rechazo de su marco teórico.

Buen conocedor el mundo de los sueños, son en cierto modo su coto de caza, H. P. L. hizo un uso sistemático y extensivo de los mismos tanto a nivel experiencial como transliterados en sus obras, sobre todo en su segunda etapa onírica. Tal y como su biógrafo Houellebecq sentencia, Lovecraft «clasifica el material [onírico], lo trabaja; a veces se entusiasma y escribe la historia sobre la marcha, sin siquiera despertarse del todo —es el caso de "Nyarlathotep"—; en otras ocasiones solo conserva algunos elementos para insertarlos en una nueva trama; pero, sea como fuere, se toma los sueños muy en serio».

En esta cita al inicio de "Al otro lado de la barrera del sueño" (1919), Lovecraft añade con posterioridad (1934) la cláusula referente a Freud, ya que no conoció la obra del vienés hasta 1921, fecha en que la menciona por vez primera en su artículo "The Defence Reopens!".

Sin embargo, el escritor estadounidense tuvo en alta estima a la psicología, sobre todo a la psicología de los sueños. Se le ha acusado sin embargo de un entendimiento superficial de las teorías freudianas. El erudito de Lovecraft S. T. Joshi señala que «no está claro qué trabajo de Freud (si lo hubiera) había leído realmente Lovecraft; de hecho, es más probable que haya leído varias de sus explicaciones en libros o revistas». En una carta de Lovecraft a Elizabeth Toldridge, escrita en 1930, el autor de "La llamada de Cthulhu" concluye diciendo que «no existe tal cosa como "amor" en ningún sentido unificado, permanente o importante» tal y como se infiere del trabajo de Freud y del análisis de coetáneos del ámbito de la psicología como Pavlov, Jung, Adler o Watson. En la misma misiva asegura que teniendo en cuenta dichas conclusiones, unidas a la falta de conocimientos científicos y a desvaríos poéticos y místico-religiosos, hablar del «amor» carece de todo significado por ser algo totalmente ilusorio.

Otras interpretaciones aluden a que, aunque Lovecraft rechazara taxativamente el papel psicológico jugado por el psicoanálisis, es evidente que parte a contrario de dichas concepciones acerca de la configuración y mecanismos de la mente humana, defendiendo que los procesos de la psique son muchísimo más complejos que los descritos por el psicoanálisis, comprimiendo este las posibilidades y riquezas intrínsecas del inconsciente.
También se le ha acusado de una crítica incisiva que apelaba a la necesaria convalidación de las entonces incipientes hipótesis —principios del siglo— tanto de Freud como del propio Einstein. De hecho, si bien es despectivo en "Al otro lado de la barrera del sueño" (1919) y también en "Del más allá" (1920): «¿Has oído algo acerca de la glándula pineal? Me río de la superficial ciencia endocrinológica, en la que se sustentan los falsos y advenedizos freudianos», los conceptos freudianos desaparecen y/o reaparecen con posterioridad, sobre todo en obras colaborativas, pero ya con una mayor aceptación exenta de crítica. A la progresiva maduración y comprobación de la ciencia psicológica también se añadió el que Lovecraft se adentrara en una nueva etapa ya alejada de la impronta onírica.

Además de a Freud, Lovecraft también cita con frecuencia en sus cartas a Watson, Pavlov, Jung y Adler, entre otros. Lovecraft menciona a Jung por su nombre y ocasionalmente cita ideas controvertidas adoptadas por el, incluso si no acredita a Jung directamente. A diferencia de Freud, se ha señalado la similitud existente entre la psicología analítica de Jung y la obra de Lovecraft.

El estilo de Lovecraft es muy personal e inconfundible, caracterizado por un tono siempre serio y solemne. Comparado, por ejemplo, con otro maestro del género de terror, M. R. James, carecía de ironía y creaba atmósferas desde el principio, al contrario que el anterior, quien las iba levantando poco a poco. Sin embargo, y por el contrario, Lovecraft era un maestro en el tono; usaba muchos adjetivos y palabras polisílabas y un "tempo" narrativo lento y detallado. También usaba cierto léxico para ir predisponiendo poco a poco la sensibilidad del lector a la atmósfera del relato —con palabras como «atávico», «numinoso», «arcano»...—.

Solía narrar sus relatos en primera persona y desde el punto de vista de un erudito usando un inglés arcaico que le servía para establecer firmemente un ambiente acorde a su idiosincrasia e, incluso, llegó a inventarse una bibliografía ficticia de grimorios en latín, árabe y hebreo —el "Necronomicón" de Abdul Alhazred, "De Vermis Mysteriis", el "Liber Ivonis" aportación de su discípulo Robert Bloch, el "Cultes de Goules" del Conde D'Erlette, etcétera—. 

Sobre su uso de la primera persona, fundía lector y protagonista, pero con la peculiaridad de que este último solía ser un individuo distanciado de la sociedad, sin vida ordinaria ni necesidades sociales o placeres confesos, herramienta que Lovecraft empleaba para que el lector asimilase su psicología atormentada y acrecentase así su miedo. Describía todo con prolijidad, pero nunca, salvo al final de su carrera, al monstruo, al que dejaba obrando en un plano abstracto mucho más ominoso. Gustaba de esparcir sensaciones vagas e indefinibles para crear efectos de inseguridad y trascendencia, desordenando la realidad espacio-temporal. Su escritura tendía a una especie de religiosidad ritual de ecos paganos, pero arreligiosa, pues el autor era ateo: Lovecraft excluyó conscientemente la religión.

Otra de las características propias del estilo lovecraftiano, tal cual señala el maestro del horror literario Stephen King, es que Lovecraft situaba sus historias de terror en situaciones cotidianas y las ambientaba en su misma época —la mayoría transcurrían en las décadas de 1920 y 1930—, donde lo espantoso eclosiona en la vida ordinaria de sus protagonistas, que salen de su cotidianidad para penetrar en lo desconocido. Las referencias que el autor hacía al pasado eran de una manera algo "vintage". 

Aunque parezca una contradicción, la literatura de Lovecraft está considerada como una de las que mejor refleja el realismo de su época. Así lo apunta uno de sus seguidores y amigos, Robert Bloch en una de sus citas:

S. T. Joshi, uno de los mayores biógrafos y devoto de la obra del autor de Providence, describió específicamente la función del «realismo» en el estilo de Lovecraft:

De acuerdo con Graham Harman en su obra "Weird Realism: Lovecraft and Philosophy", en la que realiza un estudio pormenorizado sobre el «realismo» en la obra del autor de Providence, si hay algo esencial que encierra el término «lovecraftiano» es la idea de que «la realidad es mucho más extraña y aterradora de lo que es posible comprender y, más aún, de lo que es posible describir». Harman se refiere a esto como «realismo extraño», ya que la idea del propio realismo en la literatura de Lovecraft es, de hecho, «inconmensurable». Según Harman, el acceso al realismo descripto por Lovecraft, tan solo puede hacerse de manera oblicua a la propia realidad.

Lovecraft fue un ultraconservador durante toda su vida, cosa que se pone de manifiesto en sus correspondencias mantenidas con otros colegas suyos de profesión. El mismo escritor, en varias de sus cartas, habla sobre sus ideas políticas y cómo han evolucionado paulatinamente, y comenta sobre la situación política y social de su tiempo. 

Desde un punto de vista político, Lovecraft, que provenía de una familia de ideas republicanas muy marcadas, abrazó tanto el lado republicano como el demócrata. Entre las razones de este cambio estuvieron las consecuencias de la crisis que afectó a los Estados Unidos a finales de la década de 1920 y principios de 1930. Manifestaba un claro sentimiento anticomunista; sin embargo, creía que el laborismo inglés estaba «lejos de las tentaciones bolcheviques».

En las elecciones presidenciales de Estados Unidos de 1932, Lovecraft votó por el demócrata Franklin Delano Roosevelt, y luego apoyó el "New Deal". En la carta afirma que «Roosevelt fue ciertamente mejor que Hoover, entendió la realidad probablemente más que los demás, pero en gran parte su programa no fue prudente. Otorgar grandes poderes de toma de decisiones a las masas es absurdo, diría que es desastroso», poniendo énfasis en la necesidad de nuevas regulaciones en cuanto a la mecanización en los puestos laborales.

El 27 de noviembre de 1933 escribió una carta a Natalie H. Wooley en la que afirma creer que el mundo occidental estaba condenado al declive, conviniendo con las tesis de Oswald Spengler. En la misma carta, da una visión pesimista del futuro de la civilización humana, creyendo que la guerra y otras situaciones negativas son el resultado de «impulsos humanos permanentes y no erradicables» y que en el límite será posible, a través del «ingenio y el sentido común», reducir solo «el número de conflictos armados importantes y ejercer un mayor control sobre los robos perpetrados a nivel político».
Durante la mayor parte de su vida, su idea del gobierno ideal estuvo representada por un modelo próximo al socialismo, ya que creía que los capitalistas estadounidenses se enriquecieron y acumularon ganancias a través de la mecanización, lo que en cambio trajo desempleo y, en consecuencia, pobreza. A colación con esta idea, el autor de Providence se sintió próximo con las ideas políticas progresistas de Robert M. La Follette. Por tanto, Lovecraft estuvo más próximo a la ideas comunistas de Marx y Engels que a las de los políticos capitalistas estadounidenses de su época. Sobre estas ideas comunistas, el autor de "Los mitos de Cthulhu" afirmó:

Sin embargo, advirtió de las rigideces que comporta el comunismo en donde, en el peor de los casos, se manifiestan como políticas fascistas. Por eso, Lovecraft apostó intelectualmente por la tercera vía como una posible visión de gobierno ideal.

La obra del autor de Providence se ha traducido a veinticinco idiomas a lo largo del mundo, y el nombre de Lovecraft, a día de hoy, es uno de los más relevantes en cuanto a horror de ficción se refiere, pese a que este muriera siendo prácticamente un autor desconocido. Sus escritos, particularmente los Mitos de Cthulhu, han influido desde los años 60 a los autores de ficción a lo largo y ancho del mundo, y se pueden encontrar elementos propios de Lovecraft en novelas, películas, música, videojuegos, cómics y dibujos animados. Por ejemplo, los villanos de Gotham City en el universo de "Batman" son encarcelados en el Asilo Arkham, en la ciudad ficticia de Arkham, una invención lovecraftiana. Muchos escritores modernos de terror como Stephen King, Bentley Little o Joe R. Lansdale, por nombrar a unos pocos, han citado a Lovecraft como una de sus más importantes influencias.

Lovecraft es considerado como uno de los autores de literatura fantástica más influyentes del siglo y un maestro de la literatura de terror.

Con los años, el trabajo de Lovecraft ha inspirado a numerosos escritores que, a veces con la aprobación del propio autor de Providence, han publicado historias cortas relacionadas de alguna manera con sus temas, a menudo incluidas en colecciones denominadas Mitos de Cthulhu.

A principios de la década de 1920, Clark Ashton Smith tuvo una estrecha relación con Lovecraft, que duró hasta mediados de la década de 1930. Este vínculo a menudo los llevó a colaborar en la creación de topónimos y para sus historias; en la revista "Weird Tales" se publicaron algunos de los cuentos de Ashton Smith que fueron influenciados directamente por el trabajo de Lovecraft, como "Ubbo-Sathla", "El que camina en el polvo", "La venganza del hechicero" y "El engendro sin nombre".

Incluso August Derleth fue corresponsal y amigo de Lovecraft, basándose en gran medida su producción literaria en la cosmovisión del «abuelo» —uno de los múltiples apodos utilizados por Howard en su intercambio epistolar—, como "El habitante de la oscuridad", "El guardián del umbral", "La ventana del ático" y "La cosa que entró en el viento". Más adelante, tras el fallecimiento de su colega escritor de Providence, fundó junto a Donald Wandrei la editorial Arkham House con el fin de salvaguardar el legado literario de Lovecraft.

Además de Smith y Derleth destacan Robert E. Howard, Robert Bloch y Fritz Leiber.

Son muchos los autores que, aunque no tuvieron una relación directa con H. P. L., utilizaron también parte de las características de sus obras; entre ellos el escritor de ciencia ficción Ray Bradbury, el autor de terror Stephen King, este último con dos cuentos: "Jerusalem's Lot", publicado en la colección "El umbral de la noche", y "Crouch End", que forma parte de "Pesadillas y alucinaciones", el escritor y artista Clive Barker, o el autor de varias novelas de los Antiguos Brian Keene.

En la "Trilogía Illuminatus!" de Robert Shea y Robert Anton Wilson, las alusiones a las obras de Lovecraft son frecuentes, tanto en los personajes (por ejemplo, Robert Harrison Blake y Henry Armitage), en las criaturas (Tsathoggua y Yog-Sothoth), como en los libros ("Necronomicón", "Cultos innombrables").

Jorge Luis Borges escribió el cuento "There Are More Things", incluido en el volumen "El libro de arena", como homenaje a Lovecraft; no obstante el autor argentino tildó al de Providence de «mediocre». El escritor francés contemporáneo Michel Houellebecq escribió una biografía literaria de Lovecraft titulada "H. P. Lovecraft: Against the World, Against Life". La prolífica escritora estadounidense Joyce Carol Oates escribió una introducción para una colección de historias de Lovecraft. Los filósofos franceses Gilles Deleuze y Félix Guattari se refieren a Lovecraft en "A Thousand Plateaus: Capitalism and Schizophrenia", calificando a su historia corta "A través de las puertas de la llave de plata" como una de sus obras maestras.

En 1927, H. P. Lovecraft publicó su ensayo "El horror sobrenatural en la literatura" ("Supernatural Horror in Literature"), el cual está considerado como uno de los más valiosos estudios sobre el género de terror.

Fue escrito entre noviembre de 1925 y mayo de 1927 y se publicó por primera vez en la revista "The Recluse". En 1965 se incluyó en el libro de relatos de Lovecraft titulado "Dagón y otros cuentos macabros". Durante el ensayo, el autor de Providence repasa los referentes sobre la ficción sobrenatural en la antigüedad, incidiendo en la novela gótica y, más concretamente, en la figura del escritor Edgar Allan Poe, al cual considera como el verdadero iniciador de una corriente totalmente innovadora en los cuentos de terror. Desde Bram Stoker hasta sus autores más influyentes como Algernon Blackwood o Lord Dunsany, Lovecraft analiza, capítulo tras capítulo, los mecanismos propios que tiene el terror literario. Numerosos críticos lo han considerado como «el ensayo más importante sobre la literatura de terror».

A partir de los años 60, la obra de Lovecraft, aparte de gozar de adaptaciones más o menos fidedignas al cómic, inspiraría obras originales. Es el caso de "Lone Sloane" (1966) de la que su autor, Philippe Druillet, dijo: Otras muchas obras, como "Tales Of Peter Hypnos" (1975-1976) de Josep Maria Beà, también se muestran deudoras de la obra del escritor de Providence. 
El prestigioso guionista Alan Moore —autor, por ejemplo, de "Watchmen" o de "V de Vendetta"—, escribió un cómic original inspirado totalmente en el universo lovecraftiano, dibujado por Jacen Burrows y titulado "Providence" que publicó la editorial Avatar Press entre 2015 y 2017. 

Por otra parte, en los cómics del popular "Batman", los enemigos del protagonista están encarcelados en el asilo de Arkham de Gotham City, denominación fruto de la inspiración de su dibujante Dennis O'Neil al tomar como referencia la ciudad de Arkham surgida de la imaginación de Lovecraft.

En el mundo del cine, en particular en el cine de terror, la cosmología de Lovecraft ha sido fuente de inspiración continua en muchos filmes como, por ejemplo, "The Haunted Palace" (1963) de Roger Corman, el cual fue una de sus primeras adaptaciones al cine y versión de la novela corta "El caso de Charles Dexter Ward"; "El enigma de otro mundo" (1951) de Howard Hawks, el "remake" "La cosa" (1982) de John Carpenter o "" (1979) de Ridley Scott —incluido "Prometheus" del mismo director, así como el artista involucrado en ambos filmes H. R. Giger)— inspirados en la novela "En las montañas de la locura"; "Re-Animator" (1985) de Stuart Gordon basado en el relato lovecraftiano ""; "El ejército de las tinieblas" (1992) de Sam Raimi con numerosas referencias al famoso "Necronomicón" o "El color del espacio exterior" (2019) de Richard Stanley, actualización de su relato homónimo.

Destaca como proyecto cinematográfico pendiente la adaptación de la novela de Lovecraft "En las montañas de la locura" de un guion de 2006 del director Guillermo del Toro y el guionista Matthew Robbins, cancelado sucesivamente debido al alto presupuesto y a la insistencia de Del Toro de que fuera lanzado con una calificación R para hacer justicia a la visión del autor. El 6 de marzo de 2020 se filtró el guion de la adaptación, 108 páginas disponibles en línea.

Además de ser inspiración de trabajos literarios, el mundo de la música ha sido también muy influenciado por Lovecraft. Las letras de algunas de las canciones de grupos de metal extremo (géneros como el "black metal", "death metal", etcétera) han abarcado pasajes de algunas obras del autor, así como abordado de igual modo la mitología lovecraftiana. Algunos grupos son Morbid Angel, Uriel, Mercyful Fate, Metallica, Draconian, Cradle of Filth, Internal Suffering, Tiamat e Iron Maiden. El músico argentino Claudio Gabis compuso lo que en su discografía se conoce como "Trilogía Fantástica". Las canciones «Más allá del valle del tiempo», «Fiebre de la ruta» y «El viaje de Lord Dunsany» están basadas en la literatura de Lovecraft. 

Además de los grupos nombrados que recibieron influencia directa de la literatura lovecraftiana en algunas de sus composiciones, cabe destacar el grupo de "rock" psicodélico activo durante los años sesenta y setenta que se bautizó con el propio nombre de H. P. Lovecraft y que editaron dos álbumes de estudio titulados de manera homónima.

En el terreno de la música orquestal hay varios autores como Chad Fifer, Cryo Chamber y Graham Plowman que componen partituras ambientales y evocadoras inspiradas en las mitologías fabuladas por Lovecraft.

El juego de rol "La llamada de Cthulhu", publicado por Chaosium, donde los jugadores juegan a los investigadores de lo oculto, fue muy popular a principios de los noventa. Chaosium creó un suplemento para interpretar "La llamada de Cthulhu" en un entorno contemporáneo llamado "Cthulhu Now". Configuraciones similares, típicas del estilo del escritor de Providence, también se pueden encontrar en el juego de cartas coleccionables "La llamada de Cthulhu", publicado por Fantasy Flight Games. Además, algunas razas en "Dungeons & Dragons" se refieren a criaturas de la mitología de Lovecraft.

En el campo de los videojuegos, aunque sus historias contienen muy poca acción, enfatizando la atmósfera y los lugares, son numerosos los títulos que se inspiraron en el Ciclo de Cthulhu. La empresa de software Infogrames ha producido varios juegos inspirados en el universo Lovecraft. Por ejemplo, la serie "Alone in the Dark", en particular el primer episodio, ha incluido varias referencias a las obras del autor de Providence. Otro videojuego con configuraciones y temas puramente lovecraftianos es "Shadow of the Comet", también de Infogrames, seguido de "Prisoner of Ice", así como los videojuegos de la serie "Penumbra".

Bethesda Softworks también produjo un juego de disparos en primera persona llamado "Call of Cthulhu: Dark Corners of the Earth", inspirado principalmente en el cuento "La sombra sobre Innsmouth". En 2018, Cyanide Studio produjo "", un JDR interactivo desarrollado para Microsoft Windows, PlayStation 4 y Xbox One.

Narrativa completa en orden cronológico:


Las películas basadas en los escritos de H. P. Lovecraft incluyen las siguientes.











</doc>
<doc id="15369" url="https://es.wikipedia.org/wiki?curid=15369" title="Mama">
Mama

El término científico mama se emplea para designar la región anterosuperior lateral del tronco femenino humano, de otros primates y de otros mamíferos como la elefanta, y de la región anterocaudal sobreexpuesta a la pelvis para otras especies de mamíferos. Comprende como contenido a la glándula mamaria y los conductos galactóforos, al tejido conjuntivo y a la grasa perilobular.

En la anatomía humana, las mamas se desarrollan en un par, correlativas al área antes descrita para el ser humano, mientras que en otros mamíferos se dobla el número en la región descrita anteriormente. Su estructura es generalmente asimétrica —la izquierda es de mayor tamaño que la derecha en la mayoría de los casos, y lo contrario es muy poco frecuente—, y se sitúan bajo la piel en el tórax de todos los individuos de la especie humana.

Es muy frecuente usar el eufemismo y pseudocultismo «senos» como sinónimo de mamas; sin embargo, el término es impreciso: la palabra «seno», aplicada a la mama, corresponde en realidad al espacio que se ubica entre las mamas. En español coloquial, las mamas humanas suelen llamarse «tetas», «pechos», «bubis», «chichis» (en México) o «lolas» entre otros muchos nombres. En el caso de otros mamíferos, no se utilizan algunos términos más específicamente referidos a humanos, como «pechos», pero se añaden otras denominaciones, como «ubres» (este último término, si bien considerado correcto por algunos en su aplicación a humanos, normalmente solo es utilizado, en esos casos, de forma vulgar e, incluso, despectiva, para referirse a mamas de gran tamaño).

Los mamíferos machos también poseen mamas, aunque estas no están completamente desarrolladas. Sí suelen desarrollarse, sin embargo, como consecuencia de distintas enfermedades congénitas, como el seudohermafroditismo.

Cada mama, cuyo aspecto exterior es una prominencia de tamaño y turgencia variables, posee ciertas estructuras tanto externas como internas, comenzando por las del exterior en donde se puede visualizar el pezón y la areola. Internamente la mama posee gran cantidad de tejido adiposo, que la constituye en un 90% dándole forma abultada, además se integran al tejido los conductos galactóforos y la glándula mamaria, encargados ambos de la producción y secreción de leche materna. Las glándulas mamarias se distribuyen por toda la mama, aunque las dos terceras partes del tejido glandular se encuentran en los 30 mm más cercanos a la base del pezón.  

Estas glándulas drenan en el pezón por medio de ductos, cada uno de los cuales tiene su propia apertura o poro. La intrincada red formada por los ductos se ordena de forma radial y converge en el pezón. Sin embargo, los ductos más próximos a este no actúan como reservorios de leche.

La glándula mamaria consta de dos elementos fundamentales: los acinos glandulares, donde se encuentran las células productoras de leche y los ductos, un conjunto de estructuras tubulares y huecas, ramificadas en forma de árbol, cuyas luces confluyen progresivamente en canalículos más y más gruesos hasta terminar en uno de los doce a dieciocho vértices llamados galactóforos. Los galactóforos son dilataciones ductales a modo de reservorios situados inmediatamente por detrás del pezón, formados por un epitelio escamoso no querantinizado.

En la base del conjunto areola-pezón se localizan las células mioepiteliales, con la particularidad de que son capaces de contraerse a la manera de las musculares lisas. Un conjunto de fibras de músculo liso en forma radial, provocan la erección del pezón ante estímulos como succión, roce, tacto y frío, produciendo la salida de la leche almacenada en los galactóforos.

El resto de las mamas está compuesto por tejido conjuntivo -colágeno y elastina-, tejido adiposo (grasa) y una aponeurosis llamada ligamento de Cooper. La proporción de glándula y tejido adiposo parte de 1:1 en mujeres que no están lactando, hasta 2:1 en mujeres lactantes.

Aproximadamente un 75% de la linfa proveniente de las mamas viaja a los ganglios linfáticos de la axila del mismo lado. El resto viaja a los ganglios paraesternales, a la mama del lado opuesto y finalmente hasta los ganglios linfáticos abdominales. Los ganglios axilares incluyen el grupo inferior o pectoral —que drena la parte profunda y transmuscular—, el grupo interno o subescapular —que drena la parte interna de la glándula mamaria— y el grupo externo o humeral —que drena el borde externo de la mama—.El drenaje linfático de las mamas drena en los ganglios linfáticos de la axila.

Este drenaje tiene particular importancia en la oncología, debido a que las mamas son un lugar frecuente de desarrollo de cáncer, si células malignas se desprenden del tejido mamario, podrían dispersarse a otras partes del cuerpo a través del sistema linfático produciendo metástasis. El hecho de que los vasos linfáticos recorran el tejido transmuscular del pectoral mayor es justificativo para la extirpación del mismo en el tratamiento quirúrgico del cáncer de mama —la llamada mastectomía radical de Halsted—.

Las mamas varían en tamaño y forma. Su apariencia externa no predice su anatomía interna o su potencial de lactancia. La forma de la mama depende en gran medida de su soporte, el cual proviene principalmente de los ligamentos de Cooper y del tejido torácico subyacente sobre el cual descansa. Cada mama se adhiere en su base a la pared torácica por una fascia profunda que recubre los músculos pectorales. En la parte superior del pecho recibe cierto soporte de la piel que los recubre. Esa combinación de soporte anatómico es lo que determina la forma de las mamas. En un pequeño grupo de mujeres, los ductos y galactóforos son visibles por no fusionarse con el tejido que los rodea.

La ubicación del pezón en relación al pliegue inframamario define el término ptosis, en el cual la mama cuelga de tal manera sobre el pecho que el pezón sobrepasa el pliegue inframamario. En algunos casos el conjunto pezón-areola puede eventualmente llegar a colgar hasta el nivel del ombligo. La distancia entre el pezón y la base superior del esternón en un seno joven, promedia 21 cm y es una medida antropométrica usada para determinar la simetría mamaria y el ptosis. Las mamas existen en un rango de proporción entre longitud y diámetro de la base, variando de 1:2 hasta 1:1.

Las mamas se ubican sobre el músculo pectoral mayor y por lo general se extienden verticalmente desde el nivel de la segunda costilla, hasta la sexta o séptima. En sentido horizontal, se extiende desde el borde del hueso esternón hasta una línea media, imaginaria, de la axila. A nivel del extremo anterior más distal del tórax, a la altura del tercer espacio intercostal, la piel se especializa para formar la areola y el pezón.

Cada mama limita en su cara posterior con la aponeurosis o fascia del músculo pectoral y contiene abundante tejido graso allí donde no hay tejido glandular. La grasa y el tejido conectivo, junto con los ligamentos de Cooper (que unen la glándula a la piel) constituyen un verdadero ligamento que dan forma y la sostienen, permitiendo el deslizamiento normal del seno sobre los planos musculares subyacentes. La mama, además, contiene vasos arteriales, venosos y linfáticos, así como elementos nerviosos. No existe dentro del seno nada que se parezca a una cápsula continua que envuelva a la mama. De hecho es muy común que exista un tejido llamado aberrante o ectópico (literalmente ‘fuera de sitio’) en zonas bastante alejadas de la mama.

El cuadrante superior lateral (el más alejado del esternón) se extiende diagonalmente en dirección a la axila y se le conoce como la "cola de Spence". Una delgada capa de tejido mamario se extiende desde la clavícula por arriba, hasta la séptima u octava costilla por abajo y desde la línea media hasta el borde del músculo dorsal ancho. No es raro encontrar tejido mamario en pleno hueco de la axila o bajo la piel, en la cara anterior del abdomen.

La circulación sanguínea arterial de las mamas proviene de la arteria torácica interna (antes llamada "arteria mamaria interna"), que deriva de la arteria subclavia; de la arteria torácica lateral, de la arteria toracoacromial (ambas nacen de la arteria axilar) y de las arterias intercostales posteriores. El drenaje venoso de los senos es realizado principalmente por la vena axilar, aunque también pueden participar las venas torácica interna e intercostales. Tanto los hombres como las mujeres tienen una gran concentración de vasos sanguíneos y nervios en los pezones.

En ambos sexos, los pezones tienen capacidad eréctil como respuesta tanto a estímulos sexuales, como al frío. La inervación de las mamas es dada por estímulos de ramas anteriores y laterales de los nervios intercostales cuatro a seis, provenientes de los nervios espinales. El pezón es inervado por la distribución dermatómica del nervio torácico T4.

Embriológicamente el tejido glandular de la mama no es sino el producto del desarrollo desmesurado—desde el punto de vista morfológico y funcional— de glándulas sudoríparas modificadas de la piel, adaptadas para la producción de leche. La leche materna es un tipo de secreción de valor nutricional alto, adecuadamente adaptado a las necesidades de los recién nacidos y única fuente de alimento y anticuerpos durante los primeros meses de vida.

El desarrollo mamario durante la pubertad obedece al estímulo de hormonas ováricas, principalmente estrógeno y progesterona. El estrógeno estimula el desarrollo de la porción excretora de la glándula mamaria —principalmente los galactóforos— y la progesterona es responsable del desarrollo de la porción secretora —los lobulillos—. Estas hormonas impulsan el desarrollo de características femeninas, produciendo el mismo efecto en hombres con desequilibrios hormonales o en aquellos que desean modificar su identidad sexual.

La mama experimenta cambios a lo largo del desarrollo del individuo. Salvo casos particulares, más o menos patológicos, la mama del varón se atrofia por completo, si bien el conjunto areola-pezón nunca desaparece y conserva siempre su sensibilidad particular y la capacidad de fruncimiento de la areola y de erección del pezón ante los estímulos. Los varones sometidos a tratamiento con estrógenos o que abusan de ciertas drogas, pueden desarrollar acúmulos de grasa que toman la forma de mamas (pseudoginecomastia) pudiendo secretar fluidos espontáneamente, aunque sin contenido lácteo. El desarrollo de verdaderas mamas en los hombres, compuestas por glándulas y demás estructuras, se denomina ginecomastia. Los varones obesos también suelen desarrollar una pseudoginecomastia, pero sin los componentes anatómicos femeninos.

En casos aislados existen personas con más de dos glándulas, lo que se conoce como polimastia. Cada mama "de más" se denomina "mama supernumeraria" y tiene una situación anormal, aunque casi siempre se localizará dentro de una línea imaginaria situada a cada lado del cuerpo, desde el vértice de la axila hasta la cara lateral del labio mayor de la vulva (base del escroto en el varón) del mismo lado. La presencia de pezones supernumerarios, de diferentes proporciones y composición, se conoce como politelia.

En los individuos de corta edad, en condiciones normales, la mama permanece en un estado embrionario y no se desarrolla hasta la pubertad. Las niñas típicamente desarrollan las mamas de manera no simultánea, notando la aparición de un botón mamario firme y directamente retroareolar, debajo del centro de la areola, frecuentemente algo excéntrico. Pronto se desarrolla el botón en el otro lado, aunque pueden desarrollarse simultáneamente, y en poco tiempo las dos mamas van adquiriendo su aspecto desarrollado habitual, bajo el estímulo de las hormonas sexuales femeninas. El desarrollo del tejido adiposo y conectivo aumenta bajo la influencia de otras hormonas como la progesterona, prolactina, corticoides y hormona del crecimiento.

Durante el embarazo el aumento en los niveles de estrógenos y progesterona estimula el desarrollo glandular. Las mamas tienden a hacerse esféricas debido al aumento del tejido adiposo.

En este periodo las mamas se vuelven turgentes y aumentan de tamaño. La pigmentación de la piel de la areola y del pezón aumenta muy notablemente y aparecen pequeñas eminencias granulares en los bordes de las areolas conocidas como tubérculos de Morgagni, correspondientes al desarrollo de glándulas sebáceas. La circulación de la mama aumenta y se hacen prominentes las venas superficiales.

La lactancia tiende a mantener los cambios ocurridos durante el embarazo. Al inicio de la misma y durante las primeras horas, los repetidos intentos de succión por parte del neonato acaban por provocar la salida de una secreción espesa y amarillenta, rica en colesterol, llamada calostro.

La producción de leche en las mamas comienza desde antes del parto hecho por el cual durante el parto las mamas o, lo que es lo mismo, los senos mamarios, de las parturientas suelen dilatarse o "hincharse" al producir leche las glándulas mamarias (glándulas que en los senos mamarios o mamas de una mujer una vez superada la nubilidad ocupan junto al tejido adiposo gran parte del volumen de las mamas). Sin embargo, la salida de líquido no se suele producir hasta ese momento, debido a la disminución en las concentraciones de progesterona y la producción de prolactina y oxitocina. A partir de ese momento (en algunas mujeres desde antes) la mama segrega calostro, un líquido espeso con suaves propiedades laxantes (tiene un contenido elevado de cloro, sodio, potasio y proteínas) que facilita la evacuación del meconio del intestino del recién nacido. El calostro es segregado durante tres días, una leche intermedia durante los quince siguientes para dar paso a la leche madura posteriormente.

La leche materna contiene más de 300 componentes, entre los que incluye proporciones elevadas de agua (hasta un 85 %). Aunque podría parecer que esta circunstancia limita el aporte de nutrientes al neonato es importante considerar que una osmolaridad elevada no es fácil de equilibrar por parte del riñón del lactante que, en sus primeros meses, debe extraer el agua que necesite de la leche y sin aportes adicionales. La composición de la leche materna varía de acuerdo a la edad del neonato, el clima y las necesidades específicas del neonato.

En la leche se encuentran numerosos nutrientes, así como proteínas, aminoácidos, vitaminas, y minerales esenciales además de encontrarse una potente de inmunoglobulinas tipo IgA que actúan como anticuerpos proporcionando al neonato una importante protección ante potenciales infecciones. Las fórmulas lácteas elaboradas a partir de leche bovina, carecen de este componente, y aunque recientemente algunos laboratorios tal es el caso de Bayer, indican que la gammaglobulina (o inmunoglobulina) IgA se conserva en microfragmentos dentro de la fórmula, está fútilmente no es provechosa para el ser humano debido a su estructura molecular ligada a ciertos eslabones de aminoácidos que el organismo humano no puede reconocer y que incluso en ciertos individuos se puede rechazar. Esta es una de las razones por las que se recomienda la lactancia materna durante, al menos, el primer año de vida. Incluso la Organización Mundial de la Salud sugiere amamantar seis meses con lactancia exclusiva (solo leche materna, sin agua, tés o fórmulas lácteas bóvinas o caprinas) y continuar lactando por lo menos hasta los dos años complementando con sólidos la alimentación del neonato.

La psiquiatría estudia el modo en que la lactancia materna refuerza de manera particular el vínculo emocional en la relación madre–hijo de una forma tan sólida como primaria, lo que proporciona una satisfacción particular a ambos, desarrollando en el neonato la semblanza de afecto humano. De hecho, algunas madres prolongan la lactancia de su hijo durante dos años o más, aún a pesar de que el niño toma ya una alimentación muy variada y completa. En teoría, la prolongación de la lactancia tiene además otra consecuencia: durante la misma los niveles de prolactina en sangre se mantienen elevados, lo que impide que se produzca una secreción adecuada de hormona foliculoestimulante (FSH) y luteinizante (LH) con lo que se inhibe la ovulación. Este retraso al retorno de la fertilidad ha dado lugar a un método de anticoncepción llamado MELA, que podría servir durante los primeros seis meses de vida del bebé. Sin embargo, la lactancia como tal no es eficaz como método anticonceptivo.

Se puede inducir la lactancia en una mujer que no haya estado embarazada. No se han reportado diferencias nutricionales entre la leche materna inducida o aquella que resulta de un embarazo.

Cualquier operación efectuada en las mamas, incluyendo cirugía estética, conlleva un potencial de interferencia para una futura lactancia, causando alteraciones en la sensibilidad del pezón y dificultades para interpretar una mamografía. Algunos estudios han demostrado una capacidad de lactancia comparable entre mujeres con macromastia (hipertrofia de mama) en comparación con grupos control en las que la operación reducción de senos se realizó usando una moderna técnica quirúrgica llamada "pedículo superior". Algunos organismos de cirugía plástica aconsejan posponer las reducciones electivos de senos en jóvenes adolescentes debido a que el volumen de la mama puede continuar creciendo considerablemente a medida que maduran las jóvenes y aún se desconocen los riesgos a largo plazo de estas intervenciones estéticas. La mayoría de los cirujanos evalúan cada caso individualmente, antes de someter a una paciente joven a una reducción considerable de senos, para corregir hipoplasia o asimetría severa.

Las mamas cumplen un papel fisiológico y cultural en la función sexual femenina y masculina humana. Como zona erógena, es muy importante su participación en las relaciones sexuales. Existen numerosas prácticas sexuales centradas en las mamas (véase, por ejemplo, masturbación con los pechos y fetichismo de senos), en las mujeres la excitación sexual suele manifestarse de un modo vegetativo por tres fenómenos: la erección del clítoris (en la entrada de la vagina), generalmente cierta hinchazón de los senos mamarios que va acompañada por una "erección" o rigidez de los pezones llamada telotismo. En las sociedades occidentales tecnológicamente desarrolladas muchos varones se sienten atraídos, sobre todo, por los senos de gran tamaño. Otros, sin embargo, los prefieren de un tamaño menor aunque turgentes y firmes. En realidad, el tamaño y la forma, así como la consistencia, no predicen en absoluto la capacidad de la mama para producir eficazmente leche. De hecho, gran parte de la mama es tejido adiposo, que, en parte, tiene funciones estructurales y de sostén y que contribuye a proporcionar atractivo sexual a la mujer, pero en absoluto a la lactancia.

La función sexual femenina de la mama, después del diagnóstico y tratamiento del cáncer de mama, no tiende a disminuir o diferir, en especial en mujeres sometidas a cirugías de reconstrucción estética (mamoplastia). Sin embargo, en las mujeres que hayan tenido una mastectomía total se ha notado una disminución en el interés sexual. La quimioterapia tiende a cursar con problemas en la función sexual de la mujer tratada.

El cáncer de mama consiste en la proliferación acelerada e incontrolada de células del epitelio glandular entre los conductos delgados que conectan a modo de ramas de un árbol los racimos de lóbulos y lobulillos que componen la glándula mamaria. Como en otros tumores malignos, estas células se caracterizan por presentar particularidades propias de las células embrionarias: son células diferenciadas que han aumentado enormemente sus capacidades reproductivas y que se han vuelto inmortales, es decir, no pueden envejecer. El diagnóstico del cáncer de mama requiere el examen microscópico de una biopsia del tejido mamario sospechoso. La exploración física, la mamografía y otros exámenes de rutina son eficaces en el diagnóstico temprano de la enfermedad.

Los tipos de cáncer que se desarrollan con más frecuencia son el cáncer ductal, si ocurre en los conductos, y el carcinoma lobular, si ocurre en los lóbulos. El cáncer de mama es raro en los varones. Más del 99 % de los casos ocurre en mujeres.

Varios estudios han demostrado que las mujeres de raza negra, en los Estados Unidos, tienen una mayor mortalidad por cáncer de mama, aunque las mujeres de raza blanca tienen una mayor incidencia. Después de ser diagnosticadas, las mujeres de raza negra tienen menos probabilidad de recibir tratamiento en comparación con mujeres de raza blanca. Otros estudios se han enfocado en estas disparidades, y las teorías giran en torno a una menor accesibilidad a los chequeos precoces, de técnicas de diagnóstico y de tratamiento —médico y quirúrgico— y hasta algunas características biológicas en la población negra estadounidense.

Cerca del 50 % de las mujeres con cáncer ginecológico y de seno, tratadas o no, padecen de disfunción sexual a largo plazo. A menudo, las pacientes tratadas por cáncer sienten que la enfermedad fue producto de su actividad sexual y que nuevas relaciones sexuales podrían contribuir a su reaparición. Aunque son creencias erróneas, son preocupaciones y sentimientos reales que deberían ser compartidos con el profesional de salud. La disminución de la libido y otros problemas sexuales en pacientes con cáncer de mama, son síntomas comunes de depresión y, por lo general, al tratar la depresión, mejora la función sexual de la paciente.
La infección o inflamación del seno se conoce como mastitis y puede ser de causa bacteriana, por parálisis del flujo glandular (ectasia ductal), abscesos, sífilis, por hongos (actinomicosis), etc.

Otras afecciones benignas incluyen el pezón invertido o congénitas como la (polimastia). Quistes (como la enfermedad fibroquística de las mamas) y otros cambios fibróticos, adenomas, fístulas, galactorrea y papilomas son también frecuentes. Cualquier anormalidad en el seno debe ser consultada con un profesional de salud.





</doc>
<doc id="15370" url="https://es.wikipedia.org/wiki?curid=15370" title="Janis Joplin">
Janis Joplin

Janis Lyn Joplin (Port Arthur, Jefferson, Texas; 19 de enero de 1943-Landmark Motor Hotel, Los Ángeles, California; 4 de octubre de 1970) fue una cantante estadounidense de "rock" y "blues" conocida por su poderosa voz y la gran intensidad de su interpretación.Fue una de las estrellas de rock más grandes de su época. Tras publicar tres álbumes, murió de una sobredosis de heroína a la edad de 27 años. Un cuarto álbum, "Pearl", fue publicado en enero de 1971, tres meses después de su muerte. Este álbum alcanzó el número uno en las listas de "Billboard".

En 1967, Joplin saltó a la fama durante una presentación en el Monterey Pop Festival, donde fue la cantante principal de la entonces poco conocida banda de rock psicodélico de San Francisco, Big Brother and The Holding Company. Después de lanzar dos álbumes con la banda, dejó Big Brother para continuar como solista con sus propios grupos de apoyo, primero Kozmic Blues Band y luego Full Tilt Boogie Band. Apareció en el festival de Woodstock y en el recorrido del tren Festival Express. Cinco singles de Joplin fueron a Billboard Hot 100, incluyendo una versión de la canción "Me and Bobby McGee", que alcanzó el número 1 en marzo de 1971. Sus canciones más populares incluyen sus versiones de "Piece of My Heart" (con "Big Brother and The Holding Company"), "Cry Baby", "Down on Me", "Ball 'n' Chain" y "Summertime"; y su canción original "Mercedes Benz", su grabación final.

Janis fue un símbolo femenino de la contracultura de la década de 1960 y la primera mujer en ser considerada una gran estrella del "rock and roll". En 1995 entró en el Salón de la Fama del Rock y en 2004 la revista "Rolling Stone" la colocó en el lugar 46 de los 100 mejores artistas de todos los tiempos; mientras que en 2008 la ubicó en el puesto 28 de los mejores cantantes de todos los tiempos. En 2013 recibió una estrella en el Paseo de la Fama de Hollywood. En 1999, fue elegida como la tercera mejor artista femenina del "rock" en la lista 100 Greatest Women in Rock realizada por VH1. Fue admitida en el Salón de la Fama del Rock and Roll en 1995. Audiencias y críticos por igual se refirieron a su presencia escénica como "eléctrica".

Janis Joplin sigue siendo uno de los músicos más vendidos en los Estados Unidos, contando con certificaciones de la Asociación de la Industria de la Grabación de América por 15,5 millones de álbumes vendidos tan solo en los Estados Unidos.

Nació el 19 de enero de 1943 en Port Arthur, localidad industrial de Texas. Sus padres, Seth (1910-1987), que trabajaba en una refinería, y Dorothy (1913-1998), que había destacado cantando en su instituto, habrían querido que Janis fuera maestra. Tenía dos hermanos menores, Laura (1949) y Michael (1953).

Su familia solía asistir a la Iglesia de Cristo. Los Joplin sentían que Janis siempre necesitaba más atención que el resto de sus hijos. Su madre decía: "Ella era infeliz e insatisfecha. La relación no era la más adecuada". 

En su adolescencia se hizo amiga de un grupo de marginados a través de quienes tuvo acceso a discos de artistas de blues afroamericanos como Bessie Smith, Ma Rainey o Lead Belly, a quienes más tarde Joplin acreditó como influencia en su decisión de convertirse en cantante. Al comenzar a participar en un coro, fue conociendo otros cantantes de "blues" como Odetta, Billie Holiday y Big Mama Thornton. A los dieciséis años comenzó a manifestar su amor por la música, frecuentando los bares de Luisiana, donde escuchaba música afroamericana, de "blues" y "jazz".

Entre sus compañeros de clase estaban GW Bailey y Jimmy Johnson. Joplin se graduó de la preparatoria en 1960 y asistió a Lamar State College of Technology en Beaumont, Texas, durante el verano, y más tarde, en la Universidad de Texas en Austin, aunque no completó sus estudios. (El periódico universitario, "The Daily Texan", publicó un perfil de ella en la edición del 27 de julio de 1962, titulado "Ella se atreve a ser diferente". El artículo comenzó, "Ella va descalza cuando se siente como ella misma, lleva Levi's a clase porque son más cómodos, y lleva su Autoharp con ella dondequiera que va por lo que, en caso de que tuviera el impulso de romper a cantar, le será muy útil. Se llama Janis Joplin".)

Cuando estudiaba Bellas Artes en la Universidad de Texas en Austin, comenzó a cantar de forma habitual en bares. Participaba frecuentemente con la banda Waller Creek Boys. Allí empezó a tener reputación de ser una fuerte bebedora. En 1963 se trasladó a la ciudad de San Francisco. Dejó Texas para ir a San Francisco "sólo para estar lejos de Texas, porque mi cabeza estaba en un lugar muy diferente", dijo en enero de 1963 viviendo en Playa Norte y más tarde Haight-Ashbury. 

Estando allí conoció a muchos músicos con los que más tarde se reencontraría, como su amante Ron "Pigpen" McKernan" (después, miembro de The Grateful Dead), grabando un disco casero con Jorma Kaukonen, futuro guitarrista de Jefferson Airplane y Margareta Kaukonen en la máquina de escribir, utilizada como instrumento de percusión. 

En 1964, Joplin y el futuro guitarrista de Jefferson Airplane, Jorma Kaukonen registraron una serie de estándares de "blues", acompañado además por Margareta Kaukonen en la máquina de escribir (como instrumento de percusión).

Fue en este periodo cuando comenzó a consumir drogas y se sumió, lentamente, en un estado de abandono, llegando a pesar 35 kilos. En 1965 le anunció a su familia que retomaría sus estudios universitarios, y que se casaría con un hombre que había conocido en San Francisco, llamado Peter LeBlanc; sin embargo la pareja no funcionó y Peter LeBlanc la abandonó; esto marcaría aún más su inseguridad afectiva y su sentimiento de soledad.

Cansada de esperar a LeBlanc y de ser una "chica buena", se mudó a San Francisco junto a Chet Helms, un productor que conoció en Texas. Se unió a la banda Big Brother and the Holding Company el 4 de julio de 1966, logrando una combinación perfecta. 

Chet Helms le ofreció que se uniese a la banda de la que era su mánager, y con la que finalmente grabaría su primer álbum, "Big Brother and the Holding Company", que tuvo una importante repercusión. 

Joplin amaba la libertad creativa de la escena musical en San Francisco. Solía actuar junto con otros grupos psicodélicos como The Grateful Dead, Jefferson Airplane y Quicksilver Messenger Service en los famosos salones de baile Avalon Ballroom, Fillmore East y Fillmore West, o con festivales al aire libre en el Golden Gate Park y en Haight-Ashbury.

Actuó con su grupo en el Festival de Monterey de 1967 junto con algunos grandes artistas del momento como Jimi Hendrix, The Mamas and The Papas, Jefferson Airplane, Otis Redding y The Who, entre otros. Como la primera actuación de los Big Brother no había sido filmada, les pidieron que tocasen al día siguiente. Durante esa presentación, interpretaron "Combination Of The Two;" Janis dejó a la audiencia boquiabierta con una versión del emblemático blues de Big Mama Thornton, «Ball And Chain».

A partir de entonces fueron contratados por el productor de Bob Dylan, Albert Grossman. Joplin eclipsaba a los Big Brother. En la primavera de 1968, se trasladaron a Nueva York para grabar su primer disco. Aquella combinación de música repetitiva, de estilo psicodélico de los 60, con la imponente voz de Joplin, era prodigiosa y "Cheap Thrills" salió en agosto de 1968. Lanzando a Joplin al éxito, a los tres días se hizo disco de oro y en el primer mes se vendieron más de un millón de copias. En el 2003, "Cheap Thrills" se colocó en el lugar 338 de los 500 mejores álbumes de todos los tiempos.

Las críticas sobre ella fueron muy buenas, y la prensa empezó a centrarse más en ella que en el grupo, todos le decían que ella era demasiado buena para el grupo, había tensión entre ellos a causa del protagonismo de Janis y la fama, y ella quería hacer un estilo más blues y soul, como las cantantes que veneraba, como Bessie Smith, Billie Holiday o Aretha Franklin, así que después de mucha presión por parte de su mánager, Albert Grossman, se marchó de Big Brother and the Holding Company.

Juntos se pusieron a buscar los mejores músicos del país para crear el nuevo grupo. A principios de 1969 ya estaba creado, aunque los músicos variarían a lo largo del año. Se llevó con ella al guitarrista Sam Andrew de Big Brother and the Holding Company. 

Con su nueva banda, "Kozmic Blues Band", salió su segundo disco, "I Got Dem Ol' Kozmic Blues Again Mama!". El sonido era distinto a lo que sus oyentes estaban acostumbrados: era una mezcla de rock, soul y blues, y recibió malas críticas, la revista "Rolling Stone" la denominó la "Judy Garland del rock".

En abril, Janis y la Kozmic Blues Band fueron de gira por Europa, pasando por Frankfurt, Estocolmo, París, Londres, y algunos lugares más, donde el público la acogió muy calurosamente y ella regresó a EE. UU. muy contenta, diciendo que el mejor concierto que había dado en su vida fue en Londres, donde la audiencia se volvió loca.

En ese año, a causa de la presión se enganchó a la heroína y comenzó a prodigarse en entrevistas, en las que terminaba hablando de su vida y de sus sentimientos. Decía que "hacía el amor con 25 000 personas en el escenario y luego se volvía a casa sola...". Cada vez dependía más del alcohol y de la heroína. Sin embargo, se había convertido en un símbolo de fuerza y de rebeldía para muchas mujeres de su época.

El 16 de agosto de 1969 actuó con enorme éxito en el festival de Woodstock, dónde realizó dos repeticiones de «Ball and Chain» y «Piece of My Heart».

Los músicos de la banda eran sólo profesionales, y Joplin quería que su banda fuese como una familia, como en Big Brother. Con el único que acabó conectando fue con el saxofonista Cornelius "Snooky" Flowers. A finales de 1969 Janis estaba ya destrozada y demasiado enganchada a la heroína y al alcohol, así que decidió tomarse un descanso y 
abandonar la banda. A finales de ese año la banda se separó. Su último concierto fue en el Madison Square Garden en Nueva York en la noche del 19 y 20 de diciembre de 1969.

En febrero de 1970, se fue de viaje con una amiga a Río de Janeiro por carnaval, a desintoxicarse, por lo menos, de la heroína. Allí conoció a David Niehouse y se enamoraron, estuvieron unos meses por la selva de Brasil viajando como dos viejos "beatniks" en la carretera y al volver a San Francisco, David se instaló en casa de Janis.

Albert Grossman, le propuso a Janis una nueva banda, la Full Tilt Boogie Band, y Janis, ya desenganchada de la heroína, pero no del alcohol, aceptó. David Niehouse quería seguir viajando por el mundo y le ofreció que se marcharan juntos, pero ella prefirió quedarse con su audiencia y su música. Así, Joplin congenió muy bien con todos los miembros de la banda, ellos la querían y ella los quería.

En verano de ese año, Janis y su banda participaron en el Festival Express, junto con otros artistas importantes de la época cómo The Grateful Dead, Buddy Guy y The Band. 

En una fiesta de los Hell's Angels de San Francisco, ese mismo verano, conoció a Seth Morgan y se enamoró de él. En septiembre de 1970, se trasladó a Los Ángeles a grabar "Pearl". El 4 de octubre de 1970 había sido un buen día en el estudio, y para celebrarlo salió de copas con sus compañeros y se emborrachó. Según el estudio forense, murió a la 1:40 por sobredosis de heroína. Joplin ya había pasado por experiencias similares y había salido con vida, pero esta vez no había nadie para ayudarla. Su cuerpo fue descubierto unas 18 horas después. Todos quedaron sorprendidos, pues pensaron que Janis ya no consumía, y estaba en la mejor época de su vida. 

En 1971, seis semanas después de su muerte, salió el disco "Pearl"; fue un éxito y se mantuvo en el número uno de ventas durante 14 semanas. Como homenaje, se dejó el tema «Mercedes Benz» a capella, ya que fue la última canción que Janis grabó; también se incluyó la canción «Buried Alive in the Blues» sólo con música, sin la voz de Janis. 

El sencillo «Me and Bobby McGee», compuesto por Kris Kristofferson (con quien la cantante tuvo un romance) y Fred Foster, representó su mayor éxito, al ser la única canción de Janis Joplin en alcanzar el Nº 1 en el Billboard Hot 100, por una semana en marzo de 1971.

En 2003, "Pearl" se colocó en el lugar 122 de los 500 mejores álbumes de todos los tiempos.

Las circunstancias de la muerte de la cantante fueron confusas, y aún hoy en día despiertan diversas hipótesis; el sábado 3 de octubre de 1970, Joplin visitó el estudio de grabación Sunset Sound Recorders en Los Ángeles, para escuchar la parte instrumental de "Buried Alive in the Blues", antes de grabar su pista vocal programada para el día siguiente. En algún momento de ese mismo día, le comunicaron por teléfono que su prometido, Seth Morgan, estaba en su casa jugando al billar con otras mujeres que había conocido ese sábado. En el estudio expresó su enfado por la noticia, y porque la noche anterior no había cumplido con su promesa de ir a visitarla. A pesar de ello, manifestó alegría por el progreso de la grabación. Por la noche, junto con el miembro de la banda Ken Pearson, salieron del estudio hacia el bar Barney's Beanery. Después de la medianoche los llevó a su casa y luego se retiró a su habitación en el Landmark Motor Hotel.

Al día siguiente, el domingo 4 por la tarde, Joplin no apareció en el estudio según lo convenido, por lo que el productor Phil Rothchil comenzó a preocuparse. El administrador y representante de la banda Full Tilt Boogie, John Cooke, decidió visitarla y encontró su automóvil Porsche descapotable en el aparcamiento. Al entrar a la habitación, la encontraron muerta, tirada en el suelo a un lado de su cama. La causa oficial de su muerte fue una sobredosis de heroína, probablemente bajo los efectos del alcohol. Cooke cree que Joplin accidentalmente recibió heroína con una concentración más alta a la normal, debido a la sobredosis de otros adictos en esa semana. 

El episodio habría ocurrido alrededor de la 1:45 p.m. del día 4 de octubre. Se dice que esto le sucedió en otras ocasiones, pero esta vez no hubo nadie que la ayudara. Algunas circunstancias que rodearon su muerte nunca se explicaron, como la pureza extrema que tenía la droga que la mató y que las jeringas usadas no se encontraron; se especuló incluso que pudo haber una persona involucrada. Su amiga Peggy Caserta admitió que, al igual que Seth Morgan, había prometido visitar a Joplin la noche del viernes 2 de octubre, pero se había ido de fiesta con otros consumidores de drogas que estaban alojados en un hotel de Los Ángeles. De acuerdo con su libro "Going Down With Janis", Caserta escuchó del distribuidor que les vendió la heroína a ella y Joplin el sábado, que la artista le expresó su tristeza por dos amigos que la habían abandonado la noche anterior.

La canción "Buried Alive in the Blues" quedó inconclusa con la trágica muerte de la cantante, aunque fue finalmente incluida como un tema instrumental en "Pearl", a manera de un homenaje póstumo. Joplin fue incinerada en la funeraria Pierce Brothers Westwood Village en Los Ángeles. Sus cenizas fueron esparcidas desde un avión en el océano Pacífico a lo largo de Stinson Beach. El único servicio fúnebre tuvo un carácter privado, ya que sólo asistieron los padres de Joplin y su tía materna.

En su testamento, Joplin dejó 2500 dólares para realizar una fiesta en su honor en caso de su desaparición. Alrededor de 200 personas recibieron invitaciones para la fiesta que decía: «Las bebidas son por Pearl», una referencia al apodo de la cantante. El evento, que tuvo lugar el 26 de octubre de 1970, fue en Lion's Share, localizado en San Anselmo, California. Contó con la presencia de su hermana Laura y amigos cercanos de Joplin, como el artista del tatuaje Lyle Tuttle, el prometido de Joplin, Seth Morgan, Bob Gordon, y su mánager de gira John Cooke. Se repartieron brownies mezclados con hachís entre los asistentes.

La vida privada de Janis Joplin siempre fue objeto de polémicas y amplias controversias. Se conoce que desde su adolescencia, tuvo serios problemas de personalidad y autoestima, relacionados con su aspecto físico.

Hay cierta tendencia generalizada a definirla como bisexual, a lo que se sumó su desenfrenado estilo de vida. Aunque, al parecer, tuvo más parejas femeninas que masculinas, Joplin nunca se describió a sí misma como lesbiana o bisexual, sino simplemente "sexual". Su vida sexual incluyó numerosos hombres y mujeres, en lo que se calificaban de "orgías animales". Estos aspectos hicieron que sus propios padres la rechazaran y rehusaran encontrarse con ella, en muchas ocasiones.

Quizás su pareja más estable y conocida fue Peggy Caserta, una amiga, relación que causó su ruptura con el empresario David Niehaus. Caserta afirmó en su libro de 1973, "Going Down With Janis", que ella y Joplin habían decidido separarse mutuamente en abril de 1970, para mantenerse alejadas cada una del uso de las drogas, algo que no consiguieron. Caserta era una ex-azafata de Delta Airlines y dueña de una boutique de ropa en Haight Ashbury. Ambas continuarían con su amistad, unidas por su fuerte adicción a la heroína, hasta la muerte de la cantante.

En sus últimos meses de vida, Janis Joplin estableció una fugaz relación con el estudiante de Berkeley Seth Morgan, joven de 21 años, traficante de heroína y futuro escritor de novelas. Ambos se conocieron en agosto de 1970 en una fiesta en el bar Hell's Angels de San Francisco. Para ese entonces, Joplin residía en el Landmark Motor Hotel en Hollywood Heights, Los Ángeles (lugar donde fue encontrada sin vida dos meses después), sitio en el cual se estableció previo a las sesiones de grabación de "Pearl" en el Sunset Sound Recorders.

Morgan y Joplin incluso anunciaron a inicios de septiembre de 1970 sus planes para casarse. E invitaron a la ceremonia a todos los músicos que participaban en el estudio.

Tras una vida problemática, el 17 de octubre de 1990, Morgan falleció en un accidente de tráfico cuando conducía su motocicleta en compañía de su novia (ambos bajo los efectos del alcohol y la cocaína).

En 1974, Leonard Cohen publicó el álbum "New Skin for the Old Ceremony" incluyendo la canción "Chelsea Hotel #2" donde describe su aventura con Janis Joplin en el Hotel Chelsea de Nueva York.

Big Brother and the Holding Company


Kozmic Blues Band


Full Tilt Boogie









</doc>
<doc id="15373" url="https://es.wikipedia.org/wiki?curid=15373" title="Biofísica">
Biofísica

La biofísica es la ciencia que estudia la biología con los principios y métodos de la física. Al aplicar el carácter probabilístico de la mecánica cuántica a sistemas biológicos, se obtienen métodos puramente físicos para la explicación de propiedades biológicas.

Se discute si la biofísica es una rama de la física, de la biología o de ambas. Se puede decir que el intercambio de conocimientos es únicamente en dirección a la biología, ya que esta se ha ido enriqueciendo de los conceptos físicos y no viceversa. Desde un punto de vista se puede concebir que los conocimientos y enfoques acumulados en la física «pura» se pueden aplicar al estudio de sistemas biológicos. En ese caso la biofísica le aporta conocimientos a la biología, pero no a la física. Sin embargo, la biofísica ofrece a la física evidencia experimental que permite corroborar teorías. Ejemplos en ese sentido son la física de la audición, la biomecánica, los motores moleculares, comunicación molecular, entre otros campos de la biología abordada por la física. La biomecánica, por ejemplo, consiste en la aplicación de conceptos de la dinámica clásica y la mecánica de sólidos deformables al comportamiento cinemático, dinámico y estructural de las diferentes partes del cuerpo.

Se estima que durante los inicios del siglo XXI, la confluencia de físicos, biólogos y químicos a los mismos laboratorios aumentará. Los estudios en neurociencia, por ejemplo, han aumentado y cada vez han tenido mayores frutos desde que se comenzó a implementar las leyes del electromagnetismo, la óptica y la física molecular al estudio de las neuronas.

Otros estudios consideran que existen ramas de la física que se deben desarrollar a profundidad como problemas físicos específicamente relacionados con la materia viviente. Así, por ejemplo, los polímeros biológicos (como las proteínas) no son lo suficientemente grandes como para poderlos tratar como un sistema mecánico, a la vez que no son lo suficientemente pequeños como para tratarlos como moléculas simples en solución. Los cambios energéticos que ocurren durante una reacción química catalizada por una enzima, o fenómenos como el acoplamiento químico-osmótico parecen requerir más de un enfoque físico teórico profundo que de una evaluación biológica.

Entre esos dos extremos aparecen problemas como la generación y propagación del impulso nervioso donde se requiere un pensamiento biológico, más un pensamiento físico así como algo cualitativamente nuevo que aparece con la visión integradora del problema.

Una subdisciplina de la biofísica es la dinámica molecular, que intenta explicar las propiedades químicas de las biomoléculas a través de su estructura y sus propiedades dinámicas y de equilibrio.

La bioacústica es una ciencia multidisciplinaria que combina la biología y la acústica. Usualmente se refiere a la investigación de la producción del sonido, su dispersión a través de un medio y su recepción en animales (incluyendo los humanos). Esto envuelve el énfasis neurofisiológico y anatómico de la producción y detección del sonido y la relación de las señales acústicas con el medio en el que se transmiten. Estos hallazgos han dado evidencia acerca del diseño inteligente de los mecanismos acústicos y de alguna manera de los animales que los utilizan.
En la acústica marina este término también es utilizado para nombrar el efecto de plantas y animales en la propagación del sonido bajo el agua, usualmente se refieren al uso del sonar para la estimación de biomasas

Estudio de movimientos moleculares de proteínas relacionados con su estructura, plegamiento o función.

La transmisión y recepción de información por medio de las moléculas.




</doc>
<doc id="15374" url="https://es.wikipedia.org/wiki?curid=15374" title="Licopeno">
Licopeno

El licopeno del neolatín "lycopersicum" es un caroteno rojo brillante y pigmento carotenoide y fitoquímico que se encuentra en los tomates y otras frutas y verduras de color rojo, como las zanahorias rojas, el pimiento rojo, sandías, y papayas, aunque no en las fresas o cerezas. Aunque el licopeno es químicamente un caroteno, no tiene actividad de vitamina A. Los alimentos que no son de color rojo también pueden contener licopeno, como las habas cafés o el perejil.

En las plantas, algas y otros organismos fotosintéticos, el licopeno es un intermediario importante en la biosíntesis de muchos carotenoides, incluyendo el beta caroteno, que es responsable de la pigmentación amarilla, naranja, o roja, la fotosíntesis, y la foto-protección. Como todos los carotenoides, el licopeno es un hidrocarburo poliinsaturado, es decir, un alqueno no sustituido. Estructuralmente, el licopeno es un tetraterpeno y ensamblado a partir de ocho unidades de isopreno que se componen enteramente de carbono e hidrógeno. Es insoluble en agua. Los once dobles enlaces conjugados del licopeno le dan su color rojo intenso y su actividad antioxidante. Debido a su fuerte color y no toxicidad, el licopeno es un colorante alimentario útil (registrado como E160d) y está aprobado para el uso en los EE.UU., Australia y Nueva Zelanda (registrado como 160d) y la UE.

El licopeno no es un nutriente esencial para los humanos, pero que se encuentra comúnmente en la dieta principalmente de platos preparados a base de tomates. Cuando se absorbe por el intestino, el licopeno se transporta en la sangre por diversas lipoproteínas y se acumula principalmente en la sangre, tejido adiposo, piel, hígado y las glándulas suprarrenales, pero se puede encontrar en la mayoría de los tejidos.

La investigación preliminar ha demostrado que las personas que consumen tomates pueden tener un menor riesgo de cáncer, posiblemente debido a que el licopeno afecta los mecanismos del cáncer de próstata. Sin embargo, esta área de investigación y la relación entre el licopeno y el cáncer de próstata han sido consideradas insuficientes de evidencia para su aprobación de "declaración de propiedades saludables" por la FDA.

El licopeno es uno de los primeros carotenoides que aparecen en la síntesis de este tipo de compuestos, constituyendo la base molecular para la síntesis de los restantes carotenoides. El licopeno es un carotenoide de estructura sencilla con una cadena alifática formada por cuarenta átomos de carbono. El licopeno es un carotenoide altamente lipofílico que se caracteriza por carecer de anillos cíclicos y poseer un gran número de dobles enlaces conjugados. Su obtención por síntesis química aún no está totalmente establecida y, a diferencia de otros carotenoides como el β-caroteno producido a gran escala por síntesis, el licopeno se obtiene fundamentalmente a partir de fuentes naturales, hongos y especialmente de tomates. Sin embargo, los sistemas de extracción son costosos y el licopeno presenta una baja estabilidad, lo que ha limitado su utilización como colorante alimenticio.

En nuestra dieta obtenemos licopeno a partir de alimentos muy definidos, fundamentalmente a través del consumo de tomate y derivados (salsas, tomate frito, tomate triturado, ketchup, pizzas, zumos) y de sandía. En el tomate maduro, el carotenoide mayoritario es el licopeno que lo contiene en aproximadamente en un 83% y en porcentaje también importante, se encuentra el β-caroteno, entre un 3-7%, y otros como son el γ-caroteno, que al igual que el β-caroteno tienen actividad provitamínica A, fitoeno, fitoflueno, etc. El contenido en licopeno aumenta con la maduración de los tomates y puede presentar grandes variaciones según la variedad, condiciones del cultivo como el tipo de suelo y clima, tipo de almacenamiento, etc. La cantidad de licopeno en los tomates de ensalada está alrededor de 3000 µg/100g y en los de "tipo pera" es más de diez veces esa cifra. De forma general, el contenido de licopeno es menor en los tomates cultivados en invernadero, en cualquier estación, que en los tomates producidos al aire libre durante el verano, así como también el contenido de licopeno es menor en frutos que se recolectan verdes y maduran en almacén en comparación con los frutos madurados en la tomatera. 

Actualmente es posible obtener por ingeniería genética, tomates que contienen más de tres veces la cantidad de licopeno que el resto de los tomates. 

La facilidad con la que incorporamos el licopeno a nuestro organismo, es decir, su biodisponibilidad, es diferente según la forma en que lo consumamos, así por ejemplo cuando se toma con aceite se facilita su absorción. Las investigaciones confirman que la absorción intestinal del licopeno es mucho mejor (hasta 2,5 veces más) si se consume cuando se calienta como las salsas que como fruta natural o zumo, debido a que el licopeno se absorbe mejor a través de las grasas y aceites por su liposolubilidad y a que, con temperaturas altas, se rompen las paredes celulares del fruto, que son las que dificultan la absorción del licopeno.
El licopeno se encuentra presente en el organismo humano tanto en sangre en cantidad de 30 µg/dl como en tejidos, distribuyéndose de forma variable. El licopeno es el carotenoide predominante en la composición de los tejidos humanos, concentrándose especialmente en la próstata, lo que podría explicar su fuerte acción preventiva en la aparición de cáncer de próstata.

El licopeno posee propiedades antioxidantes, y actúa protegiendo a las células humanas del estrés oxidativo, producido por la acción de los radicales libres, que son uno de los principales responsables de las enfermedades cardiovasculares, del cáncer y del envejecimiento. Además, actúa modulando las moléculas responsables de la regulación del ciclo celular y produciendo una regresión de ciertas lesiones cancerosas y de próstata.
No se conocen exactamente las bases biológicas ni fisicoquímicas de estas propiedades, pero parecen directamente relacionadas con el elevado poder antioxidante del licopeno, mucho más que otros antioxidantes como la vitamina E o el β-caroteno. Un gran número de procesos cancerígenos y degenerativos están asociados a daños oxidativos sobre el genoma y los mecanismos genéticos de control de la proliferación y diferenciación celular. El licopeno actuaría como un potente neutralizador de radicales libres (óxido y peróxido) atenuando los daños oxidativos sobre los tejidos.

Cada vez existen más estudios epidemiológicos que sugieren que el consumo de licopeno tiene un efecto beneficioso sobre la salud humana, reduciendo notablemente la incidencia de las patologías cancerosas sobre todo, de pulmón, próstata y tracto digestivo, cardiovasculares y del envejecimiento. También existen evidencias científicas de que previene el síndrome de degeneración macular, principal causa de ceguera en la gente mayor de 65 años.

Un estudio realizado por investigadores de la Universidad de Harvard, reveló que el consumo de licopeno redujo en un 45% las posibilidades de desarrollar cáncer de próstata en una población de 48.000 sujetos que tenían en su dieta por lo menos 10 raciones semanales de tomate o subproductos de este. La investigación duró seis años. Otras investigaciones descubrieron que el licopeno también reduce los niveles de colesterol en forma de lipoproteína de baja densidad (LDL), que produce aterosclerosis, por lo que la ingesta de tomates reduce la incidencia de enfermedades cardiovasculares.

Los primeros estudios se centraron en los beneficios que aportaban en la prevención de ciertos cánceres, mostraban que aquellas personas que lo consumían con frecuencia estaban menos expuestas a cánceres que afectaban al sistema digestivo y al reproductor tales como el de colon y de próstata.

Otros posteriores venían a demostrar las propiedades del antienvejecimiento del licopeno. Un ejemplo es el llevado a cabo con un grupo de 90 monjas, en el sur de Italia, con edades comprendidas entre los 77 y los 98 años. Aquellas con índices mayores de licopeno en la sangre tenían una mayor agilidad a la hora de realizar todo tipo de actividades.

Se estima que en España, a partir de frutas y hortalizas frescas, la cantidad de licopeno consumido es de aproximadamente 1,3 mg/persona/día. 

El que haya muchas pruebas que muestran que el licopeno contenido en nuestra dieta es beneficioso para nuestra salud, no quiere decir que si lo ingerimos de forma aislada en forma de pastillas o cápsulas vaya a mejorar nuestra salud o podamos evitar ciertas enfermedades. Todavía habría que realizar muchos estudios antes de poder hacer recomendaciones para consumirlo aisladamente como suplemento dietético. Pero lo que sí se puede recomendar es aumentar su ingesta a partir de las frutas y hortalizas.

No se han descrito problemas de toxicidad ante un aumento en la ingesta dietética de licopeno, salvo en la carotenodermia. Hay que ser un tanto escépticos ante las "prometedoras" perspectivas derivadas de los diferentes tipos de estudios epidemiológicos, ya que hay varios aspectos que necesitan más información, como son: 

Al ser tan común, el uso del licopeno ha sido permitido como colorante alimenticio. Debido a la insolubilidad del licopeno en el agua y a que se encuentra estrechamente ligado a la fibra vegetal, su disponibilidad ha aumentado con el uso de las comidas procesadas. Por ejemplo, el cocinar tomates para guisos o guisados (similar a las salsas de tomate enlatadas) y servirlos en platos ricos en aceites (como salsas para pastas o pizza) incrementa la asimilación del licopeno hacia el torrente sanguíneo.

El licopeno mancha instantáneamente cualquier superficie medianamente porosa, incluyendo la mayoría de los plásticos. Mientras que las manchas de tomate se pueden limpiar con facilidad de las telas (cuando las manchas aún están frescas), los plásticos manchados desafían todos los esfuerzos para quitar el licopeno con agua caliente, jabones o detergentes (aunque los productos blanqueadores lo destruyen). Los plásticos son especialmente susceptibles de ser manchados si son calentados, sufren arañazos, mojados en aceite, o atacados por ácidos (como los encontrados en los tomates).


</doc>
<doc id="15375" url="https://es.wikipedia.org/wiki?curid=15375" title="Historia de los sistemas operativos">
Historia de los sistemas operativos

Un sistema operativo es uno o varios programas que se usan para poder trabajar con los componentes de un equipo de cómputo. Los sistemas operativos proveen un conjunto de funciones necesarias y usadas por diversos programas de aplicaciones de una computadora, y los vínculos necesarios para controlar y sincronizar el hardware de la misma. En las primeras computadoras, que no tenían sistema operativo, cada programa necesitaba la más detallada especificación del hardware para ejecutarse correctamente y desarrollar tareas estándares, y sus propios drivers para los dispositivos periféricos como impresoras y lectores de tarjetas perforadas. El incremento de la complejidad del hardware y los programas de aplicaciones eventualmente hicieron del sistema operativo una necesidad.

Los primeros sistemas operativos fueron desarrollados por cada usuario para el uso de su propia computadora central, y es en 1956 que la General Motors desarrolla lo que es hoy considerado el primer sistema, el GM-NAA I/O, para su IBM 704.

A finales de la década de 1940, apareció lo que se podría considerar de la primera generación de computadoras en el mundo.
Se accedía directamente a la consola de la computadora desde la cual se actuaba sobre una serie de micro interruptores que permitían introducir directamente el programa en la memoria de la computadora.

A principios de los años 1950 con el objetivo de facilitar la interacción entre persona y computadora, los sistemas operativos hacen una aparición discreta y bastante simple, con conceptos tales como el monitor residente y el almacenamiento temporal.

Su funcionamiento era bastante simple, se limitaba a cargar programas a la memoria, leyéndolos de una cinta o de tarjetas perforadas, y ejecutarlos. El problema era encontrar una forma de optimizar el tiempo entre la retirada de un trabajo y el montaje del siguiente.

El primer Sistema Operativo de la historia fue creado en 1956 para un ordenador IBM 704, y básicamente lo único que hacía era comenzar la ejecución de un programa cuando el anterior terminaba.

Su objetivo era disminuir el tiempo de carga de los programas, haciendo simultánea la carga del programa o la salida de datos con la ejecución de la siguiente tarea. Para ello se utilizaban dos técnicas, el "buffering" y el "spooling".

En los años 60 se produjeron cambios notorios en varios campos de la informática, con la aparición del circuito integrado la mayoría orientados a seguir incrementando el potencial de los ordenadores. Para ello se utilizaban técnicas de lo más diversas.

En un sistema "multiprogramado" la memoria principal alberga a más de un programa de usuario. La CPU ejecuta instrucciones de un programa, cuando el que se encuentra en ejecución realiza una operación de E/S; en lugar de esperar a que termine la operación de E/S, se pasa a ejecutar otro programa. Si éste realiza, a su vez, otra operación de E/S, se mandan las órdenes oportunas al controlador, y pasa a ejecutarse otro. De esta forma es posible, teniendo almacenado un conjunto adecuado de tareas en cada momento, utilizar de manera óptima los recursos disponibles.

En este punto tenemos un sistema que hace buen uso de la electrónica disponible, pero adolece la falta de interactividad; para conseguirla debe convertirse en un sistema multiusuario, en el cual existen varios usuarios con un terminal en línea, utilizando el modo de operación de tiempo compartido. En estos sistemas igual que en la multiprogramación. Pero, a diferencia de ésta, cuando un programa lleva cierto tiempo ejecutándose el sistema operativo lo detiene para que se ejecute otra aplicación.

Estos sistemas se usan en entornos donde se deben aceptar y procesar en tiempos muy breves un gran número de sucesos, en su mayoría externos al ordenador. Si el sistema no respeta las restricciones de tiempo en las que las operaciones deben entregar su resultado se dice que ha fallado.
El tiempo de respuesta a su vez debe servir para resolver el problema o hecho planteado. El procesamiento de archivos se hace de una forma continua, pues se procesa el archivo antes de que entre el siguiente, sus primeros usos fueron y siguen siendo en telecomunicaciones.

Diseño que no se encuentran en ordenadores monoprocesador. Estos problemas derivan del hecho de que dos programas pueden ejecutarse simultáneamente y, potencialmente, pueden interferirse entre sí. Concretamente, en lo que se refiere a las lecturas y escrituras en memoria. Existen dos arquitecturas que resuelven estos problemas:

La arquitectura NUMA, donde cada procesador tiene acceso y control exclusivo a una parte de la memoria. 
La arquitectura SMP, donde todos los procesadores comparten toda la memoria. 
Esta última debe lidiar con el problema de la coherencia de caché. Cada microprocesador cuenta con su propia memoria caché local. De manera que cuando un microprocesador escribe en una dirección de memoria, lo hace únicamente sobre su copia local en caché. Si otro microprocesador tiene almacenada la misma dirección de memoria en su caché, resultará que trabaja con una copia obsoleta del dato almacenado.

Además del Atlas Supervisor y el OS/360, los años 1970 marcaron el inicio de UNIX, a mediados de los 60 aparece Multics, sistema operativo multiusuario - multitarea desarrollado por los laboratorios Bell de AT&T y Unix, convirtiéndolo en uno de los pocos SO escritos en un lenguaje de alto nivel. En el campo de la programación lógica se dio a luz la primera implementación de Prolog, y en la revolucionaria orientación a objetos, Smalltalk.

Se trataba de sistemas grandes, complejos y costosos, pues antes no se había construido nada similar y muchos de los proyectos desarrollados terminaron con costos muy por encima del presupuesto y mucho después de lo que se marcaba como fecha de la finalización. Además, aunque formaban una capa entre el hardware y el usuario, éste debía conocer un complejo lenguaje de control para realizar sus trabajos. 
Otro de los inconvenientes es el gran consumo de recursos que ocasionaban, debido a los grandes espacios de memoria principal y secundaria ocupados, así como el tiempo de procesador consumido. Es por esto que se intentó hacer hincapié en mejorar las técnicas ya existentes de multiprogramación y tiempo compartidos


Con la creación de los circuitos LSI (integración a gran escala), chips que contenían miles de transistores en un centímetro cuadrado de silicio, empezó el auge de los ordenadores personales. En éstos se dejó un poco de lado el rendimiento y se buscó más que el sistema operativo fuera amigable, surgiendo menús, e interfaces gráficas. Esto reducía la rapidez de las aplicaciones, pero se volvían más prácticos y simples para los usuarios. En esta época, siguieron utilizándose lenguajes ya existentes, como Smalltalk o C, y nacieron otros nuevos, de los cuales se podrían destacar: C++ y Eiffel dentro del paradigma de la orientación a objetos, y Haskell y Miranda en el campo de la programación declarativa.
Un avance importante que se estableció a mediados de la década de 1980 fue el desarrollo de redes de computadoras personales que corrían sistemas operativos en red y sistemas operativos distribuidos.
En esta escena, dos sistemas operativos eran los mayoritarios: MS-DOS (Micro Soft Disk Operating System), escrito por Microsoft para IBM PC y otras computadoras que utilizaban la CPU Intel 8088 y sus sucesores, y UNIX, que dominaba en los ordenadores personales que hacían uso del Motorola 68000.

SunOS fue la versión del sistema operativo derivado de Unix y BSD desarrollado por Sun Microsystems para sus estaciones de trabajo y servidores hasta el principio de los años 1990. Ésta estaba basada en los UNIX BSD con algunos añadidos de los System V UNIX en versiones posteriores.

SunOS 1.0 estaba basada básicamente en BSD 4.1 y se publicó en 1982. SunOS 2.0, que salió en 1985, usaba BSD 4.2 como una base e introducía una capa de sistema de ficheros virtual (VFS) y el protocolo NFS. SunOS 3.0 coincidía con el lanzamiento de la serie Sun-3 en 1986 e incorporaba varias utilidades de System V. SunOS 4.0, que salió en 1989, migró a la base de BSD 4.3, introdujo un nuevo sistema de memoria virtual, enlazamiento dinámico y una implementación de la arquitectura System V STREAMS I/O.

SunOS 5.0 y las versiones posteriores están basadas en UNIX System V Release 4.

En 1981 Microsoft compró un sistema operativo llamado QDOS que, tras realizar unas pocas modificaciones, se convirtió en la primera versión de MS-DOS (Micro Soft Disk Operating System). A partir de aquí se sucedieron una serie de cambios hasta llegar a la versión 7.1, versión 8 en Windows Milenium, a partir de la cual MS-DOS dejó de existir como un componente del Sistema Operativo.

En 1983, con la aparición de los ordenadores MSX, se realizó una adaptación para este sistema que utilizaba el procesador Z-80 llamada MSX-DOS. Era un cruce entre la versión MS-DOS 1.25 y CP/M. En 1988, una vez que Microsoft se desvinculó de proyecto, ASCII Corporation publicó la versión MSX-DOS 2.0 que añadió, entre otras cosas, soporte para el uso de directorios.

El lanzamiento oficial del ordenador Macintosh en enero de 1984, al precio de US $1,995 (después cambiado a $2,495 dólares). Incluía su sistema operativo Mac OS cuya características novedosas era una GUI (Graphic User Interface), Multitareas y Mouse. Provocó diferentes reacciones entre los usuarios acostumbrados a la línea de comandos y algunos tachando el uso del Mouse como "juguete".

AmigaOS es el nombre que recibe el conjunto de la familia de gestores de ventanas y ROMs que incluían por defecto los ordenadores personales Commodore Amiga como sistema operativo. Fue desarrollado originalmente por Commodore International, e inicialmente presentado en 1985 junto con el Amiga 1000.

OS/2 es un sistema operativo de IBM que intentó suceder a DOS como sistema operativo de las computadoras personales. Se desarrolló inicialmente de manera conjunta entre Microsoft e IBM, hasta que la primera decidió seguir su camino con su Windows e IBM se ocupó en solitario de OS/2.

OS/2 ya no es comercializado por IBM, y el soporte estándar de IBM para OS / 2 se suspendió el 31 de diciembre de 2006. Se ha mantenido desde entonces con relativamente pocas nuevas características bajo el nombre eComStation.

BeOS es un sistema operativo para PC desarrollado por Be Incorporated en 1990, orientado principalmente a proveer alto rendimiento en aplicaciones multimedia. A pesar de la creencia común fomentada por la inclusión de la interfaz de comandos Bash en el sistema operativo, el diseño de BeOS no estaba basado en UNIX.

Originalmente (1995-1996) el sistema operativo se corría sobre su propio hardware, conocido como BeBox. Más tarde (1997) fue extendido a la plataforma PowerPC y finalmente (1998) se añadió compatibilidad con procesadores x86.

Este sistema al parecer es una versión mejorada de Unix, basado en el estándar POSIX, un sistema que en principio trabajaba en modo comandos. Hoy en día dispone de Ventanas, gracias a un servidor gráfico y a gestores de ventanas como GNOME, KDE entre muchos. Recientemente GNU/Linux dispone de un aplicativo que convierte las ventanas en un entorno 3D como por ejemplo Beryl o Compiz. Lo que permite utilizar Linux de una forma visual atractiva.

Existen muchas distribuciones actuales de Gnu/Linux (Debian, Fedora, Ubuntu, Slackware, etc.) donde todas ellas tienen en común que ocupan el mismo núcleo Linux. Dentro de las cualidades de Gnu/Linux se puede caracterizar el hecho de que la navegación a través de la web es sin riegos de ser afectada por virus, esto debido al sistema de permisos implementado, el cual no deja correr ninguna aplicación sin los permisos necesarios, permisos que son otorgados por el usuario. A todo esto se suma que los virus que vienen en dispositivos desmontables tampoco afectan al sistema, debido al mismo sistema de permisos.

Solaris es un sistema operativo de tipo Unix desarrollado desde 1992 inicialmente por Sun Microsystems y actualmente por Oracle Corporation como sucesor de SunOS. Es un sistema certificado oficialmente como versión de Unix. Funciona en arquitecturas SPARC y x86 para servidores y estaciones de trabajo.

Windows NT es una familia de sistemas operativos producidos por Microsoft, de la cual la primera versión fue publicada en julio de 1993.

Previamente a la aparición del famoso Windows 95 la empresa Microsoft concibió una nueva línea de sistemas operativos orientados a estaciones de trabajo y servidor de red. Un sistema operativo con interfaz gráfica propia, estable y con características similares a los sistemas de red UNIX. Las letras NT provienen de la designación del producto como "Tecnología Nueva" ("New Technology").

Las versiones publicadas de este sistema son: 3.1, 3.5, 3.51 y 4.0. Además, Windows NT se distribuía en dos versiones, dependiendo de la utilidad que se le fuera a dar: Workstation para ser utilizado como estación de trabajo y Server para ser utilizado como servidor.

FreeBSD es un sistema operativo multiusuario, capaz de efectuar multitarea con apropiación y multiproceso en plataformas compatibles con múltiples procesadores; el funcionamiento de FreeBSD está inspirado en la variante 4.4 BSD-Lite de UNIX. Aunque FreeBSD no puede ser propiamente llamado UNIX, al no haber adquirido la debida licencia de The Open Group, FreeBSD sí está hecho para ser compatible con la norma POSIX, al igual que varios otros sistemas "clones de UNIX". 

El sistema FreeBSD incluye el núcleo, la estructura de ficheros del sistema, bibliotecas de la API de C, y algunas utilidades básicas. La versión 6.1 
trajo importantes mejoras como mayor apoyo para dispositivos Bluetooth y controladores para tarjetas de sonido y red.

La versión 7.0, lanzada el 27 de febrero de 2008, incluye compatibilidad con el sistema de archivos ZFS de Sun y a la arquitectura ARM, entre otras novedades.

La distribución más notable es PC-BSD.

Windows es el nombre de una familia de sistemas operativos desarrollados y vendidos por Microsoft basado en MS-DOS. Windows nunca fue realmente un Sistema Operativo con verdadero entorno gráfico hasta Windows 95. Hasta la versión 3.11 Windows fue un entorno de escritorio para MS-DOS. 

Windows 95 es un sistema operativo con interfaz gráfica de usuario híbrido de entre 16 y 32 bits. Fue lanzado al mercado el 24 de agosto de 1995 por la empresa de software Microsoft con notable éxito de ventas. Durante su desarrollo se conoció como Windows 4 o por el nombre clave Chicago. Esta serie de Windows terminó con Windows Me.

ReactOS (React Operating System) es un sistema operativo de código abierto destinado a lograr la compatibilidad binaria con aplicaciones de software y controladores de dispositivos hechos para Microsoft Windows NT versiones 5.x en adelante (Windows XP y sus sucesores).

En 1996 un grupo de programadores y desarrolladores de software libre comenzaron un proyecto llamado FreeWin95 el cual consistía en implementar un clon de Windows 95. El proyecto estuvo bajo discusión por el diseño del sistema ya habiendo desarrollado la capa compatible con MS-DOS, pero lamentablemente esta fue una situación que no se completó. Para 1997 el proyecto no había lanzado ninguna versión, por lo que los miembros de éste, coordinados por Jason Filby, pudieron revivirlo. Se decidió cambiar el núcleo del sistema compatible con MS-DOS y de ahora en adelante basarlo en uno compatible con Windows NT, y así el proyecto pudo seguir adelante con el nombre actual de ReactOS, que comenzó en febrero de 1998, desarrollando las bases del kernel y algunos drivers básicos.

FreeDOS es un proyecto que aspira a crear un sistema operativo libre que sea totalmente compatible con las aplicaciones y los controladores de MS-DOS.

El programa ya ha alcanzado un alto grado de madurez y tiene algunas características que no existían en MS-DOS. Algunos comandos de FreeDOS son idénticos o mejores que sus equivalentes de MS-DOS, pero aún faltan algunos del sistema operativo original.

El intérprete de línea de comandos usado por FreeDOS se llama FreeCOM.

SymbOS es un sistema operativo desarrollado originalmente en 2001 para los ordenadores Amstrad CPC. Se trata de un sistema operativo gráfico con una estética e interfaz similar a Windows 95. A pesar de la baja potencia que desarrollan estos ordenadores, alrededor de 4MHz, está minuciosamente optimizado para el hardware en el cual funciona, por lo que el rendimiento es más que aceptable.

Debido a su cuidada programación modular, ha sido migrado posteriormente a los ordenadores MSX, Amstrad PCW y Enterprise 128 que, con versiones adaptadas y recompiladas en cada caso, son capaces de ejecutar las mismas aplicaciones sin modificación alguna.

Aunque parezca un sistema obsoleto, existe una extensa comunidad implicada en el proyecto. Los programadores originales continúan actualizando y dando soporte al sistema en la actualidad.

SymbOS es un claro ejemplo de software optimizado, de tal manera que con un mínimo hardware se obtienen prestaciones similares a otros grandes sistemas operativos actuales. Esto lo convierte en el antagonista de los modernos sistemas operativos, que derrochan la mayor parte de los recursos apoyándose en la alta potencia del hardware actual.

MorphOS es un sistema operativo, en parte propietario y en parte de código abierto, producido para ordenadores basados en los procesadores PowerPC (PPC). El sistema operativo en sí es propietario, pero muchas de sus bibliotecas y otros componentes son de código abierto, como Ambient (la interfaz del escritorio). La mariposa azul es el logo característico de este sistema operativo. Está basado en el Micronúcleo de Quark.

Darwin es el sistema que subyace en Mac OS X, cuya primera versión final salió en el año 2001 para funcionar en computadoras Macintosh. 

Integra el micronúcleo XNU y servicios de sistema operativo de tipo UNIX basados en BSD 4.4 (en particular FreeBSD) que proporcionan una estabilidad y un rendimiento mayor que el de versiones anteriores de Mac OS. Se trata de una evolución del sistema operativo NEXTSTEP (basado en Mach 2.5 y código BSD 4.3) desarrollado por NeXT en 1989 comprado por Apple Computer en diciembre de 1996.

Darwin proporciona al Mac OS X prestaciones modernas, como la memoria protegida, la multitarea por desalojo o expulsiva, la gestión avanzada de memoria y el multiproceso simétrico.

mac OS, antes llamado Mac OS X, es un sistema operativo basado en Unix, desarrollado, comercializado y vendido por Apple Inc. 

La primera versión del sistema fue Mac OS X Server 1.0 en 1999, y en cuanto al escritorio, fue Mac OS X v10.0 «Cheetah» (publicada el 24 de marzo de 2001).

La variante para servidores, Mac OS X Server, es arquitectónicamente idéntica a su contraparte para escritorio, además de incluir herramientas para administrar grupos de trabajo y proveer acceso a los servicios de red. Estas herramientas incluyen un servidor de correo, un servidor Samba, un servidor LDAP y un servidor de dominio entre otros.

Haiku es un sistema operativo de código abierto actualmente en desarrollo que se centra específicamente en la informática personal y multimedia. Inspirado por BeOS (Be Operating System), Haiku aspira a convertirse en un sistema rápido, eficiente, fácil de usar y fácil de aprender, sin descuidar su potencia para los usuarios de todos los niveles.

OpenSolaris fue un sistema operativo libre publicado en 2005 a partir de la versión privativa de Solaris de Sun Microsystems, ahora parte de Oracle Corporation. OpenSolaris es también el nombre de un proyecto iniciado en 2005 por Sun para construir y desarrollar una comunidad de usuarios alrededor de las tecnologías del sistema operativo del mismo nombre. Después de la adquisición de Sun Microsystems, en agosto de 2010, Oracle decidió interrumpir la publicación y distribución de OpenSolaris, así como su modelo de desarrollo, basado en la disponibilidad de versiones de desarrollo compiladas cada dos semanas y versiones estables cada seis meses. Sin embargo, los términos de su licencia libre no han sido modificados, por lo que el código fuente afectado por ella será publicado cuando Oracle publique nuevas versiones de Solaris.

Illumos es un proyecto de software libre derivado de OpenSolaris. Fue anunciado por conferencia web desde Nueva York el 3 de agosto de 2010. El nombre del proyecto es un neologismo procedente del latín "Illum" (la luz) y de "OS" (operating system, sistema operativo).

Se trata del código base a partir del cual cualquiera podrá crear su propia distribución de software basada en el sistema operativo OpenSolaris. Pero Illumos no es una distribución, ni una bifurcación (fork), al menos por el momento, en la medida que no pretende separarse del tronco principal, sino un derivado de la "consolidación" OS/Net (más conocida como ON), que consiste básicamente en el código fuente del kernel (SunOS), los drivers, los servicios de red, las bibliotecas del sistema y los comandos básicos del sistema operativo.

OpenIndiana es un sistema operativo tipo Unix liberado como software libre y de código abierto. Es una bifurcación de OpenSolaris concebida después de la compra de Sun Microsystems por parte de Oracle y tiene como objetivo continuar con el desarrollo y la distribución del código base de OpenSolaris. El proyecto opera bajo el patrocinio de la Illumos Foundation (Fundación Illumos). El objetivo declarado del proyecto es convertirse en la distribución de OpenSolaris de facto instalada en servidores de producción donde se requieren soluciones de seguridad y errores de forma gratuita.


</doc>
<doc id="15377" url="https://es.wikipedia.org/wiki?curid=15377" title="El Teniente Blueberry">
El Teniente Blueberry

El Teniente Blueberry (o simplemente Blueberry) es una serie francesa de historietas del oeste iniciada en por el guionista Jean-Michel Charlier y el dibujante Jean Giraud para la revista "Pilote" que narra las aventuras del Teniente de Caballería Mike Steve Donovan, alias ""Blueberry"". En 1981, los mismos autores crearon un segundo personaje cuyas aventuras transcurren en el lejano oeste estadounidense: "Jim Cutlass".

Jijé iba a ser el dibujante de la serie, pero propuso a Giraud, que era su alumno. Jijé hizo la portada de Fort Navajo (está firmada por él) y sustituyó a Giraud en Tormenta en el oeste un puñado de páginas, mientras Giraud viajaba a México para convertirse en Moebius. Suyas son desde el momento en que Blueberry escapa de los indios en el cañón hasta que vuelve a Fort Navajo y encuentra a Crowe en la muralla: toda la parte de los cactus, los mexicanos y Tucson. Luego volvió a sustituir a Gir en El jinete perdido, que es casi todo suyo.

En España, estas historietas también fueron publicadas en revistas como Bravo, Gran Pulgarcito o Mortadelo de Editorial Bruguera.

Fallecido Jean-Michel Charlier, Giraud se hizo cargo de la serie, aunque el primero de sus guiones, una mezcla de western y fantástico titulada "Blueberry 1900", fuera rechazada por el hijo del guionista belga.

En 1861 Mike Donovan, hijo de un hacendado sudista de Georgia, es acusado de asesinar al padre de su prometida, Harriet Tucker. Perseguido por el auténtico asesino, un esclavo huido le ayuda a pasar a las líneas nordistas en el preciso momento de estallar la Guerra de Secesión. Adopta el nombre de Mike S. Blueberry y pasa a ser corneta del regimiento de caballería. Pendenciero, aficionado al juego, al alcohol y a las mujeres, es un militar íntegro, audaz y con sentido de la estrategia que asciende hasta ser nombrado Teniente al final de la Guerra de Secesión.

Las aventuras del Teniente le llevan a conocer y salvar la vida del General nordista Dodge durante la guerra. Éste le devolverá el favor más tarde, intercediendo por Blueberry ante el presidente Ulisses S. Grant. Blueberry vivirá un tiempo entre los apaches donde se le conoce como Tsi-Na-Pah (Nariz Rota) y llegará a contar con la amistad del Gran Jefe Cochise y el amor de su hija, Chini. Así mismo, conoce y se enfrenta al mayor Chamán de Guerra apache, Gokhlayeh, más tarde conocido como Gerónimo, en una aventura que le lleva a Tombstone donde coincide con Wyatt Earp y Doc Holliday durante los acontecimientos del OK Corral.

Entre los personajes femeninos que aparecen en las aventuras de Blueberry, hay una que es la única que le obsesiona: la cabaretera conocida como Chihuahua Pearl (también conocida como Lilly Calloway en otros tomos).

Para el propio Jean Giraud, la serie ha sido muy importante, ya que, como él mismo afirma,

Hasta ahora las aventuras de Blueberry nos han sido contadas en tres series de álbumes:

El ejemplar de Apaches se marca como nº0 porque cronológicamente se sitúa entre la Juventud de Blueberry y el primer libro del Teniente Blueberry: Fort Navajo

En 2004 se realizó una adaptación de la historieta al cine ("Blueberry. La experiencia secreta") de la mano de Jan Kounen que cosechó poco éxito de crítica y público y fue protagonizada por Vincent Cassel (Mike S. Blueberry), Juliette Lewis (Maria Sullivan) y Michael Madsen (Wallace Sebastian Blount). Colaboró Carlo de Boutiny.



</doc>
<doc id="15378" url="https://es.wikipedia.org/wiki?curid=15378" title="Economía de Andorra">
Economía de Andorra

El turismo es el principal componente de la economía de Andorra. Atractivo para los compradores de España y Francia por su condición de zona franca, el país ha desarrollado un importante complejo turístico muy activo en la temporada de invierno (gracias a los campos de esquí) y, en menor medida, en verano. En el año 2005, el país acogió a 11.049.490 visitantes. 

Andorra tiene un comercio muy activo en bienes de consumo, especialmente de productos manufacturados de importación, los cuales, al ser libres de impuestos ("duty-free") son más baratos en Andorra que en España o Francia. Como consecuencia, el contrabando es una práctica corriente. El estatus de zona franca de Andorra también ha creado una controversia con respecto a su relación con la Unión Europea. Las negociaciones sobre este tema empezaron en 1987, poco después de la incorporación de España a la UE. Un acuerdo de 1991 puso cuotas para el "duty-free" y puso límites en algunos productos (principalmente tabaco y bebidas alcohólicas). Aun así, a Andorra se le permite mantener diferencias de precio con los países de la UE, lo que es un atractivo para los visitantes.:v

Aunque menos del 2% de la tierra es cultivable, la agricultura, conjuntamente con la ganadería, eran los principales soportes de la economía andorrana hasta el surgimiento del turismo. La ganadería ovina ha sido tradicionalmente la principal actividad económica, pero las plantaciones de tabaco son más lucrativas y es a lo que está destinada ahora la mayor parte de la superficie cultivada del país. La práctica totalidad de la comida de Andorra es importada.

Aparte de la artesanía, se fabrica cigarros, cigarrillos y muebles para mercados domésticos y de exportación. Una planta hidroeléctrica en Les Escaldes, con una capacidad de 15 megawattios, provee el 15% de la electricidad de Andorra; el resto de la electricidad consumida proviene de España y Francia.

Desde el 1 de enero de 2002 se utiliza el euro como moneda oficial. Los presupuestos se elaboraban en pesetas antes de la desaparición de la moneda española.

Los servicios representan el 80% del PIB de Andorra. En el año 2005, el país recibió a 11.049.490 visitantes, de los cuales 2.418.409 eran turistas y 8.631.081 excursionistas. El 57,2% de los visitantes eran españoles, el 39,8% eran franceses, y sólo un 3,0% venían de otros países.

Con unos 270 hoteles, 400 restaurantes y numerosos comercios, el turismo emplea a una gran porción de la fuerza laboral.


PIB (Producto Interior Bruto)

PIB "per capita"

Distribución del PIB por sectores

Crecimiento PIB estimado

Tasa de inflación

Importaciones

Exportaciones

Saldo (Exportaciones-Importaciones)

Población ocupada

Población ocupada por sectores

(Datos del gobierno andorrano del año 2000) 

Población bajo el umbral de la pobreza

Se presentan a continuación las mercancías de mayor peso en las importaciones de Andorra para el período 2010-2014. Las cifras están expresadas en dólares estadounidenses valor FOB.

Se presentan a continuación los principales socios comerciales de Andorra para el periodo 2010-2014.La mayoría de sus importadores están en América y Europa. Las cifras expresadas son en dólares estadounidenses valor FOB.


</doc>
<doc id="15380" url="https://es.wikipedia.org/wiki?curid=15380" title="El final de la etapa apostólica">
El final de la etapa apostólica

Hacia el año 62, el sumo sacerdote del judaísmo, Ananías, hizo apadrear al apóstol Santiago (llamado hermano de Jesús), que regía la iglesia de Jerusalén. Uno de sus hermanos, Simón, fue llamado a sucederle, pero la situación política y el nacionalismo judío llevaron pronto a Simón a la muerte, ante esta situación el consejo de ancianos (presbíteros) u obispos de la iglesia de Jerusalén trasladaron la iglesia a la ciudad de Pela, pero la situación política de Palestina se agravaba y los conflictos internos del hebraísmo eran cada día mayores. En el año 70 los romanos atacaron a Jerusalén y destruyeron el templo. Prontamente en manos de los romanos los grupos judíos de los saduceos, zelotes y esenios serían exterminados; de todos sólo el de los fariseos sobrevivió. Esa fue la razón de la división del judaísmo y el cristianismo. De los apóstoles vivía tan sólo Juan el evangelista, que se había trasladado a Éfeso, iglesia madre de muchas de Asia Menor y Gracia, donde se manifestaban brotes gnósticos. Durante los obispados de Lino y Anacleto en la iglesia de Roma, Roma fue ganando importancia en el cristianismo, por ser la capital del imperio y por ser el lugar de muerte de los apóstoles Pedro y Pablo. Para el obispado de Clemente, Roma se convirtió en la sede del cristianismo.

Con el emperador Vespasiano, el cristianismo siguió extendiéndose, hasta que, en el año 90, Domiciano inició una nueva persecución. Juan fue llevado primero a Roma y desterrado luego a la isla de Patmos, donde escribió el "Apocalipsis" y algunas de sus cartas. Bajo el imperio de Nerva, de quien dice su biógrafo Xifilino que "no permitió que se acusase a nadie por haber observado las ceremonias de la religión judaica o haber descuidado el culto de los dioses, pudo regresar Juan a Éfeso, y pocos años después falleció, a edad muy avanzada. Con su muerte concluye la etapa apostólica. 

Algunas características de esta etapa: 
Al concluir el siglo I, el cristianismo se ha extendido por la cuenca del Mediterráneo, cuenta con los libros religiosos básicos y las distintas comunidades urbanas se sienten unidas. Surge entonces el gnosticismo. Algunos autores han considerado fundador a Simón el Mago (a quien se refieren los Hechos de los Apóstoles. Doctrina filosófico-religiosa de los primeros siglos de la Iglesia, mezcla de la cristiana con creencias orientales y judaicas, que pretendía tener un conocimiento intuitivo y misterioso de las cosas divinas. Doctrina sincretista en su fondo, el gnosticismo advertía la oposición existente entre el mundo material (malo) y el espiritual (bueno). La materia era obra de un demiurgo (dios inferior o de los ángeles, y esto les llevó a considerar que el cuerpo de Jesucristo no podía ser materia (pues no podía ser malo). La salvación para el gnóstico dependía del conocimiento personal, era fruto de su ciencia. 

En el siglo II, ciertas ideas gnósticas, la trascendencia de las cuales queda implícita tras su simple enunciación, influyeron en varios sectores cristianos y tendieron a la racionalización de la fe. Apuntaba el peligro de las primeras creencias consideradas herejía, del mismo modo que habían empezado las persecuciones. 




</doc>
<doc id="15381" url="https://es.wikipedia.org/wiki?curid=15381" title="Persecución a los cristianos">
Persecución a los cristianos

Numerosos cristianos han sufrido persecuciones por parte de no cristianos e incluso de otros cristianos de creencias diversas o más o menos estrictas durante la historia del cristianismo. 

Tales persecuciones tienen o tuvieron varios grados de intensidad, desde el arresto sin garantías, la mengua de derechos públicos, el encarcelamiento, el azotamiento y la tortura, hasta la ejecución, llamada martirio, pasando por el pago de un impuesto suplementario —como el caso de los mozárabes—, la confiscación de sus bienes o incluso la destrucción de sus propiedades, su arte, sus libros y sus símbolos o la incitación a abjurar de sus principios y delatar a otros cristianos.

En el "Nuevo Testamento" se lee que los primeros cristianos, comenzando por el propio Jesús, sufrieron persecución a manos de los jefes judíos de esa época. También relata el principio de persecuciones por los romanos. El término «los cristianos» es usado con frecuencia en una forma indiscriminada que ha sido causa de controversia.

Según el "Nuevo Testamento", la persecución de los primeros cristianos continuó después de la muerte de Jesús. Pedro y Juan fueron encarcelados por los jefes judíos, incluido el sumo sacerdote Ananías, quien no obstante los liberó más tarde (Hechos 4:1-21). En otro momento, todos los apóstoles fueron encarcelados por el sumo sacerdote y otros saduceos, pero fueron liberados por un ángel (Hechos 5:17-18). Los apóstoles, tras haber escapado, fueron llevados nuevamente ante el Sanedrín, pero esta vez Gamaliel, un rabino fariseo bien conocido de la literatura rabínica, convenció al Sanedrín de liberarlos (Hechos 5:27-40).

La razón más probable de la persecución fue, por parte de los judíos, la evidente herejía que representaba la doctrina cristiana desde un punto de vista de la doctrina tradicional judía, ya que entre otras cosas, la idea de un Dios-Hombre chocaba de frente con su arraigado monoteísmo (esto se percibe claramente en la narración bíblica de los hechos de los primeros cristianos). Es deducible además que a oídos romanos, la predicación de los cristianos sobre el inminente regreso del rey de los judíos y el establecimiento de su reino, era sediciosa. Los romanos dieron a los judíos en ese tiempo un autogobierno limitado; las principales obligaciones de los líderes judíos eran recolectar impuestos para Roma y mantener el orden civil. Así, los líderes judíos tendrían que suprimir cualquier tesis sediciosa, como las que defendían los cristianos. Esta oposición judía fue un potente motor para plantar en Roma la semilla del odio al incipiente cristianismo.

El "Nuevo Testamento" relata la lapidación de Esteban (Hechos 6:8-7:60) por miembros del Sanedrín. Esteban es recordado en el cristianismo como el primer mártir (del griego: "mártÿros", ‘testigo’).

La ejecución de Esteban fue seguida de una gran persecución de cristianos (Hechos 8:1-3), dirigida por un fariseo llamado Saulo Pablo de Tarso, enviando a muchos cristianos a prisión. Según el "Nuevo Testamento", esta persecución continuó hasta que Saulo se convirtió al cristianismo (y cambió su nombre a Pablo), tras decir que había visto una luz brillante y oído la voz de Jesús en el camino hacia Damasco, donde estaba viajando para encarcelar a más cristianos (Hechos 9:1-22).

Hechos 9:23-25 dice que «los judíos» en Damasco trataron entonces de matar a Pablo. Estaban esperándole en las puertas del pueblo, pero los evadió al ser bajado sobre el muro de la ciudad en una canasta por otros cristianos y luego escapó hacia Jerusalén. Comprensiblemente, tuvo dificultad al principio para convencer a los cristianos de Jerusalén que él, su antiguo perseguidor, se había convertido y de que ahora estaba siendo perseguido a su vez (Hechos 9:26-27). Otro atentado se hizo contra su vida, esta vez por «los grecianos» (KJV), refiriéndose a un grupo de judíos helenistas (Hechos 9:29), a quienes él debatió mientras estaban dentro y alrededor de Jerusalén.

Al principio, los romanos consideraron el cristianismo como una nueva secta judía. Aparte de las esporádicas persecuciones de Nerón y Domiciano, durante el siglo I los cristianos tuvieron que enfrentarse con mayor frecuencia con la animadversión de los escribas y fariseos, rectores del judaísmo, que con las autoridades romanas. 

Sobre la base de diversos testimonios se afirma que durante la segunda mitad del siglo I, todo el siglo II y hasta el siglo IV, los cristianos fueron también perseguidos por autoridades del Imperio romano, que consideraba a los cristianos, ya sea como judíos sediciosos (recordando que en el año 70 los judíos armaron una revuelta en Judea que originó la destrucción de Jerusalén y la deportación de los judíos de su territorio a manos romanas), o como rebeldes políticos. El historiador Suetonio menciona las revueltas causadas en Roma en tiempo del emperador Claudio «por un tal Cresto», a quien cabe identificar con Cristo, cuyas doctrinas debían haber sido divulgadas por emigrantes o esclavos judíos en Roma. Asimismo, Tácito en sus "Anales" habla de la persecución a los cristianos («nombre que toman de un tal Cristo»), por parte de Nerón. En cuanto a Suetonio, menciona en su "Vida de los doce césares", que, durante el reinado de Nerón, "fueron perseguidos bajo pena de muerte los cristianos, una secta de hombres de una superstición nueva y maléfica".

Tertuliano, en su "Apología contra los gentiles", escrita en el año 200, explica cuáles eran los delitos que la fama imputaba a los cristianos: 
Los gentiles asimilaban las reuniones nocturnas de los cristianos a ritos orientales de los «misterios», como los de Eleusis y Samos, enraizados en las prácticas mágicas, los misterios de Cibeles, los de Isis, originarios de Egipto, o los de Mitra, procedentes de Persia, que alcanzaron notable difusión incluso en España y en especial en la costa catalana.

En este contexto, hay que recordar que se hizo costumbre entre varios emperadores romanos el erigir estatuas propias en las diversas ciudades del imperio, y en autoproclamarse dioses o hijos de dioses (bajo el título de señor de señores) a los que sus súbditos debían de respetar. Un signo ejemplar de esto era la obligación de adorar o cuando menos arrodillarse ante las estatuas de los emperadores en las ciudades donde se encontraran. 

Los cristianos, tomando como principio el que Jesús es el único Señor de señores, y el único hijo del Dios verdadero, se negaban a tomar tales actitudes. Los romanos, antes que juzgar sus creencias, verían en estos gestos las actitudes de una rebelión política contra el imperio, lo cual originó varias persecuciones contra los cristianos en esa época. Los componentes ideológicos potencialmente subversivos de las doctrinas y costumbres cristianas debieron ser tomadas como una amenaza para el estatus quo del orden social romano y una amenaza, sobre todo para las clases privilegiadas de ese orden. 

Tal es el caso de la creencia en la filiación divina de toda la humanidad («Todos somos hijos de Dios») que implicaba la hermandad universal («todos somos hermanos») y la dignidad humana («cualquier cosa que le hicierais al más pequeño de ellos es como si me lo hicierais a mí»), un alegato a favor de la igualdad que chocaba frontalmente con una sociedad esclavista. También el alegato contra la riqueza y las prácticas comunistas de los primeros cristianos (que ponían a disposición de la «comunidad» todos sus bienes cuando entraban a formar parte de ella) debieron resultar amenazadores para los poderosos y privilegiados del imperio. El cristianismo fue inicialmente una religión dirigida a los humildes, a los que sufren injusticia, los pobres y a los esclavos, los grupos sociales más numerosos en un imperio en crisis, y entre los que se extendió rapidísimamente a pesar de los esfuerzos de las autoridades por evitarlo.

Hubo diez grandes persecuciones romanas contra el cristianismo, denominadas generalmente con el nombre de los emperadores que las decretaron: las de Nerón, Domiciano, Trajano, Marco Aurelio, Septimio Severo, Maximiano, Decio, Valeriano, Aureliano y Diocleciano. 

Puesto que el cristianismo era considerado ilegal en el imperio, los cristianos debían ocultarse. Sus reuniones serían entonces secretas y son famosas las catacumbas de la ciudad de Roma, donde se dice que los cristianos se reunían, aunque según los testimonios cristianos conservados, las catacumbas no eran el medio más utilizado para esconderse, ya que la mayor parte de las reuniones de culto, se haría secretamente en las mismas casas de los fieles. Para identificarse habrían utilizado símbolos que a ojos romanos no fueran evidentes, como el símbolo del Pez (Ichthys, o ΙΧΘΥΣ en griego), acrónimo que significaba para ellos "Iēsoûs CHristós THeoû hYiós Sōtér", 'Jesucristo, Hijo de Dios, Salvador'.

Una de las más conocidas e implacables y quizá la más temprana es la originada por el emperador Nerón, en torno al cual se originó la leyenda de su autoría del incendio que acabó con varios barrios de la ciudad de Roma. El historiador Cornelio Tácito escribió a principios del siglo II que ante el rumor popular de que el incendio se había originado por orden superior, halló en los cristianos los chivos expiatorios que en principio satisficieron la ira del pueblo. Fueron cruelmente reprimidos, según los "Anales" de Tácito. Suetonio, otro escritor prominente de principios del siglo II corrobora la versión, señalando que entre las obras públicas de Nerón se contaba «persiguió a los cristianos». Esta sería una de las razones que habrán llevado a cristianos como Pedro o Pablo a la muerte en Roma, de lo que hablan escritores cristianos de los primeros siglos como Clemente I.

Otro emperador que se recuerda por su crueldad con los cristianos fue Domiciano, entre los años 81 y 96. Entre los numerosos cristianos martirizados durante esta persecución estaban Simeón, obispo de Jerusalén, que fue crucificado. Flavia, hija de un senador romano, fue asimismo desterrada al Ponto; y se dictó una ley diciendo: «Que ningún cristiano, una vez traído ante un tribunal, quede exento de castigo sin que renuncie a su religión».

Entre 109 y 111 dC, Plinio el Joven fue enviado por el emperador Trajano (98-117) a la provincia de Bitinia como gobernador. Durante su mandato, Plinio encuentra a los cristianos, y escribe al emperador sobre ellos. El gobernador indicó que había ordenado la ejecución de varios cristianos. Sin embargo, no estaba seguro de qué hacer con aquellos que dijeron que ya no eran cristianos, y pidió consejo a Trajano. El emperador respondió que los cristianos no deben ser buscados y que las acusaciones anónimas deben ser rechazadas como una muestra «indigna de nuestra época», y si se retractan y «adoran a nuestros dioses», deben ser liberados. Los que persistan, sin embargo, deben ser castigados.

Parte del problema que los cristianos tuvieron durante esta época, fue mayormente provocada por el populacho, que saqueó a las comunidades cristianas de Asia Menor fundadas por el Apóstol Pablo. Sin embargo, la condena de Marco Aurelio al cristianismo, tuvo repercusiones tan conocidas como la condena a muerte de Justino, que ocurrió durante esta época. La Persecución de Lyon, que fue precedida por la violencia colectiva incluyendo asaltos, robos y lapidaciones (Eusebio, Historia eclesiástica 5.1.7), provocó la aniquilación de la floreciente cristiandad de esta ciudad (según se dijo, por ateísmo e inmoralidad). Otros cristianos conocidos fueron torturados y martirizados en este momento, como Potino o Blandina

Otro emperador bajo quien los cristianos sufrieron fue Septimio Severo, que gobernó desde el 193-211. Durante su reinado, Clemente de Alejandría dejó escrito: «Muchos mártires son quemados a diario, confinados o decapitados, ante nuestros ojos».

Septimio Severo usó la persecución como pretexto para atribuir a los cristianos la peste y el hambre que asolaban el imperio; en esta persecución, especialmente violenta, sufrieron martirio Santa Cecilia y su esposo Valeriano y tuvo lugar el famoso episodio de la Legión fulminante. 

El emperador Severo quizás no estaba personalmente en contra de los cristianos, pero la iglesia estaba ganando poder y la adhesión masiva de fieles condujo al sentimiento popular anti-cristiano y su persecución en Cartago, Alejandría, Roma y Corinto aproximadamente entre 202 y 210.

En el año 202 Septimio promulgó una ley que prohibió la difusión del cristianismo y el judaísmo. Este fue el primer decreto universal prohibiendo la conversión al cristianismo. Estallaron violentas persecuciones en Egipto y África del Norte. Leonidas, defensor del cristianismo, fue decapitado; su hijo Orígenes fue perdonado porque su madre escondió su ropa. Una joven fue cruelmente torturada y luego quemada en una caldera de brea ardiente con su madre. Perpetua y Felicidad fueron martirizadas durante este tiempo, al igual que muchos estudiantes de Orígenes de Alejandría.

Maximino el Tracio inició una persecución dirigida principalmente contra los jefes de la Iglesia en el año 235. Una de sus primeras víctimas fue Ponciano, que con Hipólito fue desterrado a la isla de la Cerdeña.

La persecución de Decio arrojó numerosos eremitas a los bosques; entre sus mártires se encuentra el papa San Fabián y Santa Águeda; el célebre Orígenes sufrió tales tormentos que murió después a consecuencia de ellos. La persecución de los cristianos se extendió a todo el Imperio durante el reinado de Decio y marcó de forma duradera a la iglesia cristiana.

En enero de 250, Decio publicó un edicto por el que se requería que todos los ciudadanos hicieran un sacrificio para mayor gloria del emperador en la presencia de un oficial romano y así obtener un certificado (Libellus) que demostrara que lo habían hecho. En general, la opinión pública condenaba la violencia del gobierno y se admiraba de la resistencia pasiva de los mártires con lo que el movimiento cristiano se fortaleció. La persecución de Decio cesó en 251, pocos meses antes de su muerte.

La persecución de Decio tuvo repercusiones duraderas para la iglesia: ¿Cómo deben ser tratados los que habían comprado un certificado o había hecho realmente el sacrificio? Parece que en la mayoría de las iglesias, los apóstatas fueron aceptados de nuevo al seno de la iglesia, pero algunos grupos se les negó la entrada a la iglesia. Esto plantea importantes cuestiones acerca de la naturaleza de la Iglesia, el perdón, y el alto valor del martirio. Un siglo y medio más tarde, san Agustín discutió con un influyente grupo llamados Donatistas, que se separó de la Iglesia Católica porque ésta abrazó a los que se habían acobardado.

Gregorio de Tours glosa las persecuciones en su "Historia de los francos":

Los escritos de Cipriano, obispo de Cartago, arrojan luz sobre las consecuencias de la persecución de Decio en la comunidad cristiana cartaginesa.

Bajo el reinado de Valeriano, que subió al trono en 253, todos los clérigos cristianos fueron obligados a sacrificar a los dioses romanos. En un edicto de 257, el castigo fue el exilio, en 258, el castigo era la muerte. Senadores cristianos, caballeros y damas fueron también obligados a sacrificar, bajo pena de fuertes multas, reducción de rango y, más tarde, la muerte. Por último, se prohibió a todos los cristianos visitar sus cementerios. Entre los ejecutados por Valeriano se encuentran: san Cipriano, obispo de Cartago, y Sixto II, obispo de Roma. Según una carta escrita por Dionisio durante este tiempo, «hombres y mujeres, jóvenes y ancianos, doncellas y matronas, soldados y civiles, de toda edad y raza, algunos por la flagelación y el fuego, otros por la espada, han conquistado en la lucha y ganado sus coronas». La persecución terminó con la captura de Valeriano por Persia. Su hijo y sucesor Galieno, revocó los edictos de su padre.

Una orden de arrestar a un cristiano, de fecha 28 de febrero 256, se encontró entre los Papiros de Oxirrinco (P. Oxy 3035). En el documento no se detallan los motivos de la detención.

La persecución de Diocleciano fue la más grave, pues este quiso reformar el imperio en todos los aspectos y una parte muy esencial de su política era reforzar el culto imperial. Fue instigado a ella por los césares Maximiano y Galerio; hasta ciudades enteras cristianas fueron arrasadas. Fue tan larga esta persecución que fue llamada la Era de los mártires, y entre los más célebres se cuentan varios papas, San Sebastián, San Pancracio y Santa Inés.

Juliano el Apóstata fue el último emperador pagano del Imperio romano. Se crio en un momento en que el paganismo estaba en declive, en Roma. Al ser proclamado augusto en el año 361, Juliano de inmediato declaró su fe a los antiguos dioses romanos y buscó provocar un renacimiento pagano. Sin embargo, fue asesinado en Persia en el año 363 y su intento de restaurar el paganismo finalmente fracasó.

Juliano utilizó muchos métodos para romper sutilmente la Iglesia. Recordó a los obispos que habían sido desterrados por las enseñanzas heréticas, el clero fue despojado de su derecho a viajar por cuenta del Estado (como lo habían hecho anteriormente) y prohibió a los cristianos enseñar obras clásicas tales como la "Ilíada" o la "Odisea". Juliano fue sustituido por el emperador cristiano Joviano.La persecución de Constantino, siglo II mediados del siglo II, las turbas estaban predispuestas a tirar piedras a los cristianos. La Persecución de Lyon fue precedida por la violencia colectiva, incluyendo asaltos, robos y lapidaciones 
Además hubo persecuciones de forma inconexa hasta el siglo III, aunque la Apologética de Tertuliano de 197 fue escrita ostensiblemente en defensa de los cristianos perseguidos y dirigida a los gobernadores romanos. El edicto de Septimio Severo, familiar en la historia del cristianismo es puesto en duda por algunos historiadores seculares por conocerse fuera del martirologio cristiano. Según la documentación del Imperio, la primera gran persecución tuvo lugar bajo Maximino el Tracio, aunque sólo afectó al clero. No fue sino hasta Decio a mediados del siglo, que una persecución de los cristianos laicos de todo el Imperio se llevó a cabo. Fuentes cristianas aseveran que se emitió un decreto que requería sacrificios públicos, un trámite equivalente a un testimonio de fidelidad al emperador y al orden establecido. Decio autorizó varias comisiones itinerantes para visitar las ciudades y aldeas y supervisar la ejecución de los sacrificios y para entregar los certificados por escrito a todos los ciudadanos que las efectuasen. Los cristianos a menudo tuvieron oportunidad de evitar el castigo efectuando sacrificios públicos o quemando incienso en honor a los dioses romanos, pero si se negaban eran acusados por los romanos de impiedad. La negativa era castigada con arresto, encarcelamiento, tortura y ejecuciones. Los cristianos huyeron a refugios en el campo, y algunos compraron sus certificados de sacrificio, denominados libelli. Varios municipios próximos a Cartago debatieron la cuestión de en qué medida la comunidad debería aceptar a estos cristianos lapsos.

En el transcurso de la descristianización de Francia durante la Revolución de ese país, se dieron las primeras persecuciones a los cristianos en la época moderna, considerándose mártires a cientos de sacerdotes y religiosos que fueron asesinados en ese periodo de la historia, como en las llamadas Masacres de septiembre y los 191 Mártires de París en la Revolución Francesa (1792).
Se considera que el primer genocidio moderno se produjo en La Vendée, al oeste de Francia, cuando en 1793 los jacobinos anticlericales de la Revolución mataron a miles de campesinos católicos considerados como contrarrevolucionarios. En 1794, durante el período conocido como «El Terror», se guillotinaron 16 monjas en Compiègne por negarse a renunciar a sus votos monásticos (años después este hecho inspiró la obra "Diálogos de Carmelitas"). Un mes antes corrieron la misma suerte cuatro monjas de Arras Hijas de la Caridad de San Vicente de Paúl, mientras ejercían su misión caritativa, son conocidas como las Martíres de Cambrai. 

Una de las mayores persecuciones contra los cristianos de la historia moderna tuvo lugar en Vietnam a lo largo del periodo que va desde 1625 hasta 1886. Se calcula que en esos años fueron asesinados unos 130 000 cristianos.

Según Antonio Socci, en el siglo XX habrían sido asesinados unos 45,5 millones de cristianos por sus creencias religiosas, aproximadamente el 65 % del total de cristianos asesinados por su fe en dos milenios. Si se considera el término «mártir» en sentido estricto, es decir, aquel que asume voluntariamente la muerte como consecuencia directa de su fe y de su testimonio evangélico, la cifra se calcula en aproximadamente 12000 personas. 

En España, desde 1934 a 1939 —periodo que va desde la revolución de octubre hasta la Guerra Civil Española—, se contabilizan alrededor de 10 mil católicos (sacerdotes, religiosos y laicos) asesinados por motivos religiosos. Esta persecución, por su intensidad, ha podido ser calificada la mayor de toda la historia del cristianismo:

Entre los años 2003 y 2009, según informó Asianews en diciembre de 2009, habrían sido asesinados alrededor de 2000 cristianos en Irak. A causa de la inestabilidad y de los ataques dirigidos contra cristianos, muchos de ellos han huido a otros territorios: de los cerca de 800 mil cristianos que había en 2003, se calcula que quedan 450 mil en 2010.

Por lo que se refiere a la India, entre 2008 y 2010 se registraron más de 1000 episodios anticristianos en el estado de Karnataka, según se informó en marzo de 2010. En el estado de Orissa, entre los años 2008 y 2010, más de 5000 cristianos sufrieron persecución y presiones para convertirse a la religión hindú. 

Según unas declaraciones de Mario Mauro en agosto de 2010, que fungía entonces como representante de la OSCE contra la discriminación de los cristianos, de 100 personas que mueren al año por persecución religiosa, 75 serían cristianos. Ese mismo mes de agosto de 2010, monseñor Mario Toso, Secretario del Consejo Pontificio para la Justicia y la Paz, declaró que los cristianos eran el grupo religioso más perseguido en el mundo. Habría, según los datos de ese año, unos 200 millones de cristianos en situaciones de persecución. En cambio, según un informe publicado también en 2010 por la Comisión de las Conferencias Episcopales Europeas, el número de cristianos perseguidos estaría en torno a la cifra de 100 millones.

En cuanto al número de cristianos muertos anualmente por su fe, según una declaración hecha pública en junio de 2011 por Massimo Introvigne, representante de la Organización para la Seguridad y la Cooperación en Europa (OSCE) para la lucha contra la intolerancia y la discriminación contra los cristianos, se trataría de 105 000 muertos al año. La cifra fue puesta en discusión en 2013, sea por la modalidad en la que se obtuvo, sea por lo elevado de la misma. Según otro estudio, el número de cristianos asesinados anualmente durante la primera década del siglo XXI sería de 10 000.

En el presente, se registran ejemplos de intolerancia o persecución hacia cristianos particularmente en países de África, entre ellos, Egipto, Marruecos, Nigeria, Kenia, República Centroafricana, y en Asia, en países como Pakistán, Indonesia, regiones de la India, Laos, y hasta en Arabia Saudita, donde la apertura de templos cristianos está prohibida.





</doc>
<doc id="15382" url="https://es.wikipedia.org/wiki?curid=15382" title="Patrística">
Patrística

La patrística es el estudio del cristianismo de los primeros siglos y de sus primeros autores conocidos como padres de la Iglesia. La patrística es la fase en la historia de la organización y la teología cristiana que abarca desde el fin del cristianismo primitivo, con la consolidación del canon neotestamentario, hasta alrededor del siglo VIII. Se considera que el periodo corre desde la parte final del Nuevo Testamento, específicamente desde los Hechos de los Apóstoles (año 100 DC) y hasta 451 (la fecha del Concilio de Calcedonia), o hasta el Segundo Concilio de Nicea, del siglo VIII. 

En su contenido ideológico, la patrística se caracterizó por ser el periodo en que se gestó el contenido doctrinal de las creencias religiosas cristianas, así como su defensa apologética contra los ataques de las religiones paganas primero, y sucesivamente de las interpretaciones que dieron lugar a las herejías, después. Durante este período, el cristianismo es difundido masivamente por los profetas, tomando fuerza entre la población y desplazando a las religiones politeístas. 

Para ser reconocido un padre de la Iglesia, era necesario reunir las siguientes condiciones: 


La religión cristiana encontró en la filosofía griega los argumentos para justificar su doctrina, pues la religión cristiana era para los padres de la Iglesia la expresión cumplida y definitiva de las verdades que la filosofía griega había logrado encontrar de manera imperfecta y parcial.

La palabra deriva de la forma combinada del latín "pater" y del griego "patḗr", 'padre', y hace referencia a los padres de la Iglesia, los teólogos cuya interpretación dominaría la historia del dogma. La influencia apologética se debió entre otras cosas al ataque hostil, y por penetrar en los datos de la revelación, el de formarse una imagen totalizadora del mundo y de la vida humana a la luz de la fe. El progreso de lo implícito a lo explícito fue un progreso en la ciencia teológica; en el proceso de argumentación y definición se emplearon conceptos y categorías tomados de la filosofía. La filosofía imperante era el platonismo, neoplatonismo (con toque estoico).

Los escritores cristianos no hicieron distinción entre filosofía y teología. Estos mostraron una divergencia de actitud ante la filosofía clásica: como enemiga o como utilidad.

Algunos de los principales representantes de esta etapa fueron Mario Victorino, Boecio, Isidoro de Sevilla, San Agustín de Hipona y Juan Escoto Erígena.

Durante este tiempo surgieron figuras destacadas en defensa de la nueva fe cristiana. En torno de la comunidad de Alejandría, en Egipto, gran centro cultural del mundo romano, se formó una escuela en la que brillaron Clemente de Alejandría (150-215) y su discípulo Orígenes (185-254): cabe mencionar que la comunidad de Alejandría estaba en contra de las herejías gnósticas; Filón y Clemente de Alejandría fueron pieza clave para esta aportación. Basados en las filosofías griegas, se introdujeron en el modo de pensar de bastantes personas. Clemente de Alejandría era escuchado por ricos y pobres, personas de clase alta, políticos, etc. y por gente humilde; se dice que se sabía de memoria los diálogos de Platón y hacía continuo uso de ellos.

Orígenes escribió numerosas obras (unas 800) y aunque incurrió en algunos errores graves, debido a su intento de "explicar" orgánicamente todas las dificultades que pudieran presentarse ante la reflexión de las creencias cristianas, en unos momentos en que el dogma no estaba todavía fijado por completo, no cabe atribuir su actitud a afán polémico o sensacionalista, sino a un íntimo deseo de aprender toda la verdad. Este afán común a muchos espíritus cultos de la época llevó a polémicas apasionadas. De la pasión que se vertía en los escritos polémicos de los primeros siglos de la Iglesia, podrán dar idea las siguientes palabras de Zonaro referentes a la persecución de Decio: 

Dos grandes personalidades del África noroccidental fueron el presbítero Tertuliano (160-245), originario de Cartago, y su discípulo el obispo San Cipriano (160-258), de Cartago también, decapitado en la persecución de Valeriano. 

Tertuliano, iniciado en el culto de Mitra cuando joven, debió convertirse después al cristianismo y luego pasó (213) al montanismo, creencia considerada entonces herejía, predicada por el frigio Montano, enemigo de la Iglesia jerarquizada. Tertuliano fue un rigorista extremado.

San Cipriano, retórico convertido al cristianismo en edad madura, es un asceta y un moralista, pero es sobre todo un espíritu práctico. Dos problemas le preocupan en especial: el de los lapsi cristianos asustadizos que ante la persecución negaban su condición de tales y prestaban adoración al emperador (a quienes considera readmisibles en el seno de la Iglesia mediante ciertas condiciones), y el de los bautizados por los considerados herejes (que no cree lo estén en realidad). 

Una de las obras de San Cipriano, escrita en 251 con ocasión del cisma provocado en Roma por Novaciano al negar a la Iglesia el derecho a readmitir a los lapsi en la comunión de los fieles, se titula "La Unidad de la Iglesia católica", y en ella advierte que no todos los peligros derivan de la persecución: "no hay que temer únicamente la persecución o todo aquello que con descubierta acometida se dirige a derribar y derrotar a los siervos de Dios; cuando el peligro está a la vista, es más fácil la cautela, y cuando el adversario se declara, el ánimo se apresta de antemano al combate. Hay que temer sí y guardarse más del enemigo cuando se presenta a escondidas, cuando engañando con cara de paz, se arrastra con paso oculto" (cap. I). "¿Y qué cosa más astuta y sutil, que el enemigo encubierto y apostado junto a la senda de Cristo (...) tramara un nuevo engaño, como el de engañar a los incautos con el mismo título de nombre cristiano? Inventó, pues, herejías y cismas, con los cuales destruye la fe, corrompe la verdad, rompe la unidad". "Todo esto sucede", sigue diciendo Cipriano, "por no volver al origen de la verdad, por no buscar la cabeza" (cap. III). Y recuerda entonces las palabras de Jesucristo a San Pedro cuando cimentó en él su iglesia. "Sobre uno únicamente, insiste, edifica su iglesia". "Quien no se cuenta en esta unidad de la Iglesia ¿cree que tiene la fe?". 


Después del concilio de Nicea: 





</doc>
<doc id="15383" url="https://es.wikipedia.org/wiki?curid=15383" title="Simbolismo cristiano">
Simbolismo cristiano

La definición y preservación de los dogmas de la fe exigía mucha cautela en un ambiente tan diverso y tan presto al sincretismo como el del Imperio romano en aquellos siglos. Los catecúmenos se habían dividido en dos grupos: oyentes (audientes), que deseaban iniciarse en la fe, entre los cuales no faltaban a veces espías a sueldo, pero que demoraban el bautismo, y elegidos ("electi"), que se preparaban ya para su ingreso en la comunidad cristiana. Unos y otros, aunque más formados estos últimos, debían mantenerse al margen de los ritos reservados para los iniciados y en especial del "misterio" de la carne y la sangre del Verbo de Dios. De aquí que, para reconocerse, los fieles "iniciados" utilizaran símbolos.

Algunos autores consideran que algunos símbolos pudieran ser derivados de la mitología antigua. El pavo y el ave Fénix simbolizan la resurrección. La palma la victoria. La paloma la sencillez cristiana, el pudor y la paz concedida al alma fiel. El ciervo, el servidor diligente de Cristo. El áncora, la esperanza en la salvación. La nave, la Iglesia. Orfeo, simbolizaba a Jesucristo. 

Se cree que en la simbología cristiana primitiva (s. II y III d. C.) el signo del ancla o "áncora" sería una forma velada de hacer referencia a la cruz de Cristo, esto, con la intención de ocultar su fe en tiempos de persecución, como la desatada en los días del emperador Diocleciano.

Símbolos cristianos eran: El pez. Objetos que se han datado como del siglo II d. C. que llevan figuras de pescados junto con la palabra griega para pescado, "“ΙΧΘΥΣ (IKHTHUS o IKHTHYS)”", que se cree es un críptico para la expresión griega "“Iesoús Christós Theoú Yiós Sotḗr”", que quiere decir “Jesucristo, Hijo de Dios, Salvador.” 

Según "The Interpreter’s Dictionary of the Bible", los pescados aparecían frecuentemente en el antiguo simbolismo pagano, a menudo aparte de escenas acuáticas. “En tales casos,” dice, “parecería tener significado simbólico, posiblemente para representar una deidad, poder, fecundidad, etc.” Esta misma obra de consulta dice, además, que ciertos judíos adoptaron el símbolo del pescado de algunas costumbres religiosas gentiles, y agrega: “Es probable que las consideraciones mencionadas expliquen hasta cierto grado la aparición del pescado en el arte de las más antiguas catacumbas cristianas. No sabemos cuándo llegó a ser interpretada la palabra griega para ‘pescado’ (ikhthys) como una cifra para ‘Jesucristo, Hijo de Dios, Salvador’;[…] pero una vez que se hizo esta identificación, el pescado llegó a ser un símbolo cristiano normal”. 

Luego desde el siglo III empiezan a haber representaciones más explícitas, como una joya en cornalina que muestra la crucifixión de Cristo junto a los doce apóstoles, del siglo III o IV d. C., procedente de la colección fotográfica y anotaciones del arqueólogo clásico sir John Beazley.

En la actualidad el cristianismo está lleno de símbolos; la cruz recuerda a la crucifixión, la virgen María personifica la forma de maternidad más pura reforzada por la asociación al color azul y al blanco, como en Isis. La figura con cuernos y cola es la representación simbólica más común del diablo, intensificada por el color rojo (como Set rojo). La creación de iconos era considerada una parte muy importante del culto. El cordero, símbolo del sacrificio de Cristo y su victoria, y el Buen Pastor, símbolo de Jesucristo y de Orfeo. Algunos símbolos eran de tema histórico - bíblico, como el sacrificio de Isaac, que se utilizaba para representar el sacrificio de la cruz; Adán y Eva, imagen de Jesucristo, nuevo Adán que reparó el pecado; el Arca de Noé, imagen de la Iglesia, etc. A veces se utilizaban también escenas alegóricas, como las de la viña, el convivió o cena, las vírgenes prudentes y las imprudentes de la parábola, etc. 

La creencia popular de que las catacumbas, cementerios subterráneos comunes a varias ciudades del imperio, fueran usadas a veces como refugio para los cristianos en tiempos de persecución ha sido descartada por la historiografía moderna.

"Hoy día es difícil sostener el carácter de refugio que se le ha venido dando a las catacumbas, ya que, exceptuando las tres grandes persecuciones de Decio en 250, de Valeriano en 257-258 y de Diocleciano entre fines del siglo III y comienzos del IV, los cristianos gozaron de periodos de relativa tranquilidad. Las catacumbas deben ser vistas como cementerios subterráneos dedicados a los difuntos y a los mártires, en cuyo honor se celebraba la eucaristía, como lugares de reposo a la espera de la resurrección, y, por ello, las pinturas que las decoran están llenas de sugerencias a la otra vida y a la celebración eucarística".

Al igual que otras comunidades, los cristianos también enterraban a sus difuntos allí, y en ellas hallaban sepultura también los cuerpos de los mártires, muertos en las persecuciones. La veneración que empezó a tributárseles originó la construcción de capillas más amplias entre los estrechos pasillos subterráneos, a menudo superpuestos en varios pisos, e hizo que los cristianos se reunieran en ellas para celebrar los misterios de la fe. El arte cristiano primitivo halló ocasión de plasmar en las paredes de estos recintos y capillas sus admirables realizaciones. 

Junto a la "Via Appia" antigua se hallan las catacumbas de San Calixto, las de San Sebastián y las de Pretextato; en la "Via Ardeatina", las de Domitila, las de Priscila en la "Via Salaria" y las de Sta Inés en la Nomentana. Todas ellas, muy visitadas por los peregrinos y turistas que acuden a Roma, no representan más que una mínima parte de las sesenta de que hoy se tiene noticia, con más de seiscientos kilómetros de galerías subterráneas de planta laberíntica, con cuatro o cinco sepulturas por piso, una encima de la otra, como los nichos de un cementerio moderno. 

Sus asambleas, que generalmente se celebraban en los tituli o casas de nobles, quienes las prestaban gustosos para ello, también se celebraban en las tumbas de los mártires. Se iniciaba con el saludo tradicional: "Que la paz sea con vosotros" para continuar con el rezo de las letanías, que el pueblo contestaba a coro; seguían dos oraciones breves, diversas lecturas, canto de un salmo, y rezo y comentario del Evangelio. Confesión publica de pecados y el canto del Marhanatha. Cuando concluía esta primera parte, se despedía a los catecúmenos y paganos. Luego continuaba la ceremonia con el ofertorio (en que los asistentes ofrecían sus presentes o limosnas) y seguían los preparativos para el sacrificio, rezo de varias oraciones, entre ellas la eucarística y la comunión bajo las dos especies (fragmento de pan asimo consagrado depositado en la mano derecha de cada comulgante por los obispos, y un sorbo de vino del cáliz que era pasado, de uno en uno, por los diáconos) Oración en acción de gracias, bendición episcopal a los fieles, y la fórmula de despedida que aún subsiste: "Id, la misa ha terminado".

La Cruz cristiana es un símbolo religioso muy familiar en la cristiandad. Este método de ejecución fue común para los esclavos romanos y para los criminales que no eran romanos. El evangelio usa la palabra stauros (estaca) y xylon (madero).

Las palabras «cruz» y «crucifijo» provienen de las derivaciones del verbo latino "cruciare", que significa "torturar".
En el s II se desarrolla el concepto teológico neoplatónico de la Cruz como límite del Pleroma.




</doc>
<doc id="15385" url="https://es.wikipedia.org/wiki?curid=15385" title="Historia del cristianismo durante la Edad Media">
Historia del cristianismo durante la Edad Media

La rosa historia del cristianismo durante la edad media abarca los hechos relacionados con el ((cristianismo)) desde la caída del Imperio romano de Occidente (c. 476) hasta la reforma protestante (), que es cuando se considera que comienza el cristianismo moderno. Este período de la historia coincide con lo que se conoce como Edad Media.

La Alta Edad Media comienza con el derrocamiento del último emperador romano de occidente (Rómulo Augusto) por Odoacro, líder de los hérulos, en el año 476 y finaliza con la coronación de Carlomagno en el año 800. Aunque esta división es arbitraria, ya que el inicio de la Alta Edad Media fue un proceso gradual en el cual la fuente de riqueza y poder se fue transfiriendo desde las ciudades al campo, mientras decaía la autoridad del poder central del emperador de Roma.

En los comienzos del cristianismo no había diferencia entre los diferentes obispos, aunque tras el cese de las persecuciones romanas (c. 360) surgió la necesidad de unificar las creencias y centralizar el poder. En el rastreo del primado papal, Dámaso I (366-384), se presentó como un nexo espiritual entre los cristianos del Imperio Romano de Occidente y de Oriente, mientras se mostraba intrasigente con las doctrinas contrarias a las establecidas en los concilios. Al mismo tiempo, la figura del emperador se consolida en el "dominado", por la que adopta una forma mística, legitimada y enviada por Dios, que busca el centralismo del poder mediante el apoyo de la Iglesia. El papa León I el Magno (440-461) asumió el título de "pontifex maximus", que habían abandonado los emperadores romanos desde el 382. La supremacía papal se consolida con Gelasio I (492-496), quien dirigió una carta al emperador Anastasio I (491-518) en donde formula la "doctrina de las dos espadas", entendida como la justificación de la superioridad de la potestad espiritual del Papa sobre la temporal del emperador.

Al mismo tiempo que el poder de la Iglesia cristiana iba creciendo en Europa, el de los emperadores disminuía. En medio de la crisis por las guerras constantes, el emperador Justiniano I (527-565) trató de reafirmar el dominio imperial en Italia desde el este, en lo que se conoce como guerra gótica (535-554). A pesar de que la campaña fue exitosa, se estableció para Italia un exarcado, la influencia imperial era limitada. En 568 los lombardos invadieron la península estableciendo el Reino lombardo. Cuando entraron en Italia, algunos lombardos conservaron su forma nativa de paganismo, mientras que otros eran cristianos arrianos, de ahí que no tuvieran buenas relaciones con la Iglesia católica, a la que persiguieron con celo. El fracaso de los emperadores para enviar ayuda dio lugar a que los papas se encargaran de la alimentación de la ciudad con el grano de la hacienda papal. Así como de la negociación de acuerdos con los lombardos, mediante el pago a sus líderes a cambio de protección o, en su defecto, la contratación de soldados para defender la ciudad. Esto marcó el final de la influencia en Roma del Imperio bizantino.

Tras la caída del Imperio Romano de Occidente, los misioneros cristianos comenzaron a predicar entre pueblos de origen celta y germánico.

En el existía un contacto fluido entre lo que hoy es Irlanda, Escocia y Gales. En este contexto, el cristianismo comenzó a expandirse en estas regiones desde la Britania posromana; comenzando por Gales, región en la cual convivían celtas paganos con bretones cristianos ya desde la época romana.

A comienzos , Irlanda se encontraba dominada por los druidas. Se desconoce como se introdujo por primera vez el cristianismo en la isla, pero se estima que comenzó con los prisioneros que eran capturados en las costas de Gran Bretaña durante las incursiones que se llevaban a cabo en busca de botín y esclavos. La crónica de Próspero de Aquitania (390-455) menciona que en el 431 Paladio de Escocia fue enviado por el papa Celestino I (422-432) a Irlanda para ser su primer obispo, aunque abandonaría la isla poco después debido a la fuerte oposición a su presencia del jefe de Wicklow. Esto evidencia que para aquella fecha ya había una pequeña comunidad cristiana.

La tradición da preeminencia a Patricio de Irlanda, quien teniendo 16 años fue secuestrado por un grupo de escotos, llevado a Irlanda y vendido como esclavo. La fecha de su cautiverio no está clara, aunque se sabe que duró seis años. Según distintos autores, debió ser entre los años 410 y 430, siendo lo más probable en torno al 420; pero en ningún caso anterior al 405. Después de su fuga estudió teología y fue enviado de regreso a Irlanda en 433 como líder de un grupo de misioneros por Germán de Auxerre (378-448), obispo de Britania, como segundo intento de evangelización luego de la expedición fallida de Paladio dos años antes. Patricio logró la conversión de los líderes de algunos clanes, lo que propició la conversión del resto de la población.

Según la tradición, la introducción del cristianismo en Escocia se atribuye a Columba de Iona (521-597). Aunque se desconoce a ciencia cierta cuánto contribuyó a esto efectivamente, no hay dudas de que fue muy influyente en las primeras comunidades cristianas de Escocia. Columba llegó a la isla de Iona en el 563 proveniente de Irlanda, junto a otros doce hombres, y allí fundó una abadía. Tras su llegada estableció contacto y fue protegido por Conall mac Comgall, rey de Dalriada, un importante estado escoto, lo que favoreció la expansión de la nueva religión.

 Pueblos germánicos que invadieron el sur y el este de la Gran Bretaña, desde principios del siglo V hasta la conquista normanda en el año 1066.

En los siglos IV y V, el imperio romano perdió buena parte de su extensión en Occidente y se transformó en oriental bizantino. Se suele señalar como sintomática la fecha del año 476, pero de hecho la invasión y cuarteamiento del imperio había empezado mucho antes (406). Un grupo de pueblos, originarios de Escandinavia, los germanos, desde Europa central se había lanzado a la conquista de los despojos de Roma. De estos pueblos, los visigodos fueron cristianizados por el obispo Ulfilas, pero el arrianismo arraigó en ellos hasta que pasaron a la ortodoxia en el 589. Burgundios y vándalos eran también arrianos. Los suevos, el 408, eran en parte todavía paganos y estuvieron vacilando entre el arrianismo y la ortodoxia hasta que hacia el 560, optaron por la última. Los ostrogodos, cuando en 489 se apoderaron de Italia, practicaban ya el arrianismo, pero su rey Teodorico se esforzó para evitar roces con los católicos. Los francos, en cambio, paganos, pasaron directamente a la ortodoxia, el 496, con el bautismo de su rey Clodoveo. "Adore tout ce que tu as brûlé, et brûle tout ce que tu as adoré", que traducido significa "Adora todo aquello que has quemado y quema todo aquello que has adorado..." 

Los germanos, no obstante, constituían la minoría dirigente. La mayor parte del campo contaba aún con poblaciones indígenas paganas. En las ciudades, la mayoría era cristiana. Cuando los vándalos pasaron al África, en el 429, hicieron que a la jerarquía episcopal ortodoxa se sumara una jerarquía arriana. Muchas ciudades del África vándala tuvieron simultáneamente obispo ortodoxo y obispo arriano. Cerca de cinco mil católicos fueron exilados por el monarca vándalo Hunirico y uno de sus sucesores, Trasamundo (496- 523), exilió a la isla de Cerdeña 120 obispos. Cuando el 534 los bizantinos recuperaron la provincia de África, el catolicismo se hallaba diezmado. La invasión musulmana, a mediados del siglo VII, lo hizo prácticamente desaparecer. 

En los siglos IV y V, Germania se va cristianizando; las regiones del Rin y del Danubio medio (Nórico y Recia) son las primeras en recibir el Evangelio, por obra de san Severino (482). Pablo Orosio y Salviano, autores religiosos de la época, aprecian los valores del mundo germánico y desean su plena conversión. 

En Oriente, san Simeón y los monjes del Sinaí convertían del arrianismo a la ortodoxia a los sabeos del sur de Arabia, Abisinia, Persia y Armenia abrazaban también la ortodoxia y el ámbito del cristianismo se extendía por el mundo.



</doc>
<doc id="15386" url="https://es.wikipedia.org/wiki?curid=15386" title="Little Richard">
Little Richard

Little Richard, nombre artístico de Richard Wayne Penniman, (Macon, Georgia, 5 de diciembre de 1932-Nashville, Tennessee, 9 de mayo de 2020) fue un cantante, compositor y pianista estadounidense de "rock and roll". Considerado como uno de los pioneros más influyentes e importantes de la historia del Rock and roll y una figura influyente en la música y la cultura popular durante siete décadas.

Su trabajo más famoso data de mediados de la década de 1950, cuando su música dinámica y su carismático espectáculo sentaron las bases del "rock and roll". Su música también jugó un papel clave en la formación de otros géneros musicales populares, como el soul y el funk. Influyó en numerosos cantantes y músicos de todos los géneros musicales, desde el rock hasta el hip hop; su música ayudó a dar forma al ritmo y al blues para las generaciones venideras, y sus actuaciones y titulares impulsaron su carrera directamente en la mezcla de la música popular estadounidense.

Ha sido honrado por muchas instituciones. Fue incluido en el Salón de la Fama del Rock and Roll como parte de su primer grupo de miembros en 1986. También fue incluido en el Salón de la Fama de los Compositores. Recibió un Lifetime Achievement Award de la Recording Academy y un Lifetime Achievement Award de la Rhythm and Blues Foundation. En 2015, recibió un Premio Rhapsody & Rhythm del Museo Nacional de Música Afroamericana por su papel clave en la formación de géneros musicales populares y ayudar a poner fin a la división racial en las listas de música y en los conciertos a mediados de 1950 cambiando significativamente la cultura estadounidense. "Tutti Frutti (canción) de Little Richard (1955) fue incluida en el Registro Nacional de Grabación de la Biblioteca del Congreso en 2010, que declaró que su "vocalización única sobre el ritmo irresistible anunció una nueva era en la música".

Sus primeras grabaciones en los años 50 eran una mezcla de "blues" y "rhythm and blues", con una fuerte influencia del "gospel", pero con una habilidad tal que marcaron decididamente una nueva clase de música. Es considerado y apodado el "arquitecto" del rock and roll, aunque el color de su piel le apartara de la gloria que alcanzaron, entre otros, Elvis. También es considerado "El Predicante Rey del Rock & Roll, Rhythm & Blues y Soul".

Algunos de sus trabajos más conocidos son Tutti Frutti y Long Tall Sally.

Procedente de una familia humilde, hijo de un destilador ilegal de whisky, fue el tercero de doce hijos, pasando su infancia más próximo a su madre que a su severo padre. Gracias a ella, recibió clases de piano. Él mismo dijo «vine a una familia a la que no le gustaba el "rhythm and blues". "Pennies From Heaven" de Bing Crosby y a Ella Fitzgerald era todo lo que podía escuchar». Perteneciente a la Iglesia Adventista del Séptimo Día, aprendió música "gospel" en las iglesias pentecostales del sur de Estados Unidos.

A los 15 años, su padre lo echó de casa escandalizado por sus escarceos homosexuales. Libre de la opresión familiar, libera sus pasiones reprimidas y se dedica a cantar en bares, tugurios o simples esquinas de la calle, para ganarse la vida. Por suerte, un matrimonio blanco, Ann y Johnny Johnson, lo sacaron de ese mundo y le permitieron seguir desarrollando sus aptitudes musicales en el escenario del Tick Tock, el club que regenteaban.

En 1951 ganó un concurso local y fue invitado por la compañía discográfica RCA Records con la que grabó ocho discos sencillos que no terminaron de cuajar. 

El año 1952 estuvo lleno de acontecimientos para Little Richard. Conoció a Sugarfoot Sam, actuando en sus números de vodevil. Pronto pasó a actuar con los Tidy Jolly Steppers en el estado de Alabama, pero poco después los abandonó para ser solista de la banda de J. L. Heath, con los que actuó por Georgia. Conoció a Billy Wright, que le propuso grabar un disco, ya bajo el nombre de Little Richard. Unos meses después, su padre moría asesinado.

En 1953 decidió formar su propio grupo, con el nombre de The Upsetters y en 1954 grabó diversos temas en una nueva discográfica, la Peacock, pero sin lograr resultados destacables. Trabajando como lavaplatos en la estación de autobuses de Macon y viendo que su carrera estaba estancada, decidió en 1955 enviar una maqueta a Specialty Records. Seis meses más tarde llegó la respuesta de Specialty para una sesión de grabación en Nueva Orleans, con la condición de que aceptase dejar a su grupo para ser acompañado por músicos de prestigio. Las primeras sesiones no terminaron de convencer, pero durante una pausa en una de dichas sesiones, Richard comenzó a cantar de manera improvisada "Tutti Frutti", una canción obscena y llena de lascivia que había estado cantando en sus actuaciones. Se cambió la letra ""Tutti Frutti, good, booty / If it don't fit, don't force it / You can grease it, make it easy"" (""Tutti Frutti, buen culito / Si no entra, no lo fuerces / puedes engrasarlo, para facilitarlo"") a ""Tutti frutti, all rooty, a-wop-bop-a-loon-bop-a-boom-bam-boom"" porque el productor de grabación, Roberte Bumps Blackwell, lo consideraba un exceso (además, "Tutti-frutti" en argot significaba "gay"). Además, Dorothy La Bostrie (su compositora) consideró que esos versos eran inaceptables.

La canción, con su onomatopéyico ""Womp-bomp-a-loom-op-a-womp-bam-boom!"", se convirtió en modelo para muchas otras pequeñas canciones futuras de Richard, tocando su piano, con Lee Allen al saxofón y su ritmo implacable. En los años siguientes, Richard tuvo varios éxitos más: "Long Tall Sally", "Slippin' and Slidin'", "Jenny, Jenny" y "Good Golly, Miss Molly". Su estilo frenético se puede ver en películas como "Don't Knock the Rock" (1956) y "The Girl Can't Help It" (1956), para las cuales cantó las canciones que daban el título, escritas por Bobby Troup.

A pesar del sonido primario de su música, sus sencillos fueron cuidadosamente seleccionados, según se puede apreciar en el triple álbum "The Specialty Sessions", en el que se incluyeron diferentes versiones. Como ejemplo de su artesanía, él y Blackwell ensayaron la estrofa de "Long Tall Sally", ""He saw Aunt Mary coming and he ducked back in the alley"" (Vio a tía Mary venir y se agachó detrás del callejón) durante todo un día hasta que consideró que había alcanzado la precisión deseada. Fue plagiado, inicialmente con éxito por cadenas de radio «para blancos», especialmente a través de Pat Boone. Este hecho, posiblemente favoreció que la fama de Little Richard se extendiera. 

En 1956 compró una mansión en Los Ángeles, California, y volvió a tocar con su antiguo grupo (The Upsetters).

Little Richard detuvo su carrera musical de forma repentina en 1957, durante una gira por el centro de Australia; renunció a su forma de vida en el "rock and roll". Parece ser que su decisión tuvo que ver con el incendio accidental de uno de los motores del avión en el que viajaba junto con su grupo. Después de aterrizar, se quitó de los dedos cuatro anillos de diamantes valorados en unos 8 000 dólares y los lanzó al río Hunter. Ingresó en una universidad cristiana en Alabama para estudiar teología y se hizo ministro pentecostal. Mientras su casa discográfica, la Specialty Records, lanzaba algunas nuevas canciones basadas en antiguas sesiones de grabación, Richard hizo muy poco musicalmente hablando, apenas algunas canciones de gospel a comienzo de los años 60.

En 1962 regresó con un entusiástico recibimiento en su gira por el Reino Unido. Los Rolling Stones, quienes admiraban a Richard incluso antes de que tuvieran un contrato de grabación, y los Beatles, también admiradores suyos, le apoyaron. Llegó a acompañar a los Beatles en su gira por Hamburgo. En 1982, Paul McCartney dijo: 

Desde entonces, Little Richard ha trabajado periódicamente en películas, ha lanzado ocasionalmente algún sencillo que otro y ha aguantado como uno de los grandes y legendarios pioneros del "rock and roll". Su vida parecía como si hubiera ido siempre de un extremo a otro. En 1964 volvió a los escenarios grabando nuevas versiones de sus éxitos; en los años 70 sus excesos sexuales y con las drogas hicieron que su iglesia lo rechazara. Finalmente, tras la muerte de uno de sus hermanos, Little Richard reorganizó su vida: limpió su organismo de drogas, se hizo vendedor de biblias a domicilio y volvió a su iglesia.

Regresó con dedicación plena al final de los años 80, diciendo que venía para realizar lo que Dios le tenía destinado ser: Little Richard. Todavía tenía la licencia de su ministro. Sin embargo, y ocasionalmente, celebró bodas (entre las que caben destacar las de Cyndi Lauper, y Bruce Willis - Demi Moore).

En 1986 apareció en la película "Down and Out in Beverly Hills", anotándose su primer gran éxito con el tema "Great Gosh-a-Mighty!", lo que condujo a un resurgimiento de su popularidad. También en este año, cuando se abrió el Rock and Roll Hall of Fame, Richard figuraba entre los primeros artistas. Su contribución pionera al género también ha sido reconocida por el Rockabilly Hall of Fame.

En 2005 estuvo trabajando en otros éxitos de R&B y "soul". Junto con el cantante y compositor Michael Jackson lanzó el sencillo titulado "I Have A Dream" (Tengo un sueño), los ingresos se destinaron a las víctimas del huracán Katrina.

También en 2005 apareció, junto a estrellas como Madonna, Iggy Pop, Bootsy Collins, y The Roots, en un anuncio comercial para la televisión americana, promocionando el teléfono Motorola ROKR.

Además salió en un capítulo de Los Simpson (temporada 14 capítulo 7) interpretándose a sí mismo.

Falleció a los 87 años el 9 de mayo de 2020, según lo informó en su momento la Rolling Stone Magazine. Enfrentaba varias dolencias desde hacia varios años. El reverendo Bill Minson, un amigo cercano del artista, confirmó el deceso a la AFP. La causa de su muerte se reportó como producto de un cáncer óseo.







</doc>
<doc id="15387" url="https://es.wikipedia.org/wiki?curid=15387" title="Rock (desambiguación)">
Rock (desambiguación)

Rock puede referirse a:


Asimismo, puede hacer referencia a las siguientes localidades o divisiones administrativas de Estados Unidos:


Inglaterra:

También, puede referirse a los siguientes autores de nombres científicos:


Además, puede hacer referencia a:


</doc>
<doc id="15388" url="https://es.wikipedia.org/wiki?curid=15388" title="Placebo">
Placebo

«Placebo» puede referirse a:


</doc>
<doc id="15389" url="https://es.wikipedia.org/wiki?curid=15389" title="Nymphaea alba">
Nymphaea alba

El nenúfar blanco europeo (Nymphaea alba, también llamado coberteras, escudete de Europa, golfán blanco, ninfa blanca, rosa del amor, rosa de Venus, aguapé blanco o azucena de agua) es una planta acuática de la familia de las ninfáceas, que habita los cursos de agua tranquilos y los estanques en las regiones templadas de Europa, tolerando incluso aguas contaminadas. Florece entre junio y septiembre y se recolecta en verano y otoño.

Tiene un rizoma carnoso y horizontal, que se arraiga al fondo del espejo de agua en el que habita. Las hojas flotan, al cabo de largos peciolos; son grandes, cordiformes y bien lobuladas, de textura coriácea y color verde claro. Las flores son solitarias, hermafroditas, con un largo pedúnculo y de coloración blanca a rosada; el cáliz se compone de cuatro sépalos, y la corola de hasta una cincuentena de pétalos gruesos. Los estambres son numerosos, provistos de anteras amarillas. La polinización puede ser autógama o entomógama. El fruto, un aqueno, disemina las semillas por hidrocoria. "2n" = 56, 84.

Se distingue del estrechamene emparentado nenúfar blanco boreal, "Nymphaea candida" , por el número de cromosomas en las células somáticas (2n = 84). Se conocen dos subespecies, "Nymphaea alba" subsp. "alba", ya descrita por Linneo, y "Nymphaea alba" subsp. "occidentalis"

China, India, Rusia, Cadeaso, Marruecos, Argelia, Túnez, suroeste de Asia, Europa. También ha sido introducida en otros países como Chile.

Irritado de los desprecios de la diosa Diana, Cupido tomó un día sus flechas, montó su arco, cogió una de ellas y la apuntó al corazón de Diana. La flecha voló a su blanco, pero no hirió a Diana, quien en un rápido movimiento logró esquivarla. Sin embargo, la flecha atravesó el seno de Ninfea, una de las ninfas de Diana.

Ninfea quedó así enamorada, y su corazón experimentó lo que nunca antes había sentido; un ardor desconocido la consumía. Se debatió entonces entre un deseo ciego y el pudor. Maldijo las leyes austeras, y amargamente se quejó del yugo que le imponía la necesidad. Trató dentro de sí de arrancar la flecha, pero no pudo. Lanzando gemidos y quejas se lanzó a los bosques. «¡Oh, pudor! -exclamó-; tú, el más precioso y más bello adorno de una ninfa sagrada; si mi espíritu es culpable para contigo de un sentimiento vivo que te ofende, mi cuerpo todavía está inocente; que sea suficiente esta víctima para tu cólera excelsa; que esta pura onda me lave de un crimen que concebí para mi pena, y que mi voluntad con horror detesta.» Así dijo, y levantando al cielo sus ojos, anegados de lágrimas, se precipitó a las aguas. Sus compañeras mientras tanto la buscaban. Las dríades finalmente la encontraron. Diana deploró el horrible destino de Ninfea, pero no permitió que su cuerpo se sumergiera. Sobre las ondas del agua, lo hizo flotar, y lo convirtió en la flor que lleva por nombre nenúfar, de una blancura brillante, con un tallo majestuoso de anchas hojas verdes. Desde entonces, las aguas que rodean al nenúfar son tranquilas y calmas. 

Quiso Diana que, puesto que Ninfea había calmado los fuegos de la pasión del hijo de Venus en el frío elemento del agua, así mismo el nenúfar tuviera la propiedad de calmar, y de embotar los sentidos para no entregarse a los ardores de la voluptuosidad.

Desde ese tiempo, las ninfas no temen ya a las flechas de Cupido, pues el humilde nenúfar las protege y les sirve como antídoto a los ataques del Amor.

Se le ha atribuido propiedades medicinales como antiafrodisíaco, calmante y Anticolinérgico. Antiguamente se usaba en conventos y seminarios en forma de infusión. Supuestamente puede usarse en ninfomanías y erectismo genital.

Las semillas pueden usarse como sucedáneo del coffea y las flores pueden conservarse en salmuera.

Sin embargo, el cultivo de "N. alba" es principalmente ornamental; una variedad de color rojo, procedente del lago Fagertärn en Tividen, Suecia, es particularmente popular, aunque su recogida del ámbito silvestre está severamente restringida hoy en día.

Adarga, adarga de río, cobertera, coberteras, cuencos, escudete blanco, escudete de río, escudetes de río, escudillos, flores de escudete, flores nenúfares, flores ninfeos, golfan blanco, golfán, golfán blanco, hierba de escudete, higos de agua, higos del río, higos de río, nenúfar, nenúfar blanco, nenunfar, nimfea blanca, ninfa, ninfa blanca, ninfa de la flor blanca, ninfea, ninfea blanca, ninfea de flor blanca, nínfea, platos, rosa de amor, rosa de Venus, yerba de adarga, yerba de escudete.


</doc>
<doc id="15390" url="https://es.wikipedia.org/wiki?curid=15390" title="Siemens (unidad)">
Siemens (unidad)

Se denomina siemens (símbolo: S) a la unidad derivada del SI para la medida de la conductancia eléctrica, que se representa con el símbolo G. Se nombró así por el ingeniero alemán Werner von Siemens. Su inversa es la resistencia eléctrica, que se representa por la letra R y cuya unidad es el ohmio.

formula_1

En donde I es la intensidad eléctrica o corriente eléctrica, y V es el voltaje (tensión o diferencia de potencial eléctrico).

Esta unidad también se denominaba mho (por ser la unidad inversa al ohmio), porque la conductancia es la inversa de la resistencia, pero este nombre no está en las actuales normas. Se representaba con una mayúscula (Ʊ) —una letra omega mayúscula invertida (℧)—.

En el dibujo anterior está representando que la conductancia eléctrica es inversamente proporcional a la resistencia eléctrica, pero con la notación antigua.

A continuación una tabla de los múltiplos y submúltiplos del Sistema Internacional de Unidades.



</doc>
<doc id="15392" url="https://es.wikipedia.org/wiki?curid=15392" title="Arte contemporáneo africano">
Arte contemporáneo africano

Muchas de las denominadas artes tradicionales de África están todavía en pleno uso y vigencia.

Como en todos los periodos artísticos, coexisten actualmente en África importantes innovaciones junto con significativos conservadurismos estilísticos. En años recientes, los avances en los medios de comunicación experimentados en el continente africano han facilitado la dispersión y difusión a gran escala de las diversas formas artísticas entre sus distintas culturas. Hoy, por ejemplo, algunas máscaras de estilo nigeriano se están usando con asiduidad entre las poblaciones de Ghana y otras tribus de la costa de Guinea.

El arte africano ha estado también sujeto a influencias exteriores. Por ejemplo, la arquitectura y los motivos decorativos islámicos pueden verse en muchas de las manifestaciones artísticas de la zona norte, especialmente en Nigeria, Malí, Burkina Faso y Níger. Motivos estampados similares a los utilizados en la India, se han encontrado en las esculturas y máscaras de los ibibio y efik, a lo largo de la costa sur de Nigeria.

Algunos artistas contemporáneos han adoptado temas cristianos para los diseños de puertas, artesonados y pilas bautismales de las iglesias y catedrales del África cristiana.

En fechas recientes, los artistas han encontrado sus principales fuentes de mecenazgo en los bancos, establecimientos comerciales, oficinas gubernamentales y cortes de los nuevos países. El turismo también ha contribuido a favorecer la demanda de arte africano, especialmente máscaras decorativas y esculturas ornamentales de ébano o marfil, dentro de los límites oficialmente permitidos.

El desarrollo de las escuelas de arte y arquitectura en las ciudades del África subsahariana ha alentado a los artistas a trabajar en nuevos materiales, como el cemento, el óleo y otras pinturas, tinta, piedra, aluminio y una gran variedad de medios gráficos. Las imágenes y diseños así creados reflejan una vibrante fusión entre la tradición africana y el Occidente contemporáneo.

Artistas como Twins Seven Seven y Ashira Olatunde, ambos de Nigeria, o Nicholas Mukomberanwa, de Zimbabue, o Eric Adjetey Anang, de Ghana se cuentan entre los más brillantes seguidores de estas nuevas formas de creación artística.



</doc>
<doc id="15393" url="https://es.wikipedia.org/wiki?curid=15393" title="Conductancia eléctrica">
Conductancia eléctrica

Se denomina conductancia eléctrica (símbolo G) a la facilidad que ofrece un material al paso de la corriente eléctrica, es decir, que la conductancia es la propiedad inversa de la resistencia eléctrica. Se mide en siemens (S). 

No debe confundirse con conducción, que es el mecanismo mediante el cual las cargas fluyen, o con conductividad, que es la conductancia específica de un material.

Este parámetro es especialmente útil a la hora de tener que manejar valores de resistencia muy pequeños, como es el caso de los conductores eléctricos.

Como ya se mencionó, la relación entre la conductancia y la resistencia está dada por:

donde:

Para el caso reactivo, la conductancia se puede relacionar con la susceptancia y la admitancia mediante la siguiente ecuación:

o por:

donde



</doc>
<doc id="15396" url="https://es.wikipedia.org/wiki?curid=15396" title="Teogonía">
Teogonía

La Teogonía (del griego Θεογονία "Theogonía"; lit. ‘origen de los dioses’) es una obra poética escrita por Hesíodo. Contiene una de las más antiguas versiones del origen del cosmos y el linaje de los . Es una de las obras claves de la épica grecolatina. Se discute si debe fecharse en el siglo o en el a. C.

La obra está construida a partir de géneros poéticos preexistentes que hasta el momento habían pertenecido a la tradición oral en Grecia: cosmogonías, teogonías, genealogías, catálogos y mitos de sucesión. Los tres primeros géneros pueden aparecer fundidos, vertebran la obra y están ordenados con un criterio aproximadamente cronológico. Los mitos de sucesión, a pesar de que pueden ser considerados como digresiones dentro de los bloques genealógicos, le dan sentido a toda la obra.

El proemio tiene dos bloques: 
finaliza con una invocación (v. 105 - 115) que marca la transición a la parte principal del poema.

Compositivamente el proemio no se distingue esencialmente de la estructura de otros proemios conservados, como los Himnos homéricos: su estructura ternaria (anuncio del tema del himno, relato de algún episodio de la vida del dios celebrado, invocación de cierre pidiendo su favor) lo vincula a formas de la lírica.
Aquí son mencionados un conjunto de deidades que representan elementos cósmicos, en forma genealógica.


Sigue una genealogía de carácter más marcadamente teogónica:

puesto que aunque allí se mencionan deidades que representan elementos (como Océano, Hiperión, Rea), colectivamente aparecen dioses más antropomórficos que los anteriores: los Titanes, Cíclopes y Hecatonquiros.

Como cierre de este bloque aparece, como primera parte del mito de sucesión, el

Sigue un conjunto de genealogías en mera yuxtaposición, con importantes digresiones épicas que contienen el resto del mito de sucesión.


Hijos de Zeus (v. 886 - 929)


Hacia el final el poema pierde su hilo:






</doc>
<doc id="15397" url="https://es.wikipedia.org/wiki?curid=15397" title="Wilfredo Gómez">
Wilfredo Gómez

Wilfredo Gómez (San Juan, 29 de octubre de 1956) es un exboxeador puertorriqueño tres veces campeón mundial. Es considerado por muchos, junto a Carlos Ortiz, Esteban de Jesús, Wilfred Benítez, Juan Laporte, Héctor Camacho, Edwin Rosario, Félix Trinidad y Miguel Cotto, los mejores boxeadores de Puerto Rico. apodos sobre el ring fueron "Bazooka" y "El niño de Las Monjas".

Campeón mundial aficionado en Cuba en 1974, Gómez se vio forzado a vivir en Panamá por varios años, debido a que no podía encontrar oponentes en Puerto Rico. Debuta como profesional en Panamá, siendo relegado a un empate a seis asaltos por Jacinto Fuentes. Después de esa pelea, encadenó un total de 32 victorias corridas por la vía del nocaut, entrando así en el grupo exclusivo de boxeadores con 20 o más victorias por nocaut seguidas. Su cadena de nocauts consecutivos lo sitúa en tercer lugar entre todos los boxeadores en cuanto a victorias conseguidas por nocaut, solo superado por Lamar Park, con 44, y Billy Fox con 43. Sin embargo, entre los campeones mundiales el y Deontay Wilder son los que más larga cadena de nocauts lograron a través de la historia, pues Park y Fox no fueron campeones mundiales. Cuando Wilder ganó su título mundial peso completo (o pesado) del Consejo Mundial de Boxeo al derrotar por puntos a Bermane Stiverne, el empató con Gómez en cuanto a campeones mundiales con la racha las larga de victorias por nocaut en la historia, pero al mismo tiempo aseguró no poder quebrar el récord ahora perteneciente a él y a Gómez. 

En 1977, y aún en medio de esa cadena de victorias por nocaut, el campeón mundial super-gallo del Consejo Mundial de Boxeo (CMB), Dong Kiung Yum de Corea del Sur, viaja a Puerto Rico a defender la corona mundial ante Gómez. Gómez visitó la lona en el primer asalto de este combate, pero se recuperó y noqueó a Yem en doce asaltos, coronándose campeón mundial por primera vez. 

Gómez defendió el título con éxito 17 veces, todas por nocaut, estableciendo un récord mundial de defensas consecutivas por nocaut en cualquier división,y también el récord de defensas en el peso Super-gallo. Entre otros, derrotó a los campeones mundiales Leo Cruz, Juan Meza, Lupe Pintor y Carlos Zárate. A Zarate lo derrotó en cinco asaltos, y su pelea contra Pintor, la cual duró catorce asaltos, se considera por críticos y expertos como una de las mejores peleas en la historia.

El 21 de agosto de 1981, Gómez sube de peso para retar al campeón mundial categoría pluma del CMB, Salvador Sánchez. En lo que muchos consideran la victoria más grande de un mexicano sobre un puertorriqueño en la historia del boxeo, Sánchez derrota a Gómez por nocaut en el octavo asalto, sorprendiendo inclusive a los apostadores de Las Vegas, ciudad sede del combate, que daba a Gómez favorito para ganar. 

Gómez bajó de peso inmediatamente, para defender la corona super-gallo cuatro veces más, con la esperanza de que Sánchez le diera una revancha. Dicha revancha nunca llegó, sin embargo, pues Sánchez falleció, el 12 de agosto de 1982, en un accidente de auto en la carretera San Luis Potosí - Querétaro.Entre sus 4 defensas en 1982, destacan los combates ante Juan Meza, futuro campeón mundial peso Super Gallo, noqueado en seis asaltos en Atlantic City, Nueva Jersey, y Lupe Pintor, en una pelea que es considerada generalmente entre los combates más emotivos y violentos en la historia del deporte, cuando Gómez, con lesiones en los ojos y los cachetes, logró derrotar al futuro miembro del salon de la fama internacional del boxeo por nocaut en el asalto número catorce. Mientras esto sucedía, Juan Laporte, otro puertorriqueño, se coronaría campeón mundial pluma del CMB al conquistar la corona dejada vacante por la muerte de Sánchez.

En 1984, Gómez sube de peso nuevamente y reta a Laporte, resultando triunfador esta vez, por decisión unánime en doce asaltos. Habiendo conquistado su segundo título mundial, Gómez esperó nueve meses para defender su corona, pero perdió el título en su primera defensa, cayendo noqueado en once asaltos ante Azumah Nelson, de Ghana.

Gómez comenzó 1985 esperando una revancha con Nelson o una oportunidad ante el campeón mundial ligero júnior de la Asociación Mundial de Boxeo (AMB), Rocky Lockridge. Lockridge aceptó pelear con Gómez, de manera que Gómez subió de peso nuevamente, y el 19 de mayo de ese año, se convierte en el octavo boxeador en conquistar tres coronas mundiales, además de ser el cuarto latinoamericano y el segundo puertorriqueño en lograr tal hazaña, al derrotar a Lockridge por una cerrada decisión dividida en quince asaltos.

Al igual que cuando reinó en el peso pluma, Gómez perdió la corona ligero júnior en su primera defensa, noqueado en nueve asaltos por el panameño Alfredo Layne, quien fue ejecutado por sicarios colombianos en 1999 al estar involucrado en una transacción de cocaína en la que se robó el cargamento pactado, por lo cual fue torturado y asesinado en la Ciudad de Panamá. 

Tras dos victorias adicionales en 1988 y 1989, Gómez anunció su retiro. Luego vivió en Venezuela y Colombia antes de regresar a su patria. En 1995 Gómez fue elegido miembro del Salón de la Fama Internacional del Boxeo. Durante su período de campeón mundial super-gallo, de 1977 a 1983, Gómez logró ser considerado un héroe nacional en Puerto Rico, título que la mayoría de puertorriqueños aún le concede.

Gómez tuvo un récord de 44 victorias, 3 derrotas y un empate, con 42 victorias por nocaut.



</doc>
<doc id="15398" url="https://es.wikipedia.org/wiki?curid=15398" title="Hominidae">
Hominidae

Los homínidos (Hominidae) son una familia de primates hominoideos, que incluyen cuatro géneros y ocho especies vivientes, entre las cuales se hallan los humanos, orangutanes, gorilas, chimpancés y bonobos .

En la clasificación tradicional, la familia Hominidae estaba compuesta exclusivamente por primates bípedos (géneros "Homo", "Australopithecus", "Paranthropus", etc.). Actualmente, según la taxonomía cladística cuyo uso se está imponiendo en primatología, los Hominidae incluyen además a los grandes simios (géneros "Gorilla", "Pan", y "Pongo") anteriormente clasificados en la familia de los póngidos. En la mayor parte de los trabajos científicos actuales, los homínidos bípedos son ahora clasificados en la subtribu Hominina [""].

Por tanto, existe una cierta confusión de términos:


Estudios realizados con técnicas moleculares del ADN indican que los chimpancés, gorilas y humanos forman un clado, con los orangutanes un poco más separados filogenéticamente. Salvo el orangután (nativo de Asia, específicamente Borneo y Sumatra), los actuales simios homínidos; humanos, chimpancés y gorilas son originarios de África (si bien en el caso del humano se extendió por todo el mundo). Sin embargo se han encontrado fósiles de homínidos en Europa y diversos lugares de Asia y África, procedentes del Mioceno (cerca de 20 millones de años antes del presente). No existen evidencias físicas de que haya ningún tipo de homínido nativo de América, y el único simio homínido que cruzó de Eurasia a América de forma natural fue "Homo sapiens" [].

Los homínidos son los primates más grandes, con un peso que oscila de 48 kg a 270 kg. En general, los machos son mayores que las hembras (dimorfismo sexual), con cuerpos robustos y brazos bien desarrollados. Tienen numerosas diferencias con respecto al esqueleto de los otros primates, especialmente relacionadas con su porte vertical.

Se caracterizan por su adaptación a la postura y marcha erectas, acortamiento de las extremidades superiores y evolución de la mano hacia una mayor funcionalidad; la regular proporción en las dimensiones de sus dientes, yuxtapuestos sin diastemas, describiendo un arco parabólico corto, con premolares inferiores homomorfos, bicuspidado el primero; y, en fin, el incremento progresivo de la capacidad craneal y la complejidad del cerebro, alojado bajo una bóveda cada vez más elevada.

Todos los miembros de esta familia tienen cerebros relativamente grandes y complejos. Tienen las narinas próximas una de otra y orientadas hacia el frente y hacia abajo. La fórmula dental es la misma en todos los miembros de este grupo: 2/2, 1/1, 2/2, 3/3 = 32 dientes.

Los homínidos son omnívoros, aunque la base de su alimentación suelen ser las frutas y vegetales: en el caso del chimpancé, pueden incluir pequeños invertebrados o incluso mamíferos, lo que constituye menos del 2% de su dieta. Otra característica es la complejidad de su comportamiento social, expresión facial y vocalización compleja. Todos construyen nidos o refugios y cuidan mucho a sus crías durante un largo período; las hembras tienen generalmente una cría en cada gestación.

Las ocho especies vivientes de homínidos se clasifican en cuatro géneros. La siguiente clasificación es la más aceptada:
Adicionalmente a las especies y subespecies anteriores, los paleoantropólogos han descrito numerosos géneros y especies extintos:


La siguiente tabla enlista el número estimado de grandes simios que viven fuera de zoológicos.



</doc>
<doc id="15399" url="https://es.wikipedia.org/wiki?curid=15399" title="Humor gráfico">
Humor gráfico

Humor gráfico es un neologismo con el que se designa a una gama diversa de obras gráficas realizadas para la prensa, desde chistes de una sola viñeta y caricaturas hasta verdaderas historietas, tiras cómicas e incluso planchas enteras. Muchas abundan en la sátira de la actualidad política y social.

Hasta mediados del siglo XX, la viñeta de prensa se llamó caricatura, y el humorista gráfico, caricaturista. En las páginas de "The New Yorker", que influyen en la mayoría de publicaciones en todo el mundo, nace el "nuevo estilo de hacer humor". 

Los renovadores del género son los estadounidenses Chas Addams, Peter Arno, George Price, Virgil Partch (VIP) y sobre todo Saul Steinberg. También los franceses Chaval, Jean Bosc, André François y Siné. 

En España confluyen varias tradiciones satíricas distintas. En el norte sobresalen los autores gallegos, con Castelao a la cabeza. En el centro hay una escuela de sátira costumbrista, con Tovar, Sileno, Fresno y K-Hito, a los que se añade el catalán Bagaria. En Valencia hay una tradición satírica propia, con nombres como Bluff, Tramús o Juan Pérez del Muro, además de Ernesto Guasp que desarrollará su carrera en la prensa catalana y mexicana. Finalmente en Cataluña hay una importante escuela satírica, con características propias, que se remonta a Pellicer y Apeles Mestres, e incluye a Cornet, Junceda, Opisso, Nogués, Passarell o Bon.

En México, nombres como Salvador Pruneda, Audiffred o García Cabral, son los precursores de la generación de Freyre, Arias Bernal, Vadillo o Carreño, que anteceden a Rius, Quezada, Helioflores o Naranjo.

En Argentina podemos considerar precursores a José María Cao, Mayol, Alejandro Sirio, o Mario Zavattaro. También humoristas gráficos como Arturo Lanteri, Dante Quinterno, Guillermo Divito, Adolfo Mazzone, Héctor Torino, Landrú, Oski. En el año 2009, en la muestra "Bicentenario: 200 años de Humor Gráfico" que el Museo del Dibujo y la Ilustración realizó en el Museo Eduardo Sívori de Buenos Aires, se homenajeó a los más importantes creadores del Humor Gráfico en Argentina a través de su historia. Desde 2012 se encuentra el Centro de Historieta y Humor Gráfico Argentinos en la Biblioteca Nacional que adquiere, identifica y colecciona para su preservación, conservación, estudio, valorización y difusión, la producción historietística y humorística argentina. Es el único fondo documental público y nacional abarcativo de toda la producción histórica de estos medios y lenguajes en la Argentina. 

Y en Cuba a Blanco, Valls, Massaguer, Maribona y Avela, que anteceden a Sergio Ruiz, Fresquito Fresquet, Chago, Fornés, Niko, Jesús de Armas, René de la Nuez, David, entre otros.

La Guerra Civil en España acaba con la tradición humorística anterior. En la revista "La Codorniz", de Tono, Mihura y Herreros, se darán a conocer humoristas como Mingote, Chumy Chúmez, Miguel Gila, Summers o Pablo. También destacan Carlos Conti, Joaquim Muntañola, Peñarroya y Castanys, y a partir de la transición, nombres nuevos como El Perich, Cesc y Ops.

Desde poco antes de la muerte de Franco se produce el "boom del humor gráfico". Hay un gran número de revistas y libros de humor. En 1977, más de cien profesionales de la historieta y el humor gráfico se integraron en la Asociación de Artistas Plásticos, buscando un mayor reconocimiento de sus derechos. Carecen entonces de ""las mínimas condiciones de contratos, seguridad social, seguro de desempleo"" y ""la propiedad intelectual de sus obras no es reconocida con la eficacia que lo son otras obras de otros sectores"". 

En la actualidad los principales humoristas están en la revista "El Jueves": Óscar, J.L. Martín, Kim, Fer, Vizcarra, Monteys, Manel Fontdevila, Malagón, etc.

Y en la prensa diaria: Gallego & Rey, Idígoras & Pachi, Guillermo, Ricardo (El Mundo); Mingote, Martinmorales, Puebla (ABC); El Roto, Peridis, Forges, Ramón, Máximo, Carlos Romeu Müller (El País); Juan Kalvellido (La República, Diagonal, Rebelión, etc), Caín, Turcios (La Razón); Manel Fontdevila, Santi Orúe, Vergara, Mauro Entrialgo (Público); Ferreres, Tàssies, Juanjo Sáez (El Periódico); Ventura & Coromina, Toni, Krahn, Kap, Labanda(La Vanguardia); Zulet (El Correo); Soria, Mesamadero (Ideal), Eneko, Calpurnio (20 minutos); Rodera (Adn), Xaquín Marín(La voz de Galicia), Sabela Arias Castro (Tierras de Santiago); Tris (La Rioja)…

En la prensa deportiva encontramos a Guillermo ("Marca"), Caye ("Sport"), Kap ("El Mundo Deportivo") y Bernal ("Equipo").

El Internet son destacables Juan Ramón Mora, Runtime-Error, Mel y las plataformas digitales que le brindan los medios a sus respectivos dibujantes, por ejemplo a Mauro Entrialgo, Ferran Martín, Manel Fontdevila o Daniele.

En dos libros colectivos editados en 2007 se puede encontrar lo más representativo del humor español contemporáneo: Humor a Toda Vela, y Comunica con Humor.

En 2016 abre oficialmente sus puertas Humoristán , el primer museo digital dedicado íntegramente al humor gráfico. En marzo de 2017 publica un pdf gratuito de 46 páginas " Un año de humor gráfico, informe Humoristan 2016 ". 

En "Picardía mexicana", libro del escritor mexicano Armando Jiménez, aparece un capítulo con algunos ejemplos de humor gráfico mexicano, sobre todo el de doble sentido.


En Costa Rica se encuentra particularmente el trabajo de Hugo Díaz, quien se destacó por la publicación de su obra en el Semanario Universidad.




</doc>
<doc id="15405" url="https://es.wikipedia.org/wiki?curid=15405" title="Gobierno de Colombia">
Gobierno de Colombia

Colombia es un país presidencialista, y un Estado unitario con separación de poderes ejecutivo, legislativo y judicial.
La Constitución política vigente fue proclamada el 4 de julio de 1991. El 60° Presidente de la República, los gobernadores departamentales son los que se encargan de hacer cumplir los reglamentos de la nación

La constitución política define en la estructura del estado colombiano mediante la división del poder público en tres ramas: la ejecutiva, la legislativa y la judicial. Sin embargo, dado que existen funciones del estado que estas entidades no cumplen, se nombran los órganos para la realización de estas como son: el Ministerio público, la Contraloría General, el Consejo Nacional Electoral, la Registraduría Nacional, el Banco de la República, la Comisión de Regulación de Comunicaciones y la Comisión Nacional del Servicio Civil, entre otras.

Es el encargado de administrar los recursos de la nación. El Presidente de la nación y Jefe de Gobierno es la cabeza del poder ejecutivo, el cual comparte con un Gabinete ministerial . Además es el comandante en jefe de las Fuerzas Militares El gabinete se compone, además del presidente y el vicepresidente, de los ministros de despacho y los directores de departamentos administrativos. La rama ejecutiva tiene tres niveles: presidente(orden nacional), gobernadores(orden departamental) y alcaldes(orden municipal) 

El presidente es elegido por voto popular directo para un período de cuatro años o menos, en caso de sustitución. La Constitución de 1991 prohibía la reelección presidencial de por vida y con anterioridad era posible la reelección mediata (un expresidente podía ser reelegido pero el presidente en ejercicio no podía ser reelegido para el período siguiente). Con referendo constitucional en 2005 esta prohibición fue abolida y se legalizó la reelección inmediata por una sola vez. Dos presidentes hicieron uso de ella pudiendo participar en las elecciones desde el cargo. Actualmente con el acto legislativo 02 de 2015 se prohíbe la reelección presidencial.


Se encarga de elaborar las normas y leyes. Ejercer control sobre el Gobierno y reformar la Constitución.
Un Congreso bicameral formado por el Senado (100 miembros elegidos por circunscripción nacional por un periodo de cuatro años y un número adicional de 2 senadores elegidos en circunscripción especial por comunidades indígenas) y la Cámara de Representantes, conformada por ciento sesenta y seis miembros elegidos por 4 años, de los cuales ciento sesenta y uno representan a las circunscripciones territoriales (departamentos y el Distrito Capital).

Se encarga de aplicar la ley de manera justa y resuelve conflictos entre las personas de acuerdo a la ley. Le corresponde administrar justicia, solucionar los conflictos y controversias entre los ciudadanos y entre estos y el Estado y decidir cuestiones jurídicas controvertidas mediante pronunciamientos que adquieren fuerza de verdad definitiva. Dichos pronunciamientos toman principalmente la forma de sentencias, fallos, o autos. Es la encargada hacer efectivos los derechos, obligaciones, garantías y libertades consagradas en la Constitución y en las leyes, con el fin de lograr y mantener la convivencia social. 

El poder judicial de Colombia empieza a partir de la Constitución Política de 1991. Es conformado por la Corte Suprema de Justicia, la Corte Constitucional, el Consejo de Estado, el Consejo Superior de la Judicatura, así como los tribunales y juzgados. La Fiscalía General de la Nación es un organismo independiente adscrito a la rama judicial del Poder Público en Colombia.

Es el conjunto de entidades encargadas de la organización de las elecciones, su dirección y vigilancia, así como lo relativo a la identificación de las personas.


Son entidades del Estado, con autonomía a las tres ramas del poder, según la Constitución o las leyes debido a su especialidad funcional.


Son aquellos organismos a los que la Constitución Política les confía las funciones relacionadas con el control disciplinario, defender al pueblo y el control fiscal. No están adscritos ni vinculados a las Ramas del poder público.


Los departamentos tienen gobernadores y corporaciones públicas propias elegidos por sufragio cada cuatro años. Se subdividen en municipios y algunos distritos con un alcalde y un concejo municipal, electos también cada cuatro años por votación directa.

Según el Consejo Nacional Electoral de Colombia, el reconocimiento de la UP, y la creación del partido de la FARC, las organizaciones políticas que en la actualidad cuentan con personería jurídica en Colombia son 16:




</doc>
<doc id="15409" url="https://es.wikipedia.org/wiki?curid=15409" title="Noam Chomsky">
Noam Chomsky

Avram Noam Chomsky (Filadelfia, 7 de diciembre de 1928) es un lingüista, filósofo, politólogo y activista estadounidense de origen judío. Es profesor emérito de lingüística en el Instituto Tecnológico de Massachusetts (MIT) y una de las figuras más destacadas de la lingüística del , gracias a sus trabajos en teoría lingüística y ciencia cognitiva. También es reconocido por su activismo político, caracterizado por una fuerte crítica del capitalismo contemporáneo y de la política exterior de los Estados Unidos. Se le considera de pensamiento socialista libertario. El "New York Times" lo ha señalado como «el más importante de los pensadores contemporáneos».

Propuso la gramática generativa, disciplina que situó la sintaxis en el centro de la investigación lingüística. Con este paradigma, cambiaron la perspectiva, los programas y métodos de investigación en el estudio del lenguaje. Su lingüística es una teoría de la adquisición individual del lenguaje e intenta explicar las estructuras y principios más profundos del mismo. Postuló un aspecto bien definido de innatismo en la adquisición del lenguaje y la autonomía de la gramática (sobre los otros sistemas cognitivos), así como la existencia de un «órgano del lenguaje» y de una gramática universal. Se opuso con dureza al empirismo filosófico y científico y al funcionalismo, en favor del racionalismo cartesiano. Todas estas ideas chocaban frontalmente con las tradicionales de las ciencias humanas, lo que concitó múltiples adhesiones, críticas y polémicas que le han acabado convirtiendo en uno de los autores más citados.

Destaca su contribución al establecimiento de las ciencias cognitivas a partir de su crítica del conductismo de Skinner y de las gramáticas de estados finitos, poniendo en tela de juicio el método basado en el comportamiento del estudio de la mente y el lenguaje que dominaba en los años cincuenta. Su enfoque naturalista en el estudio del lenguaje ha influido en la filosofía del lenguaje y de la mente (ver a Harman y a Fodor). Es el descubridor de la jerarquía de Chomsky, una clasificación de lenguajes formales de gran importancia en teoría de la computación.

También es conocido por su activismo político y por sus críticas a la política exterior de Estados Unidos y de otros países, como Israel. Chomsky, que desvincula completamente su actividad científica de su activismo político, se describe a sí mismo como simpatizante del anarcosindicalismo (es miembro del sindicato IWW). Chomsky es considerado una figura influyente en su país de origen y en el mundo.

Noam Chomsky nació el 7 de diciembre de 1928 en Filadelfia (Pensilvania), hijo del doctor William (Zev) Chomsky (estudioso de la lengua hebrea y uno de sus más distinguidos gramáticos) y de Elsie Simonofsky, maestra de hebreo. Ambos eran inmigrantes judeo-ucranianos. Desde 1945, estudió filosofía, lingüística y matemática en la Universidad de Pensilvania. Allí estuvo bajo la tutela del profesor Zellig Harris (también inmigrante judeo-ucraniano, fundador del primer departamento especializado en lingüística en Norteamérica). Harris y Elsie influyeron más que Zev en la formación de su ideología política. También por influencia de Zellig Harris, Chomsky comenzó a tomar clases de matemáticas y filosofía. Uno de sus maestros fue el filósofo Nelson Goodman, quien más tarde los presentaría en la Society of Fellows de Harvard. Recibió su doctorado en 1955, después de llevar a cabo la mayor parte de sus investigaciones en la Universidad de Harvard durante los cuatro años anteriores. En 1998 recibió el Doctorado honoris causa (lingüística) de la Universidad Rovira i Virgili. Recibió esta misma distinción por parte de la Universidad Nacional de Colombia en 2002, de la Universidad de Chile y de la Universidad de la Frontera en 2006 y de la Universidad Nacional Autónoma de México en 2010.

En su tesis doctoral comenzó a desarrollar algunas de sus ideas en lingüística, elaborándolas luego en su libro "Estructuras sintácticas", posiblemente su trabajo más conocido en este campo. Sus planteamientos lingüísticos han revolucionado muchos puntos clave del estudio del lenguaje humano, que se han plasmado en la teoría de la Gramática generativa transformacional.

Es profesor del Massachusetts Institute of Technology (MIT) desde 1961, donde ocupó la cátedra Ferrari P. Ward de Lenguaje Moderno y Lingüística de 1966 a 1976.

En abril de 2019 es reconocido con el Premio Fronteras del Conocimiento en la categoría de Humanidades y Ciencias Sociales. El jurado recogió en el acta que Chomsky ha situado la investigación de la mente humana y sus productos “en una nueva y fructífera vía que abarca la lingüística teórica, la psicolingüística, las ciencias cognitivas, las filosofías del lenguaje y de la mente y la psicología cognitiva”. 

Su cónyuge fue Carol Schatz, quien murió el 20 de diciembre de 2008. Tiene dos hijas y un hijo.

En 1957, con solo veintinueve años, Chomsky revolucionó el campo de la lingüística teórica con la publicación de la obra "Estructuras sintácticas", basada en su tesis doctoral ―"Estructura lógica de la teoría lingüística"―, que no se publicaría hasta 1975. Su efecto sobre las teorías lingüísticas y psicológicas entonces en boga fue demoledor, ya que atacaba los presupuestos centrales tanto del estructuralismo como de la psicología conductista. Hasta entonces, se creía que la adquisición del lenguaje, como cualquier otra destreza humana, se producía por medio del aprendizaje y de la asociación. Sin embargo, Chomsky postulaba la existencia de un dispositivo cerebral innato (el «órgano del lenguaje»), que permite aprender y utilizar el lenguaje de forma casi instintiva. Comprobó además que los principios generales abstractos de la gramática son universales en la especie humana y postuló la existencia de una Gramática Universal.

La Gramática Universal de Chomsky asegura que el fundamento común de la lenguas humanas es su recursividad, un proceso, habitualmente asociado a la subordinación, que posibilita a un hablante a introducir oraciones en otras oraciones sin límite. Este principio sería el que permitiría a los seres humanos establecer una comunicación rica y compleja para distanciarse, por ejemplo, de los animales. Sin embargo, la teoría de la recursividad de Chomsky se puso en entredicho en el momento en el que el profesor Daniel Everett, después de convivir con la tribu indígena de los pirahã, descubrió presuntamente un idioma nuevo que contradice dicha teoría: el idioma pirahã. Este nuevo idioma, que carecería de numeración, tiempos verbales y colores, se caracterizaría por su simplicidad aunque, a pesar de que tendría una percepción simple y reducida del mundo, cumpliría con las necesidades comunicativas de la tribu. Este descubrimiento es muy controvertido, ya que el propio Everett es la única persona fuera de la tribu capaz de entenderlo.

Chomsky denominó gramática generativa al conjunto de reglas innatas que permite traducir combinaciones de ideas a combinaciones de un código. Fundamentó la hipótesis, ya existente, de que la gramática es un sistema combinatorio discreto que permite construir infinitas frases a partir de un número finito de elementos mediante reglas diversas que pueden formalizarse. La nueva teoría consideraba que las expresiones (secuencias de palabras) tienen una sintaxis que puede caracterizarse (globalmente) por una gramática formal; en particular, una gramática extendida por normas de transformación. A los niños se les supone un conocimiento innato de la gramática elemental común a todas las lenguas humanas (lo que supone que toda lengua existente es una clase de restricción). Se sostiene que la modelización del conocimiento de la lengua a través de una gramática formal explica la «productividad» de la lengua: con un juego reducido de reglas gramaticales y un conjunto finito de términos, los humanos pueden producir un número infinito de frases, incluidas frases que nadie haya dicho anteriormente.

"The Principles and Parameters approach" (P&P) ("Aproximación por principios y parámetros"), desarrollada en las "Conferencias" de Pisa (1979) y publicada más tarde bajo el título "Lectures on Government and Binding" (LGB), retoma mucho de la gramática universal: los principios gramaticales en los que se basan las lenguas son innatos y fijos; las diferencias entre las distintas lenguas en el mundo se pueden caracterizar en términos de parámetros programados en el cerebro (como el parámetro de elisión, "pro drop param", que indica cuándo un tema explícito es siempre requerido, como en inglés, o si este puede elidirse, como en español) a menudo comparados a interruptores (de ahí el término de principios y parámetros utilizado para calificar este enfoque). Según esta teoría, un niño que aprende una lengua solo necesita adquirir los elementos léxicos básicos (palabras, morfemas gramaticales y refranes) y fijar los valores convenientes en los parámetros, lo que puede efectuarse sobre algunos ejemplos clave.

Los partidarios de esta concepción ponen como ejemplo que la velocidad con la cual los niños aprenden lenguas es inexplicablemente rápida, algo no posible a menos que tengan una capacidad innata para aprenderlas. La similitud de las etapas que siguen todos los niños a través del mundo cuando aprenden una lengua, y el hecho de que cometan errores característicos cuando adquieren su primera lengua, mientras que otros tipos de error al parecer lógicos no se producen nunca (y, según Chomsky, estos deberían darse si el mecanismo de aprendizaje utilizado fuese general más que específico de una lengua), se postulan también como un argumento a favor de dicho innatismo.

Más recientemente, en su "Programa minimalista" (1995), conservando al mismo tiempo el concepto central de «principios y parámetros», Chomsky intenta una revisión importante de las máquinas lingüísticas implicadas en el modelo de LGB, despojándolos de todo excepto de los elementos estrictamente necesarios. Al mismo tiempo, preconiza un enfoque general de la arquitectura de la facultad de la lengua humana, destaca los principios de la economía y la concepción óptima y retorna al enfoque "derivacional" de la generación, en oposición con la mayor parte del enfoque "representativo" clásico del P&P.

Chomsky caracterizó la tarea del lingüista mucho mejor que ninguno de sus predecesores y fijó con todo rigor el campo para el estudio científico del lenguaje. Su objetivo nunca fue establecer una teoría especulativa más sobre el lenguaje, sino una explicación rigurosa de su complejidad. La intención era por tanto pasar de una pre-ciencia meramente descriptiva a una ciencia con poder explicativo y predictivo falsable y con construcciones abstractas que permitiesen un riguroso sistema axiomático. Nada ha sido igual desde entonces en el campo del estudio del lenguaje y, por extensión, de la mente humana. La gramática generativa de Chomsky fue la primera evidencia sólida de que la inteligencia humana está basada en dispositivos cerebrales especializados e innatos y eso ha permitido agrupar las ciencias cognitivas. También provocó una enorme escisión epistemológica, que todavía se mantiene, frente a quienes rechazan la concepción modular e innata de la mente y siguen siendo partidarios de un modelo de cerebro como "tabla rasa", como por ejemplo los psicólogos que trabajan con procesos de emergencia o las teorías conexionistas, que consideran la lengua como un caso particular de los procesos generales del cerebro.

Chomsky se ocupa de las lenguas naturales partiendo de una gramática universal propia de todos los seres humanos, de raíz biológica, de la cual derivan las distintas lenguas de las diversas culturas que han existido en la historia del hombre y que existen aún.

La diferencia entre la gramática universal (GU) y las distintas gramáticas particulares (GGPP) radica en que la primera se relaciona con la disposición de un conjunto de principios ―como el «principio de proyección», el «principio de dependencia de la estructura», el «principio de ligamiento», la «teoría del caso», el «criterio temático» y algunos otros―, mientras que las GGPP se vinculan a las múltiples variaciones que pueden hacer las lenguas de los parámetros de esos principios. Un ejemplo de esta variación se da en el «parámetro de los sujetos nulos», que en español se puede presentar mientras que en inglés no, como muestra el siguiente ejemplo:
Así, las GGPP no son más que combinaciones de elementos finitos que pueden dar lugar a múltiples lenguas e idiomas que en esta teoría son llamadas lengua-I.

El sistema encargado de articular estos principios y variar los parámetros es el cerebro humano con su capacidad de sintaxis, que en su sentido amplio adquiere la forma de un sistema computacional que opera en módulos. Los módulos responden a una estructura matriz compuesta por tres componentes, dentro de los cuales actúan los principios y parámetros definidos como una serie de teorías de lenguaje, conectadas con cuatro módulos centrales: la estructura-P, la estructura-S, la forma fonológica (FF) y la forma lógica (FL). La estructura-P conecta las oraciones con principios, mientras que la estructura-S apela a la transformación o variabilidad que pueden presentar dichas conexiones; además, la FF se vincula con la entonación y sonido de las expresiones lingüísticas o fonología y la FL se encarga de la semántica de estas expresiones en relación a su interpretación de sentido y significado.

En la estructura-P se encuentran las primeras relaciones entre léxico y sintaxis, como las relaciones sintagmáticas que establecen qué es sintagma verbal, sintagma nominal, sintagma adjetival o sintagma preposicional, entre otras relaciones categoriales.

La estructura-S señala acciones transformacionales o de parámetro, no solamente de principio como en la estructura-P. Un ejemplo es la operación "muévase α", en la que un elemento se mueve en la oración a otra posición. La estructura-S también sirve como conector entre dos módulos que no se relacionan directamente. El primero es la forma fonológica (FF), que se encarga de articular sonidos con formas léxicas a partir de fonemas definidos, como también de establecer las entonaciones de una pregunta o una afirmación, una suposición entre otras acciones ligadas a lo mismo.

Por último, la forma lógica, quizás la más compleja de todas, conecta con el ejercicio semántico de interpretación y significado en el sentido de un oración en la cual se encuentran a nivel léxico las redes temáticas y las selecciones S, como modos de organizar la oración según papeles temáticos (tales como "agente", "tema", "experimentante" o "benefactivo") y categorías gramaticales (tales como "animado" o "humano") respectivamente, para luego dibujar la estructura morfológica de la oración a nivel sintáctico.

Estos cuatro módulos entregan una salida ("output") que sirve como entrada ("input") del siguiente módulo hasta entregar una realización lingüística u oración en un acto comunicativo.

Noam Chomsky se interesó por la política a muy temprana edad, estimulado por las lecturas en las librerías de los anarquistas españoles exiliados en Nueva York. A los once años publicó su primer artículo sobre la caída de Barcelona y la expansión del fascismo en Europa.Su activismo político arranca de la movilización popular contra la Guerra del Vietnam. La participación de Chomsky en esta movilización fue particularmente sorprendente considerando que su propia universidad, MIT, estaba investigando helicópteros, bombas inteligentes y técnicas de contrainsurgencia para la guerra en Vietnam. Y, como dice Chomsky, "se desarrolló una buena cantidad de tecnología de orientación de misiles [nucleares] en el campus del MIT". Como Chomsky también dice, "aproximadamente el 90% [del MIT] estaba financiado por el Pentágono en ese momento. Y yo personalmente estaba justo en el medio de eso. Estaba en un laboratorio militar.” La oposición de Chomsky a la guerra de Vietnam lo llevó a analizar el papel del mundo académico en la implicación de Estados Unidos en esta guerra. Fruto de este esfuerzo fueron varios artículos compilados en el libro "American Power and the New Mandarins" (El poder estadounidense y los nuevos mandarines) 1969, de entre los cuales destaca "La responsabilidad de los intelectuales" (publicado inicialmente en febrero de 1967 en "The New York Review of Books"). Desde entonces, ha sido muy conocido por sus ideas políticas de izquierda, que se centran en la lucha por superar el déficit democrático existente de Estados Unidos —es decir, la gran distancia entre las decisiones políticas y la opinión pública—, y en denunciar las "ambiciones imperiales" del gobierno de este país en el mundo. En general, se le considera un crítico del capitalismo y también ha hablado en contra del darwinismo social de Herbert Spencer.

Se define a sí mismo como partidario de la tradición anarquista, especialmente de la corriente de orientación laboral del anarquismo, el anarcosindicalismo, y es miembro del célebre sindicato revolucionario estadounidense IWW, al que también perteneció su padre. Pese a ello, no se opone totalmente a la política electoral, al menos en el ámbito de la estrategia: su postura en las elecciones de Estados Unidos es que los ciudadanos deberían votar por los demócratas locales si con ello se consigue sacar del poder a los republicanos, mientras que en las situaciones donde las victorias republicana o demócrata están claras ha pedido el voto para candidaturas más a la izquierda, como las del Partido Verde. Es uno de los más importantes colaboradores del grupo mediático independiente Z Communications. Esta actuación se inscribe claramente dentro de la tradicional táctica anarcosindicalista de impulsar movilizaciones populares que coaccionen la acción de los poderes públicos y fácticos hasta conseguir cambios concretos y reales (véase el prefacio de Chomsky al libro de Rudolf Rocker, "Anarcho-Syndicalism: Theory and Practice", 1989).

Desde un punto de vista más personal y filosófico, también se considera un conservador de la variante liberal clásica ("Chomsky's Politics", pp. 188) y se ha definido como un sionista; aunque observa que la mayoría considera como antisionista su definición de sionismo. Percibe un cambio en el significado del sionismo ("Chomsky Reader") desde la década de 1940. En la misma línea y rescatando su contenido libertario, Chomsky ha declarado su admiración y adhesión al kibutz como forma social alternativa.

Con el tiempo, se ha convertido en una de las principales figuras de la política radical estadounidense. Junto a José Saramago o Leonardo Boff, entre otros, es uno de los principales intelectuales de la izquierda en el mundo, pese a lo cual, a diferencia de su actividad científica, su aportación teórica en el ámbito político no es demasiado relevante. Nunca se ha considerado un teórico en política, sino simplemente un ciudadano informado que mantiene una actitud muy crítica hacia la ideología dominante. Chomsky cree que, mientras la actividad científica no está al alcance de cualquiera (ya que exige una formación y una abstracción conceptual muy elevada), para la actividad de crítica política basta una cierta apertura de espíritu. Ha reiterado a menudo que la política debería ser cosa de todos y no dejarse en manos de la "intelligentsia", ni mucho menos aceptar que solo los profesionales de la política (sean periodistas, intelectuales o políticos) sean los únicos capacitados para opinar sobre política.

Uno de sus principales aportes intelectuales ha sido el análisis de los medios de comunicación. En sus estudios sobre el tema se ha ocupado de los enfoques sesgados, o incluso engañosos, que hay detrás de la supuesta neutralidad de los medios más prestigiosos. Se trata de un trabajo de «contrainformación» que ha obtenido gran difusión y que muchos otros han continuado. Fruto de este esfuerzo es el libro "Los guardianes de la libertad," escrito junto con Edward S. Herman, profesor de la Universidad de Pensilvania.

Su denuncia de la política exterior de Estados Unidos, de las deficiencias democráticas de su maquinaria política, y de los engaños de los grandes medios de comunicación en este país, supone poner en duda tres de los pilares del nacionalismo estadounidense. Por otro lado, su visión sobre la política del estado israelí en Oriente Medio es parte de su crítica a la política exterior de Estados Unidos. Chomsky señala que desde hace años la maquinaria militar israelí depende mayormente del apoyo material y diplomático de Estados Unidos, y que ambos estados realizan sistemáticamente acciones violentas al margen de las leyes internacionales. Esta última circunstancia ha motivado que Chomsky declare que según los criterios internacionales actuales, ambos estados ejercen el terrorismo. En concreto en su libro "11/09/2001", afirma que los Estados Unidos es «uno de los principales estados terroristas» («"a leading terrorist state"»). Noam Chomsky lo publicó en diciembre del 2001, tres meses después de lo sucedido en Nueva York. Es un ensayo sobre los hechos y las consecuencias de los atentados del 11 de septiembre. Se basa en una estructura de siete largas entrevistas de periodistas extranjeros durante el primer mes y medio posterior a los ataques al World Trade Center y al Pentágono. No analiza únicamente las causas, las consecuencias de los atentados y la reacción del pueblo norteamericano, sino que cuestiona las razones de la guerra y los bombardeos. En este libro Chomsky refleja de nuevo su visión crítica con el poder y la industria militar.

A raíz de estas denuncias, varios detractores de Chomsky lo han tildado de antiestadounidense. Algunos incluso han comprendido sus críticas como una supuesta obsesión antiestadounidense y antisionista. Para algunos nacionalistas, es especialmente controvertida su crítica a la política del gobierno de Israel, por su origen judío. También ha sido polémico su apoyo a la libertad de expresión en los que se conoce como el escándalo Faurisson. En la década de 1970, Robert Faurisson realizaría un estudio y escribiría un libro en el cual concluye que muchos de los acontecimientos del holocausto ( como las cámaras de gas) no existieron realmente. Chomsky firmaría una petición para garantizar a las autoridades la libertad de expresión, aclarando que él mismo no compartía el punto de vista negacionista, pero que no reconocía expresiones antisemitas en el trabajo de Faurisson. Chomsky califica al holocausto como "la peor muestra de locura colectiva en la historia de la humanidad", pero considera fundamental garantizar la defensa de la libertad de expresión, incluso para aquellas ideas popularmente mal vistas. Por último, destaca la crítica que hace de la izquierda posmoderna y de su entusiasmo por el relativismo cultural que, al "deconstruir" la noción de verdad, ha invalidado también la posibilidad de la crítica.

Chomsky ha pedido a EE. UU. y a Canadá levantar sanciones económicas impuestas a Venezuela .

En cuanto a España, en 2009 firmó un manifiesto de apoyo a la candidatura a las elecciones europeas de la formación política Izquierda Anticapitalista, y en 2014 en apoyo de la formación política Podemos. En el 2018, Chomsky, junto con más de 100 académicos de 19 países, pidió en una carta la "puesta en libertad inmediata" de los políticos catalanes encarcelados en España por participar en la declaración de independencia de Cataluña.

Desde 2009 es miembro honorario de AIPTI.

Chomsky es uno de los detractores de la globalización, y esto se debe a su forma de entender la hegemonía del capitalismo moderno. Para Chomsky, Estados Unidos no cree en el libre comercio, sino que lo utiliza como un método mediante el cual los países más fuertes imponen a los países pobres la obligación de cumplir unas normas coercitivas y rígidas (la ley del embudo).

El objetivo básico de la globalización económica es globalizar toda la economía mundial, y Estados Unidos controlaría la economía mundial con el apoyo de los organismos satélites (Fondo Monetario Internacional, Banco Mundial, Organización Mundial del Comercio). El argumento habitual a favor del libre comercio liberalizado es que conducirá a un aumento generalizado de los niveles de vida. La experiencia ha demostrado que con la apertura de los mercados comerciales y financieros los inversores y empresarios han ganado mucho más dinero, pero gran parte de los países más pobres han sido las víctimas de un descenso pronunciado de sus niveles de vida.

Según precisa Noam Chomsky:
Sus afirmaciones políticas le han concitado un gran número de simpatizantes, en amplios sectores de la izquierda, especialmente europea y latinoamericana, y también algunos detractores. Su libro "11 de septiembre" ("9/11") tuvo una gran difusión, pese a haber sido publicado por una pequeña editorial. Solo la edición de este libro en inglés vendió centenares de miles ejemplares, y ha sido traducido a varias lenguas. Posteriormente, su libro "Hegemonía o supervivencia: la búsqueda estadounidense del dominio global" fue recomendado por el presidente de Venezuela Hugo Chávez en su discurso frente a la asamblea general de la ONU el día 20 de septiembre de 2006, lo que ocasionó que dicho libro, en aproximadamente dos días, pasase del puesto 160.772, al número 2 de los libros más vendidos en Amazon.

En diversas ocasiones se le ha preguntado a Chomsky si tiene una postura religiosa o es ateo, a lo cual él respondió en una ocasión:

En una discusión con Lawrence Krauss y Sean M. Carroll en el 2006, Chomsky dio una respuesta similar:
Noam Chomsky ha reconocido los límites de la razón humana, y claramente ha rechazado el cientificismo (la idea de que la ciencia lo puede explicar todo):

Por otra parte, Chomsky ha dejado claro que su postura no es antirreligiosa, pues como analista social, al igual que muchos otros autores, ha reconocido que hay una diferenciación radical entre el cristianismo de los evangelios en contraste con el de la mayor parte de los gobiernos y organizaciones religiosas:

Además, ha hablado favorablemente de la teología de la liberación y ha reconocido la labor de movimientos que han tratado de restaurar y rescatar los principios del cristianismo primitivo:






</doc>
<doc id="15410" url="https://es.wikipedia.org/wiki?curid=15410" title="Economía de Francia">
Economía de Francia

La economía de Francia es la quinta economía más grande del mundo, con un Producto Interno Bruto (nominal) de 2,574.807 millones de dólares en 2017 en términos absolutos. A nivel regional, la francesa es la segunda mayor economía de Europa, detrás de la alemana.

El sector de los servicios ocupa al 75% de la población, mientras que el primario a menos del 2% y el secundario al 24%. La economía francesa es cada vez más abierta, representando un lugar importante en el comercio internacional. Francia es el quinto país por sus exportaciones y el sexto por sus importaciones. En 2016, las exportaciones francesas representaron al 20% del su PIB y las importaciones un 23%. La tasa de desempleo sigue siendo más alta que la de otros países desarrollados. 

La industria química es un sector clave para Francia, ya que esto ayuda a desarrollar otras actividades de fabricación y contribuye al crecimiento económico. La industria turística de Francia es un componente importante de su economía, ya que Francia es el destino más visitado del mundo. Sophia Antipolis es el principal centro tecnológico de la economía de Francia. Según el Fondo Monetario Internacional, en 2013, Francia fue el vigésimo país del mundo por PIB per cápita con USD 44,099 dólares por habitante. En 2013, Francia se incluyó en el Índice de Desarrollo Humano de las Naciones Unidas con 0,884 (muy alto desarrollo humano) y en el puesto 21 en el Índice de Percepción de la Corrupción. La OCDE tiene su sede en París, la capital de la nación.

La economía de Francia entró en la recesión de finales de la década de 2000 más tarde y pareció salir antes que la mayoría de las economías afectadas, solo soportando cuatro cuartas partes de la contracción. Sin embargo, Francia experimentó un crecimiento estancado entre 2012 y 2014,con una expansión de la economía de 0% en 2012, 0,8% en 2013 y 0,2% en 2014, aunque el crecimiento repuntó en 2015 con 0,8% , 1.1% para 2016 y un crecimiento pronosticado de 1.6% para 2017 y 1.8% para el año 2018, ambos pronósticos para cada uno de los niveles más altos desde 2011 (2.1%).

En 2016, la esperanza de vida de un obrero en Francia es 6,4 años inferior a la de un ejecutivo.

En 2017, el 10% más rico de los franceses poseen más de la mitad de la riqueza del país, mientras que el 50% de los más pobres tienen el 5%.

Desde sus inicios, el poder económico de Francia ha sido a menudo vinculado a la demografía. En virtud de Luis XIV, fue el país más poblado de Europa y, por tanto, el dominante económicamente. Sin embargo, su economía estaba obstaculizada por la debilidad estructural de sus flota mercante y militar.

Mientras que la primera Revolución Industrial comenzó en Inglaterra en el siglo XVIII y luego se extendió al Benelux, Francia solo la conoció durante la segunda mitad del siglo XIX, gracias a la liberalización económica bajo el Segundo Imperio y el comienzo de la Tercera República. A finales del siglo, Francia era un país próspero y poderoso, que había superado la potencia económica de Inglaterra y que seguía extendiendo y ampliando sus asentamientos.

En 1880, Francia generaba el 10% de la producción mundial. Luego, su poder económico se debilitó gradualmente por las malas políticas económicas y un bajo crecimiento de su población agrícola. En el siglo XX, las guerras mundiales y la descolonización redujeron su peso.

Entre 1946 y 1973, vivió un período de fuerte crecimiento (un promedio de 5% por año) que el economista Jean Fourastié clasificó como los Treinta Gloriosos. Este fuerte crecimiento se debía principalmente a unos periodos muy importantes de trabajo y a un fuerte aumento de la productividad, gracias a la actualización tecnológica respecto a la potencia dominante, los Estados Unidos, pues la economía francesa tenía mucho retraso económico. Así, en 1950, el ingreso promedio de un francés representaba poco más de la mitad de la de un americano (55%), mientras que llegó a las cuatro quintas partes en 1973, que dio forma al Estado de Bienestar. El Estado, en los países occidentales, asumió tareas activas en relación con las posibilidades de incidir directamente sobre la actividad económica, en cuestiones como el nivel de empleo, de demanda y de inversión.

El final de la recuperación coincidía con el final del período de fuerte crecimiento. La fuerza de trabajo hizo poco crecimiento durante este período, a pesar del "baby boom". La economía francesa se ha beneficiado del Mercado Común Europeo desde 1957. Francia fue uno de los países fundadores de la Unión Europea en los años cincuenta.

Los franceses disfrutan de un alto nivel de vida, pero su sentido es vivir un período de crisis desde el final de los Treinta Gloriosos. Durante mucho tiempo, esta "crisis" no impidió un crecimiento significativo ni mantener la economía a nivel mundial envidiable, pero desde el decenio de 1980, los temas de "declive" y el temor de la competencia extranjera (la globalización, incluso la integración europea) han sido mucho más importantes, mientras que los indicadores económicos son cada vez más alarmantes. En particular, el desempleo ha aumentado y, a pesar de un descenso a partir de 1997, la tasa media de desempleo sigue siendo más de 3 puntos que la de los países del G7.

En Francia en 1990, el PIB per cápita representaba el 75% del de los Estados Unidos, frente al 70% en 2006. Durante años, Francia ha sido la cuarta economía más grande, y la diferencia con Gran Bretaña (2.346 millones en 2006) ha sido baja. En cambio, el exceso en este ranking por China, y después por la India, es inevitable.

Algunas estadísticas macroeconómicas muestran una disminución significativa en una parte de las clasificaciones económicas internacionales sobre los veinticinco últimos años. En 1980, Francia fue uno de los países más ricos del mundo: el PIB per cápita fue el sexto más grande del mundo, detrás de los Estados Unidos, Suiza, Luxemburgo, Islandia o Canadá. Se superaba algunos rivales económicos como Alemania, Japón o el Reino Unido. El nivel de vida en los países escandinavos también estaba por debajo del francés. El decenio de 1980 fue de relativo declive económico.

En 1994, el PIB per cápita de los franceses era el décimo tercero a escala global. Algunas economías, como las de Alemania o Japón, han visto un aumento importante. Otros han sufrido una caída todavía más fuerte que la francesa, como la de Canadá.

En 1999, la introducción de la moneda única marco el deseo de estrechar la cooperación económica de la mayoría de los países de la Unión Económica y Monetaria. En 2004, el PIB per cápita en Francia es el 16 o 17 más grande del mundo.

En 2005, la deuda pública francesa superó el 60% del PIB. La tasa de actividad de los franceses es inferior a la de los otros países desarrollados, por la entrada tardía de los jóvenes en la vida laboral (22 años en promedio), la reducción de la edad efectiva de jubilación (57 años) y la baja tasa de empleo de la población en edad de trabajar. El tiempo legal de trabajo se redujo a 35 horas semanales en 2002

La tasa de empleo (63,8% en 2006), cerca de la media europea (64,8%) es inferior a la UE-15 (66,2%), y el promedio de los países desarrollados, especialmente para personas de la tercera edad, los jóvenes menores de 30 años y poco calificados.

El crecimiento del PIB per cápita francés es menor que la de otros países durante los dos últimos decenios. Durante los últimos años una fuerte oposición social en contra de las reformas del mercado laboral ha impedido que el gobierno intente reactivar la economía a costa de la seguridad de los trabajadores. En 2007, el gobierno ha lanzado importantes esfuerzos para reformar la economía. En 2007, el déficit del presupuesto público ha vuelto a estar dentro de la limitante del 3% del PIB impuesta por la Unión Europea, y el paro ha bajado de 9%.

Francia atraviesa por una transición, desde una economía moderna y desarrollada con una importante presencia del gobierno, hacia una donde el mercado carece de regulaciones. El gobierno ha privatizado varias grandes empresas, bancos y aseguradores. Aún tiene una fuerte presencia en algunos sectores, particularmente la energía, el transporte público, la defensa y la industria. Las telecomunicaciones se abren cada vez más a la competencia. La presión fiscal es una de las más altas en Europa (casi el 45% del PIB).

En 2017, el endeudamiento del sector público alcanza el 98 % del PIB y el endeudamiento del sector privado, el 130 % del PIB. En diez años, la deuda de las empresas francesas aumentó 750 mil millones de euros.

Francia, con 834.000 nacimientos en 2008 (contra 543.000 decesos) es el país europeo donde nacen más personas y uno de los pocos países donde el crecimiento de la población no está asegurada por la sola inmigración. Mientras que la población francesa estaba tan grande en 1945 que en 1900 (alrededor de 41 millones de habitantes), en 2008 incluye más de 64 millones de franceses.

Pero la importancia de esos nacimientos se debe principalmente al hecho de que las madres pertenecen a las generaciones del baby boom. Pero en las treintas próximas décadas las mujeres serán menos que sus madres. Así, alrededor de 2050, los nacimientos y las muertes deberían ser equilibradas.

En 2006, Francia se convirtió en el primer país de Europa en materia de fecundidad, superando Irlanda por primera vez. Con una tasa de fertilidad de 2 hijos por mujer, El país está en una situación cercana a la de la década de 1960, después de un largo paréntesis durante el cual la simple sustitución de generaciones no estaba garantizada.

El punto más bajo se había alcanzado a mediados de 1990 con una tasa de 1,65. En toda Europa, hay una reanudación de la fertilidad, pero sigue en niveles muy bajos en países como Polonia (1,23 hijos por mujer), Italia (1,33) o la Alemania (1,37), donde a menudo las mujeres deben elegir entre el trabajo y la maternidad.

Francia se caracteriza por altas tasas de fecundidad y una fuerte participación de las mujeres en la fuerza de trabajo con una tasa de participación del 80% para las mujeres de 25 a 49 años. Además, este equilibrio entre la maternidad y el trabajo se realiza sin un gran trabajo a tiempo parcial como en el Reino Unido o los Países Bajos (donde el 75% de las mujeres son a tiempo parcial).

El trabajo no impide tener hijos, incluso eso crea condiciones favorables para mejorar la fertilidad. Desde hace mucho hay una política familiar para desarrollar viveros (320 000 niños en 2005 es decir un niño de cada diez) y acoger a todos los niños en la escuela a 3 años. Otras medidas incluyen las prestaciones familiares pagadas a los padres, los beneficios fiscales relacionados con la presencia de niños, la mejora de las competencias relacionadas con los niños (cuidadores), el desarrollo de la licencia parental.

Más de 13 000 franceses en 2009 superaron 100 años, y podrían ser 60 000 en 2050, entre los cuales una gran mayoría de las mujeres. Hoy en día, la esperanza de vida al nacer (o vida media) es de 77 años para los hombres y 84 años para las mujeres y aumenta en dos o tres meses al año. En 1950, la esperanza media de vida en los países desarrollados era de alrededor de 66 años.

La población se alimenta mejor que antaño, la higiene es mejor y las enfermedades infecciosas han disminuido significativamente, afectando hoy más los niños que las personas mayores, mucho mejor curadas que en el pasado. Por lo tanto, el porcentaje de personas de la tercera edad (60 años y más) en la población en 2009 es alrededor del 22%.

En 2050, Francia puede contar (según los demógrafos) alrededor de 20 millones de personas de más de 60 años, y entre ellos la mitad de 75 años y más, casi un tercio de la población de entonces. La mediana de edad (la edad por debajo de la cual es la mitad de la población) aumentaría de 37 a 45 años, un fenómeno común a todos los países desarrollados.

Por lo tanto, el futuro de las pensiones es en cuestión. En el sistema francés de los regímenes de pensiones, deben ser, en principio, un equilibrio entre los ingresos, alimentado por las contribuciones de personas que trabajan y los gastos de las pensiones de jubilación consistirá. Este equilibrio se ve seriamente amenazado.

En 2005, había en Francia más de 195 contribuyentes por 100 jubilados, debido a una combinación de factores, entre ellos el desempleo, la baja participación de la mujer antes de la década de 1970, la edad de jubilación a los 60 años y la entrada tardía de los jóvenes en el trabajo. Dentro de 25 años, la situación podría empeorar si estos factores se combinan, y Francia podría haber dos jubilados por tres activos.

El envejecimiento de la población causa inevitablemente un aumento en el consumo de medicamentos, y, por tanto, en los costes sanitarios. Según las análisis más pesimistas, podría haber entre 2000 y 2050 un crecimiento del 40% en el gasto en salud debido únicamente al envejecimiento, y el presupuesto de la salud podría representar un tercio del PIB. Desde un punto de vista médico, parece urgente desarrollar la investigación que podría evitar, o prevenir ese tipo de aumento de los costos asociados con una vida útil más larga.

La migración neta en Francia se estima en 75 000 personas en 2008. El país mantiene su especificidad en comparación con sus vecinos europeos, en los cuales la migración contribuye a una cuarta parte del crecimiento de la población, mientras que en Francia representa el 80% del crecimiento de los veinticinco países de la Unión Europea.

Desde 1975, la proporción de inmigrantes en la población se ha mantenido estable, pero la inmigración ha cambiado: las migraciones por motivos familiares han aumentado, hay más mujeres y vienen de países cada vez más lejanos. Los inmigrantes son más frecuentemente casados que el resto de la población y con más niños, tienen bajos ingresos y se concentran en las grandes ciudades.

Los inmigrantes son los más afectados por el desempleo, ocupan puestos de obreros o empleados en los servicios con poca cualificación. Sin embargo, su representación excesiva en la industria y la construcción está bajando. Además, los descendientes de los migrantes tienen el mismo estatuto social y nivel de vida que los nativos de mismo origen social.

El desempleo de los inmigrantes es uno de los mayor problemas. Los inmigrantes tienen más probabilidades que los nativos de estar desempleados o haciendo un trabajo para los que son sobre calificados. Para los hijos,incluso habiendo nacido en Francia y con calificaciones medias, medias-altas, también resulta difícil encontrar trabajo. Los inmigrantes, especialmente los recién llegados, se encuentran entre los más afectados en crisis económicas, ya que muchos tienen puestos de trabajo poco cualificados o trabajan en sectores cíclicos, como la construcción. Las capacidades de los inmigrantes altamente calificados no son muy utilizadas ni reconocidas, pero poco a poco va cambiando a medida que la integración se complementa

La población activa en Francia, según la definición del OIT (personas entre 15 y 64 años que tienen un puesto de trabajo o están desempleados) estaba acerca de 28 millones de personas en 2007. Entre ellas, unas 25,5 millones de personas estaban empleadas, o sea unas 2,5 millones se encontraban en el desempleo según la OIT. Eso corresponde a una tasa de participación de una tasa de empleo de 64,5%.

La tasa de participación de las mujeres es del 65% (y el tasa de empleo del 60%) contra el 75% (tasa de empleo 69%) para los hombres, y las mujeres representan un 47% de la población activa total. Si se toma como referencia la población de más de 15 años (49,5 millones de personas), la tasa de participación es del 56%. La de los hombres es del 62% y de las mujeres del 51%.

En cuanto al paro, la situación del mercado del trabajo ha mejorado en los últimos años, pero la diferencia con respecto a países con mejores resultados siguen siendo significativa. Mientras que había alcanzado un 12% en 1996, la tasa de desempleo francés se redujo al 7,5% a mediados del 2007. Esta sigue siendo, sin embargo, un punto porcentual por encima de la media de EU-15 y casi tres puntos por encima de la media de la OCDE. Otro problema es que el desempleo en Francia puede durar más tiempo que en otros países: 40% de los desempleados quedan en el paro más de un año, y 20% más de dos años.

Mientras que la población había aumentado durante el siglo XIX, el número de activos evolucionó poco en cincuenta años. En 1962 como en 1911, el censo de población contaba 20 millones de activos, contra 13 millones en 1806. La población en edad de trabajar (15-64 años según la definición de la OIT) aumentó en 3,3 millones entre 1911 y 1962, pero la tasa de actividad bajó. Según los censos, la fuerza de trabajo representaba el 69% de los 15-64 años en 1962 contra el 78% en 1911.

El trabajo hembro está en declive a cualquier edad, porque el peso relativo de la agricultura está disminuyendo. Desde 1921, las tasas de actividad para los hombres jóvenes (15 a 24 años) y más antiguos (más de 60) también están a la baja. Sin embargo, aproximadamente siete de cada diez hombres de 15 a 24 años, como de 60 a 64 años, aún estaban activos en 1962. A principios de los años sesenta, hubo tres movimientos: la avanzada de la generación baby boom, la migración y el flujo de las mujeres en el mercado laboral. A partir de 1975 y hasta 1995, los ancianos y los jóvenes son "excluidos" del mercado laboral.

Desde los principios de los años sesenta, el número de empleos creció rápidamente con un ritmo cercano a lo de la población activa. La desaceleración de la actividad económica puso fin a esta situación. El número de puestos de trabajo se redujo en cerca de 400 000 durante la primera mitad de la década de los ochenta y, a continuación, 500 000 de 1991 a 1993, mientras que en las etapas de la recuperación (76-79, 86-91) el empleo creció a un ritmo cercano a lo de los años sesenta. De eso resultó el aumento del desempleo masivo y persistente.

La población en edad de trabajar disminuirá después de 2010, pero la población seguirá aumentando durante varios años. Más allá de 2020-2030, es difícil anticipar los cambios en la fuerza de trabajo. La disminución de la fuerza de trabajo podría detenerse, al menos parcialmente. La edad de cese de actividad podría aumentar aún más debido al aumento de la duración de contribución. La tasa neta de migración de los trabajadores puede aumentar. También podría haber un aumento de la fecundidad más allá de 2030.

A pesar de una creciente diversidad en el mercado laboral y de la mejor cualificación de las mujeres, las principales diferencias entre hombres y mujeres en cuanto a los puestos de trabajo se mantienen. Hay ocupaciones que quedan principalmente el monopolio de un sexo. Las mujeres ocupan puestos en los servicios personales, la educación, la salud y la acción social. En contraste, la construcción son sectores masculinos. También, mucho más mujeres ocupan puestos a tiempo parcial y tienen puestos menos estables. Casi una de cada tres mujeres trabajan a tiempo parcial, contra un hombre de veinte.

Una persona de cada dos de más de 15 años y casi dos tercios de personas en edad de trabajar (15-64 años) trabajan. Pero a todos los periodos de la vida, la tasa de empleo de los hombres es mayor de la de las mujeres. Entre 25 y 49 años, la diferencia es más pronunciada: 89% de los hombres de esa edad están en el empleo, frente al 76% de mujeres.

En estas edades, las madres suelen ser menos activos en el mercado de trabajo que otras mujeres (80% contra 89%) en contraste con los hombres que suelen ser más activos cuando tienen hijos. Entre 15 y 25 años, esta diferencia es menor (68% de los hombres y 71%). Al final de la vida, entre 55 y 64 años, el 44% de los hombres y el 39% de mujeres son empleados. En total, más del 51% de las mujeres de 15 años o más son activas, 10 puntos menos que los hombres. Sin embargo, en comparación con Europa, las mujeres francesas son los más activos detrás de países nórdicos (Dinamarca, Finlandia, Noruega y Suecia).

Los inmigrantes se encuentran entre los trabajadores poco cualificados y trabajan en sectores como los servicios a los particulares, las ventas, la construcción y obras públicas. En un contexto general de envejecimiento de la población en Europa, con perspectivas disminución de la población en edad de trabajar, la inmigración va a desempeñar un papel de apoyo para satisfacer las necesidades del mercado laboral. A pesar de la liberalización del mercado laboral en Europa, la inmigración europea es minoritaria.

Las minorías raciales son más frecuentemente en desempleo que el resto de la población, en parte por culpa a la discriminación. La discriminación por motivos de origen étnico para la contratación de nuevos empleados es ilegal, y hay leyes que sancionan tal práctica, pero solo el 29% de los ciudadanos franceses conocen esta ley: esta falta de sensibilización de la opinión pública constituye un fuerte obstáculo para la aplicación efectiva de las normas jurídicas. De hecho, para que las leyes se cumplan, las personas tienen que tomar acciones legales, así los trabajadores deben saber que tienen el derecho legal a la igualdad de trato. Por eso, la HALDE (Alta Autoridad de Lucha contra la Discriminación y Promoción de la Igualdad) fue creada en 2005 para llevar campañas de información y educación.

Aunque es demasiado pronto para evaluar su impacto, la HALDE tiene una fuerte influencia, y puede desempeñar un papel importante en la lucha contra la discriminación. Tiene facultades de investigación a fin de que puedan ayudar a un individuo para reunir evidencia de discriminación, puede investigar a las empresas, incluso en ausencia de una reclamación individual, y puede aplicar sanciones cuando hay pruebas de discriminación, y por fin puede ayudar para resolver un conflicto de discriminación a través de la mediación en lugar de acciones judiciales.

La situación del mercado laboral de los jóvenes y los trabajadores de más edad sigue siendo un problema. Los trabajadores de edad media trabajan mucho en Francia, con el 82% de las personas entre 25 a 54 años que tienen un empleo, contra el 77% en la zona de la OCDE. Por el contrario, la tasa de desempleo entre los jóvenes de entre 15 a 24 años es del 20%, 4 puntos porcentuales más que en la zona de la OCDE. En Francia, los jóvenes se enfrentan a fuertes obstáculos para obtener empleo en todos los niveles de escolaridad.

Asimismo, solo el 38% de las personas entre 55 y 64 años están trabajando, 15 puntos porcentuales inferior a la media de la OCDE. Esta situación de bajas tasas de empleo de los trabajadores de más edad se debe a impuestos significativos, a un edad oficial de jubilación muy bajo (60 años), y a programas de jubilación con antelación financiados por el Estado.

Sin embargo, los gobiernos han adoptado medidas en los últimos años para mejorar la situación. Es posible jubilarse más tarde que antes, y medidas han sido adoptadas para aumentar los ingresos de los que trabajan más allá de la edad oficial de jubilación. Los programas de jubilación con antelación fueron reducidos. Usando la interfaz de usuario del sistema como una forma de jubilación anticipada se ha hecho más difícil. Pero la facilidad del acceso ampliado a las prestaciones por desempleo y períodos de contribución a niveles demasiados bajos siguen siendo problemas.

Casi el 90% de los trabajadores están contratados por un empleador: son 23 millones contra 2 millones de independientes. El empleo por cuenta propia (independientes) sigue siendo una minoría. La proporción de empleados independientes es dos veces más alta entre hombres que entre las mujeres. Los jóvenes están menos interesados en el empleo por cuenta propia: entre los menores de 25 años, menos del 2% tienen un empleo por cuenta propia; entre más de 50 años, la proporción es de casi el 16%. 

El sector terciario emplea a ocho de cada diez empleados, y en este sector, el sector público incluye a dos empleados de cada diez.

20 millones de empleados tienen un contrato permanente y 3,1 millones tienen otros tipos de contratos (temporales, contratos a plazo fijo, pasantes, aprendices y contratos "ayudados"). Estas formas de empleo representan el 12% del empleo. Sin embargo, la mayor parte de los nuevos empleos son a duradera limitada.

La legislación de protección del empleo es bastante estricta. Las normas para los despidos en gran escala son significativas, las indemnizaciones legales son altas, hay restricciones sobre el uso de contratos de duración determinada y limitaciones sobre el tiempo de trabajo. Eso acarrea un aumento en los costes ambos de los despidos y de la mano de obra, reduciendo así la contratación. Sin embargo, los gobiernos de los últimos años han tomado medidas, tales como la suspensión de las leyes más estrictas de protección del empleo.

La rigidez del mercado laboral puede ser medida por el nombre de puestos de trabajo ocupados por personas desde hace menos de un año. Solo un 12% de los puestos de trabajo están ocupados por personas que trabajan en su empresa por menos de un año. La tasa de renovación de la mano de obra es el más alto en la construcción (alrededor del 17%). En casi todos los sectores del sector terciario, es más bajo, excepto en los servicios domésticos y personales (casi el 20%). En la administración, es del 6%, y en la industria menos del 9%.

El sueldo mínimo es muy alto en comparación con otros países de la OCDE y reduce la contratación, especialmente para ciertos grupos como los jóvenes y los trabajadores poco cualificados. Desde hace dos décadas, los gobiernos han adoptado medidas de grandes reducciones de las cotizaciones sociales para los trabajadores con bajos salarios. Eso permito reducir los costes laborales, pero esta tendencia se ha ralentizado recientemente con la legislación sobre las 35 horas semanales. 

Francia es ahora uno de los países de la OCDE donde la gente trabaja menos. El gobierno llevó a cabo al principio de los años 2000 una política de reducción del tiempo de trabajo, lo que empeoró la situación. No hay ningún país de la zona de la OCDE que haya aplicado esas políticas. Fue impuesta de manera autoritaria, por dos leyes de 1998 y 2001, y requiere el mantenimiento del poder adquisitivo de los empleados, mientras que otorgaba un apoyo financiero para las empresas. Por último, fue una política para crear nuevos empleos (así se llevó a cabo en una situación económica favorable). Los efectos a corto plazo de esta medida han sido probablemente positivos.

En una perspectiva a largo plazo, hay preocupaciones de que esta política de reducción colectiva del tiempo de trabajo pesa fuertemente sobre las finanzas públicas y penalice el potencial de crecimiento económico. Otros consideran que la disminución del tiempo de trabajo facilita su reparto y la creación de nuevos empleos, además de incrementar la retribución del trabajador por hora trabajada.

Además, solo el 64,5% de las personas en edad de trabajar (15-64 años) tienen un empleo en Francia, en comparación con más del 70% en países de la OCDE como Canadá, Dinamarca, los Países Bajos, Suecia, Estados Unidos y el Reino Unido. Según el OCDE, eso puede explicar la situación difícil del mercado labora en Francia.

La salud mental de los trabajadores ha empeorado ligeramente en Francia en la última década. Al mismo tiempo, la proporción de los trabajadores sufriendo de problemas de salud mental está cerca de la media de la UE. Trabajos relacionados con los problemas de salud mental son más a menudo asociadas con las condiciones de trabajo más difíciles, tales como largas jornadas de trabajo y discriminación laboral.

Las condiciones de trabajo que tienen un impacto sobre la salud mental se han empeorado en Francia (la intensidad del trabajo y el cambio frecuente de trabajo), pero ciertos aspectos han mejorado (la discriminación en el lugar de trabajo). Sin embargo, la enfermedad mental sigue siendo más frecuente entre los desempleados o las otras personas inactivas, que entre aquellos que tienen un puesto de trabajo.

Francia es la primera potencia agrícola de la Unión Europea. Es el segundo mayor exportador mundial de productos alimentarios, detrás de los Estados Unidos, y el excedente del comercio exterior de este sector ascendió a 9 mil millones de euros en 2007. En 2005, la agricultura empleaba a cerca de un millón de personas (6% de los activos). En 2008, los ingresos agrícolas netos eran de 23 millones de euros (2% del PIB), incluyendo 7 millones de subvenciones.

La parte de los agricultores en la población laboral francesa de la fuerza laboral está disminuyendo, pero la agricultura sigue siendo uno de los sectores más dinámicos. Se ha modernizado mucho desde hace tres decenios, cuando han sucedido espectaculares aumentos en la productividad gracias a rendimientos muy fuertes.

Los principales cultivos son cereales (trigo, maíz) y el azúcar (gracias a los territorios de ultramar), vino, productos lácteos, frutas y hortalizas, animales y productos cárnicos, que son exportados y que generan excedentes. Por el contrario, la pesca conoce dificultades y es deficitaria. Francia tiene una de las mayores ganaderías de la Unión Europea: incluye más de 20 millones de cabezas de ganados, 16 millones de cerdos y 9 millones de ovejas.

Produce casi una cuarta parte de la carne consumida en Europa, es el mayor productor europeo de carne de aves y el tercer productor de ovinos y porcinos. En 2007, Francia producía 60 millones de toneladas de cereales, de los cuales alrededor de la mitad está representada por el trigo para el consumo de alimentos del ganado. La cebada y el maíz son también utilizados para el ganado. Produce alrededor de 6 millones de toneladas de carne y 20 millones de toneladas de frutas y hortalizas.

La agricultura constituye el apoyo de una fuerte sector industrial de los alimentos (sector secundario). Sector importante de la economía francesa, representa un volumen de negocios de 140 mil millones de euros, incluyendo 25 mil millones para las exportaciones. Con casi 400 000 empleados, la agroindustria es el tercer mayor empleador de la industria francesa. La industria alimentaria también es un mercado muy abierto para la exportación, que genera un superávit comercial importante. Las ventas de vinos llegan por delante de los productos más exportados, seguido de productos lácteos y del sector de los cereales.

La Política Agrícola Común (PAC), que fue creada a iniciativa de Francia para fortalecer la agricultura nacional, ha sido una fuente permanente de problemas, por no mencionar los conflictos políticos en Europa.

La industria francesa es la segunda en Europa y la novena más grande del mundo. El sector secundario representa el 20% de los puestos de trabajo, el 40% de las inversiones y casi el 80% de las exportaciones francesas. Sin embargo, aunque la industria ha visto su producción aumentar, perdió cerca de 1,5 millones de puestos de trabajo durante los últimos veinticinco años. La industria francesa ha experimentado una rápida fusión de sus negocios y una rápida expansión de sus inversiones directas en el extranjero. En el año 2008, las empresas francesas y sus 20 000 filiales fuera del hexágono empleaban 3,7 millones de personas. Las empresas controladas por grupos extranjeros emplean el 30% de los empleados.
La industria francesa posee una fama y prestigio muy importantes, reflejando el "savoir-faire" francés en los diferentes sectores de las industrias tradicionales como la automoción, el material ferroviario, el lujo, la moda y las industrias de la alimentación, sino también el éxito de tecnologías como el sector de la energía o aeronaves y naves espaciales.

Francia tiene otros sectores fuertes como las telecomunicaciones, las producción de tarjetas de chips (más del 80% de la producción mundial). La industria aeronáutica y espacial está dominada por grandes empresas, entre ellas Dassault, Airbus, Aérospatiale o Matra. La densidad del red industrial y su calidad aseguran una presencia permanente de empresas que sub-contratan muchos servicios para las empresas. 

Durante toda la década 1990 (excepto en 1993) y hasta el comienzo de los años 2000, la industria francesa estaba un sector lidero en la economía nacional, creando muchos empleos y mejorando cada año su productividad. Estaba una industria competitiva y diversificada que generaba superávites comerciales récords, estabilizando sus cuotas de mercado delante Reino Unido y Italia. Pero a comienzos de los años 2000, el sector sufrió mucho la crisis mundial y está acumulando puntos deficitarios exteriores y perdiendo cuotas de mercado desde 2001, con un alza de los costes y una baja significativa de la competitividad.

"Para la industria energética y la industria de transportes, ver arriba Infraestructuras""Para la industria agroalimentaria, ver abajo Agricultura"

La industria del automóvil desempeñaba un papel de liderazgo en el crecimiento de la producción industrial. Los fabricantes se concentran cada vez más en su diseño y montaje, y subcontratan una gran parte de otras funciones, pero hay un efecto multiplicador en las industrias productoras de bienes (acero, plástico, vidrio...), que representan el 30% de sus consumos intermedios, así como la producción de equipos mecánicos (máquina-herramienta), pero también las industrias de servicios (vehículos de transporte y sus partes). Así, 2 465 000 empleos dependen indirectamente de la industria automóvil, y en los 90 mil millones de euros de volumen de negocios, el 65% se realiza con otros sectores.

El sector se ha concentrado mucho en los últimas décadas, y dos constructores están ahora presentes en el mercado, el Groupe PSA (Peugeot, Opel y Citroën) y Renault. En 2008, estos dos grupos produjeron 5 800 millones de vehículos, incluyendo 5 mil millones de automóviles, con cerca de 40% de la producción hecha en Francia.

Exportan más de 4 mil millones de vehículos en 2007, lo que genera excedentes comerciales significativos. Sin embargo, después de una década de crecimiento sostenible, la industria automóvil se ha recientemente enfrentado a una concurrencia mundial aguda, con perdidas de cuotas de mercado, a pesar de establecerse cada vez más en el extranjero para bajar los costes.

A partir de 1945, estaba una necesidad urgente modernizar el sistema de producción para enfrentar el crecimiento demográfico. Pero después de tres décadas de excepcional expansión, en 1975 las dificultades económicas llevaron a las empresas a reducir sus inversiones en el edificio, con una baja de la compra de viviendas por los hogares. Desde 1975, la actividad de la construcción se ha ralentizado y ha experimentado muchas pérdidas de puestos de trabajo, Sin embargo, ha conocido una ligera recuperación desde 1997. Ahora, representa un volumen de negocios de más de 270 millones de euros. La industria de la construcción emplea directamente a 1,7 millones de personas y representa casi el mismo número de puestos de trabajo indirectos.

Las obras públicas son el dominio privilegiado de las grandes empresas que han atravesado un gran movimiento de concentración a partir de 1975. Los más importantes son Bouygues, Vinci y Eiffage. Estas empresas se basan en técnicas cada vez más sofisticadas. Ellos operan dentro del marcado nacional para la construcción de carreteras y de grandes edificios tales como el viaducto de Millau que fue el puente más alto del mundo. También son muy activas fuera de Francia, donde se enfrentan, sin embargo, la competencia de grupos extranjeros, incluidos los de los países recientemente industrializados.

La construcción de viviendas, por el contrario, presenta una estructura muy fragmentada, con 30 000 pequeñas y medianas empresas (PYME). La actividad de este sector está estrechamente vinculada a las medidas adoptadas para la construcción de vivienda, por diversas formas de ayuda y préstamos, que representan un total de unos 18 millones de euros al año. Desde 2000, el número de viviendas construidas cada año supera las 300 000 unidades, y supero las 400 000 unidades entre 2005 y 2007. La casa representa a la mayor parte del sector, con casi el 60% de los nuevas construcciones en 2008.

El sector terciario emplea al 76% de la población activa, más de 16 millones de franceses. Este es el sector que más contribuye al crecimiento de la francesa y que más procura empleos. Representa ahora el 75% del PIB y se desarrolla cada vez más. Así, mientras que en 1998 solo el 19% de los hogares tenían un ordenador y el 4% una conexión internet, en 2008, estaban el 62% y el 56%.

El sector del comercio emplea a más de 3 millones de personas en Francia, casi un empleado de cada cinco. El comercio es la actividad principal de 660 000 empresas: 61% en el comercio minorista (1,6 millones de empleados), el 26% en el comercio mayorista (995 000) y el 13% del comercio en las reparaciones de automóviles (420 000). En cuanto al volumen de negocios, el del comercio mayorista es de 620 mil millones, en el comercio minorista 440 mil millones, y en el comercio de automóviles 140 mil millones. La mayor parte de las empresas son pequeños comercios y tiendas del artesanado comercial, del comercio al por mayor y del comercio automóvil. Pero el sector del comercio minorista es dominado por las empresas de la gran distribución.

La gran distribución francesa emplea a más de 2,5 millones de personas. Con 1 600 hipermercados y 10 000 supermercados, Francia es uno de los países que disponen de los redes más grandes del mundo. Los distribuidores venden más del 60% de la distribución de alimentos y del 30% de los productos no alimentarios. Grupos especializados tales como Carrefour, Auchan, Intermarché, Champion, E.Leclerc y Casino dominan el sector, y se han instalado en el extranjero.

Algunos se han especializado, tales como FNAC, Decathlon, Darty, Conforama o Leroy Merlin. Los hipermercados están ubicados en las afueras de las grandes ciudades, donde hay grandes espacioso, en centros comerciales donde están concentradas muchas grandes superficies. Las pequeñas empresas conocen una rápida disminución de su actividad empresarial, aún si el gobierno les protege. Sin embargo, Francia sigue siendo uno de los países europeos donde hay más pequeñas empresas en el sector minorista, con cuatro personas en promedio por empresa. La venta por correspondencia se ha también desarrollado, dominada por La Redoute, Trois Suisses y CAMIF.

El sistema bancario es un pilar de la economía francesa. Las actividades bancarias emplean a más de 400 000 personas y contribuyen en casi el 3% del PIB. Los principales grupos bancarios están entre las mayores empleadores del país y entre las mayores capitalizaciones bursátiles. Hay ahora más de 40 000 oficinas bancarios, 430 para un millón de personas. Algunos bancos ocupan un importante peso en el sector bancario francés: BNP Paribas, Société Générale, Crédit Agricole, Crédit Mutuel, Caisse d'épargne, Banque Populaire, Dexia, Natixis, CIC, Crédit Lyonnais. Estas se encuentran entre las empresas que emplean el mayor número de personas. La empresa pública La Poste, que asegura la distribución del correo, ha diversificado mucho sus actividades hacia el sector bancario y las actividades financieras, con su filial La Banque Postale, y tienen 17 000 oficinas bancarias en Francia y 10 millones de clientes.

Los bancos se han adaptado rápidamente a las privatizaciones de los años 1980 y han resistido a las crisis bancarias desde 1990. El sector bancario ha experimentado grandes cambios desde principios de los años sesenta: la oposición tradicional entre los bancos convencionales y los bancos de inversión se desvaneció. El sistema bancario se ha desarrollado mucho. Los bancos han internacionalizado sus actividades a raíz de la mundialización del comercio y de la libre circulación de los capitales dentro de la Comunidad Europea. El reciente período se ha caracterizado por una aceleración de las fusiones entre bancos franceses pero también con grupos extranjeros. Los bancos franceses son muy presentes en el extranjero, y en particular en Europa. El número de empresas de créditos está reduciendo rápidamente desde hace dos decenios, y apenas supera 700 ahora.

El sector de los aseguradores franceses ocupa la cuarta posición en todo el mundo con un volumen de negocios superior a 195 mil millones de euros en 2007, de los cuales 93 mil millones fueron realizados en el extranjero. El sector tiene un peso significativo, emplea a 145 000 personas.Tiene cerca de 480 empresas, pero el sector está dominado por algunas grandes aseguradores.

Los mayores aseguradores franceses son grupos internacionales que han diversificado sus actividades en los últimos años para mejorar su rentabilidad, y muchas empresas fusionaron a nivel nacional tan como europeo. AXA, el mayor asegurador francés, (volumen de negocios de 91 mil millones de euros en 2008) es presente en más de 30 países, tiene 80 millones de clientes y 214 000 empleados. CNP Assurances (29 mil millones de euros), la primera aseguradora de personas en Francia, es presente en Europa y en Sudamérica. El Crédit Agricole, que es un banco, tiene una filial para los seguros, segundo asegurador en el territorio nacional.

AGF (11 mil millones de euros), que estaba en el origen una empresa francesa, fue comprada por el alemán Allianz, el líder europea para los seguros, en 2007. Otros mayor aseguradores incluyen Groupama, BNP Paribas Assurances y Sogecap (filial de la Société Générale). Los mayores mutuos son MMA, MACIF, GMF y MAIF, pero son sobre todo presentes en Francia.

Francia es el primer destino del mundo para los turistas. Ha acogido a 81 millones de turistas en 2007, o aproximadamente el 10% del total mundial. El turismo representa el 6% del PBI y emplea directamente a 800 000 activos. Contribuye positivamente a la balanza por cuenta corriente. En 2007 el turismo internacional generó 33 millones de euros de ingresos en Francia, así Francia es el tercer país para los ingresos turísticos detrás de Estados Unidos y España. Pero es el país que acoge al más turistas del mundo, delante de España y de los Estados Unidos.

Hay alrededor de 180 000 empresas, incluidos los 89 000 restaurantes, cafés 51 000, 37 000 hoteles y otros alojamientos colectivos y 3 600 agencias de viajes. Con 8,5 millones de euros en 2000, el sector del turismo se caracteriza por una importante inversión. Estos están relacionados principalmente con el alojamiento y la restauración y las instalaciones turísticas.

Entre los sitios culturales más frecuentados es la Catedral de Notre-Dame de París (14 millones de visitantes en 2007), la Torre Eiffel (7 millones), el Centro Georges Pompidou (5 millones), el Musée du Louvre (8 millones), la Basílica del Sacré Cœur, Nuestra Señora de Lourdes, y el Palacio de Versalles (5 millones). En el sector de parques de ocio, Disneyland París, con 14 millones de entradas en 2007, es líder delante del Parc Astérix. Algunas empresas se han implementado en el extranjero, como las agencias de viajes Club Méditerranée y Pierre et Vacances, y los gigantes Sodexo para la alimentación y Accor para la hostelería.

Francia es el segundo exportador de Europa, por detrás de Alemania, y el quinto del mundo. Sus cuotas de mercado se sitúan en 4% del total mundial, pero está reduciéndose desde el comienzo de los años 2000, a causa de una falta de competitividad de las empresas francesas. Después de haber conseguido excedentes récord en los años 1990, la situación de la balanza de los pagos no dejó de deteriorarse. A partir de los años 1960 y 1970, el francés comercio se ha concentrado hacia los países europeos, pero ahora está diversificando sus socios hacia los países emergentes y países de Europa del este. Sin embargo, su especialización sectorial se ha enfocado en productos manufacturados desde hace un medio siglo, sin gran modificación. La degradación rápida del comercio exterior desde los años 2000, mientras que Alemania registra un superávit récord en las mismas condiciones económicas, plantea la cuestión de la especialización de la industria francesa y de su competitividad.

Se presentan a continuación las mercancías de mayor peso en las importaciones de Francia para el período 2010-hasta abril de 2015. Las cifras están expresadas en dólares estadounidenses valor FOB.

Se presentan a continuación los principales socios comerciales de Francia para el periodo 2010-hasta abril de 2015.La mayoría de sus importadores están en Europa salvo Rusia, Estados Unidos y China. Las cifras expresadas son en dólares estadounidenses valor FOB.

Los intercambios se centran principalmente en países geográficamente próximos, en particular el Euromed que representa casi el 10% de las exportaciones francesas, y países de Europa Central y Oriental. Fuera de Europa, Francia es particularmente activa en África y en menor medida en el Oriente Medio.

El mercado europeo representa dos tercios del comercio exterior francés. Las exportaciones franceses a la UE-27 representan el 63% del total y las importaciones francesas provenientes de UE-27 el 59%. Esta alta concentración del comercio en el mercado europeo es más importante en Francia que para Alemania, Reino Unido y Italia y eso es una tendencia estructural.

El déficit comercial francés con respecto a la UE está creciendo de manera constante en los últimos diez años. Esta degradación se debe principalmente al comercio con Alemania y los países del Benelux y es el signo de una pérdida la competitividad de las empresas nacionales.

También el comercio francés es orientado al Sur y al Este. El Magreb y otras regiones vecinas son clientes importantes para Francia: Francia está el segundo mayor exportador de productos manufacturados a todos los países mediterráneos (detrás de Alemania) y el mayor exportador a los países del Magreb, en particular Argelia y Túnez.

Sin embargo, el peso total de esos países es menor, y después de la Unión Europea, los Estados Unidos son el mayor socio comercial de Francia con el 6% del comercio nacional. Sin embargo, en los próximos años la cuota de esos países en las exportaciones francesas cayera, al exportar cada vez más hacia mercados de alto crecimiento, como China y Brasil. También, Francia se ha orientado mucho hacia los países de Europa del este y de la Asia del Sureste, y la parte de sus intercambios con esos países ha aumentado mucho desde los años 1990.

Francia ya está bien posicionada en el mercado de los "BRIC". China es uno de los motores de la comercio desde finales de los años 1990, y ahora es el segundo proveedor de Francia. India, Rusia y Brasil han acelerado sus importaciones en los últimos años. Francia exporta más que el Reino Unido y Italia a China y Brasil, pero sigue siendo mucho detrás de Alemania. En China, su cuota de mercado es muy debajo en comparación con la de Alemania. En Rusia, el retraso es mucho más fuerte que en los otros tres mercados, pero es el cuarto proveedor para Francia, a causa de las exportaciones de gas. Francia saca provecho del comercio con esos países, aún hay un déficit comercial significativo.

La especialización sectorial Francia es inadecuada. Sus exportaciones son productos manufacturados afectados por la competencia de los países desarrollados. En un entorno competitivo caracterizado por la creciente gama de las exportaciones de los BRIC y la liberalización multilateral de los servicios, las cuotas de mercado de Francia están disminuyendo rápidamente. Las exportaciones franceses están posicionadas en los productos de alta tecnología, pero de media gama. Por fin Francia no es suficientemente implicada en las inversiones materiales.

La mala situación del comercio se debe en gran parte a su especialización industrial inadecuada en comparación con los otros países de la OCDE. La industria francesa es orientada a la media y alta tecnología, en lugar de la alta tecnología. Francia tiene una especialización en alta tecnología, con exportaciones de la industria aeroespacial y productos farmacéuticos, pero Alemania tiene una posición más elevada que Francia en materia de gama.

La gama media representa una mayor proporción de las exportaciones francesas: Francia exporta en la gama alta para el sector baja tecnología, pero más bien en la media gama para la alta tecnología. Al contrario, Alemania refuerza su posición en la alta calidad, en todos los niveles de tecnología.

Además, los productos franceses no tienen una competitividad suficiente, incluyendo para la alta tecnología y la alta gama. Francia ha perdido cuotas de mercado para las exportaciones de productos con alto valor añadido. Primero hay una especialización sectorial inadecuada, ya que Francia produce bienes de capital que son sensibles a los precios y los tipos de cambio (competitividad-precio o coste), cuando Alemania produce bienes industriales cuyas ventas no pueden ser afectadas por las variaciones del precio (competitividad estructural). También la especialización geográfica es inadecuada, ya que Francia es insuficientemente orientada a los países con un alto crecimiento, como India, China y los países emergentes.

La industria francesa sufre tres grandes problemas: la desindustrialización, la debilidad de la innovación y la debilidad del apoyo público a la innovación industrial. La competencia creciente a nivel mundial y la aparición de nuevos mercados en los que las empresas francesas no son suficientemente presentes son las principales razones de las perdidas de cuotas de mercado. También la política industrial del gobierno parece inadecuada, al contrario de países como Japón y EE. UU.
Todos los trabajos recientes son pesimistas en cuanto la situación de la industria francesa. La investigación es insuficiente. Entre 1980 y 2004, la industria ha perdido 1,5 millones de empleos, un tercio de su fuerza de trabajo, y la parte de la producción industrial en el PIB bajo de 30 a 20%. Estos cifras se deben a la desindustrialización de la economía francesa: la industria alcanzó un máximo del 40% de los activos en 1975 y bajo hasta 20% en la actualidad.

La industria no se adaptó a la globalización. Además, Francia acumuló un retraso frente a los otros países desarrollados a partir de los principios de los años 90 en términos de I&D privada. Francia dedica el 2% de su PIB a la investigación y la innovación frente al 2,7% en los EE. UU. y el 3% en Japón. El número de patentes no aumenta en los sectores de alta tecnología (productos farmacéuticos, biotecnología, micro-electrónica).

La acción de los gobiernos en el apoyo a la innovación industrial es insuficiente. La asistencia del gobierno para defender los sectores tradicionales (aeronáutica, espacio, energía nuclear) representa casi el 80% del total de la ayuda pública, lo que explica la debilidad de la ayuda en la tecnología más moderna. El resto de la ayuda está muy fragmentado, no se centra sectores específicos, en particular en las nuevas tecnologías con alto potencial industrial. Las ayudas públicas no ayudan suficientemente las compañías, en particular las mayores pymes, y la mayoría de las pymes son de tamaño demasiado pequeño y no crecen, así tienen dificultad exportar.

Así pues, dada la dispersión de los recursos y la baje de la competitividad, el gobierno francés ha creado en 2004 los polos de competitividad. Esos polos deben permitir una re orientación de los recursos públicos para poner en marcha programas de innovación industrial (la nanotecnología y la biotecnología). Estos programas permiten la coordinación de los actores públicos y privados en torno a un proyectos comunes. El objetivo es fortalecer las especialidades de la industria francesa, crear condiciones favorables para la aparición de nuevas actividades con una fuerte visibilidad internacional, y por tanto, mejorar el atractivo de los territorios y la lucha contra la deslocalización.

A pesar de que solo tiene recursos limitados, Francia es parcialmente independiente gracias a la industria nuclear. Produce la mitad de sus necesidades enérgicas. La producción de electricidad nuclear de Francia esta hoy la segunda más grande del mundo para este tipo de energía, detrás de los Estados Unidos. Sin embargo, las importaciones de Francia representan la gran mayoría de sus hidrocarburos: Francia sigue siendo muy dependiente, aún si esta dependencia ha sido reducida.

La producción de petróleo alcanza 2 millones de toneladas, cuando las importaciones superan 70 millones de toneladas de petróleo crudo (25 millones de toneladas de productos refinados). Francia dispone de una red de refinado muy operativa (13 refinerías). Su dependencia es casi total en cuanto al gas natural, distribuido por el grupo público Gaz de France, un grupo. El carbón representa solo el 5% de la energía primaria nacional, contra 15% en 1973.
La producción de electricidad se ha multiplicada casi por 10 en 50 años. Cubre más del 40% del total de las necesidades energéticas del país. Électricité de France (EDF) se ha convertido en una de las primeras empresas de electricidad en todo el mundo, y exporta su producción en toda la Europa. La energía nuclear representa el 78% del total de la producción nacional de electricidad, las centrales térmicas convencionales más del 10% y la energía hidroeléctrica el 12% (en contra de 55% en 1960).

Francia tiene varias ventajas en cuanto a la energía renovable: grandes recursos hidroeléctricos, uno de los más grandes bosques en Europa, unos fuertes vientos, grandes superficies. También algunas empresas como EDF y Suez han invertido mucho en la energía fotovoltaica, la energía solar y la energía térmica. De hecho, Francia es el primer productor europeo de la energía renovable con más del 20% del total de la producción de la UE. Las energías renovables proporcionan el 12% del consumo de energía, y hay una política energética importante de parte del gobierno, que ha lanzado una serie de reformas y de objetivos para desarrollar este tipo de energía.

Algunos de los principales principios que guiaron la política energética de Francia durante más de treinta años fueron la lucha contra la dependencia energética y el desarrollo de la energía nuclear por culpa a la falta de recursos fósiles en el territorio. Dos acontecimientos más recientes han cambiado las directrices básicas: el deseo de preservar el medio ambiente y un mayor papel dejado por el estado al mercado. Los consumidores franceses benefician de los precios de la energía entre los más bajos en los países de la OCDE.
Un primer principio de la política energética ha sido diversificar las fuentes. Debido a la falta de recursos fósiles en Francia, el gas y el petróleo, que representan actualmente el 49% del consumo de energía, son casi totalmente importados. La dependencia del petróleo en el Oriente Medio es hoy más bajo (27% del petróleo importado) que ayer, porque la mayor cantidad de petróleo proviene de África (19%) del mar del Norte (30%) o Rusia (23%).

Sin embargo, esta diversificación tiene sus límites, ya que hay que recordar que dos tercios de las reservas de petróleo están en el Oriente Medio. En términos de gas natural, el deseo de diversificación ha llevado a Francia a buscar otros socios que Rusia (22% del gas importado): Egipto, Argelia, Países Bajos, países acerca del mar Caspio.

La energía nuclear está en el corazón de la política energética de Francia. El país es el segundo productor de energía nuclear en el mundo y el 78% del consumo francés de electricidad está generada por la energía nuclear. Históricamente, la energía nuclear era una respuesta a la crisis del petróleo de 1973 y al declive de la producción de carbón.

La búsqueda de la independencia energética estaba en el origen de esta política: en aquella época, Francia importaba 76% de sus necesidades de energía, principalmente en forma de hidrocarburos. Hoy en día, gracias a la energía nuclear, esta cifra se redujo por debajo del 50%. El ganó de las importaciones de combustibles fósiles se estima ahora en más de 20 millones de euros al año.

La industria nuclear emplea directamente a 100 000 personas en Francia, un peso económico muy importante. En la lucha contra el efecto invernadero, la ventaja de esta tecnología es innegable: Francia es la más baja emisión de CO2 per cápita de toda la Unión Europea.

El desarrollo de las energías renovables es otro punto más reciente de la política energética. La posición exacta de la energía nuclear en el futuro dependerá en gran medida de los resultados de la investigación en energías renovables. La eólica, la solar y la energía hidroeléctrica tienen esta ventaja en la generación de electricidad que no descarguen sus desechos como la energía nuclear, pero su uso en Francia sigue siendo marginal, ya que actualmente representan solo el 5,6% del consumo total de energía en el país. Sin embargo, los requisitos medioambientales relacionados, en particular, al calentamiento global debería forzar su desarrollo en los próximos decenios.

Desde la década de 1990, la tendencia es la retirada del estado del sector de la energía. Con la privatización de grandes empresas petroleras, la apertura a la competencia (bajo la presión de Bruselas), los productores y los distribuidores de gas y electricidad, nuevos grupos franceses se han convertido en jugadores competitivos en la economía europea y mundial. Sin embargo, el estado aún tiene un papel importante en el sector de la energía debido a su carácter estratégico: ha decidido invertir con otros países en el desarrollo del reactor experimental ITER, basada en la fusión nuclear y puso en marcha la construcción de un reactor nuclear de tercera generación, EPR.

Francia tiene uno de los sistemas de transporte más densos y más eficientes en el mundo, con 146 km de carreteras y 6,2 km de líneas ferroviarias por cada 100 kilómetros cuadrados. Los redes nacionales e internacionales se centran en París, lo que provoca un aumento de la influencia de la capital en la organización del territorio, y por lo tanto un desbalance. En los últimos años las redes de transportes han sidos adaptadas a Europa, con muchos conexiones con los países vecinos.

En el ferrocarril, que ha disfrutado de dos décadas de espectacular desarrollo de las líneas de alta velocidad (TGV). En primer lugar con líneas internas que no dejan de modernizarse, en particular con la LGV Atlantique y la LGV Méditerranée, y, cada vez más, las conexiones con las redes en los países vecinos (Barcelona, Bruselas, Turín, Londres). Hay también una fuerte determinación del gobierno de practicar una política de transportes para mantener una red local en regiones abandonadas.
En cuanto al transporte aéreo, la fuerte competencia entre las compañas en Europa dio lugar al fortalecimiento de la posición dominante de Air France. Mientras que había algunos competidores, todos han desaparecido. A principios de los años 2000, Air France estaba la primera empresa europea y la tercera compañía aérea mundial para el transporte internacional de pasajeros y el cuarto para el transporte internacional de mercancías. Se fusionó en 2003 con KLM.

Air France-KLM se convirtió en el primer grupo europeo y el tercer grupo en todo el mundo en términos de tráfico, y el primer grupo en todo el mundo en términos de negocios. El tráfico de pasajeros es dominada por los aeropuertos de Orly y Roissy-Charles de Gaulle (el 38% de tráfico local y el 76% del tráfico internacional).

Francia tiene ventajas en ámbitos como la energía nuclear, la tecnología aeroespacial y el transporte y la agroindustria. No obstante, los resultados de la innovación, medidos por distintos indicadores, ha disminuido en los últimos años. La reducción de los gastos en I+D, que se redujeron de 2,3% del PIB en 1995 a 2,1% en 2006, ha llevado a Francia detrás de Alemania (2,5%), pero sigue por delante el Reino Unido (1,8%). Hasta mediados de los años 2000, Francia ha sido distanciada por sus principales competidores en las tecnologías de desarrollo rápido, incluidas la biotecnología y la nanotecnología.

Al igual que en muchos estados miembros de la UE, el sector público representa una parte significativa del gasto en I+D, cuando la de las empresas privadas aumenta lentamente. Francia lleva un número de publicaciones científicas per cápita ligeramente por debajo de la media de la OCDE, y es superada por el Reino Unido y Austria, que, sin embargo, invierten menos en I+D. Francia fue responsable del 4,5% de patentes presentadas en todo el mundo en 2005, y el número de patentes per cápita es de alrededor de la media de la OCDE. Si el número de patentes presentadas por las universidades se ha incrementado, la comercialización de los resultados de la investigación sigue siendo insatisfactoria.

La tasa de creación de empresas ha mejorado a través de iniciativas públicas pero son pocos las nuevas empresas que están creciendo. Las empresas francesas se están quedando atrás en cuanto al número de innovaciones de productos, incluyendo en la industria manufacturera, donde la innovación es crucial para la competitividad de las exportaciones. De hecho, entre 1996 y 2005, la proporción de las exportaciones de Francia de media y alta tecnología cayó al 6,8% del total mundial. Las empresas francesas tienen resultados algo mejor en las innovaciones de procesos, sin embargo se sitúan acerca de la media.

En Francia, como en la mayoría de los países industrializados, se ha desarrollado en el último cuarto de siglo una verdadera política medioambiental. Francia fue uno de los primeros países en crear, el 27 de enero de 1971, un Ministerio de Protección de la Naturaleza y el Medio Ambiente, encargado por aquel entonces simplemente de coordinar los esfuerzos del resto de los ministerios. Antes de eso, algunas medidas habían reflejado ya el interés que despertaban tales cuestiones, como demuestra la ley de 1960 por la que se creaban los parques nacionales, y la ley de 1964, muy avanzada para su época, que planteaba mecanismos de intervención económica, basados en el principio de «quien contamina paga».
De 1970 a 1998 la política francesa en materia de medio ambiente se centró en la puesta en marcha de una reglamentación y unas instituciones especializadas dedicadas a la recuperación y la eliminación de residuos (1976), al control de la calidad de aire (1981), y al control energético (1982), instituciones que en 1990 quedaron sumidas en la Agencia del Medio Ambiente y del Control Energético (ADEME). Todo ello desembocó en la adopción de un Plan Nacional para el Medio Ambiente (1990) que condujo a la primera reforma de peso de la administración encargada del medio ambiente que supuso sobre todo la creación en 1991 de 26 direcciones regionales del medio ambiente (DIREN).

El periodo 1989-2001 ha sido una etapa clave en la que la importancia del medio ambiente dentro de las políticas públicas se ha visto considerablemente reforzada por una renovación de la actuación pública (desarrollo de procedimientos de concertación y de contratación), por la modernización y el impulso dado a la administración medioambiental y por la consolidación del dispositivo legislativo, sobre todo mediante la ley de orientación sobre ordenamiento y desarrollo sostenible del territorio (1999) y la adopción del código del medio ambiente (2000).
A partir de 2002 se ha intensificado la atención al desarrollo sostenible por medio de la elaboración de una estrategia nacional, especialmente visible en el proyecto de la carta constitucional sobre medio ambiente; por medio de las políticas emprendidas sobre el agua, la naturaleza, los paisajes, la contaminación, la prevención o los riesgos; por medio de la ampliación de las capacidades en materia de evaluación medioambiental o de análisis socioeconómico; y también por medio de la acción internacional. La política nacional de desarrollo sostenible está supervisada por un Comité Interministerial de Desarrollo Sostenible (CIDD), creado en 2003 y presidido por el primer ministro, que reemplaza a tres instancias anteriores: el Comité Interministerial del Medio Ambiente (CIEN), la Comisión Interministerial de Lucha contra el Efecto Invernadero (CIES) y el Comité Interministerial de Prevención de Grandes Riesgos Naturales (CIPRNM).


Panorama general


Asuntos particulares

Sitios de estadísticas

Sitios gubernamentales

Sitios de análisis
Son sitios públicos, gobernales o independientes que analizan la situación de la economía francesa para consejar al gobierno:


Otras fuentes
Son sitios del ministerio francés de la economía y del ministerio del presupuesto, que se enfocan en puntos particulares de la economía nacional:


Hay muchos sitios públicos en relación con le economía francesa, incluyendo fuentes gobernales.

Sitios gobernales

Organismos públicos


</doc>
<doc id="15412" url="https://es.wikipedia.org/wiki?curid=15412" title="Bituminaria bituminosa">
Bituminaria bituminosa

Bituminaria bituminosa, llamado popularmente trébol hediondo o tedera (Canarias), es una especie de la familia de las fabáceas. 

Es una planta vivaz con tallo de 20-100 cm, más o menos pubescente. Sus Hojas, que exhalan un característico olor a betún, son imparipinnadas con 3 folíolos peciolados; folíolos de formas muy variables y provistos de pelos y glándulas. Inflorescencia largamente pedunculada, con cabeza densa. Corola azul-violeta, raramente púrpura rodeada por un Cáliz quinquefido hirsuto. El fruto es una legumbre monosperma ovoide de alrededor de 1/2cm, muy espinosa y velluda, provista de un pico arqueado, ancho y aplanado, unas dos veces más largo que el cuerpo del fruto.

Este representante del género "Bituminaria" es nativo en toda la Cuenca Mediterránea y Canarias. También lo es en África del Norte no desértica y, hacia el Este, hasta el Cáucaso. Presente en la India e islas del Océano Índico ("ex.gr."Mauricio).

En el archipiélago canario, se reconocen dos taxones infraespecificos:


Estas poblaciones quedan bien separadas morfológicamente de las restantes canarias y peninsulares, que corresponden con la variedad típica, "B. bituminosa" var. "bituminosa".

Habita en matorrales y formaciones preforestales, preestépicas y estépicas, desde el nivel del mar hasta 2.000 msnm. Muy corriente en bordes de caminos y carreteras.

Presenta varios usos actuales y potenciales: 

"Bituminaria bituminosa" fue descrita primero por Carlos Linneo como "Psoralea bituminosa" y publicada en "Species Plantarum", vol. 2, p. 763, 1753 y ulteriormente transferido al género "Bituminaria" por Charles Howard Stirton y publicado en "Bothalia", vol. 13(3–4), p. 318, 1981.





</doc>
<doc id="15413" url="https://es.wikipedia.org/wiki?curid=15413" title="Presión de vapor">
Presión de vapor

La presión de vapor es la presión que ejerce la fase gaseosa o vapor sobre la fase líquida en un sistema cerrado a una temperatura determinada, en la que la fase líquida y el vapor se encuentran en equilibrio dinámico. Su valor es independiente de las cantidades de líquido y vapor presentes mientras existan ambas. Este fenómeno también lo presentan los sólidos; cuando un sólido pasa al estado gaseoso sin pasar por el estado líquido (proceso denominado "sublimación" o el proceso opuesto, llamado "sublimación inversa o deposición") también hablamos de presión de vapor. En la situación de equilibrio, las fases reciben la denominación de líquido saturado y vapor saturado. Esta propiedad posee una relación inversamente proporcional con las fuerzas moleculares, debido a que cuanto mayor sea el módulo de las mismas, mayor deberá ser la cantidad de energía entregada (ya sea en forma de calor u otra manifestación) para vencerlas y producir el cambio de estado.

Inicialmente solo se produce la evaporación, ya que no hay vapor; sin embargo, a medida que la cantidad de vapor aumenta ,y por tanto la presión en el interior de la ampolla, se va incrementando también la velocidad de condensación, hasta que transcurrido un cierto tiempo ambas velocidades se igualan. Llegado este punto se habrá alcanzado la presión máxima posible en la ampolla (presión de vapor o de saturación): la presión total del volumen de gas (mezcla vapor-aire) es equivalente a la presión parcial de la fase vapor (presión de saturación). Esta presión de saturación solo podrá superarse aportando más energía (temperatura) a la mezcla, acción que incrementaría la presión de vapor (la tasa de evaporación), y a su vez, la presión total de la mezcla (ya que es un recipiente cerrado).

El equilibrio dinámico se alcanzará más rápidamente cuanto mayor sea la superficie de contacto entre el líquido y el vapor, pues así se favorece la evaporación del líquido; del mismo modo que un charco de agua extenso pero de poca profundidad se seca más rápido que uno más pequeño pero de mayor profundidad que contenga igual cantidad de agua. Sin embargo, el equilibrio se alcanza en ambos casos para igual presión..

El factor más importante que determina el valor de la presión de saturación es la propia naturaleza del líquido, encontrándose que en general entre líquidos de naturaleza similar, la presión de vapor a una temperatura dada es tanto menor cuanto mayor es el peso molecular del líquido.

Por ejemplo, el aire al nivel del mar saturado con vapor de agua a 20º C, tiene una presión parcial de 23 mbar de agua y alrededor de 780 mbar de nitrógeno, 210 mbar de oxígeno y 9 mbar de argón.

La presión de vapor es medida en unidades estándar de presión. El Sistema Internacional de Unidades (SI) reconoce la presión como una unidad derivada de la fuerza ejercida a través de un área determinada; a esta unidad se le conoce por el nombre de pascal (Pa). Un pascal es equivalente a un newton por metro cuadrado (N·m ó kg·m·s).

La medición experimental de la presión de vapor es un procedimiento simple para presiones similares que estén entre 1 y 200 kPa. Resultados más exactos son obtenidos cerca del punto de ebullición de cada sustancia en particular y con índice de error más significativo en mediciones menores a 1 kPa. Con frecuencia, algunos procedimientos consisten en purificar las sustancias que son analizadas, aislando la sustancia deseada en un contenedor, evitando cualquier gas indeseado y midiendo la presión de equilibrio de la fase gaseosa de la sustancia en el sistema cerrado a distintas temperaturas. El uso de herramientas, como un isoteniscopio, genera una mayor exactitud en el proceso.

Un líquido está, a cualquier temperatura, en equilibrio con su propio vapor cuando las moléculas de este están presentes en una cierta concentración. En este caso hablamos de equilibrio cuando se alcanzan las condiciones de saturación (se iguala evaporación con condensación). La presión que corresponde a esta concentración de moléculas gaseosas se llama "presión de vapor del líquido" a la temperatura dada, y es una relación directa entre la presión parcial de la fase vapor (presión de vapor), y la presión total de la fase vapor (donde existe el componente evaporado, y, en general el componente que previamente ocupaba el volumen, aire). Por lo tanto, conociendo la presión de vapor de un líquido a cierta temperatura, podemos conocer qué concentración de vapor obtendremos en aire en condiciones de saturación: el agua, a 20ºC, tiene aproximadamente una presión de vapor de 0,0234 bara, que en relación a 1 bara de presión atmosférica representa un 2,34% de concentración en volumen). Así sabemos que cuando a 20ºC nos indican que existe una humedad relativa del 100% (condiciones de saturación, capacidad máxima de vapor de agua en aire), nos están informando que un 2,3% del volumen de aire a nuestro alrededor es vapor de agua. La presión de vapor de cada líquido aumenta con la temperatura (las moléculas de líquido tienen más energía para superar la presión externa). Siguiendo con el ejemplo, en condiciones tropicales (40ºC) una humedad del 100% implica una cantidad mucho mayor de agua (presión de vapor de 0,0738 bara, equivalente a 7,38% de vapor en aire), hecho que explica que sea un ambiente tan agobiante.

La temperatura para la cual la presión de vapor de un líquido iguala a la presión externa se denomina punto de ebullición del líquido, asimilado al cambio de fase. A esta temperatura aparecen en el líquido burbujas de vapor que escapan de la superficie. Por ejemplo, en una olla con agua hirviendo se puede observar que las burbujas aparecen en la parte inferior de la olla, donde se alcanzan más rápidamente los 100ºC.

Como una tendencia general, la presión de vapor de los líquidos a presión atmosférica se incrementa con el aumento en la temperatura de ebullición. Este fenómeno es ilustrado en el diagrama adjunto, que muestra, para varios líquidos, el comportamiento de su presión de vapor versus la temperatura. Por ejemplo, a cualquier temperatura, el clorometano (cloruro de metilo) tiene la más alta presión de vapor de todos los líquidos expuestos en el gráfico. También se observa la baja temperatura de ebullición del propano, cuya curva de presión de vapor (línea cian) se interseca con la línea horizontal correspondiente a 1 atmósfera en -41º C.

Aunque la relación entre la presión de vapor y la temperatura no es lineal, el gráfico usa un eje logarítmico vertical para obtener una línea poco curva y así poder representar en un solo gráfico el comportamiento de varios líquidos.

El índice de peligrosidad (Ip) de una sustancia está determinado por el cociente entre la presión de vapor de la sustancia y su CMP (concentración máxima permitida) en condiciones estándar (25º C y 1 atm), por lo que esta propiedad nos permite analizar la viabilidad del uso de una sustancia para actividades determinadas, debido a que indica la probabilidad de que la misma se volatilice.



</doc>
<doc id="15414" url="https://es.wikipedia.org/wiki?curid=15414" title="Allah-Taala">
Allah-Taala

Allah-Taala, dios, supremo, creador y glorificador, adorado principalmente en la región de Hiyaz, en la "Arabia Pétrea", antes del advenimiento de Mahoma.

Varias de las antiguas tribus árabes reconocían, antes de la predicación de Mahoma, un creador del Cielo y de la tierra y le llamaban "Allah-Taalai", el muy alto, en sentido opuesto a la denominación de los otros dioses a los cuales llamaban "Al-ilahat", divinidades inferiores; que según ellos eran la verdadera compañía de Dios, pero sometidas en un todo a su poder.

La fórmula usada para acercarse al "Allah-Taalai", estaba concebida en estos términos. "Yo me consagro a tu servicio, oh Dios, tú no tienes compañero, excepto las divinidades que forman tu cohorte: pero de las cuales eres tú el dueño y soberano como de todo lo que depende de ellas". Cuando plantaban árboles frutales, o sembraban algún campo, tiraban una línea que dividía el suelo en dos partes, una para el Dios soberano y la otra para las divinidades inferiores. Si caían frutos de esta parte a la consagrada al gran Dios, tenían la costumbre de indemnizarlas, lo que no hacían en caso contrario, porque decían que las divinidades inferiores tienen necesidad de lo que pertenece al Dios soberano: pero que este no tiene necesidad de nada.

Los antiguos griegos que no entendieron las palabras "Allah-Taalai" y "Al-ilahat", formaron del primero el nombre "Orotal" y del segundo el de "Alilat", indicando con ellos dos divinidades adoradas por los árabes.


</doc>
<doc id="15415" url="https://es.wikipedia.org/wiki?curid=15415" title="Pancratium maritimum">
Pancratium maritimum

Pancratium maritimum, la azucena de mar -entre otros numerosos nombres vernaculares-, es una planta bulbosa de la familia de las Amarilidáceas. Se encuentra en los arenales y en las dunas fijas de las costas del Atlántico y en las costas del Mediterráneo, a pleno sol y tolera bien periodos prolongados de sequía.

El nardo marítimo es una planta herbácea; las hojas erguidas sobresalen del suelo, formando un denso ramillete; tienen entre 5 y 20 mm de ancho y son de color verde azulado. Tienen un bulbo alargado, blanquecino, con múltiples capas membranosas. Ingerido, resulta de gran toxicidad, debido a que contiene heterósidos cardiotónicos. Las raíces están situadas a una profundidad de hasta 80 cm bajo la superficie. 
Las flores son pediceladas, grandes y llamativas, de color blanco, con gran parecido a los narcisos y muy aromáticas, con un tamaño de hasta 15 cm de longitud. La flor presenta seis tépalos lanceolados abiertos en la periferia y con una nervio dorsal verdoso que nace en la base de la umbela. La corola con forma de trompeta, también blanca, tiene doce dientes de forma triangular. Los seis estambres son de color blanquecino, con unas anteras de color amarillo con forma arriñonada.
El ovario es trilocular y sobresale sobre el cáliz espatoide de dos brácteas caedizas. Su fruto es una cápsula grande y ovoidea, en cuyo interior se encuentran las semillas, negras, angulosas, brillantes, con forma subtriangular, de placentación axial y apiladas en cada uno de los tres lóculos. 

Florece desde finales de junio, en julio y agosto, hasta septiembre, cuando la mayoría de las plantas ya han pasado su floración. 

Vive en las dunas costeras. Requiere suelo bien drenado aunque sea pobre, seco, árido, y exposición a pleno sol. La planta tiene la particularidad de poderse enterrar más profundamente para evitar la desecación, o bien de alargar sus tallos en caso de haber quedado muy cubierta de arena. 
La planta es polinizada por una polilla halcón llamada "Agrius convolvuli". Estos insectos visitan la flor cuando la velocidad del viento es de dos metros por segundo. Cuando es mayor, las polillas no visitan la planta. Aunque la especie es polinizada de manera artificial durante el tiempo ventoso la polinización no es eficaz. Otro dato específico del lirio arena es que no es receptivo a su propio polen y la planta puede reconocerlo. Esta flor solo puede ser fértil con polinización cruzada.

Las hojas son devoradas por la oruga del Lepidóptero "Brithys crini", asociado exclusivamente a esta planta. 

Crece bien en terrenos arenosos, perfectamente drenados y en lugares cálidos y soleados. Para que los bulbos maduren totalmente es imprescindible, luego de la floración, un período cálido y seco. Los bulbos se plantan en otoño a una profundidad de 15 cm. Se multiplica mediante bulbillos, los cuales deben separarse del bulbo original en otoño.
Los bulbos de "Pancratium maritimum" contienen un inhibidor de la acetilcolinesterasa, llamado ungeremina que puede ser adecuado como tratamiento para la enfermedad de Alzheimer. Ungeremina también se ha aislado de "Nerine bowdenii", "Ungernia spiralis", "Zephyranthes flava", "Ungernia minor", "Crinum augustum", "Crinum asiaticum" y "Hippeastrum solandriflorum".

4'-Hydroxy-5,7-dimethoxy-8-methylflavan es un flavano que también se encuentra en la planta "P. maritimum".

"Pancratium maritimum" fue descrita por Carlos Linneo y publicado en "Species Plantarum", 1: 290, 1753.

Pancratium: nombre genérico que proviene del griego παν ("pan", "todo") y κρατυς ("cratys", "potente") en alusión a supuestas virtudes medicinales. 

maritimum: epíteto latino proviene del latín "mar", por su hábitat costero.

Castellano: amor mío (6), amores míos (3), amormio, azucena, azucena de la Virgen (3), azucena de la mar, azucena de mar (17), azucena marina (4), azucenas de la Virgen, corona de rey, corona de rey marítima, lirio de la Virgen (2), lliri de mar, lirio de mar, narciso coronado, narciso de mar (7), narciso marino (2), nardo (2), nardo coronado (6), nardo marino (6), pancracio. Entre paréntesis, la frecuencia del vocablo en España.




</doc>
<doc id="15416" url="https://es.wikipedia.org/wiki?curid=15416" title="Cuscuta campestris">
Cuscuta campestris

Cuscuta campestris es una especie de planta parásita de la familia de las cuscutáceas. Son naturales de la región del Caribe.

Esta planta parásita a otras herbáceas, generalmente sobre especies como "Amaranthus, Daucus, Foeniculum, Medicago, Salsola, Trifolium, Xanthium" y otras especies cultivadas. Todas las especies del género son muy parecidas.

Se ha confundido en algunas publicaciones recientes con "Cuscuta pentagona" , pero las diferencias entre las dos especies son claras. 
En español se la conoce por los siguientes nombres comunes: barba de chivo, cáncer, pelillo, tiña. coscuta


</doc>
<doc id="15417" url="https://es.wikipedia.org/wiki?curid=15417" title="Antoni Gaudí">
Antoni Gaudí

Antoni Gaudí i Cornet o Antonio Gaudí (Reus o Riudoms, 25 de junio de 1852-Barcelona, 10 de junio de 1926) fue un arquitecto español, máximo representante del modernismo catalán.

Gaudí fue un arquitecto con un sentido innato de la geometría y el volumen, así como una gran capacidad imaginativa que le permitía proyectar mentalmente la mayoría de sus obras antes de pasarlas a planos. De hecho, pocas veces realizaba planos detallados de sus obras; prefería recrearlos sobre maquetas tridimensionales, moldeando todos los detalles según los iba ideando mentalmente. En otras ocasiones, iba improvisando sobre la marcha, dando instrucciones a sus colaboradores sobre lo que debían hacer.

Dotado de una fuerte intuición y capacidad creativa, Gaudí concebía sus edificios de una forma global, atendiendo tanto a las soluciones estructurales como a las funcionales y decorativas. Estudiaba hasta el más mínimo detalle de sus creaciones, integrando en la arquitectura toda una serie de trabajos artesanales que dominaba él mismo a la perfección: cerámica, vidriería, forja de hierro, carpintería, etc. Asimismo, introdujo nuevas técnicas en el tratamiento de los materiales, como su famoso "trencadís" hecho con piezas de cerámica de desecho.

Después de unos inicios influido por el arte neogótico, así como ciertas tendencias orientalizantes, Gaudí desembocó en el modernismo en su época de mayor efervescencia, entre finales del y principios del . Sin embargo, el arquitecto reusense fue más allá del modernismo ortodoxo, creando un estilo personal basado en la observación de la naturaleza, fruto del cual fue su utilización de formas geométricas regladas, como el paraboloide hiperbólico, el hiperboloide, el helicoide y el conoide.

La arquitectura de Gaudí está marcada por un fuerte sello personal, caracterizado por la búsqueda de nuevas soluciones estructurales, que logró después de toda una vida dedicada al análisis de la estructura óptima del edificio, integrado en su entorno y siendo una síntesis de todas las artes y oficios. Mediante el estudio y la práctica de nuevas y originales soluciones, la obra de Gaudí culminará en un estilo orgánico, inspirado en la naturaleza, pero sin perder la experiencia aportada por estilos anteriores, generando una obra arquitectónica que es una simbiosis perfecta de la tradición y la innovación. Asimismo, toda su obra está marcada por las que fueron sus cuatro grandes pasiones en la vida: la arquitectura, la naturaleza, la religión y el amor a Cataluña.

La obra de Gaudí ha alcanzado con el transcurso del tiempo una amplia difusión internacional, siendo innumerables los estudios dedicados a su forma de entender la arquitectura. Hoy día es admirado tanto por profesionales como por el público en general: la Sagrada Familia es actualmente uno de los monumentos más visitados de España. Entre 1984 y 2005 siete de sus obras han sido consideradas Patrimonio de la Humanidad por la Unesco.

Antoni Gaudí nació el 25 de junio de 1852, hijo del industrial calderero Francesc Gaudí i Serra (1813-1906) y Antònia Cornet i Bertran (1819-1876). Era el menor de cinco hermanos, de los que solo llegaron a edad adulta tres: Rosa (1844-1879), Francesc (1851-1876) y Antoni. Los orígenes familiares de Gaudí se remontan al sur de Francia, en Auvernia, desde donde uno de sus antepasados, Joan Gaudí, vendedor ambulante, pasó a Cataluña en el ; el apellido en su origen podría ser Gaudy o Gaudin.

Se desconoce el lugar exacto del nacimiento de Gaudí, ya que no se conserva ningún documento que lo especifique, existiendo una controversia entre Reus y Riudoms (dos municipios vecinos y colindantes de la comarca del Bajo Campo) sobre la localidad natalicia del arquitecto. Aun así, en la mayoría de documentos de Gaudí, tanto de su época de estudiante como en los de su época profesional, figura como nacido en Reus. Sin embargo, el propio Gaudí manifestó en diversas ocasiones que era de Riudoms, lugar de origen de su familia paterna. Lo que sí es seguro es que fue bautizado en la iglesia prioral de Sant Pere Apòstol de Reus el día después de su nacimiento. El nombre que consta en su partida de bautismo es Anton Placid Guillem.

Fuese como fuese, Gaudí sintió un gran aprecio por su tierra natal, lo que evidenciaba en su gran mediterraneísmo, hecho que influyó notablemente en su arquitectura: Gaudí decía que los pueblos mediterráneos tienen un sentido innato del arte y el diseño, que son creativos y originales, mientras que los pueblos nórdicos son más técnicos y repetitivos. En palabras del propio Gaudí:

La estancia en su tierra natal le sirvió asimismo para conocer y estudiar profundamente la naturaleza, sobre todo durante sus estancias veraniegas en el Mas de la Calderera, la casa de los Gaudí en Riudoms. Le gustaba el contacto con la naturaleza, por lo que posteriormente se hizo miembro del Centro Excursionista de Cataluña (1879), entidad con la que realizó numerosos viajes por toda Cataluña y el sur de Francia. También practicó durante un tiempo la equitación, y hasta su vejez caminaba unos diez kilómetros diarios.

El ambiente familiar quizás fue uno de los catalizadores de la creatividad de Gaudí. Más de cinco generaciones en su familia trabajaron en la manufactura de productos de cobre, incluyendo a su padre y a sus dos abuelos. Fabricaban principalmente toneles gigantes para la destilación del alcohol de la uva, en Tarragona. El mismo Gaudí admite que los aspectos espaciales de estas grandes figuras de láminas de cobre forjado tuvieron una influencia en él, haciendo que desde pequeño tuviera una noción de los objetos como tridimensionales y no representados sobre un plano geométricamente. Esta percepción de las figuras como objetos maleables y casi esculturales, lo llevaron a desarrollar su estilo tan característico en el futuro.

El pequeño Gaudí era de naturaleza enfermiza, y padeció reumatismo desde niño, lo que le transmitió un carácter un tanto retraído y reservado. Quizá por eso, de mayor se convirtió en vegetariano y en partidario de las teorías higienistas del doctor Kneipp. Debido a estas creencias —y por motivos religiosos—, en ocasiones se entregaba a severos ayunos, tanto que en ocasiones ponía en peligro su propia vida, como en 1894, año en que cayó gravemente enfermo a causa de un prolongado ayuno.
Realizó sus primeros estudios en el parvulario del maestro Francesc Berenguer, padre del que sería uno de sus principales colaboradores, y luego pasó a los escolapios de Reus; destacó en dibujo, colaborando con el semanario "El Arlequín". También trabajó durante un tiempo como aprendiz en la fábrica textil Vapor Nou de Reus. En 1868 se trasladó a Barcelona para cursar enseñanza media en el Convento del Carmen de la ciudad condal. En su adolescencia estuvo cercano al socialismo utópico, realizando junto con dos compañeros de estudios, Eduardo Toda y Josep Ribera i Sans, un proyecto de restauración para el Monasterio de Poblet que lo convertiría en un falansterio utópico-social.

Entre 1875 y 1878 realizó el servicio militar en el Arma de Infantería en Barcelona, siendo destinado a Administración Militar. Pasó la mayor parte del tiempo rebajado de servicio a causa de su salud, por lo que pudo continuar con los estudios. Gracias a ello no tuvo que entrar en combate, pues coincidió en esas fechas con la Tercera Guerra Carlista. En 1876 tuvo lugar el triste suceso de la muerte de su madre, a los 57 años, así como la de su hermano Francesc a los 25, médico recién titulado que no llegó a ejercer.

Cursó arquitectura en la Escuela de la Lonja y en la Escuela Técnica Superior de Arquitectura de Barcelona, donde se graduó en 1878.
Junto a las asignaturas de arquitectura asistió a clases de francés y cursó algunas asignaturas de Historia, Economía, Filosofía y Estética. Su expediente académico fue regular, con algún que otro suspenso; Gaudí se preocupaba más de sus propios intereses que de las asignaturas oficiales. Elies Rogent, director de la Escuela de Arquitectura de Barcelona, dijo en el momento de otorgarle el título:

Para pagarse la carrera, Gaudí trabajó como delineante para diversos arquitectos y constructores, como Leandre Serrallach, Joan Martorell, Emilio Sala Cortés, Francisco de Paula del Villar y Lozano y Josep Fontserè. Quizá por eso, al recibir el título, Gaudí, con su irónico sentido del humor, comentó a su amigo el escultor Llorenç Matamala:

Sus primeros proyectos fueron los de las farolas para la Plaza Real, el proyecto irrealizado de Kioscos Girossi y la Cooperativa Obrera Mataronense. Con su primer encargo importante, la Casa Vicens, Gaudí empieza a adquirir renombre, y recibe encargos cada vez de mayor envergadura. En la Exposición Universal de París de 1878 Gaudí expuso una vitrina realizada para la Guantería Comella. El diseño modernista, a la vez funcional y estético de dicha obra, impresionó al industrial catalán Eusebi Güell que, a su regreso, contactó con el arquitecto para encomendarle varios proyectos que tenía en mente. Comenzó así una larga amistad y un fructífero mecenazgo que dio origen a algunas de las más destacadas obras de Gaudí: las Bodegas Güell, los Pabellones Güell, el Palacio Güell, el Parque Güell y la Capilla de la Colonia Güell. Asimismo, se relacionó con el marqués de Comillas, suegro del conde Güell, para el que realizó El Capricho de Comillas.

En 1883 aceptó hacerse cargo de continuar las recién iniciadas obras del Templo Expiatorio de la Sagrada Familia. Gaudí modificó totalmente el proyecto inicial, convirtiéndola en su obra cumbre, conocida y admirada en todo el mundo. A partir de 1915 se dedicó casi por completo a este proyecto, hasta que murió. Gaudí comenzaba a recibir cada vez más encargos, por lo que, al trabajar en varias obras a la vez, tuvo que rodearse de un amplio equipo de profesionales de todos los campos relacionados con la construcción; en su estudio se formarían numerosos arquitectos que con el tiempo alcanzarían un puesto de renombre en el sector, como Josep Maria Jujol, Juan Rubió, Cèsar Martinell, Francesc Folguera y Josep Francesc Ràfols. En 1885, para escapar de la epidemia de cólera que asolaba Barcelona ("véase": Pandemias de cólera en España), Gaudí pasó una estancia en Sant Feliu de Codines, residiendo en la casa de Francesc Ullar, al que en agradecimiento diseñó una mesa de comedor.
Uno de los acontecimientos de la época para la capital catalana, y que sirvió de punto de partida para el modernismo, fue la Exposición Universal de 1888, donde los principales arquitectos del momento expondrían sus mejores obras. Gaudí participó con el edificio de la Compañía Trasatlántica, y recibió un encargo para reestructurar el Salón de Ciento del Ayuntamiento de Barcelona, que finalmente no se llevó a cabo. En los primeros años 1890 recibió dos encargos fuera de Cataluña: el del Palacio Episcopal de Astorga y el de la Casa Botines en León. Así, la fama y el prestigio del arquitecto reusense se iba extendiendo por toda España. En 1891 viajó a Málaga y Tánger para examinar el terreno de un proyecto para unas Misiones Católicas Franciscanas, que le había encargado el 2º marqués de Comillas; el proyecto no se efectuó, pero las torres proyectadas para las Misiones le sirvieron a Gaudí como modelo para las torres de la Sagrada Familia.
En 1899 se hizo socio del Círculo Artístico de San Lucas, sociedad artística de corte católico fundada en 1893 por el obispo José Torras y Bages y los hermanos Josep y Joan Llimona. También se afilió a la Lliga Espiritual de la Mare de Déu de Montserrat, entidad catalanista igualmente de signo católico. Se evidencia así el carácter conservador y religioso de su pensamiento político, vinculado a la defensa de la identidad cultural del pueblo catalán. Pese a la aparente contradicción entre los ideales utópicos de su juventud y su posterior adscripción a posiciones más conservadoras, la evolución puede resultar natural si tenemos en cuenta la profunda espiritualidad del arquitecto; en palabras de Cèsar Martinell, “sustituyó la filantropía laicista por la caridad cristiana”.

El principio de siglo encontró a Gaudí embarcado en numerosos proyectos, en los que se evidenciaba el cambio de su estilo, cada vez más personal e inspirado en la naturaleza. En 1900 recibió el premio al mejor edificio del año por la Casa Calvet, otorgado por el Ayuntamiento de Barcelona. Durante la primera década del siglo se ocupa de proyectos como la Casa Figueras, más conocida como Bellesguard, el Parque Güell, proyecto de urbanización que no tuvo éxito, y la restauración de la Catedral de Santa María de Palma de Mallorca, para la que realizó varios viajes a la isla. Entre 1904 y 1910 construye la Casa Batlló y la Casa Milà, dos de sus obras más emblemáticas.
La fama de Gaudí iba en aumento, provocando por ejemplo que en 1902 el pintor Joan Llimona escogiese la fisonomía de Gaudí para representar a san Felipe Neri en las pinturas del crucero de la iglesia de San Felipe Neri de Barcelona. Ese año funda con Joan Santaló, hijo de su amigo el doctor Pere Santaló, una sociedad dedicada al forjado de hierro, que fracasó.

Desde su traslado a Barcelona, Gaudí había cambiado a menudo de domicilio: en su época de estudiante vivió de pensión, generalmente en la zona del Barrio Gótico; al iniciar su carrera, pasó a diversos pisos de alquiler en la zona del Ensanche. Por fin, en 1906 se instaló en una casa de propiedad, en el Parque Güell, construida por su ayudante Francisco Berenguer como casa de muestra de la urbanización; actualmente es la Casa-Museo Gaudí. Aquí vivió con su padre (fallecido en 1906 a los 93 años) y su sobrina, Rosa Egea Gaudí (fallecida en 1912 a los 36 años). Vivió en esta casa hasta 1925, pocos meses antes de su muerte, residiendo este último tiempo en el taller de la Sagrada Familia.
Uno de los sucesos que marcaron profundamente a Gaudí fueron los acontecimientos de la Semana Trágica de 1909; Gaudí permaneció ese tiempo recluido en su casa del Parque Güell, pero debido al ambiente anticlerical y a los atentados contra iglesias y conventos temió por la integridad de la Sagrada Familia —que afortunadamente no sufrió daños—.

En 1910 se celebró en el Grand Palais de París una exposición dedicada a Gaudí, dentro del salón anual de la Société des Beaux-Arts de Francia. Gaudí participó a instancias del conde Güell, concurriendo con una serie de fotos, planos y maquetas en yeso de varias de sus obras. Aunque participó fuera de concurso, recibió muy buenas críticas por parte de la prensa francesa. Buena parte de esta exposición se pudo ver al año siguiente en el I Salón Nacional de Arquitectura celebrado en el Pabellón Municipal de Exposiciones del Buen Retiro de Madrid.

Mientras se celebraba la exposición de París, en mayo de 1910, Gaudí pasó una estancia de reposo en Vich, donde diseñó dos farolas de basalto y hierro forjado para la Plaza Mayor de Vich, con ocasión del centenario de Jaime Balmes. Al año siguiente también se vio obligado a pasar una temporada en Puigcerdà, a causa de unas fiebres de Malta; en ese periodo de descanso concibió la fachada de la Pasión de la Sagrada Familia. Debido a su gravedad, el 9 de junio redactó un testamento ante el notario Ramon Cantó i Figueres; por fortuna, pudo reponerse por completo.

Los años 1910 fueron duros para Gaudí, que sufrió varias desgracias: en 1912 murió su sobrina Rosa; en 1914 falleció su principal colaborador, Francisco Berenguer; en 1915 una grave crisis económica casi paraliza las obras de la Sagrada Familia; en 1916 murió su amigo José Torras y Bages, obispo de Vich; en 1917 se interrumpen las obras de la Colonia Güell; en 1918 falleció su amigo y mecenas, Eusebi Güell. Quizá por todo ello desde 1915 se dedica por entero a la Sagrada Familia, refugiándose en su trabajo. Gaudí confiesa a sus colaboradores:

Efectivamente, los últimos años de su vida los dedica por completo a la «Catedral de los pobres» —como es popularmente conocida—, para la que incluso llegará a pedir limosna a fin de poder continuar con las obras. Aparte de esa dedicación, realiza pocas más actividades, casi siempre relacionadas con la religión: en 1916 participó en un cursillo de canto gregoriano impartido en el Palacio de la Música Catalana por el monje benedictino Gregori M. Sunyol.

Gaudí vivió dedicado por completo a su profesión, permaneciendo soltero toda su vida. Al parecer, tan solo en una ocasión se sintió atraído por una mujer, Josefa Moreu, maestra de la Cooperativa Mataronense, hacia 1884, pero no fue correspondido. Desde entonces Gaudí se refugió en su profunda religiosidad, en la que encontraba gran sosiego espiritual. A menudo se ha pintado la imagen de un Gaudí huraño y antipático, de bruscas contestaciones y gestos altaneros; pero la gente que lo trató más de cerca lo describió como persona afable y cortés, buen conversador y fiel con sus amigos, entre los que destacaron especialmente su mecenas, Eusebi Güell, y el obispo de Vic, José Torras y Bages, así como los escritores Joan Maragall y Jacinto Verdaguer, el doctor Pere Santaló y algunos de sus más fieles colaboradores, como Francisco Berenguer y Llorenç Matamala.
La apariencia personal de Gaudí —de rasgos nórdicos, pelo rubio y ojos azules— sufrió una radical transformación con el paso del tiempo: de ser un joven con aspecto de dandi (trajes caros, pelo y barba bien arreglados, gustos de "gourmet", frecuente asistencia al teatro y a la ópera, incluso visitaba las obras montado en su carruaje), pasó en su vejez a la más estricta sencillez, comiendo con frugalidad, vistiendo trajes viejos y gastados, con un aspecto descuidado, tanto que a veces lo tomaban por mendigo, como por desgracia pasó en el momento del accidente que le provocó la muerte.

Gaudí no dejó prácticamente escritos, aparte de informes técnicos de sus obras requeridos por instancias oficiales, algunas cartas a amigos (principalmente a Joan Maragall) y algún artículo periodístico. Se conservan algunas frases suyas recogidas por algunos de sus ayudantes y discípulos, principalmente Josep Francesc Ràfols, Joan Bergós, Cèsar Martinell e Isidre Puig i Boada. El único escrito dejado por Gaudí es el conocido como "Manuscrito de Reus" (1873-1878), una especie de diario de estudiante donde recogía diversas impresiones sobre arquitectura y decoración, exponiendo sus ideas al respecto; destacan los análisis que hizo sobre el templo cristiano y la casa solariega, así como un texto sobre ornamentación y una memoria para una mesa-escritorio.
Gaudí se reconoció siempre partidario del catalanismo, aunque nunca quiso vincularse con la política –algunos políticos como Francisco Cambó o Enric Prat de la Riba le propusieron presentarse a diputado, pero él declinó el ofrecimiento–. Aun así, tuvo diversos altercados con la policía: en 1920 fue golpeado por la misma en un tumulto formado en la celebración de los Juegos Florales; el 11 de septiembre de 1924, Día Nacional de Cataluña, durante una manifestación en contra de la prohibición del uso del catalán por parte de la dictadura de Primo de Rivera, fue arrestado por la Guardia Civil, pasando una breve estancia en el calabozo, del que salió con una fianza de 50 pesetas.

El 7 de junio de 1926 Gaudí se dirigía a la iglesia de San Felipe Neri, que visitaba a diario para rezar y entrevistarse con su confesor, mosén Agustí Mas i Folch; pero al pasar por la Gran Vía de las Cortes Catalanas, entre las calles Gerona y Bailén, fue atropellado por un tranvía, que lo dejó sin sentido. Siendo tomado por un mendigo, al ir indocumentado y a causa de su aspecto descuidado, con ropas gastadas y viejas, no fue socorrido de inmediato, hasta que un guardia civil paró un taxi que lo condujo al Hospital de la Santa Cruz. Al día siguiente lo reconoció el capellán de la Sagrada Familia, mosén Gil Parés, pero ya era tarde para hacer nada por él. Murió el día 10 de junio de 1926, a los 73 años de edad, en la plenitud de su carrera. Fue enterrado el 12 de junio, con presencia de grandes multitudes que quisieron darle el último adiós, en la capilla de Nuestra Señora del Carmen de la cripta de la Sagrada Familia. En su lápida figura la siguiente inscripción:

Tras su muerte Gaudí cayó en un relativo olvido, y su obra fue denostada por la crítica internacional por barroca y excesivamente fantasiosa. En su tierra natal fue igualmente menospreciado por la nueva corriente que sustituyó al modernismo, el novecentismo, estilo que retornaba a los cánones clásicos. En 1936, durante el transcurso de la Guerra Civil Española, fue asaltado el taller de Gaudí en la Sagrada Familia, destruyéndose gran cantidad de documentos, planos y maquetas del arquitecto modernista.
Su figura comenzó a ser reivindicada en los años 1950, por Salvador Dalí en primer lugar, seguido del arquitecto Josep Lluís Sert. En 1956 se organizó una retrospectiva sobre Gaudí en el Salón del Tinell de Barcelona, y en 1957 su primera gran exposición internacional, en el MoMA de Nueva York. Asimismo, entre los años 1950 y 1960, los estudios de críticos internacionales como Bruno Zevi, George Collins, Nikolaus Pevsner y Roberto Pane dieron gran difusión a la obra de Gaudí, mientras que en su tierra natal era reivindicado por Alexandre Cirici, Juan Eduardo Cirlot y Oriol Bohigas. También es de remarcar el gran éxito obtenido por Gaudí en Japón, donde su obra es muy admirada, destacando los estudios realizados por Kenji Imai y Tokutoshi Torii. Desde entonces la valoración de Gaudí ha ido en aumento, proceso que se reflejó en la catalogación en 1969 de 17 obras de Gaudí como Monumentos Histórico-Artísticos de Interés Cultural por parte del Ministerio de Cultura español (RD 1794/1969), siendo el primer artista «contemporáneo» en alcanzar esta distinción, pues hasta entonces las normas dictaban que solo podían tener esta catalogación las obras con un siglo o más de antigüedad. Igualmente, en 1984 varias obras del arquitecto fueron declaradas como Patrimonio de la Humanidad de la Unesco.

En 1952, centenario del nacimiento del arquitecto, se fundó la Asociación de Amigos de Gaudí, para divulgar y conservar el legado dejado por el artífice catalán. En 1956 se creó la Cátedra Gaudí, perteneciente a la Universidad Politécnica de Cataluña, con el objeto igualmente de profundizar en el estudio de la obra gaudiniana y participar en su conservación; en 1987 el rey Juan Carlos I le concedió el título de Real Cátedra Gaudí. En 1976, con motivo del 50 aniversario de su muerte, el Ministerio de Asuntos Exteriores organizó una exposición sobre Gaudí que recorrió todo el mundo.

Con motivo del 150 aniversario del nacimiento de Gaudí se celebró el año 2002 el Año Internacional Gaudí, con multitud de actos oficiales, conciertos, espectáculos, conferencias, publicaciones, etc. Entre otros eventos, el 24 de septiembre de ese año se estrenó en el Palacio de los Deportes de Barcelona el musical "Gaudí", sobre la vida y obra del arquitecto reusense, obra de Jordi Galceran, Esteve Miralles y Albert Guinovart. El año 2008 se instituyeron en su honor los Premios Gaudí, otorgados por la Academia del Cine Catalán, que reconocen las mejores producciones cinematográficas catalanas del año.

Hombre de profunda religiosidad y de vida ascética, se ha propuesto la beatificación de Antoni Gaudí, proceso iniciado en 1998 por el arzobispo de Barcelona, Ricard Maria Carles. El año 2000 fue autorizado el inicio del proceso por parte de la Santa Sede con el decreto nihil obstat, por el cual Gaudí pasa a ser considerado siervo de Dios, el primer peldaño para la beatificación.

En 2013, con motivo del 130º aniversario de la primera obra de Gaudí, la Cooperativa Obrera Mataronense, se creó con el apoyo de la Generalidad de Cataluña el Consejo para el Fomento y la Difusión de la obra de Gaudí, un órgano presidido por el consejero de Cultura de la Generalidad encargado de preservar el legado arquitectónico del genio modernista, así como difundir y dar a conocer su obra entre la población. Entre otras iniciativas, para 2017 está previsto el lanzamiento de un «pasaporte Gaudí», similar al existente para el camino de Santiago, que sería sellado al visitar cada uno de los edificios construidos por el arquitecto, fomentando así el conocimiento de sus obras.

La trayectoria profesional del arquitecto tuvo una evolución "sui generis", debido a su constante investigación en el campo de la estructura mecánica de las obras. En sus inicios, Gaudí recibió cierta influencia del arte oriental (India, Persia, Japón), a través del estudio de los teóricos de la arquitectura historicista, Walter Pater, John Ruskin y William Morris. Vemos esta corriente orientalizante en obras como el Capricho de Comillas, el Palacio Güell, los Pabellones Güell o la Casa Vicens. Más tarde, sigue la corriente neogótica de moda en el momento, siguiendo los dictámenes del arquitecto francés Viollet-le-Duc. Se puede percibir en el Colegio de las Teresianas, el Palacio Episcopal de Astorga, la Casa Botines y la Casa Bellesguard, así como en la cripta y el ábside de la Sagrada Familia. Finalmente, desemboca en su etapa más personal, con un estilo naturalista, individual, orgánico, inspirado en la naturaleza, en el que realizará sus obras maestras.

Durante su época de estudiante Gaudí pudo contemplar una colección de fotografías que la Escuela de Arquitectura poseía sobre Egipto, la India, el arte persa, maya, chino y japonés, así como los monumentos islámicos españoles, los cuales le dejaron una profunda huella, sirviéndole de inspiración para muchas de sus obras. También estudió con detenimiento el libro "Plans, elevations, sections and details of the Alhambra", de Owen Jones, perteneciente a la biblioteca de la Escuela. De los artes nazarí y mudéjar tomó múltiples soluciones estructurales y ornamentales que aplicó con ciertas variantes y libertad estilística a sus obras. Un aspecto a destacar que Gaudí toma del arte islámico es la indefinición espacial, la concepción del espacio sin límites estructurados; espacio que adquiere un sentido secuencial, fragmentado, a través de pequeños tabiques o huecos diáfanos, que crean separación sin suponer barreras compactas que delimiten un espacio uniformemente cerrado.

Pero sin duda el estilo que más le influyó fue el arte gótico, que a finales del vivía un gran renacimiento debido sobre todo a la obra teórica y restauradora de Viollet-le-Duc. El arquitecto francés propugnaba estudiar los estilos del pasado y adaptarlos al presente de una forma racional, atendiendo tanto a la razón estructural como a la ornamental. Sin embargo, para Gaudí el gótico era «imperfecto», porque pese a la eficacia de algunas de sus soluciones estructurales era un arte que había que «perfeccionar». En sus propias palabras:

Después de estas influencias iniciales, Gaudí desemboca en el modernismo en su época de mayor esplendor, en los años situados entre los siglos y . En sus inicios, el modernismo encuentra la inspiración en la arquitectura historicista, ya que para los artistas modernistas la vuelta al pasado supone una reacción contra las formas industriales impuestas por los nuevos adelantos tecnológicos producidos con la Revolución industrial. La utilización de los estilos del pasado supone una regeneración moral que permite a la nueva clase dirigente, la burguesía, identificarse con unos valores que reconocen como sus raíces culturales. Asimismo, el resurgir de la cultura catalana desde mediados del (la Renaixença), lleva a adoptar las formas góticas como estilo «nacional» de Cataluña, con la pretensión de conjugar nacionalismo y cosmopolitismo, de integrarse en la corriente modernizadora europea.

Algunos rasgos esenciales del modernismo serán: un lenguaje anticlásico heredero del romanticismo, con tendencia a un cierto lirismo y subjetivismo; vinculación decidida de la arquitectura con las artes aplicadas y los oficios artísticos, creando un estilo remarcadamente ornamental; utilización de nuevos materiales, creando un lenguaje constructivo mixto y rico en contrastes, buscando el efecto plástico del conjunto; fuerte sentimiento de optimismo y fe en el progreso, que produce un arte exaltado y enfático, reflejo del clima de prosperidad del momento, sobre todo en la clase burguesa.

Gaudí suele ser considerado el gran maestro del modernismo catalán, pero su obra va más allá de cualquier estilo o intento de clasificación. Es una obra personal e imaginativa que encuentra su principal inspiración en la naturaleza. Gaudí estudió con profundidad las formas orgánicas y anárquicamente geométricas de la naturaleza, buscando un lenguaje para poder plasmar esas formas en la arquitectura. Algunas de sus mayores inspiraciones vendrán de la montaña de Montserrat, las cuevas de Mallorca, la Cueva del Salnitre (Collbató), los riscos de Fra Guerau en la sierra de Prades cerca de Reus, la montaña de Pareis al norte de Mallorca, el Coll de la Desenrocada (entre Argentera y Vilanova d'Escornalbou) o Sant Miquel del Fai en Bigas, todos ellos lugares visitados por Gaudí.

Este estudio de la naturaleza se traduce en el empleo de formas geométricas regladas como son el paraboloide hiperbólico, el hiperboloide, el helicoide y el conoide, que reflejan exactamente las formas que Gaudí encuentra en la naturaleza. Las superficies regladas son formas generadas por una recta, denominada generatriz, al desplazarse sobre una línea o varias, denominadas directrices. Gaudí las halló en abundancia en la naturaleza, como por ejemplo en juncos, cañas o huesos; decía que no existe mejor estructura que un tronco de árbol o un esqueleto humano. Estas formas son a la vez funcionales y estéticas, y Gaudí las emplea con gran sabiduría, sabiendo adaptar el lenguaje de la naturaleza a las formas estructurales de la arquitectura. Gaudí asimilaba la forma helicoidal al movimiento, y la hiperboloidal a la luz. Decía lo siguiente sobre las superficies regladas:


</doc>
<doc id="15418" url="https://es.wikipedia.org/wiki?curid=15418" title="Alfabeto gótico">
Alfabeto gótico

El alfabeto gótico es fundamentalmente una adaptación del alfabeto griego en su grafía uncial.

Proviene del alfabeto ulfilano creado por el obispo Ulfilas. Además contiene tres caracteres de uncial latino y cinco runas germánicas. Cada letra posee un valor numérico y dos de ellas no poseen ninguna otra función. La transliteración en las obras científicas y didácticas se realiza aumentando en dos símbolos el alfabeto latino por medio de la ligadura, "ƕ" "(h+v") y la letra "thorn", "þ", tomada del inglés antiguo. La notación de Wulfila era ambigua: Un mismo dígrafo "ai" podía representar [ai], [ɛ] o [ɛ̄]. La transcripción recurre a diacríticos para aligerar las dificultades de lectura.

"Nota: Para poder visualizar estos caracteres es posible que el ordenador necesite una ."

Las respectivas grafías en código unicode ordenadas alfabéticamente corresponden a: 𐌰 𐌱 𐌲 𐌳 𐌴 𐌵 𐌶 𐌷 𐌸 𐌹 𐌺 𐌻 𐌼 𐌽 𐌾 𐌿 𐍀 𐍁 𐍂 𐍃 𐍄 𐍅 𐍆 𐍇 𐍈 𐍉 𐍊.



</doc>
<doc id="15419" url="https://es.wikipedia.org/wiki?curid=15419" title="Economía de Alemania">
Economía de Alemania

La economía de Alemania es la cuarta economía más poderosa del mundo después de la de Estados Unidos, China y Japón y la quinta por PIB (PPA). El país es considerado el motor económico de la Unión Europea (UE). En 2014, Alemania registró el mayor superávit comercial en el mundo con 285 mil millones de dólares, por lo que es el mayor exportador de capital a nivel mundial. Alemania es el tercer mayor exportador del mundo con 1.511.000 millones de dólares exportados en 2014. Las exportaciones representan el 41% de la producción nacional. El sector servicios contribuye alrededor del 70% del total del PIB, la industria 29,1%, y la agricultura 0,9%. Los principales bienes exportados de Alemania son vehículos, maquinarias, productos químicos, productos electrónicos, productos farmacéuticos, equipos de transporte, metales básicos, productos alimenticios, caucho y plásticos. 

La política socio-económica de Alemania se basa en el concepto de economía social de mercado.

Alemania es el primer país industrializado importante del mundo que se compromete a la transición energética renovable llamada Energiewende. Alemania es el principal productor de turbinas eólicas y tecnología de energía solar en el mundo. Más de 1,5 millones de plantas de generación de energía renovable se han instalado en Alemania durante los últimos 25 años. Las energías renovables producen en la actualidad más del 27% de la electricidad total que se consume en Alemania.

El 99% de todas las empresas alemanas pertenecen a las denominadas Mittelstand, pequeñas y medianas empresas de propiedad familiar. De las 500 empresas que cotizan en bolsa más grandes del mundo, 50 tienen su sede en Alemania. Por capitalización de mercado, 20 empresas con sede en Alemania están en el Fortune Global 500 como Volkswagen, Allianz, Daimler, BMW, Siemens, BASF, Múnich Re, E.ON, Bayer, y RWE.

Alemania es el mayor productor de lignito en el mundo. Alemania también es rica en madera, hierro, potasa, sal, uranio, níquel, cobre y gas natural. La energía en Alemania se obtiene principalmente por los combustibles fósiles, seguida de la energía nuclear, y por las energías renovables como la biomasa (madera y biocombustibles), eólica, hidráulica y solar.

Alemania es la ubicación más importante para las ferias comerciales del mundo. Alrededor de dos tercios de las ferias más importantes del mundo se llevan a cabo en Alemania. Las mayores ferias anuales y congresos internacionales se llevan a cabo en varias ciudades alemanas, como Hannover, Múnich, Frankfurt y Berlín.

Alemania es el único país entre los cinco principales exportadores de armas que no es miembro permanente del Consejo de Seguridad de las Naciones Unidas.

La Revolución Industrial en Alemania llegó casi un siglo más tarde que a Gran Bretaña, Francia y Bélgica, ya que Alemania se convirtió en un país unificado en el siglo XIX.

El establecimiento del Zollverein (unión aduanera alemana) y la creación de sistemas ferroviarios fueron los principales impulsores de la revolución industrial y de la unión política. En 1834, se eliminaron las barreras arancelarias entre los estados alemanes. En 1835, el primer ferrocarril alemán fue construido uniendo Dresde y Leipzig, y tuvo tanto éxito que la década de 1840 se vivió una "fiebre por los trenes" en todos los estados alemanes. Con el tiempo, otros estados alemanes ingresaron a la unión aduanera y comenzaron a vincular sus sistemas de ferrocarriles, que comenzaron a conectar todos los rincones de Alemania. Con la creación de un sistema ferroviario en toda Alemania en la década de 1840 se intensificó el desarrollo económico que abrió nuevos mercados para los productos locales, se incrementó la demanda de ingenieros, arquitectos y operarios calificados y estimuló las inversiones en el carbón y el hierro.
Con la derrota de la Francia del II Imperio en 1870 y la creación del Imperio Alemán en 1871 la industrialización se estimuló aún más. La reacción a las conquistas de Napoleón I de los estados alemanes durante la época de la Revolución Francesa produjo importantes reformas institucionales, incluyendo la supresión de las restricciones feudales sobre la venta de grandes latifundios, la reducción del poder de los gremios en las ciudades, y la introducción de una nueva ley comercial más eficiente. No obstante, las decisiones políticas sobre la economía del Imperio Alemán seguían en gran parte controlados por una coalición de "centeno y hierro", es decir los terratenientes Junker del este y la industria pesada del oeste.

En el año 1900, Alemania era líder mundial en la industrialización. Entre 1895 y 1907, el número de trabajadores empleados en la construcción de maquinaria se duplicó de medio millón a más de un millón. Alemania también fue testigo de un crecimiento demográfico sin precedentes pasando de 35 millones de habitantes en 1850 a 67.000.000 en 1913. El rápido avance hacia la madurez industrial condujo a un cambio drástico en la situación económica de Alemania, de ser un importador de tecnología para ser un gran exportador de productos terminados. En 1913, Alemania llegó a dominar todos los mercados europeos y en 1914, se convirtió en uno de los tres mayores exportadores del mundo.

Los nazis llegaron al poder, mientras que el desempleo era muy alto, pero se logró el pleno empleo más tarde gracias a los programas públicos masivos como el Reichsbahn, Reichspost o Reichsautobahn.

Las políticas económicas y fiscales expansivas tras la crisis financiera de 1931 (como Alemania estaba fuera del patrón oro) fueron aconsejadas por el Ministro de Economía no-nazi, Hjalmar Schacht, que en 1933 se convirtió en el presidente del banco central. Hjalmar Schacht abandonó el puesto en 1938 y fue reemplazado por Hermann Göring.

Las políticas comerciales del Tercer Reich estaban encaminadas a la autosuficiencia, pero con la falta de materias primas, Alemania tendrían que mantener los vínculos comerciales, pero en las preferencias bilaterales, los controles de divisas, cuotas de importación y subvenciones a la exportación en virtud de lo que se llamó el "Nuevo Plan" (Plan de Neuer) de 19 de septiembre 1934. El "Plan Nuevo" se basaba en el comercio con los países menos desarrollados que cambiarían las materias primas para los productos industriales alemanes. Esta política se conoce como la política Grosswirtschaftsraum ("mayor área económica").

Finalmente, el partido nazi desarrolló fuertes relaciones con las grandes empresas y los sindicatos, abolidos en 1933 con el fin de formar el Servicio Nacional del Trabajo (RAD) y el Frente Alemán del Trabajo (DAF) para ajustar las horas de trabajo.

Con la sustitución del Reichsmark por el Marco alemán como moneda de curso legal, se vivió un período duradero de baja inflación y rápido crecimiento industrial supervisado por el gobierno encabezado por el canciller Konrad Adenauer y su ministro de Economía, Ludwig Erhard, levantando la Alemania Occidental de la total devastación de la guerra para convertirse en una de las naciones más desarrolladas en la Europa moderna.

El Plan Marshall se amplió para incluir también a la Alemania Occidental después de darse cuenta de que el estancamiento de la economía alemana occidental estaba frenando la recuperación del resto de Europa. La cuantía de la ayuda monetaria (que era en forma de préstamos) recibidas por Alemania a través del Plan Marshall fue de alrededor de mil seiscientos cincuenta millones de dólares (en total); pero se encuentra en gran medida eclipsado por el importe que los alemanes tuvieron que pagar por reparaciones de guerra y por los altos cargos que los Aliados hicieron pagar a Alemania, del orden de 2400 millones de dólares al año. 

En 1953 se decidió que Alemania debía pagar mil cien millones de dólares de la ayuda que había recibido. El último reembolso se hizo en junio de 1971. Es discutible, sin embargo, que la recuperación hubiera sido posible sin el impulso económico inicial del Plan Marshall, así como la modernización de la infraestructura proporcionada por el plan de recuperación económica.

Además de estos factores, el trabajo eficiente, largas jornadas laborales a pleno rendimiento en los años 1950, 1960 y principios de 1970, y la mano de obra extra suministrada por miles de Gastarbeiter ("trabajadores invitados") ofrecieron una base esencial para la recuperación económica.
Los esfuerzos de reconstrucción siguieron al final de la guerra, la industria y con ello la economía del país se desarrollaron rápidamente, dando lugar al fenómeno histórico conocido como el milagro económico alemán. La calidad de los productos alemanes nunca perdió su renombre a nivel mundial, y la nación se impuso en menos de una década como primera potencia económica de Europa, posición que conserva hoy en día.

A principios de la década de 1950 la Unión Soviética se había apoderado de las reparaciones de guerra en forma de productos agrícolas e industriales y exigió pagos de reparaciones más pesados. La Baja Silesia, que contenía las minas de carbón, y Stettin, un puerto natural prominente, se perdieron a favor de Polonia.

Las exportaciones de la Alemania Occidental superó 323 mil millones dólares en 1988. En el mismo año, Alemania Oriental exportó 30.7 mil millones de dólares en bienes, el 65% a otros estados comunistas. La Alemania Oriental tuvo desempleo cero.

En 1976, el crecimiento medio anual del PIB fue de aproximadamente 5,9%

La economía alemana prácticamente se estancó en el comienzo de la década de 2000. Las peores cifras de crecimiento se lograron en 2002 (+ 1,4%), en 2003 (+ 1,0%) y en 2005 (+ 1,4%). El desempleo también era alto. Debido a estos problemas, junto con envejecimiento de la población alemana, el sistema de bienestar estuvo bajo una presión considerable. Esto llevó al gobierno a llevar a cabo un amplio programa de reformas de austeridad, la Agenda 2010, incluidas las reformas del mercado de trabajo conocidas como Hartz I - IV.

En la última parte de la primera década de 2000 la economía mundial experimentó un alto crecimiento, de la que Alemania como principal exportador también se benefició. Los efectos de las reformas Hartz lograron un alto crecimiento y disminución del desempleo, pero otros sostienen que provocaron una disminución masiva del nivel de vida, y que sus efectos son limitados y temporales. 

El PIB de Alemania se contrajo en el segundo y tercer trimestres de 2008, poniendo al país en una recesión técnica junto con la recesión europea y mundial. La producción industrial alemana cayó a 3,6% en septiembre. En enero de 2009, el gobierno alemán bajo Angela Merkel aprobó un plan de estímulo económico de 50 mil millones € para proteger a varios sectores de una recesión y un posterior aumento de la tasas de desempleo. Alemania salió de la recesión en el segundo y tercer trimestre de 2009, debido a las exportaciones (principalmente de fuera de la Zona Euro ) y a una demanda de consumo relativamente estable.

Alemania es un miembro fundador de la UE, el G-8 y el G-20, y fue el mayor exportador del mundo de 2003 a 2008. En 2011 se mantuvo como el tercer exportador y el tercer mayor importador. La mayor parte de las exportaciones del país son en ingeniería, especialmente maquinaria, automóviles, bienes químicos y metales. Alemania es un importante productor de turbinas eólicas y tecnología de energía solar. Numerosas ferias anuales y congresos se celebran en ciudades en toda Alemania. El 2011 fue un año récord para la economía alemana. Las empresas alemanas exportaron bienes por valor de más de 1 billón de €, la cifra más alta en la historia y el número de ocupados ha aumentado a 41,6 millones, la cifra más alta jamás registrada. 

Durante los años posteriores, la economía de Alemania siguió siendo más fuerte en relación con los países vecinos de la zona.

A partir de enero de 2015, la tasa de desempleo fue de 4,8 por ciento. 
A partir de diciembre de 2014, la tasa interanual del IPC fue del 0,6 por ciento.

La siguiente tabla muestra el crecimiento sin desestacionalizar del PIB durante el periodo 1992-2014

De las 500 mayores empresas cotizadas del mercado de valores del mundo medida por los ingresos en 2010, la lista Fortune Global 500, 37 tienen su sede en Alemania. 30 empresas con sede en Alemania están incluidas en el DAX, el índice bursátil alemán. Algunas de las marcas alemanas más conocidas son Mercedes-Benz, BMW, SAP, Siemens, Volkswagen, Adidas, Audi, Allianz, Porsche, Bayer, BASF, Bosch, y Nivea. 

Alemania es reconocida por sus especializadas pequeñas y medianas empresas. Alrededor de 1.000 de estas empresas son líderes del mercado mundial en su segmento y se etiquetan como campeones ocultos. 

De 1991 a 2010 se han producido 40 301 fusiones y adquisiciones, con una participación de empresas alemanas con un valor total de 2422 billones de Euros. Las mayores transacciones desde 1991 son: la adquisición de Mannesmann por parte de Vodafone con 204,8 billones de euros en 1999 y la fusión de Daimler-Benz con Chrysler para formar DaimlerChrysler en 1998 por valor de 36,3 billones de euros.
La lista incluye a las mayores empresas alemanas por ingresos en 2011:

Alemania, como federación, es un país policéntrico y no tiene un solo centro económico. La bolsa de valores se encuentra en Frankfurt am Main, la mayor compañía de medios de comunicación (Bertelsmann SE & Co. KGaA) tiene su sede en Gütersloh y los mayores fabricantes de automóviles están en Wolfsburg, Stuttgart y Múnich.

Alemania es un defensor de la integración económica y política europea más estrecha. Sus políticas comerciales son cada vez más determinadas por acuerdos entre los miembros de la Unión Europea (UE). Alemania introdujo la moneda común europea, el euro, el 1 de enero de 1999. Su política monetaria es fijada por el Banco Central Europeo en Frankfurt.

Los estados del sur ("Bundesländer"), especialmente Baviera, Baden-Württemberg y Hesse, son económicamente más fuerte que los estados del norte. Una de las regiones económicas tradicionalmente más fuertes (y al mismo tiempo más antiguas) es la región del Ruhr, en el oeste, entre Bonn y Dortmund. 27 de las 100 empresas más grandes del país se encuentran allí. En los últimos años, sin embargo, la zona, cuya economía se basa en los recursos naturales y la industria pesada, ha visto un aumento sustancial del desempleo (2010: 8,7%).

La economía de Baviera y Baden-Württemberg, los estados con el menor número de personas desempleadas (2010: 4,5%, 4,9%), por el contrario, se basa en productos de alto valor. Los sectores más importantes son los automóviles, electrónica, aeroespacial y la biomedicina, entre otros. Baden-Württemberg es un centro industrial, especialmente para el automóvil y la construcción de maquinaria de la industria y el hogar de marcas como Mercedes-Benz (Daimler), Porsche y Bosch.

Con la reunificación el 3 de octubre de 1990, Alemania comenzó la importante tarea de reconciliar los sistemas económicos de las dos ex-repúblicas. La Planificación económica intervencionista aseguró el desarrollo gradual en el este de Alemania hasta el nivel de la antigua Alemania Occidental, pero el nivel de vida y los ingresos anuales sigue siendo significativamente mayor en los estados alemanes occidentales. La modernización y la integración de la economía alemana del este sigue siendo un proceso a largo plazo programado hasta el año 2019, con transferencias anuales de oeste a este por valor de aproximadamente 80 mil millones de dólares. La tasa general de desempleo ha caído constantemente desde 2005 y alcanzó un mínimo de 20 años en 2012. En julio del 2014 comenzó legislar para introducir un salario mínimo por mandato federal que entraría en vigor el 1 de enero de 2015. 

Alemania es el país más rico de Europa, y el segundo más rico del mundo, después de Estados Unidos, en términos de la cantidad de hogares altos de riqueza por valor de más de 100 millones de dólares. La siguiente lista de los 10 de los alemanes multimillonarios se basa en una evaluación anual de la riqueza y los activos compilado y publicado por Forbes el 4 de marzo de 2014.


Wolfsburg es la ciudad en Alemania con el ingreso per cápita más alto del país con 128,000 $. La siguiente lista de las 10 de las ciudades alemanas con el más alto ingreso per cápita se basa en un estudio realizado por el Instituto de Investigación Económica de Colonia el 31 de julio de 2013


El suelo alemán es relativamente pobre en materias primas. Solo lignito (carbón marrón) y potasa (Kalisalz) están disponibles en cantidades significativas. Sin embargo, la antigua empresa minera Wismut produjo un total de 230.400 toneladas de uranio entre 1947 y 1990 e hizo la Alemania Oriental el cuarto mayor productor de mineral de uranio en todo el mundo (el más grande en la esfera de control de la URSS) en el momento. Petróleo, gas natural y otros recursos están, en su mayor parte, importados de otros países.

La sal potasa se extrae en el centro del país (Baja Sajonia, Sajonia-Anhalt y Turingia). El productor más importante es K + S AG (anteriormente Kali und Salz AG).

Los depósitos de carbón bituminoso de Alemania fueron creados hace más de 300 millones de años a partir de los pantanos que se extendía desde el actual sur de Inglaterra, sobre la cuenca del Ruhr a Polonia. Los depósitos de lignito se desarrollan de manera similar, pero en un período posterior, hace unos 66 millones de años. Debido a que la madera no está todavía completamente transformada en carbón, el lignito contiene menos energía que el carbón bituminoso.

El lignito se extrae en las partes occidentales y orientales extremas del país, principalmente en Renania del Norte-Westfalia, Sajonia y Brandenburgo. Cantidades considerables se queman en las plantas de carbón cerca de las zonas mineras, para producir electricidad. El transporte de lignito en distancias lejanas no es económicamente viable, por lo tanto, las plantas se encuentran prácticamente al lado de los sitios de extracción. El carbón bituminoso se extrae en Renania del Norte-Westfalia y el Sarre. La mayoría de las centrales eléctricas que queman carbón bituminoso operan en material importado, por lo tanto, las plantas se encuentran no solo cerca de los yacimientos mineros, sino en todo el país.

Alemania tiene una economía social de mercado que se caracteriza por una fuerza laboral altamente calificada, una infraestructura desarrollada, un gran capital social, un bajo nivel de corrupción, y un alto nivel de innovación. Tiene la economía nacional más grande de Europa, la cuarta más grande por el PIB nominal en el mundo, y está clasificado quinto por PIB (PPA) en 2009.
El sector servicios aporta alrededor del 70% del total del PIB, la industria el 29,1%, y la agricultura 0,9%.

En 2010 la agricultura, la silvicultura y la minería representaron solo el 0,9% del producto interno bruto de Alemania (PIB) y empleaba solo el 2,4% de la población, por debajo de 4% de 1991. La agricultura es muy productiva, y Alemania es capaz de cubrir el 90% de sus necesidades nutricionales con la producción nacional. Alemania es el tercer mayor productor agrícola en la Unión Europea después de Francia e Italia. Los principales productos agrícolas de Alemania son patatas, trigo, cebada, remolacha de azúcar, frutas y coles.

A pesar del alto nivel de industrialización del país, casi un tercio de su territorio está cubierto por bosques. La industria forestal proporciona alrededor de dos tercios del consumo interno de la madera y sus productos, por lo que Alemania es un importador neto de estos artículos.

La industria y construcción representaron el 29% del producto interno bruto en 2008, y emplean el 29,7% de la fuerza laboral. Alemania destaca en la producción de automóviles, maquinaria, equipos eléctricos y productos químicos. Con la fabricación de 5,2 millones de vehículos en 2009, Alemania fue el cuarto mayor productor del mundo y el mayor exportador de automóviles. Las empresas automotrices alemanes gozan de una posición muy fuerte en el llamado segmento premium, con una cuota de mercado mundial combinado de aproximadamente 90%.

Las pequeñas empresas manufactureras medianas Mittelstand que se especializan en productos tecnológicamente avanzados y con frecuencia son de propiedad familiar y forman parte importante de la economía alemana. Se estima que alrededor de 1.500 empresas alemanas ocupan una posición alta en su respectivo segmento de mercado en todo el mundo.

En 2008 los servicios constituyeron el 69% del producto interno bruto (PIB), y el sector emplea al 67,5% de la fuerza laboral. Los subcomponentes son servicios financieros, el alquiler y actividades empresariales (30,5%); comercio, hoteles y restaurantes, y el transporte (18%); y otras actividades de servicios (21,7%).

Los mayores ferias anuales y congresos internacionales se llevan a cabo en varias ciudades alemanas, como Hannover, Frankfurt y Berlín.

Alemania es el quinto país más visitado de Europa, con un total de 38 millones de pernoctaciones durante el año 2017

Alemania es el quinto mayor consumidor mundial de energía, y dos tercios de su energía primaria se importó en el año 2002. En el mismo año, Alemania fue el mayor consumidor de electricidad de Europa, por un total de 512,9 teravatios-hora. La política del Gobierno promueve la conservación de la energía y el desarrollo de energías renovables, como la energía solar, eólica, biomasa, hidroeléctrica y geotérmica. Como resultado de las medidas de ahorro energético, la eficiencia energética ha mejorado desde principios de la década de 1970. El Gobierno se ha fijado el objetivo de satisfacer las demandas de energía media del país a partir de fuentes renovables para el año 2050.

En 2000, el canciller Gerhard Schröder y la industria de la energía nuclear acordaron eliminar gradualmente todas las centrales nucleares para el año 2021. La coalición conservadora bajo la canciller Merkel revirtieron esta decisión en enero de 2010 para mantener las plantas abiertas. El desastre nuclear de la planta nuclear japonesa de Fukushima en marzo de 2011 sin embargo, cambió el clima político fundamental: las centrales nucleares más antiguas han sido cerradas. Y una fase general a cabo hasta el año 2020 o 2022 es ahora probable. La energía renovable todavía sigue jugando un papel más modesto en el consumo de energía, aunque las industrias solares y eólicas alemanas desempeñan un papel de liderazgo en todo el mundo.

En 2009, el consumo total de energía de Alemania (no solo la electricidad) provino de las siguientes fuentes: Petróleo 34,6%, el gas natural 21,7%, lignito 11,4%, el carbón bituminoso 11,1%, la energía nuclear 11,0%, y eólica 1,5%, Otros 9,0%.

Hay 3 principales puntos de entrada de los oleoductos: en el noreste (el oleoducto Druzhba, procedentes de Gdańsk ), oeste (procedente de Róterdam ) y sureste (procedentes de Nelahozeves). Los oleoductos de Alemania no constituyen una red adecuada, ya veces solo se conectan dos lugares diferentes.

La red de gas natural, por otro lado, es densa y bien comunicada. Los Gasoductos proviene principalmente de Rusia, los Países Bajos y el Reino Unido. Aunque las importaciones de gas de Rusia han sido históricamente confiable, incluso durante la guerra fría, los conflictos recientes de los precios entre Gazprom y las antiguas repúblicas soviéticas, como Ucrania, han afectado también a Alemania. Como resultado, la gran importancia política se coloca en la construcción del gasoducto Nord Stream, que va desde Vyborg en Rusia a lo largo del mar Báltico a Greifswald en Alemania.

Con su posición central en Europa, Alemania es un importante centro de transporte. Esto se refleja en sus densas y modernas redes de transporte. La extensa autopista (Autobahn) que ocupa la tercera más grande a nivel mundial por su longitud total y cuenta con una falta de límites de velocidad manta en la mayoría de las rutas.

Alemania ha establecido una red policéntrica de trenes de alta velocidad. El InterCityExpress o ICE es la categoría de servicio más avanzado de la Deutsche Bahn y sirve las principales ciudades alemanas, así como destinos en países vecinos. La velocidad máxima del tren varía entre 200 KM/h 320 kmh. Las conexiones se ofrecen en cada 30 minutos, cada hora, o dos-hora.

Los mayores aeropuertos alemanes son el aeropuerto internacional de Frankfurt y el aeropuerto internacional de Múnich, ambos son centros mundiales de Lufthansa. Otros aeropuertos importantes son Berlín Tegel, Berlín-Schönefeld, Düsseldorf, Hamburgo, Hannover, Colonia-Bonn, Leipzig/Halle y en el futuro Aeropuerto Internacional de Berlín Brandeburgo.

Los logros de Alemania en ciencias han sido importantes, y la investigación y desarrollo forman parte integrante de la economía. 

Alemania es también uno de los países líderes en el desarrollo y uso de tecnologías verdes. Las empresas especializadas en tecnología verde tienen una facturación estimada de 200 millones €. El socio alemán para la ingeniería, la ciencia y la investigación es eminentemente respetable.

Los mercados líderes de la industria de la tecnología verde de Alemania son la generación de energía, la movilidad sostenible, la eficiencia de los materiales, eficiencia energética, gestión de residuos y el reciclaje, sostenible la gestión del agua.

Con respecto a las patentes triádicas Alemania ocupa el tercer lugar después de los EE. UU. y Japón. Con más de 26.500 registros de patentes presentadas a la Oficina Europea de Patentes, Alemania es la nación líder en Europa. Siemens, Bosch y BASF, con casi 5.000 registros de patentes entre ellos en 2008, se encuentran entre los Top 5 de los más de 35.000 empresas que registren patentes. Junto con los EE. UU. y Japón, con respecto a las patentes de nano, bio y las nuevas tecnologías Alemania es uno de los países más activos del mundo. Con alrededor de un tercio de las patentes triádicas Alemania está a la cabeza mundial en el campo de la reducción de emisiones de vehículos

Como motor de la Unión Europea, Alemania dispone de la economía más potente de la eurozona, y sus indicadores macroeconómicos son una referencia indiscutible a nivel internacional, mostrando desde hace décadas unos claros índices de modernidad y fortaleza. Alemania es el cuarto país del mundo por PIB (recientemente superado por China) y el quinto país según el Índice de Competitividad Global calculado por el Foro Económico Mundial. Además, Alemania ocupa el puesto n.º 12 a nivel mundial en el ranking de los países con mayor renta per cápita. No obstante, de Alemania cabe destacar otros parámetros como la gran cantidad de superficie forestal conservada (a pesar de su elevada densidad de población) y que, según datos de Eurostat, es el país con más camas en hospitales. En la siguiente tabla se puede comprobar el contexto socioeconómico de Alemania a partir de datos del Banco Mundial, Eurostat y el Foro Económico Mundial:

Los préstamos concedidos a Grecia permiten a Alemania obtener más de mil millones de beneficios entre 2015 y 2017, lo que a veces se denuncia como una falta de solidaridad de Berlín hacia sus socios de la zona euro.

Se presentan a continuación las mercancías de mayor peso en las importaciones de Alemania para el período 2010-hasta abril de 2015. Las cifras están expresadas en dólares estadounidenses valor FOB.

Se presentan a continuación los principales socios comerciales de Alemania para el periodo 2010-hasta abril de 2015.La mayoría de sus importadores están en Europa salvo Estados Unidos y China. Las cifras expresadas son en dólares estadounidenses valor FOB.




</doc>
<doc id="15420" url="https://es.wikipedia.org/wiki?curid=15420" title="Economía de Italia">
Economía de Italia


</doc>
