<doc id="2527" url="https://es.wikipedia.org/wiki?curid=2527" title="Retórica">
Retórica

La retórica es la disciplina transversal a distintos campos de conocimiento (ciencia de la literatura, ciencia política, publicidad, periodismo, ciencias de la educación, ciencias sociales, derecho, estudios bíblicos, etc.), que se ocupa de estudiar y de sistematizar procedimientos y técnicas de utilización del lenguaje, puestos al servicio de una finalidad persuasiva o estética, añadida a su finalidad comunicativa.

La retórica tiene su origen en la Grecia clásica, donde se entendía, como se sugiere en la voz latina "ars bene dicendi", como la técnica de expresarse de manera adecuada para lograr la persuasión del destinatario. Etimológicamente, retórica es un helenismo que proviene del griego ρητορική [τέχνη], «rhetorikè (téchne)».

La retórica se configura como un "sistema de procesos y recursos" que actúan en distintos niveles en la construcción de un discurso. Tales elementos están estrechamente relacionados entre sí y todos ellos repercuten en los distintos ámbitos discursivos.

En principio, la retórica se ocupó de la lengua hablada, pero su saber trascendió al discurso escrito e influyó poderosamente en la literatura cuando la palabra escrita ganó prestigio en el régimen imperial en Roma, si bien el discurso escrito suele considerarse como una transcripción limitada o imitación estrecha del discurso oral, en la actualidad, la retórica ha vivido un gran resurgimiento y sus enseñanzas se utilizan en publicidad, la academia, la política, así como en la defensa de puntos de vista durante los juicios civiles. Por otro lado, gracias a las nuevas tecnologías audiovisuales podemos hablar de una retórica de la imagen, ya que mediante una imagen o vídeo podemos hablar sobre algo utilizando figuras retóricas (metáfora, metonimia, prosopopeya, personificación, etc.).

La retórica ocupó un lugar importante en el sistema educativo antiguo y medieval, y hasta el romanticismo su significación fue crucial dentro de las disciplinas humanísticas.

Son tres procesos complementarios los que conformaban el aprendizaje de la retórica: el "estudio de los preceptos", la "imitación de modelos" y la "práctica personal".

La elaboración del discurso verbal y su exposición ante un auditorio son aspectos que exigen la atención a cinco dimensiones que se complementan. El discurso está conformado por la "inventio", la "dispositio" y la "elocutio";

La finalidad de esta fase es establecer los contenidos del discurso. El término "inventio" procede del latín "invenire" que a su vez procede del griego εὒρεσις que significa «hallazgo», pues de lo que se trata es que el orador seleccione, halle, en un repertorio prefijado de temas aquellos que son los más adecuados a su exposición. Se trata, mentalmente hablando, de "invenire" («hallar») en la memoria, llena de "topoi" o "loci" («tópicos» o «lugares» comunes) las ideas propias o heredadas de la sociedad en general, susceptibles de ser utilizadas en el discurso.

La tipología del "tópico retórico" incluye los siguientes elementos: persona, cosa, lugar, instrumento, causa, modo, tiempo, comparación y argumentación, a los que habrá que añadirse el "tópico literario", en el caso de obras literarias.

Este término latino es una traducción del concepto de la retórica griega conocido como τἀξις que quiere decir «disposición». La finalidad de esta parte de la preparación discursiva es la "organización" de los elementos de la "inventio" en un todo estructurado. Son relevantes a este respecto el número de "partes del discurso" y su "orden" de aparición.


La estructuración tripartita, la más frecuente, consta de un "exordium" o parte inicial que tiene por objeto captar la atención (el interés o favor) del oyente ("captatio benevolentiae") e indicar a este la estructuración del discurso; una parte media con "narratio" (exposición del asunto y tesis del orador al respecto) y "argumentatio" (con las razones que sustentan dicha tesis); y, finalmente, una "peroratio" o recapitulación de lo dicho con apelaciones al auditorio.

El exordio busca hacer al auditorio benévolo, atento y dócil. Su función es señalizar que el discurso comienza, atraer la atención del receptor, disipar animosidades, granjear simpatías, fijar el interés del receptor y establecer el tema, tesis u objetivo.

La proposición es una enunciación breve y clara del tema que se va a tratar.

La división es la enumeración de las partes de que va a tratar el discurso.

La narración, desarrollo o exposición es la parte más extensa del discurso y cuenta los hechos necesarios para demostrar la conclusión que se persigue. Si el tema presenta subdivisiones, es preciso adoptar un orden conveniente ("partitio" o "divisio"). En la "partitio" tenemos que despojar al asunto de los elementos que no conviene mencionar y desarrollar y amplificar aquellos que sí conviene.

La argumentación es la parte donde se aducen las pruebas que confirman la propia posición revelada en la tesis de la exposición ("confirmatio" o "probatio") y se refutan las de la tesis que sostiene la parte contraria ("refutatio" o "reprehensio"), dos partes que Quintiliano considera independientes, de forma que para él el discurso forense tendría cinco. La confirmación del empleo de argumentos lógicos y de las figuras estilísticas del énfasis. También es un lugar apropiado para el postulado o enunciado sin prueba, siempre que no debilite nuestra credibilidad, para lo cual hay que recurrir al postulado no veraz pero plausible (hipótesis), a fin de debilitar al adversario desorientando su credibilidad; lo mejor en ese caso es sugerirlo y no decirlo. Se recurre a una «lógica retórica» o dialéctica que no tiene que ver con la lógica científica, pues su cometido no es hallar la verdad sino convencer. Se funda más en lo verosímil que en lo verdadero, de ahí su vinculación con la demagogia. Para los discursos monográficos enfocados a la persuasión, convienen las estructuras gradativas ascendentes. En el caso del discurso periodístico, la tendencia del lector a abandonar al principio recomienda el uso de la estructura opuesta: colocar lo más importante al principio. La retórica clásica recomienda para los discursos argumentativos monográficos el orden nestoriano, el 2,1,3: esto es, en primer lugar los argumentos medianamente fuertes, en segundo lugar los más flacos y débiles y en último lugar los más fuertes.

La peroración es la parte destinada a inclinar la voluntad del oyente suscitando sus afectos, recurriendo a móviles éticos o pragmáticos y provocando su compasión ("conquestio" o "conmiseratio") y su indignación ("indignatio") para atraer la piedad del público y lograr su participación emotiva, mediante recursos estilísticos patéticos; incluye lugares de casos de fortuna: enfermedad, mala suerte, desgracias, etc. Resume y sintetiza lo que fue desarrollado para facilitar el recuerdo de los puntos fuertes y lanzar la apelación a los afectos; es un buen lugar para lanzar un elemento nuevo, inesperado e interesante, el argumento-puñetazo que refuerce todos los demás creando en el que escucha una impresión final positiva y favorable.

Existen tres tipos de argumentos que pueden ser empleados en un discurso: los relativos al ethos, al pathos y al logos.

El orden de las partes puede ser "naturalis" o "artificialis". El "ordo naturalis" es el que respeta la propia naturaleza del discurso sin alteraciones intencionadas o el que sigue la tradición; el "ordo artificialis", por el contrario, altera el orden habitual de las partes (por ejemplo, empezar una historia no por el principio sino en un momento ya avanzado de la misma, esto es, "in medias res").

La "elocutio" afecta al modo de expresar verbalmente de manera adecuada los materiales de la "inventio" ordenados por la "dispositio". En la actualidad, la "elocutio" es lo que se denomina "estilo".

La "elocutio" se manifiesta a través de dos aspectos: las cualidades y los registros.

La "compositio" analiza la estructura sintáctica y fónica de los enunciados, esto es, sus constituyentes y sus distintas posibilidades de distribución en el discurso. Así, se distinguen la "compositio sintáctica" (centrada en la oración y sus partes) y la "compositio fonética" (centrada en la combinación de palabras en la oración por razones fonéticas).

La primera diferencia entre ambos es de tipo estructural y lógico-semántica: en el "periodo" existe una estructura periódica que presenta varias partes con autonomía argumentativa para cada una de ellas; en cambio, en el "estilo suelto" no existe esa estructuración, de forma que las ideas se suceden hasta llegar a la conclusión.

La segunda diferencia es de orden rítmico: en el "periodo" hay que tener en cuenta el "numerus" (el correlato en latín del metro en poesía, que se basaba en las cantidades vocálicas), mientras que en el "estilo suelto" esto es irrelevante.

La memorización del discurso elaborado depende de dos tipos de memoria según los tratadistas clásicos: la "memoria naturalis" (la innata) y la "memoria artificiosa", que implica una serie de procedimientos mnemotécnicos para facilitar el recuerdo.

También llamada "pronuntiatio", se ocupa de la declamación del discurso, prestando atención a la modulación de la voz y de los gestos, que debe estar en consonancia con el contenido de aquel.

Existen tres géneros de discursos de oratoria: el "genus iudiciale" (género judicial o forense), el "genus deliberativum" (género deliberativo o político) y el "genus demonstrativum" (género demostrativo o epidíctico).

Además de estos tres géneros, existen siete especies (εἲδη): la suasoria (προτρεπτικόν), disuasoria (ἀποτρεπτικόν), laudatoria (ἐγκωμιαστικόν), vituperadora (ψητικόν), acusatoria (κατηγορικόν), exculpatoria (ἀπολιγικόν) y la indagatoria (ἐξεταστικόν). Estas especies están presentes en los tres géneros. En el deliberativo, puesto que se busca convencer al auditoriο de una determinada tesis, las más frecuentes son la suasoria y la disuasoria. En el judicial, en el que hay que defenderse de acusaciones o realizarlas, predominan las especies acusatoria y exculpatoria y en el epidíctico, que sirve para reforzar los valores de una comunidad, la laudatoria y la vituperadora.
Aunque predοminen más en determinados discursos, las siete especies están en los tres géneros. En un discurso deliberativo se puede utilizar la especie acusatoria y la vituperadora, por ejemplo, el político que propone una ley puede acusar a su rival de algo o hacerle un vituperio con el fin de desacreditarlo. De la misma manera, en el discurso judicial son frecuentes las especies vituperadora y laudatoria. Un caso muy conocido es el discurso de Cicerón "Pro Archia Poeta" en el que hay un extenso elogio de la poesía.

En la Edad Media se añadieron a los anteriores las llamadas artes: "ars praedicandi" (sobre la técnica de elaborar sermones), "ars dictandi" (o "ars dictaminis", sobre el arte de escribir cartas) y las "ars poetriae" (preceptos gramaticales, métricos y retóricos para escribir poesía).

Podemos conocer la retórica ateniense a través de los discursos que dejaron grandes oradores como Demóstenes, Lisias o Isócrates. Heródoto y Tucídides en sus obras sobre historia, además de sucesos, también escribieron discursos pronunciados por personajes históricos como Alcibíades, Jerjes o Pericles.

Desde el punto de vista teórico las fuentes más importantes son la "Retórica a Alejandro" escrita por Anaxímenes de Lámpsaco y la "Retórica" de Aristóteles. La primera obra consiste en una serie de preceptos sobre cómo hablar elocuentemente. La segunda obra tiene un planteamiento más filosófico. Frente a la "Retórica a Alejandro" que es de carácter práctico, la "Retórica" de Aristóteles es de carácter teórico.

En la Atenas Clásica no existe una distinción clara entre la retórica y la filosofía. Por este motivo, hay que tener muy en cuenta esta última disciplina. La tragedia y la comedia, muy ligadas a lo político, son también importantes para conocer la retórica en la Atenas Clásica.

La retórica nació en la antigua Grecia alrededor del año 485 a. C. en la ciudad siciliana de Siracusa, cuando Gelón y su sucesor Hierón I, expropiaron las tierras a sus ciudadanos para adjudicárselas a miembros de su ejército personal. Más tarde, con la llegada de la democracia y el derrocamiento de los tiranos, los perjudicados pretendieron recuperar sus propiedades, y esta situación provocó una serie de pleitos en los que se manifestó la importancia de la elocuencia o arte de hablar bien y persuasivamente para conseguir las recuperaciones pretendidas. Así pues, su origen no está vinculado a lo literario sino a lo judicial, y estrechamente relacionado con lo político: la palabra pública y libre se relaciona con la retórica.
Ante la eficacia de la argumentación oral adecuada, Córax de Siracusa, en el siglo V a. C. (hacia el año 450) elaboró un sistema de comunicación para hablar ante la asamblea política o ante los tribunales con fines claramente persuasivos, que se puede considerar el primer tratado de retórica. Un discípulo suyo, Tisias, lo divulgó por Grecia. Así nacieron dos de los tres géneros clásicos de la retórica ya en su génesis: el judicial y el deliberativo. Y pronto se unió un tipo de discurso de elogio funerario en el que se trataba de alabar las virtudes del difunto, lo que se puede considerar el inicio del tercer género retórico, el demostrativo o epidíctico que, más adelante, se referiría a cualquier persona no necesariamente fallecida, o a diferentes aspectos de la vida o de la sociedad, desde un punto de vista positivo o negativo.

Las figuras de estos dos primeros maestros de retórica son bastante oscuras. Ningún escrito de ellos ha llegado hasta nuestros días, y se conoce su existencia por menciones de rétores posteriores. Hay una teoría que defiende que Tisias y Córax eran una sola persona y no dos. Según esta teoría, el primer rétor de la antigüedad se llamaría Tisias, el Corax o dicho de otra forma, Tisias el cuervo (κόραξ,κόρακος significaba en griego antiguo cuervo). Esa elocuencia vino a transformarse rápidamente en objeto de enseñanza, y se transmitió al Ática por comerciantes que comunicaban Siracusa y Atenas.
La retórica demostró pronto su utilidad como instrumento político en el régimen democrático, siglo V a. C., divulgada por profesores conocidos como sofistas, entre los cuales los más conocidos fueron Protágoras de Abdera y Gorgias. Para estos maestros de retórica que fueron también filósofos, no existe una única verdad y con el lenguaje sólo se pueden expresar cosas verosímiles (τὸ εἰκός). Valoraban mucho el poder que tenía la palabra (λὀγος) que según Gorgias es un gran soberano que con un cuerpo muy pequeño e imperceptible realiza obras de naturaleza divina.

Esta filosofía fue muy criticada por Platón. Tanto para Platón como para su maestro Sócrates, la esencia de la filosofía reposaba en la dialéctica: la razón y la discusión conducen poco a poco al descubrimiento de importantes verdades. Platón pensaba que los sofistas no se interesaban por la verdad, sino solamente por la manera de convencer, así que rechazó la palabra escrita y buscó la interlocución personal, y el método fundamental del discurso pedagógico que adoptó fue el del diálogo entre maestro y alumno.
Pero el gran maestro de la retórica griega fue Isócrates. Pensaba que la retórica era un plan de formación integral de la persona que servía para crear ciudadanos modélicos; con su sistema de enseñanza, precursor del humanismo, pretendía la regeneración ética y política de la sociedad ateniense.

Aristóteles, por otra parte, sistematizó la mayor parte de estos conocimientos sobre el arte de hablar y argumentar en una obra que consagró al efecto, su "Retórica". La gran aportación de la Retórica de Aristóteles es su enfoque filosófico. Los manuales anteriores, de los cuales el único ejemplar que se conserva es la Retórica a Alejandro, consistían en consejos prácticos sobre cómo persuadir. La Retórica de Aristóteles en cambio, realiza reflexiones teóricas sobre el lenguaje persuasivo.

Como Solón estableció que cada cual debía defenderse en persona ante un tribunal, llegaron a crearse los llamados logógrafos, que se dedicaban a confeccionar discursos para quienes no sabían hacerlos a cambio de estipendio: autores como Antifonte, Lisias, que destacó por su naturalidad y aticismo, Iseo, famoso por su habilidad en la argumentación, y el más famoso de todos ellos, Isócrates, fueron logógrafos. Estos poseían también una preocupación estilística y procuraban que el estilo del discurso se ajustara a la personalidad y condición social de quien debía memorizarlo y pronunciarlo. También existía la figura del "sunégoros" (συνήγορος) cuya función era similar a la de un abogado. Demóstenes actuó como συνήγορος cuando pronunció su famoso discurso Sobre la Corona.

En los siglos V y IV a.C., el sistema político ateniense era la democracia radical que consistía en que todo ciudadano ateniense mayor de edad y varón podía exponer en la Asamblea (ἐκλεσία) sus puntos de vista sobre los asuntos de la polis. Para poder hablar en la Asamblea era necesario ser un orador excelente. Por este motivo se desarrolló en Atenas la retórica deliberativa.

El tercer género retórico que se desarrolló en Atenas fue el epidíctico que abarca los discursos que tienen lugar en ocasiones especiales, por ejemplo, en un funeral y cuyo principal objetivo es reforzar los valores de una comunidad. El discurso Epidíctico más importante de la Atenas Clásica es el Discurso Fúnebre de Pericles.

Ya en Roma la retórica se perfeccionó sumamente por medio de las investigaciones y esfuerzos de hombres de letras como Cicerón, quien dedicó al tema una parte sustancial de su obra e hizo de la retórica el eje de sus preocupaciones. De este autor son fundamentales los textos De Oratore y La invención retórica. De los manuales de retórica republicana se conserva la "Retorica ad Herennium", de autor anónimo. En época imperial, en el marco de la segunda sofística, se destaca Marco Fabio Quintiliano, cuyos doce libros de "Instituciones oratorias" suponen la culminación de los estudios sobre la materia en el mundo romano. Hay que notar que en la época republicana florece el género deliberativo, mientras que en la época imperial es el género epidíctico el que se desarrolla con mucha fuerza. Notable es el trabajo de Menandro el Rétor y sus Dos tratados de Retórica epidíctica. Dado que la retórica era parte fundamental de la educación de todo romano ilustrado, es menester tenerla en cuenta a la hora de leer toda la producción intelectual de la época.

Durante la Edad Media, de los tres géneros oratorios, el judicial, el deliberativo y el epidíctico, entraron en decadencia el género deliberativo y el epidíctito, es decir, la oratoria política y la artística, ya que la militarización del imperio hacía inútil los conocimientos de la oratoria; sin embargo sus conocimientos fueron transvasados a la literatura en general, que se retorizó notablemente perdiendo bastante de su inspiración originaria y su frescura. Así lo vino a concluir el gran estudioso de la literatura medieval Ernst Robert Curtius en su "Literatura europea y Edad Media latina", traducido al castellano en 1955.

La retórica contemporánea ha prescindido del discurso oral y, por tanto, de entre las cinco fases de elaboración del discurso (invención, disposición, elocución, memoria y acción) de las dos últimas de índole práctica, la memoria y la acción. Se considera actualmente que es útil para actores, abogados, psicólogos, políticos, publicitarios, escritores, vendedores y, en general, quienes quieren persuadir o convencer de algo.

Sin embargo, la retórica ha vivido un gran renacimiento en la segunda mitad del siglo XX como disciplina científica con el surgir de varias corrientes de pensamiento que han redescubierto su valor para distintas disciplinas; comenzó Heinrich Lausberg realizando una gran labor de clasificación de la disciplina con sus "Elemente der literarischen Rhetorik", traducido como "Elementos de retórica literaria" en 1975; y su impagable "Manual de retórica literaria", publicado en español entre 1966 y 1970 en tres volúmenes; Chaïm Perelman y Lucie Ollbrechts-Tyteca publicaron en 1958 un fundamental "Tratado de la argumentación", traducido al castellano en 1994; la disciplina creada a raíz de este libro se denomina desde entonces Retórica de la argumentación o, a veces, Neorretórica; por otra parte, y al lado de esta llamada retórica de la argumentación, ha surgido una nueva neorretórica, la retórica contemporánea de las figuras, ilustrada por Roman Jakobson, el Grupo µ (o Grupo de Lieja), Lakoff y Johnson, etc. que permitió a la lingüística y a la semiótica desarrollarse en una orientación social y cognitivista. El estudio de la retórica como un fenómeno cultural ha sido profundamente renovado por el historiador francés de la cultura, Marc Fumaroli (Collège de France).

La invención, sola o conjuntamente con la disposición, es a menudo llamada argumentación; la elocución se subdivide, como habían determinado ya los teóricos de la antigüedad, en un gran número de puntos de vista sobre el discurso a hacer (arte de la retórica) o sobre el discurso ya hecho (retórica como ciencia): sobre el vocabulario (registros de la lengua), sobre los ritmos y las sonoridades, sobre la forma y la estructura de las frases (sintaxis, parataxis, hipotaxis, tipo de progresión remática, periodo, estilo comático, etc.).

En la política contemporánea se le considera como un método estratégico de comunicación compuesto por falacias y perorativas. Usada en el discurso como apelación al votante, usando recursos lingüísticos y tergiversando los hechos.











</doc>
<doc id="2529" url="https://es.wikipedia.org/wiki?curid=2529" title="Rayuela">
Rayuela

El término rayuela puede referirse, en esta enciclopedia:





</doc>
<doc id="2532" url="https://es.wikipedia.org/wiki?curid=2532" title="Richard Stallman">
Richard Stallman

Richard Matthew Stallman (Manhattan, Nueva York, 16 de marzo de 1953), con frecuencia abreviado como «rms», es un programador estadounidense y fundador del movimiento del software libre, del sistema operativo GNU y de la Free Software Foundation (Fundación para el Software Libre).

Entre sus logros destacados como programador se incluye la realización del editor de texto GNU Emacs, el compilador GCC, el depurador GDB, y el lenguaje de construcción GNU Make; todos bajo la rúbrica del Proyecto GNU. Sin embargo, es principalmente conocido por el establecimiento de un marco de referencia moral, político y legal para el software libre: un modelo de desarrollo y distribución alternativo al software privativo. Es también inventor del concepto de copyleft (aunque no del término): un método legal para licenciar obras contempladas por el derecho de autor, de tal forma que su uso y modificación (así como de sus derivados) permanezcan siempre permitidos.

Su innovador trabajo y activismo en torno al software libre y los derechos digitales le han merecido numerosas distinciones; incluyendo más de una docena de doctorados y profesorados honoríficos, la prestigiosa beca de la Fundación MacArthur, el premio "Pioneer" de la Electronic Frontier Foundation y varios premios de la ACM. Es miembro del salón de la fama de Internet.

Richard Matthew Stallman nació en la ciudad de Nueva York en el año 1953, en una familia judía, hijo de Alice Lippman y Daniel Stallman. Su primera experiencia con computadoras fue en el Centro Científico de IBM en Nueva York cuando cursaba la preparatoria. Fue contratado durante un verano para escribir un programa de análisis numérico en Fortran. Completó el trabajo después de un par de semanas, y dedicó el resto del verano escribiendo un editor de textos en el lenguaje de programación APL. Stallman invirtió el verano de su graduación de la preparatoria en escribir otro programa, un preprocesador para el lenguaje de programación PL/1 en el IBM S/360.

Durante este tiempo, Stallman fue también asistente voluntario de laboratorio en el departamento de biología de la Universidad Rockefeller. Aunque ya estaba ingresando a la carrera de física o matemáticas, su maestro tutor en el Rockefeller pensó que él podría ser biólogo en un futuro.

En 1971, siendo estudiante de primer año de física en la Universidad Harvard, Stallman se convirtió en un "hacker" del Laboratorio de Inteligencia Artificial del Instituto Tecnológico de Massachusetts (MIT), donde trabajaba manteniendo el sistema operativo de la casa: el Incompatible Time-sharing System (ITS). Era conocido por su alto rendimiento en Math 55: el curso de matemáticas de pregrado más avanzado de Harvard. Se graduó con honores en 1974 de esta universidad. Cursó un año de doctorado en física en el MIT, abandonando el programa para concentrarse en su programación en el Laboratorio de Inteligencia Artificial.

En 1976 mientras trabajaba como asistente de investigación de Gerald Sussman, publicó junto con Sussman un influyente artículo sobre un sistema de mantenimiento de la verdad (TMS en inglés) llamado "dependency-directed backtracking" (retropropagación dirigida por dependencias), con el propósito de resolver circuitos eléctricos mediante computadora. Fue un trabajo pionero sobre retropropagación inteligente para el problema de satisfacción de restricciones. A la fecha de 2009, el algoritmo introducido por Stallman y Sussman sigue siendo la forma más general y potente de retropropagación inteligente. La técnica de aprendizaje de restricciones, mediante la cual se guardan los resultados parciales de una búsqueda para volver a usarla en el futuro, también fue descrita por primera vez en el mismo artículo.

En los años 1980, la cultura "hacker" que constituía la vida de Stallman empezó a disolverse bajo la presión de la comercialización en la industria del software. En particular, otros hackers del laboratorio de IA fundaron la compañía Symbolics, la cual intentaba activamente reemplazar el software libre del Laboratorio con su propio software privativo.

Entre 1982 y 1983, Stallman por sí solo duplicó los esfuerzos de los programadores de Symbolics para impedir que adquirieran un monopolio sobre los ordenadores del laboratorio. En ese momento, él era el último de su generación de hackers en el laboratorio. Cuando intentó mejorar el firmware de las nuevas impresoras del laboratorio como había hecho anteriormente, el fabricante le pidió que firmara un acuerdo de no divulgación ("non-disclosure agreement"), y que llevara a cabo otras acciones que él consideró traiciones a sus principios éticos. Harto de lo que él llamaba un creciente ""acaparamiento del software"" en la industria, el 27 de septiembre de 1983 Stallman anunció en varios grupos de noticias de Usenet el inicio del proyecto GNU, que perseguía crear un sistema operativo completamente libre para las más recientes microcomputadoras PC.

El 16 de septiembre de 2019 dejó su puesto no remunerado como científico y profesor visitante del MIT y, renunció como presidente de la FSF, el 5 de Agosto del 2020 se anunciaría a Geoffrey Knauth como sucesor a la presidencia.

El nuevo sistema operativo sería portable para evitar que cayera en la obsolescencia, como sucedió con ITS. Stallman renunció a su empleo en el MIT a fin de desligar los derechos de autor sobre su nuevos programas, si bien el laboratorio ofreció albergar el proyecto.

Al anuncio inicial del proyecto GNU siguió en 1985 la publicación del Manifiesto GNU, en el cual Stallman declaraba sus intenciones y motivaciones para crear una alternativa libre al sistema operativo Unix, al que denominó GNU ("GNU No es Unix"), pronunciado de forma parecida a "ñu", en inglés (de ahí los dibujos-logotipos que lo representan). Poco tiempo después fundó la organización sin ánimo de lucro Free Software Foundation para coordinar el esfuerzo. Como Stallman no deseaba dejar su nuevo software a la suerte del dominio público, terminó por inventar el recurso legal del copyleft, que cristalizó en la Licencia Pública General GNU (conocida generalmente como la «GPL») en 1989. La mayor parte del sistema GNU, excepto el núcleo, se completó aproximadamente al mismo tiempo. En 1991, Linus Torvalds liberó el núcleo Linux bajo los términos de la GPL. Se trabajó para hacer a GNU y a Linux mutuamente compatibles, completando un sistema ciento por ciento funcional: el sistema operativo GNU/Linux.

Stallman insiste en la utilización del término «software libre», y no código abierto, porque el objetivo de su proyecto es otorgar libertad y derechos a los usuarios de computadoras. El discurso del código abierto por el contrario pretende evitar hablar de tales programas en términos morales. También busca que se diga "GNU/Linux" y no solamente "Linux" cuando se habla del sistema operativo (ver Controversia por la denominación GNU/Linux). Para Stallman el software libre no quiere decir que sea gratis. Además considera que en la enseñanza no debería utilizarse software privativo.

Las motivaciones políticas y morales de Richard Stallman lo han convertido en una figura controvertida. Muchos programadores influyentes que se encuentran de acuerdo con el concepto de compartir el código difieren con las posturas morales, filosofía personal o el lenguaje que utiliza Stallman para describir sus posiciones. Un resultado de estas disputas condujo al establecimiento del movimiento de código abierto.

Hasta 2019 Stallman tuvo una posición no remunerada como investigador en el MIT. Ha declarado ser "un ateo de ascendencia judía" y a menudo lleva un botón que dice "Enjuicien a Dios" ("Impeach God"). Niega ser un anarquista a pesar de su cautela de algunas leyes y el hecho de que ha "defendido enérgicamente la privacidad de los usuarios y su propia visión de la libertad del software".

Stallman se refiere a los teléfonos móviles como "dispositivos de vigilancia y seguimiento" y "el sueño de Stalin". Se niega a poseer un teléfono celular debido a que su hardware está total o parcialmente bajo el control de las compañías telefónicas, en lugar de los usuarios. También evita el uso de una tarjeta-llave para entrar en su oficina, ya que estos sistemas llevan un seguimiento de cada lugar y hora en que alguien entra en el edificio. A excepción de unos pocos sitios web relacionados con su trabajo en GNU y la FSF, por lo general no navega por la web directamente desde su ordenador personal con el fin de evitar ser conectado con su historial de navegación. En su lugar, usa wget o programas similares que recuperan el contenido de los servidores web y luego envían el contenido a su correo electrónico. Más recientemente, ha declarado haber comenzado a navegar la web directamente a través de Tor.

Su imagen y manías se han vuelto un ícono en la cultura hacker, llegando a aparecer en tiras cómicas.

En la actualidad Stallman se encarga de difundir la ideología del Software Libre en todo el mundo mediante charlas y conferencias. Además de su idioma nativo, habla español y francés de manera fluida y ha dado numerosas conferencias en países de habla hispana. Durante sus charlas aparece con una segunda personalidad que corresponde a "San Ignucio" con la que suele bendecir las computadoras de las personas como parte de una broma.

Stallman ha escrito numerosos ensayos sobre la libertad del software y ha sido un orador político en favor del movimiento del software libre desde principios de los 1990s. Los discursos que ha dado regularmente se titulan "El Proyecto GNU y el movimiento del software libre", "Los peligros de las patentes de software", "Copyright y globalización en la era de las redes informáticas".

La firme defensa de Stallman por el software libre inspiró la creación del "Virtual Richard M. Stallman" (vrms), un software que analiza los paquetes instalados en un sistema Debian GNU/Linux, e informa de aquellos que no son libres. Stallman no está de acuerdo con parte de la definición de software libre de este proyecto.

En 1999 promovió la creación de una enciclopedia libre, la GNUPedia, considerada como un antecedente directo de Wikipedia. El proyecto resultante se retiró finalmente en favor de esta última, que tenía objetivos similares y estaba contando con un éxito mayor.

Stallman es un viajero incansable. Ha visitado al menos 65 países, sobre todo para hablar sobre el software libre y el proyecto GNU. Según Stallman, el movimiento del software libre tiene mucho en común con aquel liderado por Mahatma Gandhi.

En abril de 2006, Stallman llevó un cartel de protesta contra el software propietario -"No compre ATI, enemigo de su libertad"- en un discurso pronunciado por el representante de esa firma, dando lugar a una llamada a la policía. ATI se fusionó luego con AMD Corporation y tomó medidas para que su documentación de hardware esté disponible para uso por la comunidad de software libre.

En agosto de 2006, en reuniones con el gobierno del estado indio de Kerala, convenció a los funcionarios de desprenderse del software propietario en escuelas estatales. Esto dio lugar a la decisión histórica de migrar todas las computadoras en 12.500 escuelas secundarias de Windows a un sistema operativo de software libre.

En Venezuela, Stallman ha pronunciado discursos públicos y promovido la adopción de software libre en la petrolera estatal PDVSA, el gobierno municipal y el ejército de la nación. En reuniones con Hugo Chávez y en discursos públicos, Stallman criticó algunas políticas sobre la radiodifusión televisiva, derechos de libertad de expresión y privacidad. Stallman estuvo en el Consejo Asesor de la cadena de televisión Telesur desde su lanzamiento, pero renunció en febrero de 2011 criticando la propaganda pro-Gadafi durante la primavera árabe.

Luego de reuniones personales, Stallman obtuvo declaraciones en favor del movimiento del software libre del presidente de la India, Dr. APJ Abdul Kalam, la candidata presidencial francesa en 2007 Ségolène Royal, y el entonces presidente de Ecuador Rafael Correa.

El 30 de noviembre de 2012, Stallman dio la conferencia de apertura en el Foro Goiano Software Libre en Brasil, hablando de casos exitosos de migración a software libre en el gobierno, los negocios y las universidades.

Stallman ha participado en protestas contra el uso de patentes de software, DRMs, y software propietario. Linus Torvalds ha criticado a Stallman por lo que considera un pensamiento "de blanco o negro".

Actualmente mantiene una postura crítica contra Facebook por suministrar masivamente información de sus usuarios a agencias gubernamentales como la NSA de Estados Unidos y empresas de todo tipo. 
Stallman ha brindado regularmente una conferencia titulada "Derechos de autor "versus" comunidad", donde revisa el estado de los DRMs y se pronuncia en contra de ciertos productos y empresas que los utilizan. Su visión sobre los DRMs se resume en la campaña de la FSF Defectuoso por Diseño. En sus charlas se manifiesta en favor de un "copyright reducido" y sugiere un límite de 10 años para los derechos de autor. Sugiere que, en lugar de las restricciones al intercambio, se apoye a los autores utilizando un impuesto y se distribuyan los ingresos sobre la base de las raíces cúbicas de su popularidad. Esto aseguraría que "los exitosos no sean estrellas" y reciban, sin embargo, una recompensa mayor comparada con el gravamen por copia privada asociada a los defensores del copyright. Otra opción sería un sistema de micropago anónimo para que la gente apoye de manera directa a los autores.

Stallman se pronuncia por que ninguna forma de intercambio no-comercial de copias sea considerada una violación a los derechos de autor. Ha abogado por la desobediencia civil en un comentario sobre la Ley Sinde.

También ha apoyado al Proyecto Biblioteca Internacional de Partituras Musicales, para volver a estar en línea luego de haber sido retirado el 19 de octubre de 2007, tras una orden de cese y desista de Universal Edition. 

Stallman destaca los peligros que algunos e-libros tienen en comparación con los libros de papel. Un ejemplo es el lector electrónico Kindle de Amazon, que impide la copia de libros electrónicos y permite a la empresa la eliminación remota de contenido. Considera que tales desarrollos presentan un gran paso atrás con respecto a los libros de papel, por ser menos fáciles de usar, copiar, prestar a los demás o vender, además de que los Kindle no se pueden comprar de forma anónima. Su cuento "El derecho a leer" ofrece una imagen de un futuro distópico en el que se impide el derecho a compartir los libros. Se opone a muchos de los términos dentro de los acuerdos de licencia de usuario final que acompañan a tales dispositivos.

Stallman desalienta el uso de varias tecnologías de almacenamiento, como discos de vídeo DVD o Blu-ray, debido a que estos estándares fueron diseñados para cifrar el contenido en desventaja de los clientes. Considera el uso de cifrado de datos por parte de los fabricantes (para obligar al usuario a ver cierto material promocional) como una conspiración.

Reconoció el escándalo de protección de copia rootkit de Sony BMG como un acto criminal. Stallman apoya un boicot a Sony por sus acciones legales contra George Hotz.
En septiembre de 2019 Stallman renunció a su puesto como investigador del Proyecto MAC en el MIT y, a la presidencia de la Free Software Foundation, el 5 de Agosto del 2020 se anunciaría en su reemplazo a Geoffrey Knauth.

Stallman ha recibido numerosos premios y reconocimientos por su trabajo, entre ellos:







Artículos en revistas científicas:

Manuales:

Recopilaciones de ensayos:

Biografía:




</doc>
<doc id="2536" url="https://es.wikipedia.org/wiki?curid=2536" title="Rosa">
Rosa

El género Rosa está compuesto por un conocido grupo de arbustos generalmente espinosos y floridos representantes principales de la familia de las rosáceas. Se denomina rosa a la flor de los miembros de este género y rosal a la planta.

El número de especies ronda las cien, la mayoría originarias de Asia y un reducido número nativas de Europa, Norteamérica y África noroccidental. Tanto especies como cultivares e híbridos se cultivan como ornamentales por la belleza y fragancia de su flor; pero también para la extracción de aceite esencial, utilizado en perfumería y cosmética, usos medicinales (fitoterapia) y gastronómicos.

Existe una enorme variedad de (más de 30 000) a partir de diversas hibridaciones, y cada año aparecen otros nuevos. 

Las especies progenitoras mayormente implicadas en los cultivares son: "Rosa moschata", "Rosa gallica", "Rosa damascena", "Rosa wichuraiana", "Rosa californica" y "Rosa rugosa". Los cultivadores de rosas o del se centraron en el tamaño y el color, para producir flores grandes y atractivas, aunque con poco o ningún aroma. Muchas rosas silvestres y «pasadas de moda», por el contrario, tienen una fragancia dulce y fuerte.

Las rosas están entre las flores más comunes vendidas por los floristas. 

El rosal es una de las plantas más populares de los jardines, incluso existen jardines específicos llamados rosaledas o rosedales, donde se exponen únicamente los miembros del género, cuya variedad es tan extensa que comprende desde rosales miniatura de 10 o 15 cm de altura, hasta grandes arbustos, trepadores que alcanzan varios metros de altura o rastreros utilizados como cubre suelos.

En español —y en otras lenguas romances también—, el término «rosa» proviene directamente y sin cambios del latín "rosa", con el significado que conocemos: «la rosa» o «la flor del rosal»; devenido del vocablo previo "rodia" [ródja] —por cambio similar como en: Clausus por Claudius—. Este último arcaísmo latino es, a su vez, prestado —a través del osco— del griego antiguo "ρόδον" [rhódon] «la rosa», «la flor del rosal» o mejor "rhodéa", «el tallo de la rosa», «el sostén de la flor».

A partir del griego antiguo se alude al posible significado de "rhódon" como «efluvio oloroso», «lo que es fragante», o «lo que desprende olor»; originado como término compuesto: por "ροήdon" o sino también de "wrodion" [bródion] en el antiguo dialecto eólico, raíces correspondientes con el persa antiguo "vereda" o "v'reda" (y sus dialectos: avéstico "warda", sogdiano "ward" y parto "wâr"), como una voz irania traspasada desde el sur de Armenia a Frigia y de ahí a Grecia. Y previamente de un origen tan antiguo como el arameo "wurrdā" y hasta del asirio "wurtinnu".

En cuanto a la base, el núcleo deriva de una raíz indoeuropea "vardh-" [wardh], "vradh-" [wradh], «crecer», «erguir(se)»; donde en sánscrito "wardh-as", significa «germinante», y wardhati, «elevar(se)», «prosperar».

Por otra parte, puede ser un derivado de una raíz grecolatina "vrad"-, «plegarse», «hacerse flexible». Y por ahí también del griego "rodanós", "rádinos", y el eólico "bradinós", «blando» o «flexible». Color claro.

"Rosa" también es un término coincidente con varios nombres germánicos que tienen la raíz "hrod", con el significado de «gloria».

Los rosales son arbustos o trepadoras (a veces colgantes), generalmente espinosos, que alcanzan de dos a cinco metros de altura, en ocasiones, pueden llegar a los 20 m trepando sobre otras plantas.

Tienen tallos semileñosos, casi siempre erectos (a veces rastreros), algunos de textura rugosa y escamosa. Presentan notables formaciones epidérmicas persistentes, bien desarrolladas y de formas variadas, conocidas como espinas o aguijones.

Las hojas pueden ser perennes o caducas, pecioladas e imparipinnadas con cinco a nueve folíolos de borde aserrado y estípulas basales. Es frecuente la presencia de glándulas anexas, odoríferas o no, sobre los márgenes.

Las flores, generalmente aromáticas, se agrupan en inflorescencias racimosas, formando corimbos. Son flores completas, hermafroditas, regulares, con simetría radial (actinomorfas). El perianto está bien desarrollado. El hipanto o receptáculo floral prominente en forma de urna (tálamo cóncavo y profundo). 

El cáliz es dialisépalo, de cinco piezas de color verde. Los sépalos pueden ser simples o, a veces, de forma compleja con lobulaciones laterales estilizadas.
Corola dialipétala, simétrica, formada por cinco pétalos regulares (o múltiplos de 5), a veces escotados, y de variados colores llamativos o sólo blancos. La corola suele ser "doble" o "plena" por transformación de los estambres en pétalos, esto ocurre mayoritariamente en cultivares.

El androceo está compuesto por numerosos estambres dispuestos en espiral (varios verticilos), generalmente en número múltiplo de los pétalos (5x).
El gineceo apocárpico (compuesto por varios pistilos separados). Nectario presente, que atrae insectos para favorecer la polinización predominantemente entomófila. Perigina (ovario medio), numerosos carpelos uniovulados (un primordio seminal por cada carpelo), así cada carpelo produce un aquenio.

El fruto es conocido como escaramujo, que corresponde a un tipo de infrutescencia denominada cinorrodón. Está compuesto por múltiples frutos secos pequeños o aquenios (poliaquenio), separados y encerrados en un receptáculo carnoso (hipantio) y de color rojizo vistoso cuando está maduro.

El aceite esencial de "Rosa damascena" se compone de terpenos y derivados de ácidos grasos, tales como citronelol (30.31 %), geraniol (16.96 %), alcohol fenetílico (12.60 %), nerol (8.46%), hexacosano (3.70 %), nonadecano (2.7 %), linalol (2.15 %), β-Ionona (1.00 %), eicosano (1.65 %), docosano, (1.27 %), farnesol (1.36%), acetato de nerilo (1.41 %), propionato de citronelilo (1.38 %), geranial (1.35 %), α-pineno (0.60 %), mirceno (0.46 %), óxido "cis" rosa (0.55 %), decanal (0.51 %), terpinen-4-ol (0.55 %), β-cariofileno (0.81 %), isoborneol (0.57 %), y heptadecano (0.92 %).

El fruto del rosal, el escaramujo, tiene un alto contenido en Vitamina C: entre 1700-2000 mg por cada 100 g de producto seco, lo que lo convierte en una de las fuentes vegetales más ricas de esta vitamina. También contiene vitaminas A, D y E, y flavonoides antioxidantes. El alto contenido de taninos es causante de estreñimiento.

Desde el punto de vista de la práctica de la jardinería, y esquemáticamente, los rosales se clasifican en cuatro grupos:

Algunas de las especies silvestres más representativas del género "Rosa":




Los rosales florecen continuamente durante todo el año desde primavera hasta principios de invierno (o más en climas cálidos). Para que esto ocurra hay que cortar las rosas marchitas. Una técnica popular consiste en seguir el tallo de la rosa seca hasta encontrar la primera rama con cinco hojas y cortar inmediatamente por encima de ella. Luego, entrado el invierno, se hace la poda radical, dejando nada más que cuatro o cinco ramas de un palmo desde el tronco principal. También se puede hacer media poda en medio de la temporada para mantener el rosal en un tamaño mediano. Esta no es necesaria para la salud de la planta ni para que florezca más.

Los cortes deben hacerse con tijera bien afilada para que resulten limpios, es decir, sin "picotazos". Deben ser sesgados, evitando los cortes rectos y no se deberán dejar fibras en ellos. Se debe cortar medio centímetro por encima de la yema exterior, en forma sesgada hacia adentro (inclinada) para que cuando llueva o se riegue la planta el agua corra y no se concentre en la yema perjudicando el crecimiento floral.

Al rosal de pie se le deberá dar forma de copa de vino para permitir un buen acceso a la luz a toda la planta.

Las rosas deben podarse cuando terminan de brotar las hojas.

Los rosales se pueden reproducir en el otoño de cuatro formas:


La mayoría suelen ser comunes a otras plantas de jardín y están en relación a la zona geográfica.

Algunas de ellas son:
Una solución para la plaga seria emplear clorpirifós como insecticida.


Ya desde la antigüedad, el cultivo de rosales estaba muy difundido, ya sea como plantas ornamentales como también para provecho de sus propiedades medicinales y aromáticas (perfumería y cosmética).

Los primeros datos de su utilización ornamental se remontan a Creta (siglo XVII a. C.). La rosa era considerada como símbolo de belleza por babilonios, sirios, egipcios, romanos y griegos. En Egipto y Grecia tuvo una especial relevancia, y mucho más en Roma. Los romanos cultivaron la rosa intensamente, siendo utilizados sus pétalos para ornamento, así como la planta en los jardines en una zona denominada Rosetum. Tras la Edad Media, donde su cultivo se restringió a Monasterios, vuelve a surgir la pasión por el cultivo del Rosal. Un ejemplo de esta pasión fue la emperatriz Josefina que a partir de 1802 en su Palacio de la Malmaison llegó a poseer una colección de 650 rosales. Las colecciones de rosas se han multiplicado desde entonces.

A fines de 1700, fue introducida en Europa, "R. semperflorens", conocida como "Rosa de Bengala", con flores pequeñas agrupadas. Para el comienzo de 1800, fue introducida en Europa, "R. indica var. fragans", conocida con el nombre de Rosa de Té, originaria de la China (conocida también como "R. chinensis").

La era moderna de las rosas se inicia a partir de 1867 con la creación del primer ejemplar híbrido de té por el productor francés Guillot, quien la llamó: «La France». El invento surgió por casualidad, cuando Guillot estaba intentando mejorar una rosa naranja. El resultado fue una flor muy olorosa y con una larga floración, distinta en tamaño y características a las rosas que había hasta entonces. La rosa de té original, anterior a la creación de los híbridos que sucedieron a la invención de Guillot de Francia, era más pequeña, casi sin olor y se producía en una escasa paleta cromática: blanco, rosa y rojo.

Durante el empiezan a llegar variedades del extremo oriente, donde su cultivo fue también muy relevante por los antiguos jardineros chinos (existen datos del cultivo de rosales hacia 3000 a. C.).

En el catolicismo la rosa es un componente simbólico del Rosario; Se dice que el Beato Angelico mientras rezaba el rosario en la calle vio a la Virgen con un grupo de ángeles que están ofreciendo canciones y alabanzas al componer una corona de rosas. Sorprendido con la visión interrumpió la oración y los ángeles se detuvieron; empezando a rezar nuevamente vio a los ángeles componer de la corona de rosas para ofrecer a María.

La rosa ha sido celebradísima en todo tiempo por los poetas y prestado materia a las mitologías y leyendas; desde Salomón que veía una rosa en la esposa del "Cantar de los cantares", Safo y Anacreonte hasta la delicada comparación de Malherbe:

En la "Novela de la rosa", esta es el premio del amor y del valor. En "El asno de oro" de Apuleyo, el borrico se vuelve hombre al comer rosas y los poetas han representado a porfía a la Aurora como una joven que esparce rosas. En la mitología indiana, la rosa representa ya el Sol, ya la Aurora, ya el Crespúsculo vespertino.

Una de las tres gracias en Grecia llevaba una rosa en la mano y se decía que la rosa había brotado del pie de Venus al salir algunas gotas de sangre de una picadura que se había causado con una espina. La fábula decía también que la rosa era al principio blanca y se había vuelto encarnada al teñirse con la sangre de Adonis (alusión al paso de la luz blanca "alba" a la luz rosada "aurora"). De igual manera que a Venus y Flora, cuyas estatuas se adornaban con guirnaldas de rosas, pertenecía esta flor a Baco y en uno de sus ditirambos invita Píndaro a coronarse de rosas en honor a Dionisos. Muchos pueblos eslavos denominan a la fiesta de la primavera "rusdija" o "fiesta de las rosas".

En algunas leyendas italianas, la rosa es símbolo de virginidad. Contrariamente, las cortesanas de Roma celebraban su fiesta el día 23 de abril consagrado a Venus Ericina y se mostraban adornadas de rosas y mirtos; en el día de San Jorge en Barcelona, también es costumbre regalar rosas y libros. En los grandes banquetes romanos, los convidados iban coronados de rosas, creyéndose que preservaban de la embriaguez. En otros países, la rosa es un símbolo funerario y de ahí, según algunos, que se planten cipreses y rosales en los cementerios.

Las rosas son símbolos antiguos del amor y de la belleza. La rosa era sagrada para un número considerable de diosas (deidades femeninas) de la antigüedad, y se utiliza a menudo como símbolo de la Virgen María. Las rosas son tan importantes que de ellas derivan términos como color rosa o rojo en una considerable variedad de idiomas.

Las rosas vienen en una variedad de colores, cada uno con un diverso significado simbólico:

Además hay ciertas expresiones:
La rosa también es el símbolo de dos dinastías reales inglesas: la Casa de Lancaster (rosa roja) y la Casa de York (rosa blanca) que se vieron enfrentadas en la conocida como Guerra de las Dos Rosas.

También es el emblema de la Selección de rugby de Inglaterra, que es conocida como «el XV de la rosa».

La rosa roja (generalmente asida con el puño) es el símbolo del Socialismo democrático, en recuerdo de Rosa de Luxemburgo, pensadora y mártir del pensamiento socialista. Es empleada por la mayoría de colectivos de esta ideología, como el Partido Socialista Obrero Español con el puño izquierdo o el Partido_Socialista_(Francia) con el puño derecho.

Su principal productor y exportador es Ecuador. La situación geográfica del país permite contar con microclimas y una luminosidad que proporciona características únicas a las flores como son: tallos largos, gruesos y totalmente verticales, botones grandes y colores vivos. Sus principales mercados: Estados Unidos, Holanda (importa flores para luego re-exportarlas a otros países de la Unión Europea), Italia, Alemania, Rusia, Canadá, Argentina, España, Francia, Suiza y Ucrania. También Chile, China y Brasil. La superficie total de plantaciones es de 3300 ha, con una disponibilidad de 85 000 toneladas por año. El 98 % de la producción se exporta.


</doc>
<doc id="2539" url="https://es.wikipedia.org/wiki?curid=2539" title="Reserva nacional Tambopata">
Reserva nacional Tambopata

La reserva nacional Tambopata (RNTMB) es un área natural protegida del Perú, ubicada en el departamento de Madre de Dios, provincia de Tambopata y se extiende en los distritos de Tambopata e Inambari. La Reserva Nacional Tambopata fue creada el 4 de septiembre de 2000, mediante el decreto supremo DS Nº 048-2000-AG, con una extensión de 274,690 ha, esta área natural protegida cuenta con una gradiente altitudinal promedio de 300msnm en un rango de 200-400msnm. Dentro de sus objetivos de creación de la reserva se han establecido 3 ejes de acción: primero proteger a la flora, la fauna y los procesos ecológicos de una muestra de la selva sur amazónica del Perú; segundo generar procesos de conservación con la población en el ámbito de la reserva, con la finalidad de usar sosteniblemente los recursos como los castañales y el paisaje para la recreación y tercero contribuir al desarrollo sostenible de la región y del país, a partir del conocimiento de la diversidad biológica y del manejo de los diversos recursos naturales renovables. 

El clima de la zona es del tipo bosque subtropical húmedo, en donde la temperatura media es de 26°C, llegando a fluctuar entre los 10°C y 38°C.

Estos límites inferiores se explican por los vientos antárticos que ingresan irregularmente a la cuenca del Amazonas provenientes desde los andes generalmente en las temporadas de vientos fríos en junio y julio.

En el caso de sus temperaturas máximas, estas se registran durante los meses de septiembre a octubre.

Las precipitaciones en la zona están en el rango de 1600 a 2400mm anual.

Los registros de las precipitaciones a nivel mensual varían de acuerdo a las temporadas, en donde la temporada de máxima precipitación es entre diciembre y marzo, a este periodo de altas lluvias tenemos los meses de transición que son octubre, noviembre, abril y mayo, finalmente la temporada de baja precipitación entre los meses de junio a septiembre.

La Reserva Nacional Tambopata tiene como principales cuencas a los ríos Tambopata y Heath, en la reserva también podemos encontrar a los ríos Azul y Malinowsquillo los cuales desembocan en la margen derecha del río Malinowski.

El río Tambopata nace en el altiplano peruano boliviano, cuenta con una extensión de 402Km y su principal afluente es el Malinowski. Este río atraviesa la Reserva Nacional Tambopata de este a oeste, siendo este uno de los principales accesos a los atractivos de la reserva.

El río Heath nace en los andes en la región de Puno y tiene su desembocadura en el río Madre de Dios con un recorrido de 200 km. A lo largo de su recorrido cuenta con los afluentes Bravo y Wiener.

El río Malinowski o también conocido como río Carama, nace a las afueras de la reserva, en la comunidad nativa de Kotsimba en el distrito de Inambari, sus afluentes son los ríos Pamahuaca, Azul, Malinowsquillo y Agua Negra por la margen derecha y el río Manuani por la margen izquierda.

La cuenca del río Tambopata presenta uno de los mayores índices de diversidad biológica en el mundo. La Reserva Nacional Tambopata se ubica en la zona media y baja de esta cuenca, vecina a la ciudad de Puerto Maldonado. Entre sus ecosistemas más comunes se encuentran los aguajales, los pantanos, los pacales y los bosques ribereños, cuyas características físicas permiten a los pobladores locales el aprovechamiento de los recursos naturales. La Reserva Nacional Tambopata alberga hábitats principalmente acuáticos que son usados como paraderos de más de 40 especies de aves migratorias transcontinentales. En la reserva nacional se protegen importantes especies consideradas en vías de extinción y le ofrece al turismo un destino privilegiado para la observación de la diversidad de flora y fauna silvestre.

En el Diagnóstico del Proceso de Elaboración del Plan Maestro de la Reserva nacional Tambopata se reportaron 1 713 especies, pertenecientes a 654 géneros de 145 familias. Para las angiospermas (plantas con flores) se consideró la clasificación propuesta por el Angyosperm Phylogeny Group (APG III) y para los pteridofitos (helechos) se consideró la clasificación propuesta por Smith et al. (2006). Las angiospermas registran 1 637 especies agrupadas en 127 familias y 622 géneros, o las familias más diversas Fabaceae (158 especies), Rubiaceae (104 especies) y Moraceae (66 especies). Los pteridofitos registran 76 especies de 32 géneros y 18 familias, siendo las familias más diversas: Polypodiaceae (16 especies), Pteridaceae (11 especies) y Thelypteridaceae (9 especies). Es así que se pueden apreciar en llanuras de sedimentación a los aguajales ("Mauritia flexuosa"), así como otras especies con valor comercial como la caoba ("Swietenia macrophylla"), tornillo ("Cedrelinga catenaeformis"), cedro ("Cedrela odorata"), lupuna (Ceiba spp.), shiringa ("Hevea brasilensis"), caucho ("Castilla elastica") y la castaña ("Bertholletia excelsa"), de esta última especie hay que resaltar que es el recurso forestal no maderable con mayor potencial económico desarrollado en la Reserva nacional Tambopata, el cual se aprovecha bajo planes de manejo aprobados y controlados por el Servicio Nacional de Áreas Naturales Protegidas por el Estado (SERNANP).

 En la Reserva nacional Tambopata se ha reportado la presencia de más de 632 especies de aves, 1,200 de mariposas, 103 de anfibios, 180 de peces, 169 de mamíferos y 103 de reptiles. En su interior se encuentra hábitats saludables para la recuperación y refugio de poblaciones amenazadas de especies como el lobo de río ("Pteronura brasiliensis"), la nutria ("Lontra longicaudis") y felinos como el yaguarundi ("Herpailurus yagouaroundi"), el puma ("Puma concolor"), el jaguar ("Panthera onca"), el ocelote o tigrillo ("Leopardus pardalis") y el margay ("Leopardus wiedii").

Entre las especies de primates se encuentra el maquisapa ("Ateles chamek"), el pichico ("Saguinus fuscicollis"), el pichico emperador ("Saguinus imperator"), el coto mono ("Alouatta seniculus"), el mono cabecinegro ("Aotus nigriceps"), el mono choro ("Lagothrix lagotricha"), el fraile ("Saimiri boliviensis"), el mono ardilla ("Saimiri sciureus"), el machín blanco ("Cebus albifrons") y el machín negro ("Cebus apella").

En cuanto a las aves destaca la presencia del águila harpía ("Harpia harpyja"), del águila crestada ("Morphnus guianensis"), del paujil común ("Mitu tuberosa"), del paujil unicornio ("Pauxi unicornis") y del paujil carunculado ("Crax globulosa"). En la Reserva nacional Tambopata se encuentra casi la totalidad de especies de guacamayos ( Ara spp.)que habitan en el Perú.

Otras especies comunes son los reptiles: boa esmeralda ("Corallus caninus"), el loro machaco (""), la boa constrictora ("Boa constrictor") y la shushupe ("Lachesis muta"). También es común observar al caimán negro ("Melanosuchus niger"), al caimán blanco ("Caiman crocodylus") y a la taricaya ("Podocnemis unifilis").

Los peces también presentan una gran variedad, entre ellos destaca el boquichico ("Prochilodus nigricans"), el zúngaro saltón ("Brachyplatystoma filamentosum"), el yahuarachi ("Potamorhyna latior"), el dorado ("") y el paco ("Piaractus brachipomun"). Entre los peces no comerciales están el sábalo (Brycon spp.), la lisa ("Schizodon fasciatus") y el bagre (Pimelodus sp.).

La Reserva nacional Tambopata es uno de los principales destinos dentro del Sistema Nacional de Áreas Naturales Protegidas por el Estado (SINANPE). Debido a su gran biodiversidad y hábitats naturales protegidos, esta reserva es un sitio privilegiado para el contacto con la naturaleza en lo que respecta a flora, fauna y paisajes.

El destino turístico más visitado es el lago Sandoval, este es calificado como un espejo de agua de 127 ha, en donde abundan poblaciones de guacamayos en la vegetación que rodea al lago, además de permitir el avistamiento de garzas, martín pescador, caimanes y nutrias. Esta zona turística cuenta con alojamientos para los visitantes.
Actualmente dispone de un camino completamente hecho de madera y ayuda al desplazamiento de personas con discapacidad.
A través de la cuenca del río Tambopata hay acceso a los lagos Cocococha y Sachavacayoc, ambos son puntos en donde abunda la vida la vida silvestre. En Sachavacayoc hay una zona para campamento para que los turistas puedan pasar la noche. Además de los lagos también se tienen las Collpas, estos son lugares en donde los animales acuden a ingerir arcilla de los barrancos de los ríos. Entre 5:30 y 9:00 a. m. se genera una aglomeración de guacamayos y loros que forman un espectáculo de color y vida silvestre para los turistas. Las principales collpas son Chuncho y Colorado, ambas están en las márgenes del río Tambopata.



</doc>
<doc id="2540" url="https://es.wikipedia.org/wiki?curid=2540" title="Reino">
Reino

Reino puede referirse a:


</doc>
<doc id="2541" url="https://es.wikipedia.org/wiki?curid=2541" title="Reino de Dios">
Reino de Dios

El concepto Reino de Dios o Reino de Los Cielos (en griego βασιλεία τοῦ θεοῦ "basileia tou theou") es un reino en el cual Dios es el gobernante y juez, cuya sede es el cielo. Al igual que los reinos de la Tierra, esta forma de gobierno sería de monarquía absoluta con jerarquía piramidal, siendo los súbditos la humanidad. Aunque las especificaciones varía en cada religión, una base fundamental es que es Infinito.

El Reino de Dios es mencionado frecuentemente en el Tanaj. Está unido al entendimiento judío de que Dios habría de intervenir directamente para restaurar la nacionalidad de Israel y luego reinar sobre ella.
Luego fue interpretado como que de la descendencia de David saldría el Mesías de Israel, que se sentaría en el trono de David y gobernaría por la eternidad. Por lo tanto los judíos esperan la intervención divina, en lo político y en lo espiritual.

El Reino de Dios fue expresamente prometido al Rey David, haciéndose un pacto entre él y Dios y prometiéndole que reinaría siempre alguien en el trono de su «casa» — la de David —.

El Catecismo de la Iglesia Católica indica que en el Nuevo Testamento se utilizan varias expresiones para caracterizar la bienaventuranza a la que Dios llama al hombre: la llegada del Reino de Dios; "«Dichosos los limpios de corazón porque ellos verán a Dios» —Mt 5, 8—; «la entrada en el gozo del Señor» — Mt 25; 21.23 —; «la entrada en el descanso de Dios» — Hb 4, 7-11—.
La idea del Reino de Dios se encuentra predominantemente en el Nuevo Testamento, especialmente en los Evangelios.

El Reino de Dios es un término usado indistintamente con el de «Reino de los Cielos». En el Evangelio según Mateo se utiliza esta última expresión, mientras que en el Lucas, en el de Marcos y en el de Juan se utiliza «Reino de Dios». La explicación habitual es que el evangelio de Mateo está destinado a los judíos quienes prefieren evitar el uso directo del nombre de Dios. Marcos y Lucas están dirigidos a una audiencia más general y menos familiarizada con el término «Reino de los Cielos».

Algunos intérpretes premilenaristas piensan que el «Reino de los Cielos» se refiere al reino milenario de Dios, mientras que el «Reino de Dios» se refiere a su reinado universal. Otros opinan que no hay base para tal distinción.

El historiador, escritor y filósofo británico H. G. Wells escribió:

El pensamiento cristiano del Reino de Dios agrupa distintos conceptos según el entendimiento de cada denominación, entre las que destacan las siguientes.

Los evangelios describen a Jesús de Nazaret proclamando el Reino como algo que ya está cerca, que está llegando en el presente, no como una realidad futura. Las actividades narradas de Jesús, al sanar las enfermedades, expulsar los demonios, enseñar una nueva ética de vida y ofrecer una nueva esperanza en Dios al más pobre, se entienden como una demostración que el Reino está en acción. Tener al Mesías, el Rey de los judíos, entre ellos, es un aspecto de este Reino: el Rey había llegado para representar su Reino. Por su vida sin pecado y mediante sus milagros estaba demostrando a los judíos como es el Reino.

"El Reino de Dios" es un genitivo, el cual nos indica que es Dios mismo desde un punto de vista concreto, su actuación en este mundo y en nuestra historia. La cuestión planteada a los contemporáneos de Jesús (especialmente a los imbuidos en la mentalidad apocalíptica) es si Dios actúa en este mundo y en esta historia, o no; y si actúa, cuándo lo hace o lo va a hacer y bajo qué condiciones. Jesús nos predica que esto es inminente, y que la esperada acción de Dios en este mundo empieza ya.

Jesús dio mucha importancia a este tema, como se puede ver en el Padrenuestro, donde es el segundo asunto más importante en esa oración.

El Reino de Dios también se refiere al cambio de corazón o mente (metanoia) por parte de los cristianos, dando énfasis a la naturaleza espiritual de su Reino al decir que "«el Reino de los Cielos está dentro de vosotros mismos»". Esta frase puede también traducirse, sin embargo, "«el reino de los cielos está en medio de vosotros.»"

Jesús usó el lenguaje del "Reino de Dios" de una forma que se contrapone con los revolucionarios judíos del siglo I, llamados zelotes, que creían que el Reino era una realidad política que llegaría con una revuelta violenta contra la dominación romana, reemplazada por una teocracia judía.

En los Evangelios canónicos, Jesús de Nazaret invita a todos los hombres a entrar en el Reino de Dios; aun el peor de los pecadores es llamado a convertirse y aceptar la infinita misericordia del Padre. El Reino pertenece, ya aquí en la tierra, a quienes lo acogen con corazón humilde. A ellos les son revelados los misterios del Reino de Dios. La Iglesia (católica) se considera a sí misma como "el inicio sobre la tierra" del Reino de Dios y que la plenitud de este se alcanzará después del juicio final, cuando el universo entero, liberado de la esclavitud de la corrupción, participará de la gloria de Cristo, inaugurando «los nuevos cielos y la tierra nueva» (2 P 3, 13). Así se alcanzará el Reino de Dios pleno, es decir, la realización definitiva del designio salvífico de Dios de «hacer que todo tenga a Cristo por Cabeza, lo que está en los cielos y lo que está en la tierra» (Ef 1, 10). Dios será entonces «todo en todos» (1 Co 15, 28), en la vida eterna.

Los protestantes, por otra parte, tienden a creer que la Iglesia es el instrumento en el cual el Reino se manifiesta, no un sinónimo del Reino en sí.

Según el teólogo protestante Dietrich Bonhoeffer el Reino de Dios en la tierra se configura en dos aspectos, en los que se manifiesta escindido: milagro y orden. «El aspecto bajo el cual el Reino de Dios se manifiesta como milagro lo llamamos iglesia; y el aspecto bajo el cual el Reino de Dios se manifiesta como orden lo llamamos estado. El Reino de Dios en nuestro mundo no es otra cosa que la dualidad de iglesia y estado… El Reino de Dios se configura en la iglesia en la medida en que ésta da testimonio del milagro de Dios… El Reino de Dios se configura en el estado en la medida en que éste reconoce y preserva el orden del mantenimiento de la vida…».

La manifestación presente del Reino fue expresada por Jesús como evidencia provisional de una realidad más amplia en un futuro inminente.

Este aspecto futuro del Reino es la creencia en una implementación post-apocalíptica del gobierno de Dios, (teocracia), especialmente en la interpretación premilenarista del protestantismo fundamentalista.

La tensión entre los aspectos futuros y presentes del Reino se han llamado "el ahora y el no todavía" del Reino de Dios. 

Típicamente, en el Catolicismo, el protestantismo liberal y entre los pentecostales, entre otros, se ha enfatizado el aspecto presente, mientras que protestantes fundamentalistas y evangélicos han enfatizado el aspecto futuro.





</doc>
<doc id="2542" url="https://es.wikipedia.org/wiki?curid=2542" title="Roger de Flor">
Roger de Flor

Roger de Flor (Brindisi, 1266-Adrianópolis, 1305) fue un caballero templario y caudillo mercenario italiano al servicio de la Corona de Aragón. Ejerció como uno de los capitanes de los almogávares y también fue conocido como Roger von Blume y Rutger Blume.

Roger fue hijo de un oficial de cetrería del emperador Federico II llamado Ricardo y de una burguesa de Brindisi, donde él nació. Cuando se arruinó la familia, su madre le confió a un caballero de la Orden del Temple y allí fue Hermano sargento al mando del navío "Halcón". 

Participó en la última cruzada a Tierra Santa, donde se distinguió en la defensa de San Juan de Acre (1291). Sin embargo, los templarios le acusaron de haberse apropiado de tesoros de la orden en la confusión en la que se desarrolló el desalojo de la ciudad, por lo que fue expulsado de la orden. Aprovechando su experiencia militar, se hizo mercenario, entrando al servicio del rey Federico II de Sicilia (hijo de Pedro III el Grande de Aragón).

Federico puso a Roger de Flor al mando de las compañías de almogávares, mercenarios que habían sido empleados por la Corona de Aragón en la conquista de Valencia y Mallorca, y más tarde para consolidar sus dominios de Sicilia frente a las pretensiones de la Casa de Anjou. Participó en la defensa de Mesina en 1302 demostrando dotes de auténtico líder. 

Tras la Paz de Caltabellota (1302) entre Carlos II de Anjou y Federico de Sicilia, en 1302 se puso al servicio del emperador bizantino Andrónico II Paleólogo para ayudarle contra el peligro otomano, al mando de una expedición de 4.000 almogávares, 1.500 soldados de caballería y 39 naves enviada por Federico (la Gran Compañía Catalana). Desfiló al mando de los almogávares, los cuales le tenían gran estima, ante el emperador bizantino en la ciudad de Constantinopla. Al mando de los almogávares aniquiló a los genoveses de Constantinopla, acto que agradeció el emperador. Harto de su tutela, pasó a Anatolia y tomó las ciudades de Filadelfia, Magnesia y Éfeso, rechazando a los turcos hasta Cilicia y los Tauro (1304), siempre en batallas en inferioridad numérica. 

Durante la primavera de 1304 tuvo lugar también una batalla entre los almogávares e invasores escitas procedentes del norte del mar Negro (alanos), que fueron derrotados. En recompensa por los servicios al Imperio, Andrónico le concedió el título de megaduque (comandante de la flota) y la mano de María, su sobrina e hija del zar de Bulgaria. Las batallas anteriores habían sido cortas y provocaron mayor número de víctimas, sobre todo en la retirada de los turcos del campo de batalla. Fueron de menor intensidad comparadas con la que se produjo cerca de las Puertas Cilicias. Roger de Flor y 8.000 almogávares derrotaron a un Ejército turco compuesto por 30 000 soldados, en su mayoría jenízaros, causando 18 000 bajas al enemigo. Después de esta gran victoria, los turcos se pensaron dos veces atacar de nuevo al Imperio Bizantino durante varios años, y Roger fue proclamado césar del Imperio, concediéndole aquel en feudo los territorios bizantinos en Asia Menor, con excepción de las ciudades. 
En la batalla destacó Berenguer de Entenza, que había apoyado a Roger con 1.000 almogávares. A éste se le concedió el título de megaduque a petición de Roger.

Estratégicamente, la posición de Roger de Flor y Berenguer de Entenza en Bizancio favorecía el proyecto Rex Bellator de Ramon Llull, que proponía en su "Liber de Fine" la ruta del sur (Almería-Granada-Norte de África-Egipto) para proseguir la Cruzada con ventaja de los reyes de la Corona de Aragón en caso de que hubiesen conseguido encabezar las órdenes militares unidas.

Sin embargo, la situación de los almogávares en el Imperio no era cómoda. Por una parte, al parecer cometieron excesos con la población local griega. Por otra, parece que la ambición de Roger de Flor era grande y pretendía erigirse en soberano de los territorios conquistados. Finalmente, su creciente ambición e influencia despertaron la hostilidad del emperador Miguel IX, hijo de Andrónico II y asociado al gobierno imperial. Así, éste le hizo asesinar en Adrianópolis durante un banquete junto con más de un centenar de jefes almogávares el 5 de abril de 1305, y atacó posteriormente a las tropas almogávares. Sin embargo, no sólo no pudieron acabar con ellos, sino que los supervivientes, bajo el mando de Berenguer de Entenza, contraatacaron y arrasaron todo cuanto encontraron a su paso en Tracia y Macedonia (hechos conocidos como "Venganza catalana"). Finalmente se creó un ducado (Atenas y Neopatria) nominalmente dependiente de la Corona de Aragón.

La figura de Roger de Flor alcanzó difusión entre sus contemporáneos gracias a la "Crónica de Muntaner", inspirando la obra "Tirante el Blanco", de Joanot Martorell. Una de las unidades de la BRIPAC (Brigada Paracaidista) del Ejército Español lleva su nombre.



</doc>
<doc id="2543" url="https://es.wikipedia.org/wiki?curid=2543" title="Real Academia Española">
Real Academia Española

La Real Academia Española (RAE) es una institución cultural con sede en Madrid (España). Esta y otras veintitrés academias de la Lengua correspondientes a cada uno de los países donde se habla el español conforman la Asociación de Academias de la Lengua Española (ASALE).

Se dedica a la regularización lingüística mediante la promulgación de normativas dirigidas a fomentar la unidad idiomática entre o dentro de los diversos territorios que componen el llamado mundo hispanohablante; garantizar una norma común, en concordancia con sus estatutos fundacionales: «velar por que los cambios que experimente [...] no quiebren la esencial unidad que mantiene en todo el ámbito hispánico».

Fue fundada en 1713 por iniciativa del ilustrado Juan Manuel Fernández Pacheco, VIII marqués de Villena y duque de Escalona, a imitación de la Academia Francesa. Al año siguiente, el rey Felipe V aprobó su constitución y la colocó bajo su protección. En 1715, la Academia aprobó sus primeros estatutos.

Las directrices lingüísticas que propone se recogen en diversas obras. Las prioritarias son el diccionario, abreviado DLE (art. 2.º de sus estatutos), editado periódicamente veintitrés veces desde 1780 hasta hoy; y la gramática (4.º), editada entre 2009 y 2011.<section begin="fragmento trm1" /><section end="fragmento trm1" />Desempeña sus funciones en la sede principal, inaugurada en 1894, en la calle Felipe IV, 4, en el barrio de Los Jerónimos, y en el Centro de Estudios de la Real Academia Española y de la ASALE, en la calle Serrano 187-189, en 2007.

Desde agosto de 2011, la RAE informa y responde dudas desde las redes sociales Facebook y Twitter utilizando la etiqueta #dudaRAE.

En 1711, España, a diferencia de Francia, Italia y Portugal, no tenía un gran diccionario. El núcleo inicial de la futura Academia lo formaron ese mismo año los ocho "novatores" que se reunían en la biblioteca del palacio madrileño de Juan Manuel Fernández Pacheco, situado en la plaza de las Descalzas Reales en Madrid.

La Real Academia Española fue fundada en 1713 por iniciativa de Juan Manuel Fernández Pacheco, VIII marqués de Villena y duque de Escalona, con el propósito de «fijar las voces y vocablos de la lengua castellana en su mayor propiedad, elegancia y pureza». El objetivo era fijar el idioma en el estado de plenitud que había alcanzado durante el siglo XVI y que se había consolidado en el XVII. Se tomaron como modelo para su creación la Accademia della Crusca italiana (1582) y la Academia Francesa (1635). La primera sesión oficial de la nueva corporación se celebró en la propia casa del marqués de Villena el 6 de julio de 1713, acontecimiento que se registra en el libro de actas, iniciado el 3 de agosto de 1713. Su creación, con veinticuatro sillas, fue aprobada el 3 de octubre de 1714 por Real Cédula de Felipe V, quien la acogió bajo su «amparo y Real Protección». Esto significaba que los académicos gozaban de las preeminencias y exenciones concedidas a la servidumbre de la Casa Real. Tuvo su primera sede en el número 26 de la calle de Valverde, de donde se trasladó a la de Alarcón esquina a Felipe IV, su sede definitiva.

En la conciencia, según la visión de la época, de que la lengua española había llegado a un momento de suma perfección, fue propósito de la Real Academia «fijar las voces y vocablos de la lengua castellana en su mayor propiedad, elegancia y pureza». Se representó tal finalidad con un emblema formado por un crisol puesto al fuego, con la leyenda: "Limpia, fija y da esplendor". Nació, por tanto, la institución como un centro de trabajo eficaz, según decían los fundadores, «al servicio del honor de la nación».

Esta vocación de utilidad colectiva se convirtió en la principal seña de identidad de la Academia Española, diferenciándola de otras academias que habían proliferado en los siglos de oro y que estaban concebidas como meras tertulias literarias de carácter ocasional.

En 1723 se le concedieron al marqués 60000 reales anuales para sus publicaciones. Fernando VI le permitió publicar sus obras y las de sus miembros sin censura previa.

En 1726 se publica el primer volumen del gran diccionario de la época, y en 1741 el de ortografía. Y después, una gramática.

En 1784, María Isidra de Guzmán y de la Cerda, primera mujer doctora por la Universidad de Alcalá, fue admitida como académica honoraria y, aunque pronunció su discurso de agradecimiento, no volvió a comparecer más. Se cuenta entre las primeras mujeres académicas del mundo. No volvió a haber otra fémina hasta la elección como académica de número de Carmen Conde en 1978.

En 1842 solicitaron un crédito de ochenta mil reales por dos años para financiar el nuevo Diccionario a José Nicasio Gallego quien era secretario de la propia Real Corporación. Mediante dicho préstamo la Academia hipotecó todos sus bienes. En 1847 se pudo saldar la hipoteca.

En 1848 la Academia reformó su organización por medio de unos nuevos estatutos, aprobados por Real Decreto. Sucesivos reales decretos (1859, 1977, 1993) aprobaron nuevas reformas.

Tras la independencia de los países americanos, la Real Academia Española promovió el nacimiento de academias correspondientes en cada una de las jóvenes repúblicas hispanoamericanas. Esta decisión estuvo motivada por la idea central del movimiento llamado panhispanismo o hispanoamericanismo, según la cual los ciudadanos de todas las naciones de matriz española tienen por patria común una misma lengua (el español) y comparten el patrimonio de una misma literatura. A pesar de que hubo precedentes de academias nacionales creadas con independencia de la Española, como la Academia de la Lengua de México (1835), que se disolvió para dar paso a la correspondiente Academia Mexicana de la Lengua (1875), y de que alguna de las academias americanas, como la Academia Argentina de Letras (1931), no tuvo vinculación estatutaria con la RAE hasta fundarse la ASALE, desde 1870 se establecieron en América diversas academias hispanoamericanas subordinadas estatutariamente a la RAE, a las que se llamó "correspondientes" por mantener con la academia matriz una relación por correspondencia postal. A ellas se añadieron la Academia Argentina de Letras, la Academia Filipina de la Lengua Española, la Academia Norteamericana de la Lengua Española y la Academia Ecuatoguineana de la Lengua Española. Estas veintidós academias, que tienen igual rango y condiciones que la RAE, constituyen con ella la Asociación de Academias de la Lengua Española (ASALE), fundada en 1951 en el marco del I Congreso de Academias celebrado en México.

La ASALE es el órgano de colaboración de todas ellas en la promoción de una política lingüística panhispánica. Esta política, plasmada en numerosos proyectos de trabajo conjunto, fue galardonada en el año 2000 con el Premio Príncipe de Asturias de la Concordia, concedido a la Real Academia Española, junto con la Asociación de Academias de la Lengua Española.

El 20 de octubre de 1993 se constituyó la Fundación pro Real Academia Española, entidad que tiene como finalidad atraer recursos económicos para la financiación de las actividades e iniciativas de la Academia. Está regida por un patronato, cuya presidencia de honor corresponde al rey de España, la presidencia al gobernador del Banco de España y la vicepresidencia al director de la Real Academia Española. Las vocalías corresponden a otros académicos, presidentes de las comunidades autónomas y de empresas privadas, como socios fundadores.

En los últimos estatutos aprobados en 1993, se consideró necesario supeditar el antiguo lema fundacional -"Limpia, fija y da esplendor"- al objetivo superior de trabajar al servicio de la unidad idiomática. El artículo primero establece, en tal sentido, que la Academia “tiene como misión principal velar por que los cambios que experimente la lengua española en su constante adaptación a las necesidades de sus hablantes no quiebren la esencial unidad que mantiene en todo el ámbito hispánico”. De esa forma quedaba sancionado un compromiso que la Academia había asumido ya desde el siglo XIX.

La Fundación está abierta a la participación de particulares mediante la correspondiente cuota económica, miembros benefactores, y entre las actividades subvencionadas se encuentran la realización del banco de datos, el "Diccionario del estudiante", el "Diccionario panhispánico de dudas", la "Gramática normativa" y otras obras en proyecto o desarrollo como el CORPES (Corpus del Español del Siglo XXI) o el "Diccionario histórico".

El artículo primero de los estatutos de la RAE dice:

Los 46 miembros de número de la Real Academia Española son elegidos por cooptación por el resto de los académicos. Las plazas de académico de número se denominan «sillas», que tradicionalmente se han distribuido de acuerdo a letras del alfabeto latino de uso para el castellano, tanto mayúsculas como minúsculas (excepción hecha de las plazas de las secciones especiales o regionales). De acuerdo a una norma de respeto, la provisión de la plaza para un nuevo académico se inicia a partir del sexto mes desde el fallecimiento del anterior ocupante de la silla correspondiente.

Los académicos de número actualmente son:

Como dato de interés, el único Premio Nobel de Literatura español que no ingresó como académico en la RAE fue Juan Ramón Jiménez (galardonado en 1956 y fallecido dos años después).

En 1784, tal vez por presiones de la Corte, María Isidra de Guzmán y de la Cerda fue admitida como Académica honoraria.

En 1853 Gertrudis Gómez de Avellaneda solicitó su ingreso lo que planteó un largo debate tras el cual se tomó el acuerdo de no aceptar mujeres como académicas de número, resolución que la Academia utilizó hasta principios del siglo XX y que le valdría la consideración de antifeminista. En 1912 la petición de Emilia Pardo Bazán fue rechazada, a pesar de los apoyos de diferentes instituciones, en virtud del acuerdo de 1853.

La candidatura de Concha Espina fue igualmente rechazada en dos ocasiones (1928 y 1930),si bien en 1928 la Academia admite la de Blanca de los Ríos, candidatura que llegó a someterse a votación aunque no resultó elegida.También fue aceptada y sometida a votación la candidatura de María Moliner en 1972, aunque en esta ocasión la votación fue ganada por amplia mayoría por el lingüista Emilio Alarcos Llorach.

En 1978, casi 300 años después de su fundación, fue aceptada la presencia femenina en la Real Academia, siendo Carmen Conde la primera mujer que ejerció como Académica de número, ocupando la silla K. Al ingreso de esta escritora se han sucedido los de otras mujeres de reconocido prestigio en el mundo de las letras: Elena Quiroga de Abarca (1983), Ana María Matute (1998), María del Carmen Iglesias Cano (2002), Margarita Salas (2003), Soledad Puértolas (2010), Inés Fernández-Ordóñez (2011), Carme Riera (2013), Aurora Egido (2014), Clara Janés (2016) y Paz Battaner (2017).

Según sus estatutos, la RAE está compuesta por:

Una junta de gobierno rige la Academia y supervisa todos los asuntos relativos a su buena operación, tanto en lo relacionado con su funcionamiento interno como con sus relaciones con los organismos del estado, y las demás Academias. Esta junta la preside el director de la Academia y está constituida por el vicedirector, el secretario, el censor, el bibliotecario, el tesorero, el vicesecretario y dos vocales adjuntos. Todos estos cargos son electivos y, a excepción de los vocales, que se eligen cada dos años, pueden ejercerse durante cuatro años, prorrogables solo una vez.

La Academia funciona en Pleno y en Comisiones que se reúnen semanalmente. Las Comisiones tienen la misión de elaborar las propuestas que posteriormente examinará el Pleno para decidir sobre su aprobación. En la actualidad existen las siguientes comisiones: Delegada del Pleno y para el Diccionario, Instituto de Lexicografía, Diccionario Histórico de la Lengua Española, Publicaciones y Boletín, Armonización de las Obras Académicas, Armonización de Terminología Lingüística, Comisión Conservadora de la Casa Museo Lope de Vega, Comisión para el III Centenario de la RAE, Ciencias Sociales, Vocabulario Científico y Técnico, Ciencias Humanas, Cultura I y Cultura II.

El Pleno, formado por todos los académicos, se reúne durante el curso académico los jueves por la tarde. Una vez aprobada las actas de la sesión anterior y de debatir cualquier tema general, los asistentes presentan enmiendas y adiciones al Diccionario. Acto seguido se examinan las propuestas formuladas por las diversas Comisiones. Las resoluciones, en el caso de que se produzca disparidad de criterio, se adoptan mediante votación.

Al servicio de los trabajos que la Academia desarrolla en Pleno o en Comisiones, funciona el Instituto de Lexicografía, integrado por filólogos y lexicógrafos que realizan las tareas de apoyo para la elaboración de los diccionarios académicos.

El 16 de abril de 2020, celebró el primer pleno virtual de su historia ante la prolongación de las medidas de confinamiento con motivo del estado de alarma provocado por el coronavirus.

Desde su creación la RAE ha tenido treinta directores. También hubo algunos casos de directores temporales, como Vicente García de Diego, director accidental (1965-1968), y Rafael Lapesa, director interino (1988).

El cargo de director de la Real Academia Española conlleva el cargo de presidente de la Asociación de Academias de la Lengua Española (ASALE).

Publicaciones conjuntas de la RAE y la Asociación de Academias de la Lengua Española (integrada por las 23 academias de la lengua española existentes en el mundo).







Todas las obras son publicadas por la RAE y ASALE.


La RAE edita dos revistas en formato digital y acceso abierto:







</doc>
<doc id="2551" url="https://es.wikipedia.org/wiki?curid=2551" title="Soda">
Soda

Soda hace referencia a varios artículos:


</doc>
<doc id="2552" url="https://es.wikipedia.org/wiki?curid=2552" title="Sistema operativo">
Sistema operativo

Un sistema operativo (SO o, frecuentemente, OS —del inglés "operating system"—) es el "software" principal o conjunto de programas de un sistema informático que gestiona los recursos de "hardware" y provee servicios a los programas de aplicación de "software", ejecutándose en modo privilegiado respecto de los restantes.

Nótese que es un error común muy extendido denominar al conjunto completo de herramientas sistema operativo,es decir, la inclusión en el mismo término de programas como el explorador de ficheros, el navegador web y todo tipo de herramientas que permiten la interacción con el sistema operativo. Otro ejemplo para comprender esta diferencia se encuentra en la plataforma Amiga, donde el entorno gráfico de usuario se distribuía por separado, de modo que, también podía reemplazarse por otro, como era el caso de directory Opus o incluso manejarlo arrancando con una línea de comandos y el sistema gráfico. De este modo, comenzaba a funcionar con el propio sistema operativo que llevaba incluido en una ROM, por lo que era cuestión del usuario decidir si necesitaba un entorno gráfico para manejar el sistema operativo o simplemente otra aplicación. Uno de los más prominentes ejemplos de esta diferencia, es el núcleo Linux, usado en las llamadas distribuciones Linux, ya que al estar también basadas en Unix, proporcionan un sistema de funcionamiento similar. Este error de precisión, se debe a la modernización de la informática llevada a cabo a finales de los 80, cuando la filosofía de estructura básica de funcionamiento de los grandes computadores se rediseñó a fin de llevarla a los hogares y facilitar su uso, cambiando el concepto de computador multiusuario, (muchos usuarios al mismo tiempo) por un sistema monousuario (únicamente un usuario al mismo tiempo) más sencillo de gestionar. Véase AmigaOS, beOS o Mac OS como los pioneros de dicha modernización, cuando los Amiga fueron bautizados con el sobrenombre de "Video Toasters" por su capacidad para la Edición de vídeo en entorno multitarea round robin, con gestión de miles de colores e interfaces intuitivos para diseño en 3D.

En ciertos textos, el sistema operativo es llamado indistintamente como núcleo o kernel, pero debe tenerse en cuenta que la diferencia entre "kernel" y sistema operativo solo es aplicable si el núcleo es monolítico, lo cual fue muy común entre los primeros sistemas. En caso contrario, es incorrecto llamar al sistema operativo núcleo.

Uno de los propósitos del sistema operativo que gestiona el núcleo intermediario consiste en gestionar los recursos de localización y protección de acceso del "hardware", hecho que alivia a los programadores de aplicaciones de tener que tratar con estos detalles. La mayoría de aparatos electrónicos que utilizan microprocesadores para funcionar, llevan incorporado un sistema operativo (teléfonos móviles, reproductores de DVD, computadoras, radios, enrutadores, etc.). En cuyo caso, son manejados mediante una interfaz gráfica de usuario, un gestor de ventanas o un entorno de escritorio, si es un celular, mediante una consola o control remoto si es un DVD y, mediante una línea de comandos o navegador web si es un enrutador.

Los primeros sistemas (1945-1954) eran grandes máquinas operadas desde la consola maestra por los programadores. Durante la década siguiente (1955-1965) se llevaron a cabo avances en el "hardware": lectoras de tarjetas, impresoras, cintas magnéticas, etc. Esto a su vez provocó un avance en el "software": compiladores, ensambladores, cargadores, manejadores de dispositivos, etc.

A finales de los años 1980, una computadora Commodore Amiga equipada con una aceleradora Video Toaster era capaz de producir efectos comparados a sistemas dedicados que costaban el triple. Un Video Toaster junto a Lightwave ayudó a producir muchos programas de televisión y películas, entre las que se incluyen Babylon 5, SeaQuest DSV y .

El problema principal de las primeras computadoras era su baja utilización, la primera solución fue poner un operador profesional que lo manejase, con lo que se eliminaron las hojas de reserva, se ahorró tiempo y se aumentó la velocidad.

Para ello, los trabajos se agrupaban de forma manual en lotes mediante lo que se conoce como procesamiento por lotes (batch processing) sin automatizar.

Según fue avanzando la complejidad de los programas, fue necesario implementar soluciones que automatizaran la organización de tareas sin necesidad de un operador. Debido a ello se crearon los monitores residentes: programas que residían en memoria y que gestionaban la ejecución de una cola de trabajos.

Un monitor residente estaba compuesto por un cargador, un Intérprete de comandos y un controlador ("drivers") para el manejo de entrada/salida.

Los avances en el "hardware" crearon el soporte de interrupciones y posteriormente se llevó a cabo un intento de solución más avanzado: solapar la E/S de un trabajo con sus propios cálculos, por lo que se creó el sistema de búfers con el siguiente funcionamiento:


Los problemas surgen si hay muchas más operaciones de cálculo que de E/S (limitado por la CPU) o si por el contrario hay muchas más operaciones de E/S que de cálculo (limitado por la E/S).

Hace aparición el disco magnético con lo que surgen nuevas soluciones a los problemas de rendimiento. Se eliminan las cintas magnéticas para el volcado previo de los datos de dispositivos lentos y se sustituyen por discos (un disco puede simular varias cintas). Debido al solapamiento del cálculo de un trabajo con la E/S de otro trabajo se crean tablas en el disco para diferentes tareas, lo que se conoce como Spool (Simultaneous Peripherial Operation On-Line).

Surge un nuevo avance: el "hardware" con protección de memoria, ofreciendo nuevas soluciones a los problemas de rendimiento:


Con los cambios anteriores el monitor residente debe abordar nuevas tareas, naciendo los Sistemas Operativos multiprogramados con las siguientes funciones:


Cuando desempeña esas tareas, el monitor residente se transforma en un sistema operativo multiprogramado.

Definición breve: llamadas que ejecutan los programas de aplicación para pedir algún servicio al SO.

Cada SO implementa un conjunto propio de llamadas al sistema. Ese conjunto de llamadas es la interfaz del SO frente a las aplicaciones. Constituyen el lenguaje que deben usar las aplicaciones para comunicarse con el SO. Por ello si cambiamos de SO, y abrimos un programa diseñado para trabajar sobre el anterior, en general el programa no funcionará, a no ser que el nuevo SO tenga la misma interfaz. Para ello:


Las aplicaciones no deben poder usar todas las instrucciones de la CPU. No obstante el Sistema Operativo, tiene que poder utilizar todo el conjunto de instrucciones del CPU. Por ello, una CPU debe tener (al menos) dos modos de operación diferentes:


Una aplicación, normalmente no sabe dónde está situada la rutina de servicio de la llamada. Por lo que si ésta se codifica como una llamada de función, cualquier cambio en el S.O. haría que hubiera que reconstruir la aplicación.

Pero lo más importante es que una llamada de función no cambia el modo de ejecución de la CPU. Con lo que hay que conseguir llamar a la rutina de servicio, sin tener que conocer su ubicación, y hacer que se fuerce un cambio de modo de operación de la CPU en la llamada (y la recuperación del modo anterior en el retorno).

Esto se hace utilizando instrucciones máquina diseñadas específicamente para este cometido, distintas de las que se usan para las llamadas de función.

Las llamadas al sistema no siempre tienen una expresión sencilla en los lenguajes de alto nivel, por ello se crean las bibliotecas de interfaz, que son bibliotecas de funciones que pueden usarse para efectuar llamadas al sistema. Las hay para distintos lenguajes de programación.

La aplicación llama a una función de la biblioteca de interfaz (mediante una llamada normal) y esa función es la que realmente hace la llamada al sistema.

El SO ocupa una posición intermedia entre los programas de aplicación y el "hardware". No se limita a utilizar el "hardware" a petición de las aplicaciones ya que hay situaciones en las que es el "hardware" el que necesita que se ejecute código del SO. En tales situaciones el "hardware" debe poder llamar al sistema, pudiendo deberse estas llamadas a dos condiciones:


En ambos casos, la acción realizada no está ordenada por el programa de aplicación, es decir, no figura en el programa.

Según los dos casos anteriores tenemos las interrupciones y las excepciones:


Una interrupción se trata en todo caso, después de terminar la ejecución de la instrucción en curso.

El tratamiento depende de cuál sea el dispositivo de E/S que ha causado la interrupción, ante la cual debe poder identificar el dispositivo que la ha causado.

La ventaja de este procedimiento es que no se tiene que perder tiempo ejecutando continuamente rutinas para consultar el estado del periférico. El inconveniente es que el dispositivo debe tener los circuitos electrónicos necesarios para acceder al sistema de interrupciones del computador.

El mecanismo de tratamiento de las interrupciones permite al SO utilizar la CPU en servicio de una aplicación, mientras otra permanece a la espera de que concluya una operación en un dispositivo de E/S.

El "hardware" se encarga de avisar al SO cuando el dispositivo de E/S ha terminado y el SO puede intervenir entonces, si es conveniente, para hacer que el programa que estaba esperando por el dispositivo, se continúe ejecutando.

En ciertos intervalos de tiempo puede convenir no aceptar señales de interrupción. Por ello las interrupciones pueden inhibirse por programa (aunque esto ellas no deben poder hacerlo).

Un ejemplo de sincronismo por interrupción es el almacenamiento de caracteres introducidos mediante el teclado. Cuando se introduce un carácter, se codifica en el registro de datos del dispositivo y además se activa un bit del registro de estado quien crea una interrupción en el "hardware". El procesador deja temporalmente la tarea que estaba completando y ejecuta la rutina de atención a la interrupción correspondiente. El teclado almacena el carácter en el vector de memoria intermedia (también llamado "buffer") asociada al teclado y despierta el proceso que había en el estado de espera de la operación de entrada/salida.

Cuando la CPU intenta ejecutar una instrucción incorrectamente construida, la unidad de control lanza una excepción para permitir al SO ejecutar el tratamiento adecuado. Al contrario que en una interrupción, la instrucción en curso es abortada. Las excepciones al igual que las interrupciones deben estar identificadas.

Las instrucciones de un programa pueden estar mal construidas por diversas razones:


El mecanismo de tratamiento de las excepciones es esencial para impedir, junto a los modos de ejecución de la CPU y los mecanismos de protección de la memoria, que las aplicaciones realicen operaciones que no les están permitidas. En cualquier caso, el tratamiento específico de una excepción lo realiza el SO.

Como en el caso de las interrupciones, el "hardware" se limita a dejar el control al SO, y este es el que trata la situación como convenga.

Es bastante frecuente que el tratamiento de una excepción no retorne al programa que se estaba ejecutando cuando se produjo la excepción, sino que el SO aborte la ejecución de ese programa. Este factor depende de la pericia del programador para controlar la excepción adecuadamente.

Un proceso es simplemente, un programa en ejecución que necesita recursos para realizar su tarea: tiempo de CPU, memoria, archivos y dispositivos de E/S. El SO es el responsable de lo siguiente:


La gestión de procesos podría ser similar al trabajo de oficina. Se puede tener una lista de tareas a realizar y a estas fijarles prioridades: alta, media, baja, por ejemplo. Debemos comenzar haciendo las tareas de prioridad alta primero y cuando se terminen seguir con las de prioridad media y después las de baja. Una vez realizada la tarea se tacha.

Esto puede traer un problema que las tareas de baja prioridad pueden que nunca lleguen a ejecutarse y permanezcan en la lista para siempre. Para solucionar esto, se puede asignar alta prioridad a las tareas más antiguas.

La memoria es una gran tabla de palabras o bytes que se referencia cada una mediante una dirección única. Este almacén de datos de rápido acceso es compartido por la CPU y los dispositivos de E/S, es volátil y pierde su contenido ante fallos del sistema. El SO es el responsable de:


Un sistema de almacenamiento secundario es necesario, ya que la memoria principal (almacenamiento primario) es volátil y además muy pequeña para almacenar todos los programas y datos. También es necesario mantener los datos que no convenga mantener en la memoria principal. El SO se encarga de:


Consiste en un sistema de almacenamiento temporal (caché), una interfaz de manejadores de dispositivos y otra para dispositivos concretos. El sistema operativo debe gestionar el almacenamiento temporal de E/S y servir las interrupciones de los dispositivos de E/S.

Los archivos son colecciones de información relacionada, definidas por sus creadores. Estos almacenan programas (en código fuente y objeto) y datos tales como imágenes, textos, información de bases de datos, etc. El SO es responsable de:


Existen diferentes sistemas de archivos, es decir, existen diferentes formas de organizar la información que se almacena en las memorias (normalmente discos) de los ordenadores. Por ejemplo, existen los sistemas de archivos FAT, FAT32, ext3, NTFS, XFS, etc.

Desde el punto de vista del usuario estas diferencias pueden parecer insignificantes a primera vista, sin embargo, existen diferencias muy importantes. Por ejemplo, los sistemas de ficheros FAT32 y NTFS, que se utilizan fundamentalmente en sistemas operativos de Microsoft, tienen una gran diferencia para un usuario que utilice una base de datos con bastante información ya que el tamaño máximo de un fichero con un sistema de archivos FAT32 está limitado a 4 gigabytes, sin embargo, en un sistema NTFS el tamaño es considerablemente mayor.

Mecanismo que controla el acceso de los programas o los usuarios a los recursos del sistema. El SO se encarga de:


Para mantener las comunicaciones con otros sistemas es necesario poder controlar el envío y recepción de información a través de las interfaces de red. También hay que crear y mantener puntos de comunicación que sirvan a las aplicaciones para enviar y recibir información, y crear y mantener conexiones virtuales entre aplicaciones que están ejecutándose localmente y otras que lo hacen remotamente.

Son aplicaciones de utilidad que se suministran con el SO pero no forman parte de él. Ofrecen un entorno útil para el desarrollo y ejecución de programas, siendo algunas de las tareas que realizan:


Como gestor de recursos, el sistema operativo administra:








</doc>
<doc id="2554" url="https://es.wikipedia.org/wiki?curid=2554" title="San Sebastián">
San Sebastián

San Sebastián (en euskera Donostia, y oficialmente Donostia-San Sebastián) es una ciudad y municipio español situado en la costa del golfo de Vizcaya y a 20 kilómetros de la frontera con Francia. La ciudad es la capital de la provincia de Guipúzcoa, en la comunidad autónoma del País Vasco. La población del municipio es de 186665 habitantes (2018), y su área metropolitana alcanza los 436 500 (2010). Es la cabecera de la Eurociudad Vasca Bayona-San Sebastián, una conurbación de más de 620 000 habitantes.

Sus principales actividades económicas son el comercio y el turismo, constituyendo en el pasado uno de los más famosos destinos turísticos de España. Su paisaje, dominado por la bahía de La Concha, así como su desarrollo arquitectónico moderno iniciado en la segunda mitad del siglo XIX, que configuró una ciudad de corte francés y aburguesado, propiciaron el desarrollo de la actividad turística a escala europea. Todo ello, unido a eventos internacionales como el Festival Internacional de Cine de San Sebastián, el Festival de Jazz de San Sebastián, la Quincena Musical o el Festival de Cine de Terror, ha dado proyección exterior a la ciudad, a pesar de sus pequeñas dimensiones. Fue Capital Europea de la Cultura en 2016 junto con Breslavia, Polonia.

San Sebastián tiene diversas denominaciones:


El escudo de San Sebastián muestra, en campo de azur, sobre ondas de azur y plata, un bergantín de oro, de tres palos, habillado de plata y acompañado de las letras SS, de plata, una en cada cantón. Bordura de plata con la leyenda "Ganadas por fidelidad, nobleza y lealtad", en letras de sable. Al timbre corona real.

La bandera de la ciudad es blanca con un cantón de color azul, en una proporción de tres partes de largo por dos de ancho. Se corresponde con la contraseña de la Provincia marítima de San Sebastián.

San Sebastián se asienta a orillas del mar Cantábrico, teniendo varias playas (siendo la más conocida la de La Concha, en la bahía homónima) y un pequeño puerto al abrigo del monte Urgull. Posee además otras montañas, tanto promontorios costeros como tierra adentro, estando su cima más alta, Urdaburu (), en un exclave homónimo, si bien la cima no pertenece al término municipal, dándose la máxima altitud del municipio de unos 585 metros en la cara sur de la misma montaña, cerca de la cima. Aunque el relieve es accidentado se encuentran algunas zonas llanas de cierta amplitud en los valles, planicies donde se concentra buena parte del núcleo urbano.

La ciudad tiene tres playas urbanas: Ondarreta, La Concha y la Zurriola, las dos primeras situadas en la bahía de La Concha y la tercera al otro lado del río Urumea. Las tres están englobadas en un mismo Sistema de Gestión Medioambiental, que trata de garantizar un uso sostenible de las mismas.


Además de estas tres playas, también es utilizable la pequeña playa que se forma en la isla de Santa Clara, a la que se puede acceder en barco en los meses de verano, o a nado, pues se encuentra a escasos 500 m de Ondarreta en marea baja.

San Sebastián tiene un clima oceánico de tipo Cfb de acuerdo a la clasificación climática de Köppen y es una de las ciudades más lluviosas de España, con una media anual de unos 1500 mm. Las lluvias son abundantes en todas las estaciones del año, especialmente en otoño, habiendo un mínimo en verano poco destacable. En 2007, San Sebastián fue la ciudad con más lluvia de España, con 1536,1 milímetros, según se desprende de los datos de los que dispone el Instituto Nacional de Estadística, recogidos en su anuario estadístico. Las precipitaciones en forma de nieve son escasas (entre 1 y 3 días al año, aunque hay inviernos como el 2004-05 y en el 2009-10 en los que el número de días fue superior a 10). A su vez, el número de heladas suele variar entre 5 y 10 anuales. A finales de septiembre y principios de octubre suelen darse «mareas vivas», pleamares más altas y bajamares más bajas de lo normal.

Las temperaturas son suaves y templadas (con una media de 15°C), aunque en verano e invierno la gran humedad (en torno a un 70-80 % la mayor parte de los días del año) provoca sensaciones térmicas de mayor calor/frío. Los días en los que sopla el viento del sur (que provoca el efecto foehn) eleva las temperaturas hasta los 20 °C en pleno invierno y hasta los casi 40 °C en verano: la humedad desciende considerablemente (aunque esta situación de altas temperaturas en verano suele durar unos pocos días o incluso unas horas, al interrumpirse con un giro de viento a componente NO, el cual proviene del mar Cantábrico; este fenómeno es la galerna y viene acompañado de un brusco descenso de las temperaturas y en ocasiones de nubes, tormentas o incluso niebla marina).

En situación de invasión de aire frío procedente de Europa (vientos del NE), San Sebastián es una de las primeras ciudades en notar el frío y suele ser una de las capitales costeras españolas más afectadas, dada su proximidad a Francia. Esto se debe a que los vientos no tienen recorrido marítimo y por lo tanto se templan menos que en otras ciudades, por lo que no es raro ver la playa de la Concha cubierta de nieve. Las temperaturas extremas registradas en el observatorio meteorológico de San Sebastián van desde –12,1 °C hasta 38,6 °C.

Estos son los valores medios y extremos de temperaturas y precipitaciones para San Sebastián:

Consta la existencia de asentamientos romanos (de alrededor de los años 50-200 d.C.) en la actual Parte Vieja de la ciudad, según excavaciones realizadas en el convento de Santa Teresa, en las faldas del Monte Urgull. En el mismo lugar se han constatado restos ya desde del siglo X, anteriores, por tanto, a la fundación de la villa y a las primeras menciones escritas.

Si bien se desconoce de manera exacta su fundación, el primer dato lo aporta un documento —considerado falso por la mayoría de los historiadores— del año 1014 de Sancho el Mayor de Navarra, según el cual el monasterio de San Sebastián se pone en manos del abad de Leyre y obispo de Pamplona. Dicho documento será confirmado, en 1101, por el rey Pedro Ramírez (Pedro I de Aragón, rey de Navarra y Aragón). Las primeras noticias escritas de San Sebastián hacen referencia a un monasterio, situado en el barrio que aún hoy se denomina San Sebastián El Antiguo. A aquel lugar se le conoció primitivamente, según algunos historiadores, como Izurum. El término español San Sebastián y la palabra vasca Donostia hacen referencia etimológicamente a dicho santo; en el caso del euskera, de la evolución de la palabra "Donesebastian", de "Done" (del latín, Domine) + Sebastian.

En los siglos XI y XII, el monasterio de San Sebastián El Antiguo, al mismo tiempo que centro espiritual, lo era de la naciente vida social y administrativa de la población de esta zona, que, con el tiempo, de no ser por diversos avatares que tendrán lugar posteriormente, habría cristalizado en un municipio.

San Sebastián fue fundada hacia 1180 por Sancho el Sabio, rey de Navarra, para ser puerto marítimo de Navarra, e inicialmente cumplió su misión como tal. Guipúzcoa a partir del año 1200 rindió vasallaje al rey castellano Alfonso VIII, enemigo de Sancho el Fuerte. Tradicionalmente, se ha tendido a creer que ese cambio de un reino a otro se dio a través de una negociación o pacto. Sin embargo, a tenor de la relectura de fuentes históricas conocidas, parece que San Sebastián pasó a Castilla mediante conquista militar. En cualquier caso, los comerciantes de San Sebastián se acostumbraron rápidamente al cambio, puesto que pasó de ser el puerto de un pequeño Estado sin posibilidades de expansión territorial (Navarra), a servir de salida al mar de una monarquía, la castellana, mucho mayor, más rica y en plena expansión.

Los Reyes de Castilla contaron en 1248 por primera vez con fuerzas navales de San Sebastián, que tomaron parte en inutilizar la escuadra de moros y el puente de Triana, cuyo resultado fue la rendición de la ciudad de Sevilla.

Alfonso VIII juró los fueros e inició la larga serie de privilegios otorgados a San Sebastián, tendentes unos a mantener vivo el tráfico navarro y otros a conservar una situación privilegiada de los comerciantes donostiarras en el mercado español. Esta prosperidad es la que la hizo resurgir de los múltiples incendios que padeció a partir de 1266, llegando a arder por completo seis veces en dos siglos y cuarto.

La guerra de los Cien Años, las guerras de bandos y la evolución de Navarra en dirección francesa por motivos dinásticos trajeron para San Sebastián, en la segunda mitad del siglo XIV, una consecuencia grave: el desplazamiento de las principales líneas de tráfico hacia Bilbao, sustituyendo a San Sebastián como centro de gravedad del tráfico comercial. En enero de 1489 un incendio redujo a cenizas la villa. Este desgraciado acontecimiento tuvo como medida la construcción en piedra de la villa. Este incendio sería el último de la época medieval de San Sebastián.

A partir del último cuarto del siglo XV, San Sebastián pasó de ser un emporio mercantil gracias su situación estratégica, a ser plaza militar y su puerto principal, Pasajes, de ser esencialmente comercial a cumplir las funciones de base naval.

Tras la catástrofe de 1489, más que de una reconstrucción de la villa hay que hablar de una nueva forma de vida de la colectividad donostiarra. A partir del último cuarto del siglo XV, San Sebastián pasará de ser un emporio mercantil, por su situación estratégica, a ser plaza militar; y su puerto principal, Pasajes, pasará de ser esencialmente comercial, a cumplir las funciones de base naval de la Escuadra Cantábrica, fuerza marítima que mantendrá durante siglos (hasta el XIX) la lucha contra las escuadras francesa, holandesa y británica.

Este nuevo papel de San Sebastián como fortaleza, encargada de frenar las acometidas de los franceses, dará lugar a que la villa tome nuevos derroteros, por los cuales ganó los títulos de Noble y Leal. En el período entre los Reyes Católicos y Felipe V, trescientos años aproximadamente, la villa sufrió numerosos sitios. Este continuo estado de guerra supuso para San Sebastián un fuerte deterioro de su economía, motivado por los gastos en las fortificaciones, el mantenimiento de la guarnición y la continua caída del comercio marítimo, que, a partir de 1573, se agravó aún más, pues Sevilla adquirió el monopolio de las transacciones con América.

Después de llevar dos siglos cumpliendo heroicamente su misión bélica, Felipe IV le concedió en 1662 el título de Ciudad. Hasta su fundación sólo había pequeñas zonas residenciales en el barrio del Antiguo, en la Parte Vieja y en el valle del Urumea, emprendiendo hasta el siglo XV un lento proceso de crecimiento.
En 1719 San Sebastián fue tomada, por primera vez, por un poderoso ejército francés mandado por el duque de Berwick, quien se encontró una ciudad débil en fortificaciones y una pequeña guarnición con escasez de víveres y munición. La ciudad estuvo ocupada por una guarnición de 2000 soldados franceses hasta el 25 de agosto de 1721 en que fue evacuada por el Tratado de La Haya.

Durante la guerra de la Independencia, San Sebastián fue ocupada en 1808 por las tropas napoleónicas. Nombrado José I (José Bonaparte) soberano de España, entró el 9 de junio en San Sebastián y recorrió la calle Narrica, en la que permanecieron todas las ventanas cerradas. En junio de 1813, los aliados (las tropas anglo-portuguesas, bajo el mando directo de "sir" Thomas Graham y teniendo por generalísimo al duque de Wellington, con un fuerte contingente de tropas y armas), sitiaron la ciudad. Después de varios días de intenso bombardeo y un primer asalto fallido, el 31 de agosto tuvo lugar el asalto definitivo, realizado a través de la brecha abierta en las murallas, lo que obligó a las tropas francesas a replegarse hacia el Castillo, donde capitularon el 8 de septiembre.

El saqueo de las tropas anglo-portuguesas causó un gran incendio, del que solo se salvaron treinta y cinco casas, que servían de alojamiento para los oficiales británicos y portugueses, situadas en la misma calle, que hoy en día lleva el nombre de 31 de agosto en honor a ser la única calle que se salvó del incendio. Las tropas también iniciaron el ataque al Castillo, así como las edificaciones situadas al norte de la calle de la Trinidad (iglesias de Santa María y de San Vicente y conventos de San Telmo y de Santa Teresa).

Tras la guerra, los vecinos más representativos se reunieron en las afueras, en Zubieta, y decidieron reconstruir la ciudad.

En él año 1823, durante la invasión conocida como de Los Cien Mil Hijos de San Luis a pesar de la mala situación de sus defensas, aún no reconstruidas en su totalidad, la ciudad optó por la resistencia frente al ejército absolutista francés. Este, en vez de un sitio formal optó por un bloqueo por tierra y mar que duró desde 9 de abril hasta el 27 de septiembre, cuando la ciudad capituló.

La división del reino en cincuenta y dos provincias establece la capitalidad de Guipúzcoa en San Sebastián; hasta entonces esta se había turnado entre San Sebastián, Tolosa, Azpeitia y Azcoitia, en función de dónde se realizaban las reuniones de Juntas y residiera el corregidor (representante del rey en la provincia). Tras un nuevo traslado a Tolosa (1844), en 1854 se declara San Sebastián capital de la provincia. Se decide el retroceso de las aduanas al Ebro y el cierre de San Sebastián como puerto habilitado para el comercio con América.

En la provincia se formaron dos bandos, carlistas y liberales, estos últimos partidarios de la Constitución. Ambos defendían los fueros, pero de diferente manera. San Sebastián optó por el liberalismo frente a la mayor parte de la Guipúzcoa rural.

En 1863, y tras un intenso debate, se derribaron las murallas, que limitaban el desarrollo de la ciudad. El 4 de mayo, a los acordes de una marcha expresamente realizada para tal acontecimiento, se procedió a quitar la primera piedra que, hecha pedazos, se repartió entre los invitados de primera fila.

San Sebastián cambió de orientación: terminada su etapa como fortaleza, pasó a cumplir la función de capital de la provincia, comenzando su expansión reflejada en el plan de Antonio Cortázar para la nueva ciudad.

A la muerte del rey Alfonso XII de España, en 1885, su viuda, la Reina Regente María Cristina, traslada todos los veranos la corte a San Sebastián, residiendo en el Palacio de Miramar. El Ayuntamiento de San Sebastián, en reconocimiento a la gran labor en favor de la ciudad, la nombró alcaldesa honoraria. Más adelante, ya en pleno desarrollo del Ensanche Cortázar, que dotó a la ciudad de su actual atractivo arquitectónico, la construcción del Casino en 1887 aumentó el número de veraneantes.

De esta etapa son todos los edificios reseñables de la ciudad (aparte de los presentes en la Parte Vieja, los más antiguos), como la Catedral del Buen Pastor de San Sebastián, la Escuela de Artes y Oficios (actual sede de Correos) y el Instituto Peñaflorida (luego ocupado por la Escuela de Ingenieros Industriales y hoy en día por el Centro Cultural Koldo Mitxelena), el Palacio de Miramar, el Teatro Victoria Eugenia, el Hotel María Cristina, las villas del Paseo de Francia o la estación del Norte, así como el resto de edificios del "Área Romántica", todos ellos con un marcado estilo francés que hizo acreedora a San Sebastián del sobrenombre de "Pequeña París" o "París del Sur".

En 1914, y con el inicio de la I Guerra Mundial, San Sebastián se convirtió en la ciudad más cosmopolita de Europa. En su Casino se dieron cita todos los personajes de la vida europea, Mata Hari, León Trotsky, Maurice Ravel, Romanones, Pastora Imperio, el torero de fama, el banquero ostentoso...; fueron los tiempos de la "Belle Époque" donostiarra, y en San Sebastián actuaron la compañía francesa de opereta, los ballets rusos, cantantes de ópera y muchos otros artistas famosos.

En 1930, la ciudad acogió la reunión de políticos republicanos que se dio en llamar Pacto de San Sebastián, que tuvo una gran trascendencia en el posterior advenimiento de la II República el 14 de abril de 1931; de hecho, el primer gobierno republicano estuvo formado, en gran medida, por el núcleo de políticos participantes en el «pacto». La elección de la capital donostiarra se debió, por una parte, a la proximidad de la ciudad con la República Francesa y al hecho de que San Sebastián fuera la capital de verano de la Corte. Fernando Sasiaín, anfitrión del Pacto, fue el alcalde de San Sebastián durante la República.

Al comenzar la Guerra Civil, el nacionalista vasco Telesforo Monzón se hizo cargo de la Comisión de Orden Público, creada por la Junta de Defensa de Guipúzcoa, en la que se reunían nacionalistas vascos, republicanos, comunistas y socialistas. Constituido el Gobierno de Euskadi, el 7 de octubre de 1936, Telesforo Monzón ocupó asimismo el Ministerio de la Gobernación.

Al poco de estallar la Guerra Civil Española, San Sebastián cayó en manos de los golpistas el 13 de septiembre de 1936. La dictadura mantuvo a San Sebastián en el papel de Ciudad Capital de Veraneo. Franco residió durante los meses de agosto desde 1940 hasta 1975 en el palacio de Ayete, que, comprado por el ayuntamiento, fue ofrecido al general. Durante ese período se celebraron en dicho lugar los Consejos de Ministros.

En 1946, durante el mandato de Rafael Lataillade Aldecoa, se llevó a cabo la recuperación del Gran Casino para reconvertirlo en Casa Consistorial.

En 1953, y a iniciativa de un grupo de comerciantes de la ciudad, nació el Festival Internacional de Cine de San Sebastián, con el doble objetivo de alargar el veraneo en la capital donostiarra y de devolver a San Sebastián la actividad cultural y el "glamour" perdidos desde la Guerra Civil. El éxito de la primera edición llevó a la dictadura a hacerse cargo del evento, que progresivamente fue ganando peso y prestigio hasta convertirse en uno de los eventos culturales más importantes y con mayor proyección exterior de España, y en uno de los mejores festivales de cine del mundo, escenario de algunos estrenos cinematográficos históricos y punto de encuentro de buena parte de las más importantes estrellas del séptimo arte.

En 1955 se inició el segundo y más importante proceso de ensanche de la ciudad, en lo que se denominó "Ensanche de Amara", dando lugar a un barrio del mismo nombre (que aludía a las marismas que había en dicho terreno antes de su construcción). Uno de los primeros pasos en la construcción del ensanche fue el traslado de la Escuela de Artes y Oficios y Comercio, situada en el centro, a unas escuelas de nueva construcción, así como el del Instituto Peñaflorida, pasando a denominarse Instituto Usandizaga en su sección femenina. Puede considerarse que el proceso de consolidación del barrio de Amara finalizó en 1993, con la construcción del Estadio de Anoeta y la renovación total de la ciudad deportiva de la ciudad (situada en Amara).

Tras ambos ensanches la ciudad consolidó su eje principal, alrededor del cual continúa expandiéndose aunque a un ritmo mucho menor. Hoy las prioridades de la ciudad son la mejora de las infraestructuras (potenciación del aeropuerto, mejores comunicaciones ferroviarias, mejora de las carreteras), la regeneración de los barrios de la periferia, el mantenimiento y potenciamiento del turismo, principal fuente de ingresos, y hasta hace unos años la lucha contra el terrorismo de ETA y la violencia callejera, que castigaron a la ciudad con intensidad. El crecimiento urbanístico pretende combinarse con el cuidado del medio ambiente, la lucha a escala municipal contra el cambio climático y la sostenibilidad. Fruto de los esfuerzos realizados en dicha dirección, San Sebastián fue premiada en 2008 por la Federación Española de Municipios y Provincias como la ciudad más sostenible de España.

A la muerte del dictador Francisco Franco se constituyó, en 1978, una gestora presidida por el socialista Ramón Jáuregui encargada de dirigir las instituciones municipales hasta las primeras elecciones municipales de la democracia, en 1979. En dichos comicios electorales resultó vencedor el PNV y el primer alcalde de la nueva etapa democrática fue Jesús María Alkain. Le sucedió, en 1983, Ramón Labayen, también del PNV, quien a su vez fue sustituido por el nacionalista Xabier Albistur, de Eusko Alkartasuna, en 1987. En el marco de la fuerte reconversión industrial que vivió el País Vasco en la década de 1980 y el clima de tensión interno, algunos informes de la época situaron a San Sebastián como la ciudad con mayor proporción de adictos a la droga del mundo. El socialista Odón Elorza, del Partido Socialista de Euskadi, alcanzó la alcaldía en 1991 a pesar de ser el candidato de la tercera fuerza más votada, gracias al apoyo del PNV y el PP. El 23 de enero de 1995, en vísperas de las elecciones municipales de mayo, la banda terrorista ETA asesinó al teniente de alcalde, Gregorio Ordóñez, candidato del Partido Popular. Ordóñez había mejorado progresivamente sus resultados electorales en el País Vasco. Tras su asesinato, el candidato del Partido Socialista, Elorza, revalidó su cargo al ser el candidato más votado y ostentó la alcaldía de la ciudad ininterrumpidamente desde entonces hasta su derrota en las elecciones municipales del 22 de mayo de 2011.

En 1991 Odón Elorza (PSE-EE) se convirtió en alcalde, con el apoyo del PP vasco y de EAJ-PNV. Con diversos pactos (con EAJ-PNV y EA en 1995; con PP en 1999) se mantuvo al frente del consistorio hasta las elecciones locales de 2011. En 2007, formó gobierno con el grupo municipal de Ezker Batua-Berdeak/Aralar.

En 2011 el candidato de Bildu, Juan Carlos Izagirre, fue elegido alcalde con los votos de los 8 concejales de su coalición; el PSE y el PP votaron por el candidato socialista, Ernesto Gasco (en total 13 votos) y el PNV votó por su candidato Eneko Goia (6 votos). Al no tener ningún candidato mayoría absoluta (14), fue elegido alcalde el candidato de la lista más votada por los ciudadanos. Por barrios, el PSE-EE fue la fuerza más votada en Bidebieta, Alza y Loyola; el PP en Ayete, Centro y Amara, y EAJ-PNV en Ibaeta y Antiguo. La coalición Bildu fue la fuerza más votada en la Parte Vieja, Añorga, Igueldo, Inchaurrondo, Eguía, Gros, Ulía y Martutene.

En 2015 el candidato del PNV Eneko Goia fue elegido alcalde con los votos de su partido y del PSE-EE.

La población de San Sebastián creció de manera progresiva a lo largo del siglo XX. Entre 1900 y 1930 el crecimiento fue regular, pasando a duplicarse en los apenas 35 años que separan 1930 de 1965. Este repunte en el crecimiento demográfico se vio atenuado por un menor crecimiento a partir de la década de los años 70, llegando a reducirse la población por primera vez en el siglo a finales de los años 80, como consecuencia de la caída generalizada de la natalidad en todo el país.
El crecimiento actual de la población es lento, si bien el fenómeno de la inmigración, aún incipiente en la ciudad (los inmigrantes, a 2006, llegan al 5 % de los empadronados, según la Sociedad de Fomento del Ayuntamiento de San Sebastián), puede incidir en un repunte del crecimiento demográfico. Según los últimos datos, a 1 de enero de 2009, la población total es de 185 357 habitantes, de los cuales 97 192 son mujeres (53 %) y 86 116 hombres (47 %).

El 59,86 % de la población de Guipúzcoa (sin contar Hendaya, por no estar en Guipúzcoa) se concentra en su área metropolitana, que cuenta con 436 500 habitantes.

Desde 2003, el Ayuntamiento de San Sebastián divide la ciudad oficialmente en 17 barrios:

















Otros barrios tradicionalmente identificados por los donostiarras son considerados oficialmente por el ayuntamiento como parte del "Centro" de la ciudad.




San Sebastián posee tres enclaves:

Además de dichos exclaves, el Ayuntamiento de San Sebastián posee la finca de Articuza, situada en territorio navarro, dentro del término municipal de Goizueta. En él hay un embalse (es el punto más lluvioso de la península ibérica) y tiene un gran valor ecológico. Su superficie es de 37 km² (equivalente a más de la mitad del término municipal de San Sebastián).

A pesar de ciertas incursiones en el mundo de la banca en la segunda mitad del siglo XIX, con la creación del Banco de San Sebastián (que posteriormente se integraría en el Banco Hispano-Americano) o el Banco Guipuzcoano, la ciudad no destacará por su actividad bancaria, sino que lo hará en el sector del turismo. La elección de la ciudad como lugar de descanso y veraneo por parte de la Casa Real española fue la catalizadora del desarrollo de la actividad turística y de su consiguiente configuración arquitectónica afrancesada a partir del derribo de las murallas que limitaban la expansión de la ciudad. Algunos organismos fueron creados ya a comienzos del siglo XX para atraer al turismo, entre los que destacan la Sociedad de Fomento de San Sebastián, creada por iniciativa privada para la construcción de un hotel de lujo (el Hotel María Cristina) y de un teatro (el Teatro Victoria Eugenia). Aún hoy el turismo sigue siendo la principal actividad económica de San Sebastián, que sigue la misma estrategia de atracción de los turistas mediante reclamos como los festivales de verano.

También es importante el sector del comercio, una constante a lo largo de la historia de la ciudad. La actividad comercial es intensa en el Centro, sobre todo en la Avenida de la Libertad, con una gran concentración de entidades bancarias y comercios de importancia. Los comercios familiares del centro están siendo relegados, progresivamente, por grandes multinacionales, algunas de las cuales poseen varios locales en la ciudad. La proximidad con Francia atrae a numerosos visitantes, que llenan los comercios y las grandes superficies locales. En lo que a las últimas se refiere, en la ciudad existen cuatro, una en el barrio de Amara, dos en el centro y otra cuarta, la más grande, situada entre los barrios de Alza e Inchaurrondo. En cualquier caso, el fenómeno de las grandes superficies fue tardío, ya que no se abrió la primera de ellas hasta 1996.

La industria, por su parte, tiene poca presencia en la ciudad y se concentra en otros puntos de la provincia de Guipúzcoa.

Durante los años 2010 y 2011, y debido a la construcción de nuevas infraestructuras viarias como la GI-40, GI-41 y del Segundo cinturón de San Sebastián, la Diputación Foral de Guipúzcoa se vio obligada a renombrar los accesos y las circunvalaciones del área metropolitana de la ciudad. Los accesos por carretera a la ciudad son los siguientes:

La ciudad consta de las siguientes circunvalaciones:

El carril bici, también llamado "bidegorri" ("camino rojo" en euskera, por ser ese el color del carril), es un medio de transporte que está creciendo mucho en el municipio. La red de carriles bici de San Sebastián supera los 56 kilómetros y está previsto ampliar dicha red hasta alcanzar una extensión suficiente como para poder recorrer en bicicleta toda la ciudad. El proyecto no ha tenido una acogida unánime: junto a quienes se felicitan por ella, hay quienes la critican porque dificulta el aparcamiento en la ciudad y crea en algunos lugares conflictos con los peatones. La red de carriles bici llega hasta los municipios colindantes (Lasarte, Pasaia y Astigarraga), enlazando con sus propias redes ciclistas.

El autobús urbano es el principal medio de transporte público municipal de San Sebastián. De dicho servicio se encarga, desde 1886, la Compañía del Tranvía de San Sebastián, que opera bajo el nombre comercial d·bus. En San Sebastián, el uso del autobús urbano por habitante es el más alto de España, dándose en 2015 un índice de 153 viajes por habitante al año. El servicio ofrece más de 30 líneas que abarcan toda la ciudad y un servicio de taxi bus para los barrios altos o a los que no pueden llegar los autobuses convencionales. También dispone de 9 líneas nocturnas para los viernes y sábados de madrugada, y líneas de refuerzo para los días de partido de fútbol y baloncesto.

Para llegar a San Sebastián desde otras localidades de la provincia, existen numerosas líneas de autobuses interurbanos integradas en Lurraldebus, la sociedad dependiente del Departamento de Movilidad y Ordenación del Territorio de la Diputación Foral de Guipúzcoa, entre las que se encuentran Autobuses Garayar, Autobuses Interurbanos Interbus, Autobuses La Guipuzcoana, EuskoTren, Herribus, Hijos de Antonio Areizaga, Transportes PESA y TSST. Las líneas enlazan la capital con el resto de la provincia y con otras ciudades del País Vasco como Bilbao, Lequeitio o Vitoria.

Las líneas interurbanas, nacionales e internaciones de autobuses tenían como destino la Estación de Atotxa, que se encuentra abajo y junto la Estación del Norte de Renfe.

En la ciudad existen dos redes diferenciadas: la de ancho métrico (dependiente de ETS) y la de ancho ibérico+UIC (dependiente de Adif).

Actualmente prestan servicio dos compañías: EuskoTren y Renfe .

La compañía estatal Renfe tiene la Estación del Norte como estación principal, y además tiene estaciones en Martutene, Loiola, Gros, Ategorrieta, Intxaurrondo y Herrera. De la Estación del Norte parten dos Alvia diarios a Madrid (por Valladolid), además de diversos servicios diarios de Intercity y otros nocturnos, a Madrid (por Pamplona), a Barcelona o a A Coruña. También paran aquí los trenes de Renfe Cercanías, que enlazan distintos puntos de la ciudad con diversos pueblos de Guipúzcoa. Está previsto que a esta estación llegue el futuro Tren de alta velocidad, en 2023. 

Sin embargo, en 2019 la estación será renovada para acomodar los trenes de alta velocidad procedentes de París; que podrán llegar hasta el municipio una vez se termine de renovar la vía a ancho mixto, lo que también permitirá trenes regionales a Bayona o Burdeos.

Además, a partir de 2020 se liberalizará el sector ferroviario para recorridos de larga distancia, por lo que habrá más compañías que operen en la ciudad.

La red de ancho métrico es operada por EuskoTren, que centraliza sus servicios en la Estación de Amara, situada en la Plaza Easo, y que además tiene también las estaciones de Errekalde, Añorga, Lugaritz, Anoeta, Loiola, Intxaurrondo, Herrera y Altza que forman parte de la línea del servicio de transporte metropolitano Metro Donostialdea, popularmente también llamado 'topo' debido a que gran parte de su trazado es subterráneo. Metro Donostialdea supone la modernización y ampliación de la línea E2 de EuskoTren. De la estación de Amara parten trenes en dirección a Lasarte-Oria, Irún y Francia. La última estación del metro es Hendaia, con lo que es habitual tomar este servicio para enlazar con el TGV dirección París.

EuskoTren, el Gobierno Vasco y la corporación local también han anunciado que, antes de 2019, se procederá a la construcción de una estación intermodal entre el Cercanías de San Sebastián operado por RENFE y el metro; así como a prolongar la línea hasta el centro de la ciudad para 2022, con la creación de las nuevas estaciones Centro-La Concha y Benta Berri, así como la renovación y sustitución de la actual estación central de Amara.

También parten desde dicha estación los servicios de cercanías-regionales hasta Éibar y Bilbao, haciendo paradas en muchos de los pueblos de la costa.

En total, tres líneas ofrecen sus servicios en San Sebastián:

El funicular de Igueldo, inaugurado en 1912, enlaza la playa de Ondarreta con el parque de atracciones en la cima del monte Igueldo.

Así mismo, se está construyendo un funicular moderno para subir al barrio de Aiete, que conectará el paseo de Morlans con la rotonda de Melodi. El proyecto también incluye la construcción de un ascensor para conectar el paseo Pío Baroja y el Paseo de Aiete. Está prevista su apertura el próximo invierno (2017-2018).

El municipio cuenta con numerosos ascensores y escaleras y rampas mecánicas en la ciudad, para facilitar el desplazamiento a los vecinos de los barrios altos, que representan al 50% de la población. Se trata de la 4ª ciudad de España con más infraestructura de movilidad vertical (Por detrás de Barcelona, Bilbao y Eibar). El plan de movilidad vertical del ayuntamiento tiene, asimismo, localizadas y ordenadas por prioridad futuras actuaciones para construir hasta 43 nuevos ascensores por la ciudad.



El Aeropuerto de San Sebastián, que se encuentra en la localidad fronteriza de Fuenterrabía, dispone de vuelos diarios a Madrid y Barcelona, además de otros destinos ocasionales. Según AENA el número de pasajeros en 2011 fue de 248 054, hubo 9562 operaciones y se transportaron 31 966 kg de carga. La ausencia de líneas de bajo coste, así como sus reducidas dimensiones y la existencia de dos aeropuertos cercanos, limitan las posibilidades de uso del aeropuerto. La Diputación de Guipúzcoa y el Ayuntamiento de San Sebastián mantienen negociaciones con el Gobierno central para la ampliación de la pista. Actualmente operan Iberia y Vueling.

Los festivales son una de las principales características de la ciudad. Los certámenes de cine y música son numerosos en la ciudad, y algunos de ellos tienen gran prestigio internacional.

San Sebastián es Capital Europea de la Cultura en 2016. Este título le fue concedido oficialmente el 28 de junio de 2011, tras la evaluación del proyecto definitivo por parte del jurado español y europeo encargado de la deliberación. Culminaba así con éxito un proceso de tres años iniciado en 2008 cuando todos los grupos políticos de la ciudad apoyaron la iniciativa del entonces alcalde socialista Odón Elorza de presentar oficialmente la candidatura de la ciudad. En septiembre de 2010 la ciudad pasó la primera fase de selección, y finalmente alcanzó el título en junio de 2011. La capitalidad donostiarra explorará el rol de la cultura para la regeneración de la convivencia y la resolución de los problemas sociales derivados del terrorismo y de la división política y cultural de la sociedad donostiarra y, en general, de la sociedad vasca.


En lo que se ha dado en llamar Donosti Sound se engloba a los exitosos grupos de indie-pop/pop-rock surgidos en la ciudad durante las décadas de los 80 y los 90. Le Mans, La Buena Vida o Family, a los que a menudo se suma a Duncan Dhu (Mikel Erentxun y Diego Vasallo), 21 Japonesas, Álex Ubago o La Oreja de Van Gogh, son algunos de los grupos surgidos en San Sebastián en torno a este estilo musical, inequívocamente marcado por la climatología gris y la fisonomía aburguesada de la ciudad.




Se dice que San Sebastián es la ciudad del mundo con mayor número de estrellas Michelin por metro cuadrado. De hecho, es la única ciudad del mundo, junto con París, que posee tres restaurantes con tres estrellas, la máxima calificación. Así pues, la gastronomía es uno de los principales atractivos turísticos de la ciudad. Como representantes de la Nueva Cocina Vasca, prestigiosos cocineros como Juan Mari Arzak, Pedro Subijana o Martín Berasategui, los tres con las respectivas tres estrellas Michelín ya comentadas, tienen sus restaurantes en San Sebastián. También son muy populares los bares de "pintxos" de la Parte Vieja, obras de arte culinarias en miniatura.

Actualmente el restaurante Mugaritz está considerado como uno de los mejores del mundo. Se encuentra entre Astigarraga y Rentería a escasos 10 km del centro de San Sebastián.

La principal fiesta de la ciudad es la Tamborrada, que se celebra el 20 de enero, día de San Sebastián. La noche del 19 al 20 de enero la Plaza de la Constitución de la Parte Vieja se llena de donostiarras alrededor del tablado en el que se sitúa la tamborrada de la Sociedad Gaztelubide, para realizar la izada de la bandera y comienzo de las fiestas. A lo largo de la mañana del día 20 desfila la Tamborrada Infantil, con más de medio centenar de compañías infantiles de centros escolares de San Sebastián y a lo largo de las 24 horas que dura la fiesta circula una centena de tamborradas de adultos. El día 20 a las doce de la noche, la Unión Artesana arría la bandera en la Plaza de la Constitución como fin de fiesta. Se trata de una fiesta con raíces históricas surgida a finales del XIX. La música que se interpreta, que incluye el himno de la ciudad (Marcha de San Sebastián, cuya letra fue obra de Serafín Baroja, padre del también donostiarra Pío Baroja), fue escrita por Raimundo Sarriegui, originalmente para piano, siendo adaptadas posteriormente para banda).

Entre la citada fiesta de San Sebastián y los carnavales existen distintas fiestas culturales y populares, entre las que cabe destacar la de los Caldereros, que se celebra el sábado más cercano a la Virgen de la Candelaria, que trata de recordar el paso de tribus nómadas por San Sebastián. Otra de estas festividades se celebra un día después de Caldereros, bajo el nombre de Iñudes eta Artzaiak, una fiesta completamente carnavelesca, donde se disfrazan, de alcalde, obispo, panadero, mikelete, cuidadoras, pastores...

En agosto, durante la semana del día 15 (la Asunción), se celebra la Semana Grande donostiarra, la gran fiesta veraniega de la ciudad. Entre las diversas actividades que se organizan, destacan el Concurso Internacional de Fuegos Artificiales y los desfiles de la comparsa de Gigantes y Cabezudos.

A finales de agosto y principio de septiembre se celebran las "Euskal Jaiak "(Fiestas Vascas), que se han celebrado bajo diferentes formas y no sin interrupciones desde la década de 1920. Son una suma de eventos culturales, deportivos y festivos relacionados con la cultura vasca que se programan a lo largo del último mes del verano. El plato fuerte de las mismas es la celebración de la Bandera de La Concha, la principal competición de traineras disputada en el Cantábrico. Esta excede el ámbito estrictamente deportivo, ya que la ciudad se llena de decenas de miles de seguidores de los equipos participantes en un ambiente de fiesta. Las tandas clasificatorias se celebran un jueves y la Bandera propiamente dicha los siguientes dos domingos en dos tandas. En el programa de las Euskal Jaiak se incluye la celebración del 31 de agosto en la que se recuerda el incendio que arrasó la ciudad en 1813, durante la guerra de la Independencia, que dejó en pie una sola calle, la más antigua de la ciudad: la calle 31 de agosto, de la Parte Vieja. Esta efeméride se conmemora con un conmovedor desfile de antorchas que se realiza por dicha calle. Otro punto fuerte es el <nowiki>"Sagardo Eguna"</nowiki> (Día de la Sidra) que suele celebrarse el sábado anterior al segundo domingo de regatas y que a la feria propiamente dicha une un gran número de actividades festivas paralelas.

El 21 de diciembre es el día de Santo Tomás. Durante este día se pueden ver por toda la ciudad puestos de productos artesanales entre los que destacan, por ser la comida típica del día, el talo, la chistorra (o txistorra, en euskera) y la sidra. Los puestos en cuestión suelen estar colocados en lugares como la plaza de Guipúzcoa o la plaza de la Constitución de la ciudad, y suelen estar atendidos por organizaciones o grupos de escolares.

El ocio nocturno de la ciudad se centra en varios puntos: la Parte Vieja, el entorno de la calle de los Reyes Católicos junto a la catedral del Buen Pastor y las discotecas de la bahía de la Concha y de la playa de la Zurriola.

En la Parte Vieja se concentran grupos variados de jóvenes de todas las edades, muchos de los cuales se desplazan a las discotecas de La Concha tras el cierre de los bares de dicha zona. Las tres discotecas situadas en la bahía acogen a todo tipo de público, si bien son consideradas discotecas de público con alto poder adquisitivo. Estas tres discotecas, principalmente las situadas en el edificio del Real Club Náutico de San Sebastián y junto al balneario de La Perla, acogen las fiestas del Festival Internacional de Cine. Otras opciones de ocio nocturno son el café situado en el Teatro Victoria Eugenia, la discoteca a orillas de la playa de la Zurriola, el centro de Ocio Illumbe formado por la plaza de toros y un centro comercial con pubs, restaurantes y discotecas o los mencionados bares del centro de la ciudad en el entorno de la Catedral.

Según datos de la Sociedad de Fomento del Ayuntamiento, casi el 70% de los donostiarras tiene estudios similares o superiores al bachillerato. El 26,6% dispone de algún título universitario o de estudios técnicos.

Al margen de los numerosos colegios privados de carácter religioso y laico y de las escuelas e institutos públicos, dependientes del Gobierno Vasco, la tradición musical de la ciudad pone de relieve el Conservatorio de Música Francisco Escudero, creado en 1879 y que posee una notable biblioteca musical con uno de los fondos históricos más importantes del país.

En lo que a la enseñanza superior universitaria se refiere, en la ciudad tienen presencia cuatro universidades y un conservatorio superior.


La investigación científica se está desarrollando de forma considerable principalmente en tres núcleos. En el campus donostiarra de la Universidad del País Vasco, donde tienen su sede la Facultad de Ciencias Químicas, la Escuela Universitaria Politécnica y cerca del cual se halla el Tecnun, Escuela Técnica Superior de Ingeniería de la Universidad de Navarra, se encuentra el Nanogune, centro de investigación de nanotecnología, y un centro de investigación mixto del Consejo Superior de Investigaciones Científicas (CSIC) y de la Universidad del País Vasco. Asimismo, en el campus se encuentra la sede del Donostia International Physics Center.

Otro núcleo de investigación es el Parque Tecnológico de Miramón, situado cerca del barrio de Ayete en un entorno natural. En él tienen su sede diversas empresas dedicadas a la investigación científica y tecnológica y el Centro de Estudios e Investigaciones Técnicas de Guipúzcoa (CEIT), y está previsto que nuevas empresas se vayan instalando en Miramón en los próximos años. Además de esta vertiente científica, el entorno de Miramón acoge también la sede de las Juntas Generales de Guipúzcoa y próximamente la nueva sede y auditorio del Orfeón Donostiarra.

Por último el Hospital Universitario Donostia con su Instituto de Investigación Biodonostia canaliza gran parte de la investigación biosanitaria de Gipuzkoa.

La ciudad deportiva de San Sebastián, situada en el barrio de Amara, es Anoeta, donde se encuentra el Estadio de Anoeta (que sustituyó, en 1993, al Campo de Fútbol de Atocha), el Velódromo de Anoeta, una piscina olímpica, una piscina de ocio, varias canchas polideportivas polivalentes, un polideportivo, tres frontones, gimnasio, miniestadio, el Palacio de Hielo, un hotel, así como un circuito para la práctica del skate. Se trata de uno de los complejos deportivos más completos de España. Asimismo, existen otros polideportivos repartidos por los respectivos barrios (Antiguo, Ibaeta, Gros, Altza...). El Hipódromo de San Sebastián, también llamado Hipódromo de Lasarte, está situado en el barrio de Zubieta. Se trata del hipódromo más importante de España junto con el Hipódromo de la Zarzuela, en Madrid. Fue creado en 1916.

La Real Sociedad o «La Real», fundada en 1909 como sucesora directa del Club Ciclista de San Sebastián, es el equipo de fútbol de San Sebastián. Fue campeón de la Liga en dos ocasiones, ha ganado otros trofeos como la Copa del Rey y ha estado en varias ocasiones a las puertas de ganar otros campeonatos nacionales e internacionales. Después de unas décadas de fútbol en 1ª división, el club de la ciudad jugó en 2ª división desde la temporada 2007–-2008 hasta que consiguió el ascenso, quedando campeona de 2ª división en la temporada 2009-2010, por lo que desde la temporada 2010-2011 milita de nuevo en 1ª división.El campo de fútbol de La Real es el Estadio de Anoeta, pero los entrenamientos se desarrollan en las Instalaciones de Zubieta que el club posee en el barrio de Zubieta.

De la misma forma, la Sociedad Deportiva Lengokoak Kirol Elkartea es uno de los clubes convenidos con la Real Sociedad que mayor aportación de jugadores realiza a dicho club, entidad que cumplirá en 2013 su quincuagésimo aniversario y que ha estado desde su fundación fielmente ligada al club de referencia de Guipúzcoa. Entre los deportistas de renombre forjados en el Lengokoak podemos destacar a Luis Miguel Arconada y Javier Urruticoechea, llegando a convertirse ambos en figuras internacionales de la portería. David Zurutuza, actual centrocampista blanquiazul, también tuvo su origen en la S. D. Lengokoak K. E.

En el ámbito del baloncesto, el principal club es el San Sebastián GBC. El 23 de mayo de 2006, en el Polideportivo José Antonio Gasca de Anoeta, el Bruesa GBC, equipo profesional del San Sebastián Gipuzkoa Basket Club, aseguró su ascenso de la liga LEB-1 (de la que se proclamó campeón) a la liga ACB, con lo que el baloncesto donostiarra volvió a situar a un equipo local en la principal liga española y segunda más importante del mundo. Ese año, el equipo se mudó a la Plaza de Toros de Illumbe, recinto con una capacidad de 11 000 espectadores, que fue reacondicionada como cancha de baloncesto. Tras consumar su descenso a la liga LEB-1 en abril de 2007, volvió de nuevo a la máxima categoría en junio de 2008. Con el patrocinio de Seguros Lagun Aro el club donostiarra se ha asentado en la Liga ACB, en la que compite en la temporada 2011-2012 por cuarta temporada consecutiva, habiendo disputado por primera vez la Copa del Rey.

El C.D. Fortuna K.E. es un club deportivo fundado en 1911 dedicado a la promoción del deporte de base. Cuenta con numerosas secciones deportivas y organiza la popular carrera pedestre Behobia-San Sebastián. En el 2003 fue galardonado con la medalla al mérito ciudadano.

El Atlético San Sebastián es un club polideportivo fundado en 1958 de gran tradición e implantación social en la ciudad. Cuenta con equipos de hockey hierba masculino y atletismo femenino situados entre la élite del deporte español. En el pasado sus secciones de baloncesto masculino y rugby estuvieron también a primer nivel.

El Bera Bera Rugby Taldea es un club polideportivo fundado en 1986. Destacan sus equipos de rugby masculino: el Pegamo Bera Bera que juega en la Liga Española de rugby y el equipo de balonmano femenino, el Balonmano Bera Bera, que está en la Liga española de balonmano femenino y que ha sido dos veces campeona de la División de Honor de balonmano femenino y cuatro veces de la Copa de la Reina.

El Club Deportivo Egia Balonmano, que tiene su sede en el barrio de Egia, es el club de balonmano con más tradición de la ciudad. Tiene equipos masculinos en varias categorías, desde cadete hasta senior.

El remo donostiarra actualmente tiene como mayor representación la trainera del club Donostiarra, aunque en otras modalidades siguen en total actividad los históricos Ur-Kirolak y Donostia Arraun Lagunak.

El Real Golf Club de San Sebastián, fundado en 1910, tenía sus instalaciones en Lasarte-Oria y en 1969 se trasladaron a Fuenterrabía.


San Sebastián constituye un importante destino turístico tanto en el ámbito español como en el europeo. Son habituales las referencias periodísticas internacionales a las bondades turísticas de la ciudad. De hecho, y a modo de ejemplo, San Sebastián fue elegida por el periódico inglés "The Guardian" como «una de las cinco mejores ciudades de veraneo» del mundo, junto con Berlín, Estocolmo, Nueva York y Ámsterdam.

Uno de los principales atractivos turísticos de la ciudad es la gastronomía. También lo son los festivales de verano (Jazz, Quincena Musical y Cine). La bahía de La Concha, bordeada por su característica barandilla, es el símbolo turístico de San Sebastián. En el centro de la bahía se encuentra "la perla de La Concha", que es la isla de Santa Clara.
Junto a la playa de Ondarreta, y siguiendo hasta el final el paseo que bordea la bahía, se llega al "Peine del Viento", un conjunto escultórico elaborado por Eduardo Chillida y convertido en otro de los símbolos de la ciudad. Avanzando en sentido oeste por el paseo de La Concha se encuentra el singular Palacio de Miramar, construido en estilo inglés por la Casa Real española en 1893 y vendido al Ayuntamiento en los años setenta. Los jardines del palacio, abiertos al público, ofrecen unas espectaculares vistas a la bahía, al igual que el Parque de Atracciones Monte Igueldo, pequeño parque de atracciones de principios del siglo XX desde el que se obtienen unas vistas espléndidas de la bahía. Desde el "Peine del Viento" hasta Mompás, una salida de tierra al mar bajo el monte Ulía en el extremo oriental de la ciudad, recorriendo la bahía de La Concha, el pequeño puerto, el paseo Nuevo, la desembocadura del río y el paseo de la playa de la Zurriola, puede recorrerse un paseo marítimo de unos siete kilómetros de longitud sin cruzar un solo semáforo.

Los paseos por el centro de la ciudad, la denominada Área Romántica de la Belle Époque, cuyas calles principales están totalmente peatonalizadas, y junto al río Urumea, son otro de los puntos fuertes de la oferta turística de San Sebastián. Son reseñables los edificios de la Diputación Foral de Guipúzcoa (inspirado en el edificio de la Ópera de París), la Catedral del Buen Pastor y los edificios de Correos y el Centro Cultural Koldo Mitxelena, situados en la misma plaza, o el Ayuntamiento (antiguo casino). En la parte vieja son destacables el Museo San Telmo, la iglesia de Santa María y la parroquia de San Vicente. Junto a la desembocadura del río se encuentran el Teatro Victoria Eugenia y el Hotel María Cristina, que configuran uno de los conjuntos monumentales más atractivos de la ciudad. Cruzando el río por el puente de María Cristina, el más vistoso de los puentes donostiarras, se encuentran la estación del Norte y las villas de estilo puramente francés situadas al borde del río.

La ciudad de San Sebastián está hermanada con nueve ciudades.




</doc>
<doc id="2555" url="https://es.wikipedia.org/wiki?curid=2555" title="Software">
Software

Se conoce como software o logicial al soporte lógico de un sistema informático, que comprende el conjunto de los componentes lógicos necesarios que hacen posible la realización de tareas específicas, en contraposición a los componentes físicos que son llamados "hardware". La interacción entre el software y el hardware hace operativo un ordenador (u otro dispositivo), es decir, el "software" envía instrucciones que el "hardware" ejecuta, haciendo posible su funcionamiento.

Los componentes lógicos incluyen, entre muchos otros, las aplicaciones informáticas, tales como el procesador de texto, que permite al usuario realizar todas las tareas concernientes a la edición de textos; el llamado "software" de sistema, tal como el sistema operativo, que básicamente permite al resto de los programas funcionar adecuadamente, facilitando también la interacción entre los componentes físicos y el resto de las aplicaciones, y proporcionando una interfaz con el usuario.

El "software", en su gran mayoría, está escrito en lenguajes de programación de alto nivel, ya que son más fáciles y eficientes para que los programadores los usen, porque son más cercanos al Lenguaje natural respecto del lenguaje de máquina. Los lenguajes de alto nivel se traducen a lenguaje de máquina utilizando un compilador o un intérprete, o bien una combinación de ambos. El "software" también puede estar escrito en lenguaje ensamblador, que es de bajo nivel y tiene una alta correspondencia con las instrucciones de lenguaje máquina; se traduce al lenguaje de la máquina utilizando un ensamblador.

El anglicismo "software" es el más ampliamente difundido al referirse a este concepto, especialmente en la jerga técnica; en tanto que el término sinónimo «logicial», derivado del término francés "logiciel", es utilizado mayormente en países y zonas de influencia francesa.

"Software" (pronunciación AFI:) es una palabra proveniente del inglés, que en español no posee una traducción adecuada al contexto, por lo cual se la utiliza asiduamente sin traducir y así fue admitida por la Real Academia Española (RAE). Aunque puede no ser estrictamente lo mismo, suele sustituirse por expresiones tales como "programas (informáticos)" o "aplicaciones (informáticas)" o "soportes lógicos".

"Software" es lo que se denomina "producto" en ingeniería de "software".

Existen varias definiciones similares aceptadas para "software", pero probablemente la más formal sea la siguiente:

Considerando esta definición, el concepto de "software" va más allá de los programas de computación en sus distintos estados: código fuente, binario o ejecutable; también su documentación, los datos a procesar e incluso la información de usuario forman parte del "software": es decir, "abarca todo lo intangible", todo lo «no físico» relacionado.

El término "software" fue usado por primera vez en este sentido por John W. Tukey en 1957. En la ingeniería de "software" y las ciencias de la computación, el "software" es toda la información procesada por los sistemas informáticos: programas y datos.

El concepto de leer diferentes secuencias de instrucciones (programa) desde la memoria de un dispositivo para controlar los cálculos fue introducido por Charles Babbage como parte de su máquina diferencial. La teoría que forma la base de la mayor parte del "software" moderno fue propuesta por Alan Turing en su ensayo de 1936, «Los números computables», con una aplicación al problema de decisión.

Si bien esta distinción es, en cierto modo, arbitraria, y a veces confusa, a los fines prácticos se puede clasificar al "software" en tres tipos:


Se define como «proceso» al conjunto ordenado de pasos a seguir para llegar a la solución de un problema u obtención de un producto, en este caso particular, para lograr un producto "software" que resuelva un problema específico.

El proceso de creación de "software" puede llegar a ser muy complejo, dependiendo de su porte, características y criticidad del mismo. Por ejemplo la creación de un sistema operativo es una tarea que requiere proyecto, gestión, numerosos recursos y todo un equipo disciplinado de trabajo. En el otro extremo, si se trata de un sencillo programa (por ejemplo, la resolución de una ecuación de segundo orden), éste puede ser realizado por un solo programador (incluso aficionado) fácilmente. Es así que normalmente se dividen en tres categorías según su tamaño (líneas de código) o costo: de «pequeño», «mediano» y «gran porte». Existen varias metodologías para estimarlo, una de las más populares es el sistema COCOMO que provee métodos y un "software" (programa) que calcula y provee una aproximación de todos los costos de producción en un «proyecto "software"» (relación horas/hombre, costo monetario, cantidad de líneas fuente de acuerdo a lenguaje usado, etc.).

Considerando los de gran porte, es necesario realizar complejas tareas, tanto técnicas como de gerencia, una fuerte gestión y análisis diversos (entre otras cosas), la complejidad de ello ha llevado a que desarrolle una ingeniería específica para tratar su estudio y realización: es conocida como ingeniería de "Software".

En tanto que en los de mediano porte, pequeños equipos de trabajo (incluso un avezado analista-programador solitario) pueden realizar la tarea. Aunque, siempre en casos de mediano y gran porte (y a veces también en algunos de pequeño porte, según su complejidad), se deben seguir ciertas etapas que son necesarias para la construcción del "software". Tales etapas, si bien deben existir, son flexibles en su forma de aplicación, de acuerdo a la metodología o proceso de desarrollo escogido y utilizado por el equipo de desarrollo o por el analista-programador solitario (si fuere el caso).

Los «procesos de desarrollo de "software"» poseen reglas preestablecidas, y deben ser aplicados en la creación del "software" de mediano y gran porte, ya que en caso contrario lo más seguro es que el proyecto no logre concluir o termine sin cumplir los objetivos previstos, y con variedad de fallos inaceptables (fracasan, en pocas palabras). Entre tales «procesos» los hay ágiles o livianos (ejemplo XP), pesados y lentos (ejemplo RUP), y variantes intermedias. Normalmente se aplican de acuerdo al tipo y porte del "software" a desarrollar, a criterio del líder (si lo hay) del equipo de desarrollo. Algunos de esos procesos son Programación Extrema (en inglés "eXtreme Programming" o XP), Proceso Unificado de Rational (en inglés Rational Unified Process o RUP), Feature Driven Development (FDD), etc.

Cualquiera sea el «proceso» utilizado y aplicado al desarrollo del "software" (RUP, FDD, XP, etc), y casi independientemente de él, siempre se debe aplicar un «modelo de ciclo de vida».

Se estima que, del total de proyectos "software" grandes emprendidos, un 28 % fracasan, un 46 % caen en severas modificaciones que lo retrasan y un 26 % son totalmente exitosos.

Cuando un proyecto fracasa, rara vez es debido a fallas técnicas, la principal causa de fallos y fracasos es la falta de aplicación de una buena metodología o proceso de desarrollo. Entre otras, una fuerte tendencia, desde hace pocas décadas, es mejorar las metodologías o procesos de desarrollo, o crear nuevas y concientizar a los profesionales de la informática a su utilización adecuada. Normalmente los especialistas en el estudio y desarrollo de estas áreas (metodologías) y afines (tales como modelos y hasta la gestión misma de los proyectos) son los ingenieros en "software", es su orientación. Los especialistas en cualquier otra área de desarrollo informático (analista, programador, Lic. en informática, ingeniero en informática, ingeniero de sistemas, etc.) normalmente aplican sus conocimientos especializados pero utilizando modelos, paradigmas y procesos ya elaborados.

Es común para el desarrollo de "software" de mediano porte que los equipos humanos involucrados apliquen «metodologías propias», normalmente un híbrido de los procesos anteriores y a veces con criterios propios.

El proceso de desarrollo puede involucrar numerosas y variadas tareas, desde lo administrativo, pasando por lo técnico y hasta la gestión y el gerenciamiento. Pero, casi rigurosamente, siempre se cumplen ciertas etapas mínimas; las que se pueden resumir como sigue:


En las anteriores etapas pueden variar ligeramente sus nombres, o ser más globales, o contrariamente, ser más refinadas; por ejemplo indicar como una única fase (a los fines documentales e interpretativos) de «análisis y diseño»; o indicar como «implementación» lo que está dicho como «codificación»; pero en rigor, todas existen e incluyen, básicamente, las mismas tareas específicas.

En el apartado 4 del presente artículo se brindan mayores detalles de cada una de las etapas indicadas.

Para cada una de las fases o etapas listadas en el ítem anterior, existen sub-etapas (o tareas).
El modelo de proceso o modelo de ciclo de vida utilizado para el desarrollo, define el orden de las tareas o actividades involucradas, también define la coordinación entre ellas, y su enlace y realimentación. Entre los más conocidos se puede mencionar: modelo en cascada o secuencial, modelo espiral, modelo iterativo incremental. De los antedichos hay a su vez algunas variantes o alternativas, más o menos atractivas según sea la aplicación requerida y sus requisitos.

Este, aunque es más comúnmente conocido como modelo en cascada es también llamado «modelo clásico», «modelo tradicional» o «modelo lineal secuencial».

El modelo en cascada puro «difícilmente se utiliza tal cual», pues esto implicaría un previo y "absoluto" conocimiento de los requisitos, la no volatilidad de los mismos (o rigidez) y etapas subsiguientes libres de errores; ello sólo podría ser aplicable a escasos y pequeños sistemas a desarrollar. En estas circunstancias, el paso de una etapa a otra de las mencionadas sería sin retorno, por ejemplo pasar del diseño a la codificación implicaría un diseño exacto y sin errores ni probable modificación o evolución: «codifique lo diseñado sin errores, no habrá en absoluto variantes futuras». Esto es utópico; ya que intrínsecamente «el "software" es de carácter evolutivo», cambiante y difícilmente libre de errores, tanto durante su desarrollo como durante su vida operativa.

Algún cambio durante la ejecución de una cualquiera de las etapas en este modelo secuencial podría implicar reiniciar desde el principio todo el ciclo completo, lo cual redundaría en altos costos de tiempo y desarrollo. La Figura 2 muestra un posible esquema del modelo en cuestión.

Sin embargo, el modelo cascada en algunas de sus variantes es uno de los actualmente "más utilizados", por su eficacia y simplicidad, más que nada en "software" de pequeño y algunos de mediano porte; pero nunca (o muy rara vez) se lo usa en su "forma pura", como se dijo anteriormente. En lugar de ello, siempre se produce alguna realimentación entre etapas, que no es completamente predecible ni rígida; esto da oportunidad al desarrollo de productos "software" en los cuales hay ciertas incertezas, cambios o evoluciones durante el ciclo de vida. Así por ejemplo, una vez capturados y especificados los requisitos (primera etapa) se puede pasar al diseño del sistema, pero durante esta última fase lo más probable es que se deban realizar ajustes en los requisitos (aunque sean mínimos), ya sea por fallas detectadas, ambigüedades o bien porque los propios requisitos han cambiado o evolucionado; con lo cual se debe retornar a la primera o previa etapa, hacer los reajustes pertinentes y luego continuar nuevamente con el diseño; esto último se conoce como realimentación. Lo normal en el modelo cascada es entonces la aplicación del mismo con sus etapas realimentadas de alguna forma, permitiendo retroceder de una a la anterior (e incluso poder saltar a varias anteriores) si es requerido.

De esta manera se obtiene el «modelo cascada realimentado», que puede ser esquematizado como lo ilustra la Figura 3.

Lo dicho es, a grandes rasgos, la forma y utilización de este modelo, uno de los más usados y populares. El modelo cascada realimentado resulta muy atractivo, hasta ideal, si el proyecto presenta alta rigidez (pocos cambios, previsto no evolutivo), los requisitos son muy claros y están correctamente especificados.

Hay más variantes similares al modelo: refino de etapas (más etapas, menores y más específicas) o incluso mostrar menos etapas de las indicadas, aunque en tal caso la faltante estará dentro de alguna otra. El orden de esas fases indicadas en el ítem previo es el lógico y adecuado, pero adviértase, como se dijo, que normalmente habrá realimentación hacia atrás.

El modelo lineal o en cascada es el paradigma más antiguo y extensamente utilizado, sin embargo las críticas a él (ver desventajas) han puesto en duda su eficacia. Pese a todo, tiene un lugar muy importante en la ingeniería de "software" y continúa siendo el más utilizado; y siempre es mejor que un enfoque al azar.

Desventajas del modelo cascada:


El "software" evoluciona con el tiempo. Los requisitos del usuario y del producto suelen cambiar conforme se desarrolla el mismo. Las fechas de mercado y la competencia hacen que no sea posible esperar a poner en el mercado un producto absolutamente completo, por lo que se aconseja introducir una versión funcional limitada de alguna forma para aliviar las presiones competitivas.

En esas u otras situaciones similares, los desarrolladores necesitan modelos de progreso que estén diseñados para acomodarse a una evolución temporal o progresiva, donde los requisitos centrales son conocidos de antemano, aunque no estén bien definidos a nivel detalle.

En el modelo cascada y cascada realimentado no se tiene demasiado en cuenta la naturaleza evolutiva del "software", se plantea como estático, con requisitos bien conocidos y definidos desde el inicio.

Los evolutivos son modelos iterativos, permiten desarrollar versiones cada vez más completas y complejas, hasta llegar al objetivo final deseado; incluso evolucionar más allá, durante la fase de operación.

Los modelos «iterativo incremental» y «espiral» (entre otros) son dos de los más conocidos y utilizados del tipo evolutivo.

En términos generales, se puede distinguir, en la figura 4, los pasos generales que sigue el proceso de desarrollo de un producto "software". En el modelo de ciclo de vida seleccionado, se identifican claramente dichos pasos. La descripción del sistema es esencial para especificar y confeccionar los distintos incrementos hasta llegar al producto global y final. Las actividades concurrentes (especificación, desarrollo y validación) sintetizan el desarrollo pormenorizado de los incrementos, que se hará posteriormente.

El diagrama de la figura 4 muestra en forma muy esquemática, el funcionamiento de un ciclo iterativo incremental, el cual permite la entrega de versiones parciales a medida que se va construyendo el producto final. Es decir, a medida que cada incremento definido llega a su etapa de operación y mantenimiento. Cada versión emitida incorpora a los anteriores incrementos las funcionalidades y requisitos que fueron analizados como necesarios.

"El incremental es un modelo de tipo evolutivo que está basado en varios ciclos cascada realimentados aplicados repetidamente, con una filosofía iterativa."
En la figura 5 se muestra un refino del diagrama previo, bajo un esquema temporal, para obtener finalmente el esquema del modelo de ciclo de vida iterativo incremental, con sus actividades genéricas asociadas. Aquí se observa claramente cada ciclo cascada que es aplicado para la obtención de un incremento; estos últimos se van integrando para obtener el producto final completo. Cada incremento es un ciclo cascada realimentado, aunque, por simplicidad, en la figura 5 se muestra como secuencial puro.

Se observa que existen actividades de desarrollo (para cada incremento) que son realizadas en paralelo o concurrentemente, así por ejemplo, en la Figura, mientras se realiza el diseño detalle del primer incremento ya se está realizando en análisis del segundo. La Figura 5 es sólo esquemática, un incremento no necesariamente se iniciará durante la fase de diseño del anterior, puede ser posterior (incluso antes), en cualquier tiempo de la etapa previa. Cada incremento concluye con la actividad de «operación y mantenimiento» (indicada como «Operación» en la figura), que es donde se produce la entrega del producto parcial al cliente. El momento de inicio de cada incremento es dependiente de varios factores: tipo de sistema; independencia o dependencia entre incrementos (dos de ellos totalmente independientes pueden ser fácilmente iniciados al mismo tiempo si se dispone de personal suficiente); capacidad y cantidad de profesionales involucrados en el desarrollo; etc.

Bajo este modelo se entrega "software" «por partes funcionales más pequeñas», pero reutilizables, llamadas incrementos. En general cada incremento se construye sobre aquel que ya fue entregado.

Como se muestra en la Figura 5, se aplican secuencias Cascada en forma escalonada, mientras progresa el tiempo calendario. Cada secuencia lineal o Cascada produce un incremento y a menudo el primer incremento es un sistema básico, con muchas funciones suplementarias (conocidas o no) sin entregar.

El cliente utiliza inicialmente ese sistema básico, intertanto, el resultado de su uso y evaluación puede aportar al plan para el desarrollo del/los siguientes incrementos (o versiones). Además también aportan a ese plan otros factores, como lo es la priorización (mayor o menor urgencia en la necesidad de cada incremento en particular) y la dependencia entre incrementos (o independencia).

Luego de cada integración se entrega un producto con mayor funcionalidad que el previo. El proceso se repite hasta alcanzar el "software" final completo.

Siendo iterativo, "con el modelo incremental se entrega un producto parcial pero completamente operacional en cada incremento", y no una parte que sea usada para reajustar los requisitos (como si ocurre en el modelo de construcción de prototipos).

El enfoque incremental resulta muy útil cuando se dispone de baja dotación de personal para el desarrollo; también si no hay disponible fecha límite del proyecto por lo que se entregan versiones incompletas pero que proporcionan al usuario funcionalidad básica (y cada vez mayor). También es un modelo útil a los fines de versiones de evaluación.

Nota: Puede ser considerado y útil, en cualquier momento o incremento incorporar temporalmente el paradigma MCP como complemento, teniendo así una mixtura de modelos que mejoran el esquema y desarrollo general.

Ejemplo:

Como se dijo, el iterativo incremental es un modelo del tipo evolutivo, es decir donde se permiten y esperan probables cambios en los requisitos en tiempo de desarrollo; se admite cierto margen para que el "software" pueda evolucionar. Aplicable cuando los requisitos son medianamente bien conocidos pero no son completamente estáticos y definidos, cuestión esa que si es indispensable para poder utilizar un modelo Cascada.

El modelo es aconsejable para el desarrollo de "software" en el cual se observe, en su etapa inicial de análisis, que posee áreas bastante bien definidas a cubrir, con suficiente independencia como para ser desarrolladas en etapas sucesivas. Tales áreas a cubrir suelen tener distintos grados de apremio por lo cual las mismas se deben priorizar en un análisis previo, es decir, definir cual será la primera, la segunda, y así sucesivamente; esto se conoce como «definición de los incrementos» con base en la priorización. Pueden no existir prioridades funcionales por parte del cliente, pero el desarrollador debe fijarlas de todos modos y con algún criterio, ya que basándose en ellas se desarrollarán y entregarán los distintos incrementos.

El hecho de que existan incrementos funcionales del "software" lleva inmediatamente a pensar en un esquema de desarrollo modular, por tanto este modelo facilita tal paradigma de diseño.

En resumen, un modelo incremental lleva a pensar en un desarrollo modular, con entregas parciales del producto "software" denominados «incrementos» del sistema, que son escogidos según prioridades predefinidas de algún modo. El modelo permite una implementación con refinamientos sucesivos (ampliación o mejora). Con cada incremento se agrega nueva funcionalidad o se cubren nuevos requisitos o bien se mejora la versión previamente implementada del producto "software".

Este modelo brinda cierta flexibilidad para que durante el desarrollo se incluyan cambios en los requisitos por parte del usuario, un cambio de requisitos propuesto y aprobado puede analizarse e implementarse como un nuevo incremento o, eventualmente, podrá constituir una mejora/adecuación de uno ya planeado. Aunque si se produce un cambio de requisitos por parte del cliente que afecte incrementos previos ya terminados (detección/incorporación tardía) "se debe evaluar la factibilidad y realizar un acuerdo con el cliente, ya que puede impactar fuertemente en los costos."

La selección de este modelo permite realizar entregas funcionales tempranas al cliente (lo cual es beneficioso tanto para él como para el grupo de desarrollo). Se priorizan las entregas de aquellos módulos o incrementos en que surja la necesidad operativa de hacerlo, por ejemplo para cargas previas de información, indispensable para los incrementos siguientes.

El modelo iterativo incremental no obliga a especificar con precisión y detalle absolutamente todo lo que el sistema debe hacer, (y cómo), antes de ser construido (como el caso del cascada, con requisitos congelados). Solo se hace en el incremento en desarrollo. Esto torna más manejable el proceso y reduce el impacto en los costos. Esto es así, porque en caso de alterar o rehacer los requisitos, solo afecta una parte del sistema. Aunque, lógicamente, esta situación se agrava si se presenta en estado avanzado, es decir en los últimos incrementos. "En definitiva, el modelo facilita la incorporación de nuevos requisitos durante el desarrollo."

Con un paradigma incremental se reduce el tiempo de desarrollo inicial, ya que se implementa funcionalidad parcial. También provee un impacto ventajoso frente al cliente, que es la entrega temprana de partes operativas del "software".

El modelo proporciona todas las ventajas del modelo en cascada realimentado, reduciendo sus desventajas sólo al ámbito de cada incremento.

El modelo incremental no es recomendable para casos de sistemas de tiempo real, de alto nivel de seguridad, de procesamiento distribuido, o de alto índice de riesgos.

El modelo espiral fue propuesto inicialmente por Barry Boehm. Es un modelo evolutivo que conjuga la naturaleza iterativa del modelo MCP con los aspectos controlados y sistemáticos del Modelo Cascada. Proporciona potencial para desarrollo rápido de versiones incrementales. En el modelo espiral el "software" se construye en una serie de versiones incrementales. En las primeras iteraciones la versión incremental podría ser un modelo en papel o bien un prototipo. En las últimas iteraciones se producen versiones cada vez más completas del sistema diseñado.

El modelo se divide en un número de Actividades de marco de trabajo, llamadas «regiones de tareas». En general existen entre tres y seis regiones de tareas (hay variantes del modelo). En la figura 6 se muestra el esquema de un modelo espiral con seis regiones. En este caso se explica una variante del modelo original de Boehm, expuesto en su tratado de 1988; en 1998 expuso un tratado más reciente.

Las regiones definidas en el modelo de la figura son:


Las actividades enunciadas para el marco de trabajo son generales y se aplican a cualquier proyecto, grande, mediano o pequeño, complejo o no. Las regiones que definen esas actividades comprenden un «conjunto de tareas» del trabajo: ese conjunto sí se debe adaptar a las características del proyecto en particular a emprender. Nótese que lo listado en los ítems de 1 a 6 son conjuntos de tareas, algunas de las ellas normalmente dependen del proyecto o desarrollo en si.

Proyectos pequeños requieren baja cantidad de tareas y también de formalidad. En proyectos mayores o críticos cada región de tareas contiene labores de más alto nivel de formalidad. En cualquier caso se aplican actividades de protección (por ejemplo, gestión de configuración del "software", garantía de calidad, etc.).

Al inicio del ciclo, o proceso evolutivo, el equipo de ingeniería gira alrededor del espiral (metafóricamente hablando) comenzando por el centro (marcado con ๑ en la figura 6) y en el sentido indicado; el primer circuito de la espiral puede producir el desarrollo de una especificación del producto; los pasos siguientes podrían generar un prototipo y progresivamente versiones más sofisticadas del "software".

Cada paso por la región de planificación provoca ajustes en el plan del proyecto; el coste y planificación se realimentan en función de la evaluación del cliente. El gestor de proyectos debe ajustar el número de iteraciones requeridas para completar el desarrollo.

El modelo espiral puede ir adaptándose y aplicarse a lo largo de todo el Ciclo de vida del "software" (en el modelo clásico, o cascada, el proceso termina a la entrega del "software").

Una visión alternativa del modelo puede observarse examinando el «eje de punto de entrada de proyectos». Cada uno de los circulitos (๏) fijados a lo largo del eje representan puntos de arranque de los distintos proyectos (relacionados); a saber:


Cuando la espiral se caracteriza de esta forma, está operativa hasta que el "software" se retira, eventualmente puede estar inactiva (el proceso), pero cuando se produce un cambio el proceso arranca nuevamente en el punto de entrada apropiado (por ejemplo, en «mejora del producto»).

El modelo espiral da un enfoque realista, que evoluciona igual que el "software"; se adapta muy bien para desarrollos a gran escala.

El Espiral utiliza el MCP para reducir riesgos y permite aplicarlo en cualquier etapa de la evolución. Mantiene el enfoque clásico (cascada) pero incorpora un marco de trabajo iterativo que refleja mejor la realidad.

Este modelo "requiere considerar riesgos técnicos" en todas las etapas del proyecto; aplicado adecuadamente debe reducirlos antes de que sean un verdadero problema.

El Modelo evolutivo como el Espiral es particularmente apto para el desarrollo de Sistemas Operativos (complejos); también en sistemas de altos riesgos o críticos (Ej. navegadores y controladores aeronáuticos) y en todos aquellos en que sea necesaria una fuerte gestión del proyecto y sus riesgos, técnicos o de gestión.

Desventajas importantes:


Este modelo no se ha usado tanto, como el Cascada (Incremental) o MCP, por lo que no se tiene bien medida su eficacia, es un paradigma relativamente nuevo y difícil de implementar y controlar.

Una variante interesante del Modelo Espiral previamente visto (Figura 6) es el «Modelo espiral Win-Win» (Barry Boehm). El Modelo Espiral previo (clásico) sugiere la comunicación con el cliente para fijar los requisitos, en que simplemente se pregunta al cliente qué necesita y él proporciona la información para continuar; pero esto es en un contexto ideal que rara vez ocurre. Normalmente cliente y desarrollador entran en una negociación, se negocia coste frente a funcionalidad, rendimiento, calidad, etc.

"«Es así que la obtención de requisitos requiere una negociación, que tiene éxito cuando ambas partes ganan»."

Las mejores negociaciones se fuerzan en obtener «Victoria & Victoria» (Win & Win), es decir que el cliente gane obteniendo el producto que lo satisfaga, y el desarrollador también gane consiguiendo presupuesto y fecha de entrega realista. Evidentemente, este modelo requiere fuertes habilidades de negociación.

El modelo Win-Win define un conjunto de actividades de negociación al principio de cada paso alrededor de la espiral; se definen las siguientes actividades:


<nowiki>*</nowiki> Directivo: Cliente escogido con interés directo en el producto, que puede ser premiado por la organización si tiene éxito o criticado si no.

El modelo Win & Win hace énfasis en la negociación inicial, también introduce 3 hitos en el proceso llamados «puntos de fijación», que ayudan a establecer la completitud de un ciclo de la espiral, y proporcionan hitos de decisión antes de continuar el proyecto de desarrollo del "software".

Al inicio de un desarrollo (no de un proyecto), esta es la primera fase que se realiza, y, según el modelo de proceso adoptado, puede casi terminar para pasar a la próxima etapa (caso de Modelo Cascada Realimentado) o puede hacerse parcialmente para luego retomarla (caso Modelo Iterativo Incremental u otros de carácter evolutivo).

En simple palabras y básicamente, durante esta fase, se adquieren, reúnen y especifican las características funcionales y no funcionales que deberá cumplir el futuro programa o sistema a desarrollar.

Las bondades de las características, tanto del sistema o programa a desarrollar, como de su entorno, parámetros no funcionales y arquitectura dependen enormemente de lo bien lograda que esté esta etapa. Esta es, probablemente, la de mayor importancia y una de las fases más difíciles de lograr certeramente, pues no es automatizable, no es muy técnica y depende en gran medida de la habilidad y experiencia del analista que la realice.

Involucra fuertemente al usuario o cliente del sistema, por tanto tiene matices muy subjetivos y es difícil de modelar con certeza o aplicar una técnica que sea «la más cercana a la adecuada» (de hecho no existe «la estrictamente adecuada»). Si bien se han ideado varias metodologías, incluso "software" de apoyo, para captura, elicitación y registro de requisitos, no existe una forma infalible o absolutamente confiable, y deben aplicarse conjuntamente buenos criterios y mucho sentido común por parte del o los analistas encargados de la tarea; es fundamental también lograr una fluida y adecuada comunicación y comprensión con el usuario final o cliente del sistema.

El artefacto más importante resultado de la culminación de esta etapa es lo que se conoce como especificación de requisitos "software" o simplemente documento ERS.

Como se dijo, la habilidad del analista para interactuar con el cliente es fundamental; lo común es que el cliente tenga un objetivo general o problema que resolver, no conoce en absoluto el área (informática), ni su jerga, ni siquiera sabe con precisión qué debería hacer el producto "software" (qué y cuantas funciones) ni, mucho menos, cómo debe operar. En otros casos menos frecuentes, el cliente «piensa» que sabe precisamente lo que el "software" tiene que hacer, y generalmente acierta muy parcialmente, pero su empecinamiento entorpece la tarea de elicitación. El analista debe tener la capacidad para lidiar con este tipo de problemas, que incluyen relaciones humanas; tiene que saber ponerse al nivel del usuario para permitir una adecuada comunicación y comprensión.

Escasas son las situaciones en que el cliente sabe con certeza e incluso con completitud lo que requiere de su futuro sistema, este es el caso más sencillo para el analista.

Las tareas relativas a captura, elicitación, modelado y registro de requisitos, además de ser sumamente importante, puede llegar a ser dificultosa de lograr acertadamente y llevar bastante tiempo relativo al proceso total del desarrollo; al proceso y metodologías para llevar a cabo este conjunto de actividades normalmente se las asume parte propia de la ingeniería de "software", pero dada la antedicha complejidad, actualmente se habla de una ingeniería de requisitos, aunque ella aún no existe formalmente.

Hay grupos de estudio e investigación, en todo el mundo, que están exclusivamente abocados a idear modelos, técnicas y procesos para intentar lograr la correcta captura, análisis y registro de requisitos. Estos grupos son los que normalmente hablan de la ingeniería de requisitos; es decir se plantea esta como un área o disciplina pero no como una carrera universitaria en sí misma.

Algunos requisitos no necesitan la presencia del cliente, para ser capturados o analizados; en ciertos casos los puede proponer el mismo analista o, incluso, adoptar unilateralmente decisiones que considera adecuadas (tanto en requisitos funcionales como no funcionales). Por citar ejemplos probables: Algunos requisitos sobre la arquitectura del sistema, requisitos no funcionales tales como los relativos al rendimiento, nivel de soporte a errores operativos, plataformas de desarrollo, relaciones internas o ligas entre la información (entre registros o tablas de datos) a almacenar en caso de bases o bancos de datos, etc. Algunos funcionales tales como opciones secundarias o de soporte necesarias para una mejor o más sencilla operatividad; etc.

La obtención de especificaciones a partir del cliente (u otros actores intervinientes) es un proceso humano muy interactivo e iterativo; normalmente a medida que se captura la información, se la analiza y realimenta con el cliente, refinándola, puliéndola y corrigiendo si es necesario; cualquiera sea el método de ERS utilizado. EL analista siempre debe llegar a conocer la temática y el problema que resolver, dominarlo, hasta cierto punto, hasta el ámbito que el futuro sistema a desarrollar lo abarque. Por ello el analista debe tener alta capacidad para comprender problemas de muy diversas áreas o disciplinas de trabajo (que no son específicamente suyas); así por ejemplo, si el sistema a desarrollar será para gestionar información de una aseguradora y sus sucursales remotas, el analista se debe compenetrar en cómo ella trabaja y maneja su información, desde niveles muy bajos e incluso llegando hasta los gerenciales. Dada a gran diversidad de campos a cubrir, los analistas suelen ser asistidos por especialistas, es decir gente que conoce profundamente el área para la cual se desarrollará el "software"; evidentemente una única persona (el analista) no puede abarcar tan vasta cantidad de áreas del conocimiento. En empresas grandes de desarrollo de productos "software", es común tener analistas especializados en ciertas áreas de trabajo.

Contrariamente, no es problema del cliente, es decir él no tiene por qué saber nada de "software", ni de diseños, ni otras cosas relacionadas; sólo se debe limitar a aportar objetivos, datos e información (de mano propia o de sus registros, equipos, empleados, etc) al analista, y guiado por él, para que, en primera instancia, defina el «Universo de Discurso», y con posterior trabajo logre confeccionar el adecuado documento ERS.

Es bien conocida la presión que sufren los desarrolladores de sistemas informáticos para comprender y rescatar las necesidades de los clientes/usuarios. Cuanto más complejo es el contexto del problema más difícil es lograrlo, a veces se fuerza a los desarrolladores a tener que convertirse en casi expertos de los dominios que analizan.

Cuando esto no sucede es muy probable que se genere un conjunto de requisitos erróneos o incompletos y por lo tanto un producto de "software" con alto grado de desaprobación por parte de los clientes/usuarios y un altísimo costo de reingeniería y mantenimiento. "Todo aquello que no se detecte, o resulte mal entendido en la etapa inicial provocará un fuerte impacto negativo en los requisitos, propagando esta corriente degradante a lo largo de todo el proceso de desarrollo e incrementando su perjuicio cuanto más tardía sea su detección" (Bell y Thayer 1976)(Davis 1993).

Siendo que la captura, elicitación y especificación de requisitos, es una parte crucial en el proceso de desarrollo de "software", ya que de esta etapa depende el logro de los objetivos finales previstos, se han ideado modelos y diversas metodologías de trabajo para estos fines. También existen herramientas "software" que apoyan las tareas relativas realizadas por el ingeniero en requisitos.

El estándar IEEE 830-1998 brinda una normalización de las «Prácticas recomendadas para la especificación de requisitos "software"».

A medida que se obtienen los requisitos, normalmente se los va analizando, el resultado de este análisis, con o sin el cliente, se plasma en un documento, conocido como ERS o Especificación de requisitos "software", cuya estructura puede venir definida por varios estándares, tales como CMMI.

Un primer paso para realizar el relevamiento de información es el conocimiento y definición acertada lo que se conoce como «Universo de Discurso» del problema, que se define y entiende por:

Universo de Discurso (UdeD): es el contexto general en el cual el "software" deberá ser desarrollado y deberá operar. El UdeD incluye todas las fuentes de información y todas las personas relacionadas con el "software". Esas personas son conocidas también como actores de ese universo. El UdeD es la realidad circunstanciada por el conjunto de objetivos definidos por quienes demandaron el "software".

A partir de la extracción y análisis de información en su ámbito se obtienen todas las especificaciones necesarias y tipos de requisitos para el futuro producto "software".

El objetivo de la ingeniería de requisitos (IR) es sistematizar el proceso de definición de requisitos permitiendo elicitar, modelar y analizar el problema, generando un compromiso entre los ingenieros de requisitos y los clientes/usuarios, ya que ambos participan en la generación y definición de los requisitos del sistema. La IR aporta un conjunto de métodos, técnicas y herramientas que asisten a los ingenieros de requisitos (analistas) para obtener requisitos lo más seguros, veraces, completos y oportunos posibles, permitiendo básicamente:


Si bien existen diversas formas, modelos y metodologías para elicitar, definir y documentar requisitos, no se puede decir que alguna de ellas sea mejor o peor que la otra, suelen tener muchísimo en común, y todas cumplen el mismo objetivo. Sin embargo, lo que si se puede decir sin dudas es
que es indispensable utilizar alguna de ellas para documentar las especificaciones del futuro producto "software". Así por ejemplo, hay un grupo de investigación argentino que desde hace varios años ha propuesto y estudia el uso del LEL (Léxico Extendido del Lenguaje) y Escenarios como metodología, aquí se presenta una de las tantas referencias y bibliografía sobre ello. Otra forma, más ortodoxa, de capturar y documentar requisitos se puede obtener en detalle, por ejemplo, en el trabajo de la Universidad de Sevilla sobre «Metodología para el Análisis de Requisitos de Sistemas Software».

En la Figura 7 se muestra un esquema, más o menos riguroso, aunque no detallado, de los pasos y tareas a seguir para realizar la captura, análisis y especificación de requisitos "software". También allí se observa qué artefacto o documento se obtiene en cada etapa del proceso. En el diagrama no se explicita metodología o modelo a utilizar, sencillamente se pautan las tareas que deben cumplirse, de alguna manera.

Una posible lista, general y ordenada, de tareas recomendadas para obtener la definición de lo que se debe realizar, los productos a obtener y las técnicas a emplear durante la actividad de elicitación de requisitos, en fase de Especificación de requisitos "software" es:


Algunos principios básicos a tener en cuenta:


Se pueden identificar dos formas de requisitos:


Es decir, ambos son lo mismo, pero con distinto nivel de detalle.

Ejemplo de requisito de usuario: El sistema debe hacer préstamos
Ejemplo de requisito de sistema: Función préstamo: entrada código socio, código ejemplar; salida: fecha devolución; etc.

Se clasifican en tres los tipos de requisitos de sistema:

Los requisitos funcionales describen:


Los requisitos no funcionales son restricciones de los servicios o funciones que ofrece el sistema (ej. cotas de tiempo, proceso de desarrollo, rendimiento, etc.)


Los requisitos del dominio se derivan del dominio de la aplicación y reflejan características de dicho dominio.

Pueden ser funcionales o no funcionales.

Ej. El sistema de biblioteca de la Universidad debe ser capaz de exportar datos mediante el Lenguaje de Intercomunicación de Bibliotecas de España (LIBE).
Ej. El sistema de biblioteca no podrá acceder a bibliotecas con material censurado.

En ingeniería de "software", el diseño es una fase de ciclo de vida del "software". Se basa en la especificación de requisitos producido por el análisis de los requisitos (fase de análisis), el diseño define "cómo" estos requisitos se cumplirán, la estructura que debe darse al sistema de "software" para que se haga realidad.

El diseño sigue siendo una fase separada del la programación o codificación, esta última corresponde a la traducción en un determinado lenguaje de programación de las premisas adoptadas en el diseño.

Las distinciones entre las actividades mencionadas hasta ahora no siempre son claras cómo se quisiera en las teorías clásicas de ingeniería de "software". El diseño, en particular, puede describir el funcionamiento interno de un sistema en diferentes niveles de detalle, cada una de ellos se coloca en una posición intermedia entre el análisis y codificación.

Normalmente se entiende por "diseño de la arquitectura" al diseño de "muy alto nivel", que sólo define la estructura del sistema en términos de la módulos de "software" de que se compone y las relaciones macroscópicas entre ellos. A este nivel de diseño pertenecen fórmulas como cliente-servidor o “tres niveles”, o, más generalmente, las decisiones sobre el uso de la arquitectura de hardware especial que se utilice, el sistema operativo, DBMS, Protocolos de red, etc.

Un nivel intermedio de detalle puede definir la descomposición del sistema en módulos, pero esta vez con una referencia más o menos explícita al modo de descomposición que ofrece el particular lenguaje de programación con el que el desarrollo se va a implementar, por ejemplo, en un diseño realizado con la tecnología de objetos, el proyecto podría describir al sistema en términos de clases y sus interrelaciones.

El diseño detallado, por último, es una descripción del sistema muy cercana a la codificación (por ejemplo, describir no solo las clases en abstracto, sino también sus atributos y los métodos con sus tipos).

Debido a la naturaleza "intangible" del "software", y dependiendo de las herramientas que se utilizan en el proceso, la frontera entre el diseño y la codificación también puede ser virtualmente imposible de identificar. Por ejemplo, algunas herramientas CASE son capaces de generar código a partir de diagramas UML, los que describen gráficamente la estructura de un sistema "software".

Durante esta etapa se realizan las tareas que comúnmente se conocen como programación; que consiste, esencialmente, en llevar a código fuente, en el lenguaje de programación elegido, todo lo diseñado en la fase anterior. Esta tarea la realiza el programador, siguiendo por completo los lineamientos impuestos en el diseño y en consideración siempre a los requisitos funcionales y no funcionales (ERS) especificados en la primera etapa.

Es común pensar que la etapa de programación o codificación (algunos la llaman implementación) es la que insume la mayor parte del trabajo de desarrollo del "software"; sin embargo, esto puede ser relativo (y generalmente aplicable a sistemas de pequeño porte) ya que las etapas previas son cruciales, críticas y pueden llevar bastante más tiempo. Se suele hacer estimaciones de un 30% del tiempo total insumido en la programación, pero esta cifra no es consistente ya que depende en gran medida de las características del sistema, su criticidad y el lenguaje de programación elegido.En tanto menor es el nivel del lenguaje mayor será el tiempo de programación requerido, así por ejemplo se tardaría más tiempo en codificar un algoritmo en lenguaje ensamblador que el mismo programado en lenguaje C.

Mientras se programa la aplicación, sistema, o "software" en general, se realizan también tareas de depuración, esto es la labor de ir liberando al código de los errores factibles de ser hallados en esta fase (de semántica, sintáctica y lógica). Hay una suerte de solapamiento con la fase siguiente, ya que para depurar la lógica es necesario realizar pruebas unitarias, normalmente con datos de prueba; claro es que no todos los errores serán encontrados sólo en la etapa de programación, habrá otros que se encontrarán durante las etapas subsiguientes. La aparición de algún error funcional (mala respuesta a los requisitos) eventualmente puede llevar a retornar a la fase de diseño antes de continuar la codificación.

Durante la fase de programación, el código puede adoptar varios estados, dependiendo de la forma de trabajo y del lenguaje elegido, a saber:




Entre las diversas pruebas que se le efectúan al "software" se pueden distinguir principalmente:


Las pruebas normalmente se efectúan con los llamados datos de prueba, que es un conjunto seleccionado de datos típicos a los que puede verse sometido el sistema, los módulos o los bloques de código. También se escogen: Datos que llevan a condiciones límites al "software" a fin de probar su tolerancia y robustez; datos de utilidad para mediciones de rendimiento; datos que provocan condiciones eventuales o particulares poco comunes y a las que el "software" normalmente no estará sometido pero pueden ocurrir; etc. Los «datos de prueba» no necesariamente son ficticios o «creados», pero normalmente sí lo son los de poca probabilidad de ocurrencia.

Generalmente, existe un fase probatoria final y completa del "software", llamada Beta Test, durante la cual el sistema instalado en condiciones normales de operación y trabajo es probado exhaustivamente a fin de encontrar errores, inestabilidades, respuestas erróneas, etc. que hayan pasado los previos controles. Estas son normalmente realizadas por personal idóneo contratado o afectado específicamente a ello. Los posibles errores encontrados se transmiten a los desarrolladores para su depuración. En el caso de "software" de desarrollo «a pedido», el usuario final (cliente) es el que realiza el Beta Test, teniendo para ello un período de prueba pactado con el desarrollador.

La instalación del "software" es el proceso por el cual los programas desarrollados son transferidos apropiadamente al computador destino, inicializados, y, eventualmente, configurados; todo ello con el propósito de ser ya utilizados por el usuario final. Constituye la etapa final en el desarrollo propiamente dicho del "software". Luego de esta el producto entrará en la fase de funcionamiento y producción, para el que fuera diseñado.

La instalación, dependiendo del sistema desarrollado, puede consistir en una simple copia al disco rígido destino (casos raros actualmente); o bien, más comúnmente, con una de complejidad intermedia en la que los distintos archivos componentes del "software" (ejecutables, bibliotecas, datos propios, etc.) son descomprimidos y copiados a lugares específicos preestablecidos del disco; incluso se crean vínculos con otros productos, además del propio sistema operativo. Este último caso, comúnmente es un proceso bastante automático que es creado y guiado con herramientas "software" específicas (empaquetado y distribución, instaladores).

En productos de mayor complejidad, la segunda alternativa es la utilizada, pero es realizada o guiada por especialistas; puede incluso requerirse la instalación en varios y distintos computadores (instalación distribuida).

También, en "software" de mediana y alta complejidad normalmente es requerido un proceso de configuración y chequeo, por el cual se asignan adecuados parámetros de funcionamiento y se testea la operatividad funcional del producto.

En productos de venta masiva las instalaciones completas, si son relativamente simples, suelen ser realizadas por los propios usuarios finales (tales como sistemas operativos, paquetes de oficina, utilitarios, etc.) con herramientas propias de instalación guiada; incluso la configuración suele ser automática. En productos de diseño específico o «a medida» la instalación queda restringida, normalmente, a personas especialistas involucradas en el desarrollo del "software" en cuestión.

Una vez realizada exitosamente la instalación del "software", el mismo pasa a la fase de producción (operatividad), durante la cual cumple las funciones para las que fue desarrollado, es decir, es finalmente utilizado por el (o los) usuario final, produciendo los resultados esperados.

El mantenimiento de "software" es el proceso de control, mejora y optimización del "software" ya desarrollado e instalado, que también incluye depuración de errores y defectos que puedan haberse filtrado de la fase de pruebas de control y beta test.
Esta fase es la última (antes de iterar, según el modelo empleado) que se aplica al ciclo de vida del desarrollo de "software". La fase de mantenimiento es la que viene después de que el "software" está operativo y en producción.

De un buen diseño y documentación del desarrollo dependerá cómo será la fase de mantenimiento, tanto en costo temporal como monetario. Modificaciones realizadas a un "software" que fue elaborado con una documentación indebida o pobre y mal diseño puede llegar a ser tanto o más costosa que desarrollar el "software" desde el inicio. Por ello, es de fundamental importancia respetar debidamente todas las tareas de las fases del desarrollo y mantener adecuada y completa la documentación.

El período de la fase de mantenimiento es normalmente el mayor en todo el ciclo de vida. Esta fase involucra también actualizaciones y evoluciones del "software"; no necesariamente implica que el sistema tuvo errores. Uno o más cambios en el "software", por ejemplo de adaptación o evolutivos, puede llevar incluso a rever y adaptar desde parte de las primeras fases del desarrollo inicial, alterando todas las demás; dependiendo de cuán profundos sean los cambios.
El modelo cascada común es particularmente costoso en mantenimiento, ya que su rigidez implica que cualquier cambio provoca regreso a fase inicial y fuertes alteraciones en las demás fases del ciclo de vida.

Durante el período de mantenimiento, es común que surjan nuevas revisiones y versiones del producto; que lo liberan más depurado, con mayor y mejor funcionalidad, mejor rendimiento, etc. Varias son las facetas que pueden ser alteradas para provocar cambios deseables, evolutivos, adaptaciones o ampliaciones y mejoras.

Básicamente se tienen los siguientes tipos de cambios:


El "software" es el producto derivado del proceso de desarrollo, según la ingeniería de "software". Este producto es intrínsecamente evolutivo durante su ciclo de vida: en general, evoluciona generando versiones cada vez más completas, complejas, mejoradas, optimizadas en algún aspecto, adecuadas a nuevas plataformas (sean de "hardware" o sistemas operativos), etc.

Cuando un sistema deja de evolucionar, eventualmente cumplirá con su ciclo de vida, entrará en obsolescencia e inevitablemente, tarde o temprano, será reemplazado por un producto nuevo.

El "software" evoluciona sencillamente porque se debe adaptar a los cambios del entorno, sean funcionales (exigencias de usuarios), operativos, de plataforma o arquitectura "hardwar"e.

La dinámica de evolución del "software" es el estudio de los cambios del sistema. La mayor contribución en esta área fue realizada por Meir M. Lehman y , comenzando en los años 70 y 80. Su trabajo continuó en la década de 1990, con Lehman y otros investigadores de relevancia en la realimentación en los procesos de evolución (Lehman, 1996; Lehman et al., 1998; lehman et al., 2001). A partir de esos estudios propusieron un conjunto de leyes (conocidas como leyes de Lehman) respecto de los cambios producidos en los sistemas. Estas leyes (en realidad son hipótesis) son invariantes y ampliamente aplicables.

Lehman y Belady analizaron el crecimiento y la evolución de varios sistemas "software" de gran porte; derivando finalmente, según sus medidas, las siguientes ocho leyes:




</doc>
<doc id="2556" url="https://es.wikipedia.org/wiki?curid=2556" title="Sociología">
Sociología

La sociología es la ciencia social que se encarga del análisis científico de la sociedad humana o población regional. Estudia los fenómenos colectivos producidos por la actividad social de los seres humanos, dentro del contexto histórico-cultural en el que se encuentran inmersos.

En la sociología se utilizan metodologías de investigación interdisciplinarias para el análisis e interpretación, desde diversas perspectivas teóricas, de las causas y significados que motivan la aparición de diversas tendencias de comportamiento social. Mientras algunos sociólogos realizan investigaciones que pueden aplicarse directamente a la política social y el bienestar, otros se centran en refinar la comprensión de los procesos sociales. Abarca desde el nivel de microsociología de la interacción y las organizaciones, hasta el nivel macro de los sistemas y la estructura social.

Los diferentes enfoques tradicionales de la sociología incluyen estratificación social, clase social, movilidad social, religión, secularización, derecho, género y desviación social. Como todas las esferas de la actividad humana se ven afectadas por la interacción entre la estructura social y la agencia individual, la sociología ha ampliado gradualmente su enfoque a otros temas, como ambiente, salud, economía, instituciones penales, Internet, educación y el conocimiento científico, entre otros.

Los orígenes de la sociología están asociados a los nombres de Ibn Jaldún, Karl Marx, Henri de Saint-Simon, Auguste Comte, Herbert Spencer, Émile Durkheim, Georg Simmel, Talcott Parsons, Ferdinand Tönnies, Vilfredo Pareto, Max Weber, Alfred Schütz, Harriet Martineau, Beatrice Webb y Marianne Weber.

Algunos de los sociólogos más destacados del siglo XX han sido Talcott Parsons, Erving Goffman, Walter Benjamin, Herbert Marcuse, Wright Mills, Michel Foucault, Pierre Bourdieu, Niklas Luhmann y Jürgen Habermas. En la actualidad, los análisis y estudios más innovadores de los comportamientos sociales corren a cargo de autores como George Ritzer, Anthony Giddens, Zygmunt Bauman, Ulrich Beck, Alain Touraine, entre otros.

El razonamiento sociológico es preexistente a la fundación de la disciplina. El análisis social tiene su origen en el conocimiento y la filosofía occidental, desarrollados desde la antigua Grecia por filósofos como Platón. El origen de la encuesta, es decir, la obtención de información a partir de una muestra de individuos, se remonta a por lo menos el Libro Domesday en 1086. El antiguo filósofo oriental Confucio escribió sobre la importancia de los roles sociales. Hay pruebas de la sociología temprana en el Islam medieval. Algunos consideran que Ibn Jaldún, un erudito musulmán del norte de África (Túnez), ha sido el primer sociólogo y padre de la sociología. Su Muqaddima fue quizás el primer trabajo para avanzar en el razonamiento científico-social de la cohesión social y el conflicto social.

Durante la época de la Ilustración y después de la Revolución Francesa, lo social y las actividades del hombre ganaron creciente interés. Escritores como Voltaire, Montesquieu, y Giambattista Vico, se interesaron por analizar las instituciones sociales y políticas europeas. Y Lord Kames inició el análisis de las causas del cambio social, y tras él, surgió una corriente conservadora, muy interesada en saber las razones de los cambios y de la estabilidad existentes en la sociedad, liderada por Joseph de Maistre y Edmund Burke, quienes criticaron muchas de las premisas de la Ilustración.

La voluntad de crear una "física social", esto es, un conocimiento indiscutible de la sociedad, de forma análoga a como se establece en la Física, surgió con el positivismo del siglo XIX. El primero en defender una teoría e investigación científica de los fenómenos sociales fue Henri de Saint-Simon (1760-1825) a mediados del siglo XIX. Auguste Comte, quien fue secretario de Saint-Simon entre 1817 y 1823, desarrolló sus teorías bajo las premisas del positivismo. Comte acuñó la palabra "sociología" en 1824 (del latín: socius, "socio, compañero"; y el sufijo griego -logía, "el estudio de"). La primera vez que apareció impresa esta palabra fue en su "Curso de filosofía positiva" de 1838.

Casi en simultáneo, en Alemania, Von Stein (1815-1890), introdujo el concepto de sociología como ciencia (Die Wissenschaft der Gesellschaft) incorporando a su estudio lo que él llamó "Movimientos sociales" y la dialéctica hegeliana. De esta manera logró darle a la disciplina una visión dinámica. Von Stein es considerado como el fundador de las ciencias de la Administración Pública.

Alexis de Tocqueville (1805-1859) por su parte, es también reconocido como uno de los precursores de la sociología, por sus estudios sobre la Revolución francesa y sobre los Estados Unidos (La democracia en América, publicada entre 1835-1840). El citado analizó a las sociedades en general e hizo una comparación entre las sociedades americanas y las sociedades europeas.

La sociología continuó con un desarrollo intenso y regular a principio del siglo XX. Émile Durkheim, quien se inspiró en algunas teorías de Auguste Comte para renovar la sociología, quería en particular "estudiar los hechos sociales como si fueran cosas". Uno de los retos de la sociología era desarrollarse como una ciencia autónoma. Durkheim buscó distinguir a la sociología de la filosofía por un lado y de la psicología por el otro. Por ello, se le considera como uno de los padres fundadores de la sociología.

El citado postuló las bases de una metodología científica para la sociología, en particular en la obra "Las reglas del método sociológico" (1895), y en "La división del trabajo social" (1893), libro que además es su tesis. Su método reposa esencialmente en la comparación de estadísticas y características cuantitativas, buscando liberarse de todo subjetivismo ligado a toda interpretación cualitativa, y a desembarazarse de todos los prejuicios morales o moralizadores "a priori" para comprender los hechos sociales como en su obra: "El Suicidio".

Karl Marx es otro científico que ha tenido una profunda influencia en el pensamiento social y la crítica del siglo XIX. Fue principalmente en Alemania donde desarrollara una teoría mayor de la sociología, influenciando posteriormente, entre otros, en la Escuela de Frankfurt.

Max Weber, contemporáneo de Durkheim, tomó un camino diferente: empleó la Ciencia política, la Economía política, la Filosofía de la cultura y del derecho, los estudios religiosos que son, según él, todo como la sociología, las "ciencias de la cultura". De acuerdo a toda una tradición de la filosofía alemana (sobre todo Wilhelm Dilthey), estas ciencias son diferentes de las ciencias naturales ya que tienen su propio método. Ellas proponen una comprensión de los fenómenos colectivos antes que la búsqueda de leyes (es el método comprensivo).

Una primera característica de estos métodos se manifiesta en su estrategia para tratar de conocer los hechos, procesos, estructuras y personas en su totalidad, y no a través de la medición de algunos de sus elementos. La misma estrategia indica ya el empleo de procedimientos que dan un carácter único a las observaciones. La segunda característica es el uso de procedimientos que hacen menos comparables las observaciones en el tiempo y en diferentes circunstancias culturales, es decir, este método busca menos la generalización y se acerca más a la fenomenología y al interaccionismo simbólico. Una tercera característica estratégica importante para este trabajo (ya que sienta bases para el método de la investigación participativa), se refiere al papel del investigador en su trato -intensivo- con las personas involucradas en el proceso de investigación, para entenderlas.

Aquí se utilizan las técnicas experimentales aleatorias, cuasi-experimentales, cuestionarios, encuestas, entre otros. Dentro de todos los análisis de los métodos cuantitativos podemos encontrar unas características basadas en el positivismo como fuente epistemológica: el énfasis en la precisión de los procedimientos para la medición, el uso de técnicas de muestreo, así como la relación entre los conceptos y los indicadores con los que se miden (para evitar las confusiones que genera el uso de un lenguaje oscuro, que pese a ser seductor, es difícil de comprobar su veracidad). Otra característica predominante de los métodos cuantitativos es la selección subjetiva e intersubjetiva de indicadores (a través de conceptos y variables) de ciertos elementos de procesos, hechos, estructuras y personas. Estos elementos no conforman en su totalidad, los procesos o las personas (de allí se deriva el debate entre los cuantitativistas que nunca ven un fenómeno integrado, sino siempre conjuntos de partículas de los fenómenos relacionados con la observación, y los cualitativistas que pueden percibir los elementos generados que comparten los fenómenos). Sin embargo, las nuevas técnicas cuantitativas, como el análisis de redes sociales, o la historia de acontecimientos, consiguen en cierta medida superar estas limitaciones.

El método comparativo estudia la correlación que existe entre uno o más fenómenos que se cotejan. Cuando se estudia, por ejemplo, la relación directa que existe entre el desarrollo del urbanismo y la relajación de las costumbres, o entre la extensión de la educación y la democracia, se hace uso del método comparativo.

Distintas corrientes han nutrido el cuerpo teórico de la sociología, entre las que destacan, la Escuela Francesa, la Escuela Inglesa, la Escuela de Chicago y la Escuela de Fráncfort. Las perspectivas generalmente usadas son el interaccionismo simbólico, el socioconstruccionismo, la teoría del conflicto, la fenomenología y la teoría funcionalista, no siendo las únicas. Muchos sociólogos se han abocado al estudio de la sociología crítica, el posestructuralismo, y otras tantas basadas en la comprensión del sujeto desde una perspectiva amplia, basada en disciplinas como la historia, la filosofía, entre otras, obteniendo así una teoría sociológica compleja y cuyos conocimientos son más profundos que en los primeros casos. Además de las expuestas, entre el grupo de las grandes escuelas se encuentran la teoría neomarxiana y la fenomenología, en su vertiente sociológica.

La teoría está asociada a Émile Durkheim y más recientemente a Talcott Parsons, además de autores como Robert K. Merton. El funcionalismo estructuralista ve a la sociedad como un sistema complejo, cuyas partes trabajan juntas para promover la solidaridad y estabilidad. Este enfoque analiza la sociedad desde un nivel macro, que es un enfoque amplio en las estructuras sociales que la conforman en su conjunto. Cree que la sociedad evoluciona de manera gradual, como parte de un proceso de adaptación y complejización, de modo análogo a los organismos vivientes. El funcionalismo se preocupa tanto por las estructuras como las funciones sociales. Se interesa por sus elementos constitutivos, a saber: normas, costumbres, tradiciones e instituciones.

A pesar de la indiscutible hegemonía que ostentó durante las dos décadas posteriores a la Segunda Guerra Mundial, el funcionalismo estructural ha perdido importancia como teoría sociológica.

El interaccionismo simbólico es una corriente de pensamiento microsociológica. Partiendo de un método de estudio participante, capaz de dar cuenta del sujeto, concibe lo social como el marco de la interacción simbólica de individuos, y concibe la comunicación como el proceso social por antonomasia, a través del cual, se constituyen simultánea y coordinadamente, los grupos y los individuos. Este analiza el sentido de la acción social desde la perspectiva de los participantes. Algunos interaccionistas simbólicos destacados son Herbert Blumer, Erving Goffman o Nikolas Rose.

Según Mead, el individuo no nace siendo persona. La persona se forma socialmente cuando logra observarse a sí misma como un objeto, es decir, cuando logra un pensamiento reflexivo sobre sí mismo. Los otros, las demás personas, son un espejo en el cual se observa la propia persona.

En un sentido similar, Goffman, basado en un modelo interpretativo dramatúrgico, estudia los ritos de interacción comunicativa que aprendemos y ponemos en juego en nuestra vida cotidiana. Define el rol como un conjunto organizado de expectativas de comportamiento en torno a una función o posición social (por ejemplo "padre", "jefe", "profesor").

La etnometodología es una corriente sociológica surgida en los años sesenta a través de los trabajos de Harold Garfinkel. Se basa en el supuesto de que todos los seres humanos tienen un sentido práctico con el cual adecuan las normas de acuerdo con una racionalidad práctica que utilizan en la vida cotidiana. En términos más sencillos, se trata de una perspectiva sociológica que toma en cuenta los métodos que los seres humanos utilizan en su vida diaria para levantarse, ir al trabajo, tomar decisiones, entablar una conversación con los otros. En la antropología también se suele seguir esta línea sociológica, sobre todo los antropólogos que se especializan en los estudios de la sociedad.

Un etnométodo utilizado en el ámbito de la educación, fue el trabajo de Pigmalión en la escuela, conocido como el famoso Test de Harvard de Adquisición Conjugada. 
La teoría del conflicto es una de las grandes escuelas de la teoría sociológica moderna, es considerada como desarrollo que se produjo en reacción a la estática del funcionalismo estructural. Durante las décadas de 1950 y 1960 la teoría del conflicto proporcionó una alternativa al funcionalismo estructural, pero ha sido superada recientemente por las teorías neomarxianas. La teoría del conflicto está íntimamente vinculada a la teoría de los juegos y a los estudios y escuelas sobre negociación.

Entre los más prominentes pensadores con enfoque sociológico de los últimos tiempos hay que tener en cuenta al pensador francés Michel Foucault (1926-1984) y al autor alemán Jürgen Habermas (nacido en 1929). Al igual que los clásicos de la disciplina, estos autores no solo han sido sociólogos sino que se han ocupado ampliamente de la filosofía y de la historia. Foucault se ocupó de materias similares a las analizadas por Weber en sus estudios de la burocracia: el desarrollo de las prisiones, hospitales, escuelas y otras organizaciones a gran escala. Por ejemplo, consideraba que la sexualidad siempre está vinculada al poder social y cuestionaba la idea de que un mayor conocimiento conduzca a una mayor libertad, porque lo concebía como una forma de "etiquetar" a las personas y de controlarlas.

El desarrollo de la teoría del intercambio tiene sus raíces en el conductismo.

El conductismo está más vinculado a la psicología, pero en sociología tiene una influencia directa en la sociología conductista y una influencia indirecta en la teoría del intercambio. El sociólogo conductista se ocupa de la relación entre los efectos de la conducta de un actor sobre su entorno y su influencia sobre la conducta posterior del actor. Los conductistas se interesan mucho por las recompensas y los costes de las acciones. Las recompensas se definen por su capacidad de reforzar la conducta, mientras los costes reducen la probabilidad de la conducta. En este sentido, el conductismo en general, y la idea de recompensas y costes en particular, han influido poderosamente en la primera teoría del intercambio.

La teoría del intercambio de Peter Blau se diferencia en distintas facetas con la de Homans, la meta de Blau era contribuir a una comprensión de la estructura social sobre la base de un análisis de los procesos sociales que rigen las relaciones entre los individuos y los grupos. La cuestión básica es cómo se llega a organizar la vida social en estructuras cada vez más complejas de asociaciones entre personas.

Walter Buckley (1967) aborda una cuestión de importancia central: las ventajas de la teoría de sistemas para la sociología. En primer lugar, dado que la teoría de sistemas se deriva de las ciencias naturales y dado que, al menos a los ojos de sus exponentes, es aplicable a todas las ciencias sociales y conductistas, ofrece un vocabulario que las unifica. En segundo lugar, la teoría de sistemas incluye varios niveles de análisis y puede aplicarse igualmente a los aspectos macro más objetivos y a los aspectos micro más subjetivos de la vida social. En tercer lugar, la teoría de sistemas se interesa por las diversas relaciones entre los numerosos aspectos del mundo social, y por tanto, milita contra los análisis parciales del mundo social.

La dicotomía entre estructura y acción, a veces referida como determinismo contra voluntarismo, forma parte de un debate ontológico duradero en la teoría social: ¿determinan las estructuras sociales el comportamiento de un individuo o lo hace la acción humana? En este contexto, se entiende por agencia a la capacidad de las personas para actuar de forma independiente y tomar decisiones libres, mientras que la "estructura" se refiere a los factores que limitan o afectan las decisiones y acciones de los individuos (como la clase social, religión, género, origen étnico, entre otras). Las discusiones sobre la primacía de la estructura o la acción se relacionan con el núcleo de la epistemología sociológica (¿de qué está hecho el mundo social, ¿qué es una causa en el mundo social y qué es un efecto?).

Una pregunta permanente dentro de este debate es acerca de la "reproducción social": ¿cómo son las estructuras (en especial, las estructuras que producen desigualdad) reproducidas a través de las elecciones de los individuos?. Diferentes respuestas han sido planteadas a este respecto por la sociología contemporánea. Entre ellas podemos mencionar a Pierre Bourdieu, con su teoría constructivista genética; Jürgen Habermas, con su distinción entre racionalidad instrumental y comunicativa -sistema y mundo de la vida-, y Anthony Giddens, con su teoría de la estructuración social.

Se entiende como un "dinamismo social" el fluir de las costumbres y creencias de una sociedad. El cambio se evidencia a través de las interacciones de cada persona con el resto social y cómo el conjunto afecta al individuo, marcando un comportamiento de comunicación global de sujetos relacionados entre sí. Las formas y convenciones de la dinámica social están marcadas por la historia y sujetas, por tanto, a un cambio permanente.

La interacción social resultante de la dinámica, expresa grados sociales, estableciendo campos de acción que se expresan mediante la diferenciación del "statu quo" social. En la interacción social, habría primero que establecer la capa o campo social sobre el que se va a observar a los individuos y cómo estos influyen mutuamente y adaptan su comportamiento frente a los demás.

La sociología en la región latinoamericana se desarrollaría a lo largo del siglo XX, con posterioridad a Europa y los Estados Unidos. Su creación se vincula a diferentes intentos de apropiación del corpus teórico de la disciplina, sumado al desafío de producir y legitimar un ideario conceptual propio, que reflejara la realidad del conjunto de estos países. Esta se nutriría además de aportes intelectuales locales variados. Los desarrollos más significativos elaborados desde la región se refieren a lecturas críticas del imperialismo y los procesos de colonización, teorías vinculadas a la modernización de la matriz económica, social y cultural, así como teorías de la dependencia, con énfasis en la subordinación de la región a escala mundial. Estas últimas se vinculan a la teología de la liberación, pedagogía del oprimido y un conjunto de estudios realizados desde la CEPAL.

Más recientemente, encontramos estudios sobre democracia, democratización y derechos humanos, aportes críticos al neoliberalismo y la globalización económica, así como estudios sobre participación política, acción colectiva y conflicto social.

Algunas organizaciones que consolidaron la institucionalización de la disciplina en la región son: ALAS, CLACSO y FLACSO.




</doc>
<doc id="2558" url="https://es.wikipedia.org/wiki?curid=2558" title="Slackware">
Slackware

Slackware Linux es una distribución del sistema operativo GNU/Linux creada en 1993 por Patrick Volkerding orientada a usuarios avanzados. Basada originalmente en SLS Linux, Slackware es la distribución de GNU/Linux más antigua aún en mantenimiento.

Su versión actual es la versión 14.2, publicada el 1 de julio de 2016. Contiene un programa de instalación sencillo de utilizar, aunque está basado en texto, a diferencia de otros entornos de instalación basados en ambientes gráficos. También cuenta con extensa documentación en inglés y un sistema de gestión de paquetes basado en menús. Lo que diferencia a Slackware Linux de otras distribuciones Linux es que la misma se asemeja en alto grado a los sistemas operativos Unix. A tal efecto, incluye software que normalmente no se encuentra en otras distribuciones Linux, tal como la última versión del entorno de comandos Korn shell.

Una instalación completa incluye una implementación de X Window System para el sistema de ventanas X.Org ; entornos de escritorio como KDE (4.8.5) (hasta la versión 10.1 estuvo incluido GNOME) y Xfce (4.10); entornos de desarrollo para C/C++, Perl, Python, Java, LISP y Ruby; utilidades de red, servidores de correo, de noticias (INN), HTTP (Apache) o FTP; programas de diseño gráfico como GIMP; navegadores web como Konqueror, Firefox y Mozilla SeaMonkey, entre otras muchas aplicaciones.

La página informativa oficial describe a Slackware como "un sistema operativo avanzado, diseñado con el doble objetivo de facilidad de uso y estabilidad como prioridades principales" y describe algunas de las funciones que se distribuyen con él: "web, ftp y servidores de correo vienen por defecto, así como una amplia selección de entornos de escritorio populares. Se incluye una gama completa de herramientas de desarrollo, editores y librerías actuales, para los usuarios que deseen desarrollar o compilar software adicional".

Slackware actualmente proporciona soporte para la arquitectura x86 de 64 bits.

La distribución de paquetes en Slackware se hace principalmente con archivos tar comprimidos. Hace uso del programa rpm2txz y rpm2tgz respectivamente para convertir paquetes RPM a formatos tgz y txz nativos. La interfaz del programa de instalación es por texto, y requiere un mayor conocimiento de GNU/Linux que otras distribuciones. Esto puede ser una desventaja para usuarios principiantes, pero no representa mayor dificultad para usuarios intermedios o avanzados de GNU/Linux.

La primera versión oficial de Slackware, la 1.00, fue publicada el 16 de julio de 1993 por Patrick Volkerding, fundador y líder de desarrollo. Estaba basada en la distribución SLS Linux y se distribuía en discos flexibles de 3½ e imágenes que estaban disponibles en servidores FTP anónimos. Slackware es la distribución más antigua entre las que siguen activamente mantenidas. 

Así Patrick J. Volkerding decía en el newsgroups comp.os.linux:
El nombre "Slackware" deriva del término "slack", tal y como lo define la Iglesia de los SubGenios.

En las primeras versiones de Slackware, la distribución tenía tres cuentas de usuario, "satan", "gonzo" y "snake". Estas eran incluidas solo como ejemplos, pero fueron eliminadas posteriormente debido a que significaban un potencial riesgo computacional. 

En 1999, el número de versión de Slackware se incrementó de 4 a 7, para demostrar que Slackware estaba actualizado al igual que otras distribuciones de Linux, muchas de las cuales tenían como número de publicación en ese momento el 6.

En 2004, Patrick Volkerding enfermó seriamente y el futuro desarrollo de Slackware se volvió incierto. Afortunadamente, se recuperó, y el desarrollo de Slackware ha continuado.

En 2005, el escritorio GNOME fue eliminado de la distribución, lo que creó una gran polémica superada en parte por el hecho de que sigue habiendo proyectos dedicados a ofrecer dicho escritorio a los usuarios de Slackware, como Freerock GNOME o dropline GNOME. 

En 2007, incluye la serie 2.6.x del núcleo Linux como estable. 

En el transcurso de la historia de Slackware, han nacido otras distribuciones y LiveCD basadas en ella. Algunas de las más populares incluyen College Linux, SLAX, Vector Linux y Zenwalk.

El 13 de agosto de 2008 Slackware incluía a KDE 4 en la rama de pruebas ("Slackware -current") en el directorio codice_1. 

El 19 de mayo de 2009 Volkerding anunció el comienzo del soporte oficial para la arquitectura de 64 bits, la cual se inició en la rama en desarrollo ("current").

El 9 de julio de 2009 Volkerding anuncia en el sitio oficial de Slackware el soporte para arquitecturas ARM, un port oficial denominado ARMedslack, tanto para la versión 12.2 como para la que está en desarrollo ("current").

El 26 de agosto de 2009 el proyecto Slackware lanzó la versión 13.0, que destacó dos importantes anuncios, el primero es el reemplazo de KDE 3 por KDE 4, y el segundo fue el lanzamiento de la primera versión oficial de Slackware para la arquitectura de 64 bits, la cual hasta ese momento otros proyectos, como Slamd64, desarrollaban ports no oficiales de Slackware para esa arquitectura.

El 24 de mayo de 2010 se lanzó la versión 13.1, que tenía como principales mejoras la versión SC de KDE 4.4.3, el kernel Linux 2.6.33.4, bibliotecas y aplicaciones actualizadas tales como Firefox y Thunderbird.

El 27 de abril de 2011 se lanzó la versión 13.37, el kernel Linux 2.6.37.6 , Kernel Linux 2.6.35.12 y 2.6.39-rc4 en testing , mejoras en el sistema X (incluye nouveau para las tarjetas gráficas nvidia) , navegador web firefox 4 , KDE SC 4.5.5 y las acostumbradas mejoras.

El 23 de marzo de 2013 se anunció que se quitaba MySQL y se agregaba MariaDB como servidor de base de datos. Este cambio está aplicado a la versión de desarrollo ("Slackware -current") por el momento y va a estar disponible en la próxima versión estable.

El 30 de junio de 2016 se anunció la versión 14.2 como estable, con el kernel Linux 4.4.14, bibliotecas y aplicaciones actualizadas tales como: XFCE 4.12.1 y KDE 4.14.21 (KDE 4.13.3 con kdelibs-4.14.21), X11 a la versión X11R7.7, la cual incluye mejoras en términos de rendimiento y soporte de hardware; gcc-5.3.0 por defecto para C, C++, Objective-C; la versión x86_64 es compatible con la instalación y arranque en máquinas que utilizan el firmware UEFI.

"Mantenlo Simple, Estúpido" (de sus siglas en inglés KISS que significan ""Keep It Simple Stupid""), es un concepto que explica muchas de las opciones en el diseño de Slackware. En este contexto, ""simple"" se refiere a un punto de vista de diseño, en vez de ser fácil de utilizar. Esta es la razón por la cual existen muy pocas herramientas GUI para configurar el sistema. Las herramientas GUI son (según nos dice la teoría) más complejas, y por lo tanto más propensas a tener problemas que una simple línea de órdenes. El resultado general sobre este principio es que Slackware es muy rápido, estable y seguro con el costo de no ser tan amigable al usuario. Los críticos mencionan que esto hace que las cosas sean difíciles de aprender y consuman mucho tiempo. Los seguidores dicen que la flexibilidad y transparencia, así como, la experiencia ganada en el proceso son más que suficientes.

Según la página oficial de Slackware el término KISS se refiere a "keep it simple stable", que traducido sería "manténgalo simple y estable".

Slackware utiliza scripts de inicio init de BSD, mientras que la mayoría de las distribuciones utilizan el estilo de scripts System V. Básicamente, con el estilo System V cada nivel de ejecución tiene un subdirectorio para sus scripts init, mientras que el estilo BSD ofrece un solo script init para cada nivel de ejecución. Los fieles del estilo BSD mencionan que es mejor ya que con este sistema es más fácil encontrar, leer, editar y mantener los scripts. Mientras que los seguidores de System V dicen que la estructura de System V para los scripts lo convierte en más poderoso y flexible. 

Cabe mencionar que la compatibilidad para los scripts init de System V han sido incorporados en Slackware, a partir de la versión 7.0.

La aproximación de Slackware para el manejo de paquetes es único. Su sistema de manejo de paquetes puede instalar, actualizar y eliminar paquetes tan fácilmente como en otras distribuciones. Pero no hace el intento por rastrear o manejar las "dependencias" referidas (por ejemplo: asegurándose de que el sistema tiene todas las bibliotecas y programas que el nuevo paquete "esperaría" estuvieran presentes en el sistema). Si los requisitos no se encuentran, no habrá indicaciones de falla hasta que el programa sea ejecutado.

Los paquetes son comprimidos en un tarball en donde los nombres de archivos terminan con .txz (El formato .tgz fue utilizado hasta la versión 12.2) en vez de .tar.gz. Son construidos de tal manera que al ser extraídos en el directorio raíz, los archivos se copien a sus lugares de instalación. Es por lo tanto posible (pero no aconsejable) instalar paquetes sin las herramientas de Slackware para paquetes, usando solamente tar's y gzip's y asegurándose de ejecutar los scripts doinst.sh en caso de ser incluidos en el paquete. 

En contraste Red Hat Linux tiene paquetes RPM los cuales son archivos CPIO, y los .deb de Debian son archivos ar. Estos contienen información detallada de las dependencias y las utilerías que se pueden utilizar para encontrar e instalar esas dependencias. Se negarán a instalarse a menos que los requisitos sean encontrados (aunque esto puede omitirse).

A pesar de que Slackware por sí mismo no incorpora herramientas para resolver dependencias automáticamente descargando e instalándolas, existen algunas herramientas externas que proveen de esta funcionalidad de forma similar a APT.

Algunas de estas herramientas determinan las dependencias analizando los paquetes instalados, determinando qué bibliotecas se necesita, y después descubriendo qué paquetes están disponibles. Este proceso automático, muy similar al APT de Debian y produce generalmente resultados satisfactorios. 


Slackware es una distribución que no se centra en tener las últimas versiones de los programas, sino que su foco es tener un sistema estable. Los nuevos paquetes se ponen a prueba y no son entregados hasta que no sean estables (esto no implica que sea la última versión disponible del programa), por ejemplo no se incluyó el núcleo Linux 2.6.* sino hasta el año 2007, habiendo sido lanzada la versión 2.6.0 en el año 2003. Pero cuando algún paquete tiene una actualización por bugs o mejoras de seguridad, estas son incorporadas a los paquetes de Slackware y se anuncia a través de una lista de correo de dichas actualizaciones y en el log de cambios ("changelog") que se encuentra en el sitio web. Slackware incluye dentro del directorio /extra del CD de instalación el programa Slackpkg que ayuda a mantener actualizado el sistema.




</doc>
<doc id="2561" url="https://es.wikipedia.org/wiki?curid=2561" title="Segundo (desambiguación)">
Segundo (desambiguación)

La palabra segundo se puede referir a:

</doc>
<doc id="2562" url="https://es.wikipedia.org/wiki?curid=2562" title="Sistema solar">
Sistema solar

El sistema solar es el sistema planetario en el que se encuentran la Tierra y otros objetos astronómicos que giran directa o indirectamente en una órbita alrededor de una única estrella conocida como el Sol.

La estrella concentra el 99,75% de la masa del sistema solar, y la mayor parte de la masa restante se concentra en ocho planetas cuyas órbitas son prácticamente circulares y transitan dentro de un disco casi llano llamado plano eclíptico. Los cuatro planetas más cercanos, considerablemente más pequeños Mercurio, Venus, Tierra y Marte, también conocidos como los planetas terrestres, están compuestos principalmente por roca y metal. Mientras que los cuatro más alejados, denominados gigantes gaseosos o «planetas jovianos», más masivos que los terrestres, están compuestos de hielo y gases. Los dos más grandes, Júpiter y Saturno, están compuestos principalmente de helio e hidrógeno. Urano y Neptuno, denominados gigantes helados, están formados mayoritariamente por agua congelada, amoniaco y metano.

El Sol es el único cuerpo celeste del sistema solar que emite luz propia, debido a la fusión termonuclear del hidrógeno y su transformación en helio en su núcleo. 
El sistema solar se formó hace unos 4600 millones de años a partir del colapso de una nube molecular. El material residual originó un disco circunestelar protoplanetario en el que ocurrieron los procesos físicos que llevaron a la formación de los planetas.
El sistema solar se ubica en la actualidad en la nube Interestelar Local que se halla en la Burbuja Local del brazo de Orión, de la galaxia espiral Vía Láctea, a unos 28 000 años luz del centro de esta.

El sistema solar es también el hogar de varias regiones compuestas por objetos pequeños. El cinturón de asteroides, ubicado entre Marte y Júpiter, es similar a los planetas terrestres ya que está constituido principalmente por roca y metal. En este cinturón se encuentra el planeta enano Ceres.
Más allá de la órbita de Neptuno están el cinturón de Kuiper, el disco disperso y la nube de Oort, que incluyen objetos transneptunianos formados por agua, amoníaco y metano principalmente. En este lugar existen cuatro planetas enanos: Haumea, Makemake, Eris y Plutón, el cual fue considerado el noveno planeta del sistema solar hasta 2006. Este tipo de cuerpos celestes ubicados más allá de la órbita de Neptuno son también llamados plutoides, los cuales junto a Ceres, poseen el suficiente tamaño para que se hayan redondeado por efectos de su gravedad, pero que se diferencian principalmente de los planetas porque no han vaciado su órbita de cuerpos vecinos.

Adicionalmente a los miles de objetos pequeños de estas dos zonas, algunas docenas de los cuales son candidatos a planetas enanos, existen otros grupos como cometas, centauros y polvo cósmico que viajan libremente entre regiones. Seis planetas y cuatro planetas enanos poseen satélites naturales. El viento solar, un flujo de plasma del Sol, crea una burbuja de viento estelar en el medio interestelar conocido como heliosfera, la que se extiende hasta el borde del disco disperso. La nube de Oort, la cual se cree que es la fuente de los cometas de período largo, es el límite del sistema solar y su borde está ubicado a un año luz desde el Sol.

A principios del año 2016 se publicó un estudio según el cual puede existir un noveno planeta en el sistema Solar, al que dieron el nombre provisional de Phattie. Se estima que el tamaño de Phattie sería entre el de Neptuno y la Tierra y que el hipotético planeta sería de composición gaseosa.

Algunas de las más antiguas civilizaciones concibieron al universo desde una perspectiva geocéntrica, como en Babilonia en donde su visión del mundo estuvo representada de esta forma.
En Occidente, el griego presocrático Anaximandro declaró a la Tierra como centro del universo, imaginó a esta como un pilar en forma de tambor equilibrado en sus cuatro puntos más distantes lo que, en su opinión, le permitió tener estabilidad.
Pitágoras y sus seguidores hablaron por primera vez del planeta como una esfera, basándose en la observación de los eclipses; y en el siglo IV a. C. Platón junto a su estudiante Aristóteles escribieron textos del modelo geocéntrico de Anaximandro, fusionándolo con el esférico pitagórico.
Pero fue el trabajo del astrónomo heleno Claudio Ptolomeo, especialmente su publicación llamada Almagesto expuesta en el siglo II de nuestra era, el cual sirvió durante un período de casi 1300 años como la norma en la cual se basaron tanto astrónomos europeos como islámicos.

Si bien el griego Aristarco presentó en el siglo siglo III a. C. a la teoría heliocéntrica y más adelante el matemático hindú Aryabhata hizo lo mismo, ningún astrónomo desafió realmente el modelo geocéntrico hasta la llegada del polaco Nicolás Copérnico el cual causó una verdadera revolución en esta rama a nivel mundial, por lo cual es considerado el padre de la astronomía moderna.
Esto debido a que, a diferencia de sus antecesores, su obra consiguió una amplia difusión pese a que fue concebida para circular en privado; el papa Clemente VII pidió información de este texto en 1533 y Lutero en 1539 lo calificó de «astrólogo advenedizo que pretende probar que la Tierra es la que gira».
La obra de Copérnico otorga dos movimientos a la Tierra, uno de rotación en su propio eje cada 24 horas y uno de traslación alrededor del Sol cada año, con la particularidad de que este era circular y no elíptico como lo describimos hoy.

En el siglo XVII el trabajo de Copérnico fue impulsado por científicos como Galileo Galilei, quien ayudado con un nuevo invento, el telescopio, descubre que alrededor de Júpiter rotan satélites naturales que afectaron en gran forma la concepción de la teoría geocéntrica ya que estos cuerpos celestes no orbitaban a la Tierra; lo que ocasionó un gran conflicto entre la iglesia y los científicos que impulsaban esta teoría, el cual culminó con el apresamiento y sentencia del tribunal de la inquisición a Galileo por herejía al estar su idea contrapuesta con el modelo clásico religioso.
Su contemporáneo Johannes Kepler, a partir del estudio de la órbita circular intentó explicar la traslación planetaria sin conseguir ningún resultado, por lo que reformuló sus teorías y publicó, en el año 1609, las hoy conocidas leyes de Kepler en su obra "Astronomia Nova", en la que establece una órbita elíptica la cual se confirmó cuando predijo satisfactoriamente el tránsito de Venus del año 1631.
Junto a ellos, el científico británico Isaac Newton formuló y dio una explicación al movimiento planetario mediante sus leyes y el desarrollo del concepto de la gravedad. Sin embargo, el heliocentrismo no sería apoyado experimentalmente sino hasta décadas después con el descubrimiento de la aberración de la luz por el astrónomo inglés James Bradley en 1725, y la medición del paralaje estelar efectuada por el matemático alemán Friedrich Bessel en 1838.

En 1655 el científico neerlandés Christiaan Huygens descubrió el satélite Titán y la verdadera naturaleza de los anillos de Saturno, y describió por primera vez las dimensiones reales del entonces conocido sistema solar (6 planetas y 6 lunas). En 1704 se acuñó el término "sistema solar". El científico británico Edmund Halley dedicó sus estudios principalmente al análisis de las órbitas de los cometas. El mejoramiento del telescopio durante este tiempo permitió a los científicos de todo el mundo descubrir nuevas características de los cuerpos celestes que existen. 

A mediados del siglo XX, el 12 de abril de 1961, el cosmonauta Yuri Gagarin se convirtió en el primer hombre en el espacio; la misión estadounidense Apolo 11, al mando de Neil Armstrong llega a la Luna el 16 de julio de 1969. En la actualidad, el sistema solar se estudia con la ayuda de telescopios terrestres, observatorios espaciales y misiones espaciales.

Los planetas y los asteroides orbitan alrededor del Sol, aproximadamente en un mismo plano y siguiendo órbitas elípticas (en sentido antihorario, si se observasen desde el Polo Norte del Sol); aunque hay excepciones, como el cometa Halley, que gira en sentido horario. El plano en el que gira la Tierra alrededor del Sol se denomina plano de la eclíptica, y los demás planetas orbitan aproximadamente en el mismo plano. Aunque algunos objetos orbitan con un gran grado de inclinación respecto de este, como Plutón que posee una inclinación con respecto al eje de la eclíptica de 17º, así como una parte importante de los objetos del cinturón de Kuiper.

Según sus características, los cuerpos que forman parte del sistema solar se clasifican como sigue:
El espacio interplanetario en torno al Sol contiene material disperso procedente de la evaporación de cometas y del escape de material proveniente de los diferentes cuerpos masivos. El polvo interplanetario (especie de polvo interestelar) está compuesto de partículas microscópicas sólidas. El gas interplanetario es un tenue flujo de gas y partículas cargadas que forman un plasma que es expulsado por el Sol en el viento solar. El límite exterior del sistema solar se define a través de la región de interacción entre el viento solar y el medio interestelar originado de la interacción con otras estrellas. La región de interacción entre ambos vientos se denomina heliopausa y determina los límites de influencia del Sol. La heliopausa puede encontrarse a unas 100 UA (15 000 millones de kilómetros del Sol).

Los sistemas planetarios detectados alrededor de otras estrellas parecen muy diferentes del sistema solar, si bien con los medios disponibles solo es posible detectar algunos planetas de gran masa en torno a otras estrellas. Por tanto, no parece posible determinar hasta qué punto el sistema solar es característico o atípico entre los sistemas planetarios del universo.

Las órbitas de los planetas mayores se encuentran ordenadas a distancias del Sol crecientes, de modo que la distancia de cada planeta es aproximadamente el doble que la del planeta inmediatamente anterior, aunque esto no se ajusta a todos los planetas. Esta relación se expresa mediante la ley de Titius-Bode, una fórmula matemática aproximada que indica la distancia de un planeta al Sol, en Unidades Astronómicas (UA):

Donde la órbita de Mercurio se encuentra en k = 0 y semieje mayor 0,4 UA, la órbita de Marte es k = 4 a 1,6 UA, y Ceres (el mayor asteroide) es k = 8. En realidad las órbitas de Mercurio y Marte se encuentran en 0,38 y 1,52 UA. Esta ley no se ajusta a todos los planetas, por ejemplo Neptuno está mucho más cerca de lo que predice esta ley. No hay ninguna explicación de la ley de Titius-Bode y muchos científicos consideran que se trata tan solo de una coincidencia.

El sistema solar se formó hace 4568 millones de años por el colapso gravitatorio de una parte de una nube molecular gigante. Esta nube primigenia tenía varios años luz de diámetro y probablemente dio a luz a varias estrellas. Como es normal en las nubes moleculares, consistía principalmente de hidrógeno, algo de helio y pequeñas cantidades de elementos pesados surgidos de previas generaciones estelares. A medida que la región —conocida como nebulosa protosolar— se convertía en el sistema solar, colapsaba y la conservación del momento angular hizo que rotase más deprisa. El centro, donde se acumuló la mayor parte de la masa, se volvió cada vez más caliente que el disco circundante. A medida que la nebulosa en contracción rotaba más deprisa, comenzó a aplanarse en un disco protoplanetario con un diámetro de alrededor de 200 UA y una densa y caliente protoestrella en el centro. Los planetas se formaron por acreción a partir de este disco en el que el gas y el polvo atraídos gravitatoriamente entre sí se unen para formar cuerpos cada vez más grandes. En este escenario, cientos de protoplanetas podrían haber surgido en el temprano sistema solar que acabaron fusionándose o fueron destruidos dejando los planetas, los planetas enanos y el resto de cuerpos menores.

Gracias a sus puntos de ebullición más altos, solo los metales y silicatos podían existir en forma sólida cerca del Sol, en el cálido sistema solar interior; estos fueron finalmente los componentes de Mercurio, Venus, la Tierra y Marte: los planetas rocosos. Debido a que los metales solo eran una pequeña parte de la nebulosa solar, los planetas terrestres no se podían hacer muy grandes. Los planetas gigantes (Júpiter, Saturno, Urano y Neptuno) se formaron más lejos, más allá de la línea de congelación: el límite entre las órbitas de Marte y Júpiter donde las temperaturas son lo suficientemente bajas como para que los compuestos volátiles permanezcan sólidos. Los hielos que forman estos planetas eran más abundantes que los metales y silicatos que formaron los planetas terrestres interiores, por lo que los permitió crecer hasta ser lo suficientemente masivos como para capturar grandes atmósferas de hidrógeno y helio: los elementos más ligeros y abundantes. Los residuos restantes que no llegaron a convertirse en planetas se agruparon en regiones como el cinturón de asteroides, el cinturón de Kuiper y la nube de Oort. El modelo de Niza explica la aparición de estas regiones y propone que los planetas exteriores se podrían haber formado en sitios diferentes de los actuales a los que habrían llegado tras múltiples interacciones gravitatorias.

Tras cincuenta millones de años, la densidad del hidrógeno y la presión en el centro de la protoestrella se hicieron tan grandes que comenzó la fusión termonuclear. La temperatura, la velocidad de reacción, la presión y la densidad aumentaron hasta alcanzar el equilibrio hidrostático: la presión térmica igualó a la fuerza de la gravedad. En ese momento, el Sol entró en la secuencia principal. El tiempo que estará en la secuencia principal será de unos diez mil millones de años; en comparación, todas las fases previas al encendido termonuclear duraron unos dos mil millones de años. El viento solar formó la heliosfera que barrió los restos de gas y polvo del disco protoplanetario (y los expulsó al espacio interestelar), con lo que terminó el proceso de formación planetaria. Desde entonces, el Sol se ha ido haciendo cada vez más brillante; en la actualidad es un 70% más brillante que a su entrada en la secuencia principal.

El sistema solar continuará más o menos como lo conocemos hasta que todo el hidrógeno del núcleo del Sol se haya convertido en helio, situación que tendrá lugar dentro de cinco mil millones de años. Esto marcará el final de la estancia del Sol en la secuencia principal. En ese momento el núcleo colapsará y la producción de energía será mucho mayor que en el presente. Las capas exteriores se expandirán unas doscientas sesenta veces su diámetro actual, por lo que se convertirá en una gigante roja. El gran aumento de su superficie hará que esté muchísimo más frío (del orden de 2600 K). Se espera que el Sol en expansión vaporice Mercurio y Venus y vuelva la Tierra inhabitable al mover la zona de habitabilidad más allá de la órbita de Marte. Por último, el núcleo estará lo bastante caliente para fusionar el helio; el Sol quemará helio durante una fracción del tiempo que estuvo quemando hidrógeno. El Sol no tiene la suficiente masa para comenzar la fusión de elementos pesados, por lo que las reacciones nucleares en el núcleo disminuirán. Las capas exteriores se perderán en el espacio en forma de nebulosa planetaria, devolviendo parte del material con el que se formó el Sol —enriquecido con elementos pesados como el carbono— al medio interestelar y dejando atrás una enana blanca con la mitad de la masa original del Sol y el tamaño de la Tierra (un objeto extraordinariamente denso).

Los principales objetos del sistema solar son:

El Sol es la estrella única y central del sistema solar; por tanto, es la estrella más cercana a la Tierra y el astro con mayor brillo aparente. Su presencia o su ausencia en el cielo terrestre determinan, respectivamente, el día y la noche. La energía radiada por el Sol es aprovechada por los seres fotosintéticos, que constituyen la base de la cadena trófica, y es por ello la principal fuente de energía de la vida. También aporta la energía que mantiene en funcionamiento los procesos climáticos. El Sol es una estrella que se encuentra en la fase denominada secuencia principal, con un tipo espectral G2, que se formó hace unos 5000 millones de años, y permanecerá en la secuencia principal aproximadamente otros 5000 millones de años.

A pesar de ser una estrella mediana, es la única cuya forma circular se puede apreciar a simple vista, con un diámetro angular de 32′35″ de arco en el perihelio y 31′31″ en el afelio, lo que da un diámetro medio de 32′03″. Casualmente, la combinación de tamaños y distancias del Sol y la Luna respecto a la Tierra, hace que se vean aproximadamente con el mismo tamaño aparente en el cielo. Esto permite una amplia gama de eclipses solares distintos (totales, anulares o parciales).

Se han descubierto sistemas planetarios que tienen más de una estrella central (sistema estelar).

Los ocho planetas que componen el sistema solar son, de menor a mayor distancia respecto al Sol, los siguientes:

Los planetas son cuerpos que giran formando órbitas alrededor de la estrella, tienen suficiente masa para que su gravedad supere las fuerzas del cuerpo rígido, de manera que asuman una forma en equilibrio hidrostático (prácticamente esférica), y han limpiado la vecindad de su órbita de planetesimales (dominancia orbital).

Los planetas interiores son Mercurio, Venus, la Tierra y Marte y tienen la superficie sólida. Los planetas exteriores son Júpiter, Saturno, Urano y Neptuno, también denominados planetas gaseosos porque contienen en sus atmósferas gases como el helio, el hidrógeno y el metano, y no se conoce con certeza la estructura de su superficie.

El 24 de agosto de 2006, la Unión Astronómica Internacional (UAI) excluyó a Plutón como planeta del sistema solar, y lo clasificó como planeta enano.

A principios del año 2016 se publicó un estudio según el cual puede existir un noveno planeta en el sistema Solar, al que dieron el nombre provisional de Phattie. Dicho estudio se centró en la explicación de las órbitas de muchos de los objetos en el cinturón de Kuiper, que difieren mucho con las órbitas que se calculan, incluidos objetos muy conocidos como Sedna. Por tanto se surgió originalmente la idea de la existencia de un objeto no conocido perturbando dichas órbitas. Utilizando modelos matemáticos se realizaron simulaciones en computadora, y se determinó que el posible planeta tendría una órbita excéntrica a una distancia de unas entre 700 y 200UA del Sol, y tardaría unos diez o veinte mil años en dar una vuelta.

Las principales características de los planetas del sistema solar son:
  

Los cinco planetas enanos del sistema solar, de menor a mayor distancia respecto al Sol, son los siguientes:

Los planetas enanos son aquellos que, a diferencia de los planetas, no han limpiado la vecindad de su órbita.

Poco después de su descubrimiento en 1930, Plutón fue clasificado como un planeta por la Unión Astronómica Internacional (UAI). Sin embargo, tras el descubrimiento de otros grandes cuerpos con posterioridad, se abrió un debate con objeto de reconsiderar dicha decisión. El 24 de agosto de 2006, en la XXVI Asamblea General de la UAI en Praga, se decidió que el número de planetas no se ampliase a doce, sino que debía reducirse de nueve a ocho, y se creó entonces la nueva categoría de planeta enano, en la que se clasificaría Plutón, que dejó por tanto de ser considerado planeta debido a que, por tratarse de un objeto transneptuniano perteneciente al cinturón de Kuiper, no ha limpiado la vecindad de su órbita de objetos pequeños.

Algunos satélites del sistema solar son tan grandes que, si se encontraran orbitando directamente alrededor del Sol, se clasificarían como planetas o como planetas enanos; por orbitar a los planetas principales, estos cuerpos pueden denominarse «planetas secundarios». El siguiente listado recoge los satélites del sistema solar que mantienen un equilibrio hidrostático:

Los cuerpos menores del sistema solar están agrupados en:


Un cuerpo menor del sistema solar ("CMSS" o del inglés "SSSB", "small Solar System body") es, según la resolución de la UAI (Unión Astronómica Internacional) del 22 de agosto de 2006, un cuerpo celeste que orbita en torno al Sol y que no es planeta, ni planeta enano, ni satélite:

Por consiguiente, según la definición de la UAI, son cuerpos menores del sistema solar, independientemente de su órbita y composición:

Según las definiciones de planeta y de planeta enano, que atienden a la esfericidad del objeto debido a su gran masa, se puede definir como «cuerpo menor del sistema solar», por exclusión, a todo cuerpo celeste que, sin ser un satélite, no haya alcanzado suficiente tamaño o masa como para adoptar una forma esencialmente esférica.

Según algunas estimaciones, la masa requerida para alcanzar la condición de esfericidad se situaría en torno a los 5 x 10 kg, resultando el diámetro mínimo en torno a los 800 km. Sin embargo, características como la composición química, la temperatura, la densidad o la rotación de los objetos pueden variar notablemente los tamaños mínimos requeridos, por lo que se rechazó asignar valores apriorísticos a la definición, dejando la resolución individual de cada caso a la observación directa.

Según la UAI, algunos de los cuerpos menores del sistema solar más grandes podrían reclasificarse en el futuro como planetas enanos, tras un examen para determinar si están en equilibrio hidrostático, es decir: si son suficientemente grandes para que su gravedad venza las fuerzas del sólido rígido hasta haber adoptado una forma esencialmente esférica.

Exceptuando los objetos transneptunianos, los cuerpos menores del sistema solar de mayor tamaño son Vesta y Palas, con algo más de 500 km de diámetro.

Para tener una noción de la dimensión astronómica de las distancias en el espacio, es interesante hacer un modelo a escala que permita tener una percepción más clara del mismo. Imagínese un modelo reducido en el que el Sol esté representado por una pelota de 220 mm de diámetro. A esa escala, la Tierra estaría a 23,6 m de distancia y sería una esfera con apenas 2 mm de diámetro (la Luna estaría a unos 5 cm de la tierra y tendría un diámetro de unos 0,5 mm). Júpiter y Saturno serían bolitas con cerca de 2 cm de diámetro, a 123 y a 226 m del Sol, respectivamente. Plutón estaría a 931 m del Sol, con cerca de 0,3 mm de diámetro. En cuanto a la estrella más próxima (Próxima Centauri), estaría a 6 332 km del Sol, y la estrella Sirio, a 13 150 km.

Si se tardase 1 h y cuarto en ir de la Tierra a la Luna (a unos 257 000 km/h), se tardaría unas tres semanas (terrestres) en ir de la Tierra al Sol, unos 3 meses en ir a Júpiter, 7 meses a Saturno y unos dos años y medio en llegar a Plutón y abandonar el sistema solar. A partir de ahí, a esa velocidad, sería necesario esperar unos 17 600 años hasta llegar a la estrella más próxima, y 35 000 años hasta llegar a Sirio.

Una escala comparativa más exacta puede tenerse si se compara el Sol con un disco compacto de 12 cm de diámetro. A esta escala, la Tierra tendría poco más de un milímetro de diámetro (1,1 mm). El Sol estaría a 6,44 metros. El diámetro de la estrella más grande del Universo conocido, VY Canis Majoris, sería de 264 metros (imagínese esa enorme estrella de casi tres manzanas de casas de tamaño, en comparación con nuestra estrella de 12 cm). La órbita externa de Eris se alejaría a 625,48 metros del Sol. Allí nos espera un gran vacío hasta la estrella más cercana, Próxima Centauri, a 1645,6 km de distancia. A partir de allí, las distancias galácticas exceden el tamaño de la Tierra (aun utilizando la misma escala). Con un Sol del tamaño de un disco compacto, el centro de la galaxia estaría a casi 11 millones de kilómetros y el diámetro de la Vía Láctea sería de casi 39 millones de kilómetros. Habría un enorme vacío, pues la galaxia Andrómeda estaría a 1028 millones de kilómetros, casi la distancia real entre el Sol y Saturno.






</doc>
<doc id="2564" url="https://es.wikipedia.org/wiki?curid=2564" title="Sainete">
Sainete

Sainete es una pieza dramática jocosa en un acto, de carácter costumbrista y popular, representado en España durante el intermedio o al final de una función. Sustituyó al entremés en los siglos XVIII, XIX y XX. 

Entre los principales cultivadores de este subgénero cómico en el siglo XVIII se encuentran los gaditanos Luis Moncín y Juan Ignacio González del Castillo, y los madrileños Ramón de la Cruz y Sebastián Vázquez; otros autores menos conocidos fueron, entre muchos otros, Antonio Pablo Fernández, Antonio Furmento Bazo, Diego Ventura Rejón de Silva y Lucas, Antonio Vidaurre, José López de Sedano, Antonio Valladares de Sotomayor y Gaspar Zavala y Zamora. A finales del siglo XIX fue materia frecuente del llamado género chico y del teatro por horas, con autores especializados como Tomás Luceño y Javier de Burgos, y revitalizaron el género en el siglo XX Carlos Arniches con su colección de sainetes "Del Madrid castizo" y los hermanos Álvarez Quintero (Serafín y Joaquín). Posteriormente en el Río de la Plata, Armando Discépolo introducirá un giro sombrío y dramático en este género transformándolo en el "Grotesco criollo".

En la historia del desarrollo del sainete pueden observarse cuatro etapas:

1. (1603-1750). En esta tuvo lugar la transformación del término sainete del campo culinario al campo artístico. Ya estaban prescritas algunas características como la poca extensión de las piezas y la mezcla de humor y moralidad, del habla canto y baile.

2. (1760-1868). Es la época en que el sainete llegó a ser un género literario gracias a las creaciones de Ramón de la Cruz, mientras que también se modificó su temática frente al entremés. (254).

3. (1868-1894) El sainete recobró rigor de la mano de Tomás Luceño. Con una extensión más amplia (hasta 45 min.) ya no tiene lugar en las pausas entre los actos.

4. (1894-1915). Este período puede calificarse como la etapa de la decadencia porque el sainete se orienta más y más hacia otros géneros, especialmente hacia la zarzuela y el melodrama, que tuvieron influencia en su desarrollo posterior; hasta que finalmente el sainete fue absorbido por la «comedia asainetada».

El sainete valenciano pretendió ser un reflejo de la vida social de la Comunidad Valenciana (España) de estos siglos. Una de sus características recurrentes es que los personajes de las clases bajas hablaban valenciano, mientras que los forasteros, los miembros de la burguesía o todo aquel que tenía una voluntad de no ser clasificado o de aparentar más riqueza y educación, hablaban un castellano plagado de valencianismos y de incorrecciones. La crítica que se realiza de esta presunción es moral y, evidentemente, sociolingüística.

Entre los sainetistas valencianos más destacados encontramos: Eduardo Escalante, Josep Bernat i Baldoví y Francisco Palanca Roca.

En Argentina, el sainete combinado con las casas del circo, dio como resultado una modalidad original conocida como sainete criollo. El sainete criollo se caracterizó por reflejar las costumbres de la vida en los conventillos, agregando a los elementos humorísticos un conflicto sentimental y una acción trágica. Esta forma teatral se afianzó durante la década de 1920. En esta época se destacaron, además de Carlos M. Pacheco y Alberto Vacarezza, autores como el uruguayo Florencio Sánchez, Gregorio de Laferrere y Roberto Payró


El sainet valencià durant el segle XX en valenciano.


</doc>
<doc id="2566" url="https://es.wikipedia.org/wiki?curid=2566" title="Silicio">
Silicio

El silicio (del latín: "sílex") es un elemento químico metaloide, número atómico 14 y situado en el grupo 14 de la tabla periódica de los elementos de símbolo Si. Es el segundo elemento más abundante en la corteza terrestre (25,7 % en peso) después del oxígeno. Se presenta en forma amorfa y cristalizada; el primero es un polvo parduzco, más activo que la variante cristalina, que se presenta en octaedros de color azul grisáceo y brillo metálico.

Sus propiedades son intermedias entre las del carbono y el germanio. En forma cristalina es muy duro y poco soluble y presenta un brillo metálico y color grisáceo. Aunque es un elemento relativamente inerte y resiste la acción de la mayoría de los ácidos, reacciona con los halógenos y álcalis diluidos. El silicio transmite más del 95 % de las longitudes de onda de la radiación infrarroja.

Se prepara en forma de polvo amarillo pardo o de cristales negros-grisáceos. Se obtiene calentando sílice, o dióxido de silicio (SiO), con un agente reductor, como carbono o magnesio, en un horno eléctrico. El silicio cristalino tiene una dureza de 7, suficiente para rayar el vidrio, de dureza de 5 a 7. El silicio tiene un punto de fusión de 1,411 °C, un punto de ebullición de 2,355 °C y una densidad relativa de 2.33(g/ml). Su masa atómica es 28.086 u (unidad de masa atómica).

Se disuelve en ácido fluorhídrico formando el gas tetrafluoruro de silicio, SiF (ver flúor), y es atacado por los ácidos nítrico, clorhídrico y sulfúrico, aunque el dióxido de silicio formado inhibe la reacción. También se disuelve en hidróxido de sodio, formando silicato de sodio y gas hidrógeno. A temperaturas ordinarias el silicio no es atacado por el aire, pero a temperaturas elevadas reacciona con el oxígeno formando una capa de sílice que impide que continúe la reacción. A altas temperaturas reacciona también con nitrógeno y cloro formando nitruro de silicio y cloruro de silicio, respectivamente.

El silicio constituye un 28 % de la corteza terrestre. No existe en estado libre, sino que se encuentra en forma de dióxido de silicio y de silicatos complejos. Los minerales que contienen silicio constituyen cerca del 40 % de todos los minerales comunes, incluyendo más del 90 % de los minerales que forman rocas volcánicas. El mineral cuarzo, sus variedades (cornalina, crisoprasa, ónice, pedernal y jaspe) y los minerales cristobalita y tridimita son las formas cristalinas del silicio existentes en la naturaleza. El dióxido de silicio es el componente principal de la arena. Los silicatos (en concreto los de aluminio, calcio y magnesio) son los componentes principales de las arcillas, el suelo y las rocas, en forma de feldespatos, anfíboles, piroxenos, micas y zeolitas, y de piedras semipreciosas como el olivino, granate, zircón, topacio y turmalina.

Sus características compartidas con el carbono, como estar en la misma familia 14, no ser metal propiamente dicho, poder construir compuestos parecidos a las enzimas (zeolitas), otros compuestos largos con oxígeno (siliconas) y poseer los mismos cuatro enlaces básicos, le confiere cierta oportunidad en llegar a ser base de seres vivos, aunque no sea en la Tierra, en una bioquímica hipotética.

Se utiliza en aleaciones, en la decantación de las siliconas, en la industria de la cerámica técnica y, debido a que es un material semiconductor muy abundante, tiene un interés especial en la industria electrónica y microelectrónica como material básico para la creación de obleas o chips que se pueden implantar en transistores, pilas solares y una gran variedad de circuitos electrónicos.
El silicio es un elemento vital en numerosas industrias. El dióxido de silicio (arena y arcilla) es un importante constituyente del hormigón y los ladrillos, y se emplea en la producción de cemento portland. Por sus propiedades semiconductoras se usa en la fabricación de transistores, células solares y todo tipo de dispositivos semiconductores; por esta razón se conoce como el Valle del Silicio a la región de California en la que concentran numerosas empresas del sector de la electrónica y la informática. También se están estudiando las posibles aplicaciones del siliceno, que es una forma alotrópica del silicio que forma una red bidimensional similar al grafeno. Otros importantes usos del silicio son:


Se utiliza en la industria del acero como componente de las aleaciones de silicio-acero. Para fabricar el acero, se desoxida el acero fundido añadiéndole pequeñas cantidades de silicio; el acero común contiene menos de un 0,30 % de silicio. El acero al silicio, que contiene de 2,5 a 4 % de silicio, se usa para fabricar los núcleos de los transformadores eléctricos, pues la aleación presenta baja histéresis (véase Magnetismo). Existe una aleación de acero, el durirón, que contiene un 15 % de silicio y es dura, frágil y resistente a la corrosión; el durirón se usa en los equipos industriales que están en contacto con productos químicos corrosivos. El silicio se utiliza también en las aleaciones de cobre, como el bronce y el latón.

El silicio es un semiconductor; su resistividad a la corriente eléctrica a temperatura ambiente varía entre la de los metales y la de los aislantes. La conductividad del silicio se puede controlar añadiendo pequeñas cantidades de impurezas llamadas dopantes. La capacidad de controlar las propiedades eléctricas del silicio y su abundancia en la naturaleza han posibilitado el desarrollo y aplicación de los transistores y circuitos integrados que se utilizan en la industria electrónica.

La sílice y los silicatos se utilizan en la fabricación de vidrio, barnices, esmaltes, cemento y porcelana, y tienen importantes aplicaciones individuales. La sílice fundida, que es un vidrio que se obtiene fundiendo cuarzo o hidrolizando tetracloruro de silicio, se caracteriza por un bajo coeficiente de dilatación y una alta resistencia a la mayoría de los productos químicos. El gel de sílice es una sustancia incolora, porosa y amorfa; se prepara eliminando parte del agua de un precipitado gelatinoso de ácido silícico, SiO•HO, el cual se obtiene añadiendo ácido clorhídrico a una disolución de silicato de sodio. El gel de sílice absorbe agua y otras sustancias y se usa como agente desecante y decolorante.

El silicato de sodio (NaSiO), también llamado vidrio, es un silicato sintético importante, sólido amorfo, incoloro y soluble en agua, que funde a 1088 °C. Se obtiene haciendo reaccionar sílice (arena) y carbonato de sodio a alta temperatura, o calentando arena con hidróxido de sodio concentrado a alta presión. La disolución acuosa de silicato de sodio se utiliza para conservar huevos; como sustituto de la cola o pegamento para hacer cajas y otros contenedores; para unir gemas artificiales; como agente incombustible, y como relleno y adherente en jabones y limpiadores. Otro compuesto de silicio importante es el carborundo, un compuesto de silicio y carbono que se utiliza como abrasivo.

El monóxido de silicio, SiO, se usa para proteger materiales, recubriéndolos de forma que la superficie exterior se oxida al dióxido, SiO. Estas capas se aplican también a los filtros de interferencias.

Fue identificado por primera vez por Antoine Lavoisier en 1787.

El silicio es uno de los componentes principales de los aerolitos, una clase de meteoroides.

Medido en peso, el silicio representa más de la cuarta parte de la corteza terrestre y es el segundo elemento más abundante por detrás del oxígeno. El silicio no se encuentra en estado nativo; arena, cuarzo, amatista, ágata, pedernal, ópalo y jaspe son algunos de los minerales en los que aparece el óxido, mientras que formando silicatos se encuentra, entre otros, en el granito, feldespato, arcilla, hornblenda y mica.

Estos métodos se basan en la mayor solubilidad de las impurezas en el silicio líquido, de forma que este se concentra en las últimas zonas solidificadas. El primer método, usado de forma limitada para construir componentes de radar durante la Segunda Guerra Mundial, consiste en moler el silicio de forma que las impurezas se acumulen en las superficies de los granos; disolviendo estos parcialmente con ácido se obtenía un polvo más puro. La fusión por zonas, el primer método usado a escala industrial, consiste en fundir un extremo de la barra de silicio y trasladar lentamente el foco de calor a lo largo de la barra de modo que el silicio va solidificando con una pureza mayor al arrastrar la zona fundida gran parte de las impurezas. El proceso puede repetirse las veces que sea necesario hasta lograr la pureza deseada bastando entonces cortar el extremo final en el que se han acumulado las impurezas.

Los métodos químicos, usados actualmente, actúan sobre un compuesto de silicio que sea más fácil de purificar descomponiéndolo tras la purificación para obtener el silicio. Los compuestos comúnmente usados son el triclorosilano (HSiCl), el tetracloruro de silicio (SiCl) y el silano (SiH).

En el proceso Siemens, las barras de silicio de alta pureza se exponen a 1150 °C al triclorosilano, gas que se descompone depositando silicio adicional en la barra según la siguiente reacción:

El silicio producido por este y otros métodos similares se denomina silicio policristalino y típicamente tiene una fracción de impurezas de 0,001 ppm o menor.

El método Dupont consiste en hacer reaccionar tetracloruro de silicio a 950 °C con vapores de cinc muy puros:

Este método está plagado de dificultades (el cloruro de cinc, sub producto de la reacción, solidifica y obstruye las líneas), por lo que eventualmente se ha abandonado en favor del proceso Siemens.

Una vez obtenido el silicio ultrapuro es necesario obtener un monocristal, para lo que se utiliza el proceso Czochralski.

A continuación se presentan las distintas alternativas de producción de SoG-Si.Todas ellas se han recogido y presentado desde 2004 en las Conferencias sobre Silicio Solar. Estas conferencias se han organizado anualmente por la revista Photon International en Múnich, a raíz de la preocupación creciente por la escasez de polisilicio. Hasta ahora ninguna de estas alternativas ha conseguido llegar a la etapa de producción, aunque algunas se encuentran cerca.

Wacker Chemie, Hemlock y Solar Grade Silicon proponen un reactor de lecho fluidizado. Este consiste en un tubo de cuarzo en el que se introduce triclorosilano (Wacker, Hemlock) o silano (SGS) por la parte inferior, junto con hidrógeno. El gas pasa a través de un lecho de partículas de silicio sobre las que ocurre el depósito, dando así partículas de tamaño mayor. Alcanzado cierto tamaño, las partículas son demasiado pesadas y caen al suelo, pudiendo ser retiradas. Este proceso no solamente utiliza una cantidad de energía mucho menor que el Siemens, sino que además puede realizarse de forma continua.

Joint Solar Silicon GmbH & Co. KG (JSSI) presenta un reactor similar al Siemens, cuyas diferencias son: a.) el silicio se deposita en un cilindro hueco de silicio en lugar de varillas; b.) se utiliza silano en lugar de triclorosilano, y por tanto la temperatura del proceso puede limitarse a 800 °C.

Tokuyama Corporation propone su proceso VLD (Vapour to Liquid Deposition). En un reactor se calienta un tubo de grafito a 1500 °C, por encima del punto de fusión del silicio. Se alimentan triclorosilano e hidrógeno por la parte superior. El silicio se deposita en las paredes de grafito en forma líquida. Por tanto, gotea en el suelo del reactor, donde solidifica en granulados y puede recogerse. El mayor gasto energético con respecto al reactor Siemens compensa por la velocidad de depósito 10 veces mayor.

Chisso Corporation y el gobierno japonés investigan un proceso a partir de la reducción de tetracloruro de silicio (SiCl4) con vapor de zinc (Zn). Se forma cloruro de cinc y silicio. Esta alternativa se desechó en los años 80 por Bayer AG ya que no se podían eliminar trazas de metales residuales. Chisso asegura que sus impurezas metálicas se encuentran en un nivel aceptable.

También se han realizado grandes esfuerzos en conseguir SoG-Si evitando el paso energéticamente costoso del uso de triclorosilano, silano o tetraclorosilano, y el posterior depósito en Siemens o similares.

Elkem purifica mg-Si en tres pasos de refino relativamente simples, pirometalúrgico, hidrometalúrgico, y de limpieza, con un consumo de solo el 20 al 25 % de la energía utilizada en la ruta Siemens. Junto con la Universidad de Constanza, han conseguido eficiencias de célula solo medio punto por debajo de las células comerciales.

Apollon Solar SAS y el laboratorio nacional de investigación francés CNRS purifican Mg-Si con un plasma. Se han conseguido células solares de un 11,7 % de eficiencia.

Otra alternativa metalúrgica es producir mg-Si con cuarzo y carbón negro tan puros que no sea necesario refinarlo más. Hay dos trabajos en paralelo: uno es el de la Universidad Nacional Técnica de Kazakh en Almaty, Kazajistán. El otro es el proyecto SOLSILC, financiado por la Comisión Europea. Las células solares fabricadas con este material han obtenido eficiencias de momento relativamente bajas. 28 por ciento de este material ya no existe.

El silicio tiene nueve isótopos, con número másico entre 25 a 33. El isótopo más abundante es el Si-28 con una abundancia del 92,23 %, el Si-29 tiene una abundancia del 4,67 % y el Si-30 que tiene una abundancia del 3,1 %. Todos ellos son estables teniendo el resto de isótopos una proporción ínfima. El Si-32 es un isótopo radiactivo que proviene del decaimiento del argón. Su tiempo de semivida es aproximadamente de unos 132 años. Padece un decaimiento beta que lo transforma en P-32 (que tiene un periodo de semivida de 14,28 días).

La inhalación del polvo de sílice cristalina puede provocar silicosis.




</doc>
<doc id="2567" url="https://es.wikipedia.org/wiki?curid=2567" title="Saturno (planeta)">
Saturno (planeta)

Saturno es el sexto planeta del sistema solar contando desde el Sol, el segundo en tamaño y masa después de Júpiter y el único con un sistema de anillos visible desde la Tierra. Su nombre proviene del dios romano Saturno. Forma parte de los denominados planetas exteriores o gaseosos. El aspecto más característico de Saturno son sus brillantes anillos. Antes de la invención del telescopio, Saturno era el más lejano de los planetas conocidos y, a simple vista, no parecía luminoso ni interesante. El primero en observar los anillos fue Galileo en 1610, pero la baja inclinación de los anillos y la baja resolución de su telescopio le hicieron pensar en un principio que se trataba de grandes lunas. Christiaan Huygens, con mejores medios de observación, pudo en 1659 observar con claridad los anillos. James Clerk Maxwell, en 1859, demostró matemáticamente que los anillos no podían ser un único objeto sólido sino que debían ser la agrupación de millones de partículas de menor tamaño. Las partículas que componen los anillos de Saturno giran a una velocidad de 48 000 km/h, 15 veces más rápido que una bala.

Debido a su posición orbital más lejana que Júpiter, los antiguos romanos le otorgaron el nombre del padre de Júpiter al planeta Saturno. En la mitología romana, Saturno era el equivalente del antiguo titán griego Crono, hijo de Urano y Gea, que gobernaba el mundo de los dioses y los hombres devorando a sus hijos en cuanto nacían para que no lo destronaran. Zeus, uno de ellos, consiguió esquivar este destino y finalmente derrocó a su padre para convertirse en el dios supremo.

Los griegos y romanos, herederos de los sumerios en sus conocimientos del cielo, habían establecido en siete el número de astros que se movían en el firmamento: el Sol, la Luna, y los planetas Mercurio, Venus, Marte, Júpiter y Saturno, las estrellas «errantes» que, a distintas velocidades, orbitaban en torno a la Tierra, centro del universo. De los cinco planetas, Saturno es el de movimiento más lento, emplea unos treinta años (29,457 años) en completar su órbita, casi el triple que Júpiter (11,862 años) y respecto a Mercurio, Venus y Marte la diferencia es mucho mayor. Saturno destacaba por su lentitud y si Júpiter era Zeus, Saturno tenía que ser Crono, el padre anciano, que paso a paso deambula entre las estrellas.

Saturno es un planeta visiblemente achatado en los polos con un ecuador que sobresale formando un esferoide ovalado. Los diámetros ecuatorial y polar son de 120 536 y 108 728 km, respectivamente. Este efecto es producido por la rápida rotación del planeta, su naturaleza fluida y su relativamente baja gravedad. Los otros planetas gigantes son también ovalados pero en menor medida. Saturno posee una densidad específica de aproximadamente 690 kg/m³, siendo el único planeta del sistema solar con una densidad inferior a la del agua (1000 kg/m³). La atmósfera del planeta está formado por un 96 % de hidrógeno y un 3 % de helio. El volumen del planeta es suficiente como para contener 740 veces la Tierra, pero su masa es solo 95 veces la terrestre, a causa de la ya mencionada baja densidad media.

El periodo de rotación de Saturno es incierto dado que no posee superficie y su atmósfera gira con un periodo distinto en cada latitud. Desde la época de los Voyager se consideraba que el periodo de rotación de Saturno, basándose en la periodicidad de señales de radio emitidas por él, era de 10 h 39 min 22,4 s (810,8°/día). Las misiones espaciales Ulysses y Cassini han mostrado que este periodo de emisión en radio varía en el tiempo, siendo en la actualidad de 10 h 45 m 45 s (± 36 s). La causa de este cambio en el periodo de rotación de radio podría estar relacionada con la actividad criovolcánica en forma de géiseres del satélite Encélado, que libera material en órbita de Saturno capaz de interactuar con el campo magnético externo del planeta, utilizado para medir la rotación del núcleo interno donde se genera. En general, se considera que el periodo de rotación interno del planeta puede ser conocido tan solo de forma aproximada.

Comparado con el planeta Tierra, el tamaño de Saturno es nueve veces mayor, y su órbita está nueve veces más lejos del Sol.Esto significa que si observamos desde el Sol a la Tierra y a Saturno cuando están en el mismo punto, en un nodo de intersección de sus órbitas, la Tierra tiene el mismo tamaño aparente que Saturno. 

Los modelos planetarios típicos consideran que el interior del planeta es semejante al de Júpiter, con un núcleo rocoso rodeado por hidrógeno, helio y trazas de otras sustancias volátiles. Sobre él se extiende una extensa capa de hidrógeno líquido, debido a los efectos de las elevadas presiones y temperaturas. Los 30 000 km exteriores del planeta están formados por una extensa atmósfera de hidrógeno y helio. El interior del planeta probablemente contenga un núcleo formado por materiales helados acumulados en la formación temprana del planeta y que se encuentran en estado líquido en las condiciones de presión y temperatura cercanas al núcleo. Este se encuentra a temperaturas en torno a 12 000 K —aproximadamente el doble de la temperatura de la superficie del Sol—.

Por otro lado, y al igual que Júpiter y Neptuno, Saturno irradia más calor al exterior del que recibe del Sol. Una parte de esta energía está producida por una lenta contracción del planeta que libera la energía potencial gravitatoria producida en la compresión. Este mecanismo se denomina mecanismo de Kelvin-Helmholtz. El calor extra generado se produce en una separación de fases entre el hidrógeno y el helio relativamente homogéneos que se están diferenciando desde la formación del planeta, liberando energía gravitatoria en forma de calor.
La atmósfera de Saturno posee un patrón de bandas oscuras y zonas claras similar al de Júpiter aunque la distinción entre ambas es mucho menos clara en el caso de Saturno. La atmósfera del planeta posee fuertes vientos en la dirección de los paralelos alternantes en latitud y altamente simétricos en ambos hemisferios a pesar del efecto estacional de la inclinación axial del planeta. El viento está dominado por una intensa y ancha corriente ecuatorial al nivel de la altura de las nubes que llegó a alcanzar velocidades de hasta 450 m/s en la época de los Voyager. A diferencia de Júpiter, no son aparentes grandes vórtices estables, aunque sí los hay más pequeños.

Es probable que las nubes superiores estén formadas por cristales de amoníaco. Sobre ellas parece extenderse una niebla uniforme sobre todo el planeta, producida por fenómenos fotoquímicos en la atmósfera superior —alrededor de 10 mbar—. A niveles más profundos —cerca de 10 bar de presión—, el agua de la atmósfera podría condensarse en una capa de nubes de agua que aún no ha podido ser observada.

Al igual que en Júpiter, ocasionalmente se forman tormentas en la atmósfera de Saturno, y algunas de ellas han podido observarse desde la Tierra. En 1933 se observó una mancha blanca situada en la zona ecuatorial por el astrónomo aficionado W. T. Hay. Era lo suficientemente grande como para ser visible con un refractor de 7 cm, pero no tardó en disiparse y desvanecerse. En 1962 empezó a desarrollarse una nueva mancha, pero no llegó nunca a destacar. En 1990 se pudo observar una gigantesca nube blanca en el ecuador de Saturno que ha sido asimilada a un proceso de formación de grandes tormentas. Se han observado manchas similares en placas fotográficas tomadas durante el último siglo y medio a intervalos de aproximadamente 30 años. En 1994 se pudo observar una segunda gran tormenta de aproximadamente la mitad de tamaño que la producida en 1990.

La sonda Cassini ha podido captar varias grandes tormentas en Saturno. Una de las mayores tormentas, con rayos 10 000 veces más potentes que los de cualquier tormenta de la Tierra, apareció el día 27 de noviembre de 2007, habiendo durado 7 meses y medio —lo que fue por un tiempo el récord de duración de una tormenta en el sistema solar—. Esta tormenta apareció en el hemisferio sur de Saturno, en una zona conocida como «callejón de las tormentas» por la elevada frecuencia con la que aparecen allí estos fenómenos. Este récord, sin embargo, ha sido batido por otra tormenta aparecida en la misma zona, que fue detectada en enero de 2009 y que duró hasta octubre de ese año. 

Una enorme tormenta, tan grande que rodeó el planeta, apareció en diciembre de 2010 en el hemisferio norte de Saturno desarrollando un vórtice central de color oscuro de 5000 kilómetros de ancho similar a la Gran Mancha Roja de Júpiter, siendo tan potente —mucho más que cualquier tormenta terrestre— que arrastró nubes de cristales de amoniaco de las profundidades de la atmósfera del planeta. Durante los aproximadamente 200 días que duró, fue estudiada con ayuda de la sonda Cassini y de telescopios terrestres, creció y se expandió hasta alcanzar un área ocho veces superior al de la Tierra, y pudieron captarse las ondas de radio producidas por el aparato eléctrico asociado a ella.

Las regiones polares presentan corrientes en chorro a 78° N y 78° S. Las sondas Voyager detectaron en los años 1980 un patrón hexagonal en la región polar norte que ha sido observado también por el telescopio espacial Hubble durante los años 1990. Las imágenes más recientes obtenidas por la sonda Cassini han mostrado el vórtice polar con gran detalle. Saturno es el único planeta conocido que posee un vórtice polar de estas características si bien los vórtices polares son comunes en las atmósferas de la Tierra o Venus.

En el caso del hexágono de Saturno, los lados tienen unos 13 800 kilómetros de longitud —algo más del diámetro de la Tierra— y la estructura rota con un periodo idéntico al de la rotación planetaria, siendo una onda estacionaria que no cambia su longitud ni estructura, como hacen el resto de nubes de la atmósfera. Estas formas poligonales entre tres y seis lados se han podido replicar mediante modelos de fluidos en rotación a escala de laboratorio.

Al contrario que el polo norte, las imágenes del polo sur muestran la presencia de una "corriente de chorro", pero no vórtices ni "ondas hexagonales persistentes". Sin embargo, NASA informó en noviembre de 2006 que la sonda Cassini había observado un "huracán" en el polo sur, con un ojo bien definido. Ojos de tormenta bien definidos solo habían sido observados en la Tierra —incluso no se ha logrado observarlo en la Gran Mancha Roja de Júpiter por la sonda Galileo—. Ese vórtice, de aproximadamente 8000 kilómetros de diámetro, ha podido ser fotografiado y estudiado con gran detalle por la sonda Cassini, midiéndose en él vientos de más de 500 kilómetros por hora.

En abril de 2010, la NASA hizo públicos unos vídeos e imágenes en los que se puede apreciar el aparato eléctrico asociado a las tormentas que se producen en la atmósfera de Saturno, la primera vez que se consigue esto.

Saturno gira alrededor del Sol a una distancia media de 1418 millones de kilómetros en una órbita de excentricidad de 0,056, que sitúa el afelio a 1 500 millones de kilómetros, y el perihelio a 1240 millones de km. Saturno se encontró en el perihelio en 1974. El periodo de traslación alrededor del Sol es de 29 años y 167 días, mientras que su período sinódico es de 378 días, de modo que, cada año, la oposición se produce con casi dos semanas de retraso respecto al año anterior. El período de rotación sobre su eje es corto, de 10 horas y 14 minutos, con algunas variaciones entre el ecuador y los polos.

Los elementos orbitales de Saturno son modificados en una escala de 900 años por una resonancia orbital de tipo 5:2 con el planeta Júpiter, bautizado por los astrónomos franceses del como "la grande inégalité" (Júpiter completa 5 vueltas por cada 2 de Saturno). Los planetas no se encuentran en una resonancia perfecta, pero están lo suficientemente cercanos a ella como para que las perturbaciones a sus respectivas órbitas sean apreciables.

Saturno tiene un gran número de satélites (82 con órbitas regulares, a fecha de 2019) el mayor de los cuales, Titán es el único satélite del sistema solar con una atmósfera importante.

Los satélites más grandes, conocidos antes del inicio de la investigación espacial son:
Mimas, Encélado, Tetis, Dione, Rea, Titán, Hiperión, Jápeto y Febe. Tanto Encélado como Titán son objetos especialmente interesantes para los científicos planetarios, ya que en el primero se cree la posible existencia de agua líquida a poca profundidad de su superficie, sobre la base de la emisión de vapor de agua en géiseres y, el segundo, presenta una atmósfera rica en metano y similar a la de la Tierra primitiva.

Otros 30 satélites de Saturno tienen nombre, pero el número exacto es incierto por existir una gran cantidad de objetos que orbitan este planeta. En el año 2000, fueron detectados 12 nuevos satélites, cuyas órbitas sugieren que son fragmentos de objetos mayores capturados por Saturno. La misión Cassini-Huygens también ha encontrado nuevos satélites, la última de ellas anunciada el 3 de marzo de 2009 y que hace la número 61 del planeta.

El disco aparente de Titán —un borroso círculo anaranjado de bordes algo más oscuros— puede verse con telescopios de aficionados a partir de los 200 mm de abertura, utilizando para ello más de 300 aumentos y cielos estables: en sus mayores aproximaciones llega a medir 0,88 segundos de arco. El resto de los satélites son mucho menores y siempre parecen estrellas, incluso a gran aumento.

Los satélites más internos pueden capturarse, sin embargo, con cualquier cámara CCD empleando focales superiores a los 2 m.

La característica más notable de Saturno son sus anillos, que dejaron muy perplejos a los primeros observadores, incluido Galileo. Su telescopio no era tan potente como para revelar la verdadera naturaleza de lo que observaba y, por error de perspectiva, creyó que se trataba de dos cuerpos independientes que flanqueaban el planeta. Pocos años después, Saturno presentaba los anillos de perfil, y Galileo quedó muy sorprendido por la brusca desaparición de los dos hipotéticos compañeros del planeta. Por fin, la existencia del sistema de anillos fue determinada por Christiaan Huygens en 1659, con la ayuda de un telescopio más potente.

Los anillos de Saturno se extienden en el plano ecuatorial del planeta desde los 6630 km a los 120 700 km por encima del ecuador de Saturno y están compuestos de partículas con abundante agua helada. El tamaño de cada una de las partículas varía desde partículas microscópicas de polvo hasta rocas de unos pocos metros de tamaño. El elevado albedo de los anillos muestra que estos son relativamente modernos en la historia del sistema solar. En un principio se creía que los anillos de Saturno eran inestables a lo largo de períodos de decenas de millones de años, otro indicio de su origen reciente, pero los datos enviados por la sonda Cassini sugieren que son mucho más antiguos de lo que se pensaba en un principio. Los anillos de Saturno poseen una dinámica orbital muy compleja presentando ondas de densidad, e interacciones con los satélites de Saturno (especialmente con los denominados satélites pastores). Al estar en el interior del límite de Roche, los anillos no pueden evolucionar hacia la formación de un cuerpo mayor.

Los anillos se distribuyen en zonas de mayor y menor densidad de material existiendo claras divisiones entre estas regiones. Los anillos principales son los llamados anillos A y B, separados entre sí por la división de Cassini. En la región interior al anillo B se distinguen otro anillo más tenue aunque extenso: C y otro anillo tenue y fino: D. En el exterior se puede distinguir un anillo delgado y débil denominado anillo F. El tenue anillo E se extiende desde Mimas hasta Rea y alcanza su mayor densidad a la distancia de Encelado, el cual se piensa lo provee de partículas, debido a las emisiones de unos géiseres que se encuentran en su polo sur.

Hasta los años 1980 la estructura de los anillos se explicaba por medio de las fuerzas gravitatorias ejercidas por los satélites cercanos. Las sondas Voyager encontraron sin embargo estructuras radiales oscuras en el anillo B llamadas "cuñas radiales" (en inglés: "spokes") que no podían ser explicadas de esta manera ya que su rotación alrededor de los anillos no era consistente con la mecánica orbital. Se considera que estas estructuras oscuras interactúan con el campo magnético del planeta, ya que su rotación sobre los anillos seguía la misma velocidad que la magnetosfera de Saturno. Sin embargo el mecanismo preciso de su formación todavía se desconoce. Es posible que las "cuñas" aparezcan y desaparezcan estacionalmente.

El 17 de agosto de 2005 los instrumentos a bordo de la nave Cassini desvelaron que existe algo similar a una atmósfera alrededor del sistema de anillos, compuesta principalmente de oxígeno molecular. Los datos obtenidos han demostrado que la atmósfera en el sistema de anillos de Saturno es muy parecida a la de las lunas de Júpiter, Europa y Ganimedes.

El 19 de septiembre de 2006 la NASA anunció el descubrimiento de un nuevo anillo en Saturno, por la nave espacial Cassini durante una ocultación solar, cuando el Sol pasa directamente detrás de Saturno y Cassini viaja en la sombra dejada por Saturno con lo que los anillos tienen una iluminación brillante. Habitualmente, una ocultación solar puede durar una hora pero el 17 de septiembre de 2006 duró 12 horas, siendo la más larga de la misión Cassini. La ocultación solar dio la oportunidad a Cassini de realizar un mapa de la presencia de partículas microscópicas que no son visibles normalmente, en el sistema de anillos.

El nuevo anillo, apenas perceptible, está entre el Anillo F y el Anillo G. Esta ubicación coincide con las órbitas de las lunas de Saturno Jano y Epimeteo, dos satélites coorbitales de Saturno cuyas distancias al centro de Saturno se diferencian menos que el tamaño de dichos satélites, por lo que describen una extraña danza que los lleva a intercambiar sus órbitas. Los investigadores de la NASA aseguraron que el impacto de meteoros en esas lunas ha hecho que otras partículas se unan al anillo.

Las cámaras a bordo de la nave Cassini captaron imágenes de un material helado que se extiende decenas de miles de kilómetros desde Encélado, otra confirmación de que la luna está lanzando material que podría formar el anillo E. El satélite Encélado pudo ser visto a través del anillo E con sus chorros saliendo de su superficie semejando "dedos", dirigidos al anillo en cuestión. Estos chorros están compuestos de partículas heladas muy delgadas, que son expulsadas por los géiseres del Polo Sur de Encelado y entran en el anillo E.

«Tanto el nuevo anillo como las estructuras inesperadas del E nos dan una importante pista de cómo las lunas pueden lanzar pequeñas partículas y esculpir sus propios ambientes locales», dijo Matt Hedman, un investigador asociado a la Universidad Cornell en Ithaca, Nueva York.

La nave también tomó una fotografía en color de la Tierra, a cerca de 1 500 millones de kilómetros de distancia, en la que parece una esfera azul claro. En otra imagen, tomada en la misma fecha, puede apreciarse también la Luna. 

Carolyn Porco, responsable del equipo que opera las cámaras de la sonda Cassini en el Instituto de Ciencia Espacial de Boulder, en Colorado, dijo al respecto:

La NASA también anunció el 24 de octubre de 2007 el descubrimiento de un cinturón de microlunas en el borde exterior del anillo A y cuyo tamaño varía desde el de un camión pequeño al de un estadio, probablemente causado por la destrucción de una luna pequeña.

En octubre de 2009 el telescopio espacial Spitzer descubre un nuevo y enorme anillo alrededor de Saturno, mucho más grande de los que le rodean. Después de muchos siglos, este había pasado desapercibido hasta ahora, porque está tan enrarecido que resulta casi invisible. Este nuevo cinturón se despliega en el confín del sistema saturniano. Su masa comienza a unos seis millones de kilómetros del planeta y se extiende hasta alcanzar 13 millones de kilómetros de diámetro. Uno de los más lejanos satélites de Saturno, Febe, órbita dentro del nuevo anillo, y probablemente sea la fuente de su composición.

El campo magnético de Saturno es mucho más débil que el de Júpiter, y su magnetosfera es una tercera parte de la de Júpiter. La magnetosfera de Saturno consta de un conjunto de cinturones de radiación toroidales en los que están atrapados electrones y núcleos atómicos. Los cinturones se extienden unos dos millones de kilómetros desde el centro de Saturno, e incluso más, en dirección contraria al Sol, aunque el tamaño de la magnetosfera varía dependiendo de la intensidad del viento solar (el flujo desde el Sol de las partículas cargadas). El viento solar y los satélites y anillos de Saturno suministran las partículas que están atrapadas en los cinturones de radiación. El periodo de rotación de 10 horas, 39 minutos y 25 segundos del interior de Saturno fue medido por el Voyager 1 mientras atravesaba la magnetosfera, que gira de forma sincrónica con el interior de Saturno. La magnetosfera interactúa con la ionosfera, la capa superior de la atmósfera de Saturno, causando emisiones aurorales de radiación ultravioleta; recientes estudios muestran que en el polo norte del planeta existe en vez de un anillo de varias auroras menores cómo en Júpiter o la Tierra una única gran aurora de forma anillada.

Rodeando la órbita de Titán, y extendiéndose hasta la órbita de Rea, se encuentra una enorme nube toroidal de átomos de hidrógeno neutro. Un disco de plasma, compuesto de hidrógeno y posiblemente de iones oxígeno, se extiende desde fuera de la órbita de Tetis hasta casi la de Titán. El plasma gira en sincronía casi perfecta con el campo magnético de Saturno.

Visto desde la Tierra, Saturno aparece como un objeto amarillento, uno de los más brillantes en el cielo nocturno. Observado a través de un telescopio, los anillos A y B se ven fácilmente, mientras que los D y E solo se ven en condiciones atmosféricas óptimas. Con telescopios de gran sensibilidad situados en la Tierra se distinguen, en la niebla de la envoltura gaseosa de Saturno, pálidos cinturones y estructuras de bandas paralelas al ecuador.

Tres naves espaciales estadounidenses incrementaron enormemente el conocimiento del sistema de Saturno: la sonda Pioneer 11 y las Voyager 1 y 2, que sobrevolaron el planeta en septiembre de 1979, noviembre de 1980 y agosto de 1981, respectivamente. Estas naves espaciales llevaban cámaras e instrumentos para analizar las intensidades y polarizaciones de la radiación en las regiones visible, ultravioleta, infrarroja y de radio del espectro electromagnético. También estaban equipadas con instrumentos para el estudio de los campos magnéticos y para la detección de partículas cargadas y granos de polvo interplanetario.

En octubre de 1997 fue lanzada la nave Cassini, con destino a Saturno, que incluía también la sonda Huygens para explorar Titán, la mayor y más interesante de las lunas del planeta. Se trata del último proyecto de gran presupuesto de la NASA, en colaboración con la Agencia Espacial Europea y la Agencia Espacial Italiana. Tras un viaje de casi siete años, estaba previsto que la Cassini recogiese datos sobre Saturno y sus satélites durante otros cuatro años. En octubre de 2002 la nave obtuvo su primera fotografía del planeta, tomada a una distancia de 285 millones de kilómetros, y en la que aparece también Titán. En junio de 2004 la Cassini sobrevoló Febe, otro satélite de Saturno (el más alejado), obteniendo imágenes espectaculares de su superficie, llena de cráteres. En julio del mismo año, la nave entró en órbita de Saturno. En enero de 2005 la sonda Huygens atravesó la atmósfera de Titán y alcanzó su superficie, enviando a la Tierra datos e imágenes de gran interés del satélite.


Saturno es un planeta fácil de observar, pues es visible en el cielo la mayor parte del tiempo y sus anillos pueden observarse con cualquier telescopio de aficionado. Se observa mejor cuando el planeta está cerca o en oposición, es decir, la posición de un planeta cuando está a una elongación de 180°, por lo que aparece opuesto al Sol en el cielo. En la oposición del 13 de enero de 2005, Saturno pudo verse con un máximo que no será igualado hasta 2031, debido a una orientación de sus anillos con respecto a la Tierra bastante favorable.

Saturno se observa a simple vista en el cielo nocturno como un punto luminoso (que no parpadea) brillante y amarillento cuyo brillo varía normalmente entre la magnitud +1 y la 0, toma aproximadamente 29 años y medio en realizar una traslación completa en su órbita con respecto a las estrellas de fondo pertenecientes al zodiaco. Con apoyo óptico, como con grandes binoculares o un telescopio, se necesita una magnificación de al menos 20x para que la mayoría de las personas puedan distinguir claramente los anillos de Saturno.

En la astrología hindú, hay nueve planetas, conocidos como Navagrahas. Conocen a Saturno como "Sani" o "Shani", el Juez entre todos los planetas, y determina a cada uno según sus propios hechos realizados malos o buenos.

La Cultura china y japonesa designan a Saturno como la estrella de la tierra dentro del esquema tradicional oriental de utilizar cinco elementos para clasificar los elementos naturales.

En el hebreo, llaman "Shabbathai" a Saturno. Su Ángel es "Cassiel". Su Inteligencia, o el espíritu beneficioso, son "Agiel" (layga), y su espíritu (el aspecto más oscuro) es "Zazel" (lzaz). Ver: Cábala.

En turco y malayo, su nombre es "Zuhal", tomado del árabe زحل.

Saturno fue también conocido como "Φαίνων" por los griegos.





</doc>
<doc id="2570" url="https://es.wikipedia.org/wiki?curid=2570" title="Sol">
Sol

El Sol (del latín "sol", "solis", «dios Sol "invictus"» o «sol», Helios en la mitología griega, a su vez de la raíz protoindoeuropea "sauel-", «brillar») es una estrella de tipo-G de la secuencia principal y clase de luminosidad V que se encuentra en el centro del sistema solar y constituye la mayor fuente de radiación electromagnética de este sistema planetario. Es una esfera casi perfecta de plasma, con un movimiento convectivo interno que genera un campo magnético a través de un proceso de dinamo. Cerca de tres cuartas partes de la masa del Sol constan de hidrógeno; el resto es principalmente helio, con cantidades mucho más pequeñas de elementos, incluyendo el oxígeno, carbono, neón y hierro.

Se formó hace aproximadamente 4600 millones de años a partir del colapso gravitacional de la materia dentro de una región de una gran nube molecular. La mayor parte de esta materia se acumuló en el centro, mientras que el resto se aplanó en un disco en órbita que se convirtió en el sistema solar. La masa central se volvió cada vez más densa y caliente, dando lugar con el tiempo al inicio de la fusión nuclear en su núcleo. Se cree que casi todas las estrellas se forman por este proceso. El Sol es más o menos de edad intermedia y no ha cambiado drásticamente desde hace más de cuatro mil millones de años, y seguirá siendo bastante estable durante otros cinco mil millones de años más. Sin embargo, después de que la fusión del hidrógeno en su núcleo se haya detenido, el Sol sufrirá cambios importantes y se convertirá en una gigante roja. Se estima que el Sol se volverá lo suficientemente grande como para engullir las órbitas actuales de Mercurio, Venus y posiblemente la Tierra.

La Tierra y otros cuerpos (incluidos otros planetas, asteroides, meteoroides, cometas y polvo) orbitan alrededor del Sol. Por sí solo, representa alrededor del 99,86% de la masa del sistema solar. La distancia media del Sol a la Tierra fue definida exactamente por la Unión Astronómica Internacional en (aproximadamente 150 millones de kilómetros). Su luz recorre esta distancia en 8 minutos y 20 segundos. 

La energía del Sol, en forma de luz solar, sustenta a casi todas las formas de vida en la Tierra a través de la fotosíntesis, y determina el clima de la Tierra y la meteorología.

Es la estrella del sistema planetario en el que se encuentra la Tierra; por lo tanto, es el astro con mayor brillo aparente. Su visibilidad en el cielo local determina, respectivamente, el día y la noche en diferentes regiones de diferentes planetas. En la Tierra, la energía radiada por el Sol es aprovechada por los seres fotosintéticos que constituyen la base de la cadena trófica, siendo así la principal fuente de energía de la vida. También aporta la energía que mantiene en funcionamiento los procesos climáticos. 

El Sol es una estrella que se encuentra en la fase denominada secuencia principal, con un tipo espectral G2 y clase de luminosidad V, por tanto, también es denominada como enana amarilla, se formó entre 4567,9 y 4570,1 millones de años y permanecerá en la secuencia principal aproximadamente 5000 millones de años más. El Sol, junto con todos los cuerpos celestes que orbitan a su alrededor, incluida la Tierra, forman el sistema solar.

A pesar de ser una estrella enana, es la única cuya forma se puede apreciar a simple vista, con un diámetro angular de 32′35″ de arco en el perihelio y 31′31″ en el afelio, lo que da un diámetro medio de 32′03″. La combinación de tamaños y distancias del Sol y la Luna son tales que se ven, aproximadamente, con el mismo tamaño aparente en el cielo. Esto permite una amplia gama de eclipses solares distintos (totales, anulares o parciales).

El vasto efecto del Sol sobre la Tierra ha sido reconocido desde tiempos prehistóricos y ha sido considerado por algunas culturas como una deidad. El movimiento de la Tierra alrededor del Sol es la base del calendario solar, el cual es el calendario predominante en uso hoy en día.

La disciplina científica que se encarga del estudio del Sol en su totalidad es la física solar.

El Sol es una estrella de tipo-G de la secuencia principal que abarca aproximadamente el 99,86% de la masa del sistema solar. El Sol tiene una magnitud absoluta de +4,83, estimada como más brillante que el 85% de las estrellas de la Vía Láctea, la mayoría de las cuales son enanas rojas. El Sol pertenece a la Población I, o a las estrellas ricas en elementos pesados. La formación del Sol pudo haber sido provocado por ondas de choque de una o más supernovas próximas. Esto fue planteado debido a la gran abundancia de elementos pesados en el sistema solar, como el oro y el uranio, en relación con las abundancias de estos elementos en la llamada Población II de estrellas, siendo éstas pobres en elementos pesados. Estos elementos podrían haberse producido por reacciones nucleares endotérmicas durante una supernova, o por transmutación a través de la absorción neutrónica dentro de una estrella masiva de segunda generación.

El Sol es, con diferencia, el objeto más brillante en el cielo, con magnitud aparente de -26,74. Es unos 13 000 millones de veces más brillante que la segunda estrella más luminosa, Sirio, que tiene una magnitud aparente de -1.46. La distancia media del centro del Sol al centro de la Tierra es de aproximadamente 1 unidad astronómica (alrededor de 150 millones de kilómetros), aunque la distancia varía a medida que la Tierra se mueve desde el perihelio en enero hasta el afelio en julio. En esta distancia media, la luz viaja desde el horizonte del Sol hasta el horizonte de la Tierra en unos 8 minutos y 19 segundos, mientras que la luz desde los puntos más cercanos del Sol y de la Tierra tarda aproximadamente dos segundos menos. 

El Sol no tiene un límite definido y en sus partes externas su densidad disminuye exponencialmente al aumentar la distancia desde su centro. No obstante, a efectos de medición, se considera el radio solar como la distancia que engloba desde su centro hasta el borde de la fotosfera, la superficie visible aparente del Sol. Con base en esta medida, el Sol es una esfera casi perfecta con un achatamiento estimado de 9 millonésimas, lo que significa que su diámetro polar difiere de su diámetro ecuatorial por tan solo 10 kilómetros. El efecto mareal de los planetas es débil y no afecta significativamente a la forma del Sol. El Sol rota más deprisa por su ecuador que por sus polos. Esta rotación diferencial es causada por el movimiento de convección debido al transporte de calor y al efecto coriolis producido por la rotación del Sol. En un marco de referencia definido por las estrellas, el periodo de rotación es de aproximadamente 25,6 días en el ecuador y de 33,5 días en los polos. Visto desde la Tierra en su órbita alrededor del Sol, el período de rotación aparente del Sol en su ecuador es de unos 28 días.

La constante solar es la cantidad de energía que el Sol deposita por unidad de tiempo y superficie y que es directamente expuesta como luz solar. La constante solar es igual a aproximadamente 1368 W/m² (vatios por metro cuadrado) a una distancia de una unidad astronómica (ua) del Sol (es decir, en la Tierra o a la misma distancia del Sol que ella). La luz del Sol en la superficie de la Tierra es atenuada por la atmósfera terrestre, de modo que, llega menos energía a la superficie (cerca de 1000 W/m²) en condiciones claras cuando el Sol está cerca del cenit. La luz del Sol en la parte superior de la atmósfera terrestre está compuesta (por energía total) de aproximadamente un 50% de luz infrarroja, un 40% por luz visible y un 10% de luz ultravioleta. La atmósfera terrestre filtra más del 70% de la radiación ultravioleta solar, especialmente en las longitudes de onda más cortas. La radiación ultravioleta solar ioniza la parte superior de la atmósfera del lado diurno de la Tierra, haciendo a la ionosfera conductora de electricidad.

El color del Sol es blanco con un índice de color-espacio (CIE) cercano al (0,3; 0,3) cuando se ve desde el espacio o desde lo alto en el cielo; en cambio, cuando se está desde una zona baja del cielo la dispersión atmosférica del Sol tiene un color amarillo, rojo, naranja y magenta. A pesar de su blancura típica, la mayoría de la gente se imagina el Sol como amarillo; las razones de ello son objeto de debate. El Sol es una estrella G2V, con "G2" indica que su temperatura superficial es de aproximadamente 5778 K (5505 °C), y "V" que, como la mayoría de las estrellas, es una estrella enana de la secuencia principal. La luminancia media del Sol es de aproximadamente 1,88 giga candelas por metro cuadrado, pero como se ve a través de la atmósfera de la Tierra, esto se reduce a aproximadamente 1,44 Gcd/m². Sin embargo, la luminancia no es constante a través del disco del Sol (oscurecimiento del limbo).

El Sol está compuesto principalmente por los elementos químicos hidrógeno y helio; que representan el 74,9% y el 23,8% de la masa del Sol en la fotosfera, respectivamente. Todos los elementos más pesados, llamados "metales" en astronomía, representan menos del 2% de la masa, con el oxígeno (más o menos el 1% de la masa del Sol), carbono (0,3%), neón (0,2%), y el hierro (0,2%) siendo el más abundante.

El Sol heredó su composición química del medio interestelar a través del cual se formó. El hidrógeno y el helio en el Sol fueron producidos por nucleosíntesis del Big Bang, y los elementos más pesados se crearon por nucleosíntesis estelar en generaciones de estrellas que completaron su evolución estelar y devolvieron su material al medio interestelar antes de la formación del Sol. La composición química de la fotosfera se considera normalmente como representativa de la composición del sistema solar primordial. Sin embargo, desde que se formó el Sol, parte del helio y de elementos pesados se han asentado gravitacionalmente desde la fotosfera. Por lo tanto, en la fotosfera de hoy en día, la fracción de helio es reducida, y la metalicidad es solo el 84% de lo que era en la fase protoestelar (antes de que la fusión nuclear comenzara en el núcleo). Se cree que la composición protoestelar del Sol ha sido de un 71,1% de hidrógeno, 27,4% de helio, y de un 1,5% de elementos más pesados.

Hoy en día, la fusión nuclear en el núcleo del Sol ha modificado la composición mediante la conversión del hidrógeno en helio, por lo que ahora la parte más interna del Sol es más o menos un 60% de helio, junto con la abundancia de elementos más pesados sin ser alterados. Debido a que el calor se transfiere desde el centro del Sol por radiación en vez de por convección, ninguno de los productos de fusión del núcleo han llegado a la fotosfera.

La zona reactiva del núcleo de «combustión del hidrógeno», donde el hidrógeno se convierte en helio, está empezando a ser circundado por un núcleo interno de «cenizas de helio». Este desarrollo continuará y posteriormente tendrá lugar la salida del Sol de la secuencia principal para llegar a convertirse así en una gigante roja.

La abundancia de elementos pesados solares descritos anteriormente son medidos usando tanto espectroscopia de la fotosfera del Sol como midiendo las abundancias en los meteoritos que nunca han sido calentados a temperaturas de fusión. Se cree que estos meteoritos retienen la composición del Sol protoestelar y, por lo tanto, no se ve afectado por la sedimentación de elementos pesados. Por lo general los dos métodos concuerdan bien.

Como toda estrella, el Sol posee una forma esférica, y a causa de su lento movimiento de rotación, tiene también un leve achatamiento polar. Como en cualquier cuerpo masivo, toda la materia que lo constituye es atraída hacia el centro del objeto por su propia fuerza gravitatoria. Sin embargo, el plasma que forma el Sol se encuentra en equilibrio, ya que la creciente presión en el interior solar compensa la atracción gravitatoria, lo que genera un equilibrio hidrostático. Estas enormes presiones se producen debido a la densidad del material en su núcleo y a las enormes temperaturas que se dan en él gracias a las reacciones termonucleares que allí acontecen. Existe, además de la contribución puramente térmica, una de origen fotónico. Se trata de la presión de radiación, nada despreciable, que es causada por el ingente flujo de fotones emitidos en el centro del Sol.

Casi todos los elementos químicos terrestres (aluminio, azufre, bario, cadmio, calcio, carbono, cerio, cobalto, cobre, cromo, estaño, estroncio, galio, germanio, helio, hidrógeno, hierro, indio, magnesio, manganeso, níquel, nitrógeno, oro, oxígeno, paladio, plata, platino, plomo, potasio, rodio, silicio, sodio, talio, titanio, tungsteno, vanadio, circonio y zinc) y diversos compuestos (como el cianógeno, el óxido de carbono y el amoniaco) han sido identificados en la constitución del astro rey, por lo que se ha concluido que, si nuestro planeta se calentara hasta la temperatura solar, tendría un espectro luminoso casi idéntico al Sol. Incluso el helio fue descubierto primero en el Sol y luego se constató su presencia en nuestro planeta.

El Sol presenta una estructura en capas esféricas o en «capas de cebolla». La frontera física y las diferencias químicas entre las distintas capas son difíciles de establecer. Sin embargo, se puede determinar una función física que es diferente para cada una de las capas. En la actualidad, la astrofísica dispone de un modelo de estructura solar que explica satisfactoriamente la mayor parte de los fenómenos observados. Según este modelo, el Sol está formado por: 1) núcleo solar, 2) zona radiante, 3) zona convectiva, 4) fotosfera, 5) cromosfera, 6) corona, 7) manchas solares, 8) granulación y 9) viento solar.

Ocupa unos del radio solar, 1/5 del mismo, y es en esta zona donde se verifican las reacciones termonucleares que proporcionan toda la energía que el Sol produce. Esta energía generada en el núcleo del Sol tarda un millón de años para alcanzar la superficie solar. En su centro se calcula que existe un 49 por ciento de hidrógeno, 49 por ciento de helio y un 2 por ciento que se distribuye en otros elementos que sirven como catalizadores en las reacciones termonucleares. A comienzos de la década de los años 30 del siglo XX, el físico austriaco Fritz Houtermans (1903-1966) y el astrónomo inglés Robert d'Escourt Atkinson (1898-1982) unieron sus esfuerzos para averiguar si la producción de energía en el interior del Sol y en las estrellas se podía explicar por las transformaciones nucleares. En 1938 Hans Albrecht Bethe (1906-2005), en los Estados Unidos, y Carl Friedrich von Weizsäcker (1912-2007), en Alemania, simultánea e independientemente, encontraron el hecho notable de que un grupo de reacciones en las que intervienen el carbono y el nitrógeno como catalizadores constituyen un ciclo, que se repite una y otra vez, mientras dura el hidrógeno. A este grupo de reacciones se les conoce como ciclo de Bethe o del carbono, y es equivalente a la fusión de cuatro protones en un núcleo de helio. En estas reacciones de fusión hay una pérdida de masa, esto es, el hidrógeno consumido pesa más que el helio producido. Esa diferencia de masa se transforma en energía, según la ecuación de Einstein (E = mc²), donde E es la energía, m la masa y c la velocidad de la luz. Estas reacciones nucleares transforman el 0,7 por ciento de la masa afectada en fotones, con una longitud de onda cortísima y, por lo tanto, muy energéticos y penetrantes. La energía producida mantiene el equilibrio térmico del núcleo solar a temperaturas aproximadamente de 15 millones de kelvins.

El ciclo ocurre en las siguientes etapas:


La energía neta liberada en el proceso es 26,7 MeV, o sea cerca de 6,7·10 J por kg de protones consumidos. El carbono actúa como catalizador, pues al final del ciclo se regenera.

Otra reacción de fusión que ocurre en el Sol y en las estrellas es el ciclo de Critchfiel o, más comúnmente conocido como cadena protón-protón. Charles Critchfield (1910-1994) era en 1938 un joven físico, alumno de George Gamow, (1904-1968) en la Universidad George Washington, y tuvo una idea completamente diferente, al darse cuenta que en el choque entre dos protones a velocidades próximas a la de la luz, puede ocurrir que uno de ellos pierda su carga positiva (e+), se fusionen y se convierta en un neutrón, que permanece unido al otro protón y forma un núcleo de deuterio, es decir, un núcleo pesado formado por un isótopo estable del hidrógeno. El positrón (e+) al ser liberado tiende a aniquilarse con bastante rapidez, fusionándose con un electrón (e-), produciendo en el proceso radiación fotónica. Al mismo tiempo, en esta segunda fase, se libera un neutrino electrónico de baja energía, que no interactúa con ningún átomo y se libera al espacio a velocidades próximas a la de luz sin colisionar con la materia.

Más tarde, la fusión de un protón (p+), o lo que es lo mismo, un núcleo H, con un núcleo de deuterio da lugar a un isótopo del helio He³ y a la emisión de fotones gamma (γ). Finalmente, con un 97% de probabilidad aproximadamente, dos núcleos del isótopo He³ dan lugar, al ser fusionados, en un núcleo estable de He más dos nuevos protones (p+), con lo que el ciclo se retroalimenta hasta la primera fase inicial, al tiempo que pierde energía a razón de 26,7 MeV netos.

La reacción puede producirse de dos maneras algo distintas:

El primer ciclo se da en estrellas más calientes y con mayor masa que el Sol, y la cadena protón-protón en las estrellas similares al Sol. En cuanto al Sol, hasta el año 1953 se creyó que su energía era producida casi exclusivamente por el ciclo de Bethe, pero se demostró durante estos últimos años que el calor solar proviene en su mayor parte (~75%) del ciclo protón-protón.

En los últimos estadios de su evolución, el Sol fusionará también el helio producto de estos procesos para dar carbono y oxígeno (véase proceso triple-alfa).

En la zona exterior al núcleo el transporte de la energía generada en el interior se produce por radiación hasta el límite exterior de la zona radiactiva. Esta zona está compuesta de plasma, es decir, grandes cantidades de hidrógeno y helio ionizado. Como la temperatura del Sol decrece del centro (15 MK) a la periferia (6 kK en la fotosfera), es más fácil que un fotón cualquiera se mueva del centro a la periferia que al revés. Sin embargo, los fotones deben avanzar por un medio ionizado tremendamente denso siendo absorbidos y reemitidos infinidad de veces en su camino. Se calcula que un fotón cualquiera puede tardar un millón de años en alcanzar la superficie y manifestarse como luz visible.

Esta región se extiende por encima de la zona radiante, y en ella los gases solares dejan de estar ionizados y los fotones son absorbidos con facilidad y se convierten en un material opaco al transporte de radiación. Por lo tanto, el transporte de energía se realiza por convección, de modo que el calor se transporta de manera no homogénea y turbulenta por el propio fluido. Los fluidos se dilatan al ser calentados y disminuyen su densidad. Por lo tanto, se forman corrientes ascendentes de material desde la zona caliente hasta la zona superior, y simultáneamente se producen movimientos descendentes de material desde las zonas exteriores menos calientes. Así, a unos bajo la fotosfera del Sol, el gas se vuelve opaco por efecto de la disminución de la temperatura; en consecuencia, absorbe los fotones procedentes de las zonas inferiores y se calienta a expensas de su energía. Se forman así secciones convectivas turbulentas, en las que las "parcelas" de gas caliente y ligero suben hasta la fotosfera, donde nuevamente la atmósfera solar se vuelve transparente a la radiación y el gas caliente cede su energía en forma de luz visible, y se enfría antes de volver a descender a las profundidades. El análisis de las oscilaciones solares ha permitido establecer que esta zona se extiende hasta estratos de gas situados a la profundidad indicada anteriormente. La observación y el estudio de estas oscilaciones solares constituyen el campo de trabajo de la heliosismología.

La fotosfera es la zona visible donde se emite luz visible del Sol. La fotosfera se considera como la «superficie» solar y, vista a través de un telescopio, se presenta formada por gránulos brillantes que se proyectan sobre un fondo más oscuro. A causa de la agitación de nuestra atmósfera, estos gránulos parecen estar siempre en agitación. Puesto que el Sol es gaseoso, su fotosfera es algo transparente: puede ser observada hasta una profundidad de unos cientos de kilómetros antes de volverse completamente opaca. Normalmente se considera que la fotosfera solar tiene unos 100 o 200 km de profundidad.

Aunque el borde o limbo del Sol aparece bastante nítido en una fotografía o en la imagen solar proyectada con un telescopio, se aprecia fácilmente que el brillo del disco solar disminuye hacia el borde. Este fenómeno de oscurecimiento del centro al limbo es consecuencia de que el Sol es un cuerpo gaseoso con una temperatura que disminuye con la distancia al centro. La luz que se ve en el centro procede en la mayor parte de las capas inferiores de la fotosfera, más caliente y por tanto más luminosa. Al mirar hacia el limbo, la dirección visual del observador es casi tangente al borde del disco solar por lo que llega radiación procedente sobre todo de las capas superiores de la fotosfera, menos calientes y emitiendo con menor intensidad que las capas profundas en la base de la fotosfera.

Un fotón tarda un promedio de 10 días desde que surge de la fusión de dos átomos de hidrógeno, en atravesar la zona radiante y un mes en recorrer los 200 000 km de la zona convectiva, empleando tan solo unos 8 minutos y medio en cruzar la distancia que separa la Tierra del Sol. No se trata de que los fotones viajen más rápidamente ahora, sino que en el exterior del Sol el camino de los fotones no se ve obstaculizado por los continuos cambios, choques, quiebros y turbulencias que experimentaban en el interior del Sol.

Los gránulos brillantes de la fotosfera tienen muchas veces forma hexagonal y están separados por finas líneas oscuras. Los gránulos son la evidencia del movimiento convectivo y burbujeante de los gases calientes en la parte exterior del Sol. En efecto, la fotosfera es una masa en continua ebullición en el que las células convectivas se aprecian como gránulos en movimiento cuya vida media es tan solo de unos nueve minutos. El diámetro medio de los gránulos individuales es de unos 700 a 1000 km y resultan particularmente notorios en los períodos de mínima actividad solar. Hay también movimientos turbulentos a una escala mayor, la llamada "«supergranulación»", con diámetros típicos de unos . Cada supergranulación contiene cientos de gránulos individuales y sobrevive entre 12 a 20 horas. Fue Richard Christopher Carrington (1826-1875), cervecero y astrónomo aficionado, el primero en observar la granulación fotosférica en el siglo XIX. En 1896 el francés Pierre Jules César Janssen (1824-1907) consiguió fotografiar por primera vez la granulación fotosférica.
El signo más evidente de actividad en la fotosfera son las manchas solares. En los tiempos antiguos se consideraba al Sol como un fuego divino y, por consiguiente, perfecto e infalible. Del mismo modo se sabía que la brillante cara del Sol estaba a veces nublada con unas manchas oscuras, pero se imaginaba que era debido a objetos que pasaban en el espacio entre el Sol y la Tierra. Cuando Galileo (1564-1642) construyó el primer telescopio astronómico, dando origen a una nueva etapa en el estudio del Universo, hizo la siguiente afirmación: "«Repetidas observaciones me han convencido, de que estas manchas son sustancias en la superficie del Sol, en la que se producen continuamente y en la que también se disuelven, unas más pronto y otras más tarde»". Una mancha solar típica consiste en una región central oscura, llamada «umbra», rodeada por una «penumbra» más clara. Una sola mancha puede llegar a medir hasta (casi tan grande como el diámetro de la Tierra), pero un grupo de manchas puede alcanzar de extensión e incluso algunas veces más. La penumbra está constituida por una estructura de filamentos claros y oscuros que se extienden más o menos radialmente desde la umbra. Ambas (umbra y penumbra) parecen oscuras por contraste con la fotosfera, simplemente porque están menos calientes que la temperatura media de la fotosfera. Así, la umbra tiene una temperatura de 4000K, mientras que la penumbra alcanza los 5600K, inferiores en ambos casos a los 6000 K que tienen los gránulos de la fotosfera. Por la ley de Stefan-Boltzmann, en que la energía total radiada por un cuerpo negro (como una estrella) es proporcional a la cuarta potencia de su temperatura efectiva (E = σT, donde σ = 5,67051·10 W/m²·K), la umbra emite aproximadamente un 32% de la luz emitida por un área igual de la fotosfera y análogamente la penumbra tiene un brillo de un 71% de la fotosfera. La oscuridad de una mancha solar está causada únicamente por un efecto de contraste; si pudiéramos ver a una mancha tipo, con una umbra del tamaño de la Tierra, aislada y a la misma distancia que el Sol, brillaría una 50 veces más que la Luna llena. Las manchas están relativamente inmóviles con respecto a la fotosfera y participan de la rotación solar. El área de la superficie solar cubierta por las manchas se mide en términos de millonésima del disco visible.

La cromosfera es una capa exterior a la fotosfera visualmente mucho más transparente. Su tamaño es de aproximadamente , y es imposible observarla sin filtros especiales, pues es eclipsada por el mayor brillo de la fotosfera. La cromosfera puede observarse durante un eclipse solar en un tono rojizo característico y en longitudes de onda específicas, notablemente en Hα, una longitud de onda característica de la emisión por hidrógeno a muy alta temperatura.

Las prominencias solares ascienden ocasionalmente desde la fotosfera, alcanzan alturas de hasta y producen erupciones solares espectaculares.

La corona solar está formada por las capas más tenues de la atmósfera superior solar. Su temperatura alcanza los millones de kelvin, una cifra muy superior a la de la capa que le sigue, la fotosfera, siendo esta inversión térmica uno de los principales enigmas de la ciencia solar reciente. Estas elevadísimas temperaturas son un dato engañoso y consecuencia de la alta velocidad de las pocas partículas que componen la atmósfera solar. Sus grandes velocidades son debidas a la baja densidad del material coronal, a los intensos campos magnéticos emitidos por el Sol y a las ondas de choque que rompen en la superficie solar estimuladas por las células convectivas. Como resultado de su elevada temperatura, desde la corona se emite gran cantidad de energía en rayos X. En realidad, estas temperaturas no son más que un indicador de las altas velocidades que alcanza el material coronal que se acelera en las líneas de campo magnético y en dramáticas eyecciones de material coronal (EMCs). Lo cierto es que esa capa es demasiado poco densa como para poder hablar de temperatura en el sentido usual de agitación térmica.

Todos estos fenómenos combinados ocasionan extrañas rayas en el espectro luminoso que hicieron pensar en la existencia de un elemento desconocido en la Tierra al que incluso denominaron "coronium" hasta que investigaciones posteriores en 1942 concluyeron que se trataban de radiaciones producidas por átomos neutros de oxígeno de la parte externa de la misma corona, así como de hierro, níquel, calcio y argón altamente ionizados (fenómenos imposibles de obtener en laboratorios).

La corona solar solamente es observable desde el espacio con instrumentos adecuados que anteponen un disco opaco para eclipsar artificialmente al Sol o durante un eclipse solar natural desde la Tierra. El material tenue de la corona es continuamente expulsado por la fuerte radiación solar dando lugar a un viento solar. Así pues, se cree que las estructuras observadas en la corona están modeladas en gran medida por el campo magnético solar y las células de transporte convectivo.

En 1970 el físico sueco Hannes Alfvén obtuvo el premio Nobel. Él estimó que había ondas que transportaban energía por líneas del campo magnético que recorre el plasma de la corona solar. Pero hasta hoy no se había podido detectar la cantidad de ondas que eran necesarias para producir dicha energía.

Pero imágenes de alta definición ultravioleta, tomadas cada ocho segundos por el satélite de la NASA Solar Dymanics Observatory (SDO), han permitido a científicos como Scott McIntosh y a sus colegas del Centro Nacional Estadounidense de Investigación Atmosférica, detectar gran cantidad de estas ondas. Las mismas se propagan a gran velocidad (entre 200 y 250 kilómetros por segundo) en el plasma en movimiento. Ondas cuyo flujo energético se sitúa entre 100 y 200 vatios por kilómetro cuadrado «son capaces de proveer la energía necesaria para propulsar a los rápidos vientos solares y así compensar las pérdidas de calor de las regiones menos agitadas de la corona solar», estiman los investigadores.

Sin embargo, para McIntosh esto no es suficiente para generar los 2000 vatios por metro cuadrado que se necesitan para abastecer a las zonas activas de la corona. Es por esto que se requiere de instrumentos con mayor capacidad temporal y espacial para estudiar todo el espectro de energía irradiada en las regiones activas de nuestra estrella.

La heliosfera sería la región que se extiende desde el Sol hasta más allá de Plutón y que se encuentra bajo la influencia del viento solar. Es en esta región donde se extienden los efectos de las tormentas geomagnéticas y también donde se extiende el influyo del campo magnético solar. La heliosfera protege al sistema solar de las radiaciones provenientes del medio interestelar y su límite se extiende a más de 100 UA del Sol, límite solo superado por los cometas.

La eyección de masa coronal (CME) es una onda hecha de radiación y viento solar que se desprende del Sol en el periodo llamado Actividad Máxima Solar. Esta onda es muy peligrosa ya que daña los circuitos eléctricos, los transformadores y los sistemas de comunicación. Cuando esto ocurre, se dice que hay una tormenta solar.

El campo magnético del sol se forma como sigue: En el núcleo, las presiones del hidrógeno provocan que sus átomos únicamente queden excluidos por las fuerzas de polaridad de los protones, dejando una nube de electrones en torno a dicho núcleo (los electrones se han desprendido de las órbitas tradicionales, formando una capa de radiación electrónica común). La fusión de los átomos de hidrógeno en helio se produce en la parte más interna del núcleo, en donde el helio queda restringido por ser un material más pesado. Dicho 'ordenamiento' induce que los propios electrones compartan estados de energía y en consecuencia sus campos magnéticos adquieran aún más densidad y potencia. Las enormes fuerzas de gravedad, impiden que los fotones (portadores de esas fuerzas) escapen de forma libre. De esta forma se genera en su interior un potente campo magnético que influye en la dinámica del plasma en las capas siguientes.

Los campos magnéticos, tal como si se tratase de un material fluido, encuentran su dinámica por las fuerzas magnetohidrodinámicas en constante interacción con las gravitatorias y rotacionales de la estrella, llegando a la superficie de manera que, los materiales más externos quedan ordenados conforme a las líneas de fuerza gauss. La rotación solar produce que las capas más externas no giren todas a la misma velocidad, por lo que el ordenamiento de estas líneas de fuerza se va descompensando a medida que los materiales distribuidos entre los polos y el ecuador van perdiendo sincronismo en el giro rotacional de la estrella. Por cada ruptura en la integridad del campo magnético, se produce un escape de líneas de fuerza gauss (produciendo las típicas manchas negras), en las que un aumento de estas, puede tener como consecuencia una erupción solar consecuente por la desintegración local del campo gauss. Cuando el Sol se acerca a su máximo desorden, las tormentas solares son máximas. Estos periodos se dan cada 11 años. El sol no posee un campo electromagnético como el de la Tierra, sino que posee lo que se denomina viento solar, producido por esas inestabilidades rotacionales del Sol. Si no fuera por eso, los campos magnéticos del Sol quedarían restringidos a la dinámica del plasma.

Por esa misma razón, una reacción de fusión entre dos átomos de hidrógeno en el interior del Sol, tarda 11 años en llegar a escapar de las enormes fuerzas gravitatorias y magnéticas.

El Sol se formó hace 4650 millones de años y tiene combustible para 7500 millones de años más. Después, comenzará a hacerse más y más grande, hasta convertirse en una gigante roja. Finalmente, se hundirá por su propio peso y se convertirá en una enana blanca, que puede tardar unos mil millones de años en enfriarse. Se formó a partir de nubes de gas y polvo que contenían residuos de generaciones anteriores de estrellas. Gracias a la metalicidad de dicho gas, de su disco circunestelar surgieron, más tarde, los planetas, asteroides y cometas del sistema solar. En el interior del Sol se producen reacciones de fusión en las que los átomos de hidrógeno se transforman en helio, produciéndose la energía que irradia. Actualmente, el Sol se encuentra en plena secuencia principal, fase en la que seguirá unos 5000 millones de años más fusionando hidrógeno de manera estable. 

Cada segundo se transforman 700 millones de toneladas de hidrógeno en cenizas de helio, este proceso transforma cinco millones de toneladas de materia en energía, lo que da como resultado que el Sol cada vez se vuelve más liviano.

Llegará un día en que el Sol agote todo el hidrógeno en la región central al haberlo transformado en helio. La presión será incapaz de sostener las capas superiores y la región central tenderá a contraerse gravitacionalmente, calentando progresivamente las capas adyacentes. El exceso de energía producida hará que las capas exteriores del Sol tiendan a expandirse y enfriarse y el Sol se convertirá en una estrella gigante roja. El diámetro puede llegar a alcanzar y sobrepasar al de la órbita de la Tierra, con lo cual, cualquier forma de vida se habrá extinguido. Cuando la temperatura de la región central alcance aproximadamente 100 millones de kelvins, comenzará a producirse la fusión del helio en carbono mientras alrededor del núcleo se sigue fusionando hidrógeno en helio. Ello producirá que la estrella se contraiga y disminuya su brillo a la vez que aumenta su temperatura, convirtiéndose el Sol en una estrella de la rama horizontal. Al agotarse el helio del núcleo, se iniciará una nueva expansión del Sol y el helio empezará también a fusionarse en una nueva capa alrededor del núcleo inerte —compuesto de carbono y oxígeno y que por no tener masa suficiente el Sol no alcanzará las presiones y temperaturas suficientes para fusionar dichos elementos en elementos más pesados— que lo convertirá de nuevo en una gigante roja, pero esta vez de la rama asintótica gigante y provocará que el astro expulse gran parte de su masa en la forma de una nebulosa planetaria, quedando únicamente el núcleo solar que se transformará en una enana blanca y, mucho más tarde, al enfriarse totalmente, en una enana negra. El Sol no llegará a estallar como una supernova al no tener la masa suficiente para ello.

Si bien se creía en un principio que el Sol acabaría por absorber a Mercurio, a Venus y a la Tierra al convertirse en gigante roja, la gran pérdida de masa que sufrirá en el proceso hizo pensar por un tiempo que la órbita terrestre –al igual que la de los demás planetas del sistema solar– se expandiría posiblemente y salvaría a nuestro planeta de ese destino. Sin embargo, un artículo reciente postula que ello no ocurrirá y que las interacciones mareales, así como el roce con la materia de la cromosfera solar, harán que nuestro planeta sea absorbido. Otro artículo posterior apunta en la misma dirección.

La mayor parte de la energía utilizada por los seres vivos procede del Sol, las plantas la absorben directamente y realizan la fotosíntesis, los herbívoros absorben indirectamente una pequeña cantidad de esta energía comiendo las plantas, y los carnívoros absorben indirectamente una cantidad más pequeña comiendo a los herbívoros.

La mayoría de las fuentes de energía usadas por el hombre derivan indirectamente del Sol. Los combustibles fósiles preservan energía solar capturada hace millones de años mediante fotosíntesis, la energía hidroeléctrica usa la energía potencial de agua que se condensó en altura después de haberse evaporado por el calor del Sol.

Sin embargo, el uso directo de energía solar para la obtención de energía no está aún muy extendido debido a que los mecanismos actuales no son suficientemente eficaces.

Una mínima cantidad de materia puede convertirse en una enorme manifestación de energía. Esta relación entre la materia y la energía explica la potencia del Sol, que hace posible la vida. ¿Cuál es la equivalencia? En 1905, Einstein había predicho una equivalencia entre la materia y la energía mediante su ecuación E=mc². Una vez que Einstein formuló la relación, los científicos pudieron explicar por qué ha brillado el Sol por miles de millones de años. En el interior del Sol se producen continuas reacciones termonucleares. De este modo, el Sol convierte cada segundo unos 564 millones de toneladas de hidrógeno en 560 millones de toneladas de helio, lo que significa que unos cuatro millones de toneladas de materia se transforman en energía solar, una pequeña parte de la cual llega a la Tierra y sostiene la vida.

Con la fórmula y los datos anteriores se puede calcular la producción de energía del Sol, obteniéndose que la potencia de nuestra estrella es aproximadamente 3'8x10 vatios, o 3'8x10 kilovatios —o, dicho de otra manera, el Sol produce en un segundo 760 000 veces la producción energética anual a nivel mundial—.

Unas de las primeras observaciones astronómicas de la actividad solar fueron las realizadas por Galileo Galilei en el siglo XVII, utilizando vidrios ahumados al principio, y usando el método de proyección después. Galileo observó así las manchas solares y pudo medir la rotación solar así como percibir la variabilidad de estas. En la actualidad la actividad solar es monitoreada constantemente por observatorios astronómicos terrestres y observatorios espaciales. Entre los objetivos de estas observaciones se encuentra, no solo alcanzar una mayor comprensión de la actividad solar, sino también la predicción de sucesos de elevada emisión de partículas potencialmente peligrosas para las actividades en el espacio y las telecomunicaciones terrestres.

La luz solar que apreciamos a simple vista es de color amarillo, pero en realidad el sol la emite en todas las longitudes de onda.

Para obtener una visión ininterrumpida del Sol en longitudes de onda inaccesibles desde la superficie terrestre, la Agencia Espacial Europea y la NASA lanzaron cooperativamente el satélite SOHO ("Solar and Heliospheric Observatory") el 2 de diciembre de 1995. La sonda europea Ulysses realizó estudios de la actividad solar, y la sonda norteamericana Génesis se lanzó en un vuelo cercano a la heliósfera para regresar a la Tierra con una muestra directa del material solar. Génesis regresó a la Tierra en el 2004, pero su reentrada en la atmósfera fue acompañada de un fallo en su paracaídas principal que hizo que se estrellara sobre la superficie. El análisis de las muestras obtenidas prosigue en la actualidad.

Aristarco de Samos fue el primero en hacer estimaciones sobre la distancia al Sol. No llegó a distancias concretas, sino que estableció distancias relativas a la distancia entre la Tierra y la Luna. Esperó a que la fase de la Luna sea de un cuarto exactamente, momento en que el ángulo Tierra-Luna-Sol debería ser un ángulo recto. Entonces la hipotenusa del rectángulo sería la distancia de la Tierra al Sol. Para esto era necesario medir con exactitud el ángulo del Sol respecto a la Luna, cosa que no es nada fácil.

Entonces determinó la distancia y el tamaño del Sol (relativos). Sin embargo, siendo necesario medir unos ángulos demasiado pequeños, y sin los instrumentos para ello, no logró la suficiente exactitud. Determinó que el Sol se encuentra 20 veces más lejos de lo que está la Luna, y determinó que su diámetro era al menos 7 veces el diámetro de la Tierra. Según los cálculos actuales el Sol se encuentra 400 veces más alejado que la Luna, y su diámetro es 109 veces más grande que el de la Tierra, por lo que fue muy grande el error de medición.

Para establecer la distancia real de la Tierra a la Luna sugirió un método utilizando curvatura de la sombra de la Tierra proyectada en la Luna, durante los eclipses lunares. (Este método fue utilizado por Hiparco de Nicea posteriormente para calcular esa distancia).

Aristarco, pensando que el Sol era al menos 7 veces más grande que la Tierra, sugirió que no es el Sol el que gira alrededor de la Tierra, sino al contrario, siendo el primero en sugerir un modelo heliocéntrico. Sin embargo, sus ideas no fueron aceptadas por sus contemporáneos y la teoría heliocéntrica no se retomó hasta 1543, 17 siglos después, cuando Copérnico publicó su libro ≪Sobre las revoluciones de los orbes celestes≫.

En 1650 Godefroy Wendelin repitió las mediciones de Aristarco midiendo directamente la distancia al Sol, esta vez con mayores recursos técnicos que 18 siglos atrás. Llegó a la conclusión de que el Sol estaba unas 240 veces más alejado que la Luna. Esta vez el error fue menor, pero el valor todavía menor al que se mide actualmente.

En 1609, Kepler abrió el camino para determinar las distancias relativas de todos los cuerpos del sistema solar, no solo de la Luna y el Sol, por lo que sabiendo la distancia a cualquiera de los planetas se podría saber la distancia al Sol. Posteriormente Cassini, en 1673 obtuvo el paralaje de Marte, por lo que logró determinar su distancia. Entonces, sobre la base de los cálculos de Kepler, determinó la distancia al Sol en 136 millones de kilómetros (esta vez la distancia se acercó bastante a los datos actuales, y el error fue solo de 7%).





</doc>
<doc id="2571" url="https://es.wikipedia.org/wiki?curid=2571" title="Stephen King">
Stephen King

Stephen Edwin King (pronunciación: /ˈstiːvən ˈɛdwɪn ˈkɪŋ/) (Portland, Maine; 21 de septiembre de 1947) es un escritor estadounidense de novelas de terror, ficción sobrenatural, misterio, ciencia ficción y literatura fantástica. Sus libros han vendido más de 350 millones de copias y en su mayoría han sido adaptados al cine y a la televisión. Ha publicado 61 novelas (siete de ellas, bajo el seudónimo Richard Bachman) y siete libros de no ficción. Ha escrito, además, alrededor de doscientos relatos y novelas cortas, la mayoría de los cuales han sido recogidos en once colecciones. 

Desdeñado por críticos y académicos literarios por ser considerado un autor «comercial», su obra ha generado mayor atención desde la década de 1990, aunque algunos de estos círculos continúan rechazando sus libros. Es criticado regularmente por su estilo presuntamente "no literario" y por la excesiva extensión de algunas de sus novelas. Por el contrario, su sentido de la narración, sus personajes animados y coloridos y su capacidad para jugar con los temores de los lectores han sido blanco de elogios. Si bien en la mayoría de sus historias utiliza el recurso del terror, también aborda de manera regular temáticas como la infancia, el racismo y la guerra, brindando un retrato social muy realista de los Estados Unidos.

Su novela corta «Rita Hayworth y la redención de Shawshank» fue la base para la película "The Shawshank Redemption", la mejor calificada de IMDb y votada por la revista "Empire" como la mejor de la historia en su encuesta "The 201 Greatest Movies of All Time" en marzo de 2006. Otras adaptaciones cinematográficas de sus obras que han logrado éxito comercial y de crítica son "Carrie", dirigida por Brian de Palma en 1976; "El resplandor", dirigida por Stanley Kubrick en 1980; "Cuenta conmigo" y "Misery", dirigidas por Rob Reiner en 1986 y 1990, ganadora la última de un Premio Óscar y un Globo de Oro gracias al desempeño de Kathy Bates como actriz principal; "La milla verde" (1999); y "La niebla" (2007). El propio King ha incursionado ocasionalmente como guionista, productor y actor en algunas series de televisión y películas, y también dirigió el largometraje "Maximum Overdrive".

King ha ganado numerosos premios literarios, incluyendo el Premio Bram Stoker en trece ocasiones, el Premio British Fantasy siete veces, los Premios Locus en cinco oportunidades, el Premio Mundial de Fantasía cuatro veces, el Premio Edgar en dos ocasiones y los premios Hugo y O. Henry en una oportunidad. Al ser nativo de Maine, muchas de sus historias se desarrollan en ese estado. También es frecuente su uso de ciudades ficticias ubicadas en Maine, como Castle Rock, Jerusalem's Lot y Derry. Es esposo de la escritora y activista Tabitha King desde 1971, con la que tiene tres hijos: Naomi Rachel (1970), Joe (1972) y Owen (1977).

Stephen King nació en Portland (Maine), segundo hijo de Donald King y Nellie Ruth Pillsbury. Cuando King tenía dos años de edad, su padre abandonó a la familia. Su madre lo crio junto a su hermano mayor David por su cuenta, algunas veces bajo grandes problemas financieros. Tras vivir en Fort Wayne (Indiana) y Stratford (Connecticut), la familia se mudó a Durham, pueblo natal de Ruth. King estudió en la Escuela Primaria de Durham y luego en la Secundaria de Lisbon Falls.

Cuando era niño, King presenció un espantoso accidente, uno de sus amigos quedó atrapado en unos rieles y fue arrollado por un tren. Aunque este hecho podría haber inspirado las oscuras creaciones de King, el mismo escritor ha descartado la idea.

Empezó a escribir desde una temprana edad, mientras se basaba en películas vistas recientemente e historietas. Mientras estaba en el colegio comenzó a vender cuentos a sus compañeros, los cuales eran copiados con la misma máquina que su hermano utilizaba para publicar su periódico llamado "Dave's Rag". Sin embargo, la actividad no fue bien vista por sus profesores, quienes lo obligaron a devolver el dinero ganado.

Aproximadamente a los trece años de edad, descubrió en la casa de su tía una vieja caja con libros de su padre, la mayoría de terror y ciencia ficción. Entre estos libros se encontraba "The Lurking Fear" de H.P. Lovecraft, quien a la postre se convertiría en una de sus principales influencias. La película "Pit and the Pendulum" de 1961, basada en el cuento homónimo de Edgar Allan Poe, causó una gran impresión en el joven King. Desde entonces comenzó a enviar sus trabajos a diferentes revistas, sin recibir una respuesta positiva. Su primer relato publicado fue incluido en la revista "Comics Review" de Mike Garrett en 1965. El título original era "I Was a Teenage Grave Robber", pero fue cambiado por el editor a "In a Half-World of Terror".

Entre 1966 y 1971 estudió inglés en la Universidad de Maine, en Orono, con grandes penurias económicas a causa de la pobreza de su madre, y escribió una columna titulada "King's Garbage Truck" en su revista. King conoció a su futura esposa, la escritora Tabitha King, en la biblioteca de la universidad y se casaron en 1971. El escritor realizó trabajos de media jornada para poder pagar sus estudios, incluso en una lavandería. Utilizó la experiencia vivida para escribir las historias de "La trituradora" ("The Mangler") y "Carretera maldita" ("Roadwork").

Después de terminar sus estudios universitarios con una licenciatura en arte en inglés y obtener un certificado para poder enseñar en secundaria, King enseñó inglés en la Academia de Hampden. Durante este periodo, él y su familia vivieron en un remolque. Escribió historias cortas (la mayoría publicadas en revistas para hombres) para poder satisfacer las necesidades de su familia. Durante este periodo King comenzó a tener problemas de alcoholismo que mantuvo durante una década. Estos problemas se verán reflejados en su tercera novela, "El resplandor", en la persona de su personaje principal, el escritor alcohólico Jack Torrance.

A comienzos de la década de 1970, King comenzó a escribir un gran número de novelas. Una de sus primeras ideas fue la de una joven con poderes psíquicos. Sin embargo, se sintió desalentado y la tiró a la basura. Tabitha rescató el trabajo y lo animó a terminarlo. Después de finalizada la novela, la tituló "Carrie", la mandó a la compañía editora Doubleday y al pasar el tiempo se olvidó de ella. Más tarde recibió una oferta de compra por 2.500 dólares de adelanto (no un gran adelanto para una novela, incluso en esa época). Poco tiempo después, el valor de "Carrie" con los derechos del manuscrito fueron vendidos por 400.000 dólares (200.000 de los cuales recibió el editor). Después del lanzamiento, su madre murió de cáncer de pulmón, y por ello no llegaría a ver la edición de la novela.

King, decidido a dedicarse exclusivamente a la escritura, se trasladó a la ciudad de Bangor, Maine con su familia. Allí empezó a escribir la novela "El misterio de Salem's Lot", una historia de vampiros basada en el clásico "Drácula" de Bram Stoker y en la novela "Peyton Place" de Grace Metalious. Mientras tanto, la novela "Carrie" fue publicada en edición de bolsillo, vendiendo más de un millón de copias en menos de un año. El 17 de octubre de 1975 la editorial Doubleday publicó "El misterio de Salem's Lot", vendiendo en su edición de bolsillo más de dos millones de copias en menos de seis meses.

Durante un viaje por Colorado, la familia King visitó el Hotel Stanley en Estes Park. Basado en su experiencia en el hotel, King empezó a escribir su tercera novela, "El resplandor". Paralelamente vio la necesidad de contratar un agente literario al sentirse insatisfecho con el bajo porcentaje recibido por los derechos de autor de sus dos obras, por lo que se puso en contacto con Kirby McCauley, quien le consiguió un contrato literario con Viking Press por tres libros y dos millones y medio de dólares. "El resplandor" fue publicada el 28 de enero de 1977. La novela relata la historia de una familia que pasa el invierno aislada en un hotel y que es atormentada por una presencia maligna que quiere apoderarse del joven Danny, dotado de un poder telepático. Considerada como una de las mejores obras de King, "El resplandor" profundiza en la desintegración de la unidad familiar a través del aislamiento, la locura y el alcoholismo, este último factor reflejando inconscientemente los recientes problemas de King con la bebida.

King creó el seudónimo de Richard Bachman porque los estándares de edición de la época no permitían que un autor publicara más de un libro al año y para liberarse de la presión que su creciente fama estaba ejerciendo en él. La primera novela publicada bajo este seudónimo fue "Rabia", un controvertido relato en el que un estudiante asesina a algunos maestros y toma como rehenes a sus compañeros de clase.

También en 1977, King se mudó a Inglaterra con su familia, que ahora incluía a un tercer hijo, Owen, nacido en febrero, con el objetivo de quedarse un año y escribir una novela allí. Sin embargo, este intento fracasó y la familia King decidió regresar a Maine tres meses después. Durante su breve estancia en Inglaterra, King conoció al escritor Peter Straub y se planteó la idea de realizar una colaboración futura con el novelista estadounidense.

En 1978 fueron publicados dos nuevos libros de King por la editorial Doubleday. En febrero fue lanzada al mercado la colección de veinte relatos cortos "El umbral de la noche", la mayoría de los cuales ya habían sido publicados en varias revistas. En septiembre vio la luz la novela "La danza de la muerte", una historia postapocalíptica en la que un virus creado en un laboratorio estadounidense se propaga accidentalmente y liquida a casi toda la población del planeta. Los pocos sobrevivientes de la pandemia son atraídos por dos poderes opuestos para replicar la lucha eterna entre el bien y el mal. "La danza de la muerte" es una de las obras más ambiciosas de King y es considerada una de sus mejores novelas. Debido a su extensión, King tuvo que hacer recortes importantes, eliminando alrededor de 250.000 palabras. Las ventas de la novela fueron similares a las obtenidas con "El resplandor".

"La larga marcha", segunda novela de King editada bajo el seudónimo de Richard Bachman, fue publicada en edición de bolsillo en julio de 1979. Esta novela, escrita diez años antes de su publicación, se ubica en un futuro distópico en el que se realiza un espectáculo anual conocido como la larga marcha, en el que centenares de jóvenes deben caminar sin parar a riesgo de ser asesinados. Finalmente, el joven que logre permanecer en pie ganará una fortuna, y por consiguiente se convertirá en el único sobreviviente del concurso. A menudo se considera a "La larga marcha" como la mejor obra del autor usando el nombre de Bachman. Un mes después fue publicada la siguiente novela de Stephen King, "La zona muerta", la cual se convirtió en el primer libro del autor publicado por la editorial Viking. La novela, alejada del terror sobrenatural presente en las anteriores obras del autor, relata la historia de John Smith, un maestro que despierta de un largo coma con la extraña habilidad de ver el pasado o el futuro de las personas que toca. Esta habilidad se convierte paulatinamente en una pesadilla para Smith y le genera un dilema moral cuando descubre que un político será el responsable de una tragedia mundial. "La zona muerta" vendió cerca de 175.000 copias en su primer año y se convirtió en la primera novela de King en alcanzar el primer lugar en la lista de "bestsellers" de "The New York Times".

Stephen King continuó escribiendo a un ritmo frenético y su siguiente novela, "Ojos de fuego", fue publicada en agosto de 1980. En esta historia, Andrew McGee y su hija Charlie, dotada del poder de la piroquinesis, son perseguidos por una agencia secreta del gobierno que quiere estudiar y sacar provecho al magnífico don de la niña. Con esta novela King termina de consolidarse como uno de los nombres más confiables de la industria editorial, nuevamente apareciendo en el primer lugar de la lista de "bestsellers" de "The New York Times". Ese mismo año el autor compró la casa de William Arnold, una vivienda victoriana ubicada en Bangor, Maine, conformada por un total de 23 habitaciones.

El año de 1981 vio la publicación de tres obras del autor. "Carretera maldita", novela publicada bajo el seudónimo de Bachman, explora la obsesión de un hombre que se niega a abandonar su hogar, el cual debe ser demolido para permitir la construcción de una carretera. Un mes después fue publicado el ensayo "Danse Macabre", en el que el autor examina la influencia de la ficción de terror en los medios escritos y audiovisuales. Este ensayo, escrito en su estilo narrativo habitual, ganó los premios Hugo y Locus. Finalmente, en la novela "Cujo", publicada en agosto, el autor relata la historia de un perro san bernardo que contrae la rabia y se convierte en una formidable máquina asesina. La novela vendió cerca de 350.000 copias en su primer año y ganó el premio British Fantasy.

La alta tasa de tres publicaciones anuales se mantuvo en 1982. Al igual que en 1981, King publicó una novela bajo el seudónimo de Bachman, "El fugitivo", nuevamente ubicándose en un futuro distópico que trae consigo un espectáculo público mortal, idea similar a la utilizada en "La larga marcha" de 1979. En junio el autor publicó una edición limitada de 10.000 ejemplares de la novela corta "", la cual se convertiría en el volumen inicial de la extensa saga de "La Torre Oscura". En la novela se relata la épica historia de Roland Deschain, un pistolero que busca llegar desesperadamente a la Torre Oscura, una legendaria edificación donde convergen todos los universos. Para su creación, King se basó en dos obras clásicas, el poema "Childe Roland to the Dark Tower Came" de Robert Browning y "El señor de los anillos" de J. R. R. Tolkien. Finalmente, "Las cuatro estaciones", publicada en agosto, es una colección de cuatro historias en las que se aleja casi en su totalidad de los elementos sobrenaturales. A pesar de su formato inusual, el libro fue un éxito comercial, alcanzando nuevamente el primer puesto en la lista de "bestsellers" del periódico de Nueva York.

En 1983 nuevamente fueron publicadas tres obras del autor de Maine. "Christine", lanzada en abril, cuenta la historia de un adolescente fracasado que se obsesiona mortalmente con un viejo auto Plymouth Fury de 1958 en el que habita un espíritu maligno. A fin de año fueron publicadas "El ciclo del hombre lobo", una historia sobre licantropía lanzada en edición limitada con ilustraciones de Bernie Wrightson, y "Cementerio de animales", novela de terror en la que relata la vida de una familia que habita en las inmediaciones de un antiguo cementerio micmac que tiene la habilidad de devolver la vida a cualquier ser vivo que sea puesto allí. "Cementerio de animales" se convirtió en ese momento en el mayor éxito comercial de King, vendiendo 657.000 copias en su primer año de publicación.

En 1984 el autor abordó el género fantástico con el lanzamiento de dos novelas, "Los ojos del dragón" y "El talismán". "Los ojos del dragón" fue escrita como una dedicatoria especial para su hija Naomi Rachel, después de darse cuenta que nunca había leído ninguno de sus libros por no ser fanática de las historias de terror. "El talismán", primera colaboración de King con su amigo Peter Straub, es la realización de un proyecto que ambos venían discutiendo durante varios años. Mezclando fantasía y horror, la novela relata la búsqueda del joven Jack Sawyer, que viaja a través de los Estados Unidos y en un universo paralelo donde la magia ha reemplazado a la ciencia para encontrar el único talismán que puede salvar la vida de su madre. Con una promoción a gran escala de Viking Press, la novela, publicada el 8 de noviembre, vendió 880.000 copias en menos de dos meses y se ubicó entre los libros de ciencia ficción más vendidos en los Estados Unidos en 1984.

"El maleficio", quinta novela publicada por Richard Bachman, salió al mercado pocos días después de "El talismán". Esta novela corta, en la que un hombre es maldecido por un gitano y empieza a perder peso de manera estrepitosa, fue el primer libro de Bachman publicado en tapa dura y con algún elemento sobrenatural en su historia. Las similitudes entre "El maleficio" y la obra de King atrajeron la atención de algunos especialistas. Steve Brown, un empleado de una biblioteca en Washington, descubrió el engaño al examinar un documento en la Biblioteca del Congreso en el que King aparecía como autor de una de las novelas de Bachman. Brown se puso en contacto con King, quien le aconsejó que escribiera un artículo contando toda la verdad. Cuando se reveló la verdadera identidad de Bachman, las ventas de la novela "El maleficio" se dispararon, pasando de 28.000 copias vendidas a 280.000 en unas pocas semanas.

"Skeleton Crew", nueva colección de relatos de Stephen King, fue publicada el 21 de junio de 1985. La colección ganó el Premio Mundial de Fantasía y ocupó durante nueve semanas el primer lugar en la lista de "bestsellers" del "New York Times", hecho sin precedentes para una colección de relatos. Dada la enorme demanda del público, en octubre fueron publicadas las primeras cuatro novelas de Richard Bachman en un volumen titulado "The Bachman Books". En ese momento la popularidad de King se encontraba en su pico más alto, convirtiéndolo en todo un fenómeno mediático. Entre el 17 y el 24 de noviembre de 1985, el autor estableció un nuevo récord al ubicar cinco de sus libros en la lista de "bestsellers".

"It", siguiente novela de King, fue publicada el 15 de septiembre de 1986, confirmando el buen estado de forma del escritor. La novela, un éxito masivo en ventas, nuevamente mezcla las desventuras de la infancia con la presencia de un ente sobrenatural, en este caso convertido en una entidad maligna que toma la forma de los temores más profundos de sus víctimas. Hasta ese momento la obra más extensa de King, "It" sigue una estructura narrativa no lineal que alterna entre dos períodos principales de tiempo y entre las diferentes perspectivas de los personajes. Considerada una de las obras maestras del autor de Maine, "It" ocupó el primer lugar de ventas en literatura de ficción en los Estados Unidos en 1986 y ganó el premio British Fantasy. Un año después salió al mercado una versión ligeramente modificada de "Los ojos del dragón" por la editorial Viking. Esta novela, alejada del estilo habitual del autor, logró vender más de 500.000 copias el primer año.

Tres nuevas novelas de King se publicaron en 1987. En "", segundo volumen de "La Torre Oscura", Roland Deschain se traslada a la ciudad de Nueva York en tres ocasiones diferentes para traer de vuelta a su compañero de misión. "Misery", novela publicada en junio, relata la historia de un escritor que es rescatado de un terrible accidente automovilístico por una fanática de su obra, quien termina secuestrándolo y obligándolo a escribir una novela para ella. King empezó a escribir la historia para esta novela en 1984 y tenía en mente publicarla como una novela de Richard Bachman, pero tras el descubrimiento de su identidad tuvo que descartar esta posibilidad. "Misery" ganó la primera edición del Premio Bram Stoker en la categoría de mejor novela. Finalmente, la novela "Los Tommyknockers" fue publicada en noviembre. En ella el autor mezcla el horror y la ciencia ficción, relatando la historia de una pequeña ciudad y el efecto que ejerce una nave alienígena en sus habitantes. King le atribuyó cierta influencia al cuento "El color del espacio exterior" de H. P. Lovecraft en el momento de la creación de la novela.

Escritas entre 1984 y 1986, "Misery" y "Los Tommyknockers" son una metáfora de las adicciones del escritor en ese momento. A su ya usual adicción al alcohol, King incluyó una fuerte adicción a la cocaína y a otro tipo de drogas. Después de la publicación de "Los Tommyknockers", su familia y amigos decidieron hacer una intervención, en la que le mostraron los residuos de su estudio para que se diera cuenta del grado de adicción alcanzado: latas de cerveza, cigarrillos, bolsas de cocaína y botellas de xanax y valium fueron algunas de las sustancias encontradas. El escritor solicitó ayuda y abandonó toda forma de alcohol y drogas hacia finales de esa década. A raíz de este proceso de desintoxicación, su actividad creativa se vio interrumpida y le resultó difícil recuperar el ritmo, ya que sufrió un bloqueo de escritor durante casi un año antes de publicar el relato "The Rainy Season" en 1989.

Como consecuencia directa de este bloqueo creativo, en 1988 no se publicó ninguna obra del autor, a excepción de "Nightmares in the Sky", un libro de fotografías de gárgolas con una larga introducción de King. Su primera novela publicada después de "The Tommyknockers" fue "The Dark Half", estrenada el 20 de octubre de 1989. Inspirada en la experiencia de King con su doble literario, Richard Bachman, la novela relata la historia de un escritor que es acosado por su seudónimo.

Después de largas negociaciones con la editorial Doubleday, finalmente King es libre de publicar una versión extendida de la novela "La danza de la muerte", titulada "Apocalipsis". Con aproximadamente ciento cincuenta mil palabras adicionales, lo que la convierte en la novela más larga de King hasta la fecha, "Apocalipsis" es una actualización en términos de referencias culturales y políticas de "La danza de la muerte". Estas adiciones introducen más variaciones de ritmo, enriquecen la psicología de los personajes, integran dos largos pasajes suprimidos en 1978 debido a la censura y solidifican la conclusión de la novela. "Apocalipsis" fue publicada el 23 de abril de 1990. En septiembre fue estrenada una nueva colección de historias, titulada "Las cuatro después de la medianoche". La colección, compuesta por cuatro relatos, difiere de "Las cuatro estaciones" porque en esta oportunidad la temática está relacionada con el terror. El libro ganó el Premio Bram Stoker en la categoría de mejor colección.

Habiendo recuperado su ritmo de escritura, King publicó dos nuevas novelas en 1991, el tercer volumen de "La Torre Oscura", titulado "", y "La tienda", en la que el autor relata la historia de Leland Gaunt, el propietario de una extraña tienda de variedades en la localidad ficticia de Castle Rock. En 1992 el autor publicó dos novelas de corte feminista, "El juego de Gerald", que relata la terrible experiencia de una mujer que accidentalmente queda esposada en una cama de una casa de campo y "Dolores Claiborne", la historia de una mujer que es la principal sospechosa de la muerte de su empleadora. A pesar de carecer de elementos sobrenaturales, ambas novelas encabezaron la lista de "bestsellers" del "New York Times" ese mismo año, demostrando que los fanáticos de King aún permanecían fieles a su estilo.

Después de la publicación de "Pesadillas y alucinaciones", colección de relatos que vio la luz el 29 de septiembre de 1993, King nuevamente sorprendió a sus lectores con la publicación de su novela "Insomnia", una obra de ritmo lento cuyo personaje principal es un anciano que sufre de insomnio y empieza a experimentar lo que inicialmente supone que son alucinaciones. En junio de 1995 completó su llamada «trilogía feminista» con el lanzamiento de la novela "El retrato de Rose Madder", historia de una mujer que sufre constantes agresiones físicas y psicológicas por parte de su esposo. El elemento fantástico se introduce en la mitad de la historia a través de una pintura que se convierte en una especie de portal hacia un universo paralelo. Pese a que estas últimas novelas siguen disfrutando de buenos números, no experimentan el éxito comercial alcanzado por anteriores obras de King, con algunos medios señalando que la popularidad del escritor se encontraba en decadencia.

Sin embargo, el autor demostró su potencial en 1996 con la publicación de dos obras, el relato "El hombre del traje negro", ganador del Premio Mundial de Fantasía en la categoría de mejor relato corto de ficción, y la novela "La milla verde", publicada en seis volúmenes entre marzo y agosto. La historia, que transcurre en 1932, relata la historia de Paul Edgecomb, un funcionario de una prisión que conoce a John Coffey, un sentenciado a muerte que posee poderes sobrenaturales. "La milla verde" ganó el Premio Bram Stoker en la categoría de mejor novela ese mismo año. En 1997 fue nominada en la misma categoría en los premios British Fantasy y Locus.

Sus dos siguientes novelas, "Desesperación" y "Posesión", esta última publicada bajo el nombre de Richard Bachman, fueron estrenadas simultáneamente el 24 de septiembre de 1996. Las dos obras presentan personajes con los mismos nombres y que se enfrentan al mismo adversario, un ente maligno llamado Tak, pero en situaciones completamente diferentes. "Desesperación" recibió mejores críticas y ocupó la tercera posición en la lista de "bestsellers", ante el quinto lugar de "Posesión" en la misma lista.

"", cuarta entrega de "La Torre Oscura", vio la luz el 24 de noviembre de 1997. Al mismo tiempo, King cambió de editorial por segunda vez en su carrera y firmó un contrato con Charles Scribner's Sons después de veinte años de colaboración con Viking. La primera novela del autor de Maine publicada por Scribner el 22 de septiembre de 1998 fue "Un saco de huesos". La novela, que relata la historia de un escritor viudo que debe enfrentarse a fuerzas sobrenaturales que azotan su vivienda, se convirtió en la primera obra de King en ganar tres premios principales, el Bram Stoker, el British Fantasy y el premio Locus, ocupando el tercer lugar de la lista de los libros de ficción más vendidos en los Estados Unidos en 1998.

Un año después King publicó dos nuevos libros, la novela "La chica que amaba a Tom Gordon" y la colección "Corazones en la Atlántida". La novela relata la historia de una chica que se pierde en los bosques de Maine y encuentra consuelo recordando la imagen de Tom Gordon, jugador de los Medias Rojas de Boston. La colección es bastante peculiar, con cinco narraciones vinculadas por el personaje de Carol Gerber, que sirve de hilo conductor. Con esta colección, King regresa a la década de 1960 y a la guerra de Vietnam, un tema que el autor quería evocar durante mucho tiempo, e integra el único elemento fantástico a través del poder psíquico del personaje de Ted Brautigan, quien reaparecerá en el último volumen de "La Torre Oscura". "Corazones en la Atlántida" y "La chica que amaba a Tom Gordon", dos libros con poco contenido terrorífico, se ubicaron respectivamente en el sexto y octavo lugar de los libros de ficción más vendidos en los Estados Unidos en 1999.

En el verano de 1999, King se encontraba trabajando en el ensayo titulado "Mientras escribo". Había terminado la sección de memorias y abandonado el libro durante dieciocho meses debido a la inseguridad acerca de cómo proceder o de si iba a molestar a terceros. Más adelante el autor reconoció que fue el primer libro que tuvo que abandonar desde que escribiese "La danza de la muerte" décadas atrás. Una vez hubo tomado la decisión de continuar con el libro, el 17 de junio escribió una lista de preguntas que le habían hecho con frecuencia sobre su forma de escribir, al mismo tiempo que otras que le hubiera gustado que le hubieran formulado. El 18 de junio escribió cuatro páginas de esta sección.

El 19 de junio a las 4:30 de la tarde aproximadamente, King caminaba por el arcén derecho de la ruta 5 en Lovell. Un conductor llamado Bryan Smith, distraído por un rottweiler incontrolado que se movía en la parte trasera de su coche marca Dodge Caravan de 1985, atropelló a King, quien aterrizó en una zanja de unos cuatro metros de profundidad desde el pavimento de la carretera de la ruta 5.

El ayudante del comisario del condado de Oxford, Matt Baker, grabó que los testigos dijeron que el conductor no conducía con exceso de velocidad ni con imprudencia. Baker también informó que King fue atropellado por detrás. El autor estaba lo bastante consciente para dar los números de teléfono de su familia al ayudante del comisario para poder ponerse en contacto con ellos, aunque se encontraba sufriendo un dolor considerable. El escritor fue llevado en primer lugar al Hospital Northern Cumberland para luego ser trasladado desde allí en helicóptero al Hospital Central de Maine. Sus heridas —el pulmón derecho colapsado, múltiples fracturas en la pierna derecha, laceración del cuero cabelludo y la cadera fracturada— lo mantuvieron en el centro médico hasta el 9 de julio, casi tres semanas internado.

Después de cinco operaciones en diez días y terapia física, retomó en julio el trabajo donde lo había dejado en el ensayo "Mientras escribo", aunque se resentía todavía de su cadera y solamente podía sentarse unos cuarenta minutos antes de que el dolor se tornara intolerable. A raíz de este accidente, el autor compró una casa en Sarasota, Florida, con el fin de pasar el invierno en un clima más favorable para su salud y recuperación.

Stephen King comenzó la década de 2000 siendo uno de los primeros escritores en explorar el mercado de los libros digitales. En marzo de 2000 publicó mediante este formato la novela corta "Montando la bala", escrita durante su convalecencia. Con cerca de 400.000 descargas en su primer día de lanzamiento, la novela se convirtió en el primer "best seller" digital. Animado por este suceso, el escritor brindó la oportunidad de descargar el primer capítulo de la novela "La planta" desde su página de Internet por un dólar. Los tres primeros capítulos de "La planta" fueron escritos entre 1982 y 1985 y distribuidos por King a sus allegados, antes de que el autor renunciara a continuar con la historia después de darse cuenta que tenía demasiadas similitudes con la película de 1986 "La pequeña tienda de los horrores". Entre julio y diciembre de 2000 escribió otros seis capítulos de la historia, pero la cantidad de lectores disminuyó gradualmente y el escritor finalmente abandonó el proyecto.

"Mientras escribo", autobiografía en la que King se encontraba trabajando antes de su accidente, finalmente fue publicada el 3 de octubre de 2000, ganando el premio Bram Stoker y el premio Locus en su respectiva categoría. En el año 2001 el autor publicó dos novelas. "El cazador de sueños", lanzada en marzo, retoma la temática alienígena, abordada por el autor en la novela "Los Tommyknockers" de 1987. "Casa Negra", publicada en septiembre, es la segunda colaboración de King con Peter Straub y relata las aventuras del personaje principal de la novela "El talismán", veinte años después de los acontecimientos de esta última obra. Ambas novelas ocuparon el cuarto y el sexto lugar respectivamente en la lista de los libros de ficción más vendidos en los Estados Unidos en 2001.

En 2002 el autor anunció que se retiraría de la escritura después de completar el ciclo de "La Torre Oscura" debido a las secuelas dejadas por su accidente. Finalmente decidió seguir escribiendo, pero ralentizó su ritmo. Dos libros de King vieron la luz ese año. "", publicado en marzo, es una colección de catorce relatos, la gran mayoría escritos durante la segunda mitad de la década de 1990. "", publicada en septiembre, es la historia de un extraño vehículo almacenado en un hangar por agentes de policía de un pequeño pueblo. El auto, aparentemente inofensivo, es una especie de portal del que emergen toda clase de extraños seres. Esta novela, cuyo primer borrador fue escrito por King antes de su accidente, no tuvo la misma acogida que sus anteriores publicaciones. A pesar de ocupar durante una semana el primer lugar de la lista de "best sellers" del "New York Times", no logró las ventas esperadas a mediano plazo y no fue bien recibida por la crítica especializada.

A partir de julio 2003, el autor empezó a compartir sus puntos de vista sobre la cultura popular en una columna de "Entertainment Weekly" llamada "The Pop of King" (referencia a "The King of Pop", apodo que recibía el cantante Michael Jackson), que se publicó hasta enero de 2011. En noviembre recibió el Premio Nacional del Libro, un prestigioso galardón entregado por la Fundación Nacional del Libro, por su destacada contribución a la literatura estadounidense, causando un gran revuelo entre los círculos académicos. El crítico y teórico literario Harold Bloom fue un acérrimo detractor de la condecoración recibida por King. Casi al mismo tiempo, el autor sufrió de neumonía, enfermedad causada indirectamente por el accidente que debilitó sus pulmones y de la que tardó varios meses en recuperarse.

King, comprometido a finalizar "La Torre Oscura", inició esta labor con la reescritura del primer volumen, "El pistolero", para hacerlo más consistente con las obras posteriores. "", publicada en noviembre de 2003, vino acompañada de los dos volúmenes finales, "", publicada el 8 de junio de 2004, y "", publicada en septiembre. Esta última obra ganó el premio British Fantasy.

El escritor estadounidense cambió de género por completo con la publicación de "Colorado Kid", una novela policíaca en la que dos viejos periodistas relatan a dos jóvenes aprendices el caso más misterioso de su larga carrera. Esta novela corta fue publicada directamente en edición de bolsillo el 4 de octubre de 2005. Al año siguiente el escritor retomó el género de terror con "Cell", publicada en enero de 2006, y en la que una señal transmitida a través de los teléfonos celulares contamina a las personas y las convierte en una especie de zombis. Esta novela es a la vez un homenaje a las películas de zombis y un ataque directo contra el uso desmedido de los teléfonos móviles. "La historia de Lisey", novela publicada en octubre de 2006, presenta un contenido más dramático y reflexivo. Inspirada por la neumonía padecida por el autor en 2003, esta novela relata la historia de la viuda de un escritor que sigue un rastro "post mortem" establecido por su difunto esposo, quien padecía una extraña maldición familiar. "La historia de Lisey" y "Cell" ocuparon la sexta y la octava posición respectivamente en la lista de los libros de ficción más vendidos en el país norteamericano en 2006. "Historia de Lisey" recibió una nominación al Premio Mundial de Fantasía en 2007 y ganó el Premio Bram Stoker el año de su publicación.

El 26 de abril de 2007 el autor recibió el Gran Premio otorgado por la Asociación de Escritores de Misterio de Estados Unidos. En junio publicó la novela "Blaze" nuevamente usando a Richard Bachman como seudónimo. Escrita a principios de la década de 1970, la novela es un claro homenaje a la novela "De ratones y hombres" de John Steinbeck. King revisó la historia y realizó modificaciones antes de publicarla en 2007. Su siguiente novela, "Duma Key", ambientada en Florida, salió al mercado el 22 de enero de 2008. En ella cuenta la historia de un hombre adquiere una casa en un cayo de Florida después de un grave accidente que lo deja con un solo brazo y se dedica a pintar cuadros que terminan convirtiéndose en hechos reales. Unos meses más tarde, en noviembre, el autor publicó "Después del anochecer", una nueva colección de relatos. Tanto "Duma Key" como la mencionada colección ganaron el Premio Bram Stoker en sus respectivas categorías.

En febrero de 2009 el autor retorna al formato digital con "Ur", novela corta disponible con la compra de un Kindle de Amazon. El 10 de noviembre del mismo año fue publicada "La cúpula", tercera obra más extensa de King después de "Apocalipsis" e "It". En esta novela de ficción, una pequeña localidad ficticia de Maine se ve abruptamente aislada del resto del mundo por una cúpula transparente e infranqueable, desatando toda serie de problemas y malentendidos en su interior y obligando a los habitantes del pueblo a tratar de convivir en medio de semejante infortunio, sin posibilidad de recibir ayuda desde el exterior.

En noviembre de 2010 fue publicada la colección "Todo oscuro, sin estrellas", ganadora del Bram Stoker en la categoría de mejor colección. Compuesta por cuatro novelas cortas, la colección presenta una variedad de géneros, siendo "1922" la única obra de terror sobrenatural incluida. "22/11/63", siguiente novela del autor, apareció el 8 de noviembre de 2011. En esta obra de suspenso, un maestro retrocede en el tiempo a través de un portal que conduce al año de 1958 para tratar de prevenir el asesinato de John Fitzgerald Kennedy. La novela, un éxito de ventas y de crítica, pasó cuatro semanas en el primer puesto de la lista de los libros más vendidos del "New York Times" y ocupó la segunda posición en el ranking de ficción en los Estados Unidos en el 2011, con más de 900.000 ejemplares vendidos.

En febrero de 2012 fue publicada la novela "", parte de la saga de "La Torre Oscura", cuya historia se ubica entre los volúmenes cuatro y cinco. Entre junio y agosto fue publicada en la revista "Esquire" una nueva obra del autor, "En la hierba alta", esta vez compartiendo autoría con su hijo Joe. En 2013 el autor publicó dos nuevas novelas. Retornó a la novela policíaca y de misterio con "Joyland", publicada el 4 de junio directamente en edición de bolsillo. La novela presenta a un joven empleado de un parque de diversiones que se lanza a la pista de un asesino en serie. En septiembre publicó "Doctor Sueño", secuela de "El resplandor" de 1977, en la que relata la vida adulta de Danny Torrance y su lucha contra un grupo de inmortales que se alimentan de la energía de niños dotados con el don del resplandor. Para promocionar esta obra, el escritor estadounidense viajó a Francia y Alemania, donde concedió varias entrevistas y conferencias, así como una sesión de firmas en París. "Doctor Sueño" ganó el Premio Bram Stoker y ocupó la segunda posición en la lista de los libros de ficción más vendidos en el país norteamericano en 2013 con más de 900.000 ejemplares vendidos.

Su siguiente libro, publicado el 3 de junio de 2014 es otra novela policíaca, titulada "Mr. Mercedes", en la que un criminal que mató a varias personas con su automóvil burla al policía retirado que estaba a cargo del caso y prepara un nuevo ataque aún más mortífero. Esta novela, ganadora del Premio Edgar, se convirtió en la primera de una trilogía centrada en el personaje de Bill Hodges, un oficial de policía retirado. El segundo volumen, titulado "Quien pierde paga", salió a la venta el 2 de junio de 2015. Entre estas dos obras, King publicó "Revival", una novela en la que un hombre común conoce a un antiguo pastor fascinado por la electricidad que ha negado la existencia de Dios como resultado de un terrible drama familiar, y se convierte en su asistente para una experiencia suprema. En esta novela King aborda la temática del fanatismo religioso, tema recurrente en otras novelas del autor como "La niebla" y "Carrie".

El 10 de septiembre de 2015 King fue recibido en la Casa Blanca, donde se le concedió la Medalla Nacional de las Artes, el más alto honor otorgado por el gobierno de los Estados Unidos a los exponentes de las artes. Su nueva colección de cuentos, titulada "El bazar de los malos sueños" y compuesta por veinte relatos, salió al mercado el 3 de noviembre de 2015. Más adelante el escritor finalizó su trilogía sobre Bill Hodges al enfrentar nuevamente al expolicía con el asesino de "Mr. Mercedes" en "Fin de guardia", publicada el 7 de junio de 2016.

El 2017 fue un año marcado por las colaboraciones. King escribió junto con Richard Chizmar la novela "La caja de botones de Gwendy", publicada en mayo. Con su hijo Owen escribió la novela "Bellas durmientes", lanzada al mercado en septiembre. En esta novela, una extraña epidemia sumerge a todas las mujeres del mundo en un sueño profundo. El 22 de mayo de 2018 el autor publicó "El visitante", una novela policíaca con un antagonista sobrenatural en la que interviene Holly Gibney, uno de los personajes principales de la trilogía de Bill Hodges. La novela corta "Elevation", publicada a finales de octubre de 2018, desarrolla su trama en la ciudad de Castle Rock y es considerada por el autor como una especie de secuela de "La caja de botones de Gwendy".

El 31 de enero de 2019 se anunció en la página oficial del autor el lanzamiento de una nueva novela, titulada "El instituto", programada para ser lanzada al mercado el 10 de septiembre del mismo año. En la página esta nueva novela es descrita de la siguiente manera: «tan psíquicamente aterradora como "Ojos de fuego" y con el espectacular poder infantil de "It", "El instituto" es una desgarradora historia de Stephen King acerca del bien y el mal, en un mundo en el que los tipos buenos no siempre ganan».

Sus novelas y relatos cortos han sido adaptados a diversos medios, tales como películas, series de televisión e historietas. Según el propio escritor, sus adaptaciones favoritas son "Cuenta conmigo", "The Shawshank Redemption" y "The Mist".

Su primera aparición en el cine ocurrió en la película de su amigo George Romero's "Knightriders" como un miembro de la audiencia. Su primer papel destacado ocurrió en la cinta "Creepshow", particularmente en el segmento "The Lonesome Death of Jordy Verrill", donde interpreta al personaje principal. Desde entonces ha realizado algunos cameos en producciones basadas en sus obras. Apareció en "Pet Sematary" como un sacerdote en el funeral de Gage, en "Thinner" como un farmacéutico, en "Rose Red" como un repartidor de pizza, en "The Storm of the Century" como un reportero, en la miniserie "Apocalipsis" como Teddy Wieszack, en "El resplandor" como un músico, en "The Langoliers" como Tom Holby; en "Sleepwalkers" como el guardián del cementerio, en "Golden Years" como un conductor de bus y en "It Capítulo Dos" como un vendedor. También se le pudo ver en la serie de comedia "Chappelle's Show" y, junto a la escritora Amy Tan, en el episodio "Insane Clown Poppy" de "Los Simpson". Adicional a la actuación, King debutó como director en la película "Maximum Overdrive", en la que también realizó un cameo como un sujeto que tiene problemas con un cajero de ATM. 

El autor produjo y actuó en la serie de televisión "Kingdom Hospital", basada en la miniserie "Riget" de Lars von Trier. También fue uno de los escritores del episodio de la quinta temporada de "The X-Files" "Chinga" junto con el creador de la serie Chris Carter. En 2010 realizó un cameo interpretando a un asesino llamado Bachman (en referencia a su seudónimo "Richard Bachman") en la serie "Sons of Anarchy".

El autor vive en Bangor, Maine con su esposa Tabitha Spruce, quien también es novelista. Tienen otra casa en el distrito Western Lakes de Maine. King pasa el invierno en su mansión con vista al mar ubicada en Sarasota, Florida. Recientemente construyó otra casa en Connecticut. Sus tres hijos Naomi Rachel, Joe Hill y Owen Phillip, alcanzaron la mayoría de edad y viven por su cuenta. Owen publicó en 2005 su primera colección de historias titulada "We're All in This Together: A Novella and Stories", y Joe Hill es autor de "20th Century Ghosts", una serie de cuentos y de varias novelas, de las que destacan "El traje del muerto" y "Cuernos".

King disfruta del béisbol y es fanático del equipo profesional Boston Red Sox, hecho que se puede evidenciar en gran parte de su obra, especialmente en la novela "La chica que amaba a Tom Gordon", en la que hace referencias constantes al lanzador Tom Gordon. El escritor también es un apasionado de las motocicletas Harley Davidson. En el otoño de 1994 realizó una gira promocional para la novela "Insomnia" a bordo de su Harley, deteniéndose en varias ciudades estadounidenses para realizar promoción en librerías.

Un fanático del "rock", el autor formó parte de la agrupación "Rock Bottom Remainders", conformada por otros escritores y editores como Dave Barry, Ridley Pearson, Matt Groening y Amy Tan, entre otros. Ha expresado en más de una ocasión que sus bandas de "rock" favoritas son The Ramones y AC/DC. The Ramones aportaron la canción «Pet Sematary» para la banda sonora de la película "Cementerio de animales" de 1989, basada en la novela de King del mismo nombre. La banda australiana AC/DC fue la encargada de aportar la totalidad de la banda sonora de la película de 1986 "Maximum Overdrive", dirigida por el propio King y basada en su relato corto "Camiones".

En su libro "Mientras escribo", King describe su estilo de escritura de gran longitud y profundidad. Cree que para las buenas historias es mejor crear una pequeña «semilla» y dejar que la historia crezca y se desenvuelva desde ahí. Generalmente empieza sus historias sin saber cómo terminarán.

Es conocido por su calidad de detalles, continuidad, y referencias internas; muchas de sus historias se ven ligadas por personajes secundarios, pueblos ficticios, o eventos de libros pasados, muy al estilo de H.P. Lovecraft.

Sus libros contienen referencias a la historia y cultura de los Estados Unidos, particularmente a la más oscura y escalofriante parte de la cultura. Las referencias están plasmadas en historias de los personajes en las cuales se explican sus temores. Algunas referencias incluyen el crimen, guerras (especialmente la guerra de Vietnam), y el racismo. 

King utiliza un estilo de narración bastante informal mientras se refiere a sus fanáticos como «lectores constantes» o «amigos y vecinos». Este estilo contrasta con los oscuros temas de sus historias. 

Stephen King tiene una sencilla fórmula para poder escribir bien: «Lee y escribe entre cuatro y seis horas al día. Si no encuentras el tiempo para hacerlo no podrás convertirte en un buen escritor».

Los personajes de sus libros han ido evolucionando al pasar de los años: 


Las novelas de terror y suspenso de King están construidas basándose en una visión constante del mundo, descrita más claramente en "Insomnia", "Corazones en la Atlántida" y "La Torre Oscura". En esta visión describe la existencia metafóricamente como una torre oscura ubicada en un paisaje de rosas rojas en el Mundo Final. En esta torre hay varios niveles con entidades en cada uno (y son los seres humanos los que habitan el nivel más bajo). Algunos son hostiles (Rey Carmesí, Randall Flagg, John Farson o Pennywise), otros benevolentes (Roland Deschain o Cloto y Láquesis, también conocidos como «los médicos calvos y bajitos»). Muchas de sus novelas toman lugar en este multiverso ficticio y algunos personajes se relacionan con hechos de otras historias.

Tras la existencia del mundo en que preside dicha torre, coexiste una fuerza vital y elemental llamada Ka. Su manifestación más común está presente en el destino que cumple cada ser del multiverso (igualmente puede referirse a un lugar particular al que uno se ve obligado a ir).

Sobre política se ha manifestado en contra de Donald Trump en repetidas ocasiones.

King es un gran admirador del escritor H. P. Lovecraft y ha incorporado varias de sus técnicas (como la conexión entre las historias de sus libros, la utilización de recortes de periódicos, transcripciones de prueba, otros materiales de documentación, y el uso de pueblos ficticios como Castle Rock y Derry) en sus novelas, pero se diferencia de él por su caracterización extensa, un diálogo efectivo e historias con finales positivos, todos estos inexistentes en los relatos de Lovecraft.

Asimismo, se ha declarado admirador de la serie de libros de "Harry Potter" de la autora J. K. Rowling, a quien, según ha mencionado en reiteradas ocasiones, considera una gran escritora.

Edgar Allan Poe, uno de los padres del género de terror contemporáneo, ha tenido una gran influencia en las historias de King. Un buen ejemplo es la novela "El resplandor". El texto extraído de la misma, «...y la muerte roja dominó sobre todas las demás...» (en inglés «...and the red death held sway over all...») recuerda al original, «...y la oscuridad y la decadencia y la Muerte Roja mantienen un dominio ilimitado sobre los demás...» (en inglés «...and darkness and decay and the Red Death held illimitable dominion over all...») contenido en la obra "La máscara de la muerte roja" de Poe. La novela de King es análoga al pequeño relato de Poe de forma bastante precisa. Los dos escritores comparten el uso de los Doppelgänger, aunque el tema está presente en la mayoría de las obras de terror y no se puede especificar a un solo autor. Además, el argumento del relato corto titulado "El cadillac de Dolan" (en inglés "Dolan's Cadillac") es en comparación casi idéntica al relato de Poe llamado "El barril de Amontillado" (en inglés "The Cask of Amontillado"), parafraseando incluso el famoso alegato de Fortunato, «¡Por el amor de Dios, Montresor!».

King declaró su admiración por otra autora menos prolífica, Shirley Jackson. La novela "El misterio de Salem's Lot" empieza con una cita del libro "La maldición de Hill House" de Jackson. Tony, un amigo imaginario que aparece en la novela "El resplandor" tiene cierta relación con otro amigo imaginario, llamado también Tony, del libro "Hangsaman" de Jackson. Hay algunas otras similitudes entre los personajes Carrie de "Carrie" y Eleanor de "La maldición de Hill House". King declaró que Carrie está basada en dos víctimas de abuso en la escuela que conoció. Una escena crucial de "La tormenta del siglo" está basada en el libro de Jackson titulado "La lotería".

Otra de sus influencias es John D. MacDonald. King ha sido un gran fanático de MacDonald a lo largo de su vida y la deuda que le debe al viejo escritor parece clara. Del mismo modo que King es un maestro en el género del terror, MacDonald es bastante popular en el género criminalístico. King aprendió mucho del arte de penetrar en la mente de los personajes, utilizado por MacDonald. La manera en que ambos escritores describen a los personajes, aunque en distinto estilo, son bastante similares. King y MacDonald demuestran una gran dedicación en su trabajo y practican bastantes horas diariamente. King dedicó la novela "Sun Dog" a MacDonald, escribiendo la frase «Te extraño, viejo amigo». 

Debido a su gran popularidad, King es comparado habitualmente con Dean Koontz y algunos admiradores desean leer un libro escrito entre los dos. Ambos escritores declararon lo imposible del proyecto, la razón principal es el hábito de King de tener personajes con una vida miserable, y Koontz tiene el de escribir finales felices para la mayoría de sus libros.

Escribió dos novelas colaborando con Peter Straub, "El talismán" y "Casa negra". King comentó que tenían planes de escribir el tercer y último de la saga pero no se ha propuesto ninguna fecha. Escribió además el ensayo "¡Campeones mundiales al fin!" con el novelista Stewart O'Nan.









</doc>
<doc id="2572" url="https://es.wikipedia.org/wiki?curid=2572" title="Smoke">
Smoke

Smoke, estrenada con el título Cigarros en Hispanoamérica, es una película estadounidense de 1995, dirigida por Wayne Wang. El escritor Paul Auster, autor del guion, fue también codirector (aunque no conste así en los créditos).

La película tuvo una continuación titulada "Blue in the Face", siguiendo a parte de los personajes de la primera e introduciendo algunos nuevos.

En torno a un estanco se desenvuelven las historias de un puñado de personajes solitarios cuyas vidas parecen marcadas por el azar: el escritor Paul Benjamin, que trata de recomponer su vida tras la muerte de su esposa por culpa de una bala perdida en un atraco; el joven Rashid Cole, que trata de encontrar a su padre, que le abandonó cuando sólo era un niño; Cyrus Cole, que vive la amputación de su brazo izquierdo como un castigo divino; o el dependiente Auggie Wren, que guarda en su pasado algunos secretos de los que no está del todo orgulloso.



</doc>
<doc id="2573" url="https://es.wikipedia.org/wiki?curid=2573" title="San Juan de Torres">
San Juan de Torres

San Juan de Torres es una localidad del municipio de Cebrones del Río, situado en el sur de la provincia de León, España.

En este pueblo se encuentran los restos de un antiguo castro celta situado en la cima de una colina.
El pueblo se encuentra atravesado por el río Órbigo, afluente del Esla.
El campo es una vega muy fértil que produce alubias, patatas, remolacha y maíz, regados por el canal o caño de Cuatro Concejos, canalizado y reformado con la concentración parcelaria.

El pueblo también es paso por una de las antiguas rutas de la Vía de la Plata. Aunque esta ruta es apenas conocida por los lugareños, se cree que pudiera ser la ruta original, actualmente desviada por posibles motivos políticos y económicos.

Antes pasaba un camino llamado Cañada, paso de trashumantes por donde circulaban los rebaños de ovejas en la primavera hacia la montaña y regresaban en invierno a Castilla, desaparecido por la parcelaria; queda solamente la calle Real dentro del pueblo.
Hace unos años había dos cofradías en el pueblo la de San Roque y San Antonio por rotación todos los años se elegían tres cofrades que se encargaban de hacer la sepultura en el cementerio de los cofrades fallecidos ese año. Todos los años esos cofrades hacían en casa de uno de ellos, una comida de cofraternidad, en una de esas comidas allá por los años que empezó la guerra civil, compraron la dehesa del Marqués de Castañón. 

Se comenta que fue por la euforia que tenían después de la comida. A pesar de las dificultades económicas que hubo en aquellos años, salieron adelante y les ha dado buenos beneficios. Es un pueblo donde en verano los que tienen la gran suerte de poseer una casa vuelven desde donde se encuentran a pasar unos días de vacaciones y así recordar y disfrutar de los pasajes extraordinarios teniendo gran relevancia la calle Real que parte muy cerca de la iglesia y tiene una historia de marqueses porque en ella residió el Marqués de Castañon.

También existía una iglesia románica perteneciente a los templarios. La iglesia fue destruida en los años 1970 y todos sus libros, reliquias, santos y obras de arte fueron vendidos o desaparecieron. La iglesia actual es una iglesia simple y pequeña. De la antigua sólo se conserva el campanar en forma de espadaña.
La torre de la iglesia ha sido restaurada, y se reformó la entrada a la iglesia, el altar y el techo, dándole un retoque a todo el interior.

Las fiestas del pueblo son el 24 de junio coincidiendo con San Juan Bautista. Es costumbre que los quintos del pueblo recojan ramas de árboles la noche de San Juan, y las reparten por el pueblo, para que todas las casas amanezcan adornadas con una rama en la puerta.


</doc>
<doc id="2576" url="https://es.wikipedia.org/wiki?curid=2576" title="Salicaceae">
Salicaceae

Salicaceae, las salicáceas, es una familia de plantas perteneciente al orden Malpighiales. La componen árboles o arbustos caducifolios y dioicos. Hojas alternas, simples, estipuladas. Flores inconspicuas, unisexuales, aclamídeas, acompañadas de brácteas y reunidas en amentos péndulos o erectos. Principalmente anemófilos y secundariamente entomófilos ("Salix"); periantio copiforme o nulo, androceo con 2 - 10 estambres; gineceo bicarpelar sincárpico de carpelos abiertos; numerosos óvulos; flores acompañadas de brácteas. Frutos en cápsula loculicida, que se abre mediante 2-4 valvas; con semillas numerosas, pequeñas, orladas de pelos (diseminación anemócora), con corto poder germinativo. Reproducción vegetativa importante. 

Comprenden unas 300 especies de climas templados y fríos, principalmente del hemisferio boreal. Forman choperas y saucedas de ribera.


</doc>
<doc id="2577" url="https://es.wikipedia.org/wiki?curid=2577" title="Salicales">
Salicales

Una única familia: Salicaceae. Árboles, arbustos y matas. Numerosos óvulos; 2 carpelos abiertos.

Es un sinónimo de Malpighiales.


</doc>
<doc id="2578" url="https://es.wikipedia.org/wiki?curid=2578" title="Sicono">
Sicono

Los siconos son un tipo de inflorescencia (infrutescencia, según la RAE), también considerados frutos compuesto o múltiple, típico del género "Ficus" al que pertenecen las higueras. Están compuestos de un receptáculo piriforme o redondeado, hueco en su interior y con una abertura apical llamada ostiolo, la cual es estrecha e intrincada cubierta de escamas interpuestas, protegido por pequeños hipsófilos; dentro y en las paredes de este receptáculo se hallan las flores y más tarde los diminutos frutículos de estas plantas. El nombre viene del griego y significa higo.

El sicono se caracterizó en los frutos del higo, consta de flores unisexuales: las flores femeninas constan de cinco pétalos y un solo carpelo. Se encuentran en el fondo del sicono. Por otro lado, las flores masculinas tienen tres sépalos y tres estambres, ubicándose en la entrada del sicono. Esto sólo es en aquellas inflorescencias de especies monoicas. Sin embargo existen especies dioicas.


</doc>
<doc id="2580" url="https://es.wikipedia.org/wiki?curid=2580" title="Sterculioideae">
Sterculioideae

Sterculioideae, según la última versión del Sistema de clasificación APG, APG III ha pasado a formar parte de Malvaceae como subfamilia. Antiguamente se consideraba distinta de las malváceas y era denominada Sterculiaceae, cuyo nombre proviene de uno de sus géneros: "Sterculia".

Según la circunscripción tradicional, Sterculiaceae, Malvaceae, Bombaceae y Tiliaceae comprendían el "núcleo Malvales" en el Sistema de Cronquist y la estrecha relación entre estas familias se reconoce generalmente. Sin embargo, Sterculiaceae se separa de Malvaceae "sensu stricto" debido a la suave superficie de los granos de polen y las anteras biloculares.

Numerosos estudios filogenéticos revelaron que Sterculiaceae, Tiliaceae y Bombacaceae como se definían tradicionalmente son cladísticamente polifiléticos, por lo que el estatus de cada una de las familias era incierto. El sistema de clasificación APG y APG II reunieron Bombacaceae, Malvaceae "sensu stricto", Sterculiaceae y Tiliaceae en una circunscripción más amplia de Malvaceae, es decir, Malvaceae "sensu lato". Según este punto de vista, los taxones anteriormente clasificados en Sterculiaceae se encuentran en las subfamilias Byttnerioideae, Dombeyoideae, Helicteroideae y Sterculioideae de Malvaceae "sensu lato".

Sterculiaceae fue reconocida como familia por la mayoría de los sistemáticos; en su sentido tradicional incluía alrededor de 70 géneros (), totalizando unas 1500 especies de árboles y arbustos tropicales. Entre ellas "Theobroma cacao" y "Cola acuminata", además de muchas especies utilizadas por su madera.

Sterculioideae está compuesta por 12 géneros y unas 430 especies de distribución pantropical, son árboles y arbustos tanto perennes como caducifolios cuyas especies 
están caracterizadas pr sus flores sin pétalos (apétalas), sin epicaliz, y por la presencia de un cáliz carnoso, usualmente petaloideo y gamosépalo. No presentan tampoco estaminoideos pero tienen una columna estaminal monadelfa (o sea, con todos los estambres unidos entre sí) y gineceos y frutos apocárpicos, o sea, con los carpelos separados. Las flores son típicamente monóicas: existen flores femeninas y masculinas en la misma planta.



</doc>
<doc id="2581" url="https://es.wikipedia.org/wiki?curid=2581" title="Saxifragaceae">
Saxifragaceae

Saxifragaceae es una familia de plantas del orden Saxifragales, con 80 géneros y unas 1200 especies, la mayoría de regiones templadas y frías del hemisferio boreal o América del Sur. 

Plantas herbáceas o leñosas con predominio de hierbas perennes. Hojas alternas, opuestas o en roseta, simples aunque a veces profundamente recortadas. Flores hermafroditas, normalmente actinomorfas, pentámeras; androceo diplostémono; gineceo súpero, semiínfero o ínfero, abiertos o cerrados, con los carpelos unidos en la parte inferior. Inflorescencias generalmente en racimo o panícula. Frutos en cápsula, con gran número de semillas. Reproducción vegetativa muy importante, por bulbillos, bien radiculares, bien en las axilas de las hojas.



</doc>
<doc id="2583" url="https://es.wikipedia.org/wiki?curid=2583" title="Siglo XX">
Siglo XX

El d.C. (siglo veinte después de Cristo) o e.c. (siglo veinte de la era común) fue el último siglo del II milenio en el calendario gregoriano. Comenzó el y terminó el . Es llamado el «siglo de la vanguardización».

El se caracterizó por los avances de la tecnología, medicina y ciencia; el fin de la esclavitud en los llamados países subdesarrollados; la liberación de la mujer en la mayor parte de los países occidentales; pero más que todo por el creciente desarrollo de la industria, convirtiendo a varios países, entre ellos Estados Unidos, en potencias mundiales. También el siglo se destacó por las crisis y despotismos humanos en forma de regímenes totalitarios, que causaron efectos tales como las Guerras Mundiales; el genocidio y el etnocidio, las políticas de exclusión social y la generalización del desempleo y de la pobreza. Como consecuencia, se profundizaron las desigualdades en cuanto al desarrollo social, económico y tecnológico y en cuanto a la distribución de la riqueza entre los países, y las grandes diferencias en la calidad de vida de los habitantes de las distintas regiones del mundo.

Al hacer balance de esta centuria, Walter Isaacson, director gerente de la revista "Time" declaró: «Ha sido uno de los siglos más sorprendentes: inspirador, espantoso a veces, fascinante siempre».

Según Gro Harlem Brundtland, ex primera ministra de Noruega, se trata de «un siglo de grandes progresos [y, en algunos lugares,] crecimiento económico sin precedentes», si bien las zonas urbanas míseras afrontaron un lúgubre panorama de «hacinamiento y enfermedades generalizadas vinculadas a la pobreza y al ambiente insalubre».

A inicio del , América Latina enfrentaba importantes cambios. Los países se habían insertado definitivamente en el sistema mundial y estaban dedicados a producir y exportar materias primas como alimentos y metales y también a importar manufacturas de los países industrializados.

El Imperio británico (que dominaba una cuarta parte del planeta y de sus habitantes), varios imperios europeos, el Imperio chino de la Dinastía Qing y el Imperio otomano controlaban gran parte del mundo en los albores del . Mucho antes de finalizar el siglo, tales imperios habían quedado relegados a los libros de historia. Al final del siglo, tras la disolución de la Unión Soviética, el primer y mayor Estado socialista, Estados Unidos de América quedó como la única superpotencia mundial.

El siglo xx se inicia en medio de grandes adelantos tecnológicos, entre los cuales el automóvil ocupa un lugar destacado. En América Henry Ford adelantó una verdadera revolución en el sistema de producción en cadena industrial que puso a prueba con la fabricación de su Modelo T. El 17 de diciembre de 1903 los hermanos Wright se convirtieron en los primeros en realizar un vuelo en un avión controlado,​ no obstante algunos afirman que ese honor le corresponde a Alberto Santos Dumont, que realizó su vuelo el 13 de septiembre de 1906.​ El avión se convertiría en uno de los más importantes inventos no solo de este siglo sino de la historia en general. En 1905, la guerra ruso-japonesa enfrentó al Imperio del Japón con el imperio de los zares de Rusia. El fin de la guerra dio como vencedor a Japón para la sorpresa del mundo occidental. La nación asiática se convirtió de facto en una nueva potencia mundial. En Rusia surge la revolución rusa de 1905, que se convertiría en la precursora de la que sucedió en 1917 y acabó provocando la caída del imperio ruso. El Imperio alemán o Segundo Reich comenzó a forjarse en torno a Prusia de una manera clara desde el reinado de Federico II el Grande y se consolidó de manera definitiva en las últimas décadas del siglo xix, gracias al impulso dado por Otto von Bismarck. En los primeros años del siglo xx, la situación de Alemania dentro de Europa había alcanzado una posición demasiado crucial para los intereses de las demás potencias. Especialmente, Gran Bretaña y Francia veían amenazados muchos de sus intereses, lo que las llevó a suscribir la llamada "Entente cordiale", ya que el desarrollo industrial y militar de Alemania se presentaba difícil de igualar por el conjunto de las naciones europeas. Además, este ímpetu de Prusia condujo a la Casa de Austria (Imperio austrohúngaro) a perder progresivamente su condición de potencia continental. La Conferencia de Algeciras consigue evitar que estalle una gran guerra entre las potencias europeas. En 1902 finaliza la segunda Guerra de los Bóer con la victoria inglesa y con la utilización masiva de campos de concentración por parte de estos. También ese año finaliza la Guerra filipino-estadounidense con la victoria estadounidense, provocando la muerte del 10 % de la población filipina de la época (se habla de genocidio filipino) y convirtiéndose en la primera guerra de liberación nacional del siglo xx. Algunos países obtienen la independencia como Australia (del Imperio británico, 1901), Cuba (de EE. UU., 1902), Panamá (de Colombia, 1903), Noruega (de Suecia, 1905) y Bulgaria (del Imperio Otomano, 1908). En 1905 el científico alemán Albert Einstein formula la Teoría de la relatividad, una de las más famosas de la historia.


La política de los años 1910 se ve fuertemente afectada por el estallido de la Primera Guerra Mundial, llamada la Gran Guerra. La transición del siglo XIX al XX empieza a ser palpable, con la muerte de Victoria del Reino Unido y el fin total de la Época Victoriana, así como el comienzo del capitalismo norteamericano tras haber salido ilesos de la Primera Guerra Mundial. La Revolución Rusa, daría paso también a otra futura superpotencia mundial, la Unión Soviética. En cuanto a la sociedad, se ve en un cambio abrupto, con la aparición de vehículos particulares al alcance de cada vez más parte de la población. En cuanto a la cultura, la música clásica se empieza a desplazar para dar paso a otros estilos de música mucho más populares, que con el paso de las décadas cobrarían cada vez más importancia. En Nueva York en 1913 se construiría el edificio más alto del mundo, un complejo proyecto arquitectónico para la época, el Woolworth Building, que seguiría siendo el edificio más alto hasta los años 1930.


Los años 1920, supusieron el fin de la hegemonía de los estados históricos que habían existido en Europa durante siglos. Tras la Primera Guerra Mundial, Reino Unido y Francia sufrieron una gran perdida de prestigio, que le costaría volver a recuperar. En los Estados Unidos sucede el crac del 29, la mayor caída en la bolsa nunca vista, esto sucumbiría al mundo en unos años de pobreza extrema. En 1922 tras el fin de la Guerra Civil Rusa, se formaría oficialmente la Unión Soviética, un año más tarde el Imperio Otomano caería. Los estados fascistas que emergerían sobre todo durante la década de los años 1930 empiezan a surgir, como la Italia fascista de Benito Mussolini, la dictadura de Primo de Rivera en España o Alejandro I en Yugoslavia. El Imperio de Japón comenzaría su dominio por toda Asia. La música sufrió un resurgimiento popular con el afloramiento de géneros como el jazz, el tango, el charlestón y otros ritmos, por otra parte en la música culta tomó relevancia el dodecafonismo y el atonalismo; especialmente en los Estados Unidos entre el breve pero intenso periodo que fue de 1923 hasta 1929, en la moda (entre las que resaltó la modista francesa Coco Chanel) las mujeres de clase alta o presumiblemente alta llegaron a usar en Occidente las primeras minifaldas así como muchas veces el corte de cabello llamado "a la garçon" (en francés: a lo muchacho), amplios escotes y brazos expuestos al aire libre y cierto liberalismo sexual promovido por los escritos de la antropóloga Margaret Mead entre otros ( Mead se encontró influida en gran medida por sus interpretaciones de la teoría psicoanalíticainaugurada décadas antes por Sigmund Freud), también las mujeres de estratos medios y altos comenzaron a fumar tabaco en forma de cigarrillos públicamente en los países «Occidentales» y occidentalizados. En pintura y escultura sobresalieron muchas veces dentro de un ambiente bohemio los vanguardismos como (en lo visual casi siempre no figurativos o de un arte figurativo muy distorsionado) el rayonismo, el orfismo, el constructivismo, el cubismo, el suprematismo, el surrealismo, el neoplasticismo (con Mondrian como principal representante); y en general la pintura abstracta así como el movimiento postexpresionista (que sin embargo pese a sus manifiestos mantenía mucho de expresionismo) caricaturezco y sarcástico llamado nueva objetividad; entre los muchos notorios artistas que surgieron o tuvieron su apogeo en esos años están los españoles Picasso, Dalí, el alsaciano Arp, el alemán Max Ernst, el suizoalemán Paul Klee, los rusos El Lisitski, Lariónov, Tatlin; los italianos Modigliani y Giorgio de Chirico, el japonés Fujita entre muchos otros.


La década de 1930 está claramente influida por la crisis económica (llamada «Gran Depresión») provocada por el Crac del 29 , que tuvo un alcance mundial y provocó fuertes tensiones sociales y políticas que permitieron la aparición de dictaduras como la de Hitler en Alemania, Franco en España o Metaxas en Grecia. Este surgimiento de totalitarismos acabó desembocando en una nueva guerra mundial. Alemania se desarrolla nuevamente, la economía se relanza con el impulso que le da la industria y la inversión del Estado en infraestructuras. El nuevo régimen nazi obtiene numerosos territorios sin disparar un solo tiro, frente a la cual se opone una política de apaciguamiento liderada por las democracias liberales occidentales que finalmente fracasó. El Imperio japonés se consolidaba en Asia afectando los intereses de Europa y Estados Unidos., especialmente en el Pacífico. Japón crea un «estado títere» en China bajo el nombre de Manchukuo. Por su parte Italia inicia una política de rearme militar y expansiva territorialmente que le lleva a la invasión de Etiopía. En Estados Unidos el presidente Franklin Delano Roosevelt lideró la recuperación económica del país tras la crisis provocada por la Gran Depresión de 1929. Gran Bretaña mantuvo su sistema político prácticamente inalterable, al contrario que Francia, que no logró consolidar una organización político-social fuerte y bordeó la guerra civil. Luego de su transformación en la Unión Soviética, Rusia fue escenario de hambrunas endémicas (como la hambruna ucraniana), represión política y la Gran Purga.


La Segunda Guerra Mundial marcó como ningún otro acontecimiento los años 1940 y el siglo en general. Al igual que en 1914, la guerra se extendió a diversos continentes, aunque este conflicto fue mucho más sangriento y modificó el mundo de una manera más radical. En 1945, al final de la guerra, Alemania había sufrido enormes pérdidas humanas y materiales, al igual que Japón. Si bien Alemania sufrió la mayor cantidad de bajas militares, fue la Unión Soviética la que sufrió el mayor número de bajas civiles. América no fue escenario de enfrentamientos significativos y los estados latinoamericanos estuvieron al margen de la confrontación, aun cuando de manera oficial apoyaron la causa de los aliados. Estados Unidos y la Unión Soviética se convirtieron en las nuevas y únicas potencias del mundo. Todas las demás antiguas potencias pasaron a un segundo nivel. La Sociedad de Naciones fue reemplazada por la ONU, que a diferencia de la anterior tuvo su sede en Nueva York y no en Europa. En 1948, se estableció formalmente el estado de Israel gracias al respaldo de Gran Bretaña y Estados Unidos. Esta nueva nación estaba conformada netamente de población judía, que en su mayoría era proveniente de Europa, donde había sufrido la persecución por parte de los nazis. Empieza el conflicto árabe-israelí. Las dos fuerzas principales de China que lucharon contra Japón, que fue su enemigo común durante la guerra, se vieron enfrentadas poco después en una guerra civil por el control del territorio. El bando comunista se vio apoyado decididamente por la Unión Soviética y el bando nacionalista, en apariencia respaldado por Estados Unidos, fue derrotado y obligado a recluirse en la isla de Formosa (actual Taiwán). La India consiguió su independencia a través de la revolución pacifista de Majatma Gandhi.


Durante esta década, las dos superpotencias vencedoras de la segunda guerra mundial, Estados Unidos y la Unión Soviética, rompieron su alianza durante la guerra y se enemistaron convirtiéndose en líderes de dos bloques: el bloque Occidental (occidental-capitalista) liderado por Estados Unidos, y el bloque del Este (oriental-comunista) liderado por la Unión Soviética y el mundo vio formarse lo que se conoció como Guerra Fría. Poco después del fin del conflicto mundial, la guerra civil en China, dio el triunfo de Mao Zedong quien instauró en la parte continental de su nación un régimen totalitario de base comunista que revolucionó al país, reconocido como República Popular China. En la década de 1950, la disputa entre los dos nuevos ejes mundiales, se intensificó notablemente con la guerra de Corea y la posterior división del país en dos estados diferentes. Se inició una carrera armamentista sin precedentes que se extendería en las siguientes décadas, así la URSS y EE. UU. se iniciaron a la carrera de un arsenal nuclear capaz de destruir todo el planeta. El proceso de descolonización iniciado después de la segunda guerra mundial se intensifica y marcará esta década y las dos siguientes. Imperios como el francés o el británico se desprenden de numerosas posesiones en África, Oriente Medio y Asia. Estados Unidos vio una revolución cultural impulsada por el rápido desarrollo industrial y el consecuente fenómeno de consumismo. Alemania y Japón experimentaron una sorprendente recuperación económica en menos de dos décadas después del final de la guerra, había transformado a ambos países en potencias económicas, si bien no políticas ni militares. Por lo tanto, aunque Francia y Gran Bretaña tenían un mayor peso político, Japón y Alemania superaban a los dos países que obtuvieron la victoria en la segunda guerra e incluso su presencia en el comercio internacional superaba a la de la URSS. Un proceso de importancia capital para el futuro de Europa y el mundo se inició cuando Robert Schuman pronunció la célebre declaración homónima y que constituye el embrión de la actual Unión Europea.


.En los años 1960 se asiste a los momentos de mayor conflicto político entre los bloques formados por Estados Unidos y la Unión Soviética, en la llamada Guerra Fría, que surgió al término de la Segunda Guerra Mundial. Momentos de enorme tensión se produjeron a partir del derribo del avión espía norteamericano “U2” sobre territorio soviético, y durante la conocida como "Crisis de los misiles de 1962", que los analistas consideran puso al mundo al borde del inicio de una tercera guerra mundial. Dicho conflicto demostró que los intentos de Estados Unidos por detener el avance del comunismo no estaban siendo fructíferos, y además conllevó posteriormente al "tratado de convivencia pacífica" entre las dos potencias mundiales.Este comienzo de la década es representativo de un período que estaría caracterizado por las confrontaciones internacionales y las protestas de una ciudadanía cada vez más crítica con las acciones de sus gobernantes y la situación que se dibujaba en el mundo tras la recuperación económica de la posguerra: movimientos de protesta contra la guerra de Vietnam; contra la invasión de las tropas soviéticas en Checoslovaquía, en la Primavera de Praga; en Mayo del 68 contra el orden establecido, durante las revueltas estudiantiles y sindicales que se inician en Francia y se extienden rápidamente por otros países. Los efectos socioculturales de estos movimientos de protesta aún se sienten actualmente. También es una década en la que se producen gran cantidad de asesinatos políticos, siendo ejemplo de ello las muertes de John F. Kennedy, Malcolm X, Martin Luther King y Robert F. Kennedy. La ""carrera espacial"", mantuvo temporalmente en cabeza a la Unión Soviética, con notables éxitos como el de haber conseguido poner al primer ser humano en órbita: el cosmonauta Yuri Gagarin. Los Estados Unidos consiguen la mayor victoria de esa carrera al lograr colocar al primer ser humano sobre la superficie lunar en 1969. Esto se logró en gran medida gracias al impulso dado por el presidente John F. Kennedy, quien había sido asesinado en 1963 en oscuras circunstancias que sumieron al pueblo estadounidense en la más profunda crisis de identidad que ha conocido hasta ahora. En Europa se consolidan las reconciliación franco-alemana, sobre las que en gran medida se basaría la construcción de la Unión Europea (UE) que se había iniciado en la década anterior. Alemania se afianza como tercera potencia económica mundial detrás de Estados Unidos y Japón. Gran Bretaña, al igual que Francia, pierde prácticamente la totalidad de sus colonias, en un proceso que se inició una vez finalizada la Segunda Guerra Mundial y que se vio precipitado en gran medida tras la independencia de Libia. Puede considerarse la década de las ideologías. En Europa la juventud se alza en lo que posteriormente se conoció como el "Mayo Francés", en 1968. Los movimientos sociales adquieren cada vez mayor importancia en América Latina, particularmente en Chile, donde en 1970 un gobierno socialista llegaría al poder por la vía democrática. En Oriente Medio se había vivido una trascendental transformación, debido a la instauración del estado de Israel en 1948, el cual quedó enclavado en el centro neurálgico de esta región. Además, las ingentes reservas de petróleo descubiertas principalmente en los llamados países del Golfo, le dieron a esta región un peso sin precedentes en la economía del planeta. La China de Mao vivió en esta década la llamada "Revolución cultural", que supuso una transformación de la milenaria sociedad de este país. Mientras tanto, Japón continuó desarrollando su reputación de potencia tecnológica y los productos provenientes de este país empezaron a alcanzar prestigio en todo el mundo, impulsando la economía del país, mientras la sociedad era reestructurada radicalmente pero conservando sus raíces culturales.


El conflicto árabe-israelí y la etapa final de la guerra de Vietnam dominan la mayor parte de la vida política de los años 1970. El mercado del petróleo se ve sacudido por las disposiciones de la Organización de Países Exportadores de Petróleo que arrastra a los países industrializados a una crisis en el sector energético y por ende a toda la industria y la sociedad. Se da un bloqueo en el suministro del petróleo y ahora son las naciones productoras las que fijan los precios del combustible. Es también la década del auge del terrorismo, con grupos de extrema izquierda como el IRA, RAF, Brigadas Rojas, ETA, FLNC, Ejército Rojo Japonés, NEP, Yihad Islámica, Septiembre Negro o FPLP. Terroristas como Carlos el Chacal se hicieron muy famosos. Algunos gobiernos respondieron al terrorismo aplicando terrorismo de Estado. La Casa Blanca es escenario del escándalo "Watergate" que llevó a que el presidente Richard Nixon fuera el único presidente estadounidense en renunciar a su cargo en este siglo. Al mismo tiempo, el intervencionismo del gobierno de este país ayuda a instaurar dictaduras militares afectas a Washington en varios países de América Latina. En Asia finaliza la guerra de Vietnam con la retirada de EE.UU. y en Camboya los jemeres rojos inician uno de los peores genocidios del siglo. El bloque comunista que la Unión de Repúblicas Socialistas Soviéticas logró conformar durante varias décadas, empieza a dar señales de desintegración y la potencia soviética se distancia de la China comunista, lo que trae consigo el debilitamiento de la influencia comunista en el mundo. En Europa a pesar de la crisis energética, los países occidentales de este continente logran igualar el nivel de vida de Estados Unidos de América y los países escandinavos consiguen el más alto equilibrio económico social del mundo. Las dictaduras del sur de Europa (Grecia, Portugal y España) desaparecen y dan lugar a regímenes democráticos. Varias guerras de esta década fueron breves: Guerra indo-pakistaní de 1971, Guerra del Yom Kippur, Invasión turca de Chipre, Guerra de Ogaden y Guerra sino-vietnamita. En 1979 los fundamentalistas musulmanes toman el control de Irán bajo el liderazgo de Ayatolá Ruholá Jomeini, con lo que este país se retira de la influencia occidental y se encierra en el más radical de los estados basados en la Sharia (ley islámica). En el ámbito social, se popularizan enormemente los electrodomésticos como el microondas y otros dispositivos como el walkman, el microprocesador, el ordenador, la calculadora o la televisión en color. El auge de las drogas provoca graves daños sociales, especialmente el de la heroína, epidemia que se agravaría en la década siguiente.


El inicio de este decenio está marcado por el aumento de las tensiones de la Guerra Fría entre Estados Unidos y la Unión Soviética. La amenaza nuclear se hace más patente que nunca, por lo que a mediados de la década se produce un acercamiento entre los dos bloques, que se ve favorecido principalmente por las políticas conocidas en Occidente como Glásnost y Perestroika, del mandatario soviético Mijaíl Gorbachov. En el plano económico, el presidente de Estados Unidos, Ronald Reagan, presenta una serie de medidas económicas de libre mercado, popularmente conocidas como Reaganomics, que sientan las bases de la economía neoliberal de los años venideros. Por otra parte, las diferencias en el desarrollo entre los diferentes pueblos del mundo se evidencian con la hambruna que devasta a varios países de África. En Etiopía la situación se torna particularmente dramática debido a la sequía. Países asiáticos como Corea del Sur, Taiwán y Singapur así como la región de Hong Kong experimentan un rápido desarrollo industrial que no se detendría durante el resto del siglo. La existencia del sida se hace pública por primera vez en junio de 1981 y acabará presentándose ante el mundo como una epidemia de enormes proporciones. Chernóbil, localidad ucraniana al norte de Kiev, se convierte en el símbolo de la incapacidad del hombre para controlar el monstruo que ha creado: el riesgo continuo e inapelable de la técnica nuclear. La catástrofe nuclear contamina toda una región y provoca una lluvia radiactiva en amplias zonas de Europa. México vivió el peor terremoto de su historia, el Terremoto de México de 1985, con una magnitud de 8.1 grados en la Escala Richter que dejó unas 10,000 víctimas. En 1985 en Colombia se desató la Toma del Palacio de Justicia en Bogotá por parte del comando guerrillero M-19. También en Colombia se vivió la peor catástrofe en su historia ocasionado por el volcán del Nevado del Ruiz causando la Tragedia de Armero falleciendo más de 28.000 personas. Otro aspecto importante de esta década fueron las desapariciones forzadas en Latinoamérica que ya habían comenzado en la década anterior. Perú, que salía del Gobierno Revolucionario de las Fuerzas Armadas por 11 años y que retornaba a la democracia de forma dictatorial, se enfrenta a la organización terrorista maoísta Sendero Luminoso, que inicia su lucha armada en Ayacucho y que poco a poco fue incursionando en la capital. En 1983 Argentina vuelve a la democracia de forma insegura, luego de que el año anterior fuera la Guerra de las Malvinas y resultaran derrotados, y asume Raúl Alfonsín a la presidencia. En 1985 se condena en un Juicio a las Juntas a los represores militares de la dictadura, siendo Argentina el primer y único país de Latinoamérica en hacerlo. Tras 15 años de dictadura militar los chilenos vuelven a las urnas en 1988 para decidir la continuidad del general Augusto Pinochet en el gobierno. El plebiscito le fue adverso y la democracia vuelve de forma insegura en 1990. El terrorismo internacional que se venía presentando desde la década anterior se intensifica y los Estados Unidos bombardea la Libia de Muamar Gadafi, como represalia por ataques terroristas supuestamente patrocinados por ese país. En 1989 la URSS y el bloque soviético en general se encuentran más debilitados que nunca. En noviembre el muro de Berlín que encarnaba la división de dicha ciudad desde el fin de la Segunda Guerra Mundial, fue demolido por los propios berlineses, dando con ello el golpe de gracia a la era soviética y convirtiéndose en el símbolo de las revoluciones de 1989 en los países de Europa del este. En el ámbito cultural, esta década tiene muchos seguidores de su estilo de vida, como la moda, la música y exhibiciones televisivas y del séptimo arte, exclusivas, en la opinión de muchos admiradores, de este decenio. Los videojuegos se hacen cada vez más populares y comienza a extenderse como una nueva cultura.


La caída del muro de Berlín y el derrumbamiento de la Unión Soviética abrieron una época conocida como la Post Guerra Fría. El colapso soviético liquidó la antigua política de bloques, nacida tras el final de la Segunda Guerra Mundial y dio paso a un nuevo cuadro internacional con los Estados Unidos como única superpotencia. Algunos hablaban del "fin de la historia", en la que las democracias liberales han ganado al comunismo y finaliza la lucha de ideologías iniciada en el siglo xix. En Europa la década se inicia pocos meses después de la caída del muro de Berlín en 1989 y el fin de la Guerra Fría. Gran cantidad de los países del este europeos se encontraban en un doble proceso de transición: de dictadura a democracia, y de economía planificada a economía de mercado. Algunos países como Checoslovaquia, Yugoslavia y la propia URSS se desintegraron. En el caso yugoslavo se produjeron enfrentamientos violentos debido a los nacionalismos que provocaron las llamadas «guerras yugoslavas» durante toda la década. Otros países que estaban ligados económicamente a la URSS sufrieron una fuerte caída económica como Cuba, Corea del Norte o Finlandia. Por otro lado, se acelera la integración de la Unión Europea, con acuerdos como el Tratado de Maastricht o el Tratado de Ámsterdam. En Asia, China recupera la colonia británica de Hong Kong en 1997 y la portuguesa de Macao en 1999. La crisis financiera asiática iniciada en 1997 provocó el aumento de la pobreza generalizada en los países del Sudeste Asiático. En África la Segunda Guerra del Congo involucra a varios países africanos y provoca millones de muertos. En 1994 en Ruanda ocurrió el genocidio más sanguinario de la historia en proporción a su duración.Culturalmente, la década de 1990 se caracterizó por el auge del multiculturalismo y de los medios alternativos, que continuó en el siguiente siglo. Se produjo el auge de nuevas tecnologías, como la televisión por cable y de internet. En la TV aparecen los primeros realities televisivos. El fin de la década coincide con la explosión de la burbuja de las punto-com, que se infló entre los años 1997-2000 y estalló en el año 2000, llevando a la quiebra a numerosas empresas tecnológicas en los países más desarrollados.


















</doc>
<doc id="2584" url="https://es.wikipedia.org/wiki?curid=2584" title="Santalales">
Santalales

Los Santalales son un orden de plantas de flor perteneciente a las dicotiledóneas. 

Tienen tendencia a la reducción de la corola; además, la mayoría tienen tendencia a la vida parásita o semiparásita —pueden producir alimento a través de la fotosíntesis pero barrenan las raíces de otras plantas para obtener agua—, tendencia a la pérdida o reducción de la clorofila: mixotrofía y reducción del aparato vegetativo. Actinomorfas, periantio sencillo, con un verticilo de estambres, gineceo ínfero. La mayoría tienen semillas sin capa exterior protectora, lo que es atípico de las angiospermas.
Las siguientes familias son típicas de los nuevos sistemas de clasificación:


En el antiguo Sistema de Cronquist, algunas de las Santalaceae son reconocidas como familias separadas llamadas Viscaceae y Eremolepidaceae. Otras 3 familias estaban incluidas también:


Estas ya no se consideran familias próximas de las Santalaceae pero, por el momento, su clasificación es incierta.


</doc>
<doc id="2585" url="https://es.wikipedia.org/wiki?curid=2585" title="Santalaceae">
Santalaceae

Las santaláceas (Santalaceae) son una familia de plantas perteneciente al orden de las santalales. 
Son plantas herbáceas o leñosas, hemiparásitas, con haustorios en las raíces de los huéspedes. Presentan hojas simples, habitualmente alternas. Las flores son inconspicuas, hermafroditas o unisexuales, actinomorfas, con perianto de tres a seis piezas, ovario ínfero, unilocular y carpelos abiertos. Los frutos pueden ser núculas o drupas. Agrupa a unas 450 especies de países cálidos y templados.

Los géneros "Arjona" y "Quinchamalium" actualmente se disponen en la familia Schoepfiaceae.




</doc>
<doc id="2586" url="https://es.wikipedia.org/wiki?curid=2586" title="Sapindales">
Sapindales

Las Sapindales son un orden de plantas dicotiledóneas, genéticamente próximo al orden Malvales; en las clasificaciones actuales incluyen, entre las familias más conocidas a los "Citrus", los cítricos.

Se caracterizan por poseer dos verticilos de estambres (a veces uno reducido a estaminodios), de manera que son predominantemente pentacíclicas. Disco nectarífero de posición variable (a veces reducido a glándulas internas).

Predominan las hojas compuestas (si bien en los citrus son simples), el hábito leñoso, las flores pentámeras y el ovario súpero. Las inflorescencias son cimosas.

Este orden contiene nueve familias, unos 460 géneros y alrededor de 5700 especies. Más de la mitad de las especies de este orden pertenecen a dos de sus familias: Sapindaceae (con unas 1600 especies), donde se encuentran recogidas tanto Hippocastanaceae como Aceraceae; y Rutaceae (con unas 1800 especies).


Las tres familias en las que no se detalla en número de especies que consta, suman unas 27 especies entre las tres.



</doc>
<doc id="2589" url="https://es.wikipedia.org/wiki?curid=2589" title="Suecia">
Suecia

Suecia (en sueco: ), oficialmente Reino de Suecia (en sueco: ), es un país escandinavo de Europa del Norte que forma parte de la Unión Europea (UE). Limita al norte con Noruega y Finlandia, al este con Finlandia y el golfo de Botnia, al sur con el mar Báltico y al oeste con el mar del Norte y Noruega. Tiene fronteras terrestres con Noruega y Finlandia, y está conectado a Dinamarca por el puente de Øresund. Su ciudad más poblada es Estocolmo, que es también su capital.

Con una extensión de km², es el quinto país más extenso de Europa. En 2016, contaba con una población total de poco más de 10 millones de personas, de las cuales el 98% cuenta con acceso a Internet, lo que lo convierte en el . Tiene una densidad de población de solo 22 h/km², similar a otros países de su entorno. Cerca del 84% de la población vive en zonas urbanas. Los suecos disfrutan de un alto nivel de vida, con una organización y cultura corporativa no jerárquica, y colectivista en comparación con sus homólogos anglosajones. La conservación de la naturaleza, la protección del medio ambiente y la eficacia energética son, por lo general, una prioridad en la formulación de políticas y cuentan con acogida por gran parte del pueblo. Mantiene el modelo nórdico de bienestar que brinda asistencia sanitaria universal y educación terciaria gratuita a sus ciudadanos, tiene el undécimo ingreso per cápita más alto del mundo y ocupa un lugar destacado en numerosas mediciones de desarrollo humano, incluida la calidad de vida, seguridad, salud, educación, igualdad, y prosperidad.

La mejora de los transportes y las comunicaciones ha permitido la explotación a gran escala de bienes naturales, sobre todo la madera y el mineral de hierro. En la década de 1980, la escolarización universal y la industrialización permitieron al país desarrollar una exitosa industria manufacturera. Tiene una rica oferta de energía hidráulica, pero carece de petróleo y de yacimientos de carbón importantes. En el siglo XX se ubicó constantemente entre los países con mejor Índice de Desarrollo Humano (IDH), actualmente ocupando la octava posición.

La Suecia moderna surgió de la Unión de Kalmar en 1397, y de la unificación del país por el rey Gustavo Vasa en el siglo XVI. En el siglo XVII, amplió sus territorios para formar el Imperio sueco. La mayor parte de los territorios conquistados fuera de la península escandinava se perdieron durante los siguientes siglos. La mitad oriental de Suecia constituida por la mitad oriental de Norrland y Österland se perdió frente a Rusia en 1809. Desde 1814, no ha participado en ningún conflicto, manteniendo una política exterior de paz y neutralidad en tiempo de guerra.

El nombre «Suecia» deriva del latín "Suetidi", el cual proviene del vocablo del inglés antiguo "Sweoðeod", que significa «pueblo de los suiones» (en escandinavo antiguo "Svíþjóð"). Esta palabra deriva de "sweon/sweonas" (en escandinavo antiguo "sviar", en latín "suiones"). La etimología de "Suiones", y por ende de Suecia, deriva probablemente del proto-germánico "Swihoniz", que significa «propiedad de uno», refiriéndose a la propiedad de una tribu germánica. El nombre en sueco, "Sverige", significa literalmente «Reino de los suiones» ("sve" ‘suiones’; "rike" ‘reino’), el cual se utilizaba para designar la zona sur del país habitada por la tribu germánica del mismo nombre.

Variaciones del inglés Sweden se utilizan en la mayoría de los idiomas, excepto en danés y en noruego, donde el nombre es el mismo que en sueco, Sverige. En los idiomas finlandés (Ruotsi) y estonio (Rootsi), el nombre proviene de la misma raíz que la palabra «Rusia», refiriéndose a la etnia rus, originaria de las zonas costeras de Uppland y Roslagen.

Su prehistoria comienza en el periodo llamado Oscilación de Allerød, alrededor del año 12 000 a. C. durante el Paleolítico superior, con la llegada de grupos nómadas de cazadores-recolectores en la zona sur del país, caracterizados por el uso de puntas de flecha hechas de piedra.

La agricultura y la ganadería, junto con la construcción de monumentos megalíticos, llegaron del continente con la cultura de los vasos de embudo alrededor del año . El sur de Suecia fue parte del área donde se desarrolló la Edad de bronce nórdica. Este periodo comenzó cerca del año con el inicio de la importación del bronce desde Europa central. La minería no fue practicada durante este periodo y como el territorio no posee grandes yacimientos, todos los metales eran importados. La Edad de Bronce Nórdica fue completamente pre-urbana: la gente se volvió sedentaria y vivía en pequeñas aldeas y granjas, en casas comunales hechas de madera.

En ausencia de la dominación del Imperio romano, se considera que la Edad del Hierro sueca finalizó en el momento de la introducción en sus tierras de la arquitectura de piedra y de órdenes monásticas alrededor del año 1100. Como los registros escritos de esta época son de poca credibilidad, este periodo es considerado protohistórico, es decir, que aquellos registros aparecieron después del periodo en cuestión, y que fueron escritos en distintas áreas, o que los registros locales y contemporáneos son extremadamente cortos.

Un intento de los romanos por extender su imperio más allá de los ríos Rin y Elba fue abortado en el año , cuando los germanos derrotaron a las legiones romanas bajo el mando de Varo, al emboscarlas en la batalla del bosque de Teutoburgo. Alrededor de esta época hubo un gran cambio en materia de cultura en Escandinavia, resultado de un mayor contacto con los romanos.

Durante esta época el clima empeoró, forzando a los granjeros a resguardar a sus animales dentro de cobertizos durante los largos inviernos. Esto llevó a una acumulación anual de estiércol, que pudo ser usado por primera vez de forma sistemática para el enriquecimiento del suelo. De esta forma, la agricultura y la ganadería progresaron y se convirtieron en el motor económico de las primeras ciudades. A principios del siglo II, gran parte del suelo cultivado del sur de sus tierras fue dividido en lotes con bardas pequeñas hechas de piedra. De un lado del muro se encontraban los sembradíos permanentes y prados para el forraje de invierno, mientras que del otro estaba el bosque y la tierra para pastar el ganado. Esta división de la tierra fue usada hasta el siglo XIX.

En la protohistoria entró con el libro "Germania" de Cornelio Tácito en el año 98. Aunque la poca información que reporta sobre esta distante área ha sido estimada como incierta, ya que hace mención a varias tribus, como los suiones y los lapones de siglos posteriores. En cuanto a su escritura, el alfabeto rúnico fue inventado por la élite del sur de Escandinavia en el siglo II, pero todo lo que ha llegado al presente son breves inscripciones en artefactos, principalmente nombres masculinos, poniendo en evidencia que los pueblos del sur de Escandinavia hablaban proto-nórdico en aquella época, un idioma del que se derivó el sueco y otras lenguas nórdicas.

La época vikinga sueca abarca desde el siglo VIII hasta el XI. Durante este periodo, se cree que los suiones se expandieron hacia el sureste y se mezclaron con los gautas que habitaban el sur de la actual Suecia. Los vikingos suecos y los vikingos guter realizaban viajes principalmente hacia el este y hacia el sur, yendo a Finlandia, los países bálticos, Rusia, el Mediterráneo y a ciudades tan lejanas como Bagdad. Sus rutas atravesaban los ríos de Rusia hasta llegar a la capital del Imperio bizantino, Constantinopla (actualmente Estambul, Turquía), de donde partían hacia distintas direcciones. El emperador bizantino Teófilo comprobó la destreza que poseían para la guerra y los invitó a servirle como su guardia personal, la cual tomó el nombre de Guardia varega. También se cree que un grupo de vikingos suecos, llamados «rus», son los padres fundadores de Rusia. Las expediciones de estos fueron plasmadas en muchas piedras rúnicas existentes en el país, tales como las piedras rúnicas griegas y varegas. Hubo también una participación vikinga considerable en expediciones al oeste, las cuales fueron registradas en las piedras rúnicas inglesas. La última gran expedición vikinga fue el fallido viaje que dirigió Ingvar el Viajero a Serkland, la región del sureste del mar Caspio. Sus expedicionarios son conmemorados en las piedras rúnicas de Ingvar, ninguna de las cuales menciona a algún superviviente. Se desconoce lo que le sucedió a la expedición, pero se cree que fueron víctimas de alguna epidemia.

No se sabe cuándo ni cómo se creó el reino de Suecia, pero la lista de solo nombra a aquellos que reinaron en Svealand (Suecia) y Götaland (Gothia) al mismo tiempo, siendo el primero de ellos Erico el Victorioso. Previamente, Suecia y Gothia habían sido naciones separadas. Aunque no se sabe desde cuándo existían aquellos reinos, "Beowulf" los describe en las semilegendarias guerras entre suecos y gautas del siglo VI.

Durante los primeros años de la era vikinga en Escandinavia, Ystad en Escania y Paviken en Gotland fueron grandes centros del comercio de aquella época. Existen ruinas de lo que se piensa era un gran mercado en Ystad, que data de los años 600 a 700 d. C. En Paviken, un importante centro comercial de la región Báltica durante los siglos IX y X, se han encontrado restos de un gran muelle con talleres de construcción de barcos e industrias artesanales. Entre los años 800 y 1000, el comercio llevó a la abundancia de plata en Gotland, y de acuerdo a varios especialistas, los habitantes de la isla tenían mayor cantidad de este metal que todo el resto de la población de Escandinavia junta.

En el año 829, san Óscar introdujo el cristianismo, pero no fue hasta el siglo XII cuando la nueva religión comenzó a reemplazar las creencias tradicionales. Durante el siglo XI, el cristianismo se convirtió en la religión predominante, y para el año 1050 ya se contaba entre las naciones cristianas. El período que va de 1100 a 1400 se caracterizó por las luchas internas por el poder y la competencia entre los reinos nórdicos. Los reyes suecos también empezaron a expandir su territorio hacia Finlandia, creando conflictos con los rus, quienes se habían desprendido de toda conexión con Suecia.

En el siglo XIV, fue asolada por una epidemia de peste negra (peste bubónica). Durante este periodo las ciudades suecas también comenzaron a obtener mayor autonomía y fueron fuertemente influidas por los mercaderes alemanes de la Liga Hanseática, activos especialmente en Visby. En 1319, Suecia y Noruega fueron unidas por el rey Magnus Eriksson y en 1397 la reina Margarita I de Dinamarca efectuó una unión personal de Suecia, Noruega y Dinamarca, naciendo así la Unión de Kalmar. Sin embargo, los sucesores de Margarita, cuyo poder estaba centrado en Dinamarca, no lograron controlar a la nobleza sueca. Por largos periodos, el poder efectivo lo poseían regentes (notablemente aquellos de la familia Sture) elegidos por el parlamento sueco. Para remediar la situación, el rey Christian II de Dinamarca ordenó la ejecución de los nobles de Estocolmo. La matanza fue conocida como el «Baño de sangre de Estocolmo» e incitó a la nobleza sueca a formar una nueva resistencia, por lo que el 6 de junio de 1523, nombraron a Gustavo I de Suecia como su rey. Este hecho se considera a menudo como la fundación del Estado moderno de Suecia y el 6 de junio es ahora la Fiesta Nacional del país. Poco después, Gustavo I rechazó el catolicismo e introdujo la Reforma Protestante en el país. Por estos acontecimientos a Gustavo I se le conoce como el «Padre de la Nación».

Durante el siglo XVII emergió como una potencia europea. Antes del surgimiento del Imperio sueco, era un país muy pobre, escasamente poblado, y con poca participación en asuntos internacionales. Fue repentinamente convertido en una de las naciones líderes en Europa por Axel Oxenstierna y el rey Gustavo II Adolfo de Suecia, gracias a la conquista de territorios de Rusia y Polonia-Lituania, pero también gracias a su participación en la Guerra de los Treinta Años, la cual la convirtió en el líder continental del protestantismo hasta el colapso del imperio en 1721.

La guerra de Gustavo II Adolfo en contra del Sacro Imperio Romano-Germánico tuvo un alto costo para este último, donde un tercio de la población murió y casi la mitad de los Estados que lo componían fueron ocupados por los suecos. El plan de Gustavo II Adolfo era aventajarse del conflicto armado para expandir los límites de su reino. Sin embargo, Gustavo II Adolfo murió después en la batalla de Lützen de 1632, dejando el trono a la menor Cristina de Suecia. Después de la batalla de Nördlingen Suecia se retiró porque se cansó de las penurias de la guerra y perdió su poderío en la zona sur de la actual Alemania, y las provincias conquistadas se separaron del dominio sueco una a una, dejándola con solo un par de territorios en el norte: Pomerania Sueca, Bremen-Verden y Wismar.

A mediados del siglo XVII, era el tercer país más extenso en Europa, solo superado por Rusia y España. En 1658, alcanzó su máxima extensión bajo el reinado de Carlos X Gustavo de Suecia (1622-1660), poco después de la firma del Tratado de Roskilde. A mediados del siglo XVI, el rey Gustavo I convirtió al país al protestantismo y realizó una serie de reformas económicas. Durante el siglo XVII, el país se vio envuelto en varias guerras, como la que sostuvo contra Polonia-Lituania, en la que ambos compitieron por los territorios de los Países Bálticos hasta la batalla de Kircholm ocurrida en 1605, la cual es considerada una de las peores derrotas del ejército sueco.

Este periodo también fue testigo de «El Diluvio», la invasión sueca de la Unión de Polonia-Lituania. Después de más de medio siglo de una guerra casi constante, la economía sueca se deterioró seriamente. Reconstruir la economía y recuperar el poder militar se convirtió en una labor que se extendió durante toda la vida del sucesor de Carlos X, Carlos XI de Suecia (1655-1697). El legado para su hijo, Carlos XII, fue uno de los mejores arsenales en el mundo, un ejército numeroso y una gran flota.

En 1700, después de la batalla de Narva (una de las primeras batallas de la gran guerra del Norte), el Ejército Ruso, peor equipado y entrenado y desmoralizado por la retirada de Pedro I de Rusia antes de la batalla, fue severamente diezmado, dándole a Suecia la oportunidad de invadir Rusia. Sin embargo, Carlos XII no persiguió al Ejército ruso, sino que se dirigió a Polonia-Lituania y en 1702, derrotó al rey polaco Augusto II y a sus aliados sajones en la batalla de Kliszów. Después de la exitosa invasión a Polonia, Carlos XII tenía preparado el terreno para invadir Rusia atacando su capital, Moscú, desde Ucrania. Además de su ejército contaba con la ayuda de cerca de 2000 cosacos ucranianos. Pero en esta ocasión el ejército zarista estaba mejor preparado y motivado, y después de acosar a los invasores con los jinetes cosacos y rebajar sus suministros con técnicas de tierra quemada, en 1709 Pedro I derrotó decisivamente a los suecos en la batalla de Poltava. Los suecos fueron perseguidos, rindiéndose tres días después en Perevolochna. Esta derrota significó el comienzo del derrumbe del Imperio sueco.

En 1716, Carlos XII intentó invadir Noruega, sin embargo, su avance fue frenado por los noruegos en 1718, con el asedio de la fortaleza Fredriksten. Los suecos no fueron derrotados militarmente en Fredriksten, pero la organización y estructura de la campaña noruega llevaron a la muerte del rey y a la retirada del ejército. Forzada a ceder grandes extensiones de tierra en el Tratado de Nystad de 1721, también perdió su lugar como imperio y como el Estado dominante del mar Báltico. Con la pérdida de la influencia sueca, Rusia emergió como un imperio y se convirtió en una de las naciones dominantes en Europa. En el siglo XVII, ya carecía de los suficientes recursos para mantener sus territorios fuera de Escandinavia, debido a lo cual perdió la mayoría de éstos, culminando con la pérdida del este de Suecia por Rusia, territorios que se convertirían en el Ducado de Finlandia semiautónomo en la Rusia imperial.

Después de que Dinamarca-Noruega fuera derrotada en las guerras napoleónicas, el 14 de enero de 1814 Noruega fue cedida a Suecia a cambio de las provincias del norte de Alemania, en el Tratado de Kiel. Los intentos de Noruega por mantenerse como una nación soberana fueron repelidos por el rey Carlos XIII de Suecia. El rey lanzó una campaña militar contra Noruega el 27 de julio de 1814, terminando con la Convención de Moss, la cual forzó a Noruega a una unión personal bajo el poder sueco, que duró hasta 1905. La campaña de 1814 fue la última guerra en la que su ejército participó como beligerante.

En los siglos XVIII y XIX tuvo lugar un importante crecimiento demográfico, que el escritor Esaias Tegnér en 1833 atribuyó a «la paz, la vacuna (contra la viruela), y las patatas.» Entre 1750 y 1850 la población sueca se duplicó. De acuerdo a algunos especialistas, la emigración en masa hacia Estados Unidos se convirtió en la única forma de evitar el hambre y la rebelión; más del 1% de la población emigraba anualmente durante la década de 1880. Por entonces, seguía en la pobreza, con una economía básicamente agrícola, pese a que Dinamarca y otros países de Europa Occidental ya habían comenzado a industrializarse. Entre 1850 y 1910 más de un millón de suecos migraron hacia los Estados Unidos y a principios del siglo XX, había más población de origen sueco en Chicago que en Gotemburgo (la segunda ciudad más grande de Suecia). La mayoría de los inmigrantes suecos se establecieron en el Medio Oeste estadounidense, alcanzando una gran incidencia en la población de Minnesota. Como destinos secundarios, otros grupos de inmigrantes se dirigieron a Delaware y Canadá.

Si bien su proceso de industrialización se desarrolló lentamente, la agricultura experimentó cambios importantes debido a las innovaciones tecnológicas y al crecimiento de la población. Estas innovaciones incluían programas del gobierno de cercamiento, sobre-explotación de las tierras agrícolas y la introducción de nuevas semillas de cultivo como la de la patata. Debido al hecho de que los campesinos suecos habían sido explotados como en ningún otro lugar en Europa, la cultura granjera sueca adquirió un papel protagónico en los procesos políticos, característica que se ha mantenido en el tiempo, con el Partido Agrario (actualmente llamado Partido del Centro). Entre 1870 y 1914, comenzó el proceso de desarrollo de su economía industrial que perdura hasta hoy.

Durante la segunda mitad del siglo XIX, se produjeron movimientos sociales y sindicales importantes, así como de grupos abstinentes y religiosos independientes, que comenzaron a presionar por un Estado democrático. En 1889 se fundó el Partido Socialdemócrata Sueco. Estos movimientos llevaron al país hacia una moderna democracia parlamentaria, alcanzada en la época de la Primera Guerra Mundial. Como la Revolución Industrial avanzaba durante el siglo XX, la población rural comenzó a migrar hacia las ciudades para trabajar en las fábricas y así poder ser eventualmente incluidos en los sindicatos. En 1917 tuvo lugar una revolución socialista que fracasó, la cual fue seguida en 1921 por el establecimiento de una monarquía parlamentaria de tipo democrático.

Durante el transcurso de ambas guerras mundiales se mantuvo oficialmente neutral, aunque su neutralidad en la Segunda Guerra Mundial ha sido muchas veces ocasión de debate; estuvo bajo la influencia alemana la mayor parte de la guerra y quedó aislada del resto del mundo por medio de bloqueos. Inicialmente, el gobierno sueco consideró que no estaba en posición de oponerse a Alemania, y posteriormente colaboró con el régimen de Adolf Hitler. Los voluntarios suecos en las unidades nazis SS estuvieron entre los primeros elementos en invadir la Unión Soviética durante la Operación Barbarroja. Asimismo, también proporcionó acero y maquinaria a Alemania durante la guerra. Hacia el final del conflicto, cuando la derrota alemana parecía inminente, Suecia comenzó a jugar un rol importante en esfuerzos humanitarios y en el albergue de refugiados, entre ellos los numerosos judíos de la Europa ocupada por los nazis que fueron salvados. Esto se debió en parte a que participó en misiones de rescate en campos de concentración, y porque el país era el principal centro de refugiados de Escandinavia y de los países Bálticos. Sin embargo, críticas internas y externas aseguran que pudo haber hecho más para resistir las amenazas de los nazis, incluso corriendo el riesgo de una ocupación.

Durante la Guerra Fría adoptó públicamente una posición de neutralidad, pero de manera no oficial algunos líderes suecos mantuvieron conexiones estrechas con Estados Unidos. Después de la Segunda Guerra Mundial, se aventajó de su infraestructura industrial intacta, estabilidad social y de sus recursos naturales para expandir su industria y apoyar la reconstrucción de Europa. Asimismo, formó parte del Plan Marshall y participó en la Organización para la Cooperación y el Desarrollo Económico (OCDE). Durante la mayor parte de la posguerra, el país fue gobernado por el Partido Socialdemócrata Sueco (en sueco: Socialdemokraterna). Este partido estableció un modelo corporativista que favorecía a las grandes empresas capitalistas, pero también a los sindicatos, organizados en la Confederación de Sindicatos Suecos (LTC), afiliada al mismo partido. El Estado sueco adquirió un rol decisivo y la cantidad de empleados públicos aumentó notablemente entre 1960 y 1980. Finalmente, el país se abrió al comercio internacional y se orientó al sector manufacturero internacional, obteniendo buenas tasas de crecimiento hasta la década de 1970.

Como otros países del mundo, entró en un periodo de declive económico luego de los embargos de petróleo de 1973-1974 y 1978-1979. En la década de 1980, los pilares de la industria sueca fueron reestructurados en gran medida. Se canceló la construcción naval, se integró la tala de bosques al proceso de producción moderna de papel, se centralizó y especializó la industria del acero y la ingeniería mecánica se orientó hacia la robótica.

Entre 1970 y 1990 casi todos los impuestos fueron elevados más del 10%. El impuesto de límite de ingresos para los trabajadores alcanzó más del 80%, y el gasto público superó la mitad del PIB nacional, a la vez que su política económica era cuestionada por los economistas clásicos.

A principios de la década de 1990, como el resto de países occidentales, el país cayó en una crisis fiscal. La respuesta del gobierno conservador fue reducir los gastos e instituir una serie de reformas para impulsar la competitividad, entre las que se encontraban reducir el Estado de bienestar sueco y privatizar bienes y servicios públicos. Las reformas le permitieron entrar en la Unión Europea, a la cual Suecia pertenece desde el 1 de enero de 1995, aunque sin adoptar el euro, pues decidió mantener la corona sueca como su moneda nacional.

Actualmente es uno de los países con más alto Índice de Desarrollo Humano, encontrándose entre las veinte economías más grandes del mundo. También suele participar en operaciones militares internacionales, incluyendo la guerra de Afganistán, donde las tropas suecas están bajo el mando de la OTAN; y en la Unión Europea apoyando operaciones de las «fuerzas de paz» en lugares como Kosovo, Bosnia-Herzegovina y Chipre. Además, el armamento utilizado por el ejército estadounidense en Irak es producido por varias empresas suecas.

Suecia es una monarquía constitucional, en la cual el rey Carlos XVI Gustavo es el jefe de estado, pero su poder real está limitado solo a funciones ceremoniales y oficiales. Aunque The Economist Group asegura que la democracia es algo difícil de medir, el «Índice de democracia de 2006» la colocó en primer lugar de su lista de 167 países.

Su gobierno está dividido en tres poderes: legislativo, ejecutivo y judicial. El poder legislativo es el "Riksdag" (el parlamento sueco), que según la constitución sueca, es la autoridad suprema del gobierno. Está conformado por 349 miembros, los cuales eligen al primer ministro, quien dirige los ministerios. Las elecciones parlamentarias se llevan a cabo cada cuatro años, en el tercer domingo de septiembre.

Los proyectos de ley deben ser presentados por los miembros del gabinete o del parlamento. Los últimos son elegidos sobre la base de escrutinio proporcional plurinominal para un periodo de cuatro años. La constitución puede ser modificada por el Riksdag, para lo cual se requiere que la decisión sea aprobada por una mayoría absoluta entre periodos de elecciones generales. Además de los estatutos gubernamentales, tiene otras tres leyes constitucionales fundamentales: el Acta de Sucesión Real, el Acta de Libertad de Prensa y la Ley Fundamental para la Libertad de Expresión.

El poder ejecutivo es ejercido por el primer ministro, el gabinete y el rey. El poder judicial cuenta con un organismo de regulación llamado "Lagrådet" (Consejo de Leyes), que tiene la facultad de examinar la constitucionalidad de las leyes y las decisiones del gobierno, aunque sus resoluciones no son obligatorias; sin embargo, debido a las restricciones de esta forma de control constitucional y a una débil jurisdicción, su labor tiene pocas consecuencias en la política nacional.

El Partido Socialdemócrata Sueco ha jugado un papel de líder político desde 1917, después de que los reformistas confirmaran su dominio y los de la izquierda dejaran el partido. Después de 1932, los gabinetes han sido dominados por el partido Socialdemócrata. En tan solo cinco elecciones generales, otro partido de centro-derecha consiguió suficientes asientos en el parlamento para convertirse en la fuerza líder en el gobierno. Sin embargo, el avance económico lento desde comienzos de la década de 1970, y especialmente la crisis de 1990, la forzaron a reformar su sistema político para hacerlo similar al de otros países europeos. En las elecciones generales de 2010, el Bloque Roji-Verde (Socialdemócratas con el Partido Verde) ganó la mayoría de asientos en el Riksdag, dejando a la Alianza con solo 170 asientos.

Las elecciones en octubre de 2014 tuvieron los siguientes resultados:

El total de los partidos de gobierno (SAP+V+MP) son 159 escaños.
El total de los partidos de oposición (M+C+FP+KD) son 141 escaños.
Los parlamentarios fueron elegidos para el período 2014-2018.

En las elecciones al Parlamento Europeo, las partes que no hayan superado el umbral Riksdag han conseguido obtener representación en ese lugar: Lista de Junio (2004-2009), el Partido Pirata (2009-2014), y la Iniciativa Feminista (2014-corriente).

En Suecia el número de votantes siempre ha sido alto en comparación con muchos países, aunque ha ido en descenso en décadas recientes, y actualmente es de alrededor del 80% (80,11% en 2002 y 81,99% en 2006). Los políticos suecos disfrutaban de un alto grado de confianza de los ciudadanos en la década de 1960, pero con el paso de los años fue disminuyendo hasta alcanzar un nivel de confianza más bajo que en los demás países de la región. En cuanto a movimientos políticos, Suecia tiene una larga historia de los llamados "Folkrörelser" («movimientos populares»), siendo los más notables los sindicatos, el movimiento independiente cristiano, el movimiento de abstinencia, el movimiento feminista, etc.

El poder judicial está representado por el Tribunal Supremo de Suecia y los tribunales inferiores. La Corte Suprema es la tercera y última instancia en todos los casos civiles y criminales; está conformada por dieciséis Consejeros de Justicia o "justitieråd" los cuales son designados por el poder ejecutivo. Esta corte es una institución independiente del primer ministro y del parlamento, por lo que el gobierno no puede interferir en sus decisiones.

Los tribunales están divididos en dos sistemas paralelos y separados: Los tribunales generales (allmänna domstolar) para casos criminales y civiles, y tribunales administrativos generales (allmänna förvaltningsdomstolar) para los casos relacionados con disputas entre personas privadas y las autoridades. En ambos sistemas existen tribunales de distrito (los primeros en abrir un caso), tribunales de apelación (la segunda instancia), siendo el tribunal supremo la tercera y última instancia. Existen además algunos tribunales especiales para determinadas áreas (laboral, marcas y patentes).

La aplicación de la ley es llevada a cabo por varias instituciones gubernamentales: la Policía Nacional de Suecia (encargado de la organización de la policía), la Fuerza Operante Nacional (unidad SWAT de Suecia), el Departamento Nacional de Investigación Criminal y el Servicio de Seguridad Sueco (responsables de actividades anti-terroristas y de contraespionaje) son algunas ejemplos.

De acuerdo a un estudio de victimización hecho a 1201 suecos en 2005, Suecia tiene un alto índice de delincuencia comparado con otros países de la Unión Europea. Los delitos más frecuentes son los asaltos, crímenes sexuales, crímenes de odio y fraudes. Sin embargo, presenta bajos niveles de robos a viviendas y de automóviles, problemas de adicciones y corrupción.

A través del siglo XX, su política exterior estuvo basada en el principio de no alianzas en tiempos de paz y neutralidad en tiempos de guerra. Esta doctrina de neutralidad data desde el siglo XIX, ya que el país no ha participado en ningún conflicto armado desde el fin de la guerra contra Noruega de 1814. Durante la Segunda Guerra Mundial, no se unió a las Fuerzas del Eje ni a los Aliados. Sin embargo, esto ha sido debatido muchas veces, debido a que Suecia permitió al régimen nazi alemán el uso de su sistema de caminos para transportar bienes y soldados, y obtener materias primas, especialmente el hierro obtenido de las minas ubicadas en el norte de Suecia, que eran vitales para la maquinaria alemana.

Durante la Guerra Fría, el país combinó su política de no alianzas con un perfil bajo en conflictos internacionales, aunque sí mantuvo una política de seguridad basada en una fuerte defensa nacional para detener posibles ataques. Al mismo tiempo, el país mantenía conexiones informales relativamente estrechas con el bloque capitalista, especialmente en materia de intercambio de información. En 1952, un DC-3 sueco fue derribado sobre el mar Báltico por un MiG-15 soviético. Investigaciones posteriores revelaron que el avión estaba obteniendo información para la OTAN. Otra aeronave, una PBY Catalina de búsqueda y rescate, fue derribada días después del primer incidente, también por los soviéticos.

A comienzos de la década de 1960, intentó jugar un rol más importante e independiente en materia de relaciones internacionales. Esto le llevó a participar en actividades internacionales para mantener la paz, especialmente a través de la ONU, y en apoyo a los países del Tercer Mundo. El primer ministro Olof Palme cuestionó severamente la acción de Estados Unidos en la guerra de Vietnam y visitó durante la década de 1970, la Nicaragua sandinista y Cuba. En 1981, un submarino clase Whiskey soviético se adentró en aguas cercanas a la base naval sueca de Karlskrona en el sureste del país. Nunca se aclaró porqué el submarino terminó en aquel lugar, si por un error de navegación o si era una misión de espionaje contra el ejército sueco. El incidente llevó a una crisis diplomática entre la Unión Soviética y Suecia. Después del asesinato de Palme en 1986, el protagonismo internacional de Suecia se redujo considerablemente, aunque permaneciendo relativamente activo en misiones de paz y ayuda humanitaria.

En 1995, el país se convirtió en miembro de la Unión Europea, y como consecuencia de la situación de seguridad en el nuevo mundo, su política exterior y su doctrina de neutralidad han sido en parte modificadas, llegando a jugar un papel más activo en la cooperación para la seguridad de Europa. Es uno de los países de la UE que no ha ingresado en el euro por iniciativa propia. Asimismo, es desde 2014 el primer país de la UE en reconocer a Palestina como un Estado soberano más.

Las Fuerzas Armadas de Suecia (Försvarsmakten) son una agencia del gobierno dirigida por el ministro de Defensa y es el responsable de su operación durante los periodos de paz. La tarea principal de las Fuerzas Armadas es la de entrenar y desplegar fuerzas para el apoyo de la paz en el extranjero, así como la habilidad de reenfocarse en la defensa del territorio sueco en caso de guerra. Las fuerzas armadas están divididas en el Ejército, la Fuerza Aérea y la Armada. El comandante supremo de las Fuerzas Armadas Suecas ("Överbefälhavaren", ÖB) es el oficial de más alto rango en el país.

Hasta el fin de la Guerra Fría, casi todos los hombres que alcanzaban la edad para el servicio militar eran reclutados. Aunque hasta hace unos años el servicio militar en Suecia era obligatorio, se esperaba terminar con esa medida próximamente. Y efectivamente, a mediados de 2010, se abolió el servicio militar obligatorio, resultando en la creación de un ejército integrado totalmente por voluntarios. En años recientes, el número de hombres reclutados ha disminuido drásticamente, mientras el número de mujeres voluntarias se ha incrementado ligeramente. El reclutamiento se ha dirigido generalmente a encontrar los reclutas más motivados, en vez de los que solo entran para cumplir su servicio. Por ley, todos los soldados sirviendo en el extranjero deben ser voluntarios. En 1975 el total de reclutas era de 45 000. En 2009, había descendido a 25 000.

Las unidades suecas formaron parte de las fuerzas de paz en operaciones en Chipre, la República Democrática del Congo, Bosnia y Herzegovina, Kosovo, Liberia, Líbano, Afganistán y Chad. Actualmente, una de las tareas más importantes para las Fuerzas Armadas de Suecia es la de crear un grupo de combate de la Unión Europea que sea liderado por Suecia, en el cual Noruega, Finlandia, Irlanda y Estonia también contribuirán.

Suecia es un estado unitario, actualmente dividido en veintiuna provincias administrativas ("län"). Cada provincia cuenta con su junta de administración o "länsstyrelse", la cual es elegida por el gobierno nacional (la primera junta de administración fue creada por el primer ministro sueco Axel Oxenstierna en 1634). En cada provincia existe un consejo o "landsting", el cual es elegido directamente por el pueblo.

Cada provincia se divide en varios municipios o "kommuner", con un total de 290 municipios. Su gobierno municipal es similar a una alcaldía. Una asamblea legislativa municipal, llamada "kommunfullmäktige", de entre 31 y 101 miembros (siempre un número impar) es elegida por elecciones populares que se realizan cada cuatro años en conjunto con las elecciones parlamentarias. A su vez, los municipios se encuentran divididos en un total de 2512 parroquias o "socken". En el pasado, esta subdivisión coincidía territorialmente con la parroquia —"församling"— usada por la Iglesia de Suecia. Actualmente, las parroquias son utilizadas con fines estadísticos.

Existen también otras divisiones que ya no tienen uso oficial, pero que aún se toman en cuenta para ciertos trabajos. La principal de ellas son las veinticinco provincias históricas de Suecia o comarcas ("landskap") las cuales todavía poseen relevancia cultural. Estas provincias se agrupan en tres grandes regiones según las características geográficas e históricas que tengan en común: Norrland para el norte, Svealand para el centro y Götaland para el sur.

Situado en el norte de Europa, Suecia limita al este con el mar Báltico y el golfo de Botnia, dándole al país una larga línea costera, que forma la parte este de la península Escandinava. Al oeste se encuentran los Alpes escandinavos (Skaderna), los cuales forman una frontera natural con Noruega. Al noreste limita con Finlandia, al suroeste con los estrechos de Skagerrak, Kattegat y Öresund, que lo separan de Dinamarca, Alemania, Polonia, Rusia, Lituania, Letonia y Estonia. Además, está conectado con Dinamarca por el puente de Öresund.

Con una superficie de , Suecia es el del mundo. Es el quinto más grande del continente y el más grande de Europa del Norte. Su tamaño es un poco más grande que el estado de California y similar al de Uzbekistán, con una población de más de 10 millones de habitantes.

La altitud mínima de Suecia se encuentra en la bahía del lago Hammarsjön, cerca de Kristianstad con 2,41 metros bajo el nivel del mar. La altitud máxima del país está en el monte Kebnekaise con El territorio sueco también comprende unas 221 800 islas, de las cuales 1085 cuentan con una población permanente. Gotland, Öland, Orust, Hisingen y Värmdö son las islas más grandes del país.

En su mayoría, el territorio sueco es plano, con excepción de la zona oeste donde surgen los Alpes escandinavos. Esta planicie y el clima propio del país, da lugar a la formación de muchos lagos, entre los que destacan por su tamaño Vänern, Vättern, Mälaren y Hjälmaren. El lago Vänern es el lago más grande del país y el tercero más grande del continente europeo, después de los lagos Ladoga y Onega en Rusia.

Geográfica e históricamente, Suecia puede dividirse en tres grandes regiones: el norte Norrland, el centro Svealand y el sur Götaland. La escasamente poblada Norrland comprende más de la mitad de la superficie del país. Además, cerca del 15% del territorio se ubica dentro del Círculo Polar Ártico. El sur es predominantemente agrícola, mientras en el norte la actividad forestal es la industria más importante. Las regiones más densamente pobladas son Öresund en el sur y el valle del lago Mälaren cerca de Estocolmo.

La mayor parte de Suecia posee un clima templado, pese a su latitud, con cuatro estaciones diferentes y temperaturas templadas todo el año. Las tres regiones históricas del país reciben climas un poco diferentes: Gotland cuenta con un clima oceánico, Svealand con un clima húmedo continental y Norrland con un clima boreal. Sin embargo, el país es más cálido y seco que otros lugares de latitudes similares y de otras latitudes incluso más al sur, debido en gran parte a la corriente del golfo. Por ejemplo, el centro y sur del país tienen inviernos más cálidos que muchas partes de Rusia, Canadá y Estados Unidos. También debido a su localización, la duración del día varía enormemente. Al norte del Círculo Polar Ártico, el sol nunca se pone en algunos días de verano, y en algunos días de invierno nunca amanece. El día en Estocolmo dura más de dieciocho horas a finales de junio, pero solo alrededor de seis horas a finales de diciembre. Gran parte del territorio sueco recibe entre 1600 y 2000 horas de luz solar anualmente.

La temperatura varía del norte al sur. Las regiones de Svealand y Gotland tienen veranos templados e inviernos fríos, con temperaturas máximas entre 20 a 25 °C y mínimas de entre 6 y 15 °C durante el verano; y una temperatura promedio de –14 a 2 °C en el invierno. Por su parte, la Norrland tiene veranos más cortos y frescos, e inviernos más largos y fríos, con temperaturas usualmente bajo el punto de congelación desde octubre hasta junio. Ocasionalmente se presentan olas de calor con temperaturas por encima de los 25 °C que se presentan durante varios días en el verano, a veces hasta en la parte norte del país. Su temperatura más alta registrada fue de 38 °C en Målilla, en 1947, mientras la temperatura más baja ha sido de –52,6 °C en Vuoggatjålme en 1966.

En promedio, la mayor parte de Suecia recibe entre 500 y 800 mm de precipitación cada año, haciendo al país considerablemente más seco que el promedio mundial. El suroeste es la región del país con más precipitaciones, entre 1000 y 1200 mm, y en algunas zonas montañosas del norte se estima que se reciben más de 2000 mm de precipitaciones. Las nevadas ocurren de diciembre a marzo en Gotland, de noviembre a abril en Svealand y de octubre a mayo en Norrland. Pese a su situación geográfica, Gotland y Svealand tienden a estar virtualmente libres de nieve.

Al igual que el clima, la flora y fauna del país varían de acuerdo a la región. De sur a norte, se puede considerar que en Suecia existen cuatro ecorregiones: bosque mixto báltico, bosque mixto sarmático, pradera y bosque montano de abedules de Escandinavia y la taiga escandinava y rusa. Esto produce una variación entre la vida silvestre de las tres regiones: en Svealand son comunes las plantas coníferas, mientras que en Gotland las plantas caducifolias son las que predominan. En general, las especies vegetales más comunes en el país incluyen a la haya, el roble, el tilo, el fresno, el arce, el olmo y varias especies de orquídeas.

De la misma forma, la fauna que habita dentro del territorio nacional se distribuye según las condiciones geográficas y climatológicas de cada región. Los osos, las linces, los lobos, los venados, los alces, los zorros y varias especies de roedores pueden ser considerados los animales más comunes en Suecia. Las aves como el gallo lira, la chocha perdiz, la perdiz, los patos y los cisnes habitan gran parte del territorio sueco. Los lagos y costas del país son el hábitat de muchas especies de peces, entre las que sobresalen el bacalao, la macarela, el salmón, el lucio europeo y el arenque. La disponibilidad del pescado, así como el clima del país, resulta en una gastronomía local basada fuertemente en los alimentos marinos.

La economía de Suecia es una economía mixta orientada principalmente a la exportación y al comercio internacional. El Estado de Bienestar Sueco se ha asentado sobre una concepción de la responsabilidad del Estado en la provisión del bienestar, en las políticas de desarrollo del pleno empleo y la provisión de una red de servicios públicos universales. La visión comunitaria del Estado de acuerdo a las tradiciones políticas, y el concepto de solidaridad emergente de los principios socialdemócratas, han conformado esta concepción.
Este modelo ha tratado de disminuir el impacto del funcionamiento del mercado de trabajo sobre el bienestar de los individuos, configurando un nivel de bienestar independiente de la posición social de los mismos. Ninguno de los partidos mayores de Suecia propone disolver ese estado de bienestar, dado que tal propuesta seria profundamente impopular con la población. 

Considerada por el Banco Mundial y por el Fondo Monetario Internacional como una «economía avanzada», actualmente su PIB nominal alcanza los 444 585 millones de dólares. Por lo tanto, cuenta con un moderno sistema de distribución, suficientes comunicaciones externas e internas y una fuerza de trabajo especializada. La madera, la energía hidráulica y el hierro constituyen la base económica del país, junto con el sector de ingenierías que aporta el 50% de la producción y exportaciones. Las telecomunicaciones y la industria automotriz y farmacéutica son también de gran importancia. La agricultura cuenta con solo el 2% de la fuerza de trabajo.

A finales del año 2009, las diez compañías suecas más importantes eran: AB Volvo, Ericsson, Vattenfall, Skanska, Svenska Cellulosa Aktiebolaget, TeliaSonera, Electrolux, H&M (Hennes & Mauritz), ICA AB y Nordea. En 2008, el gobierno de centro-derecha del primer ministro Fredrik Reinfeldt privatizó más de cincuenta empresas públicas, dejando al Estado sueco en déficit.
La población económicamente activa (PEA) es de 5,3 millones de personas (2017), de los cuales un 35,2% (2011) cuenta con estudios de educación superior. La economía del país crece a un ritmo del 2% anual.

En 2003, Suecia rechazó el euro como moneda a través de un referéndum, por lo que actualmente la moneda oficial del país es la corona sueca (SEK). El banco central de Suecia es Sveriges Riksbank, que fue fundado en 1668, lo que lo hace el banco central más antiguo del mundo. Además de ser la casa emisora de moneda, Sveriges Riksbank se ocupa de la estabilidad de los precios, manteniendo la inflación en un 2% anual, una de las más bajas entre los países europeos desde mediados de la década de 1990. Los países con los que efectúa la mayor parte de la actividad financiera son Alemania, Estados Unidos, Noruega, Reino Unido, Dinamarca, y Finlandia.

El Foro Económico Mundial de 2010 lo consideró como el segundo país más competitivo del mundo, solo por debajo de Suiza. Finalmente, ocupó el noveno lugar en el Anuario IMD de Competitividad 2008.

Gran parte del sector energético es propiedad privada y se encuentra apoyado principalmente en la energía hidráulica, que en 2000 aportó 76 TWh (53,8% de la producción total), y la energía nuclear, que produjo 53 TWh (37,4%). Al mismo tiempo, el uso de biocombustibles, turba, energía eólica y otras fuentes de energía renovable aportaron solo 4 TWh (2,7%). En 2016 se produjeron en Suecia 152,9TWh de energía eléctrica. La biomasa es principalmente usada para producir el calor utilizado en sistemas de calefacción y en procesos industriales. Nord Pool, creada en 1991, es la empresa encargada de comercializar la energía entre los países nórdicos.

La crisis del petróleo de 1973 reforzó la decisión del gobierno de disminuir su dependencia de combustibles fósiles importados. Desde entonces, la electricidad es obtenida en su mayor parte de centrales hidroeléctricas, de fuentes renovables y de energía nuclear, este último con un uso limitado. Entre otras cosas, el accidente nuclear de la central central nuclear de Three Mile Island en Estados Unidos, llevó al parlamento a prohibir la construcción de nuevas centrales nucleares. Sin embargo, después de múltiples estudios que mostraban al proyecto como «inviable», además del cambio de administración en el gobierno y un intenso debate, el parlamento aprobó la anulación de esta política en junio de 2010.

En 2006, debido a un grave accidente que estuvo a punto de causar una pérdida masiva de radiación en la central nuclear de Forsmark, el gobierno clausuró cuatro de las diez plantas de energía nuclear que se encontraban operando. En 2009, el gobierno socialdemócrata sueco «decidió imprimir un giro total a su política energética, abriendo el camino para la construcción de nuevas centrales nucleares».

Diversos líderes políticos han anunciado planes para liberar a Suecia del uso de combustibles fósiles, la disminución del uso de la energía nuclear y la inversión de varios millones de dólares para investigaciones en energía renovable y eficiencia energética. El país ha seguido por muchos años la estrategia de fijar impuestos como instrumento de política ambiental, incluyendo los impuestos energéticos y el impuesto al dióxido de carbono.

Suecia cuenta con de caminos pavimentados y 2050 km de autopistas (2016). Las autopistas corren a través de Suecia, Dinamarca y sobre el puente de Öresund hacia Estocolmo, Gotemburgo, Upsala y Uddevalla. El país lleva adelante un plan de construcción de autopistas; como parte del mismo, el 17 de octubre de 2007 fue concluida la carretera de Upsala a Gävle. Desde 1736 hasta mediados del siglo XX, el sentido de circulación era hacia la derecha ("Vänstertrafik"), hasta que los votantes rechazaron ese sentido en 1955, para imponer la dirección inversa a partir de 1963. Sin embargo, el parlamento regresó al sentido hacia la derecha en 1967, en el día llamado "Dagen H".

El ferrocarril ha sido privatizado en parte, pero existen varias compañías operadas por los condados y municipios. Entre los principales operadores se encuentran: SJ AB, Veolia Transportation, Connex, Green Cargo, Tågkompaniet, Inlandsbanan y múltiples compañías regionales. Los ferrocarriles que aún no han sido privatizados son propiedad de Banverket. En 2016 existían cerca de 14 062 km de vías férreas, de las cuales 12 322 km están electrificadas, contando además con 65 km de vía estrecha (0,891 m).

En el país existen 231 aeropuertos, 149 de ellos con pistas pavimentadas, y operan 8 compañías aéreas registradas con un tráfico de anual de 11,6 millones de pasajeros (2015). Los aeropuertos más grandes e importantes incluyen al Aeropuerto de Estocolmo-Arlanda (17,91 millones de pasajeros en el 2007) a 40 km al norte de la capital del país, el Aeropuerto de Gotemburgo-Landvetter (4,3 millones de pasajeros en 2006) y el Aeropuerto de Estocolmo-Skavsta (2 millones de pasajeros en 2006). En Suecia se encuentran las dos autoridades portuarias más importantes en Escandinavia: la del puerto de Gotemburgo y la transnacional de Copenhague-Malmö.

Suecia liberalizó su industria de telecomunicaciones en un proceso que incluyó la regularización de los medios de comunicación y que duró más de diez años, culminando en 1993. En el país existen más de 2,7 millones de líneas telefónicas en uso, además de 12,4 millones de líneas móviles (2017). A su vez, más del 90% de la población tiene acceso a Internet. Las compañías radiodifusoras públicas tuvieron el monopolio de la radio y televisión por mucho tiempo en el país, desde que la primera estación de radio comenzó sus transmisiones en 1925. Más tarde, en 1954 una segunda cadena inició transmisiones y una tercera estación abrió en 1962, en respuesta a las estaciones de radio piratas. En 1979, las estaciones de radio de beneficencia fueron permitidas y en 1993 comenzaron las estaciones de radio locales.

Oficialmente, fue en 1956 cuando la primera estación de televisión comenzó las retransmisiones. Un segundo canal, TV2, fue creado en 1969. Estos dos canales (operados por Sveriges Television desde finales de la década de 1970) tuvieron un monopolio hasta la década de 1980, cuando la televisión por cable y satélite estuvieron disponibles en el país. El primer servicio satelital en sueco fue TV3, que era transmitido desde Londres en 1987. Fue seguido por Kanal 5 en 1989 (entonces conocido como «Canal Nórdico») y TV4 en 1990.

En 1991 el gobierno anunció que comenzaría a recibir solicitudes de aquellas empresas que desearan transmitir su señal por cable. TV4, que anteriormente había transmitido vía satélite, comenzó a transmitir por cable en 1992, convirtiéndose en el primer canal de iniciativa privada en transmitir desde el interior del país. Hoy en día, cerca de la mitad de la población utiliza la televisión por cable. La televisión digital terrestre comenzó en 1999 y las transmisiones de televisión analógicas terminaron en 2007.

Suecia está entre los consumidores de periódicos más grandes del mundo, y la mayoría de las localidades y ciudades cuentan con un periódico local. Los principales periódicos de circulación nacional son: "Dagens Nyheter" (de inclinación liberal), "Göteborgs-Posten" (liberal), "Svenska Dagbladet" (conservador) y "Sydsvenska Dagbladet" (liberal). Los dos tabloides más populares son el "Aftonbladet" (socialdemócrata) y "Expressen" (liberal). El periódico gratuito "Metro International", de circulación mundial, fue originalmente fundado en Estocolmo; mientras "The Local" (liberal), otro periódico de circulación mundial, también tiene su sede en Suecia.

A fines de diciembre de 2010, su población total fue estimada en habitantes. De acuerdo a estimaciones de su Instituto de Estadísticas (SCB por sus siglas en sueco), cerca del 12 de agosto de 2004 la población sueca excedió los nueve millones por primera vez. En 2007, aproximadamente el 16,7% de los habitantes (1,53 millones) tenía al menos un pariente nacido en el extranjero, principalmente de Escandinavia. Esto refleja los grandes procesos migratorios entre los países nórdicos, originados primeramente por la búsqueda de empleo y posteriormente le siguieron décadas de inmigración de refugiados de países en conflictos. El país se transformó de una nación de emigrantes al concluir la Primera Guerra Mundial, en un país de inmigrantes después de la Segunda Guerra Mundial. En el 2006, la inmigración a Suecia alcanzó su más alto nivel desde que comenzaron los registros: 95 750 personas llegaron al país en ese año.

Los grupos de inmigrantes más numerosos en Suecia consisten en gente proveniente de Finlandia, seguidos de personas nacidas en Irak, la antigua Yugoslavia, Somalia, Alemania, Dinamarca, Noruega, Turquía, Polonia, Rumania, Rusia, Siria, Líbano, Chile e Irán. Además, Suecia es el hogar de la comunidad más grande de exiliados de asirios y cristianos sirios.

La inmigración proveniente de otros países nórdicos alcanzó su nivel más alto entre los años de 1968 y 1970 con 40 000 personas por año. Esto sucedió debido a las nuevas leyes de inmigración promulgadas en 1967, las cuales hicieron más difícil a los inmigrantes que no provenían de Escandinavia el establecerse en el país, principalmente por razones políticas. La inmigración de refugiados provenientes de las afueras de la región nórdica se incrementó notablemente a finales de la década de 1980, con la llegada de varios grupos de refugiados provenientes de Asia y América, especialmente de Irán y Chile (luego del golpe de Estado de 1973 fueron exiliados muchos simpatizantes y militantes de partidos políticos de izquierda y centroizquierda, perseguidos por la dictadura de Augusto Pinochet). Durante la década de 1990 y en adelante, otro grupo grande de refugiados llegó desde la antigua Yugoslavia y el Medio Oriente. Esta llegada de inmigrantes ha causado algunos problemas de convivencia, tal es el caso de la ciudad de Malmö, donde los inmigrantes y sus descendientes conforman el 40% de la población. De 2007 a 2010 la cifra promedio anual de inmigrantes alcanzó, considerando todas las categorías, las cien mil personas. El número de emigrantes, por su parte, rondó en torno a las 45 000 personas.

El idioma más hablado en el país es el sueco, una lengua germánica relacionada y muy similar al danés y al noruego, pero con diferencias en pronunciación y ortografía. El sueco es comprensible para noruegos y daneses, teniendo los segundos un poco más de dificultad que los primeros. Aunque el sueco es el idioma predominante, la ley sueca no lo considera como el idioma oficial. Los finlandeses que habitan al este son la minoría lingüística más significativa del país. Componen más del 3% de la población y el finés es reconocido como un idioma minoritario. Además, cuenta con otros cuatro idiomas reconocidos como minoritarios: el meänkieli, el sami, el romaní y el yidis. En 2005, se presentó ante el parlamento una propuesta para que el sueco fuera declarado el idioma oficial del país, pero finalmente fue rechazada.

La gran mayoría de sus habitantes nacidos después de la Segunda Guerra Mundial entienden y hablan el inglés gracias a los vínculos comerciales, la popularidad de los viajes al extranjero y una fuerte influencia anglo-estadounidense. A partir de 1849, el inglés se convirtió en una materia obligatoria en la escuela secundaria para aquellos que estudiaban ciencias naturales, y se convirtió en obligatoria para todos los alumnos a finales de la década de 1940. Dependiendo de las autoridades escolares locales, el inglés es una materia obligatoria entre primer y noveno grado, con al menos un año extra de estudio en la secundaria. Muchos estudiantes aprenden uno o dos idiomas aparte del inglés, entre los cuales destacan el alemán, el francés y el español.

Antes del siglo XI, predominaba la religión nórdica en la que se rendía culto a los dioses Æsir, o Ásatrú con su centro en el Templo de Upsala. Con la cristianización, las leyes del país fueron cambiadas, prohibiendo adorar a otras deidades hasta los últimos años del siglo XIX. En 1530 después de la Reforma Protestante, Olaus Petri, seguidor de las ideas de Martín Lutero, llevó a cabo la separación entre la Iglesia y el Estado sueco, al mismo tiempo que abolió la autoridad de los obispos católico. De esta manera el luteranismo se adoptó como religión en gran parte del país, proceso que llegó a su fin con el Concilio de Upsala en 1593.

Durante la era siguiente a la Reforma pequeños grupos de calvinistas de los Países Bajos, la Hermandad de Moravia y hugonotes de Bélgica jugaron un papel importante en la industria y el comercio, y fueron en parte tolerados siempre y cuando mantuvieran un bajo perfil religioso. Los lapones originalmente tenían su propia religión shamánica, pero fueron convertidos al luteranismo por los misioneros suecos en los siglos XVII y XVIII.

Con la liberalización religiosa ocurrida a finales del siglo XVIII, los seguidores de otras religiones, incluyendo el judaísmo y el catolicismo, pudieron vivir y trabajar abiertamente en el país, pero para los luteranos suecos el cambiarse de religión fue ilegal hasta 1860. En el siglo XIX llegaron a sus tierras varias Iglesias evangélicas y, hacia el final del siglo, el secularismo, lo cual condujo a muchas personas a renunciar de la religión. Abandonar la Iglesia de Suecia se tornó legal en la llamada «Ley de Deserción de 1860», pero solo con la condición de pasar a pertenecer a otra religión. El derecho a permanecer fuera de cualquier congregación religiosa fue establecido en la ley de libertad de culto de 1951.

Cerca del 56,4% de la población integra la Iglesia de Suecia (luterana), y menos del 20% de ellos asisten regularmente a los servicios religiosos de la Iglesia de Suecia. Sin embargo, la razón del número elevado de miembros se debe en parte a que hasta 1996, todos los niños que nacían se convertían automáticamente en miembros si alguno de sus padres lo era. Desde 1996, solo los niños que son bautizados se convierten en miembros. Alrededor de 275 000 suecos pertenecen a otras iglesias protestantes (donde la asistencia a los servicios es mucho más alta) y debido a la inmigración existen alrededor de 500 000 musulmanes (5,2%), 100 000 cristianos ortodoxos y 92 000 católicos viviendo en Suecia. A pesar de las cifras, muchos estudios aseguran que Suecia es uno de los países con menos adeptos religiosos del mundo y con un alto grado de ateísmo: entre 46 y 85% de los suecos no creen en un Dios.

Siendo un país desarrollado, en Suecia la atención sanitaria es universal y gratuita, es financiada casi en su mayoría con impuestos. A menudo, la nación se encuentra entre los cinco países con la tasa más baja de mortalidad infantil; también se encuentra entre los países con mayor esperanza de vida (82,2 años) y en pureza del agua potable. En Suecia existen 4,2 médicos por cada 1000 habitantes, además de que el gobierno invierte el 11,9% del PIB total en gastos de salud.

Esto se debe a la alta calidad del sistema de salud, que es similar al de otros países europeos y a menudo es clasificado como uno de los mejores en el mundo. Los servicios de salud son coordinados por la Junta Nacional de Salud y Bienestar Social ("Socialstyrelsen").

El sistema de salud actual fue fundado en 1968, gracias a la unión de la Junta Real de Salud y la Junta Real de Asuntos Sociales por el gobierno socialdemócrata, asegurando un amplia cobertura de la seguridad social, a través de la provisión de atención sanitaria gratuita, un sistema de pensiones de jubilación y subsidios por enfermedad, guarderías gratuitas de preescolar y subsidios económicos por maternidad o paternidad.

La prostitución es legal en todo el país. Ante la problemática en relación con la salud sexual a nivel social, Suecia tomó en sus manos la opción de legalizar la prostitución en 1999. Suecia se destaca por dar uno de los mayores permisos por maternidad o paternidad: La ley exige que cada uno de los padres tome 60 días de permiso laboral para el cuidado de sus recién nacidos.

Gracias a su sistema educativo bien desarrollado, en el que el gobierno invierte un 7,7% del PIB (2014), el país tiene uno de los índices de alfabetización más altos en el mundo, con un 99%. Los niños entre uno y seis años tienen garantizado un lugar en un colegio preescolar público (en sueco: "förskola" o, coloquialmente, "dagis"). Entre los siete y quince años de edad los alumnos ingresan a la escuela primaria y secundaria, las cuales son obligatorias. Los estudiantes suecos de quince años ocupan el 22.º lugar en el Informe PISA, al igual que dentro de los países miembros de la OCDE.

Después de completar el noveno grado, cerca del 90% de los graduados continúan sus estudios por tres años de educación media superior ("gymnasium"); al terminar esta, los alumnos están calificados para conseguir un empleo o para realizar una solicitud de ingreso a la universidad. El país posee gran variedad de y colegios, siendo el Instituto Karolinska, la Universidad de Upsala, la Universidad de Lund y la Universidad de Estocolmo citadas como las instituciones educativas más prestigiosas.

El sistema escolar es en gran parte financiado con los impuestos. Cualquier ciudadano puede establecer una escuela sin ánimo de lucro y el gobierno municipal debe abonarles el mismo monto que obtienen las escuelas municipales, sin realizar discriminaciones en la distribución de los cheques escolares. Este sistema data de 1992 y fue tomado de la política escolar de los Países Bajos. Como en otros países europeos, el gobierno también subsidia el intercambio de alumnos de origen extranjero que buscan un título en las instituciones suecas.

La cultura sueca es percibida típicamente como igualitaria, sencilla y abierta a influencias de otros países. El país ha recibido la influencia cultural de otros países e instituciones: la Iglesia católica y Alemania durante la Edad Media, Francia durante el siglo XVIII, de nuevo Alemania en el siglo XIX y los países de la Angloesfera después de la Segunda Guerra Mundial. De igual manera, su cultura y el desarrollo de la misma se encuentran en una íntima relación con la de los demás países nórdicos.

En todo el país existen cerca de 330 bibliotecas y más de 200 museos, la mayoría de ellos ubicados cerca de las grandes ciudades como Estocolmo, además de múltiples lugares turísticos de interés artístico, cultural e histórico. El patrimonio cultural sueco es reconocido a nivel mundial: catorce lugares dentro del territorio nacional han sido declarados «Patrimonio de la Humanidad» por la Unesco. Otro aspecto cultural destacado a nivel internacional es la entrega del Premio Nobel, instituido por Alfred Nobel. Este galardón se ha otorgado cada año desde 1901 a personas que han hecho investigaciones sobresalientes, inventado técnicas o equipamiento revolucionario o contribuciones notables a la sociedad.

En las décadas de 1960 y 1970, Suecia fue uno de los primeros lugares donde surgió un movimiento que ahora se conoce como la «revolución sexual», especialmente promoviendo la igualdad de género. Actualmente, el porcentaje de personas solteras es uno de los más altos del mundo. La película sueca "" (1967) reflejó un punto de vista liberal sobre la sexualidad e introdujo el concepto del «pecado sueco». En décadas recientes, se ha convertido en uno de los países más tolerantes del mundo hacia la homosexualidad y desde 2009 está permitido el matrimonio entre personas del mismo sexo.

El arte de Suecia se encuentra fuertemente vinculado con el arte de las demás naciones de Escandinavia, debido principalmente a las condiciones geográficas e históricas en las que se fue desarrollando. Desde las primeras pinturas rupestres y monumentos megalíticos, pasando por el arte medieval y gótico, el arte sueco no surgió en sí hasta la formación de la identidad nacional sueca, entre los siglos XVI y XVII. Así, Estocolmo se convirtió en el centro artístico de la nueva nación, donde se desarrollaron las tendencias originadas en otras partes de Europa: el renacimiento, el barroco, el rococó, entre otros.

Sin embargo, fue hasta el siglo XIX cuando los artistas suecos comenzaron a atraer a los críticos mundiales. Dentro de este escenario se destaca la participación de Anders Zorn, Carl Larsson, Eugène Jansson, Richard Bergh y August Strindberg, quienes dieron grandes aportaciones a la pintura, la escultura y la fotografía. Durante el siglo XX, las tendencias expresionistas y modernistas entraron a la escena artística de Suecia. Las nuevas tendencias artísticas desarrolladas en el país han captado la atención internacional, principalmente en el campo del diseño, la moda, la música pop y la gastronomía.

En 1930, la pintura, el diseño gráfico y la arquitectura moderna entraron al país con la corriente del funcionalismo y desde entonces las obras de pintores, diseñadores y arquitectos suecos han ganado una buena reputación. Sin embargo, su arte tradicional aún se conserva, siendo su mejor ejemplo las artesanías fabricadas en las zonas rurales y comercializadas en las ciudades e incluso exportadas a otras partes del continente. Algunas de las más populares incluyen las estufas de cerámica, obras hechas de vidrio y las tallas de madera.

En las últimas décadas, el cine sueco adquirió importancia internacional gracias a las obras de directores como Ingmar Bergman, Vilgot Sjöman, Bo Widerberg, Roy Andersson y Lasse Hallström. La industria del cine es regulada por el Instituto Sueco del Cine, apoyado en gran parte por programas del gobierno, quien destina cerca de 200 millones de dólares anuales a la producción y promoción de películas nacionales. Además, cada año se celebran varios festivales internacionales de cine en todo el país; los Premios Guldbagge son otorgados cada año a los mejores largometrajes y a menudo son considerados como los «Óscar Suecos».

Suecia cuenta con una rica tradición musical, desde las baladas folclóricas medievales hasta el "hip hop". La música nórdica precristiana se perdió con el paso del tiempo, aunque se han elaborado recreaciones históricas basadas en instrumentos encontrados en sitios arqueológicos vikingos. Entre los instrumentos utilizados se encuentran el "lur" (una especie de trompeta), instrumentos de cuerda sencillos, flautas de madera y tambores. Es posible que algunos rasgos de la música vikinga permanezcan hasta el día de hoy en las canciones tradicionales suecas.

La música tradicional es un escenario musical importante que a menudo incorpora elementos de otros géneros contemporáneos como el "rock" y el "jazz". También se encuentra presente la música lapona, llamada "yoik", la cual forma parte de la espiritualidad tradicional del pueblo lapón y ha ganado reconocimiento mundial dentro del campo de la música folclórica. Además, el país también tiene una prominente tradición en música coral, derivada en parte de la importancia cultural de la música folclórica. De hecho, de los 9,4 millones de habitantes, se estima que entre 500 y 600 mil personas forman parte de un coro.

El "jazz" es otro de los géneros importantes dentro de la música sueca. Desde los años 1950 ha mantenido un estándar artístico elevado, en gran parte debido a las bandas locales que reciben influencia de otros países como Bélgica, Francia, Reino Unido y los Estados Unidos. A menudo se cita a Lars Gullin como uno de los máximos representantes del "jazz" sueco.

Dentro de la industria musical actual, Suecia es el tercer exportador de música más grande en el mundo, con más de 800 millones de dólares de ingresos en 2007, sobrepasado solo por Estados Unidos y el Reino Unido. Actualmente, el pop sueco es uno de los estilos más conocidos del país. El grupo ABBA fue uno de los primeros grupos musicales suecos en hacerse famosos alrededor del mundo, además de que gracias a su fama el pop sueco adquirió cierto estatus de importancia internacional. A su vez, otras bandas como Roxette, Ace of Base, Europe y The Cardigans consolidaron la imagen de la música moderna sueca. Otro género similar proveniente de Alemania, el "schlager", cobró popularidad desde la década de 1950 y su influencia ha permanecido en la música actual a través de diversos festivales de música como los "folkpark", el Melodifestivalen y el Festival de Eurovisión.

El indie pop también tiene muchos representantes en Suecia. En Gotemburgo se han creado una serie de importantes sellos discográficos como Sincerely Yours o Service. Algunos artistas y grupos indies son Jens Lekman, The Knife, Love Is All, Kent (probablemente la banda de pop rock más popular en Suecia en los últimos años), The Concretes, Broder Daniel, The Tough Alliance, Peter Olof Swartz, Bjorn and John, Little Dragon, El Perro del Mar, Maia Hirasawa, Fever Ray, Popsicle, Studio, The Embassy, The Honeydrips, Brainpool, Air France, jj, Joel Alme o Pacific!.

Por otro lado, géneros como el "heavy metal", comenzaron a crecer dentro de la escena musical sueca, abarcando un amplio abanico de subgéneros con exponentes reconocidos mundialmente. Junto con Noruega, el país ha sido el centro de desarrollo de muchos de estos estilos y artistas. En la década de 1980 resulta notable la influencia de bandas como Bathory o en el "black metal" y de Candlemass en el Doom Metal. En los años 1990 destaca especialmente la ola de grupos de death metal melódico de Gotemburgo de los grupos At The Gates, Dark Tranquillity e In Flames, que generó toda una corriente de fanes y seguidores entre los que destacan bandas como Amon Amarth, Arch Enemy o Soilwork. También hubo una ola de bandas de death metal progresivo como Edge of Sanity, Meshuggah, Therion y Opeth. El renombrado guitarrista de metal neoclásico y "power metal", Yngwie Malmsteen, también es de origen sueco. En este ámbito otra banda muy relevante mundialmente son Hammerfall y además con músicos compartidos como Anders Johansson. Otros grupos importantes dentro de la escena sueca son Hammerfall, Entombed, Evergrey, Katatonia, Marduk, Dissection, The Haunted, Dark Funeral, Vintersorg. Otra banda que también ha alcanzado un éxito y reconocimiento a nivel mundial, es la banda de "garage rock" y "rock n' roll", The Hives.

En cuanto a la música electrónica y "dance" en la segunda década de siglo XXI destacan nombres como Lykke Li, Swedish House Mafia, Galantis, Avicii, Eric Saade, Carola, la greco-sueca Helena Paparizou, Yohio, Loreen, Danny Saucedo, Icona Pop, Tove lo, Alesso, Zara Larsson, AronChupa, Måns Zelmerlöw, Benjamin Ingrosso y Ghost.

El primer texto literario hallado en Suecia es la Piedra de Rök, tallada durante la Era Vikinga cerca del año Con la conversión del país al cristianismo en el , Suecia entró en la Edad Media, durante la cual los monjes prefirieron usar el latín en sus escritos, por lo que los textos en el sueco de esa época son escasos. La literatura sueca floreció solo después de que el idioma sueco fuera estandarizado en el siglo XVI, siendo la Biblia uno de los primeros libros traducidos al sueco en 1541. A menudo esta traducción es llamada la "Biblia de Gustavo Vasa".

Con la implantación del sistema educativo y la libertad que dio la secularización, el siglo XVII vio el desarrollo de múltiples escritores suecos. Ejemplo de esto son Georg Stiernhielm (siglo XVII), quien fue el primero en escribir poesía clásica en sueco; Johan Henric Kellgren (siglo XVIII), el primero en escribir una prosa fluida en sueco; Carl Michael Bellman (finales del siglo XVIII), el primer escritor de baladas de burlesque; y August Strindberg (finales del siglo XIX), un escritor socio-realista y dramaturgo que alcanzó la fama mundial. El siglo XX continuó dando notables autores como Selma Lagerlöf (Premio Nobel de Literatura 1909), Verner von Heidenstam (Premio Nobel de Literatura 1916) y Pär Lagerkvist (Premio Nobel de Literatura 1951). En total se han entregado siete Premios Nobel de Literatura a escritores suecos.

En décadas recientes, varios escritores han sido reconocidos internacionalmente, incluyendo los autores de novelas policíacas Henning Mankell, Stieg Larsson, Camilla Läckberg y Åsa Larsson así como Jan Guillou, escritor de novelas de espías. Pero la autora sueca más reconocida en las últimas décadas es la escritora de cuentos para niños Astrid Lindgren, cuyas obras principales, como "Pippi Långstrump" y "Emil of Maple Hills", aún se encuentran entre los libros infantiles más populares.
Y en el género de terror está John Ajvide Lindqvist con su novela "Déjame entrar" publicada en 2008 y ya con una adaptación sueca y un adaptación estadounidense para la pantalla grande.

Siendo un país desarrollado muy avanzado, las investigaciones científicas juegan un papel clave para el desarrollo económico y para la sociedad en general, y la alta calidad en el desarrollo científico y tecnológico es reconocida alrededor del mundo. Juntos, el sector público y privado destinan cerca del 4% del PIB a la investigación y desarrollo (I+D), lo cual le convierte en uno de los países que más invierte en I+D en términos de porcentaje del PIB. El estándar de las investigaciones suecas es alto y el país es líder mundial en múltiples campos científicos. Por ejemplo, es el primero en Europa en cuanto al número de trabajos científicos publicados per cápita.

En 1739 se fundó la Real Academia de las Ciencias de Suecia, con personajes como Carlos Linneo y Anders Celsius entre sus primeros miembros. Desde 1870, las compañías ingenieras fueron creadas a un ritmo nunca antes visto y los ingenieros se convirtieron en los héroes de la época. Muchas de las compañías fundadas por estos pioneros son aún reconocidas a nivel internacional. Entre los principales innovadores suecos de la época destacan: Alfred Nobel quien inventó la dinamita e instituyó el Premio Nobel; Gustaf Dalén fundó la compañía de gas AGA y ganó el Premio Nobel de Física por sus válvulas solares; Lars Magnus Ericsson comenzó la empresa que lleva su nombre, Ericsson, que hoy en día es una de las compañías de telecomunicaciones más grandes del mundo; Jonas Wenström fue un pionero en la corriente alterna y junto con el inventor croata Nikola Tesla, inventó el sistema electrónico de tres fases.

En comparación internacional, la alta tecnología industrial es relativamente más importante en todos los sectores, particularmente en las telecomunicaciones y en la industria farmacéutica. Aunque es un país relativamente pequeño, Suecia ha estado desde hace mucho tiempo en la vanguardia de I+D. Por varias décadas, el gobierno ha puesto como prioritarias algunas actividades científicas de investigación. Este fuerte apoyo ha ayudado a Suecia a convertirse en un país líder en términos de innovación. Durante muchos años, fue un país líder entre los miembros de la OCDE en lo que se refiere a investigaciones y el uso de tecnología avanzada.

Estadísticas demuestran que entre los años de 1970 a 2003, el sistema nacional de innovación sueco estaba entre los mejores de los países miembros de la OCDE en cuanto a la generación de invenciones tecnológicas y el número de patentes registradas de acuerdo al tamaño de la población. Solo Suiza reportó un mayor índice de patentes en relación a su población. En total, a finales de 2009 contaba con 33 523 patentes registradas, de acuerdo con la Oficina de Patentes y Marcas Registradas de los Estados Unidos, con solo diez países superando su número de patentes. Más aún, en el 2001 se encontraba entre los países con el mayor número de publicaciones científicas en los campos de ciencia médica, ciencias naturales e ingeniería.

En términos de estructura, la economía sueca se caracteriza por sus grandes exportaciones orientadas hacia el sector tecnológico e industrial (motores, vehículos y equipos de telecomunicacines), así como los comparativamente pequeños sectores de servicios y finanzas. Así la ciencia y tecnología se han vuelto una parte importante para la economía del país, principalmente para las grandes organizaciones industriales y de servicios que la dominan, ya que gran parte de las industrias suecas multinacionales tuvieron sus orígenes en el ingenio de múltiples inventores suecos.

La gastronomía sueca siempre ha estado bajo la influencia del clima y los recursos disponibles en las diferentes regiones del país. Como la de otros países escandinavos (Dinamarca, Finlandia y Noruega), es tradicionalmente sencilla. El pescado (particularmente el clupea), la carne y las patatas son los ingredientes básicos para elaborar la mayoría de las típicas recetas suecas.

Entre los platos más famosos del país destacan las albóndigas suecas, tradicionalmente servidas con salsa, papas hervidas y con mermelada de arándanos rojos; los panqueques, el "lutfisk" y el "smörgåsbord". Además, también existen una gran tradición en producción de lácteos: el queso, la "filmjölk" (leche ácida), la "långfil" (yogur espeso), la "filbunke" (leche cuajada) y la "gräddfil" (nata agria). El "knäckebröd" es el pan tradicional sueco y se ha desarrollado en muchas variantes contemporáneas. El "brännvin" (un término que agrupa bebidas alcohólicas como el "aquavit" y el vodka) es muy popular en el país, y junto con la cerveza, son imprescindibles en los eventos sociales tradicionales. Otras bebidas como el café, la leche, y las bebidas carbonatadas.

Sin embargo, debido a las influencias extranjeras y relaciones internacionales del país, su gastronomía ha sido influenciada por la cocina francesa y mediterránea desde el siglo XVIII. Actualmente, como resultado de la migración y la globalización, existen gran variedad de platillos importados, además de que el consumo de comida rápida también está generalizado.

Aparte de las festividades tradicionales de Iglesia de Suecia, también se celebran varias fechas únicas, algunas de las cuales se llevan a cabo desde la época pre-cristiana. Sin embargo, muchas de ellas son de ámbito local o regional y por lo tanto son consideradas «días festivos "de facto"». Estos incluyen el Sábado Santo, la Noche de Walpurgis, la Nochebuena, la Nochevieja, entre otros. Además de los domingos, los días que son considerados oficialmente como «días festivos» (y por lo tanto, inhábiles) se enlistan en la tabla.

El deporte en Suecia es considerado como un movimiento nacional ("föreningsstöd"), en el cual participa activamente casi la mitad de la población. Las actividades deportivas son reguladas en gran parte por la Confederación de Deportes de Suecia y el Comité Olímpico de Suecia, quienes engloban a más de 22 000 clubes deportivos en todo el país especializados en distintas disciplinas. Sin embargo, la mayor parte de las actividades deportivas son subsidiadas por el gobierno, aunque algunos de los deportes más populares reciben apoyo de varios patrocinadores.

Por otra parte, el tenis ha tenido grandes éxitos. Björn Borg es considerado como uno de los mejores tenistas masculinos de la historia del tenis. Ocupó el puesto número 1 del ranking ATP y tiene en su haber 11 títulos de Grand Slam. Otros tenistas destacados son Mats Wilander y Stefan Edberg.

Los dos deportes más populares en Suecia son el hockey sobre hielo y el fútbol. La selección de hockey sobre hielo sueca ("Tre Kronor") ha ganado el Campeonato Mundial de Hockey sobre Hielo ocho veces, siendo el tercer país con más medallas. Además ganaron la medalla de oro en las olimpiadas de 1994 y 2006.

Por su parte, la selección de fútbol ha tenido buenos éxitos en pasadas copas mundiales, siendo subcampeones en el mundial de Suecia 1958, y quedaron en tercer lugar dos veces, en Brasil 1950 y Estados Unidos 1994. A nivel de jugadores, son conocidos grandes jugadores como Gunnar Gren, Gunnar Nordahl, Nils Liedholm, Martin Dahlin, Henrik Larsson (ganador de la Bota de Oro en 2001) y Zlatan Ibrahimović; este último considerado como uno de los mejores jugadores de la actualidad. Y a nivel de clubes, el IFK Göteborg es el único club que ha sido campeón europeo al ganar en los años 80 la Copa de la UEFA (1982 y 1987).

Después del fútbol, los deportes ecuestres tienen el mayor número de practicantes, además de que Gotemburgo cuenta con un centro ecuestre de importancia internacional. Otros deportes practicados comúnmente en el país incluyen el golf, el tenis, las pruebas de atletismo y varios deportes de equipo como el balonmano, el floorball, el basquetbol y el bandy.

Suecia es el octavo país en el medallero de los Juegos Olímpicos con 193 medallas de oro, 204 de plata y 230 de bronce obtenidas hasta 2010. El país se ubica en el segundo puesto en el medallero histórico de esquí de fondo, equitación y pentatlón moderno, tercero en lucha y saltos, y cuarto en tiro y canotaje. Los deportistas con más medallas de oro han sido Gert Fredriksson, Sixten Jernberg, Gunde Svan, Henri Saint Cyr y Thomas Wassberg.

La capital sueca fue elegida como sede de la 5.ª edición de los Juegos en 1912. Otros eventos deportivos en los cuales el país ha sido el anfitrión son la Eurocopa 1992, la Copa Mundial Femenina de Fútbol de 1995, y múltiples campeonatos mundiales de hockey sobre hielo, atletismo, esquí, bandy, curling, patinaje artístico y natación.





</doc>
<doc id="2590" url="https://es.wikipedia.org/wiki?curid=2590" title="Sistema de unidades">
Sistema de unidades

Un sistema de unidades es un conjunto de unidades de medida consistente, normalizado y uniforme. En general definen unas pocas unidades de medida a partir de las cuales se deriva el resto. Existen varios sistemas de unidades:
Además de estos sistemas, existen unidades prácticas usadas en diferentes campos y ciencias. Algunas de ellas son:




</doc>
<doc id="2592" url="https://es.wikipedia.org/wiki?curid=2592" title="Singularidad gravitacional">
Singularidad gravitacional

Una singularidad gravitacional o espaciotemporal, de modo informal y desde un punto de vista físico, puede definirse como una zona del espacio-tiempo donde no se puede definir alguna magnitud física relacionada con los campos gravitatorios, tales como la curvatura, u otras. Numerosos ejemplos de singularidades aparecen en situaciones realistas en el marco de la relatividad general en soluciones de las ecuaciones de Einstein, entre los que cabe citar la descripción de agujeros negros (como puede ser la métrica de Schwarzschild) o a la descripción del origen del universo (métrica de Robertson-Walker).

Desde el punto de vista matemático, adoptar una definición de singularidad puede ser complicado,pues si pensamos en puntos en que el tensor métrico no está definido o no es diferenciable, estaremos hablando de puntos que automáticamente no pertenecen al espacio-tiempo. Para definir una singularidad debemos buscar las huellas que estos puntos excluidos dejan en el tejido del espaciotiempo. Podemos pensar en varios tipos de comportamientos extraños:

Las singularidades pueden ser, en sus aspectos más generales:

Geométricamente las singularidades físicas pueden ser:

Según su carácter las singularidades físicas pueden ser:


Según la visibilidad para observadores asintóticamente inerciales alejados de la región de agujero negro (espacio-tiempo de Minkowski) éstas pueden ser:


Los teoremas sobre singularidades, debidos a Stephen Hawking y Roger Penrose, predicen la ocurrencia de singularidades bajo condiciones muy generales sobre la forma y características del espacio-tiempo.

El primero de los teoremas, que se enuncia a continuación, parece aplicable a nuestro universo; informalmente afirma que si tenemos un espacio-tiempo globalmente hiperbólico en expansión, entonces el universo empezó a existir a partir de una singularidad (Big Bang) hace un tiempo finito:

El teorema anterior por tanto es el enunciado matemático que bajo las condiciones observadas en nuestro universo, en el que es válida la ley de Hubble, y admitiendo la validez de la teoría de la Relatividad general el universo debió empezar en algún momento.

El siguiente teorema relaciona la ocurrencia de "superficies atrapadas" con la presencia de singularidades. Puesto que en un agujero negro de Schwarzschild, y presumible agujeros con geometrías similares, ocurren superficies atrapadas, el siguiente teorema predice la ocurrencia de singularidades en el interior de una clase muy amplia de agujeros negros.
Una superficie atrapada una variedad riemanniana de dos dimensiones compacta que tiene la propiedad de que tanto su como su pasado causal tiene en todo punto una expansión negativa. No es complicado probar que cualquier esfera, de hecho cualquier superficie cerrada contenida en una esfera, dentro de la región de agujero negro de un espacio-tiempo de Schwarzschild es una superficie atrapada, y por tanto en dicha región debe aparecer una singularidad. El enunciado de este teorema, debido a Roger Penrose (1965), es el siguiente:

La existencia de una geodésica de tipo luz inextensible, implica que existirá un fotón que saliendo de dicha superficie tras un tiempo de viaje proporcional a 2/"c"|θ| se topará con una singularidad temporal futura. Aunque desconocemos la naturaleza física real de las singularidades por carecer de una teoría cuántica de la gravedad el fotón o bien "desaparecerá" o bien experimentará algún fenómeno asociado a dicha teoría de la gravedad cuántica cuya naturaleza desconocemos. Además de poder neutralizar una singularidad en su más mínimo tamaño con una fuerza equivalente o superior a dicha singularidad y una vez con esa fuerza intentando revertir el sentido de la fuerza gravitatoria se necesita una fusión (nuclear) dentro del núcleo antes de ser absorbido.

Para la cual, la traza de la curvatura intrínseca satisface "K" < "C" < 0, donde "C" es una cierta constante. Entonces ninguna curva temporal partiendo de Σ y dirigida hacia el pasado puede tener una longitud mayor que 3/|"C"|. En particular, todas las geodésicas temporales hacia el pasado son incompletas."

Aunque sin ser estrictamente teoremas de singularidades existen una colección de resultados probados por Hawking (1971) que establecen que, en el marco de la teoría general de la relatividad:

Los teoremas anteriores son importantes porque garantizan, que aun en situaciones reales donde los cálculos exactos resultan complicados o imposibles, las propiedades topológicas de un espacio-tiempo que contiene agujeros negros garantizan ciertos hechos, por complicada que sea la geometría. Naturalmente sabemos que en una teoría cuántica de la gravedad los dos primeros resultados, probablemente no se mantienen. El propio Hawking sugirió que la emisión de radiación Hawking es un proceso mecano-cuántico a través del cual un agujero negro podría perder área o evaporarse; por lo que, los resultados anteriores son sólo las predicciones de la teoría general de la relatividad.

La descripción del espacio-tiempo y de la materia que hace la teoría de la relatividad general de Einstein no puede describir adecuadamente las singularidades. De hecho, la teoría general de la relatividad sólo da una descripción adecuada de la gravitación y espacio-tiempo a escalas mayores que la longitud de Planck "l":

Donde:
formula_5 es la constante de Planck reducida, formula_6 constante de gravitación universal, formula_7 es la velocidad de la luz.

De ese límite cuántico se debe esperar que igualmente la teoría de la relatividad deje de ser adecuada cuando predice una curvatura espacial del orden de "l" cosa que sucede muy cerca de las singularidades de curvatura como las existentes dentro de los diversos tipos de agujeros negros.



</doc>
<doc id="2593" url="https://es.wikipedia.org/wiki?curid=2593" title="Sinapsis">
Sinapsis

La sinapsis (del griego ύναψις ["sýnapsis"] ["neurotrasmisores"], ‘unión’, ‘enlace’) es una aproximación (funcional) intercelular especializada entre neuronas, ya sean entre dos neuronas de asociación, una neurona y una célula receptora o entre una neurona y una célula efectora (casi siempre glandular o muscular). En estos contactos se lleva a cabo la transmisión del impulso nervioso. Este se inicia con una descarga química que origina una corriente eléctrica en la membrana de la célula presináptica (célula emisora); una vez que este impulso nervioso alcanza el extremo del axón (la conexión con la otra célula), la propia neurona segrega un tipo de compuestos químicos (neurotransmisores) que se depositan en la hendidura o espacio sináptico (espacio intermedio entre esta neurona transmisora y la neurona postsináptica o receptora). Estas sustancias segregadas o neurotransmisores (noradrenalina y acetilcolina entre otros) son los encargados de excitar o inhibir la acción de la otra célula llamada célula post sináptica.

La palabra sinapsis viene de "sinapteína", que Charles Scott Sherrington y colaboradores formaron con las palabras griegas "sin-", que significa "juntos", y "hapteina", es decir "con firmeza".

Estos "enlaces químico-eléctricos" están especializados en el envío de cierto tipo de señales de pervivencia, las cuales afectan a otras neuronas, a células no neuronales como las musculares o glandulares.

Existen dos tipos de actividad base distinta, la actividad de pervivencia y la actividad de supervivencia.

La actividad sináptica de pervivencia se desarrolla en estos contextos:

La actividad sináptica de supervivencia se desarrolla en estos contextos:

La sinapsis se produce en el momento en que se registra actividad químico-eléctrica presináptica y otra postsináptica. Si esta condición no se da, no se puede hablar de sinapsis. En dicha acción se liberan neurotransmisores ionizados con base química, cuya cancelación de carga provoca la activación de receptores específicos que, a su vez, generan otro tipo de respuestas químico-eléctricas.

Cada neurona se comunica, al menos, con otras mil neuronas y puede recibir, simultáneamente, hasta diez veces más conexiones de otras. Se estima que en el cerebro humano adulto hay por lo menos 10 conexiones sinápticas (aproximadamente, entre 100 y 500 billones). En niños alcanza los 1000 billones. Este número disminuye con el paso de los años, estabilizándose en la edad adulta.

Las sinapsis permiten a las neuronas del sistema nervioso central formar una red de circuitos neuronales. Son cruciales para los procesos biológicos que subyacen bajo la percepción y el pensamiento. También son el sistema mediante el cual el sistema nervioso conecta y controla todos los sistemas del cuerpo.

De acuerdo con las últimas investigaciones relacionadas con los astrocitos y la matriz extracelular, las sinapsis constarían de cuatro elementos: los pre y postsinápticos neuronales, los astrocitos cercanos y la matriz extracelular que funcionarían como reguladores en la transferencia de información en el interior del sistema nervioso.

Desde el punto de vista histológico y funcional, una neurona tiene tres zonas principales: el cuerpo o soma, las dendritas y el axón. Estos dos últimos elementos son los encargados de establecer las relaciones sinápticas: las dendritas son como antenas que reciben la mayoría de la información que proviene de otras células; el axón, por su parte, es el cable con el que una neurona se conecta a otras.

Las conexiones pueden establecerse a muy corto alcance, a unos cientos de micrómetros a la redonda, o a distancias mucho mayores. Las neuronas de la espina dorsal, por ejemplo, se comunican directamente con órganos como los músculos para dar lugar al movimiento (sinapsis neuromuscular).

Una sinapsis prototípica, como las que aparecen en los botones dendríticos, consiste en unas proyecciones citoplasmáticas con forma de hongo desde cada célula que, al juntarse, los extremos de ambas se aplastan uno contra otro. En esta zona, las membranas celulares de ambas células se juntan en una unión estrecha que permite a las moléculas de señal llamadas neurotransmisores pasar rápidamente de una a otra célula por difusión. El canal de unión de la neurona postsináptica es de aproximadamente 20 nm de ancho, y se conoce como "hendidura sináptica".

Estas sinapsis son asimétricas tanto en su estructura como en su funcionamiento. Sólo la neurona presináptica segrega los neurotransmisores, que se unen a los receptores transmembrana que la célula postsináptica tiene en la hendidura. El terminal nervioso presináptico (también llamado "botón sináptico" o "botón") normalmente emerge del extremo de un axón, mientras que la zona postsináptica normalmente corresponde a una dendrita, al cuerpo celular o a otras zonas celulares. La zona de la sinapsis donde se libera el neurotransmisor se denomina "zona activa". En las zonas activas, las membranas de las dos células adyacentes están unidas estrechamente mediante proteínas de adhesión celular. Justo tras la membrana de la célula postsináptica aparece un complejo de proteínas entrelazadas denominado densidad postsináptica. Las proteínas de la densidad postsináptica cumplen numerosas funciones, que van desde el anclaje y movimiento de receptores de neurotransmisores de la membrana plasmática, hasta el anclaje de varias proteínas reguladoras de la actividad de estos receptores.

Una sinapsis eléctrica es aquella en la que la transmisión entre la primera neurona y la segunda no se produce por la secreción de un neurotransmisor, como en las sinapsis químicas (véase más abajo), sino por el paso de iones de una célula a otra a través de uniones gap, pequeños canales formados por el acoplamiento de complejos proteicos, basados en conexiones, en células estrechamente adheridas.

La sinapsis eléctrica es la más común en los vertebrados menos complejos y en algunos lugares del cerebro de los mamíferos. Las membranas celulares de las neuronas presináptica y postsináptica están íntimamente en contacto,a través de nexus las cuales cuentan con canales por lo que pasan los iones. Así el impulso nervioso se transmite directamente de una célula a otra. Son más rápidas que las sinapsis químicas pero menos plásticas; por lo demás, son menos propensas a alteraciones o modulación porque facilitan el intercambio entre los citoplasmas de iones y otras sustancias químicas. En los vertebrados son comunes en el corazón y el hígado.

Las sinapsis eléctricas tienen tres ventajas muy importantes:


La sinapsis química se establece entre células que están separadas entre sí por un espacio de unos 20-30 nanómetros (nm), la llamada hendidura sináptica.

La liberación de neurotransmisores es iniciada por la llegada de un impulso nervioso (o potencial de acción), y se produce mediante un proceso muy rápido de secreción celular: en el terminal nervioso presináptico, las vesículas que contienen los neurotransmisores permanecen ancladas y preparadas junto a la membrana sináptica. Cuando llega un potencial de acción se produce una entrada de iones calcio a través de los canales de calcio dependientes de voltaje. Los iones de calcio inician una cascada de reacciones que terminan haciendo que las membranas vesiculares se fusionen con la membrana presináptica y liberando su contenido a la hendidura sináptica. Los receptores del lado opuesto de la hendidura se unen a los neurotransmisores y fuerzan la apertura de los canales iónicos cercanos de la membrana postsináptica, haciendo que los iones fluyan hacia o desde el interior, cambiando el potencial de membrana local. El resultado es "excitatorio" en caso de flujos de despolarización, o "inhibitorio" en caso de flujos de hiperpolarización. El que una sinapsis sea excitatoria o inhibitoria depende del tipo o tipos de iones que se canalizan en los flujos postsinápticos, que a su vez es función del tipo de receptores y neurotransmisores que intervienen en la sinapsis.

La suma de los impulsos excitatorios e inhibitorios que llegan por todas las sinapsis que se relacionan con cada neurona (1000 a 200 000) determina si se produce o no la descarga del potencial de acción por el axón de esa neurona.

Se distinguen tres tipos principales de transmisión sináptica; los dos primeros mecanismos constituyen las fuerzas principales que rigen en los circuitos neuronales:

La fuerza de una sinapsis viene dada por el cambio del potencial de membrana que ocurre cuando se activan los receptores de neurotransmisores postsinápticos. Este cambio de voltaje se denomina potencial postsináptico, y es resultado directo de los flujos iónicos a través de los canales receptores postsinápticos. Los cambios en la fuerza sináptica pueden ser a corto plazo y sin cambios permanentes en las estructuras neuronales, con una duración de segundos o minutos, o de larga duración (potenciación a largo plazo o LTP), en que la activación continuada o repetida de la sinapsis implica que los segundos mensajeros inducen la síntesis proteica en el núcleo de la neurona, alterando la estructura de la propia neurona. El aprendizaje y la memoria podrían ser resultado de cambios a largo plazo en la fuerza sináptica, mediante un mecanismo de plasticidad sináptica.

Generalmente, si una sinapsis excitatoria es fuerte, un potencial de acción en la neurona presináptica iniciará otro potencial en la célula postsináptica. En una sinapsis débil, el potencial excitatorio postsináptico ("PEPS") no alcanzará el umbral para la iniciación del potencial de acción. En el cerebro, cada neurona mantiene conexiones o sinapsis con muchas otras, pudiendo recibir cada una de ellas múltiples señales. Cuando se disparan potenciales de acción simultáneamente en varias neuronas que se unen en sinapsis débiles a otra neurona, pueden forzar el inicio de un impulso en esa célula a pesar de que las sinapsis son débiles.

Por otro lado, una neurona presináptica que libera neurotransmisores inhibitorios, como el GABA, puede generar un potencial inhibitorio postsináptico ("PIPS") en la neurona postsináptica, bajando su sensibilidad y la probabilidad de que se genere un potencial de acción en ella. Así la respuesta de una neurona depende de las señales que recibe de otras, con las que puede tener distintos grados de influencia, dependiendo de la fuerza de la sinapsis con esa neurona. John Carew Eccles realizó algunos experimentos importantes en los inicios de la investigación sináptica, por los que recibió el en 1963. Las complejas relaciones de entrada/salida conforman las bases de la computación basada en transistores, y se cree que funcionan de forma similar en los circuitos neuronales.

Tras la fusión de las vesículas sinápticas y la liberación de las moléculas transmisoras en la hendidura sináptica, el neurotransmisor es rápidamente eliminado del espacio por proteínas especializadas en su reciclaje, situadas en las membranas tanto presináptica como postsináptica. Esta recaptación evita la desensibilización de los receptores postsinápticos y asegura que los potenciales de acción subsiguientes generen un PEP de la misma intensidad. La necesidad de una recaptación y el fenómeno de la desensibilización en los receptores y canales iónicos significa que la fuerza de la sinapsis puede disminuir si un tren de potenciales de acción llega en una sucesión rápida, un fenómeno que hace que exista una "dependencia de la frecuencia" en las sinapsis. El sistema nervioso se aprovecha de esta propiedad para computaciones, y puede ajustar las sinapsis mediante la fosforilación de las proteínas implicadas. El tamaño, número y tasa de reposición de las vesículas también está sujeto a regulación, así como otros muchos aspectos de la transmisión sináptica. Por ejemplo, un tipo de fármaco conocido como inhibidores selectivos de la recaptación de serotonina o SSRI afectan a ciertas sinapsis inhibiendo la recaptación del neurotransmisor serotonina. Por el contrario, un neurotransmisor excitatorio muy importante, la acetilcolina, no es recaptada, pero es eliminada por acción de la enzima acetilcolinesterasa.

La modificación de los parámetros sinápticos pueden modificar el comportamiento de los circuitos neurales y la interacción entre los diferentes módulos que componen el sistema nervioso (modal). Dichos cambios están englobados en un fenómeno conocido como neuroplasticidad o plasticidad neuronal.

Por analogía con las sinapsis descritas, el encuentro entre una célula antigénica y un linfocito se denomina a veces "sinapsis inmunitaria".

Trastorno degenerativo neuronal situado en la sustancia negra, estas se encargan de producir dopamina (neurotransmisor) fundamental para que el movimiento del cuerpo se realice correctamente. Cuando no se dispone de dopamina suficiente se presentan los síntomas que caracterizan esta enfermedad.

Crisis recurrentes de descargas entre impulsos inhibitorios y excitatorios. La inhibición recurrente puede ocurrir cuando una neurona principal hace sinapsis con una neurona inhibidora. El estado hiperexcitable resulta del incremento de la neurotransmisor excitadora sináptica.

Proceso degenerativo de las neuronas de la corteza cerebral que es irreversible hasta el momento.





</doc>
<doc id="2594" url="https://es.wikipedia.org/wiki?curid=2594" title="Sparganiaceae">
Sparganiaceae

Sparganium es el nombre de un taxón ubicado en la categoría taxonómica de género, que en sistemas de clasificación como el del APG II del 2003 es el único género de la familia Sparganiaceae, siendo en otros sistemas de clasificación como el de Judd "et al." (2007), el del APWeb, el de Kubitzki (1998) y el más moderno APG III (2009), un género de la familia Typhaceae "sensu lato", en este caso compartiendo la familia con su género hermano "Typha", por lo que se podría decir que en la actualidad la familia Sparganiaceae fue abandonada. El taxón está formado por hierbas perennes acuáticas emergentes rizomatosas, con hojas dísticas bifaciales (en su hábito muy parecidas a las totoras), con cabezas globosas unisexuales por inflorescencias (las cabezas masculinas arriba, las femeninas abajo), de numerosas flores diminutas polinizadas por viento. Distribuidas en todo el mundo.

Hierbas perennes, monoicas, emergentes acuáticas, de tallo rizomatoso.

Hojas bifaciales, dísticas, envainadoras, simples, sin dividir, planas, elongadas y delgadas, de venación paralela.

Inflorescencia compuesta, de cabezas globosas bracteadas y unisexuales, las cabezas masculinas arriba, las femeninas debajo.

Flores pequeñas, unisexuales, actinomórficas, sésiles, las flores femeninas hipóginas.

El perianto es aparentemente bracteado en las flores femeninas, los tépalos como escamas son 1-6 en flores masculinas, 3-4 (raramente 2-5) en las femeninas. 

Los estambres son 1-8, antitépalos (dispuestos opuestos a los tépalos), separados o conados basalmente.

El gineceo es de 1 solo carpelo o de 2-3 carpelos conados (a su vez con 1 o 2-3 lóculos), con un ovario súpero. La placentación es apical, los óvulos son anátropos, bitégmicos, 1 por carpelo.

No hay nectarios.

El fruto es seco y como una drupa con un perianto persistente y el estilo también persistente.

Las semillas son endospermadas.

Distribuidos principalmente en regiones templadas a frías del Hemisferio Norte.

Las diminutas flores de "Sparganium" son polinizadas por viento.

La familia no fue reconocida por el APG III (2009), que asigna el único género a la familia Typhaceae "sensu lato".. La familia sí había sido reconocida por el APG II (2003) que la separaba de Typhaceae "sensu stricto".

El nombre científico del género es "Sparganium" L., Sp. Pl.: 971 (1753).

La lista de especies, conjuntamente con su publicación válida y su distribución, según el Royal Botanic Gardens, Kew (visitado en enero de 2009):


No poseen importancia económica significativa.



</doc>
<doc id="2595" url="https://es.wikipedia.org/wiki?curid=2595" title="Sistema Cegesimal de Unidades">
Sistema Cegesimal de Unidades

El Sistema Cegesimal de Unidades, también llamado sistema CGS, es un sistema de unidades basado en el centímetro, el gramo y el segundo. Su nombre es el acrónimo de estas tres unidades. 

Fue propuesto por Gauss en 1832, e implantado por la Asociación Británica para el Avance de la Ciencia (BAAS, ahora BA) en 1874 incluyendo las reglas de formación de un sistema formado por unidades básicas y unidades derivadas.

El sistema CGS ha sido casi totalmente reemplazado por el Sistema Internacional de Unidades (SI). Sin embargo aún perdura su utilización en algunos campos científicos y técnicos muy concretos, con resultados ventajosos en algunos contextos. Así, muchas de las fórmulas del electromagnetismo presentan una forma más sencilla cuando se las expresa en unidades CGS, resultando más simple la expansión de los términos en "v"/"c".

La Oficina Internacional de Pesos y Medidas, reguladora del SI, valora y reconoce estos hechos e incluye en sus boletines referencias y equivalencias de algunas unidades electromagnéticas del sistema CGS gaussiano, aunque desaconseja su uso.

A diferencia del SI, el sistema CGS no determina si debe haber una dimensión adicional para las magnitudes electromagnéticas (en el SI es la corriente). De ahí que haya varios sistemas cegesimales en función de como se tratan las constantes formula_1 y formula_2. Las ecuaciones se ajustan según el sistema concreto adoptado, aunque en la práctica apenas se usa más que el de Gauss, donde ambas constantes se toman como 1 y a cambio aparece explícitamente "c". Las dimensiones, así, pueden tener exponentes semienteros.

En el SI la corriente eléctrica se define mediante la intensidad de campo magnético que presenta, y la carga eléctrica se define como corriente eléctrica por unidad de tiempo. En una variedad del CGS, el ues o unidades electrostáticas, la carga se define como la fuerza que ejerce sobre otras cargas, y la corriente se define como carga por unidad de tiempo. Una consecuencia de este método es que la ley de Coulomb no contiene una constante de proporcionalidad.

Por último, al relacionar los fenómenos electromagnéticos al tiempo, la longitud y la masa, dependen de las fuerzas observadas en las cargas. Hay dos leyes fundamentales en acción: la ley de Coulomb, que describe la fuerza electrostática entre "cargas", y la ley de Ampère (también conocida como la ley de Biot-Savart), que describe la fuerza electrodinámica (o electromagnética) entre "corrientes".

Cada una de ellas contiene las constantes de formula_3 y formula_4. La definición estática de campo magnético tiene otra constante, formula_5. Las dos primeras constantes se relacionan entre sí a través de la velocidad de la luz, formula_6 (la razón entre formula_3 y formula_4 debe ser igual a formula_9).

De este modo se tienen varias opciones:

Una característica del sistema CGS gaussiano es que el campo eléctrico y el campo magnético tienen las mismas unidades. Existe aproximadamente media docena de sistemas de unidades electromagnéticas en uso, la mayoría basados en el sistema CGS. Estos incluyen el UEM o unidades electromagnéticas (escogidas de tal manera que la ley de Biot-Savart no tenga constante de proporcionalidad), Gausiano y unidades Heaviside-Lorentz. Para complicar más el asunto, algunos físicos e ingenieros utilizan para el campo eléctrico unidades híbridas, como voltios por centímetro.

En el antiguo sistema de unidades electromagnéticas basado en el CGS que se usó para estudiar la inducción magnética la unidad de corriente no es el estatamperio sino el abamperio = 10 amperio, lo que permite llegar a definir el gauss como unidad de densidad de flujo magnético.
En la tabla siguiente se encontrará el estatamperio y el gauss como pertenecientes al moderno sistema CGS. Esto es inexacto. El gauss no es una magnitud CGS sino electromagnética.

Los coeficientes 2998, 3336, 1113 y 8988 se derivan de la velocidad de la luz; exactamente valen 299792458, 333564095198152, 1112650056 y 89875517873681764.

Un «centímetro» de capacidad es la capacitancia de una esfera conductora, de 1 cm de radio, en el vacío.





</doc>
<doc id="2596" url="https://es.wikipedia.org/wiki?curid=2596" title="Spermatophyta">
Spermatophyta

Las espermatofitas o fanerógamas (Spermatophyta) son un grupo monofilético del reino de las plantas (Plantae) que comprende a todos los linajes de plantas vasculares que producen semillas. 

El nombre científico proviene del griego σπέρμα ("sperma", que significa "semilla"), y φυτόν ("fiton", que significa "planta"), que se traduce como «plantas con semilla». La circunscripción del grupo (es decir, los taxones de los que está compuesto) coincide exactamente con la del antiguo taxón Phanerogamae, que por lo tanto es sinónimo de esta división. Debido a que en las espermatofitas el grano de polen produce un tubo (haustorial o polínico) para llegar al óvulo y que ocurra la fecundación, este grupo también es llamado de las embriofitas sifonógamas (del griego: "embrios": embrión; "fiton": planta; "xifos": tubo; "gamos": unión sexual. Literalmente, "plantas con embrión cuya unión sexual ocurre con tubo"). A veces la jerga científica se refiere a este grupo como "embriofitas", dejando fuera a las embriofitas asifonógamas o de los briófitos y los helechos y afines.

Hace mucho tiempo que los científicos consensúan la monofilia de las espermatofitas. Entre las evidencias morfológicas de la monofilia de las espermatofitas está, por supuesto, la semilla misma, y también la producción de madera (o "xilema secundario" generado en el meristema secundario llamado "cámbium"), al menos en forma ancestral. Otra característica notable es la ramificación axilar, en comparación con la ramificación dicotómica anisotónica de sus ancestros eufilofitos.

Las espermatofitas se originaron a fines del Devónico, a partir de lignofitas, que ya tenían producción de madera y ramificación axilar, como puede observarse en el registro fósil. 

Hoy en día las espermatofitas son, por mucho, el linaje más extenso de plantas vasculares, con unas 270.000 especies vivientes (Judd "et al." 2002). Un solo subclado es el mayor responsable de esa diversidad: las angiospermas, o plantas con flores periantadas. Otros subclados, normalmente agrupados como gimnospermas, son las cícadas, los ginkgos, las coníferas y los gnetales. Estos cuatro grupos comparten un ancestro común. También se llaman "gimnospermas" a algunos fósiles de espermatofitas no productores de flores periantadas, que no comparten el mismo ancestro que las gimnospermas vivientes, por lo que algunos autores diferenciaban "Gymnospermae "sensu lato"" (pteridospermas + gimnospermas vivientes), que sería parafilético con respecto a las angiospermas y a "Gymnospermae "sensu stricto"", monofiléticos, comprendidos por los linajes vivientes.

Este grupo ha sido denominado Phanerogama (Bartling 1830), Phanerogamae (Brongniart 1843, Eichler 1883), Spermatophyta (Willkomm 1854, Goebel 1882, Britton & A. Brown 1896), Anthophyta (Braun in Ascherson 1864, Wettstein 1924-1935), Siphonogamae (Engler 1886), Embryophyta siphonogama, (Engler 1892-1924), división Magnoliophyta (Takhtajan 1964) y Spermatophytina (Cavalier-Smith 1998, Ruggiero et al. 2015).

Las espermatofitas pueden definirse como traqueofitas con las siguientes características:


Como se puede observar de sus hermanos vivientes los helechos, las espermatofitas descienden de un ancestro caracterizado por la homosporía (un solo tipo de espora, gametofitos siempre bisexuales). Un paso crítico en el desarrollo de la semilla fue la evolución de la heterosporía: la producción de dos tipos de esporas, las megasporas y las microsporas, que darán los gametofitos femeninos y masculinos respectivamente.

La heterosporía se originó muchas veces en forma independiente en linajes no emparentados de plantas vasculares (hay ejemplos en lycophytas, en equisetopsidas y en polypodiopsidas), en muchos de esos casos el desarrollo de la heterosporía fue seguido de una reducción del número de megasporas funcionales. En la línea que condujo a las plantas con semilla, en el esporófito adulto que desarrolla sus megasporangios, se produce la meiosis de sólo una célula por megasporangio, y por aborto de 3 de los productos de la meiosis, el número de megasporas funcionales es reducido a sólo un megaspora funcional por megasporangio. Esa única megaspora funcional, en el linaje de las espermatofitas fue retenida dentro del megasporangio, desarrollando su gametofito femenino y gameta femenina por completo dentro del megasporangio de la generación esporofítica anterior. Finalmente el megasporangio desarrolló los tegumentos dejando abierto el pequeño orificio llamado micrópila.

Nuestro conocimiento de los orígenes de la semilla se basa principalmente en fósiles bien preservados del Devónico tardío y Carbonífero temprano, que fueron llamados "progimnospermas" o "helechos con semilla". Recordemos que la diferenciación entre un tallo principal y ramas laterales ya había evolucionado en el linaje de las eufilofitas. Lo primero que aparece en el linaje que derivó en las espermatofitas, fue encontrado en el Devónico tardío, y es la aparición de troncos muy grandes, con madera bastante similar en su estructura a la de las modernas coníferas. Estos troncos estaban conectados a enormes sistemas de ramas que portaban muchas hojas pequeñas. "Archaeopteris", como ahora es llamada, fue descubierta como heterospórica, pero aún sin formar semillas.

La reconstrucción más exacta y la ubicación en el árbol filogenético de "Archaeopteris" y otras "progimnospermas" como "Aneurophyton" (Beck 1981, 1988, Beck y Wight 1988), fue fundamental para que los científicos puedan establecer tanto el origen de la heterosporía como el de la producción de madera, y llegar a la conclusión de que los dos eran anteriores a la evolución de la semilla. Por lo tanto es incorrecto afirmar que esos dos fósiles pertenecen a un clado que se llame espermatofitas ("plantas con semilla"), si bien son ancestros de las plantas con semilla actuales. Por lo tanto las espermatofitas y esos dos fósiles pertenecen a un grupo monofilético mayor, que fue llamado "Lignophyta" (Doyle y Donogue 1990), en referencia a que ya producían madera.

Análisis cuidadosos (por ejemplo el de Serbet y Rothwell 1992) han revelado que las primeras semillas estaban situadas en "cúpulas" ("cupules" en inglés) y cada semilla era cubierta por una excrecencia de la pared del esporangio que formaba una cámara especializada para recibir el polen, o "cámara polínica". Esta estructura probablemente se ayudaba de una secreción de una gota pegajosa ("gota de polinización") para capturar los granos de polen. 

Los tejidos del tegumento externo probablemente derivan de una serie de esporangios estériles, que inicialmente tuvieron la forma de una serie de lóbulos en el ápice de la semilla, más que la forma de una micrópila diferenciada (ver gráfico).

Se ha demostrado -en contra de lo esperado- que el grupo de las gimnospermas vivientes es un grupo monofilético, hermano de las angiospermas. 

Los análisis multigenéticos moleculares han demostrado que Spermatophyta se divide en dos grandes grupos: Gymnospermae y Angiospermae, los cuales fueron definidos por John Ray en 1703, y taxonómicamente esta clasificación se ha mantenido estable desde 1854. Así pues, la filogenia más actualizada (2014) de las plantas vivientes con semilla presenta los siguientes subgrupos:
Las diferencias entre los dos grupos están resumidas en el siguiente cuadro.

Una visión general de los grupos extintos relacionados con Spermatophyta sería la siguiente:

Durante una gran parte del último siglo, los linajes de plantas con semilla, tanto vivientes como extintos, fueron comúnmente divididos en dos grandes grupos: las cycadofitas y las coniferofitas. Las cycadofitas, entre las que se incluyen las modernas cycadáceas, se distinguían por una producción de madera (crecimiento secundario del tallo) más bien limitada, con radios más bien anchos (lo que se llama "leño manoxílico"), y por hojas grandes, de tipo fronde de helecho, y semillas con simetría radial. En contraste, en las coniferofitas, entre las que se incluyen el "Ginkgo" y las coníferas, la madera está bien desarrollada y es densa ("leño picnoxílico"), las hojas son simples y muchas veces en forma de aguja, y las semillas tienen simetría dorsiventral (están "aplastadas"). Esta distinción sugirió a algunos investigadores que las plantas con semilla en realidad se originaron dos veces. Desde este punto de vista, la línea de las cycadofitas se derivó de un ancestro de tipo Progymnosperma, en el cual el sistema de ramificación lateral aplanado derivó en grandes hojas de tipo fronde de helecho. En cambio la línea de las espermatofitas habría derivado de un ancestro del tipo "Archaeopteris", en el que las hojas individuales pueden haber sido modificadas en hojas de tipo aguja. Este escenario implica que la semilla misma fue originada dos veces, cada una correspondiéndose a un tipo de simetría diferente.

Sin embargo, en los análisis de filogenia que incluyeron los linajes vivientes junto con los representantes fósiles, en general aprueban el árbol filogenético que se muestra en la figura siguiente (ver por ejemplo Crane 1985, Doyle y Donoghue 1986, Nixon "et al." 1994, Rothwell y Serbet 1994).

Estos estudios asumen que la semilla apareció una sola vez, y que las primeras plantas con semilla eran más bien parecidas a las cícadas, al menos en lo que respecta a las hojas grandes y pinadas, y las semillas con simetría radial. Específicamente, parece que una serie de "helechos con semilla" del Devónico-Carbonífero ("Lygniopteris" y medulosas) están situados en la base de la filogenia de las plantas con semilla, y que las coniferofitas están anidadas varios niveles hacia adentro del árbol, en un clado "platyspérmico" (de semillas con simetría dorsiventral). Este árbol hipotetiza que el cambio a hojas de tipo aguja y el cambio a semillas de simetría dorsiventral fueron posteriores a la aparición de las hojas y las semillas, y probablemente fueron una adaptación a ambientes de tipo árido.

A pesar de los enormes esfuerzos hechos hasta ahora para dilucidar las relaciones filogenéticas de los 5 grupos vivientes de espermatofitas (cícadas, ginkgos, coníferas, gnetofitas y angiospermas), utilizando tanto información morfológica como molecular, las relaciones aún no reciben consenso, y son motivo de variadas discusiones en el ambiente científico. En ese sentido cabe aclarar que está definitivamente descartado que las angiospermas deriven de una gnetofita ancestral. Los estudios morfológicos detallados muestran un origen diferente de los vasos xilemáticos en gnetofitas y en angiospermas (esto quiere decir que se originaron dos veces), y las estructuras de la flor de las gnetáceas (aquí definimos "flor" como "rama de crecimiento definido portadora de hojas fértiles") no son homólogas a las de la flor de angiosperma. Además, en el año 2004 se han encontrado fósiles de Gnetofitas que confirman (de forma morfológica) su pertenencia al grupo de las gimnospermas, y descarta nuevamente su relación con las angiospermas. 

Hay que tener en cuenta que también se agrupaba dentro de las "gimnospermas" a muchos fósiles de plantas con semilla extintas (las pteridospermas) que en conjunto no forman un grupo monofilético: de hecho el grupo llamado Gymnosperma "sensu lato" se vuelve parafilético cuando uno toma en consideración los linajes de espermatofitas basales, así como otros "helechos con semilla" del Pérmico tardío y el Mesozoico, algunos de los cuales están probablemente en el linaje que derivó en las angiospermas.

Los diferentes sistemas de clasificación le dan diferente importancia relativa a las estructuras de las espermatofitas:

Según Engler 1924 se subdividen en:

Se dividen según Cronquist en:





Hoy en día hay 2 linajes vivientes de espermatofitas: las gimnospermas y las plantas con flores. Gymnospermae es referencia a que poseen las semillas "desnudas" o no totalmente cubiertas por el carpelo, en oposición a las angiospermas o plantas con flores, cuyo carpelo cubre completamente a la semilla.

Cícadas: fueron las más abundantes y diversas durante el Mesozoico. Hoy quedan alrededor de 130 especies. Las cícadas generalmente poseen un tronco bajo y ancho, con xilema secundario limitado, y hojas compuestas grandes parecidas a las de los helechos o las palmeras. Son dioicos, eso quiere decir que algunos esporófitos solo portan óvulos y luego semillas, y otros esporófitos solo portan estróbilos masculinos productores de polen. Los dos tipos de estróbilo son típicamente muy grandes, y en algunos casos de coloración brillante. Asimismo las semillas suelen ser grandes y usualmente tienen un tegumento externo carnoso y coloreado, presumiblemente una adaptación para atraer a los agentes de dispersión vertebrados. Muchas características de las cícadas pueden ser ancestrales, como el polen con tubo haustorial (en lugar de tubo polínico), y el esperma gigante multiflagelado (en lugar de los núcleos espermáticos). Sin embargo, las cícadas poseen características únicas que las alejan de las plantas con semilla ancestrales, que presumiblemente son caracteres derivados, entre los cuales se incluye la pérdida de la ramificación axilar, la presencia de trazas foliares "girdling" ("¿con fajas?"), y la producción de raíces coralloides que albergan cianobacterias fijadoras de nitrógeno. Dentro de las cícadas, los análisis filogenéticos indican que la primera división del grupo fue la que dividió al linaje de "Cycas" del resto. Por lo tanto "Cycas" estaría reteniendo algunos caracteres presumiblemente ancestrales, como los que han sido encontrados en parientes fósiles como "Taeniopteris", a saber: el tener muchos óvulos nacidos en los márgenes de carpelos (carpelos definidos como hojas fértiles portadoras de óvulos) con mofología de tipo foliar, en lugar de tener dos óvulos por carpelo peltado que los sostiene apuntando hacia el eje del esporofilo (en su "cara adaxial"), que es el carácter que se encuentra en la otra línea. También en "Cycas" las hojas fértiles portadoras de óvulos no se encuentran agrupadas en estróbilos, como sí lo están en la otra línea.

Ginkgos: solo hay una especie sobreviviente de ginkgos: "Ginkgo biloba". Esta especie es muy raramente encontrada en forma silvestre, pero los árboles presentes en los templos de China fueron mantenidos por siglos por los monjes que los habitan, y en los tiempos modernos fue cultivado por el hombre en las veredas de las ciudades. Quizás la característica más distintiva del "Ginkgo" moderno es la producción de hojas deciduas, con forma de abanico ("flabeladas"), con venación dicotómica. Los ginkgos son bien conocidos en el registro fósil, donde se observa una gran diversidad en la morfología de las hojas. Como las cícadas, los ginkgos son dioicos (esporófitos 
diferentes portan o bien carpelos o bien estambres -estambres definidos como "hojas fértiles portadoras de sacos polínicos que contienen a los granos de polen"-). Los óvulos nacen en pares sobre ramas axilares que se piensa que son estróbilos reducidos. El tegumento del óvulo se diferencia en una capa externa carnosa (y olorosa) y una capa interna pétrea (dura) que encierra al gametofito femenino. También al igual que en las cícadas, los ginkgos retienen varios caracteres de las espermatofitas ancestrales, como el polen que emite un tubo haustorial (no polínico), y el esperma flagelado capaz de nadar.

Coníferas: hay aproximadamente unas 600 especies de coníferas vivientes. Son árboles o arbustos con madera bien desarrollada y usualmente hojas de tipo aguja. Normalmente las hojas son solitarias, naciendo a lo largo del tallo, pero en los pinos ("Pinus") están agrupadas en ramitas pequeñas. Las hojas usualmente tienen adaptaciones adicionales a la sequedad, por ejemplo estomas hundidos. Sin embargo algunas coníferas del Hemisferio Sur (por ejemplo "Podocarpus", "Agathis") presentan hojas aplanadas y grandes, y en "Phyllocladus" se observan ramas aplanadas que parecen hojas. Muchas coníferas son monoicas (poseen carpelos y estambres en el mismo esporófito), pero algunos grupos son dioicos: "Juniperus", "Taxus", y "Podocarpus". En los estróbilos masculinos (que en las coníferas se llaman conos masculinos o "pollen cones" en inglés), los estambres (o "microesporofilos") sostienen en su cara abaxial a los esporangios ("microsporangios") que darán gametofitos masculinos ("microgametofitos"). Los granos de polen son los gametofitos masculinos protegidos por una pared originada en el esporófito, y a veces tienen un par de apéndices llenos de aire parecidos a sacos, presumiblemente adaptaciones a la dispersión por el viento, pero estos "sacos aéreos" parecen haberse perdido en muchas líneas. Los óvulos receptivos, a diferencia de los microsporangios, están situados en la cara adaxial de cada carpelo o "escama ovulífera", mirando hacia el eje del cono femenino. La meiosis que dará las gametas, ocurre dentro de cada óvulo, y uno solo de los 4 productos de la meiosis se desarrollará hasta dar el gametofito femenino, siempre dentro del óvulo. El gametofito femenino o "protalo", produce uno o más gametos femeninos o "huevos" en el sector cercano a la micropila. Cuando el grano de polen llega finalmente a la micropila, el gametofito masculino encerrado en él desarrolla un tubo ("tubo polínico") que atraviesa la pared del gametófito femenino. Cuando el tubo polínico termina de crecer, el gametofito masculino emite a través de él dos espermas, que pueden ser células o núcleos celulares ("núcleos espermáticos") según el linaje. Es muy común en coníferas el fenómeno de "poliembronía", con muchos embriones desarrollándose en el mismo gametófito femenino, que puede ser o bien debido a que ocurrieron eventos de fertilización independientes en los que varios huevos fueron fertilizados por varios tubos polínicos distintos, o bien debido a que el embrión único se dividió en una etapa temprana en varios embriones genéticamente idénticos, siendo la última posibilidad más comúnmente encontrada que la primera. En las modernas coníferas, se dice que el estróbilo portador de polen es "simple", mientras que el portador de óvulos es "compuesto". Esto es debido a cómo es interpretada la morfología de los estróbilos: El cono masculino es interpretado como una rama modificada portadora de hojas fértiles o estambres, por lo tanto sería una "flor" única portadora de muchos estambres. En cambio el cono femenino es interpretado como derivado de una rama con hojas, que a su vez porta ramas laterales de crecimiento definido nacidas en la axila de las hojas, cada una de las ramas laterales portadoras de hojas fértiles o carpelos. Esta interpretación es sostenida por el registro fósil, que muestra una serie de pasos en la reducción de las ramas laterales portadoras de carpelos, hasta la aparición de la "escama ovulífera" altamente modificada que vemos en los grupos modernos (Florin 1951, 1954). También se observa que cada escama ovulífera está sostenida por una bráctea ("bráctea tectriz"), que representaría la hoja portadora de la rama lateral, también altamente modificada. En unas pocas coníferas, la bráctea es conspicua, emergiendo de entre las escamas ovulíferas (por ejemplo en "Pseudotsuga mensiezii"). Sin embargo en muchas coníferas la bráctea es sumamente reducida. En las cupresáceas "Taxodium" y "Cryptomeria", la bráctea está fusionada a la escama ovulífera, y la escama ovulífera aún muestra signos de presentar "hojas" (visibles como pequeños dientes). Los estudios filogenéticos han revelado algunas cuestiones interesantes acerca de la evolución de las coníferas. (por ejemplo Stefanovic "et al." 1998). Los datos moleculares muestran una división basal entre las pináceas y un clado que albergaría a todas las demás coníferas. Las pináceas poseen varias características singulares, como óvulos invertidos (con la micropila mirando hacia el eje del cono) y las semillas aladas, alas que se originan en la escama ovulífera durante el desarrollo de la semilla. Dentro del otro clado de las coníferas, los dos grupos más grandes del Hemisferio Sur (Podocarpaceae y Araucariaceae) forman un clado, presumiblemente con la sinapomorfía de poseer un solo óvulo por escama ovulífera. Las cupresáceas están marcadas por muchas características singulares, como la fusión de la escama ovulífera con la báctea tectriz. A su vez, este grupo puede estar emparentado con las taxáceas, que tienen conos femeninos altamente reducidos con una sola semilla terminal, rodeada de un tercer tegumento ("arilo") carnoso y colorido.
Gnetales: este grupo contiene solo unas 80 especies vivientes, que pertenecen a tres linajes bastante diferenciados (Doyle 1996, Friedman 1996, Price 1996). Uno es "Ephedra", con alrededor de 40 especies distribuidas en los desiertos de todo el mundo, con hojas muy reducidas escamosas. Otro es "Gnetum", con unas 35 especies en bosques tropicales del Viejo y Nuevo Mundo, con hojas con lámina entera muy parecidas a las vistas en la mayoría de las angiospermas. Finalmente, "Welwitschia" con una sola especie, "Welwitschia mirabilis" encontrada en el sudoeste de África, produce solo dos o raramente cuatro hojas funcionales a lo largo de toda su vida, hojas que crecen indefinidamente por meristemas presentes en la base, y se necrosan gradualmente en las puntas.

Si bien estos tres clados se ven muy diferentes uno del otro, comparten muchas características inusuales, como las hojas opuestas, múltiples yemas por axila, vasos xilemáticos con aberturas circulares entre células adjuntas, polen compuesto, semillas en estróbilo, y un polen elipsoide ancestral con unas estrías características que corren de punta a punta. Las semillas también tienen dos tegumentos, el interno formando el tubo micropilar que exuda la gota de polinización, el externo derivado de un par de brácteas fusionadas. Los estudios moleculares también consensúan altamente la monofilia de este grupo. Dentro de las gnetofitas, "Gnetum" y "Welwitschia" forman un clado bien consensuado. Algunas de las sinapomorfías morfológicas son: hojas con venación reticulada, reducción aún mayor del gametófito masculino, y algunos aspectos de la estructura del gametófito femenino, como el desarrollo tetraspórico, la pérdida de los arquegonios, los núcleos libres funcionando como huevos en lugar de las células. El característico polen estriado encontrado en "Ephedra" y "Welwitschia" fue aparentemente perdido en la línea de la que derivó "Gnetum", que tiene un polen con granitos con forma de pico, no aperturado. En lo que respecta al registro fósil, es más bien pobre salvo en los granos de polen. Solo algunos macrofósiles han sido descriptos (Crane 1996). Si bien los granos de polen de las gnetofitas son encontrados desde el Triásico, parece ser que el clado que contiene a los grupos modernos se ha diversificado más significativamente durante el Cretácico medio, al mismo tiempo que las angiospermas. Al igual que las angiospermas, las gnetofitas acortaron su ciclo de vida (y probablemente se volvieron herbáceas) y evolucionaron junto con los insectos para ser polinizadas por ellos, característica aún encontrada en algunos grupos vivientes. En marcado contraste con las angiospermas en cambio, las gnetofitas nunca se volvieron un componente significativo de la flora en paleolatitudes altas y medias, y han sufrido una disminución dramática de su representatividad durante el Cretácico tardío (Crane "et al." 1995, Crane 1996). 

Con unas 257.000 especies vivientes, las angiospermas son las responsables de la mayor parte de la diversidad en espermatofitas, en embriofitas y en viridofitas. La fuerte evidencia de la monofilia de las angiospermas proviene de los estudios moleculares y de los muchos caracteres morfológicos compartidos por los miembros de este clado. De estos, algunos de los más obvios, que también son características reproductivas importantes, son: (1) las semillas son producidas dentro de un carpelo con una superficie estigmática que permite la germinación del polen, (2) el gametófito femenino es muy reducido, en la mayoría de las especies son sólo 8 núcleos en 7 células, y (3) la doble fertilización, que llevó a la formación de un tejido nutritivo característico, triploide, llamado endosperma. Otras características son: (4) muchas angiospermas poseen vasos xilemáticos en lugar de traqueidas, carácter derivado dentro del grupo, en los vasos el agua puede fluir sin necesidad de atravesar una membrana, lo que los vuelve muy eficientes en el transporte de fluidos dentro del esporófito pero probablemente también más propensos a recibir daño (en especial por embolias de aire) cuando están sujetos a estrés hídrico. (5) El floema de las angiospermas difiere del de todas las demás plantas en que los elementos del tubo criboso (que son células vivas pero sin núcleo, encargadas del transporte de azúcares) están acompañadas por una o más "células acompañantes", que nacen de la misma célula madre que el elemento criboso.



</doc>
<doc id="2597" url="https://es.wikipedia.org/wiki?curid=2597" title="Siglo VI">
Siglo VI

El (siglo sexto después de Cristo) o EC (siglo sexto de la era común) comenzó el 1 de enero del año 501 y terminó el 31 de diciembre del 600. Unos años después del fin de la época clásica (derrumbe del Imperio romano occidental en el año 476) y el inicio de la época medieval. Es llamado el «Siglo de Bizancio».
Después de la caída del Imperio romano occidental a finales del siglo anterior, Europa es fracturada en muchos reinos germánicos pequeños, que compitieron constantemente por tierra y recursos. Finalmente los francos llegaron a ser dominantes, y se expandieron hacia fuera un dominio importante que abarcaba gran parte de Francia y de Alemania.

Mientras tanto, el Imperio romano del este que sobrevivió comenzó a ampliarse bajo el mando del emperador Justiniano I, que recobró eventualmente África del norte de los vándalos, y procuró recuperar completamente Italia también con la esperanza de restablecer el control romano sobre las tierras gobernadas una vez por el Imperio romano occidental. Después de la muerte de Justiniano I, la mayor parte de sus logros desaparecieron. El Imperio sasánida alcanzó un pico de grandeza con Cosroes I en el .







</doc>
<doc id="2599" url="https://es.wikipedia.org/wiki?curid=2599" title="Sífilis">
Sífilis

La sífilis, llamada antiguamente morbo gálico, mal francés o bubas, es una enfermedad infecciosa de curso crónico, transmitida principalmente por contacto sexual, producida por la espiroqueta "Treponema pallidum", subespecie "pallidum" (pronunciado "pál lidum"). Sus manifestaciones clínicas son de características e intensidad fluctuantes, apareciendo y desapareciendo en las distintas etapas de la enfermedad: úlceras en los órganos sexuales y manchas rojas en el cuerpo. Produce lesiones en el sistema nervioso y en el aparato circulatorio. Existe en todo el mundo y se ha descrito desde hace siglos.

El nombre «sífilis» fue creado por el poeta y cirujano veronés Girolamo Fracastoro en su poema en latín "Syphilis sive morbus gallicus" (‘Sífilis o la enfermedad francesa’) en 1530. El protagonista de la obra es un pastor llamado Sífilus (quizá una variante de Sipylus, un personaje de "Las metamorfosis" de Ovidio), que cuidaba de los rebaños del rey Alcihtous. Molesto con el dios griego Apolo, ya que este quemaba los árboles y consumía los brotes que alimentaban a las ovejas, decidió no adorarlo a él sino al rey. En represalia, Apolo lo castigó junto con todo el reino, afectándolos de una enfermedad horrible, que llamó «sífilis» por el pastor. Agregándole el sufijo "-is" a la raíz Syphilus, Fracastoro creó el nuevo nombre de la enfermedad, y lo incluyó en su libro de medicina "De contagionibus" (‘Sobre las enfermedades contagiosas’, Venecia, 1584).

En este texto, Fracastoro registra que en la época, en Italia y Alemania la sífilis se conocía como el «morbo francés», y en Francia, como «el morbo italiano».

La sífilis también ha sido conocida como avariosis, búa, buba (o bubas), gálico, lúes venérea, o mal de bubas.

Las distintas denominaciones utilizadas entre los siglos XV y XVII dan idea de la vasta extensión de la enfermedad, y de la costumbre de culpar de ella a los países vecinos.


El origen y antigüedad de la sífilis representan una de las controversias no resueltas más importantes en la historia de la medicina. Las preguntas fundamentales de esta controversia son: ¿Llegó la sífilis al Viejo Mundo desde el Nuevo Mundo a través de la tripulación de Cristóbal Colón —como parece indicarlo que la primera epidemia de esta enfermedad en Europa fuese registrada en 1493—? o bien, ¿se originó la sífilis en el Viejo Mundo y permaneció como una enfermedad no identificada hasta que a finales del siglo XV se hizo notoria por una mayor virulencia o transmisibilidad? En relación con esa controversia se han elaborado dos hipótesis del origen de la sífilis, que generan debate en el campo de la antropología y la historiografía.

La hipótesis precolombina sostiene que las treponematosis, incluida la sífilis, son un conjunto de variantes de una enfermedad que se fue extendiendo tanto en el Viejo como en el Nuevo Mundo. En Europa sus manifestaciones se habrían confundido con la lepra. De acuerdo con esta hipótesis, la pinta apareció en África y Asia alrededor del 15000 a. C., con un reservorio natural animal. El pian se habría desarrollado como consecuencia de mutaciones de la pinta alrededor del X milenio a. C. extendiéndose por todo el mundo excepto en América que se encontraba aislada. La sífilis endémica emergió del pian alrededor del VII milenio a. C. como consecuencia de los cambios climáticos (aparición de clima árido). Alrededor del Siglo XXX a. C. la sífilis transmitida sexualmente apareció en el sudoeste asiático debido a las bajas temperaturas de la época postglacial, y de ahí se extendió a Europa y el resto del mundo. Desde entonces ha sufrido diversas mutaciones y manifestaciones clínicas, siendo notoria la forma clínica, «venérea», predominante en el siglo XV, probablemente acentuada por la reincorporación de cepas desde América.

La epidemiología de la primera presentación de sífilis de fines del siglo XV no define si la enfermedad era nueva o si provenía de una enfermedad anterior.

Las lesiones en esqueletos de la edad neolítica se deben a la sífilis. Incluso en esqueletos del 2000 a. C. en Rusia, con lesiones óseas patognomónicas. Aunque tales lesiones se pueden confundir con lesiones lepromatosas.
Quizá Hipócrates haya descrito los síntomas de la sífilis en su etapa terciaria.

También en las ruinas de Pompeya (que fue enterrada en el año 79 por el volcán Vesubio) se han encontrado esqueletos con signos que podrían ser de sífilis congénita.

De acuerdo con un trabajo científico de la Universidad de Bradford (Reino Unido) hecho público en junio de 1999, en un cementerio de una abadía agustiniana en el puerto de Kingston upon Hull (noreste de Inglaterra) usado entre 1119 y 1539, se encontraron 245 esqueletos, de los cuales tres tenían signos claros de sífilis. La datación con C14 indicó que el varón con las señales más evidentes de sífilis había fallecido entre 1300 y 1450.

Algunos científicos piensan que la sífilis pudo ser introducida en América tras los contactos entre vikingos.

En octubre de 2010, una excavación de esqueletos llevada a cabo en Gran Bretaña supuso un nuevo sustento para esta hipótesis, por cuanto los exámenes de los expertos indicaron que la enfermedad era conocida en este país dos siglos antes del viaje de Cristóbal Colón.

Esta hipótesis, que algunos consideran variante de la hipótesis precolombina, sostiene que todas las treponematosis corresponden a una sola enfermedad original, desarrollada muy antiguamente, quizás en el Paleolítico superior en el África subsahariana, y que desde ahí y desde entonces se extendió globalmente siendo sus variaciones consecuencia de las diferencias geográficas y climáticas. En otras palabras, la pinta, el pian, la sífilis y otras treponematosis son respuestas adaptativas del "T. pallidum" a diferencias ambientales. Hay evidencia de la existencia de treponematosis prácticamente en todos los continentes en la época precolombina. En América, las manifestaciones de la treponematosis en la época precolombina eran la sífilis venérea, en clima templado (América del Sur), y el pian, en clima tropical (Caribe). Esta hipótesis indica que el pian pudo haberse extendido desde África Occidental hacia la península ibérica en relación con el comercio de esclavos africanos negros, 50 años antes del viaje de Cristóbal Colón. El pian, endémico en África en ese momento, se manifestó en Europa de diversas formas, siendo una de ellas la sífilis venérea, es decir, de transmisión sexual.

Esta hipótesis sostiene que la sífilis era una enfermedad de transmisión sexual (ETS) del Nuevo Mundo que la tripulación de Cristóbal Colón habría llevado a Europa. Fue elaborada por Gonzalo Fernández de Oviedo y Ruy Díaz de Isla, dos médicos españoles presentes al momento del retorno de Cristóbal Colón desde América, en 1493.

Fernández de Oviedo (1478-1557), en su breve "Sumario de la Natural Historia de las Indias" (1526) dice:
Otro cronista de Indias que barajó la misma tesis fue Francisco López de Gómara (1511-1566):

Los defensores actuales dicen que está demostrado que hay esqueletos de nativos americanos precolombinos con lesiones sifilíticas y vinculan a la tripulación del primer viaje de Colón (1492) y con la epidemia de sífilis en el sitio de los alemanes contra Nápoles (1494).

El médico e historiador ecuatoriano Plutarco Naranjo critica la hipótesis colombina desarrollada por Gonzalo Fernández de Oviedo y Ruy Díaz de Isla, indicando que sus observaciones son errores históricos o fantasías, y que, por el contrario, la sífilis llegó a América desde Europa. Según este autor, no había en las expediciones personal con el conocimiento médico suficiente para identificar o reconocer las distintas enfermedades venéreas; asimismo, Fernández de Oviedo carecería de dicho conocimiento y no había reconocido enfermos ni en Europa ni en el Nuevo Mundo. Otra observación que hace Plutarco Naranjo es que el médico Diego Álvarez de Chanca, que acompañó a Cristóbal Colón y describió con lujo de detalles diversas enfermedades tanto de los marineros que los acompañaron como de los aborígenes, no hizo mención de ningún tipo de enfermedad con manifestaciones cutáneas que sugirieran el diagnóstico de sífilis. Finalmente, este autor hace notar el hecho de que la sífilis continuó expandiéndose en el Viejo Mundo mientras que en el Nuevo no se presentaron epidemias.

Otros detractores de esta hipótesis han intentado demostrar la presencia de la sífilis en Europa con anterioridad al viaje de Colón mediante la datación de esqueletos europeos con evidencias de lesiones siflíticas antes de 1492, pero los resultados no han sido concluyentes, y muchas de sus evidencias han resultado en dataciones repetidas y confirmadas con una antigüedad posterior al año 1492. Aún hay 16 huesos europeos anteriores a 1492 con lesiones que podrían ser de tipo sifilítico, evidencias que no son aceptadas por los adeptos a esta hipótesis, arguyendo que dichas dataciones se han alterado y aparecen más antiguas, debido al consumo de alimentos provenientes del océano que traen material orgánico de mayor antigüedad.

Desde Nápoles, la enfermedad barrió Europa a partir de 1495, con tasas de morbilidad y mortalidad elevadísimas.
Como lo describe Jared Diamond: «En esa época, las pústulas de la sífilis frecuentemente cubrían el cuerpo desde la cabeza a las rodillas, haciendo que se desprendiera la carne de la cara de las personas, y matando en pocos meses». Además la enfermedad era más frecuentemente fatal que hoy en día. Diamond concluye que «hacia 1546 la enfermedad habría evolucionado hasta convertirse en la sífilis con los síntomas que se conocen actualmente».

Se cree que la causa principal de esta pandemia (en Europa, gran parte de Asia y norte de África) luego del siglo XVI se debió probablemente a la rápida urbanización.

En esa época se creía que el mercurio era el remedio para la sífilis. Era común utilizarlo para tratar problemas de la piel. El tratamiento consitia en respirar el gas del mercurio caliente.

Los pacientes salivaban incontrolablemente, los dientes se les caían y perdían la razón hasta que apareció un nuevo remedio en 1517: el guayaco, un arbusto que se encuentra en Haití. Supuestamente, era lo que usaban los oriundos de la isla.

En el siglo XVIII, miles de europeos contraían la sífilis. En el siglo XIX, Flaubert, estudiando los prostíbulos de Egipto, encontró que las rameras sin excepción estaban todas infectadas con sífilis.

Las crónicas de la época le echaban la culpa de la sífilis a las enormes migraciones de ejércitos (en la época de Carlos VIII, a fines del siglo XV).

Algunos escritores sostienen que hubo simultáneamente una epidemia de gonorrea, que se suponía el mismo mal que la sífilis. Otros dicen que quizá fue una epidemia de una enfermedad concomitante, pero desconocida.

Históricamente era una enfermedad muy temida por las nodrizas o Ama de crianza de las inclusas ya que un recién nacido con sífilis congénita podía pasar desapercibido y tardar varios meses en desarrollar la enfermedad. En este caso, a través de pequeñas lesiones inadvertidas bucales o peribucales del niño podía transmitir la enfermedad a la nodriza por erosiones en el pecho en el momento de lactar. 

En 1901 el bacteriólogo alemán Paul Ehrlich sintetizó el Salvarsán, un compuesto orgánico del arsénico, concebido específicamente para el tratamiento de la sífilis y que se convirtió en uno de los primeros fármacos sintéticos eficaces para la curación de enfermedades infecciosas. El Salvarsán (y su derivado, el Neosalvarsán) se abandonaron a partir de 1944, en favor del tratamiento antibiótico con penicilina, mucho más eficaz. Para probar la penicilina, durante los años 1946 a 1948 Estados Unidos llevó a cabo experimentos sobre sífilis en ciudadanos de Guatemala sin el consentimiento ni conocimiento de los hombres y mujeres que fueron utilizados como cobayas.

En 1905 Schaudinn y Hoffmann descubrieron el agente etiológico de la enfermedad.

En 1906, August von Wassermann descubrió una reacción que lleva su nombre que diagnosticaba la enfermedad a partir de un análisis de sangre.

En 1913, Hideyo Noguchi ―un bacteriólogo japonés que trabajaba en el Instituto Rockefeller― demostró que la presencia de la espiroqueta "Treponema pallidum" (en el cerebro de un paciente con parálisis progresiva) era la causante de la sífilis.

En España se han duplicado en seis años los casos de sífilis, pasando de cuatro casos por cada 100 000 habitantes en 2006 a 7,8 en 2012.

La sífilis se contagia principalmente por contacto sexual, seguido por el contagio vía transplacentaria. Besar, recibir transfusiones sanguíneas o inocularse accidentalmente son vías de transmisión menos importantes hoy día. Estudios de parejas han establecido tasas de transmisión de entre un 18 a un 80%, mientras que estudios prospectivos dan tasas de entre un 9 a un 63%. Finalmente, la probabilidad general esperada de transmisión entre parejas es de un 60%.

Formas de contagio: Mediante el contacto de la piel con la secreción que generan los chancros, o por contacto con los clavos sifilíticos de la persona enferma; al realizar sexo oral sin preservativo (ya sea que los chancros estén en la boca, en el pene o en la vulva), o a través del beso si hay lesiones sifilíticas en la boca. Puede ser contagiada por el uso compartido de jeringas. Si la madre está infectada puede transmitirla a sus hijos a través de la placenta (sífilis congénita) o a través del canal de parto (sífilis connatal). En ambos casos, el bebé puede morir pronto o desarrollar sordera, ceguera, perturbaciones mentales, parálisis o deformidades.

Es prácticamente imposible que se transmita por una transfusión de sangre, porque la sangre se analiza antes de su transfusión, y porque el "Treponema pallidum" no sobrevive más de 48 horas en la sangre conservada en hemoteca.

La sífilis endémica puede transmitirse por contacto no sexual. Pero no se transmite por el asiento en sanitarios, actividades cotidianas, tinas de baño o compartir utensilios o ropa.

Es importante notar que el sujeto en la fase precoz de la enfermedad resulta altamente contagiante (la úlcera venérea está llena de treponemas), pero se sostiene que después de cuatro años el individuo infectado no puede difundir más el microorganismo mediante relaciones sexuales.

En las relaciones entre hombre y mujer es más fácil que se contagie el hombre. El período en el que más personas se contagian es entre los 20 y los 25 años de edad. El recontagio es muy común en varones homosexuales.

En los años ochenta y noventa en Europa hubo una relativa disminución de los casos de sífilis, relacionados con el temor al contagio por VIH, que conllevó al uso generalizado del preservativo, que representa una eficiente barrera contra el contagio, tanto del VIH como del "Treponema pállidum".

Según datos de la OMS, en el mundo existen 12 millones de nuevos casos de sífilis:


El organismo causante de la sífilis es el "Treponema pallidum" subsp "pallidum." Este microorganismo es una bacteria móvil espiroforme (con forma de hilo en espiral), perteneciente al orden "Spirochaetales," familia "Spirochaetaceae", género "Treponema". Su diámetro es de 0,10 a 0,18 micrómetros y su longitud entre 6 y 20 micrómetros. El promedio de torsiones de espiral de un T. pallidum es de 6 a 14. Su movilidad, como sacacorchos, está dado por endoflagelos, que le permiten una rápida rotación, torcerse y doblarse en ángulos.

Esta bacteria se propaga por multiplicación simple con división transversal. Al contrario que otras bacterias de su familia, solo se puede cultivar "in vitro" durante un breve período, con un máximo de supervivencia de 7 días a 35 °C, en medio particularmente enriquecido y en presencia de CO por sus particulares exigencias nutritivas y metabólicas. En nitrógeno líquido se mantiene su vitalidad, y prolifera de manera excelente en testículos de conejo.

En sangre conservada en hemoteca para transfusiones la bacteria sobrevive entre 24 y 48 horas.

"Treponema pallidum" puede sobrevivir en un hospedador humano durante varias décadas, ya que este presenta un mecanismo de resistencia a los sistemas efectores de la respuesta inmune al recubrirse de proteínas del hospedador para camuflarse hasta que alcanza el Sistema Nervioso Central.

Tras un período de incubación de entre dos y seis semanas la sífilis transcurre por cuatro etapas clínicas de límites difusos: primaria, secundaria, latente y terciaria.
Esta etapa se caracteriza por la presencia en el sitio de inoculación ―la boca, el pene, la vagina o el ano― de una úlcera indurada e indolora parecida a una herida abierta, que se denomina chancro. Se acompaña de inflamación de los ganglios regionales. En unas pocas semanas el chancro cura espontáneamente.

En el varón los chancros suelen localizarse en el pene o dentro de los testículos, aunque también en el recto, dentro de la boca o en los genitales externos, mientras que en la mujer, las áreas más frecuentes son: cuello uterino y los labios genitales mayores o menores.

Durante esta etapa es fácil contagiarse con la secreción que generan los chancros.
Una persona infectada durante esta etapa puede infectar a su pareja al tener relaciones sexuales sin protección.

La sífilis secundaria comienza entre el momento de la desaparición del chancro o hasta seis meses después. Se caracteriza por malestar general, cefalea, fiebre baja, adenopatías generalizadas, pápulas rosáceas indoloras llamadas «clavos sifilíticos» en las palmas de las manos y plantas de los pies, a veces con descamación, lesiones en la mucosa de la boca o los genitales, lesiones confluentes de aspecto verrugoso cerca del lugar donde se formó el chancro (condiloma lata) y pérdida de cabello en parches. Los clavos sifilíticos y las lesiones de las mucosas son muy contagiosos. La sífilis secundaria puede durar semanas o meses.

La sífilis latente se caracteriza por una serología positiva sin síntomas ni signos. Se divide en dos partes: sífilis latente temprana y sífilis latente tardía, dependiendo de si el tiempo de presencia de la enfermedad es menor o mayor a dos años respectivamente. Si el tiempo de la enfermedad se desconoce, se trata como una sífilis latente tardía.

En la tercera fase (llamada también fase final), entre uno y veinte años después del inicio de la infección, la sífilis se vuelve a despertar para atacar directamente al sistema nervioso o algún órgano.

En esta fase se producen los problemas más serios y puede llegar a provocar la muerte.
Algunos de los problemas son:


Aunque un tratamiento con penicilina puede matar la bacteria, el daño que haya hecho en el cuerpo podría ser irreversible.

Los bebés de las mujeres con sífilis pueden infectarse mediante la placenta o durante el parto. La mayoría de los recién nacidos con sífilis congénita no presentan síntomas, aunque en algunos casos se puede presentar una erupción cutánea en las palmas de las manos y las plantas de los pies. Entre los síntomas posteriores se incluyen sordera, deformidades en los dientes y nariz en silla de montar (cuando colapsa el puente nasal).

Antes de la aparición de las pruebas serológicas, el diagnóstico preciso era imposible.
De hecho, se la llamaba «la gran imitadora» ya que ―en la fase primaria y secundaria― sus síntomas pueden confundirse fácilmente con los de otras enfermedades, haciendo que el sujeto le reste importancia y no acuda al médico.

Antiguamente se trataba con mercurio, lo cual hizo famosa la frase «una noche con Venus y una vida con Mercurio», pero este tratamiento era más tóxico que beneficioso.

El tratamiento de elección para tratar la sífilis es la penicilina, en todas sus fases. En las fases primaria y secundaria, se usa penicilina G benzatínica en una dosis de 2,4 millones de UI por vía intramuscular por una sola vez. En las fases tardía y tardía latente se usa penicilina G benzatínica en tres dosis de 2,4 millones de UI intramuscular una vez por semana, totalizando 7,2 millones de UI.

Para la neurosífilis, el tratamiento es penicilina G cristalina administrada por vía endovenosa a razón de 18 a 24 millones de UI en una dosis administrada en una infusión continua lenta o dividida en 6 dosis diarias (a razón de una dosis cada dos o tres días). Esta última forma de administración se realiza con el fin de que el antibiótico difunda al LCR (líquido cefalorraquídeo), lugar donde se encuentra alojada principalmente la bacteria durante esta última fase. No obstante, el tratamiento no asegura una eficacia clínica.

En pacientes alérgicos a la penicilina se opta por un esquema antibiótico que no contenga betalactámicos, siendo los más usados la doxiciclina y la ceftriaxona.

Tratada a tiempo, la enfermedad tiene cura sencilla sin dejar secuelas.

El padecer la sífilis aumenta el riesgo de contraer otras enfermedades de transmisión sexual (como el VIH), ya que los chancros son una vía fácil de entrada en el organismo.

Si no se trata a tiempo, puede ocasionar:

El haber padecido sífilis y haberse curado no implica inmunidad, ya que rápidamente se puede volver a contraer. Esto se debe a que la bacteria que produce la sífilis "(Treponema pallidum)" cuenta con tan solo nueve proteínas en su cubierta, lo cual no es suficiente para que el sistema inmunitario humano la reconozca y pueda producir anticuerpos para combatirla o inmunizarse. 

El uso de condones de látex consistente y correcta para el sexo vaginal y anal puede reducir el riesgo de transmisión, pero mientras el condón puede proteger el pene o la vagina, no protege de contactos con otras áreas como el escroto o área anal. 


Durante los años 1946 a 1948 se llevaron a cabo en Guatemala experimentos sobre sífilis, dentro de un programa patrocinado y ejecutado por el gobierno de Estados Unidos. Fueron experimentos con humanos en los cuales médicos, generalmente estadounidenses, infectaron sin consentimiento de las víctimas ―a numerosos guatemaltecos, soldados, reos, pacientes psiquiátricos, prostitutas e, incluso, niños en orfandad―, inoculándoles sífilis y otras enfermedades venéreas como gonorrea, para comprobar la efectividad de nuevos fármacos, tanto antibióticos ―en especial penicilina―, como distintos tratamientos preventivos.





</doc>
<doc id="2601" url="https://es.wikipedia.org/wiki?curid=2601" title="Saccharum">
Saccharum

Saccharum es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Asia.

Se excluyen de "Saccharum" los géneros, "Erianthus, Miscanthus, Lasiorhachis, Narenga". 
Cáliz: gluma con una flor, de dos ventallas, lanceoladas, envueltas, y con un pelo en su base.
Corola: Gluma de dos ventallas, más corta y algo obtusa, con una arista dorsal torcida.
Estambre: germen oblongo: estilos dos, con plumas; con sus estigmas también plumosos.
Pistilo: germen alesnado: estilos dos, como zarcillos, con los estigmas sencillos.
Peric. ninguno: la corola, vistiendo la semilla, hace sus veces.
Semilla: una sola, oblonga, angosta y puntiaguda. 
El género fue descrito por Carlos Linneo y publicado en "Species Plantarum" 1: 54. 1753. La especie tipo es: "Saccharum officinarum" L.
El nombre del género proviene del latín "saccharum" que significa azúcar.
Tiene un número de cromosomas de: x = 10 and 12. 2n = 40, o 60, o 68, o 76–78, o 80, o 90, o 46–128, o 110, o 112, o 116–117, o 144. 4, 6, 8, 9, y 12 ploidias. Cromosomas ‘pequeños’.





</doc>
<doc id="2602" url="https://es.wikipedia.org/wiki?curid=2602" title="Schismus">
Schismus

Schismus es un género de plantas herbáceas de la familia de las poáceas. Es originario de África, Mediterráneo hasta el oeste de India.
El nombre del género deriva del griego "schisma" (hendidura), refiriéndose a la punta de la lema. 

El número cromosómico básico del género es x = 6, con números cromosómicos somáticos de 2n = 12 diploide.




</doc>
<doc id="2603" url="https://es.wikipedia.org/wiki?curid=2603" title="Secale">
Secale

Secale, es un género de plantas herbáceas de la familia de las gramíneas o poáceas. Es originario de la región del Mediterráneo, este de Europa hasta centro de Asia y Sudáfrica. 
El género tiene el nombre del latín clásico para el centeno o espelta. 



</doc>
<doc id="2604" url="https://es.wikipedia.org/wiki?curid=2604" title="Sesleria">
Sesleria

Sesleria es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Eurasia.

Algunos autores excluyen los géneros "Oreochloa, Psilathera, Sesleriella".
El género fue descrito por Giovanni Antonio Scopoli y publicado en "Flora Carniolica" 189. 1760. 



</doc>
<doc id="2605" url="https://es.wikipedia.org/wiki?curid=2605" title="Setaria">
Setaria

Setaria es un género de plantas herbáceas de la familia de las poáceas. Es originario de las regiones templadas y tropicales del globo.
Son plantas anuales. Hojas con vaina pelosa o glabra; lígula representada por una fila de pelos; limbo plano. Inflorescencia en panícula espiciforme, densa, con eje escábrido o pubescente. Pedúnculos de las espiguillas con numerosas setas rígidas, antrorsas o retrorso-escábridas, persistentes. Espiguillas cortamente pedunculadas, ovadas o elípticas, con flor inferior masculina o estéril y la superior hermafrodita. Glumas 2, desiguales, membranosas, más cortas que las flores o la superior tan larga como las flores; la inferior con (1-) 3 nervios y la superior con 5-7 nervios. Flor inferior con lema tan larga como la de la flor superior, con 5-7 nervios, membranosa; pálea membranosa. Flor superior con lema con 5 nervios poco marcados, coriácea; pálea casi tan larga como la lema y con 2 quillas, endurecida en la madurez. Cariopsis oblongoidea a elipsoidea.
El género fue descrito por Ambroise Marie François Joseph Palisot de Beauvois y publicado en "Essai d'une Nouvelle Agrostographie" 51, 178, pl. 13, f. 3. 1812. La especie tipo es: "Setaria viridis" (L.) Beauv.
El nombre del género deriva del latín "seta" (cerda), aludiendo a las inflorescencias erizadas. 

El número cromosómico básico del género es x = x = 9 y 10, con números cromosómicos somáticos de 2n = 18, 36, 54, 63, y 72, o 36-54 ya que hay especies diploides y una serie poliploide. Cromosomas relativamente «pequeños». Nucléolos persistente





</doc>
<doc id="2606" url="https://es.wikipedia.org/wiki?curid=2606" title="Sorghum bicolor">
Sorghum bicolor

El sorgo o zahína (Sorghum bicolor) es una hierba de la familia de las gramíneas (Poaceae), cuyos frutos se utilizan para hacer harina y como forraje. Es un cultivo alimenticio importante en África, América Central, y Asia Meridional y es la quinta cosecha de cereal en el mundo, en cuanto a su producción (km² 470.000 cosechado en 1996). El productor más grande es Estados Unidos. 
El sorgo se conoce con varios nombres: mijo grande y maíz de Guinea en África occidental, kafir en África austral, duro en el Sudán, mtama en África oriental, iowar en la India y kaoliang en China (Purseglove, 1972). 

El género "Sorghum" se caracteriza por presentar espiguillas que nacen de a pares. El sorgo se trata como planta anual, aunque es hierba perenne y en los trópicos puede cosecharse varias veces al año.

Tiene su origen en África del este y primero divergió de las variedades salvajes en Etiopía hace 5000 años. Se adapta bien al crecimiento en áreas áridas o semiáridas cálidas. Las muchas subespecies se dividen en cuatro grupos - sorgos del grano, sorgos forrajeros (para pastoreo y henificar), sorgos dulces (jarabes del sorgo), y sorgo de escobas (para la confección de escobas y cepillos).

Morfología

El sorgo tiene una altura de 1 a 2 metros. Tiene inflorescencias en panojas y semillas de 3 mm, esféricas y oblongas, de color negro, rojizo y amarillento. Tiene un sistema radicular que puede llegar en terrenos permeables a 2 m de profundidad. Las flores tienen estambres y pistilos, pero se han encontrado en Sudán sorgos dioicos.

El sorgo se utiliza para producir grano que sirve para la alimentación del ganado, y también para el forraje y la manufactura de escobas. 

El valor energético del grano de sorgo es un poco inferior al del maíz. Se puede estimar como media 1,08 UF/kg. Comparándolo con el grano de maíz, el de sorgo es generalmente un poco más rico en proteínas, pero más pobre en materia grasa; como las de maíz, son de un valor biológico bastante débil; son particularmente deficitarias en lisina. 

Exigencias del cultivo 

Las exigencias en calor del sorgo para grano son más elevadas que las de maíz. Para germinar necesita una temperatura de 12 a 13 °C, por lo que su siembra ha de hacerse de 3 a 4 semanas después del maíz. El crecimiento de la planta no es verdaderamente activo hasta que se sobrepasan los 15 °C, situándose el óptimo hacia los 32 °C. 
Al principio de su desarrollo, el sorgo soporta las bajas temperaturas de forma parecida al maíz, y su sensibilidad en el otoño es también comparable. Los descensos de temperatura en el momento de la floración pueden reducir el rendimiento del grano. Por el contrario, el sorgo resiste mucho mejor que el maíz las altas temperaturas. Si el suelo es suficientemente fresco no se comprueba corrimiento de flores con los fuertes calores. 

El sorgo resiste la sequía más que el maíz. Es capaz de sufrir sequía durante un periodo de tiempo bastante largo, y reemprender su crecimiento más adelante cuando cesa la sequía. Por otra parte, necesita menos cantidad de agua que el maíz para formar un kilogramo de materia seca.
Se desarrolla bien en terrenos alcalinos, sobre todo las variedades azucaradas que exigen la presencia en el suelo de carbonato cálcico, lo que aumenta el contenido en sacarosa de tallos y hojas. Prefiere suelos sanos, profundos, no demasiado pesados. Soporta algo la sal.

La planta es el alimento de las larvas del lepidóptero "Charaxes jasius".

"Sorghum bicolor" fue descrita por (L.) Moench y publicado en "" 207. 1794.





</doc>
<doc id="2607" url="https://es.wikipedia.org/wiki?curid=2607" title="Spartina">
Spartina

Spartina, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de las regiones templadas de América, Europa y África.
Son plantas perennes, rizomatosas. Espiguillas marcadamente comprimidas lateralmente, dispuestas en 2 filas apretadas a lo largo del raquis. Espiguillas con 1 (-2) flores hermafroditas. Glumas 2, aproximadamente casi tan largas como las flores, desiguales, subcoriáceas; la inferior uninervada; la superior con 1-3 nervios. Lema uninervada, coriácea. Pálea aproximadamente tan larga como la lema, de margen más o menos ampliamente escarioso. Cariopsis comprimida, glabra.
El género fue descrito por Johann Christian Daniel von Schreber y publicado en "Flora italiana, ossia descrizione delle piante" ... 1: 366. 1848. La especie tipo es: "Spartina cynosuroides"
El nombre del género deriva de las palabras griegas "spartine" (una cuerda hecha de esparto, "Spartium junceum"), refiriéndose a las hojas fibrosas. 
Tiene un número de cromosomas de: x = 7 and 10. 2n = 28, 40, 42, 60, 62, 84, 120, 122, y 124. 3, 4, 6, 8, y 12 ploidias. 



</doc>
<doc id="2608" url="https://es.wikipedia.org/wiki?curid=2608" title="Sphenopus">
Sphenopus

Sphenopus es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de la región del Mediterráneo hasta el oeste de Asia.
Son planta anuales. Hojas con vainas de márgenes libres; lígula membranosa; limbo plano o convoluto y filiforme. Inflorescencia en panícula muy laxa, con ramas patentes, divaricadas. Espiguillas comprimidas lateralmente, con 2-5 flores hermafroditas, o a veces la superior estéril; raquilla glabra o ligeramente escábrida, desarticulándose en la madurez. Glumas 2, muy desiguales, membranosas, más cortas que las flores; la inferior poco conspicua, sin nervios; la superior con 1-3 nervios, rara vez sin nervios. Lema más o menos membranosa, trinervada. Pálea membranosa, con 2 quillas. Androceo con 3 estambres. Ovario glabro. Cariopsis oblongoidea, glabra.
El género fue descrito por Carl Bernhard von Trinius y publicado en "Fundamenta Agrostographiae" 135. 1820. La especie tipo es: "Sphenopus gouanii" Trin. 
El nombre del género deriva de las palabras griegas "sphen" (cuña) y "pous" (pie), en referencia a los pedicelos distales engrosados.
Tiene un número de cromosomas de: x = 6 y 7. 2n = 12 y 24. 2 y 4 ploidias. Cromosomas ‘grandes’.



</doc>
<doc id="2609" url="https://es.wikipedia.org/wiki?curid=2609" title="Sporobolus">
Sporobolus

Sporobolus, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de las regiones templadas y tropicales del globo.
Son plantas perennes, rizomatosas. Tallos glabros. Hojas glaucas, con limbo plano o convoluto, rígido, surcado en el haz y ligeramente estriado en el envés. Inflorescencia en panícula laxa. Espiguillas comprimidas lateralmente, cortamente pedunculadas, con 1 sola flor hermafrodita articulada con la raquilla. Glumas desiguales, uninervadas. Raquilla no prolongada por encima de la flor. Lema escariosa, uninervada. Pálea igualando a la lema, binervada, biaquillada en la base. Periantio con 2 lodículas obtusas y casi enteras. Androceo con 3 estambres.
El género fue descrito por Robert Brown y publicado en "Prodromus Florae Novae Hollandiae" 169. 1810. La especie tipo es: "Sporobolus indicus" (L) R. Br.
El nombre del género deriva del griego "spora" (semillas) y "ballein" (tirar), aludiendo a la semilla cuando se libera y (probablemente) por la manera, a veces por la fuerza, de su lanzamiento.
El número cromosómico básico del género es x = 9 y 10, con números cromosómicos somáticos de 2n = 18, 24, 36, 38, 54, 72, 80, 88, 90, 108, y 126, ya que hay especies diploides y una serie poliploide. Nucléolos persistentes. Cromosomas relativamente "pequeños".





</doc>
<doc id="2610" url="https://es.wikipedia.org/wiki?curid=2610" title="Stenotaphrum">
Stenotaphrum

Stenotaphrum es un género de plantas herbáceas de la familia de las gramíneas o poáceas. Es originario de las regiones tropicales y subtropicales del globo. Comprende 13 especies descritas y de estas, solo 7 aceptadas.

El género fue descrito por Carl Bernhard von Trinius y publicado en "Fundamenta Agrostographiae" 175. 1820[1822]. La especie tipo es: "Stenotaphrum glabrum" Trin.
El nombre del género deriva de las palabras griegas "stenos" (estrecha) y "taphros" (trinchera, hueco), aludiendo a las cavidades de los raquis.
Tiene los números cromosómicos somáticos de 2n = 18, 20, y 36. 2 y 4 ploides.




</doc>
<doc id="2611" url="https://es.wikipedia.org/wiki?curid=2611" title="Stipa">
Stipa

Stipa es un género de gramíneas (Poaceae), perennes y cespitosas, que comprende aproximadamente 250 especies distribuidas por todo el globo.
En las regiones esteparias de América, el género "Stipa" es con frecuencia dominante. Forma la Pampa seca, las antiguas Grandes Praderas de Norteamérica, las sabanas de África y Sudamérica y las estepas euroasiáticas, mediterráneas y africanas. Sus especies tienen a veces valor forrajero, o bien son perjudiciales debido a las perforaciones que sus frutos producen en los cueros de los animales. Una especie del sur de Europa y norte de África, "Stipa tenacissima" , es el "esparto" utilizado en la fabricación de papel y cordelería.

Muchas especies están adaptadas a suelos áridos, semidesiertos y estepas, a las que les dan nombre, caracterizan y se emplean para evitar la erosión de los suelos y la desertización.
En zonas apropiadas forman praderas densas solas o en compañía de otros grupos. Aunque en agricultura suelen ser consideradas malezas, algunas especies se emplean por la resistencia de sus fibras para realizar cuerdas, cestos y otras urdimbres. Por su gran capacidad de regeneración y su resistencia a desaparecer son un alimento importante para muchos herbívoros y caracterizan muchas praderas salvajes en zonas secas de todo el planeta. Aunque hay excepciones, conforme las zonas son más frescas y húmedas, se desarrolla otro tipo de vegetación que sustituyen poco a poco a las especies del género stipa.

"Stipa" incluye pastos perennes, cespitosos, de unos 30 cm pero en ocasiones de hasta dos metros y medio, frecuentemente con hojas de lámina convoluta. Las espiguillas se hallan dispuestas en panojas generalmente laxas. Todas las Stipa se reconocen por tener unas aristas muy largas, que cuando son maduras en algunos se enrollan entre ellas quedando completamente enmarañadas.

Las espiguillas son unifloras, articuladas por encima de las glumas, con articulación oblicua que deja un callus puntiagudo e hirsuto unido al flósculo. Las glumas son membranosas, frecuentemente hialinas, agudas o acuminadas en el ápice, iguales o ligeramente desiguales. La lema es estrecha, notablemente convoluta, obovoidea, fusiforme o lineal, endurecida a la madurez y persistente sobre el cariopse, terminada superiormente en una arista generalmente persistente, enroscada y geniculada (doblada) una o dos veces. La pálea es plana, lanceolada, no carenada, frecuentemente reducida, rodeada por la lema. El androceo está compuesto por 3 estambres, las anteras son amarillas o violáceas, frecuentemente con un mechoncito de pelos en el ápice. El cariopse es fusiforme u obovado, con hilo linear.

El género fue descrito por Carlos Linneo y publicado en "Species Plantarum" 1: 78–79. 1753. La especie tipo es: "Stipa pennata" L.
Stipa: nombre genérico que deriva del griego "stupe" (estopa) o "stuppeion" (fibra), aludiendo a las aristas plumosas de las especies euroasiáticas, o (más probablemente) a la fibra obtenida de pastos de esparto.
Tiene un número de cromosomas de: x = 9, 10, 11, 12, y 22. 2n = 22, 28, 40, 44, 48, 68, y 96. 2, 4, y 8 ploidias.

"Stipa tenacissima", "Stipa gigantea", "Stipa parviflora", "Stipa barbata", "Stipa lagascae", "Stipa pennata", "Stipa offneri", "Stipa caudata"...

"Stipa papposa" recibe en Argentina el nombre común de aibé.




</doc>
<doc id="2612" url="https://es.wikipedia.org/wiki?curid=2612" title="Smalltalk">
Smalltalk

Smalltalk es un lenguaje reflexivo de programación, orientado a objetos y con tipado dinámico. Por sus características, Smalltalk puede ser considerado también como un entorno de objetos, donde incluso el propio sistema es un objeto. Metafóricamente, se puede considerar que un Smalltalk es un mundo virtual donde viven objetos que se comunican entre sí, mediante el envío de mensajes.

Un sistema Smalltalk está compuesto por:


Smalltalk obtuvo el segundo lugar para "lenguaje de programación más querido" en las encuestas para desarrolladores de Stack Overflow en 2017.

Los orígenes de Smalltalk se encuentran en las investigaciones realizadas por Alan Kay, Dan Ingalls, Ted Kaehler, Adele Goldberg y otros durante los años setenta en el Palo Alto Research Center de Xerox (conocido como "Xerox PARC"), para la creación de un sistema informático orientado a la educación. El objetivo era crear un sistema que permitiese expandir la creatividad de sus usuarios, proporcionando un entorno para la experimentación, creación e investigación.

Un programa Smalltalk consiste únicamente de objetos, un concepto que se utiliza universalmente dentro de todo sistema Smalltalk. Prácticamente todo, desde un número natural como el 4 hasta un servidor web es un objeto. Los objetos Smalltalk presentan características comunes:


Los objetos se comunican entre sí mediante el envío de mensajes. Asimismo, un objeto puede proveer muchas operaciones (actualmente esto está determinado por cada implementación).

Las definiciones de estas operaciones en los objetos son llamadas métodos. Un método especifica la reacción de un objeto cuando recibe un mensaje que es dirigido a ese método. La resolución, en el sentido de ligado, de un mensaje a un método es dinámica. La colección entera de métodos de un objeto es llamada protocolo de mensajes o interfaz de mensajes del objeto. Los mensajes pueden ser parametrizados, estos parámetros serán objetos, y el resultado o respuesta del mismo también será un objeto.

Las características comunes de objetos está capturado bajo la noción de clase, de tal forma que los objetos agrupados bajo una clase son llamados instancias de ella. Las instancias son creadas durante la ejecución de un programa con algún propósito y son barridos automáticamente en el momento que no son necesitados más por el recolector de basura. Exceptuando algunos objetos especiales como los muy simples, llamados literales (números, cadenas, etc), cada objeto tiene su propio estado local y representa una instancia diferente de su clase.

Smalltalk es considerado el primero de los lenguajes orientados a objetos, aunque en realidad el primero en implementar programación orientada a objetos fue Simula. En Smalltalk "todo" es un objeto, incluidos los números reales o el propio entorno Smalltalk.

Como lenguaje tiene las siguientes características:


Smalltalk ha tenido gran influencia sobre otros lenguajes como Java o Ruby, y de su entorno han surgido muchas de las prácticas y herramientas de desarrollo promulgadas actualmente por las metodologías ágiles (refactorización, desarrollo incremental, desarrollo dirigido por tests, etc.).

Las implementaciones de Smalltalk de mayor peso (VisualWorks, Squeak, VisualSmalltalk, VisualAge, Dolphin, Pharo Smalltalk, Smalltalk X) poseen un entorno de interacción muy diferente al entorno de desarrollo típico de otras tecnologías como Microsoft Visual Studio .Net o Eclipse. El entorno o ambiente Smalltalk es primordialmente gráfico y funciona como un sistema en tiempo de ejecución que integra varias herramientas de programación (Smalltalk), utilidades multimedia, interfaces para ejecutar código no nativo a Smalltalk y servicios del sistema operativo.Estas posibilidades, que han influido en la metodología de trabajo y concepción de la programación, se traducen en la tendencia a considerar a Smalltalk más que un simple lenguaje de programación.
La forma de desarrollar software en Smalltalk no consiste en el ciclo típico de las tecnologías tradicionales: Arrancar un editor de texto, compilar y ejecutar y terminar la aplicación. En Smalltalk se manipula el entorno mismo, comúnmente mediante el Navegador del Sistema.

Tradicionalmente, Smalltalk no posee una notación explícita para describir un programa entero. Sí se utiliza una sintaxis explícita para definir ciertos elementos de un programa, tales como métodos, pero la manera en que tales elementos están estructurados dentro de un programa entero generalmente es definida por las múltiples implementaciones. El estándar mismo no promueve otra dirección, por lo que define una sintaxis abstracta de programas Smalltalk, que define todos los elementos que constituyen un programa Smalltalk y la manera en que esos elementos están lógicamente compuestos por otros elementos, sin embargo, cada implementación es libre de definir y utilizar las muchas sintaxis posibles que están conformes a la sintaxis abstracta estándar. Un ejemplo de una sintaxis concreta es el Formato de Intercambio Smalltalk (o SIF, de Smalltalk Interchange Format) definida en el mismo estándar.

La sintaxis de Smalltalk-80 tiende a ser minimalista. Esto significa que existen un grupo pequeño de palabras reservadas y declaraciones en comparación con la mayoría de los lenguajes populares. Smalltalk posee un grupo de 6 palabras reservadas: self, super, nil, true , false y thisContext.

En Smalltalk no es necesario desalocar objetos explícitamente, por lo tanto no proporciona mecanismos para ello. Las implementaciones utilizan técnicas de recolección de basura para detectar y reclamar espacio en memoria asociado con objetos que ya no se utilizarán más en el sistema. En Smalltalk la recolección de basura es integrada configurable. La forma de ejecución del recolector de basura es en "background", es decir, como un proceso de baja prioridad no interactivo, aunque en algunas implementaciones es posible ejecutarlo a demanda, siendo posible definir configuraciones de memoria especiales para cada sistema mediante políticas (por ejemplo en VisualWorks). La frecuencia y características de la recolección depende de la técnica utilizada por la implementación. Adicionalmente algunas implementaciones de Smalltalk proporcionan soporte para mecanismos de finalización como el uso de Ephemerons.

Smalltalk-80 provee reflexión computacional y estructural, ya que es un sistema implementado en sí mismo. La reflexión estructural se manifiesta en que las clases y métodos que define el sistema son en sí mismos objetos también y forman parte del sistema mismo.
La mayoría de las implementaciones de Smalltalk tienden a exponer el compilador Smalltalk al entorno de programación, permitiendo que dentro del sistema se compile código fuente (textual), transformándose en objetos métodos, que son comúnmente instancias de la clase "CompiledMethod". El sistema generalmente incorpora estos métodos en las clases, almacenándolos en el diccionario de métodos de la clase a la cual se quiera agregar el comportamiento que realiza el método. Esto, así como la incorporación de nuevas clases al sistema, es realizado dentro del sistema mismo; aunque la mayor parte de las implementaciones poseen herramientas visuales que ocultan la complejidad de interactuar con la clase que usualmente se encarga de tales tareas, el "ClassBuilder".

La reflexión computacional de Smalltalk-80 se manifiesta en la posibilidad de observar el estado computacional del sistema. En los lenguajes derivados del Smalltalk-80 original, durante el envío de mensajes entre objetos, cada objeto receptor de un mensaje consulta su clase para tener acceso a los métodos que define. En caso de encontrarse el método en la clase, se dice que se "activa" el método. Esta activación de un método actualmente en ejecución, es accesible mediante una palabra clave llamada thisContext. Enviando mensajes a thisContext se puede consultar cuestiones tales como "¿quién me envió este mensaje?". Estas facilidades hacen posible implementar corrutinas, continuaciones o back-tracking al estilo Prolog sin necesidad de modificar la máquina virtual. Uno de los usos más interesantes de esta facilidad, se da en el framework de web Seaside de Avi Bryant.

En Smalltalk todo es un objeto, y a un objeto se le envían mensajes. Por ejemplo:

1 + 1

Significa que al objeto "1" le enviamos el mensaje "+" con el colaborador externo, otro objeto, "1". Este ejemplo entonces resulta en el objeto "2".
Transcript show: '¡Hola, mundo!'
En el típico Hola mundo, el objeto es Transcript, que recibe el mensaje show con el colaborador externo '¡Hola, Mundo!'.

Para crear una instancia de un objeto, sólo hay que mandar un mensaje new a una clase:

ClaseDelObjeto new

Para obtener las vocales de una cadena de texto:

'Esto es un texto' select: [:aCharacter | aCharacter isVowel].



</doc>
<doc id="2613" url="https://es.wikipedia.org/wiki?curid=2613" title="Sistema hexadecimal">
Sistema hexadecimal

El sistema hexadecimal (abreviado como 'Hex', no confundir con "sistema sexagesimal") es el sistema de numeración posicional que tiene como base el 16. Su uso actual está muy vinculado a la informática y ciencias de la computación donde las operaciones de la CPU suelen usar el byte u octeto como unidad básica de memoria, debido a que un byte representa formula_1 valores posibles, y esto puede representarse como
formula_2
formula_3,
que equivale al número en base 16 formula_4, dos dígitos hexadecimales corresponden exactamente a un byte.

En principio, dado que el sistema usual de numeración es de base decimal y, por ello, solo se dispone de diez dígitos, se adoptó la convención de usar las seis primeras letras del alfabeto latino para suplir los dígitos que nos faltan. El conjunto de símbolos es el siguiente:

Se debe notar que las letras corresponden a los siguientes valores numéricos decimales:
En ocasiones se emplean letras minúsculas en lugar de mayúsculas. Como en cualquier sistema de numeración posicional, el valor numérico de cada dígito es alterado dependiendo de su posición en la cadena de dígitos, quedando multiplicado por una cierta potencia de la base del sistema, que en este caso es 16. Por ejemplo: 3E0A = 3×16 + E×16 + 0×16 + A×16 = 3×4096 + 14×256 + 0×16 + 10×1 = 15882.

El sistema hexadecimal actual fue introducido en el ámbito de la computación por primera vez por IBM en 1963. Una representación anterior, con 0-9 y u-z, fue usada en 1956 por la computadora Bendix G-15.

Como el único factor primo de 16 es 2, todas las fracciones que no tengan una potencia de 2 en el denominador tendrán un desarrollo hexadecimal periódico.

Existe un sistema para convertir números fraccionarios a hexadecimal de una forma más mecánica. Se trata de convertir la parte entera con el procedimiento habitual y convertir la parte decimal aplicando sucesivas multiplicaciones por 16 hasta convertir el resultado en un número entero. 

Por ejemplo: 0,06640625 en base decimal.

Multiplicado por 16: 1,0625, el primer decimal será 1. Volvemos a multiplicar por 16 la parte decimal del anterior resultado: 1. Por lo tanto el siguiente decimal será un 1.Resultado: 0,11 en base hexadecimal. Como el último resultado se trata de un entero, hemos acabado la conversión.

Hay ocasiones en las que no llegamos nunca a obtener un número entero, en ese caso tendremos un desarrollo hexadecimal periódico.

En el sistema hexadecimal, al igual que en el sistema decimal, binario y octal, se pueden hacer diversas operaciones matemáticas. Entre ellas se encuentra la resta entre dos números en sistema hexadecimal, la que se puede hacer con el método de complemento a 15 o también utilizando el complemento a 16. Además de éstas, debemos manejar adecuadamente la suma en sistema hexadecimal, explicada a continuación: 


"En este caso la respuesta obtenida, 16, no está entre el 0 y el 15, por lo que tenemos que restarle 16. Por lo tanto, la respuesta obtenida será 10 (sistema hexadecimal)".

"Hay que tener cuidado de utilizar correctamente las letras, ya que operar a la vez con letras y números puede crear confusiones".
"Ocurre lo mismo que en el ejemplo anterior".

"La respuesta es 20 y no está entre el 0 y el 15, por lo que tenemos que restarle 16. Por lo tanto, la respuesta obtenida será 
14 (sistema hexadecimal)".

"Hay que tener cuidado de utilizar correctamente las letras, ya que operar a la vez con letras y números puede crear confusiones".

"La respuesta es 29 y no está entre el 0 y el 15, por lo que tenemos que restarle 16. Por lo tanto, la respuesta obtenida será 1D (sistema hexadecimal)".

"Hay que tener cuidado de utilizar correctamente las letras, ya que operar a la vez con letras y números puede crear confusiones".



Ten en cuenta que puedes comprobar los resultados utilizando calculadora científica

Como podemos hacer la resta de dos números hexadecimales utilizando el complemento a 15. Para ello tendremos que sumar al minuendo el complemento a quince del sustraendo, y finalmente sumarle el bit de overflow (bit que se desborda).

Para entender la resta en complemento a 15 lo analizaremos con un ejemplo.
Esta es la resta que tenemos que resolver: 

Primero tenemos que hacer que el minuendo y el sustraendo tengan la misma cantidad de números. 
Para ello, añadiremos ceros al sustraendo hasta que sean suficientes.
Después, crearemos un nuevo número con la misma cantidad de números que el nuevo sustraendo. 
Como en el sistema hexadecimal el mayor número que tenemos es el 15, que corresponde a la letra F, tendremos que escribir la F tantas veces como números tiene el sustraendo.
La resta se hace siguiendo las normas generales de la resta común. La diferencia obtenida se denomina el complemento a 15. Recuerda el valor correspondiente a cada letra al operar.

Ahora tendremos que sumar el minuendo y el complemento a 15 utilizando la suma en sistema hexadecimal, mencionada anteriormente.

Con la suma obtenemos el resultado 1A41E0, pero no es la respuesta final. 
Te habrás dado cuenta que este nuevo número tiene más cifras que los números iniciales que teníamos que restar. Tenemos que quitar el número de la izquierda (en este caso, el 1) y sumarlo.

La respuesta es A41E1.

Ten en cuenta que puedes comprobar los resultados utilizando una calculadora científica.

También podemos hacer la resta de dos números hexadecimales utilizando el complemento a 16, siguiendo un proceso similar que en el caso del complemento a 15. Para resolver la resta, tendremos que sumar al minuendo el complemento a dieciséis del sustraendo.

Para entender la resta en complemento a 16 lo analizaremos con el ejemplo anterior. Esta es la resta que tenemos que resolver: 
Primero tenemos que hacer que el minuendo y el sustraendo tengan la misma cantidad de números, al igual que ocurre en el proceso del complemento a 15. 

Para ello, añadiremos ceros al sustraendo hasta que sean suficientes.
Después, crearemos un nuevo número con la misma cantidad de números que el nuevo sustraendo. 

Como en el sistema hexadecimal el mayor número que tenemos es el 15, que corresponde a la letra F, tendremos que escribir la F tantas veces como números tiene el sustraendo.
La resta se hace siguiendo las normas generales de la resta común.

Ahora tenemos que sumarle 1 a la diferencia obtenida. Este paso es muy importante, ya que es la diferencia entre hacer la resta en complemento a 15 ó 16, y se suele olvidar fácilmente. Además, recuerda que estás sumando en sistema hexadecimal, siguiendo el mismo proceso explicado anteriormente.

A la diferencia obtenida y sumarle uno le denominaremos el complemento a 16.

Ahora tendremos que sumar el minuendo y el complemento a 16

Con la suma obtenemos el resultado 1A41E1. 

Te habrás dado cuenta que este nuevo número tiene más cifras que los números iniciales que teníamos que restas, cosa imposible en una resta (que la diferencia sea mayor que el minuendo y el sustraendo). Por eso, y estando en complemento a 16, tendremos que despreciar (eliminar) el número de la izquierda. En este caso es el 1. 

La respuesta, por lo tanto, es A41E1.

En ambos casos la respuesta obtenida deberá ser la misma, ya que hemos resuelto la misma resta en sistema hexadecimal. Por lo tanto, podremos comprobar que hemos operado bien comparando las respuestas obtenidas en complemento a 15 y en complemento a 16 para una misma resta.

Además, ten en cuenta que puedes comprobar los resultados utilizando una calculadora científica.




</doc>
<doc id="2614" url="https://es.wikipedia.org/wiki?curid=2614" title="Sistema binario">
Sistema binario

El sistema binario, llamado también sistema diádico en ciencias de la computación, es un sistema de numeración en el que los números se representan utilizando solamente dos cifras: cero (0) y uno ("1"). Es uno de los sistemas que se utilizan en las computadoras, debido a que estas trabajan internamente con dos niveles de voltaje, por lo cual su sistema de numeración natural es el sistema binario.

El antiguo matemático hindú Pingala presentó la primera descripción que se conoce de un sistema de numeración binario en el siglo tercero antes de nuestra era, lo cual coincidió con su descubrimiento del concepto del número cero. 

En la antigua China, en el texto clásico del I Ching, se describe una serie completa de 8 trigramas y 64 hexagramas (análogos a 3 bits) y números binarios de 6 bits. También han sido utilizadas series similares de combinaciones binarias en sistemas de adivinación tradicionales africanos, como el Ifá, así como en la geomancia medieval occidental.

El erudito y filósofo Chino Shao Yong en el siglo XI desarrolló un arreglo binario ordenado de los hexagramas del I Ching, representando la secuencia decimal de 0 a 63, y un método para generar el mismo.

En 1605 Francis Bacon habló de un sistema por el cual las letras del alfabeto podrían reducirse a secuencias de dígitos binarios, las cuales podrían ser codificadas como variaciones apenas visibles en la fuente de cualquier texto arbitrario.

En 1670 Juan Caramuel publica su libro "Mathesis Biceps;" y en las páginas XLV a XLVIII da una descripción del sistema binario.
El sistema binario moderno fue documentado en su totalidad por Leibniz, en el siglo XVII, en su artículo ""Explication de l'Arithmétique Binaire"". En él se mencionan los símbolos binarios usados por matemáticos chinos. Leibniz utilizó el 0 y el 1, al igual que el sistema de numeración binario actual.

En 1854, el matemático británico George Boole publicó un artículo que marcó un antes y un después, detallando un sistema de lógica que terminaría denominándose Álgebra de Boole. Dicho sistema desempeñaría un papel fundamental en el desarrollo del sistema binario actual, particularmente en el desarrollo de circuitos electrónicos.

En 1937, Claude Shannon realizó su tesis doctoral en el MIT, en la cual implantaba el Álgebra de Boole y la aritmética binaria utilizando relés y conmutadores por primera vez en la historia. Titulada "Un Análisis Simbólico de Circuitos Conmutadores y Relés", la tesis de Shannon básicamente fundó el diseño práctico de circuitos digitales.

En noviembre de 1937, George Stibitz, trabajando por aquel entonces en los Laboratorios Bell, construyó una calculadora basada en relés —a la cual apodó "Modelo K" (porque la construyó en una cocina, en inglés ""k"itchen")— que utilizaba la suma binaria para realizar los cálculos. Los Laboratorios Bell autorizaron un completo programa de investigación a finales de 1938, con Stibitz al mando.

El 8 de enero de 1940 terminaron el diseño de una "Calculadora de Números Complejos", la cual era capaz de realizar cálculos con números complejos. En una demostración en la conferencia de la Sociedad Estadounidense de Matemática, el 11 de septiembre de 1940, Stibitz logró enviar comandos de manera remota a la Calculadora de Números Complejos a través de la línea telefónica mediante un teletipo. Fue la primera máquina computadora utilizada de manera remota a través de la línea de teléfono. Algunos participantes de la conferencia que presenciaron la demostración fueron John von Neumann, John Mauchly y Norbert Wiener, quien escribió acerca de dicho suceso en sus diferentes tipos de memorias en la cual alcanzó diferentes logros.

En el sistema binario solo se necesitan dos cifras.

En informática, un número binario puede ser representado por cualquier secuencia de bits (dígitos binarios), que suelen representar cualquier mecanismo capaz de usar dos estados mutuamente excluyentes. Las siguientes secuencias de símbolos podrían ser interpretadas como el mismo valor numérico binario:

El valor numérico representado en cada caso depende del valor asignado a cada símbolo. En una computadora, los valores numéricos pueden representar dos voltajes diferentes; también pueden indicar polaridades magnéticas sobre un disco magnético. Un "positivo", "sí", o "sobre el estado" no es necesariamente el equivalente al valor numérico de uno; esto depende de la nomenclatura usada.

De acuerdo con la representación más habitual, que es usando números arábigos, los números binarios comúnmente son escritos usando los símbolos 0 y 1. Los números binarios se escriben a menudo con subíndices, prefijos o sufijos para indicar su base. Las notaciones siguientes son equivalentes:


Se divide el número del sistema decimal entre 2, cuyo resultado entero se vuelve a dividir entre 2, y así sucesivamente hasta que el dividendo sea menor que el divisor, 2. Es decir, cuando el número a dividir sea 1 finaliza la división.
A continuación se ordena desde el último cociente hasta el primer resto, simplemente se colocan en orden inverso a como aparecen en la división. Este será el número binario que buscamos. 


-> Ordenamos los residuos, del último al primero: 10000011
En sistema binario, 131 se escribe 10000011.

Otra forma de conversión consiste en un método parecido a la factorización en números primos. Es relativamente fácil dividir cualquier número entre 2. Este método consiste también en divisiones sucesivas. Dependiendo de si el número es par o impar, colocaremos un cero o un uno en la columna de la derecha. Si es impar, le restaremos uno y seguiremos dividiendo entre dos, hasta que ya no sea posible y se coloca el número 1. Después solo nos queda tomar el último resultado de la columna izquierda y todos los de la columna de la derecha y ordenar los dígitos de abajo a arriba.


Ejemplo

Para convertir al sistema binario el número decimal 77 haremos una serie de divisiones que arrojarán los siguientes resultados:
Existe un último método denominado de distribución. Consiste en distribuir los unos necesarios entre las potencias sucesivas de 2 de modo que su suma resulte ser el número decimal a convertir. Sea por ejemplo el número 151, para el que se necesitarán las 8 primeras potencias de 2, ya que la siguiente, 2=256, es superior al número a convertir. Se comienza poniendo un 1 en 128, por lo que aún faltarán 23, 151-128 = 23, para llegar al 151. Este valor se conseguirá distribuyendo unos entre las potencias cuya suma dé el resultado buscado y poniendo ceros en el resto. En el ejemplo resultan ser las potencias 4, 2, 1 y 0, esto es, 16, 4, 2 y 1, respectivamente.

 2= 1|1

Para transformar un número del sistema decimal al sistema binario:
 0,3125 (decimal) => 0,0101 (binario).

 0,1 (decimal) => 0,0 0011 0011 ... (binario). 

 Convertir 0.2 (decimal) a binario. 
 5.5 = 5,5

 6,83 (decimal) => 110,110101000111 (binario).

Para realizar la conversión de binario a decimal, realice lo siguiente:

Ejemplos:

formula_3

formula_4

formula_5

También se puede optar por utilizar los valores que presenta cada posición del número binario a ser transformado, comenzando de derecha a izquierda, y sumando los valores de las posiciones que tienen un 1.

El número binario 1010010 corresponde en decimal al 82. Se puede representar de la siguiente manera:

formula_6

entonces se suman los números 64, 16 y 2:
formula_7

Para cambiar de binario con decimales a decimal se hace exactamente igual, salvo que la posición cero (en la que el dos es elevado a la cero) es la que está a la izquierda de la coma y se cuenta hacia la derecha a partir de -1:

formula_8

1. Inicie por el lado izquierdo (la primera cifra a la derecha de la coma), cada número deberá ser multiplicado por 2 elevado a la potencia consecutiva a la inversa (comenzando por la potencia -1, 2).

2. Después de realizar cada una de las multiplicaciones, sume todas y el número resultante será el equivalente al sistema decimal.


 1 * 2 elevado a -1 = 0,5

 1 * 2 elevado a -1 = 0,5

La tabla de sumar para números binarios es la siguiente:

Las posibles combinaciones al sumar dos bits son:


Note que al sumar 1 + 1 es 10, es decir, llevamos 1 a la siguiente posición de la izquierda (acarreo). Esto es equivalente en el sistema decimal a sumar 9 + 1, que da 10: cero en la posición que estamos sumando y un 1 de acarreo a la siguiente posición.

 1

Se puede convertir la operación binaria en una operación decimal, resolver la decimal, y después transformar el resultado en un (número) binario. Operamos como en el sistema decimal: comenzamos a sumar desde la derecha, en nuestro ejemplo, 1 + 1 = 10, entonces escribimos 0 en la fila del resultado y "llevamos" 1 (este "1" se llama "acarreo" o "arrastre"). A continuación se suma el acarreo a la siguiente columna: 1 + 0 + 0 = 1, y seguimos hasta terminar todas las columnas (exactamente como en decimal).

El algoritmo de la resta en sistema binario es el mismo que en el sistema decimal. Pero conviene repasar la operación de restar en decimal para comprender la operación binaria, que es más sencilla. Los términos que intervienen en la resta se llaman minuendo, sustraendo y diferencia.

Las restas básicas 0 - 0, 1 - 0 y 1 - 1 son evidentes:


La resta 0 - 1 se resuelve igual que en el sistema decimal, tomando una unidad prestada de la posición siguiente: 0 - 1 = 1 y "me llevo" 1 (este valor se resta al resultado que obtenga, entre el minuendo y el sustraendo de la siguiente columna), lo que equivale a decir en el sistema decimal, 2 - 1 = 1. 


En sistema decimal sería: 17 - 10 = 7 y 217 - 171 = 46.

Para simplificar las restas y reducir la posibilidad de cometer errores hay varios métodos:




La siguiente resta, 91 - 46 = 45, en binario es:

En el resultado nos sobra un bit, que se desborda por la izquierda. Pero, como el número resultante no puede ser más largo que el minuendo, el bit sobrante se desprecia.

Un último ejemplo: vamos a restar 219 - 23 = 196, directamente y utilizando el complemento a dos:

Y, despreciando el bit que se desborda por la izquierda, llegamos al resultado correcto: 11000100 en binario, 196 en decimal.


La tabla de multiplicar para números binarios es la siguiente:

El algoritmo del producto en binario es igual que en números decimales; aunque se lleva a cabo con más sencillez, ya que el 0 multiplicado por cualquier número da 0, y el 1 es el elemento neutro del producto.

Por ejemplo, multipliquemos 10110 por 1001:

En sistemas electrónicos, donde suelen usarse números mayores, se utiliza el método llamado algoritmo de Booth.

La división en binario es similar a la decimal; la única diferencia es que a la hora de hacer las restas, dentro de la división, estas deben ser realizadas en binario.


Dividir 100010010 (274) entre 1101 (13):

Debido a que el sistema octal tiene como base 8, que es la tercera potencia de 2, y que dos es la base del sistema binario, es posible establecer un método directo para convertir de la base dos a la base ocho, sin tener que convertir de binario a decimal y luego de decimal a octal. Este método se describe a continuación: 

Para realizar la conversión de binario a octal, realice lo siguiente:

1) Agrupe la cantidad binaria en grupos de 3 en 3 iniciando por el lado derecho. Si al terminar de agrupar no completa 3 dígitos, entonces agregue ceros a la izquierda.

2) Posteriormente vea el valor que corresponde de acuerdo a la tabla:

3) La cantidad correspondiente en octal se agrupa de izquierda a derecha.

 111 = 7

 111 = 7

 011 = 3

Si el número binario tiene parte decimal, se agrupa de tres en tres desde el punto decimal hacia la derecha siguiendo los mismos criterios establecidos anteriormente para números enteros. Por ejemplo:

0.01101 (binario) = 0.32 (octal) Proceso:
011 = 3
01 entonces agregue 010 = 2
Agrupe de izquierda a derecha: 32
Agregue la parte entera: 0.32

Cada dígito octal se convierte en su binario equivalente de 3 bits y se juntan en el mismo orden. 


Para realizar la conversión de binario a hexadecimal, realice lo siguiente:

1) Agrupe la cantidad binaria en grupos de 4 en 4 iniciando por el lado derecho. Si al terminar de agrupar no completa 4 dígitos, entonces agregue ceros a la izquierda.

2) Posteriormente vea el valor que corresponde de acuerdo a la tabla:
3) La cantidad correspondiente en hexadecimal se agrupa de derecha a izquierda.

 1010 = A

 0101 = 5

Note que para pasar de Hexadecimal a binario, se remplaza el número Hexadecimal por el equivalente de 4 bits, de forma similar a como se hace de octal a binario.





</doc>
<doc id="2618" url="https://es.wikipedia.org/wiki?curid=2618" title="Sexo (desambiguación)">
Sexo (desambiguación)

En español, la palabra sexo (del latín "sexus") tiene varios significados:






</doc>
<doc id="2619" url="https://es.wikipedia.org/wiki?curid=2619" title="Símbolo">
Símbolo

Un símbolo (del latín: "simbŏlum", y este del griego σύμβολον) es la representación perceptible de una idea, con rasgos asociados por una convención socialmente aceptada. Es un signo sin semejanza ni contigüidad, que solamente posee un vínculo convencional entre su significante y su denotado, además de una clase intencional para su designado.

Los grupos sociales suelen tener símbolos que los representan: existen símbolos referentes a diversas asociaciones culturales, artísticas, religiosas, políticas, comerciales, deportivas, entre otros.

Del latín "symbŏlum", y este del griego σύμβoλoν, el símbolo es la forma de exteriorizar un pensamiento o idea, así como el signo o medio de expresión al que se atribuye un significado convencional y en cuya génesis se encuentra la semejanza, real o imaginada, con lo significado. Aristóteles afirmaba que "no se piensa sin imágenes", y simbólica es la ciencia, constituyendo ambas las más evidentes manifestaciones de la inteligencia.

En las muchas etapas que componen la evolución, en la forma de comunicación humana, del desarrollo del lenguaje hablado a la escritura, los signos visuales representan la transición de la perspectiva visual, a través de las figuras y los pictogramas, a las señales abstractas. Sistemas de notación capaces de transmitir el significado de conceptos, palabras o sonidos simples.

Los signos y símbolos transmiten ideas en las culturas prealfabetizadas y prácticamente analfabetas. Pero su utilidad no es menor entre las verbalmente alfabetizadas: al contrario, es mayor. En la sociedad tecnológicamente desarrollada, con su exigencia de comprensión inmediata, los signos y símbolos son muy eficaces para producir una respuesta rápida. Su estricta atención a los elementos visuales principales y su simplicidad estructural, proporcionan facilidad de percepción y memoria.

Entre signos y símbolos hay diferencias:

Los símbolos pueden componerse de información realista, extraída del entorno, fácil de reconocer, o también por formas, tonos, colores, texturas..., elementos visuales básicos que no guardan similitud con los objetos del entorno natural. No poseen ningún significado, excepto el que se les asigna. Existen muchas formas de clasificar los símbolos; pueden ser simples o complejos, obvios u oscuros, eficaces o inútiles. Su valor se puede determinar hasta donde penetra la mente en términos de reconocimiento y recuerdo.

El interés por los signos ha dado lugar a un importante campo de estudio: la semiótica. Esta trata tanto la función de los signos en el proceso de comunicación, como el lugar de los síntomas en el diagnóstico médico.

En la comunicación, los signos y señales aparecen, en general, en estructuras similarmente ilógicas. A veces requieren un planteamiento intuitivo que extraiga su sentido y que, por consiguiente, los haga susceptibles de interpretación creativa. Intuición, inspiración, resolución creativa de problemas..., como quiera que lo denominemos esta actividad no posee ninguna lógica, ningún patrón previsible. De la organización de signos inconexos surge la liberación de la lógica hacia el salto de la interpretación. Lo podemos llamar inspiración, pero es una forma particular de inteligencia. Es la aptitud esencial de cualquiera que debe organizar información diversa y extraer un sentido de ésta.

En el ámbito científico y técnico, también se denomina símbolo a las abreviaciones constituidas mediante grafías o letras. Difieren de las abreviaturas por carecer de punto. Tal es el caso de los símbolos químicos (ej. C, O, H0, CH),

Los símbolos nacionales son aquellos que un país adopta para representar sus valores, metas, historia o riquezas y mediante los cuales se identifica y distingue de los demás, además de aglutinar en torno a ellos a sus ciudadanos y crear un sentimiento de pertenencia. Los símbolos nacionales por excelencia son la bandera y los colores nacionales, el escudo de armas y el himno. A ellos se añaden en ocasiones otros emblemas como puede ser una planta, animal u objeto asociado íntimamente con el país. Su tipología difiere en cada cultura constituyendo un interesante campo de estudio antropológico, pues aporta abundante información sobre las ideas, conceptos y valores más significativos de cada sociedad y época.

En las sociedades primitivas, los símbolos sirvieron para expresar las cualidades esenciales de sus creencias religiosas. A lo largo de la historia, la religión ha estado ligada a una serie de símbolos significativos.

En el Antiguo Egipto se practicó esta costumbre, así, simbólica es su escritura jeroglífica, su mitología, donde cada una de las divinidades representa un aspecto cultural, y aún sus manifestaciones artísticas. Igualmente en las formas exteriores de las religiones semíticas como la asiria y fenicia, en la hindú y en las indoeuropeas, como la greco-latina, impera el símbolo, pues en ellas se utilizó la representación de los fenómenos de la naturaleza, personificados en seres mitológicos, que terminaron por encarnar los valores morales de la sociedad.

Los judíos y los musulmanes prohíben las imágenes como símbolos de adoración. En lugar de ello, subrayan la palabra y la necesidad de una cultura escrita para la participación de la oración.

Muchas representaciones de ideas abstractas mediante símbolos son de origen oriental.

Por San Clemente de Alejandría sabemos que los símbolos, que adornaban las catacumbas y que posteriormente se vieron reproducidos en la pintura y la escultura, ya eran utilizados por los cristianos en el siglo II, comúnmente adornando anillos, medallas, etc., con el propósito de reconocerse entre sí obligados al secreto que la persecución imponía a los primeros cristianos. Entre otros se empleaban símbolos de unión o reunión, como los peces de bronce o cristal encontrados en las catacumbas de Roma, que se entregaban a los bautizados para que los llevaran colgados del cuello. También era costumbre que los viajeros que habían recibido hospitalidad en una casa, rompieran un símbolo del que dejaban la mitad de modo que si volvían a visitarse, incluso sus descendientes, pudiera recordarse la hospitalidad; tal es el uso que debían tener muchas monedas partidas que con frecuencia suelen encontrarse.

Al margen de estos símbolos convencionales, tuvieron otros a los que la Iglesia dio mucha importancia, siendo el principal el símbolo de los Apóstoles, que pretendía proporcionar una sucinta guía al cristiano sobre las verdades reveladas, y para que los fieles pudieran mostrar una contraseña propia que los distinguiera de los herejes; de este modo si por cualquier causa cambiaban de congregación podían ser reconocidos como cristianos ortodoxos si evocaban el símbolo. La iglesia primitiva prohibía entregarlo por escrito para evitar que cayera en manos de los infieles, de modo que los creyentes debían aprenderlo de memoria.

El arte figurativo adoptó estos símbolos para representar, en ocasiones desprovistos ya de carácter religioso o mitológico, atributos o cualidades e incluso determinadas manifestaciones de la actividad humana, a los que fue añadiendo otros cuando fue necesario, si bien al principio deudores de las manifestaciones religiosas anteriores que constituían el patrimonio cultural común.

Indagar sobre la definición de símbolo desde la perspectiva hermenéutica que el filósofo alemán Hans-Georg Gadamer plantea en un apartado de su libro "La actualidad de lo bello" es establecer un diálogo con la etimología de la palabra y plantear relaciones con algunas de las vivencias griegas; es adentrarse al estudio semántico que pone en evidencia la influencia del filósofo Heidegger en su obra y reconocer los distanciamientos que hace al momento de interlocutar con los planteamientos del filósofo Hegel, cuando éste define lo bello en el arte. Es así como Gadamer plantea que la esencia de lo simbóloco es el autosignificado.

Gadamer, al hacer una revisión etimológica de lo que quiere decir símbolo, llega a la antigua tradición de la tablilla y la relación entre el anfitrión y el huésped, pues cada uno conservaba parte de la tablilla y al momento de unirlas, los poseedores se reconocían como antiguos conocidos. Lo anterior representa el significado que símbolo tiene desde la lengua griega como "tablilla de recuerdo". Este elemento es de gran importancia al momento de plantear lo relacionado con la experiencia de lo simbólico, pues "este individual-particular se representa como un fragmento del ser que promete complementar en un todo íntegro al que se corresponda en él". —Hans Georg Gadamer.

En este orden de ideas, Gadamer plantea que el otro fragmento existente, que siempre es buscado, logrará la completud total en lo propio, en el fragmento vital que se posee. Es así como la "experiencia de lo bello es la evocación de un orden íntegro posible" —Hans Georg Gadamer.
Con esta noción planteada, se hace la afirmación en la que se reconoce la obra de arte desde el mismo mensaje de integridad, para luego conceptualizar lo que constituye la significatividad de lo bello y del arte. De ahí, plantea que lo que se experimenta de un encuentro con el arte no es lo particular, más bien es la totalidad del mundo experimentable la que tiene lugar. Sin embargo hace la aclaración que esto no quiere decir que "la expectativa indeterminada de sentido que hace que la obra de arte tenga un significado para nosotros pueda consumarse plenamente de su sentido total". —Hans Georg Gadamer.

Es en este punto que retoma al filósofo Hegel, quien plantea lo bello en el arte como la apariencia sensible de la idea, ésta se hace verdaderamente presente en la manifestación sensible de lo bello. Gadamer se distancia de lo anterior denominándolo como una seducción idealista, pues manifiesta que lo propuesto por Hegel "no hace justicia a la auténtica circunstancia de que la obra nos habla como obra no como portadora de un mensaje" —Hans Georg Gadamer. Por consiguiente, la idea de lo simbólico reposa sobre un juego de contrarios de demostración y ocultación. De ahí que la obra no se reduzca a la simplicidad de mero portador de sentido, pues el sentido de la obra radica en que la obra misma está ahí. Esto evidencia que la seducción idealista no toma en cuenta el juego que involucra la demostración y la ocultación, que posibilita que lo universal ocupe un lugar en lo particular sin que necesariamente este tenga que pronunciarse como universal. Es así como lo simbólico no remite al significado sino que representa el significado mismo.

Además de lo anteriormente planteado por Gadamer, este emplea el concepto de conformación por el de obra, manifiesta que la conformación "no es nada de lo que se pueda pensar que alguien lo ha hecho deliberadamente" —Hans Georg Gadamer. Este concepto le permite reforzar lo ya mencionado, en la dirección que le da a la conformación, pues ésta se encuentra y existe así "ahí", susceptible de ser hallada por cualquiera que se encuentre con ella.

Es importante recordar la afirmación que Gadamer realiza al plantear que no es una mera revelación de sentido lo que se lleva a cabo en el arte, y es aquí donde retoma uno de los aportes del filósofo Heidegger cuando este le da al pensamiento la posibilidad de sustraerse al concepto idealista de sentido y de percibir la plenitud ontológica a la verdad que nos habla desde el arte en el doble movimiento de descubrir-desocultar, ocultamiento-retiro.

Paralelo a esto Paul Ricoeur en su texto "Freud: una interpretación de la cultura" —Ricoeur, P. introduce el estudio del símbolo a partir de la voz alemana "traumdeutung" compuesta por dos elementos: "el sueño y la interpretación". Al esbozar, inicialmente, piezas generales sobre el sueño se observa que sobre este recae la interpretación, pues al ser una palabra que se abre a productos psíquicos requiere ser revelada, y para ello se precisa del psicoanálisis."El sueño se inscribe así en una región del lenguaje que se anuncia como lugar de significaciones complejas, donde otro sentido se da y se oculta a la vez en un sentido inmediato" —Ricoeur, P. En esta línea, lo que en Gadamer se entiende como un juego de contrarios, de demostración y ocultación, obedece en Ricoeur a la doble región de sentido en la cual se instala el símbolo.

Al ser de doble sentido, el símbolo requiere de una interpretación que se relega al campo hermenéutico, la hermenéutica es conceptualizada por Ricoeur como "la teoría de las reglas que presiden una exégesis, es decir, la interpretación de un texto singular o de un conjunto de signos susceptible de ser considerado como un texto" —Ricoeur, P.; es por medio de la interpretación que el símbolo se inscribe en la filosofía del lenguaje, este último debe tenerse en cuenta como elemento fundante de los planteamientos filosóficos de Ricoeur para la interpretación del símbolo, lo cual se verá más adelante.

El trabajo que realiza Ricoeur descansa en la búsqueda del "criterio semántico en la estructura intencional de doble sentido" —Ricoeur, P. que tiene el símbolo, y en la necesidad de tener en cuenta esa estructura como el objeto de estudio de su investigación; dicho trabajo ha demandado observar el símbolo a partir de dos definiciones: una 'amplia' en la que la función simbólica es estudiada a partir de los planteamientos de Ernst Cassirer, gracias a los cuales Ricoeur hace una distinción entre símbolo y signo, a esta definición amplia se añaden tres 'zonas de emergencia': la fenomenología de la religión, lo onírico y la imaginación poética. La segunda definición es la 'estrecha' en la que el símbolo es visto a partir del nexo de sentido a sentido que provee la analogía.

En el trabajo de Ricoeur se precisan diversos elementos que permiten limitar los campos de acción del símbolo y de la interpretación, uno de esos elementos, de carácter fundamental, consiste en una definición concreta del símbolo, este como se dijo antes, se diferencia de lo que propone Cassirer, que correspondería, según Ricoeur más a signo, por su sentido unívoco, que al símbolo, que es de carácter doble o múltiple. En este orden de ideas el símbolo en Ricoeur es una expresión de doble o múltiple sentido que requiere un trabajo de interpretación que haga explícitos los múltiples significados que lo componen.

Respecto a las tres 'zonas de emergencia' hay dos que denotan una significación especial, las que tiene que ver con la imaginación poética y fenomenología de la religión, en esta última se anuncia un componente esencial en la investigación de Ricoeur: el lenguaje. El símbolo en la fenomenología de la religión está ligado a los ritos y a los mitos que constituyen el lenguaje de lo sagrado, los símbolos no se presentan como valores de expresión inmediata sino que están inscritos en el universo del discurso donde adquieren realidad simbólica, es entonces, por medio del lenguaje, y concretamente de la palabra, que la expresividad cósmica de la fenomenología de la religión se puede expresar. Así mismo en la imaginación poética, que comprende la importancia de la imagen como vehículo o pretexto para dar fuerza verbal a la expresión, se imponen el lenguaje y palabra como medios para poder decir al símbolo. En este sentido, entendemos que es por medio del lenguaje que el símbolo puede hacerse "real", entendiendo posibilidad de realización no realidad material, sino realidad expresiva.






</doc>
<doc id="2620" url="https://es.wikipedia.org/wiki?curid=2620" title="Servidor">
Servidor

Un servidor es una aplicación en ejecución capaz de atender las peticiones de un cliente y devolverle una respuesta en concordancia. Los servidores se pueden ejecutar en cualquier tipo de computadora, incluso en computadoras dedicadas a las cuales se les conoce individualmente como «el servidor». En la mayoría de los casos una misma computadora puede proveer múltiples servicios y tener varios servidores en funcionamiento. La ventaja de montar un servidor en computadoras dedicadas es la seguridad. Por esta razón la mayoría de los servidores son procesos diseñados de forma que puedan funcionar en computadoras de propósito específico.

Los servidores operan a través de una arquitectura cliente-servidor. Los servidores son programas de computadora en ejecución que atienden las peticiones de otros programas: los clientes. Por tanto, el servidor realiza otras tareas para beneficio de los clientes; les ofrece la posibilidad de compartir datos, información y recursos de hardware y software. Los clientes usualmente se conectan al servidor a través de la red, pero también pueden acceder a él a través de la computadora donde está funcionando. En el contexto de redes Internet Protocol (IP), un servidor este es un programa que opera como oyente de un socket.

Comúnmente, los servidores proveen servicios esenciales dentro de una red, ya sea para usuarios privados dentro de una organización o compañía, o para usuarios públicos a través de Internet. Los tipos de servidores más comunes son 
servidor de base de datos, 
servidor de archivos, 
servidor de correo, servidor de impresión, servidor web, servidor de juego, y servidor de aplicaciones.

Un gran número de sistemas usa el modelo de red cliente-servidor, entre ellos los sitios web y los servicios de correo. Un modelo alternativo, el modelo red peer-to-peer, permite a todas las computadoras conectadas actuar como clientes o servidores acorde a las necesidades.

El término "servidor" es ampliamente utilizado en el campo de las tecnologías de la información. A pesar de la amplia disponibilidad de productos etiquetados como productos de servidores (tales como versiones de hardware, software y OS diseñadas para servidores), en teoría, cualquier proceso computacional que comparta un recurso con uno o más procesos clientes es un servidor. Tomemos como ejemplo la acción de compartir archivos. Mientras la existencia de archivos dentro de una computadora no la clasifica como un servidor, el mecanismo del sistema operativo que comparte estos archivos a los clientes sí es un servidor.

De manera similar, consideremos una aplicación web servidor (como por ejemplo el servidor multiplataforma "Apache"). Este servidor web puede ejecutarse en cualquier tipo de computadora que cumpla con los requerimientos mínimos. Por ejemplo, mientras un ordenador portátil () o computadora personal usualmente no son consideradas como servidores, en ciertos casos (como el anterior) pueden cumplir el rol de uno y por lo tanto ser denominadas servidores. En este caso, es el rol de la computadora el que la coloca en la categoría de servidor.

En el sentido del "hardware", la palabra "servidor" normalmente etiqueta modelos de computadora diseñados para hospedar un conjunto de aplicaciones que tiene gran demanda dentro de una red. En esta configuración cliente-servidor, uno o más equipos (lo mismo una computadora que un programa informático), comparten información entre ellos de forma que uno actúa como anfitrión () de los otros.

Casi todas las computadoras personales pueden actuar como un servidor, pero un servidor dedicado tendrá cualidades más adecuadas para un ambiente de producción. Entre estas cualidades se pueden mencionar una unidad central de procesamiento (CPU) más rápida, memoria de acceso aleatorio (RAM) mejorada para alto desempeño, y mayores capacidades de almacenamiento en forma de múltiples discos duros. Los servidores también cuentan con otras cualidades como fiabilidad, disponibilidad y capacidad de servicio ("RAS" por su siglas en idioma inglés) y tolerancia a fallos, esta última en forma de redundancia en cuanto al número de fuentes, en almacenamiento de datos como un grupo redundante de discos independientes (RAID) y varias conexiones de red.

Los servidores se volvieron comunes a principios de 1990 en la medida en que los negocios comenzaron a utilizar computadoras personales para brindar servicios que anteriormente se alojaban en "mainframes" o en microcomputadoras. Los primeros servidores de archivos contaban con múltiples torres de CD, utilizados para alojar grandes aplicaciones de bases de datos.

Entre 1990 y el 2000 el aumento en el uso de "hardware específico" marcó el advenimiento aplicaciones de servidor autosuficientes. Uno de estas aplicaciones bien conocidas es el Google Search Appliance, que combina hardware y software en un paquete out-of-the-box packaging. Productos similares fueron el Cobalt Qube y el RaQ. Ejemplos más sencillos de dichos equipos incluyen switches, routers, gateways, y servidores de impresión, los cuales son fácilmente utilizables a través de una configuración plug-and-play.

Los sistemas operativos modernos como Microsoft Windows o las distribuciones de Linux parecen haber sido diseñados siguiendo una arquitectura cliente-servidor. Estos sistemas operativos se abstraen del hardware, permitiendo a una gran variedad de software trabajar con componentes de la computadora. De alguna forma, el sistema operativo puede ser visto como un "servidor" de hardware al software pues, excepto en los lenguajes de programación de bajo nivel, el software debe interactuar con el hardware a través de un API.

Estos sistemas operativos son capaces de ejecutar programas en un segundo plano los cuales son llamados servicios o daemons. Estos programas, entre los que se encuentra el "Servidor HTTP Apache" previamente mencionado, pueden permanecer en un estado dormido hasta que sea necesario su uso. Como cualquier software que "brinde" servicios puede ser llamado servidor, las computadoras personales modernas se pueden ver como bosques de aplicaciones clientes y servidores operando en paralelo.

El propio Internet es un bosque de servidores y clientes. Solo con el hecho de solicitar una página web de un servidor a pocos kilómetros de distancia conlleva a satisfacer una pila de protocolos de red que incluyen varios ejemplos del uso de hardware y software para servidores. Los más sencillos de estos son los routers, módems, servidores DNS, además de otros sin cuya interacción no podríamos acceder a la web.

La aparición de la computación en la nube permite servidores de almacenamiento, así como compartir recursos con un fondo común; igualmente permite a los servidores mantener un mayor grado de tolerancia a los fallos.

Los requerimientos de "hardware" para los servidores varían en dependencia del tipo de aplicación del servidor. La velocidad de la CPU no es tan crítica para un servidor como lo sería para una máquina de escritorio. El deber de los servidores de proveer servicios dentro de una red a un gran número de usuarios impone diferentes requerimientos, tales como conexiones de alta velocidad y altas prestaciones para todos los dispositivos de I/O. Como generalmente se accede a los servidores a través de la red, estos pueden funcionar sin necesidad de un monitor u otros dispositivos de entrada. Aquellos procesos que no son necesarios para las funciones del servidor no se utilizan. Muchos servidores no cuentan con una interfaz gráfica de usuario (GUI) ya que esta funcionalidad consume recursos que pueden ser utilizados por otros procesos. Igualmente las interfaces de audio y USB también pueden ser omitidas.

Los servidores funcionan por largos períodos de tiempo sin interrupción y su disponibilidad debe ser alta la mayor parte del tiempo, haciendo que la confiabilidad y durabilidad del hardware sean extremadamente importantes. Aunque los servidores pueden ser ensamblados a partir de piezas para computadoras comunes, aquellos servidores que realizan tareas críticas dentro de la infraestructura de una empresa son idealmente muy tolerantes a fallas y utilizan hardware especializado con tasa de fallo para maximizar su tiempo de funcionamiento, pues una simple falla de poco tiempo de duración puede representar costos mayores a los de comprar las piezas e instalar todo el sistema. Por ejemplo, una falla de pocos minutos en una bolsa de acciones basta para justificar los gastos de sustitución de todo el sistema por otro más confiable. Los servidores pueden incluir discos de mayor capacidad y velocidad, sistemas de enfriamiento por agua, mayores disipadores para reducir el calor, abastecimientos de energía ininterrumpido que garantice el funcionamiento del servidor ante una falla del suministro eléctrico. Estos componentes ofrecen un mayor desempeño y confiabilidad en correspondencia a un mayor precio. La redundancia de hardware —instalar más de una instancia de un módulo como la fuente o el disco duro dispuestos de forma tal que si uno falla el otro se encuentre automáticamente disponible— es ampliamente utilizada. Se utilizan dispositivos de memoria ECC que detectan y corrigen errores; otros tipos de memoria que no son ECC pueden conllevar a una corrupción de los datos.

Para aumentar la confiabilidad la mayoría de los servidores utilizan memoria para detección y corrección de errores, discos redundantes, fuentes redundantes y más. Es común que estos componentes pueden ser sustituidos en caliente, permitiendo que los técnicos puedan cambiar piezas defectuosas en un servidor sin la necesidad de tener que apagarlo. Los servidores cuentan usualmente con mejores disipadores para prevenir un sobrecalentamiento. Como en la mayoría de los casos los servidores son administrados por administradores de sistema calificados, el sistema operativo con que cuentan está más enfocado en la estabilidad y el desempeño que en parecer acogedor y fácil de usar, siendo Linux el que mayor por ciento de uso toma.

Como la mayoría de los servidores son ruidosos y necesitan de estabilidad en el suministro eléctrico, buen acceso a Internet, y mayor seguridad, es común almacenarlos en centros de servidores. Como los servidores se agrupan siempre se busca reducir el consumo energético, pues la energía extra utilizada produce un aumento de la temperatura en la habitación lo que provocando que se excedan los límites de temperatura aceptables; por ello la mayoría de las habitaciones para servidores cuentan con equipos de aire acondicionado. La cubierta de la mayoría de los servidores tiende a ser plana y ancha (usualmente medida en "unidades rack"), adaptada para almacenar varios dispositivos juntos en un soporte para servidores. A diferencia de las computadoras ordinarias los servidores pueden ser configurados, encendidos, apagados o reiniciados remotamente usando administración remota, usualmente basada en IPMI.

Muchos servidores se demoran en arrancar el hardware e inicializar el sistema operativo. Es frecuente que los servidores realicen extensas pruebas de memoria antes de inicializar además la inicialización y verificación de servicios de administración remotos. Los controladores de discos duros inician los dispositivos secuencialmente, en vez de todos a la vez, para no sobrecargar la fuente de alimentación con la carga de arranque, y luego inician el chequeo del sistema RAID para probar que las operaciones redundantes funcionen de forma correcta. Es común que un servidor tome varios minutos para inicializarse pero puede que no sea necesario reiniciarlo en meses o años.

Los sistemas operativos orientados a servidores cuentan con ciertas cualidades que los hacen más adecuados para el entorno de un servidor, como

En muchos casos, los sistemas operativos orientados a servidores pueden interactuar con sensores de hardware para detectar estados como sobrecalentamiento, fallos de discos o del procesador, y en consecuencia alertar a su operador o tomar medidas de rectificación por sí mismo.

Como los servidores deben proveer un conjunto limitado de servicios a múltiples usuarios mientras que una computadora personal debe soportar una amplia variedad de funcionalidades requeridas por su usuario, los requerimientos de un sistema operativo para un servidor son diferentes de aquellos en una computadora de escritorio. Aunque es posible que un sistema operativo haga que una computadora provea servicios y responda rápidamente a los requerimientos de un usuario, es común el uso de diferentes sistemas operativos en servidores y computadoras de personal. Algunos sistemas operativos vienen en sus versiones personales (desktop) y servidores (server) con interfaces de usuario similares.

Los sistemas operativos para servidores de Windows y Mac OS X son usados en una minoría de los servidores, ya que también existen otros sistemas operativos de pagos para mainframes como z/OS. Los sistemas operativos predominantes en servidores son aquellos que siguen distribuciones de software open source de UNIX , como los basados en Linux y FreeBSD. El ascenso de los servidores basados en microprocesadores se facilitó a partir del desarrollo de UNIX para ejecutarse sobre la arquitectura de microprocesador x86. La familia de sistemas operativos de Microsoft Windows también puede ejecutarse sobre el hardware x86 y desde Windows NT, está disponible para versiones adecuadas para uso en servidores.

Mientras que el rol de los sistemas operativos para servidores y para computadoras personales permanece diferente, las mejoras en la confiabilidad tanto del hardware como del sistema operativo han hecho borrosa la distinción entre estas dos clases. Hoy en día muchos sistemas operativos para computadoras personales y para servidores comparten las mismas bases en su código, difiriendo mayormente en su configuración. El cambio hacia las aplicaciones web y las plataformas middleware también han enseñado la demanda de servidores especializados para aplicaciones.

En la siguiente lista hay algunos tipos comunes de servidores:












Sin embargo, de acuerdo al rol que asumen dentro de una red se dividen en:


En 2010, los data centers (servidores, enfriamiento, y resto de infraestructura eléctrica), consumieron del 1.1 al 1.5% de la energía eléctrica en el mundo y del 1.7 al 2.2% en los Estados Unidos.

Concretamente, este consumo es menor que el de 6 mil millones de teléfonos móviles que hay en el mundo cuando van a recargar sus baterías. Incluso este consumo puede parecer despreciable, sobre la base de las tasas de consumo de la calefacción, el enfriamiento y el calentamiento de agua domésticos, que asciende a los dos dígitos. Finalmente, el informe Smart2020, estima que ICT (Information and Communications Technology) ahorra más de 5 veces su huella de carbono. que el resto de la economía por aumento de la eficiencia.

Las clases de tamaño incluyen:



</doc>
<doc id="2621" url="https://es.wikipedia.org/wiki?curid=2621" title="Spot">
Spot

La palabra spot puede referirse a:







</doc>
<doc id="2623" url="https://es.wikipedia.org/wiki?curid=2623" title="Secure Shell">
Secure Shell

SSH (o "S"ecure "SH"ell) es el nombre de un protocolo y del programa que lo implementa cuya principal función es el acceso remoto a un servidor por medio de un canal seguro en el que toda la información está cifrada. Además de la conexión a otros dispositivos, SSH permite copiar datos de forma segura (tanto archivos sueltos como simular sesiones FTP cifradas), gestionar claves RSA para no escribir contraseñas al conectar a los dispositivos y pasar los datos de cualquier otra aplicación por un canal seguro tunelizado mediante SSH y también puede redirigir el tráfico del (Sistema de Ventanas X) para poder ejecutar programas gráficos remotamente. El puerto TCP asignado es el 22.

SSH trabaja de forma similar a como se hace con telnet. La diferencia principal es que SSH usa técnicas de cifrado que hacen que la información que viaja por el medio de comunicación vaya de manera no legible, evitando que terceras personas puedan descubrir el usuario y contraseña de la conexión ni lo que se escribe durante toda la sesión; aunque es posible atacar este tipo de sistemas por medio de ataques de REPLAY y manipular así la información entre destinos.

Al principio solo existían los r-commands, que eran los basados en el programa rlogin, el cual funciona de una forma similar a telnet.

La primera versión del protocolo y el programa eran libres y los creó un finlandés llamado Tatu Ylönen, pero su licencia fue cambiando y terminó apareciendo la compañía SSH Communications Security, que lo ofrecía gratuitamente para uso doméstico y académico, pero exigía el pago a otras empresas. En el año 1997 (dos años después de que se creara la primera versión) se propuso como borrador en la IETF.

A principios de 1999 se empezó a escribir una versión que se convertiría en la implementación libre por excelencia, la de OpenBSD, llamada OpenSSH.

Existen 2 versiones de SSH, la versión 1 de SSH hace uso de muchos algoritmos de cifrado patentados (sin embargo, algunas de estas patentes han expirado) y es vulnerable a un agujero de seguridad que potencialmente permite a un intruso insertar datos en la corriente de comunicación. La suite OpenSSH bajo Red Hat Enterprise Linux utiliza por defecto la versión 2 de SSH, la cual tiene un algoritmo de intercambio de claves mejorado que no es vulnerable al agujero de seguridad en la versión 1. Sin embargo, la suite OpenSSH también soporta las conexiones de la versión 1.




</doc>
<doc id="2625" url="https://es.wikipedia.org/wiki?curid=2625" title="Sucrea">
Sucrea

Sucrea, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Brasil.
El nombre del género fue otorgado en honor de Dimitri Sucre.



</doc>
<doc id="2626" url="https://es.wikipedia.org/wiki?curid=2626" title="Streptostachys">
Streptostachys

Streptostachys es un género de plantas herbáceas de la familia de las gramíneas o poáceas. Es originario del norte de Sudamérica. Comprende 8 especies descritas y de estas, solo 6 aceptadas.

El género fue descrito por Nicaise Augustin Desvaux y publicado en "Nouveau Bulletin des Sciences, publié par la Société Philomatique de Paris" 2: 190. 1810. La especie tipo es: "Streptostachys asperifolia"

A continuación se brinda un listado de las especies del género "Streptostachys" aceptadas hasta noviembre de 2014, ordenadas alfabéticamente. Para cada una se indica el nombre binomial seguido del autor, abreviado según las convenciones y usos.




</doc>
<doc id="2628" url="https://es.wikipedia.org/wiki?curid=2628" title="Streptochaeta">
Streptochaeta

Streptochaeta, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de América desde México hasta Argentina. Es el único miembro de la tribu Streptochaeteae. Comprende 5 especies descritas y de estas, solo 4 aceptadas. 
Son hierbas erectas perennes emergiendo de coronas nodosas; tallos en su mayoría simples; plantas hermafroditas. Lígula ausente; pseudopecíolo anchamente sulcado, terminando en un corto pulvínulo; láminas aplanadas, ovadas, asimétricas, teseladas. Inflorescencia una espiga solitaria terminal de pseudoespiguillas dispuestas en espiral en el delgado raquis angular, desarticulándose de éste en grupo y por lo general pendiendo por algún tiempo de la punta del mismo, enredadas en las aristas ensortijadas y retorcidas; pseudoespiguillas teretes, sésiles, usualmente con 11 brácteas rígidas espiralmente imbricadas; brácteas 1–5 mucho más cortas que el resto, dispuestas en espiral, bráctea 6 la más larga, rematada en una arista alargada, retorcida, enrollada en espiral, brácteas 7 y 8 lado con lado, brácteas 9–11 verticiladas, formando un cono alrededor de la flor bisexual; lodículas ausentes; estambres 6, unidos en la base de los filamentos; ovario fusiforme; estilos 3. Fruto una cariopsis.
El género fue descrito por Heinrich Adolph Schrader y publicado en " Flora Brasiliensis seu Enumeratio Plantarum" 2(1): 536. 1829. La especie tipo es: "Streptochaeta spicata" Schrad. ex Nees
Streptochaeta: nombre genérico que deriva del griego: "strepto" = "retorcido" y "chaeta" = "pelos largos".

El número cromosómico básico es x = 11, con números cromosómicos somáticos de 2n = 22. diploide
A continuación se brinda un listado de las especies del género "Streptochaeta" aceptadas hasta noviembre de 2013, ordenadas alfabéticamente. Para cada una se indica el nombre binomial seguido del autor, abreviado según las convenciones y usos.




</doc>
<doc id="2630" url="https://es.wikipedia.org/wiki?curid=2630" title="Stiporyzopsis">
Stiporyzopsis

Stiporyzopsis, es un género monotípico híbrido entre los géneros de la familia de las poáceas ("Oryzopsis × Stipa").





</doc>
<doc id="2631" url="https://es.wikipedia.org/wiki?curid=2631" title="Sistema digital">
Sistema digital

Un sistema digital binario es un conjunto de dispositivos que son destinados a la generación, transmisión, manejo, procesamiento y almacenamiento de señales digitales. También, y a diferencia de un sistema analógico, un sistema digital es una combinación de dispositivos diseñados para manipular cantidades físicas o información que se encuentre representada en forma digital; es decir, que solamente pueda tomar valores discretos. 

Para el análisis y la síntesis de sistemas digitales binarios se utiliza como herramienta el álgebra de Boole.



Para la implementación de los circuitos digitales, se utilizan puertas lógicas (AND, OR y NOT), construidas generalmente a partir de transistores. Estas puertas siguen el comportamiento de funciones básicas booleanas.

Según el propósito de los sistemas digitales, se clasifican en:



Z = F(X)

Z= valor señales de las salidas;
X= valor señales de las entradas;
F= circuito transformador de señales (compuertas electrónicas)


Z = F(X,Q)

Z= valor señales de las salidas;
X= valor señales de las entradas;
Q= elementos de memoria (Flip Flops);
F= circuito transformador de señales (compuertas electrónicas)

Paso 1. Enunciado del problema

Paso 2. Análisis: Especificación de variables de entrada y de salida

Paso 3. Modelado: Definición de las funciones de Boole que especifican el comportamiento del sistema

Paso 4. Simplificación de las funciones de Boole (opcionalmente)

Paso 5. Diagrama lógico

Paso 6. Selección circuitos integrados

Paso 7. Ensamble del sistema digital (tablero de pruebas o circuito preimpreso)

Paso 8. Pruebas




</doc>
<doc id="2632" url="https://es.wikipedia.org/wiki?curid=2632" title="Spodiopogon">
Spodiopogon

Spodiopogon es un género de plantas herbáceas de la familia de las gramíneas o poáceas. Es originario de Asia y Oriente Medio. 
El nombre del género deriva de las palabras griegas "spodios" (ceniza) y "pogon" (barba), tal vez refiriéndose al pelo de la inflorescencia. 
Tiene los números cromosómicos somáticos de 2n = 40 y 42. Cromosoma relativamente pequeños.



</doc>
<doc id="2633" url="https://es.wikipedia.org/wiki?curid=2633" title="Sorghastrum">
Sorghastrum

Sorghastrum es un género de plantas herbáceas de la familia de las gramíneas o poáceas. Es originario de África tropical y Subtropical y América. 
El género fue descrito por George Valentine Nash y publicado en "Manual of the Flora of the northern States and Canada" 71. 1901. La especie tipo es: "Sorghastrum avenaceum" (Michx.) Nash. 
El nombre del género se compone de "Sorghum" (otro género de misma familia) y de la palabra latina "astrum" (una pobre imitación), refiriéndose a la semejanza entre los géneros. 
El número cromosómico básico es x = 10, con números cromosómicos somáticos de 2n = 20, 40 y 60. 2, 4, y 6 ploides. 




</doc>
<doc id="2634" url="https://es.wikipedia.org/wiki?curid=2634" title="Sitanion">
Sitanion

Sitanion, es un género de plantas herbáceas de la familia de las gramíneas o poáceas. Es originario de las regiones templadas de Norteamérica. 
El nombre del género deriva de la palabra griega "sitos" (grano). 
El número cromosómico básico es x = 7, con números cromosómicos somáticos de 2n = 28. 4 ploide. 



</doc>
<doc id="2637" url="https://es.wikipedia.org/wiki?curid=2637" title="Sclerochloa">
Sclerochloa

Sclerochloa es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario del sur de Europa hasta el oeste de Asia. Comprende 31 especies descritas. 
El género fue descrito por Ambroise Marie François Joseph Palisot de Beauvois y publicado en "Essai d'une Nouvelle Agrostographie" 97, 177. 1812. La especie tipo es: "Sclerochloa dura" (L.) P.Beauv. 



</doc>
<doc id="2638" url="https://es.wikipedia.org/wiki?curid=2638" title="Schizostachyum">
Schizostachyum

Schizostachyum, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario del este de Asia. 

Las siguientes especies han sido excluidas de este género:




</doc>
<doc id="2639" url="https://es.wikipedia.org/wiki?curid=2639" title="Schizachyrium">
Schizachyrium

Schizachyrium es un género de plantas herbáceas de la familia de las poáceas. Es originario de las regiones tropicales del mundo.

El nombre del género deriva de las palabras griegas "schizein" (dividir) y "achuron" (paja), refiriéndose al lema superior. 

El número cromosómico básico es x = 5 y 10, con números cromosómicos somáticos de 2n = 20, 30, 40, y 50. 




</doc>
<doc id="2642" url="https://es.wikipedia.org/wiki?curid=2642" title="Saugetia">
Saugetia

Saugetia es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de las Indias Occidentales.

Algunos autores lo incluyen en el género "Enteropogon".



</doc>
<doc id="2643" url="https://es.wikipedia.org/wiki?curid=2643" title="Sasa">
Sasa

Sasa es un género de bambúes de la familia de las poáceas. Las especies de este género tienen una rama por nudo. Es originario del este de Asia. Comprende 488 especies descritas y de éstas, sólo 61 han sido aceptadas.
El género fue descrito por Makino & Shib. y publicado en "Botanical Magazine" 15(168): 18. 1901.

Sasa: nombre genérico que proviene del nombre japonés para un pequeño bambú.


</doc>
<doc id="2644" url="https://es.wikipedia.org/wiki?curid=2644" title="Sacciolepis">
Sacciolepis

Sacciolepis es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de las regiones tropicales y subtropicales del mundo.
El nombre del género deriva de las palabras griegas "sakkion" (una pequeña bolsa) y "lepis" (escala), aludiendo a la gluma en forma de saco. 



</doc>
<doc id="2652" url="https://es.wikipedia.org/wiki?curid=2652" title="Siglo XVII">
Siglo XVII

El (siglo diecisiete después de Cristo) o e.c. (siglo diecisiete de la era común) fue el séptimo siglo del II milenio en el calendario gregoriano. Comenzó el 1 de enero de 1601 y terminó el 31 de diciembre de 1700. El siglo es el último que forma parte completo de la Edad Moderna, el cual estuvo caracterizado por el movimiento artístico conocido como el Barroco, la última parte del Siglo de Oro español, el Siglo de Oro Neerlandés, la predominación de Francia en Europa durante el reinado de Luis XIV, la revolución científica y la Gran Crisis del siglo XVII. Los mayores conflictos militares fueron la guerra de los Treinta Años, la Gran Guerra Turca y la guerra luso-neerlandesa. Es conocido como el «siglo del barroco».

El siglo estuvo fuertemente marcado por grandes crisis y transformaciones que lo convirtieron en una época de retroceso en Europa, ya que la evolución global de la economía y la población fue negativa y la producción agraria padeció sucesivas crisis. Esto causó una serie de grandes hambrunas que dieron pie a la aparición de epidemias y pestes, causas de una serie de guerras como la de los Treinta Años.

En el marco del mundo islámico, el Imperio otomano, el Imperio safávida y el Imperio mogol se fortalecieron por todo el mundo. Especialmente en el subcontienente Indio, el Imperio mogol alcanzó un apogeo en la cultura, arquitectura y el arte. Durante el reinado del emperador Aurangzeb, el imperio se coronó como la economía más grande del mundo, por delante de toda Europa poseyendo el 25% del PIB mundial.

En Japón, a principios de siglo, el "shōgun" Tokugawa Ieyasu estableció el Shogunato Tokuwaga, iniciando el período Edo. Paralelamente puso en vigor el Sakoku, una ley de política exterior el cual establecía que ningún japonés podría salir de Japón y ningún extranjero podría entrar en él. El Sakoku se mantuvo en Japón hasta el . En China la dinastía Ming acabaría derrumbándose, debido a una serie de saqueos dirigidos por el manchú Nurhaci que serían terminados por su hijo, Hung Taiji, y su nieto Shunzi. Este último acabaría convirtiéndose en emperador y fundador de la dinastía Qing.

Desde mitad de siglo, la política europea estuvo dominada por el reinado del monarca Luis XIV de Francia. La nobleza francesa semi-feudal territorial fue subyugada al poder de una monarquía absoluta a través de la rehabilitación del Palacio de Versalles. Pabellón de caza de Luis XIII y del cual Luis XIV construyó una corte real renovada desde la cual podría controlar a toda la nobleza francesa. Durante el reinado, Francia amplió sus fronteras, fortaleció su poder militar y se consolidó como la principal potencia europea. Durante este siglo, la monarquía británica se convirtió en una institución meramente simbólica, siendo el Parlamento, el que contaba con el verdadero poder. Este sistema de monarquía parlamentaria chocaba totalmente con el resto de monarquías europeas, en las cuales todavía compartían el modelo absolutista.

A finales de siglo, los europeos conocían ya la electricidad, el telescopio, el microscopio, el cálculo, la gravitación universal, las leyes del movimiento de Newton, la presión atmosférica y las máquinas de cálculo gracias al trabajo de los primeros científicos de la Revolución Científica. incluyendo a Galileo Galilei, Johannes Kepler, René Descartes, Pierre Fermat, Blaise Pascal, Robert Boyle, Christiaan Huygens, Antonie van Leeuwenhoek, Robert Hooke, Isaac Newton y Gottfried Wilhelm Leibniz. También fue un período de desarrollo de la cultura en general, especialmente en teatro, música, artes visuales y filosofía.












Durante el siglo XVII se vivieron grandes transformaciones que posteriormente marcarían toda la economía del mundo occidental. El mundo mediterráneo el cual había visto su esplendor en siglos anteriores, (Italia y España) se vio afectado por una serie de crisis, pestes y hambrunas que dieron paso a una gran recesión en sus economías. Es por eso que el área de influencia políticamente hablando se trasladó a las regiones del noroeste las cuales vieron esplendor por primera vez, como es el caso de Francia y las Provincias Unidas. También se desarrolló un comercio colonial, sobre todo en Inglaterra y Provincias Unidas donde se creó un sistema comercial dirigido por compañías privadas que contaban con la protección del estado. Destacó la compañía de las Indias Orientales fundada en 1602. Debido al desarrollo del comercio internacional se estableció el capitalismo. Paralelamente surgieron nuevas doctrinas económicas como el mercantilismo caracterizado por la mayor circulación monetaria y la creación de poderosas sociedades comerciales. El mercantilismo no sobrevaloraba la propiedad de la tierra sino que otorgaba importancia a la combinación de oro y plata mediante el aumento de las exportaciones y la defensa de la producción interna. Esto hizo que los gobiernos quisieran autoabastecerse de materias primas, ya que de lo que se trataba era de vender a los demás, pero no comprarles. Los reinos establecieron un sistema en la frontera por los cuales los productos que venían de otros reinos eran castigados con fuertes aranceles. Ante esa situación la solución sería ir adquiriendo territorios para obtener las materias primas directamente sin necesidad de comprárselas a nadie, simplemente colonizándolo. Esto dará paso a que en el futuro se formen los imperios coloniales. La expansión de la industria, el comercio y las actividades financieras también fomentaron la creciente consolidación de la burguesía todavía dentro de una sociedad estamental en la que la riqueza se estaba convirtiendo en un factor clave para alcanzar una determinada posición social, este cambio fue más acusado en los países protestantes en los que el clero había desaparecido como estamento.

La mayoría de los conflictos europeos se debieron al intento de los Habsburgo de mantener su hegemonía y el predominio del catolicismo. El más importante de ellos fue la Guerra de los Treinta Años entre 1618 y 1648. Los antecedentes los podemos encontrar en la reciente división religiosa de Europa con la aparición del protestantismo. Por su parte, España que había mantenido durante todo el siglo anterior guerras contra Francia y enemistad con Inglaterra, fueron selladas mediante la Pax Hispánica ratificada por Felipe III. La situación del Sacro Imperio Romano Germánica era más compleja, Carlos V le había dejado la parte austriaca de su imperio a su hermano Fernando I para mantener un equilibrio entre los católicos y protestantes. A Fernando I lo sucedieron Rodolfo II y Matías I, pero a principios del siglo la situación se complicó, debido a la fragmentación de los estados que componían el Sacro Imperio Romano Germánico en independientes. Los príncipes quisieron tener más poder y libertad, para ello en 1608 se forma la Liga Protestante en contra del emperador y se creó la Santa Liga Alemana en 1609. Fernando II, que acabaría convirtiéndose en futuro emperador, hizo una política agresiva contra los protestantes. Los bohemios, (habitantes de la región de Bohemia) y otros territorios erigen a Federico V como emperador y rechazan a Fernando II. El detonante de la guerra fue la Defenestración de Praga en el año 1618, en la cual dos diplomáticos católicos del futuro emperador Fernando II son lanzados por la ventana del castillo de Hradcany por los bohemios protestantes que no lo aceptaban como emperador. Ante esa situación Fernando II pide ayuda al rey español, Felipe III, el cual era de su familia. Es entonces cuando se acaba la Pax Hispánica y la monarquía hispánica entra en conflicto con todos sus enemigos históricos, las Provincias Unidas, Francia e Inglaterra. La Guerra de los Treinta Años se desarrolló por lo tanto en dos bandos, el católico y el protestante. Así, España y Austria que eran del bando católico, tuvieron que enfrentarse a Inglaterra, Provincias Unidas, Suecia y Dinamarca. La situación se mantuvo más o menos equilibrada hasta que en 1635 se produjo un giro en la guerra, cuando Francia, que era un país católico, se sumó al bando protestante para perjudicar a España. Francia en aquel entonces estaba gobernada por el rey Luis XIII y el cardenal Richelieu, estos ante la posibilidad de desprenderse de una vez del dominio español no dudaron en aliarse en el bando protestante. La primera derrota que se produjo fue la famosa Batalla de Rocroi, la cual se convirtió en la primera gran derrota de los invencibles tercios españoles. Finalmente, en 1648 la Paz de Westfalia, puso fin a la guerra con una clara victoria para el bando protestante. La caída de los Habsburgo permitió el ascenso de las economías de las Provincias Unidas y Suecia, sin embargo la más beneficiada fue Francia que continuó la guerra contra España hasta la Paz de los Pirineos en el año 1659. 

Tras el fin de la guerra contra España, Francia se coronó como la gran potencia europea bajo el reinado de Luis XIV. Con Luis XIV, Francia alcanzó su apogeo político y económico. El joven monarca, implementó la monarquía absoluta por la que se concentró todos los poderes en su persona. Su lema "¡El estado soy yo!" ejemplifica el carácter absoluto de su poder. Para ello creó una poderosa burocracia, un competente cuerpo de diplomáticos, así como un ejército permanente, pionero para la época y muy parecido a los cuerpos militares actuales. El único cabo suelto que le faltaba para concentrar todos los poderes era la nobleza francesa, la cual todavía poseía un modelo semi-feudal territorial. Luis XIV subyugó a la nobleza manteniéndola controlada en su propia residencia oficial, el Palacio de Versailles, símbolo del poder real. Su modelo, acabaría siendo imitado por todos los monarcas europeos. Su principal idea de política exterior era únicamente para beneficiar a Francia y lograr la hegemonía europea. 

Mientras en el resto del continente, se extendía el modelo absolutista francés. En Inglaterra se vivió la implantación de una monarquía parlamentaria. El origen de este proceso, se encontró en las medidas adoptadas por el rey Carlos I para recortar los poderes del Parlamento, dominado por los calvinistas. Estos, dirigidos por Oliver Cromwell, dieron un golpe de estado, por lo que estalló una guerra civil que duraría de 1642 a 1649 que acabaría con el rey ejecutado. Cromwell instauró una república que acabó convirtiéndose en una dictadura. Tras su muerte, lo sucedería su hijo, Richard Cromwell que sería forzado a dimitir en 1659, por presiones del ejército y los problemas políticos internos existentes. Un año después de su dimisión, en 1660, la monarquía volvió a ser instaurada con Carlos II, hijo del rey ejecutado durante la guerra. Sin embargo en 1688 tuvo lugar un nuevo levantamiento conocido como Revolución Gloriosa, por ella su hijo, el rey Jacobo II fue depuesto y sustituido en el trono por Guillermo de Orange, el cual aceptó la declaración de derechos. Esta declaración de derechos, era un documento que recortaba los poderes de la monarquía, garantizaba las elecciones libres y otorgaba amplios poderes al Parlamento.

El Sacro Imperio Romano Germánico quedó debilitado tras la Paz de Westfalia, los numerosos estados que constituían el imperio se hicieron cada vez más independientes y la figura imperial quedó relegada a algo meramente honorífico o casi simbólico. Las Provincias Unidas de Holanda, se organizaron como una república dirigida por el estatúder. Su pujanza comercial y marítima convirtió a Holanda en una de las principales potencias europeas. Los Países Bálticos también se consolidaron como nuevas potencias, en especial Suecia y Dinamarca, las cuales habían salido victoriosas tras la guerra.

Para la monarquía hispánica, mientras que el siglo XVI había sido una era de esplendor y de expansión política y demográfica, el siglo XVII se convirtió en un período de crisis política, estancamiento demográfico y de profunda crisis económica y social. Por eso el siglo XVII suele asociarse con la decadencia de la monarquía hispánica, aunque muchos de los problemas vinieron de las decisiones tomadas en el siglo anterior. A lo largo de la centuria la economía española tuvo una profunda crisis que afectó principalmente a la Corona de Castilla, que soportaba la mayor parte de los elevados gastos de la política internacional de la monarquía. La agricultura vivió una severa crisis, la despoblación del campo vino provocada por las constantes epidemias las levas para la guerra y el traslado de los campesinos a las ciudades huyendo de los grandes tributos. Por ello y por la falta de innovaciones técnicas, la producción agrícola disminuyó. La industria artesanal experimentó un gran deterioro debido a la competencia de los productos europeos más baratos y la reducción del consumo. El comercio sufrió una notable disminución, la crisis generalizada y las guerras provocaron la decadencias de las ferias castellanas y del comercio con América. La Hacienda Real padeció una grave crisis, el aumento de los gastos de la corte y las continuas guerras, unidos a la disminución del oro y la plata procedentes de América, dejaron a la Real Hacienda en una situación crítica. La monarquía intentó salir de esta situación con subidas de impuestos y con la venta de títulos nobiliarios y cargos públicos a particulares, todas estas medidas tuvieron poco éxito. La población española había crecido de forma continuada durante el siglo XVI pero en el siglo XVII sufrió un grave estancamiento. Se estima que la población que en 1600 era de 8 700 000 habitantes quedó reducida a 7 000 000 al finalizar la centuria. Las causas principales eran las epidemias de peste, las inmigraciones al nuevo mundo, la expulsión de los moriscos y las permanentes guerras. La nobleza aumentó su número por la venta de títulos nobiliarios, ante la situación de crisis, los nobles aumentaron las obligaciones y tributos de los campesinos. El clero creció igualmente en efectivos pues mucha gente ingresaba en la vida religiosa sin vocación alguna, huyendo de la escasez y el hambre. Los grupos burgueses sufrieron gravemente el impacto de la crisis económica, al igual que los artesanos que vieron como se arruinaban muchas industrias. El enorme imperio de Felipe II fue heredado por Felipe III, monarca de escasas dotes políticas. La política interior de su reinado se caracterizó por la figura del valido y su política exterior por la búsqueda de la paz tras un período de continuas guerras. Felipe III fue un rey de carácter débil que inauguró la práctica de delegar los asuntos de gobiernos a un ministro o hombre denominado favorito o valido. El valido de Felipe III fue el Duque de Lerma, preocupado más por sus intereses que por los asuntos de gobierno y que fue sustituido en 1618 por su hijo, el Duque de Uceda. Durante este reinado siguieron agravándose los problemas económicos, por ello en 1607 se produjo una nueva bancarrota. Una de las medidas adoptadas por el duque de Lerma fue la expulsión de los moriscos en el año 1609, decisión que tuvo unos efectos demográficos y económicos desastrosos. A Felipe III lo sucedió su hijo Felipe IV, el cual delegó en el valido, conde-duque de Olivares cuyo objetivo prioritario era lograr la hegemonía de Europa, para ello necesitaba realizar reformas en la monarquía a fin de que todos los territorios contribuyesen a los gastos, pues estos recaían mayoritariamente en la Corona de Castilla, dicho proyecto recibió el nombre de Gran Memorial y fue presentado en 1624. Olivares aumentó los impuestos, trató de recortar la autonomía y de repartir los gastos militares entre todos los reinos peninsulares mediante su proyecto de Unión de Armas. Las medidas de Olivares provocaron la sublevación de Cataluña en 1640 que pidió ayuda a Francia, además en Portugal el Duque de Braganza se autoproclamó rey, ratificando la independencia. Todo esto provocó unas grandes guerras que lograron recuperar Cataluña en 1652, pero no así Portugal que firmó la independencia con la monarquía hispánica en 1668.

Durante la mayor parte del siglo, los matemáticos comenzaron a aplicar medidas cuantitativas la medición de fenómenos físicos en la Tierra. Galileo sostenía firmemente que las matemáticas proporcionaban una especie de certidumbre necesaria que se podía comparar con la de Dios: "... con respecto a esas pocas [ proposiciones matemáticas] que el entendimiento humano entiende, creo que su conocimiento es igual al Divino en certeza objetiva..."

Si bien los filósofos naturalistas medievales usaban problemas matemáticos, limitaban los estudios sociales a análisis teóricos de la velocidad local y otros aspectos de la vida. La medición actual de una cantidad física y la comparación de esa medida con un valor calculado sobre la base de la teoría, fue limitada en gran parte a las disciplinas matemáticas de la astronomía y la óptica en Europa.

Aristóteles reconoció cuatro tipos de causas, y donde sea aplicable, la más importante de ellas es la "causa final". La causa final fue el objetivo, el objetivo o el propósito de algún proceso natural o hecho por el hombre. Hasta la revolución científica, era muy natural ver tales objetivos, como por ejemplo, el crecimiento de un niño, conduciendo a un adulto maduro. La inteligencia fue asumida solo en el propósito de los artefactos artificiales; no fue atribuido ni a otros animales ni a la naturaleza.

En la "filosofía mecánica" o Mecanicismo no se permite ningún campo o acción a distancia, las partículas o corpúsculos de materia son fundamentalmente inertes. El movimiento es causado por colisión física directa. Cuando las sustancias naturales habían sido previamente entendidas como de naturaleza orgánica, los filósofos mecánicos las consideraban máquinas. Como resultado, la teoría de Isaac Newton parecía una especie de retroceso hacia la "acción espeluznante a distancia". Según Thomas Kuhn, él y Descartes sostuvieron el principio teleológico de que Dios conservó la cantidad de movimiento en el universo:

""La gravedad, interpretada como una atracción innata entre cada par de partículas de materia, era una cualidad oculta en el mismo sentido en que había sido la "tendencia a caer" de los escolásticos... A mediados del siglo XVIII esa interpretación había sido casi universalmente aceptada, y el resultado fue una reversión genuina (que no es lo mismo que un retroceso) a un estándar escolástico. Las atracciones innatas y las repulsiones unían el tamaño, la forma, la posición y el movimiento como propiedades primarias físicamente irreducibles de la materia"."

Newton también había atribuido específicamente el poder inherente de la inercia a la materia, contra la tesis mecanicista de que la materia no tiene poderes inherentes. Pero mientras que Newton negaba vehementemente la gravedad fuera un poder inherente de la materia, su colaborador Roger Cotes hizo de la gravedad también un poder inherente de la materia, según lo establecido en su prefacio famoso a la segunda edición de 1713 de "Principia" que él corrigió y que contradecía al mismo Newton. Y fue la interpretación de Cotes de la gravedad más que la de Newton la que llegó a ser aceptada.

Se realizó un importante trabajo en el campo de la óptica. En 1604. Johannes Kepler publicó "Astronomiae Pars Optica". En él describió la ley del cuadrado inverso que gobierna la intensidad de la luz, la reflexión por los espejos planos y curvos, y los principios de las Cámara estenopeicas, así como también implicaciones astronómicas de la óptica como el paralaje y el tamaño aparente de los cuerpos celestes. Generalmente, "Astronomiae Pars Optica" se reconoce como la fundación de la óptica moderna (aunque la ley de refracción está visiblemente ausente).

Willebrord Snellius (1580-1626) encontró en 1621 la ley matemática de la refracción, conocida en el siglo XX y XXI como la ley de Snell. Posteriormente, René Descartes (1596-1650) mostró, usando la construcción geométrica y la ley de la refracción (también conocida como la ley de Descartes) , que el radio angular de un arco iris es de 42° (es decir, el ángulo subtendido en el ojo por el borde del arco iris y el centro del arco iris es 42°).​ También descubrió independientemente la ley de la reflexión, y su ensayo en la óptica fue la primera mención publicada de esta ley.

Christiaan Huygens (1629-1695) escribió varios trabajos en el área de la óptica. Estos incluyeron "Opera reliqua" (también conocido como "Christiani Hugenii Zuilichemii, dum viveret Zelhemii toparchae, opuscula posthuma") y el "Traité de la lumière".

Isaac Newton investigó la refracción de la luz, demostrando que un prisma podría descomponer la luz blanca en un espectro de colores, y que una lente y un segundo prisma podrían recomponer el espectro multicolor en luz blanca. También demostró que la luz coloreada no cambia sus propiedades separando un haz coloreado y brillando en varios objetos. Newton señaló que, independientemente de si se reflejaba, se dispersaba o se transmitía, permanecía del mismo color. De este modo, observó que el color es el resultado de que los objetos interactúan con la luz ya coloreada en lugar de los objetos que generan el color. Esto se conoce como la teoría del color de Newton. De este trabajo llegó a la conclusión de que cualquier telescopio refractor sufriría la dispersión de la luz en colores. El interés de la Royal Society le animó a publicar sus notas "On Colour" (más tarde expandidas en "Opticks"). Newton argumentó que la luz está compuesta por partículas o corpúsculos y estos se refractaban acelerando hacia el medio más denso, pero tuvo que asociarlas con ondas para explicar la difracción de la luz.

En su "Hipótesis de Luz" de 1675, Newton postuló la existencia del éter para transmitir fuerzas entre partículas. En 1704, Newton publicó "Opticks", donde expuso su teoría corpuscular de la luz. Consideraba que la luz estaba compuesta de corpúsculos extremadamente sutiles, que la materia ordinaria estaba hecha de corpúsculos más gruesos y especulaba que mediante una especie de transmutación alquímica "¿No son convertibles los cuerpos gruesos y la luz unos en otros? ...y los cuerpos no pueden recibir mucha de su actividad de las Partículas de Luz que entran en su Composición?"

El Dr. William Gilbert, en "De Magnete", inventó la nueva palabra latina "electricus" de "ἤλεκτρον" ("elektron"), la palabra griega para "ámbar". Gilbert emprendió una serie de cuidadosos experimentos eléctricos, en el curso de los cuales descubrió que muchas sustancias distintas del ámbar, como el azufre, la cera, el vidrio, etc.,​ eran capaces de manifestar propiedades eléctricas. Gilbert también descubrió que un cuerpo calentado perdía su electricidad y que la humedad impedía la electrificación de todos los cuerpos, debido al ahora bien conocido hecho de que la humedad alteraba el aislamiento de tales cuerpos. También notó que las sustancias electrificadas atraían indiscriminadamente todas las demás sustancias, mientras que un imán solo atraía el hierro. Los muchos descubrimientos de esta naturaleza le ganaron a Gilbert el título de "fundador de la ciencia eléctrica".​ Al investigar las fuerzas sobre una aguja metálica ligera, equilibrada en un punto, amplió la lista de cuerpos eléctricos y encontró también que muchas sustancias, incluyendo metales y imanes naturales, no mostraban fuerzas atractivas cuando se frotaban. Observó que el tiempo seco con viento del norte o del este era la condición atmosférica más favorable para exhibir fenómenos eléctricos -una observación susceptible de conceptos erróneos hasta que se entendiera la diferencia entre el conductor y el aislante.

Robert Boyle también trabajó frecuentemente en la nueva ciencia de la electricidad, y añadió varias sustancias a la lista de eléctricos de Gilbert. Dejó un relato detallado de sus investigaciones bajo el título de "Experiments on the Origin of Electricity" (Experimentos sobre el origen de la electricidad).​ Boyle, en 1675, declaró que la atracción eléctrica y la repulsión pueden actuar a través del vacío. Uno de sus descubrimientos importantes fue que los cuerpos electrificados en el vacío atraerían sustancias ligeras, lo que indica que el efecto eléctrico no dependía del aire como medio. También añadió resina a la entonces conocida lista de eléctricos.​​​​
Esto fue seguido en 1660 por Otto von Guericke, quien inventó un generador electrostático primitivo. A finales del siglo XVII, los investigadores habían desarrollado medios prácticos para generar electricidad por fricción con un generador electrostático, pero el desarrollo de las máquinas electrostáticas no comenzó en serio hasta el siglo XVIII, cuando se convirtieron en instrumentos fundamentales en los estudios sobre la nueva Ciencia de la electricidad. El primer uso de la palabra electricidad se atribuye a Sir Thomas Browne en su obra de 1646, "Pseudodoxia Epidemica". En 1729, Stephen Gray (1666-1736) demostró que la electricidad podría ser "transmitida" a través de filamentos metálicos.

Durante casi cinco milenios, el modelo geocéntrico de la Tierra como centro del universo era prácticamente aceptado por todos excepto por unos cuantos astrónomos. En la cosmología de Aristóteles, la localización central de la Tierra era tal vez menos significativa que su identificación como reino de imperfección, inconstancia, irregularidad y cambio, en contraposición a los "cielos" (Luna, Sol, planetas, estrellas) considerados perfectos y permanentes, inmutables, y en el pensamiento religioso, el reino de los seres celestiales. La Tierra estaba compuesta de material diferente, los cuatro elementos "tierra", "agua", "fuego" y "aire", mientras que lo suficientemente lejos por encima de su superficie (aproximadamente la órbita de la Luna), estaban los cielos compuestos de una sustancia diferente, el llamado "Éter". El modelo heliocéntrico que lo reemplazó implicaba no solo el desplazamiento radical de la Tierra hacia una órbita alrededor del Sol, sino que su compartición con los otros planetas implicaba un universo de componentes celestes hechos de las mismas sustancias cambiantes que la Tierra. Los movimientos celestiales ya no necesitaban ser gobernados por una perfección teórica, confinada a órbitas circulares.

El trabajo de Copérnico de 1543 sobre el modelo heliocéntrico del sistema solar intentó demostrar que el sol era el centro del universo. Pocos fueron molestados por esta sugerencia, y el papa y varios arzobispos estaban bastante interesados por este modelo pues deseaban más detalle. Posteriormente, su modelo fue utilizado para crear el calendario del papa Gregorio XIII.​ Sin embargo, la idea de que la tierra se movía alrededor del sol fue puesta en duda por la mayoría de los contemporáneos de Copérnico. Contradecía no solo la observación empírica, por la ausencia de una paralaje estelar observable,​ sino más significativamente en su momento, la autoridad de Aristóteles.

Los descubrimientos de Johannes Kepler y Galileo dieron credibilidad a la teoría. Kepler fue un astrónomo que, usando las observaciones exactas de Tycho Brahe, propuso que los planetas se mueven alrededor del sol no en órbitas circulares, sino en las elípticas. Junto con sus otras leyes del movimiento planetario, esto le permitió crear un modelo del sistema solar que era una mejora sobre el sistema original de Copérnico. Las principales contribuciones de Galileo a la aceptación del sistema heliocéntrico fueron su mecánica, las observaciones que hizo con su telescopio, así como su presentación detallada del caso para el sistema. Utilizando una teoría primitiva de la inercia, Galileo pudo explicar por qué las rocas que caen de una torre lo hacen hacia abajo incluso si la tierra gira. Sus observaciones de las lunas de Júpiter, las fases de Venus, las manchas en el sol y las montañas en la luna contribuyeron a desacreditar la filosofía aristotélica y la teoría ptolemaica del sistema solar. A través de sus descubrimientos combinados, el sistema heliocéntrico ganó apoyo, y a finales del siglo XVII fue generalmente aceptado por los astrónomos.

Este trabajo culminó en la obra de Isaac Newton. El "Principia" de Newton formuló las leyes del movimiento y la gravitación universal, que dominaron la visión de los científicos sobre el universo físico durante los próximos tres siglos. Derivando las leyes de movimiento planetario de Kepler a partir de su descripción matemática de la gravedad, y luego utilizando los mismos principios para explicar las trayectorias de los cometas, las mareas, la precesión de los equinoccios y otros fenómenos, Newton eliminó las últimas dudas sobre la validez del "modelo heliocéntrico" del cosmos. Este trabajo también demostró que el movimiento de los objetos sobre la Tierra y de los cuerpos celestes podría ser descrito por los mismos principios. Su predicción de que la Tierra debería tener la forma de un esferoide ovalado fue posteriormente reivindicada por otros científicos. Sus leyes de movimiento debían ser el fundamento sólido de la mecánica; su ley de la gravitación universal combinada con la mecánica terrestre y celestial en un gran sistema que parecía ser capaz de describir el mundo entero en fórmulas matemáticas.

Además de probar el modelo heliocéntrico, Newton también desarrolló la teoría de la gravitación. En 1679, comenzó a considerar la gravitación y su efecto sobre las órbitas de los planetas con referencia a las leyes de Kepler del movimiento planetario. Esto siguió tras la estimulación de un breve intercambio de cartas en 1679-80 con Robert Hooke, que había sido designado para manejar la correspondencia de la Royal Society y que abrió una correspondencia destinada a obtener contribuciones de Newton a las transacciones de la Royal Society.​ El despertar del interés de Newton en materias astronómicas recibió el estímulo adicional por la aparición de un cometa en el invierno de 1680-1681, el cual se correspondía con John Flamsteed.​ Después de los intercambios con Hooke, Newton elaboró demostraciones de que la forma elíptica de las órbitas planetarias resultaría de una fuerza centrípeta inversamente proporcional al cuadrado del radio vector (véase la ley de Newton de la gravitación universal - Historia y "De motu corporum in gyrum"). Newton comunicó sus resultados a Edmond Halley y a la Royal Society en "De motu corporum in gyrum," de 1684.​ Este tramo contenía el núcleo que Newton desarrolló y expandió para formar el "Principia".

El Principia fue publicado el 5 de julio de 1687 con el estímulo y la ayuda financiera de Edmond Halley.​ En esta obra, tres leyes universales del movimiento declaró las tres leyes universales del movimiento que contribuyeron a muchos avances durante la Revolución Industrial que siguieron y que no fueron mejoradas durante más de 200 años. Muchos de estos avances siguen siendo los fundamentos de las tecnologías no-relativistas en el mundo moderno. Usó la palabra latina "gravitas" (peso) para el efecto que se conocería como gravedad, y definió la ley de la gravitación universal.

El postulado de Newton de una fuerza invisible capaz de actuar sobre vastas distancias le llevó a ser criticado por introducir "organismos ocultos" en la ciencia. Posteriormente, en la segunda edición de los "Principia" (1713), Newton rechazó firmemente tales críticas en un General Scholium concluyente, escribiendo que era suficiente que los fenómenos implicaran una atracción gravitatoria, como lo hicieron; Pero hasta el momento no indicaron su causa, y era innecesario e inapropiado enmarcar hipótesis de cosas que no estaban implícitas en los fenómenos. (Aquí Newton usó lo que se convirtió en su famosa expresión "hipótesis no fingo"​).

En un punto fue necesaria la confrontación de dos sistemas (Descartes-Newton) contemporáneos en la concepción del mundo natural:


Tanto uno como otro daban por supuesto la exactitud de las leyes naturales deterministas fundadas en la voluntad de Dios creador. Pero mientras el determinismo de Descartes se justifica en el riguroso método de ideas a partir de hipótesis sobre las regularidades observadas, Newton constituía el fundamento de dichas regularidades y su necesidad en la propia «observación de los hechos». Mientras uno mantenía un concepto de ciencia «deductiva», el otro se presentaba como un verdadero «inductivista», Hypotheses non fingo.

La música barroca o música del Barroco es el estilo musical europeo, relacionado con la época cultural homónima, que abarcó todo el siglo. Es uno de los estilos de la generalmente llamada música clásica o culta europea, antecedido por la música del Renacimiento y seguido por la música del Clasicismo. Caracterizada por la aparición de la tonalidad y el uso del bajo continuo, la barroca fue la época en la que se crearon formas musicales como la sonata, el concierto y la ópera. Entre los músicos del Barroco destacan Johann Sebastian Bach, Georg Friedrich Händel, Antonio Vivaldi, Domenico Scarlatti, Georg Philipp Telemann, Jean-Baptiste Lully, Arcangelo Corelli, Claudio Monteverdi.
El término "barroco" se tomó de la arquitectura, donde designaba algo «retorcido», una construcción «pesada, elaborada, envuelta» (siendo el término original, «barrueco» o «berrueco», un lusismo que describía una "perla deformada" o "joya falsa"). En el siglo XVIII se usó en sentido peyorativo para describir las características del estilo musical del siglo anterior, que se consideraba «tosco, extraño, áspero y anticuado».

Las principales características de la música de la época barroca son:


Estilo surgido en plena lucha entre la Reforma luterana y la Contrarreforma católica, la música fue utilizada en el Barroco como medio de propaganda por las iglesias en competencia y por la alta nobleza, únicas instituciones (junto a algunas ciudades libres) capaces de mantener una capilla de músicos profesionales. La música se vuelve indispensable para cualquier actividad, por lo que el músico pasa a ser un sirviente más de los que acompañaban a los nobles. Producto de estos fines es, como en otras artes de la época, una estética expresiva y teatralizante: profusión en el uso de la ornamentación, dramatismo, uso de recursos para la pompa y esplendor en los espectáculos públicos, fuertes contrastes sonoros...

La transmisión de emociones se organizaba a través de la teoría de los afectos y la retórica, que transfiere conceptos de la oratoria tradicional a la composición del discurso musical. En los géneros vocales la música queda supeditada a la poesía, pues su propósito es el refuerzo en la transmisión del sentido y los sentimientos ligados a la palabra; el espectáculo de mayor éxito, y que mejor resume el gusto y la estética de la época, será la ópera, fusión de poesía, música y teatro. La claridad en la dicción de los textos es por ello condición fundamental, impuesta tanto en la música religiosa como en la teatral (aparición del estilo de recitativo).

La emancipación de la música instrumental respecto de la vocal conduce a una clara separación entre géneros instrumentales y géneros vocales. La música instrumental alcanzó pronto su madurez con la creación de formas como la sonata, el concierto y la suite, de gran trascendencia posterior.

Los géneros vocales eran divididos ya en la época entre teatrales y religiosos: entre los primeros se cuenta la gran creación del Barroco musical, la ópera, mientras a los religiosos se adscriben formas nuevas como el oratorio y la cantata, junto a antiguas como el motete y la misa.
Las corrientes humanistas, en particular la [Camerata Florentina], buscaban ya a finales del XVI una puesta al día del antiguo teatro griego, basándose sin embargo en formas musicales recientes, como el drama litúrgico, el drama pastoral, las comedias madrigalescas con figuras de la "commedia dell'arte" y los "intermezzi" teatrales. Los sucesivos experimentos en los que la música vocal se combinaba con danzas y escenas teatrales habladas forjaron finalmente un espectáculo musicalmente continuado, en que estas escenas habladas eran sustituidas por recitativos: había nacido la ópera. Entre las primeras se cuentan la "Dafne" de Jacopo Peri, de cuya música solo se conservan algunos fragmentos y cuyo tema fue significativamente tomado de "Las metamorfosis" de Ovidio, y "Eurídice", también de Jacopo Peri, esta sí conservada completa en su edición de 1600. Pero fue Monteverdi con su "Orfeo" (1607) quien consolidó la forma.

La evolución posterior y su fusión con otras formas músico-teatrales acabó convirtiendo a la ópera barroca en una representación teatral íntegramente musicada en la que se suceden números de cuatro tipos:





La ópera se impuso como el gran espectáculo de la época en toda Europa: además de en toda Italia, se representaron regularmente en lugares como Viena, Londres, Hamburgo, Dresde, Hannover, Múnich y París. Con la notable excepción de Francia, el italiano siguió siendo el idioma de los libretos, y la temática casi siempre mitológica: era la llamada "opera seria", arena del triunfo de los compositores con pretensiones de éxito del Barroco.

Paralelamente aparecieron géneros músico-teatrales más populares, en lengua vernácula, con personajes contemporáneos (a menudo de clase baja), tramas a veces humorísticas y pasajes hablados en lugar de recitativos. Estos espectáculos se introducían bien a modo de intermedio entre los actos de la ópera seria o bien como obras independientes; recibieron diversos nombres en cada país: "singspiel" (Alemania), zarzuela (España), "opera buffa" e "intermezzi" (Italia), "opéra-comique" (Francia), etc.

Musicalmente casi idéntico a la ópera (aunque con más énfasis en los coros), solía tener una temática religiosa y no era escenificado (esto es, era ejecutado al modo de las actuales "versiones de concierto"). A diferencia de la ópera, casi siempre en italiano, los oratorios solían escribirse en lengua vernácula. El más famoso ejemplo es "El Mesías" de Händel.

Un caso particular de oratorio, representado en las iglesias protestantes de la época, era la Pasión, obra de larga duración que relataba, en recitativo, el texto evangélico de la Pasión de Jesucristo, con arias y corales insertados. La "Pasión según San Mateo" de Bach es su más ilustre ejemplo.

La asunción de la monodia, el recitativo y el estilo concertante por la música de iglesia dio lugar a una nueva forma musical, la cantata, obra de uso litúrgico que intercalaba sinfonías instrumentales, recitativos, arias y coros. La composición y ejecución de nuevas cantatas religiosas en lengua vernácula era parte de las obligaciones cotidianas de los músicos de los países luteranos, caso de Bach en Leipzig: allí compuso más de doscientas.

Se escribieron también cantatas profanas, especie de minióperas de cámara habitualmente formadas por la secuencia "Recitativo-Aria-Recitativo-Aria". Con frecuencia tienen un carácter vanguardista por estar dirigidas a una audiencia selecta y culta. Aunque Alessandro Scarlatti fue el más prolífico autor del género,​ son sin embargo más conocidas la "Cantata del café" de Bach o las compuestas por Händel, en italiano, durante su estancia en Roma.
Una suite es una sucesión de movimientos o piezas de danza que se interpretan seguidas (en francés, "suite"). Su secuencia mínima clásica incluía:


A las que se podía añadir una obertura inicial más otras danzas tras la giga, elegidas libremente, como por ejemplo:


La literatura del siglo, se caracteriza por el triunfo de la ornamentación, los juegos de palabras, la búsqueda de la emoción y el placer estético. A diferencia del Renacimiento, el Barroco se caracteriza por la idea del desengaño y por el pesimismo. Las temáticas frecuentes en esta literatura son la vida como lucha, sueño o mentira y la fugacidad de los hechos humanos, plasmadas en un estilo suntuoso y recargado. La literatura barroca hace uso desmedido de la adjetivación, el hipérbaton, la elipsis, la metáfora, la perífrasis, la antítesis y las alusiones mitológicas.

La literatura barroca se manifestó en diferentes maneras, desde el Eufuismo de los poetas ingleses, el Preciosismo en Francia, el Marinismo en Italia, la Primera y Segunda escuela de Silesia en Alemania y el Conceptismo y Culteranismo en España. Entre los escritores barrocos están, en español Luis de Góngora, Francisco de Quevedo, Sor Juana, Bernardo de Balbuena; en catalán Francesc Fontanella, Francesc Vicenç Garcia, Josep Romaguera; en portugués António Vieira, Gregório de Matos, Francisco Rodrigues Lobo; en inglés, los poetas metafísicos John Donne, George Herbert, Andrew Marvell, Henry Vaughan, y en alemán Andreas Gryphius y Angelus Silesius.

En España el Barroco coincide con el Siglo de Oro. Dominan los temas amorosos, del honor, los religiosos (con la contrarreforma en marcha) y la sátira. En poesía la polémica entre Conceptismo y Culteranismo alterna con el descubrimiento de nuevas formas estróficas y la continuación del soneto renacentista. La novela vive una época de máximo esplendor, con las obras de Cervantes y gran cantidad de subgéneros (donde destaca la novela picaresca). En el teatro predominan las comedias y los "autos sacramentales" o dramatizaciones de pasajes bíblicos. Pedro Calderón de la Barca mezcla las normas de la comedia con los temas graves y hace evolucionar la tragedia hispánica.

La comedia burlesca barroca en lengua catalana contenía una serie de elementos singulares y característicos que la evidenciaban como un subgénero teatral diferente de lo que hasta ahora se había clasificado como "comedia de enredo". La comedia burlesca es la parodia de las comedias barrocas castellanas, es decir, una burla de los tópicos, personajes y de los recursos de la "comedia nueva" que promovió Lope de Vega en su tratado "Arte nuevo de hacer comedias en este tiempo" (1609). La deformación de todos estos elementos tan característicos de la escena española, los tópicos y los recursos escénicos eran entendidos por el público de la época como una manera exagerada e incoherente de romper el modelo impuesto por el teatro castellano. Los personajes nobles son ridiculizados, actúan de una manera inesperada por el público, utilizan un lenguaje grosero, juegos de palabras que crean situaciones ridículas, no faltan las descripciones escatológicas y grotescas ni los dobles sentidos obscenos. Incluye obras como "La gala està en son punt" (1625) de autor anónimo, y "La infanta Tellina i el rei Matarot" y "Los amors de Melisenda" del fraile Francesc Mulet.

La población del centro de España, la más numerosa densa y pujante y con la mayor densidad de ciudades grandes y medias, empieza a declinar desde 1580 y tiene un descenso prolongado durante el , debido entre otras causas a la emigración americana, las numerosas epidemias, un índice de celibato de hasta el 10% de la población y a la expulsión de los moriscos. La cornisa cantábrica y Cataluña mantienen algún crecimiento.

El centro de España pierde un millón de habitantes, pero en la periferia se mantiene la población, por lo que en conjunto disminuye probablemente en un millón de habitantes en la centuria y cambia su distribución geográfica: en el futuro, el centro estará despoblado, excepto Madrid; y la periferia, densamente poblada.

Así, en la época de la expulsión de los moriscos (1609-1610) se estiman habitantes, de ellos en la Corona de Aragón, mientras que para 1717 se estiman habitantes, en la Corona de Aragón, es decir, los mismos o más que en 1610. La despoblación se había producido en el centro.

El es de un esplendor sin parangón, debido a que permite este tiempo desligarse de las ataduras provenientes de la Edad Media.

El Renacimiento del es la puerta de entrada para que en los 100 años que corrieron de 1600 a 1700 la sociedad pudiese zafarse del viejo molde que implantaba métodos rígidos de comportamiento y actuación especialmente impuestos por la Iglesia.

Al romper estos viejos moldes se permitió salirse de la rigidez de las estructuras lineales e imprimir nuevas formas de movimiento especialmente en el campo de las artes, donde podrían ser la pintura, escultura y arquitectura. Este adelanto de imprimir movimiento, rescatar las formas celestiales por medio de la ornamentación, y el paso de lo estático a lo dinámico se contempla como el estilo barroco, que es un estilo moderno que deja atrás al manierismo del siglo precedente.

El barroco que se presenta en diferentes manifestaciones artísticas incluida la literatura en sus dos vertientes culteranismo y conceptismo, permite arraigar a la sociedad de entonces a un nuevo estilo de vida, en el que se adapta y acepta vivir bajo situaciones en constante cambio.

Algunas manifestaciones como puentes entre diferentes municipios como por ejemplo el puente de Roa-Riaza.








</doc>
<doc id="2654" url="https://es.wikipedia.org/wiki?curid=2654" title="Sedeniones">
Sedeniones

Los sedeniones forman un álgebra 16-dimensional sobre los números reales y se obtienen aplicando la Construcción de Cayley-Dickson sobre los octoniones.

Como en los octoniones, la multiplicación de sedeniones no es conmutativa, ni asociativa. Pero al contrario que los octoniones, los sedeniones no tienen ni siquiera la propiedad de ser un álgebra alternativa. Sin embargo, tienen la propiedad de ser potencia-asociativos.

Los sedeniones tienen el 1 como elemento neutro e inversas para la multiplicación, pero no son un álgebra de división, ya que tienen divisores del cero.

Todo sedenión es una combinación lineal de los sedeniones unitarios
1, "e", "e", "e", "e", "e", "e", "e", "e", "e", "e", "e", "e", "e", "e" y "e",
que forman la base del espacio vectorial de los sedeniones. La tabla de multiplicación de estos sedeniones unitarios es la siguiente.



</doc>
<doc id="2656" url="https://es.wikipedia.org/wiki?curid=2656" title="Sabiduría">
Sabiduría

La sabiduría es un carácter que se desarrolla con la aplicación de la inteligencia en la experiencia propia, obteniendo conclusiones que nos dan un mayor entendimiento, que a su vez nos capacitan para reflexionar, sacando conclusiones que nos dan discernimiento de la verdad, lo bueno y lo malo. La sabiduría y la moral se interrelacionan dando como resultado un individuo que actúa con buen juicio. Algunas veces se toma a la "sabiduría" como una forma especialmente bien desarrollada de sentido común. 

En ciencias de la información, la Sabiduría constituye el vértice de la pirámide constituida, de menor a mayor complejidad, por dato, información, conocimiento y sabiduría.

En la Sabiduría se destaca el juicio sano basado en conocimiento y entendimiento; la aptitud de valerse del conocimiento con éxito, y el entendimiento para resolver problemas, evitar o impedir peligros, alcanzar ciertas metas, o aconsejar a otros. Es lo opuesto a la tontedad, la estupidez y la locura, y a menudo se contrasta con estas. Tomás de Aquino define la sabiduría como "el conocimiento cierto de las causas más profundas de todo" ("In Metaphysica", I, 2). Por eso, para él, la sabiduría tiene como función propia ordenar y juzgar todos los conocimientos.

La sabiduría toma sus referencias de lo que se denomina memoria a largo plazo. En otras palabras, lo vivido ha de haberse experimentado con suficiente frecuencia o intensidad como para que no se borre de nuestro recuerdo, se inserte en los esquemas de lo que consideramos bueno o malo y se tome en cuenta como parte de los procesos de supervivencia del individuo.

La mayoría de los psicólogos consideran la "sabiduría" como distinta de las habilidades cognitivas medidas por los exámenes de inteligencia. La "sabiduría" es con frecuencia considerada como un rasgo que puede ser desarrollado por la experiencia, pero no enseñado. Cuando se aplica a asuntos prácticos, la palabra "sabiduría" es sinónimo de prudencia. Algunos consideran la sabiduría como una cualidad que incluso un niño, de otra forma inmaduro, puede poseer con independencia de la experiencia o el conocimiento completo. 
La Sabiduría según una definición muy explícita de la misma es: «La forma correcta de aplicar el conocimiento» y va mucho más allá que el mismo intelecto, mostrando así lo elemental de la Vida. 

La cultura contemporánea limita la importancia de la "sabiduría" y de la intuición.

El nivel de la "sabiduría" o la prudencia como una virtud es reconocida en fuentes culturales, filosóficas y religiosas. Algunos definen la "sabiduría" en un sentido utilitario, como una forma de prever las consecuencias y actuar para maximizar el bien común a largo plazo.

La sabiduría implica amplitud de conocimiento y profundidad de entendimiento, que son los que aportan la sensatez y claridad de juicio que la caracterizan. El hombre sabio ‘atesora conocimiento’ y así tiene un fondo al que recurrir. (Pr 10:14.) Aunque la “sabiduría es la cosa principal”, el consejo es: “Con todo lo que adquieres, adquiere entendimiento”. (Pr 4:5-7.) El entendimiento (término amplio que con frecuencia abarca el discernimiento) añade fuerza a la sabiduría, contribuyendo en gran manera a la discreción y la previsión, cualidades que también son características notables de la sabiduría. La discreción supone prudencia, y se puede expresar en forma de cautela, autodominio, moderación o comedimiento. El hombre “discreto [una forma de fró·ni·mos]” edifica su casa sobre la masa rocosa, previendo la posibilidad de una tormenta; el insensato la edifica sobre la arena y experimenta desastre. (Mt 7:24-27.)

El término hebreo jokj·máh (verbo, ja·kjám) y el griego so·fí·a, así como sus afines, son los vocablos básicos que comunican el concepto de “sabiduría”. También está la palabra hebrea tu·schi·yáh, que se puede traducir por “trabajo eficaz” o “sabiduría práctica”, y las palabras griegas fró·ni·mos y fró·nē·sis (de frēn, la “mente”), que se refieren a la “sensatez”, “discreción” o “sabiduría práctica”.


</doc>
<doc id="2661" url="https://es.wikipedia.org/wiki?curid=2661" title="Sinclair ZX Spectrum">
Sinclair ZX Spectrum

El Sinclair ZX Spectrum es un ordenador de 8 bits basado en el microprocesador Zilog Z80A, fabricado por la compañía británica Sinclair Research y lanzado al mercado el 23 de abril de 1982.

En Europa, el "Sinclair ZX Spectrum" fue uno de los microordenadores domésticos más populares de los años 1980.

Su optimizado y compacto diseño hizo las delicias de miles de aficionados a la informática y los videojuegos. Aún hoy perduran miles de fanes del Spectrum que siguen jugando a sus juegos (con emuladores que cargan sus ficheros volcados de cintas). Además hay un mercado de coleccionismo tanto de cintas de juegos originales como de los propios Spectrum.

Las características del ZX Spectrum original incluían:






Posteriormente se desarrolló una nueva carcasa, que consistía en un teclado mejorado con teclas duras y 4 capas de membrana, para permitir la pulsación de dos teclas de función en una sola, y la carcasa más profesional, con bordes cuadrados en lugar de redondeados, que llevó el nombre de ZX Spectrum + (ZX Spectrum Plus). Este desarrollo también se vendió como actualización y solía incluirse junto con una ampliación de memoria para los Spectrum de 16 kB, que añadía un botón de "reset" y una mejor ventilación.

En definitiva, el diseño del ordenador estaba increíblemente optimizado y exprimía sus aparentemente pequeñas posibilidades al máximo. Todas estas características convertían al ZX Spectrum en un equipo muy asequible y versátil, consiguiendo acercar la microinformática a un elevado número de personas.

Una de las peculiaridades del ZX Spectrum es su sistema de vídeo, al ser capaz de mostrar una matriz de 256x192 pixeles, pero la resolución de color era únicamente de 32x24, por lo que grupos de 8x8 píxeles compartían información de color.

Dicha información de color o atributos consistían en: Color de fondo o "paper", color de tinta o "ink", atributo de brillo, y un atributo flash.

El "color de fondo" se aplica a los "pixels 0", y el "color de tinta" que se aplica a los "pixels 1", pudiendo seleccionarse cada uno entre siete colores.

El atributo "brillo" aumentaba el brillo de los colores (excepto el negro, que no variaba), por lo que en pantalla podían mostrarse en total hasta 15 colores (siete por dos niveles de brillo, más el negro)

El atributo "flash" hacía que los dos atributos de color "fondo/tinta" se intercambiasen varias veces por segundo, dando un efecto de parpadeo.

Así, tenemos 256x192 = 49152 bits = 6144 bytes destinados al bitmap (2048 bytes para cada tercio de pantalla) y 32x24 = 768 bytes dedicados al color, brillo, y flash, totalizando un total de 6912 bytes.

El problema de tener distintas resoluciones para el bitmap y el color obligaba a los programadores de juegos, especialmente durante las últimas etapas de vigencia del ordenador, a adoptar soluciones ingeniosas para minimizar las colisiones entre colores, fenómeno conocido como "attribute clash" en el mundo anglosajón. Esto era debido a que el ZX-Spectrum no fue concebido en origen como una máquina de videojuegos. Si bien el "attribute clash" permitía reducir el tamaño necesario para vídeo a 6,75 kB, esto hacía que algunos de los gráficos mostrados tuvieran una apariencia de poca calidad si el diseño no era minucioso.

El hardware fue diseñado por Richard Altwasser y la carcasa y apariencia es un diseño de Rick Dickinson. El software (firmware de la ROM), así como el profuso manual de instrucciones fue obra de Steve Vickers. Todos ellos habían participado en el diseño de los modelos anteriores de Sinclair, el ZX80 y el ZX81.

En abril de 1982 aparecieron dos modelos: uno con 16 Kb a un precio de 125 libras (ampliable a 48 Kb por 60 libras) y otro con 48 Kb de fábrica por 175 libras. Con la salida de imagen en color y con un sonido muy aceptable, destacaba su pequeño tamaño y su teclado con teclas de goma dura que mantenía la tradicional forma de los modelos anteriores de presentar palabras completas con pulsaciones.

Con un precio tan ajustado, sobre todo comparado con los modelos de la competencia en el momento, los pedidos se dispararon y Sinclair y la empresa ensambladora de la máquina, Timex, no daban abasto. En julio de 1982 ya había 30.000 pedidos pendientes de atender y a finales de agosto (debido a las vacaciones de verano de la plantilla que fueron escrupulosamente respetadas) ya eran 40.000 pedidos retrasados con la consiguiente molestia de muchos compradores. El propio Clive Sinclair hizo una disculpa pública en los medios de comunicación y se comprometió a tener los pedidos entregados en septiembre de ese mismo año, cosa que cumplió.

En marzo de 1983 ya se habían vendido más de 200.000 unidades del ZX-Spectrum, y el mercado de los videojuegos domésticos se había convertido en un rentable fenómeno a nivel mundial. Sinclair Research Ltd. se convirtió en apenas unos meses en una de las compañías del sector más sólidas y con más valor del momento. El precio de sus máquinas descendió hasta 99,95 libras para el ZX-Spectrum de 16 Kb, 129,95 libras para el ZX-Spectrum 48 Kb y 39,95 libras para el anterior modelo, el ZX81. 

En 1981, Altwasser y Vickers se desvincularon de Sinclair para formar su propia compañía, a la cual llamarían Jupiter Cantab (una abreviatura de Cantabridgian). Allí lanzaron al mercado una máquina de idéntica arquitectura a la empleada en la compañía de la que salían, el Jupiter Ace, que sin embargo no tuvo prácticamente repercusión (apenas se comercializaron unas 5.000 unidades).

Con el paso de los años fueron apareciendo diversos periféricos, como por ejemplo dispositivos de almacenamiento propios (ZX Microdrive), interfaces de disco (OPUS Discovery, DISCiPLE, Beta Disk), lápices ópticos, ratones (AMX Mouse, Kempston Mouse, Star Mouse), impresoras (la ZX Printer apareció durante 1983 a un precio inicial de 39,95 libras), o mandos de juego (joysticks) que podían ser conectados directamente, por medio de la ZX Interface 2 o a través de otras interfaces que salieron posteriormente al mercado, como las de Kempston Micro Electronics.

El software del ZX Spectrum se compone actualmente de más de 20.000 títulos. A pesar de que el hardware del ZX Spectrum imponía unos límites y restricciones notables, su software era muy diverso, incluyendo implementaciones de muchos lenguajes de programación, entre ellos C, Pascal, Prolog (ej: "micro-PROLOG"), Modula-2, LISP, o Forth, diversos ensambladores/desensambladores de Z80 (ej: "OCP Editor/Assembler", "HiSoft Devpac", "ZEUS Assembler", "Artic Assembler)", compiladores de Sinclair BASIC (ej: "MCoder", "COLT, HiSoft BASIC"), extensiones del Sinclair BASIC (ej: "Beta BASIC", "Mega Basic"), programas de bases de datos (ej: "VU-File"), procesadores de texto (ej: "Tasword II"), hojas de cálculo (ej: "VU-Calc"), programas de diseño gráfico (ej: "OCP Art Studio", "The Artist", "Paintbox", "Melbourne Draw"), y de modelado 3D ("VU-3D"), aparte de, principalmente, videojuegos.

El Spectrum +128 fue fabricado en España por Investrónica, la filial de El Corte Inglés de distribución y fabricación de ordenadores, y distribuidora oficial de Sinclair Research. Investrónica también había distribuido bajo marca propia (InvesDisk) un interface de disco junto con el sistema TOS para el ZX Spectrum, desarrollado y comercializado por Timex Computer, la filial de Timex en Portugal. El desarrollo conjunto se realiza en la sede española y es por ello que en 1985 aparece primero en España.

El modelo de 128K podía funcionar en modo 48 KB o 128 KB. La mayoría de los programas comerciales se ejecutaban en el modo 48K, pero en los últimos tiempos aparecieron programas comerciales que eran compatibles con las dos versiones. Incorporaba un chip de sonido AY-3-8912 (el mismo que Timex incluiría en sus modelos de Spectrum unos años antes), además de un pequeño teclado numérico anexo pero independiente, y un editor de textos integrado en el sistema operativo firmware. Sin embargo, en la versión inglesa fueron eliminados dicho teclado numérico y el editor de texto, introduciendo en el manejo del sistema operativo un conjunto de menús que mantendrían posteriormente los modelos de Amstrad. Otra característica exclusiva para el mercado español fue el soporte de caracteres españoles, pudiendo mostrar tanto la letra eñe como la apertura de interrogación y exclamación. El principal motivo para este cambio fue una ley que obligaba a que todos los ordenadores que se comercializasen en España pudiesen mostrar dichos caracteres.

Internamente, los 128 KB se dividían en ocho páginas de 16 KB cada una, numeradas de 0 a 7. Los 64 KB de espacio de direccionamiento del procesador Z80 también se dividían en cuatro bloques de 16 KB cada uno. Finalmente, los 32 KB de ROM se dividían en dos páginas de 16 KB cada una, numeradas de 0 a 1. En el primer bloque del espacio de direcciones (direcciones 0 a 16383) podía seleccionarse cualquiera de las dos páginas de la ROM; en el segundo bloque (direcciones 16384 a 32767) estaba la página 5 de RAM; en el tercer bloque (direcciones 32768 a 49151) la página 2 de RAM; por último, en el cuarto bloque (direcciones 49152 a 65535) podía estar cualquiera de las ocho páginas. Cuando se ejecutaba un programa en BASIC y en el modo 48K, la página activa era la 0, y la 7 se utilizaba como memoria temporal para el editor de textos y de BASIC. La única manera de acceder a la memoria RAM por encima de los 64 KB era mediante un ""Disco RAM"": un disco simulado sobre la memoria RAM extra que permitía grabar y cargar datos instantáneamente.

A mayores, las versiones +2A/B y +3 incorporaban modos extra que permitían mapear páginas de RAM en los 64 kB direccionables, pudiendo así sustituir la memoria ROM por RAM y disponer de la totalidad del espacio de direcciones. Cuatro modos estaban disponibles: páginas 0, 1, 2 y 3, páginas 4, 5, 6 y 7, páginas 4, 5, 6 y 3, y páginas 4, 7, 6 y 3. Además, estos modelos tenían 64 KB de ROM para poder incluir el sistema de disco (+3DOS).

Pese a los cambios, mantenía bastante compatibilidad con los hardware periféricos desarrollados para los modelos de 48 KB. 

En los juegos, especialmente cuando se ejecutaban en el modo 128, se podía disponer de las mejoras del modelo, como la carga de varias fases en RAM. En el modo de 48 kB únicamente, el mapeado de memoria estaba inhabilitado, por lo que el chip AY-3-8912 se podía seguir utilizando, no así la memoria adicional.

El sistema de gráficos incluía un sistema de doble buffer que permitía seleccionar la memoria de representación entre la página 5 y la 7, lo que posibilitaba cambiar instantáneamente de pantalla permitiendo algunos trucos gráficos, como poder dibujar en la "pantalla shadow" y mostrarla justo al terminar de dibujarse, sin que se apreciara como se dibujaba progresivamente. Esta característica se podía utilizar para mostrar gráficos con mayor riqueza visual (aumentando la resolución vertical o emulando una mayor paleta gráfica). El empleo de esta característica requería el uso de 13,5 kB de memoria.

En 1986, la compañía Sinclair Research vendió a Amstrad, por 5 millones de libras, la marca comercial Sinclair y su línea de productos informáticos. A partir de ese momento Amstrad procedió a sacar al mercado los siguientes modelos:




En 1992 Amstrad decidió retirar los modelos de Spectrum del mercado, ante la popularización de las máquinas de 16 y 32 bits.

A mediados de 1982, Timex obtuvo la licencia para vender todos los productos Sinclair en Estados Unidos cediéndoles el derecho de usar su nombre por una comisión del 5% sobre las ventas y comenzando a vender productos bajo la marca Timex Sinclair que finalmente llegarían a comercializarse a través de varias filiales también en Argentina, Polonia y Portugal. La filial estadounidense lanzó el Timex Sinclair 1000 y el Timex Sinclair 1500 (ambos basados en el Sinclair ZX81) y el Timex Sinclair 2068 (basado en el ZX Spectrum). Por su parte la filial portuguesa lanzó el Timex Computer 2048 (basado también en el ZX Spectrum) y el Timex Computer 2068 (basado en el Timex Sinclair 2068). A partir de esta última máquina, y producto de un acuerdo entre Polish Unimor y Timex Computer fue desarrollado solo para el mercado polaco también el Unipolbrit Komputer 2086.

A modo de ejemplo de las diferencias entre los modelos Sinclair y Timex, el TS2068 fue lanzado a fines de 1983 (antes del cierre de la filial estadounidense, a mediados de 1984), está dotada de un puerto para poner cartuchos con software, dos entradas para joysticks, un chip de sonido AY-3-8912 (el mismo que posteriormente se adoptaría para los modelos de 128Kb de Sinclair y Amstrad), una extensión de ROM de 8 KB que incluía nuevos comandos para el Sinclair BASIC y dos modos de vídeo: un modo extendido en color de 32x192 (contra los 32x24 originales del Spectrum) y un modo monocromático de 512x192 píxeles. Dentro de esta línea de mejoras al modelo original de Sinclair, se llegó en 1987 a desarrollar prototipos de una versión mejorada, el Timex Computer 3256, que finalmente no llegaría a ser lanzado al mercado.

La comercialización de los ordenadores de la serie Timex Sinclair se prologaría hasta 1989, cuando Timex Computer de Portugal decidió salir del mercado informático.

En Europa, Asia y también América se fabricaron diversos clones basados en la exitosa máquina de Sinclair Research, como la serie TK (el TK 90X fue su principal representante) fabricado por la empresa brasileña Microdigital o el Inves Spectrum de la española Investrónica. En Argentina lo comercializó la empresa Czerweny bajo el nombre de CZ Spectrum.

Algunos ordenadores lanzados por otras compañías y basados también en el microprocesador Z80 (como el Enterprise 128 o Tatung Einstein) dispusieron también de periféricos que permitían ejecutar el software del Spectrum en ellos.

Adicionalmente, Amstrad trabajó en el sucesor del ZX Spectrum +3, denominado proyecto "Loki". Se trataba de un ordenador de 8 bits llevado al límite, con soporte de modos de vídeo más avanzados y memoria comparable a la de un ordenador de 16 bits. Dicho proyecto nunca llegó a finalizarse, debido al declive de los ordenadores de 8 bits.
Paralelamente la compañía Miles Gordon Technology desarrolló su propia propuesta como sucesor, el SAM Coupé. Con un procesador Z80 a 6 MHz y 256 KB de RAM, incluía una disquetera de 3,5" como dispositivo de almacenamiento.

En los países occidentales, tras su retirada del mercado en 1992, la plataforma Spectrum persistirá principalmente a través de programas emuladores, aunque surgirán iniciativas menores, como interfaces para disco duro IDE, soporte para CompactFlash, sistemas operativos alternativos o expansiones gráficas.
A finales de 2014 se anunció la aparición del Sinclair ZX Spectrum Vega, una vídeo consola basada en el Spectrum.

En los países del este europeo se desarrollarán en la década de 1990 varios ordenadores clónicos del Spectrum, muchas veces con ampliaciones diversas (Scorpion ZS 256, Pentagon 1024-SL, Kay 1024, Sprinter, ATM Turbo, Dubna 48K, Hobbit, Didaktik M, etc).

En abril de 2017 se lanzó mediante una campaña de Kickstarter el ZX Spectrum Next . Se trata de una versión actualizada y expandida del ZX Spectrum original, desarrollada mediante tecnología FPGA. El proyecto produjo dos versiones: La primera consistía únicamente en la placa base, basada en el proyecto TBBlue, que podía integrarse en carcasas y teclados originales del ZX Spectrum. La segunda versión incluía una nueva carcasa con teclado incorporado, diseñada expresamente por Rick Dickinson. A finales de 2017 se cumplió con éxito la primera parte del proyecto, cuando las placas base se enviaron a los usuarios . Después de varios retrasos y complicaciones en la producción industrial, la entrega definitiva del la versión con teclado se produjo en febrero de 2020 .




</doc>
<doc id="2665" url="https://es.wikipedia.org/wiki?curid=2665" title="SCADA">
SCADA

SCADA, acrónimo de Supervisory Control And Data Acquisition (Supervisión, Control y Adquisición de Datos) es un concepto que se emplea para realizar un software para ordenadores que permite controlar y supervisar procesos industriales a distancia. Facilita retroalimentación en tiempo real con los dispositivos de campo (sensores y actuadores), y controla el proceso automáticamente. Provee de toda la información que se genera en el proceso productivo (supervisión, control calidad, control de producción, almacenamiento de datos, etc.) y permite su gestión e intervención.

La realimentación, también denominada retroalimentación o feedback es, en una organización, el proceso de compartir observaciones, preocupaciones y sugerencias, con la intención de recabar información, a nivel individual o colectivo, para mejorar o modificar diversos aspectos del funcionamiento de una organización. La realimentación tiene que ser bidireccional de modo que la mejora continua sea posible, en el escalafón jerárquico, de arriba abajo y de abajo arriba.

En la teoría de control, la realimentación es un proceso por el que una cierta proporción de la señal de salida de un sistema se redirige de nuevo a la entrada. Esto es de uso frecuente para controlar el comportamiento dinámico del sistema. Los ejemplos de la realimentación se pueden encontrar en la mayoría de los sistemas complejos, tales como ingeniería, arquitectura, economía, sociología y biología.

Existen dos tipos de sistemas principalmente: los de lazo abierto o no realimentados y los de lazo cerrado o realimentados. Los sistemas de lazo cerrado funcionan de tal manera que hacen que la salida vuelva al principio para que se analice la diferencia con un valor de referencia y en una segunda opción la salida se vaya ajustando, así hasta que el error sea cero o por debajo de un umbral previamente definido. Cualquier sistema que tenga como objeto controlar una cantidad como por ejemplo temperatura, velocidad, presión, caudal, fuerza, posición, entre otras variables, son normalmente de lazo cerrado. Los sistemas de lazo abierto no se comparan a la variable controlada con una entrada de referencia. Cada ajuste de entrada determina una posición de funcionamiento fijo en los elementos de control (por ejemplo con temporizadores).

Es así que, la realimentación es un mecanismo o proceso cuya señal se mueve dentro de un sistema y vuelve al principio de este como en un bucle, que se llama "bucle de realimentación". En un sistema de control (que tiene entradas y salidas), parte de la señal de salida vuelve de nuevo al sistema como parte de su entrada; a esto se le llama "realimentación" o retroalimentación.

La realimentación comprende todas aquellas soluciones de aplicación que hacen referencia a la captura de información de un proceso o planta, no necesariamente industrial, para que, con esta información, sea posible realizar una serie de análisis o estudios con los que se pueden obtener valiosos indicadores que permitan una retroalimentación sobre un operador o sobre el propio proceso, tales como:



Este esquema es un ejemplo de la aplicación del sistema SCADA en áreas industriales. Estas áreas pueden ser:


Supervisión: acto de observar el trabajo o tareas de otro (individuo o máquina) que puede no conocer el tema en profundidad, supervisar no significa el control sobre el otro, sino el guiarlo en un contexto de trabajo, profesional o personal, es decir con fines correctivos y/o de modificación.

Automática: ciencia tecnológica que busca la incorporación de elementos de ejecución autónoma que emulan el comportamiento humano o incluso superior. 

Principales familias: autómatas, robots, controles de movimiento, adquisición de datos, visión artificial, etc.

PLC: Programmable Logic Controller, Controlador Lógico Programable.

PAC: Programmable Automation Controller, Controlador de Automatización Programable. 

Un sistema SCADA incluye un hardware de señal de entrada y salida, controladores, interfaz hombre-máquina (HMI), redes, comunicaciones, base de datos y software.

El término SCADA usualmente se refiere a un sistema central que supervisa y controla un sitio completo o una parte de un sitio que nos interesa controlar (el control puede ser sobre máquinas en general, depósitos, bombas, etc.) o finalmente un sistema que se extiende sobre una gran distancia (kilómetros / millas). La mayor parte del control del sitio es en realidad realizada automáticamente por una Unidad Terminal Remota (UTR), por un Controlador Lógico Programable (PLC) y más actualmente por un Controlador de Automatización Programable (PAC). Las funciones de control del servidor están casi siempre restringidas a reajustes básicos del sitio o capacidades de nivel de supervisión. Por ejemplo un PLC puede controlar el flujo de agua fría a través de un proceso, pero un sistema SCADA puede permitirle a un operador cambiar el punto de consigna (set point) de control para el flujo, y permitirá grabar y mostrar cualquier condición de alarma como la pérdida de un flujo o una alta temperatura. La realimentación del lazo de control es cerrada a través del RTU o el PLC; el sistema SCADA supervisa el desempeño general de dicho lazo.
El sistema SCADA también puede mostrar gráficos históricos, tendencias, tablas con alarmas y eventos entre otras funciones. Puede y debe estar sujeto a permisos y accesos de los usuarios y desarrolladores de acuerdo a su nivel jerárquico en la organización y la función que cumple dentro de esta.
Necesidades de la supervisión de procesos:

Una interfaz Hombre - Máquina o HMI ("Human Machine Interface") es el aparato que presenta los datos a un operador (humano) y a través del cual este controla el proceso.

Los sistemas HMI podemos pensarlos como una "ventana de un proceso". Esta ventana puede estar en dispositivos especiales como paneles de operador o en un ordenador. Los sistemas HMI en ordenadores se los conoce también como software (o aplicación) HMI o de monitorización y control de supervisión. Las señales del proceso son conducidas al HMI por medio de dispositivos como tarjetas de entrada/salida en el ordenador, PLC's (Controladores lógicos programables), PACs (Controlador de automatización programable ), RTU (Unidades remotas de I/O) o DRIVER's (Variadores de velocidad de motores). Todos estos dispositivos deben tener una comunicación que entienda el HMI.

La industria de HMI nació esencialmente de la necesidad de estandarizar la manera de monitorizar y de controlar múltiples sistemas remotos, PLCs y otros mecanismos de control. Aunque un PLC realiza automáticamente un control pre-programado sobre un proceso, normalmente se distribuyen a lo largo de toda la planta, haciendo difícil recoger los datos de manera manual, los sistemas SCADA lo hacen de manera automática. Históricamente los PLC no tienen una manera estándar de presentar la información al operador. La obtención de los datos por el sistema SCADA parte desde el PLC o desde otros controladores y se realiza por medio de algún tipo de red, posteriormente esta información es combinada y formateada. Un HMI puede tener también vínculos con una base de datos para proporcionar las tendencias, los datos de diagnóstico y manejo de la información así como un cronograma de procedimientos de mantenimiento, información logística, esquemas detallados para un sensor o máquina en particular, incluso sistemas expertos con guía de resolución de problemas. Desde cerca de 1998, virtualmente todos los productores principales de PLC ofrecen integración con sistemas HMI/SCADA, muchos de ellos usan protocolos de comunicaciones abiertos y no propietarios. Numerosos paquetes de HMI/SCADA de terceros ofrecen compatibilidad incorporada con la mayoría de PLCs.

SCADA es popular debido a esta compatibilidad y seguridad. Esta se usa desde aplicaciones a pequeñas escalas, como controladores de temperatura en un espacio, hasta aplicaciones muy grandes como el control de plantas nucleares.

La solución de SCADA a menudo tiene componentes de sistemas de control distribuido, DCS ("Distribuited Control System"). El uso de RTUs o PLCs o últimamente PACs sin involucrar computadoras maestras está aumentando, los cuales son autónomos ejecutando procesos de lógica simple. Frecuentemente se usa un lenguaje de programación funcional para crear programas que corran en estos RTUs y PLCs, siempre siguiendo los estándares de la norma IEC 61131-3. La complejidad y la naturaleza de este tipo de programación hace que los programadores necesiten cierta especialización y conocimiento sobre los actuadores que van a programar. Aunque la programación de estos elementos es ligeramente distinta a la programación tradicional, también se usan lenguajes que establecen procedimientos, como pueden ser FORTRAN, C o Ada95. Esto les permite a los ingenieros de sistemas SCADA implementar programas para ser ejecutados en RTUs

Los tres componentes de un sistema SCADA son:


La RTU se conecta al equipo físicamente y lee los datos de estado como los estados abierto/cerrado desde una válvula o un interruptor, lee las medidas como presión, flujo, voltaje o corriente. Por el equipo el RTU puede enviar señales que pueden controlarlo: abrirlo, cerrarlo, intercambiar la válvula o configurar la velocidad de la bomba, ponerla en marcha, pararla.

La RTU puede leer el estado de los datos digitales o medidas de datos analógicos y envía comandos digitales de salida o puntos de ajuste analógicos.

Una de las partes más importantes de la implementación de SCADA son las alarmas. Una alarma es un punto de estado digital que tiene cada valor NORMAL o ALARMA. La alarma se puede crear en cada paso que los requerimientos lo necesiten. Un ejemplo de una alarma es la luz de "tanque de combustible vacío"del automóvil. El operador de SCADA pone atención a la parte del sistema que lo requiera, por la alarma. Pueden enviarse por correo electrónico o mensajes de texto con la activación de una alarma, alertando al administrador o incluso al operador de SCADA.

El término "Estación Maestra" se refiere a los servidores y al software responsable para comunicarse con el equipo del campo (RTUs, PLCs, etc) en estos se encuentra el software HMI corriendo para las estaciones de trabajo en el cuarto de control, o en cualquier otro lado. En un sistema SCADA pequeño, la estación maestra puede estar en un solo computador. A gran escala, en los sistemas SCADA la estación maestra puede incluir muchos servidores, aplicaciones de software distribuido, y sitios de recuperación de desastres.

El sistema SCADA usualmente presenta la información al personal operativo de manera gráfica, en forma de un diagrama de representación. Esto significa que el operador puede ver un esquema que representa la planta que está siendo controlada. Por ejemplo un dibujo de una bomba conectada a la tubería puede mostrar al operador cuanto fluido está siendo bombeado desde la bomba a través de la tubería en un momento dado o bien el nivel de líquido de un tanque o si la válvula está abierta o cerrada. Los diagramas de representación puede consistir en gráficos de líneas y símbolos esquemáticos para representar los elementos del proceso, o pueden consistir en fotografías digitales de los equipos sobre los cuales se animan las secuencias.

Los bloques software de un SCADA (módulos), permiten actividades de adquisición, supervisión y control.


El paquete HMI para el sistema SCADA típicamente incluye un programa de dibujo con el cual los operadores o el personal de mantenimiento del sistema pueden cambiar la apariencia de la interfaz. Estas representaciones pueden ser tan simples como unas luces de tráfico en pantalla, las cuales representan el estado actual de un campo en el tráfico actual, o tan complejas como una pantalla de multiproyector representando posiciones de todos los elevadores en un rascacielos o todos los trenes de una vía férrea. Plataformas abiertas como GNU/Linux que no eran ampliamente usadas inicialmente, se usan debido al ambiente de desarrollo altamente dinámico y porque un cliente que tiene la capacidad de acomodarse en el campo del hardware y mecanismos a ser controlados que usualmente se venden UNIX o con licencias OpenVMS. Hoy todos los grandes sistemas son usados en los servidores de la estación maestra así como en las estaciones de trabajo HMI.

En vez de confiar en la intervención del operador o en la automatización de la estación maestra los RTU pueden ahora ser requeridos para operar ellos mismos, realizando su propio control sobre todo por temas de seguridad. El software de la estación maestra requiere hacer más análisis de datos antes de ser presentados a los operadores, incluyendo análisis históricos y análisis asociados con los requerimientos de la industria particular. Los requerimientos de seguridad están siendo aplicados en los sistemas como un todo e incluso el software de la estación maestra debe implementar los estándares más fuertes de seguridad en ciertos mercados.

Para algunas instalaciones, los costos que pueden derivar de los fallos de un sistema de control es extremadamente alto, es posible incluso que haya riesgo de herir a personas. El hardware del sistema SCADA es generalmente lo suficientemente robusto para resistir condiciones de temperatura, humedad, vibración y voltajes extremos pero en estas instalaciones es común aumentar la fiabilidad mediante hardware redundante y varios canales de comunicación. Una parte que falla puede ser fácilmente identificada y su funcionalidad puede ser automáticamente desarrollada por un hardware de backup. Una parte que falle puede ser reemplazada sin interrumpir el proceso. La confianza en cada sistema puede ser calculado estadísticamente y este estado es el significado de tiempo medio entre fallos, el cual es una variable que acumula tiempos entre fallas. El resultado calculado significa que el tiempo medio entre fallos de sistemas de alta fiabilidad puede ser de décadas.

Los sistemas SCADA tienen tradicionalmente una combinación de radios y señales directas seriales o conexiones de módem para conocer los requerimientos de comunicaciones, incluso Ethernet e IP sobre SONET (fibra óptica) es también frecuentemente usada en sitios muy grandes como ferrocarriles y estaciones de energía eléctrica. Es más, los métodos de conexión entre sistemas puede incluso que sea a través de comunicación wireless (por ejemplo si queremos enviar la señal a una PDA, a un teléfono móvil) y así no tener que emplear cables.

Para que la instalación de un SCADA sea perfectamente aprovechada, debe de cumplir varios objetivos:


Para desarrollar un sistema SCADA es necesario un IDE en el cual diseñar, entre otras cosas:
También funciona con los controladores lógicos establecidos por National Instrument tales como LABVIEW y MULTISIM PROTEUS entre otros incluso se establece conexión con micro controladores tales como el ARDUINO, haciendo a SCADA una herramienta bastante útil para los sistemas de control automatizado.
Así pues, una de las soluciones en el control SCADA es utilizar la aplicación creada junto con un programa para monitorizar, controlar y automatizar señales analógicas y digitales, capturadas a través de tarjetas de adquisición de datos. Uno de los programas más utilizados para este fin es el LabView (National Instruments).


Un SCADA sirve para supervisar y su principal objetivo es medir con la finalidad de corregir.

Tenemos un proceso químico, que puede ser desde una fábrica de gelatina, a una de antibióticos, que queremos supervisar.
Lo que pondremos en la planta de producción serán PLCs, HMIs, etc, lo que se denomina Nivel I, ó nivel básico de automatización. Los datos obtenidos por estos hardwares industriales son transportados a través de un bus o varios buses a un servidor (server), que es el supervisor, el que controla, mediante el mencionado SCADA. Este envío de datos se puede hacer a través de ethernet, por ejemplo. 

El servidor, a su tiempo, manda los datos a una base de datos con la finalidad de almacenar la información (para trabajar con ella, crear históricos de errores o alarmas). Esta base de datos puede estar integrada dentro del disco duro del propio servidor.
También es posible que el servidor mande la información a otro PC, PDA, Telf, Internet, es decir, transmita la información a otros sistemas operativos, en los cuales los clientes, accionistas, jefes, supervisores, pueden acceder a la información.

La información en tránsito puede concentrarse en Unidades Terminales Remotas, y viaja en el espacio mediante conmunicación satelital que es procesada, regularmente, por un Centro de Control y Monitoreo, y se pueden realizar movimientos operacionales con confirmaciones provenientes de los instrumentos puntuales (en sitio). En niveles superiores de SCADA, existe la cooperación con sistemas de administración como el ERP SAP, en los que se pueden registrar los datos para analizar y predecir el comportamiento de una línea de producción.




</doc>
<doc id="2667" url="https://es.wikipedia.org/wiki?curid=2667" title="SUSE Linux">
SUSE Linux

SUSE Linux es una de las distribuciones Linux existentes a nivel mundial, se basó en sus orígenes en Slackware. Entre las principales virtudes de esta distribución se encuentra el que sea una de las más sencillas de instalar y administrar, ya que cuenta con varios asistentes gráficos para completar diversas tareas en especial por su gran herramienta de instalación y configuración YasT.

Su nombre "SuSE" es el acrónimo, en alemán ""Software und Systementwicklung"", el cual formaba parte del nombre original de la compañía y que se podría traducir como "desarrollo de software y sistemas". El nombre actual de la compañía es "SuSE LINUX", habiendo perdido el primer término su significado (al menos oficialmente).

El 4 de noviembre de 2003, la compañía multinacional estadounidense Novell anunció que iba a comprar "SuSE LINUX". La adquisición se llevó a cabo en enero de 2004. En el año 2005, en la LinuxWorld, Novell, siguiendo los pasos de RedHat Inc., anunció la liberación de la distribución "SuSE Linux" para que la comunidad fuera la encargada del desarrollo de esta distribución, que ahora se denomina openSUSE.

El 4 de agosto de 2005, el portavoz de Novell y director de relaciones públicas "Bruce Lowry" anunció que el desarrollo de la serie "SUSE Professional" se convertiría en más abierto y entraría en el intento del proyecto de la comunidad openSUSE de alcanzar a una audiencia mayor de usuarios y desarrolladores. El software, por la definición de código abierto, tenía ya su código fuente "abierto", pero ahora el proceso de desarrollo sería más "abierto" que antes, permitiendo que los desarrolladores y usuarios probaran el producto y ayudaran a desarrollarlo.

Anteriormente, todo el trabajo de desarrollo era realizado por "SUSE", y la versión 10.0 fue la primera versión con una beta pública. Como parte del cambio, el acceso en línea al servidor YaST de actualización sería complementario para los usuarios de "SUSE Linux", y siguiendo la línea de la mayoría de distribuciones de código abierto, existiría tanto la descarga gratuita disponible mediante web como la venta del sistema operativo "en caja". Este cambio en la filosofía condujo al lanzamiento de "SUSE Linux" 10.0 el 6 de octubre de 2005 en "OSS" (código completamente abierto), "eval" (tiene tanto código abierto como aplicaciones propietarias y es una versión realmente completa) y al por menor en centros especializados.

Posteriormente, Novell fue adquirido por el 27 de abril de 2011, permaneciendo SUSE como una compañía separada. En junio de 2012, muchos de los antiguos ingenieros de SUSE que habían sido despedidos durante la propiedad de Novell volvieron a incorporarse al equipo.

El 20 de noviembre de 2014, The Attachmate Group y Micro Focus International finalizaron su fusión, convirtiendo a Micro Focus International en la nueva empresa matriz de SUSE. SUSE opera como una unidad de negocios semi-autónoma dentro del Micro Focus Group, con el expresidente Nils Brauckmann ascendido a director ejecutivo y miembro del grupo Micro Focus Group.

El 2 de julio de 2018, Micro Focus anunció la venta de SUSE a Blitz 18-679 GmbH, una subsidiaria de EQT Partners, por 2.535 millones de dólares.

"SUSE" incluye un programa único de instalación y administración llamado YaST2 que permite realizar actualizaciones, configurar la red y el cortafuegos, administrar a los usuarios, y muchas más opciones todas ellas integradas en una sola interfaz amigable. Además incluye varios escritorios, entre ellos los más conocidos que son KDE y Gnome, siendo el primero el escritorio por omisión. La distribución incorpora las herramientas necesarias para redistribuir el espacio del disco duro permitiendo así la coexistencia con otros sistemas operativos existentes en el mismo.

Usa sistemas de paquetes RPM (RPM package mánager) originalmente desarrollados por Red Hat aunque no guarda relación con esta distribución.

También es posible utilizar el sistema de instalación CNR (Click 'N Run) originalmente creado por la empresa que distribuía Lindows OS (que ahora se llama Linspire y Freespire en su versión gratuita). Este sistema sincroniza nuestra máquina al servidor CNR y al hacer clic en la página de navegación y alguno de los programas, este se instala de manera automática en el ordenador.
El sistema operativo SUSE Linux tiene integradas funciones para ayudar a administrar y gestionar servicios. Algunas de estas son (SUSE, 2014b):

- Revisión completa del sistema: permite obtener un snapshot del sistema, incluyendo los archivos de kernel y además realiza operaciones de revisión. Los administradores pueden iniciar el sistema a partir de dicha snapshot, lo que es una ventaja a la hora de fallos, seguimiento y comprobación de cambios.

- SUSE Linux Enterprise Live Patching: permite actualizar los parches de seguridad del sistema, sin necesidad de reiniciarlo. Con esto mejora la disponibilidad de las cargas de trabajo y hosts virtuales.

- Compatibilidad con KIWI: es una herramienta que permite crear imágenes del sistema operativo para implementaciones físicas (DVD, USB) o entornos hipervisores virtuales (Xen, KVM, VMWare, HyperV) y nubes públicas y privadas.

- Docker: es una tecnología de código abierto que permite automatizar la implementación de aplicaciones en contenedores de software.

- Wicked: herramienta para gestionar y administrar una red local como, por ejemplo: VLAN, virtualización, puentes, vinculación e IPV6.

Antiguamente, "SUSE" primero lanzaba las versiones personales y profesionales en paquetes que incluían una extensa documentación impresa y esperaba algunos meses antes de lanzar las versiones en sus servidores.

Comenzando con la versión 9.2, una imagen ISO de 1 DVD de "SUSE Professional" fue lanzada, así como una versión de evaluación del LiveDVD arrancable. El servidor FTP continúa funcionando y tiene la ventaja de las instalaciones en línea: sólo se descargan los paquetes que el usuario cree que necesita. La ISO tiene ventajas en cuanto a facilidad de instalación de paquetes de forma sencilla y sin conexión a Internet. Las distribuciones de DVD "en caja" soportan instalaciones x86 y x86-64, pero los CD-ROM incluidos no disponen de soporte para x86-64.
Desde la versión 9, es posible descargar el archivo ISO correspondiente a la distribución, pero después de ser instalado empieza un período de evaluación que inicialmente fue de 30 días y en las versiones posteriores es de 60 días. Este período permite usar en forma libre y gratuita los servicios de actualización de software de Novell, luego de lo cual se debe pagar una suscripción para obtener actualizaciones.







</doc>
<doc id="2671" url="https://es.wikipedia.org/wiki?curid=2671" title="Sumeria">
Sumeria

Sumeria (del acadio "Šumeru"; en sumerio cuneiforme 𒆠𒂗𒂠 "ki-en-gil", aproximadamente 'tierra, país', 'señor', cañaveral') es una región histórica de Oriente Medio, parte sur de la antigua Mesopotamia, entre las planicies aluviales de los ríos Éufrates y Tigris. La civilización sumeria está considerada como la primera civilización del mundo. Aunque la procedencia de sus habitantes, los sumerios, es incierta, existen numerosas hipótesis sobre sus orígenes, siendo la más aceptada actualmente la que argumenta que no habría ocurrido ninguna ruptura cultural con el período de Uruk, lo que descartaría factores externos, como podían ser invasiones o migraciones desde otros territorios lejanos.

El término "sumerio" también se aplica a todos los hablantes de la lengua sumeria. En dicha lengua, esta región era denominada "Kengi (ki)", equivalente al acadio "mat Sumeri", esto es, "tierra de Súmer".

El término "sumerio" es el nombre común dado a los antiguos habitantes de baja Mesopotamia por sus sucesores, los semitas acadios. Los sumerios se llamaban a sí mismos "sag-giga", que significa literalmente "el pueblo de cabezas negras". La palabra acadia "shumer" puede representar este nombre en el dialecto, pero se desconoce por qué los acadios llamaron "Shumeru" a las tierras del sur. Algunas palabras como la bíblica "Shinar", la egipcia "Sngr", o la Indoeuropea Hitita "Šanhar(a)" pueden haber sido variantes de "Šumer". De acuerdo al historiador babilonio Beroso, los sumerios fueron "extranjeros de cabezas negras".

En la Baja Mesopotamia:
asumiendo que existían asentamientos humanos desde el Neolítico como demuestra la cultura de Jarmo (6700 a. C.-6500 a. C.), y en el Calcolítico la cultura Hassuna-Samarra (5500 a. C.-5000 a. C.), El Obeid (5000 a. C.-4000 a. C.), Uruk (4000 a. C.-3200 a. C.) y Yemdet Nasr (3200 a. C.-3000 a. C.).

No existen registros escritos de esa etapa para conocer el origen de este pueblo, y tampoco los cráneos hallados en los enterramientos aclaran el problema de su origen, debido a que están representadas tanto la dolicocefalia como la braquicefalia, con algunos testimonios del tipo armenoide. Se investigan las esculturas sumerias que muestran un alto índice de cráneos braquicéfalos en sus representaciones que quizá podían dilucidar la procedencia de este pueblo, junto con las coloraciones y las dimensiones de las esculturas, que son una mezcla entre caucásicos y miembros de raza negra. Con todo esto no es suficiente evidencia para solucionar el problema puesto que la plástica podría haberlas idealizado, como pasaba en las esculturas egipcias.

Se ha descartado la posibilidad de identificación basada en la evolución de los tipos craneales en el conjunto del Oriente Medio, pues estos aparecen bastante mezclados. Sin embargo se pueden distinguir cuatro grandes grupos con rasgos pertenecientes a distintas épocas: antes de 4000 a. C. sólo se encuentran poblaciones dolicocéfalas del tipo "mediterráneo"; los "eurafricanos", que sólo son una variedad de este grupo, y que no tuvieron un papel apreciable hasta 3000 a. C.; el tipo "alpinos", braquicéfalos que se manifiestan moderadamente después de 2500 a. C., y los "armenoides", derivados tal vez de estos alpinos que aparecen en abundancia después de 500 a. C. Los pueblos descendientes de los cimerios tienden a tener en promedio las cabezas más "redondeadas" (braquicéfalas) que los demás pueblos de esa área y la palabra "sumerio" puede ser una transliteración de la palabra "cimerios" según algunos filólogos. Es por esto que varios investigadores creen que ambos pueblos son un mismo pueblo en diferentes épocas, pero no hay suficientes evidencias para sustentar esta hipótesis.

Parece posible que los sumerios fuesen una tribu proveniente de fuera, posiblemente de las estepas, pero su origen concreto es desconocido. Esto es lo que se ha venido denominando desde el siglo XX como el "problema sumerio."

En cualquier caso, es durante el período del Obeid cuando se producen avances que cristalizan en el período de Uruk, y que sirven para considerar este momento como el inicio de la civilización sumeria.

Algunos estudiosos también postulan que los sumerios establecidos en Mesopotamia, no tendrían un origen autóctono, sino que provendrían de la cultura que fundó la ciudad de Mohenjo-Daro (que existió entre el 2600 a. C. y el 1800 a. C.) en India.

Uruk, la "Erec" bíblica y la árabe "Warka", es el escenario de descubrimientos fundamentales para la historia de la humanidad: aparece la rueda en torno al 3500 a. C., y la escritura en el 3300 a. C., que es la datación más antigua de tablillas de arcilla con escritura cuneiforme encontrada hasta la fecha. Estos registros escritos confirman que los sumerios no eran un pueblo indoeuropeo, ni camita, ni semita, ni tampoco elamo-drávida (grupo, este último, al que pertenece el pueblo elamita, por ejemplo). Así lo demuestra su lengua de tipo aglutinante. No obstante, se especula, como se ha dicho, que los sumerios no fueron el primer pueblo en asentarse en la baja Mesopotamia, en el curso bajo del Creciente fértil, sino que llegaron en un determinado momento de la Edad del Cobre o Calcolítico, allá por el año 3500 antes de nuestra era, durante el período ahora denominado Uruk.

La difusión de los avances de la cultura de Uruk por el resto de Mesopotamia dio lugar al nacimiento de la cultura Sumeria. Estas técnicas permitieron la proliferación de las ciudades por nuevos territorios. Estas ciudades pronto se caracterizaron por la aparición de murallas, lo que parece indicar que las guerras entre ellas fueron frecuentes. También destaca la expansión de la escritura que saltó desde su papel administrativo y técnico hasta las primeras inscripciones dedicatorias en las estatuas consagradas de los templos.

Pese a la existencia de las listas reales sumerias la historia de este período es relativamente desconocida, ya que gran parte de los reinados expuestos en ellas tienen fechas imposibles. En realidad, estas listas se confeccionaron a partir del siglo XVII a. C., y su creación se debió probablemente al deseo de los monarcas de remontar su linaje hasta tiempos épicos. Algunos de los reyes son probablemente reales pero de muchos otros no hay constancia histórica y otros de los que se sabe su existencia no figuran en ellas.

Hacia 2350 a. C., Sargón, un usurpador de origen acadio, se hizo con el poder en la ciudad de Kiš. Fundó una nueva capital, Agadé y conquistó el resto de ciudades sumerias, venciendo a Lugalzagesi, el rey de Umma hasta entonces dominante. Este fue el primer gran Imperio de la historia y sería continuado por los sucesores de Sargón, que se tendrían que enfrentar a constantes revueltas. Entre ellos destacó el nieto del conquistador, Naram-Sin. Esta etapa marcó el inicio de la decadencia de la cultura e idioma sumerios en favor de los acadios.

El imperio se deshizo hacia el 2220 a. C., debido a las constantes revueltas y las invasiones de los nómadas amorreos y, principalmente, gutis. Tras su caída, toda la región cayó bajo el dominio de estas tribus, quienes se impusieron sobre las ciudades-estado de la región, especialmente en el entorno de la destruida Agadé. Las crónicas sumerias los describen constantemente de forma negativa, como "horda de bárbaros" o "dragones de montaña", pero es posible que la realidad no fuese tan negativa; en algunos centros se produjo un verdadero florecimiento de las artes. Es el caso de la ciudad de Lagaš, especialmente durante el gobierno del patesi Gudea. Además de la calidad artística, en las obras de Lagaš se utilizaron materiales provenientes de regiones lejanas: madera de cedro del Líbano o diorita, oro y cornalina del valle del Indo; lo que parece indicar que el comercio no se debió ver especialmente lastrado. Las ciudades meridionales, más alejadas del centro de poder guti, compraban su libertad a cambio de importantes tributos; Uruk y Ur prosperaron durante sus IV y II dinastías.

Según una tablilla conmemorativa fue Utu-hengal, rey de Uruk, quien en torno a 2100 a. C. derrotó y expulsó a los gobernantes gutis de las tierras sumerias. Su éxito no le sería de mucho provecho ya que poco después el rey de Ur, Ur-Nammu, consiguió la hegemonía en toda la región con la llamada III dinastía de Ur o Renacimiento sumerio. El imperio surgido a raíz de esta hegemonía sería tan extenso o más que el de Sargón, del que tomaría la idea de imperio unificador. Esta influencia se aprecia incluso en la denominación de los monarcas, que a imitación de los acadios se harán llamar "reyes de Sumer y Acad"

A Ur-Nammu le sucederá su hijo, Shulgi, quien combatió contra Elam y las tribus nómadas de los Zagros. A este le sucedió su hijo Amar-Suen (Amar-Sin) y a este primero un hermano suyo, Shu-Sin y después otro Ibbi-Sin. En el reinado de este último los ataques de los amorreos, provenientes de Arabia, se hicieron especialmente fuertes y en 2003 a. C. caería el último imperio predominantemente sumerio. En adelante será la cultura acadia la que predomine y, posteriormente, Babilonia heredará el papel de los grandes imperios sumerios.

La desaparición del Imperio Acadio permitió el renacimiento de Sumer y el regreso al régimen de las ciudades estado. Tienen gran relevancia las reformas de Gudea de la Dinastía de Lagaš en esta época neosumeria (2175 a. C.). Posteriormente en la III Dinastía de Ur, Ur-Nammu lleva a cabo un código bien estructurado con numerosos cambios. En esta época se empiezan a nombrar como Reyes de Sumer y Akkad (2111 a. C.). Shulgi en 2093 a. C. impulsará una evolución referente a los pesos y medidas existentes, a la vez que reforzará las fronteras por el acoso de los semitas-amorreos.

Pese a ello, finalmente sucumbió a los ataques de los amorreos los cuales llevaban tropas auxiliares elamitas-semitas, procedentes de la meseta de Irán, que prevalecieron y saquearon Ur(2003 a. C.). Se vuelve a un estado de fragmentación política y proliferan dinastías locales. Rimsin creará un pequeño imperio en 1792 a. C. donde se introducirá la propiedad privada, dándose una sociedad pre-capitalista. En cambio, en Babilonia se entronizará una dinastía amorrea (1792 a. C.).

La sociedad de la III Dinastía de Ur se organiza de esta manera:


Con respecto a la organización social, la sociedad sumeria era jerárquica y estratificada, al igual que las de todas las civilizaciones. En la cúspide de la pirámide social se encontraba el rey, a quien seguía en importancia una élite de sacerdotes, jefes militares y funcionarios de alto nivel. A continuación se ubican los comerciantes, funcionarios menores, artesanos especializados y, luego, los campesinos y artesanos. El nivel más bajo de la sociedad correspondía a los esclavos.

A fines del IV milenio a. C. Sumeria se dividió en una docena de Ciudades estado independientes cuyos límites fueron definidos por medio de canales y mojones. Estas ciudades eran grandes centros mercantiles. Cada una estaba centrada en un templo dedicado al dios patrono particular de la ciudad y gobernado por un "patesi" ("Ennsi"), o en ocasiones por un rey ("lugal"). Los patesi eran sacerdotes supremos y jefes militares absolutos, auxiliados por una aristocracia constituida por burócratas y sacerdotes. El patesi controlaba la construcción de diques, canales de riego, templos y silos, imponiendo y administrando los tributos a los que toda la población estaba sujeta. Las ciudades estado sumerias tradicionalmente eran ciudades-templos, ya que los sumerios consideraban que los dioses fundaban las ciudades para que fuesen centros de culto. Más tarde, conforme a la religión, los dioses se limitaban a comunicar a los soberanos los planos de los santuarios. El vínculo de los patesis con los ritos religiosos de la ciudad era extremadamente íntimo.

Los templos (entre los cuales se destacaban los piramidales "ziqqurat") estaban ligados al poder estatal, y sus riquezas eran usufructuadas por los soberanos, considerados intermediarios entre los dioses y los hombres. Junto con los templos de las ciudades, homenajeando a su dios patrono, no era infrecuente que se erigiesen zigurats; pirámides de ladrillos macizos cocidos al sol que servían de santuarios y acceso a los dioses cuando estos descendían hasta su pueblo durante las festividades.

Con el desarrollo de las ciudades, las tentativas de supremacía de unas sobre otras se tornaron inevitable. Durante un milenio se sucedieron luchas por el control sobre los derechos de uso del agua, de las rutas de comercio y el cobro de tributos a tribus nómadas.
Las primeras cinco ciudades desde las que se ejerció el poder predinástico son —entre paréntesis aparece el nombre actual del paraje—:


Otras ciudades principales:


Otras ciudades menores, de sur a norte:


El idioma sumerio se considera una lengua aislada ya que no está emparentada con ninguna familia lingüística conocida, aunque se han hecho muchos intentos fallidos por relacionar el sumerio a otros grupos lingüísticos. El sumerio es claramente diferente del acadio, una lengua de claro origen semítico, con él coexistió en la región alternándose como lenguas dominantes. Ambas lenguas usaron la escritura cuneiforme, originalmente desarrollada por los sumerios y cuyo uso sobrepasó al de la propia lengua sumeria por más de un milenio.

El sumerio era un idioma aglutinante, es decir, los monemas (unidades de significado) se pegaban unos con otros para crear palabras enteras, en contraste con las lenguas flexivas como el acadio o las lenguas indoeuropeas. Por tanto tipológicamente el sumerio difiere notablemente de otras lenguas de la región ya que el sumerio prefiere utilizar afijos para expresar lo mismo. En cambio otras lenguas cercanas como el elamita, las lenguas hurrito-urartianas y algunas lenguas caucásicas muestran tipologías lingüísticas más similares al sumerio, aunque no parecen directamente relacionadas con él.

Los sumerios inventaron jeroglíficos pictóricos que más tarde dieron lugar a la escritura cuneiforme propiamente dicha, y su lengua junto con el del Antiguo Egipto compiten por el crédito de ser la lengua más tempranamente documentada. Ha sobrevivido un gran corpus formado por cientos de miles de textos en sumerio, la gran mayoría de estos textos en tablillas de arcilla. Los textos sumerios conocidos incluyen textos personales y cartas de negocios y transacciones, recibos, listas de léxico, leyes, himnos y plegarias, encantamientos mágicos e incluso textos científicos de matemáticas, astronomía y medicina. Las inscripciones monumentales y los textos escritos en diferentes objetos como estatuas o ladrillos también eran bastante comunes. Muchos textos sobrevivieron en múltiples copias, ya que fueron transcritos varias veces por escribas en formación. El sumerio siguió siendo la lengua litúrgica usada en oficios religiosos y la lengua de los textos legales en Mesopotamia mucho después de que los semitas se convirtieran en el grupo hegemónico en la región.

La comprensión de los textos en sumerio puede ser complicada hoy en día, incluso para los expertos, principalmente por el uso de caracteres jeroglíficos de difícil interpretación. Los más difíciles son los textos más antiguos, que en muchos casos no dan toda la estructura gramatical de la lengua que siempre cambiaba.

Tratar un asunto tal como la religión sumeria puede ser complicado, dado que las prácticas y creencias adoptadas por aquellos pueblos variaron mucho a través del tiempo y lugar, cada ciudad poseía su propia visión mitológica y/o teológica. Los sumerios fueron posiblemente los primeros en escribir sobre sus creencias, que luego fueron la inspiración para gran parte de la mitología, religión y astrología mesopotámicas, aunque ello no implica que su religión fuera la primera y que no hubieran tomado costumbres y ritos de otros pueblos.

Los sumerios veían los movimientos a su año como la magia de los espíritus, magia que era la única explicación que tenían de cómo funcionaban las cosas. Esos espíritus eran sus dioses. Y con muchos espíritus alrededor, creían en varios dioses, que tenían emociones humanas. Creían que el sol, la luna y las estrellas eran dioses, al igual que los juncos que crecían a su alrededor y la cerveza que destilaban.

Creían que los dioses controlaban el pasado y el futuro, que les revelaban las habilidades que poseían, incluyendo la escritura, y que los dioses les proporcionaban todo lo que necesitaban saber. No tenían la visión de que su civilización se hubiera desarrollado por sus propios esfuerzos. Y tampoco tenían visión de progreso tecnológico o social.

Cada uno de los dioses sumerios (en su propia lengua, "dingir" y en plural, "dingir-dingir" o "dingira-ne-ne") era asociado a ciudades diferentes, y la importancia religiosa a ellos atribuida se intensificaba o declinaba dependiendo del poder político de la ciudad asociada. Según la tradición sumeria, los dioses crearon el ser humano a partir del barro con el propósito de que fueran servidos por sus nuevas criaturas. Cuando estaban enojados o frustrados, los dioses expresaban sus sentimientos a través de terremotos o catástrofes naturales: la esencia primordial de la religión sumeria se basaba, por lo tanto, en la creencia de que toda la humanidad estaba a merced de los dioses. Nótese la similitud de la creación del hombre a partir del barro con el relato del Génesis.

Entre las principales figuras mitológicas adoradas por los sumerios, es posible citar:

Los sumerios probablemente hayan cavado en la tierra unos metros y encontrado agua . Los sumerios creían que la tierra era un gran disco flotando en el mar. Llamaron a ese mar Nammu y pensaban que había estado desde siempre en el tiempo. Creían que del Nammu habían surgido los peces, los pájaros, cerdos salvajes y otras criaturas que moraban en las tierras pantanosas y húmedas.

Según ellos, Nammu había creado el cielo y la tierra. El cielo se había separado de la tierra, dando nacimiento al dios masculino An y la tierra, una diosa llamada Ki. Creían que Ki y An habían procreado un hijo llamado Enlil, que era la personificación de la atmósfera, el viento y la tormenta. Creían que él separó el día de la noche y que había abierto una concha invisible dejando caer agua desde el cielo. Creían que junto con su madre y Ki, Enlil sentó las bases de la creación de las plantas, los humanos y otras criaturas, que hacía germinar las semillas y que había dado forma a la humanidad a partir de la arcilla, impregnándola.

El universo consistía en un disco plano cerrado por una cúpula de latón. La vida después de la muerte implicaba un descenso al vil submundo, donde se pasaba la eternidad en una existencia deplorable, en una especie de infierno.

Creían que los cultivos crecían porque un dios masculino se estaba apareando con su esposa diosa. Ellos veían los meses húmedos y calurosos del verano, cuando los campos y praderas se teñían de marrón, como el momento de la muerte de los dioses. Cuando los campos florecían de nuevo en primavera, creían que sus dioses resucitaban. Marcaron a este, como el comienzo del año, que era celebrado en sus templos con música y cantos.

No creían en el cambio social, aunque los sacerdotes sumerios alteraban las historias que contaban, creando nuevos giros en los cuentos antiguos; sin reconocer esto como un cambio inducido por los humanos o preguntándose por qué habían fallado en hacerlo bien la primera vez. Las nuevas ideas eran simplemente revelaciones de sus dioses.

Había diferentes tipos de sacerdotes. Algunos de los más comunes eran:

Los templos sumerios consistían en una nave central con corredores en ambos lados, flanqueados por aposentos para los sacerdotes. En una de las puntas del corredor se encontraba un púlpito y una plataforma construida con ladrillos de barro, usada para sacrificios animales y ofrendas vegetales.

Los graneros y depósitos generalmente se localizaban en la proximidad de los templos. Más tarde, los sumerios comenzaron a construir sus templos en la cima de las colinas artificiales, terraplenadas y multifacetadas: esos templos especiales se llamaban zigurats.

Los sumerios fueron precursores de muchas conceptos religiosos, sagas cosmogónicas y relatos que luego aparecieron recogidas por otros pueblos mesopotámicos y regiones vecinas . Entre ellas podemos citar: la creación del mundo, la separación de las aguas primordiales, la formación del hombre con arcilla o las ideas del paraíso y el Diluvio Universal (que aparece en la Epopeya de Gilgameš). Escritos de V. Scheil y S. N. Kramer, consideran la creación de Eva a partir de la costilla de Adán como un mito sumerio, ya que en sumerio, las palabras "hacer vivir" y "costilla" se escribían igual: "ti". También la idea de la resurrección de los muertos, atribuida a innumerables religiones, aparece en Sumeria por primera vez.

Los sumerios mantenían una producción de cebada, garbanzos, lentejas, mijo, trigo, nabo, dátiles, cebolla, ajo, lechuga, puerro, amapola y mostaza. También criaban vacas, ovejas, cabras y cerdos. Además, usaban bueyes como opción principal en el trabajo de carga y burros como animal de transporte. Los sumerios pescaban peces en los ríos Tigris y Éufrates y en los canales, y cazaban aves en sus orillas y desembocaduras pantanosas.

La agricultura sumeria dependía mucho del riego, efectuándose a través del uso de canales, estanques, diques y depósitos de agua. Las frecuentes y violentas inundaciones del Tigris, y en menor medida, del Éufrates, hacían que los canales necesitaran de reparación frecuente y de la continua extracción del limo, y el reemplazo continuo de los marcadores de inspección y mojones. El gobierno ordenaba a esclavos, condenados a trabajos forzados y determinados ciudadanos la tarea de trabajar en los canales, aunque los ricos podían excluirse de esta tarea.

Después de la temporada de inundaciones y luego de la temporada del equinoccio de Primavera y el Akitu o Festival de Año Nuevo, los canales eran abiertos, los campesinos irrigaban sus campos y drenaban el agua sobrante. Posteriormente dejaban que los novillos pisotearan la tierra y matasen las malas hierbas. El paso siguiente era dragar los campos con picos. Después que se secara, araban, gradaban y rastrillaban el campo tres veces, revolviendo la tierra después con una azada antes de la siembra. Lamentablemente, la alta tasa de evaporación dio lugar a un aumento gradual de la salinidad de los campos. Por el período de Ur III, los agricultores pasaron del trigo a la cebada como principal cultivo, ya que ésta es más tolerante a la sal.

Los sumerios realizaban la cosecha durante la fase seca del otoño en equipos de tres personas que consistían en dos segadores y un enfardador. Los campesinos utilizaban un tipo de cosechadora arcaica para separar la cabeza de los cereales de sus respectivos tallos: una especie de carro de clasificación, que separaba los granos de los cereales. Después cribaban la mezcla de granos y barcia.

Las casi constantes guerras, durante 2000 años, entre las ciudades estado sumerias ayudaron a desarrollar la técnica y tecnología militar a un alto nivel. La primera guerra que se registra fue entre Lagaš y Umma en el año 2525 a. C. en una estela llamada la Estela de los Buitres. Este registro también muestra al rey de Lagaš liderando un ejército sumerio compuesto en su mayoría de infantería. Los soldados de infantería llevaban lanzas, cascos de cobre y escudos de cuero o mimbre. Los lanceros se muestran dispuestos en lo que parece ser una formación de falange, que requiere entrenamiento y disciplina. Esto implica que los sumerios hayan hecho uso de soldados profesionales.

La influencia clave en el ejército sumerio fue su paupérrima posición estratégica. Los obstáculos naturales para la defensa existían solamente en las fronteras del oeste (desierto) y del sur (golfo Pérsico). Cuando los enemigos más populosos y poderosos aparecían por el norte o el este, los sumerios se volvían susceptibles a los ataques. Los sumerios participaban en guerras con sitio entre sus ciudades, defendidas por murallas de ladrillos de barro que, obviamente, no podían detener los enemigos que ya conocían ese material.

Los sumerios inventaron el carro de guerra, al cual ataban onagros (burros salvajes). Esos carros antiguos no funcionaban tan bien en combate como los modelos construidos posteriormente. Algunos sugieren que los carros militares servían primariamente como medio de transporte, aunque en tiempo de guerra transportaban hachas de guerra y lanzas. El carro o más bien carreta sumerio constaba de una caja con cuatro ruedas macizas manejado por un equipo de dos personas y atado a cuatro onagros. El carro estaba compuesto por cestas entretejidas, y las ruedas poseían un diseño sólido de tres piezas.
Los sumerios usaban fundas y arcos simples, más tarde se inventaría el arco compuesto.

La planicie del Tigris-Éufrates carecía de piedra y árboles. Las edificaciones sumerias comprendían estructuras planoconvexas hechas de ladrillos de barro, material por contra muy abundante, desprovistas de argamasa o cemento. Debido a que los ladrillos planoconvexos eran de composición relativamente inestable, los albañiles sumerios añadían una mano extra de ladrillos, puestos perpendicularmente cada pocas hiladas. Entonces ahí, rellenaban los huecos con betún.

Las construcciones hechas con ladrillos de barro se acababan deteriorando, de forma que eran periódicamente destruidas, niveladas y reconstruidas en el mismo lugar. Esa constante reconstrucción elevó gradualmente el nivel de las ciudades, de modo que con los siglos se erigieron por arriba de la planicie a su alrededor. Las construcciones resultantes se conocían con el nombre de tell y se encontraban en todo el antiguo Oriente Próximo y Medio.

El tipo más famoso e impresionante de entre las edificaciones sumerias, eran los Zigurats o torres escalonadas, una construcción de largas y amplias plataformas sobrepuestas en cuya cima había templos. Algunos académicos han teorizado que estas estructuras podrían haber sido la base de la torre de Babel bíblica , que se describe en el Génesis.

Los sellos cilíndricos sumerios también describen casas construidas con cañas, similares a aquellas construidas por los árabes de las tierras bajas de la parte sur de Irak, hasta una fecha tan reciente como el 400 a. C. Por otro lado, los templos sumerios y palacios hicieron uso de materiales y técnicas más avanzadas como refuerzos (soportes para los ladrillos), recesos (esquinas), pilastras y clavos de arcilla recubiertos con ladrillos cocidos al horno, más resistentes que los crudos secados al sol.

Los sumerios desarrollaron un complejo sistema de metrología alrededor del 4000 a. C. Esta metrología avanzada resultó en la creación de la aritmética, la geometría y el álgebra. Desde el 2600 a. C. en adelante, los sumerios escribieron tablas de multiplicación en tabletas de arcilla y trataron con ejercicios geométricos y problemas de división. Los primeros rastros de la numeración babilónica también se remontan a este periodo. El periodo que abarca desde el 2700 al 2300 a. C. vio la primera aparición del ábaco, y una tabla de columnas sucesivas que delimitaron el orden sucesivo de magnitud de su sistema de numeración sexagesimal. Los sumerios fueron los primeros en usar un sistema de numeración de notación posicional. Otros pueblos mesopotámicos quizás hayan usado algún tipo de regla de cálculo en cálculos astronómicos.

Una tablilla encontrada en Nippur puede ser considerada el primer manual de medicina del mundo. En esa tablilla, donde había fórmulas químicas y mágicas (encantamientos), usaban términos tan especializados que para traducirse se precisó de la ayuda de químicos.

En la farmacología, se usaban sustancias vegetales, animales y minerales. Laxantes y diuréticos fueron la mayoría de los remedios de aquel pueblo. Determinadas cirugías también eran puestas en práctica. Los sumerios manufacturaban salitre, conseguido a partir de la orina, la cal, de cenizas o de la sal. Combinaban esos materiales con leche, piel de cobra, caparazón de tortuga, casia, mirto, timo, sauces, higo, pera, abeto y/o dátil. A partir de ahí, mezclaban esos agentes con vino, usando el resultado obtenido de dos formas: o pasando el producto como si fuera una crema, o luego se mezclaba junto con la cerveza, consumiendo el remedio por vía oral.

Los sumerios explicaban la enfermedad como una consecuencia del aprisionamiento, y la consecuente tentativa de escape, de un demonio dentro del cuerpo humano. El objetivo del remedio era persuadir al demonio a creer que continuar residiendo en aquel cuerpo sería una experiencia desagradable. Comúnmente los sumerios colocaban un cordero o una cabra cerca del enfermo. En el caso de no haber ovejas a disposición, probaban suerte con una estatua, que, si se conseguía transferir el demonio dentro de sí, sería cubierta de betún.

La literatura sumeria comprende tres grandes temas: mitos, himnos y lamentaciones. Los mitos se componen de breves historias que tratan de perfilar la personalidad de los dioses mesopotámicos: Enlil, principal dios y progenitor de las divinidades menores; Inanna, diosa del amor y de la guerra, o Enki, dios del agua potable frecuentemente enfrentado a Ninhursag, diosa de las montañas. Los himnos son textos de alabanza a los dioses, reyes, ciudades o templos. Las lamentaciones relatan temas catastróficos como la destrucción de ciudades o templos y el abandono de los dioses resultante.

Algunas de estas historias es posible que se apoyasen en hechos históricos como guerras, inundaciones o la actividad constructora de un rey importante, magnificados y distorsionados con el tiempo.

Una creación propia de la literatura sumeria fue un tipo de poemas dialogados basados en la oposición de conceptos contrarios. También los proverbios forman parte importante de los textos sumerios.

Los sumerios tal vez sean más recordados debido a sus muchas invenciones. Algunos especialistas les dan el crédito por la invención de la rueda y el torno alfarero. Su sistema de escritura cuneiforme fue el primer sistema de escritura del que se tenga evidencia, adelantándose a los jeroglíficos egipcios en, por lo menos, 75 años. Los sumerios estaban entre los primeros astrónomos, poseyendo la primera visión heliocéntrica de la que se tenga conocimiento (la próxima aparecería de vuelta en el 1500 a. C. por parte de los Vedas en la India). Afirmaban también que el sistema solar se constituía de cinco planetas (ya que únicamente sólo se podían ver cinco planetas a simple vista).

Desarrollaron también conceptos matemáticos usando sistemas numéricos basados en 6 y 10. A través de ese sistema, inventaron el reloj con 60 segundos, 60 minutos y 12 horas, además del calendario de 12 meses que usamos actualmente. También construyeron sistemas legales y administrativos con cortes judiciales, prisiones y las primeras ciudades estado. La invención de la escritura posibilitó a los sumerios el almacenamiento del conocimiento y la posibilidad de transferirlo a otros y a las generaciones posteriores. Eso llevó a la creación de las escuelas, a la educación y oficialización de la matemática, religión, burocracia, división de trabajo y sistemas de clases sociales.

Los sumerios también inventaron el carro de guerra y, posiblemente, las formaciones militares. Inventaron la cerveza. Lo más importante de todo, tal vez, sea el hecho que de acuerdo con muchos académicos, los sumerios fueron los primeros en tratar tanto plantas como animales. En el caso de lo primero, a través de plantaciones sistémicas y de la cosecha de una descendencia de grama mutante, conocida actualmente como einkorn, y de simientes de mijo y trigo. Con relación a lo segundo, los sumerios domesticaron a través del confinamiento y de la procreación de carneros ancestrales (similares a la cabra montés y al ganado salvaje (búfalos). Fue la primera vez que esas especies fueron domesticadas y criadas a gran escala.




</doc>
<doc id="2673" url="https://es.wikipedia.org/wiki?curid=2673" title="Santa Fe">
Santa Fe

Santa Fe puede hacer referencia a:
























</doc>
<doc id="2676" url="https://es.wikipedia.org/wiki?curid=2676" title="Sinople">
Sinople

En heráldica, sinople, sínople e incluso sinoble (del francés "sinople" y este nombre del de la antigua ciudad de Sinope) es la denominación del color verde. De entre los esmaltes heráldicos, pertenece al grupo de los colores, junto con el gules (rojo), el azur (azul), el sable (negro) y el púrpura.

Una de las primeras menciones de un escudo verde se encuentra en el "Roman de Troie", de Benoît de Sainte-Maure, que data de alrededor del año 1155, donde este esmalte es descrito con el nombre que recibía en Francia en ese momento: "vert" (‘verde’).

En los inicios de la heráldica, entre los siglos XII y XIII, este era el esmalte menos utilizado: el historiador Michel Pastoureau halló que aparecía en menos del 5 % de las armerías europeas. Para explicar esta escasa presencia del verde en los escudos, se ha argüido que hasta el siglo XIII este color tuvo connotaciones negativas (el Diablo y sus criaturas, el islam, la inestabilidad); que hasta fines del siglo XIV fue difícil de fabricar y de fijar satisfactoriamente; o que no destacaba contra el verde de la hierba.

Sin embargo, durante el siglo XIV la Europa occidental experimentó una revalorización del color verde y, si bien este color nunca fue ampliamente usado en armerías, hacia comienzos del siglo XV ya estaba bien establecido dentro del canon heráldico.

Hasta principios del siglo XIV, el término "sinople" se empleaba en la literatura francesa como designación poética del color rojo. Este vocablo derivaba de "sinope", "sinopis", palabras latinas que en la antigüedad clásica se referían por lo general al rojo, en alusión a una clase de ocre rojo muy apreciado que se extraía en Capadocia y se exportaba desde el puerto de Sinope, en Anatolia. Aun después de su adopción por parte de la heráldica con el significado de «verde», "sinople" conservó su significado literario de «rojo» durante unos dos siglos más.

Se desconoce por qué motivo la palabra "sinople" experimentó ese cambio de significado en la jerga heráldica; Pastoureau ubica este cambio entre los años 1380 y 1400, o tal vez unas décadas antes. Se ha sugerido que los heraldos franceses cambiaron el nombre del esmalte "vert" por "sinople" debido a que "vert" era homófono con "vair" (‘veros’), un forro heráldico.

En los reinos españoles, recién a mediados del siglo XV el término heráldico francés "sinople" comenzó a ser traducido como esmalte heráldico verde, en lugar de rojo.

En cuanto al aparente despropósito de la adopción del nombre de un pigmento rojo para designar a un esmalte verde, el jesuita y heraldista Claude-François Menestrier (1631–1705), en su obra "L' Art du blason justifié", lo explica citando parte del texto de un folleto manuscrito que se remontaría a alrededor del año 1400, y que trataba acerca de colores para pintura e ilustración. En su libro, Menestrier copia un capítulo de este folleto, en donde se menciona un pigmento llamado "sinoplum", el cual —siempre según el manuscrito— provenía de la «ciudad de Sinopoli» y era a veces rojo y a veces verde. Esto sugiere que en algún momento se llamó "sinoplum" al renombrado ocre rojo de Anatolia, el actual rojo carmesí, y también a alguna clase de pigmento verde, igualmente importado.

El sinople no se encuentra definido con exactitud. En consecuencia, el tono y el matiz de verde a emplear para representarlo quedan a criterio del artista heráldico. Se recomienda, sin embargo, que el verde sea fuerte y fiel a su naturaleza; no debe inclinarse demasiado hacia el amarillo ni hacia el azul.

Cuando no se dispone de colores, el sinople puede representarse mediante un rayado muy fino de líneas oblicuas paralelas que van desde el ángulo superior izquierdo del dibujo hasta el inferior derecho, según el método atribuido al jesuita Silvestre Pietra Santa. Este es el método de representación que se ve comúnmente en grabados a una tinta.

Debajo se presentan dos ejemplos antiguos y notables del uso del esmalte sinople.


Amadeo VI, duque de Saboya (1334–1383) fue apodado el «Conde Verde» debido a que solía vestir de este color. Si bien los colores de las armas de los Saboya eran plata y gules, durante la vida del Conde Verde se sumó el sinople a la librea de la Casa de Saboya. Estos tres colores, bastante más tarde, darían origen a la actual bandera de Italia.

De entre las figuras heráldicas, suelen ser de sinople las y los montes, en representación del color de la hierba, aunque las reglas de la heráldica no impiden que se les asigne cualquier otro color.

Hacia el inicio del Renacimiento se desarrolló un sistema de correspondencias simbólicas para los colores heráldicos que hoy se encuentra en desuso.
Es de notar que hacia 1828 este sistema era considerado absurdo por el heraldista inglés William Berry, aunque el español Francisco Piferrer, en 1858, lo comenta como si todavía fuese válido.

Si bien Jean Courtois, Heraldo Sicilia del Reino de Aragón, menciona en su tratado "Le blason des couleurs" (1414) que cualquiera de estas asociaciones del sinople puede usarse para blasonar, en la práctica es posible que solamente se hayan usado el sistema planetario y el sistema de piedras preciosas. Para Alberto y Arturo García Caraffa (1919), el blasonado con gemas correspondía a los títulos y el de planetas a los soberanos.
Arthur Fox-Davies cita un ejemplo de blasonado con piedras preciosas que data de 1458.

Debajo se dan algunas de las antiguas correspondencias simbólicas del sinople, así como algunos de los nombres «griegos» que se le atribuyeron.

Además, de acuerdo con Courtois, el sinople sería considerado por algunos como el «menos noble» de los colores heráldicos.

Los metales heráldicos:

Los otros esmaltes heráldicos principales:
Y además:


</doc>
<doc id="2677" url="https://es.wikipedia.org/wiki?curid=2677" title="Sable">
Sable

El sable es un arma blanca curva y (generalmente) de un solo filo, pensada para cortar, habitualmente usada en caballería e infantería (oficiales) en el siglo XIX e incluso XX. Este carácter curvo de la hoja y su filo único, diferencia tradicionalmente al sable de la espada.

Este arma blanca es de tajo y surgió por la necesidad de velocidad en combate. Esta se logra al cortar y no dejar incrustada la hoja en el cuerpo del adversario (al contrario de la mayoría de las espadas de una mano, que son de estocada). 

La curvatura, que está ubicada generalmente desde la punta hasta la mitad del sable, genera un tajo profundo.

La curvatura del sable pretende conseguir, en teoría, que un hombre a caballo, al descargar el brazo con esta arma, dibuje un amplio círculo sobre el infante logrando que en el punto de corte el sable siempre sea tangencial. Por esta razón no se ensarta, sino que corta, con lo que aumenta la herida sin clavar el arma. Debido a ello los sables pensados para caballería tienen una gran curvatura, son casi circulares; los pensados para infantería poseen una curvatura menor, pues debe concederse importancia a la función defensiva: mantener alejado al enemigo y parar sus golpes.

El sable moderno es, junto con la espada y el florete, una de las tres armas de esgrima. Deriva del arma que usaban los soldados de caballería. Tiene un protector en forma de cuenco, que se curva bajo la mano, y una hoja en forma de T en sección transversal. La longitud del sable es de 90 cm y su peso máximo es de 500 g. Los tocados o puntos se pueden conseguir embistiendo con la punta o produciendo un corte con el filo de la hoja. El blanco válido es todo el cuerpo de cintura para arriba, incluyendo cabeza y brazos. Los asaltos de sable son los más rápidos y ágiles en esgrima, por lo que requieren una buena forma física.

La danza del sable ("raks al sayf") es originaria de la danza marcial tradicional de Egipto "El Ard", que es realizada por hombres que llevan los sables en forma vertical, listos para pelear, mientras bailan. "Raks al Sayf" implica balancear el objeto sobre la cabeza, cadera, estómago, hombros, etc. No existe mucha documentación que indique que la danza del sable bailada por mujeres sea común, salvo algunas pinturas.


Sables del mundo y su historia: https://www.mundoespadas.com/sable.html


</doc>
<doc id="2678" url="https://es.wikipedia.org/wiki?curid=2678" title="Sanguíneo">
Sanguíneo

En heráldica, sanguíneo ("sanguine" en inglés) es la denominación de un color rojo oscuro. Es muy poco utilizado, y su uso se limita a las armerías de las naciones angloparlantes.

En la heráldica occidental, los colores universalmente aceptados son siete: oro, plata, gules, azur, sable, sinople y púrpura. Los demás esmaltes y metales son de invención posterior y suelen restringirse a la heráldica de determinada nación o región; tal es el caso del sanguíneo.
En inglés, los colores heráldicos llevan nombres derivados de la heráldica francesa, excepto el sanguíneo ("sanguine") y el morado ("murrey"), cuyos nombres son denominaciones cromáticas que eran de uso común en el idioma inglés al momento del establecimiento del color heráldico sanguíneo. "Sanguine" (del francés antiguo "sanguin", fem. "sanguine", y este del latín "sanguineus", ‘relativo a la sangre’) era a comienzos del siglo XIV la denominación de una variedad de tela roja, aunque hacia fines del siglo XIV ya se registra el uso de "sanguine" como denominación de color con el significado de ‘rojo sangre’.

En la heráldica inglesa este color no se considera esmalte, metal ni forro, sino que se encuentra en una categoría aparte denominada «mancha» ("stain"), junto con otros dos colores: el leonado ("tenné") y el morado ("murrey"). Algunos heraldistas, históricamente, señalaron que estas «manchas» eran los colores indicados para agregar a los escudos brisuras denotativas de infamia, pero otros autores, al no haber encontrado ejemplos de lo antedicho, dudan de que alguna vez estas brisuras se hayan llevado a la práctica. Por otra parte, el sanguíneo se ha usado de la misma manera que los demás colores heráldicos, sin que parezca tener connotaciones infamantes.

La coloración del sanguíneo heráldico no se encuentra definida con exactitud, por lo que su tono y matiz quedan a criterio del artista heráldico. Se recomienda, sin embargo, que el color empleado sea intenso y fiel a su naturaleza, a riesgo de que pueda confundirse con otro color heráldico, como el gules o el morado.

Cuando no se dispone de colores, el color sanguíneo puede representarse mediante un entramado de líneas horizontales y diagonales que se cruzan, como se ve a la izquierda de estas líneas, aunque el patrón indicado no es el único que existe para este esmalte. Este es el método de representación que se ve comúnmente en grabados a una tinta.

En la heráldica alemana existe un esmalte similar llamado "Blut" (‘sangre’) o "Blutrot" (‘rojo sangre’).


</doc>
<doc id="2679" url="https://es.wikipedia.org/wiki?curid=2679" title="Síndrome de adaptación espacial">
Síndrome de adaptación espacial

El síndrome de adaptación espacial (SAS) es la forma específica de cinetosis que sufren los astronautas durante un viaje por el espacio y su causa es la ausencia de gravedad. Reduce el rendimiento de los astronautas durante los primeros días de vuelo espacial, pero normalmente la adaptación se produce a los pocos días. Debe evitarse el movimiento excesivo que empeora los síntomas.



</doc>
<doc id="2680" url="https://es.wikipedia.org/wiki?curid=2680" title="Salud">
Salud

La salud (del latín "salus, -utis") es un estado de bienestar o de equilibrio que puede ser visto a nivel subjetivo (un ser humano asume como aceptable el estado general en el que se encuentra) o a nivel objetivo (se constata la ausencia de enfermedades o de factores dañinos en el sujeto en cuestión). El término salud se contrapone al de enfermedad, y es objeto de especial atención por parte de la medicina y de las ciencias de la salud.

La salud es un estado de completo bienestar físico, mental y social, no solamente la ausencia de enfermedad o dolencia, según la definición presentada por la Organización Mundial de la Salud (OMS) en su constitución aprobada en 1948. Este concepto se amplía a: «La salud es un estado de completo bienestar físico, mental y social, y no solamente la ausencia de afecciones o enfermedades». En la salud, como en la enfermedad, existen diversos grados de afectación y no debería ser tratada como una variable dicotómica. Así, se reformularía de la siguiente manera: «La salud es un estado de bienestar físico, mental y social, con capacidad de funcionamiento, y no sólo la ausencia de afecciones o enfermedades». También puede definirse como el nivel de eficacia funcional o metabólica de un organismo tanto a nivel micro (celular) como a nivel macro (social).

Dentro del contexto de la promoción de la salud, la salud ha sido considerada no como un estado abstracto, sino como un medio para llegar a un fin, como un recurso que permite a las personas llevar una vida individual, social y económicamente productiva. La salud es un recurso para la vida diaria, no el objetivo de la vida. Se trata de un concepto positivo que acentúa los recursos sociales y personales, así como las aptitudes físicas.

La forma física es la capacidad que tiene el cuerpo para realizar cualquier tipo de ejercicio donde muestra que tiene resistencia, fuerza, agilidad, habilidad, coordinación y flexibilidad.

Existe también la salud mental, la cual se caracteriza por el equilibrado estado emocional de una persona y su autoaceptación (gracias al autoaprendizaje y al autoconocimiento); en términos clínicos, es la ausencia de cualquier tipo de enfermedad mental. 

Estas definiciones han sido cuestionadas ya que se la considera una definición ideal, puesto que no toda la población alcanzaría ese estado. Hoy asumimos que la salud es un proceso en el cual el individuo se desplaza sobre un eje salud-enfermedad acercándose a uno u otro extremo según se refuerce o rompa el equilibrio.

La salud se concibe como la posibilidad que tiene una persona de gozar de una armonía biopsicosocial, en interacción dinámica con el medio en el cual vive.

No obstante, el concepto de salud ("buena salud") es subjetivo. Muchas personas se han acostumbrado a vivir con un estado de mala salud crónica como si fuera normal, influenciadas por el entorno social o familiar, sus vivencias personales que le imposibilitan contrastar con una situación de buena salud y, en ocasiones, la falta de apoyo o soluciones por parte de los profesionales de la salud, entre otras razones. Este hecho está impidiendo el reconocimiento y diagnóstico de trastornos que, sin tratamiento, pueden provocar consecuencias graves sobre la salud. Como ejemplos destacados cabe citar la enfermedad celíaca o la malnutrición en personas de edad avanzada. Asimismo, esta aceptación de una mala salud crónica como algo esperable o normal y la falta de concienciación acerca de la importancia de la prevención, conducen a un bajo seguimiento de los tratamientos prescritos en enfermedades crónicas diagnosticadas, con las consiguientes repercusiones negativas sobre la salud.

La alimentación es el principal factor que influye sobre la salud. Una buena salud se consigue mediante una dieta equilibrada, con una gran variedad de alimentos, equilibrio entre calorías, ingerir las comidas diarias recomendadas, entre otros. 

Podemos mirar en la pirámide alimentaria los alimentos para una nutrición sana y equilibrada.
Sin una nutrición saludable, se pueden contraer enfermedades como lo son: obesidad, desnutrición, etc.; se deben consumir pocas grasas y lípidos, muchas frutas y verduras, los productos de origen animal se deben consumir de manera regular, los cereales se deben consumir de manera constante, antes de cada comida se deben lavar frutas y verduras.
En la nutrición, un dato muy importante es la higiene que es necesaria para evitar enfermedades estomacales.
No debemos olvidar el ejercicio que sirve para una buena digestión.
También es muy importante no ponernos a dieta sin instrucciones de un especialista, ya que no es seguro.
Lo mejor, es comer todos los alimentos que nos ofrece la pirámide alimentaria, lo importante, es consumirlas en porciones adecuadas.
La Dieta mediterránea está considerada como altamente saludable, ya que algunos de los compuestos bioactivos presentes en ella incluyen compuestos fenólicos, isoprenoides y alcaloides que contribuyen a efectos saludables comúnmente asociados a dicha dieta.

La práctica regular de actividad física en cualquier edad produce un bienestar y mejora tanto en el estado de ánimo como físicamente.

El ejercicio físico es cualquier movimiento corporal repetido con el propósito de conservar la salud o mejorarla. A menudo también es dirigido hacia el mejoramiento de la capacidad atlética y/o la habilidad. El ejercicio físico regular es un componente necesario en la prevención de algunas enfermedades como problemas cardíacos, enfermedades cardiovasculares, Diabetes mellitus tipo 2, sobrepeso, dolores de espalda, entre otros.

El ejercicio físico se debe practicar con mesura y de forma equilibrada, prestando atención a los cambios físicos internos para aprender a comprender la relación causa-efecto entre el movimiento físico concreto y su efecto directo con los cambios internos percibidos.

Recomendable porque puede llevar a un desgaste físico de ciertas partes del cuerpo. Por eso, cabe insistir en el equilibrio de fuerzas, tanto internas como externas, y a ello ayuda el autoconocimiento mediante un crítico autoanálisis (autoexámenes de conciencia mientras se desarrolla la actividad física).

El ejercicio físico es necesario para una salud equilibrada; además, debe complementarse con una dieta equilibrada y una adecuada calidad de vida. Sus beneficios pueden resumirse en los siguientes puntos:


La cantidad mínima para prevenir enfermedades es de 30 minutos diarios de actividad física moderada. Otros hábitos que deben combinarse con la realización de ejercicios son: la buena alimentación, el descanso adecuado, la higiene y evitar el consumo de sustancias perjudiciales para el organismo, como el tabaco, el alcohol y otros estimulantes.

El descanso es necesario para que se produzcan en nuestro cuerpo las diferentes adaptaciones que aporta la actividad física y para que se produzca una mejora del rendimiento corporal.

La higiene es el conjunto de conocimientos y técnicas que aplican los individuos para el control de los factores que ejercen o pueden ejercer efectos nocivos sobre su salud. La higiene personal es el concepto básico del aseo, de la limpieza y del cuidado del cuerpo humano.
La higiene es un elemento imprescindible para la salud, ya que mantiene la limpieza del cuerpo, los cabellos y los dientes, cosa que previene infecciones y enfermedades.

La salud mental es un concepto que se refiere al bienestar emocional y psicológico del individuo. "Merriam-Webster" define salud mental como: «el estado del bienestar emocional y psicológico en el cual un individuo pueda utilizar sus capacidades cognitivas y emocionales, funcionar en sociedad, y resolver las demandas ordinarias de la vida diaria».

Según la OMS, no hay una definición oficial de salud mental. Las diferencias culturales, las evaluaciones subjetivas y la competición de teorías profesionales, hacen difícil definir "la salud mental". En general, la mayor parte de expertos advierten que la salud mental y las enfermedades mentales no son excluyentes. En otras palabras, la ausencia de un desorden mental reconocido, no es necesariamente un indicador de contar con salud mental (probablemente debido al desconocimiento de la gran variedad de estados mentales aún por definir, y la corta edad de la ciencia médica en general tal como la conocemos hoy en día, y en especial de la ciencia que intenta definir con más exactitud estos trastornos o complejos salud-enfermedad que proponen tanto la psicología como la psiquiatría).

En la antigua Grecia nada se sabía de virus y bacterias, pero ya reconocían que la personalidad y sus características, desempeñan un rol fundamental en los orígenes de la enfermedad.

Galeno, una figura gigantesca del mundo antiguo, ya observó la existencia de un vínculo muy estrecho entre la melancolía y el cáncer de mama. De este modo, en estos primeros enfoques médicos, encontramos tempranamente un criterio holístico en la consideración de la salud y la enfermedad.

Platón remarcaba que la buena educación es la que tendía con fuerza a mejorar la mente juntamente con el cuerpo. Reconocía, de alguna manera, que la salud corporal conduce a la higiene mental, pero, al mismo tiempo, que el buen estado mental predispone al buen estado corporal. Así, establecía, específicamente, que el alma "buena", por su propia excelencia, mejora al cuerpo en todo sentido.

En los tiempos actuales, desde el siglo XX, especialmente, pero también desde mucho antes –e incluso en la medicina oriental antigua–, se comienza a reconocer la necesidad de concepción holística de la salud.

La concepción psicosomática nos obliga a atender nuestra interioridad como causa posible de perturbaciones del cuerpo. Esto es reconocido unánimemente por la clínica occidental, que ve que en los consultorios un altísimo porcentaje de consultas responde a distorsiones de la mente o de la personalidad, en sentido amplio.

Este nuevo enfoque no es dualista a la manera cartesiana. Concibe al hombre como una unidad, en la que con mucha frecuencia anidan los poderes curativos, que estimulados, ayudan a resolver los problemas somáticos. La filosofía médica no materialista de este modo va incrementándose en el mundo en que pudo predominar la medicina convencional.

Son todas aquellas actividades que presencian consecuencias nocivas y peligrosas para nuestra salud. Las más relevantes son:

Según el reporte de Lalonde, del año 1974 realizado en Canadá, se sugiere que existen cuatro determinantes generales que influyen en la salud, a los cuales se les llamó: "biología humana", "ambiente", "forma de vida" y la "organización del cuidado de la salud". De esta manera, la salud es mantenida por la ciencia y la práctica de medicina, pero también por esfuerzo propio. "Fitness", una dieta saludable, manejar el estrés, el dejar de fumar y de abusar de otras sustancias nocivas, entre otras medidas, son pasos para mejorar la salud de alguien. Por otra parte, el estilo de vida es el conjunto de comportamientos o aptitudes que desarrollan las personas, es decir, pueden ser saludables o nocivas para la salud y además podemos encontrar que es la causa de las enfermedades dentro del factor huésped.

Tener una dieta equilibrada, que incluya todos los grupos de alimentos, y realizar actividad física moderada con regularidad (150 minutos de ejercicio a la semana) son factores clave en la mejora de salud; además de no fumar, tener un consumo moderado de alcohol, comer cinco piezas de frutas y verduras al día y tener un peso adecuando a la talla de la persona. Estos cambios en los hábitos de vida combatiría enfermedades cardiovasculares crónicas y diabetes.

Es el estudio de la vida del ser humano o la información genética que cada individuo trae en sus genes, puede proteger o favorecer la aparición de enfermedades.
Dentro del factor biológico podemos destacar las enfermedades adquiridas por el medio como el dengue o el mal de chagas.

Son todos aquellos factores que provienen del exterior y sobre los cuales el ser humano "no tiene control".

Un informe, publicado el 4 de marzo de 2008 por la Organización para la Cooperación y el Desarrollo Económico (OCDE), advierte que "la contaminación del aire va a tener efectos crecientes sobre la salud a nivel mundial"; y si no se hace nada para remediarlo –como ha venido sucediendo hasta ahora–, advierte, en 2030 "el número de fallecimientos prematuros relacionados con el ozono troposférico se multiplicará por cuatro."

Son todos aquellos factores que provienen del exterior y sobre los cuales el ser humano sí tiene control. Los productos químicos domésticos alteran gravemente el ambiente doméstico y pasan a las personas a través de los alimentos a los cuales contaminan fácilmente por estar almacenados en los mismos habitáculos durante periodos de tiempo.

Para completar una forma de vida saludable es necesario seguir ciertas pautas tanto alimentarias como de hábitos de ejercicio físico.

En primer lugar una dieta equilibrada requiere la ingesta controlada y equilibrada consistente en una alta ingesta de verduras, frutas, legumbres y cereales –que contienen antioxidantes y fibra– y pescado, rico en ácidos grasos y omega 3. También son recomendables, en menor cantidad, carnes blancas, carnes rojas, con mucho control sobre estas últimas al contener grasas saturadas.

Por su parte, los hábitos de ejercicio físico son imprescindibles para quemar el exceso de calorías ingeridas, y tonificar músculos y huesos con vistas a la vejez. Su práctica reduce las probabilidades de padecer enfermedades de corazón, enfermedades relacionadas con la presión arterial y el colesterol.

En la parte de los hábitos tóxicos, cabe destacar el alcohol y el tabaco como unas de las fuentes más perjudiciales para la salud en tanto en cuanto a la gran extensión entre la población de estos hábitos.

El proceso que permite fortalecer los conocimientos, aptitudes y actitudes de las personas para participar responsablemente en el cuidado de su salud y para optar por estilos de vida saludables, facilitando el logro y conservación de un adecuado estado de salud individual, familiar y colectivo mediante actividades de participación social, comunicativa y educativa para la salud.

La promoción también está relacionada con la prevención. Te da el control sobre riesgos a enfermedades y cambia el estilo de vida a uno más saludable. Mientras sea acompañado por una dieta balanceada, crear una rutina de ejercicios y evitar situaciones que causen estrés, todo esto con el objetivo de disminuir el riesgo a enfermedades.



</doc>
<doc id="2681" url="https://es.wikipedia.org/wiki?curid=2681" title="Sistema nervioso">
Sistema nervioso

El sistema nervioso es un conjunto de células especializadas en la conducción de señales eléctricas. Está formado por neuronas y células gliales. Las neuronas tienen la función de coordinar las acciones de los seres vivos del reino animal por medio de señales químicas y eléctricas enviadas de un lugar a otro del organismo. La mayor parte de los animales pluricelulares tienen sistemas nerviosos con características básicas similares, aunque con un grado de complejidad muy variable. Únicamente carecen de él los animales que no tienen tejidos y órganos bien diferenciados, como los poríferos (esponjas), placozoos y mesozoos.

El sistema nervioso capta estímulos del entorno, (estímulos externos) o señales del mismo organismo (estímulos internos), procesa la información y genera respuestas diferentes según la situación. A modo de ejemplo podemos considerar un animal que a través de las células sensibles a la luz de la retina capta la proximidad de otro ser vivo. Esta información es transmitida mediante el nervio óptico al cerebro que la procesa y emite una señal nerviosa que a través de los nervios motores provoca la contracción de ciertos músculos con el objetivo de desplazarse en dirección contraria al peligro potencial.




Las neuronas son las células que constituyen la unidad fundamental básica del sistema nervioso, se encuentran conectadas entre sí de manera compleja y tienen la propiedad de generar, propagar, codificar y conducir señales por medio de gradientes electroquímicos (electrolitos) a nivel de membrana axonal y de neurotransmisores a nivel de sinapsis y receptores. Los tejidos de sostén o mantenimiento están formado por las células gliales (neuroglia) y un sistema vascular especializado. 

La neurona al igual que todas las células, dispone de un citoplasma en el que existe un núcleo y diversos orgánulos como las mitocondrias y el aparato de Golgi. Su particularidad está en que del cuerpo celular arrancan diversas prolongaciones ramificadas que se llaman dendritas y otra única que recibe el nombre de axón. Las dendritas reciben la señal nerviosa en dirección al cuerpo celular, mientras que el axón la emite desde el cuerpo celular a otra neurona o una célula muscular, el axón puede dividirse en miles de ramas, cada una de las cuales lleva a la información a una célula diferente. La estructura básica del sistema nervioso está formada por redes de neuronas interconectadas por sus dendritas y axones. La zona de conexión entre dos neuronas recibe el nombre de sinapsis.

Con base en la división morfológica entre las distintas partes anatómicas de las neuronas y sus diversas formas de organización se clasifican en cuatro tipos:

Las neuronas se clasifican también en tres grupos generales según su función:

Las neuronas se pueden comunicar entre sí gracias a impulsos eléctricos que circulan a través de sus prolongaciones. El impulso se denomina potencial de acción y es unidireccional desde el cuerpo celular al axón. En estado de reposo existe una diferencia de potencial entre el interior y el exterior de la neurona ya que ambos espacios están separados por la membrana celular, a dicha diferencia de potencial se la denomina potencial de membrana en reposo. 

Cuando se genera un potencial de acción o impulso nervioso, se producen dos fenómenos consecutivos que afectan a la membrana celular, alteran su permeabilidad a los iones Na+ y K+ y modifican el potencial de membrana en reposo. En primer lugar se abren los canales que facilitan la entrada de Na+ a la célula (despolarización), posteriormente se abren los canales de la membrana que hacen posible la salida de K+ de la célula (repolarización). El potencial de acción así generado se transmite unidireccionalmente a través del axón hasta alcanzar la siguiente conexión (sinapsis).
Se llama sinapsis a la comunicación funcional que se establece entre dos neuronas o entre una neurona y una célula muscular, mediante la sinapsis el impulso nervioso puede circular a través de varias neuronas enlazadas. La neurona de la que parte el impulso se llama presináptica y la que lo recibe se denomina postsináptica. Entre ambas existe un espacio que recibe el nombre de espacio sináptico, el cual separa las membranas de las dos células aledañas. Pueden distinguirse dos tipos de sinapsis: 

Un neurotransmisor es una sustancia química producida por las neuronas que se libera al espacio sináptico de una sinapsis química por la acción de un impulso nervioso o potencial de acción. Interacciona con un receptor específico en la neurona postsináptica donde produce una determinada respuesta que puede ser excitatoria o inhibitoria. Los neurotransmisores son un aspecto fundamental en la transmisión del impulso nervioso y resultan de gran interés en farmacología, pues muchos de los medicamentos que tienen alguna acción sobre el sistema nervioso actúan sobre ellos.

Existen diferentes sustancias que actúan como neurotransmisores, algunas de las más importantes son las siguientes:

Las células gliales (conocidas también genéricamente como glía o neuroglía) son células del sistema nervioso que desempeñan, de forma principal, la función de soporte y protección de las neuronas. En los humanos se clasifican según su localización o por su morfología y función. Las diversas células de la neuroglía constituyen más de la mitad del volumen del sistema nervioso de los vertebrados. Las neuronas no pueden funcionar en ausencia de las células gliales.

Según su ubicación dentro del sistema nervioso ya sea central o periférico, las células gliales se clasifican en dos grandes grupos: 

Por su morfología o función, entre las células gliales se distinguen las células macrogliales (astrocitos, oligodendrocitos ), las células microgliales (entre el 10 y el 15% de la glía) y las células ependimarias.

Puede dividirse en dos partes bien diferenciadas para facilitar su estudio: el sistema nervioso central que está compuesto por el encéfalo y la médula espinal, y el sistema nervioso periférico que incluye todos los nervios periféricos, tanto los nervios motores como los nervios sensitivos.

Durante el desarrollo del embrión, el tubo neural primitivo da origen a la formación de tres vesículas encefálicas que se denominan prosencéfalo, mesencéfalo y rombencéfalo. Posteriormente el prosencéfalo se divide y da origen al telencéfalo y el diencéfalo, mientras que el rombencéfalo da origen al metencéfalo y el mielencéfalo. El mesencéfalo permanece sin dividirse. De esta forma se constituyen las cinco porciones de las que surgen todas las partes del encéfalo totalmente desarrollado.

Se puede describir el sistema nervioso según su anatomía o según su funcionalidad.

El sistema nervioso central está formado por el encéfalo y la médula espinal, se encuentra protegido por tres membranas, las meninges. En su interior existe un sistema de cavidades conocidas como ventrículos, por las cuales circula el líquido cefalorraquídeo.

El sistema nervioso periférico está formado por los nervios, craneales y espinales, que emergen del sistema nervioso central y que recorren todo el cuerpo. Conteniendo axones de vías neurales con distintas funciones y por los ganglios periféricos. Que se encuentran en el trayecto de los nervios y que contienen cuerpos neuronales, los únicos fuera del sistema nervioso central.

Una división menos anatómica pero más funcional, es la que divide al sistema nervioso de acuerdo al rol que cumplen las diferentes vías neurales, sin importar si estas recorren parte del sistema nervioso central o el periférico:



El sistema nervioso puede sufrir numerosas enfermedades de diferente origen: infecciosas, hereditarias, degenerativas, cerebrovasculares (por afectación de los vasos sanguíneos), desmielinizantes o tumorales.

Se cree que la primera neurona surgió hace 600 millones de años, durante el período Ediacárico, en animales diblásticos como los cnidarios. El acto reflejo es la unidad básica de la actividad nerviosa integrada y podría considerarse como el circuito primordial del cual partieron el resto de las estructuras nerviosas. Este circuito pasó de estar constituido por una sola neurona multifuncional en los diblásticos a dos tipos de neuronas en el resto de los animales llamadas aferentes y eferentes. En la medida que se fueron agregando intermediarios entre estos dos grupos de neuronas con el paso del tiempo evolutivo, como interneuronas y circuitos de mayor plasticidad, el sistema nervioso fue mostrando un fenómeno de concentración en regiones estratégicas dando pie a la formación del sistema nervioso central, siendo la cefalización el rasgo más acabado de estos fenómenos.

Era la transmisión de señales existen medidas como la redundancia, que consiste en la creación de vías alternas que llevan parte de la misma información garantizando su llegada a pesar de daños que puedan ocurrir.

La mielinización de los axones en la mayoría de los vertebrados y en algunos invertebrados como anélidos y crustáceos es otra medida de optimización. Este tipo de recubrimiento incrementa la rapidez de las señales y disminuye el calibre de los axones ahorrando espacio y energía.

Otra característica importante es la presencia de metamerización del sistema nervioso, es decir, aquella condición donde se observa una subdivisión de las estructuras corporales en unidades que se repiten con características determinadas. Los tres grupos que principalmente muestran esta cualidad son los artrópodos, anélidos y cordados.

La centralización hace referencia a la tendencia evolutiva de las neuronas a agruparse en centros localizados de integración en los que existen numerosas células que interactúan entre sí para procesar los estímulos y realizar acciones cada vez más complejas. Esta centralización progresiva es la que acabó por originar un sistema nervioso central y un encéfalo. Entre los animales actuales que no poseen centralización se encuentran las medusas cuyo sistema nervioso es una red difusa de neuronas interconectadas sin que existe ningún punto central de control.

La cefalización hace referencia a la tendencia evolutiva del tejido nervioso a agruparse en el área de la cabeza. Este proceso se ha visto favorecido por la existencia de órganos de los sentidos en el polo cefálico. La cefalización ya está presente en los platelmintos que contienen ganglios cefálicos que hacen las funciones de cerebro y puede observarse en los artrópodos, los cefalópodos y por supuesto en todos los vertebrados.

Los animales diblásticos o radiados, una agrupación parafilética que engloba tanto cnidarios como a ctenóforos, normalmente cuentan con una red de plexos subectodérmicos sin un centro nervioso aparente, pero algunas especies ya presentan condensados nerviosos en un fenómeno que se entiende como el primer intento evolutivo para conformar un sistema nervioso central. Algunas disposiciones de estos condensados, como los anillos nerviosos en las medusas, recuerdan tendencias posteriores vistas en los cicloneuros.
En los animales triblásticos o bilaterales, un grupo monofilético, existen dos tipos de planes corporales llamados protóstomos y deuteróstomos que poseen a su vez tres tipos de disposiciones del sistema nervioso: cicloneuros, hiponeuros y epineuros.Una diferencia esencial es que en protostomados y deuterostomados el SNC se encuentra en posiciones invertidas. Durante muchos años se consideró que estas y otras diferencias indicaban planes corporales y SNC esencialmente distintos, (por la posición relativa del SNC, Sistema Digestivo y vaso circulatorio principal.


Los animales protóstomos, que son triblásticos, como los platelmintos, nemátodos, moluscos, anélidos y artrópodos cuentan con un sistema nervioso hiponeuro, es decir es un sistema formado por ganglios cerebrales y cordones nerviosos ventrales. Los ganglios que forman el cerebro se sitúan alrededor del esófago, con conectivos periesofágicos que los unen a las cadenas nerviosas que recorren ventralmente el cuerpo del animal, en posición inferior respecto al tubo digestivo. Tal modelo de plan corporal queda dispuesto de esa forma cuando en la gástrula acontece un proceso embriológico llamado gastrorrafia.

Los animales deuteróstomos, que son triblásticos, se dividen en dos grupos según su simetría, radial o bilateral, o la disposición de su sistema nervioso, cicloneuros o epineuros. Dentro de los cicloneuros se encuentran los equinodermos (de simetría radial) y los hemicordados. El centro nervioso es un anillo situado alrededor de la boca (subectodérmico o subepidérmico). Dentro del grupo de los epineuros se encuentran los urocordados, los cefalocordados y los vertebrados en la que presentan un cordón nervioso hueco y tubular, dorsal al tubo digestivo. A partir de este cordón, en animales más complejos, se desarrolla el encéfalo y la médula espinal. Tales modelos de planes corporales quedan dispuestos de esa forma cuando en la gástrula acontecen unos procesos embriológicos llamados isoquilia en los cicloneuros o nototenia en el caso de los epineuros.

El filo de los cnidarios incluyen entre otros organismos las hidras y medusas. Presentan la forma más simple y primitiva de sistema nervioso que recibe el nombre de red nerviosa. En una red nerviosa las neuronas están dispersas sin una organización estructural compleja y no existe encéfalo.

El filo de los platelmintos incluye unas 20 000 especies, entre las que se incluyen algunas de vida parasitaria como la taenia solium o solitaria que vive en el intestino humano. Su sistema nervioso presenta inicios de cefalización y 2 cordones nerviosos longitudinales que pueden considerarse un sistema nervioso central primitivo. Por otra parte el tejido nervioso contiene ya numerosas interneuronas, es decir neuronas de conexión entre las sensitivas y las motoras que aumentan la complejidad de los circuitos. 

El grupo de los anélidos incluye numerosas especies, siendo una de las más características la lombriz de tierra. Estos animales cuentan con un sistema nervioso formado por un cordón nervioso ventral doble y dos ganglios situados en cada metámero. Poseen un cerebro que está formado por la unión de dos ganglios dorsales que se comunican mediante conectivos al cordón nervioso ventral.

Dentro del grupo de los moluscos se encuentran los cefalópodos (calamares y pulpos). Estos tienen un cerebro y sistema sensorial que ha alcanzado gran desarrollo. El cerebro es comparativamente de tamaño muy grande en relación al de otros invertebrados por lo que los cefalópodos alcanzan elevadas capacidades de memoria y aprendizaje.

El grupo de los bivalvos que incluye las almejas y mejillones tiene un sistema nervioso menos desarrollado que el de los cefalópodos, probablemente por su vida sedentaria. Carecen de encéfalo pero dispones de varios ganglios que controlan diversas funciones, entre ellos dos ganglios cerebro-pleurales a ambos lados del esófago que controlan los órganos sensoriales y la cavidad del manto (moluscos).
Los artrópodos son los animales más abundantes y variados de la tierra, incluyen los insectos, arácnidos y crustáceos. Poseen un sistema nervioso bien desarrollado que les permite tener un comportamiento complejo y coordinado. Su sistema nervioso central es de tipo ganglionar y consiste en una cadena de ganglios segmentarios unidos mediante un cordón nervioso ventral, algunos ganglios se fusionan en la región cefálica y dan lugar a un cerebro.

El grupo de los equinodermos incluye la estrella de mar y el erizo de mar. Estos animales poseen sistema nervioso pero no cuentan con un encéfalo que centralice la actividad. Disponen de tres anillos nerviosos situados en planos diferentes alrededor del tubo digestivo.

El sistema nervioso de los vertebrados consta de un encéfalo bien desarrollado y una médula espinal. El sistema nervioso periférico está formado por diferentes nervios que se conectan con el sistema nervioso central. Estos nervios son de tipo aferente (transportan información sensorial hacia el sistema nervioso central) o eferentes (transportan órdenes motoras desde el cerebro hasta los órganos). Existen asimismo ganglios periféricos que son agrupaciones de neuronas enlazadas a algunos de los nervios pero no deben confundirse con el sistema ganglionar de los artrópodos. 




</doc>
<doc id="2682" url="https://es.wikipedia.org/wiki?curid=2682" title="Sistema">
Sistema

Un sistema (del latín "systēma", y este del griego σύστημα "sýstēma" 'reunión, conjunto, agregado') es "un objeto complejo cuyas partes o componentes se relacionan con al menos alguno de los demás componentes"; puede ser material o conceptual. Todos los sistemas tienen composición, estructura y entorno, pero solo los sistemas materiales tienen mecanismos (o procesos), y solo algunos sistemas materiales tienen figura (forma).

Según el sistemismo, todos los objetos son sistemas o componentes de otro sistema. Por ejemplo, un núcleo atómico es un sistema material físico compuesto de protones y neutrones relacionados por la interacción nuclear fuerte; una molécula es un sistema material químico compuesto de átomos relacionados por enlaces químicos; una célula es un sistema material biológico compuesto de orgánulos relacionados por enlaces químicos no-covalentes y rutas metabólicas; una corteza cerebral es un sistema material biológico compuesto de neuronas relacionadas por potenciales de acción y neurotransmisores; un ejército es un sistema material social y parcialmente artificial compuesto de personas y artefactos relacionados por el mando, el abastecimiento, la comunicación y la guerra; el anillo de los números enteros es un sistema conceptual algebraico compuesto de números positivos, negativos y el cero relacionados por la suma y la multiplicación; y una teoría científica es un sistema conceptual lógico compuesto de hipótesis, definiciones y teoremas relacionados por la correferencia y la deducción.

Un sistema conceptual, sistema formal o sistema ideal es un constructo compuesto por conceptos de cuatro diferentes tipos:
Así, los conceptos no son sistemas conceptuales, sino solo componentes de sistemas conceptuales. Sí son sistemas conceptuales

Un sistema material, sistema concreto o sistema real es una cosa compuesta por dos o más cosas relacionadas, que posee propiedades que no poseen sus componentes, llamadas propiedades emergentes; por ejemplo, la tensión superficial es una propiedad emergente que poseen los líquidos pero que no poseen sus moléculas componentes. Al ser cosas, los sistemas materiales poseen las propiedades de las cosas, como tener energía (e intercambiarla), tener historia, yuxtaponerse con otras cosas y ocupar una posición en el espacio tiempo.

El esfuerzo por encontrar leyes generales del comportamiento de los sistemas materiales es el que funda la teoría de sistemas y, más en general, el enfoque de la investigación científica a la que se alude como sistemismo, sistémica o pensamiento sistémico, en cuyo marco se encuentran disciplinas y teorías como la cibernética, la teoría de la información, la teoría del caos, la dinámica de sistemas y otras.
Cualquier ciencia o disciplina del saber puede considerarse como sistema si explica una parte más o menos extensa del saber humano. Tal es la idea del filósofo español José Ortega y Gasset en su obra "La Historia como sistema" en la que se refiere a que la historia es un sistema (explicativo, se entiende) que permite comprender el presente. La misma idea ha sido expresada por otros autores.

El análisis más sencillo del concepto de sistema material es el que incluye los conceptos de composición, entorno, estructura y mecanismo (CEEM, por sus siglas). La composición de un sistema es el conjunto de sus partes componentes. El entorno o ambiente de un sistema es el conjunto de las cosas que actúan sobre los componentes del sistema, o sobre las que los componentes del sistema actúan. La estructura interna o endoestructura de un sistema es el conjunto de relaciones entre los componentes del sistema. La estructura externa o exoestructura de un sistema es el conjunto de relaciones entre los componentes del sistema y los elementos de su entorno. La estructura total de un sistema es la unión de su exoestructura y su endoestructura. Las relaciones más importantes son los vínculos o enlaces, aquellas que afectan a los componentes relacionados; las relaciones espaciotemporales no son vínculos. El mecanismo de un sistema es el conjunto de procesos internos que lo hacen cambiar algunas propiedades, mientras que conserva otras.

Además, la frontera de un sistema es el conjunto de componentes que están directamente vinculados (sin nada interpuesto) con los elementos de su entorno. La frontera de un sistema físico puede ser rígida o móvil, permeable o impermeable, conductor térmico (adiabática) o no, conductor eléctrico o no, e incluso puede ser aislante de frecuencias de audio. Además, algunos sistemas tienen figura (forma); pero no todo sistema con frontera tiene necesariamente figura. Si hay algún intercambio de materia entre un sistema físico y su entorno a través de su frontera, entonces el sistema es abierto; de lo contrario, el sistema es cerrado. Si un sistema cerrado tampoco intercambia energía, entonces el sistema es aislado. En rigor, el único sistema aislado es el universo. Si un sistema posee la organización necesaria para controlar su propio desarrollo, asegurando la continuidad de su composición y estructura (homeostasis) y la de los flujos y transformaciones con que funciona (homeorresis) —mientras las perturbaciones producidas desde su entorno no superen cierto grado—, entonces el sistema es autopoyético.



</doc>
<doc id="2683" url="https://es.wikipedia.org/wiki?curid=2683" title="Sexualidad">
Sexualidad

La sexualidad es el conjunto de condiciones que caracterizan el sexo de cada persona o animal. Desde el punto de vista histórico cultural, es el conjunto de fenómenos emocionales, de conducta y de prácticas asociadas a la búsqueda de emoción sexual, que marcan de manera decisiva al ser humano en todas y cada una de las fases determinantes de su desarrollo.
Durante siglos se consideró que la sexualidad en los animales, incluyendo al ser humano, era de tipo instintiva. En esta convicción se basaron las teorías para fijar las formas no naturales de la sexualidad, entre las que se incluían todas aquellas prácticas no dirigidas a la procreación .

Sin embargo, hoy se sabe que algunos mamíferos muy desarrollados, como los delfines o algunos pingüinos, presentan un comportamiento sexual diferenciado, que incluye, además de homosexualidad (observada en 450 especies de animales), variantes de la masturbación.

La sexualidad es un aspecto central en la vida de las personas. Durante muchos siglos se la consideró exclusivamente desde el paradigma biologicista, reduciéndola a la genitalidad y estandarizando binomios entre formas naturales y no naturales de la sexualidad (entre las que se incluían todas aquellas prácticas no dirigidas a la procreación).

Sin embargo, desde el paradigma de la integralidad, la sexualidad no solo abarca a la genitalidad sino también a las identidades, los roles de género, el erotismo, el placer, la intimidad, la reproducción y la orientación sexo-afectival.

De acuerdo con la Organización Mundial de la Salud, la sexualidad humana se define como un aspecto central del ser humano, a lo largo de su vida. Abarca al sexo, las identidades y los roles de género, el erotismo, el placer, la intimidad, la reproducción y la orientación sexo-afectiva.

De esta manera concebida, la sexualidad se manifiesta a través de múltiples dimensiones entre las que se incluyen los pensamientos, fantasías, deseos, creencias, actitudes, valores, conductas, prácticas y relaciones interpersonales; lo cual implica que se trata de un aspecto múltiplemente determinado por la interacción de factores biológicos, psicológicos y socio-económico-políticos. 

Por ser seres sociales, las personas construimos nuestra sexualidad con otras personas, por lo que nuestra corporalidad trasciende a la dimensión biológica. Nuestros cuerpos están atravesados por la cultura y en ese sentido, es necesario para hablar de sexualidad considerar distintas categorías como el sexo, el género, los roles de género, los estereotipos de género, la identidad de género y la orientación sexo-afectiva.

La característica del sexo desarrollado, comprende el grado en que se experimenta la pertenencia a una de las categorías dimórficas (femenino o masculino). Es de suma importancia en la construcción de la identidad, parte de la estructura sexual, basado en el sexo, incluye todas las construcciones mentales y conductuales de ser hombre o mujer. Hay que tener en cuenta que es muy importante que sepamos cuales son nuestras actitudes más personales e íntimas hacia la sexualidad.

Uno de los productos de la interacción de estos holones es la orientación sexual. En efecto, cuando interactúan el erotismo (la capacidad de sentir deseo, excitación, orgasmo y placer), la vinculación afectiva (la capacidad de sentir, amar o enamorarse) y el género (lo que nos hace hombres o mujeres, masculinos o femeninos) obtenemos alguna de las orientaciones sexuales a saber: la bisexualidad, la heterosexualidad y la homosexualidad.

La definición de trabajo propuesta por la OMS (2006) orienta también la necesidad de atender y educar la sexualidad humana. Para esto es de suma importancia, reconocer los derechos sexuales (WAS, OPS,2000):






En la medida que estos derechos sean reconocidos, ejercidos o respetados, llegarán a existir sociedades más sanas en el sentido sexual.

Es importante notar que la sexualidad se desarrolla y se expresa de diferentes maneras a lo largo de la vida de forma que la sexualidad de un infante no será la misma que la de un adolescente o un adulto. Cada etapa de la vida necesita conocimientos y experiencias específicos para su óptimo desarrollo. En este sentido, para los niños es importante conocer su cuerpo, sus propias sensaciones y aprender a cuidarlo. Un niño o una niña que puede nombrar las partes de su cuerpo (incluyendo el pene, el escroto o la vulva) y que ha aceptado que es parte de él, es más capaz de cuidarlo y defenderlo. También es importante para ellos conocer las diferencias y aprender que tanto los niños como las niñas son valiosos y pueden realizar actividades similares. En esta etapa aprenden a amar a sus figuras importantes primero (los padres, los hermanos) y a las personas que los rodean, pueden tener sus primeros enamoramientos infantiles (que son diferentes de los enamoramientos de los adolescentes) y también viven las primeras separaciones o pérdidas, aprenden a manejar el dolor ante estas. En cuanto a la reproductividad, empiezan a aprender a cuidar de los más pequeños (pueden empezar con muñecos o mascotas) y van desarrollando su capacidad reproductiva. También tienen grandes dudas sobre su origen, generalmente las dudas que tienen con respecto a la relación sexual necesitan la aclaración del sentido amoroso y del deseo de tenerlo que tuvieron sus padres. Les resulta interesante el embarazo y el nacimiento en un sentido de conocer su propio origen. Sobre todo será importante indagar la pregunta y responderla al nivel de conocimiento de acuerdo a la edad del menor.

La sexualidad adulta contiene los cuatro elementos en una interacción constante. Por ejemplo, si una mujer se siente satisfecha y orgullosa de ser mujer, es probable que se sienta más libre de sentir placer y de buscarlo ella misma. Esto genera un ambiente de cercanía afectiva y sexual con la pareja y un clima de mayor confianza que a su vez repercute en las actividades personales o familiares que expresan la reproductividad. En realidad podríamos empezar por cualquiera de las características en estas repercusiones positivas o también negativas.

Cada una de las características presentará problemas muy específicos. Así, encontramos en el sexo, los problemas de homofobia, violencia contra la mujer, desigualdad sexual, etcétera. En la vinculación afectiva se encuentran las relaciones de amor/odio, la violencia en la pareja, los celos, el control de la pareja. El erotismo presentará problemas tales como disfunciones sexuales o las infecciones de transmisión sexual. En cuanto la reproductividad se observan trastornos en la fertilidad o, más tarde, violencia y maltrato infantil, abandono de los hijos, etc.

Al igual que muchos animales, los seres humanos utilizan la excitación sexual con fines reproductivos y para el mantenimiento de vínculos sociales, pero le agregan el goce y el placer propio y el del otro. El sexo también desarrolla facetas profundas de la afectividad y la conciencia de la personalidad. En relación a esto, muchas culturas dan un sentido religioso o espiritual al acto sexual (Véase Taoísmo, Tantra), así como ven en ello un método para mejorar (o perder) la salud.

La complejidad de los comportamientos sexuales de los humanos es producto de su cultura, su inteligencia y de sus complejas sociedades, y no están gobernados enteramente por los instintos, como ocurre en casi todos los animales. Sin embargo, el motor base de gran parte del comportamiento sexual humano siguen siendo los impulsos biológicos, aunque su forma y expresión dependen de la cultura y de elecciones personales; esto da lugar a una gama muy compleja de comportamientos sexuales. En muchas culturas, la mujer lleva el peso de la preservación de la especie.

Desde el punto de vista psicológico, la sexualidad es la manera de vivir la propia situación. Es un concepto amplio que abarca todo lo relacionado con la realidad sexual. Cada persona tiene su propio modo de vivir el hecho de ser mujer u hombre, su propia manera de situarse en el mundo, mostrándose tal y como es. La sexualidad incluye la identidad sexual y de género que constituyen la conciencia de ser una persona sexuada, con el significado que cada persona dé a este hecho.

La diversidad sexual nos indica que existen muchos modos de ser mujer u hombre, más allá de los rígidos estereotipos, siendo el resultado de la propia biografía, que se desarrolla en un contexto sociocultural. Hoy en día se utilizan las siglas GLTB (o LGBT) para designar al colectivo de gais, lesbianas, transexuales y bisexuales.

La sexualidad se manifiesta también a través del deseo erótico que genera la búsqueda de placer erótico a través de las relaciones sexuales, es decir, comportamientos sexuales tanto autoeróticos (masturbación), como heteroeróticos (dirigidos hacia otras personas, estos a su vez pueden ser heterosexuales u homosexuales). El deseo erótico (o libido) que es una emoción compleja, es la fuente motivacional de los comportamientos sexuales. El concepto de sexualidad, por tanto, no se refiere exclusivamente a las “relaciones sexuales”, sino que éstas son tan sólo una parte de aquel objetivo.

Se desarrolla de forma lenta, y a una edad llegada justa, con técnicas generalmente nuevas.




</doc>
<doc id="2688" url="https://es.wikipedia.org/wiki?curid=2688" title="Santísima Trinidad (desambiguación)">
Santísima Trinidad (desambiguación)

Santísima Trinidad o Santa Trinidad puede referirse a:







</doc>
<doc id="2689" url="https://es.wikipedia.org/wiki?curid=2689" title="Suiza">
Suiza

Suiza (en alemán, "Schweiz"; en francés, "Suisse"; en italiano, "Svizzera"; en romanche, "Svizra"), oficialmente la Confederación Suiza (en alemán, "Schweizerische Eidgenossenschaft"; en francés, "Confédération suisse"; en italiano, "Confederazione Svizzera"; en romanche, "Confederaziun svizra"; y en latín, "Confoederatio Helvetica"), es un país sin salida al mar ubicado en Europa central y que cuenta con una población de habitantes (2018). Suiza es una república federada de 26 estados, llamados cantones y cuenta con cuatro idiomas oficiales: alemán, francés, italiano y romanche. Berna es la sede de las autoridades federales, mientras que el sector privado del país está más desarrollado en las ciudades de Zúrich, Basilea y Ginebra. Suiza es el cuarto país más rico del mundo, según su PIB per cápita, con 83 718 dólares estadounidenses (2011).

Limita al norte con Alemania, al oeste con Francia, al sur con Italia y al este con Austria y Liechtenstein. Se caracteriza diplomáticamente por su política de relaciones exteriores neutral, sin haber participado activamente en ningún conflicto internacional desde 1815. Suiza es sede de cuantiosas organizaciones internacionales, como la Cruz Roja, la Organización Mundial del Comercio, la Unión Postal Universal, la Unión Internacional de Telecomunicaciones, la Organización Mundial del Movimiento Scout, así como una de las dos oficinas de la ONU en Europa y de agencias especializadas de esta institución tales como la Organización Internacional del Trabajo o la Organización Mundial de la Salud. A su vez, es sede de la FIFA, máximo organismo del fútbol a escala mundial, y de la UEFA, mayor ente del fútbol europeo; también es sede del COI, máximo organismo encargado de la realización de los Juegos Olímpicos y de la FIDE, máximo organismo del ajedrez en el ámbito mundial. La fecha de su creación como Estado se fijó el 1 de agosto de 1291 de acuerdo con la tradición. Debido a este motivo, cada año se celebra la fiesta nacional el 1 de agosto.

Actualmente, se percibe como uno de los países más desarrollados del mundo. Por su política de neutralidad, el país alberga gran cantidad de inmigrantes provenientes de naciones de varios continentes, por lo que es considerado como uno de los países europeos con mayor diversidad cultural. Finalmente, es reconocida internacionalmente por su turismo de montaña y por sus relojes, chocolates, navajas, bancos, ferrocarriles y quesos. Zúrich, Ginebra y Basilea han sido clasificadas entre las diez mejores ciudades del mundo en términos de calidad de vida.

El nombre Suiza proviene de Schwyz, nombre de uno de los cantones de Waldstätten que conformaron el núcleo de la Antigua Confederación Suiza. El topónimo del cantón data del año 972 y procede quizá del antiguo alto alemán "Suittes", emparentado con el verbo "swedan" que significa «quemar, chamuscar» (afín al islandés "svíða", danés y sueco "svide" «chamuscar»), haciendo referencia a la tala y quema mediante el cual se quema una zona boscosa para construir algunas viviendas en la zona (artiga). El uso del nombre para esta área se extendió para denominar a todo el cantón, y después de la guerra de Suabia en 1499 gradualmente se utilizó para nombrar a toda la confederación. El nombre en alemán de Suiza para el país, "Schwiiz", es homónimo al del cantón y su capital, por lo que para distinguirse se emplea un artículo determinado en "d'Schwiiz" para referirse al país y la forma simple "Schwiiz" para el cantón y la ciudad.

El antiguo nombre del país, "Helvetia" deriva de la palabra "Helvetii", una tribu celta que habitó en la meseta suiza antes de la época galorromana. La primera mención del nombre "Helvetii" data del año 300 a. C. Los nombres del neolatín Confoederatio Helvetica o Helvetia fueron introducidos cuando Suiza se convirtió en un Estado federal en 1848, remontándose a la República Helvética.

Los vestigios humanos más antiguos que existen datan de hace 150 000 años aproximadamente. Asimismo, las herramientas de agricultura más antiguas fueron halladas en Gächlingen y se estima que datan del 5300 a. C.

Las tribus más antiguas conocidas en esa zona pertenecen a las culturas Hallstatt y La Tène, llamada así debido al sitio arqueológico de La Tène, ubicado al norte del lago de Neuchâtel. La cultura de La Tène floreció a finales de la Edad de Hierro, alrededor del 450 a. C., posiblemente bajo influencia de las civilizaciones griega y etrusca. Uno de los más importantes grupos étnicos de la región fueron los helvecios. En el 58 a. C., las fuerzas de Julio César derrotaron a los helvecios en la batalla de Bibracte. En el año 15 a. C., Tiberio, quien más tarde sería emperador de Roma, y Druso el Mayor conquistaron los Alpes, integrándolos al creciente Imperio romano. La región ocupada por los helvecios, de donde proviene el nombre "Confoederatio Helvetica", pasó a formar parte de la provincia romana de Galia Bélgica y más tarde de la provincia Germania Superior, mientras que la porción oriental de la Suiza moderna estuvo integrada en la provincia romana de Recia.

En la Alta Edad Media, la parte occidental de la actual Suiza formó parte del Reino de Borgoña desde el siglo IV. Los alamanes se establecieron en la meseta suiza en el siglo V y en los valles de los Alpes en el siglo VIII, formando Alamania y quedando el actual territorio de Suiza dividido entre los reinos de Borgoña y de Alamania. En el siglo VI, la región entera pasó a formar parte del Imperio franco tras la victoria de Clodoveo I sobre los alamanes en la batalla de Tolbiac (496). Posteriormente los francos también dominarían a los burgundios.

Entre los siglos VI y VIII Suiza continuó bajo la hegemonía franca (las dinastías merovingia y carolingia). En 843, tras alcanzar su máxima extensión bajo el reinado de Carlomagno, el imperio franco fue dividido en el Tratado de Verdún. El territorio de la actual Suiza fue repartido entre Francia Oriental y Francia Media hasta que fue unificada por el Sacro Imperio Romano Germánico en el siglo XI.

Para el año 1200, la meseta suiza pertenecía a los dominios de las casas de Saboya, Zähringer, Habsburgo y Kyburg. Algunas regiones (Uri, Schwyz y Unterwalden, después conocidas en conjunto como "Waldstätten") fueron anexadas como inmediaciones imperiales para garantizar el control del imperio sobre los puertos de montaña. Cuando la dinastía Kyburg cayó en 1264, los Habsburgo extendieron sus territorios al este de la meseta suiza durante el reinado de Rodolfo I, que fue emperador del Sacro Imperio en 1273.

La Antigua Confederación Suiza fue una alianza entre las comunidades de los valles centrales de los Alpes. La Confederación facilitó el desarrollo de varios intereses comunes (libre comercio) y aseguró la paz en las principales rutas mercantiles en las montañas. La Carta Federal de 1291, firmada por las comunidades rurales de Uri, Schwyz y Unterwalden, es considerada el documento que sentó las bases para la fundación de la confederación, aunque es probable que alianzas similares ya hubiesen existido desde décadas anteriores.
En 1353, los tres cantones originales se habían unido con los cantones de Glaris y Zug y con las ciudades-Estado de Lucerna, Zúrich y Berna para formar la Antigua Confederación de los ocho cantones que existió hasta finales del siglo XV. La expansión territorial ayudó a incrementar el poder y la riqueza de la confederación. En 1460, los confederados controlaban gran parte de los territorios al sur y oeste del río Rin hasta la cordillera de los Alpes. En 1499 la victoria de Suiza sobre la Liga de Suabia y la casa de Habsburgo en la guerra de Suabia dio como resultado una independencia "de facto" del Sacro Imperio.

La Antigua Confederación Suiza había adquirido una reputación de invencible durante estas guerras, pero la expansión de la Confederación sufrió un revés en 1515, con la derrota en la batalla de Marignano. Esto marcó el fin de la llamada época "heroica" de la historia de Suiza. El éxito de la Reforma de Ulrico Zuinglio en algunos cantones llevó a varias guerras internas en el país entre 1529 y 1531, las guerras de Kappel ("Kappeler Kriege"). Ya en 1648, más de un siglo después de estas contiendas, Johann Rudolf Wettstein, como enviado de la Confederación Suiza, consiguió mediante hábiles negociaciones que las potencias firmantes del Tratado de Westfalia reconocieran oficialmente la independencia de Suiza con respecto al Sacro Imperio Romano Germánico y su neutralidad en las guerras ("Ancien Régime").

Los siglos XVI y XVII estuvieron caracterizados por el creciente autoritarismo de las familias gobernantes. En 1653, esta situación, combinada con la crisis financiera traída por la guerra de los Treinta Años, produjo el estallido de la guerra campesina suiza de 1653. Sumado a esto, permanecía el conflicto religioso entre los cantones católicos y los cantones protestantes, que entre 1656 y 1712 llevaron a violentos enfrentamientos, como la batalla de Villmergen.

En 1798, las fuerzas de la Revolución francesa conquistaron Suiza e impusieron una nueva constitución. Esta constitución centralizaba el gobierno y abolía los cantones, y tanto el territorio de Mulhouse como el valle de Valtellina fueron separados de Suiza. El nuevo régimen, conocido como la República Helvética, fue muy impopular. Había sido impuesto por un ejército invasor, destruyendo siglos de costumbres y tradiciones y convirtiendo a Suiza en un Estado satélite de Francia. La fuerte represión efectuada por Francia durante la rebelión de Nidwalden (septiembre de 1798) fue un ejemplo de la presencia opresiva del ejército francés y de la resistencia local a la ocupación.

Suiza tuvo que entrar en el bloqueo continental, lo que dañó y estimuló a su industria al mismo tiempo, y tuvo que suministrar tropas. Al principio 16 000 hombres, que se redujeron a 12 000 en 1811, pero a pesar de los incentivos ofrecidos y de las amenazas de reclutamiento forzoso, los efectivos nunca llegaron a las cifras exigidas.

Cuando estalló la guerra entre Francia y sus rivales, las fuerzas de Rusia y Austria invadieron Suiza. El pueblo suizo se negó a combatir al lado de los franceses en nombre de la República Helvética. En 1803, Napoleón organizó una reunión con líderes políticos suizos en París; el resultado de esta reunión fue el documento llamado Acta de Mediación, el cual restablecía en gran parte la autonomía de Suiza y la Confederación de 19 cantones. Desde entonces, gran parte de la política suiza se encaminaría a equilibrar la tradición de los cantones autónomos con la necesidad de un gobierno central.

En 1815, el Congreso de Viena restableció por completo la independencia de Suiza, y las potencias europeas accedieron a reconocer permanentemente la neutralidad del país. Tropas suizas sirvieron a varios gobiernos extranjeros hasta 1860, cuando pelearon en el sitio de Gaeta. El tratado también aumentó la extensión territorial de Suiza, con la integración de los cantones de Valais, Neuchâtel y Ginebra. Los límites de Suiza no han cambiado desde aquel entonces.

El cantón de Berna fue uno de los tres cantones que presidieron el Tagsatzung (antiguo consejo ejecutivo y legislativo) junto con Lucerna y Zúrich. La capital del cantón fue elegida en 1848 como sede de las autoridades federales, principalmente debido a su cercanía con el área francófona del país.

La restauración del poder fue solamente temporal. Después de un periodo de disturbios con repetidos enfrentamientos violentos, como el "Züriputsch" en 1839, estalló la guerra civil en 1847 cuando algunos de los cantones católicos trataron de establecer una alianza entre ellos ("Sonderbund"). La guerra duró menos de un mes, causando menos de cien víctimas, la mayoría de las cuales se debieron a fuego amigo. La guerra del Sonderbund parece muy pequeña comparada con otros conflictos que existieron en la Europa del siglo XIX y en la historia de su sociedad.

La guerra mostró a los habitantes la necesidad de unidad para fortalecerse ante sus vecinos europeos. Suizos de todos los estratos sociales, ya fuesen católicos, protestantes, liberales o conservadores, se percataron de que los cantones progresarían más si aunaran sus intereses económicos y religiosos.

Así, mientras el resto de Europa se encontraba en medio de revoluciones y guerras, los suizos promulgaron una constitución más moderna, la cual daba al gobierno un diseño federal, en gran parte inspirado en el modelo estadounidense. Esta constitución impuso una autoridad central, dejando a los cantones el derecho de autogobernarse y resolver cuestiones locales. Además la asamblea nacional se dividió en una cámara alta (el Consejo de los Estados de Suiza, con dos representantes por cada cantón) y una cámara baja (Consejo Nacional de Suiza, con representantes electos de todo el país). Para introducir cualquier cambio en la constitución se volvió obligatorio realizar un referéndum.

Asimismo se implantó un sistema único de pesas y medidas, y en 1850 el franco suizo se convirtió en la única moneda oficial del país. El artículo 11 de la constitución prohibió el envío de tropas al extranjero, pero hizo una excepción con los Estados Pontificios, al no considerar mercenarios a los miembros del ejército papal (Guardia Suiza). En tal sentido, en 1860 el ejército suizo fue obligado a participar al lado de Francisco II de las Dos Sicilias en el sitio de Gaeta.
Una de las cláusulas más importantes de la constitución era la que establecía que podía ser reescrita completamente si la ocasión lo demandaba, de esta forma la constitución evolucionaría totalmente en lugar de ser modificada año tras año. Esta característica de la constitución se volvió muy útil con la llegada de la Revolución industrial, cuando varios proclamaron que era hora de modificar la constitución. Un primer borrador fue rechazado por la población en 1872, pero dos años más tarde se aceptaron las modificaciones. Fue aquí cuando se introdujo un referéndum facultativo para la creación y modificación de leyes a nivel federal. También se establecieron normas que regulaban el ejército, el comercio y otras cuestiones legales. Finalmente, en 1891, la constitución fue revisada de nuevo y se implantó un inusual sistema de democracia directa, el cual sigue siendo único hasta el día de hoy.

Suiza no fue invadida en ninguna de las dos guerras mundiales. Durante la Primera Guerra Mundial, Suiza dio asilo a Vladimir Illych Ulyanov (Lenin) que permaneció allí hasta 1917. En 1919 la neutralidad de Suiza fue seriamente cuestionada por el escándalo protagonizado por Robert Grimm y Arthur Hoffmann, cuando intentaron pactar una tregua entre Rusia y Alemania. No obstante, en 1920, Suiza entró en la Sociedad de Naciones, la cual tenía su sede en Ginebra, con la única condición de que quedaría libre de todo requerimiento militar.

Durante la Segunda Guerra Mundial, el ejército alemán realizó detallados planes de invasión (Operación Tannenbaum) pero nunca invadió Suiza. El país fue capaz de mantener su independencia gracias a una combinación de disuasiones militares, concesiones a Alemania y muy buena suerte en las operaciones militares que retrasaron la invasión alemana. También existieron intentos por parte del Partido Nacionalsocialista suizo para anexar el país a Alemania, pero fallaron. La prensa suiza criticó duramente al Tercer Reich, insultando frecuentemente a su Führer. Suiza fue una importante base de espionaje para ambos bandos durante el conflicto, además de que a menudo actuó como mediadora en las comunicaciones entre los Aliados y las fuerzas del Eje. La Cruz Roja Internacional, con sede en Ginebra, jugó un papel muy importante durante este y otros conflictos.
El comercio con Suiza fue bloqueado por los Aliados y por los países del Eje. La cooperación económica y la ampliación del crédito para el Tercer Reich variaban según el riesgo de invasión y de la disponibilidad de otros socios comerciales. Las concesiones alcanzaron su punto máximo luego de que fuera cortada una línea ferroviaria que conectaba al país con la Francia de Vichy, dejando a Suiza completamente rodeada por el Eje. En el transcurso de la guerra, Suiza recibió más de 300 000 refugiados, de los cuales 104 000 eran soldados extranjeros, que fueron aceptados según los "Derechos y obligaciones de los países neutrales", documento firmado en las Conferencias de la Haya de 1899 y 1907; 60 000 de los refugiados eran civiles que habían escapado de la persecución de los nacionalsocialistas alemanes. De estos, alrededor de 27 000 eran judíos. Sin embargo, las estrictas políticas de inmigración y asilo, así como las relaciones financieras con la Alemania Nacionalsocialista, generaron controversia. Durante la guerra, la Fuerza Aérea Suiza combatió aeronaves de ambos bandos. En mayo y junio de 1940, derribaron once aviones de la Luftwaffe que habían invadido el espacio aéreo suizo, obligando a otras aeronaves intrusas a retirarse después de un cambio de la política en las relaciones con Alemania. Más de cien bombarderos Aliados y sus tripulaciones fueron albergados durante la guerra. En 1944, los Aliados bombardearon por error las ciudades de Schaffhausen (matando a cuarenta personas), Stein am Rhein, Vals y Rafz (con dieciocho muertos), así como Basilea y Zúrich el 4 de marzo de 1945.
En 1959, las mujeres obtuvieron el derecho a votar en algunos cantones, y más tarde, en 1971, este derecho se convirtió en ley federal. En 1963, Suiza se adhirió al Consejo de Europa. A finales de la década de 1970, una parte del cantón de Berna se separó y creó el nuevo cantón de Jura. En 1984, Elisabeth Kopp fue la primera mujer en el Consejo Federal Suizo y fue en 1999 cuando llegó a la presidencia la primera mujer, Ruth Dreifuss. El 18 de abril de ese mismo año, la población suiza votó a favor de una revisión completa de la constitución federal.
En 2002, Suiza se convirtió en miembro de pleno derecho de la ONU, por lo que la Ciudad del Vaticano queda como el único Estado reconocido que no pertenece a dicha organización. Suiza fue uno de los fundadores de la EFTA, pero no es miembro del Espacio Económico Europeo (EEE). Una solicitud de adhesión fue enviada a la Unión Europea en mayo de 1992, pero no prosiguió cuando el acceso al EEE fue rechazado en referéndum en diciembre de ese año. Desde entonces se han realizado múltiples referendos y votaciones sobre la entrada de Suiza en la Unión Europea, pero debido a las diversas reacciones que ha tenido la población, el proceso de obtención de la adhesión se ha detenido. Sin embargo, la ley suiza ha ido cambiando gradualmente para ajustarse a lo que la Unión Europea y el gobierno suizo afirman, a través de la firma de acuerdos bilaterales. Suiza y Liechtenstein han estado rodeados totalmente por la Unión Europea desde el ingreso de Austria en 1995. El 5 de junio de 2005, el 55% de los votantes suizos accedieron a unirse al Tratado de Schengen, un resultado que ha sido catalogado por la Unión Europea como una señal de apoyo por parte de Suiza, un país que es tradicionalmente percibido como independiente o aislacionista.

La constitución federal de 1848 es el fundamento legal del Estado federal moderno y la tercera constitución más antigua aún en vigencia en todo el mundo (después de la estadounidense y la noruega). Una nueva versión de la constitución fue adoptada en 1999, pero no introdujo cambios notables en la estructura federal. Esta delimita los derechos y obligaciones básicos de los ciudadanos, su participación activa en la política, divide el poder entre la confederación y los cantones y define las autoridades y jurisdicciones federales. Existen tres principales cuerpos de gobierno a nivel federal: el parlamento bicameral (poder legislativo), el Consejo Federal (poder ejecutivo) y el Tribunal Federal de Suiza (poder judicial). La función del Tribunal Federal es la de atender las apelaciones en contra de las cortes cantonales o federales. Los jueces o magistrados son elegidos por la Asamblea Federal para un periodo de seis años.

El Parlamento suizo se compone de dos cámaras: el Consejo de los Estados, que cuenta con 46 representantes (dos de cada cantón y uno de cada semicantón), los cuales son elegidos por cada cantón bajo su propio sistema; y el Consejo Nacional, el cual consta de 200 miembros elegidos mediante un sistema de representación proporcional, dependiendo de la población de cada cantón. Los miembros de las dos cámaras son elegidos cada cuatro años. Cuando ambas cámaras se encuentran en sesión conjunta, se les conoce como Asamblea Federal. A través de referendos los ciudadanos pueden rechazar o aceptar cualquier ley proveniente del parlamento, y por medio de iniciativas pueden introducir nuevos puntos a la constitución federal, haciendo de Suiza una democracia directa.

El Consejo Federal constituye el gobierno federal, dirige la Administración Federal y hace de jefe de Estado. Está integrado por siete miembros elegidos para un mandato de cuatro años por la Asamblea Federal, quien también vigila las acciones del consejo. El presidente de la Confederación es elegido por la asamblea de entre los siete miembros del consejo, tradicionalmente en rotación y solo por un periodo de un año; el presidente dirige el gobierno y asume sus funciones representativas. Sin embargo, el presidente es un "primus inter pares" sin poderes adicionales, y permanece a la cabeza de su departamento durante su administración.

Desde 1959, el gobierno federal suizo ha estado formado por una coalición de los cuatro principales partidos políticos, cada uno teniendo un número de asientos que difícilmente refleja su popularidad entre los votantes y el número de representantes en el parlamento. Desde 1959 hasta 2003, la clásica distribución de 2 CVP/PDC, 2 SPS/PSS, 2 FDP/PLR y 1 SVP/UDC fue conocida como la «fórmula mágica» ("Zauberformel"). Actualmente los siete asientos del Consejo Federal se encuentran distribuidos de la siguiente forma:

Los ciudadanos suizos son materia de tres jurisdicciones legales: la comuna, el cantón y la confederación. La constitución federal de 1848 define un sistema de democracia directa (a veces llamada "semidirecta" o democracia representativa directa debido a que tiene una mayor similitud con instituciones de una democracia parlamentaria). Los instrumentos de la democracia directa suiza a nivel federal, conocidos como derechos civiles ("Volksrechte" o "droits civiques"), incluyen el derecho a elaborar una "iniciativa constitucional" y a un "referéndum", los cuales pueden influir en las decisiones del parlamento.

Por medio de un "referéndum", un grupo de ciudadanos puede cuestionar alguna ley que haya sido aprobada por el parlamento si puede conseguir —en un plazo de cien días— más de 50 000 firmas que estén en contra de la ley. Si lo logra, se lleva a cabo una votación nacional, donde se decide por mayoría simple si la ley es rechazada o no. Ocho cantones unidos también pueden lanzar un referéndum para la aprobación de alguna ley federal.

De manera similar, la "iniciativa constitucional" permite a los ciudadanos solicitar que una enmienda constitucional sea puesta en votación si logran 100 000 firmas que apoyen la enmienda en un plazo de 18 meses. El parlamento puede complementar la enmienda propuesta con una contrapropuesta, donde los votantes tendrán que indicar su preferencia en las papeletas, en caso de que ambas propuestas sean aceptadas. Las enmiendas constitucionales, ya sean de iniciativa popular o parlamentaria, deben ser aceptadas por una mayoría doble del voto nacional y del voto cantonal.

La Confederación Suiza se compone de 26 cantones:

<nowiki>*</nowiki>

Su población varía entre los 15 000 habitantes del cantón de Appenzell Rodas Interiores y los 1,2 millones de habitantes del cantón de Zúrich, mientras que su superficie varía entre los 37 km² de Basilea-Ciudad y los 7100 km² de los Grisones. Los cantones comprenden un total de 2889 municipios. Dentro de Suiza existen dos enclaves: Büsingen, perteneciente a Alemania, y Campione d'Italia, perteneciente a Italia.

El 11 de mayo de 1919, en un referéndum organizado en el estado federado austriaco de Vorarlberg, más del 80% de la población votó a favor de que se integrara a la Confederación Suiza. Sin embargo, la oposición del gobierno de Austria, los Aliados, los liberales suizos, los suizos-italianos y los romandos impidió la anexión de Vorarlberg.

Tradicionalmente, Suiza evita todas las alianzas que puedan implicar acción militar, política o económica y ha sido neutral desde su expansión en 1515. No fue hasta 2002 cuando Suiza se convirtió en miembro completo de la ONU, pero fue el primer Estado en adherirse a la organización después de un referéndum. Suiza mantiene relaciones diplomáticas con casi todas las naciones e históricamente ha actuado como intermediario de otros Estados. Suiza no es miembro de la Unión Europea; la población suiza ha rechazado la membresía desde principios de la década de 1990. Sin embargo, desde 2005 forma parte del espacio de Schengen.

Un número alto de instituciones internacionales tienen su sede en Suiza, en parte debido a su política de neutralidad. La Cruz Roja fue fundada en 1863, y tiene su centro de operaciones en el país. A pesar de que Suiza es uno de los países que más recientemente se integraron a la ONU, en Ginebra se encuentra la segunda sede más grande de la organización después de la ubicada en Nueva York. Ginebra también es sede de varias organizaciones dependientes de la Organización de las Naciones Unidas (ONU), como la Organización Mundial de la Salud (OMS), la Organización Mundial de Comercio (OMC), la Organización Internacional del Trabajo (OIT), la Unión Internacional de Telecomunicaciones (UIT), la Organización Mundial de la Propiedad Intelectual (OMPI), la Organización Meteorológica Mundial (OMM) de la Conferencia de las Naciones Unidas sobre Comercio y Desarrollo (CNUCYD), y de la Unión Interparlamentaria (UIP); además de otras 200 organizaciones internacionales.

Incluso muchas federaciones y organizaciones deportivas tienen su sede en el país; como el Comité Olímpico Internacional (COI), la Federación Internacional de Esgrima (FIE) y el Tribunal de Arbitraje Deportivo (TAS) en Lausana; la United World Wrestling (UWW) en Corsier-sur-Vevey; la Federación Internacional de Hockey sobre Hielo (IIHF) y la Federación Internacional de Fútbol Asociación (FIFA) en Zúrich; la Unión Europea de Asociaciones de Fútbol (UEFA) en Nyon; y la Federación Internacional de Baloncesto (FIBA) en Ginebra. Otras federaciones y organizaciones deportivas también tienen su sede en Suiza, tales como: la Federación Internacional de Hockey (FIH), la Federación Internacional de Voleibol (FIVB), la Federación Internacional de Balonmano (IHF), la Federación Internacional de Tenis de Mesa (ITTF), la Federación Internacional de Esquí (FIS), la Unión Internacional de Patinaje sobre Hielo (ISU), la Federación Internacional de Natación (FINA), la Federación Aeronáutica Internacional (FAI), la Federación Internacional de Béisbol (IBAF), la Federación Mundial de Bridge (WBF) y la Liga Europea de Bridge (EBL), la Unión Internacional de Asociaciones de Alpinismo (UIAA), la Federación Internacional de Gimnasia (FIG) y la Unión Ciclista Internacional (UCI). Debido a que muchas federaciones y organizaciones deportivas tienen su sede en Suiza, el país es conocido como la capital mundial del deporte.

En Suiza están las sedes de la Unión Internacional de Química Pura y Aplicada (IUPAC), del Banco de Pagos Internacionales (BPI), de la Organización Internacional de Normalización (ISO), del Foro Económico Mundial (WEF), de la Oficina del Alto Comisionado para los Derechos Humanos (OACDH), de la Comisión Económica de las Naciones Unidas para Europa (UNECE o ECE), de la Organización Internacional para las Migraciones (OIM), del Consejo Mundial de Iglesias (CMI), de la Unión Europea de Radiodifusión (UER), de la Comisión Internacional de Juristas (CIJ), de la Organización del Bachillerato Internacional (OBI), de la Organización Mundial del Movimiento Scout (OMMS), de la Asociación Mundial de Cardiología (AMC), de la Asociación Cristiana de Jóvenes (YMCA) y de la Asociación Europea de Libre Comercio (EFTA).

También se halla el Palacio de las Naciones, que es un complejo de edificios que fueron construidos entre 1929 y 1937 en el seno del Parque Ariana en Ginebra. Sirvió de sede a la Sociedad de Naciones (SDN) hasta 1946. Más tarde fue ocupado por la Organización de las Naciones Unidas (ONU), y en 1966, el palacio se convierte en sede de la Oficina de la Organización de las Naciones Unidas en Ginebra (ONUG) y es la segunda más importante de la organización después de la sede de Nueva York.

Asimismo se encuentra la sede principal del Fondo Mundial para la Naturaleza (WWF) y del Fondo Mundial de lucha contra el sida, la tuberculosis y la malaria.

Muchos organismos internacionales que tienen su sede en Suiza, fueron fundados en otros países y tuvieron sus sedes en su país de fundación y en otros países, hasta llegar finalmente a Suiza, donde sus sedes radicarán permanentemente y nunca más se cambiarán a otro país, debido a su política de neutralidad; claros ejemplos son la FIFA y el COI, que fueron fundados en París (Francia) pero decidieron cambiar su sede de origen a Suiza (la FIFA fundada en París se trasladó a Zúrich y el COI también fundado en París, a Lausana). Otros organismos internacionales como la Cruz Roja Internacional (CRI), el Comité Internacional de la Cruz Roja (CICR) y la Federación Internacional de Sociedades de la Cruz Roja y de la Media Luna Roja (IFRC) fueron fundados directamente en Suiza, y nunca cambiarán sus sedes a otro país por su política de neutralidad.

Las Fuerzas Armadas Suizas se componen del ejército y la Fuerza Aérea Suiza. Como Suiza es un país sin otra salida al mar que a través de las aguas internacionales del río Rin, no cuenta con una marina de guerra, pero en los lagos limítrofes el ejército dispone de botes armados. La peculiaridad del Ejército Suizo es el sistema de milicia. Los soldados profesionales constituyen solo el 5% del personal militar. El resto son ciudadanos alistados de entre 20 y 34 años. Los ciudadanos suizos tienen prohibido servir en tropas extranjeras, con la excepción de la Guardia Suiza, que sirve al Papa.

La estructura de la milicia suiza estipula que los soldados deben mantener en casa su propio equipo, incluyendo la famosa navaja del ejército suizo y sus armas personales. Algunas organizaciones y partidos políticos encuentran esta práctica como controvertida y peligrosa. A la edad de 19 años, el servicio militar es obligatorio para todos los ciudadanos varones; las mujeres pueden servir voluntariamente. Cerca de las dos terceras partes de los jóvenes suizos son declarados aptos para el servicio; los descartados deben pagar un impuesto especial en su lugar. Anualmente, cerca de 20 000 personas son entrenadas para el combate en un curso de 18 a 21 semanas. La reforma «Ejército XXI» fue adoptada por voto popular en 2009 y reemplazó al antiguo modelo "Ejército 95", reduciendo el número de efectivos de 400 000 a 200 000. De estos, 120 000 son soldados activos y 80 000 reservistas.
En total, solo se han declarado tres movilizaciones generales para asegurar la integridad y neutralidad de Suiza. La primera con motivo de la guerra franco-prusiana entre 1870 y 1871. La segunda fue decidida en respuesta al estallido de la Primera Guerra Mundial en agosto de 1914. La tercera movilización tuvo lugar en septiembre de 1939 a consecuencia de la invasión alemana a Polonia, y Henri Guisan fue elegido comandante en jefe.

Debido a su neutralidad, el ejército no puede formar parte en conflictos armados en otros países, pero ha participado en varias misiones de paz alrededor del mundo. Desde 2000, el departamento de Defensa también utiliza el sistema de inteligencia Onyx para monitorizar las comunicaciones por satélite. Después de la Guerra Fría ha habido numerosos intentos para reducir la actividad militar e incluso disolver el ejército. Uno de los referendos más importantes sobre este tema se celebró el 26 de noviembre de 1989 y, aunque no fue aprobado, mostró que un alto porcentaje de la población suiza estaba a favor de dichas iniciativas.

Extendiéndose sobre las laderas norte y sur de los Alpes, Suiza comprende una gran variedad de formas de relieve y climas en un área de 41 285 km². La población total es de algo más de 8 millones de habitantes, resultando en una densidad de población de unos 187 hab./km². La parte sur del país es montañosa y se encuentra menos densamente poblada que la parte norte, donde el terreno, en parte boscoso y en parte despejado, cuenta con la presencia de varios lagos.

Suiza se puede dividir en tres áreas topográficas básicas: los Alpes suizos en el sur, la meseta suiza en el centro y las montañas de Jura en el norte. Los Alpes son una cordillera de montañas altas que corren a través del centro y sur del país, ocupando cerca del 60% de la superficie total. Entre los picos más altos de los Alpes suizos, siendo el mayor la Punta Dufour ("Dufourspitze") con 4634 msnm, se encuentran múltiples valles, con cascadas y glaciares. Estos conforman la cabecera de algunos de los ríos más importantes de Europa, como el Rin, el Ródano, el Eno, el Aar y el Tesino. Otros ríos fluyen por el país y desembocan en los grandes lagos que hay en el territorio nacional, como el lago Lemán, el lago de Zúrich, el lago de Neuchâtel o el lago de Constanza.

Una de las montañas más famosas del país es el Cervino (4478 msnm) en los Alpes Peninos, formando parte de la frontera con Italia. Otras de las montañas más altas del país se encuentran en esa zona: la Punta Dufour (4634 msnm), el Dom (4545 msnm) y el Weisshorn (4506 msnm). En la sección de los Alpes berneses, al norte de Lauterbrunnen, se halla un valle con 72 cascadas, también conocido por los montes Jungfrau (4158 msnm) y Eiger (3970 msnm), y otros de los valles más pintorescos de la región. En el sureste destaca el valle de Engadina, donde se localiza la comuna de Sankt Moritz, y el pico más alto de la zona es el Piz Bernina (4049 msnm).

La parte septentrional del país es la más poblada, ocupando cerca del 30% de la superficie del país; es también llamada meseta suiza ("Mittelland" en alemán). Cuenta con amplios valles con colinas, bosques y pastizales, que suelen utilizarse para la agricultura y la ganadería. Es en esta zona donde se ubican las ciudades y los lagos más grandes de Suiza. El lago más grande del país es el lago Lemán, en la parte occidental del mismo y compartido con Francia.

El clima es por lo general templado, pero puede variar mucho de localidad a localidad, de las condiciones glaciares en la cima de las montañas a un clima casi mediterráneo en el sur del país. Los veranos suelen ser cálidos y húmedos con lluvias periódicas que ayudan al desarrollo de la agricultura en la región. Los inviernos en las montañas alternan días de sol y nieve, mientras que las tierras más bajas tienden a tener días nublados y neblinosos. Un fenómeno climatológico llamado Efecto Föhn puede ocurrir en cualquier época del año, incluso en invierno, y se caracteriza por el paso del aire cálido del Mediterráneo por los Alpes desde Italia. Las zonas con menos precipitaciones son los valles meridionales en el Valais, donde se cultiva el valioso azafrán y viñedos para la producción de vinos. Los Grisones también tienden a ser más secos y ligeramente más fríos, aunque a veces reciben numerosas nevadas en invierno. Las condiciones más húmedas del país persisten en las alturas de los Alpes y en el cantón del Tesino, donde las lluvias y nevadas son abundantes. La zona oriental tiende a ser más fría que la occidental del país, además de que las precipitaciones suelen ser escasas a lo largo del año, con variaciones menores entre el paso de las estaciones. El otoño suele ser la estación más seca del país, aunque los patrones del clima en Suiza pueden variar mucho de un año a otro, haciendo que sea muy difícil predecirlo.

Los ecosistemas de Suiza pueden ser particularmente vulnerables, lo cual se debe a que los múltiples valles delicados separados por las montañas a menudo forman ecosistemas únicos. Las regiones montañosas en sí son también vulnerables, con una amplia gama de plantas que no se encuentran a esas altitudes en otras partes del mundo, pero que están expuestas al maltrato de los visitantes y de la ganadería.

El calentamiento global es particularmente duro para Suiza. Esto se debe al clima continental y la ubicación en las latitudes medias. Entre el inicio de los registros meteorológicos en 1864 y 2019, se convirtió en un promedio de 1.9°C más cálido en Suiza. Como resultado, las temperaturas en Suiza aumentaron el doble de rápido que el promedio mundial. El calentamiento se ha acelerado en los últimos 30 años. Cada año entre 1991 y 2019 fue más cálido que el promedio de los años 1961 a 1990. De las diez temperaturas promedio más cálidas de junio desde que comenzaron los registros climáticos, siete se midieron después de 2002. En 1890, Davos todavía tenía 231 días de heladas (= número de días por debajo de 0°C); en 2018 solo hubo 161 días de heladas en Davos. El área de los glaciares suizos casi se redujo a la mitad entre 1850 (1621 km²) y 2019 (944 km²). Los estudios científicos llegan a la conclusión de que alrededor de 2050 los deportes de invierno ya no serán posibles en Suiza si no se cumple el objetivo de dos grados del acuerdo climático de París.

La estructura geológica de Suiza es esencialmente el resultado de la colisión entre las placas de África y Europa que ha ocurrido durante los últimos millones de años. Este fenómeno es especialmente visible en la falla de cabalgamiento de Sardona, declarada por UNESCO Patrimonio de la Humanidad.

Desde el punto de vista geológico, Suiza se divide en cinco regiones principales. Los Alpes, que esencialmente se componen de granito, y el macizo del Jura, que es una cordillera de pliegues más joven, de calizas. Entre la cadena montañosa de Jura y Los Alpes se encuentra la meseta suiza, que en parte es llana y en parte con lomajes. Se agregan además el Valle del Po en el extremo sur del Tesino, el valle del Mendrisiotto (Mendrisio), así como la fosa tectónica del Alto Rin en las inmediaciones de Basilea, la cual está ubicada en su mayor parte fuera de Suiza.

Las enormes masas de hielo —que durante las distintas glaciaciones avanzaron adentrándose mucho en el territorio de la Meseta Suiza— marcaron de manera determinante y dieron forma a la topografía de la Suiza actual durante los últimos dos millones de años.

Suiza cuenta con una de las economías capitalistas más estables, poderosas y modernas del mundo, ubicada entre las diez mejores según el Índice de Libertad Económica de 2009. El PIB nominal per cápita de Suiza es más alto que el de la mayoría de las economías europeas, solo superado por el de Luxemburgo. La moneda oficial del país es el franco suizo (CHF).

El índice de paridad de poder adquisitivo (PPA) de Suiza se encuentra entre los quince mejores del mundo. El reporte de competitividad del Foro Económico Mundial coloca a la economía de Suiza como la segunda más competitiva en el mundo. En gran parte del siglo XX, Suiza fue el país más rico en Europa por un margen considerable.

Suiza es el hogar de algunas de las corporaciones multinacionales más grandes del mundo. Las compañías más grandes de Suiza son: Glencore, Nestlé, Novartis, Hoffmann-La Roche, ABB, Sika AG y Adecco. También destacan los bancos mundiales UBS AG, Servicios Financieros Zúrich, Credit Suisse Group, Swiss Re y los grupos relojeros Swatch y Richemont. UBS AG es un banco privado y un banco de inversión que se ocupa de la gestión de riquezas ("wealth management") y de activos ("asset management") de clientes privados, corporativos e institucionales. Entre sus servicios, ofrecidos a nivel nacional y mundial, destaca también la banca de inversión ("investment banking"). Junto a Credit Suisse, UBS es el mayor y más antiguo banco presente en la Confederación Helvética. 
Las actividades económicas más importantes en Suiza se encuentran la industria química, la industria farmacéutica, la fabricación de instrumentos musicales y de medición, las inmobiliarias, los servicios financieros y el turismo. Las principales exportaciones del país son los productos químicos (34% de los bienes exportados), la maquinaria electrónica (20,9%) y los instrumentos de precisión y relojes (16,9%). Los servicios exportados suman un tercio de los bienes exportados.

La población económicamente activa llega a los 3,8 millones de personas. Suiza cuenta con un mercado laboral más flexible que los países vecinos y el índice de desempleo se mantiene bajo. Sin embargo, el índice de desempleo aumentó de 1,7% en junio de 2000 a 3,9% en septiembre de 2004. En abril de 2009 el índice de desempleo había bajado hasta 3,4%, en parte debido al alza de la economía que comenzó a mediados de 2003.

El sector privado en la economía suiza es inmenso, además de que el país cuenta con bajas tasas de impuestos para los estándares occidentales, siendo una de las de los países desarrollados. El lento crecimiento económico de Suiza en la década de 1990 y principios de 2000 trajo consigo una serie de reformas económicas para adaptarse al modelo de la Unión Europea. Según Credit Suisse, solo el 37% de los habitantes del país es dueño de su propia casa, uno de los índices más bajos en toda Europa. El aumento de los precios de los alimentos y bienes raíces fueron del 145 y 171% en 2007, mientras que en Alemania fueron del 104 y 113%. El proteccionismo agrícola, una rara excepción a la política de libre comercio suiza, contribuye al alza de los precios de los alimentos. Según la OCDE, la liberalización de los mercados está retrasando algunas economías europeas como Suiza. Sin embargo, el PPA suizo es uno de los más altos en el mundo. Aparte de la agricultura, las barreras económicas y del comercio entre la Unión Europea y Suiza son mínimas y el país ha firmado múltiples acuerdos de libre comercio con otros países del mundo.

La electricidad generada en Suiza proviene en un 56% de centrales hidroeléctricas, un 34% de centrales nucleares y un 5% de centrales térmicas y de otros combustibles convencionales como el carbón.

El 18 de mayo de 2003, fueron rechazadas dos iniciativas antinucleares: "Moratorium Plus", que pedía el cese de la construcción de nuevas plantas de energía nuclear (41,6% a favor y 58,4% en contra), y "Electricidad sin energía nuclear" (33,7% a favor y 66,3% en contra). La antigua moratoria de diez años para la construcción de nuevas centrales de energía nuclear fue el resultado de una iniciativa ciudadana de 1990, en la cual el sí ganó con el 54,5% de los votos, contra el no que obtuvo 45,5%. La Oficina Federal de Energía Suiza (SFOE) es la responsable de responder y atender todas las quejas y dudas sobre el abastecimiento y la utilización de la energía, junto con el Departamento Federal de Medio Ambiente, Transporte, Energía y Comunicaciones (DETEC). Estas agencias apoyan el concepto de la «Sociedad de 2000 vatios» para reducir en más de la mitad el consumo de energía del país hasta el año 2050.
La administración de las vías terrestres suizas es financiada a través de la viñeta suiza y con los impuestos sobre los vehículos. El sistema de autopistas suizo requiere la compra de una pegatina o viñeta, con un valor de 40 CHF por un año, tanto para vehículos de pasajeros como de carga. La red de carreteras suizas tiene una longitud de 1638 km (2000) y un área aproximada de 41 290 km², lo que convierte a Suiza en uno de los países con mayor número de autopistas en proporción a su tamaño. El aeropuerto más grande del país es el Aeropuerto Internacional de Zúrich, por el cual pasaron más de 20,7 millones de pasajeros en 2007. A este le siguen el Aeropuerto Internacional de Ginebra con 10,8 millones de pasajeros y el Aeropuerto de Basilea-Mulhouse con 4,3 millones de pasajeros, ambos aeropuertos son compartidos con Francia.

La red ferroviaria cuenta con 5063 km, transportando a más de 350 millones de pasajeros anualmente. En 2007, cada ciudadano suizo había recorrido un promedio de 2103 km en tren. La red ferroviaria es administrada principalmente por la SBB-CFF-FFS, excepto en gran parte de los Grisones, donde los 366 km de vía estrecha son operados por el Ferrocarril Rético, que incluye algunas líneas que son Patrimonio de la Humanidad. La construcción de túneles a través de los Alpes ha reducido la duración de los viajes que se efectúan entre el norte y el sur.

Suiza es altamente activa en cuanto al reciclaje y las regulaciones anticontaminantes, siendo uno de los recicladores más grandes del mundo, con un aprovechamiento de los materiales reciclables que va del 66% al 96%. En muchos lugares de Suiza, la recolección de basura en los vecindarios no es gratuita. La basura (excepto materiales peligrosos, baterías, etc.) es recogida solo si está en bolsas con una calcomanía que demuestra el pago, o en bolsas oficiales entregadas al depositar el pago del servicio. Esto supone un incentivo económico para reciclar, ya que el reciclaje es gratuito. Funcionarios de salubridad y la policía revisan los depósitos de basura para buscar aquellas bolsas donde no se verifique el pago del servicio, así como antiguas cuentas y recibos que puedan dar pista de dónde provienen aquellas bolsas. Las multas por no pagar el sistema de recolección de basura van de 200 a 500 CHF.

La educación en Suiza es muy diversa debido a que la constitución del país delega la autoridad del sistema escolar a cada cantón. Existen escuelas públicas y privadas, incluyendo muchos colegios de renombre internacional. La edad mínima para ingresar en la escuela primaria es de seis años en todos los cantones. La escuela primaria consta de cuatro a seis grados, dependiendo de la escuela. Tradicionalmente, la primera lengua extranjera que se enseñaba en las primarias era alguno de los otros idiomas oficíales, aunque en el año 2000 en algunos cantones se empezaron a dar cursos de inglés. Al final de la escuela primaria (o al comienzo de la escuela secundaria), los alumnos están separados en varios grupos (a menudo tres) de acuerdo a sus capacidades intelectuales. Los que aprenden más rápido son inscritos en clases avanzadas para ser preparados para el examen matura o bachillerato y para estudios más específicos, mientras que los escolares que asimilan los conocimientos un poco más lentamente reciben una educación más adecuada a sus necesidades. En Suiza también se encuentra el Instituto Le Rosey, apodado «la escuela de los reyes» debido a los numerosos monarcas que han estudiado en él. Es conocido como uno de los internados más caros y lujosos del mundo.

Existen 12 universidades en Suiza, diez de ellas son administradas a nivel cantonal y suelen ofrecer carreras no técnicas. La primera universidad del país fue fundada en 1460 en Basilea (con una facultad de Medicina) y tiene fama de ser uno de los mejores centros de investigación química y médica en Suiza. La mayor universidad del país es la Universidad de Zúrich con cerca de 25 000 estudiantes. Los dos institutos administrados por el gobierno federal, la ETH en Zúrich (fundada en 1855) y la EPFL en Lausana (fundada en 1969, anteriormente asociada a la Universidad de Lausana), gozan de una excelente reputación internacional. En 2008, la ETH Zúrich figuraba entre los mejores quince institutos del campo "Ciencias Naturales y Matemáticas" según una lista publicada por la Universidad de Shanghái Jiao Tong, mientras la EPFL se encontraba en el puesto 18.º de la categoría "Ingeniería/Tecnología y ciencias computacionales". Además, existen varias universidades de ciencias aplicadas. Suiza tiene el segundo mayor índice de estudiantes extranjeros en educación terciaria, solo por detrás de Australia.

Hay varios científicos suizos que han sido galardonados con el premio Nobel, por ejemplo, el famoso físico alemán nacionalizado suizo Albert Einstein, quien desarrolló la teoría de la relatividad mientras trabajaba en Berna. Más recientemente Vladimir Prelog, Heinrich Rohrer, Richard Ernst, Edmond Fischer, Rolf Zinkernagel y Kurt Wüthrich recibieron el premio Nobel de diversas ciencias. En total, hay 113 ganadores del premio Nobel que tienen alguna conexión con Suiza, y el Premio Nobel de la Paz ha sido entregado nueve veces a organizaciones con sede en el país.

En Ginebra se encuentra el laboratorio más grande del mundo, el CERN, dedicado a la investigación de la física de partículas. Otro importante centro de investigación es el Instituto Paul Scherrer. Entre las invenciones muy conocidas figuran el LSD, el microscopio de efecto túnel (premio Nobel) y el popular velcro. Algunas tecnologías ayudaron a la exploración de nuevos mundos, como el globo presurizado de Auguste Piccard y el batiscafo de Jacques Piccard, que le permitió llegar al punto más profundo del océano.

La Agencia Espacial Suiza, llamada Oficina Espacial Suiza, participó en el desarrollo de varios programas y tecnologías espaciales. En 1975 también fue uno de los diez fundadores de la Agencia Espacial Europea y es el séptimo contribuyente más importante para la AEE. En el sector privado, varias compañías están implicadas en la industria espacial, como Oerlikon Space y Maxon Motors.

En 2009, Suiza contaba con una población estimada en 7 725 200 habitantes. Los extranjeros que residen y trabajan temporalmente en el país conformaban en 2007 el 22,1% de la población. La mayoría de ellos (60%) provienen de países de la Unión Europea o de la EFTA. Los italianos son el grupo extranjero más grande del país, siendo el 17,3% de la población extranjera total. Son seguidos por los alemanes (13,2%), inmigrantes de Serbia y Montenegro (11,5%) y Portugal (11,3%). En los últimos años se produjo una fuerte inmigración albanesa, sobre todo procedente de Kosovo. Los inmigrantes de Sri Lanka, la mayoría de ellos refugiados tamiles, son el grupo asiático más grande del país. En la década de 2000, instituciones nacionales e internacionales han expresado su preocupación sobre lo que ellos creen es un incremento en la xenofobia, particularmente en algunas campañas políticas. Sin embargo, la alta proporción de ciudadanos extranjeros en el país, así como la integración de elementos extranjeros a la cultura suiza, subrayan la apertura de la sociedad suiza. Basilea, Ginebra y Zúrich están entre las diez ciudades más habitables del mundo. El 99,0% de la población está alfabetizada.

Suiza se encuentra en el cruce de algunas de las grandes culturas europeas, las cuales han influenciado fuertemente el idioma y la cultura del país. Suiza tiene tres idiomas oficiales (alemán, francés, italiano) y uno parcialmente oficial, el romanche. Todas las leyes y documentos oficiales deben estar en todas las lenguas oficiales. Los suizos suelen hablar el idioma de su región y consumir los medios de comunicación en su idioma. En el sistema educativo de Suiza, los estudiantes aprenden en el idioma nativo de su región, como segundo idioma otra lengua nacional (alemán, francés o italiano) y como tercera lengua pueden elegir entre otro idioma nacional y el inglés.

En cada cantón solo un idioma nacional es oficial, normalmente el idioma local, aunque hay cantones donde hay bilingüismo e incluso trilingüismo.

Además, los tres idiomas oficiales cuentan con algunos términos que no son entendidos fuera de Suiza, por ejemplo, palabras extraídas de otro idioma (en alemán utilizan la palabra "billette" que proviene del francés), o de palabras parecidas en otro idioma (en italiano se usa el término "azione" no para "acción", sino como "descontar o rebajar", que proviene del alemán "Aktion"). 

Aprender otro de los idiomas nacionales es obligatorio para todos los escolares suizos, por lo que se supone que la mayoría de los suizos son bilingües.

El alemán suizo (63,7% de la población total lo habla, junto con extranjeros residentes en el país; 72,5% de los residentes con la ciudadanía suiza en 2000) en el norte, este y centro del país.

El alemán hablado en Suiza pertenece al grupo de dialectos del alemán conocidos como alemán suizo o helvético, aunque en las escuelas y medios escritos se usa el alemán estándar. La mayoría de las transmisiones en radio y televisión se dan en alemán suizo.

El francés es hablado por un 20,4%, siendo lengua materna (incluyendo extranjeros) para el 21,0%. Se habla en el oeste.

Existen dialectos del franco-provenzal que son hablados en algunas comunidades rurales de la parte francófona, conocida como Romandía, entre los que se encuentran el vaudois, el gruérien, el jurassien, el empro, el fribourgeois y el neuchatelois.

El italiano es hablado por un 6,5%, siendo lengua materna (incluyendo extranjeros) para el 4,3%. Se habla en el sur.

En la parte italiana del país se habla el tesinés (un dialecto lombardo). 

El romanche, una lengua romance que es hablada localmente por una minoría (0,5%; 0,6%) en el sureste, en el cantón de Grisones, es designado por la constitución federal como un idioma nacional junto con el alemán, el francés y el italiano (artículo 4 de la constitución), y como un idioma oficial si las autoridades desean comunicarse con personas que hablan este idioma (artículo 70), pero las leyes federales y otros documentos oficiales no deben ser escritos obligatoriamente en este idioma. El gobierno federal debe comunicarse en los idiomas oficiales, y en el parlamento federal se da una interpretación simultánea en alemán, francés e italiano.

En 2006 la esperanza de vida al nacer era de 79 años para los hombres y 84 años para las mujeres, una de las más altas en el mundo. Los ciudadanos suizos cuentan con un seguro médico que es obligatorio, permitiendo el acceso a una amplia variedad de servicios médicos modernos. Sin embargo, los gastos en los cuidados para la salud son particularmente altos, ya que desde 1990 se ha registrado un aumento en la cantidad del presupuesto que se utiliza para cubrir los gastos médicos, que para 2003 representaban el 11,5% del PIB; esta situación se ha reflejado en los altos costes de los servicios prestados. Con una población cada vez más anciana y nuevas tecnologías en el cuidado de la salud, se espera que estos gastos continúen aumentando.

Entre dos tercios y tres cuartas partes de la población viven en zonas urbanas. Suiza pasó de ser un país rural a uno urbanizado en solo setenta años. Desde 1935 el desarrollo urbano ocupó gran parte del paisaje suizo desocupado los últimos 2000 años. Esta dispersión urbana no solo afecta a la meseta suiza, sino también a las montañas del Jura y los Alpes, y continúan aumentando las concesiones para el uso de la tierra. Sin embargo, desde principios del siglo XXI, el crecimiento de la población es mayor en las zonas urbanas que en cualquier otra área.

Suiza cuenta con una densa red de ciudades, donde se complementan las poblaciones grandes, medianas y pequeñas. La meseta suiza está densamente poblada, con una población relativa de 450 hab./km² y el paisaje continuamente muestra signos de la presencia del hombre. Las áreas metropolitanas más grandes son Zúrich, Ginebra-Lausana, Basilea y Berna, y tienden a expandirse. En una comparación internacional la importancia de estas áreas urbanas es mayor de lo que sugiere su número de habitantes. Además, las dos ciudades de Zúrich y Ginebra son reconocidas por la buena calidad de vida que ofrecen.

Suiza no tiene ninguna religión estatal oficial, aunque la mayoría de los cantones (excepto Ginebra y Neuchâtel) reconocen sus propias iglesias oficiales. En todos los casos incluyen la Iglesia católica y la Iglesia reformada de Suiza, que son financiadas mediante el impuesto eclesiástico. Estas iglesias, y en algunos cantones la Iglesia católica antigua y las congregaciones judías, son financiadas por diezmos pagados por los creyentes.

En el 2018, 37,2% (3 182 082 personas) de la población total eran miembros de la Iglesia católica y 24,7% (2 109 360 personas) eran miembros de la Iglesia reformada (población total en el 2018: 8 546 081).

Según una encuesta del Oficina Federal de Estadística de Suiza entre personas de 15 años o más del 2018, el cristianismo es la religión predominante en Suiza, dividido entre la Iglesia católica (35,2% de la población), la Iglesia reformada de Suiza (23,1%) y otros cristianos (5,6%). Un 5,6% de la población es musulmana, en 0,2% es judía y en 1,5% es otros religiones. En 28,0% de la población de 15 años o más no se declara perteneciente a una religión en general. La encuesta del Eurobarómetro de 2005 anunció que el 48% de los suizos entrevistados era teísta, el 39% expresó creer en "un espíritu o una fuerza de la vida", el 9% era ateo y el 4% agnóstico. El 30 de noviembre de 2009, el 57,5% de los suizos votó a favor de la prohibición de los alminares en el país, lo que ocasionó que se organizaran varias protestas en varias partes del mundo por parte de musulmanes.

El país ha estado históricamente dividido entre los católicos y los protestantes, con una compleja mezcla de territorios con mayorías católicas y protestantes por todo el país. En 1597, el cantón de Appenzell fue dividido oficialmente en dos para los católicos y protestantes. Las ciudades más grandes (Berna, Zúrich y Basilea) son predominantemente protestantes. El centro del país, así como el Tesino, son tradicionalmente católicos. La constitución federal de 1848, bajo la reciente impresión de los enfrentamientos entre los cantones católicos y protestantes que culminaron en la "Sonderbundskrieg", define un Estado consociacional, permitiendo la coexistencia pacífica entre ambos grupos. En 1980 se votó una iniciativa para separar completamente la iglesia y el Estado pero fue rechazada, con solo el 21,1% de la población a favor.

La cultura de Suiza está influida por los países vecinos, pero a través de los años se ha desarrollado una cultura distinta e independiente con algunas diferencias regionales. En particular, las regiones francófonas se orientaron más hacia la cultura francesa. En general, los suizos son conocidos por su larga tradición humanitaria, ya que Suiza fue el lugar de nacimiento del movimiento de la Cruz Roja y alberga al Consejo de Derechos Humanos de las Naciones Unidas. De forma similar, en la Suiza alemana están más orientados hacia la cultura alemana, aunque los hablantes del alemán suizo se identifican estrictamente como suizos debido a la diferencia entre el alto alemán y los dialectos del alemán suizo. En la Suiza italiana se percibe mayormente la cultura italiana. En resumen, una región tiene una conexión cultural más estrecha con el país vecino que comparte su idioma. La cultura romanche, lingüísticamente aislada en las montañas del este de Suiza, se esfuerza por mantener vivas sus tradiciones no solo lingüísticas.

Muchas zonas montañosas están altamente conectadas con las culturas deportivas del esquí en invierno y del senderismo en verano. A lo largo del año, algunas zonas tienen una cultura de ocio para atraer el turismo, incluso en primavera y verano, las estaciones más tranquilas, cuando hay menos visitantes y mayor presencia suiza. Una tradicional cultura de granjas y cultivos también predomina en algunas, y las pequeñas granjas continúan siendo omnipresentes en las afueras de las ciudades.

En el cine, las producciones estadounidenses conforman la gran mayoría de las carteleras, aunque varias películas suizas han tenido éxito comercial. El arte folclórico se mantiene vivo gracias a varias organizaciones ubicadas a lo largo del territorio nacional, donde se fomenta la música, la danza, la poesía, la talla de madera y el bordado. La trompa de los Alpes, una trompa hecha de madera, junto con el yodel y el acordeón, se han convertido en el símbolo internacional de la música suiza tradicional.

Como la confederación estuvo compuesta, desde su fundación en 1291, casi exclusivamente por regiones de habla alemana, las primeras obras literarias están en alemán. En el siglo XVIII, el francés se convirtió en el idioma de moda en Berna y otras regiones, mientras que la influencia de los aliados francófonos y otros territorios se iba marcando más que antes.

Entre los autores clásicos de la literatura suiza en alemán se encuentran Jeremias Gotthelf (1797-1854), Gottfried Keller (1819-1890) y Conrad Ferdinand Meyer (1825-1898). Los cuatro máximos representantes de la literatura suiza del siglo XX son Carl Spitteler (1845-1924) (Premio Nobel de Literatura, 1919), Robert Walser (1878-1956), Max Frisch (1911-1991) y Friedrich Dürrenmatt (1921-1990), autor de "Die Physiker" ("Los físicos") y "Das Versprechen" ("La promesa").

Los escritores suizos francófonos más prominentes son Jean-Jacques Rousseau (1712-1778), Germaine de Stael (1766-1817) y Benjamin Constant (1767-1830). Autores más recientes incluyen a Blaise Cendrars (nacido Frédéric Sauser, 1887-1961), a Charles Ferdinand Ramuz (1878-1947), cuyas novelas describen la vida de los campesinos que habitaban las zonas montañosas en una época decadente, a Gustave Roud (1897-1976) y a Philippe Jaccottet (n. 1925). Autores de habla italiana y romanche también han contribuido a la literatura suiza, pero de una forma más modesta.

Ferdinand de Saussure, lingüista suizo, padre del estructuralismo.

Probablemente, la creación más famosa de la literatura suiza sea "Heidi", la historia de una niña huérfana que vive con su abuelo en los Alpes, uno de los libros para niños más populares en el mundo que se ha convertido en un símbolo de Suiza. Su creadora, Johanna Spyri (1827-1901), escribió otras obras con temas similares.

El concepto de protección del patrimonio apareció en el país a finales del siglo XIX. Además, siete sitios culturales son parte del patrimonio de la humanidad: la ciudad vieja de Berna, la abadía de San Galo, el convento benedictino de Saint-Jean-des-Sœurs, los tres castillos de Bellinzona, los viñedos de Lavaux, el Ferrocarril Rético en el paisaje del Albula y del Bernina y el urbanismo relojero de las villas de La Chaux-de-Fonds y del Locle.

Muchos castillos y fortificaciones fueron construidos en la Edad Media por las familias dinásticas, que les sirvieron tanto como residencias como de lugares defensivos, destacando el castillo de Chillon, Lenzburgo, Mesocco, Burgdorf, Kyburgo o los tres castillos de Bellinzona. Las villas medievales estaban fortificadas y algunas, como Murten/Morat, conservan y mantienen sus murallas, aunque en la mayoría de los casos solo quedan vestigios en el corazón de ciudades, como la de Zug, la "puerta de Spalen" en Basilea o la de Berna.

Los edificios religiosos aparecieron a partir del siglo VI y se construyeron conventos, monasterios, iglesias y catedrales, entre los que sobresalen la abadía de San Galo, la abadía de Einsiedeln, la abadía de San Mauricio de Agaune, la catedral de Basilea, la abadía de Romainmôtier y la catedral de Lausana.

Hay edificios públicos, algunos que datan de la época romana, como el anfiteatro de Avenches, y también ayuntamientos, siendo el más antiguo el de Berna (1406). El ayuntamiento de Basilea (1504-1514), con su fachada de color rojo, es muy característico. La torre cuadrada en el patio del ayuntamiento de Ginebra (1555) es una edificación típica de la tradición renacentista francesa en piedra tallada. En el siglo XIX, se erigen nuevos edificios públicos para oficinas de correos, estaciones de ferrocarril, museos, teatros, iglesias y escuelas, como el Palacio Federal, la estación central de Zúrich, el Museo Nacional Suizo, el Gran Teatro de Ginebra y la Universidad de Zúrich.

Suiza tiene algunos conjuntos urbanos notables: el casco antiguo de Berna, con sus soportales, plazas y fuentes, es representativo de la ciudad medieval en Europa. Al final del siglo XIX, nacen nuevos distritos en el lugar que ocupaban las antiguas fortificaciones de las grandes ciudades, como la Bahnhofstrasse de Zúrich o el Cinturón fazyste de Ginebra. El crecimiento es objeto de planificación urbana: en 1834, La Chaux-de-Fond, que fue destruida por el fuego, se reconstruyó de acuerdo a una nueva estructura urbana (véase Ensemble urbain du XIXe siècle de La Chaux-de-Fonds). A principios del siglo XX se crean viviendas para los trabajadores basándose en el modelo de la Werkbund, como la parcelación de Freidorf (1919-1921) en Muttenz, síntesis entre el ideal de la ciudad jardín y del movimiento cooperativo. En el periodo comprendido entre 1945 y 1975 se construyeron en los suburbios de las grandes ciudades nuevas ciudades satélites, como Le Lignon en las afueras de Ginebra.

Desde el siglo XV, aparecen las casas civiles de estilo gótico en piedra, por ejemplo, la Grimmenturm de la Spiegelgasse en Zúrich, la casa Tavel en Ginebra, la "Haus zum Rüden" en Zúrich, la "Haus zum Ritter" en Schaffhausen, el "hotel de Ratzé" (1583-1586) en Friburgo y la "casa Serodine" (1620) en Ascona. Durante el Renacimiento, se abrieron arcadas en el Tesino y en el patio del castillo de Muralto, el antiguo "Palazzo Rusca" en Lugano y el "Colleggio Papio" en Ascona. En la Suiza alemana, el primer edificio renacentista fue el palacio Ritter (1556) de Lucerna.

Las casas particulares barrocas estaban ricamente decoradas con ménsulas en uno o varios pisos, como en Schaffhausen, y tenían miradores de madera o piedra, como en San Galo. Por ejemplo, el "Herrenstube" y el "Frontwagenturm" en Schaffhausen. En Zúrich, se erigieron dos casas de corporaciones en piedra tallada y presentan un aspecto severo: "Zimmerleuten" (1708) y "Saffran" (1719-1723). La región occidental está más influenciada por la arquitectura barroca francesa; este estilo se impuso en la Suiza romanda a finales del siglo XVII. Se trata de verdaderas mansiones en la rue des Granges en Ginebra, con patio de honor. También hay ejemplos de estilo rococó.

Desde 1800, se diseñaron grandes villas clasicistas, como el palacio Eynard (1817-1821) en Ginebra. Más tarde, en el siglo XX aparecen algunas realizaciones arquitectónicas del movimiento Moderno: la villa Le Lac (1923) y el inmueble Clarté (1931) en Ginebra de Le Corbusier, o la Cité Halen (1957-1961) del Atelier 5, cerca de Berna, un ejemplo de casas individuales contiguas en terraza para la clase media.

La diversidad de espacios naturales en Suiza se refleja en la gran variedad de casas rústicas, que se construyen en diversas variantes alpinas: las "Gotthardhaus" ('casas del Gotardo'), de madera, que se encuentran en aislados valles de montaña del Tesino, del Valais y en los Grisones; casa "valaisanne", del Valais, de madera, típica de la región del Valais y del Val d'Hérens; la casa tesinesa, del Tesino, en moellons; la casa engadinesa decorada con pinturas murales y Sgraffitems; las casas del Oberland bernés y Simmental, de madera maciza trabajada con sierra, "Strickbau" o en maderos cuadrados, cortados con hacha.

En la meseta suiza, las casas bernesas, cubiertas con enormes tejados en caballete con carpinterías decoradas con motivos esculpidos; las chaumières (cabañas) argovianas, las casas à colombages de madera en la meseta oriental y en Zúrich; las granjas de usos múltiples ("Dreisässenhäuser") del noroeste y de la meseta romanda, construidas en piedra.

En el Jura, las granjas jurasianas tienen grandes fachadas de piñón, totalmente en piedra recubiertas con cal.

Las infraestructuras, como puentes y túneles, son numerosas. El puente del Diablo en el corazón de los Alpes en el camino hacia el paso de San Gotardo o el Mittlere Brücke, sobre el Rin en Basilea, son ejemplos históricos. Muchos puentes medievales son de madera, como el Kapellbrücke en Lucerna. En el siglo XIX, se construyeron algunos puentes suspendidos de cables de acero en Ginebra (puente de San Antonio) y Friburgo (Gran puente), que en 1834, en el momento de su construcción, era el más largo de su género. Muchos puentes y túneles para el ferrocarril, como el viaducto de Landwasser, los túneles de del Gotardo y del Simplon se construyeron en el cambio del siglo XX. El puente de Salginatobel o el viaducto de Chillon son obras viarias del siglo XX.

La libertad de prensa y el derecho de libre expresión están reconocidos por la constitución de Suiza. La Agencia de Noticias Suiza (SNA) transmite durante todo el día información sobre política, sociedad, economía y cultura en los tres idiomas oficiales. La SNA es la que aporta casi todas las noticias sobre Suiza, y varios servicios de noticias extranjeros colaboran con ella.

Históricamente, Suiza ha tenido el mayor número de periódicos publicados en proporción a su población y tamaño. Los periódicos más influyentes son el "Tages-Anzeiger", el "Neue Zürcher Zeitung" (ambos en alemán) y "Le Temps" (en francés), pero casi cada ciudad cuenta con su periódico local. La diversidad cultural del país contribuye a la publicación de múltiples periódicos.

En contraste a los medios impresos, las radiodifusoras siempre han estado en gran parte bajo el control del gobierno. La Radiodifusora Suiza, cuyo nombre recientemente se cambió a SRG SSR, es la encargada de producir y transmitir varios programas nacionales de radio y televisión. Los estudios de la SRG SSR están distribuidos a través de las diferentes regiones lingüísticas. Los programas de radio son producidos en seis estudios centrales y cuatro estudios locales, mientras que los programas de televisión se realizan en Zúrich (SF), Ginebra (TSR), Lugano (RTSI) y Coira (RTR). Una gran compañía de transmisión por cable también permite el acceso de la población suiza a los programas de países vecinos.

La gastronomía de Suiza es multifacética. Mientras algunos platos como la "fondue", la "raclette" o el "rösti" están presentes en todas las cocinas del país, cada región desarrolló su propia gastronomía, coincidiendo cada zona gastronómica con las distintas zonas lingüísticas. La cocina tradicional suiza usa ingredientes parecidos a los de otros países europeos, entre otros productos lácteos y quesos como el gruyer/Greyerz o el emmental, producido en valles de Gruyère y de Emmental, de donde toman sus nombres.

El chocolate se ha fabricado en Suiza desde el siglo XVIII, pero ganó su reputación a finales del siglo XIX con la invención de técnicas más modernas, como el conchado y el templado, que ayudaron a mejorar la calidad de los productos. Además, otro de los grandes adelantos suizos en esta industria fue la invención del chocolate con leche en 1875 por Daniel Peter. Por ello una de las tartas típicas suizas es la "Tre Choklad" (tarta de tres chocolates).

El vino, principalmente blanco, se produce sobre todo en Valais, Vaud, Ginebra y Tesino. Los viñedos han existido en la zona desde la época de los romanos, e incluso se hallaron vestigios que podrían datar de fechas anteriores. Las variedades más producidas son el Chasselas (llamado "Fendant" en Valais) y el Pinot Noir. El Merlot es la principal variedad producida en Tesino.

En algunas zonas rurales como St. Gallen o Appenzell aún mantienen la tradición de consumir carne de perro.

Gran parte de los deportes más populares en Suiza son deportes de invierno. El esquí y el montañismo son muy practicados en el país tanto por suizos como por extranjeros, ya que sus cumbres nevadas atraen a alpinistas de todo el mundo. El país ha organizado múltiples campeonatos y torneos mundiales de deportes invernales, incluyendo dos ediciones de los juegos olímpicos de invierno en 1928 y 1948, ambos en Sankt Moritz. Además, en Engelberg, se celebra anualmente una de las pruebas de la Copa de Mundo de saltos de esquí.

Muchos suizos también son seguidores del hockey sobre hielo y apoyan a uno de los 12 clubes en la Liga A. En abril de 2009 Suiza fue la sede del Campeonato Mundial de Hockey sobre Hielo, por décima ocasión.

Como otros europeos, muchos suizos son aficionados del fútbol. El país cuenta con su propia selección nacional, organizada por la Asociación Suiza de Fútbol. Ha disputado ocho Copas del Mundo, siendo los cuartos de final su mejor resultado. Además ha participado en cuatro Eurocopas, donde solo en una, la Eurocopa 2016, ha pasado de la primera fase. Suiza organizó la Copa Mundial de Fútbol de 1954, así como la Eurocopa 2008 junto a Austria. La principal competición de fútbol del país es la Super Liga Suiza.

El automovilismo, el motociclismo y otros deportes similares fueron prohibidos en Suiza después del desastre de Le Mans en 1955 con la excepción de eventos como la carrera de montaña. Esta prohibición fue retirada en junio de 2007. Durante este periodo, siguieron surgiendo en algunas regiones del país varios corredores exitosos como Clay Regazzoni, Jo Siffert y Alain Menu, y Peter Sauber fundó la escudería que porta su nombre y que lleva compitiendo en la Fórmula 1 desde el año 1992.

El ciclismo es otro deporte que cuenta con una amplia promoción y participación. En Suiza, se celebran gran variedad de pruebas ciclistas, como la Vuelta a Suiza y el Tour de Romandía, además de que el país ha sido sede de campeonatos internacionales, como el Campeonato Mundial de Ciclismo en Ruta. Entre los ciclistas suizos más destacados figuran Fabian Cancellara, Alex Zülle y Tony Rominger.

El tenis ha cobrado popularidad en Suiza, con jugadores de la talla de Martina Hingis, Stan Wawrinka y Roger Federer, este último, es considerado el mejor jugador en la historia del deporte.

En balonmano, la Selección de balonmano de Suiza ha logrado la medalla de bronce en los Juegos Olímpicos de 1936, además de los cuartos puestos logrados en el Campeonato Mundial de Balonmano Masculino de 1954 y en el Campeonato Mundial de Balonmano Masculino de 1993.

Existen otros deportes donde varios deportistas suizos han sido exitosos, como la esgrima (Marcel Fischer), el piragüismo (Ronnie Dürrenmatt), la vela (Alinghi), el kayakismo (Mathias Röthenmund), el voleibol (Sascha Heyer, Markus Egger, Paul y Martin Laciga), snowboard (Martina Weber), entre otros.

Suiza es, junto a Australia, Francia y el Reino Unido, uno de los cuatro únicos países que han estado presentes en todas las ediciones de los Juegos Olímpicos.
Los deportes tradicionales suizos incluyen la lucha llamada "Schwingen", una antigua tradición de los cantones rurales del centro del país. El "steinstossen" es la variante suiza del lanzamiento de peso, una competición donde se arroja lo más lejos posible una pesada piedra. Practicado entre la población alpina desde la época prehistórica, se popularizó en Basilea alrededor del siglo XIII. El hornussen es otro deporte autóctono de Suiza, el cual es una mezcla entre el béisbol y el golf y es practicado principalmente en la zona norte del país.

En Suiza se ubican las sedes de numerosos organismos deportivos, entre ellos el Comité Olímpico Internacional, el Tribunal de Arbitraje Deportivo (TAS), la FIFA, la UEFA, y las federaciones internacionales de baloncesto (FIBA), hockey sobre césped (FIH), hockey sobre hielo (IIHF), voleibol (FIVB), balonmano (IHF), tenis de mesa (ITTF), esquí (FIS), patinaje sobre hielo (ISU) y natación (FINA).











</doc>
<doc id="2691" url="https://es.wikipedia.org/wiki?curid=2691" title="Siglo X a. C.">
Siglo X a. C.

El siglo X a. C. comenzó el 1 de enero de 1000 a. C. y terminó el 31 de diciembre de 901 a. C.


</doc>
<doc id="2692" url="https://es.wikipedia.org/wiki?curid=2692" title="Saskatchewan">
Saskatchewan

Saskatchewan () es una de las diez provincias que, junto con los tres territorios, conforman las trece entidades federales de Canadá. Es la provincia central de las Praderas canadienses. Su capital es Regina y su ciudad más poblada, Saskatoon.

La mayor parte de su población se concentra en la parte sur de la provincia. La agricultura es una parte fundamental en la economía de Saskatchewan, sobre todo el trigo, del que se cosecha el 45% de todo el país, por lo que se ganó el nombre de «el granero de Canadá». Otra fuente fundamental de la economía de la provincia es la minería. Saskatchewan es la mayor productora de uranio del mundo.

El nombre de la provincia proviene del río Saskatchewan, cuyo nombre deriva del cree: "kisiskāciwani-sīpiy," que significa ‘río de curso veloz’.

A grandes rasgos, Saskatchewan tiene forma de trapecio, con un área de 588276,09km². Sin embargo, debido a su tamaño, los límites septentrional y meridional, que son segmentos de los paralelos 49° norte y 60° sur, respectivamente, presentan una curvatura apreciable. Además, el límite oriental de la provincia está parcialmente torcido en lugar de seguir un meridiano, cuando las líneas de corrección fueron ideadas por topógrafos antes del programa (1880-1928). Saskatchewan limita al oeste con Alberta, al norte con los Territorios del Noroeste, al este con Manitoba, y al sur con los estados estadounidenses de Montana y Dakota del Norte. Saskatchewan es la única provincia canadiense en la que ninguna de sus fronteras se corresponden con rasgos geográficos físicos. Es también una de las dos únicas provincias sin salida al mar, junto con Alberta.

Saskatchewan está formada por dos regiones naturales principales: el Escudo Canadiense en el norte y las Llanuras Interiores en el sur. El norte de Saskatchewan está cubierto principalmente por el bosque boreal excepto las Dunas de Arena del Lago Athabasca, las dunas de arena activas más grandes del mundo al norte del paralelo 58°, adyacentes a la orilla sur del lago Athabasca. El sur de Saskatchewan contiene otra área con dunas de arena conocidas como «las Grandes Colinas de Arena» que cubren 300km². Las Colinas del Ciprés (Cypress Hills), localizadas en el borde sudoeste de Saskatchewan y "Killdeer Badlands" (Grasslands National Park) son áreas de la provincia que permanecieron sin congelarse durante el último período de glaciación.

El punto más alto de la provincia, a 1468 (metros sobre el nivel del mar), está localizado en las Colinas del Ciprés. El punto más bajo, con 213 metros, está en la orilla de lago Athabasca en el extremo norte. La provincia tiene nueve cuencas hidrográficas distintas formadas por varios ríos que desembocan en aguas del océano Ártico, bahía de Hudson y golfo de México.

Saskatchewan está lejos de cualquier masa significativa de agua. Esto, combinado con su latitud norte produce un verano frío tipo clima continental húmedo (en la clasificación climática de Köppen, Dfb) en la mitad este, y clima de estepa de seco a semiárido (en la clasificación de Köppen, Bsk) en la parte occidental de la provincia. Los veranos pueden ser muy calientes, con temperaturas por encima de 32°C durante el día. Hay rachas de vientos cálidos del sur procedentes de los Estados Unidos durante la mayor parte de julio y agosto. Si bien los inviernos pueden ser penetrantes, con temperaturas máximas por debajo de −17°C durante semanas, los vientos "chinook" (vientos cálidos y húmedos) a menudo soplan del sur, trayendo períodos suaves. La precipitación anual media va de 30 a 45cm a lo largo de la provincia, con el grueso de la lluvia en junio, julio y agosto.

Los diez municipios más poblados
La siguiente lista no incluye a Lloydminster, que tiene una población total de 23632 habitantes y se extiende a ambos lados de la frontera con Alberta. De acuerdo con el censo de 2001, solo 7840 personas vivían en el sector perteneciente a Saskatchewan, lo que posicionaría a esta ciudad en el undécimo lugar respecto a los municipios más poblados de la provincia. Todas las comunidades relacionadas son consideradas ciudades por la provincia, con la excepción de Corman Park, que es una municipalidad rural. Los municipios de la provincia con una población de 5000 o más habitantes reciben oficialmente el estatus de ciudad.

Antes de la llegada de los europeos, Saskatchewan se encontraba habitada por las tribus athabaskan, algonquiana, y sioux. El primer europeo en instalarse en Saskatchewan fue Henry Kelsey en 1690, que navegó a lo largo del río Saskatchewan en un intento por comerciar con piel, comprándosela a los indígenas de la zona. El primer establecimiento de origen europeo fue la Compañía de la Bahía de Hudson, situada en Cumberland House y fundada por Samuel Hearne en 1774.

Tras la venta de la Luisiana en 1803 por Francia a Estados Unidos, parte de las provincias actuales de Alberta y Saskatchewan, en el actual Canadá, pasaron a Estados Unidos, que cedería esa parte al Reino Unido en 1818.

A mediados del siglo XIX, las expediciones científicas encabezadas por John Palliser y Henry Youle Hind exploraron la región de la pradera provincial.

En la década de 1870, el Gobierno de Canadá formó los Territorios del Noroeste para administrar al vasto territorio comprendido entre la Columbia Británica y Manitoba. El gobierno accedió también a la firma de una serie de tratados con los nativoamericanos de su entorno, lo que fomentó la relación entre las «Primeras Naciones» (en inglés, "First Nations"), como se las conoce hoy en día, y la Corona. Poco después, las Primeras Naciones se verían empujadas a ciertas reservas.

La colonización de la provincia cogió vuelo cuando la Canadian Pacific Railway (Vía canadiense del Pacífico) fue construida a comienzos de los años 1880, y el gobierno federal dividió a la tierra conforme a la "Medición del dominio terrestre," otorgando fanegas libres a colonos voluntariosos.

La policía montada del noroeste edificó unos cuantos puestos y fortificaciones a lo largo de Saskatchewan, entre los que destacan: Fort Walsh en los Montes Cipreses, y Wood Mountain, puesto en el centro meridional de Saskatchewan, cerca de la frontera con Estados Unidos.

En 1876, siguiendo a la Batalla del Pequeño Cuerno Grande el cacique de los Lakota, Toro Sentado, guio a su gente hacia Wood Mountain, cuya reserva se fundó en 1914.

Muchos integrantes de los Métis, que no habían sido signatarios de tratado alguno, se trasladaron al distrito de Saskatchewan Rivers, al norte de la actual Saskatoon, tras la Rebelión del Red River que tuvo lugar en Manitoba en 1870. A comienzos de la década de 1880, el gobierno de Canadá rehusó oír las quejas de los Métis, que partían de temas vinculados a la ocupación territorial. Finalmente, en 1885, los Métis, mandados por Louis Riel, provocaron la Rebelión del Noroeste en reclamo de un gobierno provisional. Fueron vencidos por la milicia canadiense asentada en las praderas de la "Canadian Pacific Railway." Riel se rindió y fue declarado culpable de traición por un tribunal de Regina. Finalmente fue ejecutado el 16 de noviembre de 1885.

Con la llegada de más colonos a la región, la población fue creciendo, y Saskatchewan pasó a ser considerada una provincia el 1 de septiembre de 1905; el día de inauguración fue el 4 de ese mes.

El "Homestead Act" permitía a los colonos adquirir millas cuadradas de tierra para el cercamiento de haciendas, y ofrecía un cuarto adicional tras realizar el cometido inicial de dicha concesión. La inmigración llegó a la cima en 1910 y, pese a las dificultades de la vida fronteriza y de su alejamiento respecto a la ciudad y sus ventajas, se consiguió establecer una sociedad agraria próspera y estable.

En 1913, la Asociación de Criadores de Ganado de Saskatchewan logró establecerse como la primera organización agrícola de la provincia. La convención fundacional de 1913 había fijado, para entonces, tres objetivos principales que servirían de orientación: vigilar la legislación; seguir los intereses de la CG en la forma más honorable y legítima posible; y sugerir al parlamento el cambio de condiciones y requisitos cuando lo estime conveniente. En 1970, la primera reunión anual en Canadá tuvo lugar en Regina.

En 2005, Saskatchewan celebró su centenario. Para tal efecto, la Royal Canadian Mint (Real Ceca del Canadá) puso en circulación una moneda de 5 dólares canadienses conmemorativa que representaba los campos de trigo de la provincia. Además, se acuñó otra moneda similar de 25 centavos. La reina Isabel II de Inglaterra asistió a la ceremonia, y la cantante canadiense Joni Mitchell publicó un álbum en homenaje a Saskatchewan.

La economía de Saskatchewan es tradicionalmente agrícola; sin embargo, la emergente diversificación ha propiciado que ahora esta actividad, junto a la forestación, la pesca y la caza constituyan tan sólo el 6,8% del PIB de la provincia. El trigo es el cultivo más común, y quizás el único representativo de Saskatchewan, pero también están presentes otros como colza, lino, centeno, avena, arvejas, lentejas, mijo, y cebada. Asimismo, la minería es de vital importancia para la provincia. Saskatchewan es el primer exportador mundial de potasa. En la zona septentrional la actividad forestal recobra cierta relevancia.

Saskatchewan es también el mayor proveedor de uranio del mundo, y abastece a la mayor parte del hemisferio occidental. La industria de este mineral es seguida de cerca por el gobierno provincial que avala su cotización en el mercado internacional.

El PIB de Saskatchewan era en 2003 de 32 000 millones de dólares canadienses, con sectores económicos que se dividían de la siguiente manera:

Las compañías importantes que se encuentran en Sasckatchewan son la Hill family's Harvard Developments, Viterra (previamente Saskatchewan Wheat Pool), la Concentra Financial Services, la metalúrgica Ipsco (aunque su base operacional se asiente en Lisle, un barrio de Chicago), la productora de maquinaria agrícola Brandt Industries, PotashCorp y Cameco.

La Crown corporation incluye a las entidades más destacadas de la provincia: SaskTel, SaskEnergy (proveedora de gas natural), y SaskPower. El Bombardier opera en el NATO Flying Training Centre (Centro de entrenamiento aéreo de la OTAN) en 15 Wing, próximo a Moose Jaw. Bombardier obtuvo un contrato a largo plazo a fines de los años 1990, por un monto de 2800 millones del gobierno federal, para la compra de material aeronáutico militar y la gestión de adiestramiento.

Saskatchewan posee la misma forma de gobierno que otras provincias canadienses, con su Teniente-Gobernador (que representa a la monarquía), el "Premier" (o Primer Ministro), y una legislatura unicameral.

Durante muchos años, Saskatchewan ha sido una de las provincias de Canadá más de izquierdas, reflejando la voluntad de muchos de sus ciudadanos en cuestiones de alienación por los intereses del gran capital. En 1944 Tommy Douglas se convirtió en "premier" y estableció el primer gobierno socialista regional de Norteamérica. La mayor parte de sus MAL (Miembros de la Asamblea Legislativa) representaban a pequeños pueblos y predios rurales. Bajo su Cooperative Commonwealth Federation (CCF), el gobierno de Saskatchewan haría de ésta la primera provincia en contar con servicio de atención médica general. En 1961, Douglas abdicó de su cargo para convertirse en la primera figura política federal del Nuevo Partido Democrático.

A lo largo del período de posguerra, la CCF y sus sucesores, los Nuevos Demócratas de Saskatchewan, dominaron el campo político de la mano de Douglas Allan Blakeney, y Roy Romanow, todos sirviendo como "premiers" durante un tiempo, y transformándose en figuras nacionales. La urbanización desde la Segunda Guerra Mundial había alterado la economía provincial al despojarla de su base agrícola, lo que ocasionó una ligera emigración de los campos a la ciudad. Como resultado, hubo un correspondiente cambio en la ideología del NDS, que pasó a preocuparse más de los asuntos urbanos que de los rurales.

El Partido Liberal de Saskatchewan fue el principal en el poder durante gran parte de los primeros años de vida de la provincia, gobernando de 1905 a 1929 y de 1934 a 1944. Emergió nuevamente en 1964, pero se volvió insignificante tras la derrota del gobierno liberal de Ross Thatcher en 1971. El Partido Progresivo Conservador de Saskatchewan encabezado por Grant Devine, reemplazó gradualmente a los liberales como el nuevo rival del NDS, consiguiendo una apabullante victoria en la «Matanza del lunes por la noche» ("Monday Night Massacre") de 1982. No obstante, la popularidad de los conservadores cayó en picado a causa de los grandes déficits, aliándose con el gobierno federal de Mulroney en 1991. Muchos miembros de la Asamblea Legislativa, incluyendo a algunos ministros de gabinete, fueron declarados culpables de apropiación de fondos públicos, por lo que el Partido Conservador fue suspendido, aunque recientemente ha anunciado su intención de prsentarse a la próxima elección provincial.
Actualmente, la oposición oficial en la provincia la representa el Partido de Saskatchewan, una nueva facción política fundada en 1997 y que comprende a los antiguos simpatizantes de los "Tories," a los primeros liberales e incluso a algunos neodemócratas frustrados por la incapacidad de evolución del NDS en materia de economía y población. El actual "premier" de Saskatchewan es el neodemócrata Lorne Calvert, cuyo gobierno fue reelecto en la elección general de la provincia en 2003, por la mínima mayoría posible: el NDS obtuvo 30 de los 58 escaños de la Asamblea Legislativa y el PS los 28 restantes. Los primeros representan a ciudades y pueblos, y los segundos se centran mayoritariamente en la defensa del ámbito rural. Las «Primeras Naciones» y los Métis se hallan involucrados en la política y otras instituciones pero su representación es muy escasa. Un largo debate entre los círculos académicos canadienses gira en torno a si la extensión del sufragio a las «Primeras Naciones» inadvertidamente «regulariza» su papel de miembro de las naciones que han firmado tratados internacionales con la Corona en momentos en los que la etnia local era diferente.

Además de los tres largos períodos del NDS como gobierno provincial, Sakatchewan se inclina más hacia el derecho de política federal. De las 14 dependencias federales de la provincia, 12 son comúnmente ocupadas por miembros conservadores del Parlamento. Mientras que Sakatchewan dispone de una mayoría gubernamental del NDS, el NDS federal ha sido desplazado de la provincia durante dos elecciones consecutivas. Los únicos liberales son el Ministro de Finanzas Ralph Goodale, y Gary Merasty, primer Jefe Supremo del Consejo Superior de Prince Albert, cuya elección trajo a flote alegaciones de un posible fraude.

Aunque los habitantes de ascendencia europea componen la mayoría de la población, los aborígenes constituyen una minoría bastante considerable. Las etnias que no pertenecen a ninguno de los susodichos grupos son, en proporción, insignificantes.

"Fuente: Statistics Canada"

Origen étnico
"Nota: En el cuestionario del censo de 2001 un individuo podía hacer constar más de un origen étnico, por lo que la suma de las cifras que siguen sobrepasa el 100%."


La primera educación en las praderas fue impartida dentro del grupo familiar de la Primera Nación o las primeras familias de comerciantes de pieles. Había sólo unos pocos misioneros o escuelas de puestos de comercio establecidas en la Tierra de Rupert, más tarde conocida como los Territorios del Noroeste.

En 1886 se forman los 76 primeros distritos escolares de los Territorios del Noroeste y la primera reunión del Consejo de Educación. El gran incremento de la inmigración condujo a la formación de bloques étnicos. Las comunidades buscaban para sus hijos una educación similar a la de las escuelas de sus lugares de procedencia. Se construyen cabañas de troncos y residencias para las asambleas de la comunidad, escuelas, iglesias, bailes y reuniones.

Los prósperos años veinte y los agricultores que se establecieron con éxito en sus haciendas proporcionaron la financiación para regularizar la educación. Los libros de texto, las escuelas normales para profesores educados formalmente, los planes de estudio escolares y los programas arquitectónicos estatales de escuelas de arte proporcionaron continuidad cultural a toda la provincia. El inglés como lengua escolar ayudó a proporcionar la estabilidad económica al poder comerciar unos con otros. El número de escuelas de distrito individuales a lo largo de Saskatchewan alcanzó aproximadamente el número de 5.000, a la altura de las escuelas de distrito individuales del sistema educativo a finales de los años 1940.

Tras la Segunda Guerra Mundial, la transición de muchas escuelas individuales a un menor número pero mayores y tecnológicamente modernas escuelas de ciudad se produjo como un medio de asegurar la educación técnica. Los autobuses escolares, las carreteras, y los vehículos familiares permitieron estudiar en escuelas alejadas del lugar de residencia. Los tractores y demás maquinaria agrícola indujeron un cambio de granjas familiares y cosechas de subsistencia a grandes cultivos. Ya no había necesidad de comunidades cada 10 ó 16 kilómetros de separación o dentro del alcance de un carro y un caballo. Esta evolución todavía sigue y según el análisis de la primavera de 2007, otras 50 escuelas consolidadas rurales afrontan ahora el cierre inminente.

Los vales escolares (certificado por el cual se ofrece a los padres la posibilidad de pagar por la educación de sus hijos en una escuela de su opción, en lugar la escuela pública a la que fueron asignados) han sido propuestos recientemente como un medio de permitir la competencia entre escuelas rurales y hacer practicable la operación de escuelas cooperativas en áreas rurales.




</doc>
<doc id="2695" url="https://es.wikipedia.org/wiki?curid=2695" title="Semántica lingüística">
Semántica lingüística

La semántica lingüística es un subcampo de la semántica general y de la lingüística que estudia la codificación del significado dentro de las expresiones lingüísticas. Etimológicamente, el término viene del griego "sēmantikós", que quería decir 'significado relevante', derivada de "sêma", lo que significaba 'signo'.

Una lengua es un sistema convencional para la comunicación verbal, es decir, un sistema para transmitir mensajes convencionalmente codificados, que transmitan información o permitan interaccionar con otros individuos.

La transmisión de información requiere algún tipo de codificación del contenido semántico en forma de expresiones lingüísticas. La sintaxis codifica explícitamente algunas de las relaciones sintácticas de la situación o estado de hechos descrito por el mensaje. Así, los nombres representan las entidades físicas que intervienen en un estado de hechos, mientras que el verbo describe estados de algunas de estas entidades o los procesos que realizan unas entidades sobre las otras. Los diferentes tipos de entidades materiales pueden ser clasificados de acuerdo con el tipo de función que desempeñan en cada estado de hechos en diferentes papeles temáticos. 
Así, una descripción gramatical de una lengua debe contener ciertos principios que describan cómo se codifican los papeles temáticos de las entidades que intervienen en una oración. Por ello, la información semántica es una parte integral de la gramática.

Sin embargo, la semántica lingüística no se agota en el estudio de los papeles temáticos y su codificación. Por ejemplo, la semántica léxica trata de la codificación de significados, tanto en la dimensión paradigmática, y también de los significados obtenidos mediante derivación mediante diversos procedimiento morfológicos.


La semántica léxica, rama de la Lingüística que estudia el significado de las palabras, se puede enfocar desde una perspectiva onomasiológica, en la que se parte del significado para llegar a la forma, o desde una perspectiva semasiológica, que parte de la forma (significante) para llegar al estudio del significado.

Una adecuada descripción de las lenguas naturales debe contener datos de significado, referencia lingüística y condiciones de verdad. Pero los análisis semánticos también se aplican a aquellas expresiones construidas de palabras: las frases y las oraciones. Tradicionalmente las frases y las oraciones han recibido más atención que las palabras que las componen.


Sin embargo el concepto de referente conlleva ciertos problemas. Por un lado, no funciona siempre, ya que no todos los verbos denotan acción, ni todos los adjetivos, cualidades... Tampoco funciona cuando el nombre se refiere a una entidad que no existe, algo imaginario. Por último, varias expresiones pueden compartir el mismo referente pero significar cosas muy distintas. Por todo ello, cuando se estudia la palabra tenemos en cuenta lo siguiente:


Por lo tanto es una rama de la gramática lingüística muy importante en la elaboración de textos.


De este modo, mientras que "perro" y "chucho" denotan el mismo significado, sus connotaciones son muy diferentes. La connotación varía según a quien se le sugiera. De tal manera, la palabra "pacifista" tiene distintas connotaciones en la jerga militar y en un grupo de ""hippies"".

Cabe mencionar que los sinónimos no existen, dado que se pierde la ley de la lengua, "la que dice que una lengua busca la eficiencia, el menor esfuerzo que hay en una lengua".

Así mismo los semas constituyen una parte fundamental en cuanto a los constituyentes del significado, siendo en este contexto la unidad básica funcional.



</doc>
<doc id="2696" url="https://es.wikipedia.org/wiki?curid=2696" title="Senegal">
Senegal

El Senegal, cuyo nombre oficial es República del Senegal (en francés: "République du Sénégal"), es un estado soberano de África Occidental cuya forma de gobierno es la república semipresidencialista. Su territorio está organizado en catorce regiones.

Debe su nombre al río Senegal, que marca la frontera este y norte del país. Senegal limita con el océano Atlántico al oeste, con Mauritania al norte, con Malí al este, y con Guinea y Guinea-Bisáu al sur. Gambia forma un enclave virtual dentro de Senegal, siguiendo el río Gambia durante más de 300 km tierra adentro. Las islas de Cabo Verde se encuentran 560 km mar adentro, frente a la costa senegalesa. La población del país se estima en aproximadamente 16 millones de personas. El clima es tropical con dos estaciones, una seca y otra lluviosa.

Dakar, la capital del Senegal, se ubica en el punto más occidental del país, en la península de Cabo Verde. Durante los siglos y , numerosos puestos comerciales pertenecientes a diferentes potencias coloniales se establecieron en la costa. La ciudad de St. Louis se convirtió en esta época en la capital del África Occidental Francesa antes de que se mudara a Dakar en 1902. Dakar se convirtió posteriormente en su capital en 1960 en el momento de la independencia de Francia.

El país recibe su nombre a partir del río Senegal, cuya etimología es discutida. Una teoría popular, propuesta por David Boilat en 1853, afirma que deriva de la expresión wólof "sunu gaal", que significa "nuestra canoa", resultado de la dificultad para comunicarse entre los marineros portugueses del siglo y los pescadores wólof. Los historiadores modernos creen que el nombre hace referencia, probablemente, a la etnia bereber de los zenaga, quienes vivieron en la orilla norte del río. Una teoría que compite con las anteriores afirma que el nombre deriva de la ciudad medieval de "Sanghana" (también conocida como Isenghan, Asengan o Singhanah), descrita por el geógrafo árabe al-Bakri en 1068 como localizada en la boca del río. A pesar de todo lo anterior, la teoría de "nuestra canoa" ha sido popularmente abrazada en el Senegal moderno por su aire caluroso y su utilidad en los llamamientos a la solidaridad nacional (por ejemplo, "estamos todos en la misma canoa") hace que se oiga con frecuencia en los medios de comunicación.

Algunos serer del sur creen que el nombre del río deriva, originalmente, de la unión de los términos serer "Sene" (de Roge Sene, Deidad Suprema en la religión serer) y "O Gal" (que significa "cuerpo de agua").

Hallazgos arqueológicos por toda el área indican que el Senegal estuvo habitado en tiempos prehistóricos. El islam se estableció en el valle del río Senegal en el siglo ; el 95 % de los senegaleses de hoy en día son musulmanes. En los y , el área estuvo bajo la influencia de los imperios mandingas del Este; el imperio Jolof de Senegal también fue fundado durante este tiempo. En el siglo , el imperio Jolof se dividió en cuatro reinos competidores: los Jolof, Waalo, Cayor y Baol.

Varias potencias europeas (Portugal, los Países Bajos, e Inglaterra) compitieron por el comercio en esa área desde el siglo , hasta que en 1677, Francia terminó con la posesión de lo que se había convertido en un importante punto de partida del comercio de esclavos (la isla de Gorea, cercana a Dakar). Solo a partir de los años 1850 los franceses, bajo el gobernador Louis Faidherbe, comenzaron a expandirse por el propio territorio senegalés.

En enero de 1959, el Senegal y el Sudán francés se unieron para formar la Federación de Malí, que se convirtió en una nación totalmente independiente el 20 de junio de 1960, como resultado de la independencia y el acuerdo de transferencia de poder firmado con Francia el 4 de abril de 1960. Debido a dificultades políticas internas, la Federación se disolvió el 20 de agosto de 1960. El Senegal y el Soudan (renombrado como la República de Malí) proclamaron su independencia. Léopold Senghor, un conocido poeta internacional de la negritud, político y estadista, fue elegido como primer presidente de Senegal en agosto de 1960.

Después de la disolución de la Federación de Malí, el presidente Senghor y el primer ministro Mamadou Dia gobernaron juntos bajo un sistema parlamentario. En diciembre de 1962, su rivalidad política propició un intento de golpe de Estado por parte del primer ministro. El golpe fue reducido sin derramamiento de sangre, y Dia fue arrestado y encarcelado. El Senegal adoptó una nueva constitución que consolidó el poder del Presidente. En 1980, el Presidente Senghor se retiró de la política y transfirió el cargo a su sucesor elegido a dedo, Abdou Diouf, en 1981.
El Senegal se unió con Gambia para formar la Confederación de Senegambia el 1 de febrero de 1982. Sin embargo, la integración imaginada de los dos países nunca se llevó a cabo, y la unión fue disuelta en 1989. A pesar de diálogos de paz, un grupo separatista del sur, en la región de Casamanza, se ha enfrentado esporádicamente con las fuerzas gubernamentales desde 1982. El Senegal tiene una larga historia de participación en el mantenimiento de la paz internacional.

Abdou Diouf fue el presidente entre 1981 y 2000. Fomentó una más que amplia participación política, redujo la intervención del gobierno en la economía, y amplió los compromisos diplomáticos del Senegal, particularmente con otras naciones en desarrollo. La política interna a veces se desbordó en violencia callejera, tensiones en las fronteras, y un movimiento separatista violento en la región del sur de Casamanza. No obstante, el compromiso de Senegal con la democracia y los derechos humanos se ha consolidado con el tiempo. Diouf sirvió cuatro mandatos como Presidente. En la elección presidencial de 2000, fue derrotado en elecciones democráticas por el líder de la oposición, Abdoulaye Wade. El Senegal experimentó su segunda transición pacífica al poder, y la primera de un partido político a otro.

El 30 de diciembre de 2004, el Presidente Abdoulaye Wade anunció que firmaría un tratado de paz con dos facciones separatistas del "Movimiento de las Fuerzas Democráticas de Casamanza" (MFDC), en la región de Casamanza.

El Senegal es una república presidencial. Su presidente es elegido cada cinco años desde 2001, año en que Mame Madior Boye fue la primera mujer en acceder al cargo de primera ministra del Senegal, previamente siendo elegido cada siete, por voto adulto. El actual presidente es Macky Sall, elegido en marzo de 2012.

El Senegal tiene más de 80 partidos políticos. El Parlamento bicameral está formado por la Asamblea Nacional, que cuenta con 120 asientos, y el Senado, que dispone de 100 asientos y fue reinstaurado en 2007. En el Senegal, existe también un sistema judicial independiente. Las altas instancias de justicia nacionales son el Consejo Constitucional y la Corte de Justicia, siendo sus miembros nombrados por el Presidente.

El Senegal funciona democráticamente, siendo reconocido como uno de los países con la cultura democrática más exitosa y arraigada de África. Los administradores locales son nombrados por el Presidente y son responsables ante él. Los morabitos, líderes religiosos de las diferentes cofradías musulmanas de Senegal, también tienen una cierta influencia política en el país, especialmente durante la presidencia de Wade. En 2009, no obstante, Freedom House rebajó el estatus político de Senegal desde «libre» hasta «parcialmente libre», como consecuencia del aumento de la concentración del poder en el ejecutivo.

En 2008, el Senegal terminó en la 12ª posición del "Ibrahim Index of African Governance". El "Ibrahim Index" es un indicador comprensivo de la gobernanza en África, basado en un número de diferentes variables que reflejan el éxito con que cada gobierno provee de bienes políticos básicos a sus ciudadanos. En 2010, Senegal estaba en el puesto 15º del índice.

En 2012, el Senegal organizó elecciones presidenciales, unos comicios controvertidos como consecuencia de la candidatura de dudosa legitimidad del Presidente Abdoulaye Wade. Finalmente, de las elecciones resultó victorioso Macky Sall, y Wade aceptó su derrota. Este resultado pacífico y democrático fue saludado por numerosos observadores internacionales —como la UE— como una muestra de «madurez». En 2013, Aminata Touré fue la primera ministra del Senegal hasta 2014.

El Senegal se subdivide en 14 regiones, cada una de ellas administrada por un "Conseil Régional" (Consejo Regional) elegido según el peso de la población al nivel de cada "Arrondissement". El país está además subdividido en 45 "Départements", 103 "Arrondissements" (ninguno de los cuales dispone de funciones administrativas) y por "Collectivités Locales", cada una de las cuales elige oficiales administrativos.

Las capitales regionales tienen el mismo nombre que sus regiones:


El Senegal está situado en la parte Oeste del continente africano, entre 12º8' y 16º41' de latitud norte, y 11º21' y 17º32' de longitud Oeste. Su punto oeste, el Cabo Verde (y particularmente el emplazamiento del Club Med de Dakar), constituye la parte más occidental del continente africano.

El paisaje senegalés consiste principalmente en planos ondulados por la arena del oeste de Sahel que crecen hasta faldas de montaña en el sudeste. Allí se encuentra también el punto más alto de Senegal, un accidente geográfico sin nombre cerca de Nepen Diakha, con 581 m de altura. El límite norteño está formado por el río Senegal. Otros ríos destacables son el río Gambia y el río Casamanza. La capital Dakar yace sobre la península Cabo Verde, el punto más occidental del África continental.

El país se extiende sobre 196 722 km². Comparado con los países vecinos (Malí y Mauritania), el Senegal es un país minúsculo.

El clima es de tipo saheliano con:

En el litoral, la mar suaviza las temperaturas, las cuales son del orden de 16 °C a 30 °C; pero en el centro y en el este del Senegal, pueden llegar a los 41 °C.

Durante el invierno de Europa, el Senegal se convierte en un destino apreciado para actividades turísticas.

Según WWF, el territorio del Senegal se reparte entre cuatro ecorregiones:

Los parques y reservas naturales representan el 8% del territorio nacional. Tienen un papel importante en la preservación del medio ambiente y contribuyen de manera significativa al desarrollo turístico. En estos espacios protegidos se ha identificado un total de 169 especies de mamíferos, y 540 especies de aves.

El Senegal cuenta con seis parques nacionales: el parque nacional de Niokolo-Koba, al este del país; el parque nacional de las aves de Djoudj; el parque nacional de la Lengua de Berbería, en la región de Saint-Louis; el parque nacional de las Islas de la Magdalena a lo largo de Dakar; el parque nacional del Delta del Salum en el sur, y el parque nacional de la Baja Casamance, cerrado desde hace unos años debido a disturbios en la región.

El país incluye también una treintena de reservas naturales de menor tamaño, como la Reserva de Guembeul, la Reserva de Bandia, la Reserva Natural de Popenguine, o el espacio marino protegido de Bamboung.

Después de que su economía se contrajera un 2,1% en 1993, el Senegal puso en marcha un importante programa de reformas económicas con el apoyo de la comunidad internacional de donantes. Este paquete de reformas comenzó con una devaluación de la moneda del país, el Franco CFA, del 50%. Se desmantelaron asimismo los controles de precios y los subsidios del Gobierno. Como resultado de lo anterior, la inflación senegalesa se contuvo y disminuyó, aumentó la inversión y el PIB creció alrededor de un 5% al año entre 1995 y 2001.

Los principales sectores económicos en Senegal son el procesamiento de alimentos, la minería, el cemento, los fertilizantes artificiales, la industria química, la refinería de productos petrolíferos importados y el turismo. Las principales exportaciones del país son la pesca, los químicos, el algodón, la tela, los cacahuetes y el fosfato de calcio, y los principales mercados exteriores son Francia, Estados Unidos, China, Italia, India y Reino Unido.

Como miembro de la Unión Económica y Monetaria de África Occidental (UEMOA), el Senegal está dando pasos hacia una mayor integración regional y unos aranceles externos unificados. Senegal también forma parte de la Organización para la Armonización del Derecho Mercantil en África.

Con la introducción del primer resort Club Med en la década de 1970, comenzó el crecimiento del turismo, el cual hoy es una parte importante de la economía del país. Desde la década de 1990, el Senegal ha hecho un esfuerzo para captar turistas de Francia, ya que Senegal fue previamente uno de sus dominios. También está atrayendo turistas de España, Reino Unido e Italia, en parte motivado por el ejemplo de su vecina Gambia, la cual tiene un mayor porcentaje de turistas de Europa del Norte y de América gracias a los resorts costeros de Banjul.

En 2008, el Senegal alcanzó un millón de turistas extranjeros. Su tasa de retorno se quedó en aproximadamente un 30% (2008).

El Senegal tiene una población superior a los 13 millones, de la cual aproximadamente un 42% vive en zonas rurales. La densidad humana varía desde 77/km en la región oeste y central hasta 2/km en las áridas regiones orientales. Esta población crece muy rápidamente, con un índice de fecundidad superior a los 5 hijos por mujer. Se observa una gran diversidad étnica, siendo los principales grupos étnicos los siguientes: wólofs (43,3%), peuls (33,8%), sererers (14,7%), diolas (3,7%), malinkés (3,0%), soninkés (1,1%), y algunas etnias menos numerosas y más locales, sin contar los 50000 europeos (franceses en su mayoría) y libaneses presentes en el medio urbano. Existen numerosas comunidades senegalesas en el exterior, siendo una de las principales minorías étnicas instaladas en Francia, existiendo ya incluso segundas o terceras generaciones de emigrantes. No obstante, la estabilidad política y la ligera mejoría la situación económica del país ha provocado un descenso de la emigración.

De acuerdo con la "World Refugee Survey 2008", publicada por el Comité de Refugiados e Inmigrantes de EE.UU., el Senegal tiene una población de refugiados y buscadores de asilo que ascendía en 2007 a 23.800. La mayoría de esta población (20200) provenía de Mauritania.

El idioma oficial es el francés, mientras que el wólof está considerado como el idioma nacional, aunque se hablan más idiomas locales. Al contrario que en otros países del África Negra en donde es idioma oficial, el uso del francés está muy extendido, y prácticamente toda la población lo habla, bien como primer idioma o bien como segundo.

La población senegalesa es mayoritariamente musulmana, alcanzando su número aproximadamente un 84% del total de la población, aunque el número de musulmanes practicantes se reduce bastante. Los cristianos, sobre todo los católicos, están presentes en un 6%. El Senegal es reconocido por su tolerancia religiosa. No es raro encontrar miembros de una misma familia pertenecientes a religiones distintas. Los matrimonios interreligiosos son numerosos. Las fiestas cristianas son igualmente celebradas y respetadas por las diferentes cofradías musulmanas y demás comunidades.

El Islam, religión mayoritaria en el Senegal, se caracteriza por la presencia de diferentes cofradías a las cuales los ciudadanos suelen adherirse de manera formal o informal.

Los murides o "mourides" constituyen la cofradía más numerosa. Se reconoce fácilmente a sus discípulos. Su centro religioso se encuentra en Touba, donde está una de las mayores mezquitas de África. El fundador es el morabito Ahmadou Bamba (1853-1927). Los Tidjanes son otra gran cofradía. Tienen por ciudad santa a Tivawán. Kaolack es también una ciudad importante desde el punto de vista religioso, ya que allí se asienta el morabito Baye Niass, quien difunde un adoctrinamiento pacífico. Finalmente, los Layènes sigue los preceptos de Seydina Limammou Laye, y su centro neurálgico es la zona de Yoff, en Dakar.

Los seguidores del cristianismo se encuentran principalmente en Casamanza, en país Sérère, y en las principales ciudades como Dakar y Saint-Louis. Los cristianos senegaleses realizan un peregrinaje a Popenguine. La catedral de Dakar fue construida a comienzos del siglo por el padre Daniel Brottier, fundador de los orfelinatos. Senegal está representado ante la Santa Sede por un cardenal, un arzobispado y un obispado.

Un cierto número de senegaleses son animistas y mantienen estas creencias ancestrales. Los senegaleses animistas practican más o menos estas antiguas creencias, en pequeños agradecimientos o demandas de protección, vertiendo agua o leche a los pies de un árbol, generalmente un baobab (la casa de los espíritus).

La capital del Senegal es Dakar, de lejos la mayor ciudad del país con más de dos millones de residentes. La segunda ciudad más poblada es Touba, una "communauté rurale" (comuna rural) "de jure", con medio millón.

El Senegal es conocido en toda África por su influencia y herencia musical, gracias a la popularidad del mbalax, que tiene su origen en la tradición percusiva serer. Esta música fue popularizada por Youssou N'Dour, entre otros, logrando gran éxito internacional. La percusión sabar es especialmente popular. El sabar se utiliza fundamentalmente en las celebraciones especiales, como bodas. Otro instrumento es el tama. Otros músicos populares de renombre internacional son Ismael Lô, Cheikh Lô, Orchestra Baobab, Baaba Maal, Akon, Thione Seck, Viviane, y Pape Diouf.

El Senegal es conocido por la tradición, típica de África Occidental, de la narración de historias, realizada por los "griots", quienes han mantenido la historia de la región viva durante miles de años a través de sus palabras y música. La profesión del "griot" se pasa de generación en generación, y requiere de años de entrenamiento y aprendizaje en genealogía, historia y música. Los "griots" dan voz a generaciones y generaciones de la sociedad africana.

La lucha senegalesa es el deporte nacional del país. Tradicionalmente era practicada como una distracción y para defender el orgullo de la aldea, pero desde hace unos años la retransmisión de los combates por televisión y la aparición de patrocinadores privados han profesionalizado el deporte (antiguamente los luchadores vencedores de los combates recibían piezas de ganado y ahora se celebran veladas en las que se reparten importantes cantidades de dinero) y los luchadores son personajes muy populares en todo el país. La fama que ha adquirido el deporte en los últimos años ha trascendido fronteras, y la variante sin golpes se ha expandido a otros países, sobre todo Francia, en donde reside la mayor comunidad senegalesa en el exterior.




</doc>
<doc id="2705" url="https://es.wikipedia.org/wiki?curid=2705" title="Sesleriella">
Sesleriella

Sesleriella es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario del centro y sur de Europa.

Algunos autores lo incluyen en el género "Sesleria".



</doc>
<doc id="2710" url="https://es.wikipedia.org/wiki?curid=2710" title="Solanaceae">
Solanaceae

Las solanáceas (Solanaceae ) son una familia de plantas herbáceas con las hojas alternas, simples y sin estípulas pertenecientes al orden Solanales, de las dicotiledóneas. Comprende aproximadamente 98 géneros y unas 2700 especies, con una gran diversidad de hábito, morfología y ecología. La familia es cosmopolita, distribuyéndose por todo el globo con la excepción de la Antártida. La mayor diversidad de especies se halla en América del Sur y América Central. En esta familia se incluyen especies alimenticias tan importantes como la papa o patata "(Solanum tuberosum)," el tomate "(Solanum lycopersicum"), la berenjena "(Solanum melongena") y los chiles, ajíes o pimientos "(Capsicum"). Muchas plantas ornamentales muy populares pertenecen a las solanáceas, como "Petunia", "Schizanthus," "Salpiglossis" y "Datura". Ciertas especies son mundialmente conocidas por sus usos medicinales, sus efectos psicotrópicos o por ser ponzoñosas. Finalmente, pero no por ello menos importante, las solanáceas incluyen muchos organismos modelos para investigar cuestiones biológicas fundamentales a nivel celular, molecular y genético, tales como el tabaco y la petunia.

Las solanáceas son plantas herbáceas, subarbustos, arbustos, árboles o lianas. Pueden ser anuales, bienales o perennes, erguidas o decumbentes. Pueden estar provistas de tubérculos subterráneos. No presentan laticíferos, ni látex, ni jugos coloreados. 
Pueden presentar una agregación basal o terminal de hojas o pueden no tener ninguno de ambos tipos. Las hojas son generalmente alternas o alternadas a opuestas (o sea, alternas en la base de la planta y opuestas hacia la inflorescencia). La consistencia de las hojas puede ser herbácea, coriácea, o pueden estar transformadas en espinas. En general las hojas son pecioladas o subsésiles, raramente sésiles. Frecuentemente son inodoras pero, en ocasiones, son aromáticas o fétidas. La lámina foliar puede ser simple o compuesta, en este último caso, pueden ser ternadas o pinnatífidas. La nerviación de las hojas es reticulada y no presentan un meristema basal. Con respecto a la anatomía foliar, las láminas son en general dorsiventrales, sin cavidades secretoras. Los estomas se hallan en general confinados a una de las caras de las hojas, raramente se los halla en ambas caras. 

Las flores son en general hermafroditas, si bien hay especies monoicas, andromonoicas o dioicas (como por ejemplo, algunos "Solanum" o "Symonanthus"). La polinización es entomófila. Las flores pueden ser solitarias o estar agregadas en inflorescencias cimosas, terminales o axilares. Las flores son de tamaño intermedio, fragantes (como en "Nicotiana"), fétidas ("Anthocercis") o inodoras. Las flores son actinomorfas, levemente cigomorfas o marcadamente cigomorfas (como por ejemplo, las flores con corola bilabiada en "Schizanthus"). Las irregularidades en la simetría pueden deberse al androceo, al perianto o a ambos a la vez. Las flores en la gran mayoría de los casos presentan un perianto diferenciado en cáliz y corola (con 5 sépalos y 5 pétalos, respectivamente), un androceo con 5 estambres y dos carpelos unidos formando un gineceo con ovario súpero (se dice, entonces, que son pentámeras y tetracíclicas). Usualmente presentan un disco hipógino. El cáliz es gamosépalo (ya que los sépalos están unidos entre sí formando un tubo), con los 5 (a veces 4 o 6) segmentos iguales entre sí, es pentalobulado, con los lóbulos más cortos que el tubo, es persistente y puede muy a menudo ser acrescente. La corola usualmente presenta 5 pétalos que también se hallan unidos entre sí formando un tubo. La corola puede ser campanulada, rotada, infundibuliforme o tubular. 

El androceo presenta 5 estambres (raramente 2, 4 o 6), libres entre sí, opositisépalos (es decir, alternan con los pétalos), son usualmente fértiles o, en algunos casos (ejemplo, en "Salpiglossideae") con estaminoideos. En este último caso, pueden presentar un solo estaminoideo ("Salpiglossis") o 3 ("Schizanthus"). Las anteras pueden ser conniventes, tocándose en su extremo superior formando un anillo, o totalmente libres, dorsifijas o basifijas, bitecas, con dehiscencia poricida o a través de pequeñas fisuras longitudinales. Debido a sus anteras poricidas, requieren polinización por zumbido. El filamento de los estambres puede ser filiforme o aplanado. Los estambres pueden estar insertos dentro del tubo corolino o exertos. La microsporogénesis es simultánea, la tétrada de microsporas es tetrahédrica o isobilateral. Los granos de polen son bicelulares al momento de la dehiscencia, usualmente aperturados y colpados. 

El gineceo es bi-carpelar (raramente 3- o 5-locular), de ovario súpero y presenta dos lóculos. Los lóculos pueden estar secundariamente divididos por falsos septos, como en el caso de "Nicandreae" y "Datureae". El gineceo está situado en posición oblicua respecto al plano mediano de la flor. Presentan un único estilo y un solo estigma, este último simple o bilobado. Cada lóculo lleva de 1 a 50 óvulos anátropos o hemianátropos de placentación axilar. El desarrollo del saco embrionario puede ser del tipo "Polygonum" o del tipo "Allium". Los núcleos polares del saco embrionario se fusionan con antelación a la fertilización. Presentan 3 antípodas, usualmente efímeras, o persistentes como en el caso de "Atropa". El fruto en las solanáceas puede ser una baya (como en el caso de "Solanum"), una drupa, o una cápsula. Las cápsulas son normalmente septicidas o, raramente, loculicidas o valvares. Las semillas son usualmente endospermadas, oleosas (raramente almidonosas), sin pelos conspicuos. El embrión, que puede ser recto a curvo, presenta dos cotiledones. Los números cromosómicos básicos van desde x=7 a x=12. Muchas especies son poliploides.

A pesar de la descripción previa, las solanáceas exhiben una gran variabilidad morfológica, aun en los caracteres reproductivos. Ejemplos de la acentuada diversidad de la familia son:
En general todas las solanáceas presentan un gineceo formado por dos carpelos. No obstante, hay géneros con gineceo monocarpelar ("Melananthus" ), o con 3 a 4 carpelos como "Capsicum", o con 3 a 5 carpelos, como el caso de "Nicandra", algunas especies de "Jaborosa" y de "Trianaea". Finalmente, existe al menos un caso registrado de una especie ("Iochroma umbellatum") que posee gineceos con 4 carpelos.

Usualmente el número de lóculos en el ovario es igual que el número de carpelos. No obstante, hay especies en que tales números no son idénticos debido a la existencia de falsos septos (paredes internas que subdividen cada lóculo), como por ejemplo "Datura" y algunos miembros de la tribu Lycieae (los géneros "Grabowskia" y "Vassobia").

En las solanáceas los óvulos son, en general, anátropos. Sin embargo, hay géneros con óvulos anacampilótropos (ejemplo en "Phrodus", "Grabowskia" o "Vassobia"), hemítropos ("Cestrum") o hemicampilótropos ("Capsicum", "Schizanthus" y "Lycium"). Con respecto al número de óvulos por lóculo, en general estos son varios, algunas veces son pocos (dos pares en cada lóculo en "Grabowskia", un par en cada lóculo en "Lycium") y, excepcionalmente, se encuentra un solo óvulo en cada lóculo, como por ejemplo, en "Melananthus".

Los frutos en las solanáceas son en su gran mayoría bayas o cápsulas (incluyendo pixidios) y, con menor frecuencia, drupas.
Las bayas son típicas en las subfamilias Cestroideae, Solanoideae (con la excepción de "Datura", "Oryctus", "Grabowskia" y la tribu Hyoscyameae) y la tribu Juanulloideae (con la excepción de "Markea"). 
Las cápsulas son características de las subfamilias Cestroideae (con la excepción de "Cestrum") y Schizanthoideae, las tribus Salpiglossoideae, Anthocercidoideae y el género "Datura". La tribu Hyoscyameae presenta pixidios. 
Las drupas son típicas en la tribu Lycieae y en Iochrominae.

Los alcaloides son bases nitrogenadas, producidas por las plantas como metabolitos secundarios, que presentan una acción fisiológica intensa sobre los animales aun a bajas dosis. 
Entre los alcaloides más famosos se encuentran los presentes en las solanáceas, denominados tropanos. Las plantas que contienen estas sustancias han sido utilizadas durante siglos como venenos. No obstante, pese a su reconocido efecto ponzoñoso, muchas de estas sustancias presentan valiosas propiedades farmacéuticas. Las solanáceas se caracterizan por contar con muchas especies que contienen diversos tipos de alcaloides más o menos activos o venenosos, tales como la escopolamina, la atropina, la hiosciamina y la nicotina. Estos se encuentran en plantas como el beleño ("Hyoscyamus albus"), la belladona ("Atropa belladonna"), el chamico o estramonio ("Datura stramonium"), la mandrágora ("Mandragora autumnalis"), el tabaco y otras. Algunos de los principales tipos de alcaloides de las solanáceas son:




A pesar de que las solanáceas se hallan en todos los continentes, la mayor riqueza de especies se halla en América Central y América del Sur. Otros dos centros de diversidad incluyen Australia y África. Las solanáceas pueden ocupar una gran variedad de ecosistemas, desde los desiertos hasta los bosques tropicales y, frecuentemente se las halla también en la vegetación secundaria que coloniza áreas perturbadas.

A continuación se provee una sinopsis taxonómica completa de las solanáceas, incluyendo subfamilias, tribus y géneros, la cual está basada en los estudios más recientes sobre la sistemática molecular de la familia. 

 Es una subfamilia caracterizada por la presencia de fibras pericíclicas, androceo con 4 o 5 estambres, frecuentemente didínamos. Los números cromosómicos básicos son muy variables, desde x=7 hasta x=13. La subfamilia comprende 8 géneros (divididos en 3 tribus) y aproximadamente 195 especies distribuidas en América. El género "Cestrum" es el más importante con respecto al número de especies ya que incluye 175 de las 195 especies de la subfamilia. La tribu "Cestreae" tiene la particularidad de incluir taxones con cromosomas largos (de 7,21 a 11,51 µm de longitud), cuando el resto de la familia, en general, posee cromosomas cortos (como por ejemplo 1,5 a 3,52 µm de longitud en Nicotianoideae).

Subfamilia caracterizada por presentar fruto en drupa y semillas con embriones curvos con cotiledones grandes y carnosos. El número cromosómico básico es x=13. Incluye 4 géneros y 5 especies que se distribuyen por las Antillas Mayores. Basados en datos moleculares, algunos autores incluyen dentro de esta subfamilia a los géneros monotípicos "Tsoala" , endémico de Madagascar, y "Metternichia" del sudeste de Brasil. Goetzeaceae se considera un sinónimo de esta subfamilia.

La sistemática molecular indica que Petunioideae es el clado hermano de las subfamilias con número cromosómico x=12 (Solanoideae y Nicotianoideae). Presentan calisteginas, un alcaloide del tipo de los tropanos. El androceo está formado por 4 estambres (raramente 5), usualmente de dos longitudes diferentes. Los números cromosómicos básicos en esta subfamilia pueden ser x=7, 8, 9 y 11. Comprende 13 géneros y unas 160 especies, distribuidas por América Central y América del Sur. Basados en datos moleculares, algunos autores consideran que los géneros oriundos de la Patagonia "Benthamiella", "Combera" y "Pantacantha" forman un clado con categoría de tribu (Benthamielleae) que se debe disponer en la subfamilia Goetzeoideae. 

Comprende hierbas anuales o bianuales, con alcaloides tropanos, sin fibras pericíclicas, con pelos y granos de polen característicos. Las flores son zigomorfas. El androceo presenta 2 estambres y 3 estaminoideos, la dehiscencia de las anteras es explosiva. El embrión es curvo. El número cromosómico básico es x=10. "Schizanthus" es un género bastante atípico dentro de las solanáceas, por sus flores fuertemente zigomorfas y por su número cromosómico básico. Los datos morfológicos y moleculares indican que "Schizanthus" es un género hermano de las restantes solanáceas y que divergió tempranamente del resto de la familia, probablemente en el Cretáceo tardío o en el Terciario temprano, hace unos 50 millones de años. La gran diversificación en los tipos de flores en "Schizanthus" ha sido el producto de la adaptación de las especies de este género a los diferentes grupos de polinizadores existentes en los ecosistemas mediterráneo, alpino de altura y desértico de Chile y áreas adyacentes de Argentina.

Incluye hierbas anuales, con fibras pericíclicas, las flores son zigomorfas, el androceo con 4 estambres, didínamos o con 3 estaminoideos, el embrión es recto y corto. El número cromosómico básico es x=12. Incluye 4 géneros y unas 30 especies distribuidas en Sudamérica. 



 



Los siguientes géneros todavía no se hallan ubicados en ninguna de las subfamilias reconocidas de solanáceas. 

Las solanáceas comprenden 98 géneros y unas 2700 especies. No obstante, esa inmensa riqueza de especies no está uniformemente distribuida entre todos los géneros. Así, los 8 géneros más importantes de la familia concentran más del 60 % de las especies, como se muestra en la tabla de abajo. De hecho, únicamente "Solanum" —el género que tipifica a la familia— incluye casi el 50 % de la totalidad de especies de solanáceas. 

Entre las solanáceas se cuentan especies alimenticias tan importantes para el ser humano como la patata o papa ("Solanum tuberosum"), el tomate o jitomate ("Solanum lycopersicum"), el chile, ají o pimiento ("Capsicum annuum") o la berenjena ("Solanum melongena"). "Nicotiana tabacum," originaria de América, se cultiva en todo el mundo para producir tabaco.

Muchas solanáceas son malezas importantes en varias partes del mundo. Su importancia radica en que pueden ser hospedantes de plagas o enfermedades de los cultivos y, por ende, su presencia incrementa las pérdidas de rendimiento o calidad del producto cosechado debidas a tales factores. Ejemplo de esto son "Acnistus arborescens" y "Browalia americana" como hospedantes de tisanópteros que dañan luego al cultivo asociado, y ciertas especies de "Datura" como hospedantes de varios tipos de virus que se transmiten luego a las solanáceas cultivadas. Algunas especies de malezas, como por ejemplo "Solanum mauritianum" en Sudáfrica, representan problemas ecológicos y económicos tan graves que se están realizando estudios tendientes a realizar el control biológico de las mismas mediante el uso de insectos. 

Varias especies arbóreas o arbustivas de solanáceas se cultivan como ornamentales. Algunos ejemplos son "Brugmansia x candida" ("trompeta del ángel"), cultivada por sus grandes flores péndulas con forma de trompeta, "Brunfelsia latifolia", cuyas flores muy fragantes cambian de color desde el violeta al blanco en un período de 3 días. Otras especies arbustivas cultivadas por sus atractivas flores son "Lycianthes rantonnetii" (jazmín del Paraguay) de flores azul-violeta, "Nicotiana glauca" ("tabaco silvestre") de flores amarillas. Otras especies y géneros ornamentales de solanáceas son la petunia "(Petunia × hybrida)", "Lycium, Solanum, Cestrum," "Calibrachoa × hybrida" y "Solandra." Inclusive se ha obtenido un híbrido entre "Petunia" y "Calibrachoa" (el cual constituye un nuevo notogénero denominado "× Petchoa" G. Boker & J. Shaw) que se comercializa como ornamental. Muchas otras especies, en particular las que producen alcaloides, se utilizan en farmacología y medicina "(Nicotiana, Hyoscyamus", y "Datura").
Muchas especies de la familia, entre ellas el tabaco y el tomate, sirven como organismos modelo para tratar de dilucidar cuestiones biológicas básicas. Uno de tales aspectos, la genómica de las solanáceas, es un proyecto internacional que intenta responder a la interrogante de cómo puede un mismo conjunto común de genes o proteínas dar origen a organismos morfológica y ecológicamente tan diferenciados entre sí como son las Solanáceas. Un primer gran objetivo de este proyecto fue secuenciar el genoma del tomate. Para ello, cada uno de los 12 cromosomas del genoma haploide del tomate se asignó a distintos centros de secuenciación en diferentes países. Así, los cromosomas 1 y 10 le correspondieron a Estados Unidos, el 3 y el 11 a China, el 2 a Corea, el 4 al Reino Unido, el 5 a India, el 7 a Francia, el 8 a Japón, el 9 a España y el 12 a Italia. La secuenciación del genoma mitocondrial fue responsabilidad de Argentina y el genoma del cloroplasto lo secuenció la Unión Europea.




</doc>
<doc id="2713" url="https://es.wikipedia.org/wiki?curid=2713" title="Simone de Beauvoir">
Simone de Beauvoir

Simone de Beauvoir (, inscripta como: Simone Lucie Ernestine Marie Bertrand de Beauvoir; París, 9 de enero de 1908-ib., 14 de abril de 1986) fue una escritora, profesora y filósofa francesa. Fue una luchadora por la igualdad de derechos de la mujer y por la despenalización del aborto y de las relaciones sexuales. Escribió novelas, ensayos, biografías y monografías sobre temas políticos, sociales y filosóficos. Su pensamiento se enmarca en la corriente filosófica del existencialismo y su obra "El segundo sexo" se considera fundamental en la historia del feminismo. Fue pareja del también filósofo Jean-Paul Sartre.

Nació en el piso familiar, situado en el bulevar Raspail de París, en el marco de una familia burguesa con moral cristiana muy estricta. Era hija de Georges Bertrand de Beauvoir, que trabajó un tiempo como abogado y era un actor aficionado, y de Françoise Brasseur, una mujer profundamente religiosa. Ella y su hermana pequeña Hélène de Beauvoir, con quien mantuvo siempre una estrecha relación, fueron educadas en colegios católicos. Fue escolarizada desde sus cinco años en el Cours Désir, donde solía enviarse a las hijas de familias burguesas. Su hermana menor Hélène de Beauvoir (conocida con el apodo de Poupette) la siguió dos años más tarde.

Desde su niñez, de Beauvoir destacó por sus habilidades intelectuales, que hicieron que acabase cada año primera de su clase. Compartía brillantez escolar con Elizabeth Lacoin (llamada Zaza en la autobiografía que escribe de Beauvoir), que se convirtió rápidamente en su mejor amiga.

Desde adolescente, por otro lado, se rebelaría contra la fe familiar declarándose atea y considerando que la religión era una manera de subyugar al ser humano.

Después de la Primera Guerra Mundial, su abuelo materno, Gustave Brasseur, entonces presidente del Banco de la Meuse presentó la quiebra, lo que precipitó a toda la familia en el deshonor y la vergüenza. Como consecuencia de esta ruina familiar, los padres de Simone se vieron obligados a abandonar la residencia señorial del bulevar Raspail y a trasladarse a un apartamento oscuro, situado en un quinto piso sin ascensor en la calle de Rennes. Georges de Beauvoir, que había planeado vivir con el dinero de su esposa y de su familia, vio sus planes defraudados. La culpa que sintió entonces Françoise no la abandonó nunca a lo largo de su vida y la dote desaparecida se convirtió en una vergüenza familiar.

La pequeña Simone sufrió la situación y vio cómo las relaciones entre sus padres se deterioraban poco a poco. Hecho importante en el nacimiento de las ideas políticas feministas de Simone, toda su infancia será marcada por el hecho de haber nacido mujer: su padre no le escondió el hecho de que hubiese deseado un hijo, con el sueño de que hubiese cursado estudios en la prestigiosa Escuela Politécnica de París. Muchas veces le comentó a Simone: «Tienes un cerebro de hombre» . Con su esposa compartía la convicción de que, dada la mediocre condición económica en la que se hallaba la familia, la única esperanza de mejora social para sus dos hijas eran los estudios.

Los de Beauvoir veranearon a menudo en Saint-Ybard, en la propiedad de Mayrignac situada en Correze. El parque, fundado alrededor de 1880 por su abuelo, Ernest Bertrand de Beauvoir, fue adquirido a principios de siglo XIX por el bisabuelo, Narcisse Bertrand de Beauvoir. De Beauvoir narró estos tiempos felices en sus "Memorias de una joven formal". El contacto con la naturaleza y los largos paseos solitarios por el campo hicieron surgir en el espíritu de la joven Simone la ambición de un destino fuera de lo común.

Con solamente quince años ya estaba decidida sobre la forma de este destino: quería ser escritora. Tras haber aprobado el bachillerato en 1925, de Beauvoir empezó sus estudios superiores en el Instituto Católico de París, institución religiosa privada a la que solían asistir las muchachas de buena familia. Allí completó su formación matemática, mientras que ampliaba su formación literaria en el Instituto Sainte-Marie de Neuilly. Tras su primer año universitario en París, logró obtener certificados de matemáticas generales, literatura y latín. En 1926, se dedicó a estudiar filosofía y obtuvo en junio de 1927 su certificado de filosofía general. Tras estos reconocimientos acabó licenciándose en letras, con especialización en filosofía, en la primavera de 1928, tras haber aprobado también unas certificaciones de ética y de psicología. Sus estudios universitarios concluyeron en 1929 con la redacción de una tesina sobre Leibniz, culminación de sus estudios superiores.

Tras haber sido profesora agregada de filosofía en 1929, de Beauvoir, o Castor, apodo que le dio su amigo René Maheu y que Sartre siguió usando, en un juego de palabras entre «Beauvoir» y "beaver", en inglés, se preparó para ser profesora titular. Su primer destino fue Marsella. Sartre obtuvo a su vez un puesto en Le Havre en marzo de 1931 y la perspectiva de separarse de él destrozó a de Beauvoir. Para que pudiesen ser nombrados en el mismo instituto, Sartre le propuso que se casasen a lo que ella se negó. En "La fuerza de las Cosas", explicó el porqué:
Este grupo de amigos, que se llamaban entre ellos «la pequeña familia», permaneció unido hasta la muerte de sus miembros, pese a las tensiones ligeras o a los conflictos más serios que atravesaron.
Poco antes de la Segunda Guerra Mundial, la pareja Sartre-de Beauvoir fue destinada a París. De 1936 a 1938, de Beauvoir enseñó en el liceo Molière, del que fue despedida tras haber entablado una relación amorosa con Bianca Bienenfeld, una de sus alumnas.

Las editoriales Gallimard y Grasset rechazaron su primera novela, "Primaldad de lo espiritual", escrita entre 1935 y 1937, que se publicó tardíamente en 1979 con el título "Cuando predomina lo espiritual". "La Invitada" se publicó en 1943; en esta novela, la escritora describía, mediante personajes ficticios, la relación entre Sartre, Olga y ella misma, a la vez que elaboraba una reflexión filosófica sobre la lucha entre las consciencias y las posibilidades de la reciprocidad. Fue un éxito editorial inmediato que la llevó a ser suspendida en junio de 1943 de la Educación Nacional, tras la presentación de una denuncia por incitación a la perversión de personas menores en diciembre de 1941 por la madre de Nathalie Sorokine, una de sus alumnas. Se la reintegró como profesora tras la Liberación de París; durante la Ocupación trabajó para la radio libre francesa («Radio Vichy»), donde organizó programas dedicados a la música.

Con Sartre, Raymond Aron, Michel Leiris, Maurice Merleau-Ponty, Boris Vian y otros intelectuales franceses de izquierda, fue la fundadora de una revista, "Les Temps Modernes", que pretendía difundir la corriente existencialista a través de la literatura contemporánea. De forma paralela, continuó sus producciones personales: tras la publicación de varios ensayos y novelas donde hablaba de su compromiso con el comunismo, el ateísmo y el existencialismo. Consiguió independizarse económicamente y se dedicó plenamente a ser escritora. Viajó por numerosos países (EE. UU., China, Rusia, Cuba...) donde conoció a otras personalidades comunistas como Fidel Castro, Che Guevara, Mao Zedong o Richard Wright. En los Estados Unidos, entabló una relación pasional con el escritor americano Nelson Algren con quien mantuvo una intensa relación epistolar, llegando a intercambiar unas trescientas cartas.

Su consagración literaria tuvo lugar el año 1949: la publicación de "El segundo sexo", del que se vendieron más de veintidós mil ejemplares en la primera semana, causó escándalo y fue objeto de animados debates literarios y filosóficos. La Santa Sede, por ejemplo, se mostró contraria al ensayo. François Mauriac, que siempre tuvo animosidad hacia la pareja, publicó en "Les Temps Modernes" un editorial que creó polémica al afirmar: «ahora, lo sé todo sobre la vagina de vuestra jefa». "El segundo sexo" se tradujo a varios idiomas: en los Estados Unidos se vendieron un millón de ejemplares y se convirtió en el marco teórico esencial para las reflexiones de las fundadoras del movimiento de liberación la mujer. De Beauvoir se convirtió en precursora del movimiento feminista al describir a una sociedad en la que se relega a la mujer a una situación de inferioridad. Su análisis de la condición femenina, en ruptura con las creencias existencialistas, se apoya en los mitos, las civilizaciones, las religiones, la anatomía y las tradiciones. Este análisis desató un escándalo, en particular el capítulo dedicado a la maternidad y al aborto, entonces equiparado al homicidio. Describía el matrimonio como una institución burguesa repugnante, similar a la prostitución en la que la mujer depende económicamente de su marido y no tiene posibilidad de independizarse.

"Los Mandarines", publicado el 1954, marcó el reconocimiento de su talento literario por la comunidad intelectual: se le otorgó por esta novela el prestigioso Premio Goncourt. De Beauvoir era por entonces una de las escritoras con más lectores a nivel mundial. En esta novela, que trata de la posguerra, expuso su relación con Nelson Algren aunque siempre a través de personajes ficticios. Algren, celoso, ya no aguantaba más la relación que unía a de Beauvoir y Sartre: la ruptura entre ella y Algren demostró la fuerza del lazo que unía a los dos filósofos y la de su pacto. Posteriormente, de julio de 1952 a 1959, de Beauvoir vivió con Claude Lanzmann.

A partir de 1958, emprendió la escritura de su autobiografía, en la que describe el mundo burgués en el que creció, sus prejuicios, sus tradiciones degradantes y los esfuerzos que llevó a cabo para deshacerse de ellos pese a su condición de mujer. También relata su relación con Sartre, que calificó de éxito total. Pese a todo y a la fuerza del lazo pasional que aún los unía, ya no eran una pareja en el sentido sexual, aunque de Beauvoir se lo hiciese creer a sus lectores.

En 1964 publicó "Una muerte muy dulce", que relata la muerte de su madre: Sartre consideró siempre que éste fue el mejor escrito de de Beauvoir. La eutanasia o el luto forman el núcleo de este relato cargado de emoción. A lo largo de su luto, a la escritora le acompaña una muchacha que conoció entonces: Sylvie Le Bon, estudiante de Filosofía. La relación que unió a las dos mujeres era ambigua: madre-hija, de amistad o de amor. En su cuarto escrito autobiográfico, "Final de cuentas", de Beauvoir declaraba que compartió con Sylvie el mismo tipo de relación que la unió, cincuenta años antes, a su mejor amiga Zaza. Sylvie Le Bon fue adoptada oficialmente como hija por la escritora quien la nombró heredera de su obra literaria y de sus bienes.

Tras la muerte de Sartre en 1980 publicó en 1981 "La ceremonia del adiós" donde relató los diez últimos años de vida de su compañero sentimental, aunque los detalles médicos e íntimos de la vida del filósofo fueron mal recibidos por muchos de sus seguidores. Este texto se completó con la publicación de sus conversaciones con Sartre grabadas en Roma entre agosto y septiembre de 1974. En estos diálogos Sartre reflexionaba sobre su vida y expresaba algunas dudas sobre su producción intelectual. Al publicar estas conversaciones íntimas, de Beauvoir pretendió demostrar cómo su difunta pareja había sido manipulada por el filósofo y escritor francés Benny Lévy. Lévy hizo que Sartre reconociera una cierta «inclinación religiosa» en el existencialismo pese a que Sartre y los demás existencialistas hubiesen proclamado siempre que el ateísmo era uno de sus pilares. Para de Beauvoir, Sartre ya no disponía de la plenitud de sus capacidades intelectuales cuando había sostenido este debate con Lévy y no estaba en situación de enfrentarse a éste filosóficamente. En estos textos que desvelan la vida de Sartre también dejó ver lo mala que fue su relación con la hija adoptiva de Sartre, Arlette Elkaïm-Sartre. Concluye "La Ceremonia del adiós" con la frase siguiente: «Su muerte nos separa. Mi muerte no nos reunirá. Así es; ya es demasiado bello que nuestras vidas hayan podido juntarse durante tanto tiempo».

De 1955 a 1986, residió en el número 11 bis de la calle Victor-Schœlcher de París, donde murió acompañada de su hija adoptiva y de Claude Lanzmann. Se la enterró en el cementerio de Montparnasse de la capital francesa, en la división 20, al lado de Sartre. Simone de Beauvoir fue enterrada llevando en su mano el anillo de plata que le regaló su amante Nelson Algren al despertar de su primera noche de amor.

A lo largo de su período universitario en París Simone de Beauvoir conoció a otros jóvenes intelectuales, entre ellos Jean-Paul Sartre que calificó con admiración de genio. Una relación mítica nació entre los dos filósofos, que sólo acabó con la muerte de Sartre. Simone será su «amor necesario», en oposición a los «amores contingentes» que los dos conocerán de forma paralela: un pacto de polifidelidad, que renovaban cada dos años, se estableció entre ellos a partir de 1929, más o menos un año tras su encuentro. Ambos cumplieron este pacto filosófico: él tuvo muchos amores contingentes, ella no tantos.
El clímax de la carrera universitaria de la pareja sucedió en 1929, cuando Sartre y de Beauvoir se presentaron al concurso de la agregación de filosofía, que ganó él mientras ella quedaba en segundo puesto.

Pese a este éxito, la muerte repentina de su amiga Zaza el mismo año causó un gran sufrimiento a la filósofa. De Beauvoir, criada por una madre religiosa, perdió su fe cristiana con catorce años, tal como relató en sus "Memorias de una joven formal": años antes de sus estudios filosóficos, la joven se había emancipado de su familia y de sus "valores burgueses".

El encuentro con Sartre supone para de Beauvoir el comienzo de una vida de permanente diálogo intelectual con un interlocutor privilegiado de un nivel que ella definía como mayor al suyo, al menos al inicio de la relación. Sartre y de Beauvoir no se separaron desde que se conocieron, ni durante la separación de ésta de su familia. Su relación perduró hasta la muerte de Sartre. Sin embargo, nunca se casaron ni vivieron bajo el mismo techo. Mantuvieron una relación abierta, sintiéndose felices con el lazo que habían creado entre ellos. Este esquema relacional novedoso se cimentaba en el rechazo profundo y visceral del modo de vida burgués.

Simone se creía única, pero ante Sartre tuvo que reconocer: «Era la primera vez en mi vida que yo me sentía intelectualmente dominada por alguno». Decidieron unir sus vidas, pero en un amor libre porque ni de Beauvoir ni Sartre aceptaban el matrimonio:
De todos modos ella lo amó y lo aceptó tal como era. Sartre propuso la fórmula de su relación: «Entre nosotros se trata de un amor necesario, pero conviene que también conozcamos amores contingentes». En La Habana, Cuba, cuando visitan a Fidel Castro y se reúnen con Che Guevara, este último les manifiesta a ambos que su amor es un amor revolucionario.

Durante la Segunda Guerra Mundial y la ocupación alemana de París, vivió en la ciudad tomada escribiendo su primera novela, "La invitada" (1943), donde exploró los dilemas existencialistas de la libertad, la acción y la responsabilidad individual, temas que abordó igualmente en novelas posteriores como "La sangre de los otros" (1944) y "Los mandarines" (1954), novela por la que recibió el Premio Goncourt.

En 1945 junto a Jean Paul Sartre y otros eruditos del momento fundaron la revista Tiempos Modernos.

Las tesis existencialistas, según las cuales cada uno es responsable de sí mismo, se introducen también en una serie de obras autobiográficas, cuatro en total, entre las que destacan "Memorias de una joven de buena familia" (también conocida como "Memorias de una joven formal") (1958) y "Final de cuentas" (1972). Sus obras ofrecen una visión sumamente reveladora de su vida y su tiempo.

Entre sus ensayos destaca "El segundo sexo" (1949), un análisis sobre el papel de las mujeres en la sociedad y la construcción del rol y la figura de la mujer; "La vejez" (1970), centrada en la situación de la ancianidad en el imaginario occidental y en donde criticó su marginación y ocultamiento, y "La ceremonia del adiós" (1981), polémica obra que evoca la figura de su compañero de vida, Jean Paul Sartre.

Además de sus aportes al feminismo, cabe destacar sus reflexiones sobre la creación literaria, sobre el desarrollo de la izquierda antes y después de la Segunda Guerra Mundial, sobre el dolor y la percepción del yo, sobre los linderos del psicoanálisis y sobre las premisas profundas del existencialismo.

Simone de Beauvoir definió el feminismo en 1963 como "una manera de vivir individualmente y una manera de luchar colectivamente", explica la doctora en filosofía, Teresa López Pardina, una de las principales especialistas en la figura de la escritora y filósofa francesa.

De Beauvoir sostiene que "la mujer", tal como la definía la sociedad occidental de su tiempo, es una construcción cultural. Señala que a lo largo de la historia, la mujer ha sido definida en relación al varón como madre, esposa, hija o hermana; por lo cual, sostiene, la principal tarea de la mujer es reconquistar su propia identidad específica, desde sus propios criterios. Las características con las cuales se identifica en las mujeres no les vienen dadas de su genética, sino por cómo han sido educadas y socializadas. Como resumen de este pensamiento escribió una de sus frases más célebres: ""No se nace mujer, se llega a serlo"".

En 1949 cuando publicó "El Segundo Sexo" era una voz solitaria en la sociedad occidental en la que tras el movimiento sufragista y la obtención del derecho al voto femenino se había vuelto a recluir a las mujeres en el hogar. El libro, que en su momento fue un escándalo, pasó a ser considerado (según la filósofa feminista Alicia Puleo) un texto "clásico" pues permite hacer balance del recorrido hacia la igualdad de los sexos. La misma autora señala que las teóricas de las distintas y contrapuestas corrientes del feminismo (liberal, radical y socialista) reconocen ser ""hijas de Beauvoir"".

El ser humano, considera de Beauvoir, no es una "esencia" fija sino una "existencia": "proyecto", "trascendencia", "autonomía", "libertad" que no puede escamotearse a un individuo por el hecho de pertenecer al "segundo sexo". La idea fundamental de "El Segundo Sexo" —destaca Puleo— es hoy asumida por millones de personas que no han leído esta obra ni han oído hablar de ella y sus principios han sido incorporados a las políticas de igualdad europeas y han dado lugar a los estudios feministas y de género de centros universitarios de vanguardia"."

De Beauvoir expresó en los términos de la filosofía existencialista todo un ciclo de reivindicaciones de igualdad de las mujeres que comienza con la Ilustración y lleva a la obtención del voto y al acceso a la enseñanza superior en primer tercio del siglo XX destaca la filósofa Celia Amorós.

De Beauvoir tuvo también un papel determinante en la legalización del aborto en Francia. Con Halimi fundó el movimiento "Choisir" y fue una de las redactoras del Manifiesto de las 343 -firmado por mujeres de la política, la cultura y distintas áreas de la sociedad francesa como la escritora Marguerite Duras, la abogada Gisèle Halimi o las cineastas Françoise Sagan, Jeanne Moreau y Agnes Vardà reconociendo haber abortado- publicado el 5 de abril de 1971 por la revista "Le Nouvel Observateur."

Sobre el aborto señaló:""El aborto es parte integral de la evolución en la naturaleza y la historia humana. Esto no es un argumento ni a favor o en contra, sino un hecho innegable. No hay pueblo, ni época donde el aborto no fuera practicado legal o ilegalmente. El aborto está completamente ligado a la existencia humana…"."La actividad de Simone de Beauvoir fue, junto con Gisèle Halimi y Elisabeth Badinter, la clave para lograr el reconocimiento de los maltratos sufridos por las mujeres durante la Guerra de Argelia.

En 1977, Simone de Beauvoir junto a otros intelectuales franceses —incluyendo nombres tan prominentes como Louis Aragon, Michel Foucault, Jean-Paul Sartre, Jacques Derrida, Louis Althusser, Roland Barthes, Gilles Deleuze, Félix Guattari, Michel Leiris, Alain Robbe-Grillet, Philippe Sollers, Jacques Rancière, Jean-François Lyotard, Francis Ponge y varios doctores y psicólogos— firmaron una petición al parlamento francés cuestionando varios artículos de la ley de edad de consentimiento y su coherencia con el caso en concreto. En una carta abierta, pidieron la liberación de tres hombres (Bernard Dejager, Jean-Claude Gallien y Jean Burckardt), quienes llevaban tres años en prisión preventiva acusados de tener relaciones sexuales con menores de 15 años. El comunicado fue publicado por el periódico "Le Monde" el 26 de enero de 1977. La petición argumentaba sobre la contradicción que presentaba la legislación francesa, por cuanto a los 13 años una menor ya recibía la píldora por parte del Estado e incluso desde esa misma edad se consideraba la responsabilidad penal adolescente, pero no consideraba igualmente capaces de discernimientos a estos menores cuando se trataba del consentimiento sexual. Por años, esta carta se ha prestado para profuso debate intelectual —el propio Michael Foucault dio una entrevista sobre el tema—, no solo en el campo jurídico sobre la legislación en materia de consentimiento sexual, sino también respecto de la sexualidad misma y la libertad de los cuerpos.

En 2008, con motivo del centenario del aniversario de su nacimiento, se creó en su honor el Premio Simone de Beauvoir por la Libertad de las Mujeres a iniciativa de Julia Kristeva financiado por la Universidad Diderot de París con un montante de 20.000 euros para destacar a las personas comprometidas por su obra artística y su acción a promover la libertad de las mujeres en el mundo.










</doc>
<doc id="2717" url="https://es.wikipedia.org/wiki?curid=2717" title="Daphne gnidium">
Daphne gnidium

El torvisco o torrisco (Daphne gnidium) es un arbusto de la familia timeleáceas.

Es una planta distribuida por la región mediterránea, en casi toda la península ibérica, archipiélagos canario y balear y norte de África, donde crece en matorrales, pinares y terrenos no cultivados desde el nivel del mar hasta a 1000 metros de altitud.

En la comarca granadina de la Alpujarra, en plena Sierra de la Contraviesa, se sitúa el municipio de Torvizcón, topónimo que significa 'tierra del torvisco'.

Es un arbusto con muchas hojas con forma de punta de espada, todas dirigidas hacia arriba: tal vez, podría ser confundida con una Euphorbia, pero cortando una hoja rápidamente vemos que no sale látex blanco. Desarrolla las flores blancas al final del verano y el otoño. Hay que tener cuidado con esta planta porque es irritante. 

Su fruto es de color rojo, en baya. Tiene hojas lanceoladas, estrechas. Dado el potente efecto purgante de la corteza y de las hojas del torvisco es considerado venenoso, ya que puede producir ampollas en la piel tras un prolongado contacto.

El Torvisco es un arbusto con propiedades sorprendentes. Ha sido usado como amuleto y repelente de malos espíritus desde la Prehistoria. Es la mejor especie vegetal de la península ibérica para hacer ligaduras, su corteza es una cuerda natural por su flexibilidad y resistencia, pudiéndose hacer nudos muy firmes. En algunas zonas de Zamora se acostumbra a atarle una correa de "Daphne gnidium" a la cola de los corderos como remedio para frenar la descomposición estomacal; también es conocido su valor como insecticida en el gallinero, manteniendo a las gallinas a salvo del piojillo. Esta especie ha sido empleada, desde tiempos inmemoriales, como medio de pesca en lagunas y arroyos: su resina tóxica ataca al oxígeno del agua, por lo que echando ramas de esta planta se envenenaba a los peces que, después de dos o tres horas, sólo había que recoger. Esta forma de pesca se llama Entorviscar y además de ser peligrosa por indiscriminada está penada por la ley en España.

"Daphne gnidium" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 1: 357-358. 1753.

Daphne; nombre genérico que lo encontramos mencionado por primera vez en los escritos del médico, farmacéutico y botánico griego que practicaba en la antigua Roma, Dioscórides. Probablemente en la denominación de algunas plantas de este género se recuerda la leyenda de Apolo y Dafne. El nombre de Daphne en griego significa "laurel", ya que las hojas de estas plantas son muy similares a las del laurel. 

gnidium: epíteto geográfico que alude a su localización en Gnido.




</doc>
<doc id="2720" url="https://es.wikipedia.org/wiki?curid=2720" title="Tom Bombadil">
Tom Bombadil

Tom Bombadil ("Iarwain ben-adar" en sindarin, que significa «el más viejo y el que no tiene padre») es un enigmático personaje literario creado por J. R. R. Tolkien en el poema «Las aventuras de Tom Bombadil», publicado en el poemario del mismo nombre, donde se le describe así:

Aparece posteriormente en el Libro I de "El Señor de los Anillos", en donde asiste a Frodo, a Sam, a Merry y a Pippin en su periplo fuera de la Comarca. Aquí se nos da una descripción de su aspecto físico:

Si bien el origen y la naturaleza de Tom Bombadil continúan siendo un misterio, una cosa está clara: Tom Bombadil mantiene una relación especial y muy cercana con la Naturaleza. En apariencia, Tom Bombadil no es más que un hombre más bien bajo de estatura que lleva un abrigo azul, unas grandes botas amarillas y un sombrero adornado con una pluma azul. Su cara rojiza está enmarcada por una larga barba marrón y ojos de color azul brillante. Tom vivía junto con su esposa, Baya de Oro, en una casa junto a la colina entre el Bosque Viejo y la Quebradas de los Túmulos. A esta zona Tom la llamaba "mi país" y no solía cruzar sus fronteras aunque sabemos que salió de ahí para visitar al Granjero Maggot en La Comarca y para ponerse al corriente con Cebadilla Mantecona en la posada «El Póney Pisador» de Bree. 

El origen de Tom es incierto, pero según él mismo ya vivía en la Tierra Media antes de que Melkor llegara a ella y que Beleriand desapareciera bajo los mares. Esto significa que ya se encontraba en ella antes de la llegada de los Valar, de entre los cuales Melkor fue el primero en llegar a Arda.

No se sabe muy bien qué rol y qué importancia tuvo en las batallas de la Primera y Segunda Edad, pero fue testigo, o al menos contemporáneo, de éstas. También fue testigo de la destrucción de la mayoría de los bosques que antiguamente cubrían la mayoría de la Tierra Media. Tampoco se sabe muy bien el nivel de interacción con los pueblos de la Tierra Media, pero en algún momento se convirtió en un icono folclórico de los elfos, hombres y enanos.

Como cada año al final del verano, Tom recogía lirios para su mujer, Baya de Oro, y fue en una de estas salidas en septiembre del año 3018 de la Tercera Edad cuando se encontró con Frodo y Sam y les ayudó a rescatar a Merry y Pippin del Viejo Hombre-Sauce. Tras conseguir con una canción que el Hombre Sauce soltara a los Hobbits, Tom los invita a su casa, donde pasan un par de noches. Normalmente, siempre cantaba o hablaba en forma de versos, lo que le hacía parecer un ser absurdo, pero dentro del Bosque Viejo su poder era absoluto y no había mal lo bastante poderoso para alcanzarlo. Uno de esos días, en su casa, Tom se puso el Anillo Único y, ante el asombro de todos, no se volvió invisible, devolviéndolo con una sonrisa a su portador.

Tom Bombadil les aconsejó antes de partir que debían dirigirse al Gran Camino del Este, pero los Hobbits acabaron perdidos al desorientarse en la niebla. Tras ser capturados por los Tumularios, Frodo cantó la canción que le enseñó Tom Bombadil y este acudió en su ayuda. Tras liberar a los Hobbits, Tom les proporcionó armas de los Tumularios y escogió para Baya de Oro un broche con una gran piedra azul.

Cuando los ponis de Merry desaparecieron de los establos de «El Póney Pisador», acabaron reuniéndose con Gordo Terronillo, el poni de Tom y se quedan al cuidado de Bombadil hasta que este los envió de vuelta con Cebadilla Mantecona. Muchos elfos de Rivendel, como Elrond o Erestor, u otros seres de la Tierra Media, como Gandalf, quisieron que Tom asistiese al Concilio de Elrond, pero no le invitaron debido a que supusieron que no se desplazaría más allá de sus fronteras.

Durante el Concilio de Elrond una opción sugerida fue entregarle el anillo a Tom, pero esta idea fue rechazada, ya que aunque el anillo no tenía poder sobre él, Tom podía no tener el suficiente poder para protegerlo de Sauron o para destruirlo, y en cualquier caso no parecía que fuera a ser un guardián muy atento. Tras la Guerra del Anillo, Gandalf fue a visitar a Tom Bombadil y disfrutó con él de largos paseos. Nadie sabe con certeza qué ocurrió en estos paseos y de qué charlaron.

De origen desconocido, más viejo que la misma tierra, ama la naturaleza sobre todas las cosas y puede controlarla gracias a la poesía. Su naturaleza es motivo de discusión entre los seguidores de la serie de libros:

Probablemente el personaje sea, tal y como llegó a sugerir el mismo Tolkien, un enigma intencional, inclasificable dentro del mundo imaginario de la Tierra Media. Por ello, queda claro que Tom es una presencia única en la Tierra Media.

Dentro de la familia de J. R. R. Tolkien, Tom Bombadil era originalmente un muñeco holandés perteneciente a la infancia de Tolkien. Tolkien escribió después un poema acerca de él llamado «Las aventuras de Tom Bombadil», publicado en la Revista Oxford en 1934, mucho antes de que comenzara a escribir "El Señor de los Anillos". En la carta 19, del 16 de diciembre de 1937 Tolkien le dice al editor de "El hobbit": «¿Piensa que Tom Bombadil, el espíritu de la campiña (en proceso de desvanecimiento) de Oxford y Berkshire, podría convertirse en el héroe de una historia? ¿O está, como lo sospecho, por entero atesorado en los versos que le adjunto? (“Las aventuras de Tom Bombadil”). Aun así, podría ampliar el retrato». Y claro que lo hizo.

Cuando Tolkien decidió introducir a Tom en la trilogía, necesitó ser cambiado un poco respecto a él o su poema, excepto por la pluma en su sombrero - cambió de una de pavo real a una de cisne, debido a que los pavos reales no vivían en la Tierra Media. En el tomo uno de la Historia del Señor de los Anillos, gracias a Christopher Tolkien, podemos leer como Tolkien lo fue configurando. En una carta escrita al original corrector de la Trilogía en 1954, Tolkien revela un poco acerca del papel literario de Tom o lo que podría ser su función. Al principio de la carta, escribe que "aún en una Edad mitológica deben haber algunos enigmas, como siempre los hay. Tom Bombadil es uno de ellos (intencionadamente)".

En un primer borrador Tom ni siquiera aparece, salva a los hobbits cantando de lejos. Luego los vuelve a salvar en los Túmulos y ahí los lleva a su casa. En anotaciones más tardías, la historia se parece más a la de ahora, pero la naturaleza de Tom no era segura, solo ideas. Incluso quería que el granjero Maggot fuese pariente de Tom, dice refiriéndose al granjero: “que no sea un hobbit, sino otra criatura; no un enano, sino alguien emparentado con Tom Bombadil”. En este esquema incluso, los hobbits solo se quedaban una noche en la casa de Tom y se iban, o sea que Tom no tenía mucha importancia hasta ese momento. Luego, con el tiempo, las relecturas y las correcciones, le iría dando más importancia al personaje, convirtiéndolo cada vez en un ser más enigmático y neutral.

Gandalf denomina a Tom Bombadil el más viejo de la existencia; esto es reafirmado por su nombre en sindarin que es «Iarwain Ben-adar», que significa ‘el más viejo y sin padre’. Los enanos le llaman «Forn», que en escandinavo quiere decir ‘antiguo’ y ‘que pertenece al pasado’. Los hombres le llaman «Orald», en alemán se puede traducir como ‘muy antiguo’. Todos tienen en común que aparentemente significan ‘viejo’. Todo ello se puede simplificar en que seguramente Tom Bombadil es el ser más viejo de toda la Tierra Media y moraba allí antes que todos los demás seres. 

Tom Bombadil no aparece en ninguna de la tres películas dirigidas por Peter Jackson (alegó que no era necesario para la historia), como tampoco lo hacen ninguno de los hechos narrados en la novela sobre el Bosque Viejo en la . Sin embargo, en la versión extendida en DVD de la segunda de las películas de la trilogía (""), se incluyó una escena muy similar a la del Viejo Hombre-Sauce, pero trasladada a Fangorn y protagonizada por un ucorno. En esta escena el que «canta» para liberar a Merry y Pippin no es Tom Bombadil sino Bárbol.

Sin embargo, sí aparece en el videojuego de "", y en "". La representación del personaje en los dos videojuegos es diferente: en "La batalla por la Tierra Media II" se le presenta como un alegre anciano de cabellera y barba largas y blancas, ataviado con la ropa que se describe en el libro, y con el poder de usar su voz como un arma, combatiendo a sus enemigos cantando y bailando; mientras tanto, en el primer videojuego mencionado, Bombadil es más fiel a la descripción de la novela, con pelo castaño.
También aparece en el videojuego "Lord of the Rings Online" y se lo puede encontrar en su casa entre el bosque y la quebrada de los túmulos. También aparece en el videojuego "Lego El Señor de los Anillos", como personaje disponible para "comprar" y conserva su aspecto característico: chaqueta azul, botas amarillas, barba y cabello castaños y el sombrero. Aparece en los límites de Hobbiton y solo se puede comprar de día.



</doc>
