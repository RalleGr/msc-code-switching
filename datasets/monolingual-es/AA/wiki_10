<doc id="1568" url="https://es.wikipedia.org/wiki?curid=1568" title="JavaScript">
JavaScript

JavaScript (abreviado comúnmente JS) es un lenguaje de programación interpretado, dialecto del estándar ECMAScript. Se define como orientado a objetos, basado en prototipos, imperativo, débilmente tipado y dinámico.

Se utiliza principalmente del lado del cliente, implementado como parte de un navegador web permitiendo mejoras en la interfaz de usuario y páginas web dinámicas y JavaScript del lado del servidor ("Server-side JavaScript" o "SSJS"). Su uso en aplicaciones externas a la web, por ejemplo en documentos PDF, aplicaciones de escritorio (mayoritariamente widgets) es también significativo.

Desde 2012, todos los navegadores modernos soportan completamente ECMAScript 5.1, una versión de JavaScript. Los navegadores más antiguos soportan por lo menos ECMAScript 3. La sexta edición se liberó en julio de 2015.

JavaScript se diseñó con una sintaxis similar a C , aunque adopta nombres y convenciones del lenguaje de programación Java. Sin embargo, Java y JavaScript tienen semánticas y propósitos diferentes.

Todos los navegadores modernos interpretan el código JavaScript integrado en las páginas web. Para interactuar con una página web se provee al lenguaje JavaScript de una implementación del Document Object Model (DOM).

Tradicionalmente se venía utilizando en páginas web HTML para realizar operaciones y únicamente en el marco de la aplicación cliente, sin acceso a funciones del servidor. Actualmente es ampliamente utilizado para enviar y recibir información del servidor junto con ayuda de otras tecnologías como AJAX. JavaScript se interpreta en el agente de usuario al mismo tiempo que las sentencias van descargándose junto con el código HTML.

Desde el lanzamiento en junio de 1997 del estándar ECMAScript 1, han existido las versiones 2, 3 y 5, que es la más usada actualmente (la 4 se abandonó). En junio de 2015 se cerró y publicó la versión ECMAScript 6.

JavaScript fue desarrollado originalmente por Brendan Eich de Netscape con el nombre de "Mocha", el cual fue renombrado posteriormente a "LiveScript", para finalmente quedar como JavaScript. El cambio de nombre coincidió aproximadamente con el momento en que Netscape agregó compatibilidad con la tecnología Java en su navegador web Netscape Navigator en la versión 2002 en diciembre de 1995. La denominación produjo confusión, dando la impresión de que el lenguaje es una prolongación de Java, y se ha caracterizado por muchos como una estrategia de mercadotecnia de Netscape para obtener prestigio e innovar en el ámbito de los nuevos lenguajes de programación web.

«JAVASCRIPT» es una marca registrada de Oracle Corporation. Es usada con licencia por los productos creados por Netscape Communications y entidades actuales como la Fundación Mozilla.

Microsoft dio como nombre a su dialecto de JavaScript «JScript», para evitar problemas relacionadas con la marca. JScript fue adoptado en la versión 3.0 de Internet Explorer, liberado en agosto de 1996, e incluyó compatibilidad con el Efecto 2000 con las funciones de fecha, una diferencia de los que se basaban en ese momento. Los dialectos pueden parecer tan similares que los términos «JavaScript» y «JScript» a menudo se utilizan indistintamente, pero la especificación de JScript es incompatible con la de ECMA en muchos aspectos.

Para evitar estas incompatibilidades, el World Wide Web Consortium diseñó el estándar Document Object Model (DOM, o Modelo de Objetos del Documento en español), que incorporan Konqueror, las versiones 6 de Internet Explorer y Netscape Navigator, Opera la versión 7, Mozilla Application Suite y Mozilla Firefox desde su primera versión.

En 1997 los autores propusieron JavaScript para que fuera adoptado como estándar de la European Computer Manufacturers 'Association ECMA, que a pesar de su nombre no es europeo sino internacional, con sede en Ginebra. En junio de 1997 fue adoptado como un estándar ECMA, con el nombre de ECMAScript. Poco después también como un estándar ISO.

Netscape introdujo una implementación de script del lado del servidor con Netscape Enterprise Server, lanzada en diciembre de 1994 (poco después del lanzamiento de JavaScript para navegadores web).
A partir de mediados de la década de los 2000, ha habido una proliferación de implementaciones de JavaScript para el lado servidor. Node.js es uno de los notables ejemplos de JavaScript en el lado del servidor, siendo usado en proyectos importantes.

JavaScript se ha convertido en uno de los lenguajes de programación más populares en internet. Al principio, sin embargo, muchos desarrolladores renegaban del lenguaje porque el público al que va dirigido lo formaban publicadores de artículos y demás aficionados, entre otras razones. La llegada de Ajax devolvió JavaScript a la fama y atrajo la atención de muchos otros programadores. Como resultado de esto hubo una proliferación de un conjunto de frameworks y librerías de ámbito general, mejorando las prácticas de programación con JavaScript, y aumentado el uso de JavaScript fuera de los navegadores web, como se ha visto con la proliferación de entornos JavaScript del lado del servidor.
En enero de 2009, el proyecto CommonJS fue inaugurado con el objetivo de especificar una librería para uso de tareas comunes principalmente para el desarrollo fuera del navegador web.

En junio de 2015 se cerró y publicó el estándar ECMAScript 6 con un soporte irregular entre navegadores y que dota a JavaScript de características avanzadas que se echaban de menos y que son de uso habitual en otros lenguajes como, por ejemplo, módulos para organización del código, verdaderas clases para programación orientada a objetos, expresiones de flecha, iteradores, generadores o promesas para programación asíncrona.

La versión 7 de ECMAScript se conoce como ECMAScript 2016, y es la última versión disponible, publicada en junio de 2016. Se trata de la primera versión para la que se usa un nuevo procedimiento de publicación anual y un proceso de desarrollo abierto.

Las siguientes características son comunes a todas las implementaciones que se ajustan al estándar ECMAScript, a menos que especifique explícitamente en caso contrario.

JavaScript es compatible con gran parte de la estructura de programación de C (por ejemplo, sentencias codice_1, bucles codice_2, sentencias codice_3, etc.). Con una salvedad, en parte: en C, el ámbito de las variables alcanza al bloque en el cual fueron definidas; sin embargo JavaScript no es compatible con esto, puesto que el ámbito de las variables es el de la función en la cual fueron declaradas. Esto cambia con la versión de ECMAScript 2015, ya que añade compatibilidad con block scoping por medio de la palabra clave codice_4. Como en C, JavaScript hace distinción entre expresiones y sentencias. Una diferencia sintáctica con respecto a C es la inserción automática de punto y coma, es decir, en JavaScript los puntos y coma que finalizan una sentencia pueden ser omitidos.












JavaScript se encuentra oficialmente bajo la organización de Mozilla Foundation, y periódicamente se añaden nuevas características del lenguaje. Sin embargo, sólo algunos motores JavaScript son compatibles con estas características:


la última versión del lenguaje es ECMAScript 2016 publicada el 17 de junio de 2016.

Las variables en JavaScript se definen usando la palabra clave var:

var x; // define la variable x, aunque no tiene ningún valor asignado por defecto
var y = 2; // define la variable y y le asigna el valor 2 a ella

A considerar los comentarios en el ejemplo de arriba, los cuales van precedidos con 2 barras diagonales.

No existen funcionalidades para I/O incluidas en el lenguaje; el entorno de ejecución ya lo proporciona. La especificación ECMAScript en su edición 5.1 hace mención:
... en efecto, no existen provisiones en esta especificación para entrada de datos externos o salida para resultados computados.

Sin embargo, la mayoría de los entornos de ejecución tiene un objeto llamado codice_28 que puede ser usado para imprimir por el flujo de salida de la consola de depuración. He aquí un simple programa que imprime “Hello world!”:

console.log("Hello world!");
Una función recursiva:

function factorial(n) {

Ejemplos de función anónima (o función lambda) y una clausura:

var displayClosure = function() {
var inc = displayClosure();
inc(); // devuelve 1
inc(); // devuelve 2
inc(); // devuelve 3
Las expresiones con invocación automática permiten a las funciones pasarle variables por parámetro dentro de sus propias clausuras.

var v;
v = 1;
var getValue = (function(v) {
}(v));

v = 2;

getValue(); // 1
El siguiente código muestra varias características de JavaScript.

El siguiente ejemplo muestra la salida que debería ser mostrada en la ventana de un navegador.

El uso más común de JavaScript es escribir funciones embebidas o incluidas en páginas HTML y que interactúan con el Document Object Model (DOM o Modelo de Objetos del Documento) de la página. Algunos ejemplos sencillos de este uso son:

Dado que el código JavaScript puede ejecutarse localmente en el navegador del usuario (en lugar de en un servidor remoto), el navegador puede responder a las acciones del usuario con rapidez, haciendo una aplicación más sensible. Por otra parte, el código JavaScript puede detectar acciones de los usuarios que HTML por sí sola no puede, como pulsaciones de teclado. Las aplicaciones como Gmail se aprovechan de esto: la mayor parte de la lógica de la interfaz de usuario está escrita en JavaScript, enviando peticiones al servidor (por ejemplo, el contenido de un mensaje de correo electrónico). La tendencia cada vez mayor por el uso de la programación Ajax explota de manera similar esta técnica.

Un motor de JavaScript (también conocido como intérprete de JavaScript o implementación JavaScript) es un intérprete que interpreta el código fuente de JavaScript y ejecuta la secuencia de comandos en consecuencia. El primer motor de JavaScript fue creado por Brendan Eich en Netscape Communications Corporation, para el navegador web Netscape Navigator. El motor, denominado SpiderMonkey, está implementado en C. Desde entonces, ha sido actualizado (en JavaScript 1.5) para cumplir con el ECMA-262 edición 3. El motor Rhino, creado principalmente por Norris Boyd (antes de Netscape, ahora en Google) es una implementación de JavaScript en Java. Rhino, como SpiderMonkey, es compatible con el ECMA-262 edición 3.

Un navegador web es, con mucho, el entorno de acogida más común para JavaScript. Los navegadores web suelen crear objetos no nativos, dependientes del entorno de ejecución, para representar el Document Object Model (DOM) en JavaScript. El servidor web es otro entorno común de servicios. Un servidor web JavaScript suele exponer sus propios objetos para representar objetos de petición y respuesta HTTP, que un programa JavaScript podría entonces interrogar y manipular para generar dinámicamente páginas web.

Debido a que JavaScript es el único lenguaje por el que los más populares navegadores comparten su apoyo, se ha convertido en un lenguaje al que muchos frameworks en otros lenguajes compilan, a pesar de que JavaScript no fue diseñado para tales propósitos. A pesar de las limitaciones de rendimiento inherentes a su naturaleza dinámica, el aumento de la velocidad de los motores de JavaScript ha hecho de este lenguaje un entorno para la compilación sorprendentemente factible.

A continuación se muestra un breve ejemplo de una página web (ajustadose a las normas del estándar para HTML5) que utiliza JavaScript para el manejo del DOM:

<!DOCTYPE html>
<html>
<head>
</head>
<body>

</body>
</html>

Debido a que JavaScript se ejecuta en entornos muy variados, una parte importante de las pruebas y la depuración es probar y verificar que el código JavaScript funciona correctamente en múltiples navegadores.
La interfaz DOM para acceder y manipular páginas web no es parte del estándar ECMAScript, o de la propia JavaScript. El DOM es definido por los esfuerzos de estandarización del W3C, una organización independiente. En la práctica, las implementaciones que hacen de JavaScript los distintos navegadores difieren tanto entre ellos mismos como de las normas del estándar.

Para hacer frente a estas diferencias, los autores de JavaScript pudieron ser capaces de escribir código compatible con los estándares que también fuera capaz de ejecutarse correctamente en la mayoría de los navegadores, o en su defecto, que al menos se pudiera escribir código capaz de comprobar la presencia de ciertas funcionalidades del navegador y que se comportase de manera diferente si no se dispusiese de dicha funcionalidad. Existen casos en los que dos navegadores pueden llegar a implementar la misma característica, pero con un comportamiento diferente, hecho que a los programadores les puede resultar de ayuda para detectar qué navegador se está ejecutando en ese instante y así cambiar el comportamiento de su escritura para que coincida. Los programadores también suelen utilizar bibliotecas o herramientas que tengan en cuenta las diferencias entre navegadores.

Además, los scripts pueden no funcionar para algunos usuarios. Por ejemplo, un usuario puede:

Para apoyar a estos usuarios, los programadores web suelen crear páginas que sean tolerante a fallos según el agente de usuario (tipo de navegador) que no admita JavaScript. En particular, la página debe seguir siendo útil aunque sin las características adicionales que JavaScript habría añadido. Un enfoque alternativo que muchos encuentran preferible es primero crear contenido utilizando las tecnologías que funcionan en todos los navegadores, y mejorar el contenido para los usuarios que han permitido JavaScript.

Suponiendo que el usuario no haya desactivado la ejecución de código JavaScript, en el lado del cliente JavaScript debe ser escrito tanto con el propósito de mejorar las experiencias de los visitantes con discapacidad visual o física, como el de evitar ocultar información a estos visitantes.

Los lectores de pantalla, utilizados por los ciegos y deficientes visuales, pueden ser tenidos en cuenta por JavaScript y así poder acceder y leer los elementos DOM de la página. El código HTML escrito debe ser lo más conciso, navegable y semánticamente rico posible, tanto si JavaScript se ejecuta como si no.

JavaScript no debería de ser totalmente dependiente de los eventos de ratón del navegador y debería ser accesible para aquellos usuarios que no quieran hacer uso del ratón (informática) para navegar o que opten por utilizar solamente el teclado.
Hay eventos independientes del dispositivo, tales como codice_29 y codice_30 que son preferibles en la mayoría de los casos.

JavaScript no debe ser utilizado para crear confusión o desorientación al usuario web. Por ejemplo, modificar o desactivar la funcionalidad normal del navegador, como cambiar la forma en que el botón de navegar hacia atrás o el evento de actualización se comportan, son prácticas que generalmente son mejores evitar. Igualmente, desencadenar eventos que el usuario puede no tener en cuenta reduce la sensación de control del usuario y provoca cambios inesperados al contenido de la página.

A menudo, el proceso de dotar a una página web compleja el mayor grado accesibilidad posible, se convierte en un problema no trivial donde muchos temas se acaban llevando al debate y a la opinión, siendo necesario el compromiso de todos hasta el final. Sin embargo, los agentes de usuario y las tecnologías de apoyo a personas con discapacidad están en constante evolución y nuevas directrices e información al respecto siguen publicándose en la web.

JavaScript y el DOM permite que existan programadores que hagan un uso inapropiado para introducir scripts que ejecuten código con contenido malicioso sin el consentimiento del usuario y que pueda así comprometer su seguridad.

Los desarrolladores de los navegadores tienen en cuenta este riesgo utilizando dos restricciones.
En primer lugar, los scripts se ejecutan en un sandbox en el que sólo se pueden llevar a cabo acciones relacionadas con la web, no con tareas de programación de propósito general, como la creación de archivos.
En segundo lugar, está limitada por la política del mismo origen: los scripts de un sitio web no tienen acceso a la información enviada a otro sitio web (de otro dominio) como pudiera ser nombres de usuario, contraseñas o cookies. La mayoría de los fallos de seguridad de JavaScript están relacionados con violaciones de cualquiera de estas dos restricciones.

Existen proyectos como AdSafe o Secure ECMA script (SES) que proporcionan mayores niveles de seguridad, en especial en el código creado por terceros (tales como los anuncios).

La Política de Contenido Seguro (CSP) es el método principal previsto para garantizar que sólo código de confianza pueda ser ejecutado en una página web.

Un problema común de seguridad en JavaScript es el cross-site scripting o XSS, una violación de la política de mismo origen. Las vulnerabilidades XSS permiten a un atacante inyectar código JavaScript en páginas web visitadas por el usuario. Una de esas webs podría ser la de un banco, pudiendo el atacante acceder a la aplicación de banca con los privilegios de la víctima, lo que podría revelar información secreta o transferir dinero sin la autorización de la víctima.
Una solución para las vulnerabilidades XSS es utilizar "HTML escaping" cuando se muestre información de fuentes no confiables.

Algunos navegadores incluyen una protección parcial contra los ataques XSS reflejados (el atacante está en la misma petición web). El atacante proporciona una URL incluyendo código malicioso. Sin embargo, incluso los usuarios de los navegadores son vulnerables a otros ataques XSS, tales como aquellos en los que el código malicioso se almacena en una base de datos. Solo el correcto diseño de las aplicaciones Web en la parte servidora puede prevenir totalmente XSS.
Las vulnerabilidades XSS también pueden ocurrir debido a errores de ejecución por los desarrolladores del navegador.

Otra vulnerabilidad es la falsificación de petición de sitio cruzado o CSRF. En CSRF, el código del sitio web atacante engaña al navegador de la víctima, permitiendo al atacante realizar peticiones en nombre de la víctima, haciendo imposible saber a la aplicación de destino (por ejemplo, la de un banco haciendo una transferencia de dinero) saber si la petición ha sido realizada voluntariamente por el usuario o por un ataque CSRF.

El ataque funciona porque, si el sitio de destino hace uso únicamente de las cookies para autenticar las solicitudes de la víctima, las peticiones iniciadas por el código del atacante tendrán las mismas credenciales de acceso legítimo que las solicitudes iniciadas por el propio usuario.

En general, la solución a CSRF consiste en introducir un campo de formulario oculto cuyo valor se utilice para realizar la autenticación, y no solo por medio de las cookies, en solicitudes que puedan tener efectos duraderos. La comprobación de la cabecera HTTP referer también puede servir de ayuda.

"Hijacking JavaScript" es un tipo de ataque CSRF en el que una etiqueta <script> en el sitio web del atacante explota una vulnerabilidad en la página del sitio de la víctima que le hace devolver información privada, en forma de JSON o código JavaScript. Las posibles soluciones son:

En JavaScript, disponer de un depurador se convierte en necesario cuando se desarrollan grandes aplicaciones, no triviales. Dado que puede haber diferencias de implementación entre los diferentes navegadores (especialmente en cuanto al DOM), es útil tener acceso a un depurador para cada uno de los navegadores a los cuales nuestra aplicación web irá dirigido.

Los depuradores web están disponibles para Internet Explorer, Firefox, Safari, Google Chrome y Opera.

Existen tres depuradores disponibles para Internet Explorer: Microsoft Visual Studio es el más avanzado de los tres, seguido de cerca por Microsoft Script Editor (un componente de Microsoft Office) y, finalmente, Microsoft Script Debugger, que es mucho más básico que el otro dos, aunque es gratuito. El IDE gratuito Microsoft Visual Web Developer Express ofrece una versión limitada de la funcionalidad de depuración de JavaScript en el Microsoft Visual Studio. Internet Explorer ha incluido herramientas de desarrollo desde la versión 8 (se muestra pulsando la tecla F12).
Las aplicaciones web dentro de Firefox se pueden depurar usando el Firebug add-on o el antiguo depurador Venkman. Firefox también tiene integrada una consola de errores básica, que registra y evalúa JavaScript. También registra errores de CSS y advertencias.
Opera incluye un conjunto de herramientas llamado Dragonfly.
El Inspector Web de WebKit incluye un depurador de JavaScript utilizado en Safari, junto con una versión modificada de Google Chrome.

Existen algunas herramientas de ayuda a la depuración, también escritas en JavaScript y construidas para ejecutarse en la Web. Un ejemplo es el programa JSLint, desarrollado por Douglas Crockford, quien ha escrito extensamente sobre el lenguaje. JSLint analiza el código JavaScript para que este quede conforme con un conjunto de normas y directrices y que aseguran su correcto funcionamiento y mantenibilidad.




</doc>
<doc id="1573" url="https://es.wikipedia.org/wiki?curid=1573" title="Planta de interior">
Planta de interior

Se denomina planta de interior a cualquier especie vegetal cultivada en lugares bajo techo, como casas u oficinas. En su gran mayoría, son variedades de climas tropicales que se aclimatan en entornos geográficos ajenos gracias a que el cultivo en interior les proporciona las condiciones adecuadas. No hay que confundirlas con algunas plantas de balcón o de jardín, que se ubican en interiores temporalmente pero que para subsistir requieren periodos más largos al exterior

Este tipo de plantas se cultivan normalmente con propósitos decorativos o por razones de salud, como purificadores del aire. Pueden agruparse recreando ambientes selváticos, en invernaderos y miradores acristalados; esto fue muy habitual en la época victoriana.
Los principales factores que deberían considerarse en este tipo de plantas son la humedad del suelo, la luz, la humedad ambiental, la temperatura, los fertilizantes, el enmacetado y el control de plagas. 

Tanto el exceso como la escasez de riego pueden ir en detrimento de la planta. La mejor forma de determinar si una planta necesita riego es comprobar la humedad del suelo. Para ello, se toca la superficie de la tierra y se introduce un dedo ligeramente en el sustrato. El suelo puede variar entre muy mojado (como si estuviera recién regado) a muy seco. Típicamente, una planta de interior necesita riego alrededor de una vez por semana, aunque no se recomienda aplicar esta regla con rigidez. Para regar, rociar agua uniformemente sobre la superficie del sustrato hasta que empiece a drenar por el fondo de la maceta, lo que asegura una completa saturación.

A través del proceso de fotosíntesis las plantas convierten la energía solar en energía química, lo cual las hace crecer. Los dos importantes factores a la hora de proporcionar luz a una planta son la "intensidad" y la "duración".

Cada tipo de planta requiere una intensidad de luz diferente. La intensidad (o calidad) de luz es difícil de medir sin un luxómetro, el cual realiza las mediciones en unidades de lux. 100 lux o menos se considera normalmente como "intensidad baja" o luz "indirecta". Una oficina luminosa tiene una iluminación aproximada de 400 lux. 1.000 lux o más se considera iluminación de "alta intensidad". La luz del sol directa en el exterior está en el orden de los 32.000 a 100.000 lux.

La duración de la exposición luminosa es tan importante como la intensidad. La calidad de exposición de entre 8 a 16 horas es ideal para la mayoría de las plantas. En el hemisferio norte, las ventanas con orientación Sur tienen la mayor cantidad de exposición solar, mientras que las orientadas al oeste, Este y Norte tienen una exposición progresivamente menor. La luz solar directa es ideal, pero la luz solar natural a través de una ventana es imprevisible - los cambios estacionales, la cobertura nubosa y el tratamiento de los cristales pueden afectar a la cantidad de luz entrante.

Las fuentes de luz artificial pueden suministar una alternativa o suplemento a la iluminación recibida de las ventanas. La luz fluorescente proporciona una excelente calidad luminosa, mientras las bombillas incandescentes estándar estimulan muy poco el crecimiento. Los fluorescentes "azules" o "fríos" facilitan la luz necesaria para las plantas de follaje verde, en cambio los "cálidos" o "rojos" son adecuados para las plantas de flor. Existen bombillas fluorescentes que encajan en los casquillos estándar.

Las plantas de interior se cultivan generalmente en suelos especiales llamados "compost de enmacetado" o "sustrato de enmacetado", no en tierra natural. Una buena mezcla de sustrato para macetas incluye acondicionadores de suelo que suministren a la planta nutrientes, soporte, drenaje y aireación adecuados. La mayoría de estos compost contienen una combinación de turba y vermiculita o perlita. Sin embargo la preocupación por los daños medioambientales causados en los marjales están induciendo a sustituir la turba por fibra de coco, un recurso sostenible. 

Si se opta por utilizar tierra natural de la zona se debería, como primera medida, esterilizar por calor, metiendo el sustrato en un horno a 90ºC durante el menos 30 minutos. Esto evitará que la tierra contenga bacterias dañinas. La mayoría de las tierras, en especial aquellas con una alta proporción de arcilla, no drenan lo suficiente como para ser consideradas un medio de crecimiento adecuado para plantas de interior, por lo que se utiliza la turba o la fibra de coco para aumentar la aireación y hacer más absorbentes los suelos pesados. La vermiculita y la perlita ayudan también al drenaje aunque es más recomendable la perlita, ya que no se desmiga tan fácilmente. Si es necesario también se puede usar arena gruesa o gravilla como sustituto para aumentar el drenaje. Estos tres ingredientes se pueden mezclar en varias proporciones para crear diferentes tipos de sustrato de enmacetado. Para plantas que requieran un drenaje rápido, como los cactus, se utiliza más cantidad de arena gruesa, gravilla o perlita. Para las que necesiten mayor cantidad de humedad se usará más turba o fibra de coco. Una buena mezcla de sustrato para todo tipo de plantas consiste en 2 partes de fibra de coco y 1 parte de perlita (o vermiculita). La llamada "mezcla de sustrato pesada" contiene tierra esterilizada, musgo de sphagnum desmigado o fibra de coco y perlita en proporciones iguales. También es posible hacer una mezcla de sustrato que no contenga nada de tierra mezclando a partes iguales turba y perlita (o vermiculita), esta combinación retendrá más la humedad.

La mayoría de las plantas de interior son especies tropicales seleccionadas por su adaptación al crecimiento en un clima que varía entre los 15º a los 25°C, similar al que existe en la mayor parte de las casas. El control de la temperatura en otras plantas con requisitos diferentes necesitará prestar más atención al calentamiento y/o enfriamiento del lugar.

La humedad es algo más difícil de controlar que la temperatura. La mayoría de las plantas prosperan con un 80% de humedad relativa, mientras que la mayor parte de las casas mantienen entre un 20% y un 60%. Además de comprar un humidificador, hay alguna formas caseras que pueden aumentar la humedad. Uno de los más populares es usar pequeños guijarros, cristalitos esmerilados u otro material similar, se coloca una cama de este material en el fondo de la maceta de drenaje de la planta y se llena de agua, la evaporación de esta agua producirá humedad a su alrededor. Otro de los métodos es agrupar las plantas en lugar de colocarlas aisladas en zonas con corrientes de aire.

En condiciones de enmacetado, los nutrientes de la tierra llegan a agotarse al cabo del tiempo, los fertilizantes suministran estos nutrientes artificialmente. Sin embargo, añadir fertilizantes innecesariamente puede ser perjudicial para la planta, por lo que hay considerar algunos síntomas como crecimiento lento, amarilleamiento de las hojas o caída de hojas nuevas para juzgar si el abonado es necesario.

Los fertilizantes se marcan normalmente con números, como 20-20-20. Estos indican el porcentaje de nitrógeno, fósforo y potasio, elementos necesarios para el crecimiento vegetal. La combinación 20-20-20 es generalmente adecuada para plantas verdes, mientras que 10-20-10 es habitualmente mejor para plantas de flor.

La seguridad de un fertilizante depende de la disolución que se pueda hacer del producto. Aunque se puede producir alguna variación dependiendo de la marca, una regla general es diluir una cucharada por cada 3,5 litros de agua. En todos los casos, es más seguro infra-fertilizar que sobre-fertilizar. Esta disolución se utilizará para regar las plantas y se vigilará el crecimiento para determinar si se ha conseguido el efecto deseado y la frecuencia con que debe ser administrada. Las necesidades de abonado pueden variar entre quincenales hasta cada tres meses.

El tamaño de las macetas es un factor importante a considerar. Una maceta demasiado grande provocará el enfermamiento de las raíces debido al exceso de humedad retenida en el sustrato, mientras que una maceta demasiado pequeña restringirá el crecimiento de la planta. En general, una planta puede permanecer en la misma maceta durante aproximadamente dos años. <br>Existen una amplia variedad de macetas, pero normalmente se pueden dividir en dos grupos: las porosas y las no porosas. Las porosas son normalmente de barro, material altamente recomendado ya que proporcionan una mejor aireación, al permitir el paso del aire por los laterales. Las no porosas, como las de cerámica o plástico tienden a mantener más tiempo la humedad y restringen el flujo de aire. Otra característica necesaria son los agujeros de drenaje. Normalmente las macetas vienen con agujeros en el fondo para permitir que escurra el exceso de agua de la tierra y evitar la podredumbre de las raíces. En el caso de que una maceta no posea estos agujeros, se puede crear un mecanismo de drenaje poniendo fragmentos de arcilla o guijarros en el fondo antes de llenarla con el sustrato, lo cual hará que el exceso de agua se deposite en este espacio en lugar de permanecer en la tierra.<br> Las macetas viejas se deben lavar cuidadosamente para eliminar cualquier bacteria, causada por una planta enferma, que hubiera podido quedar.









</doc>
<doc id="1575" url="https://es.wikipedia.org/wiki?curid=1575" title="Japón">
Japón

Japón (en japonés: 日本, "Nihon" o "Nippon"), oficialmente el Estado del Japón (日本国, o "Nippon-koku"), es un país soberano insular del este de Asia. Situado en el océano Pacífico; tiene al oeste el mar del Japón, China, Corea del Norte, Corea del Sur y Rusia, al norte el mar de Ojotsk y al este y sur el mar de China Oriental y Taiwán. Los caracteres que componen el nombre de Japón pueden significar «el origen del sol» o «la base del sol», motivo por el que el país también es conocido como la Tierra del Sol Naciente, ya que desde la perspectiva de China, el sol sale desde Japón. No tiene ningún idioma oficial hasta la fecha, ya que el japonés se considera un idioma nacional en dicho país, término que no se debe confundir con el anteriormente dicho.

Japón es un archipiélago compuesto por . El Área del Gran Tokio en la isla de Honshū, donde está la ciudad de Tokio, capital "de facto" de la nación, es la mayor área metropolitana del mundo, con más de treinta millones de residentes. Y a su vez, Tokio, la capital, es la ciudad más grande del mundo en cuanto a extensión.

Los restos arqueológicos indican que el ser humano ha vivido en Japón desde el Paleolítico superior. La primera mención escrita de las islas se encuentra en textos de la antigua China del siglo I d. C. La historia de Japón ha alternado periodos de influencia extranjera con otros muy prolongados de aislamiento total. Desde el siglo XII hasta 1868 Japón estuvo gobernado por sucesivos shogunatos militares que ejercían el poder en nombre del emperador. En el siglo XVII el país entró en un largo periodo de aislamiento que no terminó hasta mediados del siglo XIX. Después de casi dos décadas de conflictos internos e insurrecciones se restauró al emperador Meiji como jefe del Estado en 1868 y se proclamó el Imperio del Japón.

A finales del siglo XIX y principios del XX, los éxitos en la primera guerra sino-japonesa, en la guerra ruso-japonesa y en la Primera Guerra Mundial permitieron a Japón expandir su imperio y fortalecer sus fuerzas armadas. La segunda guerra sino-japonesa que se inició en 1937, acabó formando parte de la Segunda Guerra Mundial desde 1941, conflictos que terminaron tras la rendición de Japón debido a los bombardeos atómicos sobre Hiroshima y Nagasaki en 1945. Desde la adopción de la constitución revisada en 1947, Japón ha mantenido una monarquía constitucional unitaria con un emperador y un órgano de gobierno democrático llamado Dieta.

Japón es desde hace varias décadas una de las grandes potencias económicas mundiales, y en la actualidad es la de acuerdo a su PIB. Asimismo, es el cuarto mayor exportador e importador de mercancías. Aunque Japón renunció oficialmente a su derecho a declarar la guerra tras la Segunda Guerra Mundial, posee unas modernas fuerzas armadas y el mundial para su autodefensa y el mantenimiento de la paz.

Es miembro de la Organización de las Naciones Unidas, el G7, el G4 y la APEC. Japón es el segundo país con la menor , solo por detrás de Singapur, las mujeres japonesas tienen la segunda mayor esperanza de vida y, según la ONU, el país presenta la tercera menor mortalidad infantil del mundo.

El nombre Japón ("Nippon/Nihon" 日本, significado literal: «el origen del sol») tiene un origen chino: pinyin rì běn, Wade-Giles jih pen, el oriente, el lugar desde donde sale el sol. El carácter 日 es la evolución de un círculo con un punto central que representa al sol, y 本 representa la raíz de un árbol y también tiene el significado de origen. La expresión «país del sol naciente» hace referencia a esta etimología del nombre en japonés.

El nombre en japonés, Nippon, es utilizado en sellos y en eventos deportivos internacionales, mientras que Nihon se usa comúnmente dentro de Japón. La versión occidental y española, Japón, proviene del nombre chino. La palabra empleada en el idioma chino mandarín para denominar al país fue registrada por Marco Polo como Cipangu, probablemente su transliteración de rìběnguó (Wade-Giles jih pen kuo). En el idioma malayo la palabra china se transformó en Japang y fue más tarde adoptada por los mercaderes portugueses en el siglo XVI. Estos últimos fueron los primeros en llevar el nombre a Europa.

Según la leyenda descrita en el "Kojiki" y en el "Nihonshoki", Japón fue fundado en el siglo VII a. C. por el emperador Jinmu. Durante los siglos V y VI, el sistema caligráfico chino y el budismo fueron introducidos junto con otras costumbres chinas a través de la península coreana o directamente desde China. Los emperadores fueron gobernantes oficiales, pero el verdadero poder permanecía generalmente en manos de poderosas cortes nobles, regentes o shogunes (gobernadores militares).

En 1543, comerciantes portugueses y más tarde misioneros jesuitas llegaron a Japón , iniciando un intercambio comercial y cultural directo entre Japón y Occidente. 

A los portugueses se les permitió comerciar y crear colonias donde pudieran convertir a los nuevos creyentes en una religión cristiana. El estado de guerra civil en Japón benefició enormemente a los portugueses, así como a varios caballeros rivales que buscaban atraer barcos portugueses negros y su comercio a sus dominios. Inicialmente, los portugueses llamaron a las tierras de Matsura Takanobu de Firando (Hirado), y en la provincia de Bungo, tierras de Ōtomo Sōrin, pero en 1562 se trasladaron a Yokoseura cuando el Daimiô de allí, Omura Sumitada, se ofreció a ser el primer señor en convertirse al cristianismo, adoptando el nombre de Dom Bartolomeu. En 1564, se enfrentó a una rebelión instigada por el clero budista y Yokoseura fue destruida . En 1571, Dom Bartolomeu, u Omura Sumitada, aseguró un pequeño terreno en el pequeño pueblo pesquero de Nagasáqui a los jesuitas, quienes lo dividieron en seis áreas, para recibir a cristianos exiliados de otros territorios y comerciantes portugueses. En 1579, Nagasáqui ya tenía cuatrocientas casas, con algunos portugueses casados. Temiendo que Nagasaki pudiera caer en manos de su rival Takanobu, Omura Sumitada (Dom Bartolomeu) decidió garantizar la ciudad directamente a los jesuitas en 1580 .

Después de unos años, como los jesuitas creían que si entendían el idioma lograrían más conversiones a la religión católica, el portugués se convirtió en la primera lengua occidental en tener un diccionario japonés, compilado por jesuitas como João Rodrigues y publicado en Nagasaki en 1603. 

Después de que Nobunaga fuera asesinado en 1582 por Akechi Mitsuhide, su sucesor Toyotomi Hideyoshi unificó la nación en 1590 y lanzó dos invasiones fallidas de Corea en 1592 y 1597. Antes de la invasión, Hideyoshi intentó contratar dos galeones portugueses para unirse a la invasión, pero el los portugueses rechazaran la oferta. En 1549, llegó a Japón para predicar el cristianismo el misionero jesuita San Francisco Javier tras desembarcar en Kagoshima, Kyūshū, por las rutas comerciales portuguesas. A comienzos del siglo XVII, el shogunato comenzó a sospechar de las misiones cristianas, considerándolas precursoras de una conquista militar por fuerzas europeas y, como medida de protección, ordenó el cierre de Japón a toda relación con el mundo exterior a excepción de contactos restringidos con mercaderes chinos y neerlandeses en la ciudad de Nagasaki. Este aislamiento se prolongó durante 251 años, hasta el año 1854, en que el comodoro estadounidense Matthew Perry forzó la apertura del Japón a Occidente bajo el Tratado de Kanagawa.

Durante un largo período, el restablecido contacto con Occidente provocó cambios en la sociedad japonesa. Tras un fuerte conflicto civil denominado guerra Boshin, el shogunato fue obligado a renunciar y el poder fue devuelto al emperador. La Restauración Meiji de 1868 inició varias reformas. El sistema feudal fue abolido y numerosas instituciones occidentales fueron adoptadas, incluyendo un sistema legal y de gobierno occidentales, junto con otras reformas en lo económico, social y militar que transformaron a Japón en una potencia mundial de nivel medio-alto. Como resultado de la Primera Guerra Sino-Japonesa y de la Guerra Ruso-Japonesa, Japón anexionó Taiwán, Corea y otros territorios a su imperio en expansión.

Así se afianzó de manera definitiva como una potencia mundial y la única de Asia. Después de la Primera Guerra Mundial, 1918, Japón ocupaba una sólida posición en el Lejano Oriente; contaba con la Armada más poderosa de la zona, ejercía gran influencia sobre China y se había beneficiado económicamente de la guerra (se ocupaba de los pedidos de los países asiáticos, a los que el resto de las potencias no lograban atender).

Durante la década de los años 1920, surgieron problemas que la democracia no pudo resolver. Por un lado, los grupos más conservadores como la milicia, los pares, etc. que se encontraban posicionados en la cámara alta del parlamento y en el Consejo, consideraban que la democracia era muy débil. La corrupción dentro del gobierno era insostenible, las acusaciones entre los miembros de la Cámara Baja provocaban continuamente disturbios. El auge comercial que había alcanzado tras la Primera Guerra Mundial disminuyó cuando en 1921, Europa comenzó su recuperación. Tuvo nefastas consecuencias de la Gran depresión, aumento de las tarifas de los países extranjeros para los productos japoneses y la pobreza que se vio reflejada en el norte donde los humildes campesinos culpaban al gobierno nipón de sus desdichas (muchos aldeanos se sumaron al ejército). La suma de estos problemas y la actitud de China, tratando de desplazar los negocios japoneses, derivó en la invasión a Manchuria (septiembre de 1931). Esta invasión se produjo sin la autorización del gobierno nipón.

Cuando el primer ministro Inukai reprobó los actos extremistas, fue asesinado por un grupo de oficiales de marina (15 de mayo de 1932), y su sucesor consideró que debía apoyar las acciones del ejército y así fue que durante los 13 años siguientes: el gobierno adoptó un estricto control de la educación, fortalecimiento del arsenal bélico y una política exterior agresiva orientada a conquistar territorios. Esto culminó en una nueva invasión de Manchuria, desatando la Segunda Guerra Sino-Japonesa.

En simultáneo se inició también una corriente de emigración que generó actuales comunidades japonesas en lugares tan distantes cómo Hawái, Estados Unidos, Perú, Brasil, Argentina, etc. Por ejemplo, respecto a la Inmigración japonesa en Argentina, surgieron muchos emprendimientos nipones cómo tintorerías, cultivos de flores, e inclusive cafés. La mayor colectividad japonesa en el extranjero se encuentra en Brasil, fundamentalmente en la zona de San Pablo.

Japón atacó la base naval estadounidense de Pearl Harbor en diciembre de 1941, lo cual llevó al país norteamericano a declarar la guerra al Imperio Japonés en el marco de la Segunda Guerra Mundial. Después de una larga campaña en el Pacífico, Japón perdió Okinawa y fue forzada a retroceder a las cuatro islas principales. El ejército estadounidense atacó Tokio, Osaka y otras ciudades con bombardeos estratégicos convencionales, y en Hiroshima y Nagasaki con dos bombas atómicas (6 y 9 de agosto de 1945). Japón finalmente aceptó la capitulación incondicional ante el ejército estadounidense el 15 de agosto de 1945 dando con ello fin a la guerra.

Finalizado el conflicto, el ejército estadounidense ocupó el territorio japonés hasta 1952, tras lo cual Japón comenzaría una muy importante recuperación económica que devolvería la prosperidad al archipiélago. Okinawa permaneció ocupada hasta 1972, y actualmente el ejército estadounidense mantiene un centenar de bases en este país. El 17 de enero de 1995 el terremoto de Kōbe causó la muerte de 6433 personas. Durante marzo del mismo año la secta Verdad Suprema llevó a cabo un ataque en el metro de Tokio que causa la muerte a 12 personas y heridas a más de 1000. En octubre de 1998, se condena con la sentencia de cadena perpetua al máximo responsable de la secta, y pena capital a otro de los miembros fundadores. Más tarde, un nuevo ataque terrorista en el aeropuerto de Narita hizo peligrar la celebración de los Juegos Olímpicos de Nagano 1998. La autodenominada Asociación Revolucionaria de Trabajadores no hizo reivindicaciones del hecho y las competiciones se celebraron tal y como estaban previstas en febrero de 1998.

El Partido Democrático de Japón obtuvo una clara victoria en las elecciones generales de 2009, obteniendo 300 escaños de los 480 disponibles.

El 11 de marzo de 2011, a las 2:46 en el epicentro, Japón se vio azotado por un terremoto de 9.0 en la escala sismológica de magnitud de momento, el terremoto de mayor magnitud de su país en 140 años. El epicentro del temblor fue en la costa del este de Honshū, provocó un violento tsunami con olas de 10 metros.
Se calcula que la catástrofe dejó más de pérdidas humanas, desaparecidos y pérdidas económicas por más de 150 mil millones de euros, según datos del gobierno nipón. Este terremoto causó muchos problemas a las centrales nucleares de Japón y provocó grandes fugas radiactivas. Una de las centrales afectadas gravemente fue la central de Fukushima.

El entonces emperador Akihito (明仁?) abdicó en el día 30 de abril de 2019 debido a su edad y a su estado de salud en declive, convirtiéndose en emperador emérito (Daijō Tennō). Le sucedió su hijo mayor, Naruhito. Esto dio fin a la Era Heisei e inicio la Era Reiwa.

Japón es una monarquía constitucional, y un estado soberano por el cual el poder del Emperador es muy limitado. Como figura decorativa ceremonial, la constitución lo define como "el símbolo del Estado y de la unidad del pueblo". El poder ejecutivo es ejercido principalmente por el primer ministro y su gabinete, mientras que la soberanía recae en el pueblo japonés. La Constitución de Japón es la constitución no enmendada más antigua del mundo. No ha cambiado desde su adopción el 3 de mayo de 1947. 

El gobierno es descentralizado. Se puede distinguir:


El órgano legislativo de Japón es la Dieta Nacional, ubicada en Chiyoda, Tokio. La Dieta es un órgano bicameral, que comprende la Cámara de Representantes con 465 escaños, elegidos por voto popular cada cuatro años o cuando se disuelve; y la Cámara de Consejeros con 242 escaños, cuyos miembros elegidos popularmente sirven términos de seis años. Existe Sufragio universal para adultos mayores de 18 años, con una voto secreto para todos los cargos elegidos.

En la práctica, es una democracia parlamentaria, el pueblo no vota a un presidente, sino a los miembros del Parlamento y estos, a su vez, votan a un primer ministro de entre uno de ellos. El tiempo que un primer ministro permanece en su cargo depende de por cuanto tiempo pueda mantener el apoyo de la mayoría del parlamento, pudiendo durar muchos años o tan solo unos meses. A diferencia de otras democracias, como los Estados Unidos o el Reino Unido, donde coexisten dos partidos fuertes que se alternan en el poder, Japón tuvo hasta las elecciones de 2009 un partido dominante (el Partido Liberal Democrático) que coexistió con otros partidos menores sin opciones reales de proponer a un primer ministro propio. El PLD ha tenido éxito electoral casi continuo desde 1955, excepto por breves períodos entre 1993 y 1994 y de 2009 a 2012. En 2009 el Partido Democrático tuvo escaños necesarios como para provocar una alternancia de poder en 2009.

El primer ministro de Japón es el Jefe de Gobierno y es nombrado por el Emperador después de ser designado por la Dieta entre sus miembros. El primer ministro es el jefe del Gabinete y nombra y destituye a los Ministros de Estado. Yoshihide Suga reemplazó a Shinzō Abe como primer ministro el 16 de septiembre de 2020, luego de que este anunciara su dimisión semanas atrás por motivos de salud.. Suga fue ratificado en el cargo en una sesión de la Dieta Nacional, donde el PLD tiene mayoría absoluta. 


Japón mantiene estrechas relaciones económicas y militares con los Estados Unidos, con el que ha formado una alianza de seguridad, piedra angular de su política exterior. Estado miembro de la Organización de las Naciones Unidas desde 1956, ha sido miembro no permanente del Consejo de Seguridad un total de 20 años, más que ningún otro miembro de la ONU, las últimas veces en 2016 y 2017. También forma parte del Grupo de los cuatro en el que cada miembro busca la condición de miembro permanente en el Consejo de Seguridad. Como miembro del G8, la APEC, la «ASEAN más tres» y participante en la Cumbre de Asia Oriental, Japón participa activamente en los asuntos internacionales. No obstante, el nivel de implicación personal japonesa es extraordinariamente bajo: únicamente el 1,3 % del personal de las organizaciones internacionales multilaterales es japonés. También es el tercer mayor donante de Ayuda oficial al desarrollo en el mundo tras donar millones de dólares en 2004. Contribuyó con tropas no combatientes en la Guerra de Irak, pero posteriormente retiró dichas fuerzas.

Japón tiene varias disputas territoriales con sus vecinos: con Rusia sobre las islas Kuriles del Sur, con Corea del Sur las Rocas de Liancourt, con la República Popular China y Taiwán sobre la islas Senkaku, y con la República Popular China sobre la zona económica exclusiva en torno a Okino Torishima. También se enfrenta a una permanente disputa con Corea del Norte por el secuestro de ciudadanos japoneses y el Programa nuclear norcoreano. Como resultado de la controversia en torno a las islas Kuriles, está técnicamente aun en guerra con Rusia ya que nunca fue firmado ningún tratado para resolver la cuestión.

La capacidad militar japonesa está limitada por el artículo 9 de la Constitución japonesa, por el que renuncia a su derecho a declarar la guerra o utilizar la fuerza militar como medio de resolver las controversias internacionales. El Ministerio de Defensa, rige la capacidad militar japonesa que se compone principalmente de la Fuerza Terrestre de Autodefensa de Japón (JGSDF), la Fuerza Marítima de Autodefensa de Japón (JMSDF) y la Fuerza Aérea de Autodefensa de Japón (JASDF). El Partido Liberal Democrático, el más importante de Japón, continúa intentando reformar el citado precepto constitucional con vistas a la denominación oficial de las Fuerzas de Autodefensa como unas fuerzas armadas, así como a la expansión de sus capacidades y funciones, para que finalmente adquieran un estatus similar al de cualquier otra fuerza armada. Las fuerzas militares japonesas se han utilizado recientemente en las operaciones de mantenimiento de la paz y el despliegue de tropas japonesas en Irak, que fue el primer uso de sus fuerzas militares en el extranjero desde la Segunda Guerra Mundial.

Este país es uno de los países industrializados donde aún se mantiene la pena de muerte. De hecho, se ha revivido la aplicación de la pena capital en Japón; en 2007 se ejecutaron por ahorcamiento a nueve personas, a 15 en 2008 y en 2012 a 16.

Japón está dividido en cuarenta y siete prefecturas, cada una de ellas gobernada por un gobernador, poder legislativo, y burocracia administrativa elegidos. Cada prefectura se divide en ciudades, pueblos y aldeas. En la primera década del siglo XXI, la nación estuvo en una reorganización administrativa, uniendo ciudades, pueblos y villas, las unas con las otras. Este proceso redujo el número de regiones administrativas sub-prefecturales y se esperaba con ello recortar costes administrativos.
Principalmente, Japón está subdividido en 47 prefecturas, agrupadas en 8 regiones:

Japón es un archipiélago estratovolcánico que comprende 377 975 km² de superficie de los cuales 13 430 km² son agua. Está conformado por 6852 islas que se extienden a lo largo de la costa asiática este del océano Pacífico y en los archipiélagos de Ryukyu, Izu y Ogasawara (los 2 últimos archipiélagos conocidos colectivamente como Islas Nanpō). Según el censo de 2005 tiene 127,55 millones de habitantes. El país está ubicado al noreste de China y de Taiwán (separado por el mar de China Oriental), levemente al este de Corea (separado por el mar del Japón) y al sur de Siberia, Rusia. Las cuatro islas principales, de norte a sur, son Hokkaidō, Honshu, Shikoku y Kyushu. La isla de Okinawa (600 km al sudoeste de Kyushu) les sigue en magnitud. Cerca del 73 % del país es montañoso, cada isla cuenta con su cadena montañosa. La montaña más alta es el Monte Fuji ("Fujisan"), de 3776 m de altura y le sigue Kitadake, con 3193 m de altura. Debido a que existe tan poco terreno llano en Japón, muchas colinas y laderas son aprovechadas en su totalidad para el cultivo. Como se encuentra situada en una zona de mucha actividad volcánica resultan frecuentes temblores de pequeña magnitud y actividad volcánica ocasional. Terremotos destructivos ocurren varias veces cada siglo, resultando a menudo en tsunamis.

Las islas montañosas del archipiélago forman un arco desde las costas del este de Asia. El territorio nacional incluye las pequeñas islas Bonin u Ogasawara incluyendo la isla Iwo Jima aproximadamente a 1100 kilómetros de las islas principales. La particularidad de que Japón sea un archipiélago produce que ningún punto de Japón esté a más de 150 kilómetros del mar.

Las cuatro islas principales se encuentran separadas por angostos canales y tres de ellas (Honshu, Shikoku y Kyūshū) por el Mar Interior de Seto. En el extremo meridional se encuentran las islas Ryukyu a 970 kilómetros al sur de la tercera gran isla, Kyūshū.

El punto más cercano al continente asiático es la península de Corea que se encuentra a una distancia aproximada de 200 kilómetros. Siempre estuvo conectada con el continente a través de rutas marítimas de comercio: en el norte con Siberia, en el oeste desde las islas Tsushima hacia la península coreana y en el sur con los puertos del sur de China.

Tiene aproximadamente un 84 % de territorio montañoso. El 14 % de la superficie se dedica a actividades agrícola-ganaderas, el 66 % a bosques y el 20 % restante está dedicado a otros usos, debido a que sus islas son una cadena montañosa en la parte sumergida de la plataforma continental, siendo las islas sus picos. Solo cerca del 25 % del territorio es llano y es donde se concentra la población. Una larga cadena montañosa divide el archipiélago por la mitad, una de las cuales se encuentra del lado del océano Pacífico y la otra del lado del mar del Japón (lo cual se aprecia en el mapa topográfico). En la mitad del Pacífico hay escarpadas montañas, de entre 1500 y 3000 metros de altura aproximadamente, que forman profundos valles y desfiladeros. En el centro convergen tres cadenas montañosas: las Hida, las Kiso y las Akaishi, las cuales forman los Alpes japoneses, siendo Kitadake su montaña más alta con 3193 metros, pero la segunda en altura del país. El punto más elevado del territorio es la cima del monte Fuji a 3776 metros de altura. El monte es un volcán dormido desde 1707 ubicado en la prefectura de Shizuoka.

Ninguna de las llanuras o valles habitados es amplia. La más grande es la llanura de Kanto, en donde está situado Tokio, y solo tiene 17 . Otras llanuras importantes son: la de llanura de Nōbi, que rodea Nagoya; la de Kinki, en el área de Osaka-Kioto; la de Sendai, que rodea la ciudad de Sendai al noreste de Honshū y la de Ishikari en Hokkaidō. La mayoría de estas llanuras están a lo largo de la costa.
La pequeña parte de tierra habitable sufrió diversas modificaciones en su terreno a lo largo de los siglos. Las tierras próximas al mar y a los ríos tiene numerosas construcciones de diques y drenajes, muchas colinas y montañas están cortadas en terrazas escalonadas para aumentar el terreno cultivable y para aumentar el terreno edificable. Este proceso de modificación del medio continúa actualmente con la extensión de la línea costera y la construcción de islas artificiales para las industrias y para el crecimiento del puerto. Un ejemplo de esto es el Aeropuerto Internacional de Kansai, en la bahía de Osaka.

Los ríos de Japón suelen ser rápidos y abruptos, solo unos pocos son navegables y la mayoría suelen tener menos de 300 kilómetros de largo. A pesar de esto, Japón logra aprovechar estos ríos para producir energía hidroeléctrica, aunque este recurso se encuentra explotado casi hasta su capacidad. El río más largo del territorio es el Shinano, el cual nace en la prefectura de Nagano hasta la prefectura de Niigata donde desemboca en el mar del Japón, pero solo tiene 367 kilómetros de largo. La mayor reserva de agua se encuentra en el lago Biwa al noreste de Kioto.

La extensión de la costa navegable especialmente en el mar de Seto, compensa la falta de ríos navegables. La costa pacífica del sur de Tokio tiene la característica de ser larga y de aumentar su profundidad de forma muy gradual debido a la sedimentación.

Es un país lluvioso y con una alta humedad, posee un clima templado con 4 estaciones diferentes bien definidas, gracias a la distancia a la que se encuentra respecto del ecuador. De todas formas el clima del norte es ligeramente frío templado (Hokkaidō) con fuertes veranos y grandes nevadas en invierno, el centro del país es caliente, veranos húmedos e inviernos cortos y en el sur ligeramente subtropical (Kyūshū) con veranos largos, calientes y húmedos e inviernos cortos y suaves. El clima a veces es afectado por los vientos estacionales producidos por los centros ciclónicos y anticiclónicos que se forman en el continente y en el Pacífico (anticiclón o ciclón hawaiano), generando vientos desde el continente hacia el Pacífico en invierno y del Pacífico al continente en verano.

Existen dos factores primarios en la influencia climatológica: la cercanía con el continente asiático y las corrientes oceánicas. El clima desde junio a septiembre es caliente y húmedo por las corrientes de viento tropicales que llegan desde el océano Pacífico y desde el sudeste asiático. Estas corrientes precipitan grandes cantidades de agua al tocar tierra, por lo que el verano es una época de importantes lluvias, que comienzan a principios de junio y duran alrededor de un mes. Le sigue una época de calor y a principios de agosto hasta principios de septiembre, un periodo de tifones, en la cual pasan por Japón 5 ó 6 de ellos y llegan a producir daños significativos. La precipitación anual de lluvias es de 100 a 200 centímetros, pero entre el 70 y el 80 por ciento de estas están concentradas en junio y en septiembre.

En invierno, los centros de alta presión del área siberiana y los centros de baja presión del norte del océano Pacífico, generan vientos fríos que atraviesan Japón de oeste a este, produciendo, importantes nevadas en la costa japonesa del mar del Japón. Como los vientos chocan contra las cadenas montañosas del centro, las grandes alturas terminan por precipitar la humedad de estos vientos en forma de nieve y al pasar por la costa pacífica del país llegan sin portar notables cantidades de humedad, por lo que no son el factor principal de nevadas en la costa pacífica. Además esto provoca que en esta costa, el tiempo en invierno sea seco y de días sin nubes, al contrario del invierno en la costa oeste.

Hay dos corrientes oceánicas que afectan al modelo climático: la corriente cálida de Kuroshio y la corriente fría de Oyashio. La corriente de Kuroshio fluye por el Pacífico desde Taiwán y pasa por Japón bastante al norte de Tokio, es una corriente que lleva mucho calor a la costa este.

Japón tiene nueve ecorregiones que reflejan el clima y la geografía de las islas, la cual va desde pluvisilvas en las islas Ryūkyū y Ogasawara, a bosques templados de frondosas en las regiones templadas de las islas principales, a bosques templados de coníferas en las partes frías de las islas más norteñas.

La fauna comprende 132 especies de mamíferos, 583 especies de aves y 66 especies de reptiles, batracios y peces.


Entre los mamíferos podemos destacar el oso negro asiático, presente en Honshu, y Shikoku, aunque extinto en Kyushu, el oso pardo de Hokkaido (ursus arctos ussuriensis), isla donde no está presente el oso negro; el jabalí, ausente en Hokkaido, pero presente en el resto del archipiélago, el ciervo sika, el serow japonés (especie de antílope parecido al rebeco, que se encuentra en las montañas de Honshu, y en menor medida en Kyushu y Shikoku); el zorro rojo (ausente de Shikoku), la marta japonesa ("Martes melampus"), el tejón japonés (Meles anakuma), presente en las grandes islas, excepto Hokkaido, el tanuki, o perro mapache, distribuido por todo el archipiélago. Es interesante señalar la presencia de dos variedades de gato salvaje, restringidas a pequeñas islas: el gato de Iriomote, isla al sur de las Riukiu, o el gato de Tshushima que solo habita en esta isla, ambas son subespecies del gato leopardo. Existen variedades del zorro volador en Okinawa y en las islas Bonin. El león marino de Steller se concentra en loberías en la costa de Hokkaido, si bien no llega criar. Existe una amenazadísima población de dugongos en las Riukiu, no obstante, la excesiva presión humana, escaso número, y deficientes leyes de protección de la naturaleza en Japón, podrían haber provocado ya su desaparición.
Se extinguieron igualmente los lobos japoneses, tanto en las islas meridionales, como en Hokkaido. Su nombre japonés es okami.

Entre las especies introducidas podemos citar la civeta de las palmeras presente en Honshu; el mapache ("Procyon lotor"), distribuido por Hokkaido y Honshu merced a la liberación de mascotas, el muntjac presente en Honshu (Península de Boso y en Oshima); el coypú de Sudamérica introducido por su piel se ha expandido por Honshu. El único primate es el macaco japonés, que puebla Honshu, Shikoku, Kyushu y alguna isla menor.

Entre las aves más vistosas podemos mencionar: la grulla de Manchuria en Hokkaido, el enorme águila marina de Steller, se trata de la mayor variedad de pigargo, el pigargo común, el águila real, el águila azor asiática, el faisán cobrizo ("Syrmaticus soemmerringii") y el faisán verde ("Phasianus versicolor"); ambos endémicos de Japón, y presentes en Kyushu, Honshu y Shikoku.

La gran variedad de la vegetación japonesa (unas 17.000 especies) se debe al clima y al relieve. Los bosques cubren el 67 % de la superficie del país y se componen en su mayoría de frondosas y coníferas: castaños japoneses, hayas japonesas ("Fagus crenata y Fagus japonica"), arces, tuyas, pino rojo japonés ("Pinus densiflora"), pino coreano ("Pinus koraiensis") y otros ("Pinus parviflora", "Pinus thunbergii"). Existen igualmente diversas variedades de robles ("Quercus acuta, Quercus aliena, Quercus dentata, Quercus mongolica, Quercus variabilis"), abedules ("Betula ermanii", "Betula maximowicziana", "Betula platyphylla") y fresnos ("Fraxinus lanuginosa", "Fraxinus mandshurica").

En general, podemos señalar que la vegetación japonesa va de la claramente tropical en las Riukiu, a la propia de los bosques den transición entre la taiga y los templados caducifolios en Hokkaido; pasando por la flora subtropical en el sur de Honshu, Shikoku y Kyushu. Esta última se caracteriza por árboles y arbustos siempre verdes, de hojas brillantes y cerosas. Se trata de una especie de laurisilva, con plantas como (camelias, rododendros, alcanforeros...).

El área templada fría se extiende por el centro de Honshu, sur de Hokkaido, y montañas de las dos islas meridionales. En esta zona encontramos hayas, arces, castaños japoneses y robles como árboles dominantes. Las coníferas en sus distintas y ricas variedades se distribuyen por todo el archipiélago. Las especies vegetales se mezclan en las zonas de contacto haciendo que la vegetación sea especialmente rica y variada, y ofreciendo en buena parte del país un otoño de colores espectaculares, de forma similar a lo que sucede en los bosques de los Apalaches americanos.

Los ciruelos blancos y rojos, los cerezos de floración temprana, así como el bambú y los pinos se han convertido en símbolos tradicionales del país.

Las islas se ubican en una de las zonas geológicamente más inestables y complejas del planeta. En general, es un país altamente sísmico a causa de su ubicación en el Cinturón de Fuego del Pacífico. En Japón se han presentado 5 importantes terremotos en los últimos 15 años.

El grupo insular nipón es, sobre todo, el resultado de continuos e inmensos movimientos oceánicos que ocurrieron durante centenares de millones de años desde mediados del Período Silúrico hasta el Pleistoceno. Este proceso fue como resultado de la subducción tectónica de la placa filipina y la placa Pacífica debajo de las continentales placa Euroasiática y placa Norteamericana.

La mayor parte del territorio terrestre está asentado sobre la placa de Ojotsk, ubicándose su línea de fricción y ruptura con la placa Euroasiática (sector también conocido como placa Amuria ) al sur de la isla de Honshū. El resto del territorio japonés se encuentra en la segunda placa mencionada. Mientras tanto, el arco de las islas Ryūkyū se encuentran al borde de la placa Filipina.

Por otro lado, la unión de la placa Filipina, la placa Euroasiática y la placa de Ojotsk ocurre en las cercanías del monte Fuji o Fujisan, convergencia con un alto potencial sísmico y vulcanológico.

Esta compleja distribución, origina profundas y extensas fosas oceánicas, especialmente en la costa pacífica del archipiélago. Destaca en particular la Fosa de Japón, de 9000 metros de profundidad, originada por una falla con borde convergente por subducción.

Japón estuvo asociado originalmente a la costa este del continente eurasiático. Las placas se subdujeron, siendo más profundas que la placa Euroasiática. Estos procesos geológicos tiraron a Japón hacia el este, originado la apertura del mar del Japón hace alrededor 15 millones de años y dando lugar a una cuenca submarina de trasarco El estrecho de Tartaria y el Estrecho de Corea fueron abiertos mucho más adelante.

Las colisiones entre estas placas y su posterior hundimiento generaron los arcos de islas de las Kuriles y de Sajalin-Hokkaidô (al norte), el arco de Honshû, que conecta Kyūshū, Shikoku, Honshû y la porción oeste de Hokkaidô (en el centro), y los arcos de las Ryûkyû e Izu-Ogasawara (en el sur).

Japón se sitúa en la zona volcánica denominada como el Cinturón de Fuego del Pacífico. Los temblores de tierra son frecuentes (con una intensidad reducida a moderada) y la actividad volcánica ocasional se siente en forma activa en las islas.
Gran cantidad de fallas tectónicas locales recorren la superficie, originando sismos de regular intensidad. Las más grandes son dos fallas transversales al sur de Honshū: la Línea Tectónica de Itoigawa-Shizuoka y la Línea Tectónica Media Japonesa, ambas fallas transformantes que se encuentran en el límite de las placas de Okhotsk y Euroasiática, a lo largo del sistema montañoso de la isla.

Resultan sumamente destructivos los terremotos, a menudo dando como resultado los tsunamis, con una frecuencia de varias veces en un siglo. Los terremotos principales más recientes incluyen el Gran terremoto de Hanshin-Awaji en 1995, el Terremoto de la costa de Chūetsu de 2007 y el Terremoto y tsunami de Japón de 2011.

Cada isla cuenta con su propia cadena montañosa, la cual sigue un eje transversal y las divide por la mitad. En Japón hay alrededor de 200 volcanes; sesenta de ellos están en actividad. El más famoso es el Monte Fuji (Fujisan), de 3776 metros de altura, coronado de nieves perpetuas. Le sigue la montaña Kitadake, con de altura. El Asama es el volcán más activo de todo el archipiélago, y está situado en la isla de Honshu a aproximadamente 100 km de Tokio. Tiene una altura de . Casi la tercera parte del país consiste de terrenos de origen piroclástico. La superficie es fundamentalmente montañosa: solo la quinta parte (el 27 %) está formado por pequeñas llanuras, la mayoría de ellas de tipo aluvial y sedimentario a lo largo de la costa.

Japón es la más grande del mundo, después de los Estados Unidos y China, en torno a 4,5 billones de dólares en términos de PIB nominal y la después de los Estados Unidos y China en términos del poder adquisitivo. Su PIB por hora trabajada es el 18º más alto del mundo desde 2006.

Banca, seguros, bienes raíces, venta al por menor, el transporte y las telecomunicaciones son las principales industrias. Tiene una gran capacidad industrial y es el hogar de algunos de los mayores, mejores y más avanzados tecnológicamente productores de vehículos de motor, equipos electrónicos, máquinas herramientas, acero y metales no-ferrosos, barcos, productos químicos, textiles y alimentos procesados. La construcción ha sido durante mucho tiempo una de las más grandes industrias, con la ayuda de contratos públicos en el sector civil por miles de millones de dólares. Ha elevado la libertad económica, la cooperación entre gobierno e industria, el énfasis en la ciencia y la tecnología, y una fuerte ética de trabajo han contribuido al crecimiento económico. Características notables de la economía de este país, incluyen una fuerte unidad entre productores, manufactureros y distribuidores, reunidos en grupos conocidos como keiretsu y la relativamente baja competencia internacional en los mercados internos. Existen varias modalidades laborales, tales como la garantía de empleo vitalicio en las grandes corporaciones.

Recientemente, algunos encargados de formular las políticas han alentado la reforma y las empresas japonesas han empezado a abandonar algunas de esas normas en un intento de aumentar la rentabilidad. La presión fiscal es menor que en cualquier gran país occidental, siendo del 26,4 % del PIB a partir de 2007. Solo una minoría de empleados japoneses paga cualquier impuesto sobre la renta, el impuesto al valor agregado es de solo 5 %, mientras que las tasas de impuestos a las empresas son altos.

Algunas de las compañías más grandes del país incluyen a Nintendo, Nissan Motors, Toyota Motor, NTT DoCoMo, Canon, Honda, Takeda Pharmaceutical Company, Sony, Suzuki, Panasonic, Toshiba, Nippon Steel, Nippon Oil, Tepco, Mitsubishi Estate, y Seven & I Holding. Es el hogar de algunas de las entidades bancarias más grandes del mundo por activos bancarios. La Bolsa de Valores de Tokio con una capitalización de mercado de más de 549,7 billones de yenes en diciembre del 2006 se erige como la segunda más grande del mundo.

Desde el decenio de 1960 hasta la década de 1980, en términos generales el crecimiento económico real se ha llamado el «milagro japonés»: un 10 % de media en el decenio de 1960, el 5 % de media en el decenio de 1970 y un 4 % promedio en la década de 1980. Este crecimiento se desaceleró notablemente en el decenio de 1990, en gran parte debido a las secuelas del exceso de inversión a finales de los años 1980 y las políticas nacionales destinadas a controlar los excesos especulativos de los mercados inmobiliarios. Los esfuerzos del gobierno para reactivar el crecimiento económico tuvieron poco éxito y fueron obstaculizados en 2000 y 2001 por la desaceleración de la economía mundial. Sin embargo, la economía mostró signos de fuerte recuperación después de 2005. El crecimiento del PIB para ese año fue del 2,8 %, con un cuarto trimestre de expansión a 5,5 %, superando las tasas de crecimiento de los Estados Unidos y la Unión Europea durante el mismo período.

Debido a que solo alrededor del 15 % de la tierra es apta para el cultivo, un sistema de terrazas agrícolas se utiliza para cultivar en áreas pequeñas. Esto ha dado lugar a uno de los más altos niveles de rendimiento de cosechas por unidad de superficie en el mundo, mientras que los subsidios agrícolas y la protección son costosos. Importa alrededor del 50 % de sus necesidades de cereales y otros cultivos, y cubre con importaciones la mayor parte de su oferta de carne. En la pesca comercial de peces, se sitúa en segundo lugar en el mundo detrás de China en el tonelaje de pescado capturado. Mantiene una de las flotas pesqueras más grande del mundo, y representa casi el 15 % de las capturas mundiales.

El transporte está muy desarrollado. A partir de 2004, hay de carreteras pavimentadas, 173 aeropuertos, y de ferrocarriles. Los puertos más importantes incluyen el puerto de Yokohama y el puerto de Nagoya. La mayoría de la energía se produce a partir de petróleo, gas natural y carbón. La energía nuclear en Japón producía hasta hace pocos años un tercio de la electricidad, pero tras el accidente nuclear de Fukushima en 2011 se paralizaron la mayoría de las centrales nucleares del país. Desde entonces, Japón ha dado un giro a su política energética, promocionando otras fuentes de energía renovable, como la energía solar fotovoltaica que se ha incrementado en gran medida.

Los principales socios de las exportaciones son los Estados Unidos 22,8 %, la Unión Europea el 14,5 %, China 14,3 %, Corea del Sur 7,8 %, Taiwán 6,8 % y Hong Kong 5,6 % (datos de 2006). Las principales exportaciones japonesas son equipos de transporte, los vehículos de motor, electrónica, maquinaria eléctrica y productos químicos. Con muy limitados recursos naturales para sostener el desarrollo económico, Japón depende de otras naciones para el suministro de la mayor parte de sus materias primas. Sus principales socios para las importaciones son China 20,5 %, los Estados Unidos 12,0 %, la Unión Europea el 10,3 %, Arabia Saudita 6,4 %, Emiratos Árabes Unidos 5,5 %, 4,8 % Australia, Corea del Sur 4,7 % e Indonesia 4,2 % (datos de 2006). Las principales importaciones realizadas son maquinaria y equipo, combustibles fósiles, productos alimenticios (en particular el sector de la carne), productos químicos, textiles y materias primas para sus industrias. En general, los más grandes socios comerciales del Japón son China y los Estados Unidos.

La deuda pública per cápita de Japón es en 2016 la más alta del mundo.

Tras la finalización de la Segunda Guerra Mundial, Japón entró en un período de crecimiento económico constante que le permitió, durante cuatro décadas consecutivas, escalar puestos a nivel internacional hasta consolidarse como la segunda potencia del planeta en términos de PIB, solo por detrás de Estados Unidos. Si bien este crecimiento se volvió más moderado con la llegada del siglo XXI, Japón sigue representando hoy en día una anomalía socio-económica en la región asiática, en la que mantiene un claro liderazgo a nivel económico (renta per cápita), social y cultural. Internacionalmente, de Japón cabe destacar su madurez demográfica: una altísima densidad de población que, sin embargo, se nutre con una de las tasas de natalidad más bajas del mundo: tan solo un único hijo por mujer, ocupando el puesto n.º 163 del mundo en el ranking de países con mayor índice de natalidad. Datos del Banco Mundial revelan la orientación tecnológica del país: Japón ocupa los últimos puestos en terrenos dedicados al sector primario, y sin embargo ocupa los primeros puestos en la penetración de Internet. Como consecuencia, según el Foro Económico Mundial, Japón es el sexto país del mundo en el Índice de Competitividad Global. En la siguiente tabla se puede analizar el contexto socioeconómico de Japón a partir de datos del Banco Mundial, Eurostat y el Foro Económico Mundial:

Japón sufre en la actualidad de un descenso en su índice de natalidad (1,3 hijos por mujer), causado entre otras razones por el elevado coste de criar y educar a un hijo. Si a lo anterior se le añade el hecho de que posee el tercer puesto en la población más longeva del mundo (82,07 años), la combinación de menos nacimientos con decesos más tardíos, hace temer por la viabilidad de su sistema de pensiones y la disponibilidad en el futuro de mano de obra suficiente. En 2005 por primera vez el número de japoneses decreció, pues se registraron menos nacimientos que decesos.

"Shoshika" (少子化) es una palabra de reciente acuñación (años 1990), cuya traducción podría ser «disminución en el número de niños» y que en la actualidad es utilizada para referirse esta carencia de infantes cada vez mayor en la sociedad japonesa.

En respuesta a este problema, el gobierno ha elevado la edad de jubilación, pero se prevé para las próximas décadas la continuidad de esta declinación de la población. Además, en 1999 reforzó las leyes contra la discriminación de las mujeres en el trabajo. A su vez, lanzó tres proyectos: Plan Ángel, Nuevo Plan Ángel y Una Propuesta Más, todos ellos orientados a facilitar que las mujeres puedan trabajar y ser madres a la vez. Pero estas medidas chocan con la fuerte tradición que rige la sociedad japonesa.

Como medida complementaria, las empresas solicitan que se bajen las barreras inmigratorias, para permitir la entrada de mano de obra no cualificada. Este proyecto está fuertemente cuestionado, porque terminaría con la homogeneidad social, provocando inevitables roces sociales. Como plan a largo plazo, las compañías invierten grandes sumas de dinero en investigación y desarrollo de robótica. Actualmente, Japón posee de los robots industriales en todo el mundo.

El 27 de marzo de 1997, el poder legislativo reconoció oficialmente a la etnia ainu como aborígenes autóctonos de Hokkaidō, en lo que suponía la primera consideración de minoría étnica del archipiélago pero el acto fue solamente simbólico, ya que se había inaugurado ese año la presa cuya expropiación de terrenos disparó las reclamaciones ainus.

En el siglo XXI las japonesas continúan la batalla por un espacio legal, político, económico y social recientemente conquistado más allá del papel secular como responsables de la transmisión de los valores que históricamente han tenido. En la década de los setenta las japonesas comenzaron a tener un protagonismo real en el desarrollo del país, pero fue a principios de los noventa con la crisis económica que azotó el país cuando comenzó su «revolución». Las jóvenes aprovechando las grietas en la sociedad por el sentimiento de crisis rompieron parte de sus ataduras.
La Constitución de 1946 reconoció la igualdad de todos los ciudadanos sin discriminación por raza, credo, sexo, condición social o linaje. En 1985 se promulgó la Ley de Igualdad de Oportunidades, en 1992 la Ley de Baja Maternal y en 2001 la Ley para la Prevención de la Violencia Conyugal, leyes que permitieron a las mujeres japonesas tener las mismas medidas de protección legal que las europeas o las norteamericanas, aunque en la práctica ninguna de las dos primeras leyes mencionadas incluye una penalización para las empresas en caso de incumplirlas.

En 2016 el mundo empresarial japonés las mujeres son apenas el 7 % en los puestos de mando frente al, por ejemplo, 23 % en Estados Unidos. Según un estudio de Goldman Sachs la economía nipona crecería un 15 % si ellas se incorporan al proceso de producción.

Las mujeres japonesas lograron el voto en 1946, pero 70 años después poco han avanzado en el Parlamento. En 2014 tan solo 45 de los 475 escaños estaban ocupados por mujeres. En 2016 seguían infrarrepresentadas con un en la cámara, que sitúa a Japón en el último puesto de la lista de clasificación de los 20 países más ricos del mundo.

En 2016, por primera vez una mujer en la historia fue elegida gobernadora de Tokio, Yuriko Koike. Una década antes, en 2007, Koike fue la primera mujer al frente del Ministerio de Defensa de Japón.

Los japoneses incorporan los rasgos de muchas religiones en sus vidas diarias en un proceso conocido como sincretismo. Las calles japonesas se decoran en las fiestas de Tanabata, Obon, Halloween y Navidad. Una oración popular cuando se tienen problemas es "«Kami-sama, Hotoke-sama, dōka otasuke kudasai.»" («Dios y Buda, ayudadme de alguna forma, por favor»), que parece implicar una creencia sincretista. Muchas personas, sobre todo aquellas pertenecientes a generaciones jóvenes, sienten que las religiones son parte de la cultura tradicional.

El budismo es la religión mayoritaria; el sintoísmo fue religión oficial del país hasta el siglo VII y actualmente es la segunda religión en número de seguidores. Debido a la influencia histórica de China, también hay confucianos, taoístas, etc. 

El cristianismo, aunque su práctica es minoritaria, está presente principalmente en su forma de catolicismo. En el caso de la Iglesia católica en Japón la autoridad máxima pertenece a la Conferencia de los Obispos Católicos del Japón (カトリック中央協議会 (日本語)) instituida en el año 1941, la cual está en plena comunión con el papa y la Santa Sede.

Además de sus religiones, las supersticiones japonesas están bastante extendidas en Japón y son utilizadas para enseñar lecciones prácticas sobre diferentes aspectos de la vida.

La cultura japonesa ha evolucionado de manera considerable en los últimos años, desde el país original de la cultura Jōmon a su cultura contemporánea, que combina las influencias de Asia, Europa y Estados Unidos. Las artes tradicionales incluyen la artesanía (ikebana, origami, ukiyo-e, muñecos, lacas, alfarería), actuaciones (bunraku, Kabuki, Noh, rakugo), tradiciones (ceremonia del té, Budō, la arquitectura, los jardines, las espadas) y cocina.

La fusión entre la impresión tradicional en madera y el arte occidental condujo a la creación del manga, un formato japonés de Historieta popular dentro y fuera de Japón. El manga ha influido la animación para la televisión y el cine dando origen al anime y el llamado live action movie, normalmente filmes o teleseries encarnadas por actores y basados en series de animación populares. Las consolas de videojuegos japonesas han prosperado desde el decenio de 1980.

La música de Japón es ecléctica, después de haber tomado prestados los instrumentos, las escalas y estilos de las culturas vecinas. Instrumentos, como el koto, se introdujeron durante los siglos IX y X. El recitativo acompañado del teatro Nō fechan del siglo XIV y la música folclórica popular, con la guitarra shamisen, desde el XVI. La música occidental, presente desde finales del siglo XIX, ahora forma parte integrante de la cultura japonesa. Después de la Segunda guerra mundial, Japón ha sido influido por la música moderna de estadounidenses y europeos, lo que ha dado lugar al J-Pop.

El karaoke es la actividad cultural más ampliamente practicada. En noviembre de 1993, un estudio realizado por la Agencia de Asuntos Culturales encontró que ese año, eran más los japoneses que habían cantado karaoke, que los que habían participado en manifestaciones culturales tradicionales, tales como arreglos florales o la ceremonia del té.

Las primeras obras de la literatura japonesa incluyen Kojiki y Nihonshoki, dos libros de historia y el Man'yōshū, un libro de poemas del siglo VIII, todos escritos en caracteres chinos. En los primeros días de la era Heian, el sistema de transcripción conocido como kana (Hiragana y Katakana) fue creado como fonogramas. Kaguya es considerada la más antigua descripción en japonés. Makura no Sōshi, una reseña de la vida en la corte de Heian, es un libro escrito por Sei Shōnagon. Del siglo XI data la primera novela japonesa, su autora fue una mujer, Murasaki Shikibu, la obra, "Genji Monogatari" ("Leyenda de Genji"), a menudo ha sido descrita como la primera novela del mundo. La era Meiji, durante el cual la literatura japonesa integró influencias occidentales, vio el declive de las formas literarias tradicionales. La obra que marcó definitivamente el modelo literario de la literatura japonesa moderna fue "Shōsetsu Shinzui" ("La esencia de la novela", 1885) de Tsubouchi Shōyō. Su díscipulo Futabatei Shimei es considerado como el creador de novela japonesa moderna. Otros autores importantes de la misma época fueron Mori Ōgai, Higuchi Ichiyō, Ishikawa Takuboku, Masaoka Shiki y, el que quizá sea el más conocido de este período, Natsume Sōseki. Posteriormente destacaron Akutagawa Ryūnosuke, Tanizaki Jun'ichirō, Yasunari Kawabata, Yukio Mishima y, más recientemente, Haruki Murakami. Cuenta además con dos , los autores Yasunari Kawabata (1968) y Kenzaburo Oe (1994).

 El sushi, uno de los platos más reconocidos de la gastronomía de Japón como cocina nacional ha evolucionado en los siglos a causa de muchos cambios políticos y sociales. En la antigüedad la mayoría de la cocina estaba influenciada por la cultura china. La cocina cambió con el advenimiento de la Edad Media, que marcó el comienzo de un abandono del elitismo con la normativa del shogunato. Al principio de la Edad Moderna ocurrieron grandes cambios que introdujeron en Japón la cultura occidental.

El término moderno «comida japonesa» ("nihon ryōri", 日本料理) o "washoku" (和食, washoku) se refiere a dicha comida al estilo tradicional, similar a la que existía antes del final del aislamiento nacional de 1868. En un sentido más amplio de la palabra, podrían incluirse también alimentos cuyos ingredientes o modos de cocinarlos fueron introducidos, posteriormente, del extranjero, pero han sido desarrollados por japoneses que los han hecho suyos. La comida japonesa es conocida por su énfasis en la estacionalidad de los alimentos (旬, "shun"), calidad y presentación de sus ingredientes.

Hay muchas opiniones sobre qué es fundamental en la cocina japonesa. Muchos piensan que el sushi o las comidas elegantes estilizadas del formal kaiseki se originaron como parte de la ceremonia del té. Muchos japoneses, sin embargo, piensan en la comida cotidiana de la gente japonesa, en especial la que existió antes del final de la Era Meiji (1868-1912) o antes de la Segunda Guerra Mundial. Pocos japoneses urbanos modernos conocen su gastronomía tradicional.

Tradicionalmente, se considera al estilo de lucha sumo como el deporte nacional ya que es uno de los más populares deportes entre los espectadores. Las Artes marciales como el judo, el kendō y el kárate también son ampliamente practicados y gozan de un considerable número de espectadores en el país. Después de la Restauración Meiji, muchos deportes occidentales fueron introducidos y empezaron a propagarse en el sistema educativo.

La Liga Japonesa de Béisbol Profesional fue establecida en 1936 y hoy en día es el Deporte más popular de Japón. Los padres alientan a sus niños a jugar el deporte más amado por los japoneses, además de que los jugadores profesionales son estrellas en su país. Una muestra de lo que significa el Béisbol para los japoneses es que su Selección nacional ha ganado las dos primeras ediciones del Clásico Mundial de Béisbol.
Desde el establecimiento de la Liga de Fútbol Profesional en 1992, la asociación de fútbol también ha adquirido numerosos seguidores. La selección nacional es considerada como la más fuerte de Asia, siendo campeona a nivel continental en cuatro oportunidades. Desde 1998 Japón se ha clasificado de manera consecutiva a todos los Mundiales de fútbol.
Organizó el Mundial 2002 junto con Corea del Sur.

El golf es también popular, al igual que el automovilismo y la Fórmula Nippon. En 1997 se completó por parte de Honda el Twin Ring Motegi con el fin de llevar la IndyCar Series a Japón, además la Fórmula 1 viaja frecuentemente a Japón para el Gran Premio que se celebra en ese país, generalmente en Suzuka, pero también ha pasado por Fuji, también el mundial de motociclismo de la FIM liderado por MotoGP hace su incursión para el Gran Premio del Pacífico en el Twin Ring Motegi, frecuentemente también iba a Suzuka, pero luego de la muerte del piloto japonés Daijiro Kato en 2003 la categoría dejó de participar allí. También destacan otros deportes como el boxeo, lucha libre (puroresu), baloncesto, hockey sobre hielo, entre otros.

La mejor participación de Japón en los Juegos Olímpicos fue en 2012 cuando obtuvo 38 medallas. En los Juegos Olímpicos de Pekín 2008 también tuvo una destacada actuación con nueve oros, seis platas y diez bronces, siendo finalmente octava en el medallero solo por detrás de China, , Rusia, Reino Unido, , Australia y Corea del Sur.

Además, Japón acogió los Juegos Asiáticos de 1958 y de 1994. También acogió los Juegos Olímpicos de 1964 en Tokio. En septiembre de 2013, la capital nipona fue elegida sede de los Juegos Olímpicos de verano del año 2020, derrotando a otras dos ciudades candidatas finalistas, Estambul (ciudad de Turquía) y Madrid (capital de España).






</doc>
<doc id="1576" url="https://es.wikipedia.org/wiki?curid=1576" title="Jet lag">
Jet lag

El jet lag, también conocido como síndrome del cambio rápido de zona horaria, síndrome transoceánico, descompensación horaria, disritmia circadiana o síndrome de los husos horarios, es un desequilibrio producido entre el reloj interno de una persona (que marca los periodos de sueño y vigilia) y el nuevo horario que se establece al viajar a largas distancias, a través de varias regiones horarias o las personas que vivan en países que cambien la hora en verano e invierno.

El reloj interno de la persona tiende a prevalecer, por lo que, al viajar de este a oeste o viceversa, tendrá sueño en pleno día y por las noches mantendrá un estado de vigilia. 

Entre los posibles síntomas provocados por el "jet lag" se encuentran: 


Quienes estén sometidos a tratamientos que requieran la administración de medicación según un horario, deben considerar la necesidad de modificarlos según prescripción facultativa para compensar la disritmia circadiana; así, puede ser necesario modificar la dosis y el momento de administración de insulina según el número de zonas horarias atravesadas, el tiempo de permanencia en cada destino, la alimentación y la actividad, por lo que se debe determinar la glucemia con frecuencia. Los regímenes pueden requerir modificación en función del tiempo ahorrado en lugar del tiempo local.

Hay estudios que sugieren que un ejercicio intenso por la mañana temprano el primer día tras un desfase horario puede acelerar la adaptación al nuevo horario mejor que tratamientos de luz o de melatonina.

Es posible minimizar los efectos del "jet lag" siguiendo los siguientes pasos antes, durante y después del vuelo. 

Los pasajeros deben ser asesorados para llegar descansados, haber practicado ejercicio y seguir una dieta saludable. Cuando la persona está en buena forma, es más fácil que esté en buena forma después de aterrizar.

También se recomienda visitar a un médico para planificar las conductas médicas que requieren monitorización, las que incluyen ingesta de medicamentos o cualquier otro detalle necesario.
Otro consejo es adaptarse a la zona horaria de destino antes. Esto incluye comenzar la rutina diaria una hora antes o después de que uno normalmente lo hace, tres a cuatro semanas antes de la salida.

Para prevenir la deshidratación, los pasajeros deben ser alentados a no ingerir alcohol y cafeína. La cafeína no sólo produce deshidratación sino que también altera los patrones de sueño. Por el contrario, la recomendación es beber mucha agua para ayudar a contrarrestar los efectos de la sequedad del ambiente dentro del avión.
A los pasajeros se les anima a ejercitar sus piernas mientras están sentados y a moverse alrededor del avión cuando el signo de cinturón de seguridad esté apagado, cada hora o dos.
Una opción para contrarrestar el "jet lag" es el viaje en segmentos más pequeños si es demasiado largo y pasar la noche en alguna ciudad. Y, por último, intentar ajustar las horas de sueño en el avión para coincidir con la hora de destino.

Una forma útil de reducir al mínimo el desfase horario es adaptarse a la hora local. Asimismo, la exposición a la luz del sol durante el día es eficaz y útil.




</doc>
<doc id="1578" url="https://es.wikipedia.org/wiki?curid=1578" title="John Ford (director de cine)">
John Ford (director de cine)

John Ford (1 de febrero de 1894-31 de agosto de 1973) —bautizado como John Martin Feeney y que comenzó su carrera cinematográfica con el nombre de Jack Ford— fue un actor, director y productor cinematográfico estadounidense, cuatro veces ganador del Premio de la Academia. Con una carrera profesional de más de 50 años, en la que participó en casi todas las facetas del arte cinematográfico antes de dedicarse a la dirección, Ford dirigió más de 140 películas, muchas de ellas de cine mudo, y está ampliamente considerado uno de los cineastas más importantes e influyentes de su generación. Cineastas como Ingmar Bergman y Orson Welles lo consideraban uno de los grandes directores de cine de todos los tiempos.

Fue también marino y militar. Participó en la Segunda Guerra Mundial como oficial de los servicios cinematográficos de la Armada de los Estados Unidos y fue herido en combate durante la batalla de Midway. Tras el final de la guerra continuó siendo reservista, colaboró en la realización de documentales durante la Guerra de Corea y la de Vietnam y alcanzó el grado de contraalmirante.

El futuro John Ford nació el 1 de febrero de 1894 (aunque muchas veces diría que en 1895) en una granja de Cape Elizabeth (Maine) y fue bautizado con el nombre de John Martin Feeney, hijo de dos emigrantes irlandeses que le transmitieron su natal gaélico y el amor a su Irlanda de origen. Su padre, Sean A. Feeney, era oriundo de Galway, al igual que su madre, Barbara «Abbey» Curran, si bien la familia de ésta procedía de las islas Aran. Fue probablemente su madre quien inspiró la permanente asociación del hogar con la figura de una mujer presente a lo largo de su filmografía. Hay dudas acerca del auténtico nombre del pequeño, pues el irlandés «Sean» parece haber sido sustituido por el equivalente anglosajón «John», que dio lugar a que se le conociera familiarmente como «Jack». En cuanto al apellido, se escribe de diversas formas, como O'Fienne u O'Fearna. Además, el mismo Ford dijo muchas veces que su segundo nombre era Aloysius. Todo ello motivó muchas polémicas entre sus biógrafos.

Fue el menor de once o trece hijos. A los cuatro años, las dificultades económicas que atravesaba la familia le obligaron a desplazarse a Portland (Maine), sustituyendo la granja familiar por un apartamento. Allí llegó a completar sus estudios secundarios sin que mostrara más inquietudes artísticas que una habilidad para la caricatura muy apreciada por sus amistades. Comenzó a trabajar en el departamento de publicidad de una fábrica de zapatos, y parece que intentó en vano entrar en la Academia Naval de Annapolis; en cualquier caso, Ford mostraría años después su amor por la Marina.

Su hermano mayor, Frank O'Feeney, se había desplazado a Hollywood en 1911. Allí, con el nombre artístico de Francis Ford, inició una prometedora carrera en la naciente industria cinematográfica. El joven Jack se uniría a él en 1913, trabajando a sus órdenes en diversos oficios: regidor, doble de acción, atrezzista, asistente de su hermano y actor. Pronto adoptó el apellido artístico de Francis y se hizo llamar Jack Ford, para disgusto de sus padres, a quienes no agradaba esa actividad profesional. Estos años le sirvieron al joven Jack para familiarizarse con el cine desde diversos ángulos y en diferentes géneros. Su hermano fue no sólo la primera influencia, sino quizá la más importante en su forma de hacer cine, lo que siempre provocó cierta envidia en Jack. Fuera de la tutela de su hermano, Ford participó como extra en el rodaje de "El nacimiento de una nación" (1915), lo que le permitió conocer la forma de trabajar de David W. Griffith, director por el que Ford siempre sintió respeto. Estos años junto a su hermano le sirvieron para conocer la industria, pero todavía no tenía conciencia de las posibilidades reales de la labor de dirección cinematográfica.

El paso a la dirección de Ford parece una evolución lógica en su carrera, aunque el azar tuvo mucho que ver en tal tránsito. Se suele considerar que su primera película como director es "The Tornado" (1917), en la que también figura como guionista. Se trataba de un "western" de corta duración y mudo, protagonizado por su hermano Francis, y resulta dudoso si John ya era el director o se limitaba todavía a ayudar a su hermano asumiendo cada vez más responsabilidades. La película, de la que no se conserva copia alguna, debió limitarse a una sucesión de acrobacias hechas por los especialistas, pero supuso el comienzo de una larga y brillante carrera profesional. De los 62 filmes de diverso metraje que Ford rodó durante la época muda, solo se conservan entre quince y veinte (algunos mutilados), lo que dificulta hacer una valoración global de su obra en este período de formación.

Afortunadamente para Ford, las películas del Oeste no gozaban de mucho prestigio entonces y los directores de los estudios Universal eran reacios a dirigirlas. Eso provocó un vacío que su hermano Francis aprovechó recomendándole al estudio. Ford rodaría un total de 37 filmes para Universal en cinco años. De allí nació una relación profesional y de amistad entre John Ford y el actor Harry Carey, quienes rodarían juntos un total de veinticinco películas mudas de apresurada realización y creciente rentabilidad. Carey fue la respuesta de Universal a actores como Tom Mix o "Broncho Billy" y, de la mano de Ford, compuso un héroe alejado de los arquetipos tradicionales. Su personaje habitual recibió el nombre de "Cheyenne Harry" ("Cayena", en ciertas versiones hispanas), aunque no era muy diferente cuando recibía otros nombres. El actor fue la segunda influencia en importancia en el cine de Ford tras su hermano Francis. El éxito en taquilla de Carey permitió subir poco a poco el salario de Ford. Parece que las películas tenían una excelente fotografía y unos escenarios exteriores que resaltaban la trama violenta. Solo se conservan "Straight Shooting" ("A prueba de balas", 1917) y "Hell Bent" ("El cowboy vengador" o "El barranco del diablo", 1918).

En enero de 1920, Ford rueda "The Prince of Avenue A", reseñable por ser su primera película ajena al "western". En el verano de ese año, Ford contrajo matrimonio con Mary France McBride Smith, con quien tendría dos hijos: Patrick (1921), quien llegaría a ser productor y realizador de cine de bajo presupuesto; y Barbara (1922), que trabajaría con el tiempo como montadora. En ese mismo año, su hermano Francis abandona definitivamente la dirección y se centra en el trabajo como actor.

A finales de 1920, Ford filmó "Just Pals" ("Buenos amigos"), su primer trabajo con la productora Fox, con la que mantendría una relación casi en exclusiva hasta 1931 y con la que rodaría más de cincuenta películas a lo largo de su vida. Se trata de un "western" "moderno" ambientado en su propia época y que narra la relación entre un vagabundo y un niño en tono de comedia. Aunque Ford siguió rodando algunas películas con Universal y Carey, la nueva productora le permitió trabajar también con Tom Mix. Por esa época realizó un viaje a Irlanda, donde estableció contacto con el Sinn Féin y con el conflicto anglo-irlandés. Volvió a casa habiendo reforzado sus lazos con la tierra de sus padres.

En 1923, rodó su película de mayor presupuesto hasta entonces: "Cameo Kirby" ("Sota, caballo y rey"), protagonizada por la estrella John Gilbert y coloreada en algunas secuencias. Probablemente la importancia del encargo motivó que por primera vez firmara con su definitivo nombre de John Ford.

En 1924, Ford filmó su mayor producción hasta la fecha, el "western" de tonos épicos "The Iron Horse" ("El caballo de hierro"). La película no estaba concebida inicialmente como una superproducción, pero la Fox no reparó en gastos conforme avanzaba el rodaje, desarrollado durante el primer trimestre del año. La película narra en tono de epopeya la construcción del ferrocarril Transcontinental por las compañías Union Pacific y Central Pacific entre los años 1863 y 1869, trama acompañada de una relación sentimental entre los protagonistas, encarnados por George O'Brien y Madge Bellamy.

El rodaje se desarrolló en difíciles condiciones, pues el numeroso equipo no fue a Nevada preparado para el duro clima propio de la estación. Hubo que improvisar alojamientos adecuados para el numeroso equipo. La productora hizo un importante esfuerzo económico encaminado a potenciar el tono épico. Hubo que construir dos ciudades enteras para las tomas generales. Dado que uno de los ejecutivos de la Fox se había encaprichado con la actriz protagonista, se añadieron posteriormente escenas rodadas sin el concurso de Ford para realzar su papel.

Quizá "El caballo de hierro" no sea la mejor película de la época silente de Ford, pero el director demostró saber hacer frente a las adversidades y dirigir a un numeroso equipo en condiciones difíciles. El resultado fue un éxito de taquilla que permitió que la compañía recuperase con creces su elevada inversión. Ello reforzó la posición de Ford en Fox y en la industria de Hollywood, en general. El tono grandioso de la cinta es compensado con cierta ironía, en la que colaboran los personajes de tres viejos borrachines irlandeses (tipo que se hará habitual en posteriores películas del director).

El éxito de "El caballo de hierro" garantizó a Ford la continuidad como director, y a continuación realizó películas de diversa temática con las que experimentó géneros distintos al "western". Tras la desaparecida "Hearts of Oak", melodrama de ambiente marítimo, Ford rodó "Lightnin"' ("Don Pancho"), comedia sin pretensiones aunque excesivamente larga, cuya acción se desarrolla en el peculiar Hotel Calivada, situado justo sobre el límite fronterizo entre los Estados de California y Nevada. La ubicación dará lugar a diversas situaciones cómicas, en las que destacan el matrimonio que regentea el hotel, personajes que prefiguran otros que poblarán más tarde la obra fordiana (como el Jeeter Lester de "Tobacco Road").

"Kentucky Pride" ("Sangre de pista") permitió a Ford introducirse en el ambiente para él grato de las carreras de caballos. La comedia se inicia desde el punto de vista subjetivo del equino protagonista hasta que pasa a contarnos las historias paralelas de su dueño, un hombre acaudalado que pierde su fortuna y su montura, y el mozo de cuadras, un irlandés interpretado por J. Farrel McDonald y que anticipa futuros personajes de Ford. "The Fighting Heart" ("Corazón intrépido") es un desaparecido melodrama que gira en torno a las consecuencias del alcoholismo, reseñable por suponer la primera aparición de un joven Victor McLaglen en el cine de Ford, del que el actor llegaría a convertirse en un emblema.

The "Shamrock Handicap" ("La hoja de trébol") permite a Ford retomar el tema de la equitación. Narra la historia de un bondadoso aristócrata irlandés arruinado por ser generoso con sus arrendatarios. Ello le obliga a vender su mejor caballo para que compita en los Estados Unidos. Lo que podría haber sido una tragedia, adquiere visos de una optimista historia de superación personal en la que el noble, su hija y su mejor jockey emigrarán a Norteamérica, triunfarán en las carreras y regresarán a la patria victoriosos. Tema muy grato a un emigrante de segunda generación como Ford. También narra una emigración desde Irlanda "Mother Machree" ("¡Madre mía!"), un film con el que la Fox experimentó la sincronización de música e imágenes y cuyo estreno se retrasó dos años. Solo conservada parcialmente, la película es excesivamente sentimental y discursiva y, aunque cercana a la temática habitual de Ford, está lejos en resultado.

"3 Bad Men" ("Tres hombres malos") está considerada por muchos críticos la mejor película del período silente de Ford. Basada en un hecho histórico, la carrera por la disputa de las tierras libres del Territorio de Dakota, podría haber dado lugar a otra superproducción épica como "El caballo de hierro". Sin embargo, aunque la memorable secuencia de la carrera responde a ese planteamiento, el resto de la película se aparta de él. Oscilando con habilidad entre la comedia y el drama, la película presenta a tres bandidos de buen corazón que deciden defender a una joven huérfana y enfrentarse a un malvado "sheriff". Los forajidos, conscientes de que su tiempo ha pasado, se sacrificarán por la muchacha y su novio, al que ellos mismos han ayudado a elegir, en lo que constituye un indudable anticipo del "western" crepuscular.

La película no fue un éxito de taquilla, pese a estar incluida en el género en el que Ford inició su carrera y con el que había conseguido su mayor éxito. Pasarían años hasta que el director volviera a dirigir su mirada hacia el oeste.

Tras la encorsetada "The Blue Eagle" ("El águila azul"), film de ambiente castrense, Ford conocerá su mayor éxito de la era silente gracias al drama bélico "Four Sons" ("Cuatro hijos"). En este caso, público y crítica caminan de la mano al considerarla una gran película. Aunque hoy permanezca casi olvidada, supuso el encumbramiento de Ford a la misma altura de figuras de la época como el mismísimo Griffith. La película trata temas habituales en Ford, como la guerra, la nostalgia de la patria perdida (Baviera en este caso sustituye a la habitual Irlanda) y la emigración como forma de reconstruir la propia vida.

Ford se despediría del cine mudo con tres películas muy diferentes. "The Hangman's House" ("El legado trágico") supone una vuelta a Irlanda desde la perspectiva nacionalista que le caracterizó tras su contacto con el IRA, así como a las carreras de caballos. La película es reseñable por suponer la primera colaboración acreditada de John Wayne a las órdenes de Ford, además de contar de nuevo con Victor McLaglen. "Riley the Cop" ("Policías sin esposas" o "El policía sin esposas"), nuevamente protagonizada por J. Farrell McDonald, es una comedia sin pretensiones relacionada con el "slapstick" en torno a un agente que se vanagloria de no haber efectuado nunca una detención y es enviado en misión al extranjero. "Strong Boy" ("¡Viva la ambición!") estaba también protagonizada por McLaglen y parece haberse perdido. Los dos últimos films fueron estrenados como películas mudas pero con sincronización musical, una técnica utilizada por los estudios en la fase de transición al sonoro.

Ford dirigió más de sesenta películas durante era del cine mudo. Aunque su carrera se hubiera truncado con la llegada del sonido, como ocurrió con grandes creadores como D. W. Griffith, Erich von Stroheim o Buster Keaton, su obra sería digna de consideración en la historia del cine. Pero Ford tenía todavía muchas más cosas que aportar.

"Napoleon's Barber" ("El barbero de Napoleón") constituye la primera toma de contacto de Ford con el cine sonoro. Es una película corta de Fox que trata una anécdota ficticia: camino de Waterloo, Napoleón Bonaparte se detiene en una barbería para ser afeitado; el barbero, que no lo reconoce, se explaya explicando lo que le haría al Emperador si lo tuviera delante... hasta que acaba reconociéndolo. Hoy perdida, la película no parece tener mayor interés que el de la experimentación de Ford con el sonido, discutiendo con los técnicos acerca de los límites de la nueva técnica.

Años después, Ford relató a Peter Bogdanovich cómo las productoras los despidieron a él y otros directores con la llegada del sonoro y los reemplazaron por directores teatrales. Cuando éstos fracasaron en una labor que desconocían por completo, Ford y los demás fueron contratados de nuevo con un aumento de sueldo. Según él, que los actores declamaran su diálogo durante el rodaje no era nuevo, pues ya se hacía durante la época muda por el público que sabía leer los labios. En cualquier caso, Ford fue de los directores que sobrevivieron al desarrollo técnico; y lo hizo gracias a asumir su condición de asalariado que debía obedecer las reglas impuestas por el patrón.

El primer reto serio del director fue "The Black Watch" (conocida como "Shari, la hechicera" o "Shari, la hechicera oriental" en el ámbito hispano). La Fox buscaba un espectáculo de aventuras exóticas de tinte colonialista británico que guardara ciertas similitudes con "Las cuatro plumas", de la que se había rodado una nueva versión ese mismo año 1929. Nuevamente es uno de los actores predilectos de Ford, Victor McLaglen, quien interpreta al oficial protagonista, secundado por Myrna Loy en el rol femenino. La película está lastrada por el deseo de explotar a ultranza las posibilidades del sonido, por lo que abundan las canciones, música militar y alaridos bélicos. Además, los productores contrataron a un director teatral para que rodara nuevas y "postizas" escenas con los protagonistas, en las que la cámara se situaba en plano fijo y los actores declamaban teatralmente, para nuevo disgusto de Ford. Pese a ello, la película tiene algunos apuntes visuales positivos que llevaron al crítico Tag Gallagher a definirla como un "melodrama neowagneriano".

El anterior film cumplió las expectativas económicas, y Ford recibió un nuevo encargo de Fox: "Salute" (conocida en español como "El triunfo de la audacia" o "La audacia triunfa", 1929). Quizá la menor ambición del encargo le hizo pensar que recibiría menos presiones; o quizá fuera la expectativa de rodar en un ambiente agradable (las instalaciones militares de Peaks Island) en compañía de sus amigos Ward Bond y John Wayne lo que le atrajo. El film, protagonizado de nuevo por George O'Brien, narra en tono de comedia la rivalidad existente entre miembros del Ejército y de la Armada de los Estados Unidos (dos instituciones muy gratas al director) que culminará en un partido de fútbol americano.

"Men Without Women" ("Tragedia submarina") supone la primera colaboración del director de Maine con el escritor Dudley Nichols, fructífera unión que se prolongaría durante catorce películas más. El propio Nichols relataría posteriormente la experiencia admitiendo su total ignorancia inicial acerca de cómo se escribía un guion y cómo Ford le enseñó. Pero Nichols sí sabía contar historias y pronto dominó la técnica cinematográfica. El trabajo conjunto de ambos inspiraría algunas de sus mejores películas. Puesto que el guionista había servido en la Marina, propuso un tema naval para su primer film, algo fácilmente aceptado por el director. La cinta relata la tragedia de la atrapada tripulación de un sumergible que se hunde sin remedio y sus desesperados esfuerzos por sobrevivir. El opresivo ambiente es suavizado mediante el habitual uso del humor en pequeñas situaciones colaterales a la trama principal. Ford recordaría más tarde que se trataba de la primera película rodada en un submarino auténtico. Técnicamente sigue siendo una película muda pero con sonido sincronizado, que incluye música (incluso alguna canción), efectos de sonido y algún diálogo.

En "Born Reckless" ("El intrépido"), de nuevo con ayuda de Nichols, Ford asumió el papel contrario al que había sufrido en "El caballo de hierro" o "The Black Watch", pues tuvo que terminar una película encargada a otro director. Puesto que el proyecto no le gustaba, optó por introducir un partido de béisbol como elemento cómico, de forma semejante a como había hecho en "Salute". Algo similar ocurrió con "Up the River" ("Río arriba"), que contaba con un guion carcelario que disgustaba a Ford. Él y el comediante Bill Colliér reescribieron el guion convirtiéndolo en una hilarante comedia de gran éxito en la que los protagonistas entraban y salían del penal constantemente. El resultado es una extraña mezcla de géneros que dio fama a una inusual pareja formada por los casi debutantes Spencer Tracy y Humphrey Bogart, pero la guionista original se sintió muy molesta con Ford.

Más interés tiene "Seas Beneath" ("Mar de fondo"), nueva aventura marítima de la mano de Dudley Nichols y con la colaboración de George O'Brien. En esta ocasión se relata la actuación de la tripulación de un buque "cazasubmarinos" durante la Gran Guerra. Aunque cierta crítica destaca hallazgos expresivos que dotan de gran "fisicidad" a la acción, como la colocación de una cámara en la popa del submarino durante su emersión, Ford quedó molesto por la imposición por parte del estudio de una actriz protagonista a la que él consideraba incapaz.

Mucho menos reseñable es "The Brat" ("La huerfanita"), comedia de la que Ford sólo recordaba años después una enérgica pelea entre dos mujeres.

"Arrowsmith" (estrenada en España como "El doctor Arrowsmith" y en Argentina como "Médico y amante") es una película interesante por varios motivos. En primer lugar, es el primer trabajo de Ford con una productora distinta de Fox Film Corporation tras una larga relación de exclusividad con ésta; la colaboración con el productor Samuel Goldwyn en una obra ambiciosa no fue sencilla para el director. En segundo lugar, constituye la primera aproximación a un tema que luego reaparecería en Ford, la medicina, esta vez a través de la adaptación de una novela de prestigio del reciente Premio Nobel Sinclair Lewis, libro que había sido, a su vez, galardonado con el Premio Pulitzer. Por último, es el primer esfuerzo serio de Ford por describir en profundidad a un personaje complejo.

Aunque la crítica ha considerado posteriormente que es una película fallida en varios aspectos, obtuvo en 1932 cuatro nominaciones a los Premios Óscar de la Academia, entre ellos el de , siendo la primera vez que una obra de Ford llegaba a obtener este tipo de reconocimiento.

La película tuvo consecuencias de otro tipo. Ford incumplió el contrato firmado con Goldwyn que le prohibía beber durante el rodaje, lo que hizo que fuera sancionado por aquel y que, a continuación, Fox diera por concluido el contrato de exclusividad que había disfrutado durante años. A partir de ese momento, aunque Ford siguió colaborando con Fox, quedó en libertad para desarrollar proyectos con otros estudios. Ello significó un importante cambio en la forma de trabajar de un director acostumbrado hasta entonces a estar en nómina de una compañía.

Ford volvió a trabajar con la compañía de sus inicios, Universal, en el rodaje de "Air Mail" ("Hombres sin miedo", 1932). Allí conocerá al capitán de fragata Frank W. "Spig" Weady, condecorado piloto de aviación de la Marina que colaboró como guionista en éste y otros films (entre ellos, "They Were Expendable", de nuevo con Ford), con el que le llegará a unir una estrecha amistad. La película se ambienta en el mundo de los pilotos dedicados al correo aéreo, y su temática se asemeja a la de la gran película posterior de Howard Hawks "Sólo los ángeles tienen alas" ("Only Angels Have Wings", 1939). No obstante, a Ford le falta la vivencia personal que sí tuvo Hawks y que le permitió impregnar la película de verosimilitud, por lo que el film "fordiano" es mucho más frío que el del cineasta-aviador.

"Flesh" ("Carne", 1932) supone la primera colaboración de Ford con la Metro-Goldwyn-Mayer. En este drama, un fuerte Wallace Beery
debe enfrentarse tanto a una banda de "gangsters" como a una temible "mujer fatal". El nombre de Ford no aparece en los títulos de crédito.

Con "Pilgrimage" ("Peregrinos" o "Peregrinación" en sus estrenos hispanos, 1933) Ford volvió a trabajar con Fox Film Corporation. La película está basada en una narración de I.A.R. Wylie, la misma autora del relato que dio lugar a "Cuatro hijos", el mayor éxito de Ford en la época del cine mudo. Nuevamente la historia versa acerca de las relaciones maternofiliales, pero en este caso la madre es una mujer dura que se niega a que su hijo contraiga matrimonio y rompe con él. El hijo morirá en la guerra y la madre sólo se reconciliará con su nuera y nieto tras conocer a otro soldado que ha tenido una experiencia similar a la de su difunto hijo.

En 1933, Ford aceptó el encargo de realizar una película protagonizada por el popularísimo actor Will Rogers. El éxito de "Doctor Bull" propiciará la realización de otras dos películas, "Judge Priest" (1934) y "Steamboat' Round the Bend" (1935), componiendo un ciclo que, por reunir una serie de características propias, se denomina a veces la "trilogía de Will Rogers".

Recobra a Dudley Nichols para "La patrulla perdida" que mete en escena en 1934 la RKO con Victor McLaglen, a quien ofrecería un nuevo gran papel en "Hangman's house". 
Ford detestará siempre su siguiente película "El mundo en marcha" ambientada en los finales del siglo XIX y principios del XX a pesar de que tiene varias escenas de guerra muy realistas.
Más éxito tuvo "Judge Priest" con Dudley Nichols en el guion y el actor Will Rogers que había dirigido el año antes en "Doctor Bull" y que nuevamente dirigiría en 1935 en la película "Steamboat round the bend", justo antes de que éste muriera en un trágico accidente de avión. Esta película es una de las preferidas del director. Se hizo un remake en 1952 titulado "El Sol brilla para todo el Mundo".

En 1934, Ford comenzó a participar económicamente en sus películas. Se compró un yate al que bautizó "L'Araner" en homenaje a Irlanda que tendría hasta 1970. Rodaría dos películas más y empezaría a tener problemas por la presión de Hollywood. Continuó su amistad con John Wayne, que trabajó con él como figurante en sus primeras películas, en "El delator".

En 1935 fundó, con King Vidor, Lewis Milestone, William A. Wellman, Frank Borzage y Gregory La Cava la Asociación de Directores, reemplazando así la Asociación de Directores de Películas. "El delator", realizada muy rápido para la RKO le permitió abordar el tema de la Irlanda británica. No son un misterio su simpatía hacia el IRA. En esta película se descubre al Ford de los decorados interiores, está lejos de sus grandes producciones y decorados clásicos del oeste.
Con este trabajo, inspirado en el cine expresionista recibe su primer que iría a parar a la Asociación de directores fundada anteriormente.

En 1935, 20th Century Pictures absorbió a la Fox, y pasó a denominarse 20th Century Fox, de Darryl F. Zanuck. Realizó junto a su nuevo productor, un gran admirador de Abraham Lincoln, "Prisionero del odio". Los problemas entre Ford y Zanuck comenzaron por el enfrentamiento a causa del acento sureño de Warner Baxter. Ford estuvo a punto de dejar la 20th Century Fox, pero finalmente accedió a los deseos de Zanuck. Desde entonces mantuvieron una estrecha amistad y admiración.

Dirigió a Katharine Hepburn en "María Estuardo" ("Mary of Scotland") para la RKO en 1936. Dirigió también en 1937 "Huracán sobre la Isla" producida por Samuel Goldwyn.

En 1937 se alistó en el Comité cinematográfico de Ayuda a la República Española para ayudar a los republicanos combatientes en la Guerra Civil Española (1936-1939). Se encargó personalmente de enviar una ambulancia con las Brigadas Internacionales.
Fue muy activo también en la lucha contra el nazismo. En 1938 defendió el bloqueo a la Alemania nazi y es nombrado miembro de la Liga Hollywoodiense Anti-Nazi. La firma del pacto germano-soviético le valió la crítica de los comunistas que le acusaron de "propaganda de guerra".

Con "La diligencia", Ford regresó al "western". En esta película cuenta con John Wayne que recibe la oportunidad de su vida y se convertirá en una gran estrella. Los exteriores se rodaron en Monument Valley.
La película fue nominada a ocho Óscar, de los que consiguió el de actor secundario con Thomas Mitchell y el de banda sonora, y Ford recibió el Premio de la Crítica Cinematográfica Neoyorquina.
"La diligencia" se considera como la mejor película del Oeste de todos los tiempos.

Después y junto a Zanuck retomó su pasión por Lincoln y rodaron juntos "El joven Lincoln" con Henry Fonda, que será el protagonista de sus dos películas siguientes: "The Grapes of Wrath" ("Las viñas de la ira", "Viñas de ira" o "Las uvas de la ira") (colaboración número doce con el guionista Nunnally Johnson) y "Corazones indomables".
En 1941 ganó nuevamente el por Las Uvas de la Ira. Su talento por fin es reconocido por los profesionales y la crítica.

Volvió a trabajar con John Wayne en "The Long Voyage Home". La última película de Ford antes de la guerra ("Qué verde era mi valle") fue todo un éxito de público y crítica. Recibió cinco Óscar, entre ellos el de mejor película y mejor dirección (arrebatándoselo a "Citizen Kane" de Orson Welles).

En 1939 Ford tuvo la intuición de que América no tardaría en entrar en la Segunda Guerra Mundial. Se puso a la cabeza de un grupo de cineastas que pidieron a Franklin Roosevelt el boicot a la Alemania nazi y fundó un grupo de gente de Hollywood al servicio de la Armada Americana, llamado Naval Field Photographic Unit. Tras el ataque japonés a Pearl Harbor el 7 de diciembre de 1941, se fundaron otros dos grupos similares.

Durante la guerra, Ford y su equipo recorrieron los teatros de operaciones militares. A principios de 1942 fueron al frente del Pacífico y realizaron para la Marina los documentales "7 de diciembre" (sobre el ataque a Pearl Harbor) y "La batalla de Midway" (una batalla decisiva a partir de la cual Estados Unidos empezó poco a poco a ganar la guerra). Las imágenes del ataque japonés a la isla de Midway fueron rodadas por el mismo Ford. Los dos reportajes le valieron un . Realizó también una pequeña película para las familias de las víctimas de Midway llamada "Escuadrón Torpedo". En 1942 se trasladó al norte de África para cubrir el desembarco. Durante 1943 cubrió múltiples operaciones exteriores así como las victorias de los aliados en "Victoria en Birmania" ("Victory in Burma"). Cubre también en 1944 el desembarco de Normandía. Sigue también al ejército durante la preparación del Proceso de Nuremberg.

De febrero a junio de 1945 rodó "They were expendable" para la Metro-Goldwyn-Mayer, con John Wayne, Robert Montgomery y Donna Reed. Esta es, junto con Hombres Intrépidos (1940) la única película de Ford sobre la Segunda Guerra Mundial, en la que tan activamente participó. El dinero recaudado por esta película fue destinado para los veteranos de la Field Photo Unit y la Field Photo Farm.

Después de la guerra regresó a Hollywood y a rodó otra vez en Monumental Valley: "Pasión de los fuertes". En "El fugitivo" (1947) trabajó de nuevo con Henry Fonda, a quien permitía interpretar con total libertad.

La dirigió en 1952, de nuevo en compañía de su actor predilecto, John Wayne. La película trata sobre un boxeador norteamericano, Sean Thorton (interpretado por Wayne), que regresa a su Irlanda natal para recuperar su granja y escapar de su pasado. Allí se enamora de una alegre chica, aunque para conseguirla deberá luchar contra las costumbres locales, incluidos el pago de una dote y la oposición del temperamental hermano de su prometida.

La película obtuvo siete nominaciones a los Óscar, incluyendo mejor película, y fue galardonada por dos. Una de las estatuillas fue a manos de Ford y la otra a los directores de fotografía Winton C. Hoch y Archie Stout. Está considerada como una de las mejores películas de la historia del cine.



En la película de 2019, Midway (película de 2019), fue interpretando por el actor Geoffrey Blake.




</doc>
<doc id="1579" url="https://es.wikipedia.org/wiki?curid=1579" title="Jalisco">
Jalisco

Jalisco , oficialmente llamado Estado Libre y Soberano de Jalisco, es uno de los treinta y un estados que, junto con la Ciudad de México, forman México. Su capital y ciudad más poblada es Guadalajara. Está ubicado en la región oeste del país, limitando al norte con Nayarit, Zacatecas y Aguascalientes, al noreste con San Luis Potosí, al este con Guanajuato, al sur con Michoacán y Colima, y al oeste con el océano Pacífico. Con 8,783,830 habs. en 2018 es el tercer estado más poblado— por detrás del Estado de México y Veracruz— y con 78,599 km², el séptimo más extenso, por detrás de Chihuahua, Sonora, Coahuila, Durango, Oaxaca y Tamaulipas. Fue fundado el 16 de junio de 1823.

Fue parte de la Provincia de Nueva Galicia, actual Aguascalientes y Jalisco, y de la Intendencia de Guadalajara en el Reino de Nueva Galicia por casi 300 años.

Forma parte de la Alianza Bajío-Occidente y de la macrorregión Centro Occidente de México. Muchas de las tradiciones consideradas mundialmente por ser "característicamente mexicanas" tienen su origen en Jalisco, como los mariachis, el tequila y los jaripeos. 

El clima en el estado va de cálido subhúmedo a semiseco templado, destacando el semicálido subhúmedo con lluvias en verano. Junto con toda la región bajío, es de los estados con mayor desarrollo y crecimiento económico, comercial y cultural. 

Se divide en 125 municipios. La Zona Metropolitana de Guadalajara tiene una población total de más de 5 millones de habitantes, compuesta por los municipios de Guadalajara, Zapopan, Tlaquepaque, Tonalá, Tlajomulco, El Salto, Ixtlahuacán de los Membrillos, Zapotlanejo y Juanacatlán, haciendo de esta la segunda aglomeración urbana más grande de México, después de la capital. Otras ciudades importantes son Puerto Vallarta, San Juan de los Lagos, Tepatitlán de Morelos, Lagos de Moreno, Ameca, Ocotlán, La Barca, Atotonilco el Alto, Arandas, Cocula, Autlán de Navarro, Tala y Ciudad Guzmán.

El nombre de Jalisco proviene de la mezcla de tres palabras de origen náhuatl: "xal-", que significa arena, "īx-", cara o superficie, y la designa de lugar "-co": "En la superficie de arena" o "En el arenal". Durante varios siglos y hasta 1836, Jalisco se escribió "Xalisco", con X inicial debido a que era la letra utilizada para reproducir el sonido correspondiente a la "J", hasta que esta última letra se incorporó al alfabeto latino. Además, en náhuatl, la letra X reflejaba el fonema ʃ en AFI, o bien el fonema "sh" en inglés.

En la región ha existido presencia humana desde hace 15,000 años aproximadamente según lo indican restos humanos, entre ellos fragmentos de cráneos, y diversidad de vestigios de animales, junto con otros testimonios de objetos manufacturados, descubiertos alrededor de las lagunas de Zacoalco y Chapala, que entonces estaban unidas entre sí. Se han podido localizar puntas de flecha, raspadores de cuerno de venado, agujas, punzones, silbatos, anzuelos y colgantes de hueso o colmillos, percutores de hueso de caballo, e incluso una vértebra de ballena con dos golpes producidos por el filo de un instrumento tosco, que fue localizada a fines del siglo XIX en Zacoalco de Torres.

En 618 d. C. se funda el Reino de Jalisco por los toltecas. Su origen y desarrollo se ubica en el horizonte clásico y en el posclásico. Por lo que se conoce actualmente, el señorío de Jalisco fue uno de los más importantes en la región, con relaciones comerciales que se extendieron hacia los pueblos del centro de Mesoamérica con los que realizaban intercambios de productos agrícolas, así como de artículos necesarios en la vida diaria y de ornato.

El señorío de Jalisco comprendió poblaciones localizadas en el occidente hacia la Bahía de Banderas. En esta región se han localizado importantes restos arqueológicos que demuestran el nivel alcanzado. Entre sus poblaciones principales estaban Tepique, Atemba, Pochotitán, Tecuitazco, Xalcocotán, Zacualpán, Xaltemba, Mazatán. El centro de este señorío se localizaba en las faldas del cerro del Coatepec, elevación que alcanza los 1.560 metros de altitud sobre el nivel mar y que domina todo el valle de Matatipac, en el actual municipio de Xalisco.

Aún, con ello, también existieron más señoríos en tierras jaliscienses a las que se suman los sayultecas, los tecuexes que tenían habitados las zonas de Xallostotitlán, Tzapotlán, Tecpatitlán, Tecomatlán, Ayahualicán, Teocaltitlán, Mexticacán, Acatic y Tonallan que estaban en constantes enfrentamientos con sus vecinos como el señorío de Teocaltiche, poblados por huachichiles y caxcanes. Mientras tanto, también destacaron los señoríos de Colima y Autlán en el sur del estado; así como la Tradición Teuchitlán en tierras de Ameca, Tequila, Etzatlán y Teuchitlán donde se ubican las pirámides circulares de Guachimontones. Y en el centro del estado en las tierras de Guadalajara y Tonalá existieron los Cocas, una tribu muy relacionada con los tecuexes tepatitlenses y que a medida que se realizaron cambios comerciales con estos pobladores, surge el gentilicio de "tapatío" para los habitantes de Guadalajara, que ese nombre era dado al trueque que los habitantes precolombinos de Tepatitlán daban a los cocas. Todas estas tribus menores pero igualmente resaltantes, fueron influenciadas por toltecas, chichimecas, estilo mezcala, estilo chupicuaro, estilo Nayarit y Estilo Tumbas de Tiro.

Tras la conquista de Tenochtitlán por parte de los españoles, el resto del territorio nacional y parte de lo que hoy son los Estados Unidos de América pasaron a formar parte del Imperio Español. Debido a la baja densidad de población, el territorio de la Nueva Galicia no ocasionó problemas para ser conquistado; sin embargo, en Michoacán, los españoles tuvieron que enfrentarse a los indígenas que ofrecieron fuerte resistencia al invasor.

Una vez sometidos los tarascos, en lo que hoy es el estado de Michoacán, dos razones primordiales hicieron que los españoles siguieran incursionando en dirección al poniente. Por un lado, la búsqueda de un puerto adecuado para establecer un astillero y zarpar de ahí en busca de las costas asiáticas; por otro, localizar los yacimientos que habían abastecido a los tarascos de metales preciosos.

Así, a fines de 1522, Cristóbal de Olid penetró por la sierra de Mazamitla hasta llegar a lo que hoy es Tamazula. Pronto regresó a Tzintzuntzan, la antigua capital purépecha que servía de base de operaciones, dejando a un primo de Hernán Cortés, llamado Hernando de Saavedra, a cargo de las minas del área explorada.

Por instrucciones de Hernando, Gonzalo de Sandoval fundó una villa de españoles entre Tecomán y el mar, a la que le dio el nombre de Colima el 25 de julio de 1523, con lo que se estableció otra plataforma para dominar la región. Como consecuencia, durante el mes de agosto de 1524, Cortés dispuso que otro pariente suyo, Francisco Cortés de San Buenaventura, fuese su lugarteniente en la Villa de Colima y sus comarcas, que repartiera tierras e indios y realizara expediciones hacia el norte para conocer la costa y buscar metales preciosos.

Los pueblos por los que pasaron y los recibieron en paz fueron convertidos en encomiendas de los españoles, sometiendo a los que se opusieron. De esta manera, desde Colima hasta La Barca, además de ruinas, también se fueron asentando algunos expedicionarios que servirían tanto para facilitar el regreso por el mismo camino que siguió de ida, como para asegurar la potestad de Hernán Cortés en toda el área.

A fines de diciembre de 1529, partió Nuño de Guzmán de la Tenochtitlán comandando a 300 españoles, además de siete u ocho mil indios bien provistos de bastimento y a cargo del transporte de 12 piezas de artillería ligera. De paso por Tzintzuntzan trató de obtener todo el oro que pudiera haber quedado en poder de los tarascos, haciendo incluso que su Caltzontzín fuese muerto después de grandes torturas. Sin embargo, los conquistadores se encontraban lejos de consumar la dominación por completo, ya que mientras algunos grupos de aborígenes se remontaron y asentaron en sitios muy poco accesibles de la Sierra Madre, otros causarían aún más problemática antes de someterse por completo al orden colonial.

Vuelto a la vertiente del Pacífico, después de su malhadada incursión por Durango, el contingente de Guzmán tuvo de permanecer varios meses en Culiacán: debió dejar que pasara la época de lluvias para que bajaran los ríos y consolidar el dominio en la comarca. Para esto último convenía fundar una villa de españoles, fundada el día 29 de septiembre de 1531, con un grupo de españoles y con indios que no serían necesarios para el retorno, mismo que habría de iniciarse el 15 de octubre siguiente.

Después de disponer la fundación de Chiametla para que sirviera de apoyo a la comunicación con el norte, Nuño de Guzmán comandó que se adelantara hasta ahí Cristóbal de Oñate para prevenir su arribo. Ante el vacío que encontró en Tepic, Oñate siguió hasta Ahuacatlán, donde supo que un enviado de la Audiencia, Luis de Castilla, se encontraba con instrucciones de fundar un poblado español por el rumbo de Xalisco para acrecentar el territorio español.

La Corona pensó reproducir en lo posible el mapa peninsular en América, de manera que el noroeste de lo conquistado hasta entonces se llamó igual que el noroeste ibérico, y Nuño procuraba de nuevo conectar Nueva Galicia con la Provincia del Pánuco asentando españoles cerca de Nochistlán.

Vuelto a Nueva España desde principios de 1530, Hernán Cortés esperó a que fuesen cambiados los funcionarios de la Real Audiencia de México para reclamar el gobierno de Tamazula y Amula; pero, además, contraatacó solicitando también Ahuacatlán y Xalisco, argumentando que su enviado Francisco Cortés de San Buenaventura había sido el primero en ocuparlas.

Las cinco villas fundadas por iniciativa de Nuño de Guzmán, San Miguel, Chiametla, Compostela, Purificación y Guadalajara, dieron lugar a la primera división administrativa del territorio. Sin embargo, el número de ellas era demasiado pequeño para imponer el modo de vida a que aspiraban los españoles, y su inestabilidad inicial una muestra de que los lugares elegidos con criterio de conquistador no resultaron ser los más convenientes para la colonización. En efecto, al cabo de una década ninguna villa permanecía en el mismo sitio.

Cuando a principios de 1533 Nuño iba rumbo al Pánuco, visitó el solar donde esta villa se encontraba y comprendió que era demasiado grande el esfuerzo requerido para vivir ahí a cambio de las magras ventajas. En consecuencia, accedió a la petición de buscar otra sede, pero sin que los colonos cruzaran la barranca hacia el sur, a efecto de mantener su presencia en la caxcana. Sin embargo, los moradores no acataron este requisito y, cuando Guzmán volvió a mediados de 1534, se los encontró instalados en el valle de Tonalá, más fértil y poblado que cualquier lugar de toda la caxcana; con la ventaja adicional de que eran una mano de obra más apta por tratarse de indígenas sedentarios.

La presencia de una población hispana en estos lugares no era solo del interés de Guzmán, como lo muestra el hecho de que, para mejorar la situación jurídica de Guadalajara, en 1539 el Rey atendió la solicitud del cabildo de la villa y le concedió las prerrogativas de ciudad y un flamante escudo de armas. De tal modo los aborígenes de Nueva Galicia pasaron a su nuevo estado llenos de virulencia y, por lo mismo, propensos a insubordinarse.

Poco a poco algunos de estos grupos aislados irían adquiriendo mayor coherencia, de manera que, en 1538, empezaron a surgir síntomas de una incipiente revuelta, llamada Rebelión de los Caxcanes, pues se dio en la región que se conoce como Caxcanes, en Jalisco y Zacatecas; a la larga, acarrearía serias mortificaciones a los españoles y provocaría cambios sustanciales en el mapa político de Nueva Galicia.

Los dos principales jefes indígenas rebeldes que se recuerdan son Coaxícar, en la zona de Hostotipaquillo, y Tenamaxtli, vencedores de Pedro de Alvarado, en Nochistlán, Zacatecas. Este murió a causa de una herida en la Guerra del Mixtón.
A esta rebelión también se le conoce como la Guerra del Mixtón, porque así se llama el monte en donde se dio la batalla más importante; el virrey Antonio de Mendoza aniquiló la resistencia en el Mixtón, en octubre de 1541.

Fue al mediar 1540 cuando Oñate comprendió que no bastaban los recursos neogallegos para hacer frente a la situación y pidió ayuda a Mendoza. Este le mandó algunos refuerzos directamente a Guadalajara y ordenó a Pedro de Alvarado que acudiese perentoriamente en defensa de sus paisanos en peligro. Finalmente el Virrey logró ponerse al frente de uno de los mayores ejércitos que se vieran en acción durante toda la época colonial para acudir a pacificar Nueva Galicia. Se dice que sobrepasaba los 50 mil individuos, mismos que el 29 de septiembre emprendieron el camino de Guadalajara a toda la velocidad que le era posible a un contingente de tal magnitud.

Nueva Galicia había sido "pacificada" "a fuego y sangre", "de seis partes de indios murieron cinco", lo cual significa, simple y llanamente, que había sido asolada por el ejército de Mendoza, pero no que se hubiera instaurado la paz completa. Su debilidad, que le impidiera defenderse por sí sola de la revuelta, se había incrementado. Ahora, a causa de ella, quedaba bajo la autoridad militar del virrey de la Nueva España y este cargaría a su vez la responsabilidad de protegerla, estableciéndose un lazo de dependencia respecto de la ciudad de México que persistiría durante toda la época colonial.

Las noticias sobre la sangrienta Guerra del Mixtón no solo corrieron por toda la Nueva España, sino también llamaron la atención de las autoridades peninsulares, quienes decidieron, en 1544, que uno de los oidores de la Audiencia de México, se presentase en Nueva Galicia, ordenase su gobierno en forma provisional y rindiese un informe de la situación. En cuanto al obispo, proponía que fuese alguien del clero regular para que fomentara la evangelización y, en cuanto a la Audiencia, que tuviera injerencia también sobre las comarcas de Zacatula y Colima, y que, para evitar abusos, se diluyese su autoridad entre cuatro oidores. Constancia de que el Consejo de Indias tomó en cuenta lo dicho por el oidor es que no pasó mucho tiempo sin que se llevara a cabo lo que solicitó.

La mayoría de las encomiendas neogallegas fueron concedidas por Nuño de Guzmán a sus seguidores, a más de otras que fueron dispuestas por Antonio de Mendoza en manos de aquellos acompañantes suyos que buscaron radicar en las tierras "pacificadas" y habían hecho méritos suficientes durante la campaña.

Es evidente que durante el virreinato, se representó para los naturales una calamidad mayor que la misma guerra para sojuzgarlos. Trabajos excesivos, escasa alimentación, castigos, epidemias, etc., fueron las causas directas del mayor descalabro demográfico de la historia de México. Se calcula aproximadamente una reducción de un 91% entre 1550 y 1650.

Finalmente, había sido en 1560 cuando Guadalajara se convirtió en capital de la Nueva Galicia. Tanto el presidente Morones como el nuevo obispo, Pedro de Ayala, apoyaron la pretensión guadalajareña y el 10 de mayo del año referido se despachó la cédula que concedió el cambio de residencia. Morones hizo su entrada el 10 de diciembre, pero el franciscano Ayala no tuvo que movilizarse ya que estaba residiendo desde hacía doce meses en el convento que su Orden tenía establecido en Guadalajara.

Los habitantes del occidente neogallego, donde la minería no es una actividad económicamente importante, no podían permanecer impávidos ante la evidencia de que los mayores recursos emigraban sin dejarles provecho, pero no pudieron lograr más, en tanto que el Virrey pretendió incluso pasar la capital de Nueva Galicia a Zacatecas, a lo que sí se negó la Corona española. Pero lo que sí se hizo, en 1571, fue establecer una Caja Real en Zacatecas con todas las de la ley y por completo independiente de la Caja tapatia.

Entre las dificultades más graves enfrentadas por los españoles en su afán de armar una nueva sociedad en el territorio sometido, figuró el problema de la comunicación; en primer término, porque el vencedor aún no acertaba a implantar su idioma; en segundo, porque en la tierra se hablaban diferentes lenguajes, propiciando que hasta el trato entre los mismos nativos fuera incierto.

De tal manera, a pesar de las disposiciones oficiales y de los esfuerzos del clero secular en favor de la castellanización, Nueva Galicia vivió durante el siglo XVI un proceso de nahuatlización, tanto de indios con otras lenguas como de los pocos habitantes españoles, tras el cual sobrevendría el mestizaje de usos y costumbres.

La vida de los neogallegos adinerados, como en el resto de la América española, giraba en torno de sus domicilios. En ellos se nacía y moría; se conmemoraban las festividades privadas y algunas comunes; se divertían y atendían negocios, y sobre todo, se jugaba a los naipes de muy diferentes maneras.

De no ser para acudir al templo o a los eventos públicos, aquella oligarquía salía a las calles solo para lo imprescindible. Raras veces se movían a pie; casi siempre recurrían al caballo o al coche, aunque el tramo por recorrer fuese corto. El medio de locomoción estaba tan ligado al estatus que difícilmente se prescindía de él.

De las casas de españoles solo salían de vez en cuando a la vía pública, sirvientes y empleados de bajo nivel. Las plazas, con abrevaderos al centro, cumplían más bien una función comercial. En sus contornos se instalaban los vendedores que ponían sus comercios por la mañana y los retiraban por la tarde a fin de guardar la mercancía en los almacenes que cada quien poseía en su casa.

Tres cosas llamaban sobremanera la atención al recién llegado de Europa hacia 1621: una era la propensión a bañarse en los numerosos manantiales, por simple gusto o para curarse llagas y dolores; la segunda consistía en el consumo generalizado de chocolate y la última venía a ser el uso del tabaco (mascado o fumado) reiteradamente.

Una de las obras importantes referentes a la historia novogalaica es la "Crónica Miscelánea de la Sancta Provincia de Xalisco", escrita por fray Antonio Tello (1567-1653) y publicada en seis tomos.

Los pudientes gustaban de vivir en el centro; de modo que entre más hacia las afueras habitaba una familia, era, sin duda, más pobre. Hasta fines del siglo XVII, no se sabe de una sola casa particular que haya sido toda de cantera. En realidad, ni los edificios públicos lo eran, excepto la catedral y la iglesia de San Francisco.

De acuerdo con el nivel alcanzado por la educación y la arquitectura neogallegas en el siglo XVII, casi nada puede decirse del desarrollo de las letras y de las artes. Tonalá, por caso, uno de los lugares más poblados cuando los españoles llegaron, mantuvo una destreza alfarera que adquiriría gran renombre gracias al consumo que los habitantes de Guadalajara realizaban de sus productos y a las adquisiciones para enviar a México e, inclusive, a España.

En el campo de las letras, el panorama se vio más retrógrado, debido al hecho de que Guadalajara no dispuso de una imprenta hasta el año 1793.

De tal modo, si no lograban los escritores que sus trabajos se imprimieran fuera de Nueva Galicia, solo podían aspirar a que se hicieran unas cuantas copias de sus originales y circulasen de mano en mano entre un raquítico grupo de lectores. De cualquier forma, algunos pocos acertaron a ver sus textos en letras de molde.

Bajo tales condiciones, pronto se sintieron los primeros efectos de un incremento de los recursos humanos y económicos que se manifestaría, entre otras cosas, en un acelerado desarrollo de Guadalajara y demás poblaciones importantes de la Provincia de Nueva Galicia.

A comienzos del siglo XVIII, franceses e ingleses daban ya claras muestras de estar interesados en participar también de la colonización en América. Pronto se sumaron los rusos, aumentando la preocupación de las autoridades españolas que vislumbraban una competencia y un peligro para sus dominios más septentrionales, además del riesgo de perder las probables riquezas de las tierras aún no colonizadas. De cualquier modo, la colonización de las tierras aún ajenas a la conquista española ocupó un importante sitio en la historia de Nueva Galicia, sobre todo porque dio lugar a una mayor trascendente metamorfosis económica, política y demográfica experimentada por la región. Guadalajara, por lo tanto, pasó a ser el punto de concentración para una larga serie de intereses de toda índole, principalmente económicos. En 1767, la situación cambiaría súbitamente donde imperaban las misiones de los jesuitas. Carlos III, molesto por su resistencia al poder real más las numerosas acusaciones de que era objeto la Compañía de Jesús, se dispuso a proscribirla y expulsar a todos sus miembros de los dominios españoles.

En Guadalajara el trámite se desarrolló sin mayores contratiempos. La madrugada del 25 de junio, por órdenes del Gobernador, se aprehendió a los 12 jesuitas que había en la ciudad y al día siguiente se les envió a Veracruz, donde fueron embarcados con rumbo a Italia. Después siguieron los jesuitas de lo que hoy son los estados de Nayarit, Sonora, Sinaloa y California.

Los jesuitas fueron sin embargo reemplazados por los franciscanos. Tras el descenso de habitantes sufrido por casi todo el Virreinato hasta mediados del siglo XVII, a causa de las continuas guerras con los indígenas, Nueva Galicia inició un considerable crecimiento que se acentuó a partir de 1720, y más aún después de 1760.

Alrededor de 1713, la población de Guadalajara llegaba a unos siete mil habitantes, en tanto que para 1738 se estimaba en alrededor de 12.000 habitantes, 20.000 a mediados de siglo y casi 35.000 al comenzar el siglo XIX. Guadalajara se transformó rápidamente en un centro de comercio privilegiado. Las alcaldías mayores y los corregimientos pasaron a denominarse "partidos", permaneciendo sujetos a su respectiva intendencia mediante subdelegados impuestos por el propio intendente. Se pensaba acabar con el antiguo contubernio de comerciantes y alcaldes, así como imponer orden en el manejo oficial y, sobre todo, en evitar la evasión de impuestos. La Caja Real de Guadalajara engrosó beneficios, aumentando, por ejemplo, al doble sus ingresos entre 1770 y 1800.

Con un total de 26 partidos políticos, inició en su comando la Intendencia de Guadalajara, pero no tardaron en suscitarse algunos cambios importantes. Después de 1803, Juchipila y Aguascalientes se unieron a Zacatecas; Colima pasó a Guadalajara, y desapareció por completo el gobierno de las fronteras de San Luis de Colotlán, cuyo territorio se adhirió al partido de Bolaños, aunque el subdelegado fijó su residencia en Colotlán. Finalmente, Compostela y el departamento naval de San Blas se convirtieron también en partido de la Intendencia de Guadalajara.

Para dar lugar a la independencia debieron enfrentarse criollos contra peninsulares, formando bandos opuestos perfectamente definidos. A este supuesto se contrapone el hecho ya establecido de cómo muchos de los españoles peninsulares estaban, de por sí, más al servicio de los núcleos criollos privilegiados que al del mismo Rey; ello sin considerar que el criollaje no favorecido, al margen de las familias prominentes, recelaba de ambos grupos, y que más de algún miembro de estas esferas encumbradas aún no digería ni olvidaba su profundo resentimiento por haber sido desplazado por unos y relegado por otros. Con la implantación de las intendencias a partir de 1786, se agravó todavía más la repulsa criolla hacia los empleados públicos "gachupines".

La noticia de que Carlos IV había abdicado a favor de su hijo Fernando se conoció en Guadalajara en julio de 1808, y sus autoridades se aprestaron a organizar la jura del nuevo Rey, tal como se había hecho veinte años atrás con Carlos IV. Sin embargo, el reporte luego informó de 16 de julio de la presionada decisión de Fernando VII de abdicar en favor de su padre y este en favor de Napoleón Bonaparte. Esta maniobra, conocida como las Abdicaciones de Bayona por los españoles, desató una vertiente oposición de casi todos los americanos. En España y sus colonias se sostenía la Doctrina Suareciana del Poder, cobrando auge la idea de que el pueblo era la fuente originaria del poder y que el Rey no podía disponer de él sin su anuencia. Por eso José I, hermano de Napoleón, era considerado como el rey ilegítimo. En España se desató una serie de oposiciones que involucraban el movimiento juntista y la guerra de la independencia española ante Francia.

Así pues, en el caso particular de México, y ante los hechos que agitaban a la Península, correspondía a los componentes de los ayuntamientos decidir qué se haría. Durante los días sucesivos se presentaron ante el Presidente personas de todas las órdenes ofreciéndose en defensa de "Religión, Rey y Patria". Incluso llegaron enviados de las comunidades indígenas a la capital de Nueva Galicia, para ofrendarse también en aras de Fernando VII.

En abril de 1809, las autoridades de la Intendencia juraron obedecer a la Suprema Junta Central Gubernativa de España e Indias, tal y como se había hecho en la Ciudad de México, en tanto que elegían al obispo Cabañas como su delegado en la Suprema Junta. Pero como el suelo hispano, durante el primer semestre de 1809, resultó atacado por la fuerza invasora, y las perspectivas del triunfo español parecían muy remotas, Cabañas no se movió de Guadalajara. Por otro lado, del sur de América empezaron a llegar noticias revolucionarias: ciudades como Caracas, Buenos Aires y Bogotá habían decidido prescindir del gobierno español y aspiraban a tomar la dirección de sus respectivas provincias.

Guadalajara tuvo noticia de la insurrección encabezada por Miguel Hidalgo en Dolores el 25 de septiembre de 1810. El canónigo José Simeón de Uría, recién electo diputado a las Cortes españolas por la Intendencia de Guadalajara, desde las proximidades de Querétaro envió la voz de alerta a las autoridades neogallegas. Para fines de septiembre, el grito de Dolores resonaba en la Nueva Galicia; dos pequeños grupos sublevados hacían acto de presencia: uno, acaudillado por Navarro, Portugal y Toribio Huidrobo, se desplazaría entre Jalostotitlán, Arandas, Atotonilco y La Barca; otro, guiado por José Antonio "El Amo" Torres, recorrería Sahuayo, Tizapán el Alto, Atoyac y Zacoalco.

El 28 de noviembre, los insurgentes de Mercado se emplazaron frente al puerto requiriendo su rendición, lo cual ocurrió tres días después, no obstante que había elementos suficientes para la defensa. Al apoderarse Torres de Guadalajara, de inmediato informó a Hidalgo y a Allende de sus logros y los invitó a tomar posesión de la recién sometida ciudad. Hidalgo recibió la oferta en Valladolid (hoy Morelia) y, sin tardanza, se trasladó a la sede neogallega al frente de casi siete mil jinetes. El 25 de noviembre acudieron a Tlaquepaque las diversas corporaciones civiles y eclesiásticas de la ciudad para recibirlo y escoltarlo durante su entrada. El 29 de noviembre expidió un primer decreto de abolición de la esclavitud dirigido a toda la Nación, pero una semana más tarde, el 6 de diciembre, emitió otro, más conciso, donde su firma se acompañaba por la de Ignacio López Rayón, en calidad de secretario.

A fin de sofocar la rebelión, avanzaron rumbo a Guadalajara los brigadieres Félix María Calleja y José de la Cruz. Hidalgo, al enterarse de ello, salió a encontrarlos al frente de su "ejército", compuesto por ochenta mil hombres. Entre ellos, iban los siete mil indios de Colotlán que comandaba el cura Calvillo, que solo sabían manejar la flecha y la honda. Aun cuando la superioridad numérica insurgente logró poner en graves aprietos a su contrario, la mejor disciplina y técnica de este le hizo ganar la batalla. Acto seguido, los principales caudillos rebeldes, acompañados por una pequeña escolta, escaparon hacia el norte, donde tendría lugar el epílogo de la audaz empresa. Calleja, por su parte, entró en Guadalajara el 21 de enero. Esa misma tarde José de la Cruz apareció también en la ciudad. Desde ese mismo momento se propusieron borrar cualquier vestigio de Hidalgo y acabar con los insurgentes que subsistieran en la Intendencia.

No obstante, allí las ideas de independencia permanecieron en el ánimo popular. Máxime que el gobierno del virreinato continuó mostrándose incapaz de oponer las soluciones conducentes a esa desatada disconformidad. Entre 1811 y 1817 se produjo una "guerra de guerrillas" con tres principales y distintos focos de rebelión: el sur de la Intendencia, el lago de Chapala y la zona alteña vecina al Bajío. A fines de 1812 se levantaron también en armas los pueblos indígenas asentados en la ribera de Chapala y en la isla de Mezcala. La causa directa fue la persecución emprendida contra Encarnación Rosas, un excombatiente aborigen. Para evitar ser aprehendido, Rosas armó a un grupo con hondas y piedras y "recibieron a los gachupines con tanta furia, que derrotados volvieron a Chapala...". Siguió una larga serie de enfrentamientos entre ribereños y soldados de la Intendencia que se prolongarían hasta 1816.

La situación se tranquilizó en Guadalajara en 1814 y la economía criolla experimentó un notable desarrollo. El comercio, por ejemplo, recibió un gran impulso al abrirse el puerto de San Blas al comercio extranjero. Por otro lado, a partir de 1811, un número elevado familias habían emigrado del resto de la Intendencia y otros lugares más remotos a la tranquilizada capital neogallega en busca del refugio y amparo que a sus personas y fortunas se les negaba en los convulsionados lugares donde residían. De esa suerte, Guadalajara alcanzó en 1814 los 60 mil moradores, comparada con la cifra de 30 mil, calculada a principios del propio siglo XIX.

Dado el peligro que la Constitución y el liberalismo imperante en las nuevas Cortes representaban para los grupos más privilegiados de todo el Virreinato, un primer mecanismo defensivo sería el de la oposición dentro de las mismas Cortes. La provincia de Guadalajara colaboró con Iturbide, cuando este hizo su triunfal entrada a la Ciudad de México, al frente del Ejército Trigarante, el 27 de septiembre de 1821. Más tarde, la Constitución Particular de 1824 de la Nueva Galicia prohibió expresamente la esclavitud en su territorio y sobre cada jefe político recayó la responsabilidad de liberar a cuantos conservaran esa condición.

Lo que enderezaría la nave del país con solo consumar la Independencia no había sobrevenido como se anhelaba, y hasta hubo quien empezara a considerar erróneo el haberse separado de España. En última instancia, se había realizado un viraje político importante: la Independencia, no esperada especialmente por grandes sectores de la población, ni consumada en la forma imaginada por los insurrectos de 1810. O sea que no se habían realizado las transformaciones sociales indispensables para contrarrestar el agobio en que vivía la inmensa mayoría de los habitantes.

De una o de otra forma, los neogallegos debieron adaptar a su cambiante escenario desde las más sencillas e íntimas costumbres hogareñas, hasta los complejos e impostergables mecanismos de subsistencia. En ello quedaba implícito el allegamiento de nuevas fórmulas de diversión, de transporte, de proceder religioso, de educación y de trato con visitantes – nacionales o extranjeros – que empezaron a recorrer la entidad en busca de contactos mercantiles y de otra índole.

En síntesis, los tiempos de la apacible vida neogallega yacían sepultados en el recuerdo de sus antecesores. El Reino de la Nueva Galicia era a partir de ese momento el Departamento de Jalisco.

Al desaparecer el Imperio, los líderes locales pretendieron una completa autonomía, por lo cual se desató una intensa campaña en favor del federalismo que se apoyó en dos grandes figuras: Francisco Severo Maldonado y Prisciliano Sánchez, ambos respaldados por el propio jefe político Luis Quintanar (1772-1837).

Desde marzo de 1821, había circulado en Guadalajara el Contrato de asociación para la República de los Estados Unidos del Anáhuac, donde Maldonado sostenía que el sistema federal era el más apropiado para gobernar un territorio de grandes dimensiones y para darle mayor cohesión a los habitantes de cada provincia.

Por su parte, el Pacto Federal de Anáhuac, de Prisciliano Sánchez, aparecido en 1823, aseguraba que el federalismo constituía "un invento feliz" de la política porque se ajustaba a las condiciones naturales del hombre, a fin de representar el único medio capaz de moderar la fuerza del gobierno central y la manera más eficaz para que cada individuo desarrollara con plenitud sus virtudes cívicas. Sobre Don Prisciliano Sánchez existe un muy completo estudio biográfico denominado "Reivindicación de Don Prisciliano Sánchez, Precursor del Federalismo Mexicano y Fundador del Estado de Jalisco," publicado en 2003 por el historiador Marco Antonio Cuevas Contreras.

Por su parte, en México se instaló finalmente el nuevo Congreso Nacional el 7 de noviembre de 1823 y, después de acalorados debates, el 31 de enero de 1824 se aprobó el Acta constitutiva federal, cuyo artículo 50 estipulaba que la república habría de ser organizada bajo las bases del federalismo. Fue remitida de inmediato a todos los estados, siendo jurada el 7 de febrero de 1824 por las autoridades de Jalisco, no obstante que en ella se concedían facultades tales al Congreso General y al Ejecutivo que les permitirían controlar desde el Centro a toda la Nación.

El primer gobernador constitucional, Prisciliano Sánchez, y su vicegobernador, Juan N. Cumplido, lo mismo que la I Legislatura del estado, tomaron posesión de sus cargos el 24 de enero de 1825.

La gestión del primer gobernador, que debía concluir en 1829, se vio interrumpida por su muerte repentina víctima de una infección, el 30 de diciembre de 1826, dando lugar a que Juan N. Cumplido se convirtiera ya en la pieza política principal de Jalisco. Hasta el día de su muerte (en 1851) fue nombrado seis veces gobernador interino en periodos que abarcaron de dos meses a un año, a más de resultar electo en tres ocasiones diputado local.

En general, los sucesores de Prisciliano Sánchez continuaron con la misma línea política de este. En el año de 1827, el Gobierno logró intervenir en el manejo de los diezmos y, en marzo de 1829, se privó a la Iglesia de su opción de adquirir bienes raíces y fundar obras pías.

Por otra parte, el uso extensivo de la libertad de imprenta dio lugar a una profusa Boletería que posibilitó la expresión escrita de todas aquellas ideas que las restricciones anteriores habían acallado. Ahora, ni censura ni tribunal alguno podían impedir y, mucho menos, castigar la crítica abierta de cuanto asunto anduviera en boga.

De 1821 data la primera escuela en Guadalajara sostenida exclusivamente con fondos del Ayuntamiento; pero no fue hasta el gobierno de Prisciliano Sánchez cuando se llevó a cabo una intensa campaña de escolarización, en tanto que la Constitución local sentaba el compromiso de crear escuelas de primeras letras en todos los pueblos de la entidad y de elaborar un plan general de estudios. Este fue publicado el 20 de marzo de 1826 y establecía que la enseñanza oficial en Jalisco habría de ser "pública, gratuita y uniforme", en sus cuatro niveles: municipal, departamental, cantonal y estatal. Asimismo, se clausuraron el colegio de San Juan Bautista y la Universidad de Guadalajara a causa de su marcada tendencia colonial, y se fundó el Instituto del Estado con un programa académico más amplio y acorde a lo que el Gobierno esperaba de la educación superior.

En cuanto a la educación de niñas, el Plan prescribía que también se estableciesen escuelas públicas "en todos los pueblos de Estado" para que aprendieran a "leer, escribir, contar, el dibujo y las labores convenientes a su sexo".

Aunque de hecho ya lo estaba desde el triunfo de los planteamientos de Cuernavaca, no fue sino el 23 de octubre de 1835 cuando el federalismo quedó oficialmente suprimido en todo el país. Jalisco y las demás entidades pasaron por entero a depender de México, mientras los partidarios del centralismo, entusiasmados por el triunfo, se lanzaban a demostrar que las cosas iban a marchar mejor en lo sucesivo. 

En junio de 1836, José Antonio Romero cesó como gobernador interino de Jalisco pues pasó al gabinete presidencial, tomando su lugar el vicegobernador Antonio Escobedo, a quién correspondió dar a conocer las llamadas Siete Leyes Constitucionales que fueron proclamadas en la Ciudad de México el 30 de diciembre de 1836.

En el ahora "departamento" de Jalisco, los tres gobernadores habidos entre 1835 y 1841: Romero, Escobedo y José Justo Corro – quien cubrió un interinato de noviembre a diciembre de 1837 –, fueron fieles ejecutores de la voluntad del Centro, a pesar de que los tres eran jaliscienses de nacimiento.

El entusiasmo que despertó el advenimiento del federalismo se vio empañado pronto por las noticias acerca de la invasión de fuerzas militares de Estados Unidos y de que la corbeta de guerra estadounidense Cyane había anclado en San Blas el 2 de septiembre de 1846. No se sabe con certeza cuánto tiempo permaneció el referido buque bloqueando el puerto, pero es evidente que impidió, o cuando menos dificultó, las operaciones de los comerciantes comarcanos, aparte del sobresalto que sembró entre los moradores.

Si bien es cierto que Jalisco veía transcurrir el asedio de las tropas norteamericanas a distancia, por cuanto éstas no daban trazas de intentar un avance o un desembarco por tierras occidentales, el Gobierno del estado no dejó de preparar dispositivos para la defensa en prevención de que la guerra cambiara su curso inesperadamente. Así, al mediar 1847 cristalizaban las negociaciones tendentes a constituir una alianza con los estados de México, Querétaro, San Luis Potosí, Zacatecas y Aguascalientes, pues se reunió en Lagos con representantes de ellos a discutir las maniobras militares conducentes. A mediados de agosto, el gobernador Angulo concurrió a Zamora con sus colegas de México, Zacatecas y Guanajuato para definir nuevas prevenciones destinadas a la salvaguardia del área.

A principios de enero de 1848 arribaron a San Blas los buques Lexington y Whiton, cuya tripulación se apoderó de algunos bagajes sin importancia. El puerto no fue atacado ni retenido por el enemigo; de cualquier forma, la cercana presencia extranjera intimidó al Gobierno de Jalisco. Muy pronto – el 2 de febrero de 1848 – sobrevino el tratado de Guadalupe Hidalgo que puso fin a la guerra. Conforme a tal pacto, México perdía, además de Texas, la Alta California, Arizona y Nuevo México, que en su conjunto significaban un poco más de la mitad del territorio nacional.

Francia, España e Inglaterra acordaron el 31 de octubre de 1861 intervenir militarmente en la República Mexicana, en virtud de la suspensión de pagos ordenada por el presidente Juárez. Posteriormente, solo los franceses continuaron con la empresa, en aras de otros fines. Al contrario de la indiferencia mostrada cuando la invasión estadounidense 15 años atrás, esta vez Jalisco se aprontó a movilizarse verdaderamente en defensa de la Nación. El propio Congreso estatuyó, antes de disolverse, que los jaliscienses entre los 18 y los 50 años de edad debían prestar servicio militar, de manera que el 2 de mayo, el gobernador Ogazón pudo disponer la organización de 10 cuerpos de infantería y de caballería.

El 6 de enero de 1864, arribó a la capital de Jalisco el ejército francés llevando a la cabeza al mariscal Aquiles Bazaine, substituto de Forey. Nadie opuso resistencia, pues Arteaga tenía dos días de haber salido con la tropa hacia el sur de Jalisco, dando lugar a las expresiones despectivas de los soldados jaliscienses que hizo públicas Bazaine, vaticinando que la "pacificación sería muy rápida". Mas la guerra de guerrillas resultó a la larga mucho más dañina para el invasor que el enfrentamiento abierto.

A consecuencia de las derrotas sufridas por los franceses en Europa en octubre de 1866, se hizo inminente el total retiro de las fuerzas expedicionarias en México, máxime que el ejército imperial ya mostraba serias cuarteaduras y empezaba a dar graves tumbos en distintas partes del país.

Eran tiempos malos los que venían: la dictadura de Santa Anna, la Revolución de Ayutla y la Guerra de tres años, causaron serios daños a la educación. De este modo, en 1860 – un año antes de la muerte de López Cotilla – solo subsistían 19 escuelas oficiales en Guadalajara y, peor aún, al restablecerse en 1867 el régimen republicano, luego de la invasión francesa, Guadalajara no contaría más de 11 planteles municipales que atendían un total de 590 niños y 69 niñas.

Benito Juárez fue reelecto Presidente de la República por resolución mayoritaria del Congreso; pero se mantendría en el poder muy debilitado por la disidencia de Lerdo de Tejada y Porfirio Díaz que ya encabezaban sendas facciones de liberales. Debilitamiento que no dejó de repercutir en Jalisco, por cuanto la Unión Liberal se erigió en el principal enemigo del Gobernador, propiciando una enconada lucha política que solo terminaría cuando los vallartistas consiguieron consolidarse en el poder en 1871. Mientras los diputados esperaban a que concluyera el periodo constitucional de Gómez Cuervo, este completó el número necesario de magistrados para reinstalar en noviembre al Supremo Tribunal de Justicia, suspendido a raíz del cese de su presidente. En febrero de 1871, la Legislatura estuvo ya constitucionalmente en tiempo hábil para regularizar sus funciones, mas el Gobernador, alegando su mala conducta anterior, no la reconoció.

Hacia 1878, la superficie de Jalisco – calculada entonces en – albergaba en sus doce cantones, 30 departamentos y 118 municipalidades que conformaban la estructura territorial del estado, más del 10% de los 9,5 millones de mexicanos; aunque el Séptimo cantón – Tepic –, con seis departamentos y 28 municipios, de hecho ya no pertenecía a Jalisco desde que, en 1867, había sido convertido en distrito militar. Comoquiera, sus pobladores llegaban a la cifra de 857.000, mayor que la de cualquier otra entidad. Más del 70% vivía en áreas rurales y tenía a la agricultura como principal ocupación, tanto que, en 1877, las cosechas jaliscienses alcanzaron el 16,5% de la productividad de todo el campo nacional. Jalisco era el mayor cultivador de maíz, frijol y trigo. El primer lugar correspondía al maíz y el segundo a los otros dos cereales acompañados de algodón, la caña de azúcar y el tabaco, cuyos respectivos volúmenes, a más de satisfacer la industria local, lograban colocar excedentes en otras partes. En seguida estaba el cultivo del agave que, año tras año, se convertía en creciente riqueza agroindustrial a consecuencia del mayor consumo del "vino mezcla" o tequila, que había sobrevenido a raíz de la fiebre del oro en la Alta California. Asimismo, aunque en cantidad mucho menor, los suelos jaliscienses cosechaban ajonjolí, papa, lenteja, arroz, cebada, chile, comino, garbanzo, haba, etc.

Cuando Porfirio Díaz fue elegido por gran mayoría en febrero de 1877, Ignacio L. Vallarta ganó la presidencia de la Suprema Corte de Justicia, lo que dio vuelo a sus aspiraciones de suceder a Díaz y ocasionó la escisión entre ambos comandantes.

Entre las principales acciones del nuevo gobierno estuvo la de fundar un Monte de Piedad y Caja de Ahorros. Asimismo, promulgar en mayo de 1887 un nuevo Reglamento de Instrucción Primaria por medio del cual el Gobierno del estado absorbía los gastos de la educación elemental y, en junio de 1889, otra Ley Orgánica de Instrucción Pública que imponía el laicismo. Además, a mediados de 1888 inició la construcción de un mercado en Guadalajara y dispuso convenientes reformas a la Escuela de Medicina.

Asimismo, en 1889, Corona pudo vanagloriarse de que la tranquilidad pública se había mantenido "sofocándose pronto y enérgicamente la intentona de algunos malhechores".

La principal acción del gobierno de Ramón Corona se enfocó a promover el comercio mediante la supresión de las alcabalas, a partir de marzo de 1888, y la introducción en Guadalajara del ferrocarril procedente de la ciudad de México, cuyo primer viaje concluyó el 15 de mayo de 1888 en medio de grandes fiestas.

Desde 1882, el gobernador Riestra había conseguido la autorización para fundar el "Banco de Jalisco". Sin embargo, los estatutos propuestos no fueron aprobados porque se contraponían con varios artículos de la Constitución. No fue sino hasta un año después, cuando Tolentino volvió a la carga y el Congreso local lo autorizó para que designara al grupo de accionistas que habría de establecer en definitiva el Banco de Jalisco, institución que efectuaría, exenta de cualquier gravamen, operaciones de depósito, descuento, circulación y emisión de dinero.

En cambio, antes de concluir 1883, sí pudo establecerse una sucursal del Banco Nacional de México, que terminó por potenciar en Jalisco el inicio de las actividades crediticias, en las cuales, además de participar como socio de algunos capitales, el estado se vio favorecido con la apertura de una cuenta de crédito hasta por 30 mil pesos. Años después, en 1889, se establecería también en Guadalajara una sucursal del Banco de Londres y México.

La ganadería, que desde tiempos antiguos había sido una de las actividades económicas más importantes, al declinar el porfiriato también registró un cierto descenso. De tal suerte, si en 1903 tenía un valor superior a 18,5 millones de pesos, para 1909 se hallaba en menos de 17; tal descenso también puede ser valorado por medio del número de bovinos; un millón en 1903 que en 1909 bajó a 735,000. A pesar de ello, hasta 1902 Jalisco fue el primer productor de ganado vacuno y de leche con el 10% de la existencia nacional, y de ganado porcino con el 9%. En lo que se refiere a su precio también subió casi un 40% entre 1890 y 1910.

Para 1895 el valor total de las cosechas en Jalisco casi alcanzó 15 millones de pesos, 8% del total nacional; en 1901 subió a 23 millones (casi el 9%) pero en 1904 bajó a 17 millones (el 7%), y aunque en 1906 tornó a subir, ya no recuperó el nivel de 1901.

El creciente interés por perpetuar el rostro propio encontró un nuevo satisfactor en la cámara fotográfica. Sobre todo porque el costo de una fotografía, mucho más bajo que los honorarios de cualquier pintor, permitieron a muchas más personas poseer la reproducción. En efecto, aun cuando los primeros en fotografiarse fueron los más acaudalados, pronto innumerables fotógrafos ambulantes recorrerían pueblos y ciudades en busca de clientes de menores recursos dispuestos a posar frente a sus voluminosos aparatos. Parece ser que fue Jacobo Gálvez, en 1853, uno de los primeros en traer a Guadalajara, después de su viaje por Europa, los elementos técnicos para reproducir imágenes casi instantáneas: una cámara obscura para fijar imágenes, no en lámina como se hacían ya en aquella época y según el método de Daguerre, sino en papel.

Al finalizar el siglo XIX, quienes se habían mantenido en la cúspide de la pirámide socioeconómica de Jalisco se encontraban de hecho concentrados en Guadalajara, donde gozaban de las crecientes comodidades y mejores perspectivas pecuniarias que el medio ofrecía. Más ahora, esta minoría se encontraba rodeada por una buena cantidad de europeos que se habían asentado en Guadalajara, atraídos por sus posibilidades comerciales, y muchos hasta casados con hijas de los más opulentos, incorporando así sus apellidos a la flor y nata de aquella sociedad.

De 1904 a 1909, Porfirio Díaz eligió Chapala para descansar cada año durante las semanas Santa y de Pascua, con lo cual también colaboró a poner de moda a la población entre las ricas familias tapatías, quienes acabaron transformando la aldea en un verdadero sitio de descanso.

Hacia 1909, aparecieron las lanchas de motor y los deportes acuáticos; en 1910 se fundó el "Yacht Club" y la "Compañía de Fomento", misma que construyó la estación y la vía ferroviaria y fue propietaria del servicio de vapores Vicking y La Tapatía, ambos destrozados por un fuerte oleaje en 1926. Un año antes se había acondicionado el antiguo Camino Real de Guadalajara que mucho impulsaría el flujo turístico sobre Chapala.

Antes de 1908, no hubo en Jalisco una oposición al Gobierno verdaderamente organizada. Más bien se manifestó en reducidos grupos de estudiantes, profesionistas y ciertos mineros y obreros textiles que llevaron a cabo algunas huelgas. De hecho, la crítica de mayor trascendencia se debió a personajes como Roque Estrada, Ignacio Ramos Praslow y Miguel Mendoza López, aglutinados en torno a un partido de nombre "Obrero Socialista", del que emergió una publicación llamada Aurora Socialista. Pero en febrero de 1908, Porfirio Díaz manifestó a un periodista estadounidense su deseo de retirarse pronto del poder y el agrado con que vería a un partido de oposición para las elecciones de 1910.

Acompañado de Roque Estrada, Francisco I. Madero estuvo en Guadalajara en diciembre de 1909. Pese a los obstáculos puestos por el Gobierno, pudo llevar a cabo un mitin que patentizó una gran popularidad; pero mayor aún resultó la concurrencia en mayo de 1910, cuando volvió a Guadalajara ya como candidato formal a la "Presidencia de la República" y con un proyecto más preciso, además de las instancias de corte político que había manejado antes.

Tan pronto como se dieron a conocer los resultados de los sufragios que dieron a Madero el triunfo, el Gobierno de Jalisco se dio a la tarea de restaurar el orden constitucional. Se convocó a elecciones municipales para el 5 de noviembre, manifestándose ya una clara preponderancia del Partido Católico Nacional (PCN), que ganó la mayor parte de las alcaldías. Ello se refrendó al restaurarse el Poder Legislativo local, en marzo de 1912, con doce diputados propuestos por el partido de referencia.

En Jalisco, además de que su Congreso enunció su propuesta de que la propiedad territorial fuese accesible a un mayor número de habitantes, se declaró también en favor de que la condición de los trabajadores mejorara y de que se diera fin a las injusticias. Los cambios, decían, habrían de realizarse mediante una evolución lenta y firme, ""sin lucha de clases, pero con medidas enérgicas"".

En marzo se estableció el descanso dominical obligatorio y en julio se reconoció el derecho de los trabajadores a organizarse y se confirió personalidad jurídica a los sindicatos, a la sazón controlados por el clero en su mayoría. Mas, por otro lado se dispuso la militarización de los empleados comerciales y que cualquier huelga no autorizada fuese reprimida con celeridad.

El 8 de julio de 1914, con Álvaro Obregón al frente, las fuerzas constitucionalistas desplegaron su triunfalismo demostrando su ánimo anticlerical. El avance había transcurrido por la costa del Pacífico, donde las fuerzas de vanguardia de Manuel M. Diéguez, Rafael Buelna y Lucio Blanco habían abierto el camino después de apoderarse de Acaponeta, San Blas y Tepic.

La ocupación de la capital tapatía se realizó pacíficamente, pues la plaza había sido evacuada, pero el gobernador huertista José María Mier y sus tropas fueron sorprendidos en El Castillo por Lucio Blanco y Enrique Estrada: el ejército fue desbandado y Mier resultó muerto.

Las fuerzas revolucionarias no fueron bien recibidas en la capital de Jalisco. No solo los miembros del clero, como afirmó Obregón, se opusieron al nuevo gobierno. El rechazo se hizo más patente a medida que empezaron a implantarse las reformas y decretos expedidos por el Gobierno constitucionalista.

El 11 de diciembre, Medina derrotó a los carrancistas e hizo que Diéguez se retirara a Ciudad Guzmán, de manera que, en cuanto lo alcanzó Villa, pudieron entrar juntos a Guadalajara sin mayor dificultad. Aquí fueron recibidos con grandes muestras de entusiasmo, dada la esperanza de que anularían las disposiciones constitucionalistas. En primer lugar, Villa nombró gobernador de Jalisco a Julián Medina, quien de inmediato prohibió la moneda carrancista y puso en circulación la propia; a su vez, prometió seguridad tanto al trabajo como a la capital y decretó que los inmuebles de la clase acomodada, confiscados por el general Diéguez, volviesen a sus antiguos propietarios, en tanto que ordenaba reabrir al culto los templos que fueron cerrados durante el gobierno de Diéguez y liberar a los sacerdotes presos.

Para los primeros días de 1915, Diéguez había fortalecido a su ejército y retornaba a Guadalajara, así que reinstaló su gobierno en Guadalajara sin mayor represalia y, de inmediato, se aprestó para continuar la campaña. El 18 de abril de 1915, Diéguez se apoderó nuevamente de Guadalajara, tras derrotar al general Medina que huyó rumbo a Lagos. Después designó a Manuel Aguirre Berlanga, una vez más, como gobernador interino, en tanto él iba en busca de Obregón, que daba los últimos toques a su campaña contra los restos del ejército enemigo.

Por otra parte, el pleito en las entrañas mismas de la Revolución hizo que las resoluciones referentes a un cambio radical en las estructuras socioeconómicas nacionales, reflejadas principalmente en las relaciones obrero-patronales y en la tenencia de la tierra, adquirieran un carácter ambiguo, destacándose mejor la precisión de las propuestas de la doctrina social católica.

La legislación agraria carrancista del 6 de enero de 1915 – incorporada al estado por Diéguez en marzo del mismo año – no había resultado prevalecedora. De ahí las reclamaciones campesinas y que pronto algunos trabajadores agrícolas pasaran a tomar tierras, no obstante que Aguirre Berlanga amenazó con castigar severamente a los autores de tales "atropellos". Los conflictos siguieron hasta el extremo de que el propio Diéguez pidió al Constituyente de Querétaro que la nueva Carta tuviera en mente a los campesinos mestizos pobres y no solo a los indígenas.

Resultado de la Constitución de 1917 fue también el incremento de la entrega de tierras; sin embargo, no todos los demandantes y necesitados la recibieron de momento. Como la reforma agraria funcionó en relación directa con el apremio campesino, los primeros grupos beneficiados fueron, o bien comunidades indígenas despojadas no mucho antes, o aquellos pueblos mayormente afectados por la crisis de principios de siglo que se habían distinguido por su participación activa en el movimiento revolucionario.

Siendo ya presidente electo, en octubre de 1920, Álvaro Obregón se manifestó partidario de la pequeña propiedad y de que cada campesino tuviese una parcela cedida por los latifundistas. En consecuencia, después de tomar posesión el 1 de diciembre, expidió una serie de decretos encaminados a regular la extensión y funcionamiento de los ejidos e instauró las procuradurías de pueblos para proporcionar a las comunidades el auxilio legal preciso, también legisló sobre las grandes y pequeñas propiedades privadas, declarando inafectables a las que constituían unidades agrícola-industriales de producción.

En el mes de octubre de 1921 fue celebrado en Guadalajara un Congreso de Obreros Libres, en el que estuvieron representados 35 mil trabajadores adheridos a las uniones católicas del país. Todos se manifestaron contra la sindicalización y a favor del mutualismo como forma de organización laboral, además de que condenaron las huelgas y todo aquello que tuviera que ver con los "obreros rojos" de la CROM (Confederación Regional Obrera Mexicana) y de la recién fundada CGT (Confederación General de Trabajadores).

Si bien es cierto que en 1926 las condiciones laborales garantizadas por el poder civil sobrepasaban a las que estaba dispuesto a conceder el régimen, no menos lo es que el problema de la tenencia de la tierra distaba de estar resuelto satisfactoriamente.

Por eso al iniciarse el choque violento entre la Iglesia y el Estado, mientras los obreros desertaban de las filas católicas, éstas se engrosaban con campesinos dispuestos a defender sus medios de subsistencia.

Jalisco es un estado libre, autónomo y soberano a la federación de México. Su gobierno se divide en tres poderes que son el ejecutivo, legislativo y judicial. El poder ejecutivo está a cargo del gobernador del estado con un período de gobierno de seis años, que es elegido democráticamente, el gobernador es el que tiene que coordinar todos los programas de desarrollo para el estado. El poder legislativo está conformado por los diputados locales que forman el congreso del estado y los eligen por tres años, en él se discuten las reformas a las leyes del estado y el presupuesto. Por último al poder judicial le corresponde aplicar las leyes, el gobernador nombra a los miembros del poder judicial. El actual gobernador electo es Enrique Alfaro de Movimiento Ciudadano para el período 2018-2024, la izquierda tuvo un crecimiento importante.

En total el estado comprende , distribuidos en 12 regiones con una subregión, cada región tiene un municipio sede designado por la importancia y ubicación estratégica de dicho municipio en la región respectiva. La división en regiones es una simple división administrativa que facilita el manejo del estado. Las regiones administrativas son las siguientes:

El Estado de Jalisco se localiza en la zona occidente de la República Mexicana. Se encuentra limitado al norte por los Estados de Zacatecas, Aguascalientes; al noroeste con Nayarit; al noreste con Guanajuato y San Luis Potosí; al sur con Colima; al sureste con Michoacán y al suroeste con el océano Pacífico. Tiene una extensión territorial de 80,137 km², lo que representa el 4.09% de la superficie total de México.

Jalisco tiene problemas de límites territoriales con sus vecinos, en especial con el estado de Colima, con quien disputa una muy importante zona de la costa. Tradicionalmente los límites entre entidades se han definido por límites naturales, en este caso el límite es un río, casi en su desembocadura en el océano Pacífico. El conflicto limítrofe se inició cuando se modificó el curso del río, quedando la zona de playa en la parte que pertenece a Colima y que Jalisco tiene intención de reclamar por su potencial económico a través del turismo que actualmente recibe como en el Complejo Grand Bay - Isla Navidad. Actualmente la solución del problema entre estos dos estados depende del Senado de la República.

Actualmente Jalisco cuenta ya con la más alta tecnología en cuanto a prevención de desastres naturales. Hace poco se colocaron en las costas del estado de Jalisco alarmas de tsunamis (maremotos) con las cuales no contaba.

El estado de Jalisco encierra áreas que corresponden a 4 provincias fisiográficas de México: Eje Neovolcánico, Mesa Central, Sierra Madre Occidental y la Sierra Madre del Sur.

Provincia del Eje Neovolcánico
Representada en el estado por las subprovincias: Bajío Guanajuatense, Sierras y Bajíos Michoacanos, Altos de Jalisco, Chapala, Guadalajara, Sierras de Jalisco, Sierras Neovolcánicas Nayaritas, Volcanes de jalisco y Escarpada Limítrofe del Sur.

Solo una pequeña porción, al sureste del municipio de San Diego de Alejandría, penetra en el estado de Jalisco y se asocia a un solo sistema de topoforma; el llano de piso rocoso que representa el 0.001% de la superficie total del estado.

Es un rincón muy pequeño de esta subprovincia el que penetra en el estado de Jalisco y abarca parte de los municipios de Ayo el Chico y Degollado; presentando tres sistemas de topoformas: Mesetas Lávicas, Lomerios de Colinas Redondeadas con Terrenos Ondulados y Valles de Laderas Teñidas.

Subprovincia de los Altos de Jalisco 
La mayor parte de esta subprovincia queda dentro del estado de Jalisco. Se caracteriza por amplias mesetas de origen volcánico y presenta la mayor densidad de topoformas degradativas, generadas por disección hídrica y abundancia de valles profundos de laderas escarpadas a fines de los caños de la Sierra Madre Occidental. Representa el 17.51% con respecto a la superficie total de la entidad y se distinguen en ella los siguientes sistemas de topoformas: Escudo-Volcanes Aislados o en Conjunto, Pequeña Meseta asociada con lomeríos, Gran Meseta con Cañadas, Meseta Lávica, Meseta Lávica asociada con lomeríos, Meseta Escalonada, Lomerío de Colinas Redondeadas, Lomeríos Suave en Arenisca Conglomerado, Valle de Laderas Escarpadas asociadas a lomeríos, Valle con Terrazas, Cañón y Depresión.

Subprovincia de Chapala 
Esta subprovincia alcanza una magnitud significativa en afallamiento asociado con manifestaciones volcánicas y grabens (áreas hundidas entre sistemas de fallas). Se tiene aquí a 1,500 msnm el mayor lago del país, cuyas aguas ocupan un enorme graben ubicado entre sistemas de grandes fallas este-oeste y otras más pequeñas dirigidas burdamente de norte a sur. Por otro lado, el vulcanismo se desarrolló a lo largo de algunas líneas de fallas y levantó las sierras que bordean el lago. El resultado es un paisaje de origen unitario pero de morfologías combinadas que aportan una notable singularidad a la provincia.

En la subprovincia de Chapala se distinguen 4 regiones o sectores:

1. Una región occidental con importantes sistemas de fallas noroeste-sureste y norte-sur que han generado grabens con esos mismos rumbos y que forman los vasos de los lagos Atotonilco, Zacoalco, San Marcos y Sayula, situados a una altitud de 1,350 msnm.

2. El propio lago de Chapala y las Sierras de Laderas de Escarpa de falla que lo circundan, más su extensión cenagosa al este: La Ciénega de Chapala. El lago, bastante somero, mantenido fundamentalmente por los aportes del río Lerma al que recibe en el extremo oriental.

3. Las sierras afalladas y llanos al norte de los lagos.

4. Las sierras afalladas y la región de lomeríos al sur de los lagos

Dentro del estado de Jalisco la subprovincia de Chapala presenta los siguientes sistemas de topoformas: Sierras de Laderas Abruptas con Cañadas; Sierra de Laderas Tendidas; Sierra con Laderas de Escarpa de Falla; Sierra con Ladera de Escarpa de Fallas y Mesetas; Escudo-Volcanes Aislados o en Conjuntos; Sierra Volcánica con Mesetas; Lomeríos Asociados con Llanos; Lomeríos Suave (tobas); Lomeríos Suaves (conglomerados y areniscas); Valle de Laderas Tendidas; Valle de Laderas Tendidas con Terrenos Ondulados; Depresión; Gran Llano; Pequeño Llano Aislado y Llano Salino.

Subprovincia de Guadalajara 
Esta pequeña subprovincia queda toda dentro del estado de Jalisco, ocupando el 3.73% de la superficie. Cubre totalmente los municipios de Antonio Escobedo, El Arenal, Guadalajara y Zapopan, Ahualuco de Mercado, Amatitán, Etzatlán, Hostotipaquillo, Magdalena, San Marcos, Tala, Tequila, Teuchitlán, Tlaquepaque y Tonalá.

La subprovincia se caracteriza por las notables manifestaciones de vulcanismo explosivo, que data de tiempos relativamente recientes y cuyas huellas se observan en la ciudad de Guadalajara y en la sierra de la primavera.

A pesar de ser una subprovincia pequeña es la menos uniforme, teniendo una gran complejidad en su panorama fisiográfico, en el que se encuentran sistemas tan distintos como sierras, mesetas, lomeríos y llanos; sin embargo, en general su litología está constituida por rocas ígneas extrusivas ácidas, vidrios volcánicos (obsidiana) basaltos y nubes ardientes.

Esta subprovincia inserta totalmente en el estado de Jalisco, está constituida por dos tipos básicos de topoformas generales: montañas y mesetas. Entre sus extremos norte y sur, las cadenas montañosas se encuentran acomodadas de tal modo que describen la forma de una burda letra "S".

Dentro del área rodeada por la curva superior de la letra quedarían alojados los sistemas de topoformas más occidentales de la vecina subprovincia de las Sierras de Jalisco. Varias cumbres de los núcleos montañosos de rocas ígneas que componen la sierra se levantan por encima de los 2,000 msnm, en tanto que las superficies más bajas se encuentran a una altitud de 800 msnm.

La subprovincia de las Sierras de Jalisco presenta los siguientes sistemas de topoformas: Gran Sierra Volcánica Compleja o Grandes Estrato-Volcanes, Sierra de Laderas Abruptas, Sierra de Laderas Tendidas, Sierra de Laderas Tendidas con Llanos, Sierra Compleja, Escudo-Volcán Aislado, Meseta Lávica, Mesetas Lávicas asociadas con cañadas, Mesetas Escalonadas asociadas con lomeríos, Mesetas Pequeñas con lomeríos, Lomerío Suave asociado con cañadas, Valle de Laderas Escarpadas, Valle de Laderas Tendidas, Valle de Laderas Tendidas asociado con lomeríos, Cañón y Pequeño Llano Aislado.

Subprovincia de las Sierras Neovolcánicas Nayaritas 
Un pequeño rincón de esta subprovincia del Eje Neovolcánico, penetra en el extremo norte del estado de Jalisco, del que ocupa el 0.007% de la superficie, localizado en parte del municipio de Hostotipaquillo y distribuido en tres sistemas de topoformas que son: una Sierra de Laderas Tendidas, una Meseta Lávica con Cañadas y un Valle Tendido con Terrenos Ondulados.

Subprovincia Volcanes Nevado de Colima y de Fuego"
Esta subprovincia penetra al estado por el este y recibe este nombre debido a sus dos geoformas más representativas, El Nevado de Colima y el Volcán del Fuego. Ocupa apenas el 2.36% de la superficie total estatal; cubriendo totalmente los municipios de Tonila y Zapotitlán de Vadillo y parte de los de Zapotlán El Grande, Tolimán, Tuxcacuesco, Tuxpan, Venustiano Carranza y Zapotiltic. El panorama fisiográfico de la subprovincia está integrado por siete sistemas de topoformas: Gran Sierra Compleja o Grandes Estrato-Volcanes Aislados, representados por el Nevado y el de Fuego, que están constituidos por andesitas (rocas ígneas medias en sílice) y sus altitudes son de 4,240 y 4,220 m respectivamente; Sierra de Laderas Abruptas, que se encuentra sobre la base occidental del Nevado, representada por el Cerro el Petacal, de rocas lávicas sílicas; los Lomeríos Suaves (tobas) asociados con cañadas y los Lomeríos Suaves (arenisca conglomerado) integran las amplias faldas que se extienden en torno a los volcanes, surcadas por arroyos radiales; el Valle de Laderas Escarpadas, que es el sistema de cañadas hondas y ramificadas, que sobre la base occidental de los volcanes han labrado sus cárcavas; el Pequeño Llano Aislado, de origen aluvial que se localiza en el extremo norte; y el Piso de Valle, que está formado por el valle plano y angosto del río Armería.

Subprovincia de la Escarpa Limítrofe del Sur 
Solo una pequeña parte de esta subprovincia penetra en el estado de Jalisco y abarca una porción del municipio de Jilotlán de los Dolores, con un solo sistema de topoformas, la Meseta Lávica asociada con Sierras que es un conjunto de mesetas basálticas escalonadas y que descienden hacia el sur, a altitudes de 1,000 a 1,500 msnm interrumpidas por Escudo-Volcanes también basálticos.

Provincia Mesa Central 
Penetra al estado de Jalisco por el noroeste; ocupa el 3.44% de la superficie total estatal y en ella se presentan parte de tres subdivisiones de la provincia que corresponden a la subprovincia Llanos de Ojuelos y las discontinuidades fisiográficas Sierra de la Cuatralba y Valles Paralelos del suroeste de la Sierra de Guanajuato.

Estas subdivisiones de la provincia poseen patrones característicos de topografía y morfología; presencia y distribución de suelos y vegetación diferentes, por lo que la descripción de suelos, vegetación, posibilidades de uso agrícola, ganadero y forestal, y el estado actual de las formas de producción agrícola, se encuentra referida por regiones

Esta provincia cuenta con una subprovincia llamada Llanos de Ojuelos.

Esta subprovincia penetra al noreste del estado y limita al sur con los Altos de Jalisco; inmediatamente al norte de Encarnación de Díaz. Comprende una porción pequeña de la entidad (2,310.30 km²), que cubre totalmente el municipio de Ojuelos y parte de los de Encarnación de Díaz y Lagos de Moreno. Los sistemas de topoformas más representativos de la subprovincia, dentro del estado son: Las Llanuras de Piso Rocoso, cubiertas por suelos someros de aluvión y salpicadas de pequeñas charcas; y las Mesetas con Cañadas que se encuentran entre las llanuras. Las Sierras Bajas y los Lomeríos probablemente se derivaron de la erosión de mesetas similares a las ya mencionadas; sus laderas son rectas y su elevación es de 2,300 y 2,250 msnm respectivamente. En general, la litología de estos sistemas de topoformas está constituida por rocas de origen volcánico, ricas en sílice.

Provincia de la Sierra Madre Occidental
Esta provincia cuenta con dos subprovincias: La de las Sierras y Valles Zacatecanos y la de Las Mesetas y Cañones del Sur
Subprovincia Mesetas y Cañones del Sur
Esta Subprovincia se encuentra en casi toda la extremidad norte de Jalisco hasta el límite sur del extenso cañón que ha formado el Río Grande de Santiago, quedando su frontera sur-oriental en el estado al norte de la ciudad de Tequila; abarca la totalidad de los municipios Bolaños, Huejuquilla el Alto, Mezquitic, Teocaltiche y Villa Guerrero, y parte de los municipios de Colotlán, Chimaltitlán, Hostotipaquillo, Huejucar, San Martín de Bolaños y Tequila.

Forma parte de la "espina dorsal" de la Sierra Madre Occidental. Su paisaje está constituido por altas mesetas, algunas de ellas enormes, que se interrumpen abruptamente por profundos cañones.

La superficie total de esta subprovincia es de 8,165.35 km² y representan el 10.35% con respecto a la superficie total del estado. Los sistemas de topoformas que se encuentran en esta subprovincia dentro del estado de Jalisco son: Superficie Disectada de Gran Meseta, que son agrupaciones de mesetas de tamaño pequeño; Pequeñas Mesetas; Asociadas a Cañadas; Lomeríos, que se encuentran como pequeños grupos aislados en los Pisos de Valle, generalmente amplios; Lomeríos y Cañadas, Piso de Valle con Terrazas; Piso Amplio de Valle con Lomeríos y por último Cañones.

Según los resultados que arrojó el "II Censo de Población y Vivienda", realizado por el Instituto Nacional de Estadística y Geografía (INEGI) con fecha censal del 12 de junio de 2010, el estado de Jalisco contaba hasta ese año con un total de 8,079,782 habitantes. De dicha cantidad, 4,064,941 eran hombres y 4,014,841 eran mujeres. La tasa de crecimiento anual para la entidad durante el período 2005-2010 fue del 1.7%. Según indica este censo, 4,434,252 de los jaliscienses viven en la zona metropolitana de Guadalajara. La población aumentó aproximadamente 750,000 habitantes desde el último conteo, realizado en 2005. Hoy en día, la población del Estado representa el 6.5% del total del país.

Según el "XII Censo de Población y Vivienda 2010", realizado por el INEGI en Jalisco, hay 1,801,306 viviendas particulares, de las cuales 1,697,299 disponen de agua corriente dentro o fuera de la vivienda, pero en el mismo terreno, lo que representa el 94.2%; 1,754,481 tienen drenaje, lo que equivale al 97.4%, y 1,182,473 cuentan con energía eléctrica, esto es, el 65.6%.

Según el "XII Censo de Población y Vivienda del 2010" (INEGI), en Jalisco hay 1,802,424 hogares, de los cuales el 25% (443,000 hogares) tienen jefatura femenina, es decir, son dirigidos por una mujer, y el 75% (1,359,424 hogares) tienen jefatura masculina, es decir, son dirigidos por un hombre.

Los wixaritari son el grupo étnico más conocido y numeroso del estado de Jalisco, se concentran principalmente al norte del estado en municipios como Mezquitic, Bolaños, Huejuquilla el Alto y Villa Guerrero, aunque comparten asentamientos con otros estados como Nayarit, Durango y Zacatecas. Al sur se encuentra otro grupo indígena nativo de Jalisco, los nahuas, de filiación uto-azteca, quienes radican en los municipios de Tuxpan y Tonila; y en menor proporción los purépechas, mixtecos, mazahuas otomíes y zapotecos.

A mediados del siglo pasado, el incremento de la población de Jalisco en el periodo 1950-1960, presentó una tasa de crecimiento anual del orden del 3.4%. El periodo que comprende 1970-1980 muestra un descenso con respecto a la década precedente, tendencia que se mantiene posteriormente. Se ha observado la disminución en el ritmo de crecimiento hasta llegar a un 1.33% del año 2000 al 2005.
En el Alto Santiago, se encuentra la Zona Metropolitana de Guadalajara (ZMG), la cual es el principal centro de población de la entidad. Una serie de factores ha generado la conurbación de la ciudad de Guadalajara con los municipios limítrofes, lo que ha acelerado el crecimiento de su población.

De acuerdo con cifras de INEGI, para el año 1950 la población total del estado de Jalisco era un poco más de 1.7 millones de habitantes, en el año 2005, esta asciende a más de 6.7 millones, junto a este significativo aumento se fueron dando diversas transformaciones demográficas a nivel sub región, en especial en el Alto Santiago, que pasó de una participación relativa en la concentración de población del 46.6% al 71.2% en este periodo de tiempo.
Con base en el último registro oficial del año 2005, la población total de la entidad suma 6,752,113 habitantes, lo cual representa el 6.5% de la población total del país (103.3 millones); en lo que se refiere a la población rural, esta representa el 13.9% de la población total del estado y la población urbana equivale al 86.1%.

La ciudad de Guadalajara, capital de Jalisco, es la sede de la segunda universidad fundada en México, la Universidad de Guadalajara. Esta entidad educativa pública es la segunda en cantidad de estudiantes en el territorio (después de la UNAM), (195,116 estudiantes de profesional medio, bachillerato, técnico superior, licenciatura y posgrado).

También es sede de la que es la primera universidad privada de México, la Universidad Autónoma de Guadalajara, por sus siglas U.A.G. La sede principal de la Universidad Autónoma de Guadalajara es Ciudad Universitaria, ubicada en el municipio de Zapopan; en dicho lugar se encuentra la rectoría y la mayoría de las carreras que se imparten. Cuentan también con el Instituto de Ciencias Biológicas, UAG campus Santa Anita (Tlaquepaque), UAG Campus Tepic, UAG Campus Tabasco, Instituto Autónomo de Educación de Tecomán (IAETAC), el sistema de educación básica y media José Vasconcelos en Baja California, y la primaria Antonio Caso más Santa Anita.

Cuenta con dos campus de la universidad privada más importante del país, el Instituto Tecnológico y de Estudios Superiores de Monterrey (Tec de Monterrey).

El Instituto Tecnológico y de Estudios Superiores de Occidente (ITESO), es una universidad privada con sede en la ciudad de Tlaquepaque. Esta institución educativa fue fundada en el año de 1957 y pertenece al Sistema Universitario Jesuita (SUJ) que a su vez forma parte de la Compañía de Jesús. En este sentido la universidad también es nombrada como la Universidad Jesuita de Guadalajara pero es conocida comúnmente como el ITESO.

Ofrece 26 programas de licenciatura, 2 de especialidades, 13 de maestría y 3 doctorados. La matrícula del ITESO es de alrededor de 8000 estudiantes. La Universidad cuenta solo con un campus, el cual está ubicado al sur de la Zona Metropolitana de Guadalajara en las inmediaciones de Tlaquepaque donde se encuentran sus diversas instalaciones.

Tres campus de la Universidad del Valle de México, tres campus del TecMilenio (Tlaquepaque, Zapopan y Ejecutivo), la Universidad del Valle de Atemajac con tres campus (Zapopan, Lagos de Moreno y Puerto Vallarta), la Universidad Panamericana, la Universidad Cuauhtémoc, la Universidad Marista de Guadalajara el Instituto Tecnológico Superior de Arandas, el Instituto Tecnológico Superior de Chapala, el Instituto Tecnológico Superior de Cocula, el Instituto Tecnológico Superior de El Grullo, el Instituto Tecnológico Superior de la Huerta, el Instituto Tecnológico Superior de Lagos de Moreno, el Instituto Tecnológico Superior de Mascota, el Instituto Tecnológico Superior de Puerto Vallarta, el Instituto Tecnológico Superior de Tala, el Instituto Tecnológico Superior de Tamazula, el Instituto Tecnológico Superior de Tequila, el Instituto Tecnológico Superior de Zapopan y el Instituto Tecnológico Superior de Zapotlanejo. Además, existe el Centro de Investigación y Asistencia Tecnológica del Estado de Jalisco CIATEJ.

De estos centros educativos 18 poseen carreras de ingeniería y otras carreras afines a la industria de la electrónica, como ingeniería electromecánica, ingeniería en tecnologías electrónicas, en tecnologías de la información y comunicaciones, ingeniería industrial, ingeniería de sistemas, teleinformática, administración de tecnologías de la información, y tecnologías computacionales, entre otras.

Así mismo, en la localidad de Atequiza, Ixtlahuacán de Los Membrillos; cuenta con la Escuela Normal Rural Miguel Hidalgo, fundada a partir de los ideales de la Revolución, es una institución formadora de docentes para el ámbito rural, atendiendo gratuitamente a hijos de campesinos y obreros.

Jalisco, el séptimo estado en extensión y el cuarto más productivo de la república mexicana (después de Ciudad de México, Estado de México y Nuevo León), ha experimentado un importante crecimiento en su actividad económica y comercial durante los últimos años. Entre los principales productos que forman parte de la comercialización del estado destacan los cosméticos, aparatos electrónicos, tecnología, farmacéuticos, construcción, textiles, tabaco, alimentos y bebidas, artículos deportivos, etc. Así mismo, el sector de servicios también ha crecido con intensa pujanza, al igual que el sector turístico y el financiero.

Este desarrollo intensivo del sector comercial en la entidad es superado por la Ciudad de México, el Estado de México y Nuevo León.
La población económicamente activa en el sector agropecuario ha disminuido, mientras que en el sector terciario y secundario ha incrementado su demanda, sobre todo en los servicios y en el comercio. Sin embargo, el estado se distingue por el cultivo de granos como: maíz, sorgo, frijol, arroz, cebada, trigo, caña de azúcar, algodón, cártamo, soya, alfalfa, melón, papa, jitomate, papaya, café, mango, aguacate, plátano, guayaba, sandía y limón agrio. 
Existe ganado porcino, bovino utilizado para abasto, y lechero, ovino, caprino y equino. 
La actividad pesquera se realiza en los puertos de Barra de Navidad, considerado puerto de cabotaje, en Puerto Vallarta, considerado puerto de altura, y en la laguna de Chapala. Las especies que se obtienen son: huachinango, charal, pescado blanco, tortuga, bagre, carpa, camarón, tiburón, mojarra, rana y popocha. 
Su actividad industrial es extractiva, minero metalúrgica, siderúrgica, maquinaria, equipo y material de transporte, productos químicos, madera, textil, eléctrica y electrónica, material fotográfico, alimentaria, bebidas, tequila, cerveza y calzado.

El turismo en Jalisco ha crecido de una manera significativa en los últimos años.
Guachimontones (o Huachimontones) es un antiguo centro ceremonial y asentamiento prehispánico ubicado en la ciudad y municipio de Teuchitlán, aproximadamente a una hora al oeste de la ciudad de Guadalajara. Este asentamiento fue bautizado así por el nombre del lugar donde se descubrió este primer sitio arqueológico, posteriormente se han descubierto otros asentamientos de la misma tradición Teuchitlán, una compleja sociedad que existió probablemente desde 300 a.C. hasta 900 d.C.
Este centro ceremonial incluye varias construcciones con un estilo arquitectónico peculiar, entre ellas varios túmulos cónicos escalonados o pirámides rodeadas de patios circulares, dos juegos de pelota, un anfiteatro y algunas terrazas y edificios.
La palabra Teuchitlán se deriva de la voz Teotzitlán o Teutzitlán que se interpreta como “lugar dedicado a la divinidad”, “lugar del dios Tenoch” o “lugar dedicado al dios reverenciado”.

Posiblemente la fundación del poblado se remonta a los aztecas que lo erigieron en un cerro denominado Huachimontón, al norte de su actual asiento.2 Fue fundado por integrantes de las tribus nahuatlacas que colonizaron el centro de México en el periodo postclásico, sin embargo se sabe que las construcciones vecinas a Teuchitlán son anteriores a tal colonización. La cultura creadora de las construcciones en Guachimontones recibe el nombre de tradición Teuchitlán, y tuvo su período de apogeo entre los años 200 y 400 d. C, desapareciendo hacia el año 900 d. C., posiblemente antes del arribo de los colonizadores náhuatl.

Además, de dicho asentamiento, en el centro del estado y en Los Altos de Jalisco se localizan restos de poblados ya en deterioro en los poblados de Valle de Guadalupe, Zapopan, Atotonilco el Alto, Cerro del Chiquihuitillo en Pegueros, Cerro encantado en Teocaltiche y Teocaltitlán de Guadalupe en Jalostotitlán, que su mayor influencia arquitectónica tuvo relatividad a los pueblos chichimecas y a la cultura chupícuara del estado de Guanajuato.



En Jalisco se localiza la segunda ciudad más poblada del país, Guadalajara, que junto con Tlaquepaque, Tonalá, El Salto, Tlajomulco de Zúñiga y Zapopan forman la zona metropolitana de la ciudad. El estado muestra una imagen comercial importante debido a su sistema de comunicaciones y vías férreas, que reflejan un factor importante para ampliar su desarrollo.

El municipio de Villa Hidalgo, el cual está localizado en Los Altos de Jalisco forma una gran importancia en la economía tanto como del estado y del país ya que ocupa el tercer lugar en importancia textil en todo el país, ahí se confeccionan principalmente prendas de tejido de punto.

Jalisco cuenta con los siguientes destinos carreteros: Guadalajara-Mazatlán-Nogales; Ciudad Juárez-Zacatecas-Lagos de Moreno-Oaxaca-Tapachula y Guadalajara-México-Veracruz. Cuenta con instalaciones portuarias que aprovechan las condiciones naturales del estero El Salado en Puerto Vallarta, dentro de la bahía de Banderas. Se conecta con los puertos de Manzanillo y Mazatlán. Posee dos aeropuertos internacionales: el de Guadalajara y Puerto Vallarta, los cuales sitúan a Jalisco dentro de las rutas internacionales más importantes.

Jalisco es uno de los estados más típicos del país, ya que es el símbolo del tequila, mariachi, charrería y mujeres bellas. Es un estado geográficamente privilegiado ya que cuenta con playas como Puerto Vallarta, Barra de Navidad, Melaque, Costalegre y Tenacatita. Así mismo cuenta con el lago más grande de México que es Chapala donde se pueden encontrar pueblos típicos como Chapala, Ajijic, Jocotepec y Tizapan el Alto. En el ámbito de turismo religioso cuenta con tres de los centros Marianos más visitados en México; San Juan de los Lagos (Virgen de San Juan), Zapopan (Virgen de Zapopan) y Talpa de Allende (Nuestra Señora del Rosario), otros centros religiosos como el Santuario de Santo Toribio Romo (Mártir de la revolución cristera) en Jalostotitlán. 

Las comunicaciones y transportes son dos actividades importantes para el desarrollo social y económico del Estado, ya que su función primordial es la de facilitar la integración social y geográfica del territorio para el traslado de personas y bienes.

La ubicación geográfica de Jalisco en el Occidente de la Nación Mexicana es estratégica, lo que le ha valido una privilegiada comunicación, tanto con el Centro, Sur, Este, Norte de la Nación, como con los Puertos del Pacífico, con las entidades vecinas y al interior del Estado.

La participación de las comunicaciones en la formación del Producto Interno Bruto ha generado el 6% del Estado. La estructura interna de este sector ha experimentado algunos cambios, puesto que la evaluación de las actividades tradicionales de correos y telégrafos, se ha visto contrarrestada ante el rápido crecimiento de la infraestructura telefónica, actividad que aumentó su importancia de manera considerable para 1997. Este aumento pone de manifiesto la integración e intercomunicación que a través de este medio está teniendo la entidad.

El Estado se encuentra comunicado por una amplia red de carreteras, a través de las cuales integra a la entidad con el resto del país y que, conjuntamente con las carreteras estatales, permite comunicación con las 125 cabeceras municipales de la entidad, en una extensión de 25.303.098 km, de los que 5,148.28 km corresponden a carreteras libres; 5,148.28 km de red Federal y 3,095.46 km de red estatal; carreteras de cuota 566.10 km; 5,433.70 km a caminos rurales y 14,155.90 de brechas. Sus principales vías de comunicación vinculan a la entidad con el interior de Jalisco, con la capital de la República y con los principales centros industriales, tales como Monterrey, N.L., Saltillo y Torreón, Coah.; Querétaro, Qro.; León y Salamanca, Gto.; San Luis Potosí y el noroeste, centro y sur del país.

El avance logrado en la construcción de caminos, ha impulsado notoriamente a los municipios que se vincularon a la red carretera, los que experimentaron un aumento en su nivel de desarrollo, dado principalmente en las regiones de alto potencial, lo que tuvo un efecto acelerador de la dinámica social y económica de las zonas favorecidas entre las regiones.

La capital del estado cuenta con una eficiente red vial, sobre todo en las vías de entrada y salida a la ciudad, así como de vías rápidas que la cruzan, en las que se localizan los pasos a desnivel en los cruces de las vías de ferrocarril y en vías rápidas.


Igualmente existe la vía cuota y libre a Colima, que conecta municipios como Sayula y Zapotlán El Grande con la capital del Estado.



La carretera León-Lagos de Moreno-Aguascalientes y la continuación de la carretera Lagos de Moreno- San Luis Potosí. Así mismo, la carretera Guadalajara-Colotlán, con los ramales a San Martín de Bolaños y Mezquitic, que integran a la región Norte con el resto del estado.

En la red ferroviaria convergen tres ejes ferroviarios, que une a la entidad con las regiones del Norte de la república, hasta la frontera con los Estados Unidos de Norteamérica; al sur permitiendo comunicación con el Puerto de Manzanillo y con el Centro de la república a través de la línea Guadalajara-México. El Estado cuenta con una longitud de red ferroviaria de 153.22 km de vías. El sistema ferroviario en la entidad establece vinculación a través de las líneas: Guadalajara-Ocotlán- La Barca-México, Línea en que se localiza la mayor parte de la industria de Jalisco, ya que establece comunicación con el Corredor Industrial del Salto. La segunda línea en importancia vincula a Guadalajara con el puerto de Manzanillo, Colima, uniendo a Guadalajara con Zacoalco de Torres, Sayula, Zapotlán El Grande y Tuxpan. La tercera comunica a Guadalajara con el noroeste del país hacia la frontera norte con los Estados Unidos de Norteamérica por Mexicali, B.C. y Nogales, Son.

Es innegable la importancia del crecimiento de la infraestructura aérea, a pesar de las buenas comunicaciones terrestres en la entidad. Este incremento se ve reflejado no solo en cuanto al movimiento de pasajeros, sino también en el de transporte de express y carga. La aviación comercial comunica al Estado por medio de un importante número de compañías aéreas nacionales y extranjeras. Para ello cuenta con dos aeropuertos internacionales operados por el grupo aeroportuario del pacífico, el aeropuerto internacional de Guadalajara Don Miguel Hidalgo, el aeropuerto internacional de Puerto Vallarta Lic. Gustavo Díaz Ordaz, el aeropuerto nacional de Unión de San Antonio, Lic. Primo de Verdad y Ramos así como también una aeropista de mediano alcance en Colotlan, Tuxpan, Mascota y recientemente en Tomatlan.

El Aeropuerto Internacional de Guadalajara "Miguel Hidalgo", ubicado en el municipio de Tlajomulco de Zúñiga, se encuentra a 13 km de la ciudad de Guadalajara.

El transporte aéreo en el interior Estado toma también relevancia, ya que cubre las áreas en donde la comunicación terrestre se encuentra escasamente desarrollada. Este transporte de aeronaves pequeñas, se apoya en una terminal anexa al Aeropuerto Internacional de Guadalajara y en 63 aeropistas localizadas en los diversos destinos dentro del Estado, conectando a lugares como: Zapotlán el Grande, Talpa, La Barca, Mascota, Autlán, Barra de Navidad, entre otras.

Jalisco cuenta con un Puerto Marino: Puerto Vallarta, considerado tanto pesquero y de turismo, como de tráfico de altura; últimamente ha adquirido cierta importancia comercial. No obstante, la producción de Jalisco se mueve hacia los mercados exteriores a través del Puerto de Manzanillo localizado en el estado de Colima a 313 kilómetros de Guadalajara por la autopista Guadalajara-Colima, el cual proporciona servicios de altura y cabotaje. Con la reconstrucción y modernización del puerto mencionado, se asegura un tráfico marítimo más fluido y una protección y cuidado mayor a las mercancías.

Las telecomunicaciones han tenido un amplio desarrollo en los últimos años, estando Jalisco comunicado por la red nacional y con el resto del mundo.

El Estado cuenta con una eficiente red telegráfica y postal, así como con un amplio sistema telefónico que permita la comunicación fluida de mensajes, tanto al interior del Estado como al resto del país e internacionalmente, y con un sistema de radiocomunicación que permite integrar aquella área donde la instalación de otros servicios resulta demasiado onerosa.

La Zona Metropolitana de Guadalajara se encuentra unida a la red nacional e internacional de telmex y microondas que constituye la columna vertebral de las telecomunicaciones en el país, canalizado a través del sistema de servicios de teleseñalización, telecontrol, teleinformación y al sistema telefónico de larga distancia, lo que le ha permitido una comunicación mayor con otras grandes ciudades del interior del país y el resto del mundo.

En general todas las cabeceras municipales tienen servicio de correo, quedando por ser incorporadas algunas localidades debido al incremento en la población.

El servicio telefónico es la actividad que presenta más participación y mayor dinamismo en su crecimiento: (7.5% promedio anual del sector). En diciembre de 1997, la cobertura telefónica se incrementó en más de 51,000 líneas con respecto a 1996; en este último año quedaron digitalizadas el 100% de las líneas en la Zona Metropolitana de Guadalajara. El servicio se concentra en la parte central del Estado, principalmente en la Zona Metropolitana de Guadalajara que en marzo de 1998 absorbían 409,969 líneas residenciales instaladas, 61,259 líneas comerciales instaladas y contaban con 52,435 líneas disponibles. En las áreas rurales se ha visto incrementado el servicio, tratando de integrar a las zonas más aisladas, y en las urbanas, se considera suficiente para cubrir la demanda.

En 1998 en el Estado existían 13.47 líneas por cada mil habitantes.

La cocina jalisciense ha contribuido ampliamente a dar fama internacional a la gastronomía mexicana. Los platillos jaliscienses tienen una relación directa con los productos locales como el maíz, el fríjol, la calabaza, el trigo, el agave y los árboles frutales.

Algunos de los platillos más representativos son: la birria, el pozole blanco o rojo, los sopes, el guacamole, frijoles charros, el menudo, las tortas ahogadas, la carne en su jugo, las enchiladas rojas y verdes, los tamales de elote, el borrego al pastor y los tamales de frijol entre mucha más variedad. Uno de los platillos que se han incorporado en las últimas décadas son los tacos al pastor, sobre todo en el municipio de Atotonilco el Alto, aunque el municipio de Arandas es también reconocido por sus tacos.

Entre sus dulces sobresalen el alfajor, palanquetas de cacahuate o pepitas de calabaza, cocadas, dulces en conserva, dulces de leche, la jericalla, perones enmielados rojos, algodones, buñuelos, camote y calabaza enmielada.

Mientras que en sus bebidas el tequila, aguamiel, pulque, tejuino y aguas frescas de horchata y de frutas naturales, marcan la distinción.

La cocina jalisciense es un espacio en el que se unen, por un lado la elaboración de platillos, en los que se distinguen los guisados, salsas, aún las más picantes, dulces y bebidas que se destacan por su apariencia y exquisito sabor, por otro lado los utensilios y productos necesarios para su preparación.

El mariachi es por excelencia un icono jalisciense y de la mexicanidad destacándose el más viejo e internacional " Vargas de Tecalitlán ", cuyo fundador fue don Silvestre Vargas.
Es variable de acuerdo al municipio, pero es predominante en la totalidad de ellos, el traje de charro para los hombres y para las mujeres, el vestido de listones , ya que se utilizan algunas veces para bailar con esa vestimenta , como el Son de la Negra, la Culebra, el Tranchete, etc. 

En Jalisco se produce una gran variedad de artesanías que han dado fama a numerosos pueblos, como los equipales de Zacoalco de Torres, las conservas y lácteos de Tapalpa, los bordados y dulces de los Altos, los artículos de "pita" de Colotlán, la cerámica de Tlaquepaque y Tonalá, entre otras.
Los artículos artesanales son de tal belleza y calidad que han sido muy bien aceptados en el extranjero a donde se exportan.
Estos objetos son elaborados en talleres adaptados en las viviendas donde generalmente participa toda la familia y la técnica para su realización es transmitida de generación en generación.

Entre las artesanías encontramos: Ropa típica de vestir que tiene demanda internacional, joyería, huaraches y sandalias de playa, muebles de madera, curiosidades de conchas y alfarería, aretes y pulseras, anillos y collares de chaquira, alfarería, talabartería; sillas de montar, bordados de tela y pita en cinturones, fundas portanavajas, hebillas de cuero, morrales etc. (piteado), loza de barro, petates y canastas de carrizo, sombreros de soyate y palma, tejidos de lana (sarapes y gabanes), deshilados, rebozos, etc.

Con frecuencia se dice que el deporte nacional de los mexicanos es la charrería, no se atribuye su origen dentro del estado pero si es el estado de Jalisco el que mayor emblema le ha dado a este deporte. Es derivado de las faenas de los caporales en las haciendas ganaderas. Su origen data de la época colonial, y se atribuye a Maximiliano de Habsburgo, segundo emperador de México, la creación del traje de charro en su forma definitiva. La práctica de la charrería está limitada a un sector muy pequeño de la población, debido al elevado costo de la manutención del caballo y de los aperos necesarios (indumentaria, accesorios). El reconocimiento como deporte nacional es más bien honorífico, porque como otros supuestos símbolos mexicanos, no tiene declaración oficial. La versión popular de la charrería es el jaripeo, presente en casi todas las fiestas de los pueblos.

El fútbol es el deporte con más afición en la entidad. Los dos clubes profesionales más populares son el Club Deportivo Guadalajara ("Chivas") y Atlas de Guadalajara ("Zorros"), que se han destacado en la Primera División Mexicana y se enfrentan en el Clásico Tapatío. En tanto, los Leones Negros de la Universidad de Guadalajara disputan actualmente la Liga de Ascenso, Los Tecos de la Universidad Autónoma de Guadalajara y el Club Deportivo Tepatitlán de Morelos militan actualmente en la Serie A de México y el Club Deportivo Oro en la Tercera División Mexicana.

En cuanto al béisbol, los Charros de Jalisco han ganado la Liga Mexicana de Béisbol en 1967,1971 y 2018. En la temporada 2014-15 pasó a disputar la Liga Mexicana del Pacífico donde es el actual campeón.

El boxeo y la lucha libre gozan igualmente de buena reputación. En la primera disciplina hay boxeadores jaliscienses, como Saúl "el Canelo" Álvarez.

La fiesta taurina es también muy seguida, sobre todo en el centro del país, siendo la plaza más importante la Monumental Plaza de Toros de Guadalajara, también conocida como Plaza de Toros "Nuevo Progreso" del arquitecto tapatío José Manuel Gómez Vázquez Aldana y otras plazas importantes como la de Jalostotitlán y Autlán de Navarro en sus carnavales.

Por otra parte, la ciudad de Guadalajara obtuvo ser sede de los Juegos Panamericanos de 2011 que se realizaron en octubre, siendo este el evento deportivo de mayor trascendencia e importancia en el continente americano. 

De igual forma, Guadalajara ha sido sede del evento de fútbol más grande del orbe, el Mundial, pues tanto en el mundial México 1970 como en el de 1986 el Estadio Jalisco albergó diversos partidos de dichas justas mundialistas.

El estado ha firmado los siguientes acuerdos de hermanamiento:







</doc>
<doc id="1581" url="https://es.wikipedia.org/wiki?curid=1581" title="Juegos de azar">
Juegos de azar

Los juegos de azar son juegos en los cuales las posibilidades de ganar o perder no dependen exclusivamente de la habilidad del jugador, sino que interviene también el azar. Es son también juegos de apuestas, cuyos premios están determinados por la probabilidad estadística de acertar la combinación elegida; mientras menores sean las probabilidades de obtener la combinación correcta mayor es el premio.

Existen juegos de azar donde la habilidad del jugador puede influir en el desarrollo del juego, como ocurre en los juegos de naipes como el póquer. No obstante el resultado del final del juego depende del azar y las cartas que toquen a cada jugador.

Por cierto tiempo, el premio más elevado otorgado por un juego de azar fue dado en Estados Unidos, en 1998, con 295 millones de dólares, que fue repartido entre 13 operarios; pero esta marca fue superada por otro caso en el año 2012, en el que el ganador obtuvo casi 656 millones de dólares.

Principalmente es útil la destreza del jugador para calcular las posibilidades que se deriven de una o varias acciones, en relación siempre con el azar; además, el jugador debe ser hábil para reducir la probabilidad de resultados desfavorables y aumentar la de los favorables mediante sus acciones. Sin embargo, el componente impredecible que es el azar puede arrebatar la victoria hasta al jugador más experimentado y diestro. 

Los sumerios y asirios utilizaban un hueso extraído del talón de animales denominado astrágalo o talus, que tallaban para que pudieran caer en cuatro posiciones distintas. Los juegos con dados se originaron en los tiempos del Imperio Romano, aunque no se conoce apenas las reglas con las que jugaban. Uno de estos juegos, denominado "hazard", palabra que en inglés y francés significa riesgo o peligro, fue introducido en Europa con la Tercera Cruzada. Las raíces etimológicas del término provienen de la palabra árabe "al-azar", que significa "dado".

El bingo consiste en un bombo con un número determinado de bolas numeradas en su interior (normalmente 75 o 90). Los jugadores juegan con cartones con números aleatorios escritos en ellos, dentro del rango de bolas correspondiente. Un locutor o cantor va sacando bolas del bombo, cantando los números en voz alta. Si un jugador tiene dicho número en su cartón lo tacha, y el juego continua así hasta que alguien consigue marcar todos los números de una línea y el cartón. Cuando un jugador completa el cartón, grita «¡bingo!»; si es el primero que lo hace gana el premio mayor.

La probabilidad de obtener una línea o el cartón entero depende del número de cartones que están interviniendo en el juego, por lo que dependerá del número de personas que estén jugando así como del número de cartones con que cada participante juegue. Como en este juego se sacan número hasta que alguien “canta bingo”, es decir, posee el cartón con todos los números tachados, la probabilidad depende del número de cartones en juego, así como, del control del jugador sobre sus cartones.

Este sencillo juego, también llamado volado, cara o sello, consiste en lanzar sobre una superficie horizontal una moneda al aire y gana el que eligió la cara vista hacia arriba. Comúnmente se dice que al haber solo dos posibles elecciones, la probabilidad de acierto es del 50%.

Aunque con más rigor, según un estudio llevado a cabo por el matemático Persi Diaconis, la verdadera probabilidad es de 51% frente a 49%, siendo la cara que se encuentra boca arriba la que posee una probabilidad mayor de salir.

No obstante, se puede dar un último caso, extremadamente poco probable, que es "de canto" y se produce cuando la moneda no cae ni de cara ni de cruz, se queda, como la misma palabra dice, de canto, sujeta por el borde de la moneda impidiendo que se vea alguna cara superponiéndose a la otra, bien es cierto que esta opción se puede desestimar, ya que tiene validez solo en condiciones perfectas de lanzamiento, con un suelo perfectamente liso, sin viento, ni ningún otro factor irregular, la moneda podría quedar así una vez por cada 6.000 lanzamientos. Aunque por supuesto un suelo irregular puede llegar a facilitar esta opción, como ya se vio en el sorteo de campos del partido de fútbol de la Copa América 2016 disputado entre Colombia y Paraguay, donde se pudo ver la moneda caer de canto.

Los sumerios y asirios utilizaban un hueso extraído del talón de animales como ovejas, ciervos o caballos, denominado astrágalo o talus, que tallaban para que pudieran caer en cuatro posiciones distintas, por lo que son considerados como los precursores de los dados.

El juego de los dados consiste en lanzar un objeto de forma poliédrica sobre una superficie horizontal. Los posibles resultados numéricos están marcados en cada una de las caras del poliedro y se eligen tomando, normalmente, el resultado marcado en la cara que queda vista hacia arriba. El dado más convencional cuenta con seis caras por lo que la probabilidad de obtener un número (de los 6) es de 1 entre 6, es decir, 16,67%.En China y la India se jugaban los dedos de la mano a los dados.

Su origen se remonta al siglo XV cuando los comerciantes genoveses idearon este sistema como estrategia de venta, al estar constituidos los premios por mercancías.

En un sorteo de un cupón, la probabilidad de que te toque depende, del número de billetes en juego, así como del número de series. Como ejemplo se pondrá el sorteo extraordinario de Navidad en España, donde se ponen en juego 170 series de 85.000 billetes, de los cuales 13.334 se llevan premio. La probabilidad de que nos toque el premio mayor con un solo cupón es de 1 entre 14 millones y medio (170 series x 85.000 billetes).La cuantía del premio a recibir no solo depende de la probabilidad de acierto, sino también del porcentaje que se devuelva como premio de la cantidad jugada, que suele ser de un 70%

En cuanto a las quinielas, su acierto depende del número de posibilidades o posibles elecciones. Si hacemos una apuesta sencilla, tenemos que hacer frente a 3 elevado a la 14 de casos posibles, ya que en cada uno de los catorce partidos tenemos tres posibles resultados: 1, X, 2. Por lo tanto, hay que dividir nuestra apuesta (1) entre todas las posibilidades (3 a la 14), con lo que para llevarse el premio hay una probabilidad de 1 entre casi 5 millones. La diferencia con otras formas de apuestas es que aquí, además del azar, existe una mayor probabilidad de acierto, que depende de la diferencia entre los equipos de fútbol en juego.

En este tipo de lotería, se tiene una serie de números, de los cuales una cantidad son los que resultan ganadores. En el caso de que sean 49 y seis los ganadores, la probabilidad que hay de ganar el premio máximo con una apuesta sencilla es de 1 entre 13.983.816, es decir, las posibles combinaciones de 6 números sobre 49 números.

Este juego a cambio de una cantidad de dinero se ofrece ocasionalmente un premio. Existen de dos tipos: las máquinas programadas (habituales en salones de juego y bares), en la que, según un programa interno, después de un número de juegos, la máquina ha de devolver una parte del ingreso que se ha realizado (en torno al 70%); las máquinas de azar (habituales en casinos), en las que dependen exclusivamente del azar. El mayor premio de una tragaperras fue dado en Atlantic City (Estados Unidos) con más de diez millones de dólares, que se habían acumulado como «bote» durante años, y a cambio de solo una moneda de cinco centavos.

El juego de la ruleta, típico de los casinos, debe su origen al matemático francés Blaise Pascal, de ahí que su nombre viene del término francés roulette, que significa rueda pequeña. En un principio poseía 36 números (la suma de los primeros 36 números da el número mágico por excelencia: 666) y a finales del siglo XIX, los hermanos Blanc la modificaron añadiéndole un nuevo número, el 0, y la introdujeron inicialmente en el Casino de Montecarlo. Esta ruleta cuenta con una proporción de premios de 36/37, que deja un margen para la casa del 2,7% (en Europa, Ruleta Europea) o el 5,4% (en EE.UU., Ruleta Americana) si cuenta con dos ceros. También esta la Francesa– Es una versión muy similar a la ruleta europea. Se diferencia sobre todo en la composición de la mesa.



</doc>
<doc id="1583" url="https://es.wikipedia.org/wiki?curid=1583" title="Juego abstracto">
Juego abstracto

Se identifica como juego abstracto a todo aquel juego en el que no existe un tema o ambientación asociado. Esto es: aquellos en los que los elementos de juego —fichas, dados, tablero, etc.— no representan el comportamiento y características de seres u objetos reales ni imaginarios.

No obstante lo anterior no es infrecuente que, al menos en algunos de los juegos abstractos de mayor antigüedad como el go, el ajedrez o el juego del molino, exista un tema de origen que con el tiempo ha ido perdiendo su representación en la mecánica del juego. Dicha mecánica suele ser simple en cuanto a reglamento, aunque puede permitir un alto grado de complejidad táctica o estratégica.

El término complementario a «juego abstracto» sería juego temático.


</doc>
<doc id="1584" url="https://es.wikipedia.org/wiki?curid=1584" title="Juego temático">
Juego temático

Se denomina juego temático a todo juego que tiene un tema o ambientación asociado. Esto es: a aquel cuyos elementos —fichas, dados, tablero, etc.— representan en alguna medida el comportamiento y características de seres u objetos reales o imaginarios.

El término antónimo a «juego temático» sería «juego abstracto».

Cuando la fidelidad en la representación del tema tratado es alta, con reglas específicas que intentan representar en detalle los comportamientos de cada elemento de juego, los juegos temáticos se conocen también como «juegos de simulación». Este es el caso, por ejemplo, de muchos juegos de tema bélico, en los que cada unidad representada puede llegar a tener reglas específicas que concuerden con las potencialidades o acción real de su contrapartida histórica.

“Herramientas de la Mente” es un currículo de educación infantil que involucra escenarios estructurados de juegos imaginarios y otras actividades. Este currículo tiene como objetivo promover y mejorar la autorregulación y las habilidades académicas de los niños, al tener un doble enfoque en el desarrollo de la autorregulación y de otras habilidades socioemocionales en contextos educativos.

Una revisión sistemática resumió los hallazgos de 6 estudios realizados en Estados Unidos, que contaron con la participación de estudiantes de todas las edades, sexos, etnias, estados socioeconómicos, de dominio del idioma y de educación especial. Los resultados demuestran que el currículo mejoró significativamente las habilidades matemáticas de los niños en comparación con el currículo común. Asimismo, el currículo parece mejorar la autorregulación y la alfabetización, no obstante, dado el pequeño número de estudios incluidos, así como de otras deficiencias metodológicas, estas conclusiones deben tomarse con precaución, por lo que es necesario realizar más investigaciones de alta calidad.

En otros casos, sin embargo, el comportamiento de los elementos de juego sólo se inspira vagamente en el tema que le sirve de inspiración. Este es el caso de muchos de los juegos llamados «de estilo alemán», o «eurogames».



</doc>
<doc id="1586" url="https://es.wikipedia.org/wiki?curid=1586" title="Juego de miniaturas">
Juego de miniaturas

Un juego de miniaturas es un tipo de juego de guerra en el que los elementos móviles del juego (en general miniaturas de plástico o de metal) no se desplazan sobre un tablero dotado de casillas sino sobre una maqueta o un diorama. Mientras que en los juegos de tablero los rangos de las armas y los movimientos de las fichas o miniaturas se contabilizan en casillas, en los juegos de miniaturas las miniaturas se ven desplazadas sobre una superficie no dividida en casillas, por lo que tales rangos y movimientos se contabilizan en centímetros o en otras unidades de medida de las distancias. Otros elementos característicos de esta clase de juegos suelen ser tarjetas que muestran los objetivos por conseguir, pistas o pruebas que superar. Las miniaturas de un juego de miniaturas se comercializan individualmente aunque también pueden comprarse por medio de paquetes sellados con contenido al azar o, al contrario, con un contenido temático determinado.

Existen distintas maneras de clasificar los juegos de miniaturas, como ejemplo nombraremos tres de los criterios que podríamos usar para tal fin:

Por Ambientación:


Por escala de figuras y modelos:


Por escala del conflicto:


Un juego que hace uso de miniaturas no es necesariamente un juego de miniaturas. En general el término «juego de miniaturas» no se aplica a juegos que hacen uso de un tablero cuya superficie esté dividida en casillas, aunque se usen miniaturas en sus partidas. Juegos como "BattleTech", "Heavy Gear" y "Axis & Allies" por ejemplo, no son juegos de miniaturas. Sin embargo hay juegos comercialmente concebidos para incitar al coleccionismo de miniaturas y a los que se designa por tanto como «juegos de miniaturas coleccionables». Esta clase de juegos sí que puede hacer uso de un tablero, como es el caso, por ejemplo, de "MLB SportsClix" (basado en el baseball), "HeroClix" (basado en superhéroes de historieta), "Halo ActionClix" (basado en la serie de videojuegos "Halo") y "Star Wars Miniatures" (basado en el universo de "Star Wars").



</doc>
<doc id="1590" url="https://es.wikipedia.org/wiki?curid=1590" title="Jijona">
Jijona

Jijona (en valenciano y oficialmente Xixona) es un municipio español situado en el interior de la provincia de Alicante, en la Comunidad Valenciana, España. Mundialmente famoso por ser el lugar donde se produce el apreciado dulce navideño del turrón, tanto la variedad de Jijona como la de Alicante. Cuenta con 6875 habitantes (INE 2018).

Situada 25 km al norte de Alicante, la villa está enclavada en las faldas de la Peña Roja. En su término municipal se encuentran el puerto de la Carrasqueta, paso natural (1020 metros al paso de la carretera N-340 para comunicar Alicante con Alcoy). En cambio, el pico de la Carrasqueta se encuentra en Ibi con una altura de 1205 msnm.

Por la parte sudoeste del término pasa el río Montnegre, que proveniente del pantano de Tibi se dirige hacia la Huerta de Alicante. A su paso por el municipio jijonenco se encuentra la pequeña pedanía de Montnegre.

El término municipal está poblado de inmensos bosques de pinos y carrascas en altas montañas de más de 1000 msnm, siendo su punto más alto en la sierra del cuartel 1243 msnm. Lo que da lugar a espectaculares vistas de valles y barrancos en vertical, así como del mar Mediterráneo, debido a su cercanía; sin embargo, otras partes de su término municipal, las más próximas a la costa, sufren de una desertización preocupante.

Tiene un clima mediterráneo seco con inviernos frescos y veranos calurosos. Las precipitaciones son muy escasas, muestra de ello el paisaje subdesértico que posee, con bad-lands, ramblas... Puede sufrir la gota fría en otoño, siendo las épocas más lluviosas la primavera y el otoño. Su paisaje se puede considerar como un subdesierto.

Los primeros indicios de vida humana en el término municipal de Jijona se remontan a la Edad de Bronce (2000-1300 a. C.). La época ibérica marca la culminación de la ocupación del territorio en la Edad Antigua, de la cual hemos de resaltar los grandes poblados de Santa Bárbara y de la "Solaneta de Nuches". En esta época el nombre actual de la ciudad empieza a tomar forma, ya que parece ser era conocida como "Uxonig" (Valle del hierro).

La época paleoandalusí se caracteriza por la existencia de un poblamiento rural disperso, asentado en altura y en las proximidades de una importante vía de comunicación entre los acuíferos de Alecua y Nutxes, del que sólo se han encontrado sus enterramientos, en los yacimientos de "l'Altet, Mas dels Constantins" y "Cotelles".

El actual emplazamiento de la ciudad se remonta a la época almohade, entre finales del siglo XII y comienzos del siglo XIII, siendo el núcleo originario el castillo. 

Se trata de una ciudad históricamente marcada por su condición fronteriza, ya que desde el Tratado de Almizra (1244) se la consideró plaza límite de la Corona de Aragón con la de Castilla. Población árabe llamada "Sexona", que presentaba un castillo almohade del que aún quedan las ruinas, fue conquistada a mediados del siglo XIII, y el 28 de abril de 1268 se le concedió el título de villa real y pasó a tener representantes en las Cortes del Reino de Valencia. En 1337 participó en las Cortes de Valencia convocadas por Pedro IV, rey que se preocupó especialmente de fortificar su castillo en 1338, previendo una invasión musulmana que no se produjo.

En la guerra entre los dos Pedros, cayó en 1364 en manos de Pedro I el Cruel, rey de Castilla, para ser de nuevo reconquistada por Pedro IV el Ceremonioso, quien contó con la ayuda de gentes naturales de Penáguila, Alcoy y Cocentaina, pasando a formar parte de nuevo de la Corona de Aragón.

Durante el siglo XV, Jijona amplió su jurisdicción mediante la adquisición a sus señores feudales de los lugares de Ibi y Torremanzanas. Ibi permaneció bajo la jurisdicción de Jijona desde 1420 hasta 1629, mientras que Torremanzanas lo hizo desde 1472 a 1794. 

Durante la Guerra de Sucesión, fue una villa marcadamente proborbónica, por lo que opuso una fuerte resistencia a las tropas del archiduque Carlos, que asediaron Jijona y obligaron a los habitantes a la rendición en el año 1706. Sin embargo, la población que consiguió huir a las montañas realizó una contraofensiva que terminó con la conquista de la plaza en el 1707. Gracias a su lealtad a Felipe V, éste le otorgó a Jijona los títulos de "Ciudad" y de "leal y fidelísima" en 1708 así como la concesión de añadir a sus Armas una "Flor de Lis". A partir de ese año fue capital del Corregimiento del mismo nombre, el cual comprendía a las ciudades de Jijona y Elche y las villas de Castalla, Biar, Tibi, Ibi y Onil, y los lugares de Torremanzanas, Salinas y Benejama. El Corregimiento de Jijona fue suprimido definitivamente en 1833, con la división provincial.

Por su importancia histórica, el municipio fue dotado de una gran extensión municipal, por lo que Jijona conserva el 5º mayor término municipal de la provincia de Alicante. De su municipio se segregaron durante el siglo XVIII el pueblo de Torremanzanas y el pequeño lugar de La Sarga, en el norte del término; este último volvió a unirse a Jijona unos años después.

Jijona cuenta con 7.575 habitantes (INE 2008).
La población fluctúa según la estación del año; en verano el número de habitantes es menor.

Tradicionalmente, la economía jijonenca se ha basado en una dualidad entre la producción y comercialización de helados en verano y la de turrón en invierno, complementada por la agricultura de secano, en la cual destacaba el cultivo del almendro, cuyo fruto es materia prima para el turrón. Durante los siglos XIX y XX, ha sido natural que durante gran parte del año muchos jijonencos se encontrasen repartidos por toda España o incluso Cuba y otras partes de Iberoamérica vendiendo sus helados y turrones. Existen muchas marcas artesanas y fábricas de turrón. 

Aunque el desarrollo de la economía de la ciudad hoy en día sigue basándose en sus turrones y helados, conocidos en el mundo entero, la fábrica más importante en la localidad es propiedad de Procter & Gamble, fabricante de marcas de higiene íntima.


En las elecciones de 1995 PP y PSOE quedaron en un empate técnico respecto al número de concejales, aunque las elecciones las ganó el partido popular. Esto obligó al PP a pactar con el CIX (independentistas de Xixona). A mitad de legislatura el PSOE pactó con el CIX y arrebataron la alcaldía al PP, que ganó por mayoría simple en 1999, sacando 6 de los 13 concejales del ayuntamiento. Actualmente gobierna el PSOE con mayoría simple.

Se celebran fiestas de Moros y cristianos en agosto. En octubre hay otras fiestas de Moros y Cristianos llamadas "Fiestas de los Heladores", ya que están hechas para los heladores que en verano trabajan.

Las fiestas patronales de la localidad, de Moros y Cristianos, se celebran en agosto, en el fin de semana más cercano al día 24, San Bartolomé, copatrono de Jijona junto a San Sebastián.




</doc>
<doc id="1591" url="https://es.wikipedia.org/wiki?curid=1591" title="Johann Sebastian Bach">
Johann Sebastian Bach

Johann Sebastian Bach (Eisenach, en la actual Turingia, Sacro Imperio Romano Germánico, -Leipzig, en la actual Sajonia, Sacro Imperio Romano Germánico, ) fue un compositor, organista, clavecinista, director de orquesta, violinista, violagambista, maestro de capilla, "cantor" y profesor alemán del período barroco.

Fue el miembro más importante de una de las familias de músicos más destacadas de la historia, con más de 35 compositores famosos. Tuvo una gran fama como organista y clavecinista en toda Europa por su gran técnica y capacidad de improvisar música al teclado. Además del órgano y del clavecín, tocaba el violín y la viola da gamba.

Su fecunda obra es considerada la cumbre de la música barroca; destaca en ella su profundidad intelectual, su perfección técnica y su belleza artística, además de la síntesis de los diversos estilos nacionales de su época y del pasado. Bach es considerado el último gran maestro del arte del contrapunto y fuente de inspiración e influencia para posteriores compositores y músicos, tales como como Joseph Haydn, Wolfgang Amadeus Mozart, Ludwig van Beethoven, Felix Mendelssohn, Robert Schumann y Frédéric Chopin, entre muchos otros.

Entre sus obras más conocidas se encuentran los "Conciertos de Brandeburgo", "El clave bien temperado", la "Misa en si menor", la "Pasión según San Mateo", "El arte de la fuga", "Ofrenda musical", las "Variaciones Goldberg", la "Tocata y fuga en re menor", varios (entre ellas las célebres "Wachet auf, ruft uns die Stimme, BWV 140" y "Herz und Mund und Tat und Leben, BWV 147"), el "Concierto italiano, BWV 971", la "Obertura en estilo francés, BWV 831", las "Suites para violonchelo solo", las "Sonatas y partitas para violín solo", los "Conciertos para teclado" y las "Suites para orquesta".

Johann Sebastian Bach perteneció a una de las más destacadas familias musicales de la historia. Durante más de doscientos años la familia Bach produjo buenos intérpretes y compositores. En aquella época, la Iglesia luterana, el gobierno local y la aristocracia daban una significativa aportación para la formación de músicos profesionales, particularmente en los electorados orientales de Turingia y Sajonia. El padre de Johann Sebastian, Johann Ambrosius Bach, era un talentoso violinista y trompetista en Eisenach, una ciudad con cerca de 6000 habitantes en Turingia. El puesto involucraba la organización de la música profana y la participación en la música eclesiástica. Los tíos de Johann Sebastian eran todos músicos profesionales, cuyos cargos incluían organistas de iglesia, músicos de cámara de la corte y compositores. Bach era consciente de los logros musicales de su familia y hacia 1735 esbozó una genealogía, "Ursprung der musikalisch-Bachischen Familie" ("Origen de la familia musical Bach"), buscando la historia de las generaciones de los exitosos músicos de su familia.

Johann Sebastian Bach nació en Eisenach, en el Ducado de Sajonia-Eisenach (en la actual Turingia, Alemania), el 21 de marzo de 1685, el mismo año que Georg Friedrich Händel y Domenico Scarlatti. La fecha de su nacimiento corresponde al calendario juliano, pues los alemanes aún no habían adoptado el calendario gregoriano, por el cual la fecha corresponde al 31 de marzo. Fue el octavo hijo (el hijo mayor tenía 14 años cuando Johann Sebastian nació) del matrimonio formado entre Maria Elisabetha Lämmerhirt y Johann Ambrosius Bach, director de los músicos de la ciudad. Su padre fue quien probablemente le enseñó a tocar el violín y los fundamentos de la teoría musical. Su tío Johann Christoph Bach lo introdujo en la práctica del órgano.

Su madre falleció en 1694, cuando Johann Sebastian tenía nueve años, y su padre —que ya le había dado las primeras lecciones de música— falleció ocho meses después. Johann Sebastian, huérfano con diez años, se fue a vivir y estudiar con su hermano mayor, Johann Christoph Bach, organista en la iglesia de San Miguel ("Michaeliskirche") de Ohrdruf, una ciudad cercana. Allí copiaba, estudiaba e interpretaba música, incluyendo la de su propio hermano, a pesar de estar prohibido hacerlo porque las partituras eran muy valiosas y privadas y el papel de ese tipo era costoso. Aprendió teoría musical y composición, además de tocar el órgano, y recibió lecciones de su hermano, que lo adiestró en la interpretación del clavicordio. Johann Christoph le dio a conocer las obras de los grandes compositores del Sur de Alemania de la época, como Johann Pachelbel (que había sido maestro de Johann Christoph) y Johann Jakob Froberger; de compositores del Norte de Alemania; de los franceses, como Jean-Baptiste Lully, Louis Marchand y Marin Marais, así como del clavecinista italiano Girolamo Frescobaldi. También en esa época estudió teología, latín, griego, francés e italiano en el "gymnasium" de la localidad.
En 1700, a sus catorce años de edad, Johann Sebastian fue premiado, junto a su amigo del colegio Georg Erdmann, dos años mayor que él, con una matrícula para realizar estudios corales en la prestigiosa Escuela de San Miguel en Luneburgo, no muy lejos del puerto marítimo de Hamburgo, una de las ciudades más grandes del Sacro Imperio Romano. Esto conllevaba un largo viaje con su amigo, que probablemente realizaron en parte a pie y en parte en carroza, aunque no se sabe con certeza. No hay referencias escritas de este período de su vida, pero los dos años de estancia en la escuela parecen haber sido decisivos, por haberle expuesto a una paleta más amplia de la cultura europea que la que había experimentado en Turingia. Además de cantar en el coro a capella, es probable que tocase el órgano con tres teclados y sus clavicémbalos. Quizás entró en contacto con los hijos de los nobles del Norte de Alemania, que eran enviados a esta escuela selectísima para prepararse en sus carreras diplomáticas, gubernamentales y militares.

Aunque existen pocas evidencias históricas que lo sustenten, es casi seguro que durante la estancia en Luneburgo, el joven Bach visitó la iglesia de San Juan ("Johanniskirche") y escuchó (y posiblemente tocó) el famoso órgano de la iglesia (construido en 1549 por Jasper Johannsen, y conocido como «el órgano de Böhm» debido a su intérprete más destacado). Dado su talento musical, es muy probable asimismo que tuviese un significativo contacto con los organistas destacados del momento en Luneburgo, muy particularmente con Georg Böhm (el organista de la "Johanniskirche"), así como con organistas de la cercana Hamburgo, como Johann Adam Reincken y Nicolaus Bruhns. Gracias al contacto con estos músicos, Johann Sebastian tuvo acceso probablemente a los instrumentos más grandes y precisos que había tocado hasta entonces. En esta etapa se familiarizó con la música de la tradición académica organística del Norte de Alemania, especialmente con la obra de Dietrich Buxtehude, organista en la iglesia de Santa María de Lübeck, y con manuscritos musicales y tratados de teoría musical que estaban en posesión de aquellos músicos. Stauffer informó del descubrimiento en 2005 de las tablaturas de órganos que Bach escribió, aun en su adolescencia, de obras de Reincken y Dieterich Buxtehude, que muestra «un adolescente disciplinado, metódico y bien entrenado profundamente comprometido con el aprendizaje de su oficio».

En enero de 1703, poco después de terminar los estudios y graduarse en San Miguel y de ser rechazado para el puesto de organista en Sangerhausen, Bach logró un puesto como músico de la corte en la capilla del duque Juan Ernesto III, en Weimar. No está claro cuál fue su papel allí, pero parece que incluía tareas domésticas no musicales. Durante sus siete meses de servicio en Weimar, su reputación como teclista se extendió tanto que fue invitado a inspeccionar el flamante órgano de la iglesia de San Bonifacio (St.-Bonifatius-Kirche, posteriormente Bachkirche, iglesia de Bach) de la cercana ciudad de Arnstadt, a 40 kilómetros al sureste de Weimar, y a dar el concierto inaugural en él. La familia Bach tenía estrechos vínculos con esta vieja ciudad de Turingia, al lado del bosque de Turingia. En agosto de 1703, aceptó el puesto de organista en dicha iglesia, con obligaciones ligeras, un salario relativamente generoso y un buen órgano nuevo, afinado conforme a un sistema nuevo que permitía que se utilizara un mayor número de teclas. En esa época, Bach estaba emprendiendo la composición seria de preludios para órgano; estas obras, inscritas en la tradición del Norte de Alemania de preludios virtuosos e improvisatorios, ya mostraban un estricto control de los motivos (en ellos, una idea musical sencilla y breve se explora en sus consecuencias a través de todo un movimiento). Sin embargo, en estas obras el compositor aún no había desarrollado plenamente su capacidad de organización a gran escala y su técnica contrapuntística, donde dos o más melodías interactúan simultáneamente.

A pesar de las fuertes conexiones familiares y el hecho de estar empleado por un entusiasta de la música no impidieron que surgiera tensión entre el joven organista y las autoridades después de varios años en el puesto. Johann Sebastian estaba insatisfecho con el nivel de los cantantes del coro. Llamó a uno de ellos «Zippel Fagottist» (fagotista flojo). Una noche, este estudiante llamado Geyersbach fue tras él con un palo. Bach presentó una denuncia contra él ante las autoridades. Absolvieron a Geyersbach con una pequeña reprimenda y ordenaron a Bach que fuera más moderado con respecto a las cualidades musicales que esperaba de sus alumnos. Meses después, su empleador se mostró muy molesto después de que Bach se ausentara de Arnstadt sin autorización durante cuatro meses (había pedido permiso para ausentarse cuatro semanas) en el invierno de 1705-1706 para visitar en Lübeck al gran maestro Dietrich Buxtehude y asistir a sus "Abendmusiken" en la iglesia de Santa María ("Marienkirche"). Este episodio bien conocido de la vida del compositor implica que tuvo que caminar unos 400 kilómetros de ida y otros tantos de vuelta a pie para pasar tiempo con el hombre al que posiblemente consideraba como la figura máxima entre los organistas alemanes. El viaje reforzó el influjo del estilo de Buxtehude como fundamento de la obra temprana de Bach y el hecho de que alargase su visita durante varios meses sugiere que el tiempo que pasó con el anciano tuvo un alto valor para su arte. Johann Sebastian quería convertirse en amanuense (asistente o sucesor) de Buxtehude, pero no quiso casarse con su hija, que era la condición para su nombramiento.

En 1706, le ofrecieron un puesto mejor pagado como organista en la iglesia de San Blas ("Divi-Blasii-Kirche") de Mühlhausen una importante ciudad al norte. El año siguiente tomó posesión de este mejor puesto, con paga y condiciones significativamente superiores, incluyendo un buen coro. A los cuatro meses de haber llegado a Mühlhausen, se casó, el 17 de octubre de 1707, con Maria Barbara Bach, una prima suya en segundo grado, con quien tendría siete hijos, de los cuales cuatro alcanzaron la edad adulta. Dos de ellos —Wilhelm Friedemann y Carl Philipp Emanuel— llegaron a ser compositores importantes en el ornamentado estilo galante que siguió al barroco.

El ayuntamiento de la ciudad aceptó los requerimientos de Bach e invirtió una gran suma en la renovación del órgano de la iglesia de San Blas. En 1708, Johann Sebastian escribió la cantata festiva "Gott ist mein König, BWV 71" para la inauguración del nuevo concejo de la ciudad, cuya publicación fue costeada por el ayuntamiento. En dos ocasiones, en años posteriores, el compositor tuvo que regresar para dirigirla.

Transcurrido apenas un año, en 1708, le llegó una nueva oferta de trabajo como organista desde la corte ducal en Weimar, por lo que abandonó su puesto en Mühlhausen. Allí, tuvo la oportunidad de trabajar con un contingente grande y bien financiado de músicos profesionales. Bach se trasladó con su familia a un apartamento muy cercano al palacio ducal. Ese mismo año nació su primera hija, Catharina Dorothea. Se fue a vivir con ellos la hermana mayor y soltera de Maria Barbara, que permaneció con ellos ayudando en las tareas domésticas hasta su muerte en 1729. También nacieron tres hijos en Weimar: Wilhelm Friedemann, Carl Philipp Emanuel y Johann Gottfried Bernhard. Tuvieron tres hijos más, que sin embargo no vivieron hasta su primer cumpleaños, incluidos los gemelos nacidos en 1713.

Este período en la vida de Bach fue fructífero y comenzó una época de composición de obras para teclado y orquestales. Alcanzó el nivel de competencia y confianza para ampliar las estructuras existentes e incluir influencias del exterior. A la muerte del príncipe Juan Ernesto en 1707, su hermano Guillermo Ernesto había asumido el poder de facto. Por su anterior cercanía con el duque Juan Ernesto, que había sido a su vez un avezado músico y admirador de la música italiana, Bach había estudiado y transcrito las obras de Antonio Vivaldi, Arcangelo Corelli y Giuseppe Torelli, entre otros autores italianos, gracias a lo cual había aprendido a escribir aperturas dramáticas y a emplear los ritmos dinámicos y los esquemas armónicos que se encontraban en dicha música, asimilando su dinamismo y emotividad armónica, y aplicando dichas cualidades a sus propias composiciones, que a su vez eran interpretadas por el conjunto musical del duque Guillermo Ernesto. Absorbió estos aspectos estilísticos en parte mediante la transcripción de conciertos para cuerda y viento para clavecín y órgano de Vivaldi; muchas de esas obras transcritas son todavía interpretadas con frecuencia. Se sintió atraído especialmente con el estilo italiano en el que uno o más instrumentos solistas alternan sección por sección con la orquesta completa a través de un movimiento.

Continuó tocando y componiendo para órgano e interpretando música de concierto con el conjunto del duque. También comenzó a componer preludios y fugas, posteriormente recopilados en su obra monumental "El clave bien temperado" ("Das Wohltemperierte Klavier"), impreso por primera vez en 1801, que consta de dos libros compilados en 1722 y 1744, cada uno de los cuales contiene un preludio y fuga en cada tonalidad mayor y menor. Comenzó a escribir "Orgelbüchlein" ("Pequeño libro para órgano") obra didáctica que dejó inconclusa. Contenía corales tradicionales luteranas arregladas en elaboraciones complejas, para formar organistas.

En 1713, le ofrecieron un puesto en Halle cuando aconsejó a las autoridades durante la renovación de Christoph Cuntzius del órgano principal de la galería oeste de la "Marktkirche Unser Lieben Frauen". Johann Kuhnau y Bach volvieron a tocar cuando se inauguró en 1716. En la primavera de 1714, Johann Sebastian fue ascendido a "Konzertmeister", un honor que implicaba realizar una cantata de iglesia mensualmente en la iglesia del castillo. Las tres primeras cantatas de la nueva serie compuesta por Bach en Weimar fueron "Himmelskönig, sei willkommen, BWV 182", para el Domingo de Ramos, que coincidió con la Anunciación de ese año; "Weinen, Klagen, Sorgen, Zagen, BWV 12", para el Domingo de júbilo; y "Erschallet, ihr Lieder, erklinget, ihr Saiten!, BWV 172" para Pentecostés. Su primera cantata navideña, "Christen, ätzet diesen Tag, BWV 63", se estrenó aquí posiblemente en 1713. o si fue interpretada para el bicentenario de la Reforma Protestante en 1717.

En 1717, ocurre en Dresde el anecdótico intento de duelo musical con Louis Marchand (se dice que Marchand abandonó la ciudad tras escuchar previamente y a escondidas a Bach). Ese mismo año, con motivo del fallecimiento del maestro de capilla (o "Kapellmeister") de la corte de Anhalt-Köthen y con la mediación del duque Ernesto Augusto, el príncipe Leopoldo ofreció a Bach el puesto vacante, que aceptó. Esto disgustó al duque de Weimar y cuando el compositor presentó su renuncia ordenó su arresto por algunas semanas en el castillo antes de aceptarla. Según una traducción del informe del secretario del tribunal, fue encarcelado durante casi un mes antes de ser despedido desfavorablemente:

El príncipe Leopoldo de Anhalt-Köthen contrató a Bach como maestro de capilla en 1717. El príncipe Leopoldo, que también era músico, apreciaba su talento, le pagaba bien y le dio un tiempo considerable para componer y tocar. Sin embargo, el príncipe era calvinista y no solía usar música elaborada en sus misas. Por esa razón, la mayoría de sus obras de este período fueron profanas. Como ejemplo están las "Suites para orquesta", las seis "Suites para violonchelo solo", las "Sonatas y partitas para violín solo" y los "Conciertos de Brandeburgo". También compuso cantatas profanas para la corte, como "Die Zeit, die Tag und Jahre macht, BWV 134a".

A pesar de haber nacido en el mismo año y de estar separados únicamente por alrededor de 130 kilómetros, Bach y Georg Friedrich Händel nunca se conocieron. En 1719, Johann Sebastian realizó un viaje de unos treinta kilómetros desde Köthen hasta Halle con la intención de conocer a Händel, pero este había abandonado recientemente la ciudad. En 1730, Wilhelm Friedemann, el hijo de Johann Sebastian, viajó a Halle para invitar a Händel a visitar a la familia Bach en Leipzig. Sin embargo, dicha visita nunca tuvo lugar. 

El 7 de julio de 1720, mientras Bach estaba de viaje con el príncipe Leopoldo en Karlovy Vary, su esposa, Maria Barbara Bach, murió repentinamente. Algunos especialistas señalan que en memoria de ella compuso la "Partita para violín solo n.º 2, BWV 1004", en especial, su última sección, la «Chacona». Al año siguiente, conoció a Anna Magdalena Wilcke, una joven y talentosa soprano 16 años más joven que él que cantaba en la corte de Köthen. Se casaron el 3 de diciembre de 1721. Juntos tuvieron trece hijos más, seis de los cuales alcanzaron la edad adulta: Gottfried Heinrich, Johann Christoph Friedrich y Johann Christian, que llegaron a ser músicos destacados; Elisabeth Juliane Friederica (1726-81), quien se casó con el alumno de su padre Johann Christoph Altnickol; Johanna Carolina (1737-81); y Regina Susanna (1742-1809).

Johann Kuhnau había sido "Thomaskantor" de la "Thomasschule" en la iglesia luterana de Santo Tomás ("Thomaskirche") de Leipzig desde 1701 hasta su muerte el 5 de junio de 1722. Bach había visitado Leipzig durante el mandato de Kuhnau: en 1714 asistió al servicio en la iglesia de Santo Tomás el primer domingo de Adviento, y en 1717 había probado el órgano de la "Paulinerkirche". En 1716, Bach y Kuhnau se habían reunido con motivo de la prueba e inauguración de un órgano en Halle.

Después de que le ofrecieran el puesto, invitaron a Bach a Leipzig solo después de que Georg Philipp Telemann indicara que no estaba interesado en trasladarse a Leipzig. Telemann fue a Hamburgo, donde «tuvo sus propias luchas con el Senado de la ciudad».

En 1723, Bach fue nombrado "Thomaskantor" y director musical de las principales iglesias de la ciudad, San Nicolás ("Nikolaikirche") y San Pablo ("Paulinerkirche"), la iglesia de la Universidad. Era un prestigioso puesto en la ciudad mercantil líder del Electorado de Sajonia, un electorado vecino de Turingia. Aparte de sus breves ocupaciones en Arnstadt y Mühlhausen, este fue el primer trabajo estatal de Bach, en una carrera que había estado estrechamente ligada al servicio a la aristocracia. Durante ese tiempo, ganó más prestigio a través de nombramientos honorarios en las cortes de Köthen y Weissenfels, así como en la del elector Augusto II de Polonia en Dresde. El compositor con frecuencia no estaba de acuerdo con su empleador, el consejo de la ciudad de Leipzig, al que consideraba «tacaño».

Este puesto, que mantuvo durante 27 años hasta su muerte, lo puso en contacto con las maquinaciones políticas de su empleador, el Ayuntamiento de Leipzig, dentro del cual había dos facciones: los absolutistas, leales al monarca sajón en Dresde, Augusto II de Polonia, y la facción de la ciudad-estado, que representaba los intereses de la clase mercantil, los gremios y los aristócratas menores. Los monárquicos fueron quienes lo contrataron, en particular por el alcalde de aquella época, Gottfried Lange, un abogado joven que había servido en la corte de Dresde. Coincidiendo con el nombramiento de Bach, a la facción de la ciudad-estado se le otorgó el control de la "Thomasschule" y se le requirió para varios compromisos con respecto a sus condiciones de trabajo.

El trabajo de Bach le requería instruir a los estudiantes de la "Thomasschule" en el canto y proveer semanalmente de música sacra a las principales iglesias de la ciudad. Además, tenía que enseñar latín, pero le permitieron emplear a cuatro ayudantes para que lo hicieran en su lugar, así como para ayudarle en la instrucción musical. Le encargaron una cantata para el servicio de los domingos y días festivos en la iglesia durante el año litúrgico. 

Habitualmente Bach interpretaba sus propias cantatas, muchas de las cuales las compuso durante sus primeros tres años en Leipzig. La primera de ellas fue "Die Elenden sollen essen, BWV 75", representada por primera vez en la "Nikolaikirche" el 30 de mayo de 1723, el primer domingo después del Domingo de Trinidad. Recopiló sus cantatas en ciclos anuales. Cinco son mencionados en sus obituarios, aunque solo existen tres. La mayoría de estas obras se utilizaban en las lecturas del Evangelio prescritas para cada domingo y día festivo en el año luterano. Comenzó un segundo ciclo anual el primer domingo después del de Trinidad de 1724 y compuso únicamente cantatas con coro; muchas de ellas fueron compuestas usando corales, himnos tradicionales de la Iglesia luterana. Entre ellos se incluyen" O Ewigkeit, du Donnerwort, BWV 20; Wachet auf, ruft uns die Stimme, BWV 140; Nun komm, der Heiden Heiland, BWV 62; "y "Wie schön leuchtet der Morgenstern, BWV 1".

Para los ensayos e interpretaciones de estas obras en la iglesia de Santo Tomás, probablemente se sentaba al clave o dirigía frente al coro de espaldas a la congregación. Detrás del coro y un nivel por encima estaba el órgano y en sendas galerías laterales a izquierda y derecha estarían las cuerdas, los vientos, la percusión y el bajo continuo.
El ayuntamiento solo otorgaba alrededor de ocho instrumentistas permanentes, limitación que fue fuente de constante fricción con Bach, que tuvo que reclutar al resto de los veinte o más músicos requeridos para las partituras medianas o grandes, en la universidad, la "Thomasschule" y el público. Bach seleccionaba a los coristas: sopranos y contraltos de la "Thomasschule" y tenores y bajos de la "Thomasschule" y de cualquier lugar de Leipzig. Las intervenciones en bodas y funerales daban un ingreso extra a estos grupos. Es probable que para este propósito, y para el entrenamiento escolar, escribiese al menos seis motetes, la mayoría para doble coro. Como parte de su trabajo regular en la iglesia dirigía motetes de la Escuela veneciana y de alemanes como Heinrich Schütz, que servirían como modelos formales para .

El predecesor de Bach como "Thomaskantor", Johann Kuhnau, también había sido director musical de la "Paulinerkirche", la iglesia de la Universidad de Leipzig. Pero cuando Bach se instaló como "Thomaskantor" en 1723, se le puso a cargo solo de la música para los servicios festivos de la iglesia en la "Paulinerkirche". Su petición de proporcionar también música para los servicios dominicales regulares allí (con su correspondiente aumento salarial) llegó hasta el elector, pero fue denegada. Después de esto, en 1725, Bach «perdió interés» en trabajar incluso para los servicios festivos en la "Paulinerkirche" y apareció allí solo en «ocasiones especiales». La "Paulinerkirche" tenía un órgano mucho mejor y más nuevo (1716) que los de la "Thomaskirche" o la "Nikolaikirche". Bach no estaba obligado a tocar ningún órgano en sus deberes oficiales, pero se cree que le gustaba tocar en el órgano de la "Paulinerkirche" «por su propio placer».

Amplió sus horizontes compositivos más allá de la liturgia al hacerse cargo, en marzo de 1729, de la dirección del "Collegium Musicum", una sociedad musical de estudiantes fundada en 1703 por Georg Philipp Telemann. Esta era una de las docenas de sociedades privadas creadas por estudiantes universitarios activos musicalmente que existían en las principales ciudades germanoparlantes y que, lideradas por los músicos profesionales más destacados de cada ciudad, se fueron haciendo progresivamente más importantes en la vida pública musical. En palabras de Christoph Wolff, asumir la dirección fue un movimiento astuto que «consolidó el firme control que ejercía Bach sobre las principales instituciones musicales de Leipzig». Durante todo el año, el "Collegium Musicum" de Leipzig participaba regularmente en escenarios como la Cafetería Zimmermann ("Zimmermannsches Caffeehaus"), una cafetería en la calle Sainte-Catherine frente a la plaza del mercado. Muchas de sus obras durante las décadas de 1730 y 1740 las escribió para el "Collegium Musicum" y este las interpretó. Entre esas obras se encuentran parte de sus "Clavier-Übung" y muchos de sus conciertos para violín y clave.

Si bien está claro que nadie en el ayuntamiento dudaba de su genio, hubo una constante tensión entre el "Kantor", que se consideraba el líder de la música eclesial de la ciudad, y la facción de la ciudad-estado, que lo veía como un maestro de escuela y quería reducir el énfasis en la composición de música tanto para la iglesia como para la "Thomasschule". A partir de 1730, la facción de la ciudad-estado estaría encabezada por el teólogo y filólogo Johann August Ernesti. Profesor en la Universidad de Leipzig, Ernesti, junto con buena parte del claustro de la Universidad, propugnaba un cambio de modelo educativo que se reorientaría hacia disciplinas más ilustradas como las ciencias naturales o la filología. Las múltiples prerrogativas de Bach como "Kantor" de Santo Tomás chocaban con esta pretensión, por lo que pronto surgió una agria disputa entre ambos, que pretendía relegar la importancia de la música a un segundo puesto, y retirar al "Kantor" toda competencia en materia educativa. El nivel de la disputa llegó a tal punto que Bach pidió ayuda al y elector de Sajonia, Augusto III, que intervino a su favor. El hecho de que hiciera intervenir al elector de Sajonia escandalizó a la corporación de Leipzig, que consideraba el asunto un tema local e interpretó su actitud como propia de alguien con delirios de grandeza. Tras la disputa, las relaciones entre Bach y sus patronos locales se degradaron rápidamente. Sea como fuera, el ayuntamiento nunca cumplió la promesa —que hizo Lange en la entrevista inicial— de ofrecer un salario de 1000 táleros anuales, si bien se le ofreció a él y a su familia una reducción de impuestos y un buen apartamento en una de las alas de la "Thomasschule", que renovaron con gran gasto en 1732.
En 1733, Bach compuso el «Kyrie» y «Gloria» de la "Misa en si menor". Presentó el manuscrito a Augusto III, en un intento finalmente exitoso de persuadir al monarca para que lo nombrara Compositor Real de la Corte. Posteriormente extendió dicha obra en una misa completa, añadiendo un «Credo», «Sanctus» y «Agnus Dei», cuya música fue sacada casi por completo de sus propias cantatas. El nombramiento de Bach como compositor de la corte fue parte de su larga disputa para conseguir un mayor poder de negociación con el ayuntamiento de Leipzig. Aunque la misa completa probablemente nunca se representó durante la vida del compositor, está considerada entre la obras corales más grandes de todos los tiempos. Entre 1737 y 1739, el antiguo alumno de Bach Carl Gotthelf Gerlach asumió el puesto de director del "Collegium Musicum".

En 1735, comenzó a preparar su primera publicación de música de órgano, que se imprimió como el tercer Clavier-Übung en 1739. A partir de ese año comenzó a compilar y componer el conjunto de preludios y fugas para clavecín que se convertiría en su segundo libro de "El clave bien temperado".

De 1740 a 1748, copió, transcribió, amplió o programó música en un estilo polifónico más antiguo ("stile antico") de, entre otros, Palestrina (BNB I/P/2), Kerll (BWV 241), Torri (BWV Anh. 30), Bassani (BWV 1081), Gasparini ("Missa Canonica") y Caldara (BWV 1082). El estilo propio de Bach cambió en la última década de su vida, mostrando una mayor integración de estructuras polifónicas y cánones y otros elementos del "stile antico". Su cuarto y último volumen de "Clavier-Übung", las "Variaciones Goldberg", para clave de dos manuales, contenía nueve cánones y se publicó en 1741. Durante este período, Bach también continuó adoptando música de contemporáneos como Händel (BNB I/K/2) y Stölzel (BWV 200), y realizó la revisión final de muchas de sus propias composiciones anteriores, como las "Pasiones según San Mateo" y "San Juan" y los "Dieciocho grandes preludios corales". También programó y adaptó música de compositores de una generación más joven, que incluían a Pergolesi (BWV 1083) y sus propios estudiantes como Goldberg (BNB I/G/2).

En 1747, Bach se unió a la "Correspondierende Societät der musicalischen Wissenschaften" de Lorenz Christoph Mizler después de una larga preparación formal, necesaria para acceder a la Sociedad. Mizler llamó a su antiguo profesor uno de sus «"guten Freunde und Gönner"» («buenos amigos y patrocinadores»). Esto es particularmente notable porque Mizler era un apasionado representante de la Ilustración alemana y polaca. Su afiliación tuvo varios efectos. Con ocasión de su entrada en la Sociedad, compuso las "Variaciones canónicas sobre "Vom Himmel hoch da komm' ich her", BWV 769". En 1746, durante la preparación de la entrada del compositor, Elias Gottlob Haussmann pintó el famoso retrato de Bach. Se tenía que enviar un retrato a cada miembro de la Sociedad. Bach dedicó por este retrato el "Canon triplex a 6" (BWV 1076) a la Sociedad. La Sociedad insistió en realizar un obituario de cada miembro, por lo que Mizler inició la historia de las biografías de Bach en la "Musikalische Bibliothek". 

Ese mismo año, Bach visitó la corte de Federico II el Grande en el palacio de Sanssouci (Potsdam), donde uno de sus hijos, Carl Philipp Emanuel, estaba al servicio del monarca como clavecinista de la corte. El rey interpretó un tema para él y lo desafió a improvisar una fuga basada en este. El compositor improvisó una fuga en tres partes en el pianoforte del monarca, entonces una novedad, y posteriormente presentó al rey Federico la "Ofrenda musical", que consistía en fugas, cánones y un trío basado en ese "Thema Regium". Su fuga en seis partes incluye un tema ligeramente alterado, más adecuado para una extensa elaboración. Las "Corales Schübler", un conjunto de seis preludios corales transcritos de movimientos de cantatas que Bach había compuesto unas dos décadas antes, se publicaron al año siguiente. Casi al mismo tiempo, también se imprimió el conjunto de cinco variaciones canónicas que Bach había presentado al ingresar a la sociedad de Mizler en 1747.

A menudo se argumentó que otras obras tardías del compositor pudieron tener conexión con la teoría musical basada en la Sociedad. Dos composiciones a gran escala ocuparon un lugar central en los últimos años de Bach. Desde alrededor de 1742 escribió y revisó los diversos cánones y fugas de "El arte de la fuga", que continuó preparando para su publicación hasta poco antes de su muerte. Bach no pudo completar su fuga final. Consiste en 18 fugas y cánones complejos basados en un tema simple y fue publicada a título póstumo en 1751. Después de extraer una cantata, "Gloria in excelsis Deo, BWV 191", de su "Misa Kyrie-Gloria" de 1733 para la corte de Dresde a mediados de la década de 1740, amplió ese escenario a su misa en "si" menor en los últimos años de su vida. Stauffer la describe como «la obra eclesiástica más universal de Bach. Consiste principalmente en movimientos reciclados de cantatas escritas durante un período de treinta y cinco años, le permitió examinar sus piezas vocales por última vez y elegir movimientos selectos para su posterior revisión y refinamiento». Aunque la misa completa nunca se representó durante la vida del compositor, se considera una de las mejores obras corales de la historia.

En enero de 1749, la hija del compositor, Elisabeth Juliane Friederica, se casó con su alumno Johann Christoph Altnickol. La salud de Bach empeoró. El 2 de junio, Heinrich von Brühl escribió a uno de los burgomaestres de Leipzig para pedirle que su director de música, Gottlob Harrer, ocupara los cargos de "Thomaskantor" y director musical «ante el eventual [...] fallecimiento del señor Bach». Se fue quedando progresivamente más ciego, por lo que el cirujano británico John Taylor lo operó durante su visita a Leipzig en marzo y de nuevo en abril de 1750.

La última obra de Bach completada fue un preludio coral para órgano, titulado "Vor deinen Thron tret ich hiermit, BWV 668a", que dedicó a su yerno Johann Christoph Altnickol, desde su lecho de muerte. En las notas de los tres pentagramas de la cadencia final, leídas según la denominación germana, se encuentran las iniciales «JSB». 

El 28 de julio de 1750, Johann Sebastian Bach falleció a la edad de 65 años. Un periódico de la época informó de que «las infelices consecuencias de su muy poco exitosa operación» fueron la causa de su muerte. Historiadores modernos especulan con que la causa de su muerte fue una apoplejía, complicada por una neumonía. Actualmente se cree que su ceguera fue originada por una diabetes sin tratar. Según ciertos médicos, padecía de blefaritis, enfermedad ocular visible en los retratos de sus últimos años.

El hijo del compositor Carl Philipp Emanuel se ocupó de que "El arte de la fuga", aunque aún sin terminar, se publicara en 1751. Junto con uno de los antiguos alumnos del compositor, Johann Friedrich Agricola, el hijo también escribió el obituario («Nekrolog»), que se publicó en la "Musikalische Bibliothek" de Mizler, en 1754.
Un inventario elaborado unos meses después de la muerte de Bach muestra que su patrimonio incluía cinco clavecines, dos laúd-clave, tres violines, tres violas, dos violonchelos, una viola da gamba, un laúd, una espineta y cincuenta y dos «libros sagrados», incluyendo obras de Martín Lutero y Flavio Josefo. Inicialmente fue enterrado en el viejo cementerio de San Juan en Leipzig. Su tumba estuvo sin identificar durante casi ciento cincuenta años hasta que, en 1894, finalmente se encontró su ataúd y lo trasladaron a una cripta en la iglesia de San Juan. Este edificio quedó destruido durante un bombardeo del bando aliado durante la Segunda Guerra Mundial, por lo que desde 1950 los restos de Johann Sebastian Bach reposan en una tumba en la iglesia de Santo Tomás de Leipzig.

La obra de Bach se puede dividir en tres grandes períodos bien diferenciados, marcados por las influencias y la asimilación de los estilos de su época, el desarrollo, búsqueda y evolución de su estilo personal, y los puestos profesionales que desempeñó.

El primer período, el de aprendizaje y estudio, va desde 1700 hasta 1713, estando ya en Weimar; en él escribió música para teclado y cantatas sacras, y formó su estilo, que sintetizó toda la tradición de la música clásica europea precedente: la polifonía clásica fijada en tiempos de Giovanni Pierluigi da Palestrina; el primer Barroco de Girolamo Frescobaldi; la música francesa del ; y la de autores alemanes e italianos de su época como Dietrich Buxtehude, Johann Pachelbel y Antonio Vivaldi. De este último copió y adaptó obras desde su juventud: así lo hizo en Weimar, cuando, gracias al duque, pudo versionar algunas de sus obras en sus "Conciertos BWV 592-597" y "BWV 972-987". Bach también se interesaba en compositores contemporáneos, a quienes estudiaba y con muchos de los cuales mantuvo una relación personal directa. Entre ellos se encontraban Jan Dismas Zelenka, Johann Mattheson, Georg Philipp Telemann, Reinhard Keiser y Georg Friedrich Händel.

El segundo período, ya de plena madurez, empieza en 1713, en Weimar, y acaba en 1740, afincado ya en Leipzig. Bach dominaba los dos estilos principales de su época, el francés y el italiano (progresiones armónicas ya plenamente tonales, claridad melódica y dinamismo rítmico, y, de hecho, su producción estuvo muy influida por el concierto italiano y la suite francesa. Sintetizó en sus obras elementos de ambos junto a rasgos autóctonos alemanes como el complejo contrapunto y textura interna y el coral, del que hace amplio uso en sus obras religiosas. Resulta de todo ello un estilo fácilmente reconocible, moderno, pero de claras raíces en el pasado. En Leipzig y Köthen, ya forjado su estilo personal, adquiere un profundo dominio técnico. Es así como hizo amplio uso de la técnica y formas alemanas del órgano (tocatas, preludios, fugas, corales), francesas del clave (suites, oberturas) e italianas del violín (conciertos, sonatas, sinfonías).

El último período de su música va desde la publicación de "Clavier-Übung III," en 1739, hasta su muerte en 1750. En esta etapa compuso el "El arte de la fuga". Durante los últimos años de su vida —dominados ya en Alemania por la estética de la Ilustración— su obra fue considerada anticuada, árida, difícil y saturada de adornos. En este período escribió obras instrumentales singularmente densas, como haría más adelante Beethoven, y su estilo personal se volvió más contrapuntístico, con apenas una leve influencia de la nueva música galante o estilo preclásico naciente en aquellos momentos, que se caracterizaba por su carácter homofónico y apenas utilizaba el cargado contrapunto que Bach usaba. Así, el 14 de mayo de 1737, Johann Adolph Scheibe, crítico musical de la nueva mentalidad ilustrada, criticó duramente su música en su "Der Critischer Musikus": «sus piezas son extremadamente difíciles de tocar; porque exige que los cantantes e instrumentistas hagan con sus gargantas e instrumentos exactamente lo que él puede tocar en el clavecín».

Escribió en casi todos los géneros y formas de su época, en multitud de combinaciones instrumentales y vocales. Culminó y realizó obras destacables en todos ellos e incluso creó géneros nuevos, como la sonata para teclado y un instrumento. Única excepción fue la ópera, género para el cual no compuso, aunque el lenguaje e influencia de la ópera seria del está presente en toda su producción vocal. La influencia de la ópera se plasma, sin embargo, especialmente en las , pasiones y oratorios. "Schweigt stille, plaudert nicht, BWV 211" (conocida como "Cantata del café") de 1735 es, prácticamente, una pequeña ópera sin representación escénica, y sus pasiones (como la "Pasión según San Mateo, BWV 244", de 1727) contienen muchos elementos operísticos.

Después de Bach, algunas formas musicales, como las pasiones, las cantatas sacras, las tocatas y las fugas, fueron cayendo en desuso para los grandes compositores. Tras su muerte, la música tomó una dirección en la que su obra no tuvo cabida; él es el punto final respecto a una forma de entender la música que se remontaba a la Edad Media, cuando tenían más importancia la polifonía que la armonía o el timbre. Pero también fue innovador y abrió caminos para la música del futuro: por ejemplo, fue el primer gran maestro del concierto para teclado. De hecho, el quinto "Concierto de Brandeburgo n.º 5, BWV 1050" (1719), en el cual el teclado adquiere un papel solista que hasta entonces nunca había tenido, puede considerarse el primer concierto escrito para teclado, que continuó en la serie de conciertos "BWV 1052-1065" (1735). En ese sentido, Bach desempeñó un papel destacado en el desarrollo de dicho género. 

En 1950, Wolfgang Schmieder elaboró el registro o catálogo de sus obras, que abarca en total 1128 obras. Se conoce por las siglas «BWV», que significan «Bach-Werke-Verzeichnis» o «Catálogo de las obras de Bach». Es un sistema de numeración usado para identificar las obras del compositor alemán, que se agrupan en dos grandes secciones.

Primero, la música vocal (BWV 1-524), que comprende cantatas (); obras corales a gran escala (BWV 225-249), incluyendo pasiones (BWV 250-524), oratorios y corales, y otras obras sacras.

Después la música instrumental (BWV 525-1127), que incluye obras para órgano (BWV 525-748), otras obras para teclado (BWV 772-994), música para laúd (BWV 995-1000), música de cámara (BWV 1001-40), música orquestal (BWV 1041-71), y cánones y fugas (BWV 1072-1126), además de otro tipo de música instrumental como conciertos (varios para un único solista y otros con hasta cuatro solistas), sonatas, suites, oberturas, preludios, fantasías, ricercares, variaciones y pasacalles. A su vez, dentro de cada una de estas dos divisiones, las obras se agrupan por géneros, y no por fecha de composición. Por esta razón, un número BWV menor no indica una obra cronológicamente temprana. La primera edición del catálogo listaba 1080 composiciones supervivientes indiscutidamente compuestas por Bach. También existe un catálogo elaborado por Christoph Wolff, de menor difusión.

La música vocal de Bach que se conserva consta de 525 obras, aunque solo 482 de ellas están completas. En su mayoría es sacra —solo 24 cantatas, cuatro lieder y un quodlibet son profanos— y compuesta para la liturgia de la Iglesia luterana alemana, en la que la música ocupa un importante lugar.

La gran mayoría de su música vocal la compuso en Leipzig entre los años 1723 y 1741, cuando Bach era "Kantor" y tenía entre sus obligaciones componer cantatas, pasiones y motetes para las cinco iglesias más grandes de la ciudad, además de para actos civiles y religiosos, como por ejemplo funerales.

El compositor diferenciaba escasamente en estilo sus obras profanas frente a las religiosas. Un ejemplo de ello es la utilización de los mismos textos para la música sacra y la profana, como sucede con la música del «Hosanna» de la "Misa en si menor, BWV 232", que antes había empleado en una cantata en homenaje a Augusto II de Polonia con motivo de una de sus visitas oficiales a Leipzig, "Es lebe der König, der Vater im Lande, BWV Anh. 11".

De su música instrumental se conservan 227 piezas para órgano, 189 piezas para clavicémbalo, 20 para instrumentos a solo, 16 de cámara, 30 orquestales y 18 especulativas. En total, son 494 las obras instrumentales completas. Están compuestas para una amplia gama de instrumentos de su época, incluso algunos experimentales, como el laúd-clave, aunque especialmente significativos son el órgano, el clavecín y el violín.

De su música instrumental solo los corales para órgano están destinados a su uso en la iglesia. Mucha de ella, especialmente la destinada al teclado, es de carácter didáctico, con frecuencia escritas para el aprendizaje de su hijo Wilhelm Friedemann. Entre las didácticas destacan "El clave bien temperado" y las series de "Suites inglesas" y "francesas".

El órgano y el clavecín ocupan un papel central en la obra de Bach con más de 400 obras destinadas a ellos, aparte de ser el sostén como bajo continuo de las obras orquestales, las cantatas, las misas, las pasiones y algunas obras de cámara (que solía dirigir desde el teclado). El clavecín adquiere un papel importante como solista en los conciertos para cuerdas y uno, dos, tres o cuatro teclados.

Su aporte a la literatura musical, avances técnicos y de interpretación, evolución e historia de estos dos instrumentos fue capital, ya que explotó al límite sus capacidades, investigó y mejoró su afinación, recursos y ejecución, y exploró las 24 tonalidades mayores y menores en "El clave bien temperado", BWV 846-893. Entre sus obras didácticas para clave están las "Invenciones a dos voces" y las "Sinfonías a tres voces".

Entre la música organística de Bach destacan también sus preludios corales, unos 170 aproximadamente. La antología "Orgelbüchlein" ("Pequeño libro para órgano"), que él mismo recopiló en Weimar y en Köthen, comprende breves preludios corales, que muchas veces destinaba a fines educativos. De hecho, tras el título de la "Orgelbüchlein" dice que este «pequeño libro para órgano, por medio del cual un principiante del órgano recibe instrucciones para desarrollar un coral de formas muy diferentes, y al mismo tiempo adquiere facilidad en el estudio del pedaleo, ya que los corales contenidos en él tratan al pedaleo como un "obbligato" (es decir, esencial, no optativo)».

Durante su estancia en Leipzig compiló tres antologías corales para órgano: los seis "Corales Schübler", que son transcripciones de movimientos de cantata, y dieciocho corales, que revisó entre 1747 y 1749 y que fueron compuestos en épocas anteriores. Todos ellos incluyen composiciones para órgano, como variaciones, fugas, fantasías, tríos y diversos preludios corales.

Bach conocía bien los instrumentos de cuerda, base de la orquesta barroca —cuya música solía escribirse para dos grupos de violines, uno de violas y un bajo continuo que solía incluir violonchelo y contrabajo—. Escribió repertorio para violín solista (sonatas y partitas) y violonchelo (suites), aún hoy plenamente vigentes y de alta dificultad técnica. Escribió sonatas para un instrumento en solitario, como la viola de gamba, acompañado de clavecín o continuo, así como sonatas trío (dos instrumentos y continuo).

Bach escribió para instrumentos individuales, dúos y conjuntos pequeños. La "Ofrenda musical" y "El arte de la fuga" son obras contrapuntistas tardías que contienen piezas para combinaciones de instrumentos no especificados. "El arte de la fuga" es una obra que se corresponde muy bien con la concepción contemporánea de la música y por ello ha pasado de ser interpretada por conjuntos barrocos, hoy día todos con instrumentos de época, a ser una parte del repertorio de los principales cuartetos de cuerda. También se interpreta frecuentemente al piano, donde puede apreciarse el carácter trascendente de la composición.

Las obras sobrevivientes en la forma de concierto incluyen dos "Conciertos para violín (BWV 1041 y BWV 1042)" y un "Concierto para dos violines, BWV 1043", a menudo denominado concierto «doble» de Bach. Este concierto tiene la particularidad de que la parte del segundo violín es más virtuosística que la del primer solista, lo que hace que los grandes solistas no tengan inconveniente en colaborar y quizá ha contribuido a su popularidad entre el público.

Johann Sebastian Bach encabezó una familia numerosa con un total de veinte hijos, nacidos entre sus 23 y sus 57 años. Tuvo siete hijos de su primer matrimonio, de los cuales sobrevivieron cuatro, y trece del segundo, de los cuales sobrevivieron solo cinco. Su primera esposa fue su prima segunda, Maria Barbara Bach (1684-1720), con la que se casó en 1707. Su segunda esposa fue la cantante Anna Magdalena Wilcke (1701-1760), con la que contrajo matrimonio en 1721.

Cinco de los hijos se dedicaron a la música, aunque uno de ellos (Johann Gottfried Bernhard) abandonó su carrera y murió prematuramente a los 24 años. Los otros cuatro llegaron a convertirse en compositores e intérpretes reputados por derecho propio: Wilhelm Friedemann, Carl Philipp Emanuel (de quien Wolfgang Amadeus Mozart tenía muy buena opinión), Johann Christoph Friedrich y Johann Christian, epígono de la época preclásica y una de las influencias principales del propio Mozart. Carl Philipp Emanuel y Johann Christian llegaron a ser más famosos en su época de lo que había sido su padre.

A la muerte del compositor, su familia dividió su legado musical. Wilhelm Friedemann perdió o vendió para saldar deudas varias obras compuestas por su padre. En cambio, Carl Phillip Emanuel conservó una buena parte de ellas.

Bach tuvo numerosos alumnos y estudiantes a lo largo de su vida; según el estudioso Hans Löffler, más de ochenta. Entre ellos se cuenta Johann Christoph Altnickol, yerno suyo, que en los últimos años del maestro fue copista de sus obras, además de ayudarlo en la redacción de sus últimas composiciones, como en el caso de uno de sus últimos corales para órgano, el "BWV 668", el último coral del "Ciclo de Leipzig BWV 651-668".

Ya en su vejez, cuando la gente se refería al apellido Bach lo hacía pensando en su famoso hijo Carl Phillip Emanuel. En las generaciones posteriores al compositor, solo algunos compositores y músicos conocían su obra. Básicamente eran sus hijos y sus alumnos. Gracias a ellos se conservó y no cayó en el olvido, mientras que el resto del mundo no tardaría muchos años en olvidarlo después de su muerte, en plena mitad del .

Lorenz Christoph Mizler, un antiguo alumno, publicó un detallado obituario de Bach en 1754, cuatro años después de su muerte, en "Musikalische Bibliothek", un periódico musical. El obituario sigue siendo probablemente «la más rica y confiable» de las primeras fuentes documentales sobre el compositor. Después de su muerte, la reputación de Bach como compositor declinó en un primer momento. Su obra se consideraba pasada de moda en comparación con el emergente estilo galante. Inicialmente, era más recordado como intérprete y profesor.

La falta de material impreso impidió una mayor difusión de su obra. Solo se publicaron tiradas muy reducidas de algunas obras instrumentales para órgano y clave. Muchas de sus obras fueron compuestas para eventos determinados; por lo tanto, las interpretaron solamente una o dos veces y no se le ocurría que podría interesarle a alguien escucharlas otra vez. Por eso no se preocupaba por publicarlas.

De la única pieza que existían muchas copias manuscritas era de "El clave bien temperado". Incluso Beethoven tenía una copia a los once años. Mozart lo conocía por haber escuchado hablar de su obra, pero nunca había visto nada suyo impreso. Una vez que escuchó un coro que lo cantaba quedó tan impresionado que pidió ver sus partituras, pero estas no existían.

En 1844, se hizo la primera interpretación moderna del "Oratorio de Navidad, BWV 248". En 1911, se halló una cantata inédita que se cataloga como "Mein Herze schwimmt im Blut, BWV 199". En 1924, se descubrió un fragmento de cantata, catalogada como "Bekennen will ich seinen Namen, BWV 200". En 1985, se encontró un manuscrito en Halle que contenía los corales BWV 1090-1120, inéditos hasta entonces. En 2005, se halló un manuscrito que contiene un aria vocal "Alles mit Gott und nichts ohn' ihn, BWV 1127".

En 2008, se hace en Berlín una reconstrucción moderna de su cabeza y rostro con técnicas de modelación por ordenador, dando una imagen de fidelidad muy aproximada a la real. Ese mismo año se encontró un manuscrito que contenía un coral para órgano inédito hasta la fecha.

A finales del y comienzos del , Bach era ampliamente reconocido por su obra para teclado. Músicos célebres, como Joseph Haydn, Wolfgang Amadeus Mozart, Ludwig van Beethoven, Felix Mendelssohn, Robert Schumann o Frédéric Chopin estaban entre sus más destacados admiradores y tuvieron un gran aprecio por las obras que conocieron de Bach; comenzaron escribiendo en un estilo más contrapuntístico después de conocer su música. Mozart, tras haber escuchado el motete "Singet dem Herrn ein neues Lied, BWV 225" durante una visita a Leipzig, solicitó examinar cuanto allí había del compositor, exclamando «¡Al fin algo de lo que se puede aprender!». Beethoven, sin conocer la totalidad de su obra, lo describió como el «"Urvater der Harmonie"» («Padre original de la armonía»). También lo definió con un juego de palabras en alemán: «Nicht Bach, sondern Meer sollte er heissen», cuya traducción es «No debiera llamarse "Bach" ('arroyo', en alemán), sino "Meer" ('mar')».

La reputación de Bach entre el público en general mejoró en parte gracias a la biografía del compositor que realizó Johann Nikolaus Forkel en 1802. Felix Mendelssohn contribuyó de manera significativa en la recuperación de la reputación de Bach con su representación de la "Pasión según San Mateo" el 11 de marzo de 1829 en Berlín. Este hecho es destacado, ya que se trataba de música muy antigua para su época. En la actualidad, se acostumbra interpretar obras de otros siglos, mientras que en el período romántico no era habitual. En 1850, se fundó la "Bach Gesellschaft" (Sociedad Bach) para promover las obras del compositor; en 1899, la Sociedad publicó una edición completa de las obras del compositor con poca intervención editorial. En 1838, se reinterpretaron por primera vez las "Suites para orquesta". En 1900, se fundó la "Neue Bachgesellschaft" una vez que la antigua sociedad cumplió su meta.

Durante el , el proceso de reconocimiento tanto musical como del valor pedagógico de algunas de sus obras continuó, quizás más notablemente en la promoción de sus "Suites para violonchelo solo" por parte de Pau Casals, el primer artista importante que grabó dichas suites. Otra novedad ha sido el crecimiento del movimiento «auténtico» o «interpretación historicista», que intenta presentar la música como la entendía el compositor originalmente. Como ejemplos, se incluyen la interpretación de las obras para teclado con un clave en lugar de con un piano moderno, el uso de pequeños coros o voces solistas en lugar de grandes elencos al estilo de los preferidos por los intérpretes en el y comienzos del , como también las grabaciones de la música integral de órgano en instrumentos del periodo barroco que realizó Marie-Claire Alain, quien también se dedicó a estudiar en profundidad la obra de Bach para interpretarla con los estándares barrocos de su tiempo.

Su música sirvió de influencia para muchos compositores del , entre ellos Astor Piazzolla, quien empleó el contrapunto y la fuga, o Brian Wilson (de The Beach Boys), que se inspiró en la música coral de Bach para componer "Pet Sounds" (1966), un álbum caratulado de "pop barroco".

Según Christoph Wolff, «Bach ahora asume un lugar en la música comparable con el de Shakespeare en la literatura o Rafael y Miguel Ángel (en Alemania también Durero) en las bellas artes».

Johann Sebastian Bach es uno de los compositores más conocidos de la música barroca. Se ha utilizado su imagen en diversos formatos artísticos y de otra índole, como pósteres, caricaturas y postales. Se han emitido sellos postales y otros documentos filatélicos y numismáticos en numerosos países del mundo, en muchos casos para conmemorar los aniversarios de su nacimiento y muerte. También se han acuñado monedas, medallas y medallones conmemorativos.

Aparece asimismo en diversos artículos de "merchandising", como relojes, objetos para fumar (como pipas, vitolas de puro o cajetillas de tabaco), tazas y jarras, muñecos de juguete, o caramelos y chocolatinas.

En Alemania, durante el , se nombraron muchas calles en su honor. Además, se erigieron estatuas y placas conmemorativas en diversos países del mundo, incluidos Alemania, Bélgica, Canadá, China, Finlandia, Francia, Países Bajos, Irlanda, España, Reino Unido y Estados Unidos. También se han realizado bustos y estatuillas con su imagen y aparece en las vidrieras de varias iglesias.

Su música ha sido incluida tres veces —más que ningún otro compositor— en el Disco de oro de las Voyager, una grabación fonográfica que contiene un amplio conjunto de imágenes, sonidos comunes, lenguajes y música de la Tierra, enviada al espacio exterior con las sondas espaciales Voyager.

El asteroide (1814) Bach, descubierto el 9 de octubre de 1931 por Karl Wilhelm Reinmuth, recibe su nombre en honor al compositor. Así mismo, el cráter de impacto en el planeta Mercurio denominado «cráter Bach» también lleva su nombre.

En su condición de autor de música religiosa, su nombre figura entre las celebraciones del Calendario de Santos Luterano y comparte fecha con Georg Friedrich Händel y Heinrich Schütz. Además, se le honra con un día festivo del Calendario de Santos de la iglesia episcopal. Se celebra el 28 de julio y lo comparte con Händel y Henry Purcell. Bach y Händel también se conmemoran en el calendario de los santos preparado por la Order of Saint Luke para uso de la Iglesia metodista unida.

En 1985, cuando se cumplieron 300 años de su nacimiento, se editó el primer registro completo de todas las cantatas sacras, dirigido por Helmuth Rilling. La edición constaba de 69 cedés y fue realizada por el sello discográfico alemán Hänssler. En 1989, se terminó el ciclo comenzado en 1971 de la grabación de cantatas realizado por Gustav Leonhardt y Nikolaus Harnoncourt y se editó en 60 cedés del sello discográfico Teldec. Esta grabación fue revolucionaria, pues se aplicó la concepción histórica de la interpretación y se cambió ésta para siempre. En 2000, se celebraron los 250 años de su muerte y tres sellos discográficos (Brilliant, Hänssler y Teldec) publicaron ediciones conmemorativas con toda la música grabada del compositor alemán, en 155, 172 y 160 cedés, respectivamente. Además, durante ese año se celebraron innumerables actos de toda índole dedicados al estudio y divulgación del artista y su obra, especialmente en su Alemania natal.

Se ha mostrado al compositor biográficamente en numerosas ocasiones en el cine, en el teatro y en la televisión, como por ejemplo: "Crónicas de Ana Magdalena Bach" (1968), de Jean Marie Straub y Danièle Huillet, "Johann Sebastian Bachs vergebliche Reise in den Ruhm" (1980) de Victor Vicas, "Johann Sebastian Bach" (1983) de Lothar Bellag, "Ein Denkmal für Johann Sebastian" (1984) de Peter Milinski, "Mi nombre es Bach" (2003) de Dominique de Rivaz y "El silencio antes de Bach" (2007) de Pere Portabella. Además, se ha usado su música en más de 1500 películas y programas de televisión.





</doc>
<doc id="1593" url="https://es.wikipedia.org/wiki?curid=1593" title="Núcleo (informática)">
Núcleo (informática)

En informática, un núcleo o kernel (de la raíz germánica "Kern", núcleo, hueso) es un "software" que constituye una parte fundamental del sistema operativo, y se define como la parte que se ejecuta en modo privilegiado (conocido también como modo núcleo). Es el principal responsable de facilitar a los distintos programas acceso seguro al "hardware" de la computadora o en forma básica, es el encargado de gestionar recursos, a través de servicios de llamada al sistema. Como hay muchos programas y el acceso al "hardware" es limitado, también se encarga de decidir qué programa podrá usar un dispositivo de hardware y durante cuánto tiempo, lo que se conoce como multiprogramación. Acceder al hardware directamente puede ser realmente complejo, por lo que los núcleos suelen implementar una serie de abstracciones del "hardware". Esto permite esconder la complejidad, y proporcionar una interfaz limpia y uniforme al hardware subyacente, lo que facilita su uso al programador.

En algunos sistemas operativos, no existe un núcleo como tal (algo común en sistemas empotrados), debido a que en ciertas arquitecturas no hay distintos modos de ejecución.

Cuando se aplica voltaje al procesador de un dispositivo electrónico, este ejecuta un reducido código en lenguaje ensamblador localizado en una dirección concreta en la memoria ROM (dirección de "reset") y conocido como "reset code", que a su vez ejecuta una rutina con la que se inicializa el hardware que acompaña al procesador. También en esta fase suele inicializarse el controlador de las interrupciones. Finalizada esta fase se ejecuta el código de arranque ("startup code"), también código en lenguaje ensamblador, cuya tarea más importante es ejecutar el programa principal ("main()") del software de la aplicación.

En informática, los sistemas operativos son el núcleo del ordenador que se asegura de:

La mayoría de las interfaces de usuario se construyen en torno al concepto de núcleo. La existencia de un núcleo, es decir, de un único programa responsable de la comunicación entre el "hardware" y el programa informático, resulta de compromisos complejos referentes a cuestiones de resultados, seguridad y arquitectura de los procesadores. El núcleo tiene grandes poderes sobre la utilización de los recursos materiales ("hardware"), en particular, de la memoria. 

Los núcleos tienen como funciones básicas garantizar la carga y la ejecución de los procesos, las entradas/salidas y proponer una interfaz entre el espacio núcleo y los programas del espacio del usuario.

Aparte de las funcionalidades básicas, el conjunto de las funciones de los puntos siguientes (incluidos los pilotos materiales, las funciones de redes y sistemas de ficheros o los servicios) necesariamente no son proporcionados por un núcleo de sistema de explotación. Pueden establecerse estas funciones del sistema de explotación tanto en el espacio usuario como en el propio núcleo. Su implantación en el núcleo se hace con el único objetivo de mejorar los resultados. En efecto, según la concepción del núcleo, la misma función llamada desde el espacio usuario o el espacio núcleo tiene un coste temporal obviamente diferente. Si esta llamada de funciones es frecuente, puede resultar útil integrar estas funciones al núcleo para mejorar los resultados.

Un núcleo Unix es un programa escrito casi en su totalidad en lenguaje C, con excepción de una parte del manejo de interrupciones, expresada en el lenguaje ensamblador del procesador en el que opera. Las funciones del núcleo son permitir la existencia de un ambiente en el que sea posible atender a varios usuarios y múltiples tareas en forma concurrente, repartiendo al procesador entre todos ellos, e intentando mantener en grado óptimo la atención individual.

El núcleo opera como asignador de recursos para cualquier proceso que necesite utilizar las facilidades de cómputo. 
Sus funciones principales son:


Reside siempre en la memoria principal y tiene el control sobre la computadora, por lo que ningún otro proceso puede interrumpirlo; solo pueden llamarlo para que proporcione algún servicio de los ya mencionados. Un proceso llama al núcleo mediante módulos especiales conocidos como llamadas al sistema.

Consta de dos partes principales: la sección de control de procesos y la de control de dispositivos. La primera asigna recursos, programas, procesos y atiende sus requerimientos de servicio; la segunda, supervisa la transferencia de datos entre la memoria principal y los dispositivos del ordenador. En términos generales, cada vez que algún usuario oprime una tecla de una terminal, o que se debe leer o escribir información del disco magnético, se interrumpe al procesador central y el núcleo se encarga de efectuar la operación de transferencia. 

Cuando se inicia la operación de la computadora, debe cargarse en la memoria una copia del núcleo, que reside en el disco magnético (operación denominada bootstrap). Para ello, se deben inicializar algunas interfaces básicas de hardware; entre ellas, el reloj que proporciona interrupciones periódicas. El núcleo también prepara algunas estructuras de datos que abarcan una sección de almacenamiento temporal para transferencia de información entre terminales y procesos, una sección para almacenamiento de descriptores de archivos y una variable que indica la cantidad de memoria principal. 

A continuación, el núcleo inicializa un proceso especial, llamado proceso 0. En Unix, los procesos se crean mediante una llamada a una rutina del sistema (fork), que funciona por un mecanismo de duplicación de procesos. Sin embargo, esto no es suficiente para crear el primero de ellos, por lo que el núcleo asigna una estructura de datos y establece apuntadores a una sección especial de la memoria, llamada tabla de procesos, que contendrá los descriptores de cada uno de los procesos existentes en el sistema. 

Después de haber creado el proceso cero, se hace una copia del mismo, con lo que se crea el proceso uno; este muy pronto se encargará de "dar vida" al sistema completo, mediante la activación de otros procesos que también forman parte del núcleo. Es decir, se inicia una cadena de activaciones de procesos, entre los cuales destaca el conocido como despachador, o planificador, que es el responsable de decidir cuál proceso se ejecutará y cuáles van a entrar o salir de la memoria central. A partir de ese momento se conoce el número uno como proceso de inicialización del sistema, "init". 

El proceso "init" es el responsable de establecer la estructura de procesos en Unix. Normalmente, es capaz de crear al menos dos estructuras distintas de procesos: el modo monousuario y el multiusuario. Comienza activando el intérprete del lenguaje de control "shell" de Unix en la terminal principal, o consola del sistema, proporcionándole privilegios de superusuario. En la modalidad de un solo usuario la consola permite iniciar una primera sesión, con privilegios especiales, e impide que las otras líneas de comunicación acepten iniciar sesiones nuevas. Esta modalidad se usa con frecuencia para revisar y reparar sistemas de archivos, realizar pruebas de funciones básicas del sistema y para otras actividades que requieren uso exclusivo de la computadora. 

Init crea otro proceso, que espera a que alguien entre en sesión en alguna línea de comunicación. Cuando esto sucede, realiza ajustes en el protocolo de la línea y ejecuta el programa login, que se encarga de atender inicialmente a los nuevos usuarios. Si el nombre de usuario y la contraseña proporcionadas son correctos, entonces entra en operación el programa Shell, que en lo sucesivo se encargará de la atención normal del usuario que se dio de alta en esa terminal. 

A partir de ese momento el responsable de atender al usuario en esa terminal es el intérprete Shell. Cuando se desea terminar la sesión hay que desconectarse de Shell (y, por lo tanto, de Unix), mediante una secuencia especial de teclas (usualmente. < CTL > - D). A partir de ese momento la terminal queda disponible para atender a un nuevo usuario.

No necesariamente se necesita un núcleo para usar una computadora. Los programas pueden cargarse y ejecutarse directamente en una computadora "vacía", siempre que sus autores quieran desarrollarlos sin usar ninguna abstracción del "hardware" ni ninguna ayuda del sistema operativo. Esta era la forma normal de usar muchas de las primeras computadoras: para usar distintos programas se tenía que reiniciar y reconfigurar la computadora cada vez. Con el tiempo, se empezó a dejar en memoria (aún entre distintas ejecuciones) pequeños programas auxiliares, como el cargador y el depurador, o se cargaban desde memoria de solo lectura. A medida que se fueron desarrollando, se convirtieron en los fundamentos de lo que llegarían a ser los primeros núcleos de sistema operativo.

Hay cuatro grandes tipos de núcleos:

El enfoque micronúcleo consiste en definir una abstracción muy simple sobre el hardware, con un conjunto de primitivas o llamadas al sistema que implementan servicios del sistema operativo mínimos, como la gestión de hilos, el espacio de direccionamiento y la comunicación entre procesos.

El objetivo principal es la separación de la implementación de los servicios básicos y de la política de funcionamiento del sistema. Por ejemplo, el proceso de bloqueo de E/S se puede implementar con un servidor en espacio de usuario ejecutándose encima del micronúcleo. Estos servidores de usuario, utilizados para gestionar las partes de alto nivel del sistema, son muy modulares y simplifican la estructura y diseño del núcleo. Si falla uno de estos servidores, no se colgará el sistema entero, y se podrá reiniciar este módulo independientemente del resto. Sin embargo, la existencia de diferentes módulos independientes origina retardos en la comunicación debido a la copia de variables que se realiza en la comunicación entre módulos.

Algunos ejemplos de micronúcleos:

Frecuentemente se prefieren los núcleos monolíticos frente a los micronúcleos debido al menor nivel de complejidad que comporta el tratar con todo el código de control del sistema en un solo espacio de direccionamiento. Por ejemplo, XNU, el núcleo de Mac OS X, está basado en el núcleo Mach 3.0 y en FreeBSD, en el mismo espacio de direccionamiento para disminuir la latencia que comporta el diseño de micronúcleo convencional.

A principios de los años 1990, los núcleos monolíticos se consideraban obsoletos. El diseño de Linux como un núcleo monolítico en lugar de como un micronúcleo fue el tema de una famosa disputa entre Linus Torvalds y Andrew Tanenbaum. Los argumentos de ambas partes en esta discusión presentan algunas motivaciones interesantes.

Los núcleos monolíticos suelen ser más fáciles de diseñar correctamente, y por lo tanto pueden crecer más rápidamente que un sistema basado en micronúcleo, pero hay casos de éxito en ambos bandos. Los micronúcleos suelen usarse en robótica embebida o computadoras médicas, ya que la mayoría de los componentes del sistema operativo residen en su propio espacio de memoria privado y protegido. Esto no sería posible con los núcleos monolíticos, ni siquiera con los modernos que permiten cargar módulos del núcleo.

Aunque Mach es el micronúcleo generalista más conocido, se han desarrollado otros micronúcleos con propósitos más específicos. L3 fue creado para demostrar que los micronúcleos no son necesariamente lentos. La familia de micronúcleos L4 es la descendiente de L3, y una de sus últimas implementaciones, llamada Pistachio, permite ejecutar Linux simultáneamente con otros procesos, en espacios de direccionamiento separados.

QNX es un sistema operativo que ha estado disponible desde principios de los años 80, y tiene un diseño de micronúcleo muy minimalista. Este sistema ha conseguido llegar a las metas del paradigma del micronúcleo con mucho más éxito que Mach. Se usa en situaciones en que no se puede permitir que haya fallos de "software", lo que incluye desde brazos robóticos en naves espaciales, hasta máquinas que pulen cristal donde un pequeño error podría costar mucho dinero.

Mucha gente cree que como Mach básicamente falló en el intento de resolver el conjunto de problemas que los micronúcleos intentaban subsanar, toda la tecnología de micronúcleos es inútil. Los partidarios de Mach afirman que ésta es una actitud estrecha de miras que ha llegado a ser lo suficientemente popular para que mucha gente la acepte como verdad.

Los núcleos híbridos fundamentalmente son micronúcleos que tienen algo de código «no esencial» en espacio de núcleo para que este se ejecute más rápido de lo que lo haría si estuviera en espacio de usuario. Este fue un compromiso que muchos desarrolladores de los primeros sistemas operativos con arquitectura basada en micronúcleo adoptaron antes que se demostrara que los micronúcleos pueden tener muy buen rendimiento. La mayoría de sistemas operativos modernos pertenecen a esta categoría, siendo el más popular Microsoft Windows. XNU, el núcleo de Mac OS X, también es un micronúcleo modificado, debido a la inclusión de código del núcleo de FreeBSD en el núcleo basado en Mach. DragonFlyBSD es el primer sistema BSD que adopta una arquitectura de núcleo híbrido sin basarse en Mach.

Algunos ejemplos de núcleos híbridos:

Hay gente que confunde el término "núcleo híbrido" con los núcleos monolíticos que pueden cargar módulos después del arranque, lo que es un error. "Híbrido" implica que el núcleo en cuestión usa conceptos de arquitectura o mecanismos tanto del diseño monolítico como del micronúcleo, específicamente el paso de mensajes y la migración de código "no esencial" hacia el espacio de usuario, pero manteniendo cierto código "no esencial" en el propio núcleo por razones de rendimiento.

Los exonúcleos, también conocidos como sistemas operativos verticalmente estructurados, representan una aproximación radicalmente nueva al diseño de sistemas operativos.

La idea subyacente es permitir que el desarrollador tome todas las decisiones relativas al rendimiento del "hardware". Los exonúcleos son extremadamente pequeños, ya que limitan expresamente su funcionalidad a la protección y el multiplexado de los recursos. Se llaman así porque toda la funcionalidad deja de estar residente en memoria y pasa a estar fuera, en bibliotecas dinámicas.

Los diseños de núcleos clásicos (tanto el monolítico como el micronúcleo) abstraen el hardware, escondiendo los recursos bajo una capa de abstracción del "hardware", o detrás de los controladores de dispositivo. En los sistemas clásicos, si se asigna memoria física, nadie puede estar seguro de cuál es su localización real, por ejemplo.

La finalidad de un exonúcleo es permitir a una aplicación que solicite una región específica de la memoria, un bloque de disco concreto, etc., y simplemente asegurarse que los recursos pedidos están disponibles, y que el programa tiene derecho a acceder a ellos.

Debido a que el exonúcleo solo proporciona una interfaz al hardware de muy bajo nivel, careciendo de todas las funcionalidades de alto nivel de otros sistemas operativos, este es complementado por una "biblioteca de sistema operativo". Esta biblioteca se comunica con el exonúcleo subyacente, y facilita a los programadores de aplicaciones las funcionalidades que son comunes en otros sistemas operativos.

Algunas de las implicaciones teóricas de un sistema exonúcleo son que es posible tener distintos tipos de sistemas operativos (p. e. Windows, Unix) ejecutándose en un solo exonúcleo, y que los desarrolladores pueden elegir prescindir ó incrementar funcionalidades por motivos de rendimiento.

Actualmente, los diseños exonúcleo están fundamentalmente en fase de estudio y no se usan en ningún sistema popular. Un concepto de sistema operativo es Nemesis, creado por la Universidad de Cambridge, la Universidad de Glasgow, Citrix Systems y el Instituto Sueco de Informática. El MIT también ha diseñado algunos sistemas basados en exonúcleos.
Los exonúcleos se manejan en diferente estructura dado que también cumplen funciones distintas.




</doc>
<doc id="1595" url="https://es.wikipedia.org/wiki?curid=1595" title="Kilogramo">
Kilogramo

El kilogramo (símbolo: kg), es la unidad básica de masa del Sistema Internacional de Unidades (SI). Es una medida ampliamente utilizada en la ciencia, la ingeniería y el comercio en todo el mundo, y a menudo simplemente se le llama kilo en el habla cotidiana.

Es la única unidad básica que emplea un prefijo y la última unidad del SI que siguió definiéndose por un objeto patrón y no por una característica física fundamental. El 20 de mayo de 2019 su definición pasó a estar ligada con la constante de Planck, una constante natural que describe los paquetes de energía emitidos en forma de radiación. Esto permite que un laboratorio de metrología debidamente equipado calibre un instrumento de medición de masa como una balanza de potencia.

La definición oficial del kilogramo es:
De la relación exacta , se obtiene la expresión para el kilogramo en función del valor de la constante de Planck, formula_1:

formula_2

La primera definición, decidida en 1795 durante la Revolución francesa, especificaba que el gramo era la masa de un centímetro cúbico de agua pura en el punto de fusión del hielo (aproximadamente a 4 °C), lo que hacía que el kilogramo fuera igual a la masa de un litro de agua pura en el punto de fusión del hielo. Esta definición era complicada de realizar con exactitud, porque la densidad del agua depende levemente de la presión, con lo que el punto de fusión del hielo no tenía un valor exacto.

En 1875 se firma la Convención del Metro, lo que lleva a la producción del Prototipo Internacional del Kilogramo en 1879 y su adopción en 1889. Este prototipo estaba fabricado con una aleación de platino e iridio —en proporción de 90-10%, respectivamente, medida por el peso— en forma de cilindro circular recto, con una altura igual al diámetro de 39 milímetros. Tenía una masa igual a la masa de 1 dm de agua a presión atmosférica y a la temperatura de su densidad máxima, que es de aproximadamente 4 °C. Dicho prototipo se guarda en la Oficina Internacional de Pesas y Medidas, ubicada en Sèvres, en las cercanías de París (Francia). Este prototipo internacional es uno de tres cilindros hechos originalmente en 1879. En 1883 el prototipo demostró ser indistinguible de la masa del estándar del kilogramo en ese entonces, y se ratificó formalmente como el kilogramo en la primera Conferencia General de Pesas y Medidas en 1889.

Por definición, el error en la medición de la masa del Prototipo Internacional del Kilogramo era exactamente cero, pues el Prototipo Internacional del Kilogramo era el kilogramo. Sin embargo, a lo largo del tiempo se han podido detectar pequeños cambios comparando el estándar frente a sus copias oficiales. Comparando las masas relativas entre los estándares en un cierto plazo se estima la estabilidad del estándar. El prototipo internacional del kilogramo parecía haber perdido cerca de 50 microgramos en los últimos 100 años, y la razón de la pérdida sigue siendo desconocida.

130 años después de su implantación, se iniciaron gestiones para definir el patrón de kilogramo mediante propiedades físicas que no variaran con el tiempo. Se establecieron dos vías principales de investigación. La primera consistía en basar la definición el la masa atómica del silicio. Para ello era necesario fijar el valor del número de Avogadro y contar el número exacto de átomos presentes una esfera de silicio, casi perfecta en su geometría y composición isotópica, cuyas características dimensionales se pueden conocer con gran exactitud. Específicamente, se determinaría el volumen ocupado por la esfera y cada uno de sus átomos, y finalmente, con el número de Avogadro, se determinaría la masa.

La otra alternativa consistía en fijar el valor de la carga del electrón o el de la constante de Planck, que relaciona la energía y la frecuencia de una onda electromagnética por medio de la expresión formula_3 y se puede describir como la unidad de energía emitida en interacciones electromagnéticas. La relación entre la energía y la masa viene dada por la ecuación determinada por Einstein formula_4. Para obtener una definición precisa del kilogramo, el valor de formula_1 debía determinarse mediante varias mediciones con equipos diferentes; los valores obtenidos debían tener con una desviación estándar que no superara cinco partes en cien millones y coincidir entre ellos con un valor de confianza del 95 %. Con este fin, varios institutos nacionales de metrología trabajaron en la puesta a punto de un dispositivo desarrollado por Bryan Kibble del National Physical Laboratory británico, denominado balanza de Kibble, también llamada balanza de Watt o de vatios, debido a que el vatio ("watt" en inglés) es la unidad de la magnitud con la cual se compara una potencia mecánica con una eléctrica. La balanza de Kibble establece la relación entre una masa, la aceleración de la gravedad, una velocidad, dos frecuencias, y la constante de Planck.

A principios de 2011, poco antes de la celebración de la 24ª Conferencia General de Pesas y Medidas, se halló consenso en que el método que se utilizaría sería el de la constante de Planck. En 2017 varios laboratorios obtuvieron medidas de la constante que satisficeron los requisitos de la Oficina Internacional de Pesas y Medidas. El 16 de noviembre de 2018, la 26.ª Conferencia General de Pesos y Medidas anunció que la definición del kilogramo pasaría a estar ligada con la constante de Planck. De esta manera, se pueden calibrar los distintos patrones del kilogramo repartidos por el mundo empleando una balanza de Kibble y el nuevo valor de la constante. La nueva definición entró en vigor el 20 mayo de 2019, quedando el «Grand Kilo» —el patrón parisino— como un estándar de masa secundario. La constante de Planck pasó a ser definida como 6.62607015×10 kg⋅m⋅s, quedando el kilogramo definido a partir de esta y, consecuentemente, a partir de otras dos unidades básicas del SI, el segundo y el metro.

Con la anterior definición se fijaba el valor de la masa del prototipo internacional del kilogramo como exactamente igual a un kilogramo, y el valor de la constante de Planck formula_1 se determinaba experimentalmente, teniendo una incertidumbre asociada. La definición actual fija el valor numérico exacto de formula_1 y es la masa del prototipo la que hereda su incertidumbre (1 x 10), debiendo determinarse a partir de ahora experimentalmente. Esto mismo ocurre para el resto de las unidades.

El gramo es el término al cual se aplican los prefijos del SI. La razón por la que la unidad básica de la masa tiene un prefijo es histórica. Originalmente, la formación de un sistema decimal de unidades fue encargada por Luis XVI de Francia y, en los planes originales, el equivalente al kilogramo fue llamado "grave". Junto con el "grave" se creó también una unidad más pequeña llamada "gravet", que era equivalente a 0.001 kg (1 gramo), así como una unidad más grande llamada "bar", que era equivalente a 1000 kg (1 tonelada). Con esas medidas se creó la siguiente escala: miligravet, centigravet, decigravet, gravet (gr), centigrave, decigrave, grave (kg), centibar, decibar, bar (t). Sin embargo, el sistema métrico no entró en vigor sino hasta después de la revolución francesa.

En 1795 una nueva ley reemplazó los tres nombres ("gravet", "grave" y "bar") por un solo nombre de unidad genérico: el "gramo". El nuevo gramo era igual al antiguo gravet. Se añadieron cuatro nuevos prefijos para cubrir la misma gama de unidades que en 1793 (miligramo, centigramo, decigramo, gramo, decagramo, hectogramo, kilogramo, y miriagramo). El gramo era también la unidad básica del más viejo sistema de medida: el sistema CGS, que no es muy ampliamente utilizado.

También es común que se utilice el vocablo como unidad de fuerza en el Sistema Técnico de Unidades, aunque debe hacerse bajo el nombre de kilogramo-fuerza o kilopondio. El kilogramo fuerza o kilopondio es, por definición, el peso de una masa de 1 kilogramo en la gravedad estándar en la superficie terrestre; esto es, 9,80665 m/s. Por eso una masa de 1 kilogramo (Sistema Internacional de Unidades) pesa 1 kilogramo fuerza (Sistema Técnico) solamente si la gravedad tiene ese valor.

1 "kilogramo" es equivalente a:





</doc>
<doc id="1597" url="https://es.wikipedia.org/wiki?curid=1597" title="Kilómetro">
Kilómetro

El kilómetro (también escrito quilómetro, aunque en desuso) es una unidad de longitud. Es el tercer múltiplo del metro, equivalente a 1000 metros.

Su símbolo, km, no acepta plural ni lleva punto final —excepto cuando se encuentra como último elemento de una frase u oración— por no ser de una abreviatura. Se destaca, además, que el símbolo del prefijo kilo- debe ser escrito siempre con la letra k minúscula y redonda (o sea, no en cursiva).

Un kilómetro contiene:

Un kilómetro es aproximadamente igual a:



</doc>
<doc id="1598" url="https://es.wikipedia.org/wiki?curid=1598" title="Kilómetro cúbico">
Kilómetro cúbico

El kilómetro cúbico es una unidad de volumen. Se corresponde con el volumen de un cubo de mil metros (un kilómetro) de lado. Equivale a un teralitro (un millardo de metro cúbico) y es el tercer múltiplo del metro cúbico.

Su abreviatura es km.

Equivalencias




</doc>
<doc id="1599" url="https://es.wikipedia.org/wiki?curid=1599" title="Kilómetro cuadrado">
Kilómetro cuadrado

El kilómetro cuadrado es la unidad de superficie, o área, que corresponde con un cuadrado de un kilómetro de lado. Equivale a un millón de metros cuadrados. En el Sistema Internacional de Unidades (SI), su símbolo es km²: no admite punto, ni mayúscula, ni plural (véanse normas ortográficas de los símbolos del SI).

 es igual a:

Recíprocamente:





</doc>
<doc id="1602" url="https://es.wikipedia.org/wiki?curid=1602" title="Kmeria">
Kmeria

Kmeria es un género de árboles perteneciente a la familia Magnoliaceae, consiste en cinco especies nativas del este de Asia y sur de China e Indochina. 

El género estaba anteriormente incluido en "Magnolia", del cual fue separado sobre la base de sus flores unisexuales y forma ventral de dehiscence. No ha sido aceptado en el catálogo de "Flora de China", donde las especies han sido divididas entre los géneros "Woonyongia" ("K. septentrionalis") y "Parakmeria" (los otros).





</doc>
<doc id="1603" url="https://es.wikipedia.org/wiki?curid=1603" title="Korarchaeota">
Korarchaeota

Las korarqueotas (Korarchaeota) son un filo de arqueas, históricamente el tercero descubierto, después de Euryarchaeota y Crenarchaeota. Inicialmente se identificaron a partir de muestras de secuencias genómicas ARNr 16S recogidas en ambientes naturales, cuyos análisis sugirieron que estas arqueas formaban parte de un filo diferente a los dos ya conocidos. Sólo se los ha encontrado en ambientes hidrotermales y en poca abundancia. Parecen diversificados en diferentes niveles filogenéticos de acuerdo a la temperatura, salinidad (agua dulce o marina) y geografía. Korarchaeota forma parte del grupo TACK junto a otros filos de arqueas recientemente descubiertos.

Se ha encontrado evidencia de conservación de energía mediante metanogénesis y la reducción de azufre en ambientes hidrotermales suboxigénicos.



</doc>
<doc id="1605" url="https://es.wikipedia.org/wiki?curid=1605" title="Koeleria">
Koeleria

Koeleria es un género de gramíneas, familia (Poaceae) perennes distribuidas en las regiones templadas de ambos hemisferios. Comprende aproximadamente 25 especies.

"Koeleria" incluye a hierbas perennes, con hojas estrechas y espiguillas dispuestas en panojas contraídas espiciformes.

Las espiguillas son paucifloras, comprimidas lateralmente, con raquilla articulada por encima de las glumas y entre los antecios, prolongada más allá del último antecio fértil en forma de cerda delgada, o llevando un antecio atrofiado en su ápice. Las glumas son aproximadamente del mismo largo. Las lemmas son algo escariosas, obtusas, agudas o bidentadas en el ápice. Las páleas son hialinas, bicarendas, bidentadas o bimucronadas en el ápice. El cariopse es oblongo o lineal.

El género fue descrito por Christiaan Hendrik Persoon y publicado en "Synopsis Plantarum" 1: 97. 1805. La especie tipo es: "Poa nitida" Lam. = "Koeleria grandiflora" Bertol. ex Schult. 
"Koeleria": nombre genérico otorgado en honor de botánico alemán Georg Ludwig Koeler.
Tiene un número de cromosomas de, x = 7. 2n = 14, 26, 28, 40, 42, 43, 56, 70, 84, 112, y 126. 2, 4, 6, 8, 10, 12, 16, y 18 ploidias (and aneuploids). Cromosomas ‘grandes’.




</doc>
<doc id="1606" url="https://es.wikipedia.org/wiki?curid=1606" title="Kickstart">
Kickstart

El Kickstart es la parte del sistema operativo del AmigaOS que reside en ROM. Podría ser el equivalente a las BIOS de los PC, aunque realmente va mucho más allá de ser un mero gestor de configuración de la placa base.

El Kickstart contiene:


Junto con el Workbench conforman el sistema operativo del AmigaOS. No obstante, únicamente con el código del Kickstart es posible arrancar el Amiga directamente con el entorno de ventanas y un CLI ("Interfaz de línea de comandos").

Contiene el código necesario para iniciar el hardware estándar del Amiga y muchos de los componentes centrales del AmigaOS. La función del Kickstart es comparable a la del BIOS más el núcleo del sistema operativo en un ordenador compatible IBM PC. Aun así, Kickstart posee más funciones disponibles en el arranque que lo inicialmente esperado en un PC, por ejemplo, el sistema completo de ventanas.

El Kickstart contiene muchas partes básicas del sistema operativo del Amiga, como "Exec", "Intuition", el núcleo del "AmigaDOS" y funcionalidad para utilizar expansiones de hardware mediante "Autoconfig". Esto significa que un Amiga recién encendido tiene muchas de las partes esenciales de un sistema operativo disponibles. Versiones posteriores del Kickstart contenían drivers para controladores IDE y SCSI, puertos PC Card y otro hardware integrado en los Amiga.

Al (re)iniciar, el Kickstart realiza un número de comprobaciones y diagnósticos al sistema y después inicia el chipset del Amiga y algunos componentes del núcleo del S.O. Entonces examina los dispositivos de arranque conectados y trata de iniciar desde uno de los de prioridad de arranque mayor. Si no se encuentra ningún dispositivo de arranque, se muestra una pantalla pidiendo al usuario que inserte un disco de arranque, típicamente un disquete.

El primer modelo de Amiga, el 1000, requiere que el Kickstart 1.x sea cargado desde un disquete en una sección de 256 KB de la RAM, llamada "writable control store"(WCS). Algunos programas del A1000 (principalmente "Dragon's Lair") incluían un código base alternativo para poder usar esos 256 KB extra para datos. Modelos posteriores de Amiga llevan incluido el Kickstart en un chip ROM, mejorando así los tiempos de arranque. El A1000 también se puede modificar para incluir dichos chips.

El Kickstart estaba almacenado en chips de ROM de 256 KB en las versiones anteriores al AmigaOS 2.0. Las versiones posteriores usan chips de ROM de 512 KB, conteniendo nuevas y mejoradas funcionalidades. El Commodore Amiga CD32 incluye una ROM de 1 MB (Kickstart 3.1) con firmware adicional y un sistema de archivos integrado para soportar unidades de CD-ROM.

Los primeros modelos Amiga 3000 fueron, al igual que el A1000, empaquetados con el Kickstart en un disquete, debido a que incluían la versión 1.4 beta en ROM. Tanto el Kickstart 1.3 como el 2.0 podían extraerse en una partición llamada específicamente WB_1.3 o WB_2.x, respectivamente, e incluido en DEVS:kickstart, un sistema de localización absoluto de donde el sistema A3000 lo encuentra en el arranque y lo copia en RAM. Estos A3000 iniciales soportaban la inclusión del Kickstart tanto en ROM como en disquete, aunque no de manera simultánea. Un A3000 configurado para usar imágenes del Kickstart en disco tiene el beneficio de ser capaz de arrancar desde varias versiones de AmigaOS con niveles altos de compatibilidad, simplemente seleccionando la imagen apropiada en el arranque.

El Commodore CD-TV incluyó ROMs con firmware adiciona que no es técnicamente parte del Kickstart. La ROM del firmware original del CD-TV debe ser actualizada para instalar una versión del Kickstart posterior a la 1.3.

El AmigaOS 2.1 es solo una actualización de software y no tiene una serie de chips ROM correspondiente. El Workbench 2.1 funciona en todas las ROMs Kickstart de la familia 2.0x. Las versiones posteriores del AmigaOS (3.5 y 3.9) son también actualizaciones solo software y no incluyen ROMs correspondientes, necesitando en su lugar el Kickstart 3.1. A partir de la versión 3.5 del AmigaOS se usa un sistema de componentes basados en un "fichero ROM" que reemplazan los chips ROMs.

Encontramos las siguientes versiones del Kickstart:


</doc>
<doc id="1607" url="https://es.wikipedia.org/wiki?curid=1607" title="Karate">
Karate

El kárate o karate (del japonés 空手 "karate", literalmente 'mano vacía') es un arte marcial tradicional de las islas Ryūkyū pertenecientes a Japón, conocidas como la prefectura de Okinawa, basado en algunos estilos de las artes marciales chinas, o "wushu", y en menor medida en otras disciplinas provenientes del sureste asiático. El nombre japonés se compone de las palabras 空 ("kara" 'vacío') y 手 ("te" 'mano'). A la persona que lo practica se la llama karateca.

El kárate tiene su origen durante el siglo XVI en las técnicas marciales nativas de las islas Ryukyu, (hoy día Okinawa). Llamadas 
técnicas de lucha nativa; así como en algunos estilos de las artes marciales chinas y está influenciado en menor medida por otras disciplinas provenientes de otros países del sureste asiático como Tailandia, Filipinas e Indonesia. Ya, en el siglo XX este estilo marcial fue influenciado en un principio por varios conceptos técnicos, tácticos y filosóficos procedentes de algunas de las artes marciales japonesas modernas, como: el kendo , el judo, y eventualmente el aikido. En un principio, El "Te" siendo el arte antecesor al karate moderno surgió de la necesidad de los guerreros nobles de la isla (los "pechin") de proteger al último rey de Okinawa, Sho Tai, y a sí mismos de los varios abusos perpetrados por los guerreros con armadura (los samuráis), quienes hacían parte de los invasores japoneses pertenecientes al clan Satsuma, en el siglo XVII. Poco a poco, el "Te" fue desarrollado en el reino de Ryukyu, y posteriormente se expandió: se enseñó sistemáticamente en Japón después de la era Taisho en el siglo XX, donde fue renombrado como karate-Do, como consecuencia de los intercambios culturales entre los japoneses y los habitantes de las islas Ryukyu. Incorporándose así a la cultura de las artes marciales tradicionales del Japón o Budo.

El "karate-Do" de hoy en día se caracteriza fundamentalmente por el empleo de golpes de puño, bloqueos, patadas y golpes de mano abierta, donde las diferentes técnicas reciben varios nombres, según la zona del cuerpo a defender o atacar. Sin embargo el karate, no restringe su repertorio solo a estos, ya que además incluye: varios barridos, algunos lanzamientos y derribos, unas pocas luxaciones articulares; además de golpes a puntos vulnerables, y a puntos nerviosos, en su currículo. En los golpes del "karate-Do" se unifican la fuerza, la rapidez, la respiración, el equilibrio, la tensión y la relajación al aplicar un correcto giro de cadera y una conexión o sinergia muy precisa de músculos y articulaciones, trasladando una gran parte del peso corporal y del centro de gravedad al impacto. Generalmente, y a diferencia de otras disciplinas, se busca derrotar al adversario mediante un impacto contundente (o unos pocos), preciso y definitivo, buscando ser lo más eficaz posible. A ese concepto se le llama "Ikken hikatsu" o "un golpe, una muerte", de forma semejante a la estocada o al corte de una katana o sable japonés.

Las sucesivas prohibiciones al porte de armas en la historia de la isla de Okinawa y la importancia dada a las artes marciales sin armas se debe a que la isla, mucho antes de ser anexada al Shogunato de Japón, ya era un puerto libre y reino independiente donde atracaban numerosas embarcaciones provenientes de varias partes de Asia (China, Corea, Tailandia, Indonesia, Filipinas). La isla de Okinawa fue asimismo el primer lugar donde llegó la nave del comodoro Perry de los EE.UU. en el siglo XIX antes de llegar a la ciudad puerto Yokohama, en el Japón, para obligar a los japoneses a abrir sus rutas comerciales; pues desde 1639 hasta 1853 tanto japoneses como okinawenses habían vivido aislados del mundo exterior por decreto del shōgun (líder militar) Tokugawa Iemitsu, hasta la época moderna (siglo XX), en que el último de los Tokugawa, Tokugawa Yoshinobu, cedió el poder total y definitivamente al emperador Meiji entre 1868 y 1902.

En la isla de Okinawa se vivía una situación naval y comercial de gran intercambio entre varios reinos, similar a la de las islas Filipinas, aunque con varias prohibiciones al porte de armas que se iniciaron en 1409 por el entonces rey Sho Shin, que favorecieron la unificación de los pequeños feudos en que se encontraba dividida la isla, evitando así futuras divisiones y conflictos entre los visitantes y los nativos. Estas medidas fueron luego enfatizadas de nuevo ya en 1609 por los guerreros samurái japoneses invasores pertenecientes al clan Satsuma, quienes confiscaron las armas restantes. Durante este periodo la vida fue aún más austera y restrictiva, obligando tanto a los nobles (Pechin) como al pueblo a desarrollar aún más los métodos de combate tanto con implementos agrícolas (kobudō), como a mano vacía (karate) respectivamente.

Durante los siglos XIX y XX se encontraban establecidos ciertos estilos de acuerdo a la estricta división regional por clases sociales, y según el énfasis, entre los movimientos circulares o lineales, así como la preferencia por el combate a distancia media y larga. De esta forma, las principales variantes del "Te", o mano practicadas en Okinawa eran: "Shuri-Te", "Naha-Te", y "Tomari-Te". Cada una de ellas contaba con características particulares tanto en las técnicas como en los métodos de práctica. En este período tres maestros se encargaron de sistematizar y revivir la práctica del karate: Anko Itosu ("Shuri-Te"), Kanryo Higaonna ("Naha-Te"), y Kosaku Matsumura ("Tomari-Te"). Con el fin de integrarse al sistema educativo escolar militar japonés. En 1872 el emperador Meiji otorgó la isla de Okinawa al clan samurái Satsuma, y nombra a sus miembros como sus únicos representantes en el territorio. En 1879 el gobierno Meiji dicta: la abolición de la familia real 'Sho' de las islas Ryukyu, el exilio del rey Sho Tai, y crea la Prefectura de Okinawa.

Los términos empleados en esa época para denominar de manera general a estos estilos nativos fueron , y . Términos que a principios del siglo XX, fueron asimilados dentro del término genérico de Kárate.

De 1901 a 1905 las escuelas de la prefectura de Okinawa comienzan a adoptar el "tuidi" como parte del programa de educación física. En esta época, el maestro cambió la pronunciación de 唐手 desde "tode" o "tuidi" a "karate". Entre 1904 y 1905, Chomo Hanashiro (estilo Shorin Ryu) y posteriormente otros maestros empiezan a emplear por primera vez los kanji 空手 en lugar de los ideogramas 唐手. En 1933, en el capítulo dedidado a Okinawa reconocido por la asociación nacional de las artes marciales del Japón o "Dai Nihon Butokukai" se reconoce al como arte marcial japonés.

Al karate se le conoce hoy en día como "el camino de la mano vacía". Siendo esta la interpretación de los ideogramas para el término Karate-Do, popularizada en occidente por el maestro Masatoshi Nakayama, representante de la Asociación Japonesa de Karate (o JKA), que promovió el estilo Shotokan o (JKA) después de la segunda guerra mundial (1939-1945), cuando se buscaba mostrar al Japón como un país pacífico ante la ocupación de los Estados Unidos, quienes prohibieron la práctica de las artes marciales por considerarlas un remanente del espíritu imperial del Japón. Esta traducción fue aceptada como alusión a la no inclusión de armas, o de ánimo bélico en el karate moderno. Sin embargo, hay que notar que todos los máximos exponentes y maestros del kárate; hasta muy recientemente, tenían conocimientos del arte del kobudo, o arte marcial del manejo de las armas tradicionales de Okinawa, como el bastón largo o bo, las macanas o tonfa, los tridentes o dagas sai, los molinos de arroz/ bridas del caballo, o nunchaku, las hoces de segar o kama, los nudillos de hierro o tekko, etc. Incluidas y preservadas hoy en día como un arte marcial por separado, aunque preservado dentro de algunos estilos de karate. Así mismo han sido varios los maestros de kárate que practicaron de manera paralela el arte del sable japonés moderno o kendo, y/o el arte moderno de la lucha o Yudo. También, otra traducción de la palabra Karate es "la mano que emerge/contiene al vacío, al todo" o "la mano del absoluto", "el camino de la voluntad". Podría hablarse inclusive del "camino del absoluto" debido a la profundidad filosófica, física y técnico-táctica del arte no solo en lo físico, sino en su posible aplicación mental y a la vida diaria, llegando a definir la vida de algunos practicantes. Otra posible traducción es "el camino de la mano y de la vida" pues el vacío o "kara" filosóficamente lo contiene todo; como esencia sin ataduras, sin juicios, sin límites, sin forma.

Si bien se reconocen como los precursores del karate clásico a los maestros Kanga Sakukawa ( también conocido como To-de Sakukawa) y Sokon Matsumura, así como a sus discípulos: Chutoku Kyan, Asato Ankō, Anko Itosu, entre muchos otros. Fue uno de sus alumnos de tercera generación, el maestro Gichin Funakoshi, el fundador del karate estilo Shotokan, a quien se le conoce como el "padre del karate moderno", siendo el mayor responsable de haber introducido y popularizado el karate en las islas principales de Japón. Sin embargo hay que notar, que durante el inicio del siglo XX varios otros maestros de Okinawa estuvieron dedicados a la enseñanza, por lo que fueron también responsables del desarrollo del karate en las islas principales del Japón. Gichin Funakoshi fue estudiante de Asato Ankō y Anko Itosu (quienes habían trabajado para introducir el karate en el sistema escolar de la prefectura de Okinawa desde 1902). Durante esta época, los maestros destacados que también influyeron en la difusión del Karate en Japón incluyen a Kenwa Mabuni (estilo Shito Ryu), Chojun Miyagi (estilo Goju Ryu), Motobu Chōki (estilo Motobu Ryu), Kanken Toyama (estilo Shudokan, quien incluso instruyó a los coreanos de los que surgiría el taekwondo ) y Kanbun Uechi (estilo Uechi Ryu). Este fue un período turbulento en la historia de la región, que incluyó eventos como la anexión del archipiélago de Okinawa al Japón en 1872, la Primera Guerra Sino-Japonesa (1894-1895), la guerra ruso-japonesa (1904-1905), la invasión y anexión de Corea (1910-1945), y el ascenso del militarismo japonés (1905-1945), además de la segunda guerra mundial (1939-1945).

La primera demostración pública del Karate en el Japón fue en 1917 en el Butoku-den de Kyoto, por Gichin Funakoshi. Esta y posteriores demostraciones dejaron bastante impresionados a muchos japoneses, entre ellos al príncipe heredero Hirohito, que quedó entusiasmado con el arte marcial de Okinawa. En 1922, el Dr. Jigoro Kano, fundador del arte japonés del Yudo, invitó al maestro Funakoshi al Dojo Kodokan para hacer una demostración y permanecer en Japón para enseñar karate. Este patrocinio fue clave para el establecimiento y posterior desarrollo del karate en Japón. Sin el respaldo del maestro Kano, el arte marcial okinawense, considerado hasta entonces como un "arte campesino, provincial, atrasado", habría sido despreciado aún más por los japoneses. Por otro lado, en el año 1929 el Maestro Kenwa Mabuni se instaló en la ciudad de Osaka para enseñar su estilo de karate, el karate Shito Ryu.

En 1949 se fundó la Asociación Japonesa de Karate (o JKA según sus siglas en inglés, o Japan Karate Association). Liderada por un alumno del Funakoshi. El maestro Masatoshi Nakayama. La JKA realizó los primeros campeonatos de kárate del Japón en 1957. La asociación pretendió inicialmente agrupar a los diferentes estilos del arte, a medida que popularizaba su práctica en occidente; pero eventualmente se convirtió en la representante a nivel mundial del karate estilo Shotokan variante JKA o Kyokai, como es conocido en Japón.

El uniforme de práctica (gi) empleado en el karate es el keikogi o karategi, (gi = traje) compuesto por una chaqueta, pantalones y un cinturón. El "karategi" se deriva del "judogi", dada la influencia de Jigorō Kanō fundador del arte marcial y deporte olímpico del yudo; a principios del siglo XX en las artes marciales japonesas modernas o Gendai Budō.
Actualmente existen dos tipos de "karate-gi" para competición: el de "kumite" o combate, que es más ligero, y el de "katas" o formas, que es más grueso y pesado.

La existencia de cinturones varía de unos estilos a otros, pero por lo general suelen ser reconocidos: los llamados grados Kyu o cinturones de nivel inferior, e intermedio y los Dan o cinturones negros superiores. 

Tomado el modelo del yudo, se establecieron los grados "kyus" o cinturones de nivel inferior. Los "kyus" comienzan con el "blanco" para los principiantes. Con el aprendizaje progresivo de las técnicas se va subiendo de nivel y va cambiando el color del cinturón. Al blanco (Rukkyu) le siguen, por orden de menor a mayor, el amarillo (Yonkyu), el naranja (Sankyu), el verde (Nikyu), el azul, el marrón (Ikkyu) y, por último, el negro (Kuroi), aunque con puntos intermedios entre una mezcla del anterior con el posterior (blanco-amarillo, amarillo-naranja, etc). No obstante, los cinturones de colores también pueden variar según las escuelas, ya que en algunas escuelas alteran el orden de los colores, o quitan alguno de los colores antes nombrados.

Estos cinturones intermedios se dan a los alumnos que tienen poca edad (aproximadamente hasta los 13-14 años) porque aprenden más lentamente y el hecho de poder examinarse de estos cinturones evita su aburrimiento al tener que esperar para pasar de un cinturón a otro. La Federación Mundial de Karate (WKF) establece como requisito el tener una edad mínima de dieciséis años para estar en posesión de primer dan. Los cinturones intermedios son los siguientes: blanco-amarillo, amarillo-naranja, naranja-verde, verde-azul y azul-marrón. Después de este último se pasa al marrón y después directamente al negro. 
Una vez se es cinturón negro, se sigue aumentando progresivamente en grados, llamados "danes". La numeración es ascendente, de primer a décimo dan: 
1er. dan (Shodan), 2º dan (Nidan), 3er. dan (Sandan), 4º dan (Yondan) y 5º dan (Godan). De ahí en adelante, en la normativa actual de algunos estilos el color del cinturón cambia, pasando a ser: 6º dan (Rokudan), 7º dan (Sichidan) y 8º dan (Hachidan) de color rojo-blanco, mientras que el 9º dan (Kudan) y el 10º dan (Judan) pueden ser de color rojo, que es el último nivel existente. Jigoro Kano fue quien quiso establecer las rayas alternativas de color blanco y rojo a partir del 6º y 7º Dan y el cinturón rojo para el 9º y 10º Dan ya que un cinturón negro se desgasta después de muchos años y vuelve a convertirse en blanco simbolizando el fin filosófico del color. Por ello, se añaden las franjas rojas en el color blanco cuando se llega a tan alto nivel.

Al margen de la Federación, las distintas escuelas y estilos suelen seguir sus propios sistemas sin atender en muchos casos lo establecido por este organismo. Esta numeración varía según la escuela, siendo lo habitual en la actualidad siete grados, pero manteniéndose en algunas escuelas tradicionales un sistema de cinco danés. Tradicionalmente era solamente hasta el 5.º dan; esto por varias razones: una es la que se asocia a la progresión con los cinco círculos del legendario guerrero samurái Miyamoto Musashi; algunas escuelas aun mantienen hasta el 5º dan, generalmente las más tradicionales o que tienen una relación directa con el maestro fundador del karate Shotokan Gichin Funakoshi, tales como por ejemplo: Shotokai y Shotokan of America (o SKA), ya que según la escala del maestro Funakoshi el grado más alto era el 5º dan; de hecho, en la época en la que Funakoshi aprendió el arte del "tuidi", "to-de" o "te", aun no existían los grados dan, sin embargo muchas escuelas alejándose de la parte tradicional han adquirido hasta el décimo dan.

Sensei (先生) es el término japonés con el que se designa a un maestro, a un sabio o a una persona docta. Fuera del Japón se emplea sobre todo en el mundo de las artes marciales tradicionales o "gendai budō" (entre estas, el Aikido, el karate-Do, el Yudo, el Kendo, etc.). Literalmente, el término "sensei" significa 'el que ha nacido antes', a partir de los caracteres "kanji" sen (先 "antes") sei (生 "nacer, vida"). O bien, desde la filosofía, como 'el que ha recorrido el camino', un guía.

Artículo Principal: Shihan

Shihan (師範) es un término del idioma japonés, generalmente usado en las artes marciales procedentes de Japón como un título honorífico para referirse a los maestros de maestros en un estilo específico.

Las diferentes organizaciones de artes marciales tienen diversos requerimientos para el uso del término en carácter de título honorífico, generalmente involucra ciertos derechos como el de usar símbolos especiales que identifican el rango y otorgar grados en el arte en el cual se ostenta.

Por ejemplo en la organización del arte del "ninjutsu", la Bujinkan se genera el derecho cuando los otros Shihan se refieren a la persona con ese título (debe tener como mínimo 10 "dan" ya que esta organización son 15 el máximo), en yudo, y en "aikidō" se llega al título de "Shihan" al alcanzar al menos el grado de sexto "dan".

En Karate se llega a este título en cuarto dan con el nombramiento de Shihan-Dai, posteriormente pasado el séptimo dan se le nombra Shihan únicamente, en noveno y décimo se nombra Soke .

Los cinturones de estos shihanes varían según la organización a la que pertenezcan siendo muy habitual la utilización de una franja roja en medio del cinturón el cual va creciendo al mismo tiempo que el Shihan avanza de grado hasta que en el décimo dan o soke la franja cubre toda la cara frontal del cinturón, pero en los sistemas los cuales llegan hasta séptimo dan este es de color rojo con blanco.

Antes de comenzar la práctica y al terminarla, y también antes de comenzar un ejercicio específico, se realizan sencillos Rei (saludos) como ritual, con el fin de que los practicantes interioricen los valores de cortesía y respeto por los demás. Estos saludos consisten en inclinaciones del tronco sentados o de pie, hechos en grupo o por parejas según el momento, y al entrar y salir de la clase o el tatami (estera). A veces se acompaña el saludo con la expresión ""¡Oss!"". Algunos de esos saludos son:


Además en las enseñanzas de karate hay que respetar ciertas normas como esperar a la orden del instructor para dar por finalizado un ejercicio o realizar ciertas acciones, no conversar en la clase, prestar atención siempre que el instructor explique algo, tener siempre una actitud constructiva cuando se hable, etc.

En el kárate hay un gran uso del "ki" o intención emocional, además de una alineación corporal precisa. Los katas o formas/coreografías y las formas de defensa son esquemas rítmicos, pero rígidos. Las técnicas utilizan diferentes partes del cuerpo para golpear, como las manos (canto, palma, dedos, nudillos), los pies (talón, borde externo, borde interno, planta, base o punta de los dedos), los codos, los antebrazos, las rodillas o la cabeza, o el hueso tibial en algunos estilos como el kyokushinkai, en las técnicas de patadas bajas a los muslos o "low kicks"/ gedan geri.

Actualmente el karate, Deriva su metodología de enseñanza del método "Kaisen" o búsqueda del mejoramiento continuo por medio de la repetición, la observación, el análisis, la retroalimentación, la ejecución y la repetición consciente (incluyendo sus aspectos físico, técnico, táctico y de condicionamiento psicológico ritual). Este método de enseñanza es común a las artes marciales tradicionales contemporáneas del Japón (Gendai Budō). El kárate asimismo toma su sistema de grados por cinturones (kyu-dan), varios de sus barridos a los pies y uniforme del yudo.

En las primeras etapas, es decir en los grados kyu o de cinturones de colores, hasta el grado de cinturón negro 1 Dan; se busca que el practicante del arte desarrolle: la correcta alineación corporal, el ajuste (o relación tensión - relajación ), los bloqueos/chequeos, las esquivas, los golpes a puntos vulnerables, los desplazamientos, los barridos, los contraataques, y el acondicionamiento físico específico caracterizado por el "endurecimiento" y/o desensibilización de varios segmentos corporales. Posteriormente, ya en los grados superiores se da un mayor énfasis a: los lanzamientos y derribos, los golpes a puntos vitales, algunas luxaciones articulares, incluyendo unas pocas estrangulaciones, y varias técnicas de combate desde el suelo; como barridos, atrapes y luxaciones. Sin embargo, nótese que en Karate no se combate en el suelo, como sí ocurre en Yudo, lucha o en Bjj. Y finalmente tras muchos años de práctica se llega al tratamiento de lesiones, los métodos de reanimación y el estudio de los circuitos metabólicos y nerviosos de estimulación o depresión energética por "puntos vitales", o "kyusho" como ocurre en las disciplinas predecesoras del arte, siendo estas las artes marciales chinas.

Las técnicas, tácticas, estrategia y métodos propios de preparación física del kárate están descritos de la siguiente manera:


Nótese que en su parte metodológica, la enseñanza y el entrenamiento del karate, se divide por lo general según los siguientes objetivos de enseñanza:

- En Karate-Do moderno y karate deportivo: Kihon, Kata, ippon kumite, y Shiai kumite. 

- En karate tradicional y de autodefensa: Kihon, Hojo Undo, kata, Bunkai, kakie, ippon kumite, ju kumite.

Series de técnicas básicas ejecutadas por separado o en combinación con otras, en varias direcciones, ejecutadas al aire de forma fluida (para estudiar los detalles) o con fuerza (para practicar la velocidad, intensidad, etc) o contra implementos, como el makiwara, el saco, los guantes de foco, etc. (para practicar mejorando el impacto). Se busca mejorar la alineación corporal, el tomar conciencia del alcance de las diferentes técnicas, desarrollar coordinación lineal y cruzada, tomar conciencia de la sinergia muscular (conexión) necesaria de los grupos musculares específicos a ser usados en cada técnica, desarrollar los reflejos y la velocidad de reacción, desarrollar la flexibilidad gestual, reforzar el condicionamiento neural motriz, trabajar de diferentes maneras la respiración, desarrollar la intención emocional, además de potenciar la autoconfianza.

Después del Kihon se pasa a aprender los "Kata", que son secuencias preestablecidas de esas técnicas, elaboradas por maestros para practicar un subestilo de autodefensa dentro del karate o aspectos concretos del mismo.

Se considera parte del Kihon el combate preestablecido con técnicas tradicionales de ataque y defensa en secuencia, o combinaciones de estas, realizadas por parejas a 5, 3, y 1 paso, o kihon kumite, esta práctica es similar al bunkai pero mucho más simplificada.

"Kata" significa "forma". A nivel básico, se toma como una sucesión de técnicas de defensa y ataque enlazadas y coordinadas contra uno o varios enemigos imaginarios. Siempre siguiendo el embusen: la línea imaginaria para realizar el kata.

Todo el volumen de técnicas, tácticas y algunos apartados de acondicionamiento físico para la práctica de esta arte marcial se encuentran resumidos en los katas. El kata es la base, el fundamento del entrenamiento clásico del karate como arte marcial y método de defensa personal civil. Deben ser decodificados, interpretados, practicados y aplicados mediante la práctica del bunkai.

Casi la totalidad de los katas son de origen chino, modificados por los maestros de Okinawa y readaptados por los japoneses. Cada estilo trabaja y estudia ciertos katas, variando los tipos y número de katas en cada estilo y habiendo diferencias (en ocasiones notables) de un estilo a otro en un mismo kata (ritmo, trayectoria, uso de las distancias, aplicación de la potencia, énfasis en técnicas a mano abierta o cerrada, de corto o largo alcance, etc). 

Respecto de los orígenes históricos de las katas cabe destacar la investigación llevada a cabo por el antropólogo español Pablo Pereda sobre el antiguo To-De Okinawense, que las enlaza con algunas técnicas espirituales usadas en el taoísmo. Su trabajo está publicado por la Universidad de León, España.

La inclusión de la modalidad de katas para competición ha sido sujeto de controversias durante décadas. Para los tradicionalistas desvirtúa el karate tradicional, al dejar a un lado varias acciones motrices puntuales que son modificadas para la estética de la competición, y al perder parte de la adaptación motriz necesaria para la defensa personal. Para los seguidores del karate deportivo fomenta el trabajo uniforme de la técnica básica y el entrenamiento memorístico de la misma. En el kata de competición se prefieren movimientos casi gimnásticos, ejecutando gestos más vistosos, (como las patadas altas), o amplios y/o cortos pero muy rápidos, distintos de la aplicación a la defensa personal original, a media y corta distancia. Los rangos de movimiento tienden a ampliarse, así como varios de los movimientos se han hecho más explosivos con el fin de hacerlos más vistosos. Con esos cambios, es de notarse que gran parte de este tipo de movimientos deportivos no son prácticos y eficaces en una situación de defensa personal real.

Durante la competición, en la modalidad de katas o formas tipo WKF ("World Karate Federation") se enfrentan dos contrincantes. Cada uno llevará un cinturón de color rojo y azul. El color del cinturón se sortea antes de la competición, siendo totalmente independiente del grado de los participantes. El participante Aka (rojo) será el que ejecute su kata primero, y Ao (azul) ejecutará su kata en segundo lugar. El jurado valorará y comparará ambas ejecuciones y el ganador se decidirá mediante la puntuación establecida por estos, como dice la nueva normativa de la WKF. Si son tres árbitros, el que reciba dos banderas a favor será el vencedor; si son cinco, deberá conseguir un mínimo de tres banderas a favor. Si uno de los dos participantes se equivoca durante su ejecución será directamente eliminado, ganando así el oponente.

En el caso de competición por equipos, serán tres personas por equipo, se observan, entre otros: la sincronía de los participantes, la explosividad y la secuencia técnica. Solo el karateka en el centro del grupo indicará el nombre del kata y dará la orden de comenzar,

"Kumite" significa "entrelazar/ cruzar / unir las manos" o "combate". Es la aplicación práctica de las técnicas a un enfrentamiento contra un oponente real.

En el karate actual, existen varios tipos de combate , o kumite, según sea la finalidad de la práctica, sea tradicional o deportiva, así: 


El desarrollo de los diferentes tipos de combate o kumite , se inició, por el kihon kumite, o combate de aprendizaje por medio de movimientos formales preestablecidos, este modelo fue desarrollado en Japón con base en el arte del sable o kendo. Este tipo de combate consiste en la aplicación por parejas de técnicas en ataque, defensa y contraataque recogidas en el kihon y en los katas, realizándolo en varios pasos hasta llegar a un solo paso. Pudiéndolo ejecutar a varios niveles (alto) jodan, (medio) chudan, (bajo) gedan, (ushiro) desde atrás, (yoko) desde uno o ambos lados; alternando niveles, velocidades, uso de los pies y manos de forma alterna, por separado o de forma simultánea, incluyendo finalmente dentro del estudio del karate como Budo (arte marcial) a modo de semi-contacto, técnicas poco comunes como: agarres, lanzamientos, algunas luxaciones y unas pocas estrangulaciones, permitiendo el estudio y madurez técnica y emocional. A su vez, desde la metodología el kihon kumite, o combate formativo Se divide en: 


Con el fin de hacerlo más dinámico, en esta forma de combate le fueron dadas normas de puntuación, las cuales se reformaron en el 2011, posteriormente las técnicas se les dieron puntos así:


La siguiente etapa histórica fue el combate deportivo, o Shiai kumite (o combate deportivo libre reglado entre dos oponentes), donde se incluyen las pocas técnicas de golpeo válidas en el combate deportivo, y finalmente desarrollar con los grados medios (o desde el 5 kyu) y los grados altos es decir ( desde el 2 kyu y después del cinturón negro primer (1) Dan), quienes ya deben tener la suficiente madurez emocional, precisión, rapidez y control, el Ju-Shiai kumite (o combate libre deportivo entre dos oponentes), para más adelante en el transcurso de la evolución marcial del practicante, realizar el kata bunkai kumite, donde se busca explorar, realizar y aplicar un repertorio seleccionado y variado de las técnicas y tácticas contenidas en las formas del karate, como Budo, es decir orientadas a la defensa personal. 

Actualmente, permanecen dos modalidades de Kumite deportivo o Shiai kumite , o combate de competición: el Jyu Kumite, tiene una mayor difusión realizándose al punto o con contacto ligero, conocido como kumite tipo JKA, o de la Japanese karate Association/ Asociación Japonesa de Karate, y el kumite tipo WKF, en alusión a la Federación Mundial de Karate o 'World Karate Federation'. Estos reciben el nombre de Shiai - Kumite. Se trata de combates entre dos deportistas con reglas, en el que cada contrincante debe anotar el mayor número de puntos, en un tiempo límite, intentando marcar algunas técnicas no letales, sobre el rival en zonas y con superficies de contacto permitidas. Con los requisitos de: buena forma, actitud vigorosa, deportividad, distancia correcta y tiempo adecuado. Generalmente los deportistas van protegidos por una serie de protecciones reglamentarias; como guantines, protectores bucal e inguinal, espinilleras y zapatones de espuma. El casco se usa para algunas categorías y modalidades.

Así, dos oponentes con cinturones de diferentes colores (rojo o azul) se sitúan en los extremos del tatami (o superficie de competencia), y cuando se les da la orden, entran y saludan a los jueces y al rival esperando a que se dé la señal de comenzar el combate. Para ganar, los competidores deberán marcar el máximo de puntos posibles (golpes de puño, de pie, lanzamientos, y barridos reglamentarios) en un tiempo límite. Al finalizar el tiempo, y una vez declarada la victoria de uno de los competidores, estos saludarán al árbitro y luego se saludarán entre ellos mismos, dándose también la mano y despidiéndose al salir de la estera o Tatami.

El término bunkai se refiere a la aplicación en combate o autodefensa de las técnicas incluidas en las formas o kata. En las escuelas clásicas del karate de Okinawa (como por ejemplo: Shorin Ryu, Goju Ryu, y Uechi Ryu) el bunkai, o porqué de la técnica (gesto) y la táctica (desplazamiento) son de vital importancia y ocupan una gran parte del tiempo de entrenamiento, además del trabajo de acondicionamiento físico. Sin estos aspectos, la comprensión de los kata quedaría incompleta. Sin embargo, para las escuelas tradicionales y modernas de karate-do provenientes del Japón, (como por ejemplo: Shotokan, Shito ryu, Wado Ryu, etc.) quienes poseen un mayor énfasis deportivo; el bunkai es un complemento de las formas o kata transmitido de forma repetitiva, sin profundizar, siendo menos importante y detallado, orientado hacia el cómo, en búsqueda de una ejecución técnica perfecta. Más en las escuelas provenientes de Okinawa se busca el desarrollo de los diferentes medios físicos de autodefensa para una situación de peligro real, es decir sin reglas. Actualmente el estudio del bunkai como medio de legítima defensa está recibiendo cada vez mayor atención en el mundo del karate occidental. Algunos de los pioneros más conocidos en esta faceta de la disciplina son: Patrick McCarthy, Harry Cook, Iain Abernethy, Ryan Parker, entre otros. Ya que en las últimas décadas la faceta de la defensa personal ha sido abandonada en muchas escuelas de karate-Do actuales, favoreciendo la formación del individuo y la orientación deportiva limitándose a la metodología del perfeccionamiento estético de los kata, el kihon, y al desarrollo del combate deportivo o kumite, sea a los puntos; o bien con contacto a similitud del kickboxing, como ocurre en el estilo Kyokushinkai.

El Bunkai como aplicación de las técnicas de básicas o "kihon" y de los movimientos pertenecientes a las formas o "kata" sirve para ajustar y adoptar el uso técnicas y tácticas reales (incluyendo por ejemplo: las patadas bajas, la alternancia entre posiciones altas y bajas, el uso de la mano en "hikite" en todos los golpes, haciendo un mayor énfasis en las combinaciones de golpes, luxaciones, estrangulaciones, golpes de mano abierta, y lanzamientos). Haciendo frente a un oponente palpable y no imaginario, haciéndose patente el estudio del propio rango o distancia, la potencia a aplicar, el manejo de la media distancia, el desarrollo de los reflejos, la precisión en los golpes, los desplazamientos, el uso de las posiciones en movimiento, etc. Elementos que en la práctica individual no pueden ser desarrollados con eficacia. Existe aun el estereotipo pedagógico según el cual, el kata es un combate imaginario contra varios atacantes, mientras que en la visión tradicional, generalmente, tal como decía el maestro Kenwa Mabuni, fundador del estilo Shito Ryu o tal como se practica en Okinawa; el kata se considera como una serie de movimientos seguidos hechos contra un mismo atacante que no se rinde o que no es fácil de reducir, que da pelea, que se resiste de forma hábil, que está vivo. Dado el carácter amplio del estudio de las katas y su bunkai, la posibilidad de varios atacantes también puede ser tenida en cuenta, pero originalmente no era el sentido principal de los kata. El Bunkai no deportivo se estudia (no son modelos coreograficos, sino un rompecabezas cinético) principalmente por parejas: por turnos uno hace de atacante y el otro aplica las técnicas del kata como defensa, primero poco a poco y progresivamente más rápido y fuerte; y con variantes progresivas en los contraataques y ángulos de ejecución. El estudio del bunkai no se limita a una o dos aplicaciones sino que se investigan las distintas posibilidades de cada movimiento, posición, y desplazamiento con el fin de aprender los principios que hacen del karate un arte de autodefensa eficaz y versátil. Algunos kata ofrecen movimientos simplificados pero su aplicación es diferente a lo que se aparenta. Otros ofrecen múltiples aplicaciones interpretando los movimientos a partir de los movimientos de los gestos básicos o Kihon. Gran parte de estas aplicaciones queda a la interpretación, comparación, exploración e investigación del karateka experimentado, con base en: la anatomía, la biomecánica, la fisiología y la psicología. Contemplando las diferentes técnicas de golpeo, luxación, lanzamiento, derribo, sujeción, uso de los puntos vulnerables, y el conocimiento y representación de las fases de escalación del conflicto. Así el practicante puede darse cuenta que la defensa personal se trata de proteger a sus seres queridos, y sobre todo de evitar el conflicto o de sobrevivir a este, por encima del propio ego.

El Hojo Undo se refiere a una serie de instrumentos y prácticas corporales (ej: kote- kitae) destinadas a preparar al cuerpo para el combate. Los instrumentos son generalmente objetos pesados con los que se realizan diversos ejercicios. Su uso se distingue del uso de pesas en otras disciplinas (por ejemplo el fitness) en que están diseñados para desarrollar la fuerza y el control de los movimientos de karate de una forma específica. También incluye prácticas y objetos de acondicionamiento de las partes del cuerpo destinadas a ser utilizadas como defensa o ataque (nudillos, antebrazos, pies, tibias, dedos, codos, etc.), mediante golpeo repetitivo para desarrollar dureza y/o insensibilidad por impacto tanto en huesos y tendones como en la piel, al mismo tiempo que se mejora la estructura corporal mediante una práctica progresiva (por lo descrito en las leyes de Wolff y Depeche sobre regeneración adaptativa de los tejidos sometidos a presión, antes de la etapa adulta). Aunque suele decirse que es con el fin de insensibilizar esas zonas y desarrollar callos, solo algunas escuelas aun lo hacen con ese fin. 

Algunos de los instrumentos utilizados en la práctica del Hojo Undo son: la tabla de golpeo, o Makiwara, Chishi o candado de piedra , Nigiri game o jarrón/es de boca ancha, Kakete iki, Kongoken o anillo de hierro, Ishisashi, Tan-Tou o vara de hierro, Jari-bako, Tetsu-geta o sandalias de plomo, Sashi-ishi, Makiage-kigu, Tetsuarei, Temochi-shiki makiwara, makiwara cilíndrico, entre otros.

Actualmente los objetos de Hojo Undo tradicional se complementan con elementos modernos para el acondicionamiento físico, como: los sacos de boxeo, los escudos de golpeo, las mancuernas, los discos, las barras, las máquinas de polea o resorte, etc.

Con 50 millones de practicantes en el mundo, el karate es el segundo arte marcial y deporte de combate más practicado en el mundo, después del Taekwondo con 60 millones, y mucho más que el Yudo que tiene 16 millones. Al contrario que estas, el karate no es una disciplina olímpica aun; sino un deporte de exhibición que tiene la opción de ser disciplina olímpica a partir de Tokio 2020, pese a que el Taekwondo en sus dos modalidades (WTF e ITF) es de por sí una variación de los estilos de Karate (shudokan y shotokan respectivamente, junto a las técnicas de pateo derivadas del arte coreano del taekyon). Esto teniendo en cuenta que se realizan numerosas competiciones de karate a nivel local, regional, nacional, continental, internacional y mundial. Incluso el karate está incluido en numerosos eventos como: los juegos mundiales, los juegos de Asia, los juegos Mediterráneos y los juegos Panamericanos. Y la Federación Mundial de Karate (WKF por sus siglas en inglés) está reconocida por el Comité Olímpico Internacional (COI). 

El "karate coreano" o Taekwondo se convirtió en disciplina olímpica desde los juegos del año 2000 en Sídney, Australia, por el impulso del entonces presidente del Comité Olímpico Internacional (COI), Juan Antonio Samaranch. En 2005, durante la sesión 117.ª del COI en Singapur, en la que se decidió que el baseball y el softball no seguirían en el programa olímpico de los juegos a partir de 2012, dejando así dos lugares disponibles para la inclusión de nuevas disciplinas. Cinco deportes fueron examinados por las comisión del programa olímpico: el patinaje, el squash, el golf, el karate y el rugby siete. Dos fueron tenidos en cuenta para el programa de los juegos de Londres 2012: el squash y el karate, que tenían el 60% de los votos necesarios a su favor, pero se requería una mayoría de ⅔ partes para ser elegidos. Tras una nueva sesión hecha en octubre de 2009 en Copenhague, se determinó qué ciudad llevaría a cabo los juegos de Río en 2016, y cuáles serían los deportes incluidos. El karate se presentó por novena vez entre cinco deportes no olímpicos a elegir y no alcanzó la mayoría de votos necesaria. Los contactos entre las federaciones de los deportes paralímpicos y el comité paralímpico internacional buscan que el handikarate o parakarate (que se realiza en silla de ruedas), sea un deporte de demostración en los juegos de Londres de 2012.

En el 2009, En la votación hecha durante el comité Internacional olímpico número 121; el kárate no recibió la mayoría de los votos (2/3 partes de los votos) para convertirse en deporte olímpico. A pesar de que se le estaba considerando para los olímpicos de 2020, pero tras la reunión del comité ejecutivo del C.O.I. que se realizó en Rusia el 29 de mayo de 2013, se decidió que el kárate junto con el wushu y otras disciplinas no relacionadas con las artes marciales, no sería tenido en cuenta para ser incluido en los juegos de 2020. Asimismo esta decisión fue ratificada en la sesión número 125 del COI llevada a cabo en Buenos Aires, Argentina, en septiembre de 2013.

Los maestros del arte marcial tradicional tanto en Okinawa como en el Japón temen que, una vez que el karate sea ratificado como deporte olímpico, y debido a la especialización competitiva, se pierda aún más su faceta como método de autodefensa, tal como ocurre actualmente con el Yudo y en el Taekwondo, dejando de lado varias técnicas y tácticas que no se utilizan en la competición, como varias formas de golpeo, desarmes, luxaciones y lanzamientos, además de los métodos de golpeo a puntos vulnerables y vitales, perdiendo efectividad ante el surgimiento de nuevos deportes de contacto como las artes marciales mixtas (Mma / Amm ).

El 3 de agosto de 2016, el Comité Olímpico Internacional (COI) aprobó incluir cinco nuevos deportes para los Juegos Olímpicos de Tokio 2020: béisbol/sóftbol, surf, escalada deportiva, karate y skateboarding.

Se disputarán una prueba femenina y otra masculina de kata (series de movimientos) y tres pesos por sexo en kumite (combate).

Tras los juegos olímpicos de Tokio el karate deja de ser deporte olímpico y es sustituido en favor de otras disciplinas que generan polémica como el break dance. Esto hace que el mundo del karate se movilice por lograr de nuevo su estatus olímpico.

Como en otras artes marciales modernas, o (Gendai Budo) en el karate se establece una diferencia entre la práctica meramente técnica y la de crecimiento interior del practicante, utilizando para ello la palabra "Dō" (camino, búsqueda espiritual) que en las tradiciones chinas y japonesas se utiliza para señalar a aquellas actividades que se practican con esa intención de crecimiento personal, en contraste con una práctica meramente técnica (jutsu).

El maestro Gichin Funakoshi, fundador del estilo Shotokan plasmó en su obra autobiográfica: "Karate-Dō: Mi camino" la filosofía de lo que para él era realmente el Karate. Lo entendió como "el purgar de uno mismo los pensamientos egoístas y malos. Porque solo con la mente despejada y consciente puede uno entenderse, así como el conocimiento que recibe". También afirmó: "Karate ni senté nashi", que significa que en el karate no existe un primer ataque, entendiéndose que un practicante de Karate nunca debe albergar, mostrar una actitud arrogante y violenta, sino que al Karate-Dō se le debe considerar como un medio para la evolución personal continua a través de un tipo específico de acondicionamiento físico y la adquisición de habilidades.

Funakoshi, quien era un asiduo practicante de la filosofía del Confucionismo, creía que uno debe ser "interior y exteriormente, humilde". Solo al comportarse con humildad se puede estar abierto a muchas opiniones respecto al karate. Esto permite escuchar y ser receptivo ante la crítica. A su juicio, la cortesía era de primordial importancia. Dijo que los practicantes de karate "nunca ser fácilmente arrastrados a una lucha". Se entiende que un golpe de un verdadero experto podría significar la muerte. Está claro que los que abusan de lo que han aprendido se deshonran a sí mismos. Asimismo, el maestro Funakoshi promovió la convicción personal y el pensamiento de que en "tiempos de graves crisis pública, hay que tener el coraje para hacer frente a … un millón de rivales". Enseñando además que la indecisión es una debilidad.

Existe una historia escrita por Funakoshi, que refleja el sentido del karate. Es una parábola acerca del Dō (camino) y un hombre insignificante:

"Un karateka pregunta a su Sensei (o maestro que ha recorrido el camino): ¿Cuál es la diferencia entre un hombre del Dō y un hombre insignificante?"

"El Sensei respondió: "Cuando el hombre insignificante recibe el cinturón negro primer Dan, corre rápidamente a su casa gritando a todos el hecho. Después de recibir su segundo Dan, escala el techo de su casa, y lo grita a todos. Al obtener el tercer Dan, recorrerá la ciudad contándoselo a cuantas personas encuentre.""

"El Sensei continuó: "Un hombre del "Do" que recibe su primer Dan, inclinará su cabeza en señal de gratitud; después de recibir su segundo Dan, inclinará su cabeza y sus hombros; y al llegar al tercer Dan, se inclinará hasta la cintura, y en la calle, caminará junto a la pared, para pasar desapercibido. Cuanto más grande sea la experiencia, habilidad y potencia, mayor será también su prudencia y humildad"."

La práctica del Karate-Dō no se refiere tan solo al desarrollo técnico y táctico, al acondicionamiento físico, al estudio de los katas y al combate real o deportivo. También debe ir de la mano del desarrollo vivencial de la parte humana y la parte espiritual, el crecimiento como personas y ciudadanos ejemplares que unidos por el bien común beneficien a la sociedad. Para lograr esto, el Karate-Do posee principios y objetivos comunes para el crecimiento de sus alumnos: respeto, justicia, armonía y esfuerzo son los primordiales.

En el caso del Karate-Dō, la ética deriva de las filosofías del confucianismo y del budismo zen, aplicados al "Karate-Dō". Estos principios fundamentales están basados en el código de los guerreros medievales japoneses o samurái, llamado bushidō. En resumen, estos se podrían sintetizar como los siguientes:


Los valores éticos del Karate se recuerdan en cada Dojo, mediante el Dojo Kun o código de normas de conducta el cual es recitado en cada clase, a manera de recordatorio de la filosofía buscando aplicar los principios filosóficos del karate-Do a la vida diaria, para beneficio del individuo, y la sociedad.

Hoy en día ya son muchos los estilos de Karate-Do tanto de origen okinawense como japonés reconocidos por la Federación Mundial de Kárate o World Karate Federation (WKF), siendo los más difundidos los siguientes: Shorin-Ryu, Goju-Ryu, Uechi-Ryu, Isshin-Ryu, Shorinji-Ryu, Ryuei-Ryu, Shito-ryu, Shotokan, Kushin Ryu, Wado-ryu, y Kyokushinkai. Algunos de estos se describen a continuación: 

Registrado oficialmente en 1908 por el maestro Chosin Chibana. Es un sistema de karate derivado del Shuri-te o estilo del palacio de Okinawa. Tiene sus bases en las técnicas y tácticas para las distancias media y larga heredadas de los pioneros del arte como: Kanga Sakukawa (To-de Sakukawa) y Sokon Matsumura, modificadas por su discípulo Yasutsune Itosu o Anko Itosu. El estilo fue posteriormente nombrado Shorin Ryu por uno de sus alumnos, el maestro Chosin Chibana. Este estilo de karate con el tiempo derivaría en variantes como Matsumura seito, Kobayashi, Shobayashi y Matsubayashi Shorin-ryu (combinación de karate Shorin-ryu con el Tomari-te del maestro Chotoku Kyan, uno de los tres estilos de To-de de Okinawa) y sería la base técnica de las variantes de karate japonés, provenientes de la región de Honshu en el Japón como: el Shotokan, el Shito-ryu y el Wado-ryu. El karate Shorin-Ryu propuesto por Chosin Chibana sería conocido más tarde como Kobayashi Shorin-ryu, siendo una de sus principales características la enseñanza de dos de los estilos más importantes de Kobudo (arte de manejo de armas ancestrales de okinawa): el kobudo estilo Ryukyu y el Kobudo estilo Matayoshi-ryu fundado por Shinpo Matayoshi. También cabe mencionar que este estilo Shorin-ryu o Kobayashi Shorin-ryu es el único estilo de karate que preserva y enseña el programa completo de kobudo. Actualmente, hay varios maestros de otros estilos de kárate, que aprendieron kobudo con maestros de Shorin-ryu. Sin embargo, en el ámbito del kárate japonés, al kobudo se le considera como un arte marcial aparte del karate. Como estilo, el Shorin Ryu hace fundamental hincapié en el combate en las distancias media y larga, así como en la rapidez, la movilidad, la creación de potencia de golpeo (generada momentáneamente por el movimiento de anteversión de la pelvis, la transferencia del peso corporal, y la contracción temporal fija de los músculos del torso y el abdomen además de la rotación de la cadera), los desplazamientos naturales, los bloqueos o chequeos en ángulo, la penetración en los golpes y la eliminación de cualquier movimiento que no posea un objetivo específico. 

Desarrollado a partir del Naha-te o estilo de la ciudad puerto de Naha. Su popularidad se debió principalmente al maestro Kanryo Higaonna (1853-1915), quien abrió un dojo en la ciudad de Naha, basándose en ocho formas traídas de China. Su mejor alumno, Chojun Miyagi (1888-1953), más tarde fundó formalmente el Gōjū Ryū, o "estilo suave y duro" en 1930. En el karate Goju-ryu se pone mucho énfasis en el combate a media y corta distancia combinando técnicas de bloqueo circular suave con contraataques fuertes y rápidos ejecutados en una rápida sucesión, así como agarres y técnicas de inmovilización. Actualmente, el Goju-ryu tiene variantes tanto de la región de Honshu (islas principales del Japón) así como en Okinawa. De las variantes de la región de Honshu están la Goju-kai, la Seigokan Goju-ryu fundada por Seigo Tada, Nihon Goju-ryu fundado por Gogen Yamaguchi y entre las variantes practicadas en Okinawa están el Gohakukai-ryu que es una combinación de Goju-ryu con el Tomari-te fundado por Iken Tokashiki, y el Yuishinkan Goju-ryu fundado por Tomoharu Kisaki" que es una combinación de Goju-ryu con el Shuri-te y técnicas de Yudo.

Fundado en 1915 por Kanbun Uechi y denominado con su nombre actual en 1939, su origen está compuesto por un antiguo estilo de kung fu (paigonoon, o estilo del tigre y la grulla) que aprendió en China y el Tode proveniente de la ciudad okinawense de Naha o Naha-te. Este estilo de karate es uno de los tres estilos principales de la prefectura de Okinawa junto con el karate Goju-ryu y el karate Shorin-ryu, además de ser el origen de estilos japoneses en la región de Honshu como el Koshukai Uechi-ryu y el Seishin-ryu. El estilo Uechi Ryū hace principal énfasis en movimientos circulares y fuertes, el uso de la distancia y corta, un gran acondicionamiento físico, así como técnicas de agarres, golpes de mano abierta y derribos.


Fundado en 1991 por la organización OKIKUKAI-Okinawa Uechi-Ryu Karate-Do Association, debido a que esta organización se separó de la organización Kokusai Shubukai Uechi-ryu Kyokai por problemas con el tercer soke del estilo Uechi-ryu, Kanmei Uechi (décimo Dan). Los maestros de esta organización juntaron a varios maestros del estilo Uechi-ryu de Okinawa y Japón para hacer crecer más la organización, sin embargo hubo algunos maestros que no aceptaron la invitación entre los que destacan sensei Gushi, sensei Seiko Toyama, sensei Kiyohide Shinjo de Kenyukai, entre otros que decidieron apoyar a la familia del sensei Kanbun Uechi. En el año de 1991, en una reunión en la ciudad de Naha en la prefectura de Okinawa, Japón, los altos maestros de la OKIKUKAI deciden fundar el estilo Shohei-ryu que significa estilo del sol naciente, usando los kanjis de la era showa y el hei, lo anterior debido a que no podían usar el nombre de Uechi-Ryu por problemas de derecho de autor, y que ya no contaban con la autorización del tercer Soke del estilo Kanmei Uechi.
Para diferenciar el estilo Shohei ryu, se crearon nuevas katas para el estilo entre las que destacan las katas Ryuko (en honor al hanshi Ryuko Tomoyose), Kata Giken creada por el Hanshi Yoshitsune Senaga (fundador de la organización Kenseikai Uechi-ryu, afiliada a la OKIKUKAI), Kata Kokahuho creada por el hanshi Tsuneo Shimabukuro (fundador de la organización Uechi-ryu Konan-ryu, afiliada a la OKIKUKAI), kata Shinshu creada por el Hanshi Satoru Shinki (antes de que la OKIKUKAI se separara de la organización Shubukai, esta kata solo se enseñaba a los maestros de alto rango o hanshis, pero en Shohei-ryu se incluyó dentro del programa de grados danes). 
En el año 2010 el Hanshi Shintoku Takara junto con un grupo pequeño de maestros deciden separarse de la OKIKUKAI, por problemas con otros maestros y fundar la Okinawa Uechi-ryu Karate-do Association, aunque aun usando el logo de la OKIKUKAI, por lo que se tenían 2 OKIKUKAIS, una Uechi-ryu y otra Shohei-ryu, un año más tarde las organizaciones afiliadas y que apoyaban la OKIKUKAI entre las que se encuentran Kenseikan de Yoshitsune Senaga y Konan-ryu de Tsuneo Shimabukuro también se separan de las 2 OKIKUKAIS.
En el año 2014 muere el Hanshi Shigeru Takamiyagi de OKIKUKAI Shohei-ryu, perdiendo a uno de sus más grandes exponentes, y en el año 2016 al hacerse el Karate-do deporte olímpico para los juegos de Tokio 2020, deciden apoyar dicha causa, cosa que el resto de maestros del estilo en Okinawa y Japón no vieron de buena manera. En el año 2017, el uso del nombre Uechi-ryu pasa a ser de dominio público, según las leyes japonesas, por lo que la OKIKUKAI abandona el nombre de Shohei-ryu y retoma el nombre de Uechi-ryu conservando las katas nuevas creadas hasta el momento y estando en proceso de crear una nueva kata. Cabe mencionar que el tercer soke Kanmei Uechi murió en 2010, por lo que el cuarto soke Kanji Uechi tomó el mando del estilo Uechi-ryu, y dio nuevamente la autorización a OKIKUKAI de usar el nombre otra vez. En el año 2019 fallecen los maestros Toshio Higa y Ryuko Tomoyose por lo que la OKIKUKAI pierde a otros dos de sus grandes maestros en un año.
En agosto del año 2019, el kyoshi Kazuma Shibahara Cinta Negra octavo Dan de la OKIKUKAI, junto con su amigo el kyoshi Yohei Nakajima séptimo Dan de Ryuei-ryu deciden salir de Japón, el sensei Kazuma rompe vínculos con las dos OKIKUKAIS (la de Shintoku Takara y la comandada por Tsutomu Nakahodo que era la del Shohei-ryu), ambos emigran a Latinoamérica, el sensei Kazuma emigra a la ciudad de Querétaro en México, y el kyoshi Yohei a Guatemala. La razón de esto es que ambos deciden crear un nuevo estilo de Karate-do usando el nombre de Shohei-ryu, por lo que crean la organización Kokusai Seidokan Nihon Shohei-ryu Karate-do Kyokai. El nuevo o resurgido Shohei-ryu conserva las katas del estilo uechi-ryu, las katas que se crearon en Okikukai, y agregan las katas del estilo Ryuei-ryu y dos katas de kyokushin que son Garyu y Yantsu. Con lo anterior el estilo Shohei-ryu pierde su característica de estilo okinawense pasando a ser parte de los estilos japoneses, pero aún más fortalecido que antes.

Fundado en 1928 por Kenwa Mabuni (1889-1952), influenciado directamente tanto por el Naha-te como por el Shuri-te, aunque enfatizando más el Shorin-Ryu que el Goju-Ryu, básicamente es un estilo mixto de karate-do. El nombre Shito se deriva de la combinación de los caracteres japoneses de los nombres de los maestros de Mabuni: Anko Itosu y Kanryo Higaonna. Las escuelas de Shitō-ryū poseen un gran número de katas, tomadas de varios estilos como el Shorin-Ryu, Shorinji-Ryu, Isshin-Ryu y Goju-Ryu. El Shito Ryu se caracteriza por un especial énfasis en la velocidad de ejecución de las técnicas y en la precisión de sus movimientos.

Registrado por Gichin Funakoshi (1868-1957) en Japón en 1938, aunque fue dado a conocer desde 1922. "shoto" era el seudónimo usado en sus poemas por el maestro Funakoshi y "kan" (escuela o dojo), se considera el primer estilo propiamente japonés de karate-Do. Asimismo, al maestro Funakoshi se considera el fundador del karate moderno, ya que fue el primero en dar a conocer el arte en la región de Honshu en el Japón. Funakoshi nació en la ciudad de Shuri en Okinawa. En su infancia comenzó a estudiar karate (conocido en ese entonces como: te, tuidi, o to-te) con el maestro Yasutsune Azato, uno de los mayores expertos de Okinawa en este arte, y posteriormente con el reconocido maestro Anko Itosu. En 1921 Funakoshi introdujo de manera pública por primera vez el Karate en Tokio. En 1936, a los 70 años, abrió su propia sala de entrenamiento. El dojo fue nombrado por sus primeros alumnos, y se llamó Shotokan. El Shotokan actual tiene características muy específicas que no se deben al tipo de karate de Okinawa enseñado inicialmente por el maestro Gichin Funakoshi; sino a las varias innovaciones incluidas por sus alumnos incluyendo a su hijo Yoshitaka, y a su alumno el maestro Masatoshi Nakayama. Innovaciones hacia el aspecto deportivo, las cuales aunque Gichin Funakoshi no siempre las compartió; las permitió en pos de hacer del karate más que un método de defensa personal, buscando un medio de formación del individuo. Este estilo se caracteriza por el uso asiduo de las posiciones bajas, amplias y fuertes y el trabajo de rotación de la cadera, los bloqueos en ángulo, la preferencia por la distancia larga, la rotación de la cadera tanto en el ataque como en la defensa, y el uso de la sinergia muscular para generar la potencia, tanto en las técnicas de ataque con puño y mano abierta, como en las técnicas de defensa; asimismo posee: algunos lanzamientos y varios barridos similares al Yudo, basados en varias técnicas de lucha provenientes de la lucha típica de Okinawa, o "Tegumi". Al igual que varios conceptos y métodos de entrenamiento tradicional derivados del kendo (esgrima japonesa), debido a que estas artes marciales fueron practicadas por varios de sus maestros iniciadores, y pioneros en su difusión en occidente.

Fundado en 1939 por Hironori Otsuka, es un sistema de karate desarrollado a partir del kobayashi Shorin Ryu, enseñado por Gichin Funakoshi antes de desarrollar el estilo Shotokan, junto con varios elementos tácticos (desplazamientos) y técnicos (luxaciones, lanzamientos y estrangulaciones) derivados del jiu-jitsu japonés (concretamente del estilo Shindō Yōshin-ryū, 新道楊心流), estilo del cual que el maestro Otsuka era ya considerado un gran maestro. El Wadō-ryū pone un fuerte énfasis en la suavidad, la absorción, sin olvidar la aplicación precisa de la fuerza. También incluye la disciplina espiritual, llevando al practicante a armonizarse con su entorno, siendo esto lo que significa "Wado Ryu": "camino de la armonía".

Fundado por Hanshi Kosuke Heianna Zukeran 10mo Dan, su estilo combina Técnicas y Katas de Uechi-Ryu, Ryuei-Ryu y Nihon Goju-ryu. Sensei Heianna fue alumno de Kanei Uechi con el que aprendió Uechi-Ryu, fue alumno después de Kenko Nakaima y compañero de Tsuguo Sakumoto con los que aprendió Ryuei-Ryu y más tarde entreno Nihon Yuishinkan Goju-Ryu con Tomoharu Kisaki. En 1979 oficialmente funda su propio estilo conocido como SeitoKaiKan o Seitokaikan-ryu, y abre su hombu dojo en la ciudad de México. Al año siguiente crea la organización Heianna Group que rige su estilo en México y Chile. Las Katas del estilo Seito-Kai-Kan son Sanchin, Suparimpei, Seienchin, Seisan, Saifa, Niseishi, Anan, Heiku, Paiku, Paiho, Pachu, Ohan, Kanshiwa, Kanshu, Kanchin, Seichi, Seiryu, Heianna Kata Ichi, Heianna Kata Ni, Kata Hiho, Kata Hiho Ni y Panchudo. Seito-Kai-Kan es un estilo de Karate-Do que combina Uechi-Ryu, Ryuei-Ryu y Nihon Goju-Ryu. 

Además de estos estilos base, existen infinidad de variantes y combinaciones de ellos. Algunos son originarios de Okinawa, como el "Isshin-ryū" del maestro Tatsuo Shimabuku. Otros surgieron de la fusión de otros estilos o por divisiones internas de los anteriores, incluyendo elementos de otras artes marciales, como el "Ken-Shin-Kan" fundado por Seiichi Akamine, el "Shindo Jinen Ryu" fundado por Yasuhiro Konishi, el "Kyokushin" o "Kyokushinkai" fundado por Masutatsu Ōyama, el "Gensei Ryu" del "Renbu Kai" de Geka Yung, el "Shōtōkai" de Shigeru Egami, el Kushin Ryu, "Shokundo-Ryu" de Taito Kumagawa,"Shudokan" del maestro Kanken Toyama, entre otros.

El Taekwondo o "kárate coreano" es un deporte olímpico de combate que se basa fundamentalmente en artes marciales mucho más antiguas como el taekkyon coreano en la forma y realización de los golpes con el pie y desplazamientos; y en los estilos Shūdōkan (en el taekwondo WTF / hoy día WT) y shotokan (en el taekwondo ITF) del karate-Do japonés de donde obtiene los golpes con el puño, varios golpes a mano abierta, la planimetría (o división del cuerpo por zonas alta/media/baja), los bloqueos, las posiciones, el sistema de grados por cinturones, su primer uniforme, y sus primeras formas. Las formas de Taekwondo conocen como "Poomsae"/pumse en la WT (World Taekwondo) y "Hyong" en la ITF (International Taekwon-Do Federation), con el fin de promover aún más su propia identidad. 

Asimismo el Tangsudo, o tang soo do, otro estilo similar al taekwondo, pero que busca ser más tradicional, al no ser muy competitivo, fue muy influenciado por el Kárate-Do japonés, su fundador el coreano kuk Wan Lee, adoptó la gran mayoría de los katas del estilo de kárate Shotokan (exceptuando las posiciones bajas), preservando incluso el manejo del bastón largo japonés o bō dentro de su estilo. y renombrándo las técnicas, posiciones y comandos en idioma coreano. A estas técnicas adicionó las técnicas patadas del arte marcial clásico coreano del Taekkyon. Posteriormente en los años 50, varias corrientes del Hapkido coreano adoptaron varias de las técnicas del Tangsudo de bloqueo, golpes a mano abierta y de puño, como complemento a las técnicas de luxación y lanzamiento, que también fueron previamente adaptadas de las disciplinas japonesas del yudo y del Daito Ryu aiki jiu-jitsu , (siendo este el antecesor directo del Aikido). 

El "full contact" o karate a "contacto pleno" es un deporte de combate que nació en los Estados Unidos en los años 60 como respuesta a las expectativas de eficacia de muchos de los practicantes occidentales de artes marciales tradicionales en EE. UU. , como el Karate-Do, el Taekwondo, y el kung-fu/wu shu, quienes, contando con una muy buena preparación física, observaron que los campeonatos tradicionales "al punto" no eran los suficientemente cercanos y justos a la realidad del combate. Sus técnicas incluyen el uso de todos los golpes del boxeo, las técnicas de patadas altas y los barridos, exceptuando las técnicas de patadas a los muslos tipo "low kick", buscando la puesta fuera de combate del adversario o "knock out" (K.O.). El primer Campeonato Profesional fue llevado a cabo por la "United States Karate Association" en 1964. Entre la lista de Campeones Mundiales de Karate Profesional se encuentran Joe Lewis, Chuck Norris y Bill Wallace. El full contact es actualmente una de las modalidades de competición del kick boxing y se le considera uno de los antecesores históricos de las modernas Artes Marciales Mixtas (AMM / MMA).

El Daido-Juku Kudo (大道塾空道 Daidō Juku Kūdō?) es también conocido simplemente como Kudo (空道 Kūdō?) es un arte marcial moderno de origen japonés, fundado en 1981 por Takashi Azuma, quien fuera campeón de karate kyokushin. Esta disciplina es principalmente una combinación de kárate y yudo, aunque incluye elementos del boxeo y del kickboxing. Los competidores de Daido-Juku visten un "kudogi" oficial, basado en el tradicional judogi. Este diseño es ideal para las técnicas de proyección y agarre. En competición, los kudokas han de utilizar protecciones genitales y bucales, junto con coderas, guantes de artes marciales mixtas y casco ("SuperSafe") homologados.

La práctica del karate, como de cualquier arte marcial, enseñado de forma progresiva, y debidamente planificado, y valorado conlleva en los niños un sinfín de beneficios. Tanto para niños como para adultos, los principales beneficios del entrenamiento en karate incluyen tanto la salud del cuerpo, como la de la mente junto a la obtención de una actitud consciente, reflexiva y respetuosa.

5 es muy importante para la concentración y la canalización de las fuerzas
De forma resumida, los beneficios del entrenamiento en las artes marciales Budo en los niños, son:


Los niños y las niñas a los que les guste este arte marcial deben comenzar a practicarlo en la edad más temprana posible, o especialmente en la adolescencia, lo que les ayudará a concentrarse mejor a la hora de estudiar, mejorando la toma de decisiones, y a tener una buena disciplina en el colegio, respetando a sus compañeros, y superiores.

Al adulto, la práctica ha de proporcionarle una mejor calidad de vida, preparándole para la vejez, y un espacio donde reflexionar y desarrollar aún más, su inteligencia emocional.



</doc>
<doc id="1611" url="https://es.wikipedia.org/wiki?curid=1611" title="Konqueror">
Konqueror

Konqueror es un navegador web, administrador de archivos y visor de archivos. Forma parte oficial del proyecto KDE. Es software libre y de código abierto, y al igual que el resto de los componentes de KDE, está liberado bajo la licencia GPL.

El nombre "Konqueror" es un juego de palabras con el nombre de otros navegadores: primero vino el Navigator (navegador), después el Explorer (explorador), y finalmente el Konqueror (conquistador). Además, sigue la convención de KDE de que los nombres de los programas contengan la letra K.

La interfaz de usuario de Konqueror es en parte reminiscente de la del Microsoft Internet Explorer (a su vez diseñada a partir de la del Netscape Navigator y la del NSCA Mosaic), aunque es mucho más personalizable. Trabaja extensamente con "paneles", los cuales pueden ser recolocados o añadidos. Por ejemplo, se puede tener un panel de marcadores en el lado izquierdo de la ventana del navegador, y pulsando un marcador, la respectiva página web se abre en el panel principal de la derecha. Alternativamente, se puede mostrar una lista jerárquica de las carpetas en un panel y el contenido de la carpeta seleccionada en otro. Los paneles son muy flexibles y pueden incluir hasta ventanas de consola. La configuración de los paneles puede salvarse, habiendo algunas ya incluidas por defecto. Por ejemplo, la configuración "Midnight Commander" muestra la ventana dividida en dos paneles verticales, cada uno de los cuales muestra una carpeta, una página web o la previsualización de un fichero.

Las funciones de navegación ("atrás", "adelante", "historial", etc.) están disponibles durante todas las operaciones. La mayoría de los atajos de teclado pueden ser reasignados usando la configuración gráfica. La barra de direcciones tiene soporte extenso de autocompletado para los directorios locales, las direcciones y términos anteriores.

La aplicación usa una interfaz de único documento. El modo de ventanas múltiples no está soportado (aunque es posible abrir una ventana separada, similar a Navigator). La versión 3.1 y posteriores soportan múltiples pestañas en una ventana.

Konqueror obtiene un puntaje de 89/100 en el Test Acid3.

Konqueror soporta también la navegación por directorios locales, ya sea mediante la introducción de la ruta en la barra de direcciones o mediante la selección de iconos en los paneles.

Konqueror permite:

Utilizando la tecnología de KParts, Konqueror puede ejecutar en su interior componentes capaces de visualizar (y en ocasiones editar) tipos de archivo específicos. Esto permite, por ejemplo, ver un documento de KOffice dentro de Konqueror, evitando la necesidad de abrir otra aplicación.

Además de navegar por directorios y sitios web, Konqueror utiliza los plug-ins KIO ("KDE Input-Output", o sistema de entrada-salida de KDE) para extender sus capacidades. KIO permite acceder a diferentes protocolos como HTTP o FTP. Konqueror también puede utilizar plug-ins KIO para acceder a archivos ZIP, comparticiones Samba (Windows) o cualquier otro protocolo imaginable como enlaces ed2k ("ed2k://"), Audio CD ("audiocd"), ripeando su contenido simplemente arrastrando y soltando. El IOSlave FISH ("fish://usuario@host") permite manejar ficheros en shells remotas seguras, y los IOSlaves "man:" e "info:"permiten acceder a las páginas man e info respectivamente. Para ver la lista completa de IOSlaves disponibles, abre el centro de información de KDE y mira en la sección "protocolos".




</doc>
<doc id="1612" url="https://es.wikipedia.org/wiki?curid=1612" title="Klarobelia">
Klarobelia

Klarobelia es un género de plantas de la familia Annonaceae. Es originaria de América central y meridional.
El género fue descrito por Laurentius Willem Chatrou y publicado en "Changing Genera. Systematic studies in Neotropical and West African Annonaceae" 121. 1998. La especie tipo es: 



</doc>
<doc id="1613" url="https://es.wikipedia.org/wiki?curid=1613" title="Kofi Annan">
Kofi Annan

Kofi Atta Annan (Kumasi, 8 de abril de 1938 - Berna, 18 de agosto de 2018) fue un economista ghanés, secretario general de las Naciones Unidas entre enero de 1997 y diciembre de 2006. Fue galardonado, junto a la ONU, con el de 2001.

Nació el 8 de abril de 1938 en Kumasi, en la entonces Costa de Oro británica, que actualmente es Ghana. Su nombre indica el día de la semana que nació, así en twi y fante (las lenguas de sus padres) "Kofi" quiere decir nacido en viernes; "Atta" expresa que es uno de dos gemelos y "Annan" significa que es el cuarto hijo.

Gracias a la situación privilegiada de su familia, pudo estudiar Economía en el Kumasi College of Science and Technology y amplió sus estudios en los Estados Unidos y Suiza, consiguiendo diversos posgrados y másteres en Economía.

En 1962 entró a trabajar en la Organización Mundial de la Salud, agencia dependiente de la ONU. Pero entre 1974 y 1976, trabajó como director de Turismo de su propio país. 

Posteriormente volvió a las Naciones Unidas como asistente del secretario general en tres etapas distintas: como coordinador de Recursos Humanos y Seguridad entre 1987 y 1990, como controlador del Programa de Planificación y Finanzas entre 1990 y 1991 y como coordinador de las Operaciones de las Fuerzas de Paz de la ONU entre marzo de 1993 y febrero de 1994.

Annan fue nombrado subsecretario general en octubre de 1995 y enviado como representante especial del secretario general de la ONU en Yugoslavia, retornando a la sede central de la ONU en Nueva York en abril de 1996.

El 13 de diciembre de 1996, Annan fue escogido por el Consejo de Seguridad de la ONU como secretario general y fue confirmado cuatro días más tarde en la Asamblea General de la ONU, sucediendo al egipcio Butros Butros-Ghali. La elección de Annan, propiciada por los Estados Unidos, rompió así el torno rotativo entre continentes y convirtió a Annan en el primer hombre negro en ocupar la Secretaría General.

Durante su mandato, su prioridad fue la planificación de la reforma de las Naciones Unidas, siendo su primera iniciativa importante la presentación del llamado Plan de reforma para la Renovación de las Naciones Unidas. Asimismo, se pronunció en repetidas ocasiones en favor de luchar activamente contra el sida, convirtiéndose en una gran prioridad de sus gobiernos. El 1 de enero de 2002 le fue renovado su mandato por el Consejo de Seguridad, así como por la Asamblea General hasta el 31 de diciembre de 2006. En 2003 se manifestó en contra de la invasión de Irak por los gobiernos de los Estados Unidos y el Reino Unido, y en 2004 la consideró ilegal.

Junto con la misma ONU recibió el en 2001 "por su trabajo por un mundo mejor organizado y más pacífico".

En 2012 fue galardonado con el Premio Confucio de la Paz por «su enorme contribución a la reforma y resurgimiento de las Naciones Unidas» y como enviado especial de la ONU y de la Liga Árabe en Siria.



</doc>
<doc id="1617" url="https://es.wikipedia.org/wiki?curid=1617" title="Corona triunfal">
Corona triunfal

La corona triunfal, de laurel, láurea o lauréola es una corona formada por hojas de laurel, generalmente entregada como recompensa a poetas (poeta laureado), deportistas y guerreros en la antigua Grecia y Roma. Consistía en un cerco de ramas, siendo en un primer momento de laurel (de allí en latín: "lavrĕa"), pero luego realizándose en oro.

En cuanto al nombre latino de esta corona (lavrĕa o laura), ha generado una familia de palabras en diversos idiomas; por ejemplo, el adjetivo español: laureada/o y el nombre propio Laura. Que exista en la etimología de esta denominación una posible relación filológica con el nombre de la doble hacha cretominóica ("labrix") es aún conjetural.

Los orígenes no están del todo precisados, pero parece indiscutible su relación con una corona vegetal semejante: la de olivos que se otorgaba a los ganadores griegos de los Juegos Olímpicos; muchos consideran que Julio César utilizó la corona de oro imitando dos ramos de laurel para disimular su calvicie. En cualquier caso, durante los homenajes de triunfo a los generales romanos victoriosos, estos eran coronados con láureas (es decir: laureados).

Esta corona se ha mantenido como símbolo de la victoria hasta nuestros días, y destaca su uso heráldico, que siempre simboliza la victoria, aunque en escudos de varios países hispanoamericanos, el símbolo de la láurea adquiere un significado adicional de connotaciones, pues no solo simboliza el triunfo bélico sino también la victoria de la libertad. En cuanto al adjetivo "laureada/o", contemporáneamente significa la persona que ha logrado cumplir y superar las exigencias de educación y cultura, especialmente al concluir los estudios medios (o "secundarios") y, sobre todo, los universitarios. También durante los Juegos Olímpicos de Atenas 2004, las ceremonias de entrega de premios incluyeron la imposición de coronas de laurel.

Dafne y Eros en el arte de lanzar flechas. Eros, molesto por la arrogancia de Apolo, ideó vengarse de él y para ello le arrojó una flecha de oro, que causaba un amor inmediato a quien hiriere. También hirió a la ninfa Dafne con una flecha de plomo, que causaba el rechazo amoroso. Así que, cuando Apolo vio un día a Dafne, se sintió herido de amor y se lanzó en su persecución. Pero Dafne, que sufría el efecto contrario, huyó de él. Y la ninfa corrió y corrió hasta que, agotada, pidió ayuda a su padre, el dios-río Ladon, el cual determinó convertir a Dafne en laurel. Cuando Apolo alcanzó a Dafne, ésta iniciaba la transformación: su cuerpo se cubrió de dura corteza, sus pies fueron raíces que se hincaban en el suelo y su cabello se llenó de hojas. Apolo se abrazó al árbol y se echó a llorar. Y dijo: «"Puesto que no puedes ser mi mujer, serás mi árbol predilecto y tus hojas, siempre verdes, coronarán las cabezas de las gentes en señal de victoria"».

La transformación la relata Ovidio en el poema "Las metamorfosis". Este mito ilustra el origen de uno de los símbolos típicos del dios, la corona de laurel

En algunos países se utiliza la corona de laurel como símbolo del grado de maestría. La corona se le da a los maestros jóvenes en la ceremonia de graduación de la universidad. La palabra "laureado" de "poeta laureado" se refiere a ser representado por la corona de laurel. El poeta y filósofo medieval italiano Dante Alighieri, egresado de la Escuela de Sicilia, a menudo aparece representado en la pintura y escultura llevando una corona de laurel.

En la Universidad de Connecticut en los Estados Unidos, los miembros de la clase de tercer año llevan a una cadena de laurel, que los de último año les entregan durante una Iniciación. Representa la naturaleza y la continuación de la vida desde un año a otro. Inmediatamente después de la iniciación, las chicas de penúltimo año escriben con los laureles su año de clases, lo que significa que han convertido oficialmente en los mayores y que el ciclo se repetirá en la primavera siguiente.

En Reed College, en Portland, Estados Unidos, los miembros de la clase que se gradúa reciben coronas de laurel a la presentación de sus tesis de grado en mayo. La tradición proviene de la utilización de coronas de laurel en las competiciones de atletismo, el último año han "cruzado la línea de meta", por así decirlo. 

En la Escuela de San Marcos en Southborough, Massachusetts, Estados Unidos, los estudiantes que completen con éxito tres años de una lengua clásica y dos de los otros gana la distinción del diploma de los clásicos y el honor de llevar una corona de laurel durante el día del premio.

Los que recibieron un Doctorado Honoris Causa por la Universidad de Umeå en Suecia, a excepción de doctores honoris causa de medicina, recibirán una corona de laurel durante la ceremonia de otorgamiento del grado honorífico.

La "corona de laureles" es un motivo común en arquitectura, mobiliario y en los textiles. La corona suele hacerse en bajorrelieve en piedra, y es un motivo decorativo en Robert Adam, Estilo federal, estilo Regencia, Directorio y Arquitectura de Bellas Artes. En arte decorativo, especialmente en el estilo Imperial, la corona de laureles aparece en textiles, en marquetería, aplicado a mobiliario. La empresa automovilística Alfa Romeo incluye, en su logotipo, la corona de laureles, desde que ganó el Campeonato Mundial inaugural de Automóviles en 1925 con el Alfa Romeo P2, y también se utiliza en la insignia de la ONU.

La corona "del servicio" se encuentra en todos los parches de comisionados en los Boy Scouts de los Estados Unidos. Esto es un símbolo de los servicios prestados a las unidades y la colaboración continua entre los voluntarios y profesionales scout. La Corona de servicio representa el compromiso al programa y al servicio a las unidades.


</doc>
<doc id="1618" url="https://es.wikipedia.org/wiki?curid=1618" title="Literatura">
Literatura

Según la Real Academia Española (RAE), literatura es el «arte de la expresión verbal» (entendiéndose como verbal aquello «que se refiere a la palabra, o se sirve de ella») y, por lo tanto, abarca tanto textos escritos (literatura escrita) como hablados o cantados (literatura oral). En un sentido más restringido y 'neotradicional' (ya que las primeras obras literarias fueron compuestas para ser cantadas y/o recitadas), es la escritura que posee mérito artístico y que privilegia la "literariedad", en oposición al lenguaje ordinario de intención menos estética y más práctica. El término literatura designa también al conjunto de producciones literarias de una lengua, de una nación, de una época o incluso de un género (la literatura griega, la literatura del siglo XVIII, la literatura fantástica, etc.) y al conjunto de obras que versan sobre un arte o una ciencia (literatura médica, jurídica, etc.). Es estudiada por la teoría literaria.

El concepto de literatura ha cambiado con el tiempo por ser parcialmente subjetivo; en su sentido genérico es el conjunto de cualquier producción escrita u oral de una nación, época o género y, en su sentido restrictivo, se considera que debe tener un valor estético o intelectual.

Hasta el siglo XVII, lo que actualmente denominamos «literatura» se designaba como" poesía" o "elocuencia". Durante el Siglo de Oro español, por "poesía" se entendía cualquier invención literaria, perteneciente a cualquier género y no necesariamente en verso, entendiéndose por tal tres tipos fundamentales de "poesía / literatura": la lírica (propia del canto, en verso), la épica (propia de la narración, en verso largo o prosa) y la dramática (en diálogo). A comienzos del siglo XVIII se comenzó a emplear la palabra «literatura» para referirse a un conjunto de actividades que utilizaban la escritura como medio de expresión. A mediados de la misma centuria, Lessing publica "Briefe die neueste Literatur betreffend", donde se utiliza «literatura» para referirse a un conjunto de obras literarias. A finales del siglo XVIII, el significado del término literatura se especializa, restringiéndose a las obras literarias de reconocida calidad estética. Este concepto se puede encontrar en la obra de Marmontel, "Eléments de littérature" (1787), y en la obra de Madame de Staël, "De la literatura considerada en relación con las instituciones sociales."

En Inglaterra, en el siglo XVIII, la palabra «literatura» no se refería solamente a los escritos de carácter creativo e imaginativo, sino abarcaba el conjunto de escritos producidos por las clases instruidas: cabían en ella desde la filosofía a los ensayos, pasando por las cartas y la poesía. Se trataba de una sociedad en la que la novela tenía mala reputación, y se cuestionaba si debía pertenecer a la literatura. Por eso Eagleton sugiere que los criterios para definir el "corpus" literario en la Inglaterra del siglo XVIII eran ideológicos, circunscritos a los valores y a los gustos de una clase instruida. No se admitían las baladas callejeras ni los romances, ni las obras dramáticas. En las últimas décadas del siglo XVIII apareció una nueva demarcación del discurso de la sociedad inglesa. Eagleton nos cuenta que surge la palabra «poesía» como un producto de la creatividad humana en oposición a la ideología utilitaria del inicio de la era industrial. Tal definición la encontramos en la obra "A Defence of poetry" (1821) de Shelley. En la Inglaterra del Romanticismo, el término «literato» era sinónimo de «visionario» o «creativo». Pero no dejaba de tener tintes ideológicos, como en el caso de Blake y Shelley, para quienes se transformó en ideario político, cuya misión era transformar la sociedad mediante los valores que encarnaban en el arte. En cuanto a los escritos en prosa, no tenían la fuerza o el arraigo de la poesía; la sociedad los consideraba como una producción vulgar carente de inspiración.

En busca de la definición de los conceptos «literatura» y «literario», surgió la disciplina de la teoría de la Literatura, que empieza por delimitar su objeto de estudio: la literatura. No hay una definición unívoca del término, ya que dependerá del crítico literario que la defina, como así también de la época y del contexto que la define. Sin embargo, los primeros estudiosos que se preocuparon por el estudio de esta disciplina son los llamados formalistas rusos.

A comienzos del siglo XX, el Formalismo ruso se interesa por el fenómeno literario, e indaga sobre los rasgos que definen y caracterizan dichos textos literarios, es decir, sobre la "literaturidad" de la obra. Roman Jakobson plantea que la literatura, entendida como mensaje literario, tiene particularidades de tal forma que la hacen diferente de otros discursos; ese interés especial por la forma es lo que Jakobson llama «función poética», por la que la atención del emisor recae sobre la forma del mensaje (o, lo que es lo mismo, hay una «voluntad de estilo» o de estilizar el lenguaje por parte del escritor). En efecto, hay determinadas producciones lingüísticas cuya función primordial es proporcionar placer literario, un deleite de naturaleza estética, producido por la belleza, en relación con el pensamiento aristotélico. El lenguaje combinaría en sus elementos más simples dos tipos de elementos: redundancias, recurrencias o repeticiones rítmicas formales y de contenido semántico, esto es, analogías, por un lado, y por el otro, desvíos de la norma, para alejarse del lenguaje común, causar extrañeza, renovar: la llamada anomalía; de ese modo se impresiona la imaginación y la memoria y se llama la atención sobre la forma del mensaje, su peculiar forma expresiva. De ambas tendencias, la rítmica o repetitiva es popularizante, y la segunda, por el contrario de sesgo aristocratizante. 

El "lenguaje literario" sería uno estilizado y con una trascendencia particular, destinado a la perdurabilidad; muy diferente de las expresiones de la lengua de uso común, destinada a su consumo inmediato. La literatura, por otra parte, exige por tradición un respaldo sustentable: "El Ingenioso Hidalgo Don Quijote de La Mancha" no habría podido escribirse si no hubieran existido antes los libros de caballerías.

Wolfgang Kayser, a mediados del siglo XX, planea cambiar el término «Literatura» por el de "Belles Lettres", diferenciándolas del habla y de los textos extraliterarios, en el sentido de que los textos literario–poéticos son un conjunto estructurado de frases portadoras de un conjunto estructurado de significados, en el que los significados se refieren a realidades independientes del que habla, creándose así objetividad y unidad propias.

Raúl H. Castagnino, en su libro "¿Qué es la literatura?", indaga sobre el concepto y cómo se extiende a realidades como la escritura, la historia, la didáctica, la oratoria y la crítica. Según Castagnino, la palabra literatura adquiere a veces el valor de nombre colectivo cuando denomina el conjunto de producciones de una nación, época o corriente; o bien es una teoría o una reflexión sobre la obra literaria; o es la suma de conocimientos adquiridos mediante el estudio de las producciones literarias. Otros conceptos, como el de Verlaine, apuntan a la literatura como algo superfluo y acartonado, necesario para la creación estética pura. Posteriormente, Claude Mauriac propuso el término "aliteratura" en contraposición a «literatura» en el sentido despectivo que le daba Verlaine. Todas estas especificaciones hacen de la literatura una propuesta que depende de la perspectiva desde la que se enfoque. Así, Castagnino concluye que los intentos de delimitar el significado de «literatura», más que una definición, constituyen una suma de adjetivaciones limitadoras y específicas.

Si se considera la literatura de acuerdo con su «extensión y su contenido», la literatura podría ser universal, si abarca la obra de todos los tiempos y lugares; si se limita a las obras literarias de una nación en particular, es Literatura nacional. Las producciones, generalmente escritas, de un autor individual, que, por tener conciencia de autor, de creador de un texto literario, suele firmar su obra, forman parte de la literatura culta, mientras que las producciones anónimas fruto de la colectividad y de transmisión oral, en ocasiones recogidas posteriormente por escrito, conforman el corpus de la literatura popular o tradicional.

Según el «objeto», la literatura será preceptiva si busca normas y principios generales; «histórico-crítica» si el enfoque de su estudio es genealógico; «comparada», si se atiende simultáneamente al examen de obras de diferentes autores, épocas, temáticas o contextos históricos, geográficos y culturales; «comprometida» si adopta posiciones militantes frente a la sociedad o el estado; «pura» si sólo se propone como un objeto estético; «ancilar», si su finalidad no es el placer estético sino que está al servicio de intereses extraliterarios.

Según los «medios expresivos y procedimientos», Castagnino propone que la literatura tiene como formas de expresión el verso y la prosa y sus realizaciones se manifiestan en géneros literarios universales, que se encuentran, más o menos desarrollados, en cualquier cultura; «lírico», «épico» y «dramático». Manifestaciones líricas son aquellas que expresan sentimientos personales; épicas, las que se constituyen en expresión de un sentimiento colectivo manifestado mediante modos narrativos, y dramáticas, las que objetivan los sentimientos y los problemas individuales comunicándose a través de un diálogo directo. A estos géneros literarios clásicos habría que añadir además el didáctico.

El teórico Juan José Saer postula que la literatura es ficción; es decir que todo lo que leemos como literatura no tiene referencia directa en el mundo real.
Lo literario sólo existe en relación con el texto en el cual aparece. Pero la literatura, aunque resulte paradójico, es profundamente verdadera: su autenticidad para por reconocerse como ficción y hablar de lo real desde allí (¿?). Saer afirma además, «que la verdad no es necesariamente lo contrario de la ficción», y que cuando optamos por la práctica de la ficción no lo hacemos con el propósito turbio de tergiversar la verdad. En cuanto a la dependencia jerárquica entre verdad y ficción, según la cual la primera poseería una positividad mayor que la segunda, es desde luego, en el plano que nos interesa, «una mera fantasía moral». 

El fenómeno literario ha estado siempre en constante evolución y transformación, de tal modo que el criterio de pertenencia de una obra a la literatura puede variar a lo largo de la historia, según varía el concepto de «arte literario».

Desde este punto de vista, la literatura es un arte. Una actividad de raíz artística que aprovecha como medio el lenguaje, la palabra que se convierte en viva por medio de escritos. Por lo tanto, es una actividad que no discrimina género, ni motivos, ni temáticas.

Para Barthes la literatura no es un corpus de obras, ni tampoco una categoría intelectual, sino una práctica de escritura. Como escritura o como texto, la literatura se encuentra fuera del poder porque en ella se está produciendo un desplazamiento de la lengua, en la cual surten efecto tres potencias: mathesis, mímesis, semiosis. Como la literatura es una suma de saberes, cada saber tiene un lugar indirecto que hace posible un diálogo con su tiempo. Como en la ciencia, en cuyos intersticios trabaja la literatura, siempre retrasada o adelantada con respecto a ella: «La ciencia es vasta, la vida es sutil, y para corregir esta distancia es que nos interesa la literatura». 

Por otra parte, el saber que moviliza la literatura no es completo ni final. La literatura solo dice que sabe de algo, es la gran argamasa del lenguaje, donde se reproduce la diversidad de sociolectos constituyendo un lenguaje límite o grado cero, logrando de la literatura, del ejercicio de escritura, una reflexión infinita, un actuar de signos.

Estudiar la literariedad y no la literatura, señaló la aparición de la primera tendencia moderna en los estudios literarios: llamado el formalismo ruso. Este grupo de intelectuales, redefinió el objeto de investigación, este no apuntaba a sustituir el enfoque trascendente. En cambio, se estudiaría, no la obra, sino las virtualidades del discurso literario que la han hecho posible. De esta forma, los estudios literarios podrán llegar a ser una ciencia de la literatura como la conocemos hoy en día.

"Sentido e interpretación":Para acceder al discurso literario debemos aprehenderlo en las obras concretas. ¿cómo aislar entonces en campo de análisis? Se definen entonces dos aspectos: el sentido y la interpretación. El sentido es la posibilidad de entrar en correlación con otros elementos de esa misma obra y en su totalidad. Por otra parte, la interpretación es diferente, según la personalidad del crítico y su posición ideológica, también varía de acuerdo a la época y contexto de producción de la obra, en otras palabras, el elemento es incluido en un sistema, que no es el de la obra, sino del crítico-lector.

En la estela de Barthes y Todorov, Garrido Gallardo actualiza la definición del término: "Arte de la palabra por oposición a las otras artes" (la pintura, la música, etc.). Actualmente, es su sentido fuerte, que nació a finales del Siglo XVIII y se consagra en la obra de Mme. De Staël, "De la Littérature" (1800). 2. "Arte de la palabra por oposición a los usos funcionales del lenguaje". Corresponde al deslinde entre los escritos de creación (“poesía” en el sentido etimológico) y los otros escritos que reclaman un estatuto aparte como científicos. En sentido estricto, de obra de creación con el lenguaje, el término "literatura" es la palabra de los siglos XIX y XX para significar dicha realidad. Antes se llamaba "poesía". Su continuación en el mundo "cíber" del siglo XXI se llama "ciberliteratura" y ya no es "literatura": tiene unas condiciones comunicativas distintas. En todo caso, hoy por hoy, la literatura sigue siendo un fenómeno cultural muy importante, pues mantiene en estado de vigilia los materiales de la “poesía” y sobrevive y continúa, codo con codo con la “ciberliteratura”, en estado de buena salud.





</doc>
<doc id="1619" url="https://es.wikipedia.org/wiki?curid=1619" title="Linus Torvalds">
Linus Torvalds

Linus Benedict Torvalds (Helsinki, Finlandia, ) es un ingeniero de "software" finlandés-estadounidense, conocido por iniciar y mantener el desarrollo del "kernel" (en español, núcleo) Linux, basándose en el sistema operativo libre Minix creado por Andrew S. Tanenbaum y en algunas herramientas, varias utilidades y los compiladores desarrollados por el proyecto GNU. Actualmente es responsable de la coordinación del proyecto.

Torvalds pertenece a la comunidad sueco-parlante de Finlandia. Sus padres tomaron su nombre de Linus Pauling (estadounidense, Premio Nobel de Química 1954). Comenzó sus andanzas informáticas a los 11 años cuando su abuelo, un matemático y estadístico de la Universidad, compró uno de los primeros microordenadores Commodore en 1980 y le pidió ayuda para usarlo; de esta manera su primera línea de código fue hecha en lenguaje BASIC.

A finales de los años 1980 tomó contacto con los ordenadores IBM, PC y en 1991 adquirió un ordenador con procesador modelo 80386 de Intel.

En 1988 fue admitido en la Universidad de Helsinki, donde estudió ciencias de la computación. Ese mismo año el profesor Andrew S. Tanenbaum sacó a la luz el S.O. Minix con propósitos didácticos. En 1990 empezó a aprender el lenguaje de programación C en su universidad.

A la edad de 21 años, con un año de experiencia programando (en C), ya conocía lo suficiente del sistema operativo Minix como para tomar prestadas algunas ideas y empezar un proyecto personal. Basándose en "Design of the Unix Operating System", publicado por Maurice J. Bach en 1986, creó una implementación que ejecuta cualquier tipo de programa, pero sobre una arquitectura de "ordenadores compatibles", IBM/PC.

Este proyecto personal desembocó el 5 de octubre de 1991 con el anuncio de la primera versión de Linux capaz de ejecutar BASH ("Bourne Again Shell") y el compilador conocido como GCC ("GNU Compiler Collection").

En enero de 1992 se adoptó la Licencia Pública General (GPL) para Linux. Esta añade libertades de uso a Linux totalmente opuestas a las del software propietario, permitiendo su modificación, redistribución, copia y uso ilimitado. Este modelo de licencia facilita lo que es conocido como el modelo de desarrollo de bazar, que ha dado estabilidad y funcionalidad sin precedentes a este sistema operativo.

En 1997 recibió los premios 1997 "Nokia Foundation Award" de Nokia y "Lifetime Achievement Award at Uniforum Pictures". Ese mismo año finalizó los estudios superiores (1988-1997) tras una década como estudiante e investigador en la Universidad de Helsinki, coordinando el desarrollo del núcleo del sistema operativo desde 1992.

Trabajó en Transmeta desde febrero de 1997 hasta junio de 2003. Actualmente trabaja para el Open Source Development Labs en Beaverton, Oregón. Solo el 2% del código del Linux actual está escrito por él, pero, además de su paternidad, en su persona sigue descansando la dirección de la gestión núcleo del sistema operativo.

En 2005 creó Git, un software de control de versiones, pensando en la eficiencia y la confiabilidad del mantenimiento de versiones de aplicaciones cuando estas tienen un gran número de archivos de código fuente.

Posee la marca registrada "Linux" y supervisa el uso de la marca a través de la organización sin ánimo de lucro Linux International.

En Finlandia, Linus Torvalds, por entonces estudiante de Ciencias de la Computación de la Universidad de Helsinki, decidió realizar la entonces cuantiosa inversión de 3500 dólares estadounidenses para adquirir un nuevo ordenador con el microprocesador 80386 de Intel, el cual funcionaba a 33MHz y tenía 4MB de memoria RAM. El pago lo realizaría a plazos, pues no disponía de tal cantidad de dinero en efectivo.

Normalmente, este ordenador lo usaba para tener acceso por línea telefónica a la red informática de su Universidad, pero debido a que no le gustaba el sistema operativo con el cual trabajaba, denominado Minix, decidió crear uno él mismo. Inicialmente, escribió un programa con lenguaje de bajo nivel prescindiendo de Minix. En los primeros intentos, consiguió arrancar el ordenador y ejecutar dos procesos que mostraban la cadena de caracteres “AAAAABBBBB”. Uno lo utilizaría para leer desde el módem y escribir en la pantalla, mientras que el otro escribiría al módem y leería desde el teclado. Inicialmente, el programa arrancaba desde un disquete.

La siguiente necesidad que tuvo fue la de poder descargar y subir archivos de su universidad, pero para implementar esta funcionalidad en el "software" emulador era necesario crear un controlador de disco. Así que después de un trabajo continuo y duro, creó un controlador compatible con el sistema de archivos de Minix. En ese momento, se percató de que estaba creando algo más que un simple emulador de terminal, así que, emprendió la tarea de crear un sistema operativo partiendo de cero.

De forma privada, Linus nombraba Linux a su nuevo sistema, pero cuando decidió hacer una presentación pública pensó que era demasiado egocéntrico llamarlo así y propuso llamarlo Freax, aunque después se le siguió conociendo como Linux, práctica que perdura hasta ahora.

Después de anunciar el 25 de agosto de 1991 su intención de seguir desarrollando su sistema para construir un reemplazo de Minix, el 17 de septiembre sube al servidor de FTP proporcionado por su universidad la versión 0.01 de Linux con 10000 líneas de código. A partir de ese momento Linux empezó a evolucionar rápidamente.

A partir de 2006, se estima que aproximadamente el dos por ciento del núcleo Linux fue escrito por el propio Torvalds. Debido a que miles de personas han contribuido al núcleo Linux, este porcentaje es una de las mayores contribuciones al mismo. Sin embargo, declaró en 2012 que su propia contribución personal ahora es principalmente un código de fusión escrito por otros, con poca programación. Torvalds conserva la máxima autoridad para decidir qué nuevo código se incorpora al núcleo estándar de Linux. 

Torvalds posee la marca registrada "Linux" y supervisa su uso, principalmente a través del Linux Mark Institute.





</doc>
<doc id="1620" url="https://es.wikipedia.org/wiki?curid=1620" title="Leyenda urbana">
Leyenda urbana

La leyenda urbana (del inglés: "urban legend") es un relato perteneciente al folclore contemporáneo; se trata de un tipo de leyenda o creencia popular, a veces emparentable con un tipo de superstición, que, pese a contener elementos sobrenaturales o inverosímiles, es presentado como hechos reales sucedidos en la actualidad. Algunas parten de hechos reales, pero estos son exagerados, distorsionados o mezclados con datos ficticios. Circulan a través del boca a boca, correo electrónico o medios de comunicación como prensa, radio, televisión o Internet. Suelen tener como trasfondo una «moraleja».

Una misma leyenda urbana puede llegar a tener infinidad de versiones, situadas generalmente en el entorno de aquellos que las narran y reciben. Por su adecuación a la sociedad industrial y al mundo moderno reciben el calificativo de «urbanas», que las opone a aquellas leyendas que, habiendo sido objeto de creencia en el pasado, han perdido su vigencia y se identifican con épocas pasadas. A menudo, el narrador afirma que los protagonistas de la leyenda urbana fueron conocidos o parientes de alguna persona cercana. Por este motivo, en inglés se las conoce también como FOAFT ("friend of a friend tales:" «historias del amigo de un amigo»).

Cuando una leyenda urbana alcanza a tener un cierto impacto político, social o económico relevante entonces se la considera una teoría de conspiración.

El término fue acuñado en 1968 por el folclorista estadounidense Richard Dorson, quien definía la leyenda urbana como una historia moderna «que nunca ha sucedido, contada como si fuera cierta». También cabe mencionar a Jan Harold Brunvand, que ha contribuido decisivamente a popularizar este término entre el público en general a través de sus libros.

Acaso la teoría más convincente sobre la etiología de este tipo de leyendas sea la del filósofo alemán Karl Hepfer en "Teorías conspirativas: Una crítica filosófica de la sinrazón", quien, al preguntarse sobre el auge de las teorías de conspiración en Europa reparó en que la mayoría de ellas respondía a «modelos de interpretación de la realidad simplificados», o intentos de regresar a un estadio anterior de nuestra cultura en el que la realidad supuestamente era sencilla de comprender, y sus actores, buenos o malos. En consecuencia, estas historias suelen tener dos caras, una incomprensible o terrorífica y otra explicativa y simplificadora que tranquiliza. 

Las historias en cuestión reciben diversas denominaciones por parte de quienes las usan y difunden. Entre los periodistas se habla de bulos, o factoides. En Internet, de hoax. En un principio, cabe distinguirlas claramente de los llamados cuentos chinos o las hipérboles desmedradas, como por ejemplo las rodomontadas o exageraciones hiperbólicas como los "Hechos de Chuck Norris", género popular de la llamada literatura de corcho y de Internet emparentables con las antiguas diversiones cortesanas de los siglos XVI y XVII, fanfarronadas conscientes que buscaban divertir como juegos de salón equivalentes a las "trolas" o "bolas" o incluso las bernardinas clásicas. Se distinguen de estos géneros jocosos en que no tienen la intención cortesana de divertir o distraer.

En Cuba se las conoce como «cuentos de camino» o «bolas», en Perú y en Colombia se las llama simplemente «cuentos» o «mitos». Entre los propios estudiosos, no falta quien prefiere catalogarlas como «leyendas» a secas, considerando que su función sigue siendo la propia de este género.
También esta clase de leyendas se expanden en todos los territorios y países haciendo que este se vuelva viral y la gente lo puede ir creyendo.

Para que una historia ficticia se convierta en leyenda urbana es preciso que se difunda de forma espontánea como verdadera y que la información alcance cierto reconocimiento popular.

El rasgo más importante de las leyendas urbanas es su carácter internacional. La historia del submarinista calcinado que es recogido accidentalmente por un avión contra incendios y lo deja caer sobre el fuego, causando su muerte, se cuenta con mínimas variaciones en su estructura en distintos lugares de América del Norte, Europa y Australia, por citar solo algunos sitios por donde circula esta leyenda.

La leyenda urbana puede inspirarse en cualquier fuente, pero incluye a menudo un elemento misterioso, incomprensible. Rara vez resulta posible localizar el origen preciso de una leyenda urbana. Cuando el investigador se enfrenta a una de ellas, se encuentra con varios relatos extendidos por distintas zonas, construidos a partir de un mismo esquema, pero adornados con detalles muy variados en función de su localización.

Las leyendas urbanas tienen una estructura más compleja (planteamiento, nudo y desenlace) que los chismes, rumores y bulos. No pretenden, como estos, desacreditar a una persona en concreto, sino que abordan una «problemática» que afecta a muchas personas. Generalmente, cuentan historias que nos alertan sobre posibles peligros que nos pueden acechar en nuestra vida diaria. De modo que la trama está urdida en función del desenlace, en el que a menudo se concentra el mensaje o moraleja, tal como sucede en las fábulas o cuento de hadas.

La leyenda urbana se encuentra en el límite de la credibilidad. Todas incluyen hechos falsos pero algunas toman elementos de la realidad o están basadas en algún hecho real. Por eso, la leyenda urbana suele contarse como si fuera un suceso verdadero o, al menos, verosímil. Esto exige que los personajes sean meros arquetipos anónimos, «un hombre», «una mujer», «una pareja» o «un conocido de un amigo», el cual el narrador de la leyenda urbana no conoce personalmente, aunque situados siempre en escenarios concretos (una determinada ciudad, calle, país) que contribuyen a hacerla creíble. A menudo, el protagonista es un «amigo de un amigo», relativamente cercano al oyente, pero no tanto que resulte viable consultarle sobre los hechos. Con el paso del tiempo, los elementos de la narración se transforman para volverla más atractiva e impactante.
Desde finales del siglo XX, Internet ha contribuido notablemente a la difusión de las leyendas urbanas, especialmente a través del correo electrónico. Las adaptaciones de las mismas en la red, además de por lo anteriormente comentado, se caracterizan por: añadir frases con alertas catastróficas, citar fuentes de confianza (medios de comunicación, fuerzas del Estado, etc.) y rogar que la información sea difundida para evitar que más personas resulten afectadas. ("Véase" hoax)

Dos de las leyendas urbanas más extendidas son las del fantasma del espejo (normalmente conocida como «Verónica» en español y «Bloody Mary» en inglés) y la autoestopista fantasma, las cuales están divulgadas por todo el mundo y se han ido modernizado con el paso del tiempo. Así, la leyenda de la autoestopista fantasma tiene su precedente en historias en las que la chica no se subía a un coche, sino que paraba a los jinetes y se montaba en la grupa de sus caballos (como sucede, por ejemplo, en el "Romance de la Infantina").
También son populares en Internet otras leyendas que relatan sucesos siniestros, la mayoría de veces relacionados con la Tecnología. Unos ejemplos son los "creepypastas" (o leyendas de internet), que entre ellas se encuentran popularmente Slender Man («Hombre Delgado» en español), una entidad con brazos largos y sin rostro que hace desaparecer a la gente; Jeff The Killer, siniestro asesino en serie, con un horrible rostro quemado y deformado, producto de una sangrienta pelea, de la cual misteriosamente sobrevivió; también una supuesta criatura apodada «The Rake» (similar al chupacabras) de la cual se han reportado algunos supuestos avistamientos.

Las leyendas urbanas, especialmente las referentes a temas de salud, no son necesariamente recientes, y son propagadas debido en gran medida a la falta de conocimientos médicos de la población general. Una de las leyendas urbanas más antiguas dice que la cesárea, operación quirúrgica abdominal para extraer el bebé del vientre materno, debe su nombre a que el dictador romano Julio César había nacido mediante este método. Algo improbable teniendo en cuenta que su madre sobrevivió a un parto que tuvo lugar en el año 100 antes de Cristo, mucho antes de la primera cesárea exitosa de la que hay registro, que tuvo lugar en el año 1500 después de Cristo. La cesárea recibe su nombre de la "Lex Caesarea", una ley promulgada en el año 715 a. C. por el rey romano Numa Pompilio, la cual obligaba a salvar la vida a los fetos de las mujeres que morían durante el embarazo o el parto, mediante un corte en el vientre, precursor de la actual cesárea. El nombre de la ley y la popularidad del personaje de Julio César han deformado la realidad creando una leyenda que perdura hasta nuestros días.

Las leyendas urbanas relacionadas con el tráfico de órganos han tenido mucha difusión. La mayoría tratan de personas que han sido secuestradas con el único fin de extirparles un riñón después de asistir a una fiesta o de consumir alguna droga, generalmente en un lugar poco recomendable. La posible moraleja de esta leyenda urbana es que uno no debe fiarse de los desconocidos.

Otra leyenda urbana de tono claramente moralizante habla de un hombre que viaja a Río de Janeiro de vacaciones y da rienda suelta a todos sus deseos, llegando a tener sexo con una mulata que habría conocido. Cuando despertó en la habitación del hotel se dio cuenta de que su acompañante ya no estaba, y temiendo un eventual robo revisó sus enseres personales encontrando todo en orden. Pero cuando se dirigió al baño encontró un mensaje en el espejo escrito con lápiz labial que decía «Bienvenido al Club del Sida». Este mito tiene varias versiones en las que se cambia al afectado por una mujer a quien un hombre muy atractivo con quien tuvo relaciones sexuales le entregó una caja con un regalo; cuando este se marchó ella abrió la caja del regalo encontrando una rosa negra y un papel con el mismo mensaje. 

También se dice que hay quienes han dejado agujas supuestamente infectadas en butacas de los cines y entre la arena de las playas, siempre acompañadas con un papel con el mismo mensaje. Todas esas leyendas surgieron en una época de mayor ignorancia respecto a la prevención y el contagio de esta enfermedad, claramente pretende dejar un mensaje moralizante para persuadir al oyente para no tener sexo con desconocidos. Esto —sumado a que no existe ningún registro de que se trate de un hecho real— lleva a la conclusión de que se trataría de otra de las tantas leyendas urbanas.

Acerca de la varicela, el sarampión y otras enfermedades infecciosas, y su conveniencia de sufrirlas en la infancia, cuando las complicaciones son menores que en la edad adulta, han surgido leyendas urbanas de padres de niños infectados que contagian o recomiendan contagiar a toda la clase del colegio o su grupo de niños conocidos, para que todos ellos experimenten la varicela cuanto antes.

A finales del siglo XX apareció una leyenda urbana sobre el Progesterex, un supuesto sedante de extrema potencia que causa una esterilización permanente a quien lo toma, y que habría sido administrado por violadores para adormecer a sus víctimas. A día de hoy no existe ningún fármaco que cause una castración química irreversible.

Hoy en día, lavar concienzudamente las latas de bebidas antes de su consumo es una práctica habitual, aunque hay muchas personas que creen que debe hacerse porque podrían haber sido contaminadas por ratas y sus excretas en los almacenes. Una leyenda urbana afirma que en Texas, EE.UU., una mujer murió víctima de leptospirosis contagiada de este modo. En realidad, las latas se almacenan empaquetadas en envoltorios de plástico, lo que impide que esta bacteria, o cualquier otro microorganismo, entre en contacto directo con ellas.

La nota marrón es el nombre que se da a una frecuencia de infrasonidos que supuestamente produciría efectos laxantes en el ser humano. El origen de esta leyenda podría estar en el conocimiento de que los infrasonidos son utilizados para provocar reacciones en las personas, como se hizo, por ejemplo, en la película Irreversible, que incluyó infrasonidos en su metraje para desconcertar al espectador.

Otras leyendas difundidas sobre la salud son: la regla de los cinco segundos, por la cual si se cae comida o cubiertos estos no están contaminados por las bacterias si se recogen antes de los 5 segundos; o los Pechos explosivos, muy difundido y que afectan a famosas operadas con silicona, por el cual estallaba uno de esos pechos artificiales en un viaje en avión a gran altura por la presión atmosférica; o el mito del 10 % del cerebro, de que los seres humanos utilizamos solamente el 10 por ciento de nuestro cerebro.

Hay numerosas leyendas acerca de la Coca-Cola y sus propiedades. De este producto se ha dicho que su «fórmula secreta» es capaz de descomponer trozos de carne, que desatasca las tuberías, que sirve para aflojar los tornillos, limpia las manchas de grasa en la ropa y es un poderoso espermicida. Se ha demostrado que todo esto forma parte de la leyenda urbana. 

También mucha gente cree que en Estados Unidos se realizó una prueba en un cine para comercializar la bebida, a base de mensajes subliminales. El supuesto experimento habría sido realizado por James Vicary en 1957 y consistía en incluir uno o dos fotogramas por minuto con la marca. En 1962 Vicary fue entrevistado por la revista "Advertising Age" («La era del comercial») y declaró que el experimento en realidad era una mentira que se llevó a cabo debido a que su empresa pasaba por dificultades económicas. Por lo tanto no se puede afirmar con certeza ni la realización de la prueba ni sus resultados.

Algunas leyendas urbanas, colindantes con el rumor, se refieren a personas famosas. Tal es el caso de la presunta muerte de Paul McCartney (exbajista de The Beatles) en un accidente de circulación en 1966, tras la cual pasó a sustituirlo un doble. Los fanáticos creyeron haber encontrado pruebas del hecho en las canciones y portadas de los discos posteriores a aquel año. También se ha dicho que Josh Saviano, actor que apareció en la serie "Aquellos maravillosos años" (1988-1993), era en realidad el cantante Marilyn Manson.

Una leyenda muy común sobre personas célebres muertas es que realmente siguen vivas. Se ha afirmado que la princesa Diana de Gales o músicos como Elvis Presley, Jim Morrison, Jimi Hendrix y Michael Jackson permanecen vivos. También, se dice en Argentina que Alfredo Yabrán (1944-1998), un empresario de ese país, realmente no se habría suicidado como demostraron las autopsias realizadas al cuerpo sino que habría montado un cadáver para que así lo pareciera, argumentando que con el poder y el dinero que poseía debería haberse fugado del país (tenía una grave causa judicial en su contra). Algo similar ocurrió en España a la raíz de la muerte de Jesús Gil, empresario, político y dueño del club de fútbol Atlético de Madrid, en 2004. Se especulaba con que su muerte no había sido real y había huido a Venezuela para escapar de sus responsabilidades penales por corrupción y apropiación indebida, entre otras.

En ocasiones ocurre al contrario y la leyenda urbana afirma que ha muerto una persona que realmente sigue viva, este es el caso de la cantante panameña Lorna. Desde el año 2003, en el que alcanzó el éxito con su reggaeton «Papichulo», se difundió la creencia de que Lorna murió de sobredosis, totalmente infundada y desmentida, puesto que el último álbum de esta cantante fue publicado en 2009.

Una de las más famosas leyendas urbanas sobre personajes famosos es la de la supuesta criogenización de Walt Disney. Muy poco después de su muerte en 1966 (ya en 1969 aparece reflejado en una revista) surgió el rumor de que el cuerpo de Disney había sido criogenizado hasta el momento en que los avances científicos pudieran devolverlo a la vida. Se trata una leyenda completamente falsa, ya que hay constancia tanto de la muerte de Disney como de su posterior incineración. No está claro el origen del rumor. Al menos dos biógrafos de Disney, Leonard Mosley ("Disney's World: A Biography", 1985) y Marc Eliot ("Walt Disney: Hollywood's Dark Prince: A Biography", 1993) mencionan el interés de Disney por la criónica en los últimos años de su vida, aunque no aportan fuentes concretas. Es imposible saber con certeza si este interés existió, en cuyo caso pudo haber sido lo que originó la leyenda. Por otro lado, el hecho de que la incineración se llevase a cabo en un ámbito estrictamente privado pudo alimentar las especulaciones. Debe tenerse en cuenta también que Disney era conocido, sobre todo en sus últimos años, por su interés por las innovaciones tecnológicas. Otra leyenda urbana afirma que el dictador español Francisco Franco está enterrado boca abajo, mirando al suelo, para que en caso de resucitara y pretendiera salir excavando, lo hiciera hacia el interior de la tierra y no volviera a la superficie.

Una leyenda urbana afirma erróneamente que el médico y político francés Joseph-Ignace Guillotin inventó la guillotina, y que posteriormente fue ejecutado con este instrumento. Guillotin es famoso por sugerir este instrumento, ya existente en Europa Central desde la Edad Media, para todas las ejecuciones en Francia, lo que llevó a nombrar popularmente a este aparato con su apellido. Josep-Ignace Guillotin falleció de muerte natural. La creencia de que murió en la guillotina procede de que otro hombre, también apellidado Guillotin y médico de profesión, murió ejecutado con ella. Del científico y religioso español Miguel Servet se dice que fue condenado a la hoguera por descubrir la circulación de la sangre, lo cual fue considerado herejía por la Inquisición. Es cierto que Servet hizo avances en ese campo y fue ejecutado en la hoguera, pero ambos eventos no están relacionados y aquella no fue la causa de su enjuiciamiento.

Otra leyenda urbana muy extendida en España es la del supuesto incidente del programa televisivo, presentado por Concha Velasco, "Sorpresa, sorpresa" en los años noventa. Se decía que el cantante Ricky Martin, ídolo de una chica a la que pretendía sorprender saliendo del armario de su habitación, se encontró a la niña untada de mermelada, helado u otro alimento realizando un juego erótico con su perro. Dicha situación no sucedió en realidad y por supuesto no existen imágenes, pese a lo cual mucha gente afirmó haber visto dicha escena. Es necesario destacar que esa leyenda es solo una de las muchas variantes de una misma historia apócrifa que también se cuenta como verdadera en los Estados Unidos, donde, una mujer es sorprendida con una fiesta sorpresa en su casa mientras esta estaba cubierta de crema de maní y era lamida ansiosamente por su perro. El folclorista Jan Harold Brunvand (quién cita el concepto de esta historia en el capítulo «"Aventuras Sexuales"» de su obra "El Fabuloso libro de las Leyendas Urbanas") afirma que por lo general las leyendas urbanas, al ir contándose de una persona a otra, tienden a diluirse o incluso exagerarse los detalles que caracterizan a la historia, con este ejemplo pasando de ser una anécdota bochornosa a parte de la carrera de un famoso cantante.

Del mismo estilo es una leyenda urbana acerca del grupo musical vasco La Oreja de Van Gogh. Supuestamente esta banda, en una entrevista en un programa de Pedro Ruiz, había reconocido que simpatizaba y apoyaba a la banda terrorista ETA, algo que ha sido desmentido por los propios cantantes.

De Steve Jobs, fundador de Apple, se cuenta que no soportaba ir en ascensor en las oficinas de la empresa acompañado de personas ajenas a sus conversaciones. Según cuentan testimonios, subirse con él en el ascensor sin autorización suya estaba penado con el despido.

Algunos lugares, reales o supuestos, que son propiedad de los gobiernos nacionales, han dado pie a leyendas urbanas, por la escasa información o secretismo que existe en torno a ellos. El Área 51, base militar aérea de Nevada en Estados Unidos, es una de ellas. El propósito de esta base es secreto y no se permite el acceso a visitas o la prensa, lo que ha originado la aparición de diversos supuestos para ella, tales como el desarrollo de armas de destrucción masiva y el almacenamiento de naves espaciales y cadáveres de extraterrestres que se habrían estrellado en la Tierra.

Por su parte, el gobierno ruso nunca ha confirmado ni desmentido la existencia del supuesto Metro-2 de Moscú, un ferrocarril subterráneo secreto que uniría puntos clave de la capital rusa y serviría de comunicación de emergencia para altos cargos políticos y militares.

Otra leyenda afirma que no hay rotondas en todo el territorio de Estados Unidos. Este tipo de cruce viario nunca fue popular en ese país y es cierto que no comenzaron a instalarse hasta los años 1990.

Del parque del Cerro del Tío Pío de Madrid se dice que fue plantado sobre un enorme vertedero, lo cual explica que sus prominentes colinas, las únicas que hay en el entorno, son en realidad montañas de basura. Esto solo es cierto en parte, pues apenas una pequeña porción del parque fue utilizada anteriormente como vertedero.

Siempre han surgido historias de personas que supuestamente viajaron a través del tiempo, los cuales fueron informados por la prensa y circularon en Internet. Muchos de estos informes han resultado ser bromas o se basaron en suposiciones incorrectas, información incompleta, o la interpretación de la ficción como un hecho. 

También hay casos de Ooparts, que son objetos que aparece fuera de tiempo, perteneciendo a una época que no es la suya y por lo tanto indicando indirectamente que alguien situó esos artefactos ahí. Un ejemplo es un supuesto teléfono inteligente en un combate de Tyson de 1995. Sin embargo se apunta que el objeto es un tipo de cámara japonesa que había empezado a comercializarse en aquella época.

Existe un mito que dice que, en 1907, la bandera de Chile habría ganado un concurso internacional sobre «la bandera patria más hermosa del mundo». Supuestamente, dos familias chilenas (Baehcker y Casas) habrían llegado al balneario de Blankenberghe ["sic"] (en Bélgica), mientras visitaban algunas localidades de las costas del Mar Báltico como parte de sus vacaciones. Al llegar a dicha ciudad, se encontraron con este concurso y decidieron participar, con la sorpresa de ganar entre una multitud de emblemas. Otra versión dice que fue en el siglo XIX, y otra le da el segundo lugar, tras la bandera de Francia; aún otras variaciones del mito indican al "Himno Nacional de Chile" como ganador de un concurso análogo, o le otorgan el segundo lugar, tras "La Marsellesa" y el tercer lugar al Himno Nacional de El Salvador. La cantidad de distintas versiones de este mito, la carencia de fuentes independientes, el error de la localidad mencionada (que se encuentra junto al mar del Norte y no al mar Báltico) y la similitud de esta leyenda con algunas parecidas en otros países ponen en grave duda el que haya ocurrido en realidad, estableciéndose solo como mito.

Existe la leyenda de que en el último capítulo de Doraemon el protagonista Nobita se despierta y resulta que descubre que todo fue un sueño. Lo cierto es que la serie no tiene un capítulo final porque su creador murió antes de pensar cómo acabar la serie. Algo parecido le sucede a la serie supercampeones, en el que Oliver en realidad estaría en un hospital soñando con partidos imposibles porque tiene las piernas amputadas porque fue supuestamente atropellado.

Una leyenda urbana muy famosa y difundida es la existencia de vídeos snuff, que supuestamente son grabaciones de asesinatos, violaciones, torturas, suicidios, necrofilia, infanticidio, entre otros crímenes reales (sin la ayuda de efectos especiales o cualquier otro truco) con la finalidad de distribuirlas comercialmente para entretenimiento.

Con el uso del Internet se han creado más leyendas, usualmente sobre temas relacionados con la tecnología. Entre las leyendas urbanas más populares relacionadas con la red se encuentran aquellas relacionadas con las nuevas tecnologías. Es el caso de la leyenda sobre la pandilla Bloods, la del sitio web "Blindmaiden.com" que supuestamente quienes la visitan corren el riesgo de morir siendo arrancados los ojos por un siniestro espectro de una mujer ciega, o la de un viajero del tiempo, John Titor, que supuestamente se comunicó con alguien por mIRC y le reveló acontecimientos del futuro.
Otras de las más destacadas son "El suicidio de Calamardo" (un presunto capítulo perdido de "Bob Esponja") en el cual se supone que Calamardo se suicida después de uno de sus tantos conciertos fallidos, el famoso «Herobrine» en "Minecraft", del cual se dice que es el hermano muerto de Notch quien es el creador del videojuego, y «SuicideMouse.AVI», un video de Mickey Mouse donde la imagen se deforma, el sonido es pobre, con gritos pertubadores y mensajes ocultos.

Una de las leyendas urbanas sobre videojuegos más conocidas es la que afirma la existencia de "Polybius". Según la historia, el juego fue lanzado al público en 1981, causando efectos devastadores a los jugadores tales como locura, estrés y horribles pesadillas. Poco tiempo después de su lanzamiento, el juego desapareció sin dejar rastro. Aún no hay pruebas de que este juego haya existido realmente. Algunos creen que el juego fue elaborado por encargo del gobierno de Estados Unidos para que los menores dejaran de jugar a los videojuegos.

Existen varias leyendas urbanas difundidas por Internet, conocidas como "creepypastas" o creepypaste (del inglés "creepy", horripilante) creadas con el fin de aterrar al lector. Una leyenda muy destacada es «Tails Doll», un personaje secreto del videojuego "Sonic R", el cual luego de desbloquearlo supuestamente causa una serie de enfermedades o trastornos psicológicos, como que durante el sueño se escucha la frase «"Can you feel the Sunshine?"» (de la banda sonora del juego), acabando con la muerte (es la leyenda urbana más conocida y famosa de los Estados Unidos además de Slender man).

Algunas de estas leyendas son sobre cartuchos de juegos alterados. Un ejemplo es «BEN Drowned», un supuesto cartucho embrujado de "", que fue propiedad de un niño que murió ahogado por accidente. Este cartucho tendría supuestamente un funcionamiento incorrecto, que mostraría elementos erróneos y corruptos en la pantalla para enloquecer al jugador. Otro caso es «"Pokémon Black"». Sin relación con el juego oficial, sería un supuesto hack de "Pokémon Rojo y Azul", en el cual el jugador entrena a un fantasma que, en lugar de simplemente noquear a los Pokémon contrarios, como ocurre en los juegos reales, los mata literalmente, y también asesina a los entrenadores rivales. Esta historia trata de moralizar sobre la banalización de la violencia en los videojuegos.

Las leyendas urbanas son comunes en la literatura. Una de ellas sostiene que las obras inéditas de William Shakespeare yacen con él en su tumba, o que sus obras son en realidad de otros autores. Otra leyenda es que Cervantes y Shakespeare fueron en realidad la misma persona. Ha adquirido también características de leyenda urbana la atribución errónea al escritor argentino Jorge Luis Borges de un texto titulado Instantes.

En la economía también existen leyendas urbanas. En España y otros países occidentales está muy extendida la creencia, errónea, de que en Japón, durante su burbuja inmobiliaria entre 1980 y 1990, los bancos concedían créditos hipotecarios a 90 y 100 años, cuyas responsabilidades pasarían de padres a hijos. También está extendida la creencia de que el rey de España siempre apuesta al número 00.000 de la Lotería de Navidad, o que el monarca cobra una comisión por cada barril de petróleo importado por el país; algo que nunca ha sido confirmado ni desmentido por la Casa Real. Desde hace más de veinte años han corrido rumores de que en España, en tiempos de crisis y momentos en los que el Estado carecía de liquidez, empresas como El Corte Inglés, Mercadona o la ONCE habían pagado las nóminas de los funcionarios a cambio de futuros favores del Gobierno. Otra creencia es que los bares de Barcelona cobran un euro por un vaso de agua del grifo; posiblemente el origen de la misma está en los tópicos sobre los catalanes.

La huelga a la japonesa sería un tipo de protesta sindical en la cual los trabajadores producen en exceso, con el objetivo de llevar a la quiebra a la empresa cuando sea imposible vender toda la producción. Los precios del stock bajarían por el exceso de oferta y la empresa tendría que afrontar gastos extraordinarios para almacenar los productos no vendidos.

Los ferrocarriles de España fueron construidos en un ancho de 1668 mm, ligeramente superior al estándar europeo de 1435 mm. Esta medida fue tomada en principio para que por España, un país montañoso en comparación con las llanuras de Europa Central, pudiesen circular locomotoras más anchas y más potentes. Aunque el problema de la potencia de las locomotoras se podría haber solucionado con máquinas más largas, la leyenda urbana reside en la creencia de que el distinto ancho de vía se implantó como medida de defensa militar, para prevenir una eventual invasión de España por ferrocarril desde Francia. Entonces, a mediados del siglo XIX, aún estaba reciente la invasión napoleónica. Esta creencia se popularizó en la sociedad española al convertirse en una profecía autocumplida, pues habría sido imposible para la Alemania Nazi, cuyo dominio llegó hasta los Pirineos, entrar en España por tren en el caso de que el régimen nazi decidiera invadir el país ibérico, algo que nunca ocurrió.

En el deporte tienen mucha más repercusión pública la retransmisión de las escenas polémicas o de vandalismo en los estadios, que la resolución y sentencia de los mismos, lo que produce desinformación o lleva a errores a los medios de comunicación y, en última instancia, a los espectadores y aficionados. El FC Barcelona ha tenido que desmentir que tuviera aún pendientes de cumplir algunas sanciones que le fueron impuestas hace años, entre ellas, la prohibición de disputar la Copa del Rey durante un año por negarse a disputar un partido contra el Atlético de Madrid (el club no tenía once jugadores aquel día, pues la mayoría de la plantilla estaba convocada con sus selecciones nacionales), o el cierre del Camp Nou por dos partidos por el lanzamiento de objetos al campo en un duelo contra el Real Madrid, en el que se llamó "el partido del cochinillo". En el primer caso el club fue indultado, admitiendo la RFEF su error por fijar el partido en un día que había competiciones de selecciones; en el segundo, el cierre del estadio se sustituyó por una multa de 4.000 euros. 

Pese a estas aclaraciones, hay periodistas que desde hace años advierten de una conspiración de la RFEF y su presidente Ángel María Villar para favorecer deportivamente al FC Barcelona (véase "El villarato"). Otra teoría es que en determinados sorteos futbolísticos (como la Champions League) hay bolas calientes (o frías), con diferente peso o rugosidad, para que la persona que tenga que meter la mano sepa cual tiene que elegir (para beneficiar a un equipo en una eliminatoria porque su rival es más débil), siendo el Real Madrid uno de los principales acusados.

El paso de los años también provoca que surjan leyendas o historias inventadas sobre hazañas increíbles de deportistas. Por ejemplo, la que afirma que Muggsy Bogues, jugador de baloncesto de los Charlotte Hornets, el más bajo de la historia de la NBA (1,60 m), realizó el único mate de su carrera el 4 de diciembre de 1990, en un partido contra los Washington Bullets. Algo que en realidad no ocurrió, puesto que aquel día estos dos equipos no jugaron ningún partido. Bogues nunca alcanzó el aro, situado a 3,05 m de estatura. El jugador más bajo que consiguió hacer mates fue Spud Webb, que mide 1,67 metros. Otra leyenda popular en España es que Miguel Induráin confesó indirectamente que se dopaba al periodista José María García en uno de sus programas radiofónicos.

Otras leyendas urbanas señaladas son que los taiwaneses comen fetos de bebés, que en las alcantarillas de Nueva York viven cocodrilos ciegos, que se puede ver la Gran Muralla China desde el espacio, que los móviles pueden provocar una explosión de un tanque de gasolina, que los cienciólogos comen bebés, gatos bonsáis embotellados, entre otras muchas.





</doc>
<doc id="1624" url="https://es.wikipedia.org/wiki?curid=1624" title="Larry Sanger">
Larry Sanger

Lawrence «Larry» Mark Sanger (Bellevue, Alejandra; 16 de julio de 1968) es un filósofo estadounidense, célebre por ser cofundador de Wikipedia, junto a Jimmy Wales, y haber contribuido a organizarla como una comunidad libre, abierta y colaborativa, desarrollando varias de las políticas más importantes de la enciclopedia. A su vez es el creador de Citizendium.

Nacido en Bellevue (Washington) el 16 de julio de 1968, aunque cuando tenía siete años de edad, la familia de Larry se mudó a la ciudad de Anchorage (Alaska), en donde Sanger desarrolló su infancia y adolescencia. 

Después de acabar su educación secundaria en 1986, se fue a la universidad Reed College, en Portland, especializándose en filosofía. En la universidad se interesó en Internet y sus habilidades de publicación. Creó un servidor de listas como medio para que los estudiantes y tutores se reúnan para "tutoría experta" y "para actuar como foro de discusión de tutoriales, métodos tutoriales y la posibilidad y los méritos de una red voluntaria y gratuita de tutores individuales y estudiantes que se encuentran a través de Internet para la educación fuera del entorno universitario tradicional. " Comenzó y moderó una lista de discusión de filosofía, la Asociación para la Filosofía Sistemática. Sanger escribió en 1994 un manifiesto para el grupo de discusión: "La historia de la filosofía está llena de desacuerdos y confusión. Una reacción de los filósofos a este estado de cosas es dudar si la verdad sobre la filosofía puede conocerse alguna vez, o si hay tal cosa como la verdad de la filosofía. Pero hay otra reacción: uno puede comenzar a pensar más cuidadosa y metódicamente que los antepasados ​​intelectuales de uno ".

Sanger recibió su Licenciatura en Filosofía del Reed College en 1991, una Maestría en Artes de la Universidad del Estado de Ohio en 1995 y un Doctorado en Filosofía de la Universidad Estatal de Ohio en el año 2000. A partir de 1998 dirigió un sitio web llamado "Revisión de Sanger de los informes de noticias Y2K", un recurso para aquellos preocupados por el problema del año 2000, como los administradores de sistemas informáticos.

Sanger trabajó para la empresa Bomis, propiedad de Jimmy Wales, que fracasó al cabo de seis años, como redactor jefe de Nupedia.
A causa de desencantos por el lento avance de esta, en enero de 2001 propone crear un wiki para dinamizar la creación de artículos.
Como resultado de esto surgirá Wikipedia, cuyo nombre fue ideado por Larry Sanger, con el propósito de aportar conocimientos universales a la humanidad y con esto evitar disputas en cuanto a definiciones y otros, en la búsqueda de la armonía y la paz mundial. De esta forma sería el único editor pagado de la enciclopedia, estatus que mantuvo desde el 15 de febrero de 2001 hasta el día de su renuncia a cualquier relación con Wikipedia, el 1 de marzo de 2002.

Sanger afirma ser el cofundador de Wikipedia junto a Jimmy Wales, aunque este último desde 2005 ha rechazado en varias ocasiones esta consideración, proclamándose el único fundador de la enciclopedia —aunque antes de esa fecha sí le reconocía como cofundador. Wales argumenta que, aunque el rol de Sanger era importante, no dejaba de ser un empleado bajo su dirección, a lo que Sanger ha respondido en alguna ocasión, afirmando que mientras él organizaba Wikipedia, Wales se centró principalmente en Bomis.

Tras salir de la Wikipedia volvió a la Universidad Ohio State, donde obtuvo el doctorado en filosofía. En septiembre de 2006, Sanger anunció la creación de una bifurcación de Wikipedia, denominada Citizendium, en la cual se utilizarían nombres reales y estaría compuesta de expertos en cada materia.


</doc>
<doc id="1625" url="https://es.wikipedia.org/wiki?curid=1625" title="Libertad">
Libertad

La libertad en sentido amplio es la capacidad humana de obrar según la propia voluntad.

Según las acepciones 1, 2, 3 y 4 de este término en el diccionario de la Real Academia Española, el estado de libertad define la situación, circunstancias o condiciones de quien no es esclavo, ni sujeto, ni impuesto al deseo de otros de forma coercitiva. En otras palabras, aquello que permite a alguien decidir si quiere hacer algo o no, lo hace libre, pero también responsable de sus actos en la medida en que comprenda las consecuencias de ellos.

La quinta acepción del término define la libertad en los Estados democráticos como «derecho de valor superior que asegura la libre determinación de las personas.». Con base en ello, la protección de la libertad interpersonal es objeto de una investigación social y política.

El fundamento metafísico de la libertad interior es una cuestión psicológica y filosófica.
Ambas formas de la libertad se unen en cada individuo como lo interno y lo externo de una malla de valores, juntos en una dinámica de compromiso. 

formula_1

En castellano la palabra "libertad" proviene del latín "libertas, -ātis", de igual significado.

La palabra inglesa para libertad, "freedom", proviene de una raíz indoeuropea que significa amar; la palabra de la misma lengua para decir miedo, "afraid", viene de la misma raíz, usado como contraposición a libertad mediante el prefijo "a" por influencia del latín vulgar. 

La libertad como desaparición de opresión significa no querer subyugar ni ser subyugado, e implica el fin de un estado de servidumbre. El logro de esta forma de la libertad depende de una combinación de la resistencia del individuo (o grupo) y su entorno.

Las leyes artificiales limitan esta forma de libertad, por ejemplo, nadie es libre de no ser representado por políticos dentro de una nación (aunque podamos o no ser libres para intentarlo).

Las leyes naturales, como las leyes físicas, o la ley de la gravedad, son también un fundamento importante para la libertad de todos los seres vivos existentes en el universo.

La ética filosófica señala que la libertad es inherente al humano, es un dato fundamental originario de la existencia humana, fundamentado en la autoconciencia y la responsabilidad moral. Por tanto, el individuo humano no puede remitir su propia libertad/responsabilidad a ningún otro y, por eso mismo, la libertad, en su sentido antropológico, es algo que no es posible eliminar ni contradecir.

Todos los actos presuponen a la libertad para poder ser infinitamente imputables (libre albedrío). La libertad se sitúa en la interioridad de la persona y siguiendo esa línea de pensamiento afirma Ricardo Yepes Stork:

La libertad ha sido a menudo utilizada para aludir a la revolución o rebelión. Por ejemplo, la Biblia registra la historia de Moisés conduciendo a su pueblo fuera de Egipto y de su opresión (la esclavitud).

En el marco de control interno, la libertad es también conocida como la libre determinación, la individualidad, o la autonomía pero sujetas a una autoridad superior.

La libertad para una persona también puede significar autonomía interna, o de maestría sobre la condición interna. Esto tiene varios significados posibles:

En una obra de Hans Sachs, el filósofo griego Diógenes se refiere a Alejandro Magno, diciéndole: «Vos sois el siervo de mis siervos». El filósofo ha conquistado al miedo, la lujuria, y la ira; Alejandro todavía sirve a estos "maestros". A pesar de haber conquistado el mundo exterior, todavía no ha dominado el mundo interior. Este tipo de dominio no depende de nada ni nadie más que nosotros mismos.

En el siglo XX notables personalidades han sido el ejemplo de esta forma de incluir la libertad, como Nelson Mandela, el rabino Leo Baeck, y Mahatma Gandhi.

El filósofo francés Jean-Jacques Rousseau afirmó que la condición de la libertad es inherente a la humanidad, una inevitable faceta de la posesión del alma, con la implicación de que todas las interacciones sociales con posterioridad al nacimiento implica una pérdida de libertad, voluntaria o involuntariamente. Él hizo la famosa frase «El hombre nace libre, pero en todas partes está encadenado».

Intenta rebatirle Ricardo Yepes Stork, quien afirma:

Por lo que la esfera de la libertad no se da de una vez y para siempre, sino que ha de ser conquistada todos los días, a través de cada una de las acciones realizadas.

Rudolf Steiner desarrolló una filosofía de la Libertad basada en el desarrollo las intuiciones éticas en circunstancias sensibles.

Artículo principal: https://en.wikipedia.org/wiki/Free_will
Los filósofos de los primeros tiempos han considerado la cuestión de la libertad. El emperador romano Marco Aurelio (121–180 d. C.) escribió:

"una política en la que existe la misma ley para todos, una política administrada con respecto a la igualdad de derechos y la libertad de expresión, y la idea de un gobierno real que respete sobre todo la libertad de los gobernados. 

Un hombre libre es aquel que en aquellas cosas que por su fuerza e ingenio es capaz de hacer, no se le impide hacer lo que tiene la voluntad de hacer.

Leviatán, parte 2, cap. XXI John Locke (1632–1704) rechazó esa definición de libertad. Aunque no menciona específicamente a Hobbes, ataca a Sir Robert Filmer que tenía la misma definición. De acuerdo con Locke:

En el estado de naturaleza, la libertad consiste en estar libre de cualquier poder superior en la Tierra. Las personas no están bajo la voluntad o autoridad legislativa de otros, sino que solo tienen la ley de la naturaleza para su gobierno. 

En la sociedad política, la libertad consiste en no estar bajo ningún otro poder legislativo, excepto el establecido por consentimiento en la comunidad. Las personas están libres del dominio de cualquier voluntad o restricción legal aparte de la promulgada por su propio poder legislativo constituido de acuerdo con la confianza depositada en él. 

Por lo tanto, la libertad no es como la define Sir Robert Filmer: "Una libertad para que todos hagan lo que quieran, vivan como les plazca, y no estar atados por ninguna ley". La libertad está limitada por las leyes tanto en el estado de la naturaleza como en la sociedad política. La libertad de la naturaleza no debe estar bajo ninguna otra restricción que la ley de la naturaleza. La libertad de las personas bajo el gobierno no debe estar sujeta a restricciones, aparte de las reglas vigentes para vivir que son comunes a todos en la sociedad y creadas por el poder legislativo establecido en ella. Las personas tienen el derecho o la libertad de seguir su propia voluntad en todo lo que la ley no haya prohibido y no estar sujeta a las voluntades inconstantes, inciertas, desconocidas y arbitrarias de los demás .

John Stuart Mill (1806-1873), en su trabajo, Sobre la libertad, fue el primero en reconocer la diferencia entre la libertad como la libertad de actuar y la libertad como la ausencia de coerción. 

En su libro Dos conceptos de libertad, Isaiah Berlin enmarca formalmente las diferencias entre dos perspectivas como la distinción entre dos conceptos opuestos de libertad: libertad positiva y libertad negativa. El último designa una condición negativa en la cual un individuo está protegido de la tiranía y el ejercicio arbitrario de la autoridad, mientras que el primero se refiere a la libertad que proviene del dominio propio, la libertad de las compulsiones internas como la debilidad y el miedo. 

Según el Concise Oxford Dictionary of Politics, el liberalismo es "la creencia de que el objetivo de la política es preservar los derechos individuales y maximizar la libertad de elección". Pero señalan que existe una discusión considerable sobre cómo lograr esos objetivos. Toda discusión sobre la libertad depende de tres componentes clave: quién es libre, qué es libre de hacer y qué fuerzas restringen su libertad . 

John Gray argumenta que la creencia central del liberalismo es la tolerancia. Los liberales permiten a otros la libertad de hacer lo que quieran, a cambio de tener la misma libertad. Esta idea de libertad es personal más que política. 

William Safire señala que tanto la derecha como la izquierda atacan el liberalismo: por la derecha por defender prácticas como el aborto, la homosexualidad y el ateísmo, y por la izquierda por defender la libre empresa y los derechos del individuo sobre el colectivo.

Según la Encyclopædia Britannica, los libertarios mantienen la libertad como su principal valor político. Su enfoque para implementar la libertad implica oponerse a cualquier coerción gubernamental, aparte de lo que es necesario para evitar que las personas se coaccionen entre sí.

Según los teóricos republicanos de la libertad, como el historiador Quentin Skinner o el filósofo Philip Pettit, la libertad no debe verse como la ausencia de interferencia en las acciones, sino como la no dominación. 

Según este punto de vista, que se origina en el Roman Digest, ser un liber homo, un hombre libre, significa no estar sujeto a la voluntad arbitraria de otro, es decir, dominado por otro. 

También citan a Maquiavelo, quien afirmó que debe ser miembro de una asociación civil libre y autónoma, una república, si desea disfrutar de la libertad individual. 

El predominio de esta visión de la libertad entre los parlamentarios durante la Guerra Civil inglesa resultó en la creación del concepto liberal de libertad como no injerencia en el Leviatán de Thomas Hobbes

Según la Real Academia Española, la libertad (Del lat. "libertas", -"ātis") es, en su primera acepción, la «Facultad natural que tiene el hombre de obrar de una manera o de otra, y de no obrar, por lo que es responsable de sus actos». Es decir, la libertad es poder elegir entre múltiples opciones, a mayor número de opciones mayor es la libertad, por lo tanto, la mayor libertad sería poder elegir entre un infinito número de opciones, sin limitaciones. 

Pero si a la libertad individual le añadimos el hecho de que no vivimos solos sino que compartimos la realidad con otros individuos que también tienen intereses entonces la libertad debe ser limitada en beneficio de todos. Según el artículo 4 de la Declaración Universal de los Derechos Humanos, se define la libertad añadiéndole una excepción, la cual consiste en limitar la libertad cuando ésta cause perjuicio a otros: «La libertad consiste en poder hacer todo aquello que no cause perjuicio al otro».

El concepto de la libertad política está estrechamente vinculada con los conceptos de las libertades cívicas o civiles y los derechos individuales, incluidas en la Declaración Universal de los Derechos Humanos, que, sin embargo, no han llegado a ser universales.

En el caso del anarquismo la libertad es entendida como la ausencia de coacción o imposición. Los anarquistas consideran que tanto las libertades personales como las económicas son igualmente importantes, y que la asociación o la cooperación debe ser voluntaria, dado el estatus de soberano a todo pacto recíproco entre personas adultas, haciendo innecesaria e indeseable toda interferencia externa a tales pactos (autoridad injustificada, involuntaria o permanente). Los anarquistas entienden la libertad como una condición inherente al ser humano y su desarrollo.

Como ejemplo de los distintos usos de la palabra libertad, algunos dicen que Irak era libre bajo Paul Bremer sobre la base de que su gobierno era un gobierno humanista y no vasallo a otros gobiernos, mucho antes de las elecciones que se celebraron. Otros han argumentado que Irak era libre bajo el régimen de Saddam Hussein porque con él Iraq no era una colonia; mientras que una tercera parte de la reclamación es que ni como Estado Dictatorial ni como Estado Colonial, Iraq sea precisamente ejemplo de la libertad política para nada.

Los ecologistas sostienen que a menudo las libertades políticas sociales deben incluir algunas restricciones a la utilización de los ecosistemas. Sostienen que no puede haber lugar para, por ejemplo, "la libertad para contaminar" o "libertad a deforestar" dadas las consecuencias. La popularidad de los todoterrenos, el golf, y la expansión urbana ha sido utilizado como prueba de que algunas ideas de la libertad y la conservación ecológica pueden chocar.

Los animalistas, especialmente los veganos, sostienen que los animales de otras especies deberían tener derechos frente a los humanos, lo cual conduce a un choque de valores que se ve reflejado en campañas de publicidad de organizaciones como PETA, HSUS, etc. en relación con el uso de animales como fuente de alimento, ocio, vestimenta, experimentación, etc.

Se han producido numerosos debates filosóficos sobre la naturaleza de la libertad, las reclamadas diferencias entre los distintos tipos de libertad, y la medida en que la libertad es deseable.
Los deterministas sostienen que todas las acciones humanas están predeterminadas y por lo tanto, la libertad es una ilusión. Una causa determinada tiene una consecuencia determinada basándose principalmente en las leyes de la física, por lo tanto, al aumentar el nivel de complejidad, la conciencia y la idea de libertad solo son consecuencia determinada de eventos físicos conocidos y regulados por leyes de las cuales no se puede escapar.

En la jurisprudencia, la libertad es el derecho a determinar la propia acción autónoma, que generalmente se concede en los campos en los que el tema no tiene la obligación de cumplir las leyes a obedecer o, de acuerdo a la interpretación de que la hipotética naturales ilimitada libertad está limitada por la ley para algunos asuntos.

Sartre habla de la libertad en su obra "Las moscas" donde dice que cada individuo nace libre pero depende de las circunstancias este puede o no seguir siendo libre. Esto explica que hay diferentes clases de libertades y cada una se marca en las distintas sociedades



Voz "Libertad" en "Philosophica": Enciclopedia filosófica "online"


</doc>
<doc id="1626" url="https://es.wikipedia.org/wiki?curid=1626" title="Leptón">
Leptón

En física, un leptón es una partícula con espín 1/2 en el caso de los neutrinos y +/- 1/2 en los demás leptones (un fermión) que no experimenta interacción fuerte. Los leptones forman parte de una familia de partículas elementales conocida como la familia de los fermiones, al igual que los quarks.

Un leptón es un fermión fundamental sin carga hadrónica o de color. Existen seis leptones y sus correspondientes antipartículas: el electrón, el muon, el tau y tres neutrinos asociados a cada uno de ellos.

Hay tres sabores conocidos de leptones: el electrón, el muon y el leptón tau. Cada sabor está representado por un par de partículas llamadas doblete débil. Uno es una partícula cargada masiva que lleva el mismo nombre que su sabor (como el electrón). La otra es una partícula neutra casi sin masa llamada neutrino (como el neutrino electrónico). Todas, es decir las seis partículas, tienen su correspondiente antipartícula (como el positrón o el antineutrino electrónico). Todos los leptones cargados conocidos tienen una sencilla unidad de carga eléctrica (que depende de si son partículas o antipartículas) y todos los neutrinos y antineutrinos tienen carga eléctrica cero. Los leptones cargados tienen dos estados de espín posibles, mientras que se observa una sola helicidad en los neutrinos (todos los neutrinos son levógiros y todos los antineutrinos son dextrógiros.

Las masas de los leptones también obedecen a una relación simple, conocida como la fórmula de Koide, pero actualmente esta relación aún no puede ser explicada.

Cuando interactúan partículas, generalmente el número de leptones del mismo tipo (electrones y neutrinos electrónicos, muones y neutrinos muónicos, leptones tau y neutrinos tauónicos) se mantiene. Este principio es conocido como la conservación del número leptónico. La conservación del número de leptones de diferente sabor (p.e. número electrónico o número muónico) algunas veces se puede violar (como en la oscilación de neutrinos). Una ley de conservación más fuerte es el número total de leptones de todos los sabores que es violada por una pequeña cantidad en el modelo estándar por las llamadas anomalías quirales.

Los acoples de los leptones a los bosones de gauge son independientes del sabor. Esta propiedad es llamada "universalidad leptónica" y ha sido probada en medidas de la vida media de tauones y muones, y en decaimientos parciales de bosones Z, particularmente en los experimentos de SLC y LEP.

Se nota que las masas de los neutrinos son conocidas, diferentes de cero, por la oscilación de neutrinos, pero sus masas son lo suficientemente ligeras que no se podían directamente medir hasta el 2007. Sin embargo tienen una medida (indirectamente basada en los periodos de oscilación) la diferencia del cuadrado de las masas entre los neutrinos que tienen que ser estimadas formula_1 y formula_2. Esto lleva a las siguientes conclusiones:
Los nombres "mu" y "tau" parecen que fueron seleccionados debido a su lugar en el alfabeto griego; mu es la séptima letra después de epsilon (electrón) y tau es la séptima después de mu.
μ y τ son versiones inestables del electrón. Cuando los leptones están cargados, estos interactúan con interacción electromagnética e interacción débil; no así los neutrinos que lo hacen solo en interacción débil.

La palabra "leptón" (del griego "leptos") fue usada por primera vez por el físico Léon Rosenfeld en 1948:

El nombre se origina de antes del descubrimiento en 1970 del pesado leptón tau, que es casi el doble de la masa de un protón.





</doc>
<doc id="1627" url="https://es.wikipedia.org/wiki?curid=1627" title="Licencia de documentación libre de GNU">
Licencia de documentación libre de GNU

La Licencia de documentación libre de GNU o GFDL ("GNU Free Documentation License") es una licencia copyleft para contenido libre, diseñada por la Fundación para el Software Libre (FSF) para el proyecto GNU. El texto completo puede consultarse en los enlaces externos.

Esta licencia, a diferencia de otras, asegura que el material licenciado bajo la misma esté disponible de forma completamente libre, pudiendo ser copiado, redistribuido, modificado e incluso vendido siempre y cuando el material se mantenga bajo los términos de esta misma licencia (GNU GFDL). En caso de venderse en una cantidad superior a 100 ejemplares, deberá distribuirse en un formato que garantice futuras ediciones (debiendo incluir para ello el texto o código fuente original).

Dicha licencia fue diseñada principalmente para manuales, libros de texto y otros materiales de referencia e institucionales que acompañaran al software "GNU". Sin embargo puede ser usada en cualquier trabajo basado en texto, sin que importe cuál sea su contenido. Por ejemplo, la enciclopedia gratuita en línea "Wikipedia" utiliza la "GFDL" (junto con la licencia Creative Commons Atribución Compartir Igual) para la totalidad de su texto.

El "FDL" fue presentada como borrador a finales del mes de septiembre de 1999 para conseguir comentarios. Después de revisiones, se publicó la versión 1.1 en marzo del año 2000, y la versión 1.2 en noviembre de 2002. La versión actual (2008) de la licencia es la 1.3.

El primer borrador de discusión de la "Licencia de Documentación Libre GNU versión 2" fue publicado el 26 de septiembre de 2006, con un borrador de la nueva "licencia de documentación libre GNU simplificada".

El nuevo borrador de la "GNU FDL" incluye varias mejoras, como nuevas condiciones elaboradas durante el proceso de la GPLv3 para mejorar la internacionalización, aclaraciones para ayudar a los usuarios en la aplicación de la licencia a audio y vídeo, y requisitos suavizados para usar extractos de un trabajo.

La nueva "Licencia de documentación libre simplificada" no tiene las exigencias de mantener portadas ni secciones invariantes. Esto proporcionará una opción de licencia más simple para los autores que no desean usar estas características de la "GNU FDL".

El 1 de diciembre de 2007, Jimmy Wales anunció que un largo período de discusión y negociación entre la "Fundación del Software Libre", "Creative Commons", la "Fundación Wikimedia" y otros han producido una propuesta, apoyada tanto por la "FSF" como por "Creative Commons", para modificar la "licencia de documentación libre" de tal manera que permita la posibilidad para la "Fundación Wikimedia" de migrar sus proyectos a CC-BY-SA.

La licencia GFDL distingue entre las secciones que componen el contenido mismo del documento, y otras secciones que tratan sobre el mismo documento.

Material con la versión actual de la licencia puede ser utilizado para cualquier propósito, siempre que el uso cumpla con ciertas condiciones:


La licencia explícitamente separa cualquier tipo de "documento" de "secciones secundarias", que no puede estar integrado con el documento, pero existen como materiales frontal o apéndices. Secciones secundarias pueden contener información con respecto a la relación del editor o autor de la materia, pero no cualquier asunto sujeto al mismo. Mientras que el documento en sí es completamente editable, y está cubierto esencialmente por una licencia equivalente a (pero mutuamente incompatibles con) la "licencia pública general de GNU", algunos de los secundarios tienen diversas restricciones diseñadas principalmente para hacer frente a las atribuciones propias de los autores anteriores.

En concreto, los autores de versiones anteriores tienen que ser reconocidos y ciertas "secciones invariantes" especificadas por el autor original y se trata de que su relación con el objeto de la materia no se puede cambiar. Si se modifica el material, el título tiene que ser cambiado (a menos que los autores anteriores dan permiso para retener el título).

La licencia también tiene disposiciones para la manipulación de la cubierta y el texto de la cubierta trasera de los libros, así como para, "dedicatorias" y las secciones de "historial", "agradecimientos", "aprobaciones". Estas características se han añadido en una parte para que la licencia sea más económicamente provechosa para los editores comerciales de la documentación del software, algunos de los cuales fueron consultados durante la redacción de la "GFDL". Las secciones de "aprobaciones" están destinadas a ser utilizadas en la norma oficial para documentos, en los que la distribución de versiones modificadas solo debe permitirse si no están etiquetados como una norma más.

La GFDL requiere que se asegure la "copia y distribución del documento en cualquier medio (óptico, mecánico, acústico o de cualquier otro tipo), sea no-comercial o comercial" y por lo tanto es incompatible con material que excluye un uso comercial. Como se mencionó anteriormente, la "GFDL" fue diseñada con los editores comerciales en mente, tal como explica Stallman:

El material que restringe la reutilización comercial es incompatible con la licencia y no puede ser incorporada en el trabajo. Sin embargo, la incorporación de este tipo de material puede ser restringido bajo la ley de derechos de autor uso justo de Estados Unidos (o trato justo en algunos otros países) y no es necesario tener una licencia para caer dentro de la "GFDL" si tal "uso justo" está cubierto por todos los usos posteriores potenciales. Un ejemplo de tal "uso justo" liberal y comercial es la parodia.

Aunque las dos licencias copyleft trabajan en principios similares, la licencia "GFDL" no es compatible con la licencia Creative Commons Atribución-Compartir Igual.

Sin embargo, a petición de la "Fundación Wikimedia", la versión 1.3 añade una sección limitada en el tiempo para permitir que determinados tipos de sitios web utilicen la "GFDL", ofrezcan además, su trabajo bajo la licencia "CC BY-SA". Estas excepciones permiten que un proyecto de colaboración basada en la "GFDL" con varios autores haga la transición a la licencia "CC BY-SA 3.0", sin obtener primero el permiso de cada autor, si la obra cumple una serie de condiciones:


Para evitar que la cláusula sea utilizada como una medida general de compatibilidad, el certificado solo permite que el cambio que se produzca antes del 1 de agosto de 2009. En el lanzamiento de la versión 1.3, la "FSF" afirmó que todo el contenido añadido antes del 1 de noviembre de 2008, para la "Wikipedia" como un ejemplo que cumplía los requisitos. La "Fundación Wikimedia" a sí mismo después de una consulta pública, para invocar a este proceso de doble licencia de contenido publicado bajo la licencia "GFDL" y bajo la licencia "CC BY-SA" en el mes de junio de 2009, y adoptó una política de atribución de todo el fundamento para el uso de los contenidos de los proyectos de la "Fundación Wikimedia".

Muchas personas y grupos consideran a GFDL como una licencia no libre, debido en parte al uso de texto "invariable" que no puede ser modificado o eliminado y la bien intencionada pero, para algunos, exagerada prohibición en contra de sistemas de gestión digital de derechos ("Digital Rights Management"), lo cual afecta también algunos usos válidos. Hasta el 16 de marzo de 2006 el proyecto Debian así lo consideraba, pero ya hace distinción explícita sobre la existencia de secciones invariables, que serían las que impedirían la inclusión de estos documentos en la sección "main" del proyecto.

La GFDL tiene la misma naturaleza viral de la licencia GPL, ya que las versiones modificadas quedan «contagiadas» con la misma licencia.

Ya que la licencia obliga a conservar una serie de textos, estos pueden resultar inconvenientes para ciertos usos. Por ejemplo, al editar un libro bajo la GFDL en papel, si su historial es muy largo, podría obligar a que buena parte de él fuera una lista de contribuciones. También crea incompatibilidades con otras licencias libres, como algunas versiones de las licencias Creative Commons. Los defensores de este tipo de licencia justifican esto por la necesidad de impedir que terceras partes modifiquen el documento, y se apropien de él.

En otro orden de críticas, el proyecto Debian, ha decidido que los documentos distribuidos bajo la Licencia de Documentación Libre de GNU (FDL) se consideran libres de acuerdo a las Directrices de software libre de Debian (DFSG) si no contienen secciones invariantes. Esta decisión suaviza la antigua interpretación de esta situación, que decía que toda la documentación publicada bajo la GNU FDL debía eliminarse del archivo. Ahora, parte de esta documentación puede mantenerse en el archivo.

La Fundación del Software Libre y el proyecto Debian están en conversaciones para solventar éstas y otras objeciones a la licencia en una nueva versión. Una alternativa para que los documentos GFDL puedan ser incluidos en las distribuciones Debian es que los autores acepten publicar sus documentos con dos licencias, la GPL y la GFDL.



</doc>
<doc id="1631" url="https://es.wikipedia.org/wiki?curid=1631" title="Lingüística">
Lingüística

La lingüística (del francés "linguistique"; este de "linguiste", «lingüista» y aquel del latín "lingua", «lengua») es el estudio científico del origen, la evolución y la estructura del lenguaje, a fin de deducir las leyes que rigen las lenguas (antiguas y modernas). Así, la lingüística estudia las estructuras fundamentales del lenguaje humano, sus variaciones a través de todas las familias de lenguas (las cuales también identifica y clasifica) y las condiciones que hacen posible la comprensión y la comunicación por medio de la lengua natural (esto último es particularmente cierto en el enfoque generativista).

Si bien la gramática es un estudio antiguo, el enfoque no tradicional de la lingüística moderna tiene varias fuentes. Una de las más importantes la constituyen los "Neogrammatiker, "que inauguraron la lingüística histórica e introdujeron la noción de ley en el contexto de la lingüística y que en particular formularon diversas leyes fonéticas para representar el cambio lingüístico. Otro punto importante son los términos de sincronía, diacronía y las nociones estructuralistas popularizadas por el trabajo de Ferdinand de Saussure y el "Cours de linguistique générale" (inspirado en sus lecciones). El siglo XX se considera, a partir del estructuralismo derivado de los trabajos de Saussure, el «punto de arranque» de la lingüística moderna. A partir de esa época parece haberse generalizado el uso de la palabra «lingüística» (la primera aparición de la palabra registrada es de 1883). La palabra «lingüista» se encuentra por primera vez en la página 1 del tomo I de la obra "Choix des poésies des troubadours", escrita en 1816 por Raynouard.

El objetivo de la lingüística teórica es la construcción de una teoría general de la estructura de las lenguas naturales y del sistema cognitivo que la hace posible, es decir, las representaciones mentales abstractas que hace un hablante y que le permiten hacer uso del lenguaje. El objetivo es describir las lenguas caracterizando el conocimiento tácito que de las mismas tienen los hablantes y determinar cómo estos las adquieren. Ha existido cierta discusión sobre si la lingüística debe considerarse una ciencia social o más bien parte de la psicología. En las ciencias sociales la conciencia de los participantes es parte esencial en el proceso, sin embargo, parece que ni en el cambio lingüístico, ni en la estructura de las lenguas la conciencia de los hablantes juegue ningún papel relevante. Aunque ciertamente en áreas incluidas normalmente dentro de la lingüística como la sociolingüística o la psicolingüística la conciencia del hablante sí tiene un papel, sin embargo, esas dos áreas no son el núcleo principal de la lingüística teórica sino disciplinas que estudian aspectos colaterales del uso del lenguaje.

El objetivo de la lingüística aplicada es el estudio de la adquisición del lenguaje y la aplicación del estudio científico de la lengua a una variedad de tareas básicas como la elaboración de métodos mejorados de enseñanza de idiomas. Existe un considerable debate sobre si la lingüística es una ciencia social, ya que sólo los seres humanos usan las lenguas, o una ciencia natural porque, aunque es usada por los seres humanos, la intención de los hablantes no desempeña un papel importante en la evolución histórica de las lenguas ya que usan las estructuras lingüísticas de manera inconsciente (esto es estudiado por F. de Saussure quien llega a la conclusión de que los cambios de una lengua se producen arbitrariamente por variaciones que el sujeto realiza y estos son involuntarios, y que la lengua varía en la historia y por eso plantea que el estudio de la lengua debe realizarse diacrónica y sincrónicamente. Saussure deja de lado la historia de las lenguas y las estudia sincrónicamente, en un momento dado del tiempo). En particular, Noam Chomsky señala que la lingüística debe ser considerada parte del ámbito de la ciencia cognitiva o la psicología humana, ya que la lingüística tiene más que ver con el funcionamiento del cerebro humano y su desarrollo evolutivo que con la organización social o las instituciones, que son el objeto de estudio de las ciencias sociales.

Para situar el ámbito o el objetivo de una investigación lingüística, el campo puede dividirse en la práctica según tres dicotomías importantes:

La ciencia que se ha constituido en torno de los hechos del lenguaje ha pasado por tres fases sucesivas antes de adoptar el enfoque moderno actual.

Se comenzó por organizar lo que se llamaba la gramática. Este estudio, inaugurado por los griegos y continuado especialmente por los franceses, estaba fundado en la lógica y desprovisto de toda visión científica y desinteresada de la lengua misma; lo que la gramática se proponía era únicamente dar reglas para distinguir las formas correctas de las formas incorrectas; se trataba de una disciplina normativa, muy alejada de la pura observación y su punto de vista era, por lo tanto, necesariamente reducido.

Después apareció la filología. Ya en Alejandría existía una escuela filológica, pero este término se asocia sobre todo con el movimiento científico creado por Friedrich August Wolf, a partir de 1777, que continúa hasta nuestros días. La lengua no es el único objeto de la filología que quiere sobre todo fijar, interpretar, comentar los textos. Este primer estudio lleva también a la historia literaria, de las costumbres, de las instituciones, etc.; en todas partes usa el método que le es propio, que es la crítica. Si aborda cuestiones lingüísticas, es sobre todo para comparar textos de diferentes épocas, para determinar la lengua particular de cada autor, para descifrar y explicar inscripciones redactadas en una lengua arcaica u oscura. Sin duda estas investigaciones son las que prepararon la lingüística histórica: los trabajos de Ritschl sobre Plauto pueden ya llamarse lingüísticos, pero, en ese terreno, la crítica filológica falla en un punto: en que se atiene demasiado servilmente a la lengua escrita, y olvida la lengua viva. Por lo demás, la antigüedad grecolatina es la que la absorbe casi por entero.

El tercer período comenzó cuando se descubrió que las lenguas podían compararse entre sí. Este fue el origen de la filología comparada o gramática comparativa. En 1816, en una obra titulada "Sistema de la conjugación del sánscrito", Franz Bopp estudió las relaciones que unen el sánscrito con el germánico, el griego, el latín, etc. y comprendió que las relaciones entre lenguas parientes podían convertirse en una ciencia autónoma. Pero esta escuela, con haber tenido el mérito indisputable de abrir un campo nuevo y fecundo, no llegó a constituir la verdadera ciencia lingüística. Nunca se preocupó por determinar la naturaleza de su objeto de estudio. Y sin tal operación elemental, una ciencia es incapaz de procurarse un método. (Fragmento del capítulo I "Ojeada a la historia de la lingüística" de la Introducción del "Curso de lingüística general". Ferdinand de Saussure)

La lingüística moderna tiene su comienzo en el siglo XIX con las actividades de los conocidos como neogramáticos que, gracias al descubrimiento del sánscrito, pudieron comparar las lenguas y reconstruir una supuesta lengua original, el idioma protoindoeuropeo. Esto animó a los lingüistas a crear una ciencia positiva en la que incluso se llegó a hablar de leyes fonéticas para el cambio lingüístico.

No será, sin embargo, hasta la publicación del "Curso de lingüística general" (1916), compuesto por apuntes que alumnos tomaron en el curso dictado por el suizo Ferdinand de Saussure, cuando se convierte la lingüística en una ciencia integrada a una disciplina más amplia, la semiología, que a su vez forma parte de la psicología social, y defina su objeto de estudio. La distinción entre lengua (el sistema) y habla (el uso) y la definición de signo lingüístico (significado y significante) han sido fundamentales para el desarrollo posterior de la nueva ciencia. Sin embargo, su perspectiva —conocida como "estructuralista" y que podemos calificar, por oposición a corrientes posteriores, como de corte empirista— será puesta en cuestión en el momento en que ya había dado la mayor parte de sus frutos y, por lo tanto, sus limitaciones quedaban más de relieve. 

Tras el estallido de la primera guerra mundial, la falta de comunicación entre continentes imposibilitó un trabajo lingüístico colaborativo y en consonancia con los mismos objetivos. Los lingüísticas y antropólogos norteamericanos decidieron entonces focalizarse en la realidad lingüística de las comunidades aborígenes locales ágrafas, cuyas lenguas estaban desapareciendo. Así, expertos como Bloomfield, Boas o Sapir, intentaron redefinir el enfoque sobre el lenguaje, orientado a su relación con el mundo; a esto denominaron "relativismo lingüístico".

En el siglo XX el lingüista estadounidense Noam Chomsky creó la corriente conocida como "generativismo". Con la idea de solventar las limitaciones explicativas de la perspectiva estructuralista, se produjo un desplazamiento del centro de atención que pasó de ser la lengua como sistema (la "langue" saussuriana) a la lengua como proceso de la mente del hablante, la capacidad innata (genética) para adquirir y usar una lengua, la "competencia". Toda propuesta de modelo lingüístico debe, pues —según la escuela generativista—, adecuarse al problema global del estudio de la mente humana, lo que lleva a buscar siempre el realismo mental de lo que se propone; por eso al generativismo se le ha descrito como una escuela mentalista o racionalista. En esta perspectiva la lingüística es considerada como una parte de la psicología o más exactamente la ciencia cognitiva.

Tanto la escuela chomskiana como la saussureana se plantean como objetivo la descripción y explicación de la lengua como un sistema autónomo, aislado. Chocan así —ambas por igual— con una escuela que toma fuerza a finales del siglo XX y que es conocida como "funcionalista". Por oposición a ella, las escuelas tradicionales chomskiana y saussuriana reciben conjuntamente el nombre de "formalistas". Los autores funcionalistas —algunos de los cuales proceden de la antropología o la sociología— consideran que el lenguaje no puede ser estudiado de forma autónoma descartando el "uso" del lenguaje. La figura más relevante dentro de esta corriente tal vez sea el lingüista holandés Simon C. Dik, autor del libro "Functional Grammar". Esta posición funcionalista acerca la lingüística al ámbito de lo social, dando importancia a la pragmática, al cambio y a la variación lingüística.

La escuela generativista y la funcionalista han configurado el panorama de la lingüística actual: de ellas y de sus mezclas arrancan prácticamente todas las corrientes de la lingüística contemporánea. Tanto el generativismo como el funcionalismo persiguen explicar la naturaleza del lenguaje, no solo la descripción de las estructuras lingüísticas.

Nos podemos aproximar al estudio de la lengua en sus diferentes niveles, por un lado, como sistema, atendiendo a las reglas que la configuran como código lingüístico, es decir, lo que tradicionalmente se conoce como gramática y, por otro lado, como instrumento para la interacción comunicativa, desde disciplinas como la pragmática y la lingüística textual.

Desde el punto de vista de la lengua como sistema, los niveles de indagación y formalización lingüísticas que convencionalmente se distinguen son:




Desde el punto de vista del habla, como acción, se destaca:

Dependiendo del enfoque, el método y los componentes de análisis varían, siendo distintos, por poner un ejemplo, para la escuela generativista y para la escuela funcionalista; por tanto no todos estos componentes son estudiados por ambas corrientes, sino que una se centra en algunos de ellos, y la otra en otros. Del estudio teórico del lenguaje se encarga la Lingüística general o teoría de la lingüística, que se ocupa de métodos de investigación y de cuestiones comunes a las diversas lenguas.

El tipo de problema considerado central y más importante en cada etapa del estudio de la lingüística moderna ha ido cambiando desde la lingüística histórica (nacida de los estudios de las etimologías y la filología comparativa) hasta el estudio de la estructura sintáctica, pasando por la dialectología, la sociolingüística. La siguiente lista enumera algunas de las principales escuelas en orden cronológico de aparición:



Se conocen alrededor de unas 6000 lenguas aunque el número de lenguas actualmente habladas es difícil de precisar debido a varios factores:

A pesar del elevado número de lenguas mutuamente ininteligibles, la lingüística histórica ha podido establecer que todas esas lenguas se pueden agrupar en un número mucho más reducido de familias de lenguas, derivando cada una de estas lenguas de una protolengua o lengua madre de la familia. Ese hecho sirve habitualmente de base para la clasificación filogenética de las lenguas del mundo. Además de ese tipo de clasificación, también se pueden hacer diversos tipos de clasificación tipológica, referidas al tipo de estructuras presentes en una lengua más que a su origen histórico o su parentesco con otras lenguas.


La distribución de las lenguas por continentes es muy desigual. Asia y África tienen cerca de 1900 lenguas cada uno, esto representa un 32% de la diversidad lingüística total del planeta. Por el contrario, Europa tiene sólo un 3% de las lenguas del planeta, siendo el continente con menor diversidad lingüística. En América existen alrededor de 900 lenguas indígenas (15% de las lenguas del planeta) y en Oceanía y las regiones adyacentes unas 1100 (18%).

La región lingüísticamente más diversa del planeta es Nueva Guinea y la menos diversa es Europa. En la primera región hasta el siglo XX no existió ninguna entidad estatal, mientras que en Europa la existencia desde antiguo de grandes estados, restringió la diversidad cultural, produciéndose un efecto uniformizador muy importante en cuanto a la diversidad lingüística.

Las lenguas del mundo presentan una gran dispersión en cuanto al número de hablantes. De hecho, unas pocas lenguas mayoritarias concentran la mayoría de hablantes de la población mundial. Así, las 20 lenguas más habladas, que suponen alrededor de un 0,3% de las lenguas del mundo, concentran casi el 50% de la población mundial, en número de hablantes; mientras que el 10% de las lenguas menos habladas apenas concentran al 0,10% de la población mundial. Y aunque el número medio de hablantes de una lengua terrestre está en torno a un millón, el 95,2% de las lenguas del mundo tienen menos de un millón de hablantes. Esto significa que las lenguas más habladas acumulan un número de hablantes desproporcionadamente alto y por eso la media anterior es engañosa respecto a la distribución. Las lenguas con pocos hablantes pueden estar en peligro de extinción, aunque no necesariamente, ya que el factor clave para la desaparición de una lengua suele ser la presencia de sustitución lingüística.





</doc>
<doc id="1632" url="https://es.wikipedia.org/wiki?curid=1632" title="Lenguaje">
Lenguaje

Un lenguaje (del provenzal "lenguatge" y del latín "lingua") es un sistema de comunicación estructurado para el que existe un contexto de uso y ciertos principios combinatorios formales. Existen contextos tanto naturales como artificiales. 

Desde un punto de vista más amplio, la comunicación indica una característica común a los humanos y a otros animales (animales no simbólicos) para expresar experiencias mediante el uso de señales y sonidos registrados por los órganos de los sentidos. Los seres humanos desarrollan un lenguaje simbólico complejo que se expresa con secuencias sonoras y signos gráficos. Por su parte, los animales se comunican a través de signos sonoros, olfativos y corporales que en muchos casos distan de ser sencillos.

Aunque casi hasta finales de se establecía taxativamente una diferencia absoluta entre el lenguaje humano y la comunicación animal, la acumulación de gran cantidad de estudios (especialmente etológicos)sugieren que muchos animales no humanos, especialmente con áreas cerebrales corticales muy o bastante desarrolladas (bonobos, chimpancés y otros primates, así como cetáceos -especialmente delfinidos-, aves -especialmente loros, cuervos, palomas, elefantes, perros, gatos, equinos etc.) poseen formas de comunicación bastante más complejas (y más cercanos al lenguaje humano) que el supuesto por Pávlov y los reflejos condicionados o los conductistas anglosajones que todo lo reducían las actividades psíquicas a un mero circuito reflejo mecanicista de "estímulo-respuesta". En rigor, Pávlov no era tan mecanicista, pero suponía al lenguaje de los animales no humanos como correspondiente a un "condicionamiento clásico" o "primer sistema de señales" (basado principalmente en el estímulo respuesta tras la reiteración de un estímulo que se asocia una «recompensa» [que implica al circuito de premio-recompensa] o a la ausencia de la misma que genera un hábito o "habitus", condicionamiento que es también común a la inmensa mayoría de los humanos) mientras que para el ser humano, Pávlov supone un "segundo sistema de señales" que es un salto cualitativo respecto al primero y que es el lenguaje humano que es heurístico al estar abierto respecto al ciclo de estímulo-respuesta.

La facultad del lenguaje no es el resultado de un aprendizaje, sino que es congénita, es decir, nace con el ser humano. Además, se presenta de igual manera en todos los seres humanos, independientemente del momento histórico y del lugar geográfico, es decir, es universal. Las lenguas pueden aprenderse y olvidarse, pero la capacidad del lenguaje no.

El lenguaje es un conjunto de signos y símbolos. Un signo es un fenómeno relacionable con otro fenómeno, por ejemplo la fiebre es un signo de una enfermedad, la caída de nieve es un signo de la estación de invierno, un camión de bomberos con su sirena es un signo de incendio. 

Un símbolo, es un fenómeno, algo que ocurre que nuestra mente relaciona con otro fenómeno, ejemplo un pulgar abajo simboliza algo negativo, la luz roja de un semáforo con un mensaje de detenerse. El elemento que distingue un símbolo de un signo es el carácter deliberativo de su relación.  Los signos que son establecidos deliberadamente se llaman símbolos.  

Varios autores han redactado listas de características definitorias de qué es una lengua natural, algunas de las cuales están presentes en la comunicación animal y los lenguajes formales. Sin embargo, sólo las lenguas naturales tienen estos quince rasgos de Hockett y, por tanto, esta lista caracteriza lo que es una lengua natural.

Entre los rasgos más definitorios están la arbitrariedad (de la relación entre el signo y el significado), la productividad (que permite producir nuevos mensajes nunca antes realizados) y la estructura jerárquica (según la cual, las lenguas humanas poseen reglas o principios sintácticos y gramaticales, por lo que las producciones no son aleatorias).

Las lenguas que concretan la facultad humana del lenguaje comparten una serie de características:


La conducta lingüística en los humanos no es de tipo instintivo, sino que debe ser adquirida por contacto o transmisión con otros seres humanos (especialmente durante los primeros años de vida de otro modo se producen casos de niños y niñas ferales). La estructura de las lenguas naturales, que son el resultado concreto de la capacidad humana de desarrollar lenguaje, permite comunicar ideas y emociones por medio de un sistema de sonidos articulados, de trazos escritos y/o de signos convencionales, mediante los cuales se hace posible la relación y el entendimiento entre individuos. El lenguaje humano posibilita la expresión del pensamiento y la exteriorización de los deseos y afectos mediante signos inicialmente sonoros/acústicos y -muy posteriormente en la genealogía del lenguaje- que son signos basados en el par significante/significado (notar que a inicios de s. XX F. de Saussure consideraba biyectivos o perfectamente correspondientes al par Ste (significante) / sdo. (significado) y que luego J. Lacan ha considerado que bajo el Significante «"hay nada"» ya que el significado de cada signo humano discurre («bajo» la censura de lo inconsciente) tras el deseo en una "cadena metonímica" en la cual los significantes constantemente cambian de significado; Lacan ha considerado que la relación biyectiva o exactamente correspondiente de Ste./sdo. solo se da en el lenguaje de los animales no humanos.

El lenguaje humano ha sido calificado como un lenguaje principalmente verbal o lenguaje verbal en contraposición a la comunicación no verbal. El lenguaje verbal se denomina así porque está constituido por palabras (en latín: "verba") es decir, formado a partir de unidades discretas ordenadas (por ejemplo los fonemas) desde el intelecto tal cual se observa en un diálogo o en una conversación en tal caso según el esquema de R. Jakobson requiere de un emisor (o locutor) al menos un mensaje, un contexto, un canal o medium (aire por donde se propala la voz, papel donde se escribe, ondas electromagnéticas etc.) un código (fonemas seleccionados [principalmente en un idioma ], grafemas, signos etc.) y obviamente un receptor o alocutor (a este esquema de Jakobson, que parece tener sus orígenes en los esquemas triangulares de Peirce, se le suele añadir el "ruido" que puede modificar el esquema). Paralelo al lenguaje verbal (y existente ya en animales no humanos) se debe siempre tener en cuenta al lenguaje paraverbal caracterizado por la mímica, los gestos, las muecas e incluso las expresiones corporales (especialmente faciales) de origen instintivo (por ejemplo la casi vegetativa e instintiva expresión facial de asco puede mímicamente transformarse en expresión ya intencionada de disgusto o cólera) .

La capacidad humana para el lenguaje, tal como se refleja en las lenguas naturales, es estudiada por la lingüística. Se considera que la progresión de las lenguas naturales va desde el habla, luego por la escritura y, finalmente, se instala una comprensión y explicación de la gramática. Desde el punto de vista social e histórico, el lenguaje humano ha dado lugar a idiomas que viven, mueren, se mudan de un lugar a otro, y cambian con el paso del tiempo. Cualquier idioma que deja de cambiar o de desarrollarse es categorizado como lengua muerta. Por el contrario, cualquier idioma por el hecho de no ser una lengua muerta, y formar parte de las lenguas vivas o modernas, está sufriendo continuamente reajustes que acumulativamente son los responsables del llamado cambio lingüístico, el lenguaje humano se suele subdividir a partir de F. de Sausurre en habla y lengua, en todo caso en ambas dimensiones del lenguaje siempre han de considerarse la sincronía (que puede definirse como el uso contemporáneo [del locutor al alocutor] del lenguaje humano) y de la diacronía (que puede definirse como la casi continua modificación del lenguaje humano evolucionando a lo "largo" del tiempo).

Hacer una distinción en principio entre un idioma y otro es por lo general imposible. Por ejemplo, hay algunos dialectos del alemán que son similares a ciertos dialectos del neerlandés. La transición entre las lenguas dentro de la misma familia lingüística a veces es progresiva (ver dialecto continuo).

Hay quienes hacen un paralelismo con la biología, donde no es posible hacer una distinción bien definida entre una especie y la siguiente. En cualquier caso, el desafío real puede ser el resultado de la interacción entre las lenguas y las poblaciones (ver dialecto o August Schleicher). Los conceptos de "Ausbausprache, Abstandsprache y Dachsprache" se utilizan para hacer distinciones más refinadas sobre los grados de diferencia entre las lenguas o dialectos.<br>
Al parecer en el lenguaje humano es fundamental la posibilidad de la metáfora (substituir una imagen -especialmente una imagen acústica- por otra merced a una semejanza aunque no haya relación de contigüidad) tal cual lo demuestra Roman Jakobson al estudiar las afasias usando los criterios de sintagma y metonimia establecidos por Ferdinand de Saussure: unas afasias serían metonímicas o sintagmáticas y otras serían metafóricas o paradigmáticas; Jakobson observa la coalescencia entre esto y la tesis propuesta por Sigmund Freud de "deslizamiento" y "condensación" en la actividad onírica, respectivamente y Lacan en sus estudios parece comprobarlo al considerar que lo inconsciente está estructurado como un lenguaje, donde una metáfora paterna es fundamental para establecer al sujeto desalienado de la máscara o persona que es el imaginario ego, a partir de esto según estas opiniones es que el Homo sapiens está capacitado para tener un principio de realidad y un lenguaje articulado coherente y altamente heurístico en una «cadena metonímica». En cambio, según Lacan, los animales no humanos existentes se encuentran restringidos a lo imaginario aunque lo imaginario -y por ende el lenguaje- de los animales no humanos, según Lacan, se corresponden con lo real en lugar del apego a la en parte ficcional o eidética realidad en que se desempeña el animal humano; esto es: los animales inteligentes no humanos parece que tienen lenguajes aparentemente no articulados que se corresponden con lo fáctico del ambiente en que viven mientras que los humanos al oscilar entre los registros de lo Imaginario y lo Real a través del registro de lo Simbólico (o lenguaje simbólico humano) puede caer en fantasías sin embargo las fantasías le permiten ingenio y una alta capacidad de adaptación evolutiva mediante la inventiva que tiene por principal medio precisamente al lenguaje simbólico.

Por otra parte Chomsky ha teorizado que la estructura del lenguaje humano se basa en sintagmas verbales y sintagmas nominales; luego según el mismo Noam Chomsky (2015) el lenguaje humano es principalmente genético; los niños (cualquiera sea su sexo) poseen la capacidad innata del lenguaje verbal sin previa información externa (que no esté) ya en el genoma humano, por ejemplo a los 2 años de nacido, un infante puede aprender una nueva palabra durante cada hora de vigilia, tal capacidad habría surgido hace 70 mil años; en todo caso para lograr plena competencia lingüística (más allá de las opiniones de Chomsky) el ser humano debe estar bien nutrido por lo menos en el primer año de su vida (alimentado principalmente con proteínas) y estimulado de un modo dialógico por otros humanos en sus primeros 4 años de vida. Tener en cuenta que el pensar consciente humano está principalmente constituido por conceptos y que los conceptos son parte del lenguaje.

Hay una inmensidad de definiciones sobre qué es el lenguaje humano, dependiendo de cada autor en cada época y en cada circunstancia.
La siguiente es una selección de varias de las definiciones que se le ha dado al lenguaje:

El lenguaje humano se debe a adaptaciones evolutivas que se dan exclusivamente en seres humanos de la especie "Homo sapiens."

En los últimos años, diversas investigaciones han apuntado a que el lenguaje humano, respecto a su parte melódica y la estructuración de fonemas, tiene un origen evolutivo común con el lenguaje de los pájaros; incluso, se ha llegado a constatar que los mismos genes que posibilitan el habla humana posibilitan también el canto de las aves. Un total de 55 genes muestran un patrón similar en la actividad del cerebro de los seres humanos y de aquellas aves capaces de aprender nuevas vocalizaciones y de reordenar los sonidos más básicos de su canto para transmitir distintos significados. Sin embargo, la parte pragmática (que es la portadora del contenido del discurso) de nuestro lenguaje habría derivado de nuestros ancestros primates no humanos; y ambas capacidades (melódica y pragmática) se habrían fundido en algún momento de los últimos 100.000 años de evolución, o, según algunos últimos experimentos desde al menos los antepasados comunes entre los actuales babuinos y seres humanos. Esto es quizás hasta 7 u 8 millones de años antes del presente. La gran diferencia estriba en que la rama que dio lugar a los actuales "Homo sapiens" tendría —por selección natural— aún más desarrolladas las áreas del cerebro (ubicadas principalmente en el hemisferio izquierdo) que los actuales babuinos,es decir: un hallazgo sugiere que el último antepasado común de los seres humanos y los babuinos pudo haber poseído la maquinaria vocal para el habla para dar lugar a la forma del lenguaje humano, y con ello al origen de las diferentes lenguas (idiomas) que han sido creados por los seres humanos.
El curso del desarrollo del lenguaje tiene por lo menos dos consecuencias determinadas:

El lenguaje humano es asombrosamente flexible. Podemos combinar un número limitado de sonidos y señales para producir un número infinito de frases, cada una con un significado distinto. Por ello podemos absorber, almacenar y comunicar una cantidad de información prodigiosa acerca del mundo que nos rodea. No obstante, la característica realmente única de nuestro lenguaje es la capacidad de transmitir información acerca de cosas que no existen. Solo los sapiens pueden hablar acerca de tipos enteros de entidades que nunca han visto, ni tocado, ni olido. Las leyendas, los mitos, los dioses y las religiones son producto de «la revolución cognitiva» y el lenguaje humano.

La neurolingüística es el área disciplinar dependiente de la neuroanatomía que se preocupa por la computación cerebral del lenguaje humano. Las principales áreas del cerebro que se encargan de procesar el lenguaje son áreas corticales del hemisferio izquierdo del cerebro:

Sin embargo, aunque normalmente el lenguaje se procesa en el Hemisferio izquierdo, esto se debe solo por la estructura física que compone el lenguaje, y no porque «el lenguaje en sí» le sea propio. Ello ya que se ha demostrado que para el silbido turco (un tipo de Lenguaje silbado; basado en la forma silbada del Idioma turco), requiere el uso de los dos hemisferios cerebrales por igual, debido a que la melodía, la frecuencia y el tono, los rasgos del silbido, se procesan en el hemisferio derecho.

Alteraciones de lenguaje:

Aunque existen otros códigos de comunicación, el lenguaje verbal es el único sistema comunicativo capaz de expresar debidamente aquello que se quiere transmitir y el único que permite elaborar infinitos mensajes. Esta circunstancia es posible por la doble articulación del lenguaje.

Depende del sentido del olfato y en algunas ocasiones del gusto. Estas señales pueden recorrer grandes distancias cuando son transportadas por las corrientes del aire, aunque sólo son percibidas a favor del viento. Las sustancias químicas específicas que producen efectos concretos se llaman feromonas. En las colonias de abejas, por ejemplo, la reina produce una feromona «real» que impide el desarrollo de los ovarios de las obreras. Las feromonas tienen una gran importancia en lo relativo a la atracción sexual.

Las ondas sonoras pueden variar de altura e intensidad con rapidez. Sirven para transmitir mucha información. Estas señales viajan en todas direcciones y el receptor las localiza con facilidad.

Por ejemplo, los monos aulladores y algunas aves, ranas y sapos poseen grandes sacos vocales que aumentan considerablemente los sonidos que emiten. En el caso de los sapos, emiten un sonido para atraer a la hembra y otro para «avisar» a otros que él también es macho. Las cigarras que cantan son machos, y lo hacen para atraer a las hembras. Los pollitos emiten sonidos de distinta intensidad en donde avisan a la gallina en distintas situaciones (si están asustados o si tienen hambre o frío). Los cocodrilos, cuando están por nacer, emiten sonidos con lo que avisan a su madre y ella destapa el nido subterráneo para que los pequeños puedan subir a la superficie.

Muchos animales diferentes usan estas señales, que se pueden encender y apagar en un instante, aunque por lo general son útiles en determinadas horas del día. Suelen ser llamativas o consistir en movimientos bruscos. Por ejemplo, una de las garras del cangrejo violinista macho es mayor que la otra, tiene colores fuertes y la sacude para atraer a las hembras. Los colores y diseños de las alas de las mariposas y de los machos de muchas aves atraen a sus compañeras en distancias cortas. Cuando vuelan por la noche, los lampíridos machos producen destellos luminosos con señales características, mientras que las hembras responden con sus destellos desde el suelo.

La comunicación táctil se refiere a las señales transmitidas a través del contacto de la piel o partes exteriores de los seres vivos. Estas señales sirven al alcance de la mano y tienen una gran importancia entre los primates, como una forma de indicación de amistad y para tranquilizar. El hecho de que un individuo cuide al otro, por ejemplo eliminándole los parásitos indeseables, es su manera de reforzar los lazos familiares y de amistad. Los mecanismos principales son:


Todos los lenguajes buscan transmitir algo a partir de un símbolo determinado y de manera deliberada partiendo del hombre; en todos los tipos de lenguaje se necesitan los elementos básicos de la comunicación (emisor, mensaje y receptor) para que pueda llevarse a cabo su objetivo y se construye gracias a los signos.Se clasifican en: 

Actualmente existen también otros tipos de lenguaje como el gráfico que comunica el mensaje por medio de imágenes (fotografías, dibujos e iconos); el audiovisual que combina las imágenes con los sonidos; y el multimedia que utiliza todos los medios que necesite.

El lenguaje puede ser estudiado según cuatro dimensiones o aspectos diferentes que definen características propias de su naturaleza:

Las personas se comunican por distintos motivos: en algunas ocasiones, solo pretenden transmitir información de manera objetiva; en otras, manifiestan sentimientos u opiniones, o pretenden influir en los demás.

Las diversas finalidades comunicativas pueden sistematizarse, teniendo en cuenta los elementos de la comunicación, en las funciones del lenguaje.

En un mismo enunciado pueden coexistir varias funciones, pero siempre hay un predominante. En "¡Siéntate de una vez!", aunque prevalece la función apelativa, también está presente la función expresiva, ya que el emisor manifiesta su fastidio. Este predominio se evidencia en la presencia de determinados rasgos lingüísticos, como el modo imperativo y el vocativo.

El lenguaje se usa para trasmitir una realidad, ya sea afirmativa, negativa o de posibilidad, un deseo, una pregunta, una orden y más. Dependiendo de cómo utilicemos las oraciones, podemos distinguir diferentes funciones en el lenguaje:



Siempre se debe considerar al lenguaje como un subconjunto de la información, por ejemplo en tal caso Léon Brillouin publicó en 1959 "Science et théorie de l'information" (versión en inglés editada por vez primera en 1962) donde son examinadas las relaciones entre estas dos disciplinas. Adopta particularmente un punto de vista de físico y hace el lazo entre la entropía informacional de Shannon y la entropía estadística de Boltzmann en donde se arriesga que la información (y con la misma el lenguaje) es un factor neguentrópico es decir por el cual se puede anular la entropía.





</doc>
<doc id="1634" url="https://es.wikipedia.org/wiki?curid=1634" title="León (desambiguación)">
León (desambiguación)

León hace referencia a varios artículos:


















</doc>
<doc id="1640" url="https://es.wikipedia.org/wiki?curid=1640" title="Lima">
Lima

Lima es la capital y la ciudad más poblada de la República del Perú. Se encuentra situada en la costa central del país, a orillas del océano Pacífico, conformando una extensa y poblada área urbana conocido como Lima Metropolitana de 70 km norte a sur, desde el distrito de Ancón hasta el distrito de Pucusana y 44 km este a oeste, desde el distrito de La Punta hasta Chosica (distrito de Lurigancho-Chosica), flanqueada por el desierto costero y extendida sobre los valles de los ríos Río Chillón, Rímac y Río Lurín. Según datos oficiales del INEI de 2020, la ciudad de Lima cuenta con más de 9,5 millones de habitantes,
mientras que Lima Metropolitana bordea los 11 millones de habitantes (el 32% de la población peruana), cifras que la convierten en la ciudad más poblada del país.

El 18 de enero de 1535, se efectuó la fundación de la ciudad con el nombre de la Ciudad de los Reyes por el conquistador español Francisco Pizarro dentro de la región agrícola conocida por los como "Lima", nombre que adquirió con el tiempo. Fue la capital del Virreinato del Perú por sus valles y bajo nivel del mar en reemplazo de Jauja que se encontraba en las alturas de los Andes, el virreinato en su momento, fungió como la entidad administrativa más relevante de la Monarquía Hispánica dentro de América del Sur, mientras que Lima a su vez fue la ciudad más grande e importante en la América Austral durante todo el periodo colonial. Después el proceso de Independencia pasó a ser la capital del los Departamentos Libres y posteriormente de la República Peruana. También fue capital del Estado Nor-Peruano además de que fue inicialmente la capital de la Confederación Perú-Boliviana.

Lima es la sede de una de las instituciones más antiguas de educación superior en el Nuevo Mundo. La Universidad Nacional de San Marcos, fundada el 12 de mayo de 1551, durante el régimen virreinal español, es la universidad más antigua en funcionamiento continuo en América.

Lima metropolitana está dividido en 50 distritos en total, donde la provincia de Lima cuenta con 43 distritos y la provincia constitucional del Callao con 7 distritos, ambas provincias cuentan con autonomía regional desde el año 2002. También esta organizado en conos o ejes de la ciudad: Cono Norte, Cono Sur, Cono Este, Cercado y el Callao.

En la actualidad está considerada como el centro político, económico, Industrial, cultural, financiero y comercial del país. En el plano internacional, actualmente es la quinta ciudad más grande de América Latina, por PBI y la quinta por , la ciudad más grande del Pacífico sudamericano, la tercera de Hispanoamérica, además la ciudad ocupa el cuarto lugar dentro de las y es una de las treinta . Por su importancia geoestratégica, ha sido definida como una ciudad global de «clase beta+».

En octubre de 2013, Lima fue elegida para albergar los Juegos Panamericanos 2019. También fue sede de la Conferencia de las Naciones Unidas sobre el Cambio Climático de diciembre de 2014, sede en 2008 y en 2016 del foro mundial APEC, del concurso Miss Universo 1982 y esta programado para ser sede de la Copa Mundial de Fútbol Sub-17 de 2021.

El actual valle del río Rímac recibía el nombre de "Rimaq" (pronunciado según la pronunciación del lambdacismo del quechua costeño y como en las variantes de la sierra) como referencia a la construcción que hoy día se conoce como "huaca de Santa Ana" («"guaca de los indios de Lima que se dezían ychmas, era una piedra redonda"». Como en otros topónimos, la oclusiva final terminó por eliminarse al pasar al idioma español, prefiriéndose con el tiempo la grafía "Lima" tras coexistir en documentos con las formas "Limac" y "Lyma".

En el origen de este topónimo, como sucedió con otros muchos en el Nuevo Mundo, es muy probable que los españoles aceptasen con facilidad el que ya empleaban las comunidades aborígenes, mutándolo por otro de sonoridad muy similar extraído de la geografía ibérica. En este caso pudieron aplicar el del río Limia, transfronterizo entre Portugal y España, cuyo nombre portugués es río Lima.

Al ser fundada el 18 de enero, se le dio el nombre de "Ciudad de los Reyes" por la proximidad de la fecha con el 6 de enero, día de los Reyes Magos y tal vez también como homenaje a los : Juana I y Carlos I. Sin embargo, siempre se mantuvo el nombre toponímico de la región, que poco a poco fue consolidándose sobre el nombre fundacional, motivo por el cual el nuevo centro poblado terminó por conocerse como la ciudad de Lima. El nombre del río, en cambio, vio alterada su grafía según los usos del Tercer Concilio Limense influido por hábitos de pronunciación aimara, al igual que ocurrió con otros muchos topónimos de origen quechua.

Históricamente, se le conoce como «Estandarte de la Ciudad de los Reyes del Perú». Está formada por un lienzo de seda color gualda y en el centro se encuentra el escudo de armas de la ciudad bordado.
El escudo de armas de Lima fue otorgado por la Corona Española el 7 de diciembre de 1537 mediante Real Cédula firmada en Valladolid por el Emperador Carlos V y su madre la Reina Juana I de Castilla, dotando a la ciudad de ostentar el escudo. Está formado por un campo principal azur, con tres coronas de oro de reyes puestas en triángulo y encima de ellas una estrella de oro que toca con sus puntas las tres coronas, y por orla unas letras de oro que dicen: "Hoc signum vere regum est" ("Este es el verdadero signo de los reyes"). Exterior al escudo se sitúan las iniciales I y K ("Ioana" y "Karolus)", que son los nombres de la reina Juana I y su hijo Carlos I. Sobre las letras se sitúa una estrella y abrazándolas dos águilas afrontadas de sable coronadas, que sujetan el escudo.
El himno de Lima fue escuchado por primera vez el 18 de enero de 2008, en una sesión solemne que contó con la presencia del entonces Presidente del Perú Alan García, el Luis Castañeda Lossio y diversas autoridades. Los encargados de la creación del himno fueron los regidores Luis Enrique Tord (autor de la letra), Euding Maeshiro (compositor de la melodía) y el productor musical Ricardo Núñez (arreglista).

Aunque la historia de la ciudad de Lima se inició con su fundación española en 1535, el territorio conformado por los valles de los ríos Rímac, Chillón y Lurín estaba ocupado por asentamientos preincaicos, los cuales estaban agrupados bajo el señorío de Ichma. La cultura Maranga y la cultura Lima fueron las que se establecieron y forjaron una identidad en estos territorios. Durante esas épocas se construyeron los santuarios de Lati (actual Puruchuco) y Pachacámac (el principal santuario de peregrinación durante la época de los incas).

Estas culturas fueron conquistadas por el imperio Wari durante el apogeo de su expansión imperial. Es durante esta época que se construyó el centro ceremonial de Cajamarquilla. Ante la declinación de la importancia Wari, las culturas locales volvieron a adquirir autonomía, destacando la cultura Chancay. Posteriormente, en el siglo XV, estos territorios fueron incorporados al imperio incaico. De esta época podemos encontrar gran variedad de huacas a lo largo de toda la ciudad, algunas de las cuales se encuentran en investigación.

Las más importantes o conocidas son las de Huallamarca, Pucllana y Mateo Salado, todas ubicadas en medio de distritos limeños con un crecimiento urbano muy alto, por lo que se encuentran rodeadas de edificios empresariales y residenciales; sin embargo, eso no obstaculiza su perfecto estado de conservación. A las afueras de la ciudad se encuentran las ruinas de Pachacámac, un importante centro religioso construido por la cultura Lima hace 3000 años y que fue utilizado incluso hasta la época en que arribaron los conquistadores españoles.

En 1532, los españoles y sus aliados indígenas (de las etnias sometidas por los Incas) bajo el mando de Francisco Pizarro tomaron prisionero a Atahualpa en la ciudad de Cajamarca. Aunque se pagó un rescate, fue condenado a muerte por razones políticas y estratégicas. Tras algunas batallas, los españoles conquistaron su imperio. La corona española nombró a Francisco Pizarro gobernador de las tierras que había conquistado. Pizarro decidió fundar la capital en el valle del río Rímac, luego del intento fallido de constituirla en Jauja.

Consideró que Lima estaba estratégicamente ubicada, próxima a una costa favorable para la construcción de un puerto pero prudencialmente alejada del mismo como para prevenir ataques de piratas y potencias extranjeras, sobre tierras fértiles y con un conveniente clima fresco. Así, el 18 de enero de 1535 se fundó Lima con el nombre de "Ciudad de los Reyes", denominada de esta forma en honor a la epifanía, sobre territorios que habían sido del curaca Taulichusco. La explicación de este nombre se debe a que «por las mismas fechas de enero estaban los españoles buscando el lugar para la fundación del emplazamiento de la nueva ciudad, [...] no lejos del santuario de Pachacámac, cerca del río Rímac.

Con todo, al igual que había sucedido con la región, en un principio llamada Nueva Castilla y después Perú, la Ciudad de los Reyes perdió pronto su nombre en favor de Lima». Pizarro, con la colaboración de Nicolás de Ribera, Diego de Agüero y Francisco Quintero trazaron personalmente la Plaza de Armas y el resto de la cuadrícula de la ciudad, construyendo el Palacio Virreinal (hoy día transformado en el Palacio de Gobierno del Perú, que de ahí conserva el nombre tradicional de "Casa de Pizarro") y la Catedral, cuya primera piedra puso Pizarro con sus propias manos. En agosto de 1536, la floreciente ciudad fue sitiada por las tropas de Manco Cápac II, pero los españoles y sus aliados indígenas consiguieron derrotarlas. En los siguientes años Lima ganó prestigio al ser designada capital del Virreinato del Perú y sede de una Real Audiencia en 1543.

Durante el siguiente siglo, prosperó como el centro de una extensa red comercial que integraba al virreinato con América, Europa y Asia Oriental. Pero la ciudad no estuvo libre de peligros; violentos terremotos destruyeron gran parte de ella entre 1586 y 1687, lo que va a suscitar un gran despliegue de actividad constructiva. Es entonces que aparecen acueductos, tajamares y muros de contención ante la crecida de los ríos, se termina el puente sobre el Rímac, se construye la Catedral (acabada en 1622) y se construyen numerosos hospitales, conventos y monasterios. Entonces podemos ver que la ciudad se articula en torno a sus barrios. Otra amenaza fue la presencia de piratas y corsarios en el océano Pacífico, lo cual motivó la construcción de las murallas de Lima entre los años 1684 y 1687.

El terremoto de 1687 marcó un punto de inflexión en la historia de Lima, ya que coincidió con una recesión en el comercio por la competencia económica con otras ciudades como Buenos Aires. Con la creación del Virreinato de Nueva Granada en 1717 se organizaron nuevamente las demarcaciones políticas, y Lima no perdió sino unos territorios que en realidad disfrutaban ya de su autonomía. En 1746 un fuerte terremoto dañó severamente a la ciudad y destruyó el Callao, obligando a un esfuerzo de reconstrucción masivo por el virrey José Antonio Manso de Velasco.

En la segunda mitad del siglo XVIII, las ideas de la ilustración acerca de la salud pública y el control social influyeron en el desarrollo de la ciudad. Durante este periodo, la capital peruana resultó afectada por las reformas borbónicas ya que perdió su monopolio sobre el comercio exterior y su control sobre la importante región minera del Alto Perú. Este debilitamiento económico llevó a la élite de la ciudad a depender de los cargos otorgados por el gobierno virreinal y la Iglesia, lo que contribuyó a mantenerlos más vinculados a la Corona que a la causa de la independencia.

El mayor impacto político-económico que vivió la ciudad en aquel entonces se produjo con la creación del Virreinato del Río de la Plata en 1776, que cambió el rumbo y las orientaciones que imponía el nuevo tráfico mercantil. Una expedición combinada de independentistas argentinos y chilenos dirigidos por el general Don José de San Martín desembarcó en el sur de Lima en 1820, pero no atacaron la ciudad. Enfrentado a un bloqueo naval y a la acción de las guerrillas en tierra firme, el virrey José de la Serna se vio forzado a evacuar la ciudad en julio de 1821 para salvar al ejército realista. Temiendo un levantamiento popular y careciendo de medios para imponer el orden, el Consejo de la Ciudad invitó a San Martín a entrar en la ciudad, firmando una Declaración de Independencia a su solicitud. Sin embargo, la guerra no había terminado y en los siguientes dos años la ciudad cambió de manos muchas veces, sufriendo abusos de ambos bandos.

Proclamada la independencia del Perú en 1821 por el general San Martín, Lima se convirtió en la capital de la flamante República del Perú. Así, fue la sede del gobierno del libertador y sede también del primer Congreso Constituyente que tuvo el país. Los primeros años de la historia republicana peruana se caracterizaron por el constante enfrentamiento entre caudillos militares, que tenían como objetivo gobernar el país y para lo cual intentaban tomar la sede de gobierno.

Así, Lima sufrió varios asedios y enfrentamientos armados en sus calles. Desde el punto de vista urbanístico, el constante crecimiento que experimentó la ciudad dio lugar a un fenómeno de modernización. En 1862 se dio inicio al proceso de cambio en la nomenclatura urbana de la ciudad y en 1868, por disposición del presidente José Balta, se dispuso la demolición de las murallas que la circundaban, dando paso a las primeras grandes avenidas.

Por causa de la Guerra del Pacífico, entre 1881 y 1883 Lima fue ocupada por fuerzas chilenas; luego de la retirada del Ejército de Chile, se inició un proceso de reconstrucción, que se vio limitado debido a los enfrentamientos entre Andrés Avelino Cáceres y Nicolás de Piérola. En los últimos años del siglo XIX, con Piérola asumiendo el poder y el inicio de lo que se denominó la República Aristocrática, comenzó su verdadera e intensa reconstrucción que duró hasta las remodelaciones que Augusto Leguía realizó como preparación para el centenario de la independencia en 1921. A inicios del siglo XX se inició la construcción de avenidas que sirvieran como una matriz para el desarrollo de la ciudad. Se tendieron las avenidas Paseo de la República, Leguía (hoy llamada Arequipa), Brasil y la paisajística Salaverry que se dirigían hacia el sur y las avenidas Venezuela y Colonial hacia el oeste uniéndose con el puerto del Callao.

En los años 1930 se iniciaron las grandes construcciones con la remodelación del Palacio de Gobierno y la Casa Municipal. Estas construcciones tuvieron su punto máximo en los años 1950, durante el gobierno de Manuel A. Odría cuando se construyeron los grandes edificios del Ministerio de Economía y del Ministerio de Educación (Edificio Javier Alzamora Valdez actual sede la Corte Superior de Justicia de Lima), el Ministerio de Salud, el Ministerio de Trabajo y los Hospitales del Seguro Obrero y del Empleado así como el Estadio Nacional y varias grandes unidades habitacionales.

También en esos años se dio inicio a un fenómeno que cambió la configuración de la ciudad, el cual fue la masiva inmigración de pobladores del interior del país produciendo el crecimiento exponencial de la población capitalina y la consecuente expansión urbana. Las nuevas poblaciones fueron asentándose en terrenos cercanos al centro los cuales se utilizaban como zona agrícola. Se fueron poblando los actuales distritos de Lince, La Victoria hacia el sur; Breña y Pueblo Libre hacia el oeste; El Agustino, Ate y San Juan de Lurigancho hacia el este y San Martín de Porres y Comas al norte.

Como punto emblemático de esa expansión, en 1973 se creó la comunidad autogestionaria de Villa el Salvador (actual distrito de Villa El Salvador) ubicada a 30 km al sur del centro de la ciudad y actualmente integrada al área metropolitana. En los años 1980, la violencia terrorista sumó al desordenado crecimiento de la ciudad el aumento de pobladores que llegaban como desplazados internos. El centro histórico de la ciudad sufrió un creciente deterioro y muchas zonas de la ciudad carecieron constantemente de los servicios básicos.

Lima se encuentra en el desierto costero del Perú, en la falda de la vertiente occidental de los andes centrales del Perú. Aunque fue inicialmente fundada sobre el valle del río Rímac, hoy se extiende sobre extensas zonas desérticas e incluso sobre otros valles.

Bordea el litoral desde el km 50 de la Panamericana Norte, en el límite del distrito de Ancón con la provincia de Huaral; hasta el km 70 de la Panamericana Sur, en el límite del distrito de Pucusana con la provincia de Cañete; que suman una extensión de poco más de 130 km de costa y playa. Hacia el este se extiende aproximadamente hasta el km 37 de la carretera Central, en el límite del distrito de Lurigancho-Chosica con la provincia de Huarochiri.

El clima de la ciudad resulta especialmente particular dada su situación. Combina una ausencia casi total de precipitaciones, con un altísimo nivel de humedad atmosférica y persistente cobertura nubosa. Así, sorprende por sus extrañas características a pesar de estar ubicada en una zona tropical a 12 grados latitud sur y casi al nivel del mar. La costa central peruana, muestra una serie de microclimas atípicos debido a la influyente y fría corriente de Humboldt que se deriva de la Antártida, la cercanía de la cordillera de los Andes y su ubicación geográfica, dándole a Lima un clima subtropical, fresco, desértico y húmedo a la vez.

Se puede decir, que tiene un clima tibio sin excesivo calor tropical ni fríos extremos que requieran tener calefacción en casa, a excepción de muy pocos inviernos. La temperatura promedio anual es de 17,5 a 19 °C, con un máximo estival anual de unos 29 °C. Los veranos, de diciembre a abril, tienen temperaturas que oscilan entre los 29 a 30 °C durante el día y 21 a 22 °C en las noches. Solamente cuando ocurre el Fenómeno del Niño, la temperatura en la estación de verano puede superar los 31 °C. Los inviernos van de junio a mediados de septiembre, con temperaturas que oscilan entre los 19 y 12 °C, siendo 8,8 °C la temperatura más baja comprobada históricamente. Los meses de primavera y otoño (septiembre, octubre y mayo), tienen temperaturas templadas que oscilan entre los 23 y 17 °C.

Por otro lado, la humedad relativa es sumamente alta (hasta el 100%), produciendo neblina persistente de junio a diciembre hasta la entrada del verano cuando las nubes son menores. Es soleado, húmedo y caliente en los veranos (diciembre-abril), nuboso y templado en los inviernos (junio a septiembre). La lluvia es casi nula. El promedio anual es de 7 mm reportado en el Aeropuerto Internacional Jorge Chávez, siendo la menor cantidad en un área metropolitana en el mundo. Una lluvia en Lima puede ser vista como un fenómeno extraño por la mayor parte de la población.

Solo muy pocas veces ha llovido intensamente en la ciudad. El fenómeno de la lluvia se da especialmente en los distritos cercanos a los cerros como La Molina y Lurigancho-Chosica. Una de las lluvias más fuertes que hubo en la ciudad en la última década, fue soportada por los distritos de La Molina, San Juan de Miraflores, Villa María del Triunfo, Villa el Salvador y Cieneguilla el 6 de abril de 2001. Aquella noche, se produjo una fuerte lluvia con truenos y relámpagos, la cual sorprendió a los habitantes. Fue producida por el desprendimiento de una célula convectiva que recorrió desde la sierra hasta ingresar a la costa. La última lluvia con truenos se produjo el 7 de marzo de 2009 en La Molina y Ate Vitarte, producto de la llegada de nubes desde la sierra.

Cuando llueve muy fuerte en Lima normalmente hay problemas, pues la ciudad no está preparada para la lluvia. En los cerros se producen huaycos o aludes. Cuando una quebrada seca se reactiva con la lluvia esta genera grandes daños. En 2002 hubo aludes en la zona de Huaycán y Santa María de Huachipa. También a lo largo de los años se han producido algunos huaycos en Lurigancho-Chosica y Chaclacayo. El último fenómeno anómalo en Lima de consideración sucedió en enero de 2011, debido a la llegada de nubes desde la sierra hasta la costa, lo que produjo intensas lluvias en varios distritos capitalinos. Lima tiene solo 1284 horas de sol al año, 28,6 horas en julio y 179,1 horas en enero, valores excepcionalmente bajos para la latitud. De enero a abril predominan los cielos claros; en mayo, y de octubre a diciembre, los cielos se mantienen parcialmente nublados; de junio a septiembre los cielos se mantienen tenebrosos, cubiertos casi permanentemente. La combinación de fenómenos climáticos se presentan así:

La corriente fría de Humboldt que recorre la costa, enfría la temperatura del agua. Esta es mucho más fría que lo que correspondería a la latitud tropical en la que se sitúa la ciudad. Así, las condiciones de frío a nivel del mar con una atmósfera superior más caliente por la acción solar, genera una inversión térmica que impide el fenómeno de convección, por el cual el aire más cálido y menos denso asciende. Esto, unido a la cordillera andina circundante, hace que se presente una casi permanente capa de espesa nubosidad extremadamente baja (a menos de 500 m del suelo), que impide el paso de la radiación solar directa. A su vez, el bloqueo por una capa de aire caliente superior evita la formación de nubes de desarrollo vertical cumulonimbus, lo que explica la ausencia de precipitaciones. Esta es la razón de la paradoja de tener un clima extremadamente nuboso y húmedo y, sin embargo, desértico. Las escasas precipitaciones (menos de 8 mm anual) conocidas como garúa son producto de la condensación de la nubosidad baja que forma el sistema.
En cuanto a la morfología, el departamento de Lima está formada por dos regiones distintas, la costa y la sierra. En la zona costera predominan las pampas desérticas, enmarcadas por colinas, en muchos casos interrumpidas por oasis formados por ríos que llevan agua todo el año. Son los valles costaneros, donde están asentadas ciudades y prospera una agricultura. Los accidentes más importantes son las colinas aisladas o formando sistemas, las quebradas secas, terrazas fluviales y marinas, y relieves ondulados, así como los acantilados litorales. La región de la sierra está formada por la Cordillera Occidental de los Andes, con alturas que llegan hasta más de 6000 msnm.

Para su abastecimiento de agua, la población de Lima depende de tres ríos: Rímac, Chillón y Lurín. Al igual que la mayoría de nacen en las altas montañas de la cordillera de los Andes y desembocan en el océano Pacífico. Son cortos, de curso empinado y régimen estacional. El río Rímac inicia su recorrido en la vertiente occidental de la cordillera de los Andes a una altitud de aproximadamente 5508 m en el nevado Paca, recorre las provincias de Lima y Huarochiri, ambas ubicadas en el departamento de Lima.

A la altura de la ciudad de Lima, el río es atravesado por varios puentes, siendo el más representativo de ellos el Puente de Piedra construido por el virrey Juan de Mendoza y Luna en 1610. En su cuenca se encuentra la planta de tratamiento de agua La Atarjea (manejada por la empresa estatal Sedapal), además de las centrales hidroeléctricas de Huampaní, Matucana, Huinco, Barbablanca y Moyopampa.

El río Chillón es la segunda fuente más importante de agua para Lima. Se forma en la vertiente occidental de la cordillera La Viuda. Su cuenca cubre una superficie de 2444 km². Su valle es fértil, como se evidencia por la presencia de varios asentamientos humanos desde épocas prehispánicas hasta la actualidad. Fue aquí donde se formó la cultura Colli. Además en el valle formado por este río se estableció la cultura Chivateros.

El río Lurín se origina en los glaciares y lagunas de los Andes occidentales. Su cuenca cubre un área de 1670 km² y se extiende desde el borde del litoral hasta la zona de los nevados Otoshmicumán y Chanape en la provincia de Huarochiri. Es conocido como el río Chalilla hasta su confluencia con el riachuelo Taquía a partir de donde recibe su nombre común. Sus principales afluentes son el Taquía, Llacomayqui, Tinajas, Numincancha y Canchahuara en su margen izquierdo y el Chamacna en el derecho.

La flora capitalina está formada por una gran variedad de hierbas, plantas, arbustos y árboles que crecen en las lomas y en los montes ribereños. El amancay es la flor típica de la ciudad, es endémica de las lomas costeras del Perú y solo aparece en la estación fría y nublada. Otras especies que forman parte de la flora limeña son la begonia, la ortiga, el ficus, la ponciana, la oreja de elefante, el olivo y el geranio. En cuanto a la fauna, en la ciudad se puede encontrar más de cien especies distintas de aves. Las más comunes son la paloma doméstica o paloma de Castilla, la cuculí, los jilgueros y los gorriones.

La ciudad de Lima cuenta con dos áreas naturales protegidas por el Servicio Nacional de Áreas Naturales Protegidas por el Estado, el refugio de vida silvestre Pantanos de Villa y la zona reservada Lomas de Ancón. Los Pantanos de Villa están ubicados en el distrito de Chorrillos, son unos humedales naturales que permiten la anidación y el tránsito de aves migratorias y residentes. Las Lomas de Ancón están localizadas en el distrito de Ancón. Comprenden una extensión de 10 962,14 hectáreas, fue nombrada zona reservada ya que en el lugar se han encontrado una gran variedad de flora no vista en otras zonas.

En el año 2019, el gobierno peruano estableció la primera Área de Conservación Regional (ACR) de la ciudad, denominada Sistema de Lomas de Lima, con una extensión de 13 475, 95 ha; abarcando las Lomas de Ancón, Carabayllo, Amancaes y Villa María. Si bien estas lomas representan alrededor del 20 % del total que representan las lomas dentro de la ciudad, se espera que en un futuro se puedan incluir otras lomas como las de Mangomarca, Lúcumo, Collique, entre otras.

Lima es la ciudad capital de la República del Perú, como tal es sede de los tres poderes que conforman el Estado Peruano. Así, el poder ejecutivo tiene su sede en el Palacio de Gobierno ubicado en la Plaza Mayor. El poder legislativo constituido por el Congreso de la República y el poder judicial con su órgano de mayor jerarquía, la Corte Suprema de Justicia de la República del Perú, también se encuentran en la ciudad en el Palacio de Justicia de Lima.

De la misma manera, todos los Ministerios tienen su sede principal en la capital. En el ámbito internacional, la ciudad es también sede de la Secretaría General de la Comunidad Andina de Naciones, el Organismo Andino de Salud, y de otras organizaciones regionales e internacionales. Al estar concentrado prácticamente en Lima todo el poder político, industrial y financiero del país, ha producido un grave centralismo, lo cual se demuestra en la desproporción poblacional y económica de la ciudad capital en comparación con otras ciudades importantes del país, como Trujillo, Chiclayo, Piura, Arequipa, Cuzco.

No existe un órgano de gobierno de la ciudad como tal. La ciudad se encuentra englobada en la provincia de Lima, que se subdivide en cuarenta y tres distritos por lo que la autoridad local es la Municipalidad Metropolitana de Lima que, a diferencia de otras municipalidades, es la única que tiene el carácter «metropolitano». La municipalidad de Lima tiene competencia en todo el territorio de la provincia. Cada uno de los cuarenta y tres distritos sobre los que se extiende la ciudad tiene su propia municipalidad distrital la que tiene competencia sobre su propio distrito pero, tienen también una obligación de coordinación con la municipalidad metropolitana. El actual alcalde de la ciudad es Jorge Muñoz Wells.

A diferencia del resto de la república, la Municipalidad Metropolitana de Lima ejerce también funciones de gobierno regional ya que no forma parte de ninguna región administrativa, según el artículo 65.º de la Ley 27867 de Gobiernos Regionales del 16 de noviembre de 2002. Sin embargo, se mantiene la organización política anterior en el sentido de que aún existe un «Gobernador» que es la autoridad política en todo el ámbito del departamento de Lima y la misma ciudad. Las funciones de esta autoridad son más policiales y militares. La administración misma de la ciudad está destinada a la autoridad municipal local.

Lima es sede de la Corte Superior de Justicia de Lima, ente rector del Distrito judicial de Lima. De acuerdo a la organización judicial del Perú, en la ciudad se concentra la mayor carga judicial a pesar de que solo tiene competencia sobre treinta y cinco de los cuarenta y tres distritos que conforman la provincia de Lima. Existen noventa juzgados de paz letrado, doscientos veintiocho juzgados especializados (dos de investigación preparatoria, tres unipersonales, cuarenta y dos civiles, diez constitucionales, diecisiete contencioso administrativo, ocho contencioso administrativo transitorios, diecisiete civiles con subespecialidad comercial, cincuenta y nueve penales, treinta y cuatro especializados de trabajo, veintiún de familia y quince mixtos), treinta y siete salas superiores (siete civiles, una mixta, cinco contencioso administrativo, dos civiles con subespecialidad comercial, seis penales de reos libres, cuatro penales de reos en cárcel, cuatro penales liquidadoras, una de apelaciones, tres laborales, una laboral transitoria, una contencioso administrativo transitoria y dos de familia).

Asimismo, dentro del territorio de la ciudad se encuentran otras divisiones judiciales:

Distrito Judicial de Lima Norte 

Distrito Judicial de Lima Sur 

Distrito Judicial de Lima Este

De acuerdo con el censo peruano de 2017, la población de la provincia de Lima es de 8 574 974  habitantes, con una densidad poblacional de 3208.8 hab/km². El primer asentamiento en lo que se convertiría el Centro Histórico de Lima estaba compuesta solo por 117 bloques de viviendas.

En 1562, un segundo distrito fue construido al otro lado del río Rímac y en 1610, se construyó el primer puente de piedra. La ciudad tenía entonces una población de unos 26 000 habitantes, los negros representaban alrededor del 40% de la población y los blancos alrededor del 38% de la población.

En 1748, la población blanca fue de más de 16 000 habitantes. A principios de la independencia la población estaba constituida esencialmente por la antigua población blanca de origen español, mestiza, amerindia y africana con que contaba desde el virreinato. Con el inicio de la República la ciudad se convirtió en receptora de una gran cantidad de inmigrantes europeos. La población cuenta con una mezcla muy compleja de diversos grupos raciales y étnicos. Los mestizos de ascendencia mixta de amerindios y europeos (principalmente españoles e italianos) son el grupo étnico más grande. Los peruanos descendientes de europeos son el segundo grupo más grande. Muchos son de origen español, italiano, alemán, francés, británico o de ascendencia croata.

Las minorías en Lima son amerindias (en su mayoría aimaras y quechuas), los afroperuanos, cuyos antepasados africanos fueron inicialmente traídos a la región como esclavos, son otra parte de la diversidad étnica de la ciudad. También hay numerosos judíos descendientes de europeos y algunos provenientes de Oriente Medio. Los asiáticos conforman un gran número de la población metropolitana, en especial los chinos (principalmente cantoneses) y descendientes de japoneses, cuyos antepasados procedían en su mayoría de los siglos XIX y XX. Lima posee la mayor comunidad étnica china en América Latina.
Por su expansión y populosa área urbana, hoy se le denomina Lima Metropolitana, y cuenta con una población mayor a 9 millones 320 mil habitantes, quienes representan el 30% de la población peruana , conocida también como "Lima-Callao", es la metrópoli conformada por la gran conurbación central de la ciudad de Lima y su extensión hacia el norte, sur y este, la cual abarca gran parte de las provincias de Lima y todo el Callao. Es el área metropolitana más poblada del Perú, la quinta más grande de América Latina y la y una de las más grandes del mundo. El proceso de conurbación comenzó a ser evidente en la década de 1980.

La aglomeración urbana tiene una superficie de 2 926 km² y una población de 10 542 829 habitantes. Se concentra principalmente en la zona costera y se extiende de norte a sur a lo largo de la costa del océano Pacífico durante casi 200 km, comenzando en el distrito de Ancón, en la frontera con la provincia de Huaral del departamento de Lima y terminando en el distrito de Pucusana, en la frontera con la provincia de Cañete, también en el departamento de Lima.

Lima y el Callao, hace años separadas por un semidesierto y conectadas en el siglo XIX por un ferrocarril, se encuentran hoy totalmente unidas, debiendo señalarse sus límites según las avenidas o mediante carteles para que estos no pasen totalmente inadvertidos. Una vista aérea desde el satélite nos muestra una sola trama urbana donde es prácticamente imposible diferenciar a Lima del Callao, en realidad separadas solo administrativamente.

El área metropolitana de Lima se compone de cinco subregiones, cuyos extremos localmente se denominan "conos". Estas subregiones son las siguientes:

Desde mediados del siglo XX, mientras Lima crecia y se modernizaba con modernas construcciones e inmensos conglomerados de departamentos para vivienda,la ciudad comenzó a recibir un importante número de inmigrantes venidos desde el interior del país. El éxodo rural se intensificó entre las décadas de 1960 a 1980, y su magnitud contribuyó a cambiar de manera decisiva la composición étnica de la capital peruana, pues los nuevos asentamientos humanos que surgieron estaban constituidos fundamentalmente por habitantes de origen mayoritariamente indígena.

La magnitud del problema de los asentamientos informales en el Perú ha contribuido a que el país haya sido uno de los países latinoamericanos objeto de mayor número de investigaciones sociológicas sobre las barriadas de viviendas precarias, convirtiéndose el fenómeno de las infraviviendas en objeto de estudio por parte de diversas universidades, científicos sociales y organizaciones no gubernamentales.

Con el paso del tiempo, han disminuido las características rurales del conglomerado de personas que habitan los asentamientos informales, puesto que las nuevas generaciones ya han crecido en la ciudad y han adoptado las costumbres urbanas en conjunto con las propias. En la actualidad el crecimiento de la ciudad no se basa tanto en la inmigración desde el campo, sino en el natural crecimiento de la población de la misma ciudad.

A pesar de que progresivamente han mejorado los índices de salubridad y acceso a los servicios públicos en las zonas más pobres de la ciudad, los niveles de desigualdad social aún persisten. Las zonas de la capital que presentan estas circunstancias se encuentran mayoritariamente a las afueras de la misma, en sectores conocidos como «conos», que a su vez dividen la ciudad en Norte, Este y Sur. No obstante, la gran abundancia de comercio en esas zonas es la que hace que sigan expandiéndose y sus habitantes tengan puestos de trabajo para poder sostener a sus familias.

La capital peruana es el principal centro industrial, comercial y financiero del país. Es uno de los centros financieros más importantes de Latinoamérica. Los principales rubros económicos que presentan una alta actividad son la industria, el comercio, los servicios y el turismo. Lima es responsable de más de dos tercios de la producción industrial del Perú y la mayoría de su sector terciario.

Se aprecian en la ciudad diversas sedes de empresas nacionales y transnacionales muchas de las cuales se encuentran ubicadas en modernos edificios construidos en diferentes sectores, especialmente en el distrito de San Isidro que se ha convertido en las últimas décadas en el centro financiero de la ciudad. El área metropolitana, con cerca de ocho mil fábricas, es también el centro de desarrollo industrial del país, gracias a la cantidad y la calidad de la mano de obra disponible y la infraestructura de las rutas y autopistas internas de la ciudad.Los sectores industriales más relevantes son los textiles, la agro industria, los alimentos, los derivados de productos químicos, el pescado, el cuero y el aceite, los cuales son procesados y fabricados en la misma ciudad. Lima tiene la mayor industria de exportación en América del Sur y es un centro regional para la industria de carga operativa. La industrialización comenzó a tomar fuerza entre los años 1930 y 1950, a través de las políticas de sustitución de importaciones, en 1950 la fabricación de productos representó el 14% del PIB.

En la década de 1950, hasta el 70% de los bienes de consumo fueron fabricados en la ciudad. El puerto del Callao es uno de los principales puertos comerciales de Sudamérica, es utilizado como punto de entrada y salida del 75% de las importaciones y el 25% de las exportaciones del país. Los principales productos de exportación son el petróleo, el acero, la plata, el zinc, el algodón, el azúcar y el café.

Lima concentra la mayor parte de la actividad económica: el 57% de la industria, el 62% del comercio, el 46% de la PEA y el 52% del PIB. En 2007, la economía peruana creció un 9%, la tasa de mayor crecimiento en toda América del Sur. La Bolsa de Valores aumentó 185,24% en 2006, y creció 168,3% en 2007, por lo que es una de las bolsas de valores de más rápido crecimiento en el mundo.

En 2006, la Bolsa de Valores de Lima fue la más rentable del mundo. La tasa de desempleo en el área metropolitana es de 7,2%. La capital peruana es también la sede central de los mayores bancos del país como el Banco de Crédito del Perú, Interbank, Banco de la Nación, BBVA Continental, Mibanco, Banco Interamericano de Finanzas, Banco Pichincha, Banco de Comercio y Scotiabank. Asimismo es sede de las mayores compañías aseguradoras, tales como Rímac Seguros, Mapfre Perú, Interseguro, Pacífico y La Positiva.

Como el principal punto de entrada al país, Lima ha desarrollado una importante industria del turismo, entre las que resaltan su centro histórico, sus centros arqueológicos, su vida nocturna, los museos, las galerías de arte, las festividades y las tradiciones populares. Actualmente Lima viene liderando el índice de ciudades más visitadas a nivel de Latinoamérica y se encuentra en el top 20 global, con 5,11 millones de visitantes en 2014.

El centro histórico de Lima, el cual comprende parte de los distritos de Lima y Rímac, fue declarado Patrimonio de la Humanidad por la Unesco en 1988 debido a la importancia que tuvo la ciudad durante el Virreinato del Perú, dejando como testimonio una gran cantidad de legados arquitectónicos. Destacan la Basílica y Convento de San Francisco, la Plaza Mayor, la Catedral de Lima, la Basílica y Convento de Santo Domingo, el Palacio de Torre Tagle, entre otros. El recorrido por las iglesias de la ciudad es muy popular entre los turistas. En un corto recorrido por el centro de la ciudad podemos encontrar muchas, varias de las cuales datan de los siglos XVI y XVII.

Entre ellas destaca la Catedral de Lima y la Basílica de San Francisco, de las cuales se dice que se encuentran unidas por los pasadizos subterráneos de sus catacumbas. También sobresale el Santuario y Monasterio de Las Nazarenas, lugar de peregrinación al Señor de los Milagros, cuyas festividades en el mes de octubre constituyen la más importante manifestación religiosa de Lima y de todos los peruanos. Algunas secciones de las coloniales murallas de Lima todavía pueden ser vistas: tal es el caso del Baluarte Santa Lucía, restos de la antigua fortificación española construida por el virrey Melchor de Navarra y Rocafull alrededor del casco de la ciudad, cuya ubicación colinda en el límite de los Barrios Altos y El Agustino.

Así mismo,teniendo Lima el privilegio de ser la unica capital de Sudamérica con acceso inmediato al mar cuenta con amplios malecones turísticos que en los últimos años se han vuelto gran atractivo para miles de turistas,sobretodo en los distritos de Miraflores y Barranco,donde también se desarrolla un amplio desarrollo en tema entretenimiento en esas zonas convirtiendo a la capital en un lugar con varios sitios de turismo y diversión.

La oferta hotelera hasta la decada de los setenta,se caracterizó por tener los mejores hoteles de la ciudad en el centro de Lima,sin embargo desde inicios de los noventa hasta la fecha estos establecimientos se han posicionado en otras zonas de la capital como en Miraflores,Santiago de Surco,San Borja y San Isidro,este último con el edificio de hoteles mas grande del Perú,el Westin Libertador de 30 pisos.
Estos finos ejemplos de las fortificaciones medievales españolas fueron utilizadas para defender la ciudad de los ataques de piratas y corsarios. Para ello se recuperó parte de la muralla correspondiente a la zona posterior de la Iglesia de San Francisco, muy cerca del Palacio de Gobierno, en la cual se construyó un parque (llamado Parque de la Muralla) y en el cual se puede observar restos de la misma. A media hora del centro histórico, en el distrito de Miraflores se puede visitar el centro turístico y de entretenimiento Larcomar el cual se encuentra sobre los acantilados frente al mar.La ciudad cuenta con dos parques zoológicos tradicionales: el principal y más antiguo es el Parque de las Leyendas, ubicado en el distrito de San Miguel, y el otro es el Parque Zoológico Huachipa ubicado al este de la ciudad en el distrito de Lurigancho-Chosica. Por otro lado, la oferta de cines es amplia y cuenta con numerosas salas de última generación (3D) que programan estrenos de películas internacionales.

Exclusivas playas son visitadas durante los meses de verano, las cuales se ubican en la carretera Panamericana al sur de la ciudad en balnearios como Punta Hermosa, San Bartolo y Asia.En la zona norte se encuentra el otrora exclusivo balneario de Ancon,el cual fue en los años sesentas el más exclusivo de Lima,actualmente si bien mantiene su belleza arquitectónica,es visitado por personas de todas partes de Lima Norte.

Numerosos restaurantes, discotecas, lounges, bares, clubes y hoteles han sido abiertos en dichos lugares para atender a los bañistas. El distrito suburbano de Cieneguilla, el distrito de Pachacámac y la ciudad de Chosica proveen importantes atractivos turísticos entre los locales. Por su elevación (sobre los 500 msnm), el sol brilla en Chosica durante el invierno, siendo muy visitada por los residentes limeños para escapar de la niebla urbana.

El Aeropuerto Internacional Jorge Chávez es el principal terminal aéreo de la ciudad metropolitana. Está ubicado en la provincia constitucional del Callao pero es el aeropuerto natural de Lima. Fue concebido en 1960 para reemplazar al antiguo Aeropuerto de Limatambo, ubicado en el distrito de San Isidro, debido a que había quedado rodeado por las nuevas áreas residenciales de la ciudad. Es el aeropuerto más importante del Perú, pues concentra la gran mayoría de vuelos internacionales y nacionales del país, sirviendo a más de 22 000 000 pasajeros por año.Su ubicación estratégica en el medio de la costa oeste de América del Sur lo ha convertido en un importante centro de conexión del subcontinente. Es el centro de operaciones para Sudamérica de la aerolínea colombiana Avianca con su asociada peruana Avianca Perú y de la chilena LAN con su asociada peruana LATAM Perú. En 2015 y, por séptimo año consecutivo, fue elegido como el «Mejor Aeropuerto de América del Sur», colocándose en los primeros puestos del ranking mundial, según una encuesta realizada vía internet por Skytrax Research a más de 13 millones de pasajeros de 112 nacionalidades y usuarios de 550 terminales aéreos alrededor del mundo.

Por otro lado, en 2013 fue distinguido por quinto año consecutivo con el World Travel Awards en la categoría de «Principal Aeropuerto de Sudamérica». La ciudad posee además otros cuatro aeródromos como la Base aérea Las Palmas ubicada en el distrito de Santiago de Surco, de uso exclusivamente militar y otras pistas de aterrizaje para aeronaves menores en los balnearios de Santa María del Mar y San Bartolo. En este último, se ubica el Aeródromo Lib Mandi, el cual es un aeródromo en el cual operan las avionetas Aero Link con vuelos chárter dentro del país.
Si bien el transporte civil marítimo en el Perú no ofrece servicios comerciales con regularidad, varios cruceros anclan en el Callao periódicamente. En Lima también se encuentra un pequeño puerto en el distrito de Lurín cuyo tránsito sobre todo se debe a los barcos petroleros de la refinería de Conchán que se encuentra cerca.

Lima también cuenta con una antigua estación de ferrocarril llamada Estación de Desamparados. Se encuentra ubicada en la margen izquierda del río Rímac. Su nombre se debe a la Iglesia de Nuestra Señora de los Desamparados que se encontraba al lado de la estación. El proyecto fue iniciado en 1890 por The Peruvian Corporation y tres años más tarde se inauguró la ruta Lima–La Oroya. El edificio de la estación, de tres niveles, fue la primera obra pública proyectada por el arquitecto peruano Rafael Marquina y Bueno y se terminó de construir en 1912.

Actualmente su uso es exclusivamente administrativo, aunque eventualmente ofrece servicios de carga y transporte de pasajeros desde Lima hacia la sierra central. Funciona también como sala de exposiciones, entre las principales piezas de exhibición se encuentra el vagón presidencial denominado "Paquita", mandado a construir en honor de la esposa del entonces Presidente del Perú Óscar Benavides.

Por su ubicación en el centro del litoral peruano, Lima es el punto de confluencia de las principales carreteras del país. La capital se comunica con todas las ciudades de la costa a través de la Carretera Panamericana, que corre paralela al mar; su sección norte llega a Tumbes (límite con Ecuador), a 1370 km de distancia y la sección sur recorre 1291 km hasta Tacna (frontera con Chile). La conexión con las ciudades de la sierra se da a través de la Carretera Central y de algunas vías de penetración afirmadas hacia Yauyos, Huancayo, Huacho, Oyón, Huánuco, Canta, La Oroya, Pucallpa, entre otros. Las vías troncales que nacen de Lima y que comunican a todo el Perú son tres:


La ciudad cuenta además con un terrapuerto llamado Gran Terminal Terrestre de Plaza Norte, inaugurado en 2010, que permite abordar buses con rutas nacionales e internacionales. También existen terminales particulares de algunas empresas de transporte y se cuenta con otras estaciones informales como "Fiori" en el distrito de San Martín de Porres para las rutas hacia el norte, "Yerbateros" en el distrito de Ate para las rutas del centro y "Atocongo" en el distrito de San Juan de Miraflores para las rutas del sur.

Uno de los grandes problemas actuales de la ciudad de Lima es el relativo al transporte público. Esta situación ha llevado a la construcción, por parte de las autoridades municipales, de viaductos, puentes, intercambios viales, vías expresas y pasos a desnivel como fórmula para solucionar los constantes congestionamientos. Es por ello que se empezaron a desarrollar sistemas de transporte públicos y privados como es el caso del Sistema Metropolitano de Transporte cuyo objetivo es mejorar la seguridad y calidad del servicio de transporte en Lima, además de la construcción de más de 100 km de ciclovías en Lima Metropolitana.

El metro de Lima y Callao, conocido popularmente como "tren eléctrico", es un ferrocarril metropolitano que actualmente cuenta con una única línea operativa, que recorre la ciudad de sur a noreste. La línea opera casi en su totalidad bajo el sistema de viaducto elevado, no obstante se determinó que la línea 2 y las siguientes cuatro líneas serán subterráneas.

Al concluirse su primer tramo en 1990, el sistema contaba con una línea de metro en viaducto de 9,2 km, atravesando tres distritos: Villa El Salvador, Villa María del Triunfo y San Juan de Miraflores. A pesar de que este tramo inicial contaba con treinta y dos vagones y siete estaciones, el metro no llegó a ponerse en operación, por no tener la distancia ni la demanda suficiente que lo hicieran comercialmente rentable.

A comienzos de 2010, se inició el proyecto de construcción de la extensión de la Línea 1 desde la Estación Atocongo en el distrito de San Juan de Miraflores hasta el Hospital Nacional Dos de Mayo en la Avenida Miguel Grau (en el centro de Lima) sumando un total de 21,48 km de recorrido. Con la conclusión de este nuevo tramo, el Metro de Lima fue inaugurado oficialmente el 11 de julio de 2011. En noviembre de 2011 se inició la construcción del tramo final de la Línea 1, la cual alcanza un total de 35 km de extensión y cuya puesta en funcionamiento se realizó en julio de 2014. Con algunas mejoras realizadas al sistema luego de la apertura del segundo tramo, actualmente transporta alrededor de 500 000 personas en un día laboral. 

También están en construcción la Linea 2 y un tramo de la Línea 4, perteneciente a las Av. Elmer Faucett y Av. Néstor Gambetta , en la Provincia Constitucional del Callao.

El Metropolitano es un sistema integrado de transporte público, que cuenta con buses articulados de gran capacidad que circulan por corredores exclusivos, bajo el esquema de autobuses de tránsito rápido (BRT). Su construcción se inició en 2006, durante la gestión edil de Luis Castañeda Lossio y su operación comercial inició el 28 de julio de 2010 de manera parcial. El Corredor Segregado de Alta Capacidad (COSAC) cubre una ruta segregada que de sur a norte recorre dieciséis distritos de la ciudad desde Chorrillos hasta Lima Norte.

La longitud de esta ruta troncal es de 26 km y el número total de estaciones es de 38. Además, se complementa con rutas alimentadoras en sus extremos sur y norte. Este servicio beneficia a más de 600 000 usuarios por día. Este sistema es similar al TransMilenio de Bogotá o al Red Metropolitana de Movilidad de Santiago de Chile.

Cabe mencionar que su ruta troncal se expandirá por el norte hasta el distrito de Carabayllo, lo constituirá los últimos 10 km de la ruta y 18 nuevas estaciones, completando así la obra y también se tiene pensado el cambio o eliminación de algunas rutas troncales y alimentadores.

Constituidos sobre la base del Sistema Integrado de Transporte, componen un sistema de transporte público en proceso de implementación, impulsado por la municipalidad de Lima. Tiene como objetivo reducir el número de rutas de transporte actuales, renovar la flota vehicular, retirar de circulación vehículos con muchos años de antigüedad o con poca capacidad de pasajeros e integrarse con los demás sistemas de transporte masivo como el Metropolitano y el Metro. El 26 de julio de 2014, luego de cuestionamientos por parte de la municipalidad del Callao y de los sindicatos de transporte, entró en fase de pre operación el primer corredor llamado "Corredor Azul", que recorre las avenidas Tacna, Garcilaso de la Vega y Arequipa.

Actualmente hay 5 líneas de los corredores, cada uno identificado con un color, los cuales pasan por algunas de las vías más transitadas de la ciudad. Están distribuidos de la siguiente forma:

Corredor Amarillo : San Martín de Porres - Surco (Con autobuses de 12 y 18 metros respectivamente)

Corredor Rojo: San Miguel - Ate / Lince - La Molina (con autobuses de 12 y 18 metros respectivamente)

Corredor Azul: Rimac - Barranco /Rimac - Miraflores /Rimac - San Isidro (con autobuses de 9 y 12 metros respectivamente)

Corredor Morado: San Juan de Lurigancho - Magdalena/San Isidro/Rimac (con autobuses de 12 metros)

Corredor Verde : San Miguel - Centro de Lima (con autobuses de 12 metros)

Cabe señalar que tanto como el Metropolitano y los Corredores Complementarios toda su flota esta conformada por unidades a gas natural vehicular para cuidar el medio ambiente y evitar la propagación del smog.

También conocido como «sistema de rutas licitadas», «sistema tradicional de buses» , es el sistema de transporte público imperante no solo en la ciudad de Lima, sino también en muchas otras ciudades del Perú. En el caso de Lima, actualmente existen 511 rutas de transporte urbano, las cuales son brindadas principalmente por autobuses y microbuses.

A pesar de que en la actualidad se encuentra en una fase de reestructuración global, este sistema se ha ido renovando con unidades modernas a raíz de las ultimas reformas de transporte que se dieron desde el 2005. Las tarifas varían entre S/. 0.50 hasta S/. 4.00 dependiendo de la distancia del recorrido.

Debido a los grandes márgenes de desempleo que afrontó el Perú en los años 1980 y la libre importación de autos usados, existio por varios años una sobreoferta de taxis y mototaxis. Aunque la Municipalidad Metropolitana de Lima inició hace varios años una reorganización del Servicio de Taxis Metropolitanos (SETAME), aún circulan taxis informales. Los vehículos no cuentan con taxímetros por lo que el monto de la tarifa se negocia al momento de tomar el servicio.

No obstante, existen numerosas empresas privadas de radiotaxi que brindan servicio puerta a puerta y ofrecen un servicio confiable y seguro. Por otro lado también existen empresas de taxi remisse para servicios entre el aeropuerto internacional y los diferentes hoteles que posee la ciudad. Estos vehículos también pueden alquilarse para servicios turísticos privados y son muy solicitados por los altos ejecutivos que visitan Lima.

La principal diferencia entre los taxis de empresas privadas y los taxis convencionales es su color exterior, mientras que los de empresas privadas en su gran mayoría son negros, los convencionales varían entre el azul y el amarillo con rectángulos rojos y blancos en las puertas y el maletero. Muchos taxis de Lima han comenzado a trabajar para empresas desarrolladoras de aplicaciones móviles a través de las cuales los usuarios, que aumentan exponencialmente, utilizan para pedir taxis.

La educación en Lima, así como en el resto del país, se divide en diferentes niveles. La educación inicial, corresponde al período entre los cero y los cinco años de edad, y está a cargo de las cunas que tienen la finalidad de brindar a los niños las estimulaciones requeridas para su desarrollo integral y los jardines que ofrecen actividades técnico-pedagógicas. La educación primaria se inicia con el primer ciclo, conformado por el primer y segundo grado. La edad de ingreso para los niños es de seis años. Este nivel empieza en el primer grado y termina en el sexto grado de primaria.

La educación secundaria consta de cinco años, de primero al quinto año. Luego viene la educación superior que puede ser técnico productiva, tecnológica o universitaria. Para impartir la educación básica (desde inicial hasta secundaria), la ciudad cuenta con 9953 centros educativos privados y 5083 instituciones públicas. La capital peruana posee la mayor concentración de . Alberga más de cincuenta universidades, entre las cuales se encuentra la Universidad Nacional Mayor de San Marcos, «Decana de América», la más antigua de América y la primera del Perú, fundada el 12 de mayo de 1551, dando lugar a la celebración del Día de la Universidad Peruana.

Otras universidades públicas tienen un importante rol en la enseñanza e investigación, como la Universidad Nacional de Ingeniería, fundada en 1876, la Universidad Nacional del Callao, la Universidad Nacional Federico Villarreal, la Universidad Nacional Agraria La Molina, y la única universidad nacional dedicada a la formación de docentes, la Universidad Nacional de Educación Enrique Guzmán y Valle, conocida como «La Cantuta» situada en Chosica y fundada el 6 de julio de 1822 por el Libertador Don José de San Martín, dando así lugar a la celebración del Día del Maestro, por ser fecha de fundación de la primera Escuela de Preceptores en el Perú. La Pontificia Universidad Católica del Perú es la primera universidad privada del país (fundada en 1917). 

Otras instituciones universitarias localizadas en la ciudad son: la Universidad César Vallejo, la Universidad de San Martín de Porres, la Universidad Inca Garcilaso de la Vega, Universidad ESAN, la Universidad de Piura, la Universidad del Pacífico, la Universidad de Lima, la Universidad Peruana Cayetano Heredia, la Universidad Peruana de Ciencias Aplicadas, la Universidad Privada San Juan Bautista, la Universidad Científica del Sur, la Universidad San Ignacio de Loyola, la Universidad Ricardo Palma, la Universidad Católica Sedes Sapientiae, entre otras. De acuerdo con los resultados obtenidos en el censo peruano de 2007, el 93,44 % de los limeños de tres o más años de edad es alfabeta. En cuanto al nivel de educación alcanzado, el 37,73 % de las personas tiene educación secundaria, mientras que el 19,76 % ha cursado la educación superior. El promedio de años de estudio es de 9 años.
Según los Censos de Población y Vivienda de 2007, el 41,86% de la población limeña cuenta con algún tipo de seguro de salud, es decir, 3 285 178 personas, a pesar de eso el 58,13% de la población no cuenta con ningún tipo de seguro. Los resultados obtenidos en los censos también señalan que hombres y mujeres acceden casi con el mismo porcentaje a un seguro de salud. Así, el 42,18% de los hombres, es decir, 1 566 399, y el 41,56% de las mujeres, que equivale a 1 517 572 personas cuentan con algún seguro de salud.

En cuanto al tipo de seguro al cual se encuentra afiliada la población, del total de personas que manifestaron poseer algún seguro de salud, el 6,43% están protegidas por el Seguro Integral de Salud, el 24,55% acceden únicamente al seguro social EsSalud, mientras que el 12,22% se encuentra afiliada a compañías privadas de seguros. Para acceder al servicio de la salud los limeños actualmente cuentan con 367 establecimientos (188 centros de salud, diecisiete hospitales, seis institutos especializados y 156 puestos de salud) dependientes del Ministerio de Salud del Perú; y con cuarenta y ocho centros asistenciales (quince hospitales, quince policlínicas, tres centros médicos, nueve postas médicas, cinco centros de atención primaria y una clínica) pertenecientes al Seguro Social de Salud del Perú.

En la ciudad también se encuentran una gran cantidad de clínicas privadas entre las que destacan: la clínica Javier Prado, la clínica Good Hope (promovida por la Iglesia Adventista del Séptimo Día), la clínica Maison de Santé (fundadores de la Sociedad Francesa de Beneficencia), la clínica Stella Maris (constituida por la Congregación de las Misioneras del Sagrado Corazón de Jesús), la Anglo Americana, y las clínicas Internacional y Ricardo Palma incluidas en el ranking de las cuarenta y dos mejores clínicas de Latinoamérica por la revista AméricaEconomía.

El primer diario limeño fue la Gaceta de Lima, que circuló por primera vez en el año de 1715. En 1790, fue creado el «Diario Curioso, Erudito, Económico y Comercial», publicado por Jaime Bausate y Mesa; un año más tarde fue fundado el Mercurio Peruano, un periódico bisemanal editado por un grupo de jóvenes intelectuales pertenecientes a la Sociedad de Amantes del País. Actualmente la ciudad es sede de los principales y mayores diarios de circulación nacional, entre los que destacan: Depor, Diario Correo, Diario Oficial El Peruano, El Comercio, El Bocón, Expreso, La Razón, La República, Líbero, Perú.21, La Nación, Todo Sport y Trome.

La primera emisora de radio del Perú se llamó OAX, fue inaugurada el 20 de junio de 1925 por el entonces presidente Augusto Leguía. La primera transmisión estuvo bajo la dirección de la Peruvian Broadcasting Company y funcionó con equipos de la empresa británica Marconi. Desde Lima emiten decenas de emisoras de tipo AM y FM con alcance local, nacional e internacional. De acuerdo con una encuesta realizada por la Compañía Peruana de Estudios de Mercado y Opinión Pública S. A. C. en 2017, las emisoras de radio limeñas con mayor audiencia son: Radio Programas del Perú, Moda, Karibeña, Ritmo Romántica, La Zona, Onda Cero, Panamericana, Nueva Q, La Kalle y Radio Felicidad.

La historia de la televisión en Perú se inició en Lima en 1939, año en que se realizó la primera demostración experimental de televisión en el país al transmitirse una película y un programa artístico desde el Colegio Nacional Nuestra Señora de Guadalupe. Luego se realizó otra prueba, esta vez desde el Gran Hotel Bolívar el 28 de mayo de 1954. Finalmente el 17 de enero de 1958, inició sus emisiones el canal estatal, con la transmisión de un documental técnico.

Lima es la sede de los canales de televisión nacionales más importantes del país. La ciudad cuenta con ocho canales de televisión (América Televisión, ATV, La Tele, Latina Televisión, América Next, Panamericana Televisión, Viva TV y TV Perú), los cuales transmiten su programación por señal abierta para todo el país con excepción de RBC Televisión que solo puede ser visto en Lima y en algunas ciudades del Perú vía cable. La ciudad también cuenta con numerosos y de televisión por satélite como: Best Cable, Cable Perú, Cable Visión Perú, Claro TV, DirecTV y Movistar TV.

La arquitectura capitalina se caracteriza por poseer una mezcla de estilos como se refleja en los cambios entre las tendencias a lo largo de varios períodos de la historia de la ciudad. Ejemplos de la arquitectura colonial incluyen estructuras tales como la Basílica y Convento de San Francisco, la Catedral de Lima y el Palacio de Torre Tagle. Estas construcciones fueron generalmente influidas por los estilos del neoclasicismo español, el barroco español y los estilos coloniales españoles.

En las edificaciones del centro histórico se pueden observar más de 1600 balcones que datan de la época colonial y republicana. Los tipos de balcones que presenta la ciudad son los balcones abiertos, rasos, de cajón, corridos, entre otros. Después de la Independencia del Perú, tuvo lugar un cambio gradual hacia los estilos neoclásico y art nouveau. Muchas de estas construcciones recibieron la influencia del estilo arquitectónico francés.

Algunos edificios del gobierno, así como las principales instituciones culturales fueron construidas en este período de tiempo arquitectónico. Durante los años 1950 y 1960, se construyeron varios edificios de estilo brutalista por encargo del gobierno militar de Juan Velasco Alvarado. Los ejemplos de esta arquitectura son el Museo de la Nación y el Ministerio de Defensa del Perú. El siglo XX ha visto la aparición de los de cristal, particularmente alrededor del distrito financiero de la ciudad. También hay varios nuevos proyectos arquitectónicos y de bienes raíces.
Los parques más grandes de Lima se ubican en la periferia de la ciudad y son conocidos como Parques Zonales. En el centro histórico se encuentran el Parque de la Reserva, el Parque de la Exposición, el Campo de Marte, el Parque Universitario, el Parque de La Muralla y el Parque Mariscal Castilla. El Parque de la Reserva tiene el complejo de piletas más grande del país, es conocido como «El Circuito Mágico del Agua».

Otros parques importantes se encuentran en diversos puntos de la ciudad, tales como el Bosque el Olivar, el Parque Reducto n.º 2, los Pantanos de Villa, el Parque de las Leyendas, el Malecón de Miraflores, el Parque de la Amistad y el Parque Kennedy, por citar algunos. El trazado de las calles de la ciudad, se presenta como un sistema de plazas las cuales tienen un propósito similar a las rotondas. Además de este propósito práctico, las plazas sirven como uno de los principales espacios verdes de Lima y contienen una gran variedad de diferentes tipos de arquitectura que van desde monumentos, estatuas y fuentes de agua.

El dialecto de Lima es conocido como el español peruano ribereño. Se caracteriza por la falta de entonaciones fuertes como en muchas otras regiones del mundo de habla española. Está fuertemente influido por el español histórico que se habla en Castilla. A lo largo de la época colonial, la mayor parte de la nobleza española radicada en Lima era originaria de esta región. El español limeño también se caracteriza por la falta de voseo, un rasgo presente en los dialectos de algunos países de América Latina. El dialecto limeño se distingue por su claridad relativa en comparación con otros acentos latinoamericanos. El lenguaje se ha visto influido por una serie de grupos de inmigrantes italianos, andaluces, chinos y japoneses. También ha recibido el influjo de anglicismos, como consecuencia de la globalización, así como por el español andino, debido a la reciente migración de pobladores de la sierra andina hacia Lima.

La cocina limeña ha sido producto de la fusión de la tradición culinaria del antiguo Perú con la cocina española en su variante más fuertemente influida por la presencia morisca en la península ibérica y con importantes aportes de las costumbres culinarias traídas de la costa atlántica del África Subsahariana por los esclavos. Posteriormente, este mestizaje se vio influido por los usos y costumbres culinarias de los chefs franceses que huyeron de la revolución en su país para radicarse, en buen número, en la capital del Virreinato del Perú.

Igualmente trascendental fue la influencia de las inmigraciones del siglo XIX, que incluyó chinos cantoneses, japoneses e italianos, entre otros orígenes principalmente europeos, además de un fuerte flujo interno desde las zonas rurales a las ciudades, en particular, a Lima en la segunda mitad del siglo XX. La ciudad cuenta además con una amplia variedad de restaurantes de comida criolla, chifa, cebicherías y pollerías. La cocina peruana, ampliamente representada en Lima, tiene varios Récords Guinness por su diversidad y su calidad. En 2006, durante el evento anual de Madrid Fusión la ciudad fue declarada como la "Capital Gastronómica de Latinoamérica".

La llegada de los conquistadores españoles al Perú significó la introducción de la religión católica en esta zona poblada de aborígenes de diversas etnias, los cuales seguían religiones animistas y politeístas, lo que produjo un sincretismo religioso. Mediante un proceso largo de adoctrinamiento y prácticas entre los pobladores prehispánicos, los frailes españoles hicieron de la fe su tarea más importante. La ciudad de Lima, capital del Virreinato del Perú, se convirtió en el siglo XVII en una ciudad de vida monástica donde surgieron santos como Rosa de Lima (patrona de los católicos en Lima, en la Policía Nacional del Perú, en la República del Perú, en el continente americano y en las Filipinas) y Martín de Porres.

La capital peruana es sede de la Arquidiócesis de Lima, la cual fue establecida en 1541 como Diócesis y en 1547 como Arquidiócesis. Es una de las más antiguas de América. Actualmente la Arquidiócesis de Lima está a cargo del cardenal Juan Luis Cipriani. La ciudad también cuenta con dos mezquitas de la religión musulmana, tres sinagogas de la religión judía, un templo de La Iglesia de Jesucristo de los Santos de los Últimos Días ubicado en La Molina, una iglesia de la religión ortodoxa ubicada en el distrito de Pueblo Libre, cinco templos budistas y seis salas de oración de la Iglesia de Dios Ministerial de Jesucristo Internacional.

Según el XI Censo Nacional de Población y VI de Vivienda el 82,83 % de los limeños mayores de doce años declaró ser católico, mientras que el 10,90 % profesa la religión evangélica, el 3,15 % pertenecen a otras religiones y el 3,13 % no especifican ninguna afiliación religiosa. Una de las manifestaciones religiosas católicas más prominentes de la capital es la procesión del Señor de los Milagros, cuya imagen que data de la época virreinal sale en procesión por las calles de la ciudad en el mes de octubre de cada año. El Señor de Los Milagros fue nombrado Patrón de la ciudad por el Cabildo de Lima en 1715 y Patrono del Perú en 2010.

La ciudad concentra la mayor cantidad de museos de todo el país, tiene cerca de cincuenta museos, entre los cuales destacan el Museo Nacional de Arqueología, Antropología e Historia del Perú, que entre sus colecciones más importantes alberga una impresionante muestra de textiles precolombinos, el Museo Nacional de la Cultura Peruana y el Museo Arqueológico Rafael Larco Herrera, situado dentro de una mansión virreinal y que presenta entre sus atractivos más destacados una fina colección de oro y plata del antiguo Perú, la famosa colección de arte erótico y los depósitos donde los visitantes pueden apreciar 45 000 objetos arqueológicos debidamente clasificados.

Ambos museos están ubicados en el distrito de Pueblo Libre y están conectados por una línea azul peatonal que facilita su visita en conjunto. En Miraflores se puede visitar la Sala Museo Oro del Perú en Larcomar, la cual tiene una colección de objetos de oro precolombino. No solo se encuentran museos dedicados a exponer las manifestaciones de la cultura precolombina peruana, sino que existen además museos de arte, de historia natural, de ciencias, religiosos y temáticos. Destacan el Museo de Arte de Lima, el Museo de Arte Italiano, el Museo de Historia Natural, el Museo de la Electricidad y el Museo Postal y Filatélico del Perú. También se pueden visitar algunas colecciones privadas abiertas al público como el Museo Oro del Perú y Armas del Mundo.

El principal deporte practicado en la capital es el fútbol, al igual que en el resto del país. A mediados del siglo XIX comenzaron a surgir los primeros equipos de fútbol en el Perú, que dieron lugar a la posterior organización de clubes de fútbol o a la inclusión de este deporte en clubes ya formados. La Liga Peruana de Fútbol fue creada oficialmente el 27 de febrero de 1912 y en un inicio solo contaba con equipos de la ciudad de Lima que eran reforzados con futbolistas "chalacos". En la actualidad, cinco equipos de la capital participan en la Primera División del Perú: Alianza Lima, Deportivo Municipal, Sporting Cristal, Universidad de San Martín de Porres y Universitario de Deportes.

Alianza Lima, Sporting Cristal y Universitario de Deportes son considerados como los equipos más importantes del país, por lo que se les conoce como los tres grandes del fútbol peruano. Entre estos clubes se disputan tradicionalmente el superclásico y el clásico moderno, y en conjunto son los más populares del país. El principal recinto deportivo para la práctica de este deporte es el Estadio Nacional del Perú, inaugurado en 1952 y que cuenta con una capacidad máxima para 55 000 espectadores. Otros estadios de fútbol de importancia son: el Estadio Alejandro Villanueva, el Estadio Monumental, el Estadio Municipal de Chorrillos, el Estadio de la Universidad Nacional Mayor de San Marcos y el Estadio Alberto Gallardo.

Otros deportes menos practicados en la ciudad, pero no por ello de menos importancia, son: atletismo, bádminton, ciclismo, equitación, fútbol sala, golf, karate, paleta frontón, parapente, rugby, squash, surf, tenis, tenis de mesa, tiro, triatlón, vela y voleibol. Para la práctica de estos otros deportes la ciudad cuenta con: el Coliseo Mariscal Cáceres (propiedad del Ejército Peruano), el Coliseo Eduardo Dibós, el Coliseo Amauta, el Campo de Marte (propiedad del Instituto Peruano del Deporte), el Club de Tenis Terrazas de Miraflores, el Los Inkas Golf Club, el Club Lawn Tenis de la Exposición (sede del Equipo de Copa Davis del Perú), el Lima Golf Club, el Lima Cricket and Football Club y el Estadio de Atletismo de la Villa Deportiva Nacional. También es destacable el hecho de contar en la propia ciudad con siete campos de golf , con el Hipódromo de Monterrico en el distrito de Santiago de Surco (propiedad del Jockey Club del Perú)y el Complejo Deportivo Villa María del Triunfo.

La ciudad ha albergado diversos eventos de importancia, en Lima se disputaron cinco ediciones de la Copa América (1927, 1935, 1939, 1953, 1957 y 2004); además de los Campeonatos Sudamericanos Sub-17 de 1986 y 1995, el Campeonato Sudamericano Sub-20 de 1975, el Campeonato Sudamericano Femenino de 2003 y la Copa Mundial de Fútbol Sub-17 de 2005.

En enero de 2009, se realizó en Lima la primera fecha del World Qualifying Series de Surf, y en noviembre del mismo año se llevó a cabo la sexta fecha del ASP World Tour en la rama femenina. En 2014 se llevaron a cabo los ISA World Surfing Games. Con respecto al baloncesto, fue sede del Campeonato Mundial Femenino de 1964 y de los Campeonatos Sudamericanos de 1938 y 1943.

En cuanto al voleibol, la capital peruana albergó el Campeonato Mundial de Voleibol Femenino de 1982, el Campeonato Sudamericano de Voleibol Femenino en tres ocasiones (1961, 1977 y 1997), el Campeonato Mundial de Voleibol Femenino Sub-20 en 1989 y 2011, el Campeonato Mundial de Voleibol Femenino Sub-18 de 2015, el Campeonato Sudamericano de Voleibol Masculino en 1961 y 1977, el Campeonato Sudamericano de Voleibol Femenino Sub-20 de 2008 y 2012, y el Campeonato Sudamericano de Clubes de Voleibol Femenino en tres oportunidades (2009, 2010 y 2013), además de otros torneos internacionales como la Copa Federación, la Copa Final Four, la Copa Latina, la Copa Panamericana, la Copa Panamericana Sub-23 y la Copa Panamericana Sub-20.

En la ciudad de Lima, entre las numerosas instalaciones públicas y privadas para la práctica de diversos deportes destacan por su importancia social las que tienen acondicionados escenarios para espectáculos deportivos (y eventualmente, artísticos) con capacidad para albergar a miles de espectadores. De las nacionales, las más grandes y representativas son el Estadio Nacional del Perú (perteneciente al Instituto Peruano del Deporte) para 55 mil asistentes, y el Estadio de la Universidad Nacional Mayor de San Marcos. De las privadas o particulares, resaltan el Estadio Monumental (del Club Universitario de Deportes) para 80 mil asistentes, el Estadio Alejandro Villanueva (del Club Alianza Lima) para 34 mil asistentes, el Estadio La Unión (del AELU) para 10 mil asistentes, el Hipódromo de Monterrico (del Jockey Club del Perú) para 8 mil asistentes, el Estadio Lolo Fernández (del Club Universitario de Deportes) para 4 mil asistentes, el Estadio Caballeros del Deporte (del Country Club El Bosque) para 3 mil asistentes, el Coliseo de Tenis (del Club Tenis Las Terrazas) para 2500 asistentes, el Estadio de fútbol del Club Regatas Lima para 2 mil asistentes, y el Coliseo de Básquet y Voley del Club Regatas Lima.

En la ciudad también se han realizado en varias ocasiones diversos campeonatos sudamericanos de atletismo, natación, rugby y tiro. En los últimos meses del año se lleva a cabo el Challenger de Lima. Con relación a competencias multidisciplinarias, fue sede de los en 1947, de los IV Juegos Sudamericanos en 1990, de los I Juegos Bolivarianos de Playa en 2012 y de los I Juegos Suramericanos de la Juventud en 2013. En 2012, la última etapa del Rally Dakar finalizó en Lima, y en 2013, fue el punto de partido de dicho rally. Asimismo en 2019 fue sede de los Juegos Panamericanos y Parapanamericanos..

El hermanamiento de ciudades es un concepto por el cual pueblos o ciudades de distintas zonas geográficas y políticas se emparejan para fomentar el contacto humano y los enlaces culturales. El 12 de octubre de 1982 la ciudad de Lima se unió a la mediante la firma de una declaración de hermanamiento múltiple y solidario de todas las capitales de iberoamérica. También pertenece a la red de Mercociudades. Actualmente Lima se encuentra hermanada con:





</doc>
<doc id="1641" url="https://es.wikipedia.org/wiki?curid=1641" title="La llamada de Cthulhu">
La llamada de Cthulhu

La llamada de Cthulhu ("The Call of Cthulhu" en inglés) es un relato corto en estructura de "novelette" escrito por H. P. Lovecraft en el año 1926. La obra fue publicada por primera vez en febrero de 1928 por la editorial de "pulp" "Weird Tales". Cthulhu hace su primera aparición en este relato, convirtiéndose en una figura central del ciclo literario de los "Mitos de Cthulhu".

La historia está compuesta por dos narrativas principales vinculadas por una tercera, la voz del «autor». Solo el autor es capaz de interpretar correctamente lo sucedido y es consciente de la importancia de la información que tiene en su poder, y va narrándolo siguiendo el orden en que él mismo fue descubriendo la verdad.

Comienza con la muerte de un eminente profesor de la Universidad Brown, Providence, y el estudio de los documentos con los que estaba trabajando. Estos incluyen un informe sobre un ataque perpetrado por una secta. Una investigación sobre los miembros de la secta saca a la luz algunas pistas sobre la horrorosa criatura que veneran, Cthulhu. Este ser, que supuestamente llegó con sus seguidores extraterrestres desde las estrellas millones de años antes de la aparición del Hombre, ahora descansa en un sueño profundo en su ciudad sumergida, R'lyeh.

La segunda parte de la historia empieza con el cuaderno de bitácora del primer oficial de un barco que descubre la ciudad hundida, pues ésta ha emergido a la superficie en el Océano Pacífico. La ciudad emergió porque «las estrellas eran propicias» y el tiempo para el despertar de Cthulhu y sus engendros había llegado.

El relato propulsó los llamados mitos de Cthulhu, relatos y novelas basados en la idea de que ciertas criaturas de otros mundos, que vivieron en nuestro planeta en épocas remotas, desean reconquistar la Tierra.
Estas historias fueron un trabajo colectivo del denominado "Círculo de Lovecraft", formado por el mismo Lovecraft y otros escritores como Clark Ashton Smith, Robert E. Howard, Robert Bloch, August Derleth y Frank Belknap Long, entre otros, la mayoría de ellos amigos o conocidos de Lovecraft. 

Este relato también dio nombre a un popular juego de rol basado en los relatos del llamado "ciclo de los mitos de Cthulhu". El juego, titulado "La llamada de Cthulhu" ("Call of Cthulhu" en inglés), fue editado originalmente en Estados Unidos por Chaosium en 1981 y traducido al español por Joc Internacional en 1988.

Hay muchas referencias musicales sobre Cthulhu y los mitos, especialmente en el thrash metal:

Los escritos de H.P. Lovecraft también sirvieron de fuente de inspiración del juego para P.C. llamado del 2005. En este juego se respetó al máximo el espíritu de sus relatos, sumergiendo al jugador en un mundo oscuro y macabro, para descubrir la verdad sobre Dagón.

También, el videojuego de rol multijugador masivo en línea World of Warcraft basa uno de sus personajes (el Dios Antiguo C'Thun) en Cthulhu.

La Sociedad Histórica Lovecraft realizó una adaptación fílmica sobre el relato, que se estrenó a mediados del 2005: La llamada de Cthulhu.

La empresa desarrolladora de videojuegos Cyanide adaptó el juego de rol de mesa "La Llamada de Cthulhu" de 1981, elaborando un videojuego para un solo jugador en el género de rol y survival horror, lanzándolo el 30 de octubre de 2018 con el nombre de .



</doc>
<doc id="1644" url="https://es.wikipedia.org/wiki?curid=1644" title="Literatura en lengua inglesa">
Literatura en lengua inglesa

La literatura inglesa es toda aquella escrita en lengua inglesa, independientemente de la procedencia de sus autores. Bajo esta denominación se reúnen obras escritas en inglés antiguo, inglés medieval, inglés moderno e inglés contemporáneo, así como aquellas escritas en las variedades dialectales que el idioma actual tiene alrededor del mundo. 

Las primeras palabras en inglés, escritas en un dialecto anglo-sajón conocido como inglés antiguo, aparecieron en los inicios de la Edad Media. El texto más antiguo que se conoce es el himno de Caedmon. En esa época era muy importante la tradición oral y gran parte de los trabajos literarios se escribieron para poder ser representados. Los poemas épicos se hicieron muy populares y algunos, como Beowulf, han llegado hasta nuestros días.

Este idioma está muy relacionado con el actual idioma noruego y con el idioma islandés, por lo que los versos anglosajones fueron probablemente una adaptación de los primeros poemas de guerra vikingos y germánicos que llegaron desde el continente. Cuando esta poesía llegó a Inglaterra, aún se transmitía de forma oral de generación en generación; la presencia constante de versos aliterados, o rima consonante, ayudaba a que los anglosajones la recordaran con facilidad. 

La primera literatura escrita aparece en la época en la que San Agustín de Canterbury fundó los primitivos monasterios cristianos; se adaptó el lenguaje a las necesidades de los lectores cristianos. Incluso sin sus líneas más sangrientas, los poemas bélicos vikingos resultaban sanguinarios: en las narraciones existía siempre una sensación de inminente peligro. Tarde o temprano todo tenía su fin. Cuando Guillermo el Conquistador convirtió Inglaterra en parte del reino normando (en 1066), la poesía en inglés antiguo se siguió leyendo y el uso del idioma se extendió.

No fue hasta los inicios del , cuando Albión se convirtió en independiente y sus relaciones con Francia se volvieron más distantes, el momento en que el idioma empezó a cambiar. Mientras que los normandos quedaron asimilados dentro de la propia cultura, el francés penetró en las clases sociales más bajas, cambiando una parte importante de la gramática y el léxico del inglés antiguo. Aunque no se convirtió en una lengua romance, el inglés de Chaucer se parece más al idioma actual que al que se hablaba en Inglaterra un siglo antes. 

A finales del periodo medieval (1200-1500), los ideales del amor cortesanos llegaron a Inglaterra y los autores comenzaron a escribir romances, tanto en verso como en prosa. Fueron especialmente populares los temas relacionados con el rey Arturo y su corte. El poema Sir Gawain y el Caballero Verde muestra gran parte de las características de la literatura de esta época: situado en los tiempos del legendario Arturo, la obra pone énfasis en las conductas de los caballeros con insinuaciones religiosas. En esa época, las obras de misterio se representaban en pueblos y ciudades para celebrar las principales festividades; también se realizaban representaciones menos formales con temática religiosa.

El primer gran autor inglés, Geoffrey Chaucer (1340-1400), escribió en inglés medieval. Su obra más famosa es los Cuentos de Canterbury, una colección de historias de géneros dispares narrados por un grupo de peregrinos que viajan hacia Canterbury. Aunque Chaucer es un autor inglés, su obra estuvo inspirada por los cambios y desarrollos que tenían lugar en Europa, especialmente en Italia. Los Cuentos de Canterbury están claramente en deuda con el Decamerón de Giovanni Boccaccio. El Renacimiento se estaba abriendo paso en Inglaterra.

En 1476, William Caxton introdujo en Inglaterra la imprenta. A partir de ese momento, la literatura vernácula empezó a florecer. La Reforma Protestante inspiró la producción de una liturgia propia que llevó hasta el Libro de Oración Común, una influencia clave en la literatura en inglés. La poesía, el drama y la prosa que se escribieron durante los reinados de Isabel I y de Jacobo I constituyen lo que en la actualidad se denomina "Renacimiento inglés".

Durante este periodo, la literatura se caracteriza por un especial interés en el comportamiento humano como tema principal de las obras, en parte por influencia del humanismo italiano. Mientras que la literatura medieval inglesa se nutría de temas religiosos, durante el renacimiento los escritores se decantaron por temas más seculares.

La Era isabelina fue testigo del florecimiento de la literatura, especialmente el drama: produciendo el llamado teatro isabelino. El renacimiento italiano redescubrió a los clásicos del teatro griego y romano que empezaron a desplazar los temas místicos tratados en las obras escritas durante la Edad Media. Los italianos estuvieron especialmente influenciados por Séneca y Plauto. Los escritores ingleses se interesaron por las obras italianas; algunas compañías de actores se instalaron en Londres y otro italiano, Giovanni Florio, se encargó durante esta época de llevar parte de la cultura y el idioma italiano hasta Inglaterra. 

Durante este periodo hizo su aparición el escritor William Shakespeare. Sin ser un hombre de letras y con una educación que se cree fue limitada, Shakespeare se convirtió en uno de los escritores más versátiles del momento que fue capaz de remover los cimientos de la escena inglesa. Sus últimas obras, escritas durante los inicios del reinado de Jacobo I, están consideradas por los críticos como sus composiciones más magistrales: "Hamlet", "Otelo", "El rey Lear", "Macbeth", "Antonio y Cleopatra" y "La Tempestad". Shakespeare popularizó también los sonetos ingleses que significaron un profundo cambio en relación con el modelo de Petrarca.

Thomas Wyatt introdujo el soneto en Inglaterra a principios del . Los poemas escritos para ser musicados, como los que escribió Thomas Campion, se hicieron populares y la literatura impresa empezó a llegar hasta numerosos hogares. Dentro del teatro de la era isabelina hay que destacar a escritores como Christopher Marlowe, Thomas Dekker y Francis Beaumont. Marlowe, que nació unas pocas semanas antes que Shakespeare, estuvo fascinado y aterrorizado a la vez por las nuevas fronteras que la ciencia moderna estaba abriendo, lo que le inspiró a escribir su obra "The Tragical History of Doctor Faustus" que trata sobre un científico obsesionado por el conocimiento y que desea llevar los poderes tecnológicos del hombre hasta los límites más extremos. Tras obtener poderes sobrenaturales, el protagonista de la obra consigue viajar en el tiempo y casarse con Helena de Troya pero termina sus días vendiendo su alma al diablo.

A finales del , la poesía inglesa se caracterizaba por un lenguaje elaborado y por sus alusiones a los temas de la mitología clásica. Entre los poetas más destacados del periodo se incluyen a Edmund Spenser y Philip Sidney.

Tras la muerte de Shakespeare, el poeta y dramaturgo Ben Jonson se convirtió en la figura más destacada de la literatura. Sin embargo, la estética de Jonson recordaba más a la de la Edad Media que a la Tudor: sus personajes incorporan la teoría de los cuatro humores. Según esta teoría médica, las diferencias en el comportamiento humano proceden del predominio de uno de los cuatro humores del cuerpo (sangre, flema, bilis negra y bilis amarilla); estos humores se corresponden con los cuatro elementos del universo: aire, agua, fuego y tierra. Jonson mostró estas diferencias hasta un punto en el que llegó a crear prototipos que se correspondían con cada uno de los humores predominantes; Shakespeare por el contrario, había abandonado ya está teoría clásica para dar paso a la psicología moderna.

Entre los autores que siguieron el estilo de Jonson destacan John Fletcher y Francis Beaumont que, aunque no tenían el talento de Shakespeare, escribieron una brillante comedia, "The Knight of the Burning Pestle" (1613), una parodia de la clase media, especialmente de esos nuevos ricos que fingen tener un gran gusto literario cuando en realidad saben muy poco de literatura. 

Otro estilo teatral que se hizo muy popular durante la época jacobina fueron las obras de venganza, popularizadas por John Webster y Thomas Kyd. George Chapman escribió también un par de tragedias de este estilo aunque se le recuerda especialmente por la traducción que realizó de las obras de Homero que resultaron de gran influencia para la literatura inglesa; sirvieron incluso de inspiración a John Keats para escribir algunos de sus poemas más destacados.

La Biblia del Rey Jacobo, uno de los proyectos de traducción más importantes en la historia de Inglaterra, se inició en el 1604 y no se completó hasta el 1611. Representa la culminación de la tradición de realizar traducciones de la Biblia al inglés que se inició con el trabajo de William Tyndale. La obra se convirtió en la Biblia estándar para la iglesia de Inglaterra y está considerada por algunos como una de las mayores obras de la literatura de todos los tiempos. Este proyecto estuvo liderado por el propio rey Jacobo I que supervisó el trabajo de 47 estudiosos. Aunque se han realizado otras traducciones al inglés, más precisas, la Biblia del Rey Jacobo sigue destacando por su estética, ya que su métrica se realizó de modo que intentaba imitar el verso hebreo de la versión original. En la historiografía destacó la magna obra de Richard Knolles, "The General History of the Turks", publicada en 1603, en un estilo ornamentado muy característico de la época, y altamente reputada a lo largo de la historia de la literatura inglesa. 

Además de Shakespeare, que destacó en los inicios de la década de 1600, los principales poetas de los inicios del siglo incluyen a John Donne y otros poetas metafísicos. Influenciados por el barroco, y tomando como temas centrales el misticismo cristiano y el erotismo, los poetas metafísicos utilizaron figuras "no poéticas" para conseguir un efecto sorpresa en el lector. Por ejemplo, en uno de los sonetos de John Donne, la punta de un compás representa a dos amantes; la mujer, que está en casa esperando, es el centro. El punto más alejado es su amante que se encuentra navegando, alejándose de ella. Pero, a mayor distancia, más estrecha la unión superior entre las puntas del compás: la distancia hace que el amor se haga más fuerte. 
Además de los poetas metafísicos, el es famoso por su poesía barroca. Esta poesía es similar al estilo artístico del mismo nombre: elevada, épica y religiosa. Muchos de los poetas que cultivaron este estilo tenían una especial sensibilidad católica y escribieron sus poesías para apoyar la contra reforma católica; pretendían crear un sentimiento de supremacía y misticismo que hiciera que los lectores protestantes regresaran hacia el catolicismo.

El turbulento periodo de mediados del , durante el reinado de Carlos I, la subsecuente Commonwealth y el Protectorado, fue testigo del nacimiento de la literatura política. Los panfletos escritos por los simpatizantes de cada una de las facciones que se organizaron durante la guerra civil, iban desde los ataques personales escritos de forma visceral hasta las diversas formas de propaganda, pasando por esquemas que buscaban una forma de reformar la nación. La obra de Thomas Hobbes "Leviathan" es uno de los trabajos más destacados en la filosofía política británica. Este periodo fue testigo también del nacimiento de los "libros nuevos", precursores de los periódicos, con periodistas como Henry Muddiman, Marchamont Needham o John Birkenhead que representaban los puntos de vista de las diversas partes en conflicto. Los continuos arrestos de los autores y la eliminación de sus trabajos, llevó a que se creara la idea de "licencia". La obra "Areopagitica", un panfleto político de John Milton, se escribió precisamente para oponerse a la idea de la licencia y está considerada como una de las más elocuentes defensas de la libertad de prensa escritas jamás.

El retiro forzado de los oficiales realistas tras la ejecución de Carlos I benefició a Izaac Walton ya que le permitió trabajar en su obra "The Compleat Angler". Publicado por primera vez en 1653, el libro, aparentemente una guía de pesca, es mucho más que eso: es un auténtico tratado sobre la vida, el tiempo libre y el placer. Los dos poetas más destacados del periodo de Oliver Cromwell fueron Andrew Marvell y John Milton; ambos produjeron obras que elogiaban al nuevo gobierno, como queda patente en la obra de Marvell "An Horatian Ode upon Cromwell's Return from Ireland". A pesar de sus creencias republicanas, consiguieron salir impunes de la Restauración de Carlos II tras la que Milton escribió algunos de sus poemas más destacados en los que los mensajes políticos se presentaban camuflados en forma de alegoría. Thomas Browne fue otro de los escritores destacados de la época; escribió sobre temas científicos, religiosos, médicos y esotéricos.

La literatura de la Restauración incluye obras tan dispares como "El paraíso perdido" de John Milton, "Sodoma" de John Wilmot, la comedia de William Wycherley "La esposa del campo" o "El progreso del peregrino" de John Bunyan.

La censura y el moralismo radical existentes durante el régimen puritano de Cromwell provocaron una ruptura en la cultura literaria; durante la Restauración, todas las formas literarias experimentaron un renacimiento. Durante el interregno, las fuerzas realistas de la corte de Carlos I estuvieron exiliadas junto al futuro Carlos II. La nobleza que viajó junto a Carlos pasó cerca de una década en medio de los escenarios europeos. El propio Carlos dedicó parte de su tiempo a asistir a diversas representaciones en Francia y desarrolló un gusto especial por las comedias españolas. 

La forma poética más destacada fue la sátira. En general, las sátiras se publicaban de un modo anónimo para evitar problemas graves para el autor, como la "ley de difamación", o las iras de los nobles a los que se criticaba. John Dryden, por ejemplo, estuvo en el punto de mira de la nobleza por sospecharse que era el autor de "Satire on Mankind". Como consecuencia de este anonimato, muchos de estos poemas permanecieron inéditos y siguen siendo obras totalmente desconocidas.

Durante este periodo, la prosa estuvo dominada por los escritos cristianos aunque fue también en esta época cuando se iniciaron dos géneros que dominaron periodos posteriores: la ficción y el periodismo. Los temas religiosos se mezclaban a menudo con los políticos y económicos, al igual que los escritos económicos y políticos introducían aspectos religiosos. Thomas Sprat escribió en 1667 "History of the Royal Society of London" y mostró, en un único documento, las metas de la ciencia empírica. John Locke escribió durante la Restauración numerosas de sus obras filosóficas. El empirismo de Locke era un intento de entender las bases del conocimiento humano, buscando el modo que permitiera tomar las decisiones adecuadas. Estos métodos científicos llevaron a Locke a escribir su obra "Treatises on Government" que más tarde inspiró a los pensadores de la Guerra de la Independencia de los Estados Unidos. Al igual que Thomas Hobbes, Locke enfatizó en la naturaleza plástica del contrato social. Para una época en la que la monarquía absoluta se consideraba derrocada, se iniciaban los intentos de una democracia y se había restaurado una monarquía limitada, sólo se podía encontrar respuesta sentando unas bases flexibles para el nuevo Gobierno.

La Restauración moderó los estridentes escritos sectarios, aunque persistió el radicalismo. Autores puritanos como John Milton se vieron obligados a abandonar la vida pública, y los autores cuáqueros o anabaptistas que habían participado de un modo directo en el regicidio de Carlos I fueron parcialmente censurados. Los escritos violentos fueron condenados a la clandestinidad y algunos de los que habían servido durante el interregnum atenuaron sus posiciones políticas. El apoyo que recibió John Bunyan fue mayor que el de otros autores religiosos de la época. Su obra "El progreso del peregrino" es una alegoría de la salvación personal y una guía para la vida cristiana. En lugar de centrarse en la retribución divina, Bunyan escribió sobre cómo un individuo puede santificar su vida, manteniéndose alejado de las tentaciones del cuerpo y del alma. El libro está escrito con un estilo directo y muestra la influencia tanto del drama como de la biografía, así como la tradición alegórica mostrada ya por Edmund Spenser.




</doc>
<doc id="1647" url="https://es.wikipedia.org/wiki?curid=1647" title="Literatura rusa">
Literatura rusa

Con el término literatura rusa se alude no solo a la literatura de Rusia, sino también a la literatura escrita en ruso por miembros de otras naciones que se independizaron de la extinta Unión de Repúblicas Socialistas Soviéticas (URSS) o por emigrados que fueron acogidos en ella. Con la disolución de la URSS varias culturas y países han reclamado a varios escritores exsoviéticos que, sin embargo, escribían en ruso. La literatura rusa se caracteriza por su marcada profundidad con figuras claves para la literatura universal como Dostoievski o Tolstói, y empezó, como todas, en forma de tradición oral sin cultivo escrito hasta la cristianización de la Rus de Kiev en 989 y, con ésta, de un alfabeto adecuado para acogerla.

Los creadores de dicho alfabeto fueron los misioneros bizantinos Cirilo y Metodio; ellos tomaron distintas grafías de los alfabetos latino, griego y hebreo, e ingeniaron otras. Al principio el lenguaje escrito ruso usó dos sistemas gráficos —los alfabetos cirílico y glagolítico—; el glagolítico, supuestamente inventado también por Cirilo y Metodio, fue abandonado, y la literatura rusa tal como la conocemos actualmente se escribe y lee en alfabeto cirílico, en su modalidad denominada alfabeto ruso.

La tradición oral popular de los skomorojis (juglares) y skazíteles, una especie de bardos itinerantes llegados desde el Imperio bizantino o los países eslavos, se expresaba a través de las bylinas (cantos o canciones) que unían tradiciones populares paganas y eclesiásticas en forma de prosa rítmica acompañada del gusli. Las bylinas relatan hazañas de los bogatyrí que defendieron Rusia contra nómadas pechenegos y cumanos y contra varios monstruos fantásticos. Los héroes de bylinas más famosos son Ilyá Múromets (Ilyá de Múrom), Dobrynia Nikítich y Aliosha Popóvich ("Aliosha hijo de clérigo (pope)"). En la tradición oral también existen canciones populares y cuentos tradicionales rusos que empezaron a recogerse por escrito en el siglo XIX cuando Aleksandr Afanásiev los compiló en ocho volúmenes.

La antigua literatura rusa se compone de unas escasas obras maestras escritas en antiguo eslavo eclesiástico, en eslavo eclesiástico y en antiguo eslavo oriental. 

En el siglo XI todas las tribus de los eslavos orientales formaban parte de la Rus de Kiev. Una lengua única, el antiguo eslavo oriental, empezó a formarse con algunos dialectos territoriales. Solo en el siglo XIII, cuando la Rus de Kiev se fragmentó, el ruso, el ucraniano y el bielorruso empezaron un desarrollo independiente. Por eso estas tres naciones poseen un periodo común en la historia de sus literaturas. 

En la Edad Media en Rusia no hubo órdenes militares de caballería ni universidades hasta que se creó, ya en el siglo XVIII, la fundada por Mijaíl Lomonósov, ahora llamada Universidad Estatal de Moscú. Los centros de enseñanza en la Rusia medieval fueron los monasterios, pero, pese a todo, en la Rusia antigua había gente alfabetizada, tal y como demuestran los numerosos documentos de Nóvgorod conservados en corteza de abedul que datan de los siglos XI-XII: cartas, papeletas, notas, cédulas, ejercicios de alumnos, etc. El primer libro conocido en antiguo eslavo eclesiástico es el manuscrito sobre tablillas de madera cubiertas de cera "Códice de Nóvgorod" () o "Salterio de Nóvgorod", que contiene los salmos 75 y 76 (alrededor del año 1010). El "Evangeliario de Ostromir" fue manuscrito en eslavo eclesiástico sobre pergamino en 1056 o 1057.

A día de hoy, las obras en antiguo eslavo eclesiástico, eslavo eclesiástico y antiguo eslavo oriental requieren ser traducidas al idioma ruso actual debido a su evolución y sucesivas reformas tanto del alfabeto cirílico en Rusia como de los tipos de letra de imprenta, incluida la reforma emprendida por Pedro I de Rusia en 1708 que introdujo el llamado "tipo de letra civil" (Гражданский шрифт). Todavía sobreviven unas pocas obras de la antigua literatura rusa, así como gran número de manuscritos deteriorados por los efectos de múltiples invasiones y guerras. Estas obras, de elaboración manuscrita, eran generalmente anónimas. Solía existir en esa antigua literatura rusa la temática recurrente de la glorificación de la belleza y del poder ruso, la denuncia de la autocracia de los y la defensa de los principios morales.

Puede decirse que existía un sistema propio de géneros literarios dividido principalmente en dos grandes grupos: literatura secular y literatura eclesiástica. En ellos encontramos los siguientes subgrupos:



Es difícil clasificar estas obras bajo un único género -muchas crónicas no son homogéneas, ya que contienen partes pertenecientes a todos los géneros anteriormente mencionados- narraciones históricas, leyendas históricas, extractos de tratados de intención propagandística e incluso piezas hagiográficas.

El primer periodo de la literatura rusa, constituido sobre todo por la obra de clérigos de principados rusos que escribían en una lengua llamada eslavón o eslavo eclesiástico, y aristócratas consagrados a la guerra, que escribían en antiguo eslavo oriental, que no se debe confundir con el eslavón, es denominado "Período de Kiev", y llega hasta 1240. Se trata fundamentalmente de hagiografías y poemas épicos. 

La literatura rusa del periodo está sometida a la influencia de literatura bizantina. Son obras eclesiásticas importantes diversas traducciones: el "Evangeliario de Ostromir" (1056) y los "Florilegios" (extractos de Padres de la Iglesia, vidas de santos, preceptos morales) compuestos en el siglo XI por el príncipe Sviatoslav II de Kiev, obras de Basilio el Grande, Juan Malalas, Juan Crisóstomo. Las traducciones de textos profanos incluyen la "Novela de Alejandro", fundada en la historia de Alejandro Magno, y "Acción de Devgenis" (Digenis Acritas) ("Devgénievo deyánie"), cantares de gestas militares, "Physiologus".

Los trabajos más importantes originales de la antigua literatura rusa son: 


De 1240 a 1480 la literatura rusa ralentizó su crecimiento a causa de la invasión mongola de la Rus de Kiev en 1223, que provocó la decadencia de la Rus de Kiev junto con el surgimiento de nuevos centros culturales como Nóvgorod. Se escriben relatos militares en prosa rítmica, como el anónimo "Canto del desastre de la tierra rusa" ("Slovo o poguíbeli zemlí Rússkoi") (siglo XIII) (en esta obra lírica y trágica el autor anónimo se lamenta por el destino de Rusia, pisoteada por los mongoles de Batu Kan y hace un llamamiento a los príncipes rusos para que se unan y repelan al enemigo), o el "Ciclo de Kulikovo" ("Zadónschina", "Cantar de allende el Don") (finales del siglo XIV - siglo XV): cuatro relatos que evocan la gran derrota de los mongoles en 1380. El "Ciclo" da fama a la Batalla de Kulikovo y tiene semejanza con el "Cantar de las Huestes de Ígor". 

Las obras eclesiásticas del periodo más destacadas son: 




A partir del reinado de Iván III de Rusia - quien en 1480 puso fin a la relación de vasallaje que el Principado de Moscú mantenía con la Horda de Oro, siendo el primer en adoptar el título de «Soberano de toda Rusia» - Moscú se convierte en el centro cultural. Los avances del laicismo renacentista en el siglo XV provocan turbulentos conflictos religiosos y políticos que generaron una amplia literatura polémica en prosa (obras por Nil Sorski - también llamado Nil del Río Sora - e Iósif Vólotski (Iósif de Volokolamsk) y sus respectivos adeptos. Iósif Vólotski intenta imponer la Iglesia sobre el Estado abogando por ampliar su poder y su riqueza. Nil del Río Sora, por el contrario, propone que la iglesia y los monjes renuncien a la riqueza secular y se reorganice la vida de los clérigos según los ideales cristianos de pobreza, trabajo y simplicidad. 

Dentro de la "literatura laica" destaca el "Viaje más allá de los tres mares" ("Viaje allende los tres mares"; "Jozhénie za tri mórya") por Afanasi Nikitin. Fue este un mercader, viajero y escritor que, en el siglo XV, descubrió la India a los rusos viajando a ella desde la ciudad de Tver. El viaje se desarrolló entre 1466 y 1472 y lo forman las notas de sus impresiones y observaciones que tomó durante su itinerario.

La literatura eclesiástica del siglo XVI continúa la tradicional disputa entre Nil del Río Sora y Iósif de Volokolamsk; esta literatura polémica y propagandística está representada por las obras de Maximus el Griego (Miguel Trivolis) (1480-1556), un seguidor de Nil del Río Sora. Su obra principal es "Amplia relación de las desgracias acaecidas a causa del desorden y excesos de los zares y autoridades contemporáneas" ("Slovo, prostranne izlagáyuschee s zhálostiyu nestroéniya i bezchíniya zaréi i vlastéi poslédnego zhitiyá") (1534-1539). En esta obra Máximus el Griego denuncia las crueldades, indolencias y otros pecados de los gobernantes rusos, los zares, reclama un régimen justo y sabio y explica el deber y los principios morales que han de regir la conducta del príncipe que dirija el estado. Por primera vez, en la historia de Rusia, Maximus el Griego escribe que el zar es el responsable del destino de su país y de sus súbditos, de forma que puede ser llamado a capítulo.
En 1553-1564 la impresión de libros llegó a Rusia. El primer impresor ruso fue Iván Fiódorov, quien desarrolló su labor en Moscú a invitación de Iván IV. El primer libro ruso impreso fue el "Apóstol" (1564); la aparición de la imprenta fue un acontecimiento importantísimo para el desarrollo y difusión de la literatura y la cultura en Rusia. 

El soberano Iván IV de Rusia fue también un escritor notable. Su obra más destacada es "Epístolas al príncipe Andréi Kurbski". Este personaje había desertado durante la Guerra Livona al Gran Ducado de Lituania y acusaba a Iván IV de ser un tirano en varias epístolas que dirigió a su exsoberano. Iván IV le respondió que los enemigos auténticos del Estado eran los boyardos, que intentaban dividir Rusia en pequeños principados. La polémica se prolongó durante dos décadas, pero Iván IV también dejó escrita su opinión sobre el estilo de la lengua escrita en este periodo y compuso además algunos poemas y cánones musicales de tema eclesiástico.
La literatura profana o laica del siglo XVI se ve representada por las obras siguientes:
• El "Domostrói" (siglo XVI), atribuido al arcipreste Silvestre, confesor de Iván IV de Rusia. "Domostrói" reúne las diversas normas que regulaban la vida corriente de una familia rusa de este periodo. En el libro se trata del deber de un ciudadano respeto al zar y la iglesia. El hombre debe ser cabeza de familia y responsable de la vida de todos sus allegados y de la verdadera educación cristiana de los mismos. El "Domostrói" proclama que la mujer se halla subordinada enteramente al marido y recomienda castigar los casos de mala conducta con castigos físicos o corporales. También es una enciclopedia doméstica que estatuye cómo debe administrarse una hacienda ejemplar o cómo realizar los trabajos caseros. En el siglo XIX la palabra "domostrói" pasó a denotar en ruso todo lo que había de atrasado y anticuado en la vida familiar. 

• "Historia de un joven y una joven" ("Póvest o Petré y Fevróni") por Ermolái-Erast (mitad del siglo XVI). La "Historia" mezcla hagiografía y la novela sentimental. Algunos hombres de ciencia opinan que se trata de la primera novela por completo profana en la literatura rusa. 

No se cultiva otra lírica que la de tema sacro, y la forma usada sigue siendo la prosa rítmica utilizada en narraciones militares como el anónimo "Relato de la toma de Pskov" ("Pskóvskoye vziatie") (1510).

Durante el siglo XVII tuvo lugar un acontecimiento trascendental para la historia y cultura de Rusia: un cisma en la Iglesia Ortodoxa rusa. En 1652 el patriarca Nikon reformó la liturgia y ritos de la Iglesia ortodoxa rusa para adecuarlos a la iglesia ortodoxa griega contemporánea. Esta reforma supuso también una subordinación mayor del estamento eclesiástico al Estado, lo que impulsó una fuerte y tenaz resistencia por la parte del pueblo que fue más tarde denominada "Viejos creyentes", autores del cisma religioso. En este periodo la obra literaria más importante es la autobiografía del "viejo creyente" Avvakum, excomulgado por el sínodo de Moscú y condenado a morir en la hoguera en Pustozersk. Se la conoce por el título de "Vida del arcipreste Avvakum" (1672-1675). 

También destacan en este periodo las anónimas narraciones costumbristas "Relato del Dolor y Mala Suerte" ("Póvest o gore i zloschasti") (segunda mitad del siglo XVII), "Relato de Savva Grudtsyn" ("Póvest o Sávve Grúdtsyne") (1670) y la satírica "Relación del juzgado de Shemyaka" ("Póvest o Shemiákinom sudé") (siglo XVII). 

La literatura rusa del periodo se halla sometida ya al influjo de la literatura occidental. En 1569 Rusia occidental queda bajo la influencia de Polonia y la cultura de esta nación ejerce un cierto influjo. A la muerte de Iván IV de Rusia se dio comienzo a una época de guerras civiles conocida como Período Tumultuoso. Diversas guerras se suceden: la de la Comunidad Polaco-Lituana contra Rusia, la de las Dimitríadas (1605-1606), la de Ingria y la Guerra de Smolensk; de todo este caos surgió como zar ruso de hecho Vladislao IV Vasa, quien gobernó entre 1610 y 1612. 

En Ucrania, la Rebelión de Jmelnytsky condujo a la desintegración de la Mancomunidad polaco-lituana. La sublevación liberó a los cosacos de Zaporozhia del dominio polaco que prefirieron aliarse con el Zarato ruso. Bohdán Jmelnytsky, el atamán de los cosacos de Zaporozhia, acordó con Alejo I de Rusia un tratado de protección, el Tratado de Pereyáslav (1654), y desde entonces Ucrania establece relaciones más estrechas con Rusia. Por intermedio de la literatura ucraniana y bielorrusa, llegan a Rusia algunas obras de géneros y autores occidentales, como las cuentecillos cómicos del "Liber facetiarum" del humanista Poggio Bracciolini, biografías de césares romanos, novelas caballerescas, novelas picarescas, novelas de aventuras, misceláneas y poemas polacos eran retraducidos y rusificados desde las versiones en lengua polaca y bielorrusa. 

El verso aparece en pleno XVII con Simeón Pólotski (1629-1680) por influjo de la literatura polaca. Esto escinde la métrica rusa en dos artes, una de prosa métrica rítmica, popularizante y sentida como más nacional, y otra más parecida a la occidental y considerada más culta. Destacan en este periodo "El jardín multicolor" ("Vertograd Mnogotsvetny") (1677-1678) de Simeón Pólotski (1629-1680) y el "Epitafio" ("Epitafion") de Silvestre Medvédev (1641-1691).

Simeón Pólotski fue también el fundador del teatro ruso. El escribió y puso en escena la "Comedia de la parábola del hijo pródigo" ("Komedia pritchi o blúdnom syne") y "Del zar Nabucodonosor" ("O Navujodonósore zaré") (1673-1678), en el teatro de la corte de Alejo I de Rusia, quien era un gran aficionado de teatro.

En el siglo XVIII Rusia se occidentalizó y secularizó bajo el cetro de hierro de Pedro I de Rusia. Puede decirse que la literatura profana o laica comienza verdaderamente en Rusia con este siglo. Pedro I en persona revisó y reformó el alfabeto ruso eliminando letras en desuso, simplificó el sistema ortográfico haciendo la lectura más accesible, así como modificó el tipo de letra de imprenta introduciendo el llamado "tipo de letra civil" (Гражданский шрифт). 

Al igual que en las demás literaturas occidentales de este siglo, la Ilustración entró en la cultura rusa, que tuvo en este siglo su periodo clásico. Este Clasicismo tuvo sus pilares en el dominio de la razón y la experiencia, por lo que el período se conoce también como "Siglo de las Luces" o "Siglo de la razón". 

El primer escritor notable del siglo XVIII es Antioj Kantemir (1708-1744), hijo de Dmitri Kantemir. Fue importante poeta satírico y su obra maestra es la sátira en verso "A mi parecer: sobre aquellos que culpan a la educación" ("Na julyáschij uchenie" - 1729), contra aquellos que querían aniquilar el legado cultural de Pedro I y otras nueve sátiras. 

La principal polémica literaria de este siglo se produjo entre Vasili Trediakovski y Mijaíl Lomonósov acerca de la poesía y las técnicas de versificación en idioma ruso. Vasili Trediakovski (1703-1769), poeta y traductor, publicó en 1735 su obra teórica titulada "El nuevo y conciso método de composición de versos rusos" ("Novi i kratki spósob k slozhéniyu stijov rosíyskij"). En oposición al verso silábico tradicional (véase ) empleado, por ejemplo, por Antioj Kantemir, introdujo las bases del verso silábico-acentual (véase ) así como los pies denominados troqueo (_U) y yambo (U_).

Mijaíl Lomonósov (1711-1765) en su "Ensayo sobre la métrica de la versificación rusa" ("Pismó o právilaj rossíyskogo stijotvórstva") de 1739 introdujo tres tipos de ritmos o pies: el dactílico (_UU), el anfibráquico (U_U) y el anapéstico (UU_), así como las rimas llanas y esdrújulas. 

El científico Mijaíl Lomonósov se considera el fundador de la literatura rusa moderna al establecer las normas que habían de regir el buen gusto del ruso literario; distingue tres estilos, el noble, de vocabulario eslavón para el poema épico, la tragedia y la oda; el medio para la sátira y los dramas y el vulgar (con vocabulario popular) para la comedia y la canción. Escribió odas sacras, panegíricos y una "Epístola sobre la utilidad del vidrio" (1752). 

El teatro ruso recibió un gran impulso también. Los dramaturgos más destacados del siglo fueron Aleksandr Sumarókov (1717-1777), Mijaíl Jeráskov (1733-1807), y, sobre todo, Denís Fonvizin. 

La obra más importante de Aleksandr Sumarókov es la tragedia "Jórev" (1747), aunque escribió otras ocho, 13 comedias, 3 libretos de ópera y también algunos versos. 

Se estima que la obra maestra de Mijaíl Jeráskov es su poema épico "Rossiada" (1778), pero también compuso 9 tragedias, 2 comedias y 5 dramas para el teatro entre 1758 y 1807. 

Otros escritores notables del periodo son poetas Iván Jémnitser (1745–1784), Vasili Kápnist (1758–1823), Iván Dmítriev (1760–1837), y el dramaturgo Yákov Kniazhnín (1742 (1740?) – 1791). 

Denís Fonvizin (1745-1792) es un brillante comediógrafo que además obtuvo importantes éxitos y reposiciones, ganando en su misma época una gran popularidad. Sus mejores y más celebradas comedias son "El Brigadier" ("Brigadir") (1768) y "El menor" ("Nédorosl") (1782). Estas piezas ridiculizan la vanidad, la galomanía o copia irreflexiva de todo lo francés y la pereza y atraso de los hacendados, así como su avidez, glotonería y brutalidad; muchas citas de sus obras se transformaron en frases proverbiales y se emplean incluso en la lengua rusa de hoy en día. 

La zarina Catalina II de Rusia también poseía talento literario y escribió algunas piezas de teatro, por ejemplo "O tempora!" ("O vremia"), "El engañador" ("Obmánschik"), "Un seducido" ("Obolschonny"), "Chamán de Siberia" ("Shamán Sibirski") y algunas piezas más. Además elaboró con buen estilo unas inteligentes "Memorias". 

En cuanto a la lírica, destacan Derzhavin y Karamzín.

Gavrila Derzhavin (1743-1816) fue influido por Lomonósov y Sumarókov y se interesó por los conatos renovadores de Jeráskov; amante de las formas clásicas, su aliento lírico es sincero. Se recuerdan sus obras "Felitsa" (1782), "Díos" (1784), "¡Resuene el trueno de la victoria!" ("Grom pobedy, razdavaysya!", himno no oficial del Imperio ruso) (1791), "La cascada" (1798) y "La Vida en Zvansk" ("Zhizn Zvánskaya") (1807). Derzhavin también experimentó con diferentes tipos ritmos y rimas, sonidos e imágenes.
El masón Nikolái Karamzín (1766-1826) reformó la lengua literaria introduciendo muchos galicismos y suprimiendo elementos eslavones, con lo que abrió una cierta distancia entre el ruso culto y el popular. Fue también un importante historiador y modernizó la poesía rusa. Gracias a Karamzín, la novela sentimental rusa se desarrolló a partir del siglo XVIII. Sus obras maestras son "Pobre Liza" ("Bédnaya Liza", la primera novela sentimental en la literatura rusa) (1792), "Las cartas de un viajero ruso" ("Pisma rússkogo puteshéstvennika") (1791-1792) y la "Historia del Estado ruso" ("Istóriya gosudarstva Rossíyskogo") (1816-1825), donde por primera vez se intenta hacer la historia de Rusia con el rigor crítico y el método de la historiografía científica. 

Una más señalada manifestación poética en la literatura rusa del siglo XVIII es la obra "revolucionaria" de Aleksandr Radíshchev (1749-1802) "Viaje de San Petersburgo a Moscú" ("Puteshestvie iz Peterburga v Moskvú") (1790). En ese libro simpatizó con los siervos campesinos describiendo su vida miserable y denunciando el trato inhumano con que las autoridades y los hacendados los trataban; utilizó la compasión como un medio de revolución y transformación social.

En el siglo XVIII aparecieron las primeras revistas literarias rusas publicadas por Nikolái Novikov.

El siglo XIX es conocido tradicionalmente como “El Siglo de Oro” de la literatura rusa. Tanto la poesía como la prosa llegaron a su apogeo. A principios de siglo la corriente principal de la literatura rusa era el Romanticismo, aunque más tarde sería el realismo literario el que alcanzaría mayor importancia.

La vida literaria de la primera mitad del siglo XIX era muy animada y variada. La sociedad rusa de la época estaba profundamente influida por las guerras napoleónicas y la victoria de Rusia en la 
primera Guerra Patriótica de 1812. Las amplias capas de la población experimentaban el auge del patriotismo y se interesaban por las ideas de la revolución francesa. En esta época aparecieron diversas revistas políticas y literarias: "El Mensajero de Europa" (Karamzín), "La Estrella Polar" (Ryléyev), "El Contemporáneo" (Pushkin) y, algo más tarde, "El Telégrafo de Moscú" (Polevói), "El Telescopio" (Nadezhdin), etc. La vida espiritual de la época ejercía influencia en las principales corrientes literarias. El romanticismo en Rusia se desarrolló de dos maneras diferentes: el supuesto romanticismo progresivo representado por Kondrati Ryléyev, Wilhelm Küchelbecker, Aleksandr Bestúzhev (Marlinski), Aleksandr Odóyevski, Denís Davýdov (un héroe de la Guerra Patriótica de 1812), Nikolái Yazýkov, Dmitri Venevítinov y Yevgueni Baratynski. Los temas principales de su poesía son algunos de los acontecimientos claves en la historia rusa, la libertad, el patriotismo y algunos motivos folclóricos rusos. El golpe más duro para las aspiraciones idealistas del romanticismo progresivo fue asestado por la derrota en la rebelión de los decembristas en 1825, como resultado de la cual muchos participantes de la rebelión, como miembros de las familias nobles de Rusia, poetas y figuras públicas, fueron ejecutados o deportados a Siberia. El romanticismo pasivo o tradicional se encuentra representado por las obras de Vasili Zhukovski. Asimismo, hay una auténtica lucha entre eslavófilos y occidentalistas.

Aleksandr Pushkin se alza sobre todos los otros poetas rusos. Poseía un genio universal; reformó la lengua rusa literaria rompiendo con la tradición del siglo XVIII, escribía consumados poemas líricos, poemas épicos ("Poltava", "El jinete de bronce", "Eugenio Oneguin"), potentes obras dramáticas en versos ("Borís Godunov", "Pequeñas tragedias"), prosa brillante ("Cuentos del difunto Iván Petróvich Belkin", "La dama de picas", "La hija del capitán", "Dubrovski"), cuentos en verso ("Ruslán y Liudmila", "Cuento del zar Saltán", "Cuento de la princesa muerta y los siete caballeros"). Se convirtió en la figura central de la poesía rusa del siglo XIX, eclipsando a otros poetas, talentos que en otras circunstancias podrían haber sido el honor de cualquier literatura nacional. Influidos por Pushkin, una serie de poetas asumió su voz recién desaparecida: Antón Délvig, Piotr Pletniov, Piotr Viázemski, Pável Katenin y algunos otros, la llamada "Pléyade pushkiniana". 

Después de la trágica muerte de Pushkin la antorcha de la poesía rusa pasó a mano de Mijaíl Lérmontov. En sus primeros poemas imitó a Pushkin y a Byron, pero su estilo poético se afianzó enseguida, se percibe claramente en el cambio de temas como, por ejemplo, en el poema "La vela" en el que habla de un bienestar que sólo se consigue luchando. En otros poemas refleja con vehemencia el pensamiento y los sentimientos de los jóvenes estudiantes que se rebelan y muestran su indignación ante la situación del siervo, el rechazo del despotismo zarista y la apasionada aspiración por la libertad. Sus obras más destacadas son sus versos líricos, "Valerik", "Borodinó", "El demonio", "El novicio", el drama "El baile de máscaras", la novela "Un héroe de nuestro tiempo". 

Otros poetas notables de la primera mitad del siglo XIX son el fabulista Iván Krylov, el poeta y dramaturgo Aleksandr Griboyédov, los poetas Yevgueni Baratynski, Konstantín Bátiushkov, Alekséi Koltsov, Iván Kozlov, Piotr Yershov.

La prosa de la primera mitad del siglo XIX está representada por las novelas grandes de Pushkin, Lérmontov y por las obras de un genio más de la literatura rusa, Nikolái Gógol. Sus obras más destacadas son "Veladas en un caserío de Dikanka", "Tarás Bulba", "Almas muertas", la comedia "El inspector" y siendo "El capote" su relato más famoso. 

La segunda mitad del siglo XIX veía la emancipación de los siervos de 1861, la humillación nacional en la Guerra de Crimea y la victoria triunfal en Guerra Ruso-Turca, 1877–1878 liberando a las gentes eslavas de los Balcanes del yugo turco. En total, la sociedad estaba profundamente influida por las ideas democráticas y humanas del siglo. 

La poesía de la segunda mitad del siglo XIX es principalmente filosófica y realista. Los poetas más notables del momento son Nikolái Nekrásov, Fiódor Tiútchev, y Afanasi Fet. Otros poetas notables son Alekséi Konstantínovich Tolstói (quien también escribía prosa y dramas teatrales), Apolón Máikov, Iván Nikitin o Alekséi Pleschéyev. 

Si la primera mitad del siglo fue la edad de oro de la poesía rusa, la segunda mitad del siglo fue la edad de oro de la prosa rusa. Los gigantes de la época son Lev Tolstói, Fiódor Dostoyevski, Nikolái Leskov, Iván Turguénev, Mijaíl Saltykov-Shchedrín, Iván Goncharov, Dmitri Mamin-Sibiriak, Vladímir Korolenko, Antón Chéjov. Otros escritores notables son Serguéi Aksákov, Aleksandr Herzen, Nikolái Chernyshevski, el satirista Kozmá Prutkov (un pseudónimo colectivo), Dmitri Písarev, Alekséi Písemski, Gleb Uspenski, Konstantín Staniukóvich, Vsévolod Garshin, Fiódor Reshétnikov. El dramaturgo más notable fue Aleksandr Ostrovski. La crítica y literatura de tipo social en el siglo XIX estaba representada por las obras de Visarión Belinski, Nikolái Dobrolyúbov, Aleksandr Herzen y Nikolái Ogariov. 

En los últimos años del siglo Nikolái Garin-Mijáilovski, Aleksandr Serafimóvich, Aleksandr Kuprín, Iván Bunin, Leonid Andréyev salieron a escena literaria.

Algunos escritores se pusieron a la literatura infantil y juvenil (Vladímir Odóyevski, quien también fue uno de los primeros escritores rusos de la ciencia ficción y Antoni Pogorelski), y otros con los cuentos sobre la vida local en determinadas regiones (como Nadezhda Sojanskaia escribiendo sobre Ucrania).

La Edad de Plata comenzó en la última década del siglo XIX y concluyó en los años veinte. El marbete "Edad de Plata" marca en realidad un nuevo rumbo en la literatura rusa. Tras el Positivismo y el Realismo rayando en el Naturalismo de los escritores revolucionarios de los ochenta, los poetas y escritores de esta denominación vivieron en la era de Art nouveau o Modernismo y Simbolismo. Pero en Rusia esas líneas culturales europeas se transformaron y amoldaron en formas e ideas absolutamente nuevas. Los poetas y escritores de la Edad de Plata rechazaban el supuesto "engagément" o compromiso social del artista y proclamaban que el artista tenía una función mesiánica o de Mesías, era una figura titánica que debía encontrar las raíces profundas de la religión y de la estética: había sido señalado para prever el Mundo Nuevo y el Hombre Nuevo, era un demiurgo libre. Durante la Edad de Plata la cultura rusa llegó al apogeo del refinamiento. Este tiempo destacó como un Renacimiento espiritual sin precedentes en Rusia. 
Las corrientes literarias más conocidas de este periodo son el Simbolismo ruso - representado por el Simbolismo místico tradicional y el "Simbolismo joven" - es decir, obras de Innokienti Ánnienski, Vladímir Soloviov (1853–1900), Vasili Rózanov (1856–1919), Dmitri Merezhkovski (1866–1941) y Zinaida Guippius, Konstantín Balmont (1867–1942), Valeri Briúsov (1873–1924), Fiódor Sologub (1863–1927), Andréi Bely (1880–1934) y Aleksandr Blok (1880–1921), , y poetas análogos por su espíritu a los simbolistas – Maksimilián Voloshin, Mijaíl Kuzmín; Futurismo ruso (David Burliuk, Velimir Jlébnikov, Alekséi Kruchiónyj, primer Vladímir Mayakovski, Vasili Kamenski, Ígor Severianin (Ígor Lótarev), primer Nikolái Aséiev, primer Borís Pasternak); Acmeísmo (primera Anna Ajmátova, Nikolái Gumiliov, primer Ósip Mandelshtam, Serguéi Gorodetski, Gueorgui Ivánov, Irina Odóyevtseva). Poetas de la corriente llamada “nuevos campesinos’” – Serguéi Esenin, Nikolái Kliúiev, Serguéi Klychkov (1889-1937), Piotr Oreshin (1887-1938), Aleksandr Shiriáyevets (1887-1924) - merecen mención también. Ellos combinaban riqueza de imágenes populares y religiosas características de la cosmovisión del campesino ruso con una búsqueda temeraria de innovación y cambios revolucionarios. Hay numerosos poetas que no pueden ser atribuidos a alguna corriente literaria distinta, por ejemplo, Vladislav Jodasévich, o Marina Tsvetáyeva.

Los simbolistas rusos empleaban los ideas de Arthur Schopenhauer, Friedrich Wilhelm Nietzsche y Oswald Spengler, manifestaban interés por el misticismo y el ocultismo, por las disputas religiosas y por las sectas populares de Rusia. Las ideas de poetas, escritores y filósofos del tiempo variaban de la aceptación del Übermensch de Nietzsche a la profesión del "anima mundi", del individualismo extremo a la 'sobórnost' (espíritu colectivo). Lo que todos ellos compartieron era una búsqueda intensiva de formas artísticas nuevas y de una lengua poética renovada. Los simbolistas ponían énfasis en el aspecto verbal de los símbolos arquetípicos, buscando a la armonía nueva. Los futuristas abogaban por una innovación radical de la lengua, probando el simbolismo de los sonidos y recurriendo a experimentos audaces con la lengua. Los acmeístas propugnaban la claridad de las imágenes poéticas, anunciando que un equilibrio entre el sentido y el sonido debía ser alcanzado. Diferentes grupos artísticos surgían con numerosos manifiestos literarios. El manifiesto más conocido y escandaloso del tiempo era la "Bofetada al gusto público" de los futuristas (1912). 

En la prosa, los escritores rusos del periodo (Andréi Bely, Leonid Andréyev, Fiódor Sologub, Alekséi Rémizov) usaban la técnica del flujo de conciencia, alógica sucesión de episodios de gramática desarticulada e imaginería entrelazada en bruto, imitando nuevos modos de la organización de los textos semejante a las reglas del montaje cinematográfico. 

Los escritores realistas (Antón Chéjov, Iván Bunin, Aleksandr Kuprín, Iván Shmeliov, Borís Záitsev, Alekséi Nikoláyevich Tolstói, Mijaíl Osorguín, Maksim Gorki) también buscaban modos nuevos de expresión y formas literarias nuevas. Según Vikenti Veresáyev, un teórico literario del tiempo, su objetivo era no la representación de la vida cotidiana y costumbres, sino la comprensión de la esencia de la vida a través de representación de la vida cotidiana, encontrar una filosofía nueva de vida. De resultas, la prosa llegó a ser más lírica, y los escritores empleaban la síntesis de prosa, música y filosofía (simbolistas), prosa y acción social (futuristas). 

Tradicionalmente los filósofos de la Edad de Plata son Nikolái Berdiáyev, Serguéi Bulgákov, Borís Vysheslávtsev, Semión Frank, Nikolái Lossky, Fiódor Stepún, Piotr Struve, Iván Ilyín, Lev Karsavin, Pável Florenski, Lev Shestov, Serguéi Trubetskói y Yevgueni Trubetskói, Vladímir Ern, Alekséi Lósev, Gustav Shpet, Dmitri Merezhkovski y Vasili Rózanov. Las obras de Helena Blavatsky eran leídas y bien conocidas en Rusia del período.

La Edad de Plata se terminó con la llegada de la era nueva – con la formación del primer estado soviético que proclamó ideales nuevos y era intolerante a todos quiénes "no iban al paso".

Tras la Revolución de Octubre la literatura rusa entró en cierta desconexión con Occidente, por lo cual se conoce muy poco, a excepción de algunos autores. 

Tras octubre de 1917 la mayor parte de los escritores de la Edad de Plata no aprobó el nuevo régimen bolchevique y abandonó el país, la mayoría para siempre. Estos escritores dieron comienzo a la literatura rusa del exilio.

Quienes por el contrario optaron por quedarse en Rusia para compartir el destino del país y sus compatriotas llegaron al apogeo de su libertad creativa; pero pasó poco tiempo para que sus convicciones y esperanzas en el futuro del país entraran en colisión con la realidad de la vida ordinaria y muchos fueron ejecutados o asesinados lentamente por la terrible falta de casi todo que hubo durante la Guerra Civil Rusa, no pudiendo publicar nada o sufriendo intimidación para ser condenados a un silencio total. Los escritores que no apoyan la revolución de forma incondicional son eliminados, arrinconados, emigrados, marginados o ninguneados.

Al mismo tiempo, el primer período de la nueva época soviética se caracterizó por la gran proliferación de diversas corrientes estéticas, voces poéticas y experimentos literarios. En este tiempo coexistieron numerosos grupos literarios que discutieron, rivalizaron y cambiaron sus miembros, generalmente, en un corto tiempo. Dentro también de las Vanguardias históricas, surgió el Imaginismo ruso, fundado por Vadim Shershenévich (1893-1942), que reivindicaba la primacía de la imagen o metáfora sobre el símbolo y el retorno a la poesía tradicional; fue cultivado por Borís Pasternak (cuya poesía destaca por encima de su prosa), Serguéi Yesenin, Riúrik Ívnev (1891-1981) y Anatoli Mariengof).

Los imaginistas probaban nuevas metáforas inesperadas, creyendo que la sorpresa de las imágenes era el objetivo final del arte metafórico. Los talentos de Yesenin y Borís Pasternak llegaron a su cumbre. La corriente poética prerrevolucionaria del acmeísmo continuó todavía. Anna Ajmátova aún escribió poemas, aunque sus publicaciones fueron escasas y más tarde cesaron. Siguió el Futurismo ruso y el Cubofuturismo ("Hylaea" o “Guiléia”) (Vladímir Mayakovski, Velimir Jlébnikov, Borís Pasternak, Víktor Shklovski, Alekséi Kruchiónyj (1886-1968)) florecieron hasta cierto tiempo. Aparecieron nuevos grupos como OBERIU (Nikolái Zabolotski, Daniíl Jarms) y los dadaístas “nichevoki”. Por primera vez en la historia de humanidad los escritores pudieron tomar parte en la creación de un mundo completamente nuevo, y ellos aprovecharon la oportunidad. Por ejemplo, Velimir Jlébnikov creó la poesía záum (en ruso, за́умь; ) o poesía transmental (magia, encantamiento a la manera de los hechiceros asiáticos). Hay que notar la figura titánica del poeta y dramaturgo Vladímir Mayakovski, quien puso su talento al servicio de la Revolución. Marina Tsvetáyeva en mucho continuó la tradición de Ajmátova y sus poemas fueron la última manifestación de la Edad de Plata. La poesía de unos genios como Mayakovski, Yesenin, Ajmátova, Pasternak, Tsvetáyeva rebasa los límites de grupos o corrientes literarias. 

Fuera de estos grupos existieron también los famosos "Hermanos de Serapión” (Vsévolod Ivánov, Mijaíl Slonimski (1897-1972), Mijaíl Zóschenko, Veniamín Kaverin, Konstantín Fedin, Nikolái Tíjonov), “Pereval” (encabezado por el crítico literario Aleksandr Voronski e incluyendo poeta Eduard Bagritski, escritores Mijaíl Prishvin y Andréi Platónov y muchos otros), y asociaciones de escritores proletarios pro-communistas - Proletkult, la Asociación de Escritores Proletarios de Rusia o RAPP (por ejemplo, Dmitri Fúrmanov, Aleksandr Fadéyev y muchos otros), LEF (Vladímir Mayakovski, Ósip Brik, Nikolái Aséiev, Alekséi Kruchiónyj, por algún tiempo Borís Pasternak y algunos otros).

Esos grupos difieren de los anteriores en lo siguiente:
Los “Hermanos de Serapión” y “Pereval” abogaban por unos valores humanos en el arte universales y comunes a todas las naciones, mientras que otros grupos como la RAPP y el LEF defendían la existencia de un criterio de clase social en literatura.

El objetivo del grupo LEF (Frente de Izquierdas del Arte) y su homónima revista, como se especificó en uno de los primeros números, fue "revisar la ideología y la práctica del llamado arte de izquierda, y abandonar el individualismo para incrementar el valor del arte para el desarrollo el comunismo." 

Miembros de Proletkult y de RAPP pensaban que literatura y arte tuvieron un carácter clasista, y, consiguientemente, las obras de arte creadas por artistas no proletarios debían ser abandonadas y olvidadas, porque eran ajenas a la nueva sociedad y la "gente nueva".
El constructivismo (1923-1930) (Iliá Selvinski (1899-1968); Vladímir Lugovskói (1901-1957)) cantó la transición del Estado capitalista al socialista y el triunfo del proletariado y fue la primera estética lírica propia de la proletkult o "cultura proletaria"; esta pretendía crear un arte esencialmente proletario y que exaltara el trabajo colectivo; los poetas cantan a la Revolución, a las máquinas y a los obreros. Los miembros de “Pereval”, al contrario, proclamaron que la función principal de arte era el conocimiento del mundo, el mérito principal de una obra literaria no es el contenido clasista, sino la calidad artística; proclamaban la continuidad del arte desde los tiempos antiguos hasta la época presente. 

Desde 1925 se enfrentan dos bandos literarios: los agrupados en la Asociación de Escritores Proletarios de Rusia, conocida por la abreviatura de RAPP y sostenida por el Estado, y los que éstos llaman "popútchiki" o compañeros de ruta, escritores que asistieron y acompañaron la revolución. Los "ráppovtsy" luchan contra el grupo de los "Hermanos de Serapión", contra los constructivistas y contra las diversas escuelas de vanguardia, incluido el grupo LEF, reclamando una literatura menos formalista y más vulgar y asequible a las masas en fondo y forma. Algo así como las escuelas del sándalo y la berza en la literatura del Socialrealismo del año 1955 en España. 

En 1932, con todo, todas las asociaciones artísticas fueron prohibidas y, en 1934, los escritores recibieron la "proposición" de incorporarse en la Unión de Escritores Soviéticos, y la administración burocrática en el mundo literario comenzó. En los treinta Rusia fue aislada del mundo entero por un telón de acero, y comenzó el exterminio físico de los escritores y artistas desagradables para el régimen, sin que fuera posible ninguna otra emigraсión. 

A partir de ese momento en la literatura rusa se instaura el llamado realismo socialista. Los principales representantes de la corriente son Máximo Gorki, Mijaíl Shólojov, Alekséi Nikoláyevich Tolstói, Konstantín Fedin), normativismo (utopía social, lo social es superior a lo personal, un hombre ideal en circunstancias ideales, la realidad debe ser desdeñada y destruida para el porvenir hermoso. El representante principal de la corriente es Aleksandr Fadéyev), modernismo o postrealismo (buscando al sentido de la vida humana en el horror existencial del mundo, esa oposición del hombre y caos siendo trágica, pero revelando la esencia del hombre y su precio) (Yevgueni Zamiatin, Yuri Olesha, Borís Pilniák, Andréi Platónov). Ellos continuaron las tradiciones del modernismo de la Edad de Plata y afirmaron el derecho del hombre a la vida privada). En 1932, el término nuevo "realismo socialista" apareció, fusionando los ideas del realismo nuevo y normativismo. 
No obstante, entre escritores prosistas más destacados del tiempo (los 20-30) pueden nombrar los siguientes escritores destacados obras de quienes son de interés para la humanidad: el escritor y publicista Iliá Erenburg, prosistas Máximo Gorki, Borís Pilniak, Mark Aguéyev, Mijaíl Bulgákov, Olga Forsh, Alekséi Nikoláyevich Tolstói, Konstantín Fedin, Andréi Platónov, Borís Lavreniov, Yuri Olesha, Valentín Katáev, Veniamín Kaverin, Pável Bazhov, Borís Sherguín, Gleb Alekséyev, satiristas y humoristas Mijaíl Zóschenko, Ilf y Petrov, escritores que en esencia describieron los actos del Ejército Rojo en la Guerra civil rusa Isaak Bábel, Dmitri Fúrmanov, Aleksandr Fadéyev, Nikolái Ostrovski, Aleksandr Serafimóvich, escritores de la ciencia-ficción y ficción social Aleksandr Beliáyev, Yevgueni Zamiatin, Vladímir Óbruchev, Aleksandr Chayánov, el trágico y romántico Aleksandr Grin.

Aparecieron escritores quienes describieron la vida rústica y la naturaleza de Rusia, por ejemplo Mijaíl Prishvin, Yevgueni Charushin. Algunos escritores se pusieron a la literatura infantil y juvenil – y ahora las obras de Kornéi Chukovski, Arkadi Gaidar, Lev Kassil, Andréi Serguéyevich Nekrásov, "Los tres gordinflones" de Yuri Olesha y "Blanquece la vela solitaria" de Valentín Katáev, poemas de Samuíl Marshak, Serguéi Mijalkov son entre los libros infantiles más predilectos. La novela histórica fue desarrollada por Vasili Yan, Alekséi Nóvikov-Pribói, Serguéi Serguéyev-Tsenski, Anatoli Stepánov, Yuri Tyniánov, Viacheslav Shishkov, María Márich. Esos escritores exploraban las relaciones entre la historia y la persona, analizando el papel de la persona en la historia. Los más conocidos dramaturgos del período son Nikolái Pogodin, Vsévolod Vishnevski.

En los treinta aparecieron los primeros poemas de Aleksandr Tvardovski y Mijaíl Isakovski.

En 1941 comenzó la Gran Guerra Patria. Aparecieron nuevos talentos, como por ejemplo Alekséi Surkov, Konstantín Símonov, Emmanuíl Kazakévich, Iósif Utkin, Borís Polevói y Vera Panova, que escribieron sobre la tragedia de la guerra y sobre las hazañas y esfuerzos de los soldados soviéticos en su lucha a muerte contra el fascismo; Vera Inber y Olga Bergolts, que sobrevivieron al Sitio de Leningrado y describieron los 900 días heroicos y trágicos; Pável Antokolski, Aleksandr Tvardovski, Mijaíl Isakovski, Andréi Platónov, Borís Pasternak, Mijaíl Shólojov, Anna Ajmátova e Iliá Erenburg emprendieron la defensa de la Unión Soviética contra la inhumanidad de fascismo. Muchos escritores perecieron en los frentes de la guerra o murieron de hambre y frío. 

Durante la época, la mayor parte de los escritores emigrados abrazaron temporalmente la causa de la URSS, dadas las difíciles circunstancias que atravesaba el país. 

En este período volvió a la literatura rusa el hombre corriente como personaje literario: héroes modestos y de carácter contradictorio. 

Las mejores obras del periodo son “Vasili Tiorkin”, de Aleksandr Tvardovski; “El Don apacible”, de Mijaíl Shólojov; "“El hijo del regimiento”", de Valentín Katáev; "“La Guardia Joven”", de Aleksandr Fadéyev; "“Invasión”" y "“El coche de oro”", de Leonid Leónov; "“La estrella”", de Emmanuíl Kazakévich; el poema "“Meridiano de Púlkovo”", de Vera Inber; "“El relato de un verdadero hombre”", de Borís Polevói; el drama "“La gente rusa”" y los libros de poemas "“Contigo y sin ti”" y "“Guerra”", de Konstantín Símonov; el poema "“Hijo”", de Pável Antokolski, "“Zoya”", de Margarita Aliguer; la pieza de teatro “Dragón”, de Yevgueni Shvarts; y la novela histórica "“Rusia joven”", de Yuri Guerman.
Después de la guerra las autoridades ejercieron una dura represión, y hasta el fallecimiento de Stalin el Estado intervino frecuentemente en la creación literaria.

El período comienza con el fallecimiento de Iósif Stalin y se termina con el fin de la Primavera de Praga. Este período se caracteriza por la renuncia gradual del "realismo socialista" como un método de literatura, el proceso literario diverso y saturado, y el retorno a los valores humanos perpetuos. 

La célebre novela "“Doctor Zhivago”" de Borís Pasternak, cuya publicación en la URSS fue prohibida hasta 1988, fue publicada por vez primera en Milán en 1957 en su versión en lengua italiana. Los poetas prohibidos de "La Edad de Plata Rusa" y de los años veinte, incluyendo a Yesenin, Zamiatin y Nabókov, recobraron gradualmente a sus lectores. 

En poesía, podemos hablar de nuevas corrientes y grupos: 





En prosa, podemos destacar nuevos rumbos del desarrollo:


Podemos mencionar asimismo obras de escritores pertenecientes a otras culturas nacionales, pero que también escribían en ruso como son el gran escritor en ruso y en kirguís Chingiz Aitmátov y el bielorruso Vasil Bykau. Sus obras se convirtieron en parte orgánica de la literatura rusa. 

La ciencia ficción rusa alcanza un nuevo nivel en los años sesenta con las novelas casi proagandísticas de Iván Yefrémov y los primeros libros de Arkadi y Borís Strugatski.

En la literatura propagandística, destacan los libros de Valentín Katáev de los años sesenta y "“La Fortaleza de Brest”" ("Bréstskaia krépost") de Serguéi Smirnov.

En cuanto a la literatura infantil y juvenil está representada por las obras de Ágnia Bartó, Vitali Gúbarev, Nikolái Nósov, Lev Davýdychev, Borís Zajoder, Anatoli Rybakov, Valeri Medvédev o Yevgueni Veltístov.

En dramaturgia, sus mayores exponentes del período son Aleksandr Vampílov, Yevgueni Shvarts, Víktor Rózov, Alekséi Arbúzov.

El período convencionalmente comienza con el final de la Primavera de Praga y el “aprieto de las tuercas” que siguió, y concluye a mediados de los ochenta con los síntomas de agravación de la crisis del estado soviético y de la ideología soviética. 

En poesía puede hablarse de las siguientes nuevas corrientes y grupos:

• "Neoacmeísmo", cuyos principales representantes son Arseni Tarkovski, Semión Lipkin, y Bela Ajmadúlina, quien continúa la tradición filosófica, compleja y refinada de la Edad de Plata. Estos autores proclamaron vínculos personales universales con todo en el mundo, probaban imágenes de la cultura y su papel en la formación y ‘mantenimiento’ una personalidad humana. 

•Los poetas con ‘guitarras’– Vladímir Vysotski, Aleksandr Gálich, Yuli Kim. Estos poetas utilizaron a menudo lo grotesco como medio para criticar la vida contemporánea, aunque a veces su poesía está marcada por un lirismo trágico sin precedentes, así como por el psicologismo y la identificación total con los héroes de sus versos (soldados de la Gran Guerra Patria, artistas, gamberros (Vysotski)). Estos poetas fueron la conciencia del país durante los años setenta. Gálich fue obligado a emigrar y Vysotski falleció prematuramente.

• La corriente de los `poetas bajos’ fue continuada, en primer lugar, por Yuri Kuznetsov, quien en su obra exploró la tragedia del medio rural tradicional ruso, su vida y sus valores, y su destrucción gradual. Su poesía está marcada por un lirismo melancólico y por la búsqueda de Dios en la vida cotidiana.

• "Neovanguardía" – "neofuturismo" (Vladímir Kazakov, Víctor Sosnora, Guennadi Aiguí) y "Grupo de Lianózovo" (neo-OBERIU) (Oleg Grigóriev, Ígor Jolin, Vsévolod Nekrásov), que abrieron un camino hacia el conceptualismo, continuando su búsqueda creativa. 

• Primeros versos de poetas de rock ruso (principios de los años 80) – ‘jóvenes enfadados’, que luchaban por su derecho a ser diferentes, tener sus opiniones, su estética y su estilo que eran distintos del punto de vista oficial. 

Puede mencionarse asimismo a Ígor Guberman, un distinguido poeta, que también utilizó la sátira en su poesía. Sus mordaces cuartetas satíricas hicieron de él "persona non grata" en la URSS y tuvo que emigrar a Israel. 

Puede mencionarse también la corriente poética denominada "neorromanticismo", practicada por cantautores y poetas como Bulat Okudzhava, Yuri Vízbor, Yevgueni Bachurin, Aleksandr Dolski, Yunna Mórits, etc. Su poesía era una poesía ‘baja’, intelectual, a veces triste e irónica, inteligente, muy lírica. En su mayor parte se manifestó en forma de canciones, que son conocidas y valoradas hasta ahora.

Yevgueni Yevtushenko y Andréi Voznesenski continuaron escribiendo, pero su poesía tuvo menor resonancia que en la década de 1960. 

En prosa, debe destacarse la evolución o desintegración gradual del realismo socialista y el retorno al realismo crítico

• Entonces una nueva corriente en prosa apareció, la llamada ‘epopeya popular’ (Anatoli Ivanóv con su “La llamada perpetua”, Piotr Proskurin, Fiódor Abrámov). Estas obras estudiaban las vidas de algunas generaciones de familias rusas, en el fondo familias campesinas y sus destinos en la Rusia ‘encabritada’ por la Revolución y martirizada en la Gran Guerra Patria y en la vida cotidiana moderna. Esos escritores examinaban el nervio moral y los valores espirituales que permitieron a la gente sobrevivir y vencer en la guerra, pero ellos no idealizan la gente. Esos escritores fueron los primeros en ver que la vida saciada lleva sus propios peligros – ‘insuficiencia cardíaca’, búsqueda de provecho, olvido de valores eternos, sordera moral. Afín a la corriente es la ‘prosa de la aldea’ cuyos principales representantes son Vasili Belov, Valentín Rasputin, Víktor Astáfiev, Vasili Shukshín, con sus héroes intensamente buscando ‘algo más’, el sentido de la vida, la justificación de su existencia.

• La Prosa de guerra está representada por las obras de Borís Vasíliev, Vitali Zakrutkin, Víktor Astáfiev, Yuri Bóndarev y Viacheslav Kondrátiev. Los escritores intentaban descubrir qué hizo que la gente continuase siendo humana en medio de la carnicería sangrienta de la guerra, rindiendo homenaje a las gentes sencillas que no se permitieron convertirse en inhumanas. 

• Puede mencionarse asimismo el desarrollo subsiguiente del movismo (mauvism) representado por las más avanzadas y más maduras obras de Valentín Katáev. Mauvism es una mezcla interesante con partes cuasi-documentales, visiones, ensueños con el movimiento libre a través del tiempo en todas las direcciones.

Es difícil etiquetar a los prosistas de la época como partidarios de una corriente literaria concreta. No obstante, pueden destacarse escritores notables como Vladímir Voinóvich, Fazil Iskander y Vasili Aksiónov, quienes prefirieron el género satírico para sus estudios del absurdo de los mitos totalitarios, el avanzado Yuri Trífonov y Gavriíl Troepolski quien en su Bim blanco, oreja negra revelaba y estudiaba la sordera moral y la depreciación de valores en la vida cotidiana, Vladímir Tendriakov y Yuri Dombrovski con su valiente revelación de la injusticia del régimen soviético con métodos casi realistas pero usando parábolas, el postrealismo místico de Vladímir Orlov y Anatoli Kim. El tema de "Archipiélago Gulag" está estudiado más profundamentete por Aleksandr Solzhenitsyn y Varlam Shalámov. La prosa histórica del período está representada por las novelas de Valentín Píkul, Dmitri Balashov, Alekséi Yúgov quienes estudiaron el progreso histórico de Rusia. 

Apareció una nueva corriente literaria en prosa, la supuesta prosa pedagógica. Son novelas y cuentos que examinan la psicología de los adolescentes, cómo se hacen mayores y ¡los problemas de su socialización y de su contacto personal y trato con los adultos. Esas obras también plantean una cuestión de la responsabilidad de los adultos para el fiasco y la falta de valores espirituales de los adolescents. Esta corriente es representada por las obras de Albert Lijánov, Simón Solovéichik, Borís Vasíliev, and Vladímir Zheléznikov.

Se puede decir que el periodo estimuló el postmodernismo ruso literario, y los escritores postmodernistas más notables del periodo son Venedikt Yeroféyev, Sasha Sokolov y Andréi Bítov.

Es el tiempo de florecimiento de ciencia ficción social y filosófica, con obras maduras de Arkadi y Borís Strugatski, Olga Lariónova, Kir Bulychóv, Séver Gansovski, y la ciencia ficción espacial de Serguéi Snégov. Esas obras se elevan sobre la lectura de pasatiempo, analizando la naturaleza humana extemporánea, planteando cuestiones filosóficas y examinando diferentes modelos sociales. 

En cuanto a la literatura infantil y juvenil, está representeada por las obras de Vladislav Krapivin, Kir Bulychóv y Eduard Uspenski, el autor de "Cheburashka".

Los mejores dramaturgos de la época fueron Aleksandr Vampílov, Grigori Gorin, Aleksandr Gelman, Edvard Radzinski, Gueorgui Polonski, Aleksandr Volodin y Mijaíl Shatrov. 

La literatura en ruso del período creada por escritores pertenecientes a otras culturas nacionales está representada por las obras maduras del kirguís Chingiz Aitmátov y de escritores bielorrusos - Vasil Bykau, lo mismo que por la nueva prosa documental de Alés Adamóvich y la prosa de guerra confesional y de multitud de voces de Svetlana Aleksiévich, galardonada con el Premio Nobel de Literatura en 2015. Sus obras no solo se convirtieron en un tesoro de la literatura en ruso sino que influyeron fuertemente sobre la literatura rusa.

Tras la Revolución de Octubre en 1917 la mayor parte de los escritores de la Edad de Plata no aprobó el nuevo régimen bolchevique y abandonó el país, la mayoría para siempre. Estos escritores dieron comienzo a la literatura rusa del exilio.

Podemos hablar de tres períodos (o tres ‘olas’ de emigración de masas) en la historia de literatura rusa en el exilio: 

Los emigrados de la "primera ola" se establecieron principalmente en Berlín, París y Praga, convirtiendo a esas ciudades en importantes centros de cultura y literatura rusa durante la emigración. Algunas revistas literarias y editoriales publicaron las obras de escritores emigrados rusos y eso estimuló discusiones intelectuales así como la vida cultural. Escritores y poetas se agruparon alrededor de las revistas dando lugar a grupos literarios. 

Los escritores más notables de la primera ‘ola’ son Iván Bunin, Aleksandr Kuprín, Iván Shmeliov, Yevgueni Zamiatin, Leonid Andréyev, Marina Tsvetáyeva y Alekséi Nikoláyevich Tolstói (los dos últimos regresaron a la URSS más tarde). Entre otros escritores y poetas que escaparon del régimen bolchevique fueron Dmitri Merezhkovski y su esposa, la poeta Zinaída Guippius, Borís Záitsev, Mijaíl Osorguín, Alekséi Rémizov, Gueorgui Ivánov, Konstantín Balmont, Teffi (Nadezhda Lojvítskaia), Vladislav Jodasévich, Irina Odóyevtseva, Ígor Severianin (Ígor Lotariov), Sasha Chorny (Aleksandr Glikberg), Nina Berbérova, Arkadi Avérchenko, Mark Aldánov, Nikolái Otsup, Elizaveta Kuzminá-Karaváyeva (Madre María), Viacheslav Ivánov, Gueorgui Adamóvich, Piotr Krasnov, y muchos otros. Sus obras exploraron los motivos apocalípticos, de fatalidad y sino, del fin de la civilización, la soledad trágica del hombre en un mundo hostil, proclamaron el precio del sustento de un alma viva humana en un mundo trágico y disgregado. Algunos de los escritores analizaron las causas de la revolución y condenaron a los “descarados, villanos y vándalos” que destruyeron la Rusia zarista. 

La "“generación desapercibida”" fueron en esencia escritores y poetas más jóvenes que maduraron y comenzaron a escribir ya emigrados. Los más conocidos poetas de la “generación desapercibida” son Borís Bózhnev, Aleksandr Ginger, Anna Prismánova, Alla Goloviná, Raísa Bloj, Borís Poplavski, Yuri Terapiano, Nikolái Turovérov, Lídiya Chervínskaya, Irina Knorring, Vladímir Smolenski. Su poesía lírica tenía como fin la representación minuciosa de los movimientos del alma, psicología intensa y apuntaba los motivos de un hombre sin hogar, solitario, amargado, un alma en pena. Los más notables prosistas son Vladímir Nabókov, Gueorgui Yevangúlov, Yuri Felzen, Gaito Gazdánov y Leonid Zúrov. 

Los representantes de la "segunda ola" son Iván Yelaguin, Nikolái Narókov, Dmitri Klenovski, Borís Shiriáyev. Sus obras giraban en torno a su amarga experiencia de la vida en la URSS. 

La "tercera ola" de emigración, ‘ola’ de disidentes, tuvo su causa en la protesta de los intelectuales contra el control ideológico omnipresente y contra el “apriete de tuercas” después de la Primavera de Praga. Algunos autores fueron deportados por las autoridades soviéticas. Se establecieron principalmente en Nueva York e Israel. Entre los escritores de la tercera ‘ola’ destacan Joseph Brodsky, Andréi Siniavski, Dmitri Bóbyshev, Sasha Sokolov, Vasili Aksiónov, Frídrij Gorenstein, Gueorgui Vladímov, Aleksandr Solzhenitsyn, Serguéi Dovlátov, Andréi Amalrik, Lev Kópelev, Irina Ratushínskaya, entre otros. 

Después de la disolución de la Unión Soviética los antepechos que dividieron la literatura rusa en dos fueron derribados. Actualmente la literatura rusa vuelve a estar unida, lo que implica que, aunque la literatura rusa es diversa, gracias a la gran proliferación de diversas corrientes estéticas, voces poéticas y experimentos literarios, puntos de vista y enfoques creativos, ya no está dividida trágicamente por un telón de acero y prohibiciones del gobierno. Los autores y sus libros pueden atravesar fronteras fácilmente.

En la segunda mitad de los ochenta la crisis de la ideología soviética se hizo muy aguda y general, lo que estimuló la aparición de una literatura nueva, post-soviética. Durante esta época el telón de acero desapareció por completo, y los autores emigrados regresaron a Rusia. Se puede decir que las dos corrientes de la literatura rusa confluyeron, transformándose en una nueva corriente.

Como suele ocurrir en épocas de crisis, la literatura se dedicó principalmente a revelar y estudiar los males y patologías de la sociedad rusa, rayando en el naturalismo fisiológico, con un pesimismo extremo, y dividiendo todas las manifestaciones de la vida en sus partes integrantes. He aquí por qué la literatura desde mediados de los 80 hasta comienzos del siglo XXI mereció en Rusia el apodo de ‘chernuja y pornuja’ – literatura negra y pornográfica. Apareció una corriente neo-naturalista en prosa representada, por ejemplo, por Anatoli Azolski y Serguéi Kaledin. Los textos que condenaban el sistema y la ideología soviéticos fueron tan numerosos que pudo hablarse de una nueva 'ideología oficial', opuesta a la ideología soviética. Pero poco a poco, con la llegada de la esperanza nueva para Rusia, la literatura se hizo más diversa. 

En poesía, las corrientes más importantes son: 

• "Conceptualismo" (Dmitri Prígov, Lev Rubinstein, Timur Kibírov). El principio fundamental de conceptualismo son los ‘juegos’ con objetos y clichés verbales de socialismo y su reducción al absurdo.

• "Neobarroco", cuyos representantes mejores son Yelena Shvarts, Iván Zhdánov y Alekséi Párshchikov.

• Un nuevo grupo literario, “Mitkí”, formado por Vladímir Shinkariov, Mijaíl Sapego, Olga y Aleksandr Florenski, Dmitri Shaguin, Borís Grebenshchikov, quienes cultivan un sentimentalismo ingenuo, de simplicidad y tontería deliberadas. La mayor parte de los poetas del rock y cantautores principales de los noventa estuvieron más o menos vinculados con el grupo. Los 'Mitkí' escribieron prosa y poesía, pintaron y cultivaron un estilo de vida especial. 

• Poetas y cantautores de rock ruso: los más conocidos son Aleksandr Bashlachov, Borís Grebenshchikov, Yuri Shevchuk, Víktor Tsoi, Yanka Diáguileva.

• Los poemas de Karén Dzhanguírov, Dmitri Býkov, Iván Ajmétiev, Bajyt Kenzhéyev, Vladímir Vishnevski son de interés también.

En los últimos tiempos la comunidad de Internet se desarrolló rápidamente en Rusia, y apareció un fenómeno nuevo, la literatura interactiva (‘Seteratura’) - 

La prosa post-modernista predomina durante el periodo. La corriente está representada principalmente por las novelas de Tatiana Tolstaya, Valeria Nárbikova, Víktor Pelevin, Viacheslav Pietsuj, Víktor Yeroféyev, Dmitri Lípskerov, Pável Krusánov, Vladímir Orlov, Nikolái Dezhnev, Anatóli Korolióv, Anatoli Kim, Vladímir Voinóvich, Vasili Aksiónov y Dmitri Býkov. El puesto de Borís Akunin entre post-modernistas puede ser disputado, pero al mismo tiempo los críticos literarios están de acuerdo con que su prosa es de alta calidad y solamente se enmascara como obra policíaca. Los post-modernistas rusos en su poética reflejan la crisis de ‘fin de siècle’ en literatura. La crisis se manifestó en la pérdida de confianza en muchas cosas: cultura, lengua, utopía; al mismo tiempo los post-modernistas sienten cierta nostalgia por la fe perdida. 

La manera realista sufrió cambios radicales, como puede comprobarse en las últimas novelas de Víktor Astáfiev, Anatoli Rybakov ("Deti Arbata" – "Los hijos de Arbat") y Gueorgui Vladímov.

El post-realismo está representado por las obras de Ludmila Ulítskaya, Dina Rúbina, Olga Slávnikova, Serguéi Dovlátov, Vladímir Makanin, Liudmila Petrushévskaia, Fridrich Gorenshtein, Alekséi Slapovski, Galina Scherbakova, Efraim Sevela, Aleksandr Kabakóv.

Los más dudosos y escandalosos escritores serios del tiempo son Yuz Aleshkovski, Yuri Mamléiev, Vladímir Sorokin, cuyas obras abundan en líquidos del cuerpo de todo género, atrocidades y un lenguaje obsceno. 

La novela histórica está desarrollada principalmente por Dmitri Balashov y Borís Vasíliev, quienes dirigen su mirada a las épocas primeras de la historia rusa, examinando vuelos y caídas del país. 

La ciencia ficción filosófica y social florece también, representada por las obras de Arkadi y Borís Strugatski, Aleksandr Grómov, Oleg Dívov, Henry Lion Oldie, Yelena Jaietskaia, Viacheslav Rybakov, Vladímir Mijáilov, Yevgueni Lukín, Sviatoslav Lóguinov, Eduard Guevorkián, Borís Shtern, Serguéi Siniakin, Jolm van Zaichik, Vladímir Jlúmov, Dmitri Býkov, Andréi Stoliarov, Aleksandr Yetóiev, Leonid Kagánov. Es literatura de alta calidad, que no debe ser discriminada por culpa de género, porque es a menudo difícil decir donde juegos post-modernistas o post-realistas se terminan y donde literatura ‘de amplio consumo’ comienza. Un escritor de ciencia-ficción muy popular es Serguéi Lukiánenko, pero él gradualmente se comercializa. Podemos mencionar asimismo las novelas-parábolas maravillosas de escritores ucranianos Marina y Serguéi Dyachenko, quienes escriben en ruso las más de las veces. El género de la literatura fantástica (fantasy) apareció en Rusia también, en el sub-género llamado ‘literatura fantástica eslava’ María Semiónova es la autora principal. 

En cuanto a la literatura infantil y juvenil, esa literatura es representado, ante todo, por los libros de “Consejos perniciosos” muy populares por Grigori Oster.

La dramaturgia del tiempo es representado por el teatro post-modernista de Venedikt Yeroféiev, Nina Sadur, neonaturalismo de Nikolái Koliada evolucionando en la dirección de neosentimentalismo, piezas de teatro post-realistas de Liudmila Petrushévskaia. 






</doc>
<doc id="1655" url="https://es.wikipedia.org/wiki?curid=1655" title="La Bañeza">
La Bañeza

La Bañeza es un municipio y ciudad española situada en la zona sur de la provincia de León, en la zona noroccidental de la comunidad autónoma de Castilla y León. Está situada en la comarca de Tierra de La Bañeza, de la cual es su capital, en el tránsito entre el Páramo y la sierra del Teleno. Es, además, cabeza de partido judicial.

Zona de población astur, su territorio formó parte del Conventus Asturum durante la época romana. La ciudad nació en el siglo IX por orden del conde Gatón a partir de los núcleos de San Pedro de Périx y Bani Eiza. Sede de un marquesado durante la Edad Moderna, a finales del siglo XIX comenzó su transformación económica y urbana, en la cual repercutió la llegada del ferrocarril Plasencia-Astorga en 1896. Un año antes, en 1895, recibió el título de Ciudad de manos de la reina María Cristina.

Su patrimonio monumental, en el que destacan las iglesias de San Salvador y Santa María, así como diversas celebraciones que tienen lugar a lo largo del año, entre las que destacan los carnavales, su Semana Santa y las fiestas patronales del mes de agosto, durante las cuales tiene lugar una de las pocas carreras urbanas de motociclismo existentes en España, la convierten en una ciudad receptora de turismo. Este último se añade a su destacada industria alimentaria, gracias a la presencia de la azucarera, y al sector servicios, muy presente en la localidad debido a su posición como centro comarcal.


La ciudad de La Bañeza está situada en la Vega del Órbigo-Tuerto, subcomarca de la Tierra de La Bañeza, de la cual es su centro, a una altitud de 771 msnm. Está situada en el sur de la provincia, en una zona llana próxima a las estribaciones de los montes de León, en este caso de la Sierra del Teleno. Su término municipal limita al norte con Soto de la Vega y Palacios de la Valduerna, al sur con Santa Elena de Jamuz y con Cebrones del Río, al este con Regueras de Arriba, y al oeste con Palacios de la Valduerna. El territorio del término municipal está representado en la hoja 231 del Mapa Topográfico Nacional.

El relieve del municipio se caracteriza por ser muy poco accidentado, debido en gran parte a su situación en la vega del río Órbigo, y tan sólo en la parte oeste del mismo aparecen pequeñas elevaciones del terreno. En el término municipal se encuentra el vértice geodésico de El Tejar, próximo al casco urbano, a una altitud de 807 msnm.

La Bañeza ve pasar por su territorio alguno de los cursos fluviales más importantes de la parte central de León. Por el este y en los límites del municipio, discurre el río Órbigo, afluente del Esla, y proveniente del norte, el Tuerto vierte sus aguas al Órbigo en las inmediaciones del casco urbano. En la parte norte, y bañando los terrenos de San Mamés de la Vega y Santiago de la Valduerna, discurre el río Duerna que, viniendo de la Sierra del Teleno, desemboca en el río Tuerto en la parte norte de la ciudad, junto a las instalaciones deportivas.

El clima en el municipio es, como en la mayor parte de la Meseta Norte, un clima mediterráneo continentalizado, levemente alterado por la influencia de la cordillera Cantábrica y los montes de León. Las precipitaciones se reparten de manera irregular, con un máximo en primavera y en otoño y un mínimo en época veraniega. En cuanto a las temperaturas, los inviernos son fríos, con frecuentes heladas y nevadas esporádicas, mientras que los veranos son cortos y calurosos. Según la clasificación climática de Köppen La Bañeza tiene un clima "Csb" (templado con verano seco y templado).

Las primeras referencias históricas existentes para el territorio bañezano conciernen al emplazamiento, en la cercana localidad de San Martín de Torres, de la ciudad astur-romana de Bedunia, mencionada por diversas fuentes como el Itinerario de Antonino. Conquistado por Roma entre los años 29 a. C. y 19 a. C., el espacio que ocupa actualmente La Bañeza formó parte del Conventus Asturum, primero dentro de la provincia Tarraconense y, desde finales del siglo III, de la Gallaecia.

Tras el ocaso del mundo romano, visigodos y suevos lucharon en los alrededores de la actual ciudad, en el despoblado de Hinojo, a mediados del siglo V, siendo la victoria para los godos. Es posible que en estos momentos, entre los siglos V y VIII existiera un pequeño asentamiento en las cercanías de la actual iglesia de San Salvador.

La actual población bañezana nació a mediados del siglo IX por orden del conde Gatón, a partir de dos núcleos: San Pedro de Périx (con gentes de Pereje) y Bani Eiza (con mozárabes de Córdoba). De la fusión de ambos surge el primer mercado y dos parroquias, San Pedro (con los años trasladada a Santa María) y San Salvador, monasterio ofrecido al obispo San Genadio en el siglo X, a finales del cual es destruido por las tropas de Almanzor, siendo recuperado a principios del siglo XI.

En 1556 Pedro de Zúñiga y Bazán recibió el marquesado de La Bañeza, pasando a convertirse la ciudad en cabecera del mismo, en manos de la familia Bazán. Durante parte del siglo XVII fue sede del Adelantamiento del Reino.

Al igual que el resto de la provincia, la ciudad sufrió las consecuencias de la ocupación napoleónica y los padecimientos durante las guerras carlistas. A finales del siglo XIX comenzó la transformación de la base económica y del núcleo urbano, con un desarrollo que coincidió con la concesión en 1895 del título de Ciudad de manos de la reina regente María Cristina en nombre de su hijo Alfonso XIII. La inauguración del ferrocarril Plasencia-Astorga en 1896 fue el hecho más estimulante para el crecimiento de la ciudad, la cual se expandió hacia la vía, ocupando parte del espacio agrario existente, con almacenes, fábricas o talleres. En los años veinte la ciudad recibió un nuevo impulso con la instalación de la azucarera, afectando no solo a la ciudad sino también a la comarca, que suministraría desde entonces la materia prima.

En 1936 la ciudad sufrió las consecuencias de la Guerra Civil, la cual se cobró la vida del entonces alcalde Isaac Nistal Blanco junto a nueve personas más. El 2 de septiembre de 2008, la Asociación para la Recuperación de la Memoria Histórica exhumó sus restos enterrados en Izagre.

En 1984 se cerró parcialmente el ferrocarril de la Vía de la Plata, comprometiendo durante años el futuro económico de la ciudad, que no comenzó a repuntar hasta la apertura de la autovía del Noroeste en 1998.

El municipio de La Bañeza contaba con 10 443 habitantes en 2015, según el censo de población del INE, de los cuales 5045 eran varones y 5398 eran mujeres. En cuanto a su distribución, la mayoría viven en La Bañeza, y unos 300 repartidos entre San Mamés de la Vega, Santiago de la Valduerna y núcleos diseminados. La población ha disminuido ligeramente desde 2011, después de registrarse un progresivo crecimiento a lo largo del siglo XX, especialmente en los últimos veinte años, a excepción de un breve paréntesis a finales de los años noventa. Este aumento se debió a la llegada de inmigrantes extranjeros y al cese en parte de la emigración de bañezanos a otras ciudades.

El crecimiento actual de La Bañeza también se debe en parte al fortalecimiento de la ciudad como centro de servicios y a la consolidación de un creciente sector industrial favorecido por la posición de la ciudad, que se encuentra junto a la autovía del Noroeste y a escasos kilómetros de los enlaces de esta con la AP-71, la A-52 y la A-66.

Por otra parte, y como otra de las causas de este crecimiento, el colectivo inmigrante durante el año 2008 en La Bañeza se cifró en 679 personas, entre los que destacan los procedentes de Europa, con 295 personas, y América, con 291 del total. Por países, los más numerosos son los de nacionalidad búlgara, integrando este colectivo 169 personas, colombianos con 153 censados y los procedentes de Marruecos con 76; el resto de inmigrantes se reparte entre varias nacionalidades de todos los continentes.


Las entidades de población que componen el término municipal de La Bañeza son las siguientes:

En 2007, el sector que más empleo generaba en La Bañeza era el de servicios, con 2.223 personas, representando un 61,1% del total. A continuación se situaban la industria y la construcción, con 845 y 483 trabajadores respectivamente, siendo un 23,2 y un 13,3%. Por último, el sector agrícola generaba tan sólo 88 empleos, un 2,4% del total.

Respecto a las empresas, un 73,6% correspondía al sector servicios, un 14,6% a la construcción, un 10,2% a la industria, y un 1,6% al sector primario.


Los terrenos municipales se distribuyen de la siguiente forma: herbáceos (50,45%), pastos (8,32%), forestales (5,61%), leñosos (3,02%) y otros usos (32,60%).


La actividad industrial bañezana se centra en el sector de la alimentación, cuyo máximo representante es la azucarera que Associated British Foods mantiene en la ciudad (hasta marzo de 2009 pertenecía a Ebro Foods). Su producción toma como materia prima la remolacha azucarera que obtiene en su mayoría de las comarcas leonesas del Páramo, Ribera del Órbigo y Maragatería, y de la comarca zamorana de Benavente y Los Valles. Otras empresas destacables, por su volumen de producción y número de empleados, son Embutidos Rodríguez, Pavimentos Páramo y Aluminios San Antonio.

La ciudad cuenta con dos áreas industriales: la primera de ellas, "La Sementera", se encuentra ubicada junto a la N-VI y es la más pequeña de las dos, con 12.000 metros cuadrados. El otro polígono, de nueva construcción, es "Villa Adela", que con una extensión de 300.000 metros cuadrados, espera una ampliación de 560.900 metros cuadrados.


En La Bañeza predomina el comercio tradicional, junto con alguna firma de nivel nacional.


La administración política del municipio se realiza a través de un ayuntamiento de gestión democrática, cuyos componentes se eligen cada cuatro años por sufragio universal. El censo electoral está compuesto por todos los residentes empadronados en La Bañeza, mayores de 18 años y con nacionalidad de cualquiera de los países miembros de la Unión Europea. Según lo dispuesto en la Ley del Régimen Electoral General, que establece el número de concejales elegibles en función de la población del municipio, la Corporación Municipal está formada por 17 ediles.

El término municipal, además de la cabecera, incluye los núcleos de San Mamés de la Vega y Santiago de la Valduerna, muy próximos al casco urbano de La Bañeza. En febrero de 2009, La Bañeza fue el primer municipio de la Castilla y León en celebrar un bautismo civil.


La gestión ejecutiva municipal está organizada en áreas de gestión al frente de las cuales hay un concejal del equipo de gobierno. Cada área de gobierno tiene varias delegaciones en función de las competencias que se le asignan y que son variables de unos gobiernos municipales a otros. Las áreas actuales de gestión del Ayuntamiento son las siguientes:



La Bañeza es la cabeza del partido judicial número 3 de la provincia de León, cuya demarcación comprende a la ciudad más otras poblaciones de las comarcas limítrofes. Acoge dos salas de Primera Instancia.


La ciudad de La Bañeza cuenta con varios centros de enseñanzas no universitarias. De carácter público, cuenta con una guardería municipal, dos centros de educación infantil y primaria (CEIP San José de Calasanz y CEIP Teleno) y dos de educación secundaria (IES Vía de la Plata y IES Ornia). De carácter privado, la ciudad cuenta con dos centros, Nuestra Señora del Carmen (concertado) y Tierras de La Bañeza, este último de Formación Profesional y no concertado.

En los institutos de educación secundaria se imparte ESO, Bachillerato y algunos ciclos de Formación Profesional. En el Vía de la Plata los ciclos formativos ofertados son Administración y Finanzas, e Instalaciones Electrotécnicas, en grado superior, y Gestión Administrativa, Equipos e instalaciones electrotécnicas, e Instalación y mantenimiento electromecánico de maquinaria y conducción de líneas, en grado medio.

En cuanto a las enseñanzas de régimen especial, La Bañeza cuenta con una Escuela Municipal de Música (Odón Alonso Ordás) y un Aula de Educación de Personas Adultas (EPA).


La Bañeza no cuenta con hospital propio, por lo que han de acudir a los centros situados en León. Dispone de un centro de salud en el que se integran las zonas básicas de salud Bañeza I y Bañeza II. La primera engloba los municipios de Santa Elena de Jamuz y Soto de la Vega, además de la cabecera, y Bañeza II abarca Santa María de la Isla, San Esteban de Nogales, San Cristóbal de la Polantera, Roperuelos del Páramo, Valdefuentes del Páramo, Riego de la Vega, Quintana y Congosto, Quintana del Marco, Palacios de la Valduerna, La Antigua, Alija del Infantado, Castrocontrigo, Castrocalbón, Pozuelo del Páramo, Destriana, Castrillo de la Valduerna, Villazala, Villamontán de la Valduerna y Cebrones del Río. Desde hace unos años, distintos colectivos reclaman la construcción de un hospital comarcal para las zonas de Astorga y La Bañeza.


Los servicios sociales en La Bañeza son gestionados por la concejalía de Bienestar Social. Esta cuenta con una serie de programas municipales como discapacitados, drogodependencias, familia, infancia-ocio, juventud, mujer, participación social y personas mayores. Entre los medios que ofrece está el CEAS, que cuenta con cuatro trabajadores sociales y un animador comunitario, aparte del trabajador social con el que cuenta el Centro de Salud de La Bañeza.

Otros recursos que encontramos en el municipio son siete residencias para personas mayores de carácter privado y el colegio Nuestra Señora del Valle, de atención a minusválidos y gestionado por la diputación de León.

Lugar de paso de la antigua Vía de la Plata, La Bañeza está conectada con el resto de la comunidad y del país a través de varios viales de distinta categoría, siendo un importante nudo de comunicaciones comarcal:

Por último, cuenta con varios viales de carácter local que unen La Bañeza con otras poblaciones cercanas como Jiménez de Jamuz o Destriana.

Hasta 1985 estuvo operativa estación de La Bañeza, perteneciente a la línea Plasencia-Astorga, inaugurada en 1896. Desde hace unos años, numerosas organizaciones y empresas reclaman su reapertura para vertebrar el oeste peninsular eficazmente y recuperar la alternativa de transportar pasajeros y mercancías por ferrocarril.

El aeropuerto de León, que entró en servicio en 1999, está situado en los términos municipales de Valverde de la Virgen y San Andrés del Rabanedo, a 49 kilómetros de La Bañeza. Según las estadísticas de Aena, en 2008 el aeropuerto movió 122.809 pasajeros, 5.700 operaciones y 15,9 toneladas de carga.

Mantiene vuelos con Madrid, Barcelona, Valencia, Tenerife y París todo el año, que se refuerzan en temporada estival con enlaces a Palma de Mallorca, Málaga-Costa del Sol, Ibiza, Gran Canaria y Menorca. Se encuentra inmerso además en unas obras de ampliación que se centran en la construcción de una nueva área terminal y en la duplicación de la superficie actual de la plataforma.

Núcleo del enclave mozárabe que más tarde dio origen a la ciudad, sus orígenes se remontan al siglo IX. Destruida por Almanzor, fue reconstruida ya en el siglo XI. Cuenta con tres naves, conservándose el ábside románico. Fue reformada en época moderna, siendo de este momento la fachada plateresca y la torre. En su interior destaca el retablo barroco obra de Francisco de Rivera, los lienzos de Felipe Gil de Mena y una talla de San Salvador, obra de 1659 de Lucas Gutiérrez.

De estilo gótico estrellado, su construcción tiene lugar en el siglo XVI, siendo heredera de la antigua iglesia de San Pedro de Périx. Presenta planta basilical de tres naves, sufriendo algunas modificaciones en el siglo XVII. En su interior destacan una imagen de la Piedad, obra de Gregorio Fernández, el retablo del altar mayor, obra de Francisco de Rivera del siglo XVII y las tallas de Santa Teresa (Diego de Gamboa, 1634), San Pablo, San Juan de la Cruz (Diego de la Peña) y la Asunción (Lucas Gutiérrez, 1662).

La construcción de la torre se inició en 1750, sufriendo múltiples retrasos año tras año. El primer cuerpo fue obra de Antonio Martín de Suinaga y el segundo de Simón Gabilán Tomé. En 1894, el chapitel que la coronaba fue destruido por un incendio.

Ubicada en la plaza Mayor, se trata de un edificio de aire neoclasicista construido entre 1900 y 1909, obra del arquitecto Lázaro Cárdenas. Pocos años después se le añadió una torre hexagonal, con tejado de pizarra, y un carillón en el que cada hora suena el Himno de la alegría.

El antiguo hospital es quizás el edificio civil más antiguo de la ciudad, con las primeras referencias en 1539 y reconstruido en 1897. Junto a él se encuentra la capilla de la Vera Cruz, que alberga distintas tallas procesionales. En varias calles de la ciudad pueden encontrarse varios edificios modernistas. Presentan una o dos plantas de ladrillo o piedra, decoración de hierro en balcones y miradores y ornamentación con pilastras, guirnaldas y otros motivos.

La capilla de Nuestra Señora de las Angustias y Soledad guarda distintos pasos procesionales de la Semana Santa bañezana, al igual que la capilla de Nuestro Padre Jesús Nazareno, que alberga el Museo Imaginero. Por otra parte, también destaca la fachada del cementerio municipal, de estilo neomudéjar, obra de Juan Bautista Lázaro de Diego de 1887.

En La Bañeza se pueden encontrar los principales periódicos de información general de León, como el decano de la provincia, Diario de León, así como los principales diarios nacionales de información general (El Mundo, La Razón, ABC, El País) así como diarios económicos (Cinco Días, Expansión) y deportivos nacionales (As y Marca). Respecto a prensa local, la ciudad cuenta con el semanario El Adelanto Bañezano, fundado en 1932, La Bañeza Hoy, fundado en 1999 e Ibañeza.es, el periódico digital de La Bañeza y comarca, los cuales ofrecen noticias locales y comarcales.

En cuanto a radio, la ciudad cuenta con varias emisoras. De información general hay presencia de algunas de las cadenas nacionales como Onda Cero, Punto Radio, Radio María y Europa FM.


Además de las diferentes cadenas nacionales, existen otras de carácter autonómico como Canal 4 Castilla y León y Televisión Castilla y León, pero desde la unión de ambas corporaciones, conformando la sociedad Radio Televisión de Castilla y León, fueron sustituidas por los canales CYLTV y La 8, pudiéndose ver a través de la TDT.

La Bañeza cuenta con el Museo Imaginero, ubicado en la capilla de Nuestro Padre Jesús Nazareno y que alberga diversos pasos procesionales como un Nazareno (Luis Salvador Carmona, siglo XVIII), Nuestra Señora de la Amargura (Navarro Santafé, 1944), un Crucificado (Faustino Sanz Herranz, 1986) o un Jesús Prendido (Antonio Palau, 1941), la Casa-Museo de Don Ángel Riesco, que se encuentra en el recinto de la Ciudad Misioneras, en la carretera de Madrid, y en la que se muestran su despacho de trabajo, el oratorio, el dormitorio y fotografías y documentos personales, el Museo de las Alhajas en la Vía de la Plata, inaugurado en la primavera de 2011, y el Centro de Interpretación de las Tierras Bañezanas, ubicado en una antigua fábrica de harinas que conserva toda su maquinaria original. Este último presenta dos temáticas diferentes: por un lado, ofrece un recorrido por el proceso de fabricación de la harina, y por otro, invita a hacer un viaje por la historia de La Bañeza y su comarca.

Entre la variada gastronomía bañezana, destacan las alubias, que en 2006 obtuvieron la Indicación Geográfica Protegida (IGP) de La Bañeza-León, y las ancas de rana. En el ámbito de la repostería, son destacables los bollos de San Lázaro, los Imperiales, las Yemas o las pastas de San Blas.


El primer espacio teatral con el que contó La Bañeza fue el Teatro Municipal, construido en 1845, perdurando hasta 1922, año en que fue derribado. Al año siguiente, en 1923, se inaugura el Teatro Seoanez, de iniciativa privada, y reconvertido en el cine California en 1948. El teatro Pérez Alonso, construido según los diseños de Javier Sanz y también de iniciativa privada, fue inaugurado el 28 de abril de 1930 con la zarzuela ""El Huésped del Sevillano"", siendo en su época uno de los más importantes de la provincia. En 1997 fue comprado por el ayuntamiento, acometiendo una primera fase de rehabilitación, y en 2007 comenzó la reforma de manos del Ministerio de Vivienda, siendo reinaugurado en marzo de 2011.


La biblioteca pública "Juan de Ferreras", cuyos orígenes se remontan a 1942 y que cuenta con varias salas de consulta, hemeroteca, zona infantil, audiovisuales y acceso a Internet, y el Centro Cultural "de las Tierras Bañezanas" son otros espacios con los que cuenta la ciudad.

La ciudad cuenta con varias asociaciones que a lo largo del año organizan diversas actividades. Entre ellas están la Asociación Amigos del Camino de Santiago Monte Urba, la Asociación Española Contra el Cáncer de La Bañeza, la Asociación de Pensionistas y Jubilados Ntra. Señora de la Asunción, la Asociación de Familiares y Enfermos de Alzheimer de La Bañeza, la Agrupación de Consumidores y Usuarios de Castrillo de Juan, la Asociación de Amas de Casa, la Asociación Bañezana de Viudas Santa Joaquina de Vedruna, la Asociación de Alcohólicos Rehabilitados de La Bañeza (A.R.BA.) o el Consejo de Barrio de El Polvorín.

Durante los diez días que transcurren desde el Viernes de Dolores al Domingo de Pascua, un total de 14 procesiones, organizadas por las tres cofradías existentes (además de la Cofradía Penitencial de las Águedas), recorren las calles de la ciudad. Estas tres son la Cofradía de la Vera Cruz, fundada en el siglo XVI, la Cofradía de Nuestra Señora de las Angustias y Soledad, fundada en 1615 pero siendo de mayor antigüedad pues las primeras menciones aparecen en los años 1550-1570, y la Cofradía de Nuestro Padre Jesús Nazareno, fundada en 1667.

Entre sus acontecimientos más significativos destaca la procesión del Santo Potajero el Miércoles Santo, declarada de Interés Turístico Provincial y organizada por la Cofradía de Nuestra Señora de las Angustias y Soledad. Según estatutos de la Cofradía, ésta tenía que dar a los pobres tres comidas a lo largo del año, acudiendo a la iglesia donde se les aseaba y se les daba la comida. Con el tiempo, la comida se fue haciendo tan popular que actualmente acuden a él todas las clases sociales de la ciudad con su cazuela a comer el potaje de garbanzos con arroz y bacalao.

A lo largo del año son numerosos los eventos culturales y festivos que tienen lugar en La Bañeza. Cronológicamente, en el mes de febrero se celebran los carnavales, fiesta declarada de Interés Turístico Nacional en 2011. Tras la celebración de la Semana Santa, a mediados del mes de abril tiene lugar la Feria del Libro, durante la cual se convocan concursos de cuentos y de poesía.

A mediados de agosto se celebran las fiestas patronales en honor a Nuestra Señora de la Asunción y San Roque, durante las cuales tienen lugar las ferias del Motor y de Artesanía y una de las pocas carreras urbanas de motociclismo en España. Por último, en el mes de septiembre, se celebra la Feria Agro-Alimentaria en cuyo último día tiene lugar la Alubiada, en la que se reparten más de 5.000 raciones de alubias de La Bañeza. Además, cada sábado se instala en las calles de la ciudad el tradicional mercado semanal.
El carnaval bañezano es una de las festividades que más arraigo tienen por parte de todos los habitantes de la ciudad y comarca, siendo una cita obligada para bañezanos y turistas de la provincia.

En 1675 Antonio Ferreras ya menciona el carnaval refiriéndose a un testamento de un vecino de la ciudad. En épocas más modernas, la fiesta, aunque prohibida durante la dictadura de Francisco Franco, siguió celebrándose en la ciudad bajo permisos explícitos de la autoridad vigente, aunque con ciertas restricciones en la forma de llevarla a cabo. Ante esto, muchos carnavaleros se saltaban la norma, siendo perseguidos por las fuerzas de seguridad; de ahí proviene la expresión bañezana de "correr el Carnaval".

El carnaval actual empieza con el acto preliminar de la Proclamación de la Musa, aunque oficiosamente empieza con el Viernes Tranquilo, seguido de Sábado de Chispas, Domingo de Carnaval, Lunes (desfile infantil y Nochebruja), Martes de Carnaval y Miércoles de Ceniza con su Entierro de la Sardina. La fiesta se alarga actualmente hasta el sábado siguiente con el "Sábado Piraña".

El carnaval de La Bañeza se caracteriza por no estar motivado con un concurso de disfraces obteniendo premios o dinero, sino que cada participante sale disfrazado llevado por las ganas de pasarlo bien, mejorar su disfraz e interpretación y contribuir al embellecimiento de la fiesta en general.

El reconocimiento y pasión de los bañezanos ante esta celebración queda patente en la plaza que lleva su nombre ("Plaza del Carnaval") y en el reconocimiento de otros, siendo galardonada en 1990 con el Blasón de Turismo, declarada en 2002 Fiesta de Interés Turístico Regional. y en 2011 de Interés Turístico Nacional.


Además de los deportes que se practican en las instalaciones municipales y de los equipos escolares, en la ciudad destacan una serie de entidades. En fútbol cuenta con el La Bañeza Fútbol Club, que milita en el grupo octavo de la tercera división de España, la escuela de fútbol Club Deportivo La Bañeza, y La Bañeza Fútbol Sala, que juega en la Tercera División de Fútbol Sala, siendo el club de la ciudad que más éxitos ha conseguido, llegando a jugar en División de Honor.

En baloncesto cuenta con el Club Atlético Bañezano de Baloncesto, que juega la liga autonómica, y el Club Baloncesto La Bañeza. Otras disciplinas tienen representación en clubes como el Club Bañezano de Piragüismo, Club Deportivo Tenis de Mesa La Bañeza, Club Ciclista Bañezano, Club de Ajedrez de La Bañeza, Club de Atletismo de La Bañeza, Club de Montaña Teleno, Club de Gimnasia Rítmica, La Bañeza Club de Tiro, Club Deportivo Ciclista El Piñón Cortés, Club Deportivo BTT La Badana, Pesca Club La Bañeza y Moto Club Bañezano.


La Bañeza cuenta con varios espacios para la práctica del deporte: el campo de fútbol "La Llanera", las piscinas (cubierta y exterior) y el polideportivo municipal, que ofrece un pabellón cubierto, frontón, gimnasio y pistas de baloncesto, fútbol sala, tenis, pádel y voley-playa.


Entre los acontecimientos deportivos que tienen lugar en La Bañeza a lo largo del año está el Memorial Santiago Fuertes de ciclismo, la Media Maratón "Vía de la Plata", que se celebra en el mes de octubre, el Torneo de Baloncesto Ciudad de La Bañeza, y especialmente el Gran Premio de Velocidad "Ciudad de La Bañeza", que tiene lugar a mediados de agosto, durante la celebración de las fiestas patronales, y que en 2009 celebró su 50.ª edición. Se trata de uno de los pocos circuitos urbanos de motociclismo que existen en el mundo (sólo se asemeja el Tourist Trophy de la Isla de Man), contando con carreras de motos clásicas (2 tiempos y 4 tiempos), motos de 125cc y Moto3 y que en 2015 batió el récord de espectadores, más de 60.000 . En 2007 se presentó, tras años de desacuerdos entre distintas administraciones, el proyecto para la construcción de un circuito de velocidad, que actualmente está a la espera de su realización.

La ciudad de La Bañeza participa en la iniciativa de hermanamiento de ciudades promovida, entre otras instituciones, por la Unión Europea. A partir de esta iniciativa se han establecido lazos con las siguientes localidades:




</doc>
<doc id="1660" url="https://es.wikipedia.org/wiki?curid=1660" title="Lythraceae">
Lythraceae

Lythraceae es una familia del orden Myrtales; incluye entre 500 a 600 especies de hierbas principalmente, con algunos arbustos y árboles en una treintena de géneros. Su distribución es mundial, con la mayor parte de las especies en los trópicos, pero abarcan también las regiones de clima templado, incluso un género autóctono de la península ibérica, relacionado con los bordes de arroyos.

La familia lleva el nombre del género tipo, "Lythrum" cuyo nombre común es "salicaria". Ahora también incluye los granados, anteriormente clasificados en una familia separada, Punicaceae.

Son hierbas, arbustos o árboles pequeños, frecuentemente con tallos 4-angulados; plantas hermafroditas. Hojas membranáceas o menos frecuentemente coriáceas, opuestas, raramente subalternas o verticiladas, simples y enteras; estípulas como proyecciones axilares diminutas. Inflorescencias en racimos o cimas axilares o panículas terminales, bractéolas 2, opuestas en los pedicelos; flores actinomorfas o zigomorfas, 4–6-meras, perianto y estambres periginos, tubo floral campanulado a tubular, persistente (excepto en "Lafoensia"); lóbulos del cáliz valvados, (3–) 4–6 (–16), con o sin pequeños apéndices en los senos; pétalos ausentes o en igual número que los lóbulos del cáliz, arrugados, caducos, insertos en los márgenes internos del tubo floral entre los lóbulos del cáliz; estambres usualmente iguales en número a las partes del perianto o el doble (en "Cuphea" usualmente 11), raramente numerosos, anteras versátiles, introrsas; ovario súpero, libre del tubo floral, 2–4 (–6)-locular, estilo 1, estigma capitado o punctiforme, raramente bilobulado ("Adenaria"). Fruto una cápsula dehiscente o indehiscente generalmente envuelta por el tubo floral persistente; semillas 3 o más, aladas o no, sin endosperma.

Tradicionalmente se ha usado la "Salicaria" en infusión durante brotes de diarrea, debido a su alto poder astringente.








</doc>
<doc id="1661" url="https://es.wikipedia.org/wiki?curid=1661" title="Loranthaceae">
Loranthaceae

Las lorantáceas (Loranthaceae) son una familia de plantas generalmente arbustivas, epifitas, hemiparásitas u holoparásitas, siempre con clorofila (a veces poca). 
Hojas simples, enteras o escuamiformes, de disposición helicoidal o verticilada. Flores unisexuales o hermafroditas, actinomorfas, una envuelta con 4-6 piezas, androceo con igual número de piezas que el periantio, de ovario ínfero, unilocular, con 2-3 carpelos, óvulos reducidos al saco embrionario. Frutos por lo común en baya, semillas con tendencia al desdoblamiento de los cotiledones (2-4-6) y protegidas por una substancia pegajosa segregada por el eje floral (viscina, usada como liga para pájaros). Unas 1400 especies repartidas en 74 géneros, la mayoría intertropicales.



</doc>
<doc id="1662" url="https://es.wikipedia.org/wiki?curid=1662" title="Linaceae">
Linaceae

Linaceae es una familia cosmopolita de plantas Magnoliopsidas o dicotiledóneas de alrededor de 250 especies en todo el mundo que abarcan gran parte del planeta. La familia incluye plantas herbáceas o raramente leñosas, y árboles de gran porte en los trópicos. Perteneciente al orden Malpighiales.
Familia cosmopolita que consta de unas 250 especies. Está formada por árboles, arbustos, hierbas anuales y perennes. Ocupa regiones desérticas, mediterráneas, selvas, estepas y la Puna húmeda y seca. En general son hierbas o pequeñas matas, anuales, bienales o perennes. Hay 14 géneros, clasificados en dos subfamilias: Linoideae y Hugonioideae a menudo reconocida como una familia distinta, la Hugoniaceae.

La familia es de origen antiguo y es una familia muy afín a la familia Erythroxylaceae, con la cual algunos taxónomos antiguos la unían. 
Las hojas de las Linaceae son siempre sencillas.

En Linoideae, el género más grande es "Linum ", con 180 a 200 especies, incluyendo el lino de cultivo "Linum usitatissimum". Los miembros de Linoideae incluyen sobre todo herbáceas anuales y perennes, así como subarbustos leñosos, arbustos y pequeños árboles ("Tirpitzia") que habitan en latitudes templadas y tropicales de Eurasia, África, Australia y las Américas. 

Hugonioideae son enredaderas, arbustos y árboles y son casi en su totalidad de distribución tropical. El género más grande de Hugonioideae es"Hugonia", con aproximadamente 40 especies. Además de por sus hábitos de crecimiento y distribución geográfica, los géneros Linoideae y Hugonioideae pueden ser diferenciados por el número de estambres fértiles (5 en Linoideae, 10 en Hugonioideae) y el tipo de fruto: en cápsulas en Linoideae y drupa carnosa en forma de fruta, en Hugonioideae que produce muchos tipos diferentes de fruta, consumidas por los pájaros, que dispersan las semillas.

Tienen las hojas simples enteras, casi siempre alternas, las hojas están opuestas o alternadas, sentadas, sin estípulas aunque a veces si están estipuladas. Inflorescencias cimosas. Flores hermafroditas, actinomorfas, pentámeras o muy raramente tetrámeras, estas mucho más frecuente en los trópicos, pétalos llamativos, prontamente caedizos, de color claro, con uña estrecha. Cáliz con sépalos libres. Corola con pétalos libres o ligeramentes soldados en la base. Androceo con 4 o 5 estambres alternando con los pétalos soldados en la base, a veces alternando con 1 verticilo de estaminodios. Ovario súpero, con 4-5 carpelos, 4-5 cavidades y 4-5 estilos. Estigmas lineares o capitados. Diplostemonas con los estambres soldados al disco; de ovario súpero, pentacarpelar, sincarpico, con estilos libres o ligeramente soldados; dos óvulos por carpelo, con un falso tabique interno con 10 cavidades. Fruto sin pico, en cápsula loculicida o raramente en drupa. Fruto en cápsula loculicida, con 8-10 valvas. Dos semillas por cavidad, separadas por un pseudotabique. 
Una especie de relevancia agrícola es el lino, "Linum usitatissimum", cultivado para la obtención de fibras textiles y aceites.


Géneros en la subfamilia Linoideae

Géneros en la subfamilia Hugonioideae 

 Y sobre su sinónimo, líneo.


</doc>
<doc id="1665" url="https://es.wikipedia.org/wiki?curid=1665" title="Lenguaje de marcado">
Lenguaje de marcado

Un lenguaje de marcado o lenguaje de marcas es una forma de codificar un documento que, junto con el texto, incorpora etiquetas o marcas que contienen información adicional acerca de la estructura del texto o su presentación.

El lenguaje de marcas más extendido es el HTML ("HyperText Markup Language", lenguaje de marcado de hipertexto), fundamento del World Wide Web (entramado de comunicación de alcance mundial).

Los lenguajes de marcado suelen confundirse con lenguajes de programación. Sin embargo, no son lo mismo, ya que el lenguaje de marcado no tiene funciones aritméticas o variables, como poseen los lenguajes de programación. Históricamente, el marcado se usaba y se usa en la industria editorial y de la comunicación, así como entre autores, editores e impresores.

Un ejemplo de cómo funciona el lenguaje de marcado puede observarse en el dictado de viva voz de un documento a una persona que lo transcribe a máquina:

Se suele diferenciar entre tres clases de lenguajes de marcado, aunque en la práctica pueden combinarse varias clases en un mismo documento. Por ejemplo, el HTML contiene etiquetas puramente procedimentales, como la "B" de "bold" (negrita), junto con otras puramente descriptivas ("BLOCKQUOTE", el atributo "HREF"). El HTML también incluye el elemento "PRE", que indica que el texto debe representarse tal y como está escrito.

El marcado de presentación es aquel que indica el formato del texto. Este tipo de marcado es útil para maquetar la presentación de un documento para su lectura, pero resulta insuficiente para el procesamiento automático de la información. El marcado de presentación resulta más fácil de elaborar, sobre todo para cantidades pequeñas de información. Sin embargo resulta complicado de mantener o modificar, por lo que su uso se ha ido reduciendo en proyectos grandes en favor de otros tipos de marcado más estructurados.

Se puede tratar de averiguar la estructura de un documento de esta clase buscando pistas en el texto. Por ejemplo, el título puede ir precedido de varios saltos de línea (o renglón), y estar ubicado centrado en la página web. Varios programas pueden deducir la estructura del texto basándose en esta clase de datos, aunque el resultado suele ser bastante imperfecto. Un ejemplo de marcado de presentación, puede ser RTF.

El marcado de procedimientos está enfocado hacia la presentación del texto, sin embargo, también es visible para el usuario que edita el texto. El programa que representa el documento debe interpretar el código en el mismo orden en que aparece. Por ejemplo, para formatear un título, debe haber una serie de directivas inmediatamente antes del texto en cuestión, indicándole al software instrucciones tales como centrar, aumentar el tamaño de la fuente, o cambiar a negrita. Inmediatamente después del título deberá haber etiquetas inversas que reviertan estos efectos. En sistemas más avanzados se utilizan macros o pilas que facilitan el trabajo.

Algunos ejemplos de marcado de procedimientos son nroff, troff, TeX. Este tipo de marcado se ha usado extensivamente en aplicaciones de edición profesional, manipulados por tipógrafos calificados, ya que puede llegar a ser extremadamente complejo.

El marcado descriptivo o semántico utiliza etiquetas para describir los fragmentos de texto, pero sin especificar cómo deben ser representados, o en qué orden. Los lenguajes expresamente diseñados para generar marcado descriptivo son el SGML y el XML.

Las etiquetas pueden utilizarse para añadir al contenido cualquier clase de metadatos. Por ejemplo, el estándar Atom, un lenguaje de sindicación, proporciona un método para marcar la hora «actualizada», que es el dato facilitado por el editor de cuándo ha sido modificada por última vez cierta información. El estándar no especifica cómo se debe representar, o siquiera si se debe representar. El software puede emplear este dato de múltiples maneras, incluyendo algunas no previstas por los diseñadores del estándar.

Una de las virtudes del marcado descriptivo es su flexibilidad: los fragmentos de texto se etiquetan "tal como son", y no "tal como deben aparecer". Estos fragmentos pueden utilizarse para más usos de los previstos inicialmente. Por ejemplo, los hiperenlaces fueron diseñados en un principio para que un usuario que lee el texto los pulse. Sin embargo, los buscadores los emplean para localizar nuevas páginas con información relacionada, o para evaluar la popularidad de determinado sitio web.

El marcado descriptivo también simplifica la tarea de reformatear un texto, debido a que la información del formato está separada del propio contenido. Por ejemplo, un fragmento indicado como "cursiva" <nowiki>(texto)</nowiki>, puede emplearse para marcar énfasis o bien para señalar palabras en otro idioma. Esta ambigüedad, presente en el marcado presentacional y en el procedimental, no puede soslayarse más que con una tediosa revisión a mano. Sin embargo, si ambos casos se hubieran diferenciado descriptivamente con etiquetas distintas, podrían representarse de manera diferente sin esfuerzo.

El marcado descriptivo está evolucionando hacia el "marcado genérico". Los nuevos sistemas de marcado descriptivo estructuran los documentos en árbol, con la posibilidad de añadir referencias cruzadas. Esto permite tratarlos como bases de datos, en las que el propio almacenamiento tiene en cuenta la estructura, no como en los grandes objetos binarios ("blobs") como en el pasado. Estos sistemas no tienen un esquema estricto como las bases relacionales, por lo que a menudo se las considera "bases semiestructuradas".

Esta es una relación de los principales lenguajes de marcas ordenados por su campo de aplicación. Nótese que los lenguajes de ámbito general pueden usarse para aplicaciones más específicas (pero no al revés). Para ver una lista más completa consulte .


Los lenguajes de marcas se llaman así por la práctica tradicional de marcar los manuscritos con instrucciones de impresión en los márgenes. En la época de la imprenta, esta tarea ha correspondido a los marcadores, que indicaban el tipo de letra, el estilo y el tamaño, así como la corrección de errores, para que otras personas compusieran la tipografía. Esto condujo a la creación de un grupo de marcas estandarizadas. Con la introducción de las computadoras, se trasladó un concepto similar al mundo de la informática.

El concepto de lenguaje de marcas fue expuesto por primera vez por William W. Tunnicliffe en 1967. La mayor novedad consistía en la separación entre la presentación y la estructura del texto. Tunnicliffe, que prefería referirse a este concepto como "codificación genérica" ("generic coding"), dirigiría más tarde el desarrollo de un estándar al que bautizaría como GenCode, destinado a la industria editorial. El editor Stanley Fish también expuso ideas similares a finales de los años 1960. Brian Reid, en su disertación de 1980 en la Carnegie Mellon University, mostró su teoría y una implementación práctica de un lenguaje descriptivo todavía en uso.

Sin embargo, quien es considerado el padre de los lenguajes de marcas es Charles Goldfarb, investigador para la compañía IBM. Goldfarb participó en la creación del lenguaje GML, y posteriormente dirigió el comité que elaboró el estándar SGML, la piedra angular de los lenguajes de marcas. En cualquier caso, y a pesar de las controversias sobre su origen, es comúnmente aceptado que la idea surgió de forma independiente varias veces durante los 70, y que se generalizó en los años 1980.

El primer lenguaje que diferenció claramente la estructura de la presentación fue ciertamente el Scribe, desarrollado por Brian Reid y descrito en 1980 en su tesis doctoral. Scribe era revolucionario por varios motivos, no solo porque separaba el estilo de las propias marcas del documento, también por el control gramático del empleo de elementos descriptivos. Scribe influyó en el desarrollo de los lenguajes posteriores. 

Otro de los principales estándares de publicación es TeX, creado y mantenido por Donald Knuth en los años 70 y 80. TeX se centra en la estructura detallada del texto y la descripción de las fuentes, fundamentalmente en el campo de las publicaciones matemáticas especializadas. Esto obligó a Knuth a dedicar un tiempo considerable en el estudio de la tipografía. Sin embargo, TeX requiere amplios conocimientos para ser utilizado, por lo que solo ha cuajado en entornos académicos, en los que es el estándar "de facto" en varias disciplinas científicas. El software más extendido para el empleo de TeX es LaTeX.

Al margen de la industria editorial también surgieron algunas iniciativas, como los lenguajes troff y nroff, lenguajes utilizados para maquetación en sistemas UNIX. Su funcionalidad era limitada porque obligaba a trabajar mediante ensayo y error, hasta que las marcas insertadas en el texto ofrecieran el resultado deseado. Estos lenguajes no llegaron a cuajar en entornos profesionales, siendo utilizados por usuarios ocasionales. La aparición de procesadores de texto tipo WYSIWYG relegó a estos sistemas al olvido.

La iniciativa que sentaría las bases de los actuales lenguajes, partiría de la empresa IBM, que buscaba nuevas soluciones para mantener grandes cantidades de documentos. El trabajo fue encomendado a Charles F. Goldfarb, que junto con Edward Mosher y Raymond Lorie, diseñó el "Generalized Markup Language" o GML (nótese que también son las iniciales de sus creadores). Este lenguaje heredó del proyecto GenCode la idea de que la presentación debe separarse del contenido. El marcado, por tanto, se centra en definir la estructura del texto y no su presentación visual.

El lenguaje GML fue un gran éxito y pronto se extendió a otros ámbitos, siendo adoptado por el gobierno de Estados Unidos, con lo que surgió la necesidad de estandarizarlo. En los primeros años 1980 se constituyó un comité dirigido por Goldfarb. Sharon Adler, Anders Berglund y James D. Mason fueron también miembros de dicho comité. Se incorporaron ideas de diferentes fuentes, y participó gran cantidad de gente. Tras un largo proceso, en 1986 la Organización Internacional para la Estandarización publicaría el "Standard Generalized Markup Language" con rango de Estándar Internacional con el código ISO 8879.

El SGML especifica la sintaxis para la inclusión de marcas en los textos, así como la sintaxis del documento que especifica qué etiquetas están permitidas y dónde: el Document Type Definition o schema. Esto permitía que un autor emplease cualquier marca que quisiera, eligiendo nombres para las etiquetas que tuvieran sentido tanto por el tema del documento como por el idioma. Así, el SGML es, estrictamente hablando, un metalenguaje, del que se derivan varios lenguajes especializados. Desde finales de los 80 han aparecido nuevos lenguajes basados en SGML, como por ejemplo el TEI o el DocBook.

El SGML tuvo una gran aceptación y hoy día se emplea en campos en los que se requiere documentación a gran escala. A pesar de ello, resultó farragoso y difícil de aprender, como consecuencia de la ambición de los objetivos previstos. Su gran potencia era a la vez una ventaja y una desventaja. Por ejemplo, ciertas etiquetas podían tener solo principio, o solo final, o incluso ser obviadas, pensando en que los textos serían redactados a mano y que así se ahorrarían pulsaciones de teclas. Sin embargo fue un punto clave en el desarrollo de los lenguajes de marcas actuales, ya que la gran mayoría derivan de este.

En 1991, parecía que los editores WYSIWYG (que almacenan los documentos en formatos binarios propietarios) abarcarían casi la totalidad del procesamiento de textos, relegando al SGML a usos profesionales o industriales muy específicos. Sin embargo, la situación cambió drásticamente cuando Sir Tim Berners-Lee, que había aprendido SGML de su compañero en el CERN Anders Berglund, utilizó la sintaxis SGML para crear el HTML.

Este lenguaje era similar a cualquier otro creado a partir del SGML, sin embargo resultó extraordinariamente sencillo, tanto que el DTD no se desarrolló hasta más tarde. DeRose argumenta que la flexibilidad y escalabilidad del marcado HTML fue uno de los principales factores, junto con el empleo de URLs y la distribución libre de navegadores, del éxito de la World Wide Web.

El HTML es hoy día el tipo de documento más empleado en el mundo. Su sencillez era tal que cualquier persona podía escribir documentos en este formato, sin apenas necesidad de conocimientos de informática. Esta fue una de las razones de su éxito, pero también condujo a un cierto caos. El crecimiento exponencial de la web en los años 90 produjo documentos en cantidades ingentes pero mal estructurados, problema agravado aún más por la falta de respeto por los estándares, por parte de diseñadores web y fabricantes de software.

La respuesta a los problemas surgidos en torno al HTML vino de la mano del XML (eXtensible Markup Language). El XML es un metalenguaje que permite crear etiquetas adaptadas a las necesidades (de ahí lo de «extensible»). El estándar define cómo pueden ser esas etiquetas y qué se puede hacer con ellas. Es además especialmente estricto en cuanto a lo que está permitido y lo que no, todo documento debe cumplir dos condiciones: ser válido y estar bien formado.

El XML fue desarrollado por el World Wide Web Consortium, mediante un comité creado y dirigido por Jon Bosak. El objetivo principal era simplificar el SGML para adaptarlo a un campo muy preciso: documentos en internet.

El nuevo lenguaje se extendió con rapidez, ya que todo documento XML es a su vez SGML. Los programas y documentos creados para y con SGML podían convertirse casi automáticamente al nuevo lenguaje. El XML simplificó radicalmente la complejidad del SGML, facilitando el aprendizaje y la implementación del nuevo estándar. Se solucionaron además viejos problemas, como los surgidos de la internacionalización, y la imposibilidad de validar un documento sin schema. El acierto fundamental de este lenguaje es que logra un equilibrio entre simplicidad y flexibilidad.

El XML fue ideado en principio para entornos semiestructurados, como textos y publicaciones. Uno de los ejemplos más claros es el XHTML, la redefinición del HTML en clave XML, con las ventajas que ello supone. Sin embargo pronto se observó que sus virtudes podían ser útiles en campos bien distintos. Los lenguajes basados en XML tienen aplicaciones incontables, como en la transacción de datos entre servidores, intercambio de información financiera, fórmulas y reacciones químicas, y un largo etcétera.

Las nuevas tendencias han abandonado los documentos con estructura en árbol. Los textos de la literatura antigua suelen tener estructura de prosa o de poesía: versículos, párrafos, etc. Los documentos de referencia suelen organizarse en libros, capítulos, versos y líneas. A menudo se entremezclan unos con otros, por lo que la estructura en árbol no se ajusta a sus necesidades. Los nuevos sistemas de modelado superan estos inconvenientes, como el MECS, diseñado para la obra de Wittgenstein, o las TEI Guidelines, LMNL, y CLIX.

La "Iniciativa de codificación de textos" o Text Encoding Initiative (TEI) ha publicado multitud de guías para la codificación de documentos de interés en humanidades y ciencias sociales, desarrollados durante años de trabajo colaborativo internacional. Estas directrices se han empleado en innumerables proyectos de catalogación de documentos históricos, trabajos académicos, etc.

Los lenguajes de marcado son la herramienta fundamental en el diseño de la web semántica, aquella que no solo permite acceder a la información, sino que además define su significado, de forma que sea más fácil su procesamiento automático y se pueda reutilizar para distintas aplicaciones. Esto se consigue añadiendo datos adicionales a los documentos, por medio de dos lenguajes expresamente creados: el RDF ("Resource descriptión framework"-Plataforma de descripción de recursos) y OWL ("Web Ontology Language"-Lenguaje de ontologías para la web), ambos basados en XML.

Una de las principales ventajas de este tipo de codificación es que la gran mayoría puede ser interpretada directamente dado que son archivos de texto plano, quedando excluidos algunos lenguajes de presentación que guardan la información en archivos binarios como '.doc' de MS Word donde solo una pequeña parte de la información es legible. Esto es una ventaja evidente respecto a los sistemas de archivos binarios, que requieren siempre de un programa intermediario para trabajar con ellos. Un documento escrito con lenguajes de marcado puede ser editado por un usuario con un sencillo editor de textos, sin perjuicio de que se puedan utilizar programas más sofisticados que faciliten el trabajo.

Al tratarse solamente de texto, los documentos son independientes de la plataforma, sistema operativo o programa con el que fueron creados. Esta fue una de las premisas de los creadores de GML en los años 70, para no añadir restricciones innecesarias al intercambio de información. Es una de las razones fundamentales de la gran aceptación que han tenido en el pasado y del excelente futuro que se les augura.

Las instrucciones de marcado se entremezclan con el propio contenido en un único archivo o flujo de datos. Este es un ejemplo en diferentes lenguajes de marcas:

El código entre paréntesis angulares como "<ul>", o con códigos "\section", son instrucciones de marcado, también llamados etiquetas. Estas etiquetas en concreto son descriptivas de la estructura del documento, pudiendo ser su presentación visual de varias maneras. La etiqueta i (de "italics", cursiva), por el contrario, especifica que el texto se debe mostrar en cursiva, sin especificar el motivo de esta diferenciación: es una etiqueta presentacional. El texto entre estas instrucciones es el propio contenido del documento.

Las organizaciones de estándares han venido desarrollando lenguajes especializados para los tipos de documentos de comunidades o industrias concretas. Uno de los primeros fue el CALS, utilizado por las fuerzas armadas de EE. UU. para sus manuales técnicos. Otras industrias con necesidad de gran cantidad de documentación, como las de aeronáutica, telecomunicaciones, automoción o hardware, ha elaborado lenguajes adaptados a sus necesidades. Esto ha conducido a que sus manuales se editen únicamente en versión electrónica, y después se obtenga a partir de esta las versiones impresas, en línea o en CD. Un ejemplo notable fue el caso de Sun Microsystems, empresa que optó por escribir la documentación de sus productos en SGML, ahorrando costes considerables. El responsable de aquella decisión fue Jon Bosak, que más tarde fundaría el comité del XML.

Aunque originalmente los lenguajes de marcas se idearon para documentos de texto, se han empezado a utilizar en áreas como gráficos vectoriales, servicios web, sindicación web o interfaces de usuario. Estas nuevas aplicaciones aprovechan la sencillez y potencia del lenguaje XML. Esto ha permitido que se pueda combinar varios lenguajes de marcas diferentes en un único archivo, como en el caso de XHTML+SMILy de XHTML+MathML+SVG.




</doc>
<doc id="1667" url="https://es.wikipedia.org/wiki?curid=1667" title="Latín">
Latín

El latín es una lengua, que pertenece a las lenguas itálicas y a su vez a la familia de las lenguas indoeuropeas fue hablada en la Antigua Roma y posteriormente durante la Edad Media y la Edad Moderna, llegando hasta la Edad Contemporánea, pues se mantuvo como lengua científica hasta el siglo XIX. Su nombre deriva de una zona geográfica de la península itálica donde se desarrolló Roma, el Lacio (en latín, "Latium").

Adquirió gran importancia con la expansión de Roma, y fue lengua oficial del imperio en gran parte de Europa y África septentrional, junto con el griego. Como las demás lenguas indoeuropeas en general, el latín era una lengua flexiva de tipo fusional con un mayor grado de síntesis nominal que las actuales lenguas romances, en la cual dominaba la flexión mediante sufijos, combinada en determinadas veces con el uso de las preposiciones, mientras que en las lenguas modernas derivadas dominan las construcciones analíticas con preposiciones, mientras que se ha reducido la flexión nominal a marcar solo el género y el número, conservando los casos de declinación solo en los pronombres personales (estos tienen, además, un orden fijo en los sintagmas verbales).

El latín originó un gran número de lenguas europeas, denominadas lenguas romances, como el español, el francés, el franco-provenzal, el friulano, el gallego, el istriano, el istrorrumano, el italiano, el ladino, el ligur, el lombardo, el meglenorrumano, el napolitano, el occitano, el piamontés, el portugués, el romanche, el rumano, el sardo, el siciliano, el valón, el véneto, aragonés, el arrumano, el asturleonés, el catalán, el corso, el emiliano-romañol, y otros ya extintos, como el dalmático. También ha influido en las palabras de las lenguas modernas debido a que durante muchos siglos, después de la caída del Imperio romano, continuó usándose en toda Europa como "lingua franca" para las ciencias y la política, sin ser seriamente amenazada en esa función por otras lenguas en auge (como el castellano en el siglo XVII o el francés en el siglo XVIII), hasta prácticamente el siglo XIX.

La Iglesia católica lo usa como lengua litúrgica oficial (sea en el rito romano sea en los otros ritos latinos), aunque desde el Concilio Vaticano II se permiten además las lenguas vernáculas. También se usa para los nombres binarios de la clasificación científica de los reinos animal y vegetal, para denominar figuras o instituciones del mundo del Derecho, como lengua de redacción del "Corpus Inscriptionum Latinarum", y en artículos de revistas científicas publicadas total o parcialmente en esta lengua.

El estudio del latín, junto con el del griego clásico, es parte de los llamados "estudios clásicos", y aproximadamente hasta los años 1960 fue estudio casi imprescindible en las humanidades. El alfabeto latino, derivado del alfabeto griego, es ampliamente el alfabeto más usado del mundo con diversas variantes de una lengua a otra.

La historia del latín comienza en el siglo VIII a. C. y llega, por lo menos, hasta la Edad Media; se pueden distinguir los siguientes períodos:

El latín aparece hacia el año 1000 a. C. en el centro de Italia, al sur del río Tíber, con los Apeninos y el mar Tirreno al oeste, en una región llamada Latium (Lacio), de donde proviene el nombre de la lengua y el de sus primeros habitantes, los latinos; sin embargo, los primeros testimonios escritos datan del siglo VI a. C., como la inscripción de Duenos y otras similares.

En los primeros siglos de Roma, desde la fundación al siglo IV a. C., el latín tenía una extensión territorial limitada: Roma y algunas partes de Italia, y una población escasa. Era una lengua de campesinos.

Así lo demuestran las etimologías de muchos términos del culto religioso, del derecho o de la vida militar. Destacamos los términos "stippulare" ('estipular'), derivado de "stippa" ('paja'), o "emolumentum" ('emolumento'), derivado de "emolere" ('moler el grano'), en el lenguaje del derecho.

En este sentido, los latinos, desde época clásica al menos, hablaban de un "sermo rusticus" ('habla del campo'), opuesto al "sermo urbanus", tomando conciencia de esta variedad dialectal del latín. «En el campo latino se dice "edus" ('cabrito') lo que en la ciudad "haedus" con una a añadida como en muchas palabras».

Después del periodo de dominación etrusca y la invasión de los galos (390 a. C.), la ciudad fue extendiendo su imperio por el resto de Italia. A finales del siglo IV a. C., Roma se había impuesto a sus vecinos itálicos. Los etruscos dejaron su impronta en la lengua y la cultura de Roma, pero los griegos presentes en la Magna Grecia influyeron más en el latín, dotándolo de un rico léxico.

El latín de la ciudad de Roma se impuso a otras variedades de otros lugares del Lacio, de las que apenas quedaron algunos retazos en el latín literario. Esto hizo del latín una lengua con muy pocas diferencias dialectales, al contrario de lo que pasó en griego. Podemos calificar, pues, al latín de lengua unitaria.

Después, la conquista de nuevas provincias, primero las Galias con César, hasta la de la Dacia (Rumania) por parte de Trajano, supuso la expansión del latín en un inmenso territorio y la incorporación de una ingente cantidad de nuevos hablantes.

Paralelamente a la expansión territorial de Roma, el latín se desarrolló como lengua literaria y como "lingua franca" a la vez que el griego, que había tenido estos papeles antes. Desde el siglo II a. C., con Plauto y Terencio, hasta el año 200 d. C. con Apuleyo tenemos una forma de latín que no tiene ninguna variación sustancial.

El latín era una lengua itálica, lo que significa que la mayoría de elementos gramaticales y la mayor parte de su léxico provienen por evolución natural de las lenguas de dialectos y hablas indoeuropeas.

El idioma original de los grupos latinos al instalarse en la península itálica se vio influido por el contacto con hablantes de otros grupos tanto indoeuropeos (oscos, umbros, griegos, celtas) como no indoeuropeos (etruscos, cretenses, picenos, ilirios, ligures…). Suelen distinguirse tres tipos de influencia sociolingüística:
Esta distinción, sin embargo, puede no resultar del todo operativa; por ejemplo, el etrusco pudo haber sido a la vez substrato, adstrato y superestrato en diferentes épocas.

Los habitantes de las regiones de la antigua Italia en las que posteriormente se difundió el latín eran hablantes nativos de otras lenguas, que al ser asimilados finalmente a la cultura latina ejercieron cierta influencia lingüística de sustrato. A veces, para indicar estas lenguas, se habla de sustrato mediterráneo, que proporcionó al latín el nombre de algunas plantas y animales que los indoeuropeos conocieron al llegar. Son lenguas muy poco conocidas, pues quedan solo unos pocos restos escritos, algunos aún sin descifrar. Un sustrato del latín arcaico en la ciudad de Roma y alrededores fue claramente la lengua etrusca.

En cuanto a la influencia del sustrato indoeuropeo osco-umbro, resulta interesante el hecho de que prefigura algunas de las características fonéticas y fonológicas que más tarde aparecerían en las lenguas romances (ciertas palatalizaciones y monoptongaciones), pues muchos hablantes de lenguas itálicas al romanizarse conservaron ciertos rasgos fonéticos propios, incluso (marginalmente) dentro de las lenguas románicas.

Fenómenos de este tipo son la influencia céltica a la que se atribuye la lenición de las consonantes intervocálicas o la [y] francesa, el vasco (o alguna lengua parecida), al que se atribuye la aspiración de la /f/ española en /h/, o el influjo eslavo, responsable de la centralización de las vocales rumanas.

Sustrato etrusco: La influencia del etrusco en la fonología latina se refleja en el hecho de desarrollar algunas aspiradas ("pulcher", 'hermoso') y la tendencia a cerrar "-o" en "-u." Las inscripciones etruscas muestran una tendencia a realizar como aspiradas oclusivas sordas previamente no-aspiradas, y poseía un sistema fonológico de solo cuatro timbres vocálicos /a, e, i, u/, teniendo este último una cualidad entre [o] y [u] que habría influido en la tendencia del latín a cerrar algunas /*o/ en [u].

Además los numerales latinos "duodeviginti" ('18') y "undeviginti" ('19') son claramente calcos lingüísticos formados a partir de las formas etruscas "esl-em zathrum" ('18') "thu-nem zathrum", '19' (donde "zathrum" es la forma etrusca para '20', "esl-" '2' y "thun-" '1'). También es un hecho de sustrato del etrusco en latín el sufijo "-na" en palabras como "persona," etc.

Durante un tiempo, Roma tuvo importantes contingentes de población de origen etrusco, por lo que el etrusco fue tanto una lengua substrato como una lengua superestrato, al menos durante el período que abarca la monarquía romana y, en menor medida, la república romana. La influencia del etrusco es particularmente notoria en ciertas áreas del léxico, como la relacionada con el teatro y la adivinación. Roma también sufrió invasiones de los galos cisalpinos, aunque no parecen existir importantes indicios de influencia celta en el latín. Sí existen algunas evidencias en el vocabulario de préstamos léxicos directos de lenguas osco-umbras, que constituyen la principal influencia de tipo substrato en el latín clásico.

Por otra parte, si bien desde antiguo los romanos tenían contactos con pueblos germánicos no existen fenómenos de influencia léxica en latín clásico. A diferencia de lo que sucede con las lenguas románicas occidentales que, entre los siglos V y VIII, recibieron numerosos préstamos léxicos del germánico occidental y del germánico oriental. Esto contrasta con la profunda influencia que el latín ejerció en el predecesor del alto alemán antiguo. Igualmente, existen abundantes rastros de la administración romana en la toponimia de regiones que hoy son de habla germánica, como por ejemplo Colonia. Los elementos germánicos en la Romania occidental proceden del período del Bajo Imperio, y constituyen el principal superestrato en latín tardío. El flujo no se interrumpió en la formación de las lenguas románicas. Las influencias de los pueblos godo, alemánico, borgoñés, franco y lombardo en las lenguas románicas se da mayoritariamente en el campo de la toponimia y la antroponimia. Aparte de estos, el número de préstamos es bastante reducido.

Es la debida al contacto con pueblos que convivieron con los latinos sin tenerlos dominados ni depender de ellos. Este tipo de influencia se nota más en el estilo y el léxico adquiridos que en los cambios fónicos de la lengua. Los adstratos osco, umbro y griego son responsables del alfabeto y sobre lo relacionado con la mitología, pues los romanos tomaron "prestados" los dioses helenos, aunque con nombres latinos.

Adstrato griego: la entrada masiva de préstamos y calcos áticos y jónicos puso en guardia a los latinos desde tiempos muy tempranos, encabezados por Catón el Viejo en el siglo III a. C. Pero en la Edad de Oro de la literatura latina los romanos se rindieron ante la evidente superioridad del idioma griego. Bien pueden resumir este sentimiento los famosos versos de Horacio: «"Graecia capta ferum victorem cepit et artis / intulit agresti Latio"» («La Grecia conquistada conquistó a su fiero vencedor e introdujo las artes en el rústico Lacio»).

Esta entrada masiva de helenismos no se limitó a la literatura, las ciencias o las artes. Afectó a todos los ámbitos de la lengua, léxico, gramatical y estilístico, de modo que podemos encontrar el origen griego en muchas palabras comunes de las lenguas románicas.

Después de la Edad Clásica, el cristianismo fue uno de los factores más potentes para introducir en la lengua latina hablada una serie de elementos griegos nuevos. Ej: παραβολη > parábola. Encontramos esta palabra dentro de la terminología retórica, pero sale de ella cuando se usa por los cristianos y adquiere el sentido de parábola, es decir, predicación de la vida de Jesús. Poco a poco va adquiriendo el sentido más general de «palabra», que sustituye en toda la Romanía al elemento que significaba «palabra» ("verbum"). El verbo que deriva de "parabole" ("parabolare, parolare") sustituye en gran parte de la Romanía al verbo que significaba «hablar» ("loquor").

El cuerpo de libros escritos en latín, retiene un legado duradero de cultura de la Antigua Roma. Los romanos produjeron una extensa cantidad de libros de poesía, comedia, tragedia, sátira, historia y retórica, trazando arduamente al modo de otras culturas, particularmente al estilo de la más madura literatura griega. Un tiempo después de que el Imperio romano de occidente cayese, la lengua latina continuaba jugando un papel muy importante en la cultura europea occidental.

La literatura latina normalmente se divide en distintos períodos. En lo que respecta a la primera, la literatura primitiva, solo restan unas pocas obras sobrevivientes, los libros de Plauto y Terencio; se han conservado dentro de los más populares autores de todos los períodos. Muchas otras, incluyendo la mayoría de los autores prominentes del latín clásico, han desaparecido, aunque bien algunas han sido redescubiertas siglos después.

El periodo del latín clásico, cuando la literatura latina es ampliamente considerada en su cumbre, se divide en la Edad Dorada, que cubre aproximadamente el periodo del inicio de siglo I a. C. hasta la mitad del siglo I d. C.; y la Edad de Plata, que se extiende hasta el siglo II d. C. La literatura escrita después de la mitad del siglo II es comúnmente denigrada e ignorada.

En el Renacimiento muchos autores clásicos fueron redescubiertos y su estilo fue conscientemente imitado. Pero sobre todo, se imitó a Cicerón, y su estilo se ha apreciado como el perfecto culmen del latín. El latín medieval fue frecuentemente despreciado como latín macarrónico; en cualquier caso, muchas grandes obras de la literatura latina fueron producidas entre la antigüedad y la Edad Media, aunque no sea de los antiguos romanos.

La literatura latina romana abarca dos partes: la literatura indígena y la imitada.




Tras la caída del Imperio romano, el latín todavía fue usado durante varios siglos como la única lengua escrita en el mundo posterior al estado romano. En la cancillería del rey, en la liturgia de la Iglesia católica o en los libros escritos en los monasterios, la única lengua usada era el latín. Un latín muy cuidado, aunque poco a poco se vio influido por su expresión hablada. Ya en el siglo VII, el latín vulgar había comenzado a diferenciarse originando el protorromance y después las primeras fases de las actuales lenguas romances.

Con el renacimiento carolingio del siglo IX, los mayores pensadores de la época, como el lombardo Pablo el Diácono o el inglés Alcuino de York, se ocuparon de reorganizar la cultura y la enseñanza en su imperio. En lo que se refiere al latín, las reformas se dirigieron a la recuperación más correcta de forma escrita, lo que le separó definitivamente de la evolución que siguieron las lenguas romances.

Luego, con el surgimiento de las primeras y pocas universidades, las enseñanzas dadas por personas que provenían de toda Europa eran rigurosamente en latín. Pero un cierto latín, el que no podía decirse que fuera la lengua de Cicerón u Horacio. Los doctos de las universidades elaboraron un latín particular, escolástico, adaptado a exprimir los conceptos abstractos y ricos en elaborados matices de la filosofía de la época. El latín ya no era la lengua de comunicación que fue en el mundo romano; todavía era una lengua viva y vital, todo menos estática.

En el siglo XIV, en Italia, surgió un movimiento cultural que favoreció un renovado interés por el latín antiguo: el Humanismo. Comenzado ya por Petrarca, sus mayores exponentes fueron Poggio Bracciolini, Lorenzo Valla, Marsilio Ficino y Coluccio Salutati. Aquí la lengua clásica empezó a ser objeto de estudios profundos que marcaron el nacimiento, de hecho, de la filología clásica.

En la Edad Moderna, el latín aún se usa como lengua de la cultura y de la ciencia, pero va siendo sustituido paulatinamente por los idiomas locales. En latín escribieron, por ejemplo, Nicolás Copérnico e Isaac Newton. Galileo fue de los primeros científicos en escribir en un idioma distinto del latín (en italiano, hacia 1600), y Oersted de los últimos en escribir en latín, en la primera mitad del siglo XIX.

Al conjunto de formas que puede tomar una misma palabra según su caso se le denomina paradigma de flexión. Los paradigmas de flexión de sustantivos y adjetivos se denominan en gramática latina declinaciones, mientras que los paradigmas de flexión de los verbos se llaman conjugaciones. En latín el paradigma de flexión varía de acuerdo con el tema al que está adscrita la palabra. Los nombres y adjetivos se agrupan en cinco declinaciones, mientras que los verbos se agrupan dentro de cuatro tipos básicos de conjugaciones.

En latín, el sustantivo, el adjetivo (flexión nominal) y el pronombre (flexión pronominal) adoptan diversas formas de acuerdo con su función sintáctica en la oración, formas conocidas como casos gramaticales. Existen en latín clásico seis formas que pueden tomar cada sustantivo, adjetivo o pronombre («casos»):


Además, hay restos de un caso adicional indoeuropeo: el locativo (indicando localización, bien en el espacio, bien en el tiempo):
El adjetivo también tiene formas flexivas, dado que concuerda necesariamente con un sustantivo en caso, género y número.

A grandes rasgos hay dos temas dentro de la conjugación del verbo latino, "infectum" y "perfectum": en el infectum están los tiempos que no indican un fin, una terminación, como el presente, el imperfecto y el futuro; son tiempos que no señalan el acto acabado, sino que, sea que está ocurriendo en el presente, ocurría con repetición en el pasado (sin indicar cuando acabó), o bien un acto futuro. En este tema del verbo la raíz no cambia, al contrario que con el perfectum, que tiene su propia terminación irregular ("capere: pf. cepi — scribere: pf. scripsi — ferre pf. tuli — esse pf. fui — dicere pf. dixi").

El perfecto (del latín "perfectum", de "perficere" 'terminar', 'completar') en cambio indica tiempos ya ocurridos, terminados, que son el pretérito, el pluscuamperfecto y el futuro perfecto.

Ambos cuentan con los siguientes modos gramaticales (a excepción del imperativo, que no existe en perfectum): el indicativo, que expresa la realidad, certeza, la verdad objetiva; el subjuntivo expresa irrealidad, subordinación, duda, hechos no constatados, a veces usado como optativo; el imperativo, que denota mandato, ruego, exhortación, y el infinitivo, una forma impersonal del verbo, usada como subordinado ante otro, o dando una idea en abstracto. Con seis personas en cada tiempo —primera, segunda y tercera, cada una en singular y plural— y dos voces —activa cuando el sujeto es el agente y pasiva cuando el sujeto padece una acción no ejecutada por él—, más los restos de una voz media, un verbo no deponente normalmente posee unas 130 desinencias.

Los verbos en latín usualmente se identifican por cinco diferentes temas de conjugaciones (los grupos de verbos con formas flexivas similares): el tema en -a larga (-ā-), el tema en -e larga (-ē-), tema en consonante, tema en -i larga (-ī-) y, por último, el tema en -i breve (-i-). Básicamente solo hay un modo de la conjugación latina de los verbos, pero vienen influidos por cierta vocal que provoca algunos cambios en sus desinencias. Por ejemplo, en su terminación de futuro: mientras lo común era indicarlo mediante un tiempo proveniente del subjuntivo, en los verbos influidos por "E" o "A" larga, el futuro sonaría exactamente igual que el presente, por lo que tuvieron que cambiar sus desinencias.

El objeto de la sintaxis es organizar las partes del discurso de acuerdo con las normas de la lengua para expresar correctamente el mensaje. La concordancia, que es un sistema de reglas de los accidentes gramaticales, en latín afecta a género, número, caso y persona. Esta jerarquiza las categorías gramaticales, de tal manera que el verbo y el adjetivo adecúan sus rasgos a los del nombre con el que conciertan. Las concordancias son adjetivo/sustantivo o de verbo/sustantivo. Obsérvese el ejemplo: «"Animus aequus optimum est aerumnae condimentum"» («Un ánimo equitativamente bueno es el condimento de la miseria»).

Mediante la construcción se sitúan los sintagmas en el discurso. En latín el orden de la frase es S-O-V, o sea, primero va el sujeto, el objeto, y al final el verbo. Esta idea de construcción supone que las palabras tienen ese orden natural; no es tan fácil de establecer en rigor. Un ejemplo de orden natural sería «"Omnia mutantur, nihil interit"» («Todo cambia, nada perece»). Por oposición, al orden que incluye desviaciones de la norma, por razones éticas o estéticas, se le da el nombre de figurado, inverso u oblicuo, como en «"Vim Demostenes habuit"», donde "Demostenes" ha sido desplazado de su primer lugar propio.

El latín se pronunciaba de forma diferente en los tiempos antiguos, en los tiempos clásicos y en los posclásicos; también era diferente el latín culto de los diversos dialectos de latín vulgar. Al ser el latín una lengua muerta, no se sabe con exactitud la pronunciación de la grafía latina: históricamente se han propuesto diversas formas. Las más conocidas son la eclesiástica (o italiana) que se acerca más a la pronunciación del latín tardío que a la del latín clásico, la "pronuntiatio restituta" (pronunciación reconstruida), que es el intento de reconstruir la fonética original, y la erasmista. La comparación con otras lenguas indoeuropeas también es importante para determinar el probable valor fonético de ciertas letras.

No hay un acuerdo entre los estudiosos. Pero parece ser que el latín, a lo largo de su historia, pasó por períodos en los que el acento era musical y por otros en los que el acento era de intensidad. Lo que está claro es que el acento tónico depende de la cantidad de las sílabas según el siguiente esquema:


El latín clásico tenía cinco vocales breves /a, e, i, o, u/ y cinco vocales largas /ā, ē, ī, ō, ū/ con valor de distinción fonológica. 

El sistema fonológico del vocalismo latino estaba conformada por la oposición dos tipos de cantidad o duración: las vocales de mayor duración, denominadas largas, y las de menor duración, denominadas breves. En la actualidad el símbolo (˘) lo usamos para designar las vocales breves y el símbolo (¯) los empleamos para designar las vocales largas.

/ă/ breve /ĕ/ breve /ĭ/ breve /ŏ/ breve /ŭ/ breve

/ā/ larga /ē/ larga /ī/ larga /ō/ larga /ū/ larga

La "y (i Græca)" originalmente no formaba parte del sistema vocálico latino y solo aparecía en préstamos cultos griegos. Su pronunciación en el griego clásico correspondía aproximadamente a la de la "u" francesa o "ü" alemana [y]. En latín generalmente se pronunciaba como una "i", pues para la población poco educada resultó difícil pronunciar la /y/ griega. Otras evidencias a favor de la existencia del sonido /y/ en latín es que era una de las tres letras claudias, concretamente la llamada "sonus medius" (escrito como: Ⱶ) se creó para representar un sonido intermedio entre [i] y [u], muy probablemente [y] (o tal vez [ɨ]) que aparecía estar detrás de ciertas vacilaciones como 'óptimo', 'lágrima'.

Tanto unas como otras podían darse en cualquier posición, es decir: no tenía ninguna relevancia fonológica el acento ni la intensidad.

El tratamiento de las vocales del latín clásico varía según el tipo de sílaba en que se encuentran. Están muy influenciadas por el acento. El acento original de la lengua “mater” del latín era musical y libre, pero ese sistema desapareció y ya no estaba reflejado en el latín clásico, en el que el acento carga sobre la penúltima sílaba si esta es larga y sobre la antepenúltima si la penúltima es breve. Sin embargo los estudiosos están divididos en lo que respecta a sus opiniones sobre la naturaleza del acento latino, aunque la opinión de la mayoría de los lingüistas cree que el acento tonal o musical es la que se mantuvo hasta el siglo IV d.C.

Las vocales del sistema fonológico latín clásico eran a, e, i, o, u, que podían ser largas o breves, y las combinaciones en diptongo de las tres primeras con las semivocales o sonantes i, u, r, l, m, n. El tratamiento de estos sonidos heredados en latín varía según el tipo de sílaba en que aparecen. Pueden dividirse en sílaba inicial, sílaba media y sílaba final. En el latín más antiguo estas vocales estaban acentuadas, y por ello se mantienen con regular constancia.

Sílabas no iniciales

En sílabas no iniciales, como hemos visto más arriba, las vocales breves y diptongos breves experimentaron alteraciones que diferían según la sílaba terminase en vocal o consonante. Todo esto lo podemos resumir bajo los epígrafes de las sílabas abiertas y las cerradas.

Las sonantes.

Ciertos tipos de sonidos, según el contexto fonético en que se hallen, funcionan como vocales o consonantes, es decir, como centro silábico o no.
Consonantismo.

Las consonantes se pronunciaban como en castellano. La eran siempre oclusivas sonoras. La representaba los sonidos [k] y [g] en latín arcaico, aunque en latín clásico se reservó solo para el sonido [k] al crearse la letra . El dígrafo correspondía en latín tardío a [kw] (en latín arcaico seguramente era una labiovelar [k]). La pronunciación de sencilla no está clara. Podría haber sido como la del castellano (que según la posición es [ɾ] vibrante simple o [r] vibrante múltiple) o tal vez como la del italiano (que muchas veces es [ɾ] incluso en inicio de palabra); entre dos vocales podría haber sido igual a la "rr" del castellano (por lo que sonaría con la misma de "rr" de "carro") o tal vez una geminada [ɾː]. La letra representaba según el contexto la semiconsonante /w/ o las vocales /ŭ, ū/. En latín tardío pasó a [β], reforzándose en [b] inicial en algunos dialectos occidentales y fricativa dándose [v] en la mayor parte de la Romania. La "x" tenía el sonido [ks], como en "éxito". La originalmente no formaba parte del alfabeto latino y aparecía solamente en algunos préstamos griegos y correspondía, al principio, al sonido [dz] como en la palabra italiana "gazza", luego terminó fricativizándose en [z].

No se sabe con certeza la pronunciación exacta de la "s" latina. Teniendo en cuenta que era la única sibilante en el sistema consonántico latino, y que en el desarrollo del francés podría haber sido la causa del desarrollo de la vocal [a] del francés medieval a [ɑ] antes de ella (ej. "casse", del latín , pronunciada originalmente [kasə] y luego [kɑsə]), muchos lingüistas consideran que tenía un sonido de realización apicoalveolar o predorsodental de /s/, parecido al del castellano del medio y norte de España. Algunos han propuesto que en muchas lenguas con una única sibilante el alófono principal de /s/ es apicoalveolar, ya que no existe la necesidad de distinguirlo de otro fonema que sería la [ʃ]. Aunque por otra parte, sí existen lenguas con una sibilante donde la /s/ no es apicoalveolar, por ejemplo el español de América. Quizás este hecho sea el origen del rotacismo intervocálico latino en palabras como " > " (< *"floses)".

El sistema consonántico del latín clásico estaba formado por cuatro subsistemas: el de las consonantes nasales, el de las líquidas, el de las semivocales y el de las orales no líquidas:

Los fonemas consonánticos comprendían una riza variedad de oclusivas, sordas (p, t, k, q y qʷ), sonoras (b, d, g, y gʷ), con los correspondientes sonidos aspirados. La única fricativa era la s. El latín no distingue entre la serie palatal y la velar ni entre aspiradas sordas y sonoras. Del sistema mencionado, el latín conservó generalmente p, t, k, (q), qʷ y b, d, g, (g), afectando los cambios importantes a las labiovelares sonoras y a las oclusivas aspiradas.

Latín vulgar (en latín, "sermo vulgaris") (o latín tardío) es un término que se emplea para referirse a los dialectos vernáculos del latín hablado en las provincias del Imperio romano. En particular, el término se refiere al período tardío, que abarca hasta que esos dialectos se diferenciaron los unos de los otros lo suficiente como para que se les considerase el período temprano de las lenguas romances. La diferenciación que se suele asignar al siglo IX aproximadamente.

Ya en el ámbito de la gramática, habría que destacar los siguientes fenómenos: en el sistema verbal, la creación de formas compuestas (normalmente mediante la combinación de "habere" con el participio pasado de otro verbo) paralelas al paradigma sintético ya existente; y la construcción de la pasiva con el auxiliar ser y el participio del verbo que se conjuga (el francés y el italiano también emplean ser como auxiliar en los tiempos compuestos de verbos de «estado» y «movimiento»).

Los seis casos de la declinación latina se redujeron y posteriormente se reemplazaron con frases prepositivas (el rumano moderno mantiene un sistema de tres casos, tal vez por influencia eslava; hasta el siglo XVIII también algunas variantes romanches de Suiza tenían caso). Si en latín no había artículos, los romances los desarrollaron a partir de los determinantes; son siempre proclíticos, menos en rumano, lengua en la que van pospuestos al sustantivo.

En cuanto a los demostrativos, la mayoría de las lenguas románicas cuenta con tres deícticos que expresan «cercanía» ("este"), «distancia media» ("ese") y «lejanía» ("aquel"). Sin embargo, el francés, el rumano y el extinto romance andalusí distinguen solo dos términos (uno para «proximidad» y otro para «lejanía»). El género neutro desapareció en todas partes menos en Rumania, Galicia y Asturias, en la que existen algunos sustantivos no contables con terminación en neutro (-o) y una terminación propia igual en el adjetivo cuando concuerda con sustantivos no contables o "de materia", ya acaben en -a, -o, -u o consonante. El orden sintáctico responde a la libre disposición de los elementos en la oración propia del latín. Aun así domina ordenación sintagmática de sujeto + verbo + objeto (aunque las lenguas del sureste permiten mayor flexibilidad en la ubicación del sujeto).

El latín tardío o latín vulgar cambió muchos de los sonidos del latín culto o clásico (1).

Los más importantes procesos fonológicos que afectaron al consonantismo fueron: la lenición de consonantes intervocálicas (las sordas se sonorizan y las sonoras desaparecen) y la palatalización de consonantes velares y dentales, a menudo con una africación posterior ("lactuca" > gallego, "leituga"; español, "lechuga"; catalán, "lletuga"). Ambos procesos tuvieron mayor incidencia en el Oeste (de las lenguas occidentales, el sardo fue la única que no palatalizó). Otra característica es la reducción de las geminadas latinas, que solamente preservó el italiano.

Aquí también se podrían agregar algunos otros cambios fonéticos, como la pérdida de la /d/ intervocálica en castellano o la pérdida de la /n/ y /l/ en portugués, gallego, catalán y occitano.

El latín de ser una marcada lengua sintética pasó a ser poco a poco una lengua analítica, en la que el orden de las palabras es un elemento de sintaxis necesario. Ya en el latín arcaico empezó a constatarse la desestima de este modelo y se advierte su reemplazo por un sistema de preposiciones. Este sistema no se propició de forma definitiva hasta que ocurrieron los cambios fonéticos del latín vulgar. Esto provocó que el sistema de casos fuera difícil de mantener, perdiéndolos paulatinamente en un lapso relativamente rápido.

Algunos dialectos conservaron una parte de este tipo de flexiones: el francés antiguo logró mantener un sistema de casos con un nominativo y uno oblicuo hasta entrado el siglo XII. El occitano antiguo también conservó un sistema parecido, así como el retorromano, que lo perdió hace unos 100 años. El rumano aún preserva un separado genitivo-dativo con vestigios de un vocativo en las voces femeninas.

La distinción entre el singular y el plural se marcaba con dos formas diferentes en las lenguas romances. En el norte y en el oeste de la línea Spezia-Rimini, al norte de Italia, el singular usualmente se distingue del plural por una /s/ final, que se presenta en el antiguo plural acusativo. Al sur y al este de esta misma línea, se produce una alternancia vocálica final, proveniente del nominativo plural de la primera y la segunda declinación.

La influencia del lenguaje coloquial, que prestaba mucha importancia al elemento deíctico o señalador, originó un profuso empleo de los demostrativos. Aumentó muy significativamente el número de demostrativos que acompañaban al sustantivo, sobre todo haciendo referencia a un elemento nombrado antes. En este empleo anafórico, el valor demostrativo de "ille" (o de "ipse", en algunas regiones) fue desdibujándose para aplicarse también a todo sustantivo que se refiriese a seres u objetos consabidos. De este modo, surgió el artículo definido (el, la, los, las, lo) inexistente en latín clásico y presente en todas las lenguas romances. A su vez, el numeral unus, empleado con el valor indefinido de alguno, cierto, extendió sus usos acompañando al sustantivo que designaba entes no mencionados antes, cuya entrada en el discurso suponía la introducción de información nueva. Con este nuevo empleo de unus, surgió el artículo indefinido (un, una, unos, unas) que tampoco existía en latín clásico.

En latín clásico los determinantes solían quedar en el interior de la frase. Sin embargo, el latín vulgar propendía a una colocación en que las palabras se sucedieran con arreglo a una progresiva determinación, al tiempo que el período sintáctico se hacía menos extenso. Al final de la época imperial este nuevo orden se abría paso incluso en la lengua escrita, aunque permanecían restos del antiguo, sobre todo en las oraciones subordinadas.

Las preposiciones existentes hasta ese momento eran insuficientes para las nuevas necesidades gramaticales y el latín vulgar tuvo que generar nuevas. Así, se crearon muchas preposiciones nuevas, fusionando muchas veces dos o tres que ya existiesen previamente, como es el caso de "detrás" (de + trans), "dentro" (de + intro), "desde" (de + ex + de), "hacia" (facie + ad), "adelante (<adenante" <ad + de + in + ante).

Hoy en día, el latín sigue siendo utilizado como lengua litúrgica oficial de la Iglesia católica de rito latino. Su estatus de lengua muerta (no sujeta a evolución) le confiere particular utilidad para usos litúrgicos y teológicos, ya que es necesario que los significados de las palabras se mantengan estables. Así, los textos que se manejan en esas disciplinas conservarán su significado y su sentido para lectores de distintos siglos. Además, esta lengua se usa en medios radiofónicos y de prensa de la Santa Sede. El papa entrega sus mensajes escritos en este idioma; las publicaciones oficiales de la Santa Sede son en latín, a partir de las cuales se traducen a otros idiomas. En noviembre de 2012 fue fundada la Pontificia Academia de Latinidad por el Papa Benedicto XVI para potenciar el latín en todo el mundo. En la Iglesia anglicana, después de la publicación del "Libro de Oración Común" anglicano de 1559, una edición en latín fue publicada en 1560 para usarse en universidades; como en la de Oxford, donde la liturgia se celebra aún en latín. Más recientemente apareció una edición en latín del "Libro de Oración Común" de los Estados Unidos de 1979.

Por otra parte, la nomenclatura de especies y grupos de la clasificación biológica sigue haciéndose con términos en latín o latinizados. Además de la terminología de la filosofía, derecho y medicina, donde se preservan muchos términos, locuciones y abreviaciones latinas. En la cultura popular aún puede verse escrito en los lemas de universidades u otras organizaciones y también puede oírse en diálogos de películas que se desarrollan en época romana como "Sebastiane" y "La Pasión de Cristo".





</doc>
<doc id="1669" url="https://es.wikipedia.org/wiki?curid=1669" title="Líquido">
Líquido

El líquido es un estado de agregación de la materia en forma de fluido altamente incompresible, lo que significa que su volumen es casi constante en un rango grande de presión. Es el único estado con un volumen definido, pero no con forma fija. Un líquido está formado por pequeñas partículas vibrantes de la materia, como los átomos y las moléculas, unidas por enlaces intermoleculares. El agua es, el líquido más común en la Tierra, además de el más abundante.Como un gas, un líquido es capaz de fluir y tomar la forma de un recipiente. A diferencia de un gas, un líquido no se dispersa para llenar cada espacio de un contenedor, pero si mantiene una densidad constante. Una característica distintiva del estado líquido es la tensión superficial, dando lugar a fenómenos humectantes.

El estado líquido es un estado de agregación de la materia intermedio entre el estado sólido y el estado de gas. Las moléculas de los líquidos no están tan próximas como las de los sólidos, pero están menos separadas que las de los gases. Las moléculas en el estado líquido ocupan posiciones al azar que varían con el tiempo. Las distancias íntermoleculares son constantes dentro de un estrecho margen. En algunos líquidos, las moléculas tienen una orientación preferente, lo que hace que el líquido presente propiedades anisótropas (propiedades, como el índice de refracción, que varían según la dirección dentro del material).

Los líquidos presentan tensión superficial y capilaridad, generalmente se dilatan cuando se incrementa su temperatura y pierden volumen cuando se enfrían, aunque sometidos a compresión su volumen es muy poco variable a diferencia de lo que sucede con otros fluidos como los gases. Los objetos inmersos en algún líquido están sujetos a un fenómeno conocido como flotabilidad.

Su forma es esférica si sobre él no actúa ninguna fuerza externa. Por ejemplo, una gota de agua en caída libre toma la forma esférica.

Como fluido sujeto a la fuerza de la gravedad, la forma de un líquido queda definida por su contenedor. En un líquido en reposo sujeto a la gravedad, en cualquier punto de su seno existe una presión de igual magnitud hacia todos los lados, tal como establece el principio de Pascal. Si un líquido se encuentra en reposo, la presión hidrostática en cualquier punto del mismo viene dada por:

Donde formula_1 es la densidad del líquido, formula_2 es la gravedad (9,8 m/s) y formula_3 es la distancia del punto considerado a la superficie libre del líquido en reposo. En un fluido en movimiento la presión no necesariamente es isótropa, porque a la presión hidrostática se suma la presión hidrodinámica que depende de la velocidad del fluido en cada punto.

En condiciones apropiadas de temperatura y presión, la mayoría de las sustancias pueden existir en estado líquido. Cuando un líquido sobrepasa su punto de ebullición cambia su estado a gaseoso, y cuando alcanza su punto de congelación cambia a sólido. Aunque a presión atmosférica, sin embargo, algunos sólidos se subliman al calentarse; es decir, pasan directamente del estado sólido al estado gaseoso (véase evaporación). La densidad de los líquidos suele ser algo menor que la densidad de la misma sustancia en estado sólido. Algunas sustancias, como el agua, son más densas en estado líquido.

Por medio de la destilación fraccionada, los líquidos pueden separarse de entre sí al evaporarse cada uno al alcanzar sus respectivos puntos de ebullición. La cohesión entre las moléculas de un líquido no es lo suficientemente fuerte por lo que las moléculas superficiales se pueden evaporar.

Los líquidos se caracterizan porque las fuerzas internas del mismo no dependen de la deformación total, aunque usualmente sí dependen de la velocidad de deformación, esto es lo que diferencia a los sólidos deformables de los líquidos. Los fluidos reales se caracterizan por poseer una resistencia a fluir llamada viscosidad (que también está presente en los sólidos viscoelásticos). Eso significa que en la práctica para mantener la velocidad en un líquido es necesario aplicar una fuerza o presión, y si dicha fuerza cesa el movimiento del fluido cesa finalmente tras un tiempo finito.

La viscosidad de un líquido crece al aumentar su masa molar y disminuye al crecer la temperatura. La viscosidad también está relacionada con la complejidad de las moléculas que constituyen el líquido: es baja en los gases inertes licuados y alta en los aceites pesados. Es una propiedad característica de todo fluido (líquidos o gases).

La viscosidad es una medida de la resistencia al desplazamiento de un fluido cuando existe una diferencia de presión. Cuando un líquido o un gas fluyen se supone la existencia de una capa estacionaria, de líquido o gas, adherida sobre la superficie del material a través del cual se presenta el flujo. La segunda capa roza con la adherida superficialmente y esta segunda con una tercera y así sucesivamente. Este roce entre las capas sucesivas es el responsable de la oposición al flujo, o sea, el responsable de la viscosidad.

La viscosidad se mide en poises, siendo un poise la viscosidad de un líquido en el que para deslizar una capa de un centímetro cuadrado de área a la velocidad de 1 cm/s respecto a otra estacionaria situado a 1 cm de distancia fuese necesaria la fuerza de una dina.

La viscosidad suele decrecer en los líquidos al aumentar la temperatura, aunque algunos pocos líquidos presentan un aumento de viscosidad cuando se calientan. Para los gases la viscosidad aumenta al aumentar la temperatura.

La viscosidad de un líquido se determina por medio de un viscosímetro entre los cuales el más utilizado es el de Ostwald. Este se utiliza para determinar viscosidad relativa, es decir, que conociendo la viscosidad de un líquido patrón, generalmente agua, se obtiene la viscosidad del líquido problema a partir de la ecuación:

La fluidez es una característica de los líquidos o gases que les confiere la habilidad de poder pasar por cualquier orificio o agujero por más pequeño que sea, siempre que esté a un mismo nivel del recipiente en el que se encuentren el líquido a diferencia del restante estado de agregación conocido como sólido.

La fluidez se debe a que un fluido puede adquirir una deformación arbitrariamente grande sin necesidad de ejercer una tensión mecánica. La tensión mecánica o presión en el seno del fluido depende esencialmente de la velocidad de la deformación no de la deformación en sí misma a diferencia de los sólidos que tienen memoria de forma y experimentan tensiones tanto más grandes cuanto más se alejan de la forma original, es decir, en un sólido la tensión está relacionada primordialmente con el grado de deformación.

Presión de un vapor en equilibrio con su forma líquida, la llamada presión de vapor, solo depende de la temperatura; su valor a una temperatura dada es una propiedad característica de todos los líquidos.

También lo son el punto de ebullición, el punto de solidificación y el calor de vaporización (esencialmente, el calor necesario para transformar en vapor una determinada cantidad de líquido).

En ciertas condiciones, un líquido puede calentarse por encima de su punto de ebullición; los líquidos en ese estado se denominan supercalentados. También es posible enfriar un líquido por debajo de su punto de congelación y entonces se denomina líquido superenfriado.

Los líquidos no tienen forma fija pero sí volumen. Tienen variabilidad de forma y características muy particulares que son:




</doc>
<doc id="1670" url="https://es.wikipedia.org/wiki?curid=1670" title="Liliaceae">
Liliaceae

Las liliáceas (nombre científico Liliaceae ) son una familia de plantas monocotiledóneas perennes, herbáceas, con frecuencia bulbosas, que pueden ser reconocidas por sus flores bastante grandes con un perigonio formado por seis tépalos libres, frecuentemente coloreados y con manchas, seis estambres extrorsos y un ovario súpero, tricarpelar y trilocular. Se hallan ampliamente distribuidas por todo el mundo, principalmente en regiones templadas del hemisferio norte. 

La familia Liliaceae fue concebida por Antoine Laurent de Jussieu en 1789 y su definición era muy amplia y artificial: todas las especies de plantas con 6 tépalos y gineceo de ovario súpero eran incluidas en esta familia. En un momento llegó a abarcar cerca de 300 géneros y 4.500 especies y se incluían dentro del gran orden Liliales en las clasificaciones de Arthur Cronquist o de Robert F. Thorne. como las monocotiledóneas petaloideas, un "grupo" caracterizado por flores con tépalos vistosos y sin almidón en el endosperma. Arthur Cronquist ubicó a la mayoría de las monocotiledóneas petaloideas con flores de seis estambres en un muy amplio Liliaceae. Mientras que, en otros tratamientos, se han dividido las monocotiledóneas petaloideas con seis estambres en Liliaceae, incluyendo especies con un ovario súpero, y Amaryllidaceae, que incluye a las especies con ovario ínfero (Lawrence 1951). No obstante, con el tiempo se llegó a reconocer que, definida de esa forma, la familia Liliaceae incluía un vasto y heterogéneo repertorio de géneros que no estaban relacionados filogenéticamente. Existieron varias propuestas para separar grupos pequeños de géneros en familias más homogéneas, pero ninguna de ellas fue ampliamente aceptada. En la década de 1980, en el contexto de una revisión general de la clasificación de las angiospermas, las liliáceas fueron sometidas a un escrutinio más intenso. Hacia fines de esa década, los Jardines Botánicos de Kew, el Museo Británico de Ciencias Naturales y los Jardines Botánicos de Edimburgo formaron un comité para examinar la posibilidad de separar a las liliáceas en subgrupos más homogéneos, al menos para la organización de sus herbarios. El comité recomendó que se utilicen 24 nuevas familias en lugar de la vieja y ampliamente definida Liliaceae. En las últimas dos décadas los estudios de ADN y los datos morfológicos (particularmente aquellos relacionados con la morfología reproductiva) sumados a los análisis filogenéticos, han permitido concluir que las "monocotiledóneas petaloideas" en realidad no pertenecen a una misma familia botánica sino que se distribuyen en dos órdenes diferentes: Asparagales y Liliales. La monofilia de estos órdenes está sustentada por análisis cladísticos basados en morfología, ADNr 18S, y muchas otras secuencias de ADN. 

Tales estudios, sumados a los análisis realizados dentro de cada uno de los órdenes han permitido reagrupar a los géneros previamente incluidos dentro de Liliaceae en una gran cantidad de familias, como se muestra a continuación a través de los cladogramas para las Asparagales y Liliales:

Ambos cladogramas demuestran que la definición clásica de Liliaceae era incorrecta, sumamente artificial y no reflejaba las verdaderas relaciones filogenéticas entre las especies que la componían. Por esta razón, y pese al uso extendido de la circunscripción amplia de las liliáceas, los botánicos de todo el mundo fueron adoptando la definición más estricta de esta familia y la segregación de los géneros que la componían en dos órdenes y numerosas familias.

La familia es reconocida por sistemas de clasificación modernos como el sistema de clasificación APG III (2009) pero la circunscripción moderna de la familia es mucho más estricta que la tradicionalmente aceptada, para que se mantenga monofilética sobre la base de los análisis moleculares de ADN recientes.

Hierbas perennes con bulbos o rizomas, con pelos simples. Las raíces son típicamente contráctiles. 

Las hojas son alternas y espiraladas (e incluso verticiladas, como en "Lilium" y "Fritillaria") y se disponen a lo largo del tallo o en una roseta basal. Son simples, enteras, con venación paralela (aunque en "Prosartes" y "Tricyrtis" con venación claramente reticulada entre las venas primarias), muchas veces son envainadoras en la base. Raramente las hojas son pecioladas. No presentan estípulas.

La inflorescencia es usualmente determinada, a veces reducida a una única flor, y terminal. Cuando es multiflora las flores se disponen en un racimo o raramente en una umbela. Las flores son hermafroditas, actinomorfas o ligeramente zigomorfas, en general grandes y vistosas, pediceladas, pueden o no presentar brácteas. El perigonio está formado por 6 tépalos dispuestos en dos verticilos trímeros, se hallan separados entre sí y libres de las demás piezas florales, imbricados, son petaloideos y usualmente presentan manchas, puntos o líneas de otros colores o tonos. El perianto puede ser homoclamídeo (o sea, todos los tépalos son iguales entre sí, como en "Fritillaria") o diclamídeo (los dos verticilos de tépalos presentan diferencias morfológicas, como en "Calochortus"). El néctar se produce en nectarios en la base de los tépalos.

El androceo presenta 6 estambres dispuestos en 2 verticilos también trímeros, los filamentos se hallan separados entre sí y libres de las demás piezas florales. Característicamente, el androceo es diplostémono (es decir que el verticilo externo de estambres es opuesto a los tépalos externos y el ciclo interno es opuesto a los tépalos internos). Las anteras están unidas al filamento en forma peltada o pseudo-basifijas (la punta del filamento rodeada pero no adherida al tejido conectivo), y de dehiscencia longitudinal. El polen es en general monosulcado. 

El gineceo es de ovario súpero y está formado por 3 carpelos connados, es trilocular. Presenta un solo estilo y un estigma 3-lobado o bien, 3 estigmas más o menos elongados que se extienden a lo largo de la cara interna de las ramas del estilo. Los óvulos son numerosos, con placentación axilar, usualmente con un tegumento y un megasporangio más o menos delgado. El saco embrionario (megagametofito o gametofito femenino) es variable según el género considerado. Puede ser monospórico (tipo "Polygonum") o tetraspórico (tipo "Fritillaria").

El fruto es una cápsula loculicida o septicida, ocasionalmente una baya. Las semillas son planas y con forma de disco o globosas, el tegumento no es negro, rasgo que las diferencia de otras familias, como por ejemplo Alliaceae. El endosperma es aceitoso (con aleurona y aceites) pero sin almidón, sus células pueden ser triploides o pentaploides, dependiendo del saco embrionario considerado.

Desde un punto de vista fitoquímico, la familia presenta saponinas esteroideas pero no exhibe cristales de rafidio ni ácido chelidónico ni compuestos azufrados derivados de la cisteína (o sea, no tienen el olor aliáceo característico de los ajos y las cebollas). 
Los números cromosómicos básicos son variables de acuerdo al género considerado.

Las liliáceas están ampliamente distribuidas, principalmente en regiones templadas del hemisferio norte. En general son plantas de praderas llanas, prados de montaña y otras comunidades abiertas. Poseen su centro de diversidad en el sudoeste de Asia a China. 

Suelen florecer en la primavera. Las vistosas flores de esta familia son polinizadas por insectos, especialmente abejas, avispas, mariposas y polillas. El néctar o polen que producen las flores de las liliáceas en gran cantidad son empleados como recompensa de la polinización. 

Las semillas son dispersadas tanto por el viento como por el agua, unas pocas especies tienen estructuras de tipo arilo y son dispersadas por hormigas.

Liliaceae, en su actual definición estricta, es claramente monofilética (Chase "et al." 1995a, b), si bien es difícil de diagnosticar morfológicamente (Tamura 1998b
). Hayashi y Kawano (2000) secuenciaron las regiones "rbcL" y "matK" del ADN cloroplastídico de "Lilium" y géneros relacionados y encontraron resultados coherentes con la circunscripción de Liliaceae "sensu stricto" propuesta por Tamura (1998, quien separó la subfamilia Calochortoideae en su propia familia Calochortaceae). Patterson y Givnish (2002) secuenciaron los genes "rbcL" y "ndhF" y encontraron un fuerte sostén para la monofilia de Liliaceae, la publicación también describe una filogenia de los géneros y provee estimaciones de los tiempos de divergencia.

Relacionadas con esta familia están Philesiaceae (2 géneros monoespecíficos, del sur de Sudamérica), Smilacaceae (monogenérica, 315 especies, casi cosmopolita), y Rhipogonaceae (1 género con 6 especies, del este de Australia), como avalado en Chase "et al." 1995a, 2006, Conran 1998, Fay "et al." 2006, Rudall "et al." 2000a. No se conocen caracteres fuera de los del ADN que unan a todas estas familias. "Smilax" es en general hermano de Liliaceae (pero nunca con más de 80 % de apoyo). Fay "et al." (2006: bajo apoyo), Givnish "et al." (2006: alto apoyo), y Chase "et al." (2006) encontraron a Philesiaceae y Rhipogonaceae como taxones hermanos, y a Smilacaceae como hermano de Liliaceae.

"Calochortus", "Prosartes, Scoliopus, Streptopus, "y" Tricyrtis" forman un clado (la subfamilia Calochortoideae), y son hierbas con rizomas rastreros ("creeping"), estilos divididos en el ápice, y el desarrollo del megagametofito del tipo "Polygonum" (es decir, el megagametofito desarrollándose de una megaspora simple, con endosperma triploide). En otras clasificaciones "Calochortus" ha sido ubicada en su propia familia, mientras que los demás géneros de Calochortoideae fueron ubicados en un heterogéneo Uvulariaceae (Dahlgren "et al." 1985) o en un Calochortaceae expandido (Tamura 1998a). Sin embargo, estos miembros de Liliaceae no están cercanamente relacionados con los morfológicamente similares "Uvularia" y "Disporum" (Shinwari "et al." 1994), y el último es aquí ubicado en Colchicaceae.

El resto de los géneros de Liliaceae constituyen los Lilioideae, un gran clado caracterizado por bulbos y raíces contráctiles, y un megagemetofito desarrollándose de 4 megasporas (de tipo "Fritillaria").

La monofilia de cada uno de estos dos subclados de Liliaceae está sostenida por caracteres de secuencias de ADN (Chase "et al." 1995a, 2000, Patterson y Givnish 2002).

Un tercer clado fue identificado a partir de las investigaciones filogenéticas de "Clintonia", un género de distribución disyunta entre América del Norte y el este de Asia. Utilizando las 5 especies de "Clintonia" ("Clintonia andrewsiana", "Clintonia borealis", "Clintonia umbellulata", "Clintonia uniflora" y "Clintonia udensis"), varios representantes de Liliaceae (tales como "Cardiocrinum cordatum", "Medeola virginiana", "Scoliopus bigelovii" y "Scoliopus hallii") y los datos de las secuencias de los genes cloroplastídicos "rbcL" y "matK", se llegó a la conclusión que "Clintona" es monofilético, que consiste en dos clados, uno de Asia oriental y el otro de Norteamérica, y que el género más estrechamente relacionado es "Medeola". Ambos géneros, "Clintonia" y "Medeola", fueron dispuestos en una subfamilia separada, Medeoloideae.

La familia fue reconocida por el APG III (2009), el Linear APG III (2009) le asignó el número de familia 61. La familia ya había sido reconocida por el APG II (2003).



Como fue descrito en los antecedentes históricos, la definición de Liliaceae ha cambiado en el transcurso de los años. En el pasado se trató a la familia como un gran conjunto heterogéneo (Liliaceae "sensu lato") que, más recientemente, fue dividido en numerosas familias segregadas. En la circunscripción moderna de Liliaceae se considera que la familia está compuesta por 16 géneros y 635 especies, los cuales se listan a continuación:


Los géneros más representados son "Fritillaria" (100 especies), "Gagea" (90 especies), "Tulipa" (80 especies), "Lilium" (80 especies), y "Calochortus" (65 especies).

Muchas especies de los géneros "Tulipa" ("tulipán"), "Fritillaria" ("ajedrezada"), "Lilium" ("lirio", "azucena"), "Calochortus" y "Erythronium" son cultivadas como plantas ornamentales en todo el mundo. No obstante, los tulipanes y las azucenas o lirios son las de mayor importancia económica dentro de la familia, como se describe a continuación.

El tulipán se cultiva con dos objetivos principales, la producción de flor cortada y la de bulbos secos. Estos últimos se destinan, a su vez, a satisfacer la demanda de bulbos para parques, jardines y uso hogareño y, por otro lado, para proveer los bulbos necesarios para la producción de flor cortada. El comercio internacional de flor cortada tiene un valor global aproximado de 11.000 millones de Euros, lo cual provee una magnitud de la importancia económica de esta actividad. 

El principal país productor de bulbos de tulipán es Holanda, país que concentra el 87% del área mundial cultivada, la cual es de aproximadamente 12.000 hectáreas. Los bulbos de esta especie se producen significativamente en otros 14 países, encabezados por Japón, Francia y Polonia. La mayoría de estos países utiliza los bulbos obtenidos para su propia producción de flor cortada o para abastecer su mercado minorista de bulbos secos. Holanda, sin embargo, aparte de ser el principal productor internacional de bulbos, es la excepción a esta generalización. De hecho, produce aproximadamente 4.000 millones de bulbos anualmente, de los cuales el 53% se usan en el mercado de flor cortada y los restantes se utilizan en el mercado de bulbos secos. De los bulbos destinados al mercado de flor cortada, Holanda utiliza el 57% para satisfacer su mercado interno y el resto lo exporta a varios países, dentro y fuera de la Unión Europea.

De modo similar que en el caso de los tulipanes, la mayor área de producción de las variedades de "Lilium" se concentra e Holanda (76% de área mundial). Otros 9 países, encabezados por Francia, Chile, Japón, Estados Unidos y Nueva Zelanda, producen azucenas a escala significativa. La mitad de los países productores utilizan los bulbos que producen en la industria de la floricultura y sólo una pequeña proporción se destina al mercado de ventas de bulbos secos. Países tales como Holanda, Francia, Chile, Nueva Zelanda y Australia utilizan los bulbos producidos para abastecer no solo su mercado interno sino también para exportarlos. Holanda produce alrededor de 2.200 millones de bulbos de lirio anualmente, de los cuales el 96% se utiliza para su propia producción de flores y el resto es exportado a países de la Unión Europea principalmente.





</doc>
<doc id="1672" url="https://es.wikipedia.org/wiki?curid=1672" title="LOA">
LOA

LOA (Lines of Action), juego abstracto entre dos jugadores creado por Claude Soucie. Emplea un Tablero de 8x8 y 12 fichas para cada jugador, blancas y negras

Contiene un par de ingredientes que le convierten en un juego especialmente recomendable: su inusual sistema de movimiento y el extraño efecto (al mismo tiempo beneficioso y perjudicial) de las capturas.

He aquí la configuración al comienzo de la partida:
De forma alterna los jugadores moverán obligatoriamente una de sus fichas.
Las Negras mueven primero. Se mueve siguiendo una línea recta (horizontal, vertical o diagonal), tantas casillas como fichas haya sobre esa línea (contando fichas propias y enemigas, incluyendo la ficha que se mueve).

"En la figura 2 se muestra un ejemplo. Las Negras comienzan moviendo su ficha sobre la casilla c8, y deciden hacerlo a lo largo de la vertical."

"Debido a que sobre la línea "c" hay dos fichas, se mueve exactamente dos casillas, hasta c6. Otras opciones para las Negras serían, por ejemplo, mover a la casilla e6, o a la a6 (capturando la ficha blanca, según aclararemos más adelante)."

"Ahora juegan las Blancas, y deciden mover su ficha sobre c6 (figura 3). Sobre la horizontal 6 hay tres fichas: dos blancas y una negra. En el caso de que las Blancas quisieran mover por la horizontal, la ficha blanca alcanzaría la vertical "d"."

Sin embargo no puede hacerlo, ya que no está permitido saltar sobre fichas enemigas (la de c6). 

"Bien, las Blancas mueven por la diagonal dos casillas, hasta c4."

"La figura 4 refleja una de las posibles respuestas de las Negras que mueven de e8 hasta b5."

Se puede comprobar mediante el ejemplo que es posible saltar por encima de fichas propias. 
Sin embargo no se permite más de una ficha sobre la misma casilla.

"(Las Blancas, por ejemplo, no pueden responder moviendo de a4 a c4)."

"Se puede ver en la figura 5 el siguiente movimiento de las Blancas, que mueven de h3 a f1, capturando la ficha negra."

Se ha de retirar la ficha capturada para no usarla más durante la partida.
Así pues, para capturar, basta que una ficha termine su movimiento sobre la casilla ocupada por una ficha enemiga.

Gana el jugador cuyas fichas forman un solo grupo concatenado. Es posible conseguirlo después de un movimiento propio o incluso gracias a un movimiento del adversario. La conexión puede ser horizontal, vertical o diagonal.

Gana también el jugador al que le quede una sola ficha sobre el tablero, debido a que su oponente capturó el resto, ya que se entiende que tiene todas sus fichas conectadas al tener una sola ficha.

Es posible que después de una captura un jugador consiga una posición vencedora y, al mismo tiempo (por haber eliminado, por ejemplo, una ficha aislada del adversario) ayude a crear una posición ganadora para el contrario. En este caso se declara la partida en Tablas.

En la figura de abajo, si mueven las negras ganarían moviendo f6->f4, o bien f6->d4.

De este modo, las negras conseguirían conectar sus cinco fichas. La captura e3 x g5 provocaría tablas: las negras se conectarían, pero al mismo tiempo darían la victoria a las blancas, al dejarles una sola ficha. La captura f6 x h8 conlleva una catástrofe para las negras, pues deja sola a la blanca en g5 y, por tanto, gana la partida.

En el caso de que las blancas moviesen primero, vencerían moviendo g5->g8 y provocarían tablas con la captura h8 x f6.

Para poder estudiar las reglas de LOA en funcionamiento analicemos una posición de partida.

"Véase la figura 7. Juegan las Negras. Las Blancas amenazan con ganar después de dos movimientos:"

"¿Qué pueden hacer las Negras?"

"El movimiento b4>d2 incluso ayuda a las Blancas: sobre la línea horizontal se encuentran ahora tres fichas, lo que permitiría a las Blancas mover a2>d2 y ganar."

"En caso de mover b3>c2, bloqueando la ruta blanca a lo largo de la línea 2, las Blancas ganaría moviendo a2xd5, movimiento inviable antes."

El lector puede entrenarse buscando otras opciones para las Negras. Con posterioridad, habiendo encontrado a un adversario para practicar el juego, se ha de tener en cuenta que existen diversas tácticas para entorpecer los planes enemigos y facilitar la consecución de los propios:





Bien, he aquí un juego rico y dinámico cuyas partidas, ya desde el principio proporcionan escaramuzas a lo largo de todo el tablero y donde el despiste más pequeño puede atraer la catástrofe.





</doc>
<doc id="1673" url="https://es.wikipedia.org/wiki?curid=1673" title="Longitud (desambiguación)">
Longitud (desambiguación)

El término longitud (del latín "longitudo") puede tener diversos significados, según el contexto:


</doc>
<doc id="1675" url="https://es.wikipedia.org/wiki?curid=1675" title="La llamada de Cthulhu (juego de rol)">
La llamada de Cthulhu (juego de rol)

La llamada de Cthulhu es un juego de rol de horror ambientado en los años veinte y en particular en los «mitos de Cthulhu», universo de ficción iniciado por el escritor estadounidense Howard Phillips Lovecraft. De hecho el título del juego retoma el del relato de mismo título que Lovecraft había escrito en 1926 y publicado por primera vez en 1928. Este juego de rol fue publicado por primera vez en Estados Unidos por la editorial Chaosium en 1981 y se encuentra actualmente en su séptima edición. El principal autor del juego, Sandy Petersen, diseñó "La llamada de Cthulhu" aplicando al universo de ficción de Lovecraft el sistema de juego genérico de Chaosium, "Basic Role-Playing" (1980), extrapolado a su vez de otro juego de rol de Chaosium, "RuneQuest" (1978).

El sistema de juego de "La llamada de Cthulhu" es el que Chaosium primero creó para su juego de rol "RuneQuest" en 1978 y que empezó a publicar a partir de 1980 bajo el título "Basic Role-Playing" (o "BRP" para abreviar) para aplicarlo a casi todos los juegos de rol que publicaría durante los años 80. "Stormbringer" fue, en 1981, el primer juego de rol de Chaosium independiente de "RuneQuest" en estar basado en "Basic Role-Playing". "La llamada de Cthulhu" fue el segundo, publicado poco después que "Stormbringer" en ese mismo año de 1981. Existe sin embargo, desde 2001, una edición de "La llamada de Cthulhu" publicada bajo licencia por Wizards of the Coast y que no usa el sistema "BRP" sino el sistema d20.

El sistema de BRP está basado esencialmente en el uso de un dado de cien para resolver las acciones de los personajes. A estos efectos las habilidades de los personajes están expresadas mediante un porcentaje y el éxito en una acción relacionada con una de esas habilidades se obtiene cuando un jugador realiza una tirada de dado de cien igual o inferior al porcentaje que su personaje tiene en la habilidad en cuestión. Si por ejemplo un personaje tiene un 25% en «Conducir Automóvil» y se ve obligado a conducir por el borde de un acantilado, el personaje y su vehículo caerán por el acantilado si el jugador que interpreta al personaje obtiene una tirada superior a 25. La conducción sería exitosa en caso de obtener 25 o menos. Otro personaje que tuviera 85% en esa misma habilidad de conducción sería evidentemente mejor conductor, pues su jugador tendría menos dificultad en obtener 85 o menos en su tirada de dado de cien. Los porcentajes atribuidos a las habilidades se ven sin embargo modificados según las condiciones en las que se encuentre el personaje. Los modificadores, positivos o negativos, los decide en general el director de juego. Si por ejemplo el personaje que tiene 85% en «Conducir Automóvil» está herido de bala en un brazo, el director de juego puede decidir que sus tiradas de «Conducir Automóvil» sufran de un modificador negativo de 25% (su 85% se ve entonces reducido a un 60%).

Además del sistema porcentual, que es el que rige las resoluciones de acciones, el sistema de juego de "La llamada de Cthulhu" prevé otras reglas para otros aspectos del juego, como el combate (con armas de fuego, aunque también con armas de combate cuerpo a cuerpo, puños, patadas etc.), la magia (en "La llamada de Cthulhu" la magia está esencialmente destinada a invocar horribles criaturas espeluznantes venidas de otras dimensiones) o la cordura (una de las originalidades del juego: en acorde a como sucede en los relatos de Lovecraft, los personajes están en todo momento corriendo el riesgo de perder parcial o definitivamente su salud mental, especialmente al descubrir los horrores sobrenaturales que se esconden detrás de la realidad cotidiana). Debido a este aspecto ocultista del universo lovecraftiano el juego designa a los personajes jugadores como «investigadores» y al director de juego como «guardián de los arcanos».

"La llamada de Cthulhu" se apoya en los mitos de Cthulhu, el mundo creado por el escritor estadounidense Howard Phillips Lovecraft y un círculo de autores que se intercambiaban relatos entre ellos aproximadamente desde 1920 a 1930.

H. P. Lovecraft creó un horror propio, apartado del típico terror gótico del romanticismo. Su mitología incluye gran cantidad de dioses y monstruos venidos de las estrellas para dominar el mundo a través de sus seguidores religiosos, todo ello descrito en relatos opresivos ambientados en los Estados Unidos durante los felices años veinte.

Además de las seis ediciones básicas que se han editado hasta ahora de "La llamada de Cthulhu", ambientadas en los años 1920, también se han publicado algunas adaptaciones ambientadas en otras épocas: en la época romana y en un futuro próximo ("Cthulhu Invictus" y "Cthulhu Rising", no traducidos aún al castellano), en la Edad Media ("Cthulhu Edad Oscura", título original: "Cthulhu Dark Ages"), en la época victoriana ("Luz de gas", título original: "Cthulhu by Gaslight") y en la época actual ("Cthulhu Actual", título original: "Cthulhu Now").

La tercera edición estadounidense de "La llamada de Cthulhu" fue traducida y publicada en España por la editorial barcelonesa Joc Internacional a partir de septiembre de 1988. Después de que la editorial Dalmau Carles Pla S.A. tradujera y publicara "Dungeons & Dragons" en 1985 "La llamada de Cthulhu" fue el segundo juego de rol en ser publicado en España así como el primero en ser publicado por Joc Internacional. Además de reimprimir el libro básico siete veces más hasta 1997 esta editorial también tradujo y publicó catorce suplementos, uno de ellos ("El Guardián de los Arcanos") conteniendo la pantalla del director de juego (que es a quien precisamente el juego denomina "guardián de los arcanos" mientras que denomina "investigadores" a los jugadores). Es de notar que en los años 80 y 90 algunos de los primeros clubs de rol españoles, como Auryn con Ricard Ibáñez o Los Pelotas con Álex de la Iglesia, crearon numerosos suplementos para "La llamada de Cthulhu", prueba del temprano éxito alcanzado en España por este juego de rol.

Cuando en 1998 Joc Internacional firmó su balance de cierre Chaosium pasó la licencia de explotación a la editorial La Factoría de Ideas, quien no retomó las ediciones de Joc Internacional sino que tradujo directamente la edición que acababa de ser publicada por aquel entonces, la edición 5.5, una versión revisada de la quinta edición estadounidense.

Además de las aventuras y las ayudas de juego creadas por los aficionados y publicadas en varias revistas, en España se publicó el suplemento "La piel de toro", con aspecto similar a las ambientaciones estadounidenses pero en el que se describía la España de la década de 1920, con amplia información y toques de los Mitos de Cthulhu. Este módulo independiente (creado por Ricard Ibáñez) fue publicado por primera vez en 1997 por Joc Internacional y reeditado en 2004 por Proyectos Editoriales Crom. La reedición de 2004 utilizaba como sistema de reglas tanto el sistema d20 como el clásico BRP.

El 11 de diciembre de 2008 Edge Entertainment anunció en su sitio web que publicaría la sexta edición de "La llamada de Cthulhu", inédita en español. En su comunicado Edge afirmaba que además incorporaría textos revisados y contenido original para que se pudiera jugar sin necesidad de adquirir más libros que el manual básico, proporcionando suficiente información para la creación de personajes y aventuras sin ningún tipo de restricciones. En el citado comunicado, Edge afirmaba: «la sexta edición de este mítico título verá la luz durante 2009». Sin embargo el año transcurrió sin que dicha sexta edición fuese publicada y sin que se emitiesen más comunicados. Finalmente la 6.ª edición, a cargo de Edge Entertainment, salió a la venta el 9 de diciembre de 2011, coincidiendo con el 30 aniversario de la primera edición del juego.

Posteriormente, en 2020, Edge Entertainment publicó la séptima edición de "La llamada de Cthulhu", con cambios notables en el sistema de juego. Explicó que el retraso se produjo debido a que la editorial original del juego, tuvo graves problemas legales y de deudas, que hacía imposible continuar trabajando con ella. La marca fue vendida a otra editorial y Edge Entertainment pudo trabajar para sacar la nueva edición. Mandó la primera versión a la imprenta en marzo de 2019.








Chaosium ha concedido licencias a otras editoriales estadounidenses para el uso del sistema de juego de "La llamada de Cthulhu", en particular con el juego independiente "Delta Green", de Pagan Publishing. De esta línea de productos los libros "Delta Green Básico" y "Delta Green Aventuras" han sido traducidos al castellano por La Factoría de Ideas. Otras licencias para juegos de Cthulhu son por ejemplo las acordadas a Miskatonic River Press, Theater of the Mind Enterprises, Triad Entertainment, Games Workshop, Fantasy Flight Games, RAFM, Grenadier Models y Yog-Sothoth.com. Estos diferentes productos se ambientan en diferentes épocas e incluso en diferentes universos de juego que los del juego de rol original.

El 1 de marzo de 2008, Pelgrane Press publicó "El rastro de Cthulhu" ("Trail of Cthulhu"), un juego de rol independiente creado por Kenneth Hite con el sistema Gumshoe y desarrollado por Robin Laws. En junio del mismo año el juego fue traducido al castellano por Edge Entertainment.

En septiembre de 2008, Reality Deviant Publications publicó "Shadows of Cthulhu", un suplemento que aporta una ambientación lovecraftiana al sistema True20 de la editorial Green Ronin Publishing.

Otro juego de rol ambientado en los mitos de Cthulhu pero adaptado a un entorno de ciencia ficción es "CthulhuTech". Publicado originalmente en inglés por Catalyst Game Labs en 2007 "CthulhuTech" fue traducido y publicado en castellano por Edge Entertainment en enero de 2011.

El último juego de rol relacionado con los Mitos de Cthulhu publicado en español es "Cultos Innombrables", usando como sistema de juego el sistema HITOS (el cual a su vez se basa en el sistema FATE). En esta ocasión pone a los jugadores por primera vez en el papel de sus tradicionales adversarios, puesto que en ahora los roles a interpretar son los de los sectarios dedicados al culto de las entidades de los Mitos; la ambientación del juego se desarrolla en la época actual. Se trata de una creación original de la editorial española Nosolorol Ediciones lanzado a finales del año 2014.










</doc>
<doc id="1680" url="https://es.wikipedia.org/wiki?curid=1680" title="Lenguaje radiofónico">
Lenguaje radiofónico

El lenguaje radiofónico es el lenguaje que se utiliza en la radio. Debido a las limitaciones del medio, se basa exclusivamente en el sonido (música, palabras, etc.), en una sola dirección (del emisor al oyente).

Los sonidos que son utilizados en la radio son divididos en distintos
segmentos 

Los tres elementos ya mencionados con anterioridad en los párrafos anteriores; entran en función por medio de los planos. La voz y la música, pueden ser por sí mismos los protagonistas. El sonido ambiente sólo lo hace circunstancial y aisladamente. 

Por último, el silencio (ausencia de sonido, ya sea palabra, música o ruido) da valor a los sonidos anteriores y posteriores, por lo que tiene un enorme potencial expresivo, que debe usarse con prudencia.

La música radiofónica podría clasificarse de esta manera: 
Además, la música puede ser de acompañamiento, acompañando a la voz. En otras ocasiones, cumple la función de los signos de puntuación (resueltos con ráfagas, golpes musicales, etc.). 

Los efectos especiales, llamados también ruidos, pueden desempeñar las mismas funciones o ser de las mismas clases que la música, aunque a veces también se utilizan efectos subliminales, como fondo (por ejemplo) de una música en primer plano.

Los planos determinan la situación, ya sea temporal, física o de intención de los distintos sonidos.

Hay varios tipos de planos como: 
Para lograr esos planos necesitamos de la presencia, en el sentido de acercamiento o alejamiento físico del plano principal; la intención en la interpretación; la intención en el texto; la calidad de esos sonidos; el ambiente o fondo. Combinando estos recursos entre ellos, la historia cobra vida. Dado que los recursos son forzosamente limitados, no debemos desperdiciar ninguno de ellos.

Se emplea normalmente con una intención psicológica, dramática. Incluso cuando cumple una función ortográfica se busca una respuesta emotiva en el oyente. Puede ser: 
Otra clasificación posible es: 
Ambiente es el entorno sonoro en donde la acción se desarrolla: 
En lo que a dramatizaciones se refiere, el ambiente es lo que da cuerpo y vida a la escena. Revela ya el lugar donde ocurre; ya la intención global; ya la subjetividad de un personaje u otro; ya el conjunto de todo ello o de la parte que se quiera. Para determinar el ambiente se puede utilizar la música, la voz y los efectos especiales. La ambientación puede ser: 



</doc>
<doc id="1681" url="https://es.wikipedia.org/wiki?curid=1681" title="Lagurus">
Lagurus

Lagurus es un género de plantas herbáceas de la familia de las poáceas. Es originario de la región del Mediterráneo.

Son plantas anuales. Hojas con vaina de márgenes libres; lígula corta, obtusa y ciliada; limbo lanceolado, plano. Inflorescencia en panícula densa, con ramas hírtulas. Espiguillas con 1 flor hermafrodita, articulada con la raquilla. Glumas subiguales, uninervadas, aristadas. Raquilla prolongada por encima de la flor, hirsuta. Lema lanceolada, con 5 nervios poco marcados, biaristulada y con una arista dorsal; arista dorsal geniculada, con columna retorcida. Pálea con 2 quillas, bífida. Lodículas con 2-3 dientes apicales. Ovario glabro. Cariopsis no surcada. Hilo elíptico.

El género fue descrito por Carlos Linneo y publicado en "Species Plantarum" 1: 81. 1753. La especie tipo es: "Lagurus ovatus" L.

El nombre del género deriva del griego "lagos", liebre y "oura" cola, refiriéndose a la forma de la panícula. 

El número de cromosomas es de: x = 7. 2n = 14. 2 ploidias. Cromosomas ‘grandes’.





</doc>
<doc id="1683" url="https://es.wikipedia.org/wiki?curid=1683" title="Leersia">
Leersia

Leersia, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de las regiones templadas y tropicales del mundo.
Son plantas perennes. Espiguillas muy comprimidas lateralmente, con una sola flor articulada con el pedúnculo, sin glumas. Lema con 5 nervios, aquillada. Pálea trinervada, aquillada. Androceo con 1-6 estambres. Cariopsis con embrión de c. 1/3 de su longitud.
El género fue descrito por Peter Olof Swartz y publicado en "Nova Genera et Species Plantarum seu Prodromus" 1, 21. 1788. La especie tipo es: "Leersia oryzoides" (L.) Sw. 
El nombre del género fue otorgado en honor de Johann Daniel Leers, médico y botánico alemán del siglo XVIII. 
El número de cromosomas es de: x = 12. 2n = 24, 48, y 60. 2, 4, y 5 ploidias. Cromosomas ‘pequeños’. 




</doc>
<doc id="1685" url="https://es.wikipedia.org/wiki?curid=1685" title="Lingüística general">
Lingüística general

La lingüística general o teórica puede estudiar cuestiones tan diversas como qué idiomas existen, qué propiedades tienen en común todos los idiomas, qué conocimiento debe tener una persona para ser capaz de usar un idioma, o como adquieren los niños la competencia lingüística. 


</doc>
<doc id="1688" url="https://es.wikipedia.org/wiki?curid=1688" title="Latitud">
Latitud

La latitud es la distancia angular entre la línea ecuatorial (el ecuador), y un punto determinado de la Tierra, medida a lo largo del meridiano en el que se encuentra dicho punto. Según el hemisferio en el que se sitúe el punto, puede ser latitud norte o sur.
La latitud proporciona la localización de un lugar, en dirección Norte o Sur desde el ecuador y se expresa en medidas angulares que varían desde los 0
° del Ecuador hasta los 90°N del polo Norte o los 90°S del Polo Sur. Esto sugiere que si trazamos una recta que vaya desde un punto cualquiera de la Tierra hasta el centro de la misma, el ángulo que forma esa recta con el plano ecuatorial expresa la latitud de dicho punto. La orientación Norte o Sur depende de si el punto marcado está más cerca del Polo Norte que del Polo Sur (latitud norte) o si está más cerca del Polo Sur que del Polo Norte (latitud Sur).
La latitud se mide en grados sexagesimales (representados por el símbolo grados ° inmediatamente arriba y a la derecha del número, mientras que las subdivisiones o fracciones de los grados se representan con ' que significa minuto sexagesimal y <nowiki>"</nowiki> que significa segundo sexagesimal), entre 0° y 90°; y puede representarse de dos formas:
Así, diez grados en latitud norte podría representarse codice_1 o codice_2; y diez grados sur podría ser codice_3 o codice_4.

En la cartografía usual —por ejemplo— la secuencia codice_5 significa una latitud (sexagesimal) de 70 grados, 55 minutos y 59 segundos de latitud Sur (un paralelo que estaría ya en la Antártida).
En la navegación marítima la latitud se suele representar con la letra griega φ (Phi).

Si se desea saber la distancia que representa un grado de latitud, se debe considerar que los grados de latitud están espaciados regularmente. Sin embargo, el ligero achatamiento de la Tierra en los polos causa que un grado de latitud varíe de 110,57 km en el ecuador hasta 111,70 km en los polos. Se suele redondear un grado de latitud a 111,12 km, de esta manera un minuto de latitud es 1852 metros (equivalente a una milla náutica) y un segundo de latitud, 30,86 metros.

La Tierra se divide en tres grandes zonas latitudinales:





</doc>
<doc id="1690" url="https://es.wikipedia.org/wiki?curid=1690" title="Lenguaje de máquina">
Lenguaje de máquina

El lenguaje de máquina o código máquina es el sistema de códigos directamente interpretable por un circuito microprogramable, como el microprocesador de una computadora o el microcontrolador de un autómata. Este lenguaje está compuesto por un conjunto de instrucciones que determinan acciones a ser tomadas por la máquina. Un programa consiste en una cadena de estas instrucciones más un conjunto de datos sobre el cual se trabaja. Estas instrucciones son normalmente ejecutadas en secuencia, con eventuales cambios de flujo causados por el propio programa o eventos externos. El lenguaje de máquina es específico de la arquitectura de la máquina, aunque el conjunto de instrucciones disponibles pueda ser similar entre arquitecturas distintas.

Los circuitos microprogramables son digitales, lo que significa que trabajan con dos únicos niveles de tensión. Dichos niveles, por abstracción, se simbolizan con los números 0 y 1, por eso el lenguaje de máquina solo utiliza dichos signos. Esto permite el empleo de las teorías del álgebra booleana y del sistema binario en el diseño de este tipo de circuitos y en su programación.

Claude Elwood Shannon, en su libro "Analysis of Relay and Switching Circuits", y con sus experiencias en redes de conmutación, sentó las bases para la aplicación del álgebra de Boole a las redes de conmutación. Una red de conmutación es un circuito de interruptores eléctricos que al cumplir ciertas combinaciones booleanas con las variables de entrada, define el estado de la salida. Este concepto es el núcleo de las puertas lógicas, las cuales son, por su parte, los ladrillos con que se construyen sistemas lógicos cada vez más complejos. Shannon utilizaba el relé como dispositivo físico de conmutación en sus redes, dado que el relé, a igual que una lámpara eléctrica, posee dos estados: activado (encendido) o desactivado (apagado).

El desarrollo tecnológico ha permitido evolucionar desde las redes de relés electromagnéticos a circuitos con tubos de vacío, luego a redes transistorizadas, hasta llegar a los modernos circuitos integrados, en cuya cúspide se encuentran los circuitos microprogramados.



</doc>
<doc id="1692" url="https://es.wikipedia.org/wiki?curid=1692" title="Lenguaje de alto nivel">
Lenguaje de alto nivel

Un lenguaje de programación de alto nivel se caracteriza por expresar los algoritmos de una manera adecuada a la capacidad cognitiva humana, en lugar de la capacidad con que los ejecutan las máquinas. Estos lenguajes permiten una máxima flexibilidad al programador a la hora de abstraerse o de ser literal. Permiten un camino bidireccional entre el lenguaje máquina y una expresión casi oral entre la escritura del programa y su posterior compilación. Por lo general suelen estar orientados a objetos, a eventos o a funciones, pudiendo estos combinarse. Asimismo, pueden ser compilados o interpretados. Algunos ejemplos son: Java, PHP, Python, Javascript, C++.

En los primeros lenguajes, la limitación era que se orientaban a un área específica y sus instrucciones requerían de una sintaxis predefinida. Se clasifican como lenguajes procedimentales o lenguajes de bajo nivel. Otra limitación de estos es que se requiere de ciertos conocimientos de programación para realizar las secuencias de instrucciones lógicas. Los lenguajes de alto nivel se crearon para que el usuario común pudiese solucionar un problema de procesamiento de datos de una manera más fácil y rápida.

Por esta razón, a finales de los años 1950 surgió un nuevo tipo de lenguajes de programación que evitaba estos inconvenientes, a costa de ceder un poco en las ventajas. Estos lenguajes se llaman "de tercera generación" o "de nivel alto", en contraposición a los "de bajo nivel" o "de nivel próximo a la máquina".

Lenguaje de alto nivel se refiere al nivel más alto de abstracción de lenguaje de máquina. En lugar de tratar con registros, direcciones de memoria y las pilas de llamadas, lenguajes de alto nivel se refieren a las variables, matrices, objetos, aritmética compleja o expresiones booleanas, subrutinas y funciones, bucles, hilos, cierres y otros conceptos de informática abstracta, con un enfoque en la facilidad de uso sobre la eficiencia óptima del programa.


"(Debido a que permite programar en nivel bajo)"



</doc>
<doc id="1693" url="https://es.wikipedia.org/wiki?curid=1693" title="Leymus">
Leymus

Leymus, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario del Hemisferio Norte.

El número cromosómico básico del género es x = 7, con números cromosómicos somáticos de 2n = 28, 42, 56 y 84, ya que hay especies diploides y una serie poliploide. Cromosomas relativamente "grandes".



</doc>
<doc id="1694" url="https://es.wikipedia.org/wiki?curid=1694" title="Lolium">
Lolium

El género Lolium perteneciente a la familia de las gramíneas (Poaceae, Gramineae) está constituido por 8 especies euroasiáticas.
Son hierbas anuales o perennes, mesotérmicas, con hojas planas y tiernas. Poseen una espiga terminal, dística, comprimida, con el raquis articulado. Las espiguillas son plurifloras, alternas y solitarias en cada nudo, las laterales con una sola gluma y la terminal con dos, dispuestas en el mismo plano que el raquis. La raquilla se halla articulada por encima de las glumas y entre los antecios. La gluma superior es lanceolada, rígida. La lemma es oblonga o lanceolada con el dorso redondeado. La pálea es bicarenada, apenas menor que la lemma. La flor es hermafrodita con tres estambres. El cariopse es oblongo y se halla adherido a las glumelas. El número cromosómico básico del género es x=7. 
Aparte de la bíblica cizaña ("Lolium temulentum" ), considerada una maleza muy dañina, dentro del género también se encuentran especies de gran importancia forrajera en regiones de clima templado como el "raigrás anual" ("L. multiflorum" ) y el "raigrás perenne" ("L. perenne" ).

"Lolium" contienen varias especies muy importantes como pasturas forrajeras y para césped, notablemente el estadio The Championships, Wimbledon. Para ganadería, producen un forraje de muy buena calidad y palatabilidad. También se utiliza a estas especies para programas de control de erosión de suelos. 

Algunas especies, particularmente "L. temulentum", son malezas afectando severamente la producción del trigo y de otros cultivos. El polen de raigrás es una de los mayores causas de la fiebre del heno.

El género fue descrito por Carlos Linneo y publicado en "Species Plantarum" 1: 83. 1753. La especie tipo es: "Lolium perenne" L.
Lolium : nombre genérico dado por Virgilio a una maleza problemática. 
Tiene un número de cromosomas de: x = 7. 2n = 14 y 28. 2 y 4 ploidias. Cromosomas ‘grandes’.





</doc>
<doc id="1696" url="https://es.wikipedia.org/wiki?curid=1696" title="Lygeum">
Lygeum

Lygeum, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originaria de la región del Mediterráneo.

Tiene 7 especies:



</doc>
<doc id="1697" url="https://es.wikipedia.org/wiki?curid=1697" title="Lisp">
Lisp

Lisp (históricamente LISP) es una familia de lenguajes de programación de computadora de tipo multiparadigma con larga historia y una inconfundible y útil sintaxis homoicónica basada en la notación polaca.

Desarrollado originalmente en 1958 por John McCarthy y sus colaboradores en el Instituto Tecnológico de Massachusetts, Lisp es el segundo lenguaje de programación de alto nivel de mayor antigüedad; apareció un año después de FORTRAN y uno antes que COBOL.

Al igual que COBOL y FORTRAN, Lisp ha cambiado mucho desde sus comienzos, y han existido un gran número de dialectos en su historia. Hoy, los dialectos de Lisp más ampliamente usados son Scheme (1975), Common Lisp (1984), Emacs Lisp (1985) y Clojure (2007).

Lisp fue creado originalmente como una notación matemática práctica para los programas de computadora, basada en el cálculo lambda de Alonzo Church. Se convirtió rápidamente en el lenguaje de programación favorito en la investigación de la inteligencia artificial (AI). Como lenguajes de programación precursor, Lisp fue pionero en muchas ideas en ciencias de la computación, incluyendo las estructuras de datos de árbol, el manejo de almacenamiento automático, tipos dinámicos, y el compilador auto contenido.

El acrónimo LISP significa "LISt Processor" (Procesamiento de listas). Las listas encadenadas son una de las estructuras de datos importantes de Lisp, y el código fuente de Lisp en sí mismo está compuesto de listas. Como resultado, los programas de Lisp pueden manipular el código fuente como una estructura de datos, dando lugar a los macro sistemas que permiten a los programadores crear lenguajes de dominio específico embebidos en Lisp.

La intercambiabilidad del código y los datos también da a Lisp su instantáneamente reconocible sintaxis. Todo el código del programa es escrito como expresiones S, o listas entre paréntesis. Una llamada de función o una forma sintáctica es escrita como una lista, con la función o el nombre del operador en primer lugar, y los argumentos a continuación; por ejemplo, una función f que toma tres argumentos puede ser llamada usando codice_1.

Lisp fue inventado por John McCarthy en 1958 mientras estaba en el Instituto Tecnológico de Massachusetts (MIT). McCarthy publicó su diseño en 1960 en un artículo de Communications of the ACM titulado "Funciones recursivas de expresiones simbólicas y su cómputo a máquina, Parte I" (la "parte II" nunca fue publicada). Allí mostró que con algunos operadores simples y una notación para las funciones, uno puede construir un lenguaje Turing completo para procesamiento de algoritmos.

Desde 1955 ó 1956, el Information Processing Language fue el primer lenguaje de AI, y ya había incluido muchos de los conceptos, tales como proceso por lista y recursión, que vinieron a ser usados en Lisp.

La notación original de McCarthy usaba "expresiones M" en corchetes que serían traducidas a expresiones S. Como un ejemplo, la expresión M codice_2 es equivalente a la expresión S codice_3. Una vez que Lisp fue implementado, los programadores rápidamente eligieron usar expresiones S, y las expresiones M fueron abandonadas. las expresiones M emergieron otra vez con los intentos efímeros del MLISP de Horace Enea y el CGOL de Vaughan Pratt.

Lisp fue implementado primero por Steve Russell en un computador IBM 704. Russell había leído el artículo de McCarthy, y se dio cuenta (para la sorpresa de McCarthy) que la función "eval" de Lisp podía ser implementada en código de máquina. El resultado fue un intérprete de Lisp funcional que podía ser usado para correr programas Lisp, o más correctamente, "evaluar expresiones Lisp".

Dos rutinas de lenguaje ensamblador para el IBM 704 se convirtieron en las operaciones primitivas para descomponer listas: car (contenido del registro de dirección) y cdr (contenido del registro del decremento). Los dialectos de Lisp todavía usan el car y cdr ( y ) para las operaciones que retornan el primer elemento y el resto de la lista respectivamente.

El primer compilador completo de Lisp, escrito en Lisp, fue implementado en 1962 por Tim Hart y Mike Levin en el MIT. Este compilador introdujo el modelo Lisp de compilación incremental, en el cual las funciones compiladas e interpretadas pueden entremezclarse libremente. El lenguaje en los memos de Hart y Levin es mucho más cercano al estilo moderno de Lisp que el anterior código de McCarthy.

Sobre su historia de cincuenta años, Lisp ha producido muchas variaciones en el tema base de un lenguaje de expresión S. Por otra parte, cada dialecto dado puede tener varias implementaciones, por ejemplo, hay más de una docena de implementaciones del Common Lisp.

Las diferencias entre los dialectos pueden ser muy visibles, por ejemplo, el Common Lisp y el Scheme usan diferentes palabras clave para definir funciones. Dentro de un dialecto que está estandarizado, sin embargo, las implementaciones conformadas soportan el mismo lenguaje base, pero con diferentes extensiones y bibliotecas.

Desde su inicio, Lisp estaba estrechamente relacionado con la comunidad de investigación de la inteligencia artificial, especialmente en sistemas PDP-10. Fue usado como la implementación del lenguaje de programación Micro Planner que fue la fundación para el famoso sistema de AI SHRDLU. En los años 1970, a medida que la investigación del AI engendró descendientes comerciales, el desempeño de los sistemas Lisp existentes se convirtió en un problema creciente.

Lisp era un sistema difícil de implementar con las técnicas de compilador y hardware común de los años 1970. Las rutinas de recolección de basura, desarrolladas por el entonces estudiante graduado del MIT, Daniel Edwards, hicieron práctico correr Lisp en sistemas de computación de propósito general, pero la eficacia todavía seguía siendo un problema. Esto llevó a la creación de las máquinas Lisp: hardware dedicado para correr ambientes y programas Lisp. Avances tanto en el hardware de computadora como en la tecnología de compiladores pronto hicieron obsoletas a las máquinas de Lisp, en detrimento del mercado de Lisp.

Durante los años 1980 y 1990, fue hecho un gran esfuerzo para unificar los numerosos dialectos de Lisp en un solo lenguaje (más notablemente, InterLisp, Maclisp, ZetaLisp, MetaLisp, y Franz Lisp). El nuevo lenguaje, Common Lisp, fue esencialmente un subconjunto compatible de los dialectos que reemplazó. En 1994, la ANSI publicó el estándar del Common Lisp, "ANSI X3.226-1994 Information Technology Programming Language Common Lisp". En aquel momento el mercado mundial para Lisp era mucho más pequeño de lo que es hoy.

Habiendo declinado algo en los años noventa, Lisp experimentó un nuevo auge enfocado en las implementaciones abiertas de Common Lisp y en el desarrollo de aplicaciones y de nuevas bibliotecas portátiles. Una muestra de este interés fue el que la versión impresa de Practical Common Lisp (Common Lisp Práctico) de Peter Seibel, un tutorial para nuevos programadores publicado en 2004, estuviese brevemente en Amazon.com como el segundo libro de programación más popular. El libro es accesible en línea sin costo.

Muchos nuevos programadores de Lisp fueron inspirados por escritores como Paul Graham y Eric S. Raymond luchando por un lenguaje que otros consideran anticuado. Los nuevos programadores de Lisp frecuentemente describen el lenguaje como una experiencia que abre los ojos y afirman que es sustancialmente más productivo que otros lenguajes. Este aumento de conciencia puede ser contrastado con el "invierno de la inteligencia artificial" y el breve crecimiento de Lisp a mediados de los 1990.

En su encuesta de las implementaciones del Common Lisp, Dan Weinreb lista once implementaciones activamente mantenidas. Scieneer Common Lisp es una nueva implementación comercial que bifurcó (fork) del CMUCL con un primer lanzamiento en 2002.

La comunidad del código libre ha creado la nueva infraestructura de soporte: Cliki es un Wiki que recoge la información relacionada con Common Lisp, el Common Lisp directory lista recursos, el #lisp es un canal popular de IRC (con soporte por un Bot escrito en Lisp), lisppaste soporta la distribución y el intercambio y comentario de retazos de código (snippets), el Planet Lisp recoge el contenido de varios blogs relacionados con Lisp, en el LispForum el usuario discute tópicos sobre Lisp, Lispjobs es un servicio para anunciar ofertas de trabajo y hay un nuevo servicio de noticias semanales (Weekly Lisp News).

Han sido celebrados los 50 años del Lisp (1958-2008) en LISP50@OOPSLA. Hay varias reuniones de usuario locales regulares (Boston, Vancouver, Hamburg,…), Reuniones Lisp (European Common Lisp Meeting, European Lisp Symposium) y una International Lisp Conference.

La comunidad Scheme mantiene activamente más de veinte implementaciones. Se han desarrollado en los últimos años varias significativas nuevas implementaciones (Chicken, Gauche, Ikarus, Larceny, Ypsilon). El estándar de Scheme Revised Report on the Algorithmic Language Scheme fue ampliamente aceptado en la comunidad del Scheme. El proceso Scheme Requests for Implementation ha creado muchas bibliotecas y extensiones casi estándares para el Scheme. Las comunidades de usuario de implementaciones individuales del Scheme continúan creciendo. En 2003 un nuevo proceso de estandarización del lenguaje fue comenzada y condujo al estándar RRS del Scheme en 2007. El uso académico del Scheme para enseñar ciencias de la computación parece haber declinado algo. Algunas universidades ya no están usando Scheme en sus cursos preliminares de ciencias de la computación.

Hay también algunos nuevos dialectos Lisp. Notablemente: Newlisp (un lenguaje de scripting), Arc (desarrollado por Paul Graham) y recientemente Clojure (desarrollado por Rich Hickey) y NU para la programación con Cocoa de Apple.

Los dos principales dialectos de Lisp usados para la programación de propósitos generales hoy en día son Common Lisp y Scheme. Estos lenguajes representan opciones de diseño significativamente diferentes.

El Common Lisp, descendiente principalmente de MacLisp, Interlisp, y Lisp Machine Lisp, es un superconjunto ampliado de los primeros dialectos del Lisp, con un estándar de lenguaje grande incluyendo muchos tipos de datos y formas sintácticas incorporados, así como un sistema del objeto. El Scheme es un diseño más minimalista, con un mucho más pequeño conjunto de características estándar pero con ciertas características de implementación (tales como optimización de llamada de cola y continuación completa) no encontradas necesariamente en Common Lisp. El Common Lisp también tomó prestadas ciertas características de Scheme tales como ámbito de léxico y clausura léxica.

El Scheme, es un dialecto del lenguaje Lisp con ámbito estático y cola recursiva auténtica inventado por Guy Lewis Steele Jr. y Gerald Jay Sussman. Fue diseñado para tener una semántica excepcionalmente clara y simple y pocas maneras diferentes de formar expresiones. Una amplia variedad de paradigmas programados encuentran una expresión conveniente en Scheme, incluyendo los estilos imperativo, funcional, y paso de mensajes. El Scheme continúa evolucionando con una serie de los estándares (Revised Report on the Algorithmic Language Scheme) y una serie de Scheme Requests for Implementation.

Además, los dialectos de Lisp son usados como lenguajes de scripting en un número de aplicaciones, con los más conocidos siendo el Emacs Lisp en el editor de Emacs, Visual Lisp en AutoCAD, Nyquist en Audacity.

Fue en Lisp donde nacieron muchas ideas de las ciencias de la computación, incluyendo la estructura de dato de árbol, recolección automática de basura, tipado dinámico, condicionales, funciones de orden superior como "map" y "reduce", recursividad, el compilador autocontenido y el REPL.

Lisp fue el primer lenguaje de programación homoicónico: todo el código fuente del programa es al mismo tiempo una estructura de datos del lenguaje (listas anidadas o árboles). Como resultado la metaprogramación en Lisp es relativamente sencilla. Ya que el código fuente de Lisp tiene una correspondencia directa con el árbol sintáctico abstracto del programa, se puede crear código de Lisp para manipular más código de Lisp, o aún crearlo desde cero, sin necesidad de un extensivo análisis sintáctico (parsing) o manipulación de código de máquina binario. Esto generalmente es considerado una de las ventajas primarias del lenguaje con respecto a su poder expresivo, y hace al lenguaje favorable a la evaluación metacircular.

La ubicua estructura codice_4, ahora admitida como un elemento esencial de cualquier lenguaje de programación, fue inventada por McCarthy para el uso en Lisp, donde vio su primera apariencia en una forma más general (la estructura codice_5). Fue heredada por el ALGOL, que la popularizó.

Lisp influyó profundamente a Alan Kay, el líder de investigación del Smalltalk, y entonces a su vez Lisp fue influenciado por Smalltalk, adoptando las características de la programación orientada a objetos (clases, instancias, etc.) a finales de los años 1970.

Lisp introdujo el concepto de recolección de basura, mediante el cual el sistema busca en el "heap" de memoria dinámica para eliminar objetos obsoletos sin intervención explícita del programador.

En gran parte debido a sus requerimientos de recursos con respecto al temprano hardware computacional (incluyendo los primeros microprocesadores), Lisp no se hizo tan popular fuera de la comunidad de inteligencia artificial, como lo fueron el FORTRAN y el descendiente del lenguaje ALGOL, el lenguaje C. Lenguajes más nuevos como Java y Python han incorporado algunas versiones limitadas de algunas de las características de Lisp, pero no pueden necesariamente brindar la coherencia y la sinergia de los conceptos completos encontrados en Lisp. Debido a su conveniencia para aplicaciones mal definidas, complejas, y dinámicas, Lisp están disfrutando actualmente de un cierto resurgimiento del interés popular.

El elemento fundamental en Lisp es la lista, en el sentido más amplio del término, pues tanto los datos como los programas son listas. De ahí viene su nombre, pues Lisp es un acrónimo de "ListProcessing".

Las listas en LISP están delimitadas por paréntesis. De aquí viene el chiste del significado de LISP: "LostInStupidParentheses" que aunque con buen humor es completamente ficticio.
Algunas de las funciones predefinidas de Lisp tienen símbolos familiares (+ para la suma, * para el producto), pero otras son más exóticas, especialmente dos que sirven precisamente para manipular listas, descomponiéndolas en sus componentes. Sus nombres ("car" y "cdr") son un poco extraños, reliquias de tiempos pasados y de la estructura de los ordenadores de segunda generación, "car" devuelve la cabeza de una lista y "cdr" su cola o resto.

Lisp sigue una filosofía de tratamiento no-destructivo de los parámetros, de modo que la mayoría de las funciones devuelven una lista resultado de efectuar alguna transformación sobre la que recibieron, pero sin alterar esta última.

Uno de los motivos por los que Lisp es especialmente adecuado para la IA es el hecho de que el código y los datos tengan el mismo tratamiento (como listas); esto hace especialmente sencillo escribir programas capaces de escribir otros programas según las circunstancias.

Lisp fue uno de los primeros lenguajes de programación en incluir manejo de excepciones con las primitivas "catch" y "throw".

Derivado de Lisp es el lenguaje de programación Logo. Sin entrar en detalles, podría decirse que Logo es Lisp sin paréntesis y con operadores aritméticos infijos.


Son operaciones del conjunto de instrucciones del IBM 704

Definición de la función:

Llamada a la función:

(último '(1 2 3 4 5 6 7)) ; devuelve el último de la lista: 7

(defun factorial (n)

(factorial 4) ;esto nos devolvería 24=4*3*2*1

 ;Propuesta por Nikolai Coica



Entre las más exitosas aplicaciones escritas en Lisp se pueden mencionar:



</doc>
<doc id="1698" url="https://es.wikipedia.org/wiki?curid=1698" title="Letra (desambiguación)">
Letra (desambiguación)

Letra o letras puede ser:

</doc>
<doc id="1700" url="https://es.wikipedia.org/wiki?curid=1700" title="Retardo (telecomunicación)">
Retardo (telecomunicación)

El retardo (en inglés y más comúnmente, lag) es una demora que se produce en una telecomunicación desde que se envía información desde un origen hasta que llega a su destino. Aunque este retardo puede deberse a una alta latencia de la red, también puede producirse debido a que no exista suficiente potencia de procesamiento en el servidor o cliente destino con el que se establece la comunicación, o en el cliente local en forma de retardos de entrada, saltos de imagen o cortes de audio y vídeo.

El "lag" produce generalmente una pésima experiencia a nivel comunicativo, tanto en el envío de datos como en el usuario o usuarios que están utilizando Internet en el momento en que se produce, ya que ralentiza sobremanera las aplicaciones que se están ejecutando.

El retardo en las redes puede estar causado por diferentes motivos, y es uno de los factores determinantes en la cuantificación del rendimiento de una red. Toda comunicación a distancia implica un cierto retardo en la llegada de los mensajes, por lo que este término se aplica cuando ese retardo es lo suficientemente prolongado como para dificultar la interacción entre los usuarios y hacer evidente la falta de simultaneidad entre ellos. 

Uno de los problemas en la retransmisión de vídeos es que se retrasa la descarga para su visualización y su imagen empeora. En la música resulta frustrante puesto que se puede llegar a escuchar entrecortado. En las llamadas, el tiempo diferido del mensaje suele aumentar y su calidad ser pésima. En los videojuegos ocurre un retardo en la imagen y sonidos del mismo, algunos objetos se encuentran fuera de lugar o en dos lugares al mismo tiempo.




</doc>
<doc id="1702" url="https://es.wikipedia.org/wiki?curid=1702" title="Ley">
Ley

La ley () es una norma jurídica dictada por el legislador, es decir, un precepto establecido por la autoridad competente, en que se manda o prohíbe algo en consonancia con la justicia, cuyo incumplimiento conlleva a una sanción.
Según el jurista panameño César Quintero, la ley es una «norma dictada por una autoridad pública que a todos ordena, prohíbe o permite, y a la cual todos deben obediencia». Por otro lado, el jurista venezolano Andrés Bello definió la ley como «una declaración de la voluntad soberana que, manifestada en la forma prescrita por la Constitución, manda, prohíbe o permite». Para Bello, lo decisivo para calificar un acto de ley es la forma en que se gesta y no la naturaleza de la disposición en él contenida.En general, las leyes son normas que regulan la convivencia social de una nación.

Las leyes son delimitadoras del libre albedrío de las personas dentro de la sociedad. Se puede decir que la ley es el control externo que existe para la conducta humana, las normas que rigen nuestra conducta social. Constituye una de las principales fuentes del derecho.



Las leyes naturales son juicios enunciativos cuyo fin estriba en mostrar las relaciones indefectibles que en la naturaleza existen, la cual es dictada por la correcta razón. Thomas Hobbes difiere entre razón y pasión como objetos de la ley natural del hombre en el cual la razón garantiza la búsqueda de paz, la renuncia a mis derechos positivos (en pos de obtener seguridad y vida) y el cumplimiento con los pactos (voluntario, único y racional). En cambio, la pasión despierta por sensaciones y necesidades naturales del hombre, como el temor a la muerte. Nace del propio instinto humano y no hace posible el pacto, ya que el hombre queda como un animal insatisfecho, siempre con ganas de más y más para mejorar.

Por lo tanto, debe concluirse que la razón será siempre por encima de la pasión, ya que nos permite pensar antes de actuar. La pasión solamente nos sirve para enseñarnos algo que ni la modernidad, ni el paso de los años, ni los pactos o contratos o conceptos de justicia e injusticia podrán enseñarnos: a sobrevivir a toda costa. El hombre de estado o el que este aprendiendo a gobernar debe entender que los hombres tienen capacidad de razón, normalmente son volubles y caen fácilmente ante el derroche de las pasiones, y eso puede ser benéfico para el, ya que puede aprender a desarrollar un mandato en el cual pueda controlar a los demás. A partir de sus esperanzas y sueños, sus temores y sus alegrías. Como ya he dicho, todos los hombres tienen el don de razonar, pero caen siempre en la trampa porque en su gran mayoría no son magnánimos, sino pusilánimes y débiles.

En Derecho, el origen de la definición de la ley se debe a Tomás de Aquino en su "Summa Theologiae" al concebirla como: «La ordenación de la razón dirigida al bien común y promulgada por el que tiene a su cargo el cuidado de la comunidad». 

Más modernamente, se denomina ley a la norma de mayor rango tras la Constitución que emana de quien ostenta el poder legislativo. Mientras no está aprobada es un proyecto de ley.



a) Por el sistema al que pertenecen: internacionales; nacionales; provinciales; locales.

b) Según el modo de operar:

c) Según cómo actúa la voluntad individual:

Algunos tipos de leyes son:

Son normas jurídicas con rango de ley dictadas por el Gobierno sobre determinadas materias. No son propiamente leyes, aunque tienen todos los efectos de éstas, ya que tienen valor, rango y fuerza de ley. Entre ellas encontramos al: 



</doc>
<doc id="1706" url="https://es.wikipedia.org/wiki?curid=1706" title="Logotipo">
Logotipo

Un logotipo —coloquialmente también llamado logo— es un signo gráfico que identifica a una empresa, un producto comercial, un proyecto, o en general, a cualquier entidad pública o privada.
Antes 
Históricamente, los artesanos del barro, del cristal, de la piedra, los fabricantes de espadas y artilugios de hierro fino, así como los impresores, utilizaban marcas para señalar su autoría.

Para que un logotipo resulte congruente y exitoso, debe ser conforme al principio fundamental del diseño donde «menos es más». Dicha simplicidad permite que sea:

Las marcas construidas exclusivamente con letras llegan a tener tanta fuerza o más que aquellas que, si bien cuentan con un icono gráfico, requieren la asociación del texto para posicionarse desde el inicio; tal es el caso, por ejemplo, de las marcas de automóviles. Posteriormente, la imagen queda intrínsecamente asociada al sonido del nombre de la marca original.

El logotipo puede ser el eje afirmador de la propiedad privada a través del hecho de la autoría.

Un logotipo se diferencia por:

La simbología es el estudio de los símbolos o el conjunto de estos. Un símbolo, por otra parte, es la representación sensorial de una idea que guarda un vínculo convencional y arbitrario con su objeto.
La noción de simbología se utiliza para nombrar al sistema de los símbolos que identifican a los diferentes elementos de algún ámbito. La electricidad, la química y la mecánica, entre otros ámbitos del conocimiento, tienen su propia simbología.
Quien conoce la simbología de una especialidad, puede expresarse mediante los símbolos e interpretar diagramas o esquemas que apelen a los símbolos en lugar de las palabras. Es posible clasificar la simbología según su objeto de estudio o área de incumbencia.

Isologo, imagotipo, isotipo y logotipo son varias tipologías posibles de la marca corporativa.




</doc>
<doc id="1707" url="https://es.wikipedia.org/wiki?curid=1707" title="Lycurus">
Lycurus

Lycurus es un género de planta con flor, gramínea, perteneciente a la familia de las poáceas. Es originaria del sur de EE. UU., Hawái hasta el norte tropical de América del Sur.
son plantas perennes cespitosas. Tallos con numerosos nudos. Vainas carinadas; la lígula es una membrana; láminas lineares, dobladas. Inflorescencia una panícula densa espiciforme, terminal o axilar, portando espiguillas pareadas, a veces solitarias o raramente en tríadas, desigualmente pediceladas, raramente ambas sésiles; espiguillas desarticulándose con los pedicelos adheridos, también tardíamente desarticulándose arriba de las glumas; espiguilla superior generalmente bisexual, a veces estaminada o raramente estéril; espiguilla inferior bisexual, estaminada o estéril. Espiguillas con 1 flósculo, sin una extensión de raquilla, lateralmente comprimidas, inconspicuamente carinadas; glumas subiguales, más cortas que el flósculo. Fruto una cariopsis; embrión c. 1/2 la longitud de la cariopsis; hilo punteado. 
El género fue descrito por Carl Sigismund Kunth y publicado en "Nova Genera et Species Plantarum (quarto ed.)" 1: 141. 1815[1816].
Lycurus: nombre genérico que deriva de las pablabras griegas "lukos" (lobo) y "oura" (cola), en alusión a la inflorescencia. 



</doc>
<doc id="1708" url="https://es.wikipedia.org/wiki?curid=1708" title="Luziola">
Luziola

Luziola es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originaria del sur de Norteamérica hasta Sudamérica tropical.
El nombre del género fue modificado desde "Luzula" que pertenece a la familia Juncaceae. 



</doc>
<doc id="1709" url="https://es.wikipedia.org/wiki?curid=1709" title="Lophopogon">
Lophopogon

Lophopogon es un género de plantas herbáceas de la familia de las poáceas. Es originario de la India y Sri Lanka.




</doc>
<doc id="1711" url="https://es.wikipedia.org/wiki?curid=1711" title="Lophatherum">
Lophatherum

Lophatherum, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Asia oriental.
El nombre del género deriva de las palabras griegas "lophos" (cresta o penacho de pelos) y de "ather" (barba de trigo, arista), refiriéndose a mechones de barbas en lemas estériles. 



</doc>
<doc id="1712" url="https://es.wikipedia.org/wiki?curid=1712" title="Lynx (navegador)">
Lynx (navegador)

Lynx es un navegador web y cliente de gopher en modo texto.

Lynx es usado en terminales de cursor direccionable y celdas de caracteres, o emuladores de terminal (incluyendo terminales VT100 y paquetes de software para computadoras de escritorio que emulan terminales VT100, como Kermit o Procomm). Originalmente fue desarrollado para UNIX y VMS y aún hoy se distribuye con varias distribuciones de Linux. Oficialmente existen versiones para Microsoft Windows (Windows 95 y posteriores), DOS, OS/2 y FreeBSD, AmigaOS, Atari TOS, BeOS entre otros tantos. Las versiones para Mac OS X son provistas por OSXGNU.

Su simplicidad facilita que un lector de pantalla trabaje sobre este navegador, lo que lo convirtió en una opción para usuarios con problemas de visión. Lynx también se usa para comprobar la usabilidad de un sitio web en navegadores web antiguos.

Para navegar con Lynx se puede seleccionar un hiperenlace con las teclas de dirección o, activando una opción para numerar los enlaces, ingresando el número de cada enlace. Las versiones actuales tiene soporte para varias características de HTML. Incluye soporte para marcadores, cookies. El contenido de las tablas es mostrado en varias líneas de texto, donde el final de cada fila de la tabla se representa con un salto de línea. Los frames son identificados por un nombre y se navegan como si fueran páginas independientes. Lynx puede mostrar archivos locales e incluye soporte para los protocolos Gopher, FTP, WAIS, NNTP, Finger, o servidores cso/ph/qi, y servicios accesibles a través de conexiones a cuentas telnet, TN3270 o rlogin.

El desarrollo de Lynx comenzó entre julio y octubre de 1992 por Michael Grobe, Charles Rezac y Lou Montulli, en el "Distributed Computing Group", dentro de "Academic Computing Services" de la Universidad de Kansas. El propósito original de Lynx era ser un navegador para distribuir información del campus, como parte del "Campus-Wide Information Server".
Lou Montulli modificó el programa para que pudiera conectarse a Internet y lanzó la versión 2.0 en marzo de 1993.
Gareth Blythe, desarrollador de DosLynx, se unió luego al proyecto Lynx.
En 1994, Lou Montulli y Gareth Blythe abandonan el proyecto para ocupar cargos en Netscape Communications Corporation.

La Universidad de Kansas se ocupó del desarrollo y distribución de Lynx hasta la versión 2.4.2.

Por las dificultades que se fueron encontrando en el desarrollo del programa, Lynx fue liberado bajo licencia GNU GPL alrededor de 1996, manteniendo la Universidad de Kansas el copyright.
Actualmente Lynx se mantiene gracias a desarrolladores independientes coordinados en una lista de correo por Thomas Dickey (quien se unió al proyecto en 1998 con el lanzamiento de la versión 2.8).




</doc>
<doc id="1716" url="https://es.wikipedia.org/wiki?curid=1716" title="Laberinto">
Laberinto

Un laberinto (del latín "labyrinthus", y este del griego λαβύρινθος "labýrinzos") es un lugar formado por calles y encrucijadas, intencionadamente complejo para confundir a quien se adentre en el mismo. La etimología de la palabra es dudosa, aunque parece provenir de Asia Menor. 

Los laberintos de forma cuadrada o rectangular son los más antiguos que existen; la primera representación conocida de un laberinto de este tipo se encuentra en una tablilla de Pilo y también aparece, como sello, en las tumbas del antiguo Egipto, donde se hizo famoso desde la antigüedad el "Laberinto de Fayum", citado por Heródoto. Los laberintos de forma redonda o circular aparecieron a fines del siglo VII a.C. en la Italia etrusca; más tarde, aparecen en las monedas de Cnosos, a finales del siglo III y se cree que eran usadas como mapa del célebre Laberinto de Creta.

Los laberintos se clasifican básicamente en dos grandes grupos ""según la relación que existe con el centro y la salida del mismo"". El primer grupo de estos laberintos es el laberinto clásico o laberinto univiario: es el que hace recorrer, al ingresar en él, todo el espacio para llegar al centro mediante una única vía, camino o sendero; es decir, no ofrece la posibilidad de tomar caminos alternativos, no hay bifurcaciones, sino que existe una sola puerta de salida, que es la misma por la que se entra al laberinto. Por el hecho de tener un solo camino o sendero que seguir a medida que se avanza dentro de él, no es posible perderse en su interior. Por ser el laberinto más sencillo es frecuentemente utilizado para realizar experimentos de robótica en informática, especialmente populares en Japón 

El segundo grupo de laberintos son los laberintos multiviarios (dédalos, perdederos o laberinto de caminos alternativos) en donde al recorrer el interior del laberinto puede seguirse el camino correcto o uno incorrecto, que llevará o no a la salida del mismo. Este tipo de laberintos se comenzaron a utilizar en los jardines de setos en la Inglaterra del siglo XII, ya que eran el lugar propicio para una cita amorosa; luego de allí se extendieron progresivamente por toda Europa, especialmente en Francia e Italia. Se destacan en este sentido los jardines laberínticos de André Le Nôtre en Versalles y el diseñado por Gerolamo Frigimelica en la Villa Pisani, cerca de Venecia, en Italia.

Por otro lado, cada uno de estos dos grandes grupos se dividen a su vez en subcategorías, atendiendo a ""la forma en que fue construido el laberinto"":

El laberinto debe su nombre a la legendaria construcción diseñada por el inventor Dédalo a pedido del rey Minos de Creta para mantener preso a su hijo Minotauro (monstruo mitad hombre, mitad toro), que acabó muerto por Teseo, quien se adentró en los inextricables pasillos dejando una huella de hilo (que le había dado la princesa Ariadna, hermana del monstruo).

Aunque no ha sido identificado positivamente ningún sitio en Creta como el laberinto del Minotauro, en Cnosos se encontraron monedas de los siglos IV-III  a. C. con el símbolo del laberinto en ellas.
El formato típico durante este período es un circuito de siete meandros o vías, conocido como el "laberinto clásico". Los ejemplos más antiguos del mundo que se conservan de este tipo de laberinto no están sin embargo en Creta o en su entorno, sino en una serie de petroglifos de arte rupestre en la provincia de Pontevedra (España), datados en la Edad de Bronce.

Otro elemento de la formación del mito del Laberinto puede haber sido que el palacio de Cnosos —la casa del "labrys" o hacha doble— era un complejo de habitaciones y corredores en el que los invasores atenienses tuvieron dificultad para encontrar y matar al rey cuando lo tomaron.

Un espacio abierto delante del palacio estaba ocupado por una pista de baile con un dibujo laberíntico que servía para guiar a los que bailaban una danza erótica de la primavera.

El origen de ese dibujo, llamado también laberinto, parece haber sido el laberinto tradicional de arbustos que se utilizaba para atraer a las perdices hacia uno de sus machos, enjaulado en la cerca central, con reclamos de alimento, quejas amorosas y desafíos; y los bailarines imitarían la danza de amor extática y renqueante de las perdices macho, cuyo destino era que el cazador les golpease en la cabeza.

El laberinto del que escaparon Dédalo y su hijo Ícaro podría haber sido el piso de mosaico en el que estaba dibujado y que tenían que seguir en la danza de la perdiz ritual.

Parece que en la primavera se realizaba en toda la cuenca del Mediterráneo una danza erótica de la perdiz en honor de la diosa Luna y que los bailarines renqueaban y llevaban alas.

En Palestina, esta ceremonia, llamada la "Pesach" (‘la renqueante’), se realizaba todavía, según san Jerónimo, en Beth-Hoglah (‘el Templo del Cojo’), donde los devotos bailaban en espiral. Beth-Hoglah se identifica con la «era de Atad», en la que se lloraba la muerte del rengo rey Jacob, cuyo nombre podría significar Yah Akeb (‘el dios del talón’). El profeta Jeremías advierte a los judíos que no deben tomar parte en esos ritos orgiásticos cananeos, y cita: «La perdiz recoge pollitos que no ha parido».

Una jarra de vino etrusca de Tragliatella en la que se ven dos héroes a caballo, muestra la teoría religiosa acerca de la danza de la perdiz. El jinete que va delante lleva un escudo en el que está dibujada una perdiz, y un demonio de la muerte se posa detrás de él; el otro héroe lleva una lanza y un escudo en que está dibujado un pato.

Detrás de ellos hay un dibujo laberíntico parecido al que se encuentra no solo en ciertas monedas de Cnosos, sino también en los intrincados dibujos hechos en el césped y que pisaban los escolares británicos en la Pascua de Resurrección hasta el siglo XIX.

Según el escritor e historiador inglés Robert Graves, la idea del laberinto está relacionada con el sistema monárquico de la prehistoria: el mejor de los hombres de una tribu era elegido rey, tenía poder absoluto sobre el grupo, pero era asesinado después de un período (se cree que un año). Solo el héroe excepcional —un Dédalo o un Teseo— volvía vivo del laberinto.
En este contexto, tiene gran importancia el descubrimiento (en los años cincuenta) en las cercanías de Bossiney (Cornualles) de un laberinto cretense tallado en la superficie de una roca. La barranca donde el Dr. Renton Green descubrió el laberinto es una de las últimas guaridas del cuervo chova de Cornualles. Se decía que la chova aloja el alma del rey Arturo que perturbó el Infierno y con quien este laberinto de Bosinney está íntimamente relacionado en la leyenda.

Una danza laberíntica parece haber sido llevada a Britania desde el Mediterráneo oriental por agricultores neolíticos del tercer milenio a. C. puesto que toscos laberintos de piedra, análogos a los británicos hechos en el césped, se dan en la zona «Beaker B» de Escandinavia y el nordeste de Rusia; y en el sudeste de Europa se encuentran laberintos eclesiásticos, utilizados en otro tiempo con propósitos penitenciales.

Los ejemplos conocidos más antiguos de los laberintos son pequeños y simples petroglifos que se presume tienen una antigüedad de 3000 años. Se encuentran en numerosos lugares alrededor del mundo, desde Siria hasta Irlanda.
Las danzas en espiral, en las que los jóvenes de ambos sexos giraban hacia un centro para alejarse después, seguían siendo muy populares en el siglo XIX, las danzas laberínticas que aún se practican en Europa descienden del antiguo baile de la grulla, o geranos, supuestamente ejecutado en la isla griega de Naxos por Teseo y sus amigos para celebrar su salida victoriosa.

A los laberintos ingleses hechos en el césped se les llama «ciudad de Troya», y lo mismo a los de Gales: "caer-droia". Probablemente los romanos los llamaban así por su Juego de Troya, una danza laberíntica ejecutada por jóvenes aristócratas en honor del antepasado de Augusto, el troyano Eneas. Según Plinio también la bailaban los niños en la campiña italiana.

Los dos diseños principales son el "clásico" y el "medieval" y, aunque existen numerosas variaciones, la forma básica es fácilmente reconocible.

En tiempos recientes el mito del laberinto ha sido transformado en una obra teatral por Ilinka Crvenkovska, en la cual se exploran las nociones de las habilidades del hombre para controlar su propio destino.

El escritor argentino Jorge Luis Borges estaba fascinado con el concepto del laberinto y lo utilizó muchas veces en el desarrollo de sus cuentos. El uso literario que este escritor le dio al tema ha inspirado a gran cantidad de otros autores en el mundo, como por ejemplo a Umberto Eco (en "El nombre de la rosa").

En los últimos años hubo un resurgimiento del interés por el símbolo del laberinto, lo que ha inspirado un resurgimiento de la construcción notable en el Parque Willen (Milton Keynes), la catedral Grace de San Francisco y el Parque Tapton de Chesterfield.

El significado cultural y la interpretación del laberinto como símbolo es muy amplio y rico. Está presente en diversas culturas, épocas y lugares, presentándose siempre como un símbolo ligado a lo espiritual. Por ejemplo, muchos laberintos dibujados en el suelo servían como una especie de trampa que atrapaba a los malos espíritus. Se conoce esta función desde la prehistoria en adelante. Incluso en algunas iglesias católicas es posible encontrarlos trazados en el piso, cerca del baptisterio (lugar donde se bautiza a los nuevos fieles). En algunas casas, la imagen del laberinto se trazaba en la puerta de ingreso, como sistema de protección. Pero una de las más importantes significaciones del símbolo del laberinto está asociada a los rituales de iniciación. Por lo tanto, el laberinto es el símbolo que representa la búsqueda del centro personal, del sí mismo del ser humano. Para el encuentro de tan preciado hallazgo, se requiere de un ritual iniciático que implica la superación, en distintas etapas, de una prueba.

Durante la Edad Media, el laberinto está fuertemente relacionado con el duro camino de los creyentes hacia Dios. El recorrido tortuoso de los caminos enredados y difíciles hasta hallar el centro simbolizaban la participación en los sufrimientos de Cristo en la cruz. El camino del laberinto es el peregrinaje, es la muerte al hombre antiguo, pecador. El hallazgo del centro representa el volver a nacer.

En el Renacimiento el ser humano se convierte en el centro del laberinto, como reflejo de las enseñanzas humanistas antropocéntricas.

En la actualidad, el laberinto se mantiene como un símbolo vivo presente en diferentes ámbitos, desde la esfera artística en numerosas propuestas en pintura, escultura, cine, etcétera, en la investigación académica antropológica, psicológica, así como también en la gráfica, publicidad e incluso en distintas áreas de entretenimiento como los juegos de computadora.





</doc>
<doc id="1719" url="https://es.wikipedia.org/wiki?curid=1719" title="Acortamiento (lingüística)">
Acortamiento (lingüística)

Se denomina en general acortamiento en morfología, subdisciplina de la gramática, al procedimiento de "creación" de nuevas palabras o neologismos al eliminar partes de ella al final o al comienzo de otro vocablo.

Puede incluir diversos metaplasmos de supresión, tales como:


Por ejemplo, se acorta "autobús" en bus, o "cinematógrafo" en cine (por apócope). Se acorta "bicicleta" en bici (por apócope), de modo coloquial. Este tipo de apócopes es frecuente en el lenguaje hipocorístico o infantil, o meramente afectivo: "boli" por "bolígrafo", "pelu" por "peluquería", "insti" por "instituto", etc.

La abreviación es una forma de acortamiento mediante el cual se reduce el cuerpo fónico de una palabra (como por ejemplo, "cine" por "cinematógrafo"), o la cantidad vocálica por paso de la larga a la breve (Ley de Osthoff). En el latín clásico, toda vocal larga seguida de vocal se abrevia ("vocalis ante vocalem corripitur").

 También tiene una Categoría de acortamientos en español contenidos en "Wikcionario".


</doc>
<doc id="1720" url="https://es.wikipedia.org/wiki?curid=1720" title="Absorción (lingüística)">
Absorción (lingüística)

La absorción es el fenómeno por el cual una vocal desaparece al incorporarse a un sonido consonántico vecino, concretamente, por la acción de una sonante vecina.

Estaría relacionado con el fenómeno gramatical de la amalgama.



</doc>
<doc id="1721" url="https://es.wikipedia.org/wiki?curid=1721" title="Activo">
Activo

Los términos activo o activa pueden referirse, en esta enciclopedia, a los siguientes artículos:





</doc>
<doc id="1723" url="https://es.wikipedia.org/wiki?curid=1723" title="Lasiacis">
Lasiacis

Lasiacis, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de América tropical y subtropical. Comprende 35 especies descritas y de estas, solo 15 aceptadas.
Son plantas perennes, raramente anuales, cespitosas y erectas, trepadoras o rastreras; plantas hermafroditas o polígamas. Vainas redondeadas; lígula una membrana; láminas lineares a ovadas, aplanadas, generalmente sin pseudopecíolos. Inflorescencia una panícula abierta o contraída; espiguillas subglobosas, obovoides o elipsoides, colocadas oblicuamente sobre el pedicelo, con 2 flósculos; desarticulación por debajo de las glumas, la espiguilla caediza como una unidad; glumas y lema inferior abruptamente apiculadas, lanosas apicalmente, negro brillantes y con la epidermis interior aceitosa en la madurez, gluma inferior 1/3–2/3 la longitud de la espiguilla, 5–13-nervia, gluma superior y lema inferior casi tan largas como la espiguilla inferior, 7–15-nervias; flósculo inferior estéril o estaminado; pálea inferior 1/4 a tan larga como la lema inferior; flósculo superior bisexual; lema y pálea superior fuertemente endurecidas, lanosas apicalmente en ligeras excavaciones; lodículas 2; estambres 3; estigmas 2. Fruto una cariopsis; embrión ca 1/2 la longitud de la cariopsis, hilo punteado o cortamente oblongo.

El género fue descrito por (Griseb.) Hitchc. y publicado en "Contributions from the United States National Herbarium" 15: 16. 1910. La especie tipo es: "Lasiacis divaricata"
El nombre del género deriva del griego "lasios" (lana) y "akis" (punto), refiriéndose al florete maduro. 




</doc>
<doc id="1724" url="https://es.wikipedia.org/wiki?curid=1724" title="Leptochloa">
Leptochloa

Leptochloa es un género de planta con flor, gramínea, perteneciente a la familia de las poáceas. Es originaria de África, América y Australia.
Son plantas anuales o perennes, cespitosas. La lígula es una membrana, ciliada o sin cilios; láminas lineares, generalmente aplanadas. Inflorescencia una panícula de racimos delgados unilaterales, las espiguillas brevipediceladas, en 2 hileras. Espiguillas comprimidas lateralmente, carinadas, con 2-10 flósculos bisexuales, el más superior reducido; desarticulación arriba de las glumas y entre los flósculos; glumas más cortas que las espiguillas, 1-nervias, carinadas, la inferior más corta a casi tan larga como la superior; lemas membranáceas, 3-nervias, el ápice obtuso a 2-lobado, aristado o sin aristas; páleas más cortas que las lemas, 2-carinadas; lodículas 2; estambres 2 o 3; estilos 2. Fruto una cariopsis, sulcado o no; embrión 1/3-2/5 la longitud de la cariopsis; hilo punteado.
El género fue descrito por P.Beauv. y publicado en "Essai d'une Nouvelle Agrostographie" 71, pl. 15, f. 1. 1812. La especie tipo es: "Leptochloa virgata" 
El nombre del género deriva de las palabras griegas "leptos" (delgado) y "chloë" (hierba), refiriéndose a las inflorescencias. 
El número cromosómico básico es x = 10, con números cromosómicos somáticos de 2n = 20, 40 y 60. Hay especies diploides y tetraploides. Nucléolos persistente. 

A continuación se brinda un listado de las especies del género "Leptochloa" aceptadas hasta mayo de 2015, ordenadas alfabéticamente. Para cada una se indica el nombre binomial seguido del autor, abreviado según las convenciones y usos. 





</doc>
<doc id="1725" url="https://es.wikipedia.org/wiki?curid=1725" title="Leptocoryphium">
Leptocoryphium

Leptocoryphium, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de América.





</doc>
<doc id="1726" url="https://es.wikipedia.org/wiki?curid=1726" title="Lepturus">
Lepturus

Lepturus, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de la costa este de África, Madagascar, a Australia y Polinesia.
El género fue descrito por Robert Brown y publicado en "Prodromus Florae Novae Hollandiae" 207. 1810. La especie tipo es: "Lepturus repens" 
El nombre del género deriva del griego "leptos" (delgado) y "oura" (cola), refiriéndose, ya sea, a la gluma lanceolada lineal o, (más probablemente), a su esbelta inflorescencia. 
A continuación se brinda un listado de las especies del género "Lepturus" aceptadas hasta mayo de 2015, ordenadas alfabéticamente. Para cada una se indica el nombre binomial seguido del autor, abreviado según las convenciones y usos. 


Reference article Missouri Botanical Garden. MO Generic Names in Use
Reference article Soreng, R. J., P. M. Peterson, K. Romaschenko, G. Davidse, F. O. Zuloaga, E. J. Judziewicz, T. S. Filgueiras, J. I. Davis & O. Morrone. 2015. A worldwide phylogenetic classification of the Poaceae (Gramineae). J. Syst. Evol. 53(2): 117–137, f. 1. 


</doc>
<doc id="1727" url="https://es.wikipedia.org/wiki?curid=1727" title="Lithachne">
Lithachne

Lithachne, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Sudamérica.



</doc>
<doc id="1730" url="https://es.wikipedia.org/wiki?curid=1730" title="Luigi Boccherini">
Luigi Boccherini

Ridolfo Luigi Boccherini (Lucca, Toscana; 19 de febrero de 1743-Madrid; 28 de mayo de 1805) fue un compositor y violonchelista italiano afincado desde los veinticinco años en España, donde desarrolló la mayor parte de su carrera como compositor. Estéticamente pertenece al estilo galante.

Nació el 19 de febrero de 1743 en Lucca, Toscana, en el seno de una familia de artistas, donde pudo desarrollar su vocación. Su padre fue contrabajista y chelista y su hermana bailarina de ballet. Su hermano Giovanni Gastone inicialmente participaba en el cuerpo de baile, pero más tarde en la poesía y la escritura al grado en que llegó a escribir libretos para Antonio Salieri y Joseph Haydn. Boccherini se interesó por el violonchelo desde temprana edad. Su padre le dio las primeras lecciones. Posteriormente, Boccherini adquirió un nivel magistral en su instrumento, bajo la tutela de Domenico Francesco Vannuci (1718-75), chelista, maestro de armonía y contrapunto, así como compositor de música sacra. 
Progresó tanto que en las fiestas de Lucca de 1756 consta su participación como violonchelista contando con tan solo catorce años de edad. También quedó su nombre registrado como músico de capilla, tocando violonchelo y contrabajo, en los anuarios de Lucca que datan del 22 de abril de 1755.

Su padre, impresionado por las aptitudes de Luigi, le envía a Roma a estudiar con Giovanni Battista Costanzi, un compositor célebre por esa época, autor de óperas y música sacra. Ahí se familiarizó con la obra de Palestrina y de Allegri, cuyo famoso "Miserere" impresionó al joven músico. En 1757, después de terminar sus estudios en la Basílica de San Pedro en Roma, acompañó a su padre, que había logrado obtener plaza para ambos en la corte imperial austriaca en Viena e incluso para sus hermanas Maria Ester, Anna Matilda y su hermano Giovanni Gastone en el baile. En 1758, en su primer viaje a Viena de los tres que haría durante su vida, tocó como solista en el teatro de la corte junto con su padre, en el contexto de la <nowiki>"</nowiki>"Musikalische Fasten-Accademien"

Boccherini regresó a Lucca alrededor de 1760 con la ilusión de obtener fama en su ciudad natal. Durante esta estancia en Lucca, compuso varios oratorios, así como las seis sinfonías o cuartetos Op 2 y 3, seis duetos y sus seis tríos op.1, que fueron publicados por "La Chevadière" en París en 1761, donde contaba con el puesto de director de música en la capilla.

En Lucca, el patrón de Boccherini fue Giacomo Puccini (1712-81), director de la capilla del Estado, organista de la catedral y en la "Accademico Filarmonico" en Bolonia. Documentos muestran que Boccherini apareció en repetidas ocasiones como solista en los festivales de Santa Croce y en conciertos de la iglesia hasta 1764. En este entonces contaba con el puesto de violonchelista de la capilla del Estado desde el 27 de abril de 1764. Sin embargo, apenas 2 años después de la muerte de su padre, Boccherini abandonó el puesto al igual que Lucca.

En 1765 Boccherini se establece en Milán e inicia una gira de conciertos con un cuarteto de cuerdas (que para este tiempo representa una novedad) creado en 1764 con los violinistas Pietro Nardini y Filippo Manfredi -pupilo de Tartini- y el viola Giuseppe Cambini. Su repertorio está formado por obras de Haydn, del propio Boccherini y otros compositores contemporáneos. Entre 1764 y 1768 compone dos oratorios: "Giuseppe riconosciuto" y "Gioas, re di Giudea". Ante la aceptación que estaba teniendo su formación de cámara, decide emprender un viaje que debía llevarle por los principales centros culturales de Europa, a finales de 1762 y principios de 1763. Ambos se embarcan en un tour de conciertos, donde visitaron  Turín, algunas ciudades de  Lombardía, Piemonte  y el sur de Francia. Se sabe también que visitó algunas ciudades de Italia, como esel caso de Modena el 7 de enero de 1763, así como Pavía y Cremona en julio de 1765, donde conoció a Giovanni Battista Sammartini.

En 1767 se instala en París, con su segundo violín Filippo Manfredi, donde publica algunos cuartetos op.1 y tríos op.2. La música de Boccherini ya era conocida a su llegada gracias a que sus obras habían sido publicadas años antes, como los  tríos  de Lucca, publicados por  "La  Chevardèrie", y algunos cuartetos publicados por Venier. Fue bien recibido por el público durante su estancia. El "Mercure de France" escribió acerca del único concierto que fue documentado de este periodo: el concierto espiritual del 20 de marzo de 1768​. 

Conoce a Madame Brillon de Jouay, a quien le dedica sus seis sonatas para violín y piano op.5, publicadas por Venier en febrero de 1769.

Algunas de sus obras compuestas durante su estancia en París fueron: Quartetos  Op.2, dedicados a  Venier; seis sonatas para violín y piano op.5, que dedica a Madame Brillon de Jouay y fueron publicadas por Venier en febrero de 1769. Varios oratorios, 6 sinfonías y cuartetos y 6 duetos. 

Boccherini decide irse a España de manera un tanto precipitada, quizá por haberse enamorado de la cantante Clementina Pelliccia (con la que terminaría casándose), que actuaba como soprano en la compañía de ópera del boloñés Luigi Marescalchi. Boccherini se enroló también en ella, uniéndose al viaje que dicha compañía tenía programado hacia España, a inicios de la primavera de 1768. En el marco de los programas establecidos por Marescalchi, participó en las actuaciones de la Compañía ante la Corte y en otras ciudades, como Valencia. Nada hay que pueda sustentar la tantas veces reiterada justificación para este cambio de planes basada en unas supuestas y nunca materializadas cartas de recomendación del embajador español en París. Fue el amor y no la conveniencia lo que empujó a Boccherini a emprender viaje hacia el sur. 

La versión tradicional de su traslado a España supone que hubo un contacto con el embajador de España en París, Joaquín Anastasio Pignatelli, y este convenció a Boccherini y a Manfredi para que se trasladaran a Madrid bajo la protección del infante Luis Antonio de Borbón y Farnesio, hermano pequeño del rey Carlos III. Lo cierto es que Manfredi permaneció un tiempo en París y Boccherini tardó en ser nombrado músico del Infante, mientras que sus primeras actividades en España estuvieron ligadas a la compañía de ópera de Marescalchi y a otros músicos.

Durante sus primeros años de estancia en España, ejerció como instrumentista en la Compañía de teatros de los Reales sitios (1768-1769).

En 1770, Boccherini es nombrado violoncelista y compositor de la capilla real del infante Luis Antonio. Con este nombramiento comienza la etapa de mayor creación musical del artista. Hacia 1770 empezó a componer música de cámara, cuartetos y quintetos para cuerda, obras con las que ha sido ampliamente relacionado. Todas sus obras compuestas desde su llegada a Madrid (incluidos  sus seis cuartetos  op. 6) y hasta el fallecimiento de Borbón, incluían la inscripción “A H.R.H Don Luis, Infante de España”.

Yves Gérard estima que Boccherini había escrito alrededor de cien obras cuando en 1770 entró formalmente al servicio de Don Luis de Borbón. Antes de esta fecha, había sido básicamente un virtuoso y su producción temprana incluye sobre todo obras para su propio instrumento (violonchelo).

En 1776, el infante Luis Antonio de Borbón contrajo nupcias morganáticas con María Teresa de Vallabriga y fue obligado a retirarse a Arenas de San Pedro en la provincia de Ávila. El infante se estableció primero en el palacio de Velada y después en el palacio de la Mosquera, en la localidad arenense, y llevó consigo a toda su orquesta. A pesar de este aislamiento, Boccherini pudo dar a conocer su música por toda Europa gracias al contacto que tenía con las grandes casas editoriales.

El año 1785 cambia sustancialmente su vida: fallece su esposa Clementina en Arenas de San Pedro, y meses después, el 7 de agosto, su patrón Don Luis. Tras su muerte, Boccherini solicita que no se le retiren los ingresos que recibía de éste, a lo que accede el rey Carlos III, nombrándolo "violón" de la Real Capilla, aunque sin tomar posesión de la plaza en espera de alguna vacante.  

Boccherini regresa a Madrid solo y con seis hijos: Joaquina, Luis Marcos, José Mariano, María Teresa, Mariana e Isabel. Una vez restablecido, consigue dos importantes patronazgos: A través del embajador de Prusia, Boccherini mandó algunos de sus trabajos al rey de Prusia, los cuales le dedicó; y en un periodo corto de tiempo, el compositor recibió una carta del rey. En un decreto de la corte datado del 21 de enero de 1786, es nombrado compositor de la Corte de Federico Guillermo II de Prusia, quien era un violonchelista aficionado y fue su mecenas entre 1786 y 1797; se cree que poco tiempo después dejó España para vivir en Potsdam y Breslau, y tuvo una relación íntima con los miembros de la corte.

En 1786 entra al servicio de María Josefa Pimentel, duquesa de Osuna y Condesa de Benavente (1752–1834) como director de su orquesta y compositor, y a partir de 1787 establece su residencia en la capital.

Hacia  1796 inició su correspondencia con el editor parisino Ignaz Pleyel (1757-1831) y también trabajó para el Marqués de Benavente, guitarrista aficionado.

En 1797, Boccherini se casó en segundas nupcias con María del Pilar Joaquina Porretti, hija del violonchelista y antiguo amigo suyo Domingo Porretti.

En los primeros meses de 1801 trabajó para el embajador francés de España, Lucien Bonaparte (1775-1840), para amenizar las veladas en su residencia oficial, el palacio de San Bernandino. Escribió varias obras que dedicó a Bonaparte, como los seis quintetos para piano en 1799, el 'stabat mater' en 1800 y 12 quintetos para dos violines, dos violas y violonchelo en 1802.

A pesar de permanecer en Madrid la mayor parte de su vida, la mayoría de la obra de Boccherini, incluyendo manuscritos autógrafos y copias, se conserva en Berlín y París. Parte de la explicación se debe a que sus obras estaban destinadas a ser publicadas fuera de España, por lo que sus manuscritos se remitieron a editores ingleses, franceses o alemanes.

Solo se conocen dos impresos con música de Boccherini que fueron producidos por imprentas madrileñas, que fueron sus seis dúos para dos violines (G.56-61) y seis tríos de cuerda dedicados al Príncipe de Asturias (G.89-94).​

El abandono repentino del mecenazgo de María Josefa Pimentel y la muerte de Federico Guillermo II de Prusia en 1797 provocaron que Boccherini fuera decayendo en los últimos años de su vida. Angustiado por las desgracias de la pérdida de sus hijos y de su segunda mujer, y a pesar de la ayuda del embajador francés Luciano Bonaparte, falleció el 28 de mayo de 1805, a los 62 años de edad. Aunque se cree que murió siendo pobre, un reciente estudio de su testamento, realizado por uno de sus descendientes directos, demuestra que no murió rico pero murió con dinero y no en la miseria.

Boccherini fue enterrado en la iglesia de los Santos Justo y Pastor de la calle del Sacramento de Madrid, hoy basílica pontificia de San Miguel. En 1927 Mussolini llevó los restos del compositor a Lucca para ser enterrado en la iglesia de San Francisco, en el panteón de los hijos ilustres de esa ciudad toscana. Sus descendientes siguen viviendo en España.

Aunque su obra ha sido clasificada dentro del estilo galante, según el violinista Carlos Gallifa «su música no tiene nada de frívola, está compuesta de un tono menor, lo que le da gran profundidad». Es un compositor otoñal, nostálgico, influenciado por esos jardines de naturaleza domesticada como fueron Aranjuez o La Granja, de lujo palaciego al estilo francés, donde el racionalismo ilustrado trataba de superar lo que entonces se consideraba caos natural.

A pesar de haber sido un virtuoso, Boccherini lamentablemente no dejó información sobre su técnica en un método para violonchelo. Tampoco generó su propia escuela violonchelística. Algunas de sus composiciones para violonchelo han generado la sospecha de que Boccherini podría haber usado un instrumento de 5 cuerdas, tales como la sonata "'L' Imperatrice." 

Algunos aspectos de la vida y obra boccherianas resultan un tanto conflictivas, sobre todo en la datación cronológica de sus obras. El importante catálogo del musicólogo francés Yves Gérard constituye una de las mejores referencias hasta la fecha.​ El total propuesto por Gérard incluye 26 sonatas para violoncelo y bajo, y de 8 a 9 conciertos para violoncelo y orquesta. Christian Speck descubrió otras sonatas que parecen ser de los años más tempranos del compositor, conservadas en los archivos del monasterio de Seitensetten, Austria. Sin embargo, se dice que a pesar de que el compositor mantuvo un catálogo de todas sus obras a lo largo de su vida como compositor, nunca incluyó las dedicadas al violoncelo y que eran de carácter virtuoso.

Alfredo Boccherini, descendiente de Luigi, publicó en 1879 algunos apuntes biográficos del compositor y un importante catálogo de sus obras, solo superado por el publicado por Yves Gérard en 1965. De no haber sido por esto, la obra de Boccherini estaría hoy en día prácticamente desaparecida. Gracias a esto, en la actualidad se sabe que Luigi Boccherini dio un impulso importante a la música de cámara, dejando, entre otras:

Los divertimentos  op. 16 


Es la primera obra de Boccherini compuesta en España, que incluye el contrabajo.  Numerados  en el texto de Gérard como G 461-6. Corresponde al periodo en el que estuvo al servicio del infante Don Luis. La edición de estas obras estuvo a cargo del musicólogo italiano Aldo  Pais. Se trata de seis obras para "due  Violini, Flauto obbligato, Viola, due  Violoncelli  e Basso de  Ripieno". Nombrada en el mismo manuscrito como su "Opera Prima".

Se custodian 14 obras manuscritas de L. Boccherini:  

La serie incompleta  de  cuartetos G.183-188 (no se cuenta con el quinto, G.187). 

Las sinfonías G.509-514. 

Trío para dos violines y bajo G.77 fechado en 1760 por el propio Boccherini. El manuscrito podría ser anterior a su llegada a España. En fuentes del  siglo XVIII esta obra es considerada la primera de una serie de tríos numerados como opus 1.

Transcripción de la sonata para pianoforte y violín op. 5 no. 2, G.26. 

De las obras anteriores se  conserva únicamente las "particellas ", a excepción de la sinfonía G.510. 

Eusebio Ruiz, nacido en 1828, fue un profesor de música, Doctor en Jurisprudencia y fue bibliotecario de la Escuela Nacional de Música durante los años de 1872-1878, encargado del arreglo y clasificación. Además de esto, fue coleccionista de música del siglo XVIII para instrumentos de arco, formando una biblioteca privada que posteriormente donó a la institución.

Pertenecieron a esta colección la serie de cuartetos manuscritos (G.183-188) y probablemente las sinfonías (G.509-514); los cuartetos fueron compuestos por Boccherini en 1775, estando al servicio del Infante Don Luis de Borbón.

Su contribución a la historia de la música es muy importante, ya que fue el mentor del quinteto de cuerdas, en su caso con doble violonchelo (se supone que él ejecutaba el primero de ellos, agregándose a la formación de cuarteto tradicional). Esta forma fue utilizada posteriormente y contemporáneamente por Mozart.

El lenguaje de Boccherini se caracterizó por la refinada técnica de cuerdas, principalmente en el violonchelo, pidiendo posiciones extremas (muy agudas para el instrumento), armónicos y hasta golpes de caja, elementos que se reivindicaron posteriormente en el siglo XX, aunque en un contexto musical totalmente diferente. El manejo de la textura fue su gran aporte, mediante el contrapunto temático utilizado de una manera sublime. Estas texturas llegaron a funcionar, en sus Quintetos de Cuerdas y Guitarra, como moldes donde se insertaba la melodía y la armonía, dando la impresión, a la vista de la partitura, de «dibujos» que cambiaban cada un número relativo de compases. Además, tuvo incursiones tempranas en la música programática, como se puede apreciar en la "Musica notturna delle strade di Madrid", o bien en el Quinteto Op. 11, "La Uccelliera", donde se representa el canto de las aves.







</doc>
<doc id="1732" url="https://es.wikipedia.org/wiki?curid=1732" title="Links">
Links

Links es un navegador web de código abierto en modo texto —y gráfico a partir de su versión 2 en modo terminal—.

El proyecto original era crear un navegador web similar a Lynx pero con más características. 

Mikuláš Patočka, poliéster , explicó que prefirió ignorar a Lynx y desarrollar un navegador aparte porque, debido a la forma en que fue desarrollado, Lynx está imposibilitado para realizar conexiones múltiples —esto impediría la capacidad de Links de descargar archivos al mismo tiempo que se navega por Internet. 

A diferencia de Lynx, Links tiene soporte para tablas y frames en HTML, y permite el scroll horizontal. Además, es compatible con terminales a color y monocromos e incluye un sistema de menús desplegables.

Desde la versión 0.98 no se agregan nuevas características a este navegador. Las versiones posteriores son liberadas sólo para corregir errores. 

En el año 2000 Mikuláš Patočka se une a Karel Kulhavý, Petr Kulhavý y Martin Pergel, compañeros en la Universidad Charles en Praga, y forman Twibright Labs. Juntos continúan el desarrollo de Links, agregando soporte para formatos gráficos de imágenes, antialiasing del texto y Javascript. 

El modo gráfico funciona incluso en sistemas UNIX sin X Window o cualquier otro gestor de ventanas, usando SVGALib o el framebuffer de la unidad de procesamiento de gráficos del sistema. 




</doc>
<doc id="1737" url="https://es.wikipedia.org/wiki?curid=1737" title="Leonardo Torres Quevedo">
Leonardo Torres Quevedo

Leonardo Torres Quevedo (Santa Cruz de Iguña, Molledo, Cantabria, 28 de diciembre de 1852–Madrid, 18 de diciembre de 1936) fue un ingeniero de caminos, matemático e inventor español de finales del y principios del . 

Prolífico innovador y genio de la mecánica de su tiempo. Gozó en vida de un gran prestigio técnico y científico, gracias a sus patentes internacionales en multitud de áreas, como los transbordadores, los dirigibles o el radiocontrol. Su labor en el campo de la Automática, verdaderamente pionero, alcanzó resonancia internacional: sus aparatos son citados como precursores de la cibernética, del cálculo analógico y de la informática.

Nació el 28 de diciembre de 1852, en Santa Cruz de Iguña, en Molledo, Cantabria. Su padre, Luis Torres Vildósola y Urquijo, era ingeniero de caminos en Bilbao, donde ejercía de ingeniero de ferrocarriles. La familia residía normalmente allí, aunque también pasaban largas temporadas en el solar materno en La Montaña cántabra, sobre todo cuando el padre dirigió la construcción del puente del ferrocarril de Santander a Alar del Rey. Su madre fue Valentina de Quevedo y Maza y sus abuelos maternos, José Manuel de Quevedo y Apolinaria de la Maza y Escalera. Los abuelos paternos fueron José Luis Torres Vildósola y Cayetana María de Urquijo, a pesar de lo afirmado por algunos de sus biógrafos, ya que aparece reflejado en la partida de bautismo.
Durante su infancia, pasó largas temporadas separado de sus padres debido a los viajes de trabajo. Por ello, fue cuidado por las señoritas de Barrenechea, parientes de su padre, que lo declararon heredero de sus bienes, lo que le facilitó su independencia futura.

Estudió el bachillerato en el Instituto de Enseñanza Media de Bilbao y más tarde fue a París, al Colegio de los Hermanos de la Doctrina Cristiana, a completar estudios durante dos años (1868 y 1869). Por traslado del padre, se instaló la familia en Madrid en 1870 y al año siguiente inició sus estudios superiores en la Escuela Oficial del Cuerpo de Ingenieros de Caminos. Suspendió temporalmente sus estudios en 1873 para acudir como voluntario a la defensa de Bilbao, que había sido sitiada por las tropas carlistas durante la Tercera Guerra Carlista. Una vez se levantó el sitio de Bilbao, el 2 de mayo de 1874, volvió junto a su hermano a Madrid, donde finalizó sus estudios en 1876, siendo el cuarto de su promoción.

Comenzó a ejercer su carrera en la misma empresa de ferrocarriles en la que trabajaba su padre, pero emprendió enseguida un largo viaje por Europa para conocer de primera mano los avances científicos y técnicos, sobre todo en la incipiente área de la electricidad. De regreso a España, se instaló en Santander, donde él mismo sufragó sus trabajos e inició una actividad de estudio e investigación que no abandonaría. Fruto de las investigaciones en estos años, aparecería su primer trabajo científico en 1893. El 16 de abril de 1885 contrajo matrimonio en Portolín con Luz Polanco y Navarro, con quien tuvo ocho hijos (Leonardo y Julia, que murieron jóvenes, Luz, Valentina, Luisa, Gonzalo, Leonardo y Fernando). Trabajó en sus primeros transbordadores en 1887, y los presentó en 1890 en Suiza, aunque no fueron aceptados.

En 1889, se instaló en Madrid, participando de su vida social, literaria y científica. Presenta su "Memoria sobre las máquinas algébricas" a la Real Academia de Ciencias Exactas, Físicas y Naturales. En 1895, presenta la memoria "Sur les machines algébriques" en un congreso en Burdeos, y en 1900, "Machines a calculer" en la Academia de Ciencias de París.

De las labores que en estos años llevaba a cabo el Ateneo se creará en 1901 el Laboratorio de Mecánica Aplicada, más tarde de Automática, del que fue nombrado director; el laboratorio se dedicó a la fabricación de instrumentación científica. Ese mismo año ingresó en la Real Academia de Ciencias Exactas, Físicas y Naturales de Madrid, con discurso sobre máquinas algebraicas. Años más tarde, acabaría siendo presidente de esta Real Academia, en 1910. Entre los trabajos del laboratorio caben destacar el magnetógrafo de Gonzalo Brañas, el espectrógrafo de rayos X de Cabrera y Costa, y el micrótomo y panmicrótomo de Santiago Ramón y Cajal.

En 1902 presenta una memoria con anteproyecto de globo dirigible a las Academias de Ciencias de Madrid y París, y en 1903, la patente del telekino. En 1910 viaja a Argentina con la infanta Isabel para proponer, en el Congreso Internacional Americano, la constitución de la Unión Hispanoamericana de Biografía y Tecnología Científicas. Aliadófilo, sus diseños patentados de dirigibles fueron usados por ingleses y franceses contra los zepelines en la I Guerra Mundial. En 1926 apareció el primer fascículo de un "Diccionario Tecnológico Hispano-Americano". En 1912, creó su primer autómata ajedrecista y en 1914, los "Ensayos sobre automática".

En 1916 se inaugura su transbordador sobre el río Niágara y el rey Alfonso XIII le impone la Medalla Echegaray; en 1918 rechaza el cargo de ministro de Fomento que le ofrece el marqués de Alhucemas. En 1920 ingresa en la Real Academia Española, en el sillón que había ocupado Benito Pérez Galdós, y pasa a ser miembro de la sección de Mecánica de la Academia de Ciencias de París. Fue también elegido presidente de la Sociedad Matemática Española, cargo que ocupó hasta 1924. Además, en ese año creó su segundo autómata ajedrecista. En 1922, La Sorbona le nombra doctor "honoris causa", y en 1927 se le nombra uno de los doce miembros asociados de la Academia de Ciencias de París.

Fue un decidido partidario del idioma internacional esperanto, que apoyó, entre otros lugares, en el Comité de Cooperación Cultural de la Sociedad de Naciones. Murió en su casa de la calle de Válgame Dios, en Madrid, en el inicio de la Guerra Civil el 18 de diciembre de 1936, cuando le faltaban 10 días para cumplir 84 años.

En 1902, Leonardo Torres Quevedo presentó en las Academias de Ciencias de España y París el proyecto de un nuevo tipo de dirigible que solucionaba el grave problema de suspensión de la barquilla al incluir un armazón interior de cables flexibles que dotaban de rigidez al dirigible por efecto de la presión interior. Este trabajo mereció un informe muy favorable tanto por parte de José Echegaray como por Paul Émile Appell. 

En 1904, es nombrado director del Centro de Ensayos de Aeronáutica,
""destinado al estudio técnico y experimental del problema de la navegación aérea y de la dirección de la maniobra de motores a distancia"".

En 1905, con ayuda del capitán Alfredo Kindelán, Torres Quevedo dirige la construcción del primer dirigible español en el Servicio de Aerostación Militar del Ejército situado en Guadalajara. En 1909 finalizan con gran éxito, y el nuevo dirigible, el "España", realiza numerosos vuelos de exposición y prueba. Quizá la innovación más importante en este dirigible fue la de hacer el globo trilobulado, de modo que aumentaba la seguridad.
A raíz de este hecho empieza la colaboración entre Torres Quevedo y la empresa francesa Astra, que llegó a comprarle la patente con una cesión de derechos extendida a todos los países, excepto a España, para posibilitar la construcción del dirigible en el país. Así, en 1911, se inicia la fabricación de los dirigibles conocidos como "Astra-Torres". Algunos ejemplares fueron adquiridos por los ejércitos francés e inglés a partir de 1913, y utilizados durante la I Guerra Mundial, en muy diversas tareas, fundamentalmente de protección e inspección naval.

En 1918, Torres Quevedo diseñó, en colaboración con el ingeniero Emilio Herrera Linares, un dirigible trasatlántico, al que llamaron "Hispania", que llegó a alcanzar el estado de patente, con objeto de realizar desde España la primera travesía aérea del Atlántico. Por problemas de financiación el proyecto se fue retrasando y fueron los británicos John William Alcock y Arthur Whitten Brown los que atravesaron el Atlántico sin escalas desde Terranova hasta Irlanda en un bimotor biplano Vickers Vimy en 16 horas y 13 minutos.

En la actualidad, los dirigibles que se siguen construyendo heredan concepciones del sistema trilobular patentado por Torres Quevedo.

La experimentación de Torres Quevedo en el área de transbordadores, funiculares o teleféricos comenzó muy pronto durante su residencia en su pueblo natal, Molledo. Allí, en 1887, construyó en su casa el primer transbordador, al que llamó "transbordador de Portolín", para salvar un desnivel de unos 40 metros: de unos 200 metros de longitud y tracción animal, una pareja de vacas y una silla a modo de barquilla. Este experimento fue la base para la solicitud de su primera patente, que solicitaría ese mismo año, el 17 de septiembre: un funicular aéreo de múltiples cables, con el que lograba un coeficiente de seguridad apto para el transporte de personas y no solo de cosas. Posteriormente construyó el denominado "transbordador del río León", de mayor envergadura, ya con motor, pero que siguió siendo utilizado exclusivamente para transporte de materiales, no de personas.

Entre 1887 y 1889, solicitó el privilegio de la patente en otros países como Alemania, Francia, Reino Unido o Suiza. En 1890 presentó su transbordador en Suiza, país muy interesado en ese transporte debido a su orografía y que ya venía utilizando funiculares para el transporte de bultos, pero su proyecto fue rechazado, permitiéndose la prensa suiza ciertos comentarios irónicos. Este fue el primer estudio que se realizó para la construcción de un teleférico de montaña en el mundo, en la línea Klimsenhorn-Pilatus Kulm. Tras dicho fracaso, decidió dedicarse a las máquinas algebraicas y en 1903 retomó sus proyectos, ya que el 15 de febrero de 1904 caducaba la patente. Preparó varios proyectos en San Sebastián y Zaragoza, y en 1907 construyó el primer transbordador apto para el transporte público de personas, en el Monte Ulía en San Sebastián. El problema de la seguridad se había solucionado mediante un ingenioso sistema múltiple de cables-soporte, liberando los anclajes de un extremo que sustituye por contrapesos. El diseño resultante era de gran robustez y resistía perfectamente la ruptura de uno de los cables de soporte. La ejecución del proyecto corrió a cargo de la Sociedad de Estudios y Obras de Ingeniería de Bilbao, que construyó con éxito otros transbordadores en Chamonix, Bolzano, Grindelwald, Río de Janeiro y otros lugares.

Pero es sin duda el Spanish Aerocar en las cataratas del Niágara, en Canadá, el que le ha dado la mayor fama en esta área de actividad, aunque desde un punto de vista científico no sea la más importante. El transbordador de 550 metros de luz es un funicular aéreo casi horizontal (la diferencia de cota entre los dos extremos es de un metro) que une dos puntos diferentes de la orilla canadiense en un recodo del río Niágara conocido como "El Remolino" ("The Whirpool"). Se desplaza a unos 7.2 km/h (120m/min). La carga por cable vía es de nueve toneladas, con un coeficiente de seguridad de los cables de 4.6. Se construyó entre 1914 y 1916 , siendo un proyecto español de principio a final: ideado por un español, construido por una empresa española con capital español (The Niagara Spanish Aerocar Co. Limited); una placa de bronce, situada sobre un monolito a la entrada de la estación de acceso, recuerda este hecho: «"Transbordador aéreo español del Niágara. Leonardo Torres Quevedo (1852–1936)"». Se inauguró en pruebas el 15 de febrero de 1916 y se inauguró oficialmente el 8 de agosto de 1916, abriéndose al público al día siguiente; el transbordador, con pequeñas modificaciones, sigue en activo hoy día, sin ningún accidente digno de mención en un siglo de servicio, constituyendo un atractivo turístico y cinematográfico de gran popularidad.

En 1903, Torres Quevedo presentó el "Telekino" en la Academia de Ciencias de París, acompañado de una memoria y haciendo una demostración experimental. En ese mismo año obtuvo la patente en Francia, España, Gran Bretaña y Estados Unidos.

El "telekino" consistía en un autómata que ejecutaba órdenes transmitidas mediante ondas hertzianas. Con el telekino, Torres Quevedo estableció los principios operacionales del moderno sistema de control remoto inalámbrico y fue un pionero en el campo del mando a distancia.

En marzo de 1905 ensayó las primeras pruebas del telekino, manejando el primer vehículo terrestre del mundo en el frontón Beti Jai de Madrid.

En 7 de noviembre de 1906, en presencia de Alfonso XIII y ante una gran multitud, demostró con éxito el invento en el puerto de Bilbao al guiar un bote desde la orilla; más tarde intentaría aplicar el "telekino" a proyectiles y torpedos, pero tuvo que abandonar el proyecto por falta de financiación.

En el año 2006, el telekino fue reconocido por la IEEE como «milestone», un ‘hito’ para la historia de la ingeniería a escala mundial.

Las máquinas analógicas de cálculo buscan la solución de ecuaciones matemáticas mediante su traslado a fenómenos físicos. Los números se representan por magnitudes físicas, que pueden ser rotaciones de determinados ejes, potenciales, estados eléctricos o electromagnéticos, etcétera.

Un proceso matemático se transforma, en estas máquinas, en un proceso operativo de ciertas magnitudes físicas que conduce a un resultado físico que se corresponde con la solución matemática buscada. El problema matemático se resuelve pues mediante un modelo físico del mismo. Desde mediados del se conocían diversos artilugios de índole mecánica, como integradores, multiplicadores, etcétera, por no hablar de la máquina analítica de Charles Babbage; en esta tradición se enmarca la obra de Torres Quevedo en esta materia, que se inicia en 1893 con la presentación en la Academia de Ciencias Exactas, Físicas y Naturales de la "Memoria sobre las máquinas algebraicas". En su tiempo, esto fue considerado como un suceso extraordinario en el curso de la producción científica española.

En 1895, presenta la Memoria "Sur les machines algébraiques" en un Congreso en Burdeosde la "Asociation pour l’Avancement des Sciences". Posteriormente, en 1900, presentará la Memoria "Machines á calculer", en la Academia de Ciencias de Francia.

En el terreno práctico, Torres Quevedo construyó toda una serie de máquinas analógicas de cálculo, todas ellas de tipo mecánico. Una de ellas es "El Ajedrecista", presentado en la feria de París de 1914 y considerado el primer videojuego de la historia. En estas máquinas existen ciertos elementos, denominados "aritmóforos", que están constituidos por un móvil y un índice que permite leer la cantidad representada para cada posición del mismo. El móvil es un disco o un tambor graduado que gira en torno a su eje. Los desplazamientos angulares son proporcionales a los logaritmos de las magnitudes a representar.

Utilizando una diversidad de elementos de este tipo, pone a punto una máquina para resolver ecuaciones algebraicas: resolución de una ecuación de ocho términos, obteniendo sus raíces, incluso las complejas, con una precisión de milésimas. Un componente de dicha máquina era el denominado «husillo sin fin», de gran complejidad mecánica, que permitía expresar mecánicamente la relación "y=log(10^x+1)", con el objetivo de obtener el logaritmo de una suma como suma de logaritmos. Como se trataba de una máquina analógica, la variable puede recorrer cualquier valor (no sólo valores discretos prefijados). Ante una ecuación polinómica, al girar todas las ruedas representativas de la incógnita, el resultado final va dando los valores de la suma de los términos variables, cuando esta suma coincida con el valor del segundo miembro, la rueda de la incógnita marca una raíz.

Con propósitos de demostración, Torres Quevedo también construyó una máquina para resolver una ecuación de segundo grado con coeficientes complejos, y un integrador. En la actualidad, la máquina Torres Quevedo se conserva en el museo de la ETS de Ingenieros de Caminos de la Universidad Politécnica de Madrid.

En sus "Ensayos sobre automática"publicados por primera vez en 1914, Torres Quevedo formula lo que será en adelante una nueva rama de la ingeniería, la automática.

Con el desarrollo del Telekino, Torres Quevedo llegó a la conclusión de que con él no sólo había fabricado el primer control remoto de la historia, sino que esta máquina, era en sí un autómata, es decir, una máquina que podía funcionar de forma autónoma ejecutando acciones respondiendo a órdenes y en función de ciertas circunstancias de su entorno.

Es esta nueva teoría es la que aplicó en la creación de su Ajedrecista.

Partiendo de esta conclusión, Torres explotó las posibilidades que le brindaba esta nueva rama de la teoría de las máquinas y la aplicó al desarrollo de máquinas de cálculo. Gracias a ello, pudo salvar las numerosas dificultades que hasta entonces había planteado la creación de estas máquinas por métodos exclusivamente mecánicos, y donde Charles Babbage había fracasado, no por falta de medios o talento, él logró resultados satisfactorios.

En estos Ensayos sobre automática, Torres desarrolla la teoría de lo que posteriormente será su aritmómetro: una máquina electromecánica capaz de realizar cálculos de forma autónoma con un dispositivo de entrada de comandos (una máquina de escribir), una unidad de procesamiento y registros de valores (un sistema de listones, poleas, agujas, escobillas, electroimanes y conmutadores), y un dispositivo de salida (de nuevo una máquina de escribir). Es en definitiva lo que «debería consagrar internacionalmente a nuestro ingeniero como el inventor del primer ordenador en el sentido actual de la historia».

Ya en este texto, Torres Quevedo describe no sólo la idea de una máquina de funcionamiento secuencial para realizar los cálculos, sino la aritmética en coma flotante, gracias a la cual se pueden manejar en los cálculos números muy grandes, en lo que constituye la primera aparición de la idea de la aritmética en coma flotante de la historia.

Con la obra mencionada, Leonardo Torres Quevedo sienta las bases de lo que más adelante se daría en llamar inteligencia artificial y describe cómo las máquinas pueden ser construidas para desempeñar más tareas que únicamente aquellas para las que no es necesario 'pensar'.

En una entrevista a Torres Quevedo realizada por la revista Scientific American en 1915, Torres Quevedo afirma que al menos en teoría casi todas las operaciones de una vasta gama podrían ser realizadas por una máquina, incluso aquellas de las que se supone que precisan la intervención de una considerable capacidad intelectual.

El texto de "Ensayos sobre automática" por otra parte se adelanta a la formulación del experimento de la 'habitación china' de John Searle. La afirmación de Descartes de que un autómata jamás sería capaz de mantener un diálogo razonable, nunca mencionada por Alan Turing, es ya discutida por Torres Quevedo al afirmar que:

Con todo ello, Torres Quevedo se adelanta varias décadas a los teóricos de las Ciencias de la Computación del como Alan Turing o Konrad Zuse entre otros.

En los últimos años de su vida Torres Quevedo dirigió su atención al campo de la pedagogía, a investigar aquellos elementos o máquinas que podrían ayudar a los educadores en su tarea. Patentes sobre las máquinas de escribir (patentes n.º 80121, 82369, 86155 y 87428), paginación marginal de los manuales (patentes n.º 99176 y 99177) y las del puntero proyectable (patente n.º 116770)
y el proyector didáctico (patente n.º 117853).

El puntero proyectable, también conocido como "puntero láser" se basa en la sombra producida por un cuerpo opaco que se mueve cerca de la placa proyectada, esta sombra es la que utilizaría como puntero. Para ello diseñó un sistema articulado que permitía desplazar, a voluntad del ponente, un punto o puntos al lado de la placa de proyección, lo que permitía señalar las zonas de interés en la transparencia. Torres Quevedo expresa así la necesidad de este invento: "«Bien conocidas son las dificultades con las que tropieza un profesor para ilustrar su discurso, valiéndose de proyecciones luminosas. Necesita colocarse frente a la pantalla cuidando de no ocultar la figura proyectada para llamar la atención de sus alumnos sobre los detalles que más les interesan y enseñárselos con un puntero»".

También construyó un proyector didáctico que mejoraba la forma en la que las diapositivas se colocaban sobre las placas de vidrio para proyectarlas.







</doc>
<doc id="1742" url="https://es.wikipedia.org/wiki?curid=1742" title="Mitos de Cthulhu">
Mitos de Cthulhu

Los Mitos de Cthulhu constituyen un ciclo literario de horror cósmico comprendido entre 1921 y 1935 por el escritor estadounidense Howard Phillips Lovecraft y complementado por otros escritores pertenecientes al Círculo de Lovecraft. Aunque muy vinculado a la ciencia ficción, el género onírico y la fantasía pura, en rigor los Mitos de Cthulhu pertenecen a la tradición del cuento de terror anglosajón. 

En él se renueva el desgastado horror gótico de fantasmas y seres inmateriales en un terror realista, de seres monstruosos y desconocidos que se esconden en los parajes más oscuros de la Tierra, el tiempo y el espacio. Influido por Arthur Machen y Lord Dunsany, los Mitos exploran a ciegas la perspectiva de que bajo el mundo cotidiano y conocido se esconde una realidad prodigiosa y aterradora que acecha a la humanidad desde las tinieblas y sume en el pánico o la locura a quien osa atisbar los abismos de aquella inaprensible dimensión.

Pese a las diferencias en los relatos, su principio fundamental fue establecido por el propio Lovecraft:

Precedida por destacados escritores (Lord Dunsany, Ambrose Bierce, R. W. Chambers, Arthur Machen y Algernon Blackwood) y enriquecida por diversos autores (Frank Belknap Long, Robert E. Howard, Clark Ashton Smith, Hazel Heald, Henry Kuttner, Robert Bloch, August Derleth, Ramsey Campbell, Brian Lumley) corresponde no obstante a Howard Phillips Lovecraft el protagonismo en la creación de los Mitos. A continuación se nombran, según Derleth, los trece relatos de Lovecraft pertenecientes a este ciclo literario ordenados de acuerdo a su fecha de creación:


Si bien estos relatos son considerados canónicos, hay numerosos escritos de la segunda época de Lovecraft (la realista), que también pueden considerarse parte de los Mitos, entre ellos:


Además Lovecraft compuso poemas relativos a los Mitos, que fueron recopilados póstumamente en "Hongos de Yuggoth" (1941).

El universo lovecraftiano se conoce únicamente a través de testimonios incompletos y aislados, cuyas descripciones están repletas de insinuaciones veladas y lagunas en blanco. Los monstruosos seres recibieron numerosas descripciones y nombres de la tradición oral de las comunidades rurales, hasta apariciones del mismo ente o dos seres independientes (o, como la siempre sugerida opción, sería el producto del imaginario colectivo sumado a la locura del protagonista). Como resultado, los Mitos no fueron sistematizados y la identidad y relaciones de los alienígenas permanecieron en un confuso e impenetrable misterio. 

Fue principalmente August Derleth, discípulo y corresponsal de Lovecraft, quien trató de clasificar a todos los seres que lo poblaban. A diferencia de Lovecraft, en quien predominaba lo ambiguo y una visión del cosmos descentralizada de las esperanzas y valores humanos, Derleth interpretó los fines de aquellos seres desde la perspectiva de la eterna lucha del bien y el mal. Él creó a los Dioses arquetípicos, y según su clasificación y sistematización de los Mitos, fue por la batalla contra estos por lo que Azathoth fue privado de inteligencia, al encabezar la rebelión contra ellos. Trató de representar el concepto judeocristiano de la lucha Dios-Diablo y la caída de Luzbel. Muchos aficionados de los mitos desprecian esta clasificación por considerar que priva de parte del horror intrínseco de los relatos de Lovecraft y es totalmente innecesaria, ya que éste jamás quiso algo semejante en su obra.

Los seres que integran los mitos se separan principalmente en tres tipos: Primigenios, Dioses arquetípicos y las llamadas razas menores. A pesar de ser el ser más conocido de las historias, y el más venerado, Cthulhu no es el ser más poderoso de los muchos que hay.

Los mitos suelen centrarse en los primigenios. Estos son seres extraterrestres, inmortales y de gran poder. La mayor parte duermen o están atrapados. Aunque hay algunos en la tierra, hay cientos (si no miles), repartidos a través del universo.

Los Dioses Exteriores son menos comunes en las historias, aunque algunos son comúnmente mencionados, especialmente Shub-Niggurath; su poder es infinito e inimaginable, y su existencia trasciende el tiempo y el espacio.

Las razas menores son seres mucho más comunes, que existen en todo el universo, hay una infinita variedad de estos, tan solo en la tierra pueden encontrarse docenas de razas ocultas al humano. Algunas son servidoras de algún primigenio o dios exterior y los veneran, pero muchas otras no son fieles a ninguno de estos tipos superiores de seres.

El mundo de los llamados Mitos de Cthulhu que engloba a estos y a las llamadas tierras de Lovecraft (triángulo imaginario creado por Lovecraft situado en Nueva Inglaterra, constituido por los pueblos ficticios de Arkham, Innsmouth y Dunwich) ha sido objeto de varias adaptaciones.

Algunas de sus invenciones han contribuido a la popularidad de los mitos:


Durante los años 1970, coincidiendo con el auge de las revistas de terror, los mitos se reflejarían en la obra de insignes historietistas. Josep María Beà, por ejemplo, recurrirá a ellos en "Sir Leo" (1971), además de iniciar un bestiario a partir de textos de Josep Lórman para la New English Library, que sólo vería la luz fragmentariamente al no encontrar editor.

La más destacada de estas obras es "Los mitos de Cthulhu" realizada por el guionista Norberto Buscaglia y el dibujante Alberto Breccia a partir de 1973 para la revista italiana "Il Mago". 

A principios de los ochenta se produjo el juego de rol llamado "La llamada de Cthulhu", publicado por la editorial Chaosium. En él se da cabida a todos los elementos constituyentes de la mitología y obras tanto de Lovecraft como de sus colaboradores. Estos elementos son los seres o criaturas de los Mitos, personajes investigadores que intentan frustrar los planes de los malvados cultistas o seguidores de las citadas criaturas y numerosos artefactos mágicos, libros de hechizos y lugares ambientados en las Tierras de Lovecraft y otras partes del mundo. La misma editorial, Chaosium, publica además del juego de rol un juego de cartas coleccionables versado sobre los mitos de Cthulhu y titulado "Mythos".

Con motivo del 30 aniversario de su aparición, la editorial Edge Entertainment, propietaria de los derechos en España, publica en noviembre de 2011 una edición especial de aniversario, que se corresponde con la sexta edición (inédita aún en España) de Chaosium, aunque incorporando contenido adicional. Asimismo, sale a la luz una antología conmemorativa titulada "Los nuevos Mitos de Cthulhu", ideada y coordinada por el escritor de género fantástico Rubén Serrano, y que cuenta con la participación de numerosos autores de Nocte, la Asociación Española de Escritores de Terror. 

El juego de video "Alone in the Dark", de 1992, tiene una influencia lovecraftiana, pero la empresa desarrolladora Infogrames no tenía los derechos para la adaptación completa, hasta que un año después pudieron adquirir los derechos del juego de rol mencionado a Chaosium y entregar "Shadow of the Comet" con un mayor manejo de elementos de Lovecraft, específicamente de sus historias "The Shadow Over Insmouth" y "The Color Out of Space". También se han creado varias películas basadas en algunos cuentos. Además se han adaptado los relatos en el formato de historietas, además de inspirar la creación de historias originales; por ejemplo, "El joven Lovecraft", un webcómic creado desde 2006, relata en tono humorístico los supuestos años de infancia de Lovecraft.

En el ámbito musical, varias bandas han creado composiciones inspiradas en esta obra. Algunos ejemplos son: Metallica, con el instrumental "The Call of Ktulu" (del álbum "Ride The Lightning"), "The Thing That Should Not Be” (del álbum '"Master of Puppets") y más recientemente con el tema "Dream No More" (del álbum "Hardwired... to Self-Destruct"; Mercyful Fate con "Ktulu (The Mad Arab Part II)" ("Into the Unknown"); Cradle of Filth con "Cthulhu Dawn" ("Midian"); Nox Arcana ("Necronomicon");The Vision Bleak con "Kutulu!"; el grupo español Ktulu, de death metal; el DJ y productor Deadmau5 con las canciones "Cthulhu sleeps" y "Cthulhu dreams"; Deicide, con “Dead by Dawn”: Hace referencia al Necronomicon; Iron Maiden con "Live After Death": La tapa del álbum muestra una lápida con la frase "“That is not dead which can eternal lie/And with strange aeons even death may die”"; Tiamat en el disco de Sumerian Cry y The Astral Sleep con canciones como “Sumerian Cry (part 3)” donde se menciona “Arab’s wise words” y “the Ancient Ones”.

El libro "La llave del Abismo" de José Carlos Somoza rinde homenaje a esta serie.


</doc>
<doc id="1746" url="https://es.wikipedia.org/wiki?curid=1746" title="LaTeX">
LaTeX

formula_1 (escrito LaTeX en texto plano) es un sistema de composición de textos, orientado a la creación de documentos escritos que presenten una alta calidad tipográfica. Por sus características y posibilidades, es usado de forma especialmente intensa en la generación de artículos y libros científicos que incluyen, entre otros elementos, expresiones matemáticas.

LaTeX está formado por un gran conjunto de macros de TeX, escrito por Leslie Lamport en 1984, con la intención de facilitar el uso del lenguaje de composición tipográfica, formula_2, creado por Donald Knuth. Es muy utilizado para la composición de artículos académicos, tesis y libros técnicos, dado que la calidad tipográfica de los documentos realizados en LaTeX, se considera adecuada a las necesidades de una editorial científica de primera línea, muchas de las cuales ya lo emplean.

LaTeX es software libre bajo licencia LPPL.

LaTeX es un sistema de composición de textos que está formado mayoritariamente por órdenes construidas a partir de comandos de TeX —un lenguaje «de nivel bajo», en el sentido de que sus acciones últimas son muy elementales— pero con la ventaja añadida de «poder aumentar las capacidades de LaTeX utilizando comandos propios del TeX descritos en "The TeXbook"». Esto es lo que convierte a LaTeX en una herramienta práctica y útil pues, a su facilidad de uso, se une toda la potencia de TeX. Estas características hicieron que LaTeX se extendiese rápidamente entre un amplio sector científico y técnico, hasta el punto de convertirse en uso obligado en comunicaciones y congresos, y requerido por determinadas revistas a la hora de entregar artículos académicos.

Su código abierto permitió que muchos usuarios realizasen nuevas utilidades que extendiesen sus capacidades con objetivos muy variados, a veces ajenos a la intención con la que fue creado: aparecieron diferentes "dialectos" de LaTeX que, a veces, eran incompatibles entre sí. Para atajar este problema, en 1989 Lamport y otros desarrolladores iniciaron el llamado «Proyecto LaTeX3». En el otoño boreal de 1993 se anunció una reestandarización completa de LaTeX, mediante una nueva versión que incluía la mayor parte de estas extensiones adicionales (como la opción para escribir transparencias o la simbología de la American Mathematical Society) con el objetivo de dar uniformidad al conjunto y evitar la fragmentación entre versiones incompatibles de LaTeX 2.09. Esta tarea la realizaron Frank Mittlebach, Johannes Braams, Chris Rowley y Sebastian Rahtz junto al propio Leslie Lamport. Hasta alcanzar el objetivo final del «Proyecto 3», a las distintas versiones se las viene denominando formula_3 (o sea, «versión 2 y un poco más...»). Actualmente cada año se ofrece una nueva versión, aunque las diferencias entre una y otra suelen ser muy pequeñas y siempre bien documentadas.

Con todo, además de todas las nuevas extensiones, la característica más relevante de este esfuerzo de re-estandarización fue la "arquitectura modular": se estableció un núcleo central (el "compilador") que mantiene las funcionalidades de la versión anterior pero permite incrementar su potencia y versatilidad por medio de diferentes "paquetes" que solo se cargan si son necesarios. De ese modo, LaTeX dispone ahora de innumerables paquetes para todo tipo de objetivos, muchos dentro de la distribución oficial, y otros realizados por terceros, en algunos casos para usos especializados.

LaTeX presupone una filosofía de trabajo diferente a la de los procesadores de texto habituales (conocidos como WYSIWYG, es decir, «lo que ves es lo que obtienes») y se basa en instrucciones. Tradicionalmente, este aspecto se ha considerado una desventaja (probablemente la única). Sin embargo, LaTeX, a diferencia de los procesadores de texto de tipo WYSIWYG, permite a quien escribe un documento centrarse exclusivamente en el contenido, sin tener que preocuparse de los detalles del formato. Además de sus capacidades gráficas para representar ecuaciones, fórmulas complicadas, notación científica e incluso musical, permite estructurar fácilmente el documento (con capítulos, secciones, notas, bibliografía, índices analíticos, etc.), lo cual brinda comodidad y lo hace útil para artículos académicos y libros técnicos.

Con LaTeX, la elaboración del documento requiere normalmente de dos etapas: en la primera hay que crear mediante cualquier editor de texto llano un "archivo o fichero fuente" que, con las órdenes y comandos adecuados, contenga el texto que queramos imprimir. La segunda etapa consiste en procesar este archivo; el "procesador de textos" interpreta las órdenes escritas en él y "compila" el documento, dejándolo preparado para que pueda ser enviado a la salida correspondiente, ya sea la pantalla o la impresora. Si se quiere añadir o cambiar algo en el documento, se deberán hacer los cambios en el archivo fuente y procesarlo de nuevo. Esta idea, que puede parecer poco práctica "a priori", es conocida a los que están familiarizados con el proceso de compilación que se realiza con los lenguajes de programación de alto nivel (C, C++, etc.), ya que es completamente análogo.
El modo en que LaTeX interpreta la «forma» que debe tener el documento es mediante "etiquetas". Por ejemplo, codice_1 le dice a LaTeX que el documento que va a procesar es un artículo. Puede resultar extraño que hoy en día se siga usando una herramienta que no sea del tipo WYSIWYG («lo que ves es lo que obtienes»), pero las características de LaTeX siguen siendo muchas y muy variadas. También hay varias herramientas o aplicaciones que ayudan a una persona a escribir estos documentos de una manera más visual (LyX, TeXmacs y otros). A estas herramientas se les llama WYSIWYM («lo que ves es lo que quieres decir»).

Una de las ventajas de LaTeX es que la salida que ofrece es siempre la misma, con independencia del dispositivo (impresora, pantalla, etc.) o el sistema operativo (MS Windows, MacOS, Unix, distribuciones GNU/Linux, etc.) y puede ser exportado a partir de una misma fuente a numerosos formatos tales como Postscript, PDF, SGML, HTML, RTF, etc. Existen distribuciones e IDEs de LaTeX para todos los sistemas operativos más extendidos, que incluyen todo lo necesario para trabajar. Hay, por ejemplo, programas para Windows como TeXnicCenter, para GNU/Linux como Kile, o para MacOS como TeXShop, todos liberados bajo la Licencia GPL. Existen además los editores multiplataformas (para MacOS, Windows y Unix) Texmaker y TeXworks, que también son liberados bajo licencia GPL.

El nombre LaTeX, al derivarse del nombre TeX, mantiene la misma regla para la pronunciación que Donald Knuth especifica en "The TeXbook", es decir que, en castellano, debe pronunciarse /látej/ pues la última letra no es la "x" (equis) sino la letra griega χ (ji). No obstante, la pronunciación viene dada por el uso, tal como explica Leslie Lamport en su libro, por lo que suele ser /láteks/ otra manera habitual de nombrarlo en español. 

Lamport dijo respecto a la pronunciación en inglés lo siguiente: 

El código "<nowiki>
LTX</nowiki>" genera
"LTX"

El código "<nowiki>LTX</nowiki>" genera LTX

El código "<nowiki>formula_4</nowiki>" genera:
formula_4

El código "\LaTeX{}" genera el . Cuando no puede ser reproducido adecuadamente, por ejemplo al escribir en texto llano, se suelen escribir las consonantes en mayúsculas («LaTeX») para evitar la confusión con la palabra «látex».

La forma más práctica () de escribir tildes y otros símbolos que no aparecen en el alfabeto inglés, es obviamente escribiéndolos directamente del teclado. Así, en vez de escribir
\'a

se prefiere escribir
á

Para eso hay que tener en cuenta el sistema de codificación del programa que se está usando. Por ejemplo, si uso un editor como el TeXmaker 1.9.9, puedo elegir la codificación en
En el preámbulo del documento LaTeX hay que escribir una línea que informa del sistema usado, por ejemplo

si se usa la codificación UTF-8 o

si se usa la codificación ISO 8859-1.
Entonces el ejemplo de arriba sería simplemente

En la publicación de artículos científicos normalmente se venía solicitando el envío de los manuscritos al editor en formato .rtf, .doc y recientemente en .docx utilizando siempre al software MS Word como software de referencia. Una situación que ha forzado a todos a actualizar las licencias de MS Office para poder acceder a la última versión de MS Office para poder publicar un manuscrito en un software legal y compatible con los requerimientos de la editorial. Afortunadamente, las editoriales han optado por usar LaTex - como Elsevier que ha facilitado un documento base LaTex (elsarticle.tex) - permitiendo que el trabajo de los autores retorne a su función de redactar y no de formatear textos.

Ejemplo de revistas que actualmente permiten la recepción de manuscritos para su publicación en LaTeX son: 











</doc>
<doc id="1754" url="https://es.wikipedia.org/wiki?curid=1754" title="Leontopodium">
Leontopodium

Leontopodium es un género de plantas con flores perteneciente a la familia de las asteráceas. Comprende 126 especies descritas y de estas, solo 63 aceptadas. 

El género fue descrito por R.Br. ex Cass. y publicado en "Bull. Sci. Soc. Philom. Paris" 1819: 144. 1819. 


</doc>
<doc id="1757" url="https://es.wikipedia.org/wiki?curid=1757" title="Lenguas indoeuropeas">
Lenguas indoeuropeas

Con el nombre de lenguas indoeuropeas se conoce a la mayor familia de lenguas del mundo en número de hablantes. La familia indoeuropea, a la que pertenecen la mayoría de las lenguas de Europa y Asia meridional, incluye más de 150 idiomas hablados por alrededor de 3200 millones de personas (aproximadamente un 45 % de la población mundial). De estas, unos 1200 millones corresponden a hablantes de las lenguas indoiranias, unos 950 millones de hablantes de las lenguas románicas y unos 820 millones de hablantes de las lenguas germánicas.

El jesuíta francés Gaston-Laurent Coeurdoux fue el primero en notar las similitudes entre 
el sánscrito, el latín y el griego, e incluso entre el alemán y el ruso, en una memoria enviada a la Académie des inscriptions et belles-lettres de Francia en 1767. A veces se atribuye erróneamente al filólogo británico sir William Jones haber sido el primero en notar las semejanzas entre el sánscrito, el latín y el griego, pues en The Sanskrit Language (1786) supone que esas tres lenguas tienen una raíz común y que, además, pueden estar ligadas al gótico, a las lenguas celtas y al persa. Franz Bopp apoyó esta hipótesis al comparar sistemáticamente estas lenguas con otras y encontrar múltiples cognados. Desde el siglo XIX, los estudiosos llamaron a esta familia lenguas indogermánicas. Posteriormente pasó a emplearse el término indoeuropeo (excepto en alemán). Un buen ejemplo de la conexión indoeuropea es la enorme similitud descubierta entre el sánscrito y dialectos antiguos del lituano.

El idioma común ancestral se conoce como protoindoeuropeo. Existe desacuerdo en torno al punto geográfico en el que se originó "(urheimat)". Los principales lugares propuestos son el sur de Rusia, el óblast de Kurgán, el sudeste de Ucrania, Armenia o Irán.

Esta familia está formada por las siguientes subfamilias: albanesa, armenia, báltica, céltica, eslava, germánica, griega, indoirania (que incluye las lenguas indoarias y las iranias) e itálica (que incluye el latín y las lenguas románicas). A ellas se suman dos subfamilias hoy desaparecidas: la anatolia (que incluye la lengua de los hititas) y la tocaria. Desde la segunda mitad del siglo XVIII, y durante todo el siglo XIX, la lingüística histórica y la neogramática intentaron reunir datos suficientes para demostrar que este conjunto de lenguas, aparentemente diversas, formaban parte de una única familia.

Los documentos del sánscrito y del griego clásico (los más antiguos de las lenguas indoeuropeas si exceptuamos los hititas, que por entonces no estaban descifrados) presentan las formas características propias de las lenguas indoeuropeas, lo que demuestra la existencia de una lengua madre común. Las relaciones entre el sánscrito, el griego clásico y el latín se habían comprobado ya hacia principios del siglo XIX.

Por otro lado, los gramáticos de la India elaboraron una clasificación sistemática de los elementos que constituyeron antiguamente el sánscrito. El estudio realizado en la India se completa con otro estudio sistemático y comparativo de los sistemas fonéticos y gramaticales de las lenguas europeas.

La conclusión de este esfuerzo conjunto fue el establecimiento de la existencia del protoindoeuropeo, lengua madre común a los idiomas estudiados, efectuándose una reconstrucción de los rasgos fonéticos y gramaticales que este debía tener. El indoeuropeo es, pues, una lengua reconstruida y fechada hacia el 3000 a. C., puesto que hacia el 2000 a. C. ya se encuentran rasgos de diferenciación notables entre las lenguas nacidas del mismo.

En general, las lenguas indoeuropeas, muestran cierta pérdida progresiva de la flexión. Por lo que se supone, el protoindoeuropeo fue una lengua muy flexiva, como lo demuestran otras lenguas clásicas, como el sánscrito, el avéstico y el griego. Frente a esto, algunas lenguas modernas, tras un largo proceso evolutivo, están orientadas hacia una vía analítica, como por ejemplo el inglés, el francés y el persa, usando complementos con preposición y verbos auxiliares en lugar de la declinación nominal y la conjugación verbal; otras, como el español o el italiano siguen manteniendo una gran flexión en sus conjugaciones, tiempos y modos verbales aunque también han perdido la mayor parte de la flexividad en sustantivos y adjetivos que se daba en las declinaciones latinas; mientras que lenguas como el alemán o el ruso, en cambio, mantienen un sistema de declinaciones.

En gran parte, la pérdida de los elementos flexivos ha sido el resultado de un largo proceso que ha conducido a la pérdida de las sílabas finales de las palabras; así, muchas de las indoeuropeas eran más breves que las correspondientes protoindoeuropeas. Además, en otras lenguas ha tenido lugar el desarrollo de nuevos procedimientos gramaticales y ha habido numerosos cambios de significado en algunas palabras concretas.

El protoindoeuropeo presenta muchos rasgos que han desaparecido de la mayoría de las lenguas indoeuropeas modernas. De hecho, entre las lenguas indoeuropeas se encuentran tipologías gramaticales que las hacen muy diferentes entre sí, no siendo cierto que todas las lenguas indoeuropeas conserven actualmente "parecido" entre sí, y su relación filogenética muchas veces solo es accesible mediante el estudio comparado profundo de las mismas y no por su aspecto superficial o las características gramaticales más evidentes. Esto se debe a que estas lenguas han seguido evoluciones marcadamente diferentes en cada región donde se hablan. Sin embargo, se reconocen algunas características casi universales en todas ellas:


El sánscrito, el latín y el griego clásico distinguían entre tres géneros gramaticales: masculino, femenino y neutro. Aunque muchas lenguas indoeuropeas más modernas han perdido alguno de estos tres géneros, en las lenguas romances (con la excepción del asturleonés), las lenguas celtas modernas y las lenguas bálticas, el género neutro se ha asimilado al masculino o al femenino. En neerlandés y las lenguas escandinavas, el femenino ha desaparecido manteniéndose la oposición entre masculino y neutro. En inglés, la distinción de género solo existe en los pronombres de tercera persona de singular (marginalmente cuando el referente es un vehículo o un país puede usarse "she" para referirse a ellos), aunque en inglés antiguo el género también existía en los demostrativos y el artículo. Algunas lenguas modernas, como el armenio, han perdido completamente la distinción de género tanto en el nombre como en el pronombre. En muchas lenguas iranias modernas existen solo dos géneros: en persa moderno solo existe distinción entre género humano y no humano y en pashto entre masculino y femenino. También muchas lenguas índicas han perdido alguno de los tres géneros presentes en sánscrito, el hindi-urdu solo diferencia entre masculino y femenino, habiéndose perdido el neutro. En bengalí la pérdida ha ido más allá y la distinción de género ya no existe, o más exactamente no es morfológicamente productiva, aunque hay residuos en el léxico.

El número de géneros en el indoeuropeo más antiguo reconstruible es dudoso, ya que parece que las lenguas anatolias más antiguas solo reflejan una distinción entre género animado y género inanimado en el adjetivo. Rodríguez Adrados ha propuesto que esta es la distinción más antigua y secundariamente apareció en el resto de las ramas también el género femenino.

En el estadio más antiguo de las lenguas indoiranias, griegas, eslavas y celtas existían tres posibilidades para el número: singular, dual y plural. En las otras ramas de la familia se registran solo dos números: singular y plural (marginalmente en latín se tiene "vīgintī" '20' con terminación de dual). Actualmente el dual ha desaparecido de todas las ramas de la familia indoeuropea, excepto entre las lenguas eslavas.

Se ha reconstruido al antecesor de todo el indoeuropeo no anatolio (pIE-II) como una lengua en la que habrían existido tres números, como en las ramas indoirania y griega. Sin embargo, el anatolio solo testimonia dos números, por lo que probablemente el protoindoeuropeo común (pIE-I) habría sido una lengua con solo dos números, siendo la creación del dual una innovación posterior del indoeuropeo no anatolio.

Las lenguas indoeuropeas más antiguas de todas las ramas de la familia (griego micénico, hitita, sánscrito, latín, antiguo irlandés, eslavo eclesiástico, ...) son lenguas flexivas con un sistema de 5 a 8 casos morfológicos. El número de casos del protoindoeuropeo es materia de debate porque no está claro que el sistema máximo de casos con caso nominativo, vocativo, acusativo, genitivo, dativo, ablativo, locativo e instrumental que encontramos en sánscrito se remonte enteramente al estadio más antiguo reconstruible. De hecho, algunos autores argumentan que existen residuos de un pre-protoindoeuropeo no flexivo anterior al protoindoeuropeo común.

Muchas lenguas indoeuropeas modernas, sin embargo, han perdido gran parte del sistema de casos y la conjugación que caracterizaban a las lenguas indoeuropeas más antiguas. Así, entre las lenguas romances, derivadas del latín, solo el rumano conserva un sistema reducido de casos. Las lenguas germánicas igualmente han reducido el número de casos con formas distintivas, habiendo desaparecido en inglés por completo las marcas de caso específicas en el sustantivo. Las lenguas indoiranias han sufrido así mismo una acusada disminución del número de casos. El hindi-urdu posee un sistema de solo tres casos directo o nominativo, vocativo y oblicuo o preposicional. Una situación similar se da en muchas lenguas iranias, como el pastún de Afganistán. El griego moderno también ha reducido el número de casos respecto al griego clásico, pero junto con las lenguas eslavas y el lituano forma parte de las lenguas indoeuropeas con una flexión nominal con mayor número de casos distintos.

El sistema verbal de la mayoría de las ramas del indoeuropeo parece haber sufrido más cambios que el sistema de flexión nominal. Por esa razón, la reconstrucción se ha basado más en las terminaciones y las marcas morfológicas que en las categorías representadas.

Antes del descubrimiento de las lenguas anatolias y su parentesco con las lenguas indoeuropeas, el sistema verbal reconstruido para el protoindoeuropeo se basaba ampliamente en el griego y en el sánscrito. Este sistema reconstruido constaría de:

Este sistema máximo, llamado modelo grecoario o indogriego, fue considerado el resultado de innovaciones tardías cuando se conoció mejor el sistema verbal del anatolio. El sistema verbal del indoeuropeo más antiguo resulta, sin embargo, de difícil reconstrucción, ya que el anatolio presenta un sistema verbal mucho más simple y es, por tanto, imposible distinguir hasta qué punto se debe a pérdida de modos o tiempos o hasta qué punto el sistema de las lenguas con una conjugación más amplia es el resultado de innovaciones.

En las lenguas modernas, especialmente en las europeas, han aparecido numerosas formas verbales basadas en verbos auxiliares y perífrasis. Así, las lenguas romances y las germánicas, como el inglés o el alemán, han perdido las formas sintéticas de la voz pasiva y las formas de perfecto, presentes en lenguas antiguas como el latín o el gótico, habiendo sido substituidas con formas perifrásticas con los verbos 'ser' y 'haber'.

El léxico común heredado es la evidencia más clara del parentesco genético entre las lenguas indoeuropeas. El trabajo a partir del método comparativo ha permitido compilar diccionarios con varios miles de términos reconstruidos (precedidos de *). La siguiente tabla da los numerales reconstruidos para diferentes ramas de la familia:

Tradicionalmente, el indoeuropeo se clasificaba en dos grupos: lenguas satem y lenguas centum, que recibieron esos nombres dependiendo de si la serie de fonemas velares protoindoeuropeos /*k, *g, *g/ se palatalizaba ("*kntom" '[el número] 100' es en avéstico "satem") o no ("*kntom" dio en latín "centum"). Sin embargo, hoy en día no se concede apenas importancia al cambio (uno entre tantos), ni se cree que sea un criterio sólido que clasifique adecuadamente a las lenguas indoeuropeas. De hecho, varias clasificaciones que tratan de reconstruir el árbol cladístico de las lenguas indoeuropeas ni siquiera consideran a las lenguas "satem" como una rama propiamente. Eso sugiere que la palatalización se extendió entre lo que eran diferentes ramas de la familia.

La primera rama que se separó del tronco común fue la rama anatolia y algo más tarde la rama tocaria, ambas ramas están actualmente extintas (sin descendientes hablados actualmente). Estas dos ramas no presentan la típica palatalización de las lenguas "satem", incluso cuando el tocario es una rama "oriental". De hecho es la única lengua oriental que no palataliza, lo cual sugiere que la palatalización en la que se basa la división "centum" / "satem" es relativamente tardía. Las subdivisiones restantes son algo más discutidas, aunque parece claro que el griego, el armenio y probablemente otras lenguas paleobalcánicas formarían juntas una subdivisión. Esta rama greco-armenia incluye tanto lenguas "satem" como lenguas "centum", razón por la cual se considera que la división "satem"-"centum" no es adecuada, dado que ninguna de las dos subdivisiones serían ramas cladísticas propiamente dichas.

Las relaciones internas entre estos grupos de último nivel son algo más complicadas y polémicas y todavía existen discrepancias menores. Por ejemplo, aunque universalmente se reconoce una especial relación entre el grupo griego y algunas lenguas paleobalcánicas (en particular el armenio), no está claro por ejemplo si las lenguas indoarias se formaron por una división de un hipotético proto-indoeslavo o, por el contrario, deben considerarse el resultado de la escisión de un hipotético proto-indogriego. Y problemas similares se encuentran con las lenguas germánicas, las lenguas eslavas, las lenguas celtas o las lenguas itálicas.

Recientemente han aparecido dos intentos de clasificación interna agrupando los subgrupos básicos anteriores: El árbol filogenético de Gray-Atkinson ("The 'New Zealand' family tree", 2003) y el árbol filogenético de Ringe-Warnow-Taylor ("The 'Pennsylvania' family tree", 2002). El primero se basa estrictamente en léxico compartido y substituido, mientras que el segundo se basa en isoglosas fonológicas y morfológicas. Aunque ambas clasificaciones presentan algunos puntos comunes, también difieren de manera importante en otros detalles. Las ramas marcadas con (†) corresponden a ramas o lenguas extintas que dejaron de tener hablantes nativos. El árbol de Gray-Atkinson tiene la siguiente forma:

El árbol de Ringe-Warnow-Taylor, que deja fuera a las lenguas germánicas, ya que considerarlas implica que no existe un árbol de ajuste óptimo (es decir, filogenéticamente perfecto), tiene la siguiente forma:

En un trabajo posterior Ringe-Warnow-Evans-Nakhleh usaron 292 caracteres (parámetros de comparación) y emplearon redes filogenéticas en lugar de árboles (bajo la hipótesis de homoplasia, desarrollo independiente y otras) llegando a una red filogenética muy similar al árbol anterior, que incluía tres "ramas" de contacto (en rojo):

En lo que se refiere a las lenguas indoeuropeas queda desde hace tiempo superada la teoría que creía en una rama itálica dentro del conjunto de las lenguas occidentales, que se ramificó a su vez en las distintas lenguas conocidas, entre las que destaca el latín. Los estudios comparativos han llevado a la conclusión de que el latín guarda similitudes importantes con las lenguas célticas, mientras que, por ejemplo, el osco, resulta más parecido en ciertos tratamientos fonéticos al griego. Las semejanzas relevantes entre ambas lenguas procederían más bien del contacto histórico que del origen común en una misma rama de las lenguas indoeuropeas. Las lenguas procederían, pues, de los fenómenos históricos diferentes que habría que situar en el tiempo, para lo que, en general, se ha tendido a buscar posibles coincidencias con los datos de origen arqueológico. Sin embargo, las identificaciones excesivamente mecánicas de la cultura de Terramara con una primera oleada, latina y la de Villanova con la segunda oleada situada en la Edad del Hierro, resulta poco aceptable en todos sus términos. Si la cultura material recibe su plena identificación ya dentro de la península, del mismo modo, las lenguas indoeuropeas de Italia no pueden considerarse como entidades trasladadas en bloque en un momento preciso de la historia. Más bien tiende a hablarse de momentos en que se producen fenómenos de indoeuropeización, relacionados de modo complejo con los contactos culturales de pueblos en movimiento, portadores de determinadas técnicas que llevan consigo, pero que también se extienden por diversos mecanismos de préstamos o imitación.

De todos modos, al margen de cualquier esquematismo y de todo intento de forzar datos de diferente origen para coordinarlos en un proceso histórico demasiado simplista, entre las lenguas indoeuropeas de Italia suelen distinguirse dos momentos que, sin duda, de un modo o de otro, tienen importancia desde el punto de vista histórico, a pesar de que su plena identificación etnicolingüística sea un punto de llegada más bien que un punto de partida. Un primer grupo, cuyos rasgos se sitúan en época más antigua, tal vez en los orígenes de la Edad de los Metales y en cierta relación con la cultura de Terramara, produciría así el bloque lingüístico que por sus rasgos principales sirve para identificar a los latinos y faliscos, o a los sículos, que habían conservado, a ambos lados del estrecho de Mesina, rasgos lingüísticos menos afectados por la posible segunda oleada. También presenta rasgos propios de esta primera etapa de indoeuropeización el véneto, que constituiría así un fósil en cierta medida arrinconado dentro del fenómeno más primitivo de ese proceso de difusión lingüística.

Al sur de la península, gracias a las tradiciones procedentes de la colonización griega, recogidas posteriormente por los historiadores, como Dionisio de Halicarnaso, se conocen pueblos que la erudición actual suele identificar con ramificaciones procedentes de esta primera etapa, no siempre fáciles de localizar y posiblemente, en algunos casos, superpuestos, diacrónica o incluso sincrónicamente, por traslados, luchas, desplazamientos o, simplemente, por tratarse de diferentes modos de conocer a una misma comunidad. Son los ausonios o auruncos, ópicos, enotrios o morgetes, ítalos, comunidades cuyo desarrollo histórico se vio profundamente afectado por los contactos con los colonos.

El segundo bloque lingüístico, el que algunos estudiosos denominan propiamente itálico, que suele identificarse con los restos arqueológicos propios de la cultura de Villanova, estaría compuesto por los umbros, al sur de los anteriores, próximos a Roma y hacia el Piceno, y los oscos, al sudeste del Lacio, subdivididos en grupos como samnitas, lucanos, brucios, en contacto conflictivo con otros pueblos y también con las colonias. Grupo al margen de todos los anteriores parece ser el mesapio, con rasgos similares a la lengua ilírica.

Existen dudas de que las lenguas satem constituyan una unidad filogenética válida dentro del indoeuropeo, como una vez se pensó. Si los árboles filogenéticos propuestos por Ringe y Warnow son correctos, las lenguas satem constituirían una unidad filogenética (a diferencia de las lenguas centum, que serían el resto de lenguas que no formarían un grupo filogenético válido).

Las lenguas centum no constituyen una unidad filogenética válida dentro del indoeuropeo, como una vez se pensó. Ya que entre estas lenguas se encuentra tanto el grupo anatolio que fue la primera rama en diferenciarse del indoeuropeo como lenguas que solo más tarde se diferenciarían entre sí. Dicho de otra manera, no sería posible reconstruir un "protocentum" que por diversificación hubiera dado lugar a las lenguas centum que fuera diferente del protoindoeuropeo común. En ese sentido, la clasificación en lenguas centum obedece más a hechos accidentales y convencionales, que a un hecho lingüístico estricto. Las lista de lenguas centum es la siguiente:


Actualmente no existe una evidencia incontrovertible de que las lenguas indoeuropeas muestren un parentesco claro con lenguas de otras familias, aunque existe un cierto número de propuestas tentativas que sugieren que es posible reconocer el parentesco lejano de las lenguas indoeuropeas con otras familias lingüísticas de Eurasia. La hipótesis nostrática (Pedersen, Ílich-Svítych y Dolgopolski) y la hipótesis euroasiática de Greenberg sostienen que las lenguas urálicas, las lenguas afroasiáticas y otras muestran un parentesco reconocible con el protoindoeuropeo y que es posible reconstruir parcialmente la protolengua de la que descienden estas familias.

Sin embargo, estas hipótesis han encontrado un alto grado de criticismo y no tienen aceptación general actualmente, aunque los partidarios de estas hipótesis han continuado con el trabajo comparativo en favor de la misma.








</doc>
<doc id="1759" url="https://es.wikipedia.org/wiki?curid=1759" title="Liliidae">
Liliidae

Liliidae es una subclase de hierbas terrestres o epifitas, ocasionalmente acuáticas. Son frecuentes los geófitos con rizomas, bulbos o cormos, frecuentemente micorrizados. Pueden llegar a ser lianas o plantas arborescentes. Las hojas son alternas o, rara vez, opuestas o verticiladas, aunque pueden ser todas basales. Suelen ser simples y enteras o algo dentadas, estrechas y paralelinervias, es frecuente la presencia de una vaina basal que puede estar reducida a escamas.

Las flores son, a menudo, epíginas, aunque también las hay hipóginas, generalmente son hermafroditas, actinomorfas o fuertemente zigomorfas; aunque suelen ser entomógamas hay algunas anemógamas o autógamas.

El perianto suele estar formado por 6 tépalos, que se disponen en dos series de tres piezas de aspecto petaloideo, ocasionalmente, el verticilo externo puede tener aspecto sepaloideo.

El androceo está compuesto por 1, 3 o 6 estambres aunque ocasionalmente pueda haber 2, 4 o más de 6; los granos de polen suelen ser binucleados o más raramente trinucleados. Generalmente, los granos de polen son monosulcados o inaperturados.

El gineceo suele presentar 3 carpelos soldados en un ovario que puede ser súpero o ínfero; la placentación es axilar o parietal, si bien el ovario puede ser pseudomonómero. Puede tener uno o más primordios seminales que suelen ser bitégmicos y crasinucelados o tenuinucelados.

El fruto es, en general, capsular, aunque, ocasionalmente puede haber frutos de otros tipos.

La subclase consta de dos órdenes con 19 familias y 25.000 especies. 



</doc>
<doc id="1762" url="https://es.wikipedia.org/wiki?curid=1762" title="Memoria">
Memoria

Memoria hace referencia a varios artículos: hace referencia a...













</doc>
<doc id="1763" url="https://es.wikipedia.org/wiki?curid=1763" title="Matemáticas">
Matemáticas

Las matemáticas o la matemática (del latín "mathematĭca", y este del griego μαθηματικά, transliterado como "mathēmatiká", derivado de μάθημα, máthēma. ‘conocimiento’) es una ciencia formal que, partiendo de axiomas y siguiendo el razonamiento lógico, estudia las propiedades y relaciones entre entidades abstractas como números, figuras geométricas, iconos, glifos, o símbolos en general.

La matemática es un conjunto de lenguajes formales que pueden ser usados como herramienta para plantear problemas de manera no ambigua en contextos específicos. Por ejemplo, el siguiente enunciado podemos decirlo de dos formas: X es mayor que Y e Y es mayor que Z, o forma simplificada podemos decir que X > Y > Z. Este es el motivo por el cual las matemáticas son tan solo un lenguaje simplificado con una herramienta para cada problema específico (por ejemplo 2x2=4, o 2+2=4).

Las ciencias naturales han hecho un uso extensivo de las matemáticas para explicar diversos fenómenos observables, tal como lo expresó Eugene Paul Wigner ():

Mediante la abstracción y el uso de la lógica en el razonamiento, las matemáticas han evolucionado basándose en el cálculo y las mediciones, junto con el estudio sistemático de la forma y el movimiento de los objetos físicos. Las matemáticas, desde sus comienzos, han tenido un fin práctico.

Las explicaciones que se apoyaban en la lógica aparecieron por primera vez con la matemática helénica, especialmente con los "Elementos" de Euclides. Las matemáticas siguieron desarrollándose, con continuas interrupciones, hasta que en el Renacimiento las innovaciones matemáticas interactuaron con los nuevos descubrimientos científicos. Como consecuencia, hubo una aceleración en la investigación que continúa hasta la actualidad.

Hoy día, las matemáticas se usan en todo el mundo como una herramienta esencial en muchos campos, entre los que se encuentran las ciencias naturales, la ingeniería, la medicina y las ciencias sociales, e incluso disciplinas que, aparentemente, no están vinculadas con ella, como la música (por ejemplo, en cuestiones de resonancia armónica). Las matemáticas aplicadas, rama de las matemáticas destinada a la aplicación del conocimiento matemático a otros ámbitos, inspiran y hacen uso de los nuevos descubrimientos matemáticos y, en ocasiones, conducen al desarrollo de nuevas disciplinas. Los matemáticos también participan en las matemáticas puras, sin tener en cuenta la aplicación de esta ciencia, aunque las aplicaciones prácticas de las matemáticas puras suelen ser descubiertas con el paso del tiempo.

La palabra «matemática» (del griego μαθηματικά "mathēmatiká" , «cosas que se aprenden») viene del griego antiguo μάθημα ("máthēma"), que quiere decir «campo de estudio o instrucción». Las matemáticas requieren un esfuerzo de instrucción o aprendizaje, refiriéndose a áreas del conocimiento que sólo pueden entenderse tras haber sido instruido en las mismas, como la astronomía. «El arte matemática» ("μαθηματική τέχνη", "mathēmatikḗ tékhnē") se contrapondría en esto a la música, «el arte de las musas» (μουσική τέχνη, "mousikē téchnē"), que sería un arte, como la poesía, retórica y similares, que se puede apreciar directamente, «que se puede entender sin haber sido instruido». Aunque el término ya era usado por los pitagóricos ("matematikoi") en el siglo VI a. C., alcanzó su significado más técnico y reducido de «estudio matemático» en los tiempos de Aristóteles (siglo IV a. C.). Su adjetivo es μαθηματικός ("mathēmatikós"), «relacionado con el aprendizaje», lo cual, de manera similar, vino a significar «matemático». En particular, μαθηματική τέχνη ("mathēmatikḗ tékhnē"; en latín "ars mathematica"), significa «el arte matemática».

La forma más usada es el plural "matemáticas", que tiene el mismo significado que el singular y viene de la forma latina "mathematica" (Cicerón), basada en el plural en griego τα μαθηματικά ("ta mathēmatiká"), usada por Aristóteles y que significa, a grandes rasgos, «todas las cosas matemáticas». Algunos autores, sin embargo, hacen uso de la forma singular del término; tal es el caso de Bourbaki, en el tratado "Elementos de matemática" ("Élements de mathématique", 1940), destaca la uniformidad de este campo aportada por la visión axiomática moderna, aunque también hace uso de la forma plural como en "Éléments d'histoire des mathématiques" ("Elementos de historia de las matemáticas") (1969), posiblemente sugiriendo que es Bourbaki quien finalmente realiza la unificación de las matemáticas. Así mismo, en el escrito "L'Architecture des mathématiques" (1948) plantea el tema en la sección «Matemáticas, singular o plural» donde defiende la unicidad conceptual de las matemáticas aunque hace uso de la forma plural en dicho escrito.

Establecer definiciones claras y precisas es el fundamento de la matemática, pero definirle ha sido difícil, se muestran algunas definiciones de pensadores famosos:


El carácter epistemológico y científico de las matemáticas ha sido ampliamente discutido. En la práctica, las matemáticas se emplean para estudiar relaciones cuantitativas, estructuras, relaciones geométricas y las magnitudes variables. Los matemáticos buscan patrones, formulan nuevas conjeturas e intentan alcanzar la verdad matemática mediante deducciones rigurosas. Estas les permiten establecer los axiomas y las definiciones apropiados para dicho fin. Algunas definiciones clásicas restringen las matemáticas al razonamiento sobre cantidades, aunque solo una parte de las matemáticas actuales usan números, predominando el análisis lógico de construcciones abstractas no cuantitativas.

Existe cierta discusión acerca de si los objetos matemáticos, como los números y puntos, realmente existen o simplemente provienen de la imaginación humana. El matemático Benjamin Peirce definió las matemáticas como «la ciencia que señala las conclusiones necesarias». Por otro lado, Albert Einstein declaró que: «cuando las leyes de la matemática se refieren a la realidad, no son exactas; cuando son exactas, no se refieren a la realidad».

Se ha discutido el carácter científico de las matemáticas debido a que sus procedimientos y resultados poseen una firmeza e inevitabilidad inexistentes en otras disciplinas como pueden ser la física, la química o la biología. Así, la matemática sería tautológica, infalible y "a priori", mientras que otras, como la geología o la fisiología, serían falibles y "a posteriori". Son estas características lo que hace dudar de colocarse en el mismo rango que las disciplinas antes citadas. John Stuart Mill afirmaba:

Así, los matemáticos pueden descubrir nuevos procedimientos para resolver integrales o teoremas, pero se muestran incapaces de descubrir un suceso que ponga en duda el Teorema de Pitágoras o cualquier otro, como sí sucede constantemente con las ciencias de la naturaleza.

La matemática puede ser entendida como ciencia; si es así debiera señalarse su objeto y su método. Sin embargo, algunos plantean que la matemática es un lenguaje formal, seguro, eficiente, aplicable al entendimiento de la naturaleza, tal como indicó Galileo; además muchos fenómenos de carácter social, otros de carácter biológico o geológico, pueden ser estudiados mediante la aplicación de ecuaciones diferenciales, cálculo de probabilidades o teoría de conjunto. Precisamente, el avance de la física y de la química ha exigido la invención de nuevos conceptos, instrumentos y métodos en la matemática, sobre todo en el análisis real, análisis complejo y el análisis matricial.

Es muy posible que el arte del cálculo haya sido desarrollado antes incluso que la escritura, relacionado fundamentalmente con la contabilidad y la administración de bienes, el comercio, en la agrimensura y, posteriormente, en la astronomía.

Actualmente, todas las ciencias aportan problemas que son estudiados por matemáticos, al mismo tiempo que aparecen nuevos problemas dentro de las propias matemáticas. Por ejemplo, el físico Richard Feynman propuso la integral de caminos como fundamento de la mecánica cuántica, combinando el razonamiento matemático y el enfoque de la física, pero todavía, no se ha logrado una definición plenamente satisfactoria en términos matemáticos. Igualmente, la teoría de cuerdas, una teoría científica en desarrollo que trata de unificar las cuatro fuerzas fundamentales de la física, sigue inspirando a las más modernas matemáticas.

Algunas matemáticas solo son relevantes en el área en la que estaban inspiradas y son aplicadas para otros problemas en ese campo. Sin embargo, a menudo las matemáticas inspiradas en un área concreta resultan útiles en muchos ámbitos, y se incluyen dentro de los conceptos matemáticos generales aceptados. El notable hecho de que incluso la matemática "más pura" habitualmente tiene aplicaciones prácticas es lo que Eugene Wigner ha definido como «la irrazonable eficacia de las matemáticas en las Ciencias Naturales».

Como en la mayoría de las áreas de estudio, la explosión de los conocimientos en la era científica ha llevado a la especialización de las matemáticas. Hay una importante distinción entre las matemáticas puras y las matemáticas aplicadas. La mayoría de los matemáticos que se dedican a la investigación se centran únicamente en una de estas áreas y, a veces, la elección se realiza cuando comienzan su licenciatura. Varias áreas de las matemáticas aplicadas se han fusionado con otras áreas tradicionalmente fuera de las matemáticas y se han convertido en disciplinas independientes, como pueden ser la estadística, la investigación de operaciones o la informática.

Aquellos que sienten predilección por las matemáticas, consideran que prevalece un aspecto estético que define a la mayoría de las matemáticas. Muchos matemáticos hablan de la "elegancia" de la matemática, su intrínseca estética y su belleza interna. En general, uno de sus aspectos más valorados es la simplicidad. Hay belleza en una simple y contundente demostración, como la demostración de Euclides de la existencia de infinitos números primos, y en un elegante análisis numérico que acelera el cálculo, así como en la transformada rápida de Fourier. G. H. Hardy en "A Mathematician's Apology" (Apología de un matemático) expresó la convicción de que estas consideraciones estéticas son, en sí mismas, suficientes para justificar el estudio de las matemáticas puras. Los matemáticos con frecuencia se esfuerzan por encontrar demostraciones de los teoremas que son especialmente elegantes, el excéntrico matemático Paul Erdős se refiere a este hecho como la búsqueda de pruebas de "El Libro" en el que Dios ha escrito sus demostraciones favoritas. La popularidad de la matemática recreativa es otra señal que nos indica el placer que produce resolver las preguntas matemáticas.

La mayor parte de la notación matemática que se utiliza hoy en día no se inventó hasta el siglo XVIII. Antes de eso, las matemáticas eran escritas con palabras, un minucioso proceso que limitaba el avance matemático. En el siglo XVIII, Euler, fue responsable de muchas de las notaciones empleadas en la actualidad. La notación moderna hace que las matemáticas sean mucho más fácil para los profesionales, pero para los principiantes resulta complicada. La notación reduce las matemáticas al máximo, hace que algunos símbolos contengan una gran cantidad de información. Al igual que la notación musical, la notación matemática moderna tiene una sintaxis estricta y codifica la información que sería difícil de escribir de otra manera.

El lenguaje matemático también puede ser difícil para los principiantes. Palabras tales como "o" y "solo" tienen significados más precisos que en lenguaje cotidiano. Además, palabras como "abierto" y "cuerpo" tienen significados matemáticos muy concretos. La jerga matemática, o lenguaje matemático, incluye términos técnicos como "homeomorfismo" o "integrabilidad". La razón que explica la necesidad de utilizar la notación y la jerga es que el lenguaje matemático requiere más precisión que el lenguaje cotidiano. Los matemáticos se refieren a esta precisión en el lenguaje y en la lógica como el «rigor».

El rigor es una condición indispensable que debe tener una demostración matemática. Los matemáticos quieren que sus teoremas a partir de los axiomas sigan un razonamiento sistemático. Esto sirve para evitar teoremas erróneos, basados en intuiciones falibles, que se han dado varias veces en la historia de esta ciencia. El nivel de rigor previsto en las matemáticas ha variado con el tiempo: los griegos buscaban argumentos detallados, pero en tiempos de Isaac Newton los métodos empleados eran menos rigurosos. Los problemas inherentes de las definiciones que Newton utilizaba dieron lugar a un resurgimiento de un análisis cuidadoso y a las demostraciones oficiales del siglo XIX. Ahora, los matemáticos continúan apoyándose entre ellos mediante demostraciones asistidas por ordenador.

Un axioma se interpreta tradicionalmente como una «verdad evidente», pero esta concepción es problemática. En el ámbito formal, un axioma no es más que una cadena de símbolos, que tiene un significado intrínseco solo en el contexto de todas las fórmulas derivadas de un sistema axiomático.

Carl Friedrich Gauss se refería a la matemática como «la reina de las ciencias». Tanto en el latín original "Scientiārum Regīna", así como en alemán "Königin der Wissenschaften", la palabra "ciencia" debe ser interpretada como (campo de) conocimiento. Si se considera que la ciencia es el estudio del mundo físico, entonces las matemáticas, o por lo menos las matemáticas puras, no son una ciencia.

Muchos filósofos creen que las matemáticas no son experimentalmente falsables, y, por tanto, no es una ciencia según la definición de Karl Popper. No obstante, en la década de 1930 una importante labor en la lógica matemática demuestra que las matemáticas no puede reducirse a la lógica, y Karl Popper llegó a la conclusión de que «la mayoría de las teorías matemáticas son, como las de física y biología, hipotético-deductivas. Por lo tanto, las matemáticas puras se han vuelto más cercanas a las ciencias naturales cuyas hipótesis son conjeturas, así ha sido hasta ahora». Otros pensadores, en particular Imre Lakatos, han solicitado una versión de Falsacionismo para las propias matemáticas.

Una visión alternativa es que determinados campos científicos (como la física teórica) son matemáticas con axiomas que pretenden corresponder a la realidad. De hecho, el físico teórico, J. M. Ziman, propone que la ciencia es «conocimiento público» y, por tanto, incluye a las matemáticas. En cualquier caso, las matemáticas tienen mucho en común con muchos campos de las ciencias físicas, especialmente la exploración de las consecuencias lógicas de las hipótesis. La intuición y la experimentación también desempeñan un papel importante en la formulación de conjeturas en las matemáticas y las otras ciencias. Las matemáticas experimentales siguen ganando representación dentro de las matemáticas. El cálculo y simulación están jugando un papel cada vez mayor tanto en las ciencias como en las matemáticas, atenuando la objeción de que las matemáticas no se sirven del método científico. En 2002 Stephen Wolfram sostiene, en su libro "Un nuevo tipo de ciencia", que la matemática computacional merece ser explorada empíricamente como un campo científico.

Las opiniones de los matemáticos sobre este asunto son muy variadas. Muchos matemáticos consideran que llamar a su campo "ciencia" es minimizar la importancia de su perfil estético, además supone negar su historia dentro de las siete artes liberales. Otros consideran que hacer caso omiso de su conexión con las ciencias supone ignorar la evidente conexión entre las matemáticas y sus aplicaciones en la ciencia y la ingeniería, que ha impulsado considerablemente el desarrollo de las matemáticas. Otro asunto de debate, que guarda cierta relación con el anterior, es si la matemática fue "creada" (como el arte) o "descubierta" (como la ciencia). Este es uno de los muchos temas de incumbencia de la filosofía de las matemáticas.

Los premios matemáticos se mantienen generalmente separados de sus equivalentes en la ciencia. El más prestigioso premio dentro de las matemáticas es la Medalla Fields, fue instaurado en 1936 y se concede cada cuatro años. A menudo se le considera el equivalente del Premio Nobel para la ciencia. Otros premios son el , creado en 1978, que reconoce los logros en vida de los matemáticos, y el Premio Abel, otro gran premio internacional, que se introdujo en 2003. Estos dos últimos se conceden por un excelente trabajo, que puede ser una investigación innovadora o la solución de un problema pendiente en un campo determinado. Una famosa lista de esos 23 problemas sin resolver, denominada los «Problemas de Hilbert», fue recopilada en 1900 por el matemático alemán David Hilbert. Esta lista ha alcanzado gran popularidad entre los matemáticos y, al menos, nueve de los problemas ya han sido resueltos. Una nueva lista de siete problemas fundamentales, titulada «Problemas del milenio», se publicó en 2000. La solución de cada uno de los problemas será recompensada con 1 millón de dólares. Curiosamente, tan solo uno (la hipótesis de Riemann) aparece en ambas listas.

La Sociedad Matemática Americana distingue unas 5000 ramas distintas de matemáticas. En una subdivisión amplia de las matemáticas se distinguen cinco objetos de estudio básicos: la cantidad, la estructura, el espacio, el cambio y la variabilidad que se corresponden con la aritmética, el álgebra, la geometría, el cálculo y la estadística. Además, hay ramas de las matemáticas conectadas a otros campos como la lógica y teoría de conjuntos, y las matemáticas aplicadas.

El término matemáticas aplicadas se refiere a aquellos métodos y herramientas matemáticas que pueden ser utilizados en el análisis o resolución de problemas pertenecientes al área de las ciencias básicas o aplicadas.

Muchos métodos matemáticos han resultado efectivos en el estudio de problemas en física, química, biología, medicina, ciencias sociales, ingeniería, economía, finanzas, ecología entre otras.

Sin embargo, una posible diferencia es que en matemáticas aplicadas se procura el desarrollo de las matemáticas "hacia afuera", es decir su aplicación o transferencia hacia el resto de las áreas. Y en menor grado "hacia dentro" o sea, hacia el desarrollo de las matemáticas mismas. Este último sería el caso de las matemáticas puras o matemáticas elementales.

Las matemáticas aplicadas se usan con frecuencia en distintas áreas tecnológicas para modelado, simulación y optimización de procesos o fenómenos, como el túnel de viento o el diseño de experimentos.

La estadística es la rama de las matemáticas que estudia la variabilidad, así como el proceso aleatorio que la genera siguiendo leyes de probabilidad. Es un conocimiento fundamental para la investigación científica en algunos campos de la tecnología, como informática e ingeniería, y de las ciencias fácticas, como economía, genética, sociología, psicología, medicina, contabilidad, etc.
En ocasiones, estas áreas de conocimiento necesitan aplicar técnicas estadísticas durante su proceso de investigación factual, con el fin de obtener nuevos conocimientos basados en la experimentación y en la observación, precisando para ello recolectar, organizar, presentar y analizar un conjunto de datos numéricos y, a partir de ellos y de un marco teórico, hacer las inferencias apropiadas.

Se consagra en forma directa al gran problema universal de cómo tomar decisiones inteligentes y acertadas en condiciones de incertidumbre. La estadística descriptiva sirve como fuente de instrucción en los niveles básicos de estadística aplicada a las ciencias fácticas y, por tanto, los conceptos manejados y las técnicas empleadas suelen ser presentadas de la forma más simple y clara posibles.




</doc>
<doc id="1765" url="https://es.wikipedia.org/wiki?curid=1765" title="Mecano">
Mecano

El término Mecano puede referirse a:

</doc>
<doc id="1766" url="https://es.wikipedia.org/wiki?curid=1766" title="Milla">
Milla

La milla es una unidad de longitud del sistema anglosajón de unidades, equivalente a 1609,344 metros.

La milla no forma parte del sistema métrico decimal. Fue heredada de la Antigua Roma y equivalía a la distancia recorrida con mil pasos, siendo un paso la longitud avanzada por un pie y luego con el otro al caminar —el doble de lo que ahora se consideraría un paso— (en latín: "milia passuum"). La milla romana medía unos 1481 metros, y por tanto, un paso simple era de unos 74 cm. No debe confundirse con la milla náutica, utilizada en navegación marítima y aérea, que equivale a 1852 metros.

Como herencia romana (antes de establecerse el sistema métrico), la milla fue una de las principales medidas de longitud en el mundo occidental (si bien su longitud difería de un país a otro). Con la introducción del sistema métrico, los países latinos y otros muchos comenzaron a usar el metro y sus múltiplos para medir las distancias terrestres, y actualmente se utiliza en todo el mundo, excepto en los países anglosajones y los de su ámbito de influencia, donde todavía utilizan la milla (aunque oficialmente ya está implantado el Sistema Internacional de Unidades).

Aunque se utilizan varias abreviaturas para su símbolo ("mi", "ml", "m", "M"), en los Estados Unidos el Instituto Nacional de Estándares y Tecnología recomienda el uso de mi, aunque en el uso común para otras unidades que la usan, al menos en México, Estados Unidos y Reino Unido, se abrevia como "m" en lugar de "mi"; como por ejemplo en millas por hora ("mph" en lugar de "mi/h").

Llamada simplemente "milla", o más precisamente "milla estatutaria," se sigue usando en los países anglosajones y equivale exactamente a 1609,344 metros (formula_1 km, expresado en fracción). En inglés se llama "Statute Mile". En los países que utilizan el sistema métrico, la milla aparece normalmente en la escala de los mapas a fin de que estos puedan ser estudiados también por los anglosajones. De la misma forma, los países anglosajones van incorporando paulatinamente el kilómetro como dato adicional en su cartografía. 


Llamada "Survey Mile" en inglés, es usada por el "Public Land Survey System" (Sistema Público de Agrimensura de Tierras) de los Estados Unidos; equivale a 5280 pies de agrimensura, aproximadamente 1609 metros.

Se introdujo en la navegación hace siglos, y fue adoptada (con muy ligeras variaciones) por todos los países occidentales, siendo definida como la longitud de un arco de 1' de meridiano terrestre. Una milla náutica equivale a 1852 metros.

Tiene siete "verstá", y equivale a 7,4676 km.



</doc>
<doc id="1768" url="https://es.wikipedia.org/wiki?curid=1768" title="Microfotografía">
Microfotografía

La microfotografía, inventada y patentada por René Dagron, consiste en la obtención de imágenes muy pequeñas (de 1 mm de diámetro) de objetos de tamaño real, y comprende toda la tecnología necesaria para el arte de hacer este tipo de imágenes. Las aplicaciones de la microfotografía incluyen el espionaje, como en el caso de William Fischer hasta los objetos de regalo con visor para las tiendas de recuerdos de viaje. Hoy en día todavía se utiliza en parte de las técnicas empleadas en la fabricación de microchips, donde se llega a reducir la imagen del circuito a nivel de micrones.

Empleando un proceso de daguerrotipo, John Benjamin Dancer fue uno de los primeros en producir microfotografías, en 1839. Dancer consiguió una proporción de reducción de 160:1, y perfeccionó sus procedimientos de reducción con el proceso del colodión húmedo, de Frederick Scott Archer, desarrollado en 1850-1851, pero desaprovechó su trabajo de décadas de microfotografías como un pasatiempo personal, y no documentó sus procedimientos. La idea de que la microfotografía sería tan sólo una novedad curiosa era una opinión compartida por el "Dictionary of Photography", de 1858, que bautizó el proceso como "una cosa insignificante e infantil."

Después de la II Guerra Mundial, surgieron aplicaciones importantes de la microfotografía: las microfichas, también llamadas "microfilmes", y distintos soportes con finalidades de archivo y documentación, pero con mucha menos reducción (una microficha tiene un diámetro de 1 cm, comparado con 1 mm de diámetro de una fotomicrografia de Dagron). Desafortunadamente, el desarrollo de las técnicas digitales de archivo ha hecho que esta tecnología se encuentre en un desuso cada vez mayor.



</doc>
<doc id="1770" url="https://es.wikipedia.org/wiki?curid=1770" title="Música">
Música

La música (del griego: "μουσική" ["τέχνη"] - "mousikē" ["téchnē"], «el arte de las musas») es, según la definición tradicional del término, el arte de organizar sensible y lógicamente una combinación coherente de sonidos y silencios respetando los principios fundamentales de la melodía, la armonía y el ritmo, mediante la intervención de complejos procesos psicoanímicos. El concepto de música ha ido evolucionando desde su origen en la Antigua Grecia, en que se reunía sin distinción a la poesía, la música y la danza como arte unitario. Desde hace varias décadas se ha vuelto más compleja la definición de qué es y qué no es la música, ya que destacados compositores, en el marco de diversas experiencias artísticas fronterizas, han realizado obras que, si bien podrían considerarse musicales, expanden los límites de la definición de este arte.

La música, como toda manifestación artística, es un producto cultural con múltiples finalidades, entre otras, la de suscitar una experiencia estética en el oyente, la de expresar sentimientos, emociones, circunstancias, pensamientos o ideas, y cada vez más, cumplir una importante función terapéutica a través de la musicoterapia.

La música además, cumple una función de vital importancia en el desarrollo cognitivo del ser humano. Colabora con el pensamiento lógico matemático, la adquisición del lenguaje, el desarrollo psicomotriz, las relaciones interpersonales , el aprendizaje de lenguas no nativas y a potenciar la inteligencia emocional entre otros. Por este motivo, la música debe estar presente en cualquier plan educativo ministerial moderno y reconocida como una disciplina imprescindible dentro de la enseñanza obligatoria.

La música es un estímulo que afecta el campo perceptivo del individuo; así, el flujo sonoro puede cumplir con variadas funciones (entretenimiento, comunicación, ambientación, diversión, etc.).

Las definiciones parten desde el seno de las culturas, y así, el sentido de las expresiones musicales se ve afectado por cuestiones psicológicas, sociales, culturales e históricas. De esta forma, surgen múltiples y diversas definiciones que pueden ser válidas en el momento de expresar qué se entiende por música. Ninguna, sin embargo, puede ser considerada como perfecta o absoluta.

Una definición bastante amplia determina que música es "sonoridad organizada" (según una formulación perceptible, coherente y significativa). Esta definición parte de que —en aquello a lo que consensualmente se puede denominar "música"— se pueden percibir ciertos patrones del "flujo sonoro" en función de cómo las propiedades del sonido son aprendidas y procesadas por los humanos (hay incluso quienes consideran que también por los animales).

Hoy en día es frecuente trabajar con un concepto de música basado en tres atributos esenciales: que utiliza sonidos, que es un producto humano (y en este sentido, artificial) y que predomina la función estética. Si tomáramos en cuenta solo los dos primeros elementos de la definición, nada diferenciaría a la música del lenguaje. 
En cuanto a la función "estética", se trata de un punto bastante discutible; así, por ejemplo, un "jingle" publicitario no deja de ser música por cumplir una función no estética (tratar de vender una mercancía). Por otra parte, hablar de una función "estética" presupone una idea de la música (y del arte en general) que funciona en forma autónoma, ajena al funcionamiento de la sociedad, tal como la vemos en la teoría del arte del filósofo Immanuel Kant.

Jean-Jacques Rousseau, autor de las voces musicales en "L'Encyclopédie" de Diderot, después recogidas en su "Dictionnaire de la Musique", la definió como el «arte de combinar los sonidos de una manera agradable al oído».

Según el compositor Claude Debussy, la música es «un total de fuerzas dispersas expresadas en un proceso sonoro que incluye: el instrumento, el instrumentista, el creador y su obra, un medio propagador y un sistema receptor».

La definición más habitual en los manuales de música se parece bastante a esta: «la música es el arte del bien combinar los sonidos en el tiempo». Esta definición no se detiene a explicar lo que es el arte, y presupone que hay combinaciones "bien hechas" y otras que no lo son, lo que es por lo menos discutible.

Algunos eruditos han definido y estudiado a la música como un conjunto de tonos ordenados de manera horizontal (melodía) y vertical (armonía). Este orden o estructura que debe tener un grupo de sonidos para ser llamados música está, por ejemplo, presente en las aseveraciones del filósofo Alemán Goethe cuando la comparaba con la arquitectura, definiendo metafóricamente a la arquitectura como "música congelada". La mayoría de los estudiosos coincide en el aspecto de la estructura, es decir, en el hecho de que la música implica una organización; pero algunos teóricos modernos difieren en que el resultado deba ser placentero o agradable.

El sonido es la sensación percibida por el oído al recibir las variaciones de presión generadas por el movimiento vibratorio de los cuerpos sonoros. Se transmite por el medio que los envuelve, que generalmente es el aire de la atmósfera. La ausencia perceptible de sonido es el silencio, aunque es una sensación relativa, ya que el silencio absoluto no se da en la naturaleza.

El sonido tiene cuatro parámetros fundamentales:

La música contiene dos elementos: el material acústico y la idea intelectual. Ambos no se hallan yuxtapuestos como forma y contenido, sino que se combinan, en la música, para formar una imagen unitaria. Para convertirse en vehículo de la idea intelectual, el material acústico experimenta una preparación pre-musical, mediante un proceso de selección y ordenamiento. 

La estructura del sonido, la escala de sonidos armónicos, exhibe ya un ordenamiento que la predestina para ser el vehículo de la intención intelectual. Con el fin de un entendimiento general previo, dentro del material acústico para la organización de la música, encontramos diversas clasificaciones, dentro de las cuales la más habitual en ambientes académicos es la que divide la música en melodía, armonía y ritmo. La manera en la que se definen y aplican estos principios, varían de una cultura a otra (también hay variaciones temporales). 
Por otro lado, la idea intelectual (podemos incluir lo que hoy llamamos cerebro-cuerpo-mente) convierte el material acústico en arte, y así la música adquiere historia, vinculándose con el tiempo y haciéndose atemporal.

La incorporación de un material acústico ampliado en el siglo XX, produjo a veces dificultades de información, por falta de un sistema válido de entendimiento previo, y es por eso que otros elementos se toman en cuenta a la hora de analizar y estudiar el fenómeno de la música, como son la forma, la instrumentación, la textura, etc. A partir de todos estos elementos, se originan nuevos principios de ordenamiento y posibilidades de composición.

Buena parte de las culturas humanas tienen manifestaciones musicales. Algunas especies animales también son capaces de producir sonidos en forma organizada; lo que define a la música de los hombres, pues, no es tanto el ser una combinación "correcta" (o "armoniosa" o "bella") de sonidos en el tiempo como el ser una práctica de los seres humanos dentro de un grupo social determinado.

Independientemente de lo que las diversas prácticas musicales de diversos pueblos y culturas tengan en común, es importante no perder de vista la diversidad en cuanto a los instrumentos utilizados para producir música, en cuanto a las formas de emitir la voz, en cuanto a las formas de tratar el ritmo y la melodía, y, sobre todo, en cuanto a la función que desempeña la música en las diferentes sociedades: no es lo mismo la música que se escucha en una celebración religiosa, que la música que se escucha en un anuncio publicitario, ni la que se baila en una discoteca. Tomando en consideración las funciones que una música determinada desempeña en un contexto social determinado podemos ser más precisos a la hora de definir las características comunes de la música, y más respetuosos a la hora de acercarnos a las músicas que no son las de nuestra sociedad.
La mayoría de las definiciones de música solo toman en cuenta algunas músicas producidas durante determinado lapso en Occidente, creyendo que sus características son «universales», es decir, comunes a todos los seres humanos de todas las culturas y de todos los tiempos. Dice Schopenhauer, «(la música) repercute en el hombre de manera tan potente y magnífica, que puede ser comparada a una lengua universal, cuya claridad y elocuencia supera a todos los idiomas de la tierra».

Muchos piensan que la música es un lenguaje "universal", puesto que varios de sus elementos, como la melodía, el ritmo, y especialmente la armonía (relación entre las frecuencias de las diversas notas de un acorde) son plausibles de explicaciones más o menos matemáticas, y que los humanos en mayor o menor medida, estamos naturalmente capacitados para percibir como bello. Quienes creen esto ignoran o soslayan la complejidad de los fenómenos culturales humanos. Así, por ejemplo, se ha creído que la armonía es un hecho musical universal cuando en realidad es exclusivo de la música de Occidente de los últimos siglos; o, peor aún, se ha creído que la armonía es privativa de la cultura occidental porque representa un estadio más "avanzado" o "superior" de la "evolución" de la música.

Otro de los fenómenos más singulares de las sociedades occidentales (u occidentalizadas) es la compleja división del trabajo de la que es objeto la práctica musical. Así, por ejemplo, muchas veces es uno quien compone la música, otro quien la ejecuta, y otro tercero quien cobra las regalías. La idea de que quien crea la música es otra persona distinta de quien la ejecuta, así como la idea de que quien escucha la música no está presente en el mismo espacio físico en donde se produce es solamente posible en la sociedad occidental de hace algunos siglos; lo más común (es decir, lo más "universal") es que creador e intérprete sean la misma persona.

Desde la antigua Grecia (en lo que respecta a música occidental) existen formas de notación musical. Sin embargo, es a partir de la música de la edad media (principalmente canto gregoriano) que se comienza a emplear el sistema de notación musical que evolucionaría al actual. En el Renacimiento cristalizó con los rasgos más o menos definitivos con que lo conocemos hoy, aunque -como todo lenguaje- ha ido variando según las necesidades expresivas de los usuarios.

El sistema se basa en dos ejes: uno horizontal, que representa gráficamente el transcurrir del tiempo, y otro vertical que representa gráficamente la altura del sonido. Las alturas se leen en relación a un pentagrama (del griego «πεντα», "penta": cinco; y «γραμμa», "grama": líneas), que al comienzo tiene una "clave" que tiene la función de atribuir a una de las líneas del pentagrama una determinada nota musical. En un pentagrama encabezado por la «clave de sol en segunda línea» nosotros leeremos como sol el sonido que se escribe en la segunda línea (contando desde abajo), como la el sonido que se escribe en el espacio entre la segunda y la tercera líneas, como si el sonido en la tercera línea, etc. Para los sonidos que quedan fuera de la clave se escriben líneas adicionales. Las claves más usadas son las de:

El discurso musical está dividido en unidades iguales de tiempo llamadas compases: cada línea vertical que atraviesa el pentagrama marca el final de un compás y el comienzo del siguiente. Al comienzo del pentagrama habrá una fracción con dos números; el número de arriba indica la cantidad de tiempos que tiene cada compás; el número de abajo nos indica cuál será la unidad de tiempo.

Para escribir las duraciones se utiliza un sistema de figuras: la redonda (representada como un círculo blanco), la blanca (un círculo blanco con un palito vertical llamado plica), la negra (igual que la blanca pero con un círculo negro), la corchea (igual que la negra pero con un palito horizontal que comienza en la punta de la plica), la semicorchea (igual que la corchea pero con dos palitos horizontales), etc.. Cada una vale la mitad de su antecesora: la blanca vale la mitad que una redonda y el doble que una negra, etc.

Las figuras son duraciones relativas; para saber qué figura es la unidad de tiempo en determinada partitura, debemos fijarnos en el número inferior de la indicación del compás: si es 1, cada redonda corresponderá a un tiempo; si es 2, cada blanca corresponderá a un tiempo; si es 4, cada tiempo será representado por una negra, etc. Así, una partitura encabezada por un 3/4 estará dividida en compases en los que entren tres negras (o seis corcheas, o una negra y cuatro corcheas, etc.); un compás de 4/8 tendrá cuatro tiempos, cada uno de ellos representados por una corchea, etc.

Para representar los silencios, el sistema posee otros signos que representan un silencio de redonda, de blanca, etc..

Como se ve, las duraciones están establecidas según una relación binaria (doble o mitad), lo que no prevé la subdivisión por tres, que será indicada con "tresillos". Cuando se desea que a una nota o silencio se le agregue la mitad de su duración, se le coloca un punto a la derecha (puntillo). Cuando se desea que la nota dure, además de su valor, otro determinado valor, se escriben dos notas y se las une por medio de una línea arqueada llamada ligadura de prolongación.

En general, las incapacidades del sistema son subsanadas apelando a palabras escritas más o menos convencionales, generalmente en italiano. Así, por ejemplo, las intensidades se indican mediante el uso de una f ("forte", fuerte) o una p ("piano", suave), o varias efes y pes juntas. La velocidad de los pulsos se indica con palabras al comienzo de la partitura que son, en orden de velocidad: "largo", "lento", "adagio", "moderato", "andante", "allegro", "presto".

La práctica de la ejecución musical sobre la base de un instrumento, promueve un mejor rendimiento a nivel cerebral. Las lecciones musicales activan a ambos hemisferios cerebrales. Por esta actividad, la concentración, memoria y disciplina de un estudiante se ven a duelo al ejercitarse, y este ejercicio suele mejorar la capacidad de las aptitudes mencionadas. En el momento en el que el cerebro se ve retado a dividirse en varias funciones que requieren concentración y precisión, como al tocar instrumentos ya sea piano, guitarra, violín, contrabajo, entre otros, mejora sus funciones. Estudios realizados por la Universidad de Harvard y la Universidad de California han comprobado que la práctica de instrumentos musicales hace que los dos hemisferios cerebrales formen nuevas conexiones, cuya realización produce que el cerebro tenga un mejor rendimiento en los campos de la concentración, memoria y aprendizaje. El legendario científico español de la neurociencia moderna,Santiago Ramón y Cajal, descubrió que la única actividad que hacía más conexiones en las células cerebrales era tocar el piano, ya que en este instrumento se emplea cada dedo en una tecla distinta, enfocándose cada mano en distintos ritmos y velocidades, y en adición, los pies, que también tienen una importante función al utilizarse los pedales. 

A nivel mental, también se denomina muy útil la teoría musical para facilitar el aprendizaje en otros idiomas. Características importantes de la música, como el tono, el timbre, la intensidad y el ritmo, tienen mucho que ver con las variaciones del habla de los distintos idiomas. Cada uno de estos tiene un acento distinto, y en la música descubrimos los diversos tonos, timbres, y ritmos que se podrían acoplar a los diferentes idiomas.



</doc>
<doc id="1772" url="https://es.wikipedia.org/wiki?curid=1772" title="Monitor">
Monitor

El término monitor puede referirse:










</doc>
