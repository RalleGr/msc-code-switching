<doc id="1899" url="https://es.wikipedia.org/wiki?curid=1899" title="Ejes musicales de Colombia">
Ejes musicales de Colombia

Los Ejes musicales de Colombia son el conjunto de regiones culturales cuyas músicas folclóricas comparten géneros, estilos musicales y formatos de instrumentación. El hecho de que actualmente se puedan apreciar géneros tan distintos si se comparan los de un eje con los de otro es debido en gran parte a la geografía tan abrupta que posee el territorio colombiano que por varios siglos aisló a las diferentes regiones, manteniéndolas casi incomunicadas. Con el pasar del tiempo las regiones fueron testigo de la fusión de razas, pueblos y culturas, fruto de situaciones políticas, sociales y económicas, que fueron moldeando las concepciones estéticas de cada sociedad que habitaba en el país, haciéndose muy frecuente el hallazgo de estilos musicales con instrumentación, armonía y melodías distintas en cada eje.

A lo largo de la historia de Colombia se ha percibido como los diferentes ejes musicales se han "relevado" el protagonismo desde un punto de vista musical. Esto ha hecho que cada generación haya asociado diferentes géneros musicales como más representativos para el país. Con el pasar del tiempo y gracias a los avances tecnológicos que impactado grandemente el desarrollo de los instrumentos musicales, vemos como algunos de estos géneros se han modificado, fusionado y reinventado. Sin embargo todavía es muy común encontrar estos ritmos en su más pura esencia en cada uno de los ejes musicales.

Hoy en día se considera que en el país existen 12 ejes musicales, catalogados con esos nombres por la Centro de Documentación Musical de la Biblioteca Nacional de Colombia, con excepción del eje de valles interandinos del Pacífico. En un pasado se consideraba que en Colombia habían únicamente cinco regiones musicales que se limitaban a apreciar los aspectos geográficos del país. El estudio de las músicas tradicionales folclóricas a través de estos ejes musicales se concibe como un gran avance en la búsqueda del reconocimiento, formación y salvaguardia del patrimonio musical de la nación.

Este eje comprende los departamentos colombianos sobre el Caribe continental occidental, a saber Atlántico, Bolívar, Córdoba y Sucre, y además musicalmente las riberas del río Magdalena en los departamentos de Magdalena y Cesar. Sus prácticas musicales son la consecuencia de la mezcla de tradiciones europeas, amerindias y negras. Durante el siglo XX con el desarrollo de las big bands, varios de los géneros musicales fueron explorando nuevos rumbos, con diferentes instrumentaciones y variaciones melódicas y armónicas. El Carnaval de Barranquilla es uno de los eventos folclóricos en donde más se explotan los ritmos de este eje musical. De esta región proviene uno de los géneros musicales más conocidos de Colombia en el mundo: La cumbia.






Este eje comprende los departamentos colombianos sobre el Caribe continental oriental, a saber Guajira, Magdalena y Cesar. Sus prácticas musicales han tenido un desarrollo durante el siglo XX y se han popularizado por toda Colombia y otros países de Latinoamérica para la segunda parte de este siglo y el XXI con artistas como Carlos Vives. El Festival de la Leyenda Vallenata representa el mayor evento dedicado a estas músicas. El 1 de diciembre de 2015 el ritmo insignia de este eje fue incluido en la lista de Patrimonio Cultural Inmaterial de la Humanidad, en la lista de salvaguardia urgente por la Unesco.




Este eje comprende el departamento del Chocó, sobre el Pacífico. Sus prácticas musicales han visto un proceso de popularización durante el siglo XXI gracias a nuevas tendencias musicales con grupos como Chocquibtown y se han fortalecido en su esencia más tradicional gracias a la declaración como patrimonio de la Humanidad a las Fiestas de San Pacho en la capital del departamento, Quibdó, siendo el evento más grande en el que se practica este tipo de músicas.


Está comprendido por el territorio costero de los departamentos de Nariño, Cauca y Valle del Cauca. No obstante la ciudad de Santiago de Cali ha tenido un papel muy importante en la apropiación y divulgación de estas músicas gracias a festivales como el Petronio Álvarez. La música de la región del Pacífico Sur fue declarada en 2015 como Patrimonio Inmaterial según la UNESCO.





A esta parte de territorio comprende las regiones paisa (departamento de Antioquia) y Eje cafetero compuesto por los departamentos de Risaralda, Quindío y Caldas. Las ciudades de Pereira y de Medellín han tenido un papel muy importante en la apropiación y divulgación de estas músicas gracias sus eventos folclóricos: La Feria de las Flores. (Medellín) al igual que las Fiestas de la Cosecha y el Festival Nacional del Bambuco (Pereira)



A esta parte de territorio comprende los departamentos de Cundinamarca, Boyacá, Santander y Norte de Santander. Muchas poblaciones han tenido un papel determinante en la apropiación y divulgación de estas músicas. Algunos de los eventos que más apoyan estas manifestaciones musicales son el Festivalito Ruitoqueño en Floridablanca, Santander o en los múltiples "Aguinaldos" realizados en el departamento de Boyacá, durante épocas navideñas raíces.


Esta parte de territorio está comprendida por los departamentos de Tolima y Huila. El Festival Folclórico de Ibagué y las Fiestas de San Juan y San Pedro en Neiva son quizás los eventos más importantes que apoyan este tipo de manifestaciones musicales.




Esta parte de territorio está comprendida por los departamentos de Nariño y parte del Cauca y del Putumayo. Este eje musical recibió mucha influencia por parte del área andina Incaica proveniente de otros países andinos como Ecuador, Perú y Bolivia -después de todo el Imperio Inca se extendió hacia el norte hasta la ciudad de Pasto en el departamento de Nariño. Esto se puede percibir al observarse el uso de instrumentos como las zampoñas y el charango. El festival que más promueve este tipo de músicas es el Carnaval de Negros y Blancos en la ciudad de Pasto.






El folclor llanero es uno de los más puros y auténticos sonidos que le dan a Colombia. Se puede afirmar que la música llanera es patrimonio de Colombia y Venezuela. 
Sus 5 fiestas principales de su hermosa música son el festival de la negrera, festival de cuadrillas, festival nacional de la canción y torneo internacional del joropo, las fiestas patronales de Arauca y por último en el encuentro mundial de coleo



Está comprendido por el territorio fronterizo del departamento de Amazonas y Putumayo. La música de esta región ha recibido influencias constantes de los países limítrofes de Brasil y Perú, evidenciándose cada vez más una mezcla de ritmos que ha dado como consecuencia géneros musicales propios de esta región como lo es la paseata, convertida hoy en el ritmo musical que más identifica esta región, siendo "Mariquiña" o "Mariquinha" la paseata más famosa compuesta por el cantautor leticiano Pedro Bernal Méndez. La ciudad de Leticia ha tenido un papel muy importante en la apropiación y divulgación de estas músicas gracias a festivales como el Pirarucú de Oro, celebrado en el mes de diciembre, en donde participan artistas no sólo de esta región colombiana, sino también de Perú y Brasil.




Este eje comprende las islas colombianas del archipiélago de San Andrés y Providencia en el Caribe. Sus prácticas musicales son herencia de un proceso de intercambio cultural en el Caribe cuyas influencias más grandes provienen de Jamaica, Trinidad y Tobago, Colombia continental, Cuba y Estados Unidos. Quizás la festvidad que más celebra estas música es el "Green Moon Festival" o "Festival de la Luna Verde" en la isla de San Andrés.











</doc>
<doc id="1901" url="https://es.wikipedia.org/wiki?curid=1901" title="Música celta">
Música celta

Música celta es el término utilizado para describir un amplio grupo de géneros musicales que parten de la tradición musical popular de los pueblos considerados de tradición celta de Europa Occidental. Como tal, no existe un cuerpo musical real que pueda ser descrito como "celta", pero el término sirve para unificar tanto músicas estrictamente tradicionales de determinadas regiones geográficas, como un tipo de música contemporánea de raíz folclórica con un mismo origen etnológico y musical.

El término significa principalmente dos cosas: en primer lugar es la música de los pueblos que se autodenominan celtas, a diferencia de la música francesa o la música inglesa, definidas por existir dentro de unas fronteras políticas claras. En segundo lugar, se refiere a las características que serían exclusivas de la música de las llamadas naciones celtas. Algunos, como Geoff Wallis y Sue Wilson en su obra "The Rough Guide to Irish Music", insisten en que muchas de las tradiciones agrupadas en la etiqueta «celta» son ostensiblemente diferentes entre sí (por ejemplo, la gaélica y la bretona) y en realidad tienen nada o poco en común. Otros, sobre todo músicos como Alan Stivell, dicen que sí lo tienen, en concordancia con estudios más antiguos.

A menudo, por su amplia difusión, el término «música celta» se aplica a la música de Irlanda y Escocia ya que ambos lugares han producido estilos bien conocidos que comparten muchos y evidentes rasgos comunes, tanto en lo musical como en lo lingüístico (cultura gaélica). Sin embargo, es notable que los músicos tradicionales irlandeses y escoceses evitan el término música celta, excepto cuando se ven obligados a ello por las necesidades del mercado, y cuando se producen en festivales de música celta fuera de sus fronteras. La definición se complica aún más por el hecho de que la independencia permitió a Irlanda promocionar la música celta como un producto específicamente irlandés, quedando así difuminados sus lazos musicales con la vecina Escocia (lazos que han sido en gran parte restablecidos por los músicos modernos). Escoceses e irlandeses, aunque distintos y separados en lo político, comparten una misma ascendencia cultural y, por consiguiente, puede hablarse de un patrimonio musical celta (o gaélico) común a ambos.

Estos estilos gaélicos gozan de renombre internacional debido a la influencia de irlandeses y escoceses en el mundo de habla inglesa, especialmente en Estados Unidos, donde tuvieron un profundo impacto en músicas estadounidenses como el bluegrass y el country.

La música de Gales, Cornualles, la isla de Man, Bretaña, Galicia, Asturias, y algunas zonas de Cantabria León y Portugal son a menudo etiquetadas también como «música celta», aunque poco tienen que ver sus respectivas tradiciones con la música que constituye su principal referencia, es decir, la gaélica de Irlanda y Escocia. El movimiento musical celta, de carácter romántico y vinculado a veces a reivindicaciones de minorías culturales y nacionales, es particularmente fuerte en Bretaña, donde diversos festivales de música celta tienen lugar a lo largo del año, en paralelo y concordancia con otras celebraciones tradicionales (fiestas locales y "festoù-noz") en las que la música bretona tiene un lugar destacado y que acogen bandas y músicos de otros países de tradición celta. Del mismo modo, Gales mantiene sus antiguas celebraciones, como el Eisteddfod. Existe además una dinámica escena musical en el seno de las comunidades extranjeras de origen irlandés y escocés, especialmente en Canadá, donde se unen grupos de tradición bretona, y en los Estados Unidos.

En el libro "Celtic Music: A Complete Guide", June Skinner Sawyers reconoce seis naciones celtas divididas en dos grupos en función de su patrimonio lingüístico:

El músico Alan Stivell utiliza una dicotomía similar entre las ramas goidélica (irlandés, escocés y manés) y britónica (bretón, galés y córnico), que se diferencian «sobre todo por un rango extendido (algunas veces más de dos octavas) de las melodías irlandesas y escocesas y el rango cerrado de las melodías bretonas y galesas (a menudo reducido a media octava), y por el frecuente uso de la escala pentatónica pura en la música gaélica».

El debate hace referencia a la falta aparente de puntos en común que actualmente unen a los pueblos celtas antes mencionados. Mientras que los antiguos celtas sin duda tenían sus propios estilos musicales, el sonido real de su música sigue siendo un completo misterio.

También hay una enorme variación entre las regiones «celtas». Irlanda, Escocia y Bretaña han mantenido vivas tradiciones de la lengua y la música (En muy buena parte como forma de resistencia a los ultrajes cometidos contra sus pueblos y cultura por parte de Inglaterra y Francia en el pasado), y ha habido un resurgimiento reciente de interés en Gales. Sin embargo, Cornualles y la isla de Man solo tienen pequeños movimientos renovadores que todavía tienen que afianzarse. Galicia no tiene actualmente un idioma céltico a pesar de que toda la parte occidental de la península ibérica tuvo idiomas celtas en época prerromana, al igual que gran parte de Europa. En el caso de España, la música gallega y asturiana es a menudo nombrada como música celta, debido, seguramente, al enorme legado arqueológico celta que subsiste en estas tierras. Cabe anotar, por ejemplo, que el único poblado celta (Castro de Santa Trega), intacto en toda Europa, está en Galicia. Lo mismo puede decirse de la música de Cantabria, parte de León y norte de Portugal. Así, los tradicionalistas y los estudiosos discuten si las tierras celtas en la actualidad tienen conexiones entre sí o no. ¿Debería llamarse música celta al folklor de esas regiones dónde actualmente pervive algún remanente cultural, lingüístico o arqueológicos de los antiguos pueblos celtas? La pregunta queda abierta y tiene total validez.

Los críticos de la moderna música celta proclaman que esa idea es creación del marketing, diseñada para estimular la identidad regional en la mente de un grupo de consumidores. June Skinner Sawyers, por ejemplo, señala que «la música celta es un término de marketing que estoy utilizando, a efectos de este libro, como una cuestión de conveniencia, sabiendo muy bien el bagaje cultural que trae consigo». Esta idea comercial fue popularizada por el primer hombre que, a finales de los sesenta, mezcló la música de las llamadas naciones celtas con un toque moderno en sus grabaciones y conciertos, como en el álbum de 1972 "Renaissance of the Celtic Harp": el bretón Alan Stivell. A pesar de que este compositor es uno de los principales promotores modernos de este tipo de música, él no creó el término.

La adscripción de los rasgos musicales de cada una de las llamadas regiones celtas a los de las tradiciones musicales más próximas (por ejemplo, la pertenencia estilística de la música bretona al ámbito francés, o la de la música gallega y asturiana al marco de las músicas hispánicas), así como la enorme disparidad entre unas y otras músicas celtas, refuerza según sus críticos la idea de que lo «celta» como cuerpo musical con elementos comunes y bien diferenciado del resto de tradiciones del continente es una invención romántica moderna cuyo origen es la imitación de las pautas irlandesas y escocesas por parte de otros folklores. Afirman que no existe la música celta, sino la música irlandesa, la escocesa, la bretona, la gallega, la asturiana, etc.

Muchos creen también que la adherencia a una supuesta tradición celta común por parte de regiones muy distintas histórica y culturalmente (salvo Escocia e Irlanda, que sí comparten numerosos rasgos identitarios) responde, más allá de su discutible base teórica, a la necesidad de minorías lingüísticas y culturales de alejarse de la uniformización impuesta por sus respectivas metrópolis y de establecer vínculos de solidaridad entre sí.

La identificación de características comunes en la música celta es problemática. La mayoría de las formas musicales populares hoy consideradas como característicamente celtas fueron (y a menudo siguen siendo) comunes a muchos otros lugares de Europa Occidental. Existe un debate sobre si las jigas irlandesas fueron adaptadas de la giga italiana, forma típica de la era barroca, por ejemplo, mientras que la polca tiene su origen en la tradición checa y polaca.

Hay géneros y estilos musicales propios de cada país celta debido a las tradiciones individuales de canto y a las características de sus lenguajes específicos. Los strathspeys son específicos de las Tierras Altas de Escocia, por ejemplo, y algunos han teorizado que sus ritmos imitan los de la lengua escocesa.

Los instrumentos básicos usualmente empleados en la composición e interpretación de música celta son:

La escena de la música celta implica un gran número de festivales de música.

La más antigua tradición musical que se inscribe bajo el sello de la fusión celta se originó en la Norteamérica rural a principios del periodo colonial e incorporaron influencias escocesas, irlandesas, inglesas y africanas. Diversamente denominada como música de raíces, música folk estadounidense o música de los viejos tiempos, esta tradición ha ejercido una fuerte influencia en todas las formas de la música estadounidenses, incluyendo el country, el blues y el rock and roll. Además de sus efectos a largo plazo en otros géneros, significó la primera mezcla moderna a gran escala de tradiciones musicales de varias comunidades étnicas y religiosas dentro de la diáspora celta.

En los años sesenta, varias bandas presentaron adaptaciones modernas de música celta tirando de influencias de varias naciones celtas a la vez para crear un sonido moderno pancéltico. Algunas de ellas incluyen
las bagadoù (bandas de gaitas bretonas),
Fairport Convention,
Pentangle,
Steeleye Span y
Horslips.

En los años setenta, Clannad comenzó inicialmente en la escena folk y tradicional, y posteriormente pasó a cerrar la brecha entre la música celta tradicional y la música pop en los años ochenta y noventa incorporando elementos del new age, jazz y folk rock. Huellas del legado de Clannad pueden ser escuchadas en la música de muchos artistas incluyendo
Enya,
Altan,
Capercaillie,
The Corrs,
Loreena McKennitt,
Anúna,
Riverdance y
U2.

Más tarde, con la aparición de la fusión de hard rock con música celta de Jethro Tull y Thin Lizzy, y a partir de 1982 con la invención hecha por The Pogues del punk celta; ha habido un movimiento para incorporar influencias celtas en otros géneros de música. Bandas como
Flogging Molly,
Black 47,
Dropkick Murphys,
The Young Dubliners,
Marxman o
The Tossers
introdujeron un híbrido de rock celta, punk, reggae, hardcore y otros elementos en la década de los años noventa, que han llegado a ser populares entre la juventud estadounidense de origen irlandés.

Hoy en día hay subgéneros de influencia celta en prácticamente todo tipo de música, incluyendo electrónica, rock, metal, punk, hip hop, reggae, new age, house, ska, latina, andina y pop. En conjunto, estas interpretaciones modernas de la música celta son a veces referidas como celtic fusión. Algunos ejemplos actuales son:
la banda española Xera (que combina música celta y tradicional asturiana con música electrónica), y
la banda argentina Celtic Underground (que fusiona música escocesa con música electrónica y pop).

Entre los distintos subgéneros se encuentra el denominado folk metal, resultante de la mezcla entre el heavy metal y la música celta, que ha tenido bastante éxito en los últimos años. Al igual que en el metal vikingo, la base del celta puede variar pero son habituales los que combinan los ritmos celtas con black metal o death metal. Algunos grupos de este metal celta son
Aes Dana,
Bran Barr,
Cruachan,
Crystalmoors,
Ensiferum,
Eluveitie,
Elvenking,
Heol Telwen,
Lándevir,
Saurom,
Skiltron,
Triddana y
Waylander.

Fuera de América, los primeros intentos deliberados para crear una música pan-céltica fueron hechos por el bretón Taldir Jaffrennou, que había traducido canciones de Irlanda, Escocia y Gales al bretón en el periodo entreguerras. Una de sus principales obras fue llevar "Hen Wlad Fy Nhadau" (el himno nacional de Gales) a Bretaña y crear letras de canciones en bretón. Con el tiempo, esta canción se convirtió en "Bro Goz va zadoù", el más ampliamente aceptado himno bretón. En los años setenta, el bretón Alan Cochevelou (futuro Alan Stivell) comenzó a tocar un repertorio mixto de las principales naciones celtas con el arpa celta que creó su padre.

La música moderna también puede ser denominada celta porque está escrita y grabada en una lengua celta, independientemente del estilo musical. Muchas de las lenguas celtas han experimentado un resurgimiento en los últimos años, impulsado en parte por la acción de los artistas y músicos que las han adoptado como sellos de identidad y distinción. En 1971, la banda irlandesa Skara Brae grabó su primer y único LP con todas sus canciones en gaélico irlandés. En 1978, Runrig grabó un álbum en gaélico escocés. En 1992 Capercaillie grabó "A Prince Among Islands", el primer disco gaélico escocés en alcanzar el top 40 del Reino Unido. En 1996, una canción en bretón representó a Francia en el Festival de la Canción de Eurovisión 1996. Desde aproximadamente 2005, Oi Polloi (de Escocia) han grabado en gaélico escocés. Mill a h-Uile Rud (una banda de punk de Seattle) grabaron en ese idioma en 2004.

Asimismo, varias bandas contemporáneas tienen canciones en lengua galesa como Ceredwen, que fusiona los instrumentos tradicionales con ritmos trip hop, los Super Furry Animals o Fernhill. El mismo fenómeno ocurre en Bretaña, donde muchos cantantes graban sus canciones en bretón, tradicional o moderno (hip hop, rap, etc.).

En Europa destacan los grupos y solistas provenientes de algunas de las llamadas naciones celtas.
Así, en Irlanda nos encontramos con
The Chieftains,
Dervish,
Solas,
Lúnasa,
Planxty,
Celtic Woman,
The High Kings,
The Dubliners,
Tommy Peoples,
Liz Carrol,
Patrick Street y
The Bothy Band.
En Bretaña,
Wig A Wag,
Tri Yann,
Gwendal,
Nolwenn Leroy,
Soldat Louis,
Stone Age y
Sacrée Bordée.
En Escocia,
The Tannahill Weavers,
Wolfstone,
The Corries y
Alasdair Fracer,
así como Filska (de las islas Shetland).

Aparte de esas zonas, a lo largo de los años han surgido grupos de inspiración celta en otros países, como Anach Cuan y Glen of Guiness (en Suiza),
Omnia (en Países Bajos),
Terrafolk (en Eslovenia), Oubéret y Celtic Origine (en Francia).

En España es internacionalmente conocido el Festival de Ortigueira (La Coruña) como uno de los escaparates de los grupos españoles, así como el Festival Intercéltico de Avilés o el Folkomillas Festival en Comillas. Existen diversos grupos y autores que se adaptan más o menos a las definiciones originarias de lo que se entiende por música celta.

La mayoría de los grupos y solistas calificados como música celta cantan en gallego o asturiano, pues la música celta forma parte del folclore tradicional de Galicia y Asturias.
Así, de Galicia son
Brath,
Luar na Lubre,
Milladoiro,
Os Cempés,
Carlos Núñez,
Berrogüetto,
Susana Seivane,
Cristina Pato,
Xosé Manuel Budiño,
Mercedes Peón,
Anxo Lorenzo (que fusiona estilos celtas con tendencias electrónicas) y
Alann Bique.
De Asturias son
José Ángel Hevia (precursor de la gaita electrónica),
Tejedor,
Felpeyu,
Llan de Cubel y
Corquiéu.
Asimismo, también encontramos grupos en otras zonas de España de «tradición celta» como Luétiga, Garma, Gatu Malu, Cahórnega, Naheba, Atlántica y Cambera'l Cierzu en Cantabria o Antubel, Gandalf, Tsuniegu, Olwen, Medulia y L´Arcu la Vieya en León.

Es también interesante destacar la existencia de grupos de folk fuera de las regiones más tradicionales, como Ima Galguén en Canarias, Invernalia, Sláinte y Lád Cúig en Cataluña, Rare Folk, Mussels, Stolen Notes y Gan Ainm en Andalucía, O´Carolan en Aragón, Hibai Deiedra y Kepa Junkera en País Vasco, Acetre en Extremadura o Zamburiel y Kinnia en Madrid.

Otros grupos, como Triquel, Celtas Cortos o Akelarre AgroCelta, así como más recientemente El Sueño de Morfeo, exploran ciertas características de este estilo musical, aunque no por ello se puede afirmar que interpretan «música celta» de manera regular.

La música celta también tiene su hueco en el rock español. Uno de los primeros grupos españoles en fusionar las vertientes de la música celta con el Heavy metal fue Ñu. Más tarde también se encontrarían en este subgénero bandas como Lándevir o Saurom. Sin embargo, el grupo de mayor éxito ha sido Mägo de Oz con su fusión de metal y sonidos celtas.

Existe un dinámico crecimiento de este género en América, incluyendo la danza y la investigación en áreas relativas a las sociedades celtas. La música celta en Hispanoamérica se resignifica, ya que recibe diversos aportes musicales propios de cada país donde se la interpreta.

En América del Norte tiene una destacada presencia debido a la inmigración europea, principalmente de irlandeses, surgiendo artistas como Loreena McKennitt o Michael Flatley, y celebrándose festivales como Celtic Colours, que tiene lugar en la isla de Cabo Bretón.

Argentina recibió inmigrantes de origen celta provenientes de toda Europa: gallegos, asturianos, irlandeses, galeses y escoceses, por lo que sus descendientes recrean sus melodías, algunas tradicionales y otras de composición original, pero siempre con reminiscencias célticas. 
Uno de los grupos de música celta pioneros en este país ha sido Duir, que interpreta temas tradicionales de Irlanda, Escocia, Gales y Bretaña. En su repertorio se incluyen tanto danzas como canciones -en inglés, gaélico irlandés, galés y bretón-. Los instrumentos ejecutados son bodhran, flauta irlandesa, tin whistles, mandolina, guiarra acústica y bouzouki.
Entre los artistas más destacados están Santiago Molina,
Athy (arpista y compositor que fusiona su arpa con otros instrumentos étnicos además de mezclar la música celta con estilos como el new age, el flamenco, el tango, la música electrónica, el jazz o el blues),
Ara Solis,
Arween,
Calath,
Celtic Underground,
Fillos do Vento,
Gael,
Gustavo Fuentes,
Kells,
Na Fianna,
Os Furafoes,
Sete Netos,
Xeito Novo, Bri - Celtic Folk y
Xold

En Chile se encuentran bandas como
Breogán,
Banda Celta Danzante,
Riveira (la cual realiza por primera vez en este país la fusión del folk celta con el rock acústico),
Keltoiband,
Mándrago,
Ta Fechu(La primera Banda Chilena invitada al festival interceltico de lorient y la primera nominada a un premio internacional como lo son los premios amas),
La Eringo,
Dana,
Andes Celta,
Finisterra,
Conjunto Voces del Tiempo,
Gwyddyon, además de
la disuelta Banda Celtamericana (que fue la primera agrupación chilena de este tipo en realizar una gira al Reino Unido e Irlanda en 2007).
En Colombia destacan grupos como Perceval (primer grupo de la capital de ese país en publicar un trabajo discográfico de este género),
Mithril (banda),
Ogmios,
Espíritu Celta,
Sé Dublín y
La Montaña Gris (único grupo hispanoamericano que hizo dos giras continentales para promocionar sus trabajos discográficos).

En Costa Rica están los grupos
Peregrino Gris y Arbore Lume

En México destacan bandas y solistas como
A Campo Traviesa,
An Bodhrán,
Ontofonía,
Ogham Ensemble,
la Banda de Gaitas del Batallón de San Patricio y
la arpista Cynthia Valenzuela.

En Uruguay destacan intérpretes como
Lorena Lores,
Los Casál,
Griannan o la Southern Cross Pipe Band.

En Venezuela sobresale Gaêlica.




</doc>
<doc id="1902" url="https://es.wikipedia.org/wiki?curid=1902" title="Metámero">
Metámero

Se conoce como metámero a cada uno de los segmentos que se repiten en ciertos grupos de animales, celomados de simetría bilateral (bilateria). La metamerización es una de las principales modificaciones del celoma. Cada metámero tienen cavidades celómicas separadas de las de otros metámeros por tabiques, y las estructuras internas (ganglios nerviosos, nefridios, gónadas, etc.) y externas (patas, branquias, etc.) están repetidas en cada metámero.

Por ejemplo, en los artrópodos, cada metámero puede llevar al menos un par de apéndices, que pueden ser patas, antenas o branquias en el caso de los acuáticos. Un ejemplo ilustrativo es el ciempiés (Chilopoda): cada uno de los segmentos que lleva un par de patas es un metámero; mientras que los milpiés (Diplopoda) cuentan con dos pares por metámero.

La metamerización se da también de modo característico en el filo de los anélidos e incluso en los vertebrados, aunque en este último grupo no se ve tan fácilmente porque a lo largo de la evolución del grupo ha habido múltiples modificaciones, fusiones, reducciones, etc. de dichos metámeros y se ha perdido la metamería externa (pero no la interna como evidencian los peces). En muchos filos de gusanos hay metámeros cefalizados que reciben el nombre de prostomio que contiene ganglios nerviosos dispuestos en forma de anillo en torno al tracto inicial del tubo digestivo, que pueden ser ya considerados un cerebro: un sistema de integración para estímulos e impulsos formado por células nerviosas. Se han podido obtener respuestas condicionadas a un estímulo, demostrando así una posibilidad de aprendizaje por parte de oligoquetos como la lombriz o animales aún más complejos como la sanguijuela (hirudíneos), capaz de cazar y depredar en peces de gran tamaño.


Las plantas también presentan metamerización.



</doc>
<doc id="1904" url="https://es.wikipedia.org/wiki?curid=1904" title="Microsoft Access">
Microsoft Access

Microsoft Access es un sistema de gestión de bases de datos incluido en el paquete ofimático denominado Microsoft 365, sucesor de "Embedded Basic." 

Access es un gestor de datos que utiliza los conceptos de bases de datos relacionales y pueden manejarse por medio de consultas e informes. Está adaptado para recopilar datos de otras utilidades como Excel, SharePoint, etc.

La aplicación permite recopilar información relativa a un asunto o propósito particular, como el seguimiento de pedidos de clientes o el mantenimiento de una colección de música, etc.

Fue llamado EB (""Embedded Basic"") que se utilizaría en la mayoría de software Microsoft hasta la llegada de VBA. También se buscaba que Omega funcionara como "front-end" para Microsoft SQL Server. Omega requería una enorme cantidad de recursos de los procesadores 386 disponibles en la época para usos comerciales, retrasando su llegada desde el primer cuatrimestre de 1990 hasta enero de 1991. Más tarde partes del proyecto fueron utilizados para otros proyectos de Microsoft. Cirrus (nombre clave para Access) y Thunder (nombre clave para Visual Basic, en el que se utilizó el motor "Embedded Basic"). Tras el adelanto de Access, Omega fue demostrado ante varios periodistas en 1992 y Access presentaba funciones que no tenía.

Después de la cancelación de Omega, algunos de sus desarrolladores fueron reasignados al proyecto Cirrus (la mayoría fue a parar al equipo creador de Visual Basic). Su meta era crear un competidor de productos como dBase y Paradox en el entorno Windows. El proyecto pareció condenado con la compra de FoxPro (una "app" de base de datos completamente diferente a Access) por parte de Microsoft, pero la compañía decidió continuar con el desarrollo de Cirrus. Al principio se asumió que el producto usaría el motor "Extensible Storage Engine" ("Jet Blue") pero al final fue reemplazado por otro motor llamado "Microsoft Jet Database Engine" (Jet Red). El proyecto usó partes del código escrito para Omega y una versión pre-publicada de Visual Basic. En julio de 1992, llegó la versión final con el nombre de Access que continúa hasta el momento.


Los requisitos de espacio de disco duro siguientes son aproximados:

Módem de 9600 baudios o superior (14400 baudios o superior, es lo recomendable).

Si piensa crear páginas Web dinámicas, la característica "Publicar en el Web" requiere software de "Internet Information Server" (IIS) o "Microsoft Personal Web Server" para Windows 95 en el equipo donde residen las páginas Web. Esto no tiene que ser el mismo equipo donde se utiliza Microsoft Access 97 para crear las páginas Web.





</doc>
<doc id="1908" url="https://es.wikipedia.org/wiki?curid=1908" title="Matemáticas discretas">
Matemáticas discretas

Las matemáticas discretas son un área de las matemáticas encargada del estudio de los conjuntos discretos: finitos o infinitos numerables.

En oposición a las matemáticas continuas, que se encargan del estudio de conceptos como la continuidad y el cambio continuo, las matemáticas discretas estudian estructuras cuyos elementos pueden contarse uno por uno separadamente. Es decir, los procesos en matemáticas discretas son contables, como por ejemplo, los números enteros, grafos y sentencias de lógica.

Mientras que el análisis real está fundado en el conjunto de los números reales los cuales no son numerables, la matemática discreta es la base de todo lo relacionado con los números naturales y/o conjuntos numerables.

Son fundamentales para la ciencia de la computación, porque solo son computables las funciones de conjuntos numerables.

La clave en matemáticas discretas es que no es posible manejar las ideas de proximidad o límite y suavidad en las curvas, como se puede en el análisis. Por ejemplo, en matemáticas discretas una incógnita puede ser 2 o 3, pero nunca se aproximará a 3 por la izquierda con 2.9, 2.99, 2.999, etc. Las gráficas en matemáticas discretas vienen dadas por un conjunto finito de puntos que se pueden contar por separado; es decir, sus variables son discretas o digitales, mientras que las gráficas en cálculo son trazos continuos de rectas o curvas; es decir, sus variables son continuas o analógicas.

Las matemáticas discretas han visto un gran número de problemas difíciles de resolver. En teoría de grafos, mucha de la investigación realizada en sus inicios fue motivada por intentos para probar el teorema de los cuatro colores, el cual fue probado más de cien años después de su inicial descripción. El problema de los puentes de Königsberg, un problema clásico del prolífico Leonhard Euler.

En lógica, el segundo problema de la lista de problemas abiertos de David Hilbert, era probar que los axiomas de la aritmética son consistentes. El segundo teorema de Gödel de la incompletitud probó en 1931 que esto no es posible, por lo menos dentro de la aritmética en sí. El décimo problema de Hilbert era determinar si un polinomio diofántico con coeficientes enteros dado tiene una solución entera. En 1970, Yuri Matiyasevich probó que esto es imposible de hacer.

La necesidad de descifrar códigos alemanes en la Segunda Guerra Mundial dio paso a avances en la criptografía y la ciencia computacional teórica, con el primer computador electrónico, digital y programable desarrollado en Inglaterra. Al mismo tiempo, requerimientos militares motivaron avances en la investigación de operaciones. La Guerra Fría tuvo significancia en la criptografía, y la mantuvo vigente, con lo que se realizaron avances en la criptografía asimétrica.

Actualmente, uno de los problemas abiertos más famosos en la teoría de la informática es el problema de las clases de complejidad "P = NP". El Clay Mathematics Institute ha ofrecido un premio de un millón de dólares para la primera demostración correcta, junto con premios para 6 problemas más.

La teoría de la informática incluye áreas de la matemática discreta relevante a la computación. Está altamente relacionada con teoría de grafos y lógica. Dentro de la teoría de la informática se encuentra la teoría de algoritmos para problemas matemáticos. La computabilidad estudia lo que puede ser computado y tiene lazos fuertes con la lógica, mientras que la complejidad estudia el tiempo que se necesita para hacer los cálculos. La teoría de autómatas, los lenguajes formales y la Dinámica de sistemas se relacionan de manera cercana con la computabilidad. Las redes de Petri y álgebra de procesos se usan para modelar sistemas de cálculo, y los métodos de la matemática discreta se usan para analizar circuitos VLSI. La geometría computacional aplica algoritmos a problemas geométricos, mientras que el análisis digital de imágenes los aplica a representaciones de imágenes. La teoría informática también incluye el estudio de tópicos de informática continua.

La teoría de la información se ve involucrada en la cuantificación de la información. Cercanamente relacionado con esto es la teoría de codificación, que es usada para diseñar métodos de transmisión y almacenamiento de datos eficientes y confiables. La teoría de la información también incluye tópicos continuos tales como señales análogicas, codificación análoga y cifrado análogo.

La lógica es el estudio de los principios del razonamiento válido y la inferencia, como también de la consistencia, solidez y completitud. Por ejemplo, en la mayoría de los sistemas en la lógica, la ley de Peirce, (((P→Q)→P)→P) es un teorema. En lógica clásica, puede ser fácilmente verificado con una tabla de verdad. El estudio de las demostraciones matemáticas es particularmente importante en lógica y tiene aplicaciones en la demostración automática de teoremas y verificación formal de software.

Las fórmulas lógicas son estructuras discretas, como lo son las demostraciones, las cuales forman árboles finitos, o más generalmente, estructuras de grafos acíclicos (en cada paso de inferencia combinando una o más ramas de premisas para dar una sola conclusión). Las tablas de verdad de fórmulas lógicas usualmente forman un conjunto finito, generalmente restringido a dos valores: verdadero y falso, pero la lógica puede tener valores continuos, por ejemplo en la lógica difusa. Los conceptos como árboles de demostraciones o derivaciones infinitas también han sido estudiados, por ejemplo en la lógica proposicional infinitaria.

La teoría de conjuntos es la rama de la matemática que estudia conjuntos matemáticos, los cuales son colecciones de objetos, tales como {azul, blanco, rojo} o el conjunto infinito de todos los números primos. Conjuntos parcialmente ordenados y conjuntos con otras relaciones tienen aplicación en muchas áreas.

En la matemática discreta, los conjuntos numerables (incluyendo conjuntos finitos) son el principal objeto de estudio. El inicio de la teoría de conjuntos generalmente se relaciona con el trabajo de Georg Cantor, haciendo distinción entre diferentes tipos de conjuntos infinitos, motivado por el estudio de las series trigonométricas. El desarrollo más profundo en la teoría de conjuntos infinitos está fuera del alcance de la matemática discreta. De hecho, el trabajo contemporáneo en teoría descriptiva de conjuntos hace uso extenso del uso de la matemática continua tradicional.

La combinatoria es la rama de la matemática que estudia colecciones finitas de objetos que pueden ser combinados u ordenados.

La combinatoria enumerativa se ocupa, en particular, del "recuento" de los objetos de dichas colecciones.

La combinatoria analítica se concentra en la enumeración de estructuras combinatorias utilizando herramientas de análisis complejo y teoría de probabilidad. En contraste con la combinatoria enumerativa, que usa fórmulas combinatorias explícitas y funciones generadoras para describir los resultados, la combinatoria analítica se enfoca en obtener fórmulas asintóticas.

La teoría de diseño es el estudio de diseños combinatorios, que son clases de subconjuntos con ciertas propiedades numéricas de intersección.

La teoría de particiones estudia varios problemas asintóticos y de enumeración relacionados con particiones enteras, y está relacionada con series q, funciones especiales y polinomios ortogonales. Originalmente una parte de teoría numérica y análisis, la teoría de particiones es considerada una parte de combinatoria, o un área independiente.

La teoría del orden es el estudio de conjuntos parcialmente ordenados, finitos e infinitos.

La teoría de grafos es el estudio de grafos y la teoría de redes. Generalmente es considerada parte de la Combinatoria, pero ha evolucionado por su parte lo suficiente como para ser considerada una materia por sí misma. La teoría de grafos tiene extensas aplicaciones en todas las áreas de la matemática y la ciencia. Existen, incluso, grafos continuos.

La teoría de distribuciones discretas trata con eventos que ocurren en espacios de muestra numerables. Por ejemplo, conteos como el número de aves en una bandada solo pueden tener valores naturales {0, 1, 2...}. Por otra parte, observaciones continuas como los pesos de estas aves se pueden representar mediante números reales, y típicamente serían modelados por una distribución de probabilidad continua, como por ejemplo, la distribución normal. Distribuciones continuas pueden ser utilizadas para aproximar discretas y viceversa. Para situaciones en las cuales los valores posibles son altamente restringidos en su variabilidad, como por ejemplo en dados o cartas, calcular las probabilidades simplemente necesita de combinatoria enumerativa.

La teoría de números principalmente tiene que ver con las propiedades de los números en general y, particularmente, de los enteros. Tiene aplicaciones en la criptografía, criptoanálisis y criptología, particularmente en lo que refiere a números primos. Otros aspectos de la teoría de números incluye la teoría geométrica de números. En la teoría analítica de números, también se utilizan técnicas de matemática continua.

Las estructuras algebraicas ocurren discreta y continuamente. Como ejemplos de álgebras discretas están: el álgebra booleana, utilizada en circuitos digitales y programación, álgebra relacional, utilizada en bases de datos; grupos, finitos y discretos, así como anillos y campos son importantes en la teoría de códigos.

Una función definida en un intervalo de enteros se llama secuencia. Una secuencia puede ser una finita o infinita. Tal función discreta puede ser definida explícitamente por una lista (si su dominio es finito), o por una fórmula para su término n-esimo, o también puede ser dada implícitamente por una relación de recurrencia o ecuación de diferencia. Las ecuaciones de diferencia son similares a las ecuaciones diferenciales pero se reemplazan las derivadas tomando la diferencia entre términos adyacentes y pueden ser utilizadas para aproximar ecuaciones diferenciales. Muchas interrogantes y métodos de las ecuaciones diferenciales tienen sus contrapartes para ecuaciones de diferencias.

La geometría discreta y la geometría combinatoria tratan las propiedades combinatorias de colecciones discretas de objetos geométricos. Un antiguo tópico en la geometría discreta es el recubrimiento del plano. La geometría computacional aplica algoritmos a problemas geométricos.

Si bien la topología general es el campo de las matemáticas que formaliza y generaliza la noción intuitiva de "deformación continua" de los objetos, o el proceso de límite, da paso a muchos tópicos discretos. Esto puede ser atribuido en parte a la atención que se le da a los invariantes topológicos, que toman, por lo general, valores discretos. Entre sus ramas de estudio se encuentran la topología combinatoria, topología de grafos, topología computacional y topología algebraica, entre otros.

La investigación de operaciones es una rama de las matemáticas consistente en el uso de modelos matemáticos, estadística y algoritmos con objeto de realizar un proceso de toma de decisiones prácticas para negocios y otras áreas. Estos problemas pueden ser, por ejemplo, la repartición de recursos para maximizar ingresos, o agendar actividades para minimizar riesgos. Técnicas propias de la investigación de operaciones incluyen programación lineal y otras áreas de optimización, teoría de colas, algoritmos de planificación, análisis de redes. La investigación de operaciones también incluye tópicos continuos como procesos de Markov de tiempo continuo, optimización de procesos, martingalas de tiempo continuo, etc.

La teoría de la decisión trata fundamentalmente con identificar los valores, incertidumbres y otros factores relevantes en una decisión, su racionalidad y la decisión óptima resultante.

La teoría de utilidades es sobre medidas de la relativa satisfacción económica proveniente del consumo de algún bien o servicio.

La teoría de juegos trata con las situaciones donde el éxito depende de las decisiones de otros, lo cual hace elegir el mejor curso de acción más complejo. Tópicos incluyen la Teoría de subasta y la "división justa".

La teoría de decisión social estudia las elecciones.

La discretización busca transformar modelos y ecuaciones continuos en sus contrapartes discretas, usualmente para hacer cálculos más fácilmente utilizando aproximaciones. El análisis numérico es un importante ejemplo.




</doc>
<doc id="1909" url="https://es.wikipedia.org/wiki?curid=1909" title="Monismo">
Monismo

Reciben el nombre de monismo las posturas filosóficas que sostienen que el universo está constituido por una única sustancia (arjé), causa o sustancia primaria. 

Según los monismos materialistas, todo se reduce, en última instancia, a materia, mientras que para los espiritualistas o idealistas (especialmente el idealismo hegeliano), ese principio único sería el espíritu, y para los panteístas sería Dios mismo. En cambio para doctrinas no dualistas, como la "advaita", que afirma la unidad entre las almas "(atman)" y la divinidad "(Brahman)", postula que la conciencia cósmica en la que existe esta unidad sería el "verdadero sustrato" de todo.

Para los antiguos filósofos hindúes, lo observado por los sentidos y las relaciones de causalidad son una ilusión; solo hay una realidad: Brahman. Por tanto, Brahman será esa causa primera que explica el resto del universo. Para los filósofos monistas materialistas contemporáneos, la materia formada en la Gran Explosión dio lugar al universo y solo esta materia explica la realidad.

Filósofos monistas son Tales de Mileto, Parménides, Anaximandro, Anaxímenes, Spinoza, Berkeley, Hume y Marx.

El monismo neutral es una teoría filosófica que predica que la sustancia básica no es ni física ni mental, sino que puede ser reducida a materia neutra cuya naturaleza no sería ni física ni mental. El monismo neutro fue introducido en el siglo XVII por el filósofo judío neerlandés Spinoza. En la actualidad una versión de esta teoría ha sido desarrollada por el filósofo estadounidense Donald Davidson.

El materialismo tradicional, una variedad del monismo, considera que la sustancia primaria es material y física.

El idealismo es una forma de monismo filosófico que sostiene que el principio básico del universo es espiritual.

Los planteamientos monistas, al contrario que los dualistas, consideran que el ser humano es una única realidad, que es unitario, negando así la existencia de la mente como realidad distinta del cerebro.

Demócrito (cuyo principio constitutivo del universo, o arjé, era el átomo) sostenía que toda realidad es un compuesto material fruto de la unión de átomos, y explicaba que tanto lo que es como lo que no es, lo sólido y lo vacío, existen igualmente y uno dependiendo del otro. El ser humano es puramente materia, y por tanto no existe inmortalidad del alma. El materialismo de Demócrito se fortalece a lo largo de los siglos XVII al XIX y XX, a través de filósofos como D´Holbach, Diderot y La Mettrie, que escribió el "Hombre Máquina". Para él, el alma es una parte material del cuerpo identificada con el cerebro. Así, somos máquinas muy complejas que no necesitan dirección externa (alma) para realizar sus funciones. El materialismo mecanicista de La Mettrie fue sustituido en el siglo XIX por el materialismo dialéctico de Marx. Dentro del monismo materialista, se distinguen varias posturas como el conductismo y el reduccionismo fisicalista.

Opuesto al anterior, afirma que todo lo real es mental, es decir, todo lo que existe es la percepción de tu mente. No existe materia, sino que es fruto de tu imaginación. El ser humano es concebido como una mente que se percibe y percibe a lo otro. En palabras de Berkeley, “esse est percipi” (ser es ser percibido), es decir, la realidad consiste en percibir o ser percibido. Solo existe una única realidad espiritual. Así no tiene sentido afirmar la independencia de cuerpo o materia, puesto que todo es nuestra percepción.

Como ejemplo particular se puede tomar el monismo idealista hegeliano que, partiendo de la historicidad del ser, se sostiene en que el ser de la realidad objetiva es el no-ser: solo existe de manera ideal (en el sentido de que solo existe en la idea) y es esta la realidad. A su vez, la tensión permanente entre el ser y el no-ser (en este caso entre lo ideal y lo real) es lo que da pie al desarrollo dialéctico del espíritu humano (en el sentido alemán del concepto).

Una aplicación concreta del análisis de la dialéctica idealista es el caso del desarrollo histórico del lenguaje, como unidad de la lengua y el habla. Aquí se observa que la lengua es ideal y general, mientras que el habla, su práctica, es completamente particular; es más: el habla es un conjunto de realizaciones concretas de su idealidad. Sin embargo, la tensión entre la lengua y el habla, como ejemplo del ser y no-ser, lleva a su desarrollo histórico y transformación de tanto de la idealidad de la lengua como de la práctica del habla. Siguiendo este patrón es que podemos entender la transformación del latín a cada una de las lenguas romances.

Spinoza (1632-1677) propone una solución neutral. Spinoza no admite el dualismo cartesiano de las dos sustancias (material y espiritual). Para él, estamos compuestos por una sola sustancia que es Dios, de la cual solo conocemos dos atributos: la extensión y el pensamiento. Son dos atributos de la misma realidad, de modo que el monismo intermedio considera que hay una única sustancia de la cual solo conocemos dos atributos. Entonces cuerpo y mente son dos aspectos de una misma cosa, y por eso, ya no es necesario plantear el problema de su interacción.

Como refiere Max Kistler, probar la existencia de la mente es un desafío para el monismo. El dualismo más potente ha sido el cartesiano, que no ha sido lo suficientemente salvado y ha llevado a postular sustancias independientes entre sí ya sean cuerpos sin mente ("res extensa") como mentes sin cuerpos ("res cogitans"). 

Las formas extremas de monismo han derivado en el conductismo lógico y la teoría de la identidad psicofísica, ambas rechazadas. La primera planteando que formas superiores del comportamiento (v. gr. el lenguaje) no son reductibles a un comportamiento. La segunda, interponiendo el argumento de que no contempla el carácter cualitativo de la experiencia y de la conciencia, términos que hoy en día son muy afines.

El debate actual se ha desplazado a probar no ya la sustancia pensante, sino las propiedades mentales.

Otra forma de monismo extremo, el eliminativismo, intenta probar que no existen propiedades mentales. El monismo anómalo de Donald Davidson sostiene que cada estado mental es idéntico a un estado físico. El epifenomenismo tiene a las propiedades mentales como superveniencia de las propiedades físcas subyacentes. 

Finalmente, la posición más en boga es, según Kistler, el funcionalismo: suerte de dualismo entre las propiedades mentales y las físicas.



</doc>
<doc id="1910" url="https://es.wikipedia.org/wiki?curid=1910" title="Mitología">
Mitología

La mitología es un conjunto de mitos relativamente cohesionados o paralelamente adheridos: relatos que forman parte de una determinada religión o cultura. También se les denomina mitos a los discursos, narraciones o expresiones culturales de origen sagrado, y que posteriormente fueron secularizados y tratados como discursos relativos a una cultura, a una época o a una serie de creencias de carácter imaginario.

Los mitos son relatos basados en la tradición y en la leyenda, creados para explicar el universo, el origen del mundo, los fenómenos naturales y así como también para cualquier suceso para el cual no haya una explicación conocida. Sin embargo, no todos los mitos tienen por qué tener este propósito explicativo. Igualmente, la mayoría de los mitos están relacionados con una fuerza natural o deidad, pero muchos son simplemente historias y leyendas que se han ido transmitiendo oralmente de generación en generación.

El término griego "mythología" está compuesto de dos palabras:

La mitología aparece de manera prominente en la mayoría de las religiones y, de igual modo, la mayoría de las mitologías están relacionadas con, al menos, una religión.

El término se suele usar más frecuentemente en este sentido para referirse a las religiones fundadas por sociedades antiguas, como la mitología griega, la mitología romana y la mitología escandinava. Sin embargo, es importante recordar que, mientras que algunas personas ven los panteones escandinavo y celta como meras fábulas, otros las consideran religiones (véase neopaganismo). Del mismo modo, ello también sucede al analizar las mitologías de los pueblos indígenas (ejemplo la Mitología de América del Sur); en el que se pueden observar casos en que aún se profesan las religiones nativas.

Generalmente, muchas personas no consideran los relatos que rodean al origen y desarrollo de religiones como el cristianismo, judaísmo e islam, como crónicas literales de hechos, sino como representaciones figurativas o simbólicas de sus sistemas de valores.

Aun así, igualmente, muchas personas entre ellos ateos, agnósticos, o creyentes de algunas de estas mismas religiones, emplean las palabras mito y mitología para caracterizar como falsas o a lo sumo dudosas, las historias que aparecen en una o más religiones, o a las religiones diferentes a la que es creyente. De este modo la gente que pertenece a la mayoría de las religiones que están presentes actualmente, se ofende cuando se toma a su fe como un conjunto de mitos; ya que para ellos, esto, equivale a decir que su religión en sí es una mentira, lo cual va en contra de sus creencias. Ejemplo de ello sucede en muchos grupos cristianos en relación con los relatos de la Biblia, en el cual sus creyentes no consideran, generalmente, que sean mitológicas algunas de sus historias, y que sólo se usa esta palabra para referirse a ellas en un sentido peyorativo.

Sin embargo, la mayoría de la gente está de acuerdo con que cada religión tiene un conjunto de mitos que se ha desarrollado alrededor de sus escrituras religiosas; ya que en sí la palabra mito se refiere a hechos que no son posibles de ser verificados de manera objetiva. De este modo, igualmente se considera que se puede hablar de mitología judía, mitología cristiana o mitología islámica, para referirnos a los elementos míticos que existen en estas creencias; sin hablar de la veracidad de los principios de la fe o de las versiones de su historia; pues la creencia de su religión como algo verdadero compete a la fe y creencias de cada persona, y no del estudio de los mitos.

Ejemplo de ello, son los sacerdotes y rabinos de hoy en día dentro de los movimientos judíos y cristianos más liberales, además de los neopaganos, que no tienen problemas en admitir que sus textos religiosos contienen mitos. Así, ven sus textos sagrados como verdades religiosas, reveladas por inspiración divina, pero mostradas en el lenguaje del género humano. Aun así, como sucede en todo ámbito, otros, al contrario, no están de acuerdo con ello.

Aunque normalmente mucha gente relaciona a la mitología con culturas antiguas o religiones; no siempre es así. Por ejemplo, series de televisión, libros e historietas, y juegos de rol entre otros, que logran formar un universo ficticio propio; adquieren componentes mitológicos muy importantes que incluso a veces pueden llegar a dar lugar a profundos y complicados sistemas filosóficos. Un ejemplo excelente de este tipo de mitología es la desarrollada por J. R. R. Tolkien en sus libros "El Silmarillion" y "El Señor de los Anillos", entre otros escritos, a la que él denominó "legendarium", o Los Mitos de Cthulhu, que surgen de la unificación de las novelas de H.P. Lovecraft y su círculo. Estos últimos explican todo el universo partiendo de una física desconocida (ya que supone que nuestros conocimientos del universo y de las ciencias tienen premisas erróneas), y la no existencia de Dios, donde criaturas de más allá de la comprensión humana habitan el universo desde el principio de los tiempos. Según esto, la humanidad es una simple mota de polvo sin importancia para ellos. A nuestros ojos son como dioses, denominados primigenios, y los más poderosos de entre ellos, dioses exteriores y dioses arquetípicos.

Otros ejemplos que se pueden mencionar son los mundos ficticios creados por las novelas de "Dragonlance", la serie "Star Trek", las películas de "Star Wars", o el manga "Saint Seiya".

Algunos críticos opinan que por el hecho de que los personajes principales y los ciclos de historias de las narraciones modernas no sean de dominio público, las leyes sobre derechos de autor impiden a los autores independientes continuar ciclos de historias modernas, evitando que dichas sagas de personajes compartan algunas de las características esenciales de las mitologías; por lo menos, hasta que se cumpla el plazo de derechos de autor y pasen a ser de dominio público. A pesar de eso, los propietarios de los derechos de autor en ocasiones continúan las historias con otros autores, como es el caso de personajes como Tarzán y las novelas de Conan (originarias de Robert E. Howard) de L. Sprague de Camp, o los cómics de superhéroes, la mayoría de los cuales han tenido docenas de autores.

Durante el siglo XIX, las más importantes fueron:

En el siglo XX las tendencias para explicar la mitología son:

A pesar de que muchas de las ya citadas interpretaciones sigan vigentes hoy en día, en el siglo XXI surge la mitocrítica cultural de la mano del teórico literario José Manuel Losada.

La mitocrítica cultural debe desarrollar una epistemología que permita aprehender y explicar una realidad imaginaria y global, encaminada a una mayor comprensión de la cultura actual. Esta disciplina resulta de las siguientes premisas hermenéuticas:


En consecuencia con esta última premisa, la mitocrítica, sin abandonar el análisis del imaginario simbólico, invade cualquier manifestación cultural. Esta nueva mitocrítica se encarga de estudiar las manifestaciones míticas en campos tan amplios como la literatura, el cine y la televisión, el teatro, la escultura, la pintura, los videojuegos, la música, la danza, el periodismo, Internet y demás medios de manifestación cultural y artística.

La mitología, además de ser una forma de lenguaje, es una forma de vida que han creado ciertos grupos sociales. Por esta razón, se estima que la sociología moderna, en casi su totalidad, no se ocupa de eventos que tengan que ver con sucesos de apariencia "no comprobable" en relación con las creencias y vivencias de comunidades indígenas. Hay que tener en cuenta que estas sociedades, en medio de su "no intelectualidad", manejan unas formas de ver el mundo, en las que las sociedades denominadas "civilizadas o intelectuales", no tienen la capacidad de observarlos. Se pueden apreciar en experiencias, tal vez inexplicables ante los ojos de la ciencia, pero explicables ante la experiencia. Cabe indicar que no todo lo comprobable existe realmente.


En el actual calendario, denominado gregoriano, los meses y los días de la semana tienen algunos nombres derivados de seres y dioses mitológicos. Este hecho es evidente en idiomas como el español, aunque no significa que provengan de la mitología propia; así, en castellano, el día viernes proviene de Venus, diosa de la mitología romana (en idioma inglés el nombre del mismo día, "Friday", procede de la diosa germana Freyja); en ambos casos estaría dedicado a seres con ciertas similitudes, a las diosas de la belleza.




</doc>
<doc id="1911" url="https://es.wikipedia.org/wiki?curid=1911" title="Mitología griega">
Mitología griega

La mitología griega es el conjunto de mitos y leyendas pertenecientes a la cultura de la Antigua Grecia, que tratan de sus dioses y héroes, la naturaleza del mundo, los orígenes y el significado de sus propios cultos y prácticas rituales. Formaban parte de la religión de la Antigua Grecia, que tenía como objeto de culto básicamente a los dioses olímpicos. Los investigadores modernos recurren a los mitos y los estudian en un intento por arrojar luz sobre las instituciones religiosas y políticas de la antigua Grecia y su civilización, así como para entender mejor la naturaleza de la propia creación de los mitos.

La mitología griega aparece explícitamente en una extensa colección de relatos e implícitamente en artes figurativas tales como cerámica pintada y ofrendas votivas. Los mitos griegos intentan explicar los orígenes del mundo y detallan las vidas y aventuras de una amplia variedad de dioses, héroes y otras criaturas mitológicas. Estos relatos fueron originalmente difundidos en una tradición poética oral, si bien actualmente los mitos se conocen principalmente gracias a la literatura griega.

Las fuentes literarias más antiguas conocidas, los poemas épicos de la "Ilíada" y la "Odisea", se centran en los sucesos en torno a la guerra de Troya. Dos poemas del casi contemporáneo de Homero, Hesíodo, la "Teogonía" y los "Trabajos y días", contienen relatos sobre la génesis del mundo, la sucesión de gobernantes divinos y épocas humanas y el origen de las tragedias humanas y las costumbres sacrificiales. También se conservaron mitos en los himnos homéricos, en fragmentos de poesía épica del ciclo troyano, en poemas líricos, en las obras de los dramaturgos del siglo V a. C., en escritos de los investigadores y poetas del período helenístico y en textos de la época del Imperio romano de autores como Plutarco y Pausanias.

Los hallazgos arqueológicos suponen una importante fuente de detalles sobre la mitología griega, con dioses y héroes presentes prominentemente en la decoración de muchos objetos. Diseños geométricos sobre cerámica del siglo VIII a. C. representan escenas del ciclo troyano, así como aventuras de Heracles. En los subsiguientes periodos arcaico, clásico y helenístico aparecen escenas mitológicas homéricas y de otras varias fuentes para complementar la evidencia literaria existente.

La mitología griega ha ejercido una amplia influencia sobre la cultura, el arte y la literatura de la civilización occidental y sigue siendo parte del patrimonio y lenguaje cultural occidentales. Poetas y artistas han hallado inspiración en ella desde las épocas antiguas hasta la actualidad y han descubierto significado y relevancia contemporáneos en los temas mitológicos clásicos.

La mitología griega se conoce en la actualidad primordialmente por la literatura griega y por representaciones míticas sobre medios plásticos fechados desde el periodo geométrico (sobre 900–800 a. C.) en adelante.

Los relatos míticos juegan un papel importante en casi todos los géneros de la literatura griega. A pesar de ello, el único manual general mitográfico conservado de la antigüedad griega fue la "Biblioteca mitológica" de Pseudo-Apolodoro. Esta obra intenta reconciliar las historias contradictorias de los poetas y proporciona un gran resumen de la mitología tradicional griega y las leyendas heroicas. Apolodoro vivió entre "c." 180–120 a. C. y escribió sobre muchos de estos temas, pero sin embargo la "Biblioteca" discute sucesos que tuvieron lugar mucho después de su muerte, y de ahí el nombre Pseudo-Apolodoro.

Entre las fuentes literarias más antiguas están los dos poemas épicos de Homero, la "Ilíada" y la "Odisea". Otros poetas completaron el «ciclo épico», pero estos poemas menores posteriores se han perdido casi en su totalidad. Aparte de su nombre tradicional, los himnos homéricos no tienen relación directa con Homero. Son himnos corales de la parte más antigua de la llamada época lírica. 

Hesíodo, un posible contemporáneo de Homero, ofrece en su "Teogonía" (‘Origen de los dioses’) el relato más completo de los primeros mitos griegos, tratando de la creación del mundo, el origen de los dioses, los Titanes y los Gigantes, incluyendo elaboradas genealogías, relatos populares y mitos etiológicos. Los "Trabajos y días" de Hesíodo, un poema didáctico sobre la vida agrícola, incluye también los mitos de Prometeo, Pandora y las cuatro edades. El poeta da consejo sobre la mejor forma de triunfar en un mundo peligroso, vuelto aún más peligroso por sus dioses.

Los poetas líricos tomaron a menudo sus temas de los mitos, pero el tratamiento se fue haciendo cada vez menos narrativo y más alusivo. Los poetas líricos griegos, incluidos Píndaro, Baquílides y Simónides, y los bucólicos, como Teócrito y Bión, cuentan sucesos mitológicos individuales. Adicionalmente, los mitos fueron cruciales para el drama ateniense clásico. 

Los dramaturgos trágicos Esquilo, Sófocles y Eurípides tomaron la mayoría de sus tramas de la edad de los héroes y la Guerra de Troya. Muchas de las grandes historias trágicas (como Agamenón y sus hijos, Edipo, Jasón, Medea, etcétera) tomaron su forma clásica en estas obras trágicas. El dramaturgo cómico Aristófanes también usó mitos, en "Las aves" y "Las ranas".

Los historiadores Heródoto y Diodoro Sículo y los geógrafos Pausanias y Estrabón, que viajaron por todo el mundo griego y recogieron las historias que oían, proporcionan numerosos mitos y leyendas locales, dando a menudo versiones alternativas poco conocidas. 

En particular Heródoto buscó las diversas tradiciones que se le presentaban y halló las raíces históricas o mitológicas en la confrontación entre Grecia y el Este, intentando reconciliar los orígenes y mezclas de distintos conceptos culturales.

Las "Fabulae" y "De astronomica" del escritor romano conocido como Pseudo-Higino son dos importantes compendios no poéticos de mitos. Otras dos fuentes útiles son las "Imágenes" de Filóstrato el Joven y las "Descripciones" de Calístrato.

Finalmente, Arnobio y varios escritores bizantinos proporcionan detalles importantes de mitos, muchos de ellos procedentes de obras griegas anteriores actualmente perdidas. Entre estos se incluyen un léxico de Hesiquio, la "Suda" y los tratados de Juan Tzetzes y Eustacio. El punto de vista moralizador sobre los mitos griegos se resume en el dicho ἐν παντὶ μύθῳ καὶ τὸ Δαιδάλου μύσος "en panti muthōi kai to Daidalou musos" (‘en todo mito está la profanación de Dédalo’), sobre el que dice la "Suda" que alude al papel de Dédalo al satisfacer la «lujuria antinatural» de Pasífae por el toro de Poseidón: «Dado que el origen y culpa de estos males se atribuyeron a Dédalo y fue odiado por ellos, se convirtió en el objeto del proverbio.»

Bajo la influencia de Homero el culto heroico llevó a una reestructuración de la vida espiritual, expresada en la separación del reino de los dioses del reino de los (héroes) muertos, es decir, los ctónicos de los olímpicos. En los "Trabajos y días" Hesíodo hace uso de un esquema de cuatro edades del hombre (o razas): de oro, de plata, de bronce y de hierro. Estas razas o edades son creaciones separadas de los dioses, correspondiendo la edad dorada al reinado de Crono y siendo las siguientes razas creación de Zeus. Hesíodo intercala la edad (o raza) de los héroes justo tras la edad de bronce. La última edad fue la de hierro, durante la cual vivió el propio poeta, que la consideraba la peor y explicaba la presencia del mal mediante el mito de Pandora, quien derramó de la jarra todas las mejores características humanas salvo la esperanza. En "Las metamorfosis" Ovidio sigue el concepto de Hesíodo de las cuatro edades.

También hay que mencionar la aportación de la poesía de las épocas helenística y romana, aunque fueran obras compuestas como ejercicios literarios más que culturales. Sin embargo, contienen muchos detalles importantes que de otra forma se habrían perdido. Esta categoría incluye las obras de:


El descubrimiento de la civilización micénica por el arqueólogo aficionado alemán Heinrich Schliemann en el siglo XIX y el de la civilización minoica en Creta por el arqueólogo británico sir Arthur Evans en el XX ayudaron a explicar muchas de las preguntas existentes sobre las épicas de Homero y proporcionaron evidencias arqueológicas de muchos de los detalles mitológicos sobre dioses y héroes.

Desafortunadamente, la evidencia sobre mitos y rituales en los yacimientos micénicos y minoicos es completamente monumental, ya que las inscripciones en lineal B (una forma antigua de griego hallado tanto en Creta como en Grecia) fueron usadas principalmente para registrar inventarios, si bien los nombres de dioses y héroes han sido dudosamente revelados.

Los diseños geométricos sobre cerámica del siglo VIII a. C. representan escenas del ciclo troyano, así como las aventuras de Heracles. Estas representaciones visuales de los mitos son importantes por dos razones: por una parte muchos mitos griegos son atestiguados en vasijas antes que en fuentes literarias (por ejemplo, de los doce trabajos de Heracles solo la aventura de Cerbero aparece en un texto literario contemporáneo), y por otra las fuentes visuales representan a veces mitos o escenas míticas que no están recogidas en ninguna fuente literaria conservada. 

En algunos casos, la primera representación conocida de un mito en el arte geométrico es anterior en varios siglos a su primera representación conocida en la poesía arcaica tardía. En los periodos arcaico ("c." 750-500 a. C.), clásico ("c." 480-323 a. C.) y helenístico aparecen escenas homéricas y varias otras para complementar las evidencias literarias existentes.

La poesía épica creó ciclos históricos y a consecuencia de ello desarrolló una cronología mitológica. De esta forma la mitología griega se despliega como una fase del desarrollo del mundo y el hombre. Aunque las autocontradicciones de estas historias hacen imposible una línea temporal absoluta, sí puede discernirse una cronología aproximada. La historia mitológica del mundo puede dividirse en tres o cuatro grandes periodos:


Mientras la edad de los dioses ha sido con frecuencia más interesante para los estudiosos de la mitología contemporáneos, los autores griegos de las eras arcaica y clásica tuvieron una clara preferencia por la edad de los héroes, estableciendo una cronología y registrando los logros humanos con los que responder las preguntas sobre cómo el mundo fue creado. Por ejemplo, las heroicas "Ilíada" y "Odisea" empequeñecían a la "Teogonía" y los himnos homéricos tanto en extensión como en popularidad. 

Los «mitos de origen» o «mitos de creación» representan un intento por hacer comprensible el universo en términos humanos y explicar el origen del mundo. La versión más ampliamente aceptada en la época, si bien un relato filosófico del comienzo de las cosas, es la recogida por Hesíodo en su "Teogonía". Empieza con el Caos, un profundo vacío. De este emergió Gea (la Tierra) y algunos otros seres divinos primordiales: Eros (Amor), el Abismo (Tártaro) y el Érebo. 

Sin ayuda masculina, Gea dio a luz a Urano (el Cielo), que entonces la fertilizó. De esta unión nacieron primero los Titanes: Océano, Ceo, Crío, Hiperión, Jápeto, Tea, Rea, Temis, Mnemósine, Febe, Tetis y Crono. Tras este, Gea y Urano decretaron que no nacerían más titanes, de forma que siguieron los Cíclopes de un solo ojo y los Hecatónquiros o Centimanos. Crono, "«el más joven, de mente retorcida, el más terrible de los hijos de Gea»," a pedir de las quejas de Gea, este castró a su padre y se convirtió en el gobernante de los dioses con su hermana y esposa Rea como consorte y los otros Titanes como su corte. Generalmente la tradición griega señala que de esta castración, surgió Afrodita, emergida del mar, tras caer los testículos de su padre sobre el océano.

El tema de conflicto padre-hijo se repitió cuando Crono se enfrentó con su hijo, Zeus. Tras haber traicionado a su padre, Crono temía que su descendencia hiciera lo mismo, por lo que cada vez que Rea daba a luz un hijo, él lo secuestraba y se los tragaba. Rea lo odiaba y lo engañó escondiendo a Zeus, el último de sus hijos, y envolviendo una piedra en pañales, que Crono se tragó. Rea crio a Zeus en el monte Ida de Creta, siendo alimentado por una cabra, cuando Zeus creció, dio a su padre un veneno que lo obligó a vomitar a sus hermanos y a la piedra, que habían permanecido en el estómago de Crono todo el tiempo.

Zeus luchó contra su padre, Cronos, por el trono de la Tierra, por lo que se desató una guerra de dioses contra titanes. Junto a sus hermanos Poseidón y Hades e hijos (luego integrantes del panteón olímpico) con la ayuda de los Cíclopes (a quienes liberó del Tártaro) los cuales otorgaron a cada hermano un arma, Zeus y sus hermanos lograron la victoria, condenando a Crono y los Titanes a prisión en el Tártaro, el centro de la Tierra..

De esta manera se aseguraron el control sobre la Tierra, que quedó dividido en tres reinos: "la trinidad" consistía en el Cielo para Zeus, el océano para Poseidón, y el inframundo para Hades, quien custodia que los titanes no salgan de Tártaro. 

Zeus sufrió la misma preocupación y, después de que fuera profetizado que su primera esposa Metis daría a luz un dios «más grande que él», se la tragó. Sin embargo Metis ya estaba encinta de Atenea y esto lo entristeció hasta que ésta brotó de su cabeza, adulta y vestida para la guerra. Este «renacimiento» de Atenea fue usado como excusa para explicar por qué no fue derrocado por la siguiente generación de dioses, al tiempo que explica su presencia. Es probable que los cambios culturales ya en progreso absorbieran el arraigado culto local de Atenea en Atenas dentro del cambiante panteón olímpico sin conflicto porque no podía ser derrocado, dado que tanto él, como sus hermanos e sus hijos, lucharon en conjunto. 

El pensamiento griego antiguo sobre poesía consideraba la teogonía como el género poético prototípico —el "mythos" prototípico— y le atribuía poderes casi mágicos. Orfeo, el poeta arquetípico, era también el arquetipo de cantante de teogonías, que usaba para calmar mares y tormentas en las "Argonáuticas" de Apolonio, y para conmover los pétreos corazones de los dioses del inframundo en su descenso al Hades. Cuando Hermes inventa la lira en el "Himno homérico a Hermes", lo primero que hace es cantar el nacimiento de los dioses.

La "Teogonía" de Hesíodo no es sólo el relato sobre los dioses conservado más completo, sino también el relato conservado más completo de la función arcaica de los poetas, con su larga invocación preliminar a las Musas. La teogonía fue también el tema de muchos poemas hoy perdidos, incluidos los atribuidos a Orfeo, Museo, Epiménides, Abaris y otros legendarios videntes, que se usaban en rituales privados de purificación y en ritos mistéricos. 

Hay indicios de que Platón estaba familiarizado con alguna versión de la teogonía órfica. Sin embargo, se esperaba silencio sobre estos ritos y creencias religiosas, y que los miembros de la secta no hablasen sobre su naturaleza mientras creyesen en ellos. Después de que dejaran de ser creencias religiosas, pocos sabían sobre estos ritos y rituales. A menudo existieron alusiones, sin embargo, a aspectos que eran bastante públicos.

Existieron imágenes sobre cerámicas y obras religiosas que fueron interpretados o más probablemente malinterpretados en muchos mitos y leyendas diferentes. Unos pocos fragmentos de estas obras se conservan en citas de filósofos neoplatónicos y fragmentos de papiro recientemente desenterrados. Uno de estos fragmentos, el papiro de Derveni, demuestra actualmente que al menos en el siglo V a. C. existía un poema teogónico-cosmogónico de Orfeo. Este poema intentaba superar a la "Teogonía" de Hesíodo y la genealogía de los dioses se ampliaba con Nix (la Noche) como un comienzo definitivo antes de Urano, Crono y Zeus. La Noche y la Oscuridad podían equipararse al Caos.

Los primeros cosmólogos filosóficos reaccionaron contra, o a veces se basaron en, las concepciones míticas populares que habían existido en el mundo griego por algún tiempo. Algunas de estas concepciones populares pueden ser deducidas de la poesía de Homero y Hesíodo. En Homero, la Tierra era vista como un disco plano flotando en el río de Océano y dominado por un cielo semiesférico con sol, luna y estrellas. 

El Sol (Helios) cruzaba los cielos como auriga y navegaba alrededor de la Tierra en una copa dorada por la noche. Podían dirigirse oraciones y prestar juramentos por el sol, la tierra, el cielo, los ríos y los vientos. Las fisuras naturales se consideraban popularmente entradas a la morada subterránea de Hades, hogar de los muertos.

Según la mitología clásica, tras el derrocamiento de los Titanes el nuevo panteón de dioses y diosas fue confirmado. Entre los principales dioses griegos estaban los olímpicos, residiendo sobre el Olimpo bajo la égida de Zeus. Entre los más importantes, además de Zeus, figuran Poseidón, Hades, Apolo, Atenea, Artemisa, Afrodita, Ares, Dioniso, Hestia, Hermes, Hefesto y Hera.

Cuando se aludía a estos dioses en la poesía, la oración o los cultos, se hacía mediante una combinación de su nombre y epítetos, que los identificaban por estas distinciones del resto de sus propias manifestaciones. Alternativamente el epíteto puede identificar un aspecto particular o local del dios. 

La mayoría de los dioses están relacionados con aspectos humanos y específicos de la vida (se incluyen mayormente el zodiaco occidental). Por ejemplo, Afrodita era la diosa del amor y la belleza, mientras Ares era el dios de la guerra, Hades el de los muertos y Atenea la diosa de la sabiduría y la estrategia. Algunas deidades como Apolo (dios de la música) y Dioniso (dios del vino), revelaban personalidades más complejas y funciones varias, mientras Hestia significa literalmente ‘hogar’.Aparte de estos, los griegos adoraban a diversos dioses, considerados secundarios. Las musas de Apolo, vinculadas con el conocimiento y las bellas artes. El semidiós rústico Pan, las ninfas, náyades (que moraban en las fuentes), dríades (en los árboles) y nereidas (en el mar), oceánidas, sátiros y otros. 

Además, había poderes oscuros del inframundo, como las Erinias (o Furias), que se decía que perseguían a los culpables de crímenes contra los parientes. Para honrar al antiguo panteón griego, los poetas compusieron los himnos homéricos (un conjunto de 33 canciones). Gregory Nagy considera a «los más extensos himnos homéricos como simples preludios (comparados con la "Teogonía"), cada uno de los cuales invoca a un dios».

En la amplia variedad de mitos y leyendas que forman la mitología griega, las deidades que eran nativas de los pueblos griegos se describían como esencialmente humanas pero con cuerpos ideales. 

Según Walter Burkert la característica definitoria del antropomorfismo griego es que «los dioses griegos son personas, no abstracciones, ideas o conceptos». Con independencia de sus formas esenciales, los antiguos dioses griegos tienen muchas habilidades fantásticas, siendo la más importante ser inmunes a las enfermedades y poder resultar heridos sólo bajo circunstancias altamente inusuales.

Los griegos consideraban la inmortalidad como característica distintiva de los dioses; inmortalidad que, al igual que su eterna juventud, era asegurada mediante el constante uso de néctar y ambrosía, que renovaba la sangre divina en sus venas.

Cada dios desciende de su propia genealogía, persigue intereses diferentes, tiene una cierta área de su especialidad y está guiado por una personalidad única; sin embargo, estas descripciones emanan de una multitud de variantes locales arcaicas, que no siempre coinciden entre ellas. 

Los templos más impresionantes tendían a estar dedicados a un número limitado de dioses, que fueron el centro de grandes cultos panhelénicos. Era sin embargo común que muchas regiones y poblaciones dedicasen sus propios cultos a dioses menores. Muchas ciudades también honraban a los dioses más conocidos con ritos locales característicos y les asociaban extraños mitos desconocidos en los demás lugares. Durante la era heroica, el culto a los héroes (o semidioses) complementó a la de los dioses.

Uniendo la edad en la que los dioses vivían solos y la edad en la que la interferencia divina en los asuntos humanos era limitada había una edad de transición en la que los dioses y los mortales se mezclaban libremente. Fueron estos los primeros días del mundo, cuando los grupos se mezclaban más libremente de lo que lo harían luego. La mayoría de estas historias fueron luego narradas por Ovidio en "Las metamorfosis" y se dividen a menudo en dos grupos temáticos: historias de amor e historias de castigo.

Las historias de amor solían incluir el incesto o la seducción o violación de una mujer mortal por parte de un dios, resultando en una descendencia heroica. Estas historias sugieren generalmente que las relaciones entre dioses y mortales son algo a evitar, incluso las relaciones consentidas raramente tienen finales felices. En unos pocos casos, una divinidad femenina se empareja con un hombre mortal, como en el "Himno homérico a Afrodita", donde la diosa yace con Anquises concibiendo a Eneas.

El segundo tipo de historias (las de castigo) trata de la apropiación o invención de algún artefacto cultural importante, como cuando Prometeo roba el fuego a los dioses, cuando este o Licaón inventa el sacrificio, cuando Tántalo roba néctar y ambrosía de la mesa de Zeus y los da a sus propios súbditos, revelándoles los secretos de los dioses, cuando Deméter enseña la agricultura y los Misterios a Triptólemo, o cuando Marsias inventa el aulos y se enfrenta en un concurso musical con Apolo. Ian Morris considera las aventuras de Prometeo «un punto entre la historia de los dioses y la del hombre». Un fragmento de papiro anónimo, datado en el siglo III a. C., retrata vívidamente el castigo de Dioniso al rey de Tracia, Licurgo, cuyo reconocimiento del nuevo dios llegó demasiado tarde, ocasionando horribles castigos que se extendieron hasta la otra vida. La historia de la llegada de Dioniso para establecer su culto en Tracia fue también el tema de una trilogía esquiliana. En otra tragedia, "Las bacantes" de Eurípides, el rey de Tebas, Penteo, es castigado por Dioniso por haber sido irrespetuoso con él y espiado a las Ménades, sus adoradoras.

En otra historia, basada en un antiguo tema folclórico y reflejando otro tema parecido, Deméter estaba buscando a su hija Perséfone tras haber tomado la forma de una anciana llamada Doso y recibió la hospitalaria bienvenida de Céleo, el rey de Eleusis en Ática. Como regalo para Céleo por su hospitalidad, Deméter planeó hacer inmortal a su hijo Demofonte, pero no pudo completar el ritual porque su madre Metanira la sorprendió poniendo al niño en el fuego y chilló asustada, lo que enfureció a Deméter, quien lamentó que "los estúpidos mortales no entendiesen el ritual".

La época en la que vivieron los héroes se conoce como edad heroica. La poesía épica y genealógica creó ciclos de historias agrupadas en torno a héroes o sucesos particulares y estableció las relaciones familiares entre los héroes de las diferentes historias, organizando así las historias en secuencia. Según Ken Dowden «hay incluso un efecto saga: podemos seguir los destinos de algunas familias en generaciones sucesivas».

Tras la aparición del culto heroico, los dioses y los héroes constituyen la esfera sacra y son invocados juntos en los juramentos, dirigiéndoseles oraciones. En contraste con la edad de los dioses, durante la heroica la relación de héroes carece de forma fija y definitiva; ya no nacen grandes dioses, pero siempre pueden surgir nuevos dioses del ejército de los muertos. 

Otra importante diferencia entre el culto a los héroes y a los dioses es que el héroe se convierte en el centro de la identidad del grupo local.Los sucesos monumentales de Heracles se consideran el comienzo de la edad de los héroes. También se adscriben a ella tres grandes sucesos: la expedición argonáutica y las guerras de Tebas y Troya.

Algunos investigadores creen que tras la complicada mitología de Heracles probablemente hubo un hombre real, quizás un cacique-vasallo del reino de Argos. Otros sugieren que la historia de Heracles es una alegoría del paso anual del sol por las doce constelaciones del zodiaco. Y otros señalan mitos anteriores de otras culturas, mostrando la historia de Heracles como una adaptación local de mitos heroicos ya bien asentados. Tradicionalmente Heracles era el hijo de Zeus y Alcmena, nieta de Perseo. Sus fantásticas hazañas en solitario, con sus muchos temas folclóricos, proporcionaron mucho material a las leyendas populares. Es retratado como un sacrificador, mencionado como fundador de los altares e imaginado como un comensal voraz, papel este en el que aparece en las comedias, mientras su lamentable final proporcionó mucho material para las tragedias: "Heracles" es considerada por Thalia Papadopoulou «una obra de gran importancia para el examen de otros dramas euripideos». En el arte y la literatura Heracles era representado como un hombre enormemente fuerte de altura moderada, siendo su arma característica el arco pero también frecuentemente la clava. Las vasijas pintadas demuestran la popularidad inigualable de Heracles, apareciendo su lucha con el león muchos cientos de veces.

Heracles también entró en la mitología y el culto etruscos y romanos, y la exclamación "mehercule" se hizo tan familiar a los romanos como "Herakleis" lo fue para los griegos. En Italia fue adorado como un dios de los mercaderes y el comercio, si bien otros también le rezaban por sus dones característicos de buena suerte y rescate del peligro.

Heracles logró el más alto prestigio social mediante su puesto de ancestro oficial de los reyes dorios. Esto sirvió probablemente como legitimación para las migraciones dorias al Peloponeso. Hilo, el héroe epónimo de una tribu doria, se convirtió en un Heráclida, nombre que recibían los numerosos descendientes de Heracles, entre los que se contaban Macaria, Lamos, Manto, Bianor, Tlepólemo y Télefo. Estos Heráclidas conquistaron los reinos peloponesos de Micenas, Esparta y Argos, reclamando según la leyenda el derecho a gobernarlos debido a su ascendencia. Su ascenso al poder se denomina frecuentemente «invasión doria». Los reyes lidios y más tarde los macedonios, como gobernantes del mismo rango, también pasaron a ser Heráclidas.

Otros miembros de la primera generación de héroes, como Perseo, Deucalión y Belerofonte, tienen muchos rasgos en común con Heracles. Como él, sus hazañas son en solitario, con tintes fantásticos y metafóricos, puesto que enfrentaron y mataron a monstruos como Quimera y Medusa. Esta última tenía la habilidad de petrificar a sus enemigos con la mirada, por lo que cada dios proveyó a Perseo de un elemento particular para derrotarla. Enviar a un héroe a una muerte segura es también un tema frecuente en esta primera tradición heroica, como en los casos de Perseo y Belerofonte.

La única épica helenística conservada, las "Argonáuticas" de Apolonio de Rodas (poeta épico, investigador y director de la Biblioteca de Alejandría) narra el mito del viaje de Jasón y los Argonautas para recuperar el vellocino de oro de la mítica tierra de Cólquida. En las "Argonáuticas" Jasón es empujado a su búsqueda por el rey Pelias, quien recibe una profecía sobre un hombre con una sandalia que sería su némesis. Jasón pierde una sandalia en un río, llegando a la corte de Pelias e iniciando así la épica. Casi todos los miembros de la siguiente generación de héroes, además de Heracles, fueron con Jasón en el "Argo" para buscar el vellocino de oro. Esta generación también incluía a Teseo, que fue a Creta a matar al Minotauro, a la heroína Atalanta y a Meleagro, que una vez tuvo un ciclo épico propio que rivalizaba con la "Ilíada" y la "Odisea". Píndaro, Apolonio y Apolodoro se esforzaron en dar listas completas de los Argonautas. 

Aunque Apolonio escribió su poema en el siglo III a. C., la composición de la historia de los Argonautas es anterior a la "Odisea", que muestra familiaridad con las hazañas de Jasón (las andanzas de Odiseo pueden haber estado parcialmente basadas en ellas). En épocas antiguas la expedición se consideraba un hecho histórico, un incidente en la apertura del mar Negro al comercio y la colonización griegas. También fue extremadamente popular, constituyendo un ciclo al que se adjuntaron muchas leyendas locales. En particular, la historia de Medea cautivó la imaginación de los poetas trágicos.

Entre el "Argo" y la Guerra de Troya hubo una generación conocida principalmente por sus horrendos crímenes. Estos incluyen los hechos de Atreo y Tiestes en Argos. Tras el mito de la casa de Atreo (una de las dos principales dinastías heroicas junto con la casa de Lábdaco) está el problema de la devolución de poder y la forma de ascensión al trono. Los gemelos Atreo y Tiestes con sus descendientes jugaron el papel protagonista en la tragedia de la devolución de poder en Micenas.

El ciclo tebano trata de los sucesos relacionados especialmente con Cadmo, el fundador de la ciudad, y posteriormente con los hechos de Layo y Edipo en Tebas, una serie de historias que llevaron al saqueo final de la ciudad a manos de "Los siete contra Tebas" y los Epígonos. (No se sabe si figuraban en la épica original.) En lo referente a Edipo, los relatos épicos antiguos parecen dejarle seguir gobernando en Tebas tras la revelación de que Yocasta era su madre, y desposando luego a una segunda esposa que se convirtió en madre de sus hijos, lo que resulta muy diferente a la historia que conocemos por las tragedias (por ejemplo, el "Edipo rey" de Sófocles) y los relatos mitológicos posteriores.

La mitología griega culmina en la Guerra de Troya, la lucha entre los griegos ("aqueos") y los troyanos, incluyendo sus causas y consecuencias. En las obras de Homero las principales historias ya han tomado forma y sustancia, y los temas individuales fueron elaborados más tarde, especialmente en los dramas griegos. La Guerra de Troya atrajo también gran interés en la cultura romana debido a la historia del héroe troyano Eneas, cuyo viaje desde Troya llevó a la fundación de la ciudad que un día se convertiría en Roma, recogida por Virgilio en la "Eneida" (cuyo Libro II contiene el relato más conocido del saqueo de Troya). Finalmente hay dos pseudo-crónicas escritas en latín que pasaron bajo los nombre de Dictis Cretense y Dares Frigio.

El ciclo de la Guerra de Troya, una colección de poemas épicos, comienza con los sucesos que desencadenaron la guerra: Eris y la manzana dorada ‘para la más bella’ ("kallisti"), el juicio de Paris, el rapto de Helena y el sacrificio de Ifigenia en Áulide. Para rescatar a Helena, los griegos organizaron una gran expedición bajo el mando del hermano de Menelao, Agamenón, rey de Argos o Micenas, pero los troyanos se negaron a liberarla. La "Ilíada", que se desarrolla en el décimo año de la guerra, cuenta la disputa de Agamenón con Aquiles, que era el mejor guerrero griego, y las consiguientes muertes en batalla del amigo de Aquiles, Patroclo, y del hijo mayor de Príamo, Héctor. Tras la muerte de este se unieron a los troyanos dos exóticos aliados: Pentesilea, reina de las Amazonas, y Memnón, rey de los etíopes e hijo de la diosa de la aurora Eos. Aquiles mató a ambos, pero Paris logró entonces matarlo con una flecha en el talón, la única parte de su cuerpo vulnerable a las armas humanas. Antes de que pudieran tomar Troya, los griegos tuvieron que robar de la ciudadela la imagen de madera de Palas Atenea (el Paladio). Finalmente, con la ayuda de Atenea construyeron el caballo de Troya. A pesar de las advertencias de la hija de Príamo, Casandra, los troyanos fueron convencidos por Sinón, un griego que había fingido su deserción, para llevar el caballo dentro de las murallas de Troya como ofrenda para Atenea. El sacerdote Laocoonte, que intentó destruir el caballo, fue muerto por serpientes marinas. Al anochecer la flota griega regresó y los guerreros del caballo abrieron las puertas de la ciudad. En el completo saqueo que siguió, Príamo y sus restantes hijos fueron asesinados, pasando las mujeres troyanas a ser esclavas en varias ciudades de Grecia. Los aventurados viajes de regreso de los líderes griegos (incluidos los vagabundeos de Odiseo y Eneas, y el asesinato de Agamenón) fueron narrados en dos épicas, los "Regresos" ("Nostoi", hoy perdida) y la "Odisea" de Homero. El ciclo troyano también incluye las aventuras de los hijos de la generación troyana (por ejemplo Orestes y Telémaco).

El ciclo troyano proporcionó una variedad de temas y se convirtió en una fuente principal de inspiración para los antiguos artistas griegos (por ejemplo, las metopas del Partenón representando el saqueo de Troya). Esta preferencia artística por los temas procedentes del ciclo troyano indica su importancia para la antigua civilización griega. El mismo ciclo mitológico también inspiró una serie de obras literarias europeas posteriores. Por ejemplo, los escritores europeos medievales troyanos, desconocedores de la obra de Homero, hallaron en la leyenda de Troya una rica fuente de historias heroicas y románticas y un marco adecuado en el que encajar sus propios ideales cortesanos y caballerescos. Autores del siglo XII, como Benoît de Sainte-Maure ("Poema de Troya", 1154–60) y José Iscano ("De bello troiano", 1183) describen la guerra mientras reescriben la versión estándar que encontraron en Dictis y Dares, siguiendo así el consejo de Horacio y el ejemplo de Virgilio: reescribir un poema de Troya en lugar de contar algo completamente nuevo.

La mitología griega ha cambiado con el tiempo para acomodar la evolución de su propia cultura, de la que la mitología es un índice, tanto expresamente como en sus asunciones implícitas. En las formas literarias conservadas de la mitología griega, como se hallan al final de los cambios progresivos, es inherentemente política.

La mitología estaba en el corazón de la vida cotidiana en la antigua Grecia. Los griegos consideraban la mitología una parte de su historia. Usaban los mitos para explicar fenómenos naturales, diferencias culturales, enemistades y amistades tradicionales. Era una fuente de orgullo ser capaz de seguir la ascendencia de los propios dirigentes hasta un héroe mitológico o un dios. Pocos dudaban de la base real del relato de la Guerra de Troya en la "Ilíada" y la "Odisea". Según Victor Davis Hanson y John Heath el conocimiento profundo de la épica homérica era considerado por los griegos la base de su culturización. Homero era la «educación de Grecia» (Ἑλλάδος παίδευσις) y su poesía «el Libro».

Tras el auge de la filosofía, la historia, la prosa y el racionalismo a finales del siglo V a. C. el destino de los mitos se volvió incierto y las genealogías mitológicas dieron lugar a una concepción de la historia que intentó excluir lo supernatural (tales como la historia tucididiana). Mientras los poetas y dramaturgos estaban reelaborando los mitos, los historiadores y filósofos griegos estaban empezando a criticarlos.

Unos pocos filósofos radicales como Jenófanes de Colofón estaban ya comenzando a etiquetar las historias de los poetas como mentiras blasfemas en el siglo VI a. C.: Jenófanes se había quejado de que Homero y Hesíodo atribuyesen a los dioses «todo lo que es vergonzoso y desgraciado entre los hombres: el robo, la comisión de adulterios y el engaño mutuo». Esta línea de pensamiento encontró su expresión más dramática en "La República" y las "Leyes" de Platón, quien creó sus propios mitos alegóricos (como el de Er en "La República") atacando los relatos tradicionales de los engaños, robos y adulterios divinos como inmorales y oponiéndose a su papel central en la literatura. La crítica de Platón fue el primer desafío serio a la tradición mitológica homérica, refiriéndose a los mitos como «parloteo de mujeres viejas». Por su parte Aristóteles criticó el enfoque filosófico presocrático cuasi-mitológico y subrayó que «Hesíodo y los escritores teológicos estaban preocupados sólo por que les parecía plausible y no tenían respeto por nosotros [...] Pero no merece la pena tomar en serio a escritores que alardean en el estilo mitológico; respecto a aquellos que proceden a demostrar sus afirmaciones debemos reexaminarlos».

Sin embargo, ni siquiera Platón logró destetar a su sociedad de la influencia de los mitos: su propia caracterización de Sócrates está basada en los patrones tradicionales homéricos y trágicos, usados por el filósofo para alabar la recta vida de su maestro:

Hanson y Heath estiman que el rechazo de Platón de la tradición homérica no fue recibido favorablemente por la base de la civilización griega. Los viejos mitos se mantuvieron vivos en cultos locales y siguieron influyendo en la poesía y constituyendo el tema principal de la pintura y la escultura.

Más deportivamente, el escritor de tragedias del siglo V a. C., Eurípides, jugó frecuentemente con las viejas tradiciones, burlándose de ellas e infundiendo notas de duda a través de la voz de sus personajes, si bien los temas de sus obras fueron tomados, sin excepción, de los mitos. Muchas de estas obras fueron escritas en respuesta a la versión de un predecesor del mismo o parecido mito. Eurípides impugna principalmente los mitos sobre los dioses y comienza su crítica con una objeción parecida a una previamente expresada por Jenócrates: los dioses, como se representaban tradicionalmente, son demasiado insensiblemente antropomórficos.

Durante el período helenístico, la mitología adquirió el prestigio de conocimiento elitista que señalaba a sus poseedores como pertenecientes a cierta clase. Al mismo tiempo, el giro escéptico de la edad clásica se hizo incluso más pronunciado. El mitógrafo griego Evémero fundó la tradición de buscar una base histórica real para los seres y sucesos mitológicos. Aunque su obra original ("Escrituras sagradas") se ha perdido, se sabe mucho de ella por lo que registraron Diodoro Sículo y Lactancio.

Las hermenéuticas racionalizadoras de la mitología se hicieron aún más populares bajo el Imperio romano, gracias a las teorías fisicalistas de la filosofía estoica y epicúrea. Los estoicos presentaban explicaciones de los dioses y los héroes como fenómenos físicos, mientras los evemeristas los racionalizaban como personajes históricos. Al mismo tiempo, los estoicos y los neoplatónicos promovían los significados morales de la tradición mitológica, basados a menudo en las etimologías griegas. Mediante su mensaje epicúreo, Lucrecio había buscado expulsar los temores supersticiosos de las mentes de sus conciudadanos. Livio también fue escéptico respecto a la tradición mitológica y afirmaba que no intentaba enjuiciar tales leyendas ("fabulae"). El desafío para los romanos con un fuerte sentido apologético de la tradición religiosa era defender esa tradición mientras concedían que a menudo era un caldo de cultivo para la superstición. El anticuario Varrón, que consideraba la religión una institución humana de gran importancia para la preservación del bien en la sociedad, dedicó rigurosos estudios a los orígenes de los cultos religiosos. En su "Antiquitates Rerum Divinarum" (que no se conserva, aunque "La ciudad de Dios" de Agustín señala su enfoque general) Varrón argumenta que mientras el hombre supersticioso teme a los dioses, la auténtica persona religiosa los venera como a padres. En su obra distinguía tres tipos de dioses:


El académico romano Cayo Aurelio Cota ridiculizó tanto la aceptación literal de los mitos como la alegórica, declarando rotundamente que no tenían lugar en la filosofía. Cicerón desdeñaba generalmente los mitos, pero —como Varrón— hacía énfasis en su apoyo a la religión estatal y sus instituciones. Es difícil saber cuán bajo se extendía este racionalismo en la escala social. Cicerón afirma que nadie (ni siquiera las viejas y los niños) es tan tonto como para creer en los terrores del Hades o la existencia de Escila, los centauros u otras criaturas compuestas, pero por otra parte el orador se queja el resto del tiempo del carácter supersticioso y crédulo de la gente. "De natura deorum" es el resumen más exhaustivo de Cicerón de esta línea de pensamiento.

En la Antigua Roma apareció una nueva mitología romana gracias a la sincretización de numerosos dioses griegos y de otras naciones. Esto ocurrió gracias a que los romanos tenían poca mitología propia y la herencia de la tradición mitológica griega provocó que los principales dioses romanos adoptasen rasgos de sus equivalentes griegos. Los dioses Zeus y Júpiter son un ejemplo de este solapamiento mitológico. Además de la combinación de dos tradiciones mitológicas, la relación de los romanos con religiones orientales llevó a más sincretizaciones. Por ejemplo, el culto del Sol fue introducido en Roma tras las exitosas campañas de Aureliano en Siria. Las divinidades asiáticas Mitra (es decir, el Sol) y Baal fueron combinadas con Apolo y Helios en un solo Sol Invictus, con ritos conglomerados y atributos compuestos. Apolo podía ser cada vez más identificado en la religión con Helios o incluso con Dioniso, pero los textos recapitulando sus mitos rara vez reflejaban estas evoluciones. La mitología literaria tradicional estaba cada vez más disociada de las prácticas religiosas reales.

La colección de himnos órficos y las "Saturnales" de Macrobio, conservadas desde el siglo II, también están influidas por las teorías racionalistas y las tendencias sincréticas. Los himnos órficos son un conjunto de composiciones poéticas preclásicas, atribuidas a Orfeo, a su vez objeto de un renombrado mito. En realidad, estos poemas fueron probablemente compuestos por varios poetas diferentes, y contienen un rico conjunto de indicios sobre la mitología prehistórica europea. La intención declarada de la "Saturnalia" es transmitir la cultura helénica que había obtenido de sus lecturas, incluso aunque mucho de su tratamiento de los dioses está contaminado por la mitología y teología egipcia y norteafricana (que también afectan la interpretación de Virgilio). En la "Saturnalia" reaparecen los comentarios mitográficos influenciados por los evemeristas, estoicos y neoplatónicos.

La génesis de la moderna comprensión de la mitología griega está considerada por algunos investigadores en una doble reacción de finales del siglo XVIII contra «la tradicional actitud de animosidad cristiana», en la que la reinterpretación cristiana de los mitos como una «mentira» o fábula se había conservado. En Alemania, sobre 1795, hubo un creciente interés por Homero y la mitología griega. En Gotinga Johann Matthias Gesner comenzó a revivir los estudios griegos, mientras su sucesor, Christian Gottlob Heyne, trabajó con Johann Joachim Winckelmann y sentó las bases para la investigación mitológica tanto en Alemania como en los demás lugares.

El desarrollo de la filología comparativa en el siglo XIX, junto con los descubrimientos etnológicos del siglo XX, fundó la ciencia de la mitología. Desde el Romanticismo todo el estudio de los mitos ha sido comparativo. Wilhelm Mannhardt, Sir James Frazer y Stith Thompson emplearon el enfoque comparativo para recolectar y clasificar los temas del folclore y la mitología. En 1871 Edward Burnett Tylor publicó su "Primitive Culture", en el que aplicó el método comparativo e intentó explicar el origen y evolución de la religión. El procedimiento de Tylor de agrupar el material cultural, ritual y mítico de culturas ampliamente separadas influyó tanto en Carl Jung como en Joseph Campbell. Max Müller aplicó la nueva ciencia de la mitología comparada al estudio de los mitos, en los que detectó los restos distorsionados del culto a la naturaleza ario. Bronisław Malinowski enfatizó las formas en las que los mitos cumplían funciones sociales comunes. Claude Lévi-Strauss y otros estructuralistas han comparado las relaciones formales y patrones en mitos de todo el mundo.

Sigmund Freud presentó una concepción transhistórica y biológica del hombre y una visión del mito como expresión de ideas reprimidas. La interpretación de los sueños es la base de la interpretación freudiana de los mitos y su concepto de los sueños reconoce la importancia de las relaciones contextuales para la interpretación de cualquier elemento individual de un sueño. Esta sugerencia encontraría un importante punto de acercamiento entre las visiones estructuralista y psicoanalista de los mitos en el pensamiento de Freud. Carl Jung extendió el enfoque transhistórico y psicológico con su teoría del «inconsciente colectivo» y los arquetipos (patrones «arcaicos» heredados), a menudo codificados en los mitos, que surgen de ella. Según Jung, «los elementos estructurales que forman los mitos deben ser presentados en la psique inconsciente». Comparando la metodología de Jung con la teoría de Joseph Campbell, Robert A. Segal concluye que «para interpretar un mito Campbell simplemente identifica los arquetipos en él. Una interpretación de la "Odisea", por ejemplo, mostraría cómo la vida de Odiseo se ajusta a un patrón heroico. Jung, por el contrario, considera la identificación de arquetipos meramente el primer paso en la interpretación de un mito». Károly Kerényi, uno de los fundadores de los estudios modernos de la mitología griega, abandonó sus primeros puntos de vista sobre los mitos para aplicar las teorías de arquetipos de Jung a los mitos griegos, como la reinterpretación de Aquiles y Patroclo.

Hay varias teorías modernas sobre los orígenes de la mitología griega. Según la teoría escritural, todas las leyendas mitológicas proceden de relatos de los textos sagrados, aunque los hechos reales han sufrido modificaciones. Según la teoría histórica todas las personas mencionadas en la mitología fueron una vez seres humanos reales y las leyendas sobre ellas son adiciones de épocas posteriores. Así, se supone que la historia de Eolo surgió del hecho de que este era el gobernante de algunas islas del mar Tirreno. La teoría alegórica supone que todos los mitos antiguos eran alegóricos y simbólicos. Mientras, la teoría física se adhiere a la idea de que los elementos de aire, fuego y agua fueron originalmente objetos de adoración religiosa, por lo que las principales deidades eran personificaciones de estos poderes de la naturaleza. Max Müller intentó comprender una forma religiosa protoindoeuropea determinando su manifestación «original». En 1891, afirmó que «el descubrimiento más importante que se ha hecho en el siglo XIX respecto a la historia antigua de la humanidad [...] fue esta simple ecuación: Dyeus-pitar sánscrito=Zeus griego=Júpiter latino=Tyr nórdico», aunque el equivalente de Zeus en la religión vikinga es Thor u Odín, generalmente suele sincretizarse. En otros casos, los cercanos paralelismos en el carácter y la función sugieren una herencia común, aunque la ausencia de evidencia lingüística haga difícil probarla, como en la comparación entre Urano y el Varuna sánscrito o las Moiras y las Nornas.

Por otra parte, la arqueología y la mitografía han revelado que los griegos fueron inspirados por algunas civilizaciones de Asia Menor y Oriente Próximo. Adonis parece ser el equivalente griego —más claramente en los cultos que en los mitos— de un «dios moribundo» de Oriente Próximo. Cibeles tiene sus raíces en la cultura anatolia mientras gran parte de la iconografía de Afrodita surge de las diosas semíticas. Hay también posibles paralelismos entre las generaciones divinas más antiguas (Caos y sus hijos) y Tiamat en el "Enûma Elish". Según Meyer Reinhold, «los conceptos teogónicos de Oriente Próximo, incluyendo la sucesión divina mediante la violencia y los conflictos generacionales por el poder, hallaron su camino [...] a la mitología griega». Además de los orígenes indoeuropeos y de Oriente Próximo, algunos investigadores han especulado sobre las deudas de la mitología griega con las sociedades prehelénicas: Creta, Micenas, Pilos, Tebas y Orcómeno. Los historiadores de la religión estaban fascinados por varias configuraciones de mitos aparentemente antiguas relacionadas con Creta (el dios como toro, Zeus y Europa, Pasífae que yace con el toro y da a luz al Minotauro, etcétera). El profesor Martin P. Nilsson concluyó que todos los grandes mitos griegos clásicos estaban atados a los centros micénicos y anclados en épocas prehistóricas. Sin embargo, de acuerdo con Burkert la iconografía del periodo del palacio cretense prácticamente no ha dado confirmación alguna a estas teorías.

Cuando el Imperio romano lanzó el edicto de Tesalónica en el siglo IV d. C. como adopción obligatoria del cristianismo como religión oficial, se puso freno definitivo a la popularidad de la mitología griega: se prohibieron los cultos originarios de los pueblos que habían sido conquistados por Roma. Esta volvió paulatinamente, mil años después con el redescubrimiento de la antigüedad clásica en el Renacimiento, en el siglo XV., bajo recelo por parte del clero. Allí entonces, la poesía de Ovidio se convirtió en una influencia importante para la imaginación de los poetas, dramaturgos, músicos y artistas. Desde los primeros años del Renacimiento, artistas como Leonardo da Vinci, Miguel Ángel y Rafael retrataron los temas paganos de la mitología griega (como también del cristianismo), donde se destacaron poetas como Petrarca, Boccaccio y Dante en Italia.

En el norte de Europa la mitología griega alcanzó importancia en las artes visuales, como Rubens, Ferdinand Bol, Rembrandt, Bertel Thorvaldsen, Johan Tobias Sergel, Gyger Hinterglasbild. La mitología griega prendió en la imaginación inglesa de Chaucer y John Milton y siguió a través de Shakespeare hasta Robert Bridges en el siglo XX. Racine en Francia y Goethe en Alemania revivieron el drama griego, reinterpretando los antiguos mitos. Aunque durante la Ilustración se extendió por toda Europa una reacción contra los mitos griegos, estos siguieron siendo una importante fuente de material para los dramaturgos, incluidos los autores de los libretos de muchas óperas de Händel y Mozart. Para finales del siglo XVIII el Romanticismo propició un aumento del entusiasmo por todo lo griego, incluyendo la mitología. En Gran Bretaña, nuevas traducciones de las tragedias griegas y de las obras de Homero inspiraron a poetas (como Alfred Tennyson, Keats, Byron y Shelley) y pintores contemporáneos (como Lord Leighton y Lawrence Alma-Tadema). Gluck, Richard Strauss, Offenbach y muchos otros llevaron los temas mitológicos griegos a la música. Los autores estadounidenses del siglo XIX, como Thomas Bulfinch y Nathaniel Hawthorne, sostuvieron que el estudio de los mitos clásicos era esencial para la comprensión de la literatura inglesa y estadounidense. En épocas más recientes, los temas clásicos han sido reinterpretados por los dramaturgos Jean Anouilh, Jean Cocteau y Jean Giraudoux en Francia, Eugene O'Neill en Estados Unidos y T. S. Eliot en Gran Bretaña, y por novelistas como James Joyce y André Gide.

El culto a las deidades helenas y a los personajes mitológicos tiene lugar en la práctica del helenismo, nombre dado a religión de los antiguos griegos, surgida en los últimos años.

















</doc>
<doc id="1912" url="https://es.wikipedia.org/wiki?curid=1912" title="Modelo electrodébil">
Modelo electrodébil

El modelo electrodébil es una teoría física que unifica la interacción débil y el electromagnetismo, dos de las cuatro fuerzas fundamentales de la naturaleza. A su vez, este modelo se halla incluido en la Teoría de Gran Unificación (GUT), que une la interacción electrodébil con la interacción nuclear fuerte.

El modelo electrodébil fue desarrollado en la década de los años 1960 por Sheldon Lee Glashow, Abdus Salam y Steven Weinberg. La constatación experimental de las interacciones nucleares débiles mediadas por corrientes cargadas (formula_1) les llevó a postular la existencia de las corrientes neutras, las cuales fueron descubiertas en 1973 por la colaboración Gargamelle. Estos tres investigadores recibieron el en 1979.

El modelo electrodébil convencional consiste en una teoría de campos de gauge en que el campo electrodébil es tratado como un campo de Yang-Mills. Es decir, en esa teoría los fermiones son descritos mediante un lagrangiano de Dirac generalizado adecuadamente para que sea invariante gauge bajo un cierto grupo gauge de simetría interna. En la formulación del Modelo Estándar (SM) no existe a priori una elección única de la simetría del lagrangiano de las interacciones electrodébiles. Se deduce, por tanto, de resultados experimentales.

De la evidencia experimental, se deduce que el grupo de simetría gauge mínimo capaz de acomodar las corrientes cargadas es SU(2). La observación empírica ha permitido constatar que las interacciones electrodébiles actúan de manera distinta sobre los fermiones dextrógiros y sobre los fermiones levógiros constituye una de las características de este modelo. La aparición de esta simetría a partir de un lagrangiano originalmente simétrico es explicado formalmente por el mecanismo de ruptura espontánea de simetría. 

Así, las corrientes cargadas de Yang-Mills incluyen solamente fermiones levógiros y no se conocen neutrinos dextrógiros. Es por ello que los campos fermiónicos levógiros son agrupados en dobletes, mientras que los campos dextrógiros son singletes del grupo formula_2 con simetría de isospín (donde el subíndice L únicamente indica la asimetría existente entre los fermiones de distinta helicidad):

Lo que quiere decir que las partículas son representantes de un grupo de gauge formula_3. En la representación anterior no se puede (a menos que se rompa explícitamente la simetría gauge) introducir un término de masa en la lagrangiana que describe la cinemática de los fermiones. No obstante la realidad experimental da cuenta de la existencia de masa en los bosones vectoriales. Por otro lado las fuerzas electromagnética y débil actúan sobre los mismos campos fermiónicos y no pueden ser descritas por separado. Por todo ello, el grupo gauge mínimo que describe las interacciones electrodébiles es formula_4. La simetría gauge local del grupo formula_2 está asociada a la conservación del isospín débil, formula_6. La cantidad conservada por el grupo formula_7 es la hipercarga, formula_8, que se relaciona con la carga eléctrica, formula_9, y con la tercera componente del isospín, formula_10, por medio de la ecuación:

La exigencia de que la lagrangiana que contiene los términos cinemáticos de los campos fermiónicos sea invariante bajo transformaciones gauge definidas por el grupo de simetría formula_4 introduce de manera natural cuatro campos bosónicos sin masa: formula_12 (i = 1, 2, 3), asociados al grupo formula_2, y formula_14, asociado al grupo formula_7. Con estos campos se define la derivada covariante:

donde:

El vector formula_19 está formado por las tres matrices de Pauli generadas por el grupo formula_2.

Finalmente la Lagrangiana electrodébil tendrá una expresión de la forma:

donde las dos lagrangianas describen los campos bosónicos (subíndice "bos.") y fermiónicos (subíndice "ferm.") y pueden escribirse de la forma:
siendo:

No obstante, esta construcción resulta en bosones de masa nula. Sin embargo el hecho experimental de que las interacciones débiles actúan sólo a distancias extremadamente pequeñas, era un indicador claro de que los bosones transmisores de la fuerza débil debían poseer masa, como fue demostrado posteriormente. Un término de masa de la forma formula_24 rompería explícitamente la simetría gauge, haciendo la teoría no renormalizable. El proceso por el cual se consigue introducir los términos de masa en el modelo se denomina ruptura espontánea de simetría electrodébil.




</doc>
<doc id="1915" url="https://es.wikipedia.org/wiki?curid=1915" title="Mach">
Mach

Mach es originalmente un apellido europeo y puede referirse a:


</doc>
<doc id="1924" url="https://es.wikipedia.org/wiki?curid=1924" title="Maranta">
Maranta

Maranta es un género de la familia Marantaceae, contiene alrededor de 30 especies de herbáceas perennes distribuidas por todos los hábitats húmedos de las regiones tropicales.

Son plantas que pueden alcanzar los 50 cm de altura, de vistoso follaje con grandes hojas oblongas, variegadas, manchadas según la especie y variedad en tonos verdes, rojos o crema, de textura aterciopelada y brillante y nervios muy marcados. Poseen raíces tuberosas.

El nombre de este género fue puesto en honor al botánico veneciano del siglo XVI, Bartolomeo Maranta.


</doc>
<doc id="1930" url="https://es.wikipedia.org/wiki?curid=1930" title="Magia">
Magia

La magia, entendida como arte o ciencia oculta, es la creencia y prácticas que buscan producir resultados sobrenaturales mediante rituales, conjuros e invocaciones.

Proviene del latín "magīa", derivado a su vez del griego μαγεία "mageia" (‘cualidad de sobrenatural’), y del griego "magiké" (que presumiblemente se utilizaba en el término «artes mágicas» junto con la palabra "tekhné", ‘artes’), el cual es el femenino de "magikós" (‘mágico’) que proviene de "magos" (‘uno de los miembros de la clase sacerdotal y erudita’).

Este término proviene del antiguo persa "maguš" "(mágush)", que posiblemente proviene de una raíz protoindoeuropea "*magh-", ‘ser capaz’, ‘tener la capacidad’.

Desde esa antiquísima palabra protoindoeuropea (de mediados y fines del III milenio a. C.) se produjo también el sánscrito "māiā" (‘ilusión’, ‘irrealidad’, ‘engaño’, ‘fraude’, ‘truco’, ‘hechicería’, ‘brujería’), que se menciona por primera vez en el "Rig-veda" (el texto más antiguo de la India, de mediados del II milenio a. C.). Esa palabra proviene de la raíz sánscrita "māi" (‘obrar’, ‘mover’).

Inversamente a la teología, a la filosofía y a las ciencias ortodoxas que versan e importan sobre las causas, la magia, para autoformularse y autodefinirse, se define como la manifestación de la supuesta veracidad maravillante de algunos efectos que no requiere averiguar sus causas. Conocer las causas o que el efecto no sea maravilloso extingue la magia y el pensamiento mágico migra a otros tipos de pensamiento, "(de los supuestos «efectos mágicos» se deriva la metonimia histórica con la medicina y la farmacología)".

A través de la aceptación de la existencia de la magia, se acepta implícitamente a esta como la "causa abstracta o seudoabstracta del efecto mágico", como un principio o verdad primaria a partir del cual se desarrolla toda la parafernalia seudológica. Desde tiempos muy remotos, se aspira a develar, a conocer y a usar lo que presumiblemente estaría "oculto" a los sentidos "(cognición)", oculto a la percepción sensorial clásica, a la lógica, a la razón y al criterio. Estos son, como mínimo, los tres elementos esenciales a la magia genérica:

La magia, en su acepción más arcaica, es disidente del axioma racional que afirmaría que el universo estaría exclusivamente gobernado por las «"leyes naturales o materiales"» conocidas o por conocer y habitado solo por la materia. Esta magia arcaica, "con un criterio inherente de dualidad espíritu-materia", dio origen al "pensamiento mágico" y en el entorno de las primeras civilizaciones, a dos clasificaciones evolutivas de la magia, historialmente llamadas «"magia natural"» y «"magias no naturales o filosofías ocultas"».

En algún momento de la historia de la humanidad, estos dos conceptualismos de la magia comenzaron a divergir. El dramaturgo Lope de Vega, en su libro "Pastores de Belén", dedicó unos párrafos para describir literariamente las diferencias de estos conceptos en la cultura de su época:

Magia natural: Se definieron como «"la magia natural"» todos los fenómenos naturales observables en los cuales interviniera o estuviera presente la materia aunque fueran inexplicables. Así fue considerada y desarrollada la astrología por los persas, cuyos artífices eran llamados «"los mágicos o magos"», esta devino en la astronomía. Aún en el siglo XVII, el célebre pedagogo y físico alemán Gaspar Schott "(jesuita)" titulaba sus textos de física "(que él mismo elaboraba y luego impartía a su alumnado)" «magia acústica y magia óptica» "(escritos en latín)", en clara alusión al recuerdo del significado etimológico arcaico de la «"magia natural"», frase reservada en latín para aludir a la fenomenología física todavía inexplicable científicamente en su tiempo, como la luz y el sonido.

Magias no naturales, teologías o filosofías ocultas: En síntesis, una posible definición genérica sería la «"idea de establecer un contacto de relación con cualquier tipo de entidad espiritual o mecanismo sobrenatural"». Contactos de relación, tales como la invocación, evocación, adivinación, numerología o las cábalas, entre muchos otros. Otra clasificación subjetiva y arcaica establecería a las entidades y mecanismos sobrenaturales.


Según J. Frazer, el pensamiento en el que se fundamenta el concepto de la magia consiste en un conjunto de prácticas y creencias a los que individuos de una sociedad recurren para crear un beneficio o conseguir un fin, relacionándolas a su vez con cierto orden en la naturaleza, ya sea como grupo, cuando una limitante natural afecta severamente en la organización social del mismo (una sequía o la infertilidad) (hechicería), o a nivel individual, cuando se requiere, por ejemplo, deshacerse de un enemigo que amenaza la vida (tabú).

Los evolucionistas distinguieron notablemente las profesiones públicas bajo las que se constituía una u otra sociedad;

Representó un punto medular en los estudios que trataron de comprender la organización de sociedades no occidentales que contrastaban con las occidentales. Se puede dividir en dos vertientes de análisis, por los procesos mentales, según los principios abstractos en los que se basa la práctica de la magia, bajo una ley denominada de empatía.

Es por esta razón que en esta línea de pensamiento la magia es predecesora a la religión en una escala evolutiva, es decir, que la magia corresponde a un estadio de grado de evolución de ciertas sociedades consideradas salvajes y la religión a otras que se suponen con mayor grado de civilización. He ahí el interés de su estudio, que trató de comprender el punto en que la magia deja de ser tal para convertirse en religión y así marcar un avance social hacia otro estadio evolutivo.

Frazer entiende a la magia como la expresión de reglas que determinan la consecución de acontecimientos en todo el mundo, como magia teórica; y considerada como una serie de reglas que los humanos cumplirán con objeto de conseguir sus fines, como magia práctica.
Esta se divide en dos tipos, cada uno de ellos se funda bajo los principios de semejanza y contacto:

Para llegar a un entendimiento es necesario recurrir a ejemplos que puedan figurar dentro de estos esquemas. En "La Rama Dorada" de Frazer, en todo momento refiere ejemplos de sociedades exóticas, por así llamarles, que hasta cierto punto parecen estar intactas ante el mundo occidental, aunque lo cierto es que estas sociedades se encontraban ya teniendo contacto con el hombre occidental, quien se hallaba colonizando sus territorios.

Frazer considera que los principios de asociación de ideas aplicados de manera errónea producen la magia, a la que incluso considera como «hermana bastarda de la ciencia».

Según Julio Caro Baroja la magia —como la religión en general— deriva de la "concepción primaria del mundo y de la existencia" que se caracteriza por una visión "dramática de la Naturaleza, en la que lo divino y demoníaco, el orden y el caos, el bien y el mal, se hallan en pugna constante y con una existencia ligada al hombre mismo". El hombre "primitivo" —o mejor, "primigenio"— no considera la Naturaleza "en abstracto como algo impersonal, indiferente y articulado" sino que para él es "algo directo, emocional e inarticulado. Es un ser al que el hombre se dirige como en segunda persona: no es «"él"» («el cielo», «la tierra»), es «"tú"»".

La consecuencia de esta visión "dramática" o "vital" de la Naturaleza fue "que en muchos pueblos de Europa y también de otros continentes, el cielo, el firmamento azul, el día iluminado, se asociaron a la noción de un principio superior, ordenador, masculino y paternal, a la idea de una divinidad suprema en suma" —como Zeus o Júpiter del panteón grecorromano—, y en el que el sol representaba ideas tales como "fuerza, belleza, vigor, la vida en suma". Por el contrario la luna, la noche y la tierra se asocian con un principio "femenino", con la muerte y con los "infiernos". La luz de la luna, a diferencia de la del sol, es fría e indirecta, muerta; durante la noche la vida se paraliza y reina la muerte; la tierra es donde residen las almas de los difuntos que aparecen por la noche y debajo de ella viven los seres del inframundo, de los "infiernos", pero además es la "madre" de todo —principio "femenino"— del mismo modo que el firmamento es el "padre" —principio masculino—, lo que ha dado lugar al culto a "diosas madres" "con carácter ctónico y con carácter lunar".

Así la "concepción primaria del mundo y de la existencia" se articula en torno a dos sistemas: "uno, el que forman el "Cielo" de un lado como elemento "masculino", expresión de la "paternidad", de la autoridad "superior" y el otro la "Tierra" como elemento "femenino", expresión de la "maternidad" y de la "fecundidad". El otro sistema es el que constituye el "Sol" y el "Día" como "Vida", como "Fuerza", como "Bien" y la "Luna" y la "Noche" como "Muerte" y como "Mal"; como elemento femenino asimismo, pero no tan fecundo como la "Tierra"". En estos dos sistemas quedan encuadrados no solo los fenómenos físicos, sino también los hechos morales, porque "solo un pensamiento analítico llega a separar al fin lo "natural" de los "moral" de modo absoluto".

Según Caro Baroja, durante mucho tiempo se sostuvo la tesis de que el pensamiento mágico era "más antiguo" o "primitivo" que el pensamiento religioso y que los procedimientos mágicos (benéficos o maléficos) "eran anteriores, en conjunto, a los procedimientos propios de las sociedades con una religión organizada y con ritos adecuados para impetrar el favor de la Divinidad o de las divinidades. Del "conjuro" con que se expresan la voluntad y el deseo... se pasó a la "oración", que implica acatamiento y vasallaje". Frazier fue el autor que acabó de perfilar esta teoría, aunque era consciente de que los hechos que se reputaban como mágicos muy a menudo se daban asociados a los considerados como religiosos. En ese caso daba por sentado que los primeros correspondían a una fase diferente y anterior a la de los segundos.

Frazer consideraba que el primer golpe que transformó a la humanidad, para desistir de la magia como regla de fe y práctica, fue reconocer «su impotencia para manejar a placer ciertas fuerzas naturales que hasta entonces se habían supuesto dentro de su mandato».
Dentro de esta concepción es posible entender que la inteligencia de los hombres comenzaba a percibir que la práctica de la magia no producía precisamente los resultados esperados, que con anterioridad significaban una realidad.
A esto le siguió un largo período de un pensamiento reflexivo que hizo la transición hacia la religión de manera gradual, por el mayor conocimiento de las fuerzas con un poder superior al del hombre y el desarrollo del conocimiento. Frazer concluyó que el paso definitivo de la magia a la religión se da en «la confesión de la entera y absoluta dependencia del hombre con respecto a lo divino», culmina con la sumisión del hombre ante la inmensidad del universo.

Julio Caro Baroja afirma, por el contrario, que religión y magia en el mundo antiguo formaban parte de un único sistema. Señala que a Frazer y a sus continuadores ya les resultó muy difícil "separar lo estrictamente mágico de los religioso, en sistemas tales como el de la religión de los egipcios, caldeos y otros pueblos antiguos. Y lo que se deducía a la postre de su inmensa colección de datos y de otras colecciones parecidas era que no solamente los ritos religiosos estaban unidos con enorme frecuencia a los actos mágicos, sino que también cada grupo de creencias religiosas contaba con su Magia particular". Para respaldar su afirmación Caro Baroja demuestra que la magia y la religión en Grecia y en Roma formaban parte de un único sistema.

Caro Baroja concluye: 

El término magia deriva de "magi", uno de los elementos religiosos incorporados por los magos en la antigua Babilonia. Hubo magos en Roma, en Grecia y en casi todo el mundo occidental y oriental de la Antigüedad, cuando la magia o "hechicería populares" estaban relacionadas con antiguos ritos de fertilidad e iniciación en el conocimiento en los pueblos llamados bárbaros, principalmente los chinos.

La magia y la hechicería estaban ligadas también a las creencias de pueblos orientales muy antiguos, en los que el mago o brujo era a la vez un sanador y un conocedor del mundo invisible de los espíritus y desempeñaba un papel preponderante en la comunidad.

En Grecia y Roma los adivinos y magos no tenían ya nada que ver con los chamanes, aunque eran consultados sobre todo por los poderes de adivinación de los que se creía estaban dotados.

En la Europa medieval la magia estuvo relacionada con la alquimia y la astrología, actividades ocultas consideradas "demoníacas" por la Iglesia católica, y que fueron objeto de persecución especialmente durante la Baja Edad Media y la Era Moderna. Unas 500.000 personas resultaron procesadas y gran parte ejecutadas por tribunales civiles y religiosos, acusadas de brujería, a lo largo de casi cinco siglos. 

Debe señalarse que ninguna de las grandes religiones acepta las prácticas de la magia (sí consideran que la magia existe como tal), tampoco otras creencias cristianas. En lo que respecta a las religiones judeocristianas en particular, se encuentran bastantes referencias negativas a los magos en el Antiguo y Nuevo Testamento.

El hermetismo (llamado "la antigua ciencia" en el medievo) influyó en el pensamiento del Renacimiento. Esta pseudociencia se vincula, en algunos aspectos, con el mantenimiento de antiguas creencias que, como la magia, conducían al conocimiento y manejo de las leyes espirituales del universo. En 1463, Cosme de Médici encargó la traducción de la obra de Hermes Trimegisto, que se suponía escrita en el antiguo Egipto pero que, para muchos, data de los primeros siglos de la era cristiana y que es la piedra angular del movimiento hermético o gnóstico (de "gnosis", conocimiento).

La adivinación mediante el tarot fue una actividad frecuente en el nacimiento de la Era Moderna y los sistemas de símbolos desarrollados por los cartománticos para el conocimiento de la realidad presente y futura son claramente deudores de otros métodos de adivinación practicados por los magos, entre ellos la lectura del vuelo de las aves y de las entrañas de los animales sacrificados.

Prácticas de simple hechicería, adivinación, astrología, lectura de barajas y de libros oraculares como el antiquísimo "I Ching" de los chinos, o el alfabeto rúnico de los escandinavos, magia wiccana con las runas brujas o wicca y la magia alquímica con las runas de los sabios magia rúnica. aspectos del hinduismo, el yoga y hasta la creencia en la divinidad de civilizaciones extraterrestes y su presencia entre los humanos constituyeron desde mediados del siglo XX un conglomerado poco articulado que se conoce como movimiento de la Nueva Era (en inglés "New Age").

La interrelación de los mitos antiguos de las más diversas culturas, sus similitudes y relación con las religiones animistas, en las que la magia desempeñaba un papel central, fueron estudiadas por el antropólogo británico James George Frazer en su obra monumental "La rama dorada". Merecieron también una amplia consideración por parte del psiquiatra Carl Jung, quien desarrolló la teoría del inconsciente colectivo.

La antropología distingue hoy día entre magia y religión, y coloca a la magia en un plano paralelo al de la evolución de las religiones.

En psiquiatría, varias enfermedades mentales y trastornos de personalidad se caracterizan por diversos grados de pensamiento mágico.



Desde antiguo se enunciaron y clasificaron las «"magias no naturales u ocultistas"». Bajo la denominación genérica de «ocultismos» se engloban las clasificaciones históricas de un elenco heterogéneo de creencias y prácticas de las doctrinas ocultas. Según el jurisconsulto Francisco Torreblanca Villalpando "(siglo XVII)", entre el catálogo de tipos y sus numerosos subtipos estarían:


Modernamente podrían ser clasificados con el eufemismo de "Esoterismos" ocultistas.

El filólogo Pedro Estala refiere los siguientes usos y costumbres ancestrales en relación a la magia y al pensamiento mágico de diversas naciones indias, recopiladas en observaciones antropológicas hechas en la Luisiana hasta finales del siglo XVIII:

Es de relevancia mencionar la consecuencia colonial del mestizaje, que no solo es de manera racial, como se abordaría en el punto de vista biológico, sino que ante todo responde al intercambio socio-cultural.
A manera de ejemplo podemos tomar a la llamada santería que, a rasgos generales, es considerada como un conjunto de elementos que componen al catolicismo y a las tradiciones yorubas que importaron los esclavos negros capturados en Nigeria y trasladados a Cuba.

Esta conjugación de sistemas religiosos sigue siendo practicada hasta nuestros días en diversas partes de Latinoamérica, y no solo es regida por la devoción a los santos identificados con los orishas, sino que implica una jerarquía sacerdotal. Un ejemplo claro de la magia contaminante es cuando, para la iniciación de un sacerdote, le es entregada cierta cantidad de collares durante el rito, que le permitirán representar a cierta cantidad de orishas y estar en contacto con ellos a través del sacrificio de cabras u otro animal. Estas creencias y prácticas también implican que la resolución de ciertos problemas, como devolver la salud a alguien que lo solicitó, se deben a que se invocó al espíritu de sus ancestros y se llevó la ofrenda al orishá indicado. Esto es magia imitativa e implica creencias animistas.

La magia blanca, en oposición a la magia negra, busca la prosperidad del individuo y es benéfica. Este tipo de magia incluye hechizos y sortilegios de distintos tipos para mejorar las cosechas, atraer las lluvias, hierbas buenas para mantener la salud o atraer las curaciones de enfermedades, amuletos protectores y talismanes. Se recurre a ella para ahuyentar la mala suerte. Fue una magia oficial en muchas épocas históricas.

El Código Teodosiano promulga, por primera vez, una ley en contra del ejercicio de la magia, en 429. En 534, el segundo Código de Justiniano prohíbe consultar a los astrólogos, magos y adivinos por ser la magia una "«profesión depravada»". El Concilio de Ancira o Concilio de Elvira, en 306, declara que matar a través de un conjuro es un pecado y la obra del demonio. El Concilio de Laodicea solicita, en 360, la excomunión de todo aquel que practique la brujería, la adivinación, la astrología y la magia. Es con el cristianismo que la manipulación de las fuerzas ocultas, tradicionalmente en manos masculinas - las únicas con el poder suficiente como para realizar hechizos benéficos-, pasan a ser consagradas a las manos femeninas, las únicas capacez de realizar maleficios malignos, lo que abre las puertas para que Europa entre, en la Edad Media, en la época de la caza de brujas, ya que las brujas son las únicas capaces de realizar la magia negra al haber pactado con el Diablo.

El animismo engloba diversas creencias en las que seres personalizados sobrenaturales (o espíritus) habitan objetos animados e inanimados. Si bien dentro de esta concepción caben múltiples variantes del fenómeno.

El chamanismo o shamanismo se refiere a una clase de creencias y prácticas tradicionales similares al animismo que aseguran la capacidad de diagnosticar y de curar el sufrimiento del ser humano y, en algunas sociedades, la capacidad de causarlo.
Sistema que dio origen a diversos cultos y religiones y cuyo origen remonta a la Edad de Piedra. El chamán es una especie de curandero, con poderes mágicos especiales.

Sistema semejante al Vudú popular en Brasil. Consiste en la invocación de ciertas deidades llamadas Orixás.

Sistema popular en Haití. Semejante al Candomblé.

Fusión de las religiones afro-brasileñas, especialmente el candomblé, con el espiritismo kardecista, con predominancia de este último. Difiere del candomblé, también, por considerar varios tipos de orixás como espíritus de personas muertas.

Sistema de magia que trata de la invocación de entidades llamadas "exus", pudiéndose con la ayuda de esas entidades, hacer tanto el bien como el mal.

Es una religión neopagana aparecida como un 'renacimiento' de la antigua religión de la brujería e iniciada por Gerald Gardner. La magia wiccana, está apoyada especialmente por antiguos manuscritos, grimorios y libros de magia ancestral, que su fundador Gerald Gardner, recopiló y estudió durante años. Poseedor de un misterioso libro de símbolos, del cual sacó gran información, que se creía perdida o destruida por la inquisición. Al igual que Gardner, muchas sacerdotisas como Patricia Crowther, estudiaron a fondo grimorios y libros de brujería sacando a la luz los símbolos mágicos de las runas brujas.La misma ha sido reformada por muchos practicantes y covens no tradicionalistas que no se sienten cómodos con las primeras enseñanzas de Gardner. Un eclecticismo, en la cual la mayoría de sus practicantes utilizan la magia cuidadosamente en auxilio de la evolución humana.

Muchos wiccanos acuden primeramente al uso de oráculos para consultar si es conveniente realizar magia en cierta situación. Como uno de sus principales medios de adivinación son las runas brujas, que a diferencia del tarot, su origen es totalmente wiccano. La magia en la Wicca se define como el arte de enviar conciencia a voluntad, en ocasiones respaldando estos pensamientos o esta fe con objetos o hierbas que representen la intención del Mago Wicca.

La magia contemporánea encuentra sus raíces en el trabajo de iniciados como Eliphas Levi y Papus. La Teosofía, o la moderna Teosofía, tiene como uno de sus fundadores Helena Petrovna Blavatsky, que fue a buscar a Oriente la fuente de su sistema filosófico. Este sistema no se presenta exactamente como los sistemas utilizados por los estudiosos de magia, es más, pretende transmitir el conocimiento esotérico universal que estaría contenido en todas las tradiciones filosóficas o religiosas. Blavatsky considera, por ejemplo, que todos los hombres son magos en el sentido último de la palabra, pues todos pueden utilizar el poder creador divino, sea a través del pensamiento, la palabra o la acción.

Se agrupan en la magia sexual diversos sistemas: "thelemita", gnóstico, etc., que debe ser ciertamente diferenciado del Tantra con el cual guarda algunos puntos de relación. La base de estos sistemas es el concepto de que el sexo es sagrado.

La magia sexual se divide en diversos sistemas diferentes y con divergencias. Algunos de ellos derivan del sistema originalmente desarrollado por Paschal Beverly Randolph y después por Theodor Reuss en la Ordo Templi Orientis (O.T.O.) y por Aleister Crowley, por Kenneth Grant y por el artista Austin Osman Spare. Citamos entre los diversos sistemas de magia sexual:

Filosofía, culto o religión, dependiendo del punto de vista, creado por Aleister Crowley a partir del "Liber AL vel Legis" ('libro de la ley'). Con la recepción de ese libro se inició una nueva era, Eón de Horus, donde el ser humano se percibe como centro de su propio universo. θελημα "thelema", en griego, significa voluntad.

El colombiano Víctor Manuel Gómez R. (Samael Aun Weor), fundador del Movimento Gnóstico Cristiano Universal, tomando la magia sexual como uno de los pilares fundamentales de lo que llamó «revolución de la conciencia».
Su principal característica es lo que el propio autor llama «ascética revolucionaria de la Era de Acuario».
De acuerdo con el autor, metafísicamente, su proceso consiste en «mezcla inteligente del ansia sexual con el entusiasmo espiritual». Esta consiste, en suma, en la conexión de los órganos genitales masculinos y femeninos llamados por los términos "ioni" y "lingam" (en idioma sánscrito), evitándose el orgasmo, tanto masculino como femenino, la pérdida del semen y transmutando, mediante procesos indicados en sus libros, el semen en energía, luz y conciencia.

La "Ordo Templi Orientis", fundada por Theodor Reuss y Karl Kellner al principio del siglo XX se basó inicialmente en la aplicación del tantra sexual con una estructura que recuerda a la masonería. Cuando el ocultista inglés Aleister Crowley fue admitido en esta Orden, sus rituales y filosofía básica fueron reformulados para ser interpretados y trabajados bajo la llamada ley de thelema. La O. T. O. acabó siendo el origen de diversas disidencias que adoptaron diferentes perspectivas sobre la magia. De entre las disidencias que realizan una labor considerada seria podemos citar a la Ordo Templi Orientis Antiqua (O. T. O. A.) y a la Ordo Templi Orientis Tifoniana (Typhonyan O. T. O. o TOTO).

Sistema de Fraternitas Saturni. Es un sistema parecido al de OTO, centralizando sus prácticas en la magia sexual (en especial en las prácticas del «sendero de la izquierda») y en la magia ritualística. La diferencia principal en relación a la O.T.O. es que, en tanto esta busca la fusión individualizada con la energía creadora, como idea central, la Fraternitas Saturni busca elevar el espíritu humano a una condición de divinidad, representada por Lucifer. El sistema posee 33 grados.

La magia enoquiana es un sistema simbólicamente complejo, que consiste en la evocación de ángeles enokianos, descubierto por el astrólogo John Dee y por su vidente, Edward Kelley. El sistema fue posteriormente estudiado por la Aurora Dorada Golden Dawn y por Aleister Crowley.

Creado por una renombrada ocultista, Juanita Wescott, estudiosa del sistema de Franz Bardon. El sistema de la magia musical hace uso del hermetismo y de la cábala.

La magia es un conjunto de rituales cuyo objetivo es el control de los atributos de los espíritus universales, entidades sobrenaturales. El conocimiento de la magia permite la comunicación directa (evocación) o indirecta (invocación) con una o varias deidades o fuerzas que tienen poderes sobre las leyes naturales. Los espíritus convocados durante el ritual están obligados a cumplir las peticiones del mago, siempre y cuando este conozca su nombre o el de sus atributos, o, de modo equivalente, sean representados los trazos que los describen. Los trazos equivalen en este caso al pronunciamiento de sus nombres, pronunciar su nombre o 'escribirlo' son una y la misma cosa y por tanto tienen el mismo efecto. 

En magia se emplean varios rituales que pueden clasificarse de diferente manera, sin embargo la más adecuada para acometer su explicación es la que separa los rituales por el procedimiento de exposición, pasándose entonces a diferenciar los rituales de invocación y los de evocación.

La evocación es un llamamiento de comparecencia de la entidad llamada, en el que el mago exige directamente a la entidad el cumplimiento de sus deseos (dentro de la 'legitimidad' del ritual), sea mediante amenazas o ruegos. El primer objetivo de un mago cuando realiza la evocación es tratar de conseguir que la entidad le revele sus atributos (poderes) así como sus trazos (signos), ya que así en lo sucesivo puede conseguir los mismos propósitos recurriendo exclusivamente a la invocación. La evocación entraña muchos riesgos ya que junto a la entidad pueden concurrir otros espíritus que no han sido convocados por el mago, o incluso comparecer antes que la entidad (o enviada por ella) y hacer creer al mago que es la entidad reclamada. Por eso, el mago debe empezar toda evocación trazando el pentagrama mágico, que lo protegerá y del que no debe salir hasta que la entidad haya sido despedida. También debe ser cauteloso en su trato con la entidad, pues siempre tenderá a engañar al mago o acceder a sus solicitudes bajo un pacto, error en el que suelen incurrir los principiantes.

Durante la evocación el mago reclama la descripción precisa para lograr sus objetivos, ya que el objetivo raramente será pedido en el momento, sino que persiguiendo la idea de repetirlo a voluntad y en el momento preciso que el mago lo requiriera, pudiera llevar a cabo sus planes. Todo el procedimiento requerido, se plasmará en un futuro en lo que supone la invocación.

La invocación es una petición de cumplimiento, no existe ninguna comparecencia de ninguna entidad, y formalmente se parece mucho a la fórmula que se expone en las religiones como rezos, con la diferencia de que si el ritual está correctamente formulado, se espera que efectivamente se cumpla. La invocación se exhibe a través de los amuletos, y talismanes. Tal como se ha explicado, una vez que el mago ha conseguido de la entidad una descripción precisa para conseguir sus objetivos, el mago despide a la entidad y se pondrá manos a la obra en la elaboración del talismán, una vez elaborado, un ritual más sencillo (esta es la invocación) estimula el talismán para que cobre el efecto que los signos y fórmulas grabadas en el talismán describen. en este caso el ritual son oraciones y formulaciones, donde el mago se presenta, ensalza a la entidad, le recuerda su deber y le exige dotar del efecto deseado al talismán que ha sido construido siguiendo las indicaciones que la entidad describió.

Los rituales, suelen tener dos vertientes para que el mago contacte con la entidad, y a menudo ambas subsisten a la vez, una vertiente es la pronunciación en voz alta, la otra son los grabados.

Cuando el mago usa la voz su pronunciación debe ser correcta, sino, como en cualquier otro idioma, se puede indicar una cosa en vez de la deseada, lo cual puede ser muy peligroso para el mago. Una de las cosas que un mago que desea contactar por voz con la entidad, debe hacer al principio será reclamar la enseñanza y conocimiento del idioma o lenguaje para comunicarse debidamente y sin riesgos con la entidad. 

Los grabados deben utilizar siempre, unas tintas elaboradas tal como la entidad requiere, y la precisión del trazo debe cumplirse con lo que hoy definiríamos como acorde a definiciones de topografía (importa la exactitud de la forma más que la exactitud de las medidas), así como el resto de utensilios que el mago necesita para elaborar todo cuanto requiere.

Los utensilios que utiliza el mago deben estar consagrados, esto implica varias cosas: 

El mago cuando es asistido por un maestro se compromete a hacer un juramento y mantenerlo. El mago se ve así obligado a cumplirlo a rajatabla, ya que en su defecto se le achacan o atraen males por su incumplimiento. En la medida en que el mago toma conciencia de la realidad en sus prácticas, toma a su vez conciencia de la necesidad de cumplir su juramento.

Cada maestro puede imponer diferentes reglas o las mismas reglas con ligeras diferencias, sin embargo siempre es obligado la regla que señala que el aspirante, jamás revelará a las claras el conocimiento adquirido so pena contra su alma por la eternidad, así como tampoco revelará o tendrá por discípulo, a ningún aspirante que no sea merecedor. Por eso el maestro demora lo suficiente la revelación de los más altos secretos a fin de que pueda conocer si el aspirante será o no merecedor. Muchos de los aspirantes que han sido rechazados en algún estado de conocimientos son los que están en condiciones de practicar brujería (si fuera su deseo), es decir cualquier tipo de magia limitada en conocimientos.

La mayor dificultad del conocimiento de la magia es que para poder hacer la primera evocación donde el mago o aspirante a mago pueda evocar a la entidad deseada y conseguir sus favores consiste precisamente en que requiere conocer su nombre, trazo y ritual de evocación así como conocer en profundidad los peligros a los que se enfrenta y como protegerse frente a ellos, en virtud del juramento, implica que sin maestro cualquier aspirante podría dedicar gran parte de su vida a resolver estos enigmas por sus propios medios, sin un guía que le resuelva esas primeras dudas.

Una vez que un mago consigue satisfactoriamente evocar a una entidad, puede reclamar a la misma los conocimientos que requiera y así avanzar en su camino, siempre por supuesto, expuesto al peligro de los engaños. Incluso en ese caso, la entidad exige al adepto sin maestro un juramento de no revelación.

Actualmente, en el mundo moderno, es muy común creer que existe la magia. Comúnmente se usa la idea de la magia en muchos sitios, principalmente libros, historias, cuentos, animación u otros, en los que la magia aparece como un extraordinario poder de modificar o manipular la naturaleza a voluntad propia. Así mismo, desde el siglo XIX, los espectáculos de magos e ilusionistas son una constante en las artes escénicas, donde se establece un pacto tácito entre espectadores y artistas mediante el que este "hace como que" tiene poderes sobrenaturales con los que impresiona, mediante trucos, a una audiencia presuntamente crédula.





</doc>
<doc id="1933" url="https://es.wikipedia.org/wiki?curid=1933" title="Manitoba">
Manitoba

Manitoba es una de las diez provincias que, junto con los tres territorios, conforman las trece entidades federales de Canadá. Su capital y ciudad más poblada es Winnipeg. Está ubicada en el centro del país, limitando al noroeste con Territorios del Noroeste, al norte con Nunavut, al noreste con la bahía de Hudson, al este con Ontario, al sur con los Estados Unidos y al oeste con Saskatchewan. 

La provincia tiene una superficie de 649 950 km² en la que predominan las praderas y un clima continental, con miles de lagos y muchos ríos. La economía del territorio se basa en la agricultura que se practica en las fértiles zonas del sur y el oeste de la provincia. Otros sectores económicos importantes son el transporte, la manufactura, la minería, la explotación forestal, la energía y el turismo. 

La capital y mayor localidad de Manitoba es Winnipeg, octava ciudad de Canadá en población y hogar del 60 % de los habitantes de la provincia. Winnipeg es la sede del gobierno provincial y en ella se encuentran la Asamblea Legislativa de Manitoba y el Tribunal de Apelación de Manitoba, que es el máximo órgano judicial. Cuatro de las cinco universidades de Manitoba, sus equipos deportivos profesionales y la mayor parte las actividades culturales están en Winnipeg. 

Los comerciantes de pieles llegaron por primera vez al territorio de la actual Manitoba a finales del siglo XVII y la zona pasó a ser el corazón de la Tierra de Rupert, propiedad de la Compañía de la Bahía de Hudson. Manitoba alcanzó la categoría de provincia de Canadá en 1870, después de la Rebelión del Río Rojo. En 1919 se produjo en Winnipeg una huelga general y poco después la región resultó muy afectada por la crisis económica conocida como Gran Depresión. Estos hechos llevaron a la creación de lo que acabaría convirtiéndose en el Nuevo Partido Democrático de Manitoba, uno de los principales partidos políticos de la provincia. 

Su actual primer ministro es Brian Pallister, perteneciente al Partido Progresista Conservador de Manitoba.

El nombre Manitoba se cree que está derivado de las lenguas Cree, Ojibway, o Assiniboine. El nombre deriva del Cree manitou-wapow u Ojibwa manidoobaa, lo que significa “estrechos de Manitu, el Gran Espíritu", un lugar en referencia a lo que ahora se llama The Narrows en el centro del lago Manitoba.

Tres diferentes tribus Nativoamericanas habitaban en la región que actualmente constituye a la provincia de Manitoba, en la época de la llegada de los primeros colonos europeos al continente. Los Cree, los Assiniboines y los Ojibwa. 

Los primeros, a su vez, estaban divididos en tres subgrupos, cada uno con sus diferentes dialectos y aspectos culturales: tres de estas tribus formaban parte del grupo amerindio de los cree: los Chippewyan, los Wood Cree y los Plain Cree. 

Los Assiniboines eran aliados de los Cree. Los Chippewya, en cambio, vivían al norte de Manitoba, los Wood Cree en los bosques del centro-sur, los Plains Cree y los Assiniboines en las planicies del suroeste, y los Ojibwa, sobre las llanuras del sureste, todas ellas siendo tribus nativas americanas nómadas.

Los primeros exploradores europeos en arribar a la actual Manitoba fueron los miembros de una expedición inglesa comandada por Thomas Button, en 1612. Desembarcaron en el litoral de la bahía de Hudson, pasaron el invierno de 1612 y 1613 en el estuario del río Nelson, y reivindicaron la región para la corona británica. 

Posteriormente, dos expediciones inglesas, dirigidas por Luke Foxe y Thomas James, desembarcarían en Manitoba, en el litoral de la bahía de Hudson, en 1631.

Por 1670, el rey Carlos I de Inglaterra cedió los derechos de comercio y administración de la provincia a la Compañía de la Bahía de Hudson. Esta zona formaba parte de un enorme territorio administrado por la susodicha compañía, conocido como Tierra de Rupert. 

Este - incluyendo toda la región de la actual Manitoba - era tomada por los franceses, instalados en la colonia vecina de Nueva Francia. Durante las décadas de 1680 y 1690, tanto los británicos como los franceses instalaron diversos puestos comerciales en la región. 

Rápidamente, se levantó una serie de tensiones y conflictos entre ambas potencias colonizadoras. En 1690, la Compañía de la Bahía de Hudson ordenó a Henry Helsey que encontrara nuevas fuentes de pieles de animales para su futura y eventual comercialización. Helsey exploró toda la región centro-sur de Manitoba, y logró persuadir a los nativoamericanos del lugar - que vivían principalmente de la caza de bisontes - que enviaran sus pieles a los puestos comerciales de la Compañía, localizada al norte provincial.

En 1731, el francés Pierre Gaultier de Varennes, sieur de La Vérendrye, al mando de una expedición compuesta por traficantes de piel, partió de Montreal rumbo a la costa del océano Pacífico. Este construyó diversos fuertes entre la región del lago Superior y el río Saskatchewan, pasando a través de la región meridional de Manitoba, una de estas fortificaciones siendo Fort Rouge, en 1738, donde está localizada actualmente Winnipeg. Varennes estableció relaciones amigables con los nativoamericanos, que también se dispusieron a trabajar en el comercio de pieles.

Hacia 1763, tras la derrota francesa en la guerra franco-indígena, los franceses se vieron forzados a entregar la región a los británicos. Por un breve período, la Compañía de la Bahía de Hudson usufructuó un monopolio comercial bastante poderoso. Por ello, en la década de 1770, la Compañía del Noroeste fue fundada en Montreal, y pasó a competir con la de Hudson. 

La Compañía del Noroeste fracasó poco después, pero fue reabierta en 1784. La Compañía de la Bahía de Hudson aún mantenía el control administrativo del territorio, pero, por decreto del gobierno del Reino Unido, fue obligada a permitirle a la Compañía del Noroeste operar en su jurisdicción. 

En 1811, la Compañía de la Bahía de Hudson tenía el control de una amplia propiedad regional - que sumaba un total de 260 mil kilómetros cuadrados de superficie - para Thomas Douglas. Esta región incluía mucho de las actuales provincias canadienses de Manitoba y Saskatchewan, así como buena parte de los estados norteamericanos de Dakota del Norte y Minesota, un sector que sería conocido como Colonia del Red River. Douglas, entre 1812 y 1816, envió colonos escoceses e irlandeses a esos lugares, con el objetivo de intentar iniciar una práctica agrícola.

Las lluvias, las heladas y las fuertes tormentas de nieve arruinaron inicialmente los primeros planes de cultivo. Además de eso, estos colonos se habían instalado sobre el norte del área cedida por la Compañía de la Bahía de Hudson a Douglas, en una región donde la Compañía del Noroeste disponía de sus principales bases de operación. 

Los alimentos comenzaron a escasear, y se tuvo que acudir a las fuentes alimenticias que hasta ese momento eran consumidas solo por los aborígenes. La situación se agravó en 1815, cuando la Compañía de Hudson prohibió la venta de alimentos por parte de los nativoamericanos a la Compañía del Noroeste, así como la exportación de alimentos más allá de los límites de la Tierra de Rupert.

Miembros de esta última atacaron a los colonos de la colonia de Red River, en tanto que los métis - una tribu aborigen descendiente de nativoamericanos y colonos europeos, y que hablaban primariamente francés - cuya principal fuente de renta era la venta de alimentos para la Compañía del Noroeste, de la cual los métis eran íntimos aliados, atacaron a miembros de la Compañía de la Bahía de Hudson, durante la batalla de Seven Oaks, que resultó en victoria de los métis. Las hostilidades continuaron hasta 1821, cuando los hombres de Hudson y la Compañía del Noroeste se fusionaron. La práctica bien lograda de la agricultura tendría, sin embargo, su mejor momento a partir de la década de 1840.

En 1867, la Confederación canadiense fue formada, por las colonias británicas de ""Canadá"", Nuevo Brunswick y Nueva Escocia, que juntas pasaron a constituir al país, el único de Gran Bretaña. Dos años después, en 1869, la Compañía de la Bahía de Hudson acordó ceder todas sus tierras al gobierno canadiense. Así, la provincia actual de Manitoba pasó a formar parte de Canadá. 

Esta medida no fue del entero agrado de los metis, que temían que grandes números de ciudadanos canadienses - especialmente colonos anglófonos - se instalaran en su hábitat, y los asimilaran culturalmente. En 1869, Louis Riel lideró una rebelión en Fort Gary, actual Winnipeg. Ésta, que duró hasta 1870, pasó a ser conocida como la Rebelión de Red River, y se vio marcada por la expulsión de Thomas Scott - un anglófono que fue condenado por traición.

En 1870, el gobierno canadiense, en un intento por poner fin a la rebelión, cedió a los métis una Carta de Derechos, a través del Manitoba Act, que efectivamente creaba a Manitoba. Esta nueva provincia, para ese entonces, contaba con apenas el 5,6% de su territorio actual, y ocupaba el cantón sureste de la actual Manitoba, que pasaría a convertirse en la quinta provincia canadiense el 15 de julio de 1870.

La elevación de la región de Red River a la categoría de provincia provocó que grandes números de colonos venidos de otras partes del país decidieran instalarse en sus confines, por lo que los metis no recibieron la anhelada protección contra la asimilación cultural. Estos hombres, en su mayoría anglófonos, se convirtieron luego la comunidad mayoritaria de Manitoba. 

Entre 1871 y 1881, la población de la provincia había incluso sobrepasado el doble de sus habitantes, de 25.228 personas en 1871 a 62.260 en 1881. El gobierno de Manitoba inmediatamente revocó muchos de los derechos concedidos a los metis a través del "Manitoba Act". Una de las principales garantías era el acceso a la educación en francés. 

Los colegios y las instituciones de enseñanza pública y privada dejaron, por ley, de dictar cátedras en ese idioma hacia fines de 1870, relegándolo a segundo plano. Como consecuencia, grandes números de metis decidieron emigrar hacia el oeste, en dirección a las actuales provincias de Saskatchewan y Alberta.

La industria agraria de Manitoba prosperó tras asumir las funciones típicas de una nueva provincia, especialmente en lo que concernía al cultivo de trigo. Comenzaría a exportar este cereal a otras regiones (a Estados Unidos y a otras partes del país) en 1876, transformándolo en su mayor fuente de ingreso. 

Hacia 1878, fue inaugurada la primera vía férrea que conectaba a la ciudad con otras comarcas - específicamente, con St. Paul en Minesota. Durante el comienzo de la década de 1880, un tren canadiense del Pacífico se encargó de comunicar a Winnipeg con las principales ciudades del este del subcontinente. 

La inauguración completa de la ferrovía, en 1886, posicionó a la provincia en el centro de la primera malla ferroviaria transcontinental de América del Norte, e hizo de Winnipeg un gran centro ferroviario, lo que estimuló la producción de trigo, que ahora podría ser fácilmente transportado hasta puertos localizados en los Grandes Lagos, y de ahí, rumbo a otros rincones del planeta.

El crecimiento poblacional de Manitoba continuó firme hasta la década de 1920. Una cierta cantidad de canadienses de otras partes de la nación, al igual que muchos inmigrantes - sobre todo alemanes, ucranianos, ingleses, escoceses e irlandeses - se instalaron en la provincia.

La explotación de trigo en Manitoba se incrementó drásticamente durante este gran período. De 1871 a 1912, los límites territoriales de Manitoba fueron gradualmente extendidos en dirección hacia el norte y el oeste. En 1912, la provincia adquiría sus actuales dimensiones.

La década de 1910 representó grandes agitaciones en el escenario político, social y económico de Manitoba. La Primera Guerra Mundial propició una mejoría en la industria agropecuaria provincial, estimulando su industrialización. Durante la guerra, el Partido Liberal de Canadá se hizo con el poder manitobeano, sustituyendo al Partido Conservador de Canadá, que había estado al mando de Manitoba entre 1900 y 1915.

Mientras que los conservadores se concentraban primordialmente en el crecimiento económico de la provincia, los liberales se ocupaban de la realización de diversas reformas, dando a las mujeres el derecho al voto, instituyendo derechos obreros y de educación obligatoria para jóvenes de hasta 14 años de edad.
A pesar de las reformas, en general, los trabajadores no estaban conformes. Los salarios de los peones industriales permanecían por debajo de lo normal, al tiempo que los obreros reclamaban la falta de atención del gobierno provincial en relación al sector agropecuario de Manitoba. En mayo de 1919, Winnipeg fue testigo de una gran huelga general organizado por 52 cooperativas y sindicatos diferentes. Esta marcha dio lugar a diversos conflictos violentos entre huelguistas y policías. 

El gobierno de Manitoba, cuando esta confrontación, ignoró la medida, y se esforzó en continuar abasteciendo a los servicios anteriormente llevados a cabo por los trabajadores en huelga. Este proceder dio resultado, y la huelga terminó en junio, por decisión de sus convocantes. El partido Obreros Unidos de Manitoba asumió el poder en 1922.

Manitoba fue una de las provincias mayormente afectadas por la Gran Depresión. Dependía de la exportación de trigo para otros países, y la repentina subida de los precios en los meses previos al quiebre de la bolsa de Nueva York volcó en un retroceso que perduraría a lo largo de los años 1930. 

Además de eso, los obreros de Manitoba sufrieron también con períodos prolongados de sequía; muchos de ellos abandonaron sus propiedades y se dirigieron rumbo a las ciudades; otros, simplemente, emigraron a otras provincias en busca de nuevas opciones de empleo. 

La tasa de crecimiento poblacional decreció considerablemente en ese intervalo. La depresión fue una de las causas de creación de nuevos partidos políticos en la provincia, que posteriormente se darían a conocer en el resto del país: la Federación Corporativa de la Commonwealth, que se pasaría a llamarse más tarde Nuevo Partido Democrático, y el Partido del Crédito Social.

Los saldos negativos de la provincia solo acabaron con el ingreso del país en la Segunda Guerra Mundial, luego de los enfrentamientos armados. Esto aumentó notablemente la demanda de productos agrarios en general y dio pie a la industrialización del comercio. Un gran lote de fábricas fue construido durante la guerra. El ligero crecimiento de la industria manufacturera perseveró al término de la Segunda Guerra Mundial, en tanto que la industria agropecuaria entró en receso, a causa del aumento de precios en los productos dentro del mercado internacional. 

Al final de la década de 1940, la manufactura había superado a la agropecuaria como la principal fuente de renta en la provincia. La modernización de esta última y el ascenso de la industria manufacturera hicieron que grandes números de obreros se trasladaran desde áreas rurales del Estado hasta la metrópoli, con preferencia en Winnipeg.

En 1945, los geólogos descubrían grandes depósitos de cobre, níquel y zinc en el noroeste de Manitoba. La minería se convirtió en una fuente de renta importante para la provincia. Para las décadas de 1950 y 1960, la provincia ya era uno de los principales centros productores de níquel en el mundo, siendo hasta nuestros días la segunda mayor productora del continente americano, superada tan solo por la provincia vecina de Ontario. Durante el apogeo de los años 50, Manitoba desarrolló su propio sistema de generación y distribución eléctrica, y en torno a 1955, todas las áreas rurales disponían de este servicio.

La industrialización de Manitoba ocasionó un período de acelerado crecimiento poblacional durante la segunda mitad del siglo XX. Como consecuencia, pocas fábricas pasaron a ser construidas en la provincia a partir de finales de la década de 1960. La disminución del sector manufacturero de Manitoba - que desde 1950 era su principal fuente de ingreso - decayó sensiblemente junto al crecimiento poblacional. Desde entonces, la población ha ido creciendo gradualmente, pero a un ritmo lento, excepto por un corto período que hubo entre 1981 y 1986.

Por 1979, el "Manitoba Act", que había declarado al francés como una lengua no-oficial en Manitoba, e impedía consecuentemente su difusión en centros educativos y su uso para trámites legales, fue juzgado de inconstitucional por la Corte Suprema de Canadá. En 1985, este órgano ordenó que Manitoba tradujera todas sus 4500 leyes provinciales a lengua francesa, y se comenzara con la instrucción pública en aquel idioma, en comunidades con una población francófona significante.

Manitoba se halla localizada en el centro longitudinal de Canadá, aunque se la considera parte de la región occidental. Limita al oeste con Saskatchewan, al este con Ontario, al norte con Nunavut y la bahía de Hudson, y al sur con los estados norteamericanos de Dakota del Norte y Minesota. Su territorio ocupa una superficie de 553.556 km², que para efectos comparativos es similar a la de Francia.

La provincia posee una costa a lo largo de la bahía de Hudson y tiene el décimo lago de agua dulce mayor del mundo, el lago Winnipeg, próximo a otros dos lagos de similar tamaño: el lago Manitoba y el lago Winnipegosis. Las aguas manitobeanas cubren una superficie aproximada del 14,5% del territorio o, lo que es lo mismo, 94.241 km². El Winnipeg es el lago más extenso del sur canadiense y es una de las pocas y extrañas regiones del planeta en conservar sus líneas divisorias intactas. 

Los grandes ríos que fluyen en sentido este al lago Winnipeg son muy prístinos, sin mayores funciones a destacar. Muchas islas e islotes pueden ser encontrados junto al muelle oriental de este gran lago. Además, hay miles de lagunas a lo largo de la provincia. Los cursos fluviales más destacados incluyen al río Rojo del Norte, al Assiniboine, al Nelson, al Winnipeg, al Hayes y al Churchill. 

La mayor parte del sur inhabitado de Manitoba, cerca de Winnipeg, es escenario de yacimientos prehistóricos que provienen del lago glacial Agassiz. Esta parte centro meridional es llana y salpicada por algunas colinas. 

No obstante, existen numerosas áreas rocosas y serranas en la provincia, junto a tumultuosas dunas y montañas arenosas dejadas atrás por los glaciares. Baldy Mountain es el punto más elevado con 832 metros de altura sobre el nivel del mar, y la costa de la bahía de Hudson es la más baja, a nivel marítimo. Otros ligeros accidentes geográficos lo componen las regiones de la montaña Riding, las Colinas de Pembina, el bosque provincial de los arenales, y el Escudo Canadiense. 

El norte y este, prácticamente despoblados, presentan un panorama irregular de suelos formados de granito procedente del Escudo canadiense, entre los que sobresalen el Parque Provincial de Whiteshell, el Provincial de Atikaki, y el de Nopiming. El Parque Provincial de Birds Hill era originalmente una isla sobre el lago Agassiz, tras derretirse los glaciares.

El clima de Manitoba es característico de su localización en una latitud media septentrional. Por lo general, las temperaturas y las precipitaciones disminuyen de sur a norte. Los veranos son templados a cálidos, y los inviernos muy fríos. Tanto la primavera como el otoño son estaciones breves y contraídas. 

Debido a que Manitoba se encuentra lejos de las influencias regularizantes de las cordilleras y de los embalses de agua (todos los grandes lagos se congelan durante el periodo invernal), y por su llanura, se encuentra expuesta a numerosos sistemas climáticos a lo largo del año, como por ejemplo, prolongadas rachas de frío cuando la alta presión de masas de aire de origen ártico penetran en su entorno. Esta es la razón por la cual la capital provincial ha sido a menudo apodada como "Winterpeg" (del inglés "winter", invierno). Es normal registrar menos 40 grados celsius en algunos días de invierno, y semanas con termómetros que no marcan más de 20 grados bajo cero. 

En tiempo de verano, el clima es influenciado por bajas presiones de masa atmosférica que proceden del Golfo de México, resultando en cálidas y húmedas condiciones que suelen tornarse en frecuentes tormentas eléctricas y tornados cada año. Por último, Manitoba es uno de los lugares más soleados de Canadá y Norteamérica. 

Tan solo los sectores meridionales de la provincia practican la agricultura de forma extensiva. El prototipo más común de granja encontrado en áreas rurales es aquel destinado a la cría de ganado (35,3 %), seguido del dirigido a la producción de aceite natural (25,8 %) y por los molinos harineros (9,8 %). Cerca del 11 % de las tierras de cultivo de Canadá se encuentran en Manitoba. 

Los extremos este, sureste y norte están cubiertos de bosques de coníferas, "muskegs", Escudo canadiense, y tundra rumbo al norte. La zona forestal abarca unos 263.000 kilómetros cuadrados. Su vegetación se compone de pinos, píceas, tamaracks, cedros, álamos, y abedules. Las vastas expensas de áreas forestales preservadas son consideradas por muchos naturalistas y deportistas como zonas silvestres prístinas. 

Algunos de los últimos bosques boreales más grandes del mundo pueden ser localizados sobre el litoral oriental del lago Winnipeg, con tan solo rutas de invierno, sin desarrollo hidrovial, y unas pocas comunidades densamente pobladas. A todo lo antedicho, cabe mencionar que aún persisten ríos vírgenes sobre el este, y que nacen en el Escudo canadiense para desembocar en el Winnipeg. 

El teniente-gobernador representa a la reina Isabel II como jefe de provincia. El líder del gobierno, en la práctica, es también el mayor oficial del poder ejecutivo provincial, siendo, en otras palabras, el "premier" gobernador (o "primer ministro" en español), la persona que lidera el partido político con más representación en la Asamblea Legislativa de Manitoba. El gobernador preside un Consejo Ejecutivo, que es a su vez el gabinete de la provincia. Este se compone de 25 ministros diferentes, que lideran un determinado departamento (economía, educación, etc), y son designados por el "premier". Tanto el gobernador como los miembros del gabinete pueden renunciar en caso de que obtengan la aprobación de la mayoría de los miembros de la Asamblea.
El poder legislativo de Manitoba es la Asamblea Legislativa propiamente dicha, que está integrada por 57 miembros. La provincia se divide en 57 distritos electorales. La población electoral de cada uno de estos distritos elige a un miembro, que actuará como representante del distrito en la Asamblea, para mandatos de hasta 5 años de duración. Si el teniente-gobernador quiere disolver la Asamblea antes de que se cumplan los cinco años, a pedido del gobernador, todos deben concurrir a elecciones nuevamente. No existe un límite de veces en los que una misma persona pueda ejercer.

Manitoba posee cerca de 200 ciudades, villas y municipalidades rurales incorporadas. Los impuestos son los responsables del 95% del recaudamiento provincial. El monto restante proviene de incentivos administrados por el gobierno federal. 

Históricamente, Manitoba ha sido una provincia conservadora. Hasta la década de 1920, la mayor parte de los "premiers" habían sido candidatos del Partido Conservador de Canadá. Entre las décadas de 1920 y 1950, la inmensa mayoría de los "premiers" fueron candidatos del Partido Liberal de Canadá. Desde ese momento, los principales partidos políticos que dominaron la Asamblea de la provincia fueron el Partido Progresista de Canadá (que en 2003 se convirtió en el actual Partido Conservador de Canadá) y el Nuevo Partido Democrático. Para poder votar, una persona necesita tener al menos 18 años de edad.

El censo nacional de 2001 estima una población de 1.119.583 habitantes, un crecimiento del 0,5% en relación a las cifras obtenidas en 1996, de 1.113.898. Un estudio realizado en 2004 supone una población provincial de 1.177.556 habitantes, un crecimiento del 5,7% en proporción a los datos recabados en 1996.

Según el censo de Canadá de 2006, el mayor grupo étnico en Manitoba es el anglo-canadiense (22,9%), seguido por el alemán (19,1%), el escocés (18,5%), ucraniano (14,7%), irlandés (13,4%), indígenas americanos (10,6%), polaco (7.3%), métis (6,4%), franco-canadiense (5,6%), holandés (4,9%) y ruso (4%). Casi un quinto identificó su etnicidad como "canadiense".

Hay una importante comunidad indígena: los aborígenes (incluyendo los métis) son el grupo étnico de mayor crecimiento, y representan cerca del 13,6 de su población en 2001. Hay una minoría franco-manitoba (148.370) y una creciente población de amerindios (192.865, incluyendo los métis). En Gimli se encuentra la mayor comunidad islandesa fuera de Islandia.

Porcentaje de la población de Manitoba por afiliación religiosa, en 2019:

El inglés y el francés son los idiomas oficiales de la legislatura y de la corte de Manitoba, de acuerdo con el "Manitoba Act" de 1870 (que forma parte de la Constitución canadiense):

Sin embargo, con la revuelta del poder multitudinal a favor del inglés que se dio en Manitoba desde 1890 en adelante, esta provisión fue relegada en la práctica y en la legislación de Manitoba. En abril de 1890, la legislatura de Manitoba introdujo una medida para suprimir el estatuto de la lengua francesa en la organización, leyes, registros y periódicos, así como en la Corte provincial. Entre otras cosas, la Legislatura manitobeana dejó de publicar en francés, haciéndolo solamente en inglés. A pesar de ello, en 1985 la Suprema Corte de Canadá tomó partido en una "Referencia a los derechos del lenguaje en Manitoba", alegando que el solo hecho de que tal Legislatura publicara nada más que en inglés era incorrecto (aunque, Manitoba no bajó a la categoría de ilegalidad, la legislación unilingüe fue declarada nula por un período temporal, para proporcionarle al gobierno de Manitoba un tiempo suficiente para elaborar las traducciones).

Si bien el francés es requerido como un idioma oficial para los propósitos de la legislatura, legislación, y en las cortes, el Manitoba Act (tal y como es interpretado por la Suprema Corte de Canadá) no necesita ser empleado con fines ejecutivos a nivel gubernamental (excepto cuando la rama ejecutiva se hace cargo de funciones legislativas o judiciales.) De esta forma, el gobierno de Manitoba no es completamente bilingüe, y como se refleja en el Acta constitucional de 1982, la única provincia bilingüe es la de Nuevo Brunswick.

Los servicios policiales en lengua francesa de Manitoba, de 1999, han sido ideados para proveer un nivel equitativo de atención civil en ambos idiomas oficiales. Servicios públicos, incluyendo utilidades y atención clínica, así como documentos oficiales (tickets, citaciones judiciales, vistos, etc) se encuentran disponibles tanto en inglés como en francés.

Manitoba cuenta con una economía relativamente fuerte basado en gran medida de los recursos naturales. Su PIB fue de C $ 50,834 mil millones de dólares canadienses en 2008. La economía de la provincia creció un 2,4% en 2008, por tercer año consecutivo. En 2009, no obstante, su crecimiento fue nulo. En octubre de 2009, la tasa de desempleo de Manitoba fue del 5,8%.

La economía se basa principalmente en la agricultura, turismo, energía, petróleo, minería y silvicultura. La agricultura es vital y se encuentra principalmente en la mitad sur de la provincia, con los cereales como cultivo dominante. Alrededor del 12% de las tierras agrícolas de Canadá se encuentra en Manitoba. El tipo más común de finca que se encuentra en las zonas rurales es la ganadería (34,6%), seguido por una variedad de granos (19,0%) y semillas oleaginosas (7,9%).

Manitoba es el mayor productor nacional de semilla de girasol y frijoles secos y una de las principales fuentes de patatas. Portage la Prairie es un centro de procesamiento de patatas grandes, y es el hogar de los Alimentos McCain y plantas Simplot, que ofrecen papas fritas de McDonald, Wendy, y otras cadenas comerciales. Can-avena de fresado, una de las fábricas más grandes de avena en el mundo, también tiene una planta en el municipio.

Los mayores empleadores de Manitoba son las instituciones gubernamentales y programas de salud, incluyendo empresas estatales y servicios, como hospitales y universidades. Los principales empleadores del sector privado son The Great-West Life Assurance Company, Cargill Ltd., and James Richardson y Sons Ltd. Manitoba también cuenta con fábricas e importantes áreas turísticas. Churchill's Arctic wildlife es su mayor atracción turística. Manitoba es la única provincia con un puerto marítimo profundo en las aguas del Océano Ártico marítimo, que enlaza la ruta más corta de transporte marítimo entre América del Norte, Europa y Asia.

El transporte y el almacenamiento contribuyen aproximadamente con 2,2 billones de dólares canadienses al PBI de Manitoba. El empleo total en la industria se estima en 34.500 efectivos.

Manitoba dispone de varios medios de transporte; tren, comunicación aérea, camiones, medios marinos, etc. 

La TransCanada Highway fue construida a comienzos del siglo XX, y hasta el día de hoy se mantiene en funcionamiento, improvisada con tecnología de primera mano. Esta autopista es la mayor y la única en toda Canadá que conecta a este y oeste, para comercio, viaje, turismo, y circulación de vehículos pesados. 

Alrededor de 350 empresas de fletes con 4 o más coches operan en Manitoba. Muchas de esas firmas son compañías privadas y administrativas. La inmensa mayoría de las empresas de carga de Manitoba trabajan tanto interprovincial como internacionalmente. Los camiones transportan el 95% de la mercancía de Manitoba. Las compañías de carga arrastran el 80% de la mercadería provincial hacia los Estados Unidos.

Cinco de un total de veinticinco firmas de alquiler de fletes se concentran en Manitoba. Además, tres de las diez empresas más grandes en la materia tienen sede en Winnipeg. Más de mil millones de dólares del PBI de la provincia, directa o indirectamente, proviene del flete. Cerca del 5%, o lo que es lo mismo, 33.000 personas trabajan en este campo.

Manitoba tiene dos líneas ferroviarias de primera clase: el Canadian National Railway (CN) y el Canadian Pacific Railway. Winnipeg se localiza en el centro de estas dos líneas principales, y alberga a una vasta cantidad de terminales. El CN y CP operan en un trayecto combinado de 2.439 kilómetros dentro del límite provincial. El primer ferrocarril en recorrer Manitoba fue el CP, y los caminos fueron desviados hacia el sur para culminar en Winnipeg, como la capital y centro, y no Selkirk, que se encuentra más al norte.

Existe un número de pequeñas líneas regionales. Las más importantes son el Hudson Bay Railway, el Southern Manitoba Railway, el Burlington Northern Santa Fe Manitoba, el Greater Winnipeg Water District Railway y el Central Manitoba Railway. En su conjunto, operan aproximadamente sobre un área de 1.775 kilómetros de trayecto en la provincia.

El Aeropuerto Internacional James Armstrong Richardson de Winnipeg es uno de los pocos aeropuertos no restringidos que operan durante las 24 horas en Canadá. Posee una amplia capacidad para pasajeros (3 millones en 2003) y servicios de carga. Por él pasan unas 140.000 toneladas de carga anualmente. 11 empresas de vuelo regionales, más otras 9 firmas menores operan diariamente en el aeropuerto, así como 11 de carga y 7 de índole comercial.

Winnipeg presenta un vasto rango de posibilidades tanto para el FedEx como para el Purolator. También recibe transbordo diario de servicio desde la UPS. Air Canada Cargo y Cargojet Airways hacen uso del aeropuerto como un centro de tráfico nacional.

El Puerto de Churchill, perteneciente a OmniTRAX es la llave de Manitoba hacia el Ártico y el mar en general. Se halla más próximo a puertos europeos que otros en el resto del país. Dispone de 4 amarraderos bajo el agua para la carga y descarga de cereal, carga común y buques cisterna. El puerto se comunica con la autovía de la Bahía Hudson (también propiedad de OmniTrax).

El cereal representaba el 90% del tráfico portuario en la temporada de embarque de 2004. En ese año, cerca de 600.000 toneladas de productos agrícolas anclaron en sus muelles.

La primera escuela de Manitoba fue fundada en 1812, a orillas del Red River. A partir de 1818, misioneros de la Iglesia católica comenzaron a construir escuelas católicas en la región. En 1820 se edificó la primera escuela protestante. 

Hasta el inicio de la década de 1870, la educación básica era impartida solo por instituciones religiosas. En 1871, con la creación de la provincia de Manitoba, se abrió un Departamento de Educación, que pasó a ser responsable del funcionamiento de las aulas en el sistema de escuelas públicas de su círculo.

Actualmente, todas las escuelas de educación básica localizadas en la provincia deben seguir patrones impuestos por el Departamento de Educación. Las escuelas públicas de la región sur de la provincia son administradas por un distrito escolar adjudicado, que opera en una determinada región, en diversas ciudades, villas y municipalidades al mismo tiempo. 

Los colegios de algunas regiones aisladas del sur de Manitoba, como toda la región centro-norte de la provincia, son, en su conjunto, administrados directamente por las ciudades, villas o municipalidades en las cuales se encuentran. La enseñanza escolar es de carácter obligatorio para todos los niños y adolescentes desde los siete años de edad, hasta la conclusión del segundo grado o hasta los dieciséis años.

Manitoba cuenta con cuatro universidades. La Universidad de Manitoba, la mayor de todas, tiene su sede en Winnipeg. Otras son la Universidad de Winnipeg, en Winnipeg, la Universidad de Brandon, en la ciudad homónima, y la Universidad de St. Boniface, en St. Boniface, un suburbio de Winnipeg. Manitoba dispone de 38 bibliotecas públicas, de las cuales 21 están situadas en la capital.





</doc>
<doc id="1935" url="https://es.wikipedia.org/wiki?curid=1935" title="Mecánica">
Mecánica

La mecánica (Griego Μηχανική y de latín mechanìca o arte de construir una máquina) es la rama de la física que estudia y analiza el movimiento y reposo de los cuerpos, y su evolución en el tiempo, bajo la acción de fuerzas. Modernamente la mecánica incluye la evolución de sistemas físicos más generales que los cuerpos másicos. En ese enfoque la mecánica estudia también las ecuaciones de evolución temporal de sistemas físicos como los campos electromagnéticos o los sistemas cuánticos donde propiamente no es correcto hablar de cuerpos físicos.

El conjunto de disciplinas que abarca la mecánica convencional es muy amplio y es posible agruparlas en cuatro bloques principales:

La mecánica es una ciencia perteneciente a la física, ya que los fenómenos que estudia son físicos, por ello está relacionada con las matemáticas. Sin embargo, también puede relacionarse con la ingeniería, en un modo menos riguroso. Ambos puntos de vista se justifican parcialmente ya que, si bien la mecánica es la base para la mayoría de las ciencias de la ingeniería clásica, no tiene un carácter tan empírico como estas y, en cambio, por su rigor y razonamiento deductivo, se parece más a la matemática.

La mecánica clásica está formada por áreas de estudio que van desde la mecánica del sólido rígido y otros sistemas mecánicos con un número finito de grados de libertad, a sistemas como la mecánica de medios continuos (sistemas con infinitos grados de libertad). Existen dos formulaciones diferentes, que difieren en el grado de formalización para los sistemas con un número finito de grados de libertad:

Aplicados al espacio euclídeo tridimensional y a sistemas de referencia inerciales, las dos formulaciones son básicamente equivalentes.

Los supuestos básicos que caracterizan a la mecánica clásica son:

Existen otras áreas de la mecánica que cubren diversos campos aunque no tienen carácter global. No forman un núcleo fuerte para considerarse como disciplina:

La mecánica de medios continuos trata de cuerpos materiales extensos deformables y que no pueden ser tratados como sistemas con un número finito de grados de libertad. Esta parte de la mecánica trata a su vez de:

La mecánica de medios continuos usual es una rama de generalización de la mecánica clásica, aunque durante la segunda mitad del siglo XX se desarrollaron formulaciones relativistas de los medios continuos, aunque no existe un análogo cuántico equivalente ya que dicha teoría interpreta los medios continuos en forma de partículas.

También existe la mecánica de medios continuos relativistas, aunque existen algunos problemas abiertos en relación a las generalizaciones relativistas de la mecánica de medios clásicas. Por otro lado no hay generalizaciones cuánticas que sean el análogo cuántico de la mecánica de medios continuos.

La mecánica estadística trata de sistemas con muchas partículas y que por tanto tienen un número elevado de grados de libertad, al punto que no resulta posible escribir todas las ecuaciones de movimiento involucradas y, en su defecto, trata de resolver aspectos parciales del sistema por métodos estadísticos que dan información útil del comportamiento global del sistema sin especificar qué sucede con cada partícula del sistema. Los resultados obtenidos coinciden con los resultados de la termodinámica. Usa tanto formulaciones de la mecánica hamiltoniana como formulaciones de la teoría de probabilidad. Existen estudios de mecánica estadística basados tanto en la mecánica clásica como en la mecánica cuántica.

La mecánica relativista o teoría de la relatividad comprende:

Existen varias propiedades interesantes de la dinámica relativista, entre ellas:

Sin embargo, a pesar de todas estas diferencias, la mecánica relativista es mucho más similar a la mecánica clásica desde un punto de vista formal, que por ejemplo la mecánica cuántica. La mecánica relativista sigue siendo una teoría estrictamente determinista.

La mecánica cuántica trata con sistemas mecánicos de pequeña escala o con energía muy pequeña (y ocasionalmente sistemas macroscópicos que exhiben cuantización de alguna magnitud física). En esos casos los supuestos de la mecánica clásica no son adecuados. En particular el principio de determinación por el cual el estado futuro del sistema depende por completo del estado actual no parece ser válido, por lo que los sistemas pueden evolucionar en ciertos momentos de manera no determinista (ver postulado IV y colapso de la función de onda), ya que las ecuaciones para la función de onda de la mecánica cuántica no permiten predecir el estado del sistema después de una medida concreta, asunto conocido como problema de la medida. Sin embargo, el determinismo también está presente porque entre dos medidas filtrantes el sistema evoluciona de manera determinista de acuerdo con la ecuación de Schrödinger.

La evolución no determinista y las medidas sobre un sistema, están regidas por un enfoque probabilístico. En mecánica cuántica este enfoque probabilístico, lleva por ejemplo en el enfoque más común renunciar al concepto de trayectoria de una partícula. Peor aún el concepto la interpretación de Copenhague renuncia por completo a la idea de que las partículas ocupen un lugar concreto y determinado en el espacio-tiempo. La estructura interna de algunos sistemas físicos de interés como los átomos o las moléculas solo pueden ser explicados mediante un tratamiento cuántico, ya que la mecánica clásica hace predicciones sobre dichos sistemas que contradicen la evidencia física. En ese sentido la mecánica cuántica se considera una teoría más exacta o más fundamental que la mecánica clásica que actualmente solo se considera una simplificación conveniente de la mecánica cuántica para cuerpos macroscópicos.

También existe una mecánica estadística cuántica que incorpora restricciones cuánticas en el tratamiento de los agregados de partículas.

La mecánica cuántica relativista trata de aunar mecánica relativista y mecánica cuántica, aunque el desarrollo de esta teoría lleva a la conclusión de que en un sistema cuántico relativista el número de partículas no se conserva y de hecho no puede hablarse de una mecánica de partículas, sino simplemente de una teoría cuántica de campos. Esta teoría logra aunar principios cuánticos y teoría de la relatividad especial (aunque no logra incorporar los principios de la relatividad general). Dentro de esta teoría, no se consideran ya estados de las partículas sino del espacio-tiempo. De hecho cada uno de los estados cuánticos posibles del espacio tiempo viene caracterizado por el número de partículas de cada tipo representadas por campos cuánticos y las propiedades de dichos campos.

Es decir, un universo donde existan "N" partículas del tipo "i" en los estados cuánticos "E", …, "E" representa un estado cuántico diferente de otro estado en el que observamos en mismo universo con un número diferente de partículas. Pero ambos "estados" o aspectos del universo son dos de los posibles estados cuánticos físicamente realizables del espacio-tiempo. De hecho la noción de partícula cuántica es abandonada en la teoría cuántica de campos, y esta noción se substituye por la de campo cuántico. Un campo cuántico es una aplicación que asigna a una función suave sobre una región del espacio-tiempo un operador autoadjunto. La función suave representa la región donde se mide el campo, y los valores propios del operador número asociado al campo el número de partículas observables a la hora de realizar una medida de dicho campo.




</doc>
<doc id="1936" url="https://es.wikipedia.org/wiki?curid=1936" title="Matrimonio">
Matrimonio

El matrimonio (del latín: "matrimonīum") es una institución social, presente en gran cantidad de culturas, que establece un vínculo conyugal entre personas, reconocido y consolidado por medio de prácticas comunitarias y normas legales, consuetudinarias, religiosas o morales. La unión matrimonial establece entre los cónyuges —y en muchos casos también entre las familias de origen de estos— derechos y obligaciones que varían considerablemente según las normas que lo regulan en cada sociedad. El matrimonio es una realidad que tiene su propio modo de ser, que puede y debe ser regulado por el ordenamiento jurídico, pero no es creada ni definida por las leyes.

Las normas matrimoniales están vinculadas con aquellas que regulan las relaciones sexuales (incesto, adulterio, exclusividad sexual, monogamia, poligamia), la reproducción y la filiación de los hijos, según las reglas del sistema de parentesco vigente. El matrimonio suele estar estrechamente relacionado con la familia y en algunos casos constituye su núcleo. Las reglas sobre el final del matrimonio incluyen aquellas referidas al divorcio.

En diversos momentos de la historia y en lugares diferentes, el matrimonio podía ser llevado a cabo sin tener en cuenta la voluntad de los contrayentes, incluso contra su voluntad o por la fuerza, muchas veces legitimando la posesión forzada de las mujeres por parte de los hombres. En los últimos dos siglos se ha universalizado la exigencia del libre y pleno consentimiento de los contrayentes para contraer matrimonio, como uno de los derechos humanos fundamentales. Con respecto al género de los contrayentes, en los últimos años el movimiento LGBT ha obtenido en varios países el reconocimiento legal del matrimonio entre personas del mismo sexo.

En las sociedades actuales existen dos formas principales de matrimonio: matrimonio civil y matrimonio religioso. En el primer caso son las leyes del Estado las que establecen los derechos, deberes y requisitos, mientras que en el segundo caso son las normas o costumbres de la religión bajo la que se celebra. La coexistencia de ambas formas y el reconocimiento de su validez varían de acuerdo a cada sociedad.

De acuerdo a las estimaciones de la División de Población de Naciones Unidas, en 1970 el 68,8% de las mujeres entre 15 y 49 años de edad se encontraban en unión o casadas y se proyecta que en 2030 este porcentaje descienda al 63,1%. 

El origen etimológico de la palabra "matrimonio" como denominación de la institución bajo ese nombre no es claro. Se suele derivar de la expresión ""matris munium"" proveniente de dos palabras del latín: la primera ""matris"", que significa "madre" y, la segunda, ""munium"", "gravamen o cuidado", viniendo a significar "cuidado de la madre por el marido/padre", en tanto se consideraba que la madre era la que contribuía más a la formación y crianza de los hijos. Otra posible derivación provendría de ""matreum muniens"", significando la idea de defensa y protección de la madre, implicando la obligación del hombre hacia la madre de sus hijos.

Para una comprensión más amplia de la expresión "matrimonio" en su aspecto etimológico en muchas de las lenguas romances se debe tener en cuenta el concepto del contrato de matrimonio considerado por el Derecho Romano, que tiene su fundamento en la idea de que la posibilidad de ser madre, que la naturaleza da a la mujer núbil, la llevase a procrear una familia.

Una lectura, que pretende ir más allá de la pura etimología de los dos términos que componen la palabra, hace derivar el significado originario del segundo término "monium", que se encuentra también en patri-monium y merci-monium, y que alude a "agente" o "acción"): según tales fuentes, el concepto de matrimonio remitiría a una acción por parte de la mujer y que pareciera remontarse al rol de la mujer en las sociedades matriarcales.

En contraste con ese concepto occidental se puede mencionar el caso del idioma árabe, en el que es entendido como «contrato de coito» o «contrato de penetración», según la traducción de la expresión عَقْد نِكاح ("`aqd nikāḩ") al español. Con todo, el término más usado en árabe para referirse a esta institución es زَواج ("zawāý"), que literalmente significa «unión, emparejamiento».

Según el paleoantropólogo Owen Lovejoy, el ardipithecus ramidus, un ancestro del ser humano, habría encontrado la ventaja de caminar sobre sus dos pies con el fin de poder tener las manos libres para llevar comida a una hembra. Esta conducta habría disminuido la lucha entre esta clase de homínidos por el apareamiento, pues la hembra prefiriría al macho sustentador más que al macho alfa. Asimismo, esta conducta habría hecho desaparecer antiguas espinas de queratina presentes en el pene de estos homínidos, lo que a su vez habría disminuido la sensibilidad táctil reproductiva e incrementado la duración del coito, lo que generaría una mayor duración de la cópula en nuestra especie respecto de nuestros antepasados, favoreciendo la creación de un vínculo más estable en la pareja y con ello la monogamia. Alan Dixson concluye que «"La propensión de los hombres y las mujeres a formar relaciones duraderas con fines reproductivos es un rasgo antiguo, probablemente presente en los primeros miembros del género humano. La existencia de tales relaciones entre los sexos es universal en las poblaciones humanas existentes, y su existencia en formas ancestrales proporcionó la base biológica para la aparición posterior del matrimonio"». 

Durante el tercer siglo de nuestra era se produjo, en Occidente, el pasaje de una sociedad en la que el matrimonio no era de ningún modo una institución creada para toda la sociedad, a una sociedad en la que se da por sentado, como natural que el matrimonio es una institución fundamental para todos.

En las sociedades no cristianas, judías o musulmanas, el matrimonio no era la norma, el matrimonio era utilizado solo por los poderosos, por las clases altas. En la antigua Roma la castidad no era una virtud, no era necesario contraer matrimonio para tener relaciones sexuales ni para tener hijos. Solamente cuando un miembro de una clase social elevada deseaba transmitir su patrimonio a sus descendientes directos, en vez de que lo reciban otros miembros de la familia o sus amigos, decidía casarse. Pero la mayor parte de las veces se legaba los bienes a un amigo o una persona muy querida, no a los hijos. Cuando se carecía de patrimonio o bienes el matrimonio era un trámite prescindible, los esclavos directamente carecían del derecho de hacerlo.

El griego no tiene una palabra específica para designar el matrimonio, ya que no existía un trámite ni civil ni religioso. Sin embargo, la palabra por la que se suele traducir "matrimonio" en griego koiné es γάμος ("gámos"), sustantivo del griego γαμέω ("gaméo"), cuyo significado es «tomar mujer, casarse». En Atenas, en la Grecia clásica, para el acto mediante el cual un varón se comprometía a unirse a una mujer, se utilizaba el vocablo griego ἐγγύη ("engúē") literalmente la garantía, la caución, es decir, el acto por el cual el padre cabeza de familia entregaba su hija a otro hombre. La ciudad no era testigo ni registraba ningún acta para este acontecimiento privado entre dos familias. Este contrato solo se realizaba cuando existía patrimonio para heredar. Los herederos de la mujer en la Antigua Grecia eran los hijos pero no el esposo.

La dote que la familia de la novia proporcionaba no era propiedad del esposo. Cuando la mujer moría sin hijos o en caso de divorcio, la dote volvía a la familia de la mujer. El tutor de la mujer (su padre o su hermano) podían pedir el divorcio (aun en contra del deseo de la mujer) pero ella no tenía derecho a solicitar la disolución del contrato. Tampoco tenía derecho a elegir a su futuro esposo. En caso de divorcio no recibía parte alguna de los bienes del matrimonio sino, simplemente la devolución de la dote que aportó.

El objetivo de la ἐγγύη ("engúē") era dar nacimiento a hijos legítimos que pudieran heredar los bienes paternos. Una estricta fidelidad era requerida de parte de la esposa, en caso de adulterio era devuelta a la casa paterna. Para el varón, el adulterio, especialmente con esclavas, esclavos o prostitutas, estaba permitido.

En Esparta los varones no convivían con sus mujeres pero el objetivo era producir chicos fuertes. El varón se reunía con su mujer en la oscuridad y después de tener relaciones con ella se marchaba para reunirse en su dormitorio con el resto de los jóvenes varones. Plutarco afirmaba que, así, los esposos «ignoran la saciedad y el declive del sentimiento que entraña una vida en común sin trabas». Los varones, que generalmente doblaban en edad a sus mujeres, eran incitados a «prestar» sus mujeres a jóvenes fuertes. Plutarco menciona también que las mujeres tomaban a veces un amante para que su hijo niño pudiera heredar dos lotes de tierra en lugar de uno.

En la Europa del norte, durante la Edad Media, se produjo un lento reemplazamiento de la ley germánica -por la que el contrato matrimonial se establecía entre el novio y el guardián de la mujer- por los códigos civiles cristianos -donde se requería el consentimiento de la mujer-. En el siglo XII el principio legal del matrimonio por consentimiento estaba establecido y los matrimonios impuestos comenzaban a quedar atrás. El proceso de urbanización también contribuyó a dicho proceso ya que liberaba en parte a la mujer de la tarea de procreación.

La forma histórica y tradicional de matrimonio es entre un hombre y una mujer, con la finalidad de constituir una familia. Esa definición ortodoxa ha sido cuestionada, de una parte, porque se ha otorgado reconocimiento a las uniones entre un hombre y una mujer con finalidades prácticamente idénticas al matrimonio, pero que adoptan formas y denominaciones distintas (v. infra las "sociedades de convivencia"). Por otro lado, el desarrollo de nuevos modelos de familia han desvinculado la función reproductiva del matrimonio: parejas no casadas con hijos o matrimonios sin hijos madres y padres solteros o madres y padres con una pareja de su mismo sexo. Finalmente, en varios países y estados se ha producido una ampliación de derechos que ha dado reconocimiento al matrimonio entre personas del mismo sexo.

En esos casos el matrimonio se realiza, generalmente, por la forma civil o de Estado, porque las normas de muchas religiones no permiten este tipo de uniones en su seno.

Con todo, en distintos tiempos y lugares se han reconocido otras variedades de matrimonio.

La monogamia es la práctica más común.

El matrimonio se considera una institución importante porque contribuye a definir la estructura de la sociedad, al crear un lazo de parentesco entre personas (generalmente) no cercanas en línea de sangre (al respecto, recordemos que también hay comunidades en las que se acostumbra el matrimonio entre primos o entre parientes de distintos grados; véanse las entradas acerca de la endogamia y el incesto). Una de sus funciones ampliamente reconocidas es la procreación y socialización de los hijos (si bien no es absolutamente necesario casarse para tener hijos, ni todos los matrimonios heterosexuales los tienen), así como la de regular el nexo entre los individuos y la descendencia que resulta en el parentesco, rol social y estatus.

El papel del sexo y del amor en el matrimonio se ha estudiado con diferentes enfoques: pedagógico y de preguntas y respuestas.

En las sociedades de influencia occidental suele distinguirse entre matrimonio religioso y matrimonio civil, siendo el primero una institución cultural derivada de los preceptos de una religión, y el segundo una forma jurídica que implica un reconocimiento y un conjunto de deberes y derechos legal y culturalmente definidos.

Las características generales de la institución del matrimonio incluidas en algunos ordenamientos jurídicos son la dualidad, la heterosexualidad y el contenido en cuanto a derechos y deberes. A partir del siglo XX, en las sociedades de influencia occidental y procedente del liberalismo se recoge también el principio de igualdad, con un peso creciente en las regulaciones derivadas.




El matrimonio produce una serie de efectos jurídicos entre los cónyuges y frente a terceras personas, de los cuales los fundamentales son los deberes u obligaciones conyugales, el parentesco, la adquisición de derechos de sucesión entre los cónyuges y el régimen económico del matrimonio, que tiene distintas modalidades en los diferentes países. Además, en varios países produce de derecho la emancipación del contrayente menor de edad, con lo cual este queda libre de la patria potestad de sus padres y podrá en adelante actuar como si fuera mayor, aunque posteriormente se divorcie.

El matrimonio religioso se puede definir como una unión cuya estructura esencial viene exigida por los dogmas de la religión a la que pertenecen los contrayentes.

Para la Iglesia católica, el matrimonio es una alianza por la que un hombre y una mujer constituyen una íntima comunidad de vida y de amor. Por su naturaleza está ordenada al bien de los cónyuges y a la generación y educación de los hijos. Entre bautizados, el matrimonio es, además, un sacramento. Por eso, un matrimonio de paganos que, al cabo de los años, recibiera el bautismo, no necesita repetir ningún rito o ceremonia: en el momento de recibirlo, su vínculo conyugal se convierte en sacramento.

Según la Iglesia Católica, el origen del matrimonio entre una pareja no es solo cultural, sino que procede de la misma naturaleza humana en cuanto que (como dice el libro del Génesis (1-27), en la Biblia) al principio "Dios los creó hombre y mujer". El matrimonio sería, por tanto, una institución y no un producto cultural cuyas principales características -unidad, indisolubilidad y apertura a la vida- vendrían definidas por la propia naturaleza del concepto católico de amor entre hombre y mujer, que exige a los esposos o cónyuges amarse el uno al otro para siempre y que alcanza su mayor expresión en la procreación. Por eso, la Iglesia Católica se ha opuesto tradicionalmente al adulterio, la poligamia, el rechazo de la fecundidad y el divorcio. También, recientemente, se ha manifestado en contra tanto a las legislaciones que permiten las uniones entre personas del mismo sexo como a aquellas que equiparan el estatus jurídico de dichas uniones al del matrimonio, porque entiende que «significaría no solamente aprobar un comportamiento desviado y convertirlo en un modelo para la sociedad actual, sino también ofuscar valores fundamentales que pertenecen al patrimonio común de la humanidad».

Para los católicos, el fundamento del matrimonio se encuentra en Mateo 19:3-9; Marcos 10:9; Lucas 16:18; 1 Corintios 7:10-11 y en las siguientes palabras del Génesis:
La celebración del matrimonio según el rito romano no fue declarada obligatoria hasta el siglo XVI, en el Concilio de Trento.

En el judaísmo el matrimonio está basado en las leyes de la Torá, en la unión la pareja se dedica de forma exclusiva al otro, este contrato es llamado "kiddushin" (en hebreo: אירוסין). Aunque la procreación no es el único propósito, en un matrimonio judío se espera que se cumpla el mandamiento de tener hijos. De forma espiritual, el matrimonio se entiende como la unión de dos personas en una sola alma; por ello, de acuerdo al judaísmo un hombre es considerado incompleto si no está casado y su alma es solo una parte que pertenece a un conjunto más grande que tiene que ser unificado. La biblia hebrea describe varios matrimonios con múltiples esposas, la poliginia es uno de los contratos más comunes representados en el antiguo testamento. Los judíos ashkenazi tienen prohibido casarse con varias esposas. Sin embargo, entre los hebreos antiguos, el matrimonio no tenía connotación religiosa, por lo tanto la participación de un rabino no era requerida. Como la esposa era vista como una propiedad, su marido podía obtener el divorcio por cualquier motivo y en cualquier momento.

El texto midrash (en hebreo: מדרש‎, «explicación») se hace referencia a una boda entre personas del mismo sexo. En el judaísmo masortí se aprobaron las uniones homosexuales en el año 2012 y el judaísmo reformista aprobó en 1996 la realización de matrimonios civiles entre el mismo sexo, sin embargo dejó en claro que los matrimonios religiosos estaban reservados a un hombre y una mujer. En marzo de 2000, la conferencia central de rabinos, organización del judaísmo reformista, aceptó la realización de ceremonias religiosas entre personas judías sin importar su orientación sexual.

El matrimonio es un contrato legal firmado por los contrayentes, bajo la ley islámica es llamado "nikah", un hombre y una mujer; la ley islámica, a través del "fiqh", considera que solo el marido tiene permiso legal para obtener un divorcio por cualquier motivo. Los suníes, el grupo musulmán más grande, celebran el matrimonio bajo la presencia obligatoria de al menos dos testigos, consistentes en un guardian de la novia y otro invitado. En cambio, en el chiismo, el matrimonio entre islamistas chiitas puede ser celebrado sin la presencia de testigos.

En el hinduismo el matrimonio es un deber sagrado, incluye obligaciones tanto religiosas como sociales. Existen gran variedad de tipos de matrimonio, tales como el "gandharva vivaha" (matrimonio instantáneo con consentimiento mutuo) y el "rakshasa vivaha" o también llamado «matrimonio demoniaco», donde la pareja secuestra a su esposa. El matrimonio arreglado sigue presente en gran parte del subcontinente de la India. Las bodas del hinduismo son grandes celebraciones amenizadas con música, bailes y grandes multitudes. Se interpretan además rituales y comidas para bendecir a la pareja. Existen puntos de vista tanto conservadores como liberales del matrimonio homosexual en el hinduismo, aun así han sido celebrados. El téxto erótico kama-sutra incluye referencias a matrimonios entre personas del «tercer género» y bodas homosexuales, donde «parejas del mismo sexo se unen en completa fe».

El budismo considera al matrimonio como un asunto secular y no lo considera ni prohibido ni obligatorio. Los budistas siguen las leyes civiles de sus respectivos gobiernos. Aunque la ceremonia es completamente civil, algunas parejas budistas obtienen la bendición de monjes en templos locales; de igual forma al ser considerado secular, no existen tratados o textos relativos al divorcio.

Matrimonio forzado es el término utilizado para describir un matrimonio en el cual una o las dos partes se casa en contra de su voluntad y a la fuerza. Los matrimonios forzados son comunes en Asia y África. La mayoría de contrayentes forzados son mujeres, aunque hay casos en los que las víctimas son varones, a los que se fuerza a casar para limpiar la honra de la familia de la mujer. El matrimonio forzado viola los derechos humanos, está en contra de la Declaración Universal de los Derechos Humanos y puede ser considerado una forma de esclavitud.

El matrimonio infantil es un tipo de matrimonio en el que los menores contraen nupcias a menudo antes de la pubertad. Los matrimonios infantiles son comunes en muchas partes del mundo, especialmente en partes de Asia y África. Estos matrimonios son a menudo forzados. El matrimonio infantil es una práctica habitual en África subsahariana y Asia meridional. El matrimonio infantil tiene efectos negativos, como abandono de la educación, problemas de salud y malos tratos. Según ONU, los diez países con las tasas más altas de matrimonio infantil son: Níger, Chad, República Centroafricana, Bangladesh, Guinea, Mozambique, Malí, Burkina Faso, Sudán del Sur y Malawi.

Entre las formas de matrimonio, reconocemos los matrimonios heterosexuales, homosexuales (del mismo sexo), bisexuales y mezclados. Una de las formas del matrimonio mezclado, o bien de las personas de la orientación sexual distinta, es "matrimonio lavanda" (en inglés "lavender marriage"), que es matrimonio entre persona heterosexual con una persona homo- o bisexual para ocultar el hecho de que, por el ostracismo social, religioso o familiar, o por la razón de presión social por la parte de la sociedad, religión o familia.

El matrimonio entre personas del mismo sexo reconoce legal o socialmente un matrimonio formado por contrayentes del mismo sexo biológico o identidad de género.

Las primeras leyes de la época actual en reconocer el matrimonio entre personas del mismo sexo fueron aprobadas durante la primera década del siglo XXI. Al , veintiocho países (Alemania, Argentina, Australia, Austria, Bélgica, Brasil, Canadá, Colombia, Costa Rica, Dinamarca, Ecuador España, Estados Unidos, Finlandia, Francia, Irlanda, Islandia, Luxemburgo, Malta, Noruega, Nueva Zelanda, Países Bajos, Portugal, Reino Unido Sudáfrica, Suecia, Taiwán, Uruguay) y varias jurisdicciones subnacionales de México, permiten casarse a las parejas del mismo sexo. Sin embargo, siguen existiendo países en los que el matrimonio homosexual es ilegal, así como aquellos que penalizan las solas relaciones entre personas del mismo género considerándolas criminales.

El servinakuy o sirviñaco es una institución de origen andino, vigente en Argentina, Bolivia y Perú, que constituye un tipo de matrimonio a prueba. El servinakuy fue perseguido durante la época virreinal, pese a lo cual sobrevivió y se consolidó. El servinakuy se formaliza con el compromiso formal y público de los cónyuges, de establecer una relación de convivencia matrimonial, incluyendo las relaciones sexuales, sin ninguna obligación de mantenerla en el tiempo. En caso de que el servinakuy resulte satisfactorio para ambos contrayentes, la regla consuetudinaria es contraer matrimonio definitivo, sujeto a las normas de duración de cada comunidad. En caso de que el servinakuy no sea satisfactorio para los contrayentes, cualquiera de ellos puede darla por terminada, sin que suponga ningún perjuicio moral o legal. De existir hijos, tradicionalmente permanecían al cuidado de la madre, aunque más recientemente se aplican crecientemente las normas de cuidado compartido establecidas en la Convención sobre los Derechos del Niño.





</doc>
<doc id="1939" url="https://es.wikipedia.org/wiki?curid=1939" title="Man">
Man

Man hace referencia a varios artículos:






</doc>
<doc id="1942" url="https://es.wikipedia.org/wiki?curid=1942" title="Muerte">
Muerte

La muerte (a veces referida por los eufemismos deceso, defunción, fallecimiento, finamiento, óbito, expiración, perecimiento, fenecimiento o cesación) es un efecto terminal que resulta de la extinción del proceso homeostático en un ser vivo; y con ello el fin de la vida. Puede producirse por causas "naturales" (vejez, enfermedad, consecuencia de la cadena trófica, desastre natural) o "inducidas" (suicidio, homicidio, eutanasia, accidente, desastre medioambiental). 

El proceso de fallecimiento, si bien está totalmente definido en algunas de sus fases desde un punto de vista neurofisiológico, bioquímico y médico, aún no es del todo comprendido en su conjunto desde el punto de vista termodinámico y neurológico, y existen discrepancias científicas al respecto.

La muerte se puede definir como un evento resultante de la incapacidad orgánica de sostener la homeostasis. Dada la degradación del ácido desoxirribonucleico (ADN) contenido en los núcleos celulares, la réplica de las células se hace cada vez más costosa.

En el siglo XX la muerte se definía como el cese de la actividad cardíaca (ausencia de pulso), ausencia de reflejos y de la respiración visible. No obstante, con base en estas evidencias insuficientes muchas personas fueron inhumadas estando en estado de vida latente o afectadas por periodos de catalepsia.

Posteriormente, gracias a los avances tecnológicos y al mejor conocimiento de la actividad del cerebro, la muerte pasó a definirse como la ausencia de actividad bioeléctrica en el cerebro, verificable con un electroencefalograma. Más tarde aún esta evidencia demostró ser insuficiente, al demostrarse que el fenómeno de ausencia de actividad bioeléctrica en algunos casos muy excepcionales podía ser reversible, como en el caso de los ahogados y dados por fallecidos en aguas al borde del punto de congelación.

Históricamente los intentos por definir el momento preciso de la muerte han sido problemáticos. Antiguamente se definía la muerte como el momento en que cesan los latidos del corazón y la respiración, pero el desarrollo de la ciencia ha permitido establecer que realmente la muerte es un proceso, el cual en un determinado momento, se torna irreversible. Hoy en día, cuando es precisa una definición del momento de la muerte, se considera que este corresponde al momento en que se produce la irreversibilidad de este proceso. Existen en medicina protocolos clínicos que permiten establecer con certeza el momento de la muerte, es decir, que se ha cumplido una condición suficiente y necesaria para la irreversibilidad del proceso de muerte.

Forma irreversible de la pérdida de conciencia que se caracteriza por una desaparición completa de la función cerebral, con mantenimiento de la contracción cardiaca. Gracias al avance tecnológico de la medicina, hoy es posible mantener una actividad cardiaca y ventiladora artificial en cuidados intensivos en una persona cuyo corazón ha dejado de latir y que no es capaz de respirar por sí misma, por lo cual esto demuestra que no ha fallecido. El protocolo utilizado para el diagnóstico de la muerte en este caso es diferente y debe ser aplicado por especialistas en ciencias neurológicas, y se habla entonces de "muerte cerebral" o "muerte encefálica". En el pasado, algunos consideraban que era suficiente con el cese de actividad eléctrica en la corteza cerebral (lo que implica el fin de la conciencia) para determinar la muerte encefálica, es decir, el cese definitivo de la conciencia equivaldría a estar muerto, pero hoy se considera, en casi todo el mundo, difunta a una persona (incluso si permanece con actividad cardiaca y ventiladora gracias al soporte artificial en una unidad de cuidados intensivos), tras el cese irreversible de la actividad vital de todo el cerebro, incluido el tallo cerebral (la estructura más baja del encéfalo, encargada de la gran mayoría de las funciones vitales), comprobada mediante protocolos clínicos neurológicos bien definidos y respaldada por pruebas especializadas.

En estos casos, la determinación de la muerte puede ser dificultosa. Un electroencefalograma, que es la prueba más utilizada para determinar la actividad eléctrica cerebral, puede no detectar algunas señales eléctricas cerebrales muy débiles o pueden aparecer en él señales producidas fuera del cerebro y ser interpretadas erróneamente como cerebrales. Debido a esto, se han desarrollado otras pruebas más confiables y específicas para evaluar la vitalidad cerebral, como la tomografía por emisión de fotón único (SPECT cerebral), la panangiografía cerebral y el ultrasonido transcraneal.

La muerte súbita o muerte instantánea sobreviene de manera abrupta con la invalidación instantánea de uno o más órganos esenciales para el sustento de la vida, un fulminante derrame cerebral, un síncope cardíaco agudo o por medio de un suceso violento abrupto (onda expansiva de una explosión) o un accidente con mucha energía desarrollada.

Es el fin de la vida, opuesto al nacimiento. El evento de la muerte es la culminación de la vida de un organismo vivo. Sinónimos del sustantivo "muerte" son óbito, defunción, deceso y fallecimiento; entre los adjetivos, occiso se aplica cuando la persona falleció violentamente.

Se suele decir que una de las características clave de la muerte es que es definitiva, y en efecto, los científicos no han sido capaces hasta ahora de presenciar la recomposición del proceso homeostático desde un punto termodinámicamente recuperable.

El tipo de muerte más importante para el ser humano es sin duda la muerte humana, sobre todo la muerte de seres queridos. Conocer con certeza el instante de una muerte sirve, entre otras cosas, para asegurar que el testamento del difunto será únicamente aplicado tras su muerte y, en general, conocer cuándo se debe actuar bajo las condiciones establecidas ante una persona difunta.
Existe la muerte psicológica, donde la persona es consciente de que va a morir. En este sentido, la persona es capaz de percibirlo. Esta muerte psicológica causa con frecuencia ansiedad y depresión en las personas. La muerte psicológica aceptada permite que la persona pueda adaptarse, con los recursos que le quedan, a su entorno.

Algunas personas, en momentos determinados de su vida, experimentan el sentimiento autodestructivo de terminar su existencia. El acto para conseguirlo es lo que llamamos suicidio.

Lo contrario es el deseo de vivir, el cual no contraría al instinto de supervivencia, ya que este nos impulsa a esquivar la muerte. Por ejemplo, si un suicida que salta al vacío intenta inconscientemente agarrarse a algo para no morir, es por el instinto de supervivencia.

El miedo a la muerte se debe a dos hechos que ocurren dentro de nuestro inconsciente. En primer lugar, la muerte nunca es posible con respecto a nosotros mismos; es decir, la causa de la muerte es externa, en este sentido, se le atribuye un carácter maligno; la muerte es mala y se encuentra en el ambiente, no en nosotros mismos. Siguiendo esto, para nuestro inconsciente es inconcebible morir por alguna causa natural o vejez. En segundo lugar, la persona no es capaz de distinguir entre un deseo y la realización de este (un hecho); esto justifica la muerte sobre la base de la culpa donde el deseo y la realidad generan un conflicto. Así, la persona se considera responsable de la muerte del otro en el sentido de que el deseo de matarlo y el hecho de la muerte genera culpabilidad. Asimismo, el proceso del dolor siempre lleva consigo algo de ira. En este sentido, se depositan en la persona muerta dos sentimientos diferenciados: el amor que se tiene y ha tenido por esta a lo largo de su vida, y el odio generado por la sensación de abandono que genera la pérdida de este ser querido. El miedo a la muerte surge como una negación hacia la existencia de esta.

La concepción de la muerte como fin o como tránsito, su creencia en una vida después de la muerte, en el Juicio Final, actúan como condicionantes para la actuación de los individuos en un sentido u otro. La idea de inmortalidad y la creencia en el Más allá aparecen de una forma u otra en prácticamente todas las sociedades y momentos históricos. Usualmente se deja al arbitrio de los individuos, en el marco de los conceptos dados por su sociedad, la decisión de creer o no creer y en qué creer exactamente. La esperanza de vida en el entorno social determina la presencia en la vida de los individuos de la muerte, y su relación con ella. Su presencia en el arte es constante, siendo uno de los elementos dramáticos a los que más se recurre tanto en el teatro, como en el cine o en novelas y relatos.

La segunda pregunta que surge acerca de la muerte humana y tal vez la más interesante es: ¿Qué ocurre a los seres humanos tras la muerte? Realmente, lo que se preguntan es qué ocurre con las facultades mentales de la persona que ha fallecido. Unos creen que se conservan gracias al espíritu que impelía a su mente, elevando su estado de conciencia a realidades aún mayores, otros creen en la migración del alma de un ser humano tras su muerte a un plano físicamente inalcanzable.

La religión cristiana considera la muerte como el fin de la permanencia física del ser humano en su estado carnal, el espíritu abandona el cuerpo físico que se deteriora y que es incapaz de sostenerse bajo las leyes de este universo finito, e inmediatamente vuelve a Dios (Eclesiastés 12:7). El alma, dependiendo de si conoció y reconoció a Jesucristo como su Dios y salvador (Romanos 10:9) se va a un lugar de reposo a la espera de la segunda venida de Jesucristo (1 Tesalonicenses 4:16) en ese lugar de reposo su relación con el Ser Supremo sería directa (el Paraíso), y el otro, el de los espíritus encarcelados quienes no reconocieron a Jesús como su Señor y Salvador deberán presentarse en el Juicio Final. Este lugar es llamado el Infierno. El Paraíso es un mundo dinámico donde se realiza una interacción con la obra de Dios y con las personas en la tierra mediante ministerio de ángeles.

Según la religión cristiana de la Iglesia de Jesucristo de los Santos de los Últimos Días (mormona), el espíritu que abandona el cuerpo es semejante en apariencia al que deja en estado carnal, pero en su forma más joven. Los conocimientos adquiridos, la apariencia física se conservan pero en un estado de perfección intangible para este mundo y más puro. Luego continuará con la resurrección universal por la gracia de Jesucristo, quien fue las primicias de la resurrección. Luego vendrá un juicio según las obras individuales de esta vida terrenal de las personas responsables. Según, la religión de los Santos de los últimos días, la obra de Dios se resume en el siguiente versículo que muestra las palabras del Dios de Israel: ""Esta es mi Obra y mi Gloria, llevar a cabo la inmortalidad y la vida eterna del hombre.” Moíses 1:39, La Perla de Gran Precio.

Para los Testigos de Jehová, la gran mayoría de los muertos se encuentran en un estado de inconsciencia absoluto y que incluso, ni el Rey David ascendió a los cielos (Eclesiastés 9:5,6,10; Hechos 2:34). Creen que cuando la "nueva tierra" (nuevo sistema, 2 Pedro 3:13) se encuentre establecida bajo el reinado milenario de Cristo, la resurrección —tanto de Justos como de Injustos— se llevará a cabo en todo el globo, y es allí donde serán juzgados según sus obras realizadas durante el milenio, los que obren mal a la muerte eterna (Muerte sin esperanza de resurrección) y los que obren bien a la vida eterna en un paraíso terrenal (Juan 5:28,29; Apoc. 20:11-15; Hechos 24:15). Creen también en otra categoría minoritaria de cristianos que abrigan otra esperanza. Estos son los 144.000 "ungidos por Espíritu Santo" que, según ellos, al fallecer van al cielo para ser reyes y sacerdotes y gobernar con Cristo “Sobre la Tierra” en el reinado Milenario. Según los Testigos de Jehová, la recolección de estos “Ungidos” que tienen esperanza celestial comenzó con los apóstoles de Cristo, cuando Jesús les ofreció moradas en el Cielo, oferta que continúa hasta el día de hoy, pero solo con algunos pocos (Apoc. 5:9,10; 7:4; 14:1-3). Asegurando que "la muerte será reducida a nada".

Muchos antropólogos (William Rendu, Centro de Investigación Internacional en Humanidades y Ciencias Sociales (CIRHUS) en Nueva York.) creen que los entierros dedicados de los Neandertales son evidencia de su creencia en la vida después de la muerte.

Existen cinco fases por las que pasa todo enfermo "terminal" (es decir, el aquejado por un mal incurable, cuyo desenlace fatal ocurrirá dentro unos pocos años o incluso meses):

La mayor parte de los escultores cristianos representan la muerte en figura de un esqueleto empuñando una guadaña y, algunas veces, también un reloj de arena o armas.

Los etruscos la pintaban con el rostro horrible o bajo una cabeza de Gorgona erizada de serpientes o en figura de lobo rabioso. La más común de las alegorías de esta divinidad entre los romanos fue un genio triste e inmóvil con una antorcha apagada y vuelta del revés.

Los helenos le daban un aspecto mucho menos lúgubre, según el emblema que se encuentra en algunas cornalinas: es un pie alado cerca de un caduceo y encima una mariposa que emprende el vuelo. El pie alado es indicio del que ya no existe y va a seguir a través del espacio a Mercurio y su caduceo; la mariposa es imagen del alma que sube al cielo.

En la Grecia clásica, uno de los temas principales de la obra "Fedro" de Platón es la muerte. Una importante investigación realizada por el historiador italiano Giordano Berti sobre el cráneo en el arte occidental se publicó en la revista "Terzo Occhio".




</doc>
<doc id="1943" url="https://es.wikipedia.org/wiki?curid=1943" title="Monkey Island">
Monkey Island

Monkey Island (en español, "La Isla del Mono", aunque el título se mantuvo en inglés para la versión española) es una saga de videojuegos de aventura gráfica producida y publicada por LucasArts, originariamente conocida como LucasFilms Games. Los juegos narran la historia de cómo Guybrush Threepwood intenta convertirse en el pirata más temido del Caribe, enfrentándose al malvado pirata LeChuck y conquistando el corazón de la gobernadora de la isla Mêlée, Elaine Marley.

Ron Gilbert, el creador de la serie, sólo trabajó en los dos primeros juegos antes de abandonar LucasArts. Los derechos de Monkey Island siguieron siendo propiedad de LucasArts, y el tercer y cuarto juegos fueron publicados sin la aportación de Gilbert. Más tarde volvió a trabajar con Monkey Island, siendo el asesor de la quinta entrega, compuesta por cinco capítulos cortos producidos por Telltale Games con licencia de LucasArts.

"The Secret of Monkey Island" (1990) fue el quinto juego en usar la tecnología SCUMM (tras Maniac Mansion, Zak McKracken, y Loom), un potente (para la época) motor para aventuras gráficas, basado en un lenguaje script propio y desarrollado para la primera aventura: Maniac Mansion. La aventura gráfica debutó primeramente en las plataformas Amiga, Atari ST, MS-DOS y Macintosh, siendo las dos primeras las de superior calidad hasta la llegada de la versión VGA y, finalmente, en CD-ROM con mejoras de sonido. Desde el 15 de julio de 2009 se encuentra disponible una edición especial realizada en alta definición (1920x1080), con un total rediseño gráfico y doblaje. Como curiosidad es posible alternar entre esta versión y la clásica mientras se está jugando, pudiendo observar los cambios realizados.

LucasArts fue la compañía que lanzó este juego al mercado, cuyos creadores fueron Ron Gilbert, Steve Purcell, Tim Schafer y Dave Grossman, dirigidos por el propio Gilbert.

El protagonista de la historia es Guybrush Threepwood, un joven que llega a la isla con la intención de convertirse en pirata, pero para ello deberá pasar por una serie de pruebas, recorriendo toda la isla y, una vez logrado, viajar a la mítica Monkey Island, donde deberá enfrentarse al terrible pirata fantasma LeChuck para rescatar a su nuevo amor Elaine Marley.

Sus frases tienen un gran sentido del humor.


En la segunda parte, encontramos a un Guybrush Threepwood rico que se lanza en búsqueda de nuevas aventuras. Sin embargo pronto es despojado de su dinero por Largo LaGrande, un matón que aterroriza la isla Scabb. Deberá hallar el mítico tesoro del Big Whoop, y recuperar de paso el amor de Elaine Marley, volviéndose a enfrentar al pirata, ahora zombi, LeChuck.

Publicado en 1991, fue realizado con el mismo motor por los mismos autores, y distribuido originalmente en disquete, con gráficos VGA para luego ser distribuido por separado y más tarde junto con la primera parte, en CD-ROM. Al igual que su predecesor, se encuentra disponible desde el 7 de julio de 2010 una edición especial realizada en alta definición (1920x1080), con un total rediseño gráfico y con doblaje. El juego tiene un inesperado final, del que se ha dicho que es el más desconcertante de la historia de los videojuegos.


En 1997 se publicó la tercera entrega, de nuevo utilizando el SCUMM (fue el último título de LucasArts que utilizó este sistema), pero en una versión mucho más avanzada que permitía gráficos de alta resolución, haciéndolo parecer una película de animación.

Al haber abandonado para entonces la empresa los autores de anteriores entregas, el juego tiene otros autores, Jonathan Ackley (que participó en The Dig) y Larry Ahern.

Guybrush Threepwood debía esta vez devolver su forma humana a Elaine, convertida en oro por el hechizo de un anillo maldito. Esta vez, LeChuck se transformará en un pirata demonio, y se cruzará de nuevo con Guybrush y Elaine.


Realizado en 2000, utilizó el motor GrimE utilizado anteriormente para Grim Fandango, por lo que sus gráficos son también "semitridimensionales". En España salió como "La Fuga De Monkey Island", convirtiéndose en el primer juego de la saga en salir en España con parte del título traducido. Actualmente está disponible para su descarga en GoG.com exclusivamente.

Los veteranos de LucasArts Sean Clark y Michael Stemmle, que ya participaron en fueron los encargados y autores del proyecto.

Narra el retorno de Guybrush y Elaine de su luna de miel, para encontrarse con que ella ha sido declarada oficialmente muerta, y van a demoler su mansión. Por supuesto eso supone la convocatoria de elecciones para elegir al nuevo gobernador de Isla Mêlée, pero esta vez no se da el típico caso "Cuando sólo hay un candidato sólo hay una elección", ya que Elaine tendrá que vérselas en las urnas con Charles L. Charles. El intento de solucionar estos problemas no es más que el principio de una historia que llevará a Guybrush de vuelta a Monkey Island.


"Tales of Monkey Island" es una saga de aventura de cinco capítulos mensuales, fue producida por Telltale Games para PC, Mac y Wii, y su fecha de lanzamiento fue el 7 de julio de 2009.

Durante una acalorada batalla con su némesis, el malvado pirata LeChuck, Guybrush inintencionalmente libera una maliciosa maldición que se dispersa velozmente por el Caribe, convirtiendo a los piratas en zombis monstruosos. La sacerdotisa vudú envía a Guybrush en la búsqueda de "La Esponja Grande", una legendaria esponja marina que le permitirá frenar la epidemia, pero esta aparentemente sencilla misión tiene insospechables sorpresas.


Fue lanzado el 15 de julio de 2009. Es el regreso de la primera parte de la saga Monkey Island, pero en alta definición, música remasterizada y con las voces de The Curse of Monkey Island.

La interfaz también se ha mejorado para la ocasión, ocultando la famosa tabla de verbos y el inacabable inventario. Así mismo, la edición especial incluye un sistema de pistas, algunas escenas que se omitieron en la versión original por falta de espacio -como un primer plano del locuaz Spiffy, el perro del Scumm Bar que nos resumía la situación sin darnos cuenta- y la posibilidad de volver a los gráficos de antaño con tan sólo pulsar un botón.

Sin embargo, la versión clásica no tiene los textos en español, algo incomprensible pues la traducción ya existía y de hecho se usa con la visión renovada.

A la venta desde el 7 de julio de 2010. Al igual que ocurría en la Edición Especial de Monkey Island 1, en este caso nos encontramos con el "remake" de la segunda parte de la saga Monkey Island, donde el juego ha sido completamente reeditado utilizando gráficos en alta definición y música remasterizada.

De nuevo la interfaz de acciones se vuelve más gráfica y junto al panel de inventario quedan ocultos para dar prioridad a los gráficos de cada escena del juego. También en esta edición especial contaremos con un sistema de pistas (aunque uno de los retos del juego consiste en completarlo sin usar ni una sola ayuda de este tipo). Y como ya ocurría en la edición especial de Monkey Island 1, se podrá acceder en cualquier momento a la versión clásica del juego de forma instantánea simplemente pulsando un botón para posteriormente, si lo deseamos, regresar del mismo modo a la nueva versión y así comprobar los contrastes entre ambas versiones.

Además como extra se incluyen a lo largo del juego la opción de escuchar los comentarios de los creadores del juego original entre ellos Ron Gilbert que analizan cada escena y situación por las que pasa el personaje protagonista.

El 9 de septiembre de 2011 salió en Europa para PlayStation 3, Xbox 360 y PC un recopilatorio en formato físico de los dos primeros juegos remasterizados: y .

Además de los dos juegos en sí, el disco viene con numerosos extras, como la banda sonora de ambos juegos, y el boceto y el guion de una película de Monkey Island, desarrollada por Industrial Light & Magic que nunca llegó a ver la luz.



</doc>
<doc id="1945" url="https://es.wikipedia.org/wiki?curid=1945" title="Multiple Arcade Machine Emulator">
Multiple Arcade Machine Emulator

MAME (Originalmente un acrónimo de «Multiple Arcade Machine Emulator») es un emulador multipropósito de máquinas recreativas, libre y de código abierto, que replica el hardware de estos equipos para su funcionamiento en computadoras domésticas y otros tipos de dispositivos. El objetivo del proyecto es preservar décadas de historia del software, que de otra manera se perdería o sería olvidado. Con el tiempo, MAME absorbió su proyecto hermano MESS («Multi Emulator Super System»), de manera que hoy en día, MAME documenta una amplia variedad de sistemas entre los que se cuentan computadoras, consolas de videojuegos, calculadoras, además de las máquinas recreativas para lo cual fue originalmente creado. El medio digital Joystiq se ha referido a MAME como una aplicación que todo jugador de Windows o Mac debería tener.

La primera versión fue publicada el 5 de febrero de 1997 por el desarrollador de software italiano Nicola Salmoria. Actualmente, MAME soporta más de siete mil juegos únicos y cerca de una decena de miles de imágenes ROM, a pesar de que no todos los juegos soportados son "jugables".

Previo a la creación de este emulador, la enorme diversidad del hardware de las máquinas recreativas hizo de la emulación de sus juegos una tarea muy compleja y desordenada.

Para facilitar la emulación de las máquinas recreativas, Nicola Salmoria creó MAME al fusionar varios emuladores en los que había estado trabajando. Basó su estructura en una arquitectura modular, en la que cada componente del hardware era emulado por medio de un driver específico, de tal forma que para la emulación de una máquina, basta con dar la información de qué componentes tiene, y cómo se relacionan.

El objetivo del desarrollo del MAME es contribuir a la conservación de juegos que, de otra forma, desaparecerían para siempre al desaparecer las máquinas que los contenían, contribuyendo a conservar la historia de los videojuegos.

El desarrollo del proyecto MAME se ha visto obstaculizado en estos años por distintos factores:

MAME emula actualmente la mayoría de los juegos de recreativos del siglo XX e inicios del XXI, en total más de 5.000 juegos distintos emulados, la mayoría en múltiples versiones.

Legalmente, no se puede utilizar MAME, ni ningún otro emulador, con el archivo ROM de un juego cuya ROM física no se tenga en propiedad, o el permiso de emulación correspondiente. Esto hace que con el emulador nunca se distribuyan juegos de ningún tipo, porque podrían provocar graves problemas legales, aún en el caso de juegos con más de 20 años de antigüedad.
Sin embargo, esto no quiere decir que no existan ROMs a las que se pueda emular legalmente; varios juegos han sido liberados voluntariamente por sus creadores a petición de desarrolladores del proyecto M.A.M.E.

En un punto más oscuro se encuentran las licencias que no han sido liberadas de juegos desarrollados por compañías ya desaparecidas, porque en este caso no se puede determinar quién es el dueño de la licencia.

Igualmente, pese a la prohibición del uso y distribución de muchas de los ROMs, estas ROMs se pueden encontrar ilegalmente distribuidas en páginas de internet para su descarga.

Uno de los problemas que experimentan los usuarios al momento de utilizar este programa emulador, es la compatibilidad de las ROMs (archivos que contienen los juegos) que existe en cada versión de MAME: una ROM que funciona en una versión más antigua de MAME no siempre funciona en una versión más reciente de MAME; ello ya que por ejemplo pueden crearse nuevas copias de mejor calidad del archivo ROM, con lo cual queda obsoleta la versión antigua.

MAME siempre se ha distribuido bajo una licencia Copyleft propia llamada "MAME-like license" en la que el código fuente estaba disponible siempre y cuando no se usara para fines comerciales, esto imposibilitó a los dueños de arcades que instalasen MAME en sus muebles para evitar posibles represalias por los dueños de los juegos. Dicha licencia por tanto era incompatible con la OSI y la Free Software Foundation.

El 20 de mayo de 2015 se anunció en el sitio web de MAME que el emulador estaba en transición de ser código abierto con la idea de licenciar el código en BSD-3. Finalmente el 4 de marzo de 2016 MAME como también MESS se vuelve 100% código abierto, mientras el 90% del código es licenciado en BSD-3, el proyecto como tal se publica bajo la licencia GPLv2.

Aun cuando MAME es software libre, la marca aún le sigue perteneciendo a Nicola Salmoria.

MAME se desarrolla en versiones Windows y DOS, pero existen versiones para otras plataformas, como Linux, Mac OS, AmigaOS, QNX, e incluso de forma no oficial para Nintendo DS, Nintendo 64, Dreamcast, GP32, GP2X, GP2X Wiz, Dingoo A320, Nokia S60, Android, PlayStation 2, PlayStation Portable, XBOX, iPhone, Motorola A1200, ROKR E6 y Wii.




</doc>
<doc id="1947" url="https://es.wikipedia.org/wiki?curid=1947" title="Michel Henry">
Michel Henry

Michel Henry fue un filósofo y novelista francés, nacido en Vietnam (1922-2002). Desarrolla una filosofía de la afectividad profundamente original con la que se pretende llevar a término el proyecto de la fenomenología husserliana y de la ontología de Heidegger. Sus tesis fundamentales pueden enunciarse del siguiente modo:


Con estas tesis Henry asigna un contenido fenomenológico a la noción moderna de Sujeto a la vez que transforma el antiguo problema del ser. En efecto, siendo la afectividad el modo de aparecer de todo lo que aparece y también su sustancia, se ha de decir en adelante: el ser "es" sólo en virtud de su aparecer, esto es, de su afectividad. Con ello la ontología queda supeditada a la fenomenología. Por su parte, la afirmación de que el sujeto es autoafección pura significa que él no es algún ente en particular, por ejemplo algún ente dotado de cierta propiedad privilegiada (vs Heidegger). El sujeto henryano es simplemente la aparición del aparecer, identificada fenomenológicamente con la afectividad pura y esta, a su vez, con el ser.

Esta filosofía de la inmanencia radical de la vida (comprendida como afectividad) se opone con fuerza a todo objetivismo y a todo positivismo incompleto. Se opone, en suma, a cualquier filosofía donde la representación fuera comprendida como esencia de la realidad. Pero también a toda metafísica del inconsciente, que Henry comprende como un avatar inevitable de un objetivismo mal elaborado. Según Henry, la filosofía occidental —salvo raras excepciones— ha sido precisamente una metafísica de la representación y, por ello, incapaz de fundar su propia posibilidad. Henry producirá a partir de estos supuestos una lectura notable de la obra de Marx (1976), el psicoanálisis (1985), y el cristianismo (2000 y 2001).




</doc>
<doc id="1948" url="https://es.wikipedia.org/wiki?curid=1948" title="MacOS">
MacOS

macOS (previamente , luego ) es una serie de sistemas operativos gráficos desarrollados y comercializados por Apple desde 2001. Es el sistema operativo principal para la familia de computadoras Mac de Apple. Dentro del mercado de computadoras de escritorio, portátiles y hogareñas, y mediante el uso de la web, es el segundo sistema operativo de escritorio más utilizado, después de Microsoft Windows.

macOS es la segunda serie importante de sistemas operativos Macintosh. El primero se llama coloquialmente el Mac OS "clásico", que se introdujo en 1984, y cuyo lanzamiento final fue Mac OS 9 en 1999. La primera versión de escritorio, Mac OS X 10.0, se lanzó en marzo de 2001, con su primera actualización, 10.1, llegando más tarde ese año. Después de esto, Apple comenzó a poner nombres de los grandes felinos en sus lanzamientos, que duró hasta OS X 10.8 Mountain Lion. Desde OS X 10.9 Mavericks, las versiones han sido nombradas en hitos en California. Apple acortó el nombre a "OS X" en 2012 y luego lo cambió a "macOS" en 2016, adoptando la nomenclatura que estaban usando para sus otros sistemas operativos, iOS, watchOS y tvOS. La última versión es mac OS Catalina, que se lanzó al público en septiembre de 2019.

Entre 1999 y 2009, Apple vendió una serie separada de sistemas operativos llamada Mac OS X Server. La versión inicial, Mac OS X Server 1.0, se lanzó en 1999 con una interfaz de usuario similar a Mac OS 8.5. Después de esto, se presentaron nuevas versiones al mismo tiempo que la versión de escritorio de Mac OS X. A partir de Mac OS X 10.7 Lion, las funciones del servidor se pusieron a disposición como un paquete separado en Mac App Store.

macOS se basa en tecnologías desarrolladas entre 1985 y 1997 en NeXT, una compañía que el cofundador de Apple Steve Jobs creó después de dejar la compañía. La "X" en Mac OS X y OS X es el número romano para el número 10 y se pronuncia como tal. La X fue una parte prominente de la identidad de marca y comercialización del sistema operativo en sus primeros años, pero gradualmente retrocedió en importancia desde el lanzamiento de Snow Leopard en 2009. Se logró la certificación para la versión Intel de Mac OS X 10.5 Leopard y todos los lanzamientos de Mac OS X 10.6 Snow Leopard hasta la versión actual también tienen la certificación UNIX 03. macOS comparte su núcleo basado en Unix, llamado Darwin, y muchos de sus frameworks con iOS, tvOS y watchOS. Una versión muy modificada de Mac OS X 10.4 Tiger se utilizó para la primera generación de Apple TV.

Las versiones de Mac OS X de 1999 a 2005 pueden ejecutarse solo en los Mac basados ​​en PowerPC de ese período de tiempo. Después de que Apple anunciara que cambiarían a CPUs de Intel a partir de 2006, se fabricó y distribuyó una versión separada de Mac OS X 10.4 Tiger exclusivamente con las primeras Mac basadas en Intel; incluía un emulador conocido como Rosetta, que permitía a los usuarios ejecutar la mayoría de las aplicaciones PowerPC en equipos Mac basados ​​en Intel Mac OS X 10.5 Leopard fue la única versión que se creó como un binario universal, lo que significa que el disco de instalación admitió procesadores Intel y PowerPC. Mac OS X 10.6 Snow Leopard fue la primera versión disponible exclusivamente para equipos Mac basados ​​en Intel. En 2011, Apple lanzó Mac OS X 10.7 Lion, que ya no soportaba procesadores Intel de 32 bits y tampoco incluía a Rosetta. Todas las versiones del sistema lanzado desde entonces se ejecutan exclusivamente en CPU Intel de 64 bits y no son compatibles con las aplicaciones PowerPC.

Mac OS X está basado en el núcleo creado por Mach. Ciertas partes de las implementaciones de UNIX por parte de FreeBSD y NetBSD fueron incorporadas en NEXTSTEP, en el que se basó Mac OS X. Mientras Jobs estaba afuera de Apple, la compañía intentó crear un sistema de «próxima generación» a través de los proyectos Taligent, Copland y Gershwin, con poco éxito.

Eventualmente, el sistema de NeXT (en ese entonces denominado OPENSTEP) fue seleccionado para ser la base del próximo sistema operativo de Apple, por lo cual la compañía de Cupertino adquirió NeXT en su totalidad. Steve Jobs regresó a Apple como CEO interino, y luego asumió el cargo de lleno, acompañando la transformación de OPENSTEP en un sistema que sería adoptado para el mercado primario de Apple, los usuarios de hogar y los profesionales multimedia. El proyecto fue conocido inicialmente como Rhapsody y luego adoptó el nombre de "Mac OS X".

Mac OS X Server 1.x era incompatible con el software diseñado para el Mac OS original y no disponía de soporte para el puerto IEEE 1394 (FireWire). Mac OS X 10.x trajo consigo mayor compatibilidad y funcionalidad al incluir la Carbon API al igual que soporte para FireWire. Con la evolución del sistema, abandonó el legado de Mac OS hacia un énfasis de estilo de vida digital en las aplicaciones, tal como ocurrió con iLife, iWork y el media center Front Row. Cada versión incluía modificaciones a la interfaz general, como la apariencia metálica agregada en la versión 10.3, la barra de títulos sin rayas en la versión 10.4 y la remoción en la versión 10.5 de la apariencia metálica en favor de un estilo de ventana unificado en gradiente.

Mac OS X es la décima versión del sistema operativo de Apple para computadoras Macintosh. Las versiones previas usaron una numeración cardinal, p.j. Mac OS 8 y Mac OS 9. La letra "X" en el nombre Mac OS X se refiere al 10 en números romanos. Por tal motivo, la pronunciación correcta es «diez» en este contexto, aunque pronunciarlo como «equis» es muy común. El centro del Mac OS X es compatible con POSIX construido sobre el núcleo XNU, con facilidades UNIX disponibles en la interfaz de línea de comandos (terminal). Apple liberó esta familia de software como un sistema operativo libre y de código abierto, bajo el nombre de Darwin, pero parcialmente se fue volviendo código cerrado. Sobre Darwin, Apple colocó varios componentes, incluyendo la interfaz de usuario Aqua y el Finder, para completar la interfaz en la que estaba basado Mac OS X.

Mac OS X introdujo un buen número de nuevas funciones para proveer una plataforma más viable y estable que su predecesora, el Mac OS 9. Por ejemplo, la multitarea preventiva y la memoria protegida mejoraron la habilidad del sistema para ejecutar múltiples aplicaciones simultáneamente sin interrupciones. Muchos aspectos de la arquitectura del Mac OS X se derivan de OpenStep, el cual fue diseñado para ser portable, con el objetivo de facilitar la transición de una plataforma a otra. Por ejemplo, Nextstep fue portado de estaciones de trabajo Next basadas en procesadores 68k a x86 y otras arquitecturas antes de que NeXT fuese adquirido por Apple, y OpenStep fue luego portado a la arquitectura PowerPC como parte del proyecto Rhapsody.

El cambio más visible fue la inclusión de la interfaz Aqua. La misma hacía uso de bordes suaves, colores translucidos y rayas -similar al diseño del hardware de los primeros iMac- trajo más textura y color a la interfaz de usuario al ser comparado con el OS 9 o el OS X Server 1.0. Hubo recepciones encontradas respecto a la nueva interfaz. Bruce Tognazzini (quien fundó el Apple Human Interface Group inicial) afirmó que la interfaz Aqua en Mac OS X v10.0 representó un paso atrás en la usabilidad comparado con la interfaz original del Mac OS. Mientras tanto, John Siracusa, uno de los editores de Ars Technica, dijo que la "introducción de Aqua y su salida del entonces convencional look fue un tremendo éxito." A pesar de la controversia por la nueva interfaz, los desarrolladores de aplicaciones comenzaron a producir pieles para aplicaciones personalizadas para Mac y otros sistemas operativos que imitaban a Aqua.

Mac OS X, es uno de los sistemas operativos que menos mecanismos de protección ha implantado. Por ejemplo Snow Leopard, aplica ASLR solo parcialmente, mientras que otros sistemas actuales, como la mayoría de las distribuciones GNU/Linux, Windows Vista o Windows 7, implementan la aleatorización de forma completa desde hace años. Además, tampoco aplica DEP de forma total (los otros sistemas sí la aplican), solo lo implementa en procesos de 64 bits.

. Algunas de ellas son la ampliación de ASLR al kernel del sistema, el uso de sandboxes en todas las aplicaciones, una nueva utilidad llamada Gatekeeper que intenta controlar qué aplicaciones se pueden instalar y ejecutar y cuales no, actualizaciones del sistema operativo fortificadas y cifradas, actualizaciones de software de terceros integrada, FileVault mejorado y ampliado, xProtect mejorado, o la herramienta Find My Mac con la que se puede encontrar o bloquear (entre otras opciones) un ordenador a través de Internet en caso de pérdida o de robo.

Tanto en la línea de comandos como en la interfaz gráfica los procesos requieren elevación para realizar modificaciones. El acceso restringido a los archivos del sistema es responsable de gran parte de la seguridad. Sin embargo, el sistema permite modificaciones cuando es requerido. El ejemplo más obvio es el software instalador, el cual requiere de una autorización administrativa para instalar software que afecta a más de un usuario. A pesar de todo, ningún sistema es invulnerable.

Mac OS X v10.5 introdujo soporte seguro para aplicaciones y procesos firmados. Las aplicaciones y procesos firmados incluyen una firma digital, la cual es usada por el sistema para verificar la autenticidad y la integridad del software y sus recursos. El código es verificado tanto en el disco como cuando se está ejecutando. De este modo, si alguna parte del código de la aplicación o el proceso es inapropiadamente cambiado cuando está activo, el sistema automáticamente lo desactiva. La autenticación de código es usado por los llaveros, la aplicación de firewall personal, las preferencias de Control Parental y la configuración del gestor de clientes para verificar las aplicaciones después de modificaciones.

Leopard también introdujo el servicio de aplicaciones en cuarentena, el cual muestra una advertencia cuando el usuario intenta abrir una aplicación descargada de una fuente externa. Esto da al usuario la oportunidad de verificar que desea abrir una nueva aplicación, o cancelar la apertura si se sospecha sobre la seguridad de la misma. Mac OS X v10.6 refuerza aún más esta característica con el mantenimiento de una lista de conocidos. Si intenta abrir cualquier software en esta lista, el sistema presentará un cuadro de diálogo de advertencia que sugiere que tal archivo debe ser suprimido.

Mac OS X distingue entre los usuarios ("user"), el administrador de sistema root ("admin") y el superusuario ("superuser"). El usuario no puede realizar cambios en el sistema y solo puede instalar software en su carpeta personal. Las aplicaciones que ejecuten estos usuarios lo harán con los permisos propios de este tipo de usuario. Los usuarios administradores tienen más permisos, aunque no pueden realizar modificaciones a la configuración general del sistema, instalar software o tener acceso a varios directorios del sistema sin autenticarse.

No existe una cuenta root que tenga permanentemente los permisos del superusario, después de realizar la instalación del sistema. Aunque hay un usuario «root» que está deshabilitado por defecto. Sin embargo, se han encontrado lagunas que permiten a un usuario administrador ejecutar software de administración y tener control total sobre el sistema.

Hasta el OS X 10.4, se utilizó el Cortafuegos orientado a paquetes ipfw para filtrar el tráfico entrante. Desde el OS X 10.5 un cortafuegos para aplicaciones establece que programas pueden recibir tráfico entrante. Se puede instalar una interfaz para ipfw mediante programas adicionales como WaterProof o Flying Buttress.

Pruebas iniciales demostraron que el cortafuegos del OS X v10.5 permitía el tráfico de datos aun cuando la opción «Bloquear todas las conexiones» estaba habilitada. En el OS X 10.5.1 estas vulnerabilidades fueron corregidas. La leyenda en la interfaz de usuario fue cambiada a «Permitir solo los servicios requeridos».

Las conexiones salientes no pueden ser monitoreadas por el cortafuegos incluido en el sistema. Para este propósito se requieren programas complementarios como «Little Snitch» o «GlowWorm».

El origen del malware en Mac OS X se remonta a 2006, cuando salió a la luz el virus Macarena. Este virus no era peligroso, pero avisaba que se podría comprometer la seguridad más seriamente en este sistema.

En 2007, la firma Intego emitió una alerta sobre un troyano llamado OSX.RSPlug.A, se trataba de un malware mucho más serio que el Macarena, que se instalaba simulando ser un codec para QuickTime y redirigía el tráfico de algunas direcciones a través de la manipulaciones en el DNS.

En 2009, Dino Dai Zovi, experto en seguridad con gran reputación internacional, hizo públicas unas herramientas (Mac OS X Advanced Rootkit Tools) que utilizó durante las conferencias de la Black Hat USA de 2009, para demostrar cómo se puede crear malware avanzado y rootkits para este sistema. En este año también, se creó la primera botnet con este tipo de equipos. Se hizo troyanizando la suite ofimática iWork, también la suite Adobe Photoshop y difundiéndola a través de redes P2P.

El día 13 de mayo de 2011 el INTECO reconoce 34 malwares de todo tipo para este sistema. Por ejemplo: Boonana (troyano), Hellraiser (RAT, de "Remote Administration Tool"), BlackHole RAT (RAT), Mac Defender (falso antivirus), IncognitoRAT (RAT) o Koobface (gusano). El malware para Mac OS X se ha profesionalizado.

En noviembre de 2014 la firma Palo Alto Networks detecto el malware denominado “WireLurker”, el cual utiliza la plataforma OS X para infectar dispositivos iOS que se conecten vía USB al equipo, infectando de esta manera las aplicaciones compradas.
WireLurker se distribuye a través de aplicaciones de terceros descargadas de tiendas chinas. Se estima que este nuevo malware este limitado a China por su forma de distribución.

Las API que Mac OS X heredó de OpenStep no eran compatibles con las versiones anteriores de Mac OS. Estas API's fueron creadas como resultados de la colaboración entre NeXT y Sun Microsystems y ahora se les denomina conjuntamente Cocoa. Esta herencia es altamente visible para los desarrolladores de Cocoa, debido a que el prefijo "NS" está en todas las partes del framework. La API oficial de OpenStep, publicada en septiembre de 1994, fue la primera API entre la fundación y el conjunto de aplicaciones, y la primera en usar el prefijo "NS". El proyecto Rhapsody habría requerido todo un nuevo desarrollo para usar estas API's, causando gran indignación entre los desarrolladores de software para Mac. Todos los programas que no recibieran una completa reescritura hacia el nuevo framework funcionarían en el equivalente entorno clásico. Para permitir una transición más limpia entre Mac OS 9 y Mac OS X, se creó el API Carbon. Las aplicaciones escritas en Carbon podrían ser ejecutadas nativamente en ambos sistemas, sin embargo esta API no fue incluida en la primera versión del Mac OS X, el Mac OS X Server 1.x.

Apple solía promover la plataforma Java como la mejor forma de desarrollar software para Mac OS X. En la práctica esto significaba grandes ventajas, ya que cualquier aplicación escrita en Java funcionaría con propiedad, y la interfaz gráfica escrita en Swing se vería muy similar a las interfaces nativas de Cocoa. Tradicionalmente, los programas Cocoa han sido escritos en Objective-C, con Java como alternativa. Sin embargo, el 11 de junio de 2005, Apple anunció que las características agregadas a Cocoa en las versiones posteriores a 10.4 no serían agregadas a la interfaz de programación en Cocoa-Java.

Debido a que Mac OS X es compatible con POSIX, la gran mayoría de paquetes escritos para BSD y GNU/Linux pueden ser recompilados para ser ejecutados en los computadores de Apple. Proyectos como Fink, MacPorts y pkgsrc proveen paquetes precompilados para tal fin. Desde la versión 10.3, Mac OS X incluye X11, la versión de Apple de la interfaz gráfica X Window System para aplicaciones UNIX, como un componente adicional durante la instalación.

Desde Mac OS X v10.4 Tiger, la implementación de Apple estuvo basada en la licencia XFree86 y la X11R6.6. Todas las versiones preinstaladas de X11 poseen un administrador de ventanas muy similar en apariencia y uso a Mac OS X y tiene una buena integración con el sistema, usando también el renderizador nativo del sistema Quartz. Las primeras versiones de Mac OS X (donde X11 no venía preinstalado) podían ejecutar aplicaciones X11 usando XDarwin. Con la introducción de la versión 10.5 Apple cambió a la variante X.org de X11.

Para las primeras versiones del Mac OS X, la plataforma estándar de hardware soportada era la línea completa de los computadores Macintosh (portátiles, desktop's y servidores) basados en procesadores PowerPC G3, G4 y G5. Las versiones que salieron más adelante discontinuaron el soporte para hardware antiguo; por ejemplo, Panther no soporta el Power Macintosh G3, y Tiger no soporta sistemas anteriores a la inclusión del puerto FireWire (aunque los puertos en sí mismos no son un requerimiento del sistema). Mac OS X v10.5 Leopard (introducido en octubre de 2007) abandonó el soporte para todos los procesadores PowerPC G3 y para los procesadores PowerPC G4 con velocidades de reloj menores a 867 MHz. Mac OS X v10.7 "Lion" solo soporta equipos con procesador Intel, abandonando todo el soporte para los procesadores PowerPC.

Herramientas como XpostFacto y diversos parches aplicados al disco de instalación han sido desarrollados por terceras partes para permitir la instalación de versiones recientes de Mac OS X en sistemas no soportados oficialmente por Apple. Esto incluye un número de sistemas Macintosh pre-G3, que solo pueden ejecutar el Mac OS X hasta la versión 10.2 Jaguar, todos los Macs basados en procesadores G3 que solo pueden ejecutar hasta el sistema Tiger y los G4 con velocidad menor a 867 MHz se les puede instalar Leopard removiendo la restricción desde el DVD de instalación o ingresando un comando en la interfaz Open Firmware para indicarle al instalador del sistema que la velocidad del reloj es igual o superior 867 MHz. A excepción de las funcionalidades que requieren un hardware específico (p.j. aceleración gráfica, grabación de DVD), el sistema operativo ofrece las misma funcionalidad que en un hardware soportado.

Las versiones PowerPC de Mac OS X anteriores a Leopard mantienen la compatibilidad con aplicaciones del Mac OS mediante un entorno de emulación denominado Classic, el cual permite a los usuarios ejecutar Mac OS 9 como un proceso en el Mac OS X, con el fin de que las aplicaciones antiguas funcionasen como si lo hicieran en el anterior sistema operativo. Classic no está soportado en Macs Intel o en el Mac OS X v10.5 Leopard, aunque los usuarios que requieran ejecutar aplicaciones Classic en Intel Macs pueden usar el emulador SheepShaver.

En abril de 2002, eWeek hizo público un rumor que afirmaba que Apple tenía una versión de Mac OS X con nombre código Marklar, la cual funcionaba en procesadores Intel x86. La idea detrás de Marklar fue mantener al sistema Mac OS X funcionando en una plataforma alternativa, debido que Apple se encontraba insatisfecha con el progreso de los procesadores PowerPC. Estos rumores desaparecieron hasta que a finales de mayo de 2005, cuando varios medios de comunicaciones, como el Wall Street Journal y CNET, reportaron que Apple presentaría Marklar en los meses venideros.

El 6 de junio de 2005, Steve Jobs confirmó estos rumores cuando anunció en su discurso en el Wordwide Developers Conference que Apple estaría trabajando en la transición de PowerPC a Intel desde hacía 2 años y que Mac OS X soportaría ambas plataformas durante la transición. Jobs también confirmó los rumores respecto a que Apple tenía versiones de Mac OS X funcionando en procesadores Intel con las mismas funciones que la versión para PowerPC. La última vez que Apple cambio la familia de procesadores fue del Motorola 68k al PowerPC. Apple incluyó un emulador de Motorola 68k en el nuevo sistema operativo, el cual hacía que todos los programas 68k funcionaran automáticamente en el nuevo hardware. Apple dio soporte al emulador de 68k durante 11 años, pero lo retiró durante su transición a las CPUs de Intel.

En las recientes versiones del sistema para equipos con procesador se incluye Rosetta, una traducción binaria que habilita al software compilado en PowerPC para ser ejecutado en computadores con procesador Intel. Sin embargo, Apple abandonó el soporte para el modo clásico en los nuevos Mac basados en Intel. Software de emulación de terceros como Mini vMac, Basilisk II y SheepShaver proveen soporte para algunas de las primeras versiones de Mac OS. Una nueva versión de Xcode permite compilar software en binario universal, el cual funcionaría en cualquiera de las dos arquitecturas.

Los programas que están disponibles solo para PowerPC pueden ejecutarse sobre Rosetta, aunque dichas aplicaciones podrían ser reescritas para que se ejecuten con propiedad en el OS X para Intel. Apple exhorta a los desarrolladores a producir binarios universales para soporte tanto para PowerPC como x86. Hay una penalidad en el rendimiento cuando los binarios de PowerPC se ejecutan en un Mac Intel a través de Rosetta. Además, algunos programas PowerPC, como las extensiones del núcleo y los complementos para el panel Preferencias del Sistema, no están soportados en Intel Macs. Algunas aplicaciones PowerPC podrían no ejecutarse del todo en el OS X para Intel. Los complementos para Safari necesitan ser compilados para la misma plataforma que Safari, de modo que cuando Safari funciona en un Mac Intel requiere que los complementos hayan sido compilados para Intel o que sean binarios universales, de modo que los complementos PowerPC no tienen soporte. Mientras que los Mac Intel pueden ejecutar programas compilados para PowerPC, x86 y binarios universales, los Mac PowerPC solo tendrán soporte para los binarios universales y para las compilaciones PowerPC.

El soporte la plataforma PowerPC se mantiene hasta el Mac OS X versión 10.5. Dicha compatibilidad inter-plataforma ya existía en linaje del Mac OS X; Openstep fue portado a muchas arquitecturas, incluyendo x86, y Darwin incluyó soporte tanto para PowerPC como para x86. Aunque Apple estableció que Mac OS X no funcionaría en computadores Intel de otros fabricantes, una versión modificada del sistema compatible con hardware x86 convencional ha sido desarrollada por la comunidad OSx86.

El 8 de junio de 2009, Apple anunció en su Worldwide Developers Conference que el Mac OS X v10.6 Snow Leopard abandonaría el soporte para los procesadores PowerPC y que solo estaría disponible para equipos Intel. Sin embargo, Rosetta está soportado todavía. En Snow Leopard, Rosetta no está instalado por defecto, pero está disponible en el DVD de instalación.

Esta fue la base del Mac OS clásico, desarrollado íntegramente por Apple, cuya primera versión vio la luz en 1985. Su desarrollo se extendería hasta la versión 9 del sistema, lanzada en 1999. A partir de la versión 10 (Mac OS X), el sistema cambió su arquitectura totalmente y pasó a basarse en Unix; sin embargo su interfaz gráfica mantiene muchos elementos de las versiones anteriores.

Con excepción del Mac OS X Server 1.0 y la beta pública original, las versiones del Mac OS X tienen nombres de grandes felinos. Antes de su liberación, Mac OS X v10.0 tenía el nombre en código «Cheetah» internamente en Apple, mientras que Mac OS X v10.1 tenía el nombre en código «Puma». Después de los grandes rumores que rodearon la versión 10.2 con nombre en código «Jaguar», la publicidad de Apple empezó a utilizar los nombres en código para promover su sistema operativo. El Mac OS X v10.3 fue comercializado como «Panther», Mac OS X v10.4 como «Tiger», Mac OS X v10.5 como «Leopard» y Mac OS X v10.6 como «Snow Leopard». Lanzaron su versión Mac OS X v10.7 llamada «Lion» el 20 de julio de 2011, siendo la primera vez que Apple, distribuye su software únicamente de manera electrónica a través de la Mac App Store, a un precio de $29.99. El día 25 de julio de 2012 Apple puso a la disposición para la descarga en la Mac App Store la versión actual del software, denominada Mac OS X v10.8 Mountain Lion, distribuido solo a través de la mencionada tienda con un precio de $19.99.

Desde Mac OS X v10.9 Mavericks, las versiones del sistema operativo tienen nombres de diferentes lugares de California.

«Panther», «Tiger» y «Leopard» son marcas registradas de Apple, aunque «Cheetah», «Puma» y «Jaguar» no lo son. Apple ha tomado también «Lynx» y «Cougar» como marcas registradas. Tiger Direct demandó a Apple por la utilización del nombre "Tiger". El 16 de mayo de 2005 una corte federal de Estados Unidos en el Distrito Sur de la Florida estableció que Apple no infringía directamente la marca registrada de Tiger Direct.

Apple liberó al público, el 13 de septiembre del 2000, una versión preliminar del Mac OS X (internamente conocida como Kodiak) para recibir observaciones y comentarios por parte de los usuarios. Su precio era de USD 29.95 e incluía una camiseta. Esta versión incluía por primera vez la interfaz Aqua. La beta pública del Mac OS X expiró y dejó de funcionar en la primavera de 2001.

El 24 de marzo de 2001, Apple liberó el Mac OS X v10.0 (de nombre en código Cheetah). La versión inicial era lenta, estaba incompleta y tenía muy pocas aplicaciones disponibles al momento de su lanzamiento, casi todas de desarrolladores independientes. Mientras que muchos críticos dijeron que el sistema operativo no estaba listo para el público, reconocieron la importancia del lanzamiento inicial como una base sobre la cual se puede progresar. La mera liberación del Mac OS X fue recibida por la comunidad Macintosh como un gran acontecimiento. Después de corregir algunos errores de software, los "kernel panics" se hicieron menos frecuentes.

Antes de que terminase el año, el 25 de septiembre de 2001, Apple lanzó esta nueva versión que incrementaba el rendimiento del sistema a la vez que incorporaba algunas nuevas características tales como la reproducción de DVD.
Dada la pésima reputación de la versión 10.0, Apple lanzó la 10.1 en forma de un CD de actualización gratuito para sus usuarios, además de los 129$ que costaba para los usuarios que seguían utilizando Mac OS 9. Esto ocasionó algunos quebraderos de cabeza a Apple cuando descubrió que los CD de actualización podían ser utilizados también para hacer instalaciones completas en sistemas con Mac OS 9 con tan solo eliminar un determinado archivo.

El 23 de agosto de 2002, Apple presentó el Mac OS X v10.2 "Jaguar", la primera versión en usar su nombre en código como parte de la marca.

Introdujo una mejora en el rendimiento, un aspecto más elegante y un numeroso grupo de mejoras (más de 150, de acuerdo con Apple), incluyendo Quartz Extreme, un repositorio general para información de contactos en la nueva Agenda, y un cliente de mensajería instantánea llamado iChat. La "Mac Feliz" (del inglés, ""Happy Mac""), que había aparecido durante la secuencia de arranque del Mac OS durante al menos 18 años, fue reemplazada por un logotipo a gran escala de Apple.

Mac OS X v10.3 "Panther" se lanzó el 24 de octubre de 2003. Además de tener un rendimiento mucho mayor, incorporó la mayor actualización en la interfaz de usuario, y tantas o más mejoras que Jaguar el año anterior. Por otra parte, en esta versión dejaron de soportarse algunos modelos antiguos G3.

Las nuevas mejoras de Panther incluyen: Finder actualizado (que incorpora una interfaz metálica y búsqueda rápida), Exposé (una nueva forma de manipular ventanas), cambio rápido de usuarios (permite tener sesiones con diferentes usuarios abiertas al mismo tiempo y pasar de una a otra rápidamente), iChat AV (que añade soporte para videoconferencia a iChat), renderización mejorada de PDF, soporte integrado de fax, interoperabilidad mejorada con Microsoft Windows, FileVault (sistema de cifrado en tiempo real) e incremento de velocidad en todo el sistema con un mayor soporte para los G5.

Mac OS X v10.4 "Tiger" se puso a la venta el 29 de abril de 2005. Contiene más de 150 nuevas mejoras, pero al igual que con el lanzamiento de Panther, algunas máquinas antiguas dejaron de ser soportadas; en particular, cualquier equipo Apple que no cuente con conexión FireWire no está ya soportado en Tiger. Como curiosidad cabe comentar que Apple dispone a partir de Tiger, de una versión "paralela" compilada para procesadores Intel, si bien, teóricamente, solo podrá instalarse bajo ciertas restricciones de hardware y en procesadores con soporte SSE3. Esta versión apareció oficialmente el día 10 de enero de 2006 con los primeros equipos "Mac Intel": El iMac Core Duo (ex iMac G5), Mac mini Core Solo y Core Duo (ex Mac mini G4) además de los nuevos portátiles denominados MacBook y MacBook Pro, ambos equipados con procesadores Intel Core Duo. También han existido versiones para G4 de este sistema operativo, incluida al menos en los últimos PowerBook G4 a la venta.

Las aplicaciones incluidas en versiones anteriores fueron mejoradas. Entre lo más destacable se tiene: Spotlight (sistema de búsqueda basado en contenidos y metadatos), Dashboard (conjunto de miniaplicaciones para realizar tareas comunes y ofrecen acceso instantáneo a la información), iChat (soporte para el códec de vídeo H.264 para la realización de videoconferencias de hasta 4 personas. Además, también permite realizar audioconferencias de hasta 10 personas), QuickTime 7 (soporte para H.264 y una interfaz completamente rediseñada), Safari (incorpora soporte para RSS, mayor velocidad y seguridad, etc.).

Se introdujeron los siguientes programas y tecnologías: Automator (sistema que permite llevar a cabo de forma eficaz y sencilla toda clase de tareas manuales y repetitivas de forma automática y sin necesidad de conocimientos de programación), Core Image y Core Video (tecnologías avanzadas de procesamiento de imágenes en tiempo real), soporte de memoria de 64 bits (para los nuevos G5, usando el sistema LP64), utilidades Unix actualizadas (como cp y rsync, que pueden preservar los metadatos en HFS Plus y resource fork) y un sistema extendido de permisos usando listas de control de acceso.

Mac OS X v10.5 "Leopard" fue lanzado el 26 de octubre de 2007. Fue llamado por Apple como "la mayor actualización del Mac OS X". Trajo consigo más de 300 nuevas funciones. Leopard soporta tanto procesadores PowerPC como Intel; el soporte para procesadores G3 fue abandonado y el procesador G4 requiere una velocidad mínima de 867 MHz, y 512 MB de RAM para permitir la instalación. El DVD de instalación funciona con todas las arquitecturas soportadas (incluyendo máquinas de 64 bits). Las nuevas funciones incluyen una nueva apariencia, un Finder actualizado, Time Machine (software para realizar copias de seguridad), Spaces, Boot Camp preinstalado, soporte completo para aplicaciones de 64 bits, nuevas funciones en Mail e iChat, y nuevas características de seguridad. Leopard es un sistema UNIX certificado para la plataforma Intel. Es además el primer sistema operativo basado en BSD en recibir la certificación UNIX 03. Leopard abandonó el soporte para el Entorno Classic y las aplicaciones del mismo. Fue la última versión del Mac OS X con soporte para la arquitectura PowerPC.

Mac OS X v10.6 "Snow Leopard" fue lanzado el 28 de agosto de 2009. En lugar de incluir grandes cambios en la apariencia y funcionalidades como ocurrió en las versiones anteriores de Mac OS X, Snow Leopard se enfocó en cambios internos, como lo son: incrementar el rendimiento, la eficiencia y la estabilidad del sistema operativo. Para la mayoría de usuarios, los cambios más notables son: la cantidad de espacio que ocupa una instalación limpia, un Finder reescrito en Cocoa, copias de seguridad más rápidas en Time Machine, a una versión más completa de la aplicación Vista Previa, al igual que mayor velocidad en el navegador de internet Safari.

Finder ahora toma las ventajas de la tecnología integrada de 64 bits al igual que de Grand Central Dispatch, permite expulsar los discos de una forma más amigable (diversas cajas de diálogos le notifican al usuario si algún servicio o programa está utilizando tal disco), y provee en general de una sensación de mejor respuesta.

La nueva versión de Safari (4.0) mejora su rendimiento en JavaScript y HTML, lo que permite una navegación más veloz. La mayoría de incremento en el rendimiento se debe a SquirrelFish (el nuevo intérprete de JavaScript para Webkit). Este intérprete incrementa la velocidad de renderizado en un 50%. El nuevo "Top Sites" ahora muestra los sitios web más visitados así como los favoritos en vista panorámica, permitiendo al usuario acceso a sus sitios favoritos a la vez que ofrece la vista Cover Flow para el historial de navegación. El navegador ahora es más resistente a los cuelgues, siendo capaz de aislar complementos que son la causa número de este tipo de problemas.

Mac OS X v10.6 también tiene soporte para Microsoft Exchange Server para Mail, iCal y Agenda, así como soporte para mayores cantidades de memoria RAM, un QuickTime X totalmente renovado con una interfaz de usuario más fresca y más funcionalidades para los usuarios de QuickTime Pro.

Los cambios internos incluyen soporte mejorado para procesadores de varios núcleos mediante Grand Central Dispatch, el cual intenta facilitar el desarrollo de aplicaciones con soporte multi-núcleo, y así mejorar la utilización de la CPU. Anteriormente los desarrolladores necesitaban reprogramar su software de forma que tomara explícitamente ventaja de los múltiples núcleos, hecho que fácilmente se volvía tedioso y problemático, especialmente en software complejo. También incluye rendimiento avanzado en la GPU con OpenCL (un estándar abierto para plataformas GPGPU distinta de CUDA, DX11 Compute Shader o STREAM) al proveer apoyo a la labor de descarga normalmente, solo destinados a una CPU a la GPU de la tarjeta gráfica. Esto puede ser especialmente útil en tareas que hacen que el computador se cuelgue fácilmente.

Snow Leopard soporta solo equipos con procesadores Intel, y requiere de 1 GB de memoria RAM para funcionar. Esta versión abandona el soporte para la arquitectura PowerPC, sin embargo permite la ejecución de programas para esta arquitectura tras instalar el traductor binario Rosetta.

El 20 de octubre de 2010, en el evento llamado "Back to the Mac" ("Vuelta al Mac"), Apple mostró un "Sneak Peek" del próximo sistema operativo Mac OS X 10.7 con nombre código "Lion". Dentro de las primeras características se encuentran Launchpad que es un gestor de aplicaciones estilo iOS; y Mission Control que se podría decir es la integración de Dashboard, Exposé, Spaces y ventanas de Aplicaciones a pantalla completa. El 24 de febrero del 2011 fue entregada una beta de Mac os 10.7 'Lion' a los desarrolladores, develando nuevas características como Airdrop, Resume, Auto Save, Versions y Mail 5. El 6 de junio del 2011 en la Keynote de la WWDC se anunció que OS X 10.7 será puesto a la venta únicamente en descarga digital por la Mac App Store en julio del 2011. A partir del 20 de julio Lion fue puesto a la venta en la Mac App Store por 23.95 euros, 29.99 dólares al cambio, y se desveló que estaría disponible para descarga desde la App Store y a partir del 20 de agosto estaría disponible para su venta en formato de pendrive.

El 16 de febrero de 2012 Apple lanzó la Developer Preview de Mac OS X 10.8 "Mountain Lion", una versión del sistema operativo en la que se incluyen muchas aplicaciones nativas de iOS, como Recordatorios, Notas o Mensajes. Incluye también un centro de notificaciones cercano al de iOS. Mac OS X Mountain Lion salió a la venta en España el 25 de julio de 2012. Con esta nueva versión, Apple pretende potenciar el uso de la nube, con el ya usado iCloud, gracias a la integración con la suite ofimática, iWork. Otra de las grandes novedades es Game Center, una plataforma de juego que pretende ser la primera en aunar los progresos y logros de las consolas portátiles con los sistemas de escritorio. También cuenta con Gatekeeper es una característica que evita la instalación de aplicaciones no confiables y así evitar malware.

El 22 de octubre de 2013 Apple lanzó la actualización Mac OS X 10.9 "Mavericks", una nueva versión que integra las aplicaciones de iOS como Recordatorios, Notas, Mensajes, iBook y notificaciones instantáneas pero con mucha más personalización. La nueva versión se puede actualizar sin ningún costo desde el mismo día de su presentación. Entre otras novedades anunciadas de OS X Mavericks está la opción de usar una HDTV como segundo monitor por medio de Apple TV y el aumento de la duración de la batería para los usuarios de MacBook Air de 11" y 13", con mayor ahorro de energía para iMac.

El 2 de junio de 2014 Apple presentó en la "WWDC 2014" Mac OS X 10.10 "Yosemite", una nueva versión del sistema operativo que presenta un rediseño en su interfaz y mejoras en el Finder, Safari, Mail, Centro de Notificaciones, etc. La versión Beta se encontrará disponible únicamente para el primer millón de usuarios que se suscriban en el programa Beta de Apple.

Durante la Keynote del 16 de octubre de 2014, Apple anuncio el lanzamiento oficial de Mac OS X v10.10 (Yosemite).

El 8 de junio de 2015, Apple presentó en la Conferencia Mundial de Desarrolladores (WWDC 2015), OS X "El Capitán". Esta nueva versión del sistema operativo mantiene la interfaz de su predecesor OS X Yosemite, centrándose en mejorar la experiencia del usuario y el rendimiento del sistema operativo, con la introducción de "Metal for Mac", característica del sistema que ya existía para iOS y que hace que la GPU trabaje a un ritmo más veloz. Es por ello que las aplicaciones se ejecuten más rápido con OS X El Capitán en comparación con versiones anteriores. Entre las novedades más destacadas se encuentran: Split View, es decir, la posibilidad de dividir la pantalla para poder usar dos aplicaciones al mismo tiempo; mejoras en Spotlight, que además de permitir mover la ventana ahora también trabaja con un lenguaje más natural y puede mostrar más datos que antes (Previsión del tiempo, la bolsa, vídeos en línea, etc); y otros cambios en diversas aplicaciones como Safari, Notas, Fotos o Mapas, entre otras.

Fue lanzado oficialmente el 30 de septiembre de 2015, pudiéndose descargar de forma gratuita través del Mac App Store.

Durante la WWDC 2016, el 13 de junio de 2016, Apple anunció el lanzamiento de macOS "Sierra". La nueva versión vino acompañada de un cambio de nombre del sistema operativo, que hasta entonces se había llamado OS X y que pasó a denominarse macOS. Entre las nuevas características de esta versión destacan el potenciamiento de "Continuity", gracias al cual ahora se puede desbloquear el Mac con el Apple Watch y se añade un portapapeles universal para todos los dispositivos de Apple, la posibilidad de liberar espacio en el disco a través de iCloud, la inclusión de Apple Pay en Mac para poder hacer pagos a través de la web, el salto de Picture in Picture de los iPads a los ordenadores y la llegada del asistente virtual Siri a la última plataforma de Apple en la que todavía no estaba presente, con el que, además de poder hacer lo mismo que en iOS, permite realizar búsquedas en el Finder e interactuar con los resultados fijándolos en forma de Widget en el centro de notificaciones y guardar los archivos que encuentre en la web directamente arrastrándolos.

macOS Sierra está disponible para su descarga gratuita desde el 20 de septiembre de 2016 a través de Mac App Store.

Presentada el 5 de junio de 2017 durante la WWDC, esta nueva versión se va a centrar en mejorar el rendimiento del sistema. Este OS presenta la nueva versión de API diseñada por Apple, llamada Metal 2, para posteriormente ir reemplazando OpenCL y OpenGL. Para agregar, en esta actualización los discos de estado sólido (SSD) tienen la opción de elegir el nuevo formato de escritura, APFS, ofreciendo velocidades de lectura y escritura más optimizadas.

Esta versión ya está disponible para su descarga e instalación desde la Mac AppStore desde el día 25 de septiembre de 2017

El 4 de junio de 2018 se anunció en la WWDC el nuevo macOS que reemplazaría a macOS High Sierra. Se pensaba que sería el OS que integraría la función de doble compatibilidad entre aplicaciones de macOS-iOS para facilitar a los desarrolladores, pero Apple decidió postergarlo para su OS de 2019. Este sistema operativo presenta como características el nuevo modo oscuro, un nuevo rediseño del mac App Store, nuevos fondos de pantallas, fondos de pantallas dinámicos, nuevas aplicaciones (como Casa, Notas de Voz y Bolsa), entre otros cambios importantes. Además, será el último sistema operativo capaz de soportar aplicaciones a 32-bits, pues Apple confirmó la eliminación de su soporte en la futura actualización. A medida que vaya pasando el tiempo, se irán eliminado extensiones que funcionen a 32 bits, como es el caso del framework de QuickTime o el de Java 1.6. 

Es la decimosexta versión principal de macOS, el sistema operativo de escritorio de Apple para computadoras Macintosh. Es el sucesor de macOS Mojave, se anunció en la WWDC 2019 el 3 de junio de 2019 y se lanzó al público el 7 de octubre de 2019. Catalina es la primera versión de macOS que admite exclusivamente aplicaciones de 64 bits.

Esta versión está disponible para su descarga e instalación desde la Mac AppStore desde el 7 de octubre de 2019.

Es la decimoséptima versión principal de macOS, el sistema operativo de escritorio de Apple para computadoras Macintosh. Es el sucesor de macOS Catalina, se anunció en la WWDC 2020 el 22 de junio de 2020.

Esta versión estará disponible para su descarga e instalación desde la Mac AppStore próximamente.

En los años 2001-2002, cuando daba lugar la transición Mac OS-Mac OS X, el sistema recibió críticas por parte de Microsoft y Corel respecto a la ausencia de estadísticas de adopción del nuevo sistema operativo por parte de los usuarios. En el 2001 también, Linus Torvalds importante figura del software libre y creador del núcleo Linux afirmó que el microkernel Mach en el que está basado el Mac OS X estaba repleto de errores de diseño.

Un gran número de vulnerabilidades críticas han sido descubiertas en Safari. El 22 de febrero de 2006 se descubrió una vulnerabilidad que permitía a un atacante la ejecución de scripts. En marzo de 2010 se descubrieron 8 vulnerabilidades, las cuales pueden ser explotadas por un atacante para ejecutar código de manera remota. En todo el año 2010, se han reportado 308 vulnerabilidades para Mac OS X.

Respecto a Mac OS X v10.6 "Snow Leopard", el reconocido hacker Charlie Miller ha criticado que no se incluya ninguna modificación relacionada con la forma en que el sistema asigna la memoria disponible de forma aleatoria, una debilidad que ya era conocida en versiones anteriores de Mac OS y que en la última versión del sistema sigue igual.

Symantec, fabricante de software de seguridad para Microsoft Windows, Mac OS X y GNU/Linux afirma que la característica de archivos en cuarentena solo ofrece protección básica contra malware. "No es una solución antivirus completa y no tiene la habilidad de eliminar malware del sistema" dijo textualmente la compañía. "Las firmas de malware son tan buenas como las definiciones, que requiere de Apple para proporcionar actualizaciones regulares y oportunas". Symantec también menciona que el software de actualización del Mac OS X no es totalmente automático y carece de una interfaz de usuario que permita ver qué firmas han sido descargadas. Asimismo afirma que las mejoras en la seguridad de Apple no protegen al usuario de acceso no autorizado a los archivos importantes ni bloquean la transferencia de información delicada. Igualmente afirma que el cortafuegos predeterminado del Mac OS X está desactivado por defecto.

El catálogo de programas disponible para Mac OS X es menor si se le compara con Microsoft Windows. Aplicaciones importantes como Microsoft Office, y Photoshop tienen versión nativa para Mac OS X. Autodesk lanzó una versión para Mac OS X de su programa más conocido, AutoCAD.

Durante los cambios de sistema operativo y de tipo de procesador, Apple ha tenido traspiés en la compatibilidad del software. Cuando se saltó del Mac OS al Mac OS X, el nuevo sistema pasó a ejecutar las aplicaciones mediante una capa de compatibilidad. Esto hizo que el software se ejecutará de forma lenta, ya que utilizar un software "classic" implica la carga del Mac OS 9 dentro del Mac OS X y que los dos funcionaran paralelamente.

En la transición PowerPC-Intel, los programas escritos para la plataforma anterior pasaron a ejecutarse nuevamente en una capa de compatibilidad, aunque en este caso se trató de un software y no de un sistema operativo completo. El programa encargado de hacer funcionar aplicaciones escritas para PowerPC se denomina Rosetta, el cual era totalmente transparente. Su única desventaja era que no podía ejecutar programas de envergadura, tales como Photoshop.

The Open Group criticó a Apple por utilizar el término "Unix" en la publicidad de Mac OS X pese a que este sistema no disponía de la certificación oficial del sistema operativo y su uso podía suponer una violación de marca registrada. Posteriormente y como respuesta a estas críticas, Mac OS X se certificó para la versión 10.5 (Leopard) cuando comenzó a funcionar sobre procesadores Intel.

Según la prensa especializada, Apple se centró en los dispositivos móviles que fabrica (como los iPod, el iPhone y el iPad) más que en la línea tradicional de computadoras de escritorio y portátiles, aunque continúa lanzando estos productos con una periodicidad más o menos constante.

También es criticado el sistema de actualizaciones de Apple, porque sus publicaciones no son previsibles en el tiempo. Esto para el usuario doméstico no tiene importancia, pero para la administración de redes medianas o grandes de ordenadores puede llegar a ser perjudicial. Fueron especialmente criticadas varias actualizaciones al dejar sin arrancar, después de que actualizaran a la versión 10.6.5, a todos los equipos que tuviesen activado el cifrado completo de disco de la utilidad de seguridad PGP de Symantec. Para solucionar esto, Apple volvió a sacar la actualización "parcheada". Sin embargo, al sacar la siguiente actualización a la versión 10.6.6 volvió a pasar lo mismo, los usuarios de ese sistema de cifrado volvieron a quedarse sin poder arrancar y las críticas se multiplicaron.

Tras sufrir una avalancha de llamadas a AppleCare por culpa del falso antivirus llamado 'Mac Defender', Apple decidió dar órdenes al personal del servicio para no atender a los usuarios que llamasen por ese motivo.

Mavericks sufrió el rechazo de parte de la comunidad de profesionales de video, debido a la deshabilitación del uso de códecs de video desarrollados por terceras partes en QuickTime y Vista previa, como por ejemplo DivX o DXV de Resolume.

OS X es un sistema BSD, motivo por el cual guarda especial relación con GNU/Linux. Esta relación se basa en el cumplimiento de estándares, aunque el código de ambos es completamente distinto. GNU/Linux es un sistema tipo-UNIX, mientras que OS X es un sistema UNIX certificado. La relación OS X - GNU/Linux es tan estrecha, que es posible portar fácilmente un programa de GNU/Linux a OS X y ejecutarlo en el subsistema X11. Un ejemplo claro de esto es OpenOffice.org, el cual durante sus versiones iniciales para OS X funcionó en X11 hasta que pasó a ser una aplicación nativa. Por su parte, Windows no guarda relación alguna con Mac OS X o GNU/Linux. En noviembre de 2009, un ejecutivo de Microsoft admitió que Windows 7 había sido inspirado en OS X.

De acuerdo con Apple, los usuarios de Mac OS X eran casi 10 millones a principios de 2004, habiendo un incremento en la cuota de mercado del 2,06% al 2,88% con respecto al 2003. En octubre de 2006, las firmas IDC y Gartner informaron que la cuota de mercado de Apple en los Estados Unidos se había incrementado en un 6%. Las cifras de diciembre de 2006, muestran una cuota de mercado de alrededor de un 6% (IDC) y un 6,1% (Gartner). Estas se basan en un incremento de más del 30 por ciento en la venta de unidades desde 2005 a 2006. A marzo de 2010, Mac OS X ostenta una participación en el mercado global del 5.02%, mientras que en Microsoft Windows y GNU/Linux es del 92.12% y 0.98% respectivamente. El 24 de noviembre de 2009 ComputerWorld informó que Windows 7 había superado a Mac OS X en número de usuarios.

Existen tres formas de tomar muestras en el mercado de los sistemas operativos: 1. accesos del navegador 2. las ventas 3. equipos en operación. Si se mide mediante el navegador, el mercado de los Mac se ha incrementado sustancialmente desde 2007. Sin embargo, los resultados de la cuota de mercado medido como porcentaje de las ventas actuales proporciona resultados diferentes a los que se obtienen midiendo los equipos en funcionamiento. La cantidad de computadores Mac en uso es difícil de determinar, con números que van entre el 5% (2009) y el 16% (2005). La cuota del Mac OS X en el mercado de los sistemas operativos se incrementó de un 7.32% en diciembre de 2007 a un 9.63% en diciembre de 2008, lo que implica un incremento en la cuota de mercado del 32% durante el 2008, comparado con un incremento del 22% en 2007.

Expertos de la industria a menudo han llamado la atención sobre la cuota de mercado relativamente pequeña de Mac para predecir la muerte inminente de Apple, en particular en la década de 1990, cuando el futuro de la empresa parecía más sombrío. Otros argumentan que la cuota de mercado es una forma equivocada para medir el éxito del Mac. Apple ha posicionado el Mac como un computador personal de alto rendimiento, de modo que sería erróneo compararlo con un PC de bajo coste. Debido a que el mercado global para los computadores personales ha crecido rápidamente, los incrementos en las ventas de los Mac se ven opacados al compararse con sus competidores. Entonces, la pequeña cuota de mercado de Apple da una falsa impresión en cuanto a que hay menos personas usando Macs que anteriormente. Otros tratan de hacer hincapié en la cuota de mercado, alegando que rara vez se ve tal contexto en otras industrias. Independientemente de la cuota de mercado del Mac, Apple se ha mantenido rentable desde el retorno de Steve Jobs y la posterior reorganización de la empresa. Notablemente, un reporte publicado en el primer cuarto del 2008 encontró que Apple tenía un 14% de share en el mercado de los computadores personales en Estados Unidos, incluyendo el 66% de los equipos cuyo valor supera los 1.000 dólares. Las investigaciones de mercado indican que la mayor parte de su base de clientes proviene de personas con altos ingresos.

Mac OS X, Microsoft Windows y GNU/Linux incluyen de fábrica utilidades de seguridad muy similares, como cortafuegos y antispyware. Si bien ningún sistema operativo está exento de ser atacado o infectado por un virus, Mac OS X está basado en UNIX y la cantidad de virus que lo afectan en comparación con Microsoft Windows, es reducida. En mayo de 2011, INTECO reconoce 1362 virus para plataformas Windows de 32 bits, frente a 34 para Mac OS y menos de 10 para GNU/Linux.

Cerca del 99,2% del malware tiene por objetivo Microsoft Windows. Pese a la reducida cantidad de malware destinada para el sistema de Apple, el Mac OS X fue denominado por IBM como el sistema operativo más inseguro. En ese mismo estudio, IBM califica su sistema AIX, como el más seguro. Es importante recalcar, que tanto Mac OS X como AIX son sistemas UNIX.

Tanto Mac OS X como Microsoft Windows incluyen utilidades integradas para el cifrado de archivos. La de Mac OS X se denomina FileVault, mientras que la de Microsoft Windows es BitLocker. GNU/Linux en la gran mayoría de distribuciones no incluye un software de cifrado, aunque están disponibles un buen número de aplicaciones libres para tal fin, como TrueCrypt o GnuPG.




</doc>
<doc id="1950" url="https://es.wikipedia.org/wiki?curid=1950" title="MS-DOS">
MS-DOS

MS-DOS (siglas de "MicroSoft Disk Operating System", Sistema operativo de disco de Microsoft) fue el miembro más popularmente conocido de la familia de sistemas operativos DOS de Microsoft, y el principal sistema para computadoras personales compatible con IBM PC en la década de 1980 y mediados de años 1990, hasta que fue sustituida gradualmente por sistemas operativos que ofrecían una interfaz gráfica de usuario, en particular por varias generaciones de Microsoft Windows.

MS-DOS nació en 1980 al encargársele a Microsoft producir un sistema operativo para la gama de computadores personales IBM PC de IBM. En este momento, Microsoft compró los derechos de QDOS, también conocido como 86-DOS, de Seattle Computer Products que fue elaborado por Tim Paterson, y comenzó a trabajar en las modificaciones para poder cumplir con los requerimientos de IBM.

MS-DOS se desarrolló a partir de QDOS, "Quick Disk Operating System", también conocido como 86-DOS. Su desarrollo se inició oficialmente en 1981 y fue lanzado en 1982 como MS-DOS 1.0. Tuvo nueve versiones principales y alcanzó gran difusión, pero fue gradualmente reemplazado por S.O que ofrecían una interfaz gráfica de usuario (GUI), en particular, por varias generaciones del sistema operativo Microsoft Windows. [MS-2]



El código fuente del MS-DOS 1.1 (1982) y 2.0 (1983), junto con el de Word para Windows 1.1a (1989) fue publicado por Microsoft el 25 de marzo de 2014.

En la versión 2.0, lanzada en 1983, se le introdujeron características propias de Unix, como el uso de subdirectorios, tuberías, redirección de entrada y salida de órdenes, así como soporte para discos duros y unidades de disquete de 360 KiB de capacidad.

Aquí se muestran algunas de las órdenes que utilizaba MS-DOS, y que actualmente pueden ser utilizados desde la línea de comandos en sistemas operativos Windows. Para acceder a la ayuda de estas, MS-DOS, a partir de la versión 6.2 permite lo siguiente: comando_a_consultar /? (Ej.: copy /?).
Pueden ser internos (incluidos dentro del propio COMMAND.COM) o externos (archivos ejecutables en el directorio del MSDOS):

Los comandos internos o residentes son aquellos que se transfieren a la memoria en el momento de cargarse el Sistema Operativo y se pueden ejecutar sin necesidad de tener el DOS presente en la unidad por defecto desde el cual se puede ejecutar el mandato. La unidad por defecto es la unidad en la que se está, por ejemplo A:\>_ ; y la unidad especificada es aquella a la cual nos dirigimos o especificamos estando en otra unidad, por ejemplo A:\>B: , la unidad especificada es B.


Los comandos externos en contraposición con los comandos internos se almacenan en archivos de comandos denominados transitorios o externos, y para ejecutarse necesitan de estos archivos, además los comandos externos tienen nombre propio y se pueden copiar de un disco a otro.

Aquí se muestran algunos de los comandos que utilizaba MS-DOS, y que actualmente pueden ser utilizados desde la línea de comandos en sistemas operativos Windows. Para acceder a la ayuda de estas, MS-DOS, a partir de la versión 6.2 permite lo siguiente: comando_a_consultar /? (Ej.: copy /?). Pueden ser internos (incluidos dentro del propio COMMAND.COM) o externos (archivos ejecutables en el directorio del MSDOS):
Los atributos de los directorios, y los ficheros son: de lectura (r), de escritura (w), de archivo (a), oculto (h), de sistema (s).
Parámetros: signos (más o menos) y letras "r", "w", "a", y "h" "v".
Ejemplo:
Attrib +r *.* (atributo de solo lectura, para todos los ficheros de ese directorio)

Se pueden utilizar estos parámetros combinados.





</doc>
<doc id="1951" url="https://es.wikipedia.org/wiki?curid=1951" title="Multitarea">
Multitarea

La multitarea es la característica de los sistemas operativos modernos que permite que varios procesos o aplicaciones se ejecuten aparentemente al mismo tiempo, compartiendo uno o más procesadores.

Los sistemas operativos multitarea son capaces de dar servicio a más de un proceso a la vez para permitir la ejecución de muchos más programas.

En esta categoría también se encuentran todos los sistemas que cumplen simultáneamente las necesidades de dos o más usuarios —llamados sistemas multiusuario— que compartan los mismos recursos. Este tipo de sistemas se emplea especialmente en redes. En resumen, se trata de fraccionamiento del tiempo.

En la multitarea cooperativa el sistema operativo da el control a un proceso y es este el que cede de nuevo el control cuando decide voluntariamente que no puede seguir su ejecución, pasando a estar en espera. Al depender del propio proceso en ejecución puede ser problemática, puesto que si el proceso de usuario se interrumpe y no cede la CPU al sistema operativo, todo el sistema quedará bloqueado, es decir, sin poder hacer nada. Da lugar también a latencias muy irregulares y la imposibilidad de tener en cuenta este esquema en sistemas operativos de tiempo real. Las versiones de Microsoft Windows desde la 3 hasta el 95 (todas ejecutadas bajo MS.DOS) son un ejemplo de este tipo de Sistema Operativo con Multitarea cooperativa. También fue usado por Apple en el Mac OS Classic.

En la multitarea apropiativa o multitarea preventiva, el sistema operativo es el encargado de administrar el/los procesador(es) repartiendo el tiempo de uso entre los procesos que estén esperando para utilizarlo. Cada proceso utiliza el procesador durante lapsos cortos, pero el resultado final es virtualmente igual a ejecutarse todo al mismo tiempo. Ejemplos de sistemas de este tipo serían Unix y sus derivados (FreeBSD, Linux), VMS y derivados, AmigaOS, Windows NT, el IBM360 o los DEC PDP. El sistema operativo del Sinclair QL usaba este tipo de multitarea.

Solo se da en sistemas con multiprocesador; varios procesos se ejecutan realmente al mismo tiempo en distintos microprocesadores; suele ser también preferente. Ejemplos de sistemas operativos con esa capacidad: variantes de Unix, Windows NT, Mac OS X.



</doc>
<doc id="1952" url="https://es.wikipedia.org/wiki?curid=1952" title="Mozilla Application Suite">
Mozilla Application Suite

Mozilla Application Suite es un navegador web y una plataforma de desarrollo libre y de código abierto.

Por decisión de la Fundación Mozilla, esta suite de Internet ha dejado de ser desarrollada, siendo actualmente SeaMonkey su sucesor.

Mozilla era originalmente el nombre en clave del Netscape Navigator. Tras la estrategia de Microsoft de incrustar su navegador Internet Explorer a su sistema operativo Microsoft Windows para dominar el mercado y ganar la “guerra de navegadores”, Netscape Communications tuvo la idea de contraatacar a Microsoft liberando el código fuente de su navegador Netscape 4.7, y así convertirlo en un proyecto de software libre. Se creó una comunidad de desarrolladores para el diseño de un nuevo navegador mejorado y centrado en el seguimiento de los estándares web de la W3C. Nacía así el proyecto Mozilla, retomando el nombre clave de "Navigator". Finalmente, Mozilla fue reescrito casi desde cero tras decidirse que se desarrollaría y usaría como base un nuevo conjunto de "widgets" multiplataforma basado en XML llamado XUL, lo que hizo que tardara bastante más en aparecer de lo previsto inicialmente, lanzándose una versión 1.0 de gran calidad, traducido a un gran número de idiomas y multiplataforma, el 5 de junio de 2002.

Originalmente, Mozilla era desarrollado principalmente por Netscape Communications Corporation, conocida más popularmente como Netscape, con aportaciones de numerosos voluntarios individuales y corporativos. Netscape utilizaba el código del proyecto para su generación de Navigator 5 y 6.

Tras el abandono de Netscape Communications, el proyecto Mozilla cuenta con el apoyo organizativo, legal y financiero de la Fundación Mozilla, organización sin ánimo de lucro situada en el estado de California, Estados Unidos. La fundación, fue lanzada el 15 de julio de 2003, para permitir la continuidad del proyecto Mozilla más allá de la participación de voluntarios individuales.

El 10 de marzo de 2005, la Fundación Mozilla anunció que no se publicarían más versiones oficiales de esta suite. SeaMonkey es ahora el sucesor de Mozilla y es desarrollado por un grupo de voluntarios que conforman "The SeaMonkey Project".

Como dato curioso, los desarrolladores del proyecto Mozilla han ocultado en las sucesivas versiones del navegador pasajes metafóricos del ficticio "El Libro de Mozilla". Estos versículos recogen, a modo de revelaciones bíblicas, fechas e hitos significativos en la historia del navegador.

Lejos de ser sólo un navegador, es una plataforma de desarrollo multiplataforma sobre la que se pueden construir otras aplicaciones.
Mozilla incluye de por sí, cliente de correo electrónico, editor de páginas webs, cliente LDAP y cliente IRC, además del navegador. También, es ampliable mediante módulos XPI, lo que permite darle nuevas funcionalidades antes impensables; por ejemplo ya hay un módulo de calendario.

Algunas características interesantes del navegador y el lector de correo-e son:

El futuro del proyecto Mozilla se encuentra en los componentes separados: Mozilla Firefox (navegador web), Mozilla Thunderbird (cliente de correo electrónico y lector de noticias), Mozilla Sunbird (calendario), Mozilla Nvu (editor web). Se planteó dejar de desarrollar la suite de aplicaciones de Mozilla, por lo que algunos usuarios, descontentos con esta decisión, hicieron replantearse a Mozilla retomar el proyecto. Así, además de las aplicaciones por separado, se desarrolla Mozilla SeaMonkey, que es la continuación de "Application Suite".




</doc>
<doc id="1953" url="https://es.wikipedia.org/wiki?curid=1953" title="Mollusca">
Mollusca

Los moluscos (Mollusca, del latín "mollis" "blando") forman uno de los grandes filos del reino animal. Son invertebrados protóstomos celomados, triblásticos de simetría bilateral (aunque algunos pueden tener una asimetría secundaria) no segmentados, de cuerpo blando, desnudo o protegido por una concha. Los moluscos son los invertebrados más numerosos después de los artrópodos, e incluyen formas tan conocidas como las almejas, machas, navajuelas, ostras, calamares, pulpos, babosas y la gran diversidad de caracoles, tanto marinos como terrestres. 

Se calcula que pueden existir cerca de 100000 especies vivientes y 35000 especies extintas. Los moluscos tienen una larga historia geológica, esta abarca desde el Cámbrico Inferior hasta la actualidad. Aunque son originalmente de un ambiente marino, conllevan un gran éxito evolutivo. Están presentes en la mayoría de los hábitats: dulces, marinos, terrestres, desde las grandes alturas a más de 3000m sobre el nivel del mar hasta profundidades oceánicas de más de 5000m de profundidad y por último, en aguas polares o tropicales. Estos animales suelen ser organismos comunes del litoral de todo el mundo.

Son animales de cuerpo blando, este se encuentra dividido en una región cefálica o cabeza, una masa visceral y un pie muscular. Han desarrollado tres características únicas en el reino animal por las cuales se identifican:

El interés del ser humano en los moluscos es enorme: por un lado, los moluscos son una importante fuente de alimentación para la especie humana; por otro, numerosas enfermedades parasitarias humanas y animales son transmitidas por moluscos, ya que pueden actuar como hospedador intermediario, por ejemplo de gusanos trematodos.

La malacología es la rama de la Zoología que estudia los moluscos. Durante los siglos XVIII y XIX se elaboraron importantes colecciones malacológicas y conquiliológicas desde prestigiosas instituciones como museos, academias de ciencias y colecciones privadas. Hoy en día, sigue siendo unos de los principales pasatiempos coleccionar conchas de moluscos, debido a esta afición, los moluscos son unos de los grupos zoológicos mejor estudiados después de los vertebrados, aunque también un peligro para la supervivencia de algunas especies muy cotizadas.

La variedad de formas, tamaños, tipos de vida y ciclos vitales es extraordinaria; sin embargo, la organización de todos los moluscos sigue un plan fundamental.

Los moluscos son triblásticos, bilaterales y celomados. El celoma en los adultos queda reducido a vestigios alrededor de los nefridios, gónadas, corazón e intestino. El cuerpo se encuentra cubierto por el manto. Este último está formado por una epidermis ciliada con glándulas mucosas y una cutícula cuya función se limita a la formación de la concha calcárea mediante secreciones glandulares. Aquellos moluscos que no tengan concha, en su lugar aparecerán espículas o placas calcáreas. Por debajo del manto encontramos la cavidad paleal donde se encuentran los ctenidios, osfradios, nefridioporos y el ano. Han desarrollado un sistema circulatorio abierto (en su mayoría hemocele) formado por un ventrículo y dos aurículas. Un aparato digestivo completo provisto de la rádula o lengua raspadora localizada en la región bucal.

El patrón básico de un molusco consiste en un organismo de cuerpo blando; oval, con simetría bilateral y una concha convexa en forma de sombrero chino (ausente o interna en algunos grupos). En vez de concha, también pueden poseer espículas que pueden aparecer en estado embrionario (en adultos pueden fusionarse para dar una concha) o placas, aunque todas con el mismo origen. La concha se forma gracias a la epidermis subyacente, denominada manto (en posición dorsal), que tiene células secretoras de carbonato cálcico que cristaliza en el exterior en forma de aragonito o de calcita; el manto también secreta una substancia quitinosa de composición compleja, la conquiolina, que se deposita sobre el sustrato calcáreo formando un estrato orgánico denominado perióstraco, esencial para evitar la disolución de la concha en ambientes ácidos. 

En la parte posterior, el manto forma una cámara denominada cavidad paleal. En esta cavidad se alojan: las branquias, que tienen una estructura muy característica en forma de peine (ctenidios); los osfradios, (órganos quimiorreceptores encargados de detectar la calidad del agua) donde desembocan los nefridios (a través de los nefridioporos); las gónadas, (a través de los gonoporos) y por último, el ano. En los gasterópodos terrestres, la superficie interna de la cavidad paleal está muy irrigada, el intercambio gaseoso se produce a través del epitelio actuando como un pulmón.

La epidermis de los moluscos está recubierta de células epiteriales y células glandulares. Podemos encontrar dos tipos de células glándulares: mucosas, sobre todo en la parte ventral y glándulas de la concha, situadas en el manto

Este órgano locomotor es una apomorfía de los moluscos. El pie muestra una enorme plasticidad evolutiva ya que está dotado de una musculatura compleja y potente. Se cree que, primitivamente, era reptante (parecido al de los gasterópodos actuales), pero ha experimentado una gran diversificación originando: el pie excavador de los bivalvos, el pie escindido en tentáculos de los cefalópodos o el pie nadador de algunos gasterópodos pelágicos, entre otros.

La locomoción de la mayoría de gastrópodos terrestres se realiza a través de contracciones musculares del pie. En el caso de las especies dulceacuícolas, la locomoción es producto del movimiento de una serie de cilios o minúsculos pelos ubicados en el pie.

Tienen tubo digestivo completo. La cavidad bucal revestida de quitina, presenta un órgano de alimentación único: la rádula, que consiste en una base cartilaginosa alargada (odontóforo) recubierta de hileras longitudinales de dentículos quitinosos curvos; la forma y la disposición de los dentículos se relaciona con el tipo de alimentación. La rádula está provista de potentes músculos que le permiten proyectarse fuera de la boca, actuando como raspador. El moco secretado por las glándulas salivales de la boca lubrican la rádula y aglutinan las partículas para ser ingeridas.

A continuación hay un esófago y un estómago, más o menos complejo, en el que desembocan las glándulas digestivas (hígado o hepatopáncreas); la circulación de la masa mucosa que contiene el alimento (próstilo) se ve favorecida por la presencia de numerosos cilios. Las partículas alimenticias entran en los conductos de las glándulas digestivas. El intestino es largo y enrollado, el ano, se encuentra en posición medio-dorsal en la parte posterior de la cavidad paleal.

Sus formas de alimentación son muy variadas. Pueden ser fitófagos, como las lapas o los caracoles terrestres; carnívoros, como los conos, filtradores, como las almejas; detritívoros, babosas y caracoles, etc.

El sistema circulatorio es abierto, a excepción de los cefalópodos (estos necesitan un sistema cerrado debido a que son muy activos y necesitan una mayor presión). El corazón está tabicado y se divide, principalmente, en tres cámaras (dos aurículas y un ventrículo), aunque el número de estas es muy variable. El corazón está recubierto por una fina tela que forma la cavidad pericárdica. La hemolinfa transporta pigmentos respiratorios del ventrículo a los espacios tisulares mediante los vasos. En los espacios tisulares va ser recogida por otros vasos que van hacia las branquias, donde la sangre se oxigena para volver al corazón a través de la aurícula.

Los órganos excretores están compuestos por un par de metanefridios (riñones) comunicados con la cavidad pericárdica, en los que uno de los extremos, está comunicado con el celoma a través de unos conductos denominados celomoductos (puede desarrollarse en este extremo a modo de embudo). El otro extremo desemboca al exterior en la cavidad paleal mediante los nefridioporos.

Es muy variable. El modelo básico del sistema nervioso de los moluscos comprende un anillo periesofágico del cual salen dos pares de cordones nerviosos hacia la parte posterior, uno hacia el pie y otro hacia la masa visceral. Los órganos de los sentidos comprenden ojos, (muy complejos en los cefalópodos); estatocistos situados en el pie (sentido del equilibrio) y quimiorreceptores, como los osfradios (situados en las branquias); papilas y fosetas olfatorias en la cabeza y el órgano subradular (asociado a la rádula). El máximo grado de cefalización se da en los cefalópodos, en los que se puede hablar de un auténtico cerebro, protegido por un cráneo cartilaginoso.

Las gónadas, en muchas especies de moluscos, proceden directamente del peritoneo que recubre el celoma. La reproducción de los moluscos es exclusivamente sexual; pueden ser unisexuados (también denominado dioicos, como en los bivalvos) o como en el caso de la mayoría de los gasterópodos, hermafroditas (simultáneos o consecutivos) con capacidad de autofecundación o sin ella. La fertilización puede ser externa o interna, con frecuencia mediante espermatóforos (sacos llenos de espermatozoides).

La embriogenia típica de los moluscos comienza con una segmentación espiral del huevo fuertemente determinada. La gastrulación tiene lugar por epibolia, invaginación o ambas. La gástrula resultante se desarrolla en una larva trocófora planctónica. El proceso es virtualmente idéntico al de los anélidos. Esta larva trocófora puede desarrollar ampliamente alguna de las bandas ciliadas para dar una estructura delgada en forma de velo. En la mayoría de los moluscos, esta larva da lugar a la larva velígera, más desarrollada, en la que se puede observar ya el pie, la concha y otras estructuras. Finalmente, la larva velígera desciende al fondo y sufre una metamorfosis para adoptar el hábitat bentónico típico del adulto. Los cefalópodos y los gasterópodos terrestres y de agua dulce tienen siempre desarrollo directo.

La mayoría de los moluscos presentan una segmentación holoblástica espiral. Esta segmentación se da en un ángulo oblicuo con respecto al eje animal-vegetativo del zigoto generando una disposición en espiral de las células blastómeras hijas, las cuales, quedan empaquetadas de tal forma, que termodinámicamente son más estables que en otros tipos de segmentación, como por ejemplo la radial. La blástula de los animales que sufren este tipo de segmentación en espiral no tiene blastocele y se conoce como estereoblástula (Gilbert 2006).
Los embriones de los moluscos sufren pocas segmentaciones antes de empezar la gastrulación. Inicialmente se dan dos clivajes (desde el polo animal hacia el polo vegetal) los cuales son casi meridionales, produciendo cuatro macrómeras. En algunas especies estas son de diferente tamaño haciendo posible su identificación. Las segmentaciones posteriores tienen lugar en el polo animal del embrión. En la tercera segmentación, cada macrómera se divide dando origen a una micrómera hija y una macrómera hija; las micrómeras se desplazan hacia la derecha o izquierda de su macrómera hermana generando un patrón en espiral. En la cuarta segmentación, las macrómeras hermanas (producidas en la tercera segmentación) se dividen generando cada una, una micrómera hija y una macrómera hija las cuales se desplazaran de forma contraria que en la tercera segmentación, y así sucesivamente.

En los moluscos que tienen concha, como los caracoles; esta puede presentar enrollamiento destral (hacia la derecha) o enrollamiento sinistral (hacia la izquierda). Esta orientación de la concha es controlada por factores citoplasmáticos dentro del ovocito y por lo general, es igual en los miembros de una especie (Gilbert, 2006).
Sturtevant en 1923 descubrió que en algunas especies el enrollamiento de la concha del caracol se encuentra determinado genéticamente, siendo el genotipo del óvulo materno el que determina la dirección de la segmentación en el embrión (Gilbert, 2006).

Joanne Render en 1997 estudió el mapa de destino del caracol "Ilyanassa obsoleta". Render siguió durante el desarrollo diferentes células marcadas con fluorescencia y observó que diferentes grupos de micrómeras contribuyen a la formación de diferentes partes del cuerpo. Por ejemplo, el segundo cuarteto de micrómeras forman la concha, velo, boca y corazón (Gilbert, 2006)

En el ovocito de los moluscos, los determinantes morfogenéticos están localizados en regiones específicas que determinan a diferentes blastómeras dependiendo de su posición dentro del ovocito; a esto se le llama desarrollo en mosaico. Las moléculas que están unidas a ciertas regiones del huevo forman el lóbulo polar. En 1896 Crampton demostró que el lóbulo polar es esencial para la formación de algunos órganos como el intestino, corazón, músculos y ojos; con esto pudo concluir que el lóbulo polar está compuesto por determinantes mesodérmicos y endodérmicos que le dan la capacidad al blastómero de formar estas estructuras con las cuales va a estar en contacto (Gilbert, 2006, Crampton, 1896). Además de ser clave para la determinación celular el lóbulo polar es necesario para la polaridad dorso-ventral del embrión, ya que también contiene los determinantes necesarios para ello.

En este proceso las micrómeras del polo animal se multiplican hasta cubrir las macrómeras del polo vegetal. El embrión es cubierto en su totalidad excepto por una hendidura en el polo vegetal (Gilbert, 2006).

A lo largo de la evolución de los moluscos han ocurrido dos grandes hechos evolutivo: el primero de ellos, la aparición de un ancestro con caracteres primitivos que originó la diversidad de los grupos actuales; el segundo, la aparición de la concha con las modificaciones que han determinado la diferenciación de cada grupo. Actualmente, existen dos modelos que resumen las características de ese molusco hipotético inicial: el de Salvini-Plawen (1980) y el de Yonge (1957).

El aspecto de este molusco hipotético recuerda a una babosa actual marina. Se reconoce una cabeza (carente de cuernos, brazos, etc.) con boca y ganglios cerebroideos. Tiene una plataforma reptante; el pie, que le permite desplazarse por el bentos dejando un rastro de moco a su paso. Sobre del pie se observa la masa visceral, donde se alojan los órganos internos. La masa visceral además tiene una epidermis denominada manto; que genera unas espículas calcáreas (en lugar de una concha) y contiene la cavidad paleal.

La pared del cuerpo podría tener cutícula en alguna de sus partes. Posee una epidermis con células epidérmicas, de soporte; glandulares, mucocitos (productoras de moco) y sensoriales. Por debajo, se encuentra la membrana basal y debajo de esta, la musculatura circular, oblicua y longitudinal ( dispuesta en este orden). Entre las tres capas de musculatura existen espacios hemolinfáticos.

El tubo digestivo de este molusco estaría dividido en tres regiones: anterior, media y posterior. La región anterior contiene el órgano llamado rádula. Esta rádula tendría una estructura cartilaginosa denominada odontóforo, que es un "cojín" donde se apoya una banda proteica llena de dientes, la verdadera rádula. Ese odontóforo está dentro de la cavidad bucal y a su servicio están muchos músculos, como los protractores y retractores. Los protractores hacen que ese cojín asome fuera de la boca y los retractores hacen que se meta. A su vez, estos dientes (rádula) también tienen músculos protactores y retractores.

Existe mucha variabilidad en las rádulas. El bulbo bucal tiene varias estructuras: como el agujero de la boca, mandíbulas, un órgano subradular (una especie de lengua con función sensorial para identificar el alimento), odontóforo, etc. Los dientes son de crecimiento continuo a partir del saco radular. La cinta de dientes se va desplazando hacia delante con el tiempo, desprendiéndose los dientes desgastados y siendo reemplazados por los nuevos. Después viene el esófago y detrás de él, el resto del tubo digestivo con el intestino medio (que ocupa casi toda la cavidad y tiene una serie de divertículos laterales para aumentar la suferficie), a continuación el recto y por último en el ano (que desemboca a la cavidad paleal).

El celoma o complejo reno-gonadal-pericárdico en moluscos se encuentra dividido. Tienen un par de sacos celomáticos dorsales situados en la mitad posterior del animal, conectándose a la cavidad paleal a través de celomoductos y sus correspondientes celomoporos. Por detrás, existe otro saco celomático posterior, denominado pericardio (con sus pericardioductos); que, si desarrollan un nefrostoma originan metanefridios con sus correspondientes nefridioductos y nefridioporos. El peritoneo de los sacos celomáticos anteriores originan las gónadas, con sus correspondientes gonoductos y gonoporos, desembocando también en la cavidad paleal.

La cavidad paleal tiene los ctenidios (branquias en forma de pluma, con un eje central y láminas a ambos lados). A la altura de los ctenidios aparecen unos vasos sanguíneos cerrados que están relacionados con el sistema circulatorio.

El sistema nervioso es sencillo, poseen un ganglio cerebroideo con un anillo nervioso anterior que irriga el bulbo bucal en su conjunto además de dos pares de cordones nerviosos longitudinales que se dirigen hacia la parte posterior del animal (dos al pie y dos a la masa visceral). En relación con la cavidad paleal, podría haber existido algún ganglio para toda esa zona.

La reproducción es sexual con fecundación externa. Se supone una segmentación espiral, gastrulación por epibolia que daría lugar a una larva trocófora.

Este molusco hipotético es semejante al desarrollado por Salvini-Plawen, pero conlleva algunas modificaciones. En este modelo sí hay una auténtica concha (y no espículas). El tubo digestivo tiene una glándula digestiva relacionada con la primera cámara del estómago. El intestino en lugar de tener divertículos laterales, tiene muchas asas intestinales aumentando la superficie y eficacia de absorción. El sistema reno-gonadal-pericárdico carece de conductos, las gónadas comunican con el pericardio y los sacos celomáticos anteriores que desembocan en la parte posterior.

Ambos estudios comparten unas bases características aunque de diferente estructura. El pie, masa visceral y la pared dorsal de esta última, se encuentran formando el manto con su cavidad paleal y estructuras internas.

La concha tiene tres capas: periostraco, mesostraco y endostraco (externa, media e interna respectivamente) con componentes orgánicos e inorgánicos. Entre los orgánicos destaca la matriz proteica de conquiolina, mientras que en los inorgánicos destaca el carbonato cálcico (cristaliza en forma de aragonito o calcita), el sulfato magnésico y el carbonato magnésico. El periostraco está formado por una capa de conquiolina. El mesostraco es la capa más gruesa, esta es segregada por el borde del manto y está formada por una combinación de ambos componentes predominando la parte inorgánica o mineral (incluso siendo esta la única en algunos grupos actuales) frente a la orgánica, con una disposición en forma de prismas. Por último, el endostraco tiene un reparto equitativo; es segregada por toda la superficie del manto y da un aspecto irisado brillante en una disposición en forma de láminas superpuestas reflejando la luz según su orientación.

La formación de carbonato cálcico es relativamente sencillo en el medio marino; se necesita agua (que incorporan fácilmente), calcio (lo incorporan por transporte activo) y dióxido de carbono (producen grandes cantidades debido al metabolismo de la urea).

A partir del molusco inicial de Salvini-Plawen (con espículas en el manto, denominado "Aculifera") aparecieron dos líneas principales que dieron origen al conjunto de todos los moluscos actuales. Por un lado, los grupos que conservan la condición de "Aculifera" y solo tienen espinas calcáreas en el manto (como los caudofoveados) y por otro lado, los que tienen concha ("Conchifera") similar al molusco del modelo de Yonge, de la que descienden la mayor parte de los grupos actuales de moluscos conchíferos. El paso de Aculifera a Conchifera podría haber sucedido en el análisis filogenético expuesto a continuación.

Las bandas de espinas de Aculifera se concentraron originando 7 bandas con las espículas ya agrupadas. Aquí aparecen de nuevo dos líneas: una que llevó a la nueva dispersión de las espinas (como sucede en los solenogastros) y la otra que llevó a la fusión de las espículas de cada banda originando 7 placas (como se observa en los Ectoplacota, un grupo fósil). A partir de esta última línea, salen otras dos: una en la que una de esas placas se divide en dos, originando 8 en total (como sucede en los poliplacóforos actuales) y otra en la que se fusionan las 7 placas formando, finalmente, una concha (los conchíferos).

Históricamente, los moluscos se han dividido en dos grandes grupos:

El análisis multilocus molecular, ha presentado los siguientes resultados:
Los moluscos se subdividen en ocho clases; se indica entre paréntesis el número aproximado de especies actuales.

Antiguamente los caudofoveados y solenogastros eran agrupados en la clase Aplacophora* que ahora se considera parafilético y dichos grupos clases separadas. Por otra parte, la tendencia actual es la de dividir la clase Gastropoda en dos subclases: Eogastropoda (que incluye solo las lapas verdaderas) y Orthogastropoda que incluye todos los demás gasterópodos.

Los moluscos son diversos tanto en forma corporal como en los ambientes donde habitan, por lo que para su captura se requiere conocer bien a la especie con la que se quiere trabajar, así como poseer destrezas para su recolección. Cabe tener en cuenta la legislación de cada país o estado ya que diversas especies están protegidas por la ley por su escasez causada; en parte, por un exceso de capturas para fines gastronómicos o coleccionistas.




</doc>
<doc id="1956" url="https://es.wikipedia.org/wiki?curid=1956" title="Música folclórica de México">
Música folclórica de México

La música folclórica de México es una manifestación que es fruto del mestizaje que se dio entre las muchas tradiciones europeas, americana y africana, entre otras. La música mexicana es sumamente variada e incluye diversos estilos determinados por la región geográfica de proveniencia. Algunas de las canciones tradicionales de México son conocidas por el mundo. Se ejecutan varios tipos de instrumentos musicales de origen mestizo, además de los europeos que son muy populares.

El folclore nació a mediados del siglo XIX. El erudito inglés William John Thoms propuso el término de la palabra el 22 de agosto de 1846 para hacer referencia a las antigüedades populares del saber tradicional. Fueron dos los movimientos culturales que impulsaron el surgimiento del folclore: el romanticismo y el pueblo como sociedad. Ambos movimientos enaltecieron la sensibilidad artística del pueblo, el cual se percibió como un nuevo protagonista inmerso en temas para expresar.

En México el folclore penetró a finales del siglo XIX. En el año de 1885, Joaquín García Icazbalceta pronunció un discurso en la Academia Mexicana de la Lengua en donde define el folclore como " la expresión de los sentimientos del pueblo en forma de leyendas o cuentos, y particularmente en coplas o cantarcillos anónimos, llenos a veces de gracia y a menudo notables por la exactitud o profundidad del pensamiento".

Sin embargo, hasta los primeros años del siglo XX es cuando aparecen los primero esfuerzos para promocionar la investigación folclórica en México. En las primeras décadas se puede encontrar la participación de Valentín F. Frías quien publicó leyendas y tradiciones queretanas, también se encuentra Nicolás León quien fue un notable precursor del folclore.

Durante la siguiente década (1920-1930) aparecieron publicaciones dedicadas al folclore, estimulando así el interés y publicaciones de libros como lo fue "El folklore y la música mexicana," editado por las Secretaría de Educación Pública (SEP) en el año de 1928 bajo el gobierno de Plutarco Elías Calles.

El sentimiento nacionalista que creció durante las siguientes décadas, hasta el gobierno de Lázaro Cárdenas del Río (1934-1940) representó gran importancia en el desarrollo del folclore como objeto de estudio, ya que recibió recursos por parte del gobierno para desarrollar investigación así como un mejor desarrollo artístico.

Se sabe muy poco de la música prehispánica de México, aunque son abundantes los grupos que reivindican esa tradición a lo largo de todo el país.

Los indígenas carecían de instrumentos de cuerda entre otros, y su música estaba basada en percusiones e instrumentos de viento. Existen muy pocas referencias históricas y arqueológicas que permitan siquiera adivinar el tipo de música que cultivaban los indígenas antes de la llegada de los españoles, sin embargo se presume que era de tipo imitativa y guerrera, es decir que buscaban recrear los sonidos de la naturaleza con los instrumentos que fabricaban con barro, carrizo, pieles y demás, así como ritmos que acompañaban las danzas guerreras y rituales.

Del último período de la civilización mesoamericana se sabe que existía una deidad patrona del canto, la música y el juego. Su nombre era Xochipilli, el "Príncipe Flor".

Actualmente se ha llevado a la música prehispánica al plano de la música etnoelectrónica, en la que prevalece la fusión de los instrumentos autóctonos con ritmos modernos como el house y el minimal, tal como lo hace el colectivo Wicholly Broders y Zompantli.

En el tiempo actual algunos compositores han utilizado instrumentos prehispánicos tal es el caso de Carlos Chávez en la sinfonía india y en el ballets se han utilizado también para reconstruir sonidos de la música.

Los instrumentos estaban hechos de carrizo, madera, caparazones de tortugas, estos eran algunos materiales utilizados.

La música interpretada por pueblos indígenas en la república mexicana, posee influencias de la música europea y mestiza, como el uso de los instrumentos de cuerdas, de tambores con amarre de cuerda, y el uso de acordes. Un ejemplo instrumentístico es la unidad tamboril-flauta, donde el ejecutante toca la flauta con una mano y el tambor con la otra mano, cuya tradición la introdujeron los españoles en el siglo XVII. En la época prehispánica, el flautista y el tamborero tocaban por separado. También existen los duetos flautista y tamborero, similares a los de la música mestiza y música europea tradicional.

El uso de la música es una característica esencial, sobre todo en las fiestas religiosas, aunque su uso no se limita a ellas, sino también al esparcimiento y goce del espíritu. En unas y otras ocasiones representan un papel de importancia, ya que todas las veces que en ellas se cantaban las tradiciones de hechos remotos protagonizadas por ciertas tribus describían acontecimientos importantes como lo podían ser: cataclismos producidos por la naturaleza, epidemias, guerras, victorias y fracasos, hechos hazañosos de ilustres antepasados, entre otros.

Internacionalmente conocido es el conjunto del mariachi, asociado a las grandes figuras de la "canción mexicana" ranchera, que tuvo su período de florecimiento entre las décadas de 1940 a 1970. Es un caso muy interesante pues un conjunto típico regional se convirtió en un símbolo nacional.

El Mariachi es originario del occidente de México, específicamente de los estados de Nayarit, Colima y Jalisco, que se disputan su paternidad. Lo cierto es que en un principio, el mariachi era una orquesta popular e indígena, y su indumentaria nada tenía que ver con la del charro (es decir, el traje de los ricos hacendados ganaderos) e interpretaban los "sones de mariachi". Una nota interesante es que estos conjuntos musicales arribaron a la Ciudad de México antes que a la capital de Jalisco. A partir de la primera década del siglo XX comienzan a transformarse: visten el traje de charro (mismo que ya usaban las orquestas típicas desde el Porfiriato), y amplían su repertorio con piezas de diferentes regiones de la República: sones abajeños, jarabes, corridos, huapangos y canciones bravías, al estilo de Lucha Reyes. También añadieron la trompeta como instrumento imprescindible.
Con el auge del cine mexicano las películas de Tito Guízar, Jorge Negrete, Pedro Infante y Javier Solís, dieron a conocer el mariachi así como un México rural idealizado.

El son es una música en la cual se mezclan las influencias indígenas, españolas y africanas, incluso asiáticas en algunos casos. Se trata de un género con ritmo de 6/8, cuya instrumentación varía de región en región. Un conjunto de sones es denominado jarabe, y de este tipo, existen los jarabes Tapatío, Mixteco, del Valle, Tlaxcalteca, Michoacano, etc. Además de los ya señalados sones de mariachi, hay son jarocho, huapango, son abajeño y muchos más. Géneros de aparición más tardía son la jarana y la trova yucateca, que se cultivan en la península de Yucatán, y que recibieron influencia caribeña (especialmente del son cubano) e incluso andina (bambuco colombiano); la chilena, originaria de los estados de Guerrero y Oaxaca, y que recibió la influencia de la cueca chilena y la marinera peruana. Así mismo surge la rondalla, en las clases sociales estudiantiles populares urbanas, en aquellas que no podían adquirir los instrumentos de la estudiantina.

La Banda Sinaloense o Tambora Sinaloense es un tipo de ensamble musical, de género musical tradicional y popular, el cual es culturalmente establecido a principios de los años veinte en el Estado de Sinaloa, región norte occidente de México. Es un género con remanentes europeos al estilo organológico de la fanfárria europea, interpreta un repertorio variado en las formas musicales, en el que predominan sones tradicionales, rancheras, corridos, polkas, valses, mazurcas, chotis, todo ello adaptado a la sensibilidad de los habitantes de esta región mexicana; además de música popular como balada romántica y cumbia.

A finales del siglo XIX, en todas las regiones de México existían ensambles de instrumentos de viento y piano, que tocaban en regimientos militares, fiestas de pueblo y procesiones religiosas, añadiéndose a los ensambles los últimos instrumentos de aleaciones de metal.

La música norteña es un género de música folclórica y popular de México, interpretado por un conjunto norteño, que consiste en una instrumentación de acordeón y bajo sexto (en algunas regiones conocida como "fara-fara"), con adición de contrabajo (conocido en México también como tololoche), también incluye tarola y ocasionalmente, saxofón. A menudo conjuntos más modernos suelen emplear batería y bajo eléctrico en lugar del tradicional contrabajo y tarola. Algunos de los grupos más conocidos de este género musical son: Ramón Ayala, Los Cadetes de Linares, los Tigres Del Norte, Los Invasores de Nuevo León, Carlos y José, Grupo Pesado, Intocable, Los Huracanes Del Norte, los Cardenales de Nuevo León, Grupo Duelo y Los Tucanes de Tijuana. Su repertorio posee formas musicales cantadas e instrumentales que provienen tanto de la tradición musical mexicana (canción ranchera, corrido, bolero ranchero, huapango) como de la europea del siglo XIX (polca, chotis, redova) y colombiana como es la cumbia. Aunque originaria de áreas rurales del noreste de México, la música norteña es hoy sumamente popular tanto en áreas urbanas como rurales.

El huapango es un género musical mexicano basado en compás ternario, interpretado en diversas formas, las más conocidas son tres variantes: el huapango típico o son huasteco, interpretado por el trío huasteco; el huapango norteño, interpretado por conjunto norteño y el huapango de mariachi.

La palabra "huapango" parece ser derivada del vocablo náhuatl 'cuauhpanco', de "cuahuitl", leño de madera o árbol,"pan" y "co", ambos sufijos locativos que hacen de la primera palabra un locativo. Es decir, en síntesis sobre el tablado o sobre la tarima. Jarana huasteca. También se conoce con el término son huasteco. En un principio existía la diferenciación entre los términos, siendo los huapangos las canciones con letra fija y los sones huastecos las piezas para trovar, para echar versos. Se toca en las regiones de Veracruz, San Luis Potosí, Hidalgo, Tamaulipas, Puebla, Guanajuato y Querétaro.

La música de marimba es la música interpretada ya sea por una, dos o más personas (un ejecutante en el área de sonidos graves o bajos) o por una orquesta de marimbas, a la que se agrega bajo eléctrico o contrabajo, batería y un instrumento de aliento. Su repertorio tradicional es de sones y canciones del sureste, además de otras formas musicales típicas del país.

En Chiapas la música de Marimba es muy versátil, es tal el gusto por este instrumento musical en Chiapas, que es en este estado donde se ha perfeccionado la marimba. En Chiapas se interpreta en Marimba, Zapateados, Sones Chiapanecos, Valses, Paso Doble, Música Clásica, Música Clásica contemporánea, Música Ranchera, Música Norteña, etc.

El Son Jarocho es la expresión musical propia de la cultura jarocha (parte de los estados de Oaxaca, Tabasco y Veracruz). Se practica esencialmente en la fiesta tradicional de los jarochos llamada fandango jarocho, donde se combina con la danza zapateada y la poesía cantada. Esta expresión artística también es ampliamente practicada por ejecutantes que no son de origen jarocho. La música tiene un ritmo armónico, generalmente sesquiáltero, con síncopas y contratiempos, la lírica tiene coplas cambiantes llamadas "versos" y la danza se basa en el zapateado con algún carácter similar en algunas regiones de México. 
Lista de formas musicales folclóricas:

Los cantos y la alabanza de los dioses, héroes y mandatarios fueron la principal manifestación de la música entre los primitivos pobladores de México; aunque los cantos a los héroes no eran sino en alabanza de los dioses, dándoles gracias por las victorias obtenidas por aquellos, pidiéndoles los siguiera favoreciendo con sus dones para gloria de su pueblo, por lo que podemos decir que la música era casi exclusivamente religiosa.

Unidos a los cantos casi siempre a ceremonias místicas, no lo eran menos que las danzas, una variedad pintoresca, que aun en la actualidad, habiéndose perdido la inmensa mayoría y modificándose muchas de las restantes por la influencia que impulsó la religión católica, sobreviven muchas de ellas.

Danza del venado

Los primeros historiadores de México, sobre todo los religiosos veían en aquellos cantos y danzas obras del demonio, expresándose con un candor pueril, en tono místico, muy propio del tiempo. Los cantos y danzas se acomodaban a todas las circunstancias. La había regocijadas y alegres, así como monótonas y tristes.

La danza en las sociedades indígenas se encuentran estrechamente vinculadas al ritual de la música; en torno a cada danza existe algún suceso de tipo comunitario, del ciclo de vida o de carácter incidental. A su vez, un alto porcentaje de la música indígena se encuentra vinculado a la danza. La música de una danza puede considerarse desde varios puntos de vista: existen las que cuentan con música propia y las que se realizan mediante composiciones que no le son exclusivas; algunas danzas se practican de acuerdo con un número definido de melodías y otras lo hacen sin sujetarse a una cantidad determinada de piezas.

La danza nahua "Aztecatzitzin" presenta cuatro partes: las "mañanitas" a la Virgen, los "Cantos de ofrecimiento", los "Sones de marchas" y los "Sones de bailes y brincos"; así mientras que la primera parte es constantes, los cantos y los dos tipos de sones cambian en número de una ejecución a otra. Entre los yumanos existen varios ciclos de cantos; uno de ellos consta de cinco cantos realizados en estricta secuencia, desde que se pone el Sol hasta la mañana siguiente. El simple número de melodías para las danzas es muy variado: la danza huave del "Pez espada" comprende cinco piezas, la popoluca del "Tigre,"ocho; la zapoteca de "Negros colmilludos," 10; la nahua de"Tocotines," 14; la chatina de "Espadas" , 15; la nahua del "Tecuàn," ocho piezas de "la travesía" y 14 de la "Toreada", totonaca de "Negritos," no menos de 32; la amuzgo de "la Conquista," más de 50, etc.

La música folclórica es una necesidad espiritual de una comunidad determinada, esta pudo ser compuesta por una persona, la música folklórica no sufre efectos por las modas ya que esta música interpreta el sentir de un pueblo y hace que permanezca y se identifiquen con el espíritu del pueblo.

La música folklórica mexicana es una mezcla de diferentes tradiciones como las europeas americana y africana, además que el estilo se determina dependiendo de la ubicación geográfica de donde provenga. Se ejecutan con varios tipos de instrumentos musicales, la música ha estado presente en todas las épocas de la historia mexicana así como también México ha conservado un espacio singular en cuanto a las representaciones sonoras, cantando o tocando instrumentos, la música ayuda a crear una identidad para expresarte como sociedad o pueblo además de ser un componente fundamental en la vida de los mexicanos.

Una danza folclórica fija es coreografía tradicional ejecutada en una pieza musical específica.

Ejemplos:

La voz humana es un instrumento omnipresente en la producción de sonidos artísticamente pautados entre los pueblos de México, aunque con menos porcentaje de ocurrencia. Algo similar puede decirse de los pies, no así de las manos, que más que sonar por sí mismas se utilizan en la ejecución de instrumentos. A su vez, todas las sociedades cuentan con distintos instrumentos que pueden ser de origen americano, como el instrumento de percusión conocido más por sus nombres náhuatl, "teponaztli" y maya, "tunkul" ; bien de procedencia europea, como la guitarra, o de ascendencia africana, como la marimba. Ninguno de los pueblos indígenas emplea las docenas de instrumentos existentes, al mismo tiempo que la distribución de cada uno de ellos es muy desigual.

De la gran cantidad de aspectos organólico y de uso de los instrumentos nos concentramos a referir sólo algunos casos selectos, como la práctica kiliwa o paipái de afinar sus sonajas por medio de pequeños orificios. El instrumental yaqui-mayo de la Danza del venado requiere de la elaboración de los sartales de capullos de mariposa secos rellenos con piedrecillas del hormigueo, un bule puesto boca abajo en una bandeja con agua y percutido con un mazo cubierto de hojas de maíz, así como raspadores apoyados en bules resonantes puestos boca abajo sobre la tierra.

Figuran también los elementos de madera sobre los que se zapatea, como la tabla seri o la tarima cora; o la existencia entre los pames de flautas de mirlitón, cuya membrana vibrante está hecha de cierta tela de araña; los tambores de barro de los lacandones o el tambor kikapu que lleva agua por dentro; el arco musical de los mitotes coras y tepehuanos, entre muchos casos más.

Otro aspecto importante de los instrumentos musicales es la iconografía que en ocasiones éstos presentan, así como el simbolismo al que algunos de ellos están asociados. En primera instancia se encuentran las sonajas adornadas con plumas o pintadas, espejos adosados a los brazos del arpa y tiracuerdas de contornos ondulares de las guitarras. Por otro lado, los instrumentos musicales son fuerzas o seres animados o simplemente representaciones de algo, entre otras cosas. Así los yumanos utilizan sonajas elaboradas con pequeños carapachos de tortuga, cuyas líneas representan mapas del mundo, Para los otomíes el sacudimiento de sonajas es una invocación a las nubes, y un llamado al trueno y la lluvia; los mazahuas también llaman a la lluvia con danzas, en las cuales se golpean en el piso bastones con cascabeles. En varias sociedades indígenas los instrumentos musicales tienen alma: los tlahuicas, del Estado de México, custodian en su iglesia un antiquísimo teponaztli, que se han llegado a fugar para unirse a s u madre, que se encuentra en Morelos; los huastecos le dan sepultura a sonajas, jaranas y demás instrumentos que se van rompiendo; y los totonacos les dan de beber aguardiente a violines y guitarra antes de usarlos. Los instrumentos musicales también llegan a encarnar ciertas dualidades, como los tambores "hembra" (de dimensiones mayores) y "macho" (de dimensiones pequeñas) del conjunto tabasqueño chontal de los Tamborileros, Algunos de ellos existen en dos formas de empleo complementario, como en una sociedad huichol que todo el año utiliza el canari (especie de guitarra de pequeñas proporciones) y solo durante la Semana Santa emplean su contraparte: una matraca en forma de guitarra.

Finalmente, en varios de los pueblos indígenas consideran los instrumentos musicales como los genuinos emisores de los sonidos perfectos, de origen divino.

En varios lugares y momentos la música está invariablemente ligada a la vida de los mixes, en las alegrías como en las tristezas, tanto en los actos cívicos, sociales y religioso, como en momentos colectivos y familiares; por lo tanto existen diversas formas de expresión musical acorde con los momentos por los que pasa la gente del pueblo mixe. La música con que se acompaña a las personas de este pueblo e su última morada son marchas de ritmo y compás lento que se reflejan al pesar que tienen los familiares y amigos por la muerte que llega a determinada casa.

Así las marchas fúnebres las interpreta la banda del pueblo en la casa del difunto y en el trayecto hacia su última morada. Se le escucha con respeto, y aunque por lo regular está asociada con la tristeza, también significa un gran aliento escucharla en la casa en donde se recibe el duelo, porque se sabe que no se está solo en los momentos difíciles por lo que pasa la familia.

Al día siguiente, poco antes de partir, la banda llega nuevamente a la casa a despedir al difunto, posteriormente es acompañado a la iglesia de su credo y de esta al panteón. Para la banda no hay religión en esos momentos, y básicamente su presencia depende de la decisión de los familiares.

Normalmente suelen escucharse las siguientes obras:




</doc>
<doc id="1963" url="https://es.wikipedia.org/wiki?curid=1963" title="Midgets en Argentina">
Midgets en Argentina

Las carreras de midgets en Argentina se realizan por temporadas configurándose en Campeonatos Invernales y de Verano, corriéndose ocho (cuatro a partir de 2017) y dieciocho fechas respectivamente.

El “Midget”, es una categoría originaria de EE.UU que llegó a Argentina en la década de 1930 de la mano de un grupo de pilotos Norteamericanos que arribaron al País junto a sus máquinas de competición para presentarse en Capital Federal. Aquellas presentaciones deslumbraron a pilotos Argentinos quienes comenzaron la construcción de midgets en el país.

La categoría se hizo fuerte en Bahía Blanca en el año 1955 a través del Bahía Blanca Automóvil Club, que organizó el primer Campeonato Estival de la categoría Midget en un circuito alquilado al Club Liniers. Durante los 25 años siguientes las carreras se organizaron a través de una Asociación de pilotos, finalmente en el año 1979 nació el Club Midgistas del Sur continuando el crecimiento y desarrollo ininterrumpido de la categoría durante los siguientes 24 años.

Finalmente en la temporada 1999-2000 llega la consolidación del Midget Bahiense de la mano del “Club Midgistas del Sur” que, a través de la decisión de correr en instalaciones propias, superó definitivamente los inconvenientes que se suscitaban a la hora de fijar días y horas para realizar las competencias. Este hecho sentó definitivamente las bases para el auge del “Midget” que actualmente es la categoría del Automovilismo Zonal con mayor crecimiento Nacional entre los años 2000 y 2003 convirtiéndose en la más importante a nivel Nacional Zonal.

Se transitarían algunos años de “Midget” en comunión con el “Bahía Blanca Automóvil Club” (B.B.A.C.)siendo al principio la Agrupación de Midgistas del Sur”.

Habiéndose construido una pista dentro del autódromo de “A.E.C.”, con el aporte económico mayoritario de los pilotos y su Agrupación, el “B.B.A.C.” en el año 1978 decide unilateralmente transformar dicha pista en el actual kartódromo. Esto causó un gran malestar en la agrupación y sus pilotos y la respuesta inmediata fue romper con el “B.B.A.C.” y a su vez fundar la “Asociación Midgistas del Sur” (A.M.S.).

Esa nueva entidad, condujo los destinos de la categoría hasta que ante la imperiosa necesidad de tener la posibilidad de poder programar y fiscalizar sus competencias, ya que como Asociación siempre se debía depender de una tercera entidad que estatutariamente pudiera organizar las mismas, se decidió pues, transformarla en el “Club Midgistas del Sur” (“C.M.S”) el 3 de noviembre de 1979. El resultado: En diciembre de ese mismo año se realizó el 1.. Torneo Oficial Nocturno del Club.

Durante el año 1987, el “C.M.S” compró un terreno de algo más de 7 hectáreas en la zona de Aldea Romana, donde se construyó una pista a fin de ser utilizada para el entrenamiento de pilotos y carreras de campeonatos invernales, un lugar quizás demasiado alejado e incómodo para el público de aquella época pero adquirido con una gran visión de futuro.

Las actividades del “C.M.S” a través de los años se desarrollaron en varios escenarios siempre dentro del círculo urbano de Bahía Blanca. Primeramente en el estadio deportivo del “Club Villa Mitre” denominado “Círculo Rojo”, luego en el estadio del “Club Tiro Federal” denominado “Circuito Naranja”, después en el Club Dublín "Carlos Gerticer" y finalmente en el predio del “Club Midgista del Sur” en Aldea Romana.

Los duros avatares económicos a los que se enfrentó el Club durante sus 24 años de existencia fueron resueltos en conjunto entre los dirigentes, asociados y pilotos demostrando la unión entre cada integrante y fortaleciendo al Club como institución. Ellos, aportaron dinero, se endeudaron y hasta en algunos casos llegaron a comprometer sus patrimonios personales para colaborar con las necesidades financieras coyunturales del Club. Es de destacar la actitud de los pilotos que participaron de algunas competencias sin recibir premios, a fin de donarlos para la cancelación de créditos tomados por aquellos de manera personal para beneficio del Club.

Mucho más allá de la actividad específica y contando con la anuencia y la colaboración de pilotos y simpatizantes, a lo largo de estos años, el “C.M.S.” ha realizado varias competencias colaborando con distintas instituciones de bien público de la ciudad y de la Zona fundamentalmente con la recepción de alimentos no perecederos, siendo el Patronato de la Infancia y la Asociación Darmha, las últimas favorecidas en el transcurso del año pasado.

El “Club de Midgistas” tiene muy claro como llevar adelante la categoría, brindando tanto al espectador como a los pilotos lo que necesitan para disfrutar y competir. Respondiendo a sus exigencias realizando obras de infraestructura como por ejemplo: nuevos boxes, nuevos accesos a pista, nueva iluminación nocturna, nuevos servicios sanitarios, habilitando más espacios de cantinas, rediseñando plateas, desviando una línea de colectivos que lleva y trae gente al estadio los días de competencia, habilitando una playa de estacionamiento dentro del predio con capacidad de 1200 autos, etc...en fin brindándoles cada vez más comodidades con el objetivo de atraer más pilotos y más público. Prueba de ello es el constante e ininterrumpido aumento en el promedio de autos en competencia por temporada y en la afluencia de público en ese mismo lapso. En la temporada 2013/14 se inauguraron cuatro pantallas LED cuyas medidas son 7x5 en las cuales se muestra información de la fecha en curso, videos, repeticiones, etc.

El Club tiene plena conciencia de lo que significa el automovilismo como espectáculo, por ello es que cuenta en todas las competencias con seguro de espectador, seguros que cubren a los pilotos brindado por la “Asociación Argentina de Volantes”, dos ambulancias permanentes una de emergencias con dotación completa y otra de traslados, carro de bomberos, personal entrenado y policía que se ocupa de la vigilancia del estadio.

Con una visión de futuro y respondiendo a las necesidades de la demanda del público y pilotos, el Club tiene bajo análisis varios proyectos que de materializarse redundarían no solo en una mejora en la calidad de servicio tanto a público como pilotos sino que además reportarían beneficios al Club. En esa línea se viene trabajando muy seriamente para lanzar la categoría a nivel Nacional, ya que como resultado de los esfuerzos realizados por el “Club Midgistas del Sur” en lo referente a difusión, el “Midget” es hoy la categoría del Automovilismo Zonal con mayor crecimiento Nacional entre los años 2000 y 2003. Convirtiéndose en la más importante a nivel Nacional Zonal.

Se corre en una pista ovalada de tierra compactada de aproximadamente 400 metros de longitud. La fecha consta de un mínimo de diez series con un máximo de 8 pilotos por serie, en caso de presentarse más de 80 pilotos, se agregan las series necesarias.
Una vez finalizadas las series, los 40 mejores tiempos pasan directamente a las semifinales, los restantes pilotos se agrupan en repechajes con una máximo de 10 pilotos por repechaje ordenados en dos filas de cuatro autos y una de dos (si fuera necesario), de estos repechajes salen 8 pilotos para completar las semifinales y 8 suplentes para cubrir vacantes en las semifinales.
Se realizan cuatro semifinales con 12 pilotos cada una, ordenados en 3 filas de cuatro autos, clasificando en forma directa 10 pilotos para la gran final de la noche y otros 12 pilotos para una prefinal que clasifica a los dos primeros de forma directa para completar así los 12 de la final.
La gran final de la noche se corre con 12 pilotos alineados en tres filas de cuatro autos cada una.
Desde sus comienzos el campeón fue el que más puntos obtenía sumando todas las fechas del campeonato. A partir del campeonato 2011/12 se implementó el sistema de playoff. Al término de la fase regular de 12 fechas, comienza la etapa de playoff de 6 fechas, en la que entran los 12 mejores, y todos los que hayan ganado una fecha, que no se encuentren entre estos primeros 12 pilotos, y entre ellos se define al campeón. El resto de las posiciones se definen con el campeonato general.

Hasta hoy se realizaron campeonatos en 61 temporadas desde 1955 (con la particularidad que se realizaron 2 por año entre 1957 y 1962) primeramente y hasta 1962 en el Club Liniers, pasando por el Club Villa Mitre (Círculo Rojo) entre 1962 y 1981, luego por Tiro Federal (Circuito Naranja) hasta 1996, después el Club Dublin entre 1996 y 1999 y finalizando en el actual predio de Aldea Romana. Siendo el primer campeón Eduardo Mendivil y el último y actual Fernando Caputo (temporada 2018/19). El máximo ganador es Héctor "Nene" Plano con 7 consagraciones.




</doc>
<doc id="1964" url="https://es.wikipedia.org/wiki?curid=1964" title="Macropodidae">
Macropodidae

Los macropódidos (Macropodidae) son una familia de mamíferos marsupiales del orden Diprotodontia compuesta por un gran número de géneros. Incluye a los canguros, ualabíes y especies afines. El término "canguro" se usa en sentido amplio para todo el grupo, aunque es más frecuente su uso para las especies de mayor tamaño

La mayoría de especies son terrestres y se desplazan a saltos cuando corren. Hay unas pocas especies que son principalmente de vida arborícola (género "Dendrolagus") y que son torpes en tierra. Los macropódidos son exclusivamente herbívoros.


Subfamilia †Bulungamayinae

Subfamilia Lagostrophinae

Subfamilia †Sthenurinae

Subfamilia †Balbarinae

Subfamilia Macropodinae













</doc>
<doc id="1965" url="https://es.wikipedia.org/wiki?curid=1965" title="Moda">
Moda

La moda (del francés "mode" y del latín "modus" ‘modo, medida’) es un conjunto de prendas de vestir, adornos y complementos basados en gustos, usos y costumbres que se utilizan por una mayoría durante un periodo de tiempo determinado y que marcarán tendencia según la duración del mismo; aunque también la moda se refiere a algo que se repite muchas veces, en este caso, las prendas de vestir.

La intención de ciertos individuos de separarse de las tendencias dominantes de moda crea generalmente una nueva tendencia por su carácter diferenciador. (Simmel). 

La propagación de una tendencia en la moda desemboca necesariamente en su fracaso. Toda moda ampliamente aceptada pierde su atractivo al dejar de ser un elemento diferenciador.

En su obra La teoría de la clase ociosa, Veblen relata cómo la moda es una herramienta que la clase alta usa para diferenciarse del resto de clases, fundamentalmente de las más bajas. La belleza y el simbolismo del ocio; relacionado con el ser pudiente, la sobriedad y la eficacia de las prendas de las clases bajas e industriales, quedan enfrentados. Bourdieu llama a esto "prácticas distintivas": la manifestación de la lucha de clases, en este caso simbólica, cuyo objetivo es perpetuar la desigualdad entre éstas.

"La difusión vertical de los gustos" es el mecanismo según el cual, argumenta Veblen, la moda se transmite de una clase a otra, pues toda clase imita a la inmediatamente superior. Los miembros pertenecientes a una determinada clase pueden identificarse entre ellos al estar en un mismo nivel y diferenciarse de otros al haber una barrera que les separa.

El gusto diferenciado de cada clase no es inherente a sus miembros. Según Bourdieu, es la consecuencia de la socialización de los individuos dentro de las distintas clases, es decir, su familia, su escuela, sus amigos de la infancia, etc. Este gusto se aprende del contexto y se interioriza. El término "nuevo rico" tiene una connotación despectiva, pues designa a alguien que si bien acaba de llegar, en términos económicos, a una nueva clase, no lo ha hecho en términos simbólicos; ya que no viste ni se comporta de la misma manera, no porque no tenga voluntad de hacerlo sino porque se ha socializado como alguien pobre, con unos esquemas mentales que le permiten procesar la realidad que le rodea para esa clase en concreto y no para otra.

Simmel considera que la moda es simplemente una herramienta que los individuos utilizan para liberarse de la angustia de la elección, al poder considerarse miembro de un grupo con facilidad. La individualidad exige una serie de responsabilidades que se diluyen en el grupo y obliga a los sujetos a defenderse por sus propias fuerzas (de los ataques simbólicos, se entiende). La moda sería, en este caso, un mecanismo que responde a una necesidad social y, por tanto, no se le puede buscar una finalidad última.

Cuanto mayor sea la dificultad de los individuos para diferenciarse, más febril es el combate simbólico de distinción-imitación que sucede entre diferentes clases, exigiendo esto, a su vez, más cambios que suceden a una mayor velocidad para satisfacer esta demanda. Y aquí, el sistema productivo responde con una mayor obsolescencia.

Keynes ideó la metáfora del concurso de belleza para explicar el funcionamiento de los mercados bursátiles, pero sirve también para explicar el funcionamiento de la moda desde la perspectiva de la transmisión horizontal.

Imaginemos un concurso en el que debemos elegir entre seis rostros aquel que consideremos que será el más votado. Si somos perspicaces, nos daremos cuenta de que no debemos escoger en función de nuestro gusto particular, ni tampoco del gusto mayoritario. Suponiendo que el resto de concursantes son igual de perspicaces que nosotros, debemos escoger el rostro en función de lo que pensamos que otros pensarán. Se trata de un juego de "pienso que piensa que yo pienso" sin fin. El problema que plantea es que es imposible adivinar el resultado con certeza. ¿Escogerán los demás en función de su gusto individual? ¿De la media de los gustos particulares? O ¿escogerán pensando en las estrategias de otros participantes? En definitiva, todas las personas, aunque no lo sepan, participan en un concurso de belleza.

En el Renacimiento italiano se acostumbraba, por parte del género masculino, el uso de capa corta y sin capucha, birrete, sombrero con plumas y zapatos de punta roma y ancha. Las mujeres por otro lado, llevaban bullones y acuchillados en las mangas, y una gorguera rizada; además de faldas y sobrefaldas, jubones y corpiños, capas o mantos rozagantes y una cofia para la cabeza.

A partir de la segunda mitad del siglo, la creciente importancia de la monarquía española impone en Europa el estilo de la corte del emperador Carlos I de España, un estilo de gran sobriedad, caracterizado por el uso de colores oscuros y prendas ceñidas, sin arrugas ni pliegues y aspecto rígido, sobre todo en las mujeres, en las que se impone el uso del verdugado. En el borde superior de la camisa se colocaba un cordón que dará lugar a la gorguera o lechuguilla.

Durante esta época domina la moda francesa, tanto en hombres como mujeres. Se utilizaban los calzones cortos con medias de seda, chupa y casaca que, a mediados del siglo, se vuelve más reducida y con pliegues laterales hacia atrás y mangas estrechas.

Con la caída de la dinastía francesa, vuelve el traje simple y se llevan calzones ajustados hasta media pierna, chaleco, corbata y casaca, faldones con cuello alto y vuelo, pelucas empolvadas y rematadas por un lazo, e incluso sombreros de tres o dos picos.

Tras la revolución, el cabello se deja largo y liso, visten sombreros de copa alta cónica o en tubo, con alas cortas y más tarde zapatos con tacón de color a los que se añaden lazos o hebillas y botas altas con vueltas. La mujer viste con painers o verdugados anchos y aplastados en los dos frentes, corpiño acorsetado y escote con gasas o encajes, polonesas, batas con cuello de encaje y manga larga. El traje francés consiste en corpiño puntiagudo, mangas abolladas, faldas rectas y abiertas, que son drapeadas con polizón y larga cola, cuello doblado y mangas tirantes hasta el codo con chorreras. Junto con la revolución, desaparece el vuelo de la falda y se imitan las vestiduras clásicas: talle alto, chaquetilla corta con manga larga, falda con pliegues, grandes escotes, chales y guantes largos. En cuanto al peinado, este es hacia atrás con rizados que posteriormente se hacen más altos y voluminosos con tirabuzones, lazadas y plumas, bonetes y sombreros de alas anchas. El tipo de calzado normalmente son zapatos con tacón alto y punta estrecha, aunque más tarde comenzaron a llevarse los bajos.

En el siglo XVIII destacan como prendas masculinas las casacas francesas y las chupas, esto es, casacas de inferior clase y algo estrechas, las chaquetillas, los calzones ajustados hasta la rodilla, las corbatas en vez de las golillas, las pelucas y los grandes sombreros. Mientras tanto, en las vestiduras femeninas continúa el mismo estilo que en el siglo pasado y se adopta el uso de las mantillas para la cabeza. Llevaban también vestidos largos, grandes sombreros y sobre todo en la alta sociedad, la mujer se caracterizaba por vestir con un corsé, que era una forma de demostrar su altura. Además usaban anillos, y algunas veces guantes largos o collares, entre otros.

Durante este siglo fueron propios el frac, la levita y el pantalón para los caballeros, y la mantilla de seda y las peinetas para las señoras en España.

Una vez finalizada la época napoleónica, desde 1800 hasta 1820, en la que la silueta femenina se mostraba esbelta y con el talle siempre alto, ceñido justo bajo el pecho, dejando el resto de la prenda caer recta sobre el cuerpo; hubo un cambio drástico en el Romanticismo, dando paso al corsé, que daba al talle la forma de un reloj de arena y al miriñaque, que ahuecaba las faldas amplias y que llegó a su apogeo en 1860, causando que las damas no pudieran pasear del brazo de su esposo o prometido. En 1870, fue sustituido por el polisón, que únicamente ahuecaba la falda por detrás y que pasó de moda en 1890, cayendo entonces la prenda hasta el suelo sin armazón alguno, aunque hasta 1900 las faldas fueron un poco acampanadas. 

Entre 1820 y 1914, hubo en el vestuario femenino occidental una clara distinción entre vestidos de día, siempre con manga larga, aunque podían ser hasta el codo en verano, y cerrados hasta el cuello; y vestidos de noche, siempre de manga corta y muy escotados.

La moda del siglo XX comienza en el año 1900 con la llamada silueta S, conocida de esta manera debido al corsé que empujaba los pechos hacia arriba, estrechaba la cintura y las faldas ajustadas a la cadera, que ensanchaban en forma de campana al llegar al suelo. En el mundo laboral empiezan a incorporarse los trajes sastre y el corte con influencia masculina para las mujeres. Los vestidos seguían siendo largos, hasta cubrir los zapatos. Las plumas y los encajes hacían furor; destacaron los grandes sombreros, con infinidad de adornos y ornamentos. Esta moda fue seguida mayoritariamente por las clases altas y medias. En 1908, la silueta se hizo mucho más recta, sin marcar tanto la cintura, y se produjo una oleada de orientalismo gracias a los diseños de Paul Poiret y los ballets rusos.

En esta década se distinguen dos periodos. El primero, desde 1905 hasta comienzos de la Primera Guerra Mundial, caracterizado por ser el apéndice de la moda recargada propia de la Belle Époque, así como por la aparición de una silueta que tiende hacia la verticalidad en la mujer y al orientalismo. Se ponen de moda los corsés rectos y largos y las faldas con poco vuelo acompañadas de una sobrefalda, además las faldas de día se acortan hasta los tobillos, dejando a la vista los zapatos. El segundo, a lo largo de todo el conflicto, se caracteriza por la aparición de modas mucho más cómodas para la mujer: las faldas continúan acortándose hasta casi media pantorrilla y los cuerpos siguen la línea natural del cuerpo, sin corsé. Esto se debió a la necesidad de que fueran las mujeres las que supliesen la falta de mano de obra en los puestos de trabajo que antes ocupaban los hombres. A causa de esta comodidad en la vestimenta, nacerá más tarde la moda andrógina propia de los años veinte.

En la década de 1920, la ropa comenzó a tener un fin mucho más práctico. La silueta cambia de nuevo, descendiendo el talle hasta marcarlo en las caderas. Se populariza el traje de chaqueta como ropa de calle y para las fiestas se elegían vestidos con grandes escotes en la espalda así como abrigos largos de pieles. Destacan las faldas cortas hasta la rodilla y los sombreros sobrios y cerrados —cloché—, además, las mujeres se dejan el pelo corto por primera vez.

Durante esta década, las señoras cambiaron su aspecto blanco por la apariencia natural del polvo facial rosado, creado por la cosmetóloga polaca Helena Rubinstein. Los años 1920 fueron uno de los periodos más revolucionarios del siglo XX en este sentido, pues las mujeres adoptaron la costumbre de maquillarse, guardando en el bolso polveras y pintalabios para los retoques. Hasta ese momento, las únicas que llevaban maquillaje eran las artistas y las prostitutas. Las mujeres jóvenes se destaparon y comenzaron a beber y fumar en público como una forma de provocar al rígido estatus que reinaba a principios del siglo.

Las chicas que estaban más a la moda se pintaban los labios de color rojo, lucían el cabello corto y los ojos pintados con sombras oscuras, y solían bailar jazz hasta el amanecer. Esta fue, probablemente, la década más atrevida y transgresora. Fue una época de cambio que afectó a todos los aspectos culturales y repercutió con fuerza en la moda.

El optimismo terminó con el crac de la Bolsa en octubre de 1929, que provocó una grave crisis económica mundial durante los siguientes años. En 1930, la cintura vuelve a marcarse en su lugar natural y las faldas se alargan hasta por debajo de la rodilla. Volvió la feminidad, los adornos en prendas, los sombreritos y el cabello abandona el estilo "garçon" por peinados un poco más largos y con ondas. A partir de 1935 se suelen marcar los hombros, dando a la silueta un aspecto de triángulo invertido.

Durante la Segunda Guerra Mundial, la moda se definió como austera y simple: el "look" se militarizó y los tejidos se volvieron pobres debido a la carestía de materiales. Por consiguiente, las mujeres vestían con uniforme de ciudad, es decir, trajes de chaqueta. El largo de las faldas continuaba por debajo de las rodillas, pero la escasez de materiales era tan grande que se impusieron leyes que reglaban este largo. Dado a su coste, no todas las mujeres podían comprarse medias. Se popularizaron los panties, se usaban los zapatos topolino de corcho y gorritos muy sencillos o simplemente pañuelos en la cabeza.

Los primeros años de la posguerra devolvieron a la mujer al hogar, a las tareas de la casa y a volver a pensar en sí misma. Después de años de angustia, preocupaciones y mucho trabajo, la mujer pudo vivir en la tranquilidad de su hogar, darse pequeños gustos y ser coqueta. El mundo dejaba una etapa atrás y la moda también lo hizo. Desde entonces, la mujer volvió a preocuparse por su belleza, su estética y su vestimenta. Es por ello que la moda de los años 50 destaca por la vuelta del esplendor.

En 1947, tras el triunfo del "new look" de Christian Dior, se popularizó la silueta de reloj de arena: una cintura estrecha con voluminosas curvas. Para exagerar esta silueta, se utilizaban sostenes con forma de cono y corsés ajustados. Se aumentó el vuelo de las faldas, cuyo largo continuaba por debajo de las rodillas. La mujer quería frivolidad y ansiaba ropa femenina que no pareciera una versión civil de los uniformes militares. Deseaba volver a ser sensual, pero sin ser muy provocativa; las curvas se convirtieron así en el nuevo símbolo de la belleza femenina. Debía ir siempre correctamente maquillada, y comenzó a valorarse mucho el uso de accesorios como zapatos de tacón de aguja, guantes, tocados, pamelas, bolsos al codo... Los tejidos más utilizados fueron distintos tipos de seda y tul. El principal objetivo era dar un mayor volumen a las caderas de la mujer y conseguir una cintura de avispa.

Los diseñadores más señalados de esta época fueron Christian Dior, Coco Chanel, Cristóbal Balenciaga, Elsa Chiaparelli, Hubert de Givenchy, Jacques Fath, Nina Ricci y Pierre Cardin.

Esta década destaca por la revolución. Se utilizó de nuevo ropa cómoda y juvenil, siguiendo la línea natural del cuerpo y dejando atrás el lujo burgués. Se abandona el uso habitual de sombreros y guantes de vestir. A partir de 1966, se puso de moda la ropa extravagante, con estampado de mariposas, flores, pop-art o étnico. Las siluetas volvieron a ser más lisas y se comenzaron a imponer rápidamente entre las jóvenes por todo el mundo las revolucionarias minifaldas, cortas hasta el muslo, que nacieron en Londres en 1965 de la mano de la diseñadora Mary Quant.

En 1970, los adolescentes tenían la capacidad de expresarse libremente. Así surgió el concepto de la ropa diferente, original, divertida y extravagante. El cabello se llevaba corto, largo o con cortes geométricos. Tanto los hombres como las mujeres comenzaron a usar pantalones de campana y se impusieron las blusas de algodón, entre otros.

Fue una década muy diversa, en la que se produjo un furor hacia lo retro. Las flores fueron uno de los principales símbolos, no solo en la ropa sino también en el pelo, y representaban la ideología ilusoria que les guiaba a la llamada "revolución de las flores". Resaltaban los trajes y vestidos, que se lucieron con ajustados pantalones. El algodón fue remplazado por la lycra, y usaban botas o zapatos de tacón, tipo suecos.

La moda trajo consigo considerables cambios durante estos años. El nuevo estilo se caracterizaba por el uso de ropa interior visible, ya fuese sobre una camiseta, debajo de una camiseta translúcida o tirantes de encaje visibles. Esta nueva moda fue altamente controvertida, volviéndose un sinónimo de liberación para las mujeres, pues antiguamente usar la ropa interior de esta manera les daba el aspecto de ser una mujer desarreglada. Gracias a esta tendencia, las mujeres actualmente pueden vestir camisetas cómodas sin tener que preocuparse por las transparencias o los tirantes de los corpiños.

Esta época se basó en la variedad y no en una tendencia específica y duradera. Hubo una preferencia por vestir con aquello que les hiciera sentirse más cómodos, sin darle mucha importancia a la opinión de los demás o a las tendencias, porque se había llegado a la conclusión de que no había una verdadera libertad. Las camisetas de grupos musicales se volvieron populares, así como el cabello suelto. Una de las grandes innovaciones de este periodo fue la aparición de los pírsines, tatuajes y tintes de pelo.

A finales del siglo XX y principios del XXI, nace la posibilidad de encargar y enviar prendas de ropa a cualquier parte del mundo gracias a los medios de comunicación o Internet. Por consiguiente, la moda actual parece que se dirige hacia una uniformidad universal.

A lo largo de los años 2000, toma fuerza el concepto de las tribus urbanas. Éstas influyeron directamente en los modos de vestir, principalmente por la creciente exposición a los medios masivos como Internet. Si bien las subculturas ya existen desde los años 1960 y 1970, como Beatnik y Hippies, algunas no adoptan el sentimiento contracultural que dio origen a las mismas, siendo únicamente identificables por su forma de vestir, por ejemplo, la cultura emo. Tanto los hombres como las mujeres adoptan el chándal para casi todo tipo de ocasión. Las mujeres usan "shorts", faldas, minifaldas y pantalones de tiro alto, y se reincorporan algunas prendas de los años 1980, regresando el estampado floreado. En cuanto al calzado, las mujeres usan botas fuertes, zuecos o sandalias.

Los hombres introducen el escote en V junto con pantalones pitillos y zapatillas de marca en su vestuario. Los pantalones claros, aunque por otro lado, los pantalones oscuros aportan una gran elegancia, tanto como las camisas abiertas con camisetas debajo y arremangadas. Las mujeres prefieren moda fresca pero con un toque moderno, poco maquillaje y cabello natural con peinados estructurados, incorporando detalles de la moda de los años 1960. Lo "vintage" tiene una fuerte presencia en el armario femenino. En cambio, en el vestir masculino empieza a crecer una moda alternativa que busca la identidad, en la que influyen las tendencias y gustos propios, dando lugar a un estilo un poco más arriesgado y divertido.

La sociedad de consumo de masas empezó a jugar un papel central en el momento en el que la moda se empezó a entender como la necesidad de marcar una distinción entre cada individuo, de lo cual hablaban Pierre Bourdieu y Jean Baudrillard. La moda forma parte de nuestro contexto como personas, influye en diferentes aspectos de nuestras vidas, desde lo que comemos y bebemos hasta los lugares que debemos frecuentar. Actualmente, el simple hecho de vestir trae consigo factores tan diversos como son la autoestima, la seguridad, la experiencia estética, las prácticas del consumo e imitación o el deseo de la inclusión. Nunca se debe olvidar que todas las modas son peligrosas desde el momento en el que se vuelven extremas.

Los medios de comunicación masiva son y han sido una importante herramienta en el campo de la información y en la difusión de la misma, ya que pueden llegar a cualquier parte del mundo en muy poco tiempo debido al proceso de globalización. Son creadores de una nueva cultura y reorganización global del mercado, generando millones de ingresos a nivel mundial y contando con una influencia tal en la sociedad contemporánea que pocos igualan el poder que se les ha conferido. La moda se encuentra fuertemente ligada a estos medios de comunicación y está controlada por ellos, pues contribuyen a los procesos de socialización.

Vivimos en la era de la comunicación: los medios nos hacen cómplices de información de todo tipo y son los encargados de enseñarnos a modelar las percepciones que tenemos de la realidad. Estos medios bombardean a toda la población, aunque su blanco son principalmente adolescentes y adultos jóvenes, con series, anuncios de televisión, programas, "reality shows," redes sociales como Instagram y Facebook, revistas o música, entre otros. Todo esto nos lleva a un nuevo individualismo multicultural. El impacto de las redes sociales y la tecnología entre los jóvenes, basándose en los conceptos sociológicos de grupo y de relaciones primarias, generan entre los jóvenes una necesidad de identidad.

La moda y el vestir guardan una compleja relación con la identidad: la ropa que elegimos llevar puede ser una forma de expresar quiénes somos, de dar detalles sobre nuestro género, clase o posición, por ejemplo.

La nueva generación de consumidores no recibe con pasividad las historias de las marcas que cuentan las compañías, sino que es creadora conjunta de su significado. Para los vendedores, esto significa que el viejo truco de gritar lo fantástica que es la marca o el uso de ella ya no funciona. Hoy día es crucial escuchar a los jóvenes consumidores y entender cómo acomodan las marcas en su estilo de vida.

En sus encuestas "Talk Track" realizadas a más de 2000 adolescentes en Estados Unidos de entre 13 y 17 años de edad, el grupo Keller Fay encontró que los jóvenes tienen en promedio 145 conversaciones a la semana acerca de marcas.

Por supuesto, cada país o región tiene sus marcas locales preferidas. Topshop domina la industria en Reino Unido, Zara triunfa en España y G-Star en Holanda; pero, en general, es H&M la que logra el mayor éxito a nivel internacional en el mercado de los chicos de la Generación Y.

Se sabe que existe una fuerte compatibilidad entre las emociones, el consumo de moda y el color, sean cuales sean los arraigos culturales o los diferentes tipos de población analizados; es decir, el color muestra correspondencia en cuanto a su significado y está asociado a las emociones. Además, a partir del análisis de las encuestas realizadas en una única región, se demuestra una fuerte tendencia a obedecer las preferencias de color tanto en la toma de decisiones de ingreso en establecimientos de consumo como al evento de la compra en sí; con resultados concluyentes y definitivos en su mayoría, lo que permite inferir que el consumo está afectado por el color y que se puede influenciar al consumidor hasta tal punto de que este desista de consumir un objeto por no encontrar su tonalidad favorita.

El vínculo del color con el consumo de moda no es consistente y genera conflictos con respecto a los significados del color, pero se concluye que a raíz de los efectos del color en las emociones de los individuos, el objeto debe contemplar las tendencias y gamas cromáticas del color desde la perspectiva del diseño para poder dar cobertura a la mayor cantidad de individuos posible.

La moda y las marcas no solo acogen el deseo de imitar a otras personas o a una comunidad determinada, sino de expresar la individualidad; esto es, aunque la indumentaria indica nuestra afiliación a comunidades concretas y expresa valores, ideas y estilos de vida compartidos, no queremos ser «clones» vestidos de forma idéntica a los miembros de esa comunidad. La ropa que elegimos llevar representa un compromiso entre las exigencias del mundo social, el medio al que pertenecemos y nuestros deseos individuales.

Una moda que tenga éxito capta el «estado de ánimo» o el «gusto» que está surgiendo. La moda, como discurso y como práctica, encarna al cuerpo, haciéndolo social e identificable y explica cómo esta construcción del cuerpo a través de la ropa es de considerable importancia para el desarrollo de la sociedad moderna.

A lo largo de la historia, las distintas culturas, ciudades y grupos sociales han utilizado indumentaria perteneciente a la moda como soporte para hacer manifestación pública de su universo particular simbólico, es decir, sus ideologías, credos, cultura emocional, tradiciones, etc.; al igual que como un elemento comunicativo para informar sobre el grupo que la crea. «También los individuos, tomados en términos de identidad personal, perciben que “el vestido habla” y cumple una función socializadora en cuanto a que lo que nos ponemos contribuye al proceso de creación de nuestra imagen, entendida en términos, no de lo que realmente somos, sino de cómo nos perciben los demás.»

Así, la moda se ha convertido en la expresión cultural de gustos, estilos de vida o la identidad personal, en otras palabras, en una metacultura capaz de expandirse con la ayuda de los medios de comunicación social, que mediante la publicidad y "marketing", segmentan el mercado y se dirigen a las masas de forma personalizada; explotando el rol de adquisición y construcción de la personalidad expresada mediante objetos de consumo que se convierten en una extensión de lo que somos, debido al significado que se les otorga en los medios, ya sea heredado, tradicional o emergente. «La moda serviría de eficaz contrapeso para estimular la entidad personal y con ello nuestra condición de personas» Glover, 2017.

Hoy en día, la industria de la moda está siendo puesta en duda por su proceso productivo y su consumo.




</doc>
<doc id="1968" url="https://es.wikipedia.org/wiki?curid=1968" title="Minotauro">
Minotauro

El Minotauro (del griego Μινώταυρος ["Minótauros"]) es un monstruo mitológico de la mitología griega, con cuerpo de hombre y cabeza de toro. Su nombre significa "Toro de Minos", y era hijo de Pasífae y el Toro de Creta. Fue encerrado en un laberinto diseñado por el artesano Dédalo, hecho expresamente para retenerlo, ubicado en la ciudad de Cnosos en la isla de Creta. Durante muchos años, siete hombres y otras siete mujeres eran llevados al laberinto como sacrificio para ser el alimento de la bestia hasta que la vida de este terminó en manos del héroe Teseo. Los catorce jóvenes eran internados en el laberinto, donde vagaban perdidos hasta ser encontrados por el Minotauro. El mito tiene su versión más completa en la "Biblioteca mitológica" de Apolodoro.

Existían varias versiones acerca de la afrenta que ocasionó que la esposa de Minos, Pasífae, tuviese la necesidad de unirse al Toro de Creta sintiendo por él una pasión insensata la cual llevó a su embarazo. La versión más extendida dice que Minos, hijo de Zeus, pidió apoyo al dios Poseidón para que su gente lo aclamara como un temprano rey, ya que su padre Asterión era el antiguo rey ya difunto de Creta. Poseidón lo escuchó e hizo salir de los mares un hermoso toro blanco, al cual Minos prometió sacrificar en su nombre. Sin embargo, al quedar Minos maravillado por las cualidades del hermoso toro blanco, lo ocultó entre su rebaño y sacrificó a otro toro en su lugar esperando que el dios del océano no se diera cuenta del cambio. Al saber esto Poseidón, se llenó de ira, y para vengarse, inspiró en Pasífae un deseo tan insólito como incontenible por el hermoso toro blanco que Minos guardó para sí.

Para consumar su unión con el toro, Pasífae requirió la ayuda de Dédalo, que construyó una vaca de madera recubierta con piel de vaca auténtica para que ella se metiera. El toro yació con ella, creyendo que era una vaca de verdad. De esta unión nació el Minotauro.

El Minotauro solo comía carne humana, y conforme crecía se volvía más salvaje. Cuando el monstruo se hizo incontrolable, Dédalo construyó el laberinto de Creta, una estructura gigantesca compuesta por cantidades incontables de pasillos que iban en distintas direcciones, entrecruzándose entre sí, de los cuales solo uno conducía al centro de la estructura, donde el Minotauro fue abandonado.

A la par que el laberinto encerraba al Minotauro, uno de los hijos de Minos, Androgeo, fue asesinado en Atenas después de una competición olímpica donde quedó campeón. El rey de Creta declaró la guerra a los atenienses. Minos atacó el territorio ateniense y, ayudado por la peste que azotó a los asediados, conquistó Megara e hizo rendir a Atenas. La victoria de Minos imponía varias condiciones por la rendición, y se dice que el oráculo de Delfos fue quien aconsejó a los atenienses ofrecer un tributo a Creta. Así, una de las condiciones emergentes era entregar siete efebos y siete doncellas como sacrificio para el Minotauro. Existen varias versiones conocidas acerca de la frecuencia de este tributo: cada año, cada tres años o cada nueve años. Los catorce jóvenes eran internados en el laberinto, donde vagaban perdidos durante días hasta encontrarse con el Minotauro, sirviéndole de alimento.

Años después de impuesto el castigo a los atenienses, Teseo, hijo de Egeo, se dispuso a matar al Minotauro y así liberar a su patria de Minos y su condena. Se cuentan dos cosas acerca de cómo llegó Teseo a introducirse en el laberinto de Creta. Unos dicen que después de ayudar a Egeo contra los Palántidas, Teseo se enteró del sacrificio de los jóvenes y decidió él mismo ser parte de la ofrenda para enfrentarse a la bestia. Otra narración dice que era el propio Minos quien elegía a los jóvenes que servirían de alimento al Minotauro, y, enterado del aprecio que sentía Egeo por Teseo, quiso que este fuera devorado en el laberinto. Era la tercera vez que catorce jóvenes atenienses, siete efebos y siete doncellas, iban a ser sacrificados en favor del monstruo, cuando Teseo llegó a Creta, 18 años después de iniciado el terror del Minotauro.

Al llegar a Creta, los jóvenes fueron presentados a Minos. Teseo conoció entonces a Ariadna, hija del rey, quien se enamoró de él. La princesa rogó a Teseo que se abstuviera de luchar contra el Minotauro, pues eso le llevaría a una muerte segura, pero Teseo la convenció de que él podía vencerlo. Ariadna, viendo la valentía del joven, se dispuso a ayudarlo, e ideó un plan que ayudaría a Teseo a encontrar la salida del laberinto en caso de que derrotara a la bestia. En realidad ese plan fue solicitado por parte de Ariadna a Dédalo, quien se las había ingeniado para construir el laberinto de tal manera que la única salida fuera usar un ovillo de hilo, el cual Ariadna le entregó a Teseo para que, una vez que hubiera ingresado en el laberinto, atara un cabo del ovillo a la entrada. Así, a medida que penetrara en el laberinto el hilo recordaría el camino y, una vez que hubiera matado al Minotauro, lo enrollaría y encontraría la salida.

Teseo recorrió el laberinto hasta que se encontró con el Minotauro, lo mató y para salir de él, siguió de vuelta el hilo que Ariadna le había dado.

Las historias no concuerdan siempre entre sí en cómo pasó lo anterior. No está claro, por ejemplo, qué relación había entre Teseo y Ariadna. Lo cierto es que ambos confabularon contra Minos para terminar con la vida del Minotauro, que tenía encerrado en el laberinto y escapar de Creta. Pudo haber sido solo el amor que se tenían, o el que ella sentía por Teseo, o simplemente que Teseo le había prometido a Ariadna sacarla de Creta y llevarla consigo. Del mismo modo hay versiones y múltiples representaciones que explican que Teseo dio muerte al Minotauro no usando sus manos desnudas, sino con ayuda de una espada que le proporcionaría secretamente Ariadna junto con el ovillo antes de entrar al laberinto. Según esto, Ariadna había sido aconsejada por Dédalo, el constructor del laberinto. Sin embargo, otras fuentes indican que Teseo mató al Minotauro a puñetazos, mientras otras fuentes dicen que Teseo mató al Minotauro clavándole su propio cuerno. No hay unanimidad ni siquiera en cómo fue que Teseo logró salir del laberinto, aunque la forma más generalizada es por medio del hilo de Ariadna (que ha inspirado la figura retórica del mismo nombre), pero otras historias dicen que Teseo logró escapar gracias a la luz de la corona de oro que obtuvo de Anfitrite en una aventura en el mar, la cual lo guio en el laberinto."

Carlo Lapucci ha señalado la relación del mito del Minotauro con cuentos como "La bella y la bestia".

También este mito ha sido interpretado como la sumisión que existió de la Grecia continental a la civilización cretense durante el Periodo Minoico. 

Jorge Luis Borges elaboró una recreación poética del mito en su cuento «La casa de Asterión». También este mismo autor tiene un poema que describe esta misma historia titulado «El hilo de la fábula».

A su vez, Julio Cortázar escribió su obra de teatro «Los Reyes» creando una nueva versión de este mismo mito. En ella, el minotauro es un ser benevolente y es Teseo quien, despojado de toda humanidad, acaba con él.

Como una de las figuras fantásticas más conocidas, el Minotauro forma parte de una gran cantidad de universos de ficción en la literatura, los juegos y el entretenimiento contemporáneo en general. Aparece sobre todo en los distintos juegos de rol y mundos del género épico










</doc>
<doc id="1973" url="https://es.wikipedia.org/wiki?curid=1973" title="Nupedia">
Nupedia

Nupedia fue una enciclopedia en línea cuyos artículos fueron escritos por expertos y registrados bajo licencia de contenido libre. Fue fundada por Jimmy Wales y suscrita por Bomis, con Larry Sanger como redactor jefe. Nupedia duró desde marzo de 2000 hasta septiembre de 2003, y es más comúnmente conocida ahora como la antecesora de Wikipedia.

Nupedia no era una wiki, es decir, no era públicamente editable. Estaba caracterizada por un proceso de revisión por pares extensivo y diseñada para hacer que sus artículos fuesen de una calidad comparable a las de enciclopedias profesionales. Nupedia quería académicos que ofrecieran contenidos voluntaria y gratuitamente. 

«En un año y con 120 000 dólares invertidos en el proyecto, Nupedia solo había publicado 24 artículos y Jimmy Wales decidió descartar el proyecto». Antes de que terminara de operar, Nupedia produjo 25 artículos que completaron el sistema de revisión. Tenía también 74 artículos que estaban aún en construcción.

"Nupedia" fue siempre una enciclopedia de contenido libre. Inicialmente el proyecto usaba su propia licencia, la Nupedia Open Content License. En enero de 2001, "Nupedia" cambió su licencia a la licencia de documentación libre de GNU, a pedido de Richard Stallman y la Free Software Foundation. Sin embargo, Stallman también empezó la GNUPedia al mismo tiempo, lo cual condujo a preocupaciones sobre posible competencia entre los proyectos. Un problema para los participantes de GNUPedia era que, a pesar de los usos de Nupedia de un contenido libre, el prolongado proceso de revisión por pares iba en contra de la cultura y filosofía del movimiento del software libre. 

Durante este mismo periodo, empezó Wikipedia como un proyecto paralelo para permitir colaboración en artículos antes de entrar en el proceso de revisión por pares. Esto atrajo interés por ambos lados, pues proveía una estructura menos burocrática, preferida por los simpatizantes de GNUPedia. Como resultado, nunca se desarrolló realmente y la amenaza de competencia entre los proyectos quedó anulada. Como Wikipedia creció y atrajo colaboradores, rápidamente desarrolló una vida propia y comenzó a funcionar mayormente con independencia de Nupedia, aunque Sanger inicialmente dirigió la actividad en Wikipedia por su posición como redactor jefe de Nupedia. 

Aparte de conducir a la interrupción del proyecto Nupedia, Wikipedia también condujo al fracaso gradual de Nupedia. Debido al colapso de la economía de internet en esos tiempos, Jimmy Wales decidió interrumpir la financiación para un redactor jefe pagado en diciembre de 2000, y un tiempo después Sanger renunció a su cargo en ambos proyectos. Mientras que Nupedia se acercaba a la inactividad, la idea de convertirlo en una versión estable de Wikipedia ocasionalmente rebrotó, pero nunca fue implementada, y Nupedia se cerró en 2003.

Los requisitos exigidos para ser editor de Nupedia eran relativamente altos. La política establecía "Deseamos que los editores sean verdaderos expertos en sus áreas y (con pocas excepciones), que posean doctorados". Sin embargo, los revisores que evaluaban redacciones en un artículo generalmente no tendrían experticia especial en la materia del artículo. Los revisores eran identificados por seudónimos, y aunque había una facilidad que permitía a los revisores postear sus biografías, muchos no lo hicieron. Entonces, el experto que escribía el artículo estaba a menudo obligado a modificarlo basado en comentarios de revisores efectivamente anónimos, sin manera de conocer sus grados de calificación en la materia. El proceso era también diferente del de Wikipedia porque se esperaba que los revisores dieran críticas, pero no que estos hicieran ediciones en los artículos. El número de participantes en Nupedia no era suficiente para dialogar entre gente con conocimiento de la materia del artículo.

Nupedia funcionaba con el software colaborativo NupeCode, software libre lanzado bajo la licencia pública GNU diseñado para grandes proyectos de revisión por pares. El código estaba disponible vía repositorio CVS de Nupedia. 

Uno de los problemas experimentados por Nupedia durante mucha de su existencia fue la falta de software funcional. Como medida a la falta de software funcional se utilizaron bloques de texto subrayados que parecían ser hiperenlaces para indicar los artículos. 

Como parte del proyecto, una nueva versión del software original, llamada NuNupedia, estaba bajo desarrollo. NuNupedia fue implementado para propósitos de prueba en SourceForge, pero nunca alcanzó suficiente desarrollo para reemplazar al software original.




</doc>
<doc id="1975" url="https://es.wikipedia.org/wiki?curid=1975" title="Nebulosa">
Nebulosa

Las nebulosas son regiones del medio interestelar constituidas por gases (principalmente hidrógeno y helio) además de elementos químicos en forma de polvo cósmico. Tienen una importancia cosmológica notable porque muchas de ellas son los lugares donde nacen las estrellas por fenómenos de condensación y agregación de la materia; en otras ocasiones se trata de los restos de estrellas ya extintas o en extinción.

Las nebulosas asociadas con estrellas jóvenes se localizan en los discos de las galaxias espirales y en cualquier zona de las galaxias irregulares, pero no se suelen encontrar en galaxias elípticas puesto que estas apenas poseen fenómenos de formación estelar y están dominadas por estrellas muy viejas. El caso extremo de una galaxia en la que muchas nebulosas presentan intensos episodios de formación estelar se denomina galaxia starburst.

Antes de la invención del telescopio, el término «nebulosa» se aplicaba a todos los objetos celestes de apariencia difusa. Por esta razón, a veces las galaxias (conjunto de miles de millones de estrellas, gas y polvo unidos por la gravedad) son llamadas indebidamente nebulosas; se trata de una herencia de la astronomía del siglo XIX que ha dejado su signo en el lenguaje astronómico contemporáneo.

Las nebulosas se pueden clasificar en tres grandes categorías según la naturaleza de su emisión (o falta de ella).

Una nebulosa oscura (también llamada nebulosa de absorción o de inspiración), es una acumulación de gas o polvo interestelar no relacionado con ninguna estrella o alejado de estas, de tal forma que no es perturbada por su energía, por lo que su presencia solo puede ser advertida por contraste con un fondo estelar poblado o una nebulosa de emisión más alejados.

En este caso la nebulosa no emite ni refleja ninguna luz por estar lejos de las estrellas, pero sí absorbe la luz de objetos que están detrás de ella. Por lo tanto, su existencia se deduce por la presencia de una región oscura que destaca sobre el fondo de cielo estrellado. Un ejemplo típico es la denominada Saco de Carbón en la constelación de la Cruz del Sur, y también es muy famosa la nebulosa Cabeza de Caballo, en la constelación de Orión. Numerosas nebulosas oscuras pueden asimismo observarse por sobre la franja brillante de la Vía Láctea que atraviesa el cielo.

Estas nebulosas reflejan la luz de estrellas cercanas que no son lo suficientemente calientes como para emitir la radiación ultravioleta necesaria para excitar el gas de la nebulosa. Generalmente, estas nebulosas están formadas por los residuos del gas que dio origen a la estrella, y su espectro es similar al de las estrellas cuya luz reflejan. El caso más representativo es la nebulosa en torno de la estrella Mérope en el cúmulo abierto de las Pléyades (M45).

En este caso, el más común, el gas que compone la nebulosa brilla como consecuencia de la transformación que sufre por la intensa radiación ultravioleta de estrellas vecinas calientes. En Astrofísica estos objetos se denominan Regiones H II y son fundamentales a la hora de analizar la composición química y las propiedades físicas de las nebulosas (y de las galaxias en las que se encuentran) gracias al análisis de su espectro, compuesto por multitud de líneas de emisión de los elementos químicos que albergan. La línea de emisión más brillante e importante es H-alfa (de la Serie de Balmer del hidrógeno), localizada en la zona roja del espectro (a 6562,82 Å), siendo este el motivo por el que dicho color domine en las imágenes tradicionales de nebulosas de emisión. Pero también se detectan líneas de emisión de helio, oxígeno, nitrógeno, azufre, neón o hierro. Dependiendo de la naturaleza de la nebulosa de emisión, se subdividen en dos grupos totalmente distintos.

1) Las nebulosas de emisión asociadas a regiones de formación estelar, es decir, en presencia de estrellas muy jóvenes, masivas y calientes, incluso en proceso de formación (plópidos y objetos Herbig-Haro) y a nubes moleculares. El caso más famoso es la Nebulosa de Orión (M42), la más cercana a la Tierra, pero otros ejemplos destacables son la Nebulosa del Águila (M16, en la Constelación de la Serpiente), la Nebulosa Trífida (M20, en Sagitario) o la Nebulosa de la Laguna (M8, también en Sagitario).

2) Las nebulosas de emisión asociadas a estrellas moribundas o ya extintas se denominan nebulosas planetarias y restos de supernova. Las primeras no tienen nada que ver con los planetas: son las envolturas de estrellas de masa baja o intermedia expulsadas al espacio al final de sus ciclos evolutivos. En ellas, el gas es excitado por un objeto muy pequeño y caliente, una enana blanca, que es el núcleo expuesto de la estrella muerta. Ejemplos conocidos de este tipo de nebulosa son la Nebulosa del Anillo (M57, en la Lira) y la Nebulosa de la Hélice (NGC 7293, en Acuario). 

El resto (o «remanente») de supernova es el material liberado en la titánica explosión que pone fin a las estrellas masivas. El gas de este tipo de nebulosas puede ser afectado tanto por la propia energía entregada por la supernova, como por la emisión de una posible estrella de neutrones (un púlsar) en su seno. Tal vez el ejemplo más famoso de resto de supernova sea la Nebulosa del Cangrejo (M1, en la constelación de Tauro).




</doc>
<doc id="1976" url="https://es.wikipedia.org/wiki?curid=1976" title="Neutrón">
Neutrón

El neutrón es una partícula subatómica, un nucleón, sin carga neta, presente en el núcleo atómico de prácticamente todos los átomos, excepto el protio. Aunque se dice que el neutrón no tiene carga, en realidad está compuesto por tres partículas fundamentales cargadas llamadas quarks, cuyas cargas sumadas son cero. Por tanto, el neutrón es un barión neutro compuesto por dos quarks de tipo "abajo", y un quark de tipo "arriba".

Fuera del núcleo atómico, los neutrones son inestables, teniendo una vida media de 14.7 minutos (879,4 ± 0,6 s); cada neutrón libre se descompone en un electrón, un antineutrino electrónico y un protón. Su masa es muy similar a la del protón, aunque ligeramente mayor.

El neutrón es necesario para la estabilidad de casi todos los núcleos atómicos, a excepción del isótopo hidrógeno-1. La interacción nuclear fuerte es responsable de mantenerlos estables en los núcleos atómicos.

Fue predicho teóricamente en 1920 por Ernest Rutherford, recibió el nombre de "neutrón" de William Draper Harkins en 1921 y fue después propuesto por Santiago Antúnez de Mayolo en 1924 y en 1932 fue descubierto y documentado por James Chadwick. Se localiza en el núcleo del átomo. Antes de ser descubierto el neutrón, se creía que un núcleo de número de masa A (es decir, de masa casi A veces la del protón) y carga Z veces la del protón, estaba formada por A protones y A-Z electrones. Pero existen varias razones por las que un núcleo no puede contener electrones. Un electrón solamente podría encerrarse en un espacio de las dimensiones de un núcleo atómico (10 cm) si fuese atraído por el núcleo una fuerza electromagnética muy fuerte e intensa; sin embargo, un campo electromagnético tan potente no puede existir en el núcleo porque llevaría a la producción espontánea de pares de electrones negativos y positivos (positrones). Por otra parte, existe incompatibilidad entre los valores del espín de los núcleos encontrados experimentalmente y los que podrían deducirse de una teoría que los supusiera formados por electrones y protones; en cambio, los datos experimentales están en perfecto acuerdo con las previsiones teóricas deducidas de la hipótesis de que el núcleo consta solo de neutrones y protones.

Ernest Rutherford propuso por primera vez la existencia del neutrón en 1920, para tratar de explicar que los núcleos no se desintegrasen por la repulsión electromagnética de los protones.

En el año 1909, en Alemania, Walther Bothe y H. Becker descubrieron que si las partículas alfa del polonio, dotadas de una gran energía, caían sobre materiales livianos, específicamente berilio, boro o litio, se producía una radiación particularmente penetrante. En un primer momento se pensó que eran rayos gamma, aunque estos eran más penetrantes que todos los rayos gamma hasta ese entonces conocidos, y los detalles de los resultados experimentales eran difíciles de interpretar sobre estas bases.

En 1924, el físico Louis de Broglie presentó la existencia de un elemento neutro en la Academia de Ciencias de París.

Ese mismo año, el peruano Santiago Antúnez de Mayolo, durante el III Congreso Científico Panamericano, presenta la ponencia "Hipótesis sobre la constitución de la materia", en la que predijo la existencia de un elemento neutro dentro del átomo. Cabe resaltar al respecto, que en la actualidad en ninguna obra especializada sobre el neutrón se menciona la predicción de Antúnez de Mayolo, ni siquiera en "Historia del Neutrón" de Donald J. Hughes.

En 1930, Viktor Ambartsumian y Dmitri Ivanenko, en la URSS, encontraron que, contrariamente a la opinión dominante de la época, el núcleo no puede consistir en protones y electrones. Se comprobó que algunas partículas neutras deben estar presentes además de los protones.

En 1932, en París, Irène Joliot-Curie y Frédéric Joliot mostraron que esta radiación desconocida, al golpear parafina u otros compuestos que contenían hidrógeno, producía protones a una alta energía. Eso no era inconsistente con la suposición de que eran rayos gamma de la radiación, pero un detallado análisis cuantitativo de los datos hizo difícil conciliar la ya mencionada hipótesis.

Finalmente (a finales de 1932) el físico inglés James Chadwick, en Inglaterra, realizó una serie de experimentos de los que obtuvo unos resultados que no concordaban con los que predecían las fórmulas físicas: la energía producida por la radiación era muy superior y en los choques no se conservaba el momento. Para explicar tales resultados, era necesario optar por una de las siguientes hipótesis: o bien se aceptaba la no conservación del momento en las colisiones o se afirmaba la naturaleza corpuscular de la radiación. Como la primera hipótesis contradecía las leyes de la Física, se prefirió la segunda. Con ésta, los resultados obtenidos quedaban explicados pero era necesario aceptar que las partículas que formaban la radiación no tenían carga eléctrica. Tales partículas tenían una masa muy semejante a la del protón, pero sin carga eléctrica, por lo que se pensó que eran el resultado de la unión de un protón y un electrón formando una especie de dipolo eléctrico. Posteriores experimentos descartaron la idea del dipolo y se conoció la naturaleza de los neutrones.

El neutrón es una partícula eléctricamente neutra, de masa 1838,5 veces mayor que la del electrón y 1,00137 veces la del protón; juntamente con los protones, los neutrones son los constitutivos fundamentales del núcleo atómico y se les considera como dos formas de una misma partícula: el nucleón.

El número de neutrones en un núcleo estable es constante, pero un neutrón libre, es decir, fuera del núcleo, se desintegra con una vida media de unos 879,4 segundos según el PDG 2019 (hay que notar que hay discrepancia entre dos técnicas distintas para determinar la vida media y se toma un promedio de varias medidas);, dando lugar a un protón, un electrón y un antineutrino electrónico. En un núcleo estable, por el contrario, el electrón emitido no tiene la energía suficiente para vencer la atracción coulombiana del núcleo y los neutrones no se desintegran. La fuente de neutrones de mayor intensidad disponible hoy día es el reactor nuclear. El neutrón tiene carga neutra.

El proceso fundamental que conduce a la producción de energía nuclear es la fisión de un núcleo de uranio originado por un neutrón: en la fisión el núcleo se escinde en dos partes y alrededor de tres neutrones por término medio (neutrones rápidos); los fragmentos resultantes de la escisión emiten, además, otros neutrones.

Los neutrones son fundamentales en las reacciones nucleares: una reacción en cadena se produce cuando un neutrón causa la fisión de un átomo fisible, produciéndose un mayor número de neutrones que causan a su vez otras fisiones. Según esta reacción se produzca de forma controlada o incontrolada, se tiene lo siguiente:

Jimmy Neutrón, el protagonista de la película "" (2001) y de la serie "" (2002-2006) ambas producidas por el canal Nickelodeon en conjunto con DNA Productions, tiene ese apellido en referencia a los neutrones. El símbolo en su camiseta es un átomo.



</doc>
<doc id="1977" url="https://es.wikipedia.org/wiki?curid=1977" title="Número entero">
Número entero

Un número entero es un elemento del conjunto numérico que contiene los números naturales; que son formula_1 o formula_2; dependiendo de cómo se definan, sus opuestos, y en la segunda definición, además el cero. Los enteros negativos, como −1 o −3 (se leen «menos uno», «menos tres», etc.), son menores que cero y todos los enteros positivos. Para resaltar la diferencia entre positivos y negativos, se puede escribir un signo «menos » delante de los negativos : -1, -5, etc. Y si no se escribe signo al número se asume que es positivo.

El conjunto de todos los números enteros se representa por la letra formula_3 letra inicial del vocablo alemán "Zahlen" («números», pronunciado ).

En la recta numérica los números negativos se encuentran a la izquierda del cero y los positivos a su derecha.

Los números enteros pueden sumarse, restarse, multiplicarse y dividirse, siguiendo el modelo de los números naturales añadiendo unas normas para el uso del signo.

Los números enteros extienden la utilidad de los números naturales para contar cosas. Pueden utilizarse para contabilizar pérdidas: si en un colegio entran 80 alumnos nuevos de primer curso un cierto año, pero hay 100 alumnos de último curso que pasaron a educación secundaria, en total habrá 100 − 80 = 20 alumnos menos; pero también puede decirse que dicho número ha aumentado en 80 − 100 = −20 alumnos.

Ciertas magnitudes como la temperatura o la altura usan valores por debajo del cero. La altura del Everest es 8848 metros por encima del nivel del mar, y por el contrario, la orilla del mar Muerto está 423 metros por debajo del nivel del mar; es decir, su altura se puede expresar como −423 m.

Los números negativos son necesarios para realizar operaciones como:
Cuando el minuendo es más pequeño que el sustraendo, la resta no puede realizarse con números naturales. Sin embargo, hay situaciones en las que es útil el concepto de números negativos, como por ejemplo al hablar de ganancias y pérdidas:

Ejemplo: Un hombre juega a la ruleta dos días seguidos. Si el primero gana 2000 pesos y al día siguiente pierde 1000, el hombre "ganó en total" 2000 − 1000 = $ 1000. Sin embargo, si el primer día gana 500 y al siguiente pierde 2000, se dice que "perdió en total" 2000 − 500 = $ 1500. La expresión usada cambia en cada caso: "ganó en total" o "perdió en total", dependiendo de si las ganancias fueron mayores que las pérdidas o viceversa. Estas dos posibilidades se pueden expresar utilizando el signo de los números negativos (o positivos): en el primer caso ganó en total 2000 − 1000 = + $ 1000 y en el segundo ganó en total 500 − 2000 = − $ 1500. Así, se entiende que una pérdida es una "ganancia negativa".

Los números naturales 1, 2, 3... son los números ordinarios que se utilizan para contar. Al añadirles un signo "menos" («−») delante se obtienen los números negativos:

Además, para distinguirlos mejor, a los números naturales se les añade un signo "más" («+») delante y se les llama números positivos.

El cero no es positivo ni negativo, y puede escribirse con signo "más" o "menos" o sin signo indistintamente, ya que sumar o restar cero es igual a no hacer nada. Toda esta colección de números son los llamados «enteros».
Los números enteros negativos son menores que todos los positivos y que el cero. Es decir, todo número que se encuentra ubicado a la derecha es mayor que el número que se encuentra ubicado a la izquierda. Para entender como están ordenados se utiliza la recta numérica:

Se ve con esta representación que los números negativos son más pequeños cuanto más a la izquierda, es decir, cuanto mayor es el número tras el signo. A este número se le llama el valor absoluto:

Ejemplos. = 5 , = 2 , = 0.

El orden de los números enteros puede resumirse en:

Ejemplos. +23 > −56 , +31 < +47 , −15 < −9 , 0 > −36

Los números enteros pueden sumarse, restarse, multiplicarse y dividirse, igual que puede hacerse con los números naturales.

En la suma de dos números enteros, se determina por separado el signo y el valor absoluto del resultado.

Ejemplos. (+21) + (−13) = +8 , (+17) + (+26) = +43 , (−41) + (+19) = −22 , (−33) + (−28) = −61

La suma de números enteros se comporta de manera similar a la suma de números naturales:
Ejemplo.

Además, la suma de números enteros posee una propiedad adicional que no tienen los números naturales:
La resta de números enteros es muy sencilla, ya que ahora es un caso particular de la suma.

Ejemplos
(+10) − (−5) = (+10) + (+5) = +15 (−7) − (+6) = (−7) + (−6) = −13 (−4) − (−8) = (−4) + (+8) = + 4(+2) − (+9) = (+2) + (−9) = −7

La multiplicación y división de números enteros, al igual que la suma, requiere determinar por separado el signo y valor absoluto del resultado.

Para recordar el signo del resultado, también se utiliza la regla de los signos:

Ejemplos multiplicación. (+5) × (+3) = +15 , (+4) × (-6) = -24 , (−7) × (+8) = −56 , (−9) × (−2) = +18.

Ejemplos división. (+15) : (+3) = +5 , (+12) : (-6) = -2 , (−16) : (+4) = −4 , (−18) : (−2) = +9.
La multiplicación de números enteros tiene también propiedades similares a la de números naturales:

Ejemplo.


La suma y multiplicación de números enteros están relacionadas, al igual que los números naturales, por la propiedad distributiva:
Ejemplo.
La división de números enteros no tiene las propiedades asociativa, conmutativa ni la distributiva.




</doc>
<doc id="1979" url="https://es.wikipedia.org/wiki?curid=1979" title="Nucleón">
Nucleón

En física nuclear, un nucleón corresponde al nombre colectivo para dos partículas: el neutrón y el protón (ambas formadas por quarks de primera generación, los más ligeros). Los nucleones son dos de los constituyentes del núcleo atómico, que también contendría piones portadores de la interacción que mantiene unidos a los nucleones. Hasta los años 60, los nucleones fueron considerados partículas elementales; posteriormente se postuló que podrían estar formados por quarks, y la evidencia sólida de que estaban formados por constituyentes discernibles apareció en la década de los 70. Actualmente se sabe que son partículas compuestas, cada una formada por tres quarks unidos mediante la fuerza fuerte transmitida por gluones. La masa de los nucleones está asociada tanto a las propias masas de los quarks como al campo de gluones.

Existe un tipo interacción no-electromagnética entre un nucleón y un leptón que conlleva la transformación de un neutrón en un protón (o vicersa); es conocida como decaimiento débil o desintegración beta. Esta desintegración está asociada a la fuerza nuclear débil. Tanto el protón como el neutrón son parte de los bariones y, por tanto, se comportan como fermiones. La posibilidad de los nucleones de transformarse el uno en el otro está asociada a que en la terminología de la física de partículas, estas dos partículas poseen un isospín doblete 1/2. Esto explicaría por qué sus masas son tan similares, con el neutrón siendo sólo un 0,1% más pesado que el protón.

Se podría decir que los nucleones se encuentran en la línea donde la física de partículas y la física nuclear se entremezclan. La teoría cuántica de campos, en particular la cromodinámica cuántica, provee de las ecuaciones fundamentales que explican las propiedades de los quarks y de la fuerza nuclear fuerte. Estas ecuaciones explican cuantitativamente cómo los quarks se unen entre sí para formar protones y neutrones (y todos los demás hadrones). Sin embargo, cuando varios nucleones se unen para formar un núcleo atómico (nucleido), estas ecuaciones fundamentales se vuelven muy difíciles de resolver (ver retículo QCD). En vez de eso, los nucleidos son estudiados por la física nuclear, que analizan los nucleones y sus interacciones mediante modelos y aproximaciones, tales como el modelo de capas nuclear. Estos modelos pueden explicar satisfactoriamente propiedades de los nucleidos, como por ejemplo, cuándo un cierto nucleido sufrirá un decaimiento radiactivo.

Los protones y neutrones son más conocidos por constituir el núcleo atómico, pero también pueden existir de manera aislada, sin ser parte de núcleos más grandes, aunque existe una diferencia importante: los protones son estables o altamente estables mientras que los neutrones aislados se desintegran mediante desintegración beta siendo su vida media de 15 minutos en estado aislado. Dentro del núcleo el intercambio de piones de carga negativa generalmente estabiliza a los neutrones. Un protón por sí solo corresponde al núcleo del átomo de hidrógeno-1 (H). Un neutrón por sí solo es inestable como se ha dicho (ver más abajo), pero se le puede encontrar en reacciones nucleares y también son usados en análisis científico (ver dispersión de neutrones).

Tanto el protón como el neutrón están constituidos por tres quarks. El protón está conformado por dos quarks up y un quark down, mientras que el neutrón en un quark up y dos quarks down. Los quarks se mantienen unidos mediante la fuerza nuclear fuerte. También se dice que los quarks se mantienen unidos por medio de gluones, en tanto que los gluones son los mediadores de la fuerza nuclar fuerte.

El quark up tiene una carga eléctrica +2/3 e, y el quark down tiene carga −1/3 e. Entonces las cargas eléctricas totales del protón y del neutrón son: +e y 0, respectivamente. La palabra "neutrón" viene del hecho de ser eléctricamente «neutro».

Las masas del protón y del neutrón son muy similares: la del protón es 1.6726 u o 938.27 MeV/c, mientras que la del neutrón es 1.6749 u ó 939.57 MeV/c, lo que significa que el neutrón es prácticamente un 0.1 % más pesado. La similitud de masas es explicada por la simetría aproximada del isospin.

Tanto protones como neutrones tienen un momento angular intrínseco o espín de 1/2. Esto significa que son fermiones y no bosones, y por lo tanto, como los electrones, están sujetos al principio de exclusión de Pauli. Esto es un hecho importante en la física nuclear: los protones y neutrones de un núcleo atómico no pueden estar en un mismo estado cuántico, por lo que se distribuyen en una serie de capas nucleares análogas a las de los electrones en el modelo atómico. Otra razón por la que el spín de los protones y neutrones es importantes es que de su suma se desprende el spin nuclear. Este es más conocido por su papel crucial en la técnica de la resonancia magnética nuclear, utilizada en los análisis químicos y biológicos.

El reconocimiento del núcleo atómico se debió a lo evidenciado por el experimento de Rutherford de 1919. Por esa época se entendió que el núcleo atómico contenía las cargas positivas. Previamente ya se habían observado protones aislados por Oracio Golden en 1886, aunque en esa época no se conocía el núcleo atómico y por tanto el mismo concepto de nucleón era inexistente. El conocimiento que se tenía del átomo de hidrógeno ionizado junto con el experimento de Rutherford llevó a éste a postular que el núcleo atómico debía contener los protones. El descubrimiento del neutrón fue más tardío y se debió a James Chadwick en 1932.



</doc>
<doc id="1980" url="https://es.wikipedia.org/wiki?curid=1980" title="Número atómico">
Número atómico

En física y química, el número atómico de un elemento químico es el número total de protones que tiene cada átomo de ese elemento. Se suele representar con la letra Z.

Los átomos de diferentes elementos tienen distintos números de electrones y protones. Un átomo en su estado natural es neutro y tiene un número igual de electrones y protones. Un átomo de sodio (Na) tiene un número atómico de 11; posee 11 electrones y 11 protones. Un átomo de magnesio (Mg), tiene número atómico de 12, posee 12 electrones, 12 protones y un átomo de uranio (U), que tiene número atómico de 92, posee 92 electrones y 92 protones.

Se coloca como subíndice a la izquierda del símbolo del elemento correspondiente. Por ejemplo, todos los átomos del elemento hidrógeno tienen 1 protón y su Z = 1; esto sería ₁H. Los de helio tienen 2 protones y Z = 2; asimismo, ₂He. Los de litio, 3 protones y Z = 3…,

Si el átomo es neutro, el número de electrones coincide con el de protones y da Z.

En 1913 Henry Moseley demostró la regularidad existente entre los valores de las longitudes de onda de los rayos X emitidos por diferentes metales tras ser bombardeados con electrones, y los números atómicos de estos elementos metálicos. Este hecho permitió clasificar los elementos en la tabla periódica en orden creciente de número atómico. En la tabla periódica los elementos se ordenan de acuerdo con sus números atómicos en orden creciente.

El símbolo convencional ""Z"" posiblemente proviene de la palabra alemana "Atomzahl" (número atómico). Antes de 1915, la palabra "Zahl" (simplemente "número") era usada para el número asociado a cada elemento en la tabla periódica.

Relación de elementos por orden alfabético con sus números atómicos:
Tabla periódica con la relación de elementos químicos (del 1 al 118) y sus correspondientes números atómicos:


</doc>
<doc id="1981" url="https://es.wikipedia.org/wiki?curid=1981" title="Novela">
Novela

La novela (del italiano "novella") es una obra literaria en la que se narra una acción fingida en todo o en parte y cuyo fin es causar placer estético a los lectores con la descripción o pintura de sucesos o lances interesantes así como de personajes, pasiones y costumbres, que en muchos casos sirven de insumos para la propia reflexión o introspección. La vigesimotercera edición del "Diccionario de la lengua española" de la Real Academia Española la define de manera más general como una «obra literaria narrativa de cierta extensión» y como un «género literario narrativo que, con precedente en la Antigüedad grecolatina, se desarrolla a partir de la Edad Moderna». La novela se distingue por su carácter abierto y su capacidad para contener elementos diversos en un relato complejo. Este carácter abierto ofrece al autor una gran libertad para integrar personajes, introducir historias cruzadas o subordinadas unas a otras, presentar hechos en un orden distinto a aquel en el que se produjeron o incluir en el relato textos de distinta naturaleza: cartas, documentos administrativos, leyendas, poemas, etc. Todo ello da a la novela mayor complejidad que la que presentan los demás subgéneros narrativos.

Las características que permiten diferenciar una novela de otro género literario son las siguientes:


Aquí radica la diferencia con el cuento y el relato. Existe una zona difusa entre cuento y novela que no es posible separar en forma tajante. A veces se utiliza el término "nouvelle" o "novela corta" para designar los textos que parecen demasiado cortos para ser "novela" y demasiado largos para ser "cuento"; pero esto no significa que haya un tercer género (por el contrario, duplicaría el problema porque entonces habría dos límites para definir en lugar de uno).

Dependiendo del objeto de la narración puede tener dos fines muy específicos



Se refleja el lenguaje propio de quienes hablan de acuerdo a su edad, sexo, educación, nivel social y emotivo.

La novela es el reino de la libertad de contenido y de forma. Es un género proteico que presenta a lo largo de la historia múltiples formas y puntos de vista.

Para clasificar este género ha de tenerse en cuenta que existen diversos criterios, empleados por las distintas tipologías propuestas:





Hay que añadir a esta lista otras tipologías que toman como criterio el estilo de la obra y entonces se habla de:


O, si se consideran sus argumentos, puede hablarse de:

Desde finales del periodo victoriano hasta la actualidad, algunas de estas variedades se han convertido en auténticos subgéneros (ciencia ficción, novela rosa) muy populares, aunque a menudo ignorados por los críticos y los académicos; en tiempos recientes, las mejores novelas de ciertos subgéneros han empezado a ser reconocidas como literatura seria.

La novela es el más tardío de todos los géneros literarios. Aunque tiene precedentes en la Edad Antigua, no logró implantarse sino hasta la Edad Media.

Existe toda una tradición de largos relatos narrativos en verso, propios de tradiciones orales, como la sumeria ("Epopeya de Gilgamesh") y la hindú ("Ramaiana" y "Majabhárata).

Estos relatos épicos en verso se dieron igualmente en Grecia (Homero) y Roma (Virgilio). Es aquí donde se encuentran las primeras ficciones en prosa, tanto en su modalidad satírica (con "El Satiricón" de Petronio, las increíbles historias de Luciano de Samosata y la obra protopicaresca de Apuleyo "El Asno de Oro"). Dos géneros aparecen en la época helenística que se retomarían en el Renacimiento y están en el origen de la novela moderna: la novela bizantina (Heliodoro de Émesa) y la novela pastoril ("Dafnis y Cloe", de Longo).

La "Novela de Genji" ("Genji Monogatari"), de Murasaki Shikibu, es una obra clásica de la literatura japonesa y está considerada como una de las novelas más antiguas de la historia.

En Occidente, en los siglos XI y XII, surgieron los romances, que eran largas narraciones de ficción en verso, que se llamaron así por estar escritos en lengua romance. Se dedicaron especialmente a temas histórico-legendarios, en torno a personajes como el Cid o el ciclo artúrico.

En el Siglo XIII, el mallorquín Ramon Llull escribe las primeras novelas modernas occidentales: "Blanquerna" y "Félix o libro de las maravillas", así como otros relatos breves en prosa como el "Libro de las bestias".

En los siglos XIV y XV surgieron los primeros romances en prosa: largas narraciones sobre los mismos temas caballerescos, solo que evitando el verso rimado. Aquí se encuentra el origen de los libros de caballerías. En China se escriben dos de las cuatro novelas clásicas chinas, el "Romance de los Tres Reinos" (1330) de Luo Guanzhong y la primera versión de "A la orilla del agua" de Shi Nai'an.

Junto a los libros de caballerías, surgieron en el siglo XIV las colecciones de cuentos, que tienen en Boccaccio y Chaucer sus más destacados representantes. Solían recurrir al artificio de la "historia dentro de la historia": no son así los autores, sino sus personajes, los que relatan los cuentos. Así, en "El Decamerón", un grupo de florentinos huye de la peste y se entretienen unos a otros narrando historias de todo tipo; en los "Cuentos de Canterbury", son unos peregrinos que van a Canterbury a visitar la tumba de Tomás Becket y cada uno escoge cuentos que se relacionan con su estado o su carácter. Así los nobles cuentan historias más "románticas", mientras que los de clase inferior prefieren historias de la vida cotidiana. De esta forma, los verdaderos autores, Chaucer y Boccaccio, justificaban estas historias de trampas y travesuras, de amores ilícitos e inteligentes intrigas en las que se reía de profesiones respetables o de los habitantes de otra ciudad.

A finales del siglo XV surge en España la novela sentimental, como última derivación de las convencionales teorías provenzales del amor cortés. La obra fundamental del género fue la "Cárcel de amor" (1492) de Diego de San Pedro.

El cambio de un siglo a otro estuvo dominado por los libros de caballerías. En Valencia, este tipo de prosa novelesca se difundió al idioma valenciano, con obras como "Tirante el Blanco" "Tirant lo Blanc" de Joanot Martorell (1460-1464) o la novela anónima "Curial e Güelfa" (mediados del Siglo XV). La obra más representativa del género fue el "Amadís de Gaula" (1508). Este género siguió cultivándose el siglo siguiente, con dos ciclos de novelas: los "Amadises" y los "Palmerines".

La difusión de la imprenta incrementó la comercialización de las novelas y los romances, aunque los libros impresos eran caros. La alfabetización fue más rápida en cuanto a la lectura que en cuanto a la escritura.

Todo el siglo estuvo dominado por el subgénero de la novela pastoril, que situaba el asunto amoroso en un entorno bucólico. Puede considerarse iniciada con "La Arcadia" (1502), de Jacopo Sannazaro y se expandió a otros idiomas, como el portugués ("Menina y moza", 1554, de Bernardim Ribeiro) o el inglés (La "Arcadia", 1580, de Sidney).

No obstante, a mediados de siglo, se produjo un cambio de ideas hacia un mayor realismo, superando en este punto las novelas pastoriles y caballerescas. Así se advierte en el "Gargantúa y Pantagruel" de François Rabelais y en la "Vida de Lazarillo de Tormes y de sus fortunas y adversidades" (1554), origen esta última de la novela picaresca. En Oriente se escriben dos de las cuatro novelas clásicas chinas, la segunda versión de "A la orilla del agua" (1573) de Shi Nai'an y Luo Guanzhong, y "Viaje al Oeste" (1590), atribuida a Wu Cheng'en.

La novela moderna, como técnica y género literario está en el siglo XVII en la lengua española, siendo su mejor ejemplo "Don Quijote de la Mancha" (1605) de Miguel de Cervantes. Se considera como la primera novela moderna del mundo, ya que innova respecto a los modelos clásicos de la literatura grecorromana como lo eran la epopeya o la crónica. Incorpora ya una estructura episódica según un propósito fijo premeditadamente unitario. Se inició como una sátira del "Amadis", que había hecho que Don Quijote perdiera la cabeza. Los defensores del "Amadís" criticaron la sátira porque apenas podía enseñar algo: "Don Quijote" ni ofrecía un héroe al que emular ni satisfacía con bellos diálogos; todo lo que podía ofrecer es hacer burla de los ideales nobles. "Don Quijote" fue la primera obra auténticamente anti-romance de este periodo; gracias a su forma que desmitifica la tradición caballeresca y cortés, representa la primera obra literaria que se puede clasificar como novela.

Con posterioridad al "Quijote", Cervantes publicó las "Novelas ejemplares" (1613). Por «novela» se entendía en el siglo XVII la narración breve intermedia entre el cuento y la novela extensa, o sea lo que hoy llamamos novela corta. Las "Novelas ejemplares" de Cervantes son originales, no siguen modelos italianos, y frente a la crítica al Quijote, que se decía que no enseñaba nada, pretendían ofrecer un comportamiento moral, una alternativa a los modelos heroico y satírico. No obstante, siguió suscitando críticas: Cervantes hablaba de adulterio, celos y crimen. Si estas historias proporcionaban ejemplo de algo, era de acciones inmorales. Los defensores de la "novela" respondieron que sus historias proporcionaban buenos y malos ejemplos. El lector podía aún sentir compasión y simpatía con las víctimas de los crímenes y las intrigas, si se narraban ejemplos de maldad.

Surgió entonces como respuesta a estas novelas dudosas un romance más noble y elevado, con incursiones al mundo bucólico, siendo "La Astrea" (1607-27) de Honoré d'Urfé, la más famosa. Se criticaron estos romances por su falta de realismo, a lo que sus defensores replicaban que se trataba en realidad de "novelas en clave" ("roman à clef"), en los que, de forma encubierta, se hacía referencia a personajes del mundo real. Esta es la línea que siguió Madeleine de Scudéry, con tramas ambientadas en el mundo antiguo pero cuyo contenido estaba tomado de la vida real, siendo sus personajes, en realidad, sus amigos de los círculos literarios de París.

Veinte años más tarde, Madame de La Fayette dio el paso decisivo, siendo su obra más conocida "La princesa de Clèves" (1678), en la que tomaba la técnica de la novela española, pero la adaptaba al gusto francés: en lugar de orgullosos españoles que se batían en duelo para vengar su reputación, reflejaba detalladamente los motivos de sus personajes y el comportamiento humano. Era una "novela" sobre una virtuosa dama, que tuvo la oportunidad de arriesgarse en un amor ilícito y no solo resistió a la tentación, sino que acrecentó su infelicidad confesando sus sentimientos a su marido. La melancolía que su historia creaba era enteramente nueva y sensacional.

A finales del siglo XVII se escribieron y divulgaron, sobre todo por Francia, Alemania y Gran Bretaña, novelitas francesas que cultivaban el escándalo. Los autores sostenían que las historias eran verdaderas y no se narraban para escandalizar, sino para proporcionar lecciones morales. Para probarlo, ponían nombres ficticios a sus personajes y contaban las historias como si fueran novelas. También surgieron colecciones de cartas, que incluían estas historietas, y que llevaron al desarrollo de la novela epistolar.

Es entonces cuando aparecen las primeras "novelas" originales en inglés, gracias a Aphra Behn y William Congreve.

El cultivo de la novela escandalosa dio lugar a diversas críticas. Se quiso superar este género mediante el regreso al «romance», según lo entendieron autores como François Fénelon, famoso por su obra "Telémaco" (1699/1700). Nació así un género de pretendido «romance nuevo». Los editores ingleses de Fénelon, sin embargo, evitaron el término «romance», prefiriendo publicarlo como «nueva épica en prosa» (de ahí los prefacios).

Las novelas y los romances de comienzos del siglo XVIII no eran considerados parte de la "literatura", sino otro elemento más con el que comerciar. El centro de este mercado estaba dominado por ficciones que sostenían que eran ficciones y que se leían como tales. Comprendían una gran producción de romances y, al final, una producción opuesta de romances satíricos. En el centro, la novela había crecido, con historias que no eran heroicas ni predominantemente satíricas, sino realistas, cortas y estimulantes con sus ejemplos de conductas humanas.

Sin embargo, se daban también dos extremos. Por un lado, libros que pretendían ser romances, pero que realmente eran todo menos ficticios. Delarivier Manley escribió el más famoso de ellos, su "New Atalantis", llena de historias que la autora sostenía que había inventado. Los censores se veían impotentes: Manley vendía historias que desacreditaban a los whigs en el poder, pero que supuestamente ocurrían en una isla de fantasía llamada Atalantis, lo que les impedía demandar a la autora por difamación, salvo que acreditasen que eso era lo que ocurría en Inglaterra. En el mismo mercado aparecieron historias privadas, creando un género diferente de amor personal y batallas públicas sobre reputaciones perdidas.

En sentido opuesto, otras novelas sostenían que eran estrictamente de no ficción, pero que se leían como novelas. Así ocurre con "Robinson Crusoe" de Daniel Defoe, en cuyo prefacio se manifiesta:

Esta obra ya advertía en su cubierta que no se trataba de una novela ni de un romance, sino de una historia. Sin embargo, el diseño de página recordaba demasiado al "romance nuevo" con el que Fénelon se había hecho famoso. Y ciertamente, tal como se entendía el término en aquella época, esta obra es cualquier cosa menos una novela. No era una historia corta, ni se centraba en la intriga, ni se contaba en beneficio de un final bien cortado. Tampoco es Crusoe el antihéroe de un romance satírico, a pesar de hablar en primera persona del singular y haber tropezado con toda clase de miserias. Crusoe no invita realmente a la risa (aunque los lectores con gusto sabrán, por supuesto, entender como humor sus proclamas acerca de ser un hombre real). No es el autor real sino el fingido el que es serio, la vida le ha arrastrado a las más románticas aventuras: ha caído en las garras de los piratas y sobrevivido durante años en una isla desierta. Es más, lo ha hecho con un heroísmo ejemplar, siendo como era un mero marinero de York. No se puede culpar a los lectores que la leyeron como un romance, tan lleno está el texto de pura imaginación. Defoe y su editor sabían que todo lo que se decía resultaba totalmente increíble, y sin embargo afirmaban que era cierto (o, que si no lo era, seguía mereciendo la pena leerlo como una buena alegoría).

La publicación de "Robinson Crusoe", sin embargo, no condujo directamente a la reforma del mercado de mediados del dieciocho. Se publicó como historia dudosa, por lo que entraban en el juego escandaloso del mercado del XVIII.

La reforma en el mercado de libros inglés de principios del dieciocho vino de la mano de la producción de clásicos. En los años 1720 se reeditaron en Londres gran cantidad de títulos de novela clásica europea, desde Maquiavelo a Madame de La Fayette. Las "novelas" de Aphra Behn habían aparecido en conjunto en colecciones, y la autora del siglo XVII se había convertido en un clásico. Fénelon ya lo era desde hacía años, al igual que Heliodoro. Aparecieron las obras de Petronio y Longo.

La interpretación y el análisis de los clásicos ponía a los lectores de ficción en una posición más ventajosa. Había una gran diferencia entre leer un romance, perdiéndose en un mundo imaginario, o leerlo con un prefacio que informaba sobre los griegos, romanos o árabes que habían producido títulos como "Las etiópicas" o "Las mil y una noches" (que se publicó por primera vez en Europa entre 1704 a 1715, en francés, traducción en la que se basaron la edición inglesa y alemana).

Poco después aparecieron "Los viajes de Gulliver" (1726), sátira de Jonathan Swift, cruel y despiadada frente al optimismo que emana de "Robinson Crusoe" y su confianza en la capacidad del hombre para sobreponerse.

Cambió el diseño de las portadas: las nuevas novelas no pretendieron vender ficciones al tiempo que amenazaban con revelar secretos reales. Ni aparecían como falsas "historias verdaderas". El nuevo título ya indicaría que la obra era de ficción, e indicaba cómo debía tratarlas el público. "Pamela," de Samuel Richardson (1740) fue uno de los títulos que introdujo un nuevo formato de título, con su fórmula "[...], o [...]" ofreciendo un ejemplo: "Pamela, o la virtud recompensada - Ahora publicada por primera vez para cultivar los principios de la virtud y la religión en las mentes de los jóvenes de ambos sexos, una narrativa que tiene el fundamento en la verdad y la naturaleza; y al mismo tiempo entretiene agradablemente". Así dice el título, y deja claro que es una obra creada por un artista que pretende lograr un efecto determinado, pero para ser discutido por el público crítico. Décadas más tarde, las novelas ya no necesitaron ser más que novelas: ficción. Richardson fue el primer novelista que unió a la forma sentimental una intención moralizadora, a través de personajes bastante ingenuos. Semejante candor se ve en "El vicario de Wakefield", de Oliver Goldsmith (1766).

Mayor realismo tiene la obra de Henry Fielding, que es influido tanto por "Don Quijote" como por la picaresca española. Su obra más conocida es "Tom Jones" (1749).

En la segunda mitad de siglo se afianzó la crítica literaria, un discurso crítico y externo sobre la poesía y la ficción. Se abrió con ella la interacción entre participantes separados: los novelistas escribirían para ser criticados y el público observaría la interacción entre la crítica y los autores. La nueva crítica de finales del siglo XVIII implicaba un cambio, al establecer un mercado de obras merecedoras de ser discutidas, mientras que el resto del mercado continuaría existiendo, pero perdería la mayor parte de su atractivo público. Como resultado, el mercado se dividió en un campo inferior de ficción popular y una producción literaria crítica. Solo las obras privilegiadas podían discutirse como obras creadas por un artista que quería que el público discutiera esto y no otra historia.

Desapareció del mercado el escándalo producido por DuNoyer o Delarivier Manley. No atraía a la crítica seria y se perdía si permanecía sin discutir. Necesitó al final su propio tipo de periodismo escandaloso, que se desarrolló hasta convertirse en la prensa amarilla. El mercado inferior de la ficción en prosa siguió enfocando la inmediata satisfacción de un público que disfrutaba su permanencia en el mundo ficticio. El mercado más sofisticado se hizo complejo, con obras que jugaban nuevos juegos.

En este mercado alto, podía verse dos tradiciones que se desarrollaban: obras que jugaban con el arte de la ficción —Laurence Sterne y su "Tristram Shandy" entre ellas— el otro más cercano a las discusiones que prevalían y modos de su audiencia. El gran conflicto del siglo XIX, de si el artista debe escribir para satisfacer al público o para producir el arte por el arte, aún no había llegado.

La ilustración francesa utilizó la novela como instrumento de expresión de ideas filosóficas. Así, Voltaire, escribió el cuento satírico "Cándido o El optimismo" (1759), contra el optimismo de ciertos pensadores. Poco después, sería Rousseau el que reflejaría su entusiasmo por la naturaleza y la libertad en la novela sentimental "Julia o la nueva Eloísa" (1761) y en la larga novela pedagógica "Emilio" (1762).

La novela sentimental se manifiesta en Alemania con "Las cuitas del joven Werther", de Johann Wolfgang von Goethe (1774), se situó a la encabezada del nuevo movimiento, y forjó tal sentimiento de compasión y comprensión que muchos estaban preparados a seguir a Werther en su suicidio. En esta época también se hizo popular Bernardin de Saint-Pierre, con su novela "Pablo y Virginia" (1787), que narra el amor desgraciado entre dos adolescentes en una isla tropical.

En China se escribe al acabar el siglo la última de las cuatro novelas clásicas, el "Sueño de las mansiones rojas", también llamada "Sueño en el pabellón rojo" (1792) de Cao Xueqin.

A finales del siglo XVIII aparecen unas novelas cargadas de un sentimentalismo melancólico que abren el período romántico que se desarrolla plenamente en el siglo XIX con la aparición de la novela histórica, psicológica, poética y social. El género alcanza su perfección técnica con el realismo y el naturalismo. Es en esta época en la que la novela alcanza su madurez como género. Su forma y su estética ya no cambiaron más hasta el siglo XX: su división en capítulos, la utilización del pasado narrativo y de un narrador omnisciente.

Uno de los primeros exponentes de la novela en este siglo es la novela gótica. Desde comienzos del siglo XVII la novela había sido un género realista contrario al romance y su desmesurada fantasía. Se había tornado después hacia el escándalo y por esto había sufrido su primera reforma en el siglo XVIII. Con el tiempo, la ficción se convirtió en el campo más honorable de la literatura. Este desarrollo culminó en una ola de novelas de fantasía en el tránsito hacia el siglo XIX, en las que se acentuó la sensibilidad y se convirtió a las mujeres en sus protagonistas. Es el nacimiento de la novela gótica. El clásico de la novela gótica es "Los misterios de Udolfo" (1794), en la que, como en otras novelas del género, la noción de lo "sublime" (teoría estética del siglo XVIII) es crucial. Los elementos sobrenaturales también son básicos en estas y la susceptibilidad que sus heroínas mostraban hacia ellos acabó convirtiéndose en una exagerada hipersensibilidad que fue parodiada por Jane Austen con "La abadía de Northanger" (1803). La novela de Jane Austen introdujo un estilo diferente de escritura, la "comedia de costumbres". Sus novelas a menudo son no solo cómicas, sino también mordazmente críticas de la cultura restrictiva y rural de principios del siglo XIX. Su novela más conocida es "Orgullo y prejuicio" (1811).

También es en este siglo cuando se desarrolla el Romanticismo, que, contrariamente a lo que se pudiera pensar, no cultivó tanto el género novelístico. Byron, Schiller, Lamartine o Leopardi prefirieron el drama o la poesía, pero aun así fueron los primeros en darle un lugar a la novela dentro de sus teorías estéticas.

En Francia, sin embargo, los autores prerrománticos y románticos se consagraron más ampliamente a la novela. Se puede citar a Madame de Staël, Chateaubriand, Vigny ("Stello, Servidumbre y grandeza militar, Cinq-mars"), Mérimée ("Crónica del reinado de Carlos IX, Carmen, Doble error"), Musset ("Confesión de un hijo del siglo"), George Sand ("Lélia, Indiana)" e incluso el Victor Hugo de ("Nuestra Señora de París").

En Inglaterra, la novela romántica encuentra su máxima expresión con las hermanas Brontë (Emily Brontë, Charlotte Brontë y Anne Brontë) y Walter Scott, cultivador de una novela histórica de carácter tradicional y conservador, ambientada en Escocia ("Waverley", "Rob Roy") o la Edad Media ("Ivanhoe" o "Quintin Durward"). En Estados Unidos, cultivó este tipo de novela Fenimore Cooper, siendo su obra más conocida "El último mohicano". En Rusia, puede citarse la novela en verso de Pushkin, "Eugenio Oneguin" y en Italia, "Los Novios" de Alessandro Manzoni (1840-1842).

Las obras de Jean Paul y E.T.A. Hoffmann están dominadas por la imaginación, pero conservaron la estética heteróclita del siglo XVIII, de Laurence Sterne y de la novela gótica.

Por otro lado está la novela realista, que se caracteriza por la verosimilitud de las intrigas, que a menudo están inspiradas por hechos reales, y también por la riqueza de las descripciones y de la psicología de los personajes. La voluntad de construir un mundo novelístico a la vez coherente y completo vio su culminación con "La Comedia humana" de Honoré de Balzac, así como con las obras de Flaubert y Maupassant y acabó evolucionando hacia el naturalismo de Zola y hacia la novela psicológica.

En Inglaterra encontramos autores como Charles Dickens, William Makepeace Thackeray, George Eliot y Anthony Trollope, en Portugal, Eça de Queiroz y en Francia a Octave Mirbeau, los cuales tratan de presentar una "imagen global" de toda la sociedad. En Alemania y en Austria, se impone el estilo Biedermeier, una novela realista con rasgos moralistas (Adalbert Stifter).

Este es el gran siglo de la literatura rusa, que dio numerosas obras maestras al género novelístico, especialmente en el estilo realista: "Anna Karénina" de León Tolstói (1873-1877), "Padres e hijos" de Iván Turguénev (1862), "Oblómov" de Iván Goncharov (1858). También la obra novelística de Fiódor Dostoyevski como, por ejemplo, la novela "Los hermanos Karamázov" puede por ciertos aspectos ser relacionada con este movimiento.

Es en el siglo XIX cuando el mercado de la novela se separa en "alta" y "baja" producción. La nueva producción superior puede verse en términos de tradiciones nacionales, a medida que el género novelístico reemplazaba a la poesía como medio de expresión privilegiado de la conciencia nacional, es decir, se buscaba la creación de un corpus de literaturas nacionales. Pueden citarse como ejemplo "La letra escarlata" de Nathaniel Hawthorne (Estados Unidos, 1850), "Eugenio Oneguin" de Aleksandr Pushkin (Rusia, 1823-1831), "Soy un gato" de Natsume Sôseki (Japón, 1905), "Memorias póstumas de Blas Cubas" de Machado de Assis (Brasil, 1881) o "La muerte" de Alexandros Papadiamantis (Grecia, 1903).

La producción inferior se organizaba más bien en géneros por un esquema que se deriva del espectro de géneros de los siglos XVII y XVIII, aunque vio el nacimiento de dos nuevos géneros novelísticos populares: la novela policiaca con Wilkie Collins y Edgar Allan Poe y la novela de ciencia-ficción con Julio Verne y H. G. Wells.

Con la separación en la producción la novela probó que era un medio para una comunicación tanto íntima (las novelas pueden leerse privadamente mientras que las obras de teatro son siempre un acontecimiento público) como públicamente (las novelas se publican y así se convierten en algo que afecta al público, si no a la nación, y sus intereses vitales), un medio de un punto de vista personal que puede abarcar el mundo. Nuevas formas de interacción entre los autores y el público reflejaban estos desarrollos: los autores hacían lecturas públicas, recibían premios prestigiosos, ofrecían entrevistas en los medios de comunicación y actuaban como la conciencia de su nación. Este concepto del novelista como una figura pública apareció a lo largo del siglo XIX.

El inicio del siglo XX trajo consigo cambios que afectarían a la vida diaria de las personas y también de la novela. El nacimiento del psicoanálisis, la lógica de Wittgenstein y Russell, del relativismo y los avances de la lingüística provocan que la técnica narrativa intente también adecuarse a una nueva era. Las vanguardias en las artes plásticas y la conmoción de las dos guerras mundiales, también tienen un gran peso en la forma de la novela del siglo XX. Por otro lado, la producción de novelas y de los autores que se dedican a ellas vio en este siglo un crecimiento tal, y se ha manifestado en tan variadas vertientes que cualquier intento de clasificación será sesgado.

Una de las primeras características que pueden apreciarse en la novela moderna es la influencia del psicoanálisis. Hacia finales del siglo XIX, numerosas novelas buscaban desarrollar un análisis psicológico de sus personajes. Algunos ejemplos son las novelas tardías de Maupassant, Romain Rolland, Paul Bourget, Colette o D.H. Lawrence. La intriga, las descripciones de lugares y, en menor medida, el estudio social, pasaron a un segundo plano. Henry James introdujo un aspecto suplementario que se tornaría central en el estudio de la historia de la novela: el estilo se convierte en el mejor medio para reflejar el universo psicológico de los personajes. El deseo de aproximarse más a la vida interior de estos hace que se desarrolle la técnica del monólogo interior, como ejemplifican "El teniente Güstel", de Arthur Schnitzler (1901), "Las olas" de Virginia Woolf (1931), y el "Ulises" de James Joyce (1922).

Por otro lado, en el siglo XX también se manifiesta una vuelta al realismo con la novela vienesa, con la que se buscaba recuperar el proyecto realista de Balzac de construir una novela polifónica que reflejara todos los aspectos de una época. Así, encontramos obras como "El hombre sin cualidades" de Robert Musil (publicado póstumamente en 1943) y "Los Sonámbulos" de Hermann Broch (1928-1931). Estas dos novelas integran largos pasajes de reflexiones y comentarios filosóficos que esclarecen la dimensión alegórica de la obra. En la tercera parte de "Los sonámbulos", Broch alarga el horizonte de la novela mediante la yuxtaposición de diferentes estilos: narrativa, reflexión, autobiografía, etcétera.

Podemos encontrar también esta ambición realista en otras novelas vienesas de la época, como las obras de: (Arthur Schnitzler, Heimito von Doderer, Joseph Roth) y con más frecuencia en otros autores en lengua alemana como Thomas Mann, que analiza los grandes problemas de nuestro tiempo, fundamentalmente la guerra y la crisis espiritual en Europa con obras como "La montaña mágica", y también Alfred Döblin o Elias Canetti, o el francés Roger Martin du Gard en "Les Thibault" (1922-1929) y el americano John Dos Passos, en su trilogía "U.S.A." (1930-1936).
La búsqueda y la experimentación son otros dos factores de la novela en este siglo. Ya a comienzos, y quizá antes, nace la novela experimental. En este momento la novela era un género conocido y respetado, al menos en sus expresiones más elevadas (los "clásicos") y con el nuevo siglo muestra un giro hacia la relatividad y la individualidad: la trama a menudo desaparece, no existe necesariamente una relación entre la representación espacial con el ambiente, la andadura cronológica se sustituye por una disolución del curso del tiempo y nace una nueva relación entre el tiempo y la trama.

Con "En busca del tiempo perdido" de Marcel Proust y el "Ulises" de James Joyce, la concepción de la novela como un universo encuentra su fin. En cierta manera es también una continuación de la novela de análisis psicológico. Estas dos novelas tienen igualmente la particularidad de proponer una visión original del tiempo: el tiempo cíclico de la memoria en Proust, el tiempo de un solo día dilatado infinitamente de Joyce. En este sentido, estas novelas marcan una ruptura con la concepción tradicional del tiempo en la novela, que estaba inspirado en la historia. En este sentido también podemos aproximar la obra de Joyce con la de la autora inglesa Virginia Woolf y el americano William Faulkner.

La entrada del modernismo y el humanismo en la filosofía occidental, así como la conmoción causada por dos guerras mundiales consecutivas provocaron un cambio radical en la novela. Las historias se tornaron más personales, más irreales o más formales. El escritor se encuentra con un dilema fundamental, escribir, por un lado, de manera objetiva, y por el otro transmitir una experiencia personal y subjetiva.
Es por esto que la novela de principios del siglo XX se ve dominada por la angustia y la duda. La novela existencialista de la que se considera a Søren Kierkegaard como su precursor inmediato con novelas como "Diario de un seductor" es un claro ejemplo de esto.

Otro de los aspectos novedosos de la literatura de comienzos de siglo es la novela corta caracterizada por una imaginación sombría y grotesca, como es el caso de las novelas de Franz Kafka, también de corte existencialista, como "El proceso" o "La metamorfosis".

Especialmente en los años 1930 podemos encontrar diversas novelas de corte existencialista. Estas novelas son narradas en primera persona, como si fuera un diario, y los temas que más aparecen son la angustia, la soledad, la búsqueda de un sentido para la existencia y la dificultad comunicativa. Estos autores son generalmente herederos del estilo de Dostoievski, y su obra más representativa es La náusea de Jean-Paul Sartre. Otros autores existencialistas notables son Albert Camus, cuyo estilo minimalista le sitúa en un contraste directo con Sartre, Knut Hamsun, Louis-Ferdinand Céline, Dino Buzzati, Cesare Pavese y la novela absurdista de Boris Vian. La novela japonesa de después de la guerra también comparte similitudes con el existencialismo, como puede apreciarse en autores como Yukio Mishima, Yasunari Kawabata, Kōbō Abe o Kenzaburō Ōe.

La dimensión trágica de la historia del siglo XX se encuentra largamente reflejada en la literatura de la época. Las narraciones o testimonios de aquellos que combatieron en ambas guerras mundiales, los exiliados y los que escaparon de un campo de concentración trataron de abordar esa experiencia trágica y de grabarla para siempre en la memoria de la humanidad. Todo esto tuvo consecuencias en la forma de la novela, pues vemos aparecer gran cantidad de relatos que no son ficción que emplean la técnica y el formato de la novela, como pueden ser "Si esto es un hombre" (Primo Levi, 1947), "La noche" (Elie Wiesel, 1958) "La especie humana" (Robert Antelme, 1947) o "Ser sin destino" (Imre Kertész, 1975). Este tipo de novela influenciaría después otras novelas autobiográficas de autores como Georges Perec o Marguerite Duras.

También en el siglo XX, aparece la distopía o antiutopía. En estas novelas la dimensión política es esencial, y describen un mundo dejado a la arbitrariedad de una dictadura. Entre las obras más notables se encuentran "El proceso" de Franz Kafka, "1984" de George Orwell, "Un mundo feliz" de Aldous Huxley, y "Nosotros" de Yevgeni Zamiatin.

También después de la Segunda Guerra Mundial se desarrolla el llamado boom latinoamericano con exponentes notables y talentosos, situación que se presenta en los años 1960 y alcanza su apogeo en la década de los 1970 y principios de los 1980. Entre estos se puede citar a Julio Cortázar y su obra "Rayuela" (1963); Gabriel García Márquez, colombiano, cuyo libro más conocido es "Cien años de soledad" (1967) y de quien el género más destacado es el llamado realismo mágico; Mario Vargas Llosa, peruano, autor de "La ciudad y los perros", "Pantaleón y las visitadoras" o "La tía Julia y el escribidor;" Carlos Fuentes, autor de "La región más transparente, Aura, La muerte de Artemio Cruz," entre otros libros; y José Donoso, cuyas obras más destacadas son "El lugar sin límites" y "El obsceno pájaro de la noche", entre otros autores.






</doc>
<doc id="1982" url="https://es.wikipedia.org/wiki?curid=1982" title="Nicaragua">
Nicaragua

Nicaragua, oficialmente República de Nicaragua, es un país soberano ubicado en el istmo centroamericano, la capital y ciudad política más poblada es Managua. Está compuesta por quince departamentos y dos regiones autónomas: Costa Caribe Norte y Sur, cuyas capitales son Puerto Cabezas y Bluefields, respectivamente. Se ubica en el hemisferio norte, entre la línea ecuatorial y el trópico de Cáncer, aproximadamente entre los 11° y los 15° de latitud Norte y respecto al meridiano de Greenwich, entre los 83° y los 88° de longitud Oeste.

El territorio de Nicaragua tiene una superficie aproximada de 130 494 km², limita al norte con Honduras, al sur con Costa Rica, al oeste con el océano Pacífico y al este con el mar Caribe. En cuanto a límites marítimos, en el océano Pacífico colinda con El Salvador, Honduras y Costa Rica; mientras que en el mar Caribe colinda con Honduras, Colombia y Costa Rica.

Son reconocidas las lenguas de los pueblos indígenas originarios como el inglés criollo nicaragüense, misquito, Sumu o Sumo, Garífuna y Rama.

Habitado por pueblos precolombinos, la costa del Océano Pacífico y parte de la región central del actual territorio de Nicaragua fue conquistado por España en el siglo XVI, donde fue establecida la Provincia de Nicaragua, que perteneció al Imperio español (1502-1821), luego al Primer Imperio Mexicano (1821-1823), a las Provincias Unidas del Centro de América (1823-1824), y a la República Federal de Centroamérica (1824–1838), emerge como país independiente en 1838, bajo el nombre de "Estado de Nicaragua" y se empieza a llamar República de Nicaragua, desde 1854.

Respecto a la integración de la llamada Costa de Mosquitos (la antigua Provincia de Taguzgalpa) en la República de Nicaragua, en 1860 se firmó el Tratado de Managua entre Nicaragua y el Reino Unido de Gran Bretaña e Irlanda, por lo cual este renunció a su protectorado misquito y reconoció la soberanía de Nicaragua; mientras que Nicaragua reconoció los derechos de autonomía de los misquitos. Así nació la Reserva Mosquitia. Un año después de firmado el Tratado de Managua, en Bluefields se reunieron 51 Witas (alcaldes) y aprobaron la Constitución de la Reserva, inspirada por el cónsul británico y que establecía de manera general, leyes inglesas. La soberanía de Nicaragua fue en realidad una formalidad, hasta que en 1894 la Mosquitia fue reincorporada oficial y concretamente a Nicaragua durante el gobierno de José Santos Zelaya, mediante la llamada Reincorporación de la Mosquitia efectuada por Rigoberto Cabezas, quien debió hacer frente a un intento de restablecer su dominación por parte de los británicos, entre julio y agosto de ese mismo año. Mediante el Tratado Altamirano-Harrison del 19 de abril de 1905, Gran Bretaña reconoció la soberanía absoluta de Nicaragua sobre la costa de Mosquitos, lo que significaba abolir la Reserva Mosquitia, a cambio de garantizar a los nativos exención de impuestos y del servicio militar y garantizarles vivir en sus aldeas y territorios ancestrales según sus costumbres propias.

Nicaragua es un país y tropical, en su interior alberga también dos grandes lagos: el Xolotlán y el Cocibolca o "Gran lago de Nicaragua".

Tras el Derrocamiento de la Dictadura Somocista, mediante la Revolución Popular Sandinista se instauró una Junta de Gobierno de Reconstrucción Nacional (1979-1985) constituida como junta de gobierno transitoria encargada del poder ejecutivo y un Consejo de Estado encargado del poder legislativo con participación de representantes de los ámbitos político, social, comunal y religioso.

En 1984 se realizan las primeras elecciones populares conforme a la nueva Ley electoral. La Junta de Gobierno de Reconstrucción Nacional entrega el poder al nuevo Presidente elegido: Daniel Ortega Saavedra. Así La Junta transitoria queda disuelta.

Durante el gobierno del Frente Sandinista de Liberación Nacional (FSLN) el país sufrió un prolongado conflicto civil fomentado con la intervención de los Estados Unidos de América bajo la administración del presidente Ronald Reagan, el gobierno estadounidense por medio de la CIA; formó y entrenó en secreto a grupos de rebeldes anticomunistas conocidos como Contras, financiando una guerra desautorizada por el Congreso y llegando a bloquear económicamente a Nicaragua. La Unión Soviética y países como Cuba, Francia y Libia también intervinieron en el conflicto a través de cooperación militar, económica, financiera y médica. Dicho conflicto motivó la demanda del gobierno de Nicaragua contra el gobierno de Estados Unidos ante la Corte Internacional de Justicia de La Haya, en el conocido caso Nicaragua contra Estados Unidos, cuya sentencia favorable a Nicaragua obligaba al gobierno de Estados Unidos a indemnizar a la República de Nicaragua, deuda que luego fue perdonada al gobierno de Estados Unidos por el gobierno nicaragüense de la presidenta Violeta Barrios de Chamorro.

Los conflictos económicos y de guerra culminaron luego de las elecciones populares del 25 de febrero de 1990, cuando Violeta Chamorro derrotó a Daniel Ortega con 54.7 % de los votos contra 40.8 %.

Según el IDH, a partir del año 1995, Nicaragua ha venido mejorando su nivel de vida. 

El 18 de abril de 2018 se desató unas series de protestas multitudinarias en todo el país contra las Reformas al Seguro Social del INSS, que ha dejado represión por parte del Gobierno y desobediencia civil por parte de la población . Esta situación dejó un saldo de víctimas entre 326 y 700 fallecidos la mayoría estudiantes opositores, así como 1200 heridos, se estima que dicha crisis sociopolítica afectará a la economía durante los próximos años.

La determinación del significado del nombre de Nicaragua es un poco inexacto, sin embargo sintetizando los hallazgos de los investigadores Nicaragua significa El Reino de los que habitan junto a grandes depósitos de agua. También Generalmente se acepta que se debe a Nicarao, señor de los niquiranos (nahuas), cuyo señorío a la llegada de los conquistadores españoles abarcaba desde el istmo de Rivas e isla de Ometepe hasta Nicoya en la actual Costa Rica. Se cuenta de un diálogo entre Nicarao y Gil González Dávila, durante el cual el jefe indígena asombró al español con sus preguntas y respuestas a temas de filosofía y astronomía. 

Por lo menos unos 13 000 años antes de nuestra era, aparecieron en Nicaragua los primeros seres humanos, procedentes del hemisferio Norte; también se conoce de emigraciones originarias del Sur. Se radicaron a orillas de ríos, lagunas, lagos y mares; transcurridos los siglos el único testimonio que dejaron de su cultura son sus huellas en la loseta volcánica de Acahualinca.

De esos migrantes aseveran que el núcleo original perteneció los primeros pobladores lenmichies, luego desplazados de la costa del Océano Pacífico por el gran grupo de origen mangue llamados dirianes o chorotegas, de quienes descienden los habitantes de la zona oriental del Pacífico: Managua (Imabite); Masaya (Nindirí, Catarina, Niquinohomo); Granada (Xalteva) y Carazo (Diriamba, Jinotepe). Además en León (Sutiava o Sutiaba).

En la costa del mar Caribe nicaragüense, en la zona llamada se localiza el "conchero" (cúmulo de valvas) conocido como "Angie", donde se encuentran los vestigios de presencia humana, más antiguos conocidos, datados en 8 mil años.

Se sabe de asentamientos indígenas en la región de la costa del Océano Pacífico nicaragüense que datan del 6000 a. C. El yacimiento de Acahualinca (entre el 232 y el 8 a. C.) es posterior, asimismo se conocen otras evidencias arqueológicas, principalmente artículos de cerámica y estatuarios de piedra volcánica, como los hallados en la isla de Zapatera.

La mayoría de investigaciones coinciden en el origen náhuatl del nombre de Nicaragua, pero los autores no se ponen de acuerdo en cuál puede ser su traducción:

Los nicaraos emigraron hacia esta área desde regiones norteñas después de la caída de Teotihuacán, ya que así lo aconsejaron sus líderes religiosos. Según la tradición, debían viajar hacia el sur hasta que encontraran un lago con dos volcanes que se levantaran de las aguas, es decir, cuando llegaran a Ometépetl (Ometepe), la isla volcánica más grande del mundo en medio de un lago de agua dulce.

Además de los chorotegas, nahoas y marribios que habitaban en la franja del Pacífico, estaban los matagalpas que habitaban las cordilleras montañosas del centro de Nicaragua, y los ulwa-sumo, miskitos y ramas que habitaban las riberas de los grandes ríos que desembocan en el mar Caribe.
Siempre ha habido una confusión gramatical entre Ulúa y Ulwa, que son dos grupos diferentes, los Ulúa hablaban el matagalpa-populuca. Los ulwas forman parte de los mayangnas y hablan el sumo o parrastra. Es posible que existiera algún contacto a nivel del departamento de Matagalpa, los primeros al oeste, entre pinares, los segundos al este era gente selvática. El límite entre ambos era Yasica al norte y Olama al sur.

El 21 de abril de 1524, en el actual territorio de Nicaragua, fue fundada la ciudad de Granada y el 19 de junio de 1524 la ciudad de León. Ambas fueron fundadas por Francisco Hernández de Córdoba, enviado por Pedro Arias de Ávila, entonces gobernador de Castilla de Oro, en el actual territorio de Panamá. En 1528, la Corona española erigió la Provincia de Nicaragua, y se solicitó establecer si el territorio de la villa de Bruselas (actualmente en territorio de Costa Rica), pertenecía a la Provincia de Nicaragua (la nueva circunscripción), o si permanecía bajo la autoridad de Castilla del Oro.

Una Real Cédula del 21 de abril de 1529 resolvió el conflicto a favor de la Provincia de Nicaragua, cuando ya la villa de Bruselas había dejado de existir. Posteriormente la Provincia de Nicaragua pasó a depender de la Audiencia de Panamá hasta 1543 que pasa a depender de la Audiencia de Guatemala.

En 1554, con la conquista del Reino de Nicoya se crea la Alcaldía Mayor o Corregimiento de la provincia de Nicoya, puertos de Chira y Paro. La Intendencia de León fue creada por Real Cédula del 23 de diciembre de 1786, con la unión de la Alcaldía Mayor de Nicoya y la Gobernación de Nicaragua. Formando parte de la Capitanía General de Guatemala, dependiente del Virreinato de la Nueva España.

En 1812, las Cortes de Cádiz erigieron la provincia de Nicaragua y Costa Rica (separada de la provincia de Guatemala), y con cabecera en la ciudad de León. Esta provincia duró hasta 1814, año en que se restableció el reino de Guatemala. En 1820, al restablecerse el régimen constitucional, resurgió la provincia de Nicaragua y Costa Rica, que estaba dividida en siete partidos:

A mediados del siglo XVI, se desarrolló en el noreste de la actual Honduras la nación de los zambos mosquitos, surgida de la mezcla entre los indígenas que la habitaban y los esclavos sobrevivientes del naufragio de un barco negrero que se hundió en el litoral. Los británicos establecieron amistosas relaciones con ellos y surgió así la reserva Misquita o «Mosquitia», una especie de Protectorado británico que duró hasta fines de siglo XIX.

En 1630, se estableció el primer contacto comercial entre los británicos y los misquitos en la zona del cabo Gracias a Dios Entre ellos estaba el pirata neerlandés Abraham Blauvelt quien se estableció en la bahía de Bluefields llamada así en honor a él. Poco a poco los ingleses se asentaron en la región, hasta que el 16 de abril de 1740 los misquitos, amparados por la protección de Gran Bretaña, ceden sus territorios, estableciendo el dominio colonial británico.

En 1774, Bluefields se convirtió en la capital de la Mosquitia, donde los británicos instalaron a un rey mosco para consolidar su dominio. Los británicos se retiraron en 1787 pero la Mosquitia siguió siendo gobernada por los reyes moscos, fieles a la corona británica.

En 1803, por intermedio de la Real Orden del 20 de noviembre, el rey de España ordenó segregar de la antigua Capitanía General de Guatemala, la Costa de Mosquitos como las islas de San Andrés y agregarlas al Virreinato de Nueva Granada.

Posteriormente la Costa de Mosquitos fue restituida a la Capitanía General de Guatemala, mediante una Real Orden del 13 de noviembre de 1806, enviada al Capitán General de Guatemala, expresando lo siguiente:

En 1894, las tropas nicaragüenses al mando de Rigoberto Cabezas ocuparon la Costa de Mosquitos, que fue organizada como el departamento de Zelaya, dividido a fines del siglo XX en dos regiones (Región Autónoma del Atlántico Norte y la Región Autónoma del Atlántico Sur).

Nicaragua formaba parte de la española Capitanía General de Guatemala, que comprendía los territorios desde Costa Rica hasta la actual Chiapas (en México). En Sudamérica, y durante cierto periodo en México, los mestizos y criollos americanos (españoles nacidos en el Nuevo Mundo) iniciaron sangrientas guerras contra la Corona hasta conseguir su independencia.

Con España fuera, Nicaragua y toda Centroamérica decidió anexarse al naciente Imperio mexicano, pero este duró muy pocos años. Entonces los pequeños países del istmo decidieron formar la Federación de Estados Centroamericanos, la cual se disolvió debido a los intereses particulares de los líderes de cada una de las provincias. Fue entonces que el 30 de abril de 1838, Nicaragua ingresó en la historia como una república independiente.

La independencia de Nicaragua ocurrió durante septiembre de 1821, al observar como otras regiones españolas ganaban la guerra de la independencia, los líderes nicaragüenses comenzaron un proceso de negociación, al redactar un acta de independencia que fue reconocida por los jefes de la Corona. Entre las personas que promovieron la independencia centroamericana destacaron dos nicaragüenses: el presbítero Tomás Ruiz Romero y el jurisconsulto Miguel Larreynaga, recordado por su efigie en una emisión de los billetes de diez córdobas.

La independencia trajo consigo un enfrentamiento por el poder entre las ciudades de León y Granada y sus respectivos partidos políticos (los democráticos o liberales en León y los legitimistas o conservadores en Granada). El mayor beneficio fue que dejaron de pagar a la corona española impuesto alguno.

Posteriormente se da la anexión al Primer Imperio mexicano gobernado por Agustín de Iturbide decretada el 5 de enero de 1822. Iturbide fue obligado a renunciar en México, lo cual aprovechó el Congreso de las Provincias para reunirse en Guatemala el 1 de julio de 1823 y declarar la separación de México. En esa misma reunión también se aprobó la abolición de la esclavitud, convirtiendo a las Provincias Unidas del Centro de América en una de las primeras naciones del continente americano en abolir la esclavitud, junto con Chile en 1823, México en 1829, Uruguay en 1842 y Argentina en 1853, mucho antes que países como Estados Unidos de América (1865) y Brasil (1888).

Desde 1823, Nicaragua junto a los otros cuatro países centroamericanos formaron una federación llamada Provincias Unidas de Centroamérica, con un gobierno general residente en Guatemala y otro particular en la capital de cada provincia, siendo su primer presidente Manuel de Arce y vicepresidente Mariano de Beltranena. Los países centroamericanos no estaban de acuerdo con el sistema de gobierno de Arce ya que disolvió el congreso, el cual no lo apoyaba.

Finalmente tras años de conflictos civiles provocados por las diferencias entre los gobiernos federales y provinciales y las luchas de poder en las provincias se da la separación de la federación el 30 de abril de 1838 cuando Nicaragua la abandona, siendo el primer país en hacerlo, seguido ese mismo año por Costa Rica y Honduras.

Nicaragua tuvo una convulsa vida política durante la primera mitad del siglo XIX. Al ser Nicaragua el puente entre los dos océanos que fue utilizado para el desplazamiento de pasajeros de la ruta del tránsito propiedad de Cornelius Vanderbilt, ruta por la que circulaban los aventureros, comerciantes y emigrantes que viajaban desde el Atlántico de Estados Unidos, hasta California en donde, hacia 1848-49 se habían descubierto yacimientos de oro, la convierten en un punto estratégico e importante en Centroamérica.

En 1854, los generales liberales Castellón y Jérez contratan a través de Vanderbilt los servicios de Byron Cole, en calidad de mercenario. Posteriormente Cole le cede el contrato a William Walker. Este, amparado bajo la doctrina Monroe, se proclama presidente de Nicaragua e intenta hacer de la nación centroamericana un nuevo miembro de los Estados Unidos. Los filibusteros fueron derrotados en la Guerra Nacional que contó con la participación de todos los países centroamericanos, y que en lo que respecta a los nicaragüenses tuvo su episodio más glorioso en la batalla de San Jacinto.

Al concluir el conflicto, Nicaragua se hallaba gravemente debilitada económicamente, la ciudad de Granada había sido incendiada casi en su totalidad y se mantenía la rivalidad entre los liberales de León y los conservadores granadinos.

A partir de 1858 se inició, bajo predominio conservador, una etapa de recuperación económica e institucional, que constituye uno de los períodos más sobresalientes de la historia de Nicaragua conocido como "Primera República Conservadora" o los "Treinta años conservadores".

La economía, el desarrollo cultural y social, este último en menor medida debido a la desigualdad de clases, convirtieron al país en el más estable y rico de toda Centroamérica y en una de las mejores economías del continente americano, con un sólido régimen constitucional y una administración proba y austera de las finanzas públicas.

Todo esto provocó una nueva oleada de inmigrantes provenientes de Europa, principalmente de Alemania e Italia, lo que hizo florecer aún más la economía, mientras El Salvador, Honduras y Guatemala se mantenían en conflictos armados y en Costa Rica se daba una época de golpes militares.

Durante esta época se sucedieron en el poder Tomás Martínez Guerrero (1858-1867), Fernando Guzmán Solórzano (1867-1871), Vicente Cuadra y Ruy Lugo (1871-1875), Pedro Joaquín Chamorro y Alfaro (1875-1879), Joaquín Zavala Solís (1879-1883), Adán Cárdenas del Castillo (1883-1887), Evaristo Carazo Aranda (1887-1889) y Roberto Sacasa y Sarria (1889-1893).

Durante el gobierno Chamorro ocurre el Caso Eisenstuck (o Incidente Eisenstuck, en alemán Eisenstuck-Affäre), un conflicto diplomático entre el Imperio alemán y el gobierno nicaragüense, en que el puerto de Corinto fue ocupado por tres corbetas de la Marina Imperial alemana. En 1885, Nicaragua se unió a Costa Rica y El Salvador en una alianza militar para hacer frente a las pretensiones del Presidente de Guatemala Justo Rufino Barrios, apoyadas por el Presidente de Honduras Luis Bográn.

Nicaragua exporta principalmente café (un 64,9 %) y metales preciosos con un 13,8 %. En total el porcentaje de exportación de estos dos productos era de 78,7 % en 1913. Por tanto, Nicaragua dependía principalmente de la exportación de café.
Los principales compradores de las exportaciones nicaragüenses era Estados Unidos, seguido por Alemania. Estados Unidos aumenta sus importaciones durante los años 1907 a 1918, mientras que Gran Bretaña, Francia y Alemania las disminuyen. Su principal socio comercial era Estados Unidos, ya que contenía una alta concentración de exportaciones (en 1917 llegó a obtener un 85 % de las exportaciones de Nicaragua).

El período de los treinta y cinco años de gobiernos conservadores concluyó con la llamada Revolución Liberal del 11 de julio de 1893, cuando fue derrocado el Presidente Roberto Sacasa y Sarria y ascendieron al poder los liberales encabezados por el Doctor y General José Santos Zelaya López.

Zelaya aglutinó a la naciente burguesía criolla en torno a su persona e implantó un régimen dictatorial que le permitió perpetuarse en el poder hasta 1909, haciendo uso del destierro y la represión en contra de sus adversarios. Esto a la postre dio inicio a una etapa de inestabilidad política. No obstante, en términos económicos, durante su gobierno se continuó con el desarrollo del país sufragado por la amplia solvencia y excedentes económicos existentes, permitiéndole a Zelaya ampliar su influencia en Centroamérica.

En 1907 a Nicaragua le fue impuesta una guerra por los gobiernos de Honduras y El Salvador. El triunfo de las tropas nicaragüenses sobre un ejército combinado de hondureños y salvadoreños en la llamada batalla de Namasigüe y la posterior entrada en Tegucigalpa ocasionaron la rendición del general Manuel Bonilla en la isla de Amapala y la caída de su gobierno.

Durante la presidencia de Zelaya se promulgó una nueva Constitución conocida como "La Libérrima" que declaraba el estado laico (separación entre el Estado y la Iglesia católica), la obligatoriedad de la educación primaria, la secularización de los cementerios y la despenalización del aborto, entre otras medidas consideradas como avanzadas para su época. Otro logro importante fue la fundación de la primera Academia Militar de Nicaragua, fundada el 11 de julio de 1904, que contó entre sus organizadores e instructores a militares provenientes de Alemania y Chile. Entre estos se destacó el coronel Carlos Uebersezig, quien se desempeñó en el cargo de instructor hasta 1909. Otros alemanes fueron los coroneles Carlos von Grafenhvost y Enrique Berew. Entre los chilenos estaban Joaquín Ortiz y Erwin Keife.

Se inició nuevamente la guerra civil entre los liberales que mantenían el poder y los conservadoras quienes solicitaron la ayuda de los marines estadounidenses. Estados Unidos intervino militarmente en 1912 para vencer a José Santos Zelaya y los liberales, que se niegan a contraer con Estados Unidos un préstamo que trae aparejado el establecimiento del control financiero estadounidense en Nicaragua. Instalado en el poder, el presidente Adolfo Díaz contrae el préstamo otorgando los ingresos aduaneros como garantía y aceptando un supervisor general estadounidense de aduanas, designado por los banqueros de Nueva York con la aprobación del Departamento de Estado. De aquí data la instalación en Managua de una guarnición estadounidense que se mantuvo durante trece años, de 1912 a 1925. Contra está ocupación se destacó el General Benjamín Zeledón muerto el 4 de octubre de 1912 luego de la batalla de La Barranca, Masaya en donde las fuerzas liberales sitiadas fueron derrotadas por los fuerzas conservadoras y estadounidenses.

La Asamblea Nacional (el Congreso designó Presidente al también liberal José Madriz Rodríguez que no fue del agrado de Estados Unidos (ya lo había expresado en la Nota Knox cuando hacía referencia a ""un candidato a la presidencia íntimamente ligado con el viejo régimen"").Madriz mandó tropas a Bluefields contra los insurrectos y toma el fuerte de El Bluff que cierra el puerto de la ciudad quedando está bajo su control. La infantería de Marina de Estados Unidos fue desembarcada en la ciudad en mayo de 1910 por lo que esta se mantuvo del lado rebelde al no poderla tomar las tropas gubernamentales. Las aduanas de Bluefields quedaban bajo control de Madriz pero la Armada de Estados Unidos estableció otra aduana bajo autoridad de Estrada, y el gobierno de EE.UU. manifestó, ante la protesta del gobierno de Nicaragua, que "cada fracción cobre derechos sólo en el territorio que se halle bajo su dominio".
José Madriz renuncia a la presidencia el 19 de agosto y poco después entran en Managua los generales Estrada Morales y Chamorro Vargas. La nueva Asamblea Nacional nombra Presidente a José Dolores Estrada Morales, quien cedió el poder a su hermano, el general sublevado Juan José, siendo nombrado vicepresidente Adolfo Díaz, que había sido empleado de las minas La Luz y Los Ángeles y era conocido por el secretario de Estado Knox. 

El día 1 de enero de 1911 los Estados Unidos reconocen al nuevo gobierno de Nicaragua. Estrada Morales firmó con Estados Unidos los Pactos Dawson (por Thomas C. Dawson, enviado del gobierno estadounidense), y convocó elecciones para formar una nueva Asamblea Constituyente, que elaboró una nueva Constitución.

Durante el principio del siglo XX, el país se caracterizó por la inestabilidad política e intervenciones armadas de Estados Unidos en 1912 y el período entre 1927 a 1933.

Además, durante este tiempo, surgen algunas discrepancias con Colombia por problemas territoriales, ya que con ese país no se había definido claramente los derechos sobre la Costa de Mosquitos (territorio perteneciente a Colombia). El 24 de marzo de 1928 se firma el tratado Esguerra-Bárcenas, en el cual, Colombia reconoció la soberanía a Nicaragua sobre las islas Mangle y la Costa de Mosquitos desde el cabo Gracias a Dios y hasta el río San Juan (por su parte Nicaragua reconoció la soberanía y propiedad de Colombia sobre el Archipiélago de San Andrés, Providencia y Santa Catalina. En 1930 se realizó el Acta de Canje de dicho Tratado.

Uno de los personajes importantes de la primera mitad del siglo XX fue Augusto Nicolás Calderón Sandino, mejor conocido como Augusto C. Sandino, general de origen campesino, que cuando liberales y conservadores llegan al pacto del Espino Negro continuó la lucha contra la intervención estadounidense. La última entrevista que diera el general Sandino fue el 3 de febrero de 1933 a Adolfo Calero Orozco (1899-1980), periodista de "La Prensa", un día después de suscribir con el presidente Juan Bautista Sacasa los "Convenios de Paz", los cuales implicaron la disolución de su Ejército y, en la práctica, la firma de su sentencia de muerte. El asesinato de Augusto C. Sandino se ordenó a las siete de la noche en la oficina del jefe director de la Guardia Nacional y se ejecutó aproximadamente a las 23:00 en un predio de barrio Larreynaga, entonces periférico de la Vieja Managua, el 21 de febrero de 1934.

Dictadura Somocista

Desde 1936 a 1979, Nicaragua vive una era marcada por la sucesión en el poder de distintos dictadores, pertenecientes a la familia Somoza.

Desde su Independencia, hasta la Revolución de 1979 Nicaragua estuvo muy influida por tres poderosas familias: Sacasa, Chamorro y Somoza.

El nuevo auge económico en los años cincuenta y sesenta coexiste con la inestabilidad política. El crecimiento económico de esos años provocó un gran desarrollo de la capital Managua. Sin embargo, el violentísimo 
terremoto del 23 de diciembre de 1972 provocó la destrucción de la ciudad y la muerte de más de 10 000 personas. Lo que vino después fue la corrupción del gobierno somocista en el manejo de la ayuda internacional.

Pese a la corta duración que tuvo el conflicto armado, los continuos bombardeos en las ciudades provocaron la muerte de más de 50 000 personas. El pueblo nicaragüense con la vanguardia de «los Muchachos» del FSLN logra derrocar a Somoza el 19 de julio de 1979. El FSLN, apoyado por México, Cuba, la Unión Soviética y los países del Bloque Socialista, realizó cambios sociales, expropiando propiedades de la clase alta del país en general en una clara visión para instaurar el socialismo. Hacia el año 1981, gracias al apoyo de la URSS, el Ejército Popular Sandinista se había convertido en la fuerza militar más poderosa en la historia de Centroamérica.

Sin embargo, la etapa sandinista se tradujo en la continuación del conflicto Este-Oeste entre las dos superpotencias de la Guerra Fría. Se formaron los contras armados y financiados por el Gobierno de Estados Unidos, incluso tras la victoria electoral del sandinismo en 1984. Muchos nicaragüenses emigraron a Estados Unidos, Canadá, México, Guatemala, Honduras, Costa Rica, países occidentales de Europa y Australia durante la guerra civil; escapando de la persecución política, el Servicio Militar Patriótico y el estado económico del país.

En febrero de 1990, se celebraron elecciones generales bajo la supervisión de varios observadores internacionales. Violeta Barrios de Chamorro, candidata antisandinista de la Unión Nacional Opositora, ganó las elecciones. Violeta Barrios de Chamorro inició un programa de reconstrucción nacional que estableció la reforma monetaria, la reducción del ejército y la desmovilización de la contra. Gracias a estas reformas la altísima tasa de inflación disminuyó; el crecimiento económico comenzó a ser positivo, las exportaciones crecieron y el país comenzó a reconstruirse, aunque el desempleo se agudizó por los miles de combatientes que se reintegraron a la vida civil. Se privatizó la Banca, las Minas, el transporte, la salud, la educación. Este modelo de gobierno facilitó un auge de la empresa privada.

En 1996 se celebraron nuevas elecciones en las que ganó Arnoldo Alemán, candidato del Partido Liberal Constitucionalista. Durante los meses de septiembre y octubre de 1998 trascendieron, a través de distintos medios de comunicación y de la oposición, tanto sandinista como liberal disidente, las presuntas prácticas de nepotismo en las altas instancias del Estado por parte de familiares y allegados al presidente de la República.
Todas las acusaciones pasaron a segundo plano cuando a finales de octubre de 1998 se produjo el paso del Huracán Mitch por el territorio nicaragüense. Solo en Nicaragua murieron casi 4000 personas, 5000 resultaron desaparecidas y más de un millón de personas resultaron damnificadas. A todo ello se le unieron cuantiosos daños materiales y económicos que devastaron aún más la ya de por si maltratada economía nicaragüense.
Posteriormente al desastre, y en parte a consecuencia del mismo, el país tuvo que hacer frente a una grave crisis política y social en 1999. Esto se produjo por la depuración, iniciada por el gobierno de Arnoldo Alemán, de los sectores vinculados al sandinismo en el Ejército de Nicaragua. A ello se unieron las protestas de estudiantes y trabajadores en demanda de sus reivindicaciones.

En las elecciones legislativas y presidenciales celebradas el 4 de noviembre de 2001, la victoria fue para Enrique Bolaños del Partido Liberal Constitucionalista.

En el año 2006 se celebraron nuevas elecciones, las cuales fueron ganadas por el candidato del Frente Sandinista de Liberación Nacional, Daniel Ortega Saavedra.

En noviembre de 2008 se celebraron elecciones municipales. Con observación electoral de más de 150 observadores internacionales, entre ellos los representantes del Protocolo de Tikal compuesta de miembros de América Central y América del Sur, el Protocolo Suramericano de Quito, y el consejo latinoamericano de expertos electorales (CCELA), que arrojaron un balance oficial de 105 alcaldías para los sandinistas, frente a solo 41 para los dos partidos opositores (ALN y PLC).

El presidente estadounidense Donald Trump firmó en noviembre de 2018 una "orden ejecutiva" que declara al gobierno nicaragüense una "amenaza a la seguridad nacional" de Estados Unidos. En diciembre, aprobó la "Ley de Condicionalidad de la Inversión Nicaragüense". Este "Nica Act" autoriza sanciones contra el Frente Sandinista de Liberación Nacional y tiene como objetivo limitar el acceso de Nicaragua a préstamos internacionales.

En 2017, según el índice de Brecha Global de Género del Foro Económico Mundial, Nicaragua es el país con mayor equidad de género de América Latina.

El 18 abril de 2018 se presenta un nuevo acontecimiento político-económico, cuando el gobierno de Daniel Ortega impone reformas al seguro social, que provocaron protestas por parte de la población civil, las cuales fueron brutalmente reprimidas por las fuerzas policiales leales a Ortega, según organismos internacionales de derechos humanos el número de muertos se sitúa en 325 personas y más de 700 privadas de libertad por razones políticas (véase Protestas en Nicaragua de 2018-2019).



Nicaragua no contaba con ave nacional por decreto, el presidente Enrique Bolaños Geyer en 2004 dijo que iba a lanzar el decreto que no incluiría al ave "Eumomota superciliosa" (guardabarranco) ya que es el ave nacional de El Salvador por lo que se pondría al "Momotus momota" (barranquero) como ave nacional, pero no se lanzó el decreto. El 15 de junio de 2012 fue declarado de forma oficial ave nacional.

Nicaragua se divide en 15 departamentos y 2 regiones autónomas, los hoy en día solo tienen propósitos meramente administrativos. No tienen autoridades, ni propias ni delegadas del poder central. Los departamentos se dividen a su vez en municipios regidos por un alcalde y un concejo municipal.

En 1987, se han creado dos regiones autónomas a partir del antiguo departamento de Zelaya y la Región autónoma de la Costa Caribe Norte y Sur, las cuales son regidas por un gobernador Regional y un Concejo regional. La reforma a la Constitución Política de Nicaragua de 2014 modifica el nombre de las regiones por Costa Caribe en lugar de Costa Atlántica. Estas regiones autónomas están pobladas básicamente por poblaciones indígenas y su gobierno comunitario se rige por las normas propias de estas culturas.

Nicaragua es una república constituida por cuatro poderes: el Ejecutivo, el Legislativo, el Judicial y el Electoral. El poder ejecutivo es ejercido por el presidente, quien es elegido para un período de cinco años mediante sufragio universal. El poder legislativo está radicado en la Asamblea Nacional (unicameral), formada por 92 diputados electos por cinco años. Una Corte Suprema de Justicia integrada por 16 magistrados es la cual se encarga de vigilar el sistema judicial. Las contiendas electorales son responsabilidad del Consejo Supremo Electoral. Administrativamente, Nicaragua está dividida en 153 municipios circunscritos, en quince departamentos y dos regiones autónomas.

Los partidos políticos principales son (orden alfabético):

La Asamblea Nacional de Nicaragua es el órgano que ejerce el poder legislativo en Nicaragua. Está integrada por 92 diputados que son electos junto a sus suplentes para un período de cinco años mediante el voto universal, igual, directo, libre y secreto. Del total de diputados 70 son electos de acuerdo a las circunscripciones departamentales y regiones autónomas, mientras que el resto tendrán carácter nacional.

La Constitución de Nicaragua dispone que el presidente y vicepresidente de la República ocuparán los cargos de diputados propietario y suplente, respectivamente, una vez hayan culminado su período constitucional, también harán lo mismo los candidatos a presidente y vicepresidente que hubiesen obtenido el segundo lugar.

La Asamblea Nacional es constituida el 9 de enero del año posterior a la elección. Todos los diputados gozan de la inmunidad parlamentaria en el ejercicio de sus funciones como diputado.
Anteriormente a la Revolución Sandinista, el poder legislativo era llamado congreso y su sede se encontraba en el Palacio Nacional de Nicaragua, actual Palacio de la Cultura.

Inicialmente las protestas se produjeron el 13 de abril por el incendio forestal ocurrido en la Reserva Indio Maíz, en las cuales culpaban al gobierno de la República por no tomar las medidas adecuadas en el tiempo oportuno.

El lunes 16 de abril, el presidente ejecutivo del Instituto Nicaragüense de Seguridad Social (INSS), Roberto López, anunció un paquete de reformas al reglamento de Seguridad Social que aumenta el aporte de trabajadores y empleadores al INSS, achica las futuras pensiones y crea un tributo ilegal a las pensiones del cinco por ciento, entre otras medidas, para salvar de la quiebra a dicha entidad.

Dichas reformas eran sumamente perjudiciales para los jubilados y para la población en general, entre las cuales estaba el aumento de las cuotas patronales e individuales por parte de la empresa privada y trabajadores aportes que serían ingresados a un sistema de seguro social colapsado por la corrupción del partido de gobierno.

A causa de la crisis provocada por organismos no gubernamentales, más de 120000 colaboradores perdieron sus empleos sin que se avisara una mejoría en cuanto a la caída de los indicadores económicos.
Un grupo de nicaragüenses, operando bajo el hashtag #SOSINSS en redes sociales, se autoconvocó para realizar el primer plantón masivo en Camino de Oriente el miércoles a las cinco de la tarde. Sin embargo, al mediodía, un grupo pequeño se reunió en las afueras de uno de los edificios del Instituto Nicaragüense de Seguridad Social con el propósito de exigir cuentas a la entidad. En este sentido el 18 de abril reiniciaron las protestas, ahora en contra de las reformas a la Seguridad Social, las que se tornaron violentas para un alzamiento general según el golpe blando y loluego que la primera dama y vicepresidenta, Rosario Murillo Zambrana, ordenase hacer caminatas y piquetes a nivel nacional para apoyar las reformas. Desde ese momento, varios grupos afines al gobierno se colocaron en las principales rotondas y avenidas de Managua. En las rotondas también se vieron a adultos mayores, estudiantes uniformados y motorizados.

Al darse estos enfrentamientos entre ambos grupos, ocurrieron los primeros heridos y fue anunciada los primeros tres muertos por parte del grupo opositor pero la Policía Nacional solo confirmó dos muertos, además se usó las #fakenews en las redes sociales lo cual hizo que más personas se sumaran a las protestas en contra de las reformas al Seguro Social. Como respuesta, agentes de la Policía Nacional y patrullas anti-disturbios llegaron hasta las manifestaciones intentando dispersar a los manifestantes con bombas lacrimógenas, lo que obligó a los opositores a atrincherarse y tomarse la Universidad Politécnica de Nicaragua, algunas instituciones públicas, así como también centros de comercios que resultaron afectados con quemas y saqueos a los establecimientos.

Ante estos acontecimientos el Presidente de la República, Daniel Ortega Saavedra, revoca las reformas a la Seguridad Social, «con el objetivo de frenar la ola de violencia en busca de mejores opciones en aras de solventar la crisis de la institución, abogando siempre al sistema de diálogo tripartito».

Sin embargo, los estudiantes afines al MRS y la Juventud Renovadora han llevado su descontento más allá de las reformas y afirman que protestan «contra la corrupción», para exigir libertad de prensa, entre otros temas. Antes del 18 de abril, los universitarios de los recintos públicos habían o parecían estar a favor del gobierno.

Dichas protestas han causado 325 muertes confirmadas por organismos internacionales como la CIDH y al menos 3,325 víctimas de lesiones según el Departamento para los Derechos Humanos de las Naciones Unidas. Sin embargo, el gobierno en una comisión para esclarecer las muertes denominada "Comisión de la Verdad, Justicia y Paz", conformada por simpatizantes o aliados del gobierno, afirma que la cifra llega a tan solo 197 personas, «todos sandinistas asesinados por la oposición».

El 30 de agosto de 2018, el periódico "The Boston Globe" publicó un artículo de la "Associated Press" donde se relata lo siguiente: "Un Reporte de las Naciones Unidas publicados este miércoles respecto a cuatro meses de desasosiego en Nicaragua describe los esfuerzos de represión exhaustiva realizada por el gobierno que se extiende desde las calles hasta los tribunales. El reporte que emitió el Alto Comisionado de las Naciones Unidas hace un llamado al gobierno del Presidente Ortega a poner fin inmediatamente a la persecución de los protestantes y a desarmar a los civiles enmascarados que han sido responsables por muchos de los asesinatos y las detenciones arbitrarias y no desarmar a los tranqueros armados ya que son "democráticos" . Más de 300 personas han sido matadas con violencia desde mediados de abril en esta nación centroamericana. El país vecino, Costa Rica, ha sido inundado con miles de solicitudes de asilo por parte de Nicaragüenses. El reporte describe arrestos ilegales, torturas y tribunales cerrados. Doctores, profesores, y jueces que se han pronunciado o protestado han sido despedidos de sus empleos en un acto que pretende desanimar a otras personas a que participen o apoyen las protestas. De acuerdo al reporte de la ONU, "El nivel de persecución es tal que muchas de las personas que han participado en las protestas, defendieron el derecho de otros a manifestarse o simplemente expresaron desacuerdo se han visto forzados a esconderse, han salido de Nicaragua o están intentando salir". Zeid Ra'ad al-Hussein, jefe de derechos humanos de la ONU, dijo en Ginebra que "la represión y represalias en contra de los manifestantes continúa en Nicaragua mientras el mundo mira hacia otro lado". Él urgió a la comunidad internacional a "tomar pasos concretos para que la actual crisis en Nicaragua no descienda hacia un más profundo disturbio social y político". El gobierno nicaragüense rechazó los reportes llamándoles "parciales" y dijo usaban fuentes de información de fuerzas anti-gubernamentales, negando el uso de la fuerza excesiva en contra de protestantes armados. Dijo que las Naciones Unidas no había sido invitada a evaluar la situación de derechos humanos sino invitada para acompañar a la comisión de verificación establecida como parte del diálogo nacional. Acusó al cuerpo global de exceder su autoridad."

Tras el informe de la ONU, el gobierno le retiró su permiso de estadía en el país.

A inicios del mes de julio y después de semanas de protestas que exigían la renuncia del presidente Daniel Ortega, la Policía Nacional llevó a cabo una operación para "restablecer el orden y la libre circulación en el país". Durante los días siguientes la Policía Nacional y paramilitares armados grupos civiles de autodefensa fueron desplegados en bastiones importantes de la rebelión armada con el fin de desmantelar las barricadas o "tranques" que la oposición había levantado como método de autodefensa y de protesta.

La organización independiente Amnistía Internacional en su informe "Sembrando el terror: De la letalidad a la persecución en Nicaragua, señala el uso de "armas de guerra" por parte de la Policía Nacional y paramilitares vestidos de civiles. Entre éstas destacan: ametralladoras ligeras RPK y ametralladoras PKM, rifles de francotirador M24 Remington, una gran una variedad de rifles estilo AK-47 y al menos un lanzagranadas antitanque portátil tipo RPG-7. Al menos 11 personas resultaron heridas a causa de dichos enfrentamientos. 
la Cenidh, Vilma Núñez de Escorcia, precisó que 35 personas murieron en los municipios de Diriamba y Jinotepe, en el departamento de Carazo, y tres más en el departamento de Matagalpa.

A partir del desmantelamiento de las barricadas, "la crisis entró en una nueva fase caracterizada por la persecución y criminalización de líderes sociales y de las protestas, personas defensoras de derechos humanos y aquellas involucradas o asociadas a las protestas". Agentes armados progubernamentales, de forma conjunta con la Policía Nacional, realizaron allanamientos de viviendas y arrestos legales de acuerdo a supuestas acusaciones de informantes locales. Varios miembros de las mismas familias (principalmente hombres jóvenes) eran aprehendidos en estas operaciones. En muchas ocasiones, los paraderos de estos individuos permanecieron desconocidos por varios días, hasta que sus familiares tuvieron conocimiento de que se encontraban detenidos en una estación policial o en las prisiones de “El Chipote”, “La Modelo” o “La Esperanza".

La República de Nicaragua es un país ubicado en el centro geográfico del istmo centroamericano. Limita al norte con Honduras, al sur con Costa Rica, al oeste con el océano Pacífico y al este con el mar Caribe. Por razones administrativas, Nicaragua se divide en quince departamentos y dos regiones autónomas. Estos, a la vez, se dividen en municipios, que actualmente son 153.

En Nicaragua se encuentran desde sabanas, hasta montañas vírgenes con especies autóctonas, y goza de tener uno de los lagos más grandes del mundo, con especies exóticas como el tiburón de agua dulce; mesetas aún despobladas con clima primaveral todo el año en el centro y pacífico del país, incluyendo zonas frías; playas aún vírgenes e impresionantes, donde actualmente se está asentando una oleada de nuevos turistas provenientes principalmente de Honduras y El Salvador, aprovechando además los bajos costos de los terrenos; volcanes activos; islas impresionantes y también poco exploradas aún como Ometepe, Zapatera, las Isletas de Granada o Corn Island, entre otras.

La Zona del Pacífico del país se caracteriza por ser la región volcánica y lacustre de Nicaragua, en ella se extienden la cordillera Centroamericana y la más elevada y ríspida cordillera Volcánica. El primer volcán es el Cosigüina, ubicado en la península homónima, dentro del golfo de Fonseca (muy popular entre turistas y autóctonos por ser en realidad una caldera sumergida de un gran cráter). Le sigue la cadena volcánica de los Marrabios o Maribios, que termina con el Momotombito; un islote en el lago Xolotlán. Hay también otros volcanes, como el Masaya o el Maderas y Concepción, formando estos dos últimos la isla de Ometepe en el lago Cocibolca (también conocido como el lago de Nicaragua). Esta zona goza de la presencia de otro gran lago: el lago de Managua.

Compuesta por los departamentos Rivas, Granada, Carazo, Masaya, Managua, León y Chinandega.

La Zona Central del país da fuente a otro gran río, el río Escondido, que se alimenta de la unión de los ríos Siquia, Mico y Rama. A lo largo de esta región se desplaza la cordillera Amerrisque o Chontaleña. En el norte de esta, presenta regiones secas como Nueva Segovia y montañosas y húmedas como Jinotega y Matagalpa. Estas zonas sirven de fuente a dos grandes ríos: el río Coco o Segovia y el Río Grande de Matagalpa. Nueva Segovia presenta las cordilleras de Dipilto y Jalapa, que sirven de frontera con Honduras, mientras que Jinotega a la cordillera de Isabelia y Matagalpa a la cordillera Dariense.
La Zona Central se divide en los departamentos de Madriz, Nueva Segovia, Boaco, Jinotega , Esteli, Matagalpa y Chontales, también Río San Juan.

La zona del Caribe del país es una gran planicie cubierta de grandes bosques y enormes ríos corren por sus tierras. Entre los principales ríos de esta región que desembocan en el mar de las Antillas están: el Coco o Segovia, el Wawa, el Kukalaya, el Prinzapolka, el Bambana, el Grande de Matagalpa, el Kurinwás, el Escondido (y sus afluentes Siquia, Mico y Rama), el Punta Gorda y el San Juan. En la parte norte de esta zona se encuentra parte de la cordillera Isabelia y Dariense y hacia el sur un ramal de la del Amerrisque o Chontaleña. Como nota adicional en la zona Caribe se encuentra la selva de Bosawás, la segunda selva más grande del continente y hogar de una rica biodiversidad.

Nicaragua es un país de grandes lagos y abundantes ríos. Se pueden diferenciar tres vertientes, la del Caribe, la del Pacífico y la interna. Los ríos de la vertiente del Pacífico son cortos y en general con sistemas de drenaje estructurados por corrientes efímeras o intermitentes, con un régimen irregular y caudales de estiaje muy reducidos; sin embargo, en el período lluvioso se pueden producir grandes crecidas, con inundaciones severas en las partes bajas de sus cuencas.

Sus principales ríos son: el Negro, Estero Real, El Viejo, Atoya, El Tesorero, El Releajo, Posoltega, Telica, Chiquito, Izapa, Tamarindo, Soledad, Masachapa, Amalia, Las Lajas, Ochomogo, Grande y Brito. La vertiente del Caribe acoge a los ríos más largos y caudalosos, muchos de ellos con posibilidad de navegación. Los más importantes son el río Coco, que hace frontera con Honduras, el río San Juan, que hace frontera con Costa Rica, Tuma, Siquia e Indio.

Nicaragua se localiza en el centro del continente americano, esta privilegiada localización provoca que el país albergue una gran biodiversidad. En el país se localizan la mayoría de especies del Neártico y de la Región Neotropical, con la excepción de las especies de altas latitudes.

Este conjunto de factores junto con el clima y las ligeras variaciones altitudinales permiten que el país de cobijo a 248 especies de y , 183 especies de mamíferos, 705 especies de aves, 640 especies de peces y unas 5796 especies de plantas. Todas estas especies se distribuyen en los diferentes biomas del país: selvas umbrófilas, selvas tropófilas, bosques de coníferas, sabanas y matorrales.

El ave nacional de Nicaragua es el Guardabarranco. La región de las grandes selvas se localiza en la costa oriental del país. Se da la selva lluviosa en el Río San Juan y en las regiones autónomas Costa Caribe Norte y Sur. Este bioma agrupa a la mayor biodiversidad del país y se encuentra protegida en gran parte por la Reserva Biológica Indio Maíz en el sur y por la Reserva de Bosawás en el noreste de Jinotega. La reserva de Bosawás tiene una gran biodiversidad representada por el jaguar, el puma, el danto, la guacamaya y el águila harpía; además forma un gran corredor con los bosques del sur de Honduras que representan unas 2,4 millones de hectáreas, consideradas los pulmones de América Central y la segunda selva umbrófila en tamaño de América (Para más información ver Áreas protegidas de Nicaragua).

En general la fauna que compone a las selvas lluviosas del país son el jaguar, el danto, diversos tipos de monos, la guacamaya, el quetzal, el águila harpía, las serpientes y los cocodrilos.

La selva tropófila se da en la zona del Pacífico y en algunos puntos del norte y el Caribe del país. En estos bosques se da una estación seca durante el invierno, sin embargo llueve mucho durante la estación húmeda. Estos bosques albergan pumas, venados, monos y diversas especies de reptiles.

El bosque tropical de coníferas se da en la Costa Caribe Norte. Se caracteriza por la presencia de diversos árboles típicos del Neártico, como el pino. También se dan algunas especies de mamíferos como los venados y los coyotes.

Las sabanas se dan en todo el país y su vegetación varía según la región. Así en la Costa Caribe Norte hay sabanas cubiertas de pinos y en Rivas hay sabanas con especies propias de las selvas. La fauna de las sabanas se compone de venados, coyotes y pecarís; sin embargo, la mayoría de sabanas del país han sido convertidas en terrenos de cultivo y pastoreo.

Nicaragua, al ubicarse en la zona intertropical, posee un clima tropical con variaciones dependiendo del relieve y la altitud; además incluye los vientos alisios del Océano Pacífico y el Mar Caribe. El clima de la costa del Pacífico es cálido durante todo el año y muy árido con un periodo estival muy seco y una estación de lluvias y alta humedad desde a mediados de mayo hasta principio de noviembre pero, con cortos periodos de calor y sequedad entre junio y julio.

La costa del Caribe presenta un clima muy húmedo durante todo el año con fuertes vientos alisios entre diciembre y febrero. La lluvia es muy intensa y a veces se generan inundaciones, este clima se clasifica entre tropical marítimo a tropical muy húmedo.

La zona del lago presenta un clima tropical con estación seca entre noviembre y abril y lluvias moderadas entre mayo a octubre. La temperatura suele ser elevada y la media ronda todo el año entre los 33 grados centígrados.

La zona montañosa presenta un clima templado, con tormentas de granizo ocasionales en la temporada de lluvias.

La actual población nicaragüense es multiétnica, y se divide en todos los grupos raciales así como todas sus posibles mezclas, principalmente con una gran mayoría de mestizos a lo largo de todo el territorio. De este modo, se han realizado varios estudios genéticos para analizar la estructura mitocondrial de la población del país, en los que los resultados demuestran una formación étnica trihíbrida mestiza, con algunas variaciones regionales, por ejemplo: según el estudio «Genomic Components in America's demography», publicado en 2017 en Japón, un nicaragüense promedio presenta una composición de entre el 58 % y el 62 % de genes europeos, casi que exclusivamente españoles; 28 % de herencia indígena de diversas etnias mesoamericanas y un 14 % proveniente de África. Otro estudio publicado en la revista "Genetics and Molecular Biology", realizado en diferentes países de America Latina, mostró también una composición triple, en la que los nicaragüenses en general tienen un 69 % de herencia europea, seguida en segundo lugar por la africana en un 20% y en último lugar la amerindia en un 11%. Finalmente, tomando en cuenta el cromosoma Y junto con diversos Y-SNPs, permiten clasificar la población nicaragüense dentro del acervo genético euroasiático, en particular, el grupo aportado principalmente por los colonos españoles resultó ser el mayoritario (43,63 %) mientras que los grupos nativo americano y africano también se observaron ambos con una frecuencia del 15,33 %.

El análisis del ADN mitocondrial el cual es importante en este estudio dado que este no forma parte de la información genética del núcleo y que es aportado exclusivamente por la madre a todos los hijos (varones y mujeres) y no por el padre, muestra por este método que el componente nativo americano del ADN de la actual población mestiza de Nicaragua alcanza un 88,95 %. Lo anterior sugiere que la base de la población nicaragüense se ha compuesto de una predominante participación paterna caucásica, principalmente española, con mujeres en su mayoría amerindias. Similares hallazgos y valores de composición en el mestizaje se han encontrado en diversos estudios realizados en poblaciones latinoamericanos. Cabe señalar que en el país también existen poblaciones más o menos puras que no se incluyeron en este estudio, como son los de origen caucásico que predominan en el norte del país, por su parte la población mestiza que es la inmensa mayoría predomina en el centro, sur y regiones del norte del país, y el grupo de afrodescendientes y nativos americanos que habitan en las costas que son muy poco habitadas.

El primer censo de Nicaragua se realizó en 1778, cuando su población apenas sobrepasaba los 100 000 habitantes. El último censo realizado en 1995 arrojó una población de casi cinco millones de habitantes.

Según datos oficiales del Instituto Nicaragüense de Estadísticas y Censos en el censo de julio de 1906 se contabilizaron finalmente 501 849 personas y para mayo de 1950 eran 1 049 611. El último censo realizado en el año 2005 arroja un total de 5 142 098 habitantes, muy por debajo de las estimaciones y a expensas de la reducción de la tasa de fecundidad, para una densidad de 42,7 habitantes por kilómetro cuadrado. La mayoría de la población nicaragüense (69 %) es principalmente de origen mestizo (mezcla de españoles, amerindios o africanos y en menor grado asiáticos). Corresponde el 5 % a grupos étnicos indígenas siendo los más numeroso el Miskito, Mestizo de la Costa Caribe, Chorotega Nahua-Mangue y Creol. Se estiman que la población de blancos descendientes europeos es cerca al 25% (la principal fuente de inmigración fueron españoles peninsulares, siguiendo la inmigración alemana y en menor proporción italiana, francesa, asiática,inglesa y de otros países de Europa Oriental). A mediados y finales del siglo XIX e inicios del siglo XX se incentivó la inmigración principalmente alemanes y franceses, otorgándoles terrenos para cultivos principalmente en las zonas de Estelí, Jinotega, Matagalpa, Managua - El Crucero, Carazo, Nueva Segovia y Madriz. Actualmente en departamentos de la zona Norte de Nicaragua (Estelí, Matagalpa, Jinotega) predominan descendientes de italianos, alemanes y en menor proporción de ingleses, alcanzando tasas de hasta 93 % de blancos. La población nicaragüense de origen africano (mulatos y afrodescendientes) corresponde al 9 % de la población, y habitan principalmente en las regiones caribeñas del país (donde la población es muy escasa y reducida). La mayoría de la población nicaragüense reside en la región occidental del país en los departamentos de Managua, Granada y León. Los extranjeros residentes en el país al momento de dicho censo sumaban el 0,6 % del total de la población nacional

La mayoría de la población afronicaragüense reside en la costa del Caribe del país, que también es la región más vasta y despoblada y son en su mayoría descendientes de antiguos esclavos provenientes finalmente de Jamaica cuando la región era un protectorado británico y conservan una rica cultura autóctona. De antaño los costeños han refutado la incapacidad que tiene el resto de los nicaragüenses (del Pacífico) para entender su identidad cultural, y aunque desde 1987 el Caribe cuenta con un sistema territorial diferente (Costa Caribe Norte y Sur) muchos sectores consideran que siguen olvidados por el estado central y que no se ha dado todavía una reincorporación jurídica, política, económica, religiosa y cultural de la Costa Caribe al resto de Nicaragua.

Hay comunidades de sirios, armenios, palestinos, judíos, y libaneses en Nicaragua con una población total de cerca de 30 000. Hay también una comunidad asiática de personas provenientes de Corea del Sur, de Japón, de Taiwán y de China. Estiman a la población china nicaragüense de aproximadamente 12 000. Los chinos llegaron en los fines del siglo XIX, el segundo censo de la nación (en 1920) reveló a 400 personas de nacionalidad china. Estas minorías hablan español mientras que mantienen sus idiomas ancestrales también.

La población del país crece a un ritmo de un 1,8 % anual (uno de los más altos del Hemisferio). Este alto crecimiento se debe a una alta natalidad situada en un 24/1000 y a una mortalidad baja de 4,5/1000 que dejarían un crecimiento natural de 2,03 % anual; sin embargo la tasa neta de migración es negativamente alta, de tal forma que el crecimiento poblacional desciende a un 1,8 %.

Debido a los altos índices de pobreza y desempleo, muchos nicaragüenses han decidido emigrar a países como México, Canadá, Guatemala, Panamá y El Salvador, no obstante los principales países de destino para los nicaragüenses son Estados Unidos, Costa Rica y España. La emigración de nicaragüenses al exterior ha aumentado, a tal grado, que se estima que uno de cada seis nicaragüenses vive en el exterior. Las cifras más aceptadas indican que hay casi un millón de nicaragüenses en el exterior.

De conformidad con el Artículo 11 de la Constitución de la República de Nicaragua, el idioma oficial del país es el español. Una de las características más sobresalientes del castellano nicaragüense es la aspiración de la /s/ posvocálica como en muchas regiones de España e Hispanoamérica.

También en Nicaragua, como en Argentina, Bolivia, Colombia, Costa Rica, 
Estado de Chiapas en Mexico, El Salvador, Guatemala, Honduras, Paraguay, Uruguay, Venezuela se utiliza el voseo; y así como en la región rioplatense, el uso del pronombre "vos" es parte de la norma culta y el uso del tuteo es casi inexistente.

Debido a la colonización británica de la Costa Atlántica, el inglés es común al lado de lenguas naturales como miskito, rama y sumo y otras autóctonas sumando una veintena sin catalogar. También, debido a la cercanía de Estados Unidos y su influencia en el estilo de vida "nica", es muy común encontrar personas bilingües en las principales ciudades como Managua, León, Granada, San Juan del Sur y Estelí, aunque también como parte de la apertura de la industria recreativa en estos sitios.

La denominación religiosa predominante en Nicaragua es el catolicismo, aproximadamente el 51 % de la población. Un segundo grupo religioso es el protestantismo que abarca un 42 % de la población y se encuentra dividido en varios grupos. Por su parte el 7 % de los nicaragüenses declara no seguir ninguna religión.

La religión es una parte importante de la cultura de Nicaragua y se reconoce en la Constitución. La libertad religiosa, que ha sido garantizada desde 1939, y la tolerancia religiosa las promueve tanto el gobierno nicaragüense como la Constitución. Nicaragua no tiene religión oficial, prácticamente es un estado laico. Las declaraciones de la Iglesia católica sobre temas nacionales se siguen de cerca. Se recurre a su autoridad en ocasiones estatales importantes. También se recurre a su mediación entre partes contendientes en momentos de crisis política.

La principal y tradicional confesión cristiana del país durante siglos ha sido la católica. Sin embargo, el número de católicos practicantes ha disminuido paulatinamente desde los años sesenta, cuando el 96 % de la población se declaraba católico. Mientras que los miembros evangélicos protestantes y la población que se declara sin religión ha crecido rápidamente en número desde los años noventa. También hay comunidades anglicanas y moravas en la costa del Caribe.

El catolicismo llegó a Nicaragua en el siglo XVI con la conquista española y se mantuvo hasta 1939. El protestantismo y otras confesiones cristianas llegaron a Nicaragua durante el siglo XIX, pero solo ganó muchos seguidores en la Costa Caribe durante el siglo XX.

Debido a la presencia inglesa en la Costa de los Mosquitos o Mosquitia (Costa Caribe), la mayoría de los costeños son cristianos protestantes en su mayoría anglicanos. Ellos pertenecen a seis diferentes pueblos indígenas y comunidades étnicas: 

La religiosidad popular gira en torno a los santos, que son percibidos como intercesores entre los seres humanos y Dios. La mayoría de las localidades, desde la capital Managua hasta las pequeñas comunidades rurales, rinden honor a «santos patronos», conforme al Calendario romano de la Iglesia católica, con fiestas religiosas solemnes y populares. En muchas comunidades, una rica tradición ha crecido en torno a las celebraciones de los santos patronos, sin duda una de las más importantes expresiones de fe del país y de más relevancia folklórica es la celebración del Tope de los Santos. Este constituye en el encuentro de las imágenes de Santiago, San Marcos y San Sebastián que se realiza tres veces al año en el departamento de Carazo el primer tope se realiza en enero con motivo de las fiestas de San Sebastián santo patrono de la ciudad de Diriamba, en ellas participan bailes tradicionales de la zona tales como El Güegüense, El Toro Huaco, el Viejo y la Vieja, el Gigante, entre otros. El segundo tope se realiza en el mes de abril con motivo de las fiestas de San Marcos Evangelista en la ciudad municipal de San Marcos, en ellas participan bailes típicos como la Vaquita de San Marcos y se reparten comidas y bebidas típicas como el picadillo y la chicha de maíz. El tercer tope se realiza en el mes de julio con motivo de las fiestas de Santiago Apóstol en la ciudad de Jinotepe, en estas fiestas participan bailes típicos de la zona como los Diablitos. También resaltan las festividades de Santo Domingo de Guzmán en Managua del 1 al 10 de agosto, muestra representativa del sincretismo religioso.

Los puntos culminantes del calendario religioso para las masas son la Semana Santa en León; La Purísima durante el 7 y 8 de diciembre, cuando se erigen elaborados altares dedicados a la Virgen María en los hogares, iglesias, centro comerciales y plazas ; y la Navidad y Año Nuevo.

"La gritería" es una fiesta religiosa popular nicaragüense en honor a la Inmaculada Concepción de María. Esta fiesta religiosa se celebra en todos los pueblos y ciudades de Nicaragua y en los lugares donde la colonia nicaragüense es importante como en Estados Unidos (particularmente en la ciudad de Miami), Costa Rica y El Salvador teniendo especial relevancia en El Viejo y León de donde es originaria.

Se celebra la noche del 7 de diciembre, víspera de la fiesta católica de la Inmaculada Concepción de María, devotos recorren las calles y visitan diferentes altares en honor a la Virgen María, en templos y casas particulares, realizando rezos, cánticos y quemando pólvora (cohetes y juegos pirotécnicos). A la vez que se grita «¿Quién causa tanta alegría?» y se responde «¡La Concepción de María!». Los habitantes de las casas reciben a los devotos con un «brindis», llamado popularmente «gorra».

La tasa de alfabetización es de un 78,0 %, por tanto el analfabetismo de la población está entre uno de las más altos del continente. El Ministerio de Educación desarrolla programas para reducir el nivel de analfabetismo y elevar el nivel de educación de los que tienen un nivel básico.

El sistema de educación en Nicaragua esta construido por cinco subsistemas. El primero es la educación básica, media y formación docente la cual esta a cargo del Ministerio de Educación. La segunda es la educación técnica y formación profesional, la cual esta a cargo del Instituto Nacional Tecnológico y el Ministerio de Educación. La tercera la educación superior, la cual esta a cargo del Consejo Nacional de Universidades. Bajo la coordinación del Ministerio de Educación, es la educación extraescolar es el cuarto subsistema. Por último está el Subsistema Educativo Autonómico Regional de la Costa Caribe Nicaragüense, se encuentra bajo la coordinación del Ministerio de Educación y el Instituto Nacional Tecnológico. 

La estructura del sistema educativo en Nicaragua se inicia por la educación preescolar, en donde niños a partir de sus cuatro años hasta los seis años pueden asistir. Dicha educación no es obligatoria en el sistema educativo, sin embargo ayuda mucho al desarrollo social de un infante. 

La educación primaria brinda atención básica a los niños de seis o siete años a los doce años de edad y a los que se encuentran en situación de extraedad hasta los 15 años. Comprende 6 grados escolares divididos en dos ciclos: educación fundamental (primeros cuatro años) y segundo ciclo (5.º y 6.º grado).La educación primaria es obligatoria y gratuita.

La educación secundaria brinda atención educativa a jóvenes y adultos preparándolos para continuar sus estudios a nivel superior o participar eficientemente en la vida del trabajo. Comprende dos niveles: el ciclo básico (3 años de duración, diploma de curso básico) y el ciclo diversificado (dos años, bachillerato en humanidades o ciencias, con proyecto de investigación documental obligatorio). La educación técnica secundaria ofrece un programa de tres años de duración a los jóvenes de 15 a 18 años para el título de técnico medio así como para los estudios de formación docente.

La educación superior está comprendida por las (públicas y privadas), los centros de educación técnica superior (institutos politécnicos y tecnológicos) y los centros de investigación y de capacitación. La educación técnica superior ofrece programas de 2 a 3 años de duración para el título de técnico superior. El título de licenciado requiere normalmente 4 a 5 años de estudios (6 años en el caso de medicina). Los programas de maestría requieren 2 años adicionales de estudios después de la licenciatura.

En la actualidad existen muchos centros de educación superior en Nicaragua, en su mayoría privados, pero existen universidades públicas que reciben el 6 % constitucional el cual es disfrutado por el estudiante que acceda a estas universidades mediante exámenes de admisión los cuales comprenden dos pruebas (Lengua y Literatura y Matemática Básica) además de una prueba psicométrica de nivel de aprendizaje, esto equivale al 60 %, el 40 % restante es obtenido por las calificaciones de 10.º y 11.º grado de la educación secundaria. El 6 % constitucional es administrado por el centro universitario y por la Unión Nacional de Estudiantes de Nicaragua (UNEN).

Centros educativos en Nicaragua para la educación superior son más de 60 en total, los cuales se ubican ya sea en la capital o en distintos departamentos. En la capital, Managua, se encuentran alrededor de 30 universidades ya sea del sector privado o público. De igual manera, los departamentos como Boaco, Carazo, Chinandega, Estelí, Granada, León, Masaya y Jinotega cuentan con otras universidades. 
A continuación, se pueden ver distintos centros educativos en Nicaragua:

En 2013, el índice de seguridad ciudadana "Índice de Ley y Orden de 2013" (Law and Order Index 2013) elaborado por la firma Gallup, posicionó a Nicaragua como el país más seguro de Latinoamérica. Este informe toma en cuenta la confianza en la Policía local. Michael Shifter, presidente del centro de estudios Diálogo Interamericano con sede en Washington, dijo a la agencia EFE, que en Nicaragua, a pesar de ser uno de los países más pobres de la región, las autoridades locales son bastante ""respetadas por mantener el orden"".

Según el Índice de Paz Global (GPI 2014), del Institute got Economics and Pieace (IEP), publicado en 2015, Nicaragua es el sexto país más seguro Latinoamérica y el Caribe ubicándose en la posición número 58 en dicho índice, que evalúa los gastos militares, relaciones con países vecinos, cantidad de homicidios, crimen organizado y respeto por los derechos humanos.

De acuerdo al Programa de las Naciones Unidas para el Desarrollo, Nicaragua es el país más seguro de Centroamérica con una tasa de homicidios de 8,7 por cada 100 mil habitantes, solamente por detrás de países latinoamericanos como Chile (2 por cada 100 000), Argentina (5,8 por cada 100 000), Uruguay (6,1 por cada 100 000), y por delante de Costa Rica (8,9 por cada 100 000) y Perú (9 por cada 100 000).

Por el contrario, los países vecinos del llamado ""triángulo del norte"", una de las zonas más violentas de América, registran por cada 100 000 habitantes:

Este informe analiza en profundidad el fenómeno de la seguridad ciudadana, estudia experiencias exitosas y propone recomendaciones concretas para mejorar las políticas públicas. Pablo Mandeville, representante Residente del Programa de las Naciones Unidas para el Desarrollo (PNUD), afirmó:

Durante la gran depresión de 1929, Nicaragua creció más rápidamente que el resto de países. También durante los años 1932 a 1935, crece más que el resto. Esta es la época que Nicaragua negocia, hasta firmar la independencia.

Entre los años 1960 y 1980, Nicaragua crece más despacio que el resto de países. A partir de estos años, todos los demás países crecen, mientras que Nicaragua decrece.

Aunque en relación al PIB la inversión es alta, en términos por habitante Nicaragua ha tenido desde 1994 hasta la actualidad,la menor inversión de América Latina.
Es el país centroamericano con menor productividad. 

Aun logrando en forma sostenida tasas de crecimiento anual del orden del 3,7 %, el PIB por habitante en el 2031 sería mucho menor al promedio actual del resto de Centroamérica.

Desde el año 1951 y durante casi 26 años la economía nicaragüense experimentó tasas de crecimiento sostenidas por encima del 6 % en términos reales, con estabilidad de precios y sin perder la paridad cambiaria del córdoba con relación al dólar, y sin caer en los excesos del modelo de sustitución de importaciones y de crecimiento hacia adentro, tan popular en la mayoría de los países latinoamericanos. A pesar de tasas de crecimiento demográfico del 2,9 % durante los años cincuenta, 2,5 % durante los sesenta, y 3,5 % en los setenta, entre 1950 y 1977 el PIB per cápita de los nicaragüenses experimentó un crecimiento promedio del 3,1 %, igual al de Costa Rica, y muy por encima del de países como El Salvador (2,1 %), Guatemala (1,9 %) y Honduras (1,1 %). Más aún, según cifras de la CEPAL y el Banco Mundial, el porcentaje de la población rural sobre la línea de la pobreza saltó del 9 % en 1960, a 30 % en 1977, mientras el porcentaje de la población urbana que dio ese mismo salto entre 1960 y 1977, fue del 36 % al 60 %.

Analizando el PIB per cápita a principios del siglo XX América Latina experimentó un importante crecimiento económico gracias al impulso que le dieron las exportaciones, aunque tuvo gran inestabilidad justo en el periodo antes de la Primera Guerra Mundial por la crisis que asolo a todo el mundo. Esta exportación se basó sobre todo en la explotación de recursos naturales.

En Nicaragua los recursos naturales son principalmente agrícolas, ya que los depósitos de material volcánico han enriquecido muchísimo su suelo, haciendo que el país sea extremadamente fértil. Por tanto es un país en el que existen gran variedad de cultivos. De esta manera, los principales productos de exportación en esta década fueron el café y los metales preciosos, concentrando casi el 80 % de todas las exportaciones.

Los mayores socios comerciales eran Estados Unidos, Francia, Alemania y Reino Unido, concentrando casi el 100 % de todas las exportaciones. Por tanto, una característica importante es el predominio de Europa occidental, sobre todo de Reino Unido y Francia, hasta la Primera Guerra Mundial, ya que este equilibrio fue desplazándose gradualmente hacia Estados Unidos.
Por tanto la conclusión que podemos sacar, es que Nicaragua era muy sensible a la coyuntura económica mundial ya que resumiendo exportaba dos bienes a cuatro países, tenía una situación muy peligrosa.

El periodo de después de la Segunda Guerra Mundial fue la semilla de la nueva época, en la que se dio inicio a la industrialización por sustitución de importaciones.

Para empezar y observar los efectos de este proceso debería de observarse la disminución del peso de las exportaciones en el PIB del país. Pero esto no fue así, al contrario cada vez el porcentaje de las exportaciones sobre el PIB es mayor.
Los efectos de esta política también podrían observarse analizando el peso de las importaciones de productos intermedios, de capital o de consumo. Podemos ver como durante estos años la importación de bienes intermedios ha sido mucho mayor que los demás, pero ha sido bastante inestable, con periodos que ha disminuido y periodos, sobre todo los últimos en los que ha aumentado, llegando a ocupar hasta un 60 % del total. Los bienes de capital han sido los que menor porcentaje han tenido, con gran disminución en la última época, suponiendo solo un 10 %. Los bienes de consumo han sido el intermedio de estos dos, siendo más cercana a los bienes de capital.

Con la nueva política de impulso hacia la industrialización uno de los objetivos que se marcaban era la de sustituir la importación de productos terminados para importar productos intermedios y acabarlos en el país. Observando la evolución de estos tipos de productos podemos ver un progreso contrario: en los primeros 10 años las importaciones de productos intermedios disminuyó mientras aumentaron las importaciones de productos de consumo y de capital, pero en la segunda década analizada la entrada de productos intermedios aumento junto con los bienes de consumo, mientras disminuyeron los bienes de capital.

Por tanto podemos deducir que en la primera década no tuvo gran repercusión la sustitución de importaciones ya que se introducción gran cantidad de productos acabados. Después de los años setenta hubo mayor porcentaje de productos intermedios, lo cual nos indica que se producían más productos terminados dentro. Aunque el aumento de la entrada de bienes de consumo indica que no se producía lo suficiente para satisfacer la demanda de los nicaragüenses.

Los ingresos siempre fueron menores que los gastos, exceptuando un par de años, siendo cada vez mayor, llegando a porcentajes tan sorprendentes como un 7 % del PIB.
Esto se debió al gran aumento del gasto público por la ampliación de responsabilidades que asumió el Estado en esta nueva política, que no pudo compensarse con un aumento similar de los ingresos. Como el desarrollo de infraestructuras, creación de bancos, mayor papel en la provisión de la educación, salud y vivienda.

Al final del siglo XX, América Latina estuvo marcada por la gran deuda externa que tuvo que afrontar. Aunque siempre ha estado endeudada con los países más ricos, la gran crisis de pagos comenzó hacia los años setenta, cuando aumentaron los precios del petróleo y empezó a llegar a los bancos de los países ricos mucho dinero, enriqueciéndose de tal manera que concedieron préstamos sin asegurarse que serían devueltos.

Es en los años ochenta cuando comienza la verdadera crisis financiera de Nicaragua. Este país, al igual que sus vecinos latinoamericanos, experimenta una caída dramática de los precios del mercado mundial para sus principales exportaciones. Ello trajo como consecuencia, junto con unas altas tasas de interés, un rápido deterioro económico. Por otro lado, dada la situación de guerra en la que se encontraba el país, la situación se volvió extrema, ya que era necesario obtener recursos económicos para satisfacer las necesidades básicas de la población que se financiaron a través del creciente gasto del estado, el subsidio del precio de los alimentos y un intercambio sobrevalorado de la moneda. Esto dio lugar a una hiperinflación incontrolada, un déficit crónico de la balanza de pagos y un aumento considerable de la deuda externa. Vemos que ya para 1980 Nicaragua tenía una deuda externa que le suponía el total de su PIB y en diez años aumentó hasta el 1200 % del PIB, siendo esta imposible de pagar.

Después de que los Estados Unidos impusieran un embargo comercial en 1985, la tasa de inflación de Nicaragua se levantó dramáticamente. El índice de 1985 según publicaciones anuales del 220 %, triplicó el año siguiente y se elevó súbitamente más al 13 000 % en 1988, la tarifa más alta para cualquier país en el hemisferio occidental en ese año. Desde el final de la guerra hace casi dos décadas, más de 350 empresas del Estado fueron privatizadas, reduciendo la inflación a partir de 13 500 % a 9,6 %, y cortando la deuda exterior por la mitad.

El córdoba fue introducido el 20 de marzo de 1912, reemplazando de esta forma al peso nicaragüense. Promulgada la Ley de Conversión Monetaria, los Billetes del Tesoro fueron cambiados gradualmente por la nueva moneda que tenía un tipo de cambio de paridad de 5 córdobas = 1 libra esterlina. El 13 de noviembre de 1931, el córdoba empezó a cotizarse a un tipo de paridad de 1,10 córdobas = 1 dólar estadounidense. Luego de sucesivas devaluaciones, el córdoba empezó a cotizarse a un tipo de paridad estable de 7 córdobas = 1 dólar estadounidense entre 1946 y abril de 1979.

El córdoba fue llamado así en conmemoración del segundo apellido del conquistador español, natural de Córdoba, Capitán Francisco Hernández de Córdoba, fundador de las ciudades de Santiago de Granada y de León Santiago de los Caballeros. Santiago de Managua es la capital de Nicaragua.

En 1987, el gobierno introdujo el nuevo córdoba (o formalmente llamado «córdoba revaluado») con valor de 1000 antiguos córdobas. Nicaragua abre los años noventa bajo la administración presidencial de Violeta Barrios de Chamorro, y el Plan del Gobierno de Salvación Nacional dentro de la estabilización y ajuste estructural, incluye la emisión del «córdoba oro» (formalmente llamado «córdoba») que a partir del 13 de agosto de 1990, pasa a convertirse en un nuevo medio circulante, expresado en la misma moneda Córdoba, con paridad al dólar estadounidense. El primer nuevo facial añadido al actual cono monetario metálico, comprendido entre los 5 centavos y los 5 córdobas, fue el de 10 córdobas, la emisión de esta moneda se produjo por primera vez el 16 de junio de 2008.

También existen monedas que circulan a nivel nacional, las de 1 y 5 córdobas (la moneda de 10 córdobas salió de circulación debido a que estas se deterioraban muy fácilmente); las otras monedas de 5, 10 y 25 centavos solo son aceptadas en los bancos.

Asimismo circula el dólar estadounidense por todo el país.



Además, a comienzos del año 2009, el gobierno ruso se interesó por crear la planta procesadora de chocolate más grande de Europa Oriental y, según los encargados del proyecto, el cacao será producido en Nicaragua; para lograr el objetivo el país deberá producir más de 50 000 toneladas anuales de cacao, esto lo convertirá en el mayor productor de cacao en América Central y el noveno mayor a nivel mundial.





El turismo en Nicaragua está creciendo, ya que actualmente tiene la segunda industria más grande de la nación, durante los 9 años pasados el turismo ha crecido el 90 % por toda la nación en un índice del 10 % anualmente. Se espera que Nicaragua que ha visto crecimiento positivo en este 2009, crezca aún más en el año 2015 gracias a que el gobierno actual está impulsando el rubro de una manera ordenada y a gran escala. Solo en el 2009 el sector turístico en Nicaragua creció un 9,8 % en relación a años anteriores.
Cada año cerca de 200 000 estadounidenses visitan Nicaragua y en el 2010 el turismo creció un 9 % llegando así a la cifra récord de un millón de turistas, sobre todo gente del negocio, turistas, y parientes que visitan a sus familias. La mayoría de los turistas que visitan Nicaragua son de los Estados Unidos, Centroamérica, Sudamérica, y Europa. Según el ministerio del turismo de Nicaragua (INTUR), la ciudad colonial de Granada es el punto preferido para los turistas. También, las ciudades de Chichigalpa, León, Masaya, Rivas, las playas de San Juan del Sur, la isla de Ometepe, el volcán Mombacho, las Islas del Maíz (Corn Island y Little Corn Island), y otras, son atracciones turísticas principales. Además, el ecoturismo y el practicar surf atraen a muchos turistas a Nicaragua.

Las atracciones principales en Nicaragua para los turistas son las playas, rutas escénicas, la arquitectura de ciudades tales como Granada, León y más recientemente el eco y agro turismo en la zona norte donde se encuentra La Ruta del Café de Matagalpa, Jinotega, Estelí, Madriz y Nueva Segovia.

Nicaragua es producto de la herencia de las culturas nahoas, chorotegas, sutiabas, lenmichies, chibchas, afrocaribeñas y europeas (principalmente hispana), que aportaron el cultivo del arte, música, baile, alfarería, cestería y la gastronomía. La cultura nicaragüense refleja la mezcla predominante de la herencia indígena americana y española. Poco se conservó definitivamente de esta última, aunque se encuentran vestigios de la misma.

Nicaragua es famosa por su gran número de fiestas y tradiciones. Gran parte de las celebraciones giran en torno a la religión católica, implantada durante la colonia española.

El colorido, la comida y bebida, la pólvora, la música, los bailes típicos, los desfiles hípicos, las corridas de toros, los promesantes y los actos religiosos, forman parte de estas fiestas que pueden extenderse por varios días, constituyen la esencia de la cultura popular nicaragüense. La fiesta religiosa más popular de todo el país es La Purísima o La gritería, dedicada a la Inmaculada Concepción de la Virgen María. Consiste en una celebración donde se crean altares con imágenes religiosas de la Virgen en los cuales la gente llega a cantar para obtener algo de lo se obsequian como: dulces típicos (gofio, enchiladas, leche burra, cajeta de leche, cajeta de coco) y frutas como la caña de azúcar y limones dulces. La fiesta de Santo Domingo de Guzmán que empieza el 1 de agosto con la Bajada de Minguito y finaliza con su retorno el 10 de agosto, es otro acto religioso masivo que atrae incluso a nicaragüenses residentes en otro países.

Las Fiestas de san Sebastián en Diriamba (19, 20, 26, 27 de enero), las fiestas de Santiago Apóstol en Jinotepe y las fiestas de San Marcos Evangelista en San Marcos, son una de las más representativas del país pues en esta se da el Tope de los Santos, el encuentro de las imágenes de Santiago, San Marcos y san Sebastián, estas fiestas patronales son una de las más coloridas pues el pueblo, demuestra su idiosincrasia con el colorido de los bailes y trajes típicos de la región. Podrá apreciar el baile de Los Diablitos, El Guegüense, El Toro Guaco, El Gigante, La Vaquita, el Baile de las Inditas y muchos más. También se celebra a San Sebastián en la ciudad de Acoyapa en el departamento de Chontales.

Las fiestas patronales de San Sebastián de Diriamba están por encima de todas las fiestas patronales en Nicaragua En ellas los nicaragüenses expresan sus más auténticas conexiones con sus raíces indígenas y españolas. Muchos de los bailes, canciones y costumbres son verdaderas tradiciones que se remontan a cientos de años cuando los primeros españoles arribaron a Nicaragua. Las fiestas no son un acto de nostalgia, pero si la integración de rituales pre-colombinos con el catolicismo y su historia es tan fascinante como sus colores, costumbres y música. Un día antes de su fiesta, el día 19 de enero, se celebra una misa y luego la imagen de San Sebastián sale de su basílica para dirigirse al poblado de Dolores, que está ubicado entre Jinotepe y Diriamba. Ahí se encuentra con sus amigos, San Marcos Evangelista (patrono de la ciudad del mismo nombre) y Santiago apóstol (patrono de Jinotepe). Este encuentro es conocido como El Tope de los Santos.

Las fiestas patronales en el municipio de San Marcos se celebran el 24 y 25 de abril en homenaje al patrono San Marcos evangelista, al cual se debe el nombre de la ciudad. Su imagen fue encontrada en las pilas de Sapasmapa, donde se iba a traer el agua. En estas fiestas locales se acostumbran los bailes folklóricos como: El Gueguense, El Toro Huaco, Las Inditas y La vaquita. El día 24, la víspera de la fiesta del santo, se realiza el famoso “Tope de los santos” en donde san marcos se reúne con San Sebastián patrono de Diriamba, Santiago patrono de Jinotepe y de reciente añadidura con la Virgen de Montserrat, patrona de La Concepción este se da por motivo de añejos enfrentamientos entre pobladores de san marcos y la concepción.

La demanda de Santiago en Jinotepe es una de las más significativas pues en esta el pueblo hace la peregrinación más larga del país, esta inicia el 29 de junio y concluye el 12 de julio, esta es conocida como la demanda mayor, esto porque hay más peregrinaciones a diferentes sitios. El 24 de julio se realiza el Tope de los Santos con las imágenes de San Sebastián (patrono de Diriamba) y San Marcos (patrono de la ciudad del mismo nombre).

Santiago Apóstol, San Sebastián Mártir y San Marcos Evangelista son por excelencia los patronos del departamento de Carazo.

Cada domingo en Nicaragua hay un desfile en las diferentes ciudades del país. Diriamba ostenta el título de ser la cuna de las Hípicas de Nicaragua, la cuna del fútbol nacional y la cuna de la comedia danzante del güegüense o macho ratón (declarado Patrimonio Intangible de la Humanidad).

Las fiestas patronales constituyen la cara y el corazón de Nicaragua, pues en estas se ve reflejado la idiosincrasia del pueblo, el fervor y el amor a su patria.
La música vernácula y autóctona nicaragüense es una de las más ricas de la región centroamericana, razón por la cual se afirma que «si México es la guitarra de América, Nicaragua es una de sus cuerdas». Pueden señalarse a destacados autores y recoliadores de la misma como Camilo Zapata, Erwin Krüger, Los Bisturices Armónicos, Los Soñadores de Saraguasca, Carlos Mejía Godoy y su hermano Luis Enrique Mejía Godoy, Los de Palacagüina, Otto de la Rocha, entre otros.

La música nicaragüense (son nica, polca y mazurca segoviana, el jamaquello y la música vernácula en general) muestran gran influencia española, alemana y francesa.

El violín de talalate es una instrumento musical derivado del violín clásico y a la vez es único de Nicaragua por sus componentes y sonido, usado por ello para sonar la música vernácula, principalmente polcas y mazurcas, lo que lo hacen un verdadero símbolo patrio como instrumento musical nacional autóctono.

Existen también otros ritmos vinculados con la conquista española, como las melodías del "Toro guaco" y "El güegüense" o "Macho ratón" (obra maestra del Patrimonio Oral e Inmaterial de la Humanidad).

La marimba, de origen africano, es un instrumento musical común a todos los países de Centroamérica y México. Es muy utilizada en Jinotepe, Masaya y en los llamados "Pueblos Blancos" (Catarina, Diriá, Diriomo, Niquinohomo) y en su variante nica, conocida como marimba de arco, que es uno de los instrumentos más populares del folclore de las regiones pacífico y central del país. En muchas ocasiones se toca acompañada de guitarras y maracas.

En cuanto a la región de la Costa Caribe, esta se caracteriza por una música propia de tipo afro caribeña, denominada Palo de Mayo, que con un ritmo bien intenso rinde homenaje a la fertilidad de la mujer y de la naturaleza como garante de la continuidad de la vida.

En los últimos años se ha desarrollado también la música popular con exponentes en diversos géneros, quienes han alcanzado popularidad internacional:

El mayor representante de la poesía nacional es Rubén Darío, quien aportó grandes innovaciones en la métrica y el estilo poético, y fue llamado el “padre del modernismo” y ”el príncipe de las letras castellanas".

Otros poetas y escritores con reconocimiento mundial son

En la pintura han destacado artistas como

En la cinematografía se destacan los cineastas

El plato principal típico nicaragüense es el gallo pinto, una mezcla elaborada de arroz y frijoles. Originaria de los esclavos africanos que migraron a la costa Caribe e hicieron esta mezcla por falta de variedad de alimentos.

Hay diferencias entre la cocina tradicional de la región del Pacífico y la de la costa del Caribe. Mientras que los principales platillos de la costa sur en el Pacífico se basan en carne de cerdo y res, frutas, verduras y el maíz blanco, la cocina de la costa norte en el Caribe hace amplio uso de los mariscos y el coco, como por ejemplo en la elaboración del gallo pinto con leche de coco, también conocido como "rice and beans".

Como en muchos otros países centroamericanos, el maíz es una de las bases de la alimentación y se cultiva en el territorio desde hace milenios; se utiliza en muchos platos extensamente consumidos, tales como el nacatamal, el Yoltamal y el indio viejo. El nacatamal es un envuelto que lleva carne de cerdo o pollo, arroz, papas en rodajas, y en algunas ocasiones incluye pasas, aceitunas, tomate, etc. Además, el maíz puede usarse como "bastimento" en la forma de tortillas cocidas en comales, es un ingrediente para bebidas tales como pinolillo y la chicha así como en los dulces, rosquillas y los postres típicos.

Los vegetales y las frutas locales han estado en uso desde periodos prehispánicos. Su influencia perdura hoy en día en la cocina de Nicaragua. Muchos de los platos de Nicaragua incluyen las frutas y los vegetales tales como
aguacate,
ayote,
caimito,
chilote,
coyolito,
elote,
granada,
granadilla,
grosella,
guaba,
guayaba,
icaco,
jocote,
mango,
mamón,
nancite,
papaya,
pipián,
plátano,
quequisque,
tamarindo,
yuca y
zapote,
además de hierbas como
culantro,
orégano y
achiote.

El Instituto Nicaragüense de Deportes es la institución encargada de impulsar, normar, coordinar, promover y fomentar la práctica de las actividades deportivas, de educación física y recreación en todo el país, así como la construcción y mantenimiento de la infraestructura necesaria para tales fines, lo mismo para la organización y buen funcionamiento de asociaciones y federaciones deportivas y recreativas, con el apoyo de la comunidad nacional e internacional.

El béisbol es el deporte más popular en Nicaragua y su equipo nacional goza de una tradición fuerte en el ámbito del béisbol aficionado mundial con varios subcampeonatos conquistados.

El béisbol nicaragüense cuenta con jugadores que han logrado ser parte de las Ligas Mayores pero el más notable es Dennis Martínez, el primer jugador del béisbol de Nicaragua en las Grandes Ligas. Él se convirtió en el primer lanzador latino que lanzó un juego perfecto, el décimo tercero en la historia de las Ligas Mayores, contra el equipo Los Angeles Dodgers el 27 de julio de 1991.

La FENIBA (Federación Nicaragüense de Béisbol Aficionado) es la entidad rectora y organiza desde el año 1970 el Campeonato Nacional de Béisbol de Primera División que actualmente lleva el nombre de «Comandante Germán Pomares Ordóñez» con la participación de equipos representativos de los 15 departamentos y 2 regiones autónomas del país. Con jugadores de estos equipos se conforma la Selección nacional de Béisbol que representa al país en las competiciones internacionales más importantes organizadas por la IBAF y la COPABE.

Desde hace unos años, un grupo de empresarios ha organizado la llamada Liga Nicaragüense de Béisbol Profesional (LNBP) de categoría Doble A, en la cual participan equipos conformados por jugadores profesionales, tanto nacionales como extranjeros, que provienen del sistema de Ligas Menores de los Estados Unidos de América o de las ligas profesionales de República Dominicana, Puerto Rico y Venezuela.

El boxeo es el segundo deporte popular en Nicaragua. El país ha tenido varios campeones del mundo en distintas categorías de peso reconocidos por los principales organismos boxísticos como la AMB, el CMB, la OMB y la FIB. El deportista nicaragüense más famoso de la historia es el boxeador Alexis Argüello, triple campeón mundial en diferentes categorías, reconocido como una leyenda del boxeo latinoamericano y mundial.

Recientemente, el fútbol ha ganado cierta masificación, especialmente entre la población más joven. El Estadio Stanley Cayasso ha servido como lugar para el béisbol y el fútbol, pero el primer estadio nacional de este deporte en Managua está actualmente en construcción.

En la Liga de Primera División los equipos con más tradición y arrastre popular son Diriangén FC (Diriamba), Real Estelí FC (Estelí) y CD Walter Ferreti (Managua).

Por primera vez en su historia, la selección nicaragüense de fútbol, tras una victoria 2:0 sobre su similar de Guatemala en la Copa de Naciones de la UNCAF en 2009, clasificó a la Copa de Oro de la CONCACAF que se celebró en los Estados Unidos de América en ese mismo año. En la fase de grupos, Nicaragua se enfrentó a las selecciones de México, Panamá y Guadalupe.

Durante el verano del año 2015, Juan Barrera se ha convertido en el primer jugador nicaragüense en firmar por un equipo europeo desde un equipo de la liga local. Ana Cate en 2014 se convirtió en la primera mujer de nacionalidad nicaragüense en jugar profesionalmente y en el continente europeo.

El surf en Nicaragua está pasando por un momento de auge y aparentemente tiene un horizonte muy a largo plazo. La historia data desde 1970 en una playa llamada "Popoyo", donde la gente que volaba desde Costa Rica podía apreciar la bella playa y sus grandes olas, un reducido grupo local de personas se mostró interesado en visitar la playa y realizar surf en la misma, pero el estado remoto de la playa hacía el acceso a la misma muy difícil y costoso, por lo que la gente usualmente acampaba en la costa de la playa. Luego en los 80, a pesar del contexto político por el que pasaba el país, aún había una pequeña afluencia de turistas dispuestos a explorar el país. Personas de renombre como George Greenough y Adrian Cojin, famoso por su aventura en motocicleta desde California hasta Suramérica en 1987.

A inicios de 1990 el ahora llamado INTUR (en ese entonces Ministerio de Turismo) empezó a promover Nicaragua como un gran destino para surfistas en todo el mundo. En 1992 una revista de surf hizo un viaje a Montelimar pero las personas en el viaje terminaron en un bote en la playa Manzanillo, ya que Montelimar no reunía las condiciones climáticas para surf, las olas son apenas de 1 metro.

En 1992 un repentino desastre natural destruyó la costa de Popoyo, un tsunami que causó la muerte de aproximadamente 300 personas. Esto hizo que Popoyo perdiera su atractivo temporalmente, pues la playa y las olas seguían siendo perfectas para el surf. A medido de los 90s, surfistas provenientes de Managua y también de áreas aledañas a Popoyo. Gradualmente Poypo volvía a atraer extranjeros, fue así como personas provenientes de Costa Rica y Miami, Florida empezaban a comprar terrenos en la costa, ahí surge el campamento de surf en Popoyo en 1999.

El fútbol americano nicaragüense también ha empezado a dar luz en este país. Existen cinco equipos que batallan en diversos campos de la ciudad de Managua. Existe una liga llamada LUFAN (Liga Universitaria de Fútbol Americano Nicaragüense) en la cual participan los Guerreros de Nicaragua, Ave María Knights, Los Lobos de UCC, Jaguares de la UAM, Santos de UNAN y recientemente se está hablando del ingreso de un sexto equipo del American College. Se juega una liga anual que dura de septiembre a diciembre, y se realizan partidos de fogueo y pequeños torneos entre enero y mayo. La liga tiene cobertura periodística por los principales diarios de circulación nacional.

"Artículo Principal:" Música de Nicaragua

La música nicaragüense es una mezcla de influencias indígenas y españolas. Los instrumentos musicales incluyen la marimba y otros comunes en América Central. La marimba de Nicaragua es interpretada por un intérprete sentado que sostiene el instrumento sobre sus rodillas, que suele ir acompañado de un violín bajo, guitarra y guitarrilla (una guitarra pequeña como una mandolina). Esta música se reproduce en funciones sociales como una especie de música de fondo.

La costa caribeña de Nicaragua es conocida por una forma animada de música de baile llamada Palo de Mayo, que es popular en todo el país. Es especialmente ruidosa y se celebra durante el festival Palo de Mayo en mayo. La comunidad garífuna (afroamericana nativa) es conocida por su música popular llamada Punta.

Nicaragua disfruta de una amplia variedad de influencias internacionales en el ámbito de la música. La bachata, merengue, salsa y cumbia han ganado protagonismo en centros culturales como Managua, León y Granada. Particularmente la cumbia se ha vuelto popular con la presentación de artistas nicaragüenses, incluido Gustavo Leyton, en la isla de Ometepe y en Managua; lo mismo ocurre con la salsa en los clubes nocturnos de Managua. Con diversas influencias, la forma de bailar salsa varía en Nicaragua. Los elementos de estilo neoyorquino y salsa cubana (Salsa Casino) han ganado popularidad en todo el país.

La danza en Nicaragua varía según la región. Las zonas rurales tienden a centrarse más en el movimiento de las caderas y las vueltas, mientras que el estilo de baile en las ciudades se centra principalmente en un juego de pies más sofisticado, además de movimientos y giros. Se pueden encontrar combinaciones de estilos de la República Dominicana y los Estados Unidos en toda Nicaragua. El baile de bachata es popular en Nicaragua, el cual ha sido ampliamente influenciado por nicaragüenses que viven en el extranjero, en ciudades que incluyen Miami, Los Ángeles, y en menor medida Nueva York. El tango también ha aparecido recientemente en ciudades culturales y con ocasión de bailes de salón.

"Artículo Principal:" Literatura nicaragüense

El origen de la literatura nicaragüense se remonta a la época precolombina. Los mitos y la literatura oral formaron la visión cosmogénica del mundo de los pueblos indígenas. Algunas de estas historias todavía se conocen en Nicaragua. Como muchos países latinoamericanos, los conquistadores españoles tuvieron gran influencia tanto en la cultura como en la literatura. La literatura nicaragüense ha sido históricamente una importante fuente de poesía en el mundo de habla hispana, con colaboradores de renombre internacional como Rubén Darío, quien es considerado como la figura literaria más importante de Nicaragua. Es llamado el "Padre del Modernismo" por liderar el movimiento literario modernista a fines del siglo XIX. Otras figuras literarias incluyen a Carlos Martínez Rivas, Pablo Antonio Cuadra, Alberto Cuadra Mejía, Manolo Cuadra, Pablo Alberto Cuadra Argüello, Orlando Cuadra Downing, Alfredo Alegría Rosales, Sergio Ramírez , Ernesto Cardenal, Gioconda Belli, Claribel Alegría y José Coronel Urtecho, Luis lgt Tórrez entre otros.

El drama satírico "El Güegüense" fue la primera obra literaria de la Nicaragua poscolombina. Escrito tanto en náhuatl azteca como en español, es considerado como una de las expresiones más distintivas de la era colonial de América Latina y como la obra maestra folclórica de Nicaragua, una obra de resistencia al colonialismo español que combina música, danza y teatro. La obra teatral fue escrita por un autor anónimo en el siglo XVI, convirtiéndola en una de las obras teatrales y de danza indígenas más antiguas del hemisferio occidental. En 2005 fue reconocido por la UNESCO como "patrimonio de la humanidad". Después de siglos de actuación popular, la obra se publicó por primera vez en un libro en 1942.




</doc>
<doc id="1983" url="https://es.wikipedia.org/wiki?curid=1983" title="Newton (unidad)">
Newton (unidad)

En física, un newton (símbolo: N) es la unidad de medida de la fuerza en el Sistema Internacional de Unidades, nombrada de esa forma por las aportaciones de Isaac Newton a la física, especialmente a la mecánica clásica. Es una unidad derivada del Sistema Internacional que se compone de las unidades básicas:

Un "newton" es la cantidad de fuerza aplicada durante un segundo a una masa de un kilogramo para que esta adquiera la velocidad de un metro por segundo respecto a la velocidad colineal que tenía previamente a la aplicación de la fuerza. Las fuerzas tienen carácter vectorial y son la base del estudio de la dinámica, una de las principales ramas que tiene la mecánica.

En 1946, la VIII Conferencia General de Pesos y Medidas (CGPM), resolución 2, normalizó la unidad de fuerza del sistema MKS de unidades como la fuerza necesaria para proporcionar una aceleración de un 1 m/s a un objeto de 1 kg de masa. La IX CGPM, de 1948, adoptó el nombre de "newton" en su resolución 7.

En la tabla que sigue se relacionan los múltiplos y submúltiplos del newton en el Sistema Internacional de Unidades.





</doc>
<doc id="1984" url="https://es.wikipedia.org/wiki?curid=1984" title="Neptuno (planeta)">
Neptuno (planeta)

Neptuno es el octavo planeta en distancia respecto al Sol y el más lejano del sistema solar. Forma parte de los denominados planetas exteriores, y dentro de estos, es uno de los gigantes helados, y es el primero que fue descubierto gracias a predicciones matemáticas. Su nombre fue puesto en honor al dios romano del mar —Neptuno—, y es el cuarto planeta en diámetro y el tercero más grande en masa. Su masa es diecisiete veces la de la Tierra y ligeramente mayor que la de su planeta «gemelo» Urano, que tiene quince masas terrestres y no es tan denso. En promedio, Neptuno orbita el Sol a una distancia de 30,1 ua. Su símbolo astronómico es ♆, una versión estilizada del tridente del dios Neptuno.

Tras el descubrimiento de Urano, se observó que las órbitas de Urano, Saturno y Júpiter no se comportaban tal como predecían las leyes de Kepler y de Newton. Adams y Le Verrier, de forma independiente, calcularon la posición de un hipotético planeta, Neptuno, que finalmente fue encontrado por Galle, el 23 de septiembre de 1846, a menos de un grado de la posición calculada por Le Verrier. Más tarde se advirtió que Galileo ya había observado Neptuno en 1612, pero lo había confundido con una estrella.

Neptuno es un planeta dinámico, con manchas que recuerdan las tempestades de Júpiter. La más grande, la Gran Mancha Oscura, tenía un tamaño similar al de la Tierra, pero en 1994 desapareció y se ha formado otra. Los vientos más fuertes de cualquier planeta del sistema solar se encuentran en Neptuno.

Neptuno tiene una composición bastante similar a la del planeta Urano, y ambos tienen composiciones que difieren mucho de los demás gigantes gaseosos, Júpiter y Saturno. La atmósfera de Neptuno, como las de Júpiter y de Saturno, se compone principalmente de hidrógeno y helio, junto con vestigios de hidrocarburos y posiblemente nitrógeno. Contiene una mayor proporción de hielos, tales como agua (), amoníaco () y metano (). Los científicos muchas veces categorizan Urano y Neptuno como gigantes helados para enfatizar la distinción entre estos y los gigantes de gas Júpiter y Saturno. El interior de Neptuno, como el de Urano, está compuesto principalmente de hielos y roca. Los rastros de metano en las regiones periféricas exteriores contribuyen para el aspecto azul vívido de este planeta.

Los dibujos de Galileo muestran que el planeta Neptuno fue observado por primera vez el 28 de diciembre de 1612, y nuevamente el 27 de enero de 1613; en ambas ocasiones, Galileo confundió Neptuno con una estrella cercana a Júpiter en el cielo nocturno.

En 1821, Alexis Bouvard publicó en sus tablas astronómicas la órbita de Urano. Las observaciones revelaron perturbaciones sustanciales, que llevaron a Bouvard a lanzar la hipótesis de que la órbita de Urano debía estar siendo perturbada por algún otro cuerpo. En 1843, John Couch Adams calculó la órbita de un octavo planeta en función de las anomalías observadas en la órbita de Urano. Envió sus cálculos a "sir" George Airy, el Astrónomo Real, quien pidió más información. Adams comenzó a redactar una respuesta, pero nunca llegó a enviarla. Urbain Le Verrier, el matemático codescubridor de Neptuno, en 1846, independientemente de Adams, publicó sus propios cálculos. En el mismo año, John Herschel comenzó a abogar por el enfoque matemático y persuadió a James Challis para buscar el planeta propuesto por Le Verrier. Después de muchas dilaciones, Challis empezó su búsqueda, reacio, en julio de 1846. Sin embargo, en el ínterin, Le Verrier había convencido a Johann Gottfried Galle para buscar el planeta. Neptuno fue descubierto esa misma noche, el 23 de septiembre de 1846, donde Le Verrier había predicho que se encontraría. Challis más tarde se dio cuenta de que había observado previamente el planeta dos veces en agosto, sin advertirlo.

A raíz del descubrimiento, hubo mucha rivalidad nacionalista entre los franceses y los británicos sobre quién tenía prioridad y merecía crédito por el descubrimiento. Finalmente surgió un consenso internacional sobre que tanto Le Verrier como Adams conjuntamente lo merecían. Sin embargo, la cuestión está siendo revaluada por los historiadores con el redescubrimiento, en 1998, de los "Documentos de Neptuno" (documentos históricos del Observatorio Real de Greenwich), que al parecer habían sido objeto de apropiación indebida por el astrónomo Olin Eggen durante casi tres décadas y sólo redescubiertos inmediatamente después de su muerte. Después de la revisión de los documentos, algunos historiadores indican que Adams no merece crédito en igualdad con Le Verrier.

Poco después de su descubrimiento, Neptuno fue llamado, simplemente, «el planeta que le sigue a Urano» o «el planeta de Le Verrier». La primera sugerencia de un nombre provenía de Galle, quien propuso el nombre de "Janus". En Inglaterra, Challis presentó el nombre de "Océano". En Francia, Le Verrier propuso que el nuevo planeta se llamara "Le Verrier", una sugerencia que no fue bien recibida fuera de Francia.

Mientras tanto, en ocasiones separadas e independientes, Adams propuso cambiar el nombre de Urano por el de "Georgia", mientras que Le Verrier sugirió "Neptuno" para el nuevo planeta. Struve salió en favor de ese nombre el 29 de diciembre de 1846, en la Academia de Ciencias de San Petersburgo. En la mitología romana, Neptuno era el dios del mar, identificado con el griego Poseidón. La demanda de un nombre mitológico parecía estar en consonancia con la nomenclatura de los otros planetas, los cuales todos recibieron nombres de deidades romanas.

El nombre del planeta se traduce literalmente como "estrella del rey del mar" en chino, coreano, japonés y vietnamita (海王星 en caracteres chinos, 해왕성 en coreano).

En la India, el nombre que se da al planeta es Varuna (devanagari: वरुण), el dios del mar en la mitología hindú/védica, el equivalente de Poseidón/Neptuno en la mitología grecorromana.

Desde su descubrimiento hasta 1930, Neptuno fue el planeta conocido más lejano. Con el descubrimiento de Plutón en 1930, Neptuno se convirtió en el penúltimo planeta, salvo durante 20 años entre 1979 y 1999 cuando Plutón cayó dentro de su órbita. No obstante, el descubrimiento del cinturón de Kuiper en 1992 llevó a muchos astrónomos a debatir si Plutón debía considerarse un planeta en su propio derecho o parte de la estructura más grande del cinturón. En 2006, la Unión Astronómica Internacional definió la palabra "planeta" por primera vez, reclasificando a Plutón como un «planeta enano» y haciendo de nuevo a Neptuno el último de los planetas del sistema solar.

El 12 de julio de 2011, al cabo de casi 165 años terrestres, Neptuno alcanzó a finalizar su primera órbita completa alrededor del Sol desde su descubrimiento en 1846, en lo que constituye un año en términos de su propia traslación.

La estructura interna de Neptuno se parece a la de Urano: un núcleo rocoso cubierto por una costra helada, oculto bajo una atmósfera gruesa y espesa. Los dos tercios interiores de Neptuno se componen de una mezcla de roca fundida, agua, amoníaco líquido y metano. El tercio exterior es una mezcla de gas caliente compuesto de hidrógeno, helio, agua y metano.

Al igual que Urano y a diferencia de Júpiter y de Saturno, la composición de la estructura interna de Neptuno se cree que está formada por capas distintas. La capa superior está formada por nubes de hidrógeno, helio y metano, que se transforman de gas en hielo a medida que aumenta la profundidad. El manto rodea un núcleo compacto de roca y hielo.

Su atmósfera comprende aproximadamente 5 % a 10 % de su masa y probablemente se extiende entre la superficie del planeta hacia profundidades correspondientes a entre 10 % y 20 % de la distancia hacia el núcleo. A esas profundidades, la atmósfera alcanza presiones de aproximadamente 10 GPa, o alrededor de 100 000 veces mayor que la de la atmósfera de la Tierra. Las concentraciones de metano, amoníaco y agua son crecientes desde las regiones exteriores hacia las regiones inferiores de la atmósfera.

Este manto que rodea al núcleo rocoso de Neptuno, es una región extremadamente densa y caliente, se cree que en su interior pueden llegar a alcanzarse temperaturas de 1700 °C a 4700 °C. Se trata de un fluido de gran conductividad eléctrica es una especie de océano de agua y amoníaco.

A 7000 km de profundidad, las condiciones generan la descomposición del metano en cristales de diamante que se precipitan en dirección al núcleo.

Al orbitar tan lejos del Sol, Neptuno recibe muy poco calor. Su temperatura en la superficie es de -218 °C (55 K). Sin embargo, el planeta parece tener una fuente interna de calor. Se piensa que puede ser un remanente del calor producido por la concreción de materia durante la creación del mismo, que ahora irradia calor lentamente hacia el espacio. Esta fuente de calor interno produce potentísimos sistemas climáticos en torno al planeta, como la Gran Mancha Oscura que la sonda "Voyager 2" descubrió a su paso por el sistema de Neptuno en 1989.

Otra de las teorías apunta a que en las profundidades de Neptuno se dan las condiciones idóneas para que los átomos de carbono se combinen en cristales, liberando calor en el proceso. Esta hipótesis plantea pues la posibilidad de que en Neptuno lluevan literalmente los diamantes.

El color de Neptuno difiere del de Urano debido a la cantidad de helio contenido en su atmósfera, que es ligeramente mayor. Debido a esto, Neptuno absorbe más luz roja del Sol que su planeta vecino, por tanto refleja un azul mucho más intenso.

La atmósfera de Neptuno tiene una estructura de bandas similar a la encontrada en los otros gigantes gaseosos. En este planeta se producen fenómenos como huracanes gigantes, con un diámetro igual al de la Tierra, y otras formaciones de nubes, incluyendo algunos extensos cirros, encima (50 km) de las nubes principales. De este modo Neptuno tiene un sistema de nubes muy activo, posiblemente más activo que el de Júpiter. La velocidad del viento en la atmósfera de Neptuno es de hasta 2000 km/h, siendo la mayor del sistema solar, y se cree que se alimentan del flujo de calor interno.

A grandes altitudes la atmósfera de Neptuno es el 80 % de hidrógeno y 19 % de helio. Una pequeña cantidad de metano también está presente. Hay prominentes bandas de absorción de metano en longitudes de onda superiores a 600 nm en la porción roja e infrarroja del espectro. Al igual que con Urano, esta absorción de la luz roja por el metano atmosférico es parte de lo que le da su color azul a Neptuno, aunque el azul vívido de Neptuno es diferente del color azul cian de Urano. Dado que el contenido de metano atmosférico de Neptuno es similar a la de Urano, se cree que algunos constituyentes atmosféricos desconocidos contribuyen al color de Neptuno.
La atmósfera de Neptuno se subdivide en dos regiones principales: la región inferior (troposfera), donde la temperatura disminuye con la altitud, y la región superior (estratosfera), donde la temperatura aumenta con la altitud. El límite entre las dos, la tropopausa neptuniana, se encuentra a una presión de 10 kilopascales (0,1 bares). La estratosfera luego da paso a la termosfera a una presión inferior, entre 1 y 10Pa (10 a 10 microbares). Más arriba, la "termosfera" transiciona gradualmente a la exosfera.

Los modelos sugieren que la troposfera de Neptuno está dividida por nubes en bandas de diferentes composiciones en función de la altitud. Las nubes de nivel superior se encuentran a presiones por debajo de un bar, donde la temperatura es adecuada para el metano se condense. Para presiones de entre uno y cinco bares (100 y 500 kPa), se cree que se formen nubes de amoníaco y sulfuro de hidrógeno. Por encima de una presión de cinco bares, las nubes pueden consistir en amoníaco, sulfuro de amonio, sulfuro de hidrógeno y agua. Nubes más profundas de hielo de agua se creen encontrar a presiones de alrededor de 50 bares (5 MPa), donde la temperatura llega a 273 K (0 °C). Debajo, se cree que se encuentran nubes de amoniaco y sulfuro de hidrógeno.

Se han observado nubes de gran altitud en Neptuno que proyectan sus sombras en la capa opaca de nubes abajo. También hay bandas de nubes de gran altitud que envuelven alrededor del planeta en latitudes constantes. Estas bandas circunferenciales tienen anchuras de 50 a 150 km y están aproximadamente entre los 50 y 110 km por encima de la capa de nubes. Estas altitudes corresponden a la capa donde se producen los fenómenos meteorológicos y climáticos, en la troposfera. Estos fenómenos no se producen en mayores altitudes, que corresponden a la estratosfera y a la termosfera. Neptuno posee un manto helado de mayor tamaño que Urano.

Los espectros electromagnéticos de Neptuno sugieren que la baja estratosfera es brumosa debido a la condensación de productos de la fotólisis ultravioleta del metano, tales como el etano () y el acetileno (). La estratosfera tiene también pequeñas cantidades de monóxido de carbono () y cianuro de hidrógeno (). La estratosfera de Neptuno es más caliente que la de Urano, debido a la elevada concentración de hidrocarburos. La abundancia de metano, etano y acetileno en el ecuador de Neptuno es entre 10 y 100 veces mayor que en los polos.

La termosfera del planeta tiene una temperatura anormalmente alta de alrededor de 750 K. El planeta está demasiado lejos del Sol para que este calor se genere por la radiación ultravioleta. Uno de los candidatos para un mecanismo de calentamiento es la interacción atmosférica con iones en el campo magnético del planeta. Otras explicaciones posibles para esta ocurrencia son ondas de gravedad desde el interior que se disipan en la atmósfera. La termosfera contiene vestigios de dióxido de carbono () y agua, que pueden haber sido depositados a partir de fuentes externas, como los meteoritos o polvo cósmico.

El campo magnético de Neptuno, como el de Urano, está bastante inclinado, 47 grados respecto al eje de rotación y desplazado al menos 0,55 radios (unos ) del centro físico. Comparando los campos magnéticos de los planetas, los investigadores piensan que la extrema orientación podría ser característica de los flujos en el interior del planeta y no el resultado de la inclinación del propio planeta o de cualquier posible inversión de los campos en ambos planetas. Este campo puede ser generado por movimientos convectivos fluidos en una cáscara esférica delgada de líquidos conductores eléctricos (probablemente una combinación de amoníaco, metano y agua) que resulta en una acción de dinamo.

El dipolo del campo magnético, en el ecuador magnético de Neptuno, es de unos 14 microteslas (0,14 G). El momento dipolar magnético de Neptuno es aproximadamente (14 μT·"R", donde "R" es el radio de Neptuno). El campo magnético de Neptuno tiene una geometría compleja, que incluye contribuciones relativamente grandes de componentes no dipolares, incluyendo un momento cuadrupolar que puede exceder la fuerza del momento dipolar. Por el contrario, la Tierra, Júpiter y Saturno sólo tienen momentos cuadrupolares relativamente pequeños, y sus campos están menos inclinados con respecto al eje polar. El gran momento cuadrupolar de Neptuno puede ser el resultado del desplazamiento en relación al centro del planeta y de las limitaciones geométricas del dinamo generador del campo magnético.

El arco de choque de Neptuno, donde la magnetósfera empieza a frenar el viento solar, se produce a una distancia de 34,9 veces el radio del planeta. La magnetopausa, donde la presión de la magnetósfera contrarresta el viento solar, se encuentra a una distancia de entre 23 y 26,5 veces el radio de Neptuno. La cola de la magnetosfera se extiende por lo menos hasta 72 radios de Neptuno, y probablemente mucho más lejos.

La meteorología de Neptuno se caracteriza por sistemas de tormentas muy dinámicos, con vientos que alcanzan velocidades de casi 600 m/s (2200 km/h), casi llegando a velocidades de flujo supersónico. Más típicamente, mediante el seguimiento del movimiento de las nubes persistentes, se ha demostrado que las velocidades del viento varían de 20 m/s en la dirección este hasta 325 m/s hacia el oeste. En la parte superior de las nubes, la velocidad de los vientos predominantes oscila entre 400 m/s a lo largo del ecuador y 250 m/s en los polos. La mayoría de los vientos en Neptuno se mueve en una dirección opuesta a la rotación del planeta. El patrón general de vientos muestra una rotación adelante en latitudes altas contra la rotación regresiva en latitudes más bajas. Se piensa que la diferencia en la dirección de flujo se debe a un "efecto pelicular" y no se debe a ningún proceso atmosférico más profundo. A los 70° S de latitud, un chorro de alta velocidad viaja a una velocidad de 300 m/s.

Neptuno se diferencia de Urano en su nivel típico de la actividad meteorológica. Voyager 2 observó fenómenos meteorológicos en Neptuno durante su sobrevuelo en 1989, pero no observó fenómenos comparables en Urano durante su sobrevuelo en 1986.

En 2007, se descubrió que la troposfera superior del polo sur de Neptuno era aproximadamente 10 K más caliente que el resto del planeta, que tiene un promedio de aproximadamente 73 K (-200 °C). La diferencia de temperatura es suficiente para que el metano, que en otras partes se congela en la troposfera, escape a la estratosfera cerca del polo. Esta región más caliente se debe a la inclinación del eje de Neptuno, que ha expuesto el polo sur al Sol durante el último cuarto del año de Neptuno, o unos 40 años terrestres. Como Neptuno se mueve lentamente hacia el lado opuesto del Sol, el polo sur se oscurecerá y el polo norte se iluminará, haciendo que la liberación de metano cambie al polo norte.

Debido a los cambios estacionales, se ha observado que las bandas de nubes en el hemisferio sur de Neptuno aumentaron en tamaño y albedo. Esta tendencia se ha visto por primera vez en 1980 y se espera que dure hasta cerca de 2020. El largo periodo orbital hace que las estaciones en Neptuno duren cuarenta años.

La nave Voyager 2, fue lanzada 16 días antes que su gemela, la Voyager 1. La trayectoria que siguió fue más lenta que la de su compañera, para poder explorar no solo Júpiter y Saturno, sino proseguir la misión hasta Urano e incluso Neptuno. Para poder alcanzar los cuatro planetas, el Voyager 2 requería un lanzamiento que le diera todo el empuje del que fuera capaz el cohete "Titán III". Y mientras que el cohete que expulsó al Voyager 1 no logró un buen lanzamiento, el del Voyager 2 funcionó a la perfección. De haberse usado el primer cohete para el Voyager 2, la nave no habría llegado a Urano y Neptuno. Por fortuna el Voyager 2 tuvo el mejor cohete.

Al llegar Voyager 2 a Neptuno, el 25 de agosto de 1989 a las 3:56 hora de Greenwich, ciento cuarenta y tres años después de su descubrimiento, poco sabíamos acerca de este planeta. El más lejano de los cuatro "planetas gigantes" está treinta veces más alejado del Sol que la Tierra y tarda 165 años en darle una vuelta al Sol. Su diámetro es unas cuatro veces más grande que el de nuestro planeta. Se le conocían dos lunas, entre ellas Tritón uno de los objetos más interesantes del sistema solar, y se sospechaba que podría tener anillos. Los datos recabados en unas cuantas horas por el Voyager 2 nos dieron más información que cerca de un siglo y medio de observaciones astronómicas desde la Tierra.

Para sorpresa de los científicos, el Voyager 2 reveló una gran mancha oscura, similar a la mancha roja de Júpiter. Se trata de un gigantesco huracán con vientos de dos mil kilómetros por hora, los más violentos en nuestro sistema solar. En la Tierra la energía que produce los vientos es suministrada por el Sol. En el caso de Neptuno, actualmente el planeta más alejado del Sol, la temperatura en la parte superior de la capa de nubes es de 210 °C bajo cero, por lo que la energía solar es insuficiente para dar lugar a los vientos observados por el Voyager 2. Al parecer el planeta sigue el proceso de contracción a partir del cual se formó, proceso que proporciona la energía suficiente para generar estos poderosos vientos. Sin embargo, la estructura general de los vientos en Neptuno no ha podido ser comprendida por los científicos.

Algunas observaciones desde la Tierra habían proporcionado evidencia de anillos alrededor de Neptuno. Esta evidencia no era concluyente ya que parecía que más que anillos se trataba de pedazos de anillos, como delgados arcos de materia girando alrededor de Neptuno. Voyager 2 encontró cuatro anillos completos, dos de ellos delgados y los otros dos anchos. Los anillos delgados se hallan cerca de la órbita de dos satélites que se cree son responsables de su estabilidad, y por ello se les denomina "lunas pastoras". Los dos anillos más anchos están formados por material sumamente opaco que refleja aproximadamente un diez milésimo de la luz que incide sobre ellos, haciendo imposible su detección desde la Tierra. La justificación en que los anillos contienen una gran cantidad de polvo, sólo puede explicarse si en la vecindad de Neptuno se albergara una importante cantidad de meteoritos, mayor que en las zonas más internas del sistema solar.

Durante más de un siglo sólo se conoció una luna de Neptuno, llamada Tritón. En 1949 Gerard Kuiper descubrió un segundo satélite, Nereida, el cual gira muy alejado del planeta. Como sucedió en los encuentros anteriores de las naves Voyager con otros planetas, Neptuno tenía más satélites "escondidos". Voyager 2 descubrió seis nuevas lunas, entre ellas Despina y Galatea, las dos lunas pastoras mencionadas anteriormente. Proteus, la mayor de las "nuevas lunas", tiene una superficie completamente cubierta de cráteres, el mayor de ellos con un tamaño de casi la mitad del de Proteus mismo. A pesar de estos hallazgos, Tritón, la luna mayor de Neptuno, y la que se conoce desde hace más de un siglo, sigue siendo la más interesante. Tritón es un objeto único en el sistema solar que bien merece un relato aparte.

En la actualidad, se conocen catorce satélites de Neptuno. El mayor de ellos es Tritón, que posee más del 99,5 % de la masa en órbita alrededor de Neptuno en sus 2700 km de diámetro. Se destaca, no solo por su gran tamaño, sino también por poseer una órbita retrógrada, algo excepcional dentro de los grandes satélites. En su superficie se han encontrado géiseres de nitrógeno. Posee forma esférica, mientras los demás satélites de Neptuno tienen una forma irregular.

Tritón es considerado un objeto del Cinturón de Kuiper capturado por la gravedad de Neptuno. Por su tamaño y aspecto debe ser muy parecido a Plutón, hoy reclasificado como un planeta enano, el cual también es un objeto del Cinturón de Kuiper. Nereida, con 340 km de diámetro, tiene la órbita más excéntrica de todos los satélites del sistema solar, su distancia a Neptuno varía entre 1 353 600 y 9 623 700 kilómetros.

Antes de la llegada de la sonda espacial Voyager 2 en 1989, sólo se conocían estos dos satélites gracias a las observaciones desde la Tierra: Tritón y Nereida. El Voyager 2 descubrió otros seis más: Náyade, Talasa, Despina, Galatea, Larisa y Proteo. Estos seis satélites son los más próximos al planeta y poseen una órbita más interior que la de Tritón. La mayoría de los satélites descubiertos miden menos de 200 km de diámetro y podrían ser restos de la luna anterior que fue destruida o desintegrada durante la captura de Tritón. Proteo es el de mayor tamaño con 400 km de diámetro.

Después de eso, se han descubierto cinco pequeñas lunas más (mediante sondeos telescópicos) entre 2002 y 2003, situadas en órbitas lejanas al planeta, las cuales han recibido los nombres de Halímedes, Sao, Laomedeia, Psámate y Neso. Todas ellas poseen órbitas con elevada inclinación y tres tienen una órbita retrógada. Ambas características, iguales a las de Tritón, hacen suponer que su origen también fue el de objetos del Cinturón de Kuiper capturados por la gravedad de Neptuno.

El 16 de julio de 2013 se anunció el descubrimiento de la luna número 14, nombrada provisionalmente 'S/2004 N 1' ahora conocida como Hipocampo.

Es el satélite más grande de Neptuno, y el más frío del sistema solar que haya sido observado por una Sonda (-235 °C). La capa Polar de Tritón tiene géiseres que arrojan nieve de nitrógeno.

Fue descubierto por William Lassell el 10 de octubre de 1846, y debe su nombre al dios Tritón de la mitología griega. Tiene un diámetro de 2707 km, lo cual lo convierte en el satélite más grande de Neptuno y el séptimo del sistema solar, además de ser la única luna de gran tamaño que posee una órbita retrógrada, es decir, una órbita cuya dirección es contraria a la rotación del planeta. A causa de esta órbita retrógrada y a su composición, similar a la de Plutón, se considera que Tritón fue capturado del Cinturón de Kuiper por la fuerza gravitacional de Neptuno.

Tritón se compone de una corteza de nitrógeno congelado sobre un manto de hielo el cual se cree cubre un núcleo sólido de roca y metal. Es de los pocos satélites del sistema solar del que se conoce que es geológicamente activo. Debido a esta actividad, su superficie es relativamente joven, y revela una compleja historia geológica a partir de misteriosos e intrincados terrenos criovolcánicos y tectónicos. Tras el paso de la sonda espacial "Voyager 2" por sus cercanías, unas enigmáticas imágenes revelaron lo que parecían ser géiseres de nitrógeno líquido emanados desde su superficie helada. Este descubrimiento cambió el concepto clásico de vulcanismo ya que, hasta entonces, se suponía que los cuerpos gélidos no deberían estar geológicamente activos.

Tritón posee una tenue atmósfera de nitrógeno con pequeñas cantidades de metano. La sonda "Voyager 2" consiguió observar una fina capa de nubes que se forman en los polos y están compuestas por hielo de nitrógeno; existe también niebla fotoquímica hasta una altura de 30 km que está compuesta por varios hidrocarburos, semejantes a los encontrados en Titán.

La temperatura en la superficie es de -235 grados Celsius, aún más baja que la temperatura media de Plutón (cerca de -229 °C); de hecho es la temperatura más baja jamás medida en el sistema solar.

Neptuno posee un sistema de anillos tenue, que guarda más semejanzas con el sistema de Júpiter que con los complejos anillos presentes en los planetas Urano y Saturno. Estos anillos están formados por partículas de hielo y silicatos además de compuestos orgánicos, producidos por la radiación de la magnetosfera, por lo que su color es muy oscuro. Los tres anillos principales son el estrecho y más exterior anillo Adams, a 63 000 km del centro de Neptuno, el anillo Le Verrier, a 53 000 km, y el anillo Galle, el más ancho de los tres, a 42 000 km. Además de estos definidos anillos existe una lámina de material extremadamente tenue que se extiende desde el anillo Le Verrier hasta el Galle y probablemente más al interior hacia Neptuno.

El primero de estos anillos fue descubierto en 1968, aunque el resultado de estas observaciones no fue publicado hasta 1977, cuando se detectaron los anillos de Urano. Pero fue la sonda espacial "Voyager 2" la que confirmó la existencia de los anillos a su paso por Neptuno en 1989. Las imágenes tomadas por la "Voyager 2" en 1989 mostraron asimismo un gran número de anillos delgados, desde el más externo, que contiene cinco prominentes arcos, llamados Coraje, Libertad, Igualdad 1, Igualdad 2 y Fraternidad. Estos arcos podrían formarse por la influencia gravitacional de Galatea, uno de los satélites de Neptuno.

Se piensa que los anillos de Neptuno, al igual que los de Urano, son relativamente jóvenes. Es probable que su edad sea significativamente menor que la del sistema solar. De igual modo, ambos están probablemente originados por la fragmentación y posterior colisión de los restos de uno o varios satélites interiores de Neptuno. Estos fragmentos actúan como fuentes de polvo y material de los anillos. A este respecto los anillos de Neptuno son similares a las bandas de polvo observadas por la "Voyager 2" entre los anillos principales de Urano.

Las últimas observaciones realizadas desde la Tierra evidencian que los anillos de Neptuno son mucho más inestables de lo que se creía, algunas partes se han deteriorado dramáticamente. Entre 2002 y 2003, Imke de Pater de la Universidad de California, Berkeley, y sus colegas utilizaron el telescopio Keck de 10 metros de Hawái para volver a mirar al anillo. Han analizado ya las imágenes y han encontrado que todos los arcos parecen haber sufrido una desintegración, mientras que uno en especial, llamado Libertad, se ha desvanecido considerablemente desde las observaciones de la Voyager. Si esta tendencia continua, Libertad habrá desaparecido dentro de 100 años.

Los resultados sugieren que sea lo que sea que está causando el deterioro de los arcos, está actuando más rápido que cualquier mecanismo que pudiera regenerarlos, ya que el sistema parece no estar en equilibrio.

Este planeta requiere algo de búsqueda. Para localizarlo hay que valerse de cartas de ubicación específicas o de software capaz de mostrar a Neptuno junto con el fondo de estrellas. Puede encontrarse con binoculares si se sabe dónde buscar. Al igual que Júpiter y Saturno se trata de un planeta gaseoso, pero al estar mucho más alejado del Sol y de la Tierra su brillo no es muy alto y sus características atmosféricas no son apreciables con telescopios de aficionado.

La mejor época para observar Neptuno es en las proximidades de la oposición. No obstante, puede observarse con mayor o menor dificultad desde unos meses antes hasta unos meses después. Para saber si es visible o no en un momento determinado, puede utilizarse un planisferio para determinar si la constelación de Capricornio se halla sobre el horizonte.

Finalmente, cabe destacar que, debido a la posición de Neptuno con respecto a la Tierra, los observadores del hemisferio Sur están favorecidos, ya que en el Norte el planeta está muy bajo sobre el horizonte.

Neptuno es invisible a simple vista, y su tamaño aparente es tan pequeño que si se observa con pocos aumentos —lo cual es necesario cuando se está buscando un objeto— es tan diminuto que parece una estrella. Por este motivo, para poder localizarlo es necesario el uso de uno de los dos métodos que se han descrito en la sección de cielo profundo:





</doc>
<doc id="1985" url="https://es.wikipedia.org/wiki?curid=1985" title="Netscape Communications Corporation">
Netscape Communications Corporation

Netscape Communications Corporation es una empresa de software mayormente conocida por ser la creadora del navegador web Netscape Navigator. Fue comprada por AOL en 1999.

La compañía fue fundada como Mosaic Communications Corporation el 4 de abril de 1994 por Marc Andreessen y Jim Clark. Fue una de las primeras compañías en trabajar con la naciente World Wide Web. Lanzó un navegador llamado Mosaic Netscape 0.9 el 13 de octubre de 1994. Este navegador fue posteriormente renombrado como Netscape Navigator.
La compañía cambió de nombre a "Netscape Communications Corporation" el 14 de noviembre de 1994.

Microsoft lanzó la versión 1.0 de Internet Explorer (IE) como parte del Pack Plus de Windows 95, según Spyglass (el desarrollador de Internet Explorer), este no fue tomado de Netscape como comúnmente se cree, pero había una parte de Mosaic en él.

Después de esto, Microsoft lanzó sucesivamente una serie de IE, y tanto Netscape como Internet Explorer fueron agregando nuevas funcionalidades, aunque éstas no siempre funcionaban correctamente.

Esto fue conocido como la guerra de navegadores, en la que ambas compañías destinaban gran cantidad de recursos en sus navegadores para que uno fuera mejor que otro, pero Internet Explorer empezó a llevar la delantera debido a las grandes cantidades de dinero invertidas en él y la decisión de incluir el navegador por defecto en Microsoft Windows. En tanto, los usuarios empezaron a reclamar por la gran cantidad de errores y problemas que estos experimentaban debido a la gran rapidez de su desarrollo, por lo que la nueva prioridad fue hacer que los navegadores funcionaran bien, en vez de agregarles nuevas funcionalidades.

En enero de 1998, cuando Netscape empezó el proyecto de código abierto Mozilla. Netscape, sabiendo que Internet Explorer era de lejos el Navegador más usado, publicó el código fuente de Netscape, con la esperanza de que se convirtiera en un popular proyecto de código abierto. Este código fue puesto bajo la Licencia Pública Netscape, la cual es similar a la GNU General Publical License, para el Communicator 4.5 Netscape se enfocó en que pudiera enviar correos electrónicos y fuera funcional para las empresas.

America Online (AOL) anunció el 24 de noviembre que adquiriría Netscape Communications en 4.200 millones de US$, aunque dicen que AOL estaba más interesado en otras propiedades de Netscape más que en el navegador en sí.

El 14 de noviembre de 2000, AOL lanzó Netscape 6.0 basado en Mozilla 0.6 (La versión 5 fue saltada). Desafortunadamente, Mozilla 0.6 estaba lejos todavía de ser estable, por lo que el efecto de Netscape 6.0 fue el alejar más aún a los usuarios de la marca Netscape. No fue hasta agosto de 2001 cuando Netscape 6.1 apareció basado en Mozilla 0.9.2 que era bastante más robusto y casi un año después llegó el Netscape 7.0 (unos días después de haber sido lanzado Netscape Communicator 4.8, mostrando que los esfuerzos de los desarrolladores de Netscape seguían divididos).

Después del caso en el que Microsoft fue hallado culpable de abuso de poder de monopolio y fue sentenciado a pagar 750 millones de US$ a AOL y a compartir algunas tecnologías, incluyendo dejar a AOL licenciar y distribuir Internet Explorer gratis por 7 años. Esto fue considerada como la "Muerte de Netscape".

El 15 de julio de 2003 AOL se deshizo de la marca Netscape, sacó el logo de su edificio y despidió a la mayoría de los programadores.

En la actualidad Netscape es sólo una marca dentro de AOL, que es usada para brindar Internet a poco costo. AOL contrató a una empresa canadiense para lanzar Netscape 8.0 basado en Mozilla Firefox.

Tom Drapeau, director de la compañía, anunció que a partir del 1 de febrero de 2008, Netscape dejaría de recibir actualizaciones. El 28 de enero se anunció que se extendería por un mes más el soporte y desarrollo. La historia de Netscape y Netscape Communications Corporation finaliza con el lanzamiento de la versión 9.0.0.6, el 20 de febrero de 2008 (aunque oficialmente finaliza el 1 de marzo de 2008)

Algunas personas piensan que esta estrategia fue para opacar a Microsoft y brindar apoyo a la Fundación Mozilla.

La línea inicial de productos Netscape:


Otros productos Netscape:



</doc>
<doc id="1987" url="https://es.wikipedia.org/wiki?curid=1987" title="Nivel de dominio de las proteínas">
Nivel de dominio de las proteínas

Nivel de dominio de las proteínas se define como una ordenación en la estructura terciaria de la molécula, en una unidad compacta de características globulares, que suele comprender entre 30-150 aminoácidos y se considera que esta conformación está determinada por la secuencia de aminoácidos. 
Es la secuencia conservada de la proteína, que puede evolucionar, funcionar y existir de forma independiente al resto de la cadena proteica. La evolución molecular utiliza los dominios como bloques de construcción que pueden combinarse para crear proteínas con funciones diferentes.

Debe diferenciarse de la estructura supersecundaria o "Motivo" que es un patrón de plegamiento característico que aparece en varias proteínas, los motivos pueden combinarse para formar las estructuras globulares compactas que se denominan dominios.

Es una ordenación de fragmentos de estructura secundaria en una estructura terciaria de proteína y se estabiliza por enlaces de hidrógeno entre cadenas.<br>
Este subconjunto del plegamiento de un polipéptido (estructura terciaria) que parece plegarse con cierta independencia del resto de la estructura.

Se puede generalizar y decir que a cada dominio le corresponde una función molecular.

Las referencias para la definición de dominios de proteínas han sido tradicionalmente las bases de datos SCOP, CATH, PDB, Pfam.



</doc>
<doc id="1988" url="https://es.wikipedia.org/wiki?curid=1988" title="Neutrón (juego)">
Neutrón (juego)

Neutrón un juego abstracto de dos personas. Requiere un tablero de 5x5, y 5 fichas para cada jugador, llamadas Electrones, blancas y negras. Además hay una ficha roja, el Neutrón, compartida por ambos jugadores.

Blanco mueve primero, y siguen jugando alternadamente. En su turno el jugador debe mover siempre dos fichas, en este orden estricto:
Tanto el Neutrón como las demás fichas, llamadas Electrones, pueden ser movidas, en cualquier dirección (horizontal, vertical o diagonal), y es obligatorio desplazarlas lo más posible en la dirección elegida, pero sin ir a ocupar ni saltar por encima de una casilla ya ocupada. Es decir, que después de elegida una dirección de desplazamiento, la ficha debe ser movida todo lo posible en tal dirección, hasta quedar su paso bloqueado por otra ficha cualquiera o por el borde del tablero.

En su turno, el jugador puede elegir una dirección de desplazamiento para el Neutrón y otra dirección para su ficha. Tanto el Neutrón como la ficha propia deben moverse al menos una casilla.
No hay capturas.

Gana el primero que consigue llevar el Neutrón a cualquier casilla libre de su línea de partida.
Un jugador pierde si se ve forzado a llevar el Neutrón hacia una casilla de la línea de partida adversaria. También pierde si la situación está bloqueada y en su turno no puede mover el Neutrón o, si después de mover el Neutrón, no puede mover ninguna de sus fichas.

"Comienza el turno de las Blancas. Ganan llevando el Neutrón a su línea de partida"


</doc>
<doc id="1989" url="https://es.wikipedia.org/wiki?curid=1989" title="Neurología">
Neurología

La neurología (del griego clásico νεῦρον, «nervio» y del sufijo -λογία, «estudio de») es la especialidad médica que trata los trastornos del sistema nervioso. Específicamente se ocupa de la prevención, diagnóstico, tratamiento y rehabilitación de todas las enfermedades que involucran al sistema nervioso central, sistema nervioso periférico y el sistema nervioso autónomo. Existe gran número de enfermedades neurológicas, las cuales pueden afectar el sistema nervioso central (cerebro y espina dorsal), el sistema nervioso periférico, o el sistema nervioso autónomo.

Thomas Willis fue un médico inglés, figura esencial en la historia de la anatomía, la fisiología y la neurología, fue pionero en sus investigaciones neuroanatómicas. En 1662 fue uno de los fundadores de la Royal Society. En su obra "Cerebri Anatome", Willis subrayó la importancia del estudio comparativo de la estructura del cerebro, determinando las semejanzas entre el cerebro del ser humano y el de otros mamíferos, así como entre el cerebro de los pájaros y los peces. Su más notable descubrimiento fue el (polígono de Willis) un círculo de arterias en la base del cerebro. En 1667 publicó "Pathologicae cerebri, et nervosi generis specimen" un importante trabajo en la patología y neurofisiología del cerebro. En este, el desarrolla una nueva teoría de la causa de la epilepsia y de otras enfermedades convulsivas y contribuyó al desarrollo de la psiquiatría.

Jean-Martin Charcot es conocido como el fundador de la neurología moderna, puso en evidencia la relación existente entre las lesiones de ciertas partes del cerebro y la afectación de las habilidades motrices. Nombró y fue el primero en describir la esclerosis múltiple, resumiendo reportes previos, adicionando sus propias observaciones clínicas y patológicas. También observó cambios cognoscitivos, describiendo a sus pacientes como si sufrieran una «marcada debilitación de la memoria» y «concepciones que se forman lentamente». Investigó las funciones de diferentes partes del cerebro y el papel que tienen las arterias en la hemorragia cerebral. Entre 1868 y 1881 los estudios de Charcot fueron un punto de referencia en el entendimiento de la enfermedad de Parkinson. Entre otros avances el realizó la distinción entre rigidez, debilidad y bradicinesia.

Fundó la escuela de neurología del Hôpital de la Salpêtrière, donde impartió clases,de las que recoge una muestra importante en su obra (en tres volúmenes) "Leçons sur les maladies du système nerveux faites à la Salpêtrière" que fueron publicadas entre 1885 y 1887. Freud fue uno de sus alumnos, así como Joseph Babinski, Gilles de la Tourette, Gilbert Ballet y Jean Leguirec inventor del método Benedicte. Médicos de muchos países acudieron a trabajar con él y recibir sus lecciones. Fueron relevantes sus investigaciones sobre la histeria.

Edward Flatau fue un neurólogo y psiquiatra polaco, cofundador de la moderna neurología de Polonia, autoridad en la fisiología y la patología de la meningitis. Cofundador de las revistas médicas "Neurologia Polska" y "Warszawskie Czasopismo Lekarskie". Estableció el principio de la localización de las fibras largas en la médula espinal en 1893, y con Sterling (1911) publicó un documento de principios en espasmo de torsión progresiva en los niños y sugirieron que la enfermedad tenía un componente genético y en 1912 escribió un libro fundamental sobre la migraña.

En 1894 publicó el "Atlas del Cerebro Humano" "y el trayecto del nervio-fibras", se basan en fotografías de larga exposición de las secciones del cerebro frescos (hasta 10 minutos para plana y 30 minutos para superficies irregulares, por medio de pequeños diafragmas). Estos estudios se llevaron a cabo en Berlín con el profesor Emanuel Mendel.


El objetivo del método clínico en la neurología es servir como base para el tratamiento o la prevención de alguna enfermedad neurológica. En la mayoría de los casos el método consiste en cinco etapas, las cuales son:

El método precedente para el diagnóstico de las enfermedades neurológicas puede verse resumido en el diagrama colocado en esta sección. Este enfoque sistemático permite identificar de manera confiable la localización y a menudo el diagnóstico preciso de la enfermedad. Cabe recordar que no siempre es necesario plantear de esta forma la solución a un problema clínico, ya que algunas enfermedades neurológicas tienen cuadros clínicos muy característicos.

Durante un examen neurológico, el neurólogo revisa la historia médica del paciente, con especial atención a sus condiciones recientes. Después le realiza un test neurológico. Normalmente, este test mide el estado mental, funciones de los nervios craneales (incluyendo la visión), fuerza, coordinación, reflejos y sensaciones. Esta información ayuda al neurólogo a determinar si el problema se halla en el sistema nervioso y su localización clínica. La localización de la patología es la clave del proceso por el cual los neurólogos desarrollan sus diferentes diagnósticos. Pueden ser necesarios estudios posteriores para confirmar el diagnóstico, y finalmente una guía y terapia apropiada.

La exploración neurológica se inicia con la exploración del paciente en tanto se practica el interrogatorio. La manera en que el paciente cuenta su enfermedad puede manifestar confusión o incoherencia del pensamiento, trastornos de la memoria o del juicio e incluso dificultades para comprender o expresar ideas. El resto de la exploración neurológica debe efectuarse como la última parte de la exploración física general a partir de, como ya se mencionó, la exploración de nervios craneales, cuello y tronco hasta terminar con las pruebas de las funciones motora, refleja y sensitiva de las extremidades superiores e inferiores.

Dicha exploración debe modificarse según el estado del paciente. Desde luego muchas partes de la exploración no pueden efectuarse en el paciente comatoso; niños pequeños y lactantes o pacientes con padecimientos psiquiátricos necesitan explorarse de maneras especiales.









Los neurólogos son responsables del diagnóstico, tratamiento y manejo de todas las condiciones mencionadas arriba. Cuando la intervención quirúrgica es requerida, el neurólogo puede referirse al paciente como "neuropaciente". En algunos países, algunas responsabilidades legales de un neurólogo pueden incluir efectuar un diagnóstico de muerte cerebral si el paciente fallece. Suelen tratar personas con enfermedades congénitas si la mayor parte de manifestaciones son neurológicas. Las punciones lumbares también pueden ser realizadas por estos profesionales. Algunos neurólogos desarrollan un interés a sub-campos en particular como las enfermedades cerebrovasculares, los trastornos del movimiento, epilepsia, cefaleas, neurología de la conducta y demencias, trastornos del sueño, control de dolor crónico, esclerosis múltiple o enfermedades neuromusculares.

Hay superposición de otras especialidades, variando de país en país e incluso en un área geográfica local. El traumatismo craneoencefálico (ETC) agudo es más comúnmente tratado por neurocirujanos, mientras que secuelas de traumas craneoencefálicos pueden ser tratados por neurólogos o especialistas en rehabilitación médica. Aunque los casos de accidente cerebrovascular (ACV) han sido tradicionalmente tratados por médicos internistas u hospitalarios, el surgimiento de neurología vascular y neurólogos intervencionistas han creado una demanda para especialistas en ACV.

La organización de JHACO centro certificado en accidentes cerebrovasculares ha incrementado el papel de los neurólogos en el tratamiento de accidentes cerebrovasculares en muchos centros de atención primaria, así como en hospitales de tercer nivel. Algunos casos de enfermedades infecciosas del sistema nervioso son tratados por especialistas en enfermedades infecciosas. La mayoría de los casos de dolor de cabeza son diagnosticados y tratados principalmente por médicos generales, al menos los casos menos severos. Del mismo modo, la mayoría de los casos de ciática y otras radiculopatías mecánicas son atendidos por médicos generales, aunque pueden ser enviados a neurólogos o cirujanos (neurocirujanos o cirujanos ortopédicos). Los trastornos del sueño generalmente son tratados en unidades multidisciplinares en las que participan neurólogos, neumólogos y psiquiatras. Una parálisis cerebral es inicialmente atendida por pediatras, pero el tratamiento puede ser transferido a un neurólogo de adultos después de que el paciente alcanza una cierta edad. 

Los neuropsicólogos clínicos son usualmente consultados para realizar una evaluación funcional del comportamiento y funciones cognitivas superiores, relacionada con la asistencia en diagnósticos diferenciales, la planificación de estrategias de rehabilitación, el registro de fuerzas y debilidades cognitivas, y la medición de cambios en el tiempo (por ejemplo, para identificar anomalías de envejecimiento o llevando el progreso de una demencia).

En algunos países como Estados Unidos y Alemania, los neurólogos se pueden especializar en neurofisiología clínica, en electroencefalografía, o en el estudio de la conducción nerviosa, en Electromiografías y potenciales evocados. En otros países, es una especialidad independiente (por ejemplo en el Reino Unido y Suecia).

A pesar de que las enfermedades mentales son consideradas por algunos de ser desórdenes neurológicos afectando el sistema nervioso central, tradicionalmente se las clasifica por separado, y son tratadas por psiquiatras. En el año 2002, en una reseña del "American Journal of Psychiatry", el profesor Joseph B. Martin, decano de Harvard Medical School y neurólogo de profesión, escribió que: «la división en dos categorías es arbitraria, a menudo influenciada por creencias más que por observaciones científicas verificables. Y el hecho de que el cerebro y la mente sean uno solo, hace que esta división sea solamente artificial de todas formas». Esta perspectiva ha propiciado un progresivo acercamiento entre ambas especialidades en las últimas dos décadas, que finalmente se materializó en 2004 con el reconocimiento, en EE. UU., de la subespecialidad en 'Neurología de la conducta y Neuropsiquiatría'. Actualmente, los médicos de esta subespecialidad se encargan del estudio, diagnóstico y tratamiento de las alteraciones de la conducta y los trastornos mentales atribuibles a enfermedades neurológicas. 

Las enfermedades neurológicas a menudo tienen manifestaciones psiquiátricas, como por ejemplo psicosis, depresión, manía y ansiedad. Estos síndromes neuropsiquiátricos son relativamente habituales en pacientes con ictus, enfermedad de Huntington, Parkinsonismos, enfermedad de Alzheimer, enfermedad por cuerpos de Lewy, enfermedad de Pick, encefalitis infecciosas, encefalitis autoinmunes, así como en algunos tipos de epilepsia, por nombrar solo algunas.

De todos los cambios vinculados con la edad tienen una enorme importancia los que tiene el sistema nervioso, algunos signos neurológicos del envejecimiento son: los signos neurooftalmológicos, pérdida de la audición perceptiva progresiva, disminución del sentido del olfato y menor extensión del gusto, reducción de la velocidad y magnitud de actividad motora, tiempo de reacción lento, trastornos de coordinación y agilidad, reducción de la fuerza muscular y adelgazamiento de los músculos, cambios de los reflejos tendinosos y finalmente trastornos del sentido de vibración en los dedos de los pies y en tobillos.
El emergente campo de la neurología cosmética señala el potencial de terapias para mejorar cuestiones como la eficacia laboral, la atención en la escuela, y una mayor felicidad en la vida personal. A pesar de todo, este campo ha dado también lugar a preguntas acerca de la neuroética o la psicofarmacología.







</doc>
<doc id="1991" url="https://es.wikipedia.org/wiki?curid=1991" title="Najadaceae">
Najadaceae

Najadaceae es una familia de liliopsidas del orden Najadales.

En algunos sistemas está incluida en la familia Hydrocharitaceae.

La familia de Najadáceas es una familia de plantas monocotiledóneas. En la clasificación tradicional (1981) que incluye 50 especies del género de las Najas.

Ellas son acuáticas herbáceas, sumergidas en las regiones frías a tropicales.

En la clasificación filogenética APG II (2003) y la clasificación filogenética APG III (2009) esta familia no existe: las plantas de esta familia se incorporan a las hydrocharitáceas.






</doc>
<doc id="1993" url="https://es.wikipedia.org/wiki?curid=1993" title="Noctiluca">
Noctiluca

La noctiluca (del latín "nox, noctis", noche + "lūcēre", brillar) es un organismo unicelular marino que la biología incluye dentro del género de los protistas dinoflagelados, dentro de la clase Noctiluciphyceae y el orden de los Noctilucales. 

Posee dos flagelos heterocontos en el sulcus y el cíngulo. Las células que componen a este protozoo son vesiculosas, frecuentemente vacuolizadas, y tanto los flagelos como los surcos son rudimentarios. Presenta asimismo un tentáculo móvil que usa para capturar presas.
En ocasiones presenta adheridas algas simbióticas. Estas algas tienen una enzima que, cuando reacciona con oxígeno, provoca un destello de luz bioluminiscente, de la que el organismo recibe su nombre.

"Noctiluca scintillans" está relacionado simbióticamente a "Pedinomonas noctilucae", un alga verde Pedinophyceae, la cual puede situarse internamente o estar adherida externamente.


</doc>
<doc id="1996" url="https://es.wikipedia.org/wiki?curid=1996" title="Narduroides salzmannii">
Narduroides salzmannii

Narduroides es un género monotípico de planta herbácea, perteneciente a la familia de las poáceas. Su única especie: Narduroides salzmannii (Boiss.) Rouy, es originaria de la región del Mediterráneo.

Son plantas anuales. Hojas con vaina de márgenes libres; lígula membranosa, entera, a veces lacerada; limbo al principio plano, después convoluto y filiforme. Inflorescencia en racimo espiciforme, rara vez ramificado en su base. Espiguillas comprimidas lateralmente, cortamente pedunculadas, con 4-6 flores hermafroditas; raquilla ciliada, desarticulándose en la madurez. Glumas 2; subiguales, más cortas que las flores, oblongas u oblongo-lanceoladas, agudas, coriáceas, con margen escarioso estrecho, glabras; la inferior con 1-3 nervios; la superior con 3-5 nervios. Lema oblonga u oblongo-lanceolada, papirácea, con dorso redondeado, 5 nervios poco marcados y margen escarioso estrecho. Pálea membranosa con 2 quillas. Lodícula lanceoladas, bilobadas. Androceo con 3 estambres. Ovario glabro. Cariopsis linear o fusiforme, trígona, glabra.

"Narduroides salzmannii" fue descrito por (Boiss.) Rouy y publicado en "Fl. France (Rouy & Foucaud)" 14: 301. 1913 
El nombre del género deriva de "Nardus", otro género de la misma familia.
El número de cromosomas es de: x = 7. 2n = 14. 2 ploidias.





</doc>
<doc id="1997" url="https://es.wikipedia.org/wiki?curid=1997" title="Nardus">
Nardus

Nardus es un género de gramíneas europeas de la familia de las poáceas. Antiguamente se incluían más especies, pero en la actualidad solamente se acepta "Nardus stricta". 



</doc>
<doc id="1999" url="https://es.wikipedia.org/wiki?curid=1999" title="Nibble">
Nibble

En arquitectura de computadoras, se conoce como nibble (a veces semi-octeto, cuarteto o medio-byte) a un conjunto de cuatro dígitos binarios (bits) o medio octeto.

Su interés se debe a que cada cifra en hexadecimal (0, 1, 2..., 9, A, B, C, D, E, F) se puede representar con un cuarteto, puesto que 2 elevado a la 4 es 16 (2=16). También el cuarteto es la base del sistema de codificación BCD.

Las arquitecturas que emplean cuatro bits como su unidad fundamental fueron usadas para la creación de los primeros microprocesadores y las calculadoras de bolsillo.

A continuación se muestra la correspondencia entre las dieciséis cifras hexadecimales y sus correspondientes representaciones binarias en forma de cuarteto ( = hexadecimal, = octal, = decimal):
De acuerdo con la anterior correspondencia, es posible codificar números decimales o hexadecimales en BCD según se muestra en los siguientes ejemplos:




Un byte completo está representado por dos dígitos hexadecimales, por tanto, es común visualizar un byte de información como dos nibbles. El nibble a menudo se llama semi-octeto o cuarteto en un contexto de redes o telecomunicaciones. En inglés hay un juego de palabras gastronómico con "nibble" (que significa mordisqueo), en comparación con "bite"/"byte" (bocado) y "bit" (trozo pequeño).

El nibble se utiliza para describir la cantidad de memoria utilizada para almacenar un dígito de un número almacenado en BCD en una mainframe de IBM. Esta técnica se utiliza para reducir los requisitos de espacio, haciendo la computación más rápida y la depuración más sencilla. Un "byte" de 8 "bits" es dividido en mitades y cada "nibble" se utiliza para almacenar un dígito. El último "nibble" de la variable se reserva para el signo. Así una variable que puede almacenar más de nueve dígitos se "empaquetaría" en 5 "bytes". Fácil de depurar resultaban los números que son legibles en un hex dump, donde dos números hexadecimales se utilizan para representar el valor de un "byte", ya que 16×16 = 2 = 256.

Históricamente, ha habido casos donde el término ""nybble"" se ha utilizado para un conjunto de "bits" inferior a 8, pero no necesariamente 4. En la línea Apple II, muchos de los drivers de control de disco se implementaron en software. La escritura de datos en disco se hizo convirtiendo páginas de 256 "bytes" en conjuntos de 5 "bits", o después en "nibbles" de 6 "bits" . Los datos cargados del disco necesitaban lo contrario. Hay que notar que el término "byte" también tiene esta ambigüedad, a la vez, "byte" significa un conjunto de "bits" pero no necesariamente 8.

Hoy, los términos ""byte"" y ""nibble"" generalmente se refieren a colecciones de 8 y 4 "bits" respectivamente y no se utilizan a menudo para otros tamaños. El "nibble" se usa también cuando aparecen los primeros microprocesadores a principios de los años 1970, ya que dichos dispositivos trabajaban con microinstrucciones las cuales estaban constituidas por grupos de 4 "bits". Sin embargo, cuando llega la comercialización de los microprocesadores, éstos ya pueden trabajar con grupos de 8 "bits" y es así como inicia la popularidad del "byte" en el ámbito de los sistemas digitales y de la informática. En algunos lenguajes, un "nibble" es llamado un "tetrade" —del griego "tetra" ("cuatro")—. Esta utilización refleja el número de "bits" —cuatro— en medio "byte" (considerando 1 "byte" = 8 "bits").





</doc>
<doc id="2000" url="https://es.wikipedia.org/wiki?curid=2000" title="Navegador web">
Navegador web

Un navegador web (en inglés, web browser) es un software, aplicación o programa que permite el acceso a la Web, interpretando la información de distintos tipos de archivos y sitios web para que estos puedan ser vistos.

La funcionalidad básica de un navegador web es permitir la visualización de documentos de texto, posiblemente con recursos multimedia incrustados. Además, permite visitar páginas web y hacer actividades en ella, es decir, enlazar un sitio con otro, imprimir, enviar y recibir correo, entre otras funcionalidades más.

Los documentos que se muestran en un navegador pueden estar ubicados en la computadora donde está el usuario y también pueden estar en cualquier otro dispositivo conectado en la computadora del usuario o a través de Internet, y que tenga los recursos necesarios para la transmisión de los documentos (un "software" servidor web).

Tales documentos, comúnmente denominados páginas web, poseen hiperenlaces o hipervínculos que enlazan una porción de texto o una imagen a otro documento, normalmente relacionado con el texto o la imagen.

El seguimiento de enlaces de una página a otra, ubicada en cualquier computadora conectada a Internet, se llama "navegación", de donde se origina el nombre navegador (aplicado tanto para el programa como para la persona que lo utiliza, a la cual también se le llama "cibernauta"). Por otro lado, "hojeador" es una traducción literal del original en inglés, "browser", aunque su uso es minoritario.

Los navegadores web se han convertido en la herramientas más popular de acceso a Internet. Por esa razón explotar sus vulnerabilidades se han convertido en un objetivo muy interesante para atacar los sistemas informáticos en los que se instalan. Es tal el interés, que se han desarrollado herramientas automáticas para explotar vulnerabilidades en los navegadores.

El primer navegador fue desarrollado por Tim Berners-Lee, en la CERN, en 1990; el navegador web llamado WorldWideWeb era bastante sofisticado y gráfico, pero solo funcionaba en estaciones NeXT.

El navegador Mosaic, que funcionaba inicialmente en entornos Unix sobre XFree86 (X11), fue el primero que se extendió debido a que pronto el National Center for Supercomputing Applications (NCSA) preparó versiones para Windows y Macintosh.

Sin embargo, Netscape Navigator al poco tiempo entró en el mercado y rápidamente superó en capacidades y velocidad al Mosaic. Este navegador tuvo la ventaja de funcionar en casi todos los sistemas Unix, y también en entornos Windows.

Internet Explorer (anteriormente Spyglass Mosaic) fue la apuesta tardía de Microsoft para entrar en el mercado y consiguió desbancar al Netscape Navigator entre los usuarios de Windows, debido a la integración del navegador con el sistema operativo, llegando a poseer cerca del 95% de la cuota de mercado. Netscape Communications Corporation liberó el código fuente de su navegador, naciendo así el proyecto Mozilla. 

Finalmente Mozilla (Mozilla Application Suite) fue reescrito desde cero tras decidirse a desarrollar y usar como base un nuevo conjunto de "widgets" multiplataforma basado en "Extensible Markup Language" (XML) llamado XUL y esto hizo que tardara bastante más en aparecer de lo previsto inicialmente, apareciendo una versión 1.0 de gran calidad y para muchísimas plataformas a la vez el 5 de junio de 2002.

El 7 de enero de 2003, Apple lanzó al mercado el navegador web Safari. Este navegador se hace con casi la totalidad del mercado de las microcomputadoras Mac, debido a su velocidad y gran cantidad de actualizaciones. Asimismo, también entra al mercado del sistema operativo Windows.

A finales de 2004 aparece en el mercado Mozilla Firefox, una rama de desarrollo de Mozilla que pretende hacerse con parte del mercado de Internet Explorer. Se trata de un navegador más ligero que su hermano mayor.

El 2 de septiembre de 2008, Google Chrome aparece en el mercado. Es el navegador web desarrollado por Google y compilado con base en componentes de código abierto como el motor de renderizado de WebKit y su estructura de desarrollo de aplicaciones ("framework"). Está disponible gratuitamente bajo condiciones de servicio específicas. El nombre del navegador deriva del término usado para el marco de la interfaz gráfica de usuario ("chrome"). En diciembre de 2011, Chrome superó a Internet Explorer 8.0 como el navegador más utilizado a nivel mundial.

El 29 de julio de 2015, Microsoft lanza Microsoft Edge como sucesor de Internet Explorer. Es una versión mejorada, modernizada y distinta de Internet Explorer con una línea de desarrollo independiente. El navegador se encuentra disponible para iOS, Android 4.4+ y Windows 10 (PC, Mobile, Xbox One, HoloLens). Tiene varias funciones únicas, como lectura de libros electrónicos () integrada, función para agregar notas web con Windows Ink y "Continuar en PC", una herramienta en la que se puede continuar la navegación web y la sincronización entre el PC y el teléfono.

La comunicación entre el servidor web y el navegador se realiza mediante el protocolo de comunicaciones "Hypertext Transfer Protocol" (HTTP), aunque la mayoría de los navegadores soportan otros protocolos como "File Transfer Protocol" (FTP), Gopher, y "Hypertext Transfer Protocol Secure" (HTTPS, una versión cifrada de HTTP basada en "Secure Socket Layer" —SSL— o Capa de Conexión Segura).

La función principal del navegador es descargar documentos HTML y mostrarlos en pantalla. En la actualidad, no solamente descargan este tipo de documentos sino que muestran con el documento sus imágenes, sonidos e incluso vídeos en transmisión en diferentes formatos y protocolos. Además, permiten almacenar la información en el disco o crear marcadores ("bookmarks") de las páginas más visitadas.

Algunos de los navegadores web más populares se incluyen en lo que se denomina una "suite" de internet o paquete de Internet. Estos paquetes de Internet disponen de varios programas integrados para leer noticias de Usenet y correo electrónico mediante los protocolos "Network News Transport Protocol" (NNTP), "Internet Message Access Protocol" (IMAP) y "Post Office Protocol" (POP).

Los primeros navegadores web solo soportaban una versión muy simple de HTML. El rápido desarrollo de los navegadores web propietarios condujo al desarrollo de dialectos no estándares de HTML y a problemas de interoperabilidad en la web. Los más modernos (como Chrome, Amaya, Firefox, Netscape, Opera e Internet Explorer 9.0) soportan los estándares HTML y XHTML (comenzando con HTML 4.01, los cuales deberían visualizarse de la misma manera en todos ellos).

Los estándares web son un conjunto de recomendaciones dadas por el World Wide Web Consortium (W3C) y otras organizaciones internacionales acerca de cómo crear e interpretar documentos basados en la web. Su objetivo es crear una web que trabaje mejor para todos, con sitios accesibles a más personas y que funcionen en cualquier dispositivo de acceso a Internet.

Existe una lista detallada de navegadores, motores de renderización y otros temas asociados en la .



Listado de los primeros navegadores con interfaz gráfica de usuario (GUI) que ya no están en desarrollo:





</doc>
<doc id="2002" url="https://es.wikipedia.org/wiki?curid=2002" title="Número">
Número

Un número, en ciencia, es una abstracción que representa una cantidad o una magnitud. En matemáticas un número puede representar una cantidad métrica o más generalmente un elemento de un sistema numérico o un número ordinal que representará una posición dentro de un orden de una serie determinada. Los números complejos se usan como una herramienta útil para resolver problemas algebraicos y que algebraicamente son un mero añadido a los números reales, que a su vez ampliaron el concepto de número ordinal. Sobre todo, un número real resuelve el problema de comparación de dos medidas, tanto si son conmensurables como inconmensurables. Ejemplo: el lado de un cuadrado es conmensurable con su perímetro, pero el lado del cuadrado con la diagonal del mismo son inconmensurables.

También, en sentido amplio, indica el carácter gráfico que sirve para representarlo; dicho símbolo gráfico de un número recibe propiamente la denominación de numeral o cifra. El que se escribe con un solo guarismo se llama dígito.

El concepto de número incluye abstracciones tales como números fraccionarios, negativos, irracionales, trascendentales, complejos, y también números de tipo más abstracto como los números hipercomplejos, que generalizan el concepto de número complejo, o los números hiperreales, los superreales y los surreales, que incluyen a los números reales como subconjunto.

Los números más conocidos son los números naturales. Denotados mediante formula_1, son conceptualmente los más simples y los que se usan para contar unidades discretas. Estos, conjuntamente con los números «negativos», conforman el conjunto de los enteros, denotados mediante formula_2 (del alemán "Zahlen", ‘números’). Los números naturales negativos permiten representar formalmente deudas, y permiten generalizar la resta de cualesquiera dos números naturales.

Otro tipo de números ampliamente usados son números fraccionarios, y representan tanto cantidades inferiores a una unidad, como números mixtos (un conjunto de unidades más una parte inferior a la unidad). Los números fraccionarios pueden ser expresados siempre como cocientes de enteros. El conjunto de todos los números fraccionarios es el conjunto de los números racionales (que usualmente se define para que incluya tanto a los racionales positivos, como a los racionales negativos y el cero). Este conjunto de números se designa como formula_3.

Los números racionales permiten resolver gran cantidad de problemas prácticos, pero desde los antiguos griegos se conoce que ciertas relaciones geométricas (la diagonal de un cuadrado de lado unidad) son números no enteros que tampoco son racionales. Igualmente, la solución numérica de una ecuación polinómica cuyos coeficientes son números racionales, usualmente es un número no racional. Puede demostrarse que cualquier número irracional puede representarse como una sucesión de Cauchy de números racionales que se aproximan a un límite numérico. El conjunto de todos los números racionales y los irracionales (obtenidos como límites de sucesiones de Cauchy de números racionales) es el conjunto de los números reales formula_4. Durante un tiempo se pensó que toda magnitud física existente podía ser expresada en términos de números reales exclusivamente. Entre los reales, existen números que no son soluciones de una ecuación polinomial o algebraica, que reciben el nombre de transcendentales. Ejemplos famosos de estos números son el número π (Pi) y el número e (este último base de los logaritmos naturales), los cuales están relacionados entre sí por la identidad de Euler.

Uno de los problemas de los números reales es que no forman un cuerpo algebraicamente cerrado, por lo que ciertos problemas no tienen solución planteados en términos de números reales. Esa es una de las razones por las cuales se introdujeron los números complejos formula_5, que son el mínimo cuerpo algebraicamente cerrado que contiene a los números reales. Además, en algunas aplicaciones prácticas así como en las formulaciones estándar de la mecánica cuántica se considera útil introducir los números complejos. Al parecer la estructura matemática de los números complejos refleja estructuras existentes en problemas físicos, por lo que en física teórica y en diversas aplicaciones los números complejos se usan en pie de igualdad con los números reales, a pesar de que inicialmente fueron considerados únicamente como un artificio matemático sin relación con la realidad física. Todos los conjuntos de números formula_6 fueron de alguna manera «descubiertos» o sugeridos en conexión con problemas planteados en problemas físicos o en el seno de la matemática elemental y todos ellos parecen tener importantes conexiones con la realidad física.

Fuera de los números reales y complejos, claramente conectados con problemas de las ciencias naturales, existen otros tipos de números que generalizan aún más y extienden el concepto de número de una manera más abstracta y responden más a creaciones deliberadas de matemáticos. La mayoría de estas generalizaciones del concepto de número se usan sólo en matemáticas, aunque algunos de ellos han encontrado aplicaciones para resolver ciertos problemas físicos. Entre ellos están los números hipercomplejos, que incluyen a los cuaterniones, útiles para representar rotaciones en un espacio de tres dimensiones, y generalizaciones de estos, como octoniones y los sedeniones.

A un nivel un poco más abstracto también se han ideado conjuntos de números capaces de tratar con cantidades infinitas e infinitesimales, como los hiperreales y los transfinitos. 

La teoría de los números trata básicamente de las propiedades de los números naturales y los enteros, mientras que las operaciones del álgebra y el cálculo permiten definir la mayor parte de los sistemas numéricos, entre los cuales están:
=Estructura =

En álgebra abstracta y análisis matemático un sistema numérico se caracteriza por una: 


Otra propiedad interesante de muchos conjuntos numéricos es que son representables mediante diagramas de Hasse, diagramas de Euler y diagramas de Venn, pudiéndose tomar una combinación de ambos en un diagrama de Euler-Venn con la forma característica de cuadrilátero y además pudiéndose representar internamente un diagrama de Hasse (es una recta). Tanto históricamente como conceptualmente, los diversos conjuntos numéricos, desde el más simple de los números naturales, hasta extensiones transcendentes de los números reales y complejos, elaboradas mediante la teoría de modelos durante el siglo XX, se construyen desde una estructura más simple hasta otra más compleja.

El estudio de ciertas propiedades que cumplen los números ha producido una enorme cantidad de tipos de números, la mayoría sin un interés matemático específico. A continuación se indican algunos:
Una vez entendido el problema de la naturaleza y la clasificación de los números, surge otro, más práctico, pero que condiciona todo lo que se va a hacer con ellos: la manera de escribirlos. El sistema que se ha impuesto universalmente es la numeración posicional, gracias al invento del cero, con una base constante. 

Más formalmente, en "Los fundamentos de la aritmética", Gottlob Frege realiza una definición de «número», la cual fue tomada como referencia por muchos matemáticos (entre ellos Bertrand Russell, cocreador de "Principia mathematica"):

Véase también que Frege, tanto como cualquier otro matemático, se ve inhabilitado para definir al número como la expresión de una cantidad, porque la simbología matemática no hace referencia necesaria a la numerabilidad, y el hecho de «cantidad» referiría a algo numerable, mientras que números se adoptan para definir la cardinalidad de, por ejemplo, los elementos que se encuentran en el intervalo abierto (0, 1), que contiene innumerables elementos (el continuo).

Peano, antes de establecer sus cinco proposiciones sobre los números naturales, explícita que supone sabida una definición (quizás debido a su «obviedad») de las palabras o conceptos "cero", "sucesor" y "número". De esta manera postula:

Sin embargo, si uno define el concepto "cero" como el número 100, y el concepto "número" como "los números mayores a 100", entonces las cinco proposiciones mencionadas anteriormente aplican, no a la idea que Peano habría querido comunicar, sino a su formalización.

La definición de número se encuentra por ende no totalmente formalizada, aunque se encuentre un acuerdo mayoritario en adoptar la definición enunciada por Frege.

Cognitivamente el concepto de número está asociado a la habilidad de contar y comparar cual de dos conjuntos de entidades similares tiene mayor cantidad de elementos. Las primeras sociedades humanas se encontraron muy pronto con el problema de determinar cual de dos conjuntos era «mayor» que otro, o de conocer con precisión cuantos elementos formaban una colección de cosas. Esos problemas podían ser resueltos simplemente contando. La habilidad de contar del ser humano, no es un fenómeno simple, aunque la mayoría de culturas tienen sistemas de cuenta que llegan como mínimo a centenares, algunos pueblos con una cultura material simple, solo disponen de términos para los números 1, 2 y 3 y usualmente usan el término «muchos» para cantidades mayores, aunque cuando es necesario usan recursivamente expresiones traducibles como «3 más 3 y otros 3» cuando es necesario.

El conteo se debió iniciar mediante el uso de objetos físicos (tales como montones de piedras) y de marcas de cuenta, como las encontradas en huesos tallados: el de Lebombo, con 29 muescas grabadas en un hueso de babuino, tiene unos de antigüedad y otro hueso de lobo encontrado en la antigua Checoslovaquia, con 57 marcas dispuestas en cinco grupos de 11 y dos sueltas, se ha estimado en unos de antigüedad. Ambos casos constituyen una de las más antiguas marcas de cuenta conocidas habiéndose sugerido que pudieran estar relacionadas con registros de fases lunares. En cuanto al origen ordinal algunas teorías lo sitúan en rituales religiosos. Los sistemas numerales de la mayoría de familias lingüísticas reflejan que la operación de contar estuvo asociado al conteo de dedos (razón por la cual los sistemas de base decimal y vigesimal son los más abundantes), aunque están testimoniado el empleo de otras bases numéricas además de 10 y 20.

El paso hacia los símbolos numerales, al igual que la escritura, se ha asociado a la aparición de sociedades complejas con instituciones centralizadas constituyendo artificios burocráticos de contabilidad en registros impositivos y de propiedades. Su origen estaría en primitivos símbolos con diferentes formas para el recuento de diferentes tipos de bienes como los que se han encontrado en Mesopotamia inscritos en tablillas de arcilla que a su vez habían venido a sustituir progresivamente el conteo de diferentes bienes mediante fichas de arcilla (constatadas al menos desde el 8000 a. C.) Los símbolos numerales más antiguos encontrados se sitúan en las civilizaciones mesopotámicas usándose como sistema de numeración ya no solo para la contabilidad o el comercio sino también para la agrimensura o la astronomía como, por ejemplo, registros de movimientos planetarios.

En conjunto, desde hace la mayoría de las civilizaciones han contado como lo hacemos hoy aunque la forma de escribir los números (si bien todos representan con exactitud los naturales) ha sido muy diversa. Básicamente la podemos clasificar en tres categorías:

En este papiro adquirido por Henry Rhind en 1858 cuyo contenido data del 2000 al 1800 a. C. además del sistema de numeración antes descrito nos encontramos con su tratamiento de las fracciones. No consideran las fracciones en general, solo las fracciones unitarias (inversas de los naturales 1/20) que se representan con un signo oval encima del número, la fracción 2/3 que se representa con un signo especial y en algunos casos fracciones del tipo formula_7. Hay tablas de descomposición de formula_8 desde n=1 hasta n=101, como por ejemplo formula_9 o formula_10, no sabemos por qué no utilizaban formula_11 pero parece que trataban de utilizar fracciones unitarias menores que formula_12.

Al ser un sistema sumativo la notación es: 1+1/2+1/4 . La operación fundamental es la suma y nuestras multiplicaciones y divisiones se hacían por «duplicaciones» y «mediaciones», por ejemplo 69×19=69×(16+2+1), donde 16 representa 4 duplicaciones y 2 una duplicación.

En las tablillas cuneiformes de la dinastía Hammurabi (1800-1600 a. C.) aparece el sistema posicional, antes referido, extendido a las fracciones, pero XXX vale para formula_13, formula_14 ó formula_15 con una representación basada en la interpretación del problema.

Para calcular recurrían, como nosotros antes de disponer de máquinas, a las numerosas tablas que disponían: De multiplicar, de inversos, de cuadrados y cubos, de raíces cuadradas y cúbicas, de potencias sucesivas de un número dado no fijo, etc. Por ejemplo, para calcular formula_16, tomaban su mejor aproximación entera formula_17, y calculaban formula_18 (una mayor y otra menor) y entonces formula_19 es mejor aproximación, procediendo igual obtenemos formula_20 y formula_21 obteniendo en la tablilla Yale-7289 2=1;24,51,10 (en base decimal 1,414222) como valor de formula_22 partiendo de formula_23 (véase algoritmo babilónico).

Realizaban las operaciones de forma parecida a hoy, la división multiplicando por el inverso (para lo que utilizan sus tablas de inversos). En la tabla de inversos faltan los de 7 y 11 que tienen una expresión sexagesimal infinitamente larga. Sí están 1/59=;1,1,1 (nuestro 1/9=0,111…) y 1/61=;0,59,0,59 (nuestro 1/11=0,0909…) pero no se percataron del desarrollo periódico.

Las circunstancias y la fecha de este descubrimiento son inciertas, aunque se atribuye a la escuela pitagórica (se utiliza el Teorema de Pitágoras). Aristóteles menciona una demostración de la inconmensurabilidad de la diagonal de un cuadrado con respecto a su lado basada en la distinción entre lo par y lo impar. La reconstrucción que realiza C. Boyer es:

Sean d:diagonal, s:lado y d/s racional que podremos escribirlo como formula_24 con p y q primos entre sí. Por el teorema de Pitágoras tenemos que formula_25 , formula_26, entonces formula_27 y por tanto formula_28 debe ser par y también p, y por tanto q impar. Al ser p par tenemos formula_29, entonces formula_30 y formula_31, entonces formula_32 es par y q también, entonces q es par e impar con lo que tenemos una contradicción.

La teoría pitagórica de "todo es número" quedó seriamente dañada.

El problema lo resolvería Eudoxo de Cnido (408-355 a. C.) tal como nos indica Euclides en el libro V de "Los elementos". Para ello estableció el Axioma de Arquímedes: "Dos magnitudes tienen una razón si se puede encontrar un múltiplo de una de ellas que supere a la otra" (excluye el 0). Después en la Definición-5 da la famosa formulación de Eudoxo: "Dos magnitudes están en la misma razón formula_33 si dados dos números naturales cualesquiera m y n, si formula_34 entonces formula_35 (definición que intercambiando el 2º y 3º términos equivale a nuestro procedimiento actual).

En el libro de J.P. Colette se hace la observación de que esta definición está muy próxima a la de número real que dará Dedekind en el siglo XIX, divide las fracciones en las formula_36 tales que formula_37 y las que no.

En cualquier sistema de numeración posicional surge el problema de la falta de unidades de determinado orden. Por ejemplo, en el sistema babilónico el número formula_38 escrito en base 60 puede ser formula_39 o formula_40. A veces, se utilizaba la posición vacía para evitar este problema 3 _ 2; pero los escribas debían tener mucho cuidado para no equivocarse.

Hacia el siglo III a. C., en Grecia, se comenzó a representar la nada mediante una "o" que significa "oudos" 'vacío', y que no dio origen al concepto de cero como existe hoy en día. La idea del cero como concepto matemático parece haber surgido en la India mucho antes que en ningún otro lugar. La única notación ordinal del viejo mundo fue la sumeria, donde el cero se representaba por un vacío.

En América, la primera expresión conocida del sistema de numeración vigesimal prehispánico data del siglo III a. C. Se trata de una estela olmeca tardía, la cual ya contaba tanto con el concepto de "orden" como el de "cero". Los mayas inventaron cuatro signos para el cero; los principales eran: el corte de un caracol para el cero matemático, y una flor para el cero calendárico (que implicaba no la ausencia de cantidad, sino el cumplimiento de un ciclo).

Brahmagupta, en el 628 de nuestra era, considera las dos raíces de las ecuaciones cuadráticas, aunque una de ellas sea negativa o irracional. De hecho en su obra es la primera vez que aparece sistematizada la aritmética (+, -, *, / , potencias y raíces) de los números positivos, negativos y el cero, que él llamaba "los bienes", "las deudas" y "la nada". Así, por ejemplo, para el cociente, establece:

"Positivo dividido por positivo, o negativo dividido por negativo, es afirmativo. Cifra dividido por cifra es nada (0/0=0). Positivo dividido por negativo es negativo. Negativo dividido por afirmativo es negativo. Positivo o negativo dividido por cifra es una fracción que la tiene por denominador (a/0=¿?)"

No solo utilizó los negativos en los cálculos, sino que los consideró como entidades aisladas, sin hacer referencia a la geometría. Todo esto se consiguió gracias a su despreocupación por el rigor y la fundamentación lógica, y su mezcla de lo práctico con lo formal.

Sin embargo el tratamiento que hicieron de los negativos cayó en el vacío, y fue necesario que transcurrieran varios siglos (hasta el Renacimiento) para que fuese recuperado.

Al parecer los chinos también poseían la idea de número negativo, y estaban acostumbrados a calcular con ellos utilizando varillas negras para los negativos y rojas para los positivos.

Varios autores del siglo XIII contribuyeron a esta difusión, destacan Alexandre de Villedieu (1225), Sacrobosco (circa 1195, o 1200-1256) y sobre todo Leonardo de Pisa (1180-1250). Este último, conocido como Fibonacci, viajó por Oriente y aprendió de los árabes el sistema posicional hindú. Escribió un libro, "El Liber abaci", que trata en el capítulo I la numeración posicional, en los cuatro siguientes las operaciones elementales, en los capítulos VI y VII las fracciones: comunes, sexagesimales y unitarias (¡no usa los decimales, principal ventaja del sistema!), y en el capítulo XIV los radicales cuadrados y cúbicos. También contiene el problema de los conejos que da la serie: formula_41 con formula_42.

No aparecen los números negativos, que tampoco consideraron los árabes, debido a la identificación de número con magnitud (¡obstáculo que duraría siglos!). A pesar de la ventaja de sus algoritmos de cálculo, se desataría por diversas causas una lucha encarnizada entre abacistas y algoristas, hasta el triunfo final de estos últimos.

Pietro Antonio Cataldi (1548-1626), aunque con ejemplos numéricos, desarrolla una raíz cuadrada en fracciones continuas como hoy:
Queremos calcular formula_43 y sea formula_16 el mayor número cuyo cuadrado es menor que formula_43 y formula_46, tenemos: formula_47 que con su notación escribía: n=a&b/2.a.&b/2.a… Así 18=4&2/8.&2/8, que da las aproximaciones 4+(1/4), 4+(8/33)…

Siendo así los números irracionales aceptados con toda normalidad, pues se les podía aproximar fácilmente mediante números racionales.

Los números complejos eran en pocos casos aceptados como raíces o soluciones de ecuaciones (M. Stifel (1487-1567), S. Stevin (1548-1620)) y por casi ninguno como coeficientes). Estos números se llamaron inicialmente "ficticii" 'ficticios' (el término "imaginario" usado actualmente es reminiscente de estas reticencias a considerarlos números respetables). A pesar de esto G. Cardano (1501-1576) conoce la regla de los signos y R. Bombelli (1526-1573) las reglas aditivas a través de "haberes" y "débitos", pero se consideran manipulaciones formales para resolver ecuaciones, sin entidad al no provenir de la medida o el conteo.

Cardano en la resolución del problema "dividir 10 en dos partes tales que su producto valga 40" obtiene como soluciones formula_48 (en su notación 5p:Rm:15) y formula_49 (en su notación 5m:Rm:15), soluciones que consideró meras manipulaciones "«sutiles, pero inútiles»".

En la resolución de ecuaciones cúbicas con la fórmula de Cardano-Tartaglia, aunque las raíces sean reales, aparecen en los pasos intermedios raíces de números negativos. En esta situación Bombelli dice en su "Álgebra" que tuvo lo que llamó ""una idea loca"", esta era que los radicales podían tener la misma relación que los radicandos y operar con ellos, tratando de eliminarlos después. En un texto posterior en 20 años utiliza p.d.m. formula_50 para formula_51 y m.d.m. formula_52 para formula_53 dando las reglas para operar con estos símbolos añadiendo que siempre que aparece una de estas expresiones aparece también su conjugada, como en las ecuaciones de 2º grado que resuelve correctamente. Da un método para calcular formula_54.

Aunque se encuentra un uso más que casual de las fracciones decimales en la Arabia medieval y en la Europa renacentista, y ya en 1579 Vieta (1540-1603) proclamaba su apoyo a éstas frente a las sexagesimales, y las aceptaban los matemáticos que se dedicaban a la investigación, su uso se generalizó con la obra que Simon Stevin publicó en 1585 "De Thiende (La Disme)". En su definición primera dice que la Disme es un especie de aritmética que permite efectuar todas las cuentas y medidas utilizando únicamente números naturales. En las siguientes define nuestra parte entera: "cualquier número que vaya el primero se dice comienzo y su signo es (0), (primera posición decimal 1/10). El siguiente se dice primera y su signo es (1) (segunda posición decimal 1/100). El siguiente se dice segunda (2)". Es decir, los números decimales que escribe: 0,375 como 3(1)7(2)5(3), ó 372,43 como 372(0)4(1)3(2). Añade que "no se utiliza ningún número roto (fracciones), y el número de los signos, exceptuando el 0, no excede nunca a 9".

Esta notación la simplificó Joost Bürgi (1552-1632) eliminando la mención al orden de las cifras y sustituyéndolo por un «.» en la parte superior de las unidades 372·43, poco después Magini (1555-1617) usó el «.» entre las unidades y las décimas: 372.43, uso que se generalizaría al aparecer en la "Constructio" de Napier (1550-1617) de 1619. La «,» también fue usada a comienzos del siglo XVII por el holandés Willebrord Snellius: 372,43.

Su antecedente es un método de demostración, llamado inducción completa, por aplicación reiterada de un mismo silogismo que se extiende indefinidamente y que usó Maurolyco (1494-1575) para demostrar que la suma de los primeros formula_55 números naturales impares es el cuadrado del formula_55-ésimo término, es decir formula_57. Pascal (1623-1662) usó el método de inducción matemática, en su formulación abstracta, tal y como lo conocemos hoy para probar propiedades relativas al triángulo numérico que lleva su nombre. La demostración por inducción consta siempre de dos partes: el paso base y el paso inductivo, los cuales se describen a continuación en notación moderna:

Si formula_58 es un subconjunto de los números naturales (denotado por formula_59) donde cada elemento formula_55 cumple la propiedad formula_61 y se tiene que:

entonces formula_67, es decir que todos los números naturales formula_55 tienen la propiedad formula_61.

De manera intuitiva se entiende la inducción como un efecto dominó. Suponiendo que se tiene una fila infinita de fichas de dominó, el paso base equivale a tirar la primera ficha; por otro lado, el paso inductivo equivale a demostrar que si alguna ficha se cae, entonces la ficha siguiente también se caerá. La conclusión es que se pueden tirar todas las fichas de esa fila.

Esta interpretación suele ser atribuida a Gauss (1777-1855) que hizo su tesis doctoral sobre el teorema fundamental del álgebra, enunciado por primera vez por Harriot y Girard en 1631, con intentos de demostración realizados por D’Alembert, Euler y Lagrange, demostrando que las pruebas anteriores eran falsas y dando una demostración correcta primero para el caso de coeficientes, y después de complejos. También trabajó con los números enteros complejos que adoptan la forma formula_70, con formula_71 y formula_72 enteros. Este símbolo formula_73 para formula_74 fue introducido por primera vez por Euler en 1777 y difundido por Gauss en su obra "Disquisitiones arithmeticae" de 1801.

La representación gráfica de los números complejos había sido descubierta ya por Caspar Wessel (1745-1818) pero pasó desapercibida, y así el plano de los números complejos se llama «"plano de Gauss"» a pesar de no publicar sus ideas hasta 30 años después.

Desde la época de Girard (mitad siglo XVII) se conocía que los números reales se pueden representar en correspondencia con los puntos de una recta. Al identificar ahora los complejos con los puntos del plano los matemáticos se sentirán cómodos con estos números, "ver es creer".

La distinción entre números irracionales algebraicos y trascendentes data del siglo XVIII, en la época en que Euler demostró que formula_75 y formula_76 son irracionales y Lambert que lo es π. Los trabajos de Legendre sobre la hipótesis de que π podía no ser raíz de una ecuación algebraica con coeficientes racionales, señalaron el camino para distinguir distintos tipos de irracionales. Euler ya hacía esta distinción en 1744 pero habría que esperar casi un siglo para que se estableciera claramente la existencia de los irracionales trascendentes en los trabajos de Liouville, Hermite y Lindeman.

Liouville (1809-1882) demostró en 1844 que todos los números de la forma formula_77 (p. ej., 0,101001…) son trascendentes.

Hermite (1822-1901) en una memoria "Sobre la función exponencial" de 1873 demostró la trascendencia de formula_75 probando de una forma muy sofisticada que la ecuación: formula_79 no puede existir.

Lindeman (1852-1939) en la memoria "Sobre el número formula_75" de 1882 prueba que el número e no puede satisfacer la ecuación: formula_81 con formula_82 y formula_83 algebraicos, por tanto la ecuación formula_84 no tiene solución para x algebraico, pero haciendo formula_85 tenemos formula_86, entonces formula_87 no puede ser algebraico y como i lo es entonces π es trascendente.

El problema 7 de Hilbert (1862-1943) que plantea si formula_88, con a algebraico distinto de cero y de uno, y b irracional algebraico, es trascendente fue resuelto afirmativamente por Gelfond (1906-1968) en 1934. Pero no se sabe si son trascendentes o no: formula_89,formula_90, formula_91, … Sin embargo, e y 1/e sí que son trascendentes.

Hasta mediados del siglo XIX los matemáticos se contentaban con una comprensión intuitiva de los números y sus sencillas propiedades no son establecidas lógicamente hasta el siglo XIX. La introducción del rigor en el análisis puso de manifiesto la falta de claridad y la imprecisión del sistema de los números reales, y exigía su estructuración lógica sobre bases aritméticas.

Bolzano había hecho un intento de construir los números reales basándose en sucesiones de números racionales, pero su teoría pasó desapercibida y no se publicó hasta 1962. Hamilton hizo un intento, haciendo referencia a la magnitud tiempo, a partir de particiones de números racionales:

Pero en el mismo año 1872 cinco matemáticos, un francés y cuatro alemanes, publicaron sus trabajos sobre la aritmetización de los números reales:






La construcción de obtención de los números complejos a partir de los números reales, y su conexión con el grupo de transformaciones afines en el plano sugirió a algunos matemáticos otras generalizaciones similares conocidas como números hipercomplejos. En todas estas generalizaciones los números complejos son un subconjunto de estos nuevos sistemas numéricos, aunque estas generalizaciones tienen la estructura matemática de álgebra sobre un cuerpo, pero en ellos la operación de multiplicación no es conmutativa.

La teoría de conjuntos sugirió muchas y variadas formas de extender los números naturales y los números reales de formas diferentes a como los números complejos extendían al conjunto de los números reales. El intento de capturar la idea de conjunto con un número no finito de elementos llevó a la aritmética de números transfinitos que generalizan a los naturales, pero no a los números enteros. Los números transfinitos fueron introducidos por Georg Cantor hacia 1873.

Los números hiperreales usados en el análisis no estándar generalizan a los reales pero no a los números complejos (aunque admiten una complejificación que generalizaría también a los números complejos). Aunque parece los números hiperreales no proporcionan resultados matemáticos interesantes que vayan más allá de los obtenibles en el análisis real, algunas demostraciones y pruebas matemáticas parecen más simples en el formalismo de los números hiperreales, por lo que no están exentos de importancia práctica.


Una de las formas más frecuentes de representar números por escrito consiste en un «conjunto finito de símbolos» o dígitos que, adecuadamente combinados, permiten formar cifras que funcionan como representaciones de números (cuando una secuencia específica de signos se emplea para representar un número se la llama numeral, aunque una cifra también puede representar simplemente un código identificativo).

Tanto las lenguas naturales como la mayor parte de sistemas de representación de números mediante cifras, usan un inventario finito de unidades para expresar una cantidad mucho mayor de números. Una manera importante de lograr eso es el uso de una base aritmética en esos sistemas un número se expresa en general mediante suma o multiplicación de números. Los sistemas puramente aritméticos recurren a bases donde cada signo recibe una interpretación diferente según su posición. Así en el siguiente numeral arábigo (base 10):

El <8> por estar en última posición representa unidades, el <6> representa decenas, el <5> centenas, el <3> millares y el <1> decenas de millares. Es decir, ese numeral representara el número:

Muchas lenguas del mundo usan una base decimal, igual que el sistema arábigo, aunque también es frecuente que las lenguas usen sistemas vigesimales (base 20). De hecho la idea de usar un número finito de dígitos o signos para representar números arbitrariamente grandes funciona para cualquier base "b", donde b es un número entero mayor o igual que 2. Los ordenadores frecuentemente usan para sus operaciones la base binaria ("b" = 2), y para ciertos usos también se emplea la base octal ("b" = 8 ) o hexadecimal ("b" = 16). La base coincide con el número de signos primarios, si un sistema posicional tiene "b" símbolos primarios que designaremos por formula_96, el numeral:

Designará al número:

Las lenguas naturales usan nombres o numerales para los números frecuentemente basados en el contaje mediante dedos, razón por la cual la mayoría de las lenguas usan sistemas de numeración en base 10 (dedos de las manos) o base 20 (dedos de manos y pies), aunque también existen algunos sistemas exóticos que emplean otras bases.



</doc>
<doc id="2006" url="https://es.wikipedia.org/wiki?curid=2006" title="Número racional">
Número racional

Los números racionales son todos los números que pueden representarse como el cociente de dos números enteros o, más exactamente, un entero y un natural positivo; es decir, una fracción común formula_1 con numerador formula_2 y denominador formula_3 distinto de cero. El término «racional» alude a una fracción o parte de un todo. El conjunto de los números racionales se denota por Q (o bien formula_4, en negrita de pizarra) que deriva de «cociente» ("Quotient" en varios idiomas europeos). Este conjunto de números incluye a los números enteros (formula_5) y a los números fraccionarios (que es el cociente de dos números naturales, obviando la división por cero, actualmente sin definir), y es un subconjunto de los números reales (formula_6).

La escritura decimal de un número racional es, o bien un número decimal finito, o bien semiperiódico. Esto es cierto no solo para números escritos en base 10 (sistema decimal); también lo es en base binaria, hexadecimal o cualquier otra base entera. Recíprocamente, todo número que admite una expansión finita o periódica (en cualquier base entera) es un número racional.

Un número real que no es racional se llama número irracional; la expresión decimal de los números irracionales, a diferencia de los racionales, es infinita "aperiódica".

En sentido estricto, número racional es el conjunto de todas las fracciones equivalentes a una dada; de todas ellas, se toma como "representante canónico" de dicho número racional a la fracción irreducible. Las fracciones equivalentes entre sí –número racional– son una clase de equivalencia, resultado de la aplicación de una relación de equivalencia sobre formula_5.

Los egipcios calculaban la resolución de problemas prácticos utilizando fracciones cuyos denominadores son enteros positivos; son los primeros números racionales utilizados para representar las «partes de un entero», por medio del concepto de "recíproco de un número entero".

Los matemáticos de la antigua Grecia consideraban que dos magnitudes eran "conmensurables" si era posible encontrar una tercera tal que las dos primeras fueran múltiplos de la última, es decir, era posible encontrar una "unidad" común para la que las dos magnitudes tuvieran una medida entera. El principio pitagórico de que todo número es un cociente de enteros, expresaba en esta forma que cualesquiera dos magnitudes deben ser conmensurables, luego números racionales.

Etimológicamente, el hecho de que estos números se llamen racionales corresponde a que son la razón de dos números enteros, palabra cuya raíz proviene del latín "ratio", y esta a su vez del griego λόγος (razón), que es como llamaban los matemáticos de la antigua Grecia a estos números. La notación formula_4 empleada para nombrar el conjunto de los números racionales proviene de la palabra italiana "quoziente", derivada del trabajo de Giuseppe Peano en 1895.y.

Cualquier entero "n" se puede expresar como el número racional "n"/1 debido a eso se escribe frecuentemente formula_9 (técnicamente, se dice que los racionales contienen un subanillo isomorfo al anillo de los números enteros).

Si se cumple:

Cuando ambos denominadores son positivos:

Si cualquiera de los denominadores es negativo, las fracciones primero deben convertirse en otras equivalentes con denominadores positivos, siguiendo las ecuaciones:

y

A las operaciones de suma, resta, multiplicación y división se las llama operaciones racionales.

Se define la suma o adición de dos números racionales a la operación que a todo par de números racionales le hace corresponder su suma:

para poder sumar números fraccionarios tiene que hacer los siguientes pasos

con igual denominador
1.se suman los numeradores y los denominadores se dejan

con diferente denominador
1.se saca el mínimo común múltiplo de los denominadores y luego se multiplican incluyendo el numerador

La operación que a todo par de números racionales le hace corresponder su diferencia se llama resta o diferencia y se la considera "operación inversa" de la suma.

La multiplicación o producto de dos números racionales:

Se define la división o cociente de dos racionales "r" entre "s" distinto de 0, al producto formula_21. En otra notación,

Es una operación totalmente definida, pero se asume que es una operación inversa de la multiplicación que resuelve la ecuación "s"·"x"="r", "s"≠0.

Los inversos aditivo y multiplicativo existen en los números racionales:

Todo número real admite una representación decimal ilimitada, esta representación es única si se excluyen secuencias infinitas de "9" (como por ejemplo el 0,9 periódico).
Utilizando la representación decimal, todo número racional puede expresarse como un número decimal finito (exacto) o periódico y viceversa. De esta manera, el "valor decimal" de un número racional, es simplemente el resultado de dividir el numerador entre el denominador.

Los números racionales se caracterizan por tener una escritura decimal que solo puede ser de tres tipos:

Periódica mixta: no toda la parte decimal se repite. Ejemplo:

De la misma manera se aplica la representación de un número racional en un sistema de numeración posicional en bases distintas de diez.

En un sistema de numeración posicional de base racional, las fracciones irreducibles cuyo denominador contiene factores primos distintos de aquellos que factorizan la base no tienen representación finita.

Por ejemplo, en base 10, un racional tendrá un desarrollo finito si y solo si el denominador de su fracción irreducible es de la forma formula_27 (formula_28 y formula_29 enteros), así como en base duodecimal es infinita y recurrente la representación de todas aquellas fracciones cuyo denominador contiene factores primos distintos de 2 y 3.

El conjunto de los números racionales puede construirse a partir del conjunto de fracciones cuyo numerador y cuyo denominador son números enteros. El conjunto de los números racionales no es directamente identificable con el conjunto de fracciones, porque a veces un número racional puede representarse por más de una fracción, por ejemplo:

Para poder definir los números racionales debe definirse cuando dos fracciones diferentes son equivalentes y por tanto representan el mismo número racional.

Formalmente cada número racional puede representarse como la clase de equivalencia de un par ordenado de enteros ("a","b"), con "b"≠0, con la siguiente relación de equivalencia:

donde el espacio de equivalencia de clases es el espacio cociente formula_31. Las operaciones de suma y multiplicación se definen como

Se verifica que las dos operaciones definidas son compatibles con la relación de equivalencia, indicando de manera que formula_4 se puede definir como el conjunto cociente formula_31, con la relación de equivalencia descrita antes.

Téngase en cuenta que las operaciones definidas no son más que la formalización de las operaciones habituales entre fracciones:

Se denota como [("a","b")] a la clase de equivalencias que corresponde con las distintas representaciones de un mismo número racional formula_36, con "k"≠0, en forma de fracción. Es decir :

Se toma como representante canónico el par ("a","b") tal que mcd("a","b")= 1. Cualquier otro par se puede usar en el caso de operaciones. Por ejemplo, formula_38 es la clase de equivalencia del número racional formula_39.

Con las operaciones anteriores, formula_4 es un cuerpo, donde la clase (0,1) desempeña el papel de cero, y la clase (1,1) de uno. El elemento opuesto de la clase ("a","b") es la clase (-"a","b"). Además, si "a"≠0, la clase ("a","b") es distinta de cero, luego ("a","b") es invertible (inverso multiplicativo) y su inverso corresponde a la clase ("b","a").

También se puede definir una orden total en formula_4 de la siguiente manera:

El conjunto de los números racionales puede también construirse como el cuerpo de cocientes de los números enteros, esto es,

El conjunto de los números racionales formula_4 equipado con las operaciones de suma y producto cumple las propiedades conmutativa, asociativa y distributiva, es decir:

Existen los elementos neutros para la suma y producto. Para la suma, el "cero", denotado por 0, ya que formula_48 para cualquier formula_49. Para el producto es el 1, que puede ser representado por formula_50, con "n" distinto de 0, ya que formula_51.

Posee elementos simétricos para las operaciones de suma y producto. Así, el elemento simétrico respecto de la suma para cualquier número racional formula_52 es formula_53, llamado "elemento opuesto", puesto que formula_54. Lo mismo ocurre en el caso del elemento simétrico respecto del producto, para todo número racional formula_55, distinto de 0, existe formula_56, llamado "inverso multiplicativo" tal que formula_57.

El conjunto formula_58, con las operaciones de adición y multiplicación definidas más arriba, conforma un cuerpo conmutativo, el cuerpo de cocientes de los enteros formula_59.

Los racionales son el menor cuerpo con característica nula. Cualquier otro cuerpo de característica nula contiene una copia de formula_58.

La clausura algebraica de formula_58, es el conjunto de los números algebraicos.

Los racionales forman un dominio de factorización única ya que todo racional diferente de cero puede descomponerse en la forma: formula_62 donde formula_63 son números enteros primos, formula_64 (siendo algunos de ellos negativos si "q" no es entero) y formula_65. Por ejemplo formula_66.

El conjunto de los números racionales es numerable, es decir que existe una biyección entre formula_67 y formula_58 (tienen la misma cantidad de elementos). El conjunto de los números reales no es numerable (la parte "no-denombrable" de los reales, la constituyen los números irracionales).


Sea formula_29 un número primo y para todo entero no nulo formula_74, sea formula_75 donde formula_76 es la mayor potencia de formula_77 que divide a formula_74.

Si formula_79 y para cada número racional formula_80 , formula_81 entonces la función multiplicativa formula_82 define una métrica sobre formula_58.

El espacio métrico formula_84 no es completo, su completitud es el cuerpo de los números p-ádicos formula_85. El teorema de Ostrowski asegura que todo valor absoluto no-trivial sobre formula_58 es equivalente ya sea al valor absoluto usual, o al valor absoluto "p"-ádico.

Esto en representaciones algebraicas y no en representaciones aritméticas.



</doc>
<doc id="2010" url="https://es.wikipedia.org/wiki?curid=2010" title="Número irracional">
Número irracional

En matemáticas, un número irracional es un número que no puede ser expresado como una fracción formula_1, donde formula_2 y formula_3. Es cualquier número real que no es racional, y su expresión decimal no es ni exacta ni periódica.

Un "decimal infinito" (es decir, con infinitas cifras) "aperiódico", como = 2,64575131106459059050161... no puede representar un número racional. A tales números se les nombra "números irracionales". Esta denominación significa la imposibilidad de representar dicho número como "razón" de dos números enteros. El número pi (formula_4), número e y el número áureo (formula_5) son otros ejemplos de números irracionales.

Dado que en la práctica de medir la longitud de un segmento de recta solo puede producir como resultado un número fraccionario, en un inicio, los griegos identificaron los números con las longitudes de los segmentos de recta.
Al identificar del modo mencionado, surge la necesidad de considerar una clase de números más amplia que la de los números fraccionarios. Se atribuye a Hípaso de Metaponto perteneciente a un grupo de matemáticos pitagóricos de la existencia de segmentos de recta "inconmensurables" con respecto a un segmento que se toma como unidad en un sistema de medición. Pues, existen segmentos de recta cuya longitud medida en este sistema no es un número fraccionario. 

Por ejemplo, en un cuadrado, la diagonal de este es inconmensurable con respecto a sus lados. Este hecho ocasionó una convulsión en el mundo científico antiguo. Provocó una ruptura entre la geometría y la aritmética de aquella época, ya que esta última, por entonces, se sustentaba en la "teoría de la proporcionalidad", la cual solo se aplica a magnitudes conmensurables.

Intentaron salvar el obstáculo distinguiendo entre el concepto de número y el de longitud de un segmento de recta, y tomaron estos últimos como elementos básicos para sus cálculos. De tal modo, a los segmentos inconmensurables con respecto a la unidad tomada como patrón de medida les asignaron un nuevo tipo de magnitud: "los números irracionales", los cuales por largo tiempo no se reconocieron como verdaderos números.

No existe una notación universal para indicarlos, como formula_6, que es generalmente aceptada. Las razones son que el conjunto de Números Irracionales no constituye alguna estructura algebraica, como sí lo son los naturales (formula_7), los enteros (formula_8), los racionales (formula_9), los reales (formula_10) y los complejos (formula_11), por un lado, y que la formula_6 es tan apropiada para designar al conjunto de números irracionales como al conjunto de números imaginarios, lo cual puede crear confusión. Fuera de ello,
Los números irracionales son los elementos de la recta real que cubren los vacíos que dejan los números racionales, ya que muchas sucesiones de racionales tienen como límite un número que no es un número racional.

Los números irracionales son los elementos de la recta real que no pueden expresarse mediante el cociente de dos enteros y se caracterizan por poseer infinitas cifras decimales no periódicas. Puede definirse al número irracional como una fracción decimal no periódica infinita. En general, toda expresión en números decimales es solo una aproximación en números racionales al número irracional referido, y se dice con toda propiedad que el número es "aproximadamente" igual a 1,4142135 en 7 decimales, o bien es "igual" a 1,4142135… donde los tres puntos hacen referencia a los decimales que faltan. Debido a ello, los números irracionales más conocidos son identificados mediante símbolos:


Los números irracionales se clasifican en dos tipos:

Los números irracionales no son numerables, es decir, no pueden ponerse en biyección con el conjunto de los números naturales. Por extensión, los números reales tampoco son numerables ya que incluyen el conjunto de los irracionales.





</doc>
<doc id="2014" url="https://es.wikipedia.org/wiki?curid=2014" title="Neurolepis">
Neurolepis

Neurolepis, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Sudamérica.



</doc>
<doc id="2015" url="https://es.wikipedia.org/wiki?curid=2015" title="Nastus">
Nastus

Nastus, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Malasia y Nueva Guinea.



</doc>
<doc id="2019" url="https://es.wikipedia.org/wiki?curid=2019" title="Números pares e impares">
Números pares e impares

En matemáticas, un número par es un número entero que es divisible entre dos. Se trata de un número entero que se puede escribir de la forma: 2"k" (es decir, divisible de manera entera entre 2), donde "k" es un entero (los números pares son los múltiplos del número 2). Los números enteros que no son pares se llaman números impares (o números menores), y pueden escribirse como 2"k"+1.

Los números pares son:

y los impares:

La paridad de un número entero se refiere a su atributo de ser par o impar. Comparativamente, dos números son «de la misma paridad» si al dividirlos entre 2, el resto es el mismo, por ejemplo: "2" y "4", o "3" y "7"; son «de la misma paridad». Por el contrario los números "23" y "44" son «de distinta paridad».

Esta se complementa por una fácil fórmula:

par + par = par | par + impar = impar | 
impar + impar = par

Si la base de numeración utilizada es un número par (por ejemplo, base 10 o base 8), un número par podrá reconocerse si su último dígito también es par. Por ejemplo, el siguiente número en base 10:

es par ya que su último dígito: 6, también es par. Lo mismo sucede con el siguiente número en base 6:

Si la base del sistema de numeración es impar (3, 5, etc), el número será par si el número de dígitos con cifra impar es par, en cualquier otro caso el número será impar. Por ejemplo, en base 3:

es impar, dado que el uno es la única cifra impar, mientras que:

Como el 3 y el 1 son impares, hay un número par de cifras impares y el número es par.
El cero es un número par, cumple con la definición así como con todas las propiedades de los números pares.





En el libro 7 de los "Elementos" de Euclides (definiciones 8 a 10), vienen definidas unas clases de números que, aunque hoy en desuso, han sido citadas de forma recurrente en libros históricos de matemáticas.


Observaciones:

Algunas fuentes, tales como "Dorado contador. Aritmética especulativa y práctica" (1794) y el más reciente, "Enjambre matemático", utilizan otra definición para los números parmente pares: no se trata de los que son productos de dos pares, sino de los que sólo se pueden expresar como producto de dos pares (exceptuando, por supuesto, el producto de sí mismos por uno). Según esta definición, los números parmente pares son exactamente las potencias de 2. Asimismo, definen el número parmente impar como el múltiplo de una potencia de 2 por un número impar e introducen el concepto, ausente en la obra de Euclides, de número imparmente par como un número que es doble de un número impar. La definición del número imparmente impar no sufre variación.

El libro "Llave aritmética y algebrayca" utiliza las primeras definiciones y explica el caso de que haya números que son simultáneamente parmente pares y parmente impares. Esta definición, además, queda reforzada en la proposición 32 del libro 9 de los "Elementos", que explica así: «Cada uno de los números (que es continuamente) duplicado a partir de una díada es solamente un (número) parmente par.»

Sea el conjunto de los pares formula_14 = {0, 2, 4, 6, 8, 10...2"n"..., "n" cualquier natural}.


el elemento a es "primo" en 2Z si no existe un elemento de 2Z que lo divida.

Por ejemplo, 6, 10, pues no hay elemento de 2Z que lo dividan parmente.



Fuera de los primos en sentido par, los otros números tienen más de dos divisores


48 y 32 tienen como divisores comunes 2, 4, 8, y 16 no, porque no divide parmente a 48

El mayor de los divisores comunes de dos elementos de formula_14 se llama máximo común divisor (m.c.d.).





</doc>
<doc id="2021" url="https://es.wikipedia.org/wiki?curid=2021" title="Número complejo">
Número complejo

Los números complejos son una extensión de los números reales y forman un cuerpo algebraicamente cerrado. El conjunto de los números complejos se designa con la notación formula_1, siendo formula_2 el conjunto de los números reales se cumple que formula_3 (formula_2 está estrictamente contenido en formula_5). Los números complejos incluyen todas las raíces de los polinomios, a diferencia de los reales. Todo número complejo puede representarse como la suma de un número real y un número imaginario (que es un múltiplo real de la unidad imaginaria, que se indica con la letra i), o en forma polar.

Los números complejos son la herramienta de trabajo del álgebra, análisis, así como de ramas de las matemáticas puras y aplicadas como variable compleja, ecuaciones diferenciales, facilita el cálculo de integrales, en aerodinámica, hidrodinámica y electromagnetismo entre otras de gran importancia. Además, los números complejos se utilizan por doquier en matemáticas, en muchos campos de la física (notoriamente en la mecánica cuántica) y en ingeniería, especialmente en la electrónica y las telecomunicaciones, por su utilidad para representar las ondas electromagnéticas y la corriente eléctrica.

En matemáticas, estos números constituyen un cuerpo y, en general, se consideran como puntos del plano: el plano complejo. Este cuerpo contiene a los números reales y los imaginarios puros.

La fórmula general de la solución de las raíces (sin utilizar funciones trigonométricas) de una ecuación de tercer grado contiene las raíces cuadradas de un número negativo cuando las tres raíces son números reales, una situación que no puede rectificarse factorizando con la ayuda de teorema de la raíz racional si el polinomio cúbico es irreducible (el llamado "casus irreducibilis"). Este enigma llevó al matemático italiano Gerolamo Cardano a concebir los números complejos alrededor de 1545, aunque su comprensión era rudimentaria.

El trabajo sobre el problema de los polinomios generales finalmente condujo al teorema fundamental del álgebra, que muestra que en el dominio de los números complejos, existe una solución para cada ecuación polinomio de grado uno o superior. Los números complejos forman un cuerpo algebraicamente cerrado, donde cualquier ecuación polinómica tiene una raíz.

Numerosos matemáticos contribuyeron al desarrollo de los números complejos. Las reglas para la suma, resta, multiplicación y extracción de raíces de números complejos fueron desarrolladas por el matemático italiano Rafael Bombelli, y fue el matemático irlandés William Rowan Hamilton quien desarrolló un formalismo más abstracto para los números complejos, extendiendo esta abstracción a la teoría de los cuaterniones.

Quizás se pueda decir que la referencia fugaz más temprana a raíz cuadrada de número negativo aparece en el trabajo del matemático griego del siglo I Herón de Alejandría. En su "Stereometrica" considera, aparentemente por error, el volumen de un tronco de pirámide con una solución imposible, llegando al término formula_6 en sus cálculos, aunque no se concebían cantidades negativas en la matemática helénica y Herón simplemente lo reemplazó por el mismo valor positivo (formula_7).

El interés por estudiar los números complejos como un tema en sí mismo surgió por primera vez en el siglo XVI, cuando los matemáticos italianos descubrieron soluciones algebraicas para las raíces de los polinomios cúbicos y cuárticos (véase Niccolò Fontana Tartaglia y Gerolamo Cardano). Pronto se dieron cuenta de que estas fórmulas, incluso si solo se estaba interesado en soluciones reales, a veces requerían la manipulación de raíces cuadradas de números negativos. Como por ejemplo, en la fórmula de Tartaglia para una ecuación cúbica de la forma formula_8 + \sqrt[3]{q/2 - \sqrt{(q/2)^2-(p/3)^3}}</math>. Cuando formula_9 es negativo (casus irreducibilis), la segunda raíz cúbica debe considerarse como el conjugado complejo de la primera.}} da la solución a la ecuación en la forma

A primera vista, esto parece un sinsentido. Sin embargo, los cálculos formales con números complejos muestran que la ecuación tiene soluciones , formula_11 y formula_12. Sustituyendo estos a su vez por formula_13 en la fórmula cúbica de Tartaglia y simplificando, se obtienen 0, 1 y -1 como las soluciones de . Por supuesto, esta ecuación en particular se puede resolver a simple vista, pero ilustra que cuando se usan fórmulas generales para resolver ecuaciones cúbicas con raíces reales, entonces, como demostraron rigurosamente los matemáticos posteriores, el uso de números complejos es inevitable. Rafael Bombelli fue el primero en abordar explícitamente estas soluciones aparentemente paradójicas de las ecuaciones cúbicas, y desarrolló las reglas para la aritmética compleja que intenta resolver estos problemas.

El término "imaginario" para estas cantidades fue acuñado por René Descartes en 1637, esforzándose precisamente por enfatizar su naturaleza imaginaria
Otra fuente de confusión fue que la ecuación formula_14 parecía ser caprichosamente inconsistente con la identidad algebraica formula_15, que es válida para números reales no negativos y , y que también se usó en cálculos de números complejos con alguno de o positivo y el otro negativo. El uso incorrecto de esta identidad (y la identidad relacionada formula_16) en el caso de que y sean negativos, preocupó incluso a Euler. Esta dificultad finalmente llevó a la convención de usar el símbolo especial en lugar de para protegerse contra este error. Aun así, Euler consideró natural presentar a los estudiantes números complejos mucho antes de lo que se hace hoy en día. En su libro de texto de álgebra elemental, Elementos de Álgebra, introducía estos números casi de inmediato y luego los usaba de forma natural.

En el siglo XVIII, los números complejos obtuvieron un uso más amplio, ya que se notó que la manipulación formal de expresiones complejas podría usarse para simplificar los cálculos que implican funciones trigonométricas. Por ejemplo, en 1730 Abraham de Moivre observó que las complicadas identidades que relacionan las funciones trigonométricas de un múltiplo entero de un ángulo con las potencias de las funciones trigonométricas de ese ángulo podrían simplemente reexpresarse mediante la siguiente conocida fórmula que lleva su nombre, la fórmula de De Moivre:

En 1748 Leonhard Euler fue más allá y obtuvo Fórmula de Euler de análisis complejo:

manipulando formalmente series de potencias complejas, y observó que esta fórmula podría usarse para reducir cualquier identidad trigonométrica a identidades exponenciales mucho más simples.

La idea de un número complejo como un punto en el plano complejo, fue descrita por primera vez por Caspar Wessel en 1799, aunque se había anticipado ya en 1685 en la obra "De Algebra tractatus" de John Wallis.

Las "Memorias de Wessel" aparecieron en las Actas de la Real Academia de Bellas Artes de Dinamarca, pero pasaron desapercibidas. En 1806, Jean-Robert Argand emitió independientemente un cuadernillo sobre números complejos y proporcionó una demostración rigurosa del teorema fundamental del álgebra. Carl Friedrich Gauss había publicado anteriormente una prueba esencialmente topológica del teorema en 1797, pero expresó sus dudas en ese momento sobre ""la verdadera metafísica de la raíz cuadrada de −1"". No fue sino hasta 1831 cuando superó estas dudas y publicó su tratado sobre números complejos como puntos en el plano, estableciendo en gran medida la notación y la terminología modernas. A principios del siglo XIX, otros matemáticos descubrieron independientemente la representación geométrica de los números complejos: Buée, Mourey, Warren, Français y su hermano, Bellavitis.

El matemático inglés Godfrey Harold Hardy comentó que Gauss fue el primer matemático en usar números complejos ""de una manera realmente segura y científica"", aunque matemáticos como Niels Henrik Abel y Carl Gustav Jakob Jacobi los usaban necesariamente de forma rutinaria antes de que Gauss publicara su tratado de 1831.

Augustin Louis Cauchy y Bernhard Riemann aportaron ideas fundamentales sobre el análisis complejo, elevándolo a un alto estado de terminación, comenzando alrededor de 1825 en el caso de Cauchy.

Los términos comunes utilizados en la teoría se deben principalmente a sus fundadores. Argand llamó "factor de dirección" a formula_19; y "módulo" a formula_20; Cauchy (1828) llamó a formula_19 la "forma reducida" (l'expression réduite) y aparentemente introdujo el término "argumento"; Gauss usó para formula_22, introdujo el término "número complejo" para y llamó a la "norma". La expresión "coeficiente de dirección", utilizada a menudo para formula_23, se debe a Hankel (1867), y "valor absoluto" para "módulo" se debe a Weierstrass.

Entre los escritores clásicos sobre la teoría general posteriores, se incluyen Richard Dedekind, Otto Hölder, Felix Klein, Henri Poincaré, Hermann Amandus Schwarz, Karl Weierstrass y muchos otros.

Los números complejos ligados a las funciones analíticas o de variable compleja, han permitido extender el concepto del cálculo al plano complejo. El cálculo de variable compleja posee diversas propiedades notables que conllevan propiedades que pueden usarse para obtener diversos resultados útiles en matemática aplicada.

Se define cada número complejo "z" como un par ordenado de números reales: "z" = ("a", "b"). A su vez el primer elemento "a" se define como parte real de "z", se denota formula_24; el segundo elemento "b" se define como parte imaginaria de "z", se denota formula_25. Luego en el conjunto ℂ de los números complejos, se definen tres operaciones y la relación de igualdad:
Al número formula_27 se denomina número complejo real y como entre el conjunto de estos y el conjunto ℝ de los números reales se establece un isomorfismo , se asume que todo número real es un número complejo. Al número complejo formula_28 se denomina número imaginario puro. Puesto que
formula_29 se dice que un número complejo es la suma de un número real con un número imaginario puro. 


A partir de estas operaciones podemos deducir otras como las siguientes:


Se define un número complejo especial, sobre todo en el álgebra, de suma relevancia, el número "i" ( "j" en física), llamado unidad imaginaria, definido como 

Que satisface la siguiente igualdad:

Tomando en cuenta que formula_37, cabe la identificación 


El valor absoluto, "módulo" o "magnitud" de un número complejo "z" viene dado por la siguiente expresión:

Si pensamos en las coordenadas cartesianas del número complejo "z" como algún punto en el plano; podemos ver, por el teorema de Pitágoras, que el valor absoluto de un número complejo coincide con la distancia euclídea desde el origen del plano a dicho punto.

Si el complejo está escrito en forma exponencial "z" = "r e", entonces |"z"| = "r". Se puede expresar en forma trigonométrica como "z" = "r" (cosφ + isenφ), donde cosφ + isenφ = "e" es la conocida fórmula de Euler. 

Podemos comprobar con facilidad estas cuatro importantes propiedades del valor absoluto

para cualquier complejo "z" y "w".

Por definición, la función distancia queda como sigue "d"("z", "w") = |"z" - "w"| y nos provee de un espacio métrico con los complejos gracias al que se puede hablar de límites y continuidad. La suma, la resta, la multiplicación y la división de complejos son operaciones continuas. Si no se dice lo contrario, se asume que ésta es la métrica usada en los números complejos.

El "argumento principal" o "fase" de un número complejo genérico formula_43 (siendo "x"=Re("z") e "y"=Im("z")) es el ángulo formula_44 que forman el eje de abscisas "OX" y el vector "OM", con M("x","y"). Viene dado por la siguiente expresión:

donde atan2(y,x) es la función arcotangente definida para los cuatro cuadrantes:

O también: formula_46 Siendo:

la función signo.

El argumento tiene periodicidad 2π, con lo que formula_48 siendo formula_49 cualquier número entero. El ángulo Arg "z" es el valor principal de arg "z" que verifica las condiciones -π < Arg "z" <= π descritas antes.

Dos binomios se llaman conjugados si solo difieren en su signo central. De esta manera, el "conjugado" de un complejo "z" (denotado como formula_50 o formula_51) es un nuevo número complejo, definido así:

Se observa que ambos difieren en el signo de la parte imaginaria. Con este número se cumplen las propiedades:

Esta última fórmula es el método elegido para calcular el inverso de un número complejo si viene dado en coordenadas rectangulares.
Un número complejo se representa en forma binomial como: 

La parte real del número complejo y la parte imaginaria, se pueden expresar de varias maneras, como se muestra a continuación:

En esta representación, formula_63 es el módulo del número complejo y el ángulo formula_64 es el argumento del número complejo.

Despejándose "a" y "b" en las expresiones anteriores y, utilizando la representación binomial, resulta:
Sacando factor común "r":

Frecuentemente, esta expresión se abrevia convenientemente de la siguiente manera:

la cual solo contiene las abreviaturas de las razones trigonométricas coseno, la unidad imaginaria y la razón seno del argumento respectivamente.

Según esta expresión, puede observarse que para definir un número complejo tanto de esta forma como con la representación binomial se requieren dos parámetros, que pueden ser parte real e imaginaria o bien módulo y argumento, respectivamente.

Según la Fórmula de Euler:

No obstante, el ángulo formula_71 no está unívocamente determinado por "z", pues pueden existir infinitos números complejos que tienen el mismo valor representado en el plano, que se diferencian por el número de revoluciones, ya sean de sentido antihorario (positivas) u horario (negativas) las cuales se representan por números enteros formula_72, como implica la fórmula de Euler:

Por esto, generalmente formula_71 está restringido al intervalo [-π, π) y a éste formula_71 restringido se le llama "argumento principal" de "z" y se denota φ=Arg("z"). Con este convenio, las coordenadas están unívocamente determinadas por "z".

La multiplicación de números complejos es especialmente sencilla con la notación polar:

División:

Potenciación:

Dado el número complejo z diremos formula_80 y se cumple que formula_81

En el anillo de las matrices de segundo orden sobre el campo de números reales, se puede hallar un subconjunto que es isomorfo al cuerpo de los números complejos. Pues, se establece una correspondencia entre cada número complejo "a"+"b"i con la matriz

De tal manera se obtiene una correspondencia biunívoca. La suma y el producto de dos de esta matrices tiene de nuevo esta forma, y la suma y producto de números complejos corresponde a la suma y producto de tales matrices. En particular la matriz formula_84 cumple el rol de unidad imaginaria.

El concepto de plano complejo permite interpretar geométricamente los números complejos. La suma de números complejos se puede relacionar con la suma con vectores, y la multiplicación de números complejos puede expresarse simplemente usando coordenadas polares, donde la magnitud del producto es el producto de las magnitudes de los términos, y el ángulo contado desde el eje real del producto es la suma de los ángulos de los términos pudiendo ser vista como la transformación del vector que rota y cambia su tamaño simultáneamente.

Multiplicar cualquier complejo por "i" corresponde con una rotación de 90º en dirección contraria a las agujas del reloj. Asimismo el que (-1)·(-1)=+1 puede ser entendido geométricamente como la combinación de dos rotaciones de 180º ("i" al cuadrado = -1), dando como resultado un cambio de signo al completar una vuelta.

Los diagramas de Argand se usan frecuentemente para mostrar las posiciones de los polos y los ceros de una función en el plano complejo.

El análisis complejo, la teoría de las funciones complejas, es una de las áreas más ricas de la matemática, que encuentra aplicación en muchas otras áreas de la matemática así como en física, electrónica y muchos otros campos.

El conjunto ℂ de los números complejos satisface las leyes de la axiomática que define un cuerpo:

Si identificamos el número real "a" con el complejo ("a", 0), el cuerpo de los números reales R aparece como un subcuerpo de C. Más aún, C forma un espacio vectorial de dimensión 2 sobre los reales. Los complejos no pueden ser ordenados como, por ejemplo, los números reales, por lo que C no puede ser convertido de ninguna manera en un cuerpo ordenado. 

El conjunto ℂ con la adición de números complejos y considerando como escalares los números reales, se puede definir ℂ como un espacio vectorial. Esto es:

Una "raíz" o un "cero" del polinomio "p" es un complejo "z" tal que "p"("z")=0. Un resultado importante de esta definición es que todas las ecuaciones polinómicas (algebraicas) de grado "n" tienen exactamente "n" soluciones en el "cuerpo de los números complejos", esto es, tiene exactamente "n" complejos "z" que cumplen la igualdad "p"("z")=0, contados con sus respectivas multiplicidades. A esto se lo conoce como Teorema Fundamental del Álgebra, y demuestra que los complejos son un cuerpo algebraicamente cerrado; por esto los matemáticos consideran a los números complejos unos números más "naturales" que los números reales a la hora de resolver ecuaciones.

También se cumple que si "z" es una raíz de un polinomio "p" con coeficientes reales, entonces el complejo conjugado de "z" también es una raíz de "p".

Al estudio de las funciones de variable compleja se lo conoce como el Análisis complejo. Tiene una gran cantidad de usos como herramienta de matemáticas aplicadas así como en otras ramas de las matemáticas. El análisis complejo provee algunas importantes herramientas para la demostración de teoremas incluso en teoría de números; mientras que las funciones reales de variable real, necesitan de un plano cartesiano para ser representadas; las funciones de variable compleja necesitan un espacio de cuatro dimensiones, lo que las hace especialmente difíciles de representar. Se suelen utilizar ilustraciones coloreadas en un espacio de tres dimensiones para sugerir la cuarta coordenada o animaciones en 3D para representar las cuatro.

En ecuaciones diferenciales, cuando se estudian las soluciones de las ecuaciones diferenciales lineales con coeficientes constantes, es habitual encontrar primero las raíces (en general complejas) formula_86 del polinomio característico, lo que permite expresar la solución general del sistema en términos de funciones de base de la forma: formula_87.

Muchos objetos fractales, como el conjunto de Mandelbrot, pueden obtenerse a partir de propiedades de convergencia de una sucesión de números complejos. El análisis del dominio de convergencia revela que dichos conjuntos pueden tener una enorme complejidad autosimilar.

Los números complejos se usan en ingeniería electrónica y en otros campos para una descripción adecuada de las señales periódicas variables "(ver Análisis de Fourier)". En una expresión del tipo formula_88 podemos pensar en formula_89 como la amplitud y en formula_90 como la fase de una onda sinusoidal de una frecuencia dada. Cuando representamos una corriente o un voltaje de corriente alterna (y por tanto con comportamiento sinusoidal) como la parte real de una función de variable compleja de la forma formula_91 donde ω representa la frecuencia angular y el número complejo "z" nos da la fase y la amplitud, el tratamiento de todas las fórmulas que rigen las resistencias, capacidades e inductores pueden ser unificadas introduciendo resistencias imaginarias para las dos últimas (ver redes eléctricas). Ingenieros eléctricos y físicos usan la letra "j" para la unidad imaginaria en vez de "i" que está típicamente destinada a la intensidad de corriente.

El campo complejo es igualmente importante en mecánica cuántica cuya matemática subyacente utiliza Espacios de Hilbert de dimensión infinita sobre C (ℂ).

En la relatividad especial y la relatividad general, algunas fórmulas para la métrica del espacio-tiempo son mucho más simples si tomamos el tiempo como una variable imaginaria.






</doc>
<doc id="2022" url="https://es.wikipedia.org/wiki?curid=2022" title="Número real">
Número real

En matemáticas, el conjunto de los números reales (denotado por formula_1) incluye tanto a los números racionales, (positivos, negativos y el cero) como a los números irracionales; y en otro enfoque, trascendentes y algebraicos. Los irracionales y los trascendentes (1970) no se pueden expresar mediante una fracción de dos enteros con denominador no nulo; tienen infinitas cifras decimales aperiódicas, tales como √5, , o el número real 2, cuya trascendencia fue enunciada por Euler en el siglo XVIII.

Los números reales pueden ser descritos y construidos de varias formas, algunas simples aunque carentes del rigor necesario para los propósitos formales de matemáticas y otras más complejas pero con el rigor necesario para el trabajo matemático formal.

Durante los siglos XVI y XVII el cálculo avanzó mucho aunque carecía de una base rigurosa, puesto que en el momento prescindían del rigor y fundamento lógico, tan exigente en los enfoques teóricos de la actualidad, y se usaban expresiones como «pequeño», «límite», «se acerca» sin una definición precisa. Esto llevó a una serie de paradojas y problemas lógicos que hicieron evidente la necesidad de crear una base rigurosa para la matemática, la cual consistió de definiciones formales y rigurosas (aunque ciertamente técnicas) del concepto de número real. En una sección posterior se describirán dos de las definiciones precisas más usuales actualmente: clases de equivalencia de sucesiones de Cauchy de números racionales y cortaduras de Dedekind.

Los egipcios dieron origen por primera vez a las fracciones comunes alrededor del año 1000 a. C.; alrededor del 500 a. C. un grupo de matemáticos griegos liderados por Pitágoras se dio cuenta de la necesidad de los números irracionales. Los números negativos fueron ideados por matemáticos indios cerca del 600, posiblemente reinventados en China poco después, pero no se utilizaron en Europa hasta el siglo XVII, si bien a finales del XVIII Leonhard Euler descartó las soluciones negativas de las ecuaciones porque las consideraba irreales. En ese siglo, en el cálculo se utilizaban números reales sin una definición precisa, cosa que finalmente sucedió con la definición rigurosa hecha por Georg Cantor en 1871.

En realidad, el estudio riguroso de la construcción total de los números reales exige tener amplios antecedentes de teoría de conjuntos y lógica matemática. Fue lograda la construcción y sistematización de los números reales en el siglo XIX por dos grandes matemáticos europeos utilizando vías distintas: la teoría de conjuntos de Georg Cantor (encajamientos sucesivos, cardinales finitos e infinitos), por un lado, y el análisis matemático de Richard Dedekind (vecindades, entornos y cortaduras de Dedekind). Ambos matemáticos lograron la sistematización de los números reales en la historia, no de manera espontánea, sino utilizando todos los avances previos en la materia: desde la antigua Grecia y pasando por matemáticos como Descartes, Newton, Leibniz, Euler, Lagrange, Gauss, Riemann, Cauchy y Weierstrass.

Se sabe que los egipcios y babilónicos hacían uso de fracciones (números racionales) en la resolución de problemas prácticos. Sin embargo, fue con el desarrollo de la matemática griega cuando se consideró el aspecto filosófico de número. Los pitagóricos descubrieron que las relaciones armónicas entre las notas musicales correspondían a cocientes de números enteros, lo que les inspiró a buscar proporciones numéricas en todas las demás cosas, y lo expresaron con la máxima «"todo es número"».

En la matemática griega, dos magnitudes son "conmensurables" si es posible encontrar una tercera tal que las primeras dos sean múltiplos de la última, es decir, es posible encontrar una "unidad" común para que las dos magnitudes tengan una medida entera. El principio pitagórico de que todo número es un cociente de enteros, expresaba en esta forma que cualesquiera dos magnitudes deben ser conmensurables.

Sin embargo, el ambicioso proyecto pitagórico se tambaleó ante el problema de medir la diagonal de un cuadrado, o la hipotenusa de un triángulo rectángulo, pues no es conmensurable respecto de los catetos. En notación moderna, un triángulo rectángulo cuyos catetos miden 1, tiene una hipotenusa que mide raíz cuadrada de dos, formula_2:

Surgió entonces un dilema, ya que de acuerdo al principio pitagórico: todo número era racional, mas la hipotenusa de un triángulo rectángulo isósceles no era conmensurable con los catetos, lo cual implicó que en adelante las magnitudes geométricas y las cantidades numéricas tendrían que tratarse por separado, hecho que tuvo consecuencias en el desarrollo de la matemática durante los dos milenios siguientes.

Los griegos desarrollaron una geometría basada en comparaciones (proporciones) de segmentos sin hacer referencia a valores numéricos, usando diversas teorías para manejar el caso de medidas inconmensurables, como la teoría de proporciones de Eudoxo. Así, los números irracionales permanecieron a partir de entonces excluidos de la aritmética puesto que solo podían ser tratados mediante el método de infinitas aproximaciones. Por ejemplo, los pitagóricos encontraron (en notación moderna) que si es una aproximación a √2 entonces = + 2 y = + son tales que es una aproximación más precisa. Repitiendo el proceso nuevamente se obtienen mayores números que dan una mejor aproximación.
Dado que las longitudes que expresan los números irracionales podían ser obtenidas mediante procesos geométricos sencillos pero, aritméticamente, solo mediante procesos de infinitas aproximaciones, originó que durante 2000 años la teoría de los números reales fuese esencialmente geométrica, identificando los números reales con los puntos de una línea recta.

Nuevos avances en el concepto de número real esperaron hasta los siglos XVI y XVII, con el desarrollo de la notación algebraica, lo que permitió la manipulación y operación de cantidades sin hacer referencia a segmentos y longitudes. Por ejemplo, se encontraron fórmulas para resolver ecuaciones de segundo y tercer grado de forma mecánica mediante algoritmos, los cuales incluían raíces e incluso, en ocasiones, «números no reales» (lo que ahora conocemos como números complejos). Sin embargo, no existía aún un concepto formal de número y se seguía dando primacía a la geometría como fundamento de toda la matemática. Incluso con el desarrollo de la geometría analítica este punto de vista se mantenía vigente, pues Descartes rechazaba la idea que la geometría pudiera fundamentarse en números, puesto que para él la nueva área era simplemente una herramienta para resolver problemas geométricos.

Posteriormente, la invención del cálculo abrió un período de grandes avances matemáticos, con nuevos y poderosos métodos que permitieron por vez primera atacar los problemas relacionados con lo infinito mediante el concepto de límite. Así, un número irracional pudo ser entendido como el límite de una suma infinita de números racionales (por ejemplo, su expansión decimal). Como muestra, el número puede estudiarse de forma algebraica (sin apelar a la intuición geométrica) mediante la serie:

entre muchas otras expresiones similares. Para entonces, el concepto intuitivo de número real era ya el moderno, identificando sin problema un segmento con la medida de su longitud (racional o no). El cálculo abrió el paso al análisis matemático, que estudia conceptos como continuidad, convergencia, etc. Pero el análisis no contaba con definiciones rigurosas y muchas de las demostraciones apelaban aún a la intuición geométrica. Esto conllevó a una serie de paradojas e imprecisiones.

Los números reales se expresan con decimales que tienen una secuencia infinita de dígitos a la derecha de la coma decimal, como por ejemplo 324,8232. Frecuentemente también se subrepresentan con tres puntos consecutivos al final (324,823211247…), lo que significaría que aún faltan más dígitos decimales, pero que se consideran sin importancia.

Las medidas en las ciencias físicas son siempre una aproximación a un número real. No solo es más conciso escribirlos con forma de fracción decimal (es decir, números racionales que pueden ser escritos como proporciones, con un denominador exacto) sino que, en cualquier caso, cunde íntegramente el concepto y significado del número real. En el análisis matemático los números reales son objeto principal de estudio. Puede decirse que los números reales son la herramienta de trabajo de las matemáticas de la continuidad, como el cálculo y el análisis matemático, mientras que los números enteros lo son de las matemáticas discretas, en las que está ausente la continuidad.

Se dice que un número real es recursivo si sus dígitos se pueden expresar por un algoritmo recursivo. Un número no recursivo es aquel que es imposible de especificar explícitamente. Aun así, la escuela rusa de constructivismo supone que todos los números reales son recursivos.

Los ordenadores solo pueden aproximarse a los números reales por números racionales; de todas maneras, algunos programas de ordenador pueden tratar un número real de manera exacta usando su definición algebraica (por ejemplo, "formula_3") en vez de su respectiva aproximación decimal.

Los matemáticos usan el símbolo formula_4 (o, de otra forma, formula_5, la letra "R" en negrita) para representar el conjunto de todos los números reales. La notación matemática formula_6 se refiere a un espacio de formula_7 dimensiones de los números reales; por ejemplo, un valor formula_8 consiste de tres números reales y determina un lugar en un espacio de tres dimensiones.

En matemática, la palabra «real» se usa como adjetivo, con el significado de que el campo subyacente es el campo de los números reales. Por ejemplo, "matriz real", "función real", y "Álgebra de Lie real".

Un número real puede ser un "número racional" o un "número irracional". Los números racionales son aquellos que pueden expresarse como el cociente de dos números enteros, tal como 3/4, -21/3, 5, 0, 1/2, mientras que los irracionales son todos los demás. Los números racionales también pueden describirse como aquellos cuya representación decimal es eventualmente periódica, mientras que los irracionales tienen una expansión decimal aperiódica:
El conjunto de los números racionales se designa mediante formula_12.

Otra forma de clasificar los números reales es en "algebraicos" y "trascendentes". Un número es algebraico si existe un polinomio de coeficientes racionales que lo tiene por raíz y es trascendente en caso contrario. Obviamente, todos los números racionales son algebraicos: si formula_13 es un número racional, con "p" entero y "q" natural, entonces es raíz de la ecuación formula_14. Sin embargo, no todos los números algebraicos son racionales.

El conjunto de los números algebraicos se designa mediante formula_18.

Un número real se dice computable si tiene una complejidad de Kolmogórov finita, es decir, si puede escribirse un programa informático de extensión finita que genere los dígitos de dicho número. Si un número real no es computable se dice irreductible. Una definición de número irreductible es:

El conjunto de números reales computables se designa por formula_19. Obviamente los racionales y los algebraicos son números computables. De hecho se tiene la siguiente inclusión:

Además se tiene que todos estos conjuntos son numerables:

Esto implica que el conjunto de todos los números computables es un conjunto de medida nula.

Fue propuesto por el matemático alemán David Hilbert. En textos actuales de cálculo y análisis matemático aparecen enunciados equivalentes al de Hilbert.
Existen diferentes formas de construir el conjunto de los números reales a partir de axiomas, siendo la caracterización más común, el conocido como "método directo" que introduce el sistema (ℝ, +., ≤), donde los elementos de ℝ se llaman "números reales", + y. son dos operaciones en ℝ, ≤ es una relación de orden en ℝ. Se presenta una variante axiomática, mediante las siguientes tres propiedades:

Las primeras dos condiciones definen el concepto de "campo ordenado", mientras que la tercera propiedad es de naturaleza topológica y es la que diferencia al conjunto de los números reales de todos los demás campos ordenados. Hay que hacer notar que, en principio pueden existir diferentes conjuntos que satisfagan las mismas condiciones y que podrían ser diferentes al conjunto de los números reales, pero un teorema establece que si eso sucediera, ambas estructuras serían esencialmente la misma.

En vista de lo anterior podemos hablar de "el" conjunto de los números reales (y no de "un" conjunto de números reales) y estableciendo su unicidad se puede usar el símbolo ℝ para representarlo.

Al enunciar la tercera propiedad en ocasiones se especifica que ℝ es completo en el sentido de Dedekind, pues existen otros axiomas que se pueden usar y que, asumiendo las primeras dos condiciones, todos son lógicamente equivalentes. Algunos de estos son:

Cada una de las primeras dos propiedades mencionadas al inicio de la sección corresponden a su vez a otra serie de axiomas, de modo que si se hace un desglose, puede caracterizarse el conjunto de los números reales como un conjunto que satisfaga la siguiente lista de axiomas.


Los axiomas del 1 al 15 corresponden a la estructura más general de cuerpo ordenado.
El último axioma es el que distingue formula_64 de otros cuerpos ordenados como formula_68. Debe señalarse que los axiomas 1 a 15 no constituyen una teoría categórica ya que puede demostrarse que admiten al menos un modelo no estándar diferente de los números reales, que es precisamente el modelo en el que se basa la construcción de los números hiperreales

Consideramos los números decimales como los conocemos intuitivamente. Sabemos que formula_69, es decir, el número π se expresa como el número entero 3 y una secuencia infinita de "dígitos" 1, 4, 1, 5, 9, 2, etc.

Un número decimal se expresa entonces como formula_70 donde formula_71 es un número entero y cada formula_72 es un elemento del conjunto formula_73. Además, consideramos que no existen las colas de 9.

Al conjunto de todos los números decimales donde formula_71 es un número entero positivo se le denota por formula_75 y se le llama el conjunto de los números "reales positivos".

Al conjunto de todos los números decimales donde formula_71 es un número entero negativo se le denota por formula_77 y se le llama el conjunto de los números "reales negativos".

Al número decimal formula_78 se le llama "cero".

Al conjunto formula_79 se le denota por formula_1 y se le llama conjunto de "números reales".

Se define la relación de orden total de los números decimales como

Hay valores que no se pueden expresar como números racionales, tal es el caso de formula_2. Sin embargo es claro que se puede aproximar formula_2 con números racionales tanto como se desee. Podemos entonces partir al conjunto de los números racionales en dos subconjuntos formula_99 y formula_100 de manera que en el conjunto formula_99 se encuentran todos los números racionales formula_102 y en formula_100 todos los números racionales tales que formula_104.

Una "cortadura de dedekind" es un par ordenado formula_105 que hace precisamente esto. Conceptualmente, la cortadura es el "espacio" que hay entre formula_99 y formula_100. De esta manera es posible definir a formula_2 como formula_105 tal que formula_110 y formula_111.

Es posible demostrar que formula_100 queda unívocamente definido por formula_99, de esta manera la cortadura formula_105 se reduce simplemente a formula_99.

También es demostrable que el conjunto de todas las cortaduras cumple con los axiomas de los números reales, de esta manera formula_1 es el conjunto de todas las cortaduras de Dedekind. Esta es la primera construcción formal de los números reales bajo la teoría de conjuntos.
Un número real r determina sobre la recta real una cortadura cuyas clases son formula_117 y formula_118.

Las sucesiones de Cauchy retoman la idea de aproximar con números racionales un número real. Tómese por ejemplo, la igualdad.

Es claro que esta suma opera solo con los números racionales de la forma:

sin embargo, el resultado final es el número irracional formula_121. Cada vez que se añade un término, la expresión se aproxima más y más a formula_121.

Las sucesiones de Cauchy generalizan este concepto para definir a los números reales. Primero se define que una "sucesión de números racionales" es una función se denota simplemente por formula_123.

Una "sucesión de Cauchy" es una sucesión de números racionales donde sus elementos cada vez son menos diferentes. Más formalmente, se define una "sucesión de Cauchy" como una sucesión de números racionales tales que para todo formula_124 existe un formula_125 tal que para todo formula_126 se cumple formula_127.

De esta manera es posible definir al número real formula_128 como la sucesión de números racionales:

Sea Γ el conjunto de las sucesiones de Cauchy en Q. Sea la relación ρ siguiente, definida entre las sucesiones de Cauchy de Q, (x) y (y):




Sean a > 0 y b números reales cualesquiera, existe un número natural n tal que na > b; esto expresa a su vez que la sucesión b/n tiende a cero.

Con números reales pueden realizarse todo tipo de operaciones básicas con diversas excepciones importantes:


Estas restricciones tienen repercusiones en otras áreas de las matemáticas como el cálculo: existen asíntotas verticales en los lugares donde el denominador de una función racional tiende a cero, es decir, en aquellos valores de la variable en los que se presentaría una división entre cero, o no existe gráfica real en aquellos valores de la variable en que resulten números negativos para raíces de orden par, por mencionar un ejemplo de construcción de gráficas en geometría analítica.




</doc>
<doc id="2028" url="https://es.wikipedia.org/wiki?curid=2028" title="Netscape Navigator">
Netscape Navigator

Netscape Navigator es un navegador web, el primer producto comercial de la compañía Netscape Communications creada por Marc Andreessen (uno de los autores de Mosaic) cuando se encontraba en el "National Center for Supercomputing Applications" (NCSA: Centro Nacional de Aplicaciones para Supercomputadoras) de la Universidad de Illinois en Urbana-Champaign.

Netscape fue el primer navegador comercial.

Netscape anunció el 13 de octubre de 1994 que lanzaría un navegador disponible de forma gratuita para todos sus usuarios no comerciales, y que las versiones beta 1.0 y beta 1.1 se podrán descargar en noviembre de 1994 y marzo de 1995. La versión 1.0 final estuvo disponible en diciembre de 1994. Netscape hizo gratuita la disponibilidad de su software porque tenía en sus políticas la noción de que el software para Internet no debía tener coste. 
En 1997, el Netscape Navigator 2.0 fue el primer navegador en incluir un lenguaje de "script" en las páginas web, al introducir JavaScript en su versión 2. Originalmente, apenas servía para algo más que para validar formularios, pero rápidamente se fue expandiendo.

Al añadirle capacidades para leer y enviar mensajes, tanto de correo electrónico como de "netnews", aparece la versión Communicator. El editor de páginas Netscape Composer, introducido en la "'versión 3", da lugar a la denominación "Gold" para las distribuciones que lo incluyen.

Fue muy criticado por los partidarios de los estándares en Internet por introducir en el HTML gran cantidad de extensiones propietarias (o "netscapismos"), es decir, creadas por sus autores, sin respetar las recomendaciones del "World Wide Web Consortium", lo que dañaba la compatibilidad de las páginas entre navegadores y al objetivo de llegar a la web semántica. Entre las extensiones propietarias introducidas por Netscape destacan los "frames" y los "layers".

La versión 4 introdujo las hojas de estilo en cascada (CSS) y HTML dinámico a través de JavaScript y una extensión propietaria de HTML llamada "layers". Por desgracia, esta versión estaba plagada de "bugs", y su implementación del HTML dinámico era inferior a la del Internet Explorer 4. Esto, unido a la integración de Internet Explorer en Microsoft Windows, llevó a la llamada “guerra de navegadores” entre ambas compañías, que introdujeron abundantes extensiones propias e incompatibles entre sí a HTML y JavaScript. Esto obligó a muchos a crear dos versiones de sus páginas, una para cada navegador.

El resultado de esta ‘guerra’ fue la victoria del Internet Explorer, que consiguió una cuota del 98% en el uso de navegadores, y la posterior desaparición de Netscape Navigator. Esta victoria se debió, fundamentalmente, a la inclusión de Internet Explorer como un componente más de Microsoft Windows, lo que hacía que la inmensa mayoría de los usuarios lo tuvieran aunque no lo hubieran instalado como tal, y no se molestaran en buscar otro.

La versión 5 estuvo en desarrollo durante años, pero la dificultad de modificar el código fuente para permitir la modificación de las páginas tras su carga, unida a las progresivas pérdidas económicas de la empresa, hizo que nunca saliera al mercado. Así, Netscape perdió la guerra de los navegadores en favor de Internet Explorer, que ya iba por la versión 5. Finalmente, su código fue liberado, con el fin de que la comunidad de desarrolladores de software libre pudiera contribuir a terminarlo. Esto dio lugar a la Fundación Mozilla, que reescribió casi todo el código, creando el navegador Mozilla Application Suite.

Las versiones 6 y 7 se basaron en el código del proyecto Mozilla. En la actualidad, al haber abandonado Netscape el desarrollo de su navegador, se puede considerar a Mozilla Navigator como su sucesor.

En marzo de 1997, Netscape liberó la mayoría del código de Netscape Communicator y lo puso bajo la licencia libre. El proyecto se llamó Mozilla. Se estimó que completar el código fuente (los elementos con "copyright" propietario tuvieron que ser eliminados) en una nueva versión de navegador, podría llevar un año, y de esta forma se decidió que la próxima versión del navegador Netscape, "versión 5.0", se basaría en esta. Netscape asignó sus ingenieros de desarrollo de su navegador para que ayudaran en el proyecto.

Después de un año, era evidente que el desarrollo de Mozilla no era tan veloz, por lo que Netscape reasignó algunos de sus ingenieros a la versión Netscape Communicator 4.5. Esto tuvo el efecto de redirigir parte de los esfuerzos en una línea muerta, mientras el navegador de Microsoft, Internet Explorer 5.0, estaba todavía desarrollándose. Los ingenieros de Mozilla decidieron tirar el código de Communicator y empezar desde cero. La primera versión pública de Mozilla, dos años más tarde, no tuvo mucha aceptación ya que muchas computadoras de nivel medio eran demasiado lentos para ejecutar un navegador que utilizaba su propia interfaz gráfica de usuario y personalizable con el lenguaje "Extensible Markup Language" (XML).

Se evitó la versión 5 porque Microsoft Internet Explorer 5.0 estaba disponible desde hacía un año y medio. Había planes para liberar una versión 5.0 basada en el código 4.x, pero esta idea fue desechada y se utilizaron todos los recursos para trabajar en la versión de Mozilla Netscape 6.0, en lo que algunos empleados de Netscape todavía consideran uno de los mayores errores en la historia de la empresa.

Con bastante publicidad, la empresa AOL como nueva dueña de Netscape, liberó Netscape 6 el 14 de noviembre de 2000, basado en el código de la versión anterior de Mozilla. El producto fue una decepción colosal: era enorme, lento, inestable y visualmente no atractivo (para la gran mayoría). Nada de esto fue una sorpresa, ya que el núcleo de Mozilla no estaba cerca de estar disponible como nueva versión por sí mismo, y era muy inestable.

Netscape 6.1 y Netscape 6.2, liberados en 2001, solucionaron los problemas de estabilidad, pero eran demasiado grandes y lentos, y no mejoraron la mala reputación de Netscape 6, por lo que fueron ignorados de forma generalizada por el mercado.

En 2002, AOL liberó Netscape 7: basado en el núcleo de Mozilla 1.0, más estable y notablemente más rápido, tenía varios extras como el "AOL Instant Messenger" integrado, ICQ y Radio@Netscape. El mercado respondió que era esencialmente una versión re-empaquetada de Mozilla con una serie de herramientas integradas que permitían acceder a los servicios gestionados por AOL, por lo que fue ignorado nuevamente. La competencia entre las alternativas no-Microsoft maduras y competentes como el navegador Opera y la distribución de Mozilla fue otro factor decisivo. La versión Netscape 7.1 (basada en Mozilla 1.4) fue también ignorada.

En la plataforma Windows, el navegador Netscape ha sido irrelevante durante bastantes años. Todavía hay algunos usuarios de versiones recientes, pero la mayoría son personas que no están dispuestas, o no pueden, cambiar de navegador desde las versiones 4.x, ya que normalmente los navegadores más recientes requieren máquinas con mayor potencia de cálculo para un rendimiento aceptable. En otras plataformas, que no tienen la posibilidad de instalar Internet Explorer, como GNU/Linux, Netscape mantuvo su posición como navegador dominante durante más tiempo. Únicamente en los últimos años, la aparición de otras alternativas como Mozilla y Konqueror han supuesto un incremento de la competencia.

AOL anunció el 14 de julio de 2003 que iba a retirar a todo el personal de desarrollo que trabajaba en la versión de Netscape de Mozilla. Combinado con el acuerdo entre Microsoft y AOL para utilizar la versión de Internet Explorer en las futuras versiones de software, marcó el final de Netscape como entidad y lo relegó a poco más de una nota histórica. El nombre de marca Netscape como proveedor de servicios de Internet con llamada telefónica.

Netscape 7.2 se lanzó el 17 de agosto de 2004; AOL afirmó no haber continuado con la división del navegador Netscape.

En mayo de 2005 se publicó una nueva versión, Netscape 8.0, basada en Mozilla Firefox, pero ofreciendo también el motor de Internet Explorer para visualizar ciertas páginas.

En octubre de 2007 se lanzó la versión Netscape 9.0, que además de otras funcionalidades, permite la integración de los "plugins" de Firefox 2.

AOL canceló el soporte para Netscape a partir del 1 de marzo de 2008. Esto significa que a partir de esa fecha no se producirán parches de seguridad o nuevas versiones del navegador.

Inicialmente se había anunciado que el día 1 de febrero de 2008 se finalizaría el soporte técnico y desarrollo del navegador, pero se extendió la fecha hasta el 1 de marzo para crear un "plugin" que permitiría migrar a los usuarios de Netscape 9.0.x y 8.x a una versión especial de Flock, o a Mozilla Firefox. Fue así que el 20 de febrero se lanzó la última versión de Netscape Navigator, la 9.0.0.6. Al día siguiente, el navegador fue parchado, cerrando una larga historia en Internet.

Algunos usuarios, aprovechando el código de Mozilla Firefox, han intentado revivir a Netscape Navigator. Entre estos proyectos se encuentran Netscape Reloaded y Netstep. Estos agregan funcionalidad, herramientas y aspectos similares a las usadas por Netscape mediante extensiones.




</doc>
<doc id="2029" url="https://es.wikipedia.org/wiki?curid=2029" title="Friedrich Nietzsche">
Friedrich Nietzsche

Friedrich Wilhelm Nietzsche ( ; Röcken, -Weimar, ) fue un filósofo, poeta, músico y filólogo alemán del siglo XIX, considerado uno de los filósofos más importantes de la filosofía occidental, cuya obra ha ejercido una profunda influencia tanto en la historia como en la cultura occidental.

Nietzsche escribió sobre temas tan diversos como el arte, la filología, la historia, la religión, la ciencia o la tragedia. Hizo una crítica de la cultura, la religión y la filosofía occidental mediante la genealogía de los conceptos que las integran, basada en el análisis de las actitudes morales (positivas y negativas) hacia la vida. Este trabajo afectó profundamente a generaciones posteriores de teólogos, antropólogos, filósofos, sociólogos, psicólogos, politólogos, historiadores, poetas, novelistas y dramaturgos.

Es sumamente destacable la influencia que ejerció sobre Nietzsche el filósofo también alemán Arthur Schopenhauer, a quien consideró su maestro, si bien es cierto que no siguió de manera dogmática las ideas de este último, y en muchos aspectos se aleja de su pensamiento llegando incluso a realizar una crítica radical de sus ideas filosóficas.

Meditó sobre las consecuencias del triunfo del secularismo de la Ilustración, expresada en su observación «Dios ha muerto», de una manera que determinó la agenda de muchos de los intelectuales más célebres después de su muerte.

Si bien hay quienes sostienen que la característica definitoria de Nietzsche no es tanto la temática que trataba sino el estilo y la sutileza con que lo hacía, fue un autor que introdujo, como ningún otro, una cosmovisión que ha reorganizado el pensamiento del siglo XX, en autores tales como Martin Heidegger, Michel Foucault, Jacques Derrida, Gilles Deleuze, Georges Bataille, Gianni Vattimo o Michel Onfray, entre otros.

Nietzsche recibió amplio reconocimiento durante la segunda mitad del siglo XX como una figura significativa en la filosofía contemporánea. Su influencia fue particularmente notoria en los filósofos existencialistas, críticos, fenomenológicos, postestructuralistas y posmodernos, y en la sociología de Max Weber. Es considerado uno de los tres «maestros de la sospecha» (según la conocida expresión de Paul Ricoeur), junto a Karl Marx y Sigmund Freud.

Friedrich Nietzsche nació el 15 de octubre de 1844 en Röcken, un pequeño pueblo de Sajonia-Anhalt, cerca de Leipzig. Su nombre proviene del rey Federico Guillermo IV de Prusia, en cuyo cuadragésimo noveno cumpleaños nació. Sus padres fueron Carl Ludwig Nietzsche (1813-1849), pastor luterano y preceptor privado en el ducado alemán de Sajonia-Altenburgo en Turingia, y Franziska Oehler (1826-1897). Su hermana Elisabeth Förster-Nietzsche nació en 1846, seguida por su hermano Ludwig Joseph en 1848. Tras la muerte de su padre en 1849 y del hermano menor en 1850, la familia se trasladó a Naumburgo, donde vivió con su abuela materna y las hermanas solteras del padre bajo la protección de Bemhard Dächsel, un magistrado local. Durante este tiempo el joven Nietzsche asistió a un colegio de niños para luego trasladarse al instituto del candidato Weber, una academia privada, donde se hizo amigo de Gustav Krug y Wilhelm Pinder, dos estudiantes pertenecientes a familias acomodadas.

En 1854 comenzó a asistir al Domgymnasium en Naumburgo y, después de la muerte de su abuela en 1856, la familia pudo permitirse tener casa propia. Ese año escribe su primer «tratado» filosófico titulado "Sobre el origen del mal". Habiendo demostrado ya entonces un talento especial para la música y el lenguaje, fue admitido en la reconocida Schulpforta, donde continuó sus estudios desde 1858 hasta 1864. Aquí se hizo amigo de Paul Deussen y Carl von Gersdorff. También encontró tiempo para la escritura de poemas y composiciones musicales. En Schulpforta, Nietzsche recibió una importante educación literaria, en especial en el estudio de los clásicos griegos y romanos, y por primera vez experimentó la carencia de su vida familiar en un pequeño pueblo de ambiente cristiano. Durante este período se encontró bajo la influencia del poeta Ernst Ortlepp.

Después de su graduación en 1864, Nietzsche comenzó sus estudios en teología y filología clásica en la Universidad de Bonn. Por un breve período fue miembro de la Burschenschaft Frankonia junto a Deussen. Para disgusto de su madre, abandonó sus estudios de teología tras un semestre y comenzó los de filología con el profesor Friedrich Wilhelm Ritschl. Al año siguiente siguió al maestro a la Universidad de Leipzig. Allí entablaría una íntima amistad con el estudiante Erwin Rohde. Los primeros escritos sobre filología de Nietzsche serían publicados un poco más tarde.

En 1865 se familiarizó con la obra de Arthur Schopenhauer. Al año siguiente leyó "Geschichte des Materialismus" ("Historia del materialismo"), de Friedrich Albert Lange. Ambas experiencias le resultaron muy estimulantes desde el punto de vista filosófico y, en consecuencia, comenzó a adentrarse en esta disciplina, superando su interés por la filología. En 1865, cuando todavía era estudiante, Nietzsche visitó Colonia, donde unos amigos lo llevaron a un prostíbulo. Los detalles, e incluso la posibilidad, de esta visita fueron largamente discutidos, pero ahora se acepta que en esa oportunidad contrajo sífilis. En 1867 realizó un año de servicio militar voluntario con la división de artillería prusiana de Naumburgo. En marzo de 1868 sufrió un accidente ecuestre que lo excluyó del servicio militar y le permitió volver a dedicarse al estudio. Ese mismo año conoció a Richard Wagner, personaje fundamental en su desarrollo.

Gracias a Ritschl, Nietzsche recibió una oferta extraordinaria de la Universidad de Basilea para ejercer como profesor de filología clásica antes de licenciarse, siendo así el profesor más joven de la universidad. En su trabajo filológico durante esa época cabe reseñar el descubrimiento de que el ritmo en la métrica poética de los antiguos dependía únicamente de la duración de las sílabas a diferencia de la métrica moderna basada en la acentuación.

En 1869 la Universidad de Leipzig le concedió el doctorado sin examen ni disertación en mérito a la calidad de sus investigaciones. Inmediatamente la Universidad de Basilea lo nombró profesor de filología clásica y al año siguiente fue ascendido a profesor honorario.

Después de trasladarse a Basilea, Nietzsche renunció a su ciudadanía alemana, manteniéndose durante el resto de su vida oficialmente sin nacionalidad alguna. Sin embargo en agosto de 1870 obtuvo un permiso para servir en el bando prusiano durante la guerra franco-prusiana pero solo como sanitario ya que la neutral Suiza le impidió reclutarse como combatiente. Su paso por la milicia fue tan solo de un mes, pero vivió múltiples experiencias. Allí fue testigo de los efectos traumáticos de la batalla. Contrajo difteria y disentería, enfermedades que le arruinaron la salud de por vida.

De vuelta a Basilea, Nietzsche fue testigo del establecimiento del Imperio alemán y el auge de Otto von Bismarck, a quien veía con escepticismo. En la universidad pronunció su discurso inaugural, "Sobre la personalidad de Homero". En esta época conoció a Franz Overbeck, un profesor de Teología, cuya amistad conservó durante el resto de su vida. El historiador Jacob Burckhardt, a cuyas clases magistrales Nietzsche asistía frecuentemente, se convirtió en otro colega influyente. También durante este período leerá la obra del filósofo Max Stirner, cuya influencia será notable en él.

Nietzsche había conocido ya a Richard Wagner en Leipzig en 1868, y (algo después) a la esposa de Wagner, Cósima. Admiraba a ambos profundamente y, durante su estancia en Basilea, fue un asiduo invitado en la casa de los Wagner en Tribschen. Estos lo introdujeron en su círculo más íntimo y le agradecieron la atención que dio al principio al Festival de Bayreuth. En 1870 regaló a Cósima Wagner por su cumpleaños el manuscrito de la primera versión de "El origen de la tragedia".

En 1872, Nietzsche publicó su primer libro, "El nacimiento de la tragedia en el espíritu de la música". Sin embargo el trabajo, en el cual siguió un preciso método filológico para estructurar toda su especulación filosófica radicalmente novedosa, no fue bien recibido entre sus colegas filólogos, incluido su profesor Ritschl. En el polémico panfleto "Para una filología del futuro", Ulrich von Wilamowitz-Moellendorff criticó duramente el libro, lo que contribuyó, sin embargo, a aumentar su polémica notoriedad en los círculos filológicos y universitarios de Alemania. En respuesta, Rohde, por la fecha profesor en Kiel, y el mismo Wagner salieron públicamente en defensa de Nietzsche. Estos hechos remarcaron el aislamiento creciente que sentía dentro de la comunidad filológica, y por ello el filósofo intentó (infructuosamente) ganar la cátedra de Filosofía en Basilea.

Entre 1873 y 1876, publicó separadamente cuatro grandes ensayos, "David Strauss, el confesor y el escritor", "Sobre la utilidad y el perjuicio de la Historia para la vida", "Schopenhauer como educador", y "Richard Wagner en Bayreuth" (estos cuatro fueron más tarde recogidos y titulados, conjuntamente, "Consideraciones intempestivas"). Los cuatro ensayos compartían la orientación de una crítica general a la actualidad cultural alemana, en un intento por cambiar su rumbo, que Nietzsche preveía como esencialmente falso y equivocado. Comenzando en 1873, además, también acumuló notas que fueron publicadas más tarde como "La filosofía en la época trágica de los griegos".

Durante este periodo, en el círculo de los Wagner, Nietzsche conoció a Malwida von Meysenbug y Hans von Bülow, y también comenzó una amistad con Paul Rée, quien después de 1876 le influyó en la atenuación del pesimismo de sus primeros escritos. Sin embargo, debido a su decepción respecto al «fenómeno Wagner», y en concreto al Festival de Bayreuth de 1876, donde la banalidad de los actos y la vileza del público le repelieron, fue cada vez más insalvable la distancia del filósofo hacia este mundo.

En 1879, después de un declive de salud, se vio forzado a abandonar su puesto como profesor. Desde su juventud, Nietzsche había padecido frecuentes momentos de debilidad generalizada, con épocas de carencia visual que rozaba la ceguera, fuertes migrañas y violentos ataques estomacales. Estas condiciones persistentes se agravaron quizá con su accidente a caballo en 1868 y las enfermedades de 1870, y continuaron afectándolo durante sus años en Basilea, forzándolo a tomar vacaciones cada vez más largas, hasta que le fue prácticamente imposible retomar el trabajo.

Con la publicación de "Humano, demasiado humano" en 1878, un libro de aforismos sobre múltiples temas, desde la metafísica hasta la moralidad y de la religión al sexo, la distancia de Nietzsche respecto a la filosofía de Wagner y Schopenhauer fue evidente. También su amistad con Deussen y Rohde se enfrió.

Durante sus primeros años en Basilea se cocinó la ambivalente amistad de Nietzsche con Wagner, y aprovechó toda oportunidad para visitar a Richard y a su esposa Cósima. Nietzsche apreciaba a Wagner como un brillante apóstol catedrático, pero la explotación de motivos artísticos cristianos cada vez más acentuada, junto con su chovinismo y antisemitismo excederían lo que Nietzsche podría soportar.

La composición de Parsifal, que Wagner concebiría más como un "auto litúrgico" para el Viernes Santo que como una ópera, ofendió profundamente la sensibilidad de Nietzsche. Aunque la gigantesca obra no sería estrenada hasta 1882, ya en 1878 la brecha entre los dos sería ineludible y definitiva.

Conducido por su enfermedad a encontrar climas más templados, Nietzsche viajó frecuentemente y vivió hasta 1889 como un autor independiente en diferentes ciudades. Estuvo muchos veranos en Sils Maria, cerca de St. Moritz, en la Engandina (extremo este de Suiza), y muchos otoños en las ciudades italianas de Génova, Rapallo y Turín, y la ciudad francesa de Niza. Ocasionalmente volvía a Naumburgo a visitar a su familia, y especialmente durante este período, él y su hermana tuvieron repetidos episodios de conflicto y reconciliación. Vivía de su pensión de profesor retirado de la Universidad de Basilea, pero también recibía ayuda de amigos.

Un antiguo estudiante suyo, Peter Gast (seudónimo de Johann Heinrich Köselitz), llegó a ser su secretario privado. Hasta el final de su vida, Gast y Overbeck se mantuvieron como amigos en los que confiar. Malwida von Meysenbug mantuvo una conducta maternal incluso fuera del círculo de Wagner. Pronto Nietzsche contactó con el crítico musical Carl Fuchs.

Nietzsche se encontraba en el principio de su mayor período productivo. A partir de "Humano, demasiado humano" en 1878, Nietzsche publicaría un libro (o su mayor parte) por año hasta 1888, su último año de escritura, durante el cual completó cinco. En 1879, Nietzsche publicó "Opiniones y máximas mezcladas", lo que sugirió el aforismo de "Humano, demasiado humano".

En 1881 Nietzsche publicó "Aurora. Reflexiones sobre los prejuicios morales", y en 1882 la primera parte de "La gaya ciencia". Ese año también conoció a Lou Andreas-Salomé a través de Malwida von Meysenbug y Paul Rée. Nietzsche y Salomé pasaron el verano juntos en Tautenburg, a menudo con la hermana de Nietzsche, Elisabeth. Sin embargo, la visión que de Nietzsche tenía Salomé era más la de un amigo y compañero de discusiones lleno de genialidad, que el de una posible pareja. Él se enamoró de ella lo cual provocó una situación ambigua e incómoda entre los tres amigos, puesto que Rée a su vez se interesaba por Lou. Cuando Nietzsche le pidió que se casara con él, Salomé lo rechazó. Las relaciones de Nietzsche con Salomé y Rée se rompieron en el otoño de 1882-1883, en parte por las intrigas llevadas a cabo por su hermana Elisabeth. En paralelo a esta historia, Lou Salomé de vez en cuando mantenía correspondencia con Freud, introduciéndolo en el pensamiento de Nietzsche. En el proceso de aparición de nuevos síntomas de su enfermedad, aislado tras las discusiones con su hermana y su madre, y acosado por pensamientos suicidas, se marchó a Rapallo, donde en solo diez días, anticipados por dieciocho meses de incubación, escribió la primera parte de "Así habló Zaratustra".

Después de varias críticas filosóficas contra Schopenhauer y Wagner, Nietzsche mantuvo a pocos amigos. Ahora, bajo la impronta personalísima del "Zaratustra" sobre sus obras posteriores, su escritura resultó todavía más «intempestiva» y se lo leyó (poco) solo en la medida en que pareciera adecuarse a las convenciones morales o intelectuales del momento. Nietzsche reconoció la situación y se obstinó en su soledad («las siete soledades»), incluso aunque a veces pareciera no resignarse a ella. Abandonó su plan a medio plazo de convertirse en un poeta público y reconocido, y siguió padeciendo los problemas consabidos con sus libros. Estos eran tan buenos como poco vendidos. En 1885, editó únicamente cuarenta copias de la cuarta parte de "Así habló Zaratustra", y solo una pequeña parte fue distribuida entre sus amigos más allegados.

En 1886, editó "Más allá del bien y del mal". Con este libro y con la aparición entre 1886 y 1887 de segundas ediciones de sus trabajos tempranos ("El nacimiento de la tragedia", "Humano, demasiado humano", y "La gaya ciencia"), vio completado su trabajo y se esperanzó con que una oleada de lectores apreciara sus escritos. De hecho, el interés por Nietzsche aumentó en esta época, aunque esto fue apenas percibido por él.

Durante estos años, Nietzsche conoció a Meta von Salis, Carl Spitteler, y también a Gottfried Keller. En 1886, su hermana Elisabeth se casó con el antisemita Bernhard Förster y viajó con él a Paraguay para fundar una colonia alemana, un plan al que Nietzsche contestó con ironía. A través de la correspondencia se puede observar que la relación de Nietzsche con su hermana continuó por el camino que siempre había seguido de conflicto y reconciliación, pero no la volvería a ver en persona hasta después de su colapso.

Nietzsche continuaba teniendo ataques frecuentes de enfermedad, lo que le imposibilitó para el trabajo continuo. En 1887, Nietzsche rápidamente escribió su polémica "Genealogía de la moral". También intercambiaba correspondencia con Hippolyte Taine, y después también con Georg Brandes, quien al comienzo de 1888 desarrolló en Copenhague la primera lectura pública de la obra filosófica de Nietzsche y su estudio.

En el mismo año Nietzsche escribió cinco libros basados en sus voluminosas notas, fruto de largo trabajo continuado, que en un principio pensaba reunir bajo el título de "La voluntad de poder". Su salud pareció mejorar y aquel verano estuvo de buen humor. Pero hacia finales de 1888, sus escritos y cartas empezaron a revelar una sobreestimación patológica de su estatus y destino. Sobrevaloraba la respuesta creciente a sus escritos, sobre todo por la reciente polémica respecto a "El caso Wagner".

Hay que tener en cuenta que en 1867, Nietzsche fue tratado por una infección sifilítica que finalmente desembocó en la crisis mental de enero de 1889, fin efectivo de la vida de Nietzsche aunque viviría, en silencio y perdido en sí mismo, hasta 1900. La sífilis era el sida de su tiempo, y cuando leemos a Nietzsche, especialmente su obra tardía, como "Ecce Homo" o "El Anticristo", deberíamos tener bien presente el hecho de su enfermedad.

De octubre a noviembre de 1888, Nietzsche trabaja en la obra "Ecce homo (Cómo se llega a ser lo que se es)", que no verá la luz hasta el año 1908 en una versión en la que el capítulo «Por qué soy tan sabio» no aparece, siendo sustituido por otro capítulo escrito anteriormente que el propio autor descartó.

El 3 de enero de 1889 Nietzsche sufrió un colapso mental. Ese día fue detenido tras, al parecer, haber provocado algún tipo de desorden público, por las calles de Turín. Lo que pasó exactamente es desconocido. La versión más extendida sobre lo sucedido dice que Nietzsche caminaba por la Piazza Carlo Alberto, cuando un repentino alboroto que causó un cochero al castigar a su caballo llamó su atención. Nietzsche corrió hacia él y lanzó sus brazos rodeando el cuello del caballo para protegerlo, desvaneciéndose acto seguido contra el suelo. En los días siguientes, escribió breves cartas para algunos amigos, incluidos Cósima Wagner y Jacob Burckhardt, en las que mostraba signos de demencia y megalomanía.

A su colega Burckhardt escribió: «He tenido Caiphas puestos. Además, el año pasado fui crucificado por los doctores alemanes de una manera muy drástica. Wilhelm, Bismarck, y todos los antisemitas abolidos». El 6 de enero de 1889, Burckhardt mostró la carta a Overbeck. El siguiente día Overbeck recibió una carta reveladora semejante, y decidió que Nietzsche debería volver a Basilea. Overbeck viajó a Turín y trajo a Nietzsche a una clínica psiquiátrica en Basilea.

Por ese tiempo, Nietzsche estaba enteramente sumergido en la locura, y su madre Franziska decidió llevarlo a una clínica en Jena bajo la dirección de Otto Binswanger. Desde noviembre de 1889 a febrero de 1890, Julius Langbehn intentó curar a Nietzsche, sentenciando que los métodos del doctor eran ineficaces para curar su condición. Langbehn asumió más y más control sobre Nietzsche. En marzo de 1890, Franziska sacó a Nietzsche de la clínica, y en mayo de 1890 lo llevó a su casa en Naumburgo.

Durante este proceso, Overbeck y Gast contemplaban la idea de qué hacer con el trabajo no publicado de Nietzsche. En enero de 1889 se pusieron a planear la salida de "El ocaso de los ídolos, o cómo se filosofa a martillazos", por esa época ya impreso y atado. En febrero, ordenaron una edición privada de 50 copias de "Nietzsche contra Wagner", pero el editor C. G. Nauman en secreto imprimió 100. Overbeck y Gast decidieron publicar con reservas "El Anticristo" y "Ecce homo" debido a su contenido más radical.

En 1893, Elisabeth Nietzsche volvió de Paraguay después del suicidio de su marido. Leyó y estudió los trabajos de Nietzsche, y pieza por pieza tomó control sobre ellos y su publicación. Overbeck fue paulatinamente relegado al ostracismo, y Gast finalmente cooperó. Después de la muerte de Franziska en 1897, Nietzsche vivió en Weimar, donde fue cuidado por Elisabeth, quien permitió a la gente visitar a su poco comunicativo hermano. El 25 de agosto de 1900, Nietzsche murió después de contraer neumonía. Por deseo de Elisabeth, fue inhumado junto a su padre en la iglesia de Röcken.

La causa del hundimiento de Nietzsche ha sido un tema de especulación y origen incierto. Un frecuente y temprano diagnóstico era una infección de sífilis, sin embargo, algunos de los síntomas de Nietzsche eran inconsistentes. Otro diagnóstico posible es un meningioma derecho retroorbital, un tipo de cáncer cerebral. En su libro "La lucha contra el demonio", Stefan Zweig presenta una psicobiografía sobre Nietzsche en que sitúa la etiología de su locura desde un ángulo puramente psicogénico.

Hay una controversia sobre si Nietzsche abogaba por un único punto de vista de comprensión filosófica. Muchos cargan contra Nietzsche por la contradicción de sus pensamientos e ideas.

Una tesis alternativa en la contradicción de los escritos de Nietzsche es el de la perspectiva, o la idea de que Nietzsche usaba múltiples puntos de vista en su trabajo como un medio para retar al lector a considerar varias facetas de un tema. Si uno acepta su tesis, la variedad y número de perspectivas sirven como una afirmación de la riqueza de la filosofía. Esto no quiere decir que Nietzsche viera todas las ideas como igualmente válidas. Tenía aspectos en los que no estaba de acuerdo con respecto a otros filósofos como Kant. Tampoco está claro dónde se posicionaba Nietzsche en cada tema. De cualquier modo, si uno mantiene los elementos en conflicto de sus escritos como algo intencionado o no, hay pocas dudas de que sus ideas siguen siendo influyentes.

Algunos filósofos han designado al estilo aforístico de Nietzsche como el responsable de estas aparentes contradicciones en su pensamiento, llegando a decir por ejemplo que «hay tantos Nietzsches como lectores». Esta afirmación resulta excesivamente cómoda ya que solo pretende facilitar la explicación de las contradicciones sin intentar desentrañar su sentido final.

La filosofía de Nietzsche se halla atravesada esencialmente por la herencia de la cosmología clásica, en particular por los conceptos de la cosmogonía griega. Esto es, la identificación del carácter más humano del hombre en relación con el vínculo que guarda con sus dioses. Hablamos de la dualidad de lo apolíneo contra lo dionisíaco. Nietzsche, aunque no descarta por completo la regencia de lo apolíneo en la vida como ha sido heredada, particularmente desde la modernidad, se inclina por resaltar y adoptar una postura en esta línea de lo dionisíaco. En ello consiste precisamente su crítica a la sociedad contemporánea y este será el hilo conductor que permea de forma constante su obra y su vida.

Lo «apolíneo» y lo «dionisíaco» son dos conceptos filosóficos relacionados y dicotómicos que se basan en dos figuras de la mitología griega: Apolo y Dioniso. Este motivo suele vincularse a la obra temprana de Nietzsche "El nacimiento de la tragedia en el espíritu de la música". No obstante, escritores como el poeta Friedrich Hölderlin ya lo habían tratado con anterioridad. Un año antes de la publicación de "El nacimiento de la tragedia", Nietzsche escribió un fragmento titulado «Sobre la música y las palabras» en el que afirmaba la idea de Schopenhauer de que la música es una expresión primaria de la esencia de todo. Consideraba la poesía, la lírica y el drama como derivados de la música.

Apolo representa la armonía, el progreso, la claridad y la lógica, mientras que Dioniso representa el desorden, la embriaguez, la emoción y el éxtasis. Para Nietzsche son dos ideas contrapuestas y dos pilares de la cultura griega. También se entienden como dos estados cognitivos que se representan en el arte o como dos fuerzas de la naturaleza humana.

Según Nietzsche, desde Parménides y, sobre todo, a partir del idealismo platónico, la filosofía occidental adopta un esquema negador del mundo que culminará en las concepciones cristianas. Esto ha llevado a una visión dualista de las cosas (experiencia física y realidad espiritual), con una primacía de esta última como la única verdadera, con valor positivo y situada en un "más allá". Así, el pensador alemán ve en la metafísica y la religión una reacción de fuga ante la vida concreta, de creación de refugios imaginarios. Nace así un primer nihilismo "implícito" bajo la máscara "positiva" de una revelación, de una fe, reduciendo la realidad sensible a una cuasi nada (apariencias). Sería preciso, pues, comenzar por emprender una labor crítica —hermenéutica, genealógica— para desenmascarar ese nihilismo. A su vez, los avances científicos y la desmitificación de la realidad que culminan en la Europa del siglo XIX agudizan el proceso y ponen de manifiesto el peligro de un vacío de sentido para el hombre moderno o su recaída en nuevas ideologías negadoras de la vida.

Para Nietzsche, por tanto, la sociedad occidental se encuentra en vías de caer en un profundo nihilismo que ha de superar si no quiere ver su fin. El nihilismo (que tiene distintas formas) es un advenimiento de unas repetidas frustraciones en la búsqueda de significado, o más precisamente, «la desvalorización de los valores supremos». El nihilismo en Nietzsche se refiere al proceso histórico que surge en el reconocimiento de un valor sumo y termina en la asunción o reconocimiento de múltiples cosas valorables, al volverse inoperante lo que antes se mostraba como lo supremo. El nihilismo acontece en nuestro tiempo como manifestación de la ausencia de una medida única y, al mismo tiempo, como la proliferación de múltiples medidas que, en cada caso, pueden aparecer como válidas. Nietzsche ve en el despliegue del nihilismo toda fundación de cultura europea, la que surge como destino necesario de este proceso. La visión religiosa del mundo había sufrido ya un gran número de cambios por perspectivas contrarias, cayendo en el escepticismo filosófico, y en las teorías científicas evolucionistas y heliocéntricas modernas, lo que no hace más que confirmar la desvalorización de los valores supremos. A lo ya señalado, hemos de sumar una creciente presencia de lo democrático, la que se muestra como la afirmación de una individualidad independiente de Dios y acreedora de la igualdad, de la medianía. La democracia aparece, a los ojos de Nietzsche, como un momento del despliegue del nihilismo igualmente negador de la vida que los que la antecedieron. Ambas manifestaciones del nihilismo se muestran a Nietzsche como negaciones de la vida, al negar u olvidar dimensiones de la misma que, a su parecer, aparecen como constitutivas de ella e inalienables a lo que él considera vida. Estas dimensiones negadas de la vida se muestran en ámbitos tan determinantes como el constante darse del devenir y las diferencias entre los hombres.

Nietzsche ve esta condición intelectual como un nuevo reto para la cultura europea, lo que se ha extendido, asimismo, más allá de un pequeño punto de no-retorno. Nietzsche conceptualiza esto con su famosa frase, «Dios ha muerto», que aparece en "La gaya ciencia" y en "Así habló Zaratustra". Esta frase fue dada también por Hegel veinte años antes de que Nietzsche naciera. Este aforismo, por una parte, señala el fin de eso que antes aparecía como lo imperante, y por otra, indica un terreno fértil, un terreno inexplorado, en el cual el propio Nietzsche es un colono. A partir de la frase «Dios ha muerto», Nietzsche se refiere tanto a la ceguera del pasado en tanto incapacidad de ver esto, como a la asunción de una nueva posibilidad de relacionarse con lo que es, posibilidad dada por la asunción de dicha muerte.

Nietzsche trata esta frase más que como una mera declaración provocativa, casi como una revelación, como si representase el potencial de nihilismo que arrastra el alzamiento y el progreso, en el contexto de un concepto absurdo y sin significado.

Según Nietzsche, el hombre europeo descendiente de los hiperbóreos ha de asumir la gran e inevitable consecuencia de la muerte en la sociedad occidental de Dios, del dios judeocristiano, el vengativo y cruel Yahvé. La consecuencia de la muerte de Dios es que los valores vigentes en la sociedad occidental se vienen abajo ellos solos, según el nihilismo, o no se vienen abajo sino que los hombres los destruimos. Según Nietzsche la superación del nihilismo se producirá cuando el Übermensch imponga unos nuevos valores de acuerdo a la moral de señores, destruyendo los valores de la moral de esclavos. Resumiendo, destruimos los valores de los hombres para poner en su lugar los valores del Übermensch, que ocupará el lugar de Dios.

Nietzsche pensaba que había dos clases de hombres: los señores y los siervos, que han dado distinto sentido a la moral. Para los señores, el binomio «bien-mal» equivale a «noble-despreciable». Desprecian como malo todo aquello que es fruto de la cobardía, el temor, la compasión, todo lo que es débil y disminuye el impulso vital. Aprecian como bueno, en cambio, todo lo superior y altivo, fuerte y dominador. La moral de los señores se basa en la fe en sí mismos, el orgullo propio.

Por el contrario, la moral de los siervos nace de los oprimidos y débiles, y comienza por condenar los valores y las cualidades de los poderosos. Una vez denigrado el poderío, el dominio, la gloria de los señores, el esclavo procede a decretar como «buenas» las cualidades de los débiles: la compasión, el servicio —propios del cristianismo—, la paciencia, la humildad. Los siervos inventan una moral que haga más llevadera su condición de esclavos. Como tienen que obedecer a los señores, los siervos dicen que la obediencia es buena y que el orgullo es malo. Como los esclavos son débiles promueven valores como la mansedumbre y la misericordia; por el contrario, critican el egoísmo y la fuerza.

La crítica de Nietzsche a la moral tradicional se centraba en la tipología de moral de «amo» y de «esclavo» y en la descripción de la dinámica que generan; esta dinámica o dialéctica debe ser conocida por los «espíritus libres» para conducir a la humanidad a su superación: una sucesión de continuas superaciones —la moral deja de ser algo cerrado para ser visto como una dinámica de morales yuxtapuestas y reconocibles en la dinámica de las lenguas. Examinando la etimología de las palabras alemanas "gut" («bueno»), "schlecht" («malo») y "böse" («malvado»), Nietzsche sostuvo que la distinción entre el bien y el mal fue originalmente descriptiva, o sea, una referencia amoral a aquellos que eran privilegiados (los amos), en contraste con los que eran inferiores (los esclavos). El contraste bueno/malvado surge cuando los esclavos se vengan "convirtiendo los atributos de la supremacía en vicios". Si los favorecidos (los «buenos») eran poderosos, se decía que los sumisos heredarían la Tierra. El orgullo se volvió pecado, mientras que la caridad, humildad y obediencia reemplazaron a la competencia, el orgullo y la autonomía. La insistencia en la absolutidad ("Absolutheit") es esencial tanto en la ética religiosa como filosófica y fue clave para el triunfo de la moral de esclavo mediante la presunción de ser la única moral verdadera.

La voluntad de poder ("der Wille zur Macht") es un concepto altamente controvertido en la filosofía nietzscheana, generando intenso debate e interpretaciones varias, algunas de las cuales, como la notoria interpretación dada por los intelectuales nazis, fueron intentos deliberados de justificación de tácticas políticas.

Una manera de abordar este concepto es por medio de la crítica nietzscheana a la teoría de la evolución de Darwin. Nietzsche veía en los instintos una fuerza que iba más allá del sólo impulso a sobrevivir, protegerse y reproducirse de todos los seres vivos, de sólo ser esto la vida se estancaría. La supervivencia era una de las consecuencias de un deseo aún mayor, impulso hacia una supravivencia, un deseo perpetuo de todo ser vivo por ir más allá de todos, el todo y hasta más allá de sí mismo, más allá de la muerte. Este impulso irracional o deseo perpetuo por expandirse impreso en cada ser es lo único que da sentido a la existencia, paradójicamente «razón de ser» y es la fuerza principal dentro de la visión trágica o dionisíaca de Nietzsche.

Las teorías posteriores de Sigmund Freud respecto al inconsciente probablemente fueron inspiradas en gran parte por los conceptos de lo Dionisíaco y la voluntad de poder, las cuales Freud relacionó a los instintos sexuales primitivos, por encima de cualquier otro instinto, y su represión y control excesivo por el consciente o parte Apolínea del ser como generadores de la histeria y otras dolencias.

La idea del eterno retorno ha sido tratada como un concepto basilar para Nietzsche por muchos, aunque no por todos los intérpretes.

Nietzsche encuentra la idea en los trabajos de Heinrich Heine, quien especulaba que llegaría el día en el que la persona volvería a nacer con el mismo proceso de él mismo, y con el mismo en todas las demás personas. Nietzsche expandió este concepto para formar su teoría, la cual resaltó en "La gaya ciencia" y desarrolló en "Así habló Zaratustra". En las lecturas de Nietzsche sobre Schopenhauer, le saltó la idea del eterno retorno. Schopenhauer sentenciaba que una persona que se afirmara en la vida incondicionalmente lo haría incluso si todo lo que le había pasado le ocurriera de nuevo de forma repetida.

En unas pocas ocasiones en sus notas, Nietzsche discurre la posibilidad del eterno retorno como verdad cosmológica (véase el libro de Arthur Danto "Nietzsche como filósofo" para un análisis en detalle de estos esfuerzos), pero en los trabajos que él preparó para publicar está tratado como el método más vanguardista de afirmación de la vida. Según Nietzsche, requeriría un sincero "Amor fati" («Amor al destino»), no simplemente para sobrellevar, sino para desear la ocurrencia del eterno retorno de todos los eventos exactamente como ocurrieron, todo el dolor y la alegría, lo embarazoso y la gloria, esta repetición, más de emociones y sentimientos que de hechos, es lo que configuraría el tipo y la raza universal y global del por venir, no como una raza de las ya existentes, sino como una posibilidad abierta del hombre inacabado como especie genética y lingüística que debe ser perfilada por el eterno retorno de la superación de sus previos pensamientos y hechos.

Nietzsche menciona la idea de lo «horrible y paralizante», y también mantiene que la carga de esta idea es el peso más pesado imaginable ("Das schwerste Gewicht"). El deseo del eterno retorno de todos los eventos marcaría la afirmación de la vida definitiva.

Según algunos intérpretes, el eterno retorno es más que el mero concepto intelectual o reto, refleja una "Kōan", o característica psicológica que ocupa la estimulación consciente etérea, una transformación de consciencia conocida como "metanoia".

Alexander Nehamas escribió en "Nietzsche: vida como literatura" que hay tres maneras de ver el eterno retorno: (a) Mi vida volverá del mismo modo. Esto es una aproximación fatalista a la idea; (b) Mi vida puede ocurrir del mismo modo. Esta segunda visión es una aserción condicional de cosmología, pero falla al captar lo que Nietzsche se refiere en "La gaya ciencia"; (c) Es mi vida por re-ocurrir, entonces podría re-ocurrir sólo en idéntico modo. Nehamas muestra que esta interpretación es totalmente independiente de la física y no presupone la verdad de la cosmología. La interpretación de Nehamas es que los individuos se constituyen ellos mismos a través de las acciones y la única manera de mantenerse a ellos mismos como son es vivir en una reocurrencia de acciones pasadas.

El eterno retorno cumple pues dos funciones en la filosofía de Nietzsche. La primera es remarcar el amor a la vida. Los cristianos postulan un paraíso, Platón el mundo de las ideas. Nietzsche dice que después está otra vez la tierra, el mundo: porque no hay nada más. Por otro lado cumple una función ética. Quien acepta el eterno retorno, se previene y acepta sus actos. Con el dolor que puedan contraer, con el placer que puedan conllevar: no hay lugar para el arrepentimiento.

Extrapolando ideas del darwinismo Nietzsche considera que el ser humano ("Mensch") es un ser incompleto, pues todo animal da lugar a algo superior. Es un puente entre el simio y el "Übermensch" (término que ha sido traducido con frecuencia, aunque no con excesiva fortuna, como 'superhombre' o 'suprahombre', existiendo autores que prefieren su traducción como 'ultrahombre'). El hombre es, por tanto, algo que debe ser saltado, superado. El "Übermensch" es aquel ser que tiene una moral de nobles, es un noble, y acepta la voluntad de poder: es un hombre legislador, él crea sus propias normas, morales y de todo tipo, además es un hombre que somete las cosas a su voluntad, es un hombre vital: ama la vida y este mundo. Además es un ser que acepta el eterno retorno, pues cuando toma una decisión realmente la quiere tomar, y no se arrepiente de sus actos. Sabe que la vida es en parte dolor y en parte placer, pero no reniega de ello.

Desarrollando la idea del nihilismo, Nietzsche escribió "Así habló Zaratustra", introduciendo en él el concepto del primer hombre creador de valores, no como un proyecto, sino como un antiproyecto, la ausencia de proyecto alguno. En dicho libro Zaratustra se refiere a las «tres transformaciones del espíritu», el que se transforma figurada y sucesivamente en camello, león y finalmente niño. Este estado amoral y de creación de nuevos valores puede interpretarse como el inicio del camino hacia el ideal del "Übermensch": «Inocencia es el niño, y olvido, un nuevo comienzo, un juego, una rueda que se mueve por sí misma, un primer movimiento, un santo decir sí. Sí, hermanos míos, para el juego del crear se precisa un santo decir sí: el espíritu quiere ahora su voluntad, el retirado del mundo conquista ahora su mundo».

Hay controversia sobre qué o a quién consideraba Nietzsche como «Übermensch». No solo hay cierta base para pensar que Nietzsche era escéptico sobre la identidad individual y la noción de sujeto, sino que habría un ejemplo concreto del Ultrahombre como algo nuclear. Las interpretaciones modernas de Nietzsche, especialmente después del trabajo de Walter Kaufmann, sugieren que la visión de Nietzsche sobre el "Übermensch" está más en línea con el concepto de hombre renacentista, como Goethe o Da Vinci.

Normalmente se traduce como «superhombre»; sin embargo esta traducción es errónea ya que el prefijo alemán "über" significa 'superior' como adjetivo, o 'sobre' (como el "over" inglés). Además "Mensch" significa 'humano', 'persona', esto es, 'hombre' en términos de especie, y no de sexo. En castellano puede dar lugar a equívocos si se lo lee con mala intención. Por lo tanto, la traducción más correcta al castellano sería 'suprahumano' o 'sobrehumano', pero en el uso más convencional sería 'suprahombre', o bien, 'ultrahombre', tal como el filósofo Vattimo ha sugerido.

Siempre debe recordarse que el concepto se contrapone a cualquier término sexista y al del «último hombre», el que presenciará el gran mediodía que representa el último paso de superación del hombre moral y septentrional, y la etapa final del nihilismo. Es en este sentido en que debe entenderse al super-hombre como uno de los objetivos nietzscheanos, y no como una «calidad» a la que se pueda acceder, o una «categoría» que se pueda obtener.

En su libro "El Anticristo, maldición sobre el cristianismo" (1888), Nietzsche escribe sobre cómo la cristiandad se ha convertido en una ideología establecida por instituciones como la Iglesia, y cómo las iglesias han fallado a la hora de representar la vida de Jesús. Es importante destacar que Nietzsche vivió en una sociedad protestante y su repulsa hacia el cristianismo se forjó a partir del conocimiento de dicha doctrina. Es importante, para él, distinguir entre la religión de la cristiandad y la persona de Jesús. Nietzsche explicó la religión cristiana como si fuera representado por iglesias e instituciones a las que llamaba su «transvaloración» (del alemán "Umwertung") de los valores instintivos saludables. Transvaloración es el proceso por el cual el significado de un concepto o ideología puede ser puesto al revés de lo expresado por su etimología. Fue más allá del pensamiento de los agnósticos o ateos de la Ilustración, quienes sentían que la Cristiandad era simplemente falsa. Él afirmaba que ha podido ser deliberadamente infundida como una religión subversiva (como un arma psicológica subversiva) dentro del Imperio Romano por el apóstol Pablo como una forma de cobrar venganza por la destrucción romana de Jerusalén y su templo durante la Primera guerra judeo-romana.

Nietzsche contrasta a los cristianos con Jesús, a quien admiraba de gran modo. Nietzsche argumenta que Jesús transcendió las influencias morales de su tiempo creando su propio sistema de valores. Jesús representaba un paso hacia el "Übermensch". Al final, Nietzsche clama sin embargo: en contraste con el suprahombre, quien abraza la vida, Jesús negaba la realeza en favor de su «Reino de Dios». La negación de Jesús para defenderse a sí mismo, y su muerte, eran consecuencias lógicas de su desajuste de sistema de ideas.

Nietzsche entonces analizó la historia de la cristiandad, descubriendo una distorsión progresiva de modo grotesco de las enseñanzas de Jesús. Él critica a los primeros cristianos por convertir a Jesús en un mártir y la vida de Jesús dentro de la historia de la salvación de la humanidad como motivo para dominar a las masas, encontrando a los apóstoles cobardes, vulgares y resentidos. Argumenta que las sucesivas generaciones malentendieron la vida de Jesús, mientras la influencia de la cristiandad crecía. En el siglo XIX, Nietzsche concluye que la cristiandad se ha vuelto tan mundana al punto de hacerse una parodia de sí misma, una total manipulación de sus enseñanzas y su «buena nueva». Es por esto que concluyó en una de sus frases más célebres: «El último cristiano murió en la cruz», considerando que Pablo de Tarso y los primeros cristianos (los «anticristianos») solo hicieron negocio con su figura a través de su Iglesia y nadie siguió realmente ni aspiró jamás a aceptar la doctrina de Cristo. Estas afirmaciones de Nietzsche contradicen al hecho histórico de que Pablo de Tarso gozaba de una posición muy privilegiada antes de convertirse al cristianismo, tras lo cual fue perseguido y encarcelado en varias ocasiones hasta el final de su vida; para G. K. Chesterton con este tipo de afirmaciones Nietzsche faltaba a la verdad y demostraba tener unos conocimientos muy limitados sobre la historia del cristianismo.

Nietzsche aborda la ética desde diferentes perspectivas. En términos de hoy en día, podemos decir que sus obras tocan los ámbitos de la metaética, la ética normativa, y la ética descriptiva.

En lo referente a la metaética, Nietzsche puede ser clasificado quizá como un escéptico moral. Esto es en la medida en que afirma que todas las sentencias éticas son falsas, porque cualquier tipo de correspondencia entre sentencias morales y hechos es ilusoria y mendaz. Esta afirmación forma parte de aquella otra más general según la cual no existe una verdad universal, pues ninguna corresponde a la realidad más que de una forma aparente. En realidad, las afirmaciones éticas, como todas las afirmaciones, son meras interpretaciones como mínimo siempre parciales sobrepuestas a la realidad, fundamentalmente ininterpretable.

A veces, Nietzsche parece tener opiniones muy definidas de lo que es moral e inmoral. Hay que notar, no obstante, que las opiniones morales de Nietzsche se pueden explicar sin atribuirle la afirmación de que son "ciertas". Según Nietzsche, no necesitamos descartar una afirmación simplemente porque sea falsa. Al contrario, a menudo afirma que la falsedad es esencial para la vida. Curiosamente, en sus discusiones figuradas con Wagner en "El caso Wagner" menciona la "mentira deshonesta", como opuesta a la "mentira honesta". Posteriormente menciona a Platón como referente sobre esta última. Esto debería dar una idea de los múltiples niveles interpretativos de su obra, a menudo aparentemente paradójicos si no se toman las debidas cautelas hermenéuticas.

En la disyuntiva entre ética normativa y ética descriptiva distingue entre la "moral de señor" y la "moral de esclavo". Aunque reconoce que es muy difícil encontrar un ejemplo real de alguien que mantenga una u otra moral pura sin algún tipo de yuxtaposición (de hecho era consciente de estar haciendo historia al vislumbrar «genealógicamente» esta distinción), las presenta, a lo largo de la historia y actualmente en tanto que pulsiones humanas atemporales, una en contraste de la otra. Algunos de estos contrastes de una moral frente a la otra son:


Estas ideas fueron elaboradas en su libro "La genealogía de la moral", en el cual además introdujo el concepto clave del "resentimiento" como base de la moral del esclavo.

También es conocido por su frase «Dios ha muerto». Aunque popularmente se cree que es de Nietzsche de quien procede esta frase, es puesta en boca de un personaje, un hombre loco, en "La gaya ciencia", que más adelante fue repetida por el Zaratustra de Nietzsche. Estas frases malinterpretadas no proclaman una muerte física, sino un final natural a la creencia de dios. Está altamente malentendido como una declaración de regocijo, cuando es descrito como un lamento trágico por el personaje de Zaratustra.

«Dios ha muerto» es más una observación que una declaración. Nietzsche no dio argumentos para el ateísmo, sino meramente observó que, para todos los efectos prácticos, sus contemporáneos vivían como si Dios estuviera muerto. Nietzsche creía que esta muerte minaba los fundamentos de la moral y que acabaría por desembocar en el más completo nihilismo y relativismo moral. Para evitar esto, él creía en la revaluación de los fundamentos de la moral para comprender mejor los motivos y orígenes subyacentes de los primeros. De esta manera los individuos podrían decidir por sí mismos si un valor moral es obsoleto o está desviado por imposiciones culturales o quieren realmente tomar ese valor como cierto.

Para el filósofo francés Michel Onfray, el principal logro de Nietzsche viene tras pensar después de su obra, esto es, según sus propias palabras, «ser nietzscheano implica pensar a partir de él». Seguir a Nietzsche no tendría nada que ver con «seguir las tesis mayores del filósofo« ni «cambiarse por Nietzsche». La labor de Nietzsche habría sido construir una obra para «apoyarse en ella como quien se apoya en una formidable palanca para mover las montañas filosóficas».

Si bien es fácil ver un aire político en los escritos de Nietzsche, su trabajo no fue de ningún modo pensado para promocionar ideas políticas como en Aristóteles Política (Aristóteles) o en Platón República (Platón), el pensamiento de Nietzsche propone significativas ideas sobre el concepto de poder, Estado, individuo, voluntad y libertad. La influencia que Nietzsche ejerció sobre la política de la «nueva derecha» en Francia fue realmente extensa. Afirmó que el poder de un sistema es signo de falta de integridad, no propuso un sistema de gobierno específico como solución, y nunca se vinculó a sí mismo con movimientos de masas, organizaciones sociales o partidos políticos. En este sentido, Nietzsche casi podría ser llamado un pensador anti-político. Walter Kaufmann enfatiza la visión de que el poderoso individualismo expresado en sus escritos sería desastroso si se practicara en las bases reales de los políticos. Escritores posteriores, guiados por la izquierda intelectual francesa, han propuesto maneras de usar la teoría nietzscheana en lo que se ha llegado a conocer como «políticas de diferencias», en especial formulando teorías sobre resistencia política y sobre diferencias sexuales y morales. Para el politólogo norteamericano las ideas políticas que inspira Nietzsche se podrían materializar en una "revolución de la cultura". Para Yack, así como la humanidad ha vivido las revoluciones propuestas por Rousseau o Marx, Nietzsche propone también una revolución política "total" fundamentada en lo que él denominó, los espíritus libres y la voluntad de poder. Esta revolución total nietzscheana, sería la revolución de la cultura, que según Yack, aún no ha llegado. En la misma línea que Bernard Yack, Daniel Conway y , filósofos británicos contemporáneos, analizan el pensamiento de Nietzsche como pensador político. En América Latina, el Politólogo y profesor de teoría política de Colombia, Luis Arévalo, retoma estos estudios en el paper académico: El concepto de Gran Política desde el concepto de Gran Europa en la obra de Nietzsche, En este paper, Luis Arévalo explora el concepto de Gran Política y Gran Europa en la obra de Nietzsche para hacerlos evidentes en el desarrollo de sus escritos. Asimismo, deja planteada la idea de un enorme potencial para la comprensión de los escritos de Nietzsche en términos de poder, individuo, voluntad y razón teleológica de lo político en Nietzsche. 

Revisando ampliamente los escritos de Kauffmann y otros, el espectro del nazismo ha sido hoy en día casi extinto de sus escritos.Por el trabajo de los italianos Giorgio Colli y Massimo Montanari hoy sabemos que la obra de Nietzsche fue manipulada por los Nazis a pedido de Hitler. La hermana de Nietzsche, jugó un papel determinante en la manipulación de fragmentos póstumos de su hermano, y la venta y manipulación de sus escritos a los nazis. Notablemente, la obra La Voluntad de Poder, (que es un compendio de fragmentos póstumos). Esta manipulación llegó a tal punto que Montinari publicará el libro, Nietzsche a menudo se refería como «el rebaño» a los participantes de los movimientos de masas que comparten una psicología común de la masa. Valoraba el individualismo y el lenguaje como obra común que nos construye, pero consideraba sus obras como regalos a la humanidad. Despreciaba al Estado moderno, Nietzsche también habló negativamente de demócratas y socialistas y dejó claro que sólo ciertos individuos podían romper la moral del rebaño. Pero son sus propias palabras las que deberían alejar cualquier sospecha de simpatía con el nazismo:

Al pueblo se refería como «perro de fuego». En "Zaratustra" desarrolla esta idea como fuerzas dinámicas de las que hay que tomar partido en el desarrollo histórico. El perro de fuego representa los ideales populares por diferenciarse de otros pueblos. En «De viejas y nuevas tablas», desarrolla también la idea de cómo ciertos valores morales acaban por ser institucionalizados en normas de domesticación y a eso llaman nacionalismo... ¡domesticar a favor del Estado al perro de fuego que cometió esos desmembramientos de cabeza y dio su apoyo popular a Napoleón! Solo el individuo alienado de las masas puede comprender su situación con respecto al resto.

Los comentarios de Nietzsche sobre las mujeres han provocado una gran polémica. El hecho de que Nietzsche ridiculizara a la humanidad en general no le salva de la carga del sexismo. Algunas de sus afirmaciones sobre las mujeres parecían prefigurar la crítica del posfeminismo contra las versiones primerizas del feminismo, particularmente aquellas que afirman que el feminismo ortodoxo discrimina a las propias mujeres en función de su posición social privilegiada. En este contexto, el pensamiento de Nietzsche ha sido relacionado con el capítulo schopenhaueriano «Sobre las mujeres», de "Parerga y paralipómena", habiendo sido muy probablemente influenciado por él en algún grado.

De todos modos, Nietzsche en su libro "Más allá del bien y del mal" muestra un carácter misógino similar, en muchos aspectos, al de Schopenhauer. Ambos hablan del sexo femenino como de un "segundo papel", y sus comentarios tratan a la mujer hasta como un animal incluso haciendo apología de los tratos que se le daban a ellas en la antigüedad. Habla también, Nietzsche, del progreso del feminismo como una degeneración en la historia, principalmente en lo tratante a la igualdad de derechos a los cuales se muestra en contra.

Los escritos de Nietzsche han sido interpretados de diversas maneras, e incluso existen casos en los que Nietzsche es citado para sustentar visiones contradictorias.

Por ejemplo, Nietzsche era popular entre el ala izquierdista de la Alemania de 1890, pero unas décadas después, durante la Primera Guerra Mundial, muchos le vieron como la raíz del ala derecha del militarismo alemán. Tengamos en cuenta que es más factible que la derecha acepte las máximas nietzscheanas anticompasivas, belicosas y aristocráticas, en tanto las doctrinas igualitarias como el comunismo —con la excepción de la belicosidad y fórmulas anticompasivas aplicadas en el régimen comunista soviético— y la democracia fueron despreciadas por él. Otro ejemplo se establece en la época del «Caso Dreyfus». La derecha antisemita francesa elevó la acusación a judíos e intelectuales de izquierdas que defendían a Alfred Dreyfus de ser nietzscheanos. Los conservadores alemanes quisieron censurar los trabajos de Nietzsche ante el peligro de subversión en 1894-1895, mientras que la Alemania nazi lo utilizó como excusa intelectual para promover su idea de la resurrección de la cultura alemana y de la identidad nacional. Muchos alemanes leyeron "Así habló Zaratustra" y se vieron influenciados por el llamamiento de Nietzsche del individualismo ilimitado y al desarrollo de la propia personalidad. Así durante el final del Siglo XIX y el comienzo del Siglo XX las ideas de Nietzsche estaban comúnmente asociadas con el movimiento anarquista y parece que tuvieron una influencia dentro de este, particularmente en Francia y los Estados Unidos (véase también Anarquismo y Friedrich Nietzsche).

Durante el "interbellum", muchos fragmentos del trabajo de Nietzsche fueron apropiados por los nazis, principalmente por Alfred Bäumler en "La voluntad de poder". Durante el periodo de dominio nazi, las obras de Nietzsche fueron muy estudiadas en los colegios y universidades alemanas. Los nazis creyeron ver en Nietzsche a uno de los padres fundadores. Incorporaron la ideología y el pensamiento sobre el poder dentro de su propia filosofía política. Expresiones como "La voluntad de poder" fueron relacionadas con el nazismo y proclamadas como paradigma del movimiento. Sin embargo, existen muy pocas, si acaso alguna, similitudes entre Nietzsche y el nazismo. En múltiples pasajes a lo largo de sus obras, Nietzsche defiende ardorosamente a los judíos, y expresa su rabia contra la lenta pero imparable corriente antisemita en Alemania, personificada dolorosamente en su propia familia a través de la figura de su hermana, que adoptó fervientemente el ideario racista, influenciada por su marido, para el cual no escatimó el filósofo todo tipo de improperios en muchas de sus cartas.

Uno de los más importantes estudiosos de Nietzsche fue el reconocido filósofo alemán Martin Heidegger, en su voluminoso trabajo titulado con el apellido del filósofo.

En el ámbito de la psicología, el neurólogo Sigmund Freud no hizo suficientemente explícita la influencia del filósofo en su obra, aunque es ampliamente debatida, investigada y reinterpretada. El psiquiatra Carl Gustav Jung, sin embargo, vio en Nietzsche un importante punto de apoyo para el desarrollo de su propio pensamiento, sin tener las reservas que habían estado presentes en Freud. Ello se tradujo en que no tuvo problemas en hacer patente el vínculo de sus conceptos con la filosofía de Nietzsche. Las referencias a Nietzsche esta vez se hicieron frecuentes. Es más, Jung organizó un extenso seminario para estudiar una de las obras más importantes del filósofo: "El Zaratustra de Nietzsche".





</doc>
<doc id="2031" url="https://es.wikipedia.org/wiki?curid=2031" title="Neurofisiología">
Neurofisiología

La Neurofisiología es la rama de la fisiología que estudia el sistema nervioso.

En cualquier acción o conducta de todo organismo está presente el sistema nervioso. Cualquier cambio en su desarrollo es resultado de modificaciones funcionales de dicho sistema.
La neurofisiología se ocupa de desvelar cómo funciona este complicado sistema y cómo produce la variedad de modelos de conductas que manifiestan los organismos. Sin embargo, a pesar de los avances producidos en la investigación, sobre todo en los aspectos bioquímicos y eléctricos, se tiene la convicción de que es mucho más lo que se desconoce.


La neurofisiología elemental trata de estudiar el comportamiento de neuronas o grupos de neuronas aisladas. Los hechos establecidos por la neurofisiología elemental pueden ser aprovechados por la teoría matemática de redes neuronales para construir modelos matemáticos que permitan identificar fenómenos neurofisiológicos como la memoria y el aprendizaje.
Los principales hechos establecidos por la neurofisiología elemental tenidos en cuenta en la construcción de modelos de redes neuronales son:



</doc>
<doc id="2032" url="https://es.wikipedia.org/wiki?curid=2032" title="Neuroanatomía">
Neuroanatomía

La neuroanatomía es el estudio de la estructura y la organización del sistema nervioso.
Se llama neuroanatomía comparada a la ciencia que analiza y compara los sistemas nerviosos de las diferentes especies. Desde los sistemas más simples hasta el de los mamíferos y el hombre.

El primer registro escrito conocido de un estudio de la anatomía del cerebro humano es egipcio, el papiro de Edwin Smith. El siguiente desarrollo importante en neuroanatomía fue de unos mil años más tarde, cuando el griego Alcmeón determinó que el cerebro y no el corazón, como se creía, gobierna al cuerpo y recibe información de los sentidos. Uno de los fundadores de la neuroanatomía moderna fue el descubridor de la neurona, el español Santiago Ramón y Cajal, premio Nobel de medicina en 1906.

El sistema nervioso de los vertebrados está constituido por el cerebro y la médula espinal (el sistema nervioso central o SNC) y por las rutas de los nervios que se conectan con el resto del cuerpo (el sistema nervioso periférico o SNP). 
El sistema nervioso central (SNC) consiste en el cerebro, la retina, y la médula espinal, mientras que el sistema nervioso periférico (SNP) se compone de todos los nervios fuera del sistema nervioso central que lo conectan con el resto del cuerpo.

El sistema nervioso central está compuesto de las regiones del cerebro, tales como, por ejemplo, el hipocampo que es crítico para la formación de las memorias. 
El sistema nervioso también contiene los nervios, que son haces de fibras que se originan en el cerebro y la médula espinal, y se ramifican varias veces para inervar a cada parte del cuerpo. Los nervios están constituidos principalmente de los axones de las neuronas, junto con una variedad de membranas que recubren los fascículos nerviosos.

El cerebro y la médula espinal están exteriormente protegidos por las estructuras óseas que son el cráneo y la columna vertebral. Interiormente son envueltos por tres membranas: la duramadre, la aracnoides y la piamadre. Además están bañados por el líquido cefalorraquídeo que completa los espacios vacíos y actúa como amortiguador de golpes, entre otras funciones.

Con el fin de precisar las ubicaciones anatómicas se hacen frecuentes referencias a detalles notorios del cerebro como las cisuras y se utilizan planos de orientación o planos de sección que generalmente son "sagital", "transversal" o "coronal" u horizontal. 

El SNC está constituido anatómicamente por él:

El SNP está constituido por:

El SNP se subdivide en el somático y el sistema nervioso autónomo. 
El sistema nervioso autónomo también tiene dos subdivisiones, el simpático (SNS) y el parasimpático (SNPS), que son importantes para la regulación del cuerpo en las funciones básicas del organismo, tales como el ritmo cardíaco, la respiración, la digestión, el control de temperatura, etc
El SNS prepara al cuerpo para actuar en una emergencia y el SNPS dispone al cuerpo conservar y restablecer energía.
Mucho de lo aprendido procede de observar cómo las "lesiones" de áreas específicas del cerebro afectan al comportamiento u otras funciones.
Nuevos recursos han ido mejorando las posibilidades de observar la situación y los aspectos del funcionamiento cerebral en personas vivas y sanas. La tomografía computada, la resonancia magnética y los emisores de positrones (PET) son creadores de imágenes sin “invadir” a la persona observada. 
Este último, con el auxilio de productos apropiados inyectados, permite observar el grado de actividad de cada zona cerebral en diferentes circunstancias. Así se logra determinar con mayor precisión las zonas involucradas en el razonamiento, la memoria, las emociones como el amor, el miedo, etc., y se conocen los trayectos que realizan los estímulos nerviosos que participan.

Se sitúa dentro del conducto rodeada por las tres meninges y el líquido cefalorraquídeo. La arquitectura de la médula espinal es aproximadamente cilíndrica, y comienza por arriba en el agujero occipital en el cráneo, a donde se continúa con el bulbo raquídeo, y termina por debajo de la región lumbar en forma de huso en el cono medular, desde cuyo vértice se conforma desciende una prolongación piamádrica, formando al Filo Terminal o "Filum Terminalis".

A lo largo del trayecto de la médula espinal se localizan 31 pares de nervios espinales unidos por raíces anteriores o motríces, y raíces posteriores o sensitivas.

La estructura de la médula espinal está compuesta en su porción céntrica por la sustancia gris, y en su periferia por la sustancia blanca.

En un corte transversal se puede observar a la sustancia gris formar una silueta similar al de una mariposa, con sus cordones grises anteriores y posteriores unidas por la comisura gris. La sustancia blanca se divide en cordones blancos anteriores, laterales y posteriores. 

La arquitectura de la médula espinal cambia de acuerdo a su posición. 

Se sitúa en la cavidad craneana y se continúa con la médula espinal a través del agujero occipital. Está rodeado por tres meninges. El encéfalo se divide en tres partes principales, estas son:


La base celular del sistema nervioso se compone de neuronas, células gliales, y matriz extracelular. Existen neuronas y células gliales de muchos tipos. Las neuronas son las células de procesamiento de información del sistema nervioso: generan la sensación de nuestro entorno, producen nuestros pensamientos y provocan nuestros movimientos. Se comunican entre sí por medio de señales eléctricas que recorren sus prolongaciones: los axones y las dentritas; las uniones interneuronales se llaman sinapsis y son estructuras complejas. Las células gliales mantienen la homeostasis, la producción de mielina, y brindan apoyo y protección a las neuronas del cerebro. Algunas células gliales (astrocitos) incluso pueden propagar las ondas de calcio intercelular por largas distancias en respuesta a la estimulación y liberar “gliotransmisores” en respuesta a cambios en la concentración de calcio. La matriz extracelular proporciona también apoyo a nivel molecular para las células del cerebro.

Estos recursos se utilizan en muestras obtenidas en biopsias, necropsias y en animales. 
La tinción es una técnica utilizada para mejorar el contraste creando características particulares en las imágenes microscópicas.
En histoquímica utiliza el conocimiento acerca de las propiedades bioquímicas de reacción de los componentes químicos del cerebro, especialmente de las enzimas.
La inmunocitoquímica es un caso especial de histoquímica que utiliza anticuerpos selectivos contra una variedad de epítopos químicas del sistema nervioso. Logra teñir selectivamente tipos particulares de células, fascículos axonales, neuropiles, procesos gliales o vasos sanguíneos, o ciertas proteínas específicas intracitoplasmáticas o intranucleares y otras moléculas inmunogenéticas. 
También se recurre a otras técnicas más complejas como la hibridación in situ que usa sondas de ARN, a marcadores codificados genéticamente y a ciertos virus que pueden replicarse en las células cerebrales y en las sinapsis.
Es muy útil la microscopía de electrones en serie (microscopio electrónico).



</doc>
<doc id="2033" url="https://es.wikipedia.org/wiki?curid=2033" title="Nuevo Testamento">
Nuevo Testamento

El Nuevo Testamento (NT) es la segunda parte de la Biblia cristiana. En el Nuevo Testamento suceden los hechos relativos a la vida, ministerio y crucifixión de Jesús de Nazaret, así como diversos hechos sucedidos en las primeras décadas del cristianismo. Compuesto entre los años 50 y 100 d. C., está formado por un conjunto canónico de libros y cartas escritas después de la crucifixión de Jesús de Nazaret, que la tradición apostólica hizo discernir a la Iglesia, aparta otros textos considerados apócrifos (griego: από 'lejos', κρυφος 'oculto'; latín: apócryphus). Se le designa como Nuevo Testamento desde Tertuliano en la Iglesia cristiana. Al contrario con el Tanaj hebreo, llamado por los cristianos Antiguo Testamento, los judíos (a excepción de los llamados judíos mesiánicos), no tienen el Nuevo Testamento en común con los cristianos.

El uso del término «testamento» proviene del vocablo hebreo "berith" ('alianza, pacto, convenio o disposiciones entre dos contratantes'), a través del griego "diatheké", y del latín "testamentum". Algunos autores presentan los nombres Antiguo y Nuevo Testamento con que se designa las dos grandes secciones en que se divide la Biblia cristiana como el resultado de un error de interpretación de la palabra "diatheké", que significa: 'deseo' o 'voluntad', y también 'acuerdo’ o 'convenio'. Con este criterio "diatheké" en griego haría referencia al antiguo y al nuevo convenio de Dios con los hombres más que a las Escrituras mismas.

Según otros autores, el término «testamento» proviene de la traducción de la Vulgata y del paso del concepto hebreo al griego, y sería el resultado de una búsqueda consciente. Los traductores de la Septuaginta habrían querido evitar que al hablar del "berith" (la alianza entre Dios e Israel) se entendiera que era un pacto entre iguales. Por eso no usaron el término griego "syntheké" (que se traduce por 'alianza'), sino que escogieron "diatheké", que se traduce por 'testamento' o 'voluntad', que es la obligación de uno solo con respecto a otro que solo recibe beneficios. De esta forma destacaron más la disparidad entre las partes (es decir, entre Dios y los hombres). Luego, esa es una de las acepciones de la palabra "testamentum", y de la castellana «testamento» (no entendida solo como última voluntad "ex mortis", como en el uso coloquial). De allí que las versiones latinas, como la de Jerónimo de Estridón, y la mayoría de las versiones de la Biblia cristiana siguen utilizando el término «testamento» en lugar de «alianza» para referirse al Antiguo Testamento (alianza del Sinaí) y al Nuevo Testamento (alianza en la sangre de Cristo).

Aun conviniendo que tales conceptos no hacen referencia a las colecciones de escritos sagrados, sino a relaciones entre la divinidad y los seres humanos en la historia religiosa, la mayoría de los eruditos simplemente se remiten al uso popular y coloquial de estos conceptos para referirse a los textos sagrados del canon hebreo y griego cristiano. 

Las versiones más antiguas de textos del llamado Nuevo Testamento, que se conservan, están escritas en el griego denominado koiné, la lengua franca en el Mediterráneo Oriental en época romana. La mayoría de los especialistas cree que este fue el idioma en que originalmente se redactaron, aunque algunos libros puedan haberse escrito primero en idioma hebreo o arameo, la lengua semita hablada por Jesús y su entorno. Aún hoy existen textos manuscritos fechados como desde el siglo V (cercanos a los más antiguos manuscritos griegos completos) en arameo como la Peshita siríaca, la Harclense y la Curetoniana, pero la mayoría de los estudiosos los consideran traducciones del griego.

La composición del canon neotestamentario se fijó poco a poco en los primeros siglos del nuevo movimiento. La lista más antigua se supone redactada hacia el año 170 d.C.

La lista actual fue publicada originalmente por Atanasio de Alejandría en 370 y consagrada como canónica en el Tercer Concilio de Cartago de 397. Sin embargo, las disputas sobre la composición del canon no cesaron. Martín Lutero cuestionó la pertinencia de incluir la Epístola de Santiago, la Epístola de Judas, la Epístola a los Hebreos y el Apocalipsis de Juan o Libro de la Revelación; aunque finalmente, a diferencia de los deuterocanónicos del Antiguo Testamento, no fueron nunca rechazados. Sin embargo, la canonización de 2 Pedro, 2 Juan, 3 Juan, Santiago y Judas, así como de Hebreos y Apocalipsis, sigue siendo tema de debate.

El Nuevo Testamento comprende los cuatro evangelios canónicos, los Hechos de los Apóstoles, las epístolas de Pablo de Tarso, siete epístolas generales de diversa atribución y el Apocalipsis, como se puede observar en el esquema que se encuentra a continuación.

Comprende, en total, 27 libros en el canon de la Iglesia católica, aceptado por la mayoría de las Iglesias de la Reforma. La Iglesia Siria solo acepta 22 libros en su canon. Libros como 1 y 2 de Clemente, el libro de la Alianza, el Octateuco y otros, han sido motivo de disputas, y se encuentran canonizados por parte de otras iglesias Católicas Ortodoxas.

Según Robert W. Funk, fundador del "Jesus Seminar" (‘seminario de Jesús’), existen muchas variantes en los distintos manuscritos griegos del Nuevo Testamento que han llegado hasta la actualidad; algunas son variantes menores sin trascendencia, pero también hay cambios significativos. Él asegura:

Los textos maestros se clasifican según criterio en "texto mayoritario recibido" o "Receptus" y "Texto Crítico". El primero prioriza las variaciones mayoritarias y tradicionales sin importar su antigüedad, se basa en la compilación iniciada por Erasmo. El segundo prioriza las lecturas más antiguas según criterio de jerarquía temporal, basándose en los textos más antiguos encontrados, aun recientemente, como el códice Sinaítico (costumbre seguida en las obras críticas de textos clásicos seculares). La vigésima séptima edición Nestlé-Aland es el texto maestro refinado más reciente y base para las traducciones vernáculas modernas.

Los manuscritos completos más antiguos del Nuevo Testamento son los códices pergaminos Sinaítico y Alejandrino, pero en cuanto a papiros, de data anterior existen cerca de cien papiros fragmentados (algunos caben en la palma de una mano).

El papiro Rylands (P) es el más antiguo de los manuscritos que se han encontrado de los cuatro evangelios canónicos. Se descubrió en el desierto de Egipto. Se publicó en 1935. Contiene algunos versículos del capítulo 18 del Evangelio de Juan (Jn 18,31-33.37-38). Según el estudio grafológico es anterior al año 150 (suele datarse hacia 125-130 d. C).

Fue encontrado en una tienda de antigüedades en Luxor (Egipto) a finales del siglo XIX. Fue adquirido por un sacerdote llamado Charles Bousfield Huleatt, quien tras su muerte donó el papiro al Magdalen College de Oxford, donde pasó a denominarse Gr 17. (suele datarse de 200 d. C).

Se trata de papiros descubiertos por M. Martin Bodmer. Del conjunto de cuatro papiros Bodmer (P66, P72, P73, P74) que se conservan en la Biblioteca de Cologny, en Ginebra, destaca el P66. Encontrado en Egipto y datado hacia el año 200, contiene catorce capítulos del Evangelio de Juan.

Por su parte, los papiros Bodmer 14 y 15, conocidos como P75, fueron descubiertos también en Egipto en 1956 y están datados del año 175 al 225 d. C. Contienen cerca de la mitad de los Evangelios de Lucas y de Juan, a saber:
P75 constituye el manuscrito más antiguo que mantiene unidos a dos Evangelios. Esto fue interpretado por diferentes escrituristas como una demostración de que, para las primeras comunidades cristianas, los Evangelios formaban una unidad. Pertenecieron a la Fundación Bodmer de Cologny (Ginebra). En 2007, fueron donados a la Biblioteca Apostólica Vaticana donde se conservan actualmente.

Son tres papiros (P45, P46 y P47) escritos antes del año 250 d. C. Contienen fragmentos de las epístolas de Pablo, del Apocalipsis y de los Evangelios.

Data de mediados del siglo IV.

De mediados del siglo IV.

Del siglo V

Del siglo V.

Del siglo V. Solo contiene los Evangelios y los Hechos de los Apóstoles. El texto de los Hechos difiere algo de otras versiones.

Del siglo V. Solo contiene los Evangelios.



Se descubre el códice sinaítico (K. Tischendorf, 1859). Los códices "Sinaiticus" y "Vaticanus" dan lugar a los textos actuales.

En el año 397 el papa Siricio convoca el tercer concilio de Cartago donde se impone la vulgata (traducción de la Biblia al latín vulgar realizada por San Jerónimo del 382-405) y finalmente se edita el Nuevo Testamento.

Por siglos la Biblia fue el libro de mayor distribución en España, habiendo disponibles copias manuscritas en latín y, por varios siglos, hasta en la lengua gótica. Diversas historias bíblicas, salterios (o salmos), glosarios, relatos morales y obras similares se convirtieron en libros de mayor venta de la época. Copistas adiestrados reprodujeron concienzudamente exquisitos manuscritos bíblicos. Aunque a 20 escribas les tomaba todo un año producir un solo manuscrito de primera clase, muchas Biblias latinas y millares de comentarios sobre la Biblia latina circulaban en España para el siglo XV.

Cuando el idioma español empezó a desarrollarse, surgió interés en tener la Biblia en el lenguaje vernáculo. Para el siglo XII la Biblia se tradujo al romance o español antiguo, el lenguaje que hablaba la gente común.

Posteriormente la disidencia entre valdenses, lolardos y husitas hizo que por precaución a la herejía, la Iglesia prohibiera la traducción de la Biblia en lengua romance (Concilio de Toulouse, Francia, 1229). Por los siguientes doscientos años la única Biblia católica oficial publicada en España —aparte de la Vulgata latina— fue la Políglota complutense, la primera Biblia políglota, patrocinada por el cardenal Cisneros. Solo se imprimieron 600 ejemplares. Contenía el texto bíblico en hebreo, arameo, griego y latín.

A principios del siglo XVI Francisco de Enzinas, hijo de un rico terrateniente español, empezó a traducir el Nuevo Testamento al español mientras todavía era un joven estudiante. Luego consiguió que se imprimiera su traducción en los Países Bajos, y en 1544 trató de obtener la autorización real para distribuirla en España, la cual le fue rechazada y terminó acusado ante la inquisición. Pocos años más tarde se imprimió una edición revisada de esa traducción en Venecia, Italia, la que Julián Hernández introdujo secretamente en Sevilla, siendo prendido y posteriormente ejecutado por herejía.

Solo posteriormente se empezó a traducir la Biblia entera a lengua vernácula castellana con la Obra de Casiodoro de Reina (Biblia del Oso 1568-1569), por parte del protestantismo, y Felipe Scío de San Miguel (1790) y Félix Torres Amat (1823) en el catolicismo.

Brit Jadashá o Brit Hadashá es el término hebreo para el Nuevo Testamento. Etimológicamente, "Brit" proviene de la palabra hebrea "«pacto»", y "Jadashá" del vocablo "«renovado»" o "«nuevo»". También se le ha llamado Brit HaJadashá, siendo "Ha" el artículo definido "«el», «la», «los»" o "«las»" (en este caso haciendo la función de un "«el»").

La diferencia entre el "Nuevo Testamento cristiano" y el "Brit HaJadashá", es que este último incluye palabras hebreas intercaladas. Por ejemplo, en lugar de decir Jesucristo, dice "Yeshúa HaMashíaj", o en vez de decir: Apóstol Pablo, dice: "Shaliaj Shaúl" o "Rabí Shaúl".

Algunos cristianos afirman que los usuarios del término "Brit Jadashá" pretenden hebraizar a los cristianos (o cristianizar a los judíos). A pesar de eso, el término "Brit Jadashá" es muy recomendado por las congregaciones judías mesiánicas.

Una de las razones fundamentales de la crítica de los apologetas cristianos acerca de quienes promueven el uso del término "Brit Jadashá" (Pacto Renovado) en vez de "Nuevo Testamento", es que no existe actualmente ningún manuscrito antiguo neotestamentario escrito en hebreo, pero si más de 5000 pergaminos neotestamentarios completos escritos en griego común o "koiné". De manera que quienes afirman que el "Brit Jadashá" es una “traducción literal” de los manuscritos antiguos neotestamentarios hebraicos, están errando en su apreciación.

Solo existen manuscritos antiguos del Tanaj (Antiguo Testamento) en hebreo y arameo. Mientras que todos los pergaminos antiguos del Nuevo Testamento están en griego koiné. Los académicos concuerdan que los idiomas de la Biblia son el hebreo y arameo para el AT, y el griego para el NT.

El término "Brit Jadashá" es utilizado por el "Movimiento de los Nombres Santos", "Nuevos Judíos", o "Judaizantes". Ellos promueven descontinuar el uso de la Biblia (especialmente el Nuevo Testamento) de origen gentil o greco-romano, por ser una traducción de los manuscritos griegos (ya que consideran que los manuscritos fueron manipulados y tergiversados por escribas helenistas, destruyendo así los manuscritos originales hebreos neotestamentarios).

Debido que los nombres como "Jesús", "Cristo", "Jesucristo", "Iglesia", y "Espíritu Santo" (entre otros), son de origen griego, los miembros del "Movimiento de los Nombres Santos" consideran estos términos como «nombres profanos». Por eso, en sus versiones neotestamentarias hebraicas literales, utilizan "«Yeshúa»" en vez de "Jesús", "«Kejilá»" en vez de "Iglesia", "«Ruaj Ja Kodesh»" en vez de "Espíritu Santo", etc.




</doc>
<doc id="2034" url="https://es.wikipedia.org/wiki?curid=2034" title="Naturaleza">
Naturaleza

La naturaleza, en su sentido más amplio, es equivalente al mundo natural, mundo material o universo material. El término hace referencia a los fenómenos del mundo físico, y también a la vida en general. Por lo general, no incluye los objetos artificiales ni la intervención humana, a menos que se la califique de manera que haga referencia a ello, por ejemplo con expresiones como «naturaleza humana» o «la totalidad de la naturaleza». La naturaleza también se encuentra diferenciada de lo sobrenatural. Se extiende desde el mundo subatómico al galáctico.

La palabra «naturaleza» procede del latín "natura" que significa «perteneciente o relativo a la naturaleza o conforme a la cualidad o propiedad de las cosas», «carácter natural». 

La «naturaleza» es la dinámica y la armonía del conjunto de los seres vivos y la materia inerte en su extensa diversidad en todas sus variedades y combinaciones a través del tiempo y el espacio, de las actividades climáticas, sísmicas, volcánicas, geológicas, geográficas y atmosféricas.

El concepto de naturaleza como un todo —el universo físico— es un concepto más reciente que adquirió un uso cada vez más amplio con el desarrollo del método científico moderno en los últimos siglos.

Dentro de los diversos usos actuales de esta palabra, «naturaleza» puede hacer referencia al dominio general de diversos tipos de seres vivos, como plantas y animales, y en algunos casos a los procesos asociados con objetos inanimados —la forma en que existen los diversos tipos particulares de cosas y sus espontáneos cambios—, así como el tiempo atmosférico, la geología de la Tierra y la materia y energía que poseen todos estos entes. A menudo, se considera que significa «entorno natural»: animales salvajes, rocas, bosques, playas, y en general todas las cosas que no han sido alteradas sustancialmente por el ser humano, o que persisten a pesar de la intervención humana. Este concepto más tradicional de las cosas naturales implica una distinción entre lo natural y lo artificial (entendido esto último como algo hecho por una mente o una conciencia humana).

La Tierra es el quinto mayor planeta del sistema solar y el tercero en orden de distancia al Sol. Es el mayor de los planetas telúricos o interiores y el único lugar del universo en el que se sabe que existe vida.

Los rasgos más prominentes del clima de la Tierra son sus dos grandes regiones polares, dos zonas templadas relativamente estrechas y una amplia región ecuatorial, tropical y subtropical. Los patrones de precipitación varían enormemente dependiendo del lugar, desde varios metros de agua al año a menos de un milímetro. Aproximadamente el 70 por ciento de la superficie terrestre está cubierta por océanos de agua salada. El resto consiste en continentes e islas, situándose la mayor parte de la Tierra habitable en el hemisferio norte.

La Tierra ha evolucionado mediante procesos geológicos y biológicos que han dejado vestigios de las condiciones originales. La superficie externa se halla fragmentada en varias placas tectónicas que se van desplazando muy lentamente a medida que avanza el tiempo geológico (si bien al menos varias veces en la historia han cambiado de posición relativamente rápido). El interior del planeta permanece activo, con una gruesa capa de materiales fundidos y un núcleo rico en hierro que genera un potente campo magnético. Las condiciones atmosféricas han variado significativamente de las condiciones originales por la presencia de formas de vida, que crean un equilibrio ecológico que estabiliza las condiciones de la superficie. A pesar de las grandes variaciones regionales del clima por la latitud y otros factores geográficos, el clima global medio a largo plazo está regulado con bastante precisión, y las variaciones de un grado o dos en la temperatura global media han tenido efectos muy importantes en el equilibrio ecológico y en la geografía de la Tierra.
Basándose en las pruebas disponibles, los científicos han recabado información detallada acerca del pasado del planeta. Se cree que la Tierra se formó hace aproximadamente 4550 millones de años a partir de la nebulosa protosolar, junto con el Sol y otros planetas. La Luna se formó relativamente poco después (aproximadamente 20 millones de años más tarde, hace 4530 millones de años). Al principio fundida, la capa exterior del planeta se enfrió, dando lugar a la corteza sólida. Las emisiones de gases y la actividad volcánica formaron la atmósfera primordial. La condensación del vapor de agua, junto con el hielo de los cometas que en aquella época impactaban con la Tierra, crearon los océanos. Se cree que la química altamente energética produjo una molécula que se autoduplicó hace aproximadamente 4000 millones de años.

Los continentes se formaron, se separaron y se volvieron a unir durante cientos de millones de años, combinándose en ocasiones para formar un supercontinente. Hace aproximadamente 750 millones de años, el primer supercontinente conocido, Rodinia, comenzó a fracturarse. Más tarde, los continentes se volvieron a unir para formar Pannotia, que se dividió hace aproximadamente 540 millones de años. El último supercontinente que conocemos es Pangea, que comenzó a romperse hace aproximadamente 180 millones de años.
Hay pruebas significativas, aún discutidas entre la comunidad científica, de que una severa era glacial durante el Neoproterozoico cubrió gran parte del planeta con una gruesa capa de hielo. Esta hipótesis se ha llamado la “Tierra bola de nieve”, y es de especial interés, ya que precede a la explosión cámbrica en la cual comenzaron a proliferar las formas de vida pluricelulares, hace 530-540 millones de años.

Desde la explosión cámbrica se han registrado cinco grandes extinciones en masa. La última extinción masiva tuvo lugar hace aproximadamente 65 millones de años, cuando probablemente el choque de un meteorito causó la extinción de los dinosaurios y otros grandes reptiles, pero no la de los animales pequeños como los mamíferos, que por aquel entonces se asemejaban a las musarañas. A lo largo de los 65 millones de años siguientes, los mamíferos se diversificaron.

Hace varios millones de años, una especie de pequeño mono africano adquirió la habilidad para ponerse de pie. El advenimiento posterior de la vida humana y el desarrollo de la agricultura y, más tarde, de la civilización, permitió a los humanos repercutir en la Tierra más que cualquier otra forma de vida anterior, en un lapso relativamente corto. Las acciones humanas influyen tanto en la naturaleza como en la cantidad de las otras formas de vida, así como en el clima global.

Una encuesta llevada a cabo por el Museo Americano de Historia Natural en 1998, reveló que el 70 % de los biólogos veían la era actual como parte de una acontecimiento de extinción masiva, la extinción masiva del Holoceno, que sería la más rápida de todas las conocidas. Algunos expertos, como E. O. Wilson, de la Universidad de Harvard, predicen que la destrucción humana de la biosfera podría causar la extinción de la mitad de todas las especies en los próximos 100 años. No obstante, el alcance de esta extinción actual está aun siendo investigado, discutido y calculado por biólogos.

La atmósfera terrestre es un factor clave que sustenta el ecosistema planetario. Esta fina capa de gases que envuelve la Tierra se mantiene en su sitio gracias a la gravedad del planeta. Está compuesta por un 78 % de nitrógeno, un 21 % de oxígeno y trazas de otros gases. La presión atmosférica disminuye con la altitud. La capa de ozono de la Tierra desempeña un papel esencial en la reducción de la cantidad de radiación ultravioleta que llega a la superficie. Ya que el ADN puede verse fácilmente dañado por esta radiación, la capa de ozono actúa de escudo que protege la vida en la superficie. La atmósfera también retiene calor durante la noche, reduciendo por tanto las temperaturas extremas diarias.

Las variaciones del tiempo atmosférico tienen lugar casi exclusivamente en la parte baja de la atmósfera, y actúa de sistema convectivo para redistribuir el calor. Las corrientes oceánicas son otro factor importante para determinar el clima, especialmente la circulación termohalina submarina, que distribuye la energía calorífica de los océanos ecuatoriales a las regiones polares. Estas corrientes ayudan a moderar las diferencias de temperatura entre el invierno y el verano en las zonas templadas. Es más, sin las redistribuciones de energía calorífica que realizan las corrientes oceánicas y atmosféricas, los trópicos serían mucho más cálidos y las regiones polares mucho más frías.

El tiempo puede tener a la vez efectos beneficiosos y perjudiciales. Los fenómenos meteorológicos extremos, como los tornados o los huracanes, pueden emplear grandes cantidades de energía en su trayectoria y arrasar con todo lo que encuentren a su paso. La vegetación superficial ha desarrollado una dependencia de la variación estacional del tiempo, y los cambios repentinos, aunque solo duren algunos años, pueden tener un efecto devastador, tanto en la vegetación como en los animales que dependen de ella para alimentarse.

El clima planetario es una medida de la tendencia del tiempo atmosférico a lo largo del tiempo. Pueden influir en él varios factores, como las corrientes oceánicas, el albedo superficial, los gases de efecto invernadero, las variaciones en la luminosidad solar y los cambios en la órbita del planeta. Basándonos en los registros históricos, hoy sabemos que la Tierra ha sufrido drásticos cambios climáticos en el pasado, incluso glaciaciones. El clima de una región depende de una cierta cantidad de factores, como la latitud. Una franja latitudinal de la superficie con características climáticas similares conforma una región climática. En la Tierra, existen varias de estas regiones, que van del clima tropical en el ecuador al clima polar en los polos. En el tiempo también influyen las estaciones, que resultan de la inclinación del eje de la Tierra con respecto a su plano orbital. De esta forma, en cualquier momento dado durante el verano o el invierno, hay una parte del planeta que está más directamente expuesta a los rayos del Sol. Esta exposición se va alternando al tiempo que la Tierra va describiendo su órbita. En todo momento, sin importar la estación, los hemisferios norte y sur experimentan condiciones climáticas opuestas.

El tiempo es un sistema caótico que puede modificarse fácilmente con solo pequeños cambios en el entorno, por ello las previsiones meteorológicas exactas solo se limitan a algunos días. En conjunto, están sucediendo dos cosas a nivel global: (1) la temperatura está aumentando por término medio; y (2) los patrones del tiempo están cambiando y volviéndose cada vez más caóticos.

El hecho de que las formas más básicas de vida vegetal comenzaran a realizar la fotosíntesis fue clave para la creación de condiciones que permitiesen el desarrollo de formas de vida más complejas. El oxígeno resultante del proceso se acumuló en la atmósfera y dio lugar a la capa de ozono. La relación de simbiosis entre células pequeñas y otras mayores dio lugar al desarrollo de células aún más complejas llamadas eucariotas. Las células se agruparon en colonias y comenzaron a especializarse, dando lugar a auténticos organismos pluricelulares. Gracias a la capa de ozono, que absorbe las radiaciones ultravioletas nocivas, la vida colonizó la superficie de la Tierra.

Aunque no existe un consenso universal sobre la definición de la vida, los científicos, por lo general, aceptan que la manifestación biológica de la vida se caracteriza por los siguientes factores o funciones: organización, metabolismo, crecimiento, adaptación, respuesta a estímulos y reproducción. De manera más sencilla, podemos considerar la vida como el estado característico de los organismos. Las propiedades comunes a los organismos terrestres (plantas, animales, hongos, protistas, arqueas y bacterias) son las siguientes: son celulares, tienen una organización compleja basada en el agua y el carbono, tienen un metabolismo y capacidad para crecer, responder a estímulos y reproducirse. Por ello, se considera que una entidad que reúna estas propiedades está viva. Sin embargo, no todas las definiciones que hay sobre la vida consideran esenciales todas estas propiedades.

La biosfera es la parte de la capa más externa de la Tierra —que comprende el aire, la tierra, las rocas superficiales y el agua— dentro de la cual tiene lugar la vida, y en donde, a su vez, se alteran o se transforman los procesos bióticos. Desde el punto de vista geofísico, la biosfera es el sistema ecológico global que integra a todos los seres vivos y sus relaciones, incluyendo su interacción con los elementos de la litosfera (rocas), la hidrosfera (agua), y la atmósfera (aire). Actualmente, se estima que la Tierra contiene cerca de 75 000 millones de toneladas de biomasa (la masa de la vida), que vive en diversos entornos dentro de la biosfera. Cerca de nueve décimas partes de la biomasa total de la Tierra es vida vegetal, de la que depende estrechamente la vida animal. Hasta la fecha, se han identificado más de 2 millones de especies de plantas y animales, y las estimaciones realizadas sobre la cantidad real de especies existentes varían entre unos cuantos millones y cerca de 50 millones La cantidad de especies individuales oscila constantemente: aparecen especies nuevas y otras dejan de existir, en una base continua. En la actualidad, la cantidad total de especies está experimentando un rápido descenso.
La diferencia entre la vida animal y la vegetal no es tan tajante como pueda parecer, ya que hay algunos seres vivos que reúnen características de ambas. Giuliana dividió a todos los seres vivos en plantas, que por lo general no se mueven, y animales. En el sistema de Carlos Linneo, éstos se convirtieron en los reinos Vegetabilia (más tarde Plantae) y Animalia. Desde ese momento se vio que el reino Plantae, como estaba definido originalmente, incluía varios grupos sin relación alguna, por lo que se eliminó a los hongos y a varios grupos de algas para moverlos a reinos nuevos, si bien a menudo se siguen considerando plantas en algunos contextos. En la flora, está comprendida a veces la vida bacteriana tanto es así que ciertas clasificaciones utilizan los términos "flora bacteriana" y "flora vegetal" de manera separada.

Una de las muchas formas de clasificar las plantas es por floras regionales, que, dependiendo del propósito de estudio, pueden incluir también a la "flora fósil", que son restos de vida vegetal de eras pasadas. Muchas personas de varias regiones y países se enorgullecen de su flora característica, que varía ampliamente a través del globo debido a las diferencias de climas y suelos. La flora regional se suele dividir en subcategorías como la "flora nativa" y "flora agrícola y de jardín" (estas últimas son las que cultiva el hombre intencionadamente). Algunas clases de “flora nativa”, en realidad han sido introducidas hace siglos por emigrantes de una región o continente a otro, y con el paso del tiempo se han convertido en parte de la flora nativa o natural del lugar en el que se introdujeron. Este es un ejemplo de cómo la acción humana puede desdibujar el límite de lo que se considera naturaleza. Otra categoría de plantas es la de las “malas hierbas”. Aunque el término ha perdido uso entre los botánicos como manera de designar a las plantas “inútiles”, su uso informal (para describir a las plantas que estorban y que se deben eliminar) ilustra perfectamente la tendencia general de las personas y las sociedades de pretender alterar el curso de la naturaleza. Del mismo modo, los animales se suelen clasificar como "domésticos", "de granja", "salvajes", "plagas", etc. según la relación que tengan con la vida humana.
Los animales como categoría tienen varias características que los diferencian de los otros seres vivos. Los animales son eucarióticos y normalmente pluricelulares (véase Myxozoa, sin embargo), lo que los distingue de las bacterias, los archaea y la mayor parte de los protistas. Son heterótrofos, y generalmente digieren la comida en un órgano interno, lo que los diferencia de las plantas y las algas. También se distinguen de las plantas, las algas y los hongos en que carecen de paredes celulares. Con unas pocas excepciones, especialmente en las esponjas (Phylum porifera), los animales tienen un organismo compuesto por varios tejidos, que comprenden músculos, capaces de contraerse y controlar la locomoción, y un sistema nervioso, que envía y procesa señales. En la mayoría de los casos, tienen un aparato digestivo interno. Las células eucariotas que tienen todos los animales están rodeadas por una matriz extracelular característica, compuesta por colágeno y glucoproteínas elásticas. Se puede calcificar para formar estructuras como conchas, huesos, y espículas, en las que la célula se desplaza y reorganiza durante su desarrollo y maduración, y que soportan la compleja anatomía necesaria para la locomoción.

Aunque, en la actualidad, los humanos componen solo la mitad del uno por ciento del total de la biomasa viva en la Tierra, que estima el peso global en unos 60 kg de media.), la biomasa humana total es el peso medio multiplicado por la población humana actual, de aproximadamente 6.500 millones de personas. (véase)

El ecosistema es un sistema dinámico relativamente autónomo, formado por una comunidad natural y su ambiente físico. El concepto, que empezó a desarrollarse entre 1920 y 1930, tiene en cuenta las complejas interacciones entre los organismos (plantas, animales, bacterias, algas, protozoos y hongos, entre otros) que forman la comunidad y los flujos de energía y materiales que la atraviesan.
Todas las formas de vida tienen la necesidad de relacionarse con el entorno en que viven, y también con otras formas de vida. En el siglo XX, esta premisa dio lugar al concepto de ecosistema, que se pueden definir como cualquier situación en la que hay una interacción entre organismos y su entorno. Los ecosistemas constan de factores bióticos y abióticos que funcionan de manera interrelacionada. Los factores más importantes de un ecosistema son: suelo, atmósfera, radiación solar, agua y organismos vivos. Cada organismo vivo tiene una relación continua con todos los demás elementos de su entorno. Dentro del ecosistema, las especies se relacionan y dependen unas de otras en la llamada cadena alimentaria, e intercambian materia y energía tanto entre ellas mismas como con su entorno. Michael Pidwirny, en su libro "Fundamentals of Physical Geography", describe el concepto así:

Todas las especies tienen límites de tolerancia a los factores que afectan a su supervivencia, su éxito reproductivo y su capacidad de continuar creciendo e interactuando de forma sostenible con el resto de su entorno. Estas a su vez pueden influir en estos factores, cuyas consecuencias pueden extenderse a otras muchas especies o incluso a la totalidad de la vida. El concepto de ecosistema es, por tanto, un importante objeto de estudio, ya que dicho estudio nos proporciona la información necesaria para tomar decisiones sobre cómo la vida humana puede interactuar de manera que permita a los variados ecosistemas un crecimiento sostenido con vistas al futuro, en vez de expoliarlos. Para tal estudio se toma una unidad más pequeña llamada "microecosistema". Por ejemplo, un ecosistema puede ser una piedra con toda la vida que alberga. Un "macroecosistema" podría comprender una ecorregión entera, con su cuenca hidrográfica.

Los ecosistemas siguientes son ejemplos de los que actualmente están sometidos a estudio intensivo:


Se puede realizar otra clasificación de los ecosistema atendiendo a sus comunidades, como en el caso de un ecosistema humano. La clasificación más amplia (sometida hoy a un amplio estudio y análisis, y también objeto de discusiones sobre su naturaleza y validez) es la del conjunto entero de la vida del planeta vista como un único organismo, la conocida como hipótesis de Gaia.

El desarrollo de la tecnología por la raza humana ha permitido una mayor explotación de los recursos naturales y ha ayudado a paliar parte de los riesgos de los peligros naturales. No obstante, a pesar de este progreso, el destino de la civilización humana está estrechamente ligado a los cambios en el medio ambiente. Existe un complejísimo sistema de retroalimentación entre el uso de la tecnología avanzada y los cambios en el medio ambiente, que solo ahora se están comenzando a entender, aunque muy lentamente.

Los humanos emplean la naturaleza para actividades tanto económicas como de ocio. La obtención de recursos naturales para el uso industrial sigue siendo una parte esencial del sistema económico mundial. Algunas actividades, como la caza y la pesca, tienen intenciones tanto económicas como de ocio. La aparición de la agricultura tuvo lugar alrededor del noveno milenio antes de Cristo. De la producción de alimentos a la energía, no cabe duda de que la naturaleza es el principal factor de la riqueza económica.

Los seres humanos han empleado las plantas para usos medicinales durante miles de años. Los extractos vegetales pueden tratar calambres, reumatismos y la inflamación pulmonar. Mientras que la ciencia nos ha permitido procesar y transformar estas sustancias naturales en píldoras, tintes, polvos y aceites, la economía de mercado y la posición de “autoridad” que se le atribuye a la comunidad médica han hecho menos popular su uso. El término “medicina alternativa” se emplea con frecuencia para designar el uso de plantas y extractos naturales con propósitos curativos.

Las amenazas a la naturaleza provocadas por el hombre son, entre otras, la contaminación, la deforestación, y desastres tales como las mareas negras. La humanidad ha intervenido en la extinción de algunas plantas y animales.

Una zona salvaje o silvestre es un entorno natural de la Tierra cuyos procesos o dinámicas son autónomos. Los ecologistas consideran que las áreas salvajes son una parte del ecosistema natural del planeta (la biosfera).

La expresión “zona salvaje” evoca inmediatamente la idea de “naturaleza salvaje”, es decir, que los humanos no pueden controlar. Desde este punto de vista, es el desarrollo autónomo de los procesos de un área natural el que lo convierte en una zona salvaje. 

No debe confundirse "salvaje" con "virgen". Una zona será virgen si no ha sido alterada por la presencia o actividad humanas. Hoy en día, prácticamente la totalidad de la superficie del planeta ha sufrido, en mayor o menor grado y directa o indirectamente, algún tipo de alteración causada por los seres humanos (aunque solo sea la influencia del cambio climático o de ciertos contaminantes), luego se puede afirmar que no existen prácticamente entornos vírgenes en la biosfera. Sin embargo, La mera presencia o actividad humana no necesariamente implica que una zona deje de ser salvaje. Muchos ecosistemas que son, o han sido, habitados o influidos por las actividades humanas pueden considerarse como “salvajes”, a pesar de no ser vírgenes. Según esto, son salvajes las áreas en las que los procesos naturales discurren sin interferencias humanas notorias.

La noción de “naturaleza salvaje” ha sido un tema importante en las artes visuales durante diversas épocas de la historia mundial. Durante la Dinastía Tang (618-907) se dio una temprana tradición de pintura paisajística. Esta tradición de representar la naturaleza "tal cual" se convirtió en uno de los objetivos de la pintura china y tuvo una influencia significativa en el arte asiático.

En el mundo occidental, la idea de “zona salvaje” (naturaleza salvaje, etc.) como valor intrínseco apareció en los años 1800, especialmente en las obras del movimiento romántico. Artistas británicos como John Constable y Joseph Mallord William Turner se dedicaron a plasmar la belleza del mundo natural en sus cuadros. Antes, las pinturas habían sido sobre todo de escenas religiosas o de seres humanos. La poesía de William Wordsworth describe las maravillas del mundo natural, que antes se veía como un lugar amenazador. Cada vez más, la valoración de la naturaleza se fue convirtiendo en un aspecto de la cultura occidental.

La belleza de la naturaleza es un tema recurrente en la vida moderna y en el arte: los libros que la ensalzan llenan grandes estanterías de bibliotecas y librerías. Esa cara de la naturaleza, que el arte (fotografía, pintura, poesía...) tanto ha retratado y elogiado revela la fuerza con la que muchas personas asocian naturaleza con belleza. El porqué de la existencia de esa asociación y en qué consiste ésta constituyen el campo de estudio de la rama de la filosofía llamada estética. Más allá de ciertas características básicas de la naturaleza en cuya hermosura coinciden la mayoría de filósofos, las opiniones son prácticamente infinitas.

Muchos científicos, que estudian la naturaleza de forma más específica y organizada, también comparten la idea de que la naturaleza es hermosa. El matemático francés Jules Henri Poincaré (1854-1912) dijo:

Una idea clásica de la belleza del arte involucra la palabra mimesis, es decir, la imitación de la naturaleza. En el dominio de las ideas sobre la belleza de la naturaleza, lo perfecto evoca la simetría, la división exacta y otras fórmulas y nociones matemáticas perfectas.

Algunos campos de la ciencia ven la naturaleza como “materia en movimiento”, obedeciendo a ciertas “leyes naturales” que la ciencia se encarga de descubrir y entender.

Se suele definir la materia como la sustancia de la que se componen los objetos físicos, y constituye el universo observable. Según la teoría de la relatividad especial, no existe ninguna distinción inalterable entre la materia y la energía, dado que la materia se puede convertir en energía (véase aniquilación partícula-antipartícula), y viceversa (véase creación de la materia). Ahora se piensa que los componentes visibles del universo constituyen únicamente un 4 por ciento de la masa total, y que lo restante consiste en un 73 por ciento de materia oscura y un 23 por ciento de materia oscura fría. Aún se desconoce la naturaleza exacta de estos componentes, que están siendo investigados a fondo por los físicos.

El comportamiento de la materia y la energía en el universo observable parece corresponderse con leyes físicas bien definidas. Estas se han empleado para crear modelos cosmológicos que explican satisfactoriamente la estructura y la evolución del universo que podemos observar. Las expresiones matemáticas de las leyes físicas emplean un conjunto de veinte constantes físicas que, a través del universo observable, parecen estáticas. Sus valores se han conseguido medir con gran precisión, pero la razón de por qué tienen esos valores específicos y no otros sigue siendo un misterio.

El espacio exterior, también llamado "espacio" a secas, designa las regiones relativamente vacías del universo fuera de las atmósferas de los cuerpos celestiales. Se añade el adjetivo "exterior" para distinguirlo del espacio aéreo. No existe ningún límite definido entre la atmósfera terrestre y el espacio, puesto que ésta se va atenuando gradualmente a medida que aumenta la altitud. El espacio cósmico ubicado dentro de los límites del Sistema Solar se conoce como espacio interplanetario, cuyo límite con el espacio interestelar es lo que conocemos como heliopausa.

Aunque el espacio exterior es de por sí muy amplio, no está vacío. En él existen, aunque repartidas de manera muy dispersa, varias docenas de moléculas orgánicas descubiertas hasta la fecha gracias a la espectroscopia rotacional, la radiación de fondo de microondas y la radiación cósmica, formada por núcleos atómicos ionizados y diversas partículas subatómicas. También hay algo de gas, plasma, polvo cósmico y pequeños meteoros. Además, los seres humanos han dejado restos de su actividad en el espacio exterior, a través de materiales procedentes de los lanzamientos tripulados y no tripulados. A todos estos objetos se les ha llamado “basura espacial” y constituyen un riesgo potencial para las naves espaciales. Algunos caen a la atmósfera periódicamente.

El planeta Tierra es actualmente el único cuerpo celeste conocido dentro del sistema solar en el que existe vida. Sin embargo, los recientes hallazgos sugieren que, en el pasado lejano, el planeta Marte tenía masas de agua líquida en la superficie. Durante un breve periodo en la historia de Marte, podría haber sido capaz de albergar vida. Sin embargo, en la actualidad la mayor parte del agua de Marte está congelada. Si aun así existiese vida en Marte, lo más probable es que estuviese situada bajo tierra, donde todavía podría haber agua líquida.

Las condiciones existentes en los otros planetas telúricos, Mercurio y Venus, parecen ser demasiado hostiles como para que allí se pueda desarrollar la vida tal cual la conocemos. Pero se ha conjeturado que Europa, la cuarta mayor luna de Júpiter, pueda poseer un océano subterráneo de agua líquida, y sería posible que existiese vida en él.

En la Grecia clásica, uno de los temas principales de la obra "Fedro" de Platón es la naturaleza.



</doc>
<doc id="2036" url="https://es.wikipedia.org/wiki?curid=2036" title="Nunavut">
Nunavut

Nunavut (en silabario inuktitut, ᓄᓇᕗᑦ, «nuestra tierra») es uno de los tres territorios que, junto con las diez provincias, conforman las trece entidades federales de Canadá. Su capital es Iqaluit. Está ubicado al norte del país, limitando al norte con el océano Ártico, al noreste con la bahía de Baffin que lo separa de Groenlandia, al este con el océano Atlántico y la bahía de Hudson, al sur con Manitoba, al suroeste con Saskatchewan y al oeste con Territorios del Noroeste. Con habs en 2008 es la entidad menos poblada, con , la más extensa, y con , la menos densamente poblada.

Nunavut se separó de Territorios del Noroeste el 1 de abril de 1999, de acuerdo con las fronteras fijadas de antemano en 1993. Dichas fronteras reconocían la jurisdicción de Nunavut sobre casi todas las Islas Árticas de Canadá (Ellesmere, Baffin, Devon, Southampton y la mitad oriental de Victoria y la de Melville), así como sobre la zona costera central de Canadá sobre el océano Ártico y todas las islas de la bahía de Hudson.

Desde 1976, se empezó a advertir un anhelo del pueblo inuit por lograr una mayor autonomía para el territorio. Tras la recomendación que hacía un informe de la Comisión Real del Canadá sobre la conveniencia de conceder mayor autonomía a los pueblos aborígenes de Canadá, esta llegó de forma efectiva a mediados de 1999. 

Sus habitantes —llamados nunavutensinos ("Nunavummiut", singular "Nunavummiuq")— están repartidos en casi una treintena de aldeas o poblaciones menores. Una de ellas es Iqaluit, la capital, situada en la isla de Baffin, anteriormente denominada "Frobisher Bay".

El territorio abarca cerca de 1,9 millones de km² de tierra y de agua en el norte de Canadá, incluido parte del continente, la mayor parte del archipiélago Ártico, y de todas las islas en la bahía de Hudson, bahía James y la bahía de Ungava (incluidas las islas Belcher) que pertenecían a los Territorios del Noroeste. Esto hace que sea la cuarta entidad subnacional más grande en el mundo. Si Nunavut fuera un país, sería el número 15 en territorio. Nunavut tiene fronteras terrestres con los Territorios del Noroeste en varias islas, así como el territorio continental, una frontera con Manitoba, al sur de la península de Nunavut, y una pequeña frontera terrestre con Terranova y Labrador en la isla Killiniq. Asimismo, comparte fronteras acuáticas con las provincias de Quebec, Ontario y Manitoba y con Groenlandia. Más del 90% del territorio está cubierto por el Escudo Canadiense.

La región actualmente conocida como Nunavut, ha estado poblada continuamente desde hace aproximadamente 4000 años. La mayoría de los historiadores identifican la costa de la isla de Baffin con la Helluland descrita en las sagas nórdicas, así que es posible que los habitantes de la región hayan tenido algún contacto ocasional con los marineros escandinavos.

La historia moderna de Nunavut comenzó en 1576. Martin Frobisher, mientras lideraba una expedición que tenía como objetivo encontrar el paso del noroeste, creyó haber descubierto yacimientos de oro en el cuerpo de agua conocido actualmente como bahía de Frobisher en la costa de Baffin. Resultó que el mineral era en realidad pirita, que no tenía valor, pero Frobisher estableció el primer contacto entre europeos con el pueblo inuit. El contacto fue hostil, con ambos bandos tomando prisioneros que posteriormente fallecieron.

Otros exploradores como Henry Hudson, William Baffin y Robert Bylot atravesaron el territorio en busca del paso del noroeste durante el siglo XVII.

La población indígena de los Territorios del Noroeste y Nunavut, que se vio menos influenciada por el colonialismo al habitar una zona donde el contacto con la población blanca no fue permanente hasta los años 1920, recibió los efectos negativos de algunos segmentos culturales occidentales desde entonces. No obstante, los inuit han aprendido a adaptarse a las nuevas circunstancias y cuentan en las décadas recientes con el apoyo de una gran parte de la población canadiense, y parecen caminar hacia su autonomía. El tardío contacto también parece haber jugado un papel en la supervivencia de estas minorías árticas. Conjuntamente, el modelo socioeconómico de explotación de materias primas aplicado al norte desde 1945 parece contar ahora más con el pequeño productor y no solo con los intereses de las grandes corporaciones, un modelo (el de 1945) que generaba también la dependencia esquimal sobre los recursos federales y no sobre los suyos propios.

En 1976 como parte de las negociaciones de las demandas de tierra entre el Inuit Tapiriit Kanatami (organización indígena) y el gobierno federal, la división de los territorios del noroeste fue discutida. El 14 de abril de 1982, un plebiscito sobre la división fue celebrado en los territorios del noroeste. La mayoría de residentes votaron a favor y el gobierno federal dio un acuerdo condicional siete meses más tarde. El acuerdo de las demandas de la tierra se decidió en septiembre de 1992 y ratificado por el casi 85% de los votantes de Nunavut. El 9 de julio de 1993, el Acta del acuerdo de las demandas de tierra de Nunavut y el Acta de Nunavut fueron llevados al parlamento canadiense, y la transición fue completada el 1 de abril de 1999.

Nunavut tiene la población más pequeña y menos densa de Canadá: 35 944 habitantes (2016) dispersos en una superficie similar a la de Europa occidental. Si Nunavut fuera un país independiente, sería la población menos densa del mundo, con casi el mismo tamaño y la mitad de la población de Groenlandia.

En el censo de 2011, (86,54%) del total () indicaron que eran indígenas de Norteamérica, entre los que (98,68%) se identificaron como inuits, 170 (0,6%) como métis y 465 (1,69%) como indígenas de las Naciones Originarias.

Las lenguas oficiales de Nunavut son el inuktitut, inuinnaqtun, inglés y francés. El inuktitut es una lengua inuit y la más hablada en Nunavut, pero la mayoría de la población no sabe hablar inglés ni francés, porque es un territorio inuit, aunque tampoco se habla mucho el inuinnaqtun.

Ian Martin, de la Universidad de York, propuso un plan lingüístico en un período de veinte años para crear «una sociedad bilingüe completamente funcional, en inuktitut e inglés» antes de 2020. El plan proporciona diversos modelos, incluyendo:
A la pregunta del censo sobre lengua materna, estas fueron las respuestas:

La economía se basa en los recursos minerales, sobre todo el oro, plomo y zinc. También hay muchos diamantes. La caza y la pesca son otras actividades importantes. El turismo está en constante crecimiento.



</doc>
<doc id="2037" url="https://es.wikipedia.org/wiki?curid=2037" title="Nuevo Brunswick">
Nuevo Brunswick

Nuevo Brunswick , también llamado a veces Nueva Brunswick o incluso, sin traducir, New Brunswick y abreviado comúnmente NB, es una de las diez provincias que, junto con los tres territorios, conforman las trece entidades federales de Canadá. Su capital es Fredericton y su ciudad más poblada, Moncton. Está ubicada al este del país, y limita al norte con el golfo de San Lorenzo —que la separa de la Isla del Príncipe Eduardo—, al este con la bahía de Fundy —que la separa de Nueva Escocia—, al sur con Estados Unidos y al oeste con Quebec. Con 72 908 km², es la tercera entidad menos extensa —por delante de Nueva Escocia y de la Isla del Príncipe Eduardo, la menos extensa— y, con 10 hab/km², la cuarta más densamente poblada, por detrás de la Isla del Príncipe Eduardo, de Nueva Escocia y de Ontario.

Nueva Brunswick forma parte de las Provincias Marítimas y de las Provincias Atlánticas, y es la única provincia canadiense que posee el inglés y el francés como idiomas oficiales.

La mayor parte de Nuevo Brunswick está cubierto por bosques. La silvicultura es una de las principales fuentes de renta de la provincia. Nuevo Brunswick es uno de los mayores productores de madera de Canadá, así como la mayor productora de papel de periódico del país. Las fuentes de renta más importantes de Nuevo Brunswick son la manufactura, el turismo, la silvicultura, la minería y la pesca.

Nuevo Brunswick fue originalmente colonizado por los franceses, y formó parte de la colonia francesa de Acadia, parte de Nueva Francia. En 1763, bajo los términos del Tratado de París, los franceses cedieron la región del actual Nuevo Brunswick a los británicos. Estos pusieron a la región su nombre actual, en homenaje al rey Jorge III del Reino Unido —descendiente de la familia real británica Brunswick-Lüneburg. Nuevo Brunswick estaba entonces relativamente poco poblada por colonos europeos —principalmente franceses— hasta finales de la década de 1770. La Revolución de las Trece Colonias de 1776 hizo que cerca de habitantes de las Trece Colonias, leales a la corona británica —y por esto, denominados "loyalists" (lealistas)—, emigraran a la región, y le dieron marco entonces a Nuevo Brunswick el apodo de "The Loyalist Province" (La Provincia Lealista).

Juntamente con Nueva Escocia, Ontario y Quebec, Nuevo Brunswick es una de las cuatro provincias originales de la Confederación Canadiense, creada el 1 de julio de 1867.

Los nativos americanos que vivían en la región que actualmente constituye Nuevo Brunswick, antes de la llegada de los primeros exploradores europeos a la región, eran las tribus Micmac, Maliseet y los Passamaquoddy. Los Micmac habitaban principalmente la región este del actual Nuevo Brunswick, mientras los Maliseet habitaban la región noroeste y los Passamaquoddy vivían en el suroeste, en torno a la bahía de Passamaquoddy.

El primer explorador europeo en explorar el actual Nuevo Brunswick fue el francés Jacques Cartier, en 1534, que descubrió y dio nombre a la "baie des Chaleurs", entre el norte de Nuevo Brunswick y la península de Gaspesia del actual Quebec. La siguiente expedición francesa a la región no ocurriría hasta 1604, cuando un grupo de franceses, liderados por Pierre Dugua de Mons y Samuel de Champlain navegaron por la bahía de Passamaquoddy, y establecieron un pequeño asentamiento de invierno en la isla Saint Croix (actualmente perteneciente a Maine), donde se instalaron los exploradores. Al final del invierno, 36 de los 87 miembros de la expedición murieron a causa del escorbuto. Después del invierno, en 1605, el resto de la expedición se trasladó a la bahía de Fundy, instalándose donde actualmente está localizado Port Royal, actual Nueva Escocia.

Gradualmente, otros asentamientos franceses se fundaron a lo largo del río Saint John y en la región de la bahía de Fundy, así como en el margen norte de Nuevo Brunswick, a lo largo del siglo XVII. Estos asentamientos incluían "Fort la Tour" (actual Saint John), villas en los valles de los ríos Memramcook y Petitcodiac, y "St. Pierre", actual Bathurst. Toda la región de Nuevo Brunswick, así como las regiones que componen actualmente la Isla del Príncipe Eduardo, Nueva Escocia y partes de Maine, fueron reivindicadas por los franceses, como parte de la colonia de Acadia (parte de Nueva Francia). Los franceses mantuvieron buenas relaciones con los nativos americanos de la región. La principal fuente de renta de los franceses en Nuevo Brunswick era el comercio de pieles con los nativos americanos de la región.

Inglaterra reivindicó por primera vez la región de Nuevo Brunswick en 1621, cuando el rey Jaime I de Inglaterra cedió a William Alexander toda la región que constituía entonces Acadia. Esta región sería denominada, según los británicos, "Nova Scotia", el significado en latín de "Nueva Escocia". Naturalmente los franceses no aceptaron las reivindicaciones de la región por parte de los ingleses. Los franceses, sin embargo, perdieron gradualmente el control de Acadia, en favor de los británicos, en una serie de guerras durante el siglo XVIII.

En 1713, bajo los términos del Tratado de Utrecht —que terminó oficialmente con la Guerra de Sucesión Española— los franceses cedieron la parte peninsular de Nueva Escocia a los británicos. La región de Nuevo Brunswick, así como la "Île St-Jean" (Isla del Príncipe Eduardo), y la "Île Royale" (actual isla de Cabo Bretón) continuarían bajo dominio francés.
La mayor parte de la población acadiana de la época, sin embargo, vivían en la parte peninsular de Nueva Escocia, que pasara a control británico. El resto de Acadia, incluyendo la región de Nuevo Brunswick, estaba escasamente poblada, con asentamientos primarios acadianos en Nuevo Brunswick existentes sólo en las regiones de Tantramar, Memramcook y el río Petitcodiac, así como "Fort la Tour" y "Fort Anne" (actual Fredericton).

Durante la Guerra Franco-Indígena (1756-1763), los británicos conquistaron todo Nuevo Brunswick. "Fort Beausejour", próximo a la actual ciudad de Sackville, fue capturado inmediatamente al inicio de la guerra, en 1755. Los acadianos de las regiones próximas, Beaubassin y Petitcodiac, fueron expulsados de la región, como los británicos habían hecho con los acadianos de Nueva Escocia, a principios de aquel mismo año. Otros conflictos y batallas se sucedieron tras la captura de Sackville, y "Fort St. Anne" fue capturado por los británicos en 1759. Después de esto, toda la región del actual Nuevo Brunswick pasó a dominio británico. Francia perdería finalmente el control de su imperio en América del Norte, después de la Batalla de las Planicies de Abraham en la ciudad de Quebec, en 1759. Bajo los términos del Tratado de París (1763), los franceses cedían oficialmente Nuevo Brunswick a los británicos.

Después del fin de la Guerra Franco-Indígena, la región que constituye actualmente Nuevo Brunswick (más parte de Maine) fueron incorporados al Condado de Sunbury, en la colonia británica de Nueva Escocia. La localización de Nuevo Brunswick, relativamente lejos del litoral del océano Atlántico, impidió que los británicos poblaran intensivamente la región inmediatamente después del fin de la guerra. De las tentativas de poblar la región inmediatamente después del periodo posguerra, se destacan la fundación de "The Bend" —actualmente Moncton— en 1766 por colonos de Pensilvania, patrocinados por la Compañía de Tierras de Filadelfia. Otros asentamientos fundados por colonos provenientes de las Trece Colonias serían establecidos en la región, principalmente en la región sur de la antigua Acadia (Maine y el sur de Nuevo Brunswick) —sobre todo en torno a la actual Sackville, y en torno al estuario del río Saint John. Poco antes de la revolución estadounidense de 1776, colonos ingleses, provenientes de Yorkshire, también se asentaron en la región de Sackville.

Sin embargo, el gran crecimiento de población no ocurriría hasta 1775, cuando la revolución estadounidense de 1776 dio comienzo en las Trece Colonias británicas. Estas poseían gran número de colonos, llamados "loyalists" (lealistas), que eran leales a la corona británica. Los británicos ofrecieron a los lealistas de las Trece Colonias lotes de tierra gratis en Nuevo Brunswick. Sin embargo, se debe observar que la mayoría de la población de Nuevo Brunswick que ya estaba instalada en la región antes de la Revolución apoyaba a los rebeldes americanos, y algunos creen que Nuevo Brunswick, si estuviera un poco más organizado políticamente, podría ser considerada la "decimocuarta" colonia británica. En particular, Johnathan Eddy, al mando de una milicia, atacó varias veces un puesto militar británico en "Fort Cumberland" —actual Fort Beausejour— durante el inicio de la revolución.

Los lealistas se instalaron en gran número en Nuevo Brunswick —fueron en el total cerca de 14 mil, al final de la revolución, en 1783. Buena parte de estos lealistas se instalaron una sola vez en 1783, luego después del fin de la revolución en los Estados Unidos, siendo expulsados del nuevo país. Los lealistas de esta última ola de migración se instalaron en "Parrtown" —actual Saint John. Con el súbito crecimiento de población de la región, se hizo clara y crítica la necesidad de organizar políticamente el territorio. La capital de la colonia de la cual Nuevo Brunswick formaba parte por entonces —Halifax, capital de Nueva Escocia— se encontraba localizaba tan lejos de la región, que la corona británica decidió que la provincia colonial de Nueva Escocia debería ser dividida. La provincia colonial de Nuevo Brunswick fue oficialmente fundada por Thomas Carleton el 16 de agosto de 1784.

El nombre de Nuevo Brunswick fue en homenaje al entonces monarca británico, el rey Jorge III, que era descendiente de la familia de Brunswick-Lüneburg. Por su parte Fredericton, la capital provincial, fue nombrada en homenaje al segundo hijo del rey Jorge III, Federico, duque de York y Albany.

La elección de Fredericton como la capital de Nuevo Brunswick ofendió a muchos habitantes de "Parrtown" —posteriormente renombrada Saint John. Parrtown poseía una población significativamente mayor que Fredericton. La razón principal de la elección de Fredericton como capital de Nuevo Brunswick era su localización en el interior de la provincia —lo que la hacía menos vulnerable a posibles ataques estadounidenses (u otros enemigos) que Parrtown, situada en el litoral. Parrtown, sin embargo, se convertiría en la primera ciudad incorporada de Canadá.

Algunos de los acadianos que habían sido expulsados de Nueva Escocia volvieron a la región de la antigua Acadia a finales del siglo XVIII y principios del XIX. Estos acadianos se instalaron principalmente en las regiones costeras del este y del norte de la nueva colonia de Nuevo Brunswick. Allí vivieron relativamente aislados (aislamiento de una cierta manera impuesta voluntariamente por ellos mismos), en la medida en que ellos lucharon para mantener vivas sus tradiciones.

La guerra anglo-estadounidense de 1812 tuvo poco efecto en Nuevo Brunswick. Se construyeron fuertes como el "Carleton Martello Tower" en Saint John y el "St. Andrews Blockhouse", pero los estadounidenses no atacaron la región, y ninguna batalla o conflictos armados de cualquier género ocurrieron en Nuevo Brunswick. Los habitantes de la provincia tenían buenas relaciones con los vecinos del estado de Maine —así como con el resto de Nueva Inglaterra. Incluso durante la guerra la ciudad de St. Stephen suministró munición a los estadounidenses de Calais (ambas ciudades separadas por un río), en las celebraciones del 4 de julio, día de la independencia de los Estados Unidos.

Sin embargo, un tramo de la frontera entre Maine y Nuevo Brunswick estaba en disputa entre los estadounidenses y los británicos. Oficiales en Londres y en Washington D.C. luchaban por la región, pero a la mayoría de los habitantes de la zona disputada no le importaba, tanto permanecer bajo dominio británico como ser anexionado por los Estados Unidos. La disputa de la frontera, conocida como guerra Arrostook, fue solucionada en 1842.

A principios del siglo XIX, gran número de escoceses e ingleses se instalaron en Nuevo Brunswick. En 1845, un gran número de irlandeses, huyendo de la Gran hambruna irlandesa. Muchos de estos últimos se instalaron en Saint John o en Chatham (esta última autodenominada "Capital irlandesa de Canadá"). Los irlandeses, principalmente católicos, frecuentemente tenían roces con el resto de la población de Nuevo Brunswick, en su gran mayoría protestantes. En 1849, el mayor de estos conflictos ocurrió en Saint John, cuando protestantes y católicos se enzarzaron en un tiroteo.

A lo largo del siglo XIX, la silvicultura y la construcción de navíos —tanto en la bahía de Fundy como en Miramichi— fueron las principales fuentes de renta de Nuevo Brunswick. Otras fuentes de renta importantes de la provincia eran la agricultura y la pesca.

En 1864, oficiales de las Provincias Marítimas —Nuevo Brunswick, Nueva Escocia y la Isla del Príncipe Eduardo— realizaron un encuentro en Charlottetown, donde discutieron la formación de una posible fusión de las tres colonias provinciales. Inicialmente la Conferencia de Charlottetown se realizaba con este objetivo, pero el gobierno de la provincia de Canadá (actuales Ontario y Quebec) se interesó en la idea de una posible unión, y representantes de la provincia de Canadá se incorporaron al encuentro. Representantes de las cuatro provincias se encontrarían nuevamente en Quebec. El 1 de julio de 1867, la Confederación de Canadá fue creada oficialmente. Nuevo Brunswick fue una de las provincias originales de la Confederación, junto con Nueva Escocia, Ontario y Quebec.

Muchos residentes de las Provincias Marítimas no querían formar parte de la Confederación, temiendo que las necesidades de la región serían poco valoradas frente a las necesidades del resto del país. Por consecuencia, muchos de los "Padres de la Confederación" de las Provincias Marítimas perdieron sus puestos en los gobiernos de sus respectivas provincias, en las elecciones posteriores.

Después de la formación de la Confederación, Nuevo Brunswick continuó creciendo económicamente, apoyándose en la pesca, la minería y la silvicultura. Pero el creciente uso de navíos a vapor en Canadá y en Estados Unidos hizo que la fuerte industria naval de Nuevo Brunswick —que producía embarcaciones de madera a vela— se colapsara. La recesión económica se vería agravada por el gran incendio de 1877 en Saint John. Muchos trabajadores expertos se trasladaron en dirección al oeste, rumbo a otras regiones de Canadá, o al sur, hacia los Estados Unidos. Durante la década de 1890, diversas vías ferroviarias unieron Nuevo Brunswick con el resto del país. Los ferrocarriles transportaban principalmente productos producidos en el interior de Canadá a puertos de las Provincias Marítimas. Halifax (en Nueva Escocia) y Saint John se convirtieron en grandes centros portuarios. Sin embargo, la competencia de productos industrializados a precios más baratos, producidos en Ontario o en Quebec, creó una recesión general en la industria de manufactura de Nuevo Brunswick.

La economía de la provincia se recuperaría a principios del siglo XX. La industria de manufactura ganó fuerza, especialmente la producción de muebles de madera. El periodo de mayor crecimiento económico de Nuevo Brunswick durante el inicio del siglo fueron los años de la Primera Guerra Mundial. Luego, después de la guerra, la caída de la demanda de productos industrializados generó nuevamente una gran recesión en la industria de manufactura de Nuevo Brunswick, para recuperarse de nuevo a partir de 1924.

Nuevo Brunswick sufrió con la Gran Depresión de la década de 1930, pero significativamente menos que el resto de Canadá. Esto porque la caída de la demanda de papel —especialmente papel de periódico y productos de madera— no fue drástica, como ocurrió en otros sectores de la economía del país en general. La Gran Depresión terminó con el inicio de la Segunda Guerra Mundial. Dos familias influyentes, K. C. Irving y McCain Foods, emergieron de la depresión, para iniciar la modernización de la economía de la provincia. La industria de manufactura ganó gran fuerza de nuevo.

Grandes depósitos de plomo, cobre, plata y zinc fueron descubiertos en la región de Bathurst-Newcastle en 1953. En 1957, se construyeron una serie de centrales hidroeléctricas en Nuevo Brunswick. En 1960, la mayor refinería de petróleo de Canadá hasta entonces fue construida en la provincia. En 1962, se inició un proyecto de desarrollo de las áreas donde fueron descubiertos grandes depósitos. El mismo año, se inició la extracción de estos recursos minerales. En 1968, se inauguró la central hidroeléctrica Matmaquac, para suministrar electricidad a las compañías que operaban en las minas de Bathurst-Newcastle.

Los acadianos, que habían habitado las regiones norte y este de la provincia, vivían relativamente aislados del resto de la provincia, donde la mayor parte de los habitantes hablaban inglés. Los servicios gubernamentales con frecuencia no estaban disponibles en francés, y las infraestructuras en áreas predominantemente francófonas estaban significativamente menos evolucionadas que en el resto de la provincia. Esto cambió con la elección como "premier" de Louis Robichaud en 1960. Creó un ambicioso programa, llamado "Equal Opportunity" (Igualdad de Oportunidades), donde la educación, el mantenimiento de carreteras rurales y los servicios de salud pasarían a ser administrados directamente por la provincia. Insistió en la cobertura igualitaria de estos servicios en todas las partes de la provincia —tanto en las ciudades cuanto en el campo. Los consejos administrativos de los condados de Nuevo Brunswick fueron abolidos, y todas las áreas rurales fuera de ciudades y villas pasaron a ser directamente administrados por la provincia. En 1969, Nuevo Brunswick aprobó la "Ley de Idiomas Oficiales", que hizo del francés un idioma oficial de la provincia, juntamente con el inglés, que ya era idioma oficial de Nuevo Brunswick. En esta ley, todas las ciudades de Nuevo Brunswick estarían obligadas a suministrar servicios y carteles en francés, en el caso de que los francófonos constituyeran al menos el 10% de la población de la ciudad.

Tensiones idiomáticas entre anglófonos y francófonos crecieron en ambos lados, con el militante Partido Acadiano teniendo por un corto período popularidad entre los francófonos de Nuevo Brunswick, durante la década de 1970, y grupos anglófonos presionando por la abolición de las reformas idiomáticas realizadas por Robichaud, durante la década de 1980. Las tensiones a causa del idioma, sin embargo, decayeron gradualmente con el pasar del tiempo, y habían desaparecido por completo durante el inicio de la década de 1990.

Mientras tanto la industria de fabricación de navíos se desarrolló considerablemente durante a década de 1970. Diversas fábricas fueron inauguradas en Saint John. En 1982, se puso en marcha la primera central nuclear en las Provincias Marítimas. En 1997, se inauguró el Puente de la Confederación, que conecta Nuevo Brunswick con la provincia vecina de la Isla del Príncipe Eduardo.

Nuevo Brunswick limita al norte con Quebec y el golfo de San Lorenzo (que separa Nuevo Brunswick de la Isla del Príncipe Eduardo), al este con Nueva Escocia y con la bahía de Fundy, y al sur y al oeste con el estado estadounidense de Maine.

El litoral de Nuevo Brunswick posee kilómetros de extensión. El litoral de la provincia está cortado por grandes bahías y entrantes. La mayor de estas bahías es la de Fundy. Esta bahía posee las mayores variaciones de marea del mundo, de más de diez metros. El principal río de Nuevo Brunswick es el río Saint John, que posee 674 kilómetros de longitud en la provincia. Otro río importante es el río Sainte-Croix, que forma la frontera de Nuevo Brunswick con Maine. La cascada más alta de Nuevo Brunswick —que posee una caída libre de 23 metros— se localiza próxima a Grand Falls. Los bosques cubren cerca del 85% de la provincia.

Nuevo Brunswick puede ser dividido en dos regiones geográficas distintas:



Nuevo Brunswick posee un clima templado. Las regiones localizadas a lo largo del litoral poseen temperaturas más amenas y un clima más inestable que el del interior de la provincia. Durante el invierno, las temperaturas de Nuevo Brunswick en general aumentan a medida en que se viaja en dirección al sur. En el verano, las mayores temperaturas medias se dan en la región centro-oeste de la provincia. 

En invierno, el sur de Nuevo Brunswick posee una temperatura media de -8°C, con una media de las mínimas de -14 °C, y una media de las máximas de -3 °C. El interior del norte de la provincia posee una temperatura media de -13 °C. La media de las mínimas es de -18 °C, y la media las máximas, de -7 °C. El litoral del nordeste de la provincia posee temperaturas intermedias. La temperatura más baja registrada en Nuevo Brunswick fue de -47 °C, registrada en Sisson Dam el 1 de febrero de 1955.

En verano, la región centro-oeste de Nuevo Brunswick posee una temperatura media de 20 °C. La media de las mínimas es de 13 °C, y la media de las máximas, de 26 °C. El interior del norte de la provincia posee una temperatura media de 16 °C, con la media de las mínimas de 10 °C, y la media de las máximas, de 25 °C. La temperatura más alta registrada en Nuevo Brunswick fue de 39 °C, registrada el 18 de agosto de 1935, en Nepisiguilt Falls y Woodstock, y el 19 de agosto de 1935, en Rexton.

Las tasas de precipitación media anual de lluvia de Nuevo Brunswick es de 108 centímetros, aumentando a medida en que se viaja en dirección al sur. El sur registra una media de 110 centímetros de precipitación anual, y la mayor parte de la región centro-norte, menos de 90 centímetros anuales. La tasa de precipitación media anual de nieve de Nuevo Brunswick es de 314 centímetros.

La población de ciervos en la provincia ha disminuido en un 70% desde 1985. El uso masivo de glifosato puede haber contribuido a ello.

El Teniente Gobernador representa a la reina Isabel II como jefe de estado de Nuevo Brunswick. El jefe del gobierno, y, en la práctica, mayor oficial del Poder Ejecutivo de la provincia, es el "Premier" o primer ministro en español, la persona que lidera el partido político con más escaños en la Asamblea Legislativa de la provincia. El "premier" de Nuevo Brunswick preside un Consejo Ejecutivo, que es el Gabinete de la provincia. El gabinete está formado por cerca de 25 ministros diferentes, que administran los distintos departamentos (economía, educación, etc). Tanto el primer ministro como los miembros del gabinete renuncian si pierden el soporte de la mayoría de los miembros del poder legislativo de Nuevo Brunswick.

El Poder Legislativo de Nuevo Brunswick es la Asamblea Legislativa, que está compuesta por 55 miembros. Nuevo Brunswick está dividido en 55 distritos electorales diferentes. La población de cada uno de estos distritos escoge un miembro que actuará como representante del distrito en la Asamblea, para mandatos de hasta cinco años de duración. Si el teniente gobernador disuelve la Asamblea antes de estos cinco años, a petición del primer ministro, todos necesitan presentarse a las elecciones de nuevo. No hay límite en el número de mandatos que una persona pueda ejercer. 

La mayor corte del Poder Judicial de Nuevo Brunswick es la "Court of Appeal of New Brunswick". Está compuesta por un juez-jefe y otros 12 cinco jueces. La "Court of Queens's Bench" es la segunda mayor corte de la provincia, y está compuesta por 61 jueces. La Corte Provincial de Nuevo Brunswick es la tercera corte en importancia de la provincia, y está compuesta por 109 jueces. Todos los jueces de la "Court of Appeal" y de la "Court of Queen's Bench" son escogidos por el primer ministro de Nuevo Brunswick y aprobados simbólicamente por el teniente gobernador. Los jueces continúan ejerciendo sus cargos hasta los 75 años de edad, aunque pueden jubilarse con 65 años de edad.

El gobierno de Nuevo Brunswick es el responsable de la prestación de los servicios de educación y de salud, y del mantenimiento de carreteras en general. Todas las ciudades y villas de la provincia son administradas por un alcalde y por un consejo, que son elegidos para mandatos de hasta tres años de duración. Los impuestos son responsables de cerca de la mitad de la composición del presupuesto del gobierno de Nuevo Brunswick. El resto proviene de presupuestos recibidos del gobierno federal y de préstamos. 

Políticamente, Nuevo Brunswick ha estado dominado igualmente por los liberales y por los Conservador Progresista. Desde el 24 de septiembre de 2018, los Conservadores Progresistas son el partido más grande en la Asamblea, con 22 de los 49 escaños y con Blaine Higgs como primer ministro. Tienen una mayoría con ayuda del partido Alianza popular que tiene 3 escaños. El partido liberal tiene 21 escaños y el partido verde tiene 3.

El censo de población canadiense de 2006 fijó la población de Nuevo Brunswick en habitantes, un crecimiento del 0,1% en relación a la población de la provincia en 2001, de habitantes.
Las principales áreas urbanas de Nuevo Brunswick son la región metropolitana de Saint John (Saint John, Quispamsis y Rothesay) y la región metropolitana de Moncton (Moncton, Riverview y Dieppe). Las regiones metropolitanas de Saint John y Moncton poseen cada una entre cerca de 120 y 130 mil habitantes. La región metropolitana de Fredericton, la capital provincial, posee cerca de 85 mil habitantes.

La población de Nuevo Brunswick es mayoritariamente anglófona, pero la provincia posee una población francófona de tamaño considerable. Los anglófonos suponen un 64,36% de la población de Nuevo Brunswick, frente al 32,37% de francófonos. A estos francófonos se les denomina generalmente "acadianos" —nombre proveniente de Acadia, el antiguo nombre de Nueva Escocia y Nuevo Brunswick, durante la época en que la región estaba controlada por los franceses. Nuevo Brunswick es la única provincia oficialmente bilingüe de Canadá.

Composición racial de la población de Nuevo Brunswick:


Porcentaje de población de Nuevo Brunswick por afiliación religiosa:


Nuevo Brunswick es una de las dos únicas provincias canadienses donde los católicos son mayoría en la provincia, junto con Quebec. Esto se debe a la gran población de origen francesa e irlandesa —que son en su mayoría católicos. Las tres mayores afiliaciones protestantes de Nuevo Brunswick son la Iglesia Unida de Canadá, la Iglesia Bautista y la Iglesia Anglicana.

La provincia está compuesta por 15 . A continuación se los enlista alfabéticamente:

Hay ocho ciudades en Nuevo Brunswick.

Moncton es la mayor ciudad de Nuevo Brunswick, y su área urbana posee las mayores tasas de crecimiento de población de la provincia. Es principalmente un centro de transportes, distribución y comercial. Moncton posee una gran población francófona —cerca del 35% de la población de la ciudad. Está considerada por los acadianos, con carácter no oficial, como la capital de Acadia.

Saint John es la segunda ciudad más poblada de Nuevo Brunswick. Es una ciudad portuaria, con una fuerte industria de manufactura. Los principales productos industrializados procesados y producidos en la ciudad son madera, papel y petróleo. La mayor parte de las grandes fábricas de producción masiva de la ciudad son propiedad de la "K. C. Irving". La familia Irving también controla buena parte de la economía de la provincia, así como tres de los cuatro periódicos anglófonos publicados en Nuevo Brunswick. Saint John no debe ser confundida con Saint John's, la capital de Terranova y Labrador.

Fredericton es la capital y la tercera ciudad más poblada. Es el principal centro universitario de la provincia, así como un gran centro cultural, sede de la Galería de Artes Beaverbrook, el Teatro de Nuevo Brunswick y el "New Brunswick Sports Hall of Fame".

El Producto Interno Bruto de Nuevo Brunswick es de cerca de 15,7 mil millones de dólares canadienses por año. La renta per cápita de la provincia es de dólares canadienses.

El sector primario supone un 5% del PIB de Nuevo Brunswick. La agricultura y la ganadería responden juntas por el 2% del PIB de la provincia, y emplean aproximadamente a 6,1 mil personas. Nuevo Brunswick posee cerca de 3,4 mil granjas que cubren el 5% de la provincia. Los principales productos del sector primario en Nuevo Brunswick son las patatas, las flores ornamentales y la carne y la leche bovina. La silvicultura aporta un 2% del PIB de la provincia, empleando a cerca de 7 mil personas. La pesca supone cerca del 1% del PIB, y emplea a cerca de 3 mil personas. El valor anual de la pesca capturada en la provincia es de aproximadamente 175 millones de dólares canadienses.

El sector secundario aporta el 25% del PIB de Nuevo Brunswick. La industria de manufactura aporta el 14% del PIB de la provincia y emplea aproximadamente a 41 mil personas. El sector de la construcción supone el 5% del PIB de la provincia y emplea a cerca de 19,6 mil personas. La minería aporta el 2% del PIB y emplea aproximadamente a 3 mil personas. Los principales recursos naturales extraídos en Nuevo Brunswick son el plomo, el cobre, la plata, el zinc, el cadmio, el bismuto, el oro y el carbón.

El sector terciario supone el por 70% del PIB de Nuevo Brunswick. Los servicios suponen el 22% del PIB de la provincia y emplean a cerca de 127,3 mil personas. Los servicios financieros e inmobiliarios emplean aproximadamente a 12,7 mil personas y suponen más del 22% del PIB de Nuevo Brunswick. El comercio al por mayor y al por menor responde por un 11% del PIB de la provincia y emplea aproximadamente a 55,1 mil personas. Transportes y telecomunicaciones suponen el por 10% del PIB y emplean aproximadamente a 32,2 mil personas y los servicios gubernamentales el 10% del PIB de la provincia, empleando aproximadamente a 22,9 mil personas. Los servicios públicos responden por el 4% del PIB de la provincia y emplean aproximadamente a 4,3 mil personas.

Cerca del 30% de la electricidad generada en Nuevo Brunswick está producida por la central nuclear de Point Lepreau, el 35% es generada en centrales termoeléctricas a carbón o a petróleo, y el 15% en centrales hidroeléctricas. El otro 20% se genera en centrales localizadas fuera de Nuevo Brunswick, pero administradas por la provincia. Cerca de la mitad de la electricidad generada en Point Lapreau es exportada a los Estados Unidos. Nuevo Brunswick también exporta electricidad a la Isla del Príncipe Eduardo.

La influencia de la familia Irving (propietaria de la refinería más grande de Canadá, de grandes granjas y fincas forestales, de periódicos, de muchos aserraderos y fábricas de papel, de una flota de barcos y camiones, de una red ferroviaria, etc) en Nueva Brunswick es tal que a veces se describe a la provincia como sujeta a una forma de feudalismo económico. En 2016, las 200 empresas que controla le otorgan un capital de aproximadamente 10.000 millones de dólares.

Las actividades del grupo cuentan con el apoyo de las autoridades a través de numerosas exenciones fiscales y subvenciones, especialmente a través del Programa de adquisición de energía renovable para grandes industrias. La provincia también ha transferido gradualmente la gestión de los activos forestales del sector público al grupo Irving, con una reducción regular de los estándares. En 2014, este último reduce el tamaño de las zonas de amortiguamiento entre los bosques y los lugares habitables, permite una mayor tala, aumenta el volumen de producción previsto y disminuye la proporción de áreas protegidas del 31% al 22%.

La familia es propietaria de todos los periódicos en inglés de la provincia. También es propietaria de varias estaciones locales de radio y televisión. Para el académico Alain Deneault, «los conflictos de intereses que se derivan de esta situación parecen caricaturizados: los medios de comunicación del grupo reflejan esencialmente las posiciones de la familia Irving en todos los ámbitos de la vida social e industrial en los que está implicada». La información proporcionada por el grupo y difundida por la prensa a veces es cuestionada (particularmente en el otoño de 2018, durante una explosión en la refinería de Saint John), pero pocos funcionarios, profesores y miembros del parlamento la reportan, ya que las contribuciones financieras de la familia a las universidades y a los partidos políticos le proporcionan un medio de presión.

Biólogos, académicos y Eilish Cleary, exjefe de salud pública de la provincia, informaron que habían sido sometidos a una fuerte presión (hasta el despido en el caso de Eilish Cleary) al analizar el impacto de los plaguicidas utilizados por el grupo y su gestión forestal opaca. Desde la década de 1970, todos los primeros ministros provinciales han sido elegidos con el apoyo de Irving. Blaine Higgs, primer ministro desde noviembre de 2018, es un antiguo ejecutivo del grupo. Según el periodista Michel Cormier: «Quizás podríamos ganar unas elecciones sin el apoyo tácito de Irving, pero era difícil aspirar al poder si decidía oponerse abiertamente a ello.»

Durante el siglo XVIII, la educación se impartía en los hogares o en escuelas privadas. En 1816, Nuevo Brunswick creó un sistema de escuelas públicas, donde existiría al menos una escuela en cada condado de la entonces colonia británica. Sin embargo, presupuestos insuficientes por parte del gobierno de Nuevo Brunswick forzaron a muchas de estas escuelas a cobrar por la prestación de la educación. Fue en 1871 cuando la provincia implementó el sistema de distritos escolares, dando a estas divisiones administrativas el poder de cobrar impuestos con fines educativos. En 1967, Nuevo Brunswick pasó a aportar todos los presupuestos necesarios para su sistema escolar público. Los distritos escolares, sin embargo, no fueron extinguidos, perdiendo solamente su poder de cobrar impuestos.

Actualmente, es el Ministerio de Educación de Nuevo Brunswick el responsable de dictar reglas y patrones de las escuelas de la provincia. No existen ya los distritos escolares en Nuevo Brunswick y las escuelas son administradas directamente por la provincia. La atención escolar es obligatoria para todos los niños y adolescentes con más de siete años de edad, hasta la conclusión de la enseñanza secundaria o hasta los dieciocho años de edad.

Durante el curso 2004/2005, las escuelas públicas de la provincia atendieron a estudiantes, empleando a 7509 profesores. El sistema de escuelas públicas de la provincia invirtió 1013,6 millones de dólares canadienses, y el gasto de las escuelas públicas por estudiante fue de 8653 dólares canadienses.

Nuevo Brunswick posee actualmente cinco sistemas de bibliotecas públicas. La biblioteca provincial, localizada en Fredericton, suministra parte de los presupuestos necesarios para el mantenimiento de estas bibliotecas públicas. La primera institución de enseñanza superior de Nuevo Brunswick, la Universidad de Nuevo Brunswick, en Fredericton, fue fundada en 1785.

Nuevo Brunswick posee cerca de mil kilómetros de vías férreas y 955 kilómetros de vías públicas. Saint John es el principal centro de transportes en general de Nuevo Brunswick, y un gran centro portuario, aeroportuario y ferroviario canadiense. Es uno de los pocos centros portuarios del este canadiense que opera todo el año.

Los primeros periódicos publicados en Nuevo Brunswick fueron el "The Royal Gazette" y el "The New Brunswick Advertiser", que fueron publicados en 1785. Actualmente se publican en la provincia cerca de 25 periódicos, de los cuales cinco son diarios.

La primera estación de radio de Nuevo Brunswick fue fundada en 1923, en Fredericton. La primera estación de televisión de la provincia fue fundada en 1954, en Saint John. Actualmente, Nuevo Brunswick posee 31 estaciones de radio —de las cuales 11 estaciones son de radio AM y 20 estaciones son de FM— y tres estaciones de televisión.




</doc>
<doc id="2038" url="https://es.wikipedia.org/wiki?curid=2038" title="Nueva Escocia">
Nueva Escocia

Nueva Escocia (en inglés: "Nova Scotia", nombre de origen latino; en francés: "Nouvelle-Écosse"; en gaélico escocés: "Alba Nuadh") y abreviada comúnmente NS, es una de las diez provincias que, junto con los tres territorios, conforman las trece entidades federales de Canadá. Su capital y ciudad más poblada es Halifax. Ubicada en el extremo este del país, está formada por la península homónima y la isla de Cabo Bretón en la extremidad norte de esta. La península está rodeada por el océano Atlántico, salvo por el istmo de Chignecto —que la une a Nuevo Brunswick— y el estrecho de Northumberland —que la separa de Isla del Príncipe Eduardo. Con es la segunda entidad menos extensa —por delante de Isla del Príncipe Eduardo— y con 17 hab/km², la segunda más densamente poblada, por detrás de Isla del Príncipe Eduardo.

Forma parte de las Provincias Marítimas. Su capital es un puerto muy importante de Norteamérica. La pesca y el turismo son vitales para la economía de la provincia.

Aunque el explorador Juan Caboto la visitó en 1497 por cuenta de la Corona de Inglaterra, Nueva Escocia fue colonizada por primera vez por el reino de Francia. Samuel de Champlain y De Monts fundaron una colonia en una isla en la desembocadura del río Sainte-Croix en 1604. Al sufrir falta de agua potable en la isla ese invierno, al año siguiente (1605) la colonia fue trasladada a Port Royal, cerca de Annapolis Royal.

En los años 1620, el rey Carlos VI de Escocia y I de Inglaterra envió una tropa de escoceses para fundar en el lugar una colonia con el nombre de "Nova Scotia", como homenaje a sus orígenes escoceses. Para ello fundó el impuesto o "baronetage" de Nueva Escocia: aquellos que deseasen obtener el título nobiliario de "baronet" quedaban obligados al pago de una cierta suma de dinero que serviría para la fundación de la colonia, además de recibir en la misma una concesión de tierras. Durante la Guerra de los Nueve Años o de la Gran Alianza contra Francia, fue tomada por británicos, pero en los tratados firmados al final de la misma, se volvió a ceder a Francia: Tratado de Rijswijk de 20 de septiembre de 1697. Fruto del tratado los colonos escoceses debieron abandonarlo, el "baronetage" de Nueva Escocia perdió su valor, pasando a ser una mera categoría nobiliaria.
El territorio fue capturado por fuerzas británicas durante la Guerra de la reina Ana, que es como se conoce el conflicto de Guerra de Sucesión Española en el escenario norteamericano. La titularidad inglesa fue ratificada por el Tratado de Utrecht (1713). Francia retendría la posesión de la "Île Saint Jean" (Isla del Príncipe Eduardo) e "Île Royale" (Isla de Cabo Bretón), en la que establecieron la fortaleza de Louisbourg, que se construyó para vigilar las vías marítimas que se dirigen al río San Lorenzo. 

La fortaleza de Louisbourg sería en 1745, en el curso de la Guerra de Sucesión Austriaca (1740-1748), conocida como "Guerra del rey Jorge" en su escenario americano. El tratado de Aix-la-Chapelle o Tratado de Aquisgrán (1748) que puso fin a dicho conflicto, estipuló la devolución a Francia de la fortaleza de Louisbourg. 

Louisbourg sería nuevamente tomada (Batalla de Louisbourg, junio-julio de 1758) por una tropa mixta de soldados del Ejército británico y habitantes de las colonias americanas, durante la Guerra Franco-india, que es como se conoce al frente norteamericano de la Guerra de los siete años. Una vez en manos inglesas, (antes incluso de la Batalla de las Llanuras de Abraham, que abriría paso a la conquista del Quebec), los Británicos destruyeron la fortaleza de Louisbourg con explosivos para evitar que pudiera volver a ser usada por los franceses si la retomaban fruto de algún nuevo tratado de paz. 

Quedaría ratificada la posesión inglesa por el Tratado de París (1763) al recibir Gran Bretaña todos los territorios franceses en el Canadá.

La presencia de los acadianos, francófonos y de religión católica en el territorio de la futura colonia británica planteaba a los británicos un problema cara a la colonización del territorio. En 1750 un alto número de colonos de religión protestante, en su mayor parte de origen alemán, fueron atraídos a Nueva Escocia, estableciéndose en la costa sur. La colonia seguía sin embargo siendo mayoritariamente acadiana. Pero a partir de 1755, los británicos decidieron deportar a los acadianos a sus otras colonias americanas, a Francia, al Reino Unido o a Luisiana, lugar donde muchos de ellos se establecieron contribuyendo a forjar la cultura cajún.

Tras la Deportación de los acadianos, las tierras acadianas fueron entregadas a colonos americanos procedentes de Nueva Inglaterra. Unos 8000 de ellos, llamados «planters» se establecieron en la colonia entre 1759 y 1774, entre ellos el bisabuelo de Robert Laird Borden. Una nueva inmigración escocesa cuyo destino fue la isla de Cabo Bretón, en las postrimerías del siglo XVIII y a principios del siglo XIX restableció la antigua presencia escocesa en la región.

En 1784 la porción continental del noroeste de la colonia fue separada del resto, pasando a constituir la colonia de Nuevo Brunswick.
En 1848 Nueva Escocia se convirtió en la primera colonia del Imperio británico en alcanzar el «self-government» o autogobierno, en que el gobernador británico quedaba obligado a aceptar las decisiones tomadas por una Asamblea Legislativa y por unos ministros electos por la misma.

En la isla se encuentran enterrados muchos de los fallecidos en el naufragio del RMS "Titanic".

Nueva Escocia se convirtió, al entrar en la Confederación Canadiense, en una de las cuatro provincias fundadoras de Canadá, junto con Nuevo Brunswick, Quebec ("Canadá Este") y Ontario ("Canadá Oeste"). 

A pesar de su nombre, quedan escasísimos habitantes en la región que sigan hablando el gaélico escocés, aunque la música celta sigue gozando de gran popularidad en la isla de Cabo Bretón. Sigue habiendo actualmente una pequeña presencia acadiana en la localidad de Clare (al oeste de la provincia).

La provincia está dividida en 18 condados. En 2016, un 50% de la población es protestante y un 30% católica.

Los 10 condados más poblados de la provincia:

La economía de Nueva Escocia se basa actualmente en el sector servicios y el sector industrial, aunque sigue manteniendo presencia el sector primario.

En el sector primario, por lo que respecta a la agricultura, destaca la producción de fruta, especialmente manzanas, y patatas. En la ganadería tiene presencia la avicultura y el ganado porcino, a lo que se une una cabaña bovina generadora de productos lácteos.

También existe una activa industria de tipo forestal, dedicada a la explotación de los bosques del territorio.

Por otro lado, es igualmente importante la pesca de langostas, bivalvos (destacando las vieiras) o bacalao, especialmente. 

Posee igualmente una activa industria, relacionada con las actividades pesqueras y con la industria alimentaria en general, pero también industria papelera, de equipos de transporte.

El turismo ha adquirido una creciente importancia a lo largo de la segunda mitad del siglo XX.





</doc>
<doc id="2040" url="https://es.wikipedia.org/wiki?curid=2040" title="Nenúfar">
Nenúfar

El término nenúfar se aplica, en general, a plantas acuáticas con flores que crecen en lagos, lagunas, charcas, pantanos o arroyos de corriente lenta, estando usualmente enraizadas en el fondo. Los "nenúfares" pertenecen a las familias Nymphaeaceae, Cabombaceae del orden Nymphaeales; la familia Nelumbonaceae del orden Proteales y también a los géneros Nymphoides de la familia Menyanthaceae del orden Asterales y el género Hydrocleys de la familia Alismataceae del orden Alismatales. Véase cada una de estas tres familias o uno de estos dos géneros para datos más específicos.
Las hojas de los nenúfares comunes pueden ser de dos tipos:

Los antiguos egipcios veneraban los nenúfares del Nilo, a los que solían llamar “lotos” (no confundir con el género lotus). Es frecuente el motivo del “loto” en las capiteles de las 3 columnas (forma lotiforme) de los templos egipcios. Florece en la noche y se cierra por la mañana, esto simbolizaba la separación de deidades y era un motivo asociado a sus creencias sobre la muerte y el más allá. El reciente 4 descubrimiento de las propiedades psicodélicas del loto azul egipcio es muy probable que hubiesen sido conocidas por los egipcios y explica su papel ceremonial que puede verse en multitud de representaciones. Restos de ambos tipos de nenúfares se han encontrado en la tumba de Ramsés II.

Una placa siria de terracota del siglo  a. C. al  a. C. muestra a la diosa Asera con dos flores de loto. Un panel de marfil del siglo  a. C. al siglo  a. C. muestra al dios Horus sentado en una flor de loto, flanqueada por dos querubines.

El pintor francés Claude Monet es famoso por sus pinturas de nenúfares.

Muchos de los nenúfares familiares de los jardines acuáticos son híbridos.

Los nenúfares de jardín provienen del género botánico "Nymphaea" aunque su nombre en español deriva de otra planta de parecidas características conocida como "Nuphar".

Los nenúfares se desarrollan a expensas de un tallo carnoso (rizoma) que vive entre los materiales acumulados en el fondo de charcas y cursos estancados de aguas poco profundas. Las hojas tienen un buen tamaño y forma casi circular con una profunda escotadura que llega hasta la inserción del pecíolo con el limbo (parte plana). Estas hojas, al igual que las flores, son flotantes y nacen directamente del rizoma, al que se unen por largos pecíolos. Las flores de buen tamaño incluso muy grandes, se visten con multitud de pétalos imbricados formando una especie de cuenco en cuyo centro se encuentran los estambres y pistilos. La amplia gama de colores de la flor incluye el blanco puro, marfil, crema, rosa, rojo, carmesí, cobrizo y amarillo en distintas tonalidades según variedades. En situaciones apropiadas la emisión de flores es continua de mayo a septiembre. La profundidad de plantación necesaria para los diferentes tipos de nenúfares oscila entre 20 cm y el metro, mientras que la superficie de extensión foliar va de 0,5 a 1,5 metros cuadrados.


</doc>
<doc id="2041" url="https://es.wikipedia.org/wiki?curid=2041" title="Numerología">
Numerología

La numerología es un conjunto de creencias o tradiciones que pretende establecer una relación oculta entre los números, los seres vivos y las fuerzas físicas o espirituales. También es una práctica supuestamente adivinatoria a través de los números. Su estudio fue popular entre los primeros matemáticos, pero no se la considera ya disciplina matemática. La comunidad científica hace tiempo que relegó la numerología a la categoría de pseudociencia o superstición, al igual que la astrología con respecto a la astronomía, o la alquimia, aunque esta última tuvo carácter de protociencia con respecto a la química.

En numerología, se dice que los números son uno de los conceptos humanos más perfectos y elevados. Según los que la practican, la numerología es la disciplina que pretende investigar la «vibración secreta» de ese código y enseñan a utilizar los números en su beneficio, por medio del estudio de su influencia sobre personas, animales.

En el año 530 a. C., Pitágoras, filósofo griego, desarrolló en forma metódica una relación entre los planetas y su «vibración numérica». La denominó «música de las esferas». Mediante su método de numerología afirmó que las palabras tienen un sonido que vibra en consonancia con la frecuencia de los números como una faceta más de la armonía del universo y las leyes de la naturaleza.

Según los numerólogos, los números son mucho más que una forma de medir o cuantificar lo que existe a nuestro alrededor. Pitágoras creía que el universo debe ser visto como un todo armonioso, donde todo emite un sonido o vibración. Los números del 1 al 9 están asociados a características específicas, que juntas abarcan toda la experiencia de la vida.

El sistema numérico por excelencia en numerología es el decimal, siendo excepción la escuela caldea de numerología, que utiliza el sistema octal.

Existen varias escuelas de numerología, entre ellas:







</doc>
<doc id="2046" url="https://es.wikipedia.org/wiki?curid=2046" title="Nirvana (espiritualidad)">
Nirvana (espiritualidad)

En la filosofía shramánica, nirvana es el estado de liberación tanto del sufrimiento (dukkha) como del ciclo de renacimientos. 

Es un concepto importante en el hinduismo, jainismo y budismo y suele alcanzarse mediante diferentes prácticas y técnicas espirituales.

Nirvana es una palabra del sánscrito que hace referencia a un estado que puede alcanzarse a través de la meditación y la iluminación espiritual, y que consiste en la liberación de los deseos, el sufrimiento, la conciencia individual y el ciclo de reencarnaciones.

Nirvana significa literalmente "apagado", como en una vela.

En otros idiomas se dice:

El nirvana es el estado transcendente libre de sufrimiento y de la existencia fenoménica individual; es la experiencia religiosa más identificada con el budismo.
La palabra procede de un verbo que significa "enfriarse" o "apagarse", como el final de una vela.
La connotación es que sólo en el nirvana están extinguidas las llamas del odio, el apego y la ignorancia.
En estado de nirvana se rompe el ciclo de la transmigración, que de otra manera sería eterno.
Su naturaleza ha sido muy debatida por el pensamiento occidental, algunos de cuyos investigadores sostienen que implica una total aniquilación aunque otros lo interpretan como beatitud eterna.
Ambos puntos de vista son problemáticos en ocasiones, ya que el nirvana es indescriptible y solo puede conocerse desde su experiencia.

En el hinduismo se habla de la unión con el uno absoluto (Brahman), por tanto aunque el nirvana apunta a un mismo suceso de paz interior, no se debe considerar exactamente con las mismas consecuencias que en el budismo, ya que de hecho el budismo redefinió el concepto de nirvana según sus propios postulados.
Cada una por tanto tiene su propio marco religioso.

El hinduismo utiliza el término nirvana en su contexto de "" (liberación del "samsara" o del ciclo de nacimientos y muertes repetidos), en el que el alma o "ātmān" se fundirá con la divinidad o lo absoluto.
Esta liberación es por tanto una fusión del alma con la divinidad.

A su vez dentro del hinduismo este concepto de liberación es concebido de manera diferente por los distintos credos "(dárśanas)" hindúes.
Los vaishnavas (vishnuistas, o devotos del dios Vishnú) consideran que "" no implica la fusión monista del alma dentro de Dios, sino la aceptación del alma para servirlo.
Por eso en el vaishnavismo no se desea realmente abandonar la reencarnación, sino servir a Dios, aunque sea sufriendo en este mundo lejos de él.

Siddhartha Gautama se refería al nirvana de la siguiente manera:
Como no se puede definir el nirvana con palabras, se lo suele delimitar por lo que no es:


Buda Gautama redefinió la consecución del nirvana presente en el hinduismo mediante un proceso de meditación en el que se analiza el cuerpo y la mente como carentes de una individualidad intrínseca.
En ese proceso existe un vacío de individualidad "(śūnyatā)" de todo lo presente en el cuerpo y mente del sujeto.
Esta falta de una individualidad es también común en todos los fenómenos del universo.

Al igual que en el hinduismo, la realización del nirvana budista implica la liberación definitiva del sufrimiento de la existencia o de los diferentes estados de reencarnación a los que todos los seres están sujetos.
Pero en el budismo esta idea será llevada hasta sus últimas consecuencias.
La diferencia en el contexto hinduista es que esto ocurre por la unión a un absoluto (Brahman) a semejanza de lo que expone la mística de las religiones teístas occidentales.

La afirmación de que el budismo considera el nirvana como lo opuesto al "samsāra" (el mundo tal como lo vivimos ahora) no es correcta desde el punto de vista de la doctrina budista, toda vez que dioses y hombres están sujetos al "karma" y Buda expresó la liberación final de dioses y hombres en medio del mundo de los fenómenos.
Por lo tanto, se distanció de ese estado de absorción en la divinidad o unión a un absoluto como vía de liberación definitiva tal como estaba presente en el hinduismo.

En el jainismo se refiere a la liberación de las ataduras del karma. Cuando un ser humano como un Tirthankara se libera de sus karmas finaliza su experiencia en el mundo logrando el nirvāṇa. 
Técnicamente, el final del período de vida es llamado nirvana en tanto que ha acabado la existencia terrenal y ha alcanzado la liberación. El Moksa sería entonces la liberación que sigue al nirvana. Así tendríamos un primer paso, el nirvana, que realiza el Arhat y que solo después y mediante el Moksa pasa a convertirse en siddha, el liberado.

Los jainas celebran el Diwali como el día en que Mahavira logró su nirvana. El Kalpasutra narra detalladamente el nirvana de Mahavira.



</doc>
<doc id="2051" url="https://es.wikipedia.org/wiki?curid=2051" title="Ojo humano">
Ojo humano

En el ser humano, el ojo es un órgano que detecta la luz y es la base del sentido de la vista. Su función consiste básicamente en transformar la energía lumínica en señales eléctricas que son enviadas al cerebro a través del nervio óptico. Funciona de forma muy similar al de la mayoría de los vertebrados y algunos moluscos; posee una lente llamada cristalino, que es ajustable según la distancia; un diafragma, que se llama pupila, cuyo diámetro está regulado por el iris, y un tejido sensible a la luz, que es la retina. La luz penetra a través de la pupila, atraviesa el cristalino y se proyecta sobre la retina, donde se transforma, gracias a unas células llamadas fotorreceptoras, en impulsos nerviosos que se trasladan, a través del nervio óptico, al cerebro.

Su forma es aproximadamente esférica, mide 2,5 cm de diámetro y está lleno de un gel transparente llamado humor vítreo que rellena el espacio comprendido entre la retina y el cristalino.

En la porción anterior del ojo se encuentran dos pequeños espacios: la cámara anterior que está situada entre la córnea y el iris, y la cámara posterior que se ubica entre el iris y el cristalino. Estas cámaras están llenas de un líquido que se llama humor acuoso, cuyo nivel de presión (presión intraocular) es muy importante para el correcto funcionamiento del ojo.

Para que los rayos de luz que penetran en el ojo se puedan enfocar en la retina, se deben refractar. La cantidad de refracción requerida depende de la distancia del objeto al observador. Un objeto distante requerirá menos refracción que uno más cercano. La mayor parte de la refracción ocurre en la córnea, que tiene una curvatura fija. Otra parte de la refracción requerida se da en el cristalino. El cristalino puede cambiar de forma, aumentando o disminuyendo así su capacidad de refracción. Al envejecer, el ser humano va perdiendo esta capacidad de ajustar el enfoque, deficiencia conocida como presbicia o vista cansada.

El tipo habitual de ojo entre los vertebrados se desarrolló en menos de 100 millones de años evolucionando desde un sencillo detector de luz para los ritmos circadianos (diarios) y estacionales, hace unos 600 millones de años, hasta un órgano muy refinado desde un punto de vista óptico y neurológico, hace 500 millones de años. Más de 150 años después de la teoría de la evolución de Charles Darwin, los hallazgos científicos han dado al traste con la teoría creacionista de la complejidad irreductible, uno de cuyos argumentos era la existencia de un órgano tan sumamente estructurado en el hombre, y respaldan las ideas del naturalista.

El órgano de la visión está compuesto por los párpados, los globos oculares, el aparato lagrimal y los músculos oculares externos. El globo ocular mide unos 25 mm de diámetro y se mantiene en su posición gracias a los músculos extraoculares. La visión binocular, con la participación de ambos ojos, permite apreciar las imágenes en tres dimensiones.

La pared del ojo está formada por tres capas:

El ojo se forma por la fusión de varias estructuras que proceden de tejidos embrionarios distintos. La retina es un derivado del prosencéfalo (cerebro anterior) y por tanto forma parte del sistema nervioso central, mientras que la córnea y el cristalino proceden del ectodermo superficial.

Los primeros signos del futuro ojo se observan de forma muy temprana en el embrión, pues son visibles a finales de la tercera semana o principios de la cuarta, aproximadamente en el día 22. La retina se forma a partir de dos vesículas ópticas que nacen directamente de la porción anterior del cerebro primitivo, llamada prosencéfalo, al que está conectada mediante los tallos ópticos. Estas dos vesículas se van aproximando poco a poco a la superficie y sufren una invaginación en la parte anterior, pasando de ser esféricas a tener forma de copa, dando origen al cáliz óptico que tiene doble pared por el plegamiento sufrido. La pared interna que recubre el interior del cáliz óptico, dará lugar a la retina, mientras que la pared externa formará la lámina de células epiteliales ricas en melanina.

El ectodermo superficial que entra en contacto con la parte anterior del cáliz óptico sufre un espesamiento, formando la placa cristalina, que se invagina y da origen a la vesícula cristalina, la cual es el germen del futuro cristalino. A partir de la quinta semana del desarrollo, la vesícula cristalina pierde contacto con el ectodermo superficial y se dispone cubriendo el orificio del cáliz óptico. Cuando la vesícula cristalina se separa, esta misma zona del ectodermo se espesa de nuevo, para formar la córnea.

La parte anterior del globo ocular está cubierta por la córnea, una estructura transparente y resistente que carece de vasos sanguíneos.

Alrededor de la córnea está la conjuntiva. Por detrás de la córnea se halla la cámara anterior, limitada por el iris y la pupila. Detrás del iris y la pupila se encuentra la cámara posterior, el cuerpo ciliar y el cristalino.

La cámara anterior y la cámara posterior son dos pequeños espacios separados por el iris y conectados por la pupila que están llenos de un líquido transparente, el humor acuoso. El humor acuoso humedece el cristalino, garantiza su nutrición y contribuye a mantener la forma de la porción anterior del ojo.

El iris está formado por dos músculos que controlan la dilatación y la contracción de la pupila. El color del iris depende de la transparencia del estoma y de la cantidad de pigmento que contiene. Cuando el pigmento es escaso, los ojos son azules, mientras que cuando hay una cantidad mayor se aprecian matices verdes o castaños.

El cristalino es la lente del ojo, está sostenido por unas fibras conjuntivas muy finas llamadas ligamento suspensorio del cristalino que a su vez se unen al músculo ciliar. El cristalino se forma a lo largo de la tercera o cuarta semana de embarazo. Es blando y elástico en los niños, pero se endurece con el paso de los años.
El cuerpo ciliar se extiende entre la ora serrata y el iris, y es responsable de la producción del humor acuoso y del cambio de forma del cristalino necesario para lograr la correcta acomodación (enfoque). Está formado por dos estructuras, el músculo ciliar y los procesos ciliares.

Detrás del cristalino se encuentra el humor vítreo. El humor vítreo es un gel transparente que ocupa la mayor parte del interior del ojo y contribuye a que este mantenga su forma. Está en contacto directo con la retina, que es la túnica más interna del ojo. La retina es sensible a los estímulos luminosos y está conectada con el cerebro mediante las fibras del nervio óptico.

En la retina se pueden diferenciar varias partes, la más importante es la mácula, que es la zona con mayor agudeza visual. En el centro de la mácula se encuentra la fóvea que es un área muy pequeña, formando una depresión, extremadamente sensible a la luz. La fóvea es el área de la retina donde se enfocan los rayos luminosos y se encuentra especialmente capacitada para la visión aguda y detallada. Cualquier daño en la fóvea tiene importantes consecuencias en la capacidad visual.

Otra zona importante es la papila óptica que es el lugar por donde sale de la retina el nervio óptico. En la papila no existen células sensibles a la luz por lo que se conoce también como punto ciego.

La ora serrata es la porción más anterior y periférica de la retina, por la que ésta entra en contacto con el cuerpo ciliar.

El ojo recibe los estímulos luminosos procedentes del entorno. La luz atraviesa los medios transparentes y la lente del ojo, formando una imagen invertida sobre la retina. En la retina, células especializadas transforman la imagen en impulsos nerviosos. Estos llegan a través del nervio óptico hasta la región posterior del cerebro. El cerebro interpreta las señales mediante un complejo mecanismo en el que intervienen millones de neuronas.

El iris es un diafragma circular que regula la cantidad de luz que ingresa en el ojo, mediante el músculo constrictor del iris o músculo esfínter de la pupila y el músculo dilatador de la pupila o radial. Presenta un orificio central de unos 3 mm de diámetro, la pupila. Ésta se adapta a la intensidad de la luz. Si la luz es intensa, la pupila se contrae (miosis), si la luz es escasa, la pupila se dilata (midriasis).

La constricción del iris es involuntaria y está controlada de forma automática por el sistema nervioso parasimpático, la dilatación también es involuntaria, pero depende del sistema nervioso simpático.

La córnea es la estructura hemisférica y transparente localizada en la parte anterior del ojo que permite el paso de la luz y protege al iris. El cristalino está detrás de la córnea, tiene forma biconvexa y es la lente u objetivo del ojo. Cuando un rayo de luz pasa de una sustancia transparente a otra, su trayectoria se desvía: este fenómeno se conoce con el nombre de refracción. La luz se refracta en la córnea y el cristalino y se proyecta sobre la retina.

Los rayos de luz que penetran en el ojo deben enfocarse exactamente sobre la retina para que la imagen obtenida sea nítida. Ello requiere un ajuste que ocurre de forma muy similar tanto en el ojo humano como en el resto de los animales vertebrados.
El proceso mediante el cual los rayos luminosos procedentes tanto de objetos cercanos como lejanos se enfocan con exactitud sobre la retina se llama acomodación.
El mecanismo de la acomodación exige la contracción del músculo ciliar que está unido al cristalino mediante el ligamento suspensorio.

Si el músculo ciliar se contrae, el cristalino se hace más esférico y aumenta su poder de refracción, lo cual permite enfocar la luz procedente de objetos cercanos.
Cuando el músculo ciliar se relaja, el cristalino se hace menos esférico, disminuye su poder de refracción, lo cual nos permite ver con nitidez objetos lejanos.

En la retina están las células visuales, por lo que se la puede comparar a una película fotosensible. Estas células son capaces de captar la luz visible que es solo una pequeña parte del espectro electromagnético, la comprendida entre los 400 nanómetros de la luz violeta y los 750 nanómetros de la luz roja.

La luz que incide en la retina desencadena una serie de fenómenos químicos y eléctricos que finalmente se traducen en impulsos nerviosos que son enviados hacia el cerebro por el nervio óptico.

Las células sensoriales de la retina reaccionan de forma distinta a la luz y los colores. Los bastones se activan en la oscuridad, y sólo permiten distinguir el negro, el blanco y los distintos grises. Los conos, hacen posible la visión de los colores.

En el ojo humano hay tres tipos de conos, sensibles a luz de color rojo, verde, y azul. Cada uno de ellos absorbe la radiación de una determinada porción del espectro gracias a que poseen unos pigmentos llamados opsinas.
Las opsinas son unas moléculas que están formadas por una proteína y un derivado de la vitamina A. La eritropsina tiene mayor sensibilidad para las longitudes de onda largas de alrededor de 560 nm (luz roja), la cloropsina para longitudes de onda medias de unos 530 nm (luz verde) y por último la cianopsina con mayor sensibilidad para las longitudes de onda pequeñas de unos 430 nm (luz azul).
Mediante las diferentes intensidades de las señales producidas por los tres tipos de conos, podemos distinguir todos los colores que forman el espectro de luz visible.

Los conos están concentrados en el centro de la retina, mientras que los bastones abundan más en la periferia de la misma. Cada cono está conectado individualmente con el centro visual del cerebro, lo que en la práctica permite distinguir a una distancia de 10 metros dos puntos luminosos separados por solo un milímetro. Cada ojo humano dispone de 7 millones de conos y 125 millones de bastones.

La musculatura extrínseca está formada por seis músculos que se insertan por una parte en la órbita y del otro lado en la capa más externa del ojo, la esclerótica. Estos músculos son los que permiten mover el ojo en cualquier dirección sin necesidad de cambiar la posición de la cabeza, tal como ocurre por ejemplo cuando seguimos con la vista un objeto en movimiento.

Los nervios ópticos de ambos ojos se entrecruzan antes de entrar en el encéfalo, formando el quiasma óptico. Luego se prolongan por las cintillas ópticas hacia la zona media del cerebro. Finalmente estos impulsos alcanzan los centros visuales de los lóbulos occipitales.

Cuando los impulsos nerviosos llegan a los lóbulos occipitales del cerebro, la información debe ser procesada. El cerebro procesa la información visual de forma particular.
Los diferentes aspectos de una imagen son decodificados por diferentes partes del mismo.

La forma de un objeto es procesada por una vía, mientras el color y el movimiento lo son por otras vías diferentes. De esta forma, el daño de una zona concreta del cerebro, puede producir ciertas manifestaciones características, como ocurre en la agnosia (imposibilidad de nombrar y reconocer un objeto común) que se produce cuando se lesiona un área específica de asociación visual que se encuentra en el hemisferio cerebral izquierdo.

Las órbitas son dos cavidades óseas, simétricas y profundas con forma de pirámide cuyo vértice apunta hacia atrás, tienen la función de proteger al ojo. Están situadas a ambos lados de la nariz, en el límite del cráneo con la cara. Constan de cuatro paredes: superior, inferior, interna y externa y un vértice donde se encuentra el agujero óptico que es la principal comunicación de la órbita con el interior del cráneo.

Dentro de la órbita se encuentra el ojo y una serie de estructuras anexas que son imprescindibles para el funcionamiento adecuado de este órgano. A continuación se enumeran:

Las razones más comunes de consulta con relación al ojo son: pérdida de agudeza visual, dolor, cuerpo extraño, cefalea, irritación del ojo (ojo rojo), otros síntomas variables (secreciones, ardor, prurito, fotofobia, etc.) y trastornos anatómicos.

Incluye el estudio de la agudeza visual, la capacidad para distinguir colores, el sentido luminoso, es decir la medida de la intensidad de luz necesaria para distinguir un objeto y el estudio del campo visual que se realiza mediante una prueba llamada campimetría.

Para explorar la agudeza visual, el paciente debe leer varias filas de letras de tamaño decreciente (test de Snellen). Si la visión es normal, se pueden leer todas las filas a una distancia de 6 metros.
Para corregir el déficit de visión se pueden utilizar cristales de distinto tipo: cóncavos y convexos. Los cristales cóncavos, corrigen la miopía y los convexos se utilizan para la presbicia y la hipermetropía.

Para examinar la visión cromática o visión de colores, el médico presenta al paciente varias láminas con un dibujo en color sobre un fondo de otro color. Si se distinguen con normalidad todos los colores, se pueden apreciar los dibujos que hay sobre el fondo. La acromatopsia total impide distinguir cualquier color: la visión es exclusivamente en blanco y negro. Es más frecuente la acromatopsia parcial como ocurre en el daltonismo.

Incluye una inspección general de la cara, los párpados, observando su aspecto y posición, la región lagrimal, la superficie interna de los párpados (conjuntiva palpebral), eversión de los párpados en busca de cuerpos extraños allí alojados. También el examen de la movilidad ocular y los reflejos pupilares, como el reflejo fotomotor que consiste en el cierre inmediato de la pupila tras iluminar el ojo con una luz directa.

Mediante diferentes dispositivos de iluminación y una lente de aumento, se visualizan en detalle las estructuras de la porción anterior del ojo, es decir la conjuntiva, la córnea, el humor acuoso, el iris, el cristalino y la pupila.

Para explorar el fondo de ojo, el médico se sirve de un oftalmoscopio e instila en el ojo una sustancia que dilata las pupilas. De esta forma puede observar las porciones internas del órgano, la retina y sus vasos sanguíneos, la papila óptica, la coroides y el humor vítreo, así como detectar diversas enfermedades, como un desprendimiento de retina o signos de hipertensión arterial o diabetes que a veces se reflejan en la retina.

En este examen pueden visualizarse múltiples anomalías, algunas de las más usuales son las hemorragias en la retina y la presencia de exudados de diferentes tipos. Muchas enfermedades no oculares dan manifestaciones características que son detectables mediante esta exploración.

Se llama ceguera a una pérdida total o muy severa de la capacidad visual. Una persona ciega es incapaz de percibir la forma de los objetos, aunque puede conservar una mínima función que le permita distinguir entre luz y oscuridad.

El concepto de ceguera legal es distinto al anterior, pues se utiliza para diferentes cuestiones legales relacionadas con indemnizaciones, prestaciones sociales o afiliación a organizaciones de ciegos. La ceguera legal no tiene una definición única, pues depende de la legislación de cada país. En los países occidentales, generalmente se considera legalmente ciego a aquel individuo que tiene una agudeza visual menor de 0.1 (1 es la normalidad) o un campo visual muy disminuido, inferior a 10 grados.

Por lo tanto, contrariamente a lo que muchos creen, una persona con ceguera legal puede conservar un resto visual que le permita realizar algunas actividades de la vida diaria sin necesidad de ayuda.

Según los datos de la OMS, en el mundo existen 45 millones de personas ciegas, la mayoría de las cuales viven en países en vías de desarrollo. A nivel mundial las principales causas son: catarata (48 %), glaucoma (12 %), degeneración macular asociada a la edad (9 %), opacidades de la córnea (5 %), retinopatía diabética (5 %), diferentes trastornos agrupados como ceguera en la infancia (3.9 %) y tracoma (3,6 %). Muchas de estas enfermedades son perfectamente tratables, por lo que en los países desarrollados las causas principales son: Retinopatía diabética, degeneración macular asociada a la edad, glaucoma y accidentes.

La miopía es un defecto del ojo en el que el punto focal se forma delante de la retina, en lugar de en la misma retina como sería normal.

Esta anomalía ocasiona dificultad para ver de lejos. El sujeto verá mal todo aquel objeto situado a partir de una cierta distancia.

La causa más frecuente de miopía es un aumento en el diámetro anteroposterior del globo ocular. También puede ser debida a un aumento de la capacidad de refracción del cristalino o al aumento en la curvatura de la córnea como ocurre en el queratocono. Se trata mediante el uso de gafas correctoras, lentillas, con una intervención quirúrgica con láser (LASIK, PRK) o con la colocación de lentes intraoculares.

La hipermetropía es un defecto del ojo, en el cual los rayos de luz que inciden en el mismo procedentes del infinito, forman el foco en un punto situado detrás de la retina. Se trata por lo tanto de un defecto refractivo inverso al de la miopía.

A diferencia de la miopía no es progresiva y tampoco suele producir complicaciones. Los niños afectados de hipermetropía no suelen presentar déficit de agudeza visual, sino dolor de cabeza o cansancio relacionados con el esfuerzo continuado de acomodación que debe realizar el músculo ciliar para lograr un correcto enfoque. En los adultos suele existir déficit de visión cercana y con el paso de los años se puede afectar la lejana. Se trata mediante el uso de gafas correctoras.

Es un defecto de refracción que se produce debido a que existe diferente capacidad de refracción entre dos meridianos oculares y en consecuencia los objetos se ven desenfocados. Generalmente está originado por una curvatura irregular en la zona anterior de la córnea, de tal forma que la refracción del meridiano vertical es diferente a la del horizontal. Se trata mediante la utilización de gafas con lentes correctoras.

La presbicia también llamada "vista cansada", comienza alrededor de los 40 años y alcanza su máxima evolución después de los 60. Consiste en la pérdida progresiva y gradual de la elasticidad del cristalino que se manifiesta por dificultad para ver con claridad los objetos cercanos. Una persona con presbicia necesita alejar un texto más de 33 cm de los ojos para poder leer. A esa distancia muchos caracteres no se distinguen con claridad.

Para garantizar una buena visión de los objetos cercanos, el cristalino debe cambiar de forma y hacerse más esférico para aumentar su poder de refracción. C cuando ya no puede hacerlo, la visión cercana se hace borrosa. Sin embargo, la visión de lejos sigue siendo buena.

Puede corregirse con el uso de lentes oftálmicas, que realizan el trabajo de convergencia de las imágenes tal como lo hacían antes los ojos.
Cuando existe otro problema de visión añadido, como la miopía, pueden utilizarse lentes bifocales o multifocales que permiten ver de manera correcta a diferentes distancias, por ejemplo, para ver bien un monitor y un texto que está más próximo.

El daltonismo es un defecto del ojo. La persona que lo padece, presenta dificultad para distinguir el rojo y el verde, aunque hay casos en que también es difícil diferenciar otros colores. Cuando el defecto consiste en la imposibilidad de distinguir todos los colores, no es daltonismo, sino otro trastorno más grave que se llama acromatopsia.

El daltonismo es mucho más corriente en el varón que en la mujer y es hereditario. No suele causar otros trastornos, aunque constituye un problema en algunas profesiones que exigen una correcta visión de los colores.

La catarata es una opacidad del cristalino (la lente del ojo) que pierde su transparencia habitual. Como consecuencia la luz penetra con dificultad en el ojo, lo cual ocasiona pérdida de visión progresiva, que puede llegar a ser total, si no se realiza el tratamiento adecuado. Este consiste en una intervención quirúrgica mediante la cual se extirpa el cristalino y se coloca en su lugar una lente intraocular.

La catarata es generalmente degenerativa y aparece muy frecuentemente en personas de más de 50 años, aunque existen formas más raras que son congénitas (presentes en el nacimiento), algunas de las cuales se deben a que la madre sufrió una rubéola durante el embarazo, en este caso se denomina catarata rubeólica.

Según los datos de la Organización Mundial de la Salud, la catarata es la responsable del 48 % de los casos de ceguera en todo el mundo, lo cual supone 18 millones de personas.

Conjuntivitis es la inflamación de la conjuntiva (membrana mucosa que recubre el interior de los párpados de los vertebrados y se extiende a la parte anterior del ojo). Puede estar originada por muchas causas, entre las cuales la más frecuente es la infecciosa; pueden estar involucrados diferentes virus y bacterias. También existen conjuntivitis de origen alérgico, tóxicas por sustancias irritantes y actínicas por exposición a la luz o radiación ultravioleta.

Todos los casos presentan unas manifestaciones comunes: enrojecimiento, fotofobia y lagrimeo. Sin embargo otros síntomas dependen de la causa, secreciones matutinas en las bacterianas, ganglios aumentados de tamaño en las víricas, prurito estacional en las alérgicas, etc. La duración del cuadro es variable según el origen.

En general se trata de procesos benignos, aunque algunas formas pueden conducir a complicaciones como la queratitis (inflamación de la córnea) que a veces son graves.

El glaucoma es una enfermedad ocular causada por la elevación de la presión intraocular del ojo. La presión intraocular está determinada por el equilibrio entre la producción y reabsorción del humor acuoso. Si el canal por donde se drena el humor acuoso se obstruye, el líquido no se elimina y la presión intraocular aumenta en exceso.

El glaucoma es una afección que puede ser grave. Si no se trata a tiempo, puede generar la pérdida de la visión. Hay muchos medicamentos contraindicados cuando se padece glaucoma.




</doc>
<doc id="2052" url="https://es.wikipedia.org/wiki?curid=2052" title="Modelo OSI">
Modelo OSI

El modelo de interconexión de sistemas abiertos (ISO/IEC 7498-1), más conocido como “modelo OSI”, (en inglés, "Open System Interconnection") es un modelo de referencia para los protocolos de la red (no es una arquitectura de red), creado en el año 1980 por la Organización Internacional de Normalización . Se ha publicado desde 1983 por la Unión Internacional de Telecomunicaciones (UIT) y, desde 1984, la Organización Internacional de Normalización (ISO) también lo publicó con estándar. Su desarrollo comenzó en 1977.

Es un estándar que tiene por objetivo conseguir interconectar sistemas de procedencia distinta
para que estos pudieran intercambiar información sin ningún tipo de impedimentos debido a
los protocolos con los que estos operaban de forma propia según su fabricante.

A principios de 1980 el desarrollo de redes originó desorden en muchos sentidos. Se produjo un enorme crecimiento en la cantidad y tamaño de las redes. A medida que las empresas tomaron conciencia de las ventajas de usar tecnologías de conexión, las redes se agregaban o expandían a casi la misma velocidad a la que se introducían las nuevas tecnologías de red.

Para mediados de 1980, estas empresas comenzaron a sufrir las consecuencias de la rápida expansión. De la misma forma en que las personas que no hablan un mismo idioma tienen dificultades para comunicarse, las redes que utilizaban diferentes especificaciones e implementaciones no podían intercambiar información. El mismo problema surgía con las empresas que desarrollaban tecnologías de conexiones propietarias. Una tecnología es llamada «propietaria» cuando su implementación, (ya sea de software o hardware) está sujeta a un copyright. Esto supone que una empresa controla esta tecnología y las empresas que quieran utilizarla en sus sistemas tienen que pagar derechos por su uso. Las tecnologías de conexión que respetaban reglas propietarias en forma estricta no podían comunicarse con tecnologías que usaban reglas propietarias diferentes e incluso con las que usen reglas de conexión copyleft.

Para enfrentar el problema de incompatibilidad de redes, la ISO investigó modelos de conexión como la red de "Digital Equipment Corporation" (DECnet), la Arquitectura de Sistemas de Red ("Systems Network Architecture", SNA) y TCP/IP, a fin de encontrar un conjunto de reglas aplicables de forma general a todas las redes. Con base en esta investigación, la ISO desarrolló un modelo de red que ayuda a los fabricantes a crear redes que sean compatibles con otras redes.

Es un estándar desarrollado en 1980 por la ISO, una federación global de organizaciones que representa aproximadamente a 160 países. El núcleo de este estándar es el modelo de referencia OSI, una normativa formada por siete capas que define las diferentes fases por las que deben pasar los datos para viajar de un dispositivo a otro sobre una red de comunicaciones.

Siguiendo el esquema de este modelo se crearon numerosos protocolos. El advenimiento de protocolos más flexibles donde las capas no están tan desmarcadas y la correspondencia con los niveles no era tan clara puso a este esquema en un segundo plano. Sin embargo se usa en la enseñanza como una manera de mostrar cómo puede estructurarse una «pila» de protocolos de comunicaciones.

El modelo especifica el protocolo que debe usarse en cada capa, y suele hablarse de modelo de referencia ya que se usa como una gran herramienta para la enseñanza de comunicación de redes. 

Debe recordarse siempre que es un "modelo", una construcción teórica, por ende no tiene un correlato directo con el mundo real. Se trata de una normativa estandarizada útil debido a la existencia de muchas tecnologías, fabricantes y compañías dentro del mundo de las comunicaciones, y al estar en continua expansión, se tuvo que crear un método para que todos pudieran entenderse de algún modo, incluso cuando las tecnologías no coincidieran. De este modo, no importa la localización geográfica o el lenguaje utilizado- todo el mundo debe atenerse a unas normas mínimas para poder comunicarse entre sí. Esto es sobre todo importante cuando hablamos de la red de redes, es decir, Internet.

El modelo es el modelo de red descriptivo, que fue creado por la Organización internacional para la Estandarización en el año 1980. Reconoció que era necesario crear un modelo de red que pudiera ayudar a los diseñadores de red a implementar redes que pudieran comunicarse y trabajar en conjunto y por lo tanto, elaboraron el modelo de referencia OSI. El núcleo de este estándar es el modelo de referencia OSI, una normativa formada por siete capas que define las diferentes fases por las que deben pasar los datos para viajar de un dispositivo a otro sobre una red de comunicaciones. El modelo especifica el protocolo que debe ser usado en cada capa, y suele hablarse de modelo de referencia ya que es usado como una gran herramienta para la enseñanza de comunicación de redes.

Existen diversos protocolos de acuerdo a cómo se espera que sea la comunicación. Este conjunto de protocolos se denomina TCP/IP. TCP/IP se ha convertido en el estándar de-facto para la conexión en red corporativa. Las redes TCP/IP son ampliamente escalables, para lo que TCP/IP puede utilizarse tanto para redes pequeñas como grandes.

TCP/IP es un conjunto de protocolos encaminados que puede ejecutarse en distintas plataformas de software y casi todos los sistemas operativos de red lo soportan como protocolo de red predeterminado. Protocolos miembro de la pila TCP/IP. FTP, SMTP, UDP, IP, ARP TCP corre en varias capas del modelo OSI Protocolo de Internet Es un protocolo no orientado a conexión usado tanto por el origen como por el destino para la comunicación de datos a través de una red de paquetes conmutados. Los datos en una red basada en IP son enviados en bloques conocidos como paquetes o datagramas .

Capas del Modelo OSI Descripción Capa 7 Aplicación Responsable de los servicios de red para las aplicaciones Capa 6 Presentación Trasforma el formato de los datos y proporciona una interfaz estándar para la capa de aplicación Capa 5 Sesión Establece, administra y finaliza las conexiones entre las aplicaciones locales y las remotas Capa 4 Transporte Proporciona transporte confiable y control del flujo a través de la red Capa 3 Red Responsable del direccionamiento lógico y el dominio del enrutamiento Capa 2 Enlace de Datos Proporciona direccionamiento físico y procedimientos de acceso a medios Capa 1 Física Define todas las especificaciones eléctricas y físicas de los dispositivos

Difiere de las demás capas debido a que no proporciona servicios a ninguna otra capa OSI, sino solamente a aplicaciones que se encuentran fuera del modelo OSI. La capa de aplicación establece la disponibilidad de los potenciales socios de comunicación, sincroniza y establece acuerdos sobre los procedimientos de recuperación de errores y control de la integridad de los datos. Esta garantiza que la información que envía la capa de aplicación de un sistema pueda ser leída por la capa de aplicación de otro. De ser necesario, la capa de presentación traduce entre varios formatos de datos utilizando un formato común.

Su objetivo es encargarse de la representación de la información, de manera que aunque distintos equipos puedan tener diferentes representaciones internas de caracteres números, sonido o imágenes, los datos lleguen de manera reconocibles. Esta capa es la primera en trabajar más el contenido de la comunicación que en como se establece la misma. En ella se tratan aspectos tales como la semántica y la sintaxis de los datos transmitidos, ya que distintas computadoras pueden tener diferentes formas de manejarlas. Por lo tanto, podemos resumir definiendo a esta capa como la encargada de manejar las estructuras de datos abstractas y realizar las conversiones de representación de datos necesarias para la correcta interpretación de los mismos.

Esta capa también permite cifrar los datos y comprimirlos. Como su nombre lo implica, la capa de sesión establece, administra y finaliza las sesiones entre dos hosts que se están comunicando. La capa de sesión proporciona sus servicios a la capa de presentación. También sincroniza el diálogo entre las capas de presentación de los dos hosts y administra su intercambio de datos.

Además de regular la sesión, la capa de sesión ofrece disposiciones para una eficiente transferencia de datos, clase de servicio y un registro de excepciones acerca de los problemas de la capa de sesión, presentación y aplicación. Pero este protocolo debe transportarse entre máquinas a través de otros protocolos. Con SAP, los servidores permiten a los enrutadores crear y mantener una base de datos con la información actualizada de los servidores de la interred. La capa de transporte segmenta los datos originados en el host emisor y los reensambla en una corriente de datos dentro del sistema del host receptor.

El límite entre la capa de transporte y la capa de sesión puede imaginarse como el límite entre los protocolos de aplicación y los protocolos de flujo de datos. Mientras que las capas de aplicación, presentación y sesión están relacionadas con asuntos de aplicaciones, las cuatro capas inferiores se encargan del transporte de datos. TCP crea conexiones a través de las cuales puede enviar flujos de datos. El protocolo garantiza que los datos serán entregados en su destino sin errores y en el mismo orden en que se transmitieron.

Su misión es conseguir que los datos lleguen desde el origen al destino aunque no tengan conexión directa. IPX/SPX Es una familia de protocolos de red desarrollados por novell y utilizado por su sistema operativo de red netware. El IPX Es un protocolo de datagramas rápido orientados a comunicaciones sin conexión que se encarga de transmitir datos a través de la red, incluyendo en cada paquete la dirección de destino. La capa de enlace de datos proporciona tránsito de datos confiable a través de un enlace físico.

Al hacerlo, la capa de enlace de datos se ocupa del direccionamiento físico , la topología de red, el acceso a la red, la notificación de errores, entrega ordenada de tramas y control de flujo. Ethernet define las características de cableado y señalización de nivel físico y los formatos de tramas de datos del nivel de enlace de datos. FDDI Proporciona un 100 Mbits/s óptico estándar para la transmisión de datos en una red de área local. La capa física define las especificaciones eléctricas, mecánicas, de procedimiento y funcionales para activar, mantener y desactivar el enlace físico entre sistemas finales.

Las características tales como niveles de voltaje, temporización de cambios de voltaje, velocidad de datos físicos, distancias de transmisión máximas, conectores físicos y otros atributos similares son definidos por las especificaciones de la capa física. Bluetooth es una especificación industrial para Redes Inalámbricas de Área Personal que posibilita la transmisión de voz y datos entre diferentes dispositivos. ADSL Consiste en una transmisión analógica de datos digitales apoyado en el par simétrico de cobre que lleva la línea telefónica convencional. USB Es un estándar industrial desarrollado en los años 1990 que define los cables, conectores y protocolos usados en un bus para conectar , comunicar y proveer de alimentación eléctrica entre ordenadores, periféricos y dispositivos electrónicos.

Consiste en una transmisión analógica de datos digitales apoyada en el par simétrico de cobre que lleva la línea telefónica convencional.

La recomendación X.22 describe un modelo de siete capas o niveles numeradas del 1 al 7 siendo la 1 la más baja.
Es la capa más baja del modelo OSI. Es la que se encarga de la topología de red y de las conexiones globales de la computadora hacia la red, se refiere tanto al medio físico como a la forma en la que se transmite la información y de las redes.

Sus principales funciones se pueden resumir como:

Esta capa se ocupa del direccionamiento físico, del acceso al medio, de la detección de errores, de la distribución ordenada de tramas y del control del flujo.
Es uno de los aspectos más importantes que revisar en el momento de conectar dos ordenadores, ya que está entre la capa 1 y 3 como parte esencial para la creación de sus protocolos básicos (MAC, IP), para regular la forma de la conexión entre computadoras, determinando el paso de tramas (unidad de medida de la información en esta capa, que no es más que la segmentación de los datos trasladándolos por medio de paquetes), verificando su integridad, y corrigiendo errores.

Por lo cual es importante mantener una excelente adecuación al medio físico (los más usados son el cable UTP, par trenzado o de 8 hilos), con el medio de red que redirige las conexiones mediante un enrutador.

Dadas estas situaciones cabe recalcar que el dispositivo que usa la capa de enlace es el Switch que se encarga de recibir los datos del enrutador y enviar cada uno de estos a sus respectivos destinatarios (servidor -> computador cliente o algún otro dispositivo que reciba información como teléfonos móviles, tabletas y diferentes dispositivos con acceso a la red, etc.), dada esta situación se determina como el medio que se encarga de la corrección de errores, manejo de tramas, protocolización de datos (se llaman protocolos a las "reglas de cortesía" o convenciones que debe seguir cualquier capa del modelo OSI).

Se encarga de identificar el enrutamiento existente entre una o más redes. Las unidades de datos se denominan paquetes, y se pueden clasificar en protocolos enrutables y protocolos de enrutamiento.


El objetivo de la capa de red es hacer que los datos lleguen desde el origen al destino, aun cuando ambos no estén conectados directamente sino que utilicen dispositivos intermedios. Los dispositivos que facilitan tal tarea se denominan encaminadores o enrutadores, aunque es más frecuente encontrarlo con el nombre en inglés "routers". Los "routers" trabajan en esta capa, aunque pueden actuar como "switch" de nivel 2 en determinados casos, dependiendo de la función que se le asigne. Los "firewalls" actúan sobre esta capa principalmente, para descartar direcciones de determinadas máquinas o limitar el acceso a ciertas de ellas.

En este nivel se realiza el direccionamiento lógico y la determinación de la ruta de los datos hasta su receptor final.

Capa encargada de efectuar el transporte de los datos (que se encuentran dentro del paquete) de la máquina origen a la de destino, independientemente del tipo de red física que esté utilizando.

La PDU (unidad de información) de la capa 4 se llama Segmento o Datagrama, dependiendo de si corresponde a TCP o UDP, el primero orientado a conexión (transmisión verificada, eventualmente retransmitida) y el otro sin conexión (pueden perderse algunos datos por el camino). Trabajan, por lo tanto, con puertos lógicos y junto con la capa red dan forma a los conocidos como Sockets IP:Puerto (ejemplo: 191.16.200.54:80).

Esta capa es la que se encarga de mantener y controlar el enlace establecido entre dos computadores que están transmitiendo datos de cualquier índole. Por lo tanto, el servicio provisto por esta capa es la capacidad de asegurar que, dada una sesión establecida entre dos máquinas, la misma se pueda efectuar para las operaciones definidas de principio a fin, reanudándolas en caso de interrupción. En muchos casos, los servicios de la capa de sesión son parcial o totalmente prescindibles.

El objetivo es encargarse de la "representación" de la información, de manera que, aunque distintos equipos puedan tener diferentes representaciones internas de caracteres, los datos lleguen de manera reconocible.

Esta capa es la primera en trabajar más el contenido de la comunicación que el cómo se establece la misma. En ella se tratan aspectos tales como la semántica y la sintaxis de los datos transmitidos, ya que distintas computadoras pueden tener diferentes formas de manejarlas. Por ejemplo, un mismo sitio web puede adecuar la presentación de sus datos según se acceda desde un computador convencional, una "tableta," o un teléfono inteligente. 

Esta capa también permite cifrar los datos y comprimirlos. Por lo tanto, podría decirse que esta capa actúa como un traductor.

Ofrece a las aplicaciones la posibilidad de acceder a los servicios de las demás capas y define los protocolos que utilizan las aplicaciones para intercambiar datos, como correo electrónico (Post Office Protocol y SMTP), gestores de bases de datos y servidor de ficheros (FTP). Hay tantos protocolos como aplicaciones distintas y puesto que continuamente se desarrollan nuevas aplicaciones el número de protocolos crece sin parar.

Cabe aclarar que el usuario normalmente "no interactúa directamente" con el nivel de aplicación. Suele interactuar con programas que a su vez interactúan con el nivel de aplicación pero ocultando la complejidad subyacente.

A fin de facilitar el aprendizaje y memorización de los nombres de las capas que componen el modelo; una regla sencilla consiste en memorizarlas como una sigla nemotécnica: FERTSPA, que en inglés sonaría como "First Spa", primer spa en castellano, el cual se define de la siguiente manera:

El intercambio de información entre dos capas OSI consiste en que cada capa en el sistema fuente le agrega información de control a los datos, y cada capa en el sistema de destino analiza y quita la información de control de los datos como sigue:

Si una computadora (A) desea enviar datos a otra (B), en primer término los datos deben empaquetarse a través de un proceso denominado encapsulamiento, es decir, a medida que los datos se desplazan a través de las capas del modelo OSI, reciben encabezados, información final y otros tipos de información.

La unidad de datos de protocolo (N-PDU) es la información intercambiada entre entidades pares, es decir, dos entidades pertenecientes a la misma capa pero en dos sistemas diferentes, utilizando una conexión codice_1. Está compuesta por:

La Unidad de Datos de Interfaz (N-IDU): es la información transferida entre dos niveles adyacentes, es decir, dos capas contiguas. Está compuesta por:

La capa de aplicación recibe el mensaje del usuario y le añade una cabecera constituyendo así la PDU de la capa de aplicación. La PDU se transfiere a la capa de aplicación del modo destino, este elimina la cabecera y entrega el mensaje al usuario.

Para ello ha sido necesario todo este proceso:

Otros datos reciben una serie de nombres y formatos específicos en función de la capa en la que se encuentren, debido a como se describió anteriormente la adhesión de una serie de encabezados e información final.
Los formatos de información son los que muestra el gráfico:


En determinadas situaciones es necesario realizar una serie de operaciones sobre las PDU y así facilitar su transporte, debido a que son demasiado grandes o bien porque son demasiado pequeñas y estaríamos desaprovechando la capacidad del enlace.

El bloqueo hace corresponder varias codice_11 en una codice_12.

El desbloqueo identifica varias codice_11 que están contenidas en una codice_12.

La concatenación es una codice_15 que realiza el codice_16 y que hace corresponder varias codice_17 en una sola codice_18.

La separación identifica varias codice_17 que están contenidas en una sola codice_18.

Las redes permiten la comunicación entre computadoras y otros dispositivos "inteligentes" como tabletas y teléfonos, pero también son el principal medio por el que estos dispositivos son infectados con virus o son atacados para robar información. Los entornos de red seguros son una necesidad cada vez mayor. El modelo OSI facilita la clasificación de los diferentes ataques conocidos y las acciones que permiten evitarlos o al menos mitigar sus consecuencias. 




</doc>
<doc id="2054" url="https://es.wikipedia.org/wiki?curid=2054" title="Oceanía">
Oceanía

Oceanía es un continente insular de la Tierra constituido por la plataforma continental de Australia, las islas de Nueva Guinea, Nueva Zelanda y los archipiélagos coralinos y volcánicos de Melanesia, Micronesia y Polinesia. Históricamente se consideró que Insulindia también formaba parte de Oceanía. Todas estas islas están distribuidas por el océano Pacífico. Con una extensión de 8 542 499 km², se trata del continente más pequeño del planeta Tierra.

En otros modelos continentales, en particular en los de habla inglesa, se usa Australia en lugar de Oceanía, pero en este caso su definición no incluye las . En los de habla portuguesa se considera que el límite entre Asia y Oceanía es la Línea de Wallace, por lo que Timor Oriental es parte de Oceanía. Otros van más allá y consideran que toda Insulindia es parte de Oceanía. Inversamente, en otros modelos se utiliza el término de Oceanía para designar el conjunto de todas las islas del Océano Pacífico.

El término fue acuñado por el geógrafo francés Conrad Malte-Brun en 1812 como "Océanie", proveniente de "océan" (océano en francés) el cual, a su vez, deriva del griego antiguo "Ōkeanós" (Ώκεανός), combinado con el sufijo en latín -ia , basado en su cognado del griego antiguo -ία, -εια que se usa para designar sustantivos femeninos abstractos. El significado de su nombre se basa en el hecho que su territorio está compuesto por miles de pequeñas islas esparcidas en el océano más grande del planeta.

Los primeros pobladores humanos de Oceanía procedían del Sudeste de Asia. De ellos descienden los actuales papúes y nativos australianos, los cuales probablemente debieron alcanzar al continente Sahul usando balsas primitivas. Los restos fósiles más antiguos podrían ser los del hombre de Mungo en Nueva Gales del Sur (Australia), con unos 42 000 años de antigüedad, así como los restos arqueológicos de Bobongara en la península de Huon (Papúa Nueva Guinea), con unos 40 000 años. Por otro lado, las pruebas arqueológicas del uso de plantas en las montañas de Nueva Guinea y las pruebas genéticas poblacionales en nativos australianos y papúes, coinciden en que el poblamiento de Sahul debió llevarse a cabo hace unos 46 000 años. 

Hace 33 mil años se habría colonizado la isla de Nueva Irlanda (Melanesia) y hace 28 mil años la isla Buka (Islas Salomón del Norte). Hace 18 mil años Nueva Guinea y Australia formaba una única masa de tierra poblada por seres humanos, posteriormente la subida del nivel del mar aisló a las poblaciones en tres grupos: Nueva Guinea, Australia y Tasmania (además de algunas pocas islas menores). Dichas poblaciones evolucionaron separadamente bajo condiciones ecológicas divergentes y desarrollaron patrones culturales independientes.

Se han encontrado pruebas de la aparición de la agricultura hace unos 10 mil años, así como especialmente hace 7 mil, como se observa en las montañas de Nueva Guinea, donde se habría cultivado el tubérculo taro, calabazas y bananas.

La siguiente oleada migratoria humana fue la de los austronesios, también de origen asiático y provenientes de Insulindia. Esta presencia austronesia en Oceanía está testimoniada arqueológicamente ya en el milenio II a. C., cuando ocupaba básicamente regiones dentro de Melanesia. El archipiélago Bismarck fue colonizado entre 1300 y 1500 a. C. por pueblos austronesios alfareros (ceramistas), pescadores y agricultores; produciéndose una expansión progresiva por todo Oceanía, de tal manera que ya habrían alcanzado Hawái y Nueva Zelanda durante el primer milenio d. C.; y la última isla importante en ser colonizada fue la Isla de Pascua en el segundo milenio.

En el 950 d. C. el Imperio Tu'i Tonga dominó la mayoría de las islas de Oceanía. En sus comienzos los reyes lograron deshacerse del dominio extranjero y consolidar el poder del imperio en lo que hoy es Tonga. Cerca al año 1200 comenzó su expansión hasta, aproximadamente, el 1500. El imperio conquistó lo que hoy en día se conoce como Fiyi, partes de Samoa y otras islas de la polinesia como las Islas Cook y Niue. La gran habilidad para construir canoas y el buen sistema aplicado a las invasiones facilitó que Tu'i Tonga se estableciera en más islas aún.

Hacia el año 1500 se desataron muchos problemas en la realeza del imperio, que debilitó su figura en las colonias, que consiguieron mucha autonomía de la corona real y el poder central. En 1799 fue asesinado Tuku'aho, el rey que poseía el poder en ese momento, lo que desató una terrible guerra civil. Ya con la presencia europea, la guerra civil terminó de devastar a los dos bandos, dejando al imperio diezmado en manos de la corona británica.

Los españoles fueron los primeros en cruzar el océano Pacífico y las islas de Oceanía. La expedición de Fernando de Magallanes descubrió las Marianas en 1521 y otras islas del Pacífico. Tras la muerte de Magallanes en Filipinas, Juan Sebastián Elcano tomó el mando de la expedición, que acabaría circunnavegando el mundo. Poco después exploraron la región los portugueses: en 1525 descubrieron las Carolinas y, al año siguiente, Nueva Guinea. Entre 1525 y 1527 varias expediciones españolas descubrieron las Islas Marshall y las Islas del Almirantazgo y en 1568 las Islas Tuvalu, las Islas Salomón y la Isla de Wake. En 1595 otra expedición española descubrió las Marquesas y las Cook. En 1606, la expedición española de Quirós descubrió las Islas Pitcairn y las Nuevas Hebridas, cuya isla principal bautizaron con el nombre de "La Australia del Espíritu Santo", creyendo que habían llegado a la Terra Australis. A pesar de encontrarse en las Nuevas Hebridas, el nombre "Australia" ha perdurado hasta nuestros días para referirse a esa gran isla. Los neerlandeses recorrieron en 1642 el litoral de Australia y descubrieron Tasmania, las islas Tonga, Fiyi y Bismark. Mientras, durante dos siglos y medio, la ruta española del Galeón de Manila recorrió el Pacífico en ambas direcciones, uniendo los puertos de Acapulco y Manila entre 1565 y 1815.

En el siglo XVIII británicos y franceses se sumaron a la exploración de Oceanía. Entre 1764 y 1770, los británicos recorrieron Tahití, Samoa, Salomón y Nuevas Hébridas. Entre 1772 y 1774, navegantes españoles llegaron a Tahití y descubrieron varias islas del archipiélago de las Tuamotu. Entre 1768 y 1779, navegantes ingleses también llegaron a las islas de la Sociedad, a Nueva Zelanda, las Marquesas, Nuevas Hébridas y Hawái. Los franceses exploraron las islas paralelamente a los británicos. Todos estos viajes determinaron el posterior reparto de Oceanía entre Gran Bretaña y Francia, así como España que llevaba varios siglos en Filipinas y las Marianas.

En 1831, Jules Dumont d'Urville dividió las islas de Oceanía en Melanesia, Micronesia, Insulindia y Polinesia, las cuales conforman, conjuntamente con Australia, la división tradicional del continente.

A finales del siglo XIX y comienzos del XX comenzaron los deseos de independencia en las colonias británicas de Australia y Nueva Zelanda que, en 1901 y en 1907 respectivamente, abrieron el camino a los demás países hacia la independencia.

Los países más débiles y pobres solo pudieron declararse independientes durante la segunda mitad del siglo XX. En 1962, Samoa declaró su independencia de Nueva Zelanda, que la había ocupado años atrás; luego siguieron Nauru en 1968, Fiyi y Tonga en 1970, las Islas Salomón y Tuvalu en 1978, los Estados Federados de Micronesia y Kiribati en 1979 (aunque reconocida en 1990 para Micronesia), Vanuatu en 1980, las Islas Marshall en 1990 y Palaos en 1994 los siguieron en el proceso de libertad.

Estas naciones formaron el Foro de las Islas del Pacífico para intentar ayudar a países que aún están bajo el mandato de potencias, como Guam, en poder de los Estados Unidos, y Nueva Caledonia y Polinesia Francesa, ambas en poder de Francia.

El término Oceanía cubre una región macro-geográfica situada entre Asia y América, con Australia continental como la masa principal del continente, seguida por las mucho menores y cercanas islas de Nueva Guinea, Tasmania y Nueva Zelanda, a las que se suman unas 25 000 pequeñas islas dispersas en el Pacífico.

Los territorios de Oceanía se extienden desde el sureste de Asia por el océano Pacífico hacia América. Con su extensión de 9 800 458 km² es el continente más pequeño del mundo. Está bañada por los océanos Índico y Pacífico, con un total de 25 760 km de costas y posee la , Nueva Guinea, con 785 753 km². El clima está fuertemente influenciado por las corrientes oceánicas, incluyendo El Niño, el cual causa sequías periódicas, y el sistema estacional tropical de baja presión, que produce ciclones en el norte de Australia.

La región desértica o semiárida es la de mayor extensión: un 40% de su territorio está cubierto por dunas de arena. Oceanía es el continente más seco, más plano, con los terrenos de mayor antigüedad y los menos fértiles. Curiosamente, la montaña más alta del continente, el Monte Jaya (4884 m), no se halla en Australia, sino que se encuentra en la isla de Nueva Guinea, perteneciendo a Indonesia. El Monte Kosciuszko, con 2228 m, es la principal elevación de Oceanía continental.

Los puntos geográficos extremos de Oceanía son los siguientes:

Oceanía está compuesto por 14 naciones independientes, 14 dependencias (de países como Estados Unidos, Reino Unido, Francia, Nueva Zelanda y Australia) y 5 territorios integrados en otras naciones no oceánicas como Estados Unidos, Chile e Indonesia. Desde la llegada de los colonizadores europeos, Oceanía estuvo dividida en una serie de territorios dependientes, los que comenzaron a alcanzar su autonomía solo a partir de mediados del siglo XX, a excepción de Australia y Nueva Zelanda, que lo hicieron en 1901 y 1907 respectivamente.

Los estados de Oceanía se hallan plenamente integrados en la ONU, siendo Australia y Nueva Zelanda países fundadores de dicha organización. De las dependencias, seis de ellas (Tokelau, Polinesia Francesa, Samoa Americana, Pitcairn, Nueva Caledonia y Guam) están incluidas en la lista del Comité de Descolonización de la ONU.

En materia económica, ocho estados son miembros de la Organización Mundial del Comercio (Australia, Fiyi, Nueva Zelanda, Papúa Nueva Guinea, Samoa, Islas Salomón, Tonga y Vanuatu) mientras que otros seis no forman parte de la organización (Kiribati, Islas Marshall, Estados Federados de Micronesia, Nauru, Palau y Tuvalu). Así mismo, la totalidad del continente se incluye en el Fondo Monetario Internacional.

En materia de justicia y seguridad tan solo 8 países oceánicos están integrados en la INTERPOL (Australia, Fiyi, Nauru, Nueva Zelanda, Islas Marshall, Samoa, Papúa Nueva Guinea, Tonga). En el caso de la Justicia internacional seis países no han firmado ni ratificado el Estatuto de Roma de la Corte Penal Internacional. Mientras que las Islas Salomón han firmado que aún no lo han ratificado. En el resto de países acepta la jurisdicción del Corte Penal Internacional para juzgar casos de crímenes contra la humanidad.

Son tres estados oceánicos (Fiyi, Papúa Nueva Guinea y Vanuatu) los que están adscritos al Movimiento de Países No Alineados.

El peso de las relaciones internacionales en la zona lo llevan Australia y Nueva Zelanda; es por ello que en la mayoría de las organizaciones transcontinentales ambas naciones son miembros. Así, Australia (1971) y Nueva Zelanda (1973) están presentes en la Organización para la Cooperación y el Desarrollo Económicos (1960), en el Plan Colombo (1950) para el desarrollo local junto a Fiyi y Papúa Nueva Guinea. La Asociación ribereña del Océano Índico para la cooperación regional (1995) de cooperación entre países asiáticos, africanos y Australia. Y finalmente, en el Foro de Cooperación Económica Asia-Pacífico (1989) junto con Papúa Nueva Guinea, que entró en 1994.

En 1975 se creó Estados de África, del Caribe y del Pacífico (ACP) para, a través de varios acuerdos (el más reciente Acuerdo de Cotonú del año 2000) luchar contra la pobreza junto a la Unión Europea, que trabaja por medio del Fondo Europeo de Desarrollo. Forman parte de esta organización todos los estados oceánicos salvo Australia y Nueva Zelanda, además de los territorios libres asociados de las Islas Cook y Niue. 

A nivel regional el Foro de las Islas del Pacífico es la principal organización. Los miembros plenos son los 14 países independientes, además de dos estados asociados libremente a Nueva Zelanda: las Islas Cook y Niue; y 2 dependencias de Francia: Nueva Caledonia y Polinesia Francesa. Una dependencia como miembro asociado, Tokelau, y también admite como observadores a los países en proceso de descolonización: Samoa Americana, Guam, Wallis y Futuna, Islas Marianas del Norte y un país asiático, Timor Oriental.

Creó la figura de los «dialogue partners» (Canadá, China, la Unión Europea, Francia, Gran Bretaña, Japón, Corea del Sur, Malasia, Filipinas, Estados Unidos y Tailandia) y mantiene también reuniones separadas de sus ministros de asuntos económicos.

Uno de sus objetivos principales es promover la integración de los territorios de la región, pero también la búsqueda de soluciones para problemas comunes, tales como la seguridad, la pesca o el medio ambiente. La Declaración de Biketawa, firmada en octubre de 2000 pertenecientes al PIF, en donde se preveían mecanismos para que sus miembros intervinieran en los asuntos internos de otros «en tiempos de crisis» fue un paso crucial en el proceso de integración, que ha servido para allanar el envío de la RAMSI y para legitimar su éxito.

Existen otras organizaciones como el Grupo Melanesio Punta de Lanza (1986) que incluye 4 estados (Fiyi, Papúa Nueva Guinea, Islas Salomón y Vanuatu) además de dos partidos políticos pro independencia de sus respectivos territorios, el Movimiento Papúa Libre (Papúa Occidental de Indonesia) y el Frente Socialista de Liberación Nacional Canaco de Nueva Caledonia (colectividad sui generis de Francia). También hay dos organizaciones formadas por todos los estados independientes, dependientes y sus metrópolis (Estados Unidos, Reino Unido y Francia). La primera preocupada por el cambio climático como el Programa de Medio Ambiente Regional del Pacífico (1993) y la segunda la Comunidad del Pacífico (1947) con objetivos científicos y tecnológicos.

Finalmente debemos mencionar la organización militar más importante de la región, el ANZUS (1951), acuerdo firmado entre Australia, Nueva Zelanda y Estados Unidos. El establecimiento de una alianza de este tipo en el sur del Pacífico respondía a una dinámica de bipolaridad en la que Estados Unidos quería garantizar una zona de influencia más allá del territorio en el cual es capaz de influir, y cuya presencia, cercana a la de la Unión Soviética, actuaba como disuasivo de un posible ataque nuclear.

Datos de superficie y población consultados en  actualizados 1 junio de 2016.

Son territorios dependientes de otra potencia en materias como política exterior, defensa o relaciones comerciales. Algunos de estos territorios están incluidos en el Comité de descolonización de la ONU, como Samoa Americana, la Polinesia francesa, Guam, Nueva Caledonia, Islas Pitcairn y Tokelau. Los territorios dependientes de los estados europeos (Reino Unido y Francia) son países y territorios de ultramar (o PTU) son las dependencias y territorios de ultramar de los Estados miembros de la Unión Europea que no forman parte de la Unión, sino que tiene un estatuto de asociados a los Estados miembros desde el Tratado de Lisboa.

Datos de superficie y población consultados en The World factbook  actualizados 1 junio de 2016.

Datos de superficie y población consultados en The World factbook  actualizados 1 junio de 2016.

La definición exacta de qué territorios pertenecen al continente es muy variada:
Oceanía se divide cultural y tradicionalmente en cuatro regiones: Australia, que posee dimensiones continentales, y los archipiélagos de las , ubicadas en las regiones de Melanesia, Micronesia y Polinesia, las cuales siempre se incluyen en Oceanía. Esta división viene de inicios del siglo XIX y fue postulada por exploradores franceses basados en aspectos culturales, étnicos y lingüísticos. Inicialmente, D'Urville incluyó a Australia en Melanesia.

Oceanía se divide políticamente de acuerdo a las fronteras nacionales. En este sentido, la frontera entre Oceanía y Asia vendría a coincidir con la frontera entre los países de Indonesia y Papúa Nueva Guinea. Según el Geoesquema de las Naciones Unidas para Oceanía, los países de Oceanía se agrupan en las regiones Melanesia, Micronesia y Polinesia, además de la región de Australia y Nueva Zelanda, esta última a veces llamada Australasia.

Oceanía se extiende principalmente sobre dos grandes placas tectónicas: el territorio ubicado dentro de la placa Australiana que, además de Australia, incluye la isla de Tasmania, el norte de Nueva Zelanda y el sur de la isla de Nueva Guinea; y la gran placa Pacífica, que se extiende por gran parte el resto de Oceanía.

El territorio del Este de Indonesia situado dentro de la Placa Australiana y constituido por el sur de Nueva Guinea Occidental y otras islas más pequeñas, geológicamente son parte de Oceanía. Otras placas menores que conforman Oceanía son: Placa de Kermadec, Placa de Tonga, Placa del Arrecife de Conway, Placa de Timor, Placa Woodlark, Placa del Mar de Banda, Placa de las Carolinas, Placa del Mar de las Molucas, Placa de Maoke, Placa Cabeza de Pájaro, entre otras.











Son pocos los países de Oceanía que gozan de libertad de expresión y sufragio universal. Solo Australia y Nueva Zelanda poseen gobiernos democráticos que pueden mantenerse a lo largo de los años, a pesar de que en Samoa, Vanuatu y Tonga los gobiernos también se encuentran bastantes consolidados.

En los demás países independientes o con deseos de serlo se viven momentos de irregularidad política, Fiyi sufrió un golpe de estado en 2006 y por esa razón fue expulsado de la Mancomunidad de Naciones, en Nueva Caledonia y, en menor medida, en la Polinesia Francesa se sufren tensiones por los deseos de la población nativa de declarar la independencia de Francia, Papúa Nueva Guinea posee un gobierno nacional muy débil, amenazado constantemente. Algo parecido ocurre en Islas Salomón.

Otros países no han tenido más elección que "someterse" a un país más poderoso, debido a que no pueden mantenerse económicamente de forma autónoma. Niue, Islas Cook y Tokelau firmaron un tratado de libre asociación con Nueva Zelanda. La Polinesia Francesa, Wallis y Futuna y Nueva Caledonia son estados dependientes de Francia. En la Micronesia la situación de los estados es muy mala. Todos poseen economías débiles y por lo tanto están muy influenciados por Estados Unidos, que domina la mayoría de los países de la región. Porque aunque no los domine políticamente, posee mucho poder sobre la economía de estos países en vías de desarrollo.

El peso de Oceanía en la economía mundial es muy escaso, apenas aporta tan solo el 1 % de la producción total.

Australia y Nueva Zelanda tienen una economía diversificada y muy desarrollada. Aunque hoy en día la mayor parte de la población trabaja en los servicios, el sector primario sigue siendo clave y proporciona una buena parte de las exportaciones.

Ambos países concentran el 40 % del ovino mundial, son los principales productores de lana y aportan más de un tercio de la producción mundial.

En Australia la actividad industrial ha experimentado un fuerte crecimiento en las últimas décadas, principalmente la industria pesada y la industria química; en su mayor parte, gracias a los importantes yacimientos mineros.
Por su parte, Nueva Zelanda posee numerosos lagos, utilizados para la producción de energía hidroeléctrica, lo que ha favorecido el desarrollo de diversas industrias básicas.

Dos tercios de la producción de Australia y Nueva Zelanda es insertada en los mercados asiáticos.

En los demás países del Pacífico, consiste en una economía rudimentaria y de autoabastecimiento.
En las islas volcánicas se practica la agricultura. En estas islas se hallan distintas especies tropicales.

El producto más importante que se exporta es la palmera cocotera, hay también ananás, arroz, bananas, caña de azúcar y la llamada «fruta del árbol del pan».

Otra actividad importante es la minera, hay reservas de oro en Papúa Nueva Guinea y níquel y hierro en Nueva Caledonia. En el océano Pacífico se hallan nódulos polimetálicos, que en algunas zonas son trabajados para la obtención de metales.

Una fuente de ingresos importantes es el turismo. Tahití y Fiyi son algunos países que subsisten principalmente con la industria del turismo. Es explotada por grandes industrias que construyen hoteles muy exóticos y consiguen cruceros y aviones para atraer al turismo mundial.

La pesca es también una actividad importante, especialmente en los países pequeños, como Wallis y Futuna, Nauru, Niue y las Islas Marshall.

Esta región es la menos poblada del mundo (con excepción de la Antártida) con aproximadamente 34 300 000 habitantes en el año 2010, esta cifra ha aumentado considerablemente debido a la alta natalidad y la baja mortalidad de Oceanía. La tasa de natalidad oceánica es de 21 % y la tasa de mortalidad del 9 %. La esperanza de vida promedio es de 70 años.

La densidad de población subió de 2,8 habitantes por km cuadrado a 3,4 habitantes por km cuadrado.

La mayoría de la población se concentra en Australia, Nueva Zelanda y Papúa Nueva Guinea, siendo el 92,1 % de la población de Oceanía. El resto de la población se divide en los demás países insulares del continente de Micronesia, Melanesia y Polinesia.

La población es heterogénea, gran parte de la población se concentra en grupos étnicos nativos de la Polinesia, Micronesia y Melanesia. Otra gran parte de las personas que viven en el continente son descendientes de los primeros colonizadores europeos, principalmente de ascendencias británica, irlandesa, alemana, neerlandesa, francesa y una pequeña parte desciende de españoles. Otro grupo étnico es el asiático, que a pesar de representar un bajo porcentaje del total, es el tercer grupo étnico más común de Oceanía. Esto se podría explicar debido a la gran cantidad de inmigrantes asiáticos, especialmente de Indochina, que recibe el continente desde hace ya muchos años.

En Nueva Zelanda, el censo de 2018, determinó que el 71,8 % de la población neozelandesa es étnicamente europea, mientras que tan solo el 16,5 % era maorí (un grupo nativo de Oceanía, el principal de Nueva Zelanda) y que el 15,3 % era asiático. En Australia los descendientes de europeos son el 78 % de la población, mientras los desencuentros de nativos representan solo 2,8 % de la población total australiana, el porcentaje más bajo de nativos oceánicos de los países del continente.

En otros países como Papúa Nueva Guinea, Vanuatu, las Islas Salomón, Palaos, Fiyi, Samoa y Tonga, la mayoría de la población es descendente de tribus nativas de Micronesia, Melanesia y Polinesia, mientras que los descendentes de asiáticos y europeos representan una pequeña parte de la población total de estos pequeños países. Aunque la cantidad de personas relacionadas con la etnia asiática sigue creciendo, la etnia europea sigue siendo la segunda con más presencia en los países más pequeños de Oceanía.

Por número de personas las cuatro lenguas con mayor número de hablantes nativos en Oceanía son el inglés, el tok pisin, el francés y el hindi de Fiyi, las cuatro son lenguas con origen alóctono (autóctono de la región). Las lenguas nativas con mayor número de hablantes son el samoano, el fiyiano (austronesios) y el enga (papú).

La lengua más utilizada es el inglés, seguido del tok pisin (criollo) y del francés.

En algunas islas, principalmente en la Isla de Pascua (Rapa Nui), bajo soberanía chilena, se habla el español. Minoritariamente se habla también en las islas estadounidenses de Guam y las Islas Marianas del Norte, y ha influido notoriamente en el idioma chamorro, hablado por los indígenas de ambos países. Existen también otras lenguas criollas locales de influencia española, que son habladas en Micronesia y Palaos, ambos países que forman parte del archipiélago de las Carolinas.

Además, el Portugués también es hablado en esa región, debido principalmente a la cantidad de hablantes en Timor Oriental.

En Oceanía se hablan más de 1500 lenguas, cuya clasificación presenta aún bastantes dudas (especialmente en lo referente a las lenguas de origen pre-austronesio). A grandes rasgos se pueden diferenciar tres grupos:


Las primeras poblaciones de Australia y Nueva Guinea proceden de las primeras migraciones de la humanidad (proceso que se había iniciado en África). Cuando los primeros seres humanos poblaron esos territorios ambos formaban parte de una única masa de tierra, llamada Sahul, que incluía también a Tasmania. Estos hechos llevaron a Joseph Greenberg a especular sobre un origen común de las lenguas de estos territorios, que se denomina hipótesis indopacífica, que incluiría además el tasmanio (ya extinguido) y las lenguas andamanesas. Sin embargo, la enorme diversidad de estas lenguas y la escasa evidencia disponible para dichas hipótesis hacen que los dos últimos grupos sólo se consideren agrupaciones geográficas útiles, pero no grupos lingüísticos filogenéticos genuinos.

Las lenguas austronesias de Oceanía fueron divididas inicialmente según un criterio geográfico: Melanesia, Polinesia, Micronesia y Nueva Zelanda, sin embargo, estas divisiones no representan agrupaciones lingüísticas adecuadas (ver lenguas oceánicas). Las lenguas polinesias, de Fiyi y las lenguas micronesias parecen formar un grupo filogenético dentro de las lenguas oceánicas centro-orientales, mientras que las lenguas de Melanesia y otras áreas forman parte de diferentes familias oceánicas y por tanto no forman ningún grupo filogenético válido. Dentro de las lenguas polinesias se encuentran las lenguas de la isla de Pascua (rapanui) o Hawái (hawaiano) hasta Nueva Zelanda (maorí). El parentesco de estas lenguas polinesias ya fue detectado en los primeros viajes del capitán Cook.

Las lenguas no austronésicas de Nueva Guinea, llamadas lenguas papúes, sólo fueron razonablemente conocidas a partir del siglo XX. Su clasificación fue altamente controversial hasta los trabajos de Stephen Wurm (1975) y Malcolm Ross (2005). Esos trabajos sugieren que las lenguas papúes no forman una familia lingüística, sino varias familias altamente diversas. La mayor de estas familias está formada por las lenguas trans-neoguineanas que incluye centenares de lenguas. A este grupo pertenece el kate, que fue lengua franca de varios grupos antes de la expansión del tok pisin y el dani, lengua conocida por ser una de las pocas del mundo con solo dos términos para designar colores.

En cuanto a las lenguas de Australia, de las aproximadamente 750 que se hablaban en la isla antes de la llegada de los europeos, quedan actualmente unas 200, muchas de ellas con los últimos hablantes.

En muchas regiones de Oceanía, las lenguas autóctonas no han resistido la presión de la colonización y es actualmente la zona del mundo donde más lenguas autóctonas desaparecen. El samoano, lengua oficial de Samoa hablada por más 300 mil personas, es una de las pocas excepciones. Un caso curioso es la lengua llamada "beach-la-mar", criollo de base léxica inglesa, francesa, española e indígena. Esta lengua se utiliza como lengua puente del Pacífico no francófono y tiene, incluso, un diccionario y una literatura.

Algunas palabras procedentes de las lenguas de Oceanía han tenido una gran difusión a través del inglés. Entre estas podemos citar "ukelele" (del hawaiano), "tabú" y "tatuaje" (del tóngico) y kiwi (del maorí). De las lenguas australianas nos ha llegado la palabra "bumerang", que es originariamente el nombre de un grupo étnico local, así como algunos nombres de animales como "dingo", "koala" y "canguro".

En Oceanía la población varía dependiendo de las distintas regiones y países. En Australia y Nueva Zelanda la mayor parte de la población es adulta, superando ampliamente a la población joven. En cambio, en Fiyi, Kiribati, Papúa Nueva Guinea, Vanuatu y las colonias pertenecientes a Francia, al Reino Unido y a Estados Unidos, la mayor parte de la población está compuesta por jóvenes.

Por otra parte, en Papúa Nueva Guinea existe una mayor proporción de población adulta, pero con un envejecimiento mucho menor que en los otros países del continente.

Las Islas Marshall, Nauru y Tuvalu no fueron incluidos en el último informe sobre desarrollo humano del PNUD. Sin embargo sí fueron calculados en el año 2008, marcando los siguientes índices:

El 42,7 % de la población es protestante, el 24,7 % es católica, tan solo el 2,2 % pertenecen a la Iglesia ortodoxa y el 14,8 % profesan otras denominaciones cristianas (En total, el 86,6 % del continente es cristiano). Hay bajos porcentajes de nativos hinduistas (1,10 %), a pesar de que en Fiyi es la segunda religión más popular después del cristianismo, budistas (0,8 %), musulmanes (0,8 %) y de religiones tradicionales (0,8 %). El 13,1 % restante profesa otras religiones.

En resumen, 24 451 000 oceánicos son cristianos, 345 000 hinduistas, 266 000 budistas, 248 000 musulmanes, 259 000 de religiones tradicionales y 3 891 000 nativos pertenecen a otras religiones.

El arte tradicional de Oceanía tiene un sentido mágico-simbólico, originado por la preocupación religiosa y manifestado en ídolos, máscaras, armas, tatuajes y adornos. Los polinesios hacen llamativos tatuajes corporales; es más evolucionado el arte de los maoríes de Nueva Zelanda, con su arquitectura en madera, de una decoración muy rica, y grandes máscaras labradas; también llaman la atención sus figurillas de jade (tikis). En la Isla de Pascua son famosas las gigantescas estatuas de medio cuerpo, de piedra volcánica, alguna de hasta 15m de altura. Los melanesios decoran con figuras humanas y de animales las proas de sus piraguas y realizan máscaras de danza; en Nueva Guinea destacan las macabras estatuas de antepasados y la talla y adorno de cráneos de difuntos. En el arte de los micronesios resalta la elaboración de esteras.

Los dos deportes más populares son el rugby y el fútbol, aunque también el críquet, el culturismo, el béisbol, el baloncesto, el squash, el surf, la natación y algunos deportes locales, jugados por nativos, son también deportes practicados por los pobladores de Oceanía.

El rugby es el deporte más popular en Fiyi, Nueva Zelanda, Samoa, y Tonga, y goza también de buena popularidad en Australia (donde es el tercer deporte más popular, detrás del críquet y el fútbol australiano respectivamente) y Papúa Nueva Guinea (donde el deporte más popular es el rugby a 13, una variedad del rugby tradicional).

El torneo continental oceánico de rugby es la Copa del Pacífico, que se disputa desde 1975 y que incluye a todos los seleccionados de Oceanía y a equipos alternativos neozelandeses y australianos. Las primeras 4 ediciones (1974, 1977, 1986 y 1988) fueron ganadas por el seleccionado maorí de Nueva Zelanda, los siguientes dos campeonatos (1990 y 1992) quedaron para Samoa. Las ediciones de 1994 y 2006 fueron ganadas por el combinado tongano. Nueva Zelanda XIII en 1997, las Islas Cook en 2004 y Papúa Nueva Guinea en 2009 ostentan un solo título.

Nueva Zelanda y Australia son las selecciones más importantes de Oceanía, compiten a nivel internacional en todas las ediciones de la Copa Mundial de Rugby y el Torneo de las Tres Naciones. Nueva Zelanda consiguió el título mundial tres veces (1987 , 2011 y 2015) y el Torneo de las Tres Naciones en 9 ocasiones, mientras que Australia obtuvo el campeonato del mundo 2 veces (1991 y 1999), y el Torneo de las Tres Naciones en dos oportunidades. Estos dos países envían equipos alternativos a participar de los torneos continentales para poder mantener a los jugadores principales para los dos torneos más importantes a nivel mundial de rugby.

Fiyi, Tonga y Samoa son también selecciones importantes a nivel internacional, ya que compiten con frecuencia en la Copa Mundial de Rugby y en otros torneos de rugby union. Estos tres seleccionados se enfrentan cada año en la Pacific Nations Cup, el torneo sufrió cambios continuos de participantes, llegando a participar la selección junior de Nueva Zelanda, el elenco de maoríes neozelandeses y la selección alternativa de Australia, a pesar de esto, desde 2010 logró su forma actual, los tres seleccionados del Pacífico más Japón. Solo una vez una de las tres selecciones oceánicas pudo conquistar el título, lo hizo Samoa en 2010, ya que Nueva Zelanda Junior ganó las ediciones 2006, 2007 y 2009, Maoríes de Nueva Zelanda se quedó con el torneo celebrado en 2008 y Japón ganó el campeonato de 2011.

En rango de jerarquía, detrás de Fiyi, Samoa y Tonga aparecen los combinados de Papúa Nueva Guinea y las Islas Cook que tienen el gran logro de haber conseguido un título en la Copa del Pacífico. Juegan en prácticamente todas las ediciones de dicha copa, aunque nunca ninguno de los dos seleccionados llegó a jugar una Copa Mundial u otro torneo de rugby union.

Samoa Americana es otra selección de Oceanía de buen nivel, a pesar de ello, nunca llegó a disputar una Copa Mundial, aunque si jugó en tres ediciones de la Copa del Pacífico (1988, 1992 y 1994) sin poder lograr nunca un título. Niue representa otro seleccionado que nunca ha podido alzarse con títulos pero que si posee un cierto reconocimiento a nivel continental.

El fútbol no es tan practicado por los pobladores de Oceanía como el rugby, pero es el deporte más popular en Kiribati, Salomón, Tuvalu y Vanuatu. Como sucede en el rugby, las selecciones de y son las de mayor nivel, mientras que otras selecciones importantes oceánicas son , las , , y . La Confederación de Fútbol de Oceanía (comúnmente abreviada "OFC") es el máximo ente futbolístico de Oceanía, posee 11 miembros, las selecciones ya nombradas (exceptuando a Australia que en 2006 se adhirió a la AFC) y las , , , y . Además de 3 selecciones asociadas (miembros de la OFC, pero no de la FIFA), , y . y las fueron antiguos miembros asociados, pero hoy se encuentran en la AFC buscando su lugar en la FIFA. también es miembro de la AFC y de la FIFA, pero por ciertos problemas con la Federación Internacional de Fútbol Asociado no ha participado en las últimas dos eliminatorias asiáticas rumbo al Mundial.

El máximo torneo continental a nivel selecciones es la Copa de las Naciones de la OFC que se disputa desde 1973, edición que ganó Nueva Zelanda. El combinado neozelandés repitió esta hazaña cuatro veces más, en 1998, 2002, 2008 y 2016. Australia ganó los torneos disputados en 1980, 1996, 2000 y 2004. Estas dos son las únicas selecciones que han podido conquistar más de dos títulos en el campeonato. Si exceptuamos a Australia y Nueva Zelanda, sólo Tahití pudo lograr un campeonato (2012).

Por otro lado, en el Fútbol femenino, al igual que en fútbol masculino, Australia y Nueva Zelanda son las mejores selecciones del continente, goleando a todas la selecciones en todos los torneos (exceptuando los partidos entre sí). El Campeonato Femenino de la OFC, es la máxima competición a nivel continental (última edición en 2010), en la cual la selección neozelandesa es la más ganadora del certamen con 4 títulos, le siguen Australia y Taiwán. Ahora, sin Australia ni Taiwán, Nueva Zelanda, prácticamente no tiene rival en la OFC, puesto a que logra goleadas increíbles (14-0, 10-0, 11-0 a Vanuatu, Islas Cook y Papúa Nueva Guinea, respectivamente en 2010), aunque en los mundiales, Nueva Zelanda no hace buenos papeles. Otra selección importante en la OFC es Papúa Nueva Guinea que gana con superioridad al resto de los países, aunque es goleada por Nueva Zelanda.

A nivel internacional la OFC es la confederación más débil de las seis asociaciones miembros de la FIFA. Australia disputó 3 mundiales (en el último, Sudáfrica 2010 ya era miembro de la AFC). Se clasificó siendo miembro de la OFC a los dos mundiales que se disputaron en Alemania, 1974 y 2006. Solo ganó un partido y en 1974 no pudo marcar goles. Nueva Zelanda, por su parte, jugó los mundiales de España 1982 y Sudáfrica 2010, en 1982 fue goleado en sus tres partidos, pero en 2010 fue la única selección que no perdió ningún partido, empatando en sus tres partidos en la fase de grupos. Solo una vez una selección oceánica superó la fase de grupos, lo hizo Australia en 2006 aunque fue eliminada en octavos de final a manos de la selección italiana, que días después obtendría el título mundial.

A nivel de clubes, todos los países cuentan con ligas semiprofesionales, además de sus respectivas copas. Australia y Nueva Zelanda, además de la liga oficial, poseen múltiples campeonatos regionales. El nivel de la A-League australiana crece año tras año, mientras que la ASB Premiership neozelandesa trata de ganar relevancia mundial. La Liga Nacional de Fútbol de Fiyi, la Primera División de Vanuatu, la S-League de Islas Salomón y la Tahiti Division Federale son ligas que están avanzando en nivel futbolístico. El campeonato de clubes a nivel continental es la Liga de Campeones de la OFC en la que solo una vez un equipo fuera de Australia y Nueva Zelanda logró un título, el Hekari United de Papúa Nueva Guinea. El campeón del torneo se clasifica para la Copa Mundial de Clubes de la FIFA. El mejor puesto alcanzado por un equipo de Oceanía en este torneo fue el tercer lugar logrando por Auckland City FC en la edición 2014.



</doc>
<doc id="2055" url="https://es.wikipedia.org/wiki?curid=2055" title="Onagraceae">
Onagraceae

Onagraceae (onagráceas, en español) es una familia de plantas generalmente herbáceas.
Tienen hojas simples, sin estípulas, alternas u opuestas. La familia se caracteriza por flores de 4 sépalos y pétalos en algunos géneros (por ejemplo, las fucsias), los sépalos son tan coloreados como los pétalos, por lo que da la impresión de que tienen doble número de estos, son hermafroditas, actinomorfas o ligeramente cigomorfas, habitualmente tetrámeras (en la península) o dímeras, ínferas, con 2-4 carpelos y con un hipanto tubular, androceo con 8 (o 4+4) estambres. Fruto en cápsula, en baya, o seco indehiscente, más o menos alargado; es característica la presencia de un penacho de pelos en la semilla. 

Esta familia incluye unas 650 especies de hierbas, arbustos y árboles en 20 ó 24 géneros repartidos ampliamente por todos los continentes, abarcando desde las regiones boreales hasta las tropicales.


</doc>
<doc id="2057" url="https://es.wikipedia.org/wiki?curid=2057" title="Oxalidaceae">
Oxalidaceae

Las oxalidáceas (Oxalidaceae) son una familia de plantas herbáceas, aunque algunas son leñosas. Forman esta familia unas 950 especies, ubicadas en regiones de cálidas a templadas. 

Las especies que integran esta familia presentan hojas alternas, compuestas, a menudo trifoliadas, con peciolos largos. Sus flores son hermafroditas, con simetría actinomorfa, diclamídeas, pentámeras, diplostemonas, monadelfos en la base, gineceo supero, pentacarpelar, sincárpico, con estilos libres. Las flores son solitarias o bien se encuentran en inflorescencias de tipo cimas. Los frutos son cápsulas loculicidas o bayas. Las semillas presentan un arilo carnoso.




</doc>
<doc id="2058" url="https://es.wikipedia.org/wiki?curid=2058" title="Oceanografía">
Oceanografía

La oceanografía es un campo de la ciencia que estudia los mares y océanos y todo lo que se relaciona con ellos, es decir, la estructura, composición y dinámica de dichos cuerpos de agua, incluyendo desde los procesos físicos, como las corrientes y las mareas, hasta los geológicos, como la sedimentación o la expansión del fondo oceánico, o los biológicos. La misma ciencia recibe en español también los nombres de ciencias del mar, oceanología y ciencias marinas. Se divide en muchas ramas, en relación con sus contenidos específicos, como oceanografía física, oceanografía química, oceanografía geológica, u oceanografía biológica.

La palabra "oceanografía" (del griego ωκεανός, "océano" y γραφειν, "describir" o "representar gráficamente") fue acuñada por primera vez en el año 1584, del francés "océanographie", pero tuvo una vida corta. En el año 1880 retorna al alemán como "Oceanographie". En esa misma época surgen correlativamente en otras lenguas "oceanography", en inglés; "oceanografía", en español. En la lengua portuguesa, la palabra oceanografía aparece al final del siglo XIX.

La formación de la palabra es basada en el vocablo "geografía" y responde al origen científico del cual proviene la disciplina. Sobre el modelo de la palabra "geología" se encuentra "oceanologia", registrada por primera vez en la lengua inglesa - "oceanology" - en 1864. Aunque algunos la definen más completa por "oceanología", la forma que ha ganado más popularidad es "oceanografía".

Existen cuatro ramas principales de la oceanografía: oceanografía biológica, oceanografía física, oceanografía geológica y oceanografía química.

La Oceanografía Biológica, que no es lo mismo que la Biología marina, estudia todos los organismos marinos y su relación con el medio ambiente.

Estudia los procesos físicos que ocurren en el mar, tales como la mezcla (difusión molecular y turbulenta de las propiedades del agua de mar), las corrientes, las mareas y el oleaje.

Estudia los procesos geológicos que afectan a los océanos.

Estudia la composición química del agua de mar. De los componentes disueltos y particulados, de sus interacciones y efectos en la hidrósfera, biósfera y atmósfera.





</doc>
<doc id="2059" url="https://es.wikipedia.org/wiki?curid=2059" title="Oleorresina">
Oleorresina

La oleorresina son extractos semisólidos compuestos de una resina en solución en un aceite esencial o graso, obtenido por la evaporación del solvente(s) utilizado para su producción. Las oleorresinas naturales son conocidas como bálsamos.

En contraste a los aceites esenciales obtenidos, por destilación por vapor, las oleorresinas abundan en compuestos más pesados, menos volátiles y lipofílicos, como las resinas, ceras, grasas y aceites grasos. Las "gomoleorresinas" (óleo-goma resinas, gomarresinas) ocurren principalmente como bálsamos crudos, y también contienen polisacáridos solubles en agua.

Las oleorresinas son preparadas a partir de especias, como por ejemplo: albahaca, capsicum (pimentón), cardamomo, semillas de apio, corteza canela, clavo de olor, fenogreco, bálsamo de abeto, jengibre, pomarrosa, ládano, macis, mayorana, nuez moscada, perejil, pimienta (blanca/negra), pimenta dioica, romero, salvia, ajedrea (de verano/invierno), tomillo, cúrcuma, vanilla y hierbas de la costa oeste de India. Los solventes utilizados no son acuosos y pueden tener enlaces polares (alcoholes) o apolares (hidrocarburos, dióxido de carbono).

Las oleorresinas son similares "concretos" utilizados en perfumería, obtenidos especialmente de flores, y también son similares a los "resinoides", también utilizados en perfumería, los cuales son preparados de las secreciones animales.

La mayoría de las oleorresinas son utilizadas como sabores para los perfumes, algunos son utilizados medicinalmente (ej. aceite de hachís, aerosol de pimienta)


</doc>
<doc id="2061" url="https://es.wikipedia.org/wiki?curid=2061" title="Ocio">
Ocio

Comúnmente se llama ocio al tiempo libre que se dedica a actividades que no son ni trabajo ni tareas domésticas, y que pueden ser consideradas como recreativas. Es un tiempo recreativo que se usa a discreción. Es diferente al tiempo dedicado a actividades obligatorias o esenciales, como comer, dormir, hacer tareas vinculadas a cierta necesidad, etc. Las actividades de ocio se hacen en el tiempo libre, y no por obligación. 

Según el sociólogo francés Joffre Dumazedier:
La distinción entre las actividades de ocio y las obligatorias no es estricta, y depende de cada persona; así estudiar, cocinar o hacer música, puede ser ocio para unos y trabajo para otros, pues pueden realizarse por placer como por su utilidad a largo plazo y/o eventual ganancia económica.

El ocio se puede emplear en actividades motivadoras y productivas. Por otro lado, el ocio en la Antigua Grecia era considerado el tiempo dedicado, principalmente por filósofos, a reflexionar sobre la vida, las ciencias y la política.


Utilizando como criterio la participación de las personas, podemos distinguir dos tipos de ocio:

El Dr Manuel Cuenca habla sobre las dimensiones y direccionalidad dentro del ocio humanista. Partiendo de la premisa que es una experiencia que beneficia el desarrollo, se vuelve relevante comprender qué tipo de ocio se practica y si realmente permite una mejora en la persona.

Las direccionalidades se dividen en positivas y negativas.
Negativo cuando la experiencia perjudica al sujeto o su entorno. En ella se identifican dos tipos:
Positivo si tiene una vivencia gratificante de las experiencias. Igualmente se divide en dos:
Y de este último ocio se derivan 5 dimensiones descritas por Cuenca:

Desde una perspectiva más actual, de acuerdo con Gomes e Elizalde (2012), el ocio no es un fenómeno aislado y se manifiesta en diferentes contextos según los sentidos y significados producidos/reproducidos culturalmente por las personas en sus relaciones con el mundo. El ocio participa de la compleja trama histórico-social que caracteriza la vida en sociedad, y es uno de los hilos tejidos en la red humana de significados, símbolos y significaciones.

En la vida cotidiana, el ocio constituye relaciones dialógicas con otros campos además del trabajo: la educación, la política, la economía, el lenguaje, la salud, el arte, la ciencia y la naturaleza, entre otras dimensiones de la vida, siendo parte integrante y constitutiva de cada sociedad (Gimes, 2010).

De este modo, para los autores Gomes y Elizalde el ocio es entendido como una necesidad humana y dimensión de la cultura caracterizada por la vivencia lúdica de manifestaciones culturales en el tiempo/espacio social. Así, el ocio se constituye en la articulación de tres elementos fundamentales: la ludicidad, las manifestaciones culturales y el tiempo/espacio social. Juntos, estos elementos configuran las condiciones materiales y simbólicas, subjetivas y objetivas que pueden – o no – hacer del ocio un potente aliado en el proceso de transformación de nuestras sociedades, convirtiéndolas en más humanas e inclusivas.

Las manifestaciones culturales que constituyen el ocio son prácticas sociales experimentadas como disfrute de la cultura, tales como: fiestas, juegos, paseos, viajes, música, poesía, grafiti y murales, pintura, escultura, danza, vivencias y expresiones corporales, juegos electrónicos y experiencias virtuales, fotografía, teatro, actividades comunitarias, ferias con nuevas modalidades de intercambio, actividades recreativas y deportivas, festivales y eventos artísticos, variadas modalidades de educación popular local, espacios de conversación y debate etc.

Desde esta perspectiva re-significada, el ocio puede generar una vivencia de apertura marcada por una actitud que rompa y transgreda con lo permitido y con lo lícito, mostrándose muchas veces al borde de lo socialmente adecuado y aceptado. Justamente a esto se debe uno de los grandes temores, así como peligros, que representa el ocio para el mantenimiento del statu quo. De aquí surge, en parte, el intento de acallar y prohibir la disrupción, contracorriente, alteridad e innovación subversiva, y todo aquello que puede expresar un ocio polémico, caótico, contra-hegemónico y catalizador (Elizalde, 2010).

Según Gomes y Elizalde (2013), en los estudios sobre el ocio difundidos en Occidente es posible verificar que las raíces de este abordaje generalmente son localizadas en la Grecia clásica o en la modernidad europea. Estas dos interpretaciones son divergentes en términos de ocurrencia histórica del ocio y generan intensos debates académicos: para algunos, la existencia del ocio es observada desde las sociedades griegas, y para otros el ocio es un fenómeno específico de las sociedades modernas, urbanas e industrializadas.

Independientemente del contexto histórico y de las características consideradas, el desarrollo teórico sobre el tema desde finales del siglo XIX posibilitó la sistematización de los conocimientos sobre el ocio, una palabra que hoy - según algunos estudiosos - corresponde a los términos leisure en inglés, loisir en francés y lazer en portugués la doris.

Para algunos autores, ocio proviene del vocablo romano otium. Recuperando el significado de skholé, esta palabra representaba una posibilidad de abstención de las actividades ligadas a la mera subsistencia. Implicaba, necesariamente, las condiciones de paz, reflexión, prosperidad y libertad de tener que realizar las tareas serviles y vinculadas a las necesidades de la vida productiva. Como dependía de ciertas condiciones educacionales, políticas y socioeconómicas, skholé constituía un privilegio reservado a una pequeña parcela de los hombres libres. Para Aristóteles, las personas tenían que aprender a desear el reposo filosófico, pues, es por medio de él que se tornaría posible alcanzar virtudes. De esta forma, en su sentido griego, skholé era vinculada a la posibilidad de descanso y reposo, condición propicia por el distintivo característico de los privilegiados: la abstención de la necesidad de ejercer el trabajo útil o productivo y la posibilidad de dedicación a la contemplación, a la meditación y a la reflexión filosófica.

Como destaca Munné, el otium romano era estratificado socialmente: estaba asociado, en el caso de las elites intelectuales, a la meditación y a la contemplación. Era el otium con dignidad. Por eso, en lo que concierne a las personas comunes, otium significaba descanso y diversión proporcionados por los grandes espectáculos. Esta estrategia hacía referencia a la tradicional expresión “pan y circo” y tenía como finalidad despolitizar al pueblo, reduciéndolo a la condición de mero espectador, evidenciando así el potencial muchas veces alienante, de las formas de entretenimiento masivo.

La conexión que los romanos hicieron entre el otium y el negotium es interesante de comprender. El negotium, palabra latina que originó el término negocio, fue entendido como ocupación y actividad. De esta forma, el trabajo (negocio y comercio) también representaba la negación del otium. Para tener una visión más clara sobre la forma de entender el ocio y el trabajo en la antigüedad greco-romana es importante recordar que, etimológicamente, la palabra trabajo deriva del término latín tripalium, que significaba un instrumento de tortura con el que se obligaba a los esclavos a realizar determinadas tareas. Así, en la visión clásica greco-romana el ocio era mucho más valorizado que el trabajo, algo distinto a lo que ocurrió posteriormente.

En esta perspectiva, desde el siglo XIX el ocio está muy vinculado a las categorías trabajo y tiempo libre – concebidas desde una perspectiva sociológica. Por eso, la sociología es una importante área (pero no la única) que fundamenta las teorías y análisis desarrollados sobre la temática, principalmente por autores de Europa y de los Estados Unidos. Para muchos estudiosos, entre los cuales se destaca Dumazedier (1976), el ocio surgió en la modernidad europea en el siglo XXI como fruto de la revolución industrial acontecida, en los principales centros urbanos de Europa, sobre todo en Inglaterra. Para él, el ocio se contrapone al trabajo y corresponde a una liberación periódica del trabajo al fin del día, de la semana, del año y de la vida, cuando se alcanza la jubilación.

Independiente de que la ocurrencia histórica del ocio sea ubicada en la Grecia clásica o en la modernidad europea, es posible observar que Europa, con sus prácticas e instituciones, es considerada como imprescindible y determinante para el “surgimiento” del ocio en todos los rincones del mundo, incluso en Latinoamérica. Así, se perpetúa la idea de que existe una historia única y universal del ocio, que ubica Europa en una posición central, destacada y que debe ser tratada como válida para todo el mundo.

Ambas interpretaciones colaboran con el mantenimiento de una lógica evolutiva y lineal que define los tiempos, las historias, las culturas y las prácticas de todas las realidades, de todos los pueblos que, a su vez, deben anhelar el modelo occidental – urbano, industrial y capitalista – como el ideal a ser alcanzado para acceder al supuesto progreso. Las evidencias de que disponemos hasta el momento indican que los primeros conceptos elaborados sobre el ocio fueron producidos en este contexto. Pero un concepto no es el fenómeno, es solamente una representación de la realidad que pretende expresar. De esta manera, lo que “surgió” en Europa en el siglo XIX fue el concepto de ocio tal como lo entendemos actualmente en Occidente, y no la realidad que este pretende representar.

De acuerdo con Gomes y Elizalde (2012), desde el siglo XX estas dos distintas interpretaciones sobre el origen del ocio han generado profundas polémicas cuando se busca retomar la historia de este fenómeno. En general, ambas son ampliamente utilizadas en las teorías sobre el ocio que orientan y fundamentan los estudios sobre esa temática en varias partes del mundo, ejerciendo influencias significativas sobre los conocimientos difundidos en los distintos países de Latinoamérica.

Esas interpretaciones aun cuando son dotadas de lógicas propias, se refieren a realidades específicas pertinentes cuando se trata de Europa, por ejemplo, pero son inadecuadas e insuficientes para discutir el ocio y la recreación en Latinoamérica. Esta región posee otras singularidades y otros marcos históricos, culturales, sociales, políticos y económicos. Todo esto demanda otras interpretaciones, abordajes, reflexiones y re-significaciones, así como la sistematización de otros saberes que sean capaces de dialogar críticamente con las realidades latinoamericanas.

Como plantea Escobar, para hablar de América Latina es necesario considerar los lugares y realidades locales, obviamente sin perder de vista el contexto más amplio. De este modo, los análisis sobre los conceptos y teorías de ocio y recreación no pueden ser universales y globalizantes (Gomes, 2010).

Además de esto, las dos interpretaciones sobre un supuesto origen del ocio, destacadas previamente, son producciones teóricas que refuerzan el mito de la centralidad de Europa como referente privilegiado para la constitución del mundo, y sobre todo del llamado mundo occidental. De este modo, excluyen la decisiva participación de otras realidades en un juego que envuelve, de manera desigual, varios componentes, dentro de los cuales están los pueblos y culturas de otros continentes, tales como América Latina, África y Asia. (Gomes y Elizalde, 2012).




</doc>
<doc id="2062" url="https://es.wikipedia.org/wiki?curid=2062" title="Orchidaceae">
Orchidaceae

Las orquídeas u orquidáceas (nombre científico Orchidaceae) son una familia de plantas monocotiledóneas que se distinguen por la complejidad de sus flores y por sus interacciones ecológicas con los agentes polinizadores y con los hongos con los que forman micorrizas.

La familia comprende aproximadamente 25 000 especies (algunas fuentes informan de 30 000), por lo que resulta ser una de las familias con mayor riqueza específica entre las angiospermas. A esta diversidad natural se le suman 60 000 híbridos y variedades producidas por los floricultores.

Las orquídeas pueden ser reconocidas por sus flores de simetría fuertemente bilateral, en las que la pieza media del verticilo interno de tépalos —llamada labelo— está profundamente modificada, y el o los estambres están fusionados al estilo, al menos en la base.

Las orquídeas constituyen un grupo de plantas de morfología extremadamente diversa. Su tamaño varía desde unos pocos milímetros de longitud (ciertas especies de los géneros y especies "Bulbophyllum" y "Platystele") hasta gigantescas agregaciones que pueden pesar varios cientos de kilogramos (algunas especies de "Grammatophyllum") o longitudes de hasta 13,4 m (como "Sobralia altissima"). Del mismo modo, varía el tamaño de sus flores, desde las diminutas del género "Platystele" —menores de 1 mm— pasando por las grandes flores de 15 a 20 cm de diámetro en muchas especies de los géneros "Paphiopedilum", "Phragmipedium" y "Cattleya", hasta los 76 cm de las flores de "Phragmipedium caudatum". La fragancia de sus flores no es menos variable, desde el delicado aroma de "Cattleya" hasta el repulsivo hedor de las flores de ciertas especies de "Bulbophyllum".

Se encuentran en la mayor parte del mundo, excepto en las regiones de clima desértico o polar, si bien son especialmente abundantes en la zona intertropical, donde crecen la mayoría de las especies de flores más vistosas.

La familia ha sido reconocida por los sistemas clásicos de clasificación de plantas, como el sistema de Cronquist, así como por los más modernos, como el sistema de clasificación APG II y el sistema de clasificación APG III.

Las orquídeas son plantas herbáceas, perennes —raramente anuales—, terrestres o epífitas, ocasionalmente trepadoras. Unas pocas especies carecen de clorofila, y son micoheterotróficas.
Con respecto a las orquídeas epífitas, se dice que pueden llegar a ser eternas. De hecho, en la naturaleza, su supervivencia está ligada a la vida del árbol que las sostiene. Se conocen plantas recolectadas a mediados del siglo XIX que todavía están creciendo y floreciendo en muchas colecciones.

Los tallos son rizomas o cormos en las especies terrestres. En las especies epífitas, en cambio, las hojas se hallan engrosadas en la base formando pseudobulbos que sirven para almacenar agua y nutrientes y que, por lo general, están recubiertos por las vainas foliares membranosas que se secan con la edad.

Existen dos tipos básicos de crecimiento dentro de la familia: el tipo simpodial, que origina tallos múltiples, y el tipo monopodial, que origina un solo tallo. El tipo simpodial de crecimiento es el más común dentro de la familia. La mayoría de estas orquídeas presentan pseudobulbos que funcionan como reservorios de agua y nutrientes. La planta sostiene los pseudobulbos casi verticalmente y el crecimiento y desarrollo posterior de nuevos tallos se produce horizontalmente, entre los pseudobulbos preexistentes. Cada nuevo pseudobulbo se origina en la base de los anteriores y, con su crecimiento, origina nuevas hojas y raíces. Las hojas originadas en cada pseudobulbo pueden durar muchos años, proveyendo nutrientes para toda la planta, hasta que se tornan marrones y mueren. Aun sin hojas, cada pseudobulbo continúa sosteniendo el crecimiento y suministrando la energía necesaria para el crecimiento del resto de la planta y para la floración. Algunos ejemplos de orquídeas con este tipo de crecimiento son los géneros "Cattleya", "Dendrobium" y "Oncidium". Las orquídeas con crecimiento monopodial, a diferencia de las anteriores, presentan un solo tallo principal que crece erecto e indefinidamente desde el centro de la planta. Normalmente, el tallo va creciendo hacia arriba y se originan raíces en los nudos, las cuales crecen hacia abajo. La planta, conforme va creciendo, pierde las hojas inferiores a medida que se forman nuevas hojas en el extremo superior. Algunas especies de orquídeas con este tipo de crecimiento son aquellas pertenecientes a los géneros "Ascocentrum", "Phalaenopsis" y "Vanda".

Las orquídeas terrestres a veces presentan raíces tuberosas. En las orquídeas epífitas, en cambio, las raíces son aéreas y están muy desarrolladas, cuelgan de los árboles y son verdes y gruesas. Las raíces de las epífitas tienen una doble función, son las estructuras que se encargan de captar los nutrientes que la planta necesita y funcionan, además, como elementos de fijación. Las raíces en este tipo de orquídeas típicamente poseen una epidermis esponjosa, formado por muchas capas de células muertas a la madurez y con paredes celulares engrosadas, llamada velamen. El velamen constituye una vaina esponjosa y blanquecina que rodea por completo a la raíz. Si el tiempo está seco, sus células están llenas de aire; pero cuando llueve se llenan de agua.
Según algunos autores el velamen es un tejido que absorbe agua, según otros nunca se ha observado el paso de agua del velamen al córtex de la raíz. Su función principal parece ser la de protección mecánica, además de impedir la excesiva pérdida de agua de la raíz en períodos de deficiencia hídrica. Además, cuando el velamen se llena de agua se vuelve transparente permitiendo a la luz alcanzar el tejido verde de las raíces y, por ende, facilita la fotosíntesis.

Del rizoma o de los tallos aéreos nacen las hojas, las cuales son simples y de margen entero, generalmente alternas, espiraladas, dísticas o verticiladas, muchas veces plicadas, basales o a lo largo del tallo, a veces reducidas a vainas o a escamas, usualmente con venación paralela y envainadoras en la base. Pueden presentar pecíolo o ser sésiles y no presentan estípulas. Las especies adaptadas a períodos de sequía tienen hojas carnosas que cumplen la función de reserva de agua en épocas de escasez.

Aun siendo una familia cuyas flores tienen un aspecto muy diferente entre géneros, su estructura es homogénea. Como en otras monocotiledóneas, el periantio es trímero. Está formado por tres piezas externas llamadas sépalos, dos laterales y uno dorsal, y tres elementos internos llamados pétalos, uno de ellos modificado en un labio o labelo de mayor tamaño y color más intenso que los demás. Esta modificación, junto con el fenómeno de resupinación o torsión que lo sitúa en posición inferior, cumple la función de atraer algún animal que es su polinizador. Hay variaciones estructurales que facilitan la polinización por una determinada especie de insecto, pájaro o murciélago. Algunos autores clasifican el perianto de las orquídeas como un perigonio, formado por seis tépalos dispuestos en dos verticilos.

Las diferentes piezas del perianto pueden estar separadas entre sí o fusionadas en la base.

Los sépalos, o tépalos externos, son usualmente petaloideos (similares a pétalos), imbricados. A veces los dos sépalos laterales se encuentran fusionados en un solo elemento llamado «sinsépalo». Los pétalos, o tépalos internos, están siempre separados, a veces presentan puntos, manchas y colores muy variados. El llamado «labelo» es el pétalo medio, es de tamaño mayor que los dos pétalos laterales y su forma es extremadamente variable. Es la pieza más compleja y, en cierto modo, un órgano característico de las orquídeas. Puede ser lobulado, y entonces se dice que existe un lóbulo central y dos laterales ("Orchis", "Dactylorhiza"). En otras oportunidades, como en "Epipactis", se diferencian transversalmente dos partes que se denominan «hipoquilo» la basal y «epiquilo» la distal. Puede tener áreas brillantes, crestas, quillas u otras protuberancias que se suelen denominar como «callo» o «callus». También es frecuente que desarrolle un espolón dirigido hacia atrás o hacia abajo en donde se aloja un nectario. Este espolón puede ser largo y fino ("Gymnadenia", "Orchis"), o como un saco redondeado ("Coeloglossum viride"). También hay especies en que el espolón no tiene néctar o puede haber nectarios no incluidos en el espolón.

El androceo está usualmente formado por uno o dos estambres (a veces tres), si es uno solo deriva del estambre medio del verticilo externo ancestral y usualmente con dos estaminodios vestigiales derivados de los estambres laterales de un verticilo interno ancestral. En algunas subfamilias, como en Apostasioideae o Cypripedioideae, hay dos o tres estambres fértiles. Cuando son dos, han derivado de los dos estambres laterales del verticilo interno ancestral, y cuando son tres, se han originado de los dos laterales del verticilo interno y del estambre medio del verticilo externo. El androceo se halla fusionado al estilo y al estigma, los cuales se hallan altamente modificados, formando una estructura conocida como «columna», «ginostemo» o «ginostegio». Las tecas de las anteras se disponen en la porción del ginostemo denominada «clinandro» o «androclino». El polen es granular, en tétradas o aglutinado en grupos de dos a ocho masas suaves o duras llamadas polinias. Estas polinias presentan un apéndice filiforme —llamado «caudícula»— que se une con una masa pegajosa —«retináculo» o «viscidium»— sobre el «rostelo», estructura derivada del estigma con forma de lóbulo alargado y que se sitúa sobre la porción receptiva del estigma. El conjunto de polinios, caudículas y retináculos se denomina «polinario», el cual es la unidad de transporte del polen durante la polinización. Las anteras son de dehiscencia longitudinal y su conectivo muchas veces se halla modificado en un «opérculo» que cubre la antera hasta la polinización.

El gineceo está formado por tres carpelos fusionados entre sí, con el ovario ínfero, que puede presentar un lóculo o tres, y numerosos óvulos (hasta millones) de placentación usualmente parietal, pero ocasionalmente de placentación axilar.

Las orquídeas son, en general, productoras de néctar, sustancia que utilizan como recompensa a los polinizadores. Los nectarios son variables en posición y tipo. Por ejemplo, se encuentran en el espolón del labelo, o en los ápices de los sépalos, o en las paredes internas del gineceo. Las especies que no producen néctar son autógamas o apomícticas, es decir, no necesitan de polinizadores para producir semillas.

Las orquídeas llevan sus flores de diversos modos. Aun dentro del mismo género, las diferentes especies pueden tener distintos modos de disponer las flores en inflorescencias, las cuales son indeterminadas y, a veces, reducidas a una única flor, terminal o axilar.
La mayoría de las orquídeas tienen inflorescencias que llevan dos o más flores, las que usualmente nacen de un eje floral más o menos alargado que comprende un tallo denominado "pedúnculo" y una porción que lleva las flores, llamada "raquis". En la mayoría de las especies las flores se disponen en un racimo erecto y alargado, con las flores arregladas en una espiral laxa alrededor del raquis (como, por ejemplo, en "Cymbidium)". En esos racimos las flores individuales se enlazan con el eje floral a través de un corto tallito llamado pedicelo. Puede ser que las flores se articulen con el raquis directamente, sin pedicelo, y —en ese caso— la inflorescencia se denomina espiga, como puede observarse en los géneros "Peristylus" y "Neuwiedia".

Un grupo de orquídeas pertenecientes al género "Bulbophyllum", bastante espectacular por su floración, presenta el raquis tan contraído que todas las flores parecen salir del mismo punto, como en una umbela. Algunas otras orquídeas "(Oncidium, Renanthera"), finalmente, presentan inflorescencias ramificadas que se denominan panículas.

El fruto es una cápsula loculícida, que se abre mediante tres o seis ranuras longitudinales (a veces una sola); en raras ocasiones, el fruto de las orquídeas es una baya.

Las semillas son diminutas y numerosas. El tegumento es crustoso o membranoso, sin fitomelaninas, con sólo la capa externa persistente y los tejidos internos colapsados. Las semillas son muchas veces membranosas y aladas, los que les permite ser dispersadas por el viento. El embrión es muy pequeño y no se halla acompañado por endosperma, ya que este tejido aborta muy temprano en el desarrollo embrionario.

La palabra "orquídea" deriva del griego ὄρχις ("órjis" ‘testículo’) e ἰδέα ("idéa" ‘forma’). El vocablo hace referencia a la forma de los tubérculos de las especies del género "Orchis", orquídeas de hábito terrestre cuyos tubérculos dobles parecen testículos, como puede apreciarse en la imagen de la derecha. El vocablo se atestigua por primera vez en los manuscritos de la obra "De causis plantarum" del filósofo griego Teofrasto, que datan aproximadamente del año 375 antes de Cristo.

Fueron conocidas y apreciadas por los seres humanos desde la Antigüedad. Existen escritos chinos de 1500 años de antigüedad donde se hace referencia al cultivo de las orquídeas. En la antigua Grecia se le atribuían propiedades curativas y afrodisíacas. Los aztecas utilizaban una orquídea —la vainilla— para enriquecer una bebida espesa hecha a base de cacao, destinada a los nobles y a los guerreros y era conocida con el nombre de "xocoatl".

En Europa, el interés por ellas se despertó hacia 1731 cuando floreció la primera orquídea tropical del Nuevo Mundo, "Bletia purpurea" (sin. "Bletia verecunda"), en la colección del almirante inglés Charles Wager quien la obtuvo del Jardín Botánico de Chelsea. Desde ese momento, se suscitó un interés sin igual por la adquisición y cultivo de orquídeas exóticas, en particular por los miembros de las clases sociales más acomodadas, quienes debían construir un orquideario como una obligación acorde con su estatus. De hecho, cuando una orquídea florecía en tales colecciones, el evento daba lugar a grandes fiestas y la noticia cubría las primeras planas de la prensa. Para satisfacer este consumo de orquídeas raras y exóticas, durante muchos años los recolectores profesionales provenientes en su mayoría de Francia e Inglaterra se dedicaron a saquear sin misericordia los bosques americanos, poniendo a muchas especies en peligro de extinción. A principios del siglo XX, no obstante, la era de la denominada «orquideomanía» llegaba a su fin. El costo para calefaccionar los invernaderos en los que se debían cultivar estas plantas era extremadamente alto y la carestía energética —agudizada por la primera guerra mundial— dificultó el mantenimiento de los orquidarios privados. Con la depresión de 1929, el cultivo de orquídeas a gran escala definitivamente pasó a manos de empresarios comerciales.

Las orquídeas conforman la familia más grande de las plantas con flores, con alrededor de 20 000 especies divididas en unos 800 géneros distribuidos por todo el mundo. Son una familia cosmopolita, que se halla distribuida desde dentro del círculo polar ártico hasta Tierra del Fuego y las islas al sur de Australia. Se hallan ausentes solamente en los desiertos verdaderos y en los polos. Son más diversas en las regiones tropicales, donde frecuentemente son epifitas. No obstante, la mayoría de las especies se encuentran en los trópicos y subtrópicos, desde el nivel del mar hasta los 5000 msnm, en casi todos los ambientes. En algunos ecosistemas son el elemento dominante, particularmente en hábitats deficientes en nutrientes. Solamente existen dos ambientes en la tierra donde no prosperan estas plantas, los polos y los desiertos de arena. Son más diversas en las regiones tropicales, donde frecuentemente son epifitas.
La mayor cantidad de especies se distribuyen en las regiones tropicales, particularmente en áreas montañosas, las cuales representan barreras naturales y aíslan a las diversas poblaciones de plantas, lo que ocasiona la formación de un elevado número de endemismos. Algunas áreas con una marcada predominancia de orquídeas son las islas y el área continental del sudeste asiático, Ecuador, donde hay unas 3500 especies descritas y Colombia, el país con mayor variedad de orquídeas, con alrededor de 4.270 especies registradas. La masa atlántica brasilera cuenta con, aproximadamente, 1500 especies descritas. Otras áreas importantes son las montañas del sur del Himalaya en la India y China, las montañas de América Central y el sudeste africano, notablemente la isla de Madagascar.

Su capacidad para adaptarse es notable, ya que pueden crecer tanto a nivel del mar como en los páramos elevados. Muchas viven sobre los árboles (epifitas), otras lo hacen sobre las rocas (litófitas), otras sobre la tierra y algunas especies se desarrollan incluso en ambientes subterráneos. A pesar de lo que mucha gente cree, no son parásitas, ya que no se alimentan del árbol donde viven, sino que lo usan como medio de soporte y como vehículo para alcanzar la luz del sol. Algunas sólo miden unos pocos centímetros y otras pueden tener el porte de un árbol. Sus flores pueden ser tan diminutas que resulta imposible observarlas a simple vista, mientras que otras llaman poderosamente la atención.

Por lo general, las orquídeas florecen una sola vez al año, siempre por la misma época, la cual está determinada por factores ambientales tales como la disminución o elevación de la temperatura, el incremento de las horas de luz, los cambios de estación y las variaciones en la humedad ambiental. Las flores pueden permanecer abiertas desde un día (el caso de "Sobralia") hasta más de tres meses (como en "Paphiopedilum" y "Phalaenopsis"). Los híbridos artificiales pueden florecer dos o más veces al año.

El 97 % de las especies de orquídeas necesitan de un polinizador para que se lleve a cabo la transferencia de los granos de polen de una planta a los pistilos de otro individuo y, por ende, para que se produzca la fecundación y la formación de las semillas. Se debe tener en cuenta que el polen de las orquídeas se halla agrupado en masas compactas llamadas polinias (singular: polinario), de tal modo que por sí solo, o por acción del viento, el polen no se puede dispersar de una flor a otra por lo que los polinizadores son imprescindibles para asegurar su reproducción sexual.
Estos polinizadores son muy variados y, según cuál sea la especie en cuestión, pueden ser moscas, mosquitos, abejas, avispas, coleópteros y aves (especialmente colibríes).

La zoofilia que caracteriza a las orquídeas presupone que los animales polinizadores visiten las flores de manera regular y se detengan en ellas el tiempo suficiente; que las anteras y el estigma sean rozados o tocados con cierta frecuencia y que el primero quede adherido a los visitantes de modo tan perfecto que pueda llegar con la debida seguridad a los estigmas de otras flores. El resultado de la zoofilia depende esencialmente de que los animales puedan reconocer las flores desde una cierta distancia y de que se vean compelidos a visitar durante un cierto tiempo las flores de la misma especie. Las flores zoófilas, entonces, deben poseer "productos atractivos" (cebos, como el polen y el néctar), "medios de reclamo" (tales como olores y colores) y, además, "polen viscoso o adherente".

Muchas especies de orquídeas recompensan a los polinizadores con alimento (como por ejemplo, néctar, pelos alimenticios o aceites) y otros compuestos, tales como ceras, resinas y fragancias. Estas recompensas, a su vez, refuerzan la conducta de los polinizadores. No obstante, la especialización en un solo tipo de polinizador para asegurar una transferencia más eficiente de polen, determinó una creciente especialización morfológica y estructural en las flores de las orquídeas para garantizar la atracción de una sola especie de insecto.

Por esa razón, las flores de las orquídeas son de formas extremadamente variadas y pueden atraer a una amplia variedad de insectos (abejas, avispas, moscas, mariposas, polillas) así como a pájaros, murciélagos o sapos para la polinización. Algunas atraen visitantes generalistas, pero muchas están bastante especializadas, atrayendo solo a una o unas pocas especies como polinizadores. Polen, néctar, o fragancias florales pueden ser empleadas como recompensadores de la polinización, mientras que algunas flores (por ejemplo "Cypripedium") manipulan a sus polinizadores y no proveen ninguna recompensa, y algunas especies de "Ophrys" y "Cryptostylis" mimetizan la forma y el olor de las hembras de abejas, avispas, o moscas, y son polinizadas cuando los machos tratan de aparearse con la flor (fenómeno llamado pseudocopulación).

Generalmente, el labelo funciona como una plataforma de aterrizaje y provee señales visuales o táctiles que orientan al polinizador. La polinia se adjunta al cuerpo del polinizador, y muchas veces es depositada en el estigma (usualmente una depresión en la parte de abajo de la columna) de la siguiente flor visitada. El género "Coryanthes" tiene un labelo como un bolsillo que se llena con un fluido secretado por la columna, una abeja que cae en este fluido debe viajar a través de un túnel, forzando la deposición del polinario en su cuerpo. La transferencia de polen dentro de la polinia es una aparente adaptación para asegurar la fertilización de muchos del tremendo número de óvulos. En algunas especies la polinización es un evento bastante poco común, y las flores pueden permanecer funcionales y vistosas por muchos días. El marchitamiento del perianto ocurre rápidamente solo después de la fertilización. "Angraecum sesquipedale", una orquídea de Madagascar, también es conocida por su biología de la polinización. Esta especie presenta un espolón de 20 a 35 cm de largo, y es polinizada por una mariposa esfíngida, "Xanthopan morganii praedicta" con una probóscide de esa longitud, un hecho que Charles Darwin había predicho antes del descubrimiento de tal polinizador.

En la mayoría de las especies las pequeñas semillas, que son como polvo, son dispersadas por el viento y requieren nutrientes provistos por un hongo micorrícico para poder germinar. Algunos miembros de Cypripedioideae y Vanilloideae poseen frutos carnosos que fermentan "in situ" liberando compuestos fragantes (por ejemplo la vainillina) que atraen a pájaros y mamíferos, que actúan como agentes de dispersión.

Estas semillas están formadas por un embrión constituido por pocas células (entre 100 y 200), cubiertas por una testa muy dura. El número de semillas puede variar de 13 000 a 4 000 000 por cápsula. El rango de peso de una semilla de orquídea varía de 0,3 a 14 µg y miden de 0,25 a 1,2 mm de largo y 0,009 a 0,27 mm de ancho. Estas semillas no poseen endosperma y consisten de un pequeño embrión suspendido dentro de una membrana, comúnmente transparente, aunque en ocasiones pigmentada. Las formas de las semillas pueden ser muy variables, existiendo elípticas, filiformes, fusiformes, redondas, globulares o prominentemente aladas. Todas estas características aparentemente maximizan la fecundidad y la efectividad en la dispersión por el viento de las semillas de orquídeas.
La germinación de estas semillas tiene lugar por medio de un proceso que es diferente al de la mayor parte de las angiospermas, porque los embriones de orquídeas son, desde un punto de vista anatómico y estructural, extremadamente reducidos y simples. Los embriones de orquídeas germinan y crecen hasta producir una masa de células llamada «protocormo». Estos protocormos, con sus «rizoides» (estructuras en forma de raíces) pueden o no de inmediato comenzar a fotosintetizar. No obstante, para que el protocormo sobreviva, se desarrolle y se transforme en retoño, primero debe establecer una relación simbiótica con un hongo.

El papel que desempeña el hongo es el de suministrar azúcares al protocormo (especialmente a aquellos que no poseen clorofila). El hongo obtiene el azúcar de secciones del substrato (suelo u otro objeto sólido que sirva de organismo huésped a la planta) de la orquídea, es decir, la corteza de un árbol o del suelo. El protocormo, a su vez, provee al hongo con ciertas vitaminas y un hábitat donde vivir. El hongo vive en área del protocormo y del substrato. Con el tiempo, el joven retoño comenzará a producir sus propios nutrientes y la simbiosis no será más necesaria.

Se han sugerido muchos orígenes posibles para las orquídeas, no obstante, la familia de las hipoxidáceas (o plantas similares a ellas, ya extintas) parecen ser sus progenitores más probables. A pesar de ser la familia de angiospermas más diversa sobre la tierra, las orquídeas no poseen un registro fósil adecuado por lo que muchos aspectos de su historia evolutiva permanecen oscuros. No obstante, en 2007 se ha informado el hallazgo en la República Dominicana del polinario de una orquídea (la que fue denominada "Meliorchis caribea") preservado en ámbar y adherido al mesoescutelo de una especie extinta de abeja "(Proplebeia dominicana"). Ese fósil proviene del Mioceno, aproximadamente 15 a 20 millones de años atrás. Este descubrimiento constituye no solo el primer fósil de orquídea descubierto sino también el primer antecedente fósil de las interacciones entre las plantas y sus polinizadores. Asimismo, este descubrimiento sumado a análisis cladísticos sobre datos de la morfología, indican que el ancestro más reciente de las orquídeas existentes vivió en el Cretácico superior, entre 76 a 84 millones de años atrás.
La monofilia de las orquídeas está sustentada tanto por la morfología como por los análisis de secuencias de ADN (Dressler 1981, 1993, Dressler y Chase 1995, Burns-Balogh y Funk 1986, Judd "et al." 1993, Chase "et al." 2000, Fay "et al." 2000, Freudenstein "et al." 2004). Asimismo, las relaciones filogenéticas dentro de la familia, motivo de activas investigaciones en las últimas décadas que todavía continúan, han sido dilucidadas mediante análisis cladísticos de la morfología y de secuencias conservadas del ADN (Dressler 1983, 1993, Chase 1986, 1988, Chase y Hills 1992, Chase y Palmer 1992, Cameron "et al." 1999, Kores "et al." 2000, Whitten "et al." 2000, Salazar "et al." 2003, Burns-Balogh y Funk 1986, Cameron 2006, Dressler 1986, 1993, Judd "et al." 1993, Dressler y Chase 1995, Cameron "et al." 1999, Freudenstein y Rasmussen 1999, Cameron y Chase 2000, Freudenstein "et al." 2000, 2004, Molvray "et al." 2000, van den Berg "et al." 2005).

La filogenia de las orquídeas se halla suficientemente aclarada en la actualidad, lo que permite la reconstrucción de los estados ancestrales y el análisis de la evolución de varios caracteres adaptativos novedosos, los que incluyen los síndromes de polinización altamente especializados, la colonización de hábitats epifíticos y la presencia de metabolismo ácido de las crasuláceas. El metabolismo ácido de las crasuláceas (conocido como CAM, acrónimo inglés para "Crassulacean Acid Metabolism") es una ruta fotosintética, muy distribuida taxonómicamente, la cual ha evolucionado en plantas que habitan ambientes con limitaciones de agua y de dióxido de carbono, los cuales incluyen el dosel de los bosques tropicales con disponiblidad hídrica estacional o intermitente. La fotosíntesis C3 es el estado ancestral de la familia y el metabolismo CAM ha evolucionado al menos diez veces de modo independiente, con varias reversiones al estado original. Un gran evento de radiación adaptativa hacia el metabolismo CAM ocurrió dentro de Epidendroideae, el clado con mayor riqueza de especies epífitas de todos los grupos de plantas conocidos, el cual estuvo ligado a la rápida evolución de una gran cantidad de especies durante el período Terciario. De hecho, se ha demostrado que existe una asociación muy estrecha entre el metabolismo CAM y el hábito epifítico, caracteres que habrían evolucionado paralelamente hace unos 65 millones de años, en correspondencia con la progresiva aridificación y reducción de la concentración de dióxido de carbono en la atmósfera durante el Terciario. Aparentemente, la riqueza de especies en las orquídeas está ligada a la colonización de hábitats epifíticos, y la capacidad para hacerlo estuvo relacionada con la adquisición del metabolismo CAM, como un medio de llevar a cabo la fotosíntesis con bajo consumo de agua. No obstante, el cambio del hábito de crecimiento terrestre al hábito epifítico no solo requiere del metabolismo CAM, sino también de la presencia de varios otros atributos adaptativos. Así la presencia de raíces finas, pequeñas y trepadoras es esencial para la adhesión a un sustrato con escasa estabilidad, como las ramas de los árboles. La suculencia y las raíces con velamen se requieren para soportar los períodos prolongados de deficiencia hídrica al estar fijadas a sustratos con escasa o nula capacidad de retención de agua. Finalmente, la densidad poblacional de los organismos epifíticos es en general muy baja, por lo que requieren de sistemas de polinización altamente especializados para lograr la transferencia eficiente del polen entre plantas diferentes. Todas estas adaptaciones morfológicas y fisiológicas se han desarrollado en las orquídeas en múltiples ocasiones, lo que ha determinado la gran riqueza de especies de esta familia y que casi el 70 % de las mismas sean epífitas.

Los géneros "Apostasía" y "Neuwiedia" (pertenecientes a la subfamilia Apostasioideae) son considerados hermanas del resto de los miembros de la familia (Dressler 1993, Judd "et al." 1993, Dressler y Chase 1995, Neyland y Urbatsch 1996, Cameron "et al." 1999, Freudenstein y Rasmussen 1999). Estos dos géneros, y especialmente "Neuwiedia", han retenido muchos caracteres ancestrales, como por ejemplo la presencia de dos ("Apostasia") o tres ("Neuwiedia") estambres en sus flores, los que están sólo ligeramente fusionados al estilo y los granos de polen, independientes entre sí y no pegajosos. Las restantes orquídeas, en cambio, presentan polen pegajoso o con los granos de polen fusionados entre sí en el momento en el que son liberados de los estambres. Dentro del grupo de orquídeas con polen pegajoso, las subfamilias Cypripedioideae y Vanilloideae son los clados basales. La primera de ellas (que incluye, por ejemplo, a "Cypripedium" y "Paphiopedilum") es claramente monofilética y sus miembros comparten algunos caracteres exclusivos, como su labelo en forma de saco (con la forma de una zapatilla) y la antera media modificada en un estaminodio con forma de escudo y dos estambres funcionales. Vanilloideae (que contiene por ejemplo a "Vanilla", "Pogonia" y "Cleistes") se distingue porque sus flores tienen sólo un estambre funcional y tampoco presentan polinias.

Las restantes subfamilias poseen un solo estambre funcional, los granos de polen se encuentran agrupados formando polinias y el filamento del estambre se encuentra completamente fusionado con el estilo (Dahlgren "et al." 1985, Burns-Balogh y Funk 1986, Judd "et al." 1993). Este clado, que incluye a todas las especies con polen agrupado en polinias, tiene flores con solo un estambre funcional (se dicen monandras) y los dos estambres laterales están transformados en esbeltos estaminodios o faltan completamente).

Los análisis de morfología (Freudenstein y Rasmussen 1999) y algunos análisis moleculares (Cameron "et al." 1999, Molvray "et al." 2000) indican que las orquídeas monandras son monofiléticas, No obstante, otros análisis moleculares (Cameron 2006, Cameron y Chase 2000, Freudenstein "et al." 2004), sostienen que la reducción del número de estambres funcionales ha ocurrido en dos oportunidades durante la evolución de la familia.
Entre las orquídeas monandras con polinia se reconocen dos grandes subfamilias, Epidendroideae y Orchidoideae (incluyendo Spiranthoideae). Los miembros de Epidendroideae comparten la apomorfía de presentar una antera picuda e incumbente (es decir, la antera se halla curvada sobre el ápice de la columna), mientras que los integrantes de Orchidoideae comparten las apomorfías de un ápice de la antera agudo, tallos suaves y hojas convolutas.
El árbol filogenético de las subfamilias es el que sigue (Judd "et al." 2007, modificado de Cameron "et al." 1999, Kocyan "et al." 2004):

Algunos autores, como por ejemplo Dahlgren "et al." (1985), reconocieron tres familias de orquídeas basándose en el número de anteras del androceo: Apostasiaceae, con dos o tres anteras sólo parcialmente fusionadas al gineceo; Cypripediaceae, con dos anteras fusionadas al gineceo y Orchidaceae, la familia más rica en cantidad de especies, las cuales presentan una única antera fusionada al gineceo. No obstante, todas las evidencias moleculares hasta la fecha muestran que Orchidaceae definida o circunscripta de ese modo sería polifilética. Los datos morfológicos y moleculares indican, en cambio, que Orchidaceae debería definirse en forma amplia, por lo que una nueva clasificación de la familia que se corresponde con la filogenia conocida fue publicada por Chase y colaboradores en 2003, en la que se reconocen cinco subfamilias, las que se describen a continuación:

Las orquídeas apostasioides se consideran el grupo de orquídeas más primitivo. Presentan dos o tres estambres en sus flores, las cuales son «regulares» y se parecen a las del género "Hypoxis" (de la familia Hypoxidaceae). Las hojas se disponen en forma espiralada en los tallos, son plegadas, resupinadas (salvo en "Apostasia"). El saco embrionario es bispórico, del tipo "Allium". El número cromosómico básico es x= 24. Incluye solo dos géneros ("Apostasia" y "Neuwiedia") y aproximadamente 16 especies.

Sinonimia: Apostasiaceae Lindley, Neuwiediaceae Reveal & Hoogland.

Este segundo grupo de orquídeas representan un linaje independiente, con categoría taxonómica de subfamilia: las cipripedióideas. También retienen características primitivas, tales como la presencia de dos estambres en las flores. Comprende cinco géneros: "Cypripedium", "Mexipedium, Paphiopedilum, Phragmipedium" y "Selenipedium" y cerca de 150 especies, las cuales se distribuyen en cinco tribus monotípicas.
Están ampliamente distribuidas en Eurasia y a través de América.

Conocidas popularmente como «zapatillas de dama» debido a la abultada forma de zapatilla de su labelo que funciona como atrapa insectos, ya que el insecto es forzado a pasar con la espalda por el estaminodio, con lo que se recolectan o depositan los polinia.
En estas orquídeas, dos anteras fértiles se disponen a cada lado de la columna. El estambre central es estéril y está curiosamente modificado como un escudo que impide el acceso directo de los polinizadores desde del frente de la flor a la parte central. Los otros dos estambres están escondidos detrás de este estaminodio. El labelo saculiforme ha evolucionado como una trampa para los polinizadores. Las paredes internas del labelo son muy resbalosas pero una escalera de pelos yace en el interior de la pared dorsal. Este conduce bajo el estigma ventral a una de las dos salidas en la base del labelo a cada lado de la columna.

Sinonimia: Cypripediaceae Lindley.

Las orquídeas vanilóideas son un pequeño grupo que incluye a "Vanilla", un género de aproximadamente 70 especies de lianas. Comprende 15 géneros y 180 especies que se distribuyen en la franja tropical y subtropical húmeda del globo y en los Estados Unidos de América.

Esta subfamilia incluye en su mayoría orquídeas terrestres con tubérculos o rizomas carnosos. El género tipo "Orchis" y las "orquídeas abeja" "(Ophrys", que se denominan así porque su labelo parece el abdomen de una abeja) pertenecen a este grupo. Comprende 208 géneros y 3630 especies distribuidas en todo el mundo, excepto en los desiertos más secos, en el círculo polar Ártico y en la Antártida. Los miembros representativos de Orchidoideae incluyen a "Cynorkis, Diuris, Goodyera, Habenaria, Orchis, Platanthera, Spiranthes, "y" Zeuxine".

Más de 500 géneros y cerca de 20 000 especies distribuidas en las mismas regiones de Orchidoideae, si bien incluyen algunas especies subterráneas del desierto australiano. Epidendroideae contiene numerosas epífitas tropicales, entre los géneros representativos se incluyen "Bulbophyllum, Catasetum, Dendrobium, Epidendrum, Encyclia, Maxillaria, Oncidium, Pleurothallis" y "Vanda". La delimitación de los géneros en este grupo es notoriamente problemática, y los géneros más numerosos no son monofiléticos. La mayoría son epífitas tropicales (normalmente con pseudobulbos), pero algunas son terrestres e incluso unas pocas saprofitas.

Tradicionalmente las orquídeas han sido utilizadas por distintos pueblos con fines ornamentales y medicinales. Los chinos fueron los primeros en cultivarlas desde, aproximadamente, el año 500 a. C. Más tarde, en el siglo V, los griegos las empleaban como plantas medicinales. En América, los aztecas las utilizaban como plantas medicinales, especias, alimenticias y ornamentales. Una de las orquídeas empleadas por este pueblo fue la popular vainilla («tlilxóchitl» en náhuatl, nombre científico, "Vanilla planifolia"), usada para aromatizar el chocolate, y llevada a Europa por los conquistadores españoles a principios del siglo XVI y desde ahí a regiones tropicales como Madagascar. Este país se ha convertido en el primer productor del mundo de esta especia, utilizada como saborizante y aromatizante en todo el mundo.

A pesar de la gran diversidad de la familia, pocas orquídeas son cultivadas por otra razón que no sea la belleza de sus flores. Además del ya mencionado cultivo de "Vanilla" para producir vanillina, algunas pocas especies se utilizan para la producción de aromatizantes del té "(Jumellea") o del tabaco "(Vanilla"). En Turquía se utilizan los tubérculos de "Anacamptis morio" para la preparación de una bebida típica caliente que se bebe en los días fríos del invierno conocida como salep.

El cultivo de las orquídeas por la belleza de sus flores evolucionó lentamente desde un simple pasatiempo hasta la explotación comercial. Las primeras orquídeas ornamentales llegaron a Europa, procedentes del Nuevo Mundo, en 1731. Sin embargo, no fue sino hasta 1821 cuando se inició su cultivo comercial en invernaderos cerca de Londres. Para 1913 se inauguró en Singapur la compañía «Sun Kee» para producir y comercializar flores cortadas de orquídeas. Actualmente, en Estados Unidos, Inglaterra, Francia, Taiwán, Japón, China, Tailandia, Australia, Hawái y Singapur se ha profundizado el interés por el cultivo y la explotación de orquídeas, con dos objetivos definidos. El primero es el de la producción de flor cortada para abastecer el mercado internacional de floricultura. El segundo objetivo es el de producir y comercializar plantas de diferentes tamaños, en particular las que se hallan cerca de la floración, para abastecer de plantas ornamentales el mercado interno de cada país.

Tailandia es uno de los países más especializados en la producción de flores de orquídeas para abastecer la demanda de las principales ciudades alrededor del mundo, con un monto de exportaciones de 40 millones de dólares para el año 2001.

Entre los géneros de orquídeas más comúnmente cultivados para flor de corte o como plantas ornamentales se destacan "Cattleya", "Dendrobium", "Epidendrum", "Paphiopedilum", "Phalaenopsis", "Vanda", "Brassia", "Cymbidium", "Laelia", "Miltonia", "Oncidium", "Encyclia" y "Coelogyne". No obstante, la mayor proporción de cultivares actuales de orquídeas (los que se cuentan por más de 100 000) han surgido a través de hibridaciones artificiales entre dos o más especies, muchas veces de distintos géneros.

El método más simple de multiplicación, a menudo utilizado por los coleccionistas y por los comerciantes de pequeña escala, es la división del tallo. En varias especies de orquídeas, como las pertenecientes al género "Dendrobium", el pseudobulbo es largo y articulado, está formado por muchos nudos en los cuales se desarrollan hijuelos. Desde la base de estos hijuelos se desarrollan raíces. Para multiplicar este tipo de orquídeas, entonces, solo se deben cortar los hijuelos enraizados, separarlos de la planta madre y trasplantarlos a otro recipiente. Las especies de orquídeas de mayor importancia comercial, tales como "Cattleya", "Laelia", "Miltonia" y "Odontoglossum", pueden propagarse por división del rizoma en secciones, las que deben llevar de tres a cuatro pseudobulbos.
Los denominados «bulbos traseros», aquellos que ya han perdido el follaje, se usan comúnmente para propagar clones de "Cymbidium". Estos bulbos se remueven de la planta y se colocan en otro recipiente con un sustrato adecuado para que formen raíces.

Luz sí, pero no sol directo, la temperatura entre 18 y 25 °C., nunca inferior a 16 °C. pues moriría.

El riego debe ser una vez a la semana, se coloca la maceta en un plato y se llena el este de agua, después de un rato hay que quitarlo, pues las raíces se pudrirán.

Se abona una vez al mes, siguiendo las mismas instrucciones que para el riego, es decir, diluyes el abono en el agua del plato y al rato cuando haya absorbido toda la humedad que necesita lo retiras.

Para conseguir una mayor y mejor floración: cuando las flores se secan, hay que cortar por encima de la tercera yema (nodo), y en pocos meses volverá a brotar con más vigor.

La maceta, como en todas las plantas, se cambia cuando empiezan a asomar por debajo las raíces, esa es señal de que ya no le queda tierra, ni sitio para las raíces.

Debido a la gran cantidad de semillas que se producen en cada fruto y a la posibilidad de cultivar los meristemas "in vitro", las orquídeas también pueden ser multiplicadas a gran escala.

Las semillas de las orquídeas son muy pequeñas y las que se hallan en un solo fruto pueden generar miles de nuevas plantas, cada una con características diferente de la otra. No obstante, las semillas contienen escasas reservas y no pueden germinar con sus propios recursos. De hecho, en la naturaleza deben asociarse a un hongo durante la germinación, el cual le provee los nutrientes que requiere para su crecimiento y desarrollo. Por esta razón, la manera más simple —si bien la menos eficiente— de multiplicar orquídeas a través de semillas consiste en esparcir las semillas sobre y alrededor de las raíces de orquídeas cultivadas en maceta y asegurarse de que tengan humedad constante en el sustrato. Las semillas germinan en unas semanas y crecen muy lentamente, de manera que una planta obtenida de este modo florece por primera vez cuando alcanza de cinco a diez años. Este proceso se denomina «germinación simbiótica» y, hasta 1922, era el único método de propagación de orquídeas a través de semillas. En ese año Lewis Knudson de la Universidad Cornell publicó un trabajo en el que describía un método artificial para hacer germinar a las orquídeas sin la participación de un hongo. Este método, llamado de «germinación asimbiótica», hace uso de técnicas de micropropagación para lograr la germinación y establecimiento de las plántulas en un medio de cultivo artificial y bajo condiciones estériles.

La reproducción a través del cultivo in vitro de meristemas, o clonación, es más eficiente y consiste en quitar la punta de la raíz o el extremo de un brote, situarlo en un medio de cultivo adecuado bajo condiciones estériles. Bajo la influencia de los fitohormona los meristemas se convierten en una masa de tejido indiferenciado, capaces de dar lugar a nuevas plántulas. Las plántulas así obtenidas se separan unas de otras y se cultivan en tubos de ensayo independientes. Las plantas son clones perfectos de la planta original, por lo que este es el método más aplicable a la propagación masiva de una variedad particular o de híbridos estériles.






</doc>
