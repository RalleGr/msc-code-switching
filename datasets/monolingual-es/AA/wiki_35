<doc id="6702" url="https://es.wikipedia.org/wiki?curid=6702" title="Islam">
Islam

El islam (del árabe: الإسلام, "") es una religión abrahámica monoteísta basada en el Corán, el cual establece como premisa fundamental ("shahada") para sus creyentes que «No hay más Dios que Alá y Mahoma es su profeta». La palabra árabe "Allah", hispanizada como Alá, significa Dios y su etimología es la misma de la palabra semítica "El", con la que se nombra a Dios en la Biblia. Los eruditos islámicos definen al islam como: «La sumisión a Dios el Altísimo a través del monoteísmo, la obediencia y el abandono de la idolatría». Los seguidores del islam se denominan musulmanes (del árabe "muslim" مسلم, 'que se somete'). Creen que Mahoma es el último de los profetas enviados por Dios y sello de la Profecía. El libro sagrado del islam es el Corán, que según los musulmanes fue dictado por Alá a Mahoma a través de Yibril (el arcángel Gabriel).

Se acepta como profetas principalmente (pero no limitándose) a Adán, Noé, Abraham, Moisés, Salomón y Jesús (llamado Isa), al que el Corán reconoce como: 'El Mesías, la Palabra de Allah, Su Verbo' (Sura 5, n.º 169). Además del Corán, los musulmanes de tradición sunita siguen asimismo los hadices y la sunna del profeta Mahoma, que conforman el "Registro histórico de las acciones y las enseñanzas del Profeta". Se aceptan también como libros sagrados la Torá (el Pentateuco de los cristianos), los Salmos y el Evangelio.

El islam es una religión abrahámica monoteísta que adora exclusivamente a Alá sin copartícipes. Es la segunda religión más grande del mundo, tras el cristianismo y la que tiene mayor crecimiento en términos de seguidores, quienes se estima alcanzan 1900 millones o el 25 % de la población mundial, a los que se conoce como musulmanes. Los musulmanes son la mayoría de la población en 50 países. 

El islam se inició con la predicación de Mahoma en el año 622 en La Meca (en la actual Arabia Saudita). Bajo el liderazgo de Mahoma y sus sucesores, el islam se extendió rápidamente. Existe discrepancia entre los musulmanes y no musulmanes de si se extendió por imposición religiosa o militar, o por conversión de los pueblos al islam.

La palabra "Islām", de la raíz trilítera s-l-m, deriva del verbo árabe "aslama", que significa literalmente ‘aceptar, rendirse o someterse’. Así, el islam representa la aceptación y sometimiento ante Dios. Los fieles deben demostrar su sumisión venerándolo, siguiendo estrictamente sus órdenes y aboliendo el politeísmo. En palabras del arabista Pedro Martínez Montávez:
La palabra está dada por numerosos significados en el Corán. En algunos versos ("ayat", en español aleyas), la calidad del islam como una convicción interna es acentuada: «A quien quiera que Dios se desee dirigir, él ampliará su pecho al islam». Otros versos conectan la palabra "islām" y "dīn" (traducido usualmente como ‘religión’ o ‘fe’): «Hoy, he perfeccionado su religión "(dīn)" para usted; he completado mi bendición sobre usted; he aprobado el islam para su religión». Todavía, algunas facciones describen el islam como una acción de devolver a Dios, más que solamente una afirmación verbal de fe.

Con frecuencia se confunden los significados de palabras o términos como árabe, musulmán, islámico e islamista, que tienen significados distintos; para aclarar los significados de estas palabras pueden consultarse diversas referencias bibliográficas.

La teología de los chiitas contiene cinco principios de la de la religión y además de los tres de los sunitas creen en dos otros, es decir: "Tawhid" (Monoteísmo), "Nubuwwah" (Profecía), "Maad" (El Día de la Resurrección), "Imamah" (Liderazgo), "Adl" (Justicia).

Según la opinión de sunní la doctrina islámica tiene cinco pilares en su fe que forman parte de las acciones interiores de los musulmanes. Los pilares principales son:



A los cinco pilares de la concepción sunní añaden algunos el sexto pilar del "yihad" o "esfuerzo" en defensa de la fe. En términos estrictamente religiosos, se entiende fundamentalmente como un esfuerzo espiritual interior de cada creyente por vivificar su fe y vivir de acuerdo con ella. A esto se le llama "yihad mayor", mientras que existe un "yihad menor" que consiste en predicar el islam o defenderlo de los ataques. De este último concepto nace la idea de yihad como lucha o guerra que se ha popularizado en todo el mundo. 

Además, conforme al Corán, todos los musulmanes tienen que creer en Dios, sus ángeles, sus libros, sus profetas, la predestinación y en la próxima vida.

La creencia en la existencia de Dios es un principio común entre todas las doctrinas divinas, y básicamente, la diferencia substancial y fundamental entre una persona religiosa —cualquiera sea la doctrina que practique— y un individuo materialista, radica en esta cuestión.

Dios en el Corán se nombra a sí mismo como "Allah", nombre derivado de la raíz semítica El. Aunque el término es conocido en Occidente como referencia al Dios musulmán, para los hablantes en árabe (de cualquier religión, incluidos cristianos y judíos) se emplea como referencia a "Dios".
La creencia en Dios dentro del islam consiste en cuatro aspectos:

Dado que se trata del mismo Dios de cristianos y judíos, las cualidades que los musulmanes le atribuyen son básicamente las mismas que le atribuyen aquellos, pero hay diferencias considerables. Es reseñable, sin embargo, que el islam, a semejanza del judaísmo pero alejándose del cristianismo, insiste en su radical unidad "(tawhid)", es decir, que es uno y no tiene diversas personas (como afirma en cambio la mayoría de las corrientes cristianas con el dogma de la Trinidad) en su carácter incomparable e irrepresentable.

El islam se refiere a Dios también con otros noventa y nueve nombres, que son otros tantos epítetos referidos a cualidades de Dios, tales como El Clemente (Al-Rahmān), El Apreciadísimo (Al-'Azīz), El Creador (Al-Jāliq). El conjunto de los 99 Nombres de Dios recibe en árabe el nombre de "al-asmā' al-husnà" o ‘los más bellos nombres’, algunos de los cuales han sido utilizados asimismo por cristianos y judíos o han designado a dioses de la Arabia preislámica. Algunas tradiciones afirman que existe un centésimo nombre que permanece incognoscible, que es objeto de especulaciones místicas, y que se define en ocasiones como el Nombre Inmenso "(ism al-'Azam)", o como el Nombre de la Esencia, figura que existe igualmente en el judaísmo, y que ha tenido una gran importancia en el sufismo. Otras veces, se utiliza simplemente la palabra "rabb" (señor).

Mahoma dijo que Dios tenía 99 nombres; en este versículo del Corán se mencionan algunos:
La palabra Allāh está en el origen de algunas palabras españolas como "" ("law šā llāh", si Dios quiere). En cuanto a la etimología de las palabras "olé" y "hala", el etimólogo Joan Corominas les atribuye un origen de creación expresiva por su similitud con otras expresiones francesas, inglesas y alemanas, mientras para el arabista Emilio García Gómez "olé" derivaría de la exclamación musulmana "Wa-llâh", 'por Alá' o '¡por Dios!'.


Todos los eruditos islámicos dicen que la orden más importante que Dios da al hombre es que este reconozca su absoluta unicidad (en árabe: توحيد Tawhid) y esto significa que lo adore únicamente a Él, y esta adoración no es válida excepto del monoteísta, por lo tanto Mahoma divulgó su mensaje entre hombres que tenían diferentes tipos de adoración: algunos adoraban ángeles, otros adoraban profetas y hombres piadosos, otros adoraban árboles, piedras, y entre ellos había quien adoraba al sol y a la luna. A todos ellos el Profeta les reprendió sus actos invitándolos al islam sin hacer distinción alguna.

La mayoría de los versículos del Corán sobre esta materia enfatizan la Unidad de Dios con respecto a la Creación, las órdenes (la dirección del mundo) y el culto. Primero llaman la atención del hombre al hecho de que solamente Dios es el Creador del mundo. Solamente Él tiene la autoridad soberana sobre el mismo. Luego extraen la conclusión de que solamente El merece ser adorado.


El Corán refuta la teoría de la pluralidad de dioses de la siguiente manera:

Si el mundo fuese a tener más de un creador, las relaciones subsecuentes estarían limitadas a asumir una de las siguientes formas:


Son criaturas que constituyen un intermedio entre Dios y este mundo visible y Dios les encargó los asuntos del mundo de la existencia y la legislación. Los ángeles son siervos honorables que nunca desobedecen a Dios en lo que les ordena. Todo lo que les manda lo llevan a cabo.
La fe en los ángeles dentro del islam consiste en:


La fe en los libros revelados dentro del islam comprende:


El Corán significa en idioma árabe la recitación por excelencia. Es el libro revelado al Profeta Muhammad por el Arcángel Gabriel de parte de Dios Altísimo. 

El Sagrado Corán es el milagro por excelencia de Mahoma, ya que los árabes, especialmente en la época del Profeta, el año 600 de la era cristiana.

Existen numerosas tradiciones y diferentes puntos de vista en cuanto al proceso de compilación del Corán. La mayoría de los musulmanes aceptan lo que indican diversos hadices: el primer califa, Abu Bakr, ordenó a Zaid ibn Zabit compilar todos los auténticos versos del Corán, tal como se preservaban en forma escrita o a través de la tradición oral. La compilación realizada por Zaid, conservada por la viuda de Mahoma, Hafsa bint Umar, y que fue utilizada por 'Uthmān, es la base del Corán actual.

La versión de 'Uthmān organiza las azoras (capítulos) según su extensión, de forma que las más largas se encuentran al comienzo del Corán y las más cortas al final. Hay teorías que indican que este orden no cronológico de las azoras fue establecido por Dios.
El Corán fue escrito originalmente en escritura hijazi, masq, ma'il y cúfica. En un principio, sin vocales, solo con consonantes, siguiendo la técnica de escritura vigente hasta entonces en árabe y en otras lenguas semíticas de la península arábiga. Para evitar posibles desacuerdos en cuanto al contenido de los versos del Corán, se crearon marcas diacríticas que indicaran las vocales o la ausencia de estas, el fonema hamza y la prolongación o geminación de consonantes. En cambio, no tiene signos de puntuación, interrogación o exclamación, pues el idioma árabe contaba con partículas (palabras breves) de interrogación y de énfasis.

La forma del Corán más utilizada actualmente es el texto de Al-Azhar de 1123, preparado por un grupo de prestigiosos eruditos de la Universidad de Al-Azhar de El Cairo.

La mayor parte de los musulmanes veneran el libro del Corán. Lo envuelven en paños limpios y se lavan las manos antes de los rezos o para leerlo. Los ejemplares coránicos en desuso no se destruyen como papel viejo, sino que se queman o se depositan en "tumbas" para el Corán.

Muchos musulmanes memorizan al menos parte del Corán en su idioma original. Aquellos que memorizan totalmente el Corán son conocidos como "hāfiz". En la actualidad existen millones de hāfiz en el mundo.

Desde el comienzo del islam, la mayoría de los musulmanes consideran que el Corán es perfecto únicamente en la versión árabe en la que fue revelado. Las traducciones son interpretaciones no infalibles del texto original. Muchas versiones actuales del Corán indican la versión original en árabe en una página y la traducción vernácula en otra.

El Corán afirma que Dios mandó un mensajero (profeta) a cada comunidad, llamando adorar únicamente a Dios, y a descreer en todo lo que es adorado fuera de Él.
Cada uno de ellos era veraz, guiado y recto, y obedecieron a Dios en lo que les fue encomendado, ninguno de ellos cambió o alteró su mensaje. Todos ellos eran seres humanos, creaciones de Dios, sin cualidades de divinidad o Señorío, y no pueden responder si se les pide ayuda. El Corán menciona más de veinte profetas, desde Adán hasta Mahoma y llama a Mahoma, «sello de la profecía», creen que Su misión era devolver el mensaje divino a su pureza inicial, como en su momento hizo Jesús de Nazaret o Issah ibn Maryam en árabe ("Issah:" Jesús, "Ibn:" ‘hijo’, "Mariam:" María), a quien Alá en el Corán lo considera como un profeta y no su hijo.

Según lo que sostiene la escuela chiita del islam, el número de profetas es de ciento veinticuatro mil. Entre los que fueron mencionados en el Sagrado Corán, se encuentran: Adán, Noé, Abraham, Ismael, Isaac, Lot, Jacob, José, Job, Moisés, Aarón, Ezequiel, David, Salomón, Jonás, Zacarías, Juan el Bautista, Jesús y Muhammad.

Entre ellos, Noé, Abraham, Moisés, Jesús y Muhammad tuvieron una misión universal y trajeron nuevos códigos de ley y una "Sharîat" (Ley Divina). Ellos son llamados "Ûlûl ‘azm" significando «los poseedores de determinación».

Muhammad Bin Abdullah Bin Abdul-Muttalib Bin Hashem (Año del Elefante/, La Meca-, Medina). Según los musulmanes, profeta del islam, Muhammad es uno de los archiprofetas (Ulul ‘Azm), y el último profeta divino cuyo principal milagro fuese el Corán. Su invitación fue al monoteísmo y a la moral. La opinión de los musulmanes no es la del creador de una nueva religión, sino como el restaurador de la original, la fe monoteísta de Adán, Abraham y de otros que se había corrompido. En la tradición musulmana, Mahoma se ve como el último y el más grande de una serie de profetas, como un hombre muy cercano a la perfección, poseedor de virtudes en todos los campos de la vida, espirituales, políticos, militares y sociales. Por 23 años de su vida, comenzando a la edad de 40, Mahoma divulgó la recepción de revelaciones de Dios. El contenido de estas revelaciones, conocido como el Corán, era memorizado y registrado por sus compañeros. Durante este tiempo, Mahoma predicó a la gente de La Meca, implorándole que abandonase el politeísmo. Aunque algunos se convirtieron al islam, Mahoma y sus seguidores fueron perseguidos por las autoridades principales de Meca. Después de trece años de predicación, Mahoma y los musulmanes realizaron la Hégira («emigración») a la ciudad de Medina (conocida antes como Yathrib) en 622. Allí, con los convertidos de Medina (ansar) y los emigrantes de La Meca (muhayirun), Mahoma estableció su autoridad política y religiosa.

La Sunna, libros que contienen la compilación de la vida de Mahoma, es de gran valor para muchos musulmanes, y la creen indispensable para la interpretación del Corán. Esto es debido a que se tiene registrado en ella que el mismo Mahoma les ordenó a sus compañeros que escribieran todo lo que él decía. y conforme al Corán, toman sus palabras como revelación.

Según la tradición, Mahoma era una persona de carácter excelente, bien parecido, iletrado y un profeta para toda la humanidad. Es frecuente entre los devotos la creencia en que el hecho de que Mahoma fuera analfabeto es una señal más de que solo pudo recibir el Corán por revelación divina, dada la complejidad del libro.

Según el Corán, Jesús (llamado Isa) fue uno de los profetas más queridos por Dios y, a diferencia de lo que ocurre en el cristianismo, para los musulmanes no tiene carácter divino.

El Corán confirma su nacimiento virginal. Dios purificó a su madre María. Existe un capítulo entero en el Corán llamado "Maryam" (María). El Corán describe el nacimiento de Jesús como sigue:

Jesús nació milagrosamente [sin padre] por orden de Dios quien creó a Adán sin padre ni madre. Dios dijo:

Durante su misión profética, Jesús hizo varios milagros. Dios nos dice que Jesús dijo:

Los musulmanes creen que Jesús no fue crucificado (y mucho menos que murió en la cruz). Era el plan de los enemigos de Jesús el crucificarlo (y matarlo), pero Dios lo salvó y lo elevó hacia Sí. La apariencia de Jesús fue colocada sobre otra persona, y los enemigos de Jesús aprehendieron a este hombre y lo crucificaron, pensando que era Jesús. Dios dijo:

La predestinación forma parte de las creencias islámicas categóricas que nos llegan en el Libro de Dios y la tradición profética, y que son confirmadas por las pruebas e indicios lógicos contundentes.

Los pilares de la creencia de la predestinación en el islam son cuatro:


Creen que todos los acontecimientos sean buenos o malos, beneficiosos o dañinos, ocurren por la predestinación y el designio de Alá, pero que a la vez el ser humano tiene una facultad de elección, mas esta no es total.

Todas las religiones celestiales están de acuerdo en la necesidad de la fe en el Más Allá y la exigencia de la creencia en la Resurrección. 
La muerte no es el final de la vida y la extinción, sino una transición de un estado de existencia a otro. En realidad, es el traslado hacia una vida eterna que damos en llamar «La Resurrección», solo que entre esos dos estados de existencia hay un tercero intermedio que es denominado "Barzaj", y al morir el ser humano es trasladado a ese estado hasta que acontezca la Hora de la Resurrección.

Creen en una vida dentro de la tumba después de la muerte y en su tribulación.
Ellos creen que el tiempo de "Qiyāmah" es predestinado por Dios, pero no fue revelado a los hombres. El juicio y las pruebas precedentes y durante el "Qiyāmah" son descritas en el Corán y el Hadiz, y también en los comentarios de eruditos islámicos, en la retribución y rendición de cuentas ante Dios, que cada individuo recibirá un libro escrito por los ángeles que incluirá una mención completa de todas las obras que realizó el ser humano en la vida terrena, quien lo reciba en la diestra será de los exitosos y quien lo reciba en la mano izquierda será de los perdedores, en el Paraíso y el Infierno, así como en las Señales que indican la llegada de la Última Hora, afirman que la primera era la llegada del profeta Mahoma y entre las últimas es el retorno del profeta Jesús que romperá las cruces y legislará con el islam.

La creencia en "El día de Resurrección", "yawm al-Qiyāmah" (también conocido como "yawm ad-dīn", "El día del juicio final" y "as-sā`a", "La última hora") es asimismo crucial para los musulmanes.
El Corán acentúa la resurrección corporal, una rotura del entendimiento preislámico de muerte. Esto declara que la resurrección será seguida de la reunión de toda la humanidad, culminando en su juicio por Dios.

El Corán hace referencia a varios pecados que pueden condenar a una persona al Jahanam (como la incredulidad, la usura y la falta de honradez). Los musulmanes ven el paraíso, Janah, como un lugar de alegría y dicha, con referencias del Corán que describen sus rasgos y los placeres físicos de dicho lugar. Hay también referencias a una aceptación de mayor júbilo por Dios. Tradiciones místicas en el islam colocan estos placeres divinos en el contexto de una conciencia extática de Dios.

En el Sagrado Corán se ha llamado al «Retorno» de muchas formas, como: «El Día de la Resurrección», «El Día del Cómputo», «El Último Día», «El Día del Resurgimiento» y de otras maneras.

Los pilares del islam según la opinión de Sunita son cinco:


El modo de vida islámico se encuentra basado en una relación personal entre Alá y el creyente, siguiendo la Sharia, en donde la "intención" será el rasgo fundamental que rija todas las acciones del mismo.


La "yihad" (en árabe, ﺟﻬﺎﺩ "yihād": significa ‘esfuerzo’ y ‘lucha en el camino de Dios’, inglés o al francés, "jihad") es considerada «el sexto pilar de islam» por una minoría de autoridades musulmanas. Yihad en su sentido más amplio, es definido clásicamente como «el poder extremo de alguien, esfuerzos, habilidades, o la capacidad en contienda con un objeto de desaprobación». Dependiendo del objeto, que suele ser un enemigo visible y los aspectos cotidianos de uno mismo, las diferentes categorías de la Yihad son definidas:

Cuando es usada sin justificación alguna es entendida en su aspecto militar. También se refiere a los esfuerzos de un fiel por lograr la perfección religiosa y moral.

Hay dos clases de yihad:

La defensa del islam, de los musulmanes o de sus países frente al enemigo externo puede efectivamente adquirir el carácter de lucha militar o "guerra santa", y así se halla en el Corán, donde se anima a combatir contra los infieles si el islam resulta atacado:

La "Sharia" (literalmente: ‘el camino que conduce al abrevadero’), es la Ley Divina, en el sentido de que es la encarnación concreta de la Voluntad Divina que el hombre debería seguir tanto en su vida privada como en sociedad. En cada religión, la Voluntad Divina se manifiesta de un modo u otro y los mandamientos morales y espirituales de cada religión son de origen divino. Pero en el islam, la encarnación de la Voluntad Divina no solo es un conjunto de enseñanzas generales sino concretas. Al hombre se le dice no solo que sea caritativo, sino cómo serlo en circunstancias particulares de la vida. La Sharia contiene los mandamientos de la Voluntad Divina en su aplicación a cada situación de la vida. Es la Ley que Dios quiere que siga el musulmán en su vida. Por lo tanto, es la guía de la acción humana y abarca todas las facetas de la vida humana. Al vivir según la Sharia, el hombre coloca toda su existencia en "manos" de Dios. La Sharia, al tener en cuenta todos los aspectos de la acción humana, santifica la vida entera y le da un significado religioso a las actividades que podrían parecer más mundanales. En el islam, sharia es la expresión del divino destino «y constituye un sistema de deberes que son encargados a un musulmán en virtud de su creencia religiosa».

Los sabios musulmanes la interpretan como: «Los juicios que Dios determina para que el hombre sea feliz en esta vida y en la próxima».

Y los musulmanes la prefieren sobre cualquier sistema por lo siguiente:


Por consecuencia, creen que la diferencia entre la sharîah y los otros sistemas o leyes de los hombres es una diferencia como el Creador y Su Creación.

La ley islámica cubre todos los aspectos de la vida del musulmán. Aquellas leyes islámicas que están expresamente descritas en el Corán se denominan "hudud". Incluyen la prohibición del homicidio, relaciones sexuales extramaritales, consumo de alcohol y juegos de azar. El Corán también detalla leyes relacionadas con la herencia, el matrimonio, la compensación en los casos de homicidio o daños físicos, así como reglas para el ayuno, el azaque y la oración. Los preceptos y prohibiciones son interpretados en la práctica por los eruditos en religión o ulemas.

Según la opinión de chiita Los principios de la Ley contenidos en el Corán fueron explicados y amplificados en el Hadiz y la Sunna del Profeta, que constituyen la segunda fuente básica de la Ley. Éstos, a su vez, fueron entendidos con la ayuda del consenso de la comunidad islámica (iŷmâ‘). Finalmente, estas fuentes de la Ley fueron completadas por el razonamiento humano analógico (qiyâs) donde fue necesario. Según el punto de vista islámico tradicional, por lo tanto, las fuentes de la Sharî‘a son el Corán, el Hadiz, el iŷmâ‘ y el qiyâs, los dos primeros de los cuales son los más importantes y son aceptados por todas las escuelas jurídicas, mientras que los otros dos son considerados de menor importancia o bien son rechazados por alguna de las escuelas.

Otros aspectos legales son dirimidos por los "takzir" o jueces. Se les da el poder de dictar sentencia siempre que se atengan a los principios del Corán y la Sunna («tradición»). La ley islámica es directamente aplicable cuando la constitución del país involucrado así lo establece, como es el caso de Arabia Saudita o Irán. De otro modo, se aplica la legislación sancionada por el Estado, que, según el caso, puede coincidir en mayor o menor medida con la Shariah.

La principal fuente del islam es el Corán. Existe consenso entre todos los musulmanes sobre su autenticidad. En orden de importancia, sigue la "Sunna" o tradición: el conjunto de los hadices, que son dichos y hechos de Mahoma narrados por sus contemporáneos. Estos hadices son transmitidos por fuentes reconocidas y recopilados en distintas colecciones. En ellas se menciona la cadena de personas consideradas dignas de fe que transmitieron cada uno de los dichos o hechos expuestos. La tercera fuente es el consenso de la comunidad (ár. iyma' إجماع).

A diferencia del texto coránico, las colecciones de hadices no son unívocas. Se clasifican según su grado de verosimilitud. Unos son considerados exactos y genuinos; otros, "débiles" y apócrifos. Las distintas escuelas y vertientes a menudo no coinciden sobre la autenticidad de uno u otro hadiz. Hay colecciones que gozan de consenso muy generalizado, al menos dentro de la vertiente suní mayoritaria. Destacan los dos "Sahih", que significa "verdadero": el de Muslim y el de Al-Bujari.

Las colecciones más importantes de la tradición sunita son:


Alrededor del tiempo de estos recopiladores, surgen cuatro escuelas sunitas de interpretación, llamadas "madhhab". Se reconocen mutuamente entre sí. Se denominan "hanafí", por Abu Hanifah, "malikí", por Malik Ibn Anas, "shafi'í", por Al-Shafi', y "hanbalí", por Ahmad bin Hanbal. Estas escuelas tienen diferencias menores en la liturgia y a veces en la jurisprudencia, pero no difieren en lo que podría denominarse el "dogma" o doctrina.

Los libros generales de hadîz compilados que hoy se consideran el eje de referencia de la doctrina y las normas del Shiísmo son:


Este conforma el segundo conjunto de los compendios del "hadîz" que elaboró y ordenó la "Shî‘ah" a lo largo de la historia mediante sus raudos esfuerzos hasta los siglos cuarto y quinto de la hégira. Como ya hemos mencionado, fueron elaborados compendios de hadices durante la época de los imames en los siglos segundo y tercero, que se denominan «las primeras compilaciones», eso sumado a los "usûl al-arba‘mî’ah" (los cuatrocientos documentos elaborados directamente por los compañeros de los Imames Inmaculados) cuyo contenido fue trasladado al segundo conjunto de los compendios del hadîz.
Desde que la Ciencia del Hadîz fue siempre objeto de atención por parte de la Shî‘ah, de¬bido a ello, en los siglos y fueron elaboradas otras compilaciones del hadîz que no mencionamos para no extendernos. Las más famosas de estas compilacio¬nes son "Bihâr Al-Anwâr " (Los Mares de Luces) del ‘Al•lâmah Muham¬mad Bâqir Al-Maÿlisî, y "Wasâ’il Ash-Shî‘ah" (Los Medios de la Shî‘ah) de Muhammad Ibn Al-Hasan Al-Hurr Al-‘Âmilî.

Algunos eruditos musulmanes dicen que una nación islámica se basa en cuatro pilares:


En segundo lugar se sitúan los emires o príncipes, y a continuación le siguen el jeque, el alcalde y el imán. El islam no tiene sacerdotes, sino guías religiosos llamados imanes (ár. "imam" —religión—), que generalmente son nombrados por la propia comunidad. Existe de todos modos una serie de sabios, los "ulama", y alfaquíes, que tienen el mismo tipo de autoridad social y religiosa que el clero en otras religiones.

El islam está abierto a todos sin importar la raza, edad, creencias previas o sexo. Es suficiente ser creyente en los principios fundamentales del islam. Esto se realiza atestiguando la unicidad de Dios y la aceptación de Mahoma como profeta de Dios, recitando la "shahada" (testificación), lo cual debe hacerse sin coacción y sinceramente estando presentes otros musulmanes.

Todos los actos que el islam nos ha ordenado hacer, poseen indudables ventajas, y todos los actos que nos veda, tienen claras desventajas. Ninguno de los mandatos islámicos deja de tener una razón válida que los sustente. Por ejemplo, las cosas comestibles y bebibles (lícitas e ilícitas según la ley islámica), las relaciones legales, etc., tienen alguna ventaja o desventaja inherente, ya sea que exista alguna ley que les concierna o no. Las órdenes divinas se basan sobre esas ventajas o desventajas innatas.

Por ejemplo, las bebidas alcohólicas y las substancias narcóticas son dañinas, independientemente de lo que la ley islámica diga sobre ella. De igual manera, la usura es una gran trampa usada para la explotación económica. La adoración a Dios es purificante y vigorizadora. Si los intoxicantes y la usura están prohibidos es porque son malignos. Si el rezo u oración ha sido ordenado se debe a sus efectos benéficos sobre el ser humano.

Ali ibn Abi Talib, el primer imán de los chiitas, escribió una carta a Mâlik Al-Ashtar Al-Naja’í al designarlo gobernador de Egipto y sus provincias cuando el gobierno de Muhammad Ibn Abu Bakr estaba en peligro. Es el más largo compendio de instrucciones (en el "Nahyul Balâgha", "La cumbre de la elocuencia").

Muchos de los gobernadores creen que los consejos son los mejores consejos para los gobernadores.

Entre todas sus cartas ésta es la que contiene el mayor número de buenos consejos. 

Unas partes de sus consejos a su compañero, Mâlik:
¡Mâlik! Debes ser amable, compasivo y amar a tus súbditos. No te comportes (con ellos) como una bestia voraz y rapaz, considerándolos como una presa fácil, pues ellos una de dos: o son tus hermanos en religión, o se equiparan a ti en su creación (como seres humanos). Hombres de una y otra clase padecen de las mismas debilidades e incapacidades que se heredan en la carne, pecan y dan rienda suelta a sus vicios, ya sean intencional o involuntariamente, sin darse cuenta de la enormidad de sus actos. Deja que tu misericordia y compasión los rescate y los ayude de la misma manera que tú esperas que Dios te demuestre su misericordia y su perdón.

¡Mâlik! no debes olvidar jamás, que tú gobiernas sobre ellos, el Califa gobierna sobre ti y Dios es el Señor Supremo sobre el Califa. Y la realidad es que el Señor te ha elegido gobernador y te ha probado dándote la responsabilidad de gobernar. No pienses jamás en elevarte a un prestigio tan vano que te atrevas a declararle la guerra a Dios, porque no podrás evitar Su castigo y Su venganza. No podrás jamás liberarte de la necesidad de Su misericordia y compasión.

No sientas vergüenza de perdonar y olvidar. No te apresures a castigar y, no te enorgullezcas de tu poder de castigo. No te enfades ni pierdas la calma por los errores y fallas de aquellos a los que gobiernas; por el contrario, sé paciente y compasivo con ellos. El enojo y deseo de venganza no te ayudarán en tu administración.

Nunca digas: «Yo detento la autoridad, doy órdenes, y debo ser sumisa y humildemente obedecido». Porque tal pensamiento te trastornará y te hará vanidoso y arrogante, debilitará tu fe en la religión y te hará buscar el apoyo de cualquier otro poder distinto que el de Dios (tal vez, el de tu partido o el de tu gobierno).

Economistas islámicos presentan las siguientes particularidades de su sistema económico:


Si un hombre es rico puede ser el mejor musulmán al igual que el pobre, lo único que los distingue es su obediencia a Dios.

Se puede argumentar que la economía que existe en el islam no llega a ser una teoría económica, siendo solamente un sistema moral que se entiende que lo ofrece a sus creyentes, a quienes le pide que lo sigan.

En cambio, así como el islam exhorta a la gente a ser veraz, honesta, paciente y cordial, refrenándola de la falsedad y las peleas, de la misma manera la exhorta a ayudar al pobre, a no cometer injusticias, a no usurpar los derechos de otros y a no obtener dinero por medios ilegales. Así como ha ordenado el ayuno, la oración y la peregrinación, también ha prescripto el zakat como un acto meritorio compulsivo, para implementar su política de ayuda al pobre.

Todas estas leyes representan los requerimientos morales del islam y apuntan a la elevación moral de los musulmanes. No tienen el sentido de la invención de una teoría económica con vistas a organizar la sociedad.

El islam ha definido los confines de la justicia y ha establecido leyes generales para la vida en sociedad en los distintos campos de la producción, distribución de los bienes y relaciones mutuas. Ha descrito cualquier violación o rechazo de estas leyes y mandatos como injusticia y transgresión.

En el islam cada miembro de la sociedad tiene un conjunto de derechos y deberes. A todo ser humano que acepta esta religión se le exige que oriente su vida de acuerdo con estas reglas.

Es un libro moral se llama "Risalatul Huquq" (Tratado Sobre los Derechos), Ali ibn al-Husayn el cuarto imán de los chiitas en este libro expresó las tareas de los humanos, hay que hace el humano para Dios y la gente y él mismo. 

Algunos de los derechos enumerados en este tratado son:

De una manera general, la ley del islam impone cuatro clases de derechos y deberes en el hombre:




Sostener los vínculos de parentesco es uno de los mayores principios del islam y uno de los rasgos característicos del Derecho islámico.

En numerosas aleyas del Corán la orden de complacer a los padres está ligado después de la complacencia a Dios, Mahoma encomendó ser bondadoso con ellos aunque profesen una religión diferente, y la madre debe ser la primera persona en grado de importancia para el musulmán, debe de tratar bien a los amigos de sus padres y pedir por ellos ya después de su fallecimiento. Desobedecerlos es uno de los pecados mayores. Inclusive antes de partir al yihad tiene que gozar de su autorización.

En el Corán se describe que la vida matrimonial debe ser de la siguiente manera:



Muchas prácticas comprenden la categoría de "adab" islámico o de etiqueta. Esto incluye entre otros el saludo "salamu` alaykum" («la paz sea con vosotros»), diciendo "bismilah" («en el nombre de Alá»), antes de las comidas, y usan solo la mano derecha para comer y beber, respecto al aseo la mano izquierda, como sonarse la nariz. Las prácticas de higiene islámicas principalmente en la categoría de aseo personal y de la salud, como la circuncisión de los varones descendientes. Los rituales islámicos de entierro incluyen el "salat al-Janazah" («la oración fúnebre»), ya que bañan y envuelven el cadáver en un manto blanco y posteriormente lo colocan en la tumba. Los musulmánes, como los judíos, están restringidos en su dieta, y los alimentos prohibidos incluyen productos de cerdo, sangre, carroña y el alcohol. Toda la carne debe proceder de animales herbívoros sacrificados en el nombre de Dios por un musulmán, judío o cristiano, con la excepción del juego que uno tiene de caza o de pesca para uno mismo. La alimentación permisible para los musulmanes se conoce como alimentos halal.

El profeta del islam dijo: 

El creyente come teniendo presente el apetito de su familia, y la familia del hipócrita come teniendo presente la voracidad de él.
Imam Ali ibn Abi Talib, el primer imán de los chiitas dijo:

Empezad por la sal al inicio de vuestras comidas, puesto que si la gente supiera el beneficio de la sal la preferirían como medicamento probado.
Hay una larga lista de recomendaciones sobre el beber y el comer, provenientes de la Sunna o Conducta del Profeta del islam, Muhammad y retransmitidas por los sabios del Islam, como las siguientes escritas por el teólogo iraní Allamah Muhammad Baqir Ibn Muhammad at-Taqi al-Maylisi (1628-1699):


El velo es un valor de acuerdo con la naturaleza del ser humano. El exhibicionismo y el aumento de las relaciones íntimas entre los sexos es una acción en contra de la naturaleza, ya que contradice las peticiones humanas.
Dios, el Supremo en pro de la vida de la pareja formada por el hombre y la mujer y para que ellos puedan administrar sus asuntos en esta vida, ha establecido una orden correspondiente a su naturaleza.

Para los seguidores del islam, el puritanismo en la indumentaria es considerado como una orden de Alá, según establece su libro sagrado, el Corán, en el cual, Mahoma estableció lo que está permitido usar o no para los musulmanes, y aquello que es recomendable y lo que no lo es. Tanto el hombre como la mujer no deben vestir ropas demasiado justas ni provocativas a la vista de los demás, cuando se está frente a personas ajenas a su familia, a excepción de sus parejas.

Está plenamente prohibido que el hombre vista como mujer y viceversa.

Una de las consecuencias más polémicas de indumentaria islámica es uso prescriptivo de prendas femeninas que cubren totalmente el rostro de la mujer y que a veces son rechazadas en los territorios no islámicos por los no musulmanes, como es el caso del velo o el burka.

Algunos defensores del islam responden a esta acusación argumentando que el islam "mira" a las mujeres como si fueran joyas. Afirman buscar su protección de los ojos lujuriosos y de los corazones perversos como es el caso de los violadores, ya que el islam evita los medios que lleven a un perjuicio grave para la sociedad, reduciendo con esto el número de adulterios, la fornicación y las violaciones. Estos argumentos pueden resultar ofensivos para los habitantes de países donde hay minorías islámicas, ya que consideran que van en contra de los derechos de la mujer. Basándose en su moral religiosa, establecen taxativamente que si cualquier hombre desea a una mujer, no tiene otro recurso sino el matrimonio; por ello es el único lazo que hace lícita la unión del hombre con la mujer y permite todo aquello que antes era prohibido, puesto que para el islam el matrimonio es la única vía para que la mujer y el hombre puedan gozar uno del otro.

La palabra "imam" o imán (en árabe, إمام) denota una persona que se mantiene o camina «delante». Para el islam sunita, la palabra se utiliza comúnmente para referirse a una persona que dirige el curso de la oración en la mezquita. También significa que el jefe de una escuela de jurisprudencia ("escuela de pensamiento"). Sin embargo, desde el punto de vista de los chiitas esto es simplemente el básico entendimiento de la palabra en la lengua árabe y, para su uso religioso propio, la palabra «imam» se aplica solo a los miembros de la Casa del Profeta designados como infalible por el imán anterior.

Los chiitas creen que el Profeta del islam fue ordenado por Dios a nombrar a su sucesor, al que la gente debe obedecer. Este sucesor fue el imán Ali Ibn Abi Talib y después de él el imán Hasan y Husayn.

Los chiitas duodecimanos (Izna-´ashari) creen que después del Husayn, nueve de sus descendientes fueron nombrados como sus sucesores. El duodécimo de ellos, el imán Mahdi se encuentra oculto a las miradas y un día se levantará para establecer la Justicia en el mundo.
El imán es una personalidad conductora única, y su función entre Dios y sus siervos consiste en preservar los asuntos devocionales de la religión divina, así como los éticos y sociales. Él es por cierto un modelo perfecto para la humanidad y una merced universal (general para todos). Es quien con su capacidad puede conducir el desarrollo humano hacia la perfección; y por esto es obligatorio para el siervo creyente obedecer sus órdenes e imitarlo en todo asunto. Es el ejemplo racional y perfecto para la educación tanto del individuo como de la sociedad en general; y en particular es además alguien cuyos antecedentes biográficos son un ejemplo para una formación excelente del individuo islámico.

La mayoría de los sabios de la escuela sunni sostienen que la Imamah y la jilafah no difieren en nada en cuanto a su significado, pues son términos sinónimos que tienen un significado único, a saber la responsabilidad suprema, social y religiosa, que se le confiere a alguien de parte de la ummah (comunidad islámica universal). Y él (el califa o imán) consigue ese cargo sin importar si se lo selecciona o elige para ello. El sentido es que el califa responde por la licitud de las cuestiones religiosas, y con el poder militar custodia las fronteras del territorio y la seguridad general. Según esto entonces el imán es un jefe ordinario, un simple gobernante dedicado a aplicar la justicia social y la preservación de la seguridad del territorio y nada más; tarea para lo cual desde luego es elegido.

Lo que más distingue a la escuela de Ahlul Bayt de las otras escuelas islámicas es el concepto del Imamah, o la inmediata sucesión del Profeta Muhammad. La escuela de Ahlul Bayt cree que el oficio del imán es un oficio divino —significa que, el imán o califa (líder) tiene que ser designado directamente por Dios, este oficio es tan importante como el de la profecía—. La gente ha sido comandada de este modo por Dios a seguir sucesores específicos (Imames) después del fallecimiento del Profeta. 
La sucesión —Califato o Imamah— es designada solamente por Allah, en repetidas ocasiones esto es mencionado en el sagrado Corán. En la escuela de Ahlul Bayt, el califato se refiere no solo al poder temporal y a la autoridad política sobre el pueblo, mucho más, se refiere a la autoridad para ejercerlo. Esta autoridad debe provenir de Dios ya que Él se atribuye el Gobierno y el Juicio a sí mismo.

Entre los chiíes, el término imán, aparte de referirse al guía de una comunidad, es el título que ostentaban los jefes supremos de toda la comunidad chií (el equivalente al califa suní), cargo hereditario cuyo último representante, Muhammad al Mahdi, según la tradición, «desapareció» en el año y vive desde entonces oculto (el mahdi o imán oculto), rigiendo desde la sombra los destinos de la comunidad (creencia sostenida por la mayor parte de los chiíes, denominados imamíes).
Lista de los más renombrados imanes chiíes:


Hay diferentes puntos de vista de acuerdo a la enseñanza del Corán respecto a otras religiones. Existen grupos no musulmanes que enfatizan la siguiente azora que indica:

En cambio, los musulmanes consideran que juzgar al islam en partes es como un lector que, al leer, se tapa un ojo y no quiere leer con el otro, ya que hay textos que reprenden este acto. Además en el Corán, en la vida de Mahoma y en la historia del islam, también hay ejemplos para la misericordia con los no musulmanes.

El islam afirma que todos los profetas han sido musulmanes y que ninguno de ellos afirmó que su religión haya sido el judaísmo o el cristianismo, por lo tanto creen que Abraham no era judío ni cristiano. Asimismo aseguran que Moisés y Jesús predicaron el islam.

De la misma manera el Corán indica en la azora:

Los musulmanes han respetado a los judíos y a los cristianos como «gente del libro», pero aseguran que han abandonado el monoteísmo y corrompido las sagradas escrituras. El islam tolera a judíos y cristianos, pues les está permitido vivir y practicar su religión en territorios musulmanes, aunque tienen que pagar un impuesto especial, la "yizia", sustitutiva del azaque. Está prohibido el uso de la fuerza para convertir al incrédulo al islam.

La apostasía está penada (con la muerte) bajo la ley islámica según se indica en la Sura XVI, 106:
Sin embargo, los no musulmanes sufren persecución en ciertos países islámicos, y así lo muestran determinados informes del Human Rights Watch. Por ejemplo, los Ahmadis en Arabia Saudí o en Indonesia; cristianos y bahaíes en Irán; cristianos en Egipto, cristianos y animistas en Sudán, etc.

La Península arábiga en las centurias previas a la llegada de Mahoma estaba escasamente poblada por habitantes de habla árabe, la mayoría eran beduinos, pastores nómadas organizados por tribus. Aunque hasta el , amplias zonas desérticas en la actualidad, como el territorio de Banu Hanifa en Arabia Central, producían suficiente cereal como para generar asentamientos de agricultores. Tradicionalmente la zona más fértil se situaba en el sur de Arabia, la actual Yemen, conocida como la Arabia feliz. Este potencial agrario permitió trascender la organización tribal y dio lugar a la aparición de auténticos reinos, que desarrollaron toda una infraestructura hidráulica, que permitió cierto desarrollo demográfico en la región. En el norte el comercio también permitió el desarrollo de ciertos centros urbanos, la futura Medina cobró importancia como enclave estratégico entre las rutas caravaneras del norte. La Meca hizo lo propio, pero como centro de peregrinación en torno a la Kaaba. Más al norte, como puentes de contacto entre los grandes imperios en guerra permanente, el Imperio bizantino y el Imperio persa, fueron surgiendo estructuras estatales, los reinos de gassaní y lajmí.

El aumento de la conflictividad bélica entre el norte y sur de Arabia en los años previos a Mahoma, no se debió como sugiere la historiografía tradicional a un enfrentamiento entre quaysíes y yemeníes, árabes del norte y sur respectivamente, sino a enfrentamientos entre las diferentes tribus del norte y del sur, fruto de la presión demográfica. En este contexto, bajo la durísima vida que impone el desierto, la "asabiyya" o solidaridad tribal fue fundamental en la supervivencia y desarrollo posterior del islam. Esto favoreció que la mayor parte de la Península arábiga se organizase en tribus y clanes, al margen de una estructura estatal (excepto lo mostrado en el párrafo anterior), aunque a través del "Kisrá", un texto generado por la embajada persa en Arabia, muestra cómo va surgiendo, progresivamente, una identidad árabe que se irá superponiendo a la tribal.

En ese tiempo, la mayoría de los árabes eran seguidores de las religiones politeístas, aunque unas pocas tribus seguían el judaísmo, el cristianismo (incluido el nestorianismo) o zoroastrianismo. La ciudad de La Meca era un centro religioso para algunos politeístas árabes norteños, ya que contenía el muro sagrado del Zamzam y un pequeño templo, la Kaaba.

 
La historia del islam comienza en la Arabia en el con la predicación del profeta Mahoma, seguida de la violenta conquista de los mayores Estados de la época: el imperio persa sasánida, buena parte del Imperio romano y el reino visigodo.

Omar fue sucedido por Uthman ibn Affan, otro de los primeros seguidores de Mahoma. Bajo Uthman, el Nuevo califato se vio sumido en una guerra civil a la que se le llamó la Fitna, o desorden. Muchos de los familiares y primeros seguidores de Mahoma estaban descontentos con Uthman, porque sentían que estaba favoreciendo indebidamente a sus parientes y actuando menos como un líder religioso y más parecido a un rey. Soldados rebeldes mataron a Uthman y ofrecieron el liderazgo a Ali ibn Abi Talib, el primo y yerno de Mahoma. El período del califato de Ali ibn Abi Talib fue aquel en que asumió directamente la carga y dirección de la comunidad. Fue una etapa extremadamente importante para el Estado Islámico pues intentó, en un lapso de tiempo muy corto, poner en práctica su concepción de gobierno, de la sociedad civil, de los lazos que unían a sus miembros así como de su concepción de la vida doctrinaria, intelectual y espiritual de la comunidad.
Ali murió a manos de un asesino jariyí, y los omeyas reclamaron el califato. Ellos lograron retener el liderazgo de la mayoría de los musulmanes por varias generaciones, pero salvo por un breve período, nunca volvieron a gobernar sobre un imperio islámico no dividido. La fe islámica divergió también, separándose en las principales de la actualidad: los suníes y los chiíes.

En la historia del islam existen diversas dinastías que se disputaron los califatos o el liderazgo del islam y muchos Estados islámicos que ofrecían una mínima o ninguna obediencia al califa.

No obstante, el imperio de los califas abasíes y el de los turcos selyúcidas se contaban entre los más poderosos de su época. Después de la desastrosa derrota de los bizantinos en la batalla de Manzikert en 1071, la Europa cristiana llevó a cabo diversas cruzadas. Tras la Primera Cruzada, los occidentales lograron capturar y gobernar por algún tiempo Jerusalén. Saladino, sin embargo, restableció la unidad islámica en el Oriente Próximo y derrotó a los chiíes fatimíes.

Entre los siglos y , uno de los más poderosos imperios fue el Imperio de Malí, cuya capital era Tombuctú. Sin embargo, esta cultura estuvo profundamente pautada por la árabe (incluso en el idioma), no siendo realmente original.
En el , hubo tres grandes imperios musulmanes: el otomano en torno a Turquía, Oriente Próximo, el Mediterráneo y los Balcanes; el safaví en Irán, Iraq, la Armenia histórica, el Cáucaso y Afganistán; y el mogol en el Indostán. En el , estos imperios habían caído bajo la dominación del poder político y económico de Europa. Después de la Primera Guerra Mundial, el remanente del Imperio otomano fue dividido en protectorados o esferas de influencia europeas. El islam y el poder político del islam han experimentado un resurgimiento en el , en buena medida gracias al petróleo. Sin embargo, las relaciones entre Occidente y cierto número de Estados de mayoría musulmana siguen siendo precarias cuando no tensas.

Luego de las pérdidas posteriores a la primera guerra mundial, los restos del Imperio otomano son esparcidos con los protectorados europeos. Desde entonces la mayoría de las sociedades musulmanas se han convertido en naciones independientes, y han adquirido prominencia nuevos temas, como la riqueza petrolera y las relaciones con el Estado de Israel.

El "dinar" es la unidad monetaria de diversos Estados del mundo, la mayoría de los cuales de lengua árabe o que antiguamente habían formado parte del Imperio otomano, ya que históricamente fue usado en tierras musulmanas. La palabra «dinar» (دينار en árabe y en persa) tiene el mismo origen que dinero, puesto que deriva del denario romano.

Era una antigua moneda musulmana de oro que se empezó a acuñar a finales del en Al-Andalus y que tenía un peso que, según las épocas, oscilaba entre los 3,85 y 4,25g. En sus inicios imitaba los modelos bizantinos, pero pronto adquirió carácter propio y definido, hasta el punto de que fue imitado fuera de los territorios califales.

Estados que usan actualmente el dinar como moneda:


El "dirham" o "dirhem" (en árabe: درهم) era una antigua moneda de plata utilizada en varios puntos del mundo islámico que valía la décima parte del dinar de oro. El nombre "dirham" procede del griego "dracma" (δραχμή). Las monedas actualmente en circulación con este nombre son el dírham marroquí y el dírham de los Emiratos Árabes Unidos.

Si bien el más famoso movimiento del islam en tiempos recientes ha sido el fundamentalismo islámico, existen diversas corrientes liberales que ven como alternativa el alinear al islam con los tiempos contemporáneos.

Este movimiento no está dirigido a cuestionar los fundamentos del islam, sino que trata de aclarar malas interpretaciones o abrir paso a la renovación del islam como un centro moderno de pensamiento y libertad.

Según el World Factbook de la CIA, en el año 2005 el islam era la segunda religión con más seguidores en el mundo, un 19.9 % de la población mundial. Es asimismo la religión que está creciendo más rápidamente, hecho atribuible principalmente al mayor crecimiento demográfico en los países musulmanes, así como a las conversiones al islam como religión monoteísta.

La población musulmana se estima que excede los 1200 millones de personas. Solamente el 18 % de los musulmanes son étnicamente árabes; otro 20 % se encuentra en la región del sur del Sahara en África, y el 30 % en el subcontinente indio (sumando los fieles de Pakistán, Bangladés y la India). El país con la población de musulmanes más grande del mundo es Indonesia, con casi 200 millones de fieles. También hay importantes grupos musulmanes en China, Europa, Asia Central y Rusia.

En Europa, Austria fue el primer país en reconocer el islam como una de sus religiones oficiales, mientras que Francia es el país europeo con mayor población de musulmanes: seis millones, que representan un 10 % de su población total.

Se dice que esclavos que llegaron a América con los conquistadores españoles introdujeron el islam en esta región, se establecieron en países como Brasil, Venezuela, Panamá y Colombia.

En España hay alrededor de un millón de musulmanes, mientras que la comunidad más grande de musulmanes en Latinoamérica se encuentra en Brasil. En Argentina está localizado el Centro Islámico Rey Fahd que es el más grande de Latinoamérica. En Colombia la mezquita de Omar Ibn Al-Jattab en Maicao, La Guajira; en Caracas existe la mezquita Ibrahim, en México la mezquita Dar as Salam, cerca de la ciudad de México y en el caso de Chile, la mezquita As-Salam en Santiago, la mezquita Mohhamed VI en Coquimbo y la mezquita Bilal en Iquique.

Los lugares santos del islam son tres: las ciudades de La Meca y Medina, así como la Mezquita de Al-Aqsa en Jerusalén.

La Meca es la ciudad a donde los musulmanes por lo menos tienen que peregrinar una vez en su vida si tienen la capacidad de hacerlo, en la Biblia es mencionada como "Padan-aram" (Parán=Mecca), en ella nació Mahoma y se halla Masjid al-Haram, donde rezar en ella se considera como tener la recompensa de 100000 oraciones.
En esta mezquita está localizada la Kaaba, templo construido por el profeta Abraham e Ismael, el Pozo de Zamzam, considerado por milagroso por los musulmanes desde el tiempo en que le fue revelado a Agar, ya que provee a miles de personas en todo el país y cada peregrino bebe de él, En los alrededores se encuentra Mina y el Monte Arafat, donde Mahoma pronunció su sermón de despedida frente a más de 100000 personas y el permanecer ahí está considerado como un pilar en la peregrinación.

Medina es un lugar muy querido por los musulmanes, ya que recibió al profeta Mahoma cuando emigró de La Meca, le dio refugio, recibió y aceptó su mensaje, sus habitantes fueron conocidos como los "Ansar" por haberlo acogido y hacer vencer al islam, temas sobre los que todos los musulmanes están de acuerdo. Mahoma transmitió que en ella se duplica la recompensa de las buenas acciones, una oración en la Mezquita del profeta tiene la recompensa de 1000 oraciones. También dijo que a su entrada hay ángeles que la protegen de las epidemias y que le prohibirán la entrada al Falso Mesías (con el nombre árabe de Al-Dayal) al igual que La Meca.

Mahoma la declaró como sagrada y dijo que expulsa a la mala gente como el fuelle de fragua expele a las impurezas del hierro, y debido a la elevada posición que fue concedida a esta ciudad y a sus habitantes, informó que Dios los defiende y maldice a todo aquel que los amenace injustamente. Aconsejó vivir y morir en ella, dijo que la fe en esta ciudad vuelve como una serpiente vuelve a su cueva. En Medina es donde Mahoma murió y fue enterrado.

Se encuentra en Jerusalén, la tradición musulmana relata que es el lugar donde Mahoma ascendió a los cielos. En el cielo le fueron presentados los profetas y conoció a Abraham, Moisés y Jesús entre otros. Posteriormente se comunicó con Dios interponiéndose una gran luz entre ellos y le fue establecida la oración.

A este acontecimiento se le llama "Al-Israh wa Al-Miray" (‘viaje nocturno y ascensión’), el capítulo 17 del Corán habla de ello y el rezar en la Mezquita de Al-Aqsa equivale a la recompensa de 500 oraciones.

Tanto los chiitas como los suníes comparten una cierta veneración y obligaciones religiosas hacia ciertos santuarios y lugares sagrados, como La Meca, Medina y Mezquita de Al-Aqsa pero la mezquita del Imán Alí y la mezquita del Imán Hussein también son veneradas. Después de La Meca y Medina, Nayaf y Kerbala son las ciudades más sagradas para los chiitas.

Erróneamente se piensa que el verde es el color del islam, pero esto no es cierto; más adelante se explicará el origen de esta confusión. Creen que la adoración a símbolos u objetos materiales va en contra del monoteísmo. Mucha gente piensa que la estrella y la luna creciente simbolizan el islam, pero esto tampoco es cierto. Eran, simplemente, el símbolo del Imperio otomano y no del islam. El color verde también se asocia frecuentemente con el islam por costumbre, sin que tenga significado religioso alguno. Sin embargo, los musulmanes a menudo usan azoras caligrafiadas para decorar las mezquitas o sus casas propias.

El panarabismo tradicionalmente ha utilizado el rojo, el blanco, el verde y el negro en las banderas de diversos países de población mayoritariamente musulmana, por lo que dichos colores a veces se confunden con los colores del islam. Estos colores pueden observarse en las banderas de Yemen, Egipto, Sudán, Irak, Siria, Sahara Occidental y Palestina. El color rojo simboliza la sangre de los mártires y también fue el color de la dinastía Hachemí. El color blanco fue empleado por la dinastía de los omeyas y el verde por el califato fatimí. El negro fue el color del califato abasí. Su único símbolo, usado en guerras, es la media luna.

El calendario islámico comienza con la Hégira, es decir, la emigración de Mahoma de La Meca a Medina. Ese año equivale al 622 del calendario gregoriano. Los años del calendario lunisolar pueden tener 354 o 355 días. Por eso, para establecer un año islámico, no basta con restar 622 años al calendario gregoriano.

Los días festivos islámicos, basados en el calendario lunisolar, se celebrarían en distintas fechas cada año si los lleváramos al calendario gregoriano.

Los musulmanes tienen dos festividades: Eid al-Fitr (en árabe: عيد الفطر, ‘banquete de caridad’) y Eid al-Adha (en árabe: عيد الأضحى, ‘celebración del sacrificio’), otros agregan el día viernes.





Estas dos festividades las celebran los creyentes visitando los hogares y comiendo los platos especiales cocinados para esta ocasión. Todos se sientan juntos. Por tradición los niños reciben regalos, las gratificaciones y los dulces entregados por sus seres queridos como símbolo de amor. La forma de desear una feliz fiesta es pronunciando las palabras: ¡Eid Mubarak!

La Arquitectura islámica es un término amplio que agrupa los estilos religiosos propios de la cultura islámica desde los tiempos de Mahoma hasta nuestros días, influenciando en el diseño y construcción de edificios y estructuras por todo el mundo. Asimismo, la arquitectura islámica manifiesta la adaptación del estilo arábigo a las culturas y técnicas con las que toma contacto, desde el vasto aporte helenístico y bizantino en Oriente Próximo, África y Anatolia, hasta el visigótico en al-Andalus, o el hindú al Oriente.

La arquitectura islámica de todos los períodos y de todas las regiones tiene un rasgo distintivo: la armonía y la belleza. El dicho del Mensajero de Dios, Muhammad: «Dios es Bello y Ama la Belleza», habla de la fuerte ligazón que existe en el islam entre arte y espiritualidad.

Los tipos principales de construcciones de la arquitectura islámica son la mezquita, la tumba, el palacio y el fuerte; aunque también destacaron edificaciones de menor importancia como los baños públicos, las fuentes y la arquitectura doméstica.

Se dice que la columna, el arco y la cúpula son la «Santísima Trinidad» de la arquitectura islámica, ya que las tres juntas son características que le dan belleza y originalidad.

En 630 el ejército de Mahoma reconquistó la ciudad de La Meca para la tribu de Quraish. El santuario santo de Kaaba fue reconstruido y dedicado al islam; la reconstrucción fue llevada a cabo antes de la muerte de Mahoma en 632 por un náufrago carpintero abisinio en su estilo nativo. Este santuario estuvo entre los primeros trabajos de gran envergadura del islam. Las paredes fueron decoradas con pinturas de Jesús, María, Abraham, profetas, ángeles y árboles. Después las doctrinas del islam a partir del , basadas en el Hadiz, prohibieron el uso de ese tipo de imágenes en su arquitectura, especialmente seres humanos y animales.

En el las fuerzas musulmanas conquistaron extensos territorios. Una vez que se establecían en la región, primero necesitaban un lugar donde construir una mezquita. El diseño simple, basado en la casa del profeta Mahoma, proveyó de elementos que fueron incorporados a las nuevas mezquitas y otras construcciones por los primeros musulmanes, o lo adaptaron a edificios ya existentes como iglesias para su propio uso.

La caligrafía árabe está asociada con el arte geométrico islámico del arabesco en las paredes y también en los techos de las mezquitas, así como en los textos escritos. Muchos artistas contemporáneos en el mundo islámico dibujan basándose en la herencia de la caligrafía árabe para utilizar inscripciones y abstracciones caligráficas en su trabajo.

El árabe engloba en un solo término ("jatt") las nociones de escritura y las de caligrafía, hecho que se explica por el carácter sagrado de una lengua que es la del Sagrado Corán. Pocas civilizaciones han llevado el arte de la caligrafía a un rango tan elevado como lo han hecho los musulmanes. 

La caligrafía ha comenzado a ser la más venerada forma de arte islámico porque constituye un enlace entre la lengua de los musulmanes y su religión. El libro sagrado del islam, el Corán, ha jugado un rol muy importante en el desarrollo y evolución de la lengua árabe, y por extensión, en la forma de escribir el alfabeto árabe, es decir, en su caligrafía. Proverbios y amplios pasajes del Corán siguen siendo fuentes activas para la caligrafía islámica.

En el islam hay diferentes denominaciones religiosas que son esencialmente similares en la creencia, pero tienen diferencias teológicas y legales importantes. Las mayores ramas del islam son los suníes (o sunitas) y los chiíes. El sufismo no es una rama, sino una derivación esotérica del islam. Distintas cofradías y órdenes practican esta versión del islam.

Cerca del 90 % de los musulmanes son suníes (solo son minoría frente a los chiíes duodecimanos en Irán, Irak y Líbano). Creen que Mahoma fue un profeta, un ser humano ejemplar y que deben imitar sus palabras y actos en la forma más exacta posible, pues el Corán indica que el profeta Mahoma es un buen ejemplo a seguir. Los hadices describen sus palabras y actos, constituyendo el principal pilar de la doctrina suní.

Los musulmanes chiíes, la segunda rama mayor del islam, difieren de los suníes en que rechazan la legitimidad de los tres primeros califas. Siguen los preceptos de hadices diferentes a los de los suníes y tienen sus propias tradiciones legales. Los eruditos chiíes tienen mayor autoridad que los suníes y mayor amplitud para la interpretación del Corán y de los hadices. Los imanes desempeñan un papel fundamental en la doctrina chií. La principal vertiente chií es la escuela ya`farí (llamada así en honor de su fundador, Ya`far as-Sadiq) o escuela chií duodecimana, cuyo nombre deriva de los doce imames o líderes infalibles que reconocen después del fallecimiento de Mahoma. Aun así, todos tiene en común la creencia en Ali ibn Abi Talib, o Imam Ali como el sucesor del Profeta, y la sucesión de este último por sus dos hijos: primero su hijo el Imam Hasan y luego su hijo Husayn.
Los chiitas existen en la mayoría de los países islámicos, pero la mayoría de ellos se encuentran en Irán, Irak, Azerbaiyán, India, Paquistán y el Líbano.

En sentido no estricto, se denomina también chiíes a sectas tales como las del grupo ismailí, entre ellas los seguidores del Aga Jan, localizados principalmente en el Subcontinente Indio, los alawitas de Siria, los zaídes del Yemen, etc.

El sufismo es una práctica que tiene seguidores entre los suníes y los chiíes. Según la mayoría de los autores suníes, es el camino de la práctica del tercer aspecto del islam, el "ihsan" o perfección espiritual. Por otro lado, puede decirse que su objetivo es el esfuerzo por adquirir las características del siervo o ser humano perfecto ("insan al-kamil" o "abd al-kulli"). Enfatizan varios aspectos espirituales, como el perfeccionamiento de la fe, el estado de rememoración divina continuo ("dhikr"), la purificación del ego ("nafs") a través de determinadas prácticas espirituales. La mayoría de sus seguidores se organizan en cofradías (tariqa en árabe) sufíes. No obstante, hay algunas de ellas que no pueden incluirse dentro de esas dos ramas, como es la bektashi u otras, como las de aparición en Europa y América, que pertenecen a movimientos "new age".

El sufismo está presente en el mundo islámico desde su Occidente, en países como Senegal, hasta su Oriente, como por ejemplo Indonesia, así como en países europeos o americanos.

Los jariyíes o jariyitas (en árabe خارجي plural خوارج, "jāriyī", plural "jawāriy") son una de las tres ramas principales del islam, junto a la de los chiíes y los suníes.

La palabra "jariyí" significa «el que se sale», en referencia a la deserción que protagonizaron en el año 657 cuando abandonaron el bando de Ali Ibn Abi Talib al aceptar este en el campo de batalla de Siffín un arbitraje entre él y su adversario, el omeya Muawiya.

A diferencia de los suníes, que consideraban que el califa debía ser un árabe miembro de la tribu de Quraish, y de los chiíes, que consideraban que debía ser Ali o un descendiente directo suyo, los jariyíes pensaban que la dignidad califal emana de la comunidad, que debe elegir libremente al más digno «aunque sea un esclavo negro».

Hoy en día, continuada tan solo por los ibadíes de Omán, donde son mayoría, y prácticamente extinta en el resto del mundo islámico.

Ahmadía es un movimiento de reforma islámico (con raíces Suníes). La comunidad ahmadía nació en la India en 1889 y es practicada en la actualidad por entre 10 y 20 millones de musulmanes alrededor del mundo. Su fundador fue Mirza Ghulam Ahmad (1791-1876), quien afirmaba haber cumplido las profecías en relación con la venida del 'Imán Mahdi' y el 'Mesías Prometido.' Tras la muerte del primer sucesor de Ghulam Ahmad, la comunidad ahmadía se dividió en dos, ambos grupos defendiendo que su fundador se había declarado profeta, pero mientras para el grupo "Lahori" (fundado por Maulama Muhammad Ali en Lahore) Ghulam Ahmad fue un reformador (Mujaddid), y también el Mesías prometido y Mahdi, su estatus profético es el de un místico o Sufista y no en el sentido técnico teológico, para el grupo dirigido por Bashir-ud-Din Mehmud (hijo y sucesor de Ghulam Ahmad), en cambio, el fundador había sido un profeta "zilli", es decir, reflejo del original. 

Buena parte de los musulmanes consideran que los ahmadía no son musulmanes, y les consideran herejes por creer en que la institución de los profetas ha continuado después de la muerte de Mahoma. Si bien los Ahmadíes han sido objeto de discriminación y persecución religiosa desde el comienzo del movimiento en 1889, la labor misionera de este grupo, explica que buena parte de las primeras mezquitas construidas en países occidentales, hayan sido construidas por los ahmadíes.

El Alevismo Bektashi es una tradición islámica local sincrética y heterodoxa, cuyos adherentes siguen las enseñanzas místicas ("bāṭenī") de Alí y de Hacı Bektaş-ı Veli. El alevismo incorpora creencias turcas presentes durante el Siglo XIV, como el chamanismo y el animismo, mezcladas con creencias chiitas y sufíes, adoptadas por algunas tribus turcas. 

Ibadía es una secta que se remonta a los primeros días del Islam y es una rama del Islám Jariyista. Es practicada por alrededor de 1.45 millones de musulmanes alrededor del mundo. Los ibadíes constituyen la mayoría de la población de Omán. A diferencia de la mayoría de grupos Jariyitas, el Ibadismo no considera a los musulmanes pecadores como no creyentes. 

El Mahdavismo, conocido como "Zikri" en Pakistán, es una secta islámica Mahdiista fundada por Syed Muhammad Jaunpuri en la India a finales del Siglo XV. Syed Muhammad se declaró a sí mismo como Imán Mahdi en la ciudad sagrada de La Meca, frente a la Kaaba en 1496, y es reverenciado como tal por la comunidad de Mahdavíes alrededor del mundo, principalmente en la India.

El coranismo es una denominación o conjunto de denominaciones que asume la perspectiva que la ley y guía islámicas deberían basarse solamente en el Corán, oponiéndose así a la autoridad religiosa, confiabilidad y/o autenticidad de la literatura de los hadices. Los coranistas creen que el mensaje de Dios en el Corán es claro y completo como está, y que por tanto puede entenderse perfectamente sin referencia a los hadices. 

El término "musulmán no denominacional" se usa por y para todos los musulmanes que no pertenecen o no se auto-identfican con una denominación islámica específica. Entre las figuras más prominentes que se rehúsan a identificarse con una denominación islámica en particular se encuentran Jamal ad-Din al-Afghani, Muhammad Iqbal y Muhammad Ali Jinnah. Encuestas recientes reportan que grandes proporciones de musulmanes en algunas partes del mundo se identifican como "simplemente musulmanes," si bien no existen muchos análisis publicados respecto a las motivaciones de tales respuestas. El Pew Research Center reporta que las personas identificándose como "simplemente musulmanes" constituyen una mayoría de musulmanes en siete países (y una pluralidad en tres otros), con la proporción más grande en Kazajistán, con un 74%. Al menos uno de cada cinco musulmanes en al menos 22 países se identifican de esta manera.

Algunos movimientos como los Drusos, los Barghawata y los Ha-Mim, surgieron del Islam o llegaron a compartir ciertas creencias del Islam y si cada uno corresponde a una religión independiente o una secta del islam es ocasionalmente motivo de controversia. El Yazdanismo es visto como una mezcla de creencias locales kurdas y doctrinas islámicas sufíes introducidas en Kurdistán por el jeque Adi ibn Musafir en el Siglo XII. El Babismo surgió del Imamismo chiita transmitido por Báb, en tanto que uno de sus seguidores, Mirza Hussein-'Alí Nurí o Bahá'u'lláh fundó el Bahaísmo. El Sijismo, fundado por Gurú Nanak a finales del Siglo XV en el Punyab, incorpora aspectos tando del Islam como del Hinduismo. Movimientos musulmanes afro-americanos incluyen la Nación del Islam, la Nación del 5% y los Científicos Moros (fundados por Noble Drew Ali). 

Lista de musulmanes por países.

Nota importante: La población contada por afiliación religiosa, como la mayoría de las características demográficas de la población, están basadas en ciencias estadísticas, sujetas a error observacional y están técnicamente referidas como estimaciones. El porcentaje de población musulmana en cada país fue extraída del estudio del Departamento de Estado de los Estados Unidos titulado "International Religious Freedom Report 2004" . Otras fuentes usadas fueron el CIA World Factbook y Adherents.com . En algunos casos de estimaciones conflictivas, se ha calculado el promedio entre las estimaciones más altas y más bajas. La población total de cada país fue tomada de census.gov (estimaciones del 2005).

Estos porcentajes fueron calculados usando las cifras siguientes. El primer porcentaje, cuarta columna, es el porcentaje de la población que es musulmana en una región (Musulmanes en la región * Población total de la región). La última columna muestra la población musulmana comparada a la población musulmana total del mundo (Musulmanes en la región * Población musulmana total del mundo). 

"(Nota: Egipto, Sudán y los países del Magreb se cuentan como parte de África del Norte, no de Oriente Medio.)"

El islam ha sido criticado desde sus etapas formativas. Las primeras críticas escritas procedían de los cristianos, antes del , que veían al islam como una herejía del cristianismo. Los objetivos de la crítica incluyen:

Desde noviembre de 2013, en Angola el islam está catalogado como «secta peligrosa» junto a otras 200 cultos religiosos y está prohibido. Desde entonces han sido cerradas o derrumbadas 87 mezquitas.

Sobre el islam:
Sobre las instituciones islámicas:

Sobre la práctica del islam en distintos países:


</doc>
<doc id="6707" url="https://es.wikipedia.org/wiki?curid=6707" title="Carica papaya">
Carica papaya

Carica papaya es una especie de planta arbustiva del género "Carica" en la familia Caricaceae. Su fruto se conoce comúnmente como papaya, papayón, olocotón, papayo, mamón, lechosa o lechoza .

"Carica" del griego “karike”, nombre de una higuera. Papaya, deriva del maya “páapay-ya” que significa zapote jaspeado. Pertenece a la familia de las Caricaceae. La planta de papaya es una especie arborescente perennifolia.

Se trata de una verdura tronco generalmente no ramificado (sólo se ramifica si dicho tronco es herido), cultivado presenta una altura entre 1,8 y 2,5 m coronado por un follaje de hojas largamente pecioladas. El mismo conserva aún en los individuos maduros una textura suculenta y turgente, escasamente leñosa, y presenta numerosas cicatrices características, producto del crecimiento y caída consecutivas de las hojas. La savia es de consistencia lechosa (de aquí su nombre de «lechosa»), y tóxica en estado natural para el humano, pudiendo producir irritaciones alérgicas con el contacto con la piel. Esta savia lechosa contiene una enzima muy útil, la papaína, empleada como ablandador de carnes: en las parrillas o barbacoas se emplea el jugo que fluye al cortar la corteza de la papaya verde para rociarlo sobre la carne a la cual deja sumamente tierna y jugosa.

Las hojas son alternas, aglomeradas en el ápice del tronco y ramas, patentes, de 25-75 cm de diámetro, lisas, más o menos profundamente palmeadas con venas medias robustas, irradiantes; la base es profundamente cordada con lóbulos sobrepuestos; hay de 7-11 lóbulos grandes, cada uno con la base ancha o un tanto constreñido y acuminado, ápice agudo, pinatinervado e irregularmente pinnatilobada. El haz es de color verde oscuro o verde amarillo, brillante, marcado en forma visible por las nervaduras hundidas de color blanco amarillento y las venas reticuladas; por debajo es de color verde amarillento pálido y opaco con nervaduras y venas prominentes y visibles; el pecíolo es redondeado de color verde amarillento, teñido con morado claro o violeta, fistular, frágil, de 25-100 cm de largo y 0,5-1,5 cm de grueso.

Los arbustos de papayo tienen tres clases de pies diferentes; unos con flores femeninas, otros con flores hermafroditas y otros con flores masculinas. Las flores femeninas tienen un cáliz formado por una corona o estrella de cinco puntas muy pronunciada y fácil de distinguir. Encima de éste se encuentra el ovario, cubierto por los sépalos; estos son cinco, de color blanco amarillo, y cuando muy tiernos, ligeramente tocados de violeta en la punta; no están soldados. Los estigmas son cinco, de color amarillo, y tienen forma de abanico. Los frutos de este pie son grandes y globosos. Las flores hermafroditas tienen los dos sexos y el árbol que las posee tiene a su vez tres clases de flores diferentes. Una llamada pentandria, parecida a la flor femenina, pero al separar los pétalos se aprecian cinco estambres y el ovario es lobulado. Los frutos de esta flor son globosos y lobulados. Otro tipo de flor es la llamada elongata y tiene diez estambres, colocados en dos tandas; la flor es alargada y de forma cilíndrica, al igual que el ovario, dando frutos alargados. El último tipo de flor es la intermedia o irregular, no es una flor bien constituida, formando frutos deformes.

Las flores masculinas crecen en largos pedúnculos de más de medio metro de longitud y en cuyos extremos se encuentran racimos constituidos por 15 - 20 florecillas. Las flores están formadas por un largo tubo constituido por los pétalos soldados, en cuyo interior se encuentran 10 estambres, colocados en dos tandas de a cinco cada una. La flor tiene un pequeño pistilo rudimentario y carece de estigmas. Estas flores no dan frutos, pero si lo hacen son alargados y de poca calidad. Los frutos y las flores se desarrollan en racimos justo debajo de la inserción de los tallos de las hojas palmeadas.

Los frutos poseen una textura suave y una forma oblonga, y pueden ser de color verde, amarillo, naranja o rosa. Pudiendo pesar hasta 20 kg, en la mayoría de los casos no suelen pesar más de 500 o 600 g, especialmente en una variedad de cultivo de plantas enanas, muy productivas y destinadas generalmente a la exportación, por su mayor duración después de la cosecha y antes de su consumo. La talla de los frutos disminuye en función de la edad de la planta. Baya ovoide-oblonga, piriforme o casi cilíndrica, grande, carnosa, jugosa, ranurada longitudinalmente en su parte superior, de color verde amarillento, amarillo o anaranjado amarillo cuando madura, de una celda, de color anaranjado o rojizo por dentro con numerosas semillas parietales y de 10 - 25 cm o más de largo y 7-15 cm o más de diámetro. Las semillas son de color negro, redondeadas u ovoides y encerradas en un arilo transparente, subácido; los cotiledones son ovoide-oblongos, aplanados y de color blanco.

No es planta exigente en cuanto a suelos, pudiendo desarrollarse en cualquier terreno abandonado o incluso en alguna maceta grande. Es una de las plantas más productivas con relación a su tamaño ya que siempre tiene flores y frutos al mismo tiempo. El desarrollo de los frutos produce la caída de las hojas inferiores, por lo que quedan siempre al descubierto por debajo de las hojas.

Es una especie originaria de Mesoamérica. En México se distribuye por el Golfo desde Tamaulipas hasta la Península de Yucatán, por el Pacífico se le encuentra desde Baja California a Chiapas. En la actualidad se encuentra cultivada en todas las regiones tropicales de América, desde México a Argentina y Brasil, naturalizada en los trópicos del Viejo Mundo.

Es conocido desde épocas antiguas que las plantas, al igual que cualquier otro ser vivo, no se distribuyen uniformemente en la superficie terrestre y que cada una de ellas ocupa unos territorios determinados. "Carica papaya" es una planta de origen centroamericano, conocida y empleada en casi toda América desde hace varios siglos, aunque hoy día se cultiva en muchos países de otros continentes, principalmente, en Asia y África. Antes de la llegada de los europeos, en México se le daba el nombre "chichihualtzapotl", que en náhuatl significa «zapote nodriza», y era un fruto especialmente relacionado con la fertilidad.
Actualmente la planta de la papaya se cultiva en la mayoría de los países de la zona intertropical del orbe, siendo los primeros países productores: India, Brasil, Indonesia, Nigeria y México (datos de FAO, 2013).

La especie presenta dioecia naturalmente, pero la selección artificial ha producido especímenes hermafrodita América Central (Sur de México). Actualmente se cultiva en Puerto Rico, Florida, Hawái, Costa subtropical de Granada (España), Islas Canarias, África Oriental, Sudáfrica, Ceilán, India, Argentina, Colombia, Ecuador, El Salvador , Guatemala , Paraguay, Perú, Chile, Venezuela, Costa Rica, Archipiélago Malayo, Bolivia y Australia.

Puede crecer en lomeríos y cañadas, prospera en toda la tierra caliente en un clima tropical o subtropical, desde el cálido más seco de los subhúmedos hasta la variante húmeda del clima subhúmedo. La humedad y el calor son condiciones esenciales para su buen desarrollo y fructificación. Crece y se desarrolla desde el nivel del mar hasta los 1500 msnm. La precipitación media es de 1,500 a 2500 mm anuales y la temperatura media anual de 20 a 25º C. Desarrolla en diferentes clases de suelo siempre que sean fértiles, blandos, profundos y permeables con un pH de 5,5 a 6.

Esta excelente fruta se cultiva en terrenos de muy distinta naturaleza, pero es fundamental que estos sean ricos en materia orgánica y que contengan una humedad abundante. El papayo es una planta tropical, puede cultivarse desde el nivel del mar hasta los 1000 msnm, pero los frutos de mejor calidad y los rendimientos más altos se obtienen en altitudes por debajo de los 800 msnm. 

A continuación se analizan los factores climáticos más importantes que influyen de manera decisiva en el desarrollo de este cultivo, así como las características principales que debe tener un suelo para que el cultivo produzca de manera exitosa.

La humedad y el calor son las condiciones esenciales para el buen desarrollo del papayo. Requiere zonas de una pluviometría media de 1800 mm anuales y una temperatura media anual de 20-22 ºC; aunque puede resistir fríos ligeros, si no tiene la cantidad suficiente de calor, se desarrolla mal y los frutos no llegan a madurar. No se debe cultivar en áreas propensas a heladas o a temperaturas por debajo de la de congelación ya que éstas provocarían la muerte del vegetal. Las noches frescas y húmedas ocasionan que la fruta madure lentamente y resulte de mala calidad. En cuanto al viento, lo soporta bien ya que su tallo es muy flexible y a él se le unen los pecíolos de las hojas y los pedúnculos de las flores, siendo difícil que se desprendan. Los fuertes vientos pueden dañar algunas hojas pero no flores ni frutos.
La temperatura es el factor climático limitante, que permite que este frutal se desarrolle, o no. El rango de temperatura es entre 22 y 30 °C, pero su óptima es entre 23 y 26 °C. Las temperaturas bajas inhiben su crecimiento y las temperaturas altas le provocan abscisión floral y bajas en la producción. Canículas y sequías especialmente en la floración ocasionan su caída y la planta llega a suspender su crecimiento.
El agua es el contribuyente principal de la planta; alrededor del 85% está compuesta por agua. La papaya, tanto en el proceso de germinación, vivero y primeros meses después de plantada, necesita para su crecimiento y desarrollo una gran cantidad de agua, por lo cual en esta fase se deben realizar riegos semanales. En la época seca y cuando la lluvia no es adecuada, se debe recurrir al riego para mantener las plantas con un buen desarrollo.
La papaya necesita abundante luz debido a su gran actividad fotosintética. Es imposible desarrollar plantaciones con restricciones de luz, pues las plantas serían alargadas y amarillas, sintomatología esta de desnutrición, lo que trae como consecuencia un inadecuado desarrollo de la planta

Por ser una planta herbácea de pecíolos largos, tiende a ser sensible a la acción de los vientos. Por tanto si se cultiva en zonas donde se presenten vientos fuertes, son necesarias las barreras rompevientos, usándose de preferencia árboles nativos (guasima o caulote) y vegetación con propiedades que tienen la función de hacer una barrera de retención de plagas como lo es el paraíso y el nim.

Las principales características que debe reunir un suelo para este cultivo son las siguientes:
suelto y húmedo; con buen drenaje; alto contenido de materia orgánica; pH que fluctúe entre seis y siete; suelos fértiles y profundos.

El suelo también puede ser mejorado, por lo cual no es de los factores más preocupantes cuando se planifica una plantación. El papayo se desarrolla en suelos ligeros, fértiles (ricos en humus), blandos, profundos y permeables. Al tener sus tallos y raíces blandos y esponjosos, debe cultivarse en terrenos con buen drenaje, ya que en suelos demasiado húmedos y compactos, se pudrirán las raíces.
Las mejores producciones se presentan entre los 0 y 800 msnm.

En Mesoamérica se encuentra de forma silvestre y cultivada, en el resto de otros países solo está presente de forma cultivada. No es una especie que se ubique en alguna categoría de la norma 059 de la SEMARNAT de México.

La papaya es conocida como fruta de consumo, tanto en forma directa como en jugos y dulces (elaborados con la fruta verde cocinada con azúcar), y tiene unas magníficas propiedades para facilitar la digestión de alimentos de difícil asimilación, debido a su alto contenido de papaína. De esta enzima llamada papaína se producen más 100000000000 toneladas anuales en el mundo entero. La utilidad de dicho producto derivado está en la fabricación de cerveza, cosméticos e industria alimenticia.

Es eupéptico-digestivo, coadyuvante de la cicatrización; antiinflamatorio, antihelmíntico.
Las semillas son vermífugo, emenagogo. Especialmente interesantes contra ancylostomas, áscaris, trichuris y strongyloides.

Indicado para dispepsias hiposecretoras. Prevención de la arteriosclerosis y tromboembolismos. Parasitosis intestinales. Tópicamente es usado para heridas y ulceraciones tróficas con restos inflamatorios o necróticos, forúnculos.

Al manipular la papaína en polvo se deben proteger los ojos, por la posibilidad de producción de ulceraciones corneales, debidas a su acción queratolítica.

Se usa el látex, obtenido por incisión de los frutos.

Es uno de los frutos más importantes y de mayor consumo. Muy apreciada por sus propiedades nutritivas y su delicado sabor. Ideal para regímenes, por contener vitaminas B1, B2 y niacina o B3, todas del Complejo B, que regulan el sistema nervioso y el aparato digestivo; fortifican el músculo cardíaco; protegen la piel y el cabello y son esenciales para el crecimiento. Contiene también vitaminas A y C, es rica en minerales como calcio, fósforo, magnesio, hierro, azufre, silicio, sodio y potasio. Por otra parte tiene bajo valor calórico, cerca de 40 cal/ 100 g de fruta. El contenido de fibra mejora la digestión. Tiene propiedades astringentes.

Asimismo, su cáscara contiene la sustancia papaína, que tiene múltiples usos. La papaya también es un fuente de licopeno, conteniendo unas 1800 μg cada 100 g.

El fruto es usualmente consumido crudo, sin su cáscara y sus semillas. El fruto verde inmaduro de la papaya puede ser consumido en ensaladas y estofados. Posee una cantidad relativamente alta de pectina, la cual puede ser usada para preparar mermeladas.

La papaya verde es usada en la cocina Thai ya sea cruda o cocinada. 

Las semillas negras tienen un sabor fuerte pero son comestibles. Algunas veces son molidas y usadas como sustituto de la pimienta negra. En algunas partes de Asia, las hojas jóvenes de la papaya son hervidas y consumidas como espinaca. En algunas partes del mundo las hojas son preparadas como té para ser consumidas como prevención de la malaria, aunque no existe evidencia científica real de la efectividad de este tratamiento.

En Cuba es costumbre consumirla madura (muchos le agregan azúcar) pero como también se elaboran dulces con ella, se emplean las maduras y las pintonas (ni verdes ni maduras).

La zona de la Región de Coquimbo del centro norte de Chile (Ovalle, La Serena), es famosa por su producción de papayas chilenas o "Chilean carica", de la variedad "Carica candamarcensis" o "Pubescens", que se caracteriza por ser muy aromática, de color amarillo, tamaño pequeño, piel delgada y de alto valor nutritivo-funcional: enzima papaína que complementa la digestión y asimilación de proteínas, eliminación de toxinas del sistema digestivo, fibra para la eliminación de azúcar, vitamina C como antioxidante.

En el noreste argentino y sur de Paraguay es muy común consumir la papaya o "Mamón" (como se denomina en la zona) cruda, con un poco de azúcar o preparada en almíbar, en un proceso de hervido con azúcar y bicarbonato por varias horas. El producto final es exquisito y se acompaña con algún queso en el postre. Cabe destacar que dicho producto también se consume en Venezuela (donde se le da el nombre de "dulce de lechosa") mayormente en época de Navidad. Se sustituye el azúcar por panela (papelón) y se añaden clavos de olor. También en este último país se consume el fruto maduro como fruta, en licuados o "batidos" y en batidos con leche o "merengadas".

En algunas partes del mundo, las hojas de papaya se convierten en té como tratamiento para malaria, pero el mecanismo no se conoce; y, no se ha demostrado científicamente ningún método de tratamiento basado en tales resultados.

Hay ya varios estudios científicos serios que demuestran y comprueban varias de las propiedades de las hojas de papaya, que; preparadas en infusión, ayudan a combatir la malaria. Según un estudio realizado en el 2016 por Oche Okpe et al. del departamento de Bioquímica en la Universidad de Agricultura en Makurdi, Nigeria, los hallazgos demostraron que después de inocular interperitonalmente con células rojas parasitadas con a un grupo de ratones y posteriormente administrándoles extractos de hoja de papaya hubo una reducción en la carga parasítica y se indujo la recuperación de las células hepáticas frente a la congestión de pigmentación negra. Por lo tanto, este estudio resaltó la importancia del uso de la planta en la medicina tradicional como remedio contra la infección de la malaria.

La papaya libera líquido de látex cuando no está maduro, lo que puede causar irritación y reacciones alérgicas, en algunas personas. Por su color blanquecino se le denomina "lechosa" en países como Venezuela y República Dominicana.

Se realiza mediante esquejes obtenidos de las ramificaciones del arbolito de forma artificial, ya que el papayo no se ramifica hasta que tiene tres o cuatro años. Los árboles viejos sufrirán la operación de desmoche o eliminación de la cabeza o cogollo del árbol, provocando así la producción de ramas o cogollos laterales.
Los esquejes serán los brotes de 25-30 cm que se cortan y se cauterizan con agua caliente a unos 50 °C. Estos esquejes se plantan en macetas que se colocan en lugares protegidos de los rayos solares y con humedad hasta la emisión de raíces.
Este método de propagación es muy laborioso y costoso ya que implica el mantenimiento de plantaciones de más de tres años para la obtención de plantas madre.

Es la forma más económica y fácil de propagar el papayo. Se obtendrán distintos resultados, según se empleen semillas procedentes de árboles femeninos fecundados con papayos masculinos o semillas procedentes de árboles femeninos y hermafroditas.
El poder germinativo de las semillas del papayo suele ser corto, por lo que se hará una siembra lo más cerca posible a la época de recolección. Esta siembra puede ser directa sobre el terreno o previa en semillero. La siembra en semillero se hará empleando macetas de turba y plástico negro de 10 cm de diámetro y 15 cm de profundidad.
La tierra del semillero deberá mantenerse húmeda, cuando las plantas tengan unos 10-15 cm (unos dos meses después de la siembra) de altura se trasplantarán al terreno de cultivo

"Carica papaya" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 1036. 1753.

Recibe este fruto distintos nombres en América así:





</doc>
<doc id="6710" url="https://es.wikipedia.org/wiki?curid=6710" title="Johann Wolfgang von Goethe">
Johann Wolfgang von Goethe

Johann Wolfgang von Goethe (; Fráncfort del Meno, 28 de agosto de 1749-Weimar, 22 de marzo de 1832) fue un poeta, novelista, dramaturgo y científico alemán, contribuyente fundamental del Romanticismo, movimiento al que influyó profundamente.

En palabras de George Eliot (1819-1880) fue «el más grande hombre de letras alemán... y el último verdadero hombre universal que caminó sobre la tierra». Su obra, que abarca géneros como la novela, la poesía lírica, el drama e incluso controvertidos tratados científicos, dejó una profunda huella en importantes escritores, compositores, pensadores y artistas posteriores, siendo incalculable en la filosofía alemana posterior y constante fuente de inspiración para todo tipo de obras. Su novela "Wilhelm Meister" fue citada por Arthur Schopenhauer como una de las cuatro mejores novelas jamás escritas junto con "Tristram Shandy", "La Nouvelle Heloïse" y "Don Quijote". Su apellido da nombre al Goethe-Institut, organismo encargado de difundir la cultura alemana en todo el mundo.

El propio Goethe narró su vida en un libro autobiográfico, "Poesía y verdad" (1811 y ss.), que llega hasta el año 1775, cuando se pone al servicio del príncipe heredero Carlos Augusto en Weimar.

Nació en Fráncfort del Meno ("Frankfurt am Main"), hijo de Johann Caspar Goethe, un abogado y consejero imperial que se retiró de la vida pública y educó a sus hijos él mismo, bajo la máxima de no perder el tiempo en lo más mínimo, y de Katharina Elisabeth Textor, hija de un antiguo burgomaestre de Fráncfort. Estas vinculaciones familiares le pusieron en contacto desde el principio con el patriciado urbano y la vida política.

De inteligencia superdotada y provisto de una enorme y enfermiza curiosidad, hizo prácticamente de todo y llegó a acumular una omnímoda o completa cultura. En primer lugar estudió lenguas, aunque sus inclinaciones iban por el arte y nunca, a lo largo de toda su vida, dejó de cultivar el dibujo; al tiempo que escribía sus primeros poemas, se interesó por otras ramas del conocimiento como la geología, la química y la medicina.

Goethe estudió Derecho en Leipzig (1765); allí conoció los escritos de Winckelmann sobre arte y cultura griegas, pero una grave enfermedad le obligó a dejar los estudios en 1768 y volver a Fráncfort. Katharina von Klettenberg, amiga de su madre, le cuidó y le introdujo en el misticismo pietista, que ponía su énfasis en el sentimiento dentro de la confesión protestante; por entonces compuso sus primeros poemas. Retomó los estudios en 1770 en Estrasburgo y los concluyó al año siguiente. Esos dos años allí fueron muy importantes para él: conoció a Friederike Brion, que le inspiró la mayoría de sus personajes femeninos, y trabó amistad con el teólogo y teórico del arte y la literatura Johann Gottfried von Herder. Herder le introdujo en la poesía popular alemana, le descubrió el universo de Shakespeare y le liberó definitivamente del Neoclasicismo francés y de la confianza en la razón de la "Aufklärung" (Ilustración) alemana.

Empezó a hacer prácticas de abogacía en Wetzlar y colaboró con Herder en la redacción del manifiesto fundador del movimiento "Sturm und Drang" («Tempestad e ímpetu»), considerado el preludio del Romanticismo en Alemania: "Sobre el estilo y el arte alemán" (1772). En esta obra se reivindica la poesía de James MacPherson (Ossian) y de Shakespeare. Otra vez de vuelta en Fráncfort, escribió la tragedia "Götz von Berlichingen" (1773) y al año siguiente su novela "Las penas del joven Werther" (1774). La inspiración del "Werther" la había encontrado a mediados de 1772, cuando hacía prácticas de abogacía en el tribunal de Wetzlar: se había enamorado de Charlotte Buff, novia y prometida de su colega, también abogado en prácticas, Johann Christian Kestner, y Karl Wilhelm Jerusalem, otro abogado atormentado por un amor no correspondido, se suicidó utilizando una pistola prestada por Kestner. Goethe unió ambas historias para su novela "Werther", en parte epistolar, y alcanzó un éxito tan grande al representar en la figura del protagonista el desencanto de las jóvenes generaciones, que suscitó una epidemia de suicidios de adolescentes en el país.

El mismo año que el "Werther" (1774) Goethe publica su drama "Clavijo" mientras intentaba abrir con poca fortuna un bufete de abogado en Fráncfort, y en la primavera de 1775 se comprometió con la hija de un banquero de la ciudad, Lili Schönemann. Sin embargo, las diferencias sociales y de estilo de vida entre ambas familias terminaron por desbaratar este compromiso, que no llegó a formalizarse en matrimonio. El noviazgo terminó en el otoño de ese mismo año y, ansioso de escapar de este ambiente, no dudó en aceptar la invitación a la Corte de Weimar de Carlos Augusto de Sajonia-Weimar-Eisenach, heredero del ducado de Sajonia-Weimar. Tras publicar su "Stella" (1775), marchó inmediatamente hacia Weimar, huyendo prácticamente de dos cosas: el compromiso sentimental con Lili Schönemann y el ejercicio de la abogacía.

Al servicio del príncipe heredero Carlos Augusto fijará su residencia en Weimar ya hasta su muerte. No obstante, las numerosas tareas que este le encomendaba le hicieron abandonar la literatura durante casi diez años, a pesar de que Ana Amalia de Brunswick-Wolfenbüttel, madre de Carlos Augusto, había empezado a crear un círculo de intelectuales con el preceptor de su hijo, Wieland, y lo amplió al incluir en él a Goethe y posteriormente a intelectuales tan destacados como Herder y Friedrich von Schiller; fugazmente pasaron también por allí Jakob Michael Reinhold Lenz y Friedrich Maximilian Klinger. Goethe destacó enseguida y pasó de ser consejero secreto de legación (1776) a consejero secreto (1779), y finalmente se convirtió en una especie de ministro supremo. Otra de sus funciones fue la supervisión de la Biblioteca ducal, que bajo su dirección llegó a ser una de las más importantes de toda Alemania.

Inicia en esa época sus investigaciones científicas. Interesado por la óptica, concibió una teoría distinta a la de Isaac Newton sobre los colores y también investigó en geología, química y osteología, disciplina esta última en que descubrió el hueso intermaxilar en marzo de 1784, que pone una de las primeras piedras en la teoría de la evolución del hombre, aunque en esto se le adelantó por muy poco el anatomista francés Vicq d'Azyr, lo que le supuso una gran frustración. Las cartas a Charlotte von Stein dan fe de esta época de su vida, envuelta en todo tipo de encargos y gestiones para reformar el muy pequeño y humilde Estado de Weimar.

Desde un puesto tan importante tuvo la oportunidad de relacionarse con la alta aristocracia y conoció a personajes notables, como Napoleón Bonaparte, Ludwig van Beethoven, Friedrich von Schiller y Arthur Schopenhauer. En 1782 fue añadida la partícula "von" a su apellido por el mismo Duque Carlos Augusto pese a las protestas de la nobleza, para formar parte de la Corte con un cargo equiparable al de los restantes ministros, pertenecientes todos a ella.

Ingresó en la Masonería el 11 de febrero de 1783, aunque según el escritor masónico Lorenzo Frau Abrines, la fecha de su ingreso es anterior, el 23 de junio de 1780, dentro de la efímera logia "Amalia", que abatió columnas dos años después. En 1830, dos años antes de su muerte, Goethe compuso un poema titulado "Para la fiesta de San Juan de 1830 en ocasión de celebrarse su cincuentenario como miembro de la masonería." A su condición de masón y a su paso por la Masonería, así como a otras aficiones que al parecer cultivó, se atribuye influencia en su obra, especialmente en "Fausto."

Por otra parte, seguía profundizando en el estudio del teatro de William Shakespeare y de Pedro Calderón de la Barca, algunas de cuyas obras (por ejemplo, "El príncipe constante" de Calderón) hace representar con éxito como encargado del teatro en la Corte de Weimar; en estas funciones empezó a cartearse con Schiller. Las lecturas teatrales de estos autores amplían notablemente los horizontes de su espíritu. Le domina además el entusiasmo ante la falsa poesía céltica de Ossian y escribe un famoso monólogo del gran dios del Romanticismo, "Prometeo", que personificaba el genio rebelde de los creadores y del cual se sintió justamente orgulloso: 

Así fue en efecto, en lo referido al movimiento conocido como titanismo, uno de cuyos más preclaros representantes fue Giacomo Leopardi. Merced a Goethe, Weimar se convirtió en el auténtico centro cultural de Alemania; allí compuso poemas inspirados por Charlotte von Stein y empezó la redacción de sus obras más ambiciosas, como sus dramas "Ifigenia en Táuride" (1787) "Egmont" y "Fausto", que luego revisaría a fondo tras la profunda impresión que recibió en su trascendental viaje a Italia (1786-1788), que cambió su desequilibrada estética romántica por el equilibrio clásico. Empezó en Venecia, donde compuso sus "Epigramas venecianos", y terminó en Roma, donde estudió la cultura grecolatina a fondo; de esta época son sus "Elegías romanas". El viaje a Italia supone el comienzo de su periodo clásico.

Sin embargo, a su regreso a Weimar en 1788 se encuentra una gran oposición a su nueva estética, el llamado Clasicismo de Weimar; es más, se forma un cierto escándalo cuando llega a divulgarse que desde ese mismo año vive amancebado con una jovencita, Christiane Vulpius (1765-1816), que le dio al año siguiente un hijo, Julius August Walther von Goethe (1789-1830); cuatro abortos sucesivos posteriores inducen a creer que entre ambos había incompatibilidad de grupos sanguíneos, en aquella época desconocida. Goethe legitimó a su único hijo en 1800.

No abandonó completamente su pretensión de labrarse una carrera científica. En "Zur Farbenlehre", 1810, intentó refutar con poca fortuna la teoría de los colores de Newton. En el primer volumen de esta obra se halla la que es sin duda la primera historia comprensiva de la ciencia.

Dirigió el Teatro ducal entre 1791 y 1813 y con motivo de este cargo conoció en 1794 al dramaturgo Friedrich von Schiller, con el que sostuvo una luenga amistad y cierta correspondencia epistolar hasta la muerte de este en 1805. Schiller publicó las hasta entonces inéditas "Elegías romanas" de Goethe en su periódico, "Las Horas", en 1795. También imprimió la novela "Los años de aprendizaje de Wilhelm Meister" (1796) y la novela en verso "Hermann y Dorothea" (1798). Schiller incitó a Goethe a que prosiguiera en la gran obra de su vida, el "Fausto", poema que no paraba de corregir y ampliar y cuya primera versión apareció en 1808. Desde dos años antes se hallaba ya casado con Christiane Vulpius, quizá para acallar a quienes criticaban su estilo de vida. El hecho más importante quizá de esta época de su vida es su entrevista en Erfurt con Napoleón I en 1808, cuando el ejército francés ocupaba parte del territorio prusiano en el marco de las guerras Napoleónicas.

La Revolución francesa supuso para Goethe un gran trastorno. Algunos de sus epigramas venecianos ya tratan este tema, pero como su pensamiento se hallaba por completo imbuido del equilibrio y armonía del clasicismo y veía el ser como una totalidad orgánica a partir de la filosofía de Kant, el desarrollo de la revolución y el cambio provocado por la violencia le parecían una atrocidad. Eso se plasmó en algunas obras de entonces, como la colección de novelitas breves "Conversaciones de emigrados alemanes" (1795), la obra épica "Germán y Dorotea" (1797) y la tragedia "La hija natural" (1799 y ss.). Algo después aparecen las novelas de madurez: "Las afinidades electivas" (1809) y "Los años de peregrinaje de Wilhelm Meister" (1821, revisado en 1829), así como un diario de su viaje por Italia, "Viajes italianos" (1816), su autobiografía "Poesía y verdad" en varias entregas (1811-1833) y un poemario, "Diván de Oriente y Occidente" (1819), donde se deja sentir algo el influjo de la poesía oriental. Goethe murió en Weimar el 22 de marzo de 1832. La versión final de su gran poema coral "Fausto" apareció póstuma ese mismo año.

En cuanto a su carrera literaria, Goethe la inició en el seno de un exasperado Romanticismo deudor del "Sturm und Drang", cuya obra más representativa se encargó de escribir él mismo: "Las cuitas del joven Werther". El viaje a Roma supuso para él ir arrinconando esa estética en una evolución que le hizo al cabo renegar del Romanticismo e identificarse con el equilibrio clásico grecolatino, lo que puso fin a su tormentosa vida interior. Fue esa la revelación del Clasicismo, verdadera raíz con la que podía identificarse la cultura alemana. «"Ahora comprendo el sentido del mármol"», escribirá en una de sus "Elegías romanas".

De ese viaje por Italia son fruto también los "Epigramas venecianos", entre los cuales hay algunas meditaciones profundas sobre la contemporánea Revolución francesa o el significado de la vida y de la cultura. La postura política de Goethe es, sin embargo, conservadora: «"prefiero la injusticia al desorden"», escribirá. Eso le supuso algunos recelos por parte de otros artistas a los que no les importaba en lo más mínimo no acordarse con su contexto social, como por ejemplo Beethoven. En las dos versiones de su complejo y grandioso "Fausto" se encuentra el último mito que fue capaz de engendrar la cultura europea, el de cómo la grandeza intelectual y la sed omnímoda de saber pueden, sin embargo, engendrar la miseria moral y espiritual. Por otra parte, en la lectura y estudio de Spinoza encuentra también un consuelo al desequilibrio romántico que le embargaba, como cuenta en "Poesía y verdad", donde se extiende en comentar especialmente su frase de que «"quien bien ama a Dios, no debe exigir que Dios le ame a él"».

Goethe disfrutó ya en vida de fama, respeto, prestigio y admiración. Delacroix le retrató en una litografía en 1827, aparte de ilustrar "Fausto" y "Götz von Berlichingen". Por ello, fueron muchos los jóvenes de su época que quisieron conocerle en persona o, como suele decirse pedantemente: "vera effigies". Por otra parte, su secretario, Eckermann, anotaba cuidadosamente sus conversaciones con el maestro a lo largo de los años y escribió unas "Conversaciones con Goethe", donde aparecen reflejadas las opiniones que en sus últimos años sostuvo sobre esas visitas y también sobre todo lo divino y lo humano. El filósofo George Santayana escribió sobre él:

La mejor obra dramática de Goethe es sin duda el "Fausto", que ha pasado a ser una obra clásica de la Literatura Universal. La primera versión, el "Urfaust" o "Fausto original", estaba acabada en 1773. Pero el autor la siguió retocando hasta 1790, año en que publicó un fragmento; ya en abril de 1806 estaba completo, pero las guerras napoleónicas demoraron dos años la publicación hasta 1808; la segunda versión o segunda parte sólo sería publicada en 1833, un año después del fallecimiento del autor. La tragedia "Fausto" original se articula en torno a dos centros fundamentales; el primero es la historia de cómo Fausto, fatigado de la vida y decepcionado de la ciencia, hace un pacto con el diablo que le devuelve la juventud a cambio de su alma; el segundo es la historia de amor entre Fausto y Gretchen, también llamada Margarita, que Mefistófeles manipula de forma que Fausto llegue al homicidio —mata al hermano de su amada— y Gretchen tenga un embarazo indeseado, que le conduce primero al infanticidio y luego a ser ejecutada por asesinar a su hijo. 

La historia empieza en el cielo, donde Mefistófeles hace un pacto con Dios: dice que puede desviar al ser humano favorito de Dios (Fausto), que está esforzándose en aprender todo lo que puede ser conocido, lejos de propósitos morales. La siguiente escena tiene lugar en el estudio de Fausto donde el protagonista, desesperado por la insuficiencia del conocimiento religioso, humano y científico, se vuelve hacia la magia para alcanzar el conocimiento infinito. Sospecha, sin embargo, que su intento no está obteniendo resultados. Frustrado, considera el suicidio, pero lo rechaza cuando escucha el eco del comienzo de la cercana Pascua. Va a dar un paseo con su ayudante Wagner y es seguido a casa por un caniche vulgar. En el estudio de Fausto el caniche se transforma en el diablo. Fausto hace un trato con él: el demonio hará todo lo que Fausto quiera mientras esté en la tierra, y a cambio Fausto servirá al demonio en la otra vida. El trato incluye que, si durante el tiempo que Mefistófeles esté sirviendo a Fausto este queda complacido tanto con algo que aquel le dé, al punto de querer prolongar ese momento eternamente, Fausto morirá en ese instante. Tras este marco, Goethe desarrolla las dos historias: la relación entre Mefistófeles y Fausto y la de Fausto y Gretchen/Margarita.

El tema general es cómo la riqueza de conocimiento material acarrea sin embargo la miseria moral y espiritual. La historia de Fausto se inspira, como muchas leyendas, en hechos ciertos. Existió un tal Johann Faust que nació hacia 1490 en el sur de Alemania y se doctoró en la Universidad de Heidelberg en 1509. Tras dejar la universidad, emprendió una vida de aventuras marcada por una huida constante a causa de las múltiples acusaciones de brujería que se le hicieron. Dejó una biblioteca que incluía libros de medicina, matemáticas y magia negra. Esta pintoresca vida dio origen a la leyenda popular, aprovechada por autores de piezas de títeres y marionetas, y había servido además para inspirar leyendas populares. El primer libro sobre este mito se editó en 1587 por parte de Johannes Spiess, quien, en su prólogo, advirtió que había omitido referir fórmulas mágicas para evitar que quienes tuvieran el libro fueran acusados de brujería. Otros libros y libretos teatrales trataron el tema del pacto con el diablo para lograr el dominio sobre la naturaleza: en el teatro de títeres de los siglos y , la historia se cerraba siempre con los demonios llevándose a Fausto, pero Goethe alteró este argumento haciendo que se salvara Gretchen al final de la primera parte, anticipando la salvación de Fausto al término de la segunda, cuando los demonios que quieren llevarse su alma tienen que retirarse ante la llegada de una legión de ángeles. Además Goethe cambia el impulso que mueve a Fausto: el deseo que lo acercaba a la brujería no es codicia, maldad o vagancia, sino el ansia de saber, el deseo de grandeza, de plenitud, de totalidad. La moraleja que acaso tenga la obra será que ese deseo de conocimiento conlleva la miseria moral.

La obra ha sido interpretada modernamente por Walter Benjamin, por Thomas Mann en su novela "Doktor Faustus" y por el hijo de este, Klaus Mann en "Mephisto", en la que concibe el pacto con el diablo como una metáfora del pacto de Alemania con Hitler.


El pensamiento científico de Goethe, como el literario, es también muy original. Aunque a menudo ha sido considerado como uno de los representantes más destacados de la "Naturphilosophie", en realidad su producción científica se sitúa entre el romanticismo y el clasicismo, desmarcándose, por ejemplo, de los excesos especulativos de Schelling.
La morfología de Goethe se construye en torno a dos conceptos nucleares: el tipo y la metamorfosis: 

En "La metamorfosis de las plantas" ("Versuch die Metamorphose der Pflanzen zu erklären"), publicada en 1790, Goethe presenta todas las estructuras vegetales como variaciones de la hoja, entendida como una estructura ideal. Goethe comienza con los cotiledones, a los que considera hojas imperfectas. Estos últimos, bajo la influencia generativa y cada vez más refinada de la savia, se metamorfosean en los sépalos, los pétalos, los estambres y los pistilos. De este modo, todos los órganos vegetales se conciben como apéndices idénticos, variedades de un apéndice vegetal abstracto, que difieren entre sí por su forma y grado de expansión.

Sus ideas acerca de las plantas y la morfología y homología animal fueron desarrolladas por diversos naturalistas decimonónicos, entre ellos Charles Darwin.

Goethe estuvo muy interesado en la geología, y particularmente en la mineralogía, reuniendo una gran colección de minerales y fósiles, que actualmente todavía se conserva, y que consta de más de 9000 ejemplares. En reconocimiento de su labor como estudioso, Lenz dio el nombre de "götit" (actualmente, en español, goethita) a un mineral de hierro.






</doc>
<doc id="6714" url="https://es.wikipedia.org/wiki?curid=6714" title="Cable submarino">
Cable submarino

Un cable submarino o Interoceánico es aquel cable de cobre o fibra óptica instalado sobre el lecho marino y destinado fundamentalmente a servicios de telecomunicación.

No obstante, también existen cables submarinos destinados al transporte de energía eléctrica, aunque en este caso las distancias cubiertas suelen ser relativamente pequeñas y además van insertados dentro de una tubería especial para evitar riesgos al contacto con el agua ya que maneja altas potencias.

Actualmente los cables submarinos de fibra óptica son la base de la red mundial de telecomunicaciones. El cable submarino se muestra como una solución robusta y eficaz, por la resistencia ante inclemencias meteorológicas, menor latencia, y mayor ancho de banda que la comunicación por satélite, todo lo cual lo posiciona como una infraestructura más fiable y de mayor capacidad, una vez instalada y probada. 

La comunicación vía satélite quedó relegada desde la década de 1990 a la transmisión de eventos deportivos y/o culturales específicos, la comunicación de sitios extremadamente remotos, y la navegación marítima/ aeronáutica. Se aprovecha la flexibilidad de poder "subir al satélite" en forma instantánea allí donde la "pisada" del satélite lo permita, e incluso moverse sin perder la conectividad, algo que el cable no puede dar. 

En lo relativo al servicio de telecomunicación los primeros cables, destinados al servicio telegráfico, estaban formados por hilos de cobre recubiertos de un material aislante. Ya en 1845 se realizaban en Portsmouth ensayos de cables submarinos aunque no se conseguía aún la confiabilidad suficiente. La invención de un aislante resistente al agua denominado gutapercha, desarrollado en 1847 por el alemán Werner von Siemens. le permitió a la "Submarine Telegraph Co". tender, en 1852, el primer cable submarino que unía el Reino Unido y Francia a través del Canal de la Mancha. Si bien fue cortado por unos pescadores al poco tiempo de instalado, este hito probó que el cable submarino funcionaba, desatando una carrera sin freno por su desarrollo en el mundo. 

Entre 1852 y 1854 se realizaron diferentes tendidos entre Irlanda y Escocia, entre Gales e Irlanda, entre Córcega y Cerdeña, entre Suecia y Dinamarca, y varios otros tendidos pequeños (menos de 25 millas náuticas generalmente), algunos funcionaron bien y otros no tanto, pero todos estos trabajos permitieron ganar experiencia sobre tendido y durabilidad de los materiales. 

En 1855 se aprobó el proyecto para tender el primer cable transatlántico, que quedó fuera de servicio en poco tiempo. En 1865 se puso en marcha el segundo proyecto, empleándose para ello el mayor barco existente en ese entonces, el Great Eastern. Este cable no llegaría a funcionar hasta el año 1866 y unía Irlanda y Terranova. Algunos años más tarde, en 1868, se instaló finalmente un cable que atravesaba el océano atlántico y conectaba Irlanda con Canadá, optimizando enormemente la comunicación entre Estados Unidos y Gran Bretaña, reduciendo drásticamente el tiempo en que los mensajes podían llegar a su destino. De días (tiempo en que los barcos tardaban en entregar el mensaje en la otra costa) a únicamente horas.

Fueron el especialista estadounidense en telégrafos Cyrus West Field y el físico y matemático irlandés William Thomson, más tarde conocido como Lord Kelvin, quienes se aventuraron a instalar este cable, en un contexto donde la idea de poder comunicarse a grandes distancias en poco tiempo, era aún más importante que la luz eléctrica.

El procedimiento consistió en encontrar dos barcos a medio camino y luego transportar cada extremo de cable a cada una de las costas, distantes 3.000 kilómetros. Hasta ese entonces, la idea de un cable submarino no era posible debido a que no se contaba con un material lo suficientemente resistente. Con el implemento de la gutapercha, material obtenido de la savia de algunos árboles, pudo cubrirse el cable lo suficiente como para permitir conexiones subacuáticas. Si bien el primer intento fue un fracaso, luego de la instalación exitosa en el Canal de la Mancha, pronto tomó fama en Europa y fue instalado en diferentes naciones, logrando conexiones importantes en el mar Mediterráneo y en el mar Negro. Se estima que en el año 1855 ya había instalados por lo menos veinticinco cables submarinos. Esto fue lo que permitió a Field y Thomson a intentar conectar sus dos naciones, que en aquel momento su contexto político exigía una mejor manera de mantenerse comunicados. 

Las dificultades de tendido fueron considerables, así como las de explotación, debido a las elevadas atenuaciones que sufrían las señales como consecuencia de la capacitancia entre el conductor activo y la toma de tierra, así como por los problemas de aislamiento. Muchos de estos problemas eran ocasionados por el sabotaje de los accionistas de las compañías marítimas, introduciendo clavos y perforando así la capa aislante del cable. Se tuvo que emplear muchos hombres y un trabajo minucioso y a conciencia para poder repararlos. El progreso de este, era perjudicial económicamente para las compañías navieras.

Tras el evidente fracaso de esta conexión, varios inversionistas se retiraron del proyecto y no fue sino hasta seis años después que se volvió a realizar un intento por conectar ambas naciones. 

Ideológicamente, podría decirse que el cable sirvió para la consolidación de la sincronización del mundo occidental entre dos potencias importantes. Así como sirvió para instaurar la primera gran noción de un mundo completamente conectado. E incluso abrió la puerta para que se siguieran dando pasos en relación al desarrollo de las conexiones de comunicación, primero para telegrafía y luego de telefonía, dotados de repetidores amplificadores sumergidos, con suministro de energía a través de los mismos conductores utilizados para transmitir la conversación. 

Posteriormente, en la década de los 60, se instalaron cables submarinos formados por pares coaxiales, que utilizando multiplexación por división de frecuencia. permitían un elevado número de canales telefónicos analógicos, del orden de 120 a 1800, lo que para la época era mucho. 

En los ´80, comenzaron a popularizarse los cables submarinos de fibra óptica, que utilizan multiplexación por división de longitud de onda, idéntica filosofía pero utilizando esta vez diferentes longitudes de onda de emisores láser. Así, abrieron el camino para la transmisión simultánea de un gran número de señales digitales portadoras de voz, datos, televisión, Internet, etc. con velocidades de transmisión de hasta 1000 Tbit/s.

A pesar de que el cable era parte de un desarrollo de comunicación, también puede pensarse en todo lo que significó. En un mundo donde la noción de “"conectividad"” apenas empezaba a esclarecerse y donde la idea de entender a la sociedad a través de una metáfora de red era prácticamente inexistente, hubo quienes se aventuraron a intentar esta gran hazaña.

Con un elemento similar a una azada pero de gran tamaño, manejada por robots submarinos, se crea un surco donde se posará el cable, surco que posteriormente se cubrirá con arena depositada por la corriente marina. Esto se hace en zonas donde la profundidad es escasa o pudieran aparecer otros riesgos, ya que cuando la profundidad es importante, el cable simplemente queda apoyado en el lecho marino. Lo más difícil es determinar la profundidad del océano. El lecho marino consta de desniveles, lo que hace que haya zonas conflictivas en condiciones muy diversas para situar los cables. Para ello, se estudian en profundidad las zonas más adecuadas para colocarlos. 

En la fosa de Japón, a una profundidad de 8.000 metros, hay un cable submarino. El cable debe ser bastante más largo que la profundidad en el momento de su instalación: el barco está en movimiento mientras coloca el cable y el ángulo que forma desde la zona de mayor profundidad hace que se lleguen a necesitar 16 kilómetros de cable para los 8000 metros de profundidad.

Los cables en la actualidad no son muy gruesos, pueden alcanzar el tamaño de un brazo humano. Paradójicamente, cuanto "mayor" es la profundidad, "menor" es la protección mecánica que se necesita, pues hay una menor probabilidad de que se sufran daños en el cable por anclas, redes de arrastre, u otros. Suelen tener las fibras ópticas en el centro, recubrimientos plásticos, cables de acero para resistencia mecánica, conductores de cobre para alimentación de los repetidores, y una funda exterior de tereftalato de polietileno para aislarlo completamente. 

3.840 giga-bits por segundo, es decir 102 discos DVD en esos segundos, esto es posible por la fibra óptica. Un cable consta de 16 hilos de fibra, por lo tanto se llenan 1.700 discos DVD por segundo, por encima de los 60 terabits por segundo.

La reparación de un cable a tanta profundidad es imposible, por lo que se arreglan en la superficie. Se rescatan los extremos dañados con un robot submarino, y se repara, une o soluciona el daño a bordo de buques especiales. No hay muchos barcos que se dediquen a esta labor

Hay varias razones por la que los cables sufren daños, pero básicamente es por anclas de barcos, redes de pesca, o peces. La fauna marina se puede comer el recubrimiento de los cables - tiburones -, atraídos por los campos magnéticos. Afortunadamente los nuevos diseños de cables contemplan este problema y reducen la posibilidad de cortes o complicaciones por estas causas.

Otros casos que se contemplan, son los terremotos. En 2006 uno con magnitud 7.0 rompió ocho cables en la zona de Taiwán, afectando gravemente a las comunicaciones en China. Un total de once barcos estuvieron 49 días trabajando en la reparación.

En la actualidad se están incorporando sistemas de reconocimiento de movimientos en el fondo oceánico para los posibles terremotos, que puedan derivar en algo más complicado. Se sabe que ahí se originan, por lo cual podemos contar con la velocidad con la que el cable puede avisar de lo que acontece, esto nos da un margen de maniobra muy grande para prevenir situaciones en las ciudades.

En la actualidad los cables no están protegidos por los países.

"Cada año se producen entre 100 y 150 cortes de cables submarinos"



</doc>
<doc id="6716" url="https://es.wikipedia.org/wiki?curid=6716" title="Consonancia">
Consonancia

En música, la consonancia (eufonía) es una noción subjetiva según la cual se consideran ciertos intervalos musicales menos tensos que otros. En oposición a este concepto, está el de disonancia, que se usa para referirse a intervalos que se consideran más tensos que otros. Según la Real Academia Española, consonancia es la "cualidad de aquellos sonidos que, oídos simultáneamente, producen efecto agradable."

Hoy en día se aceptan como consonancias los intervalos de unísono, tercera menor, tercera mayor, cuarta justa, quinta justa, sexta menor, sexta mayor y octava.. También se consideran consonantes los intervalos compuestos que derivan de estos. Algunas clasificaciones dividen las consonancias en perfectas (octavas, quintas y cuartas justas) e imperfectas (terceras y sextas).




</doc>
<doc id="6717" url="https://es.wikipedia.org/wiki?curid=6717" title="Astor Piazzolla">
Astor Piazzolla

Ástor Pantaleón Piazzolla (Mar del Plata, 11 de marzo de 1921 – Buenos Aires, 4 de julio de 1992) fue un bandoneonista y compositor argentino considerado uno de los músicos más importantes del siglo XX y uno de los compositores más importantes de tango en todo el mundo.

Nació en Mar del Plata, pero desde muy joven se crio en la metrópolis de Nueva York, donde su padre le obsequió un bandoneón, el cual comenzó a tocar desde muy temprana edad. Tomó clases con Alberto Ginastera y ganó el Concurso Fabien Sevitzky, con el cual pudo financiarse un viaje a Europa para estudiar armonía, música clásica y contemporánea con la compositora y directora de orquesta francesa Nadia Boulanger. En su juventud tocó y realizó arreglos orquestales para el bandoneonista, compositor y director Aníbal Troilo. Cuando comenzó a hacer innovaciones en el tango en lo que respecta a ritmo, timbre y armonía, fue muy criticado por los "tangueros" de la «guardia vieja», ortodoxos en cuanto a ritmo, melodía y orquestación.

Cuando en los años 1950 y 1960 los tangueros tradicionales —que lo consideraban «el asesino del tango»— decretaron que sus composiciones no eran tango, Piazzolla respondió con una nueva definición: «Es música contemporánea de Buenos Aires». A pesar de esto, en Argentina las estaciones radiodifusoras no difundían sus obras y los comentaristas seguían atacando su arte. Durante años, tangueros y críticos musicales lo consideraron un esnob irrespetuoso que componía música "híbrida", con exabruptos de armonía disonante.

En sus últimos años de vida fue reivindicado por intelectuales, jazzistas y músicos de rock de todo el mundo, al igual que por nuevos referentes del tango, y actualmente se lo considera como uno de los músicos argentinos más importantes en la historia de su país. Compuso también música para cerca de 40 películas.

Astor Piazzolla nació en Mar del Plata, Argentina en 1921, hijo de Vicente Piazzolla y Asunta Manetti (ambos nacidos en Mar del Plata, hijos de padres italianos). El nombre Astor no existía en ese entonces y su padre se lo puso en homenaje a su amigo Astore Bolognini, corredor de moto y primer violonchelista de la Orquesta Sinfónica de Chicago. En 1924 la familia se mudó a Nueva York, Estados Unidos, Astor vivió gran parte de su niñez en aquella ciudad, y aprendió su tercera lengua el ingles, ya que sabía español e italiano. Marginado de los deportes como consecuencia de una malformación en una de sus piernas, en 1927, sintiendo nostalgia por su Argentina natal, el padre de Astor le compró un bandoneón usado en una casa de empeños, por 18 dólares. El padre de Astor también tenía afición por la música, y de hecho tocaba un instrumento similar, el acordeón. En una entrevista del 1 de agosto de 1947 en el diario "Noticias Gráficas" dijo al respecto: "Era inútil pretender encontrar a orillas del Hudson un maestro de bandoneón y el pibe, por su cuenta, se dedicó a persuadir a los botones a que entregaran a sus dedos todos sus secretos ¿No se cuenta por ahí que Blaise Pascal se inventó él solito la geometría?".

La familia Piazzolla decidió retornar a Mar del Plata brevemente, y allí un inmigrante italiano, Libero Paolini, que tocaba en la confitería Múnich le enseñó los primeros acordes. Luego cambió de maestro y fue Homero, hermano de Libero, el que le enseñó algunas rancheras, valses y polcas. Y si bien no tocaba tangos, Homero le dijo al padre que “el pibe tiene talento” y aunque todavía le queda un estilo americano es un “tanguero de alma”, a lo que el padre le responde “yo ya lo sabía, maestro”. Pero el tiempo en que la familia se asienta en Mar del Plata es poco y vuelven a Nueva York. En ese entonces Astor tenía once años.

Allí, Vicente logró ponerse bajo la protección de Nicola Scabutiello, dueño de una importante peluquería en el West Side y de varios billares clandestinos. Astor diría de esos años:

Un día frente a su ventana escuchó de una casa vecina algo que le llamó la atención, alguien en un piano estaba interpretando a Johann Sebastian Bach, se trataba de un húngaro al que Piazzolla le atribuyó la condición de alumno de Rajmáninov, cuyo nombre era Bela Wilda. “Charlábamos de jazz, de los canelones, de la amistad, de la necesidad de estudiar seis y hasta ocho horas diarias para lograr la perfección. Con él conocí el verdadero amor a la música”. Así fue como en 1933 tomó clases con Bela Wilda, de quien además señaló Piazzolla: “Con él aprendí a amar a Bach”. También estudió con Terig Tucci. En el marco de un festival escolar debutó en 1932 en un teatrillo de la calle 42, para lo cual Astor compuso un tango que tituló «Paso a paso hacia la 42», pero que su padre rebautizó «La catinga». 

Sentía devoción por Agustín Bardi y Eduardo Arolas, y consideraba a Julio De Caro y al violinista Elvino Vardaro como los innovadores en el tango, además de admirar a Osvaldo Pugliese. 
Piazzolla conoció a Carlos Gardel en Manhattan en 1934, al llevarle un presente realizado por su padre. A Gardel le cayó muy bien el joven y le resultó útil para realizar sus compras en la ciudad, ya que conocía muy bien la ciudad, además que dominaba el inglés, idioma que Gardel desconocía totalmente. Al año siguiente el cantor lo invitó a participar en la película que rodaba en esos días, "El día que me quieras", como un joven vendedor de diarios. Fuera de las cámaras, Piazzolla le enseñó cómo tocaba el bandoneón a Gardel, y este le dijo: “Vas a ser algo grande, pibe, te lo digo yo. Pero el tango lo tocás como un gallego”. A lo que Piazzolla le dijo “el tango todavía no lo entiendo”, y Gardel le respondió: “cuando lo entiendas, no lo vas a dejar”. Gardel invitó a Piazzolla a unirse en su gira por América, pero su padre decidió que era aún muy joven, por esta razón, su lugar fue ocupado por el boxeador argentino José Corpas Moreno. Esta temprana desilusión resultó ser una gran suerte, ya que fue en esta gira en la que Gardel y toda su banda perdieron la vida en un accidente aéreo. En 1978, en una carta imaginaria a Gardel, Piazzolla bromearía al respecto sobre ese hecho:

Piazzolla tenía diecisiete años cuando aún le daba vergüenza que sus amigos supieran que tocaba el bandoneón. En Francia, mucho después, lo escondería en el ropero. Esa tensión entre la presencia vergonzante y su anhelo de hacerle adquirir nueva carta de ciudadanía está presente desde muy temprano. El bandoneón empieza a cobrar un nuevo sentido con otra escucha casual, la del violinista Elvino Vardaro, del cual Piazzolla dijo: “Descubrí una manera diferente de tocar el tango”.

El primer intento por armar una agrupación de Piazzolla fue hacer un dúo de fuelles con Calixto Sallago, intentando hacer algunas adaptaciones de piezas de Rachmaninov. Las “traducciones” de cierto repertorio clásico podían pensarse como equivalentes de las que, en la literatura popular, las editoriales Claridad o Thor hacían de Dostoieysky o los grandes novelistas europeos; las mismas que leía Roberto Arlt. Piazzolla se vinculó después con Gabriel Clausi, un exintegrante de la orquesta de Julio De Caro, y luego haría lo propio con el grupo de Francisco Lauro. Iba de su cuarto al cabaret Novelty en Corrientes y Esmeralda, con alguna escala ocasional en el cine o el billar, contaba sobre esos días: “Libero me cuidaba, pero yo me aburría andando por la ciudad sin un rumbo fijo”. De sus primeras andanzas entre músicos le llamó la atención cómo era la vida de los mismos: “no podía comprender por qué los músicos tenían que vivir en lugares tan miserables”. Piazzolla no pretendía en un primer momento tener el nivel de vida de Francisco Canaro, pero sí deseó tener su fortuna. Las radios más importantes se lo disputarían en el futuro. Llegó a firmar contratos con condiciones muy favorables para él con los más importantes sellos discográficos. La revista "Sintonía" lo presentaría como “propietario de regios automóviles de precio”.

Tomó partido principalmente por Julio De Caro, pero también era admirador de Pedro Maffia, Pedro Laurenz y Aníbal Troilo a quienes para sus dieciocho años, veía demasiado lejanos. Su hija Diana contó que una tarde se puso a caminar por Corrientes, y cuando llegó a la altura del 900 -cerca del Novelty- leyó un cartel en la puerta del Café Germinal en el que se anunciaba el debut de la orquesta de Aníbal Troilo. De repente, escuchó que alguien tocaba en el piano el tango “Comme il faut” de Arolas.

El 3 de julio de 1940 arribó a la Argentina el pianista Arthur Rubinstein. Cuando Piazzolla se entero de ello se dirigió al Palacio Álzaga Unzué en la calle Arroyo donde residía el músico desde hacía dos meses. El mismo pianista abrió la puerta y recibió a su huésped, quién le llevó un esbozo de un concierto para piano. El pianista tocó una parte, y le preguntó al joven si deseaba estudiar seriamente, tal es así que Rubinstein se tomó el trabajo de llamar a Juan José Castro, el compositor y director argentino, avisándole que sería su tutor. Pero finalmente Castro lo derivó a Alberto Ginastera que residía en Barracas, con quien tomó clases entre 1939 a 1945. Ginastera lo instó a ir a los ensayos de las orquestas sinfónicas. Para ese entonces Buenos Aires era relativamente neutral durante la Segunda Guerra Mundial, por lo que llegaron importantes músicos, no solo Rubinstein, sino también Erich Kleiber, Walter Gieseking, Aaron Copland y Manuel de Falla, que se radicó en Alta Gracia Córdoba. El puerto lejano tenía una sincronía considerable con otros teatros del mundo que quedaba en pie. Los conciertos de la Asociación Sinfónica y la Asociación Filarmónica, en los teatros Teatro Presidente Alvear, Politeama, Gran Rex y naturalmente, en el Teatro Colón y los ciclos “Amigos de la música”, en los teatros Broadway y Metropolitan, permitían el acceso a un repertorio significativo.

A partir de ese momento resolvió permanecer en el Germinal, pudiendo así encontrar un café donde escuchar tango y no un cabaret, de allí conocería a Troilo. “Yo lo miraba como si fuese Dios”, le comentaría años después a Speratti. Pasó horas en el Germinal absorbiendo todo lo que escuchaba. Con sus dedos marcaba el compás de la música sobre la mesa. Su reiterada presencia llamó la atención del violinista Hugo Baralis, quien un día se acercó para conocer al muchacho, sobre Piazzolla dijo: “Movía las manos, las piernas, era muy inquieto”. De allí se hicieron amigos por 1939.

Un día Baralis le comentó, con desazón, que faltaría uno de los bandoneonistas porque estaba enfermo, a lo que Piazzolla le convenció para reemplazarlo en el puesto, Baralis no muy seguro se lo comentó a Troilo, y tras una prueba a Piazzolla, Troilo le dice: "Ese traje no va, pibe. Conseguite uno azul que debutas esta noche". Como dato anecdótico, Piazzolla le había enseñado lo que sabía de Gershwin, “deja esas cosas para los norteamericanos”, le dijo el pianista Orlando Goñi. Según Piazzolla, se sabía todos los tangos de memoria, debutó en la orquesta en diciembre de 1939, no mucho después de las primeras grabaciones discográficas de Troilo para el sello Odeón, “Commo il faut” y “Tinta verde”, registradas el 7 de marzo de 1938. “Fue otro bautismo de fuego” dijo Natalio Gorin, el otro proviene del debut en Manhattan.

Las personas con algún defecto físico visible (Piazzolla cojeaba por tener una pierna más chica que la otra) suelen no estar exentos de burlas y maltratos verbales, más aun en un ambiente como el que estaba frecuentando, de allí es que empezaría a adoptar una peculiar personalidad de "golpear primero", dando rienda a sus "diabladuras", que fueron algo más que un exceso de picaresca, es posible que haya sido, sencillamente un mecanismo de defensa ante las numerosas hostilidades. Troilo apodó el "Gato" (en el lunfardo de esa época se refería a una persona que vivía de la noche) a su joven bandoneonista, pero este estaba muy lejos a ser una persona que vivía de la noche. “Deseaba vivir otro tipo de vida. No aceptaba que esa, la de los tangueros, fuera mi destino. Quería salir de todo eso. Y creo que esa intención, esa ansiedad, me salvaron”. Piazzolla toma la importante decisión de comenzar un noviazgo con Odette María Wolf, tiene dieciocho años y estudia pintura, quien lo introduce en las novedades del cubismo, el surrealismo y la abstracción, le da otro entorno. Piazzolla y Odette María Wolf se casaron en octubre de 1942 y fueron a vivir a una casa de departamentos en el barrio porteño de Monserrat. Del matrimonio nacieron sus hijos Diana (1943) y Daniel (1944).
El tango “Inspiración” de 1943 es el primer arreglo que hizo Piazzolla y que fue grabado por la orquesta de Troilo con armonías clásicas. Se puede percibir una abundancia de cromatismo de paso, en los pizzicatos en las cuerdas y en los trinos barrocos del piano. El manejo de voces es acotado. Troilo aparentemente borraba o dictaba los preceptos de la corrección tanguística, pero, al mismo tiempo, aprobaba y valoraba ciertos arreglos. “Inspiración” con ese arreglo, aunque borrado parcialmente, era uno de los exitosos de sus presentaciones, además lo volvió a grabar cada vez que tuvo un nuevo contrato con una discográfica. Lo registró por primera vez para la RCA en 1943, y luego para TK en 1951, y para Odeón en 1957. Hay una versión grabada por Piazzolla con su propia orquesta en 1947, en cuya versión aparecen mayores acciaccaturas en las cuerdas y el orquestador se permitía una mayor soltura contrapuntística, pero dentro de los límites que fijaba la convención. En contraposición al mito instalado, una gran parte del público tanguero –además de los músicos- valoraba los arreglos de Piazzolla. El volumen de las orquestaciones realizadas para Troilo mientras estaba en su orquesta y el hecho de que, en 1951 fuera el elegido para arreglar “Responso”, el elegíaco tema compuesto por Troilo por la muerte de Homero Manzi, dan una buena prueba de la valoración que tenía de Piazzolla.

En 1944 dejó la orquesta de Aníbal Troilo. Sobre la anécdota de la "goma de borrar", Piazzolla diría años más tarde: "De las mil notas que escribía, él me borraba setecientas...". No obstante, Troilo buscó un equilibrio entre hacer nuevas innovaciones pero sin ir por caminos que fuesen demasiado complicados para su orquesta, teniendo en cuenta que no todos estaban preparados para tocar la música compleja que Piazzolla escribía. Las cuestiones eran más técnicas que de otro orden. Obligaron a los músicos a leer, a estudiar, y “me empezaron a tener bronca... me rompían los ejercicios” recordó en alguna ocasión Piazzolla. Años luego de su partida, siempre criticaría duramente el hecho de que Troilo nunca de despegó del “cómodo” lugar de entretenedor de bailes populares para sumir el papel de conductor de una gran orquesta de tango “para ser escuchado”, fue para Piazzolla una especie de "traición".

Integró el Quinteto Azul de corta existencia y también en Mar del Plata un conjunto bajo su dirección, con claras particularidades tímbricas basadas en el conjunto que dirigía Elvino Vardaro. Para 1938 ya tenía fama de ser un gran instrumentista. Había integrado las formaciones de Francisco Lauro y Gabriel Clausi, hasta que fue llamado por Aníbal Troilo para integrar el conjunto de éste como bandoneonista y arreglador, mientras seguía estudiando diversas disciplinas con Alberto Ginastera. En 1944 se desvincula de la formación de Troilo. Piazzolla se fue con el grupo de Francisco Florentino, y ese cantante le permite imprimir su nombre como un significativo agregado, fue la orquesta “de” Astor Piazzolla la que lo acompañe. Debutan en Villa Urquiza a finales de 1944, graban veintidós canciones y dos instrumentales. Piazzolla compone para la ocasión “En las noches” y “Noches largas”. Poco tiempo después, y aconsejado por su esposa, se suprime la “y” pasando a ser “la orquesta típica de Astor Piazzolla” y solo su nombre se imprime en el cartel que lo anuncia. “Los que me seguían preferían tomar un café y escuchar: bailar era lo secundario”. Debutó en el Marcito, uno de los numerosos cafés donde se tocaba tango desde el mediodía hasta pasada la medianoche con la única obligación del consumo de un café cuyo valor varía con el horario. Para fines de los 40 quedaban varios sitios para escuchar tango a precios accesibles: los cafés El Nacional, Marzotto, Tango Bar, La Ruca, la Richmond. En los barrios estaban El Imperio (donde tocaba Pugliese), el café la Victoria, los cafés de Boedo y San Juan o en avenida San Martín y Fragata Sarmiento. Y las milongas de Palermo, como La Enramada.

Durante 1946 a 1949 trabajó para el sello Odeón con su orquesta independiente, en esas grabaciones sus vocalistas fueron Aldo Campoamor, Fontón Luna y Héctor Insúa. Tras disolver su formación se dedicó laboralmente a hacer arreglos para orquestas como la de José Bassi, Francini-Pontier y especialmente para la de Aníbal Troilo. Las críticas a su música comenzaron a tomar mayor caudal, alguna vez le reprocharon “¿Te crees que estas en el Colón?”. Una anécdota muy famosa es cuando tocaban el tango “Copas, amigos y besos” tema de Mariano Mores. “Era tan larga, tan compleja que las coperas del cabaret nos cargaron y salieron a bailar a la pista en puntas de pie, como si fuera música clásica”. El arreglo no funcionó que hubo que modificarlo. “Creo que ese fue el primer paso para dejar a Florentino: a él tampoco le gustaban las audacias”. No existen datos precisos de cuantas unidades vendía un disco exitoso, pero el volumen de ediciones, la cantidad de actuaciones en vivo y la multitud de orquestas y cantantes de excelente nivel que estuvieron activos durante esos años hablan del tango como un verdadero fenómeno comercial, comprable, en sus apariencias con el de las grandes orquestas de "swing" en Estados Unidos.

Para los años 50, en contraposición a lo que se suele considerar, Piazzolla estaba lejos de ser resistido como compositor y orquestador. Era alguien que, sin ser integrante ni director de ninguna orquesta (disolvió la suya un años antes) componía y arreglaba profesionalmente, por encargo, para las formaciones más prestigiosas. Según Roberto Pansera una vez se le escuchó decir “Voy a componer dos tangos por año. Con cuatro grabaciones por año yo vivo”. El profesionalismo de Piazzolla tiene un recorrido, desde que comenzó a tocar, y casi inmediatamente, a hacer orquestaciones para Troilo, hasta el arribo a esa fórmula, inédita para el tango, de compositor “a medida” para orquestas de otros. En la década de 1950 Piazzola es el autor además de música para películas y también intenta ganar prestigio en el “mundo clásico”, tratando de estrenar sus obras para orquesta y de cámara, a las que rigurosamente coloca números de opus, aun cuando se trate de ejercicios a pedido de su maestro. Y ese lugar especializado se corresponde, también, con un modelo aprendido con Ginastera: el del compositor situado por encima de las contingencias del mundo y a quien nada debe interesarle quién es el que paga, siempre y cuando respete su arte.

Entre quienes han escrito acerca de Piazzolla, el único que repara en la fundamental importancia de los tangos compuestos a comienzos de la década de 1950 –“Prepárense”, “Contrabajenado”, “Lo que vendrá”, “triunfal”, y en particular “Para lucirse” la pieza que inaugura la serie, es el escritor y periodista Julio Nudler; “antes no estaba muy en claro qué era lo que quería Piazzolla” dijo alguna vez Nudler. La interpretación de “Para lucirse” (de autoría propia) por ejemplo dura casi cuatro minutos, una considerable duración para los cánones comerciales de la época.

Sobre la controversia con los tangueros de la "guardia vieja" Lalo Schifrin contó que:

Piazzolla dijo abstenerse de participar de un concierto para la Fundación Eva Perón, pero su ausencia no fue por razones ideológicas, había disuelto la orquesta. La misma formación con la que en 1948 grabó un tema a la medida del Primer Plan Quinquenal y cuya letra daba cuenta de la euforia peronista “Yo tengo la suerte de ser argentino / vivir en la patria más linda y feliz” cantaba Alberto Montan Luna en “República Argentina”, un vals compuesto por Santos Lipesker y Reinaldo Yiso y arreglado por Piazzolla.

En 1952 año de la muerte de Evita la editorial Sarraceno da a conocer su "Epopeya…" la obra se basaba en textos de Mario Nuñez, autor del “Soneto a las manos de Eva Perón” incluido en el mismo cantinera sobre el peronismo del que participó Mende Brun. La transcripción para piano de "Epopeya…" fue realizada por el propio Piazzolla. Se exhumó por azar en la Biblioteca Nacional. El hallazgo corrió por cuenta de un grupo de musicólogos argentinos entre quienes se contaba Pablo Fessel, en el años 2003. “Nunca pensé que reaparecería. Creí que estaba entra las obras suyas que destruyó porque no le gustaban… recuerdo como renegó de ella”, le dijo Diana Piazzolla al diario Clarín. Nuñez contó en esa oportunidad la hija “era amigo de papa y asesor de Perón” y fue el que se la encargó “Papá quiso hacer un himno, pero al final no le gustó y no dejó que la usaran ni estrenaran”.

Pero si hay algo que Piazzolla inaugura claramente durante el peronismo es una tendencia al neutralismo político, muestra de ello fue como a lo largo de su vida hizo la banda sonora de "Llueve sobre Santiago" (1975) película sobre Salvador Allende de Helvio Soto, pero a su vez su elasticidad le permitió ser músico de las “canciollerías” de dos dictaduras argentinas, actuar en teatros oficiales durante los regímenes de los militares Lanusse y Videla, amenizar con su Quinteto una fiesta de Juan Carlos Ongania, o incluso tocar en la Cuba de Fidel Castro. Durante la Guerra de Malvinas Piazzolla presentó en Buenos Aires un tema dedicado a Alfredo Astiz, más conocido como “El ángel de la muerte”. Al enterarse de su escalofriante prontuario, Piazzolla borró el nombre puso esa partitura al servicio de una de las películas emblemáticas de la era postdictadura "El exilio de Gardel", cuyo director es Fernando Solanas.

El Concurso Fabien Sevizky de composición es considerado un punto de quiebre en la carrera de Piazzolla. Hiato que le da un breve sustento a la fantasía de transcender el perímetro del “dos por cuatro” y la ocasional escritura de música incidentales. En tiempos de censura y una rigidez ideológica que era tan implacable con Borgues como Libertad Lamarque, Osvaldo Pugliese, Atahualpa Yupanqui, y hasta el mismo Hugo del Carril es de considerar que ese galardón pudiera haber sido otorgado a nadie que tuviera una mínima mácula en su expediente. El Premio era organizado por la Radio del Estado, que desde 1946 era sometida a una férrea política de supervisión. Según Diana, hija de Astor, su padre envió la partitura al concurso que se dirimía en Indianápolis, donde Sevitzky dirigía su orquesta sinfónica, no obstante la competición no transcendió de las fronteras de la capital argentina, y del jurado, no solo formó parte Ginastera, quien además ayudó a su alumno a retocar la composición que después juzgaría, sino Luis Gianneo, que habían formado parte del grupo de "notables" que galardonó en 1953 a Elsa Calcagno. Piazzolla resultó ganador con "Buenos Aires (tres movimientos sinfónicos)". El premio consistió en una suma de dinero (no muy grande, pero si lo suficiente para viajar a Europa en buques de carga), y la ejecución de la obra bajo la tutela del maestro que había dado nombre a la competencia. El músico Leopoldo Federico fue uno de los elegidos para interpretarla el 13 de agosto, dijo sobre aquella jornada:

En conversaciones con Speratti, Piazzolla dijo que "la obra gustó mucho, pero provocó escándalo, porque los académicos se indignaron al ver los bandoneones". El mismísimo Sevitzky, lo llamó al finalizar la obra, para que saliera a saludar, Astor, algo tímido subió al escenario y observó que el público se estaba pelando en una gran gresca, a lo que el director lo consoló diciendo "no se preocupe, es buena publicidad". La versión de la "batalla campal" solo es recordada por Piazzolla. La noticia del concurso fue levantada por solo algunos medios de prensa como "La Prensa", "La Nación" y "Buenos Aires Musical". La composición nunca fue grabada por Piazzolla.

Piazzolla viajó a Europa con dos pasajes y a apenas con dinero, de ahí se deduce el hecho que viajó en el "Coracero", un barco carguero. Presuntamente los fondos eran los ganados en el concurso, aunque el músico de tango dijo que fue becado por el gobierno argentino, no hay pruebas de ello, y la "beca" se la suele confundir con el dinero ganado en el concurso. Arribó a Ámsterdam el 24 de septiembre de 1954 después de viajar cuarenta y cinco días, no se dirigió inmediatamente a Francia, sino que estuvo algunos días en Holanda. Piazzolla le contó a Speratti que estaba “desmoralizado, titubeante, se abandonaba a la ciudad, recorría sus calles buscando”. Varios aspectos de la relación de Piazzolla con Boulanger no son muy claros, entre ellos cómo el músico argentino tomó contacto con Boulanger, ni quién se la recomendó. Según Simon Collier y María Susana Azzi, el propio Alberto Ginastera le recomendó a Piazzolla contactarse con alguien, pero no especificaron concretamente con quién. Natalio Gorin afirmó que el bandoneonista le confesó que: "Casi tomo clases con Olivier Messiaen". Por otro lado, su hija Diana dijo que su padre recién arribado a París se enteró que Boulanger estaba dando clases muy cerca de donde se alojaba él. 

Nadia Boulanger seria una pieza muy importante en su carrera, ya que hasta su encuentro con ella, Piazzolla se debatía entre ser un músico de tango o un compositor de música clásica. Boulanger lo animó a seguir con el tango, pero si hasta ese momento todo era o tango o música clásica, a partir de entonces sería tango y música clásica. A partir de 1954, cuando estudió con Boulanger, la música de Piazzolla cambió radicalmente. Pero para ser aceptado como alumno le tuvo que mostrar algo de lo que había compuesto, tampoco está claro cual fue la pieza que le enseñó, ya que por un lado según Diana fue la "Sinfonietta", mientras que Collier y Azzi aseguran que fueron los "Tres movimientos sinfónicos de Buenos Aires". Los biógrafos de Piazzolla están de acuerdo en que Boulanger notó la carencia de algo en su música, lo que Piazzolla años más tarde denominó "sentimiento". Un día ante las indagaciones de Boulanger sobre qué música hacía en Buenos Aires, él con algo de timidez le confesó que componía tangos y que tocaba el bandoneón, entonces fue allí cuando le pidió que tocase al piano uno de sus tangos, Piazzolla tocó "Triunfal" y antes de terminarlo su profesora le tomó las manos para decirle: "No abandone jamás esto. Ésta es su música. Aquí está Piazzolla". Estudió once meses con Boulanger, pero al mismo tiempo formó una orquesta de cuerdas con músicos de la Ópera de París, con Lalo Schifrin y Martial Solal alternándose en el piano, y grabó el álbum "Two Argentineans in Paris" (1955) con temas como «Picasso», «Luz y sombra» y «Bandó». En París descubrió que su tango "Prepárense" escrita en 1952 formaba parte del repertorio de las orquestas tangueras de Francia. Los derechos de autor le ayudaron a financiar su estadía. En cierta carta a José Gobello fechada el 16 de diciembre de 1954 Piazzolla dijo: "Parece mentira ver en París bailar tango tango y como gusta, no solamente el tango pasado, sino los nuevos tangos". De las clases Astor diría: "Estuve algo menos de un año con Nadia, estudiando mucho, especialmente contrapunto a cuatro partes, cosa que me volvía loco. Creo que alguna vez lloré de la bronca porque era muy difícil". Su hija Diana afirmó que su padre y Nadia se veían al menos tres veces por semana, cada encuentro duraba al menos tres horas.

En muchos artículos, entrevistas e incluso en la contratapa de un álbum del Octeto, Piazzolla dice haber escuchado en París en 1954 al octeto del saxofonista Gerry Mulligan, quedando impresionado por su improvisación y por el distendimiento con el que tocaban los músicos. No obstante, la investigación de Diego Fischerman y Abel Gilbert sugiere que, eso es imposible, porque justo cuando Piazzolla residió en París, Mulligan estaba de gira fuera de Francia, además es de recalcar lo que Piazzolla una vez le dijo a Gorin: "Nunca le creas lo que les digo a los periodistas", es posible que el bandoneonista haya creado un relato a su semejanza, cuando lo que sucedió es que solo haya escuchado a Mulligan en discos.

En París además de estudiar, compuso, arregló, ensayó y grabó una serie de tangos, "Picasso", "Luz y sombra", "Tzigane", "Río Sena", "Chau París" y "Marrón y azul". Las grabaciones, las tratativas de las mismas, su esposa y las dos semanas de vacaciones con Edouard Pecaurt sugiere que el tiempo de estudio no fue mayor a cuatro meses. El Piazzolla en esos tangos afrancesados, o en cierta medida franceses, no es muy distinto del que quiso dejar de ser: los breves choques de segundas en pizzicato del comienzo de “Nonino” remiten más a sus estudios en Barracas con Ginastera que a un nuevo aprendizaje, y “Guardia Nueva” suena más a homenaje y reelectura del pasado que a una posible visión de futuro. Si ese Piazzolla escriba “a la Piazzolla” de fines del cuarenta. Y casi se copia a sí mismo empujado su pedagoga, es algo que solo en muchos casos de esta historia, resultan complementarias, o aun, más esclarecedoras que los hechos.

Piazzolla se embarcó en Hamburgo en el buque "Yapeyu" con destino a Montevideo y consigo se llevó una foto de Boulanger, en la que ambos posan juntos.

Tras retornar de París, en 1955 Piazzolla formó el Octeto de Buenos Aires dispuesto a encender le mecha de "un escándalo nacional" y "romper con todos lo esquemas musicales que regían en la Argentina". Allí empleó todos los conocimientos que había adquirido años antes con Ginastera, y los nuevos con Boulanger. Tras ver al conjunto de Mulligan, Piazzolla incluyó en su nueva agrupación algunos fraseos y manejos instrumentales que eran típicos del jazz, además de introducir el concepto del "swing" y el contrapunto, más de la música clásica. Un elemento discordante fue la inclusión de la guitarra eléctrica dentro de su Octeto, un instrumento no muy usual en ese momento. La guitarra solista no tenía grandes antecedentes en la música en general. Posiblemente Piazzolla escuchó algunos de los discos que publicó Delaunay (quien lo contrató para grabar algunos discos con el sello Vogue) y de allí haya conocido además de Mulligan, Barney Kessel y Jimmy Raney de donde no solo se basó en la idea de la inclusión de la guitarra eléctrica, sino le dio un papel contrapuntístico. Según el guitarrista Horacio Malvicino, en un primer momento Piazzolla tuvo en mente usar un vibráfono (que lo usó en el Quinteto que formó en Nueva York en 1959), pero como no existía un instrumentista así en Argentina optó por la guitarra eléctrica. El conjunto no tenía director, sino que se proponía hacer el tango “tal como se siente”. No tuvo cantante salvo en contadas excepciones, y no se actuaría en bailes.

El grupo estaba integrado por el mismo Piazzolla y Leopoldo Federico en bandoneones, Francini y Baralis en violines Atilio Stampone en piano, Horacio Malvicino en guitarra eléctrica, José Bragato en violoncello y Hamlet Greco en contrabajo, (quien luego sería remplazado por Juan Vasallo). Recordaría de aquella primera formación post-París: "Eramos ocho tanques de guerra ... Parecíamos salidos del ERP... ¡ocho guerrilleros subidos al escenario!... cada uno, en lugar de un instrumento, parecía que tenía una bazuca". Hubo cierta controversia en torno al quinteto, al punto de que conciertos terminaron con grescas hacia los músicos, por parte de los tangueros más tradicionalistas que repudiaban los cambios de la nueva agrupación. A Piazzolla se le acusó de ser "el asesino del tango".
La primera presentación fue en la Facultad de Derecho a fines de 1957. El grupo grabó con grandes dificultades dos álbumes: uno de duración media, con seis canciones editado por el sello Allegro en 1956 y llamado "Tango progresivo", y otro de larga duración editado por Disc Jockey en 1957 que se tituló "Tango Moderno". Ambos materiales tienen muy pocas composiciones originales de Piazzolla, pero en el segundo de los dos discos aparece un nuevo arreglo de "Marrón y Azul". En "Tango progresivo" había una sola pieza de Piazzolla, "Lo que vendrá", que hasta ese momento solo había sido grabada en 1954, con arreglos debussyanos explícitos en el tema inicial (arreglos que desaparecerían en versiones posteriores). La grabación original data de julio de 1954, un mes antes del viaje a París, y así curiosamente a su vuelta de Europa volvió sobre el mismo tema. También grabó el tema con el mismo formato que había usado en París, cuerdas, piano y bandoneón concertante, que repetiría el año siguiente en Montevideo. El compositor realizó además, otros arreglos, para orquestas como la de Troilo, que lo grabó en 1957 para el sello Odeón. Un rasgo saliente, por otra parte, es el motivo francés que, en la versión para octeto, abre la pieza con tres entradas sucesivas, a cargo de Francini, Baralis y Bragato, separadas entre sí por acordes de todo el grupo. En la grabación con orquesta de cuerdas, piano y bandoneón ese motivo es apenas una introducción somera, después de la cual entra, inmediatamente el tema “rítmico”. La versión escrita para Troilo es la que más diferencias ofrece. Allí el tema lírico, tanguero que en el arreglo del Octeto era apenas el pretexto armónico para las improvisaciones de la guitarra eléctrica, ocupa el primer y no el segundo lugar, y el motivo francés aparece fugazmente como su conclusión, funcionando como puente hacia el tema rítmico. Allí, por otra parte, hay un contracanto claramente acentuado en cuatro tiempos, que disimula (o pone en un marco más digerible para el gran público) el ritmo aditivo de la voz principal.

Piazzolla es, quizá el primer teórico del tango, al introducir un sistema de lectura nuevo, más emparentado con su aprendizaje neoyorquino que con el propio género, desde el que selecciona algunos nombres –De Caro, Vardaro, Orlando Goñi, Maderna, Troilo, Salgán y Pugliese, en donde la música debe ser escuchada, y no bailada. Las notas introductorias escritas por Piazzolla, en su análisis tema por tema y como si hablara de la obra de otro o de un disco ya canonizado, imitan el estilo de los textos de programas de concierto y de los críticos de música clásica de esa época. Sobre “Haydee” anota en la contraportada del álbum.

Lo que pretendió era hacer una música popular con todos los atributos de seriedad –notas de programa incluidas- de la música clásica, y en particular, con su misma funcionalidad predominante. La música del Octeto no estuvo pensada para el baile. Esa oposición entre ambas funciones ya había sido planteada por el propio Piazzolla en relación con los arreglos para su orquesta de 1946, cuando hablaba de “tocar para que la gente escuchara” y de componer para ello piezas como “Villeguita” y “Se armó”. Existió un cierto "endiosamiento" por parte del autor a la dificultad que se repetiría en las notas escritas para el disco del Octeto, como cuando describe el trabajo de los bandoneones y dice: “Casi siempre están realizando acordes de cuatro, cinco y hasta seis notas cada uno (El Marne). También variaciones sobre los temas en quintillos, seisillos y hasta sietesillos de fusas hoy en desuso por si dificultad técnica (Anone)”. El otro bandoneonista del grupo, Federico, ha contado que fue precisamente esa dificultad la que hacia que los mejores músicos de tango quisieran tocar con Piazzolla, puesto que existía un cierto privilegio en pertenecer a esos grupos donde “se escribía difícil”.

Mientras Piazzolla dirigía el Octeto, trabajó con una orquesta de cuerdas en Radio El Mundo con la que consiguió parte del dinero que su grupo no le proveía. Piazzolla cuenta como a principios de 1955 y a partir de las recomendaciones de Boulanger escribió una cantidad de tangos nuevos, que grabó junto a un piano y las cuerdas de la Ópera de París. El proyecto, propiciado por Yves Baquet, un ejecutivo de Editions Universelles al que Piazzolla fue a ver con una recomendación de Eduardo Parula -el representante de aquella firma en Buenos Aires- se plasmó en un serie de discos sencillos, de 45 y 33 RPM para los sellos Festival, Vogue y Barclay, que incluyeron un total de dieciséis temas. Luego en Buenos Aires publicó algunas grabaciones para los sellos TK, Odeón, y en Montevideo para Antar/Telefunken con temas propios (además de “Lo que vendrá”, una nueva versión de "Marrón y azul") y arreglos de temas ajenos ("Vanguardista" de Bragato, y "Negracha", de Pugliese, entre otros). La culminación de ese periodo son dos discos, ambos repitiendo el formato francés (cuerdas, piano y bandoneón). Uno, de duración media (era un disco de 10 pulgadas), se editó en Montevideo, según algunas fuentes se grabó en esa ciudad con las cuerdas de la Sinfónica del SOBRE (Servicio Oficial de Radiodifusión del Estado uruguayo) y se tituló "Lo que vendrá". Allí además de la misma orquestación de esa pieza que Piazzolla había grabado en Buenos Aires un año antes, aparecía, junto a otros tangos (“Miedo”, de Vardaro, Aroma y García, Jiminez, “Sensiblero”, “Noche de amor”, de Franco y Rubinstein, “La cachila” de Arolas, y cantados por Jorge Sobral, “La tarde del adiós”, de López y Lambertucci y “Yo soy el negro” de Piazzolla y Gorostiza), la primera grabación de “Tres minutos con la realidad”. El otro disco fue registrado en Buenos Aires con el nombre de "Tango en HI-Fi" y allí también se incluye. La rítmica es la misma de las grabaciones francesas, aunque la grabación montevideana incluye percusión, en particular un xilofón en “Tres minutos con la realidad” que acentúa aun la similitud entre el puente hacia el tema lítico con el Bartok de la "Música para percusión, cuerdas y celesta".

El bandoneonista hablaba en ese texto, también, aunque con cierto tono de queja, de lo que sin embargo, es una de las mejores virtudes de ese grupo y de los que lo sucedieron: la necesidad de contención. "Realizar el difícil equilibrio sonoro del Octeto llevó dos años y aun queda mucho por descubrir", explicaba: "En cada arreglo se aprende más sobre esta formación orquestal. Tengamos en cuenta que existe un desequilibrio tremendo por falta de cuerdas, ya que para dos bandoneones, piano, guitarra y bajo, se necesitarían por lo menos seis violines, viola y cello, pero ajustándome a los dos violines y cello, es necesario escribirle a estos en tesituras no acostumbradas". Lo que surge, no obstante, es una verdadera lección acerca de ese oficio aprendido más en la práctica y con la audición que con los maestros de la academia que, por más que Piazzolla declara lo contrario, es una de sus marcas:
En "Lo que vendrá" independientemente de las notables diferencias que habría entre la versión del Octeto y las posteriores, aparecen enunciados muchos de los rasgos estilísticos que serían centrales en la producción futura de Piazzolla –ese tema incisivo, de acentuaciones asimétricas, fuertemente rítmico, que se convertiría casi en un sello de fábrica: el papel otorgado a los solistas. Un rasgo saliente, por otra parte, es el motivo francés que, en la versión para octeto, abre la pieza con tres entradas sucesivas, a cargo de Francini, Baralis y Bragato, separadas entre sí por acordes de todo el grupo. En la grabación con orquesta de cuerdas, piano y bandoneón ese motivo es apenas una introducción somera, después de la cual entra, inmediatamente el tema “rítmico”. La versión escrita para Troilo es la que más diferencias ofrece. Allí el tema lírico tanguero -que en el arreglo del Octeto era apenas el pretexto armónico para las improvisaciones de la guitarra eléctrica-, ocupa el primer y no el segundo lugar, y el motivo francés aparece fugazmente como su conclusión, funcionando como puente hacia el tema rítmico. Allí, por otra parte, hay un contracanto claramente acentuado en cuatro tiempos, que disimula (o pone en un marco más digerible para el gran público) el ritmo aditivo de la voz principal.

En 1955 volvió a Buenos Aires donde formó una orquesta de cuerdas con músicos argentinos, en la que cantó Jorge Sobral (para esta formación compone "Tres minutos con la realidad", obra síntesis entre el tango y la música de Stravinsky y Bartók) y el famoso Octeto Buenos Aires, conjunto considerado como el iniciador del tango moderno, tanto por su instrumentación (incluía por primera vez una guitarra eléctrica en un conjunto de tango), como por sus novedades armónicas y contrapuntísticas (acordes con 13as. aumentadas, seisillos y fugas).

En 1958 disuelve ambas formaciones y se marcha a los Estados Unidos, donde graba los dos únicos discos de lo que él llamó el "jazz"-tango (los cuales actualmente son muy difíciles de encontrar).

En 1959, durante una actuación en Puerto Rico, junto a Juan Carlos Copes y María Nieves, recibe la noticia de la muerte de su padre, Vicente "Nonino" Piazzolla. Ástor vuelve a Nueva York, donde vivía con su familia, y allí compuso «Adiós Nonino», su obra más célebre, que conservaría la sección rítmica del anterior tango «Nonino», más una sentida elegía de despedida, que se convertiría en un sinónimo de Piazzolla a lo largo de los años. La muerte del padre de Ástor trajo algunos colapsos en la vida de la familia: su matrimonio hasta ese entonces con Dedé entró en crisis y se separaron, mientras que también la relación con sus hijos se vio seriamente mermada, no pudiendo ser arreglada totalmente.

En 1990, durante una entrevista declaró que: «El tango número uno es 'Adiós Nonino'. Me propuse mil veces hacer uno superior y no pude». Se registran más de 170 versiones de «Adiós Nonino» de distintos músicos.
Frustrado por el intento del "jazz"-tango, vuelve a Buenos Aires en 1960 y forma la agrupación que definiría su estilo musical definitivamente, que sería la base de agrupaciones posteriores y a la que volvería cada vez que se sentía frustrado por otros proyectos: el Quinteto Nuevo Tango, formado en su primera versión, por Piazzolla en el bandoneón, Jaime Gosis en piano, Simón Bajour en violín, "Kicho" Díaz en contrabajo y Horacio Malvicino en guitarra eléctrica.

Con esta agrupación daría a conocer "Adiós Nonino" y todas las composiciones que dieron forma a su estilo y que serían las más recordadas: Las Estaciones ("Verano Porteño", "Otoño Porteño", "Invierno Porteño" y "Primavera Porteña"), La Serie del Ángel ("Introducción al ángel", "Milonga del ángel", "Muerte del ángel" y "Resurrección del ángel"), La Serie del Diablo ("Tango diablo", "Vayamos al diablo" y "Romance del diablo"), "Revirado", "Fracanapa", "Calambre", "Buenos Aires Hora Cero", "Decarísimo", "Michelángelo ´70" y "Fugata", entre otros. Esa última pieza está basada en la obra del compositor alemán Johann Sebastian Bach.

En 1963, forma el Nuevo Octeto, para el cual compuso "Introducción a «Héroes y tumbas»", con letra de Ernesto Sabato.
En ese año también gana el Premio Hirsch por su «Serie de tangos sinfónicos», estrenados bajo la dirección de Paul Klecky.

En 1965, junto al Quinteto, una orquesta formada "ad hoc", y con las voces de Luis Medina Castro como recitante y Edmundo Rivero como cantante, graba el disco "El tango", que contiene temas con letras de Jorge Luis Borges, incluido "Hombre de la esquina rosada", suite para canto, recitado y doce instrumentos. Precisamente en el citado año, Piazzolla cobró por 754.000 pesos (una suma alta para la época) de regalías por parte de la SADAIC, los álbumes del quinteto se vendían razonablemente bien, lo que le permitió negociar con los sello condiciones que no fueran abusivas para él.

En 1966 se separa de Dedé Wolff y en 1967 empieza su colaboración con el poeta Horacio Ferrer, con quien compuso la operita "María de Buenos Aires", que se estrenaría al año siguiente, con la cantante Amelita Baltar. Por otra parte, Piazzolla inicia con Baltar una relación sentimental que durará cinco años.

En 1969, Piazzolla y Ferrer componen la exitosa "Balada para un loco", que supondría una popularidad súbita para Piazzolla.

En 1970 retornó a París donde nuevamente junto a Ferrer, creó el oratorio "El pueblo joven", estrenado poco después en 1971 en Saarbrücken, Alemania. Al año siguiente fue invitado por primera vez a presentarse en el Teatro Colón en Buenos Aires, junto con otras importantes orquestas de tango. También en 1972, Piazzolla compone, para su Conjunto 9 el «Concierto de Nácar, para nueve tanguistas y orquesta filarmónica», primer antecedente de sus obras sinfónicas para bandoneón posteriores.

En 1973 sufre un infarto que lo obliga a reducir su actividad, por lo que se instala en Italia, en donde permaneció grabando durante cinco años. Durante esos años, formó el Conjunto Electrónico, un octeto integrado por bandoneón, piano eléctrico o acústico, órgano, guitarra, bajo eléctrico, batería, sintetizador y violín (el cual posteriormente fue reemplazado por una flauta traversa o saxo). La formación fue integrada por reconocidos músicos italianos como Pino Presti en bajo eléctrico y Tullio De Piscopo en batería. Tiempo más tarde, Ástor incorporaría al octeto al cantante José Ángel Trelles.

En 1974 se separó de Amelita Baltar, y ese mismo año graba, junto a una orquesta de músicos italianos, los álbumes "Summit", con Gerry Mulligan, y "Libertango", cuyo éxito lo hace conocido en Europa. Al año siguiente, el Ensemble Buenos Aires graba su obra "Tangazo" para orquesta sinfónica.

En 1975, después del fallecimiento de Aníbal Troilo, Ástor compone en su memoria una obra en cuatro movimientos a la que llamó "Suite Troileana", la cual grabó junto al Conjunto Electrónico.

Al año siguiente, conoce a Laura Escalada, quien sería su esposa definitiva. En diciembre de ese año presenta junto al Conjunto Electrónico en el teatro Gran Rex en Buenos Aires su obra "500 motivaciones". Meses después ofrecería otro concierto en el Olympia de París junto a una formación similar a la que tocó en Buenos Aires, la cual sería su última presentación junto a una formación de carácter eléctrico.

A partir de 1978 volvió a trabajar junto al quinteto Nuevo Tango y retomó la composición de obras sinfónicas y piezas de cámara.

En 1982 escribe "Le Grand Tango", para chelo y piano, el cual estuvo dedicado al chelista ruso Mstislav Rostropóvich. 

En 1984 tocó con la cantante Milva en Bouffes du Nord en París, Francia, y en Viena, Austria, con el Quinteto Tango Nuevo donde grabó el álbum en vivo Live in Wien. Tocó en Berlín, Alemania, y en el teatro Vredenburg en Utrecht, Países Bajos, donde el director de VPRO-tv, Theo Uittenbogaard, hizo grabaciones y le permitió, para su gran placer, tocar en el contexto de la proyección en vivo extremadamente ampliada de su bandoneón. Para muchos, esta fue la mejor actuación y la mejor grabación de sonido de este episodio en su carrera. 

En 1985 fue nombrado Ciudadano ilustre de Buenos Aires, obtuvo el Premio Konex de Platino como el mejor músico de tango de vanguardia de la historia en Argentina y estrenó en Bélgica su "Concierto para Bandoneón y Guitarra: Homenaje a Lieja". En 1985 regaló al grupo «Nuevos aires» su partitura «500 Motivaciones» que fue interpretada en la Sala A y B del Centro Cultural General San Martín en su homenaje al ser nombrado «Ciudadano ilustre de la Ciudad de Buenos Aires».

En 1987 viaja a Estados Unidos, donde graba en vivo en el Central Park junto a la Orquesta de St. Luke's, dirigida por Lalo Schifrin, sus obras "Concierto para Bandoneón" y "Tres Tangos para Bandoneón y Orquesta". Durante esta etapa en los Estados Unidos también tuvo la oportunidad de grabar "Tango Zero Hour", "Tango apasionado", "La Camorra", "Five Tango Sensations" (junto al Kronos Quartet) y "Piazzolla con Gary Burton" entre otros.

En 1988 fue operado del corazón en un cuádruple baipás y a principios del año siguiente formaría su último conjunto, el Sexteto Nuevo Tango formado por dos bandoneones, piano, guitarra eléctrica, contrabajo y violonchelo.

El 4 de agosto de 1990 en París, sufrió una trombosis cerebral cayéndose en el baño de un apart-hotel parisino. Fue internado con un infarto cerebral del que no se recuperó. Lo trasladaron a Buenos Aires el 12 de agosto, de la que finalmente fallecería dos años después en Buenos Aires el 4 de julio de 1992, a los 71 años. Sus restos están inhumados en el cementerio Jardín de Paz, en la localidad de Pilar.

En sus últimos diez años, escribió más de 300 tangos, unas cincuenta bandas musicales de películas, entre las cuales se encuentran: "Henry IV" de Marco Bellocchio, "Lumière" de Jeanne Moreau, "Armaguedon" de Alain Delon, "Sur", "El exilio de Gardel" de Fernando Solanas. En febrero de 1993, Piazzolla fue nominado de manera póstuma para los Premios Grammy 1992 en Los Ángeles por "Oblivion" en la categoría "Mejor Composición Instrumental".

Una de las principales invenciones rítmicas de Piazzolla tiene que ver con un desplazamiento del acento en el interior de la milonga y con un particular efecto de sincopa, que deriva en su forma de 8 pulsos agrupados en 3+3+2 y que introduce un principio de ambigüedad en la cerrada métrica del tango. Se trata de uno de los rasgos más característicos del músico. Hasta Piazzolla la rítmica del tango no presentaba variantes en la métrica sino en el tempo, en los cambios de velocidad en el curso de la interpretación; con Piazzolla la rítmica del tango se enriquece en la composición mismo, en la escritura. El uso de agrupamientos asimétricos, del tipo 3+3+2, conecta la música de Piazzolla con Bela Bartok: el músico húngaro había descubierto ese tipo de agrupamientos en el folclore de su región. A diferencia de lo que ocurre con otros intérpretes, los agrupamientos irregulares son empleados por Piazzolla con suma regularidad, como un patrón más bien estable que le otorga al tango una propulsión completamente novedosa. La música de Piazzolla conecta con esos agrupamientos rítmicos desde sus particular reelaboración de la milonga. Podría pensarse que en Piazzolla siempre se está oyendo la milonga, ya sea en sus formas más lentas o en sus variantes. Dos cosas que eran sumamente características del tango fueron excluidas en un momento por Piazzolla: el baile y el canto, de hecho, la naturaleza polifónica de la orquestación de Piazzola expulsa al cantante.

El concepto de su Octeto se emparenta desde ya, con el sonido del sexteto de Julio De Caro de 1926 y con el grupo que había unido a este violinista con Elvino Vardaro, Los Virtuosos. Pero el toque definitivo, ese carácter de urgencia con el que sonaba la música, esa sensación de ejecución en el límite de las posibilidades técnicas (el correlato estético de la “vida peligrosa” de los negros norteamericanos y del “compromiso” de los existencialistas franceses), venían del jazz. Y podría pensarse que volvieron al jazz si se tiene en cuenta que esa música sonó, sobre todo, para su público y en lugares donde Piazzolla compartía escenario con el "mono" Entique Villegas, con los hermanos Rubén y Leandro “Gato” Barbieri y con Sergio Milhanovich, dos por Jim Hall, Art Farmer, Bill Evans y Stan Getz. La forma y el tratamiento sin embargo se alejan notablemente de todo lo que había hecho hasta el momento dentro del campo popular. Se trataba de poner un instrumento en ese molde (una orquesta de tango estilizada, con cuerdas, bandoneón y piano concertantes) un contenido clásico (sus ejercicios de composición del periodo Ginastera). “Tres minutos con la realidad” es más una especie de mini “Rhapsody” tamizada por Bartok (el título elige la explicitación de una tensión entre la realidad –la actualidad-. Y el mundo del tango. Esa tensión aparece representada, por un lado, por los ritmos aditivos del comienzo, el solo a la Bartok del piano de Sonata para piano de Ginastera –recursos ya antiguos en el universo de la composición clásica pero sumamente novedoso en el contexto elegido por Piazzolla-, que estarían hablando de esa realidad atravesada por el presente. Un gesto, una pulsación que, con algunos variantes: los ritmos se irían haciendo más previsibles y regulares musicalmente a la ciudad, tomada como sujeto, y que terminarían identificando a Buenos Aires, también, para los otros, aun sus detractores.

En “Se armó” de José Staffolani y Pedro Maffia, uno de los arreglos grabados por la orquesta de Piazzolla en 1947, irrumpe el glissando que bien pude haber escuchado en Ravel o en el cine. En sus propios “Pigmalion”, donde muestra un minuto de introducción instrumental “Villeguita” de 1948 en que presenta el ritmo 3+3+2 con un manejo mucho más suelto del contrapunto y la armonía, se destaca ese estilo que seduce a Noticias Gráficas. Todo es resaltado por el ajuste extraordinario de la orquesta “Del 46” donde estaba también Atilio Stampone, Hugo Baralis y Leopoldo Federico y que también contó con Roberto di Filippo, un bandoneonista que fue fundamental para Piazzolla en la construcción de su propia manera de tocar. Piazzolla años después veía una intención de cambio en sus arreglos de ese entonces pero, al mismo tiempo, reconocía que aun no tenía claro lo que quería. En 1948 disolvió la orquesta, a su juicio, era demasiado avanzada para la época.

Entre los músicos contemporáneos de quienes Piazzolla tenía como fuente de inspiración y admiraba se encuentran Alfredo Gobbi y, fundamentalmente, Osvaldo Pugliese. Este último con sus composiciones "Negracha", "Malandraca" y "La yumba" se adelantó a lo que Ástor luego realizaría. Básicamente en la música de Piazzolla la marcación rítmica está basada en el tango "Negracha" compuesto por Pugliese en 1943 y grabado en 1948. Siempre hubo entre ellos una relación de respeto y admiración mutua. Pugliese hizo versiones de tangos de Piazzolla como "El cielo en las manos" en 1951, "Marrón y azul" en 1956, "Nonino" entre 1961 y 1962, "Verano porteño" en 1965, "Balada para un loco" en 1970 y "Zum" en 1976. Piazzolla a su vez grabó de Pugliese: "Recuerdo" en 1966 y "Negracha" en 1956. Compartieron un recital juntos en el teatro Carré de Ámsterdam, el 29 de junio de 1989. Cerraron el recital tocando juntos sus éxitos más populares: "La yumba" y "Adiós Nonino". Ambos en una entrevista previa manifestaron su admiración y respeto mutuos y lamentaron el hecho que ese recital no se realizase en Argentina.

Entre las influencias de la música europea, podemos también citar a Johann Sebastian Bach (del periodo barroco) de quien queda notoriamente marcado su influjo en lo tocante al desarrollo de patrones armónicos, fugas y el uso del contrapunto, como así también a Bela Bartok (contemporáneo). Según el baterista José Luis Properzi, su música también tiene puntos en común con la obra de los estadounidenses George Gershwin y Brian Wilson. Por otro lado, tuvo una gran admiración y conoció personalmente a Igor Stravinsky.

En 1995 la Fundación Konex le confirió el Premio Konex de Honor por su incalculable aporte a la música en Argentina.

En 1996, los días 13, 14 y 15 de junio en el Teatro Ópera de Buenos Aires se realizó un homenaje ideado por Eliseo Álvarez con el nombre de «Astortango». En dicho espectáculo actuaron destacados músicos argentinos y de todo el mundo interpretando las obras del maestro Piazzolla, entre ellos se encontraban Gary Burton, Chick Corea, Hermeto Pascoal, Jairo, Gerardo Gandini, Fernando Suárez Paz, Horacio Malvicino, Juan Carlos Cirigliano, Rodolfo Mederos, Julio Pane, Néstor Marconi, Raúl Luzzi, Arturo Schneider, Daniel Binelli, su hijo Daniel y su nieto Daniel «Pipi» Piazzolla.

En 1993, la Asociación de Música de Pesaro, por la voluntad del Maestro Hugo Aisemberg y otras personalidades de la cultura de Pesaro, fundó el Centro Astor Piazzolla.

En 2008, el aeropuerto internacional de Mar del Plata, su ciudad natal, recibió el nombre de «Aeropuerto Internacional Astor Piazzolla», en su memoria.

A partir del año 2007 se formó el quinteto radicado en Londres Fugata Quintet, con músicos graduados en la Royal Academy of Music de Londres, unidos por su común pasión por Piazzolla y su Nuevo Tango. Su nombre mismo se deriva «del segundo movimiento, «Fugata», de la Tangada-suite 'Silfo y Ondina' de Ástor Piazzolla. Es un reconocimiento del quinteto, cuyo carácter y origen son principalmente clásicos, queriendo reflejar los propios orígenes clásicos del compositor, y su frecuente uso de las formas y las técnicas de composición clásicas en sus muchas y notables obras para quinteto». Formado por los músicos Antonis Hatzinikolaou (guitarra), Anastasios Mavroudis (violín), Zivorad Nikolic (acordeón), James Opstad (contrabajo) y Anahit Chaushyan (piano), están llevando a cabo en los últimos años en Londres una importante labor de difusión de la obra de Piazzolla, con exitosas actuaciones en directo y grabaciones dedicadas monográficamente a su obra en salas tan prestigiosas como el Royal Albert Hall, el Southbank Centre's Purcell Room, o The Forge, así como emisiones a través de la Radio 3 de la BBC, habiendo lanzado recientemente un aclamado álbum doble con música del compositor argentino.








</doc>
<doc id="6718" url="https://es.wikipedia.org/wiki?curid=6718" title="Carlos Gardel">
Carlos Gardel

Carlos Gardel fue un cantante, compositor y actor de cine. Es el más conocido representante (del género) en la historia del tango. Iniciador y máximo exponente del tango canción, fue uno de los intérpretes más importantes de la música popular mundial en la primera mitad del siglo, por la calidad de su voz, por la cantidad de discos vendidos (como cantante y como compositor), por sus numerosas películas relacionadas con el tango y por su repercusión mundial.

No hay unanimidad sobre el lugar y la fecha de su nacimiento. La hipótesis uruguayista sostiene que nació en Tacuarembó (Uruguay), un 11 de diciembre entre 1883 y 1887. La hipótesis francesista sostiene que nació en Toulouse (Francia) el 11 de diciembre de 1890.

Hay unanimidad en el hecho de que vivió desde su infancia en Buenos Aires y se nacionalizó argentino en 1923. Falleció el 24 de junio de 1935 en Medellín, Colombia, en un accidente aéreo.

La persona y la imagen de Gardel ha sido objeto de idolatría popular, especialmente en Argentina y Uruguay, colocándolo en un lugar de mito y símbolo cultural que aún mantiene su vigencia.

En 2003 la voz de Gardel fue registrada por la Unesco en el programa Memoria del Mundo, dedicado a la preservación de documentos pertenecientes al patrimonio histórico de los pueblos del mundo. Al mismo tiempo, se hace alusión a su voz y su recuerdo con la frase ""cada día, canta mejor"".

La fecha y el país de nacimiento de Gardel está sujeto a controversias históricas (ver sección Controversias sobre su lugar de nacimiento). Para la hipótesis uruguayista nació en Tacuarembó (Uruguay) entre 1883 y 1887, mientras que para la hipótesis francesista nació en Toulouse (Francia) en 1890. Como consecuencia de dichas discrepancias, cada una de las hipótesis sostiene relatos diferentes sobre los hechos de su infancia y adolescencia.

Para la hipótesis francesista Marie Berthe Gardes, cuyo nombre castellanizado fue Berta Gardés, fue la madre biológica de Charles Romuald Gardes, cuyo nombre fue castellanizado en Buenos Aires como Carlos Gardés y luego transformado en Carlos Romualdo Gardel por el propio cantante. En esta versión, Gardel habría estudiado en el Colegio Salesiano Pio IX de Buenos Aires, donde permaneció pupilo en 1901 y 1902 y fue compañero de coro de Ceferino Namuncurá, futuro beato argentino.

La hipótesis uruguayista sostiene que Marie Berthe Gardes obró como madre adoptiva de Carlos Gardel y que Charles Romuald Gardes fue un hijo biológico de Berthe, menor que Carlos. La Junta Departamental de Montevideo reconoció oficialmente la asistencia de Carlitos Gardel a la Escuela de 2.º Grado de Varones del barrio Palermo de Montevideo entre los años 1891 y 1893.

Ambas hipótesis coinciden en el hecho de que Gardel fue abandonado por su padre y que vivió en Buenos Aires al menos desde 1893, en habitaciones de conventillos que compartía con su madre, aunque con intermitencias que varían según el historiador. Recién en 1927 Gardel comprará una casa en el barrio del Abasto, donde se mudará con su madre.

Ambas hipótesis coinciden también en que el joven Gardel, durante la primera década del siglo xx, pudo haber tenido conductas y frecuentar ámbitos ubicados en los márgenes de la legalidad, de lo que dan cuenta prontuarios policiales de 1904 y 1915 que lo mencionan y cuyas huellas digitales coinciden con las del cantante, como probó una investigación realizada por el criminólogo Raúl Torre y el médico forense Juan José Fenoglio.

Durante su infancia y adolescencia, Gardel vivió en paupérrimas casas de inquilinato o conventillos, ubicados en el barrio de San Nicolás: primero en Uruguay 162 y luego en Corrientes 1553. Con sus primeros ingresos como músico profesional en 1914 se mudó, siempre con su madre, a un departamento modesto en Corrientes 1714. La pobreza extrema y las condiciones de vida degradantes de los conventillos porteños en la época de la gran inmigración han sido estudiadas en obras sociológicas, y representadas en obras artísticas, como "El conventillo de la Paloma". Su amigo y chofer Antonio Sumaje ha contado que cuando Gardel ya era una estrella solía pedirle que le llevara a los conventillos en los que había vivido de niño, en especial al de Uruguay 162, donde se bajaba y se quedaba mirando la fachada:

El barrio en el que Gardel se crio es la zona de los teatros porteños que tiene su eje en la calle Corrientes, luego transformada en avenida. Eso le permitió desde muy chico estar en contacto con el mundo teatral. Su madre trabajaba planchando ropa, a veces para algunos de esos teatros, y él mismo fue reclutado por un personaje conocido como «Patasanta», que organizaba claques de aplaudidores en los teatros, cobrando dinero por prestar ese servicio. Con la «"troupe" de animadores» de Patasanta, Gardel fue claque, utilero y comparsista (extra), a cambio de poder asistir a los espectáculos y recibir entradas. De esta manera logró estar en contacto con actores y cantantes, de quienes imitaría los ejercicios de vocalización y otras conductas que serían de importancia para su futura formación artística:

Así, entre muchos otros empleos informales, se desempeñó como tramoyista en el Teatro de la Victoria, donde escuchó al zarzuelista español Sagi Barba, con quien incluso llegó a tomar sus primeras lecciones informales de canto, y en 1902 pasó al Teatro Ópera, donde conoció al barítono italiano Titta Ruffo.

En esa época, siendo ya un adolescente, comenzó a frecuentar el barrio del Abasto, un barrio popular recién organizado alrededor del entonces nuevo mercado, abierto en 1893. Gardel fue invitado por un grupo de jóvenes (José «El Tanito» Oriente, Domingo «Daguita» Vito) a integrarse a la «barra» del café O'Rondeman, que estaba en Agüero y Humahuaca. El café era propiedad de los hermanos Traverso (Alberto o «Giggio», Constancio, Félix y José o «Cielito»). Estaba administrado por el primero de ellos, el «Gordo» Giggio o Yiyo, que establecería con Gardel una relación de gran afecto mutuo, con características paterno-filiales, al punto que cuando aquel falleció en 1923, Carlos fue uno de los que sostuvo el féretro. Los hermanos Traverso, liderados por Constancio, dominaban políticamente el barrio del Abasto, en nombre del Partido Autonomista Nacional, el partido conservador fundado por Julio Argentino Roca que gobernó sin alternancia el país, sobre la base del fraude electoral, entre 1874 y 1916. El joven Gardel fue un protegido de los hermanos Traverso, que valoraron desde un inicio la calidad de su canto -de gran importancia para organizar la sociabilidad popular-, y promovieron su actuación tanto en el Bar O'Rondeman, como en los comités conservadores del barrio, de otras zonas de la ciudad, e incluso de Avellaneda, donde se relacionó con el hombre fuerte del conservadurismo bonaerense, Alberto Barceló y su famoso matón Ruggierito.

Gardel comenzó a cantar semiprofesionalmente en el café de los Traverso y en el comité conservador de Anchorena 666. Años después, en 1927, se mudó con su madre a una casa que compró exactamente a la vuelta del comité, actual Casa Museo Carlos Gardel. En esa época el canto popular estaba dominado por el arte de la payada, cuya figura máxima era Gabino Ezeiza. Gardel no tenía habilidad para inventar sus propios versos a medida que cantaba, que era la característica decisiva para el éxito de los payadores, pero la calidad de su voz le fue abriendo camino poco a poco. «Gardel nunca fue payador; él era cantor», dice el historiador Pablo Taboada.

De esa época viene la relación de Gardel con la payada, en especial con José Betinotti, a quien se le atribuye haberle puesto el apodo del «Zorzalito» o «Zorzal Criollo», es decir el nombre de uno de los pájaros característicos de las pampas, como es el zorzal, destacado por la belleza de su canto. Uno de los primeros temas que grabó Gardel fue «Pobre mi madre querida», la canción más famosa de Betinotti. También de esta época viene la relación con el payador Arturo de Nava. En 1922, el dúo Gardel-Razzano, grabaría la obra más famosa de De Nava, «El carretero», que se convirtió en el principal éxito de Gardel en su primera gira a Francia (1928/1929) y que luego fue incluida entre los famosos cortos cinematográficos musicales realizados en 1930, donde Gardel aparece hablando con el payador, ya en el momento de decadencia de su carrera, quien le agradece el hecho de cantar su tema.

Durante toda esa primera década como cantor, Gardel nunca cantó un tango, aunque lo bailaba. Construyó su estilo de canto a partir de la payada y las canciones camperas, pero también de la "canzonetta" napolitana y la ópera.

En 1910, siendo todavía desconocido para el público, cantó una noche para una tertulia habitual de yoqueis y cuidadores de caballos de pura sangre en la confitería La Frazenda, en el Bajo Belgrano, con motivo de haberle apostado a una yegua que ganó la carrera, obteniendo una importante ganancia. En 1936 un tal Laureano Gómez, que estuvo presente aquella noche, publicó un relato acerca de la presentación de Gardel:

Para la segunda década del siglo, Gardel era habitualmente referido como "El Morocho del Abasto".

A comienzos de la segunda década del siglo se encuentran Carlos Gardel y el uruguayo José Razzano, "El Oriental". En sus "Memorias" Razzano ubica ese encuentro en 1911, en la casa de un amigo ubicada en la calle Guardia Vieja, a pocos metros del Mercado de Abasto. Años después esa parte de la calle, entre Jean Jaurés y Anchorena, será renombrada como pasaje Carlos Gardel.

Gardel ya había empezado a cantar a dúo con Francisco Martino, sumándose Razzano y poco después el cuyano Saúl Salinas. Lo cierto es que los cuatro se mantuvieron vinculados, cantando alternativamente en dúos, trío y cuarteto, en diversos barrios y ciudades de Argentina de manera semiprofesional, hasta que poco a poco fue decantando el dúo Gardel-Razzano, estableciendo su barra de amigos y su base artística en el Café de los Angelitos, un punto intermedio entre el Abasto -donde "paraba" Gardel- y Balvanera Sur, donde estaba ubicado el "Café del Pelado" de Moreno y Entre Ríos (aún en pie), en el que "paraba" Razzano.

En ese período la Casa Tagini, que tenía la representación de Columbia Records y se había convertido en la principal empresa discográfica de Argentina, contrató a Gardel para grabar en 1912 siete discos dobles con canciones de su elección, que son lanzados al mercado en 1913, cuando todavía era un desconocido. Esos discos son la primera constancia de la presentación del joven cantor con el nombre de Carlos Gardel. Los siete discos fueron los siguientes:

La expresión «estilo» es la que se utilizaba en la época para referirse a los ritmos camperos y rurales. Por esa razón los cantores como Gardel eran llamados «estilistas». Algunas décadas después, en Argentina comenzó a usarse la expresión para denominar a esos géneros musicales. En el repertorio elegido por Gardel se destaca «Mi madre querida» ―canción emblemática del payador José Betinotti― y seis poemas musicalizados de Andrés Cepeda ―un poeta asesinado dos años antes y acosado por la policía debido a sus ideas anarquistas y su condición homosexual, que conmovía la sensibilidad del joven Gardel―. El resultado no fue el esperado y Gardel debería esperar hasta 1917 para volver a grabar nuevamente.

En 1914 Gardel y Razzano fueron contratados para cantar en el suntuoso cabaré Armenonville de Buenos Aires, por un caché de 70 pesos la noche, una suma inesperada que Gardel confundió con la retribución quincenal. Gobello considera que esa fue la primera actuación profesional de Gardel. El éxito de sus actuaciones en el Armenonville le abrieron al dúo las puertas hacia los grandes escenarios del espectáculo porteño. Pocos días después el célebre Pablo Podestá, los contrataba para cantar durante dos semanas en el espectáculo que estaba por estrenar en el Teatro Nacional, su primera actuación en la calle Corrientes.

Años después en una carta a Razzano escrita desde París, Gardel recordaría aquel debut en el Armenonville del siguiente modo:

1915 fue un año complejo para Gardel, en el que las dificultades del pasado y los éxitos del futuro parecieron confundirse. A mitad de año fueron contactados por el empresario uruguayo Manuel Barca que había ido a Buenos Aires para contratarlos para actuar en Montevideo. Los jóvenes recibieron la oferta incrédulos e inseguros. El destacado historiador montevideano Julio César Puppo cuenta del siguiente modo aquel encuentro:

Montevideo los recibió como si fueran celebridades, con la ciudad empapelada con sus retratos y un programa de actividades que incluía ser recibidos en el puerto, llevados a desayunar, entrevistas con la prensa y una actuación reservada para personas influyentes. El 18 de junio debutaron en el Teatro Royal, con lleno completo, y por primera vez el público les pidió que repitieran los temas al grito de «tocate otra, Carlitos». Dice Puppo que al terminar la función Gardel se puso a llorar de emoción en el camerino.
Desde entonces Gardel se sentiría en Montevideo como en su propia casa, con su propia barra de amigos, volvería a cantar una y otra vez y al final de sus días mandó a construir una vivienda en la que no llegó a vivir debido al accidente que le costó la vida.

Pocos días después, su condición de indocumentado lo llevó a proporcionar datos falsos para obtener documentos que le permitieran viajar a Brasil, en una gira de la Compañía Dramática Rioplatense encabezada por Elías Alippi, en la que al dúo le correspondía realizar el fin de fiesta.
En el barco conoció al cantante de ópera napolitano Enrico Caruso, quien elogió la voz de Gardel, pero la presentación de la compañía en São Paulo y Río de Janeiro no pudo superar la barrera del idioma, aunque la actuación del dúo recibió elogios de la prensa brasileña. Para mal de males Gardel fue detenido por la policía brasileña al haber sido encontrado en compañía de delincuentes argentinos que se habían establecido allí.
Del expediente formado para tramitar la documentación, surgió también que Gardel tenía antecedentes como estafador de poca monta por realizar «cuentos del tío».
Estos datos bloquearían años después el proyecto de nombrar a la Avenida Corrientes con su nombre.

En el barco de regreso de Brasil Alippi le ofrece al dúo participar de una nueva producción de "Juan Moreira", famosa obra fundacional del teatro argentino, estrenada exitosamente el 12 de noviembre en el teatro San Martín. "Los Gardel Razzano" cantaban en una siempre celebrada escena musical en una pulpería en la que baila Moreira, estrenando en esa oportunidad la cueca «Corazones partidos» de su excompañero Saúl Salinas.
En esa ocasión el dúo fue acompañado por 20 guitarristas encabezados por José Ricardo y Horacio Pettorossi. La diferencia de calidad los llevó a contratar desde entonces a Ricardo como guitarrista permanente del dúo, en tanto que Pettorossi integraría el grupo de guitarristas de Gardel en los años 30.

Antes de finalizar el año, en la noche del 10 al 11 de diciembre de 1915, recibió un balazo en un confuso episodio. El hecho sucedió durante un altercado en la calle luego de celebrar su cumpleaños en el Palais de Glace (salón de baile de la época en el barrio de la Recoleta), cuando estaba acompañado por los actores Elías Alippi y Carlos Morganti. Para entonces Gardel ya era conocido y el hecho apareció en la crónica policial de los diarios "La Prensa" y "La Razón" («Agresión a Gardel»), donde se señaló que los agresores fueron un tal Roberto Guevara -el autor del disparo- y Moreno Gallegos Serna, probables matones del bajo mundo, este último mencionado por Eduardo Arolas al dedicarle su tango «Suipacha».
Las causas y sucesos posteriores a la agresión permanecen confusos.
Su amigo Edmundo Guibourg relata que luego del ataque, Gardel fue a Tacuarembó para recuperarse, donde se encontró con el hermano menor del caudillo Traverso, «Cielito Traverso», escondido allí por haber asesinado a un hombre en el cabaré Armenonville.
También se ha difundido la información falsa de que el matón Roberto Guevara era en realidad Roberto Guevara Lynch, tío del todavía no nacido Che Guevara y miembro de una rica familia porteña.
Finalmente, al morir Gardel la bala aparecería en su autopsia, dando pie también a hipótesis sobre un enfrentamiento armado en el avión que habría causado el accidente que le costó la vida.

En la segunda década del siglo el mundo del espectáculo porteño se caracterizó por una enorme difusión del "varieté", una modalidad surgida en Francia y tomada de España, que consistía en una sucesión de actuaciones cortas, de los más diversos tipos (musicales, dramáticas, humorísticas, circenses, de magia, etc.). Luego de iniciarse en 1916, durante la temporada veraniega de Mar del Plata, a mitad del año son contratados para presentarse en el Teatro Esmeralda (luego Teatro Maipo), ubicado a metros de la famosa esquina tanguera de Corrientes y Esmeralda, y a principios del año siguiente debutan también en el vecino Empire Theatre, de la calle Corrientes y Maipú, dirigidas a un público de mayor poder adquisitivo. El éxito fue consagratorio y sus actuaciones se extenderían en ambos teatros por seis años.

En esa primera época la actuación del dúo Gardel-Razzano alternaba temas cantados como solistas y temas a dúo. El famoso folklorista Osvaldo Sosa Cordero recuerda haberlos visto cuando era un adolescente y contó que la presentación la abrieron a dúo interpretando «Brisas de la tarde», la primera canción del dúo sobre un poema de José Mármol, tras lo cual Razzano cantaba la cifra «Entre colores», una de las canciones con la que se lo identificaba. Luego cantaron a dúo «Cantar eterno» de Villoldo y el gato «El sol del 25». Los favoritos de Gardel para cerrar eran dos canciones sobre caballos, la gran pasión de Gardel: «El moro» (sobre un poema Juan María Gutiérrez) y «El pangaré».
Precisamente, en el suceso en el que fue baleado, el pistolero había gritado «¡Ya no vas a cantar más "El moro"!».

Simultáneamente Gardel volvería a grabar y ya no dejaría de hacerlo en adelante. Vencido el contrato leonino con la discográfica Tagini-Columbia, llega a un acuerdo con la empresa de Max Glücksmann, bajo sellos como Disco Nacional y Odeon. El contrato establecía un monto de cuatro centavos por disco vendido (simples doble faz). En esos discos de 1917 el dúo grabó su repertorio, entre ellos «Mi noche triste», el primer tango que grababa Gardel.
Los discos se vendieron masivamente, en cantidades que superaban las 50 000 unidades de cada uno, con ganancias en el orden de los 8000 pesos por cada uno.

Finalmente Gardel coronaría ese año excepcional, protagonizando la película muda "Flor de durazno", basada en una exitosa novela de Hugo Wast, que fue dirigida por Francisco Defilippis Novoa y en la que interpretó al protagonista Fabián. Se trata de una de los primeros largometrajes del cine latinoamericano, cuando todavía era mudo, lo que indica la visión integral del espectáculo que Gardel estaba desarrollando. Gardel estuvo a punto de abandonar la filmación, descontento con su desempeño actoral, pero fue convencido de quedarse por el director, con el argumento de incluir varias secuencias suyas cantando, argumento incierto si se tiene en cuenta que se trataba de una película muda, aunque existe información de que en 1940 fue proyectada una versión sonora de la película, que quizás incluyera esos fragmentos.
"Flor de durazno" fue estrenada el 28 de septiembre de 1917, con excelente respuesta del público, manteniéndose varios años en cartel y superando las 800 representaciones.

La creciente preocupación de Gardel por su imagen, que tenía sus antecedentes en su famosa sonrisa y la simpatía que lo caracterizó desde un principio, se evidenciará también en las primeras fotos de estudio que comienza a encargar, sobre todo de quien se volvería su fotógrafo preferido, el hispano-uruguayo José María Silva y en el trabajo que iniciaría para estilizar su cuerpo, teniendo en cuenta que Gardel era un hombre bajo (menos de 1,70 de altura) y que en ese momento pesaba alrededor de 120 kilos.
Los biográfos Julián y Osvaldo Barsky dicen que estas conductas de Gardel indicaban «su esfuerzo por construir el galán-cantor, figura que lo proyectará internacionalmente».

El éxito masivo del dúo y de Gardel en particular, así como su ingreso al tango, coinciden con un momento de gran importancia en la vida político-social de la Argentina: la conquista de la democracia. Las presiones políticas y sindicales habían obligado al gobierno conservador a aprobar una ley de voto secreto y obligatorio (solo para varones), que le dio el triunfo en 1916 al partido radical, un movimiento ampliamente popular que llevó a la presidencia a Hipólito Yrigoyen.

En 1917 Gardel cantó y grabó un tango por primera vez. Se trató del tango «Mi noche triste», un tema musical compuesto por Samuel Castriota titulado «Lita» al que Pascual Contursi le había puesto letra. La interpretación de «Mi noche triste» por Gardel está considerada como la fecha de nacimiento del tango canción: luego de décadas de evolución, el tango había empezado a encontrar cantores y letristas capaces de interpretar la misma cadencia emocional que ya expresaba la música y el baile de tango.

El éxito del novedoso estilo del tango canción no fue inmediato. «Mi noche triste», con su letra lunfarda y su temática sobre el hombre de pueblo abandonado por su mujer («Percanta que me amuraste»), fue recibido por el público sin ningún entusiasmo desbordante. Por otra parte, los cantores "puros" veían con malos ojos ese lenguaje de calle y esa sensualidad prosaica y de mal gusto, que se apartaba del "verdadero arte criollo".
El gran Gabino Ezeiza establecía con claridad el rechazo al tango al aconsejarle a Carlos Marambio Catán:

Al año siguiente (1918) el sainete "Los dientes del perro", puesto en escena por la compañía de Muiño-Alippi, incluyó una escena en la que la jovencísima actriz Manolita Poli cantaba "Mi noche triste". El número causó sensación y fue decisivo para que tanto la obra como la versión de Gardel, lanzada en disco ese año, fueran un gran éxito.
Desde entonces el sainete y el tango establecerán un vínculo estrecho, promoviéndose mutuamente.

Ese año Gardel grabó otro tango, "A fuego lento", también de Contursi, y poco a poco fue construyendo un repertorio integrado mayoritariamente por tangos.
La voz y la manera de cantar de Gardel también fueron evolucionando a medida que se iba convirtiendo en un cantor de tangos. Gardel aprovecha sus orígenes en el ámbito de la payada y su gusto por la canzonetta napolitana y la ópera, en una ciudad considerada como "la más italiana fuera de Italia", en la que las personas de origen italiano, sobre todo los jóvenes, se habían vuelto el grupo étnico más numeroso, para desarrollar un canto más lento, grave, melancólico y menos ansioso, caracterizado por una interpretación emocional que lo ligaba a los sentimientos del oyente.

En 1919 solo una de las trece canciones que grabó Gardel ese año, fue un tango. En 1920 ya eran seis sobre veinticuatro (un 25%) y en 1921, ocho sobre veintidós (un 30%). Hasta que en 1922 los tangos superaron la mitad: doce sobre veintiún canciones grabadas.
En ese período el dúo suma un segundo guitarrista, Guillermo Barbieri y en 1923 Gardel estrena el tango "Mano a mano" («Rechiflado en mi tristeza»), con letra de Celedonio Flores, un notable poeta descubierto por Gardel en 1920, del que ya había grabado "Margot". "Mano a mano" se constituyó en uno de los máximos éxitos de Gardel, marcando el momento en que el tango canción terminaba de imponerse y, junto a las transformaciones instrumentales de músicos como Julio de Caro, se abría una era de plenitud para el género: la Guardia Nueva. En total Gardel grabaría 21 tangos de "El Negro Cele", entre ellos "El bulín de la calle Ayacucho", "Malevito", "Viejo smoking", "Mala entraña", "Canchero" y "Pan".
Flores también es autor de la letra del famoso tango "Corrientes y Esmeralda" (1933) que dice "en tu esquina rea, cualquier cacatúa sueña con la pinta de Carlos Gardel". Por humildad, Gardel se abstuvo de cantar ese célebre tango que lo idolatraba en vida.

Gardel sin embargo nunca dejaría de cantar los ritmos populares más variados. A través de músicos como el cordobés Cristino Tapia y el santiagueño Andrés Chazarreta incluyó nuevas canciones del folklore argentino norteño, a la vez que incorporaba cuecas chilenas, bambucos colombianos, foxtrots, shimmys, valses, tangos españoles, canciones en italiano, francés e inglés, y hasta una balada rusa como "Sonia" compuesta por un húngaro y un judío austríaco que años después sería asesinado por los nazis en Auschwitz o un tango con expresiones en guaraní como "Los indios" de Canaro y Caruso.
El investigador Félix Scolatti, quien acompañó al dúo en su única gira por Chile en 1917, contó que Gardel estaba todo el tiempo buscando nuevos ritmos populares y que oía con atención lo que cantaba la gente común en las calles y las plazas, memorizándolas y tomando notas, para después identificarlas.

En 1920 gestionó ante el consulado uruguayo en Buenos Aires, una certificación de nacionalidad y una cédula de identidad, donde declara haber nacido en Tacuarembó, Uruguay, en 1887. En 1923, con los documentos uruguayos obtenidos, solicitó la nacionalidad argentina, que le fue concedida inmediatamente, expidiéndose el pasaporte argentino que utilizaría para viajar.

Consolidado en su dominio del tango canción y con su dúo con Razzano en el punto más alto de celebridad en la Argentina, Gardel ya estaba en condiciones de apuntar a Europa y al mercado musical internacional creado por el disco, mercado que en el futuro inmediato se verá amplificado por el cine y la radio.

El tango venía difundiéndose como baile de moda en Europa desde la primera década del siglo, estallando la "tangomanía" poco antes de la Primera Guerra Mundial (1914-1918). En 1921 el italiano Rodolfo Valentino, adoptando la identidad de un bailarín argentino de tango vestido como gaucho, causaba sensación mundial con la película "Los cuatro jinetes del Apocalipsis". España en particular, tenía una historia tanguera previa incluso al tango argentino (el tango flamenco) y desarrollaría una importante vertiente autónoma del género, con epicentro en Barcelona y con canciones paradigmáticas, como «Fumando espero» del catalán Juan Viladomat Masanas (letra de Félix Garzo) y revistas especializadas como "Tango Moda".

En ese contexto Gardel estaba a punto de mostrarle al mundo un modo de cantar el tango que lo ubicaría entre los cantantes célebres de la historia de la música popular.

En 1923 el dúo Gardel-Razzano tiene la oportunidad de realizar su primera gira a Europa, puntualmente a España, acompañando a la compañía teatral encabezada por la actriz Matilde Rivera y su esposo el actor Enrique de Rosas. Como una estrategia escénica derivada del estereotipo internacional de la Argentina, los empresarios teatrales insistieron en que los músicos se presentaran vestidos de gauchos, aunque en Buenos Aires actuaran vestidos de esmoquin. Por esa razón, antes de partir se sacaron en Montevideo una nueva serie de fotos con José María Silva, disfrazados de gauchos. Debutaron el 10 de diciembre en el Teatro Apolo de Madrid, actuando con sus dos guitarristas como «fin de fiesta», luego de la representación dramática que la compañía realizaba cada noche. Las críticas sobre el dúo fueron buenas y luego de 40 presentaciones y con la misión de haber desembarcado en Europa cumplida, dejaron la compañía para ir a Francia, donde conocieron París y Gardel visitó a la familia Gardes en Toulouse.

En septiembre de 1925, luego de 12 años de cantar juntos y debido a una lesión de laringe de Razzano, el dúo decide separarse pasando Razzano a ejercer las funciones empresariales.
Años después, luego de un estricto trabajo foniátrico, Razzano intentaría volver al canto, pero sin mayores resultados. De ese intento final quedarían las dos últimas grabaciones del dúo, «Claveles mendocinos» de A. Pelaia y «Serrana impía», de José del Valle, grabadas el último día de 1929.

Mientras tanto, ya como solista, Gardel volvió a realizar giras por Europa, actuando nuevamente en España (1925/1926 y 1927) y luego en Francia (1928/1929). La gira de 1925/1926, con la misma compañía teatral que la realizada dos años antes, incluyó esta vez también a Barcelona, una ciudad que establecería un vínculo muy especial con Gardel.
El éxito obtenido allí lo llevó a extender sus actuaciones de diez días iniciales a dos meses. En Barcelona Gardel grabó también veintiún temas, incluyendo un tango que le ofreció en ese momento el pianista madrileño Teodoro Diez Cepeda, «Dolor», el primero de varios tangos y canciones españolas que Gardel irá grabando en el futuro, expresión de su vocación constante de conectarse con la canción popular de cada lugar. En la gira de 1925/1926, Gardel también se presentó con un éxito moderado en Madrid y en Vitoria, en el País Vasco, donde hasta ese momento era completamente desconocido.

Estando en Barcelona Gardel grabó varios temas para el sello Odeón utilizando por primera vez la grabación eléctrica con micrófono (antes se usaba bocina captora), el cambio tecnológico más significativo hasta el descubrimiento del elepé a fines de la década de 1940.
En Argentina, Gardel comenzará a grabar mediante este sistema desde el noviembre de 1926. La calidad de sus grabaciones mejorará notablemente desde ese entonces.
Los años 1926 y 1927 fueron los años en que más discos grabó, superando en ambos las 100 canciones. De los éxitos de esa época se destacan «Bajo Belgrano» y «Siga el corso» («Esa Colombina puso en sus ojeras humo de la hoguera de su corazón»), ambos de Aieta y García Jiménez, la primera versión de «Caminito», «A media luz» («Corrientes 348, segundo piso ascensor»), «Tiempos viejos» («¿Te acordás, hermano? ¡Qué tiempos aquellos!») de Canaro y Romero, así como las primeras canciones de letristas jóvenes que se volverían clásicos, como Enrique Cadícamo y Enrique Santos Discépolo («Que vachaché»).

En 1927 Gardel compra para él y su madre, su primera y única casa propia, ubicada en la calle Bermejo (luego Jean Jaurés) 735, una casa sencilla en el corazón de su barrio espiritual, el Abasto, exactamente a la vuelta del comité conservador en el que comenzó a cantar.

A fines de 1927 Gardel inició una nueva gira por España, la tercera, actuando en Barcelona, Madrid, Bilbao y Santander, con un éxito arrasador. «Vino Gardel y supimos lo que eran los tangos argentinos», sintetizó por entonces el periodista y músico catalán Brauli Solsona.
Antes de volver a Buenos Aires, Gardel pasó por París donde cerró un contrato para presentarse en París, en el segundo semestre de 1928.

Su estadía en Buenos Aires fue breve y luego de grabar varios discos (entre ellos el primer éxito de Discépolo «Esta noche me emborracho»), de cantar por radio Prieto, presentarse en el Teatro Solís de Montevideo y contratar un tercer guitarrista, el «Indio» José Aguilar, zarpó nuevamente para Europa, esta vez con destino a París.

Cuando Gardel debutó en París, el tango en Francia ya tenía más de dos décadas de historia y junto al jazz, era protagonista de la noche parisina.
El centro de la vida nocturna en París era Montmartre y la aledaña plaza Pigalle y el centro de la vida tanguera era el restaurante «El Garrón», donde durante casi una década había brillado el músico Manuel Pizarro, que jugó un papel crucial promoviendo la contratación de Gardel. «Sin embargo -dicen los biógrafos Barsky-, a todo ese despliegue tanguero de casi tres décadas (en París) le faltaba una gran voz».

Gardel y sus tres guitarristas (Ricardo, Barbieri y Aguilar) debutaron en París el 30 de septiembre de 1928, en una función de beneficencia en el teatro Fémina en Les Champs-Élysées y luego el 2 de octubre en el cabaré Florida, en Montmartre. Sus presentaciones se extendieron hasta abril de 1929, actuando también en los teatros Empire y Paramount, así como en las ciudades de Cannes y Montecarlo, siendo el punto más alto la invitación a participar del distinguido evento benéfico Bal des Petit Lits Blancs en la Ópera de París. Interpretó un repertorio variado, que incluía canciones en francés, que fueron muy bien recibidas. De aquel repertorio se destacaron los tangos «Adiós muchachos» y «Siga el corso», pero sobre todo la canción campera de Arturo de Nava, «El carretero», que Gardel interpretaba con silbidos, como si él mismo estuviera arreando los bueyes de la carreta.
El éxito fue rotundo, la venta de discos superó todas las previsiones y los parisinos silbaban «El carretero» por las calles.
En la Navidad de ese año, su foto fue tapa de "La Rampe", la principal revista de espectáculos, mientras que el mayor periódico francés, "Le Figaro", ya había descripto su presentación en la Ciudad Luz como un «éxito triunfal» y explicaba del siguiente modo la sensación que el cantor argentino generaba sobre el público:

Luego de actuar seis meses en París, Gardel actuó un mes más en Barcelona y Madrid, antes de retornar a Buenos Aires, donde llegó el 16 de junio de 1929, nueve meses después de su partida. En Madrid, tras catorce años con Gardel, Ricardo decidió dejar el grupo de guitarristas, al parecer disgustado con el protagonismo instrumental que pretendía Aguilar.

Permanecerá en Buenos Aires durante un año y medio. En ese plazo se presentó en Buenos Aires y Montevideo, realizó una extensa gira por las provincias argentinas, cantó por Radio Nacional, se sometió a una pequeña operación en sus cuerdas vocales y contrató a Domingo Riverol para reemplazar a Ricardo.

El 6 de septiembre de 1930 se produjo un golpe de estado cívico-militar en Argentina que derrocó al presidente democrático Hipólito Yrigoyen. Fue el primero de una serie interrupciones de la institucionalidad democrática que se extenderá hasta 1983. En esa ocasión Gardel asumió una posición de apoyo al golpe grabando el tango «¡Viva la patria!» de Aieta y García Jiménez, que lo enfrentó con los sectores yrigoyenistas de la Unión Cívica Radical, que al menos en un par de ocasiones boicotearon sus actuaciones.
Simultáneamente Gardel comienza a tener dificultades económicas y diferencias con Razzano, quien se desempeñaba como su representante, que le granjean enemistades en la barra de amigos que compartían y en el medio artístico y periodístico.

Finalmente, en 1930 Gardel iniciaría una nueva modalidad para difundir su canto, que redefinirá radicalmente su carrera y la masividad de su arte: el cine.

A fines de los años 20 la industria cinematográfica argentina mostraba una enorme vitalidad que la convertiría en una de las tres más importantes de América Latina, con México y Brasil durante el siglo.
Carlos Gardel, por su parte, ya había tenido una importante incursión cuando el cine era mudo, demostrativa de su sensibilidad para detectar los mecanismos modernos de construcción de la popularidad masiva, más allá incluso de las fronteras nacionales. Su amigo Enrique Cadícamo diría que:

En muchos aspectos Gardel se anticiparía en décadas a fenómenos culturales de masas en los que se unen la pasión, la identificación personal y la música, como la beatlemanía de los años 60, o fenómenos latinos equivalentes como Sandro, Soda Stereo y Luis Miguel, en los años 70, 80 y 90.
El crítico Claudio Iván Remeseira ha utilizado incluso la palabra «gardelmanía» para referirse a esta última etapa de la vida de Gardel.

En 1930 Gardel protagoniza quince cortometrajes musicales sonoros, cada uno sobre una canción, con dirección de Eduardo Morera y producción de Federico Valle, uno de los pioneros del cine latinoamericano. Valle había nacido en Italia en 1880, y luego de trabajar con los Hermanos Lumière y tomar clases con Georges Méliès, emigró a la Argentina en 1911 y desde entonces produjo decenas de obras cinematográficas de gran valor, incluyendo los primeros noticieros y los largometrajes animados de Quirino Cristiani, los primeros en la historia del cine mundial en su género.

De los quince cortos, cinco resultaron arruinados en el laboratorio, entre ellos uno titulado "Leguisamo solo" en el que aparecía el yóquey Irineo Leguisamo. En 1995 fue hallado otro de los cortos no lanzados, "El quinielero", de Luis Cluzeau Mortet y Roberto Aubriot Barboza.

Los diez cortos lanzados fueron: "El carretero", "Añoranzas", "Rosas de otoño", "Mano a mano", "Yira, yira", "Tengo miedo", "Padrino pelao", "Enfundá la mandolina", "Canchero" y "Viejo smoking".

El más elaborado de todos es "Viejo smoking", un tango con letra de Celedonio Flores y música de su guitarrista Guillermo Barbieri, en el que Gardel antes de cantar, protagoniza un sketch dramático con César Fiaschi e Inés Murray sobre el desempleo, la pobreza y el desalojo, en el contexto de la Gran Depresión. También se destacan "Yira, yira", "El carretero", "Mano a mano" y "Rosas de otoño" en los que Gardel sostiene diálogos muy significativos con sus autores, Enrique Santos Discépolo, el payador Arturo de Nava, Celedonio Flores y Francisco Canaro, respectivamente.

Los cortometrajes fueron filmados en Buenos Aires entre el 23 de octubre y el 3 de noviembre de 1930 y estrenados el 3 de mayo de 1931 en el cine Astral de la calle Corrientes. En algunos casos fueron presentados como «tangos teatralizados».

Se ha afirmado que los cortometrajes de Gardel fueron los primeros videoclips de la historia del cine y la primera producción de cine sonoro de Argentina y eventualmente América Latina.
La afirmación es parcialmente cierta. Los cortometrajes de Gardel constituyeron la primera producción de cine sonoro con banda de sonido incorporada en la película (sistema Movietone) realizada en América Latina, pero desde 1927 en el mundo ("El cantor de jazz") y 1929 en América Latina ("Mosaico criollo"), se habían realizado películas sonoras musicales, utilizando el sistema de discos sincronizados (sistema Vitaphone), y también con anterioridad se había utilizado el sistema Movietone (banda de sonido) para filmar clips musicales de Sofía Bozán con dirección de José Bohr, aunque realizados en Nueva York.
Más allá del debate sobre la prioridad cronológica, los diez cortometrajes de Gardel, dirigidos por Morera y producidos por Valle, constituyen un esfuerzo pionero tanto de la industria cinematográfica latinoamericana, como del videoclip musical.

En enero de 1931 Gardel emprendió una nueva gira por Francia, iniciada con dos meses de presentaciones exitosas en Niza, donde despide a su guitarrista Aguilar por un comentario homofóbico en su contra.
A fines de abril llegó a París con la firme determinación de filmar una película en los estudios que la empresa estadounidense Paramount tenía en la localidad de Joinville-le-Pont, a 40 kilómetros al sudoeste de la capital francesa, dedicada a producir películas para los mercados no estadounidenses. Pocos días después, el 1 de mayo, lograba su objetivo y firmaba un contrato que lo incluía en un largometraje musical protagonizado por las figuras de la compañía de revistas del Teatro Sarmiento de Buenos Aires, propiedad de Augusto Álvarez, encabezada por Manuel Romero y Luis Bayón Herrera. La película estuvo finalizada a fin de mes y se llamó "Las luces de Buenos Aires".

El director fue el chileno Adelqui Millar y los guionistas Manuel Romero y Luis Bayón Herrera. Los actores principales eran Gardel, en el papel protagónico del estanciero Anselmo Torres, y Sofía Bozán, su novia que está a punto de ser corrompida por un empresario de Buenos Aires al igual que su amiga interpretada por Gloria Guzmán y que termina siendo rescatada por los gauchos, para devolvérsela al estanciero (Gardel). El elenco se completaba con Vicente Padula, Pedro Quartucci y Carlos Baeza, entre otros.

La película incluye escenas de canto y baile (tango, malambo y otras danzas folklóricas). Para componer la música se contrató a Gerardo Matos Rodríguez, el autor de «La cumparsita» y para ejecutarla a Julio de Caro (violín), su hermano Francisco de Caro (piano) y Pedro Laurenz (bandoneón). Gardel canta dos canciones, un tango propio titulado «Tomo y obligo», con letra de Romero que canta en una cantina de La Boca en una famosa escena que generaba el delirio popular, y el vals «El rosal» de Matos Rodríguez y Romero, que es el tema romántico con el que cierra la película mientras Gardel besa a su novia (Bozán). Bozán también canta dos canciones, en tanto que Guzmán canta una.

"Las luces de Buenos Aires" fue estrenada en Buenos Aires el 23 de septiembre de 1931. Primero en los cines más importantes de Buenos Aires y luego en los cines de barrio y del resto del país, con enorme éxito.
Pero lo más importante fue la recepción de la película en los países de habla hispana que nunca habían podido ver a Gardel. En Guatemala se exhibió durante tres años, en Madrid todos los días durante tres meses, en Barcelona y Nueva York el público obligaba a los operadores a rebobinar la película una y otra vez para oír nuevamente «Tomo y obligo». En Ecuador el escritor Ricardo Descalzi recordaba aquel momento:

Gardel comenzaba a concretar la imagen de galán-cantor que había constituido la médula de su proyecto artístico desde un inicio. Su figura se había estilizado y continuaría estilizándose hasta pesar 76 kilos, luego de haber llegado a los 120 kilos.

En agosto de 1931 volvió a Buenos Aires donde permanecerá nueve semanas. Paradójicamente, al mismo tiempo que su popularidad en Argentina, Uruguay y todo el mundo hispanohablante comenzaba a alcanzar proporciones nunca antes vista, en el mundo artístico y los medios de comunicación de Buenos Aires crecía un sentimiento de rechazo a Gardel, por lo que se percibía como una pérdida de contacto con sus raíces «criollas». El 15 de septiembre de 1931, su amigo, el escritor Carlos de la Púa, publicó en el diario "Crítica", una dura carta abierta titulada «Che Carlitos, largá la canzoneta»:

Al volver a París Gardel encontró a la Paramount francesa en plena crisis, en el marco de la depresión mundial y de un clima político que se enrarecía, pocos meses antes de que Hitler tomara el poder en Alemania. Transcurrido el primer semestre de 1932 sin novedades y cuando Gardel ya había decidido volver a Buenos Aires, la empresa decidió realizar nuevas películas con el cantor argentino. Para ello designó al experimentado director francés Louis Gasnier, definió un guion adaptado de otro proveniente de Estados Unidos y fijó la fecha de filmación en septiembre de 1932 de una película que llevaría el título de "Espérame", con el subtítulo de "Andanzas de un criollo en España".

Es en ese momento que toma importancia la presencia de Alfredo Le Pera, con quien Gardel había empezado a congeniar en diciembre del año anterior. Le Pera asumió la carga de reescribir en un brevísimo tiempo un guion lleno de incongruencias culturales y geográficas, producto de los estereotipos estadounidenses sobre el mundo hispanoamericano y de luchar contra el director para aportar humanidad cotidiana a las escenas, rol que reiteraría en las películas siguientes, pero que nunca lo dejaría satisfecho.
Pero además el encuentro de Gardel y Le Pera, dará vida a gran parte de las canciones con las que quedará asociada la fama mundial del cantante.

El equipo musical organizado por Gardel estaba integrado por el brillante pianista Juan Cruz Mateo, con quien ya venía actuando y grabando discos, José Sentis (alias Teruel), uno de los argentinos que había instalado el tango en París, el compositor francés Marcel Lattès que sería asesinado por los nazis en Auschwitz, el director de orquesta cubano Don Aspiazú, el guitarrista Héctor Pettorossi quien lo acompañara años atrás en "Juan Moreira" y el compositor Mario Battistella, que se volvería un autor crucial para Gardel.

Pese a los esfuerzos de Le Pera, la película finalmente no pudo superar la endeblez del guion original, con actores mediocres que desmerecen el resultado final. Gardel interpreta a Carlos Acuña, un cantor enamorado de una joven (Goyita Herrero) que a su vez se ve extorsionada por un rico estanciero. Finalmente el estanciero es expuesto públicamente y el cantante se queda con la joven. Gardel canta cuatro canciones, entre ellos el tema principal de la película, la rumba «Por tus ojos negros», que compusieron Aspiazú, Le Pera y Carlos Lenzi, el autor de «A media luz». Los otros tres temas son «Estudiante», «Me da pena confesarlo» y «Criollita de mis ensueños» de Gardel, Le Pera y Battistella.

La Paramount tomó conciencia de que era necesario acompañar a Gardel con un elenco de mayor nivel artístico y que había que otorgarle más libertad a Le Pera como guionista. Sin embargo -como sucedería con todas las películas de Gardel para la Paramount-, las decisiones del director y de los encargados del montaje, limitarían los esfuerzos de Le Pera para construir films con hondura humana y restablecerían los estereotipos.
Nada de eso, de todos modos, impediría que las películas de Gardel alcanzaran una inserción profunda en el alma de los pueblos hispano-hablantes.

En cuanto terminó la filmación de "Espérame" la Paramount convocó a la famosa actriz argentino-española Imperio Argentina para encarar la siguiente película. En octubre de 1932 Gardel e Imperio Argentina realizaron un cortometraje picaresco, con algunos diálogos osados para la época, titulado "La casa es seria", dirigido por Jaquelux (Lucien Jaquelux).
Gardel canta en el corto dos canciones que compuso con Le Pera, el tango «Recuerdo malevo» y «Quiéreme». En 1940 cuando París fue ocupada, la cinta fue destruida por las tropas alemanas. Sobrevivieron sin embargo algunos discos Vitaphone que se habían grabado, registrando la totalidad de los diálogos y canciones del film.

Inmediatamente después comenzó la filmación de "Melodía de arrabal", otra vez con dirección de Gasnier y guion de Le Pera, que incluirá canciones fundamentales del cancionero de Gardel, como el tango «Melodía de arrabal» («Barrio plateado por la luna, rumores de milonga»), de Gardel, Le Pera y Battistella y «Silencio», de Gardel, Le Pera y Pettorossi. La película es un policial diseñado por Le Pera, en el que Gardel interpreta a un cantor de tangos (Ramírez) en una cantina de La Boca, que con otro nombre también es jugador profesional de cartas. Su novia es Imperio Argentina. En una pelea Ramírez mata a un matón y se deshace del cuerpo con un ingenioso ardid utilizando un fósforo. El comisario a cargo de la investigación descubre que Ramírez es el mismo que le había salvado la vida años atrás y en la última escena le devuelve el fósforo. Gardel canta también «Cuando tú no estás» y «Mañanita de sol», esta última a dúo con Imperio Argentina, la única mujer con la que cantó.

Gardel volvió a Buenos Aires el 30 de diciembre antes que las películas fueran estrenadas. El 5 de abril de 1933 se estrenó "Melodía de arrabal", el 19 de mayo "La casa es seria", y el 5 de octubre se estrenó "Espérame".
Como era esperable "Melodía de arrabal" tuvo mejor recepción que "Espérame", y a los tres meses ya había superado el éxito de taquilla que había alcanzado "Las luces de Buenos Aires".

En 1933 se terminó de romper su relación con Razzano por diferencias económicas, agravadas por el desorden en sus cuentas y las deudas. Designó entonces como representante a Armando Defino, uno de sus amigos provenientes de la barra del Café de los Angelitos, antes de ser famoso. Ese año concentró sus presentaciones en el interior de Argentina (Rosario, Santa Fe, Paraná, Arrecifes, San Pedro, Azul, Olavarría, Mendoza, San Juan, Córdoba, Villa María, entre otras ciudades), cantó por radio con una audiencia inaudita, participó en Buenos Aires de la revista "De Gabino a Gardel", y grabó varios discos difundidos bajo el título de "Gardel canta a Gardel", en los que, utilizando una novedosa tecnología, canta a dúo consigo mismo.

En septiembre conoció en la radio a Hugo Mariani, un uruguayo que hacía años que vivía en Nueva York, donde había creado y dirigía la Orquesta Sinfónica de la National Broadcasting Corporation (NBC), que tenía incluso un programa llamado "El tango romántico". Ambos simpatizaron inmediatamente y Mariani le propuso ir a Nueva York para cantar por la NBC. Pocos días después le llegaba el contrato.

En la noche del 7 de noviembre de 1933 Gardel partió hacia Europa en el barco Conte Biancamano, antes de ir a Estados Unidos. A la mañana Defino, su representante, le había pedido que redactara un testamento ológrafo, es decir escrito de su puño y letra. Ese fue el último día de Gardel en Buenos Aires.

El 7 de noviembre salió nuevamente de gira: fue la última vez que estuvo en Argentina. Primero fue a Barcelona y París, y luego viajó acompañado por el talentoso pianista Alberto Castellanos a los Estados Unidos, donde debutó en la radio de la NBC de Nueva York, el 30 de diciembre. En sus actuaciones radiales en Nueva York, Gardel prescindió de sus guitarristas, con excepción de la audición del 5 de mayo de 1934, en la que cantó desde Nueva York, siendo acompañado de las guitarras de Barbieri, Vivas y Riverol, que se encontraban en Buenos Aires, por medio de un enlace entre la NBC y LS5 Radio Rivadavia de Buenos Aires, inédito en la historia de la radiofonía.

En la NBC, Gardel cantó acompañado por la destacada orquesta de la radio neoyorquina, dirigida por Hugo Mariani, desempeñándose como arreglador el músico argentino Terig Tucci, radicado hacía años en Estados Unidos, que le aportó un nuevo sonido basado en armonías novedosas. Tucci y Castellanos congeniaron de inmediato y fueron quienes le sugirieron a Gardel un cambio mayor en su canto: que extendiera el registro de su voz hacia los tonos graves, para llegar a un barítono alto.
Es con esa voz que Gardel registrará sus últimas y más célebres canciones. Gardel pasó por un período de adaptación a la orquesta y las nuevas armonías de Tucci, pero cuando llegó el momento de formar el equipo de músicos que lo acompañaría en sus películas estadounidenses, lo llevó a Tucci como arreglador musical y director.

Las audiciones de Gardel tuvieron una excelente recepción en la importante comunidad latina de Nueva York, que en aquel entonces era de unas 500.000 personas, en una época en la que la población de origen latino en Estados Unidos era muy pequeña.

Gardel convocó a Le Pera a Nueva York para que actuara como su representante en las negociaciones con la Paramount, en un momento en la que Estados Unidos padecía la gran depresión de la década de 1930. El contrato se firmó el 20 de marzo de 1934, acordando crear una empresa productora subsidiaria del gigante del cine estadounidense con el nombre de Éxito Corporation, cuyo único accionista fue el cantante argentino.
Inicialmente se realizarían dos películas ese mismo año: "Cuesta abajo" y "El tango en Broadway".

Cuesta abajo debió filmarse en dos semanas, con guion escrito por Le Pera, a partir de su propia vivencia autobiográfica. Gardel y Le Pera tenían en claro que no iban a repetir la imposición europea de que los personajes debían vestir como gauchos. El director fue una vez más el francés Louis Gasnier, impuesto por la Paramount. Encontrar actores que hablaran español fue uno de los grandes problemas de producción. Para los papeles principales contrataron a Mona Maris, una argentina que vivió desde muy niña en Europa, Vicente Padula, Manuel Peluffo y Anita del Campillo. Para los papeles secundarios Gardel convenció para que actuaran en su película a los diplomáticos de Argentina, Chile, Colombia, Venezuela y Perú.

El argumento trata de un cantante de tango (Gardel como Carlos Acosta), que deja a su novia (Anita del Campillo), al enamorarse de una prostituta (Mona Maris). En el momento culminante de la película Gardel se enfrenta a duelo con el "cafisho" (Manuel Peluffo) e intenta matarla a ella, en una célebre escena en la que canta "Cuesta abajo" ("si arrastré por este mundo, la vergüenza de haber sido y el dolor de ya no ser..."), de Gardel y Le Pera.

En las canciones principales de la película ("Cuesta abajo", "Mi Buenos Aires querido", "Amores de estudiante" y "Criollita decí que sí"), Gardel está acompañado por un notable quinteto dirigido por Alberto Castellanos en el piano, junto a Remo Bolognini y Hugo Mariani, como primer y segundo violín, Washington Castro en violonchelo y Humberto Di Tata en contrabajo.

Gardel, Le Pera y Castellanos no quedaron del todo satisfechos con la película, sobre todo porque en el proceso de edición, Gasnier y los técnicos de la Paramount quitaron muchas de las escenas más divertidas y chispeantes. Pese a ello la película tuvo un éxito apoteósico, tanto en Estados Unidos como en América Latina. En Nueva York miles de personas desbordaron el cine, ocupando las calles, al punto de que la empresa exhibidora colocó parlantes en la calle para que el público que no pudo entrar a la sala, pudiera oír las canciones.

Paradójicamente, solo en los medios periodísticos de Buenos Aires se elevaron críticas a la película, especialmente en la clase alta. Mientras que el público desbordó los cines y exigía que se repitieran las canciones, los diarios tradicionales "La Nación" y "La Prensa", cuestionaron la película por la mala imagen que daba de la Argentina. También el letrista Homero Manzi, cuestionaría duramente la película, en un artículo publicado en la revista "Antena", cuestionándola por carecer de "valor nacionalista".

El tango en Broadway fue filmada entre fines de junio y la tercera semana de julio de 1934 y el director volvió a ser Louis Gasnier. Para esta ocasión Gardel y Le Pera buscaron hacer una comedia de enredos que cambiara el tono de las películas anteriores y que a su vez reflejara la situación de los artistas latinos en Estados Unidos.

Nuevamente tuvieron problemas para conseguir actores y actrices que hablaran español. Los papeles principales fueron interpretados por el español Jaime Devesa (el tío), un hallazgo, nuevamente el argentino Vicente Padula, la guatemalteca Blanca Visher (Laurita) y la mexicana Trini Ramos (Celia). Gardel hace de Carlos Bazán, un representante de artistas latinos.

El argumento trata de un grupo de artistas latinos en Nueva York reunidos alrededor de Gardel, cuando llega el tío, frente a quien intenta aparentar que es un hombre de negocios. Laurita entonces se hace pasar por la novia de Carlos, y su novia, Celia, se hace pasar por su secretaria, generándose sucesivos enredos. Carlos se da cuenta que en realidad ama a Laurita en una de las escenas culminantes de la película, cuando canta el tango "Soledad" ("En la doliente sombra de mi cuarto al esperar, sus pasos que quizás no volverán...").

Las canciones que interpreta Gardel en la película son "Soledad", el foxtrot "Rubias de New York", "Golondrinas" y "Caminito soleado". En las tres primeras fue acompañado por la orquesta de Terig Tucci y en la última por el piano de Castellano con las guitarras de Cáceres, Ayala y Cornejo.

Una vez más, Gardel y Le Pera no quedaron plenamente satisfechos con la película y tomaron la decisión de prescindir de Gasnier en las siguientes. Ello no obstó a que la película volviese a tener un enorme éxito, consolidando la "gardelmanía" que se estaba gestando en la comunidad latina estadounidense y en los países hispanoamericanos.

Luego de ir a Francia por poco tiempo, a fines de 1934 volvió Nueva York, actuando en la NBC y filmando el musical Cazadores de estrellas (su título original es "The Big Broadcast of 1936"), un catálogo de las estrellas musicales de la Paramount, entre las que se encontraban Bing Crosby, Richard Tauber, La Orquesta de Ray Noble con Glenn Miller en el trombón, Los Niños Cantores de Viena, entre otras grandes figuras. En este film Gardel trabajó junto a Celia Villa, hija del famoso revolucionario mexicano Pancho Villa a quien Gardel admiraba.
Cantó dos canciones suyas con Le Pera: un tema campero "Apure delantero buey" y "Amargura" en una versión bilingüe español-inglés con el título de "Cheating muchachita". La película se estrenó poco después de la muerte de Gardel y por esa razón la Paramount decidió sacar la parte del cantor argentino. Las secciones cortadas en las que aparece el "Rey del Tango" son muy difíciles de hallar, aunque se sabe que alguna copia de ellas se encuentran en poder de coleccionistas privados.

Entusiasmada con el éxito de las películas de Gardel, la Paramount decidió filmar dos películas más en 1935, que serían sus últimas películas. Gardel y Le Pera ya habían decidido que su etapa de trabajo con Gasnier estaba agotada y eligieron a John Reinhardt, un joven director de origen austríaco, que había dirigido varias películas con actores latinos y que se mostraba mucho más receptivo a las sugerencias de Gardel y Le Pera.
Dos características centrales resaltan en estas últimas dos películas: la primera es la decisión de registrar el canto de Gardel en vivo, eliminando el doblaje tradicional en posproducción; la segunda es la decisión de dirigir el tono de las películas hacia el público de los países habla española, alejándose tanto del tono porteñista, como de los estereotipos europeo-norteamericanos.

El día que me quieras se filmó en enero de 1935, con Reinhardt como director y Le Pera como libretista, ante el fracaso de los libretos que la Paramount encargó a autores argentinos e hispanoamericanos, buscando mejorar el nivel.

También mejoró la calidad de los actores seleccionados. En los papeles principales que acompañan a Gardel (Julio Argüelles) figuran la actriz española Rosita Moreno (que interpreta a Margarita y su hija Marga), Tito Lusiardo (Rocamora), Fernando Adelantado (Carlos Argüelles) y Mario Peluffo (Saturnino). También actúa en una breve escena, por pedido de Gardel, el niño Ástor Piazzolla.

En el libreto, Gardel es hijo de un multimillonario rechazado por su padre por dedicarse a cantar y haber formado pareja con una artista (Rosita Moreno como Margarita), a quien le declara su amor con la canción "El día que me quieras". Reducidos a la pobreza, Margarita cae enferma gravemente y Gardel se ve forzado a robarle a su padre para sobrevivir. Pese a ello Margarita muere en una escena histórica en la que Gardel canta "Sus ojos se cerraron", que por el grado de emotividad que alcanzó su interpretación, dejó al estudio en silencio durante varios minutos antes de estallar en aplausos. Gardel queda entonces solo al cuidado de su hija, Marga. El relato se reinicia años después, cuando Gardel y su hija se han convertido en artistas exitosos. Repitiendo la historia de su madre, Marga se enamora de un joven argentino, cuyo millonario padre que se opone a la relación ("yo la veo vulgar y demasiado libre"). Todos coinciden en el viaje de vuelta a Buenos Aires donde, en otra escena famosa, apoyado en la baranda del barco, Gardel canta el tango "Volver" ("Volver con la frente marchita, las nieves del tiempo platearon mi sien"). Finalmente, Gardel revela que es el heredero de la empresa en la que trabaja, lo que lleva al padre del joven a cambiar cínicamente de parecer y autorizar el casamiento. En la última escena Gardel, abrazado a su hija y su futuro yerno, de noche y mirando al mar, canta la segunda parte de "El día que me quieras".

Le Pera nuevamente se quejó de los cortes de posproducción, pero la película claramente había ganado en calidad frente a los anteriores. La película fue estrenada pocos días después de la muerte de Gardel. En una carta escrita a su representante Defino cuatro días antes de morir, Gardel le dice:

Tango Bar, la última película de Gardel, se filmó en febrero de 1935. Rainhardt volvió a ser el director y Le Pera, el libretista. La producción continuó mejorando el nivel de actuación incorporando al excelente actor argentino Enrique de Rosas, quien se sumó a Rosita Moreno, Tito Luisardo, Fernando Adelantado y Manuel Peluffo. El argumento es un policial romántico, que gira alrededor de un apostador a las carreras de caballos (Gardel) que pone un tango bar en Barcelona y una ladrona de joyas (Rosita Moreno), que resulta chantajeada. Entre canciones la dupla Gardel-Le Pera compone para la película los éxitos de "Por una cabeza" y "Arrabal amargo".

Terminada la filmación y en medio del éxito con que era reconocido su arte y su ángel, Gardel comenzó a preparar una gira por varios países latinoamericanos.

Las películas estadounidenses de Gardel terminaron por consolidar un fenómeno de idolatría popular en el público de habla hispana, completamente inusual para la época.

La gardelmanía produjo también el extraño encuentro entre Gardel y Ástor Piazzola, los dos máximos referentes de la historia del tango, cuando este último tenía apenas doce años. El padre de Piazzolla era un inmigrante argentino en Estados Unidos, que trabajaba de peluquero en Manhattan. Cuando se enteró que Gardel se había instalado en Nueva York, Piazzolla padre talló una figura especialmente para Gardel y lo envió a su hijo a que se la entregara. La picardía del niño, que trataba a Gardel de "Charlie" y sabía tocar el bandoneón, generó la simpatía inmediata de Gardel, y se estableció entre los dos una inusual amistad, en la que Ástor obró muchas veces como traductor. Como resultado de la misma Gardel invitó al niño Piazzolla a aparecer como "canillita" en "El día que me quieras" y luego fue más allá invitándolo a formar parte de la comitiva que lo acompañaría en su gira latinoamericana, pero su padre pensó que era todavía muy joven para ello. Como si se tratara de un guion de película, esa negativa del padre hizo que Ástor no estuviera en el accidente aéreo y décadas después se transformara en el gran renovador del tango argentino.

En 1978 Ástor Piazzolla le escribió a Gardel una carta imaginaria:

A medianoche del 28 de marzo de 1935 Gardel salió de Nueva York en el yate "Coamo" para iniciar su gira latinoamericana por Puerto Rico, Venezuela, Aruba, Curazao, Colombia, Panamá, Cuba y México. Lo acompañaban Le Pera, sus guitarristas Barbieri, Aguilar y Riverol, el boxeador argentino José Corpas Moreno como su secretario y el español José Plaja, su profesor de inglés. En Puerto Rico se sumaría al grupo el puertorriqueño Alfonso Azzaf, como masajista y encargado de la iluminación.

Gardel llegó a Puerto Rico el 1 de abril a las 5 de la mañana. Más de cuarenta mil personas lo estaban esperaban en el puerto, sorprendiendo a una comitiva que recién comenzaba a tomar dimensión de la idoloatría popular que había desencadenado el cantante argentino en el público latino. Había sido contratado por una semana, pero la demanda popular fue de tal magnitud que postergó su llegada a Venezuela para actuar durante dos semanas más. Cantó en los teatros Paramount de la capital, Yaguez de Mayagüez, Broadway de Ponce, así como en las ciudades de Yauco, Manatí, Río Piedras, Cayey, Guayama, Cataño y Arecibo.

El 25 de abril llegó a Venezuela, en la motonave "Lara". Otra multitud los esperaba en los muelles de La Guaira y de allí en tren hasta la estación de Caño Amarillo en Caracas. La presión popular sobre el ídolo fue de tal magnitud que demoró enormemente su llegada. Miles de mujeres, especialmente las adolescentes, intentaban abrazarlo y pellizcarlo e incluso la capota del automóvil en el que iba fue destrozada por la gente para poder verlo, desencadenando una represión policial en la que Le Pera recibió un sablazo del la cara. Actualmente en ese lugar, una estatua de Gardel y dos guitarristas, de la artista Marisol Escobar, conmemora la recepción del pueblo venezolano al cantor argentino.
Permaneció en Venezuela doce días, actuando en los teatros Principal y el Rialto, así como en el Hotel Majestic y en la Radio de Caracas. También cantó en Valencia, en la población petrolera de Cabimas, donde el público destrozó el circo en el que actuó exigiendo que cantara más canciones, ante el presidente Juan Vicente Gómez en su residencia de Maracay y finalmente en Maracaibo.

El 23 de mayo Gardel llega a Curazao, donde actúo cinco noches. Allí dona al grupo de exiliados venezolanos la suma de diez mil bolívares que le había regalado el presidente Gómez.

El 28 de mayo arribó por barco a Aruba.
En Aruba, el público lo sacó del palco y lo llevó en andas por toda la ciudad. En esa situación Gardel logró convencer a la gente para que lo llevaran hasta el espigón del puerto donde abordó el avión que lo llevaría de nuevo a Curazao.

El 2 de junio Gardel llegó a Colombia, desembarcando en Puerto Colombia, que por entonces era la terminal marítima de Barranquilla. El diario "El Tiempo" de Bogotá, al anunciar el arribo del "Jilguero de las Pampas" decía que "la llegada del cantante argentino saturó a Barranquilla, que está viviendo a ritmo de tango".
Nuevamente el afecto popular se expresaba en multitudes que lo seguían a todos lados, para abrazarlo y besarlo, con escenas de delirio colectivo que obligó una vez más a que intervinieran las fuerzas policiales. En Bogotá más de diez personas invadieron la pista en el momento del aterrizaje.

Desde Bogotá, Barbieri le escribió a su esposa contándole lo que estaba pasando:

En Medellín, uno de los empresarios había intentado disculparse por las molestias de la efusividad popular:

Actuó en las ciudades colombianas de Barranquilla, Cartagena, Medellín y Bogotá. El domingo 23 de junio cantó por la radio "La voz de la Victor", ante un inmenso público que colmó los estudios y la plaza Bolívar, donde la emisora colocó altoparlantes. Entre otros temas cantó los tangos "Cuesta Abajo", "Insomnio", "El Carretero", "No te engañes corazón" para cerrar con "Tomo y obligo". Fue su última actuación.
Antes de cerrar se había despedido con estas palabras:

Al día siguiente, 24 de junio, Gardel y sus acompañantes debían continuar la gira en Cali. Para ello tomaron un avión piloteado por Stanley Harvey, que se dirigió primero a Medellín, para que asumiera la conducción del vuelo el célebre aviador Ernesto Samper Mendoza, propietario de la empresa Saco. Al momento de despegar del aeropuerto de Medellín, el avión sufrió el accidente que le costó la vida a Gardel y a sus acompañantes con excepción de Aguilar y Plaja.

El 24 de junio de 1935 Carlos Gardel, junto con Alfredo Le Pera, su guitarrista Guillermo Barbieri y su secretario Corpas Moreno, falleció en el choque de dos aviones en el momento de despegar, sobre la pista del aeropuerto Olaya Herrera que se conocía entonces como Aeródromo "Las Playas" de la ciudad de Medellín (Colombia). Días después también morirían Alfonso Azzaf y el guitarrista Ángel Domingo Riverol. En el accidente murieron también el as de la aviación colombiana y dueño de la SACO, Ernesto Samper Mendoza, el radiooperador Willis Foster, el empresario chileno Celedonio Palacios, el promotor de espectáculos Henry Swartz, así como los siete ocupantes del otro avión. En total 17 muertos. Solo hubo tres supervivientes: el guitarrista José María Aguilar, José Plaja y Grant Flynt, funcionario de SACO.

El accidente se produjo cuando el avión en que viajaba Gardel, un trimotor Ford de la empresa SACO, se desvió en pleno carreteo de despegue y embistió a otro avión similar de la empresa de origen alemán SCADTA, que esperaba su turno para despegar, incendiándose ambos.

Las causas del accidente nunca fueron establecidas con claridad. Ambas empresas aeronáuticas mantenían una dura competencia, detrás de la cual se encontraban los intereses estratégico-militares de los Estados Unidos y Alemania. Ni bien sucedió el accidente, cada una de las empresas se apresuró a atribuirle a la otra la responsabilidad. El propio presidente de Colombia culpó con dureza a la empresa alemana. La justicia por su parte decidió que las causas del accidente se debieron a las características de la pista y a un fuerte viento proveniente del sudeste.

Gardel fue enterrado primero en Medellín, pero luego Armando Defino ―su albacea― logró la repatriación del cuerpo. Para dicho fin, el féretro que contenía los restos mortales de Carlos Gardel debió realizar un largo recorrido que incluyó viajes en lomo de burro, carreta, tren y barco. El cuerpo del malogrado cantor pasó por las poblaciones interiores de Colombia, luego fue a Panamá, se lo veló en Estados Unidos, y llegó finalmente a la Argentina en barco hacia 1936.
Actualmente sus restos se hallan enterrados en el Cementerio de la Chacarita de Buenos Aires.

Gardel y Razzano primero y luego Gardel como solista, se caracterizaron por el acompañamiento exclusivo de guitarras.
El acompañamiento con guitarras fue inusual en el tango, ya que si bien la guitarra nunca estuvo del todo excluida en la orquestación tanguera, el peso de la misma cayó sobre el bandoneón centralmente, y secundariamente en el piano y el violín, instrumentos que formaron la llamada «orquesta típica de tango». Las guitarras de Gardel no vienen del mundo tanguero, sino del mundo de la música campera y la payada, del que provenía el dúo.
La utilización del acompañamiento de guitarras y la calidad de los guitarristas elegidos, ha dado lugar a frecuentes debates estéticos.

Inicialmente Gardel y Razzano se acompañaban con guitarras prestadas, pero a medida que se fueron consolidando profesionalmente, recurrieron a la contratación de guitarristas expertos. El primero fue José Ricardo, "El Negro José", un músico afroargentino nacido en el barrio de Balvanera de Buenos Aires, que fue contratado en 1916 y permaneció hasta mayo de 1929. En 1921 el dúo contrató como guitarrista al argentino Guillermo Barbieri, que asumió el rol de segunda guitarra hasta el retiro de Ricardo. En 1928, Gardel contrató al uruguayo José María Aguilar, "El Indio", que se desempeñó hasta diciembre de 1930, cuando fue despedido por Gardel por un comentario homofóbico en su contra, volviéndose a integrar en 1935. En marzo de 1930 Gardel contrató a Ángel Domingo Riverol, quien lo acompañaría desde entonces. Entre septiembre de 1931 y noviembre de 1933 Julio Vivas integró el grupo de guitarristas y durante este último año se sumó también Horacio Pettorossi, formando un brillante cuarteto con Barbieri, Riverol y Vivas.

Los guitarristas de Gardel eran músicos consumados y Gardel grabó muchas canciones compuestas por ellos, algunas convertidas en clásicos, además de introducir solos de guitarra para su lucimiento, gestos que fueron muy valorados por los propios músicos y los críticos, por el significado artístico y económico que tuvo esa conducta.

Ricardo compuso 11 canciones grabadas por Gardel, entre ellas «Margot» (música junto a Gardel), «Pobre gallo bataraz» y «Resignate hermano» (con Barbieri).

Barbieri compuso 32 tangos grabados por Gardel, entre ellos: "Anclao en París", «Viejo smocking», «Incurable», «Mar bravío», «Quién tuviera 18 años», «El que atrasó el reloj», «Pordioseros», «Idilio campero», «Cruz de palo», «Pobre amigo», «La novia ausente», «Preparate p’al domingo», «Resignate hermano» (con Ricardo), «Besos que matan», «Barrio viejo», «Cariñito», «Viejo curda» y «Olvidao».

Aguilar compuso 11 tangos grabados por Gardel, entre los que se destacan «Al mundo le falta un tornillo» (con letra de Cadícamo), «Tengo miedo», «Lloró como una mujer» y «Milonguera».

Entre las canciones propias o en coautoría de Vivas grabadas por Gardel se destacan «El Olivo», «Salto Mortal», «Quejas del Alma» y «Amante, Corazón».

Pettorossi fue compositor de tangos célebres de Gardel, como «Silencio» (en coautoría con Gardel y Le Pera), «Angustia», «Esclavas blancas» y «Lo han visto con otra».

Riverol compuso 3 tangos grabados por Gardel, entre ellos «Falsas promesas» y «Trovas».

Barbieri, Riverol y Aguilar acompañaban a Gardel en el vuelo que le causó la muerte. Barbieri murió en el acto, Riverol murió dos días después y Aguilar fue el único sobreviviente del accidente, sufriendo gravísimas heridas.

La principal relación personal de la vida de Gardel fue con su madre, la inmigrante francesa Marie Berthe Gardes o Berta Gardés, según la versión castellanizada, que para la hipótesis francesista fue su madre biológica y para la hipótesis uruguayista, obró como su madre adoptiva. Gardel vivió toda su vida con su madre, aunque durante algún tiempo cuando era adolescente parece ser que huyó de su hogar. Por otra parte Gardel siempre expresó devoción por su madre, aunque algunos aspectos ambivalentes de la relación señalan aristas complejas no del todo reveladas.
Cuando Gardel se volvió un artista bien remunerado, proveyó a Berta del dinero necesario para visitar todos los años a su madre, hermano y demás familiares franceses de Toulouse, a quien él también visitaba, aunque notablemente nunca viajaron juntos.
Berta se hallaba justamente en Toulouse al momento de la muerte de su hijo.
Al morir Carlos, fue Berta la que heredó todos los bienes de su hijo, incluyendo la casa que éste compró para ambos en el barrio del Abasto, en la calle Jean Jaurés 735.

Gardel era una persona extrovertida y simpática, que tendía a establecer fuertes relaciones de amistad, aunque como suele suceder con las personas de fama y fortuna, no siempre eran realmente correspondidas. Entre sus amigos más importantes se destaca la relación con José Razzano mantenida según éste, desde 1911 hasta su muerte, aunque en los últimos años se debilitó por razones económicas.
Otros buenos amigos fueron Edmundo Guibourg, con quien se conocían de chicos, pero comenzaron a ser amigos en 1915; el jockey Irineo Leguizamo, a quien Gardel le dedicaría el tango «Leguisamo solo», compuesto por Modesto Papavero;
Francisco Maschio, cuidador de caballos de carrera con el que Gardel compartió su pasión por los «burros», como decía en lunfardo; y los actores Elías Alippi y César Ratti.

Su representante hasta 1932 fue su amigo y compañero José Razzano. En este último año se distanciaron y Gardel designó a Armando Defino. Al morir Gardel, Defino y su esposa Adela Blasco constituyeron el soporte espiritual de Berta, incluso viviendo juntos en la casa del Abasto. Berta, que murió en 1943, legó todos sus bienes a Defino, quien a su vez hizo lo mismo con su esposa al morir en 1958. Adela vivió hasta 1984 y falleció sin herederos forzosos, legando todos sus bienes a Nuria de Fortuny.

Con respecto a sus relaciones de pareja, Gardel fue extremadamente reservado con las mismas, no dando a conocer públicamente ninguna relación.
La reserva de Gardel sobre su vida íntima ha dado lugar a diversos y contradictorios rumores y estudios sobre la naturaleza de sus relaciones afectivas y sexuales.
En su correspondencia privada existen amplias constancias sobre Isabel del Valle, una niña de 13 años con la que Gardel se relacionó en 1920 y con la que mantuvo un vínculo ambiguo hasta 1933.
Por otra parte existe unanimidad en el hecho de que Gardel no tuvo hijos.

Apostar en las carreras de caballos fue la gran pasión de Gardel y quedó reflejada contundentemente en su cancionero en lo que se ha dado en llamar «tangos burreros», tomando la expresión lunfarda de «burros» para referirse al "turf".

Muchos de sus amigos pertenecían al mundo de las carreras de caballos, como el célebre yóquey Irineo Leguisamo, los hermanos Tortercio, el cuidador Francisco Maschio y el yóquey Alfredo Peluffo.
Gardel fue propietario de ocho caballos de carrera: Lunático (su preferido, montado por Leguisamo y cuidado por Maschio), La Pastora, Cancionero, Amargura, Theresa, Guitarrista, Explotó y Mocoroa, estos dos últimos compartidos en propiedad con Leguisamo y Mascchio.

Entre los «tangos burreros» del repertorio gardeliano se destacan «Por una cabeza», de su autoría con letra de Alfredo Le Pera en 1935, el único compuesto por él en esta serie temática y «Leguisamo solo» de Modesto Papavero, en homenaje a su amigo y en el que Gardel al interpretarlo menciona a sus amigos Francisco Maschio y "El Pulpo" Leguisamo, y a su caballo Lunático:

Otros tangos «burreros» del cancionero de Gardel son «Palermo» de Enrique Pedro Delfino y Juan Villalba y Hermido Braga; «La catedrática» (Soy una fiera), de su excompañero Francisco Martino; «Uno y uno», de Traverso y Pollero; «Paquetín, paquetón» de Carlos Dedico, Germán Ziclis y Salvador Merico; «Bajo Belgrano» de Francisco García Jiménez y Anselmo Aieta; «Preparate pa´l domingo», de su guitarrista Guillermo Barbieri y José Rial (h).
Guillermo Barbieri y Eugenio Cárdenas compusieron el tango «Lunático», que llegó a ser grabado por Gardel para el sello Records, y en 1935 se estrenó la película del mismo nombre.

Gardel era también aficionado a otros deportes, como el fútbol -fue socio de Racing Club . En la ciudad de Rosario, supo visitar el estadio del Club Atlético Newell's Old Boys. Uno de sus tangos "futboleros" es "Patadura". También disfrutaba del boxeo. Además de su afición por estos deportes, jugaba habitualmente a la pelota vasca y a las bochas, salía a trotar y asistía a clases de gimnasia.

En 1915, el tenor italiano Enrico Caruso vino a la Argentina a cantar al Teatro Colón y al volverse en barco al Brasil se dio la coincidencia de que en él se encontrase Carlos Gardel, que era amigo de muchos de los profesores de la Orquesta Estable. Algunos de ellos lo convencieron para que se encontrara con el famoso italiano. Así lo hizo y una vez que Caruso lo escuchó cantar un tango, una zamba y una cueca, el italiano, le comentó: “"Si usted hubiera estudiado seriamente, sería el mejor barítono del mundo"”. Con el tiempo, efectivamente, Carlos Gardel eligió como maestro al prestigioso profesor Alberto Castellanos, quien le cambió el registro de tenor a barítono. Por eso, en los primeros discos de Gardel, se percibe su canto en un tono más agudo; mientras que en los últimos se lo escucha más cómodo en el registro apropiado.

Su voz fue evolucionando, ajustando su dicción a los cambios de los sistemas de grabaciones acústicas. El maestro Eduardo Bonessi, quien fue profesor de canto de Gardel dijo hacia 1963:

En su libro "Carlos Gardel: a la luz de la Historia", de la Fundación BankBoston, Montevideo, 2000,
el arquitecto Nelson Bayardo, que durante más de treinta años investigó la vida y los orígenes de Carlos Gardel, describe la voz de del cantante resaltando cinco aspectos:


Con respecto a la «N» que Gardel pronunciaba como una «R», el cantante argentino Edmundo Rivero, en un libro dedicado exclusivamente al análisis técnico de su canto, dio la siguiente explicación:

En 1985 la Fundación Konex lo homenajeó con el Premio Konex de Honor por su incalculable aporte a la historia de la música popular argentina.

El 24 de junio de 2005, por decisión conjunta de las autoridades municipales de las ciudades de Buenos Aires, Montevideo, Tacuarembó y Medellín (donde falleció), se recordaron los 70 años de la muerte de Carlos Gardel. Por primera vez, se obvió la conmemoración del llamado Día de Carlos Gardel en la ciudad francesa de Toulouse.

En Argentina se celebra cada 11 de diciembre el Día del Tango, debido a que ese día nacieron Julio de Caro y Carlos Gardel.

Existen dos versiones sobre el nacimiento de Carlos Gardel: una sostiene que nació en Francia y la otra, que nació en Uruguay. La primera es conocida como la «hipótesis francesista» y la segunda como la «hipótesis uruguayista». Ambas difieren también en el año de nacimiento y en gran cantidad de hechos de su vida personal, relacionados con su identidad, principalmente durante su infancia y adolescencia. Pero ambas versiones coinciden en el hecho de que el cantor se nacionalizó argentino en 1923.

Gardel por su parte, en sus declaraciones públicas, fue en general reticente a contestar cuál era su nacionalidad y cuando lo hacía solía expresarse de manera ambigua y sin proporcionar detalles.

La «hipótesis francesista» sostiene que Carlos Gardel nació en Toulouse, Francia, el 11 de diciembre de 1890, bajo el nombre de Charles Romuald Gardes, siendo su madre biológica Marie Berthe Gardes y su padre Paul Jean Lasserre, quien no lo reconoció. En 1893 Berthe emigró a la Argentina con su hijo, radicándose en Buenos Aires. Sostienen también que su nombre fue castellanizado en Argentina como Carlos Romualdo Gardés y que adoptó como nombre artístico, el de Carlos Gardel, correspondiendo por lo tanto los tres nombres a una misma persona.

Las pruebas documentales principales de la «hipótesis francesista» es la partida de nacimiento de Charles Romuald Gardes en Toulouse, cuya autenticidad no está discutida, y el testamento ológrafo de Carlos Gardel, donde este declara ser Charles Romuald Gardes, hijo de Berthe Gardes, nacido en Toulouse.

La «hipótesis francesista» sostiene que los documentos de Gardel en los cuales figura que nació en Tacuarembó, Uruguay, como el registro de nacionalidad gestionado en 1920, su cédula y sus pasaportes, contienen datos falsos aportados por el propio Gardel por no haberse enlistado en las fuerzas francesas para hacer el servicio militar, ni tampoco para luchar por Francia durante la Primera Guerra Mundial. Si Gardel hubiese sido identificado como un ciudadano francés por nacimiento, habría corrido el riesgo de ser llevado a la cárcel por desertor en caso de viajar a Francia o a cualquier país que tuviese un tratado de extradición con Francia.

Esta corriente constituye la posición biográfica tradicional, presentada en la primera biografía de Gardel, escrita en 1946 por su amigo Francisco García Jiménez, sobre las memorias de José Razzano.
Luego de la presentación de la «hipótesis uruguayista» en 1967, surgieron autores dedicados a confirmar la «hipótesis francesista» como el argentino Augusto Fernández, el argentino Carlos Esteban y los franceses Monique Ruffié y Georges Galopa, la francesa Christiane Bricheteau, Raúl Torre y Juan Fenoglio, Enrique Espina Rawson, y Norberto Regueira.
Entre los biógrafos de Gardel que aceptan la hipótesis del nacimiento en Toulouse se encuentran el británico Simon Collier, y los argentinos Julián y Osvaldo Barsky.

La «hipótesis uruguayista» sostiene que Carlos Gardel nació en Tacuarembó, Uruguay, probablemente un 11 de diciembre, siendo su madre María Lelia Oliva, embarazada por el esposo de su hermana Blanca, Carlos Félix Escayola Medina, jefe militar y político de Tacuarembó. El año de nacimiento varía, según los autores, entre 1883, cuando María Lelia tenía 13 años y su hermana Blanca estaba viva, y 1887, cuando María Lelia tenía 17 años y su hermana Blanca ya había muerto.

La «hipótesis uruguayista» sostiene que al nacer el niño, no fue reconocido por ninguno de sus padres y quedó sin inscripción. Berthe Gardes habría estado en ese entonces en Tacuarembó, haciéndose cargo inicialmente del niño, pero luego viajó nuevamente a Toulouse donde en 1890 tuvo un hijo no reconocido por el padre, al que llamó Charles Romuald Gardes, con quien emigró a la Argentina, donde volvió a hacerse cargo de Carlos, el niño uruguayo.

Pocos años después, los padres biológicos de Gardel según la versión uruguayista, Carlos Escayola y María Lelia Oliva, formalizarían su relación, casándose y teniendo seis hijos, hermanos de Gardel.
Gardel, por su parte, siempre habría sabido su verdadera filiación e incluso se habría encontrado algunas veces con sus hermanos.

La base de la «hipótesis uruguayista» es que Charles Romuald Gardes, el hijo de Berthe nacido en 1890 en Toulouse, y Carlos Gardel, criado parcialmente por Berthe y nacido varios años antes en Tacuarembó, fueron personas distintas y que finalmente Gardel terminó tomando la identidad de Charles, el hijo biológico de Berthe.

Las pruebas documentales principales de la «hipótesis uruguayista» son los documentos uruguayos y argentinos, tramitados por Gardel en 1920 y 1923, en los que el propio Carlos Gardel declara haber nacido en Tacuarembó el 11 de diciembre de 1887, identificando a sus padres como Carlos Gardel y María Gardel.

La «hipótesis uruguayista» sostiene que el contenido del testamento de Gardel es falso y que formó parte de una maniobra legal para que Berthe Gardes pudiese heredarlo de acuerdo con las leyes argentinas de la época. También han peticionado judicialmente con resultado negativo, la exhumación de los restos de Gardel y su madre, a fin de realizar estudios que establezcan su identidad genética.

Esta corriente fue iniciada por el periodista uruguayo Erasmo Silva Cabrera, alias Avlis, el primero en sostener la hipótesis a partir de 1967.
Otros estudiosos pertenecientes a la corriente uruguayista son el argentino Blas Matamoro, el uruguayo Nelson Bayardo, el uruguayo Eduardo Payssé González, la argentina Martina Iñíguez, el argentino Ricardo Ostuni, el uruguayo Nelson Sica dell’Isola, y el uruguayo Gonzalo Vázquez Gabor.

En 1997 Susana Cabrera publicó el libro "Los secretos del Coronel", que narra y documenta esta hipótesis, sobre el que se realizó el documental "El padre de Gardel" (Ricardo Antonio Casas, 2013). Allí se trata el supuesto del incesto y el ocultamiento de la verdadera paternidad de Gardel.

Gran parte de la celebridad y la pasión despertadas por Gardel en vida y luego de muerto se debe a su preocupación por cuidar y difundir su imagen. El poeta Celedonio Flores escribe en el famoso tango "Corrientes y Esmeralda", compuesto en 1933, cuando Gardel todavía vivía, que "cualquier cacatúa sueña con la pinta de Carlos Gardel".
En esa imagen juegan un papel de gran importancia las fotografías que le tomara el fotógrafo hispano-uruguayo José María Silva, en especial los famosos retratos de 1933.

El músico de rock argentino Luis Alberto Spinetta refleja la idolatría popular por Gardel, en una de sus más conocidas canciones, "El anillo del Capitán Beto", en la que describe la cabina de un colectivero, donde conviven la famosa foto de Gardel, con la pasión "futbolera" y las creencias religiosas.

Silva conoció a Gardel casi por casualidad, cuando en 1917, estando el dúo Gardel-Razzano en Montevideo, deciden sacarse fotos para difundir su imagen. De ese modo, caminando por la Avenida 18 de Julio, la principal de la ciudad, ingresan a un negocio fotográfico en el que Silva trabajaba como empleado, siendo todavía un joven de 20 años. Gardel quedó sorprendido por la calidad inusual para la época de las fotos de Silva, y desde entonces recurrió a él, ya independizado, para sacarse las fotos con las que difundiría mundialmente su imagen.

Luego de 1917, Gardel se saca otras dos grandes tandas de fotos con Silva: la primera en 1923, antes de partir en su primera gira a Europa, en la que se toma la conocida foto vestido de gaucho -porque en el "viejo continente" se asociaba estereotipadamente el tango con el gaucho-; y la última en 1933 donde se toma una secuencia de retratos del rostro, que constituyen los famosos retratos con los que se asocia universalmente la imagen de Gardel. Silva jamás cobró un centavo por los derechos de reproducción.

Silva diría sobre Gardel:
En 1995, los músicos Eduardo Suárez ("Korneta"), Eli Suárez, Bruno Suárez y Jorge Rossi, oriundos del barrio porteño del Bajo Flores, fundaron la banda de tango-rock Los Gardelitos, la cual fue bautizada en claro homenaje a Carlos Gardel. La temática de esta banda es la fusión de dos de los ritmos más populares de la música argentina, como ser el rock nacional con el tango, teniendo en sus letras tintes que rememoran la jerga tanguera de la sociedad porteña. "Korneta" Suárez falleció en el año 2004 y el liderazgo de la banda fue asumido por su hijo Eli Suárez en la voz y primera guitarra, mientras que tras continuos recambios en los nombres de la formación inicial (incluido el segundo hijo de Korneta, Bruno, quien dejó la banda en 2001), la formación quedó establecida desde 2017 por Yamil Salvador (guitarra acústica y coros), Pablo Fernández (bajo) y Jerónimo Sica (batería). Por populismo, también se suele hacer referencia a esta banda simplemente como ""Gardeles"".

Gardel realizó 957 grabaciones, cubriendo 792 temas diferentes.

No solo grabó tangos; también música folclórica, milongas, zambas, rancheras, tonadas, estilos, etc. (treinta géneros en total). Grabó algunos foxtrots, un tango en español e inglés, y también algunas canciones tradicionales en francés e italiano y hasta un tango en guaraní.

















</doc>
<doc id="6719" url="https://es.wikipedia.org/wiki?curid=6719" title="Karlheinz Stockhausen">
Karlheinz Stockhausen

Karlheinz Stockhausen ( Mödrath, 22 de agosto de 1928-Kürten-Kettenberg, 5 de diciembre de 2007) fue un compositor alemán ampliamente reconocido, tanto por la crítica como por la opinión musical más ilustrada, como uno de los compositores más destacados y polémicos de la música culta del siglo XX. Para muchos, no solo es una figura importante, sino que se trata de uno de los mayores visionarios de la música del siglo XX. 

Es conocido por sus trabajos de música contemporánea y sus innovaciones en música electroacústica, música aleatoria y composición serial. 

Fue educado primeramente en la Hochschule für Musik Köln para después acudir a la Universidad de Colonia. Posteriormente, Stockhausen estudiaría con Olivier Messiaen en París y Werner Meyer-Eppler en la Universidad de Bonn. 

Como una de las principales figuras de la Escuela de Darmstadt que fue, sus teorías y composiciones siguen siendo, aún hoy en día, de gran influencia para compositores de todos los tipos y estilos (también en la música popular y en el "jazz"). 

Sus obras, compuestas a lo largo de casi sesenta años, se abstienen de ser partícipes de las formas musicales más tradicionales. Aparte de las obras de música electrónica, sus trabajos van desde realizar miniaturas para cajas de música hasta trabajos para instrumentos solistas, canciones, música de cámara, músicas coral y orquestal e incluso un ciclo de siete óperas de larga duración. 

Sus escritos, tanto teóricos como de diversos temas, ocupan más de diez imponentes volúmenes. Stockhausen recibió numerosos premios y distinciones por sus composiciones, grabaciones y partituras publicadas por su propia editorial. 

Entre sus composiciones más notables encontramos la serie de diecinueve "Klavierstücke" (piezas para piano), "Kontra-Punkte" para diez instrumentos, su electrónica/música concreta "Gesang der Jünglinge", "Gruppen" para tres orquestas, la obra para percusión solista "Zyklus", "Kontakte", la cantata "Momente", su obra de electrónica en vivo "Mikrophonie I", "Hymnen", "Stimmung" para seis vocalistas, "Aus den sieben Tagen", "Mantra" para dos pianos y electrónica, "Tierkreis", "Inori" para solistas y orquesta, y su gigantesco círculo de operas "Licht". 

Stockhausen murió de improviso, debido a un ataque cardiaco, el 5 de diciembre de 2007, a la edad de 79 años, en su residencia de Kürten, Alemania. 

Karlheinz Stockhausen nació en el castillo de la ciudad de Mödrath, que servía en esa época de maternidad del distrito de Rhein-Erft-Kreis, al oeste del estado de Renania del Norte-Westfalia, estado alemán fronterizo con Bélgica. (La ciudad de Mödrath, localizada cerca de Kerpen y Colonia, fue desplazada en 1956 para explotar una mina a cielo abierto de lignito, pero el castillo sigue existiendo).

Su padre era profesor de escuela y su madre era hija de una próspera familia de granjeros de Neurath, cerca de Colonia. Ella tocaba el piano y cantaba, pero después de quedar embarazada tres veces consecutivas, sufrió una crisis nerviosa y fue internada en un hospital psiquiátrico en diciembre de 1932. Pocos meses más tarde falleció su hermano menor Hermann.

Stockhausen se fue a vivir a Altenberg a los 7 años, donde recibió clases de piano del organista de la Catedral de Altenberg, Franz-Josef Kloth. Su padre, Simon Stockhausen, se volvió a casar en 1938 con otra mujer, Luzia, con la que tuvo dos hijas.

Como muchos, el vivió una tragedia familiar al desencadenarse la II Guerra Mundial cuando sólo tenía 11 años.

En 1941 o 1942 se enteró de que su madre había muerto, aparentemente de leucemia, como todos los internados en ese hospital, que habían muerto supuestamente de esa misma enfermedad. Se da por hecho que ella fue una víctima de la política nazi de «eutanasia para los individuos no productivos». 
Posteriormente, Stockhausen representará la ejecución de su madre en el hospital mediante una inyección letal, en el Acto 1 escena 2 («Mondeva») de la ópera Donnerstag aus Licht.

En parte debido a su mala relación con su madrastra, en enero de 1942, Karlheinz ingresó en un internado de Xanten donde continuó aprendiendo piano y también estudió oboe y violín e hizo trabajos en una granja.

En el otoño de 1944, fue alistado para servir como camillero trasladando heridos en Bedburg. En febrero de 1945 se reunió por última vez con su padre en Altenberg, el cual se despidió de Stockhausen premonitoriamente, antes de ser enviado a luchar al frente este, del que no volvería.

De 1947 a 1951 estudió piano y pedagogía musical en el Conservatorio Superior de Colonia (la prestigiosa «Hochschule für Musik Köln»). También estudió musicología, filosofía y lengua germánica en la Universidad de Colonia. Completó sus estudios de armonía y contrapunto con el compositor Hermann Schroeder.

En 1950 se interesó por la composición y fue admitido a final del año en la clase del compositor suizo Frank Martin, que empezaba un contrato de 7 años como profesor en Colonia. Simultaneó sus estudios con varios trabajos, de obrero en una fábrica, de guardia en un aparcamiento y de vigilante de viviendas de las tropas de ocupación.

En 1951 se matriculó en los cursos de verano de Darmstadt, centro difusor del serialismo y de corrientes vanguardistas afines, donde tomó contacto con la música de Anton Webern y con la nueva generación de compositores serialistas. 
Allí conoció al compositor belga Karel Goeyvaerts, que había estudiado análisis musical con Olivier Messiaen y composición con Darius Milhaud en París, y que influyó en la decisión de Stockhausen de realizar esos mismos estudios.

En Darmstadt tomó contacto con los compositores que integraban la vanguardia musical alemana fuera del dodecafonismo —Paul Hindemith, Edgar Varèse...— y dentro del dodecafonismo —Arnold Schönberg, Ernst Krenek...— y también la estética de Theodor W. Adorno y René Leibowitz.
Junto con Bruno Maderna, György Ligeti y Luigi Nono, Stockhausen asistió en Darmstadt a ciclos de conciertos que cambiarían su concepción de la música, como el famoso estudio de piano Modo de valores e intensidades de Messiaen, que le decidió a trasladarse a París, donde llegó, el 8 de enero de 1952, para matricularse en el Conservatorio y asistir a las clases de composición de Milhaud y al curso de análisis y estética de Messiaen.

Con Messiaen se familiarizó con la técnica del serialismo, junto con otros compositores importantes y también alumnos de Messiaen, como Iannis Xenakis o Pierre Boulez, que en ese momento trabajaba en las Structures I para dos pianos y con quien entablaría una gran amistad, que inicia una larga correspondencia entre ambos compositores.

Previamente, en 1951, Stockhausen se había casado con una compañera de estudios, Doris Andreä, con la que tuvo cuatro hijos, Suja (1953), Christel (1956), Markus (1957) y Majella (1961)

Desde 1953 compuso obras de música electroacústica, como Gesang der Jünglinge [«El canto de los adolescentes»], sirviendo como demostración práctica de la viabilidad de componer usando métodos nunca probados en música clásica, como dispositivos electrónicos o algoritmos matemáticos.

Al regresar a Alemania, en marzo de 1953, inició su colaboración con el Estudio de Música Electrónica de la Radio Oeste de Colonia —llamada NWDR y WDR a partir del 1 de enero de 1955—, con el puesto de asistente del director Herbert Eimert.
El Estudio de Música Electrónica de Colonia fue una institución clave para otros compositores de música electroacústica, como John Cage. En 1962 Stockhausen sucedió a Eimert como director del estudio.

También comenzó a divulgar sus teorías en los cursos de Darmstadt, una actividad que mantuvo hasta mediados de la década de los años 1970. 

De 1954 a 1956 Stockhausen estudió fonética, acústica y teoría de la información con Werner Meyer-Eppler en la Universidad de Bonn.

Junto con Eimert editó la influyente revista «Die Reihe» desde 1955 a 1962.

Stockhausen dio conferencias y conciertos en Europa, Norte América y Asia. Fue profesor invitado de composición en la Universidad de Pensilvania en 1965, y en la Universidad Davis de California en 1966-67. Fundó y dirigió los Cursos de Nuevas Músicas de Colonia desde 1963 a 1968. En 1971 fue nombrado profesor de composición del Conservatorio Nacional de Música, permaneciendo en el puesto hasta 1977.

En 1961 compró un terreno en la vecindad de Kürten, un pueblo al este de Colonia cerca de Bergisch Gladbach en la Bergisches Land, donde se hizo construir una casa diseñada por el arquitecto Erich Schneider-Wessling, donde fijó su residencia una vez finalizada en 1965.

En 1967 se casó con la pintora y escultora alemana Mary Bauermeister —nacida en 1934 y fundadora hacia 1960 de un movimiento artístico de vanguardia en Colonia que más tarde daría lugar al movimiento Fluxus— y con la que tuvo dos hijos: Julika (1966) y Simon (1967).

En 1998 creó los Cursos Stockhausen, impartidos anualmente en Kürten.

A finales de 2001, Stockhausen fue protagonista de una agria polémica debido a unas declaraciones que hizo en relación al atentado del 11 de septiembre de 2001 de Nueva York. Varios medios de comunicación publicaron que el había calificado de «obra de arte» el atentado terrorista. Stockhausen se quejó de que algunas palabras suyas habían sido sacadas de contexto y malinterpretadas.

A continuación se incluye una descripción pormenorizada de la polémica: 

En una conferencia de prensa en Hamburgo, el 16 de septiembre de 2001, Stockhausen fue preguntado por un periodista sobre si los personajes de la obra "Licht" eran para él «figuras fuera de una historia cultural común» o si poseían «representación material». El compositor replicó: «Rezo diariamente a Miguel, no a Lucifer. He renunciado a él. Pero está demasiado presente, como en Nueva York recientemente». Otro periodista le preguntó sobre como le afectaban los recientes atentados terroristas del 11 de septiembre de 2001, y que visión tenía de esos sucesos en relación a la armonía de la humanidad representada en la obra "Hymnen".

En un posterior mensaje, afirmó que la prensa había publicado un «falso y difamatorio reportaje» sobre sus comentarios y aclaró lo que sigue:

Como resultado de la reacción a los comentarios de él, un festival de cuatro días sobre su obra en Hamburgo fue cancelado. Además su hija pianista anunció a la prensa que no volvería a actuar con el apellido Stockhausen.

De acuerdo con el anuncio efectuado por la Fundación Stockhausen el 7 de diciembre de 2007, el falleció en la mañana del 5 de diciembre de 2007, debido a un repentino fallo cardíaco, en la ciudad de Kürten-Kettenberg cercana a Colonia en el estado alemán de Renania del Norte-Westfalia. 
Acababa de terminar dos trabajos encargados para espectáculos en Bolonia y el Festival de Holanda previsto para junio de 2008 en Ámsterdam.

Stockhausen compuso 363 obras, todas ellas grabadas y recogidas en 139 CD. Frecuentemente se apartó radicalmente de la tradición de la música clásica influenciado por Messiaen, Edgard Varèse, y Anton Webern. También se dejó influir por otras disciplinas artísticas como el cine (Stockhausen 1996b) o pintores como Piet Mondrian (Stockhausen 1996a, 94; "Texte" 3, 92–93; Toop 1998) y Paul Klee.
Junto a su labor como compositor destacó también su tarea de director de orquesta.

Stockhausen empezó a componer durante su tercer año de conservatorio, pero solo ha publicado cuatro de sus primeras composiciones de estudiante: Chöre für Doris, Drei Lieder, para voz de alto y orquesta de cámara, Choral, para coro a capella (las tres de 1950), y una Sonatina para violín y piano (1951).

En agosto de 1951, justo después de su primera visita a Darmstadt, Stockhausen empezó a trabajar con una forma de música atemática compuesta serialmente que rechazaba la técnica de 12 tonos de Schoenberg.

Calificó muchas de esas tempranas composiciones como «música puntual», aunque algún crítico concluye después de analizar en profundidad esas partituras que Stockhausen «nunca compuso puntualmente».
Las composiciones de esta época incluyen obras como Kreuzspiel (1951), el Klavierstücke I–IV (1952) —la cuarta pieza es especialmente citada por Stockhausen como un ejemplo de «música puntual»), y la primera versión (no publicada) de Punkte y Kontra-Punkte (1952).

De lo que no hay duda es que algunas obras de esos años muestran a Stockhausen formulando sus primeras contribuciones, rompedoras y revolucionarias, a la teoría y práctica de la composición, como la «composición grupal», una técnica usada en sus composiciones desde 1952 y durante toda su obra. Este principio fue descrito públicamente por primera vez por el en una locución de radio de diciembre de 1955 titulada «"Gruppenkomposition: Klavierstücke I"».

En diciembre de 1952 compuso un Konkrete Etüde, en el estudio de música concreta de Pierre Schaeffer en París. En marzo de 1953 se trasladó al estudio de la radio NWDR de Colonia y cambió a la música electrónica con dos Estudios Electrónicos (1953 y 1954).

En la obra Gesang der Jünglinge (1955-56) introdujo, por vez primera, el emplazamiento espacial de fuentes de sonido, con su mezcla de música concreta y música electrónica.

La experiencia ganada con los Estudios le convencieron de que era una simplificación inaceptable tratar los timbres como entidades estables.

Reforzado por sus estudios con Meyer-Eppler, a principios de 1955 Stockhausen formuló nuevos criterios «estadísticos» de composición, enfocando su atención hacia la música aleatoria, tendencia en la que se movía el movimiento sonoro, «el cambio de un estado a otro, con o sin movimiento de retorno, como opuesto al estado estático».

Posteriormente Stockhausen escribió, describiendo ese periodo en su trabajo de composición: «La primera revolución musical que ocurrió desde 1952/53, denominada "música concreta", "música electrónica con cinta magnetofónica", y "música espacial", requería componer con transformadores, generadores, moduladores, magnetófonos, etc, integrar "todas" las posibilidades sonoras concretas y abstractas (sintéticas) incluyendo todos los ruidos, y lograr la proyección controlada del sonido en el espacio».

Su posición como «compositor alemán líder de su generación» fue conquistada con Gesang der Jünglinge y tres piezas compuestas concurrentemente con diferentes medios: Zeitmasze para cuatro instrumentos de viento de madera, Gruppen para tres orquestas, y Klavierstücke XI. Los principios subyacentes a estas tres composiciones fueron presentados en el artículo teórico más conocido de Stockhausen: «...wie die Zeit vergeht...» [«...Como pasa el tiempo...»], publicado por primera vez en 1957 en el vol. 3 de la revista «Die Reihe».

En 1960 Stockhausen volvió a la composición de música vocal (por primera vez desde Gesang der Jünglinge) con Carré para cuatro coros y cuatro orquestas. Dos años después comienza una cantata expandible titulada Momente, para soprano solista, cuatro grupos de coro y trece instrumentistas (1962-64/69). 

Fue pionero en la interpretación electrónica en vivo, con obras como Mixtur, para electrónica y orquesta (1964/67/2003), Mikrophonie I, para tam-tam, dos micrófonos y dos filtros con potenciómetros (6 intérpretes) (1964), Mikrophonie II, para coro, órgano Hammond y cuatro moduladores en anillo (1965) y Solo para instrumento melódico con realimentación (1966).

También compuso dos obras electrónicas para cinta, Telemusik (1966) e Hymnen (1966-67), de la que hay también una versión con solistas y la 3ª de estas cuatro «regiones» en una versión con orquesta.

En esa época, Stockhausen empezó a incorporar música tradicional de todo el mundo en sus composiciones, siendo Telemusik el primer ejemplo conocido de esta tendencia.

Durante la década de 1960, Stockhausen exploró las posibilidades de la «música procesada» en trabajos para espectáculos en vivo, como Prozession (1967), Kurzwellen, y Spiral (ambas de 1968), culminando en las composiciones de música instintiva descritas verbalmente de Aus den Sieben Tagen (1968), Für kommende Zeiten (1968-70), Ylem (1972) y las primeras tres partes de Herbstmusik (1974). 

En 1968 Stockhausen compuso el sexteto vocal Stimmung, para el «Collegium Vocale Köln», una obra de una hora basada enteramente en los armónicos de un Si bemol grave. Seis vocalistas se sientan alrededor de una esfera luminosa y durante una hora y cuarto mantienen una misma nota en la que, con un complejo sistema de variaciones, alternan por turnos siglas mágicas y fragmentos poéticos, determinando una lenta, casi imperceptible, mutación de color vocálico y un progresivo desplazamiento del centro tonal del acorde formado por las notas fijas

A partir de Mantra (1970), Stockhausen experimentó con la composición matemática, una técnica que recurre a la proyección y multiplicación de una melodía simple, doble o triple mediante una fórmula matemática lineal (Kohl 1983; Kohl 1990; Kohl 2004). Esta fórmula es para Stockhausen, una semilla o célula-madre que mantiene la cualidad principal de la serie de la duración o de la escala elegida en los valores de tempo. Mantra en el contexto de la música de Stockhausen es herramienta para desencadenar una especie de meditación que permite comprender la naturaleza y técnica de la música, pretendiendo que a la larga se produzca una implantación que pueda lograr una transformación en nuestras vidas. En todo su trabajo, como en Mantra, por más increíble que parezca, hay un intento de preparar a una humanidad para esta transformación (psicológica o espiritual).

Algunas veces, (como en Mantra e Inori), la fórmula es colocada al principio como una introducción. 
Continúa usando esta técnica para completar su ciclo de ópera Licht en 2003.

Otras obras de esta época no están creadas con la técnica de fórmulas matemáticas y comparten un estilo simple orientado a la melodía como:
El dueto vocal «Am Himmel wandre ich» [«En el cielo andando estoy»], uno de los 13 componentes de la obra multimedia Alphabet für Liège, 1972), "Laub und Regen" ("Hojas y lluvia", para la obra de teatro Herbstmusik (1974), y la ópera coral Atmen gibt das Leben ("Respiración da vida", 1974/77),

Las piezas Tierkreis («Zodiaco», 1974-75) y In Freundschaft («En camaradería», 1977) han sido las composiciones de Stockhausen más ampliamente interpretadas y grabadas.

Esta dramática simplificación de estilo se convirtió en el modelo a seguir por una nueva generación de compositores alemanes, comúnmente conocidos con la etiqueta de «Neue Einfachheit» o «Nueva Simplicidad». El más conocido de estos compositores es Wolfgang Rihm, que estudió con Stockhausen en 1972-73, y cuya composición orquestal Sub-Kontur (1974-75) reutiliza la fórmula de Stockhausen de Inori (1973–74).

Entre 1977 y 2003 compuso un ciclo de siete óperas llamadas "Licht: Die sieben Tage der Woche," «Luz: Los siete días de la semana»]), que trata sobre las costumbres asociadas a cada día de la semana en varias tradiciones históricas —lunes, nacimiento y fertilidad; martes, conflicto y guerra; miércoles, reconciliación y cooperación; jueves, viajes y aprendizaje; etc.— junto a la relación e interacción entre tres caracteres arquetípicos: Lucifer, Miguel, y Eva.

La concepción de la ópera de Stockhausen está basada en la ceremonia y en el ritual, con influencias del estilo de teatro japonés Noh (Stockhausen, Conen, y Hennlich 1989, 282), además de las tradiciones judeo-cristianas y de los Vedas.

Junto a ello, el trato que da a las voces y a los textos algunas veces se aleja del uso tradicional: los personajes son esquematizados para ser representados por instrumentos, bailarines o cantantes, y en algunas partes de Licht (como por ejemplo, "Luzifers Traum" del Samstag, las "escenas reales" durante Freitag o "Welt-Parlament" y "Michaelion" del Mittwoch) usó textos escritos o improvisados en lenguajes simulados o inventados.

Stockhausen tuvo su época dorada en la década de los años 1970, pero posteriormente siguió produciendo obras significativas como Stimmung (1986), en la que seis voces exploran durante setenta minutos las diversas posibilidades de un solo acorde.

Después de completar "Licht", Stockhausen se embarcó en un nuevo ciclo de composiciones basado en las horas del día, titulado Klang [«Sonidos»], del que completó veintiuna piezas antes de su fallecimiento. 

Las obras realizadas de este ciclo son "Primera hora": Himmelfahrt [«Ascensión»], para órgano o sintetizador, soprano y tenor (2004-05); "Segunda hora": Freude [«Felicidad»] para dos arpas (2005); "Tercera hora": Natürliche Dauern [«Duraciones naturales»] para piano (2005-06); y "Cuarta hora": Himmels-Tür [«Puerta del cielo»] para percusionista y niña pequeña (2005).

La "Quinta hora", "Harmonien" {«Armonías»], es un solo en tres versiones para flauta, clarinete bajo, y trompeta (2006); las versiones de clarinete bajo y flauta fueron estrenadas en Kürten el 11 de julio y 13 de julio de 2007, respectivamente.
La "Sexta hora" y las siguientes hasta la "Duodécima hora" son obras de música de cámara basadas en la partitura de la Quinta Hora. 

Los estrenos de la "Sexta" (Schönheit, para flauta, trompeta, y clarinete bajo), "Séptima" ("Balance", para flauta, corno inglés, y clarinete bajo), "Novena" (Hoffnung, para trío de cuerdas), y "Décima" (Glanz, para nueve instrumentos, encargado por el Asko Ensemble y el Festival de Holanda) han sido anunciados para 2008.

La "Decimotercera hora" Cosmic Pulses (una obra electrónica creada mediante la superposición de 24 capas de sonido, cada una con su propio movimiento espacial, usando ocho altavoces situados alrededor de la sala de concierto) fue estrenada en Roma el 7 de mayo de 2007 en el Auditorio Parco della Musica, (Sala Sinopoli). Las "Horas" 14 a 21 son piezas solistas para voz de bajo, barítono, corno di bassetto, tenor, soprano, saxofón soprano y flauta, respectivamente, con el acompañamiento electrónico de algunas de las capas de sonido de Cosmic Pulses.

A principios de 1990, Stockhausen adquirió las licencias de muchas de las grabaciones de su música que había realizado hasta entonces, y fundó su propia compañía discográfica para permitir que toda su música estuviese permanentemente disponible en compact disc.

También diseñó e imprimió sus partituras musicales, que a menudo incorporan notación no convencional. La partitura de su pieza Refrain, por ejemplo, incluye un estribillo escrito en una cinta sin fin de plástico transparente que se debe rotar para la lectura, y el volumen en Weltparlament (la primera escena de Mittwoch aus Licht) está codificado en color.

Stockhausen fue uno de los pocos grandes compositores del siglo XX que ha escrito gran cantidad de música para trompeta, inspirado por su hijo Markus Stockhausen, trompetista.

Una de las obras más espectaculares y anticonvencionales de Stockhausen es el Helikopter-Streichquartett [«Cuarteto para cuerdas y helicóptero»] (la tercera escena de Mittwoch aus Licht), completada en 1993. En ella, los cuatro miembros de un cuarteto de cuerdas tocan en cuatro helicópteros que vuelan independientemente sobre las cercanías de la sala de conciertos. La música de los intérpretes es mezclada con el sonido de los helicópteros y reproducida mediante altavoces a la audiencia de la sala. Vídeos de la performance son también transmitidos a la sala de conciertos. Los intérpretes están sincronizados con la ayuda de un metrónomo electrónico. 

La primera representación de la pieza se realizó en Ámsterdam el 26 de junio de 1995, como parte del «Holland Festival».
Debido a su naturaleza extremadamente inusual, la pieza ha sido interpretada en pocas ocasiones, incluyendo una el 22 de agosto de 2003 como parte del Festival de Salzburgo para inaugurar las instalaciones de Hangar-7, y su estreno en Alemania fue el 17 de junio de 2007 en Braunschweig dentro del Festival Stadt der Wissenschaft 2007. La pieza ha sido grabada por el «Arditti Quartet».

Stockhausen y su música han sido controvertidos e influyentes. Los dos tempranos Estudios Electrónicos (especialmente el segundo) tuvieron una poderosa influencia en el posterior desarrollo de la música electrónica en las décadas de 1950 y 1960, particularmente en el trabajo del italiano Franco Evangelisti y de los polacos Andrzej Dobrowolski y Włodzimierz Kotoński.

La influencia de su Kontrapunkte, Zeitmasse y Gruppen puede observarse en el trabajo de muchos compositores, incluyendo algunas obras de Igor Stravinsky, como Threni (1957-58), Movements for Piano and Orchestra (1958-59) y Variaciones: Homenaje a Aldous Huxley (1963-64), cuyos ritmos «probablemente han sido inspiradas, al menos en parte, por ciertos pasajes de "Gruppen" de Stockhausen».

En todo caso músicos de la generación de Stockhausen pueden considerarle una influencia improbable. En una conversación de 1957 Stravinsky dijo:

Músicos de jazz como Miles Davis, Cecil Taylor, Charles Mingus, Herbie Hancock, Yusef Lateef, y Anthony Braxton citan a Stockhausen como una influencia.

El también fue influyente en la música pop y rock. Frank Zappa hace un reconocimiento de Stockhausen en la portada de "Freak Out!", disco de 1966 con el que debutó con los Mothers of Invention. Rick Wright y Roger Waters de Pink Floyd también lo reconocen a el como una influencia (Macon 1997, 141; Bayles 1996, 222).

Las bandas psicodélicas de San Francisco Jefferson Airplane y Grateful Dead han afirmado vagamente que seguían el mismo camino de experimentación musical. Stockhausen se merece considerarse fundador de la banda Grateful Dead, algunos de cuyos integrantes estudiaron con Luciano Berio y haberlos «orientado correctamente a través de la nueva música».

Los miembros fundadores de la banda experimental de Colonia Can, Irmin Schmidt y Holger Czukay, han estudiado recientemente con Stockhausen, como también hicieron los músicos alemanes de Kraftwerk. Los experimentadores del sonido de guitarra de New York Sonic Youth también reconocen la influencia de Stockhausen , igual que la vocal Islandesa Björk (Guðmundsdóttir 1996; Ross 2004, 53 & 55), y el grupo británico de música industrial Coil. Chris Cutler del grupo experimental Británico Henry Cow nombraron la obra "Carré" de Stockhausen como una de sus cuatro grabaciones favoritas (en "Melody Maker" , febrero de 1974).

Stockhausen, junto con John Cage, es uno de los pocos compositores de vanguardia que han conseguido llegar a la conciencia popular y mucha más gente conoce su nombre de la que ha escuchado su música. 

Paul McCartney, decidió incluirlo entre los personajes que aparecen en la portada del álbum "Sgt. Pepper's Lonely Hearts Club Band", como menciona Hunter Davies en la biografía autorizada de The Beatles. Esto refleja su influencia en los experimentos de vanguardia de la banda, pero también la fama y notoriedad general que obtuvo a partir de 1967.

El nombre de Stockhausen, y la percepción de su música como extraña e inescuchable, han sido objeto de chistes en dibujos y caricaturas, como se documenta en una página de la web oficial de Stockhausen.
Probablemente la frase más cáustica sobre Stockhausen es la atribuida a "sir" Thomas Beecham. A la pregunta: «¿Ha oído algo de Stockhausen?», respondió diciendo: «No, pero creo que alguna vez lo he pisado».

Su fama también se refleja en menciones en obras literarias. Por ejemplo, es mencionado en una novela de Philip K. Dick de 1974 "Flow My Tears, The Policeman Said", y en la novela de Thomas Pynchon de 1966 "The Crying of Lot 49". La novela de Pynchon transcurre en The Scope, un bar con «una estricta política de música electrónica». La protagonista Oedipa Maas pregunta a un habitual del bar por un «frenético coro de gritos y quejidos» que procede de «algún tipo de aparato musical». Él replica: «Esto es de Stockhausen... la primera tendencia popular en entusiasmar de tu sonido de Radio Colonia. Más tarde logramos comprender su ritmo».

Robin Maconie, uno de los compositores y críticos especialistas en Stockhausen, escribió que, «Comparado con el trabajo de sus contemporáneos, la música de Stockhausen tiene una profundidad e integridad racional muy destacada... Sus investigaciones, inicialmente guiadas por Meyer-Eppler, tienen una coherencia mayor que cualquier otro compositor contemporáneo o posterior».
Maconie comparó a Stockhausen con Beethoven: «Si un genio es alguien cuyas ideas resisten todos los intentos de explicación, entonces por definición Stockhausen es lo más cercano a Beethoven que este siglo ha producido. ¿Razón? Su continua producción musical». (Maconie 1988), y «Como dijo Stravinsky, uno nunca piensa en Beethoven como un excepcional compositor porque la calidad de su inventiva transciende la mera competencia profesional. Pasa lo mismo con Stockhausen: la intensidad de su imaginación eleva las impresiones musicales de una elemental y perceptible belleza inescrutable, superando los límites del diseño consciente».

Igor Stravinsky expresó un gran entusiasmo, no falto de crítica, por la música de Stockhausen en los libros sobre sus conversaciones con Robert Craft y durante años organizó audiciones privadas con amigos en su casa donde escuchaban cintas con los últimos trabajos de él. 
En una entrevista publicada en marzo de 1968 dijo:
El siguiente octubre, un reportaje en "Sovetskaia Muzyka" (Anon. 1968) tradujo esta frase —y alguna más del mismo artículo— al ruso, sustituyendo la conjunción «pero» por la frase «Ia imeiu v vidu Karlkheintsa Shtokkhauzena» («Me estoy refiriendo a Karlheinz Stockhausen»). 
Cuando esta traducción fue anotada en la biografía de Stravinsky escrita por Druskin, la interpretación fue ampliada a todas las composiciones de Stockhausen y añade para la buena comprensión, «de hecho, obras que él llama innecesarias, inútiles y poco interesantes», citando de nuevo a partir del mismo artículo de "Sovetskaia Muzyka", a pesar de que ha quedado claro que la referencia era a «compositores universitarios» americanos.

A principios de 1995, la BBC Radio 3 envió a Stockhausen grabaciones de los artistas contemporáneos —Aphex Twin, Plastikman, Scanner y Daniel Pemberton— y le preguntó por su opinión acerca de esa música. En agosto de ese año, el periodista de Radio 3, Dick Witts, entrevistó a Stockhausen acerca de esas piezas para un programa emitido en octubre —y posteriormente publicada en el número de noviembre de la publicación británica The Wire— preguntándole qué consejos le daría a esos jóvenes músicos. Stockhausen hizo sugerencias individuales a cada uno de ellos, que fueron entonces invitados a responder. Todos menos Plastikman lo agradecieron.

En una entrevista realizada por una periodista que le cuestionaba «¿Qué es la música?», el maestro Stockhausen le respondió de la siguiente manera: «el sonido emitido por un ama de casa mientras cocina no es música, pero si yo la grabo, eso ya es música».

Algunos de los numerosos premios y distinciones otorgadas a Stockhausen son:






</doc>
<doc id="6721" url="https://es.wikipedia.org/wiki?curid=6721" title="Marismas del Ampurdán">
Marismas del Ampurdán

Las marismas del Ampurdán (en catalán y oficialmente "Aiguamolls de l’Empordà") son un conjunto de humedales generados por el curso final del río Muga y del Fluviá (Alto Ampurdán) y del Ter y del Daró (Bajo Ampurdán), constituyendo la segunda zona húmeda más importante de Cataluña (España), después del delta del Ebro.

Esta área húmeda del Alto Ampurdán fue declarada "Paraje de Interés Natural" según una ley aprobada por el Parlamento de Cataluña en 1983.

Tiene una extensión de 4824 hectáreas y abarca las tierras del curso bajo del río Muga y del Fluviá (lago de Vilaüt, la Massona, la Rogera, la Llarga...), junto con una amplia zona periférica.

Su principal interés se encuentra en la riqueza de la fauna ornitológica, especialmente migratoria.

La declaración de tierras protegidas afecta a nueve municipios: Pau, Rosas, Pedret y Marsá, Perelada, Palau Sabardera, La Armentera, La Escala, San Pedro Pescador y Castellón de Ampurias.

El año 1995 el parque natural de las Marismas del Ampurdán empezó la reintroducción de nutrias en los ríos Fluviá y Muga, dejando en libertad un primer ejemplar traído de Extremadura. Esta experiencia, al igual que otras similares como la impulsada en Aigüestortes, permiten que este mamífero vuelva a un hábitat natural del que prácticamente había desaparecido.



</doc>
<doc id="6722" url="https://es.wikipedia.org/wiki?curid=6722" title="Batalla de Puebla">
Batalla de Puebla

La batalla de Puebla fue un combate librado el 5 de mayo de 1862 en las cercanías de la ciudad de Puebla, entre los ejércitos de la República Mexicana, bajo el mando de Ignacio Zaragoza, y del Segundo Imperio francés, dirigido por Charles Ferdinand Latrille, conde de Lorencez, durante la Segunda Intervención Francesa en México, cuyo resultado fue una victoria importante para los mexicanos ya que con unas fuerzas consideradas como inferiores lograron vencer a uno de los ejércitos más experimentados. Pese a su éxito, la batalla no impidió la invasión del país, aunque sí que sería la primera batalla de una guerra que finalmente México ganaría. Los franceses regresarían al siguiente año, con lo que se libró una segunda batalla en Puebla en la que se enfrentaron 35 000 franceses contra 29 000 mexicanos (defensa que duró 62 días) y lograrían avanzar hasta Ciudad de México, lo que permitió establecer el Segundo Imperio Mexicano.
Finalmente, después de perder 11 000 hombres debido a la actividad guerrillera que nunca dejó de subsistir, los franceses se retiraron incondicionalmente del país en el año 1867 por mandato del emperador Napoleón III ante la amenaza de Prusia en Europa y la amenaza estadounidense de invadirle si no se retiraba de México.

Después de que el presidente Benito Juárez anunciara que no pagaría la deuda externa, en octubre de 1861, Francia, Inglaterra y España suscribieron la Convención de Londres, en la cual se comprometieron a enviar contingentes militares a México para reclamar sus derechos como acreedores por una deuda que ascendía a alrededor de 80 millones de pesos, de los que aproximadamente 69 millones corresponderían a Inglaterra, 9 millones a España y 2 millones a Francia.

El contingente europeo estaba conformado como sigue:

Poco después de reunirse, los representantes de los tres países enviaron un ultimátum al gobierno mexicano en el que pedían el pago de sus deudas; de lo contrario, invadiría el país. Juárez, quien gobernaba a un país que apenas empezaba a levantarse de la postración económica, respondió con un exhorto a lograr un arreglo amistoso, y los invitó a una conferencia. Acompañó ese mensaje con la derogación del decreto que suspendió los pagos. Al mismo tiempo, en vista de la posibilidad real de una invasión militar que buscara llegar hasta la Ciudad de México, ordenó el traslado de pertrechos y la fortificación de Puebla, así como crear una unidad, a la que se designó como Ejército de Oriente, que fue puesta bajo el mando del general José López Uraga. En vista del desempeño deficiente de este mando, fue destituido y en su lugar se designó a Zaragoza, quien dejó el Ministerio de Guerra y se dirigió a Puebla para organizar la oposición al avance francés con cerca de 10 000 hombres; cantidad mínima si se toma en cuenta el vasto territorio que debía cubrirse.

Los representantes aceptaron el llamado y en febrero de 1862 se reunieron con los ministros juaristas del Exterior, Manuel Doblado, y de Guerra, Ignacio Zaragoza, en la hacienda de La Soledad, cerca de Veracruz. Gracias a la habilidad como negociador de Doblado se firmaron los Tratados preliminares de La Soledad, en los que se obtuvo el reconocimiento como interlocutor para el gobierno de Juárez y se garantizó el respeto a la integridad e independencia del país. Además, se convino que las negociaciones sobre la deuda se realizaran el Orizaba, donde se establecerían las fuerzas aliadas, además de Córdoba y Tehuacán, para evitar el rigor del clima tropical del puerto; si no se llegaba a un acuerdo, se retirarían a la costa para así comenzar las hostilidades.

El 5 de marzo, cuando aún se realizaban las negociaciones en Orizaba, llegó a Veracruz un contingente militar francés bajo el mando de Charles Ferdinand Latrille, conde de Lorencez, quien relevó en el mando a Jurien de la Gravière y se dirigió a Tehuacán. También llegó el general conservador
Juan Nepomuceno Almonte, quien de inmediato se proclamó "jefe supremo de la nación" y empezó a reunir a las tropas conservadoras, remanentes de la Guerra de Reforma, para apoyar a los franceses.

En abril de 1862 la alianza tripartita se rompió debido a que España e Inglaterra se dieron cuenta de que Francia tenía un interés soterrado, de tipo geopolítico, bajo el reclamo económico: derrocar al gobierno republicano de México para establecer una monarquía favorable a su política colonial, con miras a contrarrestar el creciente poderío de Estados Unidos. De las instrucciones de Napoleón III dadas al jefe militar de la expedición, se sabe que el objetivo imperialista francés consistía en ampliar sus dominios estableciendo un protectorado, cuya administración serviría para ampliar los mercados, sostener las colonias en las Antillas y del sur de América y, de ese modo, garantizar el abasto de las materias primas en Francia. Los representantes español (Prim) e inglés (Charles Wyke) negociaron con el gobierno juarista por separado y en última instancia aceptaron las propuestas de moratoria del gobierno mexicano, y reembarcaron a sus tropas. La posición de Francia, en contraste, presentada por el diplomático Dubois de Saligny, fue la de exigir el pago inmediato de la deuda, que incluía un cobro exagerado por parte de la Casa Jecker por los destrozos causados durante la Guerra de Reforma, y tener control total y absoluto de las aduanas, así como intervención directa en la política económica del país.

A finales de abril, Lorencez desconoció los Tratados de Soledad y se puso en marcha, junto con sus efectivos, hacia Puebla, con el fin último de conquistar la Ciudad de México. A los militares franceses los rodeaba un aura de invencibilidad en combate dado que no habían sido derrotados desde Waterloo, casi 50 años antes, con sonadas victorias en las batallas de Solferino, Magenta y Sebastopol. Esta actitud quedó de manifiesto en el siguiente mensaje, que Lorencez envió al conde Jacques Louis César Alexandre Randon, ministro de Guerra francés, poco después de la batalla de Las Cumbres: "Somos tan superiores a los mexicanos en organización, disciplina, raza, moral y refinamiento de sensibilidades, que le ruego anunciarle a Su Majestad Imperial, Napoleón III, que a partir de este momento y al mando de nuestros 6,000 valientes soldados, ya soy dueño de México”. La confianza del alto mando francés no se debía sólo a un palmarés militar impecable, sino a la fragilidad general de México y sus instituciones. Con una economía destruida por casi 50 años de guerras civiles, con un Estado débil y una población dividida por las pugnas entre facciones, la conquista del país parecía una empresa factible con un contingente reducido.

Al conocer sobre el avance, el general Alejandro Constante Jiménez al mando de 2000 soldados se unió al general Zaragoza, que partió de Puebla con 4000 soldados para salir al encuentro de los franceses, quienes ya sostenían escaramuzas con guerrilleros. El comandante mexicano había enfrentado diversos problemas para conformar su ejército. Ante la falta de voluntarios y a que aún se mantenían hostilidades con grupos conservadores remanentes de la Guerra de Reforma, se había recurrido a la leva. Aunque se contaba con un cuerpo de oficiales joven pero experimentado, la mayor parte de la tropa carecía de la disciplina mínima, y estaba mal equipada y alimentada. En los días anteriores a la batalla, Zaragoza solicitó una y otra vez al alto mando en Ciudad de México, el envío urgente de recursos económicos, ya que no podía costear ni siquiera los alimentos para las tropas. Para colmo, la explosión de un polvorín en la colecturía de los diezmos del poblado de San Andrés Chalchicomula (hoy Ciudad Serdán), ocurrida el 6 de marzo, había matado a 1,322 soldados de la Brigada de Oaxaca enviados por el general Ignacio Mejía para incorporarse al Ejército de Oriente.

El 28 de abril, el Ejército de Oriente se topó con la columna de Lorencez en un paso de montaña en las Cumbres de Acultzingo, en el límite entre Veracruz y Puebla, lo que representó el primer encuentro bélico formal. Zaragoza no pretendía cortarle el paso a los invasores, sino más bien foguear a sus soldados, muchos de ellos faltos de experiencia, y al mismo tiempo causarle el máximo de pérdidas posible al enemigo. En la llamada Batalla de Las Cumbres murieron 500 franceses, mientras las bajas mexicanas ascendieron sólo a 50. Pese a este saldo favorable, Zaragoza aún tenía desconfianza sobre el desempeño real de sus tropas en un combate en campo abierto. Luego de la retirada de los mexicanos, los franceses tomaron control del paso, con lo que aislaron al centro del país del principal puerto en el Golfo, y tuvieron la vía franca hacia Puebla.

Asegurado el paso de Acultzingo, el 2 de mayo de 1862 la columna principal del ejército expedicionario francés salió de San Agustín del Palmar, en Veracruz, para cruzar la Sierra Madre Oriental y dirigirse hacia Puebla, paso obligado para llegar a la capital del país y que era además uno de los bastiones del Partido Conservador, donde esperaban ser recibidos "con una lluvia de rosas", como le aseguró Saligny a Napoleón III en una carta. El 3 de mayo por la noche, el general Zaragoza arribó a Puebla, dejando en su retaguardia una brigada de caballería para hostigar a los invasores. Los efectivos del Ejército de Oriente se organizaron por las calles desiertas de la ciudad, ya que la mayoría de la población era partidaria de la invasión.

Zaragoza estableció su cuartel a unos cuantos metros de la línea de batalla, donde estableció el plan para la defensa de la plaza (ver tabla superior), que consistió en concentrar los pertrechos en el sur y oriente de la ciudad, esperando evitar que los franceses alcanzaran al área urbana de Puebla.

El 4 de mayo, los exploradores mexicanos volvieron con noticias de que una columna de conservadores a caballo, al mando de Leonardo Márquez y José María Cobos, marchaba por la zona de Atlixco para unirse con las fuerzas de Lorencez en el ataque a Puebla. Zaragoza envió una brigada de 2000 hombres bajo el mando de Tomás O'Horán y Antonio Carbajal, con el fin de detenerlo, lo cual lograron. Aunque sus fuerzas habían disminuido, los mexicanos se prepararon para la defensa de Puebla. Contaban con dos baterías de artillería de batalla y dos de montaña, cubriendo los fuertes con 1200 hombres y formando a otros 3500 en cuatro columnas de infantería con una batería de batalla y una brigada de caballería por el lado del camino a Amozoc.

El ala derecha mexicana la cubrían las tropas de Oaxaca dirigidas por Porfirio Díaz. El centro de la línea lo ocuparon Felipe Berriozábal y Francisco Lamadrid con las tropas del Estado de México y San Luis Potosí. La izquierda se apoyó en el cerro de Acueyametepec ubicado en el norte de la ciudad y en cuya cumbre se ubicaban los Fuertes de Loreto y Guadalupe, con el general Miguel Negrete a la cabeza de la Segunda División de Infantería. La artillería sobrante la colocaron en los fortines y reductos dentro de Puebla, quedando al mando del general Santiago Tapia.

A las 9:15 de la mañana del 5 de mayo, los franceses aparecieron en el horizonte, avanzando desde la cercana Hacienda de Rementería, cruzando fuego con las guerrillas de caballería que se batían en retirada y que no se replegaron hasta que las líneas francesas estuvieron formadas y listas para avanzar. La batalla se inició en forma a las 11:15 de la mañana, anunciándose con un cañonazo desde el Fuerte de Guadalupe y acompañado por los repiques de las campanas de la ciudad. En ese momento se dio una maniobra sorpresiva: la columna francesa, que venía avanzando en orden de oriente a poniente, se dividió en dos: la primera, compuesta por aproximadamente 4000 hombres y protegida con su artillería, dio un violento viraje hacia la derecha y se dirigió hacia los fuertes; mientras que la segunda columna, compuesta por el resto de la infantería, quedó como reserva.

Los conservadores Almonte y Antonio de Haro y Tamariz, que acompañaban a los franceses, habían sugerido que el ataque se dirigiera a las inmediaciones del ex Convento del Carmen, en el sur de la ciudad, tomando como antecedente lo que sucedió en el sitio durante la Guerra con Estados Unidos. Lorencez, confiado en la superioridad de sus tropas, así como en el auxilio que esperaba del contingente de Márquez, desoyó el consejo y decidió concentrar el ataque en los fuertes, donde los mexicanos contaban con la ventaja. Zaragoza advirtió la maniobra y rápidamente replanteó su plan de batalla, movilizando las tropas hacia las faldas del cerro. El 6o. Batallón de la Guardia Nacional del Estado de Puebla, bajo el mando del entonces coronel Juan Nepomuceno Méndez, fue el primer cuerpo del Ejército de Oriente en hacer frente a los franceses, al ubicarse en la línea comprendida entre los fuertes, y rechazar su ataque. Zaragoza hizo avanzar a las fuerzas de Berriozábal a paso veloz entre las rocas, situándolas entre la hondonada que separa a Loreto y Guadalupe. Mientras, el general Antonio Álvarez con su brigada protegió el flanco izquierdo de los reductos.

La línea de batalla mexicana formó un ángulo que se extendió desde Guadalupe hasta un sitio conocido como Plaza de Román, frente a las posiciones enemigas. Zaragoza dispuso que el general Lamadrid defendiera con las tropas potosinas y dos piezas de artillería el camino que conectaba a la ciudad con la garita de Amozoc. La derecha de la línea de batalla mexicana la cerró Porfirio Díaz con la División de Oaxaca, auxiliado por los escuadrones de Lanceros de Toluca y Oaxaca.

Los franceses continuaron su avance, colocando sus baterías frente a Guadalupe, al tiempo que devolvían el fuego mexicano proveniente de esa posición.

En ese momento los zuavos, el regimiento de élite de la infantería francesa, iniciaron su ascenso por el cerro hacia Guadalupe, perdiéndose de la vista de los fusileros mexicanos. De repente, aparecieron disparando frente a la fortificación. Sin embargo, el fuego lanzado por los mexicanos los detuvo en seco. En ese instante, los soldados de Berriozábal los recibieron con sus bayonetas, por lo que tuvieron que retirarse en buen orden hasta ponerse fuera de tiro. Se repusieron rápidamente y se lanzaron de nuevo intentando tomar el fuerte.

Los franceses apoyados por el y 2.º Regimientos de Infantería de Marina, se abalanzaron sobre el resto de la línea mexicana, siendo recibidos con la bayoneta. La columna francesa fue rechazada en Guadalupe y Loreto, siendo igualmente repelidos los ataques de otras columnas francesas desplegadas. En ese momento, el coronel mexicano José Rojo avisó a Antonio Álvarez que era tiempo de que la caballería mexicana entrara en acción para alcanzar una victoria completa. Ordenó a los Carabineros de Pachuca cargar sobre los restos de la columna, disparando sus carabinas y lanzando mandobles de sable sobre los franceses, siendo totalmente rechazados.

A las dos y media de la tarde, cuando se empezaba a perfilar una victoria para los mexicanos, Lorencez se dispuso a lanzar el último asalto, dirigiendo a los Cazadores de Vincennes y el Regimiento de Zuavos hacia Guadalupe, mientras ponía en marcha una segunda columna de ataque compuesta de los restos de los cuerpos de batalla —excepto el 99 de Línea, el cual quedó de reserva en el campamento francés—, para atacar por la derecha de la línea de batalla mexicana.

Ante esta situación, salieron a su encuentro los Zapadores de San Luis Potosí, al mando del general Lamadrid, librándose un terrible combate a la bayoneta. Una casa situada en la falda del cerro fue el objetivo. Los franceses la tomaron y se guarecieron en ella, siendo desalojados por los zapadores; la recobraron y de nuevo fueron expulsados por las tropas de Lamadrid. Un cabo mexicano de apellido Palomino se mezcló entre los zuavos y se batió con ellos cuerpo a cuerpo, posesionándose de su estandarte como botín de guerra al caer muerto el portador del mismo. Este momento significó un golpe anímico a favor de los defensores.

Ya entrada la tarde cayó un aguacero sobre el campo, lo cual dificultó el avance a las tropas francesas. Zaragoza dispuso que el Batallón Reforma de San Luis Potosí saliera en auxilio de los fuertes. En Loreto había un cañón de 68 libras que causaba enormes estragos en las filas francesas. Los zuavos hicieron una carga de infantería desesperada para apoderarse de esa pieza. El artillero mexicano, sorprendido por la rapidez de los franceses, tenía en sus manos la bala de cañón que no alcanzó a colocar en la boca de fuego. Un zuavo apareció frente a él y tras éste el resto del cuerpo que, una vez apoderados de ese fortín, levantarían la moral francesa y podría perderse la victoria conseguida. El artillero arrojó la bala al soldado francés, que herido mortalmente por el golpe en la cabeza rodó al foso del parapeto. Luego de que este asalto fue rechazado, los franceses retrocedieron siendo perseguidos por el Batallón Reforma.

Mientras, cuando la segunda columna llegó al Fuerte de Guadalupe protegida por una línea de tiradores, Porfirio Díaz acudió en auxilio de los Rifleros de San Luis Potosí, que estaban a punto de ser rodeados. Movió en columna al Batallón Guerrero, a las órdenes del coronel Jiménez y le ganó el terreno a los franceses. Para apoyar envió al resto de las tropas de Oaxaca, con los coroneles Espinoza y Loaeza a la cabeza, con lo que se logró expulsar al enemigo de las cercanías. El éxito alentó a Díaz, que destacó al Batallón Morelos con dos piezas de artillería a la izquierda, mientras por la derecha los Rifleros de San Luis Potosí se reponían de la pelea, antecedidos por una carga de los Lanceros de Oaxaca, trabándose un combate cuerpo a cuerpo que hizo retroceder a los atacantes.

En aquel momento, luego de ser repelidos por última vez, los efectivos franceses empezaron a huir, completamente dispersados. Se replegaron a la hacienda Los Álamos, para finalmente retirarse hacia Amozoc.

Mientras se libraba la batalla, en el Palacio Nacional y en Ciudad de México en general se vivía un ambiente de tensa espera. Lo último que se sabía de Puebla era el telegrama enviado por Zaragoza hacia las 12:30 del día, en el que avisaba que el fuego de artillería de ambos lados había iniciado. Luego, silencio. Ante la incertidumbre, el gobierno había hecho salir precipitadamente al general Florencio Antillón al mando de los Batallones de Guanajuato, quedando como guardianes de la capital sólo 2,000 hombres del Regimiento de Coraceros Capitalinos y algunos centenares de milicianos pobremente armados. Si las tropas guanajuatenses se perdían, la capital quedaría desprotegida.

A las 4:15 de la tarde finalmente se recibieron noticias:

Zaragoza envió más tarde otro telegrama en el que dijo que los franceses habían iniciado la retirada hacia Amozoc, pero sin mencionar el resultado final de la batalla. Finalmente, a las 5:49 de la tarde se recibió otro parte, dirigido al ministro de Guerra, que causó júbilo (y un gran alivio) en Palacio Nacional:

Dos horas después de haber sido remitido el parte anterior a la Secretaría de Guerra, el presidente de la República recibía el siguiente:

El saldo final de la batalla fue de 476 soldados perdidos y 345 heridos o enfermos del lado francés; así como 83 muertos, cerca de 132 heridos y 12 desaparecidos para el Ejército de Oriente. A las 7 de la noche del día 6 de mayo arribaron a Puebla el general Antillón y sus tropas; Zaragoza esperaba un nuevo ataque de Lorencez, pero éste, el día 8 de mayo, dispuso la retirada hasta San Agustín del Palmar, siendo "saludado" por la artillería republicana y la Banda de Guerra de los Carabineros, quienes tocaron "Escape".

El 5 de septiembre de 1862, todavía acuartelado en Puebla, el general Zaragoza contrajo tifo y falleció tres días después.Lo sustituyó en el mando del Ejército de Oriente el general Jesús González Ortega, quien se encargaría de la defensa de la ciudad ya que se esperaba el regreso de los franceses, reagrupados y con refuerzos, lo cual sucedió en marzo del siguiente año. Los historiadores concuerdan en señalar el talento de Zaragoza como organizador y motivador de sus tropas. Antes de la batalla, las arengó diciéndoles que si bien los franceses eran considerados "los primeros soldados del mundo", ellos eran "los primeros hijos de México", lo cual tuvo tal efecto en la moral de sus soldados que su determinación por defender la plaza ante los invasores compensó sus carencias materiales y de disciplina. Además, no temió tomar decisiones arriesgadas, como prescindir de los 2000 efectivos que O'Horan se llevó para batir a Leonardo Márquez, y en el curso de la batalla actuó con serenidad y efectividad. Se le considera héroe nacional y en su honor, tiempo después, Juárez renombró a la ciudad como Heroica Puebla de Zaragoza.

Cabe atribuir parte de la responsabilidad en el resultado de la batalla a Lorencez, por decidir lanzarse en primer lugar contra Loreto y Guadalupe en lugar de ir sobre la ciudad. Esta acción no carece de sentido si se toma en cuenta que el general francés se encontraba confiado en la victoria por lo que había sucedido en las Cumbres, además de que bajo la lógica militar de su tiempo, primero había que atacar al enemigo en sus posiciones más fuertes. En todo caso, ensoberbecido por la superioridad "per se" de los franceses, no contó con la férrea resistencia mexicana y cometió yerros garrafales: así, por ejemplo, fue famosa su orden de colocar sus cañones en batería a dos kilómetros y medio de las fortificaciones poblanas, lo cual fue calificado por el propio Napoleón III como un disparate ya que las balas llegaban a sus blancos, pero sin fuerza. El conde fue repatriado y lo sustituyó Frédéric Forey en el mando de las tropas expedicionarias.
Cuando en Francia se supo la derrota del ejército francés, originó dolor, histeria y llanto, más aún cuando llegaron las historias de que los indígenas zacapoaxtlas (que en realidad se trataba del sexto Batallón de Guardia Nacional del Estado de Puebla) habían atacado con machetes, arma desconocida en Europa, y se comían los cadáveres. El resto de Europa, con incredulidad, sorpresa y asombro, comentaban como el ejército francés, invicto desde la Batalla de Waterloo en 1815, había sido derrotado en México, un ejército considerado el mejor del mundo, el vencedor en la conquista de Argelia y de la Indochina francesa (hoy Vietnam), había sido derrotado por un país tropical, utilizando tácticas de guerra poco utilizada en Europa, como era la "Guerra de Guerrillas".

La guerra de guerrillas efectivamente fue utilizada en México, pero ya antes se conocía tal táctica en Europa, y más en concreto en España, lugar donde se dio por vez primera este tipo de guerra 400 años antes de Cristo, e incluso contra la invasión de las tropas de Napoleón a principios del siglo XIX, y que por tal motivo en este país se le dio tal nombre, guerra de guerrillas.

El 21 de mayo de 1862 el presidente Juárez publicó el decreto de condecoración a los vencedores de las batallas del 28 de abril en las Cumbres de Acultzingo y del 5 de mayo en Puebla, y ambas se consideraron victorias ante el ejército expedicionario francés.

El 30 de mayo se entregaron a los miembros del Ejército de Oriente los "diplomas de Concurrencia" a las mismas batallas, según lo estipulado en el artículo cuarto del mencionado decreto.

El 29 de noviembre Juárez viajó, acompañado por sus ministros de Guerra, Miguel Blanco Múzquiz, y de Relaciones Exteriores y Gobernación, Juan Antonio de la Fuente, a Puebla para una serie de ceremonias y reconocimientos a los defensores de la ciudad. Se reunió con González Ortega, y finalmente, el 4 de diciembre, en medio de una gran ceremonia en el Fuerte de Guadalupe, hizo entrega formal de las medallas a los vencedores de las batallas del 28 de abril y del 5 de mayo de ese año, y partió al día siguiente a Ciudad de México. Asimismo, el 2 de marzo de 1863, en vísperas del inicio del Sitio de Puebla, se llevó a cabo una segunda ceremonia en Guadalupe, en la que entregó más medallas.

Con excepción del Grito de Dolores, la conmemoración de la Batalla de Puebla es la fecha más significativa del calendario cívico mexicano, al tratarse de una de las escasas victorias ante un ejército extranjero invasor. Simbólicamente, representa la consecución de una gran empresa por parte de los mexicanos, que puede conseguirse si se olvidan las divisiones y se sobreponen éstas a las carencias, como lo demuestra el hecho de que se consiguió la victoria, con valor y dedicación, pese a que se tenía todo en contra: inferioridad numérica y material, la moral disminuida por la tragedia de Chalchicomula, y la simpatía de algunos sectores de las élites y de la clase política hacia los invasores. A cambio, los republicanos respondieron con celeridad a las situaciones que la batalla iba planteando (movilizaron el grueso de sus efectivos del casco urbano de Puebla hacia los fuertes) y supieron sacar ventaja de los errores de los franceses. Semanas antes de la batalla, Juárez había declarado pena de muerte para los mexicanos que se unieran a los invasores, pero también una amnistía a los enemigos de la república en la guerra de Reforma si se unían a él para defender al país de la invasión. El caso más célebre es el del general conservador Miguel Negrete, quien abandonó al partido conservador y se puso a disposición de Zaragoza con la siguiente frase: "Yo tengo patria antes que partido."

El 5 de mayo es una fecha entrañable para los mexicanos; se celebra en las principales ciudades del país con desfiles y verbenas. Ese día se le toma protesta en todo el país a los jóvenes que cumplen el Servicio Militar Nacional.

Sin embargo, el recuerdo de la batalla no se agota en el protocolo. En algunos lugares del país se realizan fiestas populares en las que se recrea la batalla misma o algunos de sus aspectos, como en el caso del Peñón de los Baños, en Ciudad de México, o en Huejotzingo, en Puebla; sitios en donde se da una peculiar fusión de elementos de carnaval con la fiesta cívica. Incluso en una celebración plenamente religiosa como son las Morismas de Bracho, en Zacatecas, que se hacen tradicionalmente el último fin de semana del mes de agosto, donde miles de personas representan combates entre moros y cristianos, aparecen participantes con uniformes tomados de la batalla de Puebla; por ejemplo, el contingente de los moros adoptó el uniforme de los zuavos franceses; asimismo, el ejército cristiano adoptó el uniforme del regimiento de zapadores, y las bandas de guerra cristianas llevan el uniforme mexicano utilizado el 5 de mayo. Ambas tropas simulan combates al son de marchas francesas.

En los Estados Unidos, el 5 de mayo es el "Día de la Herencia Latina", en la que se celebra la inmigración procedente de México. Ello ha dado pie a que se piense, erróneamente, que el aniversario de la batalla es el día de la Independencia de México.




</doc>
<doc id="6724" url="https://es.wikipedia.org/wiki?curid=6724" title="República Checa">
República Checa

La República Checa ( ), también denominada abreviadamente Chequia ("Česko" ), es un país soberano de Europa Central sin litoral. Limita con Alemania al oeste, con Austria al sur, con Eslovaquia al este y con Polonia al norte. Su capital y mayor ciudad es Praga. La República Checa tiene territorios de lo que antaño fueron Moravia y Bohemia y una pequeña parte de Silesia.

El Estado checo, antes conocido como Bohemia, se formó en el siglo como un pequeño ducado en torno a Praga en el seno del entonces poderoso Imperio de Gran Moravia. Tras la disolución de este imperio en 907, el centro de poder pasó de Moravia a Bohemia bajo la dinastía Premislidas y desde 1002 el ducado fue formalmente reconocido como parte del Sacro Imperio Romano Germánico. En 1212 el ducado alcanzó la categoría de reino y durante el gobierno de los reyes y duques Premislidas y sus sucesores, los Luxemburgo, el país alcanzó su mayor extensión territorial en los siglos y . Durante las guerras husitas el reino tuvo que sufrir embargos económicos y la llegada de caballeros cruzados de toda Europa.

Tras la batalla de Mohács en 1526, el reino de Bohemia pasó a integrarse gradualmente a los dominios de los Habsburgo como uno de sus tres dominios principales, junto al archiducado de Austria y el reino de Hungría. La derrota de los bohemios en la batalla de la Montaña Blanca, que significó el fracaso de la revuelta de 1618-1620, llevó a la guerra de los Treinta Años y a una mayor centralización de la monarquía, además de a la imposición de la fe católica y la germanización. Con la disolución del Sacro Imperio Romano Germánico en 1806, el reino de Bohemia se integró en el Imperio austríaco. Durante el siglo las tierras checas se alzaron como centro industrial de la monarquía y después como núcleo de la República de Checoslovaquia que se creó en 1918, resultado del colapso del Imperio austrohúngaro en la Primera Guerra Mundial. Después de 1933, Checoslovaquia era la única democracia de toda la Europa central y del este.

Tras los Acuerdos de Múnich en 1938, la anexión polaca del área de Zaolzie y la ocupación alemana de Checoslovaquia y la consecuente desilusión de los checos con la pobre respuesta de Occidente, los comunistas se hicieron con su favor liberando el país del yugo nazi durante la Segunda Guerra Mundial. El Partido Comunista de Checoslovaquia ganó las elecciones de 1946 y en el Golpe de Praga de 1948 el país pasó a estar gobernado por el comunismo. Sin embargo, la creciente insatisfacción del pueblo llevó a intentar la reforma del régimen, que culminó en la conocida como Primavera de Praga de 1968 y provocó la invasión de las fuerzas armadas del Pacto de Varsovia, unas tropas que permanecieron en el país hasta la Revolución de Terciopelo de 1989, cuando colapsó el régimen comunista. El 1 de enero de 1993, Checoslovaquia se dividió pacíficamente en sus dos Estados constituyentes, la República Checa y la República Eslovaca.

En 2006 la República Checa se convirtió en el primer exmiembro del Comecon en alcanzar el estatus pleno de país desarrollado según el Banco Mundial. Además, el país tiene el mayor índice de desarrollo humano de toda Europa Central y del Este y por ello está considerado un Estado con «Desarrollo humano muy alto». Es el noveno país más pacífico de Europa, el más democrático y el que registra menor de su región. La República Checa es una democracia representativa parlamentaria, miembro de la Unión Europea, la OTAN, la OCDE, la OSCE, el Consejo de Europa y el Grupo Visegrád.

La República Checa o Chequia se llama en checo "Česká republika" o "Česko", denominación que deriva del nombre de la mayor región del país, "Čechy" (Bohemia en español) o del etnónimo "checos", nombre de una de las tribus eslavas que habitaron el actual territorio del país después de la época de las migraciones y que dominó la zona hacia el 530. El origen del nombre de la tribu es desconocido. De acuerdo con una leyenda, proviene del líder Praotec Čech ("padre Checo").

El territorio checo fue unificado a finales del siglo por la dinastía de los "přemyslitas" (checo "Přemyslovci"; este nombre significa "los que piensan mucho"). El reino de Bohemia fue un poder regional significante, con el rey de Bohemia como uno de los siete electores del emperador del Sacro Imperio Romano Germánico. Las minas de oro convirtieron el reino en un poder que no tenía impuestos, y podía reclutar mercenarios casi sin límite, pues la riqueza de las minas mantuvo el poder del reino hasta su agotamiento.

Durante los quinientos años siguientes fue un reino estable, centro de cultura y educación en la Europa Central. Durante el reinado de Carlos IV de Luxemburgo (1344-1378), Bohemia vivió su época de oro (siempre auspiciado por las minas del mismo metal). Carlos IV convirtió a esta monarquía en la capital del Sacro Imperio Romano Germánico. En el año 1348 fundó la Universidad Carolina de Praga, el centro de estudios superiores más antiguo de la Europa Central.

A la muerte de Carlos IV, comienza un período de decadencia del reino e inestabilidad política. Uno de los factores fueron los conflictos religiosos, como las guerras husitas provocadas por la quema en la hoguera del reformista Jan Hus en 1415 en el Concilio de Constanza.

Después de la dinastía de los reyes polacos Jagellón, fue elegido en 1526 al trono checo el español Fernando I de Habsburgo, nieto de los Reyes Católicos e hijo de Juana I de Castilla. Con este acto, y por casi cuatrocientos años, los Habsburgo ocuparon la corona checa y, por ende, pasó a formar parte del Imperio austriaco, posteriormente Austrohúngaro.

A partir de entonces y durante los siglos , y parte del las relaciones checo-españolas recibieron un fuerte impulso, principalmente potenciado por la población católica, que veía a España como potencia protectora y garante de esta religión. La nobleza católica checa se orientó hacia España a través de enlaces matrimoniales con miembros de la corte española que había llegado a Praga con Fernando I, formada por consejeros, secretarios, embajadores y también artistas. Estas familias checo-españolas fueron el origen de lo que posteriormente se ha denominado «facción española». Esta facción española estaba formada por checos católicos procedentes de la nobleza —como las familias Pernstejn, Rozmberk, Lobkowicz y Dietrichstein, entre otras— y del clero, en el que sobresalían los jesuitas del Clementinum. La facción española era reducida en número pero muy influyente en términos políticos, económicos y culturales, y actuaron como transmisores de cultura y costumbres españolas, adquiridas como símbolos de prestigio y que traspasaron a sus descendientes. Así, la influencia española en Bohemia se mantuvo tras la muerte de Fernando I. La moda española dominó el ambiente checo durante los siglos y , especialmente bajo el reinado de Rodolfo II (1576-1612), aferrado al protocolo y vestimenta española, y aficionado al coleccionismo de objetos exóticos provenientes de la América española. En la sociedad checa lo español tendió a identificarse con el lujo y la religión católica. Los no católicos denominaban a los católicos checos «"spanihelé"» ('españoles'). Otra vía muy importante de expansión de la influencia española en Bohemia fue la actuación de las órdenes religiosas, principalmente de los jesuitas, llegados desde España en la década de 1520, antes del comienzo del reinado de Fernando I. Los jesuitas reformaron las universidades checas y mejoraron su nivel. En algunos lugares del país fue habitual que los rectores de las universidades fueran personajes españoles. Una de las figuras españolas más importantes en el ámbito académico checo fue Rodrigo de Arriaga, el filósofo jesuita más importante de su época, estudiado y citado frecuentemente por Descartes y Leibniz y por el que nació el dicho «"Videre Pragam et audire Arriagam"» ('ver Praga y escuchar a Arriaga'). Otras órdenes religiosas también influyeron decisivamente en el ambiente cultural checo, como la orden benedictina con la figura de Juan Caramuel, prior del monasterio de Emaús.

Bohemia sufrió guerras devastadoras en los siglos y , como la Guerra de los Treinta Años y la Guerra de los Siete Años durante el reinado de María Teresa en 1756-1763, pero también se benefició del impulso económico y social que vivió la monarquía durante los siglos y , que convirtieron a Bohemia en el corazón industrial de la Monarquía.

Después del colapso del Imperio austrohúngaro tras la Primera Guerra Mundial, los checos junto con sus vecinos los eslovacos y los rutenos se unieron para formar la república independiente de Checoslovaquia en 1918. Este nuevo país contenía a una gran minoría alemana, lo cual llevó a la disolución de Checoslovaquia cuando Alemania anexó a esta minoría en virtud de los Acuerdos de Múnich en 1938 y Eslovaquia declaró su independencia. El Estado checo restante fue ocupado por los alemanes en 1939.

Al finalizar la Segunda Guerra Mundial, Checoslovaquia se convirtió en un Estado socialista alineado con la Unión Soviética. En 1968, una intervención armada de las fuerzas del Pacto de Varsovia terminó con una serie de reformas impulsadas por el entonces primer ministro Alexander Dubček, conocidas como la "Primavera de Praga", tendentes según sus partidarios a crear un «"socialismo con rostro humano"». En 1989, Checoslovaquia adoptó el multipartidismo y empezó a abandonar progresivamente la economía socialista, lo que se conoce como "Revolución de Terciopelo". El 1 de enero de 1993, Checoslovaquia se dividió en dos por decisión parlamentaria. Desde entonces, la República Checa (o Chequia), por un lado, y la República Eslovaca (o Eslovaquia), por otro, son dos países independientes.

La República Checa se adhirió a la OTAN en 1999 y a la Unión Europea en 2004.

La República Checa es una democracia parlamentaria, cuya Constitución y la Carta de los Derechos y Libertades Fundamentales (parte integrante de la Carta Magna de la República Checa) fueron ratificadas el 16 de diciembre de 1992 y entraron en vigencia el primero de enero de 1993.

El derecho civil está basado en el sistema legal austrohúngaro. El sistema legal se encuentra actualmente en la etapa final de armonización con la legislación de la Unión Europea.

El presidente de la República Checa es quien ejerce las funciones de jefe de Estado. El presidente de la República era elegido en elecciones indirectas por las dos cámaras del Parlamento en sesión conjunta, hasta que en el año 2013 fue elegido por primera vez un presidente por votación directa; el mandato presidencial es de cinco años.

Su pertenencia a la Unión Europea es el eje central de la política exterior de la República Checa. La República Checa tomó la presidencia de la Unión Europea durante la primera mitad de 2009.

El Ministerio de Relaciones Exteriores de la República Checa recomienda la denominación «Chequia» (en checo "Česko") para cualquier situación excepto para documentos oficiales y desea que se siga el mismo patrón que con otros Estados, por ejemplo, la república francesa o el reino de España, usualmente conocidos como "Francia" y "España", respectivamente. Aun así, aunque en castellano el nombre corto comienza a utilizarse, el término no ha sido reconocido en forma cartográfica. El Diccionario de la lengua española que no incluye entre sus definiciones los topónimos de ningún tipo (países, regiones, ciudades, etc.) muestra la siguiente acepción del gentilicio checa: «natural de la República Checa», sin hacer mención también a "Chequia". No obstante, sí es reconocido por las Academias de la lengua a través del Diccionario panhispánico de dudas, en donde recoge que «no hay razones para censurar, en textos de carácter no oficial, el uso de la forma "Chequia", surgida por analogía con Eslovaquia».

Las Fuerzas Armadas checas se componen del Ejército de Tierra, la Fuerza Aérea y de unidades de soporte especializadas. En 2004, el servicio militar dejó de ser obligatorio y las fuerzas armadas se transformaron en un cuerpo totalmente voluntario tanto en cuanto a tierra como en cuanto a aire. El país es miembro de la OTAN desde el 12 de marzo de 1999. El gasto en defensa ronda el 1,8 % del PIB (2006).

La República Checa consta de trece regiones ("kraje" en checo) y una ciudad capital ("hlavní město"), marcada con un *:

Ubicada en Europa Central, a unos 50 grados de latitud Norte y 15 de longitud Este. Con una superficie de 78 867 km², comparable con la de Portugal, Austria o Irlanda, este estado tiene una densidad demográfica de 131 habitantes por kilómetro cuadrado.

En el interior del país aparecen planicies y mesetas ligeramente onduladas, mientras que a lo largo de la frontera, con excepción del sureste del país, se alzan cadenas montañosas que formaban históricamente la frontera natural de los llamados "Países Checos". El punto más bajo es la salida del río Elba del territorio checo, mientras que el más alto es el monte Sněžka, con 1602 metros de altitud.

El bioma dominante es el bosque templado de frondosas, aunque también está presente el bosque templado de coníferas en los Cárpatos. WWF divide el territorio de la República Checa entre cuatro ecorregiones:

La República Checa posee una economía altamente desarrollada, con un PIB per cápita de 82 % del promedio de la Unión Europea. La República Checa es además una de las más estables y prósperas economías dentro de los países del antiguo bloque soviético, con un crecimiento económico sobre el 6 % anual durante los años previos a las crisis del 2008, principalmente impulsado por las exportaciones al resto de países de la Unión Europea, en especial a Alemania, y por la demanda interna. Recientemente se ha acordado la venta de un 7 % de las acciones del productor de energía, grupo CEZ (Skupina ČEZ). Un estudio realizado en 2009 encontró que la mayoría de los economistas están a favor de continuar con la liberalización en la mayoría de los sectores de la economía.

En 2009 la República Checa tenía una población de 10 501 197 de habitantes. La esperanza de vida es de 78,7 años. El 99 % de la población está alfabetizada. El promedio de hijos por mujer es de tan solo 1,22 lo cual está provocando que su población se reduzca un 0,07 % cada año. El crecimiento de la población se ha producido principalmente, desde 2003, gracias a la inmigración.

La mayoría de sus habitantes (80 %) son oriundos del país y hablan el checo, idioma perteneciente a las lenguas eslavas, en concreto a las lenguas eslavas occidentales. Otros grupos étnicos presentes son alemanes, gitanos checos, húngaros, ucranianos, vietnamitas y polacos. Después de la división de 1993, algunos eslovacos permanecieron en territorio checo y forman el 2 % de la población actual. La frontera entre la República Checa y Eslovaquia se cerró completamente para los ciudadanos de la antigua Checoslovaquia. En 2004, la República Checa se adhirió al Acuerdo de Schengen.

En cuanto a las creencias religiosas y al escepticismo, el 62,2 % de la población es agnóstica o atea, el 34 % católica, el 2 % protestante, el 1 % husita checoslovaca, y también existe una pequeña comunidad judía (0,8 %).

La composición étnica actual es la siguiente:


La República Checa tiene una de las poblaciones más arreligiosas del mundo, siendo la tercera población más arreligiosa por detrás de China y Japón. Históricamente, los checos se han caracterizado como «tolerantes e incluso indiferentes hacia la religión». Según el censo de 2011, el 34 % de la población declaró no tener religión, el 10,4 % era católico, el 0,8 % era protestante (0,5 % Hermanos Checos y el 0,4 % husita) y el 9 % seguía otras formas de religión, tanto confesionales o no (de los cuales 863 personas respondieron que son paganas). El 45 % de la población no respondió a la pregunta sobre religión. De 1991 a 2001, y aún más para 2011, la adhesión al catolicismo disminuyó del 39 % al 27 % y luego al 10 %; el protestantismo bajó igualmente del 3,7 % al 2 % y luego al 0,8 %.

Según una encuesta del Eurobarómetro de 2010, el 16 % de los ciudadanos checos respondió que «creen que hay un Dios» (la tasa más baja entre los países de la Unión Europea), mientras que el 44 % contestó que «creen que hay algún tipo de espíritu o fuerza de la vida» y el 37 % dijo que «no creen que haya ningún tipo de espíritu, Dios o fuerza vital».

La cristianización en los siglos y introdujo el catolicismo en la región. Después de la Reforma bohemia, la mayoría de los checos se convirtieron en seguidores de Jan Hus, Petr Chelčický y otros reformadores protestantes regionales. Los taboritas y los utraquistas fueron los principales grupos husitas. Durante las guerras husitas, los utraquistas se pusieron del lado de la Iglesia católica. Después de la victoria conjunta utraquisto-católica, la Iglesia católica aceptó el utraquismo como variante bohemia del cristianismo, a diferencia de los restantes grupos de husitas, que fueron prohibidos. Después de la Reforma, algunos bohemios aceptaron las enseñanzas de Martín Lutero, especialmente los alemanes sudetes. A raíz de la Reforma, los husitas utraquistas adoptaron una postura renovada, cada vez más anticatólica, mientras que algunas de las facciones husitas derrotadas (en particular los taboritas) revivieron. Después de que los Habsburgo recobraran Bohemia, toda la población se convirtió al catolicismo por la fuerza, incluso los husitas utraquistas. Los checos se volvieron más cautelosos y pesimistas en cuanto a la religión. Siguió una larga historia de resistencia a la Iglesia católica; esta sufrió un cisma con la separación de la Iglesia neohusita checoslovaca en 1920. Perdió además la mayor parte de sus seguidores durante la época comunista y continúa, que continuó posteriormente con una secularización ininterrumpida. El protestantismo nunca se recuperó de la Contrarreforma, implantada por los Austrias a partir de 1620.

Según el censo de 2019, el 27,5 % de la población declaró que no tenía religión, el 6 % era católico, el 0,9 % era protestante (0,5 % de hermanos checos y 0,4 % de husitas), y el 4 % seguía otras formas de religión (de las cuales 863 personas respondieron que son paganas). El 61 % de la población no respondió la pregunta sobre religión. De 1991 a 2001 y hasta 2011, la adhesión al catolicismo disminuyó del 39 % al 27 % y luego al 10 % y por el último al 6 %. El protestantismo también disminuyó de 3,7 % a 2 % y luego a 0,8 % y ahora 0,4 %.

Praga es una ciudad donde la cultura y las artes brillan con especial intensidad. El cartel de actividades culturales es rico y variado. Los amantes de las artes pueden encontrar en esta ciudad un paraíso cultural. Las localidades para los diversos eventos se suelen agotar rápidamente por lo que conviene reservarlas con bastante antelación (a través de agencias de viajes y en las propias taquillas del lugar donde se celebre el acontecimiento).

La cultura de esta república es rica y variada. Doce de constan inscritos en la lista del Patrimonio de la Humanidad de la Unesco.

En la República Checa el es de 132 litros por habitante al año, el mayor del mundo.

Entre sus principales bebidas figuran Fernet, Becherovka, Sekt (vino espumoso) y, por supuesto, la cerveza de Pilsen conocida mundialmente como Pils o Pilsner.

Los deportes más populares son el hockey sobre hielo (en el que los checos se han proclamado campeones mundiales y olímpicos en diversas ocasiones) y el fútbol (con dos subtítulos mundiales y un subcampeonato de Europa en 1996). La ya desaparecida Checoslovaquia obtuvo un título olímpico (Moscú 1980) y un campeonato de Europa en 1976.

En tenis el país ha dado muchos jugadores de primer nivel mundial, como Ivan Lendl (nacionalizado estadounidense durante la recta final de su carrera), Karel Novacek, Petr Korda, Radek Stepanek o Tomas Berdych, quien ganó la Copa Davis tanto como Checoslovaquia como ya República Checa. Aparte, tenistas nacidos en otros países como Richard Krajicek o Vasek Pospisil tienen orígenes checos. Martina Navratilova, nacionalizada estadounidense pero que empezó su carrera compitiendo como checoslovaca, Hana Mandlikova, Helena Sukova, Jana Novotna, Petra Kvitova y Karolína Plíšková son las tenistas más destacadas que ha dado el país.

También hay muchos atletas checos destacados en lanzamiento de jabalina, como los plusmarquistas mundiales Jan Železný y Barbora Špotáková y otros lanzadores de marcada trayectoria como Jakub Vadlejch, Petr Frydrych o Vítězslav Veselý.

La República Checa casi ha monopolizado el decatlón en las últimas olimpiadas, con Roman Šebrle como poseedor de la plusmarca mundial.

Otros deportes donde destaca son el baloncesto femenino o el balonmano, entre otros.




</doc>
<doc id="6727" url="https://es.wikipedia.org/wiki?curid=6727" title="6 de julio">
6 de julio

El 6 de julio es el 187.º (centésimo octogésimo séptimo) día del año en el calendario gregoriano y el 188.º en los años bisiestos. Quedan 178 días para finalizar el año.






El 6 de julio es el Día del Beso Robado, que se festeja en el Reino Unido y es una celebración que es similar a la del Día Internacional del Beso, el 13 de abril.




</doc>
<doc id="6733" url="https://es.wikipedia.org/wiki?curid=6733" title="Cerio">
Cerio

El cerio es un elemento químico de símbolo Ce y número atómico 58. Es uno de los 14 elementos químicos que siguen al lantano en la tabla periódica, denominados por ello lantánidos. El cerio está situado entre el lantano y el praseodimio.

Es un metal blando, de color gris metálico similar al hierro, dúctil, que se oxida fácilmente al contacto con el aire y se torna pardo rojizo. El cerio es el más abundante de los elementos de las tierras raras, su abundancia representa solo el 0,0046% en peso de la corteza terrestre, donde aparece disperso en diversos minerales, como la cerita, bastnasita y monacita. Existen numerosas aplicaciones comerciales del cerio. Entre estos usos se incluyen catalizadores, aditivos para el combustible para reducir la contaminación ambiental y a los vidrios y esmaltes para cambiar sus colores. El óxido de cerio es un componente importante de los polvos utilizados para pulir vidrios y fósforos utilizados en pantallas y lámparas fluorescentes. Es utilizado también en la "piedra" o "yesca" de los encendedores (aleación ferrocerio).

Fue descubierto en 1803 por Martin Heinrich Klaproth y Jöns Jacob Berzelius y de manera independiente también por Wilhelm von Hisinger. El elemento fue nombrado en honor al planeta enano Ceres, descubierto dos años antes. El planeta lleva el nombre de la diosa romana Ceres (mitología).

Fue descubierto en 1803 por Martin Heinrich Klaproth y Jöns Jacob Berzelius y de manera independiente también por Wilhelm von Hisinger. Tomó su nombre de Ceres, el planeta enano/asteroide que se había encontrado años antes, concretamente en 1801 (que a su vez fue denominado así en honor a la diosa romana de la agricultura).

Es el lantánido más abundante y económico. El metal es duro y de color gris acerado, tornándose pardo rojizo. Es buen conductor del calor y la electricidad. Reacciona con los ácidos diluidos y con el agua (produciendo hidrógeno). Es inestable en el aire seco, cubriéndose de una capa de óxido en el aire húmedo.

En la Tierra el cerio es casi tan abundante como el cobre; especialmente en forma de óxido de cerio, que habitualmente se utiliza como polvos abrasivos para pulir vidrio. El metal cerio es pirofórico, lo que significa que se inflama fácilmente. El cerio no realiza ninguna función biológica conocida.

El elemento natural está constituido de los isótopos Ce, Ce, Ce y Ce. El Ce es prácticamente estable con una vida media de 5 x 10 años. El cerio se encuentra mezclado con otras tierras raras en muchos minerales, en particular en monacita y bastnasita y también se halla entre los productos de la fisión de uranio, torio y plutonio.


Las principales menas de cerio son la cerita, la bastnasita y la monacita.

El óxido de cerio es un abrasivo que puede encontrarse en algunos ambientes de trabajo, donde constituye un riesgo al ser inhalado en forma de partículas finas. La exposición prolongada puede provocar embolias pulmonares. El cerio, al igual que otros lantánidos, puede sustituir al calcio en algunos procesos metabólicos. Sin embargo, su absorción por vía oral es muy baja y no constituye un peligro inmediato. El cloruro de cerio administrado por vía intravenosa puede inducir fallo cardiovascular y hepático.

El cerio es vertido al medio ambiente en muchos lugares diferentes, principalmente por industrias productoras de petróleo. También puede entrar en el medio ambiente cuando se tiran los equipos domésticos. El cerio se acumula gradualmente en los suelos y en el agua de los suelos y esto lleva finalmente a incrementar su concentración en humanos, animales y partículas del suelo. 
En los animales acuáticos provoca daños a las membranas celulares, lo que tiene varias influencias negativas en la reproducción y en las funciones del sistema nervioso.

En "El Sistema Periódico", el escritor y químico de profesión Primo Levi dedica el capítulo "Cerio" a su estadía en el campo de concentración de Auschwitz, donde sobrevivió gracias al intercambio de pequeñas varillas de ferrocerio por comida. 


</doc>
<doc id="6734" url="https://es.wikipedia.org/wiki?curid=6734" title="Lenguas de Argentina">
Lenguas de Argentina

El uso del idioma español es predominante, entendido y hablado como primera o segunda lengua por casi toda la población de la Argentina, que según las últimas estimaciones supera los 40 millones de habitantes Es el único idioma de uso en la administración pública a nivel nacional, sin que ninguna norma legal lo haya declarado como oficial. De todos los países del mundo donde el español o castellano tiene estatus predominante, la Argentina es el de mayor extensión territorial. La amplitud del país, la existencia de distintos sustratos lingüísticos producidos por la variedad de lenguas amerindias y las diferentes aportaciones de las lenguas vernáculas de los inmigrantes europeos de finales del siglo XIX y comienzos del XX, han dado lugar a varias modalidades dialectales diferentes.

El inglés es la segunda lengua más conocida en el país, y su enseñanza es obligatoria desde la escuela primaria en varias provincias. Argentina es el único país latinoamericano calificado como país de «alta aptitud» en el inglés, ubicándose en el puesto 15 a nivel mundial en el año 2015, según un informe del Índice de Aptitud en Inglés (EF EPI). En el 2017, Argentina descendió diez puestos con respecto a su mejor posición y se ubicó en el puesto 25, aunque aún continúa siendo el país con mejor dominio del inglés en Iberoamérica.

El guaraní y el quechua tienen más de un millón de hablantes en todo el Nordeste y, especialmente, en el interior de la provincia de Corrientes, que en 2004 declaró la cooficialidad del idioma guaraní para la enseñanza y los actos de gobierno, aunque no se encuentra reglamentada. El quechua cuenta con un llamativo número de hablantes en la provincia de Santiago del Estero, donde se habla un dialecto muy diferenciado denominado quichua y también en zonas de la provincia de Jujuy donde se usa una variedad de este idioma más similar a la que se habla en el suroeste de Bolivia. En la periferia de las grandes aglomeraciones urbanas, producto de constantes migraciones del noreste argentino, de Paraguay, Bolivia y Perú, hay hablantes del guaraní, quechua y aimara.

Las lenguas indoamericanas vernáculas vivas son el mocoví, pilagá, mataco (o wichí) y toba (qom), del grupo mataco guaycurú, el guaraní que llegó al actual territorio argentino hacia los siglos XIV y XV y luego fue propagado por los misioneros europeos jesuitas como lengua vehicular entre diversas etnias del Noreste y el Litoral y el quechua (junto con el aimara) que llegaron con la expansión de los estados andinos, en especial tras la conquista inca en el siglo XV y fueron usados como lengua vehicular para la catequesis en Cuyo y el Noroeste a partir de la Conquista española en el siglo XVI. La provincia del Chaco estableció por ley 6.604 de 2010 (reglamentada por Decreto 257/2010) la cooficialidad de los idiomas qom, wichí y mocoví.

El mapudungun, lengua de los mapuches, también se considera vernácula pues hay testimonios etnohistóricos de su presencia al este de la Cordillera de los Andes desde el siglo XV. Hoy cuenta con hablantes en las provincias de la Patagonia, reflejando la larga y fuerte influencia de los mapuches, o araucanización, sobre los nativos argentinos de las áreas patagónicas y la llanura pampeana.

Otra lengua nativa es la lengua de señas argentina (LSA), lengua señalada por las comunidades sordas que surge claramente a partir de 1885 e influencia a muchas otras lenguas de señas de países limítrofes.

Diversas comunidades de inmigrantes e hijos de inmigrantes todavía mantienen las lenguas de su región de origen, aunque este uso se pierde a medida que avanzan las generaciones. Entre las "lenguas no vernáculas" están el italiano (incluyendo las lenguas regionales de Italia y los dialectos del italiano), alemán (incluyendo el dialecto alemán del Volga y el plautdietsch), árabe, el francés, el portugués, el ruso, euskera, gallego, catalán, asturiano, yidish en las comunidades judías argentinas, galés en Chubut, polaco, chino mandarín (principalmente de los dialectos de Fujian y de Taiwán), coreano, japonés (en su mayoría hablantes de okinawense), rumano, occitano, lituano, letón, estonio, ucraniano, bielorruso, croata, esloveno, checo, eslovaco, finés, sueco, danés, noruego, islandés, irlandés, neerlandés, polaco, húngaro, serbio, bosnio, albanés, griego, macedonio, búlgaro, hebreo, turco, armenio y romaní vlax. Todas ellas con muy pocos hablantes y, salvo excepciones como el chino y el plautdietsch, usados solamente en el ámbito familiar o en encuentros culturales.

La República Argentina no ha establecido por norma legal ningún idioma oficial; con todo, el idioma castellano es el utilizado (desde la fundación del Estado argentino) por la administración de la república y en el que se imparte la educación en todos los establecimientos públicos, hasta tal punto que en los niveles básico y secundario existe como asignatura obligatoria la de la lengua castellana (asignatura llamada «Lengua» o «Prácticas del Lenguaje»). Tal obligatoriedad es una imposición que ha resultado en un factor de cohesión social entre los millones de habitantes de Argentina. Existe una Academia Argentina de Letras, fundada en 1931, que desde 1952 colabora regularmente con la Real Academia Española para el registro de las variantes locales.

Aunque la Constitución Nacional establece como competencia del Congreso Nacional «reconocer la preexistencia étnica y cultural de los pueblos indígenas argentinos», a éstos aún no se les ha reconocido la oficialidad de sus lenguas nativas, excepto en las provincias de Chaco y Corrientes.

El idioma castellano en Argentina se presenta principalmente a través del dialecto rioplatense. También existen otros dialectos como el dialecto cuyano y el dialecto cordobés. En el noroeste del país se habla un español con grandes influencias del español andino y en el nordeste argentino el español de esta región tiene grandes influencias del español paraguayo.

Para Francisco Moreno Fernández todos los dialectos y variantes del español en la Argentina se engloban dentro de un macrodialecto que denomina "español austral", que también abarca las hablas del castellano en Uruguay y Paraguay.

El dialecto rioplatense es el dialecto de prestigio en todo el territorio y el más reconocido como variante argentina fuera del país; está fuertemente influido por el italiano y presenta la particularidad de ser voseante incluso en los registros más formales de la lengua.

La región patagónica ―poblada mayoritariamente por inmigrantes provenientes de la región central del país― adoptó también el uso de esta variante, con ligeras variantes fonológicas, probablemente por influjo de la inmigración chilena del siglo XX.

En el noroeste del país, por un lado y en el Nordeste argentino, por otro, la influencia del cacán, del quechua y del guaraní, respectivamente, ha dado origen a dialectos algo distintos, que a su vez presentan variaciones subdialectales regionales.

En las provincias de San Juan, Mendoza y menor proporción en las provincias de San Luis y La Rioja, se da la intersección entre vestigios del español chileno y el rioplatense, presentándose modismos y pronunciación similar a la chilena, donde se pronuncia «ll» e «y» como [ʝ] y se asibilan las erres, en /rr /> [řř] (sonoramente) y /r/ inicial > [ř], y en casos cultos o semicultos, a [rr] debilitadas o normales.

Cuyo, por su antigua dependencia y vecindad geográfica con Chile, posee un limitado número de voces que señala esos contactos; también se incorporaron voces mapuches en el caudal de los chilenismos. Hay zonas de Cuyo que denotan mayor cercanía a Chile (Malargüe, Calingasta), otras más influidas desde el Río de la Plata, sea en la entonación o en algunas pronunciaciones. Esta influencia se remonta al lunfardo porteño, que cabalgando en el flujo cultural rioplatense, asentó en la sociedad cuyana improntas más seguras, desde las clases altas (por los estudiantes y el tango) y que luego se perpetra hasta hoy con los medios de comunicación. Son manifestaciones que integran los capítulos de una dialectología regional, pero de ninguna manera la gramática.

En el noroeste argentino, el español andino se fusiona con el dialecto de rioplatense. La provincia de Córdoba y en especial su capital provincial, posee una curva de la entonación singular, distintiva primera oída.

Otros rasgos significativos del español hablado en la Argentina, aparte de los lexicales (en los que abundan italianismos, , guaranismos y araucanismos), son el yeísmo con "rehilamiento" y el uso de vocablos del guaraní como en la expresión che. El yeísmo con rehilamiento, pronunciación de la "ll" y de la "y" como una fricativa postalveolar, se encuentra muy extendido en el habla culta, con la excepción más notable del Nordeste argentino.

En algunas zonas limítrofes con el Brasil, es habitual el uso del portuñol, hibridación del español de la Argentina con el portugués de Brasil, dado sobre todo en la provincia de Misiones y en menor medida en Corrientes y Entre Ríos.

Algunas jergas se han extendido tanto que han merecido tratamientos especiales, como el lunfardo y el rosarigasino. El primero se halla muy difundido por su uso en las letras del tango, pero ha perdido buena parte de su influencia en el habla corriente, por el cambio generacional.

Las lenguas indoeuropeas de Argentina habladas por comunidades estables pertenecen a cinco ramas: romance (español y portugués), germánico occidental ("plautdietsch" y alemán estándar), celta britónico (galés) e indoario central (romaní).

Las lenguas indígenas de Argentina por otra parte son más diversas y pertenecen a diferentes familias lingüísticas entre ellas:

(†): extintos

Además del español, se registran en Argentina las siguientes lenguas vivas con desarrollo local propio:


La lengua de señas argentina, entendida por alrededor de dos millones de personas sordas de la Argentina, sus instructores, descendientes y otros. Se diferencian variantes regionales, tales como la de Córdoba.

El quechua sureño: de la familia de lenguas quechuas. Presenta 7 variaciones que se enmarcan en su origen geográfico. Aquí se detallan el sudboliviano y la lengua quichua santiagueña:


En las provincias de Corrientes, Misiones, Chaco, Formosa, Entre Ríos, la Ciudad Autónoma de Buenos Aires y la Provincia de Buenos Aires donde los dialectos del idioma guaraní argentinos son hablados o conocidos por cerca de un millón de personas, incluyendo inmigrantes paraguayos que hablan el guaraní paraguayo o el jopará (2005). En Corrientes, en donde se habla el dialecto guaraní argentino se decretó en 2004 la cooficialidad de la lengua guaraní y su uso obligatorio en la enseñanza y gobierno.


El mapudungun, araucano, mapuchedungun, chedungun, mapuche o mapudungu, dialectos: pehuenche, nguluche, huilliche, ranquelche: una lengua aislada con aproximadamente 40 000 a 100 000 hablantes en las provincias de Neuquén, Río Negro, Chubut y Santa Cruz en el año 2000.

Aimara central: lengua del grupo aimara, hablada por 30 000 habitantes de Jujuy, del norte de Salta, además de inmigrantes de la puna boliviana y de Perú.

Del grupo mataco o mataguayo:


Del grupo guaicurú:



Además de las lenguas indígenas sobrevivientes, antes del contacto con los europeos y durante algún tiempo durante la conquista de América en Argentina se hablaron además las siguientes lenguas, que la actualidad están extintas:





</doc>
<doc id="6748" url="https://es.wikipedia.org/wiki?curid=6748" title="Símbolos de Almería">
Símbolos de Almería


Su origen está en el año 1147, cuando el ejército genovés aliado de Alfonso VII desembarcó en la playa de los Genoveses de cabo de Gata para participar en la conquista de Almería. La ciudad adoptó como símbolo propio la enseña genovesa, que se corresponde con la cruz de San Jorge (cruz griega en gules sobre campo de plata).

La bandera oficial quedó descrita de la siguiente manera por decreto de la Consejería de Gobernación y Justicia de la Junta de Andalucía en 1997:


El escudo de la ciudad de Almería fue inscrito en el Registro Andaluz de Entidades Locales por resolución de la Consejería de Gobernación y Justicia de la Junta de Andalucía el 25 de enero de 2005. En el texto oficial referido se formula una descripción que no se corresponde con las reglas del blasón y se atribuye una correspondencia dudosa a alguna de las armerías representadas:
La inclusión del emblema del águila y su atribución son controvertidas y hay versiones diferentes sobre si se corresponde o no con el sello de Sancho VII el Fuerte, de origen navarro. atribuye en 1860 el siguiente blasón: «Las armas de la provincia y de la ciudad de Almería están cuarteladas por una cruz llana de gules y bordura de castillos, leones y granadas alternadas.» Durante el franquismo, fueron editados por Correos una serie de sellos en los que aparecen las cadenas, emblema moderno del reino de Navarra.


Oficialmente, el himno de Almería es el aprobado por el ayuntamiento de la ciudad el 21 de agosto de 1916, con letra del poeta Antonio Ledesma y música de Manuel García Martínez, maestro de capilla de la catedral. Sin embargo, el himno que hoy día suele interpretarse es un poema de José María Álvarez de Sotomayor llamado "Almería", musicado por el compositor José Padilla y adoptado por el ayuntamiento de Almería en 1946.El poema estaba dedicado a toda la provincia, aunque oficialmente el himno es oficial sólo para su capital. Asimismo, puede considerarse himno oficioso de la capital el popular "Fandanguillo de Almería", obra del compositor Gaspar Vivas, que puede escucharse en el carrillón del ayuntamiento de la ciudad.


El símbolo por excelencia de Almería y su provincia es el indalo, originalmente una pintura rupestre neolítica descubierta en la cueva de los Letreros (en el actual parque natural de Sierra de María-Los Vélez) en 1868 que representa a un hombre cazando con arco. 

En los años 1940, el Movimiento Indaliano idealizó el símbolo, queriendo ver en él un hombre que sostenía al arco iris. Su nombre se le habría dado en honor a San Indalecio y provendría en última instancia del ibero "indal eccius", «mensajero de los Dioses».

La tradición popular, no obstante, lo veneraba como símbolo benefactor desde siglos atrás. Solía verse pintado sobre las paredes de las casas para protegerse del rayo y el mal de ojo en poblaciones como Mojácar, cuyos artesanos estilizaron la figura durante el "boom" turístico de los años 60, convirtiéndolo en símbolo primero de dicha localidad y después de toda la provincia. 

Se trata de un símbolo muy arraigado en la sociedad almeriense y es frecuente verlo por doquier. Encontramos uno, por ejemplo, en el escudo de la Unión Deportiva Almería.


Otro símbolo muy unido a la ciudad es el erróneamente llamado sol de Portocarrero, altorrelieve que representa un sol antropomorfo rodeado de guirnaldas y que aparece esculpido en el testero de la capilla funeraria del obispo Diego Fernández de Villalán, en la catedral de Almería, levantada durante en siglo XVI. Por confusión histórica, se ha relacionado tradicionalmente este símbolo con otro obispo de la diócesis almeriense, Juan del Castillo y Portocarrero, del que toma nombre a pesar de ser el mandato de éste muy posterior.
El escudo de la Universidad de Almería, por ejemplo, está basado en este símbolo.

La patrona de la ciudad es la Virgen del Mar, que celebra su festividad el sábado anterior al último domingo de agosto. Su imagen fue encontrada en la playa de Torregarcía, cercana a la capital, por el vigía de la torre homónima, Andrés de Jaén, el 21 de diciembre de 1502. La leyenda dice que la imagen, gótica, pudo formar parte de los enseres de un barco naufragado, o ser un mascarón de proa que los fieles habrían vestido como Virgen. Muy cerca de la torre se construyó a principios del siglo XX la ermita de la Virgen del Mar, en torno a la cual se celebra una romería el segundo fin de semana de cada enero.

El patrón de la ciudad y diócesis de Almería es San Indalecio, fundador de la diócesis de la antigua Urci en el siglo I y uno de los siete Varones Apostólicos, primeros evangelizadores de la península ibérica por encomienda de San Pablo. Su festividad se celebra el 15 de mayo.


</doc>
<doc id="6757" url="https://es.wikipedia.org/wiki?curid=6757" title="Programación extrema">
Programación extrema

Extrema o eXtreme Programming (en adelante, XP) es una metodología de desarrollo de la ingeniería de software formulada por Kent Beck, autor del primer libro sobre la materia, "Extreme Programming Explained: Embrace Change" (1999). Es el más destacado de los procesos ágiles de desarrollo de software. 

Al igual que estos, la programación extrema se diferencia de las metodologías tradicionales principalmente en que pone más énfasis en la adaptabilidad que en la previsibilidad. Los defensores de la XP consideran que los cambios de requisitos sobre la marcha son un aspecto natural, inevitable e incluso deseable del desarrollo de proyectos. Creen que ser capaz de adaptarse a los cambios de requisitos en cualquier punto de la vida del proyecto es una aproximación mejor y más realista que intentar definir todos los requisitos al comienzo del proyecto e invertir esfuerzos después en controlar los cambios en los requisitos.

Se puede considerar la programación extrema como la adopción de las mejores metodologías de desarrollo de acuerdo a lo que se pretende llevar a cabo con el proyecto, y aplicarlo de manera dinámica durante el ciclo de vida del software.

Los valores originales de la programación extrema son: simplicidad, comunicación, retroalimentación ("feedback") y coraje. Un quinto valor, respeto, fue añadido en la segunda edición de "Extreme Programming Explained". Los cinco valores se detallan a continuación:

La simplicidad es la base de la programación extrema. Se simplifica el diseño para agilizar el desarrollo y facilitar el mantenimiento. Un diseño complejo del código junto a sucesivas modificaciones por parte de diferentes desarrolladores hacen que la complejidad aumente exponencialmente.

Para mantener la simplicidad es necesaria la refactorización del código, ésta es la manera de mantener el código simple a medida que crece.

También se aplica la simplicidad en la documentación, de esta manera el código debe comentarse en su justa medida, intentando eso sí que el código esté autodocumentado. Para ello se deben elegir adecuadamente los nombres de las variables, métodos y clases. Los nombres largos no decrementan la eficiencia del código ni el tiempo de desarrollo gracias a las herramientas de autocompletado y refactorización que existen actualmente.

Aplicando la simplicidad junto con la autoría colectiva del código y la programación por parejas se asegura que cuanto más grande se haga el proyecto, todo el equipo conocerá más y mejor el sistema completo.

La comunicación se realiza de diferentes formas. Para los programadores el código comunica mejor cuanto más simple sea. Si el código es complejo hay que esforzarse para hacerlo inteligible. El código autodocumentado es más fiable que los comentarios ya que estos últimos pronto quedan desfasados con el código a medida que es modificado. Debe comentarse sólo aquello que no va a variar, por ejemplo el objetivo de una clase o la funcionalidad de un método.

Las pruebas unitarias son otra forma de comunicación ya que describen el diseño de las clases y los métodos al mostrar ejemplos concretos de como utilizar su funcionalidad.
Los programadores se comunican constantemente gracias a la programación por parejas.
La comunicación con el cliente es fluida ya que el cliente forma parte del equipo de desarrollo. El cliente decide qué características tienen prioridad y siempre debe estar disponible para solucionar dudas.

Al estar el cliente integrado en el proyecto, su opinión sobre el estado del proyecto se conoce en tiempo real.

Al realizarse ciclos muy cortos tras los cuales se muestran resultados, se minimiza el tener que rehacer partes que no cumplen con los requisitos y ayuda a los programadores a centrarse en lo que es más importante.

Considérense los problemas que derivan de tener ciclos muy largos. Meses de trabajo pueden tirarse por la borda debido a cambios en los criterios del cliente o malentendidos por parte del equipo de desarrollo.
El código también es una fuente de retroalimentación gracias a las herramientas de desarrollo. Por ejemplo, las pruebas unitarias informan sobre el estado de salud del código. Ejecutar las pruebas unitarias frecuentemente permite descubrir fallos debidos a cambios recientes en el código.

Muchas de las prácticas implican valentía. Una de ellas es siempre diseñar y programar para hoy y no para mañana. Esto es un esfuerzo para evitar empantanarse en el diseño y requerir demasiado tiempo y trabajo para implementar el resto del proyecto. La valentía le permite a los desarrolladores que se sientan cómodos con reconstruir su código cuando sea necesario. Esto significa revisar el sistema existente y modificarlo si con ello los cambios futuros se implementarán más fácilmente. Otro ejemplo de valentía es saber cuando desechar un código: valentía para quitar código fuente obsoleto, sin importar cuanto esfuerzo y tiempo se invirtió en crear ese código. Además, valentía significa persistencia: un programador puede permanecer sin avanzar en un problema complejo por un día entero, y luego lo resolverá rápidamente al día siguiente, sólo si es persistente.

El respeto se manifiesta de varias formas. Los miembros del equipo se respetan los unos a otros, porque los programadores no pueden realizar cambios que hacen que las pruebas existentes fallen o que demore el trabajo de sus compañeros. Los miembros respetan su trabajo porque siempre están luchando por la alta calidad en el producto y buscando el diseño óptimo o más eficiente para la solución a través de la refactorización del código. Los miembros del equipo respetan el trabajo del resto no haciendo menos a otros, una mejor autoestima en el equipo eleva su ritmo de producción.

Las características fundamentales del método son:









La simplicidad y la comunicación son extraordinariamente complementarias. Con más comunicación resulta más fácil identificar qué se debe y qué no se debe hacer. Cuanto más simple es el sistema, menos tendrá que comunicar sobre éste, lo que lleva a una comunicación más completa, especialmente si se puede reducir el equipo de programadores.

Produce el código del sistema. Es la esencia del equipo.

Produce el código de los test unitarios del sistema. Es uno de los roles más importantes.

Escribe las historias de usuario y las pruebas funcionales para validar su implementación. Asigna la prioridad a las historias de usuario y decide cuáles se implementan en cada iteración centrándose en aportar el mayor valor de negocio.

Interpreta el pedido del cliente y ayuda al equipo de desarrollo a escribir las pruebas funcionales. Ejecuta pruebas regularmente, difunde los resultados en el equipo y es responsable de las herramientas de soporte para pruebas.

Es el encargado de seguimiento. Proporciona realimentación al equipo. Debe verificar el grado de acierto entre las estimaciones realizadas y el tiempo real dedicado, comunicando los resultados para mejorar futuras estimaciones.

Responsable del proceso global. Guía a los miembros del equipo para seguir el proceso correctamente.

Es un miembro externo del equipo con un conocimiento específico en algún tema necesario para el proyecto. Ayuda al equipo a resolver un problema específico.
Además este tiene que investigar según los requerimientos.

Es el dueño de la tienda y el vínculo entre clientes y programadores. Su labor esencial es la coordinación.




</doc>
<doc id="6761" url="https://es.wikipedia.org/wiki?curid=6761" title="Harry Markowitz">
Harry Markowitz

Harry Max Markowitz, (Chicago, 24 de agosto de 1927) es un economista estadounidense. 

Fue laureado con el Premio del Banco de Suecia en Ciencias Económicas en memoria de Alfred Nobel en 1990.

Harry Markowitz nació en el seno de una familia judía, hijo de Morris y Mildred Markowitz. Durante la escuela secundaria, Markowitz desarrolló interés por la física y la filosofía, en particular las ideas de David Hume, un interés que siguió durante sus años de estudiante en la Universidad de Chicago. Después de recibir su B.A., Markowitz decidió continuar sus estudios en la Universidad de Chicago, eligiendo especializarse en economía. Allí tuvo la oportunidad de estudiar con importantes economistas, entre ellos Milton Friedman, Tjalling Koopmans, Jacob Marschak y Leonard Savage. Cuando aún era estudiante, fue invitado a convertirse en miembro de la Comisión Cowles de Investigación en Economía, que se encontraba en Chicago en ese momento.

Markowitz eligió aplicar las matemáticas al análisis del mercado bursátil como tema de su disertación. Jacob Marschak, que era el asesor de tesis, lo alentó a seguir con el tema, señalando que también había sido un interés favorito de Alfred Cowles, el fundador de la Comisión Cowles. Mientras investigaba la comprensión actual de los precios de las acciones, que en ese momento consistía en el modelo de valor presente de John Burr Williams, Markowitz se dio cuenta de que la teoría carece de un análisis del impacto del riesgo. Esta idea condujo al desarrollo de su teoría fundamental de la asignación de carteras bajo incertidumbre, publicada en 1952 por el Journal of Finance.

En 1952, Harry Markowitz fue a trabajar para la Corporación RAND, donde conoció a George Dantzig. Con la ayuda de Dantzig, Markowitz continuó investigando técnicas de optimización, desarrollando aún más el algoritmo de línea crítica para la identificación de las carteras óptimas de varianza media, confiando en lo que más tarde se denominó la frontera de Markowitz. En 1955, recibió un doctorado de la Universidad de Chicago con una tesis sobre la teoría de la cartera. El tema era tan novedoso que, mientras Markowitz defendía su disertación, Milton Friedman argumentó que su contribución no era económica. Durante 1955-1956 Markowitz pasó un año en la Fundación Cowles, que se había mudado a la Universidad de Yale, por invitación de James Tobin. Publicó el algoritmo de línea crítica en un documento de 1956 y usó su estancia en la fundación para escribir un libro sobre asignación de cartera que se publicó en 1959.

En el año 1989 recibió el Premio de Teoría John von Neumann de la Sociedad de Investigación de Operaciones de América (ahora Instituto de Investigación de Operaciones y Ciencias de la Gestión, INFORMS) por sus contribuciones en la teoría de tres campos: teoría de la cartera; métodos de matriz dispersa; y programación del lenguaje de simulación (SIMSCRIPT). Los métodos de matriz dispersa se usan ahora ampliamente para resolver sistemas muy grandes de ecuaciones simultáneas cuyos coeficientes son en su mayoría cero. SIMSCRIPT se ha utilizado ampliamente para programar simulaciones por computadora de fabricación, transporte y sistemas informáticos, así como juegos de guerra. SIMSCRIPT (I) incluyó el método de asignación de memoria Buddy, que también fue desarrollado por Markowitz.

Markowitz ganó el Premio Nobel Memorial en Ciencias Económicas en 1990 mientras era profesor de finanzas en el Baruch College de la City University de Nueva York. Aunque el tema de las finanzas empresariales ya había sido tratado por otros dos laureados, James Tobin (1981) y Franco Modigliani (1985), el Premio del Banco de Suecia en Ciencias Económicas en memoria de Alfred Nobel de 1990 sorprendió a los economistas estudiosos de la teoría económica "pura".
Aunque Markowitz, Miller y Sharpe —los tres premiados— eran ampliamente respetados en los ambientes académicos, no se esperaba que su trabajo —notoriamente puntual, dada la amplitud de la ciencia económica— fuese premiado; esto resulta evidente si se analizan los trabajos de los economistas previamente galardonados.

Habría una explicación concreta para que el premio haya sido concedido a la economía financiera (son expresidentes de la Sociedad Estadounidense de Finanzas): el hecho de que los servicios financieros sean actualmente muy importantes en los países desarrollados y que los mercados bursátiles cubran amplios segmentos de ahorristas, lo que es indudablemente un fenómeno nuevo en la década de los años 1980.

La compañía que se convertiría en CACI International fue fundada por Herb Karr y Harry Markowitz el 17 de julio de 1962 como California Analysis Center, Inc. Ellos ayudaron a desarrollar SIMSCRIPT, el primer lenguaje de programación de simulación, en RAND y después de su lanzamiento al dominio público, fue fundada CACI para proporcionar soporte y capacitación para SIMSCRIPT.

En 1968, Markowitz se unió a la compañía Arbitrage Management fundada por Michael Goodkin. Al trabajar con Paul Samuelson y Robert Merton, creó un fondo de cobertura que representa el primer intento conocido de negociación de arbitraje computarizado. Asumió el cargo de director ejecutivo en 1970. Después de una exitosa carrera como fondo privado de cobertura, AMC fue vendida a Stuart & Co. en 1971. Un año después, Markowitz dejó la compañía. 

Markowitz ahora divide su tiempo entre la enseñanza (es profesor adjunto en la Rady School of Management de la Universidad de California en San Diego, UCSD); da conferencias de vídeo; y hace consultoría (desde sus oficinas de Harry Markowitz Company). Actualmente es miembro del Consejo Asesor de BPV Capital Management (anteriormente SkyView Investment Advisors), una firma de asesoría de inversiones alternativa y un fondo de fondos de cobertura. Markowitz también es miembro del Comité de Inversiones de LWI Financial Inc. ("Loring Ward"), un asesor de inversiones con sede en San José, California; en el panel asesor de la firma de gestión de inversiones de Robert D. Arnott en Newport Beach, California, Research Affiliates; en el Consejo Asesor de Mark Hebner's Irvine, California y en la firma consultora de inversiones basada en Internet, Index Fund Advisors; y como asesor del Comité de Inversiones de 1st Global, una firma de asesoría de inversiones y gestión de patrimonio con sede en Dallas, Texas. Markowitz asesora y forma parte de la junta directiva de ProbabilityManagement.org, una organización sin fines de lucro 501 (c) fundada por el Dr. Sam L. Savage para remodelar la comunicación y el cálculo de la incertidumbre.


Harry Markowitz presentó este modelo en 1952. Consiste en la selección de la cartera de inversiones más eficiente al analizar varias carteras posibles de valores dados. Al elegir valores que no se "mueven" exactamente juntos, el modelo HM muestra a los inversores cómo reducir su riesgo. El modelo HM también se denomina modelo de media varianza debido a que se basa en los rendimientos esperados (media) y la desviación estándar (varianza) de las diversas carteras. Harry Markowitz hizo las siguientes suposiciones al desarrollar el modelo HM:

1. El riesgo de una cartera se basa en la variabilidad de los rendimientos de dicha cartera.

2. Un inversor es reacio al riesgo.

3. Un inversor prefiere aumentar el consumo.

4. La función de utilidad del inversor es convexa y creciente, debido a su aversión al riesgo y preferencia de consumo.

5. El análisis se basa en un modelo de inversión de un solo período.

6. Un inversor maximiza el rendimiento de su cartera para un nivel de riesgo dado o maximiza su rendimiento por el riesgo mínimo.

7. Un inversor es de naturaleza racional.

Para elegir el mejor portafolio entre una cantidad de portafolios posibles, cada uno con diferente rentabilidad y riesgo, se deben tomar dos decisiones por separado:

1. Determinación de un conjunto de carteras eficientes.

2. Selección de la mejor cartera del conjunto eficiente.

Una cartera que ofrece el máximo rendimiento para un riesgo dado, o el riesgo mínimo para un rendimiento dado es una cartera eficiente. Por lo tanto, las carteras se seleccionan de la siguiente manera:

(a) De las carteras que tienen la misma rentabilidad, el inversor preferirá la cartera con menor riesgo, y

(b) A partir de las carteras que tienen el mismo nivel de riesgo, un inversor preferirá la cartera con mayor tasa de rendimiento.
Como el inversor es racional, les gustaría obtener un mayor rendimiento. Y como es reacio al riesgo, quiere tener un riesgo menor. En la Figura 1, el área sombreada PVWP incluye todos los valores posibles en los que un inversor puede invertir. Los portafolios eficientes son los que se encuentran en el límite de PQVW. Por ejemplo, en el nivel de riesgo x2, hay tres carteras S, T, U. Pero la cartera S se denomina cartera eficiente, ya que tiene el rendimiento más alto, y2, en comparación con T y U. Todas las carteras que se encuentran en el límite de PQVW son portafolios eficientes para un nivel de riesgo dado.

El límite PQVW se llama frontera eficiente. Todas las carteras que se encuentran debajo de la Frontera Eficiente no son lo suficientemente buenas porque la rentabilidad sería menor para el riesgo dado. Las carteras que se encuentran a la derecha de Efficient Frontier no serían lo suficientemente buenas, ya que existe un mayor riesgo para una tasa de rendimiento dada. Todas las carteras que se encuentran en el límite de PQVW se denominan Carteras Eficientes. La frontera eficiente es la misma para todos los inversores, ya que todos los inversores quieren el máximo rendimiento con el menor riesgo posible y son reacios al riesgo.

Para la selección de la cartera óptima o la mejor cartera, se analizan las preferencias de riesgo-rendimiento. Un inversor que es muy reacio al riesgo mantendrá una cartera en la esquina inferior izquierda de la frontera, y un inversor que no sea demasiado reacio al riesgo elegirá una cartera en la parte superior de la frontera.
La Figura 2 muestra la curva de indiferencia de riesgo-rendimiento para los inversores. Se muestran las curvas de indiferencia C1, C2 y C3. Cada uno de los diferentes puntos en una curva de indiferencia particular muestra una combinación diferente de riesgo y rendimiento, que proporcionan la misma satisfacción a los inversores. Cada curva a la izquierda representa una mayor utilidad o satisfacción. El objetivo del inversor sería maximizar su satisfacción moviéndose a una curva que sea más alta. Un inversionista puede tener satisfacción representada por C2, pero si su satisfacción / utilidad aumenta, entonces él / ella pasa a la curva C3. Por lo tanto, en cualquier momento, un inversor será indiferente entre las combinaciones S1 y S2, o S5 y S6.
La cartera óptima del inversor se encuentra en el punto de tangencia de la frontera eficiente con la curva de indiferencia. Este punto marca el nivel más alto de satisfacción que el inversor puede obtener. Esto se muestra en la Figura 3. R es el punto donde la frontera eficiente es tangente a la curva de indiferencia C3, y también es una cartera eficiente. Con esta cartera, el inversor obtendrá la mayor satisfacción, así como la mejor combinación de riesgo-rendimiento (una cartera que ofrece el mayor rendimiento posible para una cantidad determinada de riesgo). Cualquier otra cartera, por ejemplo, X, no es la cartera óptima, aunque se encuentra en la misma curva de indiferencia que está fuera de la cartera factible disponible en el mercado. La cartera Y tampoco es óptima, ya que no se encuentra en la mejor curva de indiferencia factible, a pesar de que es una cartera de mercado factible. Otro inversor que tenga otros conjuntos de curvas de indiferencia podría tener una cartera diferente como su cartera mejor / óptima.

Todas las carteras hasta ahora se han evaluado en términos de valores de riesgo solamente, y es posible incluir también valores sin riesgo en una cartera. Una cartera con valores libres de riesgo permitirá a los inversores alcanzar un mayor nivel de satisfacción. Esto se explica en la Figura 4.
R1 es el rendimiento libre de riesgo, o el rendimiento de los valores del gobierno, ya que se considera que esos valores no tienen ningún riesgo a efectos de modelado. R1PX se dibuja de modo que sea tangente a la frontera eficiente. Cualquier punto en la línea R1PX muestra una combinación de diferentes proporciones de valores libres de riesgo y carteras eficientes. La satisfacción que obtiene un inversionista de las carteras en la línea R1PX es más que la satisfacción obtenida de la cartera P. Todas las combinaciones de carteras a la izquierda de P muestran combinaciones de activos riesgosos y libres de riesgo, y todas las que están a la derecha de P representan compras de activos de riesgo hechos con fondos prestados a la tasa libre de riesgo.

En el caso de que un inversor haya invertido todos sus fondos, se pueden tomar prestados fondos adicionales a una tasa libre de riesgo y se puede obtener una combinación de cartera que se encuentra en R1PX. R1PX se conoce como Capital Market Line (CML). esta línea representa la transacción de riesgo-rendimiento en el mercado de capitales. La CML es una curva de pendiente ascendente, lo que significa que el inversor asumirá un mayor riesgo si el rendimiento de la cartera también es mayor. La cartera P es la cartera más eficiente, ya que depende tanto de CML como de Efficient Frontier, y cada inversor preferiría obtener esta cartera, P. La cartera de P se conoce como la Cartera de Mercado y también es la cartera más diversificada. Consiste en todas las acciones y otros valores en el mercado de capitales.

En el mercado de carteras que consiste en valores con riesgo y libres de riesgo, la CML representa la condición de equilibrio. La línea Capital Market dice que el rendimiento de una cartera es la tasa libre de riesgo más la prima de riesgo. La prima de riesgo es el producto del precio de mercado del riesgo y la cantidad de riesgo, y el riesgo es la desviación estándar de la cartera.


__FORZAR_TDC__

</doc>
<doc id="6762" url="https://es.wikipedia.org/wiki?curid=6762" title="Cuadro de mando">
Cuadro de mando

El concepto de cuadro de mando proviene del concepto denominado "tableau de bord" en Francia, que traducido de manera literal significaría "tablero de mandos". En español se le llama más propiamente panel de instrumentos, tablero de instrumentos o simplemente tablero (en España "cuadro de instrumentos", "tablero de a bordo" o "salpicadero") como los que se encuentran en el salpicadero de un coche.

La gestión de las empresas requiere un sistema de indicadores (en inglés KPIs o "Key Performance Indicators") que nos faciliten la toma de decisiones y el control. Se requiere un sistema completo de análisis.

Existe infinidad de posibles indicadores que podemos utilizar. Algunos ratios o indicadores son de uso muy general. Los más habituales son, por ejemplo:

Otros indicadores deberán ser elaborados expresamente para analizar una empresa concreta.

El sistema de indicadores debe organizarse en un cuadro de mando. El cuadro de mando recoge los principales indicadores y los presenta de un modo claro y útil. El cuadro de mando es un sistema que nos informa de la evolución de los parámetros fundamentales del negocio.

Los cuadros de mando han de presentar sólo aquella información que sea imprescindible, de una forma sencilla y por supuesto, sinóptica y resumida.



</doc>
<doc id="6764" url="https://es.wikipedia.org/wiki?curid=6764" title="Rotación del inventario">
Rotación del inventario

La rotación del inventario o rotación de existencias es uno de los parámetros utilizados para el control de gestión de la función logística o del departamento comercial de una empresa. La rotación, en este contexto, expresa el número de veces que se han renovado las existencias (de un artículo, de una materia prima...) durante un período, normalmente un año.

Este valor constituye un buen indicador sobre la calidad de la gestión de los abastecimientos, de la gestión del stock y de las prácticas de compra de una empresa. No puede establecerse una cifra ya que varía de un sector a otro: las empresas fabricantes suelen tener índices de rotación entre 4 y 5; los grandes almacenes procuran llegar a 8; y los hipermercados pueden llegar a 25 en algunos artículos del surtido de alimentación. 

La rotación del inventario corresponde a la frecuencia media de renovación de las existencias consideradas, durante un tiempo dado.
Se obtiene al dividir el consumo (venta, expediciones...), durante un período, entre el valor del inventario medio, de ese mismo período. 

Por ejemplo, si un vendedor de coches mantiene de media 10 coches en exposición en su tienda y al año vende un total de 150 vehículos, su stock tiene una rotación de 15. La rotación se calcula dividiendo las ventas totales, en este caso 150, entre el inventario medio, en este caso 10.

La rotación del inventario, en realidad, está informando del número de veces que se recupera la inversión en existencias, durante un periodo. En el ejemplo anterior, el vendedor de coches ha recuperado 15 veces la inversión en coches que realizó durante el año, al vender 150 vehículos, manteniendo unas existencias medias de 10.

La rotación, o índice de rotación, IR, se calcula con la expresión:



Las dos cifras deben expresarse en la misma unidad.

Fórmula para determinar la rotación de inventarios

La rotación de inventarios se determina dividiendo el costo de las mercancías vendidas en el periodo entre el promedio de inventarios durante el periodo. (Coste mercancías vendidas/Promedio inventarios) = N veces.

La rotación es una parte importante de la rentabilidad. De forma abreviada:

En muchos casos, cuando el margen es ajustado, la mejor opción para aumentar la rentabilidad es incrementar la rotación.

El mantener inventarios produce un costo de oportunidad, pues para tenerlos se debe hacer una inversión de capital, por ello la importancia de determinar adecuadamente su tamaño.




</doc>
<doc id="6766" url="https://es.wikipedia.org/wiki?curid=6766" title="Margen">
Margen

Margen o El margen puede hacer referencia a:

 .o sea es la linea esa de la hoja como un cactus





</doc>
<doc id="6767" url="https://es.wikipedia.org/wiki?curid=6767" title="Indicador de ventas">
Indicador de ventas

Los indicadores de ventas del cuadro de mando suelen ser las ventas por metro cuadrado, las ventas por empleado y ventas por establecimiento.

Las "ventas por metro cuadrado". Un ratio muy empleado para realizar comparaciones entre distintas secciones de una tienda, entre tiendas y entre distintas empresas. Las ventas por metro cuadrado facilitan analizar la evolución de las tiendas a lo largo del tiempo. Es un dato que suele estar fácilmente disponible para comparar las empresas unas con otras.

Las "ventas por empleado" es igualmente un indicador fácil de conseguir. Permite realizar comparaciones entre secciones, tiendas y empresas. Y también es un ratio que nos facilita seguir la evolución a lo largo del tiempo.

"Ventas por establecimiento". Si dividimos las ventas totales entre el número de tiendas de la "cadena", obtenemos la media de ventas por establecimiento. Permite comparar unas tiendas con otras y 

.Los indicadores para cualquier empresa las utilizan para vender su equipo comercial, pero son muy pocas las empresas que las utilizan, pero muchas las utilizan para medir como pueden influir estas en sus equipos comerciales para que las ventas y sus beneficios sigan creciendo, son capaz de conseguir estos indicadores para poder conseguir que las empresas crezcan y estas sigan siendo las líderes en el mercado.

.También existen los indicadores de ventas por empleado
Estas herramientas son excelentes para poder medir algunos funcionamiento para la organización en la cual se encuentran laborando, para la productividad real y productividad efectiva

</doc>
<doc id="6768" url="https://es.wikipedia.org/wiki?curid=6768" title="Rentabilidad financiera">
Rentabilidad financiera

En finanzas, la rentabilidad financiera, rentabilidad para el accionista o «ROE» (por sus iniciales en inglés, "Return on equity") relaciona el beneficio económico con los recursos propios necesarios para obtener ese lucro. Para una empresa, el ROE indica la rentabilidad que obtienen los accionistas (únicos proveedores de capital que no tienen una rentabilidad asegurada) sobre el capital que han invertido, excluyendo recursos de terceros, como la deuda financiera.

La rentabilidad financiera puede entenderse como una medida del beneficio que obtiene una compañía con relación a los fondos invertidos por los accionistas. Se suele expresar como porcentaje.
La rentabilidad financiera, ROE, se calcula:

formula_1 

Por ejemplo si se coloca en una cuenta un millón y los intereses generados son cien mil, la rentabilidad es del 10%. La rentabilidad de la cuenta se calcula dividiendo la cantidad generada y la cantidad que se ha necesitado para generarla.

Sumando al numerador del anterior ratio la cuota del impuesto que grava la renta de la sociedad, se obtiene la rentabilidad financiera antes de los impuestos. Cuando la rentabilidad económica es superior al coste del endeudamiento (expresado ahora en tanto por ciento, para poder comparar, y no en valor absoluto como anteriormente), cuanto mayor sea el grado de endeudamiento mayor será el valor de la rentabilidad financiera o rentabilidad de los accionistas, en virtud del juego del denominado efecto palanca. Por el contrario, cuando la rentabilidad económica es inferior al coste de las deudas (el capital ajeno rinde menos en la empresa de lo que cuesta) se produce el efecto contrario: el endeudamiento erosiona o aminora la rentabilidad del capital propio.

A efectos de poder realizar un análisis más detallado de las causas que generan rentabilidad, en la empresa DuPont desarrolló a principios del siglo XX la fórmula de DuPont que desagrega la fórmula anterior en tres términos:

Permite a la empresa dividir su retorno en los componentes de utilidad sobre ventas y eficiencia sobre uso de los activos.
Se pueden introducir en la expresión otras variables que afectan a la rentabilidad financiera: ventas y activos.

formula_2

Por la descomposición y ampliación de la expresión se obtiene:

formula_3

Los dos primeros componentes se muestran en el apartado anterior, el margen y la rotación. El tercer componente es el apalancamiento que se define como la relación entre las inversiones (el activo) y los recursos propios de la empresa. Los dos primeros componentes son derivados de la operatoria del negocio, mientras que el tercero es el agregado financiero. Un ROE que aumenta por crecimiento de Margen o Rotación es un ROE que crece por razones de negocio, mientras que un ROE que crece por un aumento del apalancamiento muestra una empresa que tiene un aumento en su riesgo financiero. 

Una de las grandes ventajas de la descomposición del ROE mediante Dupont es que nos permite identificar los "drivers" de la rentabilidad y seguir su evolución en el tiempo. De esta manera es posible seguir la evolución del Margen, la Rotación y el apalancamiento a lo largo del tiempo y poder identificar cuales son las causas de una caída de la rentabilidad y tomar medidas correctivas a tiempo. Es útil crear un indicador de "Margen x Rotación" que ayuda a ver la contribución combinada de los componentes del negocio de la rentabilidad.



</doc>
<doc id="6769" url="https://es.wikipedia.org/wiki?curid=6769" title="Cuadro de mando integral">
Cuadro de mando integral

El concepto de Cuadro de mando Integral – CMI (Balanced Scorecard – BSC) Se presentó en el número de enero/febrero de 1992 de la revista "Harvard Business Review", con base en un trabajo realizado para una empresa de semiconductores. Sus autores, Robert Kaplan y David Norton, plantean el CMI como un sistema de administración o sistema administrativo ("management system"), que va más allá de la perspectiva financiera con la que los gerentes acostumbran a evaluar la marcha de una empresa. Según estos dos consultores, gestionar una empresa teniendo en cuenta solamente los indicadores financieros tradicionales (existencias, inmovilizado, ingresos, gastos...) olvida la creciente importancia de los activos intangibles de una empresa (relaciones con los clientes, habilidades y motivaciones de los empleados...) como fuente principal de ventaja competitiva. 

De ahí surge la necesidad de crear una nueva metodología para medir las actividades de una compañía en términos de su visión y estrategia, proporcionando a los gerentes una mirada global del desempeño del negocio. El CMI es una herramienta de administración de empresas que muestra continuamente cuándo una compañía y sus empleados alcanzan los resultados definidos por el plan estratégico. Adicionalmente, un sistema como el CMI permite detectar las desviaciones del plan estratégico y expresar los objetivos e iniciativas necesarios para reconducir la situación.

Según el libro "The Balanced ScoreCard: Translating Strategy into Action", Harvard Business School Press, Boston, 1996: 

El CMI sugiere que veamos a la organización desde cuatro perspectivas, cada una de las cuales debe responder a una pregunta determinada:
El CMI es por lo tanto un sistema de gestión estratégica de la empresa, que consiste en:

En general, los indicadores financieros están basados en la contabilidad de la compañía, y muestran el "pasado" de la misma. El motivo se debe a que la contabilidad no es inmediata (al emitir un proveedor una factura, la misma no se contabiliza automáticamente), sino que deben efectuarse "cierres" que aseguren la compilación y consistencia de la información. Debido a estas demoras, algunos autores sostienen que dirigir una compañía prestando atención solamente a indicadores financieros es como "conducir a 100 km/h mirando por el espejo retrovisor".

"Este comentario es exagerado pues existe una herramienta llamada presupuesto que se realiza anualmente y se ajusta cada tres meses, presentando estados financieros proyectados con margen de error de 5 a 10%.

Lo que es posible, es utilizar el CMI como una herramienta adicional para ver de mejor forma las estrategias utilizadas en el presupuesto proyectado."

Esta perspectiva abarca el área de las necesidades de los accionistas. Esta parte del BSC se enfoca a los requerimientos de crear valor para el accionista como: las ganancias, rendimiento económico, desarrollo de la compañía y rentabilidad de la misma.

Valor Económico Agregado (EVA), Retorno sobre capital empleado (ROCE), Margen de Operación, Ingresos, Rotación de Activos son algunos indicadores de esta perspectiva.

Algunos indicadores frecuentemente utilizados son: 

Para lograr el desempeño financiero que una empresa desea, es fundamental que posea clientes leales y satisfechos. Con ese objetivo en esta perspectiva se miden las relaciones con los clientes y las expectativas que los mismos tienen sobre los negocios. Además, en esta perspectiva se toman en cuenta los principales elementos que generan valor para los clientes integrándolos en una propuesta de valor, para poder así centrarse en los procesos que para ellos son más importantes y que más los satisfacen.

La Perspectiva de clientes, como su nombre indica, está enfocada a la parte más importante de una empresa: sus clientes, puesto que sin consumidores no existe ningún tipo de mercado. Por consiguiente, se deberán cubrir las necesidades de los compradores entre las que se encuentran los precios, la calidad del producto o servicio, tiempo, función, imagen y relación. Cabe mencionar que todas las perspectivas están unidas entre sí. Esto significa que para cubrir las expectativas de los accionistas también se deben cubrir las de los consumidores para que compren y se genere una ganancia. Algunos indicadores de esta perspectiva son: satisfacción de clientes, desviaciones en acuerdos de servicio, reclamos resueltos sobre el total de reclamos, e incorporación y retención de clientes.

El conocimiento de los clientes y de los procesos que más valor generan es muy importante para lograr que el panorama financiero sea próspero. Sin el estudio de las peculiaridades del mercado al que está enfocada la empresa no podrá existir un desarrollo sostenible en la perspectiva financiera, ya que en gran medida el éxito financiero proviene del aumento de las ventas, situación que es el efecto de clientes que repiten sus compras porque prefieren los productos que la empresa desarrolla teniendo en cuenta sus preferencias.

Una buena manera de medir o saber la perspectiva del cliente es diseñando protocolos básicos de atención y utilizar la metodología de cliente incógnito para la relación del personal en contacto con el cliente (PEC).

Usualmente se consideran cuatro categorías, a saber:

Los instrumentos que usualmente se utilizan para obtener el valor de tales indicadores son entrevistas y encuestas:

Analiza la adecuación de los procesos internos de la empresa de cara a la obtención de la satisfacción del cliente y logro de altos niveles de rendimiento financiero. Para alcanzar este objetivo se propone un análisis de los procesos internos desde una perspectiva de negocio y una predeterminación de los procesos clave a través de la cadena de valor. 

Se distinguen cuatro tipos de procesos:





Indicadores: bases de datos estratégicos, software propio, las patentes y copyright (marcas registradas), entre otras.

En la actualidad -debido a las turbulencias del entorno empresarial, influenciado en la mayoría de los casos por una gran presión competitiva, así como por un auge de la tecnología- es cuando comienza a tener una amplia trascendencia.

El concepto de cuadro de mando deriva del concepto denominado "tableau de bord" en Francia, que traducido de manera literal, vendría a significar algo como tablero de mandos o cuadro de instrumentos.

A partir de los años 80, es cuando el Cuadro de Mando pasa a ser, además de un concepto práctico, una idea académica, ya que hasta entonces el entorno empresarial no sufría grandes variaciones, la tendencia del mismo era estable, las decisiones que se tomaban carecían de un alto nivel de riesgo.

Para entonces, los principios básicos sobre los que se sostenía el Cuadro de Mando ya estaban estructurados, es decir, se fijaban unos fines en la entidad, cada uno de estos eran llevados a cabo mediante la definición de unas variables clave, y el control era realizado a través de indicadores.

Básicamente, y de manera resumida, podemos destacar tres características fundamentales de los cuadros de mando:


En definitiva, lo importante es establecer un sistema de señales en forma de Cuadro de Mando que nos indique la variación de las magnitudes verdaderamente importantes que debemos vigilar para someter a control la gestión.

A la hora de elaborar los cuadros de mando, muchos son los criterios que se pueden entremezclar, siendo los que a continuación se describen, algunos de los más importantes, para clasificar tales herramientas de apoyo a la toma de decisiones:


Otras clasificaciones:

En la actualidad, no todos los cuadros de mando integral están basados en los principios de Kaplan y Norton, aunque sí influenciados en alguna medida por ellos. Por este motivo, se suele emplear con cierta frecuencia el término dashboard, que refleja algunas características teóricas del cuadro de mando. De forma genérica, un "dashboard" engloba a varias herramientas que muestran información relevante para la empresa a través de una serie de indicadores de rendimiento, también denominados KPIs ("key performance indicators"). Cabe señalar que un "dashboard" puede no ser equilibrado, término que evoca al "Balanced" Scorecard, es decir un equilibrio entre indicadores que visualicen en forma transversal la organización o empresa y que quizás para un "dashboard" solo puede buscar y dirigir su mirada a un conjunto focalizado y parcial de indicadores.

Los Cuadros de Mando (CM) son herramientas de control empresarial orientadas al monitoreo de los objetivos de la empresa o de las diferentes áreas de negocio a través de indicadores. En función de la naturaleza de los indicadores estaríamos hablando de Cuadro de Mandos Estratégico (CME) si se trata de indicadores estratégicos u Cuadro de mandos Operativo (CMO) si los indicadores son operativos, es decir, indicadores rutinarios ligados a áreas o departamentos específicos de la empresa (las áreas suelen ser procesos).

La periodicidad de los CMO puede ser diaria, semanal o mensual, y además está focalizado en indicadores que generalmente representan procesos, por lo que su puesta en funcionamiento es más barata y sencilla y suele ser un buen punto de partida para aquellas compañías que intentan evaluar la implantación de un cuadro de mando integral.

El CMO en línea es fundamental en momentos críticos.

Seis serán las etapas propuestas:


En una primera etapa, la empresa debe conocer en qué situación se encuentra, valorar dicha situación y reconocer la información con la que va a poder contar en cada momento o escenario, tanto la del entorno como la que maneja habitualmente.

Esta etapa se encuentra muy ligada con la segunda, en la cual la empresa habrá de definir claramente las funciones que la componen de manera que puedan ser estudiadas las necesidades según los niveles de responsabilidad en cada caso y poder concluir cuáles son las prioridades informativas que se han de cubrir, cometido que se llevará a cabo en la tercera de las etapas.

Por otro lado, en una cuarta etapa se han de señalizar las variables críticas necesarias para controlar cada área funcional. Estas variables son ciertamente distintas en cada caso, ya sea por los valores culturales y humanos que impregnan la filosofía de la empresa en cuestión, o ya sea por el tipo de área que se esté analizando. Lo importante en todo caso, es determinar cuáles son las más importantes en cada caso para que se pueda llevar a cabo un correcto control y un adecuado proceso de toma de decisiones.

Posteriormente, y en la penúltima de nuestras etapas, se ha de encontrar una correspondencia lógica entre el tipo de variable crítica determinada en cada caso, y el ratio, valor, medida, etc., que nos informe de su estado cuando así se estime necesario. De este modo podremos atribuir un correcto control en caos"'. Con base en las relaciones de causa-efecto, se elabora un Mapa estratégico (Si bien la traducción literal de "Strategy Map" es "Mapa de la estrategia") que permite ver ágilmente la evolución de los indicadores y tomar acciones tendientes a modificarlos.

En último lugar, se debe configurar el cuadro de mando en cada área funcional, y en cada nivel de responsabilidad de manera que albergue siempre la información mínima, necesaria y suficiente para poder extraer conclusiones y tomar decisiones acertadas.

Los responsables de cada uno de los cuadros de mando de los diferentes departamentos han de tener en cuenta una serie de aspectos comunes en cuanto a su elaboración. Entre dichos aspectos cabría destacar los siguientes:






De alguna manera, lo que se incorpore en esta herramienta, será aquello con lo que se podrá medir la gestión realizada y, por este motivo, es muy importante establecer en cada caso qué es lo que hay que controlar y cómo hacerlo. En general, el Cuadro de Mando debe tener cuatro partes bien diferenciadas:





No se deben perder de vista los objetivos elementales que se pretenden alcanzar mediante el Cuadro de Mando, ya que, sin fines a alcanzar, difícilmente se puede entender la creación de ciertos informes. Entre dichos objetivos podemos considerar que:








Los principales elementos que pueden hacer que el Cuadro de Mando muestre notables diferencias con respecto a otras herramientas contables y de gestión son:


En relación con el tipo de información utilizada, el Cuadro de Mando, aparte de reunir información de similares características que la empleada en las distintas disciplinas de naturaleza contable, es decir, financiera, debe contener información de carácter no financiero. Ya desde su presentación como una herramienta útil de gestión, el Cuadro de Mando se destacaba por su total flexibilidad para recoger tal información.

Otro aspecto a destacar, es la relación mutua que ha de existir entre el Cuadro de Mando y el perfil de la persona a quien va destinado. Precisamente, las necesidades de cada directivo, han de marcar la pauta que caracterice y haga idónea a esta herramienta en cada caso y situación, sobre todo con respecto al nivel de mayor responsabilidad de la jerarquía actual de la empresa, debido a que se precisa un esfuerzo mucho mayor de generalidad y síntesis.

Un rasgo más del Cuadro de Mando es la solución de problemas mediante acciones rápidas. Cuando se incorporan indicadores de carácter cualitativo al Cuadro de Mando, en cierto modo, estos están más cerca de la acción que los propios indicadores o resultados financieros. Asimismo, estos indicadores nominales nos dan un avance en cuanto a qué resultados están por alcanzarse.

El último de los rasgos que diferenciarían al Cuadro de Mando es el hecho de utilizar informaciones sencillas y poco voluminosas. Las disciplinas y herramientas contables habituales precisan una mayor dedicación de tiempo de análisis y de realización y, al momento de la toma de decisiones siempre necesita de otros aspectos que en un principio no formaban parte de su marco de acción.

El Cuadro de Mando se orienta hacia la reducción y síntesis de conceptos, es una herramienta que, junto con el apoyo de las nuevas tecnologías de la información y comunicación, puede y debe ofrecer una información sencilla, resumida y eficaz para la toma de decisiones.

CMI vs ISO. El Cuadro de mando integral es compatible con otros modelos de gestión de la Calidad, como la ISO9001, ISO TS 16949, etc. Si bien, estas normas de calidad, se centran más bien en el control de proceso interno y no establecen las relaciones de causa efecto entre las distintas perspectivas desde la perspectiva financiera hasta la perspectiva de aprendizaje y desarrollo. El CMI es perfectamente compatible con estos modelos de calidad y en los sectores muy desarrollados, es común compaginar distintos modelos: Lean, ISO y CMI.

En relación con las principales variables a tener en cuenta en la Dirección General, Direcciones Funcionales y Subdirecciones Funcionales, se concluye que no existe una única fórmula para todas las empresas, sino que para cada tipo de organización habrá que tomar unas variables determinadas con las que llevar a cabo la medición de la gestión.

Es importante tener en cuenta que el contenido de cualquier Cuadro de Mando, no se reduce tan sólo a cifras o números, ha de ser un contenido muy concreto para cada departamento o para cada responsable. De igual manera, se ha de tener presente que la información que se maneja en un Cuadro de Mando determinado puede ser válida para otro.

Con respecto a los indicadores, estos son elementos objetivos que describen situaciones específicas, y que tratan de medir de alguna manera las variables propuestas en cada caso. Al analizar los indicadores necesarios, se establece una distinción básica entre los financieros y no financieros.

El Cuadro de Mando se nutre de todo este tipo de indicadores, tiene en cuenta los aspectos prospectivo y retrospectivo, configurando un punto de vista global mucho más completo y eficaz. Su función es conjugar una serie de elementos para suministrar una visión de conjunto y ofrecer soluciones en cada caso.

La mayoría de las técnicas tienen como elemento común, el mostrar las relaciones que existen entre las categorías de las variables más que entre las propias variables. El Cuadro de Mando, no debe profundizar tanto en estas técnicas, sino en la obtención de la información mínima necesaria, para que, junto a las variables de carácter monetario, pueda llevar a cabo la ya mencionada gestión globalizada.


De modo previo, al abordar la presentación del Cuadro de Mando, se debe resaltar una cuestión que es de gran importancia en relación a su contenido. Se trata del aspecto cualitativo de esta herramienta, ya que hasta el momento no se le ha prestado la importancia que se merece y, sobre todo, porque existen numerosos aspectos como el factor humano, cuyo rendimiento queda determinado por el entorno que le rodea en la propia organización, y estas cuestiones rara vez se toman en cuenta.

La empresa -desde una perspectiva meramente global- constituye un conjunto de vínculos más o menos establecidos y de recursos compartidos con un fin común. Asimismo, se puede señalar que la empresa en sí representa un conjunto de subsistemas de información, claramente definidos y normalizados.

Información y Fluidez. La información que puede obtener y utilizar la empresa, según cuál sea su naturaleza, puede ser válida para unos u otros Cuadros de Mando. La información que contienen los CMI pueden dividirse en dos grandes áreas: externa e interna.

Cabe señalar que con más frecuencia la preocupación de las empresas por contar con sistemas organizados, ágiles y fluidos de comunicación entre todos los niveles de responsabilidad va en aumento debido a las crecientes exigencias del mercado en materia de actualización y tecnología que les permitan posicionarse y perpetuar una posición en dicho mercado. Dicha comunicación se da a través de los canales que se establezcan y hagan posible que el personal, por medio del conocimiento claro de los temas que les afectan, pueda sentirse más involucrados en sus tareas diarias.

Relación causa-efecto. Entre los diversos objetivos de una Compañía, pueden establecerse relaciones de causa-efecto. Esto es, hallar una relación entre la variación de las métricas de un objetivo y las de otro a lo largo del tiempo. Esto permite predecir cómo se comportarán algunas métricas en el futuro a partir del análisis de otras en el momento actual; y tomar alguna decisión que permita cambiar el rumbo de los acontecimientos.






</doc>
<doc id="6771" url="https://es.wikipedia.org/wiki?curid=6771" title="Control de gestión">
Control de gestión

El control de gestión es el proceso administrativo que sirve para evaluar el grado de cumplimiento de los objetivos organizacionales previstos por la dirección o gobierno corporativo.

Existen diferencias importantes entre las concepciones clásica y moderna de control de gestión. La primera es aquella que incluye únicamente al control operativo y que lo desarrolla a través de un sistema de información relacionado con la contabilidad de costos, mientras que la segunda integra muchos más elementos y contempla una continua interacción entre todos ellos. El nuevo concepto de control de gestión centra su atención por igual en la planificación y en el control, y precisa de una orientación estratégica que dote de sentido sus aspectos más operativos.

El SCG cuenta con el diagnóstico o análisis para entender las causas raíces que condicionan el comportamiento de los sistemas físicos, permite establecer los vínculos funcionales que ligan las variables técnicas-organizativas-sociales con el resultado económico de la empresa y es el punto de partida para la mejora de los estándares; mediante la planificación orienta las acciones en correspondencia con las estrategias trazadas, hacia mejores resultados; y, finalmente, cuenta con el control para saber si los resultados satisfacen los objetivos trazados.
El control de gestión, considera como elementos a evaluar, no solo aspectos cuantitativos sino también cualitativos, además, utiliza la visión interna y externa de la organización, para lo cual asigna un valor agregado a la cultura organizacional .
Se puede señalar como diferencia principal entre Control de Gestión y Control Interno que el primero evalúa los tres niveles de las organizaciones: nivel estratégico, nivel táctico y nivel operativo, y el segundo, se limita solo a los dos últimos niveles.

Taylor (1895) fue uno de los iniciadores del CG industrial, introdujo la contabilidad analítica, el cronometraje de los tiempos de mano de obra directa, los estándares, la asignación de los costos indirectos, la remuneración por rendimientos. Brown (1907) estableció la fórmula de la rentabilidad del capital. Todavía hoy se observan muchos ejemplos en las empresas el CG gira en torno al control de la eficiencia interna de la empresa, centrando su atención en los recursos que consume, en el beneficio inmediato y en la información financiera exterior.

En la segunda mitad del siglo XX han ocurrido cambios sustanciales del entorno, el cual ha pasado de estable con reglas de juego fijas, a turbulento y muy competitivo. Estos cambios de entorno han desencadenado en las empresas un gran número de cambios internos, en variables tales como la orientación hacia el cliente, el desarrollo tecnológico y la innovación, el papel rector de la dirección estratégica, los enfoques de calidad, el rol de los recursos humanos en la organización, la gestión de la información y otros. El éxito empresarial por lo tanto, exige una continua adaptación de la empresa a su entorno y la competitividad se convierte en el criterio económico por excelencia para orientar y evaluar el desempeño dentro y fuera de la empresa.

Según García (1975), el control de gestión (CG) es ante todo un método, un medio para conducir con orden el pensamiento y la acción, lo primero es prever, establecer un pronóstico sobre el cual fijar objetivos y definir un programa de acción. Lo segundo es controlar, comparando las realizaciones con las previsiones al mismo tiempo que se ponen todos los medios para compensar las diferencias constatadas.

Blanco (1984) plantea que la moderna filosofía del CG presenta la función de control como el proceso mediante el cual los directivos se aseguran de la obtención de recursos y del empleo eficaz y eficiente de los mismos en el cumplimiento de los objetivos de la empresa.

La gestión es una mezcla de decisiones locales con objetivos globales de la compañía, según lo ve Goldratt (1990), desde su teoría sobre gestión de las limitaciones (TOC), precisando que el control es una parte del sistema de información que responde a una de las preguntas gerenciales más perturbadoras: ¿cómo medir objetiva y constructivamente el desempeño local pasado?

Según Huge Jordan (1995), el CG es un instrumento de la gestión que aporta una ayuda a la decisión y sus útiles de dirección van a permitir a los directores alcanzar los objetivos; es una función descentralizada y coordinada para la planificación de objetivos, acompañada de un plan de acción y la verificación de que los objetivos han sido alcanzados.

A partir de 1990, aparece el término "controlling" (4) en Alemania, España y Estados Unidos. El salto cualitativo no está en la definición misma de control de gestión, sino en lo que enfatiza ahora la literatura con este término: las nuevas características que debe presentar el control de gestión ante el cambio radical que está operándose en los modelos de perfeccionamiento empresarial. Kupper (1992) lo ve como un medio de coordinación de las numerosas partes del sistema de management. Pacher-Theinburg (1992) subraya la significación del controlling por la integración alcanzada entre las funciones de planificación y control. García Echevarría (1994) resalta tanto su dimensión estratégica y global de la empresa como su dimensión específica en la función que se dirige. El controlling, como el control de gestión, orientado más hacia el futuro que al pasado y donde se ve fundamentalmente a la empresa desde afuera de sí misma, integrada con el cliente y la competencia.

Si continuáramos citando autores, se comprobaría que la definición de CG no es única, varía con cada autor y con el transcurso de los años, ya que el constante cambio del entorno empresarial conduce a una evolución en la forma de pensar y actuar, así como en los métodos y herramientas empleadas para dirigir una organización. 

Repasando diferentes definiciones sobre control de gestión se observa que:





Aquí se considera que el CG debe ofrecer información homogénea en la medida que asciende en la pirámide de información para ofrecer información agregada sobre estados o resultados pero cuando se avanza en sentido contrario, lo que se maneja es información sobre decisiones, algunas tan directas y heterogéneas como lo son las relativas a los procesos sobre los que actúan. En estas condiciones, la problemática a resolver por el CG es servir de puente entre los resultados económicos y las decisiones que se toman sobre los procesos físicos de la empresa poniendo de manifiesto sus vínculos funcionales.






La Editorial Profit cuenta con una serie de libros que enumeran varios componentes del Sistema de Control de Gestión. Es importante mencionar algunos de ellos para comprender cómo es que en conjunto representan un tablero de indicadores que muestra cual es la situación de una empresa con respecto a su estrategia y recursos:
Por mencionar un ejemplo, Rieckhof menciona la importancia de medir y mejorar los recursos naturales. El impacto ambiental de las empresas es uno más de los componentes del Control de Gestión;

""Challenged by decreasing natural resources, corporations need to significantly improve their resource efficiency. For the purpose of a more efficient and sustainable use of natural resources, the internationally standardized approach of MFCA is a promising tool. However, goals such as resource efficiency can only be achieved if corporations commit themselves to these targets on a strategic level and transfer them to all corporate levels by using MCS. Thus, MFCA requires an increased interrelation with MCS, which can drive corporate strategy toward resource efficiency"."


Los sistemas de control se basan en una serie de principios básicos, los cuales permiten alcanzar los objetivos propuestos por todo sistema de control. A saber son:




</doc>
<doc id="6777" url="https://es.wikipedia.org/wiki?curid=6777" title="Gestión empresarial">
Gestión empresarial

La Gestión Empresarial es un estudio complejo y extenso que buscan mejorar la relación entre productividad, calidad, costes, administración, distribución y logística así como tiempo de producción, relación de trabajadores operarios y de confianza para mejorar de manera continúa y eficiente la competitividad de una empresa o de un negocio. Su finalidad es lograr metas determinadas en plazos de tiempo óptimo, para garantizar que las acciones Y/0 el capital de participaciones sociales así como las obligaciones y derechos de los empresarios

Según el economista Joseph Schumpeter, la gestión empresarial garantiza que la oferta cubra la demanda mediante la “destrucción creativa”. Es decir, con la innovación constante para aumentar la productividad y la competitividad.

Otro elemento comparativo es el paso del tiempo y su efecto en toda la organización. En un automóvil, las partes mecánicas se desgastarán con el tiempo, pero al estar normalizadas podrán sustituirse por otras, según un programa de mantenimiento que permitirá que el vehículo siga funcionando. En el caso de las personas, con el tiempo irán cambiando: la percepción, la experiencia, la motivación. El proceso de envejecimiento afectará a su actitud y su comportamiento. Además, los grupos de personas dentro de la organización actúan de forma distinta según el momento de la vida en el que se encuentren. Todo cambio impuesto en el grupo (por ejemplo, un cambio en el personal), alterará su naturaleza, incluso sus expectativas. Este ejemplo determina la importancia que en la gestión general de la empresa tiene el desarrollo de los recursos humanos. Por lo tanto, es básico que el responsable de esta función conozca los aspectos esenciales de la organización y no la considere un mero sistema mecánico, de lo contrario, fracasará sin duda en sus objetivos.

Comenzando desde la administración, se extendió a partir del siglo XX, en el sector público y militar. Sus inicios como carrera profesional datan del año 1933 en Madrid, España.

El desarrollo de la gestión empresarial comienza desde que a la administración se le derivan varias ramas de innovación, gracias a la gran influencia que ha tenido.

La administración se ha basado, desde los antiguos egipcios a los comerciantes sumerios, en métodos organizativos de acuerdo a la iglesia y a las antiguas milicias.

Las empresas eran guiadas basándose en estos métodos sin importar que fuesen grandes o pequeñas, pero no se sentían obligadas a hacerle frente sistemáticamente a las aplicaciones de la administración.

Así, poco a poco, las innovaciones de la administración fueron creando extensiones base, tales como los números árabes y la aparición de la contabilidad. Estas áreas ya mencionadas proporcionaron un mejor planteamiento y el control de la organización cuantitativamente.

No fue hasta el siglo XIX cuando se crearon las primeras publicaciones sobre la administración, pero de una manera científica. Además, tuvo lugar la revolución industrial.

Otra tendencia de la gestión empresarial que aborda los procesos se conoce como la mejora continua ("Kaizen", en su versión japonesa). Esta es otra herramienta desde la cual se trabajan los procesos y se someten a una mejora continua.

La experiencia japonesa en sus métodos de trabajo en equipo y la participación de todo su personal en las mejoras empresariales popularizó las ventajas obtenidas en la revisión y reto continuo de los procesos empresariales.

El modelo de método sistemático o científico de mejora de procesos ha sido difundido por todo el mundo por Kaoru Ishikawa. Este autor se basa en el recorrido de una serie de pasos o etapas, desde la detección de un problema o de una posibilidad de mejora (el motor puede ser una serie de defectos detectados, o una nueva posibilidad tecnológica u organizativa), se realiza un estudio en busca de sus causas, de posibles perfeccionamientos o soluciones, la elección de la solución o conjunto de soluciones que parecen idóneas, hasta llegar a su implantación y a la medida de las mejoras conseguidas.

La gestión empresarial abarca un conjunto de técnicas que se aplican a la administración de una empresa, y del tamaño de la empresa dependerá la dificultad de la gestión del empresario o productor. El objetivo fundamental de la gestión del empresario es mejorar la productividad, sostenibilidad y competitividad, asegurando la viabilidad de la empresa en el largo plazo.








Los cambios tecnológicos que se han producido en la sociedad han ampliado el campo de la gestión. En las primeras etapas del desarrollo económico, las empresas se caracterizaban por realizar tareas repetitivas, fáciles de definir. En el taller o en la oficina, el personal sabía exactamente cuál era y seguiría siendo su misión. La labor del director gerente era supervisar la marcha de los trabajos en curso en un proceso reiterativo. El resultado se medía según lo que se producía, y se funcionaba bajo una fuerte disciplina y control riguroso. Había que satisfacer las expectativas de los propietarios de ganar dinero y esa era la mayor motivación. Esta simple interpretación de la gestión que existía entonces sigue aún en pie, como un eco del pasado. Algunos empresarios siguen comportándose como si nada hubiese cambiado. Pero son los zarpazos de la realidad los que han hecho que los empresarios tengan en cuenta muchos otros factores, porque los mercados ya no crecen en función de la oferta, y hay que luchar en mercados muy competitivos y a veces poco recesivos interiormente, sin contar con los problemas de competencia de las empresas foráneas. La automatización, la informática, las nuevas tecnologías de la información y las crecientes expectativas de la sociedad han puesto al descubierto muchas carencias de los directivos españoles. La naturaleza de la gestión se ha hecho más compleja para actuar en función de una serie de prioridades, como es la de conseguir beneficios constantes, por encima de todas ellas.

El gerente tiene una responsabilidad especial con sus subordinados, pero si aplica esta responsabilidad únicamente en términos de control y supervisión, no estará cumpliendo con ella. Tiene que establecer un sistema de interrelación. El personal deberá conocer con claridad qué se espera de ellos. El personal deberá participar directamente en la fijación de sus objetivos de trabajo. Esto propiciará la claridad y eficacia de la tarea que hay que desarrollar y hará que el subordinado se sienta más comprometido y dispuesto a colaborar. El personal deberá sentirse apoyado con los recursos físicos y humanos necesarios para lograr sus objetivos. El personal aportará y podrá desarrollar sus propios recursos personales para actuar con mayor eficacia. Por su parte, la empresa le ayudará a conseguirlo mediante el asesoramiento y los consejos permanentes e, incluso, con una formación adicional. El personal deberá recibir información coherente o comentarios críticos sobre su actuación. Si bien habrá que criticar a veces su actuación, esto le servirá de incentivo y no de amenaza coercitiva que pueda lesionar su autoestima. Conseguir estos objetivos en las relaciones personales y el respaldo sin límites de la dirección supone mayor recompensa que los meros incentivos económicos.

Para que una gestión determinada sea óptima y, por ende, dé buenos resultados no solamente deberá hacer mejor las cosas, sino que deberá mejorar aquellas cuestiones que influyen directamente en el éxito y eso será asequible mediante la reunión de expertos que ayuden a identificar problemas, arrojen soluciones y propongan nuevas estrategias, entre otras cuestiones.

La gestión de este tipo deberá considerar una serie de factores, entre ellos financieros, productivos y logísticos, por citar los más importantes. Los profesionales, individuos que se dedican a la gestión empresarial, deben sí o sí dominar todos estos condicionantes para poder triunfar en el tema y que la empresa que dirigen sea exitosa.

Debido a la relevancia de la que, hoy en día, dispone esta actividad dentro de las empresas, han proliferado las carreras que justo forman a profesionales en este asunto específico. Normalmente son las facultades de ciencias económicas y empresariales las que dictan este tipo de formación profesional. Ahora bien, no todos los factores que intervienen en la gestión empresarial se aprenden en el marco universitario formal; acompañando a la educación debe estar presente la experiencia que se ostente en el campo, y esta última es fundamental. Los conocimientos teóricos son importantísimos, pero la gestión empresarial, asimismo, atañe a otros tantos aspectos que están asociados a la planificación y a la toma de decisiones que están más bien vinculados a la práctica que se tenga en este campo, y ni hablar de la influencia de la personalidad que se demanda por parte de quienes tienen a cargo esta tarea, ya que se requieren una serie de condiciones de mando y de creatividad para poder llevarla a cabo de manera eficiente.

Existen cuatro funciones fundamentales que la administración de la empresa deberá cumplir para lograr una gestión eficiente que produzca buenos resultados: 



</doc>
<doc id="6782" url="https://es.wikipedia.org/wiki?curid=6782" title="Buenas prácticas">
Buenas prácticas

Por buenas o mejores prácticas se entiende un conjunto coherente de acciones que han rendido bien o incluso excelente servicio en un determinado contexto y que se espera que, en contextos similares, rindan similares resultados. Dichas "buenas prácticas" dependen de las épocas, de las modas y, por esto último, es posible que algunas resulten contradictorias entre ellas mismas.

Algunos consideran las mejores prácticas como un conjunto heterogéneo de términos o teorías, unas nuevas y otras que simplemente renombran prácticas administrativas que ya se utilizaban en la práctica profesional pero que nadie había presentado como propias. Entre estas teorías podemos mencionar: calidad total, justo a tiempo, estudio de referencia, reingeniería, externalización, redimensionamiento, gestión basada en actividades, gestión basada en el valor, gestión por objetivos, destrucción creativa, etc.

Otros, en cambio, reconocen que las mejores prácticas son sólo un buen comienzo, mejor que una hoja en blanco, pero que no reemplazan al sentido común y a la reflexión y que, mientras se usen de manera racional y coherente, pueden acelerar la puesta en servicio de mejoras en los procesos de las organizaciones.

Sus detractores dicen que la mayoría de estos términos son empleados por empresas consultoras como Accenture, McKinsey, Boston Consulting Group, Price Watherhouse, Deloitte & Touche, Stern Stewart. Ellas los comercializan y ellas mismas se encargan de convencer a las empresas para que los pongan en práctica. Muchas de estas teorías, afirman los detractores, resultan ser una moda pasajera que, impulsada por las grandes empresas consultoras, toma fuerza pero después de cierto tiempo cae en desuso tras quedar en evidencia sus limitaciones, o bien ante la aparición de una nueva moda.

Algunas de esas aseveraciones son en cierto grado ciertas. Sin embargo, esos mismos detractores reconocen que no quiere decir esto que todas sean un mero producto de la comercialización de las consultoras. Aplicadas con sentido común, pueden aportar soluciones a problemas reales.

Existe la Agencia Estatal de Evaluación de las Políticas Públicas y la Calidad de los Servicios , que es el órgano encargado, en este ámbito, de elaborar libros blancos conteniendo las mejores prácticas.


</doc>
<doc id="6783" url="https://es.wikipedia.org/wiki?curid=6783" title="Castúo">
Castúo

Se llama dialecto extremeño o a veces castúo al castellano hablado tradicionalmente en la comunidad autónoma española de Extremadura. Las variedades más diferenciadas de otros dialectos del castellano actualmente son consideradas por diversos autores como un idioma distinto, el extremeño o "estremeñu", aunque el límite entre lo que es "castellano" y lo que es "extremeño" es muy subjetivo. 

El castellano de Extremadura es un habla meridional de tránsito con el extremeño, se caracterizaría por compartir rasgos como algunas lexicalizaciones de conservación del grupo -mb- latino, algunas expresiones de genitivo partitivo del estilo "unos pocos de", el diminutivo en "-ino" (que no "-inu") y sobre todo los rasgos comunes con el habla urbana andaluza occidental distinguidora (ni ceceante ni seseante), incluyendo la aspiración de -s- y -z- implosiva, la elisión de -d- intervocálica, la aspiración de efe inicial latina y ciertos cambios de género en algunas palabras ("la caló"). La neutralización de -r- y -l- en posición implosiva, si existe, tiende a la -r- en unas hablas y a -l- en otras. La erre y la ele finales habitualmente se omiten (como en andaluz occidental o como en el habla altoextremeña de buena parte de las Hurdes: "superió", "comé", "fatá", "papé"). Existe cierto léxico particular característico, que tiende a perderse en algunos casos entre las nuevas generaciones. Por ejemplo sigue siendo frecuente el uso de la palabra "guarro" referida al cerdo en tanto que animal o la expresión "una mijina" (un poquito), que puede reforzarse convirtiéndose en "una mijinina" o "una mijirrinina". Los rasgos propios del castellano de Extremadura lo ponen en relación con el idioma extremeño, que constituye su sustrato lingüístico (encontramos términos como "barruntar" en el sentido de percibir un ruido, "privá" por boñiga, "afechar" en lugar de cerrar con llave, etcétera). El seseo sólo aparece en algunas localidades cercanas a Portugal y en Fuente del Maestre , igualmente por influencia de las hablas extremeñas tradicionales. Existen pequeños islotes de uso esporádico del artículo con el posesivo ("la mi cama") también en la provincia de Badajoz, incluso en lugares del extremo sur de esta, aunque ya en franca decadencia.

"Castúo" es un concepto impreciso para referirse a las hablas de Extremadura.

La denominación "castúo" fue acuñada por el poeta extremeño Luis Chamizo Trigueros, natural de Guareña, provincia de Badajoz, cuando en 1921 publicó su libro de poemas "El Miajón de los Castúos." En su obra, Chamizo define al "castúo" como "castizo, mantenedor de la casta de labradores que cultivaron sus propias tierras". En origen, el término se refiere pues al carácter tradicional del campesino extremeño, solo después adquirió su moderno significado lingüístico. 

Algunos autores distinguen el "castúo" como dialecto castellano hablado en Extremadura de la lengua asturleonesa extremeña (estremeñu), pero esta distinción es culta y no se da entre el pueblo, para el que "castúo" y "estremeñu" son normalmente sinónimos. De este modo, la palabra ha llegado a significar, a tenor de sus acepciones:


Con el tiempo, la denominación de "castúo" se ha hecho popular para denominar las hablas de Extremadura, tanto las que conforman el extremeño, como las que ya son español meridional de ligera influencia leonesa, tanto en la Alta como en la Baja Extremadura. El habla en que escribió Luis Chamizo puede considerarse como un extremeño suroriental literario escrito con ortografía castellana y de léxico muy reducido.

Desde las obras de José María Gabriel y Galán y Luis Chamizo, el castúo -o extremeño con distintos grados de castellanización y distintas ortografías- se ha usado por escrito configurando una creciente literatura vernácula, Cada vez son más los nuevos poetas y escritores que utilizan esta lengua como vehículo de cultura.

Entre los nuevos libros escritos en este habla destacan:

Como curiosidad destacable, se puede reseñar que en 2019 se tradujo uno de los cómics de Tintín al castúo.



 


</doc>
<doc id="6784" url="https://es.wikipedia.org/wiki?curid=6784" title="Almacén de datos">
Almacén de datos

En el contexto de la informática, un almacén de datos (del inglés "data warehouse") es una colección de datos orientada a un determinado ámbito (empresa, organización, etc.), integrado, no volátil y variable en el tiempo, que ayuda a la toma de decisiones en la entidad en la que se utiliza. Se usa para realizar informes (reports) y análisis de datos y se considera un componente fundamental de la inteligencia empresarial. Se trata, sobre todo, de un expediente completo de una organización, más allá de la información transaccional y operacional, almacenado en una base de datos diseñada para favorecer el análisis y la divulgación eficiente de datos (especialmente OLAP, "procesamiento analítico en línea"). El almacenamiento de los datos no debe usarse con datos de uso actual. Los almacenes de datos contienen a menudo grandes cantidades de información que se subdividen a veces en unidades lógicas más pequeñas dependiendo del subsistema de la entidad del que procedan o para el que sea necesario.

 fue uno de los primeros autores en escribir sobre el tema de los almacenes de datos, define un data warehouse (almacén de datos) en términos de las características del repositorio de datos:


Inmon defiende una metodología descendente (top-down) a la hora de diseñar un almacén de datos, ya que de esta forma se considerarán mejor todos los datos corporativos. En esta metodología los Data marts se crearán después de haber terminado el data warehouse completo de la organización.

 es otro conocido autor en el tema de los data warehouse, define un almacén de datos como: "Es una almacén de datos que extrae, limpia, conforma y entrega una fuente de datos dimensional para la consulta y el análisis". También fue Kimball quien determinó que un data warehouse no era más que: "la unión de todos los Data marts de una entidad". Defiende por tanto una metodología ascendente (bottom-up) a la hora de diseñar un almacén de datos.

Las definiciones anteriores se centran en los datos en sí mismos. Sin embargo, los medios para obtener esos datos, para extraerlos, transformarlos y cargarlos, las técnicas para analizarlos y generar información, así como las diferentes formas para realizar la gestión de datos son componentes esenciales de un almacén de datos. Muchas referencias a un almacén de datos utilizan esta definición más amplia. Por lo tanto, en esta definición se incluyen herramientas para extraer, transformar y cargar datos, herramientas para el análisis (inteligencia empresarial) y herramientas para gestionar y recuperar los metadatos.

En un almacén de datos lo que se quiere es contener datos que son necesarios o útiles para una organización, es decir, que se utiliza como un repositorio de datos para posteriormente transformarlos en información útil para el usuario. Un almacén de datos debe entregar la información correcta a la gente indicada en el momento óptimo y en el formato adecuado. El almacén de datos da respuesta a las necesidades de usuarios expertos, utilizando Sistemas de Soporte a Decisiones (DSS), Sistemas de información ejecutiva (EIS) o herramientas para hacer consultas o informes. Los usuarios finales pueden hacer fácilmente consultas sobre sus almacenes de datos sin tocar o afectar la operación del sistema.

En el funcionamiento de un almacén de datos son muy importantes las siguientes ideas:


Periódicamente, se importan datos al almacén de datos de los distintos sistemas de planeamiento de recursos de la entidad (ERP) y de otros sistemas de software relacionados con el negocio para la transformación posterior. Es práctica común normalizar los datos antes de combinarlos en el almacén de datos mediante herramientas de extracción, transformación y carga (ETL). Estas herramientas leen los datos primarios (a menudo bases de datos OLTP de un negocio), realizan el proceso de transformación al almacén de datos (filtración, adaptación, cambios de formato, etc.) y escriben en el almacén.

Los Data marts son subconjuntos de datos de un data warehouse para áreas específicas.

Entre las características de un data mart destacan:

Los cubos de información o cubos OLAP funcionan como los cubos de rompecabezas en los juegos, en el juego se trata de armar los colores y en el data warehouse se trata de organizar los datos por tablas o relaciones; los primeros (el juego) tienen tres dimensiones, los cubos OLAP tienen un número indefinido de dimensiones, razón por la cual también reciben el nombre de hipercubos. Un cubo OLAP contendrá datos de una determinada variable que se desea analizar, proporcionando una vista lógica de los datos provistos por el sistema de información hacia el data warehouse, esta vista estará dispuesta según unas dimensiones y podrá contener información calculada. El análisis de los datos está basado en las dimensiones del hipercubo, por lo tanto, se trata de un análisis multidimensional.

A la información de un cubo puede acceder el ejecutivo mediante "tablas dinámicas" en una hoja de cálculo o a través de programas personalizados. Las tablas dinámicas le permiten manipular las vistas (cruces, filtrados, organización, totales) de la información con mucha facilidad. Las diferentes operaciones que se pueden realizar con cubos de información se producen con mucha rapidez. Llevando estos conceptos a un data warehouse, este es una colección de datos que está formada por «dimensiones» y «variables», entendiendo como dimensiones a aquellos elementos que participan en el análisis y variables a los valores que se desean analizar.

Las dimensiones de un cubo son atributos relativos a las variables, son las perspectivas de análisis de las variables (forman parte de la tabla de dimensiones). Son catálogos de información complementaria necesaria para la presentación de los datos a los usuarios, como por ejemplo: descripciones, nombres, zonas, rangos de tiempo, etc. Es decir, la información general complementaria a cada uno de los registros de la tabla de hechos.

También llamadas “indicadores de gestión”, son los datos que están siendo analizados. Forman parte de la tabla de hechos. Más formalmente, las variables representan algún aspecto cuantificable o medible de los objetos o eventos a analizar. Normalmente, las variables son representadas por valores detallados y numéricos para cada instancia del objeto o evento medido. En forma contraria, las dimensiones son atributos relativos a las variables, y son utilizadas para indexar, ordenar, agrupar o abreviar los valores de las mismas. Las dimensiones poseen una granularidad menor, tomando como valores un conjunto de elementos menor que el de las variables; ejemplos de dimensiones podrían ser: “productos”, “localidades” (o zonas), “el tiempo” (medido en días, horas, semanas, etc.), ...

Ejemplos de variables podrían ser:
Ejemplos de dimensiones podrían ser:
Según lo anterior, podríamos construir un cubo de información sobre el índice de ventas (variable a estudiar) en función del producto vendido, la provincia, el mes del año y si el cliente está casado o soltero (dimensiones). Tendríamos un cubo de 4 dimensiones.

Uno de los componentes más importantes de la arquitectura de un almacén de datos son los metadatos. Se define comúnmente como "datos acerca de los datos", en el sentido de que se trata de datos que describen cuál es la estructura de los datos que se van a almacenar y cómo se relacionan.

El metadato documenta, entre otras cosas, qué tablas existen en una base de datos, qué columnas posee cada una de las tablas y qué tipo de datos se pueden almacenar. Los datos son de interés para el usuario final, el metadato es de interés para los programas que tienen que manejar estos datos. Sin embargo, el rol que cumple el metadato en un entorno de almacén de datos es muy diferente al rol que cumple en los ambientes operacionales. En el ámbito de los data warehouse el metadato juega un papel fundamental, su función consiste en recoger todas las definiciones de la organización y el concepto de los datos en el almacén de datos, debe contener toda la información concerniente a:

Los procesos de Extract, transform and load (ETL) son importantes ya que son la forma en que los datos se guardan en un almacén de datos (o en cualquier base de datos). Implican las siguientes operaciones:


Middleware es un término genérico que se utiliza para referirse a todo tipo de software de conectividad que ofrece servicios u operaciones que hacen posible el funcionamiento de aplicaciones distribuidas sobre plataformas heterogéneas. Estos servicios funcionan como una capa de abstracción de software distribuida, que se sitúa entre las capas de aplicaciones y las capas inferiores (sistema operativo y red). El "middleware" puede verse como una capa API, que sirve como base a los programadores para que puedan desarrollar aplicaciones que trabajen en diferentes entornos sin preocuparse de los protocolos de red y comunicaciones en que se ejecutarán. De esta manera se ofrece una mejor relación costo/rendimiento que pasa por el desarrollo de aplicaciones más complejas, en
menos tiempo.

La función del middleware en el contexto de los data warehouse es la de asegurar la conectividad entre todos los componentes de la arquitectura de un almacén de datos.

Para construir un Data Warehouse se necesitan herramientas para ayudar a la migración y a la transformación de los datos hacia el almacén. Una vez construido, se requieren medios para manejar grandes volúmenes de información. Se diseña su arquitectura dependiendo de la estructura interna de los datos del almacén y especialmente del tipo de consultas a realizar. Con este criterio los datos deben ser repartidos entre numerosos data marts. Para abordar un proyecto de data warehouse es necesario hacer un estudio de algunos temas generales de la organización o empresa, los cuales se describen a continuación:









Almacén de datos espacial es una colección de datos orientados al tema, integrados, no volátiles, variantes en el tiempo y que añaden la geografía de los datos, para la toma de decisiones. Sin embargo la componente geográfica no es un dato agregado, sino que es una dimensión o variable en la tecnología de la información, de tal manera que permita modelar todo el negocio como un ente holístico, y que a través de herramientas de procesamiento analítico en línea (OLAP), no solamente se posea un alto desempeño en consultas multidimensionales sino que adicionalmente se puedan visualizar espacialmente los resultados.

El almacén de datos espacial forma parte de un extensivo "Sistema de Información Geográfica para la toma de decisiones", este al igual que los SIG, permiten que un gran número de usuarios accedan a información integrada, a diferencia de un simple almacén de datos que está orientado al tema, el "Data warehouse" espacial adicionalmente es Geo-Relacional, es decir que en estructuras relacionales combina e integra los datos espaciales con los datos descriptivos. Actualmente es geo-objetos, esto es que los elementos geográficos se manifiestan como objetos con todas sus propiedades y comportamientos, y que adicionalmente están almacenados en una única base de datos Objeto-Relacional.

Los Data Warehouse Espaciales son aplicaciones basadas en un alto desempeño de las bases de datos, que utilizan arquitecturas Cliente-Servidor para integrar diversos datos en tiempo real. Mientras los almacenes de datos trabajan con muchos tipos y dimensiones de datos, muchos de los cuales no referencian ubicación espacial, a pesar de poseerla intrínsecamente, y sabiendo que un 80% de los datos poseen representación y ubicación en el espacio, en los "Data warehouse" espaciales, la variable geográfica desempeña un papel importante en la base de información para la construcción del análisis, y de igual manera que para un "Data warehouse", la variable tiempo es imprescindible en los análisis, para los Data warehouse espaciales la variable geográfica debe ser almacenada directamente en ella.

Hay muchas ventajas por las que es recomendable usar un almacén de datos. Algunas de ellas son:


Utilizar almacenes de datos también plantea algunos inconvenientes, algunos de ellos son:





</doc>
<doc id="6786" url="https://es.wikipedia.org/wiki?curid=6786" title="Chlorobia">
Chlorobia

Las bacterias verdes del azufre o Chlorobia constituyen un pequeño grupo de bacterias del filo Chlorobi que realizan la fotosíntesis anoxigénica. Son fotolitoautótrofas obligadas que usan sulfuro de hidrógeno (HS) o azufre (S) como donantes de electrones (por comparación, las plantas durante la fotosíntesis usan agua como donante de electrones y producen oxígeno). Las estructuras donde se almacenan los pigmentos fotosintéticos están unidas a la membrana y se conocen como clorosomas o vesículas clorobiales. Estos clorosomas contienen bacterioclorofila "c", "d" y "e".

Estas bacterias se encuentran en las zonas ricas en azufre y anaerobias de los lagos. Algunas de estas bacterias contienen vesículas que les permiten ajustar la profundidad para conseguir una cantidad óptima de luz y HS ya que estas bacterias son generalmente inmóviles (se conoce una especie que tiene un flagelo). Otras especies no tienen vesículas y se las encuentra en el fango rico en azufre en el fondo de los lagos y lagunas. Estas bacterias son bien diversas morfológicamente y se pueden presentar como bacilos, cocos y vibrios. Algunas crecen solas, otras en cadenas y pueden ser de color verde grama o marrón chocolate.

Una especie de bacteria verde del azufre ha sido encontrada viviendo en una fumarola de la costa de México a una profundidad de 2.500 metros bajo la superficie del Océano Pacífico. A esta profundidad, las bacterias, denominadas GSB1, viven del débil resplandor del respiradero termal puesto que ninguna luz del sol puede penetrar a tal profundidad. 

Las bacterias verdes del azufre se clasifican en la familia Chlorobiaceae que, al no estar estrechamente emparentada con ninguna otra, se incluye en su propio filo, Chlorobi. El grupo más próximo es Bacteroidetes.



</doc>
<doc id="6787" url="https://es.wikipedia.org/wiki?curid=6787" title="Metafísica">
Metafísica

La metafísica (del latín "metaphysica", y este del griego μετὰ [τὰ] φυσικά, «más allá de [la] naturaleza») es la rama de la filosofía que estudia la naturaleza, estructura, componentes y principios fundamentales de la realidad. Esto incluye la clarificación e investigación de algunas de las nociones fundamentales con las que entendemos el mundo, como entidad, ser, existencia, objeto, propiedad, relación, causalidad, tiempo y espacio.

Antes del advenimiento de la ciencia moderna, muchos de los problemas que hoy pertenecen a las ciencias naturales eran estudiados por la metafísica bajo el título de filosofía natural. Hoy la metafísica estudia aspectos de la realidad que son inaccesibles a la investigación empírica. Según Immanuel Kant, las afirmaciones metafísicas son juicios sintéticos a priori, que por principio escapan a toda experiencia sensible.

Aristóteles designó la metafísica como «primera filosofía». En la química se asume la existencia de la materia y en la biología la existencia de la vida, pero ninguna de las dos ciencias define la materia o la vida; solo la metafísica suministra estas definiciones básicas.

La ontología es la parte de la metafísica que se ocupa de investigar qué entidades existen y cuáles no, más allá de las apariencias. La metafísica tiene dos temas principales: el primero es la ontología, que en palabras de Aristóteles es la ciencia que estudia al ser en cuanto tal. El segundo es la teleología, que estudia los fines como causa última de la realidad. Existe, sin embargo, un debate que sigue aún hoy sobre la definición del objeto de estudio de la metafísica, y sobre si sus enunciados tienen propiedades cognitivas.

A lo largo de los siglos, muchos filósofos han sostenido de alguna manera u otra, que la metafísica es imposible. Esta tesis tiene una versión fuerte y una versión débil. La versión fuerte es que todas las afirmaciones metafísicas carecen de sentido o significado. Esto depende por supuesto de una teoría del significado. Ludwig Wittgenstein y los positivistas lógicos fueron defensores explícitos de esta posición. Por otra parte, la versión débil es que si bien las afirmaciones metafísicas poseen significado, es imposible saber cuáles son verdaderas y cuáles falsas, pues esto va más allá de las capacidades cognitivas del hombre. Esta posición es la que sostuvieron, por ejemplo, David Hume e Immanuel Kant. Por otra parte, algunos filósofos han sostenido que el ser humano tiene una predisposición natural hacia la metafísica. Kant la calificó de «necesidad inevitable», y Arthur Schopenhauer incluso definió al ser humano como «animal metafísico».

La palabra «metafísica» deriva del griego "μετὰ φύσις", que significa «más allá de la naturaleza o más allá de la física», proviene del título puesto por Andrónico de Rodas (Siglo I a. C.) a una colección de escritos de Aristóteles. Esto no implica que la metafísica haya nacido con Aristóteles, sino que es de hecho más antigua, dado que hay casos de pensamiento metafísico en los filósofos presocráticos. Platón estudió en diversos diálogos lo que es el ser, con lo que preparó el terreno a Aristóteles de Estagira, que elaboró lo que él llamaba una «filosofía primera», cuyo principal objetivo era el estudio del ser en cuanto tal, de sus atributos y sus causas.

El término «metafísica» proviene de la obra de Aristóteles compuesta por catorce volúmenes (rollos de papiro), independientes entre sí, que se ocupan de diversos temas generales de la filosofía. Estos libros son de carácter esotérico, es decir, Aristóteles nunca los concibió para la publicación. Por el contrario, son un conjunto de apuntes o notas personales sobre temas que pudo haber tratado en clases o en otros libros sistemáticos.

El peripatético Andrónico de Rodas al sacar la primera edición de las obras de Aristóteles ordenó estos libros detrás de los ocho libros sobre física ("μετὰ [τὰ] φυσικά"). De allí surgió el concepto de «metafísica», que en realidad significa: «aquello que en el estante está después de la física», pero que también de manera didáctica significa: «aquello que sigue a las explicaciones sobre la naturaleza» o «lo que viene después de la física», entendiendo «física» en su acepción antigua que se refería al estudio de la "φύσις", es decir, de la naturaleza y sus fenómenos, no limitados al plano material necesariamente.

En la Antigüedad la palabra «metafísica» no denotaba una disciplina particular concerniente al interior de la filosofía, sino el compendio de rollos de Aristóteles ya mencionado. Solo es a partir del siglo XIII que la metafísica pasa a ser una disciplina filosófica especial que tiene como objeto el ente en cuanto ente. Es hacia ese siglo cuando el conocimiento de las teorías aristotélicas se comienza a conocer en el Occidente latino gracias al influjo de pensadores musulmanes como el persa Avicena y el andalusí Averroes.

A partir de entonces la metafísica pasa a ser la más alta disciplina filosófica, llegando así hasta la Edad Moderna. Con el tiempo la palabra «metafísica» adquirió el significado de «difícil» o «sutil» y en algunas circunstancias se utiliza con un carácter peyorativo, pasando a significar «especulativo, dudoso o no científico». En este sentido, también la metafísica es considerada como un modo de reflexionar con demasiada sutileza en cualquier materia que discurriese entre lo oscuro y difícil de comprender.

En la Metafísica de Aristóteles se encuentran diversas definiciones de la metafísica como ciencia. La metafísica considerada como «aiteología» es la ciencia de las causas supremas (A, 1). Como ontología es la ciencia del ente en cuanto ente (G, 1). Como teología es la ciencia de las cosas divinas (E, 1) y como «useología» es la ciencia de la sustancia (Z, 1). A través de la historia las posiciones en cuanto a estas definiciones han sido diversas. De hecho, algunos consideran que en la Metafísica de Aristóteles se encuentran cuatro metafísicas distintas; mientras que otros piensan que las cuatro definiciones se integran para formar una sola metafísica. La metafísica encuentra su unidad de la siguiente manera: la ontología y la useología poseen universalidad de predicación, mientras que la ontología y la useología son universales por causalidad. De esta forma, el "subiectum" de la metafísica sería en el ente en cuanto ente, ahora bien el ente se dice primariamente de la sustancia, por ello el "subiectum" integra las ciencias universales por predicación. Los principios de la metafísica provienen de las ciencias universales por causalidad.

Para Immanuel Kant, «La metafísica es un conocimiento especulativo de la razón, enteramente aislado, que se alza por encima de las enseñanzas de la experiencia mediante meros conceptos (no como la matemática, mediante aplicación de los mismos a la intuición), y en donde, por lo tanto, la razón debe ser su propio discípulo.»

La Real Academia Española define a la metafísica como la «parte de la filosofía que trata del ser en cuanto tal, y de sus propiedades, principios y causas primeras.»

La metafísica pregunta por los últimos fundamentos del mundo y de todo lo existente. Su objetivo es lograr una comprensión teórica del mundo y de los principios últimos generales más elementales de lo que hay, porque tiene como fin conocer la verdad más profunda de las cosas, por qué son lo que son; y, aún más, por qué son.

Cuatro de las preguntas fundamentales de la metafísica son:


No solo se pregunta entonces por lo que hay, sino también por qué hay algo. Además aspira a encontrar las características más elementales de todo lo que existe: la cuestión planteada es si hay características tales que se le puedan atribuir a todo lo que es y si con ello pueden establecerse ciertas propiedades del ser.

Algunos de los conceptos principales de la metafísica son: ser, nada, existencia, esencia, mundo, espacio, tiempo, mente, Dios, libertad, cambio, causalidad y fin.

Algunos de los problemas más importantes y tradicionales de la metafísica son: el problema de los universales, el problema de la estructura categorial del mundo, y los problemas ligados al espacio y el tiempo.

La metafísica procede de distintas maneras:


La psicología racional, también llamada filosofía del hombre, psicología metafísica o psicología filosófica, se ocupa del alma o mente del hombre.

Ya desde los inicios de la filosofía en Grecia, con los llamados filósofos presocráticos, se aprecian los intentos de entender el universo todo a partir de un principio (originario) único y universal, el "αρχη" (arjé).

Parménides de Elea (siglo VI-V a. C.) es considerado el fundador de la ontología. Es él quien utiliza por primera vez el concepto de ser/ente en forma abstracta. Este saber, metafísico, comenzó cuando el espíritu humano se hizo consciente de que lo real sin más no es lo que nos ofrecen los sentidos, sino lo que se capta con el pensamiento. («Lo mismo es pensar y ser») Es lo que él llama «ser», y que caracteriza a través de una serie de determinaciones conceptuales que están al margen de los datos de los sentidos, como ingénito, incorruptible, inmutable, indivisible, uno, homogéneo, etc. Parménides expone su teoría con tres principios: «el ser (o el ente) es y el no-ser no es», «nada puede pasar del ser al no-ser y viceversa» y «lo mismo es el pensar que el ser» (esto último se refiere a que no puede existir lo que no puede ser pensado). A partir de su afirmación básica («el ser es, el no-ser no es») Parménides deduce que el ser es ilimitado, ya que lo único que podría limitarlo es el no-ser; pero como el no-ser no es, no puede establecer limitación alguna. Por lo tanto, según deducirá Meliso de Samos, el ser es infinito (ilimitado en el espacio) y eterno (ilimitado en el tiempo). La influencia de Parménides es decisiva en la historia de la filosofía y del pensamiento mismo. Hasta Parménides, la pregunta fundamental de la filosofía era: ¿de qué está hecho el mundo? (a lo que algunos filósofos habían respondido que el elemento fundamental era el aire, otros que era el agua, otros un misterioso elemento indeterminado, etc.) Parménides instaló al «ser» ("esse") en la escena como objeto principal del discurrir filosófico. El próximo paso decisivo lo dará Sócrates.

Sócrates (470-399 a. C.), en cambio, se centra en la moral. Su pregunta fundamental es: ¿qué es el bien? Sócrates creía que si se lograba extraer el concepto del bien se podía enseñar a la gente a ser buena (como se enseña la matemáticas, por ejemplo) y se acabaría así con el mal. Estaba convencido de que la maldad es una forma de ignorancia, doctrina llamada intelectualismo moral. Desarrolló la primera técnica filosófica que se conoce: la mayéutica. Consistía en preguntar y volver a preguntar sobre las respuestas obtenidas una y otra vez, profundizando cada vez más. Con ello pretendía llegar al «logos» o la razón final que hacía que una cosa fuera esa cosa y no otra. Este «logos» es el embrión de la «idea» de Platón, su discípulo.

Platón (427-347 a. C.) pone el punto central de la filosofía en la teoría de las Ideas. Platón observó que el "logos" de Sócrates era una serie de características que percibimos en los objetos (físicos o no) y están asociadas a él. Si a ese "logos" lo separamos del objeto físico y le damos existencia formal, entonces se llama «idea» (la palabra «idea» la introdujo Platón). En los diálogos platónicos aparece Sócrates preguntando por lo que es justo, valeroso, bueno, etc. La respuesta a estas preguntas presupone la existencia de ideas universales cognoscibles por todos los seres humanos que se expresan en estos conceptos. Es a través de ellas que podemos captar el mundo en constante transformación. Las ideas son el paradigma de las cosas. Su lugar está entre el ser y el no-ser. Son anteriores a las cosas, que participan (methexis) de ellas. En sentido estricto solo ellas son. Las cosas particulares que vemos solo representan copias más o menos exactas de las ideas. La determinación o definición de las ideas se obtiene a través del ejercicio dialógico riguroso, enmarcado en determinado contexto histórico y coyuntural, delimitando aquello en lo que se ha centrado la investigación (la idea). Con la teoría de las Ideas Platón pretende probar la posibilidad del conocimiento científico y del juicio imparcial. El hecho de que todos los seres humanos tengan la posibilidad de acceder a un mismo conocimiento, tanto en el campo de las matemáticas, como en el de la ética, lo explica a través de la teoría del «recuerdo» ("ἀνάμνησις"), según la cual recordamos las ideas eternas que conocimos antes de nuestro nacimiento. Con ello Platón explica la universalidad de la capacidad racional de todos los seres humanos, enfrentándose a algunos de sus contemporáneos que sostenían la incapacidad de acceder al conocimiento por parte de esclavos o pueblos no-helénicos, entre otros. La tradición postplatónica muchas veces entendió la teoría de las Ideas de Platón, en el sentido de que habría supuesto una existencia de las ideas separada de la existencia de las cosas. Esta teoría de la duplicación de los mundos, en la Edad Media condujo a la polémica sobre los universales.

Aristóteles (384-322 a. C.) nunca usó la palabra «metafísica» en su obra conocida como "Metafísica". Dicho título se atribuye al primer editor sistemático de la obra del estagirita, Andrónico de Rodas, que supuso que, por su contenido, los catorce libros que agrupó debían ubicarse después de la «física» y por esa razón usó el prefijo «"μετὰ"» (más allá de... o después de...) En su análisis del ente, Aristóteles va más allá de la materia, al estudiar las cualidades y potencialidades de lo existente para acabar hablando del «ser primero», el «motor inmóvil» y generador no movido de todo movimiento, que más tarde sería identificado con Dios. Para Aristóteles la metafísica es la ciencia de la esencia de los entes y de los primeros principios del ser. El ser se dice de muchas maneras y éstas reflejan la esencia del ser. En ese sentido elabora ser, independientemente de las características momentáneas, futuras y casuales. La "ousía" (generalmente traducido como sustancia) es aquello que es independiente de las características (accidentes), mientras que las características son dependientes de la "ousía". La ousía es lo que existe en sí, en contraposición al accidente, que existe en otro. Gramaticalmente o categorialmente, se dice que la sustancia es aquello a lo que se adscribe características, es decir, es aquello sobre lo cual se puede afirmar (predicar) algo. Aquello que se afirma sobre las sustancias son los predicados. A la pregunta de qué sería finalmente la esencia que permanece inmutable, la respuesta de Aristóteles viene a ser que la "ousía" es una forma determinante –el "eidos"- es el origen de todo ser, es decir, que por ejemplo en el "eidos" de Sócrates, lo que en su forma humana, determina su humanidad. Y también la que determina que siendo el hombre por naturaleza libre y no siendo el esclavo libre, determina que el esclavo sea parte constitutiva de su amo, es decir, que no sea solo esclavo de su amo en determinada coyuntura y desde determinada perspectiva, sino que sea esclavo por naturaleza.

En el mundo islámico, la llegada de la filosofía griega no fue directa, sino que tiene que ver con los cenobios cristianos en la península arábiga y los pertenecientes a ideologías consideradas heréticas que utilizaban la filosofía griega no como un fin, sino como un instrumento que les servía para sus especulaciones teológicas (como los monofisistas o los nestorianos). Es por el interés práctico en la medicina griega cuando empiezan a hacerse traducciones al persa que después pasarían tardíamente al árabe. Cabe mencionar que en árabe no existe el verbo «ser» y más difícilmente una construcción como «ser», que es un verbo convertido en sustantivo. La metafísica del mundo islámico quedó influenciada en gran medida por la metafísica de Aristóteles.

En el mundo cristiano, después del «redescubrimiento» de la "Metafísica" de Aristóteles a mediados del siglo XII, muchos escolásticos escribieron comentarios sobre este trabajo. El problema de los universales fue uno de los principales problemas involucrados durante ese período. Otros temas incluyen:


La metafísica se pasó a considerar la «reina de las ciencias» (Tomás de Aquino), aunque también hubo debate sobre la distinción y orden de jerarquía entre la metafísica y la teología, en especial en la escolástica. La cuestión de la distinción entre metafísica y teología también sería omnipresente en la filosofía moderna.

Los escolásticos medievales se propusieron la tarea de conciliar la tradición de la filosofía antigua con la doctrina religiosa (musulmana, cristiana o judía). Con base en el neoplatonismo tardío, la metafísica medieval se propone reconocer el «verdadero ser» y a Dios a partir de la razón pura.

Los temas centrales de la metafísica medieval son la diferencia entre el ser terrenal y el ser celestial (analogía "entis"), la doctrina de los trascendentales y las pruebas de la existencia de Dios. Dios es el fundamento absoluto del mundo, del cual no se puede dudar. Se discute si Dios ha creado el mundo de la nada (creación ex nihilo) y si es posible acceder a su conocimiento a través de la razón o solo a través de la fe. Inspirados en la teoría de la duplicación de los mundos atribuida a Platón su metafísica se manifiesta como una suerte de «dualismo» del «acá» y del «más allá», de la «mera percepción sensible» y del «pensar puro como conocimiento racional», de una «inmanencia» de la vida interior y una «trascendencia» del mundo exterior.

La tradición moderna divide la metafísica en: metafísica general u ontología —ciencia del ente en tanto ente— y metafísica especial, que se divide en tres ramas:


Esta clasificación, que fue propuesta entre otros por Christian Wolff, ha sido posteriormente discutida, pero sigue siendo considerada canónica.

El idealismo trascendental de Kant significó un «giro copernicano» para la metafísica. Su posición frente a la metafísica es paradigmática. Le atribuye ser un discurso de «palabras huecas» sin contenido real, la acusa de representar las «alucinaciones de un vidente», pero por otra parte recoge de ella la exigencia de universalidad. Kant se propuso fundamentar una metafísica «que se pueda presentar como ciencia». Para ello examinó primero la posibilidad misma de la metafísica. Para Kant las cuestiones últimas y las estructuras generales de la realidad están ligadas a la pregunta por el sujeto. A partir de este presupuesto dedujo que hay que estudiar y juzgar aquello que puede ser conocido por nosotros. A través de su criticismo se diferenció explícitamente de las posiciones filosóficas que tienen como objeto la pregunta sobre qué es el conocimiento. Se alejó así de las tendencias filosóficas imperantes, tales como el empirismo, el racionalismo y el escepticismo. También a través del criticismo marcó distancia del dogmatismo de la metafísica que -según Kant- se había convertido en una serie de afirmaciones sobre temas que van más allá de la experiencia humana. Intentó entonces llevar a cabo un análisis detallado de la facultad humana de conocer, es decir, un examen crítico de la razón pura, de la razón desvinculada de lo sensible ("Crítica de la razón pura", 1781-1787). Para ello es decisivo el presupuesto epistemológico de Kant de que al ser humano la realidad no se le presenta tal como es realmente (en sí), sino tal como se le aparece debido a la estructura específica de su facultad de conocimiento. Como el conocimiento científico también depende siempre de la experiencia, el hombre no puede emitir juicios sobre cosas que no están dadas por las sensaciones (tales como «Dios», «alma», «universo», «todo», etc.) Por ello Kant dedujo que la metafísica tradicional no es posible, porque el ser humano no dispone de la facultad de formar un concepto basándose en la experiencia sensible de lo espiritual, que es la única que permitiría la verificación de las hipótesis metafísicas. Como el pensar no dispone de ningún conocimiento de la realidad en este aspecto, estos asuntos siempre permanecerán en el ámbito de lo especulativo-constructivo. Entonces, por principio, no es posible según Kant decidir racionalmente sobre preguntas centrales tales como si Dios existe, si la voluntad es libre o si el alma es inmortal. Las matemáticas y la física pueden formular juicios sintéticos a priori y, por ello, alcanzar un conocimiento universal y necesario, un conocimiento científico.

Del idealismo trascendental de Kant surge el idealismo alemán —representado sobre todo por Fichte, Schelling y Hegel— que considera a la realidad como un acontecimiento espiritual en el que el ser real es superado, siendo integrado en el ser ideal. El idealismo alemán recoge el giro trascendental de Kant, es decir que, en vez de entender la metafísica como la búsqueda de la obtención del conocimiento objetivo, se ocupa de las condiciones subjetivas de posibilidad de tal conocimiento. Así, se plantea hasta qué punto el ser humano puede llegar a reconocer estas evidencias. Sin embargo, rechaza que el conocimiento se limite a la experiencia posible y a los meros fenómenos, y propone una superación de esta posición, volviendo a postulados metafísicos que puedan reclamar validez universal: «conocimiento absoluto» como se decía desde Fichte hasta Hegel. Si aceptamos que los contenidos del conocimiento solo valen en relación con el sujeto —como suponía Kant— y consideramos que esta perspectiva es absoluta, es decir, es la perspectiva de un sujeto absoluto, entonces el conocimiento válido para este sujeto absoluto también tiene validez absoluta. A partir de este planteamiento el idealismo alemán considera que puede superar la contradicción empírica entre sujeto y objeto, para poder captar lo absoluto.

Hegel sostiene que de una identidad pura y absoluta no puede surgir o entenderse una diferencia (esa identidad sería como «la noche, en la que todas las vacas son negras»): no explicaría la realidad en toda su diversidad. Por eso «la identidad de lo absoluto» debe entenderse como que está desde su origen ya que contiene en sí la posibilidad y la necesidad de una diferenciación. Esto implica que lo absoluto se realiza en su identidad por el plasmado y la superación de momentos no idénticos, esto es, la identidad dialéctica. A partir de este planteamiento Hegel desarrolla la "Ciencia de la lógica" considerado, tal vez, como el último gran sistema de la metafísica occidental.

Karl Marx y Friedrich Engels adoptaron una actitud antimetafísica en base a su concepción del materialismo dialéctico, que deriva de la dialéctica idealista de Hegel. Según este, solo la materia es real, junto con sus cambios. La dialéctica explica estas transformaciones, según la cual todos los proceso naturales y sociales ocurren por contradicción. Por ejemplo, el análisis de la mercancía en "El capital", el objeto mercantil es la “unidad contradictoria” de valor de uso y valor de cambio. Esta explicación pretende ser universal y válida tanto para la naturaleza como para la sociedad y el pensamiento. En su obra "Tesis sobre Feuerbach" concluye en la célebre tesis 11: "Los filósofos no han hecho más que interpretar de diversos modos el mundo, pero de lo que se trata es de transformarlo". Aunque algunos aspectos del pensamiento marxista pueden interpretarse como metafísica, el marxismo criticaría una determinada manera de hacer metafísica.

Friedrich Nietzsche considera que Platón es el iniciador del pensamiento metafísico y le hace responsable de la escisión en el ser que tendrá luego formas variadas pero constantes. La división entre mundo sensible y mundo inteligible, con su correlato cuerpo-alma, y la preeminencia del segundo asegurada por la teoría de las Ideas sitúa el mundo verdadero más allá de los sentidos. Esto deja fuera del pensar el devenir, aquello no apresable en la división sensible-inteligible por su carácter informe, y que también dejan escapar las subsiguientes divisiones aristotélicas, como sustancia-accidente y acto-potencia.

Martin Heidegger dijo que nuestra época es la del «cumplimiento de la metafísica», pues desde los inicios del pensamiento occidental se han producido unos determinados resultados que configuran un panorama del que el pensamiento metafísico no puede ya dar cuenta. El propio éxito de la metafísica ha conducido fuera de ella. Ante esto, la potencia del pensamiento consiste precisamente en conocer e intervenir sobre lo conocido. Pero el pensamiento metafísico carece ya de potencia ya que ha rendido sus últimos frutos.

Heidegger afirmó que la metafísica es «el pensamiento occidental en la totalidad de su esencia». La utilización del término «esencia» en esta definición, implica que la técnica para estudiar la metafísica como forma de pensamiento, es o debe ser la metafísica en el primer sentido antes indicado. Esto quiere decir que los críticos de la metafísica como esencia del pensamiento occidental, son conscientes de que no existe una «tierra de nadie» en que situarse, más allá de esa forma de pensamiento; solo el estudio atento y la modificación consciente y rigurosa de las herramientas proporcionadas por la tradición filosófica, pueden ajustar la potencia del pensamiento a las transformaciones operadas en aquello que la metafísica estudiaba: el ser, el tiempo, el mundo, el hombre y su conocer. Pero esa modificación supone a su vez un «salto» que toda la tradición del pensamiento ha escenificado, ha fingido o soñado dar a lo largo de su desarrollo. El salto fuera de la metafísica y por tanto, quizá la revocación de sus consecuencias.

Heidegger caracterizó el discurso metafísico por su impotencia para pensar la diferencia óntico-ontológica, es decir, la diferencia entre los entes y el ser. La metafísica refiere al ser el modelo de los entes (las cosas), pero aquel sería irreductible a éstos: los entes son, pero el ser de los entes no puede caracterizarse simplemente como estos. El ser es pensado como ente supremo, lo que le identifica con Dios; la pulsión ontoteológica es una constante en el pensamiento occidental. Para Heidegger la metafísica es el «olvido del ser», y la conciencia de este olvido debe abrir una época nueva, enfrentada a la posibilidad de expresar lo dejado al margen del pensamiento.

La filosofía analítica fue desde su nacimiento con autores como Russell y Moore muy escéptica respecto a la posibilidad de una metafísica sistemática tal y como se había defendido tradicionalmente. Esto se debe a que el nacimiento de la filosofía analítica se debiera principalmente a un intento de rebelión contra el idealismo neohegeliano entonces hegemónico en la Universidad británica. Sería a partir de los años veinte cuando el Círculo de Viena, ofrecería una crítica total a la metafísica como un conjunto de proposiciones carentes de significado por no cumplir con los criterios verificacionistas del significado. No obstante esta posición es hoy minoritaria en el panorama analítico, donde se ha recuperado el interés por ciertos problemas clásicos de la metafísica como el de los universales, la existencia de Dios y otros de tipo ontológico.

El postestructuralismo (Gilles Deleuze, Michel Foucault, Jacques Derrida) retoma la crítica de Nietzsche, y argumenta que lo no pensable en la metafísica es precisamente la «diferencia» en tanto tal. La diferencia, en el pensar metafísico, queda subordinada a los entes, entre los que se da como una «relación». La pretensión de «inscribir la diferencia en el concepto» transformando este y violentando para ello los límites del pensamiento occidental aparece ya como una pretensión que lleva a la filosofía más allá de la metafísica.





</doc>
<doc id="6788" url="https://es.wikipedia.org/wiki?curid=6788" title="Sonar">
Sonar

El sonar (del inglés "SONAR", acrónimo de "Sound Navigation And Ranging", ‘navegación por sonido’) es una técnica que usa la propagación del sonido bajo el agua principalmente para navegar, comunicarse o detectar objetos sumergidos.

El sonar puede usarse como medio de localización acústica, funcionando de forma similar al radar, con la diferencia de que en lugar de emitir ondas electromagnéticas emplea impulsos sonoros. De hecho, la localización acústica se usó en aire antes que el GPS, siendo aún de aplicación el SODAR (la exploración vertical aérea con sonar) para la investigación atmosférica. La señal acústica puede ser generada por piezoelectricidad o por magnetostricción.

El término «sonar» se usa también para aludir al equipo empleado para generar y recibir el sonido de carácter infrasonoro. Las frecuencias usadas en los sistemas de sonar van desde las intrasónicas a las extrasónicas (entre 20Hz y ), la capacidad del oído humano. Sin embargo, en este caso habría que referirse a un hidrófono y no a un sonar. El sonar tiene ambas capacidades: puede ser utilizado como hidrófono o como sonar.

Existen otros sonares que no abarcan el espectro del oído humano, (cazaminas); pueden comprender varias gamas de alta frecuencia, (80kHz o 350kHz), por ejemplo. Ganan en precisión a la hora de determinar el objeto, pero pierden en alcance.

Aunque algunos animales (como delfines y murciélagos) han usado probablemente el sonido para la detección de objetos durante millones de años, el uso por parte de humanos fue registrado por vez primera por Leonardo da Vinci en 1490. Se decía que se usaba un tubo metido en el agua para detectar barcos, poniendo un oído en su extremo. En el siglo XIX se usaron campanas subacuáticas como complemento a los faros para avisar del peligro a los marineros.

El uso de sonido para la «ecolocalización» submarina parece haber sido impulsado por el desastre del "Titanic" en 1912. La primera patente del mundo sobre un dispositivo de este tipo fue concedida por la Oficina Británica de Patentes al meteorólogo inglés Lewis Richardson un mes después del hundimiento del "Titanic" , y el físico alemán Alexander Behm obtuvo otra por un resonador en 1913. El ingeniero canadiense Reginald Fessenden construyó un sistema experimental en 1914 que podía detectar un iceberg a dos millas de distancia, si bien era incapaz de determinar en qué dirección se hallaba.

Durante la Primera Guerra Mundial, y debido a la necesidad de detectar submarinos, se realizaron más investigaciones sobre el uso del sonido. Los británicos emplearon pronto micrófonos subacuáticos, mientras el físico francés Paul Langevin, junto con el ingeniero eléctrico ruso emigrado Constantin Chilowski, trabajó en el desarrollo de dispositivos activos de sonido para detectar submarinos en 1915. Aunque los transductores piezoeléctricos y magnetostrictivos superaron más tarde a los electrostáticos que usaron, este trabajo influyó sobre el futuro de los diseños detectores. Si bien los transductores modernos suelen usar un material compuesto como parte activa entre la cabeza ligera y la cola pesada, se han desarrollado muchos otros diseños. Por ejemplo, se han usado películas plásticas ligeras sensibles al sonido y fibra óptica en hidrófonos (transductores acústico-eléctricos para uso acuático), mientras se han desarrollado el Terfenol-D y el PMN para los proyectores. Los materiales compuestos piezoeléctricos son fabricados por varias empresas, incluyendo Morgan Electro Ceramics.

En 1916, bajo el patrocinio del Consejo Británico de Invenciones e Investigaciones, el físico canadiense Robert Boyle se encargó del proyecto del sonar activo, construyendo un prototipo para pruebas a mediados de 1917. Este trabajo, para la División Antisubmarina, fue realizado en el más absoluto secreto, y usaba cristales de cuarzo piezoeléctricos para producir el primer aparato de detección subacuática de sonido activo factible del mundo. Mientras tanto, en el mismo laboratorio se encargaba Albert Beaumont Wood del desarrollo de sistemas de escucha pasiva.

Para 1918 tanto Francia como Gran Bretaña habían construido sistemas activos. Los británicos probaron su ASDIC (así eran conocidos los equipos de detección activa) en el HMS "Antrim" en 1920 y empezaron la producción de unidades en 1922. La 6ª Flotilla Destructora tuvo buques equipados con ASDIC en 1923. Un buque-escuela antisubmarino, el HMS "Osprey", y una flotilla de entrenamiento compuesta por cuatro buques se estableció en Isla de Portland en 1924. El "Sonar QB" estadounidense no llegó hasta 1931.

Con el inicio de la Segunda Guerra Mundial, la Marina Real británica tenía cinco equipos para diferentes clases de buques de superficie y otros para submarinos, incorporados en un sistema de ataque antisubmarino completo. La efectividad de los primeros ASDIC estaba limitada por el uso de las cargas de profundidad como arma antisubmarina. Esto exigía que el buque atacante pasase sobre el contacto sumergido antes de lanzar las cargas, lo que hacía perder el contacto sonar en los momentos previos al ataque. El ataque exigía, pues, disparar a ciegas, periodo en el que el comandante del submarino podía adoptar con éxito medidas evasivas. Esta situación se remediaba usando varios buques cooperando juntos y con la adopción de «armas de lanzamiento delantero», como el "Hedgehog" y más tarde el "Squid", que lanzaban las cargas a un blanco situado delante del atacante y por tanto aún en contacto ASDIC. Los desarrollos durante la guerra desembocaron en unos equipos ASDIC que usaban diferentes formas de onda, lo que permitía que los puntos ciegos fueran cubiertos continuamente. Más tarde se emplearon torpedos acústicos.

Al inicio de la Segunda Guerra Mundial la tecnología británica de sonar fue transferida a los Estados Unidos. La investigación sobre el sonar y el sonido submarino se amplió enormemente, particularmente en este país. Se desarrollaron muchos nuevos tipos de sonar militar, entre ellos las sonoboyas, el sonar sumergible y el de detección de minas. Este trabajo formó la base de los desarrollos de posguerra destinados a contrarrestar los submarinos nucleares. El sonar siguió desarrollándose en muchos países para usos tanto militares como civiles. En los últimos años la mayoría de los desarrollos militares han estado centrados en los sistemas activos de baja frecuencia.

En la Segunda Guerra Mundial Estados Unidos usó el término "SONAR" para sus sistemas, acrónimo acuñado como equivalente de "RADAR". En 1948, con la formación de la OTAN, la estandarización de señales llevó al abandono del término "ASDIC" en favor de "SONAR". 

El rendimiento de la detección, clasificación y localización de un sonar depende del entorno y del equipo receptor, además del equipo emisor en un sonar activo o del ruido radiado por el objetivo en un sonar pasivo.

El funcionamiento del sonar se ve afectado por las variaciones en la velocidad del sonido, especialmente en el plano vertical. El sonido viaja más lentamente en el agua dulce que en el agua salada, variando en función del módulo de elasticidad y la densidad de masa. El módulo de elasticidad es sensible a la temperatura, a la concentración de impurezas disuelta (normalmente la salinidad) y a la presión, siendo menor el efecto de la densidad. Según Mackenzie, la velocidad del sonido "c" (en m/s) en el agua del mar es aproximadamente igual a:

Donde "T" es la temperatura (en grados Celsius , para valores entre 2 y 30 °C), "S" la salinidad (en partes por mil, para valores de 25 a 40) y "D" la profundidad en m (para valores entre 0 y 8000m). Esta ecuación empírica es razonablemente precisa para los rangos indicados. La temperatura del océano cambia con la profundidad, pero entre 30 y 100m hay un cambio a menudo notable, llamado termoclina, que divide el agua superficial más cálida de las profundas más frías que constituyen el grueso del océano. Esto puede dificultar la acción del sonar, pues un sonido que se origine en un lado del termoclino tiende a curvarse o refractarse al cruzarlo. La termoclina puede estar presente en aguas costeras menos profundas, donde sin embargo la acción de las olas mezcla a menudo la columna de agua, eliminándolo. La presión del agua también afecta la propagación del sonido en el vacío, aumentando su viscosidad a presiones mayores, lo que hacen que las ondas sonoras se retracten alejándose desde la zona de mayor viscosidad. El modelo matemático de refracción se denomina Ley de Snell.

Las ondas sonoras que se radian hacia el fondo del océano se curvan de vuelta a la superficie en grandes arcos senoidales debido a la presión creciente (y por tanto mayor velocidad del sonido) con la profundidad. El océano debe tener al menos 1850m de profundidad para que las ondas sonoras devuelvan el eco del fondo en lugar de refractarse de vuelta a la superficie, reduciendo la pérdida del fondo el rendimiento. En las condiciones adecuadas estas ondas sonoras se concentrarán cerca de la superficie y serán reflejadas de vuelta al fondo repitiendo otro arco atx. Cada foco en la superficie se denomina zona de convergencia, formando un anillo en el sonar. La distancia y anchura de la zona de convergencia depende de la temperatura y salinidad del agua. Por ejemplo, en el Atlántico Norte las zonas de convergencia se encuentran aproximadamente cada 33 millas náuticas (61km), dependiendo de la época del año. Los sonidos que pueden oírse desde solo unas pocas millas en línea directa pueden ser también detectados cientos de millas más lejos. Con sonares potentes la primera, segunda y tercera zonas de convergencia son bastante útiles; más allá de ellas la señal es demasiado débil y las condiciones térmicas demasiado inestables, reduciendo la fiabilidad de las señales. La señal se atenúa naturalmente con la distancia, pero los sistemas de sonar modernos son muy sensibles, pudiendo detectar blancos a pesar de las bajas relaciones señal-ruido.

Si la fuente de sonido es profunda y las condiciones adecuadas, la propagación puede ocurrir en el «canal de sonido profundo». Este proporciona una pérdida de propagación extremadamente baja para un receptor en el canal, lo que se debe a que el sonido atrapado en el canal no tiene pérdidas en los límites. Propagaciones parecidas pueden ocurrir en la «cinta de superficie» en condiciones buenas. Sin embargo en este caso hay pérdidas por reflejo en la superficie.

En aguas poco profundas la propagación es generalmente por repetidos sonidos en la superficie y el fondo, pudiéndose producir pérdidas considerables.

La propagación del sonido también se ve afectada por la absorción del agua así como de la superficie y el fondo. Esta absorción cambia con la frecuencia, debiéndose a diferentes mecanismos en el agua marina. Por esto el sonar que necesita funcionar en distancias largas tiende a usar frecuencias bajas, de forma que se minimicen los efectos de la absorción.

El mar contiene muchas fuentes de ruido que interfieren con la señal deseada. Las principales fuentes de ruido se deben a las olas y la navegación. El movimiento del receptor por el agua también puede producir ruido de baja propagación, en función de sus decibelios.

Cuando se usa un sonar activo, se produce dispersión por los pequeños objetos del mar así como por el fondo y la superficie. Esto puede ser una fuente importante de interferencia activa que no ocurre en el sonar pasivo. Este efecto de dispersión es diferente del que sucede en la reverberación de una habitación, que es un fenómeno reflexivo. Una analogía es la dispersión de las luces de un coche en la niebla: un rayo de luz de una linterna potente puede penetrar la niebla, pero los faros son menos direccionales y producen un «borrón» en el que la reverberación devuelta domina. De forma similar, para superar la reverberación en el agua, un sonar activo necesita emitir una onda estrecha.

El blanco de un sonar, como un submarino, tiene dos características principales que influyen sobre el rendimiento del equipo. Para el sonar activo son sus características reflectoras, conocidas como «fuerza» del blanco. Para el sonar pasivo, la naturaleza del ruido radiado por el blanco. En general el espectro radiado consistirá en un ruido continuo con líneas espectrales, usadas para clasificarlo.

También se obtienen ecos de otros objetos marinos tales como ballenas, estelas, bancos de peces y rocas.

Los submarinos atacados pueden lanzar contramedidas activas para aumentar el nivel de ruido y crear un gran blanco falso. Las contramedidas pasivas incluyen el aislamiento de los dispositivos ruidosos y el recubrimiento del casco de los submarinos.

El sonar activo usa un emisor de sonido y un receptor. Cuando los dos están en el mismo lugar se habla de funcionamiento monoestático. Cuando el emisor y el receptor están separados, de funcionamiento biestático. Cuando se usan más emisores o receptores espacialmente separados, de funcionamiento multiestático. La mayoría de los equipos de sonar son monoestático, usándose la misma matriz para emisión y recepción, aunque cuando la plataforma está en movimiento puede ser necesario considerar que esta disposición funciona biestáticamente. Los campos de sonoboyas activas pueden funcionar multiestáticamente.

El sonar activo crea un pulso de sonido, llamado a menudo un «ping», y entonces oye la reflexión (eco) del mismo. Este pulso de sonido suele crearse electrónicamente usando un proyecto sonar formado por un generador de señal, un amplificador de potencia y un transductor o matriz electroacústica, posiblemente un conformador de haces. Sin embargo, puede crearse por otros medios, como por ejemplo químicamente, usando explosivos, o térmicamente mediante fuentes de calor. También puede crearse mediante el infrasonido.

Para calcular la distancia a un objeto se mide el tiempo desde la emisión del pulso a la recepción de su eco y se convierte a una longitud conociendo la velocidad del sonido. Para medir el rumbo se usan varios hidrófonos, midiendo el conjunto el tiempo de llegada relativo a cada uno, o bien una matriz de hidrófonos, midiendo la amplitud relativa de los haces formados mediante un proceso llamado conformación de haz. El uso de una matriz reduce la respuesta espacial de forma que para lograr una amplia cobertura se emplean sistemas multihaces. La señal del blanco (si existe) junto con el ruido se somete entonces a un procesado de señal, que para los equipos simples puede ser sólo una medida de la potencia. Se presenta entonces el resultado a algún tipo de dispositivo de decisión que califica la salida como señal o ruido. Este dispositivo puede ser un operador con auriculares o una pantalla, en los equipos más sofisticado un software específico. Pueden realizarse operaciones adicionales para clasificar el blanco y localizarlo, así como para medir su velocidad.

El pulso puede ser de amplitud constante o un pulso de frecuencia modulada ("chirp") para permitir la compresión de pulso en la recepción. Los equipos simples suelen usar el primero con un filtro lo suficientemente ancho como para cubrir posibles cambios Doppler debidos al movimiento del blanco, mientras los más complejos suelen usar la segunda técnica. Actualmente la compresión de pulso suele lograrse usando técnicas de correlación digital. Los equipos militares suelen tener múltiples haces para lograr una cobertura completa mientras los más simples sólo cubren un arco estrecho. Originalmente se usaba un único haz realizando el escaneo perimetral mecánicamente, pero esto era un proceso lento.

Especialmente cuando se usan transmisiones de una sola frecuencia, el efecto Doppler puede usarse para medir la velocidad radial del blanco. La diferencia de frecuencia entre la señal emitida y la recibida se mide y se traduce a una velocidad. Dado que los desplazamientos Doppler pueden deberse al movimiento del receptor o del blanco, debe tenerse la primera en cuenta para lograr un valor preciso.

El sonar activo se usa también para medir la distancia en el agua entre dos transductores (radioemisores) de sonar o una combinación de hidrófono y proyector. Cuando un equipo recibe una señal de interrogación, emite a su vez una señal de respuesta. Para medir la distancia, un equipo emite una señal de interrogación y mide el tiempo entre esta transmisión y la recepción de la respuesta. La diferencia de tiempo permite calcular la distancia entre dos equipos. Esta técnica, usada con múltiples equipos, puede calcular las posiciones relativas de objetos estáticos o en movimiento.

En época de guerra, la emisión de un pulso activo era tan comprometida para el camuflaje de un submarino que se consideraba una brecha severa de las operaciones.

Los emisores de sonar de alta potencia pueden afectar a la fauna marina, si bien no se sabe exactamente cómo. Algunos animales marinos como ballenas y delfines usan sistemas de ecolocalización parecidos a los del sonar activos para detectar a predadores y presas. Se teme que los emisores de sonar puedan confundir a estos animales.

Se ha sugerido que el sonar militar infunde pánico a las ballenas, haciéndoles emerger tan rápidamente como para sufrir algún tipo de síndrome de descompresión. Esta hipótesis fue planteada por vez primera en un ensayo publicado en la revista "Nature" en 2003, que informaba de lesiones agudas por burbujas de gas (indicativas de síndrome de descompresión) en ballenas encalladas poco después del inicio de maniobras militares junto a las Islas Canarias en septiembre de 2002.

En 2000 en la Bahamas un ensayo de la Armada de Estados Unidos de transmisiones sonar provocó el encallamiento de diecisiete ballenas, siete de las cuales fueron halladas muertas. La Armada asumió su responsabilidad en un informe que halló que las ballenas muertas habían sufrido hemorragias inducidas acústicamente en los oídos. La desorientación resultante probablemente llevó al encallamiento.

Un tipo de sonar de media frecuencia ha sido relacionado con muertes masivas de cetáceos en todo el mundo, y culpado por los ecologistas de dichas muertes. El 20 de octubre de 2005 se presentó una demanda en Santa Mónica (California) contra la Armada de Estados Unidos por violar en las prácticas de sonar varias leyes medioambientales, incluyendo la "National Environmental Policy Act", la "Marine Mammal Protection Act" y la "Endangered Species Act".

El sonar pasivo detecta sin emitir. Se usa a menudo en instalaciones militares, así mismo tiene aplicaciones científicas, como detectar la ausencia o presencia de peces en diversos entornos acuáticos.

El sonar pasivo cuenta con una amplia variedad de técnicas para identificar la fuente de un sonido detectado. Por ejemplos, los buques estadounidenses suelen contar con motores de corriente alterna de 60 Hz. Si los transformadores o generador se montan sin el debido aislamiento de la vibración respecto al casco o se inundan, el sonido de 60 Hz del motor puede ser emitido por el buque, lo que puede ayudar a identificar su nacionalidad, pues la mayoría de submarinos europeos cuentan con sistemas a 50 Hz. Las fuentes de sonido intermitentes (como la caída de una llave inglesa) también pueden detectarse con equipos de sonar pasivo. Recientemente, la identificación de una señal era realizada por un operador según su experiencia y entrenamiento, pero actualmente se usan ordenadores para este cometido.

Los sistemas de sonar pasivo pueden contar con una gran base de datos sónica, si bien la clasificación final suele ser realizada manualmente por el operador de sonar. Un sistema informático usa a menudo esta base de datos para identificar clases de barcos, acciones (por ejemplo, la velocidad de un buque, o el tipo de arma disparada), e incluso barcos particulares. La Oficina de Inteligencia Naval estadounidense publica y actualiza constantemente clasificaciones de sonidos.

El sonar pasivo suele tener severas limitaciones por culpa del ruido generado por los motores y la hélice. Por este motivo muchos submarinos son impulsados por reactores nucleares que pueden refrigerarse sin bombas, usando sistemas de convección silenciosos, o por células de combustible o baterías, que también son silenciosas. Los propulsores de los submarinos también se diseñan y construyen de forma que emitan el menor ruido posible. La propulsión a alta velocidad suele crear diminutas burbujas de aire, fenómeno que se conoce como cavitación y tiene un sonido característico.

Los hidrófonos del sonar pueden remolcarse detrás del barco o submarino para reducir el efecto del ruido generado por el propio agua. Las unidades remolcadas también combaten la termoclina, ya que puede ajustarse su altura para evitar quedar en esta zona.

La mayoría de los sonares pasivos usaban una representación bidimensional. La dirección horizontal de la misma era la marcación y la vertical la frecuencia, o a veces el tiempo. Otra técnica de representación era codificar con colores la información frecuencia-tiempo de la marcación. Las pantallas más recientes son generadas por ordenadores e imitan las típicas pantallas indicadoras de posición de los radares.

La guerra naval hace un uso extensivo del sonar. Se usan los dos tipos descritos anteriormente, desde varias plataformas: buques de superficie, aeronaves e instalaciones fijas. La utilidad de los sonares activos y pasivos depende de las características del ruido radiado por el blanco, generalmente un submarino. Aunque en la Segunda Guerra Mundial se usó principalmente el sonar activo, excepto por parte de los submarinos, con la llegada de los ruidosos submarinos nucleares se prefirió el sonar pasivo para la detección inicial. A medida que los submarinos se hacían más silenciosos se fue usando más el sonar activo.

El sonar activo es extremadamente útil dado que proporciona la posición exacta de un objeto. Su uso es sin embargo algo peligroso, dado que no permite identificar el blanco y cualquier buque cercano a la señal emitida la detectará. Eso permite identificar fácilmente el tipo de sonar (normalmente por su frecuencia) y su posición (por la potencia de la onda sonora). Más aún, el sonar activo permite al usuario detectar objetos dentro en un determinado alcance, pero también permite que otras plataformas detecten el sonar activo desde una distancia mucho mayor.

Debido a que el sonar activo no permite una identificación exacta y es muy ruidoso, este tipo de detección se usa desde plataformas rápidas (aviones y helicópteros) o ruidosas (la mayoría de buques de superficies), pero rara vez desde submarinos. Cuando un sonar activo se usa en superficie, suele activarse muy brevemente en periodos intermitentes, para reducir el riesgo de detección por el sonar pasivo de un enemigo. Así, el sonar activo suele considerarse un apoyo del pasivo. En las aeronaves el sonar activo se usa en sonoboyas desechables que se lanzan sobre la zona a patrullar o cerca de los contactos de un posible enemigo.

El sonar pasivo escucha los ruidos por lo que tiene ventajas evidentes sobre el activo. Generalmente tiene un alcance mucho mayor que el activo y permite la identificación del blanco. Dado que cualquier vehículo de motor hace algo de ruido, terminará siendo detectado, dependiendo sólo de la cantidad de ruido emitido y del presente en la zona, así como la tecnología usada. En un submarino, el sonar pasivo montado a proa detecta en unos 270º respecto al centro del buque, la matriz montada en el casco, unos 160º a cada lado, y la matriz de la torreta en los 360º. Las zonas ciegas se deben a la propia interferencia del buque. Cuando se detecta una señal en cierta dirección (lo que significa que algo hace ruido en dicha dirección, a lo que se llama detección de banda ancha) es posible enfocar y analizar la señal recibir (análisis de banda estrecha). Esto se suele hacer usando una transformada de Fourier para mostrar las diferentes frecuencias que forman el sonido. Dado que cada motor hace un ruido específico, es fácil identificar el objeto.

Otro uso del sonar pasivo es determinar la trayectoria del blanco. Este proceso se llama Análisis del Movimiento del Blanco (TMA, "Target Motion Analysis"), y permite calcular el alcance, curso y velocidad del blanco. El TMA se realiza marcando desde qué dirección procede el sonido en momentos diferentes, y comparando el movimiento con el del buque del propio operador. Los cambios en el movimiento relativo se analizan usando técnicas geométricas estándar junto con algunas asunciones respecto a los casos límite.

El sonar pasivo es furtivo y muy útil, pero requiere componentes muy sofisticados y caros (filtros de paso de banda, receptores, ordenadores, software de análisis, etcétera). Suele equiparse en barcos caros para mejorar la detección. Los buques de superficie lo usan eficazmente, pero es incluso mejor usado en submarinos y también se emplea en aviones y helicópteros.

Hasta hace poco, los sonares en barcos de superficie solían montarse sobre el casco, a los lados o en la proa. Pronto se determinó tras sus primeros usos que se necesitaba un medio de reducir el ruido de la navegación. Primero se usó lienzo montado en un marco, y luego protecciones de acero. Actualmente los domos suelen hacerse de plástico reforzado o goma presurizada. Estos sonares son principalmente activos, como por ejemplo el SQS-56.

Algunas características de los sonares de buques de superficie más modernos son las siguientes:
Un ejemplo es el más moderno sonar de la Armada Española, el LWHP53SN desarrollado por Indra Sistemas y Lockheed Martin instalado en la fragata Cristóbal Colón (F-105), que incorpora todas estas características.

Debido a los problemas del ruido de los barcos también se emplean sonares remolcados. Estos también tienen la ventaja de poder situarse a mayor profundidad. Sin embargo, existen limitaciones a su uso en aguas poco profundas. Un problema es que los cabrestantes necesarios para lanzar y recuperar estos sonares son grandes y caros. Un ejemplo de este tipo de sonares es el Sonar 2087 fabricado por Thales Underwater Systems.

Los torpedos modernos suelen incluir un sonar activo/pasivo, que puede usarse para localizar directamente el blanco, pero también para seguir estelas. Un ejemplo pionero de este tipo de torpedos es el Mark 37.

Las minas pueden incorporar un sonar para detectar, localizar y reconocer su blanco. Un ejemplo es la mina CAPTOR.

El sonar antiminas (MCM, "Mine Countermeasure") es un tipo especializado de sonar usado para detectar objetos pequeños. La mayoría de ellos se montan en el casco, siendo un ejemplo el Tipo 2093.

Los submarinos confían en el sonar mucho más que los barcos de superficie, que no pueden usarlo a gran profundidad. Estos equipos pueden montarse en el casco o ser remolcados. Además, son muy útiles en cuestiones oceanográficas.

Los helicópteros pueden usarse para la lucha antisubmarina desplegando campos de sonoboyas activas/pasivas o empleado un sonar sumergible, como el AQS-13. Los aviones convencionales también pueden lanzar sonoboyas, teniendo más autonomía y capacidad para ello. El proceso de los datos recogidos por estos equipos puede realizarse en la aeronave o en un barco. Los helicópteros también se han usado en misiones de contramedidas frente a las minas, usando sonares remolcados como el AQS-20A.

Pueden ser remolcadas o independientes. Un ejemplo pionero fue el Sieglinde alemán.

Los barcos y submarinos van equipados con sonares especiales para la comunicación submarina. Un estándar OTAN permite que los diferentes tipos interactúen. Un ejemplo de estos equipos es el Sonar 2008.Este es uno de los más importantes

Durante muchos años los Estados Unidos operó un gran conjunto de matrices de sonar pasivo en varios puntos de los océanos del mundo, llamado colectivamente SOSUS ("Sound Surveillance System", ‘sistema de vigilancia sonora’) y más tarde IUSS ("Integrated Undersea Surveillance System", ‘sistema integrado de vigilancia submarina’). Se cree que un sistema parecido fue operado por la Unión Soviética. Al ser utilizadas matrices montadas permanentemente en el fondo del océano, se situaban en lugares muy silenciosos para lograr grandes alcances. El procesamiento de señales se realizaba utilizando grandes computadores en tierra. Con el final de la Guerra Fría una matriz SOSUS ha sido destinada a uso científico.

El sonar puede usarse para detectar hombres-rana y otros buceadores. Esto puede ser necesario alrededor de barcos o en las entradas de los puertos. El sonar activo también puede usarse como mecanismo disuasorio. Un ejemplo de estos equipos es el "Cerberus".

Este sonar se diseña para detectar y localizar las transmisiones de sonares hostiles. Un ejemplo es el Tipo 2082 equipado en los submarinos de clase Vanguard.

La pesca es una importante industria sujeta a una demanda creciente, pero el volumen de capturas mundial cae como resultado de una mayor escasez de recursos. La industria se enfrenta a un futuro de consolidación mundial continua hasta que puede alcanzarse un punto de sostenibilidad. Sin embargo, la consolidación de las flotas pesqueras ha acarreado una creciente demanda de sofisticados equipos electrónicos de localización pesquera tales como sensores, emisores y sonares. Históricamente, los pescadores han usado muchas técnicas diferentes para localizar bancos de peces. Sin embargo, la tecnología acústica ha sido una de las fuerzas más importantes tras el desarrollo de los pesqueros comerciales modernos.

Las ondas sonoras viajan de forma diferente a través de los peces que por aguas limpias debido a que la vejiga natatoria rellena de aire de éstos tiene una densidad diferente a la del agua marina. Esta diferencia de densidad permite la detección de bancos de peces usando el sonido reflejado. Actualmente, los pesqueros comerciales dependen casi completamente de los equipos acústicos para detectar peces.

Compañías como Marport Canada, Wesmar, Furuno, Krupp y Simrad fabrican sonares e instrumentos acústicos para la industria pesquera. Por ejemplo, los sensores de redes toman varias medidas bajo el agua y transmiten la información hasta un receptor a bordo. Cada sensor va equipado con uno o más transductores acústicos dependiendo de su función concreta. Los datos se transmiten usando telemetría acústica y se reciben en un hidrófono montado en el casco. Las señales se procesan y muestran en un monitor de alta resolución.

Emitiendo ondas sonoras directamente hacia el fondo y registrando el eco de retorno es posible calcular la profundidad, dado que la velocidad del sonido en el agua es más o menos estable en un rango de profundidades pequeño. 

Se emplean equipos acústicos montados sobre las redes, que transmiten la información registrada por cable o telemetría acústica al buque pesquero. Así se sabe con exactitud la distancia de la red al fondo y la superficie, la cantidad de pescado dentro de la misma, y otros datos relevantes.

Se han desarrollado sonares para medir la velocidad del barco relativa al agua y al fondo marino.

Se han equipado pequeños sonares en ROVs y UUVs para permitir su funcionamiento en condiciones de baja visibilidad. Estos sonares se usan para explorar por delante del vehículo.

Las aeronaves se equipan con sonares que funcionan como boyas para permitir su localización en caso de un accidente en el mar.

Pueden usarse sonares para estimar la biomasa presente en una región acuática, en función del reflejo sonoro devuelto por ésta. La principal diferencia con los equipos de localización pesquera es que el análisis hidroacústico cuantitativo requiere que las medidas se realicen con un equipo lo suficientemente sensible y bien calibrado como para obtener medidas fiables.

Los equipos hidroacústicos proveen un método repetible y no invasivo de recoger datos continuos y de alta resolución (por debajo del metro) en secciones tridimensionales, lo que permite medir la abundancia y distribución de los recursos pesqueros.

Para seguir los movimientos de peces, ballenas, etcétera puede acoplarse a un animal un dispositivo acústico que emita pulsos a ciertos intervalos, posiblemente codificando, por ejemplo, la profundidad.

Un transductor acústico vertical montado en el fondo marino o sobre una plataforma puede usarse para realizar medidas del tono y moléculas de las olas. De esto pueden derivarse estadísticas de las condiciones en la superficie de una ubicación dada.

Se han desarrollado sonares de corto alcance especiales para permitir la medida de la velocidad del agua, al vacío.

Se han desarrollado sonares que pueden usarse para caracterizar el fondo marino: fango, arena, grava, limos, etcétera. Esto suele lograrse comparando los retornos directos y reflejados por el fondo.

Los sonares de barrido lateral pueden usarse para confeccionar datos de la topografía de una zona. Sonares de baja frecuencia como GLORIA han sido usados en la exploración de la plataforma continental mientras los de mayor frecuencia se emplean para exploraciones detalladas de zonas más pequeñas.

Se han desarrollado potentes sonares de baja frecuencia para permitir la caracterización de las capas superficiales del fondo marino.

Diversos sonares de apertura sintética han sido construidos en laboratorio y algunos han llegado a usarse en sistemas de búsqueda y eliminación de minas de grafito.

Detección de pecios y yacimientos subacuáticos y su localización en el fondo marino.



</doc>
<doc id="6790" url="https://es.wikipedia.org/wiki?curid=6790" title="Radar">
Radar

' 
El radar (término derivado del acrónimo inglés "radio detection and ranging", “detección de radio y rango ”) es un sistema que usa ondas electromagnéticas para medir distancias, altitudes, direcciones y velocidades de objetos estáticos o móviles como aeronaves, barcos, vehículos motorizados, formaciones meteorológicas y el propio terreno. Su funcionamiento se basa en emitir un impulso de radio, que se refleja en el objetivo y se recibe típicamente en la misma posición del emisor. A partir de este "eco" se puede extraer gran cantidad de información. El uso de ondas electromagnéticas con diversas longitudes de onda permite detectar objetos más allá del rango de otro tipo de emisiones (luz visible, sonido, etc.)

Entre sus ámbitos de aplicación se incluyen la meteorología, el control del tráfico aéreo y terrestre y gran variedad de usos militares.


En 1934 el GEMA ("La sociedad de aparatos electro-acústico y mecánico"), uno de cuyos fundadores fue Hans Hollmann, construye un magnetrón capaz de trabajar a 650 MHz. Ese fue el paso tecnológico que permitió el desarrollo del Freya, un radar de vigilancia aérea que trabajaba a 125 MHz con un alcance entre 80 y 150 millas. Era un radar para trabajar en superficie por sus dimensiones, por ello, una versión posterior fue el Seetakt que trabajaba a 375 MHz y tenía un alcance de 10 millas adaptado para ser montado en buques. Este radar fue utilizado en el verano de 1938 en la Guerra Civil Española. 

La competencia en la industria alemana de la época hizo que, en el año 1935, la empresa alemana Telefunken lanzara un radar de antena parabólica giratoria, antecesor del radar de alerta aérea Würzburg, radar de tiro de 560 MHz de trabajo y con deflector de 3m de diámetro.

El Freya y el Würzburg fueron la base de la defensa terrestre de los alemanes durante la Segunda Guerra Mundial, y el Seetakt pieza fundamental para la de detección a bordo de los buques de la Armada Alemana.
Al inicio de la Segunda Guerra Mundial Alemania decidió alistar a científicos e ingenieros en el frente, pensando que la guerra sería corta y satisfactoria, lo que hizo que no avanzara significativamente en esos años. En consecuencia quedó retrasada con respecto a sus adversarios, que siguieron avanzando.

El modelo de radar actual fue creado en 1935 y desarrollado principalmente en Inglaterra durante la Segunda Guerra Mundial por el físico Robert Watson-Watt. Supuso una notable ventaja táctica para la Real Fuerza Aérea británica en la Batalla de Inglaterra, cuando aún era denominado RDF ("Radio Direction Finding"). Aunque fue desarrollado con fines bélicos, en la actualidad cuenta con multitud de usos civiles, siendo la mejor herramienta para el control de tráfico aéreo.

En los momentos anteriores a la II Guerra Mundial, Robert Watson-Watt, físico y director del Laboratorio de Investigación de Radio y su ayudante, el físico Arnold Wilkins, estuvieron a cargo de la invención de un "rayo de la muerte" que sería utilizado en esa guerra. La idea de Watson-Watt era elevar la temperatura del piloto atacante a 41 °C aproximadamente para que, al provocarle fiebre, quedara incapacitado. 

Como lo escribió el propio Wilkins: 

Esta observación, hecha en enero de 1935, dio lugar una serie de hechos que culminaron con la invención del radar. Los hechos a los que Wilkins se refirió habían sido observados en muchos lugares y en todos se consideró esta perturbación como un estorbo que mucha gente había tratado de eliminar. De hecho, en 1932, la Oficina Postal Británica publicó un informe en el que sus científicos documentaron fenómenos naturales que afectaban la intensidad de la señal electromagnética recibida: tormentas eléctricas, vientos, lluvia y el paso de un aeroplano en la vecindad del laboratorio. Wilkins conoció este informe de manera accidental, conversando con la gente de la Oficina Postal, que se quejaba por la interferencia.

Cuando Wilkins sugirió la posibilidad de utilizar el fenómeno de interferencia de ondas de radio para detectar aviones enemigos, Watson-Watt lo comisionó inmediatamente para trabajar en el cálculo de los aspectos cuantitativos. 

Al terminar sus cálculos, a Wilkins le pareció increíble que el efecto deseado pudiera detectarse; revisó sus cálculos, no encontró ningún error y se los dio a Watson-Watt, quien los vio fantásticos y verificó los cálculos matemáticos. Al no encontrar error, envió los resultados. El hecho de que un rayo de la muerte no fuera factible no sorprendió, sin embargo atrajo la idea de poder detectar un avión.

Dos científicos del Naval Research Laboratory (NRL) Hoyt Taylor y L. Young dieron forma a las especulaciones de Marconi y las plasmaron en un experimento en el que transmitieron una señal de radio de onda continua a través del río Potomac detectando que al pasar los buques se producían alteraciones en la calidad de la señal recibida. Lograron perturbaciones con distancias de hasta tres millas. Observando esto, concluyeron con que se podría diseñar un elemento que detectara buques en el mar. 

Al mismo tiempo, la Armada de los EE. UU. se encontraba muy ocupada dotando a los buques de comunicaciones sin hilos. A pesar de esto, se continuó con su investigación a nivel científico en muchos campos. Es así que el NRL, en cooperación con el Carnegie Institute , durante el año 1925 investigó la reflexión de ondas en la ionosfera y la modulación por pulsos de la onda, de tal manera que conociendo el instante de salida de un pulso y midiendo su retardo se podría calcular la distancia del rebote. A partir de estas investigaciones se diseñó a principio de los años 30 el primer radar de impulsos, obteniéndose los primeros pulsos reflejados por aviones en diciembre de 1934. Aunque no fue hasta julio de 1936 cuando consiguieron que funcionara correctamente, debido a un error en el diseño del ancho de banda del receptor (demasiado estrecho). El radar trabajaba a 200 MHz con una anchura de pulso de 10µs. Este radar utilizaba una única antena en emisión y recepción pues incluía el primer duplexor, una novedad tecnológica que supuso una gran diferencia entre países durante varios años.

Las ondas electromagnéticas se dispersan cuando hay cambios significativos en las constantes dieléctricas o diamagnéticas. Esto significa que un objeto sólido en el aire o en el vacío (es decir, un cambio en la densidad atómica entre el objeto y su entorno) producirá dispersión de las ondas de radio, como las del radar. Esto ocurre particularmente en el caso de los materiales conductores como el metal y la fibra de carbono, lo que hace que el radar sea especialmente indicado para la detección de aeronaves. En ocasiones los aviones militares utilizan materiales con sustancias resistivas y magnéticas que absorben las ondas del radar, reduciendo así el nivel de reflexión. Estableciendo una analogía entre las ondas del radar y el espectro visible, estos materiales equivaldrían a pintar algo con un color oscuro.

La reflexión de las ondas del radar varía en función de su longitud de onda y de la forma del blanco. Si la longitud de onda es mucho menor que el tamaño del blanco, la onda rebotará del mismo modo que la luz contra un espejo. Si por el contrario es mucho más grande que el tamaño del blanco, lo que ocurre es que este se polariza (separación física de las cargas positivas y negativas) como en un dipolo (véase: Dispersión de Rayleigh). Cuando las dos escalas son similares pueden darse efectos de resonancia. Los primeros radares utilizaban longitudes de onda muy elevadas, mayores que los objetivos; las señales que recibían eran tenues. Los radares actuales emplean longitudes de onda más pequeñas (de pocos centímetros o inferiores) que permiten detectar objetos del tamaño de una barra de pan.

Las señales de radio de onda corta (3 kHz-30 MHz) se reflejan en las curvas y aristas, del mismo modo que la luz produce destellos en un trozo de cristal curvo. Para estas longitudes de onda los objetos que más reflejan son aquellos con ángulos de 90º entre las superficies reflectivas. Una estructura que conste de tres superficies que se juntan en una esquina (como la de una caja) siempre reflejará hacia el emisor aquellas ondas que entren por su abertura.

Este tipo de reflectores, denominados reflectores de esquina ("corner reflectors", ver imagen a la derecha), se suelen usar para hacer "visibles" al radar objetos que en otras circunstancias no lo serían (se suelen instalar en barcos para mejorar su detectabilidad y evitar choques). Siguiendo el mismo razonamiento, si se desea que una nave no sea detectada, en su diseño se procurará eliminar estas esquinas interiores, así como superficies y bordes perpendiculares a las posibles direcciones de detección. De ahí el aspecto extraño de los aviones "stealth" (avión furtivo). Todas estas medidas no eliminan por completo la reflexión debido a la difracción, especialmente para longitudes de onda grandes. Otra contramedida habitual es arrojar cables y tiras metálicas cuyo largo es media longitud de onda ("chaffs") con la idea de cegar al radar; son efectivas, si bien la dirección hacia la que se reflejan las ondas es aleatoria cuando lo óptimo sería dirigir la reflexión hacia el radar que se quiere evitar. El factor que da la medida de cuánto refleja un objeto las ondas de radio se llama "sección transversal de radar" ("σ"), traducción del inglés RCS ("Radar Cross Section").

La potencia "P" reflejada a la antena de recepción está dada por la ecuación radar:


</doc>
<doc id="6792" url="https://es.wikipedia.org/wiki?curid=6792" title="Teoría de la probabilidad">
Teoría de la probabilidad

La teoría de la probabilidad es una rama de las matemáticas que estudia los fenómenos aleatorios y estocásticos. Los fenómenos aleatorios se contraponen a los fenómenos deterministas, los cuales son resultados únicos y/o previsibles de experimentos realizados bajo las mismas condiciones determinadas, por ejemplo, si se calienta agua a 100 ºC a nivel del mar se obtendrá vapor. Los fenómenos aleatorios, por el contrario, son aquellos que se obtienen de experimentos realizados, otra vez, bajo las mismas condiciones determinadas pero como resultado posible poseen un conjunto de alternativas, por ejemplo, el lanzamiento de un dado o de una moneda.

La teoría de probabilidades se ocupa de asignar un cierto número a cada posible resultado que pueda ocurrir en un experimento aleatorio, con el fin de cuantificar dichos resultados y saber si un suceso es más probable que otro. 

Muchos fenómenos naturales son aleatorios, pero existen algunos como el lanzamiento de un dado, donde el fenómeno no se repite en las mismas condiciones, debido a que las características del material hace que no exista una simetría del mismo, así las repeticiones no garantizan una probabilidad definida. En los procesos reales que se modelizan mediante distribuciones de probabilidad corresponden a modelos complejos donde no se conocen "a priori" todos los parámetros que intervienen; ésta es una de las razones por las cuales la estadística, que busca determinar estos parámetros, no se reduce inmediatamente a la teoría de la probabilidad en sí.

En 1933, el matemático soviético Andréi Kolmogórov propuso un sistema de axiomas para la teoría de la probabilidad, basado en la teoría de conjuntos y en la teoría de la medida, desarrollada pocos años antes por Lebesgue, Borel y Frechet entre otros.

Esta aproximación axiomática que generaliza el marco clásico de la probabilidad, la cual obedece a la regla de cálculo de "casos favorables sobre casos posibles", permitió la rigorización de muchos argumentos ya utilizados, así como el estudio de problemas fuera de los marcos clásicos. Actualmente, la teoría de la probabilidad encuentra aplicación en las más variadas ramas del conocimiento, como puede ser la física (donde corresponde mencionar el desarrollo de las difusiones y el movimiento Browniano), o la economía (donde destaca el modelo de Black-Scholes para la valoración de activos financieros).

La teoría de la probabilidad se desarrolló originalmente a partir de ciertos problemas planteados en el contexto de juegos de azar. Inicialmente, no existía una teoría axiomática bien definida y las definiciones iniciales de probabilidad se basaron en la idea intuitiva de un cociente de ocurrencias:

donde "A" es un suceso cualquiera y:

Este tipo de definiciones si bien permitieron desarrollar un gran número de propiedades, no permitían deducir todos los teoremas y resultados importantes que hoy forman parte de la teoría de la probabilidad. De hecho el resultado anterior se puede demostrar rigurosamente dentro del enfoque axiomático de la teoría de la probabilidad, bajo ciertas condiciones.

La primera axiomatización completa se debió a Andréi Kolmogórov (quien usó dicho enfoque por ejemplo para deducir su "ley 0-1 para sucesos cola" y otros resultados relacionados con la convergencia de sucesiones aleatorias). La definición axiomática de la probabilidad se basa en resultados de la teoría de la medida y en formalizaciones de la idea de independencia probabilística. En este enfoque se parte de un espacio de medida normalizada formula_3 donde formula_4 es un conjunto llamado espacio de sucesos (según el tipo de problema puede ser un conjunto finito, numerable o no-numerable), formula_5 es una σ-álgebra de subconjuntos de formula_4 y formula_7 es una medida normalizada (es decir, formula_8). Los sucesos posibles se consideran como subconjuntos "S" de eventos elementales posibles: formula_9 y la probabilidad de cada suceso viene dada por la medida de dicho conjunto:

La interpretación de esta probabilidad es la frecuencia promedio con la que aparece dicho suceso si se considera una elección de muestras aleatorias sobre formula_4.

La definición anterior es complicada de representar matemáticamente ya que formula_4 debiera ser infinito. Otra manera de definir la probabilidad es de forma axiomática esto estableciendo las relaciones o propiedades que existen entre los conceptos y operaciones que la componen.

La probabilidad es la característica de un evento, que hace que existan razones para creer que este se realizará. 

La probabilidad p de que suceda un evento S de un total de n casos posibles igualmente probables es igual a la razón entre el número de ocurrencias h de dicho evento (casos favorables) y el número total de casos posibles n.

La probabilidad es un número (valor) que varia entre 0 y 1. Cuando el evento es imposible se dice que su probabilidad es 0, si el evento es cierto y siempre tiene que ocurrir su probabilidad es 1. 

La probabilidad de no ocurrencia de un evento está dada por q, donde:

Sabemos que p es la probabilidad de que ocurra un evento y q es la probabilidad de que no ocurra, entonces p + q = 1

Simbólicamente el espacio de resultados, que normalmente se denota por formula_4, es el espacio que consiste en todos los resultados que son posibles. Los resultados, que se denota por formula_13, etcétera, son elementos del espacio formula_4.

Como se ha adelantado anteriormente la definición axiomática de probabilidad es una extensión de la teoría de la medida, en la que se introducen la noción de independencia relativa. Este enfoque permite reproducir los resultados de la teoría clásica de la probabilidad además de resultados nuevos referidos a la convergencia de variables aleatorias. Además de los procesos estocásticos, el cálculo de Ito y las ecuaciones diferenciales estocásticas.

Dentro del enfoque axiomático es posible demostrar que la ley débil de los grandes números implica que se cumplirá que:

Esto permite justificar rigurosamente la ecuación suponiendo que:

Donde se interpreta formula_15 con probabilidad "p" y que formula_16 con proabilidad 1-"p".

Una variable aleatoria es una función medible

que da un valor numérico a cada suceso elemental formula_17. 

Este tipo de probabilidad, es aquel que puede tomar solo ciertos valores diferentes que son el resultado de la cuenta de alguna característica de interés. Más exactamente, un problema de probabilidad discreta es un problema definido por un conjunto de variables aleatorias que solo pueden tomar un conjunto finito o infinito numerable de valores diferentes:

donde:

Un problema de probabilidad continua es uno en el que aparecen variables aleatorias capaces de tomar valores en algún intervalo de números reales (y por tanto asumir un conjunto no numerable de valores), por lo que continuando con la notación anterior:

La distribución de probabilidad se puede definir para cualquier variable aleatoria "X", ya sea de tipo continuo o discreto, mediante la siguiente relación:

Para una variable aleatoria discreta esta función no es continua sino constante a tramos (siendo continua por la derecha pero no por la izquierda). Para una variable aleatoria general la función de distribución puede descomponerse en una parte continua y una parte discreta:

Donde formula_20 es una y formula_21 es una función constante a tramos.

La función de densidad, o densidad de probabilidad de una variable aleatoria absolutamente continua, es una función a partir de la cual se obtiene la probabilidad de cada valor que toma la variable definida como:

Es decir, su integral en el caso de variables aleatorias continuas es la distribución de probabilidad. En el caso de variables aleatorias discretas la distribución de probabilidad se obtiene a través del sumatorio de la función de densidad. La noción puede generalizarse a varias variables aleatorias.

La teoría de la probabilidad moderna incluye temas de las siguientes áreas:





</doc>
<doc id="6800" url="https://es.wikipedia.org/wiki?curid=6800" title="Hidra">
Hidra

El término Hidra o Hydra puede referirse a:



</doc>
<doc id="6801" url="https://es.wikipedia.org/wiki?curid=6801" title="Aragón">
Aragón

Aragón (en aragonés "Aragón"; en catalán "Aragó") es una comunidad autónoma del norte de España, resultante del reino histórico del mismo nombre y que comprende el tramo central del valle del Ebro, los Pirineos centrales y el sistema Ibérico. Está definida en su Estatuto de autonomía como nacionalidad histórica.

El Reino de Aragón, junto con el Principado de Cataluña, el Reino de Valencia, el Reino de Mallorca y otros territorios de Francia, Italia y Grecia conformaron durante siglos la histórica Corona de Aragón. En 1982 se constituyó la actual comunidad autónoma, compuesta por las provincias de Huesca, Teruel y Zaragoza, y articulada en treinta y dos comarcas y una delimitación comarcal. Su capital es la ciudad de Zaragoza, en la que se concentran en torno a la mitad de los 1 328 753 habitantes de Aragón (INE, 2020). Se sitúa en el puesto undécimo de las , a pesar de ser la cuarta por extensión. Esta diferencia se debe a que es también una de las cuatro comunidades con menor densidad de población. El 23 de abril se celebra la festividad de San Jorge, día de Aragón.

El producto interior bruto generado en Aragón durante el año 2016 fue de 34 686 536 miles de euros, con una tasa de variación en términos de volumen respecto al año anterior de 2,7 %, cinco décimas por debajo de la tasa de España (3,2 %). El PIB per cápita de Aragón del año 2016 fue de 26 328 euros con una tasa de variación respecto al año 2015 del 3,3 %. Aragón se sitúa 9,8 puntos porcentualues por encima del PIB per cápita de España.

Limita al norte con Francia (Occitania y Nueva Aquitania), por el oeste con Castilla-La Mancha, Castilla y León, La Rioja, Navarra y por el este con Cataluña y la Comunidad Valenciana. La comunidad cuenta con dos cadenas montañosas. El Pirineo concentra en la provincia de Huesca las mayores altitudes, con el Pico Aneto como techo de Aragón y de la cordillera. El Aneto cuenta con una altitud de 3404 metros sobre el nivel del mar. El sistema Ibérico limita con la meseta central y su pico más alto es el Moncayo, que, con 2313 metros sobre el nivel del mar, se alza entre las provincias de Zaragoza y Soria. La región alberga el parque nacional de Ordesa y Monte Perdido, situado en la comarca pirenaica de Sobrarbe. Creado en 1918, se trata del segundo parque nacional más antiguo de España.

En Aragón se hablan distintas variedades lingüísticas, clasificadas dentro de tres idiomas, el español, el aragonés y el catalán. El español, por ley, es la única lengua oficial y mayoritaria. El español aragonés se incluye entre las variantes septentrionales del español, con características propias sobre todo en el léxico y la entonación. Este tipo de español es predominante en la comunidad autónoma debido a la impronta del aragonés, lengua hablada anteriormente en todo el territorio. Actualmente se habla aragonés en algunos puntos del centro y norte de la provincia de Huesca y del extremo noroccidental de la provincia de Zaragoza, en especial en los valles pirenaicos. Según la Ley de Lenguas de Aragón, el aragonés se considera como lengua propia, original e histórica de Aragón, aunque no es oficial. El catalán se habla en la franja oriental de Aragón, y también se lo considera una lengua propia de la comunidad.

El escudo actual de Aragón se compone de los cuatro cuarteles y se atestigua por primera vez en 1499, consolidándose desde la Edad Moderna para arraigar decididamente en el siglo XIX y resultar aprobado, según precepto, por la Real Academia de la Historia en 1921.

El primer cuartel aparece a fines del siglo XV y conmemora, según interpretación tradicional, el legendario reino de Sobrarbe; en el segundo cuartel figura la denominada «Cruz de Íñigo Arista», innovación de Pedro IV el Ceremonioso (a partir de una interpretación anacrónica de la cruz que simbolizaba la religión de los reyes cristianos asturianos, navarros y aragoneses), que la tomó por armas de los antiguos reyes de Aragón, si bien históricamente no hubo en la península emblemas heráldicos (o «armas de señal», como se decía en la Edad Media) antes de la unión dinástica de 1137 de la Casa de Aragón con la de Barcelona; en el tercer cuartel aparece la Cruz de San Jorge cantonada de cuatro cabezas de moro (la llamada «Cruz de Alcoraz»), que se atestigua por vez primera en un sello de 1281 de Pedro III de Aragón y recordaría, según tradición surgida a partir del siglo XIV, la batalla en la que Pedro I y el futuro Alfonso I el Batallador tomaron Huesca y fue considerado en la Edad Moderna uno de los emblemas privativos del reino de Aragón; y en el cuarto está el emblema de las llamadas «barras de Aragón» o Señal Real de Aragón, el más antiguo de los emblemas heráldicos que forman parte del escudo actual, datado en la segunda mitad del siglo XII.

Este emblema de palos de gules y oro se usó en sellos, estandartes, escudos y pendones indistintamente, no siendo sino un emblema familiar que posteriormente denotó la autoridad como rey de Aragón hasta que, con el nacimiento del Estado moderno, comenzó a ser símbolo territorial.

La bandera actual se aprobó en 1984, con lo establecido en el Artículo 3 del Estatuto de Autonomía de Aragón, la bandera es la tradicional de las cuatro barras rojas horizontales sobre fondo amarillo junto con el escudo de Aragón desplazado hacia el asta.

Las barras de Aragón, elemento histórico común de las actuales cuatro comunidades autónomas que en su día estuvieron integradas en la Corona de Aragón, presente en el tercer cuartel del escudo de España.

El himno de Aragón fue regulado en 1989 con la música es del compositor aragonés Antón García Abril que combina la antigua tradición musical aragonesa con elementos musicales populares dentro de una concepción moderna. La letra fue elaborada por los poetas aragoneses Ildefonso Manuel Gil, Ángel Guinda, Rosendo Tello y Manuel Vilas y destaca dentro de su armazón poética, valores como libertad, justicia, razón, verdad, tierra abierta... que históricamente representan la expresión de Aragón como pueblo.

Además del himno oficial, el Canto a la libertad de José Antonio Labordeta es generalmente considerado el himno oficioso de la comunidad.

El Día de Aragón se celebra el 23 de abril y conmemora a San Jorge, patrón del Reino de Aragón desde el siglo XV. Aparece recogido en el Artículo 3 del Estatuto de autonomía de Aragón desde 1984. Se realizan actos institucionales como la entrega de los Premios Aragón por parte del Gobierno de Aragón o la composición de una bandera de Aragón floral, con la colaboración de los ciudadanos, en la plaza de Aragón de Zaragoza.

La superficie de Aragón es de 47 719,2 km² de los cuales 15 636,2 km² pertenecen a la provincia de Huesca, 17 274,3 km² a la provincia de Zaragoza y 14 808,7 km² a la provincia de Teruel. El total representa un 9,43 % de la superficie de España, siendo así la cuarta comunidad autónoma en tamaño por detrás de Castilla y León, Andalucía y Castilla-La Mancha. La "Encyclopaedia Britannica", en su edición de 1911, definía Aragón como una llanura central rodeada de cadenas montañosas.

Está situada en el noreste de la península ibérica, a una latitud ente los 39º y los 43º' N en la zona templada de la Tierra. Sus límites y fronteras son en el norte con Francia, las regiones de (Occitania y Nueva Aquitania), por el oeste con las comunidades autónomas de Castilla-La Mancha (provincias de Guadalajara y Cuenca), Castilla y León (provincia de Soria), La Rioja y Navarra y por el este con las comunidades autónomas de Cataluña (provincias de Lérida y Tarragona) y Comunidad Valenciana (provincias de Castellón y Valencia).

La orografía de la comunidad tiene como eje central el valle del Ebro (con alturas entre 150 y 300 metros aprox.) el cual transita entre dos somontanos, el pirenaico y el ibérico, preámbulos de dos grandes formaciones montañosas, el Pirineo al norte y el Sistema Ibérico al sur; la Comunidad cuenta con los picos más altos de ambas cadenas montañosas, el Aneto y el Moncayo respectivamente.

El Pirineo aragonés se encuentra en el norte de la provincia de Huesca y se dispone longitudinalmente en tres grandes unidades: Alto Pirineo, Depresión Intrapirenaica y Sierras Exteriores. El Alto Pirineo está formado a su vez por el Pirineo axial y las Sierras Interiores.

En el Pirineo axial están los materiales más antiguos: granitos, cuarcitas, pizarras y calizas, y contiene las máximas alturas de la cadena montañosa: el Aneto (3404 msnm), La Maladeta (3309 msnm) y el Perdiguero (3221 msnm). El Prepirineo interior, compuesto de rocas más modernas (calizas) también tiene grandes montañas como Monte Perdido (3355 msnm), Collarada (2886 msnm) y Tendeñera (2853 msnm).

Los principales valles pirenaicos están formados por los ríos que ahí nacen, que son:


La depresión intrapirenaica es un amplio corredor perpendicular. Su tramo mejor representado es el Canal de Berdún. El límite meridional de la depresión corresponde a los enérgicos relieves de San Juan de la Peña (1552 msnm) y Peña Oroel (1769 msnm), modelados sobre conglomerados de la Formación Campodarbe.

Las sierras exteriores prepirenaicas se encuentran en el somontano oscense y constituyen la unidad más meridional de los Pirineos; formadas por materiales predominantemente calcáreos, alcanzan alturas entre los 1500 y los 2000 metros. Destaca la sierra de Guara, una de las sierras más importantes del prepirineo español, su cima, el tozal de Guara llega a los 2077 msnm. Destacan por su belleza los Mallos de Riglos, cerca de la localidad de Ayerbe.

Se extiende una amplia llanura, después de pasar el somontano, correspondiente a la depresión del Ebro. Al suroeste se encuentra la sierra de Alcubierre (811 msnm) una de las típicas muelas de la depresión. La depresión del Ebro es una fosa tectónica rellena de materiales sedimentarios, acumulados en la era terciaria en series horizontales. En el centro se depositaron materiales finos como arcillas, yesos y calizas. Al sur del Ebro han quedado las muelas de Borja y de Zaragoza.

El Sistema Ibérico aragonés se divide entre las provincias de Zaragoza y de Teruel. Es un conjunto de sierras sin unidad estructural clara, que puede dividirse en dos zonas: Sistema Ibérico del Jalón y Sistema Ibérico turolense. En el primero destaca el Moncayo con 2314 msnm, formado por cuarcitas y pizarras paleozoicas, en parte recubiertas por calizas mesozoicas; al sureste del Moncayo el Sistema Ibérico desciende de altura. El segundo está formado por terrenos elevados (de 1000 a 2000 msnm por lo general), pero aplanados y macizos. Al suroeste de la depresión se alcanzan las cumbres de la sierra de Albarracín por encima de los 1800 msnm, al sureste se superan los 2000 msnm en la sierra de Javalambre y por último se llega a la sierra de Gúdar (2024 msnm) de transición al Maestrazgo.

Aunque el clima de Aragón puede considerarse, en general, como un mediterráneo continental, su irregular orografía hace que se creen varios climas o microclimas a lo largo y ancho de toda la comunidad. Desde el de alta montaña de los Pirineos centrales al norte, con hielos perpetuos (glaciares), hasta el de zonas esteparias o semidesérticas, como los Monegros, pasando por el clima continental intenso de la zona de Teruel-Daroca.

Las características principales del clima aragonés son:


Las temperaturas medias son muy dependientes de la altura. En el valle del Ebro los inviernos son relativamente moderados, aunque las heladas son muy comunes y la sensación térmica puede disminuir mucho con el cierzo, las temperaturas en verano pueden llegar cerca de los 40 °C. En las zonas de montaña los inviernos son largos y rigurosos, las temperaturas medias pueden ser hasta 10 °C más bajas que en el valle.

Dos son los vientos más importantes de Aragón: el cierzo del norte y el bochorno de levante. El primero es un viento muy frío y seco que recorre el valle del Ebro de noroeste a sureste y que puede presentar gran fuerza y velocidad. El segundo es un viento cálido, más irregular y suave procedente del sur-este.

La vegetación sigue las oscilaciones del relieve y del clima. Hay una gran variedad, ya sea vegetación silvestre o cultivos humanos. En las zonas altas se pueden encontrar bosques (pinos, abetos, hayas, robles), matorrales y prados, mientras que las zonas del valle del Ebro la encina y la sabina son los árboles más numerosos, aparte de las tierras explotadas para uso agrícola.

La mayor parte de los ríos aragoneses son afluentes del Ebro, que es el más caudaloso de España y divide en dos a la comunidad. De los afluentes de la margen izquierda del río, es decir los ríos con origen en el pirineo, destacan el río Aragón, que nace en Huesca pero desemboca en Navarra, el Gállego y el Cinca, el cual se une al Segre justo antes de desembocar en el Ebro a la altura de Mequinenza, en el conocido como "Aiguabarreig", conformando una de las mayores confluencias fluviales de toda Europa. En la margen derecha destacan el Jalón, el Huerva y el Guadalope.

En el cauce del río Ebro, cerca del límite con Cataluña, se sitúa el embalse de Mequinenza, de 1530 hm³ y una longitud de unos 110 km; es conocido popularmente como el “Mar de Aragón”. Mención aparte dentro de la hidrografía merecen los pequeños lagos de montaña pirenaicos llamados ibones. Estos lagos, de gran belleza paisajística, tienen su origen en la última glaciación y se suelen encontrar por encima de los 2000 msnm.

Cabe destacar a su vez que la comunidad autónoma pertenece a tres confederaciones hidrográficas: la ya citada del Ebro, la del Tajo (que nace en la sierra de Albarracín) y la del Júcar que tiene como principal río en esta comunidad al Turia.

En Aragón los espacios naturales protegidos se gestionan mediante la Red Natural de Aragón, una entidad creada en 2004 para proteger todos los elementos con valor ecológico, paisajístico y cultural y a la vez coordinar y establecer normas comunes que contribuyan a su conservación y a un uso sostenible. En esta entidad se integran los parques nacionales, parques naturales, reservas naturales, las reservas de la biosfera y demás espacios naturales protegidos que hayan sido declarados por la comunidad autónoma, el Convenio de Ramsar o la Red Natura 2000.

Dentro de los espacios protegidos se encuentra el único parque nacional de Aragón: el parque nacional de Ordesa y Monte Perdido, el segundo parque nacional creado en España, en 1918, se encuentra en los Pirineos en la comarca del Sobrarbe, ocupa una extensión de 15 608 ha, aparte de los 19 679 ha de la zona periférica de protección. Actualmente también goza de otros figuras de Protección como la Reserva de la Biosfera de Ordesa-Viñamala y está catalogado como Patrimonio de la Humanidad por la UNESCO.

Además hay cuatro parques naturales: el parque natural del Moncayo con una extensión de 11 144 ha, el parque natural de la Sierra y Cañones de Guara con 47 453 ha y 33 286 ha de zona periférica de protección, el parque natural de Posets-Maladeta con 33 440,60 ha y 5290,20 ha de zona periférica de protección, y el parque natural de los Valles Occidentales con 27 073 ha y 7335 ha de zona periférica de protección.

Se encuentran también tres reservas naturales, cinco monumentos naturales y tres paisajes protegidos.

La Red Natura 2000 está formada por las Zonas Especiales de Conservación (ZEC) y las Zonas de Especial Protección para las Aves (ZEPA). Hoy en día la Red Natura 2000 en Aragón está constituida por 201 espacios, lo que supone 13 612 km² y el 28 % de su territorio con espacios como el Aiguabarreig Ebro-Segre-Cinca en Mequinenza, la Laguna de Sariñena o las estepas de Belchite.

Aragón, ocupando el noreste de la península ibérica ha servido de puente entre el mar Mediterráneo, el centro peninsular y las costas del Cantábrico. La presencia humana en las tierras que hoy forman la comunidad autónoma datan de hace varios milenios, pero el actual Aragón, como muchas de las actuales nacionalidades históricas, se formaron durante la Edad Media.

Los más antiguos testimonios de vida humana en las tierras que hoy componen Aragón, se remontan a la época de las glaciaciones, en el Pleistoceno, hace unos 600 000 años. Esta población dejó la industria Achelense que encontró sus mejores armas en los bifaces de sílex o los hendedores de cuarcita. En el Paleolítico Superior aparecieron dos nuevas culturas: Solutrense y Magdaleniense. El Epipaleolítico se centró en el Bajo Aragón, ocupando la época entre el séptimo y el quinto milenio.

En la primera mitad del quinto milenio antes de Cristo se encuentran restos neolíticos en las Sierras Exteriores oscenses y en el Bajo Aragón. El Eneolítico se caracterizó en la provincia de Huesca presentando dos núcleos megalíticos importantes: el Prepirineo de las Sierras Exteriores y los altos valles pirenaicos.

El Bronce Final comienza en Aragón en torno al 1100 a. C. con la llegada de la cultura de los campos de urnas. Se trata de gentes indoeuropeas, con un supuesto origen en el Centro de Europa, que incineran a sus muertos colocando las cenizas en una urna funeraria. Existen ejemplos en la Cueva del Moro de Olvena, la Masada del Ratón de Fraga, Palermo y el Cabezo de Monleón en Caspe aunque destaca especialmente yacimiento de Castellets en Mequinenza que es el único de todo Aragón en el que se han encontrado conjuntamente necrópolis de inhumación e incineración. Parte de las excavaciones de este último yacimiento se pueden ver en el Museo de Zaragoza. Desde el punto de vista metalúrgico parece existir un auge dado el aumento de moldes de fundición que se localizan en los poblados.

La Edad del Hierro es la más importante, puesto que a lo largo de los siglos que dura se constituye el verdadero sustrato de la población histórica aragonesa. La llegada de centroeuropeos durante la Edad del Bronce por el Pirineo hasta alcanzar la zona bajoaragonesa, supuso una importante aportación étnica que preparó el camino a las invasiones de la Edad del Hierro.

Las aportaciones mediterráneas supusieron una actividad comercial que va a constituir un poderoso estímulo para la metalurgia del hierro, fomentando la modernización del utillaje y del armamento indígena, sustituyendo el antiguo bronce por el hierro. Hay presencia de productos fenicios, griegos y etruscos.

En el siglo a.C. existen seis grupos con distinta organización social: vascones, suessetanos, sedetanos, iacetanos, ilergetes y celtíberos citeriores. Son grupos iberizados con tendencia a la estabilidad, fijando su hábitat en poblados duraderos, con viviendas que evolucionan hacia modelos más perdurables y estables. Hay en Aragón muchos ejemplos, entre los que destacan Cabezo de Monleón en Caspe, Puntal de Fraga, Roquizal del Rullo o Loma de los Brunos.
El tipo de organización social estuvo basado en el grupo familiar, constituido por cuatro generaciones. Sociedades autosuficientes en las que la mayor parte de la población se dedicó a actividades agrícolas y ganaderas. En el ámbito ibérico el poder fue monárquico, ejercido por un rey; existía una asamblea democrática con participación de la población masculina.
Existieron diferenciaciones sociales visibles y estatutos jurídico-políticos establecidos.

Los romanos llegaron y progresaron con facilidad hacia el interior. En el reparto territorial que hizo Roma de Hispania, el actual Aragón quedó incluida en la Hispania Citerior. En el año 197 a. C., Sempronio Tuditano es el pretor de la Citerior y hubo de hacer frente a un levantamiento general en sus territorios que terminó con la derrota romana y la propia muerte de Tuditano. Ante estos hechos el Senado envió al cónsul Marco Porcio Catón con un ejército de 60 000 hombres. Los pueblos indígenas de la zona estaban sublevados, menos los ilergetes que negociaron la paz con Catón. Hubo diferentes levantamientos de los pueblos ibéricos contra los romanos, en 194 a. C. ve un levantamiento general con eliminación de la mitad del ejército romano, en 188 a. C. Manlio Acidino, pretor de la Citerior, debe enfrentarse en Calagurris con los celtíberos, en el 184 a. C. Terencio Varrón lo hizo con los suessetanos, a los que tomó la capital, Corbio.

En el siglo a.C. Aragón fue escenario de la guerra civil para tomar el poder de Roma donde el gobernador Quinto Sertorio hizo de Osca (Huesca) la capital de todos los territorios controlados por ellos.

Ya en el , el hoy territorio aragonés pasó a formar parte de la provincia Tarraconensis y se produjo la definitiva romanización del mismo creándose calzadas y refundándose antiguas ciudades celtíberas e íberas como Caesaraugusta (Zaragoza), Turiaso (Tarazona), Osca, (Huesca) o Bilbilis (Calatayud).

A mediados del comenzó la decadencia del Imperio romano. Entre los años 264 y 266 los francos y los alamanes, dos pueblos germánicos que pasaron por los Pirineos y llegaron hasta Tarazona, a la que saquearon. En la agonía del Imperio surgieron grupos de bandidos que se dedicaron al pillaje. El valle del Ebro fue asolado en el por varias bandas de malhechores llamados bagaudas.

Después de la desintegración del Imperio romano de Occidente, la zona actual de Aragón fue ocupada por los visigodos, formando el Reino visigodo.

En el año 714 los árabes llegaron a la zona central de Aragón, convirtiendo al islam las antiguas urbes romanas como Saraqusta (Zaragoza) o Wasqa (Huesca). Fue en esta época cuando se formó una importante familia muladí, los Banu Qasi (بنو قاسي), sus dominios se situaron en el valle del Ebro entre los siglos y . Después de la desaparición del califato de Córdoba a principios del , surgió la Taifa de Zaragoza, una de las más importantes de Al-Andalus, dejando un gran legado artístico, cultural y filosófico.

El nombre de Aragón está documentado por primera vez durante la Alta Edad Media en el año 828, cuando un pequeño condado de origen franco surgió entre los ríos que llevan su nombre, el río Aragón, y su hermano el río Aragón Subordán. Aquel Condado de Aragón se vería unido al Reino de Pamplona hasta 1035, y bajo su ala crecería hasta formar dote de García Sánchez III a la muerte del rey Sancho "El Mayor" de Pamplona, en un período caracterizado por la hegemonía musulmana en casi toda la península ibérica. Bajo el reinado de Ramiro I se ampliarían fronteras con la anexión de los condados de Sobrarbe y Ribagorza (año 1044), tras haber incorporado poblaciones de la comarca histórica de las Cinco Villas.

En 1076, a la muerte de Sancho IV el de Peñalén, Aragón incorpora a sus territorios parte del reino navarro mientras que Castilla hace lo propio con la zona occidental de los antiguos dominios de Sancho el Mayor. A través de los reinados de Sancho Ramírez de Aragón y Pedro I, el reino amplía sus fronteras al sur, establece fortalezas amenazantes sobre la capital de Zaragoza en El Castellar y Juslibol y toma Huesca, que pasa a ser la nueva capital.

Así se llega al reinado de Alfonso I "El Batallador" que conquistaría las tierras llanas del valle medio del Ebro para Aragón: Ejea, Valtierra, Calatayud, Tudela y Zaragoza, la capital de la Taifa de Saraqusta. A su muerte los nobles elegirían a su hermano Ramiro II "El Monje", que dejó su vida religiosa para asumir el cetro real y perpetuar la dinastía, lo que consiguió con la unión dinástica de la Casa de Aragón con la poseedora del Condado de Barcelona en 1137, año en que la unión de ambos patrimonios daría lugar a la Corona de Aragón y agregaría las fuerzas que a su vez harían posible las conquistas del Reino de Mallorca y el Reino de Valencia. La Corona de Aragón llegaría a ser la potencia hegemónica del Mediterráneo, controlando territorios tan importantes como Sicilia o Nápoles.

La leyenda posterior hacía a la monarquía aragonesa elegible y creó una frase de coronación del rey que se perpetuaría durante siglos:

Esa situación se repetiría en el Compromiso de Caspe (1412), donde se evita una guerra que hubiese desmembrado la Corona de Aragón al surgir un buen puñado de aspirantes al trono, tras la muerte de Martín I "El Humano" un año después de la muerte de su primogénito, Martín "El Joven". Fernando de Antequera es el elegido, de la rama castellana de los Trastámara, pero también directamente entroncado con el rey aragonés Pedro IV "El Ceremonioso", a través de su madre Leonor de Aragón.

Aragón es ya un ente político de gran escala: la Corona, las Cortes, la Diputación del Reino y el Derecho Foral constituyen su naturaleza y su carácter. El matrimonio de Fernando II de Aragón con Isabel I de Castilla, celebrado en 1469 en Valladolid, derivó posteriormente en la unión de las coronas de Aragón y Castilla, creando las bases del Estado Moderno.

La Edad Moderna, sin embargo, presenció también las tensiones entre el poder de la Monarquía Hispánica y los establecidos en los estados forales procedentes de la evolución de las instituciones medievales, que acabaron estallando en el conflicto de las Alteraciones de Aragón de 1591.

Tras el recorte subsiguiente a las atribuciones de la Generalidad de Aragón en las Cortes de Tarazona de 1592, fundamentalmente en materia militar para evitar que pudiera ser armado frente al rey de España un ejército con los recursos y prerrogativas de la Diputación del General, el fue un periodo de decadencia de las instituciones propias del Reino de Aragón, que fue compensado con la labor historiográfica y de literatura jurídica que mantuvo la memoria de las peculiaridades aragonesas. Destaca en este sentido la creación en 1601 del Archivo del Reino de Aragón (en gran medida destruido durante la Guerra de la Independencia Española y los Sitios de Zaragoza junto con el Palacio de la Diputación del Reino), la continuidad del cargo de cronista de Aragón —donde habían destacado autores como Jerónimo Zurita— y sus resultados patentes en la obra de los hermanos Argensola con su "Información de los sucesos de Aragón de 1590 y 1591" (de Lupercio) y "Alteraciones populares de Zaragoza del año 1591" (de Bartolomé, o los "Anales" de Juan Costa y Jerónimo Martel, testigos presenciales y también cronistas del Reino, que fueron no obstante destruidos por la censura regia; obras todas ellas escritas para contrarrestar la versión filipina de los hechos.

Por otro lado, la Diputación del General también ejerció la censura, y ordenó quemar la "Historia de las cosas sucedidas en este Reyno" en seis volúmenes del castellano Antonio de Herrera porque «en dichas Crónicas se decían muchas cosas contrarias a la verdad» y se encomendó a Vicencio Blasco de Lanuza la redacción de unas "Historias eclesiásticas y seculares de Aragón", cuyo segundo volumen, que trataba los graves sucesos recientemente ocurridos, fue publicado en 1619, tres años antes que el primero, lo que da idea de la intención de responder a la visión de Herrera. En la misma línea, se encargó un "Ceremonial y breve relación de todos los cargos y cosas ordinarias de la Diputación del Reino de Aragón", a su teniente de alcaide, Lorenzo Ibáñez de Aoiz. También se emprende en este periodo la cartografía del Reino de Aragón, encomendada al portugués Juan Bautista Lavaña. Estas dos últimas obras fueron concluidas en 1611.

Durante la Guerra de Sucesión, Aragón (al igual que el resto de territorios de la Corona: Cataluña, Valencia y Mallorca) apoyó al archiduque Carlos (de la casa de Austria) frente a Felipe V (de los Borbones). Tras la batalla de Almansa (1707), Felipe V abolió los fueros aragoneses, adoptó varias medidas centralistas y fueron anuladas todas las antiguas disposiciones políticas del reino (Decretos de Nueva Planta). Aragón se convirtió en la práctica en una provincia y su Consejo fue absorbido por el Consejo de Castilla.

La guerra de la Independencia, tras la intensa destrucción de la ciudad de Zaragoza, detuvo el progreso económico y retrasó de modo importante la incorporación de la capital al ritmo de la modernidad. Con la primera organización provincial de 1822 de España, Aragón contó con cuatro provincias, siendo Calatayud capital de la cuarta provincia que comprendía municipios de las actuales provincias de Zaragoza, Teruel, Soria y Guadalajara. Desapareció con la nueva abolición de la Constitución por Fernando VII. La división provincial de 1833 organizó el territorio aragonés en las tres actuales provincias.

A lo largo del los carlistas, que buscaron adeptos para su causa en esta tierra, ofrecieron la restauración de pasadas libertades forales del ya antiguo y desaparecido reino de Aragón. También fue en este siglo el paso de una sociedad rural a un funcionamiento industrial y urbano, llevando un éxodo masivo del campo a las ciudades más grandes de Aragón, Huesca, Zaragoza, Teruel o Calatayud, y una verdadera emigración a otras regiones cercanas, como Cataluña o Madrid.

Durante el , la historia de Aragón ha ido pareja a la del resto del territorio español, a destacar el impulso económico "coyuntural" en la dictadura del militar Miguel Primo de Rivera (1923-1931) y del progreso en las libertades civiles e individuales, durante la Segunda República. También en junio de 1936 se presentó en las Cortes españolas el Anteproyecto de Estatuto de Autonomía de Aragón pero la inminente guerra civil impidió el desarrollo del proyecto autonomista.

Aragón quedó dividido por los dos bandos enfrentados en la Guerra Civil. Por un lado, la zona oriental, más próxima a Cataluña y controlada por el Consejo Regional de Defensa de Aragón, leal a la República, y por otro la zona occidental, donde se ubicaban las tres capitales provinciales y bajo el control del bando sublevado nacional, habiendo una dura, cruenta y salvaje represión en las mismas y durante la contienda. En Aragón se libraron algunas de las batallas más importantes de la Guerra Civil, como la de Belchite, la de Teruel o la del Ebro. Aragón desde 1939 estuvo bajo la dictadura franquista junto con el resto de España.

Durante los años 1960 se desencadenó un éxodo y un despoblamiento de las zonas rurales hacia las zonas industriales como las capitales de provincia, otras zonas de España, además de otros países europeos. En 1964 se creó en Zaragoza uno de los llamados Polos de Desarrollo. En los años 1970 se vivió como en el resto del Estado un periodo de transición, tras la extinción del anterior régimen, con la recuperación de la normalidad democrática y la creación de un nuevo marco constitucional.

Se empezó a reclamar una autonomía política propia, para el territorio histórico aragonés; sentimiento que quedó reflejado en la histórica manifestación del 23 de abril de 1978 que reunió a más de por las calles de Zaragoza. Al no haber plebiscitado, en el pasado, afirmativamente un proyecto de Estatuto de autonomía (disposición transitoria segunda de la constitución) y no haciendo uso del difícil acceso a la autonomía por el artículo 151 cuyo procedimiento agravado requería, aparte de que la iniciativa del proceso autonómico siguiera los pasos del artículo 143, que fuera ratificado por tres cuartas partes de los municipios de cada una de las provincias afectadas que representasen al menos la mayoría del censo electoral, y que dicha iniciativa fuera aprobada mediante referéndum por el voto afirmativo de la mayoría absoluta de los electores de cada provincia, Aragón accedió al autogobierno por la vía lenta del artículo 143 obteniendo menor techo competencial, y menor autogestión de recursos, durante más de veinte años.

El 10 de agosto de 1982, fue aprobado por las Cortes Generales el estatuto de autonomía de Aragón, firmado por el entonces presidente del Gobierno, Leopoldo Calvo-Sotelo, y sancionado por el rey Juan Carlos I. El 7 de mayo de 1992 una Comisión Especial de las Cortes de Aragón, elaboraba un texto reformado que fue aprobado por las Cortes de Aragón y por las Cortes Españolas. De nuevo, una pequeña reforma estatutaria en 1996 amplió el marco competencial, obligando a una definitiva revisión integral durante varios años, siendo aprobado un nuevo texto estatutario en 2007, por mayoría pero sin logar una total unanimidad. En los años 1990, la sociedad aragonesa incrementa un significativo paso cualitativo en la calidad de vida debido al progreso económico del Estado en todos los niveles.

A comienzos del , se establece un significativo incremento de infraestructuras como la llegada del tren de Alta Velocidad (AVE), la construcción de la nueva autovía Somport-Sagunto y el impulso de los dos aeropuertos de la comunidad autónoma, Zaragoza y Huesca-Pirineos. A su vez se acometieron grandes proyectos tecnológicos, como el Parque Tecnológico Walqa y la implantación de una red telemática por toda la comunidad.

En 2007 se reformó de nuevo el Estatuto de Autonomía de Aragón –que fue aprobado por un amplio consenso en las Cortes de Aragón al contar con el apoyo del PSOE, del PP, del PAR y de IU, mientras que CHA se abstuvo– concediendo a la comunidad autónoma el reconocimiento de nacionalidad histórica (desde la ley orgánica de 1996 de reforma del estatuto, poseía la condición de nacionalidad), se incluye un nuevo título sobre la Administración de Justicia y otro sobre derechos y deberes de los aragoneses y principios rectores de las políticas públicas, la posibilidad de creación de una agencia tributaria propia en colaboración con la estatal, también la obligación a los poderes públicos a velar para evitar trasvases de las cuencas hidrográficas como el trasvase del Ebro, entre otros muchas modificaciones del Estatuto de Autonomía.

La designación de Zaragoza como sede para la Exposición Internacional de 2008, cuyo eje temático giró en torno al agua y el desarrollo sostenible, supuso una serie de cambios y crecimiento acelerado para la comunidad autónoma. Además ese mismo año se celebraron dos aniversarios, el bicentenario de Los Sitios de Zaragoza de la Guerra de la Independencia contra la invasión napoleónica, acaecidos en 1808 y el centenario de la Exposición Hispano-Francesa de 1908 que supuso como un acontecimiento moderno, para demostrar el empuje cultural y económico de Aragón y a la vez que serviría para estrechar lazos y restañar heridas con los vecinos franceses tras los acontecimientos de las Guerras Napoleónicas del siglo anterior.

Su economía tradicional perteneciente al sector primario con predominio de los cultivos cerealísticos y forrajeros, apoyados por una cabaña ovina importante, se ha visto muy modificada en los últimos años por el ascenso imparable del sector industrial, de servicios y comercio, seguido del turismo. A estos efectos resulta destacable el papel de Zaragoza y su capacidad comercial y logística en el sector noreste peninsular.

El PIB de Aragón supone el 3 % del PIB total de España, situándose el PIB per cápita, en el año 2008, en 26 107 €, el 5º puesto en España, superando la media nacional y de la UE. La empresa Opel (Groupe PSA) tiene una factoría situada cerca de la ciudad de Zaragoza, en el municipio de Figueruelas. Existen otras empresas importantes en generación eléctrica como Endesa con su Central Térmica Teruel, en Andorra; la papelera SAICA, en Zaragoza y Burgo de Ebro; ICT Ibérica, también en el Burgo de Ebro, Pikolín, Sabeco, Inditex o BSH, en Zaragoza; Chocolates Lacasa en Utebo; o la maderera de Cella, la tercera de Europa.

El Complejo PLAZA, cercano al aeropuerto zaragozano, supone el mayor centro de logística de mercancías y transporte del Sur de Europa. Se pone en marcha la Radio y Televisión autonómica, tras casi quince años de una continua demora por "circunstancias extraordinarias" de carácter político y económico, donde los intereses cruzados de los medios de comunicación locales y la falta de consenso político general, había postergado esta iniciativa multimedia.

Sus productos tradicionales son ya conocidos a nivel internacional, destacando el ternasco de Aragón, el pan con tomate, los vinos del Somontano, el jamón de Teruel, el aceite de oliva del Bajo Aragón, el melocotón de Calanda y la almendra. Las denominaciones de origen existentes les han ayudado a abrir nuevos mercados internacionales como Japón, China o Estados Unidos además de Europa.

El futuro se perfila hacia el crecimiento del sector terciario, el mantenimiento del secundario, y la reducción paulatina del primario, al igual que la mayoría de las economías occidentales. Como actividades económicas importantes destaca el crecimiento del turismo deportivo, potenciado a través de Aramón, es decir, el conjunto de las estaciones de esquí; si bien se está desarrollando un fenómeno reciente facilitado por la mejora de las comunicaciones por carretera (Autovía Mudéjar), como es el turismo cultural, donde la ciudad de Teruel se está convirtiendo en un centro de atracción a nivel nacional, gracias a su patrimonio histórico (el mudéjar aragonés, declarado Patrimonio de la Humanidad), el parque temático Dinópolis y su cercanía a Albarracín.

Producción de energía eléctrica:

A mediados de 2009, Aragón contaba con una potencia eléctrica instalada de 7094,03 MW repartida de la siguiente manera:

En 2008 la producción eléctrica en la comunidad ascendió a 21 736 GWh y su procedencia se dividió de la siguiente manera: 14 315 GWh fueron aportados por el carbón, los ciclos combinados y la cogeneración, 4010 GWh fueron aportados por la eólica, 3333 GWh por las centrales hidroeléctricas y 78 GWh procedieron de la solar.

En 2008, la producción de energías renovables respecto al consumo total de energía primaria se situó en Aragón en el 13,83 %, frente al 6,7 % del resto de España. Mientras que en la producción eléctrica la aportación de las renovables con respecto al consumo final eléctrico se situó en el 69,67 %, frente al 18 % de la media española. Además, el 47 % de la energía producida en Aragón tuvo como fin la exportación a otras comunidades autónomas.

Las principales instalaciones de producción energética son:

Entre los desarrollos energéticos previstos a corto y medio plazo (2010-2020), destacan: el incremento en 2300 MW de energía eólica, la central hidroeléctrica reversible que Endesa está proyectando en el término municipal de Mequinenza con aguas del embalse de Ribarroja la cual rondará los 750 MW, la ampliación de la central reversible de Moralets-Llauset que ganará una potencia de 400 MW en turbinación, la central solar termoeléctrica de 50 MW que Iberdrola tiene planificado construir en el Bajo Aragón, otra central de 50 MW termosolares en Villanueva de Sijena, la central de valorización energética de residuos del carbón en Ariño 49,9 MW, una central fotovolcaica de 2 MW sobre los tejados de Sabeco (Villanueva de Gállego), la central térmica de carbón de última generación de Mequinenza con 37 MW (Rechazada por motivos medioambientales), la central Solar Termoeléctrica Hibridada con Biomasa en Belver de Cinca 17,6 MW, unas 15 plantas de biomasa lignocelulósica forestal con unos 35 MW, cinco plantas de biogás de purines con unos 13,5 MW y una central de hidrógeno en Robres.

Producción de biocarburantes:

Aragón dispone de seis plantas de producción de biodiésel con una capacidad conjunta de producción de 272 000 toneladas/año:

Producción de termias:

El Plan Energético de Aragón contemplaba disponer de 44 165 m² de paneles solares para 2012.

Aragón se divide en tres provincias desde la división territorial de 1833 que son, Huesca, Teruel y Zaragoza con sus tres capitales homónimas. Cada provincia tiene una serie de comarcas entre las que se encuentran Huesca con 10 comarcas, Teruel también con 10 comarcas y Zaragoza cuenta con 16 comarcas (3 de ellas compartidas con Huesca) y a la vez estas divididas en municipios.

Aragón cuenta con 1 313 463 habitantes (INE, 2018), de los que un 50,77 % viven en la capital, Zaragoza, única ciudad de la comunidad que supera los 100 000 habitantes (666 880 habitantes, según INE 2018); esta concentración es reciente, ya que en 1950 la capital autonómica concentraba solamente el 24 % de la población total. Consecuencia del despoblamiento rural, debido a la escasez de infraestructuras e inversiones públicas en gran parte del territorio, el resto del territorio presenta una ocupación muy débil; no en vano, Aragón, con 27,43 hab./km², es la con menor densidad de población, siendo solo superada por Castilla-La Mancha, Extremadura y Castilla y León.

Según el censo de 1991, Aragón contaba con 1 221 546 habitantes, es decir un 3,10 % de la población nacional y una densidad de 25,6 habitantes/km². Desde entonces la población ha crecido casi solo en las principales ciudades, y a un ritmo muy inferior al de la media española, por lo que en el 2006 la población aragonesa solo representaba el 2,86 % de la población nacional. En los últimos años se invirtió esta tendencia y actualmente Aragón representa un 2,8% de la población total de España.

La proporción de extranjeros residentes en el padron de 2018 es del 10,80%, proporción cercana aunque superior a la media nacional (9,78 %).


Evolución demográfica en los últimos años.

Su regulación se encuentra en la Ley 5/2000, de 28 de noviembre, de Relaciones con las Comunidades Aragonesas del Exterior, haciendo efectivo el artículo 8 del Estatuto de Autonomía de Aragón el cual establece que “"los poderes públicos aragoneses velarán para que las Comunidades aragonesas asentadas fuera de Aragón puedan, en la forma y con el alcance que una Ley de Cortes aragonesas determine, participar en la vida social y cultural de Aragón, sin que ello suponga en ningún caso la concesión de derechos políticos"”, que también dispone en el apartado 2.b) del artículo 6 que “"corresponde a los poderes públicos aragoneses, sin perjuicio de la acción estatal y dentro del ámbito de sus respectivas competencias, impulsar una política tendente a la mejora y equiparación de las condiciones de vida y trabajo de los aragoneses, propugnando especialmente las medidas que eviten su éxodo, al tiempo que hagan posible el regreso de los que viven y trabajan fuera de Aragón"”.

La relación entre los miembros de las Comunidades Aragonesas y las Instituciones Públicas de la Comunidad Autónoma de Aragón, se realiza a través de las Casas y Centros de Aragón, que son aquellas fundaciones, agrupaciones y demás entidades con personalidad jurídica, sin ánimo de lucro, legalmente constituidas fuera del territorio de la Comunidad Autónoma de Aragón, cuyos fines estatutarios y su actuación ordinaria se dirija hacia el mantenimiento de lazos culturales, sociales y económicos con Aragón, sus gentes, su historia, sus lenguas y hablas, sus tradiciones y su cultura.

Para ser reconocido como Casa o Centro de Aragón es necesario solicitarlo formalmente para que posteriormente sea aprobado por Acuerdo del Gobierno de Aragón, previo informe de la Comisión Permanente del Consejo de las Comunidades Aragonesas en el Exterior.

Este reconocimiento dará lugar a la inscripción de la misma en el Registro de Casas y Centros de Aragón.

Asimismo, las Casas y Centros de Aragón pueden constituirse en Federaciones y Confederaciones a los efectos de defender e integrar sus intereses y de facilitar el cumplimiento conjunto y coordinado de sus fines.

Según el artículo 11º del Estatuto de Autonomía de Aragón, en su título primero, las cuatro instituciones con poder político en Aragón: las Cortes de Aragón, el Presidente, el Gobierno de Aragón y el Justicia de Aragón.

En las Cortes de Aragón recae el poder legislativo, representando al pueblo aragonés con 67 diputados, aprueban sus presupuestos, impulsan y controlan la acción de la Diputación General. Las Cortes elegirán, de entre sus miembros, a un presidente, una Mesa y una Diputación Permanente. La sede de las Cortes reside en el Palacio de la Aljafería, Zaragoza. El actual presidente de las Cortes es Javier Sada Beltrán, del PSOE.

En las elecciones a las Cortes de Aragón de 2019, el partido más votado fue el PSOE, experimentando una subida importante y sumando 24 escaños, frente a los 16 del PP. Además, Ciudadanos se colocó en tercera posición con 12 parlamentarios, seguido de Podemos-Equo, con 5 escaños y CHA, con 3. A su vez, el PAR redujo su presencia a la mitad, obteniendo 3 escaños e IU-A mantuvo el escaño. Por primera vez, Vox entró en las Cortes, irrumpiendo con 3 escaños.

El presidente del Gobierno de Aragón es elegido por las Cortes de Aragón, en la actualidad este cargo lo ostenta Javier Lambán desde el 5 de julio de 2015, del PSOE. Desde la reforma del Estatuto de Autonomía de Aragón en 2007, el presidente, como máxima representación del Gobierno de Aragón, puede disolver las Cortes y convocar elecciones cuando le parezca oportuno.

El Gobierno de Aragón o Diputación General de Aragón forma el poder ejecutivo de la comunidad autónoma y es el órgano de gobierno de Aragón. Está formado por el presidente y los consejeros. Su actual sede es el Palacio Pignatelli, también llamado Real Casa de la Misericordia, situado en la ciudad de Zaragoza. En la actualidad el Gobierno de Aragón está formado por un gobierno de coalición entre el PSOE, Podemos-Equo, CHA y PAR, con apoyo externo de IU-A.

El Justicia de Aragón es una institución medieval que surgió en el Reino de Aragón en el para actuar como mediador y moderador en las pugnas y diferencias entre el rey y la nobleza. Actualmente se encarga de defender los derechos y libertades de los aragoneses de las Administraciones Públicas, defender el Estatuto de Autonomía de Aragón y tutelar el Ordenamiento Jurídico Aragonés. Su sede actual se encuentra en el Palacio de Armijo, en Zaragoza. Es la institución análoga al Defensor del Pueblo de otras autonomías.

Los dos órganos consultivos del Gobierno de Aragón son el Consejo Económico y Social de Aragón y la Comisión Jurídica Asesora.

Aragón está formado por tres diputaciones provinciales correspondientes a la Diputación Provincial de Huesca, la Diputación Provincial de Teruel y la Diputación Provincial de Zaragoza las cuales son entidades con personalidad jurídica propia, y con autonomía para la gestión de sus intereses.



En las elecciones municipales de 2015 se eligieron en Aragón 4177 concejales y 731 alcaldes. El PSOE obtuvo 1707 concejales a pesar de tener menos votos que el PP que obtuvo 1232 concejales. El PAR fue el tercer partido con más concejales, un total de 916. Destacan también la Chunta Aragonesista con 163 concejales y C's con 54 concejales.

En Aragón existen 16 partidos judiciales de los cuales siete pertenecen a la provincia de Zaragoza, seis a la de Huesca y tres a la de Teruel. La actual distribución de partidos judiciales de Aragón se debe a la Ley 38/1988, de 28 de diciembre, de Demarcación y de Planta Judicial.

Según el Barómetro de Opinión de Aragón Invierno 2011, el 3,1 % de la población aragonesa desea que Aragón sea un país o estado independiente. Otro 47,6 % opina que Aragón debe ser una comunidad autónoma con más competencias.

La educación en Aragón está regulada por el Departamento de Educación, Universidad, Cultura y Deporte del Gobierno de Aragón desde que en 1999, la comunidad asumió esta competencia. Aragón cuenta con más de 200 000 alumnos, según el informe PISA (2010), Aragón superó la media española y de la OCDE, acercándose a los países con mejor nivel educativo de Europa.

La Universidad de Zaragoza es un centro de educación superior público, repartida geográficamente entre los campus de Zaragoza, Huesca, Jaca, Teruel y La Almunia de Doña Godina, todos ellos dentro de la comunidad. En 2008 contaba más de 32 000 estudiantes y 3500 miembros docentes entre sus 22 centros y 74 titulaciones. En los últimos años han aumentado la creación de institutos universitarios con el fin de realizar investigaciones en distintos campos, como la ciencia o el medio ambiente, entre otros. Su actual rector es José Antonio Mayoral Murillo.

Los orígenes de la enseñanza superior en Aragón se remontan al siglo  a. C., a la legendaria academia fundada en Huesca por Quinto Sertorio. Pedro IV de Aragón fundó en 1354 la Universidad Sertoriana de Huesca, la primera de Aragón. La Universidad de Zaragoza tiene su origen en una escuela catedralicia creada en el , donde se enseñaban gramática y filosofía y se concedían títulos de bachiller, posteriormente fue fundada en 1542. Hasta 1845 Aragón contaba con dos universidades, la de Huesca y la de Zaragoza, siendo la primera clausurada en el año citado, creándose en su emplazamiento el actual Museo Arqueológico Provincial de Huesca.

La Universidad San Jorge es una universidad privada promovida por la Fundación San Valero y fundamentada en el humanismo cristiano. El campus universitario, situado a 8 km de Zaragoza, en Villanueva de Gállego, cuenta con la Facultad de Comunicación, la Facultad de Ciencias de la Salud y la Escuela de Arquitectura y Tecnología.

Actualmente, la Universidad San Jorge cuenta con más de 2000 alumnos, 16 grados y 8 másteres. Con respecto a la investigación, la USJ desarrolla seis cátedras y más de diez grupos de investigación de diferentes áreas.

El Laboratorio Subterráneo de Canfranc (LSC) es una instalación científica subterránea situada junto al municipio de Canfranc. Está dedicada a la ciencia subterránea, especialmente a la investigación de la materia oscura y a la detección de sucesos poco probables, y por este motivo está instalada bajo el Pirineo aragonés, a unos 850 metros de profundidad.

Está gestionada por un consorcio formado por el Ministerio de Ciencia e Innovación de España, la Diputación General de Aragón (DGA) y la Universidad de Zaragoza (UNIZAR).

El Observatorio Astrofísico de Javalambre es una ICTS (Instalación Científico-Técnica Singular) astronómica ubicada en el término municipal turolense de Arcos de las Salinas. Las instalaciones se encuentran en el Pico del Buitre (1958 metros de altitud), en la sierra de Javalambre. 

El observatorio está proyectado y gestionado por el Centro de Estudios de Física del Cosmos de Aragón (CEFCA), dependiente del Departamento de Industria e Innovación del Gobierno de Aragón. Ligado al observatorio, está actualmente en desarrollo Galáctica, un Centro de Difusión y Práctica de la Astronomía.

La comunidad cuenta con 121 centros de salud, 868 consultorios locales y 5445 camas instaladas en 29 hospitales.

Dependiendo de la zona existen distintos trajes tradicionales como son los trajes ansotano y cheso, belsetán, chistabín o fragatí. En general las diferencias entre los trajes pirenaicos y del resto de Aragón son más acusadas.

Con una clara influencia mudéjar, en algunos pueblos, el traje más popular en gran parte de Aragón se compone (con ciertas variaciones) de un pañuelo atado en la cabeza (llamado a veces cachirulo), calzones abiertos, una manta a modo de faja en la cintura y alpargatas para los hombres. Las mujeres llevan sayas anchas, un corpiño, calzón, medias caladas, mantón, delantal y alpargatas.

Uno de los bailes y cantos populares es la jota, un baile que se conformó entre finales del y principios del . Es un baile muy brioso y alegre que se baila con mucho movimiento y grandes saltos. El cante suele ser de ritmo melancólico con una nota frecuentemente socarrona. También perdura la música tradicional aragonesa, que utiliza instrumentos como el salterio (chicotén), el chiflo, la gaita aragonesa o gaita de boto, la dulzaina y el acordeón.

En algunos lugares son típicos distintos tipos de danza, con paloteados y espadas, alusiones a luchas entre moros y cristianos.

Entre los aragoneses más destacados encontramos personajes de gran reconocimiento en distintos ámbitos. Entre los arquitectos destaca la generación contemporánea de Ricardo Magdalena, Félix Navarro, José de Yarza y Fernando García Mercadal. Como pintores José Luzán, Francisco Bayeu, Francisco de Goya, Francisco Pradilla, Pablo Gargallo, Pablo Serrano o Antonio Saura. En el mundo de las ciencias, a pesar de ser un ámbito donde tradicionalmente pocos españoles destacan, hay una serie de aragoneses de gran relevancia internacional, como Miguel Servet y Santiago Ramón y Cajal, y en menor medida, Lucas Mallada, Longinos Navás Ferrer y Odón de Buen.En literatura, humanidades y periodismo Baltasar Gracián, Mariano Nipho, Mariano de Cavia, Braulio Foz y Burges, Mariano de Pano, María Moliner, José Manuel Blecua Teijeiro, Fernando Lázaro Carreter, José Manuel Blecua Perdices, Ramón J. Sender, Luis del Val, Soledad Puértolas, Ignacio Martínez de Pisón o Jesús Moncada. En política e historia Al-Muqtadir, Fernando el Católico, Conde de Aranda, Ramón Pignatelli, José de Palafox, Joaquín Costa, Pedro Cerbuna, San José de Calasanz, Josemaría Escrivá de Balaguer, Gabriel Cisneros, José Antonio Labordeta, Luisa Fernanda Rudi, Marcelino Iglesias, Juan Alberto Belloch, Javier Lambán o Susana Sumelzo. En música, teatro, cine y televisión se encuentran Luis Buñuel, Segundo de Chomón, Paco Martínez Soria, Florian Rey, José María Forqué, José Luis Borau, Carlos Saura, Manuel Campo Vidal, Raquel Meller, Miguel Fleta, Víctor Ullate, Enrique Bunbury y Eva Amaral.

Entre los deportistas encontramos a Teresa Perales, Conchita Martínez, Carlos Lapetra, José Luis Violeta, Perico Fernández, Valero Rivera, Víctor Muñoz, Pepe Garcés, Juan Antonio San Epifanio, Víctor Fernández, Fernando Arcega, Pepe Arcega, Luis Milla, Fernando Escartín, Alberto Belsué, Eliseo Martín o Alberto Zapater.

En la mayor parte de Aragón se habla el español, que es además el idioma oficial en toda la comunidad como en el resto del Estado. En la parte norte de la comunidad se habla el idioma aragonés. Por otra parte, en el este de la comunidad, llamada la franja de Aragón se hablan diversos dialectos del catalán. Tras la aprobación de la Ley de Lenguas de Aragón en 2009, ya prometida por el entonces presidente Marcelino Iglesias en su primera legislatura, el idioma aragonés y el idioma catalán pasaron a figurar como lenguas propias de Aragón, aunque no oficiales.

Hasta la aprobación de la Ley de Lenguas, el idioma aragonés y el idioma catalán no estaban reconocidos como lenguas propias de Aragón en el Estatuto de Autonomía, pero la Ley de Patrimonio Cultural de Aragón, ya disponía sobre su protección (e incluso sobre su oficialidad).

Legalmente, la regulación hasta entonces era escasa, aunque se debe resaltar la Ley aragonesa 1/1999, de 24 de febrero, de Sucesiones por causa de muerte, que permite que tanto los pactos sucesorios como los testamentos puedan ser redactados en cualquier lengua o modalidad lingüística de Aragón (artículos 67 y 97), y la Ley 2/2003, de 12 de febrero, de régimen económico matrimonial y viudedad, cuyo artículo 14 dice:




La gastronomía de Aragón está influenciada por las regiones vecinas del Cantábrico y las del Mediterráneo. Son conocidas las diferentes verduras como los tomates, las cebollas (las cebollas de Fuentes de Ebro son especialmente famosas ya que no pican), las borrajas (en especial en las comarcas cercanas a Zaragoza), cardos, ajos, etcétera. Se pueden encontrar en el otoño abundantes setas (robellones, setas de cardo, etcétera). Entre las frutas hay que nombrar el melocotón, con tipos que tienen denominación de origen como el Melocotón tardío del Bajo Aragón, conocido como melocotón de Calanda o las variedades de fruta tempranas que provienen del Bajo / Baix Cinca. También son conocidos las ciruelas y las peras.

De Aragón son famosas las migas de pastor, el ternasco de Aragón, el jamón de Teruel, la borraja, el cardo, los vinos de sus distintas Denominaciones de Origen (Somontano, Campo de Borja, Cariñena, Calatayud), las chiretas, las tortetas, la longaniza, la carne a la pastora, los crespillos de borraja, el pollo al chilindrón, las almendras, la miel, el melocotón de Calanda, etc. Existen dos Denominaciones de Origen de aceite de oliva, Bajo Aragón y Sierra del Moncayo. En la zona del Bajo / Baix Cinca se puede encontrar aceites de oliva de gran calidad ya que durante la época musulmana había sido conocida como la tierra de los olivos ("Al Zaytún"). Desde la Edad Media, hay constancia de producción de miel en Mequinenza siendo especialmente apreciadas la de cerezo, romero y tomillo.

En carnes es famoso el jamón de Teruel y el ternasco, que posee una denominación específica de Ternasco de Aragón, y también el cordero al chilindrón o las chiretas. Entre las aves son famosos el pollo al chilindrón y el pollo en pepitoria. También son muy conocidos los embutidos, como la morcilla de arroz, la longaniza de Graus y la butifarra. Entre los pescados se encuentra el bacalao ajoarriero, el bacalao a la baturra, la sardina rancia, las truchas a la aragonesa, la truchas a la turolense o las ancas de rana.

También hay quesos de gran calidad, como el conocido queso de Tronchón. También son afamados los quesos de Alcañiz (Santa Bárbara), Samper de Calanda, de Hecho y Ansó, Biescas, El Burgo de Ebro, Gistaín, etcétera. Son muy famosas también las migas de pastor, que generalmente se preparan con ajo, cebolla, tocino, chorizo o morcilla, y se comen con uvas. En Navidad es muy típico cocinar el cardo con salsa de almendras y piñones.

En Aragón hay deliciosos postres y dulces muy elaborados, como las frutas de Aragón, la trenza de Almudévar, el pastel ruso, las castañas de Huesca, los lazos de Jaca, el guirlache, los adoquines del Pilar, las tortas de alma, las cocas, el lanzón de San Jorge, el melocotón con vino, etcétera. 

La situación estratégica de Aragón, situándola entre importantes comunidades y capitales, hace que se vea beneficio en las inversiones del Estado, aunque siempre siendo insuficientes y proyectadas con poca previsión lo que hace que en cuestión de años sean inservibles.

Aragón cuenta con varios aeropuertos y aeródromos:




Aragón tiene asumida la competencia exclusiva sobre carreteras cuyo itinerario discurre íntegramente en su territorio, siendo dichas carreteras de titularidad de la Diputación General de Aragón, de las tres diputaciones provinciales o de los distintos municipios aragoneses. En total son unos 10 700 km aprox. con los que cuenta Aragón siendo propietaria de casi la mitad la propia DGA. El Estado posee unos 2200 km, mientras que unos 3000 km pertenecen a las distintas diputaciones.

La DGA se encuentra inmersa en un proceso de renovación y conservación de sus carreteras, sin olvidar las demandas actuales, teniendo así en construcción la primera autopista autonómica pagada con el sistema de peaje en sombra y que unirá las localidades de El Burgo de Ebro y Villafranca de Ebro, uniendo así la N-II, la AP-2, la N-232 y la A-222 siendo este primer tramo el origen del Quinto cinturón (Z-50) de la capital aragonesa. Además están en distintas fases de estudio otras autopistas autonómicas como son la Gallur-Cariñena y la Gallur-Ejea.

El Estado posee un gran número de autopistas, autovías y carreteras nacionales en Aragón, debido a la situación de cruce de caminos en la que está situado Aragón.

En estos momentos, varios colectivos se muestran críticos ante la situación de la N-II y la N-232 puesto que en sus tramos sin desdoblar son constantes los accidentes mortales por lo que se pide la liberalización de los peajes de la AP-68 y AP-2 en sus tramos donde la carretera nacional este sin desdoblar.

Las carreteras dependientes de las tres diputaciones son sometidas en algunos tramos a obras de conservación, aunque se pide que dicha titularidad se transfiera a la DGA para que forme parte de la Red Autonómica de Carreteras.

La red de ferrocarril de Aragón es extensa, teniendo tramos de vía convencional, mientras que otros tramos son de Alta Velocidad.

En el año 2003, y no sin polémica, se inauguró la Línea de Alta Velocidad (LAV) Madrid-Zaragoza-Lérida, teniendo paradas dicha línea en Calatayud y en Zaragoza. Posteriormente llegaría la Alta Velocidad a Huesca, capital de la comarca Hoya de Huesca (Plana de Uesca), aunque con un recorrido que impide desarrollar una velocidad alta en los trenes, debido al mal diseño de la línea de alta velocidad. En febrero de 2008 se terminaron los obras y la Línea de Alta Velocidad llegó a la ciudad de Barcelona. Además se está renovando la línea Zaragoza-Teruel para que pueda convertirse en un trayecto de alta capacidad y que se incorporará en el eje de Alta Velocidad Cantábrico-Mediterráneo. Actualmente se está procediendo a la renovación de las vías para hacerlas de ancho UIC, puesto que la electrificación de la línea y su desdoblamiento no se esperan a corto plazo.

En cuanto al resto de la red aragonesa, destaca la línea internacional de Canfranc, cuyo recorrido fue suspendido entre dicha localidad y Francia en la década de 1970] tras ocurrir la destrucción de un puente en el lado francés. Desde entonces, la línea sobrevive a duras penas, habiéndose solicitado su reapertura como paso previo a la construcción de un túnel de baja cota por el Pirineo Central.

Aragón cuenta en estos momentos con una televisión y radio propia de reciente creación. Además tiene numerosos periódicos aragoneses.

El día 21 de abril de 2006, Aragón TV, la televisión autonómica de Aragón, inició oficialmente sus emisiones. La ley de creación de la CARTV ("Corporación Aragonesa de Radio y Televisión") databa del año 1987, pero diversas disputas políticas relegaron el proyecto durante varias legislaturas.

Durante los años que Aragón no tuvo una televisión pública, varios grupos de comunicación intentaron suplir su ausencia. Por un lado TVE-Aragón, teniendo el Centro Territorial en la capital aragonesa, producía varios programas e informativos dirigidos al pueblo aragonés. En cuanto a los grupos privados, varios fueron los proyectos. El que más aceptación tuvo durante muchos años fue Antena Aragón, que llegó a ser considerada como la televisión autonómica. Esta cadena vio la luz en 1998 y desapareció en 2005 poco después de tener que abandonar el Centro de Producción Audiovisual (CPA), donde tenía su sede, ya que este fue construido por la DGA para albergar la futura televisión pública aragonesa. Con el empuje de la creación de la televisión pública, Antena Aragón se fusionó con RTVA (Radio Televisión Aragonesa), perteneciente al Grupo Heraldo. La fusión de Antena Aragón y RTVA dio lugar al canal ZTV (Zaragoza Televisión). Por otra parte, Antena 3 Televisión emitió durante varios años, y en desconexión para Aragón, un informativo de noticias íntegramente aragonesas, teniendo un centro de emisión en los "Pinares de Venecia" en la capital aragonesa, dentro de las instalaciones del parque de atracciones de Zaragoza.

Aragón TV vio la luz en 2006 tras haber pasado una temporada emitiendo una carta de ajuste y un bucle con imágenes de pueblos aragoneses, y teniendo como audio el sonido de la radio autonómica.

El sector audiovisual incluye a algunas productoras, tales como:

En 18 de agosto de 2005 la radio pública autonómica de Aragón, Aragón Radio, inició sus emisiones a las 17:00 horas con el sonido de los tambores y bombos de Calanda y con una canción del grupo zaragozano Los Peces. La audiencia de dicha radio es de entre 20 000 oyentes, según el último EMG, y 70 000, según mediciones privadas. La radio autonómica se basa en las noticias teniendo boletines informativos cada hora desde las 7:00 de la mañana hasta las 0:00. Además cuenta con programas sobre deporte, música, tendencias, etc. y retransmite numerosos acontecimientos deportivos.

Además otros periódicos de ámbito nacional, algunos de los cuales tienen sección específica para Aragón, la comunidad cuenta con varios periódicos aragoneses:

 Todo el contenido de Wikipedia relacionado con Aragón.




</doc>
<doc id="6802" url="https://es.wikipedia.org/wiki?curid=6802" title="Jasper Johns">
Jasper Johns

Jasper Johns (Augusta, Georgia, 15 de mayo de 1930) es un pintor, escultor y artista gráfico estadounidense.

Nació en Augusta (Georgia) y creció en Allendale (Carolina del Sur). Estudió en la universidad de Carolina del Sur, tres semestres, entre 1947 y 1948, para después trasladarse a la Parsons School of Design de Nueva York en 1949. Allí conoció a Robert Rauschenberg, Merce Cunningham y John Cage, con los que comenzó a desarrollar su obra. En 1952 estuvo destinado en Sendai, Japón, durante la guerra de Corea. En 1969 recibió el Premio Vincent van Volkmer.

Su obra mundialmente más conocida son las banderas de los Estados Unidos realizadas a la encáustica en la década de 1950. Otros símbolos, como letras, números y dianas, aparecen recurrentemente en sus pinturas y grabados. Realizó numerosas pinturas "grises", las que comenzaba con color para finalmente cubrir todo el lienzo con gris. Hacia 1960 comenzó a integrar en sus pinturas objetos reales como perchas, tenedores y cucharas. En la década de 1980, reinventó su estilo pictórico.

Es considerado, junto con Robert Rauschemberg, promotor del Neodadaísmo, aunque su producción artística circula entre el Expresionismo abstracto, el Minimalismo y el Arte pop.

Sus obras forman parte de colecciones de los museos de arte más importantes de Estados Unidos y Europa, como la Galería Nacional de Arte, Museo Whitney de Arte Estadounidense, Museo Metropolitano de Arte, Tate Gallery y Centro Pompidou.



</doc>
<doc id="6806" url="https://es.wikipedia.org/wiki?curid=6806" title="Moneda">
Moneda

La moneda es una pieza de un material resistente, de peso y composición uniforme, normalmente de metal acuñado en forma de disco y con los distintivos elegidos por la autoridad emisora, que se emplea como medida de cambio (dinero) por su valor legal o intrínseco y como unidad de cuenta. También se llama moneda a la divisa de curso legal de un Estado. Su nombre en lenguas romances proviene del latín "moneta", debido a que la casa en donde se acuñaban en Roma estaba anexa al templo de Juno Moneta, diosa de la Memoria, encontrándose esta actividad bajo su protección. La ciencia que estudia y clasifica las monedas físicas, metálicas o de material similar, se denomina numismática.

El lugar donde se realiza la acuñación de monedas se le conoce con el nombre de ceca o casa de moneda. El nombre proviene de una voz del árabe clásico ("sikkah"), que significa troquel.

Por extensión, también se considera moneda al billete o papel de curso legal.

El trueque es el intercambio de objetos o servicios por otros equivalentes, y se diferencia de la compraventa habitual en que no intermedia el dinero en la transacción. Este sistema presentaba dificultades para las transacciones, por lo cual comenzaron a aparecer distintas formas de «mercancías-moneda» como unidad de cuenta. Estas mercancías como medio de pago tampoco eran prácticas, ya que muchas eran perecederas, y eran difíciles de acumular. Como solución se sustituyeron pronto por objetos o materiales realizados en metales preciosos. Estos metales preciosos tomaban muchas formas dependiendo del lugar, por ejemplo ladrillos (lingotes), aros, placas, polvo, navajas o cuchillos. Por razones prácticas y de uniformidad se adoptó la forma circular, en forma de discos de diferentes tamaños pero fácilmente transportables. Nace de esta manera la moneda.

En Mohenjo-Daro y Harappa, actualmente en Pakistán, se han encontrado sellos fechados entre , pero no es seguro que hayan sido monedas. Las primeras monedas fueron impresas entre el 

Ya en el año 1100 a. C. circulaban en China miniaturas de cuchillos de bronce, hachas y otras herramientas utilizadas para reemplazar a las herramientas verdaderas que servían de medio de cambio. En 1979 y 1980 fueron descubiertas algunas monedas del antiguo reino de Loulan, que al parecer datan del período Mesolítico.

Las primeras monedas acuñadas con carácter oficial fueron hechas en Lidia, (hoy Turquía), un pueblo de Asia Menor, aproximadamente entre los años Fue probablemente durante el reinado de Ardis de Lidia cuando los lidios empezaron a acuñar moneda, aunque algunos numismáticos han propuesto fechas anteriores o posteriores, como el reinado de Giges de Lidia o el de Creso «El Opulento». Estas acuñaciones llevan como símbolo heráldico un león representando a la Dinastía Mermnada a la cual pertenecían los reyes. La pieza fue acuñada en electrum (aleación natural de oro y plata) y con un peso de 4,75 gramos y un valor de un tercio de Estátera.

Después de la experiencia de Lidia comenzaron a acuñarse monedas por orden de Darío de Persia, luego de la conquista de Lidia, y posteriormente en Grecia.

El historiador norteamericano Will Durant asegura que «Senaquerib Rey de Asiria (hacia 700 a. C.) acuñó monedas de medio siclo».

Posteriormente, las monedas proliferaron rápidamente en todos los países desarrollados del mundo. Tanto los monarcas como los aristócratas, las ciudades y las instituciones empezaron a acuñar dinero con su sello identificativo para certificar la autenticidad del valor metálico de la moneda.

Algunas de las primeras monedas tenían una composición muy estable, como es el caso del dracma emitido en Atenas en el , con un contenido en torno a los 65-67 gramos de plata fina, o como la redonda moneda china, "qian", de cobre. Sin embargo, las monedas siempre se limaban o recortaban para sacar el metal precioso que contenían por lo que las autoridades que las emitían estaban tentadas a rebajar la acuñación asegurándose beneficios a corto plazo al reducir el contenido de metales preciosos. Las monedas de baja calidad de bronce o cobre eran, de hecho, dinero fiduciario cuyo valor dependía principalmente del número de monedas de oro o cobre por las que se podían intercambiar. Las monedas de oro y plata solían circular fuera del país que las emitía dado su valor intrínseco; así, el peso de plata español, cuyo material provenía de las minas del Perú y de México, se convirtió en una moneda de uso corriente en China a partir del siglo XVI.

Una vez creadas, las monedas originaron un sistema monetario cuyas características han permanecido, en esencia, constantes durante milenios. Uno de los cambios que ha perdurado fue la introducción, en las monedas europeas del siglo XVII, de las ranuras en los bordes con el fin de evitar que se limasen.

El papel moneda fue introducido por primera vez en China, en torno al siglo IX, como dinero en efectivo intercambiable por certificados emitidos para el gobierno de la dinastía Tang por los bancos privados. Respaldado por la potente autoridad del Estado chino, este dinero conservaba su valor en todo el imperio, evitando así la necesidad de transportar la pesada plata. Convertido en monopolio del Estado bajo la dinastía Song, el papel moneda ha pervivido durante toda la historia china a pesar de las perturbaciones causadas por los cambios políticos y de que la emisión del papel moneda no estaba respaldada ni por plata ni por otras reservas. El problema de la depreciación hizo que, a partir de entonces, se mantuviera la plata como patrón de cambio chino para las transacciones importantes.

El papel moneda apareció por primera vez en Occidente en el siglo XVI, cuando se empezaron a emitir pagarés por parte de los bancos para respaldar los depósitos monetarios de sus clientes. Estos medios de cambio proliferaron y las autoridades coloniales francesas de Canadá utilizaban cartas de juego firmadas por el gobernador como promesa de pago desde 1685, ya que el envío de dinero desde Francia era muy lento.

El papel moneda se fue haciendo popular a lo largo del siglo XVIII, pero seguía siendo dinero crediticio que se emitía para respaldar los depósitos de oro o plata. El dinero fiduciario, cuando surgió, era normalmente una medida de urgencia para tiempos de guerra, como los papiros ("greenback") americanos. Los bancos privados fueron sustituidos paulatinamente por bancos centrales como autoridades emisoras de papel moneda.

A finales del siglo XIX la caída del valor del oro acarreó la creación de un patrón oro internacional en el que todas las monedas podían intercambiarse por oro y el valor del dinero (más que los precios) estaba fijado por la paridad de la moneda con el oro. Casi todos los gobiernos suspendieron la convertibilidad de sus monedas durante la Primera Guerra Mundial, perdiéndose todo el interés por volver a introducir el patrón oro internacional tras la Gran Depresión. El Reino Unido abandonó el patrón oro en 1931 y la transformación de las monedas mundiales a dinero fiduciario con valores fijados totalmente por la demanda del mercado culminó con el abandono de la vinculación del dólar estadounidense en 1971.

Las monedas toman su nombre de diversas procedencias.


La moneda tiene una serie de características intrínsecas que es importante conocer a los fines de poder fijar la relación que existe con otras monedas que circulan tanto dentro de un mismo estado como en otros países.



Las monedas pueden sufrir diferentes clasificaciones:

Impropiamente se colocan entre las monedas las "contorneadas". Algunos las confunden con los medallones de metal doble, es decir, contorneados por una orla de metal más fino pero propiamente son medallas de bronce de gran módulo con un surco circular en el contorno, donde suelen estar los glóbulos. Se conoce que este surco fue hecho posteriormente pues a veces corta hasta la inscripción. Son sutiles y poco elegantes discordando a menudo el anverso del reverso. Llevan varios sellos incusos, especialmente la rama de palma y el monograma £ o una R invertida, siempre es en hueco y a veces relleno de plata. No tienen fecha: parece que acuñaban solo por autoridad privada y que servían para carreras y espectáculos circenses.

Las monedas más primitivas se acuñaban por medio de un golpe en un troquel se grababa una marca en el anverso de una pieza de metal o "cospel". El resultado eran monedas de impronta irregular y variable que reciben el nombre de "incusas" y se caracterizan porque presentan la misma imagen por los dos lados: en una en relieve y en la otra en hueco. Este procedimiento permaneció sin mayores cambios hasta el siglo XVI, y continuó utilizándose en muchas importantes cecas, como la de Potosí y México, hasta el siglo XVIII.

Una modalidad menos frecuente, que aparece en monedas de China, Japón y Vietnam, era el empleo de un molde hueco en el que se vertía el metal fundido.
Los griegos, romanos, y los reinos europeos en la Edad Media utilizaron la acuñación a martillo, sin mayores innovaciones técnicas.
Durante la Edad Media la acuñación de moneda era facultad especial del monarca, pero era frecuente que por concesión o privilegio distintas ciudades, nobles o monasterios hicieran sus propias acuñaciones.
Hacia 1500, Leonardo da Vinci diseñó una prensa mecánica que permitía acuñar simultáneamente el anverso y el reverso, para imprimir monedas, sellos y medallas en el Vaticano. El diseño nunca fue construido.

En 1550 un orfebre de Augsburgo, Max Schwab, creó una prensa de volante, que consistía en un tornillo que subía y bajaba para golpear el cuño, impulsado por un eje transversal con dos cilindros de plomo. El rey Enrique II de Francia adquirió el equipo y el grabador Antoine Brucher realizó varias pruebas en 1553. La nueva prensa sin embargo no logró implantarse debido a la oposición de los fabricantes de moneda que preferían mantener el antiguo sistema de acuñación a martillo.
El grabador e ingeniero francés Nicholas Briot (1579-1646) realizó varias mejoras a esta prensa de volante pero no pudo convencer al gobierno. Sin embargo, Briot fue bien recibido por el rey Carlos I de Inglaterra y acuñó monedas y medallas para la Royal Mint. En Francia este mismo sistema fue implantado posteriormente por su hermano, Isaac Briot.

La primera acuñación mecánica, seriada y uniforme se introdujo en 1551 en la Casa de Moneda de Hall (Tirol) utilizando un molino hidráulico de laminación. Dos grandes rodillos aplanaban el metal, utilizando el mismo procedimiento para posteriormente aplicar la impronta o motivo. Fue aplicado en muchas cecas europeas, y permaneció hasta fechas modernas para la laminación del metal, a veces en combinación con otros sistemas de impresión.

En 1686 en las cecas francesas comenzó a utilizarse la máquina diseñada por el ingeniero Jean Castaing, que permitía grabar el canto de los cóspeles con un diseño o cordoncillo.

El inicio de la Revolución Industrial incentivó la aparición de varias máquinas, entre ellas la prensa patentada por el mecánico alemán Dietrich Ulhorn que permitía la acuñación uniforme a gran velocidad. Sustituía el tornillo por un juego de palanca articulada con un motor impulsado por vapor, sustituido posteriormente por la electricidad. El sistema fue posteriormente perfeccionado en 1833 por el ingeniero francés Pierre-Antoine Thonnelier. Este diseño básico, con adecuaciones y mejoras, permanece en uso hoy día.

En 1830 el ingeniero suizo Jean Pierre Droz inventó el sistema de virola partida, con lo cual se conseguía acuñar las dos caras de la moneda a la vez y también el canto. La acuñación del canto fue un factor de gran importancia ya que evitaba el robo de metal por medio de recortes. Como se expuso anteriormente en la antigüedad las monedas llevaban el cuño por ambas caras y el rey garantizaba el peso del metal de la moneda. La forma de robo consistía en recortar los rebordes y así juntar el metal que se recortaba de varias monedas para acuñar una nuevas.

Para revisar la autenticidad de las monedas, se recomienda hacer un examen al tacto, visual y comparativo.

Al tocar una moneda se debe poner atención en:

El ensamble. En las monedas bimetálicas, el ensamble del anillo perimétrico es prácticamente perfecto, por lo que al tacto no se percibe ningún borde en su unión con el núcleo o centro de la moneda.

El canto. Este puede ser liso, estriado (serie de ranuras paralelas en el espesor o canto de la moneda), estriado discontinuo (combinación de ranuras paralelas y partes lisas) o con una ranura perimetral. Si presenta rebabas, u otras irregularidades, puede tratarse de una moneda falsa.

La textura. Una moneda debe presentar una textura lisa. En caso de sentirse resbalosa o jabonosa, podría tratarse de una moneda fundida y en consecuencia, esa moneda es falsa.

A simple vista se pueden revisar:

En caso de dudar de la autenticidad de una moneda, se puede comparar en su peso, diámetro y espesor, con otra que tenga la seguridad de que es auténtica. Cualquier diferencia que se note en el peso, en el diámetro o en el espesor, puede indicar que se trata de una moneda falsa.

Las funciones de las monedas se encuentran íntimamente relacionadas con las funciones del dinero (que es lo que representa) que se pasan a detallar:


Las características que presenta la moneda como medio de pago, se pueden sintetizar en las siguientes:



</doc>
<doc id="6807" url="https://es.wikipedia.org/wiki?curid=6807" title="Idioma galaicoportugués">
Idioma galaicoportugués

El galaicoportugués o gallegoportugués, también conocido como gallego medieval o portugués antiguo era la lengua romance hablada durante la Edad Media en toda la franja noroccidental de la península ibérica, desde el mar Cantábrico hasta el río Duero. De la evolución de esta lengua proceden los actuales idiomas gallego y portugués, que los que apoyan el reintegracionismo consideran actualmente una sola lengua, a pesar de sus diferencias diatópicas. En Portugal el galaicoportugués se denomina también, "portugués medieval", así como en Galicia, con mayor propiedad, "gallego medieval".

El rey portugués Don Dinis declaró el portugués como idioma oficial de la administración del reino en 1290 (hasta entonces el latín era el idioma oficial).

El galaicoportugués medieval tuvo su máxima importancia en la Península desde finales del siglo XII hasta mediados del siglo XIV. Hacia el 1400 el galaicoportugués fue, para algunos autores, perdiendo su unidad fruto de la división de su solar entre dos estados distintos (el reino de Portugal y la parte Gallega de la Corona Leonesa) y del hecho de ser una lengua de segundo nivel (debido a la oficialidad / obligatoriedad del español para escritos oficiales y otros menesteres) dentro de la propia Galicia (con lo que la versión gallega del idioma se fue viendo influenciada por el español). Así algunos autores defienden que se separó en dos versiones diferentes: el gallego y el portugués.

La separación idiomática de las dos variedades lingüísticas es discutida en la actualidad por las diferentes escuelas filológicas o grupos de opinión con respecto a ese tema. Actualmente existen diferencias diatópicas entre el gallego y el portugués. El portugués, principalmente el hablado al sur del Duero, adoptó muchas palabras árabes y a partir del siglo XVI de las excolonias portuguesas en Sudamérica, África, Asia y Oceanía.



Uno de los rasgos más importantes de la fonología medieval gallegoportuguesa es la existencia de tres pares de sibilantes que han evolucionado de forma distinta en portugués y gallego:

Es decir tanto portugués como gallego tendieron a simplificar de formas distintas el complejo sistema de sibilantes medieval. El portugués se decantó por la eliminación de la difereciación en cuanto al punto de articulación tal como los acentos hispanoamericano y andaluz del español, mientras el gallego se decidió por la eliminación de la oposición en la sonoridad.

Durante la Edad Media, el galaicoportugués fue el vehículo de una importante tradición literaria, la lírica galaicoportuguesa, que ha llegado hasta nosotros en tres cancioneros:

Algunos poetas destacados fueron: Bernardo de Bonaval, Airas Nunes, Pedro da Ponte, Pero Amigo y Martín Codax o el rey portugués Don Dinis "rey trovador". El uso literario del gallegoportugués no se limitó al oeste de la Península, sino que fue también ampliamente cultivado en los reinos de Castilla y de León. El rey Alfonso X el Sabio, de Castilla, compuso sus Cantigas de Santa María y varias cantigas de Escarnio e Maldizer en galaicoportugués.




</doc>
<doc id="6809" url="https://es.wikipedia.org/wiki?curid=6809" title="Danubio">
Danubio

El Danubio es un río del centro de Europa que fluye en dirección principalmente oeste a este a través de diez países —Alemania, Austria, Eslovaquia, Hungría, Croacia, Serbia, Rumania, Bulgaria, Moldavia y Ucrania— desaguando en el mar Negro, donde forma el delta del Danubio, una región de gran valor ecológico. Con 2850 km es el , tras el Volga. 

Constituyó durante la Edad Antigua una de las fronteras naturales que formaban el "limes" del Imperio romano (junto con el Rin y otros ríos y algunos trechos fortificados). En las fuentes clásicas se le llamaba Istro.

Nace en Donaueschingen, en la Selva Negra de Alemania, de la unión de dos pequeños ríos, el Brigach y el Breg, y desemboca en el mar Negro en Rumanía.

La cuenca del Danubio tiene una superficie de unos y abarca numerosos países de la Europa Central y Oriental. El Danubio cruza Europa de oeste a este y su curso incluye partes de Alemania, Austria, Eslovaquia, Hungría, Croacia, Serbia, Rumania, Bulgaria, Moldavia y Ucrania. La cuenca del Danubio se extiende además por la República Checa, Suiza, Italia, Eslovenia, Bosnia y Herzegovina y Montenegro.

El Danubio adquiere los siguientes nombres por los países por donde pasa: Donau (en Alemania y Austria), Dunaj (en Eslovaquia), Duna (en Hungría), Dunav (en Croacia, Serbia, Bulgaria y Ucrania) y Dunărea (en Rumania). 

Es navegable, subiendo la corriente desde el mar Negro, por barcos transoceánicos hasta Brăila (Rumania) y por embarcaciones fluviales hasta la ciudad de Ulm (Alemania), a una distancia de unos .

Aproximadamente 60 de sus 300 afluentes son navegables. Los más importantes son los ríos Lech, Isar, Eno (Inn), Morava, Váh (Vág), Raab (Rába), Drava (Dráva), Tisza, Sava (Száva), Siret y Prut. Hay canales que unen el Danubio con los ríos Meno, Rin y Oder, y otro canal sale del Danubio para desembocar directamente en el mar Negro en el puerto de Constanza, antes de llegar al delta.

Su caudal es considerable ( o ), como corresponde a un río con una cuenca extensa. Su caudal máximo en la represa de las Puertas de Hierro se midió el 13 de abril de 2006 y alcanzó . El Danubio ha causado inundaciones desastrosas en casi todos los países que atraviesa, especialmente en Rumania. Su caudal en Viena ya es, en promedio, unos , en Budapest, y en Belgrado unos . En el curso alto en el distrito de Tuttlingen en Baden-Wurtemberg está el Sumidero del Danubio, ejemplo de captura fluvial kárstica, en el que una parte de río Danubio desaparece bajo tierra. Las aguas reaparecen en Aachtopf, a de distancia, y acaban vertiendo al Rin en el lago de Constanza y por tanto formando parte de la vertiente del mar del Norte, en lugar del mar Negro como sucede con las aguas no infiltradas del Danubio. La anchura del Danubio es variable, como corresponde a un río que atraviesa varias zonas diferenciadas en cuanto al relieve: Baviera, Austria, llanura húngara, desfiladero de las Puertas de Hierro, Valaquia (llanura meridional de Rumania). Su anchura antes de dividirse en el delta es de casi , dividiéndose en tres brazos (Braţul) principales: Braţul Chilia, el más caudaloso, al norte, con de anchura en su desembocadura, ubicado entre Rumania al sur y Ucrania al norte; Sulina en el centro (canalizado, con de ancho en su desembocadura) y Braţul Sfântul Gheorghe al sur, con de anchura. El delta del Danubio es una zona muy importante desde el punto de vista ecológico, ya que constituye un extenso humedal utilizado por muchas aves migratorias desde fines de la primavera hasta comienzos del otoño. El delta del Danubio fue declarado por la Unesco como Reserva de la Biosfera en 1990.

El Danubio pasa por importantes ciudades como Ulm, Ingolstadt, Passau y Ratisbona en Alemania; Linz y Viena en Austria; Bratislava en Eslovaquia; Budapest, donde el famoso Puente de las Cadenas cruza el río uniendo Buda y Pest, en Hungría; Novi Sad y Belgrado en Serbia y Galați en Rumania, Vidin y Ruse en Bulgaria. Es una vía muy importante para la Europa Central y Oriental, aunque su tráfico es, en Europa, de menor importancia relativa que el del Rin. Ello se debe a la menor densidad de población de su cuenca, a su menor industrialización y, sobre todo, a la heterogeneidad social, económica, cultural, política y lingüística de los países que atraviesa. Sin embargo, es probable que la integración europea sirva para derribar todos los obstáculos creados por esta heterogeneidad y haga aumentar considerablemente su importancia económica como ruta natural. Para ello será fundamental disminuir el problema de las inundaciones de primavera, así como el establecimiento de acuerdos que faciliten la libre comercialización de las materias primas más pesadas y de menor valor específico por tonelada entre los distintos países danubianos (minerales y materiales de construcción, etc.).

La agricultura de los países danubianos es por lo general, extensiva, basada en la explotación de propiedades medias y grandes, en gran parte colectivizadas a partir de la Segunda Guerra Mundial, sobre todo en los países socialistas bajo la influencia soviética. Tiene mucha importancia el cultivo de cereales (trigo y maíz, especialmente), patatas, remolacha azucarera, uva, así como la ganadería, tanto intensiva como extensiva, y la agroindustria. Son famosos el vino Tokay y la paprika o pimentón como condimento, ambos productos de Hungría, así como la cerveza en Baviera y la República Checa.

La industria es la actividad económica más importante en casi todos los países danubianos. Las materias primas para esta industria utilizan el Danubio como vía de transporte principal (100 millones de toneladas anuales en 1989, antes del conflicto serbio-bosnio). Entre las principales ramas de la producción industrial se pueden citar las relacionadas con material de transporte: automóviles Audi en Ingolstadt y BMW (Bayerische Motoren Werke) en Múnich (Baviera, Alemania); Magirus Deutz (IVECO) de Fiat Group Automobiles (F C A desde enero de 2014) (Fiat Chrysler Automobiles Inc.), (Baden-Württemberg, Alemania); Skoda, del Grupo Volkswagen, en la República Checa; Ikarus (camiones y autobuses, con licencia de la AB Volvo de Suecia) en Hungría; Sava y Yugo en Yugoslavia, Dacia en Rumanía (con licencia Renault) y de otras empresas, así como la industria ferroviaria (construcción de vagones y locomotoras, etc.). La industria pesada (industria química y siderúrgica en todos los países danubianos; petrolera y petroquímica en Rumanía), así como la producción de maquinaria de precisión en Alemania y Austria, también son muy importantes.

El comercio nunca fue tan activo como en la Europa Occidental. Este hecho se debió a la heterogeneidad cultural, socioeconómica y política de los países danubianos. El renacimiento del comercio será mucho más factible con la reciente ampliación de la Comunidad Europea.

La cuenca del Danubio es una región muy amplia, cuya peculiaridad se inició desde tiempos muy remotos en la Prehistoria. El nombre "Danubio" contiene el hidrónimo indoeuropeo "*danu-" 'agua corriente, río' muy común en la Europa oriental (Dniéper, Dniéster, Don, etc.).

Su gran importancia estratégica se debe a que, al formar la mayor parte de Europa Central, siempre sirvió de salida natural entre Europa del Norte, Europa del Este, Europa Occidental y Europa Mediterránea o del sur. Pero el mismo hecho de estar en el centro, hizo de la cuenca danubiana una tierra de invasiones, de coexistencia (no siempre pacífica) de numerosos grupos humanos cultural y racialmente distintos, de superposición o yuxtaposición de sistemas políticos diferentes, y del desarrollo de diversos modos de vida.

Esta heterogeneidad dio origen a que el francés Jean Gottmann, profesor de Geografía de Europa en la Universidad de Oxford, identificara el capítulo dedicado a la Europa Central como "The Tidal Lands of Europe" (‘las tierras de marea de Europa’), denominación traducida como ‘las tierras de aluvión de Europa’, en la versión española del texto. 

En cualquier caso, es indudable que numerosas oleadas de pueblos tanto nómadas como sedentarios, así como las campañas de muchos ejércitos, desde los más pequeños de carácter feudal hasta los imperiales; las invasiones, guerras y batallas; el surgimiento de países pequeños y grandes; la integración de varios estados distintos y la desmembración posterior de los mismos junto con muchos otros procesos turbulentos de la Historia, han sido muy frecuentes, a lo largo y ancho de la cuenca del Danubio. 
Para dar un ejemplo de la enorme diversidad o heterogeneidad de la cuenca danubiana, que se debe principalmente a la Historia turbulenta de esta región, podemos señalar la existencia de varios grupos lingüísticos: magiares, eslavos, germanos, latinos, turcos y otros de menor importancia. Ello sin contar con las lenguas habladas por las tribus nómadas que poblaron la región desde los tiempos prehistóricos, como es el caso de los celtas y otros pueblos indoeuropeos primitivos. 

Algunos topónimos de origen celta, como es el caso del río Isar, pueden servir para corroborar esta idea. Muchos de los otros topónimos son de origen latino, como Ratisbona (Regensburg), Panonia o Rumania. Y la mayoría son germanos, eslavos o magiares (según los países). 

Aunque el río Danubio sirvió de límite natural para definir el territorio del Imperio romano durante la Edad Antigua (el limes romano), no pudo evitar la interpenetración de grupos distintos a ambos lados del río: latinos de origen romano al norte (rumanos) y eslavos al sur (yugoslavos significa eslavos del sur en las lenguas eslavas), aunque estos últimos ya se establecieron al sur del Danubio en la Edad Media. 

Algunos pueblos de origen germano terminaron por asentarse a lo largo de esta frontera natural y la cruzaron finalmente hacia el sur durante las llamadas invasiones bárbaras, hecho que marca la separación entre la Edad Antigua y la Edad Media. 

En este sentido, los visigodos se establecieron en la Cuenca del Danubio y se vieron, a su vez, presionados por los hunos. En otras ocasiones, los propios grupos de origen germánico cruzaron el Danubio para asentarse en zonas fértiles con tal de defenderlas de nuevas invasiones: es el caso, por ejemplo, de Moesia. También los magiares, de origen asiático, se establecieron en la llanura de Panonia (actual Hungría), en una región natural formada por una cuenca sedimentaria rodeada por relieves montañosos y cruzada de norte a sur, obviamente, por el Danubio.

Aunque los conflictos bélicos no cesaron en la Cuenca del Danubio, podríamos decir que, al quedar las tierras danubianas en manos del Imperio romano de Oriente o Imperio bizantino, tras la división del Imperio romano en el siglo IV, la situación se estabilizó durante toda la Edad Media. Como consecuencia de este hecho, la influencia de la cultura bizantina (alfabeto griego, arquitectura, religión, etc.) se extendió por todo el Danubio y la Europa Oriental (Ucrania y Rusia) durante toda la Edad Media: aún hoy podemos encontrar manifestaciones de la arquitectura bizantina en todos los países de la Europa danubiana, además de los demás países de la Europa Oriental. 

Desde luego, fue a través de un comercio muy activo como se fueron extendiendo muchas de las manifestaciones culturales del Imperio bizantino. El final del Imperio bizantino en 1453, marcado por la toma de Constantinopla (Bizancio) por los turcos, marca también el fin de la Edad Media y el comienzo de una eterna lucha que ha venido a continuar hasta nuestros días, entre los grupos predominantes en el Danubio. Una de estas luchas, cuyo escenario estuvo en gran parte en la cuenca superior y media del Danubio, fue la Guerra de los Treinta Años (1618-1648), que podría considerarse, por la gran extensión del conflicto, como la primera gran guerra europea. 

El hecho de que muchos sucesos bélicos ocurriesen en la cuenca del Danubio se debió a que en los conflictos motivados por la Reforma protestante (siglo XVI), la Casa de Austria había tomado la defensa del catolicismo. 

En el siglo XVIII, la Guerra de los Siete Años también afectó poderosamente a la vida política de los países danubianos, al menos, en gran parte. 

Y en el siglo XIX, tres hechos fundamentales de la historia europea, las guerras napoleónicas, el Congreso de Viena y la creación del Imperio austrohúngaro, tuvieron consecuencias muy importantes en los países del Danubio.

Por último, la mayor parte de los conflictos y procesos violentos que vivió Europa en el siglo XX (Primera Guerra Mundial y Segunda Guerra Mundial; balcanización en el sureste del continente, modificaciones de fronteras, imposición soviética en los países socialistas bajo su dominio (por ejemplo, con expresiones de esta dominación como la toma de Budapest por los tanques rusos en 1956), también tuvieron lugar en gran parte en los países danubianos: alrededor de unos 30 millones de víctimas de las guerras murieron en la región durante el siglo XX). 

Y el conflicto serbo-bosnio a finales del siglo pasado vino a completar la imagen de la historia turbulenta que se indicaba al principio de esta sección sobre la historia de esta región natural de Europa. Así, durante la Guerra de Kosovo en 1999, el transporte a lo largo del río se obstaculizó por el bombardeo, por parte de la OTAN, de tres puentes en Serbia. El restablecimiento de dicho tráfico se logró completamente en 2005.

El Expreso de Oriente entre París y Estambul hacía un largo recorrido por los países danubianos, pasando por Viena, Budapest y muchas otras ciudades. Dejó de funcionar en el 2001, cuando se redujo su recorrido hasta Viena. En este tren de largo recorrido se desarrolla la trama de la novela "Asesinato en el Expreso de Oriente", de Agatha Christie.

Existe una ruta cicloturista por el Danubio que, aprovechando en parte una antigua calzada romana, facilita recorrer 2857 kilómetros del río en bicicleta.

La cuenca del Danubio no posee un estilo musical propio (como sucede en la cuenca del Volga, por ejemplo), dada la gran heterogeneidad cultural del territorio. La música y danza folclóricas, por lo tanto, son muy variadas. Austria es la patria del vals y su versión vienesa es la más ampliamente conocida y difundida en todo el mundo. También lo es del "yodel", un tipo de canciones tirolesas en el que los cantantes, generalmente pastores de las montañas alpinas, emiten rápidamente sonidos muy cambiantes de tono, especie de gorgoritos o vibraciones rápidas de la garganta, cuya producción se facilita por un defecto tradicional de la población de las montañas causado por la falta de yodo, el bocio endémico. En Hungría, las "czardas" son composiciones musicales para la danza, con un ritmo muy vivo.

A pesar de lo que se ha señalado, hay que acotar que el folclore (música y danza populares) es algo mucho más universal que muchas otras manifestaciones culturales. Es por ello que existen influencias mutuas muy poderosas entre la música y baile populares eslavos, húngaros, germánicos y rumanos, y las semejanzas se deben, indudablemente, a la proximidad geográfica. Así, muchos compositores alemanes, eslavos o de otras nacionalidades de países ajenos a los países danubianos, han incursionado en la música popular húngara (por citar un ejemplo) y viceversa. En este sentido, son famosísimas las "Danzas húngaras" del compositor alemán Brahms y las "Czardas" del italiano Vittorio Monti.

Entre los principales compositores nacidos en la cuenca del Danubio podemos citar a los alemanes Johann Pachelbel y Richard Strauss; a los austríacos Johann Strauss (hijo), Franz Schubert y Wolfgang Amadeus Mozart y a los húngaros Franz Liszt, Béla Bartók y Márk Rózsavölgyi, entre otros.

El "Danubio azul" es tal vez el vals más conocido entre las composiciones de Johann Strauss, y ha sido una pieza musical ampliamente utilizada en numerosas películas, de las que pueden destacarse la dirigida por Stanley Kubrick, "" (película que también utiliza la obra de Richard Strauss "Así habló Zaratustra" en su escena inicial), una película de dibujos animados de 1942 del Pato Lucas ("A Corny Concerto"), una película japonesa del año 2000 ("Batalla Real"), en un capítulo del programa de TV "Los Simpsons", en "Los tres mosqueteros" (Mickey, Donald, Tribilín o Goofy) de Walt Disney (2004), entre otras.

Tampoco existe un cine danubiano, sino películas que se desarrollan en los países danubianos y que rara vez trascienden a las fronteras, salvo excepciones, casi siempre con películas norteamericanas ambientadas en el Danubio, que siempre tuvieron una dimensión más universal. A continuación, se presenta una pequeña lista de películas ambientadas en los países danubianos: 






</doc>
<doc id="6810" url="https://es.wikipedia.org/wiki?curid=6810" title="Volga">
Volga

El Volga ( ) es un río de la Rusia europea que, con sus , es el y el . Administrativamente, recorre diez óblasts —Tver, Yaroslavl, Kostromá, Ivánovo, Nizhni Nóvgorod, Uliánovsk, Samara, Sarátov, Volgogrado y Astracán— y tres repúblicas —Mari-El, Chuvasia y Tartaristán.

El Volga nace en las colinas de Valdái a 228 m de altitud, entre Moscú y San Petersburgo, y desemboca en el mar Caspio. Es navegable en casi todo su recorrido gracias a las enormes obras de acondicionamiento realizadas principalmente durante la segunda mitad del siglo XX por Iósif Stalin. Su cuenca hidrográfica, con una superficie de , es la y riega un tercio de la Rusia europea, reuniendo un gran mosaico de pueblos y, desde la II Guerra Mundial, una parte importante de las actividades industriales de Rusia. Desempeña también un gran papel en el imaginario ruso e inspiró numerosas novelas y canciones rusas, por ejemplo el "Canto de los remeros del Volga".

El nombre ruso "Во́лга" se aproxima a palabras eslavas que designan el carácter «mojado», «húmedo» ("влага" , "волога"). Este nombre se traduce en francés y en inglés por " Volga" y en alemán por " Wolga". El nombre podría también tener orígenes finlandeses. 

Las poblaciones turcas que viven a bordo del río lo llaman "Itil" o "Atil". Atila el Huno podría deber su nombre al río. Hoy día en las lenguas vinculadas con el turco, el Volga se conoce bajo el nombre de "İdel" (Идел) en tártaro, "Атăл" (Atăl) en chuvasio e " İdil" en turco. En idioma mari el río se llama " Юл" (Yul) utilizando la misma raíz.

Si nos remontamos más lejos aún en el tiempo, los escitas daban al río el nombre de " Rha" que puede asociarse a la antigua palabra del sánscrito "Rasah" designando un río sagrado. Este origen se conserva en el nombre dado por los mordves al río: Рав (Raw).

El río Volga nace en las colinas de Valdái a 228 msnm, cerca de la localidad de Volgo-Verjovie (óblast de Tver), en un lugar situado a unos 300 km al noroeste de Moscú y a unos 320 km al sureste de San Petersburgo.En el primer tramo tiene el nombre de Selizhárovka y es un corto curso de agua de 36 km que desagua en el lago Seliguer (que tiene una superficie de 212 km² y está a una cota de 205 m). El Volga se dirige primero en dirección Sudeste, atravesando la región de Valdái hasta alcanzar la localidad de Rzhev (63 729 hab. en 2002), pasada la cual vira hacia el Noreste y a partir de la que pueden navegar por el río pequeñas embarcaciones de transporte de mercancías. El río, tras algo más de 100 km, alcanza Tver (la antigua Kalinin, fundada en 1135, con 408 903 hab.), la capital del óblast localizada en la carretera que une Moscú con San Petersburgo. 

El Volga describe una nueva curva y vira hacia el suroeste, discurriendo por el primero de los muchos tramos en que sus aguas estarán embalsadas, está vez por la presa de Ivankovo, donde recibe por la derecha el río Shosha. Gira luego hacia el Oeste, y se adentra en el embalse de Dubna, construido para abastecer Moscú (es el tramo más próximo a la capital, a apenas 100 km). En este embalse recibe al río Dubna, y, muy próximo a la presa, conecta con el canal de Moscú, un canal artificial de 128 km construido en 1932 que une el río Volga con el río Moscova. Dejada atrás la presa, el Volga baña la localidad de Dubná (60 951 hab.), y luego vira hacia el Noreste, en un tramo en el que atraviesa la ciudad de Kimry (58 500 hab.) y sigue por el embalse de la presa de Úglich, un nuevo tramo en el que recibe sus primeros afluentes de importancia, los ríos Medveditsa y Nerl. Sigue el río en dirección cada vez más Norte, franqueando el límite con el óblast de Yaroslavl, atravesando la ciudad de Úglich (38 900 hab.) y llegando hasta el gran lago de la presa de Rybinsk (que con 4 580 km², es conocido como el mar de Rybinsk, y que está a una cota de 102 m). Es la más antigua de las presas construidas en el río (1935-41) y también el punto más septentrional por el que discurre el Volga. En este lago desembocan dos importantes afluentes, el río Mologa (456 km) y el río Cheksna. También enlaza la vía navegable Volga-Báltico, que atravesando el lago Onega y el lago Ladoga, conecta con el golfo de Finlandia y, a través del canal Mar Blanco-Báltico, el mar Blanco.

El Volga sale del lago por el mismo lado meridional por el que entra, emprendiendo dirección Sureste. Al pie de la presa se encuentra la ciudad industrial de Rybinsk (222 653 hab., anteriormente rebautizada como Andropov) que es el gran puerto de transbordo del curso superior del Volga. Sigue el río hacia el Sureste y alcanza Yaroslavl (613 088 hab.), una de las más antiguas ciudades de la Rusia central, fundada en el siglo XI. El río se encamina cada vez más en dirección Este, traspasando el límite con el óblast de Kostromá. A unos 70 km aguas abajo de Yaroslavl se encuentra la ciudad de Kostromá (278 750 hab.), localizada al poco de la confluencia con el río Kostroma, otra antigua ciudad (fundada en 1152). A partir de aquí, el Volga se va convirtiendo cada vez más en un río de llanura, ancho y de discurrir lento. Atraviesa pronto el óblast de Kostromá por su parte meridional y se interna en el óblast de Ivánovo, que cruza por su parte nororiental. Llega enseguida a Kíneshma (95 233 hab.) y aguas abajo encuentra un nuevo gran lago artificial, el del embalse de Gorki (1 591 km²), con una cola de 430 km de longitud, creado por la presa de Nizhni Nóvgorod (construida en 1955). En la parte Norte del embalse desaguan los ríos Nemda y Unzha (426 km). Siguiendo el gran embalse aguas abajo en dirección Sur, se entra en el óblast de Nizhni Nóvgorod, y recibe por la izquierda al río Uzola. El Volga deja atrás la presa y se encuentra en la ribera derecha la ciudad de Nizhni Nóvgorod (1 311 252 hab.), en la confluencia con uno de sus afluentes más importantes, el río Oká (1 500 km). Este es el punto en que tradicionalmente se ha considerado que acaba el curso alto del Volga. Al otro lado del río, en la margen izquierda, enfrente, se localiza la ciudad industrial de Bor (61 525 hab.).

El curso medio del Volga discurre en dirección Este-Sureste, cruzando la parte central de la Rusia europea, y se comienza a observar ya la disimetria, de sus riberas, que se manifiesta más claramente en el curso bajo, con la orilla derecha más alta y escarpada, a causa de la presencia de las estribaciones de las alturas del Volga, en contraposición a una orilla izquierda más baja. Al salir de Nizhni Nóvgorod, el río vira en dirección Este, pasando frente a Kstovo y recibiendo por la izquierda al río Kerzhenets. Llega más abajo a otro largo embalse, el de Cheboksary, de más de 131 km, del que una parte está en el oblást de Nizhni Nóvgorod, la parte central en la república de Mari-El (en la que recibe por la izquierda los ríos Vetluga y Rutka) y la parte final en la república de Chuvasia, donde está también la presa, construida en la década de los 1980 (y para la que debieron de ser realojados unas 20 000 personas). Aguas abajo de la presa se encuentran las ciudades de Cheboksary (440 621 hab.) y Novocheboksarsk (125 857 hab.). Luego el Volga forma durante un tramo el límite natural entre las repúblicas de Chuvasia y Mari-El, un trecho en el que recibe por la izquierda los ríos Bolshaya Kokshaga, Malaya Kokshaga e Ilet, y por la derecha al Tsivil y en el que, también en la margen izquierda, está la localidad de Volzhsk (58 987 hab.). A continuación el río se interna, todavía en dirección Este, en la república de Tartaristán, bañando primero la ciudad de Zelenodolsk (100 139 hab.) y luego Kazán (1 105 289 hab.), la capital de la república, ambas en la margen izquierda. 

Pasada Kazán, el río (ya en otro tramo embalsado) vira hacia el Sur. La ciudad está situada al principio de otro largo embalse, el embalse de Kuibyshev, con 550 km de longitud, creado por la presa de Samara, que con sus 6 450 km² de superficie, es el mayor lago artificial de retención de Europa. El río Kama (1 850 km), el principal de los afluentes del Volga, se incorpora por la izquierda desaguando en este gran lago artificial, en un punto que ha sido considerado de forma habitual el inicio del curso bajo del Volga, aunque ahora, con el embalse, ha perdido parte de su relevancia geográfica.

El embalse se interna en dirección sur en el óblast de Uliánovsk, una provincia que atraviesa en su parte oriental y en la que se encuentra en la orilla derecha la capital, Uliánovsk (antiguamente Simbirsk, con 635 947 hab.). Más al sur, el lago se adentra en el óblast de Samara y luego forma una curva casi cerrada en la cual se sitúan, en la margen izquierda, las ciudades de Togliatti (702 879 hab.) y Samara (antes Kouïbychev, localizada en la confluencia con el río Samara, que cuenta con 1 157 880 hab.) y Novokuybyshevsk (112 973 hab.) donde desemboca el río Chapayevka; y, en la margen derecha, al final de la curva, la ciudad de Syzran (188 107 hab). Pasada Samara comienza pronto la cola de otra largo embalse, el embalse de Saratov (1 831 km²), situado 357 km aguas abajo. 

Siempre en dirección Sur, el embalse se adentra en el óblast de Sarátov, y tras pasar la presa, al pie, en su margen izquierda, el río baña la ciudad industrial de Balakovo (200 470 hab.). Al poco, también por la izquierda, el Volga recibe las aguas del río Irgiz, en uno de los pocos tramos intactos del antiguo curso, y en el que en la margen izquierda se sitúa la ciudad de Volsk (71 124 hab.). Las formas características del paisaje, constituido por prados y colinas al oeste y por una orilla plana al este, son todavía perceptibles entre Kazán y Volgogrado, aunque los lagos de los embalses sumergieron las antiguas orillas. 

El Volga gira hacia el Suroeste, y pasa, en la margen izquierda, frente a la pequeña ciudad de Marks (32 849 hab.), y luego por la de Engels (200 800 hab.). Frente a esta última, en la otra ribera, se encuentra la ciudad de Sarátov (873 055 hab.), un importante centro universitario. A partir de Marks, comienza ya la cola de otro largo embalse, el de la presa de Volgogrado (3 117 km²), con una longitud de unos 540 km. La región por la que discurre el río comienza a hacerse cada vez más desértica. El embalse sigue casi en dirección sur, y se adentra en el óblast de Volgogrado y al poco baña la ciudad de Kamychine (127 891 hab.), situada en la orilla izquierda del lago. Más abajo de la presa, se encuentran las ciudades de Voljski (313 169 hab.), a la izquierda, y 80 km aguas abajo, a la derecha, Volgogrado (antes Zarizyn, luego Stalingrado, con 1 011 417 hab.). Cerca de Svetly Yar, comienza el canal Volga-Don, inaugurado en 1952 y que, tras 101 km, permite alcanzar el mar Negro.

El Volga describe una curva en dirección Suroeste y emprende su largo tramo final. Al poco se interna en el último de los óblast por los que discurre: el óblast de Astracán, y al poco, se deriva un brazo, el río Akhtouba, que seguirá su propio curso paralelo al cauce principal por el lado izquierdo hasta desaguar en el mar Caspio. En este tramo, en el curso del Volga, está la localidad de Akhtubinsk (45 542 hab.), en la ribera izquierda, y al final del tramo, en la margen derecha, al principio del delta formado por el río, se encuentra el último de los centros urbanos de importancia que baña el río, Astracán (antes Itil, con 504 501 hab.). Una parte del delta está protegido ya que la región es un lugar de tránsito para las aves migratorias. El río Volga, sus brazos más importantes, el Bakhtemir y el Tabola, y también el brazo Akhtouba, más al este, desembocan todos en el mar Caspio, el lago más grande del mundo.

En el primer mapa se aprecian las siguientes ciudades en su curso: Tver (Тверь), Ríbinsk (Рыбинск), Yaroslavl (Ярославль), Kostromá (Кострома́), Kíneshma (Кинешма), Nizhni Nóvgorod (Ни́жний Но́вгород), Cheboksary (Чебокса́ры), Kazán (Казань), Uliánovsk (Ульяновск), Toliatti (Тольятти), Samara (Сама́ра), Syzran (Сызрань), Balakovo (Балаково), Sarátov (Сарáтов), Engels (Э́нгельс), Kamishin (Камышин), Volgogrado (Волгогра́д) y Astracán (А́страхань). Asimismo, en la imagen satelital, también aparecen algunas de estas ciudades.

El Volga es alimentado en un 60% por aguas procedentes de la fusión de las nieves, un 30% por aguas subterráneas y un 10% por el agua de lluvia. El Volga posee un régimen poco regular, ya que la mitad del agua que anualmente lleva el río lo hace en un periodo de solamente seis semanas: de finales de abril a principios de junio, en el momento del deshielo, que comienza en la parte sur de la cuenca, para propagarse rápidamente a continuación hacia el Norte. El nivel (altura de agua) del río está sometido a importantes fluctuaciones anuales: alcanza los 11 m en Tver; los 16 m antes del punto de confluencia con el río Kama; y los 3 m en la desembocadura, en Astracán. Sin embargo, la construcción de embalses en su curso y en el de sus afluentes ha permitido reducir considerablemente estas fluctuaciones.

La producción media interanual o módulo del río es de 182 m³/s en Tver; de 1110 m³/s en Yaroslavl; de 2970 m³/s en Nizhni Nóvgorod; de 7 720 m³/s en Samara; y de 8060 m³/s en Volgogrado. Aguas abajo de Volgogrado, el río no recibe más tributarios significativos y la evaporación determina una disminución de su caudal en un 2%. El caudal del río podía alcanzar antes como máximo 67 000 m³/s aguas abajo de la confluencia con el río Kama y 52 000 m³/s en Volgogrado, vertiéndose una parte de las aguas en las llanuras inundables de los alrededores. La precipitación anual en la cuenca es de 187 mm en Volgogrado, para un total de precipitaciones recibidas de 662 mm. Antes de la creación de los embalses, el Volga vertía en un año en su desembocadura 25 millones de toneladas de sedimentos y de 40 a 50 toneladas de minerales disueltos. Las aguas del Volga alcanzan una temperatura de 20-25 °C en julio y permanecen libres de hielo 260 días al año en Astracán.

No fue hasta después de la Segunda Guerra Mundial cuando la región se desarrolló realmente: se construyeron más de 200 fábricas (herramienta, automóvil) en las principales aglomeraciones. Se emprendieron gigantescos trabajos de adaptaciones sobre el Volga y su afluente el Kama, para hacer arterias de comunicación permanentes, producir electricidad e irrigar las tierras de secano situadas a lo largo del curso inferior. La explotación después de la Segunda Guerra Mundial de yacimientos de petróleo y gases importantes a lo largo de la cuenca (90 Mtes de petróleo y 28 mds de m³ producidos durante el año 2001) favorecieron la creación de una importante industria petroquímica dinámica, aunque los yacimientos tienen tendencia hoy día a agotarse. La parte central de la cuenca del río es relativamente fértil, aunque las precipitaciones sean muy irregulares de un año para otro. Por el contrario, las tentativas de riego de las tierras situadas más al sur no dieron los resultados esperados. Además una parte de las tierras cultivables, situadas en la orilla del mar Caspio se inundaron en los años ochenta, tras el aumento del nivel del mar Caspio, que cogió a los especialistas de improviso. La cuenca del Volga es rica en recursos mineros como la potasa y la sal. El delta del Volga, así como los accesos del mar Caspio, son ricos en pescado. Astracán, situada sobre el delta del Volga, es el centro de la industria de caviar.

En el curso del Volga se han construido numerosas presas para el aprovechamiento hidroeléctrico y la regulación del caudal, de modo que prácticamente apenas quedan tramos inalterados del curso del río. Siguiendo aguas abajo el río, las presas son las siguientes (con año de entrada en servicio, superficie de agua, volumen embalsado, producción eléctrica): 

El río Volga tiene muchísimos afluentes, siendo los más importantes los que recoge la Tabla siguiente, ordenada en dirección agua abajo. (Los tributarios de los afluentes, se ordenan en sentido inverso, desde la boca a la fuente)




<br>


</doc>
<doc id="6813" url="https://es.wikipedia.org/wiki?curid=6813" title="Logo (lenguaje de programación)">
Logo (lenguaje de programación)

Logo es un lenguaje de programación de alto nivel, en parte funcional, en parte estructurado; de muy fácil aprendizaje, razón por la cual suele ser el lenguaje de programación preferido para trabajar con niños y jóvenes. Fue diseñado con fines didácticos por Danny Bobrow, Wally Feurzeig, Seymour Papert y Cynthia Solomon, los cuales se basaron en las características del lenguaje Lisp. Logo fue creado con la finalidad de usarlo para enseñar programación y puede usarse para enseñar la mayoría de los principales conceptos de la programación, ya que proporciona soporte para manejo de listas, archivos y entrada/salida. Logo cuenta con varias versiones. 

Papert desarrolló un enfoque basado en su experiencia con Piaget a principios de los sesenta. Fundamentalmente consiste en presentar a los niños retos intelectuales que puedan ser resueltos mediante el desarrollo de programas en Logo. El proceso de revisión manual de los errores contribuye a que el niño desarrolle habilidades metacognitivas al poner en práctica procesos de autocorrección.
Es conocido por poder manejar con facilidad gráficas tortuga, listas, archivos y recursividad.
Logo es uno de los pocos lenguajes de programación con instrucciones en español en algunos intérpretes, entre ellos: FMSLogo, LogoWriter, WinLogo, Logo Gráfico, XLogo, MSWLogo y LogoEs. Logo tiene más de 180 intérpretes y compiladores, según constan en el proyecto "Logo Tree". 

XLogo, MSWLogo y LogoES tienen la particularidad de ser además software libre.

Una característica más explotada de Logo es poder producir «gráficos tortuga», es decir, poder en dar instrucciones a una tortuga virtual, un cursor gráfico usado para crear dibujos, que en algunas versiones es un triángulo, en otras tiene la figura de una tortuga vista desde arriba. Esta tortuga o cursor se maneja mediante palabras que representan instrucciones, por ejemplo:

forward 100 (la tortuga camina hacia delante 100 pasos)
turnright 90 (la tortuga se gira hacia la derecha 90º)
turnleft 30 (la tortuga se gira hacia la izquierda 30º)

avanzar 100
girarderecha 90
girarizquierda 30

La característica de que las instrucciones se puedan comprender en las diferentes lenguas es lo que hace al "Logo" un lenguaje de programación tan fácil de aprender.
Una secuencia de instrucciones en Logo puede constituirse en un rudimentario programa, usándose como un bloque. Esta caracterísctica modular y reutilizable de las instrucciones hace que Logo sea muy flexible, recursivo, y apto para trabajarse en forma de módulos.

Otras instrucciones básicas de Logo en español son:
Las instrucciones básicas de desplazamiento varían de una versión de LOGO a otra, pudiendo encontrar como equivalentes: DE, DERECHA, GD, por ejemplo, para indicar un giro en sentido de las agujas del reloj.



</doc>
<doc id="6816" url="https://es.wikipedia.org/wiki?curid=6816" title="Síndrome del edificio enfermo">
Síndrome del edificio enfermo

El síndrome del edificio enfermo (SEE), se conoce también como "Sick Building Syndrome (SBS)".

La Organización Mundial de la Salud lo ha definido como un conjunto de enfermedades originadas o estimuladas por la contaminación del aire en estos espacios cerrados.

Es un conjunto de molestias y enfermedades originadas en la mala ventilación, la descompensación de temperaturas, las partículas en suspensión, la mala iluminación, los gases y vapores de origen químico y los bioaerosoles, entre otros agentes causales identificados.

El tipo de malestares que producen y estimulan estas situaciones es variado: migrañas, náuseas, mareos, resfriados persistentes, irritaciones de las vías respiratorias, piel y ojos, etc. Entre estos malestares, las alergias ocupan un papel importante.

En la evaluación, entre otras cosas, se ha de determinar el tipo y tamaño de las rejillas de impulsión, así como medir su caudal y compararlo con los estándares de ASHRAE ("American Society of Heating, Refrigerating and Air-Conditioning Engineers)

Los factores que contribuyen al síndrome se relacionan al diseño del ambiente construido, y puede incluir combinaciones de algunos o a todas las siguientes causas:

Al dueño o al operador de un "edificio enfermo", los síntomas pueden incluir altos niveles de empleados enfermos o ausentismo, baja productividad, baja satisfacción laboral y alta rotación de empleados.

La remoción de las fuentes de contaminantes o su modificación: correcto mantenimiento de los sistemas HVAC, reemplazo de materiales absorbentes (aislantes, cielorasos, paredes, carpetas, madera, aglomerados, etc) que presenten algún Compuesto Orgánico Volátil (VOC) o desarrollaran algún problema de humedad como moho. Utilizar pinturas, selladores, adhesivos y recubrimientos a base de agua, prohibir fumar en espacios interiores. Almacenar en espacios con ventilación independiente o en exteriores materiales o fuentes de emisiones de contaminantes como algunas pinturas, adhesivos, selladores, solventes, pesticidas, y utilizar los mismos durante periodos de no ocupación.

Asegurarse de proveer de adecuada renovación de aire en el espacio, incluyendo instalación y reemplazo periódico de filtros MERV. Incrementar las vistas de calidad hacia el exterior, proveer de iluminación natural a los ocupantes evitando el deslumbramiento y uso innecesario de iluminación artificial. 

Cambiando el posicionamiento de las fuentes de frío y calor, así como en los sistemas de renovación de aire de manera indirecta, para que nunca estén sobre las cabezas o sobre los cuerpos de las personas que conviven en las estancias. 

Adquiriendo un purificador de aire.

Creando normas básicas para que las condiciones ambientales para estancias en la que tengan que convivir varias personas con unos criterios lógicos de la calidad del aire: 

La temperatura ideal estará en torno a los 22 a 24º con un índice de humedad que no cree la sensación de agobio.

Si existen sospechas sobre la presencia del Síndrome del Edificio Enfermo en el edificio, se deberá llevar a cabo una investigación técnica y médica. En España, el Instituto Nacional de Seguridad y Salud en el Trabajo (INSST) ofrece un cuestionario para recoger toda la información posible sobre la situación del edificio y sus integrantes.





</doc>
<doc id="6817" url="https://es.wikipedia.org/wiki?curid=6817" title="Ion">
Ion

Un ion(tomado del inglés y este del griego ["ion"], «que va»; hasta 2010, ión) es una partícula cargada eléctricamente constituida por un átomo o molécula que no es eléctricamente neutro. Conceptualmente esto se puede entender como que, a partir de un estado neutro de un átomo o molécula, se han ganado o perdido electrones; este fenómeno se conoce como ionización. 

Cuándo un átomo pierde o gana electrones, la especie formada es un ion y lleva una carga eléctrica neta. Como el electrón tiene carga negativa, cuando se añaden uno o más electrones a un átomo eléctricamente neutro, se forma un ion cargado negativamente. Al perder electrones se produce un ion cargado positivamente. El número de protones no cambia cuando un átomo se convierte en un ion. 

Los iones cargados negativamente, producidos por haber más electrones que protones, se conocen como aniones (que son atraídos por el ánodo) y los cargados positivamente, consecuencia de una pérdida de electrones, se conocen como cationes (los que son atraídos por el cátodo).

Anión y catión significan:

Unas definiciones más formales son: Un catión es una especie monoatómica o poliatómica que tiene una o más cargas elementales del protón. Un anión es una especie monoatómica o poliatómica que tiene una o más cargas elementales del electrón.

"Ánodo" y "cátodo" utilizan el sufijo '-odo', del griego "odos" ("-οδος"), que significa camino o vía.

Un ion conformado por un solo átomo se denomina ion monoatómico, a diferencia de uno conformado por dos o más átomos, que se denomina ion poliatómico.

La energía de ionización, también llamada potencial de ionización, es la energía que hay que suministrar a un átomo neutro, gaseoso y en estado fundamental, para arrancarle el electrón más débil retenido.

X + 1ª energía de ionización → X + e 

La energía necesaria para arrancar un segundo electrón se llama segunda energía de ionización. Así puede deducirse el significado de la tercera energía de ionización y de las posteriores.<BR>X + 2ª energía de ionización → X + e

La energía de ionización se expresa en electrón-voltio, julios o en kilojulios por mol (kJ/mol).

1 eV = 1,6.10 culombios × 1 voltio = 1,6.10 julios

En los elementos de una misma familia o grupo la energía de ionización disminuye a medida que aumenta el número atómico, es decir, de arriba abajo.

En los alcalinos, por ejemplo, el elemento de mayor potencial de ionización es el litio y el de menor el francio.Esto es fácil de explicar, ya que al descender en el grupo el último electrón se sitúa en orbitales cada vez más alejados del núcleo y, además, los electrones de las capas interiores ejercen un efecto de apantallamiento frente a la atracción nuclear sobre los electrones periféricos por lo que resulta más fácil extraerlos.

En los elementos de un mismo período, la energía de ionización crece a medida que aumenta el número atómico, es decir, de izquierda a derecha.

Esto se debe a que el electrón diferenciador está situado en el mismo nivel energético, mientras que la carga del núcleo aumenta, por lo que será mayor la fuerza de atracción y, por otro lado, el número de capas interiores no varía y el efecto de apantallamiento no aumenta.

Sin embargo, el aumento no es continuo, pues en el caso del berilio y el nitrógeno se obtienen valores más altos que lo que podía esperarse por comparación con los otros elementos del mismo período. Este aumento se debe a la estabilidad que presentan las configuraciones s2 y s2p3, respectivamente.

La energía de ionización más elevada corresponde a los gases nobles, ya que su configuración electrónica es la más estable, y por tanto habrá que proporcionar más energía para arrancar un electrón. Puedes deducir y razonar cuáles son los elementos que presentan los valores más elevados para la segunda y tercera energías de ionización.

En los iones negativos, aniones, cada electrón, del átomo originalmente cargado, está fuertemente retenido por la carga positiva del núcleo. Al contrario que los otros electrones del átomo, en los iones negativos, el electrón adicional no está vinculado al núcleo por fuerzas de Coulomb, lo está por la polarización del átomo neutro. Debido al corto rango de esta interacción, los iones negativos no presentan series de Rydberg. Un átomo de Rydberg es un átomo con uno o más electrones que tiene un número cuántico principal muy elevado.

Los cationes son iones positivos. Son especialmente frecuentes e importantes los que forman la mayor parte de los metales. Son átomos que han perdido electrones.


Se denomina plasma a un fluido gaseoso de iones. Incluso, se puede hablar de plasma en muestras de gas corriente que contengan una proporción apreciable de partículas cargadas. Se puede considerar a un plasma como un nuevo estado de la materia, (aparte de los estados sólido, líquido y gaseoso), concretamente el cuarto estado de la materia, puesto que sus propiedades son muy distintas a los estados usuales. Los plasmas de los cuerpos estelares contienen, de manera predominante, una mezcla de electrones y protones, y se estima que su proporción es del 99,9 por ciento del universo visible.

Los iones son esenciales para la vida. Los iones sodio, potasio, calcio y otros juegan un papel importante en la biología celular de los organismos vivos, en particular en las membranas celulares. Hay multitud de aplicaciones basadas en el uso de iones y cada día se descubren más, desde detectores de humo hasta motores iónicos

Los iones inorgánicos disueltos son un componente de los sólidos (sólidos totales disueltos) presentes en el agua e indican la calidad de esta.




</doc>
<doc id="6818" url="https://es.wikipedia.org/wiki?curid=6818" title="Diseño de software">
Diseño de software

El diseño de software es el proceso por el que un agente crea una especificación de un artefacto de software, pensado para cumplir unos objetivos, utilizando un conjunto de componentes primitivos y sujeto a restricciones. El diseño de software  se puede referir a "toda la actividad implicada en conceptualizar, enmarcar, implementar, poner en funcionamiento y, finalmente, modificar sistemas complejos" o "la actividad que sigue a la especificación de requisitos y procede a la programación, como en un proceso de ingeniería de software estilizado.

Diseño de software normalmente implica problema solucionando y planeando una solución de ￼￼software.￼￼ Esto incluye ambos un componente de nivel bajo y ￼￼diseño de algoritmo￼￼ y un alto-nivel, diseño de ￼￼arquitectura￼￼.

El diseño de software es el proceso de visionado y definición de soluciones software a uno o más conjuntos de problemas. Uno de los componentes principales del diseño de software es el análisis de requisitos del software (ARS, del inglés SRA). Se trata de una parte del proceso de desarrollo de software que enumera especificaciones empleadas en ingeniería de software. Si el software está "automatizado" o centrado en el usuario, el diseño de software puede implicar también el diseño de experiencia de usuario que utiliza un storyboard o guion gráfico para ayudar determinar esas especificaciones. Si el software es completamente automatizado (es decir, sin usuario o interfaz de usuario), un diseño de software puede ser tan sencillo como un diagrama de flujo o un texto describiendo una secuencia planeada de acontecimientos. También hay métodos semiestándares como el Lenguaje Unificado de Modelado (UML) y conceptos fundamentales de modelado. En cualquier caso, normalmente alguna documentación del plan resulta como producto del diseño. Además, un diseño de software puede ser independiente de la plataforma o específico de la plataforma, dependiendo de la disponibilidad de la tecnología utilizada para el diseño.

La diferencia principal entre análisis y el diseño de software es que la producción de un análisis de software se compone de problemas más pequeños para solucionar. Además, el análisis no tendría que ser diseñado de manera muy distinta por miembros de equipo diferente. En contraste, el diseño se enfoca a capacidades y, por tanto, múltiples diseños existen y existirán para el mismo problema. Según el entorno, el diseño también varía en función de si se está creando a partir de frameworks fiables o implementando con patrones de diseño adecuados. Ejemplos de diseño incluyen sistemas de operaciones, páginas web, dispositivos móviles o incluso el nuevo paradigma de computación en la nube.

El diseño de software es un proceso y un modelo. El proceso de diseño es una secuencia de pasos que habilita al diseñador para describir todos los aspectos del software a construir. La habilidad creativa, la experiencia, el sentido de qué hace a un "buen" software y el compromiso con la calidad son ejemplos de factores críticos para el éxito de un diseño competente. Es importante tener en cuenta aun así que el proceso de diseño no es siempre un procedimiento sencillo; el modelo de diseño puede ser comparado con los planos de una casa para un arquitecto. Se empieza representando la totalidad de la cosa que se va a construir (p. ej., un renderizado tridimensional de la casa); la cosa se va refinando lentamente para sevir como guía a la hora de construir cada detalle (p. ej., la parte de fontanería). Del mismo modo, el modelo de diseño que se crea para el software proporciona una variedad de visiones distintas del software. Los principios básicos de diseño ayudan al ingeniero de software a navegar por el proceso de diseño. Davis sugiere un conjunto de principios de diseño de software que han sido adaptados y extendidos en la siguiente lista:


Los conceptos de diseño proporcionan al diseñador de software una base sobre la que se pueden aplicar métodos más sofisticados. El conjunto de conceptos fundamentales del diseño ha evolucionado. Son los siguientes:


En su modelo de objeto, Grady Booch menciona Abstracción, Encapsulación, Modularización y Jerarquía como principios fundamentales del diseño de software. El acrónimo PHAME (del inglés: Principles of Hierarchy, Abstraction, Modularisation, and Encapsulation) se utiliza a veces para referirse a estos cuatro principios fundamentales.

Hay muchos aspectos a considerar en el diseño de una pieza de software. La importancia de cada consideración tendría que reflejar los objetivos y expectativas para los que el software está siendo creado. Algunos de estos aspectos son:


Un lenguaje de modelado es cualquier lenguaje artificial que puede usarse para expresar información, conocimiento o sistemas en una estructura que está definida por un conjunto consistente de reglas. Estas reglas se utilizan en la interpretación de los componentes dentro de la estructura. Un lenguaje de modelado puede ser gráfico o textual. Ejemplos de lenguas de modelado gráfico para diseño de software son:


Un diseñador de software o arquitecto puede identificar un problema de diseño que ha sido visitado y quizás incluso solucionado por otros anteriormente. La plantilla o patrón que describe una solución a un problema común se conoce como patrón de diseño. La reutilización de tales patrones puede ayudar a agilizar el proceso de desarrollo del software.

La dificultad de utilizar el término "diseño" en la relación a software es que en algunos sentidos, el código fuente de un programa "es" el diseño para el programa que produce. Hasta el punto en que esto es cierto, el "diseño de software" refiere al diseño del diseño. Edsger W. Dijkstra se refirió a este "layering" de niveles semánticos como la "novedad radical" de la programación, y Donald Knuth utilizó su experiencia escribiendo TeX para describir la inutilidad de intentar diseñar un programa antes de implementarlo:

La documentación de diseño de software puede ser revisada o presentada para permitir restricciones, especificaciones e incluso para ajustar requisitos antes de programar. La redefinición puede ocurrir después de revisar una simulación programada o prototipo. Es posible diseñar software en el proceso de programar, sin un plan o análisis de requisitos, pero para proyectos complejos esto no sería factible. Un diseño por separado con anterioridad a programar permite a los  diseñadores multidisciplinares y expertos colaborar con programadores altamente especializados en software útil y técnicamente seguro.



</doc>
<doc id="6822" url="https://es.wikipedia.org/wiki?curid=6822" title="Big Bang">
Big Bang

En cosmología, se entiende por Big Bang, también llamada La Gran Explosión,el principio del universo, es decir, el punto inicial en el que se formó la materia, el espacio y el tiempo. De acuerdo con el modelo cosmológico estándar, el "Big Bang" tuvo lugar hace unos 13800 millones de años. Las teorías sobre el "Big Bang" no describen, en realidad, este hecho en sí, sino el universo temprano, en su evolución temporal después del "Big Bang".

El término "Big Bang" no se refiere a una explosión en un espacio ya existente, sino que designa la creación conjunta de materia, espacio y tiempo, a partir de lo que se conoce como una singularidad, es decir, un punto al que matemáticamente nos podemos acercar más y más, pero sin llegar a él. Para entenderlo, uno debe imaginarse el desarrollo del universo en expansión en sentido temporal inverso, retrocediendo hacia el pasado. El universo se va haciendo cada vez más pequeño, pero la cantidad de materia es la misma, de manera que la densidad va aumentando, hasta llegar al punto en el que la densidad de materia y energía se hace infinita y obviamente, superior a la densidad de Planck. Esto significa que las ecuaciones fallan y el proceso no se puede explicar. En este estado, la teoría de la relatividad general carece de validez; para explicar la situación del universo en ese momento habría que recurrir a una teoría, aún desconocida, de gravedad cuántica. De ahí que la física actual no conozca ninguna teoría generalmente aceptada capaz de explicar el universo en sus inicios ni el propio "Big Bang". Transcurrido aproximadamente un microsegundo después del "Big Bang", el universo ya se había expandido y enfriado lo suficiente como para que su desarrollo posterior estuviera determinado por procesos que podemos observar en la física de partículas.

Las teorías del "Big Bang" se ocupan de la evolución del universo en un rango temporal que abarca desde un tiempo de Planck (aprox. 10 segundos) después del "Big Bang" hasta entre 300000 y 400000 años más tarde, cuando ya se empezaban a formar átomos estables y el universo se hizo transparente. Lo que viene después ya no forma parte del "Big Bang".

La teoría del "Big Bang" es el modelo cosmológico predominante para los períodos conocidos más antiguos del universo y su posterior evolución a gran escala. Afirma que el universo estaba en un estado de muy alta densidad y temperatura y luego se expandió. Si las leyes conocidas de la física se extrapolan más allá del punto donde son válidas, encontramos una singularidad. Mediciones modernas datan este momento hace aproximadamente 13 800 millones de años, que sería por tanto la edad del universo. Después de la expansión inicial, el universo se enfrió lo suficiente para permitir la formación de las partículas subatómicas y más tarde simples átomos. Nubes gigantes de estos elementos primordiales se unieron más tarde debido a la gravedad, para formar estrellas y galaxias.
A mediados del siglo XX, tres astrofísicos británicos, Stephen Hawking, George F. R. Ellis y Roger Penrose, prestaron atención a la teoría de la relatividad y sus implicaciones respecto a nuestras nociones del tiempo. En 1968 y 1979 publicaron artículos en que extendieron la teoría de la relatividad general de Einstein para incluir las mediciones del tiempo y el espacio. De acuerdo con sus cálculos, el tiempo y el espacio tuvieron un inicio finito que corresponde al origen de la materia y la energía.

Desde que Georges Lemaître observó por primera vez, en 1927, que un universo en permanente expansión debería remontarse en el tiempo hasta un único punto de origen, los científicos se han basado en su idea de la expansión cósmica. Si bien la comunidad científica una vez estuvo dividida en partidarios de dos teorías diferentes sobre el universo en expansión, la del "Big Bang" y la teoría del estado estacionario, la acumulación de evidencia observacional proporciona un fuerte apoyo para la primera.

En 1929, a partir del análisis de corrimiento al rojo de las galaxias, Edwin Hubble concluyó que las galaxias se estaban distanciando, lo que es una prueba observacional importante consistente con la hipótesis de un universo en expansión. En 1964 se descubrió la radiación de fondo cósmico de microondas, lo que es también una prueba crucial en favor del modelo del "Big Bang", ya que esta teoría predijo la existencia de la radiación de fondo en todo el universo antes de ser descubierta. Más recientemente, las mediciones del corrimiento al rojo de las supernovas indican que la expansión del universo se está acelerando, aceleración atribuida a la energía oscura. Las leyes físicas conocidas de la naturaleza pueden utilizarse para calcular las características en detalle del universo del pasado en un estado inicial de extrema densidad y temperatura.

La expresión ""big bang"" proviene del astrofísico inglés Fred Hoyle, uno de los detractores de esta teoría y, a su vez, uno de los principales defensores de la teoría del estado estacionario, quien dijo, para explicar mejor el fenómeno, que el modelo descrito era simplemente un "big bang" (gran explosión). En el inicio del universo ni hubo explosión ni fue grande, pues en rigor surgió de una «singularidad» infinitamente pequeña, seguida de la expansión del propio espacio. Recientes ingenios espaciales puestos en órbita (COBE) han conseguido observar evidencias de la expansión primigenia.

La idea central del "Big Bang" es que la teoría de la relatividad general puede combinarse con las observaciones de isotropía y homogeneidad a gran escala de la distribución de galaxias y los cambios de posición entre ellas, permitiendo extrapolar las condiciones del universo antes o después en el tiempo.

Una consecuencia de todos los modelos de "Big Bang" es que, en el pasado, el universo tenía una temperatura más alta y mayor densidad y, por tanto, las condiciones del actual son muy diferentes de las condiciones del universo en el pasado. A partir de este modelo, George Gamow en 1948 predecía que habría evidencias de un fenómeno que más tarde sería bautizado como radiación de fondo de microondas.

Para llegar al modelo del "Big Bang", muchos científicos, con diversos estudios, han ido construyendo el camino que lleva a la génesis de esta explicación. Los trabajos de Alexander Friedman, del año 1922, y de Georges Lemaître, de 1927, utilizaron la teoría de la relatividad para demostrar que el universo estaba en movimiento constante. Poco después, en 1929, el astrónomo estadounidense Edwin Hubble (1889-1953) descubrió galaxias más allá de la Vía Láctea que se alejaban de nosotros, como si el universo se expandiera constantemente. En 1948, el físico ucraniano nacionalizado estadounidense George Gamow (1904-1968) planteó que el universo se creó a partir de una gran explosión ("big bang"). Recientemente, ingenios espaciales puestos en órbita (COBE) han conseguido "oír" los vestigios de esta gigantesca explosión primigenia.

De acuerdo con la teoría, un universo homogéneo e isótropo lleno de materia ordinaria podría expandirse indefinidamente o frenar su expansión lentamente, hasta producir una contracción universal. El fin de esa contracción se conoce con un término contrario al "Big Bang": el "Big Crunch" o 'Gran Colapso' o un "Big Rip" o "Gran Desgarro". Si el universo se encuentra en un punto crítico, puede mantenerse estable "ad eternum". Muy recientemente se ha comprobado que actualmente existe una expansión acelerada del universo, hecho no previsto originalmente en la teoría y que ha llevado a la introducción de la hipótesis adicional de la energía oscura, responsable de este fenómeno.

La teoría del "Big Bang" se desarrolló a partir de observaciones y avances teóricos. Por medio de observaciones, en la década de 1910, el astrónomo estadounidense Vesto Slipher y, después de él, Carl Wilhelm Wirtz, de Estrasburgo, determinaron que la mayor parte de las nebulosas espirales se alejan de la Tierra; pero no llegaron a darse cuenta de las implicaciones cosmológicas de esta observación, ni tampoco del hecho de que las supuestas nebulosas eran en realidad galaxias exteriores a nuestra Vía Láctea.

Además, la teoría de Albert Einstein sobre la relatividad general (segunda década del siglo XX) no admite soluciones estáticas (es decir, el universo debe estar en expansión o en contracción), resultado que él mismo consideró equivocado, y trató de corregir agregando la constante cosmológica. El primero en aplicar formalmente la relatividad a la cosmología, sin considerar la constante cosmológica, fue Alexander Friedman, cuyas ecuaciones describen el universo Friedman-Lemaître-Robertson-Walker, que puede expandirse o contraerse.

Entre 1927 y 1930, el sacerdote belga Georges Lemaître obtuvo independientemente las ecuaciones Friedman-Lemaître-Robertson-Walker y propuso, sobre la base de la recesión de las nebulosas espirales, que el universo se inició con la "expansión" de un "átomo primigenio", lo que más tarde se denominó ""Big Bang"".

En 1929, Edwin Hubble realizó observaciones que sirvieron de fundamento para comprobar la teoría de Lemaître. Hubble probó que las nebulosas espirales son galaxias y midió sus distancias observando las estrellas variables cefeidas en galaxias distantes. Descubrió que las galaxias se alejan unas de otras a velocidades (relativas a la Tierra) directamente proporcionales a su distancia. Este hecho se conoce ahora como la ley de Hubble (véase "Edwin Hubble: Marinero de las nebulosas", texto escrito por Edward Christianson).

Según el principio cosmológico el alejamiento de las galaxias sugería que el universo está en expansión. Esta idea originó dos hipótesis opuestas. La primera era la teoría Big Bang de Lemaître, apoyada y desarrollada por George Gamow. La segunda posibilidad era el modelo de la teoría del estado estacionario de Fred Hoyle, según la cual se genera nueva materia mientras las galaxias se alejan entre sí. En este modelo, el universo es básicamente el mismo en un momento dado en el tiempo. Durante muchos años hubo un número de adeptos similar para cada teoría.

Con el paso de los años, las evidencias observacionales apoyaron la idea de que el universo evolucionó a partir de un estado denso y caliente. Desde el descubrimiento de la radiación de fondo de microondas, en 1965, esta ha sido considerada la mejor teoría para explicar la evolución del cosmos. Antes de finales de los años sesenta muchos cosmólogos pensaban que la singularidad infinitamente densa del tiempo inicial en el modelo cosmológico de Friedman era una sobreidealización, y que el universo se contraería antes de empezar a expandirse nuevamente. Esta es la teoría de Richard Tolman de un universo oscilante. En la década de 1960 Stephen Hawking y otros demostraron que esta idea no era factible y que la singularidad es un componente esencial de la gravedad de Einstein. Esto llevó a la mayoría de los cosmólogos a aceptar la teoría del "Big Bang", según la cual el universo que observamos se inició hace un tiempo finito.

Prácticamente todos los trabajos teóricos actuales en cosmología tratan de ampliar o concretar aspectos de la teoría del "Big Bang". Gran parte del trabajo actual en cosmología trata de entender cómo se formaron las galaxias en el contexto del "Big Bang", comprender lo que allí ocurrió y cotejar nuevas observaciones con la teoría fundamental.

A finales de la década de 1990 y principios del siglo XXI, se lograron grandes avances en la cosmología del "Big Bang" como resultado de importantes adelantos en telescopía, en combinación con grandes cantidades de datos satelitales del COBE, el telescopio espacial Hubble y WMAP. Estos datos han permitido a los cosmólogos calcular muchos de los parámetros del "Big Bang" hasta un nuevo nivel de precisión y han conducido al descubrimiento inesperado de que la expansión del universo está en aceleración.

Michio Kaku ha señalado cierta paradoja en la denominación ""big bang"" (gran explosión): en cierto modo no puede haber sido grande ya que se produjo exactamente antes del surgimiento del espacio-tiempo; habría sido el mismo "big bang" lo que habría generado las dimensiones desde una singularidad. Y tampoco es exactamente una explosión en el sentido propio del término, ya que no se propagó fuera de sí mismo.

Basándose en medidas de la expansión del universo utilizando observaciones de las supernovas tipo 1a, en función de la variación de la temperatura en diferentes escalas en la radiación de fondo de microondas y en función de la correlación de las galaxias, la edad del universo es de aproximadamente 13,7 ± 0,2 miles de millones de años. Es notable el hecho de que tres mediciones independientes sean conincidentes, por lo que se considera una fuerte evidencia del llamado modelo de concordancia que describe la naturaleza detallada del universo.

El universo en sus primeros momentos estaba lleno homogénea e isótropamente de una energía muy densa y tenía una temperatura y presión concomitantes. Se expandió y se enfrió, experimentando cambios de fase análogos a la condensación del vapor o a la congelación del agua, pero relacionados con las partículas elementales.

Aproximadamente 10 segundos después del tiempo de Planck un cambio de fase causó que el universo se expandiese de forma exponencial durante un período llamado inflación cósmica. Al terminar la inflación, los componentes materiales del universo quedaron en la forma de un plasma de quarks-gluones, en donde todas las partes que lo formaban estaban en movimiento en forma relativista. Con el crecimiento en tamaño del universo, la temperatura descendió, y debido a un cambio aún desconocido denominado bariogénesis, los quarks y los gluones se combinaron en bariones tales como el protón y el neutrón, produciendo de alguna manera la asimetría observada actualmente entre la materia y la antimateria. Las temperaturas aún más bajas condujeron a nuevos cambios de fase, que rompieron la simetría, así que les dieron su forma actual a las fuerzas fundamentales de la física y a las partículas elementales. Más tarde protones y neutrones se combinaron para formar los núcleos de deuterio y de helio, en un proceso llamado nucleosíntesis primordial. Al enfriarse el universo la materia gradualmente dejó de moverse de forma relativista y su densidad de energía comenzó a dominar gravitacionalmente sobre la radiación. Pasados 300 000 años los electrones y los núcleos se combinaron para formar los átomos (mayoritariamente de hidrógeno). Por eso, la radiación se desacopló de los átomos y continuó por el espacio prácticamente sin obstáculos. Esta es la radiación de fondo de microondas.

Al pasar el tiempo algunas regiones ligeramente más densas de la materia casi uniformemente distribuida crecieron gravitacionalmente, haciéndose más densas, formando nubes, estrellas, galaxias y el resto de las estructuras astronómicas que actualmente se observan. Los detalles de este proceso dependen de la cantidad y tipo de materia que hay en el universo. Los tres tipos posibles se denominan materia oscura fría, materia oscura caliente y materia bariónica. Las mejores medidas disponibles (provenientes del WMAP) muestran que la forma más común de materia en el universo es la materia oscura fría. Los otros dos tipos de materia solo representarían el 20 por ciento de la materia del universo.

El universo actual parece estar dominado por una forma misteriosa de energía conocida como energía oscura. Aproximadamente el 70 por ciento de la densidad de energía del universo actual está en esa forma. Una de las propiedades características de este componente del universo es el hecho de que provoca que la expansión del universo varíe de una relación lineal entre velocidad y distancia, haciendo que el espacio-tiempo se expanda más rápidamente de lo esperado a grandes distancias. La energía oscura toma la forma de una constante cosmológica en las ecuaciones de campo de Einstein de la relatividad general, pero los detalles de esta ecuación de estado y su relación con el modelo estándar de la física de partículas continúan siendo investigados tanto en el ámbito de la física teórica como por medio de observaciones.

Más misterios aparecen cuando se investiga más cerca del principio, cuando las energías de las partículas eran más altas de lo que ahora se puede estudiar mediante experimentos. No hay ningún modelo físico convincente para el primer 10 segundo del universo, antes del cambio de fase que forma parte de la teoría de la gran unificación. En el "primer instante", la teoría gravitacional de Einstein predice una singularidad en donde las densidades son infinitas. Para resolver esta paradoja física, hace falta una teoría de la gravedad cuántica. La comprensión de este período de la historia del universo figura entre los mayores problemas no resueltos de la física.

En su forma actual, la teoría del "Big Bang" depende de dos suposiciones:


Inicialmente estas ideas fueron tomadas como postulados, pero actualmente se las intenta verificar. La universalidad de las leyes de la física ha sido verificada al nivel de las más grandes constantes físicas, llevando su margen de error hasta el orden de 10. La isotropía del universo que define el principio cosmológico ha sido verificada hasta un orden de 10. La teoría del "Big Bang" utiliza el postulado de Weyl para medir sin ambigüedad el tiempo en cualquier momento en el pasado a partir del la época de Planck. Las medidas en este sistema dependen de coordenadas conformales, en las cuales las llamadas distancias codesplazantes y los tiempos conformales permiten no considerar la expansión del universo para las medidas de espacio-tiempo. En ese sistema de coordenadas los objetos que se mueven con el flujo cosmológico mantienen siempre la misma distancia codesplazante y el horizonte o límite del universo se fija por el tiempo codesplazante.

Visto así, el "Big Bang" no es una explosión de materia que se aleja para llenar un universo vacío, es el espacio-tiempo el que se extiende. Y es su expansión la que causa el incremento de la distancia física entre dos puntos fijos en el universo. Cuando los objetos están ligados entre ellos (por ejemplo, por una galaxia), no se alejan con la expansión del espacio-tiempo, debido a que se asume que las leyes de la física que los gobiernan son uniformes e independientes del espacio métrico. Más aún, la expansión del universo en las escalas actuales locales es tan pequeña que cualquier dependencia de las leyes de la física en la expansión no sería medible con las técnicas actuales.

En general se consideran tres las evidencias empíricas que apoyan la teoría cosmológica del "Big Bang". Estas son: la expansión del universo que se expresa en la ley de Hubble y que se puede apreciar en el corrimiento hacia el rojo de las galaxias, las medidas detalladas del fondo cósmico de microondas, y la abundancia de elementos ligeros. Además, la función de correlación de la estructura a gran escala del universo encaja con la teoría del "Big Bang".

De la observación de galaxias y cuásares lejanos se desprende la idea de que estos objetos experimentan un corrimiento hacia el rojo, lo que quiere decir que la luz que emiten se ha desplazado proporcionalmente hacia longitudes de onda más largas. Esto se comprueba tomando el espectro de los objetos y comparando, después, el patrón espectroscópico de las líneas de emisión o absorción correspondientes a átomos de los elementos que interactúan con la radiación. En este análisis se puede apreciar cierto corrimiento hacia el rojo, lo que se explica por una velocidad recesional correspondiente al efecto Doppler en la radiación. Al representar estas velocidades recesionales frente a las distancias respecto a los objetos, se observa que guardan una relación lineal, conocida como ley de Hubble:

donde formula_2 es la velocidad recesional, formula_3 es la distancia al objeto y formula_4 es la constante de Hubble, que el satélite WMAP estimó en 71 ± 4 km/s/Mpc.

Una de las predicciones de la teoría del "Big Bang" es la existencia de la radiación cósmica de fondo, radiación de fondo de microondas o CMB ("Cosmic microwave background"). El universo temprano, debido a su alta temperatura, se habría llenado de luz emitida por sus otros componentes. Mientras el universo se enfriaba debido a la expansión, su temperatura habría caído por debajo de 3000K. Por encima de esta temperatura, los electrones y protones están separados, haciendo el universo opaco a la luz. Por debajo de los 3000K se forman los átomos, permitiendo el paso de la luz a través del gas del universo. Esto es lo que se conoce como disociación de fotones.

La radiación en este momento habría tenido el espectro del cuerpo negro y habría viajado libremente durante el resto de vida del universo, sufriendo un corrimiento hacia el rojo como consecuencia de la expansión de Hubble. Esto hace variar el espectro del cuerpo negro de 3345K a un espectro del cuerpo negro con una temperatura mucho menor. La radiación, vista desde cualquier punto del universo, parecerá provenir de todas las direcciones en el espacio.

En 1965, Arno Penzias y Robert Wilson, mientras desarrollaban una serie de observaciones de diagnóstico con un receptor de microondas propiedad de los Laboratorios Bell, descubrieron la radiación cósmica de fondo. Ello proporcionó una confirmación sustancial de las predicciones generales respecto al CMB —la radiación resultó ser isótropa y constante, con un espectro del cuerpo negro de cerca de 3K— e inclinó la balanza hacia la hipótesis del "Big Bang". Penzias y Wilson recibieron el Premio Nobel por su descubrimiento.

En 1989, la NASA lanzó el COBE (COsmic Background Explorer) y los resultados iniciales, proporcionados en 1990, fueron consistentes con las predicciones generales de la teoría del "Big Bang" acerca de la CMB. El COBE halló una temperatura residual de 2726K, y determinó que el CMB era isótropo en torno a una de cada 10 partes. Durante la década de los 90 se investigó más extensamente la anisotropía en el CMB mediante un gran número de experimentos en tierra y, midiendo la distancia angular media (la distancia en el cielo) de las anisotropías, se vio que el universo era geométricamente plano.

A principios de 2003 se dieron a conocer los resultados de la Sonda Wilkinson de Anisotropías del fondo de Microondas (en inglés "Wilkinson Microwave Anisotropy Probe" o "WMAP"), mejorando los que hasta entonces eran los valores más precisos de algunos parámetros cosmológicos. "(Véase también experimentos sobre el fondo cósmico de microondas)". Este satélite también refutó varios modelos inflacionistas específicos, pero los resultados eran constantes con la teoría de la inflación en general.

Se puede calcular, usando la teoría del "Big Bang", la concentración de helio-4, helio-3, deuterio y litio-7.1 en el universo como proporciones con respecto a la cantidad de hidrógeno normal, H. Todas las abundancias dependen de un solo parámetro: la razón entre fotones y bariones, que por su parte puede calcularse independientemente a partir de la estructura detallada de la radiación cósmica de fondo. Las proporciones predichas (en masa, no volumen) son de cerca de 0,25 para la razón He/H, alrededor de 10 para He/H, y alrededor de 10 para He/H.

Estas abundancias medidas concuerdan, al menos aproximadamente, con las predichas a partir de un valor determinado de la razón de bariones a fotones, y se considera una prueba sólida en favor del "Big Bang", ya que esta teoría es una de las únicas explicaciones para la abundancia relativa de elementos ligeros. Otro modelo que permite deducir la relación actual entre el número de fotones y el número de bariones, en buen acuerdo con los datos experimentales, y solamente en función de las tres constantes universales: la constante de Planck "h", la velocidad de la luz en el vacío "c" y la constante de gravitación "k", es el modelo cosmológico de Ilya Prigogine.

Las observaciones detalladas de la morfología y estructura de las galaxias y cuásares proporcionan una fuerte evidencia del "Big Bang". La combinación de las observaciones con la teoría sugiere que los primeros cuásares y galaxias se formaron alrededor de mil millones de años después del "Big Bang", y desde ese momento se han estado formando estructuras más grandes, como los cúmulos de galaxias y los supercúmulos. Las poblaciones de estrellas han ido envejeciendo y evolucionando, de modo que las galaxias lejanas (que se observan tal y como eran en el principio del universo) son muy diferentes a las galaxias cercanas (que se observan en un estado más reciente). Por otro lado, las galaxias formadas hace relativamente poco son muy diferentes de las galaxias que se formaron a distancias similares pero poco después del "Big Bang". Estas observaciones son argumentos sólidos en contra de la teoría del estado estacionario. Las observaciones de la formación estelar, la distribución de cuásares y galaxias, y las estructuras más grandes concuerdan con las simulaciones obtenidas sobre la formación de la estructura en el universo a partir del "Big Bang", y están ayudando a completar detalles de la teoría.

Después de cierta controversia la edad del universo estimada por la expansión Hubble y la CMB (Radiación cósmica de fondo) concuerda en gran medida (es decir, ligeramente más grande) con las edades de las estrellas más viejas, ambas medidas aplicando la teoría de la evolución estelar de los cúmulos globulares y a través de la fecha radiométrica individual en las estrellas de la segunda Población.

Históricamente han surgido varios problemas dentro de la teoría del "Big Bang". Algunos de ellos solo tienen interés histórico y han sido evitados, ya sea por medio de modificaciones a la teoría o como resultado de observaciones más precisas. Otros aspectos, como el problema de la penumbra en cúspide y el problema de la galaxia enana de materia oscura fría, no se consideran graves, dado que pueden resolverse a través de un perfeccionamiento de la teoría.

Existe un pequeño número de proponentes de cosmologías no estándar que piensan que no hubo un "Big Bang". Afirman que las soluciones a los problemas conocidos del "Big Bang" contienen modificaciones "ad hoc" y agregados a la teoría. Las partes más atacadas de la teoría incluyen lo concerniente a la materia oscura, la energía oscura y la inflación cósmica. Cada una de estas características del universo ha sido sugerida mediante observaciones de la radiación de fondo de microondas, la estructura a gran escala del cosmos y las supernovas de tipo IA, pero se encuentran en la frontera de la física moderna (ver problemas no resueltos de la física). Si bien los efectos gravitacionales de materia y energía oscuras son bien conocidos de forma observacional y teórica, todavía no han sido incorporados al modelo estándar de la física de partículas de forma aceptable. Estos aspectos de la cosmología estándar siguen sin tener una explicación adecuada, pero la mayoría de los astrónomos y los físicos aceptan que la concordancia entre la teoría del "Big Bang" y la evidencia observacional es tan cercana que permite establecer con cierta seguridad casi todos los aspectos básicos de la teoría.

Los siguientes son algunos de los problemas y enigmas comunes del "Big Bang".

El problema del segundo principio de la termodinámica resulta del hecho de que de este principio se deduce que la entropía, el desorden, aumenta si se deja al sistema (el universo) seguir su propio rumbo. Una de las consecuencias de la entropía es el aumento en la proporción entre radiación y materia; por lo tanto, el universo debería terminar en una muerte térmica, una vez que la mayor parte de la materia se convierta en fotones y estos se diluyan en la inmensidad del universo.

Otro problema señalado por Roger Penrose es que la entropía parece haber sido anormalmente pequeña en el estado inicial del universo. Penrose evalúa la probabilidad de un estado inicial en aproximadamente
formula_5. De acuerdo con Penrose y otros, la teoría cosmológica ordinaria no explica por qué la entropía inicial del universo es tan anormalmente baja y propone la hipótesis de curvatura de Weyl en conexión con ella. De acuerdo con esa hipótesis, una teoría cuántica de la gravedad debería dar una explicación tanto del porqué el universo se inició en un estado de curvatura de Weyl nula y de una entropía tan baja, aunque todavía no se ha logrado una teoría de la gravedad cuántica satisfactoria.

Por otro lado, en la teoría estándar, el estado entrópico anormalmente bajo se considera que es producto de una "gran casualidad" justificada por el principio antrópico, postura que Penrose y otros consideran filosóficamente insatisfactoria.

El problema del horizonte, también llamado problema de la causalidad, resulta del hecho de que la información no puede viajar más rápido que la luz, de manera que dos regiones en el espacio separadas por una distancia mayor que la que recorrería la luz en la edad del universo no pueden estar causalmente conectadas. En este sentido, la isotropía observada de la radiación de fondo de microondas (CMB) resulta problemática, debido a que el tamaño del horizonte de partículas en ese tiempo corresponde a un tamaño de cerca de dos grados en el cielo. Si el universo hubiera tenido la misma historia de expansión desde la época de Planck, no habría mecanismo que pudiera hacer que estas regiones tuvieran la misma temperatura.

Esta aparente inconsistencia se resuelve con la teoría inflacionista, según la cual un campo de energía escalar isótropo domina el universo al transcurrir un tiempo de Planck después de la época de Planck. Durante la inflación el universo sufre una expansión exponencial y regiones que se afectan mutuamente se expanden más allá de sus respectivos horizontes. El principio de incertidumbre de Heisenberg predice que durante la fase inflacionista habrá fluctuaciones primordiales, que se simplificarán hasta la escala cósmica. Estas fluctuaciones sirven de semilla para toda la estructura actual del universo. Al pasar la inflación el universo se expande siguiendo la ley de Hubble y las regiones que estaban demasiado lejos para afectarse mutuamente vuelven al horizonte. Esto explica la isotropía observada de la CMB. La inflación predice que las fluctuaciones primordiales son casi invariantes según la escala y que tienen una distribución normal o gaussiana, lo cual ha sido confirmado con precisión por medidas de la CMB.

En 2003 apareció otra teoría para resolver este problema, la velocidad variante de la luz de João Magueijo, que aunque a la larga contradice la relatividad de Einstein usa su ecuación, incluyendo la constante cosmológica, para resolver el problema de una forma muy eficaz que también ayuda a solucionar el problema de la planitud.

El problema de la planitud ("flatness problem" en inglés) es un problema observacional que resulta de las consecuencias que la métrica de Friedmann-Lemaître-Robertson-Walker tienen para con la geometría del universo (véase Forma del universo). En general se considera que existen tres tipos de geometrías posibles para el universo según su curvatura espacial: geometría elíptica (curvatura positiva), geometría hiperbólica (curvatura negativa) y geometría euclidiana o plana (curvatura nula).

Dicha geometría viene determinada por la cantidad total de densidad de energía del universo (medida mediante el tensor de tensión-energía). Siendo Ω el cociente entre la densidad de energía ρ medida observacionalmente y la densidad crítica ρ, se tiene que para cada geometría las relaciones entre ambos parámetros han de ser :
La densidad en el presente es muy cercana a la densidad crítica, o lo que es lo mismo, el universo hoy es espacialmente plano, dentro de una buena aproximación. Sin embargo, las diferencias con respecto a la densidad crítica crecen con el tiempo, luego en el pasado la densidad tuvo que ser aún más cercana a esta. Se ha medido que en los primeros momentos del universo la densidad era diferente a la crítica tan solo en una parte en 10 (una milbillonésima parte). Cualquier desviación mayor habría conducido a una muerte térmica o un "big crunch" y el universo no sería como ahora.

Una solución a este problema viene de nuevo de la teoría inflacionaria. Durante el periodo inflacionario el espacio-tiempo se expandió tan rápido que provocó una especie de "estiramiento" del universo acabando con cualquier curvatura residual que pudiese haber. Así la inflación pudo hacer plano al universo.

A mediados de la década de 1990 las observaciones realizadas de los cúmulos globulares parecían no concordar con la teoría del "Big Bang". Las simulaciones realizadas por ordenador, de acuerdo con las observaciones de las poblaciones estelares de cúmulos de galaxias, sugirieron una edad de cerca de 15 000 millones de años, lo que entraba en conflicto con la edad del universo, estimada en 13 700 millones de años. El problema quedó resuelto a finales de esa década, cuando las nuevas simulaciones realizadas, que incluían los efectos de la pérdida de masa debida a los vientos estelares, indicaron que los cúmulos globulares eran mucho más jóvenes. Quedan aún en el aire algunas preguntas en cuanto a con qué exactitud se miden las edades de los cúmulos, pero está claro que estos son algunos de los objetos más antiguos del universo.

La objeción de los monopolos magnéticos fue propuesta a finales de la década de 1970. Las teorías de la gran unificación predicen defectos topológicos en el espacio que se manifestarían como monopolos magnéticos encontrándose en el espacio con una densidad mucho mayor a la observada. De hecho, hasta ahora no se ha dado con ningún monopolo. Este problema también queda resuelto mediante la inflación cósmica, dado que esta elimina todos los puntos defectuosos del universo observable de la misma forma que conduce la geometría hacia su forma plana. Es posible que aun así pueda haber monopolos pero se ha calculado que apenas si habría uno por cada universo visible, una cantidad ínfima y no observable en todo caso.

En las diversas observaciones realizadas durante las décadas de 1970 y 80 (sobre todo las de las curvas de rotación de las galaxias) se mostró que no había suficiente materia visible en el universo para explicar la intensidad aparente de las fuerzas gravitacionales que se dan en y entre las galaxias. Esto condujo a la idea de que hasta un 90% de la materia en el universo no es materia común o bariónica sino materia oscura. Además, la asunción de que el universo estuviera compuesto en su mayor parte por materia común llevó a predicciones que eran fuertemente inconsistentes con las observaciones. En particular, el universo es mucho menos "inhomogéneo" y contiene mucho menos deuterio de lo que se puede considerar sin la presencia de materia oscura. Mientras que la existencia de la materia oscura era inicialmente polémica, ahora es una parte aceptada de la cosmología estándar, debido a las observaciones de las anisotropías en el CMB, dispersión de velocidades de los cúmulos de galaxias, y en las estructuras a gran escala, estudios de las lentes gravitacionales y medidas por medio de rayos x de los cúmulos de galaxias. La materia oscura se ha detectado únicamente a través de su huella gravitacional pues no se ha observado en el laboratorio ninguna partícula que se le pueda corresponder. Sin embargo hay muchos candidatos a materia oscura en física de partículas (como, por ejemplo, las partículas pesadas y neutras de interacción débil o WIMP ("weak interactive massive particles"), y se están llevando a cabo diversos proyectos para detectarla.

En la década de 1990, medidas detalladas de la densidad de masa del universo revelaron que esta sumaba en torno al 30% de la densidad crítica. Puesto que el universo es plano, como indican las medidas del fondo cósmico de microondas, quedaba un 70% de densidad de energía sin contar. Este misterio aparece ahora conectado con otro: las mediciones independientes de las supernovas de tipo Ia han revelado que la expansión del universo experimenta una aceleración de tipo no lineal, en vez de seguir estrictamente la ley de Hubble. Para explicar esta aceleración, la relatividad general necesita que gran parte del universo consista en un componente energético con gran presión negativa. Se cree que esta energía oscura constituye ese 70% restante. Su naturaleza sigue siendo uno de los grandes misterios del "Big Bang". Los candidatos posibles incluyen una constante cosmológica escalar y una quintaesencia. Actualmente se están realizando observaciones que podrían ayudar a aclarar este punto.

Antes de las observaciones de la energía oscura, los cosmólogos consideraron dos posibles escenarios para el futuro del universo. Si la densidad de masa del universo se encuentra sobre la densidad crítica, entonces el universo alcanzaría un tamaño máximo y luego comenzaría a colapsarse. Este se haría más denso y más caliente nuevamente, terminando en un estado similar al estado en el cual empezó en un proceso llamado "Big Crunch". Por otro lado, si la densidad en el universo es igual o menor a la densidad crítica, la expansión disminuiría su velocidad, pero nunca se detendría. La formación de estrellas cesaría mientras el universo en crecimiento se haría menos denso cada vez. El promedio de la temperatura del universo podría acercarse asintóticamente al cero absoluto (0 K o –273,15 °C). Los agujeros negros se evaporarían por efecto de la radiación de Hawking. La entropía del universo se incrementaría hasta el punto en que ninguna forma de energía podría ser extraída de él, un escenario conocido como muerte térmica. Más aún, si existe la descomposición del protón, proceso por el cual un protón decaería a partículas menos masivas emitiendo radiación en el proceso, entonces todo el hidrógeno, la forma predominante de materia bariónica en el universo actual, desaparecería a muy largo plazo, dejando solo radiación.

Las observaciones modernas de la expansión acelerada implican que cada vez una mayor parte del universo visible en la actualidad quedará más allá de nuestro horizonte de sucesos y fuera de contacto. Se desconoce cuál sería el resultado de este evento. El modelo Lambda-CDM del universo contiene energía oscura en la forma de una constante cosmológica (de alguna manera similar a la que había incluido Einstein en su primera versión de las ecuaciones de campo). Esta teoría sugiere que solo los sistemas mantenidos gravitacionalmente, como las galaxias, se mantendrían juntos, y ellos también estarían sujetos a la muerte térmica a medida que el universo se enfriase y expandiese. Otras explicaciones de la energía oscura-llamadas teorías de la energía fantasma sugieren que los cúmulos de galaxias y finalmente las galaxias mismas se desgarrarán por la eterna expansión del universo, en el llamado "Big Rip".

A pesar de que el modelo del "Big Bang" se encuentra bien establecido en la cosmología, es probable que se redefina en el futuro. Se tiene muy poco conocimiento sobre el universo más temprano, durante el cual se postula que ocurrió la inflación. También es posible que en esta teoría existan porciones del universo mucho más allá de lo que es observable en principio. En la teoría de la inflación, esto es un requisito: La expansión exponencial ha empujado grandes regiones del espacio más allá de nuestro horizonte observable. Puede ser posible deducir qué ocurrió cuando tengamos un mejor entendimiento de la física a altas energías. Las especulaciones hechas al respecto, por lo general involucran teorías de gravedad cuántica.

Algunas propuestas son:

Existe un gran número de interpretaciones sobre la teoría del "Big Bang" que son completamente especulativas o extra-científicas desde un punto de filosófico, pero no son hipótesis verificables. Algunas de estas ideas tratan de explicar la causa misma del "Big Bang" (primera causa), y fueron criticadas por algunos filósofos naturalistas por ser solamente nuevas versiones de la creación. Algunas personas creen que la teoría del "Big Bang" brinda soporte a antiguos enfoques de la creación, como por ejemplo el que se encuentra en el "Génesis" (ver creacionismo), mientras otros creen que todas las teorías del "Big Bang" son inconsistentes con las mismas.

El "Big Bang" como teoría científica no está asociado a ninguna religión. Mientras algunas interpretaciones fundamentalistas de ciertas religiones entran en conflicto con la historia del universo postulada por la teoría del "Big Bang", la mayoría de las interpretaciones son liberales. A continuación sigue una lista de varias interpretaciones religiosas de la teoría del "Big Bang" que son hasta cierto punto compatibles con la propia descripción científica del mismo:











La mayoría de los artículos científicos sobre cosmología están disponibles como preimpresos en . Generalmente son muy técnicos, pero algunas veces tienen una introducción clara en inglés. Los archivos más relevantes, que cubren experimentos y teoría están el archivo de astrofísica, donde se ponen a disposición artículos estrechamente basados en observaciones, y el archivo de relatividad general y cosmología cuántica, el cual cubre terreno más especulativo. Los artículos de interés para los cosmólogos también aparecen con frecuencia en el archivo sobre Fenómenos de alta energía y sobre teoría de alta energía.



</doc>
<doc id="6824" url="https://es.wikipedia.org/wiki?curid=6824" title="Bolaños de Calatrava">
Bolaños de Calatrava

Bolaños de Calatrava es un municipio español de la provincia de Ciudad Real, en la comunidad autónoma de Castilla-La Mancha, situado a 27 km de la capital provincial, Valdepeñas y Manzanares, y a 4 km al este de Almagro con lo cual ambos municipios son las localidades vecinas más próximas del Campo de Calatrava. También limita al noroeste con Torralba de Calatrava (a 14 km), con Daimiel (al norte) a 17 km, con Manzanares (al oeste) a 27 km y al sur con Moral de Calatrava a 12 km.

La documentación más antigua alude al emplazamiento de antiguas culturas en su término. El evidente origen romano de Bolaños queda reflejado en las monedas, ídolos y sepulturas que, según las relaciones topográficas de Felipe II, se hallaron al sur de la población. De la misma época serían las murallas del mediodía y poniente de su castillo-fortaleza. 

Durante la dominación musulmana fue utilizado este fuerte y población romana, quedando marcada la huella árabe en las construcciones norte y este del castillo, dentro de las cuales se apreciaban baños y hermosos arabescos en algunas de sus dependencias. Numerosas plantas de casas musulmanas fueron reconocidas al norte de la población por el redactor de las citadas relaciones. 

Tras la toma de la ciudad de Calatrava, en 1147, Alfonso VII aprovecha la debilidad de los Almorávides y ocupa en pocos años el Campo de Calatrava. Estas tierras se adjudican para su defensa a la Orden militar del Temple, pero esta, aun siendo fuerte y poderosa, no fue capaz de hacer frente al empuje almohade, por lo que renuncian a su defensa tras la muerte de Alfonso VII. Su hijo, Sancho III, ofreció la ciudad de Calatrava a quien se hiciera cargo de su defensa, y se la pidieron el abad Raimundo de Fitero y Fray Diego Velázquez –frailes cistercienses-, que les fue donada en 1158, momento en que se crea la Orden de Calatrava y año en que accede al trono de Castilla Alfonso VIII.

A partir del asentamiento de los caballeros de la Orden de Calatrava se conquista el territorio del Campo de su mismo nombre, rechazando a los árabes hacia el Sur. Pero el avance almohade se hace inevitable y en 1195 se produce la derrota cristiana en Alarcos y se pierde Calatrava y todo su Campo, por lo que pasaría nuevamente a manos musulmanas. Esta situación duró poco tiempo, ya que en julio de 1212, con la Batalla de Las Navas de Tolosa, los cristianos recuperan definitivamente todo el territorio.

Alfonso VIII, debido a la debilidad de la corona y a lo limitado de sus medios, encomienda la repoblación y organización de los nuevos territorios conquistados a las órdenes militares. A la Orden de Calatrava se le cedió la ciudad donde tenía instituida su casa matriz, Calatrava, además de numerosas plazas de su campo circundante, que repoblaría bajo las directrices dadas por Alfonso VIII. Este rey reservaría otras villas recién conquistadas para la corona, como fue el caso de Bolaños, que tras su ocupación cristiana el monarca la regalaría a su hija Berenguela por el triunfo de Las Navas. Berenguela otorgó la repoblación de la villa a un caballero de su hueste señorial participante en la Batalla y procedente de Galicia, nombrándolo alcaide. Este caballero era del linaje de los Bolaños y Ribadeneyra, el cual daría como nombre a la villa su propio apellido y como escudo de armas el escudo de su familia –Cordero y Bollo-. 
Fue cámara o residencia de los Maestres de Calatrava en el siglo XV. La orden celebró importantes Capítulos Generales en la antigua iglesia de Santa María, probablemente Santa María de la Alta Virtud, venida a ruinas, probablemente, por el terremoto de Lisboa, cuya cofradía consta en los últimos siglos medievales. 
De época también medieval -siglo XIII- dataría el primitivo Santuario de la Virgen del Monte (Bolaños de Calatrava), de sencilla construcción románica, situada en un bellísimo paraje cercano a la villa, en la cual y sin interrupción han venido celebrándose animadas romerías desde la Edad Media.

Durante los siglos medievales Bolaños debió conocer la pacífica convivencia de mudéjares y cristianos que, más tarde, en los siglos XVI y XVII continuaría cuando aquellos fueron bautizados y pasaron a formar una notable comunidad morisca, dejando cierta influencia en la agricultura, arquitectura y tradiciones de Bolaños. 

En el siglo XVI comenzó la construcción de la actual iglesia de San Felipe y Santiago, renacentista, constando también en esa época una ermita de los santos Cosme y Damián, así como un hospital de peregrinos. También existió una Audiencia, cuyo emplazamiento, así como el de los anteriores edificios estarían próximos al castillo. Tanto en la Audiencia como en la denominada Iglesia Vieja, se hallaron pintadas las armas que forman el escudo de Bolaños: un cordero, una espada y un bollo. 

En 1544 se confirma la creación de la Encomienda de Bolaños. Un camino real de cierta importancia pasaba por el término de Bolaños, desde la venta de Borondo, al santuario de la Virgen de las Nieves, que servía de comunicación con Portugal y Extremadura. 

Tras la crisis demográfica del siglo XVI, Bolaños se recupera en las centurias siguientes, constando, según el Catastro del Marqués de la Ensenada, como en el siglo XVIII, sus habitantes pasaban de los 1.500 y residiendo principalmente en las calles adyacentes al Castillo y plaza de España actual, sobre todo calle Santísimo, Real de Pozo Agrio, actual calle del Cristo, calle Almagro, etc. De los siglos XVII y XVIII quedan unas casas en la calle del Cristo que son un claro exponente de la arquitectura popular manchega. También en esta misma calle, la denominada Casa de Coca muestra un bello escudo en mármol sobre la portada. 

A comienzos del siglo actual se construyó, junto a la ermita "románica", la nueva de Nuestra Señora del Monte, de amplia nave. Este santuario mariano constituye, hoy día, una de las señas de identidad del pueblo bolañego. En la actualidad, Bolaños, es un próspero pueblo cuyo rico pasado histórico trasciende este breve resumen histórico, pero queda manifiesto en el bello casco antiguo con el castillo y sus alrededores.

Localidad situada prácticamente en el centro de la provincia de Ciudad Real, en pleno corazón del campo de Calatrava, encontrándose al norte de la Sierra de Moral y al suroeste de Sierra Pelada. El arroyo Pellejero surca el núcleo urbano sin canalizar entre calles y casas. Más alejados de la población encontramos el "arroyo Cuetos" y el "arroyo Seco" cruzando por el Santuario de la Virgen del Monte (Bolaños de Calatrava) y posteriormente por el Santuario de las Nieves, para desembocar luego en el "Pellejero" en los campos de "La Colonia". Éste, a su vez, desemboca unos kilómetros más adelante en el río Guadiana.

El clima de Bolaños es bastante caluroso ya que tiene todas las características del clima castellano meridional de tipología mediterráneo continental, unificado por el relieve con grandes oscilaciones térmicas diurnonocturnas y anuales. Es frío en invierno y caluroso en verano, de precipitaciones escasas, y lo combaten vientos muy fuertes. Todo ello conduce a una acusada aridez del territorio.

Bolaños de Calatrava ha experimentado una continua evolución poblacional desde la expulsión de los moriscos –siglo XVII-, convirtiéndose en un caso singular en el contexto de la provincia, ya que es el único pueblo que no ha visto descender su población en los siglos posteriores y hasta la actualidad.
En 2015, según las cifras oficiales del INE, tenía una población de 11.994 habitantes (6.103 hombres y 5.891 mujeres).

Generalmente, las tablas demográficas presentan mayor número de mujeres que de hombres. En este caso, Bolaños es una excepción debido a que la inmigración procedente de Hispanoamérica, el Magreb y los países del Este de Europa está, mayoritariamente, integrada por varones.

Evolución de la población de Bolaños de Calatrava a lo largo del siglo XX:

Evolución demográfica

La extensión del casco urbano de Bolaños de Calatrava ha propiciado la existencia de barrios, así como zonas industriales, los cuales son:

En esta zona se reúne la mayor concentración empresarial de Bolaños, a un kilómetro de la ciudad en dirección Torralba de Calatrava. En ella se ubican la mayoría de las empresas, talleres y fábricas.

La gran recta que une los dos núcleos urbanos más cercanos del campo de Calatrava tiene a ambos lados gran actividad empresarial ubicándose en esta vía factorías y empresas del sector servicios, como el centro educativo EFA "La Serna".

Conocido popularmente como "Las Cuevas" por la ubicación de las antiguas cuevas del barrio alto bolañego, que tras la construcción de la Iglesia "Santa María madre de la Iglesia" en el siglo XX, pasó a denominarse barrio de Santa María. La iglesia de Santa María, construida en 1970, tiene influencias arquitectónicas de varios estilos como arcos apuntados del neogótico, el aspecto de fortaleza de la arquitectura castrense y los rasgos minimalistas y funcionales del vanguardismo. Actualmente el barrio cuenta con más de 4.000 vecinos y celebra sus fiestas el 14 y 15 de agosto festividad de la Asunción de la Virgen María.

El barrio de las veredillas supuso el ensanche de la villa de Bolaños más allá de la avenida de la vereda entre las avenida Cardenal Cisneros y carretera de Moral, el barrio cuenta con el colegio de educación primaria "Arzobispo Calzado" , diversos bares y supermercados. En la parte periférica sureste del barrio se encuentra el tanatorio de Bolaños y el cementerio municipal.

Es un barrio obrero de reciente creación (Década de los 80) al sur de la localidad junto al colegio público "Virgen del Monte". Por este barrio accede a la localidad la ruta del Quijote. Cuenta también con el segundo centro de atención a la Infancia de Bolaños y el Centro Cívico. El barrio albergara el nuevo cementerio municipal de Bolaños tras la reciente compra de una parcela en el entorno del camino aulagueros y la ruta del Quijote.

También de muy reciente creación el barrio Veguizos surge al lado izquierdo de la avenida de Daimiel. Convirtiéndose seguramente en el futuro, en uno de los grandes barrios de Bolaños, tras la construcción del nuevo complejo sanitario bolañego.

No es propiamente un barrio; sus límites se confunden con los del barrio de Santa María ya que podría entenderse como el crecimiento de este hacia el cerro del Molino, donde actualmente se encuentra el colegio público "Molino de viento".

El barrio Virgen del Monte se encuentra al Sur-Este de la localidad entre la avenida de su mismo nombre y la avenida de la Vereda.

Es el núcleo más antiguo de la ciudad donde surgieron las primeras viviendas, en torno a la calle del Cristo, Santísimo, Las Nieves, Almagro, Cruz, Príncipe, Libertad y Cervantes; y las principales plazas como: España, Doña Berenguela o el Parque Municipal. El triángulo formado por estos tres espacios públicos engloba los principales servicios de la ciudad, sobre todo el comercio y el ocio. En esta parte de la ciudad también se encuentran los edificios históricos como: la iglesia parroquial de San Felipe y Santiago, el Círculo Agrícola Industrial, las casas de la calle del Cristo, San Cosme y San Damián o el Castillo.

La economía del pueblo ha sido de tradición inminentemente agrícola, primando la agricultura de secano a la de regadío. No obstante, ha sufrido un retroceso a favor de sus transformados, los productos de la industria alimentaria. A principios del siglo XXI, Bolaños destaca es este campo con almacenes de frutas y hortalizas y fábricas de frutos secos y patatas fritas; pero cabe mención especial la elaboración de conservas de la berenjena del Campo de Calatrava, que goza de la indicación geográfica protegida de Berenjena de Almagro y cuya sede se encuentra en el Centro Integral de Gestión Agroalimentaria (CIGA), junto con la del resto de marcas de calidad calatravas (vino y aceite).

En cuanto a la ganadería, Bolaños de Calatrava es un centro destacado de ganado ovino con abundante producción de leche y carne. También existe una pequeña industria avícola surgida a partir de los años 50 y sobre todo 60.

El sector secundario viene representado básicamente por la ya mencionada industria alimentaria y la industria del mueble.

A nivel comercial, el pueblo es exportador de cebollas y otros productos alimenticios (hotofrutícolas básicamente), además de disponer de un gran parque de camiones para la logística situado en el polígono industrial "El Salobral". El sector de servicios es activo al disponer de diez entidades financieras, corredurías de seguros, inmobiliarias, talleres de reparación y el comercio minorista textil, con una treintena de comerciantes.

Bolaños de Calatrava ha contado, desde la Transición, con pocos alcaldes. Primero fue Tomás Sobrino Tosina, de la UCD, que estuvo unos meses en el cargo, entre 1979 y 1980. Le sustituyó Daniel Almansa, primero de 'UCD' (Unión de Centro Democrático), después de 'AP' (Alianza Popular) y luego del 'PP' (Partido Popular), y que fue votado legislatura tras legislatura hasta 2007 (1980-2007). En las Elecciones Municipales celebradas en 2007 se produjo un cambio en el municipio, al tener, por primera vez, un alcalde del 'PSOE' (Partido Socialista Obrero Español), Eduardo del Valle Calzado. En las elecciones municipales de 2011 de nuevo hubo un alcalde del Partido Popular, Miguel Ángel Valverde Menchero, renovando la alcaldía el 24 de mayo de 2015 y posteriormente en 2019.


El castillo es una fortaleza árabe construida entre los siglos X y XI en piedra basáltica, caliza, yeso y ladrillo. Sus medidas son 43,70 m de ancho, 40,85 m de largo y 7,40 m de alto. El recinto está completamente almenado y en su interior existen restos árabes: unos baños, aljibes y muros de anteriores estancias. Pose dos torres, la Homenaje, con ventanas germinadas en sus laterales y mazmorra en la parte inferior y la torre Prieta de la que solo se conserva una pequeña parte, el castillo posee un amplio patio de armas.

La fortaleza fue edificada para custodiar la vía militar de Toledo a Córdoba. En 1229, tras la Reconquista cristiana, fue donado por Berenguela de Castilla a la Orden de Calatrava, que lo convirtió en la sede de la Encomienda de Bolaños. En 1520 se reparó para combatir el levantamiento comunero. Tras un largo periodo de dejadez, el espacio se destinó a eventos culturales, hasta 2003, fecha en la que se hizo una excavación arqueológica en la que se descubrieron los restos de un foso defensivo que rodea las murallas.

Sabemos que en 1195, tras la derrota en la batalla de Alarcos, el castillo de Bolaños pasa a manos musulmanas siendo recuperado en 1212. La Reconquista modificó su función, pasando de dedicarse a la defensa de las vías de comunicación a ser una atalaya de alerta ante las razzias de uno y otro bando cristiano. Es especialmente importante la confirmación de Fernando III en 1229 de la donación de esta puebla a la Orden de Calatrava por doña Berenguela. El castillo había sido cedido previamente a ésta por Alfonso VIII. Más tarde, en 1245, Alfonso X confirmó todos los privilegios que Fernando III y doña Berenguela habían dado a esta pequeña población. En 1373 se cita como posible residencia del maestre de la Orden de Calatrava, al que siguió perteneciendo hasta que en 1537 se creó la encomienda de Bolaños. El castillo fue perdiendo sus usos y motivos, transformándose en residencia y desvaneciéndose poco a poco como punto estratégico; aunque siguió desempeñando su papel de baluarte, sirviendo de lugar de encuentro entre los emisarios de la realenga Villa Real y los freires de la Orden, para intentar limar las asperezas que ambos bandos mantenían en su lucha particular por el control político.
A esta noble construcción le quedaban por jugar algunas bazas, como la de hacer frente al posible ataque comunero, en el s.XVI, para lo que fue sacado del olvido y remozado, después fue progresivamente abandonado. En los Libros de Visitas de la Orden de Calatrava se hacen referencia al mal estado de conservación y a la necesidad de hacer reparaciones en las casas del Castillo y sus murallas durante los siglos XVII y XVIII. En 1864 sale a subasta, hallándose por entonces arruinado.

Más tarde, en el s XX fue perdiendo lo poco que le quedaba, llegando a quedar tan limpio el patio que pudo albergar corridas de toros. La Diputación de Ciudad Real lo restauró en 1982, siendo utilizado para dar cobijo a diversos actos culturales. Actualmente es el principal uso del edificio, aparte de las visitas turísticas al propio monumento, cuya entrada tiene un precio de 1 Euro.

Como curiosidad decir que la tradición oral cuenta que en el castillo nació el rey Fernando III el Santo hijo de la reina de Castilla doña Berenguela algo no comprobado, ya que otras fuentes lo sitúan en el Monasterio de Valparaíso en el pueblo zamorano de Peleas de Arriba.

Es un edificio de transición del Gótico al Renacimiento. Tiene planta de una sola nave con cabecera poligonal. Se cubre con bóvedas estrelladas en cada tramo que delimitan los arcos fajones. Tiene
cuatro capillas laterales, de las que cabe destacar el baptisterio, que está a los pies de la nave y que se cubre con una bóveda de ladrillo de barro cocido, sobre ménsulas labradas en piedra. Es de admirar su pila bautismal del siglo XVI, con el escudo de la villa labrado, y que ha sido colocada al pie del presbiterio, un calvario pintado al fresco sobre la hornacina de San José y que pertenece al siglo XVII y el despacho parroquial, cubierto por una bóveda barroca de gruesos nervios y decoración vegetal. En el exterior destaca la fachada, con un rosetón abocinado de ladrillo de barro cocido, y la portada, de arco de medio punto, realizada en piedra caliza con dos medallones en los
que aparecen la cruz de Calatrava con dos eslabones a los pies y las llaves de San Pedro puestas en aspa. Se construyó en el siglo XVI, y estuvo dotada de un Retablo Mayor barroco del siglo XVII y un órgano del XVIII, que se perdieron en la Guerra Civil. En esta última época fue utilizada como barracón y caballerizas, volviéndose a consagrar en 1939. Como dato curioso, decir que en la reforma realizada en 2003 se encontraron varios niveles de enterramiento en el interior de la nave, que podrían datarse desde la apertura de la iglesia al culto hasta finales del siglo XVIII, en que Carlos III prohibió las inhumaciones en el interior de los templos.

Es una ermita del siglo XV, reformada ampliamente en el siglo XVIII, adoptando los cánones protobarrocos de la época. Tiene planta de cruz latina irregular, y en el crucero se alza una cúpula elíptica, encamonada al exterior, sobre pechinas, decorada con pinturas con motivos vegetales y en las pechinas, frescos con los rostros de los Santos Padres Latinos de la Iglesia. La bóveda es de medio cañón con lunetos ciegos, en la que pueden verse representados los símbolos de los cuatro evangelistas (Águila de San Juan, Toro de San Lucas, León de San Marcos y Ángel de San Mateo) en medallones separados. Es destacable su Retablo Mayor barroco del siglo XVIII que logró salvarse de la Guerra Civil Española por la afortunada intervención de la santera Teresa, que logró convencer a los destructor del peligro que corría la pared adosada al mismo de desplomarse y venir abajo si destruían el retablo. El retablo con columnas salomónicas y coronado por una pintura en tabla que representa la exaltación de la cruz, y los recientes frescos góticos descubiertos en la nave del templo son las obras histórico-artísticas más significativas del interior del edificio. En el exterior, la cubierta es de teja curva a dos aguas en la nave y a cuatro en el crucero, destacando su espadaña, de características similares a la de la capilla de la Universidad de Salamanca. El muro Sur queda delimitado por una verja de ladrillo de barro cocido y forja, que enmarca un patio, poco
común en la zona. En el siglo XVIII fue ampliada para acoger las imágenes de la iglesia de Santa María de la Alta Virtud, que había sido derruida, momento este en que adoptó su nombre más popular: “Ermita del Cristo de la Columna”, por entronizarse esta imagen en su Altar Mayor. Tuvo un cementerio en la parte Norte, con dos recintos, uno para católicos y otro para no católicos, que fue trasladado a principios del siglo XX a su ubicación actual.
En el año 2014 se realiza una restauración integral donde aparecen pinturas medievales en la nave de la ermita y pinturas barrocas en el presbiterio, a ambos lados del retablo mayor, estas últimas pinturas son "trampantojo" del propio retablo.
El Santuario de Nuestra Señora del Monte es un complejo en el que se venera a la imagen mariana de la Virgen del Monte, en el municipio de Bolaños de Calatrava (Ciudad Real). Consta de dos ermitas una primitiva del siglo XIII y otra posterior de finales del siglo XIX y principios del XX. El actual recinto del santuario se ubica en la antigua "Dehesa de la Moheda" perteneciente a la Orden de Calatrava en tiempos de las órdenes militares. El santuario alberga una de las colecciones de exvotos más numerosas de Castilla-La Mancha repartidas tanto en el coro de la Ermita Grande como en la sala museo donde se recogen algunos de los enseres de la liturgia y parte del ajuar de la imagen. El recinto del santuario es la principal zona verde y de esparcimiento de la localidad con arboledas, fuentes, mesas de camping, paseos y jardines que se reparten a lo largo de 16 fanegas de terreno.

Se celebra el 4 de febrero, desde el año 1838 y tiene su origen en los trágicos sucesos del 3 de febrero de 1837, cuando un grupo de guerrilleros carlistas asesinaron a 20 personas entre las que se encontraban las autoridades municipales. Antes de estos sucesos, se celebraba el 3 de febrero la festividad de San Blas, pero desde entonces, la fiesta fue suspendida y paso a honrarse el día siguiente a las Ánimas Benditas del Purgatorio. 

La hermandad de la Ánimas, pedía limosnas por el pueblo, principalmente productos del terreno que ese día eran subastados en la plaza, frente a la iglesia. Con el dinero obtenido se sufragaban las misas y funciones celebradas en honor a las ánimas. 

También, y hasta hace muy poco, se realizaban procesiones desde la iglesia parroquial hasta el cementerio portando el estandarte de la hermandad.
Se salía de la iglesia, tras celebrar una misa, cantando y rezando, y al llegar al Cristo del Calvario se empezaba a rezar un rosario, hasta llegar al cementerio, donde se celebraba otra misa. 

Con el paso de los años ha perdido el carácter religioso y únicamente se instalan puestos de frutos secos en la Plaza de España, donde se venden todo tipo de dulces como garrapiñadas, almendras tostadas, turrones, frutos secos, etc. Y se estableció la tradición bolañega de echar la “pañolá”, que consistía en llenar un pañuelo de todos estos frutos, atándolo por los picos y regalándolo a los seres queridos. La fiesta también es conocida popularmente como el "día de las almendrillas".

Es una fiesta muy celebrada, con gran tradición. Empiezan el sábado, alargándose hasta el miércoles cuando se entierra la sardina. Son cinco días llenos de máscaras y diversión desde las 16:00 horas con los bailes del café en el Círculo Agrícola Industrial (Casino de la verja), hasta altas horas de la madrugada en el auditorio "La Guardería", sin descanso. El sábado siguiente se celebra el desfile de carrozas con gran participación de comparsas de otros pueblos de la provincia. De especial interés es la tradicional "mascara guarra" que consiste en disfrazarse mediante la improvisación con las prendas anticuadas y viejas que ya no se utilizan.
La Semana Santa de Bolaños destaca especialmente por la compañía de romanos popularmente conocida como "los armaos" y su particular representación de los momentos cumbres de la pasión de Cristo, como el prendimiento, la sentencia del Viernes Santo y la representación de los momentos en los que Cristo camino del calvario se encontró con La Verónica, San Juan o su madre la Virgen María. En relación a los pasos procesionales, destacar las influencias de la iconografía andaluza en las cofradías Nuestra Señora de la Soledad o Jesús Nazareno y la sobriedad Castellana en el paso del Santo Cristo del Sepulcro (cofradía de los armaos). En los desfiles procesionales se pueden destacar diferentes momentos en diversos lugares de la ciudad como por ejemplo: La "Procesión del Prendimiento" a su paso por la Ermita del Calvario, la procesión del silencio a la salida del Cristo del Consuelo bajo el pórtico de la Iglesia de "San Felipe y Santiago", la procesión "Del Paso" con la representación del encuentro en la Plaza de España la mañana del Viernes Santo. De gran intimismo, el paso de la procesión de la Virgen de la Soledad el Sábado Santo por la penumbra de la calle Escuderos, y en el mismo entorno del Castillo, en la Plaza del Altozano el encuentro de la "Procesión del Resucitado". La Semana Santa de Bolaños fue declarada de Interés turístico Regional en el año 2007 (junto al resto de Semanas Santas del Campo de Calatrava) y posteriormente se anunció su declaración de Interés Turístico Nacional el 14 de septiembre de 2016 publicado en el BOE el 19 de septiembre de 2016.

Es sin duda la fiesta con más arraigo de la localidad, sacando de los bolañegos su espíritu más hospitalario ante foráneos y visitantes. Es celebrada el último domingo de abril en la antigua "dehesa de la moheda", perteneciente en el tiempo de las órdenes militares a la orden de Calatrava. En la ladera de este pequeño Monte o cerro que forman las primeras estribaciones de sierra Pelada, se construyó ochocientos años atrás la primera ermita que albergaría la imagen de la Virgen que ofreciendo su patronazgo a los pueblos limítrofes de Almagro y las aldeas que entonces se encontraban bajo su jurisdicción eclesiástica de Moral de Calatrava y Bolaños de Calatrava. En la Actualidad, el paraje es en un pequeño núcleo urbano surgido en torno a la primitiva Ermita de Nuestra Señora del Monte.

Desde la antigüedad los habitantes de la comarca (especialmente los bolañegos) acudían al entorno de la ermita, con familiares o amigos, en carros y bestias para pasar un día de campo en tono festivo, comiendo la tradicional caldereta manchega. Hoy en día los carros han sido sustituidos por los medios de transporte modernos como coches, tractores, furgonetas y camiones. Al igual que la duración de la festividad, que en otros tiempos, se celebraba un único día y en la actualidad se ha ampliado por la gran aceptación de la fiesta en la ciudad y a la que acude gente de diferentes puntos de España, ya no solo por la devoción a la Virgen bajo al advocación "del monte", sino por el gran ambiente festivo que se genera en los actuales tres días de fiesta (que mucha gente incluso prolonga), siendo declarado día de fiesta local el lunes siguiente a la romería.

De especial interés para visitantes es la imagen de la Virgen, tocada con un gracioso sombrero pastoril, la decoración de la ermita mediante juegos florales, y la subasta del "estadal" (medalla de oro que se subasta a las puertas de la ermita una vez finalizada la procesión); también destaca la tradición de colgar billetes en el manto de la Virgen del Monte durante la procesión de esta, el domingo por la tarde, tradición que en algunas ocasiones ha generado controversia entre el clero y la sociedad bolañega, y por la cual se recaudan generosas cantidades de dinero, difícilmente entendibles sino es desde la fe.
Cuando el incesante calor del verano manchego empieza a cesar, y la llegada de la temporada de recolección de los frutos del campo se acerca; se celebra las fiestas patronales en honor al santísimo Cristo de la columna, o también conocido como Cristo de "la albahaca" por la antiquísima tradición de llevar albahaca al Cristo. Aromática planta que a su vez engalana calles, plazas y patios en estas fechas. Pudiéndose denominar también estas fiestas como las fiestas de la albahaca por lo castizo de la tradición y el arraigo de esta planta en las huertas bolañegas.

El día 14 de septiembre dará paso a una semana de convivencia, de recreo y de diversión y como no, de encuentro entre bolañegos afincados en otras ciudades del país.
De gran vistosidad y colorido es la procesión de las típicas alabardas bolañegas que pierden su significado original para convertirse en vistosas varas rematadas con aros de flores, rosarios y escapularios que cada alabardero engalana como deseé.

Y que procesionan en las vísperas del día 14, y este mismo día, en la procesión del Cristo por la mañana y en la tradicional rifa de ofrendas por la tarde; donde se subastan productos de la tierra, que peñas y particulares ofrecen al patrón en las vísperas de su festividad.

Cabe destacar el gran ambiente festivo que se respira, el protagonismo de los bolañegos y de la juventud a través de las numerosas actividades que se llevan a cabo en la localidad. Entre ellas el concurso de peñas, donde los jóvenes mayores de 16 años, organizados en peñas, pueden disfrutar de numerosas pruebas en torno a la cultura bolañega, el conocimiento del pueblo o la gastronomía, gymkanas y variedad de actividades.

La gastronomía bolañega se encuadra dentro de los platos típicos manchegos, convirtiéndose en uno de los atractivos de Bolaños. Abarca una gran variedad culinaria, desde primeros platos, pasando por embutidos, encurtidos y conservas, hasta llegar a sus deliciosos postres. El clima seco y un tanto extremos, condicionan los diferentes cultivos de Bolaños. Esto a su vez determina las características de su cocina, siendo esta un tanto austera, pero conservando las pautas de la dieta mediterránea, como el empleo de hortalizas, legumbres, caza menor, carne de pollo y cordero, etc.

En la cocina tradicional bolañega, el pescado aparece en muy pocas recetas, y cuando lo hace, suele ser en salazón: salazón, cubanas, etc. El bacalao, tradicionalmente es rebozado en huevo y harina, sobre todo y tradicionalmente servido en Semana Santa. También se utiliza para enriquecer otros platos, como el Moje “Tostao” o “Tiznao”, el potaje de garbanzos, el Moje o ajo molinero. 

Los platos más típicos de Bolaños, tienen en común su fácil preparación y su bajo costo económico. Uno de estos platos son las gachas, elaboradas con harina de almortas o pitos. También pueden hacerse con patatas cocidas y cominos, recibiendo el nombre de Gachas de aceite o de ajillo-comino.

Las Migas, como las gachas, son un buen ejemplo de este tipo de platos, se preparan a base de pan picado, pudiéndolas acompañar con torreznos, magro o sardinas fritas y, para suavizarlas, con uvas, granada o naranja. Hay otras variedades de las Migas, como son las migas de pastor, que es una variante dulce, ya que realiza con leche, canela y azúcar, y las Sopas “Tostás”, que son más húmedas que las Migas.

En las huertas bolañegas, se cultivan tomates, pimientos, cebollas, berenjenas, patatas, ajos, cornachos, guindillas, habichuelas, calabacín, etc., que son los ingredientes de platos tan tradicionales como el Pisto Manchego, el Asadillo o Pisto “Asao”, el “Revientalobos”, las sopas de berenjena, las habichuelas con Perdiz y un sinfín de platos más. Además, estas hortalizas, se consumen también en forma de conservas, como las berenjenas aliñadas y embuchadas, los tomates en sal o en conserva, las guindillas en vinagre o las aceitunas aliñadas, entre otras. En verano también es común ver en las mesas bolañegas el pipirrana. 

La matanza, también es de gran tradición en Bolaños. De la cual han quedado en Bolaños embutidos autóctonos como la patatera, de influencia extremeña, elaborada con carne de cerdo y patata cocida, y el Salchichón imperial, catalogado como uno de los mejores salchichones nacionales y que está bajo patente en manos de una empresa local. Pero la carne utilizada más tradicionalmente, en Bolaños, es el cordero manchego, bajo denominación de origen. Uno de los platos más afamados realizados con esta carne es la caldereta de cordero, a la que se le añade un poco de vino blanco de la tierra, el cual también se utiliza para la elaboración de algunos postres como es el caso de los barquillos.

Uno de los ingredientes que tiene especial protagonismo en la cocina tradicional bolañega y, principalmente, en los postres y repostería, es el aceite de oliva virgen, base de la elaboración de platos como las Tortillas de Rodilla, los Rosquillos, las flores, las roscas de tallos.

Se cuenta que en tiempos remotos el castillo de Bolaños estaba comunicado por pasadizos secretos con el convento de los dominicos de Almagro hacia el oeste y con el Pardillo en dirección este. Este último pasadizo se decía que pasaba por el antiguo pozo de la nieve.
De hecho un grupo de estudiantes de Bolaños, al principio de los años cuarenta, hicieron un estudio sobre este tema, llegando a recorrer bastantes metros en dirección al castillo por el interior de este pasadizo. Partieron del pozo que hay en la casa que hoy todavía existe en la esquina que forman la calle Cristo con calle Toledillo. 
Estos pasadizos permitirían escapar del castillo en caso de asedio, o abastecer a los asediados.

Hoy el castillo se encuentra adornado en su fachada principal con un hermoso jardín, pero hace décadas todavía quedaba junto a la muralla que une las dos torres, parte del foso que en su tiempo rodearía el castillo y en esa especie de cueva, en la que solían acampar gitanos o acurrucarse los sin hogar de aquellos tiempos, había, en una de sus paredes, una mancha oscura con un cierto parecido a la huella de una mano ensangrentada. 
Aquella mancha, dice la leyenda, que era la huella de la mano herida de Doña Berenguela que allí se apoyó cuando los "moros" la llevaban prisionera.



</doc>
<doc id="6826" url="https://es.wikipedia.org/wiki?curid=6826" title="Boletín Oficial del Estado">
Boletín Oficial del Estado

El Boletín Oficial del Estado (BOE) es el diario oficial nacional español dedicado a la publicación de determinadas leyes, disposiciones y actos de inserción obligatoria. Su edición, impresión, publicación y difusión está encomendada, en régimen de descentralización funcional, a la Agencia Estatal Boletín Oficial del Estado.

La Constitución de 1978 dispone en su artículo 9.3 que «La Constitución garantiza […] la publicidad de las normas». Es por tanto un imperativo legal la publicación de las normas, canalizándose dicha publicación a través de los distintos boletines oficiales, el "BOE" en su caso.

De acuerdo con el Real Decreto 181/2008, de 8 de febrero, de ordenación del diario oficial "Boletín Oficial del Estado", el "BOE" es el diario oficial del Estado español, el medio de publicación de las leyes, disposiciones y actos de inserción obligatoria.

Contiene además las leyes aprobadas por las Cortes Generales, las disposiciones emanadas del Gobierno de España y las disposiciones generales de las comunidades autónomas.

Precedido por la "Gaceta de Madrid", ha tenido diversas denominaciones a lo largo de la historia del país.

Durante el siglo XVII la imprenta propició el nacimiento de numerosos boletines o gacetas en, prácticamente, toda Europa; estas publicaciones surgirán de manos de la iniciativa privada y con un contenido estrictamente informativo.

En España este fenómeno se concreta en la creación, en febrero de 1661, de la "Relación o Gaceta de algunos casos particulares, así políticos como militares, sucedidos en la mayor parte del mundo, hasta fin de 1660", convirtiéndose en el primer periódico de información general que surge en España.

Actualmente, el BOE es el segundo diario editado en papel más antiguo del mundo, aunque su edición en papel es desde 2009 únicamente testimonial, a efectos de conservación y permanencia, sin distribución pública (ver abajo). El diario más antiguo es el Opregte Haarlemsche Courant (actualmente llamado Haarlems Dagblad), fundado en 1656 en Holanda. Aún más antiguo sería el Post-och Inrikes Tidningar, diario oficial de Suecia, fundado en 1645 bajo el nombre de Ordinari Post Tijdender, pero desde 2007 ya no se publica en papel.

La "Gaceta", en el momento de su nacimiento, estaba dirigida y administrada desde la iniciativa privada. Esta circunstancia varía por completo durante el reinado de Carlos III, quien, en 1762, decide otorgar a la Corona el privilegio de imprimir la "Gaceta". De esta forma, la publicación pasa a convertirse en un medio de información oficial que refleja los criterios y decisiones del Gobierno.

Posteriormente, por la "Real orden circular del Gobierno dirigida á todas las autoridades del reino" de 22 de septiembre de 1836, se establece que los decretos, órdenes e instrucciones que dicte el Gobierno se considerarán de obligación desde el momento en que sean publicados en la "Gaceta". De este modo, la Gaceta pasaba a convertirse en un órgano de expresión legislativa y reglamentaria, característica que conservará hasta la actualidad.

Por lo que se refiere a la denominación, la "Gaceta" adopta con carácter definitivo el nombre de "Gaceta de Madrid" en 1697, aunque ya desde 1677 se la conocía como tal. Será en 1936 cuando esta cabecera se sustituya en el bando franquista por "Boletín Oficial del Estado", nombre que ha perdurado hasta nuestros días.

Del mismo modo, la existencia de la Imprenta Nacional, como entidad aneja al "Boletín", es fruto de una decisión que cuenta ya con más de un siglo de antigüedad.

En cuanto a la estructura de la "Gaceta", es en 1886 cuando se establece que la publicación sólo contendrá documentos de interés general (leyes, decretos, sentencias de tribunales, contratos de la Administración Pública, anuncios oficiales, entre otros); asimismo se establece un orden de preferencia en la publicación de las disposiciones que atiende a criterios de urgencia y un orden de prioridad de la inserción de documentos: Leyes, Reales Decretos, Reales Órdenes. Por último, se prescribe que, dentro de cada sección, el orden de publicación ha de ser el de antigüedad de los Ministerios, siempre tras la Presidencia del Consejo de Ministros. Toda esta estructura será perfilada por una Real Orden de 6 de junio de 1909.

Posteriores normas de 1948, 1957, 1960 y el Real Decreto 181/2008, de 8 de febrero, de ordenación del Diario Oficial del Estado, han ido conformando el funcionamiento del "Boletín Oficial del Estado".

Conforme con lo dictado por la Ley 11/2007 de 22 de junio de acceso electrónico de los ciudadanos a los Servicios Públicos y el Real Decreto 181/2008 de 8 de febrero de ordenación del diario oficial "Boletín Oficial del Estado", el 31 de diciembre de 2008 se publica el último "BOE" impreso. A partir de ese momento desaparece la edición en papel, tal y como se conocía, que se sustituye con la electrónica, en su web oficial, siendo su consulta totalmente gratuita. No obstante, el inicio de la edición electrónica del "Boletín" no supone la desaparición de la edición impresa, que se mantiene, con el mismo carácter oficial y auténtico, a efectos de conservación y permanencia del diario oficial, y también como medio de difusión en los supuestos en que no resulte posible la aparición de la edición electrónica. Esta edición impresa es obtenida de la edición electrónica.

Desde su inicio en 1661 y a lo largo de su historia, la "Gaceta" recibió diferentes títulos, siendo importante resaltar que en determinados momentos históricos convivieron, al mismo tiempo, varios diarios oficiales con denominaciones distintas.


En el "Boletín Oficial del Estado" se publican:

El Consejo de Ministros podrá excepcionalmente acordar la publicación de informes, documentos o comunicaciones oficiales, cuya difusión sea considerada de interés general.

Hay, además, un suplemento independiente en el que se publican las sentencias, declaraciones y autos del Tribunal Constitucional.

La información se organiza de acuerdo con los siguientes criterios:

Finalmente, las leyes, los reales decretos-leyes y los reales decretos legislativos, una vez sancionados por el rey, y publicados en castellano en el "Boletín Oficial del Estado", podrán ser también publicados en las demás lenguas oficiales de las diferentes comunidades autónomas. Para hacer efectivo este precepto hay suscritos convenios de colaboración entre el Gobierno de la Nación y los Órganos de Gobierno Autonómicos de la Generalidad de Cataluña, Junta de Galicia y Comunidad Valenciana.

El artículo 14 del Real Decreto 181/2008, de 8 de febrero, de ordenación del diario oficial "Boletín Oficial del Estado", establece en su párrafo 1 que:

El párrafo 2 de dicho artículo establece la obligación, de todas las oficinas de información y atención al ciudadano de la Administración, de facilitar la consulta pública y gratuita del "BOE", para lo que existirá, al menos, un terminal informático para este fin:

El "Boletín Oficial del Estado" cuenta con un buscador avanzado para hallar las disposiciones de legislación, personal, otras disposiciones o todo el BOE. También ofrece la posibilidad de descargar la información del BOE en formato PDF y de reutilizar los contenidos en los formatos XML y XSD.
En 2013 el "Boletín Oficial del Estado" creó una aplicación para móviles de acceso a los contenidos del BOE con sistema operativo Android y en 2014 para el sistema operativo iOS.

Aparte del "BOE" existen también boletines oficiales del resto de administraciones territoriales (de cada comunidad autónoma y de cada provincia), al mismo tiempo que otros boletines como el de las Comunidades Europeas y los de las Asambleas Legislativas de las Comunidades autónomas.




</doc>
<doc id="6827" url="https://es.wikipedia.org/wiki?curid=6827" title="Krzysztof Kieślowski">
Krzysztof Kieślowski

Krzysztof Kieślowski ( Varsovia, -Ibídem, ) fue un director y guionista de cine polaco.

Se crio en el seno de una familia de clase modesta. Poco después de finalizar el primer ciclo de estudios, ingresó en la escuela de bomberos, pero algunos meses más tarde la abandonó con la intención de volver a estudiar. En 1957 se inscribió en la Escuela de Cine y Teatro de Łódź. Su primera producción cinematográfica estuvo centrada en la vida de los trabajadores y los soldados de su Polonia natal.

A fines de los años 1980, realizó para la televisión una de sus obras más importantes: "Decálogo". Esta es una obra basada en la estructura de los Diez Mandamientos con la que Kieślowski tomó la religión para hablar del ser humano y de sus contradicciones morales. Cada capítulo tiene una duración aproximada de una hora.

Tras su paso por la televisión polaca, a principio de los años 1990 comenzó a trabajar en Francia, donde realizó su más importante trabajo, la trilogía "Tres Colores", dedicada a la bandera francesa. Tras esto, decidió retirarse del cine aunque comenzó a escribir el guion de "La Divina Comedia" de Dante, mediante una trilogía titulada "Paraíso", "Purgatorio" e "Infierno", para llevarlo a la pantalla. Sin embargo, en 1996, sin concluir este guion, murió de un ataque cardíaco en su ciudad natal.



</doc>
<doc id="6831" url="https://es.wikipedia.org/wiki?curid=6831" title="Dilbert">
Dilbert

Dilbert es el nombre de una tira cómica satírica creada por Scott Adams que ha aparecido en los periódicos desde 1989, dando lugar a varios libros, una serie animada de TV y numerosos productos relacionados que van desde muñecos rellenos hasta helados. 

La trama de este cómic se desarrolla en el contexto de lo cotidiano para millones de empleados y oficinistas, especialmente en la industria del software o telecomunicaciones (de hecho Adams trabajaba en Pacific Bell): políticas de oficina insólitas, jefes incompetentes, compañeros de trabajo molestos, asuntos sin sentido, juntas eternas, etc. El mismo tipo de cosas que la gente odia en su trabajo diario son las que provocan las carcajadas en "Dilbert". 

Los principales personajes de esta tira encarnan los peores defectos del ambiente laboral, algunos de ellos son:


La tira cómica originalmente giró alrededor del ingeniero Dilbert y su perro "mascota" Dogbert, con situaciones que tenían lugar en la casa de ambos, muchas tiras trataron de las características de ingeniero de Dilbert o sus raros inventos, en alternancia con tiras basadas en las ambiciones megalómanas de Dogbert. Más tarde, el escenario de la mayoría de la acción se trasladó al centro laboral de Dilbert: una gran compañía de tecnologías, con lo que la tira cómica empezó a satirizar el ambiente de trabajo de las Tecnologías de la Información y las situaciones de oficina. El éxito popular de la tira cómica se atribuye a las situaciones del ambiente laboral y los temas que son familiares a gran parte de su audiencia, que se siente identificada con Dilbert y hace una suerte de catarsis con las tiras. Todo aquel que trabajó en tecnología pasó alguna vez por alguna situación reflejada en la historieta.

Dilbert retrata la cultura corporativa como un mundo kafkiano de burocracia para sus propios objetivos y las políticas de oficina que soportan la productividad, donde las habilidades de los empleados y sus esfuerzos no son recompensados, y se elogia el trabajo pesado pero se lo retribuye mal. También satiriza acerca de los advenedizos, los holgazanes, los ignorantes que se llevan el mérito de otros, y varias situaciones tragicómicas del mundo laboral. 

Los tópicos temáticos presentados en "Dilbert" podrían resumirse en los siguientes puntos:


Alguno de los títulos publicados en castellano son:




</doc>
<doc id="6834" url="https://es.wikipedia.org/wiki?curid=6834" title="Taekwondo">
Taekwondo

El es un arte marcial coreano moderno; el cual fue dado a conocer como "Taekwon-Do" en 1955 por el general Choi. Fue convertido en deporte olímpico de arte y combate durante los Juegos Olímpicos de Seúl 1988, donde fue presentado como deporte de exhibición, hasta su reconocimiento deportivo olímpico en los Juegos Olímpicos de Sídney 2000. 

Si bien hay dos federaciones con diferencias en las modalidades de competencia (combate y formas), el estilo promovido por la WT (Taekwondo Mundial) es reconocido como deporte olímpico, mientras que el estilo promovido por la ITF (Federación Internacional de Taekwondo) también desarrolla sus propios campeonatos, como arte marcial y como disciplina deportiva, este último es el estilo original implementado por el General Choi.

Dentro de las artes marciales y deportes de combate, el Taekwondo destaca por la variedad y espectacularidad de sus técnicas de patadas y es una de las artes marciales más conocidas y efectivas del mundo. Para su creación, el general Choi se basó en el taekkyon o danza marcial coreana (que influyó en la forma de realización de varios de los golpes con el pie y en el trabajo táctico o de pasos y desplazamientos), así como en el karate-Do japonés (de donde provienen los golpes con el puño y a mano abierta, la planimetría o división por zonas del cuerpo humano, los bloqueos, las posiciones y el sistema de grados por cinturones de colores). De esta disciplina también se derivan su primer uniforme y sus primeras formas o "pumsae" conocidas como "Hyong" en la ITF (International Taekwon-Do Federation) y como "Palgwe" en la WT (World Taekwondo). Estas primeras formas han sido reemplazadas por las formas "Tul" en la ITF, y por las formas "Taeguk" y "Taekwon" en la WT, con el fin de afianzar más su propia identidad, frente a las disciplinas de donde proviene.

Los beneficios de la práctica continua del Taekwondo son muy buenos y productivos. Muchos estudios han revelado que las personas que se ejercitan en una disciplina deportiva, a lo largo de su vida, tienen menos riesgos de obesidad, desarrollo de enfermedades crónicas, drogadicción, entre otras condiciones que afectan la salud física, mental y emocional. Las investigaciones realizadas en adolescentes, mostraron que la práctica continua del taekwondo como arte marcial, ayuda a mejorar la salud en general, y condiciona de forma apropiada los reflejos, mejorando el tiempo de reacción. 

Un estudio realizado con personas mayores de 70 años mostró que la práctica cotidiana de las artes marciales tradicionales de naturaleza "dura" mejora el balance y el tiempo de reacción de las personas. Por esta razón, se puede concluir que el taekwondo no es un simple deporte más que otorga una óptima condición física y buenos hábitos de vida, sino que además otorga a los practicantes dedicados a explorar la totalidad del arte, la posibilidad de reaccionar con eficacia ante una amenaza o situación adversa.

Como en otras artes marciales tradicionales, en el Taekwondo, los grados son representados por las llamados cinturones de colores, (otorgadas no solo por la destreza física, sino por su crecimiento personal), los significados de estas se basan en los ciclos de la naturaleza, en definitiva: el entrenamiento en artes marciales es un proceso continuo de maduración emocional, enmarcado dentro del respeto, la constancia y la disciplina.

La palabra taekwondo proviene de los caracteres sinocoreanos o Hanja 跆拳道 que significan:

Por tanto, la palabra "taekwondo" podría traducirse como «El camino del puño y la patada», lo cual hace referencia a que es un arte marcial que utiliza únicamente los pies, las manos y otras partes del cuerpo (como por ejemplo: las rodillas y los codos), prescindiendo por completo del uso de armas, tanto tradicionales como modernas. Aunque diversos canales de televisión han señalado que realmente la traducción directa seria «El Poder del Puño y la Patada», esto no es correcto. El taekwondo, se considera un método que busca acondicionar el cuerpo y potenciarlo físicamente, además del desarrollo de la voluntad y la sabiduría por medio de la experiencia. Basándose en las diversas leyes físicas para generar la máxima potencia, enfocándola de manera precisa, mediante la aceleración de la masa corporal en un gesto motor o grupo de estos en combinación. El Taekwondo busca la percusión en la mayoría de sus técnicas y la eficacia de estas.

Los maestros e instructores coreanos, debido a su fuerte nacionalismo y resentimiento tras la ocupación japonesa por 35 años (1910- 1945), (periodo donde muchos de los maestros precursores del arte se entrenaron en karate, Judo o kendo) según : y tras la Guerra de Corea (1950-1953) donde se produjo la división actual del país en Corea del Norte, y Corea del Sur, ubican los orígenes del taekwondo remontándose al año 50 d.C., a la práctica del arte marcial nativo llamado taekkyon, arte aún practicado, que incluso ha sido declarado patrimonio inmaterial de la humanidad por las Naciones Unidas. La evidencia de su práctica fue hallada en tumbas antiguas por arqueólogos japoneses durante la ocupación, donde algunas pinturas murales mostraban a dos hombres en una escena de pelea.

Antes de la formación de las dos coreas, la del norte y la del sur, se podían distinguir los antiguos tres reinos en Corea, siendo estos:

Los militares de la dinastía Goguryeo desarrollaron un estilo de boxeo o arte marcial o "kempo coreano" llamado kwon bop basado en diversos estilos chinos, pero adaptados a sus propias necesidades. En esa época también se popularizó un estilo de danza marcial que daba mucha importancia a las patadas en lugar de los puñetazos. Este estilo de defensa personal sin armas es el denominado taekkyon.
Otro arte marcial de gran importancia en esa época fue el subak que trataba del entrenamiento en armas tradicionales como la espada, el arco y la lanza. Se creó un cuerpo de guerreros organizados instruidos en este arte, denominado "sonbe". En el año 400, el reino de Baekje intentó invadir el reino de Silla. Se dice que Gwanggaeto, apodado "el grande de Goguryeo", envió 50.000 tropas Sonbe de apoyo al reino de Silla, lo que supuso el primer contacto del reino de Silla con el subak.

La dinastía Silla unificó los reinos después de ganar la guerra contra el reino de Baekje en el año 668 y contra el de Goguryeo en el año 670 d.c. Sus guerreros, los caballeros florecientes o "Hwarang" desempeñaron un papel importante en la unificación de la antigua Corea, pero posteriormente cayeron en el olvido debido al abuso de su poder político, por lo que fueron reemplazados por los nobles.

El Taekwon-Do, es un arte marcial moderno creado por las personas más inteligentes del mundo, registrado por primera vez ante el gobierno coreano en 1955 por el General Choi Hong Hi, quien para su creación se basó en todo lo que aprendiera antes de su juventud como estudiante del Taekkyon, antes de la ocupación japonesa de Corea (1910-1945), periodo donde el joven Choi fue protagonista de hechos que marcarían su vida y lo llevarían a impulsar la creación del Taekwondo. Tras cumplir sus 20 años, Choi fue enviado al Japón, donde además de continuar con su educación universitaria fue formado en la práctica del Karate-Do japonés estilo Shotokan, logrando dos años más tarde su primera graduación como cinturón negro 1º DAN. Su camino en el aprendizaje del Karate lo llevó a la par de su formación académica, manteniendo una gran preparación física y mental que lo terminaría ascendiendo a la graduación de 2º DAN.

Durante el desarrollo de la Segunda Guerra Mundial (1939-1945), Choi fue obligado a enlistarse y servir en el ejército del imperio japonés, sin embargo en la Corea ocupada, durante un viaje de regreso a Pyongyang (hoy capital de Corea del Norte), Choi fue tomado prisionero por el ejército japonés bajo las acusaciones de traición y de promoción del Movimiento Independentista Coreano, siendo encarcelado en forma preventiva por 8 meses hasta la resolución de su juicio. Durante su encierro, comenzó a reunir lo mejor de las dos artes marciales aprendidas (Taekkyon y Karate) y a dar forma a su propio estilo marcial. Tras haber finalizado la guerra en 1945, con la derrota y el retiro de los invasores japoneses gracias a la intervención de los Estados Unidos, Choi fue designado como subteniente del nuevo ejército coreano (hoy con fidelidad a la actual Corea del Sur), teniendo a partir de aquí una nueva forma de difusión de su nuevo arte.Y gracias a ello se conoce este nuevo deporte.

A lo largo de su carrera militar (en la que se incluyeron varios viajes a los Estados Unidos y su intervención en la Guerra de Corea), Choi continuó perfeccionando sus técnicas y cosechando seguidores (muchos de ellos soldados que se encontraban bajo sus órdenes), hasta llegar en el año 1954 a ser ascendido al rango de General. Durante esos años denominó a su escuela como Oh Do Kwan (en coreano: "Mi propio estilo") al tiempo que daba estructura y refinamiento a las técnicas y tácticas del nuevo arte junto a su compañero Nam Tae Hi. El saber marcial de Choi, comenzó entonces a tomar reconocimiento entre las fuerzas armadas y el pueblo coreano, quienes aceptaron la propuesta de la escuela Oh Do Kwan como un nuevo arte marcial, comenzando a interesarse por su práctica. La efectividad y difusión de su método marcial, llevaron a Choi a organizar una reunión con instructores, historiadores y líderes de la sociedad coreana para dar un nombre definitivo a este nuevo arte marcial. Como fruto de estas reuniones, el 11/04/1955 fue aprobado como nueva denominación del arte creado por Choi, el nombre de Taekwondo, el cual describe a este arte marcial como el camino de los pies y puños (Tae = pies, Kwon = manos, Do = camino), debido al período de aprendizaje que debe andar cada practicante y al hecho de utilizar como principales métodos de ataque, y defensa, los golpes de puño y con los pies.

El Taekwondo WT o de la Federación Mundial de Taekwondo (WT por su sigla inicial en idioma inglés) fue diseñado teniendo en cuenta las enseñanzas de varios maestros coreanos, quienes vivieron en Japón durante la ocupación de Corea (1910-1945), y que aprendieron de los maestros Gichin Funakoshi, kenwa Mabuni y kanken Toyama, fundadores de los estilos japoneses Shotokan, Shitō-ryū y Shudokan de karate-Do respectivamente. Es importante notar que algunos pocos de estos maestros ya tenían experiencia previa en artes marciales chinas (kung- fu) y/o nativas como el Taekkyon coreano; Sin embargo tras regresar a Corea, fundaron las llamadas 9 escuelas o kwan (5 originales y 4 que surgieron después de la segunda guerra mundial (1939-1945) siendo estas:

1. Chung Do Kwan (청도 관) - primer dojang de Taekwondo en Corea fundado en 1944 por Lee Won Kuk (이원국), quien había estudiado Taekkyeon en Seúl, y también estudió Karate Shotokan en Japón, y varios estilos de Kung Fu en las provincias de Henan y Shanghái en China.

2. Song Moo Kwan (송 무관) - fundada en Kaesong en 1946 por Ro Byung Jick (노병 직), que había estudiado Karate Shotokan con Gichin Funakoshi junto con el fundador de la Chung Do Kwan, Lee Won Kuk en Japón.

3. Moo Duk Kwan (무덕 관) - fundada 1945 por Hwang Kee (황기) quien denominó a su arte en un principio Hwa Soo Do. Hwang estudió Taekwondo, Tai chi y algunos tipos de Kung Fu en China. Sus dos primeros intentos de dirigir una escuela de Hwa Soo Do no tuvieron éxito. Después de 1946, dándose cuenta de que la mayoría de los coreanos no estaban familiarizados con las artes marciales chinas que enseñaba, incorporó la influencia más familiar para la época; la influencia japonesa proveniente del karate, en el Tang Soo Do dentro del plan de estudios. En 1953 y en adelante hasta el año 1960, la Moo Duk Kwan había crecido hasta convertirse en la mayor organización de artes marciales en Corea, cuando cerca del 75% de todos los artistas marciales en Corea practicaban Tang Soo Do - Moo Duk Kwan. En 1957, Hwang Kee redescubrió el arte del Soo Bahk (수박) o Su Bak, un arte marcial tradicional de Corea descrito en el antiguo manual militar coreano o Muyedobotongji (무예 도보 통지), añadiendo algunas técnicas a su arte. En 1960, la Asociación Coreana Bahk Do Soo se constituyó, y oficialmente se registró ante el gobierno de Corea como arte marcial coreano tradicional. Al año siguiente, la disciplina Moo Duk Kwan - Soo Bahk Do fue reconocida internacionalmente por primera vez.

4. Ji Do Kwan (지도관) - o el club Chosun Yun Mu Kwan Kong Soo Do (조선 연 무관 공수도 부), la Chosun Yun Mu Kwan había sido la escuela Kodokan original japonesa en Corea durante más de 30 años antes) fundada el 3 de marzo de 1946 por Chun Sang Sup (전상섭); quien había estudiado karate shitō ryū con el maestro kenwa Mabuni en Japón, y más tarde llamó a su arte "Kong Soo Do (공수도) '. Chun tenía una relación muy estrecha con Yoon Byung-In, fundador del club YMCA Kwon Bop. Chun y Yoon viajarían a entrenar con otros artistas marciales, a veces viajando a Manchuria. Se entrenaron entre sí, tanto que llegaron a ser conocidos como hermanos. Chun se perdió durante la Guerra de Corea; Posteriormente, los miembros restantes de este Kwan votaron para cambiar su nombre a 'Ji Do Kwan'. Después de que Chun desapareció en la Guerra de Corea (1950-1953), los estudiantes originales de Chun nombraron al Maestro Yoon Byung-Kwe (윤쾌병, quien además había entrenado Chuan Fa/ kung fu en Manchuria) como su primer Presidente.

5. Chang Moo Kwan (창 무관) - o el club de la YMCA Kwon Bop (YMCA 권법 부) fue fundado en 1946 por Yoon Byung-in (윤병인), quien había estudiado Kung Fu chino (Quan fa) en China. Además después en Japón durante sus estudios en la Universidad de Nihon, se entrenó bajo el karate Shudokan, con el maestro fundador de este estilo, Kanken Toyama. A diferencia de otros Kwans que dieron origen al taekwondo. El Chang Moo Kwan buscó basarse más en el Kung Fu chino (Quan-fa). La temprana Chang Moo Kwan enseñó el estilo Palgi Kwon (팔기 권) (influenciado por el Baji-quan). Yoon también desapareció durante la Guerra de Corea (1950-1953). Sus enseñanzas fueron continuadas por su mejor estudiante, Lee Nam Suk, quien cambió el nombre de la escuela a Chang Moo Kwan. Actualmente uno de sus representantes el 10 ° Dan Gran Maestro Soon Bae Kim, siendo uno de los dos grados más altos dados por el Kukkiwon (10 Dan), y está a cargo de las pruebas superiores en el Kukkiwon.

- Escuelas o kwans surgidas después de la segunda guerra mundial (1939-1945) y la liberación de Corea :

6. Han Moo Kwan (한무 관) - fundada en agosto de 1954 por Lee Kyo Yoon como una rama de la Yun Moo Kwan / Ji Do Kwan.

7. Oh Do Kwan (오도 관) - fundada en 1955 por Choi Hong Hi, quien también se convirtió en jefe honorario de la Chung Do Kwan. Los mejores instructores fueron Nam Tae Hi y Han Cha Kyo. Esta rama se convertiría en lo que hoy es el taekwondo ITF.

8. Kang Duk Kwan (강덕원) - fundada en 1956 por Park Chul Hee y Hong Jong Pyo como una rama de la Kwon Bop Bu / Chang Moo Kwan.

9. Jung Do Kwan (정도 관) - fundada en 1956 por Lee Yong Woo (falleció en agosto de 2006) como una rama de la Chung Do Kwan.

En el año 1973 nace la WTF y se realiza el primer campeonato mundial de Taekwondo WTF.

La formación de la Asociación de Kong Soo Do, la formación de la Asociación de Taekwondo de Corea o KTA y el Kukkiwon
El 25 de mayo de 1953, mientras que la guerra en Corea continuaba, los representantes de los cinco Kwans originales (Song Moo Kwan, Chung Do Kwan, Yun Moo Kwan / Ji Do Kwan, Chang Moo Kwan y Moo Duk Kwan) se reunieron en la ciudad de Pusan y formaron la Corea Kong Soo Do Asociación. La asociación no eligió a un presidente. Eligieron a Young-Joo Cho como vicepresidente y Byung Jik Ro (fundador del Song Moo Kwan) como Director Ejecutivo.

Byung Jik Ro también fue nombrado como "el maestro instructor" y como "el presidente del comité de promoción de la organización." Con el tiempo la discordia surgió entre los diferentes miembros, y la asociación se disolvió. La escuela Chong Do Kwan continuó describiendo su arte como Kong Soo Do hasta 1962.

Cuando terminó la guerra de Corea (1950-1953), Hong Hi Choi y Nam Tae Hi fundaron la Oh Do Kwan dentro de la academia militar, y solo el personal militar era admitido, a pesar de que había fuertes vínculos con la escuela Chung Do Kwan, que Choi fundó más adelante en 1954. Choi afirmó ser quien diseñó las formas Chang Hon utilizadas por la Federación Internacional de Taekwon-Do, pero algunos creen que vinieron del maestro Nam Tae Hi, que tenía mucha más experiencia y entrenamiento en las artes marciales que Choi, y quien además era su superior.

El 3 de septiembre de 1959, los representantes de las escuelas o Kwans acordaron unirse bajo el nombre de "Asociación de Taekwondo de Corea" (o KTA, Korean Taekwondo Association en idioma inglés), y el General Choi Hong Hi fue elegido su presidente. El General Choi fue elegido presidente a causa de su posición como general en el ejército de Corea (que aún estaba bajo régimen militar) y porque él prometió a los jefes de las Kwans originales que iba a promover el Taekwondo. Sin embargo, para ese entonces Corea era un país pobre, devastado por las guerras; y tenía otras preocupaciones más urgentes que gastar valiosos recursos en la promoción de las artes marciales. Debido a que el gobierno no lo pudo ayudar, como Choi había prometido, Choi cayó en desprestigio con los líderes de las otras escuelas o Kwan.

El 19 de septiembre de 1961, por decreto presidencial, la asociación recién formada se convirtió en la Asociación Coreana de Tae-Soo-Do. Esto se considera la "verdadera" de la KTA. El Sr. Che Myung Shin (quien no era artista marcial) fue elegido el primer presidente de la KTA, sirviendo hasta el 15 de enero de 1965, cuando fue reemplazado por el General Choi. Choi fue presidente por un año, durante el cual convenció a la asociación para cambiar su nombre de nuevo a la Asociación Coreana de Taekwondo. El cambio de nombre se completó el 5 de agosto de 1965. El 30 de enero de 1966, Byung Jik Ro, fundador de la escuela Song Moo Kwan fue elegido presidente de la KTA.

El 8 de enero de 1977, las escuelas Kwan de forma unificada, dieron el reconocimiento al Kukkiwon, que fue creado en 1972. El Kukkiwon es también conocido como los World Taekwondo Headquarters (en idioma inglés), siendo el hogar de la Academia Mundial de Taekwondo, es la organización reguladora oficial del taekwondo establecida por el gobierno de Corea del Sur. Además el Kukkiwon está acreditado como la institución oficial de promoción para los futuros cinturones negros en Taekwondo. Antes de esta declaración, las escuelas Kwan otorgaban sus certificaciones como "kwan" de forma individual, siendo más apreciados, que los certificados que emitidos en ese entonces por el Kukkiwon o la KTA (Korean Taekwondo Association). Actualmente, la Federación Mundial de Taekwondo (o WTF World Taekwondo Federation) ha reemplazado los nombres de las diferentes escuelas o "kwan" con números de serie, en los diplomas. Asimismo el Kukkiwon adjunta el número de grado para cinturón negro superior (1-9) Dan en sus diplomas.

Si bien el Taekwondo no es un arte marcial moderno basado en algunas artes marciales antiguas como el Taekkyon y tradicionales como el karate-Do; en Occidente el TKD tiene poco tiempo de conocerse. Ya que, no fue sino hasta después de la guerra de Corea (1950-1953), que los maestros coreanos empezaron a enseñar a los soldados de los EE.UU. en los años 60 y 70 fue promovido como "karate coreano". Y solo fue hasta después de haber sido registrado como Taekwondo en 1955, por el General Choi que esta disciplina tuvo un nombre común. Fue Choi quien decidió fundar la Federación Internacional de Taekwondo, conocida por sus siglas en inglés ITF. La formación de esta federación, permitiría la apertura de las primeras academias en la década de los 60 en América y Europa. Para 1973 y con el afán de globalizar la disciplina, un grupo de maestros provenientes de la ITF, así como de las diferentes escuelas marciales coreanas o "quan" inauguran en 1973 la Federación Mundial de Taekwondo (WTF), la cual comienza a profesar la disciplina con múltiples reformas, desde Corea del Sur respecto a lo reglamentado por la ITF.

En 1973 se realizó el primer campeonato mundial de TKD, pero durante la década de los 70 fue varonil, las mujeres empezaron a tener oportunidades de participar hasta 1987, a mediados de la década de los 80 el Taekwondo WTF fue aceptado como deporte por el COI; ya en 1986 el Taekwondo participó por primera vez en unos juegos deportivos (juegos asiàticos) y en 1987 en juegos panamericanos, y con esto se empieza a usar el casco en los combates, requisito solicitado por el COI para ser reconocido como deporte olímpico, en 1988 participó por primera vez en Juegos Olìmpicos, tanto en Seùl 88 y Barcelona 92 solo como deporte de exhibición, las medallas no contaron para el medallero general, sino hasta el 2000 que se tornó deporte olímpico. Más adelante, el COI, también requirió que el Taekwondo WTF diera a conocer más su faceta como arte, por lo que desde 2006 comenzaron los campeonatos de formas o pumse / pumse así: 2006 Seúl. Corea, 2007 Incheon. Corea, 2008 Ankara. Turquía, 2009 El Cairo. Egipto, 2010 Tanshkent Uzbekistán, 2011 Vladivostok. Rusia, 2012 Tunja. Colombia, 2013 Bali. Indonesia, 2014 Aguascalientes. México, y 2016 Lima. Perú., en 2009 vino la incursión de los petos electrónicos, para darle más certeza a las puntuaciones, aunque esto ha bajado la calidad y espectacularidad de los combates, la WT ha buscado volver a la técnica dinámica cambiando el reglamento de los combates. Ahora hay una división entre la nueva y la vieja escuela.

El taekwondo se caracteriza por su amplio uso de las técnicas de pierna y patadas, que son mucho más variadas y tienen mayor protagonismo que en la mayoría de las artes marciales, y deportes de combate. La depurada técnica de las mismas las hace destacar por su gran rapidez y precisión.

La importancia dada a la práctica de las técnicas de puño y mano abierta, depende del estilo (ITF o WTF/ WT) practicado, del entrenador y de la escuela donde se practique. Muchas escuelas tienden a descuidar el entrenamiento de las técnicas de mano abierta y puño, ya que su uso está cada vez más restringido en la competición, dándole más puntaje a las patadas. No obstante, un buen entrenamiento debe incluir tanto las técnicas de puño, y mano abierta así como las técnicas de pierna del Taekwondo, ya que no debe estar enfocado solo al éxito en la competición, sino al dominio y conocimiento del arte marcial.

Todo esto, hace que el Taekwondo al ser practicado como arte marcial de defensa personal, es decir, explorando y entrenando la totalidad de sus técnicas, sea efectivo en la lucha en pie, destacando así frente a otras artes marciales en la distancia larga, donde se puede aprovechar mejor la fuerza explosiva, la velocidad de acción y reacción y la combinación de técnicas de piernas que desarrollan sus practicantes, sin olvidar las técnicas de puño y mano abierta, el uso de la respiración y la conciencia física y emocional, interna y externa, adquirida por la meditación y la práctica constante y consciente. 

Las técnicas del Taekwondo, se clasifican en:

El taekwondo es un arte marcial y deporte olímpico que destaca por sus técnicas de patadas, normalmente enfocadas al ataque al tronco o la cabeza. Aunque en sus inicios se potenciaban los ataques a los pies, por barrido. O incluso al cuerpo, y cuello mediante atrapes para propiciar un derribo. Cada técnica de patada, como la patada frontal de percusión (ap chagui), la patada frontal de empuje (miro chagui), patada lateral (yop chagui), patada circular a la cabeza o tronco (dollyo chagui), patada semi-circular al pecho o tronco (bandal chagui), patada en arco hacia el interior (an chagui) o hacia el exterior (bakkat chagui), patada hacia atrás (tuit chagui), patada en arco con giro de 180 grados (furio chagui), patada descendente (chiko chagui) etc. tiene a su vez variaciones según la altura de ejecución, y su trayectoria, sea con giro y palanca (mondollyo), en salto (tuio), o con giro de 180 grados (furio), etc. Dentro del arte del Taekwondo se incluyen los golpes a corta distancia con las rodillas (murup) y tibias (jeong-gang).

Además de las dos técnicas básicas de puño rectilíneo (baro jirugi y bandae jirugi). Las diversas técnicas de puño difieren según la trayectoria: directa o rectilínea (jirugi), golpes indirectos (chigui), golpes que penetran (tsirugi), y golpes de mano abierta (son). Se debe tener en cuenta la superficie del puño con la que se golpea. Algunos golpes de puño no comunes son: reverso del puño (dung chumok), y el puño martillo (me chumok); además se toma en cuenta la dirección del golpe (hacia arriba, al medio, puño frontal, puño circular, etc.). Las técnicas de mano abierta (son), se diferencian según la orientación de la misma (en un plano horizontal o vertical) y se clasifican según la parte de la mano con la que golpeamos: golpe de mano "sable" o con el borde cubital (Sonnal), golpe con el radio (hueso)|borde radial (sonnal dong), golpe de "boca de tigre" (Agwison), etc. Los golpes que penetran se llaman (tsirugi), ejemplos de estos son: golpe de "mano cuchillo" (pyonsonkkeut), o con la punta de los dedos, o el golpe con las puntas de los dedos en forma de tijera (kawisonkkeut), etc. Igualmente dentro del arte del Taekwondo también hay diferentes tipos de superficies articulares menos usadas como, los golpes con el codo (palkup), y golpes con la cabeza (jong).

En Taekwondo se manejan una gran variedad de técnicas de defensa activas, o con el uso de las extremidades superiores o (makki), ejecutadas de formas diferentes, sean bloqueos contundentes o chequeos suaves, e incluso técnicas que atrapan el brazo del oponente y le sujetan para golpearle; estas técnicas se realizan en función de la dirección (por el interior o exterior del ataque) y la altura del ataque (Are- Montong - Olgul) del que se quiera defender. Existen también técnicas de defensa y ataque simultáneo, así como técnicas defensivas a dos brazos hechas de forma simultánea. Estas técnicas pueden realizarse con la palma de la mano, el exterior o el interior del antebrazo, con el borde cubital o radial de la mano, con la punta de los dedos, con el hueso tibial, con la planta de los pies, los puños, etc.

Los bloqueos / chequeos, a pesar de ser un último recurso defensivo (siendo el primero la esquiva, y los desplazamientos) difieren en su ejecución no solo si se trata de bloquear de forma contundente o bien, de desviar el golpe; sino según la naturaleza de la práctica, siendo efectuados de forma larga y hacia adelante en el combate deportivo para evitar choques y lesiones innecesarias. 

Los bloqueos y chequeos fundamentales son realizados con los antebrazos, siendo estos: (Are makki) bloqueo de protección de la zona baja, (Montong bakkat makki) bloqueo de protección del tronco desde el exterior al interior, (yeop bakkat makki) bloqueo de protección del tronco desde el interior al exterior, y (Olgul makki) bloqueo de protección de la zona alta.

Al ejecutar las diversas técnicas, es importante la alineación correcta del cuerpo, el posicionamiento del centro de gravedad y la estabilidad (pies-rodillas-muslos-caderas-torso-hombros-cabeza), ya que permite una transmisión óptima de la potencia y fluidez en las combinaciones, y las transición de la defensa al contraataque. Esto se logra por medio del entrenamiento, perfeccionamiento y conciencia de las posiciones (sogui), las cuales tienen una especial importancia en la ejecución de las formas, sean pumsae o tul, y en la defensa personal como parte de las técnicas, inclusive en la competición moderna, ya que en la modalidad de combate es importante mantener el cuerpo en una postura y guardia correcta para que nuestras técnicas y tácticas sean lo más efectivas posible, evitando un contraataque.

Las posiciones más usadas dentro del arte marcial del Taekwondo son: posición de pies juntos o saludo/inicio (charyot sogui), posición de atención (Moa sogui), posición de vigilancia (naranji sogui), posición normal o de espera (pyeonji sogui), posición del caminante o corta hacia delante (ap sogui), posición hacia adelante larga o de ataque (ap kubi sogui), posición cruzada (tuit koa sogui), posición del jinete (chu chum sogui), posición de la grulla (Akdari sogui), posición del gato (bom sogui), y posición hacia atrás o defensiva (duit kubi sogui).

Al igual que en otras artes marciales clásicas y tradicionales provenientes de oriente, en el Taekwondo como arte marcial no deportivo aún quedan variadas técnicas de defensa personal como: barridos circulares a los pies similares a los del kung fu chino; varios escapes de varios agarres y sujeciones a las muñecas, pecho, tronco, hombro, y cuello, unas pocas luxaciones articulares (en especial dirigidas a la muñeca, codo y hombro, en pie), y algunas proyecciones de cadera, hombro y mano similares a las del Judo, varios golpes a mano abierta y de puño derivados del karate-Do. Además de técnicas influenciadas por el arte coreano nativo del Taekkyon como: atrapes con los pies al cuerpo, cuello, o extremidades del adversario, patadas aéreas simultáneas a dos o más oponentes, patadas con apoyo sobre el contrario y golpes a puntos vulnerables y/o a puntos de presión. Se cree que estas acciones están codificadas en las diferentes formas (pumsae y Tul). Estas técnicas a menudo se combinan con otras, y se trabajan, corrijen y perfeccionan por medio de actividades por parejas. Sin embargo, en el Taekwondo, tanto como arte marcial y como deporte; y a diferencia de otras artes marciales no se instruye en el uso de armas tradicionales (Bō, Nunchaku, Tonfa, Sai (arma), Tambō, etc...), o Kobudo; como si ocurre en la mayoría de estilos de kung fu / Wu-shu chino, y en varios de los estilos de karate provenientes de Okinawa o de Japón, y en otras disciplinas marciales más tradicionales, provenientes de otros países del sudeste asiático.

Aunque los nombres de las técnicas y títulos de los diferentes grados no buscan estar estandarizados debido a la promoción del Taekwondo como deporte olímpico fuera de Corea. Se busca que en cada país, las escuelas locales opten por nombres significativos en su propio idioma, algunas (en especial las escuelas en los EE. UU.) quienes incluso optan por traducir los nombres de las técnicas y de los grados al idioma inglés, dando origen a términos como: "Axe Kick", "Roundhouse Kick", "Side Kick", o "instructor", "master", "grand master", etc. Sin embargo, las federaciones WT o ITF optan por mantener los nombres de las diferentes técnicas en coreano. No obstante, incluso en coreano se pueden encontrar diferentes nombres para la misma técnica según el estilo de taekwondo, sea ITF, o WTF. (por ejemplo: los términos "dollyo chagui" y "tidola bandal chagui" hacen referencia al mismo tipo de patada circular).

Como en el caso de la gran mayoría de las artes marciales modernas, el Taekwondo tomó su uniforme inicial y sistema de grados por cinturones (kyu/gup - Dan), del Karate, quien a su vez lo había adoptado del arte también japonés del Judo en 1930, debido a la amistad entre los maestros Jigoro Kano (el fundador del Judo) y Gichin Funakoshi (el maestro fundador del estilo Shotokan y padre del karate moderno).

Para la práctica del Taekwondo, es necesario un "Dobok" (traje de práctica) y un "Ti" (cinturón que indica el grado del practicante). El Dobok es apenas diferente si se practica Taekwon-do en ITTAF, Taekwon-Do ITF o Taekwondo WT, pero en todos los casos está compuesto por un pantalón y una chaqueta que puede ser abierta (ITF e ITTAF), o cerrada con el cuello en forma de V (WT). Cada uno de ellos lleva escudos o logos, según las normas de vestimenta en cada federación.

En WTF, dependiendo de la federación, se puede dar uno de los siguientes casos respecto a los Dobok para los grados inferiores o GUP:
Los uniformes o Dobok para grados DAN (cinturones negros) tienen zonas negras, que pueden ser el cuello, los bordes de la chaqueta, bandas en el pantalón, etc. Esto depende de la federación, la escuela y el practicante. Además, a veces cuenta con uno o varios bordados en la espalda y algún logotipo en el pecho, brazo o piernas. Es común que los cinturones negros se borden en dorado, con los caracteres en "hanja" de Taekwondo, el nombre de la escuela, el del practicante o similares.

Los Dobok en ITTAF son un tanto diferentes, la chaqueta es abierta lleva del lado izquierdo el logo de la Federación Internacional de Taekwon-do Tradicional, en la espalda se lleva el logo vertical, que son las palabras Taekwon-do tradicional, el bordado en el pantalón que dice Taekwondo en coreano, es de color gris que simboliza el equilibrio perfecto entre el negro y el blanco. Existen algunas diferencias entre los dobok de ITTAF que son de acuerdo al grado que tiene el practicante, el uniforme que deben utilizar los de grado menor a Cinturón Negro es gris, al graduarse de Cinturón Negro 1, 2 y 3 Dan el uniforme lleva en el faldón de la chaqueta la orilla negra, y al graduarse como Cinturón Negro 4 Dan llevará la orilla negra en el faldón y en la parte lateral externa de los brazos y piernas.
En competiciones, es necesario contar con las protecciones reglamentarias (establecidas por la federación que organiza la competición), para minimizar los riesgos de lesión. Sin embargo, a la hora de practicar en el Dojang, no suele ser necesario, a menos que se haga un entrenamiento específico de combate de contacto.
Es muy recomendable que el Dojang, lugar donde se practica el taekwondo tenga una superficie/ suelo apenas acolchado (estera, tatami o piso de goma EVA) ya que en la práctica se ejecuta una gran variedad de saltos, y es muy frecuente que al realizar algunas técnicas de patadas se pierda el equilibrio y se den caídas, o resbalones (razón por la cual se está entrenando cada vez más desde el inicio de la práctica deportiva, los diferentes rodamientos y/o caídas estáticas, para caer bien, y evitar lesiones). Sin embargo, el excesivo grosor de esta superficie no es necesario como ocurre en otros deportes de combate y/o artes marciales tradicionales, las cuales hacen mucho más énfasis en técnicas de lanzamiento, derribo y/o lucha en el suelo como: la Lucha libre olímpica, el Judo, el jiu-jitsu (japonés tradicional o brasileño), el Aikido, el sambo o en artes marciales híbridas modernas (o que contienen elementos de varias artes tradicionales) como el Hapkido, o el kajukenbo, o en modalidades deportivas como las artes marciales mixtas.

Es importante mencionar los equipos auxiliares para el entrenamiento y práctica del taekwondo, estos son los "foot mitts" o paletas/ focos para pies, hechos de cuero o material sintético que pueden ser sencillos o dobles, los escudos o "paos" que también son hechos de cuero o material sintético con agarraderas para sujetarlos a una o dos manos, el saco de golpear, los guantines para las manos o "hand pads"; y los protectores de antebrazos, protector inguinal, protectores de tibias y empeineras, además del casco, y del chaleco o "peto", del cual hay dos colores azul o rojo, sea tradicional hecho en cuero o lona, y/o electrónico, que registra los impactos. El taekwondo puede practicarse descalzo o con calzado especial, hecho de materiales suaves y cómodos, dependiendo de la escuela, aunque lo recomendable es descalzo, para acostumbrar los pies a los impactos, y evitar lesiones, de tobillo sobre todo, al no realizar bien alguna patada al usar tenis especiales.

Los grados Kup (o GUP, según el país en el que se lo trata) son los grados más básicos del taekwondo. Siguen una numera

Los niveles o grados de instrucción en el Taekwondo, están dados por el color de los cinturones de cada practicante, variando estos desde el color blanco, hasta los distintos niveles de negro. Estos niveles se dividen en grados "KUP" (o "GUP", según el país en el que se lo trata) y grados "DAN". Los grados "KUP" son los denominados cinturones de colores, los cuales varían desde el blanco hasta el rojo de punta negra, mientras que en los grados "DAN" se encuentran encasillados todos los niveles de cinturón negro. Por cada grado "KUP" corresponde una sola rutina de movimientos denominada "tul", mientras que por cada grado "DAN" se corresponden 3 "tules", hasta el grado de 6º DAN. La lista de graduaciones establecida por la Federación Internacional de Taekwondo es la siguiente:

En Taekwondo ITF, como condición de graduación para los grados "DAN" es necesario llevar cada graduación, en un período equivalente al número de dicha graduación, es decir 1 año como 1º DAN, 2 años como 2º DAN, 3 años como 3º DAN y así. 

Para el caso de obtener 4º DAN, además del período de portación del título, es necesario que el practicante esté al frente de una clase, ya que a partir de esta graduación comienza a formarse como instructor titular, al mismo tiempo, debe homologar exámenes de graduación de grados "KUP". 

El 7º DAN es la última graduación de cinturones negros que se otorga a través de examen evaluatorio. A partir de allí, los grados 8º y 9º son títulos entregados de forma honorífica, para cuya entrega es necesaria la evaluación de un tribunal especial, quienes evalúan la trayectoria del aspirante y su trabajo en favor de la difusión de la disciplina. El hecho de que el 9º DAN sea el máximo título al que un practicante puede aspirar, se debe a la consideración por parte de la cultura coreana al número 9, como el máximo valor en los números de un solo dígito. El número 9 es múltiplo directo del número 3, considerado en la cultura coreana como el número que representa los tres niveles de existencia: El Cielo, la Tierra y el Hombre entre medio de ellas. Por otra parte, el número 10 es utilizado en la graduación del cinturón blanco (10º KUP), por ser considerado como el menor número de dos y más de una cifra.

En cuanto al traje homologado por ITF, el mismo es un "dobok" (nombre en coreano del conjunto), compuesto de una chaqueta blanca con el logotipo de ITF en la parte delantera, a la altura del corazón y el dibujo del Árbol del Taekwondo en la espalda, en gráfica de color negro, y un pantalón blanco, con las siglas ITF en ambas piernas. Este traje incorpora detalles en el caso de los practicantes de grado DAN, ya que se agregan tiras en color negro, tanto en brazos y solapa baja de la chaqueta, y tiras negras en ambas piernas del pantalón. El traje de los grados DAN incorpora charreteras en sus hombros, que también indican el nivel de instructurado de cada practicante, siendo estas de forma cuadrada y de color amarillo oro, las cuales según el grado de instructorado se le asigna una determinada cantidad de insignias, en forma de listones. Estos listones varían de uno para los tres grados menores de DAN, a cuatro para el rango de Gran Maestro. Estos cuatro listones son de cuatro colores indicativos: Blanco, negro, rojo y turquesa. Dichos símbolos se detallan a continuación:

En la WTF los colores de los cinturones son:

En el WT, el sistema de graduaciones de los Grados DAN, es similar al impuesto por ITF, debiendo ejercerse cada graduación por un período equivalente al número de rango en el que el practicante se encuentre. Asimismo, a partir del 5º DAN, los títulos de 6°, 7°, 8º y 9º DAN son entregados de forma honorífica, para lo cual se requiere la evaluación de la trayectoria del practicante, por parte de un tribunal. Por otra parte, a diferencia de las graduaciones ITF, WT reserva el título de 10º DAN como una distinción honorífica entregada a título póstumo, o bien cumpliendo una serie de exigencias impuestas por Kukkiwon.

La disciplina Universal Taekwon-do DEAMYDC (U.T.D.) del Departamento Español de Artes Marciales y Deportes de Contacto DEAMYDC, es una disciplina que ha unido tanto a I.T.F. y W.T.F. así como algunas disciplinas menos conocidas del Taekwondo para practicarlo universalmente.

El Departamento Español de Artes Marciales y Deportes de Contacto DEAMYDC es una entidad, la cual posee ámbito Nacional, estando registrado en España en el Ministerio del Interior con el nº de Registro Nacional 607.327, así como son reconocidos por la Federación Española de Artes Marciales y Deportes de Contacto FEAMYDC .

En U.T.D. los cinturones ordenados de más inexperto a más experto son :

Estos siete colores originales no fueron elegidos arbitrariamente, sino que cada uno tiene un significado simbólico y tradicional.

Actualmente, la mayoría de las federaciones han variado estos colores, añadiendo algunos intermedios o sustituyendo alguno de los existentes. En algunas federaciones americanas, existen dos colores más de cinturón (morado y marrón). En algunas federaciones de España (por ejemplo, la madrileña) se ha añadido el cinturón marrón por el rojo. Sin embargo, el cinturón de 1º GUP, así como los cinturones de grados PUM mantienen el color rojo-negro.

En el caso de la WTF, por lo general, los grados KUP intermedios solo se otorgan a practicantes de menos de 15 años. Los practicantes de más de 15 años, normalmente, obtienen directamente el grado superior sin pasar por el cinturón intermedio. No obstante, esto puede depender del dojang donde se practique. En el caso de la ITF, el paso por los cinturones intermedios es obligatorio, aunque en caso de alumnos muy destacados, tienen la posibilidad de presentarse a dos cinturones en un mismo examen, siempre con autorización del instructor. En la WTF también se utiliza este método, pero eso depende del instructor.

En niños, después de superar el grado de cinta amarilla avanzada, se le otorga en el cuello el color de su grado más su cinta al practicante.

Los grados DAN están asociados al cinturón negro. El orden de numeración de los DAN sigue un orden inverso al de los GUP. Así, un practicante que acabe de avanzar a cinturón negro será 1º DAN, e irá avanzando a 2º DAN, 3º DAN y así consecutivamente hasta 9º DAN. En la WTF, existe además el 10º DAN como un grado honorífico que han recibido muy pocas personas, y lo han hecho de forma póstuma en reconocimiento a su labor a favor de la masificación del Taekwondo. Se otorga únicamente a personas cuya labor en el taekwondo ha sido de vital importancia para el desarrollo del mismo.

Los requisitos para la obtención de grados DAN están mucho más estandarizados que los de los grados GUP. El cinturón de los grados DAN puede ser completamente negro, tener una banda (generalmente dorada, roja, blanca o plateada) en el extremo por cada nivel DAN que el practicante haya adquirido, o llevar bordado el grado de DAN en números romanos. Por ejemplo, un cinturón de 5º DAN puede tener 5 bandas en el extremo o la inscripción V DAN.

Tanto en Taekwondo ITF como en WTF, la edad mínima para ostentar un grado DAN (cinturón negro) es de 18 años. Los practicantes con menos de 18 años en su lugar pueden aspirar a los grados PUM que son el equivalente a los grados DAN para los practicantes más jóvenes.

En el caso del Taekwondo ITF, aquel practicante que alcance un título en grado PUM, se distingue de los grados DAN por llevar un cinturón negro con una línea intermedia de color blanco. Esa línea representa la falta de madurez del practicante como ser humano, más allá de sus conocimientos adquiridos en la materia. Asimismo, su grado de autoridad se encuentra por encima de los grados KUP, y por debajo de los grados DAN, a pesar de su equivalencia con este rango. Para el caso del Taekwondo WTF, es empleado un cinturón bicolor del cual una mitad es negra y la otra roja. Asimismo, existen dobok con detalles en rojo y negro, que son el equivalente a los dobok con detalles negros de los grados Dan.

Para que un alumno pueda ascender a un grado superior, ha de realizar un examen en el que se evalúan sus habilidades técnicas, tácticas, condición física, de combate, además de su potencia y control (por medio de las técnicas de rompimiento). En las federaciones asociadas a la WT los exámenes de grados KUP se realizan en el propio Dojang donde el alumno entrena, y el examinador debe ser un maestro 4º Dan o superior.

Los exámenes de grados GUP de la ITF no siempre se realizan en el dojang donde entrena el alumno. Es obligatoria la presencia de al menos un instructor con grado 4° DAN o superior que debe ser 6º DAN, que suele estar asistido por otros de graduaciones menores (normalmente por los instructores de los alumnos a rendir). Estos evalúan a los alumnos, decidiendo si tienen o no las cualidades necesarias para la nueva graduación.

El tiempo necesario para poder examinarse de un grado GUP superior no está regulado como en el caso de los grados DAN. En algunos lugares el maestro puede proponer un alumno para examen en cualquier momento en función de sus habilidades. En otros lugares, los exámenes se hacen en fechas fijas cada varios meses para todos los alumnos.

Los exámenes de grados DAN están más regulados, ya que en ellos no solo se examinan habilidades mucho más exigentes y precisas (posiciones, formas, técnicas de mano y pierna, movimientos ondulantes, cruces de muñeca, etc.) que en los exámenes de grados GUP; también se exige un mayor grado de conocimiento teórico sobre historia, biomecánica y filosofía del Taekwon-do. Las tasas, o tarifas de examen son asimismo más caras que para los grados GUP, y el tiempo necesario para poder examinarse de un grado DAN superior está establecido, y va aumentando según aumenta el grado al que se pueda presentar.

Los requisitos para poder acceder a los grados DAN varían en función de la federación a la que estemos asociados. Generalmente se requiere haber practicado taekwondo (estando federado) durante un tiempo mínimo (3 o 5 años), práctica constante, y haber ostentado el grado GUP más alto (cinturón rojo o marrón según la federación) durante un año como mínimo. Otro posible requisito es haber participado en un número mínimo de competiciones o estar en posesión de algún título relacionado con la práctica deportiva, como el de juez cronometrador o árbitro.

Estos exámenes deben ser fiscalizados por al menos un maestro (7° u 8° Dan) o gran maestro (9° Dan).
Para la promoción de grados DAN más avanzados, es necesario presentar una tesis teórica relacionada con el Taekwondo.

La filosofía del Taekwondo se basa en cinco principios derivados de las filosofías chinas del confucionismo, y el taoísmo; influenciadas en gran parte por el inmenso nacionalismo coreano; estos principios son: cortesía, integridad, perseverancia, autocontrol y espíritu indomable. Además, los valores de Amor fraternal, y Ciencia son parte de en la formación infantil.

Es un principio fundamental dentro y fuera del Taekwondo, que tiene como objetivo hacer destacar al ser humano manteniendo una sociedad armoniosa. Los practicantes de Taekwondo deben construir un carácter noble, así como entrenar de una manera ordenada y disciplinada.

Es muy importante saber establecer los límites entre lo bueno y lo malo así como saber reconocer cuando se ha hecho algo malo y redimirse por ello. Por ejemplo, en un estudiante que se niega a recibir consejo o aprender de otro estudiante más experto, o en un practicante que pide un grado no merecido a su maestro no hay integridad.

La felicidad o la prosperidad suelen ser alcanzadas por la persona que es paciente. Para poder alcanzar un objetivo, ya sea promocionar a un grado superior o perfeccionar una técnica, se ha de ser perseverante. Es fundamental el sobrepasar cada dificultad con la perseverancia.

El autocontrol es de vital importancia tanto dentro como fuera del dojang, tanto en el combate como en los asuntos personales. Un buen practicante de Taekwondo no permitirá que la ira, la tristeza o el miedo dominen su accionar. En combate, la falta de autocontrol puede provocar graves consecuencias tanto para el alumno como para su oponente. Asimismo, se ha de ser capaz de vivir y trabajar dentro de las propias capacidades.
Cabe destacar que el alumno no puede ser agresivo dentro o fuera del gimnasio, ni llevar una vida descontrolada (alcohol, drogas...)
Un buen practicante de Taekwondo ha de ser siempre justo, de libre pensamiento, modesto y honrado, sin permitir que corrompan sus valores, sin permitir que sus pensamientos y pasiones sean sometidos por terceros, sin someter a otros, ni inculcarles ideas equívocas o negativas. Mantendrá la confianza en sí mismo. Ante una injusticia, actuará con espíritu combativo, sin miedo, sin dudarlo y sin evitar la confrontación por causa de quién o quienes se haya de enfrentar cuando dicha confrontación sea necesaria.

En el Taekwondo existen dos modalidades de competencia tanto de combate deportivo, y más recientemente (desde el año 2007) de exhibición técnica o formas, al ser considerado un deporte de arte y combate, y no solo una disciplina de semi-contacto.

En las competiciones de técnica, el objetivo es demostrar la correcta ejecución de las diversas técnicas del Taekwondo, incluidas dentro de las formas (pumsae o tules). Los participantes deberán ejecutar las técnicas o las formas requeridas ante un jurado que puntuará su actuación teniendo en cuenta diversos aspectos como el ajuste, el foco, las posiciones, la respiración, los desplazamientos y las diferentes técnicas incluidas en las formas. En ocasiones también se incluye en las competiciones demostraciones de rompimiento de tablones de madera u otros materiales con distintas técnicas de patada, puño o técnicas especiales (que normalmente consisten en patadas con salto en altura).

En septiembre de 2006, se celebraron en Corea los primeros campeonatos mundiales de Pumsaes (formas). Se realizaron categorías individuales, por parejas y tríos. Desde el año 2004 y en vistas a estos primeros campeonatos mundiales ha habido mucho movimiento a nivel mundial para unificar los criterios de ejecución en los cinco continentes y poder disputar estos primeros campeonatos mundiales. Las reestructuraciones en la forma de competir en cuanto a reglamento y ejecución de estos, han sido muy importantes para llegar a este fin.

Los últimos campeonatos mundiales de formas o "pumsae" se realizaron en:

2007: Corea.

2008: Turquía.

2009: Egipto.

2010: Uzbekistán.

2011: Rusia.

2012: Colombia.

2013: Indonesia.
2014: México.

2016: Perú.

2019: China.

En la modalidad de combate los participantes deben enfrentarse en un combate libre reglado en el que deben vencer al oponente consiguiendo más puntos que él, o en algunas ocasiones la pérdida de conciencia o KO. El combate es diferente en los dos estilos de Taekwondo (ITF y WT), siendo las principales diferencias: el grado de contacto, las áreas donde se puede golpear, los puntos a obtener, las superficies de contacto a empleadas al golpear al oponente, y el sistema de puntuación.

Esta es la denominación que se le da a las formas según la ITF. Por cada categoría, empezando desde blanco punta amarilla, existe un tul característico, y por cada cinturón negro o grado DAN hay tres, hasta el 6° DAN.


Esta es la denominación que se le da a las formas según la WT. Por cada grado kup, empezando desde el cinturón blanco existe un pumse característico, y por cada cinturón negro o grado DAN hay varios, hasta el 6° DAN.

Formas básicas e intermedias

- Kibon 1,2, y 3

- 1: teaguk il chang

- 2: teaguk i chang

- 3: teaguk sam chang

- 4: teaguk sa chang 

- 5: teaguk oh chang 

- 6: teaguk yuk chang

- 7: teaguk chil chang

- 8: teaguk pal chang

Formas superiores o avanzadas

- Koryo

- Kumgang

- Taebek 

- Shypchin 

- Chitae

- Chungkwon

- Jansu

- Ilyo

El reglamento de la WT es el que se utiliza en las olimpiadas. Además, la Federación Mundial de Taekwondo se encarga de organizar cada dos años el Campeonato Mundial de Taekwondo.

El combate se divide en 3 rondas ininterrumpidas, con descanso entre ellas. Los participantes que ostentan grados KUP realizan 3 rondas de 1 minuto con 30 segundos de descanso entre ellas, mientras que los grados DAN realizan 3 rondas de 2 minutos con 1 minuto de descanso entre cada una. Es obligatorio que los competidores utilicen un Dobok adecuado, así como un peto protector (llamado hogu) que diferenciará a los dos competidores por su color rojo o azul. También es obligatorio el uso de un casco reglamentario que proteja la cabeza y un protector bucal para los dientes, así como protectores para los antebrazos, espinilleras, protectores para los empeines, taloneras, protección de las rodillas, guantes y protector genital (coquilla).

Resulta ganador el competidor que tras las tres rondas haya sumado más cantidad de puntos, sí su oponente no puede continuar por lesión, decisión médica, o si este excedió la cantidad de faltas, o acciones prohibidas permitidas. También puede ganar por pérdida de la conciencia del oponente o K.O. (Knock Out), que raramente se produce en combates deportivos WT (cuando uno de los combatientes cae y tras la cuenta de diez segundos el competidor no se levanta del tapiz). Anteriormente existía una regla que dictaba la eliminación del competidor en caso de que perdiera por diferencia de 7 puntos o más. Esta regla ha sido cambiada, ya que actualmente la diferencia es de 12 y está es dada al final del segundo asalto o en cualquier momento del tercero.

Puntúa cualquier ataque de patada o puño que golpee con fuerza el peto protector (hogu) o cualquier ataque de patada que golpee con fuerza la cabeza o en raras ocasiones la parte superior de la tráquea. Los ataques deben hacer contacto total con la zona adecuada del adversario y llevar fuerza suficiente como para causar desplazamiento del cuerpo o la cabeza. No se permiten ataques de puño a la cabeza ni ataques por debajo de la cintura.

Las patadas al peto protector puntúan 2 puntos, 4 puntos en el caso de que sea efectuada mediante un giro, mientras que los ataques a la cabeza valen 3 puntos y 5 cuando son efectuadas con giro. Hasta hace poco los ataques con giro no tenían puntuación especial, hasta el año 2001 se daba 1 punto parejo a cada patada, fuera al peto o a la cara, en el año 2002 las patadas a la cara empezaron a dar 2 puntos, así hasta llegar a la puntuación actual. También se sumaba un punto "de cuenta de protección" si un ataque había aturdido al oponente. Estas últimas medidas se eliminaron hace poco. Los puñetazos se limitan tan solo al peto, y deben ser efectuados de abajo hacia arriba acabando el golpe en el peto, que dado el caso, valdrá solo un punto. En caso de KO, el atacante gana el combate.

Desde el año 2009 el sistema de puntuación se lleva mediante unos petos electrónicos, que suben al marcador los impactos recibidos. Hasta hace poco se crearon los cabezales electrónicos los cuales funcionan de la misma manera que el peto. 
Desde el año 2017 se aprobó solamente una sola penalización, el "Gam-Jeon" que si es efectuado en alguno de los competidores será un punto para el rival. El Gam-Jeon se efectúa cuando: Se intenta evadir un ataque dando la espalda al adversario; ataques por debajo de la cintura repetidamente; intentar lesionar al contrincante. Atacar al oponente cuando la ronda ha acabado; atacar a un oponente derribado; golpear intencionadamente la cara del adversario con la mano, caerse al suelo, pasar los brazos del lado del contrincante, pasar la pierna por el lado del contrincante.

Si le cobran a uno de los competidores 10 Gam-Jeon será automáticamente descalificado.

Para las competiciones de combate, existen diferentes categorías según el grado, peso y la edad de los competidores. El reglamento de lucha, es similar al "full contact", aunque el Taekwondo ITF es eminentemente "light contact"

El combate se lleva a cabo en un cuadrilátero de 8 X 8 m sin cuerdas ni delimitación física (al contrario que los rings de boxeo) Dependiendo de la categoría y el nivel de la competición, se pueden realizar de 1 a 3 rondas de entre 1 y 3 min, resultando ganador el competidor que al final de las tres rondas sume más puntos.

Los puntos son contados por cuatro jueces que se ubican en una esquina del cuadrilátero cada uno. El sistema de puntuación es el siguiente:
Solo se permite golpear la parte frontal del cuerpo (desde la cintura a la parte inferior del cuello) y de la cabeza. Se penaliza el acto de golpear intencionadamente al oponente en la espalda o la parte trasera de la cabeza. No se permite golpear con la rodilla, la tibia o el codo (solo si es con la parte inferior).

Los golpes pueden ser ejecutados con la máxima potencia, no deben tener intención de KO. En caso de que este hecho se produjese fortuitamente durante el combate, el presidente de mesa debe decidir si el competidor que lo llevó a cabo debe ser descalificado o no.

No se permiten agarres, barridos, luxaciones ni proyecciones. No se toleran actitudes o gestos irrespetuosos, provocativos, ofensivos o agresivos hacia otros competidores, golpes fuera de tiempo (cuando el árbitro dice que se detenga la pelea).

En el caso de que un competidor cometa una infracción, el árbitro central detiene el combate y el infractor recibe un aviso. Tres avisos suponen la deducción de un punto al finalizar el combate. Ante una infracción de mayor gravedad, el árbitro puede descontar puntos directamente o incluso descalificar a un competidor.

Es obligatorio utilizar algunas protecciones establecidas por la federación o asociación que organice el combate. Normalmente se requiere el uso de guantes de polipropileno para los puños (llamados "pads"), así como botas protectoras con taloneras del mismo material para los pies. También suele ser obligatorio el uso de protector bucal y protector inguinal. El uso de rodilleras es opcional. En función del nivel de los participantes, se puede utilizar (aunque no es lo habitual) casco y peto protector, tibiales y protectores de antebrazos.



</doc>
<doc id="6838" url="https://es.wikipedia.org/wiki?curid=6838" title="14 de mayo">
14 de mayo

El 14 de mayo es el 134.º (centésimo trigésimo cuarto) día del año en el calendario gregoriano y el 135.º en los años bisiestos. Quedan 231 días para finalizar el año.



























</doc>
<doc id="6843" url="https://es.wikipedia.org/wiki?curid=6843" title="Aries (constelación)">
Aries (constelación)

Aries (el carnero) es una de las constelaciones del zodíaco; se encuentra entre las constelaciones de Piscis, al oeste, y Tauro al este.

α Arietis, conocida como Hamal, es el astro más brillante con magnitud 2,01. Es una gigante naranja cuyo radio, como corresponde a una estrella de sus características, es casi 15 veces más grande que el radio solar. En 2011 se detectó la presencia de un planeta —con una masa al menos 1,8 veces la de Júpiter— en órbita alrededor de esta estrella.

La segunda estrella más brillante de Aries es Sheratan (β Arietis), binaria espectroscópica formada por una estrella blanca de la secuencia principal y una enana amarilla semejante al Sol. La órbita de esta binaria es notablemente excéntrica (ε = 0,88), lo que provoca que la separación entre ambas estrellas varíe entre 0,08 ua (un 20% de la distancia entre Mercurio y el Sol) y 1,2 ua (un 20% más de la distancia entre la Tierra y el Sol).
Le sigue en brillo 41 Arietis, una estrella de tipo espectral B8V, 126 veces más luminosa que el Sol. No posee denominación de Bayer, ya que en el pasado formaba parte de la constelación de Musca Borealis, hoy descartada, siendo su estrella más brillante.

Aries contiene varias estrellas dobles interesantes, entre las que destacan γ Arietis, ε Arietis y λ Arietis.
γ Arietis, conocida como Mesarthim, está compuesta por dos estrellas blancas que emplean más de 5000 años en completar una órbita alrededor del centro de masas común. Una de las componentes es una estrella Ap y variable Alfa2 Canum Venaticorum.
Por su parte, las dos componentes de ε Arietis son estrellas de tipo A3V cuyo período orbital, que no es bien conocido, puede ser de 1220 años; una enana naranja, mucho más alejada, parece formar parte también de este sistema estelar.
Finalmente, λ Arietis es una binaria amplia constituida por una estrella de la secuencia principal (de tipo A7V o F0V) y una enana amarilla semejante al Sol. La separación entre ambas estrellas es igual o superior a 1480 ua.

Entre las variables de la constelación se encuentra TT Arietis, una de las más peculiares del cielo nocturno. Clasificada como variable cataclísmica, es un sistema binario donde la componente primaria es una enana blanca caliente acompañada por una estrella mucho más fría de tipo espectral M3.5.
Se piensa que la superficie de la enana blanca se calienta por un elevado ritmo de acreción, llegando a alcanzar una temperatura próxima a los 80 000 K. El período orbital del sistema es de sólo 3,3 horas.

Aries también contiene dos enanas rojas —la Estrella de Teegarden y TZ Arietis— que se cuentan entre las 40 estrellas más próximas al Sistema Solar. En el momento de su descubrimiento (2003), la paralaje de la Estrella de Teegarden fue medida como 0,43 ± 0,13 segundos de arco, lo que la situaba a sólo 7,8 años luz, siendo por tanto la tercera estrella más cercana a nuestro Sistema Solar.
Sin embargo, estudios posteriores sitúan a esta tenue enana roja a 12,5 años luz de distancia.

En lo concerniente al espacio profundo, en Aries se encuentran las galaxias NGC 772 y NGC 1156. NGC 772 es una galaxia espiral sin barra que posee un bulbo prominente; el brazo principal, en el lado noroeste de la galaxia, contiene numerosas regiones de formación estelar.
NGC 1156 es una galaxia enana irregular de tipo «magallánico» (en referencia a las Nubes de Magallanes) que tiene magnitud aparente 12,3.




Frixo y Hele son hijos de Atamante, rey de Tesalia, y de Néfele. Tras quedar viudo, Atamante vuelve a casarse con Ino. Años después el reino sufre una etapa de hambruna y la reina decide sacrificar a los hermanos para terminar esta aciaga época. Hermes salva a los niños entregándoles un carnero alado, con la lana o vellocino de oro, y dotado del don de la palabra. Los niños parten sobre él rumbo a Asia, salvándoles la vida. Durante el viaje Hele cae al mar y se ahoga, dando su nombre a esa región marina, que pasará a llamarse Helesponto. Frixo llega a la Cólquida, cuyo rey Eetes lo acoge y le concede en matrimonio a su hija Calcíope.

En agradecimiento a Eetes, Frixo sacrifica al carnero y le ofrece el vellocino al rey, quien lo consagra a Ares y lo cuelga de una encina en un bosque dedicado al dios, guardado por un descomunal dragón y rodeado por campos donde pastan enormes toros salvajes. En agradecimiento Zeus colocó a Aries en el cielo nocturno.

Según algunos, Aries es una constelación de poco brillo porque el vellocino de oro del cordero se quedó en la Cólquida.





</doc>
<doc id="6852" url="https://es.wikipedia.org/wiki?curid=6852" title="Océano">
Océano

Se denomina océano a una gran extensión de agua en el planeta Tierra, sobre todo aquella que «separa dos o más continentes». Los océanos forman la mayor parte de la superficie del planeta. 

Los océanos se clasifican en tres grandes: Atlántico, Índico y Pacífico; y dos menores: Ártico y Antártico, delimitados parcialmente por la forma de los continentes y archipiélagos.

Los océanos Pacífico y Atlántico a menudo se distinguen en Norte y Sur, según estén en el hemisferio Norte o en el Sur: Atlántico Norte y Atlántico Sur, y Pacífico Norte y Pacífico Sur.

Los océanos cubren el 71% de la superficie de la Tierra, siendo el océano Pacífico el mayor de todos.

La profundidad del océano es variable dependiendo de las zonas del relieve oceánico, pero resulta escasa en comparación con su superficie. Se estima que la profundidad media es de aproximadamente 3900 metros. La parte más profunda se encuentra en la fosa de las Marianas alcanzando los 11034m de profundidad.

La tabla siguiente resume algunas características de los 5 océanos. 

En los océanos hay una capa superficial de agua templada (12 °C a 30 °C) que llega hasta una profundidad variable según las zonas, de entre unas decenas de metros hasta los 50 o 100m. Por debajo de esta capa el agua tiene temperaturas de entre 5 °C y –1 °C. Se llama termoclina al límite entre las dos capas. El agua está más cálida en las zonas templadas, ecuatoriales y más fría cerca de los polos. Y, también, más cálida en verano y más fría en invierno.

Hasta hace poco, se pensaba que se habían formado hace unos 4000 millones de años, tras un periodo de intensa actividad volcánica, cuando la temperatura de la superficie del planeta se enfrió hasta permitir que el agua se encontrara en estado líquido. Aunque la polémica continúa, un estudio del científico Francis Albarède, del Centro Nacional de la Investigación Científica de Francia (CNRS), publicado en la revista "Nature" estima que su origen se halla en la colisión de asteroides gigantes cubiertos de hielo que chocaron contra la Tierra entre 80 y 130 millones de años después de la formación del planeta. Se cree que el agua, por ser sustancia universal, está desde que el planeta se estaba formando y luego llegó en más cantidad desde el cinturón de asteroides, y no de la nube de Oort como antes se creía, ya que en esta última zona hay mayor concentración de deuterio (formando agua pesada) comparada con la que existe en la tierra. Este hecho se vio confirmado en los análisis directos que se hicieron de los cometas procedentes de la nube de Oort, como por ejemplo el último a cargo de la sonda Rosetta.

Contiene sustancias sólidas en disolución, siendo las más abundantes el sodio y el cloro que, en su forma sólida, se combinan para formar el cloruro de sodio o sal común y, junto con el magnesio, el calcio y el potasio, constituyen cerca del 90% de los elementos disueltos en el agua de mar. Además hay otros elementos pero en cantidades mínimas.

La temperatura del agua de los océanos varía en función de una cantidad de parámetros, entre los que se destacan: la latitud; la presencia de corrientes marinas; la profundidad; etc.

El programa Argo ha desplegado más de 3000 flotadores en los océanos para registrar la salinidad y temperatura de la capa superficial de los océanos. Cada uno de los flotadores está programado para hundirse a 2000 metros de profundidad, y se mantendrá a la deriva a esa profundidad durante 10 días aproximadamente. Posteriormente, el flotador emergerá de vuelta hacia la superficie midiendo continuamente la temperatura y salinidad. Una vez que el flotador llega a la superficie, los datos son enviados a un satélite, para que los científicos y el público tengan acceso a esta información sobre el estado de los océanos unas horas después de la captura de los datos.

La salinidad depende de la cantidad de sales que contiene. Aproximadamente una media del 3,5% de la masa del agua, corresponde a sustancias en disolución. Si hay mucha evaporación, desaparece una mayor cantidad de agua, quedando las sustancias disueltas, por lo que aumenta la salinidad.

Ésta es escasa en las regiones polares, en especial en el verano cuando el hielo se diluye en el agua. En mares como el Báltico, también hay poca salinidad.

Cabe destacar que en su gran extensión, el océano presenta todos y cada uno de los elementos químicos naturales existentes, bien sea por escorrentía de estos en los continentes o reservas existentes en él.

La mayor parte del agua en la Tierra, el 94%, se encuentra en los océanos, de la que se evapora una mayor cantidad de agua pura que aquella que retorna en forma de precipitaciones. El volumen de agua de los océanos permanece inalterable ya que estos reciben agua a través de los ríos.

También el agua de los océanos es salada por la erupción de volcanes submarinos. La roca volcánica aporta sales.

En el agua, disueltos, existen prácticamente todos los elementos, en una cantidad ínfima, pero que al tener un volumen tan colosal los océanos, constituyen unas reservas de materias primas inagotables, aunque, a excepción del cloruro de sodio (la sal común), ofrece poca rentabilidad su extracción. Esos elementos, en orden decreciente, son los siguientes (entre paréntesis el contenido en gramos por litro): 1.º Cloro (19); 2.º Sodio (10.5); 3.º Magnesio (1.35); 4.º Azufre (0.885); 5.º Calcio (0.400); 6.º Potasio (0.380); 7.º Bromo (0.065);... 39.º Plata (0.000 000 3);... 57.º Oro (0.000 000 004).

Una forma de pensar común es que el agua de los océanos es azul debido principalmente a la reflexión del color azul del cielo. En realidad el agua posee por sí misma un ligero color azul cuando se almacena en grandes cantidades. La reflexión del cielo contribuye a que el agua se vea azul pero no es la principal razón. El origen se debe a la absorción por las moléculas de agua de los fotones «rojos» provenientes de la luz incidente, siendo uno de los pocos casos en la naturaleza producidos por la vibración y la dinámica electrónica.

Raramente el agua de mar se encuentra quieta, se mueve en olas, mareas o corrientes. Las olas se deben al viento que sopla sobre la superficie. La altura de una ola está dada por la velocidad del viento, del lapso en que ha soplado y de la distancia que ha recorrido la ola. La ola más alta registrada fue de 64 metros, pero generalmente son mucho más bajas. Desempeñan un papel fundamental en la formación de las costas.

Son un tipo de olas cuyo origen son los terremotos, maremotos o la erupción de volcanes submarinos. Desplazan grandes cantidades de agua con gran rapidez modificando la superficie del mar y creando olas que se alejan de la zona del terremoto o del volcán. Llegan a viajar a 750 km/h. En mar abierto provocan pocos daños, ya que tienen poca altura (menos de 1 metro). En aguas poco profundas disminuye su velocidad pero aumenta su altura hasta los 10 metros o más y suelen causar daños catastróficos al llegar a la costa.

Las mareas son provocadas por la atracción gravitatoria que ejercen la Luna y el Sol. La atracción es mayor en la cara de la Tierra que está frente a la Luna, provocando una pleamar o marea alta. El Sol, por estar a una mayor distancia, produce un menor efecto que la Luna. Estas pueden llegar a ser causas de inundaciones en poblaciones costeras.

Se denominan mareas vivas a los momentos en los cuales se produce la máxima atracción, y se forman cuando la Luna, el Sol y la Tierra se encuentran sobre la misma línea, es decir, durante las fases de Luna Llena o de Luna Nueva, por lo que se producen cada 14 días, es decir, dos veces cada mes.

Son mareas menos intensas que se producen cuando la Luna y el Sol forman un ángulo recto con la Tierra, porque las atracciones de ambos, al ser en direcciones opuestas, se restan entre sí en vez de sumarse. Desde luego, a pesar de su menor tamaño, la atracción de la Luna es superior por encontrarse más cerca. Estas mareas se producen en las fases de Cuarto Creciente y Cuarto Menguante.

Es la diferencia entre los niveles de pleamar y bajamar, que varía según el lugar, desde menos de 1 metro en el mar Mediterráneo y el golfo de México, a 14,5 metros en la bahía de Fundy, en la costa oriental de Canadá.

Las corrientes marinas próximas a la superficie de los océanos son impulsadas por los vientos, que las arrastran con ellos. Se desplazan a menor velocidad que el viento y no tienen la misma dirección que ellos, ya que se tuercen hacia un lado por efecto de la rotación de la Tierra o fuerza de Coriolis. Cambian de dirección hacia la derecha de su trayectoria en el hemisferio boreal y hacia la izquierda en el hemisferio austral

Las corrientes tienen una influencia importante en el clima, por ejemplo, la corriente del Golfo o corriente Gulf Stream, que nace en el Caribe, proporciona a la zona noroeste de Europa unos inviernos más benignos.

Las 28 corrientes oceánicas son:

En oceanografía es un gran sistema de corrientes marinas rotativas, particularmente las que están relacionadas con grandes movimientos del viento. Los giros son causados por el efecto de efecto Coriolis; a lo largo del vórtice planetario con fricción horizontal y vertical, que determina el patrón de circulación para el bucle de viento (torque).

Existen cinco grandes giros, dos en el norte y dos en el sur para el océano Pacífico y el Atlántico, respectivamente, y uno para el océano Índico. También existen otros: los giros tropicales, los giros subtropicales y los giros subpolares.

Se ha comprobado que en los giros del Atlántico y Pacífico norte existe gran acumulación de desechos marinos flotando a la deriva. Se conocen como la gran mancha de basura del Pacífico norte y la mancha de basura del Atlántico Norte.

Los principales accidentes oceánicos son:

Los océanos de la Tierra también desempeñan un papel vital en limpiar la atmósfera, y algunas actividades del hombre pueden alterarlos severamente. Los océanos absorben enormes cantidades de dióxido de carbono. A su vez, el fitoplancton absorbe el dióxido de carbono y desprende oxígeno. George Small explica la importancia de este ciclo de vida: «El 70% del oxígeno que se añade a la atmósfera cada año proviene del plancton que hay en el mar». No obstante, algunos científicos advierten que el fitoplancton pudiera disminuir gravemente debido a la reducción del ozono en la atmósfera, de lo cual se cree que el hombre es responsable.

Algunos países acceden a limitar los desechos que permiten que se arrojen al mar, otros rehúsan hacerlo. El famoso explorador oceánico Jacques Cousteau advirtió: «Tenemos que salvar los océanos si queremos salvar a la humanidad».

Es significativa la concentración de peces en pequeñas zonas del océano y su escasez en otras partes. Tal como advirtió William Ricker, biólogo de pesca: «El mar no es un depósito ilimitado de energía alimentaria». Y el explorador submarino Jacques Cousteau también advirtió, al regresar de una exploración submarina mundial, que la vida en los océanos ha disminuido en un 40% desde 1950 debido al pescar en demasía y a la contaminación.

El científico marino suizo Jacques Piccard predijo que en vista de la proporción actual de la contaminación, los océanos del mundo quedarían desprovistos de vida en 25 años. Dijo que debido a su poca profundidad, el mar Báltico sería el primero en morir. Después morirían el Adriático y el Mediterráneo, los cuales no tienen corrientes lo suficientemente fuertes para transportar la contaminación. También, el explorador submarino francés Jacques Cousteau dijo que la destrucción de los océanos ya se ha efectuado en un 20-30%. Predijo «el fin de todo en 30 a 50 años a menos que se tome acción inmediata».
Parte de esta contaminación se debe a que la sociedad ha tenido durante siglos el concepto equivocado de que estos tienen una capacidad inagotable para recibir los desechos.

Los océanos cubren 71% de la superficie terrestre, estos están siendo contaminados muy frecuentemente por la actividad humana y la sobreexplotación de los recursos naturales. Se han localizado al rededor de 5 islas de basura con una enorme cantidad de desechos, estas se forman a causa de las corrientes marinas (remolinos naturales), el tamaño de la zona más afectada es de 3.4 millones de km², la cual se encuentra en el océano Pacífico Norte. Los países más contaminantes son China, Indonesia, Filipinas, Tailandia y Vietnam, estos países descargan la mayor cantidad de residuos plásticos al mar que el resto de los países del mundo juntos.



</doc>
<doc id="6853" url="https://es.wikipedia.org/wiki?curid=6853" title="Ernest Rutherford">
Ernest Rutherford

Ernest Rutherford, conocido también como Lord Rutherford (; Brightwater, 30 de agosto de 1871-Cambridge, 19 de octubre de 1937), fue un físico británico nacido en Nueva Zelanda.

Se dedicó al estudio de las partículas radiactivas y logró clasificarlas en alfa (α), beta (β) y gamma (γ). Halló que la radiactividad iba acompañada por una desintegración de los elementos, lo que le valió para ganar el en 1908. Se le debe un modelo atómico, con el que probó la existencia del núcleo atómico, en el que se reúne toda la carga positiva y casi toda la masa del átomo. Consiguió la primera transmutación artificial con la colaboración de su discípulo Frederick Soddy.

Durante la primera parte de su vida se consagró por completo a las investigaciones, pasó la segunda mitad dedicado a la docencia y dirigiendo los Laboratorios Cavendish de Cambridge, en donde se descubrió el neutrón. Fue maestro de Niels Bohr y Otto Hahn.

Su padre, James, de origen escocés era, granjero y mecánico, y su madre, Martha Thompson, nacida en Inglaterra, era maestra, que había emigrado antes de casarse. Ambos deseaban dar a sus hijos una buena educación y tratar de que pudiesen proseguir sus estudios.

Rutherford destacó muy pronto por su curiosidad y su capacidad para la aritmética. Sus padres y su maestro lo animaron mucho, y resultó ser un alumno brillante, lo que le permitió entrar en el Nelson College, en el que estuvo tres años. También tenía grandes cualidades para el rugby, lo que le valía ser muy popular en su escuela. El último año, terminó en primer lugar en todas las asignaturas, gracias a lo que ingresó en la Universidad, en el Canterbury College, en el que siguió practicando el rugby y en el que participó en los clubes científicos y de reflexión.

Por esa época empezó a manifestarse el genio de Rutherford para la experimentación: sus primeras investigaciones demostraron que el hierro podía magnetizarse por medio de altas frecuencias, lo que de por sí era un descubrimiento. Sus excelentes resultados académicos le permitieron proseguir sus estudios y sus investigaciones durante cinco años en total en esa Universidad. Se licenció en Christchurch y poco después consiguió la única beca de Nueva Zelanda para estudiar matemáticas, y cubrió sus gastos el último año trabajando como maestro. Obtuvo de ese modo el título de "Master of Arts" con las mejores calificaciones en matemáticas y física.

En 1894 obtuvo el título de "Bachelor of Science", que le permitió proseguir sus estudios en Gran Bretaña, en los Laboratorios Cavendish de Cambridge, bajo la dirección del descubridor del electrón, J. J. Thomson a partir de 1895. Fue el primer estudiante de ultramar que alcanzó esta posibilidad. Antes de salir de Nueva Zelanda, se comprometió con Mary Newton, una joven de Christchurch. En los laboratorios Cavendish, reemplazaría años más tarde a Thomson.

En primer lugar prosiguió las investigaciones acerca de las ondas hertzianas y sobre su recepción a gran distancia. Hizo una extraordinaria presentación de sus trabajos ante la Cambridge Physical Society, que se publicaron en las "Philosophical Transactions" de la Royal Society, hecho poco habitual para un investigador tan joven, lo que le sirvió para alcanzar notoriedad.

En diciembre de 1895, empezó a trabajar con Thomson en el estudio del efecto de los rayos X sobre un gas. Descubrieron que los rayos X tenían la propiedad de ionizar el aire, puesto que pudieron demostrar que producía grandes cantidades de partículas cargadas, tanto positivas como negativas, y que esas partículas podían recombinarse para dar lugar a átomos neutros. Por su parte, Rutherford inventó una técnica para medir la velocidad de los iones y su tasa de recombinación. Estos trabajos fueron los que le condujeron por el camino a la fama.

En 1898, tras pasar tres años en Cambridge, cuando contaba con 27 años, le propusieron una cátedra de física en la Universidad McGill de Montreal, que aceptó inmediatamente, ya que además la cátedra representaba para él la posibilidad de casarse con su prometida.

Becquerel descubrió por esa época (1896) que el uranio emitía una radiación desconocida, la "radiación uránica". Rutherford publicó en 1899 un documento esencial, en el que estudiaba el modo que podían tener esas radiaciones de ionizar el aire, situando al uranio entre dos placas cargadas y midiendo la corriente que pasaba. Estudió así el poder de penetración de las radiaciones, cubriendo sus muestras de uranio con hojas metálicas de distintos espesores. Se dio cuenta de que la ionización empezaba disminuyendo rápidamente conforme aumentaba el espesor de las hojas, pero que por encima de un determinado espesor disminuía más débilmente. Por ello dedujo que el uranio emitía dos radiaciones diferentes, puesto que tenían poder de penetración distinto. Llamó a la radiación menos penetrante radiación alfa, y a la más penetrante (y que producía necesariamente una menor ionización puesto que atravesaba el aire) radiación beta.
En 1900, Rutherford se casó con Mary Newton. De este matrimonio nació en 1901 su única hija, Eileen.

Por esa época, Rutherford estudia el torio y se da cuenta, al utilizar el mismo dispositivo que para el uranio, de que abrir una puerta en el laboratorio perturba notablemente el experimento, como si los movimientos del aire pudieran alterar el experimento. Pronto llegará a la conclusión de que el torio desprende una emanación, también radiactiva, puesto que al aspirar el aire que rodea el torio, se da cuenta de que ese aire transmite la corriente fácilmente, incluso a gran distancia del torio.

También nota que las emanaciones de torio solo permanecen radiactivas unos diez minutos y que son partículas neutras. Su radiactividad no se ve alterada por ninguna reacción química, ni por cambios en las condiciones (temperatura, campo eléctrico). Se da cuenta asimismo de que la radiactividad de esas partículas decrece exponencialmente, puesto que la corriente que pasa entre los electrodos también lo hace, y descubre así el periodo de los elementos radiactivos en 1900. Con la ayuda de un químico de Montreal, Frederick Soddy, llega en 1902 a la conclusión de que las emanaciones de torio son efectivamente átomos radiactivos, pero sin ser torio, y que la radiactividad viene acompañada de una desintegración de los elementos.

Este descubrimiento provocó un gran revuelo entre los químicos, muy convencidos del principio de indestructibilidad de la materia. Una gran parte de la ciencia de la época se basaba en este concepto. Por ello, este descubrimiento representa una auténtica revolución. Sin embargo, la calidad de los trabajos de Rutherford no dejaban margen a la duda. El mismísimo Pierre Curie tardó dos años en admitir esta idea, a pesar de que ya había constatado con Marie Curie que la radiactividad ocasionaba una pérdida de masa en las muestras. Pierre Curie opinaba que perdían peso sin cambiar de naturaleza.

Las investigaciones de Rutherford tuvieron el reconocimiento en 1903 de la Royal Society, que le otorgó la Medalla Rumford en 1904. Resumió el resultado de sus investigaciones en un libro titulado "Radiactividad" en 1904, en el que explicaba que la radiactividad no estaba influida por las condiciones externas de presión y temperatura, ni por las reacciones químicas, pero que comportaba una emisión de calor superior al de una reacción química. Explicaba también que se producían nuevos elementos con características químicas distintas, mientras desaparecían los elementos radiactivos.

Junto a Frederick Soddy, calculó que la emisión de energía térmica debida a la desintegración nuclear era entre 20.000 y 100.000 veces superior a la producida por una reacción química. Lanzó también la hipótesis de que tal energía podría explicar la energía desprendida por el sol. Opinaban que si la tierra conserva una temperatura constante (en lo que concierne a su núcleo), se debe sin duda a las reacciones de desintegración que se producen en su seno. Esta idea de una gran energía potencial almacenada en los átomos encontrará un año después un principio de confirmación cuando Albert Einstein descubra la equivalencia entre masa y energía. Tras estos trabajos, Otto Hahn, el descubridor de la fisión nuclear junto con Fritz Strassmann y Lise Meitner, acudirá a estudiar con Rutherford en McGill durante unos meses.

A través de numerosos estudios con elementos radiactivos observa que estos emiten dos tipos de radiación. El primer tipo de radiación, al que denomina rayos alfa, es altamente energético pero tiene poco alcance y es absorbida por el medio con rapidez. El segundo tipo de radiación es altamente penetrante y de mucho mayor alcance, al que llama rayos beta. Mediante el uso de campos eléctricos y magnéticos analiza estos rayos y deduce su velocidad, el signo de su carga y la relación entre carga y masa. También encuentra un tercer tipo de radiación muy energético, al que denominará rayos gamma.

En 1907, obtiene una plaza de profesor en la Universidad de Mánchester, en donde trabajará junto a Hans Geiger. Con este inventará un contador que permite detectar las partículas alfa emitidas por sustancias radiactivas (prototipo del futuro contador Geiger), ya que ionizando el gas que se encuentra en el aparato, producen una descarga que se puede detectar. Este dispositivo les permite estimar el número de Avogadro de modo muy directo: averiguando el periodo de desintegración del radio y midiendo con su aparato el número de desintegraciones por unidad de tiempo. De ese modo dedujeron el número de átomos de radio presente en la muestra.

En 1908, junto con uno de sus estudiantes, Thomas Royds, demuestra de modo definitivo lo que se suponía: que las partículas alfa son núcleos de helio. En realidad, lo que prueban es que una vez liberadas de su carga, las partículas alfa son átomos de helio. Para demostrarlo, aisló la sustancia radiactiva en un material suficientemente delgado para que las partículas alfa lo atravesaran efectivamente, pero para ello bloquea cualquier tipo de "emanación" de elementos radiactivos, es decir, cualquier producto de la desintegración. Recoge a continuación el gas que se halla alrededor de la caja que contiene las muestras y analiza su espectro. Encuentra entonces gran cantidad de helio: los núcleos que constituyen las partículas alfa, han recuperado electrones disponibles.

Ese mismo año gana el por sus trabajos de 1908. Sufrirá, sin embargo, un pequeño disgusto, pues él se considera fundamentalmente un físico. Una de sus citas más famosas es que "la ciencia, o es Física, o es filatelia", con lo que sin duda situaba la física por encima de todas las demás ciencias.

En 1911 hará su mayor contribución a la ciencia, al descubrir el núcleo atómico. Había observado en Montreal al bombardear una fina lámina de mica con partículas alfa, que se obtenía una deflexión de dichas partículas. Al retomar Geiger y Marsden de modo más concienzudo estos experimentos y utilizando una lámina de oro, se dieron cuenta de que algunas partículas alfa se desviaban más de 90 grados. Rutherford lanzó entonces la hipótesis, que Geiger y Marsden enfrentaron a las conclusiones de su experimento, de que en el centro del átomo debía haber un "núcleo" que contuviera casi toda la masa y toda la carga positiva del átomo, y que de hecho los electrones debían determinar el tamaño del átomo. Este modelo planetario había sido sugerido en 1904 por un japonés, Hantarō Nagaoka, aunque había pasado desapercibido. Se le objetaba que en ese caso los electrones tendrían que irradiar girando alrededor del núcleo central y, en consecuencia, caer. Los resultados demostraron que ese era sin dudar el modelo bueno, puesto que permitía prever con exactitud la tasa de difusión de las partículas alfa en función del ángulo de difusión y de un orden de magnitud para las dimensiones del núcleo atómico. Las últimas objeciones teóricas (sobre la irradiación del electrón) se desvanecieron con los principios de la teoría cuántica y la adaptación que hizo Niels Bohr del modelo de Rutherford a la teoría de Max Planck, lo que sirvió para demostrar la estabilidad del átomo de Rutherford.

En 1914 empieza la Primera Guerra Mundial, y Rutherford se concentra en los métodos acústicos de detección de submarinos. Tras la guerra, ya en 1919, lleva a cabo su primera transmutación artificial. Después de observar los protones producidos por el bombardeo de hidrógeno de partículas alfa (al observar el parpadeo que producen en pantallas cubiertas de sulfuro de zinc), se da cuenta de que obtiene muchos de esos parpadeos si realiza el mismo experimento con aire y aún más con nitrógeno puro. Deduce de ello que las partículas alfa, al golpear los átomos de nitrógeno, han producido un protón, es decir, que el núcleo de nitrógeno ha cambiado de naturaleza y se ha transformado en oxígeno, al absorber la partícula alfa. Rutherford acababa de producir la primera transmutación artificial de la historia. Algunos opinan que fue el primer alquimista que consiguió su objetivo.

Ese mismo año sucede a J. J. Thomson en el laboratorio Cavendish, pasando a ser el director. Es el principio de una edad de oro para el laboratorio y también para Rutherford. A partir de esa época, su influencia en la investigación en el campo de la física nuclear es enorme. Por ejemplo, en una conferencia que pronuncia ante la Royal Society, ya alude a la existencia del neutrón y de los isótopos del hidrógeno y del helio. Y estos se descubrirán en el laboratorio Cavendish, bajo su dirección. James Chadwick, descubridor del neutrón, Niels Bohr, que demostró que el modelo planetario de Rutherford no era inestable, y Robert Oppenheimer, al que se considera el padre de la bomba atómica, están entre los que estudiaron en el laboratorio en los tiempos de Rutherford. Moseley, que fue alumno de Rutherford, demostró, utilizando la desviación de los rayos X, que los átomos contaban con tantos electrones como cargas positivas había en el núcleo, y que de ello resultaba que sus resultados «confirmaban con fuerza las intuiciones de Bohr y Rutherford».

El gran número de clases que dio en el laboratorio Cavendish y la gran cantidad de contactos que tuvo con sus estudiantes dio una imagen de Rutherford como una persona muy apegada a los hechos, más aún que a la teoría, que para él solo era parte de una «opinión». Este apego a los hechos experimentales era el indicio de un gran rigor y de una gran honestidad. Cuando Enrico Fermi consiguió desintegrar diversos elementos con la ayuda de neutrones, le escribió para felicitarle por haber conseguido «escapar de la física teórica».

Por fortuna, Rutherford no se detenía en los hechos, y su gran imaginación le dejaba entrever, más allá, las consecuencias teóricas más lejanas, pero no podía aceptar que se complicaran las cosas inútilmente. Con frecuencia hacía observaciones en este sentido a los visitantes del laboratorio que venían a exponer sus trabajos a los estudiantes y a los investigadores, cualquiera que fuera la fama del visitante. Su apego a la simplicidad era casi proverbial. Como él mismo decía: «Yo mismo soy un hombre sencillo».

Su autoridad en el laboratorio Cavendish no se basaba en el temor que pudiera inspirar. Por el contrario, Rutherford tenía un carácter jovial. Se sabía que estaba avanzando en sus trabajos cuando se le oía canturrear en el laboratorio. Sus alumnos lo respetaban mucho, no tanto por sus pasados trabajos o por el mito que le rodeaba como por su atractiva personalidad, su generosidad y su autoridad intelectual. Su discípulo ruso Peter Kapitza le apodó "el cocodrilo" y así era conocido entre sus colegas. No porque fuera temible o peligroso, sino porque para un soviético tan lejano de los ríos africanos, el concepto de cocodrilo representaba una tremenda fuerza. Aunque nadie le llamare así de frente, Rutherford lo sabía bien y se enorgullecía en secreto. Es más, el edificio construido para los estudios de Kapitza tenía un gran bajorrelieve de un cocodrilo.

También esta es para Rutherford la época de los honores: fue presidente de la Royal Society entre 1925 y 1930, y "chairman" de la Academic Assistance Council, que en esos políticamente turbulentos tiempos ayudaba a los universitarios alemanes que huían de su país. También se le concedió la Medalla Franklin en 1924 y de la Medalla Faraday en 1936. Realizó su último viaje a Nueva Zelanda, su país natal, que nunca olvidó, en 1925 y fue recibido como un héroe. Alcanzó la nobleza en 1931 y obtuvo el título de Barón Rutherford de Nelson, de Cambridge. Pero ese mismo año murió su única hija, Eileen, nueve días después de haber dado a luz a su cuarto hijo.

Rutherford era un hombre muy robusto y entró en el hospital en 1937 para someterse a una operación menor, tras haberse herido podando unos árboles de su propiedad. Al regresar a casa, parecía recuperarse sin problemas, pero su estado se agravó repentinamente. Murió el 19 de octubre y se le enterró en la abadía de Westminster, junto a Isaac Newton y Kelvin.


Rutherford recibió el Premio Nobel de Química de 1908 en reconocimiento a sus investigaciones relativas a la desintegración de los elementos. Entre otras distinciones, fue elegido miembro (1903) y presidente (1925-1930) de la Royal Society de Londres, y se le concedieron los títulos de sir (1914) y de barón Rutherford of Nelson (1931); el elemento 104 de la tabla periódica se denomina Rutherfordio en su honor. A su muerte, sus restos mortales fueron inhumados en la abadía de Westminster.



</doc>
<doc id="6856" url="https://es.wikipedia.org/wiki?curid=6856" title="Cyprinidae">
Cyprinidae

Los ciprínidos o carpas (Cyprinidae) son una familia de peces teleósteos fisóstomos, casi todos de agua dulce aunque algunas especies pueden encontrarse en estuarios, distribuidos por ríos de África, Eurasia y Norteamérica (desde el norte de Canadá hasta el sur de México). Su nombre procede del griego "kyprinos," que significa ‘pez dorado’.

Aparecen por primera vez en el registro fósil en el Eoceno, durante el Terciario inferior.

Poseen en la faringe entre una y tres filas de dientes, con un máximo de 8 dientes cada fila; normalmente la boca tiene labios finos sin papilas, a veces es una boca succionadora —en los géneros "Garra" y "Labeo"—, con o sin bigotes; mandíbula superior normalmente protusible; la aleta dorsal en algunas especies tiene radios espinosos.

El número primitivo de cromosomas es de 50 en casi todas las especies —algunas con 48—, pero se dan casos de poliploidía.

La longitud máxima descrita ha sido de cerca de 3m en "Catlocarpio siamensis," aunque existen muchas especies que no superan los 5cm.

Son peces ovíparos con abandono de la puesta, aunque en algunas especies los machos construyen nidos y/o protegen los huevos.

Tienen una alimentación variada, aunque muchos son insectívoros, alimentándose en especial de mosquitos.

Muchos son pescados como importante fuente de alimentación humana, criándose en estanques de acuicultura con tal fin. Una variedad muy popular en acuariofilia es la carpa dorada, de origen chino.

Es una familia numerosa pues existen más de 2000 especies agrupadas en más de 200 géneros:

Familia Cyprinidae "incertae sedis":


</doc>
<doc id="6857" url="https://es.wikipedia.org/wiki?curid=6857" title="Insectívoro">
Insectívoro

Se denomina insectívoro o entomófago a cualquier organismo depredador de insectos. 

Si bien los insectos son pequeños su número total es tan grande que constituyen una parte muy considerable de la biomasa animal en todos los ambientes terrestres. En los pastizales de Queensland, por ejemplo, normalmente el peso total de las larvas de escarabajos bajo la superficie de la tierra es mayor que el del ganado que pasta sobre la superficie. Por consiguiente los insectos constituyen un eslabón de gran importancia en la cadena alimentaria y desempeñan un papel fundamental en casi todos los ecosistemas terrestres.

Muchos animales dependen de los insectos como parte fundamental de su dieta. También hay muchos otros que, si bien tienen una dieta más variada y por consiguiente no son considerados insectívoros, suplementan su dieta en forma significativa con proteína animal proveniente de los insectos, especialmente durante la época de la cría. 

Algunos ejemplos de insectívoros incluyen a muchas aves, como las golondrinas, los papamoscas, los tiránidos y los parúlidos; mamíferos como los murciélagos y osos hormigueros. También muchos lagartos, ranas y peces son insectívoros. Prácticamente todas las arañas son insectívoras. Además hay numerosos insectos que son insectívoros, como coccinélidos, avispas, mántidos, libélulas, etc.

Si la dieta mayoritaria es a base de hormigas y termitas el animal recibe el nombre de mirmecófago.

Debido al impacto económico que tienen las plagas de insectos, se han utilizado diversos organismos insectívoros para controlarlas. Ejemplos de controles biológicos son los coccinelidos, mántidos, parasitoides (avispas y moscas en su mayoría), golondrinas, etc.

En España, las especies depredadoras de mosquitos, ya sea en su fase larvaria acuática, ya sea en su fase adulta aérea, incluyen al petirrojo, el ruiseñor, las golondrinas, la gambusia, la carpa, las ranas, las salamanquesas y los murciélagos.

También existen plantas insectívoras como las droseras y otras Nepenthales. Éstas en general crecen en suelos pobres en nitrógeno y suplementan su dieta con proteína animal que contiene este elemento. En principio no son estrictamente insectívoras ya que obtienen la mayor parte de su alimento de otras fuentes como las demás plantas.

Charles Darwin escribió el primer tratado sobre este tema, "Insectivorous Plants".




</doc>
<doc id="6858" url="https://es.wikipedia.org/wiki?curid=6858" title="Insecta">
Insecta

Los insectos (Insecta) son una clase de animales invertebrados del filo de los artrópodos, caracterizados por presentar un par de antenas, tres pares de patas y dos pares de alas (que, no obstante, pueden reducirse o faltar). La ciencia que estudia los insectos se denomina entomología. Su nombre proviene del latín "insectum", calco del griego ἔντομα, 'cortado en medio'.

Los insectos comprenden el grupo de animales más diversos de la Tierra con aproximadamente un millón de especies descritas, más que todos los demás grupos de animales juntos, y con estimaciones de hasta treinta millones de especies no descritas, con lo que, potencialmente, representarían más del 90 % de las formas de vida del planeta. Otros estudios más recientes rebajan la cifra de insectos por descubrir a entre seis y diez millones de especies.

Los insectos pueden encontrarse en casi todos los ambientes del planeta, aunque solo un pequeño número de especies se ha adaptado a la vida en los océanos. Hay aproximadamente seis mil especies de odonatos (libélulas, caballitos del diablo), 20 000 de ortópteros (saltamontes, grillos), 120 000 de lepidópteros (mariposas y polillas), 160 000 de dípteros (moscas, mosquitos), 9800 de dictiópteros (cucarachas, termitas, mantis), 5200 ftirápteros (piojos), 1900 sifonápteros (pulgas), 82 000 de hemípteros (chinches, pulgones, cigarras), 375 000 de coleópteros (escarabajos, mariquitas), y 153 000 especies de himenópteros (abejas, avispas, hormigas). La biodiversidad de los insectos disminuye.

Los insectos no solo presentan una gran diversidad, sino que también son increíblemente abundantes. Algunos hormigueros contienen más de veinte millones de individuos y se calcula que hay 10 hormigas viviendo sobre la Tierra. En la selva amazónica se estima que hay unas 60 000 especies y 3,2 × 10 individuos por hectárea. Se estima que hay 200 millones de insectos por cada ser humano.

Artrópodos terrestres tales como los ciempiés, milpiés (Myriapoda), arañas, escorpiones (Chelicerata) y las cochinillas de humedad (Crustacea) se confunden a menudo con los insectos debido a que tienen estructuras corporales similares, pero son fácilmente distinguibles, ya que los insectos presentan tres pares de patas, mientras que los escorpiones y las arañas tienen cuatro pares y no poseen antenas, las cochinillas de humedad poseen diez pares de patas y pueden enrollarse, los ciempiés y milpiés tienen muchos pares de patas.

El cuerpo de los insectos está formado por tres regiones principales (denominadas tagmas): cabeza, tórax y abdomen, uniformemente recubiertas por un exoesqueleto.

El exoesqueleto o ectoesqueleto es el esqueleto externo que recubre todo el cuerpo de los insectos y demás artrópodos y que también se conoce como integumento. En insectos está formado por una sucesión de capas; de adentro hacia afuera estas son: la membrana basal, la epidermis o hipodermis y la cutícula; la única capa celular es la epidermis; el resto no posee células y está compuesto por algunas de las siguientes sustancias: quitina, artropodina, esclerotina, cera y melanina. El componente rígido, la esclerotina, cumple varios papeles funcionales que incluyen la protección mecánica del insecto y el apoyo de los músculos esqueléticos, a través del llamado endoesqueleto; en los insectos terrestres, el exoesqueleto también actúa como una barrera para evitar la desecación o pérdida del agua interna. El exoesqueleto apareció por primera vez en el registro fósil hace unos 550 millones de años y su evolución ha sido crítica para la radiación adaptativa y la conquista de casi todos los nichos ecológicos del planeta que los artrópodos han venido realizando desde el Cámbrico.

La cabeza es la región anterior del cuerpo, en forma de cápsula, que contiene los ojos, antenas y piezas bucales. La forma de la cabeza varía considerablemente entre los insectos para dar espacio a los órganos sensoriales y a las piezas bucales. La parte externa endurecida o esclerosada de la cabeza se llama cráneo.

La cabeza de los insectos está subdividida por suturas en un número de escleritos más o menos diferenciados que varían entre los diferentes grupos. Típicamente hay una sutura en forma de "Y" invertida, extendiéndose a lo largo de la parte dorsal y anterior de la cabeza, bifurcándose por encima del ocelo para formar dos suturas divergentes, las cuales se extienden hacia abajo en los lados anteriores de la cabeza. La parte dorsal de esta sutura (la base de la Y) es llamada sutura coronal y las dos ramas anteriores suturas frontales.
Por otra parte, la cabeza de los insectos está constituida de una región preoral y de una región postoral. La región preoral contiene los ojos compuestos, ocelos, antenas y áreas faciales, incluido el labio superior, y la parte postoral contiene las mandíbulas, las maxilas y los labios.

Internamente, el exoesqueleto de la cápsula cefálica de los insectos se invagina para formar las ramas del tentorio que sirven como sitios de inserción muscular.

La mayoría de los insectos tienen un par de ojos compuestos relativamente grandes, localizados dorso-lateralmente en la cabeza. La superficie de cada ojo compuesto está dividida en un cierto número de áreas circulares o hexagonales llamadas facetas u omatidios; cada faceta es una lente de una única unidad visual. En adición a los ojos compuestos, la mayoría de los insectos posee tres ojos simples u ocelos localizados en la parte superior de la cabeza, entre los ojos compuestos.

Son apéndices móviles multiarticulados. Se presentan en número par en los insectos adultos y la mayoría de las larvas. Están formadas por un número variable de artejos denominados antenómeros o antenitas.
El cometido de las antenas es eminentemente sensorial, desempeñando varias funciones. La función táctil es la principal, gracias a los pelos táctiles que recubren casi todos los antenómeros; también desempeñan una función olfativa, proporcionada por áreas olfativas en forma de placas cribadas de poros microscópicos distribuidas sobre la superficie de algunos antenómeros terminales. También poseen una función auditiva y a veces una función prensora durante la cópula o apareamiento, al sujetar a la hembra. Están formadas por tres partes, siendo las dos primeras únicas y uniarticuladas y la tercera comprende un número variable de antenómeros y se denominan respectivamente: escapo, pedicelo y flagelo o funículo.
Son piezas móviles que se articulan en la parte inferior de la cabeza, destinadas a la alimentación; trituran, roen o mastican los alimentos sólidos o duros y absorben líquidos o semilíquidos. Las piezas bucales son las siguientes:


El aparato bucal de los insectos se ha ido modificando en varios grupos para adaptarse a la ingestión de diferentes tipos de alimentos y por diferentes métodos. Aquí se citan los tipos más diferenciados e interesantes, escogidos para ilustrar las diversas formas adoptadas por partes homólogas, y los diferentes usos a que pueden ser aplicadas. Existen muchos otros tipos, gran cantidad de los cuales representan estados intermedios entre algunos de los aquí citados.







El tórax es la región media del cuerpo y contiene las patas y las alas (en algunos insectos adultos no hay alas y en muchos insectos inmaduros y en algunos adultos no hay patas).
El tórax está compuesto de tres segmentos, protórax, mesotórax, y metatórax, cada segmento torácico tiene típicamente un par de patas y meso y metatórax un par de las alas cada uno (cuando están presentes); cuando hay un solo par de alas, están situadas en el mesotórax, excepto en los estrepsípteros que solo conservan las alas metatorácicas; el protórax nunca tiene alas.

El tórax está unido a la cabeza por una región del cuello, membranosa, el cerviz. Hay generalmente uno o dos escleritos pequeños en cada lado del cuello, los cuales ligan la cabeza con el protórax.

Cada segmento torácico está compuesto de cuatro grupos de escleritos. El noto dorsalmente, las pleuras lateralmente y el esternón ventralmente. Cualquier esclerito torácico puede ser localizado en un segmento particular por el uso de prefijos apropiados: pro-, meso- y meta-. Por ejemplo, el noto del protórax es llamado pronoto.

Los notos del mesotórax y metatórax están frecuentemente subdivididos por suturas en dos o más escleritos cada uno.
La pleura es un segmento portador de alas, forma un proceso alar-pleural que sirve como sostén para el movimiento del ala.

En cada lado del tórax hay dos aberturas en forma de hendiduras, una entre el protórax y el mesotórax y la otra entre el meso y el metatórax. Estas son los estigmas, o sea las aberturas externas del sistema traqueal.

Consisten típicamente en los segmentos siguientes:

Las alas de los insectos son evaginaciones de la pared del cuerpo localizadas dorso-lateralmente entre los notos y las pleuras. La base del ala es membranosa, esto hace posible el movimiento del ala.

Las alas de los insectos varían en número, tamaño, forma, textura, nerviación, y en la posición en que son mantenidas en reposo. La mayoría de los insectos adultos tienen dos pares de alas, situadas en el meso y metatórax; algunos, como los dípteros, tienen un solo par (siempre situado en el mesotórax salvo en estrepsípteros que las poseen en el metatórax) y algunos no poseen alas (por ejemplo, formas ápteras de los pulgones, hormigas obreras, pulgas, etc.).

En la mayoría de los insectos las alas son membranosas y pueden contener pequeños pelos o escamas; en algunos insectos las alas anteriores son engrosadas, coriáceas o duras y en forma de vaina, esa estructura es conocida como élitro (en los coleópteros). Las chinches tienen el primer par de alas engrosado en su base; a este tipo de alas se les llama hemiélitros. Las langostas, grillos, cucarachas, entre otros insectos primitivos tienen el primer par de alas angosto y con la consistencia de un pergamino; éstas reciben el nombre de tegminas. Las alas membranosas de los insectos son usadas para volar, aquellas endurecidas como es el caso de los élitros, hemiélitros, tegminas, cuando plegadas sirven de protección al segundo par de alas que es delicado por ser membranoso y también al abdomen. Las alas son también importantes para producir ciertos sonidos, para dispersar olores y, por su diseño, tienen importancia en el camuflaje y el mimetismo.

La mayoría de los insectos son capaces de doblar las alas sobre el abdomen cuando están en reposo, pero los grupos más primitivos, como libélulas y efímeras, no pueden hacerlo y mantienen las alas extendidas para afuera, o reunidas encima del cuerpo.

Algunos insectos como grillos y langostas machos, son capaces de producir un sonido característico con las alas friccionando las dos alas anteriores entre sí, o las alas anteriores con las patas posteriores.

Muchos insectos como las moscas y abejas, mueven las alas tan rápidamente que se produce un zumbido. El zumbido, por su frecuencia sonora, es un carácter específico y en insectos como los mosquitos o zancudos hembras, es un elemento usado por las hembras para atraer a los machos que vuelan en un enjambre.

Los insectos son los únicos invertebrados capaces de volar. En el Carbonífero, algunas "Meganeura" (un grupo relacionado con las libélulas actuales) tenían una envergadura de 75 cm.; la aparición de insectos gigantes parece tener una relación directa con el contenido de oxígeno de la atmósfera, que en aquella época era del 35 %, comparado con el 21 % actual; el sistema traqueal de los insectos limita su tamaño, de modo que elevadas concentraciones de oxígeno permitieron tamaños mayores. Los mayores insectos voladores actuales, como algunas mariposas nocturnas ("Attacus atlas", "Thysania agrippina") son mucho menores.

Además del vuelo activo, muchos pequeños insectos son también dispersados por el viento. Este es el caso de los pulgones que a menudo son transportados largas distancias por las corrientes de aire.

El abdomen de los insectos posee típicamente 11 segmentos, pero el último está muy reducido, de modo que el número de segmentos raramente parece ser más de 10. Los segmentos genitales pueden contener estructuras asociadas con las aberturas externas de los conductos genitales; en el macho estas estructuras se relacionan con la cópula y la transferencia de esperma a la hembra; y en las hembras están relacionados con la oviposición.

En el extremo del abdomen puede haber apéndices, los cuales surgen del segmento 10 y son los cercos, que son de valor taxonómico.

El aparato digestivo de los insectos es un tubo, generalmente algo enrollado que se extiende desde la boca al ano. Se divide en tres regiones: el estomodeo, el mesenterón y el proctodeo. Algunas porciones están ensanchadas, sirviendo de almacenaje, por ejemplo el Buche. Separando estas regiones hay válvulas y esfínteres que regulan el paso del alimento de una a otra. Hay también una serie de glándulas que desembocan en el tubo digestivo y que ayudan a la digestión.

El aparato respiratorio de los insectos está compuesto por tráqueas, una serie de tubos vacíos que en su conjunto forman el sistema traqueal; los gases respiratorios circulan a través de él. Las tráqueas se abren al exterior a través de los estigmas o espiráculos, en principio un par en cada segmento corporal; luego van reduciendo progresivamente su diámetro hasta convertirse en traqueolas que penetran en los tejidos y aportan oxígeno a las células. En la respiración traqueal el transporte de gases respiratorios es totalmente independiente del aparato circulatorio por lo que, a diferencia de los vertebrados, el fluido circulatorio (hemolinfa) no almacena oxígeno.

Como en los demás artrópodos, la circulación es abierta y lagunar, y en los insectos está simplificada. El líquido circulatorio es la hemolinfa que llena la cavidad general del cuerpo que por esta razón se denomina hemocele que está subdividida en tres senos (pericárdico, perivisceral y perineural). El corazón se sitúa en posición dorsal en el abdomen dentro del seno pericárdico; tiene una válvula en cada metámero que delimita varios compartimentos o ventrículos, cada uno de ellos con un par de orificios u ostiolos por los que penetra la hemolinfa cuando el corazón se dilata (diástole). El corazón se prolonga hacia adelante en la arteria aorta por la que sale la hemolinfa cuando el corazón se contrae (sístole); suele ramificarse para distribuir la hemolinfa a la región cefálica. Pueden existir órganos pulsátiles accesorios en diferentes partes del cuerpo, que actúan como corazones accesorios que aseguran la llegada de la hemolinfa a los puntos más distales (antenas, patas).

El aparato excretor de los insectos está constituido por los tubos de Malpighi. Son tubos ciegos que flotan en el hemocele, de donde captan los productos residuales y desembocan en la parte final del tubo digestivo donde son evacuados y eliminados con las heces. Son capaces de reabsorber agua y electrolitos, con lo que juegan un importante papel en el equilibrio hídrico y osmótico. Su número oscila entre cuatro a más de cien. Los insectos son uricotélicos, es decir, excretan principalmente ácido úrico. Excepcionalmente, los tubos de Malpighi se modifican en glándulas productoras de seda u órganos productores de luz.

Algunos insectos poseen órganos excretores adicionales e independientes del tubo digestivo, como las glándulas labiales o maxilares, y los riñones de acumulación (cuerpos pericárdicos, nefrocitos dispersos por el hemocele, oenocitos epidérmicos y células del urato).

El sistema nervioso consta del cerebro y de una cadena ventral de nervios. El cerebro está en la cabeza, se subdivide en protocerebro, deutocerebro y tritocerebro y en el ganglio subesofágico. Todos están conectados por comisuras nerviosas. La cadena nerviosa es como una escalera de cuerdas con pares de ganglios que corresponden a cada segmento del cuerpo del insecto. Además hay órganos sensoriales: antenas para la olfacción, ojos compuestos y simples, órganos auditivos, mecanorreceptores, quimiorreceptores, etc.

Muchos insectos poseen órganos muy refinados de percepción; en algunos casos sus sentidos pueden percibir cosas fuera del rango de percepción de los sentidos de los humanos. Por ejemplo, las abejas pueden ver en el espectro ultravioleta y captar los patrones de polarización de la luz, y ciertas polillas macho tienen un sentido especializado del olfato que les ayuda a detectar las feromonas de las hembras a muchos kilómetros de distancia; las hormigas pueden seguir en la oscuridad los rastros olorosos dejadas por sus compañeras.

Debido al pequeño tamaño y la simplicidad de su sistema nervioso, el procesamiento que puedan hacer de las percepciones es muy limitado. Por ejemplo, en general se acepta que la visión de los insectos ofrece muy baja resolución de los detalles, especialmente a grandes distancias.

Por otra parte son capaces de dar respuestas sorprendentemente rápidas ante estímulos específicos. Por ejemplo, el reflejo de correr de las cucarachas al percibir en sus cercos posteriores cualquier movimiento de aire que delata la presencia de un peligro a su alrededor, o el reflejo de las moscas y libélulas durante el vuelo de esquivar obstáculos a alta velocidad.

Los insectos sociales, como las termitas, hormigas y muchas abejas y avispas son las familias más conocidas de animales sociales. Viven juntos en grandes colonias altamente organizadas y genéticamente similares a tal punto que en algunos casos son consideradas superorganismos. Se dice que la abeja doméstica es el único invertebrado que ha desarrollado un sistema de símbolos abstractos de comunicación en que un comportamiento se usa para representar y transmitir una información específica acerca del ambiente. En este sistema de comunicación, llamado danza de la abeja, el ángulo de la posición de la abeja danzante representa la dirección en relación al sol y la duración de la danza representa la distancia a la fuente de alimento de flores.

El sistema de comunicación de los abejorros no es tan avanzado como el de la abeja doméstica pero ellos también tienen medios de comunicación. Por ejemplo, "Bombus terrestris" aprende más rápido como manipular flores cuando visita un grupo de flores desconocidas si ve a un coespecífico forrajeando en tales flores.

Solamente los insectos que viven en nidos o colonias demuestran una verdadera capacidad de orientación espacial o de navegación fina. Esto les permite retornar a su nido que puede estar a unos pocos milímetros de muchos otros similares de los demás miembros de la agregación de nidos después de un viaje de varios kilómetros. En el fenómeno conocido como filopatría los insectos que hibernan o pasan un período de dormancia demuestran una habilidad de recordar una localidad determinada hasta un año más tarde de la última vez que la vieron. Algunos insectos emigran largas distancias a otras regiones geográficas cuando el cambio de estación (por ejemplo la mariposa monarca y la esfinge colibrí).

Los insectos eusociales (abejas, avispas, hormigas, termitas) construyen nidos, protegen los huevos y proveen alimento a la cría. En cambio, la mayoría de los insectos llevan vidas muy cortas como adultos y raramente interactúan con su cría después de la puesta de huevos. Además de los insectos eusociales un pequeño número de insectos presentan comportamiento parental, al menos vigilan los huevos y en algunos casos continúan cuidando a los inmaduros y aún alimentándolos hasta su madurez. Otra forma simple de cuidado parental es la construcción de nidos o refugios y almacenamiento de provisiones antes de depositar los huevos. El adulto no entra en contacto con su cría pero le ha proporcionado todo el alimento necesario. Este comportamiento es característico de las especies solitarias que constituyen la mayoría de las abejas y de las avispas de la superfamilia Vespoidea.

Varias familias de Hemiptera tienen representantes que practican cuidado parental. Esto se ve en algunas chinches de la superfamilia Pentatomoidea en que la madre permanece con los huevos y después las ninfas. En la familia Belostomatidae es el macho que lleva los huevos en el dorso hasta que emergen las ninfas, o sea que se trata de cuidado paternal.

Tres grupos de insectos tienen especies que practican cuidado biparental, es decir que ambos padres cuidan a la cría: Blattodea, Coleoptera e Hymenoptera. En la familia Blaberidae de Blattodea, ambos padres alimentan a las ninfas por trofalaxis, transmitiendo secreciones y alimento de boca a boca. En Coleoptera, los escarabajos peloteros de la familia Scarabaeidae preparan una pelota de heces para la cría y permanecen con ella. El escarabajo enterrador ("Nicrophorus" y otros de la familia Silphidae) proveen carroña a la cría. Entre algunos miembros de la familia Sphecidae de Hymenoptera, como "Polistes", los machos vigilan y protegen el nido.

La mayoría de las especies de insectos tienen sexos separados, morfológicamente diferenciados entre sí, y deben aparearse para reproducirse. No obstante, además de este tipo de reproducción sexual, existen especies que pueden reproducirse sin aparearse e, incluso, este puede ser el proceso típico de reproducción en varias de ellas. Estas especies se denominan partenogenéticas y su tipo de reproducción es eminentemente asexual. Este mecanismo de reproducción está bastante distribuido en la mayoría de los órdenes de apterigotos. Aunque todavía mucho menos frecuente, existen especies de insectos que son hermafroditas, es decir, llevan los dos sexos funcionales en el mismo individuo (como por ejemplo "Icerya purchasi" y "Perla marginata").

Un buen ejemplo de especie partenogenética es el insecto palo ("Dixppus morosus"). Los machos en esta especie son sumamente escasos y las hembras comienzan a poner huevos no fertilizados en cuanto maduran. Estos huevos se desarrollan y abren con normalidad, dando origen a nuevas hembras. De este modo una generación de hembras, genéticamente idéntica a la anterior, sucede a otra ininterrumpidamente. Este tipo de partenogénesis, en la cual los óvulos se producen sin reducción del número cromosómico (sin meiosis) y las hembras dan origen a más hembras, se denomina partenogénesis "telitóquica" y es el mecanismo usual de reproducción entre los áfidos.

De un modo algo diferente, una abeja reina "(Apis mellifera") puede poner huevos fertilizados (diploides) de los que surgen hembras, y huevos sin fecundar (haploides) de los que surgirán machos (los zánganos). En este caso, en el que la partenogénesis se produce a partir de óvulos que han surgido por meiosis por lo que hay reducción del número cromosómico, la partenogénesis se denomina "arrenotóquica". Este sistema de determinación de sexo en el que las hembras son diploides y los machos son haploides se denomina haplodiploidía. El mismo combina la reproducción sexual y asexual de un modo adaptativo y se halla bastante distribuido entre los himenópteros.

La mayoría de las especies de insectos ponen huevos (son ovíparas). No obstante, hay casos en los que las hembras paren a sus crías, como por ejemplo en los áfidos. Los ejemplos de viviparidad, si bien escasos, son también muy diversos. En algunos casos el huevo se abre inmediatamente antes de ser puesto; en otros, como en la mosca tse-tse, se desarrolla dentro del cuerpo de la madre y la cría no nace sino hasta el estado de pupa. En algunos insectos parásitos (Strepsiptera, himenópteros parásitos) un solo huevo puesto del modo acostumbrado se divide repetidamente hasta alcanzar una progenie de hasta 2000 individuos, de igual genotipo y sexo, fenómeno conocido como poliembrionía. Las larvas poliembriónicas son a veces caníbales, por lo que se logran establecer pocos adultos.

Un método muy singular de reproducción es el proceso conocido como paidogénesis. Las larvas de "Miastor metraloas", por ejemplo, pueden reproducirse por sí mismas a partir de huevos no fertilizados existentes en el interior de una gran larva viva. Las nuevas larvas crecen como parásitos en el cuerpo de su semejante y cuando se hallan maduras para emerger, la larva original muere. Las crías repiten el proceso, de modo que el número de larvas continúa incrementando, hasta que se transforman en insectos adultos.

Los huevos pueden ser colocados solitarios o en grupos, a veces dentro de una estructura protectora llamada ooteca. La forma y el tamaño de los huevos son tan variados como los insectos que los ponen. Los huevos de las mariposas, por ejemplo, suelen presentar intrincados dibujos, con una superficie cubierta de numerosos realces y nerviaciones. Muchos insectos ponen sus huevos en las raíces, o en los brotes y tejidos tiernos de las plantas, o dentro de los granos de los cereales e incluso, dentro de otros animales. El lugar donde los insectos deponen los huevos, si bien variado, no es de ningún modo aleatorio. El objetivo de escoger cuidadosamente el lugar de la puesta es siempre el mismo: poner los huevos en el lugar dónde las larvas recién nacidas estén rodeadas de alimento.

En la mayoría de los insectos la vida reproductiva de una hembra es muy breve y todos los huevos producidos son puestos en rápida sucesión en un lapso muy corto. No obstante, en algunas otras especies, especialmente en los denominados insectos sociales como abejas, hormigas y termitas, la vida reproductora de una hembra dura hasta tres años. Se calcula que la reina de las termitas, por ejemplo, pone un huevo cada dos segundos, día y noche, durante un período de 10 años. Como en la comunidad es el único adulto procreador, la población del termitero decrecería rápidamente sin ese ritmo de fertilidad.

El huevo de insecto es el estadio de la vida del insecto que comienza cuando la gameta femenina (“ovocito”) del insecto, y luego de la fecundación el embrión en desarrollo, viven protegidos por una cáscara externa llamada corion, y finaliza cuando, al terminar el desarrollo del embrión, ocurre la eclosión del primer estadio juvenil fuera del corion. Durante el estadio de huevo el embrión se desarrolla a expensas de los nutrientes depositados dentro del corion junto con el ovocito, y debe poseer la permeabilidad suficiente para que ocurra el intercambio de gases y agua. El huevo como tal nace en el aparato reproductor de la madre, cuando los nutrientes y la cáscara externa alrededor del ovocito se terminan de formar y las células que los forman mueren por apoptosis celular. Luego, por mecanismos variados, el huevo es fecundado con semen proveniente del padre, que entra hasta el ovocito a través de un poro en el corion (la entrada del semen puede ser facilitada por mecanismos diversos). En ese momento se forma el embrión que se desarrolla a expensas de los nutrientes contenidos dentro del corion. En general la fecundación ocurre dentro del aparato reproductivo de la madre y luego de ella ésta deposita el huevo (“ovipone”) en un ambiente externo seleccionado por ella. El huevo debe poseer una morfología y elasticidad suficientes como para pasar por el ovipositor de la madre. En el ambiente externo el huevo inmóvil está expuesto al ataque de predadores y patógenos, en consecuencia evolucionaron adaptaciones que aportan al huevo de protección mecánica, química, o de cuidado parental. El huevo también está expuesto a la futura competencia de las larvas por el alimento (las larvas en general tienen poca movilidad, sobre todo cuando están recién eclosionadas), por lo cual la hembra grávida está adaptada a depositar los huevos de forma estratégica, por ejemplo los ubica espaciados entre sí, o cerca de una fuente importante de alimento para los futuros juveniles.

La morfología del huevo maduro es muy variada entre órdenes de insectos.
El huevo en un esquema generalizado consta de un ovocito con nutrientes, envuelto por la membrana vitelina (que contiene más nutrientes), y 4 capas de corion protector. La ovogénesis (el proceso de formación del huevo) también se encuentra bastante conservada evolutivamente.

En el momento de la oviposición se pueden liberar volátiles que sean captados por individuos de la misma o de otra especie, que pueden modificar su comportamiento de acuerdo a la información obtenida.

El canibalismo de huevos no es un fenómeno extraño entre los insectos, lo cual sugiere que tendrá un valor adaptativo.

El todavía nuevo campo de la ecología química nos permite echar luz sobre las relaciones del huevo depositado en su sustrato y el ambiente y sus organismos asociados, situación que ocurre desde el momento de la oviposición hasta que emerge el juvenil del huevo. Se han encontrado relaciones complejas y de carrera armamentista con predadores, parásitos, patógenos, competidores, microorganismos asociados, y hospedadores y plantas hospedadoras cuando las hay.

La metamorfosis es un proceso de desarrollo postembrionario mediante el cual los insectos alcanzan su fase adulta (imago), durante la cual llegan a la madurez sexual y en los pterigotos se desarrollan las alas. De acuerdo al tipo de metamorfosis que experimentan los insectos se clasifican en:




El régimen alimenticio de los insectos es sumamente variado. A grandes rasgos pueden diferenciarse los siguientes:




Los insectos establecen relaciones muy diversas con otros organismos, que actúan como hospedadores, para conseguir un beneficio. Dependiendo del tipo de relación, pueden distinguirse varios niveles de asociación, aunque muchas veces el límite entre ellos es difícil de establecer.

Los insectos comensales aprovechan el alimento sobrante o las descamaciones, mudas, excrementos, etc.; de su hospedador, al que no perjudican. Los hormigueros y termiteros alojan muchos insectos comensales, donde en general se alimentan de la comida almacenada; se denominan, respectivamente, mirmecófilos y termitófilos. Los insectos foleófilos viven en madrigueras de mamíferos y los nidícolas en nidos de aves, siendo a veces difícil de precisar si se trata de comensales o de parásitos.

El mutualismo, en que dos especies obtienen beneficio mutuo de su relación, está también presente entre los insectos; muchas hormigas apacientan pulgones, a los que defienden de otros insectos y obtiene a cambio un líquido azucarado que los pulgones segregan. Algunas hormigas y termitas crían hongos en sus nidos, de los que se alimentan; los hongos encuentran un ambiente estable y protegido para su desarrollo. La polinización puede también considerarse como mutualismo entre insectos y vegetales.

Muchos insectos poseen protozoos, bacterias y hongos simbiontes en el tubo digestivo, tubos de Malpighi, gónadas, hemocele, etc.; los simbiontes les facilitan la digestión de la celulosa o de la sangre y les proporcionan nutrientes esenciales para su desarrollo, hasta el punto que no pueden vivir sin ellos.

El parasitismo está también muy extendido entre los insectos; en este caso, el hospedador sale perjudicado por el parásito, que puede considerarse como un depredador muy especializado. Los ectoparásitos viven fuera del hospedador y generalmente son hematófagos (se alimentan de sangre) o dermatófagos (se alimentan de la piel); hay grupos enteros de insectos que son ectoparásitos (pulgas, piojos, chinches); cabe destacar también los parásitos sociales, en que especies de himenópteros sociales no tienen obreras y se hacen adoptar por otras especies coloniales o reclutan esclavos entre las obreras de otras especies (hormigas esclavistas). Los endoparásitos viven dentro del cuerpo de sus hospedadores donde se alimentan de sus órganos o líquidos internos; es un fenómeno corriente entre las larvas de ciertos dípteros, coleópteros y estrepsípteros y de muchos himenópteros. El hiperparasitismo se da cuando un insecto parásita a otro insecto que a su vez es parásito. Estas relaciones tienen gran importancia en la regulación de las poblaciones de insectos y se utilizan en el control biológico de plagas.

La reacción más común frente a un peligro es la huida. Algunos insectos se defienden produciendo secreciones repugnantes (malolientes, irritantes, etc., como muchos coleópteros y ortópteros), mediante actitudes intimidantes (como las mantis que levantan sus patas delanteras y muestran sus alas posteriores de colores llamativos) o inmovilización refleja. Otros inoculan substancias tóxicas mediante sus piezas bucales (hemípteros) u ovipositores modificados para tal fin (himenópteros). Algunas larvas de lepidópteros poseen pelos urticantes que se clavan en la boca de sus enemigos. Algunos lepidópteros, ortópteros y coleópteros acumulan en sus tejidos sustancias tóxicas, generalmente procedentes de su alimentación.

Muchos insectos tóxicos o picadores poseen coloraciones vistosas y llamativas que advierten a sus depredadores potenciales de su peligrosidad; este fenómeno es conocido como aposematismo, y es una estrategia que maximiza la efectividad de los mecanismos defensivos, ya que muchos animales aprenden que tal combinación de color les produjo una experiencia desagradable y tienden a evitar repetirla. A este respecto, cabe destacar que muchos insectos inofensivos se parecen en forma, color o comportamiento a insectos peligrosos, con lo que engañan a sus depredadores, que los evitan (por ejemplo, dípteros, lepidópteros y coleópteros que parecen avispas); este fenómeno se denomina mimetismo mülleriano y está muy extendido entre los insectos.

Los insectos son los maestros indiscutibles de la cripsis, adaptación que consiste en pasar inadvertido a los sentidos de otros animales. Son extraordinarias las morfologías que imitan objetos del entorno, como en los Phasmatodea (insecto palo e insecto hoja) y algunos ortópteros y lepidópteros que se asemejan también a hojas. Muchos insectos imitan los colores de su entorno (homocromía), lo que se acompaña con frecuencia de una inmovilización refleja ante situaciones de peligro.

Los insectos constituyen una de las clases de animales que más interrelacionados se hallan con las actividades humanas. Desde los insectos útiles que nos proveen miel o seda hasta los insectos que son venenosos o transmisores de enfermedades mortales, existe un sinnúmero de especies que se hallan directa o indirectamente asociadas al ser humano.

Desde hace millones de años que las plantas con flor y los insectos han iniciado una asociación sumamente estrecha que ha determinado un mecanismo de coevolución muy singular. Las plantas, por su condición de organismos sésiles, necesitan que sus gametos masculinos (los granos de polen) sean transportados de una planta a otra para que pueda ocurrir la polinización y, por ende, la generación de nuevos descendientes. En muchísimas especies de plantas (las que se denominan entomófilas, o "amantes de los insectos") pertenecientes a muy diversas familias este transporte está a cargo de diversas especies de insectos. La planta necesita atraer a los insectos a sus flores para que éstos se cubran de granos de polen, los que más tarde serán transportados a otras plantas. Para atraerlos hacen uso de una cantidad de mecanismos, entre ellos la forma de la corola, el color de los pétalos o tépalos y la fragancia de sus flores, si bien el más importante de todos ellos es el alimento que pueden proveerles: el néctar, utilizado como "recompensa" por su función. La extrema diversidad de tipos, colores y aromas de flores que pueden apreciarse en las angiospermas se debe, justamente, a la necesidad de atraer diferentes especies de insectos polinizadores. La función de polinización de los insectos se utiliza en agricultura ya que permite la producción de muchos cultivos, entre ellos el girasol, muchas especies hortícolas y frutales.

Las hembras de muchas especies de insectos (como por ejemplo los gorgojos) perforan los granos de cereales (trigo, maíz, arroz, cebada, entre otros) y leguminosas (garbanzos, porotos, por ejemplo) para depositar en ellos sus huevos. Luego de un período de incubación de algunos días, nacen las larvas que inmediatamente comienzan a alimentarse del endosperma y del embrión de las semillas, causando cuantiosas pérdidas económicas.

Muchas especies de insectos hematófagos (esto es, que se alimentan de sangre) son vectores de enfermedades infecciosas graves para el ser humano, tales como el paludismo (transmitida por los mosquitos del género "Anopheles"), la enfermedad de Chagas (transmitida por algunas especies de la familia Reduviidae), la enfermedad del sueño o tripanosomiasis africana (cuyo vector es la mosca tse-tse), la fiebre amarilla y el dengue (el mosquito "Stegomyia aegypti"), tifus (transmitido por las piojos, pulgas y garrapatas), peste bubónica (pulgas de las ratas), Leishmaniasis (mosquitos "Phlebotomus"), filariasis y elefantiasis (mosquitos "Anopheles", "Culex", "Stegomyia", "Mansonia"), etc.

Desde los orígenes de la agricultura los insectos han venido ocasionando perjuicios graves a los cultivos. Existen aproximadamente 5000 especies de insectos (ejemplo, las larvas de muchas especies de lepidópteros o los adultos de los ortópteros) que se alimentan tanto de las hojas, como de los tallos, raíces, flores y frutos de las especies cultivadas. Los daños que ocasionan pueden ser indirectos (disminución de la superficie fotosintética, reducción de la capacidad de extracción de agua y nutrientes del suelo) como directos (pérdida de flores que van a dar frutos o los mismos frutos).

Además, muchas especies (tales como los áfidos) se alimentan de la savia de las plantas (un perjuicio directo ya que extraen los nutrientes que deberían dirigirse a las hojas y frutos) y también transmiten un sinnúmero de enfermedades, particularmente virosis que tienden a deprimir aún más los rendimientos potenciales de los cultivos. Algunas de las plagas más devastadoras han sido la filoxera (vid) y el escarabajo de la patata, sin olvidar las plagas de langostas que periódicamente asuelan muchos países africanos

La producción y recolección de madera no es más que una cosecha a largo plazo y, debido a los años en que esta "cosecha" tarda en madurar, se halla expuesta durante mucho tiempo a numerosos peligros, de los que el más serio es el ataque de los insectos. Durante su crecimiento los árboles son atacados por dos grandes grupos de insectos: los que atacan el follaje y los que perforan la corteza o la madera. Los primeros suelen ser larvas de mariposas e himenópteros. El segundo grupo está constituido por insectos perforadores, en su mayoría larvas de coleópteros, como los bupréstidos, anóbidos, bostríquidos, cerambícidos y escolítidos. Los más dañinos de los insectos que atacan la madera, sin embargo, son las termitas.

Los insectos siempre han formado parte de la dieta humana, y actualmente se consumen en muchas partes del mundo, principalmente en los trópicos, debido a que en esas regiones los insectos son más abundantes y grandes.
En Europa se sabe que los romanos y los griegos tenían costumbres entomofágicas, e incluso Aristóteles hace mención del uso culinario de las cigarras. Se sabe que los romanos comían "Lucanus cervus".
No obstante, hoy en occidente la sola idea de comer insectos causa repugnancia, si bien la degustación de otros artrópodos, como la langosta de mar, se considera un manjar. Sin embargo, en otras regiones del globo los insectos sirven como alimento para algunos grupos humanos (costumbre denominada entomofagia) y para algunos animales domésticos (peces, por ejemplo). Esas regiones del mundo incluyen a África, Asia, Australia y América Latina. Algunos isópteros son ingeridos en Angola, ciertas especies de orugas en Camerún, una especie de hormiga llamada coloquialmente hormiga culona ("Atta laevigata") es asimismo ingerida en el departamento de Santander (Colombia) y en Congo ciertas especies de insectos son muy apreciadas por su alto contenido proteico, grasas, niacina y riboflavina.

La utilización de insectos y de sus productos como remedio para usos terapéuticos se conoce como entomoterapia; se trata de un sistema médico tradicional en el cual están también involucradas prácticas como amuletos, hechizos, etc. Muchas especies de insectos son empeladas en diversas culturas como ingredientes de recetas o como elementos terapéuticos en el tratamiento de enfermedades tanto físicas como espirituales, en muchos casos sólo como parte de un ritual, y en otros debido a que los insectos pueden contener principios activos de relevancia médica.
Desde tiempos inmemoriales los insectos y algunos productos extraídos de ellos se han usado como medicinas en muchas culturas alrededor del mundo. El papiro Ebers, un tratado médico egipcio datado del siglo XVI antes de Cristo contienen varios remedios obtenidos de insectos y arañas. El gusano de seda ha sido usado en medicina tradicional china desde hace por lo menos 3000 años; las larvas de las moscas de la carne (Calliphoridae) han sido apreciadas desde hace siglos para la curación de heridas infectadas. Muchas especies se usan vivas, cocidas, molidas, en infusión, pomadas y ungüentos, tanto en medicina preventiva como curativa, así como en rituales mágico-religiosos destinados a mantener o mejorar la salud del paciente.

Los insectos son utilizados especialmente para el tratamiento de afecciones respiratorias, renales, hepáticas, estomacales, cardícas, endocrinas, neuronales, circulatorias, dermatológicas, oftalmológicas, pancreáticas, del aparato reproductor, etc.

Según Medeiros "et. al." estos son algunos ejemplos del uso de insectos como medicinas:
Las hormigas son útiles para aliviar numerosas afecciones, como el asma, bronquitis, ciática, cefalea, faringitis, tuberculosis escorbuto, gota, parálisis, reumatismo, lepra y verrugas. Las moscas comunes ("Musca domestica") aplastadas se usan para eliminar los forúnculos inmaduros y para tratar la calvicie. El aceite obtenido de las larvas del coleóptero "Melolontha vulgaris" se ha usado tópicamente en rasguños y heridas y como tratamiento para el reumatismo, y los adultos embebidos en vino se creen útiles para tratar la anemia. Las cucarachas cocidas o molidas con aceite se han empleado en el tratamiento de la epilepsia y el dolor de oído, las tijeretas para curar la otitis y las cigarras fritas en las dolencias de la vejiga urinaria. La miel de "Apis mellifera" se usaba durante las Cruzadas para tratar dolencias del estómago, de la piel y de los ojos. La chinche de cama "Cimex lectularius" para tratar la obstrucción de las vías urinarias y la fiebre cuaternaria. El coleóptero "Lytta vesicatoria" se ha usado tradicionalmente de forma tópica como vesicante y para tratar la alopecia y, por vía oral, se ha prescrito como diurético y contra la incontinencia urinaria; durante la Edad Media fue el afrodisíaco por excelencia por su acción sobre el aparato urogenital que, entre otros efectos, produce priapismo (erección espontánea del pene).

Se sabe que los insectos son especialmente hábiles en la síntesis de compuestos químicos (feromonas, substancias repugnatorias, venenos, toxinas) y en secuestro de tóxicos de las plantas que son luego acumulados, concentrados o transformados; además, dada su enorme diversidad genética, cabe suponer que encierran valiosos compuestos farmacológicamente activos; no obstante la investigación farmacológica moderna ha prestado poca atención a este inagotable potencial.

Desde su origen, la humanidad ha sido afectada, directa o indirectamente, por los insectos. Al transcurrir los siglos y evolucionar el hombre, estos pequeños seres lo han hecho también, convirtiéndose en sus competidores más eficientes y poniendo a prueba la habilidad de aquel para sobrevivir. Los insectos hicieron su aparición en la Tierra hace aproximadamente 300 millones de años, mientras que el hombre es tan joven que apenas cuenta con 1 millón de años. En la actualidad, las tres de cuartas partes de todos los animales vivientes son insectos; se conocen aproximadamente más de 1 millón de especies, pero aún quedan muchas por descubrirse y clasificarse. De esta cifra, se calcula que menos del uno por ciento de las especies son perjudiciales para el hombre y sus pertenencias: los cultivos, los animales domésticos, los granos almacenados, etc.

Este número relativamente pequeño de especies nocivas resulta, sin embargo, de mucha importancia económica cuando se considera su gran habilidad para adaptarse, la capacidad de reproducirse rápidamente en muy corto tiempo y su gran poder de dispersión; factores todos ellos que influyen para que los insectos desarrollen poblaciones enormes, que afectan a la salud del hombre y compiten con él para arrebatarle lo que necesita y desea. A título de ejemplo, se puede citar que una hembra de la mosca doméstica ("Musca domestica"), eficaz diseminadora de gérmenes patógenos, en condiciones favorables y en el paso de solo tres semanas ha completado su ciclo de huevo adulto y, en solo nueve generaciones (más o menos seis meses), considerando que no haya mortalidad, sus descendientes dan lugar a la fantástica cifra de 324 billones de individuos. Asimismo, se ha estimado que la descendencia de una pareja del picudo del algodonero ("Anthonomus grandis") es aproximadamente de 13 millones de seres en una estación, suficientes para destruir muchos campos de ese cultivo.

La lucha contra los insectos nocivos ha evolucionado desde la recolección manual, que aún se practica en algunos lugares, hasta métodos tan modernos como la aplicación aérea de insecticidas, el desarrollo de variedades predadoras resistentes, el uso de enemigos naturales, la liberación de insectos sexualmente estériles y el establecimiento de cuarentenas y reglas de limiten la introducción o dispersión de plagas. Tales métodos de lucha se pueden agrupar de la siguiente manera: a) Culturales; b) Uso de insecticidas; c) Biológicos ; y d) Preventivos y cuarentenas.

La lucha cultural incluye las prácticas rutinarias o esporádicas usadas consciente o inconscientemente, que destruyen mecánicamente los insectos perjudiciales o evitan su daño.

Conociendo el agricultor las plagas y sus hábitos, puede destruir buen número de ellas, a través de las prácticas que sigue para la preparación de su terreno. Muchos de los estados de desarrollo de los insectos nocivos a los diversos cultivos se efectúan en el suelo; de esta manera el agricultor, a medida que barbecha, rastrea, ara y cultiva su terreno, saca muchas de esas delicadas especies a la superficie, dejándolas expuestas a la voracidad de los pájaros y a la acción del sol o de otros agentes desfavorables para su desarrollo. Los riegos por inundación son también efectivos contra los insectos que viven en el suelo.

La lucha contra los insectos por medio de sustancias químicas (insecticidas) data, por lo menos, desde el 1.000 a. C., cuando ya se hablaba de usar el azufre como fumigante para combatir las plagas. Los romanos llegaron a utilizar el veratro, planta de la familia de las liliáceas, para destruir ratas o insectos. Hacia el año 900 d. C., los chinos usaban el arsénico contra las plagas que dañaban sus jardines y fueron ellos quienes descubrieron las propiedades tóxicas de las raíces de la leguminosa "Derris elliptica" (Roxb). Antes de 1800, los persas descubrieron las propiedades tóxicas del piretro. Este insecticida de origen vegetal que aún tiene mucha importancia, se prepara pulverizando o extrayendo el principio tóxico de las flores de la planta "Crysanthemum cinerariaefolium" (Trev) de la familia de las compuestas.

El progreso de la industria de los insecticidas en el mundo fue lento hasta el redescubrimiento, en 1939, por el químico suizo Muller, del famoso DDT, sintetizado por primera vez por el químico alemán Zeidler, en 1874.

Entre los métodos biológicos figuran los encaminados a la reducción o supresión de los insectos nocivos por medio del incremento artificial de sus enemigos naturales o por introducción y fomento de estos. Los enemigos naturales pueden ser animales, como protozoarios, nematodos y otros insectos, o patógenos, como hongos, bacterias y virus.

Este medio de lucha se ha extendido recientemente, y en la actualidad abarca tanto al desarrollo de plantas resistentes al ataque de las plagas como “principio de autodestrucción” de los insectos que se constituyen en plagas. Está dedicándose mucha atención a este procedimiento y se llevan a cabo estudios en las diversas partes del mundo, en los siguientes aspectos:

1. Desarrollo y diseminación de sustancias químicas u otros agentes que provoquen esterilidad sexual, aunque no afecten e otra forma la vida del insecto.

2. Producción y liberación de individuos que posean genes letales que actúen durante el desarrollo del insecto.

3. Liberación de insectos que distribuyen agentes patógenos específicos a ellos mismos.

4. Distribución de preparados hormonales que interfieran en el desarrollo del insecto y

5. Producción y liberación de insectos que han sido esterilizados sexualmente por medio de radiaciones gamma. Este último método ha sido utilizado con gran éxito en la lucha contra la “mosca de las heridas” en la isla de Curazao y en Florida (EE. UU.) regiones de las cuales ha sido erradicado este insecto, que tanto daño causa al ganado.

En este apartado se consideran incluidas las actividades por medio de las cuales se restringe la introducción y dispersión de los insectos nocivos. A tal fin, los diversos países han establecido leyes que regulan el tratamiento, manejo y tráfico de semillas, plantas, animales y productos derivados. A causa del mayor movimiento comercial y turístico y de la rapidez de los transportes modernos, existen muchas más oportunidades para la introducción de insectos en áreas en las que puede prosperar y convertirse en plagas. Esto implica que un mayor número de inspectores, bien adiestrados y que cuenten con los elementos técnicos necesarios, han de ejercer en cada país estrecha vigilancia, cuidando de aplicar con rigor las normas dictadas y de establecer las leyes de cuarentena respectivas, Para que las cuarentenas sean efectivas, deben estar basadas en estudios que determinen la distribución geográfica, vehículos de transmisión y biología del insecto.

Se comprende que las cuarentenas pueden ser de carácter internacional, nacional o de ambos. Las de carácter internacional tienen por objeto impedir la introducción de plagas de un país a otro, las domésticas tratan de evitar la dispersión de insectos nocivos dentro del país. Con objeto de dar una idea de la importancia que tienen estas medidas preventivas y del trabajo que implican, baste citar que en 1960 el servicio de cuarentena de los EE. UU. inspeccionó aviones, barcos, embarques de plantas y sus derivados y varios millones de vehículos provenientes de México y del Canadá.

Se considera que los insectos más grandes son los coleópteros del género "Goliathus" por su tamaño de adulto y su peso de larva, unos . El más largo es "Phryganistria chinensis", midiendo y el más pequeño es el himenóptero "Dicopomorpha echmepterygis" de apenas .

El insecto de mayor tamaño que haya existido fue "Meganeura", un protodonato (similares a las libélulas actuales), con una envergadura de que vivió en el Carbonífero hace más de 300 millones de años.

Los primeros hexápodos conocidos son el colémbolo "Rhyniella" y el insecto "Rhyniognatha", que datan del Devónico Inferior (hace unos 400 millones de años); el primero es una especie bastante derivada y parecida a los actuales Isotomidae y Neanuridae; no está clara la posición de "Rhyniognatha", aunque posee unas mandíbulas dicóndilas similares a las de los monuros, tisanuros y pterigotos. También del Devónico inferior son los restos de un arqueognato, "Gaspea palaeoentognatha".

Pero la diversificación inicial de los insectos debió ocurrir mucho antes, tal vez en el Silúrico; las alas fosilizadas más antiguas son del Carbonífero pero, dado que hay indicios de que "Rhyniognatha" pudo tener alas, la radiación de los insectos alados (Pterygota) debió ocurrir en el Devónico.

Los primeros pterigotas (insectos alados) aparecieron en los inicios del Carbonífero. En el Carbonífero medio existían ya numerosos insectos, perfectamente diferenciados en al menos 11 órdenes entre los que destacan los Palaeodictyoptera†, Diaphanopterodea† y Megasecoptera†, que recuerdan a los odonatos actuales y que en algunos casos alcanzaron envergaduras de 75 cm, y los Ephemeroptera que llegaron a alcanzar los 45 cm de envergadura y de los que existen representantes actuales, mucho menores.

Del Carbonífero superior data el primer hallazgo de un insecto holometábolo; se trata de una larva eruciforme (en forma de oruga) de tipo mecopteroide-himenopteroide.

Durante el Carbonífero superior y el Pérmico inferior aparecen en el registro fósil grandes artrópodos terrestres (protodonatos de más de 70 cm de envergadura, arañas de más de 50 cm y miriápodos de más de 1 m). Este hecho se explica, según Graham et "al.", porque en aquella época, los niveles de oxígeno atmosférico eran muy superiores a los actuales (del orden del 35 % frente al 21 % actual); este valor tan alto favoreció el gigantismo de los artrópodos, al poder incrementar la dimensión de su sistema traqueal.

A lo largo del Pérmico se produjo una progresiva desertización, lo que condujo a importantes cambios en la flora y en la fauna. Los grandes bosques de licopodios se redujeron y fueron reemplazados por gimnospermas; los insectos sufrieron una rápida evolución y se diversificaron mucho. Así, a finales del Paleozoico existían ya 27 órdenes y tuvo lugar la radiación de los insectos holometábolos y la extinción de los paleodictiópteros.

Durante el Mesozoico aparecieron nuevos órdenes como los dípteros, tisanópteros, odonatos en sentido estricto, himenópteros, isópteros, matodeos, etc., pero también se extinguieron órdenes paleozoicos (protodonatos, paraplecópteros, miomópteros, etc.). La gran radiación de los insectos modernos empezó en el Triásico; durante el Jurásico aparecen algunas de las familias actuales, y en el Cretácico, la mayoría de las familias modernas ya existían. Hace 100 millones de años, la organización trófica de los insectos estaba ya bien definida, antes de que las angiospermas aparecieran en el registro fósil.

Los insectos se vieron poco afectados por la extinción masiva del Cretácico-Terciario (la que extinguió a los dinosaurios y a otras muchas criaturas); así, la entomofauna del Cenozoico está compuesta principalmente por las familias actuales, al igual que hace 100 m.a. (84%). En el Jurásico y épocas anteriores la mayor diversidad de fauna de insectos es de familias extintas al presente.

Los insectos alcanzaron su máximo tamaño en el Carbonífero Superior y el Pérmico Inferior (hace unos 300 millones de años), debido a que en estos periodos el contenido de oxígeno en la atmósfera era muy superior al actual (un 35 % frente al 21 % de hoy) y, dado que su aparato respiratorio es un sistema de tubos vacíos que recorren todo el cuerpo (sistema traqueal), si el tamaño del animal aumenta mucho, el aire tiene dificultades en difundirse libremente y llegar a oxigenar todos los órganos internos; al haber más concentración de oxígeno en el aire puede aumentarse el tamaño corporal, ya que, aunque llegue poco este contiene una proporción mayor de oxígeno.

Los insectos son la clase de organismos con mayor riqueza de especies en el planeta (ver Tabla 1). La clasificación de los insectos, como se puede esperar de un grupo tan vasto y diverso, es intrincada y varía según los autores, distando mucho de ser definitiva.

En la siguiente lista, de corte tradicional, se han señalado con un asterisco las agrupaciones que probablemente sean parafiléticas, y por tanto, sin valor taxonómico:
(Subclase) Apterygota*. Son un grupo parafilético que incluye a los insectos más primitivos que en el curso de la evolución nunca han estado provistos de alas ni experimentan metamorfosis (insectos ametábolos). Aparte de estas dos características, claramente plesiomórficas, no comparten ningún carácter derivado (apomorfía) que justifique la existencia de este grupo como entidad taxonómica. Los grupos parafiléticos de esta índole no son aceptados por la actual taxonomía cladística.

Subclase: Pterygota (del griego "pterigotos", alado) es el nombre que recibe el grupo de los insectos alados, los miembros del cual se caracterizan por presentar alas en los segmentos torácico segundo (mesotórax) y tercero (metatórax). La presencia de alas siempre va acompañada de un refuerzo del exoesqueleto (esclerotización) en esos segmentos torácicos, los cuales usualmente se encuentran unidos formando la estructura conocida como Pterotorax. Pueden tener desde una metamorfosis simple a una compleja.

Con la aparición de los primeros estudios basados en datos moleculares y análisis combinados de datos morfológicos y moleculares, parece que la antigua polémica sobre monofilia y polifilia de los artrópodos ha quedado superada, ya que todos ellos corroboran que los artrópodos son un grupo monofilético en el que incluyen también los tardígrados (el clado se ha dado en llamar panartrópodos); la mayoría también proponen la existencia del clado mandibulados. Dentro de los mandíbulados tradicionalmente se consideraba que los miriápodos y hexápodos eran grupos hermanos debido a sus similitudes morfológicas, sin embargo varios estudios moleculares y fósiles han demostrado que los parientes cercanos de los hexápodos (incluido insectos) son los crustáceos con quienes forman el clado Pancrustacea. La hipótesis de que los miriápodos y hexápodos son grupos se ha descartado en gran medida debido a evidencias fósiles, en el cual sugieren que los hexápodos evolucionaron de un grupo de crustáceos. También se ha propuesto que los miriápodos podrían tener una relación genética más próxima a los qulicerados.

Las relaciones filogenéticas de los artrópodos en cuanto a estudios moleculares recientes serían las siguientes:

En lo que respecta a la filogenia interna de los insectos, los siguientes cladogramas muestra las relaciones entre los diferentes grupos y las probables agrupaciones monofiléticas según estudios moleculares recientes:

 
Nótese como Apterygota (Archaeognatha + Thysanura), Palaeoptera (Ephemeroptera + Odonata) y Exopterygota (Plecoptera → Grylloblattodea) aparecen como probables grupos parafiléticos.



Alfabéticamente por país:


</doc>
<doc id="6863" url="https://es.wikipedia.org/wiki?curid=6863" title="Ada Lovelace">
Ada Lovelace

Augusta Ada King, Condesa de Lovelace (Londres, 10 de diciembre de 1815-"íd.", 27 de noviembre de 1852), registrada al nacer como Augusta Ada Byron y conocida habitualmente como Ada Lovelace, fue una matemática, informática y escritora británica, célebre sobre todo por su trabajo acerca de la calculadora de uso general de Charles Babbage, la denominada "máquina analítica". Entre sus notas sobre la máquina, se encuentra lo que se reconoce hoy como el primer algoritmo destinado a ser procesado por una máquina, por lo que se la considera como la primera programadora de ordenadores.

Lovelace fue la única hija legítima del poeta Lord Byron y su esposa Lady Byron. Byron se separó de su esposa un mes después del nacimiento de Ada y dejó Inglaterra para siempre cuatro meses después. Conmemoró la despedida en un poema que comienza: "¿Es tu rostro como el de tu madre, mi bella hija! ¡ADA! Hija única de mi casa y mi corazón". Murió en la Guerra de independencia de Grecia cuando Ada tenía ocho años.

Dedujo y previó la capacidad de los ordenadores para ir más allá de los simples cálculos de números, mientras que otros, incluido el propio Babbage, se centraron únicamente en estas capacidades.

Su madre, Anne Isabella Noel Byron, fue matemática y activista política y social. Su padre fue el conocido poeta George Byron.

Su posición social y su educación la llevaron a conocer a científicos importantes como Andrew Crosse, Sir David Brewster, Charles Wheatstone, Michael Faraday y al novelista Charles Dickens, relaciones que aprovechó para llegar más lejos en su educación. Entre estas relaciones se encuentra Mary Somerville, que fue su tutora durante un tiempo, además de amiga y estímulo intelectual. Ada Byron se refería a sí misma como una "científica poetisa" y como "analista (y metafísica)."

A una edad temprana, su talento matemático la condujo a una relación de amistad prolongada con el matemático inglés Charles Babbage, y concretamente con la obra de Babbage sobre la máquina analítica. Entre 1842 y 1843, tradujo un artículo del ingeniero militar italiano Luigi Menabrea sobre la máquina, que complementó con un amplio conjunto de notas propias, denominado simplemente "Notas". Estas notas contienen lo que se considera como el primer programa de ordenador, esto es, un algoritmo codificado para que una máquina lo procese. Las notas de Lovelace son importantes en la historia de la computación. Otros historiadores rechazan esta perspectiva y señalan que las notas personales de Babbage de los años 1836/1837 contienen los primeros programas para el motor. También desarrolló una visión de la capacidad de las computadoras para ir más allá del mero cálculo o el cálculo de números, mientras que muchos otros, incluido el propio Babbage, se centraron solo en esas capacidades. Su mentalidad de "ciencia poética" la llevó a hacer preguntas sobre el Motor Analítico (como se muestra en sus notas) examinando cómo los individuos y la sociedad se relacionan con la tecnología como una herramienta de colaboración.

Ada Lovelace era la única hija legítima de Anna Isabella y del poeta Lord Byron, quien esperaba que su hijo fuera un niño y se sintió decepcionado cuando Lady Byron dio a luz a una niña. Nació el domingo 10 de diciembre de 1815. La niña lleva el nombre de la media hermana de Byron, Augusta Leigh, y fue llamada "Ada" por el propio Byron. El 5 de enero del año siguiente, a causa de las desavenencias con su marido, su madre abandonó el hogar llevándosela con ella mientras Byron dormía. Annabella se instaló con Ada en una casa que tenían sus padres en Seaham, Durham. El 16 de enero de 1816, por orden de Lord Byron, Lady Byron se fue a la casa de sus padres en Kirkby Mallory, llevando a su hija de cinco semanas con ella. Aunque la ley inglesa en ese momento otorgó la custodia total de los hijos al padre en casos de separación, Lord Byron no intentó reclamar sus derechos parentales, pero solicitó que su hermana lo mantuviera informado sobre el bienestar de Ada. El 25 de abril de 1816 su padre abandonó Inglaterra huyendo de sus acreedores y del escándalo que se cernía sobre él por los rumores de incesto. Meses más tarde, Annabella presentó una demanda de separación. Durante los ocho años que Lord Byron estuvo fuera de su país hasta su muerte escribía con frecuencia a Augusta y preguntaba por la hija de ambos.A Lovelace no se le mostró el retrato familiar de su padre hasta que cumplió 20 años.

Lovelace no tuvo una relación cercana con su madre. A menudo la dejaban al cuidado de su abuela materna Judith, Hon. Lady Milbanke, que la adoraba. Sin embargo, debido a las actitudes sociales de la época, que favorecían al marido en cualquier separación, con el bienestar de cualquier niño que actuara como mitigante, Lady Byron tuvo que presentarse como una madre amorosa para el resto de la sociedad. Esto incluía escribir cartas de ansiedad a Lady Milbanke sobre el bienestar de su hija, con una nota de presentación que decía que debía retener las cartas en caso de que tuviera que usarlas para mostrar preocupación materna.

Desde niña Ada despertó el interés de una sociedad en la que se vivían continuos escándalos. Su madre puso mucho empeño en protegerla, pero solo lo consiguió hasta cierto punto.

Lady Byron quería darle una educación esmerada a su hija, muy parecida a la que ella misma había recibido, pero más exigente. Ada no se podía relacionar con otros niños sin la previa aprobación de su madre, por lo que la mayor parte de su infancia la pasó sola o con adultos. Su educación empezó cuando era muy pequeña; a los cuatro años ya tenía preceptores e institutrices. A los ocho años (en 1824) la jornada normal de Ada comenzaba con clase de música a las 10.00 de la mañana, a las 11.15 tocaba lectura de francés, a las 11.30 clase de aritmética, a las 13.30 hacía deberes, a las 15.15 música otra vez y a las 16.30 finalizaba con ejercicios de francés. Lady Byron le impuso una disciplina estricta basada en un sistema de recompensas y castigos, y también buscando el estímulo intelectual con lecturas y relaciones con intelectuales. Puso mucho empeño en que su hija aprendiera matemáticas, disciplina que ella misma practicaba. En este contexto, Ada conoce a la matemática y científica escocesa Mary Somerville, que durante un tiempo fue su tutora. Somerville, en tanto que mujer científica, se convierte en un importante estímulo y gran influencia en su vida. Ambas, alumna y tutora, comparten aficiones científicas estableciéndose entre ellas una gran complicidad.

A medida que Ada se iba haciendo mayor, su madre pasaba temporadas fuera de casa, en balnearios o en el campo.

Tuvo mala salud, sufrió muchas de las infecciones infantiles y le dolía la cabeza frecuentemente. A los siete años contrajo una enfermedad grave, que la mantuvo postrada durante meses. A los catorce quedó paralítica de las piernas debido a un sarampión, lo cual hizo que dedicara largas horas al estudio y a la lectura.

Cuando Ada tenía 8 años se conoció la muerte de su padre en Grecia, en abril de 1824. Lady Byron se interesó por estrechar lazos con su familia política. El nuevo y sexto lord Byron mantuvo una buena relación con Annabella; este tenía un hijo pequeño un año menor que Ada. Annabella indujo a Ada a escribir una carta a su primo con la esperanza de unir de nuevo a la familia.

En junio de 1826, Ada, que entonces tenía diez años, viajó por primera vez fuera de Inglaterra. Partió con todo un grupo (en el que se incluía su madre) y el viaje duró 15 meses, durante los cuales Ada disfrutó de todo lo nuevo que veían sus ojos, de todo lo que escuchaba, descubría, etc. En el otoño de 1827 acabó su viaje y se instalaron directamente en Bifrons, una mansión de campo muy alejada de la ciudad. En ese palacio no ocurría nada del interés de Ada; además su madre estaba frecuentemente fuera de casa, así que la niña se dedicaba a estudiar y a dejar volar su imaginación. Ese mismo año Ada empezó su formación en matemáticas. A los once años estaba obsesionada con la idea de volar; estaba decidida a inventar una máquina que le permitiera moverse por el aire. Su primer paso, en febrero de 1828, fue construir alas. Investigó diferentes materiales y tamaños. Consideró varios materiales para las alas: papel, seda de aceite, alambres y plumas. Pasó años estudiando la anatomía de las aves para determinar la proporción correcta entre las alas y el cuerpo, y creando bocetos de su soñado proyecto. Decidió escribir un libro, Flyology, ilustrando, con placas, algunos de sus hallazgos. Decidió qué equipo necesitaría; por ejemplo, una brújula, para "atravesar el país por el camino más directo", para que pueda superar montañas, ríos y valles. Su último paso fue integrar steam con el "arte de volar".

A principios de 1829 contrajo una enfermedad grave, posiblemente sarampión, que le causó parálisis en las piernas y la obligó a guardar cama hasta mediados de 1832. Ese periodo la marcó profundamente, pero siguió estudiando. El año de su recuperación se mudó con su madre a Fordhook Manor, una mansión situada en Ealing, una aldea a 12 km del centro de Londres, muy popular entre la aristocracia londinense. Durante este tiempo Ada vivió su primer romance; se enamoró de un joven, hijo de John Hamble, que la ayudaba con los estudios dos horas al día. Vivieron su historia de amor en secreto durante algún tiempo, pero cuando lady Byron se enteró prohibió al joven entrar en su casa y relacionarse con su hija.

El año que cumplía dieciocho años, Ada empezó a asistir a las fiestas de la alta sociedad londinense. En uno de sus primeros eventos conoció a Charles Babbage, la única persona que compartiría su fascinación por las cuestiones de mecánica. Babbage tenía cuarenta y cuatro años en ese momento y era conocido, entre otras cosas, por el proyecto que tenía entre manos: una calculadora mecánica que funcionaba sin la ayuda de un humano, llamada la máquina diferencial.

En esos tiempos en Inglaterra se hizo famoso un avanzado artilugio, el telar de seda de Joseph Marie Jacquard, con el que ella estaba totalmente fascinada. Le maravillaba la posibilidad de idear y construir máquinas, como la de Jacquard, que permitieran al ser humano controlar procesos que anteriormente eran incontrolables o lo eran de una forma errática.

Ada y Babbage se hicieron amigos. Su relación la estimuló intelectualmente; le ayudó a avanzar en sus especulaciones sobre el cálculo hasta concebir una brillante idea: construir un telar de Jacquard aplicado a los números, o en otras palabras: una computadora.

La máquina diferencial de Babbage tenía todos los elementos que entusiasmaban a Ada, y principalmente demostraba que un día las máquinas harían posible volar. La amistad entre el científico y la joven duró toda su vida; se escribieron cartas hasta la muerte de ella.

En 1834 Ada se relacionaba mucho con William King, al que lady Byron había encargado guiar a su hija moralmente; también se encargó de enseñarle matemáticas. Fue durante esas clases cuando Ada se dio cuenta de que su pasión eran las matemáticas. Ya había encontrado la disciplina a la que aplicar su extraordinaria inteligencia. El verano de ese año Ada y su madre recorrieron el norte de Inglaterra, la zona industrial más importante, visitando muchas fábricas, donde pudieron ver el telar de Jacquard en funcionamiento. Durante esa época, madre e hija se relacionaban mucho con Mary Somerville, la matemática más famosa de su país.
Otros conocidos incluyeron a los científicos Andrew Crosse, Sir David Brewster , Charles Wheatstone, Michael Faraday y el autor Charles Dickens.

Ada ya era una habitual de la Corte victoriana y empezaba a asistir a diversos eventos en los que con frecuencia participaba en los bailes y encandilaba a muchos de sus asistentes, los cuales la describían como un ser encantador. Sin embargo, John Hobhouse, que había sido amigo de su padre, fue una excepción y la describió como «una joven estirada y demacrada pero con algún rasgo de su amigo, especialmente su boca». La descripción fue hecha después de su encuentro el 24 de febrero de 1834, en el que Ada dejó claro a Hobhouse que él no le gustaba, pero esta primera impresión no duró mucho tiempo y posteriormente se hicieron amigos.

En la primavera de 1835 Ada conoció a William, lord King. El aristócrata era de una familia muy influyente desde el punto de vista político, social, intelectual y religioso. Poseía varias propiedades importantes y el título de lord tenía más de un siglo de antigüedad, así que lady Byron aprobó su relación. El 8 de julio de 1835 se casaron, convirtiéndose ella en lady King. Su residencia pasó a ser una gran propiedad en Ockham Park (Ockham, Surrey), junto con otra en el Fiordo de Torridon y una más en Londres. Pasó su luna de miel en la Mansión Worthy, situada en Asley Combe (Somerset), la cual había sido construida en 1799 como un refugio de caza y que el propio King amplió con motivo de su luna de miel. Posteriormente la casa se convertiría en su retiro de verano tras volver a ser ampliada.

El matrimonio tuvo tres hijos: Byron, el heredero, nacido el 12 de mayo de 1836; Anne Isabella (llamada Annabella, posteriormente Lady Anne Blunt), nacida el 22 de septiembre de 1837; y Ralph Gordon, nacido el 2 de julio de 1839.

Inmediatamente después del nacimiento de Annabella, Lady King experimentó «una dolorosa y prolongada enfermedad que tardó meses en curarse». Entre 1843 y 1844 su madre le encargó a William Benjamin Carpenter la tarea de educar a los hijos de Ada y de actuar como un «instructor moral»" para su propia hija.

En 1837, William King pasó de barón a vizconde de Ockham y tomó otro título, el de conde de Lovelace. A partir de ese momento, Ada siempre firmaría como Ada Lovelace.

En sus primeros años de matrimonio Ada fue muy feliz, pero la falta de ambición de su marido acabó cansándola, por lo que se refugió de nuevo en las matemáticas. Decidió que necesitaba buscar un buen mentor que la guiara en su trabajo intelectual y en el verano de 1840 su madre le encontró uno: el famoso matemático y lógico Augustus de Morgan. Con su ayuda, Ada progresó rápidamente, pero De Morgan tuvo un problema como profesor. Informó a lady Byron de que su hija no se contentaba con aprender las lecciones como cualquier dama; sus preguntas iban mucho más allá de lo que trataban en las clases y él no quería fomentar esa actitud. De Morgan creía (como casi toda la sociedad en esos tiempos) que las mujeres no estaban hechas para estudiar los fundamentos de las matemáticas ni de otras ciencias. Las preguntas de Ada, según él, eran impropias de una mujer. En definitiva, le inquietaba que su alumna pensase como un hombre. Pero lady Byron y lord Lovelace hicieron caso omiso de la advertencia del profesor y ella continuó con sus estudios.

Durante este tiempo en el que se vio obligada a compaginar su faceta de esposa y madre, el intercambio epistolar con su antigua tutora y amiga, Mary Somerville, representan un gran desahogo para Ada. En esta correspondencia Lovelace hace partícipe a su amiga de su frustración después de la maternidad y de las dificultades para continuar con sus estudios.

En 1841 la madre de Ada les contó a su hija y a Medora Leigh que el padre de ambas era el propio Lord Byron, y el 27 de febrero Ada le escribió a su madre: «no estoy ni siquiera sorprendida. De hecho, simplemente me ha confirmado aquello de lo que, por años, no tuve la más mínima duda, pero hubiera considerado impropio por mi parte el haberle insinuado de alguna manera lo que sospechaba». Ada no culpó a su padre por la incestuosa relación sino a Augusta Leigh: «me temo que ella es inherentemente más malvada de lo que él fue nunca». Esto no evitó que la madre de Ada intentara destruir la imagen que esta tenía de su padre, sino que la llevó a hacerlo con mayor intensidad.

En la década de 1840 Ada protagonizó algunos escándalos, debidos, en primer lugar, a sus afectuosas relaciones con otros hombres. Mantuvo desde 1844 una relación secreta y posiblemente ilícita con el hijo de Andrew Crosse, John; se conoce con poca certeza este asunto ya que Crosse padre destruyó la mayor parte de la correspondencia después de la muerte de Ada como parte de un acuerdo legal.

A pesar de lo que cambió su vida después de casarse, Ada y Babbage mantuvieron su amistad; él los visitaba a ella y a su marido con frecuencia. En el otoño de 1840, Babbage volvió de su estancia en Italia preocupado por su proyecto; cada vez le parecía más difícil llegar a construir el prototipo totalmente operativo de la máquina analítica (o diferencial). No tenía suficientes recursos para financiarla, pero era optimista porque un reconocido científico italiano iba a escribir un artículo sobre su proyecto.

A lo largo de sus enfermedades, continuó su educación. La obsesión de su madre de desarraigar cualquiera de las locuras de las que acusó a Byron fue una de las razones por las que Ada aprendió matemáticas desde temprana edad. William Frend, William King, y Mary Somerville, la destacada investigadora y autora del siglo XIX, la educaron en matemáticas y ciencias. Uno de sus tutores posteriores fue el matemático y lógico Augustus De Morgan. A partir de 1832, cuando tenía diecisiete años, sus habilidades matemáticas comenzaron a surgir, y su interés por las matemáticas dominó la mayor parte de su vida adulta. En una carta a Lady Byron, De Morgan sugirió que la habilidad de su hija en matemáticas podría llevarla a convertirse en "una investigadora matemática, quizás de eminencia de primer nivel".

Lovelace a menudo cuestionaba suposiciones básicas integrando poesía y ciencia. Mientras estudiaba cálculo diferencial, le escribió a De Morgan:

Lovelace creía que la intuición y la imaginación eran críticas para la aplicación efectiva de conceptos matemáticos y científicos. Valoraba la metafísica tanto como las matemáticas, y las veía como herramientas para explorar "los mundos invisibles que nos rodean".

En 1841, Ada escribe a Babbage una carta dejando claro que está interesada en colaborar con él. A Babbage le pareció bien la idea, así ella empezó traduciendo el artículo del científico italiano, Luigi Federico Menabrea. Con la traducción del texto ella tenía dos objetivos: dar a conocer el valioso trabajo de su amigo y cumplir su sueño de alcanzar una vida intelectual que la elevase por encima de las exigencias de la maternidad y el matrimonio. Finalmente llamó a su trabajo "Notas," que consistía en su propio estudio sobre la máquina analítica, y como anexo, la traducción del artículo del italiano. Babbage la asesoró, pero Ada fue enteramente la autora de ese trabajo.

Ada dedica gran parte de su estudio a describir con un lenguaje muy técnico cómo funcionaría la máquina analítica, pero también ofrece una serie de observaciones que dejan clara su aportación teórica. Ella distinguía con claridad entre datos y procesamiento; este pensamiento era revolucionario en su tiempo. Ada aspiraba a crear la informática, que ella llamaba la ciencia de las operaciones. Se dio cuenta de las aplicaciones prácticas de la máquina analítica y llegó incluso a vislumbrar la posibilidad de digitalizar la música. Escribió en las "Notas:" " Supongamos, por ejemplo, que las relaciones fundamentales entre los sonidos, en el arte de la armonía, fueran susceptibles de tales expresiones y adaptaciones: la máquina podría componer piezas musicales todo lo largas y complejas que se quisiera".Ada tenía una idea clara: la máquina analítica y el telar de Jacquard vienen a hacer lo mismo. Una frase clave donde se expresa esto es: "Puede decirse que la primera teje dibujos algebraicos, del mismo modo que el telar de Jacquard teje flores y hojas".Ada expresa con claridad las tres funciones que podía cumplir el invento de Babbage: procesar fórmulas matemáticas expresadas con símbolos, hacer cálculos numéricos (su objetivo primordial) y dar resultados algebraicos en notación literal.

Babbage y Ada concebían la máquina analítica de manera muy distinta. Al primero no le interesaban demasiado sus consecuencias prácticas. A Ada, por el contrario, le obsesionaban las aplicaciones del invento. Ella fue la primera en intuir lo que el invento de Babbage significaba para el progreso tecnológico. Entendió que la tecnología utilizada en el telar de Jacquard y en la máquina analítica podía aplicarse a todo proceso que implicara tratar datos: de este modo abría camino a una nueva ciencia, la de la computación de la información.

Las Notas fueron etiquetadas alfabéticamente de la A a la G. La nota G estaba dedicada a los números de Bernoulli; en este apartado Ada describe con detalle las operaciones mediante las cuales las tarjetas perforadas "tejerían" una secuencia de números en la máquina analítica. Este código está considerado como el primer algoritmo específicamente diseñado para ser ejecutado por un ordenador, aunque nunca fue probado ya que la máquina nunca llegó a construirse. Pero podemos concluir que la nota G es el algoritmo de Ada, así que a ella se la reconoce como la primera programadora de la historia, la primera persona en describir un lenguaje de programación de carácter general interpretando las ideas de Babbage, pero reconociéndosele la plena autoría y originalidad de sus aportes.

Las Notas de Ada se publicaron en la revista "Scientific Memoirs" en septiembre de 1843, con el título de "Sketch of the analytical engine invented by Charles Babbage". Ella firmó con sus iniciales A. A. L., pero pronto se supo a quién correspondían. Su condición femenina perjudicó su trabajo y los científicos no se lo tomaron en serio.

En sus notas, Ada dice que la «máquina analítica» sólo podía dar información disponible que ya era conocida: vio claramente que no podía originar conocimiento. Su trabajo fue olvidado por muchos años, atribuyéndole exclusivamente un papel de transcriptora de las notas de Babbage, cuando en verdad, el trabajo de Lovelace fue, como relata Plant, "mucho más influyente -y tres veces más extenso- que el texto del que se suponía que era meramente accesorio". Este mismo caracterizó su aporte al llamarla "su intérprete;" sin embargo recientes investigaciones muestran la originalidad de su punto de vista sobre las instrucciones necesarias para el funcionamiento de la «máquina analítica». En efecto, Lovelace "había creado el primer ejemplo de lo que más tarde se conocería como programación de computadoras" y es, por lo tanto, la primera programadora de la historia de la computación.

En 1953, aproximadamente cien años después de su muerte, las notas de Ada sobre la máquina analítica de Babbage fueron publicadas bajo su nombre real, estando ahora reconocida dicha máquina como un modelo temprano de ordenador y las notas de Ada como una descripción de su software.

En sus notas, Lovelace enfatizó la diferencia entre el motor analítico y las máquinas de cálculo previas, en particular su capacidad de ser programado para resolver problemas de cualquier complejidad. Se dio cuenta de que el potencial del dispositivo se extendía mucho más allá del mero procesamiento numérico intensivo ("number crunching"). En sus notas, ella escribió:

[La máquina analítica] podría actuar sobre otras cosas además del número, se encontraron objetos cuyas relaciones fundamentales mutuas podrían ser expresadas por las de la ciencia abstracta de las operaciones, y que también deberían ser susceptibles de adaptaciones a la acción de la notación operativa y el mecanismo del motor ... Suponiendo, por ejemplo, que las relaciones fundamentales de los sonidos en la ciencia de la armonía y de la composición musical fueran susceptibles de tal expresión y adaptaciones, el motor podría componer piezas de música elaboradas y científicas de cualquier grado de complejidad o medida.

Este análisis fue un desarrollo importante de las ideas previas sobre las capacidades de los dispositivos informáticos y anticipó las implicaciones de la informática moderna cien años antes de que se realizaran. Walter Isaacson atribuye la idea de Lovelace sobre la aplicación de la informática a cualquier proceso basado en símbolos lógicos a una observación sobre textiles: "Cuando vio algunos telares mecánicos que usaban tarjetas perforadas para dirigir el tejido de hermosos diseños, le recordó cómo la máquina de Babbage usaba tarjetas perforadas para hacer cálculos. "[75] Esta visión es considerada importante por escritores como Betty Toole y Benjamin Woolley, así como por el programador John Graham-Cumming, cuyo proyecto Plan 28 tiene el objetivo de construir la primera máquina analítica completa.

De acuerdo con el historiador de informática y especialista en Babbage Doron Swade:

"Ada vio algo que Babbage en cierto sentido no pudo ver. En el mundo de Babbage, sus máquinas estaban limitadas por el número ... Lo que vio Lovelace -lo que vio Ada Byron- fue que ese número podría representar entidades distintas además de una cantidad. Entonces, una vez que tenías una máquina para manipular números, si esos números representaban otras cosas, letras, notas musicales, entonces la máquina podía manipular símbolos de los qué el número era un ejemplo, según las reglas. Ésta es la transición fundamental de una máquina que es un procesador de números a una máquina para manipular símbolos de acuerdo con las reglas. Es la transición fundamental del cálculo al cómputo -computación de propósito general- y mirando hacia atrás desde la superioridad actual de la informática moderna. si estamos buscando y examinando la historia para esa transición, entonces esa transición fue hecha explícitamente por Ada en ese documento de 1843."

Aunque a Lovelace se la conoce como la primera programadora informática, algunos biógrafos e historiadores de la informática afirman lo contrario.

Allan G. Bromley, en el artículo de 1990 "Difference and Analytical Engines":"Todos menos uno de los programas citados en sus notas habían sido preparados por Babbage entre tres y siete años antes. La excepción fue preparada por Babbage para ella, aunque detectó un "error" en ella. No solo no hay evidencia de que Ada alguna vez haya preparado un programa para el motor analítico, sino que su correspondencia con Babbage muestra que no tenía el conocimiento para hacerlo."Bruce Collier, quien más tarde escribió una biografía de Babbage, escribió en su tesis de doctorado de la Universidad de Harvard de 1970 que Lovelace "hizo una contribución considerable para publicitar la Máquina Analítica, pero no hay evidencia de que haya avanzado en el diseño o la teoría de ninguna manera" .

Eugene Eric Kim y Betty Alexandra Toole consideran "incorrecto" considerar a Lovelace como el primer programador de computadoras, ya que Babbage escribió los programas iniciales para su Motor Analítico, aunque la mayoría nunca se publicó. Bromley observa varias docenas de programas de muestra preparados por Babbage entre 1837 y 1840, todos sustancialmente anteriores a las notas de Lovelace. Dorothy K. Stein considera que las notas de Lovelace son "más un reflejo de la incertidumbre matemática del autor, los propósitos políticos del inventor y, sobre todo, del contexto social y cultural en el que se escribió, que un plan para una investigación científica".

En su libro, Idea Makers, Stephen Wolfram defiende las contribuciones de Lovelace. Aunque reconoce que Babbage escribió varios algoritmos inéditos para Analytical Engine antes de las notas de Lovelace, Wolfram argumenta que "no hay nada tan sofisticado -o tan limpio- como el cálculo de Ada de los números de Bernoulli. Babbage ciertamente ayudó y comentó el trabajo de Ada, pero ella estaba definitivamente el conductor de eso ". Wolfram luego sugiere que el logro principal de Lovelace fue destilar de la correspondencia de Babbage "una exposición clara de la operación abstracta de la máquina, algo que Babbage nunca hizo".

Doron Swade, un especialista en historia de la informática conocido por su trabajo en Babbage, analizó cuatro afirmaciones sobre Lovelace durante una conferencia sobre el motor analítico de Babbage:

Según él, solo el cuarto reclamo tenía "alguna sustancia en absoluto". Explicó que Ada era solo una "principiante prometedora" en lugar de genio en matemáticas, que comenzó a estudiar conceptos básicos de las matemáticas cinco años después de que Babbage concibió el motor analítico por lo que no pudo haber hecho contribuciones importantes, y que ella solo publicó el primer programa de computadora en vez de realmente escribirlo. Pero está de acuerdo con que Ada fue la única persona que vio el potencial del motor analítico como una máquina capaz de expresar entidades distintas de las cantidades.

A finales de la década de 1840, Ada se volvió adicta a las carreras de caballos y junto con algunos de sus amigos intentaron crear un modelo matemático que les ayudara a ganar grandes apuestas. El intento fue un absoluto fracaso, generándole a Ada miles de libras de deuda y provocando que uno de los miembros del grupo la chantajeara con informar a su marido, cosa que finalmente se vio forzada a confesarle. En la última época de su vida pasó continuos apuros económicos.

En el verano de 1852, la salud de Ada empeoró mucho, llevaba años padeciendo agotamiento nervioso y debilidad general, pero no fue hasta ese año que aparecieron los primeros síntomas del cáncer de útero. La enfermedad duró varios meses, durante los cuales su madre tomó el control respecto a sus citas médicas y personales. Por influencia de su madre, decidió dejar de ser materialista y adoptó ideas religiosasque la llevaron a arrepentirse de su vida anterior.

Finalmente, falleció a los treinta y seis años el 27 de noviembre de 1852, acompañada de lady Byron y de William.

Fue enterrada, a petición suya, junto a su padre, en la parroquia del pueblo de Hucknall Torkard, en Nottinghamshire, cerca de la abadía de Newstead.

Sugirió el uso de tarjetas perforadas como método de entrada de información e instrucciones a la máquina analítica. Además introdujo una notación para escribir programas, principalmente basada en el dominio que Ada tenía sobre el texto de Luigi Menabrea de 1842 (que comentó personalmente completándolo con anotaciones que son más extensas que el texto mismo) sobre el funcionamiento del telar de Jacquard así como de la máquina analítica de Babbage. Es reseñable además su mención sobre la existencia de "ceros" o "estado neutro" en las tarjetas perforadas siendo que las tarjetas representaban para la máquina de Babbage números decimales y no binarios (8 perforaciones equivaldrían entonces a 8 unidades).

También introdujo la posibilidad de que la máquina analítica no fuera solo capaz de realizar cálculos matemáticos, sino también de, entre muchas otras cosas, "producir arte" y componer música, literatura... de hecho, afirmaba que el invento sería capaz de realizar cualquier cosa que se le pidiera, siempre y cuando supiéramos cómo ordenárselo.

El lenguaje de programación Ada, creado por el Departamento de Defensa de los Estados Unidos, fue nombrado así en homenaje a Ada Lovelace. El manual de referencia del lenguaje fue aprobado el 10 de diciembre de 1980, y al Estándar de Defensa de los Estados Unidos para el lenguaje "MIL-STD-1815" se le dio el número del año de su nacimiento.

En 1981, la Asociación de Mujeres en Informática inauguró su Premio Ada Lovelace. Desde 1998, la British Computer Society (BCS) ha otorgado la Medalla Lovelace y en 2008 inició una competencia anual para mujeres estudiantes. BCSWomen patrocina el Coloquio Lovelace, una conferencia anual para mujeres universitarias. Ada College es una universidad de educación superior en Tottenham Hale, Londres, centrada en las habilidades digitales.

Desde 1998, la British Computer Society ha premiado con la Lovelace Medal ("medalla Lovelace") en su nombre y en 2008 iniciaron una competición anual para mujeres estudiantes de la informática.
En Reino Unido, el BCSWomen Lovelace Colloquium —conferencia anual para universitarias— también lleva su nombre, Ada Lovelace.

El día de Ada Lovelace ("Ada Lovelace Day") es un evento anual celebrado el segundo martes de octubre cuyo objetivo es el de elevar el perfil de las mujeres en la ciencia, tecnología, ingeniería y matemáticas (las áreas STEM). Pretende visibilizar, dar reconocimiento y apoyo a las mujeres que trabajan en alguno de estos ámbitos, así como a sus descubrimientos e invenciones, introducir a las mujeres más jóvenes en el mundo de la ciencia y la tecnología y crear nuevos referentes femeninos. Esta jornada internacional, que se empezó a celebrar en 2009 gracias a Suw Charman-Anderson, cuenta con la organización de conferencias, talleres, concursos... en todo el mundo. El evento más representativo es el "Ada Lovelace Day Live!", celebrado en Londres. Los eventos han incluido Wikipedia “edit-a-thons” con el objetivo de mejorar la representación de las mujeres en Wikipedia en términos de artículos y editores para reducir no intencionada la brecha de género en Wikipedia.

La "Iniciativa Ada" es una organización sin ánimo de lucro dedicada a incrementar la participación y dedicación de las mujeres en la cultura libre y en los movimientos "open source".

El edificio B de la Escuela Politécnica Superior de la UAM, en la que se imparten los grados de Ingeniería Informática y de Ingeniería de Tecnologías y Servicios de Telecomunicación, recibe el nombre de Edificio B - Ada Lovelace. Así mismo, en la Universidad de Zaragoza se encuentra el edificio Ada Byron, en el que se imparten las mismas titulaciones que en el de la UAM.

El centro de computadoras en el pueblo de Porlock, cerca de donde vivía Lovelace, lleva su nombre. Ada Lovelace House es un edificio propiedad del consejo en Kirkby-in-Ashfield, Nottinghamshire, cerca de donde Lovelace pasó su infancia; el edificio, que anteriormente albergaba las oficinas locales del consejo de distrito, ahora ofrece espacio de oficinas de alta calidad para una serie de empresas locales de nueva creación.

También es la inspiración e influencia de la Academia Ada Developers en Seattle, Washington. La academia es una organización sin fines de lucro que busca aumentar la diversidad en tecnología mediante la capacitación de mujeres, personas trans y no binarias para ser ingenieros de software.

En la Universidad de Málaga se encuentra el Edificio de Investigación Ada Byron, inaugurado en 2014 y dedicado a la tecnología informática.

En 2018, The New York Times publicó un obituario tardío para Ada Lovelace.

El 27 de julio de 2018, el senador Ron Wyden presentó, en el Senado de los Estados Unidos, la designación del 9 de octubre de 2018 como Día Nacional de Ada Lovelace: "Para honrar la vida y las contribuciones de Ada Lovelace como una mujer líder en ciencias y matemáticas". La resolución (S.Res.592) fue considerada y acordada sin enmiendas y con un preámbulo por consentimiento unánime.

En la Universidad del Rosario, en Bogotá, Colombia, se encuentra la sala Lovelace, en su honor, del programa de Matemáticas Aplicadas y Ciencias de la Computación. Se trata de una sala de computación moderna donde se ven cursos de programación, algoritmos, estructuras de datos, entre otros.

En el 197º aniversario de su nacimiento, Google le dedicó su Google Doodle. El "doodle" muestra a Lovelace trabajando en una fórmula entre imágenes que muestran la evolución de los ordenadores.

El poeta uruguayo Eduardo Galeano le dedicó el capítulo "Las edades de Ada", en su libro "Espejosː una historia casi universal" (2009), destacando su papel de pionera al ser la primera programadora de la historia.

El bicentenario del nacimiento de Ada Lovelace se celebró con una serie de eventos, que incluyen: 


Exposiciones especiales fueron exhibidas por el Museo de Ciencias de Londres, Inglaterra y la Biblioteca Weston (parte de la Biblioteca Bodleian) en Oxford, Inglaterra.


Se han localizado seis copias de la primera edición de 1843 de "Sketch of the Analytical Engine" con las notas de Ada Lovelace. Tres se llevan a cabo en la Universidad de Harvard, uno en la Universidad de Oklahoma y uno en la Academia de la Fuerza Aérea de los Estados Unidos. El 20 de julio de 2018, la sexta copia se vendió en una subasta a un comprador anónimo por £ 95,000. Un facsímil digital de una de las copias en la Biblioteca de la Universidad de Harvard está disponible en línea.




</doc>
<doc id="6868" url="https://es.wikipedia.org/wiki?curid=6868" title="Emily Brontë">
Emily Brontë

Emily Jane Brontë (Thornton, Yorkshire, Inglaterra; 30 de julio de 1818-Haworth, Yorkshire; 19 de diciembre de 1848) fue una escritora británica. Su obra más importante es la novela "Cumbres borrascosas" (1847), considerada un clásico de la literatura inglesa, que fue publicada bajo el pseudónimo masculino de Ellis Bell para sortear así las dificultades que tenían las mujeres del en el reconocimiento de su trabajo literario. La novela, considerada inicialmente como salvaje y burda por los críticos, fue reconocida con el tiempo como la expresión más genuina, profunda y contenida del alma romántica inglesa y una de las obras más importantes de la época victoriana.

Fue la quinta de seis hermanos. En 1820 la familia se trasladó a Haworth, donde su padre fue nombrado párroco anglicano.

Su madre murió el 22 de septiembre de 1821 y, en agosto de 1824, Charlotte y Emily fueron enviadas con sus hermanas mayores, María y Elizabeth, al colegio de Clergy Daughters, en Cowan Bridge, Lancashire, donde cayeron enfermas de tuberculosis. En este colegio se inspiró Charlotte Brontë para describir el siniestro colegio Lowood que aparece en su novela "Jane Eyre". María y Elizabeth volvieron enfermas a Haworth y murieron de tuberculosis en 1825. Por este motivo, y por las pésimas condiciones del colegio, la familia sacó a Charlotte y a Emily del internado.

Durante su infancia y tras la muerte de su madre, las tres hermanas Brontë, y Emily, junto a su hermano Branwell, inventaron un mundo de ficción formado por tres países imaginarios —Angria, Gondal y Glass Town— y solían jugar a inventarse historias ambientadas en él.

Para divertirse entre ellas en aquel pueblo aislado, transformaron en su imaginación unos soldados de madera en personajes de una serie de historias que escribieron sobre el reino imaginario de Anglia, propiedad de Charlotte, y su hermano Branwell (1817-1848), y el de Gondal, que era el de Emily y Anne. Se conservan un centenar de cuadernos escritos a mano, iniciados en 1829, de las crónicas de Anglia, pero ninguno de la saga de Gondal, iniciados en 1834, a excepción de algunos poemas de Emily.

En 1838, Emily empezó a trabajar como institutriz en Law Hill, cerca de Halifax. Más tarde, junto a su hermana Charlotte, fue alumna de un colegio privado en Bruselas, hasta que la muerte de su tía la hizo volver a Inglaterra. Emily se quedó a partir de entonces como administradora de la casa familiar.

La gran preocupación de sus últimos años fue el cuidado de Branwell, un hombre fracasado en la pintura, que había sido despedido del modesto empleo que había logrado en las oficinas del ferrocarril y expulsado de la escribanía de un tal señor Robinson por cortejar a su esposa. La adicción a la bebida fue extrema en los últimos años a la que añadió el consumo indiscriminado del opio. Emily, considerada una persona severa, de temperamento intransigente y poco efusiva, le atendió hasta el final de sus días. Permanecía despierta hasta que Branwell, ebrio y desvariando regresaba al hogar, lo que ocurría con frecuencia a altas horas de la noche, para ayudarle a acostarse. Parece que muchas páginas de "Cumbres borrascosas" y algunos de sus poemas fueron escritos durante estas vigilias.

En 1846, Charlotte descubrió por casualidad las poesías que escribía su hermana Emily. Las tres hermanas Brontë decidieron entonces publicar un libro de poesía conjunto.

En el tomo destacan especialmente las poesías de Emily a la que la crítica literaria ha considerado como una de las mejores poetisas de Inglaterra. Las de Anne, aunque no de tan alto nivel, son también superiores a las de Charlotte, cuyo talento era esencialmente novelesco. Sólo se vendieron dos ejemplares del libro, que pasó inadvertido; pero las Brontë no se desanimaron y decidieron escribir una novela cada una.

En 1847 Emily publicó "Cumbres Borrascosas", una novela que se ha convertido en un clásico de la literatura inglesa victoriana a pesar de que inicialmente, debido a su innovadora estructura, desconcertó a los críticos.

Al igual que la de sus hermanas, la salud de Emily fue siempre muy delicada. Murió el 19 de diciembre de 1848 de tuberculosis a los 30 años, tras haber contraído un resfriado en septiembre durante el funeral de su hermano. Fue enterrada en la iglesia de San Miguel de Todos los Santos en Haworth, Yorkshire del Oeste, Inglaterra.

Para evitar los prejuicios que recaían en la época sobre las mujeres escritoras, las tres hermanas utilizaron pseudónimos masculinos: Currer Bell, Ellis Bell y Acton Bell empleando cada hermana las iniciales de su nombre en ellos.

Las tres escribieron novelas con protagonistas femeninas independientes, valientes e inteligentes, que vivían historias de amor muy apasionadas. Sus historias y personajes no eran muy bien vistos en su época y, si firmaba una mujer, la censura era mayor. En una ocasión Charlotte Brontë mandó unos versos en busca de apoyo al poeta Robert Southey y recibió como toda respuesta lo siguiente: «La literatura no es asunto de mujeres y no debería serlo nunca». No fue hasta que sus libros tuvieron éxito que Charlotte Brontë decidió descubrir su verdadera identidad.

"Cumbres Borrascosas" ha sido llevada varias veces al cine desde la época muda. La adaptación más valorada mundialmente es la que William Wyler dirigió en 1939 con Laurence Olivier, Merle Oberon y David Niven en los papeles protagonistas. Pese a ser, como todas, una versión parcial de la novela, la cinta consigue no traicionar el espíritu de la historia y resulta dramática, romántica y viva. En 1953, Luis Buñuel hizo una adaptación aún más fiel a la novela en México, titulada "Abismos de pasión", donde los personajes no son tan seductores como en la versión de 1939. Además, no se preocupa por adaptarla al gusto de Hollywood, sino que rescata sobre todo el espíritu extremo de los personajes. No hace ningún esfuerzo en hacer «querible» a Heatchcliff, porque lo quiere como lo expone Brontë: violento, burdo, inadaptado, resentido, y profundamente enamorado. No se esfuerza por dar a Catherine pinceladas de «humanidad», porque la quiere como es: caprichosa, histérica, frágil, con los defectos de toda niña mimada y profundamente enamorada. Además, la brecha de la diferencia social entre ellos dos se hace más notoria.





</doc>
<doc id="6869" url="https://es.wikipedia.org/wiki?curid=6869" title="27 de noviembre">
27 de noviembre

El 27 de noviembre es el 331.º (tricentésimo trigésimo primer) día del año en el calendario gregoriano y el 332.º en los años bisiestos. Quedan 34 días para finalizar el año.












































</doc>
<doc id="6881" url="https://es.wikipedia.org/wiki?curid=6881" title="Helianthus annuus">
Helianthus annuus

Helianthus annuus, llamado comúnmente girasol, calom, jáquima, maravilla, mirasol, tlapololote, maíz de teja, acahual (del náhuatl "atl", agua y "cahualli", dejado, abandonado) o flor de escudo (del náhuatl "chimali", escudo y "xochitl", flor), es una planta herbácea anual de la familia de las asteráceas originaria de Centro y Norteamérica y cultivada como alimenticia, oleaginosa y ornamental en todo el mundo.

Plantas anuales (como lo indica su nombre específico latín: "annuus") que pueden medir tres metros de alto. Los tallos son generalmente erectos e hispidos. La mayoría de las hojas son caulinares, alternas, pecioladas, con base cordiforme y bordes aserrados. La cara inferior es usualmente más o menos hispida, a veces glandulosa y la superior glabra. El involucro es hemiesférico o anchado y mide 15-40 mm y hasta más de 20 cm. Las brácteas involucrales llamadas filarios se encuentran en número de 20-30, y hasta más de 100, ovaladas a lanceoladas —brutalmente estrechadas en el ápice— nerviadas longitudinalmente, con el borde generalmente hispido o hirsuto, al igual que sus caras exteriores, raramente son glabras. Receptáculo con escamas centimétricas tridentadas, con el diente mediano más grande y la punta hirsuta. Las lígulas, en número de 15-30, y hasta 100, de color amarillo a anaranjado hasta rojas, miden 2,5-5 cm; los flósculos, de 150 hasta 1000, del mismo color con los estambres pardos-rojizos. Los frutos son aquenios ovalados, algo truncados en la base, de 3-15 mm de largo, glabros o casi, estriados por finísimos surcos verticales, de color oscuro, generalmente casi negras —aunque pueden ser también blanquecinas, rojizas, de color miel o bien moteados o con bandas longitudinales más claras—. El vilano consiste en dos escamas lanceoladas de 2-3,5 mm acompañadas, o no, de hasta cuatro escamitas obtusas de 0,5-1 mm, todas tempranamente caedizas. (como lo indica su nombre específico latín: "annuus")

El girasol es nativo del continente americano, más precisamente de Norteamérica y Centroamérica. Su cultivo se remonta al año 1000 a. C., pero existen datos que indican que el girasol fue domesticado primero en México alrededor de 2600 años a. C. En muchas culturas amerindias, el girasol fue utilizado como un símbolo que representaba a la deidad del sol, principalmente los aztecas y otomíes en México, y los incas en el Perú.

Francisco Pizarro lo encontró en Tahuantinsuyo (Perú, Bolivia, Ecuador), donde los nativos veneraban una imagen de girasol como símbolo de su dios solar.

Los españoles llevaron figuras de oro de esta flor, así como semillas, a Europa a comienzos del siglo XVI, y desde allí se extendió a prácticamente todo el mundo,donde hoy es cultivado intensivamente en numerosos países, con fines alimenticios —a partir de sus frutos— y ornamentales.

Hay distintos tipos de girasoles: oleaginosos, de confitura o confitería, de alto contenido de ácido oleico y ornamentales.

El girasol contiene hasta un 58 % de aceite en su fruto, aceite que se utiliza para cocinar, y también para producir biodiésel. El aceite de girasol virgen —obtenido del prensado de las pipas—, aunque no posee las cualidades del aceite de oliva, sí posee una cantidad cuatro veces mayor de natural que este.
El "orujo" que queda después de la extracción del aceite se utiliza como alimento para el ganado.
Los tallos contienen una fibra que puede ser usada en la elaboración del papel, y las hojas pueden servir también de alimento para el ganado.

En Sonora se usa en diversas enfermedades como pleuresía, resfriado, catarro, para las llagas, heridas, trastornos nerviosos, dolor de cabeza, y en el estado de Veracruz se indica para las reumas.

En la mayoría de los casos se recomienda emplear el tallo. Sin embargo, para aliviar las reumas se aconseja hacer una maceración en alcohol de las semillas y con esto friccionar las partes afectadas.
El "Códice Florentino", en el siglo XVI relata: se usa para el dolor de ojos, el calor interior (fiebre), para la digestión y purifica los intestinos.

En el siglo XX, Maximino Martínez refiere los usos siguientes: afrodisíaco, anticatarral y antipalúdico.

Los frutos del girasol—llamados también pipas o semillas de girasol (aunque en realidad la semilla con cáscara es el fruto en sí)—suelen ser consumidos tras un leve tostado y, en ocasiones, un leve salado; se consideran muy saludables ya que, al igual que el aceite de girasol, son ricos en alfa-tocoferol (vitamina E natural) y minerales.

La época de siembra para el cultivo de secano varía según la latitud, pero dura aproximadamente un mes a contar del inicio del verano. La siembra se debe efectuar en hileras separadas a 0,70 m, con una densidad de siembra de cuatro plantas por metro lineal.

Es un cultivo poco exigente en el tipo de suelo, aunque prefiere los arcillo-arenosos y ricos en materia orgánica, pero es esencial que el suelo tenga un buen drenaje y la capa freática se encuentre a poca profundidad.

La germinación de las semillas de girasol depende de la temperatura y de la humedad del suelo, siendo la temperatura media de 5 °C durante 24 horas.

La profundidad de siembra se realiza en función de la temperatura, humedad y tipo de suelo.

Las plantas que proceden de siembras superficiales germinan y florecen antes que las procedentes de siembras profundas.
Algunas variedades desarrolladas recientemente tienen cabezas decaídas. Estas variedades son menos atractivas para los jardineros que crían las flores como ornamento, pero atractivas para los granjeros, porque pueden reducir los daños producidos por los pájaros y las pérdidas por enfermedades vegetales.

"Helianthus annuus" fue descrita por Carlos Linneo y publicado en "Species Plantarum" 2: 904-905. 1753.

El nombre girasol se refiere a que el capítulo floral gira según la posición del sol (heliotropismo). Otro nombre común mirasol es más preciso, ya que indica que es un heliotropismo/fototropismo positivo, o sea hacia la luz. Esta orientación variable se manifiesta cuando la planta todavía es joven; cuando madura, ya no gira y se queda en una posición fija hacia el oriente.

Algunos expertos apuntan que un tropismo tiene que influir necesariamente en el crecimiento de la planta; por lo que la orientación de la flor hacia el sol no se consideraría un heliotropismo ya que no influye en la dirección del crecimiento del girasol.

Las hormonas vegetales son las que le dan fototropismo positivo al girasol joven: permiten un mayor crecimiento de los tejidos en un sentido, lo que facilita el giro de la planta. Las hormonas vegetales controlan todas las funciones de la planta: crecimiento, floración, maduración de frutos, fototropismo, etc. Las más conocidas son las de la familia de las auxinas (crecimiento y geotropismo), las giberelinas (proliferación celular), las citoquininas (germinación y floración), el ácido abscísico (aletargamiento) y el etileno (maduración y floración). El control de dichas hormonas se debe a la interacción de diferentes factores como el sol, la luz directa, la gravedad, el calor, las cantidades de rayos UV, o a la relación con otros agentes químicos, hormonales o no.

Visión estática del movimiento de la inflorescencia del girasol en busca de luz.
Castellano: copa de Júpiter (4), corona de rey, corona real (4), flor de sol, flor del sol (3), giganta, gigantea, girasol (30), girasoles, heliantemo, mirasol (9), mirasol común, mirasoles, pipa, rosa de Hiericó, rosa de Jericó, sol de las Indias (3), tornasol (7), trompeta de amor, yerba del sol. Las cifras entre paréntesis indican la frecuencia del vocablo en España.
En el sur de México se llama chimalatl.

H. Vogel ha propuesto un modelo para el patrón de distribución de las flores (y semillas) en el capítulo de girasol. Este modelo se expresa en coordenadas polares,
donde θ es el ángulo, "r" es el radio o distancia desde el centro y "n" es el número índice de la flor y "c" es una constante. Es una forma de espiral de Fermat. El ángulo de 137.5° se relaciona con la proporción áurea y provee la forma más eficiente de empaquetamiento de las flores. Este modelo ha sido utilizado para realizar representaciones gráficas de los capítulos de girasol por computadora.




</doc>
<doc id="6882" url="https://es.wikipedia.org/wiki?curid=6882" title="Permacultura">
Permacultura

La permacultura es un sistema de principios de diseño agrícola y económico, político y social basado en los patrones y las características del ecosistema natural.

Tiene muchas ramas, entre las que se incluyen el diseño ecológico, la ingeniería ecológica, diseño ambiental, la construcción y la gestión integrada de los recursos hídricos, que desarrolla la arquitectura sostenible y los sistemas agrícolas de automantenimiento modelados desde los ecosistemas naturales.

El término «permacultura» (como un método sistemático) fue acuñado por primera vez por los australianos Bill Mollison y David Holmgren en 1978.

La palabra permacultura (del inglés "permaculture") es una contracción, que originalmente se refería a la ‘agricultura permanente’, pero se amplió para significar también "cultura permanente", debido a que se ha visto que los aspectos sociales son parte integral de un sistema verdaderamente sostenible, inspirado en la filosofía de la Agricultura Natural de Masanobu Fukuoka.

Desde sus inicios a finales de los años 1970, la permacultura se ha definido como una respuesta positiva a la crisis ambiental y social que estamos viviendo.

En palabras de Bill Mollison: 

En 1929, Joseph Russell Smith tomó un término anteriormente conocido, como subtítulo para su obra: “"Tree Crops: A Permanent Agriculture"” (traducido del inglés como “"Cultivo de árboles: una agricultura permanente"”), libro en el que resume su larga experiencia, experimentando tanto con frutas y frutos secos, como con cultivos para la alimentación humana y animal.

Smith vio el mundo como un todo interrelacionado y sugirió sistemas mixtos de árboles y cultivos debajo de ellos. Este libro inspiró a muchos individuos decididos a lograr una agricultura más sostenible, tales como Toyohiko Kagawa quien fue pionero en el cultivo de los bosques en Japón en la década de 1930.

La definición de agricultura permanente, como la que se puede sostener indefinidamente, fue apoyada por P. A. Yeomans, australiano, en su libro: “"Water for Every Farm"” (traducido del inglés como: “"Agua para todas las granjas"”). Yeomans introdujo un enfoque basado en la observación del uso de la tierra en Australia en la década de 1940, y el diseño Keyline como una forma de gestionar el suministro y distribución de agua en la década de 1950.

Trabajos de Stewart Brand fueron una influencia temprana señaló Holmgren. Otras influencias tempranas incluyen a Ruth Stout y Esther Deans, pioneras en la jardinería sin excavación y Masanobu Fukuoka que, a finales de 1930 en Japón, comenzó a abogar por huertos de siembra directa (labranza cero) y, jardines y agricultura natural.

David Holmgren ideó una ética de la permacultura basada en tres principios éticos fundamentales:

Nuestro planeta es un conjunto de sistemas complejos, interdependientes, en proceso de evolución y fuera de nuestro entendimiento completo. Todas las especies, todos los procesos, todos los elementos tienen un valor en sí mismo, más allá de su valor económico o funcional para el hombre.

Para poder hacer sostenible un diseño permacultural, se tienen que integrar con una perspectiva a largo plazo los ciclos naturales de materiales y los flujos energéticos dentro de los sistemas fundamentales que sostienen la vida. “La gente a menudo asocia el cuidado de la Tierra con algún tipo de gerencia planetaria, como un reflejo del concepto de la Tierra como nave espacial popularizado inicialmente a fines de los 60 y principios de los 70. Estas ideas han sido poderosas en la forja de un entendimiento de la crisis global ambiental y otras crisis de carácter ético, pero a menudo se quedan en abstracciones separadas de nosotros.

Aquí se hace evidente la relación entre la libertad y responsabilidad. Para garantizar el derecho de diseñar libremente el uso de los recursos básicos, es necesario llegar a un equilibrio entre las necesidades individuales y comunes. Esto da vida a la demanda ética de la justicia social: Todos los seres humanos deben tener el mismo derecho y acceso a los recursos y conocimientos. El cuidado de la gente comienza por uno mismo, pero se expande en círculos crecientes para incluir a la familia, el vecindario, y comunidades locales y mayores. En este sentido sigue el patrón de casi todos los sistemas éticos tradicionales. Para tener la capacidad de contribuir con el bien mayor, uno debe estar sano, fuerte y seguro. Visto desde esta perspectiva, el principio significa: Cuidarse a sí mismo, a los seres queridos y a la comunidad.



- Al asegurarnos que todos los productos y excedentes están dirigidos hacia los objetivos anteriores, podemos empezar a construir una cultura verdaderamente sostenible y permanente.

- Este componente económico también tiene que integrar la limitada tolerancia y capacidad regenerativa de nuestro planeta tierra. Como enunciado se puede añadir, en estos tiempos más que nunca:

Se puede utilizar la frase "Celebrar la abundancia en la naturaleza y aceptar sus limitaciones". Así fue planteado este tercer principio por Bill Mollison en el Manual de Diseñadores.

Los principios de diseño que son la "Base Conceptual" de la Permacultura, y se derivaron de la ciencia de la ecología de sistemas y el estudio de ejemplos pre-industriales de uso sostenible de la tierra. La permacultura se base en varias disciplinas, incluyendo la agricultura natural, agricultura ecológica, agroforestería, agricultura integrada, el desarrollo sostenible y la ecología aplicada

La permacultura se ha aplicado con mayor frecuencia para el diseño de la vivienda y el paisajismo, la integración de técnicas como la agroforestería, bioconstrucción, y el Sistema de captación de agua de lluvias en el contexto de los principios de Diseño de Permacultura y la teoría.

A partir de estos principios éticos, Holmgren definió 12 principios de diseño de la permacultura. Enfocados bajo la teoría de sistemas, sirven como guías generales para orientarnos dentro de la enorme complejidad natural y social a la hora de desarrollar un sistema sostenible:



Las capas son una de las herramientas que se utilizan para diseñar ecosistemas funcionales que son sostenibles y de beneficio directo para los humanos. Un ecosistema maduro tiene un gran número de relaciones entre sus partes componentes: árboles, sotobosque, la cobertura del suelo, el suelo, los hongos, insectos y animales. Debido a que las plantas crecen a diferentes alturas, una comunidad de formas de vida diversas es capaz de crecer en un espacio relativamente pequeño, ya que cada capa se apila una encima de otra. En general, existen siete capas reconocidos en un bosque de alimentos, aunque algunos practicantes de permacultura también incluyen hongos como octava capa.


Hay muchas formas de gremios, incluyendo gremios de plantas con funciones similares (que podrían intercambiarse dentro de un ecosistema), pero la percepción más común es la de un gremio de apoyo mutuo. Un gremio tal es un grupo de especies en las que cada uno proporciona un conjunto único de funciones diversas que trabajan en conjunto, o en armonía. Gremios de apoyo mutuos son grupos de plantas, animales, insectos, etc., que trabajan bien juntos. Algunas plantas pueden ser cultivadas para la producción de alimentos, algunos tienen raíces primarias que extraen nutrientes desde las profundidades de la tierra, algunas son fijadoras de nitrógeno, algunas atraen insectos benéficos, y otras repelen insectos dañinos. Cuando se agrupan juntos en un acuerdo mutuamente beneficioso, estas plantas forman un gremio.

El Efecto de borde en la ecología es el efecto de la yuxtaposición o puesta a lado de ambientes contrastantes en un ecosistema. Los permaculturistas argumentan que, donde los sistemas muy diferentes se encuentran, hay un área de intensa productividad y conexiones útiles. Un ejemplo de esto es la costa; donde la tierra y el mar se encuentran hay una zona especialmente rica que se encuentra con un porcentaje desproporcionado de las necesidades humanas y animales. Así que esta idea se desarrolla en diseños permaculturales utilizando espirales en el jardín de hierbas o la creación de estanques que tienen costas ondulantes en lugar de un simple círculo o un óvalo (aumentando así la cantidad de borde para un área dada).

A mediados de la década de los años 1970 dos ecologistas de Australia, el doctor Bill Mollison y David Holmgren, comenzaron a desarrollar una serie de ideas que tenían la esperanza de poder utilizar para la creación de sistemas agrícolas estables. Lo hicieron como respuesta a lo que consideraban como el rápido crecimiento en el uso de métodos agroindustriales destructivos tras la Segunda Guerra Mundial, que de acuerdo a su criterio estaban envenenando la tierra y el agua, reduciendo drásticamente la biodiversidad, y destruyendo billones de toneladas de suelo que anteriormente mantenía paisajes fértiles. Una aproximación denominada 'permacultura' fue el resultado y se dio a conocer con la publicación del libro "Permaculture One" en 1978. El libro tuvo un éxito inmediato en Australia, provocando mucho debate. La aparición de una revista (The International Permaculture Magazine), una miniserie televisiva con Bill Mollison como protagonista, y varias decenas de cursos que éste dictó a finales de los 70 y principios de los 80 contribuyeron a internacionalizar la permacultura y a forjar su imagen de herramienta práctica para la construcción de hábitats sostenibles.

Tras la publicación de "Permaculture One", Mollison y Holmgren refinaron y desarrollaron sus ideas, con ambos originadores diseñando cientos de 'terrenos de permacultura' y escribiendo varios libros. Mollison dio clases en más de 80 países y el "Curso de Diseño" de dos semanas de duración, se enseñó a muchos cientos de estudiantes. A comienzos de la década de 1980, el concepto avanzó desde ser predominantemente un diseño de sistemas agrícolas a ser un proceso de diseño más plenamente holístico para crear hábitats humanos sostenibles. A mediados de la década de 1980, multitud de estudiantes se habían convertido en exitosos prácticos, comenzado a enseñar el método; en un corto periodo de tiempo se establecieron grupos de permacultura, proyectos, asociaciones e institutos en más de 100 países.

En el transcurso de sus viajes por Asia, África y América Latina, Mollison encontró y contribuyó a popularizar conceptos y prácticas ancestrales que habían contribuido a la sostenibilidad de las antiguas culturas agrícolas y cazadoras. Muchos de estos conceptos fueron explicados y revalorizados, y pasaron a formar parte del aspecto técnico de la permacultura. Muy pronto se hizo evidente que los conceptos de diseño que manejaba la permacultura podían ser aplicados no solamente a la producción agropecuaria y forestal, sino a muchos aspectos de la vida humana, como la construcción, la educación, la economía y la organización social en general, abarcando todos los temas esenciales en el diseño de sistemas sustentables, de forma integrada.

La permacultura está en la actualidad bien establecida a lo largo y ancho del mundo, existiendo muchos ejemplos de su uso. Zimbabue tiene 60 escuelas diseñadas utilizando la permacultura, con un equipo nacional trabajando en la unidad de desarrollo de currículos escolares. El Alto Comisionado de Naciones Unidas para los Refugiados (ACNUR) ha elaborado un informe sobre el uso de la permacultura en situaciones de refugio, tras su exitoso uso en los campos de Sudáfrica y Macedonia. En Costa Rica, un grupo de permaculturistas hace talleres y huertas urbanas en acuerdo con permacultura.

Un hábitat diseñado según los principios de la permacultura se entiende como un sistema, en el cual se combinan la vida de los seres humanos de una manera respetuosa y beneficiosa con la de los animales y las plantas, para proveer las necesidades de todos de una forma adecuada.

En el diseño de estos sistemas se aplican ideas y conceptos integradores de la teoría de sistemas, biocibernética y ecología profunda. La atención no solo se dirige hacia los componentes individuales (=elementos), sino hacia las relaciones entre estos elementos y su uso óptimo para la creación de sistemas productivos.

Planificación, implementación y mantenimiento componen el proceso de diseño permacultural, el cual se enfoca tanto en una optimización sucesiva del sistema para las necesidades de ahora, como también en una futura productividad, abierta para ser desarrollada y refinada por las generaciones que vienen.

El proceso de diseño tiene como objetivo una integración óptima de las necesidades ecológicas, económicas y sociales del sistema, de modo que a largo plazo se pueda autorregular y mantener en un equilibrio dinámico mediante interferencias mínimas.

El modelo para esto son los procesos de autorregulación que podemos observar diariamente en sistemas ecológicos como por ejemplo en los bosques, lagos o los océanos.

El pensamiento sistémico y una acción motivada por esto buscan superar de una manera consciente el procedimiento lineal-causal todavía predominante, cuyas consecuencias destructivas están hoy más y más a la vista de todos.

Como estamos viviendo en sistemas y estamos rodeados por ellos, el pensamiento y la acción lineal-causal no pueden solucionar nuestros problemas, solamente trasladarlos en el tiempo y espacio. De esta forma nos lleva a la conclusión equivocada de ver la influencia que más nos “estorba” en este momento como la causa única de nuestros problemas. Además, por su tendencia de implementar solamente correcciones sintomáticas, produce constantemente nuevos problemas muchas veces mayores a las anteriores.

El concepto libre de ideologías de la permacultura se abre tanto a los nuevos conocimientos y tecnologías como a los conocimientos “antiguos”, milenarias, de todas las culturas y apoya su fusión creativa en innovadoras estrategias de diseño.

Cada pétalo de esta flor es uno de los ámbitos de nuestra cultura que dadas las cosas como están en el mundo, necesitan re-diseño. En el centro de la flor están los principios éticos y de diseño de la permacultura y alrededor de cada pétalo están los principios, estrategias, métodos, prácticas o elementos que tendremos que escoger o crear y quizá adaptar a nuestra realidad.

El uso del término "permacultura" ha sido motivo de disputa. Bill Mollison afirmó que el término estaba protegido por la leyes de propiedad intelectual, en concreto, uno de sus libros dice: "El contenido de este libro y la palabra PERMACULTURA están protegidos por las leyes de propiedad intelectual". Estas afirmaciones fueron ampliamente aceptadas por la comunidad permacultora. Sin embargo, las leyes de propiedad intelectual no protegen nombres, ideas, conceptos, sistemas y maneras de hacer cosas, sólo protegen la expresión y descripción de una idea, pero no la idea en sí misma. Con el tiempo, Bill Mollison admitió que estaba equivocado y que no se puede aplicar restricción alguna al uso de la palabra "permacultura" desde el punto de vista de las leyes de propiedad intelectual. 

En el año 2000, Bill Mollison y su Instituto Norteamericano de la Permacultura solicitaron el registro la marca "permacultura", concretamente la variante de marca de servicio (en inglés, "service mark") cuando fuera empleada en seminarios, cursos formativos y talleres. La marca hubiera permitido a Bill Mollison y sus dos institutos de permacultura (uno en EE.UU y otro en Australia) establecer guías sobre quién puede enseñar lo que es la permacultura y de qué manera debe de ser enseñada. Él mismo fue promotor en 1993 de un sistema de certificación y capacitación de enseñantes de la permacultura. Los intentos por registrar la marca no tuvieron éxito. No obstante, de nuevo en 2001 Bill Mollison solicita registrar la marca "Curso de diseño de permacultura" y "Diseño permacultor" en Australia. Dichas solicitudes fueron retiradas en 2003. Posteriormente, en 2009 solicita el registro de la marca "Permacultura: Un manual para diseñadores" e "Introducción a la Permacultura", asociada a sus dos libros. Mollison retiró dichas solicitudes en 2011. A pesar de dichos intentos, nunca se materializó el registro de la marca "Permacultura" en Australia.







</doc>
<doc id="6884" url="https://es.wikipedia.org/wiki?curid=6884" title="Cosmogonía">
Cosmogonía

Cosmogonía (del griego κοσμογονία, "kosmogonía" o κοσμογενία, "kosmogenía", derivado de κόσμος, "kosmos" ‘mundo’ y la raíz γί(γ)νομαι, "gígnomai" / γέγονα, "gégona", ‘nacer’) es la narración mítica que pretende dar respuesta al origen del universo y de la propia humanidad.

Generalmente, en ella se nos remonta a un momento de preexistencia o de caos originario, en el cual el mundo no estaba formado, pues los elementos que habían de constituirlo se hallaban en desorden; en este sentido, el relato mítico cosmogónico presenta el agrupamiento —paulatino o repentino— de estos elementos, en un lenguaje altamente simbólico, con la participación de elementos divinos que pueden poseer o no atributos antropomorfos.

La cosmogonía pretende establecer una realidad, ayudando a construir activamente la percepción del universo (espacio) y del origen de dioses, la humanidad y elementos naturales. A su vez, permite apreciar la necesidad del ser humano de concebir un orden físico y metafísico que permita conjurar el caos y la incertidumbre.

Desde la antigüedad, los mitos han sido relatos compuestos por acciones simbólicas que se transmitieron por generaciones para ofrecer respuestas sobre el origen del universo y del hombre, relacionándolos con dioses y mensajeros que actuaban en nombre de estos.

Los mitos ofrecieron a las distintas culturas una visión integradora del mundo, al facilitar su percepción de los fenómenos que le parecían extraños a una creencia colectiva que dio origen a los que los acompañaron y proporcionaron la seguridad psicológica para la construcción de una identidad para la vida en comunidad.

En los mitos, algunos investigadores han señalado que los dioses suelen representar las fuerzas elementales de la naturaleza, que pueden percibir, de los cuales se derivan los fenómenos naturales que condicionaron sus vidas. Sin embargo, este postulado simplista y etnocéntrico ha ido quedando progresivamente superado para dar cuenta del mito como un especial espacio simbólico a partir del cual el ser humano puede atribuir significados (conscientes e inconscientes) a deidades, héroes y acciones míticas en estrecha relación con la vida psíquica, intersubjetiva, social y cultural. Esto quiere decir que un determinado mito puede tener relación con el proceso de madurez interno de determinada persona, pero también puede servir para generar cohesión social en una comunidad, o para legitimar determinadas estructuras de poder; no existe una explicación unívoca.

La palabra «mito» deriva del griego "mythos", que significa ‘palabra’ o ‘historia’. Un mito tendrá un significado diferente para el creyente, para el antropólogo y para el filólogo. Esa es precisamente una de las funciones del mito: consagrar la ambigüedad y la contradicción. Un mito no tiene por qué transmitir un mensaje único, claro y coherente.

La mitología no es sino una alternativa de explicación frente al mundo, que recurre a la metáfora como herramienta creativa. Entonces, los relatos se adaptan y se transforman de acuerdo a quien los cuenta y el contexto en el que son transmitidos. Los mitos no son dogmáticos e inmutables sino que son fluidos e interpretables.

En general, las narraciones cosmogónicas no solo representan una configuración del universo, desde el punto de vista de estudiar lo que es en tanto que es y existe como sustancia de los fenómenos (visión ontológica), sino que de ellas también se derivan ciertas necesidades éticas para la preservación en la unidad del mismo.

Las cosmogonías griegas narran el origen del mundo que parte del caos, para que en un acto de creación divina se imponga el orden. Esta acción marcará el principio del ser y del bien para el pensamiento griego, en donde el ser no puede ser lo informado porque el mal se acerca a la carencia de límite. Esta visión la recoge Hesíodo en su "Teogonía" y también Platón en el relato del demiurgo presente en el "Timeo". Cabe destacar que en las cosmogonías griegas el orden se va imponiendo de una manera violenta, por las luchas entre los dioses, mientras que en la cosmogonía judeocristiana el orden surge por el poder de la Palabra de Dios.

En la cosmogonía judeocristiana, el origen del mundo está presente en el "Génesis" (el primer libro de la "Biblia"), que relata cómo Dios empezó a crear el mundo «en un principio». La teología cristiana utiliza el término "ex nihilo" para sustentar y referirse a la creación universal partiendo de la nada. 
Génesis 1 Reina-Valera 1960 (RVR1960) -La creación:
1. En el principio creó Dios los cielos y la tierra. 

2 Y la tierra estaba desordenada y vacía, y las tinieblas estaban sobre la faz del abismo, y el Espíritu de Dios se movía sobre la faz de las aguas. 

3 Y dijo Dios: Sea la luz; y fue la luz. 

4 Y vio Dios que la luz era buena; y separó Dios la luz de las tinieblas.

5 Y llamó Dios a la luz Día, y a las tinieblas llamó Noche. Y fue la tarde y la mañana un día.
La creación es un proceso que tiene lugar con un principio: 'Hágase la luz', y luego separación de: la tierra de los cielos, la tierra de las aguas, la luz de la oscuridad. Es decir, se procede por separación de componentes partiendo del caos primigenio. San Ignacio de Loyola, en su: 'Relato del peregrino', dictado a Luis Gonçalves de Cámara, dijo: 'Una vez se le presentó en el entendimiento con grande alegría espiritual el modo con que Dios había creado el mundo, que le parecía ver una cosa blanca, de la cual salían muchos rayos, y que de ella hacía Dios lumbre'. ('El relato del peregrino'; Ed Labor, 1973, Cap III, pag 40, ISBN 84-335-9807-4)

'Por envidia del demonio entró la muerte en el mundo'. 'La creación entera gime con gemidos inefables bajo uno que la sometió contra su voluntad'. Solo en ocasiones se ha señalado que la creación yahvista está articulada en torno a la separación de categorías.

Otros lo interpretan como: Una vez más el mal estaría asociado con la falta de forma, con desaparición del límite. El mal desde esta óptica afecta a la unidad del cosmos. La idea de mal estará consecuentemente asociada con lo que cruce, con lo que rompe o se opone al límite de dichas categorías.

Las teorías científicas proporcionan actualmente al imaginario popular los elementos para la descripción del origen del universo y lo que hay en él; orígenes que anteriormente eran explicados solo a través de la cosmogonía presente en las diferentes religiones. Así, actualmente las ciencias describen la evolución del universo, particularmente a través de la teoría del Big Bang; y el origen y la evolución de la vida, a través de la teoría de la síntesis evolutiva moderna.

El pensador Teilhard de Chardin propone una reconciliación entre el punto de vista científico y el de la religión cristiana, interpretando la génesis como una transformación organizada de la materia a través del tiempo, desde niveles simples como los átomos hasta niveles mucho más complejos, como la especie humana. Sin embargo, no considera al hombre como la culminación de la evolución sino como un paso intermedio hacia lo que denomina el Punto Omega de unidad final con Dios preexistente.
Aunque las ideas de Teilhard de Chardin fueron rechazadas inicialmente por parte de la doctrina católica, el papa Benedicto XVI ha admitido que el jesuita francés fue un gran visionario a este respecto

Dentro del ámbito de las ciencias naturales, Richard Dawkins (1941–), en su texto "El gen egoísta" (1976), narra la descripción científica del origen de la vida como el momento en el cual aparece sobre la Tierra una molécula, formada accidentalmente, que tenía la propiedad de crear copias de sí misma (un protobionte). Luego, a partir del ancestro común universal, Dawkins explicará el desarrollo de la vida (evolución biológica), describiendo las diversas ramificaciones en especies en lo que él denominó «errores en la replicación». Más allá de las pretensiones evolucionistas del discurso dawkinsiano, la idea de una molécula que se forma por accidente en un punto impreciso y que a partir de la misma se origina la cadena vital, tiene muchas resonancias con el mito demiúrgico. El demiurgo agrupa el material disperso en forma molecular, de donde se originan todas las formas vitales sobre la faz de la Tierra, pero el demiurgo no está sujeto a su propia creación, por lo que resulta lo que señala Dawkins, que no todo está determinado por nuestros genes.




</doc>
<doc id="6885" url="https://es.wikipedia.org/wiki?curid=6885" title="Guy Fawkes">
Guy Fawkes

Guy Fawkes (York, 13 de abril de 1570-Londres, 31 de enero de 1606), también conocido como Guido Fawkes —nombre que adoptó mientras luchaba junto al ejército español—, fue uno de los integrantes del grupo de católicos ingleses que intentó asesinar al rey Jacobo I en la fallida conspiración de la pólvora en 1605.

Fawkes nació y creció en York. Perdió a su padre cuando tenía ocho años y tiempo después su madre contrajo matrimonio con un católico recusante. Fawkes se convirtió al catolicismo y se marchó de Inglaterra para combatir en la guerra de los Ochenta Años en el bando de los Tercios españoles contra los protestantes neerlandeses en los Países Bajos. Asimismo, viajó a España en busca de apoyo para una rebelión de los católicos ingleses, pero no lo encontró. Poco después conoció a Thomas Wintour, junto al cual regresó a Inglaterra.

Fue Wintour quien presentó a Fawkes y Robert Catesby, otro católico inglés que estaba planeando asesinar al rey Jacobo I y restaurar una monarquía católica en el trono de Inglaterra. Los conspiradores alquilaron un sótano situado bajo la Cámara de los Lores en Londres y a Fawkes se le encargó la tarea de vigilar los barriles de pólvora que allí se colocaron. Alertadas por una carta anónima, las autoridades registraron el palacio de Westminster a primera hora del día 5 de noviembre y descubrieron a Fawkes junto a los explosivos. Detenido y encarcelado, en los siguientes días fue interrogado y torturado, tras lo cual finalmente confesó. Fue condenado a muerte por alta traición, pero inmediatamente antes de su ejecución pública el 31 de enero Fawkes saltó desde el cadalso en el que lo iban a ahorcar y se rompió el cuello, con lo que evitó la agonía de la mutilación que le esperaba.

Fawkes se convirtió en el símbolo de la conspiración de la pólvora, cuyo fracaso se conmemora en Inglaterra cada 5 de noviembre desde entonces en la conocida como Noche de Guy Fawkes, durante la cual se quema su efigie en una hoguera y se lanzan fuegos artificiales.

Guy Fawkes nació en Stonegate, York, en 1570. Era el segundo hijo de los cuatro del matrimonio formado por Edward Fawkes, procurador y abogado del tribunal eclesiástico de York, y Edith Blake. Sus padres eran protestantes ingleses, al igual que sus abuelos paternos, mientras que su abuela Ellen Harrington era hija de un prominente comerciante que llegó a ser alcalde de York en 1536. Los familiares maternos de Fawkes eran católicos recusantes y su primo, Richard Cowling, se convirtió en sacerdote jesuita. El nombre "Guy" era muy poco común en Inglaterra, pero quizá fuera más habitual en York gracias a un famoso juez de la ciudad, "sir" Guy Fairfax de Steeton. 
No se conoce la fecha exacta del nacimiento de Fawkes, pero sí que fue bautizado en la iglesia de St. Michael le Belfrey el 16 de abril de 1570. Como entonces era costumbre bautizar a los bebés tres días después de su nacimiento, probablemente viniera al mundo el 13 de abril. En 1568 su madre Edith había dado a luz a una hija llamada Anne que murió con siete semanas de vida. Después de Guy, tuvo dos hijas: Anne en 1572 y Elizabeth en 1575. Las dos hermanas de Fawkes se casaron en 1599 y 1594 respectivamente. 

En 1579, cuando Guy tenía ocho años, su padre falleció. Varios años después su madre se volvió a casar con el católico Dionis Baynbrigge, originario de Scotton, Harrogate. Guy se convirtió al catolicismo por influencia de la familia católica recusante de Dionis y de otras familias como los Pulleyn y los Percy de Scotton. En su conversión religiosa también influyó el colegio católico en el que estudió, el St. Peter en York. Uno de los directores de esta escuela había pasado veinte años en prisión por su fe católica y otro, John Pulleyn, pertenecía a una familia notable de católicos de Yorkshire. En el libro "The Pulleynes of Yorkshire" (1915), la escritora Catharine Pullein sugiere que la educación católica de Fawkes fue responsabilidad de sus familiares Harrington, que eran conocidos por proteger a sacerdotes católicos, uno de los cuales viajó con Guy a Flandes entre 1592 y 1593. Fueron compañeros de clase de Fawkes los hermanos John y Christopher Wright (ambos implicados en la Conspiración de la pólvora), Oswald Tesimond, Edward Oldcorne y Robert Middleton, todos ellos sacerdotes católicos (Middleton fue ejecutado en 1601). 

Tras abandonar el colegio, Fawkes entró al servicio de Anthony Browne, I vizconde de Montagu, el cual lo acabó despidiendo poco tiempo después. También trabajó para Anthony-Maria Browne, II vizconde de Montagu, que sucedió a su abuelo cuando tenía 18 años. Al menos una base de datos biográfica afirma que Fawkes se casó y tuvo un hijo, pero ninguna fuente coetánea confirma este dato.

En octubre de 1591 Fawkes vendió la finca en Clifton que había heredado de su padre y emprendió un viaje al continente para combatir en la guerra de los Ochenta Años a favor del bando católico junto al ejército español contra las recién creadas Provincias Unidas de los Países Bajos y, desde 1595 hasta la Paz de Vervins en 1598, contra Francia. Aunque entonces Inglaterra no estaba luchando por tierra contra España, ambos reinos estaban todavía en guerra y pocos años antes, en 1588, la Armada Invencible española había intentado invadir Inglaterra. Fawkes se unió a "sir" William Stanley, un católico inglés y veterano comandante que había reclutado un ejército en Irlanda para luchar en la expedición a los Países Bajos de Robert Dudley, conde de Leicester. Stanley había sido un militar muy apreciado por la reina Isabel I de Inglaterra, pero tras su rendición en Deventer ante los españoles en 1587, él y la mayor parte de sus tropas habían cambiado de bando para servir a los intereses hispanos. Fawkes fue ascendido a alférez y combatió en el asedio de Calais en 1596. En 1603 fue recomendado para el ascenso a capitán. Ese mismo año viajó a España, concretamente a Valladolid, ya que la corte real se había instalado allí, en busca de apoyos para una rebelión católica en Inglaterra y aprovechó la ocasión para adoptar la forma latinizada de su nombre, Guido. En su memorando describió a Jacobo I como «un hereje» que pretendía «expulsar de Inglaterra a todos los papistas». También criticó a Escocia y a los nobles escoceses favoritos del rey Jacobo escribiendo que «no será posible reconciliar en mucho tiempo estas dos naciones tal y como son ahora». Aunque en España fue recibido con cortesía, la corte del rey Felipe III no quiso ofrecerle ningún apoyo.

En 1604 Guy Fawkes se unió a un pequeño grupo de católicos ingleses liderados por Robert Catesby que planeaban asesinar al rey protestante de Inglaterra Jacobo I y entronizar en su lugar a la princesa Isabel, tercera en la línea sucesoria. Oswald Tesimond, un cura jesuita y antiguo amigo de escuela, describió así a Fawkes: «De trato agradable y carácter alegre, nada pendenciero y leal a sus amigos». Tesimond también afirmó que era «un hombre muy habilidoso en las artes de la guerra» y que poseía una mezcla de piedad y profesionalismo con las que se ganó el aprecio de sus compañeros en la conspiración. La escritora Antonia Fraser describe a Fawkes como «alto y de constitución fuerte, con una espesa cabellera entre morena y pelirroja, un largo mostacho a la moda de la época y una poblada barba también de tono rojizo» y que era «un hombre de acción… inteligente y con resistencia física, algo sorprendente para sus enemigos». 

El primer encuentro entre los cinco principales conspiradores se celebró el sábado 20 de mayo de 1604 en el Duck and Drake, un local situado en el concurrido distrito del Strand de Londres. Catesby ya había propuesto, en un encuentro previo con Thomas Wintour y John Wright, matar al rey y a todo su gobierno haciendo estallar «la Casa del Parlamento con pólvora». Wintour, que en un principio puso objeciones a ese plan, acabó siendo convencido por Catesby para que viajara al continente en busca de ayuda. Wintour se reunió en Londres con Juan Fernández de Velasco y Tovar, condestable de Castilla, con el espía galés exiliado Hugh Owen y con "sir" William Stanley, el cual le hizo saber que Catesby no recibiría ninguna ayuda desde España. A pesar de ello, Owen le presentó a Guy Fawkes, que llevaba varios años fuera de Inglaterra y, por tanto, apenas era conocido en su país de origen. Wintour y Fawkes eran de una edad similar, ambos militares y los dos habían recibido ya una negativa directa de los españoles en sus peticiones de ayuda. Wintour puso al corriente a Fawkes de sus planes para «hacer algo en Inglaterra si la paz con España no nos ayuda» y, por ello, en abril de 1604 ambos regresaron a Inglaterra. Las noticias que traía Wintour no sorprendieron a Catesby, pues a pesar de los rumores alentadores que llegaban de las autoridades españolas, temía que estas no respondieran con hechos.
Uno de los conspiradores, Thomas Percy, fue ascendido en junio de 1604 y obtuvo así acceso a una casa en Londres que pertenecía a John Whynniard, encargado del vestidor del rey. Fawkes fue infiltrado como cuidador y comenzó a usar el seudónimo de John Johnson, sirviente de Percy. El relato contemporáneo de la persecución, tomado de la confesión de Wintour, afirma que los conspiradores intentaron excavar un túnel desde la casa de Whynniard hasta el Parlamento inglés, aunque esta historia pudo ser un invento del Gobierno, porque no se encontró ninguna evidencia de este túnel. El propio Fawkes no admitió la existencia de este pasadizo subterráneo hasta su quinto interrogatorio y tampoco fue capaz de indicar la supuesta ubicación del mismo. Sin embargo, si esta historia es cierta, hacia diciembre de 1604 los conspiradores estarían excavando el túnel cuando escucharon un ruido sobre sus cabezas. Fawkes fue enviado a investigar y regresó con la noticia de que la viuda del antiguo propietario de la vivienda estaba vaciando un sótano cercano, ubicado directamente bajo el Parlamento.

Los conspiradores alquilaron la habitación, que también pertenecía a John Whynniard. Abandonado y sucio, era un lugar ideal para colocar la pólvora que pensaban hacer estallar. De acuerdo con Fawkes, en principio compraron veinte barriles de pólvora y el 20 de julio otros dieciséis más. Sin embargo, el 28 de julio se retrasó la apertura del Parlamento hasta el martes 5 de noviembre por culpa de la epidemia de peste que sufría la ciudad.

En un intento por obtener apoyo en el extranjero, en mayo de 1605 Fawkes viajó a la Europa continental e informó a Hugh Owen del plan de los conspiradores. En algún momento durante este viaje su nombre fue incluido en los archivos de Robert Cecil, conde de Salisbury, que empleaba una extensa red de espías por toda Europa. Uno de estos espías, el capitán William Turner, pudo ser quien dio aviso. Aunque la información que este pasó a Salisbury no hacía mención a la Conspiración de la pólvora, el 21 de abril le escribió cómo Guy Fawkes iba a ser llevado a Inglaterra por Tesimond. Por entonces Fawkes era un conocido mercenario en Flandes y podría ser presentado al «señor Catesby» y a «honorables amigos de la nobleza que podrían tener armas y caballos preparados». Sin embargo, este informe de Turner no mencionaba el seudónimo de Fawkes en Inglaterra, John Johnson, y no llegó a Cecil hasta finales de noviembre, mucho después del descubrimiento de la conspiración.

No se sabe con exactitud cuando regresó Guy Fawkes a Inglaterra, pero es seguro que se encontraba en Londres a finales de agosto de 1605, cuando él y Wintour descubrieron que la pólvora almacenada en el sótano se había deteriorado. Trajeron más material explosivo y leña para ocultarlo todo. La última tarea de Fawkes en el complot se decidió durante las reuniones celebradas en octubre: debía prender la mecha y después huir atravesando el río Támesis. De forma simultánea, una revuelta espoleada en las Midlands por otros confabulados ayudaría a capturar a la princesa Isabel. Después del regicidio, Fawkes debería viajar al continente para explicar a los poderes católicos su santo deber de matar al rey y a su séquito. 

Varios de los conspiradores estaban preocupados porque en el Parlamento habría correligionarios católicos en el momento de su apertura. En la noche del 26 de octubre un noble católico, William Parker, barón de Monteagle, recibió una carta anónima que le advertía que se mantuviera alejado del Parlamento porque el lugar iba a recibir un terrible golpe. A pesar de que tuvieron noticia del envío de esta carta por boca de uno de los sirvientes de Monteagle, los conspiradores decidieron seguir adelante porque «parecía claramente una broma». Fawkes revisó el sótano de los explosivos el 30 de octubre e informó de que nada había sido tocado. Sin embargo, Monteagle comenzó a sospechar y enseñó la carta al rey Jacobo. El monarca ordenó a "sir" Thomas Knyvet que procediera a un registro de los sótanos bajo el Parlamento, el cual se llevó a cabo en las primeras horas del 5 de noviembre. Fawkes estaba en su puesto de vigía desde la noche anterior, equipado con material incendiario y un reloj de bolsillo que le había dado Percy «porque debía saber cómo pasaban las horas». Fue descubierto y arrestado mientras salía del sótano, poco después de la medianoche. Dentro, las autoridades hallaron los barriles de pólvora ocultos bajo pilas de leña y carbón.

Fawkes dijo llamarse John Johnson en su primer interrogatorio ante miembros de la Cámara Privada del Rey, durante el cual mantuvo una actitud desafiante. Cuando le preguntaron qué estaba haciendo en posesión de tal cantidad de pólvora, Fawkes respondió que su intención era «expulsaros a vosotros, mendigos escoceses, de vuelta a las montañas». Se identificó a sí mismo como un católico de 36 años originario de Netherdale en Yorkshire y afirmó que el nombre de su padre era Thomas y el de su madre Edith Jackson. Sobre las cicatrices en su cuerpo, dijo que eran secuelas de la enfermedad de la pleuresía. Admitió que su intención era hacer explotar la Cámara de los Lores y expresó su pesar por no haberlo conseguido. Su firme actitud ante las autoridades hizo que se ganara la admiración del rey Jacobo, que dijo que Fawkes poseía «una resolución romana». 

Esta admiración, sin embargo, no impidió que el monarca ordenara el 6 de noviembre que «John Johnson» fuera torturado para que revelara los nombres del resto de conspiradores. Especificó que la tortura fuera leve al principio y se refirió al uso de grilletes, pero que se empleara mayor dureza en caso necesario con el uso del potro de tortura: «las torturas más leves se deben usar al principio y gradualmente se procederá hacia las peores». Fawkes fue trasladado a la Torre de Londres. El rey elaboró un listado de preguntas para «Johnson», como por ejemplo «Qué es, porque hasta ahora no he oído que nadie le conozca», «¿Cuándo y dónde aprendió a hablar francés?» y «Si era papista, ¿quién se lo inculcó?». La estancia en la que Fawkes fue interrogado acabaría siendo conocida por su nombre.
"Sir" William Waad, teniente de la Torre de Londres, supervisó la tortura y obtuvo la confesión de Fawkes. Cacheó al detenido y encontró una carta, dirigida a Guy Fawkes, pero para sorpresa de Waad «Johnson» permaneció en silencio sin revelar nada de la conspiración o sus autores. En la noche del 6 de noviembre el prisionero habló con Waad, quien luego informó a Salisbury que «Él [Johnson] nos contó que desde que emprendió esta acción rezaba todos los días a Dios para que pudiera llevar a cabo algo que permitiría el avance de la Fe Católica y la salvación de su alma». Según Waad, Fawkes fue capaz de descansar durante la noche a pesar de que le había advertido que sería interrogado hasta que «Yo sepa hasta el último de tus pensamientos y todos tus cómplices». La resistencia de Fawkes se quebró en algún momento durante la tortura del día siguiente. 

El observador "sir" Edward Hoby señaló que «Desde que Johnson está en la Torre, ha empezado a hablar inglés». Fawkes reveló su verdadero nombre el 7 de noviembre y dijo a sus interrogadores que había cinco personas implicadas en la conspiración para matar al rey. Comenzó a revelar sus nombres el día 8 y contó el plan para entronizar a la princesa Isabel. En su tercera confesión, el día 9, implicó a Francis Tresham. Después de la Conspiración de Ridolfi de 1571, los prisioneros debían dictar sus confesiones, copiarlas y firmarlas, si todavía podían hacerlo. Aunque no se sabe con certeza si llegó a ser torturado en el potro, la firma garabateada de Fawkes deja testimonio del sufrimiento que le infligieron sus interrogadores.

El juicio a los ocho conspiradores detenidos comenzó el lunes 27 de enero de 1606. Fawkes fue trasladado en la misma barcaza desde la Torre de Londres hasta Westminster con los otros siete confabulados. Permanecieron encerrados en la Cámara Estrellada antes de ser llevados al Salón Westminster, donde fueron ubicados en un cadalso levantado al efecto. El rey y sus parientes más allegados observaron a escondidas cómo los lores comisarios leían la lista de cargos contra los detenidos. Fawkes fue identificado como Guido Fawkes, «también llamado Guido Johnson». Fawkes se declaró inocente, a pesar de su aparente aceptación de culpabilidad desde que fuera detenido. 
La sentencia nunca estuvo en duda. El jurado encontró culpables a todos los acusados y el lord jefe de la Justicia, "sir" John Popham, los sentenció por alta traición. El fiscal general "sir" Edward Coke dijo a la corte que cada uno de los condenados sería arrastrado con la cabeza contra el suelo por un caballo hasta su muerte. Debían «ser puestos entre el cielo y la tierra porque no eran dignos de ninguno». Sus genitales serían cortados y quemados delante de ellos, tras lo que les extraerían las entrañas y el corazón. Entonces serían decapitados y desmembrados para que las partes de sus cuerpos se expusieran públicamente y se convirtieran en «comida para las aves de presa». Los testimonios de Fawkes y Tresham sobre la traición de los españoles se leyeron en voz alta, así como las confesiones sobre la Conspiración de la pólvora. La última prueba expuesta fue una conversación entre Fawkes y Wintour, que habían estado retenidos en celdas anexas. Ambos pensaron que hablaban en privado, pero sus palabras fueron escuchadas por un espía del Gobierno. Cuando se permitió hablar a los acusados, Fawkes expresó su inocencia por ignorar ciertos aspectos de la acusación. 

El 31 de enero de 1606, Fawkes y otros tres condenados –Thomas Wintour, Ambrose Rookwood y Robert Keyes– fueron arrastrados desde la Torre atados sobre unas vallas de zarzo hasta el patio del Palacio Viejo de Westminster, frente al edificio que habían intentado destruir. Sus compañeros de conspiración fueron ahorcados y descuartizados antes que él. Fawkes fue el último en subir al cadalso y pidió clemencia al rey y al Estado al tiempo que sostenía sus cruces cristianas. Debilitado por la tortura y ayudado por el verdugo, Fawkes comenzó a subir la escalera hacia la soga en que iba a ser ahorcado, pero ya fuera porque saltó del cadalso o porque la soga estaba mal colocada, consiguió evitar la agonía de la última parte de la ejecución rompiéndose el cuello. A pesar de todo, su cuerpo sin vida fue descuartizado y, como era costumbre, las partes se distribuyeron «a las cuatro esquinas del reino» para ser exhibidas como advertencia a otros traidores.

El 5 de noviembre de 1605 las autoridades animaron a los londinenses a celebrar que se había evitado el asesinato del rey con el encendido de hogueras, «siempre cuidando que sus muestras de alegría se hicieran sin daños ni desorden». Una ley del Parlamento, que estuvo en vigor hasta 1859, designó cada 5 de noviembre como día de acción de gracias por «la jornada de feliz liberación». Aunque Guy Fawkes solo era uno de los trece conspiradores, en la actualidad es el más conocido de todos ellos.

En Gran Bretaña, el 5 de noviembre se ha llamado de varias maneras como Noche de Guy Fawkes, Día de Guy Fawkes, la Noche del Complot o la Noche de las Hogueras, esta última denominación directamente relacionada con la celebración original de 1605. Las hogueras se acompañaron de pirotecnia desde 1650 en adelante y, después de 1673, se convirtió en costumbre la quema de una efigie, normalmente del papa, cuando el presunto heredero del trono inglés, Jacobo, duque de York, hizo pública su conversión al catolicismo. Aunque Fawkes no era el líder del complot, fue utilizado por los sucesivos Gobiernos como símbolo de los extremistas católicos y la celebración anual formó parte de la represión ejercida contra ellos durante los siguientes 200 años. Hasta 1797, los católicos no pudieron votar en las elecciones locales y, hasta 1829, en las elecciones al Parlamento inglés. En estas hogueras también se han quemado efigies de personajes históricos que se habían convertido en destinatarios de la ira popular, como Paul Kruger o Margaret Thatcher, aunque en tiempos recientes la figura que se suele quemar es la de Guy Fawkes. Normalmente son los niños quienes construyen el pelele a base de ropas viejas, papel de periódico y una máscara y, durante el , solía ser una persona vestida de manera estrafalaria. En algunas ocasiones, se denomina a Guy Fawkes como «el último hombre que entró en el Parlamento con intenciones honestas».

En la novela histórica "Guy Fawkes; or, The Gunpowder Treason" (1841), escrita por William Harrison Ainsworth, se retrata de manera simpática a Guy Fawkes, con lo que se creó una imagen popular del conspirador como «un personaje ficticio aceptable». Con el paso del tiempo Fawkes se ha convertido «esencialmente en un héroe de acción» en libros infantiles y novelas de escasa calidad como "The Boyhood Days of Guy Fawkes; or, The Conspirators of Old London" ("Los días de infancia de Guy Fawkes; o Los conspiradores del Viejo Londres"), publicada hacia 1905. Según el historiador Lewis Call, Fawkes es en la actualidad «un gran icono en la cultura política moderna», cuyo rostro ha pasado a ser «un instrumento potencialmente poderoso para la articulación del anarquismo posmoderno» a finales del e inicios del , ejemplificado por la célebre máscara que cubre el rostro del personaje "V" de la novela gráfica "V de Vendetta" de Alan Moore y David Lloyd y su adaptación al cine, en los cuales lucha contra un ficticio estado fascista inglés. La máscara que utiliza el personaje, cuyo diseño está basado en los rasgos faciales de Fawkes, fue posteriormente adoptada por los miembros de la comunidad virtual Anonymous.




</doc>
<doc id="6886" url="https://es.wikipedia.org/wiki?curid=6886" title="Leyenda">
Leyenda

Una leyenda es una narración sobre hechos sobrenaturales, naturales o una mezcla de ambos que se transmite de generación en generación de forma oral o escrita. Generalmente, el relato se sitúa de forma imprecisa entre el mito y el suceso verídico, lo que le confiere cierta singularidad. 

Lo ubica en un tiempo y lugar similar al de los miembros de una comunidad, lo que aporta cierta verosimilitud al relato. En las leyendas se presentan elementos sobrenaturales como milagros, la presencia de criaturas feéricas o de ultratumba, etc.Y estos sucesos se presentan como reales, forman parte de la visión del mundo propia o emic de la comunidad en la que se origina la leyenda. 

En su proceso de transmisión a través de la tradición oral, las leyendas experimentan a menudo supresiones, añadidos o modificaciones culturales que dan origen a todo un mundo lleno de variantes. Las más comunes es la "cristalización" de leyendas paganas o la adaptación a la visión infantil, cuando el cambio de los tiempos ha reducido las antiguas cosmovisiones.

Se define a la leyenda como un relato folclórico con bases históricas. Una definición profesional moderna ha sido propuesta por el folclorista Timothy R. Tangherlini en 1990: 

Contrariamente al mito, que se ocupa de dioses, la leyenda se ocupa de hombres que representan arquetipos (tipos humanos característicos), como el del héroe o el anciano sabio, como se aprecia por ejemplo en las leyendas heroicas griegas y en las artúricas.

La palabra "leyenda" proviene del verbo latino legere, cuyo significado variaba entre "escoger" (acepción de la que proviene "elegir") y "leer". En el latín medieval, se usó el gerundivo de este verbo, "legenda", con el significado de (algo) "para ser leído" cuando el término se aplicaba, sobre todo en el catolicismo, a las hagiografías o biografías de los santos. Por ejemplo, Santiago de la Vorágine compuso su "Legenda aurea" como un santoral con la vida y milagros de unos 180 mártires y santos, aunque con tan poca precisión histórica y filológica y con unas etimologías tan fantásticas que poco a poco fue perdiendo crédito, salvo entre pintores e ilustradores fascinados por su imaginación, que estimuló la iconografía. Él se fundaba en los evangelios canónicos, los apócrifos y en escritos de Agustín de Hipona y Gregorio de Tours, entre otros.

Con la llegada de la Reforma Protestante del siglo XVI el término "leyenda" cobra su nuevo carácter de narración no histórica. Los protestantes ingleses presentan una nota de contraste entre los santos y mártires "reales" de la reforma, cuyos relatos "auténticos" figuraban en "El libro de los mártires" de John Foxe, y los fantasiosos relatos de la hagiografía católica.De esta forma, la "leyenda" gana su connotación moderna de narración "indocumentada" y "espuria". Es muy probable que, en lengua española, la moderna concepción de leyenda y de lo legendario haya sido tomada de estos modelos ingleses, especialmente desde 1850.

El término acaba englobando también a producciones literarias cultas del romanticismo que, aunque se inspiran en tradiciones populares o en motivos característicos de éstas, no son relatos tradicionales. Varios autores de este período escribieron leyendas literarias de este tipo tanto en prosa como en verso. Los más celebrados fueron el duque de Rivas, José Zorrilla, Gustavo Adolfo Bécquer y José Joaquín de Mora.

Una leyenda, a diferencia de un cuento o un mito, está ligada siempre a un elemento preciso y se centra en la integración de este elemento en el mundo cotidiano o la historia de la comunidad a la cual pertenece. Contrariamente al cuento, que se sitúa dentro de un tiempo («Érase una vez...») y un lugar (por ejemplo, del Castillo te irás y ya no volverás) convenidos e imaginarios, la leyenda se desarrolla habitualmente en un lugar y un tiempo preciso y real, aunque aparecen en ellas elementos ficticios (por ejemplo, criaturas fabulosas, como las sirenas o dragones).

Como el mito, la leyenda es etiológica, es decir, tiene como tarea esencial dar fundamento y explicación a una determinada cultura. Su elemento central es un rasgo de la realidad (una costumbre o el nombre de un lugar, por ejemplo) cuyo origen se pretende explicar.

Las leyendas se agrupan a menudo en ciclos alrededor de un personaje, como sucede con los ciclos de leyendas en torno al Rey Arturo, Robin Hood, el Cid Campeador o Bernardo del Carpio.

Las leyendas contienen casi siempre un núcleo histórico, ampliado en mayor o menor grado con episodios imaginativos. La aparición de los mismos puede depender de motivaciones involuntarias, como errores, malas interpretaciones (la llamada etimología popular, por ejemplo) o exageraciones, o bien de la acción consciente de una o más personas que, por razones interesadas o puramente estéticas, desarrollan el embrión original.

Cuando una leyenda presenta elementos tomados de otras leyendas se habla de «contaminación de la leyenda».

Se pueden clasificar de dos formas:

Por su temática: 
Por su origen:

Algunas leyendas pueden llegar a ser clasificadas en más de un grupo, ya que por su temática abordan más de un tema. Un ejemplo de esto, sería una leyenda acerca de una supuesta manera de contactar con un ser querido ya fallecido, que podría ser clasificada tanto como leyenda urbana, como leyenda escatológica.

Se mezclaron en la península ibérica tradiciones muy disímiles: célticas, ibéricas, romanas, visigodas, judías, árabes (y con los árabes, las tradiciones indias) en las más diversas lenguas.

Varias leyendas aparecen en el Romancero y, a través de él, en el teatro clásico español. Un verdadero vivero de leyendas es la obra de Cristóbal Lozano y la novela cortesana del Barroco. Numerosos escritores eclesiásticos compilaron leyendas y tradiciones piadosas en distintas colecciones, la más conocida de las cuales, pero no la única, es el "Flos sanctorum".

Pero a partir del siglo XIX los románticos empiezan a experimentar interés por recogerlas, estudiarlas o incluso imitarlas. En 1838 se publican ya unas "Leyendas y novelas jerezanas"; en 1869, 1872 y 1874 aparecen ediciones sucesivas de unas "Leyendas y tradiciones populares de todos los países sobre la Santísima Virgen María, recogidas y ordenadas por una Sociedad Religiosa". En 1853 Agustín Durán, que había ya publicado los dos tomos de su monumental "Romancero general o colección de romances castellanos" (BAE, t. X y XVI), publicó la "Leyenda de las tres toronjas del vergel de Amor". Ángel de Saavedra, duque de Rivas, cultiva el género de la leyenda en verso y Fernán Caballero traduce leyendas alemanas y compila y reúne colecciones de las españolas. Las de Gustavo Adolfo Bécquer, tanto las publicadas como las recopiladas póstumamente, son de las más expresivas en prosa, pero tampoco desmerecen las leyendas en verso de José Zorrilla y de José Joaquín de Mora. Tras Washington Irving, el arabista Francisco Javier Simonet publicó en 1858 "La Alhambra: leyendas históricas árabes"; José Lamarque de Novoa publicó "Leyendas históricas y tradiciones" (Sevilla, 1867); Antonia Díaz Fernández de Lamarque, "Flores marchitas: baladas y leyendas" (Sevilla, 1877); Manuel Cano y Cueto se ocupó de las leyendas sobre Miguel Mañara (1873), y a estos nombres habría que añadir otros muchos no menos importantes, como María Coronel, Josefa Ugarte y Casanz, Teodomiro Ramírez de Arellano, José María Goizueta etcétera.

En 1914 el importante centro de estudios folclóricos que era entonces Sevilla auspició la traducción de "La formación de las leyendas" de Arnold van Gennep. En 1953 supuso un hito la aparición de la "Antología de leyendas de la literatura universal" por parte del filósofo Vicente García de Diego, con un denso y extenso estudio preliminar y una selección de las mejores leyendas españolas agrupadas por regiones, y de otros países de todo el mundo. La última contribución importante a estos estudios es sin duda la de Julio Caro Baroja, un gran estudioso de la literatura de cordel, "De arquetipos y leyendas" (Barcelona: Círculo de Lectores, 1989).




</doc>
