<doc id="1369" url="https://es.wikipedia.org/wiki?curid=1369" title="GNU Hurd">
GNU Hurd

GNU Hurd es un proyecto dentro del Proyecto GNU para reemplazar al núcleo de un sistema operativo tipo Unix totalmente libre, GNU. Se ha estado desarrollando desde 1990 y distribuyendo bajo la licencia GPL.

Hurd intenta superar a los Unix en cuanto a funcionalidad, seguridad y estabilidad, aún manteniéndose compatible con ellos. Esto se logra gracias a que Hurd implementa la especificación POSIX ─entre otras─, pero elimina las restricciones arbitrarias a los usuarios.

Aunque el Proyecto GNU se suele considerar a Hurd como núcleo, en sentido estricto esto no sería correcto, dado que parte importante de Hurd reside en un espacio de usuario que interactúa con un micronúcleo, GNU Mach. De hecho, Hurd sería un sistema operativo, tal como se considera al núcleo Linux, y la extensa colección de programas GNU corriendo sobre Hurd se denomina GNU/Hurd, tal como se llama GNU/Linux a la misma corriendo sobre Linux.

El desarrollo de Hurd empezó en el año 1990. Aunque Richard Stallman, fundador del proyecto GNU, había anunciado que esperaba el lanzamiento oficial del sistema operativo GNU (también conocido como GNU/Hurd) antes de finales de 2002, esto no fue conseguido, en parte porque se comenzó a utilizar el núcleo Linux.

La palabra Hurd es un acrónimo recursivo. Hurd es el acrónimo de «Hird of Unix-Replacing Daemons» (en español: «Hird» de demonios que reemplazan a Unix). A su vez el término «Hird» significa «Hurd of Interfaces Representing Depth» («Hurd» de interfaces que representan profundidad). Tanto «Hurd» como «Hird» en inglés americano se pronuncian como /hɜːrd/ «herd» (en español: manada), por lo que GNU Hurd se podría traducir como «manada de ñúes», referente a su arquitectura de un conjunto de servidores corriendo.

A diferencia de la mayoría de núcleos tipo Unix, Hurd se erige encima de un micronúcleo (actualmente solo está soportado Mach, aunque existió un proyecto ahora abandonado para poder ejecutar Hurd en el micronúcleo de segunda generación L4), responsable de facilitarle los servicios de un núcleo más básicos: coordinar el acceso al hardware (a la CPU —mediante multiproceso—, a la memoria RAM —mediante gestión de memoria—, y a otros dispositivos de sonido, gráficos, almacenamiento, etc.).

Hay otros sistemas tipo Unix que se ejecutan encima del micronúcleo Mach, como OSF/1, NEXTSTEP, Mac OS X, Lites y MkLinux. Todos ellos están implementados como un único "servidor". Por lo tanto, sustituyen el núcleo monolítico de los sistemas Unix tradicionales con dos elementos, el micronúcleo y el servidor Unix.

En cambio, Hurd consiste en múltiples servidores ejecutándose simultáneamente. En lugar de un solo programa enorme que controle desde el reloj hasta el manejo de la red, en Hurd cada una de estas tareas es gestionada por un servidor independiente. Esto hace que (teóricamente, al menos) el desarrollo de Hurd sea mucho más fácil, ya que es menos probable que el hacer cambios en un servidor tenga efectos indeseados en otros servidores.

En el diseño original de Mach una de las principales metas fue este tipo de «conjunto de servidores», pero parece que Hurd es el primero en implementar este diseño sobre un micronúcleo Mach (aunque QNX es similar, pero basado en su propio micronúcleo). No está claro por qué no hubo ninguna implementación de múltiples servidores anteriormente, aunque parece que los grupos que trabajaban en Mach estaban demasiado ocupados en este para dedicarse al sistema operativo en su totalidad. Hurd intenta, además, ser portable entre micronúcleos.

En Hurd un buen número de conceptos tradicionales de Unix cambian o se potencian:

Bajo Unix, cada programa que se ejecuta tiene asociada una identidad de usuario, que normalmente se corresponde con el usuario que inició el proceso. Esta identidad determina en gran medida qué acciones se le permite realizar al programa. Ningún proceso externo puede cambiar la identidad de un programa que se esté ejecutando. Un proceso de Hurd, por otra parte, se ejecuta asociado a un conjunto de identidades de usuario, que puede contener múltiples identidades, una, o ninguna. Un proceso con los suficientes privilegios puede añadir o eliminar identidades de otro proceso. Por ejemplo, existe un servidor de contraseñas que otorga identidades en respuesta a una contraseña de usuario correcta.

En lo que respecta al sistema de archivos, se puede establecer un programa adecuado como "traductor" para un solo archivo o una jerarquía de directorios entera. Cada acceso al archivo traducido, o a los archivos en la jerarquía en el segundo caso, son de hecho manejados por este programa. Por ejemplo, un traductor de archivos puede simplemente redirigir las operaciones de lectura y escritura hacia otro archivo, no como un enlace simbólico de Unix. El "montaje" de Unix, en Hurd se consigue configurando un traductor de sistema de archivos (usando el mandato codice_1). Los traductores también se pueden usar para proporcionar servicios al usuario. Por ejemplo, el traductor ftpfs permite a un usuario encapsular un sitio FTP remoto en un directorio. Con esto, se pueden usar programas estándar como codice_2, codice_3 o codice_4 para manipular archivos en el sitio remoto. Hay traductores incluso más potentes, como UnionFS, que permite a un usuario unificar varios directorios en uno solo, de tal manera que al listar este directorio se muestra el contenido de todos los directorios unificados (una característica ausente en la mayoría de Unices, aunque presente en FreeBSD).

Quizás la característica más potente de Hurd es la posibilidad de que cualquier usuario ejecute sus propios servicios de sistema. Un usuario puede asignar cualquier traductor al sistema de archivos para su uso personal. Incluso puede reemplazar servidores del sistema, como el servidor de autenticación, con otros servidores de su elección. Todo esto se puede hacer sin afectar a los otros usuarios, gracias a que los ámbitos de efecto están bien definidos. De hecho, incluso es posible para un usuario ejecutar Hurd dentro de sí mismo, lo que se conoce como sub-Hurd.

Según la documentación de Debian son los siguientes:


También incluye varios sistemas de ficheros:


Entre todos ellos implementan la interfaz de programación de aplicaciones o API Single Unix Specification que es un superset de POSIX. En realidad, es la biblioteca codice_7 la que implementa la API POSIX, igual que en Linux, y Hurd da una interfaz cercana pero de más bajo nivel.

La forma en que los programas llaman a Hurd es a través del sistema de archivos. Funcionan como un sistema de archivos especial, parecido al codice_8 de linux. Por ejemplo, si queremos hablar con el servidor auth miraremos en el directorio donde esté montado (codice_9) y haremos llamadas codice_10 sobre él.

De alguna forma, por tanto, el servidor del sistema de archivos es el que hace de interfaz del API y también sabe a cuál de los otros servidores de bajo nivel mandar las llamadas. A bajo nivel, cuando se hace un open de uno de estos archivos, el programa recibe los distintos dispositivos de "hardware" que vayan compilados dentro del micronúcleo. Por tanto Hurd no necesita llevar él mismo la gestión de bajo nivel de las interrupciones; en cambio sí necesita traducir las señales "hardware" a señales del sistema operativo.

Necesita un gestor de arranque que siga el protocolo multiboot como GRUB. La configuración se realiza mediante los siguientes pasos (o se configura el gestor de arranque para que lo haga automáticamente):

Con esto, el micronúcleo cargará los servidores del hurd y les pasará el control.

Actualmente, hay al menos cinco distribuciones de GNU/Hurd en preparación (Debian GNU/Hurd, Gentoo, Arch Hurd, Bee y A.T.L.D. GNU/Hurd), aunque ninguna ha publicado versiones oficiales.

Se está intentando crear una nueva versión del Hurd llamada NgHurd, este proyecto comenzó con un intento de portar el micronúcleo L4 a Hurd lo cual lo hubiera dotado de una mayor velocidad entre otras características. Dicho proyecto fue abandonado, por lo cual se están discutiendo las características para esta nueva versión desde cero, incluyendo el micronúcleo a utilizar.




</doc>
<doc id="1370" url="https://es.wikipedia.org/wiki?curid=1370" title="Historia">
Historia

La historia es la ciencia que tiene como objetivo el estudio de sucesos del pasado, tradicionalmente de la humanidad, y como método, el propio de las ciencias sociales/humanas, así como el de las ciencias naturales en un marco de interdisciplinariedad. Se trata de la disciplina que estudia y narra cronológicamente los acontecimientos pasados. Se denomina también «historia» al periodo que transcurre desde la aparición de la escritura hasta la actualidad, aunque es un convencionalismo ampliamente superado, y se considera a la prehistoria también como parte intrínseca de la historia. 

Más allá de las acepciones propias de la "ciencia histórica", "ciencia de la historia", "ciencias históricas" o "ciencias de la historia", «historia», en el lenguaje usual, es la narración de cualquier suceso, incluso de sucesos imaginarios y de mentiras; sea su propósito el engaño, el placer estético o cualquier otro (ficción histórica). Por el contrario, el propósito de la ciencia histórica es averiguar los hechos y procesos que ocurrieron y se desarrollaron en el pasado e interpretarlos ateniéndose a criterios de la mayor objetividad posible; aunque la posibilidad de cumplimiento de tales propósitos y el grado en que sean posibles son en sí mismos objetos de estudio de la historiología o teoría de la historia, como epistemología o conocimiento científico de la historia. 

A su vez, se llama «historia» al pasado mismo, e incluso puede hablarse de una «historia natural» en que la humanidad no estaba presente (término clásico ya en desuso, que se utilizaba en oposición a la historia social, para referirse no solo a la geología y la paleontología, sino también a muchas otras ciencias naturales —las fronteras entre el campo al que se refiere tradicionalmente este término y el de la prehistoria y la arqueología son imprecisas, a través de la paleoantropología—, y que se pretende complementar con la historia ambiental o ecohistoria, y actualizarse con la denominada «Gran Historia»: campo académico interdisciplinar que se define como "el intento de comprender de manera unificada, la historia del Cosmos o Universo, la Tierra, la vida y la humanidad", cubriendo los acontecimientos ocurridos desde el Big Bang hasta la historia del mundo actual).

Ese uso del término «historia» lo hace equivalente a «cambio en el tiempo». En ese sentido, se contrapone al concepto de filosófico equivalente a esencia o permanencia (lo que permite hablar de una filosofía natural en textos clásicos y en la actualidad, sobre todo en medios académicos anglosajones, como equivalente a la física). Para cualquier campo del conocimiento, se puede tener una perspectiva histórica —el cambio— o bien filosófica —su esencia—. De hecho, puede hacerse eso para la historia misma (véase tiempo histórico) y para el tiempo mismo (véase "Historia del tiempo", de Stephen Hawking, libro de divulgación sobre cosmología). En este sentido, todo pasado en relación con el presente hace alusión al tiempo y a su cronología, y por lo tanto tener historia. 

En las ciencias de la salud, se utiliza el concepto de historia clínica para el registro de datos sanitarios significativos de un paciente, que se remontan hasta su nacimiento o incluso hacer lo propio con respecto a su herencia genética.

Se denomina historiador o historiadora a la persona encargada del estudio de la historia. Al historiador profesional se le concibe como el especialista en la disciplina académica de la historia, y al historiador no profesional se le suele denominar cronista.

Dentro de la popular división entre "ciencias" y "letras" o "humanidades", se tiende a clasificar a la historia entre las disciplinas humanísticas junto con otras ciencias sociales (también denominadas ciencias humanas), o incluso se la llega a considerar como un puente entre ambos campos, al incorporar la metodología de estas a aquellas. La ambigüedad de esa división del conocimiento humano y el cuestionamiento de su conveniencia ha llevado al llamado "debate de las dos culturas".

No todos los historiadores aceptan la identificación de la historia con una ciencia social, al considerarla una reducción en sus métodos y objetivos, comparables con los del arte si se basan en la imaginación (postura adoptada en mayor o menor medida por Hugh Trevor-Roper, John Lukacs, Donald Creighton, Gertrude Himmelfarb o Gerhard Ritter). Los partidarios de su condición científica son la mayor parte de los historiadores de la segunda mitad del siglo XX y del siglo XXI (incluyendo, de entre los muchos que han explicitado sus preocupaciones metodológicas, a Fernand Braudel, E. H. Carr, Fritz Fischer, Emmanuel Le Roy Ladurie, Hans-Ulrich Wehler, Bruce Trigger, Marc Bloch, Karl Dietrich Bracher, Peter Gay, Robert Fogel, Lucien Febvre, Lawrence Stone, E. P. Thompson, Eric Hobsbawm, Carlo Cipolla, Jaume Vicens Vives, Manuel Tuñón de Lara o Julio Caro Baroja). Buena parte de ellos, lo hicieron desde una perspectiva multidisciplinar (Braudel combinaba historia con geografía, Bracher con ciencia política, Fogel con economía, Gay con psicología, Trigger con arqueología), mientras los demás citados lo hacían a su vez con las anteriores y con otras, como la sociología y la antropología. Esto no quiere decir que entre ellos hayan alcanzado una posición común sobre las consecuencias metodológicas de la aspiración de la historia al rigor científico, ni mucho menos que propongan un determinismo que (al menos desde la revolución einsteniana de comienzos del siglo XX) no proponen ni las llamadas "ciencias duras". Por su parte, los historiadores menos proclives a considerar científica su actividad tampoco defienden un relativismo estricto que imposibilitaría de forma total el conocimiento de la historia y su transmisión, y de hecho de un modo general aceptan y se someten a los mecanismos institucionales, académicos y de práctica científica existentes en la historia y comparables a los de otras ciencias (ética de la investigación, publicación científica, revisión por pares, debate y consenso científico, etcétera).

La utilización que hace la historia de otras disciplinas como instrumentos para obtener, procesar e interpretar datos del pasado permite hablar de ciencias auxiliares de la historia de metodología muy diferente, cuya subordinación o autonomía depende de los fines a los que estas mismas se apliquen.

El registro de anales y crónicas fue en muchas civilizaciones un oficio ligado a un cargo institucional público, controlado por el Estado. Sima Qian (denominado "padre de la Historia", en la cultura china) inauguró en esa civilización los registros históricos oficiales burocratizados (). La crítica del musulmán Ibn Jaldún ("Muqaddima" —"Prolegómenos a la Historia Universal—", 1377) a la manera tradicional de hacer historia no tuvo consecuencias inmediatas, y se le consideró un precedente de la renovación de la metodología de la historia y de la filosofía de la historia que no se inició sino hasta el siglo XIX, fruto de la evolución de la historiografía en Europa occidental. Entretanto, los cronistas oficiales castellanos y de Indias dieron paso en la España ilustrada del siglo XVIII a la fundación de la Real Academia de la Historia; instituciones similares existen en otros países.
La docencia de la historia en la enseñanza obligatoria fue una de las bases de la construcción nacional desde el siglo XIX, proceso simultáneo a la proliferación de las cátedras de historia en las universidades (inicialmente en las facultades de letras o "Filosofía y Letras", y con el tiempo, en facultades propias o de Geografía e Historia —disciplinas cuya proximidad científica y metodológica es una característica de la tradición académica francesa y española—) y la creación de todo tipo de instituciones públicas y privadas (clubes históricos o sociedades históricas, muy habitualmente "medievalistas", respondiendo al historicismo propio del gusto romántico, empeñado en la búsqueda de elementos de identificación nacional); así como publicaciones dedicadas a la historia.
En la enseñanza media de la mayor parte de los países, los programas de historia se diseñaron como parte esencial del currículo. En especial la agregación de historia presente en los "lycées" franceses desde 1830 adquirió con el tiempo un prestigio social incomparable con los cargos similares en otros sistemas educativos y que caracterizó el "elitismo" de la escuela laica republicana hasta finales del siglo XX.

A ese proceso de institucionalización, siguió la especialización y subdivisión de la disciplina con diferentes sesgos temporales (de cuestionable aplicación fuera de la civilización occidental: historia antigua, medieval, moderna, contemporánea —estas dos últimas, habituales en la historiografía francesa o española, no suelen subdividirse en la historiografía anglosajona: "—"), espaciales (historia nacional, regional, local, continental —de África, de Asia, de América, de Europa, de Oceanía—), temáticos (historia política, militar, de las instituciones, económica y social, de los movimientos sociales y de los movimientos políticos, de las civilizaciones, de las mujeres, de la vida cotidiana, de las mentalidades, de las ideas, cultural), historias sectoriales ligadas a otras disciplinas (historia del arte, de la música, natural, de las religiones, del derecho, de la ciencia, de la medicina, de la economía, de la ciencia política, de las doctrinas políticas, de la tecnología), o centrada en cualquier tipo de cuestión particular (historia de la electricidad, de la democracia, de la Iglesia, de los sindicatos, de los sistemas operativos, de las formas —literarias de la Biblia—, etc). Ante la atomización del campo de estudio, también se han realizado distintas propuestas que consideran la necesidad de superar esas subdivisiones con la búsqueda de una perspectiva holística (historia de las civilizaciones, historia total o historia universal) o su enfoque inverso (microhistoria); sin olvidar el nuevo campo académico e interdisciplinar de la Gran Historia como "el intento de comprender de manera unificada, la Historia del Cosmos o Universo, la Tierra, la Vida y la Humanidad", cubriendo la historia desde el Big Bang hasta la Historia del mundo actual. Examina los tiempos de larga duración utilizando un enfoque multidisciplinar basado en la combinación de numerosas disciplinas de la ciencia y las humanidades que estudian el pasado, las "Ciencias-Históricas", y explora la existencia humana en el contexto de un panorama más amplio, que en relación al presente hace alusión al tiempo y la cronología, enseñándose en universidades y escuelas.

El Premio Nacional de Historia (de Chile —bianual, a una personalidad— y de España —a una obra publicada cada año—) y el Premio Príncipe de Asturias de Ciencias Sociales (a una personalidad del ámbito de la historia, la geografía u otras ciencias sociales) son los más altos reconocimientos de la investigación histórica en el ámbito hispanohablante, mientras que en el ámbito anglosajón existe una de las versiones del Premio Pulitzer. El Premio Nobel de Literatura, que puede recaer en historiadores, solo lo hizo en dos ocasiones (Theodor Mommsen, en 1902, y Winston Churchill, en 1953). Desde una perspectiva más propia de la consideración actual de la historia como una ciencia social, el Premio Nobel de economía fue concedido a Robert Fogel y Douglass North en 1993. Por otra parte, el de la History of Science Society se estableció en 1958. El premio consiste en una medalla y una cantidad en metálico. Este premio se otorga en reconocimiento a un libro extraordinario sobre la historia de la ciencia. Cada año, un centenar de autores compiten por este premio, que es considerado el más importante para libros de historia de la ciencia.

El Premio Internacional de Ciencias Históricas, es el premio internacional más prestigioso de Historia otorgado por el Comité Internacional de Ciencias Históricas ("International International Committee of Historical Sciences" / "Comité international des sciences historiques"), la asociación internacional de "Ciencias Históricas" fundada en Ginebra el 14 de mayo de 1926, que concede desde 2015 el Premio Internacional de Historia del CICH, Jaeger-LeCoultre, al "historiador que se ha distinguido en el campo de la Historia por sus obras, publicaciones o docencia, y haya contribuido significativamente al desarrollo del conocimiento histórico". Considerado el "Premio Nobel" en Ciencias Históricas, el jurado del Consejo del CISH, que cuenta con 12 miembros de diferentes países, selecciona al ganador dentro de un grupo de candidatos excelentes y altamente calificados. Solo los miembros colectivos del CISH (sus comités nacionales o sus organizaciones afiliadas internacionales) pueden presentar candidatos.

La identificación del concepto de "historia" con la narración escrita del pasado produce, por un lado, su confusión con el término historiografía ("historia" se llama a la vez al objeto estudiado, a la ciencia que lo estudia y al documento resultado de ese estudio); y por otro justifica el empleo del término prehistoria para el período anterior a la aparición de la escritura, reservándose el nombre "historia" para el periodo posterior.

Según ese uso restrictivo, la mayor parte de la humanidad queda "fuera de la historia", no tanto porque no accede personalmente a la lectura y la escritura (el analfabetismo fue la condición común de la inmensa mayoría de la población, incluso para las clases dominantes, hasta la imprenta), sino porque los reflejados en el discurso histórico han sido siempre muy pocos, y grupos enteros quedan "invisibilizados" (las clases bajas, las mujeres, los discrepantes que no pueden acceder al registro escrito), con lo que ha sido objeto de preocupación de algunos historiadores la reconstrucción de la "visión de los vencidos" y la "historia desde abajo".

Lo mismo ocurre con gran número de pueblos y culturas (las consideradas como culturas primitivas, en una terminología ya desfasada de la antropología clásica) que "no tienen historia". El tópico los idealiza al considerar que son "pueblos felices". Entran en ella cuando se produce su contacto, habitualmente destructivo (aculturación), con civilizaciones (sociedades complejas, con escritura). Incluso en ese momento no son propiamente objeto de la "historia" sino de la protohistoria (historia realizada a partir de las fuentes escritas producidas por los que generalmente son sus pueblos colonizadores por oposición a los pueblos indígenas). No obstante, independientemente de que los historiadores y los antropólogos ideológicamente tengan una tendencia "etnocentrista" ("eurocentrista", "sinocentrista" o "indigenista") o, de forma opuesta, "multiculturalista" o "relativista cultural", existe la posibilidad de obtener o reconstruir un relato fiable de los acontecimientos que afectan a un grupo humano utilizando otras metodologías: fuentes arqueológicas (cultura material) o historia oral. En buena parte, esta diferencia es artificial, y no necesariamente novedosa: el mismo Heródoto no puede sino usar ese tipo de fuentes documentales cuando redacta la que se considera la primera "Historia", o al menos acuña el término, en la Grecia del siglo V a. C. "para que el tiempo no abata el recuerdo de las acciones de los hombres y que las grandes empresas acometidas, ya sea por los griegos, ya por los bárbaros, no caigan en olvido; da también razón del conflicto que puso a estos dos pueblos en la lid". Así comienza su obra titulada "Ἱστορίαι" (léase "históriai", literalmente «investigaciones», «exploraciones», latinizado "Historiae" —«"Historias»", en plural—), seminal para la ciencia histórica, y que suele denominarse en castellano "Los nueve libros de historia". La lid citada son las guerras médicas y los bárbaros, persas.

La palabra "historia" deriva del griego ἱστορία (léase "historia", traducible por «investigación» o «información», conocimiento adquirido por investigación), del verbo ἱστορεῖν («investigar»). De allí pasó al latín "historia", que en castellano antiguo evolucionó a "estoria" (como atestigua el título de la "Estoria de España" de Alfonso X el Sabio, 1260-1284) y se reintrodujo posteriormente en el castellano como un cultismo en su forma latina original.

La etimología remota procede del protoindoeuropeo "*wid-tor-" (de la raíz "*weid-", «saber, ver» —construcción hipotética—) presente también en las palabras latinas "idea" o "visión", en las germánicas "wit", "wise" o "wisdom", la sánscrita "veda", y las eslavas "videti" o "vedati", y en otras lenguas de la familia indoeuropea.

La palabra antigua griega ἱστορία fue usada por Aristóteles en su Περὶ τὰ ζῷα ἱστορίαι (léase "Peri ta zoa jistória", latinizado "Historia animalium", traducible por "Historia de los animales" [el título griego es plural y el latino es singular]). El término se derivaba de ἵστωρ (léase "jístōr", traducible por «hombre sabio», «testigo» o «juez»). Se pueden encontrar usos de ἵστωρ en los himnos homéricos, Heráclito, el juramento de los efebos atenienses y en las inscripciones beocias (en un sentido legal, con un significado similar a «juez» o «testigo»). El rasgo aspirado es problemático, y no se presenta en la palabra cognata griega εἴδομαι («aparecer»). La forma ἱστορεῖν («inquirir»), es una derivación jónica, que se expandió primero en la Grecia clásica y más tarde en la civilización helenística.

En el estudio de la historia conviene diferenciar tres conceptos a veces usados laxamente y que pueden llegar a ser confundidos entre sí:


Es imposible ignorar la polisemia y la superposición de estos tres términos, pero simplificando al máximo: la historia son los hechos del pasado; la historiografía es la ciencia de la historia; y la historiología es la epistemología o teoría de la historia.

La filosofía de la historia no debe confundirse ni con la historiología, ni con la historiografía, de los que se separa claramente. La filosofía de la historia es la rama de la filosofía que concierne al significado de la historia humana, si es que lo tiene. En su origen especuló si era posible un fin teleológico de su desarrollo, o sea, se pregunta si hay un diseño, propósito, principio director o finalidad en el proceso de la historia humana. En la actualidad se discute más sobre la función del conocimiento histórico dentro del conocimiento y las implicaciones del mismo. También se ha discutido sobre si el objeto de la historia debe ser una verdad histórica, el deber ser, o si la historia es en algún sentido es cíclica o lineal y el devenir histórico se aparta indefinidamente del punto de partida. También se ha discutido si es posible hablar de la idea de progreso positivo en ella.

Tampoco deben confundirse los supuestos fines teleológicos del hombre en la historia con los "fines de la historia" es decir, la justificación de la propia historia como memoria de la humanidad. Si la historia es una ciencia social y humana, no puede abstraerse del porqué se encarga de estudiar los procesos sociales: explicar los hechos y eventos del pasado, sea por el conocimiento mismo, sea porque nos ayudan a comprender el presente: Cicerón bautizó a la historia como "maestra de la vida", y como él Cervantes, que también la llamó "madre de la verdad". Benedetto Croce remarcó la fuerte implicación del pasado en el presente con su "toda historia es historia contemporáea". La historia, al estudiar los hechos y procesos del pasado humano, es un útil para la comprensión del presente y plantear posibilidades para el futuro. Salustio llegó a decir que "entre las distintas ocupaciones que se ejercitan con el ingenio, el recuerdo de los hechos del pasado ocupa un lugar destacado por su gran utilidad". Un tópico muy difundido (atribuido a Jorge Santayana) advierte que "los pueblos que no conocen su historia están condenados a repetirla", aunque otro tópico (atribuido a Carlos Marx) indique a su vez que cuando se repite lo hace "una vez como tragedia y la segunda como farsa".

La radical importancia de ello se basa en que la historia, como la medicina, es una de las ciencias en que el sujeto investigador coincide con el objeto a estudiar. De ahí la gran responsabilidad del historiador: la historia tiene una proyección al futuro por su potencia transformadora como herramienta de cambio social; y a los profesionales que la manejan, los historiadores, les es aplicable lo que Marx dijo de los filósofos ("hasta ahora se han encargado de interpretar el mundo y de lo que se trata es de transformarlo"). No obstante, desde otra perspectiva se pretende una "investigación desinteresada" para la objetividad en la ciencia histórica. Aunque "llegar a conocer los hechos tal como fueron", como pretendía Leopold Ranke, es imposible, sí es un imperativo de la investigación histórica acercarse al máximo a ese objetivo, y además hacerlo con una perspectiva tal que sitúe los hechos en su contexto, de modo que al conocimiento factual se añada el entendimiento de "lo que realmente pasó"; y aunque sea inevitable que sesgos de todo tipo alteren la forma en que tal entendimiento se produce, al menos ser conscientes de cuáles pueden ser y en qué grado actúan.

No hay un acuerdo universal sobre la periodización de la historia, aunque sí un consenso académico sobre los periodos de la historia de la civilización occidental, basado en los términos acuñados inicialmente por Cristóbal Celarius (Edades Antigua, Media y Moderna), que ponía al mundo clásico grecorromano y su Renacimiento como los hechos determinantes para la división; y que actualmente es de aplicación general. La acusación de eurocentrismo que se hace a tal periodización no impide que sea la más utilizada, por ser la que responde precisamente al desarrollo de los procesos históricos que produjeron el mundo contemporáneo.

En cuanto a la división del tiempo prehistórico en Edad de la Piedra y Edad de los Metales, fue propuesta en 1836 por el arqueólogo danés Christian Jürgensen Thomsen.

La evolución tecnológica presenta dos grandes cesuras en el pasado de la humanidad: la revolución neolítica y la revolución industrial, lo que permite hablar de tres grandes periodos: el caracterizado por la exclusividad de sociedades cazadoras-recolectoras, el preindustrial y el industrial (a veces se emplea el adjetivo postindustrial para el periodo de la historia más reciente).

El problema de cualquier periodización es hacerla coherente en términos sincrónicos y diacrónicos, es decir: que sea válida tanto para "el transcurso del tiempo" en un único lugar, como para lo que ocurre "al mismo tiempo" en distintos ámbitos espaciales. Cumplir ambos requisitos resulta difícil cuando los fenómenos que originan el comienzo de un periodo en un lugar (especialmente el Próximo Oriente, Asia Central o China) tardan en difundirse o surgir endógenamente en otros lugares, que a su vez pueden estar más o menos próximos y conectados (como Europa Occidental o el África subsahariana), o más o menos lejanos y desconectados (como América u Oceanía). Para responder a todo ello, los modelos de periodización incluyen términos intermedios y periodos de solapamiento (yuxtaposición de características distintas) o transición (aparición paulatina de las novedades o características mixtas entre el periodo que empieza y el que termina). La didáctica de la historia se ayuda frecuentemente de diferentes tipos de representación gráfica de la sucesión de hechos y procesos en el tiempo y en el espacio.






</doc>
<doc id="1372" url="https://es.wikipedia.org/wiki?curid=1372" title="Hadrón">
Hadrón

Un hadrón (del griego ἁδρός, "hadrós", "denso" o "fuerte") es una partícula subatómica formada por quarks que permanecen unidos debido a la interacción nuclear fuerte entre ellos. Antes de la postulación del modelo de quarks se definía a los hadrones como aquellas partículas que eran sensibles a la interacción fuerte.

Como todas las partículas subatómicas, los hadrones tienen números cuánticos correspondientes a las representaciones del grupo de Poincaré: codice_1, donde codice_2 es el espín, codice_3 la paridad, codice_4 la paridad C, y codice_5 la masa. Además, pueden llevar números cuánticos de sabor como el isoespín, extrañeza, etc.

El término "hadrón" fue introducido por Lev B. Okun en una asamblea en la International Conference on High Energy Physics de 1962. En esta asamblea dijo:
Tanto el modelo de quarks, como la evidencia empírica sugieren que los hadrones son partículas compuestas por quarks y/o antiquarks. Hay dos tipos de hadrones (sin contar los casos "exóticos"):
Estas partículas tienen un número bariónico (codice_6) diferente de cero, que es igual a +1 para los nucleones e igual a -1 para sus antipartículas.

La mayor parte de los hadrones se han podido clasificar adecuadamente por el modelo de quarks, que postula que todos los números cuánticos de los bariones se derivan de aquellos de los "quarks de valencia". Para un barión estos son tres quarks, y para un mesón estos son un par quark-antiquark.

Cada quark es entonces un fermión con codice_6 = 1/3. Los estados excitados bariónicos o mesónicos son conocidos como resonancias. Cada estado fundamental hadrónico puede tener muchos estados excitados, y cientos han sido observados en experimentos con partículas. Las resonancias decaen extremadamente rápido (aproximadamente en 10 s) por las interacciones fuertes.

Los mesones que se encuentran fuera de la clasificación según el modelo de quarks se denominan mesones exóticos. Estos incluyen bolas de gluones, mesones híbridos y tetraquarks. Los únicos bariones que están fuera del modelo de quarks a la fecha son los pentaquarks, pero la evidencia de su existencia no ha sido esclarecida aún. Recientemente se ha demostrado la existencia del hadrón Z(4430), con un nivel de confianza de sigma 13.9.

Las resonancias son partículas masivas de muy corta existencia, se desintegran muy rápidamente en partículas más ligeras. Desde la aparición del modelo de quarks se las interpreta como estados excitados con una energía superior a la del estado fundamental, de sistemas ligados de quarks. Por tanto las resonancias no serían estrictamente estructuras diferentes, aunque inicialmente fueron interpretadas así por tener una masa diferente a la del estado fundamental (la discrepancia de masa tiene que ver con la relación "E" = "mc").

Todos los hadrones son sistemas de quarks ligados mediante interacción fuerte, la teoría estándar que da cuenta de esta interacción fuerte es la cromodinámica cuántica (en inglés "quantum chromodynamics" o QCD). Esta teoría postula diversos tipos de quarks que interaccionan entre sí mediante un campo gluónico. Dicho campo está formado por bosones denominados gluones. Debido a una propiedad importante de la teoría llamada confinamiento, los quarks con energías por debajo de la escala QCD experimentan este confinamiento, que impiden observar quarks libres a bajas energías, por lo que usualmente aparecen en forma de hadrones. Otra propiedad interesante de la teoría es que estos sistemas ligados de quarks o hadrones que son compuestos, y no llevan carga de color: si están formados por 3 quarks uno es "rojo", otro es "verde" y otro "azul" (de tal manera que se dicen que son "blancos"). En los mesones si el quark es de un "color" y anti-quark tienen el "anticolor" correspondiente. Así que globalmente no predomina ningún "color" que es una de las consecuencias del confinamiento.

En otras fases de materia QCD los hadrones pueden desaparecer. Por ejemplo, a temperatura y presión muy altas, a menos que haya suficiente cantidad de sabores muy masivos de quarks, la teoría QCD predice que los quarks y gluones van a interactuar débilmente y ya no estarán confinados. Esta propiedad, que se conoce como libertad asintótica, ha sido experimentalmente confirmada a las escalas de energía de entre un GeV y un TeV. Pero esta teoría pronto se pondrá a prueba ya que el 10 de septiembre de 2008 se puso en funcionamiento un acelerador de partículas o hadrones (el LHC, gran colisionador de hadrones, por sus iniciales en inglés), que mide 27 km de circunferencia, situado en el límite entre Francia y Suiza, cerca de la ciudad de Ginebra, y ha costado 3.700 millones de Euros (unos 6.000 millones de dólares según algunas fuentes).



</doc>
<doc id="1373" url="https://es.wikipedia.org/wiki?curid=1373" title="Hora">
Hora

La hora es una unidad de tiempo que se corresponde con la vigésima cuarta parte de un día solar medio.

Se utiliza para el tiempo civil y comprende 60 minutos o 3600 segundos, aunque pequeñas irregularidades en la rotación de la Tierra hacen que sean necesarios ajustes. Dado que desde 1967 el segundo se mide a partir de propiedades atómicas muy precisas, para mantener los estándares de tiempo cercanos al día solar medio se utilizan segundos intercalares.

En castellano el término "hora" no tiene abreviatura, pero si se utiliza como indicación del momento en que sucede o se hace una cosa en relación con cada una de las veinticuatro partes en que se divide el día y se escribe con cifras, opcionalmente puede emplearse el símbolo h, y en ese caso debe escribirse sin punto y es invariable en plural. No obstante, en países americanos que tienen al castellano como su idioma principal, es común que usen el sistema de 12 horas es decir, dividir las 24 horas en 12 horas; por ejemplo, en vez de ser las 01:00 h, serán las , en vez de ser las 13:00 h serán las aunque se use para señalar un singular.

Se llama hora a la doceava parte del tiempo que transcurre desde la salida del Sol hasta su puesta. Los egipcios dividían el día en veinticuatro horas, doce con luz solar y doce nocturnas, sería este sistema el que adoptaron los griegos y los romanos. Estos últimos, primero aplicaron el sistema de doce horas diurnas y más tarde al cómputo de la noche, tiempo transcurrido desde la puesta del Sol hasta su salida, también fue dividida en doce horas. Este tipo de horas se medía mediante un reloj de sol o mediante una Clepsidra. Cuando un reloj mecánico utiliza estas horas, su rapidez debe ser cambiada cada mañana y tarde, por ejemplo cambiando el largo de su péndulo. La hora según esta definición está regulada según el Sistema Horario Temporario.

El tiempo, a su vez, puede ser medido a través del uso de un reloj. El propósito de establecer un horario, por ejemplo, consiste en indicar el momento preciso en que tendrá lugar un hecho futuro para que las personas puedan organizar su rutina.

Posteriormente fue definida como la veinticuatroava parte del día solar aparente, lapso entre un mediodía y el siguiente, o entre una puesta de sol y la próxima. En esta definición las horas varían un poco, puesto que la duración del día solar aparente varía a lo largo del año. Cuando un reloj utiliza estas horas, debe ser ajustado unas pocas veces durante el mes. Según se tome como origen el paso del Sol por el Ocaso o el Orto se denominará Sistema Horario Itálico o Sistema Horario Babilónico respectivamente.

La hora es también una medida angular:la Tierra da una vuelta sobre sí misma en aproximadamente 24 horas, una hora equivale a 15° (o sea, la veinticuatroava parte de la circunferencia). En todo meridiano terrestre el paso del Sol se produce al mediodía; una hora después pasará por otro meridiano situado a 15° al oeste del primero y así sucesivamente hasta medianoche, en cuyo momento preciso se hallará en el antemeridiano del meridiano de origen. A partir de entonces, el Sol se acerca a este por levante, hasta volver al punto inicial 24 horas después.

Ahora bien, dada la forma esferoide del globo terrestre, la superficie limitada por dos meridianos separados por la distancia angular de 15° tiene la forma de un huso. Por convención universalmente adoptada, todos los relojes situados en el interior de un mismo huso horario indican la misma hora, aunque esa regla forzosamente tiene ciertas excepciones. Así, cuando una parte relativamente pequeña de un país se halla fuera del huso, se considera (para uniformar la hora nacional) que todo el territorio está en el huso principal. En los países muy extensos de este a oeste, como la Federación Rusa, Canadá o Estados Unidos, no existe "una" hora nacional, sino tantas horas como husos atraviesan el territorio. O en otros casos una parte de un país se puede sujetar a un horario, como por ejemplo el estado mexicano de Sonora que no cambia nunca su horario y mantiene la misma hora que su vecino estado fronterizo de Arizona.

Ciertos países, aprovechando que el Sol se oculta más tarde en verano, instituyen unos meses al año la llamada "hora de verano", es decir, adelantan todos los relojes de una hora, lo cual equivale a adoptar la hora del huso contiguo situado al este. Del mismo modo, en invierno se vuelve al huso horario original para aprovechar al máximo posible la luminosidad del Sol. En la Unión Europea este cambio tiene lugar en el mismo día para todos los Estados Miembros.

En otros casos, razones geopolíticas incitan a un país a adoptar de modo permanente la hora correspondiente al huso vecino: España, ubicada en el huso 0 cambió a la hora del huso 1 (hora CET), con objeto de facilitar las relaciones con la parte Occidental y Central de la Unión Europea.

El conocimiento de la hora tiene muchas repercusiones, tiene mucha importancia en astronomía y en otros campos de la actividad humana. Por esa razón, existen servicios internacionales y nacionales encargados de conservar una hora exacta y de difundirla a los usuarios. Durante largo tiempo, la tarea de determinar la hora estuvo a cargo de astrónomos que se fundaban en los movimientos de los astros. En la actualidad, se utilizan relojes atómicos que indican la hora con una enorme precisión.

La hora exacta y oficial de España, se mantiene según el reloj atómico del Real Instituto y Observatorio de la Armada (ROA) de San Fernando (Cádiz).

En México la hora oficial la determina el Centro Nacional de Metrología (CENAM), dependiente de la Secretaría de Economía.

En Chile la hora oficial la determina el Servicio Hidrográfico y Oceanográfico de la Armada de Chile (SHOA).

En Colombia la hora oficial la determina el Instituto Nacional de Metrología de Colombia.

En Costa Rica la hora oficial la determina el Instituto Meteorológico Nacional de Costa Rica (IMN).







</doc>
<doc id="1375" url="https://es.wikipedia.org/wiki?curid=1375" title="Hypericaceae">
Hypericaceae

Hypericaceae es una familia cosmopolita del orden Malpighiales, aceptada por la APG II (2003), con alrededor de 560 especies repartidas en 9 géneros. Se extiende desde las regiones templadas hasta los trópicos.

Plantas leñosas o herbáceas (árboles y lianas en los trópicos), glandulíferas (glándulas pedunculadas o sentadas aspecto en las hojas translúcido). Rica en aceites y resinas de color amarillo intenso, usadas como colorantes (gutagamba). Hojas opuestas o verticiladas, simples y enteras. Flores reunidas en inflorescencias terminales, en panículos, umbelas y cimas, generalmente hermafroditas, regulares, dispuestas en cimas dicasiales o solitarias (raramente); corola y cáliz con 4 - 5 piezas libres, pétalos amarillos; androceo con numerosos estambres unidos y agrupados solo por la base en 4 - 5 haces; gineceo súpero, sincárpico, con 3 - 5 carpelos, estilos libres. Frutos en cápsulas septicidas, bacciformes o drupáceos.

Lista de géneros y sinónimos relacionados alfabéticamente según APWeb:



</doc>
<doc id="1379" url="https://es.wikipedia.org/wiki?curid=1379" title="Historia del constitucionalismo español">
Historia del constitucionalismo español

La historia del constitucionalismo español es reflejo directo de las convulsiones políticas españolas de los siglos XIX y XX, mostrando las tensiones sociales y políticas que existieron en el país.

El constitucionalismo español, se podría definir como el proceso a través del cual el Estado español se ha dotado desde 1808 de una serie de normas magnas 

La crisis del Antiguo Régimen absolutista se agudizó en 1808, produciéndose el Motín de Aranjuez contra Godoy y el propio Rey Carlos IV de España. Este abdica en favor de su hijo Fernando VII de España, pero antes de consolidarse en el poder, Napoleón les hace ir a Bayona con el pretexto de arbitrar sus querellas familiares. Napoleón hace abdicar a padre e hijo en favor de su hermano José Bonaparte. Evitando aparecer un usurpador, Napoleón convocó en Bayona una asamblea de diputados, a los que presentó un texto de Constitución, promulgado el 8 de julio de 1808.

La asamblea de Bayona debería estar formada por cincuenta nobles, cincuenta eclesiásticos y cincuenta representantes del pueblo, pero solo acudieron sesenta y cinco personas, la mayoría nobles, a la que se añadieron algunos españoles residentes en Francia. La asamblea fue presidida por Miguel José de Azanza, discutió varios problemas y aprobó el proyecto de Constitución presentado por Napoleón el 7 de julio de 1807. Había sido redactado por M. Esmenard, un francés residente en España, y fue revisado por el general Joaquín Murat y el mismo emperador.

Organizaba España como una monarquía hereditaria en la cual, el monarca ocupaba el centro del poder político, pero con la obligación de respetar los derechos de los ciudadanos proclamados en su texto.

Nació en un contexto complejo, dictado fuera del territorio nacional y con un marcado carácter afrancesado, apadrinado por los liberales moderados. Debido a que no fue elaborada por los representantes de la Nación, por su origen y proceso no puede considerarse una Constitución, sino una Carta otorgada.

Se abre con la definición confesional del Estado, para tratar después todo lo referente a la Corona y, en títulos posteriores, aborda el entramado institucional, finalizando con un desordenado reconocimiento de determinados derechos y libertades. Pese a establecerse un conjunto de instituciones, no puede hablarse de división de poderes: las atribuciones del monarca eran amplísimas, las Cortes se estructuraban en la representación estamental y las facultades del Senado y de las propias Cortes carecían de fuerza para obligar. Aun así, debido al contexto histórico, este diseño no pudo desarrollarse.

El estatuto de Bayona contiene los elementos de una reforma política y social, tendentes a desarrollar el comercio, disminuir las bases del poder de la nobleza y potenciar a la burguesía. Se pueden destacar:

Respecto de los derechos y libertades, cabe destacar el carácter confesional que se le atribuye a España:

El artículo 1 señalaba que “"La religión Católica, Apostólica y Romana, en España y en todas las posesiones españolas, será la religión del Rey y de la Nación y no se permitirá ninguna otra".”

En un último título se contempla (disposiciones generales) una serie de derechos y libertades. La influencia de la Revolución francesa fue importante: se regulaban derechos de los inicios del liberalismo burgués, lo que suponía un avance respecto de la situación existente.

El Estatuto preveía un papel predominante del monarca, aunque su estatuto personal y prerrogativas no venían claramente enunciados. No obstante, del ámbito funcional de las instituciones, se revelan los amplios poderes del Rey. La importancia se observa en su ubicación (tras la religión) y que le dedica 4 de los 13 títulos.

Tampoco tuvieron vida efectiva. Se estructuraba en 3 estamentos (alto clero, nobleza y pueblo), donde se advertía una clara influencia del Antiguo Régimen, así como contradicción con los principios inspiradores de la Revolución. No se les confería de modo expreso la función legislativa, aunque sí de forma tácita en algunos preceptos.

Desconocía la institución del Gobierno. Contemplaba un título a los ministerios en el que establece un número (7-9) y su denominación. Los ministros eran responsables de la ejecución de las leyes y órdenes del rey. También regula la Administración de Hacienda, que aboga por la supresión de aduanas interiores, separa el Tesoro público del de la Corona y se configura un Tribunal de Contaduría para el examen y aprobación de las cuentas.

Órgano que agrupaba funciones diseminadas del Antiguo Régimen y acaba con la polisinodía en la que se confundían funciones de orden normativo con otras ejecutivas y judiciales. Tenía la facultad de examinar y extender los proyectos de leyes civiles y criminales y los reglamentos generales de la Administración. No deben confundirse sus funciones con las del actual Consejo de Estado, meramente consultivo.

Tenía importancia crucial. Se configuraba como independiente, aunque el rey nombraba a todos los jueces. Se articulaba en distintas instancias a las que los ciudadanos podían acudir, se establecía la publicidad del proceso criminal y se emplazaba a la creación de un único código de leyes civiles y criminales y otro de comercio para España y las Indias, para poder racionalizar el caótico sistema normativo de entonces.

La marcha de Fernando VII y la presencia invasora francesa provocó un vacío de poder en 1808. La guerra había empezado y las capitulaciones de los monarcas ante Napoleón acrecentaron la sensación de vacuidad. Frente al derrumbamiento de la Administración, la resistencia se estructura a través de juntas provinciales y locales que representan un auténtico poder paralelo, hecho que conllevaría a que la legitimidad monárquica diera paso a la popularidad.

Frente a esta pluralidad de centros de poder, se crea la Junta Central que procederá a la convocatoria de Cortes (no estamentales) que devendrán constituyentes: el 24 de septiembre de 1810 se constituían las Cortes de Cádiz y el mismo día se aprueba un Decreto en el que aparecen los principios básicos del futuro texto constitucional: la soberanía nacional y la división de poderes.

Estaban formadas por una amalgama de intereses: pese al marcado sello liberal de las Cortes, existía presencia de corrientes absolutistas y reaccionarias junto a diputados reformistas o radicales. Incluso parte de los diputados conservadores acabarían promulgando un manifiesto en el que pedían a Fernando VII que suprimiera a su retorno la Constitución (Manifiesto de los Persas). Aun así, la Constitución tendrá un carácter de compromiso entre las opciones liberales y absolutistas. Fue promulgada por las Cortes Generales españolas reunidas extraordinariamente en Cádiz el 19 de marzo de 1812.

Por Decreto de 4 de mayo de 1814, Fernando VII derogó la Constitución de 1812 y todas las disposiciones dictadas en su desarrollo, y a partir de esa fecha fueron restableciéndose las del Antiguo Régimen Absolutista (si bien, como afirma algún autor, bajo la promesa de redactar una nueva Constitución). Posteriormente se volvió a aplicar desde el 8 de marzo de 1820, cuando en Madrid (España), Fernando VII es obligado a jurar la Constitución española de 1812, estando vigente durante el Trienio Liberal (1820-1823).


La Constitución carece de un título específico, pero a lo largo del texto se recogen de forma diseminada distintos derechos.

Por un lado, el artículo 12 ("la religión de la nación española es y será perpetuamente la Católica Apostólica Romana, y la nación la protege por leyes sabias y justas y prohíbe el ejercicio de cualquier otra") es confesional y cerradamente confesional, al imponer una religión y prohibir el resto. Es pues, a "sensu contrario", la negación de la libertad religiosa.

Los derechos reconocidos y diseminados por el texto reproducían los derechos individuales burgueses importados de la Revolución francesa, así, el artículo 4 habla de la libertad civil, la propiedad y los demás derechos legítimos (cláusula abierta).

La igualdad parece enunciada de forma menos enfática que en la Declaración de los Derechos del Hombre y del Ciudadano de 1789, se formulaba la existencia de un solo fuero para toda clase de personas en causas civiles y criminales y se reconocía el sufragio activo. Existía libertad de expresión (excepto en los escritos religiosos).

Se articulaban garantías en las detenciones y procesos judiciales: prohibición del tormento, inviolabilidad personal y domiciliaria, el habeas corpus, a ser informado de las causas, entre otras. Se dedicaba un título específico a la instrucción pública, dando importancia a la enseñanza y reconociendo una instrucción pública para todos los ciudadanos.

Era unicameral para evitar intermediaciones entre los representantes de la soberanía y el rey, evitando así una segunda cámara de aristócratas elegidos por el rey. El proceso de elección se regulaba con todo detalle, mediante sufragio indirecto en cuatro grados: la primera elección era casi universal (varones mayores de edad) para luego ir restringiéndose conforme avanza hacia un sufragio censitario pasivo.

La legislatura era de dos años y regía el principio de automaticidad de la convocatoria, ya que no dependía de la voluntad real, se reunían cada año durante tres meses y se preveían sesiones extraordinarias. Además, había una Diputación Permanente que velaba por los poderes de la Cámara cuando esta no estaba reunida.

Las sesiones, salvo que dispusieran lo contrario, eran públicas. Tenían potestad para crear su Reglamento de organización y funcionamiento interno, y se establecía la inviolabilidad de los diputados en sus opiniones y en el ejercicio de sus funciones, y la inmunidad en causas criminales contra ellos, que debían ser juzgadas por un Tribunal de las Cortes.

Ejercía la potestad legislativa junto con el rey, ya que la iniciativa se atribuía a éste y al diputado individual. También tenía una potestad financiera en cuanto fijaba los gastos de la Administración y aprobaba el reparto de las contribuciones.

La figura del Rey se regulaba como un órgano constitucional que tenía poderes limitados (poder constituido) en la medida que compartía el poder político con otras instituciones (sobre todo, las Cortes). El Art. 172 pone de relieve un amplio número de materias en las que no podía intervenir. De sus funciones, cabe destacar la legislativa a través de 2 instrumentos: 1) iniciativa legislativa y 2) la sanción y promulgación de las leyes, así como la posibilidad de interponer un veto suspensivo de carácter temporal en determinadas condiciones.

El poder ejecutivo recae en el rey, al tener la competencia sobre la dirección de la política interior y exterior, ejercicio de la función ejecutiva y potestad reglamentaria (en lo no atribuido a las Cortes) y la defensa. En esencia, parecidas a las ejercidas hoy en día por el Gobierno. La figura del Rey era inviolable y no sujeta a responsabilidad, articulándose en el texto constitucional la figura del referendo.

Se preveía la existencia de un Consejo de Estado, cuyos miembros eran nombrados por el rey a propuesta de las Cortes, que asesoraban al Rey y no tenían función jurisdiccional (diferencia del Estatuto de Bayona). Sus dictámenes no eran vinculantes.

El rey tenía la potestad vigente de crear normas espaciales por el desarrollo público del estado de vinculación directa parlamentaria.

Nombrados y separados por el rey, estableciéndose un cargo incompatible con el de diputado (separación rígida de poderes). La Constitución no contemplaba al Gobierno como órgano colegiado. No obstante, la práctica condujo a la existencia del órgano de Gobierno (reunión de los Secretarios) presidido por el rey y, mediante Decreto de 1824, por el Presidente del Consejo de Ministros en ausencia de este. Se configuraba este Presidente como un primus inter pares que dirigía las sesiones cuando no estuviera presente la figura del Rey.

Se reconocía la integración del Estado en comarcas y provincias con cierta descentralización incipiente de carácter administrativo. El gobierno se articulaba a través de Diputaciones y Ayuntamientos y se preveía la figura del Jefe Superior, nombrado por el rey, al que se le confería el gobierno político de las provincias y presidencia de los Ayuntamientos (donde hubiere). Es una excepción al principio electivo, interferencia del poder central en las instituciones locales y un precedente de la institución del Gobernador civil.

Una vez producida la muerte de Fernando VII en 1833, la maquinaria del Estado estaba en manos de los liberales. El testamento otorgaba como sucesora a Isabel II y nombraba Reina Gobernadora a María Cristina, esposa del Rey. Durante la enfermedad del monarca y ante las pretensiones carlistas, la Corona se alía con los liberales concediendo una amplia amnistía e inicia un reformismo moderado que topa con la oposición carlista (en parte por motivos socioeconómicos y la cuestión foral).

La pretensión de abrir el sistema político a la participación de los liberales moderados se hará mediante la elaboración de una norma (Estatuto) con vocación transitoria. Fracasada la reforma de Cea Bermúdez, la Regente (en 1834) encarga la formación del Gobierno a Martínez de la Rosa quien, junto a Garelly y Javier de Burgos, será autor del Estatuto Real (que será sancionado el 10 de abril de ese mismo año).



Son bicamerales (no volverán a ser unicamerales hasta 1931) formadas por: Estamento de Próceres (cámara alta) y Estamento de Procuradores (cámara baja). Tiene reminiscencias del Antiguo Régimen: los Próceres son aristócratas sociales divididos entres los Grandes de España y los elegidos por el rey. Eran cargos vitalicios, de número indeterminado, garantizándose con ello las mayorías suficientes a la monarquía. Los Procuradores, se basaba en el principio electivo de sus miembros pero se exigía una renta alta (sufragio censitario).

El Estatuto no contemplaba el sistema electoral y se remitía a leyes posteriores de diverso signo: la primera (1834) era de sufragio indirecto y censitario y la segunda (1836) sistema de elección directa y sufragio censitario y capacitario. Estaban a medio camino entre una asamblea consultiva y una legislativa. No tenían capacidad auto normativa, pues el Reglamento de ambas Cámaras debía ser aprobado por la Reina Gobernadora previo dictamen del Consejo de Gobierno y de Ministros. Además, se preveían constantes interferencias del Rey en el funcionamiento de las Cortes, lo que impide el principio de autonomía parlamentaria, quedando éstas reducidas a un organismo de colaboración y consulta del monarca.

Las leyes requerían la aprobación de las 2 cámaras y la subsiguiente sanción real, reconociéndose implícitamente la capacidad de veto absoluto del Rey. No disponían de automaticidad de convocatoria, pues era el rey quien las convocaba, suspendía o disolvía.

Se le concedía un conjunto desorbitado de facultades:

Sin duda, es importante la "constitucionalización" de la figura del Presidente del Consejo de Ministros en varios pasajes. Aunque solo hable ocasionalmente de Gobierno, el resto de referencias van dirigidas al Consejo de Ministros. También recoge la denominación de Ministro frente a la de Secretario de Estado y del Despacho (heredada de la época de Felipe V). Aparece un incipiente proto-sistema de parlamentarismo al necesitar la doble confianza (Rey y Cortes) para gobernar y la aparición de la llamada "cuestión de gabinete" o "cuestión de confianza".

El sistema del Estatuto Real se mantuvo vigente hasta 1836, cuando la Guardia Real de la Granja impuso a la Reina Regente el restablecimiento de la Constitución de 1812 y la convocatoria de unas Cortes constituyentes. Sin embargo, ante la evidente imposibilidad política de restablecer la Constitución de 1812, los progresistas decidieron reformarla en un nuevo texto que fuese asimilable tanto para los progresistas como para los moderados, siendo el primer intento serio del constitucionalismo español en establecer una Constitución consensuada, en un momento álgido de la guerra civil para así mostrar, tanto interna como externamente -muchos países no olvidaban el caos europeo que supuso el restablecimiento de la norma gaditana- un frente liberal unido frente al carlismo.

Por ello, los progresistas hicieron concesiones importantes con el fin de que los moderados respaldasen la nueva norma:

No obstante, también se incluyeron ciertos credos progresistas como la elección popular de los Ayuntamientos y las Diputaciones Provinciales, y el restablecimiento de la Milicia Nacional.

En el aspecto religioso se llega a un acuerdo de consenso: el Estado se declara aconfesional admitiendo la libertad de cultos, pero se compromete de modo especial con la Iglesia Católica, costeando los gastos de "culto y clero" como compensación a la desamortización de sus bienes.

Se mantiene la Milicia Nacional.

Los municipios se regirán por alcaldes elegidos por el pueblo.

Tras las tumultuosas regencias de la Reina Regente y del general Espartero, se disuelve el Senado, se proclama la mayoría de edad de la Reina Isabel II, y se convocan nuevas elecciones a Cortes, con victoria de los moderados liderados por el general Narváez, quienes deciden reformar la vigente Constitución por otra más acorde a sus ideas -a pesar de la oposición progresista y de algunos sectores moderados, que defendían la norma de 1837 porque había sido fruto del consenso político y que les serviría para alternarse en el poder sin tener que cambiar la Constitución cada vez que se cambiase el Gobierno-.

Por tanto, el texto resultante no fue una simple reforma del anterior -aunque fue la única Constitución española surgida del procedimiento de reforma estipulado en la anterior Constitución-, sino que establecieron cambios muy importantes:

-El Senado, de nombramiento real y carácter vitalicio.

-El Congreso de los Diputados, elegidos por sufragio censitario (muy restringido del 1% de electores).

Durante la Década Moderada (1844-1854) transcurrió la Revolución de 1848, se suspendieron las garantías constitucionales con el fin de evitar la propagación de la ola revolucionaria europea en España. Aprovechando este contexto y tras lograr firmar un nuevo concordato, en 1852 el moderado ultramontano Juan Bravo Murillo, el entonces primer ministro español elaboró un proyecto constitucional en 1852 cuyo objetivo era volver a una normativa más acorde al Antiguo Régimen o a un sistema basado en una Carta otorgada similar al derogado Estatuto Real de 1834, con la intención de atraerse a los sectores más proclives al carlismo.

Sin embargo, la oposición al nuevo proyecto constitucional fue de tal naturaleza, tanto entre los moderados como en los demás partidos, que no podía prosperar de ninguna manera.

Esta constitución non nata surgía como producto del Bienio progresista iniciado en 1854, que acabó con la Década moderada.

Su contenido reafirmaba de forma absoluta el principio de la soberanía nacional, de modo que nada se da por preconstituido y todas las instituciones, incluida la Corona, encontrarían su fundamento en la voluntad nacional. También se reconocía ampliamente los derechos políticos e instalaba, por primera vez en España, un régimen de tolerancia religiosa. Se continuó manteniendo el sufragio directo censitario, aunque el Senado volvería a ser electivo. Se restablecía además, al igual que lo hacía la Constitución de 1812, la Diputación permanente de las Cortes, cuya función era velar por la observancia de la Constitución cuando las Cortes estuviesen cerradas. Se trata de una constitución un tanto rígida; ya que establece un procedimiento difícil de reforma; procedimiento que en parte fue seguido por el resto de constituciones que se promulgaron con posterioridad.

No obstante, este proyecto constitucional no terminó siendo promulgado tras la contrarrevolución de 1856, liderada por el general O'Donnell.

Después de que la Corte huyera a Francia, el poder supremo se confió al general Serrano, que convocó Cortes constituyentes que elaboraron un nuevo texto constitucional.

Esta fue una constitución democrática que estuvo vigente hasta el año 1873. La soberanía era nacional y el poder estaba dividido: el poder legislativo lo tenían las cortes, el poder ejecutivo residía en el rey y el poder judicial en los tribunales. Se continuó con la religión católica como religión oficial del estado aunque el texto garantizaba el ejercicio de cualquier otra, en público o en privado, en su artículo 21. Sufragio universal masculino.

Elaborada durante la I República que no llegó a promulgarse, que definía España como una República Federal, integrada por diecisiete Estados, que se daban su propia Constitución y que poseerían órganos legislativos, ejecutivos y judiciales, según un sistema de división de competencias entre la Federación y los Estados miembros. Sin embargo, la imposibilidad de llegar a un acuerdo para articular el funcionamiento de los Estados dentro de la federación, impidió que llegara a buen fin el proyecto.

Tras el golpe de Estado del general Pavía en enero de 1874, no se consiguió que ningún grupo político ofreciera una fórmula estable de gobierno. Ante esta situación, el futuro Alfonso XII, desde Inglaterra, se dirigió a los españoles a través del conocido como Manifiesto de Sandhurst, ofreciéndose para gobernar bajo la fórmula de monarquía liberal. El general Martínez Campos llevó a cabo el Pronunciamiento de Sagunto de diciembre de 1874, que pondría fin a la I República y que daría lugar a la Constitución de 1876.

La nueva Carta Magna propondría a Alfonso de Borbón, hijo de la destronada Isabel II de España como Jefe de Estado con ciertas prerrogativas —por ejemplo, la soberanía compartida o el veto real—. Aunque inicialmente era partidaria del sufragio censitario, la Constitución de 1876 se reforma en 1890 para traer el sufragio universal masculino. La Constitución de 1876 fue suspendida en 1923, tras el golpe de Estado del capitán general Miguel Primo de Rivera, lo que la hace la constitución más longeva de la historia de España (47 años).

El proyecto de Constitución de 1929, llamada Estatuto Fundamental de la Monarquía, fue un proyecto de constitución —o mejor de carta otorgada— elaborado por la Sección Primera de la Asamblea Nacional Consultiva designada por la Dictadura de Primo de Rivera en octubre de 1927. Pretendía ser la nueva ley fundamental de la Monarquía de Alfonso XIII en sustitución de la Constitución liberal de 1876, suspendida desde el triunfo del golpe de Estado de Primo de Rivera en septiembre de 1923. Quería instaurar en España un régimen autoritario, antiliberal y antidemocrático, ya que en su articulado se limitaba drásticamente el ejercicio de los derechos y libertades, no se establecía la división de poderes ni se reconocía la soberanía nacional, sólo la mitad de las Cortes unicamerales era elegida por sufragio universal, mientras que la otra mitad era designada por las "corporaciones" y por el rey, y sus poderes y atribuciones habían sido muy mermados en favor de la Corona y del Consejo del Reino, una nueva institución con rasgos del Antiguo Régimen —antecedente del organismo del mismo nombre de la Dictadura franquista—. El proyecto rompía con toda la historia del constitucionalismo español y no satisfizo a nadie, ni siquiera al dictador, debido a los amplios poderes que concedía al rey en detrimento del jefe del gobierno, por lo que no llegó a discutirse en el Pleno de la Asamblea Nacional Consultiva y nunca entró en vigor.

La constitución republicana de 1931, nacida de unas elecciones municipales y de la posterior renuncia al trono por parte de Alfonso XIII introduce por primera vez algunas innovaciones del constitucionalismo contemporáneo, como son la renuncia a la guerra como forma de resolución de conflictos internacionales, o la inclusión, a partir de las teorías de Kelsen, de un Tribunal Constitucional, llamado Tribunal de Garantías Constitucionales. Introduce también, por primera vez, la descentralización del Estado, por medio de las Regiones Autónomas, anticipo de la organización territorial de la constitución de 1978.

Las profundas contradicciones de la sociedad española de los años veinte y treinta desembocarán en la Guerra Civil Española, tras la cual se instaurará la dictadura del General Francisco Franco, que supondrá la derogación de esta constitución y su sustitución por las Leyes Fundamentales del Reino, vigentes hasta la aprobación de la última constitución democrática de 1978.

Por tales se conoce el conjunto de leyes que establecían el entramado político-institucional del modelo de Estado dictatorial instaurado por el general Francisco Franco tras la Guerra Civil Española, pero no se les reconoce el carácter de Constitución pues no reconocían el principio de soberanía nacional y por encima de ellas se situaba el poder del general Franco, que eran quien las había promulgado.

La primera fue el Fuero del Trabajo que regulaba la vida laboral y económica. La Ley Constitutiva de las Cortes de 1942 establecía las Cortes como instrumento colaborador. En el Fuero de los Españoles de 1945 se fijaron los derechos y deberes de los españoles. La Ley del Referéndum Nacional de 1945 regulaba el referéndum. Por la Ley de Sucesión en la Jefatura del Estado de 1947 España se configura como un reino. La Ley de Principios del Movimiento Nacional de 1958 señala los principios rectores del ordenamiento jurídico y la Ley Orgánica del Estado de 1967, reforma todas las anteriores y fija los poderes del jefe del Estado.

Finalmente, la Ley para la Reforma Política de 1977 fue el instrumento jurídico que permitió articular la Transición española.

Nacida de la reforma legal realizada por las Cortes Españolas que condujo a la Ley para la reforma política, y fruto de la negociación entre los diversos partidos políticos surgidos tras las elecciones generales de España de 1977; consensuándose así una carta magna en donde participaron políticos que representaban a la inmensa pluralidad de las diferentes ideologías políticas, tanto del espectro derecha-izquierda como de los diversos posicionamientos sobre la vertebración territorial, social y económica de España. Esta constitución acoge la monarquía parlamentaria como forma política del Estado; asume la asunción de los valores democráticos, sociales y del Estado de Derecho, así como la recuperación de la organización territorial de la constitución republicana de 1931. La constitución de 1978 es la única refrendada y aprobada por el pueblo español mediante referéndum.

La cronología utilizada es la de su fecha de promulgación, que difiere de los períodos de vigencia y así:






</doc>
<doc id="1381" url="https://es.wikipedia.org/wiki?curid=1381" title="Haloragaceae">
Haloragaceae

Las Haloragaceae son una familia del orden Saxifragales.

Son plantas herbáceas o sufrutescentes, perennes, acuáticas o terrestres; tallos rizomatosos o erectos; plantas hermafroditas o monoicas. Hojas alternas, opuestas o verticiladas, simples o pectinadas, estipuladas o con las estípulas como escamas. Flores solitarias y axilares o en espigas, racimos o panículas terminales; flores unisexuales o raramente perfectas, epíginas; perianto ausente, uniseriado o biseriado; sépalos ausentes o 2–4; pétalos ausentes o 2–4, deciduos, libres, más grandes que los sépalos; estambres ausentes o 4 u 8, libres, frecuentemente en 2 verticilos y entonces los exteriores opuestos a los pétalos, anteras basifijas, 2-loculares, con dehiscencia longitudinal; carpelos 4, unidos, lóculos 1–4, óvulos 1 por lóculo, anátropos, estigmas frecuentemente plumosos. Frutos nuececillas o drupas, anguladas, sulcadas o aladas; semilla con testa membranácea, embrión recto, cilíndrico u obcordiforme, endosperma abundante, carnoso.
Fórmula floral:
formula_1 or formula_2

Frutos nuciformes o esquizocárpicos. Unas 180 especies.

Bastante cosmopolita, en el Hemisferio Sur, y la mayoría australianas. "Haloragis" no está en Europa

La familia fue descrita por Robert Brown y publicado en "A Voyage to Terra Australis" 2: 549. 1814. El género tipo es: "Haloragis"
Nueve Gros., 145 spp.:

El taxón de la más tempranas familia Cercodiaceae y Myriophyllaceae están ahora incluidas en la familia Haloragaceae. Antes, el género "Gunnera" estaba en esta familia.




</doc>
<doc id="1383" url="https://es.wikipedia.org/wiki?curid=1383" title="Hippocastanaceae">
Hippocastanaceae

Las Hippocastanaceae es una pequeña familia de árboles y arbustos integrada por tres géneros y unas 25 especies de América del Norte, Asia y la península balcánica.

Hojas opuestas, palmadas o imparipinnadas. Flores hermafroditas o unisexuales, ligeramente zigomorfas, pentámeras y de ovario súpero, dispuestas en inflorescencias paniculiformes. Fruto en cápsula loculícida.

Los miembros de esta familia están estrechamente emparentados con la familia Sapindaceae, mayoritariamente tropical. Los sistemas de clasificación actuales incluyen a los miembros de las Hippocastanaceae junto con los de Aceraceae, entre otros, en las Sapindaceae "sensu lato".

Recientes estudios moleculareshan demostrado que mientras las Aceraceae y Hippocastanaceae son monofilético en sí mismos, su separación de las Sapindaceae "sensu lato", Juss. "nom. cons." dejaría las Sapindaceae "sensu stricto" como un grupo parafilético. Por lo tanto, es ahora considerada como un simple sinónimo de la subfamilia Hippocastanoideae, Dumortier de las Sapindaceae "sensu lato", las Sapindaceae "sensu stricto" quedándose también como mera subfamilia Sapindoideae Burnett.

Su interés económico es escaso y se reduce al cultivo de algunas especies, como ornamentales y de sombra, a su madera, que es de escasa calidad y al empleo medicinal del castaño de indias.



</doc>
<doc id="1385" url="https://es.wikipedia.org/wiki?curid=1385" title="La bestia en la cueva">
La bestia en la cueva

La bestia en la cueva (título original en inglés: "The Beast in the Cave") es uno de los primeros cuentos de H. P. Lovecraft, escrito cuando contaba tan solo quince años de edad.

Se reduce a un mero ejercicio de recreación o imitación de los cuentos de terror gótico, casi rayando el plagio. No obstante, es curioso poder constatar la tradición gótica en un temprano Lovecraft.



</doc>
<doc id="1386" url="https://es.wikipedia.org/wiki?curid=1386" title="Himno Europeo">
Himno Europeo

El himno de la Unión Europea, oficialmente Himno Europeo, es uno de los cuatro símbolos oficiales de la Unión Europea. El himno tiene su origen en la "Oda a la Alegría" ("An die Freude" en alemán), escrita por Friedrich von Schiller en 1785 y la composición realizada por Ludwig van Beethoven para su novena sinfonía. Fue adoptado oficialmente en 1985.

Este himno, según la Unión Europea, no sustituye a los himnos nacionales de los países de la UE, sino que "celebra los valores que todos ellos comparten".

En 1793, a la edad de 23 años, Ludwig van Beethoven conoció la obra del escritor alemán, y desde ese momento manifestó su inspiración y deseo de ponerle música. El 7 de mayo de 1824, diez años después de la Octava Sinfonía, Beethoven presenta en el Teatro de la Corte Imperial de Viena su Novena Sinfonía en Re menor, Op. 125 -posteriormente conocida como “Coral”- cuyo cuarto y último movimiento concibió para ser interpretado por un coro y solistas basándose en la "Oda a la Alegría"...

En 1971, la Asamblea Parlamentaria del Consejo de Europa (no confundir con el Consejo de la Unión Europea) decidió proponer la adopción de la antesala de la "Oda a la Alegría" de la Novena Sinfonía de Beethoven como himno, tomando la sugerencia hecha por el conde austriaco Richard Nikolaus Graf von Coudenhove-Kalergi en 1955. Beethoven fue visto generalmente como la mejor elección para un himno de Europa. El 19 de enero de 1972, el Consejo de Europa anunció finalmente la elección de la "Oda a la Alegría" como himno europeo. 

Herbert von Karajan, uno de los más grandes directores contemporáneos, accedió a una petición del Consejo de la Unión Europea de escribir tres arreglos instrumentales para solo de piano, viento y orquesta sinfónica, con los que se hizo oficial en 1985 como Himno de la Unión Europea tras la aprobación de los jefes de Estado y de Gobierno de la UE, siendo interpretado por primera vez de manera oficial el 29 de mayo de ese mismo año.

El Consejo de Europa es una institución diferente al Consejo de la Unión Europea y agrupa a países miembros de la Unión, pero también a países que no lo son, es por ello que el himno es el mismo para el Consejo de Europa y para la UE.

En marzo de 2004, el Consejo de Europa lanzó un CD con varias versiones del himno europeo, entre ellas la primera versión rap.

Debido al gran número de idiomas utilizados en la Unión Europea, el himno es puramente instrumental, y la letra en alemán de Friedrich Schiller no tiene carácter oficial. A pesar de esto, las letras alemanas suelen ser cantadas por los coros y la gente común cuando el himno toca en algunos actos oficiales, como ya ocurrió en la ampliación de la UE en 2004, en la frontera entre Alemania y Polonia.

A pesar de esto, se ha intentado en varias ocasiones dotarle de letra al himno. Recientemente, el latín, como antigua lengua de muchos países europeos, fue el lenguaje propuesto por el compositor austriaco Peter Roland. El compositor ofreció una copia de su versión a Romano Prodi, entonces presidente de la Comisión Europea durante una reunión en Viena en febrero de 2004.

En Francia, varias adaptaciones de la Oda eran conocidas mucho antes de la aparición de la Unión Europea. Se publicó una versión de Maurice Bouchor (1855-1929) titulada "Himno a la humanidad universal" ("Hymne à l'humanité universelle"), que añadía varios versos a otro texto anterior de Jean Ruault. Esta versión y otra por Maurice Bouchor y Julien Thiersot bajo el título "Himno de los tiempos futuros" ("Hymne des temps Futurs") que fue publicada en un libro de música está muy extendida entre las escuelas básicas, donde se suele tocar de forma no oficial durante los eventos europeos. También se conoce otra versión por el escritor católico Folliet Joseph (1903-1972).

Existe también un proyecto de la Comisión Europea (CE) para dotarlo de un texto que represente los ideales de la Unión. Peter Roland ha preparado tres estrofas en latín relacionadas con la paz y la Europa unida en la diversidad, haciendo eco al lema de la UE: "Unida en la Diversidad".

Existe también una versión de Miguel Ríos escrita en 1970.

Aún más reciente es la propuesta del partido Unión Europea de Esperanto (EEU) que ofrece un texto en esperanto, escrito por el expresidente de la EEU Umberto Broccatelli. En la página web de EEU se pueden encontrar traducciones de este texto en 37 idiomas, incluyendo los idiomas oficiales de la UE. Como parte de una iniciativa ciudadana europea, el 1 de abril de 2012 la EEU presentó como propuesta a la Comisión Europea que "la Unión Europea recomiende cantar el himno europeo en el idioma neutral esperanto, como propone Umberto Broccatelli, cuando los representantes de los Estados miembros quieran expresar conjuntamente su pertenencia a una Europa común y de iguales derechos".




</doc>
<doc id="1387" url="https://es.wikipedia.org/wiki?curid=1387" title="Hélice alfa">
Hélice alfa

Las hélices alfa son estructuras secundarias de las proteínas. Esta hélice mantiene su forma por la presencia de los puentes de hidrógeno que se forman entre los átomos de oxígeno del grupo carbonilo de un aminoácido y el átomo de hidrógeno del grupo amino de otro aminoácido situado a cuatro aminoácidos de distancia en la cadena. Los grupos R se extienden hacia afuera de la hélice. 
Es una estructura anfipática porque posee una parte hidrofílica y una parte hidrófoba, lo que produce el enrollamiento de esta estructura, de manera que la parte hidrófoba no interactúe con el agua. 

En las proteínas, la hélice α es el principal motivo de estructura secundaria. Fue postulada primero por Linus Pauling, Robert Corey, y Herman Branson en 1951 basándose en las estructuras cristalográficas entonces conocidas de aminoácidos y péptidos y en la predicción de Pauling de la forma planar de los enlaces peptídicos.

Los aminoácidos en una hélice α están dispuestos en una estructura helicoidal dextrógira, con unos 3,6 aminoácidos por vuelta. Cada aminoácido supone un giro de unos 100° en la hélice, y los Cα de dos aminoácidos contiguos están separados por 1,5Å. La hélice está estrechamente empaquetada; de forma que no hay casi espacio libre dentro de la hélice. Todas las cadenas laterales de los aminoácidos están dispuestas hacia el exterior de la hélice. 

El grupo N-H del aminoácido (n) puede establecer un enlace de hidrógeno con el grupo C=O del aminoácido (n+4). De esta forma, cada aminoácido (n) de la hélice forma dos puentes de hidrógeno con su enlace peptídico y el enlace peptídico del aminoácido en (n+4) y en (n-4). En total son 7 enlaces de hidrógeno por vuelta. Esto estabiliza enormemente la hélice. Está dentro de los niveles de organización de la proteína.

Los cuatro primeros aminoácidos de la hélice, tal conocida como alfa, y los cuatro últimos solo podrán formar un enlace de hidrógeno en vez de dos, por lo tanto la hélice α suele ser más estable en la zona central que en los extremos. Para compensar esta pérdida, los aminoácidos de los extremos suelen ser polares y forman puentes de H con sus cadenas laterales y la cadena lateral de otros aminoácidos de la hélice. Cuando dos hélices alfa se aproximan entre sí tienden a interaccionar con ángulos de -30 y 60o.

En la hélice los momentos dipolares de todos los aminoácidos están perfectamente alineados, con lo que se forma un dipolo total con una carga parcial positiva en el extremo N-terminal y una carga parcial negativa en el extremo C-terminal. 

En una hélice α, las cadenas laterales de los aminoácidos en posición (n) y en posición (n+4) quedan alineados. De forma que si en esas posiciones ponemos dos aminoácidos con carga de igual signo o muy voluminosos se desestabiliza la hélice.

Algunos aminoácidos, llamados "disruptores de hélices", pueden desestabilizar la estructura helicoidal. Uno de ellos es la prolina, que al ser un iminoácido (aunque algunos autores cuestionan que la prolina no es en rigor un iminoácido), el N de su enlace peptídico no tiene unido un H para formar un enlace de hidrógeno con el aminoácido en (n+4). Además, el metileno unido al N del enlace peptídico también provoca impedimentos estéricos que hacen que la hélice tienda a romperse en el punto donde esté la prolina, aunque no lo hará si esta es suficientemente larga y estable. La glicina al proporcionar una gran flexibilidad, puesto que su cadena lateral es solo un H, suele estar en los acodamientos al final de la hélice.

Al primer aminoácido de una hélice en el extremo N-terminal se le llama N-cap y al último aminoácido de la hélice, en el extremo C-terminal se le llama C-cap. 
En posición N-cap, suelen aparecer aminoácidos polares no cargados, como la asparagina, o cargados negativamente, como el ácido glutámico, de forma que se compense la pérdida de un enlace peptídico en los extremos de la hélice que ya hemos comentado y en el caso del glutámico, la carga negativa de su cadena lateral interacciona con la carga parcial positiva del extremo N-terminal de la hélice.

En el C-cap son frecuentes la glicina y la prolina, que como ya hemos comentado rompen la estructura de la hélice, y también aminoácidos cargados positivamente, como la lisina, cuya carga positiva interacciona con la carga parcial negativa del extremo C-terminal de la hélice.

Los polipéptidos cortos habitualmente no son capaces de adoptar la estructura de hélice alfa, ya que el coste entrópico asociado con el plegamiento de la cadena polipeptídica es demasiado alto.

Las hélices α además de ser el tipo de estructura secundaria más frecuente en las proteínas, son de gran importancia en los motivos estructurales de unión al ADN, como los motivos hélice-giro-hélice y los dedos de zinc. Esto se debe que el diámetro de 12Å de la hélice α coincide con la anchura de la hendidura mayor del ADN en forma B o B-DNA.

Existen otros tipos de estructuras helicoidales similares a la hélice α en las proteínas, pero mucho menos comunes:



Julian Voss-Andreae es un escultor alemán con grados académicos en física experimental y escultura. Desde el año 2001 Voss-Andreae crea "esculturas de proteínas" inspiradas en la estructura proteica, siendo la hélice α uno de sus objetos preferidos. Este artista ha fabricado esculturas de hélice α a partir de diversos materiales, como bambú y otros árboles. En el año 2004 realizó un monumento en memoria de Linus Pauling, descubridor de la hélice alfa, diseñado a partir de una gran viga de acero reordenada según la forma de la estructura de la hélice alfa. La escultura de color rojo brillante y 3 metros de altura se ubica frente a la casa de infancia de Pauling en Portland, Oregón.




</doc>
<doc id="1388" url="https://es.wikipedia.org/wiki?curid=1388" title="Hélice de colágeno">
Hélice de colágeno

La hélice de colágeno es un tipo de estructura secundaria de las proteínas que solamente la presenta el colágeno, que está formado por unas unidades denominadas tropocolágeno, y son estas las que presentan la hélice colágena.

Este tipo de estructura está constituida por tres cadenas polipeptídicas que se enrollan de forma levógira sobre sí mismas. Al enrollarse las tres hélices alfa para formar la triple hélice de colágeno lo hacen de forma dextrógira. Es decir, la triple hélice de colágeno es una hélice dextrógira formada por tres hélices alfa levógiras.

No están tan enrolladas como las hélices alfa. La hélice del colágeno contiene tres aminoácidos por vuelta, mientras que la hélice alfa contiene 3,6.

Una característica de estas estructuras es la composición en cuanto a aminoácidos, que sigue el mismo patrón Gly-X-Y-Gly-X-Y etc. y es para todas las cadenas. X e Y son cualquier aminoácido, aunque existen preferencias por la prolina, hidroxiprolina y en menor proporción por la lisina. La glicina es el aminoácido más pequeño y el único capaz de colocarse dentro de la hélice, los demás siempre hacia afuera. La hélice la favorecen los más pequeños.

La estabilidad se mantiene por los enlaces de hidrógeno entre el grupo amino de los enlaces peptídicos en los que participa la glicina y el carbonilo de cualquier enlace peptídico. Los enlaces se establecen tanto en cada hebra como entre hebras, por lo tanto son enlaces intermoleculares intercatenarios.

También contribuyen a la estabilidad las fuerzas de van der Waals, estas interacciones son de tipo físico (por atracción entre aminoácidos).

También se pueden formar enlaces covalentes entre restos de aminoácidos (lys). Estos suelen ser entre cadenas, se forma de manera espontánea y se puede destruir con el calor.


</doc>
<doc id="1389" url="https://es.wikipedia.org/wiki?curid=1389" title="Proteína conjugada">
Proteína conjugada

Las proteínas conjugadas o heteroproteínas son moléculas que presentan una parte proteica (apoproteína) y otra no proteica menor (grupo prostético). Esto las diferencia de las proteínas simples u holoproteínas. Todas son globulares, y se clasifican en función del grupo prostético.



</doc>
<doc id="1390" url="https://es.wikipedia.org/wiki?curid=1390" title="Holoproteína">
Holoproteína

Una holoproteína es una proteína que está conformada exclusivamente por una secuencia de aminoácidos. Es sinónimo de proteína simple. 

Las holoproteínas se clasifican en:

Estas proteínas son solubles en agua, se encuentran en todas las células del cuerpo y también en el torrente sanguíneo. Algunos ejemplos de albúminas son las lacto albúminas que se encuentran en la leche y las seroalbúminas que se encuentran en la sangre.
Estas proteínas son solubles en agua y en soluciones salinas diluidas con fuertes ácidos y sus bases. Los ejemplos de globulinas son la lactoglobulina de la leche y la ovoglobulina.

Estas proteínas son solubles en ácidos diluidos y en álcalis. La proteína de glutelina de trigo es un buen ejemplo de glutelinas. Éstas, sólo se producen en el material vegetal.

Estas proteínas son solubles en un 70 u 80% de alcohol. Entre ellas podemos destacar el fliadin de trigo y la zeína del maíz. Se encuentran únicamente en los materiales vegetales.

Los albuminoides o las selenoproteinas son insolubles en todos los disolventes neutros, en los álcalis diluidos y en los ácidos. Se encuentran en los tejidos conectivos, en el cabello y en las uñas. Algunos ejemplos son la queratina, que se encuentra en las capas queratinizadas de la piel y en la corteza o córtex del cabello y de las uñas y el colágeno que se encuentra en las fibras blancas del tejido areolar.

Éstas son proteínas solubles en agua en la que los ácidos básicos aminados son predominantes. Son ricos en arginina o en lisina. Las eucariotas del ADN de los cromosomas se asocian con las histonas en la formación de las nucleoproteínas.

Estas proteínas son solubles en agua y en polipéptidos básicos de bajo peso molecular (aproximadamente de unos 4.000 daltons). Son muy ricos en aminoácidos argininos. La cadena polipeptídica consiste en 28 residuos de aminoácidos, entre los que se incluyen 19 argininas y 8 o 9 aminoácidos no básicos. Las protaminas se encuentran unidas al ADN de los espermatozoides de algunos peces. Algunos ejemplos de protaminas son la salmina (del salmón) y la esturina (de los esturiones).


</doc>
<doc id="1392" url="https://es.wikipedia.org/wiki?curid=1392" title="Hipoglucemia">
Hipoglucemia

La hipoglucemia, también conocido como hipoglicemia (no debe confundirse con su antónimo, hiperglucemia), es un estado definido por una concentración de glucosa en la sangre anormalmente baja, inferior a 50-60 mg / 100 ml. Se suele denominar shock insulínico, por la frecuencia con que se presenta en pacientes con diabetes mellitus en tratamiento con insulina. Generalmente se asocia con alteraciones o pérdida del conocimiento.

La hipoglucemia muy a menudo es resultado del tratamiento para la diabetes mellitus. A continuación se listan otros factores que deben considerarse en cualquier paciente con hipoglucemia:

1. Fármacos: antidiabéticos orales (sobre todo clorpropamida, repaglinida, nateglinida), alcohol, dosis altas de saliciatos, sulfonamidas, pentamidina, quinina, quinolonas. 

2. Enfermedad grave: insuficiencia hepática, renal o cardiaca; septicemia, inanición prolongada.

3. Deficiencias hormonales: insuficiencia suprarrenal, hipopituitarismo.

4. Insulinoma: tumor de células B pancreáticas, hiperplasia de células B (conocida como nesidioblastosis, ya sea congénita, o posterior a cirugía gástrica o bariátrica)

5. Otras etiologías raras: tumores de células no B (tumores mesenquiomatosos grandes o epiteliales que producen factor de crecimiento similar a insulina ll, otros tumores no pancreáticos), insulina o anticuerpos contra el receptor para insulina, defectos enzimáticos hereditarios.

La hipoglucemia puede deberse a diversas causas. En personas sanas suele ser consecuencia de un ayuno muy prolongado debido a que el organismo sigue utilizando glucosa, una vez que ya no queda glucógeno en el hígado para producirla.
Un ejercicio intenso acompañado de poca ingesta previa puede provocar hipoglucemia.
En personas que padecen diabetes mellitus es muy habitual. En este caso, suele deberse a un fallo en la administración de insulina exógena o de medicamento oral antiadiabético. Si se administra cuando no se ha comido lo suficiente, los niveles de glucosa pueden bajar hasta producir una hipoglucemia severa. En este tipo de pacientes también se puede producir por un exceso de ejercicio unido a una escasa ingesta de alimentos ya que la actividad física promueve la utilización de glucosa por los tejidos.

Hay que vigilarla especialmente en niños menores de 6 años, ya que puede perjudicar al desarrollo cerebral.

También puede causar hipoglucemia el consumo de alcohol debido a los efectos inhibidores de la neo glucogénesis hepática. Para que esto ocurra el glucógeno hepático debe haberse consumido. Esto se da en el ejercicio intenso y en el ayuno prologado.

En términos generales, la hipoglucemia es el resultado de dos factores: 

Cuando el cuerpo produce glucagón y adrenalina, logra corregir cualquier exceso de insulina (que haga bajar demasiado los niveles glucémicos) y logra avisarnos de que no hay suficiente glucosa circulando para permitir la función normal del cuerpo. Pero el proceso de corrección es imperfecto o ausente en la mayoría de las personas con DM. Por este defecto, el azúcar en sangre baja a niveles hipoglucémicos cuando la insulina esté activa y presente en una cantidad excesiva para la cantidad de carbohidrato presente en la sangre. Si se administra insulina cuando los niveles de glucosa en sangre son normales, puede haber un episodio de hipoglucemia. Si la cantidad de actividad física es mayor a la prevista, la cantidad de insulina o medicamento oral presente en el cuerpo puede resultar excesiva, lo cual podría iniciar un episodio de hipoglucemia. También se puede dar un episodio de hipoglucemia si a la persona con DM1 ó DM2 se le administra insulina o el medicamento oral y luego decide no comer en las siguientes horas. La manera más confiable de saber si se tiene, o se está cerca de tener, un episodio de hipoglucemia es utilizando el medidor casero de glucosa.

Se producen sensaciones muy variadas como:
Un síntoma que identifica esta condición temporal es un dolor en el centro del pecho, lo mejor es tomar un refresco o un dulce para elevar los niveles de glucosa en la sangre.

Si no se ingieren hidratos de carbono, se puede sufrir de convulsiones, pérdida de conciencia, coma, daño cerebral y muerte.



Para evitar recaídas se recomienda que se cambien los hábitos alimenticios del paciente para que haya glucosa disponible en sangre a lo largo de todo el día. Están aconsejadas comidas reducidas y con mayor frecuencia (5 o 6 veces al día), que incluyan hidratos de carbono de digestión y absorción lenta. En lo posible habría que evitar el consumo de alcohol y los azúcares de rápida absorción.






</doc>
<doc id="1393" url="https://es.wikipedia.org/wiki?curid=1393" title="Hidrocarburo">
Hidrocarburo

Los hidrocarburos son compuestos orgánicos conformados únicamente por átomos de carbono e hidrógeno. Los hidrocarburos son ejemplos de hidruros del grupo 14. Debido a que el carbono tiene 4 electrones en su capa más externa (y debido a que cada enlace covalente requiere una donación de 1 electrón, por átomo, para la formación del enlace) por lo tanto el carbono tiene exactamente cuatro enlaces que hacer, y solo es estable si se usan los 4 de estos enlaces.
Los Hidrocarburos aromáticos (arenos), alcanos, cicloalcanos y alquilo son compuestos basados en diferentes tipos de hidrocarburos.

Las cadenas de átomos de carbono pueden ser lineales o ramificadas, y abiertas o cerradas. Los que tienen en su molécula otros elementos químicos (heteroátomos) se llaman "hidrocarburos sustituidos".

La mayoría de los hidrocarburos encontrados en la Tierra ocurren naturalmente en petróleo crudo, donde la materia orgánica descompuesta proporciona una abundancia de carbono e hidrógeno que, cuando se une, puede catenarse para formar cadenas aparentemente ilimitadas.

Los hidrocarburos se pueden clasificar en dos tipos: alifáticos y aromáticos. Los alifáticos se pueden clasificar a su vez en alcanos, alquenos y alquinos según los tipos de enlace que unen entre sí los átomos de carbono. Las fórmulas generales de los alcanos, alquenos y alquinos son CH, CH y CH, respectivamente.

Hidrocarburos saturados o alcanos: son compuestos formados por carbono e hidrógeno, presentan enlaces sencillos (SP3). Presenta una fórmula general (CnH2n+2), donde n es el número de carbonos del compuesto y el sufijo -o y su terminación en -ano.

CH4→ Metano, C2H6→Etano, C3H8→Propano, C4H10→Butano, C5H12→Pentano, C6H14→ Hexano, C7H16→Heptano
C8H18→Octano, C9H20→Nonano, C10H22→Decano.

De acuerdo al tipo de estructuras que pueden formar, los hidrocarburos se pueden clasificar en:

Los sistemas policíclicos se pueden clasificar por su complejidad en: 




Según los enlaces entre los átomos de carbono, los hidrocarburos se clasifican en:

Los hidrocarburos extraídos directamente de formaciones geológicas en estado líquido se conocen comúnmente con el nombre de petróleo, mientras que los que se encuentran en estado gaseoso se les conoce como gas natural.

La explotación comercial de los hidrocarburos constituye una actividad económica de primera importancia, pues forman parte de los principales combustibles fósiles (petróleo y gas natural), así como de todo tipo de plásticos, ceras y lubricantes.

Según los grados API, se clasifican en:

formula_1

Si es:

Debido a las diferencias en la estructura molecular, la fórmula empírica sigue siendo diferente entre los hidrocarburos; en los alcanos lineales o de "cadena recta", los alcanos y los alquenos, la cantidad de hidrógeno enlazado disminuye en los alcanos y los alquinos debido a la "autovinculación" o catenación del carbono que impide la saturación completa del hidrocarburo mediante la formación de enlaces dobles o triples.

Esta capacidad inherente de los hidrocarburos para unirse a sí mismos se conoce como catenación, y permite que los hidrocarburos formen moléculas más complejas, como el ciclohexano, y en casos más raros, arenos como el benceno. Esta capacidad proviene del hecho de que el carácter de enlace entre los átomos de carbono es enteramente no polar, en el sentido de que la distribución de electrones entre los dos elementos se debe de alguna manera a los mismos valores electronegatividad de los elementos (~0.30), y no resulta en la formación de un electrofilo.

Generalmente, con la catenación viene la pérdida de la cantidad total de hidrocarburos enlazados y un aumento en la cantidad de energía requerida para la división de la unión debido a la tensión ejercida sobre la molécula; en moléculas como el ciclohexano, esto se conoce como tensión anular, y ocurre debido a la configuración electrónica espacial "desestabilizada" del átomo.

En química simple, según la teoría del enlace de valencia, el átomo de carbono debe seguir la regla del 4-hidrógeno, que establece que el número máximo de átomos disponibles para unirse con el carbono es igual al número de electrones que son atraídos hacia la capa externa del carbono. En términos de capas, el carbono consiste en una capa externa incompleta, que comprende 4 electrones, y por lo tanto tiene 4 electrones disponibles para enlaces covalentes o enlaces dativos.

Los hidrocarburos son hidrofóbicos como los lípidos.

Algunos hidrocarburos también son abundantes en el sistema solar. Se han encontrado lagos de metano y etano líquido en la luna más grande de Saturno, Titán, confirmada por la Misión Cassini-Huygens.

Los hidrocarburos también son abundantes en las nebulosas que forman hidrocarburo aromático policíclico (PAH).

Los hidrocarburos son una fuente de energía primaria para las civilizaciones actuales. El uso predominante de los hidrocarburos es como fuente de combustible. En su forma sólida, los hidrocarburos toman la forma de asfalto (betún). 

Las mezclas de hidrocarburos volátiles se utilizan ahora con preferencia a los clorofluorocarbonos como propulsor para aerosoles, debido al impacto de los clorofluorocarbonos en la capa de ozono.

El metano (CH) y el etano (CH) son gaseosos a temperatura ambiente y no pueden ser fácilmente liquidados por presión sola. El Propano (CH) es, sin embargo, fácil de licuar, y existe en 'botellas de propano' principalmente como líquido.El etano y el propano son una materia prima prometedora para la síntesis de etileno y propileno. Estos alquenos son sustancias químicas de plataforma que permiten la síntesis de derivados (como epóxido, etanol, etilenglicoles, ácido acético, ácido acrílico, acrilnitrilo) y polímeros (polietileno, polipropileno, etc.). El butano (CH) es tan fácil de licuar que proporciona un combustible seguro y volátil para pequeñas bolsas lighters. El pentano (CH) es un líquido incoloro a temperatura ambiente, comúnmente utilizado en química e industria como un poderoso solvente casi inodoro de ceras y compuestos orgánicos de alto peso molecular, incluyendo grasas. El Hexano (CH) es también un solvente no polar y no aromático ampliamente utilizado, así como una fracción significativa de gasolina común.
Los C hasta C alcanos, los alcanos y cicloalcanos isoméricos son los componentes principales de las mezclas de gasolina, nafta, combustible para aviones y solventes industriales especializados. Con la adición progresiva de unidades de carbono, los hidrocarburos simples estructurados sin anillo tienen viscosidades más altas, índices de lubricación, puntos de ebullición, temperaturas de solidificación y un color más profundo. En el extremo opuesto del metano se encuentran los alquitranes pesados que permanecen como la "fracción más baja" en una réplica de refinación de petróleo crudo. Se recogen y se utilizan ampliamente como compuestos para techos, composición de pavimentos, conservantes de la madera (la serie creosota) y como líquidos extremadamente resistentes al cizallamiento de alta viscosidad.

El uso de hidrocarburos también es frecuente en la naturaleza. Algunos artrópodos eusociales, como la abeja brasileña sin aguijón, "Schwarziana quadripunctata", utilizan "olores" únicos de hidrocarburos para determinar el parentesco entre no parientes. La composición química de los hidrocarburos varía entre edad, sexo, ubicación del nido y posición jerárquica. 

El envenenamiento por hidrocarburos como el de benceno y el petróleo suelen producirse accidentalmente por inhalación o ingestión de estos compuestos químicos citotóxicos. Inyección intravenosa o subcutánea de compuestos de petróleo con la intención del suicidio o abuso es un evento extraordinario que puede resultar en daño local o toxicidad sistémica como necrosis tisular, formación de absceso, fallo del sistema respiratorio y daño parcial en los riñones, el cerebro y el sistema nervioso. Moaddab y Eskandarlou informan de un caso de necrosis de la pared torácica y empiema resultante de un intento de suicidio por inyección de petróleo en la cavidad pleural.

Hay tres tipos principales de reacciones de hidrocarburos:


Las reacciones de sustitución solo se producen en hidrocarburos saturados (enlaces carbono-carbono simples). En esta reacción, un alcano reacciona con una molécula de cloro. Uno de los átomos de cloro desplaza a un átomo de hidrógeno. Esto forma ácido clorhídrico así como el hidrocarburo con un átomo de cloro.
hasta CCl (tetracloruro de carbono)

hasta CCl (hexacloroetano)

Las reacciones de adición involucran a los alquenos y a los alquinos. En esta reacción una molécula halógena rompe el enlace doble o triple en el hidrocarburo y forma un enlace.

Los hidrocarburos son actualmente la principal fuente de energía eléctrica y de calor (como la calefacción de los hogares) debido a la energía que se produce cuando se quema. 

A menudo esta energía se utiliza directamente como calor, como en los calentadores domésticos, que utilizan ya sea petróleo o gas natural. El hidrocarburo se quema y el calor se utiliza para calentar el agua, que luego circula. Un principio similar se utiliza para crear energía eléctrica en centrales eléctricas.

Las propiedades comunes de los hidrocarburos son el hecho de que producen vapor, dióxido de carbono y calor durante la combustión y el oxígeno es necesario para que se produzca la combustión. El hidrocarburo más simple, metano, se quema de la siguiente manera:

En un suministro inadecuado de aire, se forman el gas monóxido de carbono y el vapor de agua:

Otro ejemplo es la combustión de propano:

Y finalmente, para cualquier alcano liner de n átomos de carbono,

La quema de hidrocarburos es un ejemplo de una reacción química exotérmica.

Los hidrocarburos también pueden ser quemados con flúor elemental, resultando en productos tetrafluoruro de carbono y fluoruro de hidrógeno.

Los hidrocarburos extraídos en forma líquida se denominan petróleo (literalmente "aceite de roca") o aceite mineral, mientras que los hidrocarburos en forma gaseosa se denominan gas natural. El petróleo y el gas natural se encuentran en el subsuelo de la Tierra con las herramientas de geología del petróleo y son una fuente importante de combustible y materias primas para la producción de productos químicos orgánicos.

La extracción de combustible líquido de hidrocarburos de cuencas sedimentarias es parte integral del desarrollo energético moderno. Los hidrocarburos son minados de arenas bituminosas y esquisto bituminoso, y potencialmente extraídos de hidrato de metano sedimentario. Estas reservas requieren destilación y mejoras para producir crudo sintético y petróleo.

Las reservas de petróleo en rocas sedimentarias] son la fuente de hidrocarburos para las industrias de energía, transporte y petroquímica.

Los hidrocarburos de importancia económica incluyen los combustibles fósiles tales como carbón, petróleo y gas natural, y sus derivados tales como plásticos,parafinas, ceras, solventes y aceites. Los hidrocarburos – junto con NO y la luz solar. – contribuye a la formación de ozono troposférico y los gases de efecto invernadero.

Las bacterias en la capa gabróica de la corteza del océano pueden degradar los hidrocarburos; pero el medio ambiente extremo dificulta la investigación Otras bacterias como "Lutibacterium anuloederans" también pueden degradar hidrocarburos.
Es posible la micorremediación o descomposición de hidrocarburos por micelio y setas.

Muchos hidrocarburos son altamente inflamables; por lo tanto, se debe tener cuidado para evitar lesiones. El benceno y muchos hidrocarburos aromáticos] son posibles carcinógenos, y se debe usar el equipo de seguridad adecuado para evitar que estos compuestos dañinos entren en el cuerpo. Si los hidrocarburos se queman en áreas estrechas, se puede formar monóxido de carbono tóxico. Los hidrocarburos deben mantenerse alejados de los compuestos flúor debido a la alta probabilidad de formación de compuestos tóxicos como el ácido fluorhídrico.

Los hidrocarburos se introducen en el medio ambiente a través de su uso extensivo como combustibles y productos químicos, así como a través de fugas o derrames accidentales durante la exploración, producción, refinación o transporte. La contaminación antropogénica del suelo por hidrocarburos es un grave problema mundial debido a la persistencia de los contaminantes y al impacto negativo en la salud humana

Los hidrocarburos sustituidos son compuestos que tienen la misma estructura que un hidrocarburo, pero que contienen átomos de otros elementos distintos al hidrógeno y el carbono en lugar de una parte del hidrocarburo. La parte de la molécula que tiene un ordenamiento específico de átomos, que es el responsable del comportamiento químico de la molécula base, recibe el nombre de grupo funcional.

Por ejemplo:

Los compuestos halogenados tienen como grupo funcional los átomos de halógenos. Tienen una alta densidad. Se utilizan en refrigerantes, disolventes, pesticidas, repelentes de polillas, en algunos plásticos y en funciones biológicas: hormonas tiroideas. Por ejemplo: cloroformo, diclorometano, tiroxina, Freón, DDT, PCBs, PVC.
La estructura de los compuestos halogenados es: "R-X", en donde X es flúor (F), cloro (Cl), bromo (Br) y yodo (I), y R es un radical de hidrocarburo.

Los microorganismos se consideran como seres capaces de adaptarse y adaptar su metabolismo en función de las condiciones ambientales en las que se desarrollen y los parámetros físico-químicos que presenten, lo que les permite también desarrollarse en lugares donde están presentes los hidrocarburos. 

Existen alrededor de 160 géneros de microorganismos que degradan los hidrocarburos, entre los principales se encuentran:



</doc>
<doc id="1394" url="https://es.wikipedia.org/wiki?curid=1394" title="Hercio">
Hercio

El hercio o hertz (símbolo Hz) es la unidad de frecuencia del Sistema Internacional de Unidades.

Nombrado en honor al físico alemán Heinrich Rudolf Hertz (1857-1894), que descubrió la propagación de las ondas electromagnéticas. El nombre fue establecido por la Comisión Electrotécnica Internacional (IEC por sus siglas en inglés) en 1930. Este fue adoptado en 1960 por la CGPM (Conférence Générale des Poids et Mesures: Conferencia General de Pesos y Medidas), reemplazando el nombre anterior de "cps" ("ciclos por segundo"), así como sus múltiplos relacionados:
El término "ciclo por segundo" fue completamente reemplazado por "hercio" en la década de 1970. Es además usado en las curvas senoides, que representan ondas sonoras.

Un hercio representa un ciclo por cada segundo, entendiendo "ciclo" como la repetición de un suceso. Por ejemplo, el hercio se aplica en física a la medición de la cantidad de veces por un segundo que se repite una onda (ya sea sonora o electromagnética) o puede aplicarse también, entre otros usos, a las olas de mar que llegan a la playa por segundo o a las vibraciones de un sólido. La magnitud que mide el hercio se denomina frecuencia y es, en este sentido, la inversa del período. Un hercio es la frecuencia de una oscilación que sufre una partícula en un período de un segundo.

La conversión entre una frecuencia formula_1 medida en hercios y una velocidad angular formula_2 medida en radianes por segundo es

A continuación una tabla de los múltiplos y submúltiplos del SI (Sistema Internacional de Unidades).



</doc>
<doc id="1395" url="https://es.wikipedia.org/wiki?curid=1395" title="Edad Antigua">
Edad Antigua

La Edad Antigua es un período tradicional, muy utilizado en la periodización de la historia humana, definido por el surgimiento y desarrollo de las primeras civilizaciones que tuvieron escritura, llamadas por ello "civilizaciones antiguas". Tradicionalmente ha sido el período inicial de la historia propiamente dicha, iniciada con la invención de la escritura, precedida de la prehistoria. Algunos esquemas periódicos consideran que existe una etapa llamada "protohistoria", entre la prehistoria y la Edad Antigua, definida por el surgimiento de las primeras civilizaciones sin escritura.
Cada etapa de la historia comienza y termina debido a un acontecimiento importante. Así, la Edad Antigua se inicia en el año 4.000 a.C., con el nacimiento de la escritura, y finaliza en el año 476 d.C., con la caída del Imperio Romano de Occidente, acontecimiento con el que arranca la Edad Media.

Durante la Edad Antigua surgieron y se desarrollaron cientos de civilizaciones de gran importancia en todos los continentes, muchas de las cuales generaron productos, instituciones, conocimientos y valores que aún se encuentran presentes en la actualidad, desde Sumeria (IV milenio a. C.) y el Antiguo Egipto, pasando por las antiguas civilizaciones védicas en la India, la China Antigua, las antiguas Grecia y Roma, el Imperio aqueménida en Persia, la Antigua Sudamérica, entre muchos otros. 

En el curso de la Edad Antigua surgieron las ciudades y el proceso de urbanización, el Estado, el derecho y la ley, así como grandes religiones como el budismo y el cristianismo.

Sea cual fuera el criterio empleado, coincidiendo en tiempo y lugar, unos y otros procesos cristalizaron en el inicio de la vida urbana (ciudades muy superiores en tamaño, y diferentes en función, a las aldeas neolíticas); en la aparición del poder político (palacios, reyes) y de las religiones organizadas (templos, sacerdotes); en una compleja estratificación social; en grandes esfuerzos colectivos que exigen la prestación de trabajo obligatorio; en el establecimiento de impuestos y el comercio de larga distancia (todo lo que se ha venido en llamar «revolución urbana»). Este nivel de desarrollo social, que por primera vez se alcanzó en la Sumeria del (espacio propicio para la constitución de las primeras ciudades-estado competitivas a partir del sustrato neolítico), llevaba ya cuatro milenios desarrollándose en el Creciente Fértil. A partir de ellas, y de sucesivos contactos (tanto pacíficos como violentos) de pueblos vecinos (culturas sedentario-agrícolas o nómada-ganaderas que se nombran tradicionalmente con términos de validez cuestionable, más propios de familias lingüísticas que de razas humanas: semitas, camitas, indoeuropeos, etc.), se fueron conformando los primeros estados de gran extensión territorial, hasta alcanzar el tamaño de imperios multinacionales.
Procesos similares tuvieron lugar en diversos momentos según el área geográfica (sucesivamente Mesopotamia, el valle del Nilo, el subcontinente indio, China, la cuenca del Mediterráneo, la América precolombina y el resto de Europa, Asia y África); en algunas zonas especialmente aisladas, algunos pueblos cazadores-recolectores actuales aun no habrían abandonado la prehistoria mientras que otros entraron violentamente en la edad moderna o la contemporánea de la mano de las colonizaciones de los siglos XVI al XIX.

Los pueblos cronológicamente contemporáneos a la Historia escrita del Mediterráneo Oriental pueden ser objeto de la protohistoria, pues las fuentes escritas por romanos, griegos, fenicios, hebreos o egipcios, además de las fuentes arqueológicas, permiten hacerlo.

La Antigüedad clásica se localiza en el momento de plenitud de la civilización grecorromana ( al ) o, en sentido amplio, en toda su duración ( al ). Se caracterizó por la definición de innovadores conceptos sociopolíticos —los de ciudadanía y de libertad personal, no para todos, sino para una minoría sostenida por el trabajo esclavo—, a diferencia de los imperios fluviales del antiguo Egipto, Babilonia, India o China, para los que se definió la imprecisa categoría de «modo de producción asiático», caracterizados por la existencia de un poder omnímodo en la cúspide del imperio y el pago de tributos por las comunidades campesinas sujetas a él, pero de condición social libre (pues aunque exista la esclavitud, no representa la fuerza de trabajo principal). 

El final de la Edad Antigua en la civilización occidental coincide con la caída del Imperio romano de Occidente, en el año 476 (el Imperio romano de Oriente sobrevivió toda la Edad Media hasta 1453 como Imperio bizantino), aunque tal discontinuidad no se observa en otras civilizaciones. Por tanto, las divisiones posteriores (Edad Media y Edad Moderna) pueden considerarse válidas solo para aquella, mientras que la mayor parte de Asia y África, y con mucha más claridad América, son objeto en su historia de una periodización propia.
Algunos autores culturalistas hacen llegar la Antigüedad tardía europea hasta los siglos VI y VII, mientras que la escuela «mutacionista» francesa la extiende hasta algún momento entre los siglos IX y XI. Distintas interpretaciones de la historia hacen hincapié en cuestiones económicas (transición del modo de producción esclavista al modo de producción feudal, desde la crisis del siglo III), políticas o ideológicas (desaparición del imperio e instalación de los reinos germánicos desde el siglo V), religiosas (sustitución del paganismo politeísta por los monoteísmos teocéntricos: el cristianismo —siglo IV— y posteriormente el islam —siglo VII—), filosóficas (filosofía antigua por la medieval) y artísticas (evolución desde el arte antiguo —clásico— hacia el arte medieval —paleocristiano y prerrománico—).

Las civilizaciones de la Antigüedad son agrupadas geográficamente por la historiografía y la arqueología en zonas en que distintos pueblos y culturas estuvieron especialmente vinculados entre sí; aunque las áreas de influencia de cada una de ellas llegaron en muchas ocasiones a interpenetrarse e ir mucho más lejos, formando imperios de dimensiones multicontinentales (el Imperio persa, el de Alejandro Magno y el Imperio romano), talasocracias («gobierno de los mares») o rutas comerciales y de intercambio de productos e ideas a larga distancia; aunque siempre limitadas por el relativo aislamiento entre ellas (obstáculos de los desiertos y océanos), que llega a ser radical en algunos casos (entre el Viejo Mundo y el Nuevo Mundo). La navegación antigua, especialmente la naturaleza y extensión de las expediciones que necesariamente tuvieron que emprender las culturas primitivas de Polinesia (al menos hasta la Isla de Pascua), es un asunto aún polémico. En algunas ocasiones se ha recurrido a la arqueología experimental para probar la posibilidad de contactos con América desde el Pacífico. Otros conceptos de aplicación discutida son la prioridad del difusionismo o del desarrollo endógeno para determinados fenómenos culturales (agricultura, metalurgia, escritura, alfabeto, moneda, etc.) y la aplicación del evolucionismo en ámbitos arqueológicos y antropológicos.

El Antiguo Oriente Próximo o Antiguo Oriente es el término utilizado para denominar las zonas de Asia occidental y noreste de África donde surgieron las civilizaciones anteriores a la civilización clásica grecorromana, y que actualmente se denomina Oriente Próximo u Oriente Medio. Para la misma región, Vere Gordon Childe acuñó la denominación Creciente Fértil, al definirla como la zona donde surgió primero la Revolución neolítica () y posteriormente la Revolución urbana (). Son los actuales países de Irak, parte de Irán, parte de Turquía, Siria, Líbano, Israel, los Territorios palestinos, Jordania, Arabia y Egipto. Cronológicamente, se entiende como un periodo que va desde el inicio de las civilizaciones históricas en torno al (en esta zona la aparición de la escritura, las ciudades y los templos es simultánea a la Edad del Bronce) hasta la expansión del Imperio aqueménida en el 

La desembocadura del Tigris y el Éufrates en la Baja Mesopotamia dio origen a la acumulación de depósitos aluviales en la zona de marismas que va ganando paulatinamente terreno al mar frente a la costa en retroceso del golfo Pérsico (actualmente a más de cien kilómetros del lugar que ocupaba en el IVmilenioa.C., y con los dos ríos confluyentes —Shatt al-Arab—). La zona fue propicia (con la condición de mantener una gran capacidad de organización social para el trabajo colectivo en la construcción de obras hidráulicas como canalizaciones, regadío y drenajes) para el desarrollo de las ciudades-estado sumerias (Ur, Uruk, Eridú, Lagash). Estas, en competencia entre sí y con los pueblos nómadas de estepas y desiertos circundantes (los del sur y oeste englobados por la historiografía en el amplio concepto étnico de semitas y los del este en la zona irania donde se fue formando la civilización elamita), así como con los núcleos que se fueron formando más al norte (Babilonia) y más al norte aún en la Alta Mesopotamia (Nínive); fueron desarrollando las características constitutivas de la civilización (sociedad compleja) y el estado (superestructura político-ideológica): templo, clase sacerdotal y religión organizada, frontera, guerra territorial, ejército, propaganda, impuestos, burocracia, monarquía, construcciones como murallas y zigurats; y el rasgo que marca el inicio de la historia: el registro de la memoria en la escritura.
La dinámica del crecimiento territorial llevó a la formación de imperios, que en su pretensión de monopolizar el poder, se describían a sí mismos como un continuo espacial «entre el mar pequeño y el mar grande» (el golfo Pérsico y el Mediterráneo), en enumeraciones más o menos fiables de pueblos anexionados, destruidos, dispersados, rechazados, sometidos, tributarios, o simplemente socios comerciales, aliados o contactos diplomáticos.

Cordilleras, mesetas, estepas y desiertos caracterizan un difícil medio físico entre el río Tigris al oeste, el golfo Pérsico al sur, el río Indo al este y los montes Elburz, el mar Caspio y el río Oxus al norte. No obstante, también son la vía terrestre que conecta el Oriente Próximo con el Asia Central y el Asia Meridional (más difícilmente, siendo más usada la conexión marítima); y a través de esas zonas, en última instancia, con el Extremo Oriente. La extensa región persa o irania cumpliría un papel clave en la teoría indoeuropea, de debatida validez, que suponía la existencia de un grupo ancestral de pueblos de las estepas portadores de rasgos comunes (lingüísticos, étnicos, culturales e incluso de estructura de pensamiento), esencialmente ganaderos (otorgaban un gran valor a vacas, caballos y perros), de estructura social patriarcal, jerarquizada y triádica (visible incluso en su panteón de dioses), que protagonizaron una gigantesca expansión que incluiría la conquista de India por los arios; la de Europa por los predecesores de griegos, latinos, celtas, germanos y eslavos; y la de Mesopotamia, Anatolia, Levante y Egipto por medos y persas.
La península de Anatolia, vía terrestre entre Asia y Europa, de la que la separa el estrecho del Bósforo y las numerosas islas del Egeo, con las que siempre mantuvo un continuo cultural (del que son muestra los aqueos y troyanos del mito homérico), estuvo en el corazón de las innovaciones de la Revolución Neolítica y la Revolución Urbana, desarrollando estados poderosos que entraron en relación y competencia con los mesopotámicos e incluso con Egipto. Hacia el norte, la costa del mar Negro (el Ponto para griegos y romanos), acogía mitos como el del vellocino de oro que se hallaba en la Cólquide. La cordillera del Cáucaso la pone en contacto con las lejanas llanuras eurasiáticas.

La zona costera más oriental del Mediterráneo, por su ubicación entre África y Asia y sus favorables condiciones físicas, actuó como un «pasillo» entre el mar y el desierto, muy compartimentado, aunque con valles fluviales de dirección norte-sur (los del Jordán y el Orontes), que posibilitó las comunicaciones terrestres entre África, Asia y Europa. Ese papel se había cumplido desde el Paleolítico y el Neolítico (Jericó), y se acentuó con las primeras civilizaciones. Los grandes imperios de Egipto, Mesopotamia y Anatolia tuvieron en esta zona su zona de contacto geoestratégico. La situación crítica de finales del permitió que se desarrollaran potentes civilizaciones locales de fuerte personalidad e influencia en el desarrollo histórico posterior (rasgos como el alfabeto o el monoteísmo), con una proyección muy superior a su extensión geográfica o población.
Entre el Tigris y la cordillera del Líbano comienza una vasta zona desértica que se extiende hacia el sur hasta la península arábiga. Supone un obstáculo insalvable para el desarrollo de la agricultura más allá de pequeñas zonas de oasis muy dispersos, excepto en la zona del Yemen (Arabia Felix —‘Arabia feliz’—). Las actividades económicas que se desarrollaron y permitieron la formación de una peculiar civilización fueron, por tanto, la ganadería nómada y las lucrativas rutas caravaneras del comercio a larga distancia que conectaban todas las partes del mundo antiguo a través de los puertos del mar Rojo, el golfo de Adén y el golfo Pérsico (abiertos al océano Índico —navegación hasta la India e Indonesia—, al este de África —donde la relación con Eritrea y Etiopía fue muy estrecha— y a la costa oriental de Egipto —Berenice—), y ciudades del interior como Alepo, Damasco, Apamea, Petra o Palmira (que conectaban con el Levante mediterráneo).
«Egipto es un don del Nilo» (Heródoto), pues pocas civilizaciones tuvieron una relación tan determinante con un río. Su crecida anual permite la fertilidad y altísima densidad de población de una estrecha franja que recorre el despoblado desierto norteafricano («desertizado» en el periodo postglacial) desde las cataratas del sur hasta el delta del norte. La dualidad entre el Alto Egipto y el Bajo Egipto forjó, sobre una sociedad campesina extraordinariamente estable y vinculada por el trabajo colectivo en las obras hidráulicas, unas instituciones y una cultura caracterizadas por la sacralización de la figura del faraón, la fortaleza de los templos, una eficaz burocracia y una compleja religión del más allá. Dentro de una gran continuidad a lo largo de milenios (que a veces se ha interpretado como homogeneidad o incluso estereotipación, con escasísimas excepciones —el periodo de Amarna—), se mantuvo una repetida dialéctica entre la unidad y la disgregación en el devenir cíclico de las fases de la historia egipcia, con periodos de esplendor y de crisis.


Hélade es el concepto geográfico y cultural que abarcaba en la Antigüedad clásica el territorio habitado por los griegos o helenos, más amplio que la actual Grecia, y que comprendería el territorio continental europeo que va desde el Peloponeso al sur hasta una difusa separación con Macedonia, Tracia y Epiro al norte; además de las islas del mar Egeo y del mar Jónico y la costa occidental de la actual Turquía (Jonia) hasta el Helesponto. También se asimilaban al concepto de Hélade las colonias griegas establecidas por todo el Mediterráneo; y también podían entenderse próximos a él los extensos territorios de las monarquías helenísticas de Egipto y el Próximo Oriente, que en mayor o menor medida habían sido helenizados.

Muchos mitos griegos se situaban en costas o islas situadas en un indefinido «extremo Occidente» (Vulcano —Hefaistos—, Trabajos de Hércules —Heracles, Columnas de Hércules, Gerión, Atlas—, Atlántida, Jardín de las Hespérides, Odisea —Cíclopes, Lestrigones, Sirenas, Escila y Caribdis, Ogigia, Lotófagos—); otros se situaban en dirección menos clara, o más bien en el Mediterráneo oriental (hacia el mar Negro —la Cólquide de los viajes de Jasón, los Argonautas y el Vellocino de Oro—, el sur del Egeo —la Creta de Minos, Dédalo, Ícaro, y el Minotauro vencido por el ateniense Teseo; o del rapto de Europa— o el Chipre del nacimiento de Afrodita).




El Imperio romano tuvo un impacto muy superior a su propia extensión espacial (casi seis millones de kilómetros cuadrados, ya de por sí una de las mayores entre los imperios de todos los tiempos) y a su duración temporal (del 27a.C. al 476d.C. en Occidente y al 1453 en Oriente); por ser la institución política y la formación económico social decisiva para la conformación de la civilización occidental, que en buena medida puede considerarse una pervivencia suya. A través de ella pervivieron sus conceptos jurídicos e institucionales (derecho romano, municipio romano, provincia romana, senado romano...), artísticos y culturales (arte y cultura clásica, urbanismo romano, vía romana, teatro romano, termas, acueductos...) y el propio idioma (el latín). La romanización fue un proceso que tuvo mucho de sincrético, puesto que incorporaba rasgos culturales de los pueblos conquistados. Muy especialmente se identificó con la civilización griega, a la que Roma reconocía como superior a la suya propia, excepto en cuestiones políticas y militares "(Ex Oriente Lux, Ex Occidente Dux)".
En su periodo final, la aportación judeocristiana fue decisiva.


Las estepas del Asia Central tuvieron históricamente una estrecha relación (dialéctica de pueblos nómadas y sedentarios) con la llanura del Indostán, y esta con la península del Decán. La conexión por tierra con el Oriente Medio a través de los desiertos de Irán fue, en cambio, más comprometida, mientras que la navegación por el mar Arábigo permitió rutas más fluidas. No obstante, todas ellas fueron experimentadas, a veces en el transcurso de la misma expedición, como fue el caso de la de Alejandro Magno (326).

El aislamiento geográfico de esta zona está marcado por las más altas cordilleras del mundo: el Himalaya, el Altái, el Hindu Kush, el Tian Shan, el Pamir y el Karakorum; y algunos de los más extensos y secos desiertos: el Taklamakán y el Gobi. Incluso las comunicaciones marítimas entre India y China son dificultosas (exposición a los monzones, prolongada navegación por la interposición de la península de Indochina y la península de Malaca que obliga a cruzar por zonas como el estrecho de la Sonda o el estrecho de Malaca). Aun así, existieron contactos, como testimonia la continuidad de rutas comerciales y la difusión de tecnologías, alfabetos y religiones (el hinduismo al Sureste asiático y el budismo a Tíbet, China y Japón). No obstante, la dificultad de ese contacto se percibía como resultado de un viaje de dimensiones míticas ("Viaje a Occidente").

El desierto del Sahara y las dificultades del curso superior del Nilo supusieron dos formidables barreras geográficas que provocaron una discontinuidad cultural muy importante entre el Norte de África y el África Subsahariana. No obstante, fueron lo suficientemente permeables como para permitir el contacto mediante rutas caravaneras con la zona del río Níger y el golfo de Guinea, y el contacto a través del mar Rojo con Eritrea y Etiopía, zonas fuertemente vinculadas a la península arábiga. El caso especial de Madagascar es consecuencia de la procedencia de la población malgache, relacionada a través del océano Índico con otras poblaciones malayo-polinesias.

En la América precolombina, surgieron dos centros civilizatorios distintos: la región andina hacia el y Mesoamérica hacia el 


En fondo blanco, los periodos considerados prehistóricos (sin presencia de escritura —la existencia de proto-escritura en algunas culturas es una cuestión polémica—), en fondo ligeramente sombreado los periodos históricos (con presencia de escritura —las primeras escrituras y alfabetos, en letras de color rosa—), en fondo de distintos colores, los distintos imperios (entidades políticas de gran extensión, que alcanza al menos una de las zonas consideradas en este esquema).

Mediterráneo Occidental (hegemonía romana tras las guerras púnicas): 

Mediterráneo Oriental:

-Grecia:

-Egipto:

-Asia menor y Mar Negro:
-Levante, Mesopotamia y Asia Central:

William Shakespeare compuso varias obras teatrales con ambientación en la Antigüedad:
"Julio César (Shakespeare), Antonio y Cleopatra, Coriolano, Tito Andrónico", etc.
Cervantes hizo lo propio en "El cerco de Numancia"; pero fue más usual en el teatro clásico francés: Pierre Corneille ("Horacio", "Cinna", etc.) y Jean Racine ("La Tebaida", "Andrómaca", "Fedra", etc.), a partir del cual —y basándose en modelos clásicos y en textos antiguos de Terencio y Plauto— se fijaron las convenciones académicas que fijaron el modelo del teatro neoclásico del siglo XVIII.

La novela histórica surgida en el romanticismo tuvo en la Edad Media su principal escenario (véase medievalismo), pero también se buscó la ambientación en distintas civilizaciones de la Edad Antigua.

Muchas de las novelas se adaptaron al cine o la televisión:

El éxito editorial de los temas históricos ha multiplicado la aparición de "best sellers" del género, sobre todo los relacionados con la historia militar de Roma.


La adaptación de mitos de la edad antigua ha dado origen a un género cinematográfico especial: "Troya", "Furia de titanes", "Jasón y los argonautas", etc., así como el cine bíblico: "Los diez mandamientos" (de Cecil B. DeMille, 1923 y 1956), "Salomón y la reina de Saba", "Sansón y Dalila", etc.

Véase .

También distintas adaptaciones de los evangelios: "La historia más grande jamás contada, La túnica sagrada, El Evangelio según San Mateo, La Pasión de Cristo", etc. Véase .

Con el nombre de "peplum" (por la vestidura denominada en castellano peplo) se designa a un subgénero cinematográfico en que la ambientación en la Antigüedad es una simple excusa para una película de aventuras de bajo presupuesto en la que los anacronismos y otras inadecuaciones a la historia son abundantes ("Hércules", de 1958, y "Hércules, Sansón, Maciste y Ursus", de 1964). Las características del género ha propiciado la realización de numerosas secuelas y parodias.
Tanto estas como las de mayor nivel popularmente recibieron el nombre de «películas de romanos» (aunque fueran ambientadas en la época griega o cualquier otra época antigua), y su visionado en los «cines de barrio» de sesión continua y doble programa, o en los cines de verano tuvo un notable papel en la educación sentimental de la juventud desde finales de los años cincuenta hasta los setenta, reflejado en obras como las de Terenci Moix (egiptómano y mitómano en concreto de Elizabeth Taylor, actriz que representó a Cleopatra). Joaquín Sabina tiene una canción titulada "Una de romanos", caracterizada por la nostalgia de la juventud pasada.







</doc>
<doc id="1398" url="https://es.wikipedia.org/wiki?curid=1398" title="Historia de México (época independiente)">
Historia de México (época independiente)

 (México)
Tras las revueltas independentistas iniciadas a principios del [[siglo XIX ] hasta culminar en el año de [[1821]], la [[Nueva España]] se separó del control de [[España]] para pasar el control administrativo y material a los "[[criollo]]s" (españoles nacidos en la Nueva España), evento que se logró a partir de la guerra independentista de [[1810]] hasta [[1821]], movimiento que fue iniciado por [[Miguel Hidalgo y Costilla]] y continuado por otros insurgentes. Durante el transcurso del [[siglo XIX]] el país fue sujeto de constantes revueltas y levantamientos destinados a obtener el control y el poder administrativo. Facciones que disputaban intereses eclesiásticos, conflictos territoriales, nuevas formas de gobierno, e invasiones de países extranjeros dejaron agotados los recursos con los que contaba el país haciendo que la nueva nación emergente tardara en perfilarse. 

Después de que se empezó a querer una independencia a principios del siglo XIX, la Nueva España se separó del dominio de España para que todas las tierras y poder económico pasara a los criollos. La Independencia empieza el 15 de septiembre en la noche (pero se celebra el 16 desde el principio de sus años independientes que durante el régimen Porfirista se consolida porque él también cumplía años ese día) de 1810 con el grito de "Dolores" por Miguel Hidalgo y Costilla. Con otros Insurgentes pelearon durante 11 años hasta ganar la guerra de independencia en 1821. Con esto se cambió el nombre a Estados Unidos Mexicanos.

La forma en que Bustamante llegó al poder y el asesinato de Guerrero motivaron un clima de descontento que alentó el regreso de personajes como [[Antonio López de Santa Anna]], a la sazón Héroe nacional, por haber derrotado a las fuerzas españolas de reconquista de [[Isidro Barradas]].

Durante estos años [[Antonio López de Santa Anna]] se transformó en la persona más importante de la nación, cambiando sus lealtades de acuerdo con que bando tenía más poder en ese momento.

El costo de esta inestabilidad fue la pérdida de la mitad del país; pérdida que favoreció a los [[Estados Unidos de América|Estados Unidos]]. [[Texas]] se declara independiente en 1836, y [[California]], [[Nevada]], [[Utah]], la región occidental de [[Colorado (estado)|Colorado]] (la oriental era del [[Luisiana (Nueva Francia)|Territorio de la Luisiana]]), [[Arizona]], [[Nuevo México]] y las pequeñas zonas fronterizas de [[Wyoming]], [[Kansas]] y [[Oklahoma]] que pertenecían a México se pierden al finalizar la guerra México-Estados Unidos(1846-1848)...

Las bases fundamentales de la invasión de Estados Unidos a México se dieron en lo que se conoce como el "[[Destino Manifiesto]]". Esta política era un recurso que elaboraban los norteamericanos para extender en la medida de lo posible a otros países su ideología, ya fuera por la dominación cultural [[Y|o]] bien con la expansión militar. El segundo recurso siempre era más utilizado.
Los pobladores de Estados Unidos querían seguir expandiéndose, decidieron invadir el territorio mexicano, el gobierno mexicano los dejó con tres condiciones; que hablaran español, que se convirtieran a la religión católica y que no tuvieran esclavos. Los estadounidenses aceptaron en principio, pero al poco tiempo dejaron de cumplir su promesa y la guerra por el territorio mexicano empezó ([[Guerra México-Estados Unidos]]). Sus ansias de expandirse hacia el sur fueron inevitables, lo que provocó una guerra a todas luces desigual.
En ese momento el presidente de la unión americana era [[James Polk Knox]], quien habría advertido al congreso de su país de sus deseos de intervención a su débil vecino del sur, y fue el mismo congreso quien lo motivó a realizar esta invasión, es decir, casi de forma unánime se pronunciaron por esta, salvo pocas voces que estaban en desacuerdo, entre ellas la de [[Abraham Lincoln]], representante de Illinois. Tiempo después, México perdió territorio

El recuerdo de la gran revolución de Ayutla, nos da ocasión para significar la limpia trayectoria de la vida de [[Juan N. Álvarez]], ciudadano ejemplar, revolucionario puro que entrega a la Patria medio siglo de su existencia, amalgamada con la causa misma de la libertad y agigantada por la fuerza política y moral y el profundo contenido social de nuestras revoluciones. 

Inicia [[Morelos]] apenas sus operaciones en el Sur, cuando el 17 de noviembre de 1810, en el pueblo de Coyuca, hoy de Benítez, se incorpora a su escolta el joven Juan N. Álvarez, quien ha de asistir al lado de Morelos, mientras este vive y después, al lado de Don Vicente Guerrero, a la mayor parte de las acciones de armas de los 11 años de la Guerra de Independencia, hasta verla coronada por el éxito en el memorable Abrazo de Acatempan, el [[Plan de Ayutla]] y la entrada a México del Ejército Trigarante. 

No disipada todavía la lucha, defiende el federalismo (Constitución del 4 de octubre de 1824), con el conocimiento pleno de que representaba la única forma de asegurar el pleno goce de las libertades, que el centralismo pretendía ahogar, continuando el sistema virreinal a base de concentrar el poder y la autoridad en unas cuantas manos. 

Esta convicción le mantuvo activo hasta 1854. En el período que va de la consumación de la Independencia Política a la Gran Revolución de Ayutla, solo mantiene en paz a su provincia, cuando surgen los gobiernos liberales que dan vigencia a la Constitución de 1824, con una sola excepción que lo honra. Siendo presidente Santa Anna y manteniéndose los sureños en rebeldía, acaece la invasión estadounidense; el sur depone su actitud y al mando de Juan N. Álvarez presta su contingente, para mantener la integridad Nacional. 

El 1º de marzo de 1854 se proclama el Plan de Ayutla y es la figura de aquel joven soldado que se unió a Morelos en 1810, que maduro en convicciones a través del penoso evolucionar de su pueblo, el que ha de prestarle eje y alma a la gran Revolución de Ayutla. 

Jesús Romero Flores, escribe “Tres etapas grandiosas ha tenido la Revolución Mexicana: La lucha por la Independencia Política, 1810; la lucha por la libertad espiritual, 1854 y la lucha por la autonomía económica 1910. Hidalgo, Álvarez y Madero, acaso sin proponérselo conscientemente, iniciaron cada una de esas etapas que fueron felizmente continuadas por otros muchos paladines“.

Pero la figura de Juan N. Álvarez se actualiza, cobra importancia, a través de la política presente, porque no solo funde su vida al calor que producen las luchas libertarias, sino que es entonces y se prolonga ahora como una eterna y hermosa lección de civismo. 

El hombre que ha dado su juventud a la Patria, viejo ya, abraza una vez más su vieja causa con estas ejemplares palabras: 

“Mi edad bastante avanzada y mis notorias enfermedades, me exigen retirarme al descanso de la vida privada; más al llamado de mis conciudadanos he alejado de mí el bienestar particular y vengo a sacrificarlo todo a la causa sagrada que desde tiempos muy atrás sirvo con lealtad, porque ella es la de mi Patria“.

Y cuando triunfante la Revolución de Ayutla estima necesario nuevamente el sacrificio nos hereda estas preciosas palabras. 

“Pobre entré a la Presidencia y pobre salgo de ella, pero con la satisfacción que no pesa sobre mí la censura pública, porque dedicado desde mi más tierna edad al trabajo personal, se manejar el arado para sostener a mi familia, sin necesidad de los puestos públicos donde otros se enriquecen con ultraje de la orfandad y la miseria“

La Guerra de Reforma duró de diciembre de 1857 a enero de 1861. Con el transcurso de los años, la guerra se hizo más sangrienta y polarizó a la gente en la nación. Muchos de los moderados se unieron a los liberales, convencidos de que era necesario disminuir y controlar el gran poder de la iglesia.

"Artículos principales: [[Segunda Intervención Francesa en México]] y [[Segundo Imperio Mexicano]]

La presidencia de Benito Juárez(1858-71) fue interrumpida por el segundo imperio de México (1864-67). Conservadores trataron de instituir una monarquía cuando ayudaron a traer a México el archiduque de la casa real de Austria, conocido como [[Maximiliano I de México|Maximiliano de Habsburgo]] (cuya esposa era la princesa belga Carlota Amalia) con la ayuda militar de [[Francia]], que estaba interesada en la explotación de las minas del noroeste del país.

Aunque el ejército francés, entonces considerado uno de los más eficientes del mundo, sufrió una derrota inicial en la [[Batalla de Puebla]] el 5 de mayo de 1862, eventualmente derrotaron a las fuerzas del gobierno mexicano dirigido por el general [[Ignacio Zaragoza]], y pusieron a Maximiliano como el emperador de México. Maximiliano de Habsburgo favorecía el establecimiento de una monarquía limitada que compartiría el poder con un congreso electo democráticamente

La República fue restaurada en 1867, cuando los franceses salieron de México. Benito Juárez se dedicó a reconstruir el país y a cumplir con los mandatos de la constitución de 1857. La sociedad se secularizó, y el gobierno intenta atraer a la inversión extranjera con proyectos que actualizaban la infraestructura de transportes.

Durante estos años, Benito Juárez consolidó su poder, y fue reelegido en dos ocasiones. [[Porfirio Díaz]], héroe de la batalla de Puebla, se levantó en armas en contra de Juárez en 1872, pero la nación responde con desdén a su llamado a las armas. Benito Juárez muere en 1872, y Sebastián Lerdo de Tejada asume la presidencia. 

En 1876, Lerdo de Tejada busca la reelección, y Díaz vuelve a levantarse en armas. En esta ocasión, Díaz es victorioso y derrota a Lerdo de Tejada, que termina huyendo del país.

Porfírio Díaz llegó a la presidencia en 1876. Durante los más de treinta años de su presidencia (1876-1911) [[gerontocracia|gerontocratica]], la infraestructura del país se fortaleció gracias a la inversión extranjera aun así el quería buscar de nuevo la reelección. Este periodo de relativa prosperidad y paz es conocido como el porfiriato. Pero la gente no estaba conforme con el gobierno durante el porfiriato. México atraía a inversionistas porque Díaz les daba muchas preferencias y la paga a los trabajadores era muy baja. El resultado fue que una minoría de inversionistas, nacionales y extranjeros, se enriquecieron, y la mayor parte de la población vivía en la miseria. La [[democracia]] fue suprimida completamente, y la disidencia era reprimida, generalmente con brutalidad.

En 1910, Díaz, ya de ochenta años, decidió convocar elecciones para reelegirse como presidente. Creyó que para entonces había eliminado toda oposición seria en México. Sin embargo, [[Francisco I. Madero]], un hombre de disposición académica proveniente de familia adinerada, decidió lanzarse como candidato en contra de Díaz, y pronto obtuvo el apoyo del pueblo.

Cuando los resultados oficiales de la elección fueron anunciados, se declaró que Díaz había ganado la reelección con el casi unánime voto de la nación; Madero recibió unos cuantos cientos de votos. El fraude fue tan obvio, que la gente se amotinó. Madero preparó un documento llamado el Plan de San Luis Potosí, en el cual llamó a los mexicanos a la armas para luchar en contra del gobierno de Porfirio Díaz el 20 de noviembre de 1910.

Este plan inició la revolución mexicana. Madero fue encarcelado en San Antonio, Texas, pero el plan continuó su curso, aun con Madero tras las rejas. El ejército federal fue derrotado por las fuerzas revolucionarias, lideradas por [[Emiliano Zapata]] en el sur, [[Pancho Villa]] y [[Pascual Orozco]] en el norte, y [[Venustiano Carranza]]. Porfirio Díaz renunció en 1911, por “el bien de la nación”, y salió a su exilio en Francia, donde murió en 1915.

Los generales revolucionarios tenían objetivos diferentes. Las figuras revolucionarias variaban de los liberales, como Madero, a los radicales como Emiliano Zapata y Pancho Villa. Como consecuencia, fue difícil llegar a un acuerdo de cómo organizar el gobierno de las fuerzas triunfantes de la revolución. El resultado fue una lucha por el control del gobierno de México que duró más de veinte años. Este periodo es considerado parte de la revolución mexicana, pero también se puede considerar como una guerra civil. Durante este tiempo muchos de los líderes más destacados de la revolución, Madero(1913), Venustiano Carranza(1920), Emiliano Zapata(1919) y Pancho Villa(1923), fueron asesinados.

Después de la renuncia de Díaz, Madero fue elegido presidente en 1911. En 1913 sufrió un golpe de estado y fue asesinado por órdenes de [[Victoriano Huerta]]. Venustiano Carranza, general revolucionario encabezó el movimiento en contra de Huerta. Carranza, uno de los muchos presidentes que México tuvo durante este periodo turbulento, también promulgó una nueva constitución el 5 de febrero de 1917, la cual todavía rige México.

En 1920, [[Álvaro Obregón Salido]] asumió la presidencia. Él le dio lugar en el nuevo gobierno a todos los elementos de la sociedad mexicana excepto por los hacendados y religiosos más reaccionarios, y catalizó con éxito el movimiento liberal, particularmente en contenimiento del rol de la iglesia católica, mejorando la educación y tomando pasos hacia la institución de derechos a la mujer.

Aunque la revolución Mexicana y la guerra civil habían terminado para 1920, los conflictos armados no cesaron hasta el final de esa década. El conflicto más grande de esta era fue entre aquellos que favorecían una sociedad secular con separación de la religión y el gobierno, y aquellos que favorecían la supremacía de la [[Iglesia católica]]. Este conflicto terminó en un alzamiento armado de parte de aquellos que apoyaban a la iglesia, y la guerra se llamó “la guerra cristera”-

Porfirio Díaz había apoyado el Plan de Ayutla bajo las órdenes de Juárez durante la guerra de la reforma y contra Maximiliano. Por diferencias con Juárez proclamó el Plan de la Noria, y tuvo que exiliarse. Más tarde, lanzó el Plan de Tuxtepec contra Lerdo de Tejada ocupó la capital y el gobierno en 1876, y gobernó hasta 1911 con pocas interrupciones ningún hombre había conservado tanto tiempo el poder después de la conquista. Manejo el país durante 30 años, directamente unas veces y otras por medio de otro presidente. El porfiriato le dio a México dos cosas que le eran muy necesarias: inversión de capitales, paz y orden interno que había vuelto a conocer desde tiempos de la colonia.
Durante el porfiriato se creó la Secretaria de Educación Pública y Bellas Artes, y en 1910 se reorganizó la universidad de acuerdo con las normas actuales de la enseñanza superior.

Hasta la instauración del régimen del General Porfirio Díaz a finales del [[siglo XIX]] y principios del [[siglo XX]] el país fue impulsado de manera importante ante la nueva [[Revolución industrial]]; las costumbres y la fisonomía de las ciudades, los transportes y la producción de bienes materiales cambiaban para dar paso a la nueva modernidad. Esto marcó grandes distancias entre las sociedades creando un ambiente de inestabilidad que desató la [[Revolución mexicana]] en el año de [[1910]], periodo caracterizado por nuevas revueltas e insurrecciones en múltiples regiones del país hasta que grupos revolucionarios obtuvieron el control y de inmediato se pasó a promulgar la nueva Constitución moderna que desplazó a las anteriores.
El expresidente [[Álvaro Obregón]] quiso retornar al poder y logró que se reformaran las leyes que prohibían la reelección. Ganó las elecciones presidenciales de 1928. Pero antes de tomar posesión, durante una comida en que se celebraba su victoria, fue asesinado.

Como consecuencia del asesinato del presidente electo, el Congreso designó como presidente provisional a [[Emilio Portes Gil]]. Para fortalecer el gobierno, Calles les propuso a los jefes políticos y militares la creación de un partido político que serviría para resolver sus diferencias y fomentar la unidad. Así nació, en 1929, el Partido Nacional revolucionario (PNR).
En las nuevas elecciones ganó el candidato del PNR, [[Pascual Ortiz Rubio]]; fue una votación muy discutida contra [[José Vasconcelos Calderón|José Vasconcelos]], que era candidato independiente. Sin embargo, el verdadero poder lo tuvo [[Plutarco Elías Calles]], llamado Jefe Máximo de la revolución.

De 1928 a 1934 hubo tres presidentes: Emilio Portes Gil, Pascual Ortiz Rubio y [[Abelardo L. Rodríguez]]. Ninguno de ellos cubrió un periodo completo. A este periodo se le conoce como el Maximato, porque durante ese tiempo el poder se concentró en el Jefe Máximo. La influencia de Calles terminó cuando el siguiente presidente de la República, el general [[Lázaro Cárdenas del Río|Lázaro Cárdenas]], lo expulsó del país, exiliándolo a Francia.

Durante el [[siglo XX]], México continuó su trayecto integrándose a los nuevos adelantos de la sociedad mundial. El [[Partido Revolucionario Institucional]] mantuvo la supremacía en la administración del país desde la época de la [[Revolución mexicana]] y con grandes altibajos fue superado por una importante oposición pacífica al ya convertido régimen a principios del [[siglo XXI]].

Al terminar el periodo presidencial de [[Lázaro Cárdenas del Río|Lázaro Cárdenas]], una parte importante de las clases medias y altas se encontraba alienada por sus medidas izquierdistas, por lo que éste, para mantener la frágil estabilidad que había alcanzado el país, decidió escoger como sucesor a [[Manuel Ávila Camacho]] de una tendencia más conservadora.

Entre las acciones que realizó [[Manuel Ávila Camacho]] se encuentran la creación del [[IMSS]]; la eliminación del sector militar del [[Partido Nacional Revolucionario|PNR]] (el cual tomó, desde ese momento, su nombre actual, [[Partido Revolucionario Institucional|PRI]]; y la sustitución del líder de la [[Confederación de Trabajadores de México|CTM]], [[Vicente Lombardo Toledano]], por [[Fidel Velázquez]], quien presidiría dicha organización hasta su muerte en 1997.
En general, el gobierno de [[Manuel Ávila Camacho]] se caracterizó por la búsqueda de lo que se llamó en ese entonces "unidad nacional", es decir, la reconciliación de las diferencias que había provocado el cardenismo, aunque en algunos casos esto significara un retroceso en las políticas sociales adoptadas por Cárdenas.

En materia de política exterior, el gobierno de Ávila Camacho tuvo que enfrentar la entrada de México a la [[Segunda Guerra Mundial]] del lado de los [[Aliados (Segunda Guerra Mundial)|aliados]], luego de que un submarino alemán hundiera el buque petrolero mexicano "[[Potrero del Llano]]" frente a las costas de [[Florida]]. Lo anterior comprometió a México en la [[México en la Guerra Mundial|Guerra]].

En el año 2000 [[Vicente Fox Quesada]] postulado por el [[Partido Acción Nacional]] ganó las elecciones presidenciales y por primera vez en 71 años el partido oficial emanado de los postulados de la revolución cesó en su predominancia.

Pero en las elecciones federales de 2003 el [[Partido Revolucionario Institucional]] mantuvo la mayoría de los curules en la cámara de senadores y ganó las elecciones en la mayoría de los estados de la república, manteniendo su liderazgo

En el año 2006, por segunda ocasión en la historia, el Partido Acción Nacional se impuso en las elecciones a la presidencia de la república con su candidato Felipe Calderón Hinojosa, en una dudosa contienda al lado de Andrés Manuel López Obrador.
Tras comenzar su gobierno el presidente Calderón le declara una guerra violenta y con pocos resultados (aparte de la inseguridad y matanzas) para el país y para colmo sobrevino una crisis económica del 2008-2009 que causó una ola de desempleo y violencia aparte de la corrupción en incremento.

Así con una economía que volvía a crecer y una fuerte inseguridad se celebraron elecciones en 2012 y resultó ganador el licenciado Enrique Peña Nieto por el PRI aunque al principio las cosas no fueron mal a mediados del 2013 la inseguridad y violencia se incrementaron y para finales del 2014 la popularidad del presidente Peña Nieto bajaba drásticamente gracias a los 43 estudiantes desaparecidos en Ayotzinapa , a comienzos del 2015 el crecimiento económico se ha hecho más lento y la popularidad presidencial en su más bajo nivel a pesar de las reformas implementadas por el presidente Peña Nieto.
[[Categoría:Historia de México| ]]

</doc>
<doc id="1401" url="https://es.wikipedia.org/wiki?curid=1401" title="Horizonte de sucesos">
Horizonte de sucesos

En relatividad general, el horizonte de sucesos —también llamado horizonte de eventos— se refiere a una hipersuperficie frontera del espacio-tiempo, tal que los eventos a un lado de ella no pueden afectar a un observador situado al otro lado. Obsérvese que esta relación no tiene por qué ser simétrica o biyectiva, es decir, si A y B son las dos regiones del espacio tiempo en que el horizonte de eventos divide el espacio, A puede no ser afectada por los eventos dentro de B, pero los eventos de B generalmente sí son afectados por los eventos en A. Por dar un ejemplo concreto, la luz emitida desde dentro del horizonte de eventos jamás podría alcanzar a un observador situado fuera, pero un observador dentro podría observar los sucesos del exterior.
Existen diversos tipos de horizontes de eventos, y estos pueden aparecer en diversas circunstancias. Una de ellas particularmente importante sucede en presencia de agujeros negros, aunque este no es el único tipo de horizonte de eventos posibles, existiendo además horizontes de Cauchy, horizontes de Killing, horizontes de partícula u horizontes cosmológicos.

El horizonte de sucesos es una superficie imaginaria de forma esférica que rodea a un agujero negro, en la cual la velocidad de escape necesaria para alejarse del mismo coincide con la velocidad de la luz. Por ello, ninguna cosa dentro de él, incluyendo los fotones, puede escapar debido a la atracción de un campo gravitatorio extremadamente intenso.

Las partículas del exterior que "caen" dentro de esta región nunca vuelven a salir, ya que para hacerlo necesitarían una velocidad de escape superior a la de la luz y, hasta el momento, la teoría indica que nada puede alcanzarla.

Por tanto, no existe modo de observar el interior del horizonte de sucesos, ni de transmitir información hacia el exterior. Esta es la razón por la cual los agujeros negros no tienen características externas visibles de ningún tipo, que permitan determinar su estructura interior o su contenido, siendo imposible establecer en qué estado se encuentra la materia desde que rebasa el horizonte de sucesos hasta que colapsa en el centro del agujero negro.

Si cayéramos en un agujero negro, en el momento de atravesar el horizonte de sucesos no notaríamos ningún cambio, ya que no se trata de una superficie material, sino de una frontera imaginaria, alejada de la zona central donde se concentra la masa. La característica peculiar de esta frontera es que representa el punto de no retorno, a partir del cual no puede existir otro suceso más que caer hacia el interior, dando así origen al nombre de esta superficie.

Al incluir efectos cuánticos en el horizonte de sucesos, se hace posible la emisión de radiación por parte del agujero negro debido a las fluctuaciones del vacío que dan origen a la llamada radiación de Hawking.

Otro tipo de horizonte diferente es el que ve un observador uniformemente acelerado. Para caracterizar este tipo de horizonte necesitamos introducir las coordenadas de Rindler para el espacio-tiempo de Minkowski. Partiendo de las coordenadas cartesianas la métrica de dicho espacio-tiempo:

Consideremos ahora la región conocida como "cuña de Rindler", dada por el conjunto de puntos que verifican:

Y definamos sobre ella un cambio de coordenadas dado por:

Cuya transformación inversa viene dada por:

Usando estas coordenadas la cuña de Rindler del espacio de Minkowski tiene una métrica expresada en las nuevas coordenadas dada por la expresión:

Esta métrica tiene una singularidad aparente en formula_1, donde el tensor expresado en las coordenas de Rindler tiene un determinante que se anula. Esto sucede porque en formula_2 la aceleración asociada al observador se hace infinita. En estas coordenadas el horizonte de Rindler es precisamente la frontera de la cuña de Rindler. Es interesante que puede demostrarse que este horizonte es análogo en muchos aspectos al horizonte de eventos de un agujero negro.

El límite del universo observable es una hipersuperficie que constituye la barrera de lo que puede ser observado en cada instante de tiempo, más allá existirían partículas cuya luz todavía no ha tenido tiempo de alcanzarnos, debido a que la edad del universo es finita (ver Big Bang). Todo suceso actual o pasado situado tras el horizonte de eventos, no forma parte del universo observable actual (aunque puede ser visible en el futuro cuando las señales luminosas procedentes de ellos alcancen nuestra posición futura).

La forma en que este horizonte del universo observable cambia según la naturaleza de la expansión del universo. Si la expansión tiene ciertas características, que no serán nunca observables, por ejemplo, sin importar cuanto tiempo transcurra (eso pasa en cierto tipo de expansión acelerada, por ejemplo). La frontera pasada de los eventos que nunca podrán ser observados es propiamente un horizonte de sucesos llamado horizonte de sucesos de partícula.

El criterio para determinar si el horizonte de sucesos del universo es diferente del vacío es el siguiente, defínase una distancia comóvil formula_3 mediante la expresión:

En esta ecuación, "a"("t") es el factor de escala, "c" es la velocidad de la luz y "t" es la edad actual del universo. Si formula_4, es decir, los puntos arbitrariamente lejanos pueden ser observados, entonces el horizonte de sucesos es vacío. Si formula_5 entonces existirá un horizonte de sucesos.

Ejemplos de modelos cosmológicos sin horizonte de sucesos son los modelos de universos dominados por materia o por radiación. Un ejemplo de modelo cosmológico con horizonte de sucesos es un universo dominado por la constante cosmológica, como por ejemplo un Universo de De Sitter.

El estudio de la causalidad en relatividad general se lleva a cabo siguiendo un enfoque topológico, así un horizonte de eventos futuro o pasado puede caracterizarse como el conjunto de puntos de la clausura topológica del dominio de dependencia de una hipersuperficie lumínica situada en el "infinito" que no pertenecen al pasado o futuro cronológico de dicho dominio. Conviene aclarar que cuando se dice que una hipersuperficie está ubicada en el "infinito" se quiere decir que está situada sobre los puntos del diagrama conforme de Penrose que representa el espacio-tiempo, en signos los horizontes de eventos pasado formula_6 y futuro formula_7 de una hipersuperficie lumínica formula_8vienen dados por:

Donde la definición de los signos que aparecen es la misma usada en .



</doc>
<doc id="1403" url="https://es.wikipedia.org/wiki?curid=1403" title="Hydrocharitaceae">
Hydrocharitaceae

Las hidrocaritáceas (nombre científico Hydrocharitaceae) son una familia de hierbas acuáticas perennes, sumergidas o flotantes, distribuidas en todo el mundo, la mayoría son de agua dulce aunque también hay géneros marinos. La familia es reconocida por sistemas de clasificación modernos como el sistema de clasificación APG III (2009) y el APWeb (2001 en adelante). Anteriormente era la única familia del orden Hydrocharitales, pero en los sistemas de clasificación mencionados está incluida en el orden Alismatales. Sus hojas son a veces pecioladas pero usualmente indiferenciadas. La inflorescencia muchas veces tiene dos brácteas fusionadas (a veces libres) en la base. El ovario es ínfero, muchas veces con placentación parietal laminar o más o menos fuertemente intrusa. Los lóbulos del estigma son bífidos. La familia es muy heterogénea morfológicamente, siendo subdividida en 4 subfamilias: Hydrocharitoideae, Stratiotoideae, Anacharidoideae e Hydrilloideae. Los mecanismos de polinización también varían mucho dentro de la familia.

Hierbas acuáticas, completamente sumergidas a emergentes en parte, y enraizadas en el sustrato o flotantes y sin fijación, en hábitats marinos o de agua dulce, muchas veces rizomatosas, tejidos más o menos aerenquimatosos.

Pelos unicelulares, de pared gruesa, con extensiones de la epidermis en estructuras puntiagudas de tipo aguja ("prickle") a lo largo de márgenes o venas.

Hojas alternas y espirales, opuestas, o verticiladas, a lo largo del tallo o en una roseta basal, simples, enteras o serradas, a veces con una lámina bien desarrollada, con venación paralela o palmada, o evidente solo en la vena media, envainadoras en la base. Sin estípulas. Pequeñas escamas presentes en el nodo dentro de la vaina de la hoja.

Inflorescencias determinadas, a veces reducidas a una flor solitaria, axilar, por debajo de ella 2 brácteas muchas veces conadas.

Flores bisexuales o unisexuales (plantas entonces monoicas o dioicas), usualmente radiales, con perianto diferenciado en cáliz y corola.

3 sépalos, separados, valvados.

3 pétalos, separados, usualmente blancos, imbricados, a veces faltantes.

Estambres 1, 2, 3 o numerosos, filamentos separados a conados. Polen usualmente sin aperturas, en "Thalassia" y "Halophila" unidos en cadenas como hilos.

Carpelos usualmente 3-6, conados, ovario ínfero, con óvulos esparcidos en la superficie de los lóculos, la placenta muchas veces más o menos profundamente intrusa, estilos muchas veces divididos, pareciendo el doble del número de carpelos, estigmas elongados y papilosos.

Óvulos numerosos (o solitarios y basales).

Néctar muchas veces secretado de estaminodios.

Fruto carnoso, puede ser una baya o una cápsula que se abre irregularmente o valvadamente. Embrión a veces curvado. Sin endosperma.

Ampliamente distribuidas, pero más comunes en regiones tropicales y subtropicales, en hábitats de agua dulce (la mayoría de los géneros) o marinos ("Enhalus, Halophila, Thalassia").

La familia posee una variedad interesante de mecanismos de polinización. Muchas especies en "Egeria, Limnobium, Stratiotes", y "Blyxa" tienen flores vistosas que están por encima de la superficie del agua y son polinizadas por variados insectos usualmente recolectores de néctar. En "Vallisneria, Enhalus" y "Lagarosiphon", las flores masculinas se desprenden y flotan en la superficie del agua, mientras que entran en contacto con las flores femeninas. En "Elodea", las anteras de las flores masculinas pueden explotar, desparramando granos de polen en la superficie del agua, las mismas flores masculinas son a veces desprendidas de la planta y flotan en la superficie del agua hasta el estigma. En "Hydrilla" el transporte del polen puede ocurrir por viento o agua. Finalmente, en "Thalassia" y "Halophila" la polinización ocurre bajo el agua.

Puede ocurrir polinización cruzada o autopolinización.

Los frutos carnosos maduran debajo del agua.

Los frutos o las semillas son dispersadas por el agua o los animales.

La reproducción vegetativa por fragmentación de los rizomas es común.

Hydrocharitacae, si bien monofilética (Dahlgren y Rasmussen 1983, Les "et al." 2006) es morfológicamente heterogénea, y ha sido dividida en 3 a 5 subfamilias (Dahlgren "et al." 1985).

"Najas" tiene flores reducidas con un óvulo basal y erecto, pero su ubicación dentro de Hydrocharitaceae está sostenida por la anatomía del tegumento de la semilla y los análisis de secuencias de ADN (Les 1993, Les y Haynes 1995, Les "et al." 2006).

"Zannichellia" (Zannichelliaceae) probablemente también pertenece aquí (Les "et al." 1997a).

La familia fue reconocida por el APG III (2009), el Linear APG III (2009) le asignó el número de familia 31. La familia ya había sido reconocida por el APG II (2003).

La familia fue descrita por Antoine-Laurent de Jussieu y publicado en "Genera Plantarum¡" 67. 1789. El género tipo es: "Hydrocharis" L.

Los géneros más representados son "Ottelia" (40 especies), "Najas" (40 especies), y "Elodea" (15 especies).

Los géneros son, según Angiosperm Phylogeny Website: (visitado en abril de 2015):

Sinónimos, según el APWeb: Enhalaceae Nakai, Halophilaceae J. Agardh, Hydrillaceae Prantl, Najadaceae Jussieu, "nom. cons.", Thalassiaceae Nakai, Vallisneriaceae Link.

Muchos géneros, como "Hydrilla, Egeria, Elodea, Vallisneria", y "Limnobium", son utilizados como plantas de acuario.

Especies de "Elodea, Hydrilla, "y" Lagarosiphon" son malezas acuáticas perniciosas.

Más descripciones


</doc>
<doc id="1404" url="https://es.wikipedia.org/wiki?curid=1404" title="Hidrógeno">
Hidrógeno

El hidrógeno (en griego, de ὕδωρ "hýdōr", genitivo ὑδρός "hydrós", y γένος "génos" «que genera o produce agua») es el elemento químico de número atómico 1, representado por el símbolo H. Con una masa atómica de 1,00797, es el más ligero de la tabla periódica de los elementos. Por lo general, se presenta en su forma molecular, formando el gas diatómico H en condiciones normales. Este gas es inflamable, incoloro, inodoro, no metálico e insoluble en agua.

Debido a sus distintas y variadas propiedades, el hidrógeno no se puede encuadrar claramente en ningún grupo de la tabla periódica, aunque muchas veces se sitúa en el grupo 1 (o familia 1A) por poseer un solo electrón en la capa de valencia o capa superior.

El hidrógeno es el elemento químico más abundante, al constituir aproximadamente el 75% de la materia visible del universo. En su secuencia principal, las estrellas están compuestas principalmente por hidrógeno en estado de plasma. El hidrógeno elemental es relativamente raro en la Tierra y es producido industrialmente a partir de hidrocarburos como, por ejemplo, el metano. La mayor parte del hidrógeno elemental se obtiene "in situ", es decir, en el lugar y en el momento en que se necesita. Los mayores mercados del mundo disfrutan de la utilización del hidrógeno para el mejoramiento de combustibles fósiles (en el proceso de hidrocraqueo) y en la producción de amoníaco (principalmente para el mercado de fertilizantes). El hidrógeno puede obtenerse a partir del agua por un proceso de electrólisis, pero resulta un método mucho más caro que la obtención a partir del gas natural.

El isótopo del hidrógeno más común es el protio, cuyo núcleo está formado por un único protón y ningún neutrón. En los compuestos iónicos, puede tener una carga positiva (convirtiéndose en un catión llamado hidrón, H, compuesto únicamente por un protón, a veces en presencia de 1 o 2 neutrones); o carga negativa (convirtiéndose en un anión conocido como hidruro, H). También se pueden formar otros isótopos, como el deuterio, con un neutrón, y el tritio, con dos neutrones. En 2001, fue creado en laboratorio el isótopo H y, a partir de 2003, se sintetizaron los isótopos H hasta H. El hidrógeno forma compuestos con la mayoría de los elementos y está presente en el agua y en la mayoría de los compuestos orgánicos. Tiene un papel particularmente importante en la química ácido-base, en la que muchas reacciones implican el intercambio de protones (iones hidrógeno, H) entre moléculas solubles. Puesto que es el único átomo neutro para el que se puede resolver analíticamente la ecuación de Schrödinger, el estudio de la energía y del enlace del átomo de hidrógeno ha sido fundamental hasta el punto de haber desempeñado un papel principal en el desarrollo de la mecánica cuántica.

Las características de este elemento y su solubilidad en diversos metales son muy importantes en la metalurgia, puesto que muchos metales pueden sufrir fragilidad en su presencia, y en el desarrollo de formas seguras de almacenarlo para su uso como combustible. Es altamente soluble en diversos compuestos que poseen tierras raras y metales de transición, y puede ser disuelto tanto en metales cristalinos como amorfos. La solubilidad del hidrógeno en los metales está influenciada por las distorsiones locales o impurezas en la estructura cristalina del metal.

El término "hidrógeno" proviene del latín "hydrogenium", y este del griego antiguo "ὕδωρ" ("hydro"): ‘agua’ y "γένος-ου"("genos"): ‘generador’; es decir, «productor de agua». Fue ese el nombre con el que lo bautizó Antoine Lavoisier. La palabra puede referirse tanto al átomo de hidrógeno, descrito en este artículo, como a la molécula diatómica (H), que se encuentra a nivel de trazas en la atmósfera terrestre. Los químicos tienden a referirse a esta molécula como dihidrógeno, molécula de hidrógeno, o hidrógeno diatómico, para distinguirla del átomo del elemento, que no existe de forma aislada en las condiciones ordinarias.

El hidrógeno diatómico gaseoso, H, fue el primero producido artificialmente y formalmente descrito por T. von Hohenheim (más conocido como Paracelso), que lo obtuvo artificialmente mezclando metales con ácidos fuertes. Paracelso no era consciente de que el gas inflamable generado en estas reacciones químicas estaba compuesto por un nuevo elemento químico. En 1671, Robert Boyle redescubrió y describió la reacción que se producía entre limaduras de hierro y ácidos diluidos, lo que resulta en la producción de gas hidrógeno. En 1766, Henry Cavendish fue el primero en reconocer el hidrógeno gaseoso como una sustancia discreta, identificando el gas producido en la reacción metal-ácido como «aire inflamable» y descubriendo más profundamente, en 1781, que el gas produce agua cuando se quema. Generalmente, se le da el crédito por su descubrimiento como un elemento químico. En 1783, Antoine Lavoisier dio al elemento el nombre de "hidrógeno" (del griego "υδρώ" (hydro), agua y "γένος-ου" (genes) generar, es decir, «productor de agua») cuando él y Laplace reprodujeron el descubrimiento de Cavendish, donde se produce agua cuando se quema hidrógeno.

Lavoisier produjo hidrógeno para sus experimentos sobre conservación de la masa haciendo reaccionar un flujo de vapor con hierro metálico a través de un tubo de hierro incandescente calentado al fuego. La oxidación anaerobia de hierro por los protones del agua a alta temperatura puede ser representada esquemáticamente por el conjunto de las siguientes reacciones:

Muchos metales, tales como circonio, se someten a una reacción similar con agua, lo que conduce a la producción de hidrógeno.

El hidrógeno fue licuado por primera vez por James Dewar en 1898 al usar refrigeración regenerativa, y su invención se aproxima mucho a lo que conocemos hoy en día como termo. Produjo hidrógeno sólido al año siguiente. El deuterio fue descubierto en diciembre de 1931 por Harold Urey, y el tritio fue preparado en 1934 por Ernest Rutherford, Marcus Oliphant, y Paul Harteck. El agua pesada, que tiene deuterio en lugar de hidrógeno regular en la molécula de agua, fue descubierta por el equipo de Urey en 1932.

François Isaac de Rivaz construyó el primer dispositivo de combustión interna propulsado por una mezcla de hidrógeno y oxígeno en 1806. Edward Daniel Clarke inventó el rebufo de gas de hidrógeno en 1819. La lámpara de Döbereiner y la Luminaria Drummond fueron inventadas en 1823.

El llenado del primer globo con gas hidrógeno fue documentado por Jacques Charles en 1783. El hidrógeno proveía el ascenso a la primera manera confiable de viajes aéreos después de la invención del primer dirigible de hidrógeno retirado en 1852 por Henri Giffard. El conde alemán Ferdinand von Zeppelin promovió la idea de utilizar el hidrógeno en dirigibles rígidos, que más tarde fueron llamados zepelines, el primero de los cuales tuvo su vuelo inaugural en 1900. Los vuelos normales comenzaron en 1910, y para el inicio de la Primera Guerra Mundial, en agosto de 1914, se había trasladado a 35 000 pasajeros sin ningún incidente grave. Los dirigibles elevados con hidrógeno se utilizan como plataformas de observación y bombarderos durante la guerra.

La primera travesía transatlántica sin escalas fue hecha por el dirigible británico "R34" en 1919. A partir de 1928, con el Graf Zeppelin LZ 127, el servicio regular de pasajeros prosiguió hasta mediados de la década de 1930 sin ningún incidente. Con el descubrimiento de las reservas de otro tipo de gas ligero en los Estados Unidos, este proyecto debió ser modificado, ya que el otro elemento prometió más seguridad, pero el Gobierno de Estados Unidos se negó a vender el gas a tal efecto. Por lo tanto, el H fue utilizado en el dirigible "Hindenburg", que resultó destruido en un incidente en vuelo sobre Nueva Jersey el 6 de mayo de 1937. El incidente fue transmitido en vivo por radio y filmado. El encendido de una fuga de hidrógeno se atribuyó como la causa del incidente, pero las investigaciones posteriores señalaron a la ignición del revestimiento de tejido aluminizado por la electricidad estática.

Gracias a su estructura atómica relativamente simple, consistente en un solo protón y un solo electrón para el isótopo más abundante (protio), el átomo de hidrógeno posee un espectro de absorción que pudo ser explicado cuantitativamente, lo que supuso el punto central del modelo atómico de Bohr, que constituyó un hito en el desarrollo la teoría de la estructura atómica. Además, la consiguiente simplicidad de la molécula de hidrógeno diatómico y el correspondiente catión dihidrógeno, H, permitió una comprensión más completa de la naturaleza del enlace químico, que continuó poco después con el tratamiento mecano-cuántico del átomo de hidrógeno, que había sido desarrollado a mediados de la década de 1920 por Erwin Schrödinger y Werner Heisenberg.

Uno de los primeros efectos cuánticos que fue explícitamente advertido (pero no entendido en ese momento) fue una observación de Maxwell en la que estaba involucrado el hidrógeno, medio siglo antes de que se estableciera completamente la teoría mecano-cuántica. Maxwell observó que el calor específico del H, inexplicablemente, se desviaba del correspondiente a un gas diatómico por debajo de la temperatura ambiente y comenzaba a parecerse cada vez más al correspondiente a un gas monoatómico a temperaturas muy bajas. De acuerdo con la teoría cuántica, este comportamiento resulta del espaciamiento de los niveles energéticos rotacionales (cuantizados), que se encuentran particularmente separados en el H debido a su pequeña masa. Estos niveles tan separados impiden el reparto equitativo de la energía calorífica para generar movimiento rotacional en el hidrógeno a bajas temperaturas. Los gases diatómicos compuestos de átomos pesados no poseen niveles energéticos rotacionales tan separados y, por tanto, no presentan el mismo efecto que el hidrógeno.

El hidrógeno es el elemento químico más abundante del universo, suponiendo más del 75% en materia normal por masa y más del 90 % en número de átomos. Este elemento se encuentra en abundancia en las estrellas y los planetas gaseosos gigantes. Las nubes moleculares de H están asociadas a la formación de las estrellas. El hidrógeno también juega un papel fundamental como combustible de las estrellas por medio de las reacciones de fusión nuclear entre núcleos de hidrógeno.

En el universo, el hidrógeno se encuentra principalmente en su forma atómica y en estado de plasma, cuyas propiedades son bastante diferentes a las del hidrógeno molecular. Como plasma, el electrón y el protón del hidrógeno no se encuentran ligados, por lo que presenta una alta conductividad eléctrica y una gran emisividad (origen de la luz emitida por el Sol y otras estrellas). Las partículas cargadas están fuertemente influenciadas por los campos eléctricos y magnéticos. Por ejemplo, en los vientos solares las partículas interaccionan con la magnetosfera terrestre generando corrientes de Birkeland y el fenómeno de las auroras.

Bajo condiciones normales de presión y temperatura, el hidrógeno existe como gas diatómico, H. Sin embargo, el hidrógeno gaseoso es extremadamente poco abundante en la atmósfera de la Tierra (1 ppm en volumen), debido a su pequeña masa que le permite escapar al influjo de la gravedad terrestre más fácilmente que otros gases más pesados. Aunque los átomos de hidrógeno y las moléculas diatómicas de hidrógeno abundan en el espacio interestelar, son difíciles de generar, concentrar y purificar en la Tierra. El hidrógeno es el decimoquinto elemento más abundante en la superficie terrestre La mayor parte del hidrógeno terrestre se encuentra formando parte de compuestos químicos tales como los hidrocarburos o el agua. El hidrógeno gaseoso es producido por algunas bacterias y algas, y es un componente natural de las flatulencias.

El gas hidrógeno (dihidrógeno) es altamente inflamable y se quema en concentraciones de 4% o más H en el aire. La entalpía de combustión de hidrógeno es −285.8 kJ/mol; se quema de acuerdo con la siguiente ecuación balanceada.
Cuando se mezcla con oxígeno en una variedad de proporciones, de hidrógeno explota por ignición. El hidrógeno se quema violentamente en el aire; se produce la ignición automáticamente a una temperatura de 560 °C. Llamas de hidrógeno-oxígeno puros se queman en la gama del color ultravioleta y son casi invisibles a simple vista, como lo demuestra la debilidad de la llama de los motores principales del transbordador espacial (a diferencia de las llamas fácilmente visibles del cohete acelerador del sólido). Así que se necesita un detector de llama para detectar si una fuga de hidrógeno está ardiendo. La explosión del dirigible Hindenburg fue un caso infame de combustión de hidrógeno. La causa fue debatida, pero los materiales combustibles en la cubierta de la aeronave fueron los responsables del color de las llamas. Otra característica de los fuegos de hidrógeno es que las llamas tienden a ascender rápidamente con el gas en el aire, como ilustraron las llamas del "Hindenburg", causando menos daño que los fuegos de hidrocarburos. Dos terceras partes de los pasajeros del "Hindenburg" sobrevivieron al incendio, y muchas de las muertes que se produjeron fueron por caída o fuego del combustible diésel.

H reacciona directamente con otros elementos oxidantes. Una reacción espontánea y violenta puede ocurrir a temperatura ambiente con cloro y flúor, formando los haluros de hidrógeno correspondientes: cloruro de hidrógeno y fluoruro de hidrógeno.

A diferencia de los hidrocarburos, la combustión del hidrógeno no genera óxidos de carbono (monóxido y dióxido) sino simplemente agua en forma de vapor, por lo que se considera un combustible amigable con el medio ambiente y ayuda a mitigar el calentamiento global.

El nivel energético del estado fundamental electrónico de un átomo de hidrógeno es –13,6 eV, que equivale a un fotón ultravioleta de, aproximadamente, 92nm de longitud de onda.

Los niveles energéticos del hidrógeno pueden calcularse con bastante precisión empleando el modelo atómico de Bohr, que considera que el electrón orbita alrededor del protón de forma análoga a la órbita terrestre alrededor del Sol. Sin embargo, la fuerza electromagnética hace que el protón y el electrón se atraigan, de igual modo que los planetas y otros cuerpos celestes se atraen por la fuerza gravitatoria. Debido al carácter discreto (cuantizado) del momento angular postulado en los inicios de la mecánica cuántica por Bohr, el electrón en el modelo de Bohr solo puede orbitar a ciertas distancias permitidas alrededor del protón y, por extensión, con ciertos valores de energía permitidos. Una descripción más precisa del átomo de hidrógeno viene dada mediante un tratamiento puramente mecano-cuántico que emplea la ecuación de onda de Schrödinger o la formulación equivalente de las integrales de camino de Feynman para calcular la densidad de probabilidad del electrón cerca del protón. El tratamiento del electrón a través de la hipótesis de De Broglie (dualidad onda--partícula) reproduce resultados químicos (tales como la configuración del átomo de hidrógeno) de manera más natural que el modelo de partículas de Bohr, aunque la energía y los resultados espectrales son los mismos. Si en la construcción del modelo se emplea la masa reducida del núcleo y del electrón (como se haría en el problema de dos cuerpos en Mecánica Clásica), se obtiene una mejor formulación para los espectros del hidrógeno, y los desplazamientos espectrales correctos para el deuterio y el tritio. Pequeños ajustes en los niveles energéticos del átomo de hidrógeno, que corresponden a efectos espectrales reales, pueden determinarse usando la teoría mecano-cuántica completa, que corrige los efectos de la relatividad especial (ver ecuación de Dirac), y computando los efectos cuánticos originados por la producción de partículas virtuales en el vacío y como resultado de los campos eléctricos (ver Electrodinámica Cuántica).

En el hidrógeno gaseoso, el nivel energético del estado electrónico fundamental está dividido a su vez en otros niveles de estructura hiperfina, originados por el efecto de las interacciones magnéticas producidas entre los espines del electrón y del protón. La energía del átomo cuando los espines del protón y del electrón están alineados es mayor que cuando los espines no lo están. La transición entre esos dos estados puede tener lugar mediante la emisión de un fotón a través de una transición de dipolo magnético. Los radiotelescopios pueden detectar la radiación producida en este proceso, lo que sirve para crear mapas de distribución del hidrógeno en la galaxia.

Existen dos tipos distintos de moléculas diatómicas de hidrógeno que difieren en la relación entre los espines de sus núcleos: En la forma de ortohidrógeno, los espines de los dos protones son paralelas y forman un estado triplete, en forma de para-hidrógeno, los spins son antiparalelas y forman un singular. En condiciones normales de presión y temperatura el hidrógeno gaseoso contiene aproximadamente un 25% de la forma "para" y un 75% de la forma "orto", también conocida como "forma normal". La relación del equilibrio entre ortohidrógeno y parahidrógeno depende de la temperatura, pero puesto que la forma orto es un estado excitado, y por tanto posee una energía superior, es inestable y no puede ser purificada. A temperaturas muy bajas, el estado de equilibrio está compuesto casi exclusivamente por la forma "para". Las propiedades físicas del para-hidrógeno puro difieren ligeramente de las de la forma normal ("orto"). La distinción entre formas "orto"/"para" también se presenta en otras moléculas o grupos funcionales que contienen hidrógeno, tales como el agua o el metileno.

La interconversión no catalizada entre el parahidrógeno y el ortohidrógeno se incrementa al aumentar la temperatura; por esta razón, el H condensado rápidamente contiene grandes cantidades de la forma "orto" que pasa a la forma "para" lentamente. La relación "orto"/"para" en el H condensado es algo importante a tener en cuenta para la preparación y el almacenamiento del hidrógeno líquido: la conversión de la forma "orto" a la forma "para" es exotérmica y produce el calor suficiente para evaporar el hidrógeno líquido, provocando la pérdida del material licuado. Catalizadores para la interconversión "orto"/"para", tales como compuestos de hierro, son usados en procesos de refrigeración con hidrógeno.

Una forma molecular llamada hidrógeno molecular protonado, H, se encuentra en el medio interestelar, donde se genera por la ionización del hidrógeno molecular provocada por los rayos cósmicos. También se ha observado en las capas superiores de la atmósfera de Júpiter. Esta molécula es relativamente estable en el medio del espacio exterior debido a las bajas temperaturas y a la bajísima densidad. El H es uno de los iones más abundantes del universo, y juega un papel notable en la química del medio interestelar.

Si bien se suele catalogar al hidrógeno como no metal, a altas temperaturas y presiones puede comportarse como metal. En marzo de 1996, un grupo de científicos del Laboratorio Nacional Lawrence Livermore informó de que habían producido casualmente, durante un microsegundo y a temperaturas de miles de kelvins y presiones de más de un millón de atmósferas (> 100 GPa), el primer hidrógeno metálico identificable.

A pesar de que el H no es muy reactivo en condiciones normales, forma multitud de compuestos con la mayoría de los elementos químicos. Se conocen millones de hidrocarburos, pero no se generan por la reacción directa del hidrógeno elemental con el carbono (aunque la producción del gas de síntesis seguida del proceso Fischer-Tropsch para sintetizar hidrocarburos parece ser una excepción pues comienza con carbón e hidrógeno elemental generado in situ). El hidrógeno puede formar compuestos con elementos más electronegativos, tales como los halógenos (flúor, cloro, bromo, yodo) o los calcógenos (oxígeno, azufre, selenio); en estos compuestos, el hidrógeno adquiere carga parcial positiva debido a la polaridad del enlace covalente. Cuando se encuentra unido al flúor, al oxígeno o al nitrógeno, el hidrógeno puede participar en una modalidad de enlace no covalente llamado "enlace de hidrógeno" o "puente de hidrógeno", que es fundamental para la estabilidad de muchas moléculas biológicas. El hidrógeno puede también formar compuestos con elementos menos electronegativos, tales como metales o semimetales, en los cuales adquiere carga parcial negativa. Estos compuestos se conocen como hidruros.

El hidrógeno forma una enorme variedad de compuestos con el carbono. Debido a su presencia en los seres vivos, estos compuestos se denominan compuestos orgánicos; el estudio de sus propiedades es la finalidad de la Química Orgánica, y el estudio en el contexto de los organismos vivos se conoce como Bioquímica. Atendiendo a algunas definiciones, los compuestos "orgánicos" requieren la presencia de carbono para ser denominados así (ahí tenemos el clásico ejemplo de la urea) pero no todos los compuestos de carbono se consideran orgánicos (es el caso del monóxido de carbono, o los carbonatos metálicos. La mayoría de los compuestos orgánicos también contienen hidrógeno y, puesto que es el enlace carbono-hidrógeno el que proporciona a estos compuestos muchas de sus principales características, se hace necesario mencionar el enlace carbono-hidrógeno en algunas definiciones de la palabra "orgánica" en Química. (Estas recientes definiciones no son perfectas, sin embargo, ya que un compuesto indudablemente orgánico como la urea no podría ser catalogado como tal atendiendo a ellas).

En la Química Inorgánica, los hidruros pueden servir también como ligandos puente que unen dos centros metálicos en un complejo de coordinación. Esta función es particularmente común en los elementos del grupo 13, especialmente en los boranos (hidruros de boro) y en los complejos de aluminio, así como en los clústers de carborano.

Algunos ejemplos de compuestos covalentes importantes que contienen hidrógeno son: amoniaco (NH), hidracina (NH), agua (HO), peróxido de hidrógeno (HO), sulfuro de hidrógeno (HS), etc.

A menudo los compuestos del hidrógeno se denominan hidruros, un término usado con bastante inexactitud. Para los químicos, el término "hidruro" generalmente implica que el átomo de hidrógeno ha adquirido carga parcial negativa o carácter aniónico (denotado como H). La existencia del anión hidruro, propuesta por G. N. Lewis en 1916 para los hidruros iónicos del grupo 1 (I) y 2 (II), fue demostrada por Moers en 1920 con la electrolisis del hidruro de litio (LiH) fundido, que producía una cantidad estequiométrica de hidrógeno en el ánodo. Para los hidruros de metales de otros grupos, el término es bastante erróneo, considerando la baja electronegatividad del hidrógeno. Una excepción en los hidruros del grupo II es el BeH, que es polimérico. En el tetrahidruroaluminato (III) de litio, el anión AlH posee sus centros hidrúricos firmemente unidos al aluminio (III).

Aunque los hidruros pueden formarse con casi todos los elementos del grupo principal, el número y combinación de posibles compuestos varía mucho; por ejemplo, existen más de 100 hidruros binarios de boro conocidos, pero solamente uno de aluminio. El hidruro binario de indio no ha sido identificado aún, aunque existen complejos mayores.

La oxidación del H formalmente origina el protón, H. Esta especie es fundamental para explicar las propiedades de los ácidos, aunque el término «protón» se usa imprecisamente para referirse al hidrógeno catiónico o ion hidrógeno, denotado H. Un protón aislado H no puede existir en disolución debido a su fuerte tendencia a unirse a átomos o moléculas con electrones mediante un enlace coordinado o enlace dativo. Para evitar la cómoda, aunque incierta, idea del protón aislado solvatado en disolución, en las disoluciones ácidas acuosas se considera la presencia del ion hidronio (HO) organizado en clústers para formar la especie HO. Otros iones oxonio están presentes cuando el agua forma disoluciones con otros disolventes.

Aunque exótico en la Tierra, uno de los iones más comunes en el universo es el H, conocido como hidrógeno molecular protonado o catión hidrógeno triatómico.

El isótopo más común de hidrógeno no posee neutrones, existiendo otros dos, el deuterio (D) con uno y el tritio (T), radiactivo con dos. El deuterio tiene una abundancia natural comprendida entre 0,0184 y 0,0082% (IUPAC). El hidrógeno es el único elemento químico que tiene nombres y símbolos químicos distintos para sus diferentes isótopos.

El hidrógeno también posee otros isótopos altamente inestables (del H al H), que fueron sintetizados en el laboratorio, pero nunca observados en la naturaleza.

El hidrógeno es el único elemento que posee diferentes nombres comunes para cada uno de sus isótopos (naturales). Durante los inicios de los estudios sobre la radiactividad, a algunos isótopos radiactivos pesados les fueron asignados nombres, pero ninguno de ellos se sigue usando. Los símbolos D y T (en lugar de ²H y ³H) se usan a veces para referirse al deuterio y al tritio, pero el símbolo P corresponde al fósforo y, por tanto, no puede usarse para representar al protio. La IUPAC declara que aunque el uso de estos símbolos sea común, no es lo aconsejado.

H es un producto de algunos tipos de metabolismo anaeróbico y es producido por diversos microorganismos, por lo general a través de reacciones catalizadas por enzimas que contienen hierro o níquel llamadas hidrogenasas. Estas enzimas catalizan la reacción redox reversible entre H y sus componentes, dos protones y dos electrones. La creación de gas de hidrógeno ocurre en la transferencia de reducir equivalentes producidos durante la fermentación del piruvato al agua.

La separación del agua, en la que el agua se descompone en sus componentes, protones, electrones y oxígeno ocurre durante la fase clara en todos los organismos fotosintéticos. Algunos organismos —incluyendo el alga "Chlamydomonas reinhardtii" y cianobacteria— evolucionaron un paso más en la fase oscura en el que los protones y los electrones se reducen para formar gas de H por hidrogenasas especializadas en el cloroplasto. Se realizaron esfuerzos para modificar genéticamente las hidrogenasas de cianobacterias para sintetizar de manera eficiente el gas H incluso en la presencia de oxígeno. También se realizaron esfuerzos con algas modificadas genéticamente en un biorreactor.

El gas H es producido en los laboratorios de química y biología, muchas veces como un subproducto de la deshidrogenación de sustratos insaturados; y en la naturaleza como medio de expulsar equivalentes reductores en reacciones bioquímicas.

En el laboratorio, el gas H es normalmente preparado por la reacción de ácidos con metales tales como el zinc, por medio del aparato de Kipp.

Zn + 2 H → Zn + H

El aluminio también puede producir H después del tratamiento con bases:

2 Al + 6 HO + 2 OH → 2 Al(OH) + 3 H

La electrólisis del agua es un método simple de producir hidrógeno. Una corriente eléctrica de bajo voltaje fluye a través del agua, y el oxígeno gaseoso se forma en el ánodo, mientras que el gas hidrógeno se forma en el cátodo. Típicamente, el cátodo está hecho de platino u otro metal inerte (generalmente platino o grafito), cuando se produce hidrógeno para el almacenamiento. Si, sin embargo, el gas se destinara a ser quemado en el lugar, es deseable que haya oxígeno para asistir a la combustión, y entonces, ambos electrodos pueden estar hechos de metales inertes (se deben evitar los electrodos de hierro, ya que consumen oxígeno al sufrir oxidación). La eficiencia máxima teórica (electricidad utilizada "vs" valor energético de hidrógeno producido) es entre 80 y 94%.

2HO → 2H(g) + O

En 2007, se descubrió que una aleación de aluminio y galio en forma de gránulos añadida al agua podía utilizarse para generar hidrógeno. El proceso también produce alúmina, pero se puede reutilizar el galio, que previene la formación de una película de óxido en los gránulos. Esto tiene importantes implicaciones para la potenciales economía basada en el hidrógeno, ya que se puede producir en el lugar y no tiene que ser transportado.

El hidrógeno puede ser preparado por medio de varios procesos pero hoy día el más importante consiste en la extracción de hidrógeno a partir de hidrocarburos. La mayor parte del hidrógeno comercial se produce mediante el reformado catalítico de gas natural o de hidrocarburos líquidos. A altas temperaturas (700-1100 °C), se hace reaccionar vapor de agua con metano para producir monóxido de carbono y H:

Esta reacción es favorecida termodinámicamente por un exceso de vapor y por bajas presiones pero normalmente se practica a altas presiones (20 atm) por motivos económicos. La mezcla producida se conoce como "gas de síntesis", ya que muchas veces se utiliza directamente para la síntesis de metanol y otras sustancias químicas. Se pueden usar otros hidrocarburos, además de metano, para producir gas de síntesis con proporciones variables de los productos. 

Si el producto que se desea es solo hidrógeno, se hace reaccionar el monóxido de carbono a través de la reacción de desplazamiento del vapor de agua, por ejemplo con un catalizador de óxido de hierro. Esta reacción es también una fuente industrial común de dióxido de carbono:

Otras opciones para producir hidrógeno a partir de metano son la pirólisis, que resulta en la formación de carbono sólido:

O la oxidación parcial, la cual se aplica también a combustibles como el carbón:

Otro proceso que produce hidrógeno como producto secundario es la electrólisis de salmuera para producir cloro.

Existen más de 200 ciclos termoquímicos que pueden ser utilizados para la separación del agua, alrededor de una docena de estos ciclos, tales como el ciclo de óxido de hierro, ciclo del óxido cerio (III)-óxido cerio(IV), ciclo de óxido zinc-zinc, ciclo del azufre-yodo, ciclo del cobre-cloro, ciclo híbrido del azufre están bajo investigación y en fase de prueba para producir hidrógeno y oxígeno a partir de agua y calor sin utilizar electricidad. Un número de laboratorios (incluyendo Francia, Alemania, Grecia, Japón y los Estados Unidos) están desarrollando métodos termoquímicos para producir hidrógeno a partir de energía solar y agua.

En condiciones anaeróbicas, las aleaciones de hierro y acero se oxidan lentamente por los protones de agua concomitante reducidos en hidrógeno molecular (H). La corrosión anaeróbica de hierro conduce primero a la formación de hidróxido ferroso (óxido verde) y se puede describir mediante la siguiente reacción:

A su vez, bajo condiciones anaeróbicas, el hidróxido ferroso (Fe(OH) ) puede ser oxidado por los protones de agua para formar magnetita e hidrógeno molecular. Este proceso se describe por la reacción de Schikorr:

La magnetita así cristalizada (FeO) es termodinámicamente más estable que el hidróxido ferroso (Fe(OH) ).

Este proceso ocurre durante la corrosión anaeróbica de hierro y acero en aguas subterráneas sin oxígeno y en suelos reducidos por debajo del nivel freático.

En ausencia de oxígeno atmosférico (O), en condiciones geológicas profundas que prevalezcan lejos de atmósfera de la Tierra, el hidrógeno (H) se produce durante el proceso del serpentinización por la oxidación anaeróbica de protones del agua (H) del silicato ferroso (Fe) presente en la red cristalina de la fayalita (FeSiO, el hierro olivino). La reacción correspondiente que conduce a la formación de magnetita (FeO), cuarzo SiO) e hidrógeno (H) es la siguiente:

Esta reacción se parece mucho a la reacción de Schikorr observada en la oxidación anaeróbica del hidróxido ferroso en contacto con el agua.

De todos los gases de fallo formados en transformadores eléctricos, el hidrógeno es el más común y se genera bajo la mayoría de condiciones de fallo, por lo que, la formación de hidrógeno es un primer indicio de problemas graves en el ciclo de vida del transformador.

Se necesitan grandes cantidades de H en las industrias del petróleo y química. Una aplicación adicional de H es de tratamiento ("mejoramiento") de combustibles fósiles, y en la producción de amoníaco. Los principales consumidores de H en una planta petroquímica incluyen hidrodesalquilación, hidrodesulfuración, y de hidrocraqueo. El H se utiliza como un agente hidrogenizante, particularmente en el aumento del nivel de saturación de las grasas y aceites insaturados (que se encuentran en artículos como la margarina) y en la producción de metanol. Del mismo modo es la fuente de hidrógeno en la fabricación de ácido clorhídrico. El H también se utiliza como agente reductor de minerales metálicos.

Además de su uso como un reactivo, H tiene amplias aplicaciones en la física y la ingeniería. Se utiliza como gas de protección en los métodos de soldadura tales como la soldadura de hidrógeno atómico. H se utiliza como un enfriador de generadores en centrales eléctricas, porque tiene la mayor conductividad térmica de todos los gases. H líquido se utiliza en la investigaciones criogénicas, incluyendo estudios de superconductividad. Dado que el H es más ligero que el aire, teniendo un poco más de 1/15 de la densidad del aire, fue ampliamente utilizado en el pasado como gas de elevación en globos aerostáticos y dirigibles.

En aplicaciones más recientes, se utiliza hidrógeno puro o mezclado con nitrógeno (a veces llamado "forming gas") como gas indicador para detectar fugas. Las aplicaciones pueden ser encontradas en las industrias automotriz, química, de generación de energía, aeroespacial y de telecomunicaciones. El hidrógeno es un aditivo alimentario autorizado (E 949) que permite la prueba de fugas de paquetes, entre otras propiedades antioxidantes.

Los isótopos más raros de hidrógeno también poseen aplicaciones específicas para cada uno. El deuterio (hidrógeno-2) se utiliza en aplicaciones de la fisión nuclear como un moderador para neutrones lentos, y en las reacciones de fusión nuclear. Los compuestos de deuterio tienen aplicaciones en la química y biología en los estudios de los efectos isotópicos. El tritio (hidrógeno-3), producido en los reactores nucleares, se utiliza en la producción de bombas de hidrógeno, como un marcador isotópico en las ciencias biológicas, como una fuente de radiación en pinturas luminosas.

La temperatura de equilibrio del punto triple de hidrógeno es un punto fijo definido en la escala de temperatura ITS-90 a 13,8033 Kelvin.

El hidrógeno no es una fuente de energía, excepto en el contexto hipotético de las centrales nucleares de fusión comerciales que utilizan deuterio o tritio, una tecnología actualmente lejos de desarrollo. La energía del sol proviene de la fusión nuclear del hidrógeno, pero este proceso es difícil de lograr de forma controlable en la Tierra. El hidrógeno elemental de fuentes solares, biológicas, o eléctricas requieren más energía para crear lo que es obtenido al quemarlo, por lo que, en estos casos, sirve el hidrógeno como portador de energía, como una batería. Se puede obtener a partir de fuentes fósiles (tales como metano), pero estas fuentes son insustentables.

La densidad de energía por unidad de volumen tanto del hidrógeno líquido como del gas de hidrógeno comprimido en cualquier presión posible es significativamente menor que aquella de fuentes de combustible tradicionales, aunque la densidad de energía por unidad de "masa" de combustible sea más alta. Sin embargo, el hidrógeno elemental ha sido ampliamente discutido en el contexto de la energía, como un posible "portador" de energía futura a gran escala de la economía. Por ejemplo, el secuestro de CO seguido de captura y almacenamiento de carbono podría realizarse al punto de producción de H a partir de combustibles fósiles. El hidrógeno utilizado en el transporte se quemaría relativamente limpio, con algunas emisiones de NOx, pero sin emisiones de carbono. Sin embargo, los costos de infraestructura asociados con la conversión total a una economía del hidrógeno podría ser sustancial.

El hidrógeno es empleado para saturar enlaces rotos de silicio amorfo y carbono amorfo que ayuda a la estabilización de las propiedades del material. Es también un potencial donante de electrones en diferentes materiales óxidos, incluyendo ZnO, SnO, CdO, MgO, ZrO, HfO, LaO, YO, TiO, SrTiO, LaAlO, SiO, AlO, ZrSiO, HfSiO, y SrZrO.

El hidrógeno genera diversos riesgos para la seguridad humana, de potenciales detonaciones e incendios cuando se mezcla con el aire al ser un asfixiante en su forma pura, libre de oxígeno. Además, el hidrógeno líquido es un criogénico y presenta peligros (tales como congelación) asociados con líquidos muy fríos. El elemento se disuelve en algunos metales y, además de fuga, pueden tener efectos adversos sobre ellos, tales como fragilización por hidrógeno. La fuga de gas de hidrógeno en el aire externo puede inflamarse espontáneamente. Por otra parte, el fuego de hidrógeno, siendo extremadamente caliente, es casi invisible, y por lo tanto puede dar lugar a quemaduras accidentales.

Aunque incluso interpretar los datos de hidrógeno (incluyendo los datos para la seguridad) es confundido por diversos fenómenos. Muchas de las propiedades físicas y químicas del hidrógeno dependen de la tasa de parahidrógeno/ortohidrógeno (por lo general llevar a días o semanas a una temperatura determinada para llegar a la tasa de equilibrio por el cual los resultados suelen aparecer los parámetros de detonación de hidrógeno, como la presión y temperatura crítica de fundición, dependen en gran medida de la geometría del recipiente.




</doc>
<doc id="1412" url="https://es.wikipedia.org/wiki?curid=1412" title="Herpetología">
Herpetología

La herpetología (del griego «ἑρπετόν», "herpeton" "animal reptante, que se arrastra", y «-λογία» "-logía", tratado, estudio, ciencia) es la rama de la zoología que estudia a los reptiles y anfibios. La herpetología comprende la biología, ecología, etología, taxonomía, genética y manejo de estos organismos. 

Los anfibios y reptiles viven en ambientes acuáticos y terrestres, por lo que están expuestos a la contaminación y destrucción del hábitat a causa de las actividades humanas. El estudio de los anfibios y reptiles es importante porque su biodiversidad indica el estado de conservación de los ecosistemas. Algunos venenos y toxinas producidas por los reptiles y los anfibios son útiles en la medicina humana, por ejemplo, el estudio de los venenos de ciertas serpientes se investiga en busca de fármacos anticoagulantes.

Para ser herpetólogo regularmente se requiere un título universitario en biología, ecología o zoología y posteriormente se especializa en el estudio de los anfibios y reptiles a partir de cursos, talleres o el desarrollo de una tesis. Sin embargo, existen personas que han estudiado otras carreras y se han vuelto herpetólogos de forma autodidacta, leyendo, reuniéndose con otras personas interesadas en la herpetología (como los miembros una sociedad herpetológica) y adquiriendo experiencias con anfibios y reptiles como mascotas o en el campo. Existen tres áreas principales de empleo para los herpetólogos: 1) Posicionarse en una universidad como profesor e investigador, para esto se requiere generalmente un doctorado, 2) Posicionarse en una agencia gubernamental de vida silvestre y 3) Posicionarse en un museo de historia natural o colección herpetológica como curador o personal, esto a menudo implica la misma capacitación académica que se exige para un puesto universitario. Los herpetólogos pueden aumentar sus ingresos cobrando una tarifa por servicios o productos a partir de fotografías, conferencias, libros, artículos o realizando excursiones de vida silvestre.


</doc>
<doc id="1414" url="https://es.wikipedia.org/wiki?curid=1414" title="Helictotrichon">
Helictotrichon

Helictotrichon, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario Europa, África, Sudeste Asiático, Norte y Sur de América.
Son plantas perennes, cespitosas o cortamente estoloníferas, con innovaciones intra y extravaginales. Hojas con vaina de márgenes ligeramente soldados en la base; lígula corta, truncada, ciliada, membranosa; limbo rígido, con haz surcado y envés liso. Inflorescencia en panícula laxa y ramificada con ramas escábridas. Espiguillas comprimidas lateralmente, con 2-4 flores hermafroditas y articuladas con la raquilla. Glumas 2, desiguales; la inferior con 1-3 nervios, la superior con 3-5 nervios. Lema con dorso redondeado y con 5-7 nervios y ápice bidentado; arista inserta hacia la parte media dorsal de la lema, geniculada, con columna retorcida en hélice y de sección redondeada. Pálea con 2 quillas ciliadas. Lodículas enteras. Ovario con ápice hirsuto. Cariopsis oblongo-elíptica, surcada ventralmente, con ápice peloso. Hilo linear.
Es importante la especie forrajera nativas "H. milanjianum" en Kenia.
El género fue descrito por Besser ex Roem. & Schult. y publicado en "Mantissa" 3: 526, in obs. 1827. La especie tipo es: "Helictotrichon sempervirens" (Vill.) Pilg.
El nombre del género deriva de las palabras griegas "helictos" (espiral) y "trichon", probablemente refiriéndose a la arista. 

El número cromosómico básico del género es x = 7, con números cromosómicos somáticos de 2n = 14, 28, 42, 70, 81, 98, 112, 126, 133 y 147, ya que hay especies diploides y una serie poliploide. Cromosomas relativamente «grandes».




</doc>
<doc id="1415" url="https://es.wikipedia.org/wiki?curid=1415" title="Hemarthria">
Hemarthria

Hemarthria es un género de plantas herbáceas de la familia de las poáceas. Es originario África tropical, Madagascar, Asia Oriental, región Indomalaya y Australia.

Son plantas perennes. Tallo generalmente ramificado. Hojas con lígula representadas por una fila de pelos; las más superiores espatiformes. Inflorescencias axilares o terminales, espiciformes, con raquis marcadamente excavado, con 2 espiguillas por nudo, una sentada (inferior) y alojada en la excavación del raquis, la otra pedunculada (superior) con pedúnculo soldado con la parte externa de uno de los márgenes de la concavidad. Espiguillas no articuladas, comprimidas dorsiventralmente, con 2 flores, la inferior reducida a una lema membranosa, la superior hermafrodita. Glumas 2, la superior de la espiguilla inferior de cada nudo, semimembranosa, soldada parcialmente con la concavidad del raquis, la inferior de la espiguilla inferior y las 2 de la espiguilla superior de cada nudo, coriáceas y con numerosos nervios. Lemas y páleas membranosas, hialinas. Lodículas glabras. Androceo con 3 estambres. Cariopsis con embrión de más de 1/2 de su longitud.
El género fue descrito por Robert Brown y publicado en "Prodromus Florae Novae Hollandiae" 207. 1810. La especie tipo es: "Hemarthria compressa" R.Br. 
El nombre del género deriva de las palabras griegas "hemi" (la mitad) y "arthron" (conjunta), refiriéndose a las articulaciones de la inflorescencia (entrenudos), que son ahuecados. 
Número de la base del cromosoma,x = 9, o 10. 2n = 18 ó 20 (18 +2 B), o 36, o 54. 2, 4, y 6, ploid (y aneuploides). Cromosomas "pequeños". 



</doc>
<doc id="1416" url="https://es.wikipedia.org/wiki?curid=1416" title="Heteropogon">
Heteropogon

Heteropogon es un género de plantas herbáceas perteneciente a la familia de las poáceas. Tiene una distribución cosmopolita en las regiones tropicales.

El término "heteropogon" deriva de las voces griegas "ἕτερος" [jéteros] ('diferente, otro') y "πώγων" [pógon] ('barba'), y se refiere a las espiguillas fértiles, con barbas las femeninas y sin barbas las masculinas.

Son matas erectas de gramíneas que se encuentran en las regiones tropicales de todo el mundo, y algunas especies que crecen en zonas templadas y cálidas. Las inflorescencias aparecerán en forma de espiguillas. 
Número de la base del cromosoma, x = 10 y 11. 2n = 20, 22, 40, 44, 50, 60 y 80. 2, 4, 6 y 8, ploid. 



</doc>
<doc id="1417" url="https://es.wikipedia.org/wiki?curid=1417" title="Holcus">
Holcus

Holcus es un género de plantas de la familia de las poáceas, conocidos genéricamente como "pastos dulces" o "pastos miel" por el contenido en glucosa de la hoja (aunque no deben confundirse con el "Paspalum dilatatum", al que también se conoce por ese nombre). 
Son nativos de Eurasia, y prefieren los climas frescos y templados.
Los tallos son cortos, rodeados de hojas lisas de color verde grisáceo. Las inflorescencias son de color blanco o violáceo, y miden entre 2 y 6 cm de largo. 

Son plantas anuales o perennes. Hojas con vaina de márgenes libres; lígula dentada, membranosa; limbo plano o ligeramente convoluto. Inflorescencia en panícula laxa. Espiguillas ligeramente comprimidas lateralmente, con 2 (-3) flores articuladas con la raquilla. Raquilla prolongada por encima de la última flor, generalmente pelosa. Glumas más largas que las flores, ligeramente desiguales, aquilladas; la inferior uninervada; la superior trinervada. Lema elíptica, con 5 nervios, truncada; la de la flor inferior mútica o aristada; la de la flor superior generalmente aristada; arista dorsal o subterminal, geniculada o curvada. Callo obtuso y corto. Pálea más corta que la lema, con 2 quillas escábrida. Lodículas generalmente con 1 diente lateral. Ovario glabro. Cariopsis oblongo-elíptica, ligeramente surcada. Hilo elíptico.
El género fue descrito por Carlos Linneo y publicado en "Species Plantarum" 2: 1047. 1753. La especie tipo es: "Holcus lanatus" L.




</doc>
<doc id="1418" url="https://es.wikipedia.org/wiki?curid=1418" title="Hordelymus">
Hordelymus

Hordelymus, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Eurasia.




</doc>
<doc id="1419" url="https://es.wikipedia.org/wiki?curid=1419" title="Hordeum">
Hordeum

Hordeum es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de Norteamérica y del norte de Asia.
Es un género de plantas perteneciente a la familia Gramíneas o Poáceas, pueden ser anuales o perennes, menores de 1,6 m de altura.
Morfológicamente se puede distinguir una vaina con dos apéndices auriculiformes en la zona ligular, lígula corta y láminas planas, excepcionalmente setáceas.
Poseen una flor hermafrodita con 3 estambres, fruto cariopse oblongo, deprimido con surco ventral y ápice pubescente, adherido a las glumelas o separándose de ellas por efecto de la trilla.
La inflorescencia es en espigas, las cuales pueden ser dísticas o comprimidas, con un raquis frágil o tenaz. Espiguillas unifloras dispuestas de a 3 en cada soporte del raquis, con el dorso de la lemma hacia afuera; la espiguilla central es siempre hermafrodita, las laterales pueden ser hermafroditas o estériles; raquilla articulada arriba de las glumas y prolongaciones en apéndice filiforme, piloso o glabro.
Glumas 2, lanceoladas o lineares.

Lemma lanceolada, 5-nervada, aristada, trifurcada o mútica.

Existen aproximadamente unas 25 a 30 especies en las regiones templadas de todo el mundo, 4 de las cuales son domésticas:
"Hordeum vulgare; Hordeum distichum; Hordeum intermedium; Hordeum deficens". En general prefieren un suelo fértil bien drenado a pleno sol.
El género fue descrito por Carlos Linneo y publicado en "Species Plantarum" 1: 84–85. 1753. 1753. La especie tipo es: " Hordeum vulgare" L
Hordeum: nombre antiguo latino para la cebada.
El número de cromosomas es de: x = 7. 2n = 14, 28, y 42





</doc>
<doc id="1420" url="https://es.wikipedia.org/wiki?curid=1420" title="Hyparrhenia">
Hyparrhenia

Hyparrhenia es un género de plantas herbáceas de la familia de las poáceas. Es originario de África.

La mayoría son nativas de África tropical, algunas se pueden encontrar en zonas cálidas templadas en Eurasia. Son gramíneas anuales y perennes. La inflorescencia surge como dobles espigas de espiguillas en parejas.

Son plantas perennes, cespitosas. Hojas con lígula membranosa, obtusa o truncada, denticulada, glabra. Inflorescencia en panícula, compuesta por varios pares de racimos, parcialmente envueltos por vainas espatiformes. Espiguillas geminadas, articuladas por debajo de las glumas, ligeramente comprimidas dorsiventralmente, desiguales; la inferior de cada pareja sentada, con 1 flor inferior reducida a la lema y otra superior hermafrodita; la superior pedunculada, con 1 flor inferior reducida a la lema y otra superior masculina. Glumas más largas que las flores, subiguales; la inferior con 7-11 nervios y 2 quillas; la superior trinervada. Lema de las flores hermafroditas con arista terminal 1-2 veces geniculada; la de las flores masculinas mútica. Pálea muy reducida o ausente. Lodículas glabras. Androceo con 3 estambres. Cariopsis con embrión de c. 1/3 de su longitud.
El género fue descrito por Andersson ex E.Fourn. y publicado en "Mexicanas Plantas" 2: 51, 67. 1886. La especie tipo es: "Hyparrhenia foliosa" (Kunth) Andersson ex E. Fourn. 
Hyparrhenia: nombre genérico que deriva del griego "hipo" = (bajo) y "arrhen" = (masculino), en alusión a que las espiguillas masculinas solo se encuentran en las bases del racimo.
El número de cromosomas es de : x = 10 y 15. 2n = 20, 30, 40, 44, 45, y 60. 2, 4, y 6 ploides. Nucleolos persistentes.




</doc>
<doc id="1421" url="https://es.wikipedia.org/wiki?curid=1421" title="Helada (desambiguación)">
Helada (desambiguación)

La palabra helada puede referirse a:


</doc>
<doc id="1424" url="https://es.wikipedia.org/wiki?curid=1424" title="Hombre">
Hombre

Hombre hace referencia a:











</doc>
<doc id="1426" url="https://es.wikipedia.org/wiki?curid=1426" title="Homo sapiens">
Homo sapiens

Homo sapiens (del latín, "homo" ‘hombre’ y "sapiens" ‘sabio’) es una especie del orden de los primates perteneciente a la familia de los homínidos. También son conocidos bajo la denominación genérica de «humanos». Los seres humanos poseen capacidades mentales que les permiten inventar, aprender y utilizar estructuras lingüísticas complejas, lógicas, matemáticas, escritura, música, ciencia y tecnología. Los humanos son animales sociales, capaces de concebir, transmitir y aprender conceptos totalmente abstractos.

Se considera "Homo sapiens" de forma indiscutible tanto a los que poseen las características anatómicas de las poblaciones humanas actuales como lo que se define como «comportamiento moderno». Los restos más antiguos atribuidos a "Homo sapiens" se encuentran en Marruecos, con 315 000 años. Las evidencias más antiguas de comportamiento moderno son las de Pinnacle Point (Sudáfrica), con 165 000 años.

Pertenece al género "Homo," que fue más diversificado y durante el último millón y medio de años incluía otras especies ya extintas. Desde la extinción del "Homo neanderthalensis", hace 28 000 años, y del "Homo floresiensis" hace 12 000 años (debatible), "Homo sapiens" es la única especie conocida del género "Homo" que aún perdura.

Hasta hace poco, la biología utilizaba un nombre trinomial —"Homo sapiens sapiens"— para esta especie, pero más recientemente se ha descartado el nexo filogenético entre el neandertal y la actual humanidad, por lo que se usa exclusivamente el nombre binomial. "Homo sapiens" pertenece a una estirpe de primates, los hominoideos. Aunque el descubrimiento de "Homo sapiens idaltu" en 2003 haría necesario volver al sistema trinomial, la posición taxonómica de este último es aún incierta. Evolutivamente se diferenció en África y de ese ancestro surgió la familia de la que forman parte los homínidos.
Filosóficamente, el ser humano se ha definido y redefinido a sí mismo de numerosas maneras a través de la historia, otorgándose de esta manera un propósito positivo o negativo respecto de su propia existencia. Existen diversos sistemas religiosos e ideales filosóficos que, de acuerdo con una diversa gama de culturas e ideales individuales, tienen como propósito y función responder a algunas de esas interrogantes existenciales. Los seres humanos tienen la capacidad de ser conscientes de sí mismos, así como de su pasado; saben que tienen el poder de planear, transformar y realizar proyectos de diversos tipos. En función de esta capacidad, han creado diversos códigos morales y dogmas orientados directamente al manejo de estas capacidades. Además, pueden ser conscientes de responsabilidades y peligros provenientes de la naturaleza, así como de otros seres humanos.

El nombre científico es el asignado por el naturalista sueco Carlos Linneo (1707-1778) en 1758, alude al rasgo biológico más característico: "sapiens" significa «sabio» o «capaz de conocer», y se refiere a la consideración del ser humano como «animal racional», al contrario que todas las otras especies, siendo la descripción que aportó para "Homo sapiens" fue simplemente: "Nosce te ipsum" («Conócete a ti mismo»). Es precisamente la capacidad del ser humano de realizar operaciones conceptuales y simbólicas muy complejas —que incluyen, por ejemplo, el uso de sistemas lingüísticos muy sofisticados, el razonamiento abstracto y las capacidades de introspección y especulación— uno de sus rasgos más destacados. Posiblemente esta complejidad, fundada neurológicamente en un aumento del tamaño del cerebro y, sobre todo, en el desarrollo del lóbulo frontal, es también una de las causas, a la vez que producto, de las muy complejas estructuras sociales que el ser humano ha desarrollado, y que forman una de las bases de la cultura, entendida biológicamente como la capacidad para transmitir información y hábitos por imitación e instrucción, en vez de por herencia genética. Esta propiedad no es exclusiva de esta especie y es importante también en otros primates.

Linneo clasificó al hombre y a los monos en un grupo que llamó antropomorfos, como subconjunto del grupo cuadrúpedos, pues entonces no reconocía signos orgánicos que le permitieran ubicar al ser humano en un lugar privilegiado de la escala de los vivientes. Años más tarde, en el prefacio de "Fauna suecica", manifestó que había clasificado al hombre como cuadrúpedo porque no era planta ni piedra, sino un animal, tanto por su género de vida como por su locomoción y porque además, no había podido encontrar un solo carácter distintivo por el cual el hombre se diferenciara del mono; en otro contexto afirmó sin embargo que considera al hombre como el fin último de la creación. A partir de la décima edición de "Systema naturae" reemplazó a los cuadrúpedos por los mamíferos y como primer orden de estos, puso a los primates, entre los cuales colocó al hombre. Linneo tuvo el mérito de dar origen a un nuevo e inmenso campo epistemológico, el de la antropología, si bien se limitó a enunciarlo y no lo cultivó. A él tendrán que remitirse todos los científicos posteriores, tanto para retomar sus definiciones como para criticarlas. En 1758 se definió al "Homo sapiens" linneano como una especie diurna que cambiaba por la educación y el clima. 

Linneo no designó un holotipo para "Homo sapiens", pero en 1959 William Stearn propuso al propio Linneo, padre de la moderna taxonomía, como lectotipo para la especie. Con posterioridad se difundió la idea de que había sido sustituido por Edward Cope, pero esta propuesta no llegó a formalizarse, así que siguen siendo los restos de Linneo enterrados en Uppsala el tipo nomenclatural -que debe considerarse simbólico- para la especie "Homo sapiens". 

En la actualidad existen defensores de incluir al ser humano, chimpancé ("Pan troglodytes") y bonobo ("Pan paniscus") en el mismo género, dada la cercanía filogenética, que es más estrecha que la que se encuentra entre otras especies animales que sí están agrupadas genéricamente.

El ser humano es un ser vivo, y como tal está compuesto por sustancias químicas llamadas biomoléculas, por células y realiza las tres funciones vitales: nutrición, relación y reproducción.

Además, el cuerpo es un organismo pluricelular; es decir, está formado por muchas células, entre las cuales existen diferencias de estructura y de función.

Por otra parte, el ser humano es un animal, pues tiene células eucariotas, es decir, presenta orgánulos celulares especializados en una función determinada y su material genético se encuentra protegido por una envoltura; y presenta nutrición heterótrofa; es decir, que para obtener su propia materia orgánica se alimenta de otros seres vivos.

En cuanto a su locomoción y movimiento, es uno de los más plásticos del reino animal, pues existe una amplia gama de movimientos posibles, lo que le capacita para actividades como el arte escénico y la danza, el deporte y un sinnúmero de actividades cotidianas. Asimismo destaca la habilidad de manipulación, gracias a los pulgares oponibles, que le facilitan la fabricación y uso de instrumentos.

El ser humano adulto contemporáneo puede medir, como media, entre 1,5 a 1,9 metros; y pesar entre 50 y 90 kg. La especie humana posee un notorio dimorfismo sexual en el nivel anatómico, siendo los hombres adultos más altos y más pesados que las mujeres en promedio, aunque se ha notado una «tendencia secular» al aumento de las tallas en ambos sexos (especialmente durante el siglo XX). El varón adulto puede medir, como media, entre 1,65 a 1,8 m. con un peso de entre 70 y 90 kg; y la mujer adulta, como media, entre 1,55 a 1,65 m. con un peso de entre 50 y 70 kg.

La mente se refiere colectivamente a aspectos del entendimiento y conciencia que son combinaciones de capacidades como el raciocinio, la percepción, la emoción, la memoria, la imaginación y la voluntad. La mente, según la neurociencia, es un resultado de la actividad del cerebro.

El término pensamiento define todos los productos que la mente puede generar incluyendo las actividades racionales del intelecto y las abstracciones de la imaginación; todo aquello que sea de naturaleza mental es considerado pensamiento, bien sean estos abstractos, racionales, creativos, artísticos, etc. Junto con los cetáceos superiores (delfines y ballenas), los homininos de los géneros "Gorilla" y "Pan," y los elefantes, alcanzan el mayor desarrollo y aun muchas de sus interacciones nos son desconocidas.

El ser humano es un animal omnívoro.  En las primeras especies del género "Homo", el paso de una alimentación eminentemente vegetariana a la inclusión de la carne en la dieta no se debió a cuestiones culturales, sino a los desajustes metabólicos provocados por un mayor desarrollo cerebral. Sin embargo, en el humano, una dieta demasiado rica en proteínas necesita el complemento de carbohidratos y grasas; de lo contrario pueden aparecer carencias nutricionales importantes que pueden incluso provocar la muerte. Por ello, la alimentación del ser humano se basa en la combinación de materia vegetal con carne, aunque hay humanos que optan debido a voluntad propia o razones médicas a realizar dietas vegetarianas.

La especie humana es entre los seres vivos pluricelulares actuales una de las más longevas; se tienen documentados casos de longevidad que sobrepasan los cien años. Tal longevidad es un carácter genotípico que, sin embargo, debe ser coadyuvado por condiciones vivenciales favorables. En el Imperio romano, hacia el año 1 d. C., la esperanza de vida rondaba solo los 25 años, debido en gran parte a la elevada mortalidad infantil. A principios del siglo XXI, la esperanza de vida global era de unos 70 años aproximadamente, siendo más elevada en países desarrollados y más baja en países subdesarrollados.

La 'infancia' humana es una de las más prolongadas en comparación con otras especies cercanas, siendo la edad de la pubertad es aproximadamente a los once años en las niñas y a los trece años en los niños, aunque las edades varían según la persona.
Como todos los mamíferos, el ser humano tiene unos comportamientos reproductivos y sexuales. Pero a diferencia de la mayoría de ellos no tiene una época reproductiva estacional determinada, manteniendo actividad sexual y fertilidad en las hembras a lo largo de todo el año. Las mujeres tienen un ciclo de ovulación aproximadamente mensual, durante el cual producen óvulos y pueden ser fecundadas; en caso contrario tienen la menstruación, que es la eliminación a través de la vagina de los tejidos y sustancias relacionados con la producción de células sexuales.

Pero el comportamiento sexual humano no está únicamente supeditado a las funciones reproductivas, sino que, de modo similar a otros simios antropoides, tiene fines recreativos y sociales. En el contacto sexual se busca tanto el placer como la comunicación afectiva. Es una parte importante de las relaciones de pareja y también se considera importante en las necesidades psicológicas del invididuo aunque no tenga una relación de pareja.

Desde el punto de vista psicoanalítico, entre otras implicaciones, la importancia del lenguaje simbólico en el "Homo sapiens" hace que los significantes sean los soportes del pensar o los pensamientos. En nuestra especie, el pensar humano, a partir de los tres años y medio de edad se hace prevalentemente simbólico.

Asociado con lo anterior (y esto lo explica el psicoanálisis), debe notarse que la especie humana es prácticamente la única que se mantiene en celo sexual continuo: es realmente destacable que en la especie humana no exista un estro propiamente dicho. En las mujeres existe un ciclo de actividad ovárica en virtud del cual existen cambios fisiológicos en todo su sistema reproductivo y del cual derivan ciertos cambios de conducta. Sin embargo, como en las mujeres la aceptación sexual no se circunscribe a una parte del ciclo reproductivo, no se debería usar el término ""estro"" o ""celo"" en el ser humano, dado que la aceptación sexual es independiente de su ciclo reproductivo. Ya entre chimpancés y, sobre todo, bonobos, se nota una conducta próxima.

Ahora bien; dada la dificultad de vivir "solamente" practicando relaciones sexuales, un "mecanismo" evolutivo compensatorio habría sido el de la sublimación –la cual se considera asociada a la existencia de un lenguaje y un pensar simbólicos–. Si se da una sublimación, esto parece significar que también se da una "represión" (en el sentido freudiano) que origina a lo inconsciente. El "Homo sapiens" es, en este sentido, un "animal pulsional". Según la reflexología de Pavlov el "Homo sapiens" "no" se restringe a un "primer sistema de señales" (el de estímulo/respuesta y respuesta a un estímulo substitutivo), sino que el ser humano se encuentra en un nivel de "segundo sistema de señales". Este segundo sistema es, principalmente, el del lenguaje simbólico que permite una heurística, que es la capacidad para realizar de forma inmediata innovaciones positivas para sus fines.

Por otra parte, la especie humana es de las pocas, junto con el bonobo ("Pan paniscus"), en el reino animal que copula cara a cara, lo cual tiene implicaciones emocionales de gran relevancia para la especie.

Cabe anotar que con el surgimiento de la teoría de la inteligencia emocional, desde la psicología sistémica, el ser humano no debe reducirse a sus pulsiones, las cuales sublima o reprime, sino que se entiende como un ser sexuado, que vive esta dimensión en relación con la formación recibida en la familia y la sociedad. La sexualidad se forma entonces desde los primeros años y se va entendiendo como una vivencia procesual acorde a su ciclo vital y su contexto socio-cultural.

A diferencia de lo que ocurre en la mayor parte de las otras especies sexuadas, la mujer sigue viviendo mucho tiempo tras la menopausia. En las otras especies la hembra suele fenecer al poco tiempo de llegada la misma.

Por la indicada prematuración, la madurez sexo-genital es –en relación a otras especies– muy tardía entre los individuos de la especie humana. Actualmente en muchas zonas la menarquia está ocurriendo a los once años; esto significa que, aunque la madurez sexo-genital es siempre lenta en la especie humana, existe un adelantamiento de la misma respecto a épocas pasadas (del mismo modo suele darse una menopausia cada vez más tardía). Pero si la madurez sexo-genital es tardía en la especie humana, aún más suele serlo la madurez intelectual y, en especial, la "madurez emotiva".

A lo largo de la historia se han ido desarrollando distintas concepciones míticas, religiosas, filosóficas y científicas respecto del ser humano, cada una con su propia explicación sobre el origen del hombre, trascendencia y misión en la vida.

Evolutivamente, en cuanto perteneciente al infraorden Catarrhini, "Homo sapiens" parece tener su ancestro, junto con todos los primates catarrinos, en un período que va de los 50 a 33 millones de años antes del presente (AP). Uno de los primeros catarrinos, quizás el primero, es "Propliopithecus", incluyendo a "Aegyptopithecus." En este sentido, el ser humano actual, al igual que primates del "Viejo Mundo" con características más primitivas, probablemente descienda de esa antigua especie.

En cuanto a la bipedestación, esta se observa en ciertos primates a partir del Mioceno. Ya se encuentran ejemplos de bipedación en "Oreopithecus bambolii" y la bipedestación parece haber sido común en "Orrorin" y "Ardipithecus". Las mutaciones que llevaron a la bipedación fueron exitosas porque dejaban libres las manos para coger objetos y, particularmente, porque en la marcha un homínido ahorra mucha más energía andando sobre dos piernas que sobre cuatro patas, puede acarrear objetos durante la marcha y otear más lejos. Sin embargo, de remontarse la bipedestación a quizás a unos seis millones de años AP, la andadura o forma de marcha típica del humano se consolida aproximadamente hace al menos unos cuatro millones de años con "Australopithecus." Previamente los primates antropoides apoyaban toda la planta del pie haciendo una flexión y descargando el peso en el calcáneo; en cambio, "Australopithecus" logra una marcha bípeda eficiente, pues se notan claramente los cambios anatómicos a nivel del pie, en especial del dedo gordo; también ajustando el ángulo del fémur con el cuerpo para el equilibrio, la cadera o pelvis cambia a más robusta, corta y cóncava (forma de cuenco); la columna pasó de ser un arco en forma de C a una forma de S y el agujero de la base del cráneo que conecta con la columna se desplazó hacia adelante como dirigiéndose al centro de gravedad de la cabeza.

Hace 1.5 millones de años con "Homo erectus" o con "Homo ergaster", la andadura moderna implica la existencia de un pequeño ángulo entre el dedo gordo y el eje del pie, así como la presencia del arco longitudinal de la planta y una distribución medial del peso (nótese que en las mujeres la andadura distribuye el peso más hacia las partes internas del pie debido a la mayor anchura de la pelvis).

Todos los cambios reseñados han sucedido en un periodo relativamente breve (aunque se mida en millones de años). Esto explica la susceptibilidad de nuestra especie a afecciones en la columna vertebral y en la circulación sanguínea y linfática (por ejemplo, el corazón recibe -relativamente- "poca" sangre).

Lo que denominamos propiamente «humano» es una referencia a la aparición de la capacidad de fabricar herramientas de piedra en un homínido bípedo, "Homo habilis", considerado por la mayoría como la especie humana más primitiva, mostrando además incremento en la capacidad craneana con respecto a "Australopithecus". Es así como se establece que hace unos 2.5 millones de años, con la aparición del género "Homo", se toma como punto de inicio para el Paleolítico o Edad de Piedra. Mayor éxito evolutivo tendrá "Homo erectus", quien logrará expandirse por todo Eurasia.
Probablemente cuando los ancestros de "Homo sapiens" vivían en selvas comiendo frutos, bayas y hojas, abundantes en vitamina C, pudieron perder la capacidad metabólica que tiene la mayoría de los animales de sintetizar en su propio organismo tal vitamina; ya antes parecen haber perdido la capacidad de digerir la celulosa. Tales pérdidas durante la evolución han implicado sutiles pero importantes determinaciones: cuando las selvas originales se redujeron o, por crecimiento demográfico, resultaron superpobladas, los primitivos homínidos (y luego los humanos) se vieron forzados a recorrer importantes distancias, migrar, para obtener nuevas fuentes de nutrientes. La pérdida de la capacidad de metabolizar ciertos nutrientes como la vitamina C habría sido compensada por una mutación favorable que permite a "Homo sapiens" una metabolización óptima (ausente en primates) del almidón, y así una rápida y "barata" obtención de energía, particularmente útil para el cerebro. "Homo sapiens" parece ser una criatura bastante indefensa, y como respuesta satisfactoria la única solución evolutiva que ha tenido es su complejísimo sistema nervioso central, espoleado principalmente por la búsqueda de nuevas fuentes de alimentación. Se ha sugerido la hipótesis de que la cefalización aumentó paralelamente al incremento de consumo de carne, aunque dicha hipótesis no concuerda con el grado de cefalización desarrollada por los animales carnívoros. La habilidad humana para digerir alimentos con alto contenido de almidón podría explicar el éxito del Homo sapiens en el planeta, y sugiere un estudio genético.

Se denomina «humanos arcaicos», «"Homo sapiens" arcaico» o también «pre-sapiens», a un cierto número de especies de "Homo" que aún no son considerados anatómicamente modernos. Poseen hasta 600 000 años de antigüedad y tienen un tamaño cerebral cercano al de los humanos modernos. El antropólogo Robin Dunbar opina que es en esta etapa cuando aparece el lenguaje humano. La filiación de estos individuos dentro de nuestro género resulta aun controvertida.

Entre los humanos arcaicos están considerados "Homo heidelbergensis", "Homo rhodesiensis", "Homo neanderthalensis" y a veces "Homo antecessor." En 2010 se ha añadido a estos el denominado «hombre de Denísova», y en 2012 el denominado «hombre del ciervo rojo» en China. Ya que no son "sapiens", algunos especialistas prefieren llamarlos simplemente "arcaicos" antes que "H. sapiens" arcaico.

Se denomina propiamente "Homo sapiens" o anatómicamente modernos a individuos con una apariencia similar a la de los humanos modernos. Estos humanos pueden clasificarse como premodernos, pues en ellos no se observa todavía el conjunto de características de un cráneo moderno, casi esférico, con la bóveda alta y la frente vertical. La similitud se aprecia a nivel del esqueleto del cuerpo y cavidad craneana, pero esta similitud no es total pues el rostro aun mantiene características arcaicas como los arcos superciliares (grandes cejas) y prognatismo maxilar (proyección bucal), aunque menos desarrollados que en los neandertales.

Se considera dentro de este grupo a los restos de Florisbad en Sudáfrica (260 000 años), los de Herto en Etiopía, que corresponde a "Homo sapiens idaltu" (160 000 años), los de Jebel Irhoud en Marruecos (315 000 años) y los de Skhul/Qafzeh al norte de Israel (100 000 años). También se considera anatómicamente modernos a los hombres de Kibish; sin embargo, estos se enmarcan mejor dentro de los humanos modernos.

Se considera "Homo sapiens sapiens" de forma indiscutible a los que poseen las características principales que definen a los humanos modernos: primero la equiparación anatómica con las poblaciones humanas actuales y luego lo que se define como "comportamiento moderno".

Actualmente, gracias a los análisis científicos, se sabe que en la genealogía de la evolución humana habría existido un antepasado común masculino y uno femenino, a los cuales se les nombró como sus símiles religiosos.

Los restos más antiguos son los de Omo I, llamados Hombres de Kibish, encontrados en Etiopía con 195 000 años, y restos en cuevas del río Klasies en Sudáfrica con 125 000 años y con indicios de una conducta más moderna.

Esta antigüedad coincide con lo estimado para la Eva mitocondrial, la cual está considerada la antecesora de todos los seres humanos actuales y de la que se cree que vivió en el África Oriental (probablemente Tanzania) hace unos 200 000 años.

Por otra parte, la línea patrilineal nos lleva hasta el Adán cromosómico, quien nos confirma un origen para los humanos modernos en el África subsahariana y se le calcula unos 140 000 años de antigüedad.

Es casi seguro que la Eva mitocondrial y el Adán, los primeros "Homo sapiens" eran melanodérmicos, esto es, de tez oscura. Esto se debe a que la piel oscura es una excelente adaptación a la exposición solar alta de las zonas intertropicales del planeta Tierra; la tez oscura (por la melanina) protege de las radiaciones UV (ultravioletas) y obtiene de ellas por metabolismo un nutriente llamado folato, indispensable para el desarrollo del embrión y del feto; pero, a medida que las poblaciones humanas migraron a latitudes más allá de los 45º (tanto norte como sur) la melanina paulatinamente fue menos necesaria, más aún, en las cercanías de las latitudes de los 50º la casi total falta de este pigmento en la dermis, cabello y ojos ha sido una adaptación para captar más radiaciones U.V. —relativamente escasas en tales latitudes, salvo que se produzcan huecos de ozono—; en tales latitudes la tez muy clara posibilita una mayor metabolización de vitamina D a partir de las radiaciones UV.

La aparición del comportamiento humano moderno significó el más importante cambio en la evolución de la mente humana, dando lugar a que el ingenio creativo humano le llevaría a dominar su entorno paulatinamente. Una revolución humana que nos hizo como somos hoy.

Las innovaciones que fueron apareciendo consisten en una gran diversidad de herramientas de piedra, en el uso de hueso, asta y marfil, en entierros con bienes funerarios y rituales, construcción de viviendas, diseño de las fogatas, evidencia de pesca, cacería compleja, aparición del arte figurativo y el uso de adornos personales.

Las evidencias más antiguas se encuentran en África; herramientas elaboradas hace 165 000 años se encontraron en la cueva de Pinnacle Point (Sudáfrica). Restos de puntas de flechas y herramientas de hueso para pescar se encontraron en el Congo y tienen 90 000 años. Igualmente antiguos son unos símbolos sombreados con ocre rojo en costas al sur de África.
Según la teoría fuera de África, hubo una gran migración de África hacia Eurasia hace 70 000 años que produjo la paulatina dispersión por todos los continentes. Según los estudios genéticos y los descubrimientos paleontológicos, se estima que hace 60 000 años hubo una migración costera por el Sur de Asia, de pocos miles de años, que posibilitó la colonización posterior de Australia, Extremo Oriente y Europa.

En Occidente hubo un centro de expansión en el Medio Oriente que está relacionado con el hombre de Cromañón y la población temprana de Europa, probable causa de la extinción del hombre de Neandertal.

Según algunos estudios genéticos, en Europa hubo tres migraciones: la primera, proveniente del Asia Central hace 40 000 años que colonizó la Europa del Este. Una segunda oleada hace 22 000 años, proveniente del Oriente Medio, que se instaló en la Europa del sur y del oeste. El 80 % de los europeos actuales son descendientes de estas dos migraciones, que durante el transcurso del máximo glaciar de hace 20 000 años se refugiaron en la península ibérica y en los Balcanes, para volver a expandirse por el resto de Europa cuando llegó el clima favorable. La tercera migración se habría producido hace 9000 años, proveniente del Oriente Medio, durante el transcurso del Neolítico, y solo el 20 % de los europeos actuales llevan marcadores genéticos correspondientes a esos emigrantes.

Otros estudios dicen lo contrario, afirmando que en Europa el componente neolítico desde el Cercano Oriente es el más importante. Lo cierto por ahora es que el acervo genético europeo prehistórico proviene mayoritariamente del Cercano Oriente, y una menor parte proviene de África, Asia Central y Siberia.

En Oriente la población es igualmente antigua. El pliegue epicántico de los párpados existente en gran parte de las poblaciones del Asia y de América, el pliegue que hace 'bridados' en su aspecto externo a los ojos, ha sido una especialización de poblaciones que durante las glaciaciones debieron pervivir en lugares con abundancia de nieve; los ojos vulgarmente llamados «rasgados» entonces fueron el modo de adaptación para que los ojos no padecieran un excesivo reflejo de la luz solar reflejada por la nieve.

Sin embargo, una publicación de julio de 2019 en la revista "Nature" puso en tela de juicio las teorías e ideas previas acerca del momento del poblamiento de Europa por el "Homo sapiens" desde África. El hallazgo y datación de un cráneo de "Homo sapiens" de años de antigüedad en Grecia significaría un poblamiento de Europa años más temprano que lo que se suponía.
El lenguaje designa todas las comunicaciones basadas en la interpretación, incluyendo el lenguaje humano, pero la mayoría de las veces el término se refiere a lo que los humanos utilizan para comunicarse, es decir, a las lenguas naturales. El lenguaje es universal y es usado por naturaleza en las personas y en los animales. Sin embargo, filósofos como Martin Heidegger consideran que el lenguaje propiamente tal es solo privativo del hombre. Es famosa la tesis de Heidegger según la cual el lenguaje es la casa del ser (Haus des Seins) y la morada de la esencia humana. Este criterio es similar al de Ernst Cassirer, quien ha definido al "Homo sapiens" como el "animal simbólico por excelencia"; tan es así que es casi imposible suponer un pensamiento humano sin la ayuda de los símbolos, particularmente de los significantes que subyacen como fundamentos elementales para todo pensar complejo y que transcienda a lo instintivo.

Actualmente la especie humana muestra esta faceta hablando en torno a 6000 idiomas diferentes, si bien más del 50 % de los 7000 millones de personas que actualmente conforman la colectividad humana, sabe hablar al menos una de las siguientes lenguas: chino mandarín, español, inglés, francés,árabe, hindi, portugués, alemán,bengalí y ruso.

En muchas civilizaciones los seres humanos se han visto a sí mismos como diferentes de los demás animales, y en ciertos ámbitos culturales (como las religiones del Libro o buena parte de la metafísica del Occidente) la diferencia se asigna a una entidad inmaterial llamada alma, en la que residirían la mente y la personalidad, y que algunos creen que puede existir con independencia del cuerpo.
Posiblemente, la manifestación más clara de humanidad es el arte —en el sentido amplio del término—, que produce la cultura. Por ejemplo, los individuos de una determinada especie de ave fabrican un nido, o emiten un canto, cuyas características son específicas, comunes a todos los individuos de esa especie. En cambio, cada hombre puede imprimir a sus acciones los rasgos propios de su individualidad; por eso, cuando se analiza un cuadro, una forma de escribir, una manera de fabricar herramientas, etc., se puede deducir quién es su autor, su artífice, su artista.

En 2011, en la revista "Science", se publicó un trabajo de Francesco d'Errico, de la Universidad de Burdeos, donde afirma haber encontrado uno de los rastros más antiguos de un taller de pintura, en la cueva Blombos en Cape Coast, 300 km al este de Ciudad del Cabo. Este hecho muestra un modo sistemático para obtener pigmentos, pues reunir todos los elementos necesarios para una preparación de este tipo es indicativo de un elevado nivel de pensamiento, que se puede llamar pensamiento simbólico. "La capacidad de tener estos pensamientos es considerada un gran paso en la evolución humana, precisamente lo que nos diferenció del mundo animal".

Paralelamente, también es la única especie que dedica su tiempo y energía a algo aparentemente inútil desde el punto de vista puramente práctico. El arte es una de las manifestaciones de la creatividad humana, pero una manifestación vacía y negativa desde el punto de vista de la supervivencia. Si bien esta actividad es en principio dañina, en realidad es la herramienta con la cual el "Homo sapiens" desarrolla su cultura, unión y fuerza como pueblo.

Una sociedad humana es aquella que se considera a sí misma, a los habitantes y a su entorno, todo ello interrelacionado con un proyecto común, que les da una identidad de pertenencia. Asimismo, el término connota un grupo con lazos económicos, ideológicos y políticos. Tal sociedad supera al concepto de nación-estado, planteando a la sociedad occidental como una sociedad de naciones, etc.

En relación con la capacidad para realizar grandes modificaciones ambientales, cabe decir que "Homo sapiens" es actualmente un poderoso agente geomorfológico; es en este y otros sentidos que el ser humano es actualmente el mayor superpredador y la especie más poderosa del planeta. Sin embargo, sigue siendo frágil ante posibles eventos cataclísmicos que pudieran afectar a su hábitat, como las glaciaciones.

"Homo sapiens", por ser un animal muy vulnerable en el medio natural, es muy dependiente de la tecnología (ergo: es dependiente de la ciencia por primitiva que esta sea), así es que se dice de "Homo sapiens" que es "homo faber".

Quizás, dado que todo sistema retroalimentado de forma natural llega a su fin, el fin de un ecosistema llega cuando la vida ha logrado evolucionar hasta lograr seres con un grado de conciencia capaz de programarse en función de la educación recibida y no según lo termodinámicamente sostenible. La educación es, por tanto, la demostración evidente de si somos parte de un sistema aún mayor o intentamos independizarnos de todo, estableciendo nuestras formas de obtener nuestros recursos, sin tener en cuenta los ya establecidos por la propia naturaleza.

Por ejemplo, la naturaleza le dota de capacidades físicas para buscar alimentos en el medio que les rodea de una manera termodinámicamente eficaz. Los humanos establecen que lo mejor es racionalizar los medios que la naturaleza les da y replicarlos de forma industrial, aplicando procesos que no se dan de forma natural, aumentando el consumo energético por redundar algo que ya existe y ampliándolo a algo totalmente termodinámicamente innecesario, como es el hecho de que se le entregue alimento en casa, de intervenir los códigos genéticos de las especies alimentarias para hacerlas resistentes a enfermedades, de influir en qué alimentos contendrán semillas y cuáles no y un largo etcétera, que a día de hoy nos hace la vida más cómoda, pero que ignoran cómo les afectan esos cambios en su estructura genética y, por lo tanto, si su descendencia portará características fundamentales para sobrevivir a un medio natural o, por el contrario, nacerán y dependerán tan íntimamente del medio artificial que cualquier modificación a ese medio le incapacite de tal manera que provoque su extinción.




</doc>
<doc id="1427" url="https://es.wikipedia.org/wiki?curid=1427" title="Humana Inc.">
Humana Inc.

Humana Inc. (), fundada el año 1961 en Louisville, Kentucky, es una corporación empresarial que comercializa y administra seguros de salud. Con un conjunto de 11,5 millones de clientes en Estados Unidos, la compañía es la mayor en términos de beneficio del estado de Kentucky e integrante de la lista Fortune 100. Asimismo tiene una capitalización bursátil de más de 13 mil millones de dólares, beneficios por valor de 25,2 mil millones y posee 26.000 empleados en todo Norteamérica. Humana comercializa sus seguros de salud en los 50 estados de EE. UU., Washington D. C. y Puerto Rico, poseyendo además intereses económicos en Europa Occidental.

La compañía fue fundada por David A. Jones, Sr. y Wendell Cherry como empresa propietaria de residencias de la tercera edad en 1961. Entonces llamada Extendicare, llegó a ser la mayor empresa de este tipo en los Estados Unidos, para dejar esta actividad de lado y centrarse en la compra de hospitales en 1972. Llegó a ser la mayor compañía hospitalaria del mundo en la década de los ochenta. 

El nombre de la compañía cambió a Humana Inc. en 1974. Humana sufrió un tremendo crecimiento en los años venideros, en parte como consecuencia de la toma de control de American Medicorp Inc. en el año 1978, que tuvo como consecuencia que la empresa doblara su tamaño. Durante la segunda mitad de los años setenta, la empresa volcó sus esfuerzos en una estrategia de construcción y apertura rápida de hospitales en un mes. Durante este boom de la construcción, Humana desarrolló el modelo de doble pasillo para la construcción de hospitales. Este diseño altamente eficaz redujo la distancia entre pacientes y enfermeros localizando el servicio sanitario en el interior del edificio con las habitaciones de los pacientes rodeando el perímetro.

Humana trajo la investigación pionera del corazón artificial de la mano de los doctores Robert Jarvik y William DeVries, inventor y cirujano del primer corazón de este tipo que se implantó en la Universidad de Utah en 1982, para crear el Humana Heart Institute en Louisville en 1985.

Durante la última década del siglo XX Humana separó sus hospitales de sus operaciones relativas a la aseguración médica.

Durante el desarrollo del sistema sanitario de EE. UU. en la década de los ochenta, Humana creó y comenzó a comercializar seguros de salud. Por otro lado en 1998, el grupo United Healthcare intentó adquirir la compañía, sin embargo el esfuerzo fracasó cuando se dio a conocer las pérdidas trimestraes de United por valor de casi mil millones de dólares.

En el año 2001, Humana se unió en colaboración con Navigy, Inc. (subsidiaria de la también empresa aseguradora Blue Cross and Blue Shield Association of Florida, Inc.) para lanzar Availity, un servicio que facilita los trámites entre profesionales médicos de Florida, usuarios de los planes de salud y aseguradoras.

En 2005, la compañía pactó un acuerdo empresarial con el grupo Virgin, ofreciendo incentivos financieros a los asegurados para obtener un estilo de vida saludable en estos.

El Business Health Care Group of Southeast Wisconsin (en español, Grupo de Sanitario del Sureste de Wisconsin) escogió a Humana como socio administrativo para ayudar a reducir los costes sanitarios.

Humana lanzó en 2006 el servicio RightSource, una farmacia por correo a domicilio que opera en todo EE. UU.
La siguiente lista representa algunas de las mayores adquisiciones realizadas por Humana desde 1990 en EE. UU.




</doc>
<doc id="1428" url="https://es.wikipedia.org/wiki?curid=1428" title="Historia de la inteligencia artificial">
Historia de la inteligencia artificial

La Inteligencia Artificial surge definitivamente a partir de algunos trabajos publicados en la década de 1940 que no tuvieron gran repercusión, pero a partir del influyente trabajo en 1950 de Alan Turing, matemático británico, se abre una nueva disciplina de las ciencias de la información. 

Si bien las ideas fundamentales se remontan a la lógica y algoritmos de los griegos, y a las matemáticas de los árabes, varios siglos antes de Cristo, el concepto de obtener razonamiento artificial aparece en el siglo XIV. A finales del siglo XIX se obtienen lógicas formales suficientemente poderosas y a mediados del siglo XX, se obtienen máquinas capaces de hacer uso de tales lógicas y algoritmos de solución.

En su histórico artículo de 1950, Turing propuso que la pregunta «¿puede pensar una máquina?» era demasiado filosófica para tener valor y, para hacerlo más concreto, propuso un «juego de imitación». En la prueba de Turing intervienen dos personas y una computadora. Una persona, el interrogador, se sienta en una sala y teclea preguntas en la terminal de una computadora. Cuando aparecen las respuestas en la terminal, el interrogador intenta determinar si fueron hechas por otra persona o por una computadora. Si actúa de manera inteligente, según Turing es inteligente. Turing, señaló que una máquina podría fracasar y aún ser inteligente. Aun así creía que las máquinas podrían superar la prueba a finales del siglo XX.

De todas maneras esta prueba no tuvo el valor práctico que se esperaba, aunque sus repercusiones teóricas son fundamentales. El enfoque de Turing de ver a la inteligencia artificial como una imitación del comportamiento humano no fue tan práctico a lo largo del tiempo y el enfoque dominante ha sido el del comportamiento racional, de manera similar, en el campo de la aeronáutica se dejó de lado el enfoque de tratar de imitar a los pájaros y se tomó el enfoque de comprender las reglas de aerodinámica. Aunque desde luego, el enfoque del comportamiento humano y el del pensamiento humano siguen siendo estudiados por las ciencias cognitivas y continúan aportando interesantes resultados a la Inteligencia Artificial, y viceversa.

La ciencia no se define, sino que se reconoce. Para la evolución de la Inteligencia Artificial las dos fuerzas más importantes fueron la lógica matemática, la cual se desarrolla rápidamente a finales del siglo XIX, y las nuevas ideas acerca de computación y los avances en electrónica que permitieron la construcción de los primeros computadores en 1940.
También son fuente de la inteligencia artificial: la filosofía, la neurociencia y la lingüística. La lógica matemática ha continuado siendo un área muy activa en la inteligencia artificial. Incluso antes de la existencia de los ordenadores con los sistemas lógicos deductivos.

Los juegos matemáticos antiguos, como el de las Torres de Hanói, muestran el interés por la búsqueda de un modo resolutor, capaz de ganar con los mínimos movimientos posibles.

Cerca de 300 a. C., Aristóteles fue el primero en describir de manera estructurada un conjunto de reglas, silogismos, que describen una parte del funcionamiento de la mente humana y que, al seguirlas paso a paso, producen conclusiones racionales a partir de premisas dadas.

En 250 a. C. Ctesibio de Alejandría construyó la primera máquina autocontrolada, un regulador del flujo de agua que actuaba modificando su comportamiento "racionalmente" (correctamente) pero claramente sin razonamiento.

En 1315, Ramon Llull tuvo la idea de que el razonamiento podía ser efectuado de maneral artificial.

En 1847 George Boole estableció la lógica proposicional (booleana), mucho más completa que los silogismos de Aristóteles, pero aún algo poco potente.

En 1879 Gottlob Frege extiende la lógica booleana y obtiene la Lógica de Primer Orden la cual cuenta con un mayor poder de expresión y es utilizada universalmente en la actualidad.

En 1903 Lee De Forest inventa el triodo, también llamado bulbo o válvula de vacío.

En 1936 Alan Turing publicó un artículo de bastante repercusión sobre los "Números Calculables", un artículo que estableció las bases teóricas para todas las ciencias de computación, y que puede considerarse el origen oficial de la informática teórica. En este artículo introdujo el concepto de Máquina de Turing, una entidad matemática abstracta que formalizó el concepto de algoritmo y resultó ser la precursora de las computadoras digitales. Podía conceptualmente leer instrucciones de una cinta de papel perforada y ejecutar todas las operaciones críticas de un computador. El artículo fijó los límites de las ciencias de la computación porque demostró que no es posible resolver problemas con ningún tipo de computador. Con ayuda de su máquina, Turing pudo demostrar que existen problemas irresolubles, de los que ningún ordenador será capaz de obtener su solución, por lo que se le considera el padre de la teoría de la computabilidad. 

En 1940 Alan Turing y su equipo construyeron el primer computador electromecánico y en 1941 Konrad Zuse creó la primera computadora programable y el primer lenguaje de programación de alto nivel Plankalkül. Las siguientes máquinas más potentes, aunque con igual concepto, fueron la ABC y ENIAC.

En 1943 Warren McCulloch y Walter Pitts presentaron su modelo de neuronas artificiales, el cual se considera el primer trabajo del campo de inteligencia artificial, aun cuando todavía no existía el término.

En 1950 Turing consolidó el campo de la inteligencia artificial con su artículo "Computing Machinery and Intelligence", en el que propuso una prueba concreta para determinar si una máquina era inteligente o no, su famosa Prueba de Turing por lo que se le considera el padre de la Inteligencia Artificial. Años después Turing se convirtió en el adalid que quienes defendían la posibilidad de emular el pensamiento humano a través de la computación y fue coautor del primer programa para jugar ajedrez.

En 1951 William Shockley inventa el transistor de unión. El invento hizo posible una nueva generación de computadoras mucho más rápidas y pequeñas.

En 1956 se dio el término "inteligencia artificial" en Dartmouth durante una conferencia convocada por John McCarthy, a la cual asistieron, entre otros, Minsky, Newell y Simon. En esta conferencia se hicieron previsiones triunfalistas a diez años que jamás se cumplieron, lo que provocó el abandono casi total de las investigaciones durante quince años.

En 1980 la historia se repitió con el desafío japonés de la quinta generación, que dio lugar al auge de los sistemas expertos pero que no alcanzó muchos de sus objetivos, por lo que este campo sufrió una nueva interrupción en los años noventa.

En 1987 Martin Fischles y Oscar Firschein describieron los atributos de un agente inteligente. Al intentar describir con un mayor ámbito (no solo la comunicación) los atributos de un agente inteligente, la IA se ha expandido a muchas áreas que han creado ramas de investigación enormes y diferenciadas. Dichos atributos del agente inteligente son: 


Podemos entonces decir que la IA posee características humanas tales como el aprendizaje, la adaptación, el razonamiento, la autocorrección, el mejoramiento implícito, y la percepción modular del mundo. Así, podemos hablar ya no solo de un objetivo, sino de muchos, dependiendo del punto de vista o utilidad que pueda encontrarse a la IA.

En los 90 surgen los agentes inteligentes al paso de los años eso fue evolucionando

El programa Artificial Linguistic Internet Computer Entity (A.L.I.C.E.) ganó el premio Loebner al Chatbot más humano en 2000, 2001 y 2004, y en 2007 el programa Ultra Hal Assistant ganó el premio.

Muchos de los investigadores sobre IA sostienen que «la inteligencia es un programa capaz de ser ejecutado independientemente de la máquina que lo ejecute, computador o cerebro»:

2010: El programa Suzette ganó el premio Loebner. Algunos programas de inteligencia artificial gratuitos son Dr. Abuse, Alice, Paula SG, Virtual woman millenium.

2011: Un ordenador de IBM gana el concurso de preguntas y respuestas 'Jeopardy!': El ordenador de IBM Watson ha salido victorioso de su duelo contra el cerebro humano. La máquina ha ganado el concurso de preguntas y respuestas Jeopardy!, que emite la cadena de televisión estadounidense ABC, al imponerse a los dos mejores concursantes de la historia del programa. Watson les ha vencido en la tercera ronda, contestando preguntas que le obligaban a pensar como una persona.

2014: Un ordenador ha logrado superar con éxito el test de turing: Un ordenador ha logrado superar con éxito el test de Turing haciendo creer a un interrogador que es una persona quien responde sus preguntas- en un certamen organizado en Londres por la Universidad de Reading (Reino Unido). El ordenador, con el programa Eugene desarrollado en San Petersburgo (Rusia), se ha hecho pasar por un chico de 13 años, y los responsables de la competición consideran que es un “hito histórico de la inteligencia artificial”.

2016: Un ordenador de Google vence al campeón mundial de un juego milenario “Go”: Un programa informático desarrollado por la compañía británica Google DeepMind había conseguido vencer, por primera vez, a un campeón profesional de un milenario juego de origen oriental llamado Go. El reto era enorme para una máquina, ya que la prueba de estrategia encierra una gran complejidad.




</doc>
<doc id="1429" url="https://es.wikipedia.org/wiki?curid=1429" title="Heráclito">
Heráclito

Heráclito de Éfeso (en griego antiguo: Ἡράκλειτος ὁ Ἐφέσιος "Herákleitos ho Ephésios"; Éfeso, 540  a. C.-"ibidem", 480 a. C.), fue un filósofo griego presocrático nativo de Éfeso, ciudad de Jonia, en la costa occidental del Asia Menor (en la actual Turquía y luego parte del Imperio persa). 

La principal fuente de su vida nos llega a través de Diogenes Laercio. Nació en el seno de una familia aristócrata, pero evitó su vida privilegiada convirtiéndose en un filósofo ermitaño autodidacta. La obra de Heráclito es completamente aforística y se le atribuye un libro titulado "Sobre la naturaleza" (περὶ φύσεως). Como de los demás filósofos griegos anteriores a Platón, no quedan más que fragmentos de sus obras, y en gran parte se conocen sus aportes gracias a testimonios posteriores. Estos fueron recopilados en la obra "Die Fragmente der Vorsokratiker" bajo la numeración Diels-Kranz. 

Fue conocido también como El Oscuro de Éfeso debido a la naturaleza oracular y paradójica de su filosofía, y "El filósofo llorón" (en contraste con Demócrito, "el filósofo risueño") al ser considerado un misántropo ante el mundo. Diógenes Laercio atribuye a Teofrasto la teoría de que Heráclito no completó algunas de sus obras debido a la melancolía. Sus expresiones crípticas han sido objeto de numerosas interpretaciones. Ha sido visto de diversas maneras como un "monista material o un filósofo de procesos; un científico cosmólogo, un metafísico, o principalmente un pensador religioso; un empirista, un racionalista o un místico; un pensador convencional o un revolucionario; un desarrollador de lógica o alguien que negó el principio de no contradicción; el primer filósofo genuino o un oscurantista anti-intelectual". 

Heráclito creía que el mundo estaba regido de acuerdo con lo que denominó el "Logos" ("palabra", "razón" o "discurso"). También creía que el cosmos era una transmutación de fuego. Heráclito fue famoso por su insistencia en el cambio ("panta rei") y por su firme compromiso con la unidad y armonía de los contrarios, a diferencia del filósofo eléata Parménides, quien declaraba que "lo que es, no puede no ser", negando así el cambio. Por esta razón, Parménides y Heráclito han sido considerados como dos de los fundadores de la dialéctica y en parte de la metafísica y moral.

La fuente principal de la vida de Heráclito nos llega a través del historiador Diogenes Laercio en su obra "Vidas, opiniones y sentencias de los filósofos más ilustres".

Heráclito "floreció" en la 69ª Olimpiada, 504–501 a. C. Hijo de un tal Heración o Blisón, Heráclito se crio en el seno de una familia aristocrática hereditaria del cargo de Basileos c. 540 a.C. en Éfeso, parte del Imperio Persa, en lo que hoy es Turquía. Tal cargo Heráclito se lo cedió a su hermano. Diógenes relata que Heráclito era un misántropo. Creía que Hesíodo, Pitágoras, Jenófanes y Hecateo no sabían nada y que Homero y Arquíloco merecían ser derrotados. No fue discípulo de nadie, aunque se dice que lo fue de Jenófanes. Diógenes Laercio relata que cuando Heráclito era niño había dicho que "no sabía nada", pero luego afirmó que "sabía todo".  Odiaba a los atenienses y a sus compañeros efesios, deseando a los últimos riquezas como castigo por sus malos caminos y que se ahorcasen por desterrar a su líder más destacado. Debido a ello, se retiró a los montes a vivir como un ermitaño. Es probable que interviniera en los asuntos de la ciudad en el período en que el gobierno de Persia había dado lugar a la autonomía.

La vida de Heráclito como filósofo fue interrumpida por hidropesía. Los médicos que consultó no pudieron prescribir una cura. Diógenes enumera varias historias sobre la muerte de Heráclito: en dos versiones, Heráclito se curó de la hidropesía y murió de otra enfermedad. Sin embargo, en un relato, el filósofo se enterró en un establo esperando que el calor húmedo del estiércol le sacara el húmedo nocivo, mientras que otro dice que se trató con un linimento de estiércol de vaca y, después de un día propenso al sol, murió y fue enterrado en el mercado. Murió hacia el año 470 a.C. Según Neantes, después de mancharse con estiércol, Heráclito fue devorado por perros.

La obra de Heráclito es completamente aforística. Su estilo remite a las sentencias del oráculo de Delfos y reproduce la realidad ambigua y confusa que explica, usando el oxímoron y la antítesis para dar idea de la misma. Diógenes Laercio (en "Vidas"..., IX 1–3, 6–7, 16) le atribuye un libro titulado "Sobre la naturaleza" ("περὶ φύσεως"), que estaba dividido en tres secciones: «Cosmológica», «Política» y «Teológica». No se posee mayor certeza sobre este libro. Estos se catalogan utilizando el sistema de numeración Diels-Kranz recopilados en la obra "Die Fragmente der Vorsokratiker".

El primer estudioso en proponer un ordenamiento de los fragmentos fue P. Schuster (1873), poniendo a la cabeza de todos el que posteriormente fue dispuesto como B56 (Diels-Kranz) y que refiere la adivinanza que unos niños plantearon a Homero, y que este, «el más sabio de todos los griegos», como lo pinta Heráclito (véase más abajo), no supo resolver. Ingram Bywater en 1877 hizo un reacomodo de los fragmentos conforme a la indicación de Laercio, traducido al español por José Gaos. Es curioso que Bywater no considera importante el fragmento que Schuster pone a la cabeza de todos, y no lo incluye en su propia ordenación. Agustín García Calvo reconstruye la posible estructura del libro en su edición de los fragmentos del mismo, titulada "Razón común". Distingue tres apartados: «Razón general», «Razón política» y «Razón teológica».

Heráclito conocido como «el Oscuro», por su expresión lapidaria y enigmática. Heráclito Sostuvo que el fundamento de todo está en el cambio incesante. El ente deviene y todo se transforma en un proceso de continuo nacimiento y destrucción al que nada escapa. Enrique Hülsz afirmó que "todos los distintos temas que forman el conjunto de la filosofía de Heráclito están recíprocamente contenidos unos en otros".

Es común incluir a Heráclito entre los primeros filósofos físicos ("φυσικοί", como los llamó Aristóteles), que pensaban que el mundo procedía de un principio natural (como el agua para Tales de Mileto, el aire para Anaxímenes y el "ápeiron" para Anaximandro), y este error de clasificación se debe a que, para Heráclito, este principio es el fuego, lo cual no debe leerse en un sentido literal, pues es una metáfora como, a su vez, lo eran para Tales y Anaxímenes. El principio del fuego refiere al movimiento y cambio constante en el que se encuentra el mundo. Esta permanente movilidad se fundamenta en una estructura de contrarios. La contradicción está en el origen de todas las cosas.

La naturaleza está regida por una ley que Heráclito denomina Λόγος ("Logos") con el significado de razón, palabra o discurso en griego. Aunque Heráclito "juega deliberadamente con los diversos significados de "Logos"", no hay ninguna razón convincente para suponer que lo usó en un sentido técnico especial, significativamente diferente de la forma en que se usaba en el griego ordinario de su época.

Este "Logos" no solo rige el devenir del mundo, sino que le "habla" ("indica", "da signos") al hombre, aunque la mayoría de las personas «no sabe escuchar ni hablar». El orden real coincide con el orden de la razón, una «armonía invisible, mejor que la visible» pues la naturaleza le encanta esconderse, aunque Heráclito se lamenta de que la mayoría de las personas sean sordas o dormidas al "Logos", incapaces de ver lo real. Si bien Heráclito cree el uso de los sentidos como indispensables para comprender la realidad, sostiene que con ellos no basta y que es igualmente necesario el uso de la inteligencia, como afirma en el siguiente e importante fragmento:

Este "Logos" se encuentra comúnmente dentro del alma de cada uno y hay posibilidad en todo hombre de despertar escucharlo y volverse sabio. Teólogos durante los siglos han identificado el "Logos" de Heráclito con Dios.

Al uso de los sentidos y de la inteligencia, hay que agregarle una actitud crítica e indagadora. La mera acumulación de saberes no forma al verdadero sabio, porque para Heráclito lo sabio es «uno y una sola cosa», esto es, la teoría de los opuestos, interpretación que muestra su monismo, aunque quizás sea más bien dialéctico. Heráclito recuerda a Laozi en su doctrina de la «unidad de los opuestos».

Según Platón y Aristóteles, Heráclito sostuvo opiniones ilógicas porque las cosas opuestas son idénticas, de modo que todo es y no es al mismo tiempo. "La discordancia, el contraste y la oposición son el mismo principio de concordancia, armonía y unidad de las propias cosas. Aunque, según Oswald Spengler, en Heráclito no puede hablarse de identidad los contrarios, sino de antinomias, en tanto que ningún opuesto puede darse sin el otro."

El conflicto de los opuestos genera una armonía presente en la naturaleza y los asuntos humanos (luz y oscuridad, calor y frío, hombre y mujer...) que dan sentido y riqueza a la existencia. En una metáfora y uno de los primeros usos de una fuerza en la historia de la filosofía, Heráclito compara la unión de los opuestos con un arco o lira ensartada en forma por un equilibrio de la tensión de la cuerda.

La realidad es una y múltiple al mismo tiempo por la esencia de todas las cosas, haciendo que exista una identidad o una idea universal concreta basada en la diferencia.

Heráclito ha pasado a la historia como el modelo de la afirmación del devenir. Su filosofía se basa en la tesis del flujo universal de los seres: «"Panta rei"» (πάντα ρεῖ), todo fluye. El devenir está animado por el conflicto: «La guerra ("pólemos") es el padre de todas las cosas», una contienda que es al mismo tiempo armonía, no en el sentido de una mera relación numérica, como en los pitagóricos, sino en el de un ajuste de fuerzas contrapuestas, como las que mantienen tensa la cuerda de un arco. El fragmento quizás más conocido de su obra dice:

El fragmento (citado con frecuencia erróneamente como "no se puede entrar dos veces en el mismo río", siguiendo la versión que da Platón en el "Crátilo") ejemplifica la doctrina heraclítea del cambio: el río —que no deja de ser el mismo río— ha cambiado sin embargo casi por completo, así como el bañista. Si bien una parte del río fluye y cambia, hay otra (el "cauce", que también debe interpretarse y no tomarse en un sentido literal) que es relativamente permanente y que es la que guía el movimiento del agua. 
A primera vista esto puede parecer contradictorio, pero debe recordarse que Heráclito sostiene que los opuestos no se contradicen sino que forman una unidad armónica (pero no estática). Es razonable, entonces, que la otra cara del agua sea el fuego, como él mismo lo adelanta en sus fragmentos. La historiografía filosófica impuso un Heráclito platonizado con un primitivo empirismo al sostener la evidencia del cambio experimentado por los sentidos. Sin embargo, Heráclito advirtió que la vista da falsedades y los oídos son malos testigos para los hombres que tienen almas bárbaras. El verdadero conocimiento consiste en comprender esta armonía omnipresente tal como se encarna en la variedad de la percepción.

Las doctrinas de Heráclito y Parménides de Elea siempre han sido contrapuestas (con cierto margen de error), ya que la del primero suele ser llamada «del devenir» o (con cierto equívoco) «del todo fluye», mientras que el ser parmenídeo es presentado como una esfera estática e inmóvil. A pesar de sus diferencias, Heráclito describe el "Logos" al igual que Parménides describe "lo que es", divino, eterno e inmutable. Las similitudes tampoco deben tomarse como indicación de influencia directa.

Heráclito ve en el fuego la mejor expresión simbólica de los dos pilares de su filosofía: el devenir perpetuo y la lucha de opuestos, pues el fuego solo se mantiene consumiendo y destruyendo, y constantemente cambia de materia. Algunos autores ven en el ejemplo del río el cauce como el "Logos" que «todo rige», medida universal que ordena el cosmos, y en el agua del río, el fuego. 

Algunos autores como Aristóteles, interpretaron el fuego de Heráclito e Hípaso de Metaponto como el "arché" de la realidad, siendo eterno donde todas las cosas son mutaciones del fuego.

Sin embargo, la lectura monista del fuego es difícil por su doctrina del cambio. El fuego es más un símbolo del cambio. Proporciona un estándar de valor para otras cosas, pero no es idéntico a ellos. Dijo que tanto Dios como el fuego son "querer y excederse". Por "Dios", Heráclito no declaraba la versión cristiana de un solo Dios como "motor inmóvil" de todas las cosas, Dios como Creador, porque el universo es eterno, "siempre fue y será"; pero lo divino se opone a lo humano; lo inmortal frente a lo mortal, lo cíclico frente a lo transitorio. Podría decirse que es más preciso hablar de "lo Divino" y no de "Dios". Hipólito lo ve como una referencia del juicio divino y al infierno. A pesar de su empleo del lenguaje religioso, su visión teológica era bastante panteística. No obstante en algunos fragmentos habla de un Dios personal.

Su actitud hacia las religiones de su tiempo, especialmente a la báquica, era hostil.

El hombre puede descubrir este "Logos" en su propio interior, pues el "Logos" es común e inmanente al hombre y a las cosas (la doctrina de Heráclito fue interpretada, olvidando esta afirmación del "Logos", en la filosofía inmediatamente posterior —sobre todo, en Platón— como una negación de la posibilidad del conocimiento: si nada es estable, se niega la posibilidad de un saber definitivo). Sin embargo:Su desprecio a los hombres le llevó a pensar que solamente la fuerza obligará a los hombres a obrar en su propio bien. Decía que «a todo animal hay que llevarlo al pasto con golpes», y «los burros prefieren la paja al oro». Heráclito afirma que la guerra es algo bueno, común para todos, ya que la lucha es justicia.

Heráclito no era democrático, ya que no cree en la opinión de la mayoría para guiar a un pueblo porque la mayoría es mala y pocos son buenos. Por ejemplo, refiriéndose a Pitágoras, opinó que hizo pasar por sabiduría lo que no era erudición sino arte de engañar. Solamente estimaba a Bías, a quien "cuyo nombre es más respetable que el de los otros".

Heráclito distingue entre las leyes humanas y la ley divina. Él se manifiesta contra el derecho consuetudinario tradicional en contraposición con la ley dada por el Estado. Sin embargo, elimina el sentido humano de la justicia de su concepto de Dios, pues para Dios todas las cosas son justas, buenas y justas. La ley es obedecer el plan de un solo hombre, y las leyes humanas están alimentadas por la ley divina (el logos) que los hombres deben defender. La verdadera virtud consiste en la subordinación del individuo a las leyes de la armonía del Logos, donde se encuentra la verdadera libertad. 

Su ética es un ascetismo orgulloso, parecido al de Nietzsche. Un hombre vale mil si conoce el "Logos". La virtud es ser moderado y la sabiduría es conocer y obrar según la naturaleza. Heráclito consideró que el alma humana era una mezcla de fuego (noble) y agua (innoble). Se puede interpretar que Heráclito apreciaba más el autodominio, y desprecia las placeres que distraen al hombre. El placer es frío y húmedo. Esto se puede ver en borrachos.

Lo que pase con estas almas secas, es bueno. Pensar bien es la mayor excelencia y la sabiduría es actuar y hablar lo que es verdadero, percibiendo las cosas según su naturaleza. La doctrina de la inmortalidad del alma se destaca prominentemente en su ética. También se ha interpretado que Heráclito aboga por un relativismo moral:

La primera cita del uso más temprano de "kosmos" en cualquier texto griego existente viene de Heráclito. Para Heráclito el universo es finito y el mundo es único. Describió la bóveda celeste como un cuenco boca abajo que forma llamas, siendo éstas los astros. Señaló que el Sol es la llama más clara y cálida encontrándose muy alejado de nosotros, y la Luna más cerca. Con esto explicó los eclipses solares y fenómenos meteorológicos.

Él llamó a todo el cosmos "un fuego eterno". Heráclito se refiere al avance del fuego con el fenómeno de la ekpyrosis, donde todo se destruye y en el fuego. Este proceso define claramente el destino del Universo que nace del fuego y luego perece en el fuego. A este proceso de “extinción” lo llama el “camino hacia abajo”. Ahora bien, el devenir no es irracional, ya que el "Logos", la razón universal, lo rige: «Todo surge conforme a medida y conforme a medida se extingue». Es el “camino hacia arriba”.

Heráclito fue un hilozoísta. Se le atribuye la doctrina cosmológica del eterno retorno. También parece abogar por la reencarnación tras la muerte.

He aquí algunas frases de Heráclito:

La contraposición del ""panta rei"" tuvo una influencia determinante sobre Platón, el cual con el fin de resolver las contradicciones con la teoría del ser de Parménides, contemporáneo de Heráclito, quien crítico suyo que concluyó que el "no-ser" existe sólo en sentido relativo, dando así un fundamento filosófico al sentido griego del devenir. Bajo la influencia del heraclitismo de Crátilo, Platón llegó a la conclusión de que las definiciones socráticas, los universales, no corresponden a las cosas sensibles y por ello introdujo las "Formas". Esta concepción de la Razón universal, ordenadora de todo, aparece en el sistema de los estoicos, que tomaron de Heráclito su cosmología.

La doctrina del Logos como razón universal es similar a la doctrina del Tao y fue adoptada por los estoicos. Hipólito lo interpreta con el Evangelio de Juan:

El mismo Hegel se consideraba filosóficamente heredero de Heráclito, hasta el punto de afirmar: «No hay proposición de Heráclito que yo no haya aceptado en mi Lógica» (Hegel, "Lecciones sobre la historia del la filosofía"). Heráclito, pero, a diferencia de Hegel, no concebía el devenir como una progresiva toma de conciencia de lo absoluto; para él, el devenir parece consistir más bien en los cambios de un idéntico sustrato o "Logos": «todas las cosas son Uno y el Uno todas las cosas»; «Este cosmos es el mismo para todos ... pues siempre es y será». De esta visión del mundo, se vería influido especialmente el estoicismo. Friedrich Engels, que se asoció con los Jóvenes Hegelianos, también le dio a Heráclito el crédito por inventar dialéctica, relevante para su propio materialismo dialéctico. El mismo Vladimir Lenin reafirmó lo anterior.

Más adelante, la tradición filosófica aristotélica valoraría Heráclito incompatible con los principios de la lógica formal, si bien el mismo Aristóteles (como antes Platón) no había acogido la teoría del devenir en un intento de conciliar con el rígido estatismo de Parménides e introduciendo así la doctrina de la transición perpetua de la potencia al acto, que encontraría mejor acogida entre los místicos neoplatónicos. De acuerdo con Plotino, que también mantenía los principios de la lógica del eleática , «Heráclito sabía que el Uno es eterno y espiritual: ya que sólo lo que tiene cuerpo convierte eterno y fluye» ( "Enéadas" , V, 9).

El filósofo existencialista Søren Kierkegaard escribió de él:

También Nietzsche tenía una alta estima por Heráclito. Martin Heidegger , quien a finales de los sesenta tenía un famoso seminario sobre el filósofo griego junto con Eugen Fink a Friburgo , considera que el concepto de verdad, entendida como ἀλήθεια, o "no escondido" (en alemán "Unverborgenheit" ) es una especie de paráfrasis del fragmento del texto de Heráclito n. 93 DK: "El señor, el oráculo está en Delfos, no dice ni oculta, sino que indica". Para Heidegger, la filosofía de Heráclito sirve de confirmación de su posición. La ilustración de John McTaggart de las teorías o series A y B del tiempo se ha visto como una aplicación análoga al tiempo de las vistas de Heráclito y Parménides respectivamente.

Recientemente en 2015, el comic "The Cartoon Introduction To Philosophy" (Filosofía en viñetas) de Michael F. Patton y Kevin Cannon, presenta un risueño Heráclito como anfitrión del libro, en el cual recorre el "río de la filosofía" junto con varios filósofos, desde Tales hasta David Chalmers.










</doc>
<doc id="1431" url="https://es.wikipedia.org/wiki?curid=1431" title="Híbrido">
Híbrido

El término híbrido, palabra proveniente del Latín "hybrida" ("mestizo"), que posee características de distintas naturalezas. puede tener un parecido con:



</doc>
<doc id="1434" url="https://es.wikipedia.org/wiki?curid=1434" title="Hierochloë">
Hierochloë

Hierochloe, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario de las regiones templadas y frías del mundo. Comprende 92 especies descritas y de estas, solo 35 aceptadas.

Probablemente se puede incluir en el género "Anthoxanthum" 
Son plantas perennes, cespitosas o rizomatosas, comúnmente con olor a cumarina. Lígula una membrana; láminas lineares, aplanadas a convolutas. Inflorescencia una panícula espiciforme o laxa, terminal. Espiguillas comprimidas lateralmente, subsésiles o cortamente pediceladas; flósculos 3, caedizos como una unidad; desarticulación solamente arriba de las glumas; glumas alargadas, subiguales, membranáceas, carinadas, la inferior 1-nervia, la superior 3-nervia; flósculos inferiores 2, estériles o estaminados, pardos, ciliados, vacíos y sin una pálea o con 2-3 estambres y una pálea, las lemas subiguales, 3-5-nervias, la primera lema con una arista corta recta, la segunda lema con una arista geniculada torcida insertada dorsalmente en el 1/2 inferior; flósculo terminal mucho más corto que los estériles, bisexual o pistilado, la lema papirácea, sin arista, 3-5-nervia, la pálea 1-2-carinada, las lodículas 2, con 2 estambres, el ovario glabro, los estilos 2, separados, exertos apicalmente. Fruto una cariopsis, no adherido a la pálea; hilo cortamente linear. 
El género fue descrito por Robert Brown R.Br. y publicado en "Prodromus Florae Novae Hollandiae" 208. 1810. La especie tipo es: "Hierochloe odorata" 
Hierochloe nombre genérico que deriva del griego "hieros" (sagrada) y "chloë" (hierba), aludiendo a "("H. odorata") que se sembraba delante de las puertas de las iglesias en los días festivos ".

El número cromosómico básico es x = 7, con números cromosómicos somáticos de 2n = 14, 28, 42, 56, 64, 66, 68, 71, and 72, or 74–78. Hay especies diploides y una serie poliploide. Cromosomas relativamente «grandes».





</doc>
<doc id="1435" url="https://es.wikipedia.org/wiki?curid=1435" title="Hilaria">
Hilaria

Hilaria, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario del suroeste de EE. UU. y México a Venezuela.
Son plantas perennes, estoloníferas o rizomatosas. Con vainas redondeadas; la lígula una membrana ciliada o erosa; láminas lineares. Inflorescencia una espiga; espiguillas dimorfas, en fascículos sésiles o subsésiles, los fascículos desarticulándose como una unidad consistente de 1 espiguilla central y 2 laterales; callo obtuso. Espiguillas centrales sésiles, lateralmente comprimidas, casi ocultas por las espiguillas laterales; glumas 1-7-nervias, más cortas que los flósculos, papiráceas a coriáceas, asimétricas, basalmente connatas o libres, 2-lobadas a truncadas o agudas, con 0-2 aristas desde el seno y a veces desde el dorso; flósculos 1(2), el inferior bisexual o pistilado, el superior estaminado o estéril cuando presente; lema membranácea, a veces atenuándose en un cuello largo y angosto, 2-fida o 2-lobada, aristada o sin aristas; pálea casi tan larga como la lema, 2-nervia; lodículas 2, rudimentarias; estambres 3; estigmas 2, plumosos, exertos terminalmente; fruto una cariopsis, el embrión 9/ 10 la longitud de la cariopsis, el hilo punteado. Espiguillas laterales subsésiles, comprimidas lateralmente; glumas más cortas a más largas que los flósculos, asimétricas, flabeladas, papiráceas o coriáceas y connatas en la base, 3-7-nervias, la punta aguda o lobada, con 0-6 aristas desde el seno o el dorso; flósculos 1-5, estaminados o estériles; lema membranácea, aguda a 2-lobada, 3-nervia; pálea casi tan larga como la lema, membranácea; lodículas 2; estambres 3.
El género fue descrito por Carl Sigismund Kunth y publicado en "Nova Genera et Species Plantarum (quarto ed.)" 1: 116–117, pl. 37. 1815[1816]. La especie tipo es: "Hilaria cenchroides" 
El género fue nombrado en honor de Augustin Saint-Hilaire. 
El número cromosómico básico es x = 9, con números cromosómicos somáticos de 2n = 36, 72, 86, 90 y 120. Hay especies diploides y una serie poliploide. Nucléolos persistentes. 





</doc>
<doc id="1438" url="https://es.wikipedia.org/wiki?curid=1438" title="Hefesto">
Hefesto

En la mitología griega, Hefesto (en griego Ἥφαιστος "Hêphaistos", quizá de φαίνω "phainô", ‘brillar’) es el dios del fuego y la forja, así como de los herreros, los artesanos, los escultores, los metales y la metalurgia. Era adorado en todos los centros industriales y manufactureros de Grecia, especialmente en Atenas. Su equivalente aproximado en la mitología romana era Vulcano, en la japonesa Kagutsuchi, en la egipcia Ptah y en la hindú Agni.

Hefesto era bastante feo, estaba lisiado y cojo; aunque su esposa era Afrodita. Incluso el mito dice que, al nacer, Hera lo vio tan feo que lo tiró del Olimpo y le provocó una cojera. Tanto es así, que caminaba con la ayuda de un bastón y, en algunas vasijas pintadas, sus pies aparecen a veces al revés. 

En el arte, se le representa cojo, sudoroso, con la barba desaliñada y el pecho descubierto, inclinado sobre su yunque, a menudo trabajando en su fragua. 

La apariencia física de Hefesto indica arsenicosis, es decir, envenenamiento crónico por arsénico que provoca cojera y cáncer de piel. El arsénico se añadía al bronce para endurecerlo y la mayoría de los herreros de la Edad de Bronce habrían padecido esta enfermedad.

Hefesto era hijo de Hera, junto a Zeus. En la "Teogonía" de Hesíodo, Hera lo concibió sola, celosa porque Zeus había dado a luz a Atenea, que le había brotado de la cabeza. En la "Ilíada", se afirma que Zeus fue padre de Hefesto.

La tensión entre ambas versiones era tal que aunque en una y en otra se narra que Atenea terminó naciendo de Zeus, en la que Hefesto era anterior se decía que había sido él quien había abierto la cabeza del padre para liberar a la hermana, mientras que en la otra versión se sostenía que había sido Prometeo.

De cualquier forma, en el pensamiento griego los destinos de Atenea, diosa de la sabiduría y la guerra, y Hefesto, dios de la forja que fabricaba las armas de la guerra, estaban relacionados. Hefesto y Atenea Ergane (como patrona de los artesanos) se honraban en una fiesta llamada Calqueas en el trigésimo día del mes Pianepsio. Hefesto también fabricó muchos de los pertrechos de Atenea.
Hera, mortificada por haber alumbrado tan grotesca descendencia, no tardó en arrojarlo del Olimpo. Hefesto cayó durante nueve días y nueve noches hasta el mar, donde, como cuenta su mismo personaje en la "Ilíada", dos diosas del mar, la nereida Tetis (madre de Aquiles) y la oceánide Eurínome, lo recogieron y lo cuidaron en la isla de Lemnos, y allí creció hasta convertirse en un maestro artesano.

Otras versiones afirman que fue su padre Zeus quien lo arrojó a causa de una conspiración de Hera y Hefesto para derrocarlo, y en la "Ilíada" se narra que fue porque liberó a su madre, que estaba presa con una cadena de oro entre la tierra y el cielo tras una pelea con Zeus. Hefesto cayó en la isla de Lemnos, y quedó lisiado con cojera.

Tras haber fabricado tronos de oro para Zeus y otros dioses, Hefesto se vengó elaborando uno mágico de oro que envió como regalo a Hera. Cuando esta se sentó en él, quedó atrapada, incapaz de levantarse. Los demás dioses rogaron a Hefesto que volviese al Olimpo y la liberase, pero él se negó, enfadado aún por haber sido expulsado. Intervino entonces Dioniso, quien emborrachó a Hefesto y lo llevó de vuelta al Olimpo a lomos de una mula. Hefesto, contrariado por la treta y dueño de la situación, impuso severas condiciones para liberar a Hera, una de las cuales fue a contraer matrimonio con Afrodita.

En el panteón olímpico, Hefesto estaba formalmente casado con Afrodita, a quien nadie podía poseer. Hefesto estaba contentísimo de haberse unido con la misma diosa de la hermosura y forjó para ella magnífica joyería, entre ella un cinturón que la hacía más irresistible aun para los hombres. Afrodita fue entregada a Hefesto por Zeus como agradecimiento por haberlo ayudado en el nacimiento de Atenea, puesto que Zeus tenía un fuerte dolor de cabeza tras haberse tragado a la embarazada oceánide Metis y Hefesto lo ayudó a extraerla. También, hay que recordar que algunas versiones mitológicas indican a Zeus como padre de Afrodita.

Sin embargo, Afrodita se entregaba en secreto a Ares, el dios de la guerra, según se narra en la "Odisea". Cuando Hefesto tuvo noticia de estos amores por medio de Helios, el sol, que todo lo ve, tejió una red de oro irrompible casi invisible con la que atrapó en la cama a los amantes en uno de sus encuentros. Hesíodo cuenta que el suceso fue motivo de gran algarabía en el Olimpo, pues Hefesto llamó a todos los demás dioses olímpicos para que se burlaran de la pareja de amantes. Hermes, el Argifonte, el mensajero de los dioses comentó que no le habría importado sentir tal vergüenza. Hefesto no quiso liberarlos hasta que prometieran terminar su romance, y así lo hicieron, pero escaparon ambos tan pronto como levantó la red Hefesto, y no mantuvieron su promesa.

Según algunos autores, su desgraciado matrimonio con Afrodita fue lo que le impulsó a asaltar a Atenea cuando esta acudió a él por nuevas armas.

Prometeo había creado al ser humano a semejanza de los dioses, pero tardó tanto que no le quedó con qué protegerlo. Apiadándose de su indefensa creación, robó el fuego del Olimpo para que la humanidad pudiera calentarse. Según algunas versiones, Prometeo robó el fuego del carro de Helios (en la mitología posterior, de Apolo) o de la forja de Hefesto. En otras (notablemente, el "Protágoras" de Platón), Prometeo robaba las artes de Hefesto y Atenea, llevándose también el fuego porque sin él no servían para nada. Obtuvo así el hombre los medios con los que ganarse la vida.

Para aplacar la furia de Zeus, Prometeo dijo a los humanos que quemasen ofrendas a los dioses, pero entonces le engañó de nuevo dándole los huesos y tendones del sacrificio en lugar de la carne. Para vengarse, Zeus ordenó a Hefesto que hiciese una mujer de arcilla, a la que llamó Pandora. Zeus le infundió vida y la envió a Prometeo, junto al ánfora que contenía todas las desgracias con las que quería castigar a la humanidad. Prometeo sospechó y no quiso tener nada que ver con Pandora, por lo que fue enviada con Epimeteo, quien la desposó. Pandora terminaría abriendo la caja a pesar de las advertencias de su marido.

Zeus se enfureció al ver cómo Prometeo se libraba de Pandora, e hizo que lo llevaran al monte Cáucaso, donde fue encadenado por Hefesto con la ayuda de Bía y Cratos. Envió entonces un águila para que se comiera el hígado de Prometeo. Al ser inmortal, el hígado volvía a regenerarse cada día, y el águila volvía a comérselo cada noche.

Este castigo había de durar para siempre, pero Heracles pasó por el lugar de cautiverio de Prometeo de camino al jardín de las Hespérides y lo liberó disparando una flecha al águila. Prometeo fue así liberado, aunque debía llevar con él un anillo unido a un trozo de la roca a la que fue encadenado.

Según la "Ilíada", la forja de Hefesto estaba en el monte Olimpo. Pero lo habitual era situarla en el corazón volcánico de la isla egea de Lemnos. Hefesto era identificado por los griegos con los dioses-volcanes del sur de Italia Adranos y Vulcano. Escritores clásicos posteriores siguieron esta idea describiendo una forja del dios en las islas volcánicas de Lipari, cerca de Sicilia. Los colonizadores griegos de esta isla terminarían asociando la fragua de Hefesto con el Etna.

Hefesto fabricó muchos de los accesorios que lucían los dioses, y se le atribuye la forja de casi todos los objetos metálicos con poderes finamente trabajados que aparecen en la mitología griega: el casco y las sandalias aladas de Hermes, la égida de Zeus, el famoso cinturón de Afrodita, la armadura de Aquiles, las castañuelas de bronce de Heracles, el carro de Helios, el hombro de Pélope, el arco y las flechas de Eros, el casco de invisibilidad de Hades, el collar que regaló a Harmonía y el cetro de Agamenón. Asimismo era el forjador de los rayos de Zeus.

Hefesto también creó diversas criaturas:



Hefesto trabajaba ayudado por:


A pesar de estar casado con Afrodita, Hefesto no tuvo descendencia con ella, salvo que Virgilio hablase en serio cuando afirmaba que Eros era su hijo.

En la "Ilíada", la consorte de Hefesto es llamada Caris. Hesíodo afirmaba que era la más joven de las tres Cárites: Aglaya, ‘la gloriosa’. Según la tradición órfica, fueron padres de:


Según Apolodoro, Hefesto intentó violar a Atenea pero no lo logró. Su semen cayó al suelo, y así Gea engendró a Erictonio, uno de los reyes de Atenas. Atenea crio entonces al bebé como una madre adoptiva. Alternativamente, el semen cayó en la pierna de Atenea, y esta lo limpió con un trozo de lana que tiró al suelo, surgiendo entonces Erictonio de la tierra y la lana. Otra versión dice que Hefesto quería que Atenea se casase con él, pero que desapareció en el lecho nupcial, y Hefesto terminó eyaculando en el suelo.

Higino propuso una etimología, según la cual "Erictonio" procede del ‘conflicto’ ("Eri-") entre Atenea y Hefesto, y ‘de la Tierra’ ("-ctonio"). Algunos autores sugieren que una Atenea más antigua y menos virginal se oculta tras esta retorcida reelaboración del mito.

En cualquier caso, hay un Templo de Hefesto (llamado «Hefesteo» o también «Teseo») situado a los pies de la Acrópolis, cerca del ágora de la ciudad.

Se decía que Erictonio creó los carros para ocultar la deformidad de las piernas de Hefesto.

A veces se consideraba a Hefesto padre con Etna de los Palicos, los daimones ctónicos de los géiseres y los manantiales de aguas termales de la región de Palacia (Sicilia).

Hefesto estaba de algún modo conectado con la arcaica religión mistérica frigia y tracia de los Cabiros, que eran llamados los "Hephaistoi" (‘hombres de Hefesto’) en Lemnos. Estos, hijos de Hefesto con la ninfa Cabiro, eran "daimones" que moraban en la isla de Samotracia (mar Egeo) junto con sus hermanas, las ninfas Cabírides.

También se cuenta entre su descendencia a Talía, la ninfa siciliana a la que amó Zeus.

Hefesto fue también padre de los siguientes mortales:


Higino nombra también a Filoto ("Philottus") y Espínter ("Spinther") entre los hijos de Hefesto, sin dar más detalles.









</doc>
<doc id="1440" url="https://es.wikipedia.org/wiki?curid=1440" title="Heráldica">
Heráldica

La heráldica es la ciencia del blasón. Según la RAE, "blasón" se define como el «arte de explicar y describir los escudos de armas de cada linaje, ciudad o persona». Es también un campo de expresión artística, un elemento del derecho medieval y de las dinastías reales hasta nuestros días. Más recientemente, ha sido admitida dentro de las ciencias anexas de la historia junto con la diplomática, la falerística, la sigilografía y la vexilología.

Se desarrolló durante la Edad Media en toda Europa hasta convertirse en un código coherente de identificación de personas, progresivamente incorporado por estamentos de la sociedad feudal como la nobleza y la Iglesia católica para la identificación de linajes y miembros de la jerarquía, siendo igualmente adoptado por otros colectivos humanos, como gremios y asociaciones, además de ser adoptado para la identificación de ciudades, villas y territorios. Lo equivalente en la cultura japonesa es el Kamon.

Siguiendo a Alberto Montaner Frutos, la heráldica es un sistema de comunicación que forma parte del sistema de la emblemática y está formado por signos constituidos por armerías o escudos de armas. Estas armerías están conformadas por cuatro conjuntos de elementos o «repertorios paradigmáticos»:

1) El campo, normalmente limitado por la representación de un escudo, aunque no siempre, que solo excepcionalmente posee valor distintivo.

2) Las particiones del campo, que delimitan zonas en su interior

3) Las señales, también denominadas muebles, que pueden ser figuras geométricas u objetos.

4) Los esmaltes, o colores heráldicos, que se dividen en metales: oro y plata; y colores: gules, azur, sable, sinople y púrpura.

A partir del siglo XIV aparece un quinto repertorio paradigmático, el de los ornamentos exteriores al campo. Pueden situarse encima del escudo (timbre), que tiene como formas básicas la corona y el yelmo, este último con o sin cimera; a sus lados, sosteniéndolo (soportes o tenantes); rodeándolo (collares, cintas, cordones...) o enmarcándolo (mantos y pabellones).

Estos elementos paradigmáticos se seleccionan para formar signos sintagmáticos según ciertos principios, como el que prescribe que no se utilice en el campo y las señales esmaltes del mismo grupo (colores y metales), sino combinar metal y color.

Blasón es una palabra de origen oscuro, puede ser que venga de alguna lengua franconia de la palabra "blâsjan" (antorcha encendida, gloria), o más probablemente del latín "blasus" significando ‘arma de guerra’. “Blasonar” significa "describir" las armerías siguiendo las reglas de la ciencia heráldica. En un estricto sentido, el blasón es, entonces, un enunciado que puede ser oral o escrito. Es la descripción de las armerías hecha en un lenguaje técnico, el lenguaje heráldico. El blasonamiento es la acción que consiste en describir las armerías (y por tanto de enunciar el blasón que representa). La ciencia del blasón es muy antigua, se funda menos de un siglo después que se estableciera el uso de armerías en la Edad Media. En esgrima, los blasones (amarillo, rojo, azul...) son exámenes que permiten probar un nivel de técnica adquirida, de arbitrar o de participar en ciertas competencias. Algunos son distribuidos igualmente después de una victoria. Se expresan en una pieza de tela (cuyo color cambia siguiendo el nivel) en el codo o añadida al hombro desarmado.

Las definiciones siguientes son precisas, aunque está lejos de reflejar su uso real. En la práctica los términos “blasón”, “armas”, “escudo” y “armerías” funcionan como sinónimos y son intercambiables, tanto en las obras comunes como en las de los estudiosos de la heráldica.





La heráldica es lo relativo al lenguaje del blasón, a la ciencia de los heraldos y al diseño de las armerías. Más específicamente, es la disciplina que tiene por objeto el conocimiento y el estudio de las armerías. La heráldica cubre cuatro disciplinas conexas:





El uso de las armerías viene de la evolución del equipo militar entre los siglos XI y XII, que hicieron prácticamente imposible el reconocimiento del rostro de un caballero. El casco de los caballeros (que figura todavía en los ornamentos exteriores) cubría progresivamente la cara: la nariz está protegida por un nasal, la cota de malla (que protege la cabeza y el cuello) tiende a cubrir la parte baja del rostro y está definitivamente cerrado por una visera móvil.

Para hacerse reconocer en las batallas y los torneos, los caballeros comienzan a pintar figuras distintivas sobre sus escudos (muebles y piezas o figuras geométricas).

El escudero es un gentil hombre que acompaña a un caballero y carga su escudo. A partir del momento en el que el escudo porta las figuras distintivas, el escudero que porta el escudo puede representar al caballero, aun en su ausencia. El escudero es probablemente el origen de la representación de los tenantes en los ornamentos exteriores.

Las cinco regiones principales del escudo (jefe, corazón, flancos diestro y siniestro, punta) se refieren a partes del cuerpo del escudero que porta el blasón en el pecho y se presenta de frente. Como el escudero está visto de frente, “diestra” y “siniestra” están invertidos en heráldica en cuanto a su significación usual: la diestra del escudero es la izquierda del observador y viceversa.

La razón de ser de un caballero es librar batallas. La batalla le permite probar su valentía a través de sus encuentros y los rescates recolectados sobre los vencidos aumentaban sus bienes materiales.

En un comienzo no hay gran diferencia entre el desarrollo de una batalla y el de un torneo. En los dos casos se trata de una gran trifulca armada organizada en un campo de batalla entre dos bandos, donde los participantes respetan ciertas reglas. La diferencia es en el entorno de la confrontación.




La batalla de Crécy es la primera gran batalla donde la “regla del juego” no fue respetada: las tropas inglesas libraron una batalla no para obtener gloria y rescates, sino para neutralizar a las tropas francesas (y lo lograron). Los franceses protestaron que los ingleses no hubieran respetado las reglas del juego (pérfidamente, de ahí la locución "pérfida Albión") aplicada a Inglaterra, pero esas reglas simplemente habían cambiado ya. A partir entonces los géneros se separan. Los torneos se desarrollan en campos cerrados y las batallas se convierten cada vez más en un asunto de mercenarios y soldados, no de caballeros.

Para los grandes señores, el rol del escudero tomó progresivamente una dimensión diplomática y se especializó en la función del heraldo. Desarmados, sin valor de rescate, se benefician de inmunidad diplomática de facto, y pueden desplazarse libremente para asegurar su misión, incluyendo los campos y países enemigos. Son sujetos, en consecuencia, de una imparcialidad y discreción estrictas. La actividad de los heraldos se rige por todo un código de derechos y obligaciones.

Los heraldos de armas portan una túnica, el tabardo, que los hace inmediatamente identificables. Es una túnica densa y desciende hasta las rodillas, armada de las armas de su señor por adelante, detrás y en las mangas. Es una vestimenta que indica que su portador se beneficia de los privilegios de inmunidad de los heraldos. El tabardo transforma al heraldo en un símbolo viviente de las armas y del honor de su señor.

En la Edad Media, el heraldo se vuelve un servidor público al servicio de un príncipe o un señor. En el desarrollo de la guerra, está encargado de llevar la declaración de guerra, las advertencias. Para los caballeros que participan en una refriega (sea en batalla o en torneo), puede recibir testamentos o depósitos sagrados y se asegura de los dignos servicios funerales en caso de ser necesario. Su papel se completa finalmente sobre todo lo que respecta al honor: reconoce las armas de los nobles y vigila los blasones, preside las ceremonias y los juegos, y es testigo de actos de valor.

Aunque menos conocidas, también podemos encontrar en esta época heraldas. Tenían las mismas ocupaciones que los heraldos. Las más destacadas fueron Escolástica de Muñón y Cesarea Taberné.

En los torneos y las justas, los heraldos anunciaban al caballero mencionando su blasón, es decir la descripción de las figuras cubriendo su escudo, antes de nombrar a su titular. Esta práctica es el origen del lenguaje heráldico, en un origen natural y comprensible para todo el público. Es esta práctica la que funda y establece la heráldica.


A partir del siglo XIV, los heraldos se convierten en especialistas de la heráldica, o la ciencia de las armerías y blasones. Son ellos quienes codifican la composición y la descripción formulando, notablemente, las reglas del blasón, viajando y estableciendo armerías para pintar y retener las que encontraban.

El rey de armas es aquel que está designado para juzgar las armerías (y los títulos de nobleza).

Las figuras pintadas en el escudo, establecidas y enunciadas por los heraldos, dan origen a la heráldica. La heráldica es esencialmente la ciencia de los heraldos, y su origen no puede comprenderse sino a través de su rol.

El primer elemento que fue armado, con un objetivo militar, fue el escudo del caballero. Después estos elementos fueron retomados en todo su equipo, para permitir reconocer al titular (en los lados de sus armas) pero también para representar (estandarte) o marcar su propiedad (cascos y armaduras de caballos)...

Este vínculo entre las armas y su titular fue retomado en la composición de los sellos. Las armerías fueron así transformadas en la imagen de la personalidad jurídica. La práctica de sellos armados se extendió hasta ser de uso común de todas las entidades capaces de tener un sello. Esta práctica aún está viva en el uso de los anillos armados, los cuales están, en principio, destinados a servir de sello —es por lo que están grabados de manera cóncava y normalmente usados en el dedo meñique—.

En un principio reservadas a los jefes de guerra que las portaban en sus escudos (fin del s. XI), el uso de armerías se extendió progresivamente a los caballeros y después a la nobleza (s. XII). A través de la identificación de la persona por las armerías, notablemente en los sellos, el uso se extendió a las mujeres y a los nobles prelados (fin del s. XII). y de los prelados a los burgueses, artesanos y jueces, capítulos, corporaciones, comunidades urbanas (principios del s. XIII), comunidades eclesiásticas y órdenes religiosas (s. XIV), señoríos, dominios, provincias, universidades y administraciones civiles... Transformadas en un signo de identidad social, las armas se vuelven hereditarias y designan a casas, es decir a las familias y vínculos de parentesco (s. XV), después, y más generalmente, a vínculos sociales, que son cada vez más representados.

Hasta el siglo XVI, las figuras empleadas eran principalmente figuras animales, en número bastante restringido (una quincena de uso corriente), así como algunos muebles inanimados (varias veces abstractos), y sobre todo figuras geométricas. Sin embargo, el repertorio se engrandece con objetos, armas, partes del cuerpo, edificios, etcétera.

Armar un objeto le agregaba un elemento decorativo y afirmaba un vínculo con el titular, legible y comprensible por aquellos que no sabían leer. Las armerías se encontraban así en todos los testimonios del pasado: documentos, libros, tapicerías, monumentos, placas de chimeneas, muebles, joyas, vehículos... La identificación de las armerías (cuando no son fantásticas) permiten reemplazar su soporte en el tiempo y el espacio social, y de retrasar parte de la historia del origen geográfico. La identificación del titular es facilitada por los ornamentos exteriores, notablemente las órdenes de caballería representadas. Estos pueden conducir a una gran precisión (incluyendo el año de creación), cuando esta ha modificado frecuentemente la composición de sus armas y la conjunción de armas sobre un mismo soporte puede conducir a conclusiones incluso más precisas.

La composición de un blasón representó gráficamente la situación de un titular conforme a un cierto orden social, entre los siglos XIII y XIX. El estudio del blasón supone entonces un cierto conocimiento de la sociedad y de su organización en nobleza, rangos, órdenes y costumbres.

Sin embargo, tener armerías nunca ha sido, desde el punto de vista histórico, un privilegio de una clase noble.

Las armas no son nobles por naturaleza, en un inicio no son más que la insignia del titular. Es la obligación de este titular “ennoblecerlas”, es decir manifestar su nobleza por sus actos, otorgándoles honor y gloria a sus armas. El reconocimiento social oficial de este carácter noble, o “ennoblecimiento”, no viene a reconocer sino una nobleza que ya ha sido adquirida previamente.

El noble es esencialmente el “jefe” de algo, es quien tiene gloria y honor. El medio para acceder puede ser por las armas, por violencia o usurpación, por herencia de posesiones o siendo el titular de un cargo... En esta lógica, el ejercicio eficaz y durable del poder es su propia legitimación y solo el resultado cuenta en el largo plazo. Una persona es reconocida como noble cuando ocupa una situación de mando o responsabilidad por un tiempo prolongado, al punto de identificarla con esa persona social. Las armas representan a la vez a la persona, su poder actual y la gloria acumulada por muchas generaciones.

El éxito atrae más éxito, incluido a los miembros de su familia, y una casa “noble” tiende a mantenerse así. La dirección de unas tierras o de un territorio es generalmente hereditaria y no es siempre posible distinguir las armas de una tierra de aquellas de la casa que la dirige. En cambio, un cargo es generalmente personal, aunque está más a voluntad que figure en los ornamentos exteriores que en las armas propiamente dichas.

Las armas más famosas son el signo de una propiedad colectiva con las que se debe o desea relacionar. La relación se traduce en retomar las armas integralmente (en caso del jefe de la rama), con una brisura o en una composición. Esta relación se obtiene por derecho (título, herencia y rama), por adquisición (dominios poseídos) o por privilegio adquirido o concedido. Es un honor el portar armas famosas y este honor obliga en principio al titular a contribuir a la gloria de esas armas. Es eso lo que se expresa en la frase “Nobleza obligada”: portar armas nobles significa simplemente que se es de una rama noble pero no dice nada más sobre su propio carácter.

El titular de un blasón es la “persona” que designa ese blasón. Las armas le pertenecen a un cierto titular, del cual se representan los atributos por los adornos exteriores. Es el conjunto de esta relación lo que representan las armerías. El titular puede ser de cualquier tipo (individuo, familia, colectividad o institución).

La composición de armas nuevas traduce lo que el titular poner por delante en relación a un tejido de vínculos y de derechos sociales: simbólica primitiva, pero también pertenencia a una rama (por las armas de la familia), afirmación de su genealogía (por composición de las armas de sus padres, abuelos), matrimonio (por composición de las armas del cónyuge), dominios sobre los cuales se tienen derechos reales o supuestos, actuales o pasados. Las armas de las ciudades o instituciones se componen con aquellas de su fundador o señor.

Las armas, propiamente dicho, son generalmente invariables pero los adornos exteriores dependen generalmente del titular: sus títulos, dignidades y cualidades, su función o su condición social.

Las órdenes de caballería nacen con las cruzadas, alrededor de órdenes religiosas con vocación militar (Orden del Temple, Orden del Santo Sepulcro, Orden de los Hospitalarios...). Como todas las órdenes monásticas, esas órdenes pueden asociar a no-religiosos: la pertenencia a una orden manifiesta su asociación con una cierta vocación (varia de acuerdo a la orden) y el prestigio de la orden descansa sobre el miembro asociado. Al término de la Edad Media, las órdenes de corte sin vocación religiosa fueron creadas, la más prestigiosa siendo la orden del Toisón de Oro.

Las órdenes pueden ser soberanas (por ejemplo, la Orden de Malta). Lo más frecuente es que estaban unidas al país o a la casa dinástica que la ha creado.

Las insignias de la orden de caballería fueron generalmente parte de los ornamentos exteriores de las armerías. Ciertas órdenes se inscribían, dependiendo del jefe, en el escudo del titular. Lo más usual es que se añadiera un collar de la orden alrededor del escudo. Cuando el titular era miembro de muchas órdenes, la orden más prestigiosa se situaba en el exterior.

La admisión a una orden era el objeto de un acto oficial y registrado, es por ello que la representación de un collar de la orden en las armerías permiten identificar al titular más precisamente que simplemente enunciando las armas familiares.

En Francia, las órdenes de caballería nacionales (Saint-Michel, Saint-Esprit...) fueron suprimidas por la Asamblea Constituyente, al mismo tiempo que los atributos de la nobleza. Napoleón creó la orden nacional de la Legión de Honor y la Orden Nacional del Mérito fue creada en el Siglo XX.

En Francia, la Asamblea Constituyente decreta el 19 de junio de 1790 la supresión de la nobleza (como estatuto de la persona) y de sus atributos reales o supuestos: títulos de dominio, privilegios, órdenes de caballería, armerías y libertades. Prohibidas por un tiempo, las armerías fueron restauradas al principio del s. XIX por Napoleón por decreto el 1 de marzo de 1808 que limitó, durante el Imperio, su uso a los nobles, limitación abolida por Luis XVIII durante la restauración. Las armerías ya no son el objetivo social en las que se habían convertido al final del antiguo régimen.

Jurídicamente, las armas son el equivalente designado de un nombre propio (nombre de familia o nombre de lugar) y son accesorios a ese nombre. Las armas son una propiedad regular, de transmisión hereditaria y susceptible de ser adquirido o conferido. El derecho asociado con las armerías se parece como a aquel de las marcas y es probablemente el primer tema sobre el que se elaboró un derecho internacional (por normas o costumbres).

Como regla general, cada uno puede portar armas, a reserva de no usurpar aquellas de otros. Algunos países que han conservado una nobleza (notablemente el Reino Unido) le han impuesto una reglamentación específica, hasta un tribunal dedicado (Escocia). Sin embargo, el “derecho” a portar tales o tales armas es por la mayor parte un asunto de costumbre.

El principal problema del derecho de armas es, para un titular, el probar la anterioridad en el uso de un blasón que ha reivindicado. Esta prueba es generalmente aportada a través de actos oficiales que registran un blasón dado o acuerdan una modificación en las armas preexistentes.

Las reglas del blasón per se, es decir aquellas que hablan sobre la composición de las armas, están implícitas y responden a las costumbres. El carácter bien o mal constituido de un blasón se evalúa en función de un “espíritu heráldico”. La evaluación se apoya sobre el concejo de autoridades eminentes que pronuncian sus lecciones en sus tratados de heráldica a los que hacen referencia. Estas reglas modificadas o movibles como aquellas de buen tono: cuando el consejo de las autoridades es unánime, el juicio puede ser trazado, para los casos más marginales este debe ser modificado.

Aunque la creación de los blasones depende de la iniciativa de sus futuros propietarios, tiene, desde el inicio, reglas más o menos estrictas, con vistas a hacer la identificación eficaz: lectura fácil por el empleo de colores francos sobreponiéndose los unos sobre los otros, motivos de gran tamaño con contornos simplificados fácilmente legibles, y sobre todo la unicidad de las armerías —a menudo no respetada, más por ignorancia que por voluntad de plagio—.

Esta voluntad de identidad se traduce también por el uso de símbolos, recuerdo de hechos marcantes o traducciones de rasgos característicos vinculados al propietario ("Armas alusivas"), o por figuración del patronímico, juego de palabras ("Armas parlantes") —p.e. el “jeroglífico” que constituyen las armas de "Gonesse", una comuna del Valle del Oise, el “gozne” ("gond" en francés) enlazado por una letra S: "gond-esse" en francés—.

Pero el blasón no está fijado y puede evolucionar en función:


De igual manera puede desaparecer y ser reemplazado por un blasón de sustitución, cuando el blasón original ha sido “deshonrado” por una acción poco honorable de su propietario o de un ancestro del mismo (ver león, león "cobarde", "vil", etc.).

De hecho no se conoce más que una sola regla que se pueda enunciar en términos indiscutibles —es decir para la que se pueda determinar con certeza si es respetada o no—: «No metal sobre metal, no esmalte sobre esmalte». Esta es la "regla de contrariedad de los esmaltes".

A veces se puede afirmar:


Las armas son indudablemente significativas, hay sistemas precisos y completos de interpretación simbólica de armas ya definidos, pero tales sistemas aparentan ser una “mancia” (arte adivinatorio). Aunque hay armas que han sido deliberadamente compuestas en referencia a uno de esos sistemas, no es el caso general, y la identificación precisa del sistema utilizado es igualmente una tarea delicada.

El valor que puede tomar una figura en un sistema particular es el propio de cada sistema y no puede generalizarse. Si muchos cruzados portaron una cruz, si el bezante carga usualmente el blasón de un antiguo cruzado, no podemos deducir por eso que todas las cruces heráldicas fueron creadas en las cruzadas, ni que la pieza honorable en forma de cruz haya tenido siempre un motivo religioso: puede no ser más que una figura puramente geométrica, o resultar de una composición, o referirse a un lugar.

Pero después de establecer como principio que hay siempre un significado en cada elección de figuras, hemos de decir que numerosas armas no tienen significados conocidos, y los que se les dan habitualmente no son, frecuentemente, más que hipótesis. La interpretación de lo simbólico debe ser prudente con su contexto: el titular de las armas no las ha compuesto arbitrariamente y un significado puede tener su origen en armas preexistentes.

Los escudos compuestos pueden corresponder a matrimonios, a piezas concedidas por la Gracia del Rey o por adquisiciones. Quienes cargan sus derechos en las armas correspondientes los traducen gráficamente en la composición de las armerías.

La composición más simple consiste en poner dos escudos juntos manteniendo la forma individual de cada uno. En la Edad Media se tenía el hábito de juntar los blasones de los cónyuges, el marido a diestra (el lugar de honor) y la mujer a la siniestra. Después esta moda evolucionó y se acuartelaron los blasones con las armas de los esposos —en el primer y cuarto las armas del esposo, en el segundo y el tercero las de la esposa—.

En los siglos XVII al XVIII, las armas subcompuestas buscaban (muy artificialmente) representar sistemáticamente todas las alianzas y ancestros de un personaje, por sus cuarteles de nobleza, al punto de volverse globalmente ilegibles. En estos excesos, que completaban las grandes armas, la composición se opone a la primera regla del blasón, que le impone a las armas el ser simples. Sin embargo, es legítimo (aun por vanidad) representar sobre un mismo escudo las armas de todos los abuelos, bisabuelos, tatarabuelos etc. (para mostrar respectivamente 8, 16, 32 ó 64 cuarteles de nobleza), pero esta composición es artificial y no muestra más que las alianzas. Las armas personales deben mantenerse simples.

Los esmaltes son el nombre de las diferentes tonalidades cromáticas representadas en heráldica. Los esmaltes se dividen en tres grupos: metales, colores y una combinación de ambos llamada forros.








</doc>
<doc id="1442" url="https://es.wikipedia.org/wiki?curid=1442" title="Harry Potter">
Harry Potter

Harry Potter es una serie de novelas fantásticas escrita por la autora británica J. K. Rowling, en la que se describen las aventuras del joven aprendiz de magia y hechicería Harry Potter y sus amigos Hermione Granger y Ron Weasley, durante los años que pasan en el Colegio Hogwarts de Magia y Hechicería. El argumento se centra en la lucha entre Harry Potter y el malvado mago lord Voldemort, quien asesinó a los padres de Harry en su afán de conquistar el mundo mágico.

Desde el lanzamiento de la primera novela, "Harry Potter y la piedra filosofal", en 1997, la serie logró una inmensa popularidad, críticas favorables y éxito comercial alrededor del mundo. Para julio de 2013 se habían vendido entre 400 y 450 millones de ejemplares de los siete libros, que los ubican como la de la historia y los cuales han sido traducidos a más de 65 idiomas, entre los que se incluyen el latín y el griego antiguo. El séptimo y último libro, "Harry Potter y las reliquias de la Muerte", fue lanzado mundialmente en inglés el 21 de julio de 2007, mientras que en español se publicó el 21 de febrero de 2008.

La editora Bloomsbury Publishing tiene los derechos de publicación en inglés para el Reino Unido y el resto de Europa, mientras que la editorial Scholastic los tiene para los Estados Unidos y la Editorial Salamandra los tiene para el idioma español y su distribución por España e Hispanoamérica.

El éxito de las novelas ha hecho de la marca "Harry Potter" una de las más exitosas del mundo, con un valor de 15 000 millones de dólares, y a Rowling la primera escritora de la historia en alcanzar los 1 000 millones de dólares en concepto de ganancias gracias a su trabajo. En 2005, fue la novena persona con el ingreso anual más alto del mundo. 

En 1999 la productora de cine Warner Bros. adquirió los derechos para adaptar los siete libros a una serie de películas. La última de ellas, "", se estrenó el 15 de julio de 2011 y con ocho películas realizadas la serie se convirtió en una de las del cine en concepto de recaudaciones en taquilla.

La historia comienza con la celebración del mundo mágico. Durante muchos años, había sido aterrorizado por el malvado mago lord Voldemort. La noche del 31 de octubre, mató a Lily y James Potter. Sin embargo, cuando intenta matar a su hijo de 1 año, Harry, la maldición asesina "avada kedavra" se vuelve sobre sí mismo. El cuerpo de Voldemort resulta destruido, pero él sobrevive: no está muerto ni vivo. Por su parte, a Harry solo le queda una cicatriz con forma de rayo en la frente que es el único remanente físico de la maldición de Voldemort. Harry es el único sobreviviente de la maldición asesina, y a raíz de la misteriosa derrota de Voldemort, el mundo mágico empieza a llamarlo como «el niño que sobrevivió». 

El 1 de noviembre, Rubeus Hagrid, un semi-gigante, deja a Harry con los únicos parientes que le quedan, los crueles Dursley. Estos son su tío Vernon, su tía Petunia y Dudley, su primo malcriado. Ellos intentarán en vano esconder su herencia mágica (por ejemplo, al decirle que sus padres murieron en un accidente de tráfico, o castigándolo severamente después de cualquier comportamiento extraño). Sin embargo, la víspera de su undécimo cumpleaños, Harry tiene su primer contacto con el mundo mágico cuando recibe cartas del Colegio Hogwarts de Magia y Hechicería, las cuales eran entregadas por lechuzas, aunque su tío impide que pueda leerlas. Ya en su cumpleaños, Hagrid aparece y le dice a Harry que existe un mundo mágico y otro «muggle» , puesto que él es un mago, ha sido invitado a asistir al colegio.

Al contrario que en novelas como las de "Las Crónicas de Narnia", en las que se trata un universo alternativo, o "El Señor de los Anillos", donde la «Tierra Media» se trata de un pasado ficticio, el mundo mágico de las novelas de Harry Potter es un universo paralelo al nuestro y contiene diversos elementos mágicos análogos a cosas del mundo no mágico o muggle. Este universo mágico tiene una organización política para cada Estado; en el caso del Reino Unido, donde se desarrolla la mayor parte de la acción, la máxima institución es el Ministerio de Magia. Existe un «Estatuto Internacional del Secreto» que obliga a todos los magos y brujas del mundo a mantener en secreto para los "muggles" la existencia del mundo mágico. 

La capacidad de hacer magia, según las novelas, es innata más que aprendida, aunque los jóvenes magos deben asistir a escuelas con el fin de dominarla y controlarla. Esta capacidad es totalmente hereditaria, aunque existan magos hijos de muggles (o «sangre sucia» de forma despectiva) pues estos siempre debieron tener un ascendente mago; también es posible que existan hijos de magos sin alguna capacidad mágica. A estos últimos se los llama «squibs». Los magos tienen un desarrollado sistema social, con su propia moneda, sanidad y una compleja red de transportes y comunicaciones.

Dentro del mundo mágico, coexisten con los magos que también son mantenidas en secreto y fuera de contacto con los muggles. Entre ellas se encuentran dragones, fantasmas, unicornios, sirenas, centauros y otras inventadas o adaptadas por la autora como los o los .

Los libros evitan ubicar la historia en algún año en particular, sin embargo hay un par de referencias que permiten establecer una línea de tiempo con años reales. La primera se da en la segunda novela, "Harry Potter y la cámara secreta", en la que el fantasma Nick Casi Decapitado celebra el 500º aniversario de su muerte, que ocurrió el 31 de octubre de 1492, por lo tanto, el libro se ubica en el ciclo lectivo de 1992 a 1993. Esta cronología se reitera en "Harry Potter y las reliquias de la Muerte", cuando se indica que la muerte de James y Lily Potter ocurrió el 31 de octubre de 1981. Estos datos permiten deducir que el argumento de la historia transcurre desde 1981, cuando Dumbledore entrega a Harry a sus tíos al comienzo de "La piedra filosofal", hasta 1998, al final de "Las reliquias de la Muerte".

"Harry Potter y la piedra filosofal" ("Harry Potter and the Philosopher's Stone") es el primer libro de la serie, fue publicado en Reino Unido el 26 de junio de 1997 y en español en marzo de 1999. Se trata de uno de los libros más vendidos de la historia, las estimaciones de sus ventas mundiales superan los 110 millones de copias. En la primavera de 2007, una primera edición firmada por Rowling fue subastada en Londres por 27 876 libras esterlinas.

En esta primera obra se introducen la mayoría de los personajes principales de la serie, así como muchos de los lugares donde se desarrollará la acción. Se narran los primeros pasos de Harry en el mundo de la magia, así como su primer enfrentamiento con Voldemort, quien en su búsqueda de la inmortalidad quiere obtener el poder de la piedra filosofal.

"Harry Potter y la cámara secreta" ("Harry Potter and the Chamber of Secrets") fue publicado originalmente el 2 de julio de 1998, y en español en octubre de 1999. Muchos de los elementos del primer boceto de este libro fueron eliminados tanto por su autora como por el editor. Además, el libro tiene una importante relación temática con el sexto libro. Mucha de la información que iba a ser revelada en este tomo fue desplazada a la sexta entrega. Como consecuencia de esto, muchos de los elementos que aparecen en una forma cotidiana en "La cámara secreta" aparecen nuevamente en "El misterio del príncipe" con su verdadera relevancia.

El libro relata el segundo año de Harry en Hogwarts. Un día un elfo llamado Dobby vino a casa de Harry para avisarle de que Hogwarts corría un grave peligro. Más tarde su amigo Ron, le recogerá en un coche volador y así empieza su curso en Hogwarts durante el cual aparecen mensajes en las paredes de los pasillos de la escuela que advierten que la Cámara de los Secretos ha sido abierta, seguidos de una serie de ataques a alumnos que no provienen de familias con sangre mágica. En esta entrega introducen la figura del elfo doméstico y personajes relevantes para el resto de la serie, como Lucius Malfoy, Ginny Weasley y Arthur Weasley, además de revelar un poco más del pasado de Voldemort a través de su diario personal.

"Harry Potter y el prisionero de Azkaban" ("Harry Potter and the Prisoner of Azkaban") fue publicado en inglés el 8 de julio de 1999, mientras que en español lo hizo en abril de 2000. Este fue el libro que más rápido escribió Rowling, pues lo terminó en tan solo un año después de comenzar a escribirlo. Fue además acreedor del Premio Costa y del Premio Bram Stoker, entre otros, que lo ubican como uno de los libros fantásticos más laureados de los últimos años.

En esta oportunidad se introducen la figura del dementor y los personajes de Remus Lupin y Sirius Black, quien al inicio de la novela escapa de la prisión de Azkaban, además de desarrollar la historia de los padres de Harry. Es el único libro de la serie en el que no aparece Voldemort.

"Harry Potter y el cáliz de fuego" ("Harry Potter and the Goblet of Fire") fue publicado en inglés el 8 de julio de 2000 y en español en marzo de 2001. El tamaño del libro incrementó considerablemente respecto a los primeros tres, una idea de la que Rowling estaba al tanto desde la concepción de la novela. El título atravesó diversas modificaciones, entre las cuales se incluyeron "Harry Potter y el Torneo Doomspeell", "Harry Potter y el Torneo de los tres magos", hasta que la autora se inclinó por "El cáliz de fuego" pues recordaba al concepto de la «copa del destino», que de acuerdo a ella era el tema del libro. La novela fue ganadora del Premio Hugo a la mejor novela en 2001.

En esta ocasión, se narra el cuarto año de Harry en Hogwarts y el misterio que rodea el ingreso involuntario de su nombre en el Torneo de los Tres Magos, en el cual es obligado a competir junto a otros tres participantes. La historia explora más a fondo el mundo mágico y termina con el resurgimiento de lord Voldemort. Previo a la publicación del libro, se generó mucha controversia y anticipación ante el anuncio de la autora de que un personaje moriría.

"Harry Potter y la Orden del Fénix" ("Harry Potter and the Order of the Phoenix") es con casi 900 páginas en su edición inglesael libro más largo de la serie, un hecho que la propia autora considera un defecto. Fue publicado mundialmente en inglés el 21 de junio de 2003, y en español el 21 de febrero de 2004. La edición en español a cargo de Salamandra constó de tres versiones: una para España, otra para el cono sur y otra para Colombia, México y Estados Unidos. Esta distinción se hizo para respetar algunas particularidades del lenguaje regional. Su tirada inicial en español fue de 1 100 000 copias. 

En el quinto libro, Harry Potter debe enfrentarse tanto a un Voldemort resurgido como al resto del mundo mágico que se niega a creer que esto es cierto, empezando por el Ministerio de Magia. Este nombra a Dolores Umbridge como la nueva directora de Hogwarts, y junto con Luna Lovegood y Bellatrix Lestrange son los tres personajes más destacados que se introducen en esta entrega. Por otro lado, se revela una importante profecía que concierne a Harry y a Voldemort.

"Harry Potter y el misterio del príncipe" ("Harry Potter and the Half-Blood Prince") fue publicado en inglés el 16 de julio de 2005 y fue presentado por Rowling en una rueda de prensa reservada solo a niños entre 8 y 16 años. Por su parte, en español fue publicado el 23 de febrero de 2006, con una tirada inicial de un millón de ejemplares. Casi un año antes de su publicación original, Rowling había manifestado en su sitio web oficial su voluntad de matar a otro personaje, por lo que se sucedieron una serie de apuestas no oficiales en las que se barajaron las posibilidades.

En esta sexta entrega, Harry se topa con un antiguo libro de texto de pociones lleno de anotaciones y recomendaciones firmadas por un misterioso príncipe. Al mismo tiempo, recibe clases particulares por el propio director del colegio, Albus Dumbledore, que le hace conocer momentos del pasado de Voldemort, para así enseñarle lo que son los horrocruxes, objetos elementales para lograr su victoria. Al final del libro, el profesor Severus Snape, cuya lealtad estuvo en duda durante toda la serie, asesina a Dumbledore. La frase "Snape kills Dumbledore" (Snape mata a Dumbledore) se convirtió en un fenómeno de internet que impulsó todo tipo de videos y gráficos.

La séptima novela, "Harry Potter y las reliquias de la Muerte" ("Harry Potter and the Deathly Hallows"), fue publicada en inglés el 21 de julio de 2007, cerrando la serie que duró una década. En español fue publicado el 21 de febrero de 2008, con una tirada inicial de un millón y medio de ejemplares. El libro batió récords de venta, con más de 11 millones de copias vendidas en sus primeras 48 horas, solo en el Reino Unido y Estados Unidos. La marca anterior la tenía "El misterio del príncipe".

Esta última novela narra los acontecimientos que siguen directamente a la muerte de Dumbledore, en los que Voldemort finaliza su ascenso al poder y logra dominar el Ministerio de Magia. Harry y sus amigos deciden no asistir a su último año en Hogwarts, para salir en la búsqueda de los horrocruxes restantes. Finalmente, se lleva a cabo la batalla de Hogwarts, entre la Orden del Fénix, alumnos y profesores del colegio, por un lado, y Voldemort y los Mortífagos, por el otro. La novela finaliza con un epílogo que cuenta el futuro de los personajes supervivientes 19 años después del enfrentamiento, mostrando que cada uno de ellos ha formado sus vidas.

El 23 de octubre de 2015, J. K. Rowling anunció una octava parte de la saga.

La octava entrega de la serie de Harry Potter (que está dividida en dos partes) se publicó el 31 de julio de 2016. No es una novela como las anteriores, sino sencillamente el guion utilizado en la obra de teatro sobre el mismo, la cual se estrenó el 30 de julio de 2016.

Adicionalmente, Rowling escribió seis libros secundarios que se ubican dentro del universo argumental de las ocho novelas principales. Todos se escribieron con un carácter benéfico, dado que sus recaudaciones fueron donadas a las entidades Comic Relief y The Children's Voice.

"Animales fantásticos y dónde encontrarlos" (en inglés, "Fantastic Beasts and Where to Find Them") es un libro de texto usado por los estudiantes de Hogwarts, escrito en la ficción por Newt Scamander, un afamado mago biólogo. Describe y analiza las distintas criaturas mágicas que habitan en el mundo. Fue publicado el 5 de marzo de 2001, con un diseño que representa a la copia usada por Harry Potter en "El prisionero de Azkaban". Incluye además algunas notas al margen hechas supuestamente por los tres protagonistas. El 12 de septiembre de 2013 Warner Bros. anunció que se estaba preparando una película basada en este libro con el guion de J. K. Rowling. El 15 de octubre de 2014 se hizo oficial que el actor Eddie Redmayne encarnaría el papel principal de la película. Warner Bros anunció que "Animales fantásticos y dónde encontrarlos" sería una pentalogía que se estrenaría en 2016, 2018, 2020, 2022 y 2024.

"Quidditch a través de los tiempos" (en inglés, "Quidditch Through the Ages") fue publicado en forma conjunta con el anterior, y persiguió los mismos fines benéficos. En este caso, se trata de un manual sobre las reglas y la historia del quidditch, el deporte más popular entre los magos. Aunque en la serie aparece como un regalo de Navidad de Hermione a Harry, el libro está diseñado como un ejemplar de la biblioteca de Hogwarts, con un aspecto algo ajado y con una pegatina que detalla los alumnos que han solicitado su préstamo anteriormente.

Por su parte, "Los cuentos de Beedle el Bardo" ("The Tales of Beedle the Bard") fue escrito a finales de 2007 como una «despedida de la serie» por parte de la autora. Solo se hicieron siete copias manuscritas e ilustradas por Rowling, de las cuales seis fueron regaladas y una fue subastada en Londres. La subasta se llevó a cabo en la casa Sotheby's de la ciudad, y el libro fue comprado por Amazon.com por un precio de 1 950 000 libras esterlinas. Todas las copias, de 157 páginas, están forradas en cuero marroquí con ornamentos de plata e incrustaciones de piedras semi preciosas.

Según la serie, Beedle el Bardo es al ficticio mundo mágico, lo que los hermanos Grimm o Hans Christian Andersen son al mundo real. Sus cuentos son conocidos popularmente entre los niños magos como lo son Cenicienta o Blancanieves entre los muggles. Una recopilación de estas historias, escrita en runas antiguas, aparece en el último libro de la heptalogía como una herencia de Albus Dumbledore a Hermione Granger y tiene un papel fundamental en el desarrollo del argumento.









Según cuenta en su sitio web, en 1990 Rowling estaba viajando en un tren de Mánchester a Londres, cuando la idea «de repente se formó en su cabeza».

En 1995, "Harry Potter y la piedra filosofal" estaba terminado y el manuscrito fue enviado a diversos agentes. El segundo agente al que acudió, se ofreció a representarla y enviar su manuscrito a Bloomsbury Publishing. Después de que ocho editoras rechazaron el libro, Bloomsbury ofreció a Rowling un adelanto de 2500 libras esterlinas para la publicación.

A pesar de que Rowling no había tenido en mente una categoría de edad particular para sus potenciales lectores cuando comenzó a escribir, los editores apuntaron inicialmente a niños de entre nueve y once años. En la víspera de la publicación, los editores pidieron a Joanne Rowling adoptar un seudónimo con un género más neutral, para abordar a los chicos varones de esta edad, temiendo que no estarían interesados en leer una novela escrita por una mujer. Ella eligió utilizar J. K. Rowling (Joanne Kathleen Rowling), omitiendo su nombre y usando el de su abuela como segundo.

El primer libro de "Harry Potter" fue publicado en Reino Unido por Bloomsbury en junio de 1997 y en los Estados Unidos por Scholastic en septiembre de 1998, previo pago de 105 000 dólares a Rowling, una suma sin precedentes para un libro para niños por el derecho de las ediciones en Estados Unidos. Temiendo que algunos de los lectores no entendieran la palabra «filosofal» ni la asociaran a un tema mágico (la piedra filosofal está relacionada con la alquimia), Scholastic insistió en que el libro sea retitulado como "Harry Potter and the Sorcerer's Stone" ("Harry Potter y la piedra del hechicero") para el mercado estadounidense.

Los editores de Rowling lograron capitalizar este fenómeno gracias a las rápidas y sucesivas publicaciones de los cuatro primeros libros que no permitieron que decayera el interés de los lectores, aun incluso cuando Rowling se tomó un descanso entre la publicación de "El cáliz de fuego" y "La Orden del Fénix". La serie también logró seguidores adultos, lo que impulsó dos ediciones de cada libro de Harry Potter, con texto idéntico, pero con una carátula dirigida a los niños y otra a los mayores.

En diciembre de 2005, Rowling declaró en su sitio web que «2006 será el año en el que escribiré el último libro de la serie "Harry Potter".» El progreso de "Harry Potter y las reliquias de la Muerte" fue detallado en subsecuentes actualizaciones de su diario virtual hasta su publicación, el 21 de julio de 2007.

Rowling terminó el libro el 11 de enero de 2007 en el hotel Balmoral, en Edimburgo, donde escribió un mensaje debajo de un busto de Hermes que reza: «JK Rowling terminó de escribir Harry Potter y las reliquias de la Muerte en esta habitación (652) el 11 de enero de 2007.» 

Sin embargo, Rowling declaró que el último capítulo del séptimo libro (el epílogo) lo escribió «en más o menos 1990». En junio de 2006, en una aparición en el programa de entrevistas británico "Richard & Judy", Rowling anunció que este capítulo había sido modificado, dado que un personaje «se salvó» y otros dos que anteriormente sobrevivían a la historia, ahora morían. También dijo que veía la lógica en matar a Harry Potter, con el fin de evitar que otros autores escribiesen libros sobre la vida de Harry luego de Hogwarts.

Rowling escribió los siete libros de "Harry Potter" en 17 años. En una entrevista en el año 2000 a su editor estadounidense, Rowling declaró que no hay una universidad después de Hogwarts. En cuanto a la continuación de la serie luego del séptimo libro, dijo: «no voy a decir "nunca", pero no tengo planes de escribir un octavo libro».

Cuando se le preguntó sobre escribir otros libros relacionados con la serie, al estilo de "Quidditch a través de los tiempos" o "Animales fantásticos y dónde encontrarlos", respondió que consideraría hacerlo si los beneficios son destinados a la caridad, como bien sucedió con estos dos libros. Otra sugerencia fue un tipo de enciclopedia, que contuviera información que no tuvo cabida en la serie. Sobre esto, el 24 de julio de 2007, Rowling anunció en una entrevista que «probablemente» escribiría una enciclopedia del mundo de "Harry Potter", la cual incluiría datos descartados de la historia, así como también información a lo ocurrido después de "Las reliquias de la Muerte", como detalles acerca del futuro de los personajes, etc.

Las novelas se basan principalmente dentro del género fantástico, aunque en muchos aspectos también pueden ser consideradas "Bildungsromane", o novelas de formación, en las que se detalla algún tipo de desarrollo de un personaje. La historia se ubica principalmente en Hogwarts, un internado británico para magos. En este sentido, las novelas son «descendientes directos de "Tom Brown's School Days" de Thomas Hughes y otras novelas victorianas y eduardianas que se basan en la vida en los colegios públicos». Por su parte, en palabras de Stephen King, las novelas son «astutos cuentos de misterio», y cada libro está construido al estilo de las aventuras de Sherlock Holmes, donde se dejan un número de pistas escondidas en la narrativa, mientras los personajes persiguen a una serie de sospechosos a lo largo de exóticos escenarios, llevando a un giro final inesperado. Están escritas en tercera persona con un narrador omnisciente que focaliza en Harry salvo contadas excepciones (como los primeros capítulos de "La piedra filosofal", "El misterio del príncipe" o "Las reliquias de la Muerte"), y los secretos de la historia le son desvelados al lector al mismo tiempo que a Harry.

Los libros tienden a seguir una fórmula muy estricta. Ubicados a lo largo de años consecutivos, generalmente comienzan con Harry en casa de los Dursley, en el mundo "muggle". Seguido, se traslada a algún escenario mágico, como , el o , por un breve período antes de empezar el año escolar, el cual comienza cuando se sube al Expreso de Hogwarts, en el Andén 9¾. Una vez allí, se desarrolla la historia que alcanza su clímax cerca o justo después de los exámenes finales, cuando Harry debe enfrentarse a Voldemort o alguno de sus Mortífagos. Por último, aprende una importante lección o detalle clave de la trama en una conversación con Albus Dumbledore. Esta fórmula se rompe completamente en la última novela, en la que Harry y sus amigos pasan la mayor parte del tiempo fuera de Hogwarts, y solo regresan allí para la confrontación final.

Por otro lado, Voldemort está presente de alguna manera (físicamente, a través de un sueño o una visión) en cada capítulo hasta el quinto libro, y a partir del cual, aparece en la mayoría restante. Esta estructura permite al lector desentrañar los misterios al mismo tiempo que Harry, encontrando pistas solo cuando él lo hace.

Según Rowling, el principal tema del que se rodea la heptalogía es la muerte: «Mis libros son en buena parte sobre la muerte. Se inician con la muerte de los padres de Harry. Después está la obsesión de Voldemort de conquistar la muerte y su búsqueda de la inmortalidad a cualquier precio, el objetivo de cualquiera capaz de hacer magia. Entiendo por qué Voldemort quiere conquistar a la muerte. Todos le tenemos tanto miedo».

Distintos especialistas de la industria literaria han desarrollado otras interpretaciones de los temas que presentan los libros, unas más complejas que otras, y algunas incluyendo matices políticos. En general, se ha concluido que en las novelas se manifiestan temas como la normalidad, opresión, supervivencia, y la superación de estándares establecidos. Rowling ha declarado que los libros comprenden «un argumento a favor de la tolerancia» y que además transmiten un mensaje que propone «cuestionar la autoridad y no asumir que el "establishment" o la prensa te cuentan toda la verdad».

Mientras que se podría decir que los libros comprenden muchas otras temáticas, tales como el poder (o abuso de él), amor y prejuicio, las mismas están, según Rowling, «fuertemente arraigadas al argumento»; la autora prefiere dejar que estos conceptos «crezcan orgánicamente» más que sentarse e intentar impartir conscientemente tales ideas a sus lectores. En la misma línea se encuentra la siempre presente temática adolescente, en cuya descripción la autora estuvo resuelta a admitir la sexualidad de sus personajes, con el fin de no «estancar a Harry en un permanente estado prepubescente».

El incremento del hábito de la lectura entre los niños y jóvenes ha sido la tendencia más destacada que se le atribuyó a "Harry Potter". Una encuesta llevada a cabo en 2006 por "Kids and Family Reading Report" y Scholastic arrojó como resultados que el 51 % de los lectores de la serie de entre 5 y 17 años dijo que no había leído por placer anteriormente a Harry Potter, pero que después sí lo hace. Además, el estudio afirma que el 65 % de los niños y el 76 % de los padres declaraba que el desempeño escolar de ellos mismos o de sus hijos había mejorado desde que empezaron a leer los libros. Charlie Griffiths, director de la "National Literacy Association", dijo «cualquiera que persuada a los niños a leer debería ser atesorado, y lo que Rowling nos ha dado con "Harry Potter" es por poco un milagro». Por su parte, el primer ministro británico, Gordon Brown, alabó a la escritora diciendo: «Creo que J. K. Rowling ha hecho más por la literatura que ningún otro ser humano».
A medida que la serie avanza, cada libro se vuelve progresivamente más largo, desarrollando habilidades literarias en los lectores. Una comparación muestra que cada libro, salvo el sexto, es más largo que su predecesor, requiriendo una mayor concentración y atención en aquellos niños que abordan la lectura de la serie.

También es destacable el fanatismo que consiguieron los libros. En respuesta a la ansiedad de los fanáticos, las librerías de todo el mundo comenzaron a organizar eventos que coincidían con el lanzamiento de los libros, empezando con la publicación de "El cáliz de fuego", en el 2000. Estos eventos, que incluían generalmente juegos, actuaciones y pintadas en la cara, han logrado una gran popularidad entre los fanáticos y han sido increíblemente exitosos en atraer compradores, hecho que se pone de manifiesto con la venta en el primer día de publicación de casi 9 millones de copias de las 10,8 millones de la tirada inicial.

"Harry Potter" también trajo cambios al mundo editorial, siendo uno de los más destacados la reforma de la lista de "best-sellers" del "New York Times". El cambio vino inmediatamente después del lanzamiento de "El cáliz de fuego", en 2000, cuando los editores se quejaron del número de puestos que ocupaban los libros de Harry Potter y otros destinados al público infantil. Como consecuencia, el New York Times creó una lista separada para la literatura infantil.

La palabra "muggle" se ha extendido más allá de sus orígenes, siendo usada por muchas personas para indicar a aquel que le falta alguna habilidad. En 2003, el término entró en el Oxford English Dictionary con esa definición.

En noviembre de 2007, la revista "Advertising Age" estimó el valor total de la marca "Harry Potter" en 15 000 millones de dólares. La popularidad de la serie se tradujo en un sustancial éxito financiero para Rowling, sus editores y otros dueños de los derechos de la marca. Este éxito hizo de Rowling la primera y hasta ahora única persona que amasó mil millones de dólares estadounidenses escribiendo libros. Esta cifra la ubicaría, según algunas fuentes, como la mujer más adinerada del Reino Unido, por encima de la Reina Isabel II.

Para el lanzamiento de "El cáliz de fuego", se usaron 9000 camiones de FedEx únicamente para entregar los libros. En Estados Unidos, la tirada inicial del libro fue de 3,8 millones de copias. Este récord fue sobrepasado por "La Orden del Fénix", con 8,5 millones, que a su vez fue superado por "El misterio del príncipe", cuya tirada inicial fue de 10,8 millones. Solo en Estados Unidos y Reino Unido se vendieron casi 9 millones de copias del sexto libro en las primeras 24 horas desde su publicación. Por su parte, la tirada inicial en inglés de "Las reliquias de la Muerte" fue de 12 millones de copias, estableciendo así un nuevo récord.

Por otro lado, algunas librerías declararon que la venta de libros de Harry Potter no les resultaba beneficiosa. La intensa competencia para ofrecer el mejor precio de las populares novelas rebajó los ingresos esperados. El precio sugerido para "Las reliquias de la Muerte" fue de 35 dólares, pero Amazon.com ofreció el libro a un precio de oferta de 18 dólares, comportamiento que siguieron otras cadenas para mantenerse competitivas. Esto llevó a las librerías más pequeñas a vender el libro al precio sugerido, pero añadiendo otros beneficios, como cupones de descuento para la próxima compra u objetos de recuerdo relacionados con Harry Potter.

En sus principios, "Harry Potter" recibió críticas sobresalientes, que ayudaron a crear una gran base de lectores para la serie. Tras su publicación, muchos de los principales diarios británicos elogiaron "La piedra filosofal". El "Mail on Sunday" lo describió como «el debut más imaginativo desde Roald Dahl», un punto de vista secundado por el "Sunday Times". Por su parte, "The Guardian" lo llamó «una novela ricamente texturizada, despegada por un ingenio imaginativo» y "The Scotsman" dijo que tiene «todas las señas de un clásico».

Llegada la publicación del quinto volumen, "Harry Potter y la Orden del Fénix", los libros comenzaron a recibir fuertes críticas de distintos expertos literarios. El crítico y catedrático de Yale, Harold Bloom cuestionó los méritos literarios de los libros al decir «la mente de Rowling está tan gobernada por "clichés" y metáforas muertas que no tiene otro estilo de escritura». En un artículo del "New York Times", A. S. Byatt denominó al universo de Rowling como un «mundo secundario compuesto de una colección de partes incongruentes derivadas de todo tipo de literatura infantil [...] escrito para personas cuya imaginación está confinada a dibujos animados de la televisión, las telenovelas, telerrealidad y la prensa del corazón». 

Por el contrario, la autora Fay Weldon admitió que la serie «no es lo que esperarían los poetas», mas «esto no es poesía, es prosa legible, vendible, útil y cotidiana». El crítico literario A. N. Wilson elogió la serie en "The Times": «No hay muchos autores con la habilidad "dickensiana" de JK capaz de hacernos hojear las páginas, llorar —abiertamente, con lágrimas saltando— y unas pocas páginas después reír con chistes buenos [...] Hemos vivido en la década en la que se publicó la más divertida, espeluznante y conmovedora historia infantil jamás escrita»." 

Stephen King denominó a la serie como «una obra de la que solo una imaginación superior es capaz de hacer», y calificó al sentido del humor de Rowling como «admirable». Sin embargo, escribió que si bien la historia es «buena», él está «un poco cansado de encontrarse a Harry en casa con sus horribles tíos», la fórmula con la que comienzan todos los libros. También predijo que la serie «soportará la prueba del tiempo, y terminará en la estantería donde solo queda lo mejor; y Harry tomará su lugar con Alicia, Huck, Frodo y Dorothy». El autor Orson Scott Card escribió una crítica de "Las reliquias de la Muerte" en la que dice «JK Rowling ha creado algo que merece permanecer en el tiempo, volverse un clásico permanente de la literatura inglesa, y no solo una "ficción infantil"».

Los libros fueron objeto de numerosos procedimientos legales, los cuales varían desde quejas de grupos religiosos estadounidenses que proclaman que la magia en los libros promueve la brujería entre los niños, hasta conflictos sobre los derechos de autor o infracciones de marcas registradas.

La inmensa popularidad y el alto valor del mercado de los libros ha llevado a Rowling, sus editores y la productora de cine Warner Bros. a tomar medidas legales para proteger sus derechos, las cuales incluyen prohibir la venta de imitaciones, «perseguir» a dueños de páginas web sobre el uso del dominio "Harry Potter" y demandar a la autora Nancy Stouffer para contrarrestar sus acusaciones de plagio sobre su trabajo.

Por otro lado, algunos grupos criticaron a los libros por promover distintas agendas políticas, mientras que ciertos religiosos declararon que los libros promueven la brujería y por tanto no son aptos para niños. En 2003, Joseph Ratzinger, el Papa Benedicto XVI, declaró antes de asumir como Sumo Pontífice que los libros «seducen a los jóvenes lectores de manera subliminal y distorsionan la cristiandad en el alma antes de que ésta pueda desarrollarse». Por último, las declaraciones de Rowling que señalan a Dumbledore como homosexual han aumentado las controversias políticas que rodean la serie.

La serie ha sido traducida a 65 idiomas, con lo que se ubicó a Rowling entre los autores más traducidos de la historia. La primera traducción se hizo al inglés estadounidense, dado que muchas palabras y conceptos usados por los personajes en las novelas, propios del inglés británico, podrían ser malinterpretados por los jóvenes lectores estadounidenses. Subsecuentemente, los libros fueron traducidos a idiomas tan diversos como el ucraniano, hindi, bengalí, galés, afrikáans y vietnamita. El primer volumen, "La piedra filosofal", fue traducido al latín e incluso al griego antiguo, haciendo de este el texto más extenso publicado en ese idioma desde las novelas de Heliodoro, en el Siglo III a. C. 

La enorme demanda de una edición local decente hizo que se tomara con sumo cuidado la tarea de traducción e interpretación del texto. En algunos países como Italia, se publicó una segunda edición actualizada, teniendo en cuenta las sugerencias de los lectores. En otros países, como China o Portugal, la traducción se hizo entre varias personas para reducir el tiempo entre la publicación inglesa y la local. La edición turca del segundo al séptimo libro fue llevada a cabo por Sevin Okyay, un popular crítico literario y comentarista cultural. Con la finalidad de mantener en secreto el argumento, las traducciones autorizadas solo podían empezar después de que los libros fueran publicados en inglés. Por lo tanto, se dio un retardo de varios meses hasta que las traducciones estuvieran disponibles. Esto derivó en que muchas copias de las ediciones en inglés se vendieran a fanáticos impacientes en muchos países de habla no inglesa. Tanta fue la impaciencia para leer el quinto libro, que su edición británica se convirtió en el primer libro de lengua inglesa en lograr el primer puesto en la lista francesa de "best sellers".

Todas las novelas de la heptalogía fueron publicadas en inglés como audiolibros. Existe una versión británica, narrada por Stephen Fry y una estadounidense, por Jim Dale. Por su parte, en español solo se editó el primer volumen, en formato CD-ROM.

En 1999, Rowling vendió los derechos cinematográficos de los cuatro primeros libros a la Warner Bros. por 1 000 000 de libras esterlinas. La principal condición que puso Rowling fue que el reparto principal fuese estrictamente británico, aunque se permitió la contratación de actores irlandeses, como el fallecido Richard Harris como Dumbledore, además de actores y actrices franceses y de Europa del este para "Harry Potter y el cáliz de fuego", puesto que algunos personajes del libro son de ese origen. Tras considerar muchos directores de la talla de Steven Spielberg, Terry Gilliam, Jonathan Demme y Alan Parker, el 28 de marzo de 2000, Chris Columbus fue confirmado por Warner, quien apuntó su trabajo previo en películas infantiles como "Home Alone" y "Mrs. Doubtfire" como el principal argumento para esta decisión. Después de un , el rodaje comenzó en octubre de 2000 en los estudios Leavesden y en la propia Londres, mientras que la producción finalizó en julio de 2001. El 16 de noviembre de 2001 se estrenó mundialmente "La piedra filosofal". Solo tres días después de ese estreno, comenzó la producción de la segunda película, "Harry Potter y la cámara secreta", en la que Columbus repitió en su función de director. Esta adaptación se estrenó el 15 de noviembre de 2002.

Columbus rechazó la oferta de dirigir "Harry Potter y el prisionero de Azkaban", película en la que solo participó como productor. Fue el director mexicano Alfonso Cuarón quien se hizo cargo de la dirección, el rodaje tuvo fecha en el año 2003. La película se estrenó el 4 de junio de 2004. Puesto que la producción de la cuarta película comenzaría antes del estreno de la tercera, Mike Newell fue elegido para dirigir "Harry Potter y el cáliz de fuego", que se estrenó el 18 de noviembre de 2005. Newell también rechazó la propuesta de dirigir la siguiente película, por lo que se designó en la dirección para "Harry Potter y la Orden del Fénix" al director de telefilmes británico David Yates. El estreno de esta película fue el 11 de julio de 2007. Yates también dirigió la sexta entrega, traducida por Warner Bros como "Harry Potter y el misterio del príncipe", que fue estrenada el 15 de julio de 2009. 
La última adaptación, "Harry Potter y las reliquias de la Muerte", se dividió en dos partes. La fue estrenada el 19 de noviembre de 2010 en 2D y en formato IMAX, y la en 2D, 3D y formato IMAX el 15 de julio de 2011, ambas dirigidas también por David Yates.

Rowling ejerció cierta influencia en las películas, supervisando el proceso de filmación de la primera adaptación y fungiendo como productora de las últimas dos películas, al lado de David Heyman y David Barron. Los filmes fueron un enorme éxito de taquilla, figurando todas ellas en su momento entre las 20 películas que más recaudaron a nivel mundial de la historia. Por otro lado, las películas como conjunto componen la , sobrepasando a las de "James Bond", cuya serie consta de 23 títulos, o "Star Wars", de 7. Además de suponer un éxito financiero, las películas en general recibieron aclamación por parte de la crítica. En efecto, según el recopilador de reseñas Rotten Tomatoes, la última entrega fue el segundo título mejor criticado de 2011.

El 31 de mayo de 2007, Warner Bros., Universal Studios y Leavesden Studios anunciaron que se construiría un parque temático sobre Harry Potter en Islands of Adventure, titulado "The Wizarding World of Harry Potter", en Orlando (Estados Unidos). El parque cuenta con atracciones interactivas, además de tiendas y restaurantes. Los planes para llevar a cabo este parque se fueron desarrollando desde hacía año y medio antes, con contribuciones de J. K. Rowling y Stuart Craig. El parque abrió sus puertas en junio de 2010.

El 15 de julio de 2014 se inauguró un parque temático similar llamado de la misma manera, The Wizarding World of Harry Potter, en los Universal Studios de Japón en Osaka (Japón). También se encontraba en construcción The Wizarding World of Harry Potter en Universal Studios Hollywood, cerca de Los Ángeles (California), con una inauguración programada para 2016.

Hasta el momento, Electronic Arts ha lanzado ocho videojuegos basados en las tramas de las películas y las novelas. Además, EA produjo en 2003 un juego de simulación de Quidditch: "". LEGO también produjo dos videojuegos, uno sobre las cuatro primeras entregas y otro sobre las tres últimas, además de una serie de muñecos y escenarios basados en las cinco películas estrenadas. Por otro lado, Wizards of the Coast creó un juego de cartas coleccionables similar a "" basado en el mundo de Harry Potter. Este mazo de cartas llegó a ser el segundo juguete más vendido de Estados Unidos. Por último, "" era el nuevo videojuego de Harry Potter para dispositivos móviles. Podía descargarse gratuitamente en Android.




</doc>
<doc id="1444" url="https://es.wikipedia.org/wiki?curid=1444" title="Historia de América">
Historia de América

La historia de América se refiere al conjunto de sucesos relativos al continente americano, incluidas las Antillas y demás islas próximas, desde que fue poblado por los primeros seres humanos hasta la actualidad.

La historia americana no coincide con los períodos históricos utilizados para la historia de África, Eurasia y Oceanía. Los seres humanos ingresaron al continente con alta probabilidad por el estrecho de Bering y lo poblaron en toda su extensión. Durante varios milenios, los pueblos originarios de América evolucionaron de manera independiente y sin contacto alguno con el resto de las culturas humanas, creando civilizaciones, tecnologías, idiomas y estructuras políticas, económicas, culturales, religiosas y artísticas originales. A partir de 1492 América fue incorporada al resto del mundo como anexo colonial de Europa, que constituyó en el continente sociedades esclavistas que modificaron radicalmente la composición étnica de la población, en un proceso paralelo a la catástrofe demográfica que eliminó a gran parte de su población originaria. A comienzos del siglo XIX comenzó el proceso de descolonización y creación de los estados-nacionales americanos actuales, ninguno de los cuales surgió como continuidad de los pueblos originarios, situación que no se presenta en ningún otro continente.

Debido a su originalidad, las periodizaciones históricas usadas en Europa, no se corresponden con la historia del ser humano en América, razón por la cual la historiografía y la antropología americanas crearon periodizaciones adecuadas a la realidad americana. Este artículo parte de la periodización creada por los arqueólogos Gordon Willey y Philip Phillips, que es la que mayor consenso ha alcanzado en la comunidad científica y divide a la historia de América en los siguientes períodos: 


"Cronología de la Historia de América"
"La cronología superior "corresponde a las Migraciones""

"La cronología inferior: "desarrollo de civilización en América"
La Prehistoria de América es el periodo del tiempo que comprende el poblamiento del continente hasta la formación de las grandes civilizaciones americanas. Se trata de un tiempo de sumo interés e investigación dado que el continente americano fue la única porción de tierra en el planeta que tuvo un desarrollo humano aislado hasta su encuentro directo con las culturas de Europa, África y el resto del mundo. Ello no significa que no hubo de una u otra forma una interacción mínima o significativa con el resto, pero los pueblos americanos no participaron de los acontecimientos históricos y logros que unieron a los demás continentes hasta 1492.

La Prehistoria de América es objeto de permanente estudio dadas las muchas preguntas que permanecen sin respuestas contundentes, como las teorías del poblamiento y la historia y el desarrollo de muchos pueblos americanos aborígenes. La fascinación por la América prehistórica y precolombina estimulan no pocas veces la imaginación, los mitos y las suposiciones. Ciertos o no, ellos representan un reto para la ciencia en un continente aún por descubrir. En la Prehistoria americana, la Cultura Clovis (de hace 13.500 años aproximadamente), es la que más restos arqueológicos deja y la que permite darse una idea de la intensa actividad de los pueblos de cazadores y recolectores que poblaron en el continente.

Durante el periodo arcaico (8000 a. C. - 1500 a. C.), el hombre americano descubrió la agricultura, a la par de otros pueblos en otros continentes. Ello tendría como consecuencia la sedentarización, la creación de sociedades más complejas y la construcción de ciudades. Caral-Supe situada en el actual Perú, corresponde a ese periodo con dataciones del 2627 a. C., es decir, casi a la par con las ciudades mesopotámicas, egipcias, indias y chinas. Ese era el preludio que marcaba el fin de la Prehistoria de América y que daría origen a la Cultura Olmeca hacia el 1500 a. C., la primera gran civilización del continente cuyo esplendor iría hasta el 900 cuando San Lorenzo, su principal centro ceremonial, fue saqueado. La Cultura Olmeca se sitúa entonces en el llamado Periodo Formativo de América (también llamado "Periodo Preclásico" o "Periodo Agrícola") y se desarrolló en Mesoamérica. Tres fueron los centros principales de esta primera civilización: San Lorenzo (datado del 1500 a. C.), Tres Zapotes y La Venta (el más grande centro urbano que podía albergar hasta 18 mil habitantes).
En América del Sur los grandes protagonistas serían los pueblos de la Cultura Chavín, que llegaron a dominar extensos territorios y a construir importantes centros urbanos en torno a santuarios dedicados al "dios Jaguar". Por su parte, en la actual Colombia florecían las llamadas Cultura San Agustín y Calima. Otras culturas reseñables son las de los Anasazi y sus similares (Arizona), así como los "constructores de Montículos" de Norteamérica. El desarrollo de estas culturas en el continente fue en general aisladas las unas de las otras, pero la complejidad de sus creaciones denota ya una gran madurez que prepararía el Periodo Clásico.

Con el Periodo Clásico se entra en el áuge de las civilizaciones americanas. El surgimiento de la Cultura Maya en 292 y de sus ciudades-estado, especialmente Tikal, Palenque y Copán, marcan el inicio histórico del Clásico, que se cierra con el saqueo de la ciudad olmeca de San Lorenzo y el abandono de los Mayas de la parte central de México y Centroamérica para ubicarse en la Península de Yucatán en 900. Mesoamérica posee entonces dos culturas (Olmecas y Mayas), se desarrolla el comercio, el urbanismo, la administración, la religión, la guerra, la astronomía, la matemática, la escritura y la política. Entre los grandes legados a la humanidad de este período quedan el Calendario maya, el más preciso jamás inventado y la Escritura maya.

 
El "Periodo Posclásico, Alto Clásico" o "Precolombino" comprende la formación de los pueblos en América tal como fueron encontrados por los europeos en 1492. Para muchos observadores, en realidad la distinción "clásico" - "posclásico" no reviste una gran distinción. Hacerla, implicaría decir que las culturas precolombinas del posclásico eran inferiores a las del clásico y no hay pruebas de ello.

Por otra parte, especialmente la actividad cultural en Mesoamérica. Los pueblos americanos desarrollaron culturas autónomas originales hasta el punto de producir dos revoluciones neolíticas separadas, en Mesoamérica y los Andes Sudamericanos que dieron origen a docenas de civilizaciones agrocerámicas, entre ellas se encuentran:

Las civilizaciones agroalfareras americanas desarrollaron sistemas originales de organización social basados fundamentalmente en el cultivo de maíz y complejas técnicas de gestión de los ecosistemas, así como la cría de algunos animales domésticos (muy pocos) como es el caso del pavo en América del Norte y el acure o la llama en la Cordillera de los Andes. Los cultivos más importantes en el caso de Mesoamérica fueron el maíz, las alubias (también llamadas caraotas, porotos, etc., en algunos países hispanoamericanos) y la auyama o calabaza. En Sudamérica, el papel predominante del maíz era complementado por el de los tubérculos (papa en las tierras altas de los Andes, batata en las de menor altitud) y raíces, como la yuca. Las civilizaciones andinas desarrollaron también una depurada tecnología textil de que permitía tejidos de hasta 500 hilos por pulgada estructurados en capas sucesivas. Otros cultivos desarrollados por las civilizaciones americanas fueron el algodón, el tomate, el chocolate, la vainilla, el pimiento, etc.

Las culturas agroalfareras de América del Norte también se organizaron en torno al maíz y a la gestión ecológica de las praderas. Los pueblos cazadores se organizaron en torno a la caza del bisonte (impropiamente llamados búfalos) o de la pesca y la caza de mamíferos marinos, en el caso de los esquimales e indígenas del extremo norte del continente. Elementos comunes de las culturas precolombinas que alcanzaron un alto grado de desarrollo fueron la edificación de templos y sitios religiosos monumentales, con avanzados sistemas antisísmicos, siendo claro ejemplo las zonas arqueológicas de Cuzco, Machu Pichu, Teotihuacan, Templo Mayor en la ciudad de México, Nazca, Palenque, Tulum y Tikal entre otros. La ciencia precolombina alcanzó sus puntos más altos con el descubrimiento del cero por la civilización maya, y los calendarios. Contaron con avanzados sistemas de escritura en Mesoamérica y un misterioso sistema de registros (quipus) en los Andes Sudamericanos, así como una refinada metalurgia. Prácticamente todas las culturas americanas contaban con complejos conocimientos y prácticas de gestión ambiental.

El Imperio incaico fue el de mayor extensión en la América precolombina. Surgió a fines del siglo XII; y llegó a abarcar desde el actual Ecuador y el sur de Colombia, pasando por los andes y el altiplano de Perú y Bolivia, hasta Chile y el norte de Argentina. Dichos territorios fueron cuna de diversas culturas preincaicas que fueron conquistadas y anexadas al territorio imperial. Para una mejor organización política el Imperio Inca también llamado "Tahuantinsuyo" (que proviene de la frase quechua "Tawantin Suyu" "las cuatro regiones -en su conjunto-"), estuvo conformado por cuatro suyukuna o regiones:


La capital del imperio era la ciudad del Cuzco, "el ombligo del mundo". Luego de una época de expansión y gran apogeo, el imperio entró en una crisis sucesoria y consecuentemente en una gran decadencia, que culminó con su desaparición gradual producto de la conquista española a principios del siglo XVI. El territorio imperial fue anexado a lo que sería el virreinato del Perú. Por datos arqueológicos y antropológicos se ha ido estudiando el verdadero proceso de la ocupación del Cuzco. El consenso apunta a que, debido al colapso del reino de Taypiqala se produjo la migración de su pueblo. Este grupo de cerca de 500 hombres se habría establecido paulatinamente en el valle del río Huatanay, proceso que culminaría con la fundación del Cuzco. Posteriormente, los reyes cusqueños fueron pactando alianzas y conquistando otros reinos. Hacia fines del siglo XV, gobernaban sobre las zonas altas y medias del valle del Vilcanota y vivían en constante fricción con los Estados colindantes.

Manco Cápac fundó el Imperio incaico, aproximadamente el año 1200 d. C. y fue su primer gobernante. Durante el gobierno de Pachacútec se produjo el mayor crecimiento del imperio. Inauguró el periodo imperial, porque los incas se convirtieron en emperadores al anexionar numerosos reinos. Pachacútec mejoró la organización del estado, dividiendo el imperio en cuatro regiones o "suyus". Por el norte, sometió a los "huancas" y "tarmas", hasta llegar a la zona de los "cajamarcas" y "cañaris" (Ecuador). Por el sur sometió a los "collas" y "lupacas", que ocupaban la meseta del altiplano. Organizó a los "chasquis" e instituó la obligatoriedad de los tributos. Se le considera el último gran emperador del incario. Huayna Cápac, considerado el último monarca, continuó la política de su padre, "Túpac Inca Yupanqui", en cuanto a la organización y fortalecimiento del estado. Para conservar los territorios conquistados tuvo que sofocar en forma sangrienta continuas sublevaciones. Derrotó a los "chachapoyas" y anexionó la región del golfo de Guayaquil, llegando hasta el río Ancasmayo (Colombia). Estando en Quito, enfermó gravemente y falleció en 1525. Con su muerte se inició la decadencia del imperio. Antes de morir, designó a su hijo "Ninan Cuyuch" como su sucesor. Pero el príncipe murió repentinamente y en su lugar fue coronado su hermano Huáscar (1525). Este debió enfrentar a su medio hermano Atahualpa, quien también se consideraba legítimo heredero del trono.

Muy pronto importantes regiones del imperio fueron sacudidas por sangrientas batallas entre tropas cusqueñas y quiteñas, que terminaron con la victoria final de los últimos. "Huáscar" fue tomado prisionero y muerto posteriormente por orden de "Atahualpa". Este último era hijo de Huayna Cápac con una princesa de Quito. Tras la muerte de su padre, se rebeló contra Huáscar, apoyado por la nobleza quiteña. Sus tropas, dirigidas por "Calcuchímac" y "Quizquiz", derrotaron al ejército cusqueño en la batalla de Cotabamba (Apurímac) y entraron triunfantes al Cuzco. Enterado de la victoria, "Atahualpa" marchó a Cajamarca para ser coronado inca. En el trayecto era aclamado por los pueblos del norte. Sin embargo, al llegar a Cajamarca, fue tomado prisionero por los españoles. Era el año 1532. Este hecho marcó el fin del "Imperio Incaico". En contra de lo pensado, "Atahualpa" (que gobernó "de facto" entre 1532 - 1533), no forma parte de la "capaccuna" al nunca ceñir la "mascapaicha". Por lo tanto es impropio llamarle "Sapa Inca", como algunas veces se le titula.

Los aztecas, nombre comúnmente usado para referirse a los mexicas, constituyeron un pueblo dominante en el área norte de Mesoamérica durante el periodo posclásico tardío (1320-1521). En 1325 fundaron su ciudad, Tenochtitlan, actual Ciudad de México. Ya sentados en su ciudad los mexicas estuvieron por varias décadas bajo el dominio del poderoso señorío de Azcapotzalco, al que sirvieron como soldados a sueldo. Hacia 1430, los mexicas habían asimilado la cultura de los pueblos avanzados del valle y se habían convertido en un eficiente poder militar. Atacaron y derrotaron entonces a Azcapotzalco y se transformaron en uno de los señoríos más fuertes de la región. Iniciaron así una hazaña guerrera, que en sólo 70 años les haría dueños del mayor imperio que había existido en Mesoamérica.

El imperio sería forjado principalmente por Tlacaélel, quien convenció a los mexicas de atacar al señor de Azcapotzalco en lugar de rendirse. Tlacaelel además reformó la historia y la religión mexica. Ordenó la quema de los libros mexicas y reescribió su historia. Elevó al Huitzilopochtli, semi-dios mexica, al nivel de los antiguos dioses nahuas, (Quetzalcóatl, Tláloc y Tezcatlipoca). Identificó a Huitzilopochtli con el sol y creó la necesidad de sacrificios humanos constantes, también creó las guerras floridas para poder tener una fuerza militar eficiente incluso en tiempos de paz. Les dio a los mexicas una conciencia histórica y la responsabilidad de mantener la existencia del universo a través de los sacrificios humanos, la mayoría de los sacrificados eran los esclavos que se capturaban durante las guerras. Esa visión místico-guerrera se contraponía a la antigua visión tolteca de Quetzalcóatl que tenían los demás pueblos nahuas.

En la poesía náhuatl se puede apreciar el conflicto entre esas dos visiones del mundo. Tlacaélel rehusó convertirse en tlatoani (rey), pero fue el poder detrás del trono a lo largo de tres reinados. Los mexicas formaron una alianza con los señoríos de Texcoco y Tlacopan creando así lo que se conoció como la Triple Alianza. Bajo el mando de notables jefes militares, como Moctezuma I lhuicamina y Ahuízotl, los mexicas conquistaron el centro de México, Veracruz, la costa de Guerrero, parte de Oaxaca y dominaron el territorio de Soconusco, en los límites con Guatemala. Sólo unos cuantos pueblos lograron resistir el empuje mexica: los purépechas (también conocidos como purhépechas), los tlaxcaltecas y algunos señoríos mixtecos.

Los vikingos fueron los primeros europeos en llegar a América, al que llamaron Vinland, estableciendo al menos un poblado en la isla de Terranova (Canadá), en L'Anse aux Meadows. Hay teorías sobre otros "descubrimientos" anteriores y posteriores al de la costa este (o de la oeste por los chinos), pero ninguno de estos ha sido probado con evidencia firme.

La llegada de los europeos causó la entrada a América de una serie de peligrosas enfermedades (viruela, tifus, fiebre amarilla, etc.) para las que los pueblos originarios no tenían defensas biológicas adecuadas.

El investigador estadounidense H. F. Dobyns ha calculado que un 95% de la población total de América murió en los primeros 130 años después de la llegada de Colón. Por su parte, Cook y Borak, de la Universidad de Berkeley, establecieron luego de décadas de investigación, que la población en México disminuyó de 25,2 millones en 1518 a 700 mil personas en 1623, menos del 3% de la población original. En 1492 España y Portugal juntas no superaban los 10 millones de personas.

No cabe duda alguna que el colapso demográfico de la población original de América fue la causa esencial de la derrota militar de muchas de las civilizaciones conquistadas por los europeos, como México y 

El historiador estadounidense Charles Mann dice que Cortés: 
Algo similar sucedió con el Imperio incaico, derrotado por las huestes de Francisco Pizarro en 1531. La primera epidemia de viruela fue en 1529 y mató entre otros al Emperador Huayna Cápac, padre de Atahualpa. Nuevas epidemias de viruela se declararon en 1533, 1535, 1558 y 1565, así como de tifus en 1546, gripe en 1558, difteria en 1614 y sarampión en 1618. Dobyns estimó que el 90% de la población del Imperio Inca murió en esas epidemias.

En 1492 Cristóbal Colón realizó el primer viaje documentado de Europa a América lo que condujo a la colonización extensa europea del continente.

Cada una de las potencias europeas que conquistaron y colonizaron el continente que recién habían descubierto, utilizaron diferentes mecanismos de dominación de los habitantes de América. En general los historiadores españoles sostienen que la colonización británica fue bárbara y genocida, mientras que los historiadores británicos sostienen que la colonización española explotó el trabajo indígena hasta su exterminio para reemplazarlo luego con esclavos secuestrados en África. Estas visiones son conocidas respectivamente como la leyenda rosa y la leyenda negra de la colonización de América por Europa.

El resultado general fue una enorme mortandad de indígenas que se ha llegado a estimar en el 95% (Dobyns,1983).

Para responder a la masiva mortandad de indoamericanos, a partir del siglo XVII los portugueses, anglo-sajones, franceses y holandeses secuestraron alrededor de 60 millones de africanos, de los cuales unos 12 millones llegaron vivos a América donde fueron reducidos a la esclavitud.

Se realizó un gran flujo de mercancías y herramientas entre ambos continentes, también intercambios culturales y costumbres. En uno y otro continente se introdujeron nuevas especies de alimentos, plantas y animales. De manera negativa también, se introdujeron nuevos tipos de enfermedades que particularmente diezmaron algunas comunidades indígenas.

Hay que señalar también que la conquista europea fue rechazada en la mayor parte del continente. Varios pueblos originarios resistieron exitosamente las invasiones europeas sobre vastos territorios, y mantuvieron el dominio sobre ellos hasta finales del siglo XIX: la Patagonia, la Araucanía, la llanura pampeana, el Mato Grosso, la Región Amazónica, la región del Darién, y las grandes praderas del oeste norteamericano, permanecieron bajo el dominio de naciones como los Mapuche, Het, Ranquel, Wichí, Qom, Amazónicas, Algonquina, Hopi, Comanche, etc.

También se crearon en América del Sur algunas repúblicas de afroamericanos que lograron huir de la esclavitud a la que habían sido reducidos por los portugueses, como el Quilombo de los Palmares o el Quilombo de Macaco o los simarrones en Colombia como el "Palenque".

El control directo de Europa comenzó a decaer el 4 de julio de 1776 con la declaración de Independencia de los Estados Unidos ante la corona británica, aunque siempre hubo insurrecciones e inconformidad por parte de los nativos, dicho acontecimiento sería un aliciente más para la emancipación de las restantes colonias del continente.

El proceso de independencia en América Latina empezó a principios del siglo XIX, si bien a mediados del siglo XVIII comenzaron las primeras revoluciones "Comuneras" contra el poder español. Entre ellas destacan los "Comuneros del Paraguay", 1735 y la Insurrección de los comuneros en el Virreinato de la Nueva Granada. El nombre de "comuneros" se debe al lema de José de Antequera y Castro: ""La voluntad del común es superior a la del propio rey"". Si bien los comuneros fueron derrotados originalmente (por ejemplo los del Paraguay en la "Batalla de Tavapy") poco a poco los diferentes países bajo dominio español obtuvieron su independencia.

El 25 de mayo de 1809 con la Revolución de Chuquisaca se inició la Guerra de Independencia Hispanoamericana que finalizaría en 1824 con la Batalla de Ayacucho. Al finalizar la misma, España había perdido prácticamente todas sus colonias en América, con excepción de las islas de Cuba y Puerto Rico.

Los territorios independizados darían origen luego de complejos procesos a 15 nuevas naciones independientes. Paraguay, Bolivia, Colombia, Costa Rica, Chile, Ecuador, El Salvador, Guatemala, Honduras, México, Nicaragua, Argentina, Perú, Uruguay y Venezuela. En 1844 y 1898 el proceso se completaría con la independencia de República Dominicana y Cuba, respectivamente.

En los primeros años después de la independencia se registran varios intentos de conformar grandes estados nacionales en Hispanoamérica. En 1819 se conformó un gran estado independiente sudamericano, denominado Gran Colombia, y que abarcó los territorios de los actuales Panamá, Colombia, Venezuela y Ecuador. La República se disolvió en 1830. En 1816 se conformaron las Provincias Unidas del Río de la Plata como gran estado sudamericano, incluyendo una gran parte del Alto Perú que luego integró Bolivia, y la Banda Oriental que luego se independizó como República Oriental del Uruguay. Entre 1837 se formó la Confederación Perú-Boliviana que se disolvió dos años después. En 1823 se formaron las Provincias Unidas del Centro de América que se disolvieron en 1839 para formar Costa Rica, Nicaragua, El Salvador, Honduras y Guatemala.

Un estado que logró la independencia de manera pacífica en este periodo fue el Brasil. A raíz de las Guerras Napoleónicas, la capital fue trasladada de Lisboa a Río de Janeiro implicándose con ello la asignación de la categoría de "reino" a Brasil, un reino dentro del Reino Unido de Portugal, Brasil y Algarve (1807 – 1821). Al disolverse pacíficamente tal reino surgió el "Imperio de Brasil". La independencia fue proclamada el 7 de septiembre de 1822 por el hijo del rey de Portugal, Pedro I, que estableció una monarquía constitucional, de economía basada en el trabajo esclavista. Durante el siglo la mano de obra esclava fue gradualmente sustituida por inmigrantes europeos, sobre todo alemanes e italianos. Otro país que logró la independencia de manera pacífica fue el Paraguay.

Los grandes protagonistas de este periodo en América fueron George Washington, Simón Bolívar, José de San Martín, Miguel Hidalgo y Costilla, Agustín de Iturbide y otros que son considerados los "padres" de las patrias americanas contemporáneas por sus luchas contra el dominio colonial. La mayor parte de los países caribeños y Canadá se independizaron durante el siglo XX.

En 1868 la flota de España atacó las costas de Chile y Perú en razón de un conflicto colonial. También restableció brevemente su dominación en Santo Domingo, entre 1861 y 1865, y mantuvo control sobre Puerto Rico y Cuba hasta 1898. En 1888-1889 Brasil abolió la esclavitud y luego la monarquía para establecerse como república.

Los diferendos limítrofes provocaron guerras constantes entre las nuevas repúblicas de América a lo largo de las décadas posteriores. Las más destacadas fueron la Guerra del Pacífico (1879-1884, Chile contra Bolivia-Perú) y la Guerra de la Triple Alianza (1865-1870, Argentina-Brasil-Uruguay contra Paraguay). Esta última terminó con una derrota total de Paraguay, que conllevó incluso un desastre demográfico: la población del país, aproximadamente 525.000 personas antes de la guerra, fue reducida a unos 221.000 en 1871, de los que solamente unos 28.000 eran hombres. La consolidación de las nuevas repúblicas no fue pacífica en cambio. No sólo las luchas limítrofes, sino guerras civiles sacudieron los cimientos de los nuevos estados. El expansionismo de países como Estados Unidos que cercenó el territorio de México; Brasil que impuso su soberanía en los territorios amazónicos aún a costa de correr las fronteras de sus vecinos, los conflictos territoriales entre Perú, Bolivia y Chile; la creación del Uruguay, la desintegración de la Gran Colombia que crearía tres nuevos estados: Colombia, Venezuela y Ecuador, son la prueba de una época convulsa causada por la desaparición de las colonias. Esta época de grandes cambios para el continente que trajo el siglo XIX entre independencia y consolidación terminaría todavía con la construcción del canal de Panamá, un canal interoceánico que partió el continente en dos, a costa de cercenar el territorio colombiano y crear un nuevo estado, Panamá (1903), bajo la creciente influencia de una nueva potencia: Estados Unidos.
El Siglo XX en América representó una época de grandes cambios e interacciones. El continente que había estado aislado del resto del planeta por siglos, era ahora uno de los más célebres, de los más visitados, de los más mencionados. Seguía siendo el "Nuevo Mundo" y el territorio de las oportunidades. Los Estados Unidos especialmente tendría un papel central en el desarrollo de la ciencia y la tecnología: el cine de Hollywood conquistaría el mundo, el jazz, Elvis Presley, el rey del "Rock'N Roll", los inventos, Broadway, los monopolios, los viajes espaciales y otros tantos factores. El cine mexicano, argentino y brasileño serían la contraparte, Carlos Gardel, el rey del tango, el boom de la literatura hispanoamericana con autores a la altura de los grandes clásicos universales como Gabriela Mistral, Pablo Neruda, Jorge Luis Borges, Gabriel García Márquez, Mario Vargas Llosa y otros, artistas de renombre mayor como Fernando Botero, Diego Rivera, Frida Kahlo, Reverón, Torres García, y centenares de nombres en la pintura, la escultura, las artes escénicas, el cine. El continente de las razas y de las culturas, harían que el siglo XX se hiciera de una u otra forma, americano.

El siglo XX se caracterizó por dos fenómenos contradictorios, por un lado Estados Unidos y Canadá establecieron libres democracias estables firmemente, mientras que el resto del continente sufrió en muchos de sus países diversos tipos de dictaduras y hombres temibles de todo tipo. Si bien debe señalarse que las elecciones en Estados Unidos entre finales del siglo XIX y XX eran altamente fraudulentas, y en México el sistema demográfico desembocó en un régimen autoritario sin alternancia democrática en la presidencia. Algunas fuentes explican que no es casual esta división, y que esta inestabilidad política es consecuencia de un proceso económico y político de injerencia estadounidense aliada a las clases dirigentes de cada país latinoamericano. A finales del siglo que la mayor parte del continente logró hacerse de gobernantes elegidos democráticamente, aunque no en todas las circunstancias se han establecido instituciones duraderas. El desarrollo económico de los Estados Unidos haría de ese país ya desde principios de siglo la meca de la inmigración, sobre todo desde Europa y Asia, junto a los países rioplatenses de Argentina y Uruguay.

En menor medida el resto de los países americanos no fueron ajenos a esa nueva oleada de pueblos que "colonizaban" a su forma el Nuevo Mundo. El desarrollo industrial del norte del continente que haría de Estados Unidos una potencia mundial, crearía una desface de frente a un sur empobrecido. La emigración de latinoamericanos hacia este país aumentaría con el paso de las décadas hasta convertirlos como la segunda ""minoría"" en su territorio. El canal de Panamá, inaugurado en 1914, con su ubicación en el punto más angosto entre el mar Caribe y el océano Pacífico, tuvo un efecto de amplias proyecciones al acortar la distancia y tiempos de comunicación marítima, produciendo adelantos económicos y comerciales que beneficiarían especialmente a Estados Unidos. El liberalismo económico se abriría cancha en Latinoamérica especialmente después de la crisis económica de 1929, pero en numerosos países serían las clases altas y dirigentes los beneficiarios ante una campesinado pobre y marginal. Los recursos naturales latinoamericanos estarían en manos de las multinacionales estadounidenses, pero también europeas. La Matanza de la Escuela Santa María de Iquique en 1907 en Chile y la "Masacre de las Bananeras", protagonizada por la United Fruit Company en 1928 en Colombia, son dos de los muchos ejemplos de cómo fueron las políticas del desarrollo económico en Latinoamérica. La guerra del Chaco (1932 - 1935) entre Bolivia y Paraguay por el control del río Paraguay, terminó con la victoria paraguaya y dejó a ambos como los más pobres de este subcontinente hacia finales del siglo XX.

El 9 de abril de 1948 fue asesinado el caudillo popular Jorge Eliécer Gaitán en Bogotá, lo que desbocaría a Colombia en un conflicto político por el resto del siglo. El 22 de noviembre de 1963 otros magnicidios atentarían contra las intenciones de cambiar una realidad política desfasada en el continente, la falta de derechos de los afro-americanos en Estados Unidos: es asesinado el presidente estadounidense John Fitzgerald Kennedy y el líder político Martin Luther King. Hacia finales del siglo, América contaba con varios de los países más pobres del mundo como Haití, Bolivia y El Salvador, entre otros o países en donde convivía el primer con el tercer mundo como Brasil, Argentina, Colombia y México, toda esta realidad en el mismo continente del país más rico del mundo. La idea de ver a ""Latinoamérica como el patio trasero de los Estados Unidos"" según el presidente estadounidense Ronald Reagan se convirtió en el resumen de lo que fue la historia del continente durante el siglo XX y el cumplimiento de la profecía del Libertador Simón Bolívar:

Durante la Primera y Segunda Guerra Mundial, el continente se mantuvo a salvo de la ola destructiva que arrasó Europa, Asia y África y se volvió una vez más receptor natural de cientos de refugiados. Con el fin del conflicto, el 30 de abril de 1948, se funda la Organización de los Estados Americanos. El 25 de abril de 1945 se celebró la primera conferencia en San Francisco de la Organización de las Naciones Unidas para garantizar la paz del mundo, la cual tendría como sede definitiva a la ciudad de Nueva York. La Organización de los Estados Americanos se fundaría el 30 de abril de 1948 en Bogotá como culmen de un largo ideal comenzado en 1890 con la "Primera Conferencia Internacional Americana", efectuada en la ciudad de Washington D.C., que se convertiría en 1910 en la "Unión Panamericana". La Carta de la OEA confirmó el respaldo a metas comunes y respeto a la soberanía de cada uno de los países del continente.

El comandante Neil Armstrong fue el primer ser humano que pisó la superficie de la luna el 20 de julio de 1969 al Sur de "Mar de la Tranquilidad", ("Mare Tranquilitatis"). Armstrong, nacido en Ohio en 1930, viajó con otros dos compañeros en la misión Apollo 11.

Pero la llamada guerra fría tendría consecuencias nefastas en suelo americano. En el primer lustro de los años 1960 el régimen implantado en Cuba por Fidel Castro y el Che Guevara, entre otros, orientó la política de su país hacia la Unión de Repúblicas Socialistas Soviéticas (URSS), de la cual pasó a ser un incondicional aliado en detrimento de los intereses geoestratégicos de Estados Unidos. La situación tuvo su punto más dramático en la "Crisis de los misiles de Cuba" que llevó a la humanidad a estar más cerca que nunca de una "tercera guerra mundial", pero que pudo evitarse gracias a la voluntad de Nikita Jrushchov y John F. Kennedy. Como consecuencia, estalló el conflicto armado en Colombia en 1964, hubo más series de violentos regímenes dictatoriales en diversos países de América Latina: Brasil (1964), Argentina (1968 y 1976), Chile (1973), Uruguay (1973), Bolivia (1980), además del estallido del conflicto armado en el Perú en 1980.

El 4 de abril de 1968 otro magnicidio sacudió al continente: era asesinado el Dr. Martin Luther King, Jr. en Memphis, uno de los grandes activistas del Movimiento por los Derechos Civiles en Estados Unidos para los afroamericanos, laureado con el . Organizó y llevó a cabo marchas por el derecho al voto, la no discriminación, y otros derechos civiles básicos. La mayoría de estos derechos fueron promulgados en las leyes de los Estados Unidos con la aprobación del Acta de los Derechos Civiles y el Acta de los derechos de votación. Es tal vez más famoso por su discurso "I Have a Dream (Yo tengo un sueño)" dado en frente del Monumento a Lincoln durante la Marcha en Washington por el trabajo y la libertad en 1963. King es recordado como uno de los mayores líderes y héroes de la historia de Estados Unidos, y en la moderna historia de la no violencia.
Después del fin de la guerra fría con la caída del Muro de Berlín, el continente vio el avance del Neoliberalismo, un conjunto de propuestas político-económicas con énfasis en la libre circulación de capitales, la privatización de empresas públicas y el desmantelamiento del "Estado Benefactor". Los padres de dichos procesos fueron el Banco Mundial, la Organización Mundial del Comercio y el Fondo Monetario Internacional (FMI). Dichas políticas que obedecen a una más compleja red del mercado internacional, si bien puso fin a gobiernos de facto como las dictaduras latinoamericanas, generó por ejemplo la crisis financiera argentina a partir de 1998 que crearía una alarma económica continental

Otra característica del fin de siglo, especialmente en la década de los 80, sería el fortalecimiento financiero de las mafias de la droga que tuvieron como epicentro Colombia, México y Estados Unidos, especialmente. La mafia, ligada a la droga, adquirió un enorme poder económico que llegó incluso a ser un verdadero poder paralelo al Estado. Uno de los nombres claves de la época, que llegó a proporciones de mito, fue el de Pablo Escobar, que, aparte de su enriquecimiento ilícito, y de acuerdo de la edición de 1985 de la Revista Forbes, llegó a ser el quinto "hombre más rico del mundo", con la capacidad de poner en jaque la política colombiana y crear un conflicto internacional que involucró a otros países americanos en la llamada "guerra contra el narcotráfico".

El 2001 marcó el inicio de un nuevo milenio y un nuevo siglo. Si el siglo XX no fue el siglo de la paz y la prosperidad continental, la manera en la que irrumpió la nueva data cronológica no auguró mejores tiempos. El 11 de septiembre de 2001 tendrían lugar los ataques suicidas que implicaron el secuestro de cuatro aviones de pasajeros, que fueron empleados como bombas aéreas dejando alrededor de 3.000 muertes. Las Torres Gemelas del Centro Mundial de Comercio (WTC por sus siglas en inglés), fueron destruidas y el Pentágono resultó dañado. La historia se precipitaría para el mundo entero: el presidente George W. Bush iniciaría las invasiones de Afganistán e Irak y Oriente y Occidente se verían enfrentados en un conflicto que despertó viejas disputas, abrió la perspectiva a nuevas ambiciones y creó nuevas situaciones históricas.

Las siguientes son los grandes bloques económicos en el continente, aunque existen numerosos tratados bilaterales:


Historia del siglo XX




</doc>
<doc id="1450" url="https://es.wikipedia.org/wiki?curid=1450" title="Historia de Oceanía">
Historia de Oceanía

El poblamiento humano de Oceanía se produjo en varias oleadas. Los primeros pobladores de Oceanía fueron Homo sapiens procedentes del sureste de Asia. De ellos descienden los actuales papúes y nativos australianos. El poblamiento de Australia y Nueva Guinea se remonta al 40 000 a.C.

Una segunda oleada mucho más reciente, es la que pobló el resto de islas del pacífico. Esta segunda oleada humana fue la de los pueblos austronesios (iniciada entre el 3000 a. C. y el 2000 a. C.), también de origen asiático, más concretamente procedentes de Taiwán. Los austronesios fueron grandes navegantes y fueron los primeros pobladores de muchas partes de Oceanía, en particular de Polinesia, Nueva Zelanda o Hawái'i, llegaron al menos tan lejos como la Isla de Pascua. El poblamiento de Micronesia y Polinesia, se prolongó durante tres milenios desde el 2000 a. C. hasta el I milenio d. C.. Nueva Zelanda por ejemplo fue poblada entre el s. IX y XIV por los maoríes.

En el 950 d. C. el Imperio Tu'i Tonga dominó la mayoría de las islas de Oceanía, en sus comienzos los reyes lograron deshacerse del dominio extranjero y consolidó el poder del imperio en lo que hoy es Tonga. Cerca al año 1200 comenzó su expansión que se dio hasta, aproximadamente el 1500. El imperio conquistó lo que hoy en día se conoce como Fiyi, partes de Samoa y otras islas de la polinesia como las Islas Cook y Niue. La gran habilidad para construir canoas y el buen sistema aplicado a las invasiones facilitó que Tu'i Tonga se estableciera en más islas aún. 

Cercano al año 1500 se desataron muchos problemas en la realeza del imperio que debilitó su figura en las colonias, que consiguieron mucha autonomía de la corona real y el poder central. En 1799 fue asesinado Tuku'aho, el rey que poseía el poder en ese momento, lo que desató una terrible guerra civil. Ya con la presencia europea la guerra civil terminó de devastar a los dos bandos, dejando al imperio diezmado en manos de la corona británica.

Antes de que Cristóbal Colón llegara a América (1492), el entonces ‘hatun auqui’ (príncipe conquistador) Túpac Yupanqui –en el futuro se convertiría en el décimo gobernante de la civilización inca– emprendío una expedición a la Polinesia. La misión era encontrar nuevas especies de animales y plantas que podrían resultar útiles para el imperio. Tenía tan solo 25 años.
Túpac Yupanqui luego de obtener el control de la isla Puná (Ecuador), a la que llegó en balsa, recibió noticias de la existencia de dos islas lejanas Auachumbi y Ninachumbi, que albergaban una gran variedad de recursos.

Con 120 embarcaciones y 20 000 hombres, el joven príncipe inició su aventura a estas dos islas, que se tratarían de Mangareva y Rapa Nui (Isla de Pascua). También llegaría a Nuku Hiva, en el archipiélago de Las Marquesas. Luego de la espectacular travesía retorno al Cusco, capital del Tahuantinsuyo. El viaje le habría tomado aproximadamente año y medio

Los cronistas Pedro Sarmiento de Gamboa, Martín de Murúa y Miguel Cabello de Balboa –que vivieron en el virreinato del Perú en el siglo XVI– coinciden con este relato y son la únicas fuentes de este acontecimiento. Sumado a que en la isla de Mangareva existe una leyenda sobre un rey Tupa, que vino del este en balsas con velas, trayendo orfebrería, cerámica y textilería y del que hasta hoy existe una danza.

En el primer viaje de circunnavegación del globo, Fernando de Magallanes divisó las Islas Marianas y otras islas de Oceanía en 1521, antes de encontrar su muerte en las Filipinas en la isla de Mactan en una refriega con los naturales del país. Independientemente, el portugués Cristovão de Mendonça llegó a Botany Bay (Australia) en el año 1522, costas también visitadas tres años después por Gomes de Sequeira. Poco después otros marinos portugueses se unieron a la explotación de la región; en 1525 Diego de Rocha descubrió las islas Carolinas, visitadas al año siguiente también por Toribio Alonso de Salazar, y en 1526 Jorge de Meneses arribó a Nueva Guinea. Otros exploradores de la región en esta época fueron Luis Váez de Torres, Miguel López de Legazpi, García Jofre de Loaísa, Álvaro de Mendaña y Ruy López de Villalobos.

También los holandeses navegaron la región, y Abel Tasman recorrió el litoral de Australia en 1642, arribando a la isla que en su honor se llamó Tasmania y las islas, Tonga, Fiyi y Nueva Guinea Alemana. Entre tanto desde Acapulco (México) y Callao (Perú) partieron expediciones que hallaron numerosas islas del Pacífico.

Las rivalidades portuguesas, españolas y holandesas fueron reemplazadas por la de los ingleses y franceses en el siglo XVIII. Entre 1764 y 1770 exploraron la zona John Byron, Samuel Wallis, Philip Carteret y otros, quienes recorrieron Tahití, Samoa, Islas Salomón y Nuevas Hébridas. Por su parte, el inglés James Cook realizó tres viajes por islas de Pacífico entre 1768 y 1779, y llegó a las Islas de la Sociedad, Nueva Zelanda, Islas Marquesas, Nuevas Hébridas y Hawái. 

El 6 de abril de 1772, el día de Pascua Jacobo Roggeveen, un navegante neerlandés avistó la Isla de Pascua, descubriéndola de manera oficial, aunque una expedición enviada desde Callao, el 10 de octubre de 1770, avistó la isla el 15 de noviembre. Se realizó una circunnavegación para poder cartografiar la isla. Los navegantes quedaron muy sorprendidos por las estatuas de gran tamaño, los Moái. En otras expediciones también los marines se sorprendieron de la gran altura de algunos nativos, que llegaban a medir 2,17 metros. Además, los hombres eran muchos más numerosos que las mujeres en aquella isla, la diferencia era muy notoria. Los nativos vivían en cuevas y estaban llenos de tatuajes, los nativos de la Isla de Pascua fueron una de las etnias que más sorprendió a los colonizadores europeos.

Los franceses exploraron las islas simultáneamente con los ingleses. Entre 1826 y 1840 lo hizo Jules Dumont D'Urville y luego Jean-François de La Pérouse entre 1785 y 1787. Todos estos viajes determinaron el reparto de Oceanía entre las potencias colonizadoras: Reino Unido, Holanda, Francia, España, Portugal, Estados Unidos y Alemania en menor medida..

A finales del siglo XIX y comienzos del XX comenzaron los deseos de independencia en las colonias, Australia y Nueva Zelanda, en 1901 y en 1907 abrieron el camino a los demás países hacia la independencia. Los países más débiles y pobres tardaron mucho en declararse independientes, en 1962, Samoa declaró la independencia de Nueva Zelanda, que la había ocupado años atrás, luego Nauru en 1968, Fiyi y Tonga en 1970, Islas Salomón y Tuvalu en 1978, los Estados Federados de Micronesia y Kiribati en 1979 (aunque reconocida en 1990 para Micronesia), Vanuatu en 1980, Islas Marshall en 1990 y Palaos en 1994 los siguieron en el proceso de libertad. Formaron el Foro de las Islas del Pacífico y aún hoy intentan ayudar a países como Guam, Nueva Caledonia y Polinesia Francesa que todavía están bajo el mandato de potencias.



</doc>
<doc id="1452" url="https://es.wikipedia.org/wiki?curid=1452" title="Historia de África">
Historia de África

La historia de África se refiere al conjunto de sucesos relativos al poblamiento humano del continente africano, desde los orígenes de los seres humanos hasta la actualidad.

La prehistoria de África comienza con el surgimiento de los primeros homínidos hace unos cinco millones de años, por lo que el período prehistórico en África incluye hechos mucho más antiguos que la historia de los otros continentes poblados por seres humanos mucho más tardíamente.

El período propiamente histórico de la Edad Antigua en África incluye la aparición de la civilización egipcia, el posterior desarrollo de las sociedades fuera del valle del Nilo y la interacción entre ellas y las civilizaciones fuera de África. A fines del siglo VII el norte y este de África fueron fuertemente influenciados por la expansión del islam, propiciando la aparición de nuevas culturas, tales como los pueblos suajili. Esto también incrementó el tráfico de esclavos (previamente existente) y que culminaría formalmente en el siglo XIX. La historia africana precolonial se enfoca en la época que transcurre entre comienzos del siglo XVI, caracterizada por el traslado de grandes cantidades de pobladores africanos en calidad de esclavos al Nuevo Mundo, hasta el inicio de la disputa europea por África. El periodo colonial africano transcurrió desde finales de los años 1800 hasta el advenimiento de los movimientos independentistas en 1951 cuando Libia se convirtió en la primera colonia africana en ganar su independencia. La historia africana moderna ha estado plagada de revoluciones y guerras, contando también, no obstante, con el crecimiento de las economías de algunas naciones africanas a lo largo del continente.

La historia africana ha sido un reto para los investigadores dada la escasez de fuentes escritas en grandes partes del África subsahariana, y también debido a las opiniones contrastantes sobre lo que es y no es africano. Algunas técnicas de estudio como el registro de la historia oral, la arqueología, la paleontología lingüística y la genética —para rastrear el movimiento de los pueblos— han sido cruciales a la hora de escribir la historia de varias regiones africanas que en el pasado había sido un misterio.

Según se dice en las últimas exploraciones paleontológicas y arqueológicas, los homínidos ya existían en África hace por lo menos 5 millones de años. La anatomía de su cráneo era similar a la de sus parientes cercanos, los grandes simios africanos, pero habían adoptado una forma bípeda de locomoción, la cual les otorgaba una ventaja crucial, pues les permitía vivir tanto en áreas boscosas como en la sabana en una era en la que África se estaba volviendo árida, con las sabanas superponiéndose a los bosques y selvas. 

Hace unos 3 millones de años varias especies de homínidos del género "Australopithecus" habían surgido a lo largo del sur, este y centro de África. El siguiente gran paso evolutivo ocurrió hace aproximadamente 2 millones de años con la llegada del "Homo habilis", la cual se cree que fue la primera especie de homínido capaz de fabricar herramientas. Esto le permitió a "H. habilis" comenzar a comer carne. En la cacería, "H. habilis" no era capaz de competir con grandes depredadores, y seguía siendo más presa que cazador, aunque probablemente podía robar huevos de nidos y pudo haber sido capaz de capturar pequeños animales.

Hace 1,8 millones de años, "Homo erectus" apareció por primera vez en África, aunque de igual forma lo hizo casi simultáneamente en el Cáucaso (Europa Oriental). Algunos de los primeros representantes de esta especie seguían teniendo cerebros bastante pequeños y usaban primitivas herramientas de roca, de forma muy similar a "H. habilis". Su cerebro más adelante creció y "H. erectus" terminó desarrollando una tecnología de herramientas más compleja, de tipo achelense. Posiblemente fueron los primeros grandes cazadores. Además, "Homo erectus" dominó el arte de producir fuego, y fue el primer homínido en salir de África, expandiéndose por todo el Viejo Mundo. También se ha sugerido que "Homo georgicus", un descendiente de "Homo habilis", pudo ser el primero homínido y el más primitivo en vivir fuera de África. No obstante, muchos científicos consideran al "Homo georgicus" como un miembro anterior y más primitivo de la especie "Homo erectus".

El registro de fósiles muestra que "Homo sapiens" pudo haber vivido en el sur y este de África hace al menos 100.000 y posiblemente 150.000 años. Hace unos 40.000 años comenzó la colonización de nuestro planeta por los seres humanos modernos con su expansión hacia fuera de África. Su migración es indicada por evidencias lingüísticas, culturales y genéticas.

Al final de la Edad de Hielo (alrededor del 10.500 a. C.), el Sahara se había convertido de nuevo en un fértil valle, y su población africana regresó del interior del continente y de las montañas costeras en el África subsahariana. Sin embargo, el clima cada vez más seco y cálido hizo que para el año 5000 a. C. la región del Sahara se fuera volviendo cada vez más árida. La población se desplazó fuera de la zona dirigiéndose hacia el valle del Nilo, donde crearon asentamientos permanentes o semipermanentes. Una recesión climática mayor ocurrió, disminuyendo las fuertes y persistentes lluvias en África central y oriental; desde entonces las condiciones secas han prevalecido en el este de África.

El fenómeno internacional conocido como la cultura del vaso campaniforme comenzó a afectar a África noroccidental. Llamada así por las vasijas de cerámica de forma característica encontradas en tumbas, la cultura del vaso campaniforme está asociada con el surgimiento de una mentalidad guerrera. El arte rupestre de este periodo en el norte de África representa animales pero también pone un nuevo énfasis en la figura humana, equipada con armas y adornos. La gente procedente de la región de los Grandes Lagos de África se asentó a lo largo de la costa oriental del Mar Mediterráneo para convertirse en los proto-canaanitas, quienes dominaron las tierras bajas entre el río Jordán, el Mediterráneo y el Desierto de Sinaí.

Grabados en roca del Neolítico, conocidos como petroglifos, y los megalitos en el desierto del Sahara en Libia dan fe de la prematura cultura cazadora-recolectora establecida en las secas praderas de África del Norte durante la Glaciación. La región donde actualmente se encuentra el Sahara fue originalmente un buen sitio para la agricultura (cerca del año 4000 a. C.). No obstante, después de la desertificación del Sahara, el establecimiento en el norte de África se concentró en el valle del Nilo, donde los nomos de Egipto sentaron las bases para la cultura del Antiguo Egipto. Hallazgos arqueológicos muestran que las tribus primitivas vivieron a lo largo del Nilo mucho antes de que la historia dinástica de los faraones comenzara. Para el año 6000 a. C. había aparecido la agricultura organizada.

Las evidencias más antiguas de historia escrita en África provienen del Antiguo Egipto, y el calendario egipcio sigue siendo usado como el patrón para datar a las culturas de la Edad del Bronce y la Edad de Hierro en la región.

Alrededor del año 3100 a. C. Egipto fue unificado bajo el primer faraón conocido, Narmer, quien inauguró la primera de las 31 dinastías en las que se divide la historia del Antiguo Egipto, las cuales se agrupan en tres fases: Imperio Antiguo, Imperio Medio e Imperio Nuevo. Las Pirámides de Guiza (cerca de El Cairo), construidas durante la cuarta dinastía, dan fe del poder de la religión y el gobierno faraónicos. La Gran Pirámide, que es la tumba del faraón Keops (también conocido como Jufu), es la única de las Siete Maravillas del Mundo que aún se mantiene en pie. El Antiguo Egipto alcanzó su máximo poder, riqueza y extensión territorial en el periodo del Nuevo Imperio (1567-1085 a. C.).

La importancia del Antiguo Egipto en el desarrollo del resto de África se ha debatido. Los antiguos académicos de occidente generalmente veían a Egipto como una civilización mediterránea con poco impacto sobre el resto de África. Los estudios recientes, no obstante, han comenzado a desacreditar esta noción. Algunos han argumentado que varios egipcios antiguos, como los badarienses, probablemente migraron hacia el norte desde Nubia, mientras que otros hablan de un movimiento de pueblos de gran envergadura a lo largo y ancho del Sahara antes del comienzo de la desertificación. Sea cual sea el origen de cualquier pueblo o civilización, parece razonablemente seguro que las comunidades predinásticas del valle del Nilo eran esencialmente indígenas en su cultura, recibiendo poca influencia por parte de fuentes externas del continente durante varios siglos precediendo directamente al comienzo de los tiempos históricos.

Justo antes de la desertificación del Sahara, las comunidades que se desarrollaron al sur de Egipto, en lo que hoy en día es Sudán, fueron plenos partícipes en la Revolución Neolítica y tuvieron un estilo de vida entre sedentario y seminómada, pudiendo domesticar plantas y animales. Megalitos encontrados en Nabta Playa son ejemplos de lo que probablemente fueron los primeros instrumentos arqueoastronómicos del mundo, unos 1000 años más antiguos que Stonehenge. Esta complejidad, como fue observada en Playa Natba y expresada por diferentes niveles de autoridad dentro la sociedad del lugar, posiblemente sentó las bases para la estructura tanto de la sociedad neolítica en Nabta Playa como del Imperio Antiguo de Egipto. Los pobladores pertenecientes al llamado "Grupo A", quienes habitaron el actual norte de Sudán y fueron contemporáneos del Naqada predinástico en el Alto Egipto, fueron responsables de lo que puede haber sido uno de los reinos más antiguos conocidos en el valle del Nilo, al que los egipcios llaman "Ta-seti" (Tierra del arco). Su desaparición con el surgimiento del Egipto dinástico más tarde permitió el surgimiento de reinos como Kush, Kerma y Meroe, los cuales en conjunto comprendían lo que en ocasiones es llamado Nubia. El último de ellos vería su devastador golpe final dado por el líder de un reino creciente en Etiopía, Ezana de Aksum, llevando efectivamente a su fin a las civilizaciones nubianas clásicas.

Separadas por el "mar de arena" —el Sahara—, el África septentrional y el África subsahariana han estado conectadas por las fluctuantes rutas comerciales transaharianas. Las historias fenicia, griega y romana en el norte de África pueden ser seguidas a través de textos acerca del Imperio romano y de sus provincias en el Magreb, tales como Mauritania, África, Tripolitania, Cirenaica, Egipto, etc.

Las regiones alrededor del Mediterráneo fueron colonizadas y pobladas por los fenicios antes del año 1000 a. C. Cartago, fundada cerca del año 814 a. C., creció rápidamente hasta convertirse en una ciudad sin rivales en el Mediterráneo. Los fenicios sometieron a las tribus bereberes, las cuales constituían la mayor parte de la población local, convirtiéndose en los dominadores de toda la región habitable en África del Norte, y hallando en el comercio una fuente de inmensa prosperidad.

Para el primer milenio a. C., el trabajo del hierro había sido introducido en el norte de África y rápidamente se comenzó a expandir a través del Sahara hacia las regiones septentrionales del África subsahariana, y para el año 500 a. C., la metalurgia empezó a volverse común en África occidental, posiblemente después de ser introducida por los cartagineses. El trabajo del hierro fue establecido plenamente alrededor de 500 a. C. en áreas de África oriental y occidental, a pesar de que en otras regiones no se comenzó a realizar esta actividad hasta los primeros siglos de nuestra era. Algunos objetos de cobre originarios de Egipto, el norte de África, Nubia y Etiopía se han hallado en el oeste de África, datando de alrededor del año 500 a. C., sugiriendo que las redes comerciales ya habían sido establecidas en aquella época.

Los griegos fundaron la ciudad de Cirene en la Antigua Libia alrededor del año 631 a. C. Cirenaica se convirtió en una floreciente colonia, aunque al estar completamente rodeada por desiertos tuvo poca o nula influencia sobre el interior de África. Los griegos, no obstante, ejercían una fuerte influencia sobre Egipto. La ciudad de Alejandría fue fundada por Alejandro Magno en 332 a. C., y bajo el mando de la dinastía helenística de los ptolemaicos se hicieron intentos por penetrar hacia el sur, y de esta forma se obtuvo cierto conocimiento de Etiopía.

Entre los años 500 a. C. y 500 d. C. aproximadamente, la civilización de los garamantes (posiblemente los ancestros de los tuareg) existió en lo que hoy en día es el desierto libio.

Las tres potencias —Cirenaica, Egipto y Cartago— terminarían siendo desplazadas por los romanos. Después de siglos de rivalidad con Roma, Cartago finalmente caería en 146 a. C. Dentro de poco más de un siglo Egipto y Cirene se incorporaron al Imperio romano. Bajo el dominio de Roma, las porciones pobladas de la región fueron muy prósperas. A pesar de que Fezzan fue ocupado por ellos, los romanos hallaron en el resto del Sahara una barrera impenetrable. Nubia y Etiopía fueron alcanzadas, pero una expedición enviada por Nerón para descubrir el nacimiento del Nilo fracasó. La mayor extensión de conocimiento geográfico mediterráneo del continente africano se muestra en los escritos de Ptolomeo (siglo II), quien conocía o intuía la existencia de las grandes reservas acuíferas del Nilo, de puestos comerciales a lo largo de las costas del Océano Índico en lugares tan al sur como Rhapta —en la actual Tanzania—, y había oído hablar del río Níger.

La interacción entre Asia, Europa y África del Norte durante este periodo fue significativa. Algunos efectos importantes incluyen la difusión de la cultura clásica alrededor de las costas del Mediterráneo; la continua lucha entre Roma y las tribus bereberes; la introducción del cristianismo en toda la región, y los efectos culturales de las iglesias en Túnez, Egipto y Etiopía. La era clásica llegó a su fin con la invasión y conquista de las provincias romanas en África por parte de los vándalos en el siglo V. El poder en la región regresaría al siglo siguiente al Imperio bizantino.

Los árabes musulmanes conquistaron el norte de África desde el Mar Rojo hasta el Océano Atlántico y continuaron hacia España, comenzando con la invasión de Egipto en el siglo VII. A lo largo del norte de África el cristianismo prácticamente desapareció, excepto en Egipto donde la Iglesia Copta permaneció sólida, en parte debido a la influencia de Etiopía. Algunos argumentan que cuando los árabes hubieron convertido Egipto intentaron acabar con los coptos, pero Etiopía —donde también se practicaba esta religión— le advirtió a los musulmanes que si intentaban acabar con los coptos, reducirían el flujo del agua del Nilo que corría hacia Egipto. Esto se debía a que el Lago Tana era la fuente del Nilo Azul, mismo que fluye hacia la corriente principal del Nilo. Algunos creen que esta es una de las razones por las que las minorías coptas aún existen hoy en día.

Alrededor del año 3000 a. C. la agricultura surgió independientemente en Etiopía, con cultivos como el café, teff, mijo dedo, sorgo, cebada y ensete. Los burros también fueron domesticados independientemente en la región de Etiopía y Somalia, pero la mayoría de los animales domesticados llegaron ahí desde las regiones del Sahel y el Nilo. Algunos cultivos también fueron adoptados de otras regiones en esta época, entre ellos se pueden mencionar el mijo perla, caupí, algodón, sandía y porongo, mismos que comenzaron a ser cultivados tanto en África occidental como en la región de Sahel mientras que el mijo dedo, guisante, lenteja y lino se asentaron en Etiopía.

Etiopía tenía una cultura antigua diferente con una historia intermitente de contacto con Eurasia después de la diáspora de homínidos hacia el exterior de África. Conservaba un lenguaje, cultura y sistema de cultivo únicos. El sistema de cultivo estaba adaptado a las zonas montañosas del norte y no se aplicaba a ningún cultivo de otras regiones. El miembro más famoso de este sistema de cultivo era el café, pero una de las plantas más útiles era el sorgo, un cereal de tierras áridas; el teff era endémico de la región.

Etiopía tuvo un gobierno centralizado por muchos milenios y el Reino de Aksum, el cual se desarrolló allí, había creado un poderoso imperio comerciante —con rutas comerciales que llegaban a lugares tan lejanos como la India—.

Históricamente, los swahili podían ser encontrados en lugares tan septentrionales como Mogadiscio en Somalia, y tan meridionales como el río Ruvuma en Mozambique. Aunque alguna vez se creyó que eran los descendientes de los colonos persas, los antiguos swahili ahora son reconocidos por la mayor parte de los historiadores, lingüistas históricos y arqueólogos como un pueblo bantú que tuvo importante interacción con mercantes musulmanes desde fines del siglo VII y comienzos del siglo VIII de nuestra era.

El inicio de la agricultura Sahel occidental se sitúa hacia el 5000 a. C. Aunque en el área tropical de África occidental la fecha del inicio de la agricultura se sitúa hacia el año 3000 a. C., donde se empezaron a cultivar de manera independiente palmas aceiteras. También se domestican ñames africanos aunque la ganadería se propaga allí desde el Sahel y la región del Nilo. También fueron adoptados cultivos de otras regiones en esta época, tales como el mijo perla, caupí, maní, algodón, sandía y porongo, comenzando a ser cultivados tanto en África occidental como en el Sahel.

Alrededor del año 1000 a. C., los emigrantes bantúes habían llegado a la región de los Grandes Lagos de África oriental. A mediados de ese milenio, los bantúes también se habían asentado en regiones donde actualmente se encuentran países como Angola y la República Democrática del Congo. Uno de los principales eventos ocurridos en África central durante este periodo fue el establecimiento del Imperio Kanem-Bornu en lo que hoy en día es Chad. El Imperio Kanem florecería en los siglos posteriores poniendo las bases para el surgimiento de futuros grandes estados en la región del Sahel.

La historia del sur de África sigue siendo en gran parte un misterio, debido a su aislamiento de otras culturas del continente. En el año 500 a. C. aquel aislamiento llegó a su fin con el asentamiento de emigrantes bantúes en la actual Zambia. Al sureste, los khoisan, también conocidos como bosquimanos, iniciaron la domesticación del ganado y cambiaron su estilo de vida cazador-recolector que había sido el dominante en la región desde el inicio de los tiempos. Para el año 300 a. C., los bantúes habían llegado al actual territorio de Sudáfrica, sirviendo de base para la aparición de estados centralizados.

Desde antes del I milenio a. C. se había iniciado en África central, una importante expansión bantú, probablemente asociada a la expansión de ciertos cultivos, que alteró profundamente la distribución genética y lingüística del África negra. Dándole una apariencia similar a la actual, donde existe un océano de pueblos que hablan lenguas nigero-congoleñas quedando poblaciones marginales que o bien hablan lenguas no emparentadas con el bantú (khoisano, sandawe, hadza) o tienen marcadores genéticos bastante diferentes de los bantúes comunes (e.g. pigmeos).

La expansión de los bantúes se prolongaría durante los primeros siglos de nuestra era hasta incluso después de la llegada de los exploradores europeos culminando en la formación del reino zulú en África Meridional

En el siglo VII hubo una considerable inmigración árabe, resultando en una gran absorción de la cultura bereber. Incluso antes de esto los bereberes en general habían adoptado la lengua y religión de sus conquistadores. La influencia árabe y la religión islámica se adhirieron indeleblemente al norte de África. Juntas se propagaron hacia el sur, a través del Sahara. También se establecieron firmemente a lo largo de la costa oriental, donde los árabes, los persas y los indios establecieron florecientes colonias, tales como Mombasa, Malindi y Sofala, ejerciendo una influencia análoga a aquella desempeñado en siglos previos por los cartagineses en la costa norte. Hasta el siglo XIV, Europa y los árabes en África del Norte ignoraban la existencia de estas ciudades y estados orientales.

Los primeros inmigrantes árabes habían reconocido la autoridad de los califas de Bagdad, y la dinastía Aglabí —fundada por Aglab, uno de los generales de Harún al-Rashid, a fines del siglo VIII— reinó como vasalla del califato. No obstante, a comienzos del siglo X la dinastía Fatimí se estableció en Egipto donde El Cairo había sido fundado en el año 968, y desde ahí dominó hasta regiones tan lejanas como la costa del Atlántico. Más tarde surgirían otras dinastías como la Almorávide y la Almohade. Eventualmente los turcos, quienes habían conquistado Constantinopla en 1453 y habían tomado Egipto en 1517, establecieron las regencias de Argelia, Túnez y Trípoli (entre 1519 y 1551), permaneciendo Marruecos como un estado bereber arabizado independiente bajo el dominio de la dinastía Sharifan, la cual surgió a fines del siglo XIII.

Bajo el dominio de las dinastías previas, la cultura árabe había alcanzado un alto grado de excelencia, mientras que el proselitismo de los seguidores del islam condujeron a una considerable extensión de esta religión en el continente. Esto se llevó a cabo más fácilmente por el uso del camello (introducido originalmente en África por los conquistadores persas de Egipto), el cual permitió que los árabes pudieran atravesar el desierto. De esta forma las regiones de Senegambia y el centro de Níger se convirtieron en zonas clave para el comercio transahariano y el intercambio de ideas.

El islam también se difundió a través del interior de África occidental, como la religión de los mansas del Imperio de Malí (1235-1400) y muchos gobernantes del Imperio Songhay (1460-1591). Después del legendario hajj de 1324 de Mansa Musa, Timbuctú se volvió célebre como centro de enseñanza islámica teniendo la primera universidad de África subsahariana. La ciudad había sido visitada en 1352 por el gran viajero árabe Ibn Battuta, cuya travesía a Mombasa y Quiloa (Kilwa) proporcionó los primeros conocimientos acertados de aquellas florecientes ciudades musulmanes de los swahili en las costas orientales africanas.

El avance árabe hacia el sur fue detenido por el ancho cinturón de densa selva, desplegándose casi a todo el ancho del continente aproximadamente al sur de la latitud 10° N, y mismo que bloqueó su avance tal como el Sahara lo había hecho con sus predecesores. La selva evitó que supieran de la existencia de la costa de Guinea y del resto de África que se encontraba más allá. Una de las últimas regiones en caer bajo el control de los árabes fue Nubia, la cual había sido dominada por cristianos hasta el siglo XIV.

Por un tiempo las conquistas musulmanes en el sur de Europa prácticamente convirtieron al Mediterráneo en un lago musulmán, pero la expulsión en el siglo XI de los sarracenos de Sicilia y el sur de Italia por parte de los normandos fue seguida por descendientes de los conquistadores de Túnez y Trípoli. Un poco después un fuerte comercio con las costas africanas, y especialmente con Egipto, se desarrolló con Venecia, Pisa, Génova y otras ciudades del norte de Italia. Para fines del siglo XV España había expulsado completamente a los musulmanes, pero aún en la época en la que los moros seguían en Granada, Portugal había sido lo suficientemente fuerte para llevar la guerra hacia África. En 1415 un ejército portugués capturó la ciudadela de Ceuta en la costa mora. De ahí en adelante Portugal interfirió repetidamente en los asuntos de Marruecos, mientras que España adquirió muchos puertos en Argelia y Túnez.

Portugal, no obstante, sufrió una aplastante derrota en 1578 en Alcazarquivir, siendo comandados los moros por Abu Marwan Abd al-Malik I Saadi de la entonces recién establecida Dinastía Saadi. Por ese entonces los españoles habían perdido casi todas sus posesiones africanas. Los Estados berberiscos, primariamente a partir del ejemplo de los moros expulsados de España, degeneraron en meras comunidades de piratas, y bajo la influencia turca la civilización y el comercio decayeron. La historia de estos estados desde inicios del siglo XVI hasta la tercera década del siglo XIX se compone en gran parte de hazañas piratas por una parte y de inútiles represalias por la otra.

El comercio de oro y otros materias primas, propició la formación de aristocracias en la región del Sahel, en que un soberano centralizaba el comercio con la costa norte de África. Entre estos imperios estuvieron el Imperio de Ghana, el Imperio de Malí, el Imperio Songhay, el Imperio Kanem-Bornu o el Imperio Wadai.

En la región de los grandes lagos a partir del siglo XV surgieron reinos bien organizados y centralizados como Bunyoro, Budanda, Ruanda y Burundi. El surgimiento de estos reinos debió mucho al inicio del uso del hierro en la región y a nuevos cultivos como la banana. Ambas innovaciones permitieron una mejora de los rendimientos agrícolas que conllevó un aumento importante de la densidad de población.

Durante el siglo XV Enrique el Navegante, hijo del Rey Juan I de Portugal, planeó adquirir territorio africano para Portugal. Bajo su inspiración y dirección algunos navegantes portugueses emprendieron una serie de viajes de exploración que resultaron en la circunnavegación de África y el establecimiento de la soberanía portuguesa sobre una gran cantidad de zonas costeras.

Las naves portuguesas rodearon al Cabo Bojador en 1434, Cabo Verde en 1445 y para 1480 la totalidad de la costa de Guinea era conocida por los portugueses. En 1482, Diogo Cão llegó a la desembocadura del Congo, el Cabo de Buena Esperanza fue rodeado por Bartolomé Díaz en 1488, y en 1498 Vasco da Gama, después de haber rodeado aquel cabo, exploró la costa oriental, desembarcando en Sofala y Malindi, y de ahí fue hacia la India. Portugal declaró su soberanía en todo punto en que sus navegantes desembarcaran, pero esta no fue ejercida en el extremo sur del continente.

La costa de Guinea, siendo la más cercana a Europa, fue la primera en ser explotada. Numerosos fuertes europeos y establecimientos comerciales fueron fundados, siendo el primero de ellos São Jorge da Mina (Elmina), establecido en 1482. Las principales mercancías comerciadas fueron esclavos, oro, marfil y especias. El descubrimiento europeo de América (1492) fue seguido por un gran desarrollo del tráfico de esclavos, el cual, antes de la era portuguesa, había sido un tráfico por tierra confinado casi exclusivamente al África musulmana. La naturaleza lucrativa de este tráfico y las grandes cantidades de oro aluvial obtenido por los portugueses atrajeron a otras naciones a la costa de Guinea. Los navegantes ingleses llegaron en 1553, y fueron seguidos por los españoles, holandeses, franceses y daneses, entre otros. La supremacía colonial a lo largo de la costa pasó en el siglo XVII de Portugal a los Países Bajos y de los holandeses en los siglos XVIII y XIX a Francia y el Reino Unido. Toda la costa de Senegal a Lagos fue dotada de fuertes y "fábricas" de las potencias europeas, y este panorama internacional persistió hasta el siglo XX aunque todas las tierras interiores del oeste de África se habían vuelto territorio francés o británico.

Al sur de la desembocadura del Congo en la región de Damaraland (en lo que hoy en día es Namibia), los portugueses, de 1491 en adelante, ganaron influencia sobre los nativos, y a comienzos del siglo XVI a través de sus esfuerzos el cristianismo fue adoptado en gran parte del Reino del Congo. Una incursión de tribus del interior más tarde ese mismo siglo acabó con el poder del estado semi-cristiano, y la actividad portuguesa fue transferida en buena parte hacia el sur, fundando São Paulo de Loanda (hoy Luanda) en 1576. Antes de la independencia de Angola en 1975, la soberanía de Portugal sobre esta región costera, excepto en la desembocadura del Congo, solamente había sido desafiada por una potencia europea, los holandeses, de 1640 a 1648 cuando Portugal perdió el control de los puertos marítimos.

El más antiguo tráfico africano de esclavos externo fue transahariano. Aunque hace mucho ya había ocurrido algo de tráfico a lo largo del Nilo y muy poco a través del desierto occidental, el transporte de grandes cantidades de esclavos no fue viable hasta que se introdujeron los camellos provenientes de Arabia en el siglo X. En este punto, una red transahariana comercial fue establecida para transportar esclavos hacia el norte. A diferencia de las Américas, los esclavos en África del Norte eran principalmente sirvientes en lugar de peones, y un número de mujeres igual o mayor que de hombres fue llevado, mismas que por lo general eran empleadas como camareras de las mujeres de los harenes. Tampoco era poco común convertir a los esclavos varones en eunucos.

El tráfico de esclavos a través del Atlántico se desarrolló más adelante, pero terminaría convirtiéndose mucho más grande y tendría un impacto mucho mayor. La penetración en incremento de las Américas por parte de españoles, portugueses, ingleses, franceses y holandeses, entre otros, propició una enorme demanda de mano de obra en Brasil, Guyena, el Caribe y Norteamérica. Los trabajadores eran requeridos para la agricultura, la minería y otras tareas. Para satisfacer esta demanda, se desarrolló un tráfico transatlántico de esclavos. Los esclavos adquiridos en aquellas regiones de África occidental conocidas por los europeos como Costa del Esclavo, Costa de Oro y Costa de Marfil con frecuencia eran el desafortunado producto de las luchas entre los estados africanos enemigos. Los poderosos reyes africanos de la bahía de Biafra podían vender sus presos internamente o intercambiarlos con los traficantes de esclavos europeos por bienes como armas de fuego, ron, telas y semillas. Cabe destacar que los traficantes europeos también realizaban sus propias cacerías de esclavos.

A pesar de que las Guerras Napoleónicas distrajeron a Europa de la exploración de África, hubo desarrollos significativos. La invasión de Egipto (1798-1803) primero por parte de Francia y luego por Gran Bretaña resultó en un intento de Turquía de recuperar el control directo sobre aquel país, seguido en 1811 por el establecimiento bajo el mando de Mehmet Alí de un estado casi independiente, y la extensión del dominio egipcio sobre el este de Sudán (de 1820 en adelante). En el sur de África la lucha contra Napoleón llevó al Reino Unido a tomar asentamientos holandeses en El Cabo, y en 1814 la Colonia del Cabo, la cual había sido ocupada continuamente por tropas británicas desde 1806, fue cedida formalmente a la corona británica.

Para mediados del siglo XIX, las misiones protestantes realizaron actividades misioneras en la costa de Guinea, en Sudáfrica y en los dominios de Zanzíbar. Se llevaban a cabo entre personas a quienes los europeos conocían poco. En muchos casos los misioneros se convertían en exploradores o agentes comerciales y de colonialismo. Uno de los primeros en intentar rellenar los espacios en blanco restantes en el mapa europeo fue David Livingstone, que había estado involucrado en las labores misioneras desde 1840 al norte del Orange. En 1849 Livingstone cruzó el desierto de Kalahari de sur a norte y llegó al lago Ngami, y entre 1851 y 1856 atravesó el continente de oeste a este, dando a conocer las grandes vías fluviales del alto Zambeze. Durante estas travesías Livingstone "descubrió", en noviembre de 1855, las famosas Cataratas Victoria, nombradas así en honor de la reina Victoria I del Reino Unido. En África, este salto de agua es llamado "Mosi-oa-Tunya" ("humo que truena"). Entre 1858 y 1864 el bajo Zambeze, el río Shire y el lago Nyasa fueron explorados por Livingstone. Una meta primordial para los exploradores era localizar el nacimiento del Nilo. Las expediciones de Burton y Speke (1857-1858) y Speke y Grant (1863) lograron localizar el lago Tanganica y el lago Victoria. Más adelante fue demostrado que era del segundo lago del que nacía el Nilo.

Henry Morton Stanley, quien en 1871 había tenido éxito al encontrar y socorrer a Livingstone, se dirigió a Zanzíbar en 1874, y en una de las más memorables de todas las expediciones de exploración en África circunnavegó los lagos Victoria y Tanganica, y, adentrándose más hasta el río Lualaba, siguió su curso río abajo hasta el Océano Atlántico —a donde llegó en agosto de 1877— y probó que era el río Congo.

Los exploradores también estuvieron activos en otras partes del continente. El sur de Marruecos, el Sahará y Sudán fueron atravesados en muchas direcciones entre 1860 y 1875 por Friedrich Gerhard Rohlfs, Georg August Schweinfurth y Gustav Nachtigal. Estos viajeros no solo aumentaron considerablemente el conocimiento geográfico, sino que también obtuvieron información invaluable respecto a la gente, los lenguajes y la historia natural de los países que visitaron. Entre los descubrimientos de Schweinfurth hubo uno que confirmó las leyendas griegas acerca de la existencia más allá de Egipto de una "raza pigmea". Pero el primer occidental en descubrir a los pigmeos de África central fue Paul du Chaillu, quien los halló en el distrito de Ogowe de la costa oeste en 1865, cinco años antes que el primer encuentro de Schweinfurth con ellos; du Chaillu hubo previamente, como resultado de sus viajes en la región de Gabón entre 1855 y 1859, hecho popular en Europa el conocimiento de la existencia del gorila, posiblemente el simio gigante visto por Hannón el Navegante, y cuya existencia, hasta mediados del siglo XIX, era concebida como legendaria al igual que la de los pigmeos de Aristóteles.

Mientras la exploración de las áreas más remotas e inaccesibles del continente era incipientes, ya se habían producido en otras partes del continente, siendo el más notable la invasión de Argel por parte de Francia en 1830. Esta acción puso fin a los estados bereberes independientes, un obstáculo mayor para la estrategia francesa en el Mediterráneo. La autoridad egipcia continuó su expansión hacia el sur. La ciudad de Zanzíbar, en la isla homónima, rápidamente cobró importancia. Relatos acerca de un vasto mar interior, y el "descubrimiento" en 1840-1848, por parte de los misioneros Johann Ludwig Krapf y Johannes Rebmann, del monte Kilimanjaro y de Kenia, estimularon en Europa el deseo de mayor conocimiento.

Aun así a finales del siglo XIX, el África subsahariana, era una de las últimas regiones del mundo en gran parte sin afectar por el "imperialismo informal", también resultaba atractiva para las potencias europeas por razones económicas y raciales. Durante una época donde la balanza comercial de Gran Bretaña mostraba un creciente déficit, con los mercados continentales encogiéndose y cada vez más proteccionistas debido a la Gran Depresión entre los años 1873 y 1896, África ofrecía al Reino Unido, Imperio Alemán, Francia y otros países un mercado abierto del que se cosecharía un gran excedente: un mercado que comprara más de la metrópoli de lo que vendía en total. El Reino Unido, al igual que la mayoría de los otros países industriales, había empezado a tener un desfavorable balance de comercio (que era contrarrestado, de todos modos, por el ingreso de las inversiones de sus colonias). Estas razones de fondo condujeron a la conferencia de Berlín donde los principales imperios europeos decidirían el reparto de África y la asignación de áreas de influencia que llevarían al colonialismo europeo de finales del siglo XIX y al sometimiento militar efectivo de millones de africanos.

La descolonización de África se refiere los procesos independentistas que ocurrieron en el continente posteriormente al término de la Segunda Guerra Mundial. Comenzó con Libia en 1951, a pesar de que Liberia, Sudáfrica, Egipto y Etiopía ya eran independientes. Lo siguieron Sudán y Túnez en 1956, Ghana en 1957 y Guinea en 1958, y con un apogeo en 1960, con el llamado "Año de África", donde 17 países africanos declararon la independencia, incluyendo gran parte de África Occidental Francesa. La mayor parte de los demás países se independizaron durante la década de 1960, aunque algunos colonizadores como Portugal, eran reacios a renunciar a la soberanía, lo que resultó en amargas guerras de independencia que se prolongaron durante una década o más. Los últimos países africanos en lograr la independencia formal fueron Angola de Portugal en 1975, Seychelles del Reino Unido en 1976, y Yibuti de Francia en 1977. Debido a que muchas ciudades fueron fundadas, ampliadas y rebautizadas por los europeos, después de la independencia a muchos lugares se les cambió el nombre.

Desde el fin de la Guerra Fría tres estados realizaron procesos de secesión y lograron su independencia de otras repúblicas africanas. Namibia se independizó de Sudáfrica en 1990, Eritrea de Etiopía en 1993, y Sudán del Sur de la República de Sudán en 2011.

Hoy en día, África contiene , la mayoría de los cuales tienen fronteras que se dibujaron durante la era del colonialismo europeo. Desde el colonialismo, los estados africanos han sido frecuentemente obstaculizados por la inestabilidad, la corrupción, la violencia y el autoritarismo. La gran mayoría de los estados africanos son repúblicas que operan bajo alguna forma del sistema presidencial de gobierno. Sin embargo, pocos de ellos han sido capaces de sostener gobiernos democráticos de manera permanente, y muchos en su lugar tenido ciclos a través de una serie de golpes de Estado, produciendo dictaduras militares. Como ejemplos opuestos se puede tomar a Botsuana que desde su independencia en 1966 ha mantenido una fuerte tradición de estables democracias representativas, con consistentes registros de elecciones ininterrumpidas y la percepción de corrupción más baja de África, mientras que por el otro extremo está Somalía, país que sufre de una guerra civil desde 1991, entre varios bandos que han declarado autonomías regionales sin que un gobierno estatal pueda revertirlo. Estas autonomías regionales no son reconocidas internacionalmente, y han generado que Somalía sea considerado un Estado fallido. 

Gran inestabilidad fue principalmente el resultado de la marginación de los grupos étnicos, y el injerto bajo estos líderes. Por razones políticas, muchos dirigentes abrieron conflictos étnicos, algunos de los cuales fueron exacerbados, o incluso creados, por el dominio colonial. En muchos países, el ejército era percibido como el único grupo que podía mantener efectivamente el orden y gobernó a muchas naciones en África durante los años setenta y principios de los ochenta. Durante el período comprendido entre los primeros años de la década de 1960 y finales de los ochenta, África tuvo más de 70 golpes de Estado y 13 asesinatos presidenciales. Las disputas fronterizas y territoriales también eran comunes, con las fronteras impuestas por Europa de muchas naciones siendo ampliamente disputadas a través de conflictos armados.

El conflicto de la guerra fría entre los Estados Unidos y la Unión Soviética, así como las políticas del Fondo Monetario Internacional (FMI) también jugaron un papel en la inestabilidad. Cuando un país se independizó por primera vez, se esperaba que se alineara con una de las dos superpotencias. Muchos países del norte de África recibieron ayuda militar soviética, mientras que otros en África central y meridional recibieron el apoyo de Estados Unidos, Francia o ambos. La década de 1970 vio una escalada de los conflictos de la Guerra Fría, ya que la nueva Angola independiente y Mozambique se alinearon con la Unión Soviética, y África Occidental y Sudáfrica trataron de contener la influencia soviética apoyando regímenes amistosos o movimientos insurgentes. En Rhodesia, la guerrilla izquierdista apoyada por los soviéticos y los chinos del Frente Patriótico de Zimbabue llevó a cabo una brutal guerra de guerrillas contra el gobierno blanco del país. Hubo una gran hambruna en Etiopía, cuando cientos de miles de personas murieron de hambre. Algunos afirmaron que las políticas económicas marxistas empeoraron la situación. El conflicto militar más devastador en África independiente moderna ha sido la Segunda Guerra del Congo; este conflicto y sus secuelas han causado la muerte de unos 5,5 millones de personas. Desde 2003 se ha producido un Conflicto de Darfur que se ha convertido en un desastre humanitario. Otro acontecimiento trágico notable es el genocidio ruandés de 1994 en el cual se calcula que 800,000 personas fueron asesinadas. El SIDA en el África poscolonial también ha sido una cuestión frecuente.

En el siglo XXI, sin embargo, el número de conflictos armados en África ha disminuido constantemente. Por ejemplo, la guerra civil de Angola llegó a su fin en 2002 después de casi 30 años. Esto ha coincidido con muchos países que abandonan las economías de mando del estilo comunista y se abren a las reformas del mercado. La mejora de la estabilidad y las reformas económicas han llevado a un gran aumento de la inversión extranjera en muchas naciones africanas, principalmente de China, lo que ha impulsado un rápido crecimiento económico en muchos países, paralizando décadas de estancamiento y declive. Varias economías africanas se encuentran entre las de mayor crecimiento mundial a partir de 2016. Una parte significativa de este crecimiento, que a veces se denomina "Africa Rising", también puede atribuirse a la difusión facilitada de las tecnologías de la información y específicamente el teléfono móvil.

Por otra parte, el surgimiento de la primavera árabe y los conflictos asociados, sumado a la insurgencia del Estado Islámico y movimientos que lo apoyan tales como el Boko Haram en Nigeria, han generados nuevos brotes de violencia en el norte y occidente de África durante la década de 2010.










</doc>
<doc id="1455" url="https://es.wikipedia.org/wiki?curid=1455" title="Hidrología">
Hidrología

La hidrología (del griego: ὕδωρ, "hýdōr" "agua" y λόγος, "lógos" "estudio") es una rama de las ciencias de la Tierra que estudia el agua, su ocurrencia, distribución, circulación, y propiedades físicas, químicas y mecánicas en los océanos, atmósfera y superficie terrestre. Esto incluye las precipitaciones, la escorrentía, la humedad del suelo, la evapotranspiración y el equilibrio de las masas glaciares. Por otra parte, el estudio de las aguas subterráneas corresponde a la hidrogeología.

Por el contrario, se denomina hidrografía al estudio de todas las masas de agua de la Tierra y, en sentido más estricto, a la medida, recopilación y representación de los datos relativos al fondo del océano, las costas, las mareas y las corrientes, de manera que se puedan plasmar sobre una carta hidrográfica. No obstante esta diferencia, los términos se utilizarán casi como sinónimos, ya que la parte de la hidrografía que interesa aquí es aquella que crea relieve, por lo tanto, la que está en contacto con la superficie terrestre, y por eso mismo la que es objeto de un análisis hidrológico.

La circulación de las masas de agua en el planeta son responsables del modelado de la corteza terrestre, como queda de manifiesto en el ciclo geográfico. Esa influencia se manifiesta en función de la distribución de las masas de rocas coherentes y deleznables, y de las deformaciones que las han afectado, y son fundamentales en la definición de los diferentes relieves.

Recordemos que un río es una corriente de agua que fluye por un cauce desde las tierras altas a las tierras bajas y vierte en el mar o en una región endorreica (río colector) o a otro río (afluente). Los ríos se organizan en redes. Una cuenca hidrográfica es el área total que vierte sus aguas de escorrentía a un único río, aguas que dependen de las características de la alimentación. Una cuenca de drenaje es la parte de la superficie terrestre que es drenada por un sistema fluvial unitario. Su perímetro queda delimitado por la divisoria o interfluvio.

Los trazados de los elementos hidrográficos se caracteriza por la adaptación o inadaptación a las estructuras litológicas y tectónicas, pero también la estructura geológica actúa en el dominio de las redes hidrográficas determinando su estructura y evolución.

El estudio hidrológico, inicia con el análisis morfométrico de la cuenca, que incluye: la delimitación de la cuenca, la medición del área y la longitud, altura máxima y mínima, índice de compacidad, factor de forma, curva hipsométrica, pendiente media, caracterización de la red de drenaje y el perfil altimétrico del cauce principal, entre otros.

En el transcurso de su desarrollo la hidrología se ha definido de diversas formas, una de las más simples es la que se deriva del análisis etimológico del vocablo, por ello, se tendría: La hidrología es la ciencia del agua.

En el nivel actual de desarrollo de las actividades humanas y de las ciencias en general no se puede satisfacer con la definición anterior, demasiado simplista e incompleta, por ello se recomienda analizar las siguientes:

Generalmente los diversos autores reconocen 8 períodos en el desarrollo histórico de la hidrología, estos son:

Aunque las fechas no son exactas, varios autores como O.E. Meinzer, definen este período, desde la antigüedad hasta el 1400.
Durante este período el concepto de ciclo hidrológico fue especulado
La mayoría de los conceptos desarrollados en esta época resultaron ser erróneos, con excepción del propuesto por Marco Vitruvio, quien estableció que el agua subterránea provenía de la infiltración del agua de lluvia y del derretimiento de la nieve.

A este período pertenecen las grandes construcciones hidráulicas de la antigüedad las que requirieron un conocimiento hidrológico práctico, entre ellos los pozos de Arabia, los Kanats de Persia, los acueductos de Roma, los canales y sistemas de irrigación y obras de control de inundaciones en China, y zonas de riego en Egipto, Mesopotamia, India y en los Andes.

Entre el 1000 y el 1600. En el período conocido como el Renacimiento, se tuvo un cambio gradual de los conceptos filosóficos puros de la hidrología a la ciencia observacional de tal época. Por ejemplo, basándose en observaciones, Leonardo da Vinci y Bernard Palissy lograron una correcta comprensión del ciclo hidrológico, especialmente en lo relativo a la infiltración de la lluvia y retorno del agua a través de manantiales.

Entre el 1600 y el 1700. El inicio de la moderna ciencia de la hidrología puede ser considerado en el siglo XVII, con las mediciones, por ejemplo: las de Pierre Perrault y Edmé Mariotte en el río Sena de París y Edmond Halley en el mar Mediterráneo, los cuales llegaron a conclusiones correctas del fenómeno hidrológico estudiado. A este período corresponde también los primeros estudios de los pozos artesianos.

Entre el 1700 y el 1800. Durante el Siglo XVIII, los estudios experimentales hidráulicos tuvieron gran auge y como resultado de ellos muchos principios hidráulicos fueron obtenidos, por ejemplo: el teorema y piezómetro de Bernoulli, la fórmula de Chézy y el principio de D'Alembert, los tubos de Pitot y Borda.

Entre el 1800 y el 1900.El Siglo XIX fue una gran era de hidrología experimental que tuvo su inicio en el período precedente y que marcó más firmemente el comienzo de la ciencia de la hidrología. Sin embargo la mayoría de contribuciones se tuvieron en la geohidrología y en la medición de las aguas superficiales (Hidrometría). Por ejemplo: la ecuación de Hagen-Poiseuille del flujo capilar (1840), la Ley de Darcy (1856), la fórmula del pozo de Dupuit-Thiem (1863) y el principio de Ghyben-Herzberg (1889).

En el campo de la hidrometría, en relación al aforo de aguas superficiales, se tuvo un gran avance, incluyendo: el desarrollo de varias fórmulas del flujo e instrumentos de medida y el comienzo del aforo sistemático de corrientes. Entre las contribuciones principales se tiene la fórmula de descarga de los vertedores de Francis (1855), la determinación del coeficiente de Chézy propuesta por Ganguillet y Kutter (1869) y por Manning (1889) y en el campo de la evaporación, la ley deDalton (1802), por último, en el campo de la precipitación, la correlación entre la lluvia y la altitud, determinada por Miller (1849).

Entre el 1900 y el 1930.
Aunque muchos trabajos de hidrología moderna fueron iniciados en el Siglo XIX, el desarrollo de la hidrología cuantitativa fue todavía inmaduro y entonces la ciencia de la hidrología fue enormemente empírica, debido a que la base física para varias determinaciones hidrológicas no era bien conocida, o bien porque se disponía de mucha información cuantitativa experimental para ser usada y procesada. Durante la parte final del Siglo XIX, y los siguientes 30 años, el empirismo hidrológico fue evidente, por ejemplo: cientos de fórmulas empíricas fueron propuestas, seleccionando sus coeficientes y parámetros en base al juicio y experiencia.

Entre el 1930 y el 1950. En este período se inician los grandes hidrólogos que utilizan el análisis racional para resolver los problemas hidrológicos planteados, así por ejemplo se tienen a: Sherman (1932) con el concepto de hidrograma unitario. Horton (1953) con la teoría de la infiltración de la lluvia, Theis (1935) que introduce el concepto de noequilibrio en la hidráulica de pozos, Gumbel (1941) que propone la distribución de probabilidades de valores extremos, Hazen (1930) que promueve el uso de la estadística en la hidrología, Bernard (1944) que discute el papel de la meteorología y marca el inicio de la hidrometeorología y Einstein (1950) quien introduce el análisis teórico en los estudios de sedimentación. Otro notable desarrollo de este período fue el establecimiento de muchos laboratorios hidráulicos e hidrológicos en el mundo.

Desde el 1950 hasta el presente. Alrededor del año 1950, las aproximaciones teóricas tienen uso extensivo a los problemas hidrológicos, ya que muchos principios racionales propuestos anteriormente, pueden ser sujetos a un verdadero análisis matemático. Los instrumentos sofisticados y las computadoras de alta velocidad empiezan su desarrollo y entonces, se pueden tomar medidas delicadas del fenómeno hidrológico y resolver ecuaciones matemáticas complicadas involucradas en la aplicación de modernas teorías hidrológicas.

Son ejemplos de los estudios hidrológicos teóricos: el análisis linear y no linear de sistemas hidrológicos, la adopción de conceptos estadísticos y transitorios en la hidrodinámica del agua subterránea y superficial, La aplicación de le las teorías de transferencia de masa y calor al análisis de evaporaciones, al estudio energético y dinámico de la humedad del suelo, la generación secuencial de datos hidrológicos sintéticos y el uso de la investigación de operaciones en el diseño de sistemas de recursos hídricos.

En la actualidad la hidrología tiene un papel muy importante en el planeamiento del uso de los Recursos Hidráulicos, y ha llegado a convertirse en parte fundamental de los proyectos de ingeniería que tienen que ver con suministro de agua, disposición de aguas servidas, drenaje, protección contra la acción de ríos y recreación. De otro lado, la integración de la hidrología con la Geografía matemática en especial a través de los sistemas de información geográfica ha conducido al uso imprescindible del computador en el procesamiento de información existente y en la simulación de ocurrencia de eventos futuros.

Los estudios hidrológicos son fundamentales para:

Todo esto y muchas aplicaciones más hacen que el hidrólogo sea un personaje importante en todo equipo multidisciplinar que enfrenta problemas de ingeniería civil en general y problemas de carácter ambiental.

La hidrología puede catalogarse, de acuerdo con la forma de análisis, y el uso que se dará de los resultados. Puede clasificarse, aun sabiendo de la limitación de cualquier clasificación en:

En la hidrología cualitativa el énfasis está dado en la descripción de los procesos. Por ejemplo en la determinación de las formas y causas que provocan la formación de un banco de arena en un río, estudio asociado al transporte sólido de los cursos de agua; o al análisis de la ocurrencia de condensaciones en determinados puntos de una carretera, que afectan la visibilidad y por lo tanto pueden aconsejar a cambiar el trazado de la misma.

La hidrología hidrométrica, o hidrometría, se centra en la medición de las variables hidrológicas, se trata básicamente de trabajos de campo, donde el uso adecuado de los instrumentos de medición, la selección adecuada de los locales en los cuales las medidas son efectuadas y la correcta interpretación de los resultados es fundamental para la calidad de la información recabada. Ayudando en su totalidad a poder calcular aspectos relacionados con cauces y las dependencias hidrológicas.

El énfasis de la hidrología cuantitativa esta en el estudio de la distribución temporal de los recursos hídricos en una determinada cuenca hidrográfica. Los instrumentos más utilizados en esta rama de la hidrología son los instrumentos matemáticos, modelos estadísticos y modelos conceptuales.

Es la rama más nueva de la hidrología, y se populariza a partir de los años 1960 - 70, con el auge de las redes telemétricas, donde sensores ubicados en varios puntos de una cuenca transmiten, en tiempo real los datos a una central operativa donde son analizados inmediatamente para utilizarlos en auxilio de la toma de decisiones de carácter operativo, como abrir o cerrar compuertas de una determinada obra hidráulica.

La Asociación Internacional de Hidrología Científica (IASH, por su sigla en inglés de International Association of Scientific Hydrology) propone la siguiente división de la hidrología:




</doc>
<doc id="1462" url="https://es.wikipedia.org/wiki?curid=1462" title="Célula haploide">
Célula haploide

Una célula haploide es aquella que contiene un solo juego de cromosomas o la mitad (n, haploide) del número normal de cromosomas que en células diploides (2n, diploide). Las células reproductoras, como los óvulos y los espermatozoides de los mamíferos, la etapa asexual de hongos, briófitos, protozoos y algunas algas contienen un solo juego de cromosomas, mientras que el resto de las células de un organismo superior suelen tener dos juegos de ellos. Cuando los gametos se unen durante la fecundación, el huevo fecundado contiene un número normal de cromosomas (2n): es una célula diploide.

La génesis de una célula haploide puede ocurrir de dos maneras:

La meiosis de hecho se divide en meiosis 1 y meiosis 2. Es en la meiosis 1; además de una división citoplasmática, se genera una duplicación del ADN, de tal forma que cada uno de los 46 cromosomas (en el caso del homo sapiens) queda constituido por dos cromátidas hermanas (46 cromosomas de estructura doble). Luego, la división citoplasmática se da y las dos células hijas fruto de la meiosis 1, entran a meiosis 2.

La meiosis se encarga de separar las cromátidas hermanas sin inducir una nueva replicación en el ADN; creando así cuatro células con la mitad de cromosomas de sus predecesoras, es decir, células haploides o gametos.

Individuos de algunas especies, como los zánganos, de la abeja melífera "Apis melífera", se desarrollan a partir de óvulos no fecundados y son por tanto haploides.




</doc>
<doc id="1463" url="https://es.wikipedia.org/wiki?curid=1463" title="Hedonismo">
Hedonismo

El hedonismo (del griego ἡδονή "hēdonḗ" 'placer' e "-ismo") es una doctrina moral que establece la satisfacción como fin superior y fundamento de la vida. Su principal objetivo consiste en la búsqueda del placer simple y natural que pueda asociarse con el bien evitando el dolor.

El hedonismo no consiste en afirmar que el placer es un bien, ya que dicha afirmación ha sido de esta manera admitida por otras muchas doctrinas éticas muy alejadas del hedonismo, sino en considerar que el placer es el único y supremo bien.

El término «hedonismo» puede tomarse en dos sentidos, lato y estricto. En el primero, el hedonismo sería una teoría ética de gran amplitud en la que la palabra placer tendría un significado muy extenso, que abarcaría tanto el placer como la utilidad; en este sentido, el utilitarismo se encuadraría dentro del hedonismo. En un sentido más restringido, el hedonismo se diferencia del utilitarismo, fundamentalmente, porque el primero cifra el bien en el placer individual, mientras que el segundo afirma como bien sumo el placer, el bienestar y la utilidad social. El hedonismo tiene un carácter individualista, el utilitarismo es de índole social y sostiene el punto de vista de que la satisfacción humana se encuentra en la búsqueda y posesión del placer material y físico.

Dentro del hedonismo en sentido estricto se pueden distinguir dos formas del mismo, de acuerdo con los dos significados que tiene el término placer. Este designa al placer sensible, o inferior, y al placer espiritual, o superior. En consecuencia, habrá dos formas de hedonismo llamadas hedonismo absoluto y hedonismo mitigado, o eudemonismo.

El hedonismo radical sostiene que todos los placeres físicos deben ser satisfechos sin ninguna restricción, mientras que el hedonismo moderado afirma que las actividades placenteras deben ser moderadas, para que así aumente el placer. En ambos casos el placer es la principal motivación del comportamiento.

Por lo que se refiere al hedonismo psicológico, son varias las doctrinas existentes según la determinación temporal del placer. La teoría del placer de los fines, o «hedonismo psicológico del futuro», sostiene que el placer personal es el fin último y único de una persona.

Las dos escuelas clásicas del hedonismo, formuladas en la Antigua Grecia, son la escuela cirenaica y el epicureísmo.

Aristipo de Cirene, discípulo de Sócrates y fundador de la escuela cirenaica de filosofía fue uno de los máximos representantes del hedonismo. Él consideraba el placer como principal objetivo, es decir, como fin que al ser alcanzado rápidamente es posible llegar a la felicidad. Resalta más el placer del cuerpo sobre los placeres mentales.

La escuela cirenaica, fundada entre los siglos IV y III a. C., plantea que el placer es elegible por uno mismo, caso contrario de la felicidad que no es más que el conjunto de los distintos placeres. El placer es guiado por la prudencia pues es el hombre quien debe dominar al placer y no dejarse dominar por él. Tanta prioridad se le otorga al placer, que sobrepone la realización de los deseos personales para satisfacerse de manera inmediata ignorando los intereses de los demás incluso si esto implicara actos inmorales. Su interés por el placer presente invita a preocuparse por el hoy, ya que el futuro es incierto. (Primero mis dientes, luego mis parientes).

Fue una de las más antiguas escuelas socráticas y enfatizaba solo un lado de las enseñanzas de Sócrates. Con base en la afirmación de Sócrates de que la felicidad es uno de los fines de la acción moral, Aristipo mantenía que el placer era el bien superior. Decía que las gratificaciones corpóreas, que consideraba intensas, eran preferibles a las mentales. Los cirenaicos también negaban que se pospusiera la gratificación inmediata por la ganancia a largo plazo. En este respecto difieren de los epicúreos.

Epícuro de Samos, cuyo objetivo en la filosofía era evitar el sufrimiento procurando la felicidad, por lo tanto, el objetivo principal para el ser humano debía ser el alcance de la felicidad priorizando la satisfacción obtenida por los deseos para subsistir y moderando aquellos que son naturales, pero no vitales. 

El epicureísmo, movimiento fundado hacia el 300 a. C., plantea que la felicidad consiste en vivir continuamente bajo la satisfacción del placer que no excita los sentidos, sino al que se refiere a la ausencia del dolor o de cualquier tipo de aflicción; más que buscar un placer inmediato busca aquel que requiere del uso de la razón, es decir, el que valora las consecuencias sobre las acciones y otorga placer a largo plazo. El placer se encuentra asociado con la tranquilidad, por lo que está relacionado con la "ataraxia", o la capacidad de controlarse uno mismo y aceptar los problemas naturales fuera de nuestro control, como lo es la muerte.

El epicureísmo identificaba el placer con la tranquilidad y enfatizaba la reducción del deseo sobre la adquisición inmediata del placer. En esta forma, el epicureísmo escapa a la objeción precedente: mientras el placer y el bien mayor son de hecho lo mismo, Epicuro argumentaba que el placer más alto consiste en una vida simple, moderada, complementada con discusiones filosóficas entre amigos. Enfatizaba que no era bueno hacer algo que a uno le haga sentir bien si después de experimentarlo denigraría las experiencias posteriores y no le permitiría sentirse bien. Así mismo afirmaba que a veces por tener placeres momentáneos intensos se sacrifica el bienestar posterior. Epicuro entendía por placer la ausencia de dolor.

Existen escritos de Epicuro y de sus seguidores que nos muestran sus doctrinas: entre los deseos, algunos son naturales y necesarios y otros ni lo uno ni lo otro, solo consagrados a la opinión vana. La disposición que tengamos hacia cada uno de estos casos determina nuestra aptitud para ser felices o no. 


Epicuro formuló algunas recomendaciones con respecto a estas categorías:


La filosofía epicúrea ganó un gran número de adeptos. Fue una importante escuela de pensamiento que perduró durante siete siglos después de la muerte de su creador. Hacia la Edad Media decayó y fueron destruidos muchos de sus escritos. Sin embargo, hoy existen remanentes de esta doctrina que han sido compilados y difundidos por el mundo.

Las dos escuelas convergen en su repudio por la superstición y la religión y sus bases en la conducta y el juicio mediante la experiencia y la razón. Así anticipan las posiciones del humanismo e iluminismo posteriores.

Una forma extrema de hedonismo que considera la restricción moral y sexual como innecesaria o perjudicial. Los defensores famosos son el Marqués de Sade y John Wilmot.

En los siglos XVIII y XIX, los filósofos británicos Jeremy Bentham, James Mill y John Stuart Mill hicieron la propuesta de una doctrina universal más conocida como utilitarismo. Según esta teoría, el comportamiento humano debe tener como criterio final el bien social. Hay que guiarse moralmente buscando todo aquello que proporciona y favorece el bienestar de un mayor número de personas.

Dentro de la filosofía contemporánea se destaca la figura de Michel Onfray como abierto proponente del hedonismo, quien manifiesta en una entrevista que «"se cree que el hedonista es aquel que hace el elogio de la propiedad, de la riqueza, del tener, que es un consumidor. Eso es un hedonismo vulgar que propicia la sociedad. Yo propongo un hedonismo filosófico que es en gran medida lo contrario, del ser en vez del tener, que no pasa por el dinero, pero sí por una modificación del comportamiento. Lograr una presencia real en el mundo, y disfrutar jubilosamente de la existencia: oler mejor, gustar, escuchar mejor, no estar enojado con el cuerpo y considerar las pasiones y pulsiones como amigas y no como adversarias"».

Otra figura destacable en defensa de este planteamiento hedonista es la escritora Valérie Tasso. Su libro "Antimanual de sexo" intenta abordar desde esta perspectiva el fenómeno de la sexualidad humana con declaraciones como la siguiente: «El hedonismo es una actitud ante la vida. Es una filosofía vital que prima al instante sobre el devenir, que reivindica la valentía sobre el miedo, que respeta la materialidad y cuestiona el espíritu, que gestiona lo que sucede sin despreciarse por lo que nunca sucedió, que aprecia la lógica de la vida y cuestiona la lógica de la muerte, que sabe que lo suficiente es suficiente, que busca el placer donde está, no donde se busca, que hace de su cuerpo su aliado y no su prisión, que desea sin que lo esclavice su deseo, que emplea su tiempo más que su dinero [...] El hedonista ejerce el difícil arte de establecer la paz consigo mismo».

El filósofo transhumanista David Pearce cree y promueve la idea de que existe un fuerte imperativo ético para que los humanos trabajen hacia la abolición del sufrimiento en toda la vida sensible. Su manifiesto "The Hedonistic Imperative" describe cómo las tecnologías como la ingeniería genética, la nanotecnología, la farmacología y la neurocirugía podrían converger para eliminar todas las formas de experiencias desagradables entre los animales humanos y no humanos, reemplazando el sufrimiento con gradientes de bienestar, un proyecto al que se refiere como "ingeniería del paraíso".

La fe católica se opone a las formas más sensuales del hedonismo, considerando que minan los valores y las virtudes del eudemonismo espiritual, en el cual el Cristianismo frecuentemente ha fundado su moral.

El hedonismo es considerado por muchas religiones una actitud carente de moral pero no porque aprecie algún placer, sino porque lo antepone a las exigencias del amor a Dios y al prójimo. Para el catolicismo, es una actitud que corre el riesgo de caer en el egocentrismo, el cual incapacita gravemente al sujeto para relacionarse con otros, a menos que sea para explotarlos y satisfacer su afán de placer.

El filósofo británico G. E. Moore dedica gran parte de su libro "Principia Ethica" (1903) a la refutación del hedonismo. Entiende que considerar que el placer y solamente el placer es bueno significa caer en lo que llamó «falacia naturalista». Al decir que «el placer y solamente el placer es bueno», el placer se convierte en un equivalente de «bueno». Así, la proposición «el placer es bueno» significa realmente «el placer es el placer», tautología de ningún interés ético. Moore defendía que el bien era indefinible, si bien podían atribuírsele ciertas características que no obstante no delimitarían su significación por completo.

La psicología positiva, basada en investigaciones científicas de psicológica cognoscitiva, ha pensado muchas veces que sustentar la felicidad en la búsqueda del placer, «la vida placentera», deriva en un mayor índice de insatisfacción. La búsqueda de una felicidad auténtica, como indica el psicólogo Martin E. P. Seligman, implica poner un mayor enfoque en el compromiso y el significado. La «vida comprometida» está basada en gratificaciones que no pueden ser adquiridas por atajos, como aprender un oficio, o un deporte; se busca el «flujo», que es el balance del reto con la habilidad. Por otra parte, la vida significativa son las acciones y creencias basadas en algo mayor a nuestro ego, acciones motivadas por un bien común, etcétera. Se ha dicho que aquellos que basan su felicidad en la «vida comprometida» y «la vida significativa» cuentan con un mayor índice de satisfacción en la vida. La «felicidad auténtica» es un concepto superior al simple hecho de no sentir dolor, sentir placer, o no sufrir enfermedades psicológicas.

Estos datos, sin embargo, no son científicos, sino más bien ideales. La mayoría de neurocientíficos cree que nuestro cerebro funciona con un esquema de «castigo-recompensa», en el que algo que beneficiaría a nuestros antepasados (comida, pertenecer a un grupo o tener sexo) llevan a la producción de endorfinas, u hormonas del placer, lo que haría que los hedonistas tengan la razón. Aunque se advierte que algunas partes de las teorías hedonistas puedan ser morales y no precisamente abordan un tema objetivo.



</doc>
<doc id="1466" url="https://es.wikipedia.org/wiki?curid=1466" title="Ingeniería">
Ingeniería

La ingeniería es el conjunto de conocimientos científicos y tecnológicos para la innovación, invención, desarrollo y mejora de técnicas y herramientas para satisfacer las necesidades y resolver problemas tanto de las personas como de la sociedad.

El ingeniero se apoya en las ciencias básicas (matemática, física, química, biología, ciencias económicas y administrativas, ciencias de la ingeniería, ingeniería aplicada) tanto para el desarrollo de tecnologías, como para el manejo eficiente y productivo de recursos y fuerzas de la naturaleza en beneficio de la sociedad. La ingeniería es una actividad que transforma el conocimiento en algo práctico.

La ingeniería aplica los conocimientos y métodos científicos a la invención o perfeccionamiento de tecnologías de manera pragmática y ágil, adecuándose a las limitaciones de tiempo, recursos, requisitos legales, requisitos de seguridad, ecológicos, etc.

Su estudio como campo del conocimiento está directamente relacionado con el comienzo de la Revolución Industrial, constituyendo una de las actividades pilares en el desarrollo de las sociedades modernas.

Actualmente la ingeniería se clasifica en diversas áreas según su campo de aplicación.

La ingeniería es una disciplina amplia y en cierta medida cambiante, ya que depende en gran medida del avance tecnológico y de las herramientas de las que hacen uso los ingenieros; además, la educación en ingeniería no es homogénea y su duración, entre otros aspectos, difiere internacionalmente. Además, la ingeniería es en muchos países una profesión regulada y cuya educación formal ha de adaptarse a la normativa nacional. 

Su función principal es la de realizar diseños o desarrollar soluciones tecnológicas a necesidades sociales, industriales o económicas. Para ello el ingeniero debe identificar y comprender los obstáculos más importantes para poder realizar un buen diseño. Algunos de los obstáculos son los recursos disponibles, las limitaciones físicas o técnicas, la flexibilidad para futuras modificaciones y adiciones y otros factores como el coste, la posibilidad de llevarlo a cabo, las prestaciones y las consideraciones estéticas y comerciales. Mediante la comprensión de los obstáculos, los ingenieros deciden cuáles son las mejores soluciones para afrontar las limitaciones encontradas cuando se tiene que producir y utilizar un objeto o sistema.

Los ingenieros utilizan el conocimiento de la ciencia, las matemáticas y la experiencia para encontrar las mejores soluciones a los problemas concretos, creando los modelos matemáticos de los problemas que les permiten analizarlos rigurosamente y probar las soluciones potenciales. Si existen múltiples soluciones razonables, los ingenieros evalúan las diferentes opciones de diseño sobre la base de sus cualidades y eligen la solución que mejor se adapta a las necesidades, costo, seguridad y otras condiciones de contorno.

En general, los ingenieros intentan probar si sus diseños logran sus objetivos antes de proceder a la producción en cadena. Para ello, emplean entre otras cosas prototipos, modelos a escala, simulaciones, pruebas destructivas y pruebas de fuerza. Los ensayos comprueban si los artefactos funcionarán como se había previsto.

Para hacer diseños estándares y fáciles, las computadoras tienen un papel importante. Utilizando los programas de diseño asistido por ordenador (DAO, más conocido por CAD, "computer-aided design"), los ingenieros pueden obtener más información sobre sus diseños. El ordenador puede traducir automáticamente algunos modelos en instrucciones aptas para fabricar un diseño. La computadora también permite una reutilización mayor de diseños desarrollados anteriormente, mostrándole al ingeniero una biblioteca de partes predefinidas para ser utilizadas en sus propios diseños.

Los ingenieros deben tomar muy seriamente su responsabilidad profesional para producir diseños que se desarrollen como estaba previsto y no causen un daño inesperado a la gente en general. Normalmente, los ingenieros incluyen un factor de seguridad en sus diseños para reducir el riesgo de fallos inesperados.

La ciencia intenta abordar la explicación de los fenómenos, creando modelos matemáticos que correspondan con los resultados experimentales. Tecnología e ingeniería constituyen la aplicación del conocimiento obtenido a través de la ciencia, produciendo resultados prácticos. Los científicos trabajan con la ciencia y los tecnólogos con la tecnología. Sin embargo, la ingeniería se desarrolla al congeniar ciencia y tecnología (p. ej., creando formatos, diseños, herramientas y materiales para la industria). No es raro que los científicos se vean implicados en el desarrollo de la tecnología y de la ingeniería por las aplicaciones de sus descubrimientos. De modo análogo los ingenieros y tecnólogos, descubren a veces nuevos fenómenos o teorías que desenvuelven el campo de la ciencia.

Los ingenieros tienen como su función principal hallar soluciones a los problemas utilizando destrezas tecnológicas y científicas; el ingeniero debe tener una gran pericia visual espacial para realizar distintas cosas con ayuda de esta capacidad.

También puede haber conexiones entre el funcionamiento de los ingenieros y los artistas, principalmente en los campos de la arquitectura y del diseño industrial.


Los ingenieros, a la hora de tomar decisiones, deben tener en cuenta que la vida, la seguridad, la salud, el bienestar de la población y el medio ambiente podrían verse afectados por su juicio y deben colocar estos valores por encima de otras consideraciones, ya sean económicas o de otro tipo. El objetivo principal de la ética en la ingeniería es dar a conocer, las responsabilidades a las que los ingenieros, deben enfrentarse al realizar cualquier tipo de obra, en la que segundas personas podrían salir afectadas.

La ciencia investiga, le interesa saber, su producto son los conocimientos.

La ingeniería por su lado, aplica todos aquellos conocimientos que son el resultado de la investigación. Le interesa el conocimiento de la ciencia en la medida en que lo pueda aplicar; el producto son las obras y los aparatos físicos que crea.

La ingeniería tenía antiguamente dos ramas fundamentales: militar y civil. Esta última dio origen a la ramas mecánica y eléctrica. De las ramas citadas, derivan las demás.

Es la rama de la ingeniería que da apoyo a las actividades de combate y logística de los ejércitos mediante un sistema MCP —movilidad, contramovilidad y protección— construyendo puentes, campos minados, pasarelas, etc. Los ingenieros se encargan también de aumentar el poder defensivo por medio de construcciones o mejoramiento de estructuras de defensa. Además de sus misiones clásicas de apoyo en combate en situaciones de guerra, actúa en épocas de paz colaborando en la solución de problemas de infraestructura de índole nacional.

Se caracterizan por tener una base científica y tecnológica. Son ingenierías de nivel superior y de un alto grado de complejidad (la duración de un programa de calidad satisfactoria es de 6 años). Cada una de estas ingenierías tienen como tronco común las bases de la ingeniería civil: estructuras, construcción, geotecnia, hidráulica, sanitaria, ambiental, transporte, así como también en ciencias básicas, ciencias económicas y administrativas, ciencias de la ingeniería, ingeniería aplicada según especialidad.
Todas ellas tienen en común su actuación en el diseño, proyección y construcción de edificios, instalaciones, equipos, procesos y productos propios de la ingeniería civil, además de los de su especialidad.







Disciplina de base tecnológica, con una formación satisfactoria en ciencias básicas e ingeniería aplicada en cada una de las especialidades correspondientes, para el diseño y desarrollo de productos y procesos, propios de su especialidad. Su duración promedio es de 4 a 5 años. Las especialidades más comunes actualmente son:

A inicios del siglo XXI la ingeniería en sus muy diversos campos ha logrado explorar los planetas del sistema solar con alto grado de detalle, destacan los exploradores que se introducen hasta la superficie planetaria; también ha creado un equipo capaz de derrotar al campeón mundial de ajedrez; ha logrado comunicar al planeta en fracciones de segundo; ha generado internet y la capacidad de que una persona se conecte a esta red desde cualquier lugar de la superficie del planeta mediante una computadora portátil y teléfono satelital; ha apoyado y permitido innumerables avances de la ciencia médica, astronómica, química y en general de cualquier otra. Gracias a la ingeniería se han creado máquinas automáticas y semiautomáticas capaces de producir con muy poca ayuda humana grandes cantidades de productos como alimentos, automóviles y teléfonos móviles. Elisa Leonida Zamfirescu (1887-1973) fue la primera mujer ingeniera del mundo. En 1909 se inscribió en la Academia Real Técnica de Berlín, Charlottemburgen y se graduó en 1912.

Pese a los avances de la ingeniería, la humanidad no ha logrado eliminar el hambre del planeta, ni mucho menos la pobreza, siendo evitable la muerte de un niño de cada tres en el año 2005. Sin embargo, además de ser este un problema de ingeniería, es principalmente un problema de índole social, político y económico.

Un aspecto negativo que ha generado la ingeniería y compete en gran parte resolver a la misma es el impacto ambiental que muchos procesos y productos emanados de estas disciplinas han generado y es deber y tarea de la ingeniería contribuir a resolver el problema.

En sus inicios la Ingeniería estuvo vinculada, casi exclusivamente a actividades militares, gubernamentales y religiosas. Basta con mencionar los caminos, puentes, murallas, torres, faros, puertos, monumentos funerarios y otras construcciones. En tiempos de paz la Ingeniería fue puesta al servicio del bienestar del Ser Humano, al margen de la guerra y los ejércitos. De ahí que cuando, en el siglo XIX, algunas Universidades empezaron a ofrecer esta carrera, la llamaron ingeniería civil para distinguirla de la ejercida por los militares (Ingeniería Militar).

A continuación se listan algunas de las primeras escuelas universitarias en Europa y América:

Aquí están las conexiones entre la ingeniería y el arte, que son directos, en algunos campos, por ejemplo, la arquitectura, arquitectura del paisaje y el diseño industrial (incluso estas disciplinas a veces pueden ser incluidas en una Facultad de la Universidad de Ingeniería); e indirecta en otros.
El Instituto de Arte de Chicago, por ejemplo, organizó una exposición sobre el arte del diseño aeroespacial de la NASA. Diseño de Robert Maillart puente es percibido por algunos como han sido deliberadamente artística. En la Universidad del Sur de Florida, un profesor de ingeniería, a través de una subvención con la Fundación Nacional de Ciencias, ha desarrollado un curso que se conecta el arte y la ingeniería.
Entre los famosos de la historia, Leonardo Da Vinci es un artista del Renacimiento y un ingeniero bien conocido, y un excelente ejemplo del vínculo entre el arte y la ingeniería.

Del mismo modo, existen numerosos puentes que han sido considerados como monumentos con categoría de Patrimonio Mundial por la UNESCO, como el acueducto Pontcysyllte o el conjunto de los puentes del centro de París.


</doc>
<doc id="1467" url="https://es.wikipedia.org/wiki?curid=1467" title="Impresora">
Impresora

Una impresora es un dispositivo periférico de salida, del ordenador que permite producir una gama permanente de textos o gráficos de documentos almacenados en un formato electrónico, imprimiéndolos en medios físicos, normalmente en papel, utilizando cartuchos de tinta o tecnología láser (con tóner).

Muchas de las impresoras son usadas como periféricos de salida, y están permanentemente unidas al ordenador por un cable. Otras impresoras, llamadas impresoras de red, tienen una interfaz de red interno (típicamente wireless o ethernet), y que puede servir como un dispositivo para imprimir en papel algún documento para cualquier usuario de la red.

Además, muchas impresoras modernas permiten la conexión directa de aparatos de multimedia electrónicos como las tarjetas "CompactFlash", "Secure Digital" o "Memory Stick", "pendrives", o aparatos de captura de imagen como cámaras digitales y escáneres. También existen aparatos multifunción que constan de impresora, escáner o máquinas de fax en un solo aparato. Una impresora combinada con un escáner puede funcionar básicamente como una fotocopiadora.

Son diseñadas para realizar trabajos repetitivos de poco volumen, que no requieran virtualmente un tiempo de configuración para conseguir una copia de un determinado documento. Sin embargo, las impresoras son generalmente dispositivos lentos (10 páginas por minuto es considerado rápido), y el gasto por página es relativamente alto.

Para trabajos de mayor volumen existen las imprentas, que son máquinas que realizan la misma función que las impresoras pero están diseñadas y optimizadas para realizar trabajos de impresión de gran volumen, como sería la impresión de periódicos. Las imprentas son capaces de imprimir cientos de páginas por minuto o más.

En general, las impresoras se pueden dividir en categorías siguiendo diversos criterios.

La distinción más común se hace entre:

Además, se pueden seguir los siguientes criterios para clasificar las impresoras:


Técnicamente, las impresoras láser son matriciales, pero la nitidez de la impresión y el tamaño reducido de los puntos impresos con alta densidad, se puede considerar que los trazos de sus caracteres son continuos.

Esta clasificación se refiere al medio utilizado para enviar los datos a la impresora:

Muchas versiones de impresoras estaban disponibles en paralelo y en serie, e incluso incorporaban ambas opciones, aumentando la flexibilidad para instalarlas. Actualmente, la tendencia es a favor de las impresoras en serie, a través del estándar USB.



Los distintos tipos de impresoras se diferencian en la velocidad de impresión y en la calidad del producto impreso.

Las impresoras de caracteres, como las matriciales, imprimen en un rango de velocidad entre 200 y 400 caracteres por segundo (cps), que supone de 90 a 180 líneas por minuto (lpm). Las impresoras de línea presentan un amplio rango de velocidades, desde 400 a 2000 líneas por minuto. La velocidad de las impresoras de página oscila entre 4 y 800 páginas por minuto (ppm) para impresiones en blanco y negro, y la décima parte para la impresión en color.

En entornos de oficinas en los que se empleen formularios en papel continuo o de varias hojas de papel continuo, la impresora más adecuada es la de matriz de puntos, pero si se requiere mayor calidad de impresión se utilizará impresora láser. Las impresoras de inyección de tinta son las preferidas para entornos domésticos, por precio asequible.

La elección del motor de compresión tiene un efecto substancial en los trabajos a los que una impresora está destinada. Hay diferentes tecnologías que tienen diferentes niveles de calidad de imagen, velocidad de impresión, coste, ruido y además, algunas tecnologías son inapropiadas para ciertos tipos de medios físicos (como papel carbón o transparencias).

Otro aspecto de la tecnología de impresión que es frecuentemente olvidado es la resistencia a la alteración: la tinta líquida como de una cabeza de inyección de tinta es absorbida por las fibras del papel, y por eso los documentos impresos con tinta líquida son más difíciles de alterar que los que están impresos por tóner o tinta sólida, que no penetran por debajo de la superficie del papel.

Las impresoras láser e impresoras térmicas utilizan este método para adherir tóner al medio. Trabajan utilizando el principio de la "xerografía" que está funcionando en la mayoría de las fotocopiadoras: adhiriendo tóner a un tambor de impresión sensible a la luz, y utilizando electricidad estática para transferir el tóner al medio de impresión al cual se une gracias al calor y la presión.

Las impresoras láser son conocidas por su impresión de alta calidad, buena velocidad de impresión y su bajo costo por copia; son las impresoras más comunes para muchas de las aplicaciones de oficina de propósito general. Son menos utilizadas por el consumidor, generalmente debido a su alto coste inicial. Las impresoras láser están disponibles tanto en color como en monocromo.

El advenimiento de láseres de precisión a precio razonable ha hecho a la impresora monocromática basada en tóner dominante en aplicaciones para la oficina.
Otro tipo de impresora basada en tóner es la impresora led la cual utiliza una colección de ledes en lugar de láser para causar la adhesión del tóner al tambor de impresión.
El tóner, también denominado tinta seca por analogía funcional con la tinta, es un polvo fino, normalmente de color negro, que se deposita en el papel que se pretende imprimir por medio de atracción electrostática.(del inglés, "toner").

Una vez adherido el pigmento, este se fija en el papel por medio de presión o calor adecuados.
Debido a que en el proceso no intervienen diluyentes, originalmente se ha denominado xerografía, del griego "xeros" que significa seco.

Las impresoras de inyección de tinta ("Ink Jet") rocían hacia el medio cantidades muy pequeñas de tinta, usualmente unos picolitros. Para aplicaciones de color, incluyendo impresión de fotos, los métodos de chorro de tinta son los dominantes, ya que las impresoras de alta calidad son poco costosas de producir. Virtualmente todas las impresoras de inyección son dispositivos en color; algunas, conocidas como impresoras fotográficas, incluyen pigmentos extra para una mejor reproducción de la gama de colores necesaria para la impresión de fotografías de alta calidad (y son adicionalmente capaces de imprimir en papel fotográfico, en contraposición al papel normal de oficina).

Las impresoras de inyección de tinta consisten en inyectores que producen burbujas muy pequeñas de tinta que se convierten en pequeñísimas gotitas de tinta. Los puntos formados son el tamaño de los pequeños pixeles. Las impresoras de inyección pueden imprimir textos y gráficos de alta calidad de manera casi silenciosa.

Existen dos métodos para inyectar la tinta:

Las impresoras de inyección tienen un coste inicial mucho menor que las impresoras láser, pero tienen un coste por copia mucho mayor, ya que la tinta necesita ser repuesta frecuentemente. Las impresoras de inyección son también más lentas que las impresoras láser, además de tener la desventaja de dejar secar las páginas antes de poder ser manipuladas agresivamente; la manipulación prematura puede causar que la tinta (que está adherida a la página en forma líquida) se mueva.

Las impresoras de tinta sólida, también llamadas de cambio de fase, son un tipo de impresora de transferencia térmica pero utiliza barras sólidas de tinta en color CMYK (similar en consistencia a la cera de las velas). La tinta se derrite y alimenta una cabeza de impresión operada por un cristal piezoeléctrico (por ejemplo cuarzo). La cabeza distribuye la tinta en un tambor engrasado. El papel entonces pasa sobre el tambor al tiempo que la imagen se transfiere al papel.

Son comúnmente utilizadas como impresoras en color en las oficinas, ya que son excelentes imprimiendo transparencias y otros medios no porosos, y pueden conseguir grandes resultados. Los costes de adquisición y utilización son similares a las impresoras láser.

Las desventajas de esta tecnología son el alto consumo energético y los largos periodos de espera ("calentamiento") de la máquina. También hay algunos usuarios que se quejan de que la escritura es difícil sobre las impresiones de tinta sólida (la cera tiende a repeler la tinta de los bolígrafos), y son difíciles de alimentar de papel automáticamente, aunque estos rasgos han sido significantemente reducidos en los últimos modelos. Además, este tipo de impresora solo se puede obtener de un único fabricante, Xerox, como parte de su línea de impresoras de oficina Xerox Phaser. Previamente las impresoras de tinta sólida fueron fabricadas por Tektronix, pero vendió su división de impresión a Xerox en el año 2000.

Las impresoras de impacto o impresoras de golpe se basan en la fuerza de impacto para transferir tinta al medio, de forma similar a las máquinas de escribir, están generalmente limitadas a reproducir texto. En su momento dominaron la impresión de calidad. Hay dos tipos principales:

Las impresoras de impacto trabajan con un cabezal en el que hay agujas, estas agujas golpean una cinta, similar al de una máquina de escribir, que genera la impresión de la letra.

En el sentido general, muchas impresoras se basan en una matriz de muchos píxeles o puntos que, juntos, forman la imagen más grande. Sin embargo, el término matriz o de puntos se usa específicamente para las impresoras de impacto que utilizan una matriz de pequeños alfileres para crear puntos precisos. Dichas impresoras son conocidas como matriciales. La ventaja de la matriz de puntos sobre otras impresoras de impacto es que estas pueden producir imágenes gráficas además de texto. Sin embargo, el texto es generalmente de calidad más pobre que las impresoras basadas en impacto de tipos.

Algunas sub-clasificaciones de impresoras de matriz de puntos son las impresoras de alambre balístico y las impresoras de energía almacenada.

Las impresoras de matriz de puntos pueden estar basadas bien en caracteres o bien en líneas, refiriéndose a la configuración de la cabeza de impresión.

Las impresoras de matriz de puntos son todavía de uso común para aplicaciones de bajo costo y baja calidad como las cajas registradoras. El hecho de que usen el método de impresión de impacto les permite ser usadas para la impresión de documentos autocopiativos como los recibos de tarjetas de crédito, donde otros métodos de impresión no pueden utilizar este tipo de papel. Las impresoras de matriz de puntos han sido superadas para el uso general en computación.

Las impresoras de sublimación de tinta emplean un proceso de impresión que utiliza calor para transferir tinta a medios como tarjetas de plástico, papel o lienzos. El proceso consiste usualmente en poner un color cada vez utilizando una cinta que tiene paneles de color. Estas impresoras están principalmente pensadas para aplicaciones de color de alta calidad, incluyendo fotografía en color, y son menos recomendables para texto. Primeramente utilizadas en las copisterías, cada vez más se están dirigiendo a los consumidores de impresoras fotográficas.

Las impresoras térmicas se basan en una serie de agujas calientes que recorren el papel termosensible que al contacto se vuelve de color negro. Por su bajo coste, son muy usadas en los cajeros automáticos y supermercados.

Las impresoras llevan consigo memoria interna. Van desde los 6 KB en las impresoras matriciales hasta como mínimo 2 MB en las impresoras láser.

Actualmente en las láser venden módulos de memoria independientes para ampliar la capacidad de la misma.

La memoria se usa como búfer y como almacenamiento permanente y semipermanente. Además su uso es necesario porque el tratamiento de gráficos vectoriales y el diseño de fuentes en mapa de bits consumen memoria.

El búfer es utilizado para mantener trabajos de impresión activos y la permanencia se utiliza para almacenar el diseño de las fuentes y los datos.

Hay que tener en cuenta que para tratar la impresión de un documento la página tiene que estar enteramente almacenada en memoria.
El rendimiento de la memoria depende tanto del sistema operativo como de la configuración del controlador de impresora.

Por ejemplo, la gestión de impresión varía si estamos en un sistema operativo DOS u otro multiplataforma.

La conexión de la impresora con el computador ha ido evolucionando conllevando a la mejora de rendimiento de impresión y comodidad de usuario.

La forma más antigua de conexión era mediante puerto serie en donde la transferencia se hacía bit a bit, permitía distancias largas con velocidades lentas que no superaban los 19 200 bytes/segundo.

Se elevó hasta la conexión mediante puerto paralelo en la que las transferencias eran byte a byte permitiendo 8 conexiones paralelas consiguiendo una velocidad más rápida entre los ½ MB/segundo hasta los 4 MB/segundo. El inconveniente era la limitación de la distancia del cable que une la impresora con el computador ya que no permite una longitud mayor de 2 metros.

Otra forma de conexión se consiguió poniendo la impresora en red Ethernet mediante conexiones RJ-45 basadas en el estándar IEEE 802.3.
Las velocidades conseguidas superan los 10 Mb/segundo basada en el manejo de paquetes.
No hay que confundirla con una impresora compartida, ya que las impresoras en red operan como un elemento de red con dirección IP propia.

Otro método de conexión más actual es por medio de puertos USB ("Universal Serial Bus"). La velocidad vuelve a mejorar con 480Mb/segundo con las ventajas que conlleva el puerto USB: compatibilidad con varios sistemas y la posibilidad de usarla en dispositivos portátiles.

Finalmente, la conexión inalámbrica Wi-Fi, mediante el protocolo IEEE 802.11, está siendo la más novedosa. Alcanza 300 Mb/segundo y funciona tanto para impresoras de tinta, láser o multifunción.

Aunque consigue menos velocidad que las conectadas por USB, las wifi proporcionan ventajas tales como la autonomía, la movilidad y libertad del usuario sin la utilización de cables. Para la correcta utilización y evitar accesos no deseados deberemos cifrar la red.

Un “lenguaje de descripción de página” (PDL) es un medio de codificar cada elemento de un documento para poder así transmitirlo a la impresora para que esta lo imprima. Es el medio que define las características y composición que describirían un documento impreso dentro de un flujo de datos. Hay varios tipos de PDL:

Fue creado por Apple para no depender tecnológicamente de los tipos PostScript de Adobe, pero su calidad resultó ser inferior. Fue comprada por Microsoft lo cual ha contribuido a que no llegara a desaparecer. La principal fortaleza de "TrueType" es que ofrece a los diseñadores de fuentes un gran grado de control sobre la forma que sus fuentes se muestran a diferentes tamaños.

El problema con la mayoría de los programas es que no usan normalmente el truetype. En general cargan las fuentes en estilo Postscript y se descartan todas las insinuaciones; esto es una gran pérdida para fuentes con alta calidad. Aparte del diseño de la fuente, hay que tener en cuenta otras dos claves para la calidad de fuente: el perfil del carácter y la insinuación. Solo algunas fundiciones actualmente producen fuentes que exploten al máximo el potencial de insinuación de truetype. Ahora hay aplicaciones que convierten un Type 1 de Postscript en un truetype, pero son los manuscritos mejores que los generados automáticamente.

Los plóteres sirven para hacer impresiones de dibujo de planos de arquitectura, ingeniería, diseño industrial, etc., para la impresión de láminas, pósteres, ampliaciones fotográficas, gigantografías, carteles en rutas, vía pública, señalización, etc. Existen dos clases de plóter según el uso de sus tintas, a base de agua o disolventes. Un caso particular es el plóter de corte, que corta un medio adhesivo que luego se fijará a otra superficie, desde camisetas a carrocerías.

Existen dispositivos como celulares, que se utilizan en casas de revelado fotográfico o en el hogar. Estos dispositivos suelen ser conocidos como impresora fotográfica, impresora con calidad fotográfica o bases de impresión fotográfica. Estos dispositivos imprimen en color, produciendo imágenes que imitan el rango de colores y resoluciones de los métodos de revelado fotográfico previos a esta tecnología.

A menudo se utiliza el modelo comercial de las maquinillas y las cuchillas de afeitar en el negocio de las impresoras. Las compañías pueden vender una impresora por debajo de su coste, y obtener beneficios de los cartuchos de tinta, papel u otras partes que se reemplazan. Esto ha causado disputas legales respecto al derecho de otras compañías distintas al fabricante de la impresora de vender cartuchos de tinta compatibles o alternativos. Para proteger al modelo comercial de las maquinillas y las cuchillas de afeitar muchos fabricantes invierten considerables sumas en desarrollo de nuevas tecnologías y sus patentes.

Otros fabricantes, en reacción a los desafíos que trae este modelo comercial, apuntan a obtener mayores beneficios de las impresoras y menos de los cartuchos de tinta, promoviendo los menores precios de los cartuchos a través de campañas de publicidad. Esto genera dos propuestas bien diferentes: "impresora barata - tinta cara" o "impresora cara - tinta barata". Finalmente, la decisión del consumidor depende de su tasa de interés de referencia o su preferencia intertemporal.

Tanto los cartuchos, como la tinta y el papel son 3 elementos imprescindibles para poder realizar copias con una impresora, y el saber escoger el elemento más adecuado en función del tipo de impresión que se pretende realizar puede aumentar el rendimiento de nuestra impresora hasta límites insospechados.

En el caso de las impresoras láser, la vida útil del cartucho depende de la cantidad de tóner que contenga y cuando el tóner se agota, el cartucho debe ser reemplazado. En el caso de que el cartucho y el OPC (órgano sensible fotoconductivo) se encuentren en compartimentos separados, cuando se agota el tóner solo se reemplaza el cartucho, pero en el caso de que el OPC esté dentro del cartucho se deben cambiar ambos, aumentando considerablemente el gasto. La situación es más crítica en el caso de las impresoras láser en color.

En las impresoras de chorro de tinta la vida útil del cartucho depende de la duración de la tinta, aunque muchos cartuchos se pueden rellenar de nuevo, lo que ayuda a reducir el gasto de comprar uno nuevo aunque el uso excesivo de un cartucho puede provocar que realice sus impresiones con menor calidad.

Existen dos tipos de tinta para impresoras:

El objetivo de todo fabricante de tintas para impresoras es que sus tintas puedan imprimir sobre cualquier medio y para ello desarrollan casi diariamente nuevos tipos de tinta con composiciones químicas diferentes.

Actualmente, cuando se quiere hacer una copia de alta calidad en una impresora se ha de usar papel satinado de alta calidad. Este papel resulta bastante caro y en el caso de querer hacer muchas copias en calidad fotográfica su costo sería muy alto. Por ello, los fabricantes desarrollan nuevas impresoras que permitan obtener impresiones de alta calidad sobre papel común.

Algunos fabricantes, como por ejemplo Epson, fabrican su propio papel.

Si no se tiene cuidado a la hora de seleccionar el tipo de papel adecuado para la impresora o en el momento de colocar el papel pueden aparecer pequeños problemas. Puede que la mala colocación del papel de lugar a que la impresora no detecte el papel, para lo que bastará con volver a colocarlo bien. Esta mala colocación o una mala elección del papel también puede dar lugar a que durante la impresión se produzca un atasco debido a que la impresora ha tomado varias hojas a la vez, por lo que se debe ser cuidadoso a la hora de situar el papel en la bandeja y no se debe sobrecargar con mucho papel esta bandeja.

En ocasiones al imprimir documentos o fotografías pueden aparecer bandas horizontales que hacen empeorar la calidad de la impresión. Aunque este problema puede estar ocasionalmente relacionado con una mala elección del papel de impresión generalmente se debe a problemas de tinta en impresiones de inyección de tinta. Una causa posible es la configuración de calidad de la impresión, puesto que el documento puede requerir una configuración de mayor calidad de la impresora. Otras posibles causas pueden ser que la tinta del cartucho se está agotando o que los cabezales están sucios.

Algunas otras clases de impresoras son importantes por razones históricas o para usos especiales, entre ellas están las siguientes:



</doc>
<doc id="1470" url="https://es.wikipedia.org/wiki?curid=1470" title="Iridio">
Iridio

El iridio es un elemento químico de número atómico 77 que se sitúa en el grupo 9 de la tabla periódica. Su símbolo es Ir. Se trata de un metal de transición, del grupo del platino, duro, frágil, pesado, de color blanco plateado. Es el segundo elemento más denso (después del osmio) y es el elemento más resistente a la corrosión, incluso a temperaturas tan altas como 2000 °C. Solo algunos halógenos y sales fundidas son corrosivas para el iridio en estado sólido. El iridio en polvo es mucho más reactivo y puede llegar a ser inflamable.

Fue descubierto en 1803 entre las impurezas insolubles del platino natural. Smithson Tennant, el primer descubridor, llamó al metal iridio en honor a la diosa Iris, la personificación del arcoíris, debido a los diversos y llamativos colores de sus sales. El iridio es uno de los elementos más raros en la corteza terrestre, con una extracción y consumo anual de tan solo tres toneladas. El Ir y el Ir son los dos isótopos naturales del iridio y también sus únicos isótopos estables; el Ir es el más abundante de los dos.

Los compuestos de iridio más importantes son las sales y ácidos que forma junto con el cloro, aunque el iridio también forma una serie de compuestos organometálicos, utilizados en la catálisis industrial y en investigación. El iridio metálico es usado cuando se necesita alta resistencia a la corrosión a altas temperaturas, como en las bujías de gama alta, crisoles para la recristalización de los semiconductores a altas temperaturas, y los electrodos para la producción de cloro mediante el proceso de cloro-álcali. Los radioisótopos de iridio se usan en algunos generadores de radioisótopos.

El iridio se encuentra en meteoritos en una abundancia mucho mayor que en la corteza terrestre. Por esta razón, la abundancia inusualmente alta de iridio en la capa de arcilla en el límite Cretáceo-Paleógeno dio lugar a la hipótesis de Álvarez de que el impacto de un objeto extraterrestre masivo causó la extinción de los dinosaurios y muchas otras especies hace 65 millones de años. Del mismo modo, una anomalía de iridio en muestras de núcleos del Océano Pacífico sugirió el impacto Eltanin de hace aproximadamente 2,5 millones de años.

El iridio también se emplea en aleaciones de alta resistencia que pueden soportar altas temperaturas. Es un elemento poco abundante y se encuentra en la naturaleza en aleaciones con platino y osmio. Se emplea en contactos eléctricos, aparatos que trabajan a altas temperaturas, y como agente endurecedor del platino.

Es de color blanco, parecido al platino, pero presenta una ligera coloración amarilla. Es difícil trabajar este metal, pues es muy duro y quebradizo. Es el metal más resistente a la corrosión. No es atacado por los ácidos, ni siquiera por el agua regia. Para disolverlo se emplea ácido clorhídrico, HCl, concentrado con clorato de sodio, NaClO a temperaturas altas.

El iridio es considerado comúnmente un metal extraterrestre, ya que abunda en los meteoritos y es raro en la corteza terrestre, con solo una pequeña concentración de 0,001 ppm. Es el metal más denso después del osmio. Se sabe que en el núcleo de la Tierra se encuentra este metal junto al hierro y al níquel, sus componentes más importantes.

Pertenece a los metales del grupo del platino. Debido a su dureza, fragilidad y su alto punto de fusión (el noveno más alto de todos los elementos), es difícil dar forma o trabajar sobre el iridio sólido como se haría con otros metales, por lo que se prefiere trabajarlo en forma de polvo metálico. Es el único metal que mantiene buenas propiedades mecánicas por encima de los 1600 °C. El iridio tiene un punto de ebullición muy alto (el décimo entre todos los elementos) y se convierte en superconductor a temperaturas debajo de los 0.14 K.

El módulo de elasticidad del iridio es el segundo más alto de todos los elementos, superado únicamente por el del osmio; esto, junto con un alto módulo de rigidez y un bajo coeficiente de Poisson, indica el alto grado de rigidez y resistencia a la deformación que han hecho que su manipulación sea una cuestión de gran dificultad. A pesar de estas limitaciones y del alto costo del iridio, es muy valioso para aplicaciones donde la resistencia mecánica es un factor esencial y se usa en algunas tecnologías modernas que operan en condiciones extremas.

La densidad medida del iridio es ligeramente inferior (0,1%) a la del osmio, el cual es el elemento más denso conocido. Anteriormente existía una ambigüedad respecto a qué elemento era más denso, debido a la pequeña diferencia de densidades entre estos dos elementos y la dificultad para medir con precisión dicha diferencia. Con la mayor precisión en los factores utilizados para calcular la densidad cristalográfica mediante rayos X se pudieron calcular sus densidades como 22,56 g/cm para el iridio y 22,59 g/cm para el osmio.

El iridio es el metal más resistente a la corrosión conocido: no es atacado por casi ningún ácido, el aqua regia (aunque si pulverizado), metales fundidos o silicatos a altas temperaturas. Puede, sin embargo, ser atacado por algunas sales fundidas, tales como el cianuro sódico y cianuro potásico, como también por el oxígeno y los halógenos (particularmente el flúor) a altas temperaturas.

El iridio forma compuesto en estados de oxidación entre -3 hasta +6, los más comunes son +3 y +4. Los estados de oxidación mayores son poco comunes, pero incluyen al IrF6 y a dos óxidos mixtos, el SrMgIrO y el SrCaIrO. El dióxido de iridio, un polvo marrón, es el único óxido de iridio bien caracterizado, un sesquióxido de iridio, el IrO, ha sido descrito como un polvo de color azul-negro el cual se oxida a IrO por exposición al HNO. También se han encontrado compuestos de iridio y Azufre, como el IrS. El iridio también forma compuestos con estados de oxidación +4 y +5, como KIrO y KIrO, que puede ser preparado a partir de la reacción del óxido de potasio o del superóxido de potasio con iridio a altas temperaturas.
Actualmente no se conocen hidruros binarios de iridio (IrH), pero se conocen hidruros complejos como el IrH
de iridio con todos los hálogenos. Para estados de oxidación +4 y superiores, únicamente se conocen el tetrafluoruro, el pentafluoruro y el hexafluoruro. El hexafluoruro de iridio, es un sólido amarillo volátil y altamente reactivo, compuesto de moléculas octaédricas. Se descompone en agua y se reduce a IrF, un sólido cristalino de iridio negro. El pentafluoruro de iridio tiene propiedades similares pero en realidad es un tetrámero, IrF, formado por cuatro octaedros que comparten esquinas.

El HIrC, y su sal amónica son los compuestos de iridio más importantes desde el punto de vista industrial. Estos compuestos están involucrados en la purificación de iridio y se utilizan como precursores para la mayoría de los otros compuestos de iridio, así como en la preparación de recubrimientos para ánodos. El ion IrCl tiene un intenso color marrón oscuro, y puede ser fácilmente reducido a IrCl, de un color más claro, y viceversa. El tricloruro de iridio (IrCl), que se puede obtener en forma anhidra de la oxidación directa del polvo de iridio mediante cloro a 650 °C, o en forma hidratada mediante la disolución de IrO en ácido clorhídrico, es a menudo utilizado como materia prima para la síntesis de otros compuestos de Ir(III). Otro compuesto que se utilizan para sintetizar otros compuestos de Ir(III) son el hexacloroiridio de amonio ((NH)IrC). Los compuesto de Ir(III) son diamagneticos con una geometría molecular octaédrica.

Los compuestos organoiridicos contienen enlaces iridio-carbono, donde por lo general, el metal se encuentra en los estados de oxidación más bajos, por ejemplo, el estado de oxidación 0 se encuentra en el tetrairidio dodecarbolino (Ir(CO)), el cual es el más común y estable carbonilo binario de iridio, en este compuesto, cada uno de los átomos de iridio se enlaza a los otros tres, formando así una estructura tetraédrica. Algunos compuestos organometálicos de Ir(I) so lo suficientemente importantes como para llevar el nombre de sus descubridores. Uno de ellos es el complejo de Vaska (IrCl(CO)[P(CH)]), el cual tiene la rara cualidad de unirse a la molécula de oxígeno diatómico (O). Otra es la catálisis de Crabtree, una catálisis homogénea llevada a cabo mediante reacciones de hidrogenación. Estos compuestos tienen una estructura cuaternaria planar, d compleja, con un total de 16 electrones de valencia, lo que explica su capacidad de reacción.

El iridio tiene dos isotopos naturales estables, el Ir y el Ir, con una abundancia natural de 37.3% y 62.7%, respectivamente. Al menos 34 radioisótopos han sido sintetizados variando entre números másicos de 164 a 199. El Ir, el cual se desintegra en los dos isótopos estables, es el radioisótopo más estable con una semivida de 73.827 días. Otros tres isótopos, el Ir, Ir, Ir, tienen una semivida de al menos un día. Isótopos con número de masa debajo de 191 decaen mediante una combinación de desintegración ß, desintegración α y emisión de protones, con la excepción del Ir, que decae por medio de captura electrónica, y el Ir, el cual decae por medio de emisión de positrones. Isótopos sintéticos con una masa atómica mayor a 191 decaen mediante desintegración β, aunque el Ir también puede decaer en menor medida mediante captura de electrones. Todos los isotopos conocidos de iridio fueron descubiertos entre 1934 y 2001, el más reciente de ellos es el Ir.

Al menos 32 isómeros metaestables han sido caracterizados, variando en masa atómica entre 164 a 197, el más estable de todos estos es el Ir, el cual decae mediante transición isomérica con una semivida de 241 años, por lo que es más estable que cualquiera de los isótopos sintéticos de iridio en sus estados fundamentales. El menos estable es el Ir, con una semivida de apenas 2 µs. El isótopo Ir fue el primer elemento en que se vio el efecto Mößbauer, lo que lo hace útil para la espectroscopia Mössbauer en investigaciones físicas, químicas, bioquímicas, metalúrgicas y mineralógicas.

El descubrimiento del iridio data de la misma época en que se descubrió el platino y el resto de metales de su grupo. El platino elemental fue usado por los antiguos etíopes y por las culturas sudamericanas, las cuales siempre tuvieron acceso a una pequeña cantidad de metales del grupo del platino, incluyendo el iridio. El platino llegó a Europa con el nombre de "platina" (pequeña plata), descubierto en el siglo XVII por españoles en la región que hoy se conoce como Departamento de Chocó en Colombia. Pero el descubrimiento de que este metal era un elemento nuevo y no una aleación de elemento conocidos no se produjo hasta 1748.

Los químicos que estudiaron el platino encontraron que este se disolvía en aqua regia, creando sales solubles. Estos químicos siempre notaban una pequeña cantidad de un residuo de color oscuro insoluble. Joseph Louis Proust pensó que este residuo se debía a grafito. Los químicos franceses Victor Collet-Descotils, Antoine François, el conde de Fourcroy, y Louis Nicolas Vauquelin también observaron el residuo oscuro en 1803, sin embargo, no obtuvieron suficiente como para realizar experimentos. Ese mismo año un científico británico, Smithson Tennant analizó el residuo insoluble y concluyó que este debía de contener un nuevo metal. Vauquelin expuso el residuo en polvo a álcalis y ácidos y obtuvo un nuevo óxido volátil, el cual él creía que se trataba del nuevo metal que llamó "ptene", que provenía de la palabra griega πτηνος (ptènos) y significaba "Alado". Tennant, que contaba con una cantidad mucho más grande del residuo, continuó su investigación e identificó dos nuevos elementos dentro del residuo negro, el iridio y el osmio. Obtuvo cristales de color rojo oscuro (probablemente de Na[IrCl]•nHO)por una serie de reacciones con hidróxido de sodio y ácido clorhídrico. Llamó a uno de los elemento iridio en honor a la diosa griega Iris, debido a los colores de sus sales. El descubrimiento de los nuevos elementos fue documentado en una carta a la Royal Society el 21 de junio de 1804.

El científico británico John George Children fue el primero en fundir una muestra de iridio en 1813 con la ayuda de la "mejor batería galvánica que jamás se haya construido" (hasta esa época).

El primero en obtener iridio puro fue Robert Hare en 1842. Encontró que la densidad del iridio rondaba los 21.8 g/cm y notó que el metal no era maleable y era extremadamente duro.

La primera fundición de una cantidad significativa del metal fue realizada por Henri Sainte-Claire Deville y Jules Henri Debray en 1860. Para fundir el metal, se necesitó más de 300 litros de O puro y H por cada kilogramo de iridio. Estas dificultades extremas para fundir el metal han limitado las posibilidades de manejar el iridio.

John Isaac Hawkins estaba buscando obtener una pluma con una punta fina y dura, y en 1834 logró crear una pluma de oro con punta de iridio.

En 1880, John Holland y William Lofland Dudley, lograron fundir iridio añadiendo fósforo, más tarde patentarían el proceso en los Estados Unidos. La compañía británica Johnson Matthey indicó más adelante que había estado utilizando un proceso similar desde 1837 y ya había presentado iridio fundido en una serie de ferias por todo el mundo. El primer uso de una aleación de iridio con rutenio fue realizada para fabricar termopares por Otto Feussner en 1933. Esto permitió medir temperaturas en el aire de hasta 2000 °C.

En 1957 Rudolf Ludwig Mößbauer, descubrió el efecto de la resonancia y retroceso-libre y absorción de rayos gamma en átomos de una muestra de sólido que únicamente contenía Ir. Por este fenómeno, conocido como el Efecto Mößbauer (que desde entonces se ha observado en otros núcleos como el del Fe), Mößbauer recibió el premio nobel de física en el año de 1961, solo tres años después de publicar su descubrimiento

El iridio es uno de los elementos menos abundantes en la corteza terrestre, en promedio solo se encuentra una fracción de masa de 0.001 ppm en toda la corteza; el oro es 40 veces más abundante, el platino 10 veces más, y la plata y el Mercurio unas 80 veces más abundantes que el iridio. El telurio es tan abundante como el iridio. Únicamente existen tres elementos tan poco abundantes como el iridio: el renio, el rutenio y el rodio; el iridio es 10 veces más abundante que los últimos dos. En contraste con su escasa abundancia en la corteza terrestre, el iridio es relativamente común en los meteoritos, con una concentración de 0,5 ppm o más.

El iridio se puede encontrar en la naturaleza como un elemento sin combinar o en aleaciones naturales, especialmente las aleaciones de osmio-iridio, estas aleaciones se pueden separar en dos grandes grupos: las aleaciones osmiridio, las cuales son más ricas en osmio, y las iridiosmio que contienen una mayor cantidad de iridio que de osmio. También se encuentra en los depósitos de níquel y cobre, normalmente se encuentran metales del grupo del platino en estos yacimientos en forma de sulfuros, telururos, antimoniuros, y arseniuros. Dentro de la corteza terrestre, el iridio se encuentra en concentraciones más altas en tres tipos de estructura geológica: los depósitos ígneos, los cráteres de impacto, y depósitos elaborados a partir de una de estas estructuras. La reserva primaria de iridio más grande conocida es la del complejo ígneo Bushveld en Sudáfrica, aunque los grandes depósitos de cobre-níquel cerca de Norilsk, en Rusia, y la cuenca de Sudbury en Canadá también son importantes fuentes de iridio. Pequeñas reservas de este metal también han sido encontradas en los Estados Unidos. El iridio puede encontrarse en depósitos secundarios, combinado con el platino u otros metales del grupo del platino en depósitos aluviales. Este tipo de depósitos fueron explotados por las culturas precolombinas en el departamento del Chocó, aún hoy en día siguen siendo una fuente de metales del grupo del platino.

El límite K-T de 65 millones de años, marca la frontera temporal entre los períodos Cretácico y el Cenozoico del tiempo geológico, fue identificado debido a una delgada capa de arcilla rica en iridio, la cantidad de esta capa de iridio podría contener 200.000 toneladas de ese metal. En 1980, un equipo liderado por Luis Walter Álvarez, propuso un origen extraterrestre para todo este iridio encontrado en la capa; lo atribuyó a un impacto de asteroide o de un cometa. Esta teoría, conocida como la hipótesis Álvarez, es la más aceptada para explicar la extinción de los dinosaurios. Un gran cráter de impacto enterrado que data de hace 65 millones de años fue identificado en lo que hoy se conoce como la península de Yucatán (el cráter de Chicxulub). Dewey M. McLean y otros científicos argumentan que ese iridio podría tener orígenes volcánicos debido a que el núcleo de la tierra es rico en iridio, y aún hoy, volcanes activos como el Piton de la Fournaise ("pico del horno") en la isla de Reunión siguen liberando iridio.

El iridio se obtiene comercialmente como un subproducto de la minería y producción de níquel y cobre. Mediante la electrorrefinación del cobre y el níquel, metales nobles como la plata, el oro y los metales del grupo del platino, así como el selenio y el telurio se depositan en el fondo de la celda como barro anódico, el cual constituye el punto de partida para su extracción. Con el fin de separar los metales, lo primero que debe hacerse es disolver el barro en una solución. Existen varios métodos, dependiendo del proceso de separación y la composición de la mezcla. Dos métodos muy usados son fundir con peróxido de sodio y luego disolver en aqua regia, el otro consiste en disolver en una mezcla de cloro y ácido clorhídrico.

Después de que se disuelva, el iridio se separa de otros metales del grupo platino por la precipitación de (NH)IrCl o mediante la extracción de IrCl con aminas orgánicas. El primer método es similar al procedimiento de Tennant y Wollaston utilizado para su separación. El segundo método se puede planificar como una continua extracción líquido-líquido y por lo tanto más adecuada para la producción a escala industrial. En cualquier caso, el producto se reduce mediante el uso de hidrógeno, produciendo el metal en forma de polvo o esponja que se puede tratar con técnicas de metalurgia de polvos.

La producción anual de iridio en el año 2000 fue de alrededor de 3 toneladas, lo que equivale a aproximadamente 100.000 onzas troy (ozt). El precio del iridio alcanzó en 2007 un precio de 440 dólares por onza troy, pero el precio ha fluctuado considerablemente, como se muestra en la tabla, en el año 2010 el precio se elevó a más 750 USD/ozt, sin embargo, en promedio se ha mantenido en el rango de los años 2007-2009, es decir, de $425–$460 USD/ozt. La alta volatilidad en los precios de los metales pertenecientes al grupo del platino se ha atribuido a la oferta, demanda, la especulación y acaparamiento, amplificada por el pequeño tamaño del mercado y la inestabilidad de los países productores.

El alto punto de fusión, la dureza y resistencia a la corrosión del iridio y sus aleaciones determinan la mayoría de sus aplicaciones. El iridio y especialmente las aleaciones iridio-platino u osmio-iridio tienden a desgastarse muy poco y son usadas, por ejemplo, en múltiples hileras de poros, a través de las cuales un plástico fundido se extruye para formar fibras, como el rayón. Las aleaciones de osmio-iridio son usadas en brújulas y balanzas.

La resistencia a la corrosión y al calor hacen del iridio un agente de aleación importante. Algunas piezas de larga duración en motores de avión están hechas de iridio aleado y en tuberías para aguas profundas se usa una aleación especial de titanio-iridio debido a su resistencia a la corrosión. El iridio también es ampliamente utilizado como agente endurecedor en aleaciones de platino. La dureza Vickers del platino puro es de 56 HV, mientras que la de una aleación con 50% de iridio puede alcanzar durezas por encima de los 500 HV.

A menudo, dispositivos que están expuestos a temperaturas extremas se hacen de iridio, por ejemplo, crisoles de alta temperatura hechos de iridio se utilizan en el proceso Czochralski para producir óxido de monocristales (como zafiros) para usar en dispositivos de memoria en computadoras y en láseres de estado sólido. La gran resistencia a la abrasión del iridio y sus aleaciones lo hacen ideal para fabricar los contactos eléctricos en bujías.

Compuestos de iridio se utilizan como catalizadores en el proceso Cativa para la carbonilación del metanol para producir ácido acético El iridio en sí mismo es usado como catalizador en un tipo de motor para automóvil introducido en 1996 llamado motor de ignición directa. El radioisótopo Ir es una de los dos fuentes de energía más importantes para uso industrial de la radiografía de rayos γ en los ensayos no destructivos para metales. Además, Ir se utiliza como una fuente de radiación gamma para el tratamiento del cáncer mediante braquiterapia, una forma de radioterapia donde se coloca una fuente radiactiva sellada en el interior o junto a la zona que requiere tratamiento.

En 1889 se usó una aleación de 90% de platino y 10% de iridio para construir el prototipo internacional de metro y kilogramo realizado por la oficina internacional de pesas y medidas cerca a París. La definición de la barra de metro fue reemplazada de la unidad fundamental de medición en 1960 por una línea del espectro atómico del kriptón, pero el prototipo de kilogramo sigue siendo el estándar internacional de masa. El iridio ha sido utilizado en los generadores termoeléctricos de radioisótopos de naves espaciales no tripuladas, como el Voyager, Viking, Pioneer, Cassini, Galileo y en la nave New Horizons. El iridio fue escogido para encapsular el combustible de plutonio-238 en el generador debido a la gran resistencia del material y sus capacidades operativas por encima de los 2000 °C. También se utiliza este metal para generar Rayos X ópticos, en especial en telescopios de rayos X. Los espejos del observatorio de rayos X Chandra están recubiertos con una capa de iridio 60 nm de espesor. El iridio demostró ser la mejor opción para reflejar rayos X, superando a metales como el níquel, el oro, el platino. La capa de iridio, la cual tuvo que ser del espesor de apenas unos cuantos átomos, fue aplicada mediante alto vacío depositando iridio gaseoso en una capa base de cromo.

El iridio se usa en la física de partículas para la producción de antiprotones, una forma de antimateria. Los antiprotones se producen al disparar un haz de protones de alta intensidad a un "objetivo de conversión", que debe ser hecho de un material extremadamente denso. A pesar de que el tungsteno se puede utilizar en lugar del iridio, este último tiene la ventaja de que posee una mejor estabilidad bajo las ondas de choque inducidas por el aumento de la temperatura durante el rayo incidente. Complejos de iridio están siendo investigados como catalizadores para hidrogenación asimétrica. Estos catalizadores se han utilizado en la síntesis de productos naturales capaces de hidrogenar determinados sustratos difíciles, tales como alquenos, enantioselectivamente (la generación de sólo uno de los dos enantiómeros posibles). El iridio forma una variedad de complejos de interés fundamental en la recolección de tripletes.

Aleaciones de iridio-osmio se han usado en plumas estilográficas. El primer uso de una cantidad importante de iridio fue en el año de 1834 en una punta de iridio montada en oro. Desde 1944, la famosa pluma estilográfica "Parker 51" fue equipada con una punta de una aleación de rutenio e iridio (3.8% de iridio). Se han utilizado aleaciones de platino-iridio en los agujeros de ventilación de cañones; esta es una aplicación importante pues evita los gastos ocasionados por el desgaste de estos orificios cuando están en servicio. El pigmento ""iridio negro"", el cual consiste en iridio dividido muy finamente, se usa para colorear porcelanas de un color negro intenso.

El iridio en forma de metal no es peligroso para la salud debido a su poca reactividad con los tejidos, únicamente hay 20 partes por trillón de iridio en los tejidos humanos. Sin embargo, el polvo finamente dividido de iridio puede ser peligroso de manejar, ya que es irritante y puede inflamarse en el aire. Se sabe muy poco acerca de la toxicidad de los compuestos de iridio debido a la escasez del metal y a que sus compuestos se utilizan en cantidades muy pequeñas, pero las sales solubles, tales como los haluros de iridio, podrían ser peligrosos debido a los otros elementos que forman parte del compuesto. Sin embargo, la gran mayoría de los compuestos de iridio son insolubles, lo que hace que la absorción involuntaria de estos compuestos por el cuerpo humano sea difícil. Un radioisótopo de iridio, el Ir, es peligroso al igual que cualquier otro isótopo radioactivo. Los únicos reportes relacionados con lesiones por iridio conciernen a la exposición accidental de Ir usado en braquiterapia. Las altas radiaciones de rayos gamma de alta energía por el Ir pueden incrementar el riesgo de cáncer. La exposición externa puede causar quemaduras, envenenamiento por radiación, y la muerte. La ingestión de Ir puede quemar el revestimiento del estómago y de los intestinos. Ir, Ir y Ir tienden a depositarse en el hígado, y puede plantear riesgos para la salud tanto por radiación gamma como por radiación beta.




</doc>
<doc id="1471" url="https://es.wikipedia.org/wiki?curid=1471" title="Intérprete de comandos">
Intérprete de comandos

Un intérprete de órdenes o de comandos, es un programa informático que tiene la capacidad de traducir las órdenes que introducen los usuarios, mediante un conjunto de instrucciones facilitadas por él mismo directamente al núcleo y al conjunto de herramientas que forman el sistema operativo. Las órdenes se introducen siguiendo la sintaxis incorporada por dicho intérprete, dentro del entorno proporcionado por el emulador de terminal, mediante un inductor que espera a que le sean introducidos los comandos o instrucciones codice_1

Al ingresar la orden con la tecla 'Intro', el intérprete analiza la secuencia de caracteres ingresada y, si la sintaxis de la orden es correcta, la ejecuta, recurriendo para ello a las funciones que ofrece el sistema operativo o el programa que representa, bien sea un gestor de datos de banco, una sesión de FTP, de ssh, etc. La respuesta al usuario se representa en el monitor o en forma de segundo plano. Se trabaja de manera interactiva, es decir, usuario y máquina se comunican de forma sucesiva.

Incorporan características tales como control de procesos, redirección de entrada/salida, listado y lectura de ficheros, protección, comunicaciones y un lenguaje de órdenes para escribir programas por lotes o (scripts o guiones). Uno de los intérpretes más conocidos, es el Bourne Shell, el cual fue el intérprete usado en las primeras versiones de Unix y se convirtió en un estándar de facto.



</doc>
<doc id="1473" url="https://es.wikipedia.org/wiki?curid=1473" title="Islas Baleares">
Islas Baleares

Las Islas Baleares (en catalán y oficialmente, "Illes Balears") son una comunidad autónoma uniprovincial española, compuesta por las islas del archipiélago balear. Se encuentran situadas en el mar Mediterráneo, frente a la costa oriental de la península ibérica. Su capital es Palma.

El archipiélago está formado por dos grupos de islas y numerosos islotes: las islas Gimnesias (Mallorca, Menorca, Cabrera y algunos islotes cercanos como Dragonera, Conejera o la isla del Aire) y las islas Pitiusas (Ibiza y Formentera, junto los islotes que las rodean, como Espalmador —de propiedad privada— y Espardell).

A pesar de que durante mucho tiempo se ha creído que "Baleares" provenía de la palabra griega "ballein", que significa "lanzar", últimamente se ha cambiado de opinión y parece que se descarta el origen helénico. Lo cierto es que los griegos utilizaron la palabra "Gimnesias" para referirse a las islas de Menorca y Mallorca. En cambio, cartagineses y romanos prefirieron la denominación "Baleares" para Menorca y Mallorca. Todos ellos llamaron a Ibiza y Formentera Pitiusas. El origen del nombre "Baleares" no es griego sino púnico, y proviene del plural "ba' lé yaroh". El substantivo "ba' lé" significa "los que ejercitan el oficio de" y actúa como sujeto del verbo "yaroh" que significa "tirar piedras". El significado final sería algo así como "los maestros del lanzamiento". Y estos maestros del lanzamiento eran los honderos de las islas. Así pues, Baleares significa "honderos". Autores clásicos como Plinio el Viejo o Diodoro Sículo han hablado mucho de ellos.

La geografía del archipiélago de las Islas Baleares comprende Mallorca, Cabrera, Menorca, Ibiza y Formentera. En total el territorio tiene 4992km² y va desde el nivel del mar hasta los 1445m de altitud en el Puig Mayor de la Sierra de Tramontana de Mallorca. Las coordenadas geográficas están entre los 40º5'48' y 38º40'30' de latitud N y entre 1º12'47' y 4º19' de longitud E. Ibiza está separada de la costa de la Comunidad Valenciana por solo 75 km de mar, esta misma distancia separa Mallorca de Ibiza. La distancia mínima que separa Mallorca de Menorca es de 35 km.

La Prehistoria e historia antigua de las Islas Baleares precisa diferenciar entre las islas de Mallorca y Menorca y las de Ibiza y Formentera.

En las islas de Mallorca y Menorca, las primeras evidencias claras de población estable se remontan al Actualmente su prehistoria se divide en cinco fases sucesivas:


En el caso de Ibiza y Formentera la presencia de población estable es similar a la de las islas mayores pero en torno al (mediados del s. VII) aparece la presencia confirmada de asentamientos fenicios, probablemente procedentes de Gadir más que de Oriente en los asentamientos de Sa Caleta y Vila (Iboshim), convirtiendo así a la ciudad en la primera fundada del archipiélago y una de las primeras de España. Desde Iboshim un floreciente comercio unía las islas con todos los puntos del Mediterráneo, con productos importados o propios como la sal de Ibiza o la de Mallorca, explotada por los iboshitanos desde los islotes de Na guardis o de Na Galera, en Mallorca.

Los romanos conquistaron las islas de Mallorca y Menorca y se aliaron con Iboshim en torno al año , unificando por primera vez todo el archipiélago bajo una misma administración y una misma cultura (pues había una dicotomía del fondo étnico —que persiste actualmente en una diferencia insalvable de cultura— entre las Pitiusas, pobladas por fenicios, y las Gimnesias, con gentes pertenecientes a la cultura talayótica), aunque la colonización romana fue poco intensa. Incorporadas al principio a la Hispania Citerior, y posteriormente a la Tarraconensis, las islas formaron parte de la provincia Cartaginense durante el Bajo Imperio, y a finales del siglo IV se constituyeron en provincia independiente (Balearica).

En el año 406 la helada del Rin facilitó la entrada de pueblos germánicos (suevos, vándalos y alanos), que en el año 409 traspasaron los Pirineos para asentarse temporalmente en la Península. En el año 429 las islas Baleares fueron saqueadas junto a Cartagena, Sevilla y el resto de Hispania, según cuenta el historiador Hidacio. Después de ello cruzaron el estrecho fundando el Reino vándalo, incorporando las islas en el año 455. Más tarde, en el año 534, fueron conquistadas por las
tropas de Justiniano I e integradas al Imperio bizantino hasta principios del siglo VIII. La crisis económica y demográfica del archipiélago, a lo largo de los siglos VII al IX, les expuso de forma creciente a los ataques exteriores. Después de una etapa de incursiones, el Emirato de Córdoba las ocupó en el año 903. Posteriormente, dependieron de la Taifa de Denia (1013-1067), del Imperio Almorávide (1120-1203) y de los Almohades (del 1203 hasta la conquista cristiana).

La Corona de Aragón experimentó durante los siglos XII y XIII una fuerte expansión hacia el Mediterráneo, que la llevó hasta las Baleares. El origen de la actual extensión del catalán se encuentra en la Corona de Aragón, donde el catalán era el idioma dominante y más hablado, hablado por el 80% de la población. Jaime I de Aragón capitaneó una flota que desembarcó en Mallorca a finales del verano de 1229. Después de largos combates que se prolongaron durante meses, el rey entró victorioso en la ciudad el 31 de diciembre de ese mismo año. El asalto fue seguido de una matanza indiscriminada que ocasionó un verdadero genocidio de la población mallorquina; tanto es así que los miles de cadáveres que no pudieron ser enterrados provocaron una epidemia entre los conquistadores que causó numerosas bajas. Como consecuencia, los nobles quisieron quedarse con todo el botín en lugar de sortearlo entre la tropa. Esto provocó la revuelta de peones y caballeros. Finalmente se produjo el reparto del botín que duró hasta el 30 de abril de 1230.

Gracias a todo esto, los musulmanes supervivientes tuvieron tiempo de organizar diversos focos de resistencia en las montañas, lo que prolongó un par de años las luchas contra los musulmanes de Mallorca que, finalmente, terminaron convertidos en esclavos o semiesclavos.
Así, las Baleares fueron repobladas mayoritariamente por payeses del Rosellón, Gerona y Barcelona.

Toda esta destrucción debilitó también al ejército de Jaime I hasta el punto de que, cuando Menorca pidió el vasallazgo de la Corona, se le concedió. Así, Menorca se convirtió en una Taifa autónoma, donde la religión y la cultura árabe se mantuvieron durante medio siglo más. Pero en enero de 1287, la flota de Alfonso III, el Franco, llegó al puerto de Mahón. Se pactó la capitulación de la isla de forma que los caudillos y nobles pudieron escapar a cambio de entregar al resto de la población para que se les esclavizara. Las Islas Baleares fueron repobladas por cristianos originarios del Ampurdán y de la Cataluña Vieja, quienes importaron el catalán a la zona.

Por lo que respecta a Ibiza, también fue conquistada por Jaime I, pero en agosto de 1235. Sus habitantes fueron también esclavizados y sus bienes repartidos entre los magnates.

Durante la II República (1931-1939) se proyectó sin éxito un Estatuto de Autonomía para las Islas Baleares.

En 1936, con el inicio de la guerra civil española, el archipiélago queda dividido en dos zonas: la parte central y oeste (Formentera, Ibiza, Mallorca) quedan dentro del área dominada por los militares alzados contra la Segunda República Española, mientras en Menorca fracasa la insurrección. En los primeros meses del conflicto, se desarrollará desde Cataluña principalmente, una operación para tomar Mallorca, el llamado desembarco de Mallorca, que se desarrollaría entre agosto y septiembre de 1936 y que finalmente sería rechazado por el ejército franquista, volviendo a quedar las cosas igual que antes. En ese momento llegaron desde Italia refuerzos aéreos y de tierra dirigidos por el jerarca fascista Arconovaldo Bonaccorsi, que durante algunos meses de 1936 se convirtió en el verdadero jefe de Mallorca. De hecho, durante toda la contienda la isla de Mallorca se convirtió en una importante base aeronaval italiana, desde la cual las fuerzas italianas acosaron las rutas de suministro republicanas y bombardearon sistemáticamente la retaguardia republicana en Levante. En febrero de 1939 la isla de Menorca fue ocupada por las tropas franquistas.

Tras la transición regresan los ánimos autonomistas y en 1983 finalmente es aprobado un Estatuto de Autonomía de las Islas Baleares.

La provincia de las Islas Baleares es la 13.ª de España en que existe un mayor porcentaje de habitantes concentrados en su capital (36,29%, frente al 31,96% del conjunto de España).

El archipiélago ha sufrido un gran crecimiento demográfico tras el boom turístico de los años 1960: en el periodo 1970-2005, este fue del +76,10%, frente al +29,90% de la media española. En el año 2018, la población total de las islas asciende a personas.

Según el Padrón municipal de habitantes (INE, 2010), un 21,9% de la población balear es de nacionalidad extranjera, siendo la Comunidad Autónoma y la segunda provincia de España —tras Alicante— con mayor número de residentes foráneos. Un 52,4% de los extranjeros provienen de la Unión Europea, destacando los alemanes (14,9% del total), británicos (9,7%), italianos (6,9%), rumanos (5,2%) y franceses (3,6%). Un 24,1% viene de América del Sur, destacando por su número los ecuatorianos (5,4%), argentinos (4,5%), y colombianos (4,2%). Un 14,8% viene de África, principalmente de Marruecos (9,9%) y Nigeria (1,4%).

Dos son los idiomas cooficiales en las Islas Baleares en estos momentos. El español, al igual que en el resto del estado, y el catalán, lengua cooficial definida en su Estatuto de Autonomía. El castellano es, además, la lengua habitual de uso para una mayoría de la población balear. La denominación del catalán en las islas no es unánime en tanto que se reivindica también la distinción de los dialectos baleares (mallorquín, menorquín e ibicenco) como idiomas con entidad propia, lo cual no está exento de connotaciones políticas.

En las zonas turísticas, es común que se utilicen idiomas extranjeros, (como el inglés y el alemán) en locales o en eventos de importancia.

La capital de las Islas Baleares y de la isla de Mallorca es la ciudad de Palma, también llamada "Ciutat". En ella se encuentra la sede del Gobierno Balear, del Parlamento de las Islas Baleares y del Consejo Insular de Mallorca.

Al margen del gobierno autonómico, cada una de las islas está dotada con una organización política y administración propia detentada por los denominadas Consejos Insulares: el Consejo Insular de Mallorca con asiento en la propia ciudad de Palma, el Consejo Insular de Menorca que tiene su sede principal en Mahón a pesar de que esta isla no tiene atribuida la capitalidad legal reconocida a ninguna población, el Consejo Insular de Ibiza cuya sede está en la ciudad de Ibiza (popularmente identificada como "Vila") y el Consejo Insular de Formentera con sede en San Francisco Javier.
El Consejo Insular de Formentera fue creado en 2007 con la reforma del estatuto de autonomía de las Islas Baleares, ya que anteriormente Formentera e Ibiza compartían órgano de gobierno y administración (el llamado Consejo Insular de Ibiza y Formentera). Desde las elecciones de 2007 se vota separadamente de manera directa para elegir la composición de los Consejos Insulares, cuyos miembros anteriormente coincidían con los diputados de cada isla elegidos para el Parlamento de las Islas Baleares.

Gimnesias y Pitiusas han tenido una historia geográfica diferente. Durante las glaciaciones del Cuaternario, debido a la acumulación de agua en forma de hielo en los casquetes polares y en las grandes sierras, mares y océanos bajaron de nivel. Esto provocó que se unieran Menorca y Mallorca por un lado e Ibiza y Formentera por el otro. Todas las faunas y floras se mezclaron, pero entre la Gran Gimnesia y la Gran Pitiusa no fue así, ya que permaneció un canal marino de más de 70km, infranqueable por la fauna terrestre. La menor medida de la Gran Gimnesia (2000km²) y un clima más árido provocó la extinción de la fauna terrestre y la falta de vegetales arbóreos notables.

En el pasado, Gimnesias y Pitiusas tuvieron ecosistemas distintos. Las Gimnesias tenían bosques de encinas en el interior y en los llanos costeros grandes bosques de boj balear ("Buxus balearica"), planta que aún se puede encontrar de forma residual en Mallorca. Las Pitiusas estaban prácticamente desnudas de vegetación arbórea y predominaban las hierbas nitrófilas producto del efecto de las deyecciones de la gran cantidad de colonias de aves que tenían.

Actualmente hay en las Baleares numerosas plantas endémicas, entre otras "Apium bermejoi, Euphorbia fontqueriana, Euphorbia margalidiana, Euphorbia pithyusa, Galium balearicum, Galium crespianum, Galium friedrichii" o "Helleborus lividus".

En el pasado, la fauna de las Gimnesias y de las Pitiusas era muy distinta. Parece ser que, a excepción de las especies voladoras (aves, murciélagos e insectos voladores) no compartían casi ninguna especie terrestre: diferentes comunidades vegetales, diferentes herbívoros, diferentes carnívoros como Hypnomys morpheus, especies de "Myotragus" o "Nesiotites hidalgo".

Cuenta con algunas especies endémicas como el sapillo balear ("Alytes muletensis"), o las lagartijas balear ("Podarcis lilfordi") y de las Pitiusas ("Podarcis pityusensis").

El fenómeno del turismo ha modificado el tipo de economía de las islas. Más de un 70% de la población (2001) se dedica al sector servicios. La industria de la zona es básicamente la del textil, el cuero y el calzado. El turismo está muy desarrollado y es la principal fuente de ingresos. Palma, la capital de las Islas Baleares, y Mallorca son las zonas más visitadas y famosas por los turistas.

Las Islas Baleares constituyen la tercera comunidad autónoma española con mayor número de turistas extranjeros, detrás de Canarias, en segundo lugar y Cataluña, en primer lugar. Recibe más de 9,8 millones de turistas extranjeros anualmente. Según los datos aportados por AENA (Aeropuertos Españoles y Navegación Aérea) Mallorca es el principal destino turístico en las islas, con el 65% del total. La sigue Ibiza, con un 37% y luego Menorca y Formentera, con un 18,13% y un 12,37%, respectivamente. Los turistas que visitan las islas provienen principalmente de Europa, sobre todo de Alemania y Reino Unido.

La generación de energía en las islas corre a cargo básicamente de las cinco centrales térmicas instaladas en Mallorca, Menorca e Ibiza:

Como muestra del arte prehistórico, las islas conservan muchos restos de la denominada cultura megalítica balear entre los que destacan los talayot o "talaiots", las navetas o "navetes" y las taulas o "taules", todos ellos del periodo comprendido entre 1800 y 1500 a. C.
No son muchos los restos que quedan de la época musulmana. La catedral de Santa María de Palma de Mallorca, la Lonja y el castillo de Bellver (construcción circular que preside con su Torre del Homenaje la bahía de Palma) son claras muestras del arte gótico. Cabe destacar también, durante ese periodo iglesias como la de Santa Creu, Santa Eulalia, San Jaume, San Nicolás... Posteriormente iglesias como San Francisco, Montesión... En Ciudadela y Palma existen algunos ejemplos de la arquitectura del siglo XVIII, periodo en el que destacó como pintor P. Calvo.

La gastronomía de Baleares posee muchos puntos de contacto con la cocina catalana y valenciana. Es de características puramente mediterráneas. Las islas han sido conquistadas varias veces durante su historia entre franceses e ingleses, lo que puede decirse que ha dejado ciertas influencias culinarias. Cabe mencionar que existen marcadas diferencias entre la cocina mallorquina y menorquina.

Entre los ingredientes más típicos se encuentran el cerdo y sus subproductos. Uno de los más típicos es la sobrasada (embutido con carne, tocino y abundante pimentón), que se consume de diversas formas: en Mallorca se hornea y se asa, y en Menorca se fríe (a veces se sirve con miel). Existen otros embutidos, como el "camaiot", la butifarra ("botifarró") y el "xolís" (de origen campesino).




</doc>
<doc id="1477" url="https://es.wikipedia.org/wiki?curid=1477" title="Ibn Hazm">
Ibn Hazm

Abu Muḥammad ʿAli ibn Aḥmad ibn Saʿīd ibn Ḥazm (árabe: ), más conocido como Ibn Hazm, aunque también fue llamado entre los cristianos Abén Házam (Córdoba, 7 de noviembre de 994 - Montíjar, Huelva, 15 de agosto de 1064), fue un filósofo, teólogo, historiador, narrador y poeta andalusí, considerado el «Padre de la Religión comparada». (456 AH Fue el único autor que dejó algunas indicaciones sobre los grupos tribales que pasaron a al-Ándalus en la época de la conquista. Sus antepasados fueron hispanos arabizados convertidos al islam.

Nació en los últimos años del siglo X y justo antes de la crisis que acabaría para siempre con el Califato de Córdoba. Provenía de una familia muladí que vivía de la explotación de una finca por Montíjar, cerca de Huelva. Su abuelo se trasladó a la capital califal en los tiempos en que la fama de esta descollaba por todo el mundo, aunque poco se sabe de él. En cambio, sí se sabe que su padre, Ahmad, fue un hombre culto y hábil, ya que, una vez que hubo entrado en el mundo político cordobés, se ganó la confianza tanto del califa como del visir, Almanzor, llegando a ser nombrado él mismo visir y tomando el mando cuando se ausentaba Almanzor. Así, su hijo 'Ali pasó su infancia en la corte cordobesa de al-Zahira.

Perteneciendo pues a la aristocracia cordobesa, vivió de primera mano el estallido de la guerra civil cordobesa, que quebró su apacible vida. La familia de 'Ali se situó de lado del bando legitimista Omeya, en contraposición de los que apoyaban el nuevo linaje amirí, el de su antiguo protector Almanzor, y ello produjo su caída en desgracia. En 1012 murió su padre Ahmad, y 'Ali tuvo que marcharse desterrado a Almería.

En Almería, acompañado por su amigo y correligionario Muhammad ibn Ishāq, se enfrentaron al gobernador cuando él cambió de bando y apoyó a un nuevo pretendiente, y acabaron desterrados de nuevo, esta vez en un pueblo llamado Aznalcázar. Estando allí, oyeron que un nuevo pretendiente Omeya estaba levantando un ejército en Játiva con el que reclamar de nuevo el Califato, así que se pusieron en camino para unirse a él. Este, bisnieto de Abderramán III llamado 'Abd al-Rahmān ibn Muhammad ibn 'Abd al-Malik, decidió atacar a los ziríes de Granada antes de llegar a la capital, y allí estos acabaron con su ejército. En esta batalla Ibn Hazm fue hecho prisionero. De ahí se retiró a Játiva, donde, contando unos 28 años, escribió "El collar de la paloma".

En 1023 la ciudad de Córdoba eligió al nuevo Califa, tras la caída del Califato hammudí, siendo el elegido Abderramán V, que eligió como equipo gobernante a Ibn Hazm y su grupo de amigos, haciéndolos visires; antiguos aristócratas cordobeses, eran personas cultas y preparadas, pero sin embargo su gobierno no duró más de mes y medio, tiempo tras el cual el Califa fue ejecutado e Ibn Hazm puesto de nuevo en la cárcel.

A partir de ahí, nuestro 'Ali renunció definitivamente a la política para dedicarse por completo a los estudios jurídicos y teológicos. Abrazó la escuela zahirí, de la que daba cursos junto a su maestro Abū-l-Jiyār de Santarén en la Mezquita mayor de Córdoba hasta que en 1027 fue denunciado por el vulgo cordobés por contravenir la escuela malikí oficial. Desde ese momento renunció a la enseñanza y se dedicó a vagar por los distintos reinos de taifas como polemista y erudito. En 1039 se refugió durante un tiempo en Mallorca, protegido por un magnate. Mantuvo encendidas disputas con tantos otros sabios y reyezuelos de su época, entre otros, con al-Mutadid de Sevilla, que dio como fruto la quema de sus libros en la taifa sevillana, y que inspiró a Ibn Hazm sus famosos versos:

Así, mantuvo esta vida de sabio errante hasta el final de sus días, cuando por fin se retira al cortijo familiar de Montíjar, con la única compañía de sus hijos, y donde se dedica a escribir y escribir. Poco se sabe sin embargo de su vida familiar, ya que habla poco de ella en sus obras.

Fue un ingente polígrafo cuyas miles de páginas no pueden reducirse a una breve explicación. Escribió obras históricas, como "Risāla fī faḍl al-Andalus" («Epístola en elogio de al-Ándalus») o "Naqt al-ʿarūs" («Bordado de la novia»), "Ŷamharat ansāb al-ʿarab" (conocido como Yamhara, «Linajes árabes») y un importante "Al-faṣl fī-l-milal wa-l-ahwāʾ wa-l-niḥal" («Historia crítica de las religiones, sectas y escuelas»), en que traza los rasgos de los sistemas filosóficos contrarios a las religiones positivas, incluidas las antiislámicas. Estas obras solo fueron superadas en Occidente en el siglo XIX.

De carácter didáctico es "Falsafat al-ajlāq" («Los caracteres y la conducta»), traducida al castellano por Miguel Asín Palacios y de tema polémico teológico es "Risālat fī radd ʿalà bni Nagrīla (Polémica teológica con Ibn Nagrella)".

Su obra más famosa es "Ṭawq al-ḥamāma" o "El collar de la paloma" en la que trata el tema del amor. Fue escrito en Játiva hacia 1023. Se trata de un libro de reflexiones sobre la verdadera esencia del amor, intentando descubrir lo que tiene de común e inmutable a través de los siglos y las civilizaciones de influencia neoplatónica, conocido en la cultura musulmana como "amor udrí", incluyendo detalles autobiográficos y documentales. Constituye también un diwan, o antología poética de tema amoroso, pues está empedrado de composiciones elegantes y refinadas.

Ibn Hazm era un hombre de profundas convicciones religiosas. Este dirigió parte de sus críticas contra la relajación de costumbres en Al-Ándalus, ya que su obra está penetrada por la firme creencia en Dios -"Alá" en árabe- y en el Islam como única religión verdadera, además de considerar que fue esta una de las causas fundamentales de la decadencia del Califato de Córdoba. Dentro de su más profundo pensamiento religioso establece la preeminencia de estas cuatro ciencias: ciencia del Corán, ciencia de las traducciones, ciencia del Derecho y ciencia de la Teología. Esto indica la preeminencia, como entre tanto otros autores de su época, de la religión sobre el pensamiento especulativo. De hecho, llega a reconocer la imposibilidad de conocer la esencia, atributos y naturaleza de Dios, situando, por tanto, la fe por encima de cualquier otra consideración. Su obra más importante en este ámbito fue el "Libro de las decisiones sobre las religiones", en la que intenta desentrañar dentro de los diferentes movimientos religiosos cuál es la doctrina islámica verdadera, buscando la más literal y menos alegórica.

También escribió numerosas obras filosóficas. Su pensamiento se basaba en Aristóteles y se esfuerza en distinguir lo verdadero de lo falso, lo que lleva a un sexto sentido o "sentido común" por el cual se demuestran las verdades. Dichas verdades están en estrecha relación con la fe por lo que un conocimiento cabal de la filosofía puede relacionar a estas verdades con la teología. De este modo, elabora una teología natural acercándose a los postulados de Santo Tomás y desarrollando el tema de la esencia y la existencia, concluyendo que son idénticas solo en Dios, pero con un significado diferente que la doctrina tomista.

Pero quizás su aporte más significativo esté dado por su testimonio acerca del motivo de la actividad del hombre, cuando indica que todo lo que hace el hombre lo hace para evitar la preocupación, para distraerse. ¿Distraerse de qué? De la muerte.





</doc>
<doc id="1478" url="https://es.wikipedia.org/wiki?curid=1478" title="I milenio">
I milenio

El primer milenio comenzó el 1 de enero del año 1 y terminó el 31 de diciembre del 1000. Fue un periodo de grandes cambios culturales y políticos, especialmente en el continente Euroasiático. Su primera mitad se caracterizó por el auge y caída de grandes imperios tales como el Chino (Asia), Romano (Europa) y Gupta (India). El Cristianismo y más adelante el Islam tuvieron su creación y auge durante este periodo, siendo de las religiones más expandidas del continente para el año 1000.

En Europa, la primera mitad del milenio (que coincide con el fin de la Antigüedad Clásica) vio el máximo apogeo y eventual declive del Imperio Romano al igual que la rápida propagación del Cristianismo. Hacia el Siglo IV se iniciaron las Grandes Migraciones, las cuales también tuvieron efectos en Asia. La Ciudad Eterna y el Imperio Romano Occidental cayeron en el año 476, marcando el inicio de la "Edad Media" de la historia occidental. A pesar de la caída de Roma, la mitad Oriental de su imperio (apodado "Imperio Bizantino" por la historiografía) perduró mil años más. La segunda mitad del milenio se caracterizó por el auge de nuevos reinos cristianos como el Franco (481), Lombardo (568) o el Inglés (927), además de eventos como la Era Vikinga, la formación del sistema feudal y la aparición y fugaz expansión del Islam con las conquistas árabes del Siglo VII.

En Asia, el milenio vio el auge y caída de varias dinastías de China. De estas resalta la Dinastía Han, que cayó en el 220, y la Dinastía Tang, que gobernó desde el 618 al 907. Ambas dinastías fueron edades doradas para dicha civilización, la cual se consolidó como la máxima hegemonía de la región. El Budismo y el Islam fueron introducidos a Asia durante este periodo. En el Siglo VIII inicia la Edad de Oro del islam, la cual trae diversos avances científicos y tecnológicos. En esta misma época, los Pueblos túrquicos inician su migración de Asia Central hacia Europa Oriental.




</doc>
<doc id="1480" url="https://es.wikipedia.org/wiki?curid=1480" title="Isótopo">
Isótopo

La palabra isótopo (del griego: ἴσος "isos" 'igual, mismo'; τόπος "tópos" 'lugar', "en mismo sitio") se usa para indicar que todos los tipos de átomos de un mismo elemento químico (isótopos) se encuentran en el mismo sitio de la tabla periódica. Los átomos que son isótopos entre sí son los que tienen igual número atómico (número de protones en el núcleo), pero diferente número másico (suma del número de neutrones y el de protones en el núcleo). Los distintos isótopos de un elemento difieren, pues, en el número de neutrones.

La mayoría de los elementos químicos tienen más de un isótopo. Solamente 8 elementos (por ejemplo berilio o sodio) poseen un solo isótopo natural. En contraste, el estaño es el elemento con más isótopos estables, 10. 

Otros elementos tienen isótopos naturales, pero inestables, como el uranio, cuyos isótopos pueden transformarse o decaer en otros isótopos más estables, emitiendo en el proceso radiación, por lo que se dice que son radiactivos. 

Los isótopos inestables son útiles para estimar la edad de una gran variedad de muestras naturales, como rocas y materia orgánica. Esto es posible, siempre y cuando, se conozca el ritmo promedio de desintegración de determinado isótopo, en relación a los que ya han decaído. Gracias a este método de datación, se puede estimar la edad de la Tierra.

Todos los isótopos de un mismo elemento tienen el mismo número atómico pero difieren en lo que actualmente se conoce como número másico.

Si la relación entre el número de protones y de neutrones no es la apropiada para obtener la estabilidad nuclear, el isótopo es radiactivo.

Por ejemplo, en la naturaleza el carbono se presenta como una mezcla de tres isótopos con números másicos 12, 13 y 14: C, C y C. Sus abundancias respecto a la cantidad global de carbono son respectivamente 98,89 %, 1,11 % y trazas.



Los isótopos se subdividen en isótopos estables (existen menos de 300) y no estables o isótopos radiactivos (existen alrededor de 1200). El concepto de estabilidad no es exacto, ya que existen isótopos casi estables. Su estabilidad se debe al hecho de que, aunque son radiactivos, tienen un periodo de semidesintegración extremadamente largo comparado con la edad de la Tierra. 

Inicialmente los nombres de los isótopos de cada elemento que se iban descubriendo recibieron nombres propios diferentes al del elemento al que pertenecían. Así cuando se descubrieron tres isótopos del hidrógeno, recibieron los nombres de protio, deuterio y tritio. El núcleo del protio consta de un protón, el del deuterio de un protón y un neutrón, y el del tritio de un protón y dos neutrones.

Cuando se siguieron descubriendo isótopos de casi todos los elementos se vio que serían necesarios cientos o miles de nombres y se cambió el sistema de nomenclatura. Actualmente cada isótopo se representa con el símbolo del elemento al que pertenece, colocando como subíndice a la izquierda su número atómico (número de protones en el núcleo), y como superíndice a la izquierda su número másico (suma del número de protones y de neutrones). Así los isótopos del hidrógeno protio, deuterio y tritio se denotan H, H y H, respectivamente.

Como todos los isótopos de un mismo elemento tienen el mismo número atómico, que es el orden en la tabla periódica, y el mismo símbolo, habitualmente se omite el número atómico. Así para los isótopos del hidrógeno escribiremos H, H y H. Esto se hace porque todos los isótopos de un elemento particular se comportan de la misma manera en cualquier reacción química. Por ejemplo, un átomo del escaso isótopo de oxígeno que tiene número másico 18, se combinará exactamente igual con dos átomos de hidrógeno para formar agua que si se tratara del abundante átomo de oxígeno de número másico 16. Sin embargo cuando se están describiendo reacciones nucleares es útil tener el número atómico como referencia. 

En el caso de textos no científicos, como textos periodísticos, esta notación con subíndices y superíndices es incómoda, por lo que también se usa una notación consistente en el nombre del elemento unido por un guion al número másico del isótopo de que se trate. De esta forma los isótopos del hidrógeno H, H y H, también se pueden nombrar como hidrógeno-1, hidrógeno-2 e hidrógeno-3 respectivamente.

Estas son las reglas de nomenclatura científicamente aceptadas, correspondientes a la "Nomenclatura de Química Inorgánica. Recomendaciones de 2005 (Libro Rojo de la IUPAC)", tal y como se pueden encontrar en su sección IR-3.3.

Hay que recordar que los nombres de los elementos químicos son nombres comunes y como tales deben escribirse sin mayúscula inicial, salvo que otra regla ortográfica lo imponga.

Los radioisótopos son isótopos radiactivos ya que tienen un núcleo atómico inestable y emiten energía y partículas cuando se transforman en un isótopo diferente más estable. La desintegración puede detectarse con un contador Geiger o con una película fotográfica. 

La principal razón de la inestabilidad está en el exceso de protones o neutrones. La fuerza nuclear fuerte, que une protones y neutrones entre sí, requiere que la cantidad de neutrones y protones esté cerca de cierta relación. Cuando el número de neutrones es superior al que requiere esta relación el átomo puede presentar decaimiento beta negativo. Cuando el átomo tiene un exceso de protones (defecto de neutrones) suele presentar decaimiento beta positivo. 

Esto sucede porque la fuerza nuclear fuerte residual depende de la proporción de neutrones y protones. Si la relación está muy sesgada hacia uno de los extremos la fuerza nuclear débil responsable del decaimiento beta puede producir esporádicamente la pérdida de algún nucleón. Para números atómicos elevados ("Z" > 80) también se vuelve frecuente la desintegración alfa (que casi es mucho más frecuente cuando además hay exceso de protones).

Cada radioisótopo tiene un periodo de semidesintegración o semivida característico. La energía puede ser liberada principalmente en forma de radiación alfa (partículas constituidas por núcleos de helio), beta (partículas formadas por electrones o positrones) o gamma (energía en forma de radiación electromagnética).

Varios isótopos radiactivos inestables y artificiales tienen usos en técnicas de radioterapia en medicina. Por ejemplo, un isótopo del tecnecio (Tc, la "" indica que es un isómero nuclear metaestable) puede usarse para identificar vasos sanguíneos bloqueados. 

Varios isótopos radiactivos naturales se usan en datación radiométrica para determinar cronologías, por ejemplo, arqueológicas.

Las siguientes son varias de las aplicaciones de diferentes isótopos en diversas áreas, como la medicina:






</doc>
<doc id="1481" url="https://es.wikipedia.org/wiki?curid=1481" title="Iodopsina">
Iodopsina

La iodopsina o yodopsina es una cromoproteína, un pigmento situado en los segmentos exteriores de los conos del ojo humano, siendo responsable de la percepción del color. Esta tiene una mayor concentración en la fóvea. Viene asociada a la vitamina A. Al recibir la luz produce una diferencia de potencial que da lugar a una corriente eléctrica por medio de la cual la información visual se transmite por las neuronas hasta el cerebro.


</doc>
<doc id="1482" url="https://es.wikipedia.org/wiki?curid=1482" title="Inercia">
Inercia

En física, la inercia (del latín "inertĭa") es la propiedad que tienen los cuerpos de permanecer en su estado de reposo relativo o movimiento relativo. Dicho de forma general, es la resistencia que opone la materia al modificar su estado de movimiento, incluyendo cambios en la velocidad o en la dirección del movimiento. Como consecuencia, un cuerpo conserva su estado de reposo relativo o movimiento rectilíneo uniforme relativo si no hay una fuerza que, actuando sobre él, logre cambiar su estado de movimiento. 

En la naturaleza no existe el reposo, siempre toda la materia está en movimiento, por eso cuando se habla de reposo o Movimiento Rectilíneo Uniforme (MRU) se debe añadir la palabra "relativo" (relativo a un sistema de referencia). El cuerpo está en reposo o en MRU solo con respecto de ese sistema de referencia. Cuando un cuerpo está en reposo relativo sobre la superficie de la Tierra, en realidad está participando de los distintos movimientos que realiza el planeta y está sometido a diferentes fuerzas como las gravitatorias de la Tierra, el Sol, La Luna y otros cuerpos, así como la resistencia mecánica que impide que se hunda en la tierra, o se deslice. Se puede decir que el cuerpo se encuentra en equilibrio sobre la superficie de la Tierra y por lo tanto en reposo relativo.

Podríamos decir que es la resistencia que opone un sistema de partículas a modificar su estado dinámico. 

En física se dice que un sistema tiene más inercia cuando resulta más difícil lograr un cambio en el estado físico del mismo. Los dos usos más frecuentes en física son la inercia mecánica y la inercia térmica.

La primera de ellas aparece en mecánica y es una medida de dificultad para cambiar el estado de movimiento o reposo de un cuerpo. La inercia mecánica depende de la cantidad de masa y del tensor de inercia.

La inercia térmica mide la dificultad con la que un cuerpo cambia su temperatura al estar en contacto con otros cuerpos o ser calentado. La inercia térmica depende de la capacidad calorífica.

Las llamadas fuerzas de inercia son fuerzas ficticias o aparentes que un observador percibe en un sistema de referencia no-inercial.

Hay investigadores que consideran la inercia mecánica como manifestación de la masa, y están interesados en las ideas de la física de partículas sobre el bosón de Higgs. De acuerdo al modelo estándar de física de partículas todas las partículas elementales carecen prácticamente de masa. Sus masas (y por lo tanto su inercia) provienen del Mecanismo de Higgs vía intercambio con un campo omnipresente de Higgs. Esto lleva a deducir la existencia de una partícula elemental, el bosón de Higgs.
Otros están inclinados a ver la inercia como una característica conectada con la masa, y trabajan a lo largo de otros caminos. El número de los investigadores que entregan nuevas ideas aquí es reducido. Muchas de las ideas presentadas al respecto todavía son miradas como protociencia, pero ilustra cómo está avanzando la formación de teorías en esta área.
Una publicación reciente del físico sueco-americano C. Johan Masreliez propone que el fenómeno de la inercia puede ser explicado, si los coeficientes métricos en la línea elemento de Minkowskian son cambiados como consecuencia de la aceleración. Cierto factor de posicionamiento modela la inercia como efecto de tipo gravitacional.
En un artículo sucesivo para "Physica Scripta", explica cómo la relatividad especial puede ser compatible con un cosmos con un marco cosmológico fijo y único de la referencia. La transformación de Lorentz modela la formación de la estructura ("morphing") de las partículas móviles, que pudieran preservar sus características cambiando sus geometrías del espacio-tiempo local. Con esto la geometría se convierte en dinámica y una parte integral de movimiento. Masreliez dice que es esta geometría la que cambia para ser la fuente de la inercia; ergo, para generar la fuerza de inercia.Si fuera aceptada, la inercia podría conectar la relatividad especial con la general. Sin embargo, aunque los marcos de inercia siguen siendo físicamente equivalentes y las leyes de la Física se aplican igualmente, no modelan el mismo espacio-tiempo. Estas nuevas ideas, SEC han sido comprobadas hasta ahora no solo por el proponente sino también por algunos miembros de la comunidad científica.La teoría de la SEC es controvertida, ya que refuta la hipótesis del Big Bang
Otro acercamiento ha sido sugerido por Emil Marinchev (2002).



</doc>
<doc id="1489" url="https://es.wikipedia.org/wiki?curid=1489" title="Instrumento musical">
Instrumento musical

Un instrumento musical es un objeto compuesto por la combinación de uno o más sistemas resonantes y medios para su vibración, construido con el fin de producir sonido en uno o más tonos que puedan ser combinados por un intérprete para producir música. Al final, cualquier cosa que produzca sonido armónico puede servir de instrumento musical, pero la expresión se reserva, generalmente, a aquellos objetos que tienen ese propósito específico.

El cuerpo humano, ha ido generando sonidos por medio de las vías aéreas superiores vocales y percusivos, fue, probablemente, el primer instrumento. Sachs y otros han especulado sobre la capacidad de "Homo habilis" de agregar sonidos de modo idiofónico a impulsos de expresión emocional motriz como la danza, empleando diversos medios como piedras, troncos huecos, brazaletes, conchas y dientes de animales.

Excavaciones arqueológicas y demás han encontrado aerófonos de filo (flautas) de hueso de sesenta mil años de antigüedad. Resulta evidente que algunos aerófonos producen sonido por la acción natural del viento (sobre cañas de bambú), ofreciendo el fenómeno sonoro al observador casual.
Asimismo, otros aerófonos como los cuernos de animales, por el volumen de los sonidos producidos, pudieron ser y fueron empleados como instrumentos de señales sonoras para la caza.
La gran cantidad de instrumentos musicales de viento, cuerda y percusión encontrados en excavaciones arqueológicas de todas las grandes civilizaciones antiguas y la extensa documentación pictórica y literaria coinciden con la gran importancia que la música ha tenido siempre para el ser humano.

En tiempos del Egipto ptolemaico, el ingeniero Ctesibio de Alejandría desarrolló el "órgano hidráulico" o hydraulis, destinado a producir melodías con gran volumen sonoro, que podía ser empleado en funciones circenses al aire libre

Existen muchas divisiones alternativas y subdivisiones de instrumentos. Generalmente, al estudiar los instrumentos musicales es frecuente encontrarse con la clásica división de los instrumentos en cuatro familias: viento, cuerda, percusión y los instrumentos eléctricos (creados por el ser humano hace aproximadamente 50 años). Sin embargo, debido a que esta clasificación está orientada a los instrumentos de la orquesta sinfónica, adolece de ciertas restricciones y defectos. Debido a ello, algunos musicólogos sencillamente amplían esta clasificación añadiendo hasta tres categorías adicionales: voz, teclados y electrónicos. Sin embargo, en 1914 los músicos Curt Sachs y Erich Hornbostel idearon un nuevo método de clasificación que atendiendo a las propiedades físicas de cada instrumento, pretendía ser capaz de englobar a todos los existentes. Una tercera clasificación, muy seguida en el este de Asia, clasifica los instrumentos atendiendo a sus materiales de construcción: metal, madera, barro, cuero, entre otros.

La clasificación más usada de manera convencional es la de viento, cuerda y percusión.

Erich von Hornbostel y Curt Sachs publicaron en 1914 una clasificación de los instrumentos musicales en su trabajo "Zeitschrift für Ethnologie" que es ampliamente seguida en la actualidad.

Establecieron cuatro clases o categorías principales de instrumentos musicales (a la que añadieron una quinta posteriormente), que a su vez se dividen en grupos y subgrupos, según el modo de generación del sonido:

Son aquellos instrumentos en los que el sonido procede de un cuerpo sólido y es generado por vibración del instrumento mismo mediante percusión, frotación o pulsación, como en el caso de las claves, xilófono, campana.

Los membranófonos son aquellos en los cuales el sonido es generado por la vibración de una membrana por percusión o frotación, como es el caso del timbal, tambor, conga.
Son los llamados instrumentos de viento, donde el sonido es generado por la vibración del aire, a causa del roce con una lengüeta, labios o cuerdas vocales.

En función a cómo se produce el sonido podemos clasificarlo en dos tipos:

En viento madera el instrumento produce el sonido mientras que en viento mental, la persona que lo toca .

En viento madera podemos clasificar los instrumentos según su embocadura:

-Bisel:destacan instrumentos como la flauta dulce y la flauta travesera.

-Lengüeta simple: como por ejemplo el clarinete y el saxofón 

-Lengüeta doble: entre los que se encuentran el oboe y el fagot


Los cordófonos o también conocidos como instrumentos de cuerda, son aquellos que producen el sonido mediante la vibración de cuerdas tensadas. Estos instrumentos tienen además una caja de resonancia para amplificar el sonido. En base a la forma en la que obtenemos el sonido podemos dividirlo en tres tipos diferentes : frotada, pulsada y percutida. 

Durante el siglo XX se desarrolló un nuevo tipo de instrumento, los denominados electrófonos. En estos instrumentos, el sonido es generado por medios electrónicos, como en el sintetizador o el theremín. No deben ser confundidos con los "instrumentos electroacústicos", donde el sonido es generado de modo no electrónico pero modificado electrónicamente, como en el caso de la guitarra eléctrica y el bajo eléctrico. Sachs, por esta razón, más tarde añadió una quinta categoría a su clasificación, los electrófonos.



</doc>
<doc id="1490" url="https://es.wikipedia.org/wiki?curid=1490" title="Imprenta">
Imprenta

La imprenta es un método mecánico destinado a reproducir textos e imágenes sobre papel, tela u otros materiales. En su forma clásica, consiste en aplicar una tinta, generalmente oleosa, sobre unas piezas metálicas (tipos) para transferirla al papel por presión. Aunque comenzó como un método artesanal, su implantación a mediados del siglo XV trajo consigo una revolución cultural.

Más modernamente, la evolución de diversas tecnologías ha dado lugar a diferentes métodos de impresión y reproducción, como son la flexografía, la serigrafía, el huecograbado, el alto grabado, la fotografía electrolítica, la fotolitografía, la litografía, la impresión "offset", la xerografía y los métodos digitales.

Ya los romanos tuvieron sellos que imprimían hojas de inscripciones sobre objetos de arcilla alrededor del año 440 a. C. y el 430 a. C. Entre 1041 y 1048, Bi Sheng inventó en China —donde ya existía un tipo de papel de arroz— el primer sistema de imprenta de tipos móviles, a base de complejas piezas de porcelana en las que se tallaban los caracteres chinos; esto constituía un complejo procedimiento por la inmensa cantidad de caracteres que hacían falta para la escritura china. En 1234, artesanos durante la dinastía Koryo (en la actual Corea), conocedores de los avances chinos con los tipos móviles, crearon un juego de tipos móviles de metal que se anticipó a la imprenta moderna, pero lo usaron raramente. Sin embargo, la imprenta moderna no se creó hasta el año 1450 aproximadamente, de la mano de Johannes Gutenberg.

En la antigua Europa, muchas personas y poblaciones pretendieron ser parte de este arte; aunque las opiniones apuntan a que fue el alemán Johannes Gutenberg, por las ideas que tenía y la iniciativa de unirse a un equipo de impresores, quien inventó la tipografía. Existe documentación subsecuente que le atribuye la invención aunque, curiosamente, no consta el nombre de Gutenberg en ningún impreso conocido.

Ante la controvertida historia, aparecieron, disputando el honor al llamado "Padre de la Imprenta", los nombres del alemán Mentelin, impresor de Estrasburgo (1410-1478); el del italiano Panfilo Castaldi, médico y después tipógrafo en 1470, el italiano Aldo Manucio, y Lorenzo de Coster, de Haarlem, (Países Bajos) (1370-1430). Cada uno tiene un monumento en sus respectivas localidades; sin embargo, perdieron el pleito definitivamente los partidarios de Mentelin y Castaldi.

Una edición que data del año 1502 en Maguncia, Alemania, impresa por Peter Schöffer, sucesor de la imprenta que inicialmente fue creada por Gutenberg, dice:

Hasta 1450 y aún en años posteriores, los libros se difundían en copias manuscritas por amanuenses, muchos de los cuales eran monjes y frailes dedicados exclusivamente al rezo y a la réplica de ejemplares por encargo del propio clero o de reyes y nobles. A pesar de lo que se cree, no todos los monjes copistas sabían leer y escribir. Realizaban la función de copistas, imitadores de signos que en muchas ocasiones no entendían, lo cual era fundamental para copiar libros prohibidos que hablasen de medicina interna o de sexo. Las ilustraciones y las letras mayúsculas eran producto decorativo y artístico del propio copista, que decoraba cada ejemplar que realizaba según su gusto o visión. Cada uno de sus trabajos podía durar hasta diez años.

En la Alta Edad Media se utilizaba la xilografía en Europa para publicar panfletos publicitarios o políticos, etiquetas, y trabajos de pocas hojas. Para realizarlas se trabajaba el texto en hueco sobre una tablilla de madera, incluyendo los dibujos —un duro trabajo de artesanía—. Una vez confeccionada, se acoplaba a una mesa de trabajo, también de madera, y se impregnaban de tinta negra, azul o roja (solo existían esos colores). Después se aplicaba el papel y con un rodillo se fijaba la tinta. El desgaste de la madera era considerable por lo que no se podían hacer muchas copias con el mismo molde. Este tipo de impresión recibe el nombre de xilografía.

Cada impresor fabricaba su propio papel, estampando una marca de agua a modo de firma de impresor. Por estas marcas de agua es por lo que se conocen sus trabajos.

En este entorno, Gutenberg apostó a que era capaz de hacer a la vez varias copias de la Biblia en menos de la mitad del tiempo que tardaba en copiar una el más rápido de todos los monjes copistas del mundo cristiano y que éstas no se diferenciarían en absoluto de las manuscritas por ellos.

Pidió dinero a Johann Fust, y comenzó su reto sin ser consciente de lo que su invento iba a representar para el futuro de toda la humanidad. 

En vez de usar las habituales tablillas de madera, que se desgastaban con el uso, confeccionó moldes en madera de cada una de las letras del alfabeto y posteriormente rellenó los moldes con plomo, creando los primeros tipos móviles. Tuvo que hacer varios modelos de las mismas letras para que coincidiesen todas entre sí: en total, más de 150 tipos, que imitaban la escritura de un manuscrito. Había que unir una a una las letras que se sujetaban en un ingenioso soporte, sistema mucho más rápido que el grabado en madera y considerablemente más resistente al uso. 

Como plancha de impresión, amoldó una vieja prensa para uva a la que sujetó el soporte con los tipos móviles con un hueco para las letras mayúsculas y los dibujos. Estos, posteriormente, serían añadidos mediante el viejo sistema xilográfico y terminados de decorar de forma manual.

Lo que Gutenberg no calculó bien fue el tiempo que le llevaría poner en marcha su nuevo invento, por lo que antes de finalizar el trabajo se quedó sin dinero. Volvió a solicitar un nuevo crédito a Johann Fust y, ante la negativa del prestamista, le ofreció formar una sociedad. Johann Fust aceptó la propuesta y delegó la vigilancia de los trabajos de Gutenberg a su sobrino, Peter Schöffer, quien se puso a trabajar codo a codo con él, al tiempo que vigilaba la inversión de su tío.

Tras dos años de trabajo, Gutenberg volvió a quedarse sin dinero. Estaba cerca de acabar las 150 Biblias que se había propuesto, pero Johann Fust no quiso ampliarle el crédito y dio por vencidos los anteriores, quedándose con el negocio y poniendo al frente a su sobrino, ducho ya en las artes de la nueva impresión como socio-aprendiz de Gutenberg.

Gutenberg salió de su imprenta arruinado y se cuenta que fue acogido por el obispo de la ciudad, el único que reconoció su trabajo hasta su muerte, pocos años después.

Peter Schöffer terminó el cometido que inició su maestro y las Biblias fueron vendidas rápidamente a altos cargos del clero, incluida la Santa Sede, a muy buen precio. Pronto empezaron a llover encargos de nuevos trabajos. La rapidez de la ejecución fue sin duda el detonante de su expansión, puesto que antes la entrega de un solo libro podía posponerse durante años.

Actualmente, se conservan muy pocas Biblias de Gutenberg —o de 42 líneas— y, menos aún, completas. En España se conservan dos, una completa en Burgos y otra con solo el Nuevo Testamento en Sevilla.

En 1449, Johannes Gutenberg ya había impreso el primer libro, el llamado "Misal de Constanza", en la imprenta de Maguncia, Alemania. La Biblia de Gutenberg no fue únicamente el segundo libro impreso, sino que, además, fue el más perfecto. Su imagen no difiere en absoluto de un manuscrito.

En la Península, la primera imprenta fue instalada en Segovia en 1472, y su primer libro es el "Sinodal de Aguilafuente".. En Nueva España, la primera imprenta fue establecida en México en 1539. En Centroamérica, el primer libro es "Tratado sobre el cultivo del añil", impreso, precisamente, en tinta azul. En el Virreinato del Perú, el primer libro es "La Doctrina Cristiana" (Lima, 1584).

Gutenberg, en su labor de impresor, creó su famoso incunable "Catholicon", de Juan Balbu de Janna. Pocos años después, imprimió hojas por ambas caras y calendarios para el año 1448. Además, junto con su amigo Fust editaron algunos libritos y bulas de indulgencia y en particular, aquel monumento de la imprenta primitiva, la Biblia de las 42 líneas, en dos tomos de doble folio, de 324 y 319 páginas respectivamente, con espacios en blanco para después pintar a mano las letras capitulares, las alegorías y viñetas que ilustrarían coloridamente cada una de las páginas de la Biblia.

Según las declaraciones de diversos testigos resulta que, mientras en apariencia fabricaba espejos, Gutenberg se servía de todos los instrumentos, materiales y herramientas necesarios para la secreta imprenta: plomo, prensas, crisoles, etc., con el supuesto pretexto de fabricar con planchas xilográficas de madera unos pequeños devocionarios latinos de título "Speculum" que eran fabricados en Holanda y Alemania con los títulos de "Speculum, Speculum humanae salvationis, Speculum vitae humanae, Speculum salutis", etc. Pero algunos declararon que con el pretexto de imprimir espejos, "Gutenberg, durante cerca de tres años, había ganado unos 100 florines en las cosas de la imprenta."

Hungría sería el primer reino que recibiría el renacimiento en Europa después de Italia, bajo el reinado de Matías Corvino en el siglo XVI se inauguraría la primera imprenta húngara en 1472. Andrés Hess sería llamado a Hungría desde Italia, quien usando el sistema de Gutenberg organizaría la imprenta húngara y haría publicar dos obras: "Cronica Hungarorum" ("La crónica de los húngaros"), y el "Magnus Basilius: De legendis poëtis - Xenophon: Apologia Socratis" (dos obras griegas clásicas en un solo tomo). Durante el periodo de 1493 al 1946 funcionó la primera imprenta en Montenegro, conocida como Imprenta de Crnojević, considerada la primera imprenta estatal del mundo.

Años más tarde y hacia 1500 la situación social cambiaba en Alemania y una guerra civil hizo que en Maguncia los impresores huyeran para evitar caer en la guerra. A los impresores les costó mucho guardar el secreto y los talleres de imprentas se esparcieron por toda Europa.

La imprenta se conoce en América una vez concluida la conquista española. En 1539 el impresor Juan Cromberger monta una filial de su imprenta de Sevilla en Ciudad de México en un local de Juan de Zumárraga. Esta filial estará a cargo de Juan Pablos, que comienza su labor de impresión ese mismo año. A la Nueva España llegaron varios impresores europeos que tuvieron una papel fundamental dentro del mundo del libro. El primer impresor ya mencionado, fue Juan Pablos, estuvo activo de 1548-1560, posteriormente llega Antonio de Espinosa quien labora de 1559-1576, el tercero fue Pedro Ocharte de 1563-1592. Pedro Balli es el cuarto impresor novohispano, estuvo activo de 1574 a 1600. Llegó a México por el año de 1569, en calidad de librero. "Se despacho a la provincia de la Nueva España por soltero y por real cédula de su magestad, el 15 de julio de 1569". 
El cronista Gil González Dávila ha querido decir que la primera obra impresa fue "Escala espiritual para llegar al Cielo" por San Juan Clímaco en 1532, en su versión traducida del latín por un fraile español, y aunque concuerda en el título del libro con el historiador Dávila Padilla, la fecha de 1532 es equivocada ya que en ese año no había medios para imprimir nada por aquellas tierras. El primer libro impreso sería "Breve y más compendiosa Doctrina Christiana", escrito por Juan de Zumárraga, en la imprenta de Juan Cromberger gestionada por Juan Pablos en 1539.

Así inició la más grande repercusión de la imprenta en la cultura de la humanidad. La palabra escrita ahora podía llegar a cualquier rincón, la gente podía tener acceso a más libros y comenzar a preocuparse por enseñar a leer a sus hijos. Las ideas cruzaban las fronteras y el arte de la tipografía fue el medio de difundirlas.

Libros, incunables, ediciones ilustradas con grabados de madera: la mejora de las técnicas y materiales de imprenta llevaron durante cuatro siglos las palabras por todo el mundo. El arte tipográfico evolucionó y llegó a crear obras maestras en la formación y estructuras de libros y ediciones especiales impresas. Actualmente las técnicas de impresión en calidad y volumen han mejorado de forma impresionante, algunas por medio de computadora, olvidándose del arte tipográfico que muchos tipógrafos del mundo se resisten a cambiar.

Pocos inventos han tenido la influencia en el ser humano como la creación de la imprenta, ese antiguo arte que, si va unido en una obra la labor del tipógrafo y la obra escrita de un buen autor, proporciona una obra de arte completa, lista para conmover con belleza literaria y estética tipográfica al lector, el fin primero y último de la imprenta.
A finales del siglo XIX, se perfeccionó el proceso, gracias a la invención en 1885 de la linotipia, por Ottmar Mergenthaler.

Los nuevos medios de comunicación aparecieron en un momento de un cambio acelerado y de comunicaciones más veloces y fueron la respuesta a la mayor demanda de información y entretenimiento. Los nuevos sistemas y estructuras nunca borran por completo los anteriores sino que se superponen. Así, las nuevas técnicas de almacenamiento y recuperación de información han necesitado de los medios de impresión en este campo para reagrupar y encontrar nuevas colocaciones, a menudo de carácter más especializado.

La revolución audiovisual se ha presenciado en medio de un diluvio de material de promoción impreso. Todo esto ha traído consigo cambios que afectan al libro; por ejemplo, la composición convencional es ahora tan cara que solamente se justifica en tiradas muy grandes, pero hay una gran variedad de métodos de impresión más económicos, como la fotocopia y la duplicación electrostática.

Nuevos horizontes se desplegaron con la llegada de la impresión digital. El ahorro de tiempo y los costos ofrecidos por las nuevas técnicas digitales valen también para la industria editorial que se beneficia de la rapidez y amplias posibilidades que la impresión digital ofrece:

Con la aparición de la tinta electrónica y los conocidos libros electrónicos o "eBooks" se ha logrado que ya no sea necesario imprimir un libro para poder distribuirlo y por ende leerlo. Diversos dispositivos permiten la compra y adquisición de libros, publicaciones y revistas desde el mismo aparato, lo que reduce de forma notable el costo de producción de la propiedad intelectual además de aportar una solución ecológica. También hay que resaltar el papel de Internet como gran medio para distribuir información a través de páginas web y correo electrónico, sustituyendo muchas veces al uso tradicional del papel en ámbitos como la prensa escrita o el correo postal. Por estas razones el uso de la imprenta ha disminuido, e incluso campañas ecológicas invitan a no generar desechos imprimiendo material que puede ser visto o leído en dispositivos digitales, generando una mayor conciencia sobre lo que será impreso.




</doc>
<doc id="1491" url="https://es.wikipedia.org/wiki?curid=1491" title="Iridaceae">
Iridaceae

Las iridáceas (Iridaceae) son una familia de plantas perennes, herbáceas y bulbosas pertenecientes al orden Asparagales dentro de las monocotiledóneas. La familia, cuyo nombre deriva del género "Iris", cuenta con más de 2000 especies que se distribuyen por casi todo el mundo, siendo una de las familias más importantes en horticultura. Géneros tales como "Crocus" e "Iris" son componentes preponderantes de las floras de varias regiones de Eurasia e "Iris" se halla muy bien representado en Norte América. "Gladiolus" y "Moraea" son géneros muy amplios y componentes principales de la flora subsahariana y sudafricana. "Sisyrinchium", con más de 140 especies, es el género de iridáceas más diversificado en América, donde también se encuentran varios otros miembros de la familia, muchos de los cuales son importantes en la floricultura tropical.

Actualmente se reconocen 66 géneros que se distribuyen entre siete subfamilias y ocupan una gran variedad de hábitats. La mayoría de las especies se adapta a climas estacionales que tienen un período de pronunciada sequía o frío desfavorables para el crecimiento vegetal y durante el cual las plantas permanecen latentes. Por esa razón, la mayoría de las iridáceas son de hoja caduca ya que sus partes aéreas (hojas y tallos) se secan cuando el bulbo o el cormo entra en letargo o dormancia. Las plantas así sobreviven períodos que no son favorables para el crecimiento refugiándose bajo el suelo. Las especies de iridáceas de hoja perenne se limitan a los bosques subtropicales y a las sabanas, a las praderas templadas y a los fynbos húmedos.

Las iridáceas son plantas generalmente herbáceas y perennes, raramente anuales o arbustivas leñosas con crecimiento secundario anómalo. El follaje puede mantenerse todo el año o puede secarse en alguna estación para luego rebrotar, por lo que las iridáceas pueden ser perennifolias o caducifolias. Excepcionalmente, como es el caso de "Geosiris", no presentan clorofila ya que los miembros de este género son plantas saprofíticas. Los tallos son rizomas, cormos o bulbos, o un cáudice leñoso. Presentan grandes cristales prismáticos de oxalato de calcio en los haces vasculares de las vainas como así también taninos o varios tipos de terpenoides. Los pelos que cubren varios órganos aéreos son simples.

Las hojas son simples, de margen entero, delgadas y en general lineares o ensiformes, paralelinervadas, alternadas y dísticas, muchas veces equitantes, y con lámina unifacial (con el plano de la hoja paralelo al tallo) o terete (circulares en el corte transversal), a lo largo del tallo a basales, de base envainadora, sin estípulas. En "Geosiris" las hojas son solo escamas y no presentan clorofila.

Las flores de la mayor parte de las iridáceas son grandes y llamativas, perfectas, esto es, son hermafroditas con órganos femeninos y masculinos funcionales. Además, son pentacícilicas ya que poseen cinco verticilos o ciclos de piezas florales: dos ciclos constituyen el perigonio, un ciclo forma el androceo y el último verticilo conforma el gineceo. Con respecto a su simetría, las flores de las iridáceas pueden ser cigomorfas a actinomorfas ya que presentan desde uno a varios planos de simetría. Pueden estar sostenidas a través de un pedicelo, o bien, ser sésiles. En general están encerradas por una a dos brácteas. El perigonio está compuesto por tres piezas externas de sépalos petaloideos y tres piezas internas de pétalos, los que colectivamente se denominan tépalos ya que no difieren en cuanto a su textura o color. El perigonio, no obstante, puede ser homoclamídeo —"Sisyrinchium"— o heteroclamídeo —"Moraea, Iris, Trimezia"— según si la forma de los tépalos externos difiere de la de los tépalos internos. Los tépalos internos pueden ser más pequeños y más erectos que los externos, como en el caso de muchas especies de "Iris" y algunas de "Moraea", estar muy reducidos y curvados hacia abajo, como en el caso de los miembros del subgénero "Scorpiris"; o directamente pueden faltar, como ocurre en "Patersonia". Los tépalos usualmente son grandes, imbricados, vistosos, a veces punteados, y pueden ser libres o estar unidos en sus bases, hasta formando un tubo prominente en el caso de los miembros de Ixioideae el que puede tener una longitud de hasta 20 cm como en el caso de "Iris unguicularis". Los tépalos externos en el caso de las tribus Irideae y Tigrideae pueden diferenciarse en dos porciones y la porción proximal se denomina «garra». Las garras, especialmente en los tépalos internos, son frecuentemente pilosas y están cubiertos de manchas o marcas y, a menudo, están cubiertos de glándulas. En los tépalos externos de las especies del subgénero "Iris" se hallan las guías de néctar, las que se encuentran cubiertas de pelos largos y multicelulares que forman lo que se conoce como «barba» y que explica su denominación popular de «iris barbados». El androceo está formado por tres estambres, excepcionalmente solo dos como en el caso de "Diplarrhena", los que se hallan insertos en la base de los tépalos externos. Los estambres pueden disponerse separados entre sí o estar unidos por sus filamentos formando un tubo, lo que conforma un androceo monadelfo. La posición de los estambres es variable, ya que pueden disponerse radial o unilateralmente. Las anteras a veces se hallan unidas a las ramas del estilo, son de dehiscencia longitudinal y extrorsa o poricida. El polen usualmente es monosulcado. El gineceo está constituido por tres carpelos unidos entre sí y es de ovario ínfero, a excepción de "Isophysis" que posee ovario súpero y por esa razón, al menos parcialmente, se halla segregado en su propia subfamilia, "Isophysidae". El ovario presenta tres cavidades o lóculos, cada uno de los cuales lleva desde uno a varios óvulos con placentación axilar y, más raramente, parietal. Los óvulos suelen ser anátropos o campilótropos y bitégmicos. El estilo es filiforme, terminal, usualmente con tres ramas o con tres lóbulos, las ramas a veces se hallan expandidas y son petaloideas, como ocurre en muchas especies de Iridoideae. El estigma es trífido, a veces bífido, terminal o bien, dispuesto en la cara abaxial de las ramas del estilo. Los nectarios se hallan en los septos del ovario, en la base de los tépalos externos, en los tépalos internos ("Tigridia"), en la base de los estambres ("Iris") o bien, pueden estar ausentes, como en el caso del género "Sisyrinchium".

Las flores son solitarias o bien se hallan en varios tipos de inflorescencias terminales por lo común sostenidas por una bráctea. Los tipos de inflorescencia pueden ser umbelas, ripidios, muchas veces altamente modificadas, o espigas. Los ripidios están cubiertos por dos brácteas (espatas) opuestas, usualmente grandes, foliosas o secas. Cada flor en las espigas presenta dos brácteas opuestas. En "Geosiris" la inflorescencia es subterránea.

El fruto es una cápsula loculicida normalmente dehiscente, puede ser dura o cartilaginosa y en ocasiones leñosa. Las semillas son entre globulares a angulosas (en forma de prisma) o incluso discoidales y pueden presentar alas, arilo o una cubierta seminal, normalmente con estructura celular y de tono amarronado. El endosperma es duro y contiene hemicelulosa, aceite y proteína. En su interior se ubica un pequeño embrión.

Ampliamente distribuidas, siendo especialmente diversas en el sur de África. Las especies de esta familia ocupan hábitats muy diversos, tanto en climas tropicales, subtropicales como templados. La mayoría de las especies de "Iridaceae" se hallan adaptadas a climas estacionales que presentan períodos excesivamente secos o fríos, desfavorables para el crecimiento vegetal, y en los cuales estas plantas entran en reposo. De hecho, la mayoría de las especies son caducifolias. Las especies perennifolias se hallan restringidas en su distribución a los bosques subtropicales, a las sabanas y a las estepas templadas. En las especies deciduas, la parte aérea (tallos y hojas) se seca durante el período desfavorable y las plantas entran en reposo gracias a que poseen órganos subterráneos de supervivencia y de reserva de nutrientes (rizomas, bulbos y cormos). Esta adaptación es particularmente ventajosa para todas las iridáceas que habitan comunidades que soportan incendios periódicos durante la estación seca. En esos períodos, las plantas se hallan en reposo y de ese modo sobreviven al calor del fuego. Los incendios limpian de vegetación la superficie, eliminando la competencia y, además, aportan nutrientes al suelo a través de las cenizas. Cuando las primeras lluvias caen, los bulbos, cormo (tallo subterráneo)s y rizomas comienzan a brotar rápidamente, iniciando un nuevo período de crecimiento y desarrollo sostenido por las reservas acumuladas en sus tejidos durante la estación previa.

Las iridáceas presentan una gran variabilidad en su ecología reproductiva y una gran diversidad de tipos y estructuras florales congruentes con la adaptación a la polinización por animales (zoofilia). La mayoría de las especies son entomófilas y son polinizadas por diversos órdenes de insectos (especialmente escarabajos, abejas y moscas), mientras que otras son polinizadas por pájaros (ornitófilas). Las recompensas florales son néctar o polen.

Las semillas usualmente son dispersadas por viento o agua, pero también ocurre dispersión biótica.

La mayoría de las especies que componen este género florecen en verano, cuando las hojas ya están secas. Las flores, actinomorfas a cigomorfas, son usualmente de color rosado o rojo, si bien también hay especies con flores de color blanco, amarillo, marrón o crema. El género presenta dos números cromosómicos básicos, x= 15 y 16.

La biología de la polinización de "Tritoniopsis" es bastante sorprendente. Hay especies que presentan flores con los tépalos unidos en sus bases formando un tubo corto y de color rosado que son polinizadas por abejas que buscan su néctar. A partir de estos caracteres florales, considerados ancestrales, se han derivado varios modos más especializados de polinización durante la evolución del género. Así, cuatro especies con tubos florales alargados y con perianto bilabiado rosado o rojo son polinizadas por pájaros del género "Nectarinia" (Passeriformes) o bien por la mariposa "Aeropetes tulbaghia". Otras dos especies con flores rosadas con márgenes rojos son polinizadas por moscas del género "Prosoeca" (Nemestrinidae). "Tritoniopsis parviflora", finalmente, se considera única entre las iridáceas de Sudáfrica, ya que además de presentar néctar azucarado, produce aceite en las flores como recompensa para la abeja "Redivia gigas" (Melittidae).

Las iridáceas son una de las familias más grandes y mejor estudiadas dentro del orden Asparagales, se distingue de las otras familias de Aspargales debido a la estructura única de su inflorescencia (un ripidio) y su combinación de ovario ínfero con tres estambres. En las iridáceas también son comunes las hojas unifaciales, mientras que las hojas bifaciales son la norma en las restantes asparagales.

La divergencia entre las doryantáceas y las iridáceas ocurrió hace aproximadamente 82 millones de años, durante el período Campaniense del Cretácico. "Isophysis" es el único miembro viviente de las iridáceas que es hermano de todos los demás integrantes de la familia, de los cuales divergió hace unos 66 millones de años, en el período Maastrichtiense.
La familia se originó en el Hemisferio Sur, cuando Australia estaba unida a la Antártida formando un solo supercontinente que se hallaba a latitudes mayores, antes de que ocurriera una glaciación significativa. Los dos clados más grandes de la familia divergieron hace 61 millones de años en el Cretácico tardío. Los análisis filogenéticos basados en la morfología y en las secuencias de ADN indican que las iridáceas constituyen un clado monofilético. Los caracteres morfológicos analizados en forma independiente ubicaron a las iridáceas dentro del orden de las liliales, mientras que las secuencias de ADN, o el análisis conjunto de datos morfológicos y moleculares, la ubican dentro de Asparagales.

Tres clados grandes son evidentes dentro de Iridaceae:

Muchas especies de iridáceas han sido estudiadas con respecto a su número cromosómico y cariotipo. Tales estudios han permitido determinar el número cromosómico básico de casi todos los géneros (los cuales varían desde x=6 hasta x=16) y delinear cuáles han sido los cambios cromosómicos que han acompañado la evolución de las iridáceas, desde su centro de diversificación en el sur de África hasta su actual distribución global. La reducción disploide (o sea, la disminución progresiva del número cromosómico básico como consecuencia de rearreglos cromosómicos) ha jugado un papel fundamental en la evolución de varios géneros, tales como "Gladiolus, Romulea, Crocus, Iris, Morea" y "Sisyrinchium." Todos estos géneros presentan varios números cromosómicos básicos y una especialización adaptativa que ha acompañado los cambios a nivel cromosómico. Un ejemplo de estos cambios en el número cromosómico lo ofrece "Gladiolus". En este género el número cromosómico básico más frecuente es x=15, con una gran mayoría de especies diploides (2n=30) en África. No obstante, para varias especies africanas se han informado otros números cromosómicos básicos. Así, "G. atropurpureus" presenta x = 12 (2n = 24 y 36); "G. serapiflorus", "G. gregarius," y "G. pseudospicatus" son diploides con x = 11 (2n = 22); "G. unguiculatus" presenta x = 13 (2n = 26) y x = 12 (2n = 24); mientras que "G. actinomorphanthus" presenta x = 14 (2n = 28). Estos números básicos x= 10, 11, 12, 13 y 14 se han originado por disploidía a partir de x = 15. Debido a que todas estas especies no se encuentran relacionadas desde el punto de vista morfológico, la reducción disploide en "Gladiolus" ha ocurrido en varias oportunidades durante la evolución del género, aparentemente en 4 linajes diferentes. Los cambios en el número cromosómico básico no estuvieron acompañados con reducciones en la cantidad de ADN nuclear ya que las mediciones de la longitud cromosómica total indican que todas las especies diploides presentan aproximadamente la misma cantidad de material cromosómico, con independencia del número básico de cromosomas. Finalmente, en África la poliploidía en las especies de "Gladiolus" es infrecuente, pero en las especies euroasiáticas es la regla más que la excepción. De hecho, el análisis cromosómico de las entidades europeas "G. atroviolaceus, G. communis, G. illyricus, G. imbricatus" y " G. italicus" indicó que no existen poblaciones diploides, sino que la mayoría de esos taxones forman series poliploides (3x, 4x, 6x, 8x y 12x) basadas en el número básico x = 15.

El nombre de la familia se basa en el del género "Iris", el mayor y más conocido de Europa. El origen del nombre se remonta a 1753, cuando Carlos Linneo viendo el extenso colorido de sus especies lo nombró como la diosa griega Iris. Este es un nombre conservado, de modo que incluso si un nombre anterior llega a ser descubierto para la familia, el nombre «Iridaceae» seguiría siendo válido. Se atribuye a la obra de 1789 de Antoine Laurent de Jussieu "Genera plantarum secundum ordines naturales disposita, juxta methodum in horto Regio Parisiensi exaratum anno 1774".

La familia ha sido aceptada en todos los grandes sistemas de clasificación del siglo XX. En el sistema de Cronquist es tratada como parte del orden Liliales dentro de la subclase Liliidae, el sistema de Takhtajan la colocó en su propio orden —Iridales— junto con Isophysidaceae y Geosiridaceae, las cuales fueron tratadas como familias separadas con un solo género cada una, y en el sistema de Thorne es tratada como parte del orden Orchidales, en su propio suborden, Iridineae. En el sistema creado por el Grupo para la filogenia de las angiospermas en 1998, 2003 y 2009 (APG, APG II y APG III, respectivamente) se coloca a las iridáceas en el orden de las asparagales, que forma parte a su vez de un clado llamado «monocotiledóneas no commelinóideas».

Sobre la base de la morfología floral y vegetativa, la anatomía, la embriología, la ultraestructura del polen, el análisis cromosómico y la quimiosistemática de compuestos flavonoides, la familia Iridaceae ha sido subdividida por el botánico Peter Goldblatt en cuatro subfamilias, las cuales se corresponden con los cuatro linajes principales que sugiere el análisis filogenético:

La familia comprende aproximadamente 70 géneros y más de 1600 especies, distribuidas por todo el globo, con una marcada concentración de especies en el hemisferio sur y el mayor centro de radiación en África, al sur del Sahara.

Muchas especies de Iridaceae presentan una gran importancia económica en la horticultura ornamental y en la industria de la flor cortada, especialmente "Gladiolus", "Freesia", "Sparaxis", "Iris", "Tigridia" («flor tigre»), "Ixia" («lirio del maíz»), "Romulea", "Neomarica", "Moraea" («lirio mariposa»), "Nemastylis", "Belamcanda", "Sisyrinchium" («pasto de ojos azules»), "Crocosmia", y "Trimezia". Muchos otros géneros ("Watsonia", "Crocus", "Dietes", "Tritonia", "Hesperantha" y "Neomarica") se cultivan en jardines en regiones tropicales y templadas, como plantas perennes y bulbosas.

"Moraea" y "Homeria" son dos géneros de plantas venenosas y representan un problema en las regiones productoras de ovinos y bovinos, notablemente en Sudáfrica.
Numerosas especies de iridáceas han sido utilizadas como plantas alimenticias, condimenticias, ornamentales y medicinales por diferentes culturas a través de los siglos. Los indios Navajo, por ejemplo, utilizaban decocciones de la planta de "Iris missouriensis" Nutt. como emético. Trozos de rizomas de la misma especie eran utilizados para controlar el dolor de muelas o se aplicaba la decocción caliente de la planta en los oídos para calmar la otitis. Las raíces pisadas de "Iris versicolor" L. se aplicaban en las heridas, probablemente como antiséptico y las infusiones de las raíces secas se suministraban para calmar cualquier dolor. En Hawái, "Sisyrinchium acre" se utilizaba de diversos modos. Las hojas y el jugo que se podía extraer de ellas se utilizaban para dar color azul a los tatuajes. Las hojas, maceradas con sal, azúcar y otras especies se recomendaba para limpiar y curar enfermedades de la piel. En India, "Iris ensata" se usaba como antihelmíntico, depurativo, diurético y vermífugo y, junto con otras especies, en el tratamiento de afecciones venéreas. El lirio leopardo ("Iris domestica") tiene una larga historia de uso en la medicina tradicional china ya que aparentemente es muy efectiva para controlar enfermedades causadas por bacterias, hongos y virus, como así también para disminuir la fiebre o disminuir inflamaciones. Las raíces de esta especie se cosechaba en el verano o el otoño y se secaba para usar más tarde. Otra Iridácea muy utilizada en medicina popular durante siglos es el azafrán ("Crocus sativus"). Los usos eran múltiples: antiespasmódico, afrodisíaco, carminativo, expectorante, narcótico, sedativo y estimulante, siendo en la actualidad reemplazado por medicinas menos onerosas.

La raíz de orris son los rizomas secos de "Iris germanica", "Iris florentina" o "Iris pallida". Antiguamente se utilizaba en medicina herbal occidental y, en la actualidad, se usa principalmente como fijador y nota de base en perfumería, como así también como ingrediente de muchas marcas de ginebra.

La flor de lis (en el francés original "fleur de l'iris") de la heráldica es una flor estilizada de una especie del género "Iris". Específicamente, se trata de "Iris pseudacorus", una especie común al borde de los cursos de aguas en Francia. Se utiliza como un diseño decorativo o como un símbolo. Puede tener, a un mismo tiempo, un significado religioso, político, dinástico, artístico, emblemático o simbólico.

La flor de lis se ha usado en heráldica desde hace siglos. En el siglo XII, Luis VI y Luis VII fueron los primeros monarcas franceses en usarla en su escudo. Los reyes ingleses la usaron más tarde en sus armas para enfatizar sus reclamos sobre el trono de Francia. En el siglo XIV, se incorporó a menudo en las insignias de familia que se cosían en el manto del caballero, que era usado por su propietario sobre la cota de mallas, de ahí el término «manto de armas».

Durante el siglo XX el símbolo de la flor de lis fue adoptado por el Movimiento Scout Mundial, organización presente en todo el mundo. Los scouts la representan sobre fondo de color violeta morado, pintada en blanco o plateado y rodeada por cuerda que acaba en un nudo «llano» (nudo de la hermandad), y con dos estrellas de cinco picos en los pétalos exteriores. Cada pétalo representa uno de los tres principios y deberes (hogar, sociedad y creencia) y tres virtudes (abnegación, lealtad y pureza) que todo Scout debe seguir y tener. Las estrellas representan la vida al aire libre y los diez artículos de la ley scout.

Existen especies de iridáceas que se consideran vulnerables o amenazadas de extinción. Las causas pueden ser la degradación de su hábitat natural o una distribución muy restringida. Según la Lista Roja de la IUCN las siguientes especies son vulnerables o se hallan amenazadas: "Gladiolus pole-evansii", "Gladiolus usambarensis", "Moraea callista", "Moraea stagnalis", "Mastigostyla orurensis", "Stahlia monosperma", "Crocus cyprius", "Crocus etruscus", "Crocus hartmannianus", "Iris boissieri", "Mastigostyla orurensis", "Romulea antiatlantica", "Romulea aquatica" y "Romulea multisulcata".

















</doc>
<doc id="1492" url="https://es.wikipedia.org/wiki?curid=1492" title="Internet Relay Chat">
Internet Relay Chat

IRC (Internet Relay Chat) es un protocolo de comunicación en tiempo real basado en texto, que permite debates entre dos o más personas. Se diferencia de la mensajería instantánea en que los usuarios no deben acceder a establecer la comunicación de antemano, de tal forma que todos los usuarios que se encuentran en un canal pueden comunicarse entre sí, aunque no hayan tenido ningún contacto anterior. Las conversaciones se desarrollan en los llamados canales de IRC, designados por nombres que habitualmente comienzan con el carácter # o & (este último solo es utilizado en canales locales del servidor). Es un sistema de charlas ampliamente utilizado por personas de todo el mundo.

Los usuarios del IRC utilizan una aplicación cliente para conectarse con un servidor, en el que funciona una aplicación IRCd (IRC daemon o servidor de IRC) que gestiona los canales y las conversaciones murales.

IRC fue creado por Jarkko Oikarinen en agosto de 1988 con el motivo de reemplazar al programa MUT (talk multiusuario) en un BBS llamado OuluBox en Finlandia. Oikarinen se inspiró en el Bitnet Relay Chat el cual operaba en la red Bitnet.

Fue utilizado en el intento de golpe de estado en la Unión Soviética de 1991 para informar a través de un periodo de censura en los medios y por los kuwaitíes durante la primera guerra del Golfo, eventos tras los cuales el IRC ganó popularidad.

Durante la primera mitad de la década de los 2000 la mayoría de redes vivieron un rápido incremento de usuarios, correspondiente con la popularización de Internet y especialmente de las redes de Chat. Desde entonces, la mayoría de redes ha sufrido un estancamiento o un retroceso en el número de usuarios, a pesar de la mayor implantación de Internet. La caída coincide con la popularización de otro tipo de redes, como la mensajería instantánea o las redes sociales.


Después de la primera implementación de Jarkko Oikarinen, han surgido una gran cantidad de implementaciones distintas de clientes IRC, tanto como programas independientes, como mIRC, Irssi, Konversation o X-Chat de los más populares, como integradas dentro de otros programas, como Chatzilla.

Se destaca también la utilización de distintos scripts, los cuales tienen como finalidad tomar un cliente existente de IRC como plataforma para el desarrollo de distintos scripts los cuales añaden funcionalidades extra y facilitan la operación de diversos clientes IRC.
En este caso se destacan Looksharp, NavIRC, IRCap, Xscript, entre otros.

IRC se definió originalmente como un protocolo de texto plano (extendido posteriormente), al que IANA asignó el puerto 194/TCP.
De todos modos el estándar de facto siempre ha sido utilizar IRC en el puerto 6667/TCP y otros cercanos (por ejemplo los puertos TCP 6660–6669, 7000) para evitar tener que ejecutar el servicio IRCd con privilegios de Root.

Algunos de los programas responsables del funcionamiento del IRC son:

Además de los Servidores y Clientes, en IRC se usan hoy en día diversos programas que entregan servicios tanto a la red en general, como a los usuarios en forma específica.
Algunos servicios como NickServ, ChanServ, MemoServ, HelpServ, HostServ, OperServ y StatServ son básicos en el funcionamiento de las redes de IRC.

Algunos de los servicios más usados en IRC son:


El IRC es popularmente utilizado para hablar, hacer amigos y reunir grupos de gente con los mismos gustos o transferir datos. Para ello, cualquier persona puede iniciar el canal específico.
Además de esto un canal de IRC también es utilizado como sitio para compartir archivos. Los hay especializados en música y en libros, entre otros. Otra modalidad muy utilizada es la de los juegos, en el que se destacan los Cyberjuegos, habiendo cientos de canales en todos los servidores.



</doc>
<doc id="1493" url="https://es.wikipedia.org/wiki?curid=1493" title="Illicium">
Illicium

El género Illicium comprende 45 especies de arbolitos o arbustos aromáticos y pertenece a la familia Schisandraceae. La especie tipo es "I. anisatum" 

Con los caracteres generales de la familia Schisandraceae.


Polinización entomógama, fundamentalmente llevada a cabo por dípteros, atraídos por el olor de las flores similar al pescado, en el caso de "I. floridanum".

La especie con mayor interés económico es el badián, cuyo fruto, denominado anís estrellado, badiana o badiana de China, "Illicium verum", de sabor a anís, por la presencia de anetol, se usan como condimento y en infusión, para tratar las flatulencias de los lactantes (carminativo) y las malas digestiones (eupéptico). 

Otras especies, sin embargo, son tóxicas por contener alcaloides venenosos. Este es el caso de un sucedáneo irregular del anterior, el anís estrellado del Japón, badiana del Japón o shikkimi, "Illicium anisatum", cuyo consumo puro o mezclado con el anterior provoca intoxicaciones, porque contiene sikamina, ácido sikímico, sikimipicrina y los alcaloides tóxicos shikimina y shikimotoxina, neurotóxicos. Los síntomas de envenenamiento incluyen vómitos, convulsiones, revulsión ocular (nistagmo) e irritabilidad alternando con somnolencia, detectadas en lactantes. Pueden resultar gravemente afectados los riñones, el tracto urinario, los órganos digestivos y el sistema nervioso. El ácido siquímico es la substancia base en la obtención del antivírico Oseltamivir. 

Algunas especies de "Illicum" tienen uso en jardinería, por ejemplo "Illicum anisatum", "Illicum floridanum".

El género se distribuye por el sureste de Asia, sureste de los Estados Unidos, México oriental, Cuba, Haití y República Dominicana.






</doc>
<doc id="1495" url="https://es.wikipedia.org/wiki?curid=1495" title="Infinitesimal">
Infinitesimal

Lo infinitesimal o infinitésimo se puede definir como una cantidad infinitamente pequeña, y originalmente fundamentó ciertos razonamientos del cálculo infinitesimal. En la crisis de los fundamentos matemáticos de principios del siglo XIX los infinitésimos fueron abandonados por los matemáticos, aunque siguieron siendo tratados informalmente en las ciencias aplicadas, y se suelen considerar como números en la práctica. Solo después de la segunda mitad del siglo XX apareció un enfoque totalmente riguroso de los números infinitesimales.

El análisis no estándar introducido en los años 1960 por Abraham Robinson es un enfoque axiomático y riguroso que permite introducir infinitesimales (números hiperreales no nulos cuyo valor absoluto es más pequeño que cualquier número real estándar). Si bien los resultados que pueden lograrse mediante el análisis no estándar pueden ser alcanzados por la teoría estándar de los números reales, existen muchas demostraciones matemáticas y deducciones que son más simples y breves cuando se usan el análisis no estándar. El inverso multiplicativo de un infinitesimal es un número real no estándar ilimitado.

El cálculo infinitesimal fue propuesto inicialmente por Arquímedes. Luego fue utilizado por Isaac Newton y Gottfried Leibniz, en los albores del surgimiento del Análisis matemático moderno, pero posteriormente fue desacreditado por George Berkeley y finalmente olvidado. Durante el siglo XIX Karl Weierstrass y Cauchy comenzaron a utilizar la definición formal de límite matemático, por lo que el cálculo infinitesimal ya no era necesario. Sin embargo durante el siglo XX los infinitesimales fueron rescatados como una herramienta que ayuda a calcular límites de forma simple. Es bastante popular el uso de infinitésimos en la bibliografía rusa.

Otra manera de trabajar con los infinitésimos es considerarlos como números, y no como límites, es decir trabajar en un conjunto formula_1 que contenga más números que los usuales. Se les llaman números hiperreales, y son una creación del análisis no estándar.

Un infinitesimal o infinitésimo es una cantidad infinitamente pequeña. Se puede definir matemáticamente como:

Algunas funciones son infinitésimos en determinados puntos, por ejemplo:

Por lo tanto, toda función cuando tiende a 0 en un punto se denomina infinitésima.


Dadas formula_2 y formula_6


Si dos infinitésimos son equivalentes entonces se puede aproximar uno a otro. Es decir si "f"("x") y "g"("x") son infinitésimos equivalentes cuando formula_13 entonces se puede decir que formula_14 cuando formula_15. Si se presentan como factor o divisor pueden sustituirse uno por otro para el cálculo de límites cuando formula_15:

Teorema: si existe el límite de formula_17 cuando formula_15, siendo formula_19 y formula_20 infinitésimos equivalentes en formula_21, entonces el límite de formula_22 es igual al límite de formula_17.

formula_24 es un infinitésimo cuando formula_25:


formula_24 es un infinitésimo cuando formula_36:

El análisis no estándar es una generalización del análisis real. El análisis no estándar permite definir además de los objetos definibles en la teoría ordinaria de los números reales nuevos objetos denominados "externos" o "no estándar". Cualquier objeto (número, conjunto o función) definible en la teoría convencional de los números reales es un objeto "estándar" dentro del análisis no estándar. Junto con los objetos "estándar" el análisis no estándar de Robinson permite introducir "objetos no estándar" como número inifinitesimales o números ilimitados (infinitos) y manejarlos de manera totalmente coherente dentro de la teoría.

La teoría no estándar parte de introducir un nuevo predicado formula_38, ese predicado permite construir un lenguaje formal que incluye a la teoría ordinaria de los números reales pero permite definir nuevos números (concretamente la noción de número "i-pequeño" e "i-grande" permiten construir números infinitesimales y números ilimitados más grandes que cualquier número real estándar u ordinario). El predicado "estándar" se caracteriza por tres axiomas adicionales que no posee la teoría ordinaria de los números reales, y que por tanto crean un lenguaje formal que permite formalizar números adicionales. El análisis no estándar hace un uso crucial de números infinitesimales e ilimitados:

El análisis no estándar por tanto permite construir un conjunto de números que extiende al de los números reales, este conjunto es de los números hiperreales y se representa como formula_39 y en él se pueden definirse reglas aritméticas para los números infinitesimales (inf(·)), ilimitados (Inf(·)), limitados (complemento del anterior: ¬Inf(·)) y apreciables (ni infinitesimos, ni ilimitados: ¬inf(·)∧¬Inf(·)), a partir de estos cuatro conjuntos se tienen las siguientes reglas de Leibniz para las operaciones aritméticas de estos conjuntos:
Para la multiplicación las reglas de Leibniz son las siguientes:




</doc>
<doc id="1498" url="https://es.wikipedia.org/wiki?curid=1498" title="Imperata">
Imperata

Imperata es un género de plantas de la familia de las poáceas. Es originario de zonas tropicales y regiones cálidas y templadas de todo el mundo.
Son hierbas perennes gramíneas rizomatosas nativas de las zonas tropicales y regiones cálidas y templadas de todo el mundo. Tienen tallos sólidos erguidos y sedosas inflorescencias. La especie más conocida es Imperata cylindrica, que es reconocido como una devastadora maleza nociva en muchos lugares y cultivada como planta ornamental en otros.

Tiene hojas con lígula membranosa, truncada, ciliada. Inflorescencia en panícula densa. Espiguillas todas semejantes, articuladas por debajo de las glumas, redondeadas, con 2 flores; la inferior reducida a la lema, y la superior hermafrodita. Pedúnculos con la parte apical ensanchada, ciatiforme. Glumas más largas que las flores, subiguales, con 5-7 nervios. Lema mútica. Palea más corta que la lema. Sin lodículas. Androceo con 2 estambres.
El género fue descrito por Domenico Maria Leone Cirillo y publicado en "Plantarum Rariorum Regni Neapolitani" 2: 26. 1792. La especie tipo es: "Imperata arundinacea" Cirillo. 
Imperata: nombre genérico otorgado en honor del naturalista italiano Ferrante Imperato (1525? – 1615?). 

El número cromosómico básico del género es x = 5 y 10, con números cromosómicos somáticos 2n = 20, 40, 50 y 60 , ya que hay especies diploides y una serie poliploide. Los cromosomas son relativamente pequeños.




</doc>
<doc id="1500" url="https://es.wikipedia.org/wiki?curid=1500" title="Intérprete (informática)">
Intérprete (informática)

En ciencias de la computación, intérprete o interpretador es un programa informático capaz de analizar y ejecutar otros programas. Los intérpretes se diferencian de los compiladores o de los ensambladores en que mientras estos traducen un programa desde su descripción en un lenguaje de programación al código de máquina del sistema, los intérpretes solo realizan la traducción a medida que sea necesaria, típicamente, instrucción por instrucción, y normalmente no guardan el resultado de dicha traducción.

Usando un intérprete, un solo archivo fuente puede producir resultados iguales incluso en sistemas sumamente diferentes (ejemplo. una PC y una PlayStation 4). Usando un compilador, un solo archivo fuente puede producir resultados iguales solo si es compilado a distintos ejecutables específicos a cada sistema.

Los programas interpretados suelen ser más lentos que los compilados debido a la necesidad de traducir el programa mientras se ejecuta, pero a cambio son más flexibles como entornos de programación y depuración (lo que se traduce, por ejemplo, en una mayor facilidad para reemplazar partes enteras del programa o añadir módulos completamente nuevos), y permiten ofrecer al programa interpretado un entorno no independiente de la máquina donde se ejecuta el intérprete, sino del propio intérprete (lo que se conoce comúnmente como máquina virtual).

Para mejorar el desempeño, algunas implementaciones de algunos lenguajes de programación pueden interpretar o compilar el código fuente original en una forma intermedia más compacta, y después traducir eso al código de máquina (ej. Perl, Python, MATLAB, y Ruby). Algunos aceptan los archivos fuente guardados en esta representación intermedia (ej. Python, UCSD Pascal y Java).

En la actualidad, uno de los entornos más comunes de uso de los intérpretes es en los navegadores web, debido a la posibilidad que estos tienen de ejecutarse independientemente de la plataforma.

Hay un espectro de posibilidades entre la interpretación y la compilación, dependiendo de la cantidad de análisis realizados antes de que el programa sea ejecutado. Por ejemplo, el Emacs Lisp es compilado a bytecode, que es una representación altamente comprimida y optimizada del código fuente del Lisp, pero no es código de máquina (y por lo tanto no está atado a cualquier hardware particular). Este bytecode es entonces interpretado por un intérprete de bytecode (que está escrito en C). En este caso, el código compilado es el código de máquina para una máquina virtual, que no está implementada en el hardware, sino en el intérprete de bytecode. El mismo acercamiento es utilizado con el código Forth usado en sistemas Open Firmware: el lenguaje fuente es compilado en "código F" (un bytecode).

La desventaja principal de los interpretadores es que cuando se interpreta un programa, típicamente corre más lentamente que si hubiera sido compilado. La diferencia en velocidades puede ser minúscula o grande; a menudo un orden de magnitud y a veces más. Generalmente toma más tiempo correr un programa bajo un interpretador que correr el código compilado, pero puede tomar menos tiempo para interpretarlo que el tiempo total requerido para compilarlo y ejecutarlo. Esto es especialmente importante si se está haciendo y probando un código prototipo cuando un ciclo de editar, interpretar y depurar del interpretador, a menudo puede ser mucho más corto que el ciclo de editar, compilar, ejecutar y depurar del compilador.

La interpretación de código es más lenta que la ejecución de código compilado porque el interpretador debe analizar cada sentencia en el programa cada vez que es ejecutada y entonces realizar la acción deseada, mientras que el código compilado solo realiza la acción dentro de un determinado contexto fijo por la compilación. Este análisis en tiempo de ejecución se conoce como "sobrecarga interpretativa". En un interpretador, el acceso a las variables es también más lento porque el mapeo de identificadores hacia las localizaciones de almacenamiento debe hacerse repetidamente en tiempo de ejecución en vez de en el tiempo de compilación. Hay varios compromisos entre la velocidad de desarrollo al usar un interpretador y la velocidad de ejecución al usar un compilador. Algunos sistemas (ej., algunos LISPs) permiten al código interpretado y al compilado llamarse el uno al otro y compartir variables. Esto significa que una vez que una rutina ha sido probada y depurada bajo el interpretador puede ser compilada y por lo tanto beneficiarse de una ejecución más rápida mientras que otras rutinas están siendo desarrolladas. Muchos interpretadores no ejecutan el código fuente tal y como está sino que lo convierten en una forma interna más compacta. Por ejemplo, algunos interpretadores BASIC reemplazan palabras clave (keywords) con tokens de un simple byte que pueden ser usados para encontrar la instrucción en una tabla de saltos. Un interpretador puede bien usar el mismo analizador lexicográfico y el analizador sintáctico (parser) que el compilador y entonces interpretar el árbol de sintaxis abstracta resultante.

En el espectro entre la interpretación y la compilación, otro acercamiento está transformando el código fuente en un árbol de sintaxis abstracta optimizado (AST), y después procediendo a ejecutar el programa siguiendo esta estructura arborescente. En este acercamiento cada sentencia necesita ser analizada (parsed) solo una vez. Como una ventaja sobre el bytecode, el AST mantiene la estructura y las relaciones globales del programa entre las sentencias (que se pierden en una representación de bytecode), y proporciona una representación más compacta.

Así, el AST se ha propuesto como un mejor formato intermedio para los compiladores justo a tiempo que el bytecode. También, permite realizar un mejor análisis durante tiempo de ejecución. Un interpretador Java basado en AST ha demostrado ser más rápido que un interpretador similar basado en bytecode, gracias a las más poderosas optimizaciones permitidas al tener la estructura completa del programa, así como tipos de datos de alto nivel, disponibles durante la ejecución.

Para desdibujar más la distinción entre los interpretadores, los interpretadores de bytecode y la compilación, está la compilación justo a tiempo (o JIT), una técnica en la cual la representación intermedia es compilada a código de máquina nativo en tiempo de ejecución. Esto confiere la eficiencia de ejecutar el código nativo, al costo de tiempo de inicio y de un uso creciente de la memoria cuando el bytecode o el AST es compilado por primera vez. La optimización adaptativa es una técnica complementaria en la cual el interpretador hace un análisis de desempeño del programa que está corriendo (profiling) y compila sus partes más frecuentemente ejecutadas a código nativo. Ambas técnicas tienen algunas décadas, apareciendo en lenguajes tales como Smalltalk en la década de 1980.

En años recientes, la compilación justo a tiempo ha ganado la atención de la mayoría de los implementadores de lenguajes de programación, con Java, Python, y el Microsoft .NET Framework todos ahora incluyendo JITs.

Algunos ejemplos de intérpretes:


Un lenguaje interpretado es un lenguaje de programación para el que la mayoría de sus implementaciones ejecuta las instrucciones directamente, sin una previa compilación del programa a instrucciones en lenguaje máquina. El intérprete ejecuta el programa directamente, traduciendo cada sentencia en una secuencia de una o más subrutinas ya compiladas en código máquina.

Los términos "lenguaje interpretado" y "lenguaje compilado" no están bien definidos porque, en teoría, cualquier lenguaje de programación puede ser interpretado o compilado. Cada vez es más popular, en las implementaciones más modernas de un lenguaje de programación, ofrecer ambas opciones.

Los lenguajes interpretados también pueden diferenciarse de los lenguajes de máquina. Funcionalmente, tanto la ejecución y la interpretación significan lo mismo -obtener la siguiente instrucción/sentencia del programa y su ejecución-. Aunque el "bytecode" (código byte) interpretado es además idéntico a su forma en código máquina y tiene una representación en ensamblador, el término "interpretado" se reserva en la práctica para lenguajes "procesados por software" (como las máquinas virtuales o emuladores) por encima del procesado nativo (por ejemplo, por hardware).

En principio, los programas de muchos lenguajes se pueden compilar o interpretar, emular o ejecutar nativamente, así que esta designación se aplica solamente a la implementación práctica más usual, en vez de representar una propiedad esencial del lenguaje. De forma parecida al microcódigo del procesador, muchos intérpretes, internamente recaen en una compilación en tiempo de ejecución.

Evitando la compilación, los programas interpretados son más fáciles de evolucionar durante el desarrollo y la ejecución (transformándose en ocasiones de uno en la otra). De otra parte, ya que la compilación implica una traducción a un formato más amigable con la máquina, los programas interpretados corren más lentamente y menos eficientemente (es decir, gastan considerablemente más energía). Esto es especialmente verdad para los lenguajes de guion, cuyas sentencias son más complejas de analizar comparadas con las instrucciones máquina.

Muchos lenguajes se han implementado usando tanto compiladores como intérpretes, incluyendo BASIC, C, Lisp, Pascal y Python. Java y C# se compilan a código byte, el lenguaje interpretado específico para la máquina virtual. Muchas implementaciones de Lisp pueden mezclar libremente código interpretado y compilado.

En los comienzos de la computación, el diseño de lenguajes fue fuertemente influenciado por la decisión de usar la compilación o la interpretación como modos de ejecución. Por ejemplo, algunos lenguajes compilados requieren que los programas deban indicar explícitamente el tipo de dato de una variable en el momento en que sea declarada o al ser usada por primera vez, mientras que algunos lenguajes interpretados toman ventaja de los aspectos dinámicos de la interpretación para hacer tales declaraciones innecesarias. Por ejemplo, Smalltalk (1980), que fue diseñado para ser interpretado en tiempo de ejecución, permite a objetos genéricos interactuar dinámicamente entre sí.

Inicialmente, los lenguajes interpretados eran compilados línea por línea, es decir, cada línea era compilada a medida que estaba a punto de ser ejecutada, y si un bucle o una subrutina hicieran que ciertas líneas se ejecutaran múltiples veces, serían recompiladas repetidamente. Esto ha llegado a ser mucho menos común. La mayoría de los lenguajes interpretados usan una representación intermedia, que combina tanto la compilación como la interpretación. En este caso, un compilador puede producir el código byte o el código enhebrado, que entonces es ejecutado por un intérprete de código byte.

Los ejemplos incluyen:

La representación intermedia se puede compilar una sola vez (como en Java), cada vez que se vaya a ejecutar (como en Perl o Ruby), o cada vez que se detecte un cambio en el código fuente antes de la ejecución (como en Python).

Interpretar un lenguaje da a las implementaciones una flexibilidad adicional sobre las implementaciones compiladas. Algunas características son más fáciles de implementar en intérpretes que en compiladores son (pero no se limitan a estas):


La principal desventaja de la interpretación es una velocidad de ejecución del programa mucho más lenta, comparada con la ejecución directa del código máquina en la CPU del ordenador. Una técnica utilizada para mejorar las prestaciones es la compilación en tiempo de ejecución, que convierte las secuencias ejecutadas más frecuentes en código máquina del ordenador.


Muchos lenguajes interpretados son primero compilados a código byte, que luego es normalmente interpretado por la máquina virtual usando la compilación en tiempo de ejecución, del código byte a código nativo. Sin embargo, algunas veces, el código byte también puede ser compilado a un binario nativo usando un compilador "Ahead-of-time compilation" (compilación por adelantado), o ejecutado nativamente, por el procesador hardware.





</doc>
<doc id="1501" url="https://es.wikipedia.org/wiki?curid=1501" title="Intérprete">
Intérprete

El término intérprete puede estar vinculado o referido a los artículos de Wikipedia que se indican a continuación:


</doc>
<doc id="1503" url="https://es.wikipedia.org/wiki?curid=1503" title="Inteligencia artificial">
Inteligencia artificial

La inteligencia artificial (IA) es la inteligencia llevada a cabo por máquinas. En ciencias de la computación, una máquina «inteligente» ideal es un agente flexible que percibe su entorno y lleva a cabo acciones que maximicen sus posibilidades de éxito en algún objetivo o tarea. Coloquialmente, el término inteligencia artificial se aplica cuando una máquina imita las funciones «cognitivas» que los humanos asocian con otras mentes humanas, como por ejemplo: «percibir», «razonar», «aprender» y «resolver problemas». Andreas Kaplan y Michael Haenlein definen la inteligencia artificial como «la capacidad de un sistema para interpretar correctamente datos externos, para aprender de dichos datos y emplear esos conocimientos para lograr tareas y metas concretas a través de la adaptación flexible». A medida que las máquinas se vuelven cada vez más capaces, tecnología que alguna vez se pensó que requería de inteligencia se elimina de la definición. Por ejemplo, el reconocimiento óptico de caracteres ya no se percibe como un ejemplo de la «inteligencia artificial» habiéndose convertido en una tecnología común. Avances tecnológicos todavía clasificados como inteligencia artificial son los sistemas de conducción autónomos o los capaces de jugar al ajedrez o al Go. 

Según Takeyas (2007) la IA es una rama de las ciencias computacionales encargada de estudiar modelos de cómputo capaces de realizar actividades propias de los seres humanos con base en dos de sus características primordiales: el razonamiento y la conducta.

En 1956, John McCarthy acuñó la expresión «inteligencia artificial», y la definió como «la ciencia e ingenio de hacer máquinas inteligentes, especialmente programas de cómputo inteligentes».

También existen distintos tipos de percepciones y acciones, que pueden ser obtenidas y producidas, respectivamente, por sensores físicos y sensores mecánicos en máquinas, pulsos eléctricos u ópticos en computadoras, tanto como por entradas y salidas de bits de un software y su entorno software.

Varios ejemplos se encuentran en el área de control de sistemas, planificación automática, la habilidad de responder a diagnósticos y a consultas de los consumidores, reconocimiento de escritura, reconocimiento del habla y reconocimiento de patrones. Los sistemas de IA actualmente son parte de la rutina en campos como economía, medicina, ingeniería, el transporte, las comunicaciones y la milicia, y se ha usado en gran variedad de aplicaciones de software, juegos de estrategia, como ajedrez de computador, y otros videojuegos.

"Búsqueda heurística." Podemos definir una heurística como estrategia que limita grandiosamente la búsqueda de soluciones ante grandes espacios de problemas.
Por lo tanto, ante un problema, nos ayuda a seleccionar las bifurcaciones dentro de un grafo con más posibilidades; con ello se restringe la búsqueda, aunque no siempre se garantiza una solución adecuada. Todo lo que se debe tener en cuenta para que una heurística sea adecuada es que nos proporcione soluciones que sean lo suficientemente buenas.
Además, con la utilización de la búsqueda heurística, no será necesario replantear un problema cada vez que se afronte, ya que si fue planteado anteriormente, esta sugerirá la forma en que se ha de proceder para resolverlo.

"Representación del conocimiento." La representación es una cuestión clave a la hora de encontrar soluciones adecuadas a los problemas planteados.
Si analizamos más detenidamente el término encontramos varias definiciones: según Barr y Feigenbaum, la representación del conocimiento es una combinación de estructuras de datos y procedimientos de interpretación que, si son utilizados correctamente por un programa, este podrá exhibir una conducta inteligente; según Fariñas y Verdejo, la Inteligencia Artificial tiene como objetivo construir modelos computacionales que al ejecutarse resuelvan tareas con resultados similares a los obtenidos por una persona, por lo que el tema central de esta disciplina es el estudio del conocimiento y su manejo; y según Buchanan y Shortliffe, la Representación del Conocimiento en un programa de Inteligencia Artificial significa elegir una serie de convenciones para describir objetos, relaciones, y procesos en el mundo.
Gran parte del esfuerzo realizado en la consecución de ordenadores inteligentes, según Rahael, ha sido caracterizado por el intento continuo de conseguir más y mejores estructuras de representación del conocimiento, junto con técnicas adecuadas para su manipulación, que permitiesen la resolución inteligente de algunos de los problemas ya planteados.
Otra característica importante es la inclusión en los programas de Inteligencia artificial, aunque por separado, de los conocimientos y la unidad que controla y dirige la búsqueda de soluciones. Dada esta disposición, en estos programas la modificación, ampliación y actualización de los mismos es sencilla.

El razonamiento que puede tener cualquier persona, ha demostrado ser una de los aspectos más difíciles de modelar «dentro» de un ordenador. El sentido común a menudo nos ayuda a prever multitud de hechos y fenómenos corrientes, pero, como ya hemos dicho, es muy complicado representarlos en un ordenador, dado que los razonamientos son casi siempre inexactos y sus conclusiones y las reglas en que se basan solamente son aproximadamente verdaderas.

"Lenguajes, entornos y herramientas de Inteligencia Artificial." En la Inteligencia Artificial, se han desarrollado diferentes lenguajes específicos para los diferentes campos de aplicación.
Estos lenguajes en su mayoría cuentan con una serie de características comunes que podemos resumir de la siguiente forma:
Este tipo de software ofrece una gran modularidad.
Poseen gran capacidad de tomar decisiones de programación hasta el último momento, es decir cuando el programa ya está ejecutándose.
Ofrecen grandes facilidades en el manejo de listas, y esto es importante, ya que las listas son la estructura más habitual para la representación del conocimiento en la Inteligencia Artificial.
Facilitan la realización de ciertos tipos de deducción automática permitiendo también la creación de una base de hechos (lugar donde se recogen los datos iniciales del problema a resolver y los resultados intermedios una vez obtenidos).
Permiten el uso simultáneo de estructuras que incorporan conocimiento declarativo o conocimiento procedimental.
Tienen una marcada orientación gráfica. Además, las herramientas de Inteligencia Artificial permiten hacer un seguimiento de los cambios realizados a lo largo de la sesión.
Disponen de herramientas para desarrollar programas que son capaces de comprender otros programas y realizar modificaciones sobre ellos.

Stuart Russell y Peter Norvig diferencian estos tipos de la inteligencia artificial:

La IA se divide en dos escuelas de pensamiento:

Se conoce también como IA simbólico-deductiva. Está basada en el análisis formal y estadístico del comportamiento humano ante diferentes problemas:

La Inteligencia Computacional (también conocida como IA subsimbólica-inductiva) implica desarrollo o aprendizaje interactivo (por ejemplo, modificaciones interactivas de los parámetros en sistemas de conexiones). El aprendizaje se realiza basándose en datos empíricos.

Los países latinoamericanos tienen la capacidad para aprovechar todo el potencial de la IA, sin embargo, debido a las limitaciones sociales y económicas, se ha realizado poca inversión en el gobierno, la industria y la investigación para avanzar en IA. Esto es una desventaja, ya que la IA es una tecnología importante y fundamental en la cuarta revolución industrial, y dada su naturaleza multipropósito, poder exponencial y capacidad predictiva podría ser una herramienta importante para abordar diversos desafíos que afectan el desarrollo de la región.


El concepto de IA es aún demasiado difuso. Contextualizando, y teniendo en cuenta un punto de vista científico, podríamos definir esta ciencia como la encargada de imitar el cerebro, que no el cuerpo, de una persona en todas sus funciones. Estas pueden ser las ya existentes en el humano o bien otras novedosas e incorporadas en el desarrollo de una máquina inteligente.

En relación a la conciencia y las emociones, y aunque por el momento la mayoría de los investigadores en el ámbito de la Inteligencia Artificial se centran sólo en el aspecto racional, hay expertos que consideran seriamente la posibilidad de incorporar componentes «emotivos» como "indicadores de estado", a fin de aumentar la eficacia de los sistemas inteligentes en determinadas situaciones.

Particularmente, en el caso de los robots móviles, es necesario que estos cuenten con algo similar a las emociones con el objeto de saber –en cada instante y como mínimo– qué hacer a continuación [Pinker, 2001, p. 481].

Al tener «sentimientos» y, al menos potencialmente, «motivaciones», podrán actuar de acuerdo con sus «intenciones» [Mazlish, 1995, p. 318]. Así, se podría equipar a un robot con dispositivos que controlen su medio interno; por ejemplo, que «sientan hambre» al detectar que su nivel de energía está descendiendo o que «sientan miedo» cuando este esté demasiado bajo.

Esta señal podría interrumpir los procesos de alto nivel y obligar al robot a conseguir el preciado elemento [Johnson-Laird, 1993, p. 359]. Incluso se podría introducir el «dolor» o el «sufrimiento físico», a fin de evitar las torpezas de funcionamiento como, por ejemplo, introducir la mano dentro de una cadena de engranajes o saltar desde una cierta altura, lo cual le provocaría daños irreparables.

Esto significa que los sistemas inteligentes deben ser dotados con mecanismos de retroalimentación que les permitan tener conocimiento de estados internos, igual que sucede con los humanos que disponen de propiocepción, interocepción, nocicepción, etcétera. Esto es fundamental tanto para tomar decisiones como para conservar su propia integridad y seguridad. La retroalimentación en sistemas está particularmente desarrollada en cibernética: por ejemplo, en el cambio de dirección y velocidad autónomo de un misil, utilizando como parámetro la posición en cada instante en relación al objetivo que debe alcanzar. Esto debe ser diferenciado del conocimiento que un sistema o programa computacional puede tener de sus estados internos, por ejemplo la cantidad de ciclos cumplidos en un loop o bucle en sentencias tipo "do... for", o la cantidad de memoria disponible para una operación determinada.

A los sistemas inteligentes el no tener en cuenta elementos emocionales les permite no olvidar la meta que deben alcanzar. En los humanos el olvido de la meta o el abandonar las metas por perturbaciones emocionales es un problema que en algunos casos llega a ser incapacitante. Los sistemas inteligentes, al combinar una memoria durable, una asignación de metas o "motivación", junto a la toma de decisiones y asignación de prioridades con base en estados actuales y estados meta, logran un comportamiento en extremo eficiente, especialmente ante problemas complejos y peligrosos.

En síntesis, lo racional y lo emocional están de tal manera interrelacionados entre sí, que se podría decir que no solo no son aspectos contradictorios sino que son –hasta cierto punto– complementarios.

Entonces nos planteamos la siguiente pregunta ¿Podrá adquirir consciencia la inteligencia artificial? La posibilidad de crear máquinas conscientes es inquietante. Sin embargo, está lejos de convertirse en realidad. Por ahora, solo se ha logrado que algunos robots se autoidentifiquen, aunque de la misma manera que identificarían a otros, es decir, sin tener consciencia de su propio «yo». Más allá de eso, queda un vasto camino por recorrer: comprender la consciencia para traducirla a programación que volcar en las máquinas. Y la primera parte de esta labor de momento parece inabarcable. 

Las principales críticas a la inteligencia artificial tienen que ver con su capacidad de imitar por completo a un ser humano. Sin embargo, hay expertos en el tema que indican que ningún humano individual tiene capacidad para resolver todo tipo de problemas, y autores como Howard Gardner han teorizado sobre la solución.

En los humanos, la capacidad de resolver problemas tiene dos aspectos: los aspectos innatos y los aspectos aprendidos. Los aspectos innatos permiten, por ejemplo, almacenar y recuperar información en la memoria, mientras que en los aspectos aprendidos reside el saber resolver un problema matemático mediante el algoritmo adecuado. Del mismo modo que un humano debe disponer de herramientas que le permitan solucionar ciertos problemas, los sistemas artificiales deben ser programados de modo tal que puedan llegar a resolverlos.

Muchas personas consideran que el test de Turing ha sido superado, citando conversaciones en que al dialogar con un programa de inteligencia artificial para chat, no saben que hablan con un programa. Sin embargo, esta situación no es equivalente a un test de Turing, que requiere que el participante se encuentre sobre aviso de la posibilidad de hablar con una máquina.

Otros experimentos mentales como la Habitación china, de John Searle, han mostrado cómo una máquina podría simular pensamiento sin realmente poseerlo, pasando el test de Turing sin siquiera entender lo que hace, tan solo reaccionando de una forma concreta a determinados estímulos (en el sentido más amplio de la palabra). Esto demostraría que la máquina en realidad no está pensando, ya que actuar de acuerdo con un programa preestablecido sería suficiente. Si para Turing el hecho de engañar a un ser humano que intenta evitar que le engañen es muestra de una mente inteligente, Searle considera posible lograr dicho efecto mediante reglas definidas a priori.

Uno de los mayores problemas en sistemas de inteligencia artificial es la comunicación con el usuario. Este obstáculo es debido a la ambigüedad del lenguaje, y se remonta a los inicios de los primeros sistemas operativos informáticos. La capacidad de los humanos para comunicarse entre sí implica el conocimiento del lenguaje que utiliza el interlocutor. Para que un humano pueda comunicarse con un sistema inteligente hay dos opciones: o bien que el humano aprenda el lenguaje del sistema como si aprendiese a hablar cualquier otro idioma distinto al nativo, o bien que el sistema tenga la capacidad de interpretar el mensaje del usuario en la lengua que el usuario utiliza. También hay desperfectos en las instalaciones de los mismos.

Un humano, durante toda su vida, aprende el vocabulario de su lengua nativa o materna, siendo capaz de interpretar los mensajes (a pesar de la polisemia de las palabras) utilizando el contexto para resolver ambigüedades. Sin embargo, debe conocer los distintos significados para poder interpretar, y es por esto que lenguajes especializados y técnicos son conocidos solamente por expertos en las respectivas disciplinas. Un sistema de inteligencia artificial se enfrenta con el mismo problema, la polisemia del lenguaje humano, su sintaxis poco estructurada, y los dialectos entre grupos.

Los desarrollos en inteligencia artificial son mayores en los campos disciplinares en los que existe mayor consenso entre especialistas. Un sistema experto es más probable que sea programado en física o en medicina que en sociología o en psicología. Esto se debe al problema del consenso entre especialistas en la definición de los conceptos involucrados y en los procedimientos y técnicas a utilizar. Por ejemplo, en física hay acuerdo sobre el concepto de velocidad y cómo calcularla. Sin embargo, en psicología se discuten los conceptos, la etiología, la psicopatología, y cómo proceder ante cierto diagnóstico. Esto dificulta la creación de sistemas inteligentes porque siempre habrá desacuerdo sobre la forma en que debería actuar el sistema para diferentes situaciones. A pesar de esto, hay grandes avances en el diseño de sistemas expertos para el diagnóstico y toma de decisiones en el ámbito médico y psiquiátrico (Adaraga Morales, Zaccagnini Sancho, 1994).

Al desarrollar un robot con inteligencia artificial se debe tener cuidado con la autonomía,hay que tener cuidado en no vincular el hecho de que el robot interaccione con seres humanos a su grado de autonomía. Si la relación de los humanos con el robot es de tipo maestro esclavo, y el papel de los humanos es dar órdenes y el del robot obedecerlas, entonces sí cabe hablar de una limitación de la autonomía del robot. Pero si la interacción de los humanos con el robot es de igual a igual, entonces su presencia no tiene por qué estar asociada a restricciones para que el robot pueda tomar sus propias decisiones.

Con el desarrollo de la tecnología de inteligencia artificial, muchas compañías de software como el aprendizaje profundo y el procesamiento del lenguaje natural han comenzado a producirse y la cantidad de películas sobre inteligencia artificial ha aumentado.
Stephen Hawking advirtió sobre los peligros de la inteligencia artificial y lo consideró una amenaza para la supervivencia de la humanidad.

La animatrónica junto con la inteligencia artificial es lo que da como resultado los androides, como se suele conocer a los robots que imitan el comportamiento humano. Tenemos una técnica capaz de dotar del aspecto y comportamiento de seres vivos a máquinas. Es decir, 'humanizar' a los robots. Pero ya no solo hablamos que los movimientos sean muy reales, sino que además, parece real gracias a la piel sintética que han usado y al maquillaje.

La empresa Disney está a punto de usar la animatrónica y la inteligencia artificial para simular uno de sus personajes en la vida real: "Pascal", uno de los personajes de la película "Enredados".

Por otro lado, Dubái ya está usando policías robots creados por PAL Robotics.


Las técnicas desarrolladas en el campo de la inteligencia artificial son numerosas y ubicuas. Comúnmente cuando un problema es resuelto mediante inteligencia artificial la solución es incorporada en ámbitos de la industria y de la vida diaria de los usuarios de programas de computadora, pero la percepción popular se olvida de los orígenes de estas tecnologías que dejan de ser percibidas como inteligencia artificial. A este fenómeno se le conoce como el efecto IA.


La mayoría de los juegos de mesa y una gran cantidad de problemas informáticos mediante la modelización del problema en estados con la posterior aplicación de un algoritmo de búsqueda entre estos estados. 

La aplicación más evidente es el control de los PNJ (Personaje No Jugador) en el juego. La búsqueda de ruta es otro de uso común para la IA, buscar un camino para mover un PNJ de un punto en un mapa a otro, teniendo en cuenta el terreno y evitando los obstáculos. Más allá de búsqueda de caminos, la navegación es un subcampo de la IA del juego que se centra en dar a los PNJ la capacidad de navegar en su entorno, la búsqueda de un camino hacia un objetivo, evitando colisiones con otras entidades o colaborar con ellos. La IA también está involucrada con el equilibrio de la dificultad del juego, que consiste en el ajuste de la dificultad de un videojuego en tiempo real basado en la habilidad del jugador, aumentando la dificultad del juego se aumentaría la capacidad de la IA reduciendo así el «tiempo de reacción» a determinados sucesos.

Una de las aplicaciones de la I.A en la que es muy fácil entender el funcionamiento y la programación de la misma es por ejemplo en el "tic-tac-toe", es decir, «las tres en raya». ¿Cómo podría programarse un juego de este tipo?

Para empezar, el tablero es una estructura de datos de tipo matriz que contiene unas casillas las cuales están ocupadas por un jugador o vacías. Una partida es una secuencia de estados por los que pasa un tablero. Para programar la inteligencia artificial para que pueda ganarnos debemos hacer que aprenda los distintos estados e ir avanzando por los que pueda ganar:



Normalmente para estos juegos se utiliza la estrategia minimax, la cual imita el comportamiento humano tras examinar un cierto número de jugadas anteriormente. En este enfoque existe una función de evaluación que da un valor a cada posible movimiento.

Al hablar acerca de la propiedad intelectual atribuida a creaciones de la inteligencia artificial se forma un debate fuerte alrededor de si una máquina puede tener derechos de autor. Según la Organización Mundial de la Propiedad Intelectual (OMPI), cualquier creación de la mente puede ser parte de la propiedad intelectual, pero no especifica si la mente debe ser humana o puede ser una máquina, dejando la creatividad artificial en la incertidumbre.

Alrededor del mundo han comenzado a surgir distintas legislaciones con el fin de manejar la inteligencia artificial, tanto su uso como creación. Los legisladores y miembros del gobierno han comenzado a pensar acerca de esta tecnología, enfatizando el riesgo y los desafíos complejos de esta. Observando el trabajo creado por una máquina, las leyes cuestionan la posibilidad de otorgarle propiedad intelectual a una máquina, abriendo una discusión respecto a la legislación relacionada con IA.

El 5 de febrero de 2020, la Oficina del Derecho de Autor de los Estados Unidos y la OMPI asistieron a un simposio donde observaron de manera profunda cómo la comunidad creativa utiliza la inteligencia artificial (AI) para crear trabajo original. Se discutieron las relaciones entre la inteligencia artificial y el derecho de autor, qué nivel de involucramiento es suficiente para que el trabajo resultante sea válido para protección de derechos de autor; los desafíos y consideraciones de usar "inputs" con derechos de autor para entrenar una máquina; y el futuro de la inteligencia artificial y sus políticas de derecho de autor.

El Director General de la OMPI, Francis Gurry, presentó su preocupación ante la falta de atención que hay frente a los derechos de propiedad intelectual, pues la gente suele dirigir su interés hacia temas de ciberseguridad, privacidad e integridad de datos al hablar de la inteligencia artificial. Así mismo, Gurry cuestionó si el crecimiento y la sostenibilidad de la tecnología AI nos guiaría a desarrollar dos sistemas para manejar derechos de autor- uno para creaciones humanas y otro para creaciones de máquinas.

Aún hay una falta de claridad en el entendimiento alrededor de la inteligencia artificial. Los desarrollos tecnológicos avanzan a paso rápido, aumentando su complejidad en políticas, legalidades y problemas éticos que se merecen la atención global. Antes de encontrar una manera de trabajar con los derechos de autor, es necesario entenderlo correctamente, pues aún no se sabe cómo juzgar la originalidad de un trabajo que nace de una composición de una serie de fragmentos de otros trabajos.

La asignación de derechos de autor alrededor de la inteligencia artificial aún no ha sido regulada por la falta de conocimientos y definiciones. Aún hay incertidumbre sobre si, y hasta que punto, la inteligencia artificial es capaz de producir contenido de manera autónoma y sin ningún humano involucrado, algo que podría influenciar si sus resultados pueden ser protegidos por derechos de autor. 

El sistema general de derechos de autor aún debe adaptarse al contexto digital de inteligencia artificial, pues están centrados en la creatividad humana. Los derechos de autor no están diseñados para manejar cualquier problema en las políticas relacionado con la creación y el uso de propiedad intelectual, y puede llegar a ser dañino estirar excesivamente los derechos de autor para resolver problemas periféricos dado que:

“Usar los derechos de autor para gobernar la inteligencia artificial es poco inteligente y contradictorio con la función primordial de los derechos de autor de ofrecer un espacio habilitado para que la creatividad florezca”

La conversación acerca de la propiedad intelectual tendrá que continuar hasta asegurarse de que la innovación sea protegida pero también tenga espacio para florecer.









</doc>
<doc id="1504" url="https://es.wikipedia.org/wiki?curid=1504" title="Ichnanthus">
Ichnanthus

Ichnanthus, es un género de plantas herbáceas perteneciente a la familia de las poáceas. Es originario del oeste de África tropical. Comprende 155 especies descritas y de estas, solo 33 aceptadas.
Son plantas anuales o perennes; con tallos frecuentemente decumbentes en los nudos inferiores; plantas hermafroditas. Hojas frecuentemente caulinares, en ocasiones basales; lígula una membrana esparcida a densamente ciliada; láminas lanceoladas a ovadas, aplanadas, a menudo con la base asimétrica y angostada, pseudopecioladas o sésiles. Inflorescencia una panícula simple o compuesta, generalmente una terminal y conspicuamente exerta de la vaina superior, en algunas especies con 1–varias panículas axilares menos exertas; espiguillas lanceoloides, pareadas, desigualmente pediceladas, comprimidas dorsalmente pero con las glumas prominentemente carinadas de manera que en muchas especies aparecen comprimidas lateralmente, con 2 flósculos; desarticulación por debajo de las glumas y a veces por debajo del flósculo superior; glumas desiguales, carinadas, la inferior generalmente más de la 1/2 del largo de la espiguilla; gluma superior y lema inferior casi iguales, más largas que el flósculo superior, herbáceas; flósculo inferior estéril o estaminado; pálea inferior membranácea; flósculo superior bisexual, comprimido dorsalmente; lema superior endurecida, la raquilla se continúa por abajo de la lema formando un pequeño pedicelo; pedicelo con apéndices membranáceos adnados en la base de la lema y libres en la parte superior (frecuentemente engrosados con aceite en la madurez), o los apéndices reducidos a pequeñas áreas esclerosadas o cicatrices en la base de la lema; lodículas 2; estambres 3; estilos 2. Fruto una cariopsis ovoide a elipsoide; embrión 1/3–1/2 la longitud de la cariopsis, hilo punteado.

El género fue descrito por Ambroise Marie François Joseph Palisot de Beauvois y publicado en "Essai d'une Nouvelle Agrostographie" 56, pl. 12, f. 1. 1812. La especie tipo es: "Ichnanthus panicoides" P. Beauv. 
Número de cromosomas: 2n = 18, 20, 40, y 54. 
Ichnanthus: nombre genérico que deriva de la palabra griega: "chnos" (un paso o de marca), tal vez se refieren a los apéndices debajo del florete superior. 





</doc>
<doc id="1505" url="https://es.wikipedia.org/wiki?curid=1505" title="Isachne">
Isachne

Isachne es un género de plantas herbáceas de la familia de las poáceas. Es originario de las regiones tropicales y subtropicales del mundo.
El número cromosómico básico del género es x = 10, con números cromosómicos somáticos 2n = 20, 50, y 60 , ya que hay especies diploides y una serie poliploide.



</doc>
<doc id="1506" url="https://es.wikipedia.org/wiki?curid=1506" title="Ischaemum">
Ischaemum

Ischaemum es un género de plantas herbáceas de la familia de las poáceas. Es originario de las regiones tropicales y subtropicales del mundo.
El género fue descrito por Carlos Linneo y publicado en "Journal of Botany, British and Foreign" 66: 141. 1928.
El nombre del género deriva del griego "ischaimon" (astringente), nombre dado originalmente a "Digitaria sanguinalis" por sus supuestas cualidades astringentes. 
El número cromosómico básico del género es x = 9 o 10, con números cromosómicos somáticos 2n = 18, 20, 40, 54, 56, y 68 , ya que hay especies diploides y una serie poliploide.

Relación de especies



</doc>
<doc id="1507" url="https://es.wikipedia.org/wiki?curid=1507" title="Ixophorus unisetus">
Ixophorus unisetus

Ixophorus es un género monotípico de plantas herbáceas de la familia de las poáceas. Su única especie, Ixophorus unisetus, es originaria de México, distribuyéndose desde México a Brasil y en Cuba.
Son plantas perennes cespitosas; con tallos de 50–140 cm de largo y 0.6–1 mm de ancho, suculentos, erectos, ramificados con la edad; nudos glabros o ligeramente adpreso pilosos; plantas monoicas. Vainas glabras, carinadas; lígula una membrana lacerada o ciliada, 1–2.5 mm de largo; láminas lineares, hasta 75 cm de largo y 10–25 mm de ancho, aplanadas, laxas, glabras. Inflorescencias terminales y axilares, panículas de racimos, panícula 10–25 cm de largo, cilíndrico-ovoide, racimos numerosos, simples, 2–8 cm de largo, escabrosos; cada espiguilla con una cerda subyacente, 7–12.5 mm de largo, víscida, espiguillas 3.5–4.7 mm de largo, lanceoladas y agudas en la antesis, anchamente ovadas en la madurez, subsésiles en 2 hileras a lo largo de los lados inferiores del raquis triquetro; desarticulación por debajo de las glumas, la espiguilla caediza como una unidad; glumas desiguales, herbáceas, gluma inferior anchamente ovada, 0.7–1.5 mm de largo, aguda, 1–3-nervia, gluma superior y lema inferior 3.5–4.7 mm de largo, ocultando al flósculo superior; flósculo inferior estaminado, con 2 lodículas y 3 estambres, las anteras 2–3.4 mm de largo; pálea inferior 2-carinada, tornándose circular en la madurez, con una base cordada y amplias alas cartáceas, mucho más ancha que el resto de la espiguilla; flósculo superior pistilado, 2–3.3 mm de largo, raramente con estambres rudimentarios; lema superior más corta que la espiguilla, elíptica, endurecida, apiculada, papilosa, los márgenes enrollados hacia adentro; pálea endurecida; lodículas 2; estilos 2. Fruto una cariopsis; embrión ca 1/2 de la longitud de la cariopsis, hilo de 1/3 la longitud de la cariopsis, elíptico.
"Ixophorus unisetus" fue descrito por (J.Presl) Schltdl. y publicado en "Linnaea" 31: 747, 420–422. 1861-1862.




</doc>
<doc id="1509" url="https://es.wikipedia.org/wiki?curid=1509" title="Imperio romano">
Imperio romano

El Imperio romano (en latín: "Imperium Romanum", "Senatus Populusque Romanus" o "Res publica populi romani") fue el tercer periodo de civilización romana en la Antigüedad clásica, posterior a la República romana y caracterizado por una forma de gobierno autocrática. El nacimiento del Imperio viene precedido por la expansión de su capital, Roma, que extendió su control en torno al mar Mediterráneo. Bajo la etapa imperial los dominios de Roma siguieron aumentando hasta llegar a su máxima extensión durante el reinado de Trajano, momento en que abarcaba desde el océano Atlántico al oeste hasta las orillas del mar Caspio, el mar Rojo y el golfo Pérsico al este, y desde el desierto del Sahara al sur hasta las tierras boscosas a orillas de los ríos Rin y Danubio y la frontera con Caledonia al norte. Su superficie máxima estimada sería de unos 6,5 millones de km².

El término es la traducción de la expresión latina «Imperium Romanum», que significa literalmente «El dominio de los romanos». Polibio fue uno de los primeros hombres en documentar la expansión de Roma aún como República. Durante los casi tres siglos anteriores al gobierno del primer emperador, César Augusto, Roma había adquirido mediante numerosos conflictos bélicos grandes extensiones de territorio que fueron divididas en provincias gobernadas directamente por propretores y procónsules, elegidos anualmente por sorteo entre los senadores que habían sido pretores o cónsules el año anterior. 

Durante la etapa republicana de Roma su principal competidora fue la ciudad púnica de Cartago, cuya expansión por la cuenca sur y oeste del Mediterráneo occidental rivalizaba con la de Roma y que tras las tres guerras púnicas se convirtió en la primera gran víctima de la República. Las guerras púnicas llevaron a Roma a salir de sus fronteras naturales en la península itálica y a adquirir poco a poco nuevos dominios que debía administrar, como Sicilia, Cerdeña, Córcega, Hispania, Iliria, etc.

Los dominios de Roma se hicieron tan extensos que pronto fueron difícilmente gobernables por un Senado incapaz de moverse de la capital ni de tomar decisiones con rapidez. Asimismo, un ejército creciente reveló la importancia que tenía poseer la autoridad sobre las tropas para obtener réditos políticos. Así fue como surgieron personajes ambiciosos cuyo objetivo principal era el poder. Este fue el caso de Julio César, quien no solo amplió los dominios de Roma conquistando la Galia, sino que desafió la autoridad del Senado romano.

El Imperio romano como sistema político surgió tras las guerras civiles que siguieron a la muerte de Julio César, en los momentos finales de la República romana. Tras la guerra civil que lo enfrentó a Pompeyo y al Senado, César se había erigido en mandatario absoluto de Roma y se había hecho nombrar "Dictator perpetuus" (dictador vitalicio). Tal osadía no agradó a los miembros más conservadores del Senado romano, que conspiraron contra él y lo asesinaron durante los Idus de marzo dentro del propio Senado, lo que suponía el restablecimiento de la República, cuyo retorno, sin embargo, sería efímero. El precedente no pasó inadvertido para el joven hijo adoptivo de César, Octavio, quien se convirtió años más tarde en el primer emperador de Roma, tras derrotar en el campo de batalla, primero a los asesinos de César, y más tarde a su antiguo aliado, Marco Antonio, unido a la reina Cleopatra VII de Egipto en una ambiciosa alianza para conquistar Roma.

A su regreso triunfal de Egipto, convertido desde ese momento en provincia romana, la implantación del sistema político imperial sobre los dominios de Roma deviene imparable, aún manteniendo las formas republicanas. Augusto aseguró el poder imperial con importantes reformas y una unidad política y cultural (civilización grecorromana) centrada en los países mediterráneos, que mantendrían su vigencia hasta la llegada de Diocleciano, quien trató de salvar un Imperio que caía hacia el abismo. Fue este último quien, por primera vez, dividió el vasto Imperio para facilitar su gestión. El Imperio se volvió a unir y a separar en diversas ocasiones siguiendo el ritmo de guerras civiles, usurpadores y repartos entre herederos al trono hasta que, a la muerte de Teodosio I el Grande en el año 395, quedó definitivamente dividido.

En el inmenso territorio del Imperio Romano se fundaron muchas de las grandes e importantes ciudades de la actual Europa Occidental, el norte de África, Anatolia, el Levante. Ejemplos son París (Lutecia), Estambul (Constantinopla), Vienna (Vindobona), Barcelona (Barcino), Zaragoza (Caesaraugusta), Mérida (Augusta Emerita), Milán (Mediolanum), Londres, (Londinium), Colchester (Camulodunum) o Lyon (Lugdunum) entre otros.

Finalmente, en 476 el hérulo Odoacro depuso al último emperador de Occidente, Rómulo Augústulo. El Senado envió las insignias imperiales a Constantinopla, la capital de Oriente, formalizándose así la capitulación del Imperio de Occidente. El Imperio romano oriental proseguiría casi un milenio en pie como el Imperio romano (aunque usualmente se use el moderno nombre historiográfico de Imperio bizantino), hasta que en 1453 Constantinopla cayó bajo el poder del Imperio otomano.

El legado de Roma fue inmenso; tanto es así que varios fueron los intentos de restauración del Imperio, al menos en su denominación. Destaca el intento de recuperar occidente de Justiniano I, por medio de sus generales Narsés y Belisario, el de Carlomagno con el Imperio Carolingio o el del Sacro Imperio Romano Germánico, sucesor de este último, pero ninguno llegó jamás a reunificar todos los territorios del Mediterráneo como una vez lograra la Roma de tiempos clásicos.

Con el colapso del Imperio romano de Occidente finaliza oficialmente la Edad Antigua dando inicio la Edad Media.

Los primeros emperadores desde Augusto hasta la muerte de Nerón, es decir, entre 27 a. C. y 68 d. C., formaron la dinastía Julio-Claudia, que tras el periodo del 68 al 69, el año de los cuatro emperadores, dio paso a la dinastía Flavia con tres emperadores del 69 al 96 y a la dinastía Antonina, los cinco buenos emperadores, del 96 al 180. El 180 se inició la dinastía Severa que duró hasta la muerte de Alejandro Severo en el 235. Con la muerte de Alejandro, se da por iniciada la crisis del siglo.

Los sucesores de Augusto no demostraron ser especialmente dotados, lo que evidenciaba las debilidades de un sistema dinástico hereditario. Tiberio, Calígula y Nerón fueron especialmente despóticos e incluso se dejaron llevar por excesos que pusieron a prueba la fortaleza del sistema consolidado bajo la administración de Octavio. 

Esta dinastía de emperadores sobresalió en el aspecto de la administración y la construcción. Mantuvieron protegidas las fronteras mediante campamentos militares y otorgaron derechos de ciudadanía romana a los habitantes de las provincias del imperio. 

Los llamados «Cinco Buenos Emperadores» llevaron Roma a su culmen territorial, económico y de poder: Nerva; Trajano, de origen hispano y gran conquistador; Adriano, querido emperador que realizó grandes reformas y visitó numerosas partes del imperio; Antonino Pío; y Marco Aurelio(junto con Lucio Vero), pensador a la par que defensor de las fronteras.

A principios del siglo , las tribus germánicas, empujadas hacia el oeste por la presión de los pueblos hunos, procedentes de las estepas asiáticas, penetraron en el Imperio romano. Las fronteras cedieron por falta de soldados que las defendiesen y el ejército no pudo impedir que Roma fuese saqueada por visigodos y vándalos. Cada uno de estos pueblos se instaló en una región del imperio donde fundaron reinos independientes. Uno de los más importantes fue el que derivaría a la postre en el Sacro Imperio Romano Germánico. 

El emperador ya no controlaba el Imperio, de tal manera que en el año 476 Odoacro, rey de los hérulos, destituyó a Rómulo Augústulo, un adolescente de quince años que fue el último emperador romano de Occidente y envió las insignias imperiales a Zenón, emperador romano de Oriente.

A lo largo de los siglos que suceden a la caída del Imperio romano de Occidente, muchas civilizaciones de la edad media y más tarde, de la edad moderna, se proponen restaurar el Imperio Romano a su antigua gloria. El intento más antiguo y el que más se acercó fue el del Imperio bizantino, por decisión de Justiniano I, en el siglo utilizó a sus mejores generales (Narsés y Belisario) para devolver la antigua gloria del Imperio. 

Tres siglos más tarde, un rey Franco, Carlomagno, hijo de Pipino el Breve, fundó la dinastía Carolingia, convirtiendo el reino Franco en el Imperio carolingio. Carlomagno se hizo con el poder de la mayoría de territorios en Europa Central, convirtiéndose en la principal potencia de Europa en ese momento. Más tarde, se firmó el tratado de Verdún (843), que repartía el imperio entre los tres nietos de Carlomagno, los reinos sucesores fueron la Francia Occidental ("Francia Occidentalis"), que se convertiría en el reino de Francia, Francia Media y Francia Oriental (Francia Orientalis), que se convertiría en el Sacro Imperio Romano. A pesar de que fuera muy extenso, no se asemejaba en tamaño ni siquiera al Imperio de Occidente en su apogeo territorial.

Un reino sucesor del Imperio carolingio se hizo con mucho territorio en Europa, fue entonces cuando fue rebautizado como Sacro Imperio Romano. Este Imperio no fue tan extenso como su antecesor, el Imperio carolingio, pero fue mucho más duradero, llegando hasta la Edad Contemporánea.

 
El mando supremo del ejército correspondía al Emperador. En provincias el mando correspondía al gobernador provincial (pero este a su vez estaba supeditado al Emperador que podía apartarlo cuando quisiera), pudiendo también asumirlo temporalmente el Emperador. El número de legiones osciló en toda la época imperial, con un número máximo cercano a la treintena. 

Las clases altas de caballeros y senadores fueron desapareciendo del ejército, de modo que las legiones debían reclutarse entre los ciudadanos, primero en Italia y después progresivamente en las provincias donde estaban acantonadas (destacaron los mauros, los tracios y sobre todo los ilirios), de modo que desde Adriano el reclutamiento se hizo casi exclusivamente en las provincias donde servía la legión, y por fin se recurrió a mercenarios extranjeros (sobre todo germanos). Con la entrada de los proletarios el ejército se profesionalizó, si bien estos soldados tenían más facilidad para el motín y el saqueo. Los ascensos se ganaban por méritos, por favores o por dinero. El tiempo de servicio fue aumentado progresivamente y no eran excepcionales servicios de treinta o más años, tras lo cual se conseguía un estipendio económico, la ciudadanía y privilegios como el acceso a algunos cargos municipales. 

La legión disponía de arsenales ("armamentos") y de talleres de fabricación y reparación. Los soldados recibían un sueldo, donativos imperiales en ocasión del acceso al trono, las fiestas o los motines, regalos ("stillaturae") y el botín de guerra. La ración de alimentos diaria fue creciendo y se le proporcionaba trigo, sal, vino, vinagre, carne fresca y carne salada. 

Los campamentos se convirtieron en plazas fuertes. Disponían de murallas y torreones y se dividían interiormente en cuatro partes marcadas por dos vías perpendiculares. Contenían sala de baños, sala de reuniones, capillas, oficinas, cárcel, hospital y almacenes. Los mercaderes, artistas, prostitutas y otros acudían a sus alrededores y se establecían constituyéndose aglomeraciones urbanas, y crecían los barrios exteriores para la población civil ("canabae") con casas de baños, anfiteatros y otros edificios públicos. Los terrenos próximos se utilizaban como pastos para el ganado, que se arrendaban a los agricultores de la zona. 

Una típica legión romana (cuyo emblema era un águila plateada) consistía en diez cohortes (con su respectivo estandarte) cada una de ellas con cinco o seis centurias de ochenta hombres subdivididas en diez contubernios (unidad básica de ocho legionarios que compartían tienda), contando pues cada legión cinco o seis mil hombres de infantería, divididos en cincuenta o sesenta centurias. Contaba también con las guerrillas regulares auxiliares y de caballería ("alae") con ciento veinte hombres de caballería. 

El emperador y en su nombre el gobernador provincial designaban a los "legatus legionis", lugartenientes de la legión con funciones de pretor, y a sus asistentes los tribunos militares y los centuriones. 

Junto a los legados de la legión estaban los "benefiaciarii" (encargados de misiones de confianza), los "strato" (escuderos), los "comentarienses" (archiveros), los "cornicularii" (contadores) y los "actuario" (escribientes). Los tribunos militares se dividían en "laticlavii" (afectos a la administración) y "angusticlavii" (misiones propiamente militares). Los centuriones eran los oficiales básicos de infantería (la centuria de 80 hombres) y de caballería (la turma de 30 hombres). Cada centuria y turma tenía un suboficial llamado "optio" (equivalente a sargento), que también ejercía funciones administrativas. Los decuriones eran suboficiales que en la infantería mandaban una decuria (nueve hombres) y en la caballería de las unidades auxiliares mandaba un escuadrón o "turma" (30 jinetes). Otros suboficiales eran el "tesserarius" (equivalente a un sargento), el "signifer" o "vexillarius" (portaestandartes), el "aquilifer" (el portador del águila legionaria), el "campiductor" (instructor) y el "pecunarius" (furriel). 

Las cohortes se estructuraban en diez filas de 40 o 60 hileras que en tiempos de Trajano se redujeron a cinco filas. Con Adriano surgió la cohorte familiar (compuesta de 1200 soldados escogidos) mientras las restantes cohortes fueron llamadas "quingentaries" y contaban 500 soldados. 

Se estructuraron varias cohortes especializadas: las de infantería (peditata), la de caballería o mixta ("equitativa"), la policial ("togata"), la de vigilancia ("excubitoria"), la de guarnición en una ciudad ("urbana"), la encargada de apagar incendios ("Vigilio") y la encargada de la guardia y custodia imperial o de un caudillo ("Praetoriana "). Esta guardia personal del general en jefe fue habitual en el Imperio. Existía el cuartel general (Guardia Pretoriana o guardia del general en jefe) los miembros tenían más sueldo y estaban dispensados de los trabajos del campamento, y que llegaron a ser los árbitros del Imperio.

Las centurias estaban al mando de centuriones (el centurión de más prestigio era el "primus pilus" habitualmente el más veterano), por encima del cual había seis tribunos de la legión de rango ecuestre, y el "legatus" de la legión, de rango senatorial, que había sido anteriormente pretor (en las provincias donde solo había una legión, el "legatus" de la provincia y el de la Legión era la misma persona).

El equipamiento de los legionarios cambiaba sustancialmente dependiendo del rango. Durante las campañas, los legionarios iban equipados con armadura ("lorica segmentata"), escudo ("scutum"), casco ("galae"), una lanza pesada y una ligera ("pilum"), una espada corta ("gladius"), una daga ("pugio"), un par de sandalias ("caligae"), una "sarcina" (mochila de marcha), y comida y agua para dos semanas, equipo de cocina, dos estacas ("Sude murale") para la construcción de muros, y una pala o cesta.

La Armada romana (en latín "classis", literalmente "flota") comprendió las fuerzas navales del antiguo Estado romano. A pesar de jugar un papel decisivo en la expansión romana por el Mediterráneo, la armada nunca tuvo el prestigio de las legiones romanas. A lo largo de su historia los romanos fueron un pueblo esencialmente terrestre, y dejaron los temas náuticos en manos de pueblos más familiarizados con ellos, como los griegos y los egipcios, para construir barcos y mandarlos. Parcialmente debido a esto, la armada nunca fue totalmente abrazada por el Estado romano, y se consideraba «no romana». En la Antigüedad, las armadas y las flotas comerciales no tenían la autonomía logística que en la actualidad. A diferencia de las fuerzas navales modernas, la armada romana, incluso en su apogeo, no existió de forma autónoma, sino que operó como un adjunto del Ejército romano. 

En el transcurso de la primera guerra púnica la armada fue expandida masivamente y jugó un papel vital en la victoria romana y en la ascensión de la República romana a la hegemonía en el Mediterráneo. Durante la primera mitad del siglo a. C. Roma destruyó Cartago y subyugó los reinos helenísticos del este del Mediterráneo, logrando el dominio completo de todas las orillas del mar interior, que ellos llamaron "Mare Nostrum". Las flotas romanas volvieron a tener un papel preponderante en el siglo a. C. en las guerras contras los piratas y en las guerras civiles que provocaron la caída de la República, cuyas campañas se extendieron a lo largo del Mediterráneo. En el 31 a. C. la batalla de Accio puso fin a las guerras civiles con la victoria final de Augusto y el establecimiento del Imperio romano. 

Durante el período imperial el Mediterráneo fue un pacífico «lago romano» por la ausencia de un rival marítimo, y la armada quedó reducida mayormente a patrullaje y tareas de transporte.

Sin embargo, en las fronteras del Imperio, en las nuevas conquistas o, cada vez más, en la defensa contra las invasiones bárbaras, las flotas romanas estuvieron plenamente implicadas. El declive del Imperio en el siglo d. C. se sintió en la armada, que quedó reducida a la sombra de sí misma, tanto en tamaño como en capacidad de combate. En las sucesivas oleadas de los pueblos bárbaros contra las fronteras del Imperio la armada sólo pudo desempeñar un papel secundario. A comienzos del siglo v las fronteras del imperio fueron quebradas y pronto aparecieron reinos bárbaros en las orillas del Mediterráneo occidental. Uno de ellos, el pueblo vándalo, creó una flota propia y atacó las costas del Mediterráneo, incluso llegó a saquear Roma, mientras las disminuidas flotas romanas fueron incapaces de ofrecer resistencia. El Imperio romano de Occidente colapsó en el siglo y la posterior armada romana del duradero Imperio romano de Oriente es llamada por los historiadores Armada bizantina.

Las ciudades romanas eran el centro de la cultura, la política y la economía de la época. Base del sistema judicial, administrativo y fiscal eran también muy importantes para el comercio y a su vez albergaban diferentes acontecimientos culturales. Es importante destacar que Roma fue, a diferencia de otros, un imperio fundamentalmente urbano.

Las ciudades romanas estaban comunicadas por amplias calzadas que permitían el rápido desplazamiento de los ejércitos y las caravanas de mercaderes, así como los correos. Las ciudades nuevas se fundaban partiendo siempre de una estructura básica de red ortogonal con dos calles principales, el "cardo" y el "decumano" que se cruzaban en el centro económico y social de la ciudad, el foro, alrededor del cual se erigían templos, monumentos y edificios públicos. También en él se disponían la mayoría de las tiendas y puestos comerciales convirtiendo el foro en punto de paso obligado para todo aquel que visitase la ciudad. Así mismo un cuidado sistema de alcantarillado garantizaba una buena salubridad e higiene de la ciudad romana.

Curiosamente, este riguroso ordenamiento urbanístico, ejemplo del orden romano, nunca se aplicó en la propia Roma, ciudad que surgió mucho antes que el imperio y que ya tenía una estructura un tanto desordenada. El advenimiento del auge del poder imperial motivó su rápido crecimiento con la llegada de multitud de nuevos inmigrantes a la ciudad en busca de fortuna. Roma nunca fue capaz de digerir bien su grandeza acentuándose más aún el caos y la desorganización. La capital construía hacia lo alto, el escaso espacio propició la especulación inmobiliaria y muchas veces se construyó mal y deprisa siendo frecuentes los derrumbes por bloques de pisos de mala calidad. Famosos eran también los atascos de carros en las intrincadas callejuelas romanas. La fortuna sin embargo quiso que la capital imperial se incendiara el año 64 d. C., durante el mandato de Nerón. La reconstrucción de los diferentes barrios se realizó conforme a un plan maestro diseñado a base de calles rectas y anchas y grandes parques lo que permitió aumentar muchísimo las condiciones higiénicas de la ciudad.

Por lo demás toda ciudad romana trataba de gozar de las mismas comodidades que la capital y los emperadores gustosos favorecían la propagación del modo de vida romano sabedores de que era la mejor carta de romanización de las futuras generaciones acomodadas que jamás desearían volver al tiempo en que sus antepasados se rebelaban contra Roma. Por ello, allí donde fuera preciso se construían teatros, termas, anfiteatros y circos para el entretenimiento y el ocio de los ciudadanos. También muchas ciudades intelectuales gozaban de prestigiosas bibliotecas y centros de estudio, así fue en Atenas por ejemplo ciudad que siempre presumió de su presuntuosa condición de ser la cuna de la filosofía y el pensamiento racional.

Para traer agua desde todos los rincones se construían acueductos si era preciso, el agua llegaba a veces con tal presión que era necesario construir abundantes fuentes por todas partes lo que aún aumentaba más el encanto de dichas ciudades, que a pesar de estar construidas en tierras secas recibían la llegada de las bien planificadas canalizaciones romanas.

Las casas típicas eran las "insulae" (isla). Solían estar hechas de adobe normalmente de unos tres o cuatro pisos aunque en Roma o en otras ciudades de gran densidad se llegaban a construir verdaderos rascacielos cuya solidez muchas veces fue más que dudosa. La gente rica y de dinero, patricios de buena familia o ricos comerciantes plebeyos que habían hecho fortuna se alojaban en casa de una sola planta con patio interior ("impluvium") recubierto de mosaicos llamadas "domus".

En honor a las victorias se construían columnas, arcos de triunfo, estatuas ecuestres y placas conmemorativas que solían hacer siempre referencia al emperador reinante y sus gloriosas victorias conseguidas en pos de la salvaguarda de la "pax romana" de la que gozaban inconscientes los ciudadanos de la urbe. Era un motivo que se recordaba constantemente para dar sentido a la recaudación imperial, sin dinero no hay ejército, sin ejército no hay seguridad y sin seguridad no hay ciudades ni comercio. Algo que quedaría patente a finales del bajo imperio.

Con la llegada de la crisis del siglo y, particularmente, ya en el tardío Imperio cristiano la seguridad de la que disfrutaron durante tiempo las ciudades romanas había desaparecido. Y muchas de ellas, sobre todo las más fronterizas con los limes acechados por los pueblos germanos se vieron obligadas a amurallarse y recluirse en fortificaciones sacrificando calidad de vida por seguridad. Fue un paso hacia atrás que se materializaría con la desaparición del Imperio de Occidente, la ruralización, el fin de las actividades comerciales y el surgimiento de los castillos medievales.

La economía del Imperio romano era la propia de un imperio esclavista; los esclavos trabajaban, obviamente sin remuneración alguna, lo cual producía una enorme riqueza. Las diferentes ciudades y provincias estaban conectadas por una red de comunicaciones, vías y puertos, que fomentaban el comercio notablemente.

Aunque la vida se centraba en las ciudades, la mayoría de los habitantes vivían en el campo con un buen nivel, donde cultivaban la tierra y cuidaban el ganado. Los cultivos más importantes eran el trigo, la cebada, la viña y los olivos, también árboles frutales, hortalizas y legumbres. Los romanos mejoraron las técnicas agrícolas introduciendo el arado romano, molinos más eficaces, como el grano, el prensado de aceite, técnicas de regadío y el uso de abono.

Desde el punto de vista económico, la base agrícola varía bastante según las zonas.

La sociedad romana original (comienzos de la República) se configura de dos clases sociales que tenían la ciudadanía romana: una aristocracia de propietarios ("patricii", patricios) y una clase popular que luchaba por conseguir derechos ("plebs", plebeyos). Como ya se ha dicho anteriormente, la economía estaba basada en el sistema de producción esclavista, donde la mayoría de los esclavos eran prisioneros de guerra. Existían mercados de esclavos donde se comerciaba con ellos como si fuesen simples mercancías.

Así pues la sociedad romana en sus orígenes estaba dividida en:

Al evolucionar la República y convertirse en Imperio, esta sociedad evolucionó con ella dando origen a nuevos grupos o transformando otros. Ya hacia finales del siglo a. C. se había formado la clase de los optimates (o aristocracia patricio-plebeya), resultado de la fusión de los antiguos patricios con los plebeyos más ricos. 

En la medida que Roma entró en el gran circuito económico del Mediterráneo se desarrolló la clase de los caballeros (u orden ecuestre), dedicada a los negocios (empresarios mineros, grandes comerciantes, prestamistas, etc.). 

Por su parte, la antigua clase media campesina, propietaria de tierras en Italia, se arruinó con las guerras y con la competencia de los latifundios y los productos agrícolas a bajo precio venidos de las provincias. Los campesinos pobres que la formaban emigraron a Roma y a las grandes ciudades de Italia, transformándose en el proletariado romano, una masa ociosa y llena de vicios, cuyos integrantes solían engrosar la clientela de los políticos profesionales y a quienes vendían sus votos. El proletariado fue sostenido por el aporte económico de sus patrones y, durante el Imperio, por las arcas fiscales y los recursos de los emperadores.

La sociedad siguió evolucionando durante el Imperio.

Se tiene constancia de más de sesenta lenguas diferentes habladas en los territorios que alguna vez formaron parte del Imperio romano. El proceso de romanización que tuvo lugar en los territorios controlados de manera prolongada por el Imperio romano comportó en muchos de ellos un proceso de sustitución lingüística que llevó a la desaparición de lenguas autóctonas. Sin embargo, este proceso no fue siempre de corta duración y típicamente abarcó diversas generaciones e incluso siglos, en los que el bilingüísmo con el latín o incluso el multilingüismo fue frecuente.

La mayor parte de lenguas en la parte europea del Imperio romano eran lenguas indoeuropeas de los grupos anotolio, celta, germánico, greco-armenio e itálico, además de algunas otras lenguas indoeuropeas más difíciles de clasificar (a veces llamadas lenguas paleobalcánicas). Aunque también están testimoniadas lenguas no indoeuropeas autóctonas como el aquitano y las lenguas tirsénicas, cuya principal representante es el etrusco. En el norte de África y Oriente Próximo, también tienen presencia muchas ramas de las lenguas afroasiáticas (egipcio, bereber y semítico).

La religión de los romanos era politeísta (adoraban un gran número de dioses). Los más venerados eran Júpiter, Minerva y Juno. En honor a ellos se construyeron templos y se ofrecieron sacrificios de animales. El emperador era adorado como un dios y en todo el Imperio se practicaba el culto imperial.

También veneraban, en casa, a los dioses protectores del hogar y de la familia; en cada casa había un altar dedicado a esos dioses. Además, los romanos eran muy supersticiosos y, antes de tomar una decisión consultaban la voluntad de los dioses, expresada por medio de los oráculos.

El calendario religioso romano reflejaba la hospitalidad de Roma ante los cultos y divinidades de los territorios conquistados. Originalmente eran pocas las festividades religiosas romanas. Algunas de las más antiguas sobrevivieron hasta el final del imperio pagano, preservando la memoria de la fertilidad y los ritos propiciatorios de un primitivo pueblo agrícola. A pesar de eso, se introdujeron nuevas fiestas que señalaron la asimilación de los nuevos dioses. Llegaron a incorporarse tantas fiestas que los días festivos eran más numerosos que los laborales. Las más importantes eran las fiestas lupercales, saturnales, equiria y de los juegos seculares.

Tiempo después, terminadas las persecuciones contra los cristianos, el cristianismo fue tolerado con el emperador Constantino. Según la leyenda, antes de la batalla de Puente Milvio vio una cruz en el cielo, bajo la cual una inscripción decía «bajo este símbolo vencerás». Al día siguiente grabó en los escudos de todos sus soldados la cruz y obtuvo una gran victoria, si bien solo se bautizó unos días antes de su muerte. Solo con el emperador Teodosio I el Grande el cristianismo se convirtió en religión oficial del Imperio.





</doc>
<doc id="1511" url="https://es.wikipedia.org/wiki?curid=1511" title="Protocolo de control de mensajes de Internet">
Protocolo de control de mensajes de Internet

El ICMP inicia después del IPv4 cabecera y se identifica con el protocolo número “1”. Todos los paquetes ICMP tendrán una cabecera de 8 bytes y la sección de datos de tamaño variable. Los primeros 4 bytes de la cabecera serán consistentes. El primer byte es reservado para el tipo de ICMP. El segundo octeto es para el código de ICMP. El tercer y cuarto byte es una suma de comprobación de todo el mensaje ICMP. El contenido de los restantes 4 bytes de la cabecera pueden variar dependiendo de la función del tipo y el código ICMP.

Los mensajes de error de este protocolo contienen una sección de datos que incluye todos los IP de cabecera más los 8 primeros bytes de los datos del paquete IP que ha causado el mensaje de error. El paquete ICMP es encapsulado en un nuevo paquete IP.

Bits 0-7 8-15 16-23 24-31


Un Echo Reply (Respuesta de Eco) en el protocolo ICMP es un mensaje generado como respuesta a un mensaje Echo Request (petición de Eco).

Formato del Mensaje:

Destination Unreachable es un tipo de paquete ICMP cuya función es transportar un mensaje que es generado por un enrutador, y se envía al host de origen, que recibe el mensaje emitido por el enrutador.

El mensaje en sí significa que este router considera inalcanzable el destino al que quiere llegar el host.

Si se recibe de parte del host de destino, significa que el protocolo que se intentó acceder no está activo en aquel momento.

El campo Type tiene el valor 3. El campo código contendrá alguno de los siguientes valores:

La Fuente Saciable: las peticiones que provienen del remitente disminuyen su velocidad sobre la base de los mensajes enviados a un host o router. Este mensaje se puede generar si un router o host esta deficiente en espacio de búfer para procesar esta solicitud, o puede ocurrir que el bufer del host o enrutador este llegando a su límite.

La información es enviada a una velocidad muy alta que parte de un anfitrión o de varios host al mismo tiempo hacia un enrutador en particular perteneciente a la red. Aunque un router tiene capacidades de almacenamiento en búfer, esta se limita dentro de un rango en específico. El enrutador no puede colocar más datos que se excedan de la capacidad de almacenamiento que provee el búfer. De esta forma, si la cola se llena, las informaciones se descartan hasta que la cola ya no este saturada. Pero como no hay mecanismos de confirmación está presente en la capa de red, el usuario no tiene conocimiento si la información ha llegado a su destino con éxito. De ahí algunas medidas correctivas deben ser tomadas por medio de la capa de red para prevenir estos tipos de situaciones. Estas medidas se refieren como fuente de amortiguación. En un mecanismo de enfriamiento fuente, el enrutador considera que la tasa de datos entrantes es más rápido que la velocidad de datos de salida, y envía un mensaje ICMP a los clientes, informándoles deben frenar su velocidad de transferencia de datos o esperar una cantidad de tiempo para enviar nuevamente datos. Al usuario recibir esta notificación automáticamente se desacelerara la velocidad de datos salientes o quedara en espera hasta que pase suficiente cantidad de tiempo lo que le permitirá al router vaciar la cola. Por lo tanto fuente saciar mensaje ICMP actos como el control de flujo en la capa de red.

Donde
Tipo debe establecerse en 4
Código debe establecerse en 0
Encabezado IP y los datos adicionales es utilizado por el emisor para que coincida con la respuesta a la solicitud correspondiente

"Redirect" solicita que los paquetes de datos se envíen en una ruta alternativa. ICMP Redirect es un mecanismo para enrutadores para transferir datos del router a los hosts. El mensaje informa al receptor (hosts) que actualice su información de enrutamiento. Si un anfitrión intenta enviar información a través del router 1 y el router 1 envía la información al router 2 y una ruta directa desde el host al router 2 está disponible (es decir, el anfitrión y el router 2 están en el mismo segmento de Ethernet), entonces el router 1 enviará una notificación de redirección para informar al host que el mejor trayecto para cumplir su destino es a través del router 2. Entonces el anfitrión debe enviar paquetes directamente al router 2. Y este intentará enviar el original datagrama al destino previsto. Sin embargo, si el datagrama contiene datos del enrutamiento, no se enviará esta notificación incluso si hay mejores caminos disponibles.

Donde:

El Echo Request (Petición eco) es un mensaje de control que se envía a un host con la expectativa de recibir de él un Echo Reply (Respuesta eco). Esto es conocido como Ping y es una utilidad del protocolo ICMP, subprotocolo de IP. Todo host debe responder a un Echo Request con un Echo Reply que contenga exactamente los mismos datos que el primero.

Formato del mensaje:


El Tiempo excedido se crea por una puerta de enlace para informar a la fuente de un datagrama debido al tiempo de vida de campo al llegar a cero. Un mensaje sobrepasando el tiempo también puede ser enviado por un host si no logra volver a montar una fragmentación de datagramas dentro de su límite de tiempo.

Los mensajes del tiempo excedido son utilizados por la Ruta de Seguimiento de utilidad para identificar las puertas de enlace en el cambio de los anfitriones.

Donde:
El IP cabecera y los primeros 64 bits de la carga original útil son utilizados por el host de origen para que coincida con el mensaje de tiempo excedido para el datagrama descartado. Para los protocolos de nivel superior, tales como UDP (Datagrama de Protocolo de Usuario) y TCP (Protocolo de Control de Transmisión) el bit de carga útil de 64 bits incluirá la fuente y puertos de destino del paquete descartado.

"Timestamp" Es usada para la sincronización de tiempo. Consiste en el origen del timestamp

Donde:

Respuesta a una timestamp del mensaje. Se compone de la timestamp originario enviado por el remitente del timestamp, así como una timestamp y así recibir una timestamp de la transmisión.

Donde:
Todos los timestamp son en unidades de milisegundos desde la medianoche UT. Si el tiempo no está disponible en milisegundos o no puede ser proporcionado con respecto a la medianoche UT entonces cualquier momento se puede insertar en una timestamp siempre y cuando que el bit de orden superior del timestamp también se establezca como indicador del valor estándar.

se envía normalmente por un host a un router con el fin de obtener una adecuada Máscara de Subred.
Los remitentes deben responder este mensaje con una Solicitud de Dirección de Máscara.

Donde:

ICMP Solicitud de Dirección de Máscara puede ser usada como parte de un proceso de reconocimiento para recabar información sobre la red de destino, por lo tanto, ICMP Solicitud de Dirección de Máscara está desactivando por defecto en Cisco IOS.
La Respuesta a la Dirección de Máscara se utiliza para responder a un mensaje de petición de dirección de máscara con una máscara de subred adecuada.
Donde:

El Destino Inalcanzable se genera por el host o en la puerta de enlace entrante para informar al cliente de que el destino es inalcanzable por alguna razón. Un mensaje de destino inalcanzable se puede generar como resultado de un TCP, UDP o ICMP u otra transmisión.Los Puertos TCP inalcanzables sobre todo responden con TCP RST en lugar de un tipo de destino inalcanzable 3 como era de esperar.

El error no se génera si el datagrama original tiene un IP Multicast de dirección de destino. Las razones para este mensaje pueden incluir: la conexión física con el host no existe (la distancia es infinita), el protocolo indicado o el puerto no está activo, los datos deben ser fragmentados pero el marcador "no fragmentar" está activo.

Donde:

Un mensaje ICMP se encapsula en IP:

ICMP se puede utilizar para transmitir diferentes tipos de mensajes de gestión, que se identifican principalmente por el tipo y el código correspondiente.

Lista de mensajes de control permitidos (incompleta):
(Fuente: IANA ICMP Parameters)



</doc>
<doc id="1512" url="https://es.wikipedia.org/wiki?curid=1512" title="II milenio">
II milenio

El segundo milenio comenzó el 1 de enero de 1001 d. C. y terminó el 31 de diciembre de 2000 d. C. Fue el milenio anterior y es el milenio en el que la sociedad humana más ha evolucionado desde que los primeros homínidos dejaron de ser nómadas.

Durante este milenio se producen las fechas más importantes de la historia universal: 1453, caída del Imperio Romano Oriental a los turcos; 1492, descubrimiento accidental de América por Cristóbal Colón, quien tenía la intención de llegar a las Indias; 1789, la Revolución Francesa que provocaría un drástico cambio democrático en la mayoría de países occidentales y 1945, el fin de la Segunda Guerra Mundial, el conflicto bélico más importante de la historia y que daría paso al sufragio universal, declaración de los derechos humanos y la creación de una comunidad mundial, entre otros. La Revolución Industrial de mediados del Siglo XVIII supuso un antes y después en la historia humana, iniciando una serie de enormes cambios tecnológicos, demográficos, sociales y filosóficos en todo el mundo. También fue de los principales catalizadores de la "Gran Divergencia", término que describe el ascenso cultural, político y tecnológico de Europa (""Occidente"") sobre el resto de civilizaciones, las cuales terminaron siendo todas en algún momento víctimas de algún tipo de colonización. Eventos como la Revolución científica (Siglo XVI) la aparición del Internet (1969) cambiaron radicalmente la forma de vida de los humanos con respectos a sus contrapartes de unos pocos siglos atrás.

En Europa, la primera mitad del milenio se caracterizó por el fin del feudalismo tras la devastadora Peste Negra y Crisis del Siglo XIV para dar paso a Estados más centralizados y de carácter absolutista. El fin de comercio con Oriente (caída de Constantinopla) y los diversos cambios sociales y económicos resultaron en la Era de los Descubrimientos y el auge de los primeros Imperios Coloniales en el Nuevo Mundo, periodo en el que la humanidad exploró por primera vez la totalidad del planeta. En Asia, destaca la expansión del Imperio Mongol y sus devastadores efectos en China y el Mundo Islámico.

En la segunda mitad del milenio se ampliaron significativamente los conocimientos en todos los campos científicos: la física gracias a Galileo, Copérnico, Newton o Einstein; la biología con Pasteur, Hooke o Darwin; la astronomía, gracias al ya mencionado Galileo, Kepler o Edmund Halley. Gracias a estos avances durante finales del milenio se consiguió que el hombre pisara por primera vez la Luna (1969), conocido también como "Revolución Espacial". También fue un periodo de revoluciones ideológicas tales como la Reforma Protestante (s. XVI) o la Ilustración (s. XVIII). Se dieron los primeros pasos de globalización y los conflictos bélicos fueron progresivamente aumentando de escala y magnitud, eventualmente culminando en Guerras Mundiales. La política mundial se verá dominada por Francia e Inglaterra (luego transformado en el Reino Unido), quienes se enfrentaron durante la mayor parte del milenio (desde la Conquista Normanda de 1066 hasta el Congreso de Viena de 1815).

Los últimos dos siglos del milenio fueron el periodo más transformadores de toda la historia humana. Se dio una Industrialización e Urbanización sin precedentes y se puso fin a los antiguos regímenes monárquicos que habían dominado a la mayoría de la humanidad desde hacía varios milenios para entrar a una nueva era de Liberalismo, Nacionalismo y Democracia en la mayoría del mundo. La Segunda Revolución Industrial trajo el mayor "boom" tecnológico de la historia, el cual se aceleró dramáticamente en el Siglo XX. En dicho siglo, solo se necesitaron 66 años para pasar del primer vuelo en avión (1903) a la llegada a la Luna (1969). Por último se dio la Globalización, gracias a la cual gran parte de la humanidad quedó conectada entre sí de una forma nunca antes vista.





</doc>
<doc id="1515" url="https://es.wikipedia.org/wiki?curid=1515" title="Incunable">
Incunable

Un incunable (del latín "incunabulae", en la cuna) es todo libro impreso durante el siglo XV. Concretamente, antes del día de Pascua de 1501, pues en esa época se hacía comenzar el año en este día. Fue posiblemente Cornelius Beughem quien empleó la palabra por primera vez, en su "Incunabula typographiae" (1688). Previamente se atribuye dicho término a Bernhard von Mallinckrodt quien llamaría a esta época “typographicae incunabula” en 1640 en su obra "De ortu et progressu artis typographica".

En este período la industria tipográfica todavía no se había especializado: el impresor era dueño y manipulador de la prensa, fundidor de tipos, fabricante del papel, encuadernador, editor, librero, artesano, artista y erudito. Algunos de ellos dejaban una «marca de agua» o filigrana en el papel que fabricaban, de esa manera sabemos quién la editó; pero hay muchos que carecían de firma y fecha. Hoy en día, estudios científicos que analizan los tipos de fundición utilizados, han ayudado a catalogar la mayoría de las ediciones existentes. Estas ediciones son documentos históricos que, por primera vez, pusieron la cultura al alcance de todos.

El término «incunable» hace referencia a la época en que los libros se hallaban «en su cuna», es decir en la primera «infancia» de la técnica moderna de hacer libros a través de la imprenta. Así, son reconocidos como incunables los libros impresos entre 1453 (fecha de la invención de la imprenta moderna) y 1500, procedentes de unas 1200 imprentas, distribuidas entre 260 ciudades, con un lanzamiento aproximado de 35 000 obras distintas. 

A Johannes Gutenberg, de Maguncia, se le atribuye la invención de los caracteres móviles fundidos. Los primeros incunables salieron de su imprenta, y entre ellos destaca la "Biblia de Gutenberg" (1453-55), en latín, de 42 líneas. Durante los primeros treinta años, la imprenta se expandió por Europa occidental y comenzó a dividirse en diferentes actividades especializadas. Al principio, los libros no tenían portada con caracteres en letra gótica y las palabras tenían numerosas abreviaturas, imitando a los códices. Pero ya en el mismo siglo fueron adoptándose otros tipos de letras, especialmente la redonda o romana, la veneciana o itálica y la cursiva, mucho más legibles que las primeras y que al fin prevalecieron sobre estas (salvo en Alemania) desde comienzos del siglo siguiente. Hacia finales del siglo XVI, se introdujo el tipo "elzeviriano" (del neerlandés Elzevir) más delgado que los anteriores y después siguieron otros caracteres de fantasía, hasta llegar a la gran variedad que hoy conocemos.

Antes de los tipos metálicos móviles, se usaban planchas de madera fija, que dieron lugar a los "incunables xilográficos", entre los que destaca la "Biblia Pauperum" o "Biblia de los pobres". Como se indica arriba, un incunable (del lat. "incunabulum", cuna) es todo libro impreso de caracteres móviles, desde los orígenes del arte tipográfico hasta el año 1500 inclusive (31 de diciembre de 1500). El término latino aplicado a una categoría de libros, fue empleado primeramente por el librero holandés Cornelio van Beughem en el repertorio que tituló "Incunabula typographiae" (Ámsterdam, 1688),

El primer libro español impreso que se conserva es el Sinodal de Aguilafuente, impreso por Juan Párix de Heidelberg (Johannes Parix) en 1472, que contiene actas de una reunión celebrada en Aguilafuente, Segovia. Incunables españoles de gran valor son la Biblia (impresa en valenciano en Valencia en 1478), Los doce trabajos de Hércules (originalmente escrita en valenciano, con el título "Los dotze treballs de Hèrcules") de Enrique de Villena (Zamora, 1483), Tirante el Blanco (originalmente escrita en valenciano, con el título "Tirant lo Blanch") de Joanot Martorell (Valencia, 1490), Gramática de la lengua castellana de Antonio de Nebrija (Salamanca, 1492) y la primera edición de La Celestina de Fernando de Rojas, atribuido a Fadrique de Basilea en 1499, afamado impresor que trabajó en Burgos durante treinta años y que dejó tras de sí una importante estirpe de impresores en la ciudad.

Entre las ediciones más importantes de incunables, se encuentran las de Gutenberg, Nicolas Jensen, William Caxton y Aldo Manuzio.

Para conocer los incunables principalmente aquellos que no tienen fecha, hay que fijarse en otras particularidades que los distinguen: 

El catálogo más importante de incunables es posiblemente el "Gesamtkatalog der Wiegendrucke", iniciado en 1925.

Las mayores colecciones del mundo, con el número aproximado de incunables que poseen, están custodiadas en:
La siguiente es una lista de instituciones latinoamericanas que cuentan con colecciones de 'incunables universales', es decir, impresos realizados entre 1450 y 1500. No se incluye en la lista los postincunables (1501-ca. 1530) o los llamados popularmente 'incunables latinoamericanos', es decir, los primeros impresos realizados en el continente americano, que siempre serían posteriores a 1501.




</doc>
<doc id="1516" url="https://es.wikipedia.org/wiki?curid=1516" title="Instrumento de viento">
Instrumento de viento

Los aerófonos de metal producen un sonido de timbre fuerte. En este caso, el músico hace vibrar sus labios en una boquilla que genera la frecuencia acústica. Entre los aerófonos de metal podemos nombrar a la trompeta, la tuba y el trombón, entre otros.

Los instrumentos de viento son aquellos que emiten sonidos al exhalar aire de forma conveniente.

Los instrumentos de viento se pueden clasificar en dos categorías. Estas categorías se dividen atendiendo al material con el que se produce el timbre:


Los instrumentos de viento o tubos sonoros pueden clasificarse en función de tres criterios distintos:

Los tubos pueden ser cónicos, cilíndricos o prismáticos:
Prismáticos: instrumentos primitivos y algunos tubos de órgano.

Los tubos se clasifican en tubos de embocadura, de lengüeta (simple o doble) y de boquilla:


</doc>
<doc id="1521" url="https://es.wikipedia.org/wiki?curid=1521" title="Iglesia (organización)">
Iglesia (organización)

Una iglesia refiere tanto a una comunidad local como a una institución religiosa que agrupa a cristianos de una misma . En sociología, este término designa a un grupo religioso institucionalizado y con vocación universalista.

La palabra "iglesia" proviene de la voz griega ἐκκλησία (transliterado como "ekklēsía") vía el latín "ecclesia".

El sustantivo posee una doble herencia de significado en la Biblia:

Así, Iglesia en algunos pasajes del Nuevo Testamento podría combinar ambas ideas (la hebrea y la griega) o solo una de ellas, dando por eso profundo y complejo significado a las palabras de Jesús de Nazaret a Simón Pedro recogidas en el Evangelio según san Mateo:

Por otro lado, otros orígenes etimológicos de Iglesia se observan en idiomas distintos al castellano. Mientras que en las lenguas romances "iglesia" deviene del griego "ekklēsía", como ya se ha visto, en las lenguas germánicas (alemán "kirche", inglés "church"), procede del griego popular bizantino ("kyrikē"), que puede significar algo ‘referente al Señor ("kyrios")’; no obstante, no existe unanimidad al respecto.

En algunos pasajes de la Biblia su uso en singular hace referencia a una congregación local y específica, como es el caso del relato en "Hechos de los apóstoles" con respecto a la Iglesia de Jerusalén:
Pero en otros pasajes Pablo de Tarso parece utilizar el vocablo para referirse a un conjunto de congregaciones:
Con todo, los estudiosos concuerdan en que las Sagradas Escrituras hacen poca distinción entre el singular y el plural, por eso, del mismo modo, Iglesia puede hacer referencia a una reunión de creyentes en un hogar, como es el caso de la mencionada en la Epístola a los romanos:
Como asimismo a una reunión de creyentes en una sola ciudad, como los destinatarios de la Primera epístola de san Pablo a los corintios
O a la reunión de creyentes de una provincia, como se refiere San Pablo a las iglesias de Asia en su Primera epístola a los tesalonicenses:
En otros pasajes de la Biblia, particularmente en las epístolas paulinas, se utiliza la palabra Iglesia para designar aquello que los cristianos han definido a lo largo de su historia como "cuerpo místico de Cristo" o, toda la "comunidad universal de los creyentes".

Así ocurre, por ejemplo, en la Epístola a los Efesios donde Pablo de Tarso explica el "eterno propósito redentor de Dios" realizado en una Iglesia en la que participan tanto judíos como no judíos, personas de todas las naciones, tanto esclavos como hombres libres, etc. Un verso de la Epístola a los colosenses deja muy clara esta idea, una Iglesia…
La Iglesia católica es la Iglesia cristiana más numerosa. Está compuesta por 24 Iglesias "sui iuris": la Iglesia latina y 23 Iglesias orientales, que se encuentran en completa comunión con el papa y que en conjunto reúnen a más de 1329 millones de fieles en el mundo.

La Iglesia católica sostiene que en ella subsiste la única Iglesia fundada por Cristo, encomendada por él al apóstol Pedro, a quien le confió su difusión y gobierno junto con los demás apóstoles. Por ello, se considera a sí misma como un «sacramento», un «signo e instrumento de la unión íntima con Dios y de la unidad de todo el género humano».

En el Cristianismo ortodoxo, la Iglesia ortodoxa reúne a las Iglesias autocefalías que eligen a sus propios primados. Debido a su influencia o su importancia histórica, una Iglesia autocéfala puede llevar el título de patriarcado o de arzobispado y, por lo tanto, ser dirigida por un patriarca o un arzobispo. Las iglesias autónomas tienen un arzobispo.

En el Protestantismo, la Iglesia universal está representada por las iglesias locales, parroquias y sínodos, afiliados a las iglesias nacionales y a las organizaciones internacionales, es decir, entre los principales, la Comunión Anglicana, la Federación Luterana Mundial, la Comunión Mundial de Iglesias Reformadas. La gestión de la Iglesia está asegurada por los ministerios que son principalmente los pastor, diácono, chantre y evangelista. 

En el Cristianismo evangélico, la Iglesia evangélica local es la organización que representa la Iglesia universal y es vista por los evangélicos como el cuerpo de Jesucristo. Ella es responsable de la enseñanza y las ordenanzas, a saber, el bautismo del creyente y la comunión. Muchas iglesias están miembros de denominaciones cristianas evangélicas y se adhieren a una confesión de fe común y a las regulaciones. Algunas denominaciones son miembros de una alianza nacional de la Alianza Evangélica Mundial. La gestión de la Iglesia está asegurada por los ministerios evangélicos que son principalmente los diácono, líder de alabanza, evangelista y pastor. El ministerio de obispo con una función de supervisión sobre las iglesias a escala regional o nacional está presente en todos los denominaciones cristianas evangélicas, incluso si los títulos de presidente del consejo o supervisor general se utilizan principalmente para esta función. 




</doc>
<doc id="1525" url="https://es.wikipedia.org/wiki?curid=1525" title="Isla del Príncipe Eduardo">
Isla del Príncipe Eduardo

Isla del Príncipe Eduardo (nombre oficial en inglés: "Prince Edward Island;" en francés: "Île-du-Prince-Édouard"), comúnmente abreviada PEI, es una de las diez provincias que, junto con los tres territorios, conforman las trece entidades federales de Canadá. Su capital y ciudad más poblada es Charlottetown. Ubicada al este del país, es una isla rodeada por el océano Atlántico y separada de Nuevo Brunswick por el estrecho de Northumberland. Con 139 407 habs. en 2008 es la cuarta entidad menos poblada —por delante de Territorios del Noroeste, Yukón y Nunavut, la menos poblada—, con 5660 km², la menos extensa, y con 24,6 hab/km², la más densamente poblada. 

Su capital, Charlottetown, es conocida como la cuna de la Confederación Canadiense, aunque la provincia no se asoció a la Confederación hasta más tarde. En 1997 fue unida al continente americano por el puente de la Confederación.

La isla estuvo habitada por primera vez hace unos . Estos pioneros habrían llegado por un istmo hoy cubierto por el estrecho de Northumberland. Parece que la isla estaba habitada constantemente y que la caza y la pesca dieron lugar a migraciones estacionales. Los nativos americanos "micmac", que la llamaban "Abegweit", llegaron a la isla hace unos .

En 1534, Jacques Cartier fue el primer explorador europeo en anunciar la existencia de la isla, que describió como «la tierra más hermosa que uno pueda imaginar». A partir de entonces, los pescadores franceses y vascos frecuentaron la isla durante casi 200 años, pero no se establecieron en ella de forma permanente. No quedan rastros de su presencia.

Nicolas Denys obtiene la concesión de la isla, llamada Isla Saint-Jean en ese momento, alrededor de 1653, pero solo se ocupa de la pesca y no deóa ningún establecimiento tras él en la isla. Francia no la colonizó hasta después de los Tratados de Utrecht (1713). En 1719, se hizo una nueva concesión de la isla y de la de Miscou a un conde llamado Saint-Pierre, que envió un grupo de colonos al año siguiente. Un censo en 1735 da un total de 81 familias asentadas en la isla. La colonia dependía de Île Royale (Cap-Breton).

Posteriormente, pasó a formar parte de Acadia, una colonia francesa. Como tal, la isla era llamada "Île Saint-Jean" (Isla San Juan). Aproximadamente mil acadianos fueron deportados en 1758, cuando los británicos la conquistaron, durante la guerra franco-indígena.

La nueva colonia de "St. John's Islands" quedó prácticamente desierta tras el fin de las hostilidades, salvo por la presencia de un fuerte inglés. Con el fin de atraer personas a la región al menor costo posible, el Capitán Samuel Holland, del tesoro real de Inglaterra, propuso al "Departamento de Comercio y Agricultura" que se llevase a cabo en la región una expedición científica, a fin de alentar el asentamiento y la actividad pesquera, tanto en la isla como en el resto de las colonias británicas en América del Norte, y especialmente en los territorios recién conquistados a Francia (Acadia y Nueva Francia).

La exploración se llevó a cabo entre 1764 y 1766, y durante este tiempo se fundaron tres condados, cada uno de aproximadamente dos mil km². Cada condado fue subdividido en cinco partidos, de 400 km² cada uno. Cada condado tenía su cabecera, mientras que el resto del territorio fue dividido en 67 lotes diferentes, cada uno con aproximadamente 80 km². Posteriormente, se subastaron entre la nobleza británica. 

Los nuevos propietarios de los lotes deberían reclutar a su vez nuevos contratistas, así como financiar el traslado de estos desde Inglaterra (o desde cualquier colonia de esta) hasta la Isla. A su vez, estos tendrían la obligación de trabajar en la los trabajos forestales en la región y, asimismo, pagar una tasa anual a sus señores.

En 1798, Gran Bretaña cambió el nombre de la colonia de Isla San Juan a Isla del Príncipe Eduardo, para distinguirla de otras posesiones suyas en el Canadá Atlántico, como les ciudades Saint John (Nuevo Brunswick) y St. John's (Terra Nova). El nuevo nombre de la colonia homenajeaba el príncipe Eduardo, Duque de Kent, el cuarto hijo del Rey Jorge III del Reino Unido. Eduardo por entonces comandaba las tropas británicas en Halifax.

Durante la década de 1840, los habitantes de la Isla del Príncipe Eduardo comenzaron a exigir una mayor autonomía política. El Reino Unido cedió a la presión en 1851, dando a la Isla total control sobre el gobierno, en asuntos internos.

En septiembre de 1864, la Isla del Príncipe Eduardo fue sede de la Conferencia de Charlottetown, que fue el primero de una serie de encuentros que llevaron a la creación de los "Artículos de la Confederación de Canadá", en 1864 - firmada por Ontario, Quebec, Nuevo Brunswick y Nueva Escocia. Sin embargo, la Isla del Príncipe Eduardo, junto con Terranova y Labrador, no estuvieron de acuerdo con los términos de la Confederación y se negaron a entrar en ella. A fines de la década de 1860, aún como colonia británica, políticos de la Isla del Príncipe Eduardo barajaban varias posibilidades: volverse independientes, unirse a Canadá o a los Estados Unidos, o continuar siendo una colonia inglesa. Finalmente, la Isla decidiría unirse a Canadá en 1873.

A principios de la década de 1870, la Isla del Príncipe Eduardo inició la construcción de un ferrocarril, pero rápidamente comenzó a endeudarse. No queriendo responsabilizarse por el pago de la deuda contraída, Inglaterra presionó a su colonia para que nuevamente entablase negociaciones con la Confederación Canadiense. En 1873, el entonces primer ministro de Canadá, John Alexander Macdonald, intentando detener a cualquier precio el peligro que representaba el expansionismo norteamericano, propuso como solución al problema los siguientes términos: Canadá pagaría las deudas contraídas por la Isla del Príncipe Eduardo, compraría todos los lotes que restasen en ella y, también, proporcionaría transporte adecuado entre la isla y el continente; pero ésta, a cambio, tendría que unirse a la Confederación. De este modo, la Colonia aceptó los términos y entró a formar parte de la Confederación Canadiense el 1 de julio de 1873.

Durante las primeras décadas como provincia canadiense, la población de la isla creció gradualmente. Sin embargo, se hizo claro que los establecimientos industriales y comerciales de la provincia no estaban en condiciones de competir con los productos más baratos producidos en las otras provincias de Canadá (principalmente en Ontario y Quebec). La agricultura y la pesca eran las principales fuentes de ingreso de la provincia, pero ni siquiera estos dos sectores podían competir con la industria pesquera de Nuevo Brunswick o de Nueva Escocia, o contra la industria agropecuaria del interior canadiense. 

La provincia se hizo cada vez más dependiente de la ayuda financiera del gobierno canadiense, y su población comenzó a decaer gradualmente en número a partir de la década de 1890. Durante las décadas de 1920 y 1930, la provincia tuvo que gastar más en educación, salud pública y asistencia social y financiera, lo que, a pesar de haber frenado el descenso poblacional de la Isla, aumentó sus problemas financieros. La Gran Depresión de los años 30 solamente vino a agravar la situación financiera de la provincia en su conjunto, que había sido hasta entonces solo precaria, durante las primeras décadas del siglo XX - con excepción de un breve período, durante los años de la Primera Guerra Mundial.

La Isla del Príncipe Eduardo recibió mayor ayuda financiera del gobierno canadiense a partir del inicio de la década de 1940. Esto, aunado a la Segunda Guerra Mundial, generó que diversos servicios públicos, tales como transportes y educación, fuesen drásticamente mejorados; así como que hubiese una recuperación de la industria agraria. Con esto, la Isla del Príncipe Eduardo registró su primer período de crecimiento poblacional, desde el censo nacional de 1891. Desde el inicio de la década de 1940, la población de la provincia ha solamente crecido, aunque muy lentamente, siendo así que fue apenas, durante el inicio de la década de 1970, que la población de la Isla del Príncipe Eduardo superó la que tenía la provincia en 1891.

El gobierno de la Isla del Príncipe Eduardo, en coordinación con el gobierno canadiense, invirtió aún más en educación y en transportes. Para entonces, el turismo ya se había convertido en una de las principales fuentes de ingreso. Además, en 1969, la provincia intentó revitalizar su economía a través de diversos actos, los cuales fracasaron en su objetivo; así que el gobierno de la Isla del Príncipe Eduardo volvió, durante la década de 1980, a dar mayor atención a sus principales sectores económicos: la agricultura, la pesca y a un fuerte turismo en crecimiento. En 1997, el Puente de la Confederación fue inaugurado, ofreciendo a la provincia una conexión directa con el resto del continente e incentivando así el turismo. Esto ayudó a colocar el turismo en la segunda posición como fuente de ingreso de la provincia, atrás solamente de la agricultura.

La isla se conoce como el Jardín del Golfo, ya que la isla se encuentra en el golfo de San Lorenzo, al oeste de la Isla de Cabo Bretón, al norte de la península de Nueva Escocia, y al este de Nuevo Brunswick. Las costas del sur forman el Estrecho de Northumberland. La isla cuenta con dos zonas urbanas. La más grande se centra en el puerto de Charlottetown, ubicada en medio de la costa del sur; consiste en la capital, Charlottetown, varias comunidades residenciales como Cornwall y Stratford, y una franja cada vez más ancha de urbanizaciones y desarrollo urbano. Otra zona urbana se centra en el puerto de Summerside, ubicada en la costa del sur 40 km (25 mi) al oeste del puerto de Charlottetown; consiste ante todo en la ciudad de Summerside. Estos puertos, como todos los puertos naturales de la isla, son creados por rías.

La Isla del Príncipe Eduardo, debido a su localización (rodeada por grandes cuerpos de agua) posee un clima más estable y ameno que el resto del país, registrando las temperaturas más altas de Canadá durante el invierno y las más bajas durante el verano. Por lo cual, el tiempo con el que cuenta la provincia también es muy estable, con condiciones climáticas que poco varían durante un día dado.

Por otra parte, su pequeño tamaño hace que el clima sea en gran medida homogéneo en toda la provincia. La región oeste de la isla posee temperaturas levemente más bajas durante el invierno y más altas en el verano, en relación con la región este, debido a su mayor proximidad con el cuerpo principal del continente.

Durante el invierno, la Isla del Príncipe Eduardo posee una temperatura media de -7°C. La media de las mínimas es de -12 °C y la media de las máximas, de -3 °C. La temperatura más baja que se haya registrado en la provincia es de -37 °C, ocurrida en Alberton, el 26 de enero de 1884. Durante el verano, posee una temperatura media de 19 °C. La media de las mínimas es de 13 °C y la media de las máximas, de 22 °C. Y, a su vez, la temperatura más alta que se haya registrado en la provincia es de 37 °C, ocurrida en Charlottetown, el 19 de agosto de 1935. Su tasa de precipitación media anual de lluvia es de 111 centímetros, mientras que la de nieve es de 276 centímetros.

Históricamente, el Partido Liberal de Canadá ha dominado la política de la Isla del Príncipe Eduardo. Más de la mitad de los gobernadores de la provincia han sido liberales y, consecuentemente, más de la mitad de los gobiernos provinciales han sido dominados por una Asamblea compuesta por una mayoría liberal. Los liberales ocupan actualmente los cuatro escaños que a la provincia le corresponden en la Cámara de los Comunes.

Cuando entró a la Confederación, la representación parlamentaria de la provincia era de seis escaños en la Cámara de los Comunes y de cuatro en el Senado. Sin embargo, a medida que el tiempo fue pasando, la población de la provincia no creció proporcionalmente en relación al crecimiento de la del resto del país - especialmente la del oeste de Canadá -, por lo cual disminuyó el número de representantes en la Cámara de los Comunes a cuatro.

La gran mayoría de las localidades de la provincia son administradas por un alcalde y por un consejo municipal. Cerca del 60% de los ingresos que percibe el gobierno de la provincia son por concepto de impuestos. El resto proviene de los ingresos recibidos del gobierno federal y de empréstitos.

El teniente-gobernador representa a la Reina Isabel II como jefe de la Isla del Príncipe Eduardo. El jefe del gobierno en práctica, y también el mayor oficial del poder ejecutivo de la provincia, es el "premier," o primer ministro. El premier es quien encabeza el partido político con más escaños en la Asamblea Legislativa; preside un Consejo Ejecutivo, que es el gabinete de la provincia. Hay unos 25 diferentes ministros en el gabinete, como el Ministro de Educación, el Ministro de Economía, el Ministro de Trabajo, etc. Los ministros renuncian sus posiciones si el gabinete pierde el apoyo de la mayoría de los miembros del parlamento.

El Poder Legislativo de la Isla del Príncipe Eduardo es la Asamblea Legislativa, la cual está compuesta por 27 miembros. Cada uno de ellos es elegido por la población de uno de los 27 distritos electorales de la provincia, para mandatos de hasta cuatro años de duración. Si el Teniente-Gobernador disolviere la Asamblea antes de estos cinco años, a petición del gobernador, se convocará a nuevas elecciones. No hay límite de términos que una persona puede ejercer.

La corte más alta es la Corte Suprema de la Isla del Príncipe Eduardo, compuesta por nueve jueces. Estos jueces son nombrados por el primer ministro de la provincia y aprobada simbólicamente por el teniente-gobernador. Una vez escogidos, los jueces de la corte pueden ejercer sus oficios hasta los 75 años de edad.
Según el censo nacional canadiense de 2006, la población de la Isla del Príncipe Eduardo era de 138 519 habitantes, un crecimiento de 2,4% sobre la población de la provincia en relación a 2001, que era estimada en 135 294 habitantes.

Entre las diez provincias de Canadá, la Isla del Príncipe Eduardo es la provincia de población más densa. Hay sin embargo 32 ciudades canadienses con más habitantes que la Isla del Príncipe Eduardo. Según el censo canadiense de 2001, el mayor grupo étnico de la provincia son los escoceses (38,0%), seguidos por los ingleses (28,7%), irlandeses (27,9%), franceses (2,3%), alemanes (4,0%), y holandeses (3,1%). Casi la mitad de los respondientes se identificaron sencillamente como "canadienses."
Composición racial de la población de la Isla del Príncipe Eduardo:


La provincia está dividida en 3 condados:

La Isla del Príncipe Eduardo posee apenas dos ciudades primarias ("cities"): Charlottetown y Summerside. La provincia también tiene otras siete ciudades secundarias ("towns"): Stratford, Cornwall, Montague, Kensington, Souris, Alberton y Georgetown.

10 mayores municipalidades de la provincia

La economía de la Isla del Príncipe Eduardo está basada principalmente en la agricultura, el turismo y la pesca. Todas estas actividades tienen grandes variaciones a lo largo del año y son susceptibles a impactos externos como, por ejemplo, desastres naturales y depresiones económicas. Esta provincia es extremamente pobre en recursos naturales, como minerales, no obstante, existen cantidades todavía no determinadas de gas natural en su parte oriental.

La agricultura es la mayor fuente de ingreso de la economía de la provincia desde que esta fue colonizada por los ingleses - actualmente, la papa es el vegetal más cultivado en la provincia. La Isla del Príncipe Eduardo es el mayor productor de patatas de Canadá - es responsable por un tercio de la producción anual canadiense. Cerca de 1,3 billones de kilos de patatas son producidas anualmente en la provincia, que es también gran productora de semillas de patatas, que son exportadas a más de 20 países alrededor del mundo.

El turismo es la segunda mayor fuente de ingreso de la Isla del Príncipe Eduardo, habiendo superado en importancia a la pesca a mediados del siglo XX. Las principales atracciones turísticas son sus playas, pistas de golf y las atracciones y eventos locales. La estación más dinámica es el verano - meses de julio y agosto - pese a un crecimiento del número de turistas norteamericanos en septiembre y en octubre en la provincia (así como en Nuevo Brunswick y Nueva Escocia se está prolongando la estación turística hasta los meses de invierno.

La pesca todavía es la tercera mayor fuente de ingreso de la Isla del Príncipe Eduardo; sin embargo, la provincia es menos dependiente de la industria pesquera de lo que lo son otras provincias canadienses localizadas en costa la costa atlántica (Nuevo Brunswick, Nueva Escocia, Terranova y Labrador). La captura de langostas es la mayor actividad pesquera de la isla, la cual se efectúa en mayo y en septiembre. Por el hecho de que la provincia queda cubierta de hielo oceánico durante los meses de invierno, la pesca está limitada a los meses de verano, al final de la primavera y al inicio del otoño.

El Producto Interno Bruto de la provincia es de más de 2,8 billones de dólares canadienses por año. El sector primario aporta el 5% del PIB de la Isla del Príncipe Eduardo. La agricultura y la ganadería representan juntas el 5% del PIB de la provincia, y emplea aproximadamente 4,6 mil personas. La Isla del Príncipe Eduardo posee cerca de 2 mil tierras de cultivo, que cubren aproximadamente la mitad de la provincia. Apenas Saskatchewan posee un mayor porcentaje de su extensión territorial cubierta por tierras de cultivo. La pesca representa el 4% del PIB de la provincia y emplea aproximadamente 2 mil personas. La silvicultura representa el 1% del PIB de la provincia, empleando cerca de 700 personas.

El sector secundario representa el 16% del PIB de la Isla del Príncipe Eduardo. El valor total de los productos fabricados en la provincia es de 275 millones de dólares canadienses. Los principales productos industriales fabricados en la provincia son principalmente alimentos industrializados, en parte asociado a la industria pesquera de la provincia. La industria manufacturera representa el 10% del PIB de la Isla del Príncipe Eduardo y emplea aproximadamente 6,5 mil personas. La industria de construcción representa el 5% del PIB de la provincia y emplea cerca de 3,8 mil personas. Es despreciable el aporte económico de la explotación minera de la provincia. El único recurso natural presente en la provincia de uso importante para el hombre son las pequeñas reservas de gas natural.

El sector terciario representa el 76% del PIB de la Isla del Príncipe Eduardo. Servicios personales y comunitarios representan el 25% del PIB de la provincia y emplea cerca de 24,1 mil personas. Servicios financieros e inmobiliarios emplean aproximadamente 2,2 mil personas y representa más de 20% del PIB de la Isla del Príncipe Eduardo. Servicios gubernamentales representan el 13% del PIB de la provincia, empleando aproximadamente 5,6 mil personas. El comercio por mayoreo y menudeo representa el 11% del PIB de la provincia y emplea aproximadamente 9,9 mil personas. Transportes y telecomunicaciones representan el 7% del PIB y emplean cerca de 5 mil personas, y las utilidades públicas representan el 1% del PIB de la provincia, empleando cerca de 100 personas. La provincia genera apenas el 40% de la electricidad que consume, 5% en plantas termoeléctricas de carbón, y 35%, en plantas eólicas. El otro 60% necesita ser comprados de Nuevo Brunswick.

En 1999, se registraron cerca de 24200 estudiantes en las escuelas públicas de la Isla, y unos 1400 profesores. Por otro lado las escuelas privadas atendieron a cerca de 250 estudiantes, empleando aproximadamente a 10 profesores. El sistema de escuelas públicas de la provincia consumió cerca de 143 millones de dólares canadienses, y el gasto de las escuelas públicas por estudiante es de aproximadamente 5,8 mil dólares canadienses.

La Isla del Príncipe Eduardo cuenta con 20 bibliotecas públicas administradas por la provincia. Hay una sola universidad, la Universidad de la Isla del Príncipe Eduardo, en Charlottetown. También hay un sistema de colegios comunitarios, Holland College, con facultades especializadas en varias ciudades. 

Las primeras escuelas de la Isla del Príncipe Eduardo fueron construidas a inicios del siglo XIX. En 1852, el gobierno colonial de la provincia creó un sistema de escuelas públicas e instituyó un impuesto para costear tal sistema. En 1877, la provincia instituyó el Consejo Central de Educación y, en 1945, el Departamento de Educación de la Isla del Príncipe Eduardo.

Actualmente, el Departamento de Educación de la Isla del Príncipe Eduardo dicta las reglas y patrones que todas las instituciones educacionales en la provincia tienen que seguir. Todas las escuelas son directamente administradas por el Departamento de Educación. La atención escolar compete a todos los niños y adolescentes con más de seis años de edad, hasta la graduación de la segundo grado o hasta los veinte años de edad.

La primera biblioteca pública de la Isla del Príncipe Eduardo fue fundada en 1933. Actualmente, las 20 bibliotecas públicas de la provincia son administradas por el Departamento de Educación de la provincia. La Isla del Príncipe Eduardo cuenta con una universidad, la Universidad de la Isla del Príncipe Eduardo, y una facultad, ambas administradas por el Departamento de Educación de la provincia.

En 1997, el Puente de la Confederación fue inaugurado, conectando la Isla del Príncipe Eduardo con Nuevo Brunswick, así reemplazando al servicio del "ferry" entre ambas provincias. 
Hasta hace poco tiempo, el transporte de pasajeros y, principalmente, de carga, hacia dentro y fuera de la provincia, era relativamente caro y demorada 45 minutos, vía "ferry", y esto no contando el horario de atención (servicio restringido por las noches, por ejemplo) o el tiempo de espera entre la salida de un "ferry" y la llegada de otro. Estas embarcaciones conectaban la Isla del Príncipe Eduardo con Nueva Escocia, Nuevo Brunswick y las Islas de la Magdalena.

En 1997, el Puente de la Confederación fue inaugurado, conectando la Isla del Príncipe Eduardo con Nuevo Brunswick, y, así, substituyó el servicio de "ferry" entre ambas provincias, el cual fue descontinuado; mientras que los que había con Nueva Escocia y las Islas de la Magdalena continúan hasta el día de hoy. Actualmente, la provincia posee 4,9 mil kilómetros de vías públicas. Una curiosidad es el hecho de que, hasta el 1 de mayo de 1924, los vehículos transitaban a la izquierda de cualquier vía pública, a diferencia del resto de Canadá, donde lo hacían a la derecha.

Cuando fue inaugurado el Ferrocarril de la Isla del Príncipe Eduardo, en 1873, era un ferrocarril de trocha angosta. Fue convertido en trocha patrón o estándar en 1930. Anteriormente, en 1915, este ferrocarril había pasado al control de "Ferrocarriles Gubernamentales Canadienses", un órgano público federal, que se convirtió en "Ferrocarriles Nacionales Canadienses" (FNC) en 1918. En 1989, FNC decidió abrir mano de sus líneas en la provincia. Actualmente, la Isla del Príncipe Eduardo es la única provincia canadiense sin servicio ferroviario de transporte de carga o de pasajeros. El antiguo ferrocarril que tenía es actualmente un ferrocarril turístico.

El primer periódico publicado en la Isla del Príncipe Eduardo fue el "Journal-Pionner", publicado en 1867, en Summerside. En 1887, la primera edición del "The Guardian" fue publicada en Charlottetown. Estos son publicados hasta el día de hoy, siendo los dos únicos periódicos de circulación diaria de la provincia. La primera estación de radio de la provincia fue fundada en 1924, en Charlottetown. Actualmente, la provincia posee 8 estaciones de radio. Ninguna estación de televisión ha sido fundada todavía en la Isla del Príncipe Eduardo, dependiendo únicamente de las estaciones de radio localizadas en las provincias vecinas de Nuevo Brunswick y Nueva Escocia.
La novela "Ana la de Tejas Verdes" (1908) de Lucy Maud Montgomery está ambientada en esta isla.




</doc>
<doc id="1526" url="https://es.wikipedia.org/wiki?curid=1526" title="Instrumento de percusión">
Instrumento de percusión

Un instrumento de percusión es un tipo de instrumento musical cuyo sonido se origina al ser golpeado o agitado. Es la forma más antigua de instrumento musical.

La percusión se distingue por la variedad de timbres que es capaz de producir y por su facilidad de adaptación con otros instrumentos musicales. Cabe destacar que puede obtenerse una gran variedad de sonidos según las baquetas o mazos que se usan para golpear algunos de los instrumentos de percusión.

Un instrumento de percusión puede ser usado para crear patrones de ritmos (batería, tam-tam entre otros) o bien para emitir notas musicales (xilófono).
Suele acompañar a otros con el fin de crear y mantener el ritmo. Algunos de los instrumentos de percusión más famosos son el redoblante (tambor) y la batería.

Ejemplos:

El bombo, las maracas, las campanas, tubulares,etc.

Los instrumentos de percusión pueden clasificarse en dos categorías según la afinación: 

Entre ellos están: el bombo, la caja, el cajón, el afuche, las castañuelas, las claves, el cencerro, el címbalo, el güiro, la matraca, la zambomba, el vibraslap, la quijada, la batería, la tuntaina o victoria

En las orquestas se suele diferenciar entre:

Según otro criterio, se pueden clasificar en cuatro categorías que son:

Esta clasificación tampoco es estricta, por ejemplo, la pandereta es un membranófono y un idiófono porque tiene ambos, en la piel y en los cascabeles.


 y percusionista.


</doc>
<doc id="1528" url="https://es.wikipedia.org/wiki?curid=1528" title="Iron Maiden">
Iron Maiden

Iron Maiden es una banda británica de "heavy metal" fundada en 1975 por el bajista Steve Harris. Es considerada una de las bandas más importantes de todos los tiempos en este género. Ha vendido más de 100 millones de discos en todo el mundo, a pesar de haber contado con poco apoyo de la radio y la televisión comercial durante la mayor parte de su carrera. Sin embargo, la banda basó su éxito en llegar directamente a los aficionados, grabando discos de alta calidad y realizando destacadas actuaciones en vivo.

La agrupación ha obtenido diversos reconocimientos a lo largo de su carrera, como el Premio Ivor Novello en la categoría de «Logro Internacional» en 2002. En 2005 fueron incluidos en el "Hollywood's RockWalk" en Sunset Boulevard, Los Ángeles. En 2009 fue ganadora del premio «Mejor Performance en Vivo» en los BRIT Awards, el premio musical más importante del Reino Unido. En el año 2011 también obtuvieron un Grammy, en la categoría de «Mejor interpretación de Metal», por la canción «El Dorado».Además, ha ganado el premio de mejor banda metal británica del año en varias ocasiones, en los Metal Hammer Golden Gods Awards, entre otros reconocimientos.

Durante sus más de 40 años de trayectoria, Iron Maiden ha sido identificada gráficamente por su famosa mascota «Eddie the Head», un personaje antropomórfico que ha aparecido en la gran mayoría de las portadas de sus álbumes y sencillos, así como en sus presentaciones en vivo.

Tras varias audiciones y cambios en su formación, ésta finalmente se consolidó con el vocalista Paul Di'Anno, los guitarristas Dave Murray y Dennis Stratton y el batería Clive Burr, siempre bajo el liderazgo del bajista y principal compositor Steve Harris. Luego de muchas giras por todo el Reino Unido, en 1979 la banda publicó un EP llamado "The Soundhouse Tapes", y en 1980, su álbum debut homónimo, el cual llegó al cuarto puesto de las listas británicas, sin mediar promoción masiva alguna. Ese mismo año, Stratton fue reemplazado por el guitarrista Adrian Smith, con quien publicaron el álbum "Killers" (1981). Luego, y tras la salida de Di Anno, ese mismo año, el cantante Bruce Dickinson entró para ocupar el puesto de vocalista para el álbum "The Number of the Beast" de 1982, el cual llegó al número uno de las listas británicas, marcando el inicio de una serie de lanzamientos de impacto. Para el año 1983 la banda lanzó el álbum "Piece of Mind", que contaba como novedad con la salida del batería Clive Burr y la entrada de Nicko McBrain en su reemplazo. A partir de allí, se consolidó la alineación más exitosa que ha tenido la agrupación, la cual ha realizado numerosas giras y álbumes. Iron Maiden ha grabado 16 álbumes de estudio y es considerada una de las bandas más influyentes no solo para el "heavy metal" y sus respectivos subgéneros, sino también para diversas agrupaciones de "rock", e incluso artistas de otros estilos.

La historia de Iron Maiden parte en el año 1971, cuando Steve Harris, inspirado en bandas como Wishbone Ash, Thin Lizzy, UFO, Black Sabbath, Jethro Tull, Genesis, King Crimson, The Who y Deep Purple, entre otras, adquirió un bajo Fender Precision Bass por unas 40 libras esterlinas, y tras dejar atrás la opción de la batería, para la cual no contaba con el espacio suficiente. Inicialmente Harris también tuvo la ilusión de ser jugador de fútbol del West Ham, sin embargo, comenzó a dedicar todos sus esfuerzos a su otra gran pasión, la música. Esto condujo a la formación de una agrupación musical que llamó Gypsy's Kiss en 1972, cuyo primer concierto fue en el mítico local Cart & Horses en Maryland Point, Stratford.
Tras unos cuantos conciertos bajo el nombre de Gypsy´s Kiss, Harris decidió crear el proyecto Smiler, cuyos miembros tenían algunos años más que él, lo que le sirvió para acumular experiencia. Pese a ello, Harris deseaba plasmar sus inquietudes como compositor en mayor grado, y el resto de la banda se encargaba de rechazar sus composiciones por considerarlas «muy complicadas». Esto hizo que el bajista renunciara a Smiler y se propusiera formar una nueva agrupación donde tuviera el mando de la composición.

De este modo, Harris fundó Iron Maiden el día de Navidad de 1975. El grupo estaba compuesto por y en las guitarras, en la batería, Steve Harris en el bajo y en la voz. Harris tenía la idea de emular el sonido de Wishbone Ash en cuanto al concepto de "guitarras gemelas". Las primeras sesiones de grabación de la banda dieron como resultado composiciones que trascendieron en la carrera de Iron Maiden como «Transylvania», «Wrathchild» o «Innocent Exile».

El 1 de mayo de 1976 tuvo lugar el primer concierto de la banda en el Cart & Horses, un pub muy popular del East End de Londres. Empezó a correr la voz y los seguidores de la banda empezaron a crecer con cada presentación.

Harris decidió el nombre de la banda al ver un instrumento de tortura en una vieja película llamada "El hombre de la máscara de hierro". Se trataba de un ataúd de metal conocido como doncella de hierro, con docenas de clavos oxidados en su interior, donde las víctimas eran introducidas hasta que morían desangradas. Sin embargo, en medio de una presentación en el Cart & Horses en Stratford, informaron a Harris que ya existía otra banda con el mismo nombre. De común acuerdo, los músicos decidieron no darle importancia al asunto y siguieron adelante con el nombre y con la banda.

El vocalista Paul Day al poco tiempo fue sustituido por el cantante anterior (específicamente de la era Smiler), , que si bien no podía igualar el registro de Day, lo suplía con su presencia escénica. Wilcock a su vez recomendó a un talentoso guitarrista llamado Dave Murray, quien era admirador al igual que Harris de las bandas Wishbone Ash, Fleetwood Mac, Free, Genesis, UFO, Deep Purple y Jimi Hendrix. A su vez, Murray admiraba lo que estaba haciendo Iron Maiden en sus diversas presentaciones en Londres. La idea de integrar a Dave Murray era la de formar una banda con seis miembros y tres guitarristas.

En 1976, el apogeo comercial del "punk" era bastante fuerte a diferencia de la escena del "rock", que venía de capa caída, por lo que los ingresos monetarios para la banda eran muy bajos a pesar del gran éxito a nivel underground y de seguidores que estaban teniendo. Ese fue justamente el motivo de la salida de Dave Sullivan y Terry Rance, ya que cada uno de ellos había contraído matrimonio y debían mantener a sus respectivas familias, por lo que se ve imposibilitada la idea de las tres guitarras junto a Dave Murray, quien había congeniado de buena forma con Steve Harris.

Por intermedio del cantante Dennis Wilcock, reingresó (Bob ya había estado un muy corto tiempo con Iron Maiden) como el segundo guitarrista. Dennis Wilcock se caracterizaba por tener una personalidad muy frontal, polémica, manipuladora y egocéntrica, por lo que comenzó a imponer sus gustos personales y decidió despedir al batería Ron “Rebel” Matthews, al propio reingresado Bob "Bob Sawyer" Angelo y a Dave Murray. Este hecho generó una enorme presión en Steve Harris, quien tras meditar la dificultad de encontrar un nuevo cantante, finalmente optó por acceder a los caprichos de Wilcock sacando a Murray de la banda, en lo que él mismo define en el documental "Early Days" como una actitud personal totalmente estúpida de su parte.

En 1977 Terry Wapram se integró a la banda en la guitarra, junto al excéntrico Barry Graham Purkis, más conocido como Thunderstick en la batería, proveniente de la banda Samson. Harris decidió integrar a un tecladista llamado Tony Moore, y finalmente en la primavera de 1977, el mismo Dennis Wilcock decidió retirarse intempestivamente de la banda tras un concierto. El norte de la agrupación oscilaba entre la gran cantidad de seguidores y los cambios que siguieron, ya que Steve Harris decidió prescindir de Moore y Thunderstick. El músico siguió insistiendo en conformar una agrupación sólida y contactó de nuevo con el batería (quien había tocado con él en la era Smiler) y con el guitarrista Dave Murray, que terminó reemplazando a Terry Wapram. De esta forma, Murray se reintegró a Iron Maiden, agrupación conformada hasta ese momento solo por Steve Harris y Doug Sampson. A pesar de las adversidades, el trío de músicos siguió firme en su propósito.

Un compañero de Doug Sampson recomendó al cantante Paul Di'Anno, quien para entonces se encontraba en una banda llamada Bird of Prey. Di'Anno fue del gusto inmediato de Steve Harris, quien lo integró a Iron Maiden en 1977. El grupo funcionó durante un tiempo con un solo guitarrista, compensando con el bajo las partes de la segunda guitarra en canciones como «Iron Maiden». Durante ese tiempo, casi la totalidad de las ganancias de la agrupación eran invertidas en escenografía, como por ejemplo la famosa máscara ubicada detrás de la batería de Doug Sampson, una versión primigenia de la mascota Eddie the Head.

Fueron tiempos difíciles para Harris y sus compañeros; eran los años del "punk" que explotaba por las calles de Londres, con bandas como los Sex Pistols que gozaban del favoritismo de las masas. Incluso algunas disqueras le sugirieron a Harris que cambiara la imagen de su grupo, que se cortasen el pelo y que adaptaran su música a los tiempos que corrían. Sin embargo, el bajista tenía una idea muy clara de cómo quería que fuera su grupo y el tipo de música que quería tocar. Se refirió a este hecho de la siguiente manera: «No podría haber comenzado una banda de "punk"... eso estaría en contra de mi religión». Di'Anno, por su parte, comentó en aquellos tiempos: «Compositores que alguna vez estuvieron en Fairport Convention están ahora con The Clash, solo viven alterando sus gustos para mantenerse acorde a los tiempos. No veo la razón de eso. Debes mantenerte en la música que te gusta, ser fiel».

Harris vio la necesidad de contratar a otro guitarrista para seguir evolucionando, y fue así como pasaron esporádicamente por la banda acompañando a Dave Murray los guitarristas Paul Todd, Tony Parsons y Mad Mac. Fueron varias las anécdotas que cuenta Steve Harris alrededor de esta época y estos tres músicos, como por ejemplo, el caso de Paul Todd, que siendo un gran guitarrista se veía impedido para ensayar por su novia, o Mad Mac, que siempre llevaba a su perro a los ensayos, y que partió muy entusiasta, pero tenía una extraña bipolaridad anímica que tras unos meses le impidió seguir en la banda.

Como las giras por Gran Bretaña ya eran bastante extensas, la banda adquirió un camión al que transformaron para acarrear los equipos y también para poder dormir durante estas, y le llamaron «La Diosa Verde» por su color verde oscuro. Fue en este contexto en el que en 1978 Paul, Doug, Steve y Dave grabaron el EP "The Soundhouse Tapes" en los estudios Spaceward en Cambridge, incluso durmiendo en el suelo de la casa de una enfermera que había conocido Paul Di'Anno, ya que el vehículo no los resguardaba totalmente del frío. Después de haber vendido una gran cantidad de copias, quisieron llevarse a casa la cinta original para agregar más temas a la grabación, pero cuando fueron a retirarla se enteraron que el "master" había sido borrado, quedando solo el cartucho QIC, que es lo que al final resultó como "The Soundhouse Tapes".

Por aquel tiempo, conocieron a Neal Kay, un DJ de "rock" que era dueño del primer local de "heavy metal" de Londres, el Bandwagon. El primer encuentro entre Neal y Steve Harris fue muy especial, ya que el mismo Kay reconoce no haber sido muy amable con Steve cuando este le entregó el demo para que lo escuchara. Sin embargo, cuando se dio el tiempo de oírlo quedó realmente asombrado e impactado por la fuerza de la agrupación, algo que, en sus propias palabras, no le había sucedido antes con ninguna otra banda. Al tiempo, composiciones como «Iron Maiden» o «Prowler» se pondrían a la cabeza de la lista de canciones del Bandwagon. La popularidad de la banda empezó a crecer tras el lanzamiento del disco, y tal como cuenta el mismo Neal Kay, los fanáticos del "rock" y del "heavy metal" se rindieron a los pies de Iron Maiden en toda Inglaterra.

Poco tiempo después inició la asociación con el mánager Rod Smallwood, quien escuchó las canciones de la banda sorprendiéndose gratamente e invitándolos a un par de conciertos en el Windsor Castle en Harrow Road y en el Swan en Hammersmith. Sin embargo, la calidad del grupo, la presencia contestataria y la respuesta que generaba en la audiencia de la época (que incluso ya era bastante más fuerte que el de las propias bandas "punk" de moda e imperantes), les trajo algunos problemas en algunos locales en los que se les prohibió tocar por la algarabía que generaban. Pero los problemas vendrían en especial a manos de Paul Di'Anno, de hecho la segunda vez que Rod Smallwood se dispuso a ver a la banda en vivo, Paul había sido arrestado por la policía, teniendo que ser el mismo Steve Harris quien asumiera el rol de cantante (además de bajista) por esa noche, con un Iron Maiden conformado como un "power trio".

Rod Smallwood, lejos de desilusionarse, quedó impactado por la actitud de Steve y Dave sobre el escenario. A partir de ese momento, Rod decidió asumir el rol de mánager de la banda. En este contexto, la discográfica EMI ofreció un contrato al grupo, después de haber visto un par de «shows electrizantes» como contaran los mismos John Darnley, Martin Haxby y Brian Sheperd de EMI Records, en especial Darnley, encargado de la parte "rock" del sello, y que incluso se hizo admirador de la agrupación. La idea era ficharlos para la grabación de tres discos. Paradójicamente, el ritmo vertiginoso que llevaba la banda le pasó factura a Doug Sampson, quien decidió retirarse. Paralelamente al retiro de Doug se integró el guitarrista Dennis Stratton, justo antes de la grabación del primer álbum, y es el mismo Stratton justamente quien lleva a Clive Burr para reemplazar a Doug Sampson en la batería, quedando de este modo lista la agrupación que plasmaría la siguiente grabación.

Smallwood logró que Brian Shepherd, presidente del sello discográfico EMI, presenciara el histórico concierto de la banda en el Club Marquee en 1979, el cual calificó de «electrizante», y una semana más tarde, Iron Maiden firmaba contrato con la mencionada compañía discográfica, tras superar en la consideración de los ejecutivos a otra banda representativa del NWOBHM, Def Leppard.

En diciembre de 1979, la banda grabó su primer larga duración, "Iron Maiden", con Paul Di'Anno en la voz, Steve Harris en bajo y coros, Dave Murray en guitarra, Clive Burr en batería y Dennis Stratton en guitarra y coros, celebrando además la edición del primer sencillo oficial "Running Free," que rápidamente escalaba las listas británicas hasta posicionarse en el puesto treinta y cuatro.
El 14 de abril de 1980 la banda publicó oficialmente el esperado primer álbum de estudio, titulado "Iron Maiden". Si bien recibió excelentes críticas por parte de los medios especializados, para Steve Harris no llegó al nivel que hubiera deseado, ya que consideró que el productor discográfico Will Malone no trabajó lo suficiente en el sonido. A pesar de la inconformidad de Harris, el disco alcanzó la cuarta posición en las lista británicas, y para celebrarlo la banda retornó al Ruskin Arms, uno de los locales que los vio nacer, para hacer otro recordado e histórico concierto.

Después del primer álbum, el guitarrista Dennis Stratton, que ingresara en la séptima alineación del grupo, abandonó la formación debido a diferencias musicales. En su reemplazo ingresó Adrian Smith, amigo personal de Dave Murray que anteriormente había rechazado unirse ya que estaba cómodo con su banda Urchin, que además estaba teniendo cierto éxito a nivel local.

El 2 de febrero de 1981 la banda publicó su segundo trabajo discográfico, titulado "Killers"". "El productor discográfico fue Martin Birch, que había trabajado con grupos como Deep Purple, Black Sabbath y Fleetwood Mac (teniendo en su haber la producción de discos clásicos como "Machine Head" y "Heaven and Hell" de los mencionados respectivamente)"." Al escuchar el material del grupo, Birch le preguntó a Steve Harris por qué no lo habían llamado para el primer disco. La respuesta fue: «Pensamos que eras demasiado famoso para decir que sí». Comparado con el primer disco, si bien quizás no produjo el impacto del anterior, "Killers" es mucho más acabado en cuanto a sonido. En febrero de ese mismo año, la banda se embarcó en su primera gran gira mundial. En Europa compartieron escenarios con la agrupación estadounidense Kiss. La banda llegó por primera vez a los Estados Unidos, donde tocó junto a Scorpions, Judas Priest, 38 Special y Rainbow.

Su primera gira por Japón y, junto a ésta, la grabación del álbum en directo "Maiden Japan", el 23 de mayo de 1981, le valió al grupo la conquista de su primer disco de oro. No obstante, el ascenso de la banda no frenó los cambios que se producirían al interior de la misma. Paul Di'Anno fue expulsado de la agrupación debido a su estilo de vida de excesos con el alcohol y las drogas, que lo tenían física y psicológicamente desgastado. Di'Anno había sido detenido por la policía en varias ocasiones debido a sus abusos, abandonando a la agrupación en momentos claves. Esto motivó a Steve Harris a tomar la decisión de no contar más con él como vocalista. Tras su ausencia, cantantes como Terry Slesser hicieron pruebas para la banda, pero fue finalmente Bruce Dickinson, (otro ex-Samson), quien llegó el mismo año para ocupar el puesto.

Cuando la idea de incluir a Dickinson fue propuesta por Steve al mánager Rod Smallwood, este inicialmente se mostró reticente, debido a un problema que él había tenido en el pasado con la banda Samson. Sin embargo, Harris convenció a Rod para que fueran a ver a Bruce en un show de Samson, en el mítico Reading Festival en Inglaterra. Tras ver en directo la calidad de Dickinson, como vocalista y como frontman, ambos se convencieron y decidieron ofrecerle el puesto de cantante en Iron Maiden. De esta manera, contactaron con él para que se presentase a una audición, y justo cuando interpretó la canción «Remember Tomorrow» le anunciaron su contratación. Aunque inicialmente el cantante tuvo algunas dudas, la propuesta de Iron Maiden era bastante tentadora, al tratarse de una banda ya fichada por la gigante EMI Music y que se encontraba girando por toda Europa, Estados Unidos y Asia. Después de meditarlo por varios días, aceptó. El primer concierto de Dickinson con Iron Maiden fue el 26 de octubre de 1981 en Bolonia, Italia.

La consagración definitiva de Iron Maiden alrededor del mundo llegó con su tercer álbum de estudio, "The Number of the Beast," publicado el 29 de marzo de 1982. La gira promocional del disco fue titulada "The Beast On The Road," comenzando en Inglaterra para culminar diez meses más tarde en Japón, siendo su segunda visita a este país. Con el sencillo «Run to the Hills», Iron Maiden llegó hasta el número 7 en el Top 40 británico.
Pero fue en plena gira, y mientras su autobús se quedaba varado en la carretera, que la banda se enteró que el álbum había pasado a encabezar las listas británicas.

Sin embargo, la temática del disco y su portada, en la que se mostraba a Eddie manejando al demonio como a una marioneta, generaron controversia en algunos sectores religiosos en los Estados Unidos. Precisamente estos últimos se manifestaron frente a las puertas de uno de sus conciertos acusándolos de apología del satanismo, básicamente por la canción «The Number of the Beast», que fue la que desencadenó todas las acusaciones. Los medios oficiales o de difusión masiva le dieron la espalda a la banda, en una especie de censura velada, sin embargo, esto no impidió que comenzaran a ser un fenómeno de voz en voz, y hasta romper récords de audiencia en los Estados Unidos, a pesar de que los medios nunca se hicieron eco de este fenómeno. No fue así en cambio con bandas como Quiet Riot, Judas Priest, Twisted Sister, o Mötley Crüe, que sí contaron con un importante apoyo mediático y comercial en La Unión.Por ese entonces se produjo un cambio más en la formación de la agrupación. Clive Burr abandonó la banda por problemas personales y una cierta incapacidad de seguir con el ascendente ritmo y éxito de la banda, y en su lugar fue reemplazado por el exbatería de la banda francesa Trust, Nicko McBrain, dejando constancia de sus cualidades como instrumentista, a la vez que añadió una nueva dimensión al sonido de la banda.

El 16 de mayo de 1983 fue publicado un nuevo álbum de estudio, titulado "Piece of Mind". Con este disco consiguieron discos de platino y oro en varios países. En junio de ese mismo año lanzaron la gira World Piece Tour, que los llevó a presentarse como cabeza de cartel en el Rock Pop Festival de Westfalenhalle en Dortmund (Alemania), compartiendo el escenario con Scorpions, Judas Priest, Def Leppard, Ozzy Osbourne, Quiet Riot y Michael Schenker Group en diciembre de 1983.

El 3 de septiembre de 1984 fue lanzado al mercado el quinto álbum de la banda, titulado "Powerslave". El disco comienza con la canción «Aces High», seguida de «2 Minutes to Midnight», basada en el Reloj del Apocalipsis de la Universidad de Chicago que da cuenta simbólicamente del tiempo restante para la guerra nuclear y el fin de la civilización, cuyo tiempo «récord» de cercanía fue dos minutos para la medianoche en 1953. "Powerslave" finaliza con la canción «Rime of the Ancient Mariner», basada en el poema del mismo nombre de Samuel Taylor Coleridge.

The World Slavery Tour, gira que abarcó 23 países y constó de 191 conciertos en 331 días, se realizó en soporte de "Powerslave". La gira concluyó en los Estados Unidos con récords de audiencia a pesar de la prácticamente nula difusión en los medios masivos, lo cual es mencionado incluso por el propio Bruce Dickinson en el concierto del "Live After Death" grabado en el Long Beach Arena de California.

Con el lanzamiento de "Powerslave" en 1984, América del Sur los recibió con notable éxito durante el festival Rock in Rio que se realizó en Brasil en Jacarepaguá, en la zona oeste de Río de Janeiro en 1985, en un histórico concierto que también contó con la participación de bandas como Queen, Scorpions, Ozzy Osbourne, George Benson, Yes y AC/DC.

Durante el transcurso de la gira The World Slavery Tour fue grabado en el Long Beach Arena en California el álbum en directo "Live After Death". La portada del disco incluyó una cita de Howard Phillips Lovecraft, escritor de cuentos de terror con estilo y forma de metaficción. El álbum comienza con el discurso que el primer ministro Sir Winston Churchill pronunció como aliento al pueblo británico ante la inminencia del bombardeo a Londres por parte del ejército Alemán nazi durante la Segunda Guerra Mundial, a modo de introducción para la canción «Aces High».

El 29 de junio de 1986 fue publicado el sexto álbum de estudio de Iron Maiden, "Somewhere in Time", en el que la banda implementó el uso de sintetizadores como complemento, con un sonido que claramente apuntaba a lo progresivo. El disco fue un éxito a nivel mundial, impulsado especialmente por el sencillo "Wasted Years". Sin embargo, no incluyó créditos de escritura de Dickinson, cuyo material fue rechazado por el resto de la banda. El guitarrista Adrian Smith demostró creatividad compositiva en esta etapa, aportando las letras de las canciones "Wasted Years", "Sea of Madness" y "Stranger in a Strange Land", siendo esta última escogida como el segundo sencillo del álbum.En marzo de 1988 la banda publicó el sencillo promocional «Can I Play With Madness», que alcanzó la tercera posición en el Reino Unido. El sencillo vino acompañado de un clip de vídeo, dirigido por el cineasta británico Julian Doyle y protagonizado por el actor y comediante Graham Chapman, fallecido poco tiempo después del lanzamiento del clip.

El séptimo álbum de la banda, un disco conceptual basado en la obra "El séptimo hijo" de Orson Scott Card, fue publicado el 11 de abril de 1988. "Seventh Son of a Seventh Son" se convirtió en el primer álbum de Iron Maiden en el que se incluyeron teclados, tocados por Harris y Smith, a diferencia de las guitarras sintetizadas utilizadas en el anterior disco. En esta oportunidad, las ideas de Dickinson fueron aceptadas y el cantante tuvo créditos de composición en las canciones «Moonchild», «Can I Play with Madness», «The Evil That Men Do» y «Only the Good Die Young».

"Seventh Son" se convirtió en el segundo álbum de Iron Maiden en alcanzar la primera posición en las listas de éxitos del Reino Unido, aunque solamente logró la certificación de disco de oro en los Estados Unidos, en contraste con los cuatro álbumes anteriores. El disco fue acompañado de una gran gira promocional así como de una escenografía y juegos de luces. La gira incluyó gran parte de Europa y de los Estados Unidos. Una de las presentaciones más recordadas de esta gira ocurrió en el festival Monsters of Rock, celebrado el 20 de agosto de 1988, en el que la banda fue por primera vez cabeza de cartel y en el que compartieron escenario con Kiss, Guns N' Roses, Megadeth, David Lee Roth y Helloween. El festival convocó a más de cien mil espectadores, pero se vio empañado por la muerte de dos aficionados durante la actuación de Guns N' Roses, por lo que la edición del año siguiente fue cancelada.

La gira concluyó con varios conciertos en el Reino Unido en noviembre y diciembre de 1988, con los conciertos en el NEC Arena de Birmingham grabados para un vídeo en directo, titulado "Maiden England". Durante la gira, el técnico de Harris, Michael Kenney, se encargó de tocar los teclados en vivo. Kenney ha actuado como teclista en vivo de la banda desde entonces, también tocando en los cuatro álbumes siguientes antes de que Harris se convirtiera en el único teclista de estudio del grupo desde el año 2000 con "Brave New World". 

A mediados de 1989 trascendió la noticia de que Adrian Smith pondría en marcha la creación de una agrupación musical, algo que venía madurando desde hacía tiempo y que varias veces debió postergar por las obligaciones que supone ser miembro de Iron Maiden. Así, Smith lanzó el álbum "Silver and Gold" con la banda ASAP, la que integró con unos viejos amigos y donde él mismo se hizo cargo de la voz. Bruce Dickinson también puso en marcha su proyecto personal y lanzó el álbum "Tattooed Millionaire", proyecto que se aleja del sonido tradicional de Iron Maiden. Tras una sólida carrera en grupo de muchos años, la agrupación empezaba a dar señales de deseos individuales.

A inicios de 1990, año marcado por la anunciada ausencia de Maiden de los escenarios y en el que celebraba sus primeros diez años como estrella de la compañía discográfica EMI, Adrian Smith dejaba la banda en plena planificación del siguiente álbum, que incluso contaría con un tema de su autoría. Según cuenta el mismo Harris, si esta decisión de Smith se hubiese presentado en otra época, probablemente no se hubiera llevado a cabo en buenos términos, sin embargo, la separación se realizó en términos completamente amistosos y la banda dejó en libertad a su guitarrista. De esta manera, la formación clásica había llegado a su fin. Sin embargo, a los siete días se dio a conocer a Janick Gers como reemplazo de Smith. Gers había trabajado con Dickinson como guitarrista en el álbum "Tattooed Millionaire" y con bandas como White Spirit y Gillan.

El álbum "No Prayer for the Dying" debutó el 1 de octubre de 1990 en las listas británicas en el puesto número dos. En el disco fue incluida "Bring Your Daughter... to the Slaughter", única canción de Iron Maiden hasta la fecha que pudo encabezar la lista UK Singles Chart. Fue grabada originalmente por la banda de Dickinson para la banda sonora de la película de terror "". La canción fue prohibida por la BBC debido a su provocativa letra y sólo se proyectó un clip en vivo de 90 segundos en el programa "Top of the Pops".

Después de dos años, la banda se embarcó en una nueva gira titulada No Prayer On The Road. Sin embargo, la gira debió terminar antes de lo planeado, cancelándose las visitas a Japón y Australia debido al comienzo de la Guerra del Golfo. Finalmente la gira finalizó en Salt Lake City, Utah en marzo de 1991.

En mayo 1992 fue publicado un nuevo álbum de Iron Maiden, "Fear of the Dark". Se convirtió en el primer álbum de estudio cuya portada no fue dibujada por Derek Riggs, pues sus ideas no coincidían con lo que quería la banda en este disco. El arte de portada fue diseñado por Melvyn Grant. "Fear of the Dark" le dio a la banda otro número uno en las listas británicas.

Una multitudinaria gira mundial, llamada Fear of the Dark Tour, se inició el día 5 de junio de 1992 y la inauguración oficial fue en Reikiavik. Luego la banda se trasladó a los Estados Unidos y Canadá, prosiguiendo su itinerario por América Latina, destacándose un gran escándalo a nivel gubernamental y eclesiástico en Chile, en donde fueron censurados por las autoridades de forma encubierta, generando un escándalo en dicho país y la desazón de miles de admiradores, muchos de los cuales incluso realizaron marchas por el centro de Santiago en señal de protesta. La fecha que no pudo realizarse en Chile fue reemplazada por Uruguay en la Estación General Artigas, una estación de trenes abandonada. En dicho lugar, la banda quedó fascinada con la arquitectura de la misma (típica inglesa del siglo XIX), y entre máquinas y vagones de este origen y antigüedad se realizó una sesión fotográfica, que no ha visto la luz, salvo una foto en el aeropuerto (al llegar a territorio uruguayo) en el libreto que acompaña al doble álbum en directo "A Real Live/Dead One".

Concluido el tramo sudamericano, Iron Maiden se dirigió a Europa, donde actuó en muchos países y nuevamente fue cabeza de cartel en el Festival Monsters of Rock, que tuvo lugar en el circuito de Donington Park, el sábado 22 de agosto de 1992, ante miles de espectadores. La presentación de este festival, en el que Adrian Smith retornó brevemente a la formación de la banda durante la canción "Running Free", fue grabada y recopilada en el álbum en vivo "Live at Donington". El siguiente tramo de la gira los llevó a Australia, Nueva Zelanda, Corea, Taiwán, Indonesia, India y Japón con siete presentaciones en Nagoya, Fukuoka, Hiroshima, Osaka (con dos presentaciones), Yokohama y Tokio.

En 1993, Dickinson dejó la banda para continuar con su carrera en solitario, pero aceptó quedarse para una gira de despedida y dos álbumes en vivo. El primero, "A Real Live One", contenía canciones de 1986 a 1992, y fue lanzado en marzo de 1993. El segundo, "A Real Dead One", contenía canciones de 1980 a 1984, y fue lanzado después de que Dickinson dejara la banda. La gira no fue una buena experiencia para la agrupación y Steve Harris afirmó que Dickinson sólo puso su mayor esfuerzo en espectáculos de alto perfil, y que en varios conciertos parecía simplemente murmurar al micrófono. Dickinson se encargó de desmentir estas declaraciones, afirmando que le era imposible estar al cien por ciento si el ambiente no era el adecuado, argumentado además que la noticia de su salida había impedido cualquier posibilidad de un buen ambiente durante la gira. El 28 de agosto de 1993 se realizó un pequeño concierto de despedida de Dickinson, el cual fue filmado por la BBC bajo el nombre de "Raising Hell". El ilusionista Simon Drake se encargó de presentar el espectáculo.

La despedida entre la banda y el vocalista fue caballerosa en un principio. Apenas algún comentario posterior de Steve Harris deja traslucir la incomodidad: "Supuestamente, hacía mucho que no se sentía bien con nosotros, estaba cansado y creativamente desmoralizado, lo cual es muy raro porque jamás nos dijo nada. Si se sentía así, entonces tendría que haberse ido antes y yo mismo le habría aconsejado que se fuera".

Sin embargo, posteriormente Dickinson comenzó a argumentar sus diferencias respecto a sus excompañeros en algunos medios de comunicación, en especial en relación a Steve Harris, a quien calificaba como demasiado "tradicional".

Antes de la despedida de Dickinson, Iron Maiden comenzó a escuchar a distintos candidatos a reemplazarlo, entre estos Andre Matos y Doogie White. Steve Harris argumentó que el sucesor de Dickinson debía ser preferentemente de nacionalidad inglesa. Finalmente, la balanza se inclinó por Blaze Bayley, cantante del grupo Wolfsbane, que ya había acompañado a Iron Maiden en una gira en 1990. Como ya había ocurrido en el pasado, a la hora de los cambios en su alineación, Iron Maiden consideró la amistad y empatía para tomar una decisión.

Para el nuevo álbum, la banda no sólo presentó a un nuevo cantante, sino también a un nuevo productor. Desde 1981, cada álbum de estudio de Iron Maiden había sido producido o coproducido por Martin Birch. Pero ahora, ya retirado, Steve decidió hacerse cargo de la producción junto a Nigel Green, quien había sido ingeniero en los álbumes "Killers" y "The Number of the Beast," y en la actualidad productor de su propio sello discográfico. Finalmente, después de un año de trabajo, en octubre de 1995 fue lanzado el disco "The X Factor" previo inicio de la gira The X Factour que los llevó por primera vez a Sudáfrica e Israel. La gira también abarcó el Este de Europa (Rumania, Bulgaria, Eslovenia, Hungría, Polonia y la República Checa); Europa Occidental, Estados Unidos, México, Canadá, Japón y Sudamérica.

La salida de Bruce Dickinson afectó a la recepción del nuevo álbum, sin embargo, el trabajo llegó al Top 8 de las listas británicas. En este álbum, las canciones son más largas y oscuras, abandonando en gran parte el sonido que caracterizó a la banda en la década de 1980. Ese enfoque siniestro y oscuro del álbum muy probablemente era el reflejo del difícil momento emocional y personal de Steve Harris en aquellos años, pues atravesaba por el divorcio de su esposa y la muerte de su padre.

El arte de portada también representó un cambio. En ella se puede ver a Eddie mientras está siendo diseccionado. El trabajo de la portada y del libreto interno fueron obra de Hugh Syme, quien previamente había trabajado en discos como "Moving Pictures", "Roll the Bones" o "Counterparts" de Rush y "Countdown to Extinction" y "Youthanasia" de Megadeth.

En 1996 vio la luz "Best of the Beast", primer disco recopilatorio oficial presentado por la banda, en dos versiones: un disco sencillo de 16 canciones y un disco doble de 27 canciones. Se incluyó además la canción inédita "Virus", grabada durante las sesiones del último disco de estudio.

Durante 1997, durante el auge de los videojuegos de consolas de 32 bits y de PC, Iron Maiden encargó a la empresa inglesa Virtual Studio la realización de un juego basado en su mascota, Eddie, y con canciones del grupo como banda sonora. Inicialmente su nombre sería "Melt" y contaría con versiones para PC y para PlayStation. Después de varios retrasos, y aunque se llegó a hacer una reserva a través del club de fanes oficial del grupo, el juego fue cancelado debido a la baja calidad del mismo.

En 1998 fue lanzado el álbum de estudio "Virtual XI", bajo un concepto mucho más clásico, a diferencia de la oscuridad plasmada en el álbum anterior. El disco no tuvo una recepción muy cálida, alcanzando apenas la posición número 16 en las listas británicas, la posición más baja de un disco de la banda en toda su carrera.

Mientras la banda gestaba este álbum, fue retomada la idea del lanzamiento de un videojuego. Encargaron a la compañía de desarrollo multimedia Synthetic Dimensions la creación de un videojuego basado en el arte gráfico que ha venido acompañando al grupo a lo largo de su carrera y que tuviera como protagonista a Eddie. El videojuego fue titulado "Ed Hunter", y se publicó en 1999 acompañado de un disco recopilatorio de 20 canciones escogidos por los fanáticos en la web oficial de Iron Maiden.

Debido a la escasa popularidad obtenida con "Virtual XI", Iron Maiden empezó a sufrir de una menor convocatoria de público en sus conciertos, y el desempeño de Blaze en vivo no era el mejor cuando debía interpretar canciones clásicas de la banda. Esto causó inconformidad entre muchos seguidores de la banda e, incluso, en el interior de la misma.

Tras el concierto de Maiden en Buenos Aires, Argentina, el 12 de diciembre de 1998, con el que concluyó la gira Virtual XI World Tour, se dio por terminada la participación de Blaze en la banda y le fue notificado su despido. Sin embargo, la noticia no se hizo pública en ese momento.

El año de 1999 inició con muchas especulaciones y rumores que hablaban de una supuesta salida de Blaze y se comentaban posibles reemplazos, entre los que se mencionó a Michael Kiske, anterior cantante de Helloween, que ya había sonado como reemplazo de Dickinson antes de reclutar a Blaze Bailey. Sin embargo, en el mes de febrero se anunció el retorno de Bruce Dickinson, generado por el deseo recíproco de ambas partes y tras una conversación de Dickinson con Rod Smallwood. Smallwood lo veía como una gran posibilidad para Iron Maiden, pero pensaba que Steve Harris no estaría muy convencido, pues tras la salida de Bruce la relación de Steve con el vocalista no había sido la mejor.

Bruce propuso también el regreso de Adrian Smith, quien en ese momento era uno de los guitarristas de su banda solista y con el que grabó los exitosos álbumes "Accident of Birth" (1997) y "Chemical Wedding" (1998). La banda decidió además conservar a Janick Gers en su formación, creando así un trío en las guitarras. 

Ese mismo año la banda lanzó su videojuego "Ed Hunter", y como promoción, se realizó una modesta gira titulada The Ed Hunter Tour, con alrededor de 30 fechas en Norteamérica y Europa. Una vez culminada la gira, el grupo se volcó de lleno en la preparación del que sería su duodécimo disco, titulado "Brave New World". El trabajo, publicado el 29 de mayo del año 2000, alcanzó la séptima posición en las listas británicas y la primera en varios países del mundo, retomando además el sonido característico de la agrupación.

La esperada gira mundial de presentación del álbum incluyó algunos países de América del Sur como Chile, Brasil y Argentina. Para poner fin a la gira se registró un nuevo disco en vivo titulado "Rock in Rio" (2002) grabado durante el festival Rock in Rio en su tercera edición, ante 250.000 personas.
En esta gira, Iron Maiden interpretó después de muchos años la canción "Run to the Hills" en los conciertos de Río de Janeiro y Santiago de Chile. Ese mismo año también se lanzó "Eddie's Archive", una caja recopilatoria de seis discos compactos que contiene los conciertos "Beast Over Hammersmith" y "The BBC Archives" y un recopilatorio de Lados B titulado "Best of the B'Sides".

En 2003, Iron Maiden publicó un nuevo álbum de estudio, "Dance of Death". El primer sencillo del disco, titulado "Wildest Dreams", fue presentado meses antes en la gira por Europa y Estados Unidos llamada Give Me Ed... Til I'm Dead, que comenzó en la ciudad española de La Coruña. Acto seguido, se lanzó un segundo sencillo, titulado "Rainmaker", que incluye una versión orquestal de la canción que da título al álbum, "Dance of Death".

Nuevamente la banda se embarcó en una gira mundial que culminó en Japón y que produjo un nuevo álbum en vivo, titulado "Death on the Road". Melvyn Grant, autor de la portada del disco "Fear of the Dark", fue el artista elegido para realizar la portada del directo, tras el rechazo de Derek Riggs debido a la presión a la que fue sometido. Como decisión, el artista no quiso realizar más portadas de Eddie para Iron Maiden, aunque sí creó una versión femenina de la mascota para el disco del grupo tributo compuesto íntegramente por mujeres, "The Iron Maidens".

Culminada la gira, fue lanzado un EP llamado "No More Lies", con cuatro canciones y una muñequera de obsequio.

En noviembre de 2004 fue publicado un DVD doble titulado "The Early Days", que presenta grabaciones inéditas de los primeros años, desde "Iron Maiden" hasta "Piece of Mind". En el DVD también se incluyó un documental con la participación de varios músicos que integraron la banda entre 1972 y 1983. En 2005 se realizó una gira que abarcó Europa y parte de América a modo de promoción, en la que solo se interpretaron temas de los cuatro primeros discos.

En agosto de 2006, Iron Maiden publicó su decimocuarto álbum de estudio, titulado "A Matter of Life and Death," siendo la guerra y la religión las principales temáticas abordadas. El disco fue un éxito comercial y de crítica, otorgándole a la banda su primer top 10 en la lista estadounidense "Billboard 200" y recibiendo el premio al mejor álbum del año entregado por la revista "Classic Rock". Siguió una gira de apoyo, durante la cual tocaron el álbum en su totalidad, algo que la banda jamás había llevado a cabo, obteniendo un respuesta que fue mixta.

En noviembre de 2006, Iron Maiden y Rod Smallwood anunciaron la finalización de un vínculo de 27 años con Sanctuary Music y el comienzo de una nueva empresa llamada Phantom Music Management. Sin embargo, no se hicieron cambios significativos. Un mes después, la banda grabó una sesión en directo en los estudios Abbey Road. Su ejecución se presentó en un episodio del programa Live from Abbey Road, junto con sesiones de Natasha Bedingfield y Gipsy Kings en marzo de 2007 en Channel 4 y en junio del mismo año a través de Sundance Channel.

La segunda parte de la gira A Matter of Life and Death, que tuvo lugar en 2007, fue apodada A Matter of the Beast para celebrar el 25º aniversario del álbum "The Number of the Beast" e incluyó apariciones en varios festivales importantes de todo el mundo. La gira comenzó en el Medio Oriente con la primera presentación de la banda en Dubái, después de la cual tocaron ante más de 30.000 personas en el Bangalore Palace Grounds, marcando el primer concierto de cualquier banda importante de "heavy metal" en el subcontinente indio. La agrupación tocó una serie de fechas europeas, incluyendo una aparición en Download Festival, su cuarta presentación en Donington Park, ante aproximadamente 80.000 personas. El 24 de junio terminaron la gira con una actuación en la Academia Brixton de Londres a beneficio del fondo benéfico The Clive Burr MS, con el objetivo de recaudar fondos para el tratamiento de la esclerosis múltiple, enfermedad que venía aquejando durante varios años al anterior batería de Iron Maiden.

El 5 de septiembre de 2007, la banda anunció una nueva gira llamada Somewhere Back in Time World Tour, en la que presentaron un setlist conformado por canciones clásicas de la agrupación, haciendo énfasis en la época de "Powerslave". La primera parte de la gira, que dio inicio en Bombay el 1 de febrero de 2008, consistió de 24 conciertos en 21 ciudades. La agrupación se transportó en un avión Boeing 747-400, pilotado por el propio Bruce Dickinson y bautizado Ed Force One. Tocaron por primera vez en Costa Rica y Colombia.

La gira condujo al lanzamiento de un nuevo álbum recopilatorio, titulado "Somewhere Back in Time", que incluía una selección de temas desde el álbum debut de 1980 hasta "Seventh Son of a Seventh Son" de 1988, así como varias versiones en vivo de "Live After Death". La gira mundial Somewhere Back in Time continuó con dos etapas más en los Estados Unidos y Europa en el verano de 2008, durante las cuales la banda utilizó un escenario más amplio, incluyendo otros elementos del espectáculo original "Live After Death". 

La última parte de la gira tuvo lugar entre febrero y marzo de 2009, nuevamente con el Ed Force One como medio de transporte. La manga final llevó a la banda a presentarse por primera vez en Perú y en Ecuador, y a regresar a Venezuela y a Nueva Zelanda después de 17 años. La agrupación también tocó otro concierto en la India (el tercero en el país en un lapso de 2 años) en el festival Rock in India ante una multitud de 20.000 personas. La gira finalizó en Florida el 2 de abril. En general, la gira tuvo una asistencia de más de dos millones de personas en todo el mundo.

En la edición del año 2009 de los Premios BRIT, Iron Maiden ganó el premio en la categoría de mejor banda británica en vivo. Votada por el público, la banda ganó por una victoria aplastante.

El 20 de enero de 2009, la banda anunció que el 21 de abril de 2009 estrenaría un largometraje documental en algunos cines. "" se filmó durante la primera parte de la gira mundial Somewhere Back in Time entre febrero y marzo de 2008. Fue coproducido por Banger Productions y distribuido en cines por Arts Alliance Media y EMI. La película fue publicada en formatos Blu-ray, DVD y CD en mayo y junio, encabezando las listas de éxitos en 22 países.

"The Final Frontier," decimoquinto álbum de estudio de Iron Maiden, fue publicado el 16 de agosto de 2010, alcanzando la primera posición en las listas de éxitos de 28 países. Aunque Steve Harris había afirmando anteriormente que la banda sólo publicaría quince álbumes de estudio, los mismos miembros de la banda se encargaron de negar esa afirmación después de la publicación del disco.

La gira soporte del álbum llevó a la banda a presentar 98 espectáculos a nivel mundial ante unos dos millones de personas, incluyendo primeras visitas a Singapur, Indonesia y Corea del Sur. El sencillo "El Dorado" ganó un premio en la categoría mejor interpretación de metal en la gala de los Premios Grammy, celebrados el 13 de febrero de 2011. La banda ya había sido nominada dos veces en esta categoría, con "Fear of the Dark" en 1994 y "The Wicker Man" en 2001.

El 15 de marzo se anunció una nueva recopilación, titulada "From Fear to Eternity". La fecha original de lanzamiento se fijó el 23 de mayo, pero posteriormente se retrasó hasta el 6 de junio. El doble disco cubre el periodo 1990-2010 (los ocho álbumes de estudio más recientes de la banda), y, como en "Somewhere Back in Time", se incluyeron versiones en vivo con Bruce Dickinson en lugar de grabaciones originales que incluían a otros vocalistas, en este caso Blaze Bayley.

En un comunicado de prensa, Rod Smallwood reveló que Iron Maiden publicaría un nuevo concierto en DVD en 2011, filmado en Santiago de Chile y Buenos Aires, durante la gira mundial The Final Frontier. El 17 de enero de 2012, la banda anunció que la nueva versión, titulada "En Vivo!" y basada en imágenes del concierto de Chile, estaría disponible en todo el mundo en CD, LP, DVD y Blu-ray el 26 de marzo, excepto en los Estados Unidos y Canadá (donde se lanzó el 27 de marzo). Además de las imágenes del concierto, el video incluye un documental de 88 minutos de duración, titulado "Behind The Beast", que contiene entrevistas con la banda y su equipo. En diciembre de 2012, la versión de "Blood Brothers" de "En Vivo!" fue nominada para un premio Grammy a la mejor interpretación de metal.

El 15 de febrero de 2012, la banda anunció el Maiden England World Tour 2012-14, conmemorando la reedición del vídeo "Maiden England" de 1988. La gira comenzó en Norteamérica en el verano de 2012 y fue seguida por otras fechas en 2013 y 2014, que incluyeron la quinta actuación de la banda en Donington Park, su primer concierto en el recién construido estadio nacional de Estocolmo, su regreso al festival Rock in Rio en Brasil y su debut en Paraguay. En agosto de 2012, Steve Harris declaró que el vídeo de "Maiden England" se volvería a publicar en 2013, con una fecha de lanzamiento posterior fijada para el 25 de marzo de 2013 en formatos de DVD, CD y LP bajo el título "Maiden England '88".

El 13 de marzo de 2013 se anunció la muerte del exbatería Clive Burr a los 56 años. En el año 2001 Clive fue diagnosticado con esclerosis múltiple, enfermedad que le abocó a quedar postrado en una silla de ruedas. El bajista Steve Harris declaró al respecto: "Era una persona maravillosa y un batería increíble que hizo una valiosa contribución al grupo en sus inicios, cuando comenzábamos a tocar". La noticia fue anunciada en la página oficial de la banda. Dickinson afirmó que conoció a Burr cuando este dejaba Samson en diciembre de 1982. Cuando le diagnosticaron esclerosis múltiple en 2001, sus ex compañeros en Iron Maiden crearon la fundación Clive Burr MS Trust con el fin de ayudarle a recaudar dinero para poder costearse la vida. El grupo también dio varios conciertos en honor de Burr cuando este se encontraba con problemas para financiar su casa, según indicó la BBC.

Después de cinco años del lanzamiento de "The Final Frontier", Iron Maiden publicó un nuevo álbum de estudio llamado "The Book of Souls", el 4 de septiembre de 2015. Junto al álbum se lanzó el sencillo "Speed of Light". "The Book of Souls" es el álbum de más duración en la historia de la banda, superando a "The Final Frontier", y también contiene la canción más larga de Iron Maiden hasta la fecha, titulada "Empire of the Clouds", compuesta por Bruce Dickinson y basada en el desastre aéreo del dirigible británico R.101. El álbum inicialmente iba a lanzarse entre abril y mayo, pero tuvieron que atrasar su fecha de lanzamiento debido al cáncer de garganta que afectó al vocalista Bruce Dickinson. El álbum fue bien recibido por la crítica y por los fanáticos, y llegó a ser número 1 en 24 países a pocas semanas desde su lanzamiento, obteniendo la certificación de disco de oro en el Reino Unido con 110.000 copias vendidas y debutando en el puesto 4 del "Billboard 200". En febrero de 2016, la banda se embarcó en la gira The Book of Souls World Tour, tocando en 35 países de América del Norte y del Sur, Asia, Australasia, África y Europa, incluyendo sus primeras presentaciones en China, El Salvador y Lituania. Al igual que en las giras Somewhere Back in Time de 2008-09 y The Final Frontier de 2010-11, el grupo viajó en un avión a medida, pilotado por Dickinson y apodado Ed Force One, aunque utilizaron un avión jumbo Boeing 747-400. La banda completó la gira en 2017 con otros espectáculos europeos y norteamericanos.

El viernes 11 de marzo de 2016, la banda realizó su octava presentación en Chile, siendo teloneados por The Raven Age y Anthrax. Al día siguiente, en la mañana del 12 de marzo, después de dar su concierto, la banda estaba por viajar en su avión Ed Force One para dar sus conciertos en Argentina. Sin embargo, vivieron un lamentable accidente con su avión Ed Force One en el Aeropuerto Internacional de Santiago.
Los resultados del imprevisto fueron dos de los motores de la aeronave completamente dañados, dos trabajadores heridos y hospitalizados y la gira de la banda por Sudamérica fue puesta en duda. Fueron los propios miembros de la banda quienes confirmaron que, a pesar del accidente, continuarían con sus conciertos en Argentina. El avión fue reparado nueve días después de lo sucedido y nuevamente volaron para seguir con sus conciertos en todo el mundo.

El 20 de septiembre de 2017 se anunció el lanzamiento de un nuevo álbum en directo, "". Grabado a lo largo de la mencionada gira, fue lanzado el 17 de noviembre de 2017.

En el verano de 2016, la agrupación lanzó un juego para móviles llamado "Iron Maiden: Legacy of the Beast" y un juego de "pinball" con el mismo nombre en 2018. Como soporte del juego, la banda se embarcó en una nueva gira mundial, titulada Legacy of the Beast World Tour, iniciando en territorio europeo en 2018, llegando a América en 2019. En Chile, la banda tocó dos fechas consecutivas, algo que nunca había hecho en ese país. El 23 de septiembre de 2019, la banda anunció una presentación en el Belsonic Festival en Belfast y en Donington Park en Inglaterra, ambos en 2020.

Iron Maiden ocupó el vigésimo cuarto puesto en el ranking de los "100 mejores artistas de "hard rock" de la historia" de VH1, la cuarta posición en la lista de las "10 mejores bandas de "heavy metal" de todos los tiempos" de MTV y el tercer puesto en el "Top 20 de las mejores bandas de "metal"" de VH1 Classic. La banda también ganó el Premio Ivor Novello por sus logros internacionales en 2002 y se incorporó al Hollywood RockWalk durante una gira por los Estados Unidos en 2005.

Iron Maiden utiliza con frecuencia el eslogan "Up the Irons" en las notas de sus discos, y la frase también puede verse en varias camisetas con licencia oficial de la banda. Es una paráfrasis de "Up the Hammers", la frase que hace referencia al club de fútbol londinense West Ham United, del que es aficionado su fundador Steve Harris.

La mascota de Iron Maiden, Eddie the Head, acompaña la gran mayoría de portadas de los álbumes y sus espectáculos en directo. Originalmente era una máscara de papel maché incorporada en el telón de fondo de los recitales, que rociaba sangre falsa durante sus presentaciones. Con el paso del tiempo fue modificado por el dibujante Derek Riggs, quien se encargó de darle vida hasta 1992, momento en el que la banda comenzó a utilizar obras de muchos otros artistas, incluyendo a Melvyn Grant. Eddie también aparece en los videojuegos "Ed Hunter" y "Legacy of the Beast", y en otros artículos relacionados con la banda. En 2008 fue galardonado con el "Icon Award" en el "Metal Hammer Golden Gods", mientras que Gibson.com lo describe como "el icono de metal más reconocible del mundo y uno de los más versátiles".

El logo de Iron Maiden ha adornado todos los lanzamientos de la banda desde su debut, el EP "The Soundhouse Tapes" de 1979. El tipo de letra tiene su origen en el diseño del cartel de Vic Fair para la película de ciencia ficción de 1976, "The Man Who Fell to Earth", también utilizada por el músico Gordon Giltrap, aunque Steve Harris afirma que la diseñó él mismo, utilizando sus habilidades como dibujante de arquitectura. La canción "Always Look on the Bright Side of Life" (de la película "Monty Python's Life of Brian") es un elemento básico en sus conciertos y es reproducida al final de los mismos.

En mayo de 2019, la banda presentó una demanda de 2 millones de dólares contra la empresa de videojuegos 3D Realms por infringir su marca a través del lanzamiento previsto de un juego llamado "Ion Maiden", que, según la banda, "es casi idéntico a la marca Iron Maiden en apariencia, sonido e impresión comercial general". Acusaron además a 3D Realms de causar "confusión entre los consumidores" al representar un icono de cráneo similar a la mascota de la banda, Eddie, además de las similitudes con el juego "Legacy of the Beast" de la propia banda.

Según la revista "Guitar World", la música de Iron Maiden ha "influido en generaciones de nuevos grupos de "metal", desde leyendas como Metallica hasta estrellas emergentes como Avenged Sevenfold". El batería de Metallica, Lars Ulrich, afirmó que "siempre ha tenido una increíble cantidad de respeto y admiración por Iron Maiden". Kerry King, guitarrista de Slayer, declaró que "significaban mucho para él en sus primeros días" y Scott Ian de Anthrax confirmó que "tuvieron un gran impacto en su vida".

M. Shadows de Avenged Sevenfold afirmó que Iron Maiden "son, con diferencia, la mejor banda en directo del mundo y su música es atemporal", mientras que el cantante de Trivium, Matt Heafy, aseguró que "sin Iron Maiden, Trivium seguramente no existiría". El líder de Slipknot y Stone Sour, Corey Taylor, afirmó: "Steve Harris hace más con cuatro dedos de lo que jamás he visto hacer a nadie. ¿Y Bruce Dickinson? Para mí, es el cantante de heavy metal por excelencia de la vieja escuela. Podía alcanzar notas enfermizas y era un gran "showman". Todo esto me convirtió en fanático. Y no había ningún tipo con el que saliera que no estuviera tratando de dibujar a Eddie en sus cuadernos". La música de Iron Maiden ayudó a Jesper Strömblad de In Flames a ser pionero en el género "death metal" melódico, afirmando que inicialmente quiso combinar el "death metal" con los sonidos melódicos de la guitarra de Iron Maiden.

Otros artistas del ambiente del "heavy metal" que citan a la banda como una influencia incluyen a Chris Jericho, cantante de Fozzy, Cam Pipes, vocalista de 3 Inches of Blood, Vitaly Dubinin, bajista de Aria, Mikael Åkerfeldt, guitarrista y vocalista de Opeth y los músicos Yoshiki y Hide de la banda japonesa X Japan. John Petrucci, John Myung y Mike Portnoy, miembros actuales y anteriores de Dream Theater, han declarado que Iron Maiden fue una de sus mayores influencias cuando se formó su banda por primera vez. Incluso la banda ofreció un recital en el que tocaron el álbum "The Number of the Beast" en su totalidad, publicado meses después a modo de "bootleg".

El nombre de la banda ha sido mencionado prominentemente en varias canciones, como los sencillos "Teenage Dirtbag" de Wheatus, "Back to the 80's" de la banda danesa de "dance-pop" Aqua, "Fat Lip" de Sum 41, "Heart Songs" de Weezer, "Psycho Joe" de Blues Traveler y "Eddie, Bruce and Paul" de NOFX. Esta última canción es descrita por Sputnikmusic como "un relato humorístico de la partida de Paul Di'Anno".

En 2008, "Kerrang!" publicó "Maiden Heaven: A Tribute to Iron Maiden", un álbum compuesto por canciones de Iron Maiden interpretadas por bandas como Metallica, Machine Head, Dream Theater, Trivium, Coheed and Cambria y Avenged Sevenfold. En 2010, Maiden uniteD, una banda de tributo acústico compuesta por miembros de Ayreon, Threshold y Within Temptation, publicó "Mind the Acoustic Pieces", una reinterpretación de todo el álbum "Piece of Mind". Existen otros álbumes tributo a Iron Maiden interpretados en una gran variedad de géneros y con diversos instrumentos.

Canciones de Iron Maiden han aparecido en las bandas sonoras de varios videojuegos, incluyendo "Carmageddon 2", "", "Grand Theft Auto: Episodes from Liberty City", "", "Tony Hawk's Pro Skater 4", "SSX on Tour" y "Madden NFL 10". Su música también aparece en la serie de videojuegos "Guitar Hero" y "Rock Band". En películas como "Phenomena" de Darío Argento y "Murder by Numbers" de Barbet Schroeder se pueden escuchar también canciones de la banda. Los personajes animados de la serie "Beavis and Butt-Head" han hecho comentarios favorables sobre la banda en varias ocasiones.

El autor de la franquicia de "Transformers", Bill Forster, es un fanático declarado de Iron Maiden e hizo varias referencias a la banda, incluyendo letras de canciones y la frase "Up the Irons" en sus libros, más precisamente en las series "The Ark" y "The AllSpark Almanac".

En 1982, la banda lanzó uno de sus álbumes más populares, controvertidos y aclamados, "The Number of the Beast". El arte de portada y el tema del título llevaron a grupos cristianos en los Estados Unidos a tildar a la banda de satanistas, animando a la gente a destruir copias del disco. El mánager Rod Smallwood afirmó que estos grupos inicialmente quemaron los discos, pero más tarde decidieron destruirlos con martillos por miedo a respirar los humos del vinilo derretido. Las protestas no se restringieron a los Estados Unidos, ya que organizaciones cristianas impidieron que Iron Maiden se presentara en Chile en 1992, asegurando que las letras de sus canciones eran perjudiciales para la juventud.

Contrariamente a las acusaciones, la banda siempre ha negado la idea de su supuesto satanismo. Bruce Dickinson desmintió estas acusaciones en el escenario de su gira World Slavery Tour, prueba de ello quedó registrada en la versión en DVD del álbum "Live After Death". Steve Harris también ha opinado acerca de estas acusaciones: "Es una locura. Están totalmente equivocados. Obviamente no han leído la letra de la canción". Harris también ha afirmado que la canción "The Number of the Beast" fue inspirada por una pesadilla que tuvo después de ver "" y por la obra literaria "Tam o' Shanter" del escritor escocés Robert Burns. Además, el baterista de la banda, Nicko McBrain, se acogió al cristianismo en 1999.

En 2005 la banda actuó en el Festival Ozzfest, organizado por Ozzy Osbourne y su esposa y mánager, Sharon. La empresaria incitó a algunos amigos de su familia y miembros de otras bandas a sabotear la última presentación de Iron Maiden en el Anfiteatro San Manuel en San Bernardino, California, el 20 de agosto. Sharon ordenó que el sonido de la banda fuera cortado, retrasó la entrada de Eddie y alentó a los seguidores de su familia a arrojar huevos, tapas de botellas y encendedores desde la audiencia. Según Bruce Dickinson, este ataque fue la respuesta a unas declaraciones suyas en las que criticaba los programas de telerrealidad, algo que, según él, Sharon Osbourne tomó de manera personal.

Sharon afirmó más tarde que Steve Harris le había presentado disculpas a su esposo Ozzy en San Bernardino por los comentarios de Dickinson, algo que Harris negó tiempo después, asegurando que sus palabras fueron tergiversadas. Años más tarde, Dickinson se refirió a este altercado como una "tormenta en una taza de té" y se refirió a Ozzy Osbourne como un icono musical.

Steve Harris, bajista y compositor principal de Iron Maiden, ha declarado que sus influencias incluyen a Black Sabbath, Judas Priest , Deep Purple, Led Zeppelin, Uriah Heep, Pink Floyd, Genesis, Yes, Jethro Tull, Thin Lizzy, UFO, Queen, Kiss y Wishbone Ash. En 2010 declaró: "Creo que si alguien quiere entender la esencia de Maiden, en particular las guitarras armónicas, todo lo que tienen que hacer es escuchar el álbum "Argus" de Wishbone Ash. También a Thin Lizzy, pero no tanto. Luego quisimos tener algo de progresivos también, porque me gustaban mucho bandas como Genesis y Jethro Tull. Así que, combinas todo eso con los riffs pesados y la velocidad y lo tienes". En 2004, Harris explicó que el lado más "metal" de la banda estaba inspirado en "Black Sabbath y Deep Purple, con un poco de Zeppelin". Además, Harris desarrolló su propio estilo de tocar, descrito por el guitarrista Janick Gers como "similar a tocar una guitarra rítmica", y citado como responsable del estilo galopante de la banda, que se evidencia en canciones como "The Trooper" y "Run to the Hills".

Los guitarristas de la banda, Dave Murray, Adrian Smith y Janick Gers, tienen cada uno sus propias influencias individuales y estilo de tocar. Dave Murray es conocido por su técnica de legato que, según él, "evolucionó de forma natural. Cuando era pequeño, yo había oído a Jimi Hendrix usar legato y me gustó ese estilo". Adrian Smith indicó que él "se inspiró en el blues rock en lugar del metal" y sus influencias fueron Johnny Winter y Pat Travers, lo que le llevó a convertirse en un "guitarrista melódico". Janick Gers, por el contrario, prefiere un estilo más improvisado, en gran parte inspirado por Ritchie Blackmore, que, afirma él, contrasta con el sonido "rítmico" de Smith.

El cantante Bruce Dickinson, que normalmente trabaja en colaboración con el guitarrista Adrian Smith, tiene un estilo vocal operístico, inspirado por Arthur Brown, Peter Hammill, Ian Anderson e Ian Gillan, y se le considera frecuentemente uno de los mejores cantantes de "heavy metal" de todos los tiempos. Aunque Nicko McBrain solo aparece como autor una vez, en el álbum "Dance of Death", Harris suele trabajar con él durante el desarrollo de las canciones. Adrian Smith comentó: "A Steve le encanta tocar con él. A menudo trabajaban durante horas repasando las partes de bajo y batería".

A lo largo de su carrera, el estilo de la banda ha experimentado cambios que van desde un sonido crudo en los primeros álbumes, hasta llegar a un estilo más progresivo, e incluso bajo el uso de sintetizadores como en "Somewhere in Time" (1986) y en "Seventh Son of a Seventh Son" (1988), y desde 1990 con "No Prayer for the Dying", en un intento de volver a la raíces sonoras de la banda, mezclándolos con estos elementos más progresivos, descritos por Steve Harris como "no progresivo en el sentido moderno como Dream Theater, sino más en el estilo de los años 1970". Según el propio Harris, "Seventh Son of a Seventh Son" fue el primer álbum de Iron Maiden en integrar elementos progresivos, retomados nuevamente en "The X Factor" de 1995, álbum que es "como una extensión de "Seventh Son" en el sentido de los elementos progresivos que contiene". La evolución en el sonido de la banda contrasta con sus primeras producciones discográficas, que según AllMusic, "se nutre claramente de elementos del "punk rock"", aunque Harris lo niega rotundamente. Bruce Dickinson tiene una opinión similar al respecto, asegurando que el álbum debut de la banda tiene un sonido similar al "punk" debido a su pésima producción.


Álbumes de estudio


</doc>
<doc id="1532" url="https://es.wikipedia.org/wiki?curid=1532" title="Indoeuropeo">
Indoeuropeo

Indoeuropeo es el nombre de una familia de lenguas y también de la lengua hipotética de la que desciende esta familia. Las lenguas indoeuropeas, antiguamente llamadas "lenguas indogermánicas", se hablan actualmente desde la India hasta Europa (de ahí su nombre), además de hablarse en muchas otras partes del mundo como resultado de la colonización europea. Estas lenguas tienen algunos rasgos comunes entre sí y diferentes a las de otras lenguas, incluso habladas en zonas próximas del mundo; sin embargo lo que da unidad a las lenguas indoeuropeas es sobre todo que la historia de la familia se ha podido reconstruir con bastante detalle gracias al método comparativo. 

La palabra "indoeuropeo" también se emplea para referirse a los pueblos históricos que originariamente hablaron esas lenguas (pueblos indoeuropeos), a su sociedad (sociedad indoeuropea), a su religión (religión indoeuropea) y a su cultura (cultura indoeuropea).

El término "indoeuropeo" se utiliza principalmente en las ciencias sociales (antropología, antropología lingüística, arqueología, etnología, filología, geografía e historia) y muy especialmente en la lingüística histórica. Se ha empleado también en pseudociencia en determinados contextos, por lo que ocasionalmente ha sido objeto de especial polémica (""el problema indoeuropeo""), como justificación de posiciones ideológicas (el nordicismo).

Nació como un concepto filológico, dada la identificación que la filología comparada comenzó a hacer entre un gran conjunto de lenguas actualmente habladas desde la India hasta Europa. Se suele citar a William Jones como primera persona que observó los paralelismos entre el latín, el griego clásico y el sánscrito, y dedujo que estas lenguas, y otras, derivaban de un antecesor común.

El concepto de "indoeuropeo" pasó a aplicarse también a los pueblos históricos que originariamente hablaron esas lenguas (pueblos indoeuropeos), a su sociedad (sociedad indoeuropea), a su religión (religión indoeuropea) y a su cultura (cultura indoeuropea).

De forma intercambiable se utilizaban los términos indogermano o indogermánico, especialmente en el ámbito de habla alemana, aunque se acuñó inicialmente en francés. El término "indoeuropeo" se empleó inicialmente en inglés. Diferentes denominaciones usadas para el mismo concepto fueron jafético u otras relativas a lo sánscrito, a lo celta (indocelta), a lo ario (arioeuropeo) o a lo tocario.

Los conceptos indoario, indoiranio e indohitita son utilizados de una manera diferenciada, pero confluyente.

No debe confundirse, en cambio, con el concepto de lo indogriego, completamente diferente, pues se refiere a la influencia helenística en la India posterior a Alejandro Magno.

Hay muy distintas hipótesis sobre la ubicación inicial, en el tiempo y en el espacio (alrededor de 4000 a. C., en el entorno de la extensa zona esteparia entre la Europa suroriental y el Asia central -"Urheimat"-) de las que debieron ser "primeras" manifestaciones de lo indoeuropeo: lo protoindoeuropeo; y con ellas, la denominada lengua protoindoeuropea, el pueblo o conjunto de pueblos que la hablarían (pueblo protoindoeuropeo) y la reconstrucción arqueológica de sus posibles rasgos culturales y sociales (religión protoindoeuropea, cultura protoindoeuropea, sociedad protoindoeuropea).
Ambos términos (indoeuropeo y protoindoeuropeo) se usan especialmente en oposición al de preindoeuropeo, que designa al sustrato anterior al de la llegada de los indoeuropeos (o en su caso preindoeuropeos), tanto en India como en Europa o en Anatolia. Para el caso de la protohistoria de España, el término "preindoeuropeo" identifica al área del sur y el este peninsular (Tartessos y el área cultural de los iberos), mientras que el término "indoeuropeo" identifica al área del centro, oeste y norte (identificado a grandes rasgos con el área cultural de lo celta), con la notable excepción de los vascones, de lengua preindoeuropea (el antecedente del euskera).
Por similitud con los conceptos de romanización o arabización, se utiliza el concepto de indoeuropeización para designar a la aculturación que se produjo como consecuencia del contacto con los pueblos indoeuropeos o protoindoeuropeos.

Entre los más importantes indoeuropeístas (los dedicados a estudios indoeuropeos, especialmente la filología indoeuropea) están William Jones, Rasmus Rask, Franz Bopp, Friedrich Schlegel, Jakob Grimm, Georges Dumézil, y Ferdinand de Saussure;, Émile Benveniste, Jerzy Kuryłowicz, André Martinet, Winfred P. Lehmann, Tamaz V. Gamkrelidze y entre los hispanohablantes Francisco García Ayuso, Antonio Tovar, Francisco Rodríguez Adrados y Francisco Villar Liébana.

Como consecuencia del empleo diferente que puede darse al concepto (científico o pseudocientífico), muy diferentes instituciones llevan el nombre de "estudios indoeuropeos":


</doc>
<doc id="1533" url="https://es.wikipedia.org/wiki?curid=1533" title="Ictiología">
Ictiología

La ictiología es una rama de la zoología dedicada al estudio de los peces. Esta incluye los osteíctios (peces óseos), los condrictios (peces cartilaginosos, tales como el tiburón y la raya) y los agnatos (peces sin mandíbula). Se estima que hay alrededor de 32.700 especies descritas y que cada año son descritas oficialmente 250 nuevas especies. La dificultad en la clasificación radica en la gran variedad que han alcanzado durante el proceso evolutivo y la accesibilidad de los humanos al medio acuático. Por otra parte la ictiología además se ocupa de la biología y comportamiento de los peces.

Las primeras descripciones científicas de peces fueron hechas por Aristóteles, quien mencionó varios. Guillaume Rondelet publicó su "De Piscibus Marinum" describiendo 244 especies. Durante el 1600, los exploradores encontraron nuevos tipos de peces; George Markgraf, en su "Naturalis Brasilae", añadió 100 especies más y en 1686, la "Historia Piscium" de John Ray y Francis Willughby describía más de 400.

El título de "padre de la ictiología" se le atribuye a Peter Artedi , un estudiante de Linneo que identificó cinco órdenes de peces (incluidos cetáceos) y los dividió en géneros. Artedi se ahogó accidentalmente en un canal de Ámsterdam y Linneo publicó sus manuscritos de forma póstuma.

Durante los siglos XVIII y XIX, una constante corriente de especímenes provenientes de todo el mundo inundaron los museos.

En la década de 1780, Marcus Elieser Bloch publicó "Ichthyologia" como una serie de volúmenes de láminas y, tras su muerte, su asociado Johann Gottlob Schneider publicaría el "M. E. Blochii Systemae Ichthyologiae", describiendo 1.519 especies.

La obra "Regne animal distribué d'après son organisation" de Georges Cuvier, publicada entre 1817-1830 fue un paso clave para la clasificación de los peces. Cuvier trabajó con su estudiante Achille Valenciennes para sacar los 22 volúmenes de "Histoire Naturelle des Poissons" en la década de 1830 -que aunque nunca fue completada, describía 4.514 especies.

Albert Günther publicó su "Catalogue of the Fishes of the British Museum" entre 1859 y 1870, describiendo más de 6.800 especies y citando otras 1.700.
Se considera como el más grande ictiólogo de principios del siglo XX a David Starr Jordan, que escribió 650 libros y artículos sobre la materia, además de ocupar el cargo de presidente de la Universidad de Indiana y la Universidad de Stanford.

Cabe hacer mención a la técnica de la Ictioterapia, técnica oriental, mediante la cual una legión de peces remo masajearan toda la epidermis del sujeto en busca de impurezas de las que alimentarse.



</doc>
<doc id="1535" url="https://es.wikipedia.org/wiki?curid=1535" title="Jesús de Nazaret">
Jesús de Nazaret

Jesús de Nazaret, también llamado Cristo, Jesucristo o simplemente Jesús, (provincia de Judea, Imperio romano; ca. 4 a. C.—Jerusalén, Imperio romano; 30-33 d. C.) fue un predicador y líder religioso judío del siglo. Es la figura central del cristianismo y una de las más influyentes de la historia.

Prácticamente todos los historiadores de la Edad Antigua afirman la existencia histórica de Jesús. Según la opinión mayoritariamente aceptada en medios académicos, basada en una lectura crítica de los textos sobre su persona, Jesús de Nazaret fue un predicador judío que vivió a comienzos del siglo en las regiones de Galilea y Judea, y fue crucificado en Jerusalén en torno al año 30, bajo el gobierno de Poncio Pilato.

La figura de Jesús está presente en varias religiones. Para la mayoría de las ramas del cristianismo, es el Hijo de Dios y, por extensión, la encarnación de Dios mismo. Su importancia estriba asimismo en la creencia de que, con su muerte y posterior resurrección, redimió al género humano. El judaísmo niega su divinidad, ya que es incompatible con su concepción de Dios. En el islam, donde se lo conoce como Isa, es considerado uno de los profetas más importantes, rechazando al mismo tiempo su divinidad. Las enseñanzas bahá'ís consideran a Jesús como una "manifestación de Dios", un concepto bahá'í para los profetas. Algunos hindúes consideran que Jesús es un avatar o un sadhu. Algunos budistas, incluido Tenzin Gyatso, el decimocuarto dalái lama, consideran a Jesús como un bodhisattva que dedicó su vida al bienestar de las personas.

Lo que se conoce de Jesús procede casi exclusivamente de la tradición cristiana —aunque se le menciona en fuentes no cristianas—, especialmente de la utilizada para la composición de los evangelios sinópticos, redactados, según opinión mayoritaria, unos treinta o cuarenta años, como mínimo, después de su muerte. La mayoría de los estudiosos considera que mediante el estudio de los evangelios es posible reconstruir tradiciones que se remontan a contemporáneos de Jesús, aunque existen grandes discrepancias entre los investigadores en cuanto a los métodos de análisis de los textos y las conclusiones que de ellos pueden extraerse.

Lo que figura a continuación es un relato de la vida de Jesús tal y como aparece en los cuatro evangelios incluidos en el "Nuevo Testamento", considerados libros sagrados por todas las confesiones cristianas. El relato evangélico es la fuente principal para el conocimiento de Jesús, y constituye la base de las interpretaciones que de su figura hacen las diferentes ramas del cristianismo. Aunque puede contener elementos históricos, expresa fundamentalmente la fe de las comunidades cristianas en la época en que estos textos fueron escritos, y la visión que por entonces tenían de Jesús de Nazaret.

Los relatos referentes al nacimiento e infancia de Jesús proceden exclusivamente del Evangelio de Mateo (1,18-2,23) y del de Lucas (1,5-2,52).
No hay relatos de este tipo en los Evangelios de Marcos y Juan. Las narraciones de Mateo y Lucas difieren entre sí:



En los Evangelios de Mateo y de Lucas aparecen sendas genealogías de Jesús (Mt 1, 2-16; Lc 3, 23-38).
La de Mateo se remonta al patriarca Abraham, y la de Lucas a Adán, el primer hombre según el Génesis. Estas dos genealogías son idénticas entre Abrahán y David, pero difieren a partir de este último, ya que la de Mateo hace a Jesús descendiente de Salomón, mientras que, según Lucas, su linaje procedería de Natam, otro de los hijos de David. En ambos casos, lo que se muestra es la ascendencia de José, a pesar de que, según los relatos de la infancia, este solo habría sido el padre adoptivo de Jesús.

La llegada de Jesús fue profetizada por Juan el Bautista (su primo, según el Evangelio de Lucas), por quien Jesús fue bautizado en el río Jordán.
Durante el bautismo, el Espíritu de Dios, en forma de paloma, descendió sobre Jesús, y se escuchó la voz de Dios.

Según los evangelios sinópticos, el Espíritu condujo a Jesús al desierto, donde ayunó durante cuarenta días y superó las tentaciones a las que fue sometido por el Demonio.
No se menciona este episodio en el Evangelio de Juan. Después Jesús marchó a Galilea, se estableció en Cafarnaún, y comenzó a predicar la llegada del Reino de Dios.

Acompañado por sus seguidores, Jesús recorrió las regiones de Galilea y Judea predicando el evangelio y realizando numerosos milagros. El orden de los hechos y dichos de Jesús varía según los diferentes relatos evangélicos. Tampoco se indica cuánto tiempo duró la vida pública de Jesús, aunque el Evangelio de Juan menciona que Jesús celebró la fiesta anual de la Pascua judía (Pésaj) en Jerusalén en tres ocasiones. En cambio los evangelios sinópticos mencionan solo la fiesta de Pascua en la que Jesús fue crucificado.

Gran parte de los hechos de la vida pública de Jesús narrados en los evangelios, tienen como escenario la zona septentrional de Galilea, en las cercanías del mar de Tiberíades, o lago de Genesaret, especialmente la ciudad de Cafarnaúm, pero también otras, como Corozaín o Betsaida.
También visitó, en el sur de la región, localidades como Caná o Naín, y la aldea en la que se había criado, Nazaret, donde fue recibido con hostilidad por sus antiguos convecinos.
Su predicación se extendió también a Judea (según el Evangelio de Juan, visitó Jerusalén en tres ocasiones desde el comienzo de su vida pública), y estuvo en Jericó y Betania (donde resucitó a Lázaro).

Escogió a sus principales seguidores (llamados en los evangelios «apóstoles»; en griego, ‘enviados’), en número de doce, de entre el pueblo de Galilea. En los sinópticos se menciona la lista siguiente: Simón, llamado Pedro y su hermano Andrés; Santiago el de Zebedeo y su hermano Juan; Felipe y Bartolomé; Tomás y Mateo el publicano; Santiago el de Alfeo y Tadeo; Simón el Zelote y Judas Iscariote, el que posteriormente traicionaría a Jesús (Mt 10,2-4; Mc 3,16-19; Lc 6, 13-16).
Algunos de ellos eran pescadores, como las dos parejas de hermanos formadas respectivamente por Pedro y Andrés, y Juan y Santiago.
Mateo se identifica generalmente con Leví el de Alfeo, un publicano de quien en los tres sinópticos se relata brevemente cómo fue llamado por Jesús (Mt 9,9; Mc 2,14; Lc 5,27-28). lo que acarreó a Jesús numerosos reproches de los fariseos.

El Evangelio de Juan solo menciona los nombres de nueve de los apóstoles, aunque en varios pasajes hace referencia a que eran doce.

Predicó tanto en sinagogas como al aire libre, y las muchedumbres se congregaban para escuchar sus palabras. Entre sus discursos, destaca el llamado Sermón de la Montaña, en el Evangelio de Mateo (Mt 5-7). Utilizó a menudo parábolas para explicar a sus seguidores el Reino de Dios. Las parábolas de Jesús son breves relatos cuyo contenido es enigmático (a menudo han de ser después explicadas por Jesús). Tienen en general un contenido escatológico y aparecen exclusivamente en los evangelios sinópticos. Entre las más conocidas están la parábola del sembrador (Mt 13,3-9; Mc 4,3-9; Lc 8,5-8), cuyo significado explica Jesús a continuación; la de la semilla que crece (Mc 4,26-29); la del grano de mostaza (Mt 13,31-32; Mc 4,30-32), la del trigo y la cizaña (Mt 13,24-30), la de la oveja perdida (Mt 18,12-14; Lc 15,3-7) y la de la moneda perdida (Lc 15,8-10), la del siervo despiadado (Mt 18, 23-35), la de los obreros enviados a la viña (Mt 20,1-16), la de los dos hijos (Mt 21,28-32), la de los viñadores homicidas (Mt 21,33-42; Mc 12,1-11; Lc 20,9-18); la de los invitados a la boda (Mt 22, 1-14), la de las diez vírgenes (Mt 25,1-13), la de los talentos (Mt 25,14-30; Lc 19,12-27), la del juicio final (Mt 25,31-46). Dos de las más conocidas aparecen solo en el Evangelio de Lucas: se trata de la parábola del buen samaritano (Lc 10,30-37) y la del hijo pródigo (Lc 15,11-32). En las parábolas, utiliza Jesús frecuentemente imágenes relacionadas con la vida campesina.

Mantuvo controversias con miembros de algunas de las más importantes sectas religiosas del judaísmo, y muy especialmente con los fariseos, a quienes acusó de hipocresía y de no cuidar lo más importante de la Torá: la justicia, la compasión y la lealtad (Mt 12, 38-40; Lc 20, 45-47).

La originalidad de su mensaje radicaba en la insistencia en el amor a los enemigos (Mt 5,38-48; Lc 6, 27-36) así como en su relación estrechísima con Dios, a quien llamaba en arameo con la expresión familiar "Abba" (Padre) que ni Marcos (Mc 14,36) ni Pablo (Rm 8, 15; Gal 4, 6) traducen. Se trata de un dios cercano que busca a los marginados, a los oprimidos (Lc 4, 18) y a los pecadores (Lc 15) para ofrecerles su misericordia. La oración del Padre nuestro (Mt 6,9-13: Lc 11,1-4), que recomendó utilizar a sus seguidores, es clara expresión de esta relación de cercanía con Dios antes mencionada.

Según los evangelios, durante su ministerio Jesús realizó varios milagros. En total, en los cuatro evangelios canónicos se narran veintisiete milagros, de los cuales catorce son curaciones de distintas enfermedades, cinco exorcismos, tres resurrecciones, dos prodigios de tipo natural y tres signos extraordinarios.



Además, hay varios pasajes que hacen referencia de modo genérico a exorcismos de Jesús (Mc 1,32-34;Mc 3,10-12).



En esos tiempos, los escribas, fariseos y otros, atribuyeron a una confabulación con Belcebú este poder de expulsar a los demonios. Jesús se defendió enérgicamente de estas acusaciones.
Según los relatos evangélicos, Jesús no solo tenía el poder de expulsar demonios, sino que transmitió ese poder a sus seguidores.
Incluso se menciona el caso de un hombre que, sin ser seguidor de Jesús, expulsaba con éxito demonios en su nombre.

Los evangelios sinópticos relatan que Jesús subió a un monte a orar con algunos de los apóstoles, y mientras oraba se transformó el aspecto de su rostro, y su vestido se volvió blanco y resplandeciente. Aparecieron junto a él Moisés y Elías. Los apóstoles dormían mientras tanto, pero al despertar vieron a Jesús junto a Moisés y Elías. Pedro sugirió que hicieran tres tiendas: para Jesús, Moisés y Elías. Entonces apareció una nube y se oyó una voz celestial, que dijo: «Este es mi Hijo elegido, escuchadle». Los discípulos no contaron lo que habían visto.

Según los cuatro evangelios, Jesús fue con sus seguidores a Jerusalén para celebrar allí la fiesta de Pascua. Entró a lomos de un asno, para que se cumplieran las palabras del profeta Zacarías (Zc 9, 9: «He aquí que tu rey viene a ti, manso y montado sobre un asno, sobre un pollino hijo de una bestia de carga»). Fue recibido por una multitud, que lo aclamó como «hijo de David» (en cambio según el Evangelio de Lucas fue aclamado solamente por sus discípulos).
En el Evangelio de Lucas y en el de Juan, Jesús es aclamado como rey.

Según los evangelios sinópticos, a continuación fue al Templo de Jerusalén, y expulsó de allí a los cambistas y a los vendedores de animales para los sacrificios rituales (el Evangelio de Juan, en cambio, sitúa este episodio al comienzo de la vida pública de Jesús, y lo relaciona con una profecía sobre la destrucción del Templo).
Vaticinó la destrucción del Templo y otros acontecimientos futuros.

En Betania, cerca de Jerusalén, fue ungido con perfumes por una mujer.
Según los sinópticos, la noche de Pascua cenó en Jerusalén con los Apóstoles, en lo que la tradición cristiana designa como la Última Cena. En el transcurso de esta cena pascual, Jesús predijo que sería traicionado por uno de los Apóstoles, Judas Iscariote. Tomó pan en las manos, diciendo «Tomad y comed, este es mi cuerpo» y, a continuación, cogiendo un cáliz de vino, dijo: «Bebed de él todos, porque esta es la sangre de la Alianza, que será derramada por la multitud para la remisión de los pecados».
Profetizó también, según los sinópticos, que no volvería a beber vino hasta que no lo bebiera de nuevo en el Reino de Dios.

Tras la cena, según los sinópticos, Jesús y sus discípulos fueron a orar al huerto de Getsemaní. Los apóstoles, en lugar de orar, se quedaron dormidos, y Jesús sufrió un momento de fuerte angustia con respecto a su destino, aunque decidió acatar la voluntad de Dios.

Judas había efectivamente traicionado a Jesús, para entregarlo a los príncipes de los sacerdotes y los ancianos de Jerusalén a cambio de treinta piezas de plata.
Acompañado de un grupo armado de espadas y garrotes, enviado por los príncipes de los sacerdotes y los ancianos, llegó a Getsemaní y reveló la identidad de Jesús besándole la mejilla. Jesús fue arrestado. Por parte de sus seguidores hubo un conato de resistencia, pero finalmente todos se dispersaron y huyeron.

Tras su detención, Jesús fue llevado al palacio del sumo sacerdote Caifás. Allí fue juzgado ante el Sanedrín. Se presentaron falsos testigos, pero como sus testimonios no coincidían no fueron aceptados. Finalmente, Caifás preguntó directamente a Jesús si era el Mesías, y Jesús dijo: «Tú lo has dicho». El sumo sacerdote se rasgó las vestiduras ante lo que consideraba una blasfemia. Los miembros del Sanedrín escarnecieron cruelmente a Jesús.
En el Evangelio de Juan, Jesús fue llevado primero ante Anás, suegro de Caifás, y luego ante este último. Solo se detalla el interrogatorio ante Anás, bastante diferente del que aparece en los sinópticos.
Pedro, que había seguido a Jesús en secreto tras su detención, se encontraba oculto entre los sirvientes del sumo sacerdote. Reconocido como discípulo de Jesús por los sirvientes, le negó tres veces (dos según el Evangelio de Juan), como Jesús le había profetizado.

A la mañana siguiente, Jesús fue llevado ante Poncio Pilato, el procurador romano. Tras interrogarle, Pilato no le halló culpable, y pidió a la muchedumbre que eligiera entre liberar a Jesús o a un conocido bandido, llamado Barrabás. La multitud, persuadida por los príncipes de los sacerdotes, pidió que se liberase a Barrabás, y que Jesús fuese crucificado. Pilato se lavó simbólicamente las manos para expresar su inocencia de la muerte de Jesús.

Jesús fue azotado, lo vistieron con un manto rojo, le pusieron en la cabeza una corona de espinas y una caña en su mano derecha. Los soldados romanos se burlaban de él diciendo: «Salud, rey de los judíos».
Fue obligado a cargar la cruz en la que iba a ser crucificado hasta un lugar llamado Gólgota, que en arameo significa ‘lugar del cráneo’. Le ayudó a llevar la cruz un hombre llamado Simón de Cirene.

Dieron de beber a Jesús vino con hiel. Él probó pero no quiso tomarlo. Tras crucificarlo, los soldados se repartieron sus vestiduras. En la cruz, sobre su cabeza, pusieron un cartel en arameo, griego y latín con el motivo de su condena: «Este es Jesús, el rey de los judíos», que a menudo en pinturas se abrevia INRI ("Iesus Nazarenus Rex Iudaeorum", literalmente ‘Jesús de Nazaret, rey de los judíos’). Fue crucificado entre dos ladrones.

Hacia las tres de la tarde, Jesús exclamó: «Elí, Elí, lemá sabactani», que, según el Evangelio de Mateo y el Evangelio de Marcos, en arameo significa: ‘Dios mío, Dios mío, ¿por qué me has abandonado?’.
Las palabras finales de Jesús difieren en los otros dos evangelios. También hay diferencia entre los evangelios en cuanto a qué discípulos de Jesús estuvieron presentes en su crucifixión: en Mateo y Marcos, son varias de las mujeres seguidoras de Jesús; en el Evangelio de Juan se menciona también a la madre de Jesús y al «discípulo a quien amaba» (según la tradición cristiana, se trataría del apóstol Juan, aunque en el texto del evangelio no se menciona su nombre).

Un seguidor de Jesús, llamado José de Arimatea, solicitó a Pilato el cuerpo de Jesús la misma tarde del viernes en que había muerto, y lo depositó, envuelto en una sábana, en un sepulcro excavado en la roca. Cubrió el sepulcro con una gran piedra.
Según el Evangelio de Mateo (no se menciona en los otros evangelios), al día siguiente, los «príncipes de los sacerdotes y los fariseos» pidieron a Pilato que colocase frente al sepulcro una guardia armada, para evitar que los seguidores de Jesús robasen su cuerpo y difundieran el rumor de que había resucitado. Pilato accedió.

Los cuatro evangelios relatan que Jesús resucitó de entre los muertos al tercer día después de su muerte y se apareció a sus discípulos en varias ocasiones.
En todos ellos, la primera en descubrir la resurrección de Jesús es María Magdalena. Dos de los evangelios (Marcos y Lucas) relatan también su ascensión a los cielos. Los relatos sobre Jesús resucitado varían, sin embargo, según los evangelios:





Según los autores del Nuevo Testamento, la vida de Jesús supuso el cumplimiento de algunas profecías formuladas en ciertos libros del Antiguo Testamento. Los libros bíblicos más citados en este sentido por los primeros cristianos fueron Isaías, Jeremías, los Salmos, Zacarías, Miqueas y Oseas. Para los autores del Nuevo Testamento, en una visión compartida por los cristianos posteriores, en estos textos se anuncia la venida de Jesús de Nazaret, que sería el Mesías que esperaba el pueblo de Israel. A menudo los redactores de los evangelios, sobre todo el autor del Evangelio de Mateo, citan explícitamente estos textos para subrayar el cumplimiento de estas profecías en la vida y muerte de Jesús. Entre otras cosas, consideran que fueron profetizadas las circunstancias y el lugar de nacimiento de Jesús (Is 7,14; Miq 5,2); su relación con Galilea (Is 9,1); su condición mesiánica (Is 9, 6-7; Is 11, 1-9; Is 15, 5); el papel de precursor de Juan el Bautista (Is 40,3) e incluso su pasión y muerte sacrificial (a este respecto se citan sobre todo cuatro poemas, incluidos en el Deutero Isaías (o Segundo Isaías), que presentan la figura de un siervo de Yahvé, a cuyo sacrificio se atribuye un valor redentor, pero también otros muchos pasajes.

Los judíos, que también consideran sagrados estos libros, no aceptan la creencia cristiana de que estas profecías se refieren a Jesús de Nazaret. Para la investigación histórica actual, el principal interrogante es hasta qué punto estos libros contribuyeron a moldear los relatos evangélicos.

A diferencia de lo que ocurre con otros personajes de la Antigüedad, pero al igual que sucede con otros muchos, no existen evidencias arqueológicas que permitan verificar la existencia de Jesús de Nazaret. La explicación principal que se da a este hecho es que Jesús no alcanzó mientras vivía una relevancia suficiente como para dejar constancia en fuentes arqueológicas, dado que no fue un importante líder político, sino un sencillo predicador itinerante.
Si bien los hallazgos de la arqueología no pueden ser aducidos como prueba de la existencia de Jesús de Nazaret, sí confirman la historicidad de gran número de personajes, lugares y acontecimientos descritos en las fuentes.

Por otro lado, Jesús, como muchos destacados dirigentes religiosos y filósofos de la Antigüedad, no escribió nada, o al menos no hay constancia alguna de que así haya sido. Todas las fuentes para la investigación histórica de Jesús de Nazaret son, por lo tanto, textos escritos por otros autores. El más antiguo documento inequívocamente concerniente a Jesús de Nazaret es el llamado "Papiro P52", que contiene un fragmento del Evangelio de Juan y que data, según los cálculos más extendidos, del 125 aproximadamente (es decir, casi un siglo después de la fecha posible de la muerte de Jesús, hacia el año 30).

Si bien los testimonios materiales referentes a la vida de Jesús son muy tardíos, la investigación filológica ha logrado reconstruir la historia de estos textos con un alto grado de probabilidad, lo que arroja como conclusión que los primeros textos sobre Jesús (algunas cartas de Pablo) son posteriores en unos veinte años a la fecha probable de su muerte, y que las principales fuentes de información acerca de su vida (los evangelios canónicos) se redactaron en la segunda mitad del siglo I. Existe un amplio consenso acerca de esta cronología de las fuentes, al igual que es posible datar algunos (muy escasos) testimonios acerca de Jesús en fuentes no cristianas entre la última década del siglo I y el primer cuarto del siglo II.

En el estado actual de conocimientos acerca de Jesús de Nazaret, la opinión predominante en medios académicos es que se trata de un personaje histórico, cuya biografía y mensaje experimentaron modificaciones por parte de los redactores de las fuentes. Existe, sin embargo, una minoría de estudiosos que, desde una crítica radical de las fuentes, consideran probable que Jesús ni siquiera fuese un personaje histórico real, sino una entidad mítica, similar a otras figuras objeto de culto en la Antigüedad.

Son sobre todo las fuentes cristianas, obviamente parciales, las que proporcionan información sobre Jesús de Nazaret. Los textos cristianos reflejan principalmente la fe de las comunidades primitivas, y no pueden considerarse, sin más, documentos históricos.

Los textos en los que la crítica actual cree posible hallar información acerca del Jesús histórico son, principalmente, los tres evangelios sinópticos (Mateo, Marcos y Lucas). Secundariamente, proporcionan también información acerca de Jesús de Nazaret otros escritos del Nuevo Testamento (el Evangelio de Juan, las epístolas de Pablo de Tarso), algunos evangelios apócrifos (como el de "Tomás" y el de "Pedro)", y otros textos cristianos.

Por otro lado, existen referencias a Jesús en unas pocas obras no cristianas. En algunos casos se ha puesto en duda su autenticidad (Flavio Josefo), o que se refieran al mismo personaje cuya vida relatan las fuentes cristianas (Suetonio). Apenas aportan alguna información, excepto que fue crucificado en tiempos de Poncio Pilato (Tácito) y que fue considerado un embaucador por los judíos ortodoxos.

Son muy numerosos los escritos cristianos de los siglos I y II en los que se encuentran referencias a Jesús de Nazaret. Sin embargo, solo una pequeña parte de los mismos contiene información útil acerca de él. Todos ellos reflejan, en primer lugar, la fe de los cristianos de la época, y solo secundariamente revelan información biográfica sobre Jesús.

Los principales son:


Los textos más antiguos conocidos relativos a Jesús de Nazaret son las cartas escritas por Pablo de Tarso, consideradas anteriores a los evangelios. Pablo no conoció personalmente a Jesús. Su conocimiento de él y de su mensaje, según sus propias afirmaciones, puede provenir de una doble fuente: por un lado, sostiene en sus escritos que se le apareció el propio Jesús resucitado para revelarle su evangelio, una revelación a la que Pablo concedía gran importancia (Gal 1, 11-12); por otro, también según su propio testimonio, mantuvo contactos con miembros de varias comunidades cristianas, entre ellos varios seguidores de Jesús. Conoció, según él mismo afirma en la "Epístola a los Gálatas", a Pedro (Gal 2, 11-14), Juan (Gal 2, 9), y Santiago, al que se refiere como «hermano del Señor» (Gal 1, 18-19; 1 Cor 15, 7).

Aunque la tradición cristiana atribuye a Pablo catorce epístolas incluidas en el Nuevo Testamento, solo existe consenso entre los investigadores actuales en cuanto a la autenticidad de siete de ellas, que se datan generalmente entre los años 50 y 60 (Primera epístola a los tesalonicenses, Epístola a los filipenses, Epístola a los gálatas, Primera epístola a los corintios, Segunda epístola a los corintios, Epístola a los romanos y Epístola a Filemón). Estas epístolas son cartas dirigidas por Pablo a comunidades cristianas de diferentes lugares del Imperio romano, o a individuos particulares. En ellas se tratan fundamentalmente aspectos doctrinales del cristianismo. Pablo se interesa sobre todo por el sentido sacrificial y redentor que según él tienen la muerte y resurrección de Jesús, y son escasas sus referencias a la vida de Jesús o al contenido de su predicación.

Sin embargo, las epístolas paulinas sí proporcionan alguna información. En primer lugar, se afirma en ellas que Jesús nació «según la Ley» y que era del linaje de David, «según la carne» (Rom 1, 3), y que los destinatarios de su predicación eran los judíos circuncisos (Rom 15, 8). En segundo lugar, refiere ciertos detalles acerca de su muerte: indica que murió crucificado (2 Cor 13, 4), que fue sepultado y que resucitó al tercer día (1 Cor 15,3-8), y atribuye su muerte a los judíos (1 Tes 2, 14) y también a los «poderosos de este mundo» (1 Cor 2, 8). Además, la Primera epístola a los corintios contiene un relato de la Última Cena (1 Cor 11, 23-27), semejante al de los evangelios sinópticos (Mt 26, 26-29; Mc 14, 22-25; Lc 22, 15-20), aunque probablemente más antiguo.

Los estudiosos están de acuerdo en que la principal fuente de información acerca de Jesús se encuentra en tres de los cuatro evangelios incluidos en el Nuevo Testamento, los llamados sinópticos: Mateo, Marcos y Lucas, cuya redacción se sitúa generalmente entre los años 70 y 100.

El punto de vista dominante en la crítica actual es que los evangelios no fueron escritos por testigos personales de la actividad de Jesús. Se cree que fueron escritos en griego por autores que no tenían conocimiento directo del Jesús histórico. Algunos autores, sin embargo, continúan manteniendo el punto de vista tradicional sobre esta cuestión, que los atribuye a personajes citados en el Nuevo Testamento.

Aunque no es aceptada por la totalidad de los críticos, las afinidades entre estos evangelios suelen ser explicadas por la llamada teoría de las dos fuentes, propuesta ya en 1838 por Ch. Weisse, y que fue luego significativamente matizada por B. H. Streeter en 1924. Según esta teoría, el evangelio más antiguo es Marcos (y no Mateo, como se creía anteriormente). Tanto Lucas como Mateo son posteriores, y utilizaron como fuente Marcos, lo que explica el material común entre los tres sinópticos, denominado «de triple tradición». Pero, además, existió una segunda fuente, a la que se dio el nombre de Q, que contenía casi exclusivamente palabras de Jesús, lo cual explica el llamado material de doble tradición, que se encuentra en Mateo y Lucas, pero no en Marcos (Q es hoy considerado un documento independiente, del que incluso existen ediciones críticas).
Por último, tanto Lucas como Mateo contienen material propio, que no se encuentra en ninguna de las dos fuentes hipotéticas.

El grado de fiabilidad que se concede a los evangelios depende de los estudiosos. La opinión más extendida es que son principalmente textos apologéticos, es decir, de propaganda religiosa, cuya intención principal es difundir una imagen de Jesús acorde con la fe de las primitivas comunidades cristianas, pero que contienen, en mayor o menor medida, datos acerca del Jesús histórico. Se ha demostrado que contienen varios errores históricos y geográficos, numerosas incongruencias narrativas y abundantes elementos sobrenaturales que son sin duda expresiones de fe y de los que se discute si tienen o no un origen histórico. Sin embargo, sitúan a Jesús en un marco histórico verosímil, en general acorde con lo conocido mediante fuentes no cristianas, y esbozan una trayectoria biográfica bastante coherente.

La corriente de investigación llamada «historia de las formas», cuyos máximos representantes fueron Rudolf Bultmann y Martin Dibelius, se orientó sobre todo a estudiar la «prehistoria» literaria de los evangelios. Estos autores determinaron que los evangelios (incluido Q, considerado como un «protoevangelio») son compilaciones de unidades literarias menores, denominadas perícopas, que pertenecen a géneros literarios diferentes (narraciones de milagros, diálogos didácticos, enseñanzas éticas, etc.). Estas perícopas tienen su origen último en la tradición oral sobre Jesús, pero solo algunas de ellas se refieren a dichos y hechos verdaderos del Jesús histórico. Más adelante, otra escuela, denominada «historia de la redacción» (o crítica de la redacción), destacó el hecho de que, a la hora de compilar y unificar narrativamente el material de que disponían, los autores de los evangelios respondían a motivaciones teológicas.

Para datar los evangelios sinópticos, un aspecto de particular importancia son las referencias a la destrucción del Templo de Jerusalén. Estudiando estas referencias, la mayoría de los autores coinciden en afirmar que los tres sinópticos, en su estado actual, son posteriores a la destrucción del templo (año 70), en tanto que Q es muy probablemente anterior.

Los autores de los evangelios responden a motivaciones teológicas concretas. En sus obras, intentan armonizar las tradiciones recibidas acerca del Jesús histórico con la fe de las comunidades a las que pertenecen.





Generalmente se considera que el Evangelio de Juan es más tardío que los sinópticos (suele datarse en torno al año 100) y que la información que ofrece acerca del Jesús histórico es menos fiable. Muestra una teología más desarrollada, ya que presenta a Jesús como un ser preexistente, sustancialmente unido a Dios, enviado por él para salvar al género humano.
Sin embargo, parece que su autor utilizó fuentes antiguas, en algunos casos independientes de los sinópticos, por ejemplo, en lo relativo a la relación entre Jesús y Juan el Bautista, y al proceso y ejecución de Jesús.
Relata pocos milagros de Jesús (solo siete), para los que posiblemente utilizó como fuente un hipotético "Evangelio de los Signos". En este evangelio son muy numerosas las escenas de la vida de Jesús que no tienen un paralelo en los sinópticos (entre ellas, algunas de las más conocidas, como las bodas de Caná o la resurrección de Lázaro de Betania).

Se denomina evangelios apócrifos a aquellos textos sobre hechos o dichos de Jesús no incluidos en el canon del Nuevo Testamento. Como señala Antonio Piñero, la mayor parte de los apócrifos no aportan información válida sobre el Jesús histórico, ya que se trata de textos bastante tardíos (posteriores a 150), y que utilizan como fuentes los evangelios canónicos.

Existen, sin embargo, algunas excepciones notables: el "Evangelio de Pedro", el "Papiro Egerton 2", los "Papiros de Oxirrinco" y, muy especialmente, el "Evangelio de Tomás".
Sobre la datación de estos textos no hay acuerdo entre los especialistas, pero la posición mayoritaria es que pueden contener información auténtica acerca de Jesús. Dado su carácter fragmentario, sin embargo, se han utilizado sobre todo para confirmar informaciones que también transmiten los evangelios canónicos.


La historicidad de estas referencias es considerada en general bastante dudosa.

Apenas hay menciones de Jesús en fuentes no cristianas de los siglos I y II. Ningún historiador se ocupó por extenso de su historia: solo existen alusiones de pasada, algunas de ellas ambiguas, y una de las de Flavio Josefo (el llamado «Testimonio flaviano») contiene posiblemente alguna interpolación posterior. Sin embargo, todas juntas bastan para certificar su existencia histórica.
Al respecto "The New Encyclopaedia Britannica" afirma: 

Estas fuentes pueden dividirse en:


El primer pasaje de la citada obra que menciona a Jesús es conocido con el nombre de «testimonio Flaviano». Se encuentra en "Antigüedades Judías", 18.3.3. Fue objeto de interpolaciones posteriores por copistas cristianos, y durante muchos años se debatió incluso si en su versión original Josefo aludía a Jesús. Este debate fue resuelto en 1971, al aparecer un manuscrito árabe del siglo X en el que el obispo Agapio de Hierápolis citaba ese texto de Josefo. Ya que la primera copia que se posee de Josefo (la de la Ambrosiana) data del siglo XI, un siglo más tarde, hay que admitir que el texto árabe, anterior, reproduce el de Josefo sin interpolaciones.

El segundo pasaje no ha solido ser discutido, ya que está estrechamente relacionado con el contexto de la obra y parece improbable que se trate de una interpolación. Se encuentra en "Antigüedades Judías", 20.9.1, y se refiere a la lapidación de Santiago, que el texto identifica como hermano de Jesús, un personaje que es llamado del mismo modo en algunos textos de Pablo de Tarso. Aunque sin consenso absoluto, para la mayor parte de los autores el pasaje es auténtico.


Breves menciones en sendas obras de Suetonio (c. 70-"post" 126), Tácito (61-117) y Plinio el Joven (62-113). Excepto el de Tácito, son más bien referencias a la actividad de los cristianos:


Existen algunos textos más, como el de Luciano de Samósata (segunda mitad del siglo II d.C.), que menciona a «aquel hombre a quien siguen adorando, que fue crucificado en Palestina... aquel sofista crucificado», u otro que, aunque es dudoso, podría ser una referencia a Jesús de Nazaret: se trata de una carta, conservada en siríaco, escrita por un tal Mara Bar-Serapion, en la que se habla de un «rey sabio» condenado a muerte por los judíos. No hay acuerdo sobre si esta carta data del siglo I, II o III de nuestra era, y tampoco está claro si es o no una referencia a Jesús de Nazaret.

La escasez de fuentes no cristianas sugiere que la actividad de Jesús no llamó la atención en su época, aunque según las fuentes cristianas su predicación habría congregado a multitudes. Las fuentes no cristianas aportan solo una imagen muy esquemática al conocimiento de Jesús como personaje histórico.

La investigación histórica de las fuentes cristianas sobre Jesús de Nazaret exige la aplicación de métodos críticos que permitan discernir las tradiciones que se remontan al Jesús histórico de aquellas que constituyen adiciones posteriores, correspondientes a las primitivas comunidades cristianas.

La iniciativa en esta búsqueda partió de investigadores cristianos. Durante la segunda mitad del siglo XIX, su aportación principal se centró en la historia literaria de los evangelios.

Los principales criterios sobre los que existe consenso a la hora de interpretar las fuentes cristianas son, según Antonio Piñero, los siguientes:






No todos los autores, sin embargo, interpretan del mismo modo estos criterios, e incluso hay quienes niegan la validez de algunos de ellos.

El pueblo judío, sin estado propio desde la destrucción del Primer Templo en , en tiempos de Nabucodonosor II, había pasado varias décadas sometido, sucesivamente, a babilonios, persas, la dinastía ptolemaica de Egipto y el Imperio seléucida, sin que se produjeran conflictos de gravedad. En el , sin embargo, el monarca seléucida Antíoco IV Epífanes, decidido a imponer la helenización del territorio, profanó el Templo (el Segundo Templo, reconstruido en época persa), lo que desencadenó una rebelión, acaudillada por una familia sacerdotal, los Macabeos, que tendría como consecuencia el establecimiento de un nuevo estado judío independiente, que duraría hasta el año 

En este año, el general romano Pompeyo intervino en la guerra civil que enfrentaba a dos hermanos de la dinastía asmonea, Hircano II y Aristóbulo II. Con esta intervención dio comienzo el dominio romano en Palestina. Dicho dominio, sin embargo, no se ejerció siempre de forma directa, sino mediante la creación de uno o varios estados clientes, que pagaban tributo a Roma y estaban obligados a aceptar sus directrices. El propio Hircano II fue mantenido por Pompeyo al frente del país, aunque no como rey, sino como etnarca. Posteriormente, tras un intento de recuperar el trono del hijo de Aristóbulo II, Antígono, quien fue apoyado por los partos, el hombre de confianza de Roma fue Herodes, quien no pertenecía a la familia de los asmoneos, sino que era hijo de Antípatro, un general de Hircano II de origen idumeo.

Tras su victoria sobre los partos y los seguidores de Antígono, Herodes fue nombrado rey de Judea por Roma en Su reinado, durante el cual, según opinión mayoritaria, tuvo lugar el nacimiento de Jesús de Nazaret, fue un período relativamente próspero.

A la muerte de Herodes, en , su reino se dividió entre tres de sus hijos: Arquelao fue designado etnarca de Judea, Samaria e Idumea; a Antipas (llamado Herodes Antipas en el Nuevo Testamento) le correspondieron los territorios de Galilea y Perea, que gobernó con el título de tetrarca; por último, Filipo heredó, también como tetrarca, las regiones más remotas: Batanea, Gaulanítide, Traconítide y Auranítide.

Estos nuevos gobernantes correrían diversa suerte. Mientras que Antipas se mantuvo en el poder durante cuarenta y tres años, hasta 39, Arquelao, debido al descontento de sus súbditos, fue depuesto en 6 d. C. por Roma, que pasó a controlar directamente los territorios de Judea, Samaría e Idumea.

En el período en que Jesús desarrolló su actividad, por lo tanto, su territorio de origen, Galilea, formaba parte del reino de Antipas, responsable de la ejecución de Juan el Bautista, y al que una tradición tardía, que solo se encuentra en el Evangelio de Lucas, hace jugar un papel secundario en el juicio de Jesús. Judea, en cambio, era administrada directamente por un funcionario romano, perteneciente al orden ecuestre, que llevó primero el título de prefecto (hasta el año 41) y luego (desde el 44) el de procurador. En el período de la actividad de Jesús, el prefecto romano era Poncio Pilato.

El prefecto no residía en Jerusalén, sino en Cesarea Marítima, ciudad de la costa mediterránea que había sido fundada por Herodes el Grande, aunque se desplazaba a Jerusalén en algunas ocasiones (por ejemplo, con motivo de la fiesta de Pésaj o Pascua, como se relata en los evangelios, ya que era en estas fiestas, que congregaban a miles de judíos, cuando solían producirse tumultos). Contaba con unos efectivos militares relativamente reducidos (unos 3.000 hombres), y su autoridad estaba supeditada a la del legado de Siria. En tiempos de Jesús, el prefecto tenía el derecho exclusivo de dictar sentencias de muerte "(ius gladii)".

Sin embargo, Judea gozaba de un cierto nivel de autogobierno. En especial, Jerusalén estaba gobernada por la autoridad del sumo sacerdote, y su consejo o Sanedrín. Las competencias exactas del Sanedrín son objeto de controversia, aunque en general se admite que, salvo en casos muy excepcionales, no tenían la potestad de juzgar delitos capitales.

Aunque separada de Judea por la historia, Galilea era en el siglo I una región de religión judía. Tenía, sin embargo, algunos rasgos diferenciales, como una menor importancia del Templo, y una menor presencia de sectas religiosas como los saduceos y los fariseos. Estaba muy expuesta a las influencias helenísticas y presentaba grandes contrastes entre el medio rural y el medio urbano.

Al este de Galilea se encontraban las diez ciudades de la Decápolis, situadas todas ellas al otro lado del río Jordán, a excepción de una, Escitópolis (llamada también Bet Shean). Al noroeste, Galilea limitaba con la región sirofenicia, con ciudades como Tiro, Sidón y Aco/Tolemaida. Al sudoeste se situaba la ciudad de Cesarea Marítima, lugar de residencia del prefecto (luego procurador) romano. Por último, al sur se encontraba otra importante ciudad, Sebaste, así llamada en honor al emperador Augusto.

En pleno corazón de Galilea se encontraban también dos importantes ciudades: Séforis, muy cercana (5 o 6 km) a la localidad de donde era originario Jesús, Nazaret; y Tiberíades, construida por Antipas y cuyo nombre era un homenaje al emperador Tiberio. Tiberíades era la capital de la monarquía de Antipas, y estaba muy próxima a Cafarnaún, ciudad que fue con probabilidad el centro principal de la actividad de Jesús.

Es importante destacar que las ciudades eran focos de influencia de la cultura helenística. En ellas residían las élites, en tanto que en el medio rural habitaba un campesinado empobrecido, del que procedía con toda probabilidad Jesús. Las ciudades eran en general favorables a Roma, como se demostró con ocasión de la primera guerra judeo-romana.

En las fuentes cristianas no se menciona que Jesús visitase ninguna de las ciudades de Galilea ni de su entorno. Sin embargo, dada la proximidad de Tiberíades a los principales lugares mencionados en los evangelios, es difícil pensar que Jesús se sustrajo por completo a la influencia helenística.

El medio campesino, del que procedía Jesús, veía con hostilidad las ciudades. Los campesinos de Galilea soportaban importantes cargas impositivas, tanto del poder político (la monarquía de Antipas), como del religioso (el Templo de Jerusalén), y su situación económica debió de ser bastante difícil.

Galilea fue la región judía más conflictiva durante el siglo I, y los principales movimientos revolucionarios antirromanos, desde la muerte de Herodes el Grande en 4 a. C. hasta la destrucción de Jerusalén en el año 70, se iniciaron en esta región. La lucha contra el Imperio romano fue, según el historiador Geza Vermes, «una actividad galilea general en el primer siglo d. C.».

En tiempos de Jesús, al igual que en la actualidad, el judaísmo era una religión monoteísta, basada en la creencia de un único Dios. Los judíos creían que Dios había elegido a su pueblo, Israel, y había establecido con él una alianza a través de Abraham y Moisés, principalmente. Los actos fundamentales de dicha alianza eran, para los judíos, la vocación de Abraham, el éxodo, y la promulgación de la ley en el Sinaí.
La fidelidad de los judíos a esta alianza se manifestaba, además de en su adoración a su único Dios, en la rigurosidad con que seguían los mandamientos y preceptos de la Torá, o la llamada Ley mosaica; esta regulaba todos los aspectos de la vida de los judíos, como la obligación de circuncidar a los hijos varones, la prohibición de trabajar en sábado, y otras ciertas reglas alimentarias (por ejemplo, la de no comer carne de cerdo) y de purificación.

En el siglo I, el centro del culto a Dios era el Templo de Jerusalén. Era necesario acudir a este tres veces al año (durante las llamadas fiestas de peregrinación), para realizar diversos sacrificios y entregar ofrendas. El culto del Templo era administrado por los sacerdotes y levitas, cuyo número era muy elevado, quienes desempeñaban los llamados oficios sagrados durante las fiestas, tales como custodiar y limpiar el Templo, preparar los animales y la leña para los sacrificios, y cantar salmos durante las celebraciones públicas.
Los sacerdotes y levitas se mantenían con los tributos de los campesinos, obligatorios para todos los judíos.

Pero el Templo no era el único lugar en que se rendía culto a Dios: en época de Jesús existía también la costumbre de reunirse cada sábado en las sinagogas. Mientras que el culto en el Templo estaba dominado por los sacerdotes, la costumbre de reunirse en las sinagogas fue promoviendo la religiosidad de los laicos.
Además, en las sinagogas no se llevaban a cabo sacrificios a diferencia del Templo, sino que tan solo se leían y comentaban los textos sagrados.

En la época de Jesús, existían sectas divergentes dentro del judaísmo. El autor que más información proporciona sobre este tema es Flavio Josefo. Este distingue entre tres sectas principales: la saducea, la esenia y la farisea. Esta última era bastante respetada por el pueblo y estaba constituida principalmente por laicos.

Los fariseos creían en la inmortalidad del alma y eran conocidos por el rigor con que interpretaban la ley, considerando a la tradición como fuente de esta. En cuanto a los saduceos, gran número de ellos formaba parte de la casta sacerdotal, pero en oposición a los fariseos, rechazaban la idea de que la tradición era fuente de ley y negaban también la inmortalidad del alma. Por último, el grupo de los esenios es considerado por la inmensa mayoría de los investigadores como el autor de los denominados manuscritos del Mar Muerto. Constituían una especie de monacato, cuyos seguidores eran estrictos cumplidores de la ley, aunque diferían de los otros grupos religiosos en su interpretación de esta.

Otro aspecto de suma importancia en el judaísmo del siglo I es su concepción apocalíptica: la creencia en una intervención futura de Dios, que restauraría el poder de Israel y tras la que reinarían la paz y armonía universales. Esta idea adquirió gran fuerza en la época en que el pueblo judío fue sometido por la ocupación romana (aunque está ya presente en varios de los libros proféticos de la "Tanaj", especialmente en el "Libro de Isaías)", y se relaciona estrechamente con la creencia en la llegada de un Mesías. Además, es muy mencionada en la llamada literatura intertestamentaria: libros apócrifos generalmente atribuidos a patriarcas u otras figuras destacadas de la Biblia hebrea.

Jesús de Nazaret nació con bastante probabilidad en torno al año 4 a. C., aunque la fecha no puede determinarse con seguridad. Según la opinión hoy mayoritaria entre los estudiosos, su lugar de nacimiento fue la aldea galilea de Nazaret, aunque pudo haber nacido también en Belén, en Judea, cerca de Jerusalén. Es probable que sus padres se llamaran José y María, y que tuviera varios hermanos y hermanas. No hay constancia de que estuviera casado; probablemente era célibe, aunque tampoco hay ninguna fuente que lo afirme. Cuando tenía aproximadamente treinta años, se hizo seguidor de un predicador conocido como Juan el Bautista y, cuando este fue capturado por orden del tetrarca de Galilea, Antipas (o tal vez antes), formó su propio grupo de seguidores. Como predicador itinerante, recorrió varias localidades de Galilea, anunciando una inminente transformación que denominaba Reino de Dios. Predicaba en arameo, aunque es muy probable que conociese también el hebreo, lengua litúrgica del judaísmo, tanto en sinagogas como en casas privadas y al aire libre. Entre sus seguidores había varias mujeres.

Desarrolló su predicación durante un tiempo imposible de concretar, pero que en cualquier caso no excedió de tres años, y muy probablemente fue bastante inferior. Durante su predicación, alcanzó fama en la región como sanador y exorcista. Según su punto de vista, su actividad como taumaturgo anunciaba también el Reino de Dios. Fue acusado de borracho y comilón, amigo de publicanos y prostitutas (Mt 11,19), y de exorcizar con el poder del príncipe de los demonios (Mt, 12, 22-30). Sus familiares lo tuvieron por enajenado (Mc 3,21). Las muchedumbres le inspiraban compasión (Mt 14, 14) y la única vez que habló de su personalidad se autodefinió como manso y humilde de corazón (Mt, 11-29) pero rechazó ser llamado bueno, porque solo Dios es bueno (Mc 10,18). La presencia viva de Jesús generaba en sus discípulos una alegría liberadora: «¿acaso pueden los compañeros del novio ayunar mientras el novio está con ellos? Mientras que tienen con ellos al esposo no pueden ayunar» (Mc 2, 19).

Con motivo de la fiesta de la Pascua, acudió con un grupo de seguidores suyos a Jerusalén. Probablemente por algo que hizo o dijo en relación con el Templo de Jerusalén, aunque no pueden excluirse otros motivos, fue detenido por orden de las autoridades religiosas judías de la ciudad, quienes lo entregaron al prefecto romano, Poncio Pilato, acusado de sedición. Como tal, fue ejecutado, posiblemente en torno al año 30, por orden de las autoridades romanas de Judea. A su muerte, sus seguidores se dispersaron, pero poco después vivieron colectivamente una experiencia que les llevó a creer que había resucitado y que regresaría en un plazo breve para establecer el Reino de Dios que había predicado en vida.

"Jesús" es la forma latinizada del griego Ιησοῦς (Iesoûs), con el que es mencionado en el Nuevo Testamento, escrito en griego. El nombre deriva del hebreo Ieshu, forma abreviada de Yeshúa, la variante más extendida del nombre Yehoshúa, que significa ‘Yahveh salva’, y que designa así mismo a Josué, un conocido personaje del Antiguo Testamento, lugarteniente y sucesor de Moisés.

Se sabe que era un nombre frecuente en la época, ya que en la obra de Flavio Josefo son mencionados unos veinte personajes de igual denominación.
La forma de este nombre en arameo ―el idioma de la Judea del siglo I― es la que con toda probabilidad usó Jesús: Ieshuá (ישׁוע, Yēšûaʿ).

En Marcos y Lucas, Jesús es llamado "Iesoûs hó Nazarēnós" (Ιησοῦς ὅ Ναζαρηνός); en Mateo, Juan y a veces en Lucas se utiliza la forma "Iesoûs hó Nazoraîos" (Ιησοῦς ὅ Ναζωραῖος), que aparece también en Hechos de los Apóstoles.
La interpretación de estos epítetos depende de los autores: para la mayoría, ambos hacen referencia a su localidad de origen, Nazaret; otros, interpretan el epíteto "nazoraîos" (‘nazoreo’) como compuesto de las palabras hebreas "neser" (‘retoño’) y "semah" (‘germen’); según esta interpretación, el epíteto tendría un carácter mesiánico; otros, en cambio, lo interpretan como Nazareo (separado para Yahveh).
El "Diccionario de la lengua española" (de la Real Academia Española) recoge para la palabra «nazareno» la descripción: ‘Hebreo que se consagraba particularmente al culto de Dios, no bebía licor alguno que pudiese embriagar, y no se cortaba la barba ni el cabello’.
Muy posiblemente, en tiempos de Jesús hubiese unos cuantos hombres más que actuasen de esta manera como servicio religioso.

Jesús nació probablemente en Nazaret, en Galilea, ya que en la mayoría de las fuentes se le llama «Jesús de Nazaret», y en la antigüedad solía expresarse de esta forma el lugar de nacimiento.
Sin embargo, dos evangelios (Lucas y Mateo), los únicos que entre los evangelios canónicos hacen referencia a la infancia de Jesús, relatan su nacimiento en Belén, en Judea. Aunque este lugar de nacimiento es el comúnmente aceptado por la tradición cristiana, los investigadores actuales han puesto de relieve que los relatos de Mateo y Lucas están elaborados con temas de la tradición davídica, contienen varios elementos históricamente poco fiables, y muestran una clara intención de demostrar que Jesús era el Mesías, que, según Miq 5,2, debía nacer en Belén.
Son muchos los críticos actuales que consideran que la historia del nacimiento de Jesús en Belén es una adición posterior de los autores de estos evangelios y no se corresponde con la realidad histórica.
Sin embargo, otros autores, la mayoría de ellos católicos, entienden que no hay razones para dudar de la veracidad histórica de Mateo y Lucas en lo referente a este punto.

Aunque Nazaret es citada 12 veces en los evangelios, y las investigaciones arqueológicas indican que el pueblo fue continuamente ocupado desde el siglo VII antes de nuestra era, «Nazaret» no es mencionada por historiadores o geógrafos de los primeros siglos de nuestra era. Según John P. Meier, Nazaret era «un lugar insignificante situado en los montes de la Baja Galilea, un pueblo tan oscuro que nunca lo mencionan el Antiguo Testamento, Josefo, Filón, ni la literatura temprana de los rabinos, ni los "pseudepigrapha" del Antiguo Testamento».
Aunque Lc 1, 26 la llama «ciudad», en realidad sería una pobre aldea que debió toda su importancia posterior al hecho cristiano.
El nombre de nazarenos dado a los cristianos palestinenses del siglo I era sin dudas irónico y despectivo, y en tal sentido el nombre de Jesús se acompañó con el título «de Nazaret», un lugar oscuro que en nada lo favorecía, tal lo señalado por Raymond E. Brown.

Con los datos con que se cuenta en el presente, no es posible precisar el año del nacimiento de Jesús de Nazaret. Se considera un dato bastante seguro que la muerte de Herodes el Grande tuvo lugar en el año 4 a. C. De allí que al datar el nacimiento de Jesús, la gran mayoría de los autores se decantan por un rango entre los años 7 y 4 a. C., ya que existe probabilidad a favor de que el nacimiento haya sucedido en los últimos años del reinado de Herodes el Grande.
Algunos autores extienden el plazo probable del nacimiento a 8 a. C., o 3-2 a. C., aunque estas posiciones son hoy claramente minoritarias.

Las fuentes cristianas no ofrecen una cronología absoluta de los acontecimientos de la vida de Jesús, con una sola salvedad: Lc 3,1 fija el comienzo de la actividad de Juan el Bautista en «el año quince del reinado de Tiberio», que posiblemente pueda interpretarse como equivalente a uno de estos años: 27, 28 o 29. Un poco más adelante (Lc 3,23), indica que Jesús contaba aproximadamente 30 años al comienzo de su predicación. Además de situar ―al igual que Mateo― el nacimiento de Jesús al final del reinado de Herodes el Grande, el relato de Evangelio de Lucas 2, 1-2 menciona el «censo de Quirino» (cuyo nombre completo y preciso es Publio Sulpicio Quirinio, siendo «Quirino» o «Cirino» probables desviaciones de los copistas), lo que plantea un problema histórico que no se ha resuelto. En "Antigüedades judías", 17.13; 18.1, el historiador Flavio Josefo aludió a un censo bajo Cirino (Quirinio o Quirino) siendo Coponio procurador de Judea. Si se cotejan los versículos de Lucas con todas las crónicas históricas sobre el gobierno de Quirinio en Siria y los empadronamientos que se hicieron bajo el mandato de César Augusto, se llega al hecho de que se desconoce que se haya ordenado un censo que «abarcara a todo el mundo conocido bajo Augusto», y que el censo de Judea, que no incluía a Nazaret, y que se llevó a cabo bajo Quirinio, habría ocurrido unos diez años después de la muerte de Herodes el Grande, es decir, en el año 6 o 7 d. C. y por lo tanto, presumiblemente después del nacimiento de Jesús. Es probable que "post factum", es decir, tras la muerte de Jesús de Nazaret, su nacimiento se haya asociado a recuerdos dispersos de acontecimientos que ocurrieron unos años antes o después del nacimiento en sí. Sobre este punto, Antonio Piñero señaló: «La inmensa mayoría de los investigadores cree que Lucas se refiere «de oídas» al censo de Quirinio del 6 d. C, por tanto unos diez años después del nacimiento de Jesús».

Convencionalmente, se adoptó como la fecha de nacimiento de Jesús la calculada en el siglo VI por Dionisio el Exiguo, basada en cálculos erróneos y que hoy sirve de inicio de la llamada era cristiana; también convencionalmente, en el siglo IV comenzó a celebrarse su nacimiento el 25 de diciembre.

Sobre la familia de Jesús, todos los evangelios están de acuerdo en el nombre de su madre, María y de su padre, José, si bien dos de los evangelios (Mateo y Lucas) contienen relatos, diferentes entre sí, acerca de la concepción milagrosa de Jesús por obra del Espíritu Santo. Según estos relatos, José no habría sido su padre verdadero, sino solo su padre legal, por ser el esposo de María. La mayoría de los investigadores creen que estos relatos son bastante tardíos: no se mencionan en los evangelios de Marcos y de Juan, y existen indicios que permiten sospechar que en tiempo de Jesús este era conocido como «hijo de José».

Los hermanos de Jesús son mencionados en varias ocasiones en los evangelios y en otros libros del Nuevo Testamento.
En Mc 6, 3 se mencionan los nombres de los cuatro hermanos varones de Jesús: Santiago (Jacobo), José, Judas y Simeón o Simón, y se indica también la existencia de dos hermanas.

Son numerosas las fuentes que indican la ascendencia davídica de Jesús, a través de José (a pesar de que, como antes se ha dicho, algunos evangelios afirman explícitamente que José no fue el padre biológico de Jesús). Varios pasajes del Nuevo Testamento muestran que era llamado «hijo de David», y que la idea de su origen davídico estaba muy extendida en los primeros años del cristianismo aunque él nunca se refirió a sí mismo como tal. Los críticos no están de acuerdo, sin embargo, en que esta ascendencia davídica sea un dato cierto, dado que puede tratarse de una adición de los evangelistas para demostrar la condición mesiánica de Jesús. Las genealogías de Jesús que aparecen en Mateo y Lucas (Mt 1, 1-16 y Lc 3, 23-31) son diferentes entre sí, aunque ambas vinculan a José, padre legal de Jesús con la estirpe de David.

La actividad de Jesús se inscribió en el marco de la religiosidad judía. De las fuentes se infiere que en general cumplió los preceptos de la Ley mosaica (aunque en ocasiones discrepara de la interpretación que de ella hacían algunos grupos religiosos), y que participó de creencias comunes en el judaísmo del siglo I (como la existencia de demonios o la resurrección de los muertos).

Los investigadores están de acuerdo en que la lengua materna de Jesús fue el arameo. Aunque los evangelios están escritos en griego, contienen frecuentes expresiones en arameo, la mayor parte de ellas atribuidas a Jesús. Además, el arameo era la lengua habitual de los judíos de Galilea. Seguramente el arameo hablado en Galilea era una variante dialectal reconocible, como lo atestigua el hecho de que Pedro sea reconocido por su acento en Jerusalén (véase Mt 26, 73).

No puede aclararse si Jesús hablaba o no griego.
En general se cree que conocía el hebreo, que en la época era solo una lengua religiosa y de cultura, y que sabía leer, ya que en una ocasión se le presenta leyendo el "Libro de Isaías" (escrito en hebreo) en una sinagoga.

Parece ser que tanto Jesús como su padre, José, ejercieron la profesión de carpinteros.
En cualquier caso, hay bastante consenso en cuanto a que procedía de un medio campesino. En su predicación hizo también constantes referencias a las labores agrícolas, y apenas parece interesado por el medio urbano (no hay constancia de que en su predicación visitara nunca las principales ciudades de Galilea, a pesar de que la importante ciudad de Séforis se hallaba a corta distancia de Nazaret).

No se conoce con certeza cuánto tiempo duró la vida pública de Jesús. Los evangelios sinópticos mencionan una sola fiesta de Pascua celebrada por él con sus discípulos en Jerusalén, durante la cual fue detenido y crucificado. Eso parece sugerir que su vida pública duró solamente un año. En el Evangelio de Juan, por el contrario, se mencionan tres fiestas de Pascua, las tres celebradas por Jesús en Jerusalén, lo que hace suponer que el ministerio de Jesús se prolongó durante dos o tres años. En todos los evangelios solo hay una indicación precisa de fecha, la que se ofrece en Lucas (Lc 3, 1-2), indicando que la actividad de Juan el Bautista se inició el año 15 del mandato de Tiberio, lo que puede coincidir, según diferentes cálculos, con los años 27, 28 o incluso 29 de nuestra era, aunque la mayoría de los autores se inclina por el año 28.

La vida pública de Jesús se inicia, según todos los evangelios, con su bautismo por Juan el Bautista en el río Jordán. Es probable que Jesús iniciase su actividad como seguidor del Bautista.

Seguido de un grupo de fieles, de entre los cuales escogió a sus más allegados, los doce apóstoles o enviados, recorrió en su actividad toda Galilea (especialmente el área en torno a Cafarnaún) y las regiones aledañas de Fenicia, la Decápolis y el territorio de la tetrarquía de Herodes Filipo.

Según las fuentes cristianas, su predicación transmitía un mensaje de esperanza especialmente dirigido a los marginados y pecadores (Lc 15). Posiblemente llegó a congregar a grandes multitudes (se habla, por ejemplo, de cinco mil personas en referencia a la multiplicación de los panes y los peces).
Se trasladó a Jerusalén para celebrar allí la Pascua con sus discípulos, y entró triunfalmente en la ciudad.

En los cuatro evangelios canónicos, el comienzo de la vida pública de Jesús lo marca su bautismo por Juan en el Jordán. Juan el Bautista es un personaje relativamente bien conocido gracias a la información que de él proporciona Flavio Josefo, quien afirma que era «un hombre de bien que incitaba a los judíos [...] a ser justos los unos con los otros y píos hacia Dios, y a ir juntos al bautismo» ("Antigüedades judías", 18, 116-119) y relata que Herodes Antipas lo ejecutó por miedo a que provocase una revuelta.
El mensaje de Juan, tal y como es reflejado por las fuentes, parece bastante semejante al de Jesús; según Mateo, en su predicación hacía referencia al Reino de los Cielos e insistía en la necesidad de un pronto arrepentimiento. El hecho de que Jesús se sometiese al rito bautismal sugiere que probablemente formase inicialmente parte de la comunidad religiosa del Bautista.

En los evangelios, Juan se considera a sí mismo un precursor, declarando que no es digno de desatar la correa de las sandalias de Jesús y que este sustituirá su bautismo de agua por el bautismo «en el Espíritu Santo».
Por su parte, Jesús habla con gran respeto de Juan, afirmando que «entre los que nacen de mujer no se ha levantado otro mayor», si bien añade que «el más pequeño en el Reino de los Cielos es mayor que él».
En el Evangelio de Juan se sugiere que entre los discípulos de Jesús y del Bautista llegó a haber cierta rivalidad, pero se deja claro que Juan aceptó siempre su subordinación a Jesús.

Debe tenerse en cuenta que los evangelios fueron escritos por seguidores de Jesús, con la finalidad de conseguir nuevos conversos. Si, como parece, Juan el Bautista fue un personaje relativamente conocido y respetado en su tiempo (como parece demostrarlo el hecho de que Flavio Josefo se refiera a él por extenso), es bastante explicable que los evangelistas lo presenten admitiendo públicamente la superioridad de Jesús.

Del estudio de las fuentes (sobre todo los sinópticos) se infiere que Jesús predicó de forma itinerante en la zona norte de cisjordania hoy Palestina y, preferentemente, en las aldeas que bordeaban el lago de Genesaret. Sus seguidores fueron principalmente de extracción campesina, y le acompañaron también varias mujeres, lo cual resulta inusual en el contexto de los movimientos religiosos del judaísmo. Escogió a doce apóstoles o enviados, posiblemente en representación de las doce tribus de Israel. Ni los nombres de los apóstoles ni los relatos de cómo se unieron a Jesús coinciden en todos los evangelios, pero todos concuerdan en la cifra de doce.

La crítica es prácticamente unánime en considerar que el núcleo de la predicación de Jesús era el anuncio del Reino de Dios. Sin embargo, existen importantes discrepancias a la hora de interpretar qué significa esta expresión en el contexto de la predicación de Jesús. El «Reino de Dios» se anuncia como algo inminente; en este sentido, la predicación de Jesús se inserta en el contexto de la literatura apocalíptica del judaísmo, en la que existe la esperanza de una próxima intervención de Dios en los asuntos humanos. Para entrar en el Reino de Dios que Jesús profetiza es necesaria una transformación interior "(metanoia)" que alcanza todos los ámbitos de la existencia humana; así, quien no se hace como un niño no entrará en el Reino (Mt 18, 1-5) y el perdón es condición para un culto eficaz (Mt, 5, 21-26).

Jesús describió el Reino de Dios utilizando parábolas (véase más arriba), en muchas de las cuales aparece un contraste entre un inicio pequeño e insignificante y un final espléndido (Mt 13,31-34), un padre generoso y unos invitados al banquete ocupados y desagradecidos (Mt 22, 1-14), un rey compasivo y un siervo sin piedad (Mt 18, 21-35), un viñador confiado y unos arrendatarios infieles (Lc 20, 9-19), un sembrador despreocupado y distintos tipos de tierra (Mc 4,1-9).

Hay bastante consenso entre los especialistas en cuanto a que la predicación de Jesús iba dirigida en exclusiva al pueblo de Israel. Según Mateo, así lo dijo: «No soy enviado sino a las ovejas perdidas de la casa de Israel» (Mt 15, 24). Entre los historiadores que no han aceptado esta exclusividad judía se encuentra Ernest Renan, quien se expresaba así en su polémica obra "Vida de Jesús" (1863):

En cualquier caso, se admite que algunos gentiles podrían haber participado de su mensaje. Según los evangelios, sanó a algunos gentiles, como el criado del centurión de Cafarnaún o la hija de la mujer sirofenicia, conmovido por la fe que demostraron.

No hay unanimidad entre los estudiosos con respecto a si Jesús se consideró a sí mismo como el Mesías de Israel, como afirman los evangelios canónicos, o si su identificación como tal pertenece a la teología de las primeras comunidades cristianas. En los sinópticos, y especialmente en el Evangelio de Marcos, Jesús admite implícitamente que es el Mesías, pero pide en numerosas ocasiones a sus discípulos que no lo divulguen («secreto mesiánico»).

Se considera generalmente un dato histórico que Jesús se designó a sí mismo como «Hijo del Hombre», aunque no está claro si se trata de un título escatológico, como parece desprenderse de su empleo en el Libro de Daniel y otros textos intertestamentarios, o si es un mero circunloquio semítico para hacer referencia a la primera persona del singular.

En líneas generales, la predicación de Jesús se mantuvo en el marco del judaísmo de su época.
En algunos aspectos, sin embargo, entró en conflicto con la interpretación que de la ley judía hacían otros grupos religiosos (fundamentalmente saduceos y fariseos), sobre todo en dos aspectos: la observancia del sábado y la pureza ritual. Existen discrepancias sobre cómo interpretar estos conflictos: como una controversia ética (prioridad del bien del hombre sobre la letra del precepto, de lo interior sobre lo exterior), como una controversia de autoridad (Jesús tiene un poder recibido de lo alto y lo ejerce) o como una controversia escatológica (se inaugura un nuevo tiempo).

En la predicación de Jesús, tienen una gran importancia sus enseñanzas éticas. El centro de la ética de Jesús era el amor al prójimo, al desvalido de quien no se puede recibir contraprestación (Lc 14,13) y, muy especialmente, el amor al enemigo (única manera de distinguirse de los paganos que aman a los que les aman a ellos) (Mt 5,44-48, Lc 6,27-38). Para algunos autores, la ética que Jesús predicaba tiene un carácter provisional, y se orienta sobre todo a la época de preparación del Reino de Dios.
Por ese motivo también, la ética de Jesús enfatiza la renuncia a los bienes materiales. En todo caso, las fuentes coinciden en que no se puede servir a Dios y a las riquezas (Mt 6,24).

Son muchos los especialistas que han llamado la atención acerca de la coincidencia en las fuentes sobre la especial consideración que Jesús parece haber tenido hacia las mujeres de diversa condición, en especial las marginadas, enfermas y pecadoras públicas. Algo, en cierta medida, novedoso para un rabí de la época. Los ejemplos son múltiples: así la encorvada a la que se acerca y cura en sábado llamándola hija de Abraham, título exclusivamente masculino (Lc 13,11); la que sufría una patología femenina extrema que la hacía impura y excluida y que alcanza a tocarle sin que Jesús pueda evitar curarla (Mc 5,25-34); la extranjera pagana, único personaje en los evangelios canónicos que le convence en una discusión, apelando a su corazón con una parábola (Mt 15,28); la viuda a la que Jesús se acerca por propia iniciativa, conmovido (Lc 7,13); la prostituta que le unge, con escándalo de los presentes, y a la que le son perdonados los pecados porque «ha amado mucho» (Lc 7, 37-47); la viuda pobre a la que Jesús ensalza por su generosidad (Mc 12, 41-44); Marta y María, las amigas que le acogen en su casa (Lc 10, 38-42); etc.

Las fuentes sinópticas coinciden también en que entre los discípulos itinerantes de Jesús se encontraban mujeres (María Magdalena, Juana, Salomé...), algo no muy común en una sociedad patriarcal. E incluso afirman que permanecieron al pie de la cruz cuando todos habían huido (Mc 15,40-41). Resulta también paradójico que se reconozca como primeros testigos de la resurrección a mujeres, cuyo testimonio apenas tenía validez en aquel contexto social (Mc 16, 11).

Por otro lado, en sus diatribas contra los escribas y fariseos, Jesús les reprocha que devoren los bienes de las viudas con pretextos religiosos (Lc 20, 18), y a los príncipes de los sacerdotes y a los ancianos del pueblo les llega a asegurar que las prostitutas les precederán en el Reino de Dios (Mt 21, 31).

Por su parte, en el Evangelio de Juan, destacan algunos personajes femeninos: la enemiga étnica de vida licenciosa que es interlocutora del discurso del «agua viva» y de la «adoración en espíritu y en verdad», que acaba evangelizando a sus convecinos samaritanos; Marta de Betania, protagonista de un diálogo fundamental sobre la «resurrección y la vida»; y la mujer adúltera a la que Jesús salva de morir lapidada conforme a la Ley de Moisés. Incluso la crítica histórica y exegética más exigente reconoce que, más allá del carácter kerigmático de estos relatos, se esconde un trasfondo histórico en donde el predicador judío, Jesús de Nazaret, otorgó una consideración llamativa a las mujeres de su tiempo.

Tanto las fuentes sinópticas como el Evangelio de Juan presentan a Jesús como hacedor de milagros. También destaca esta faceta de su actividad el Testimonio Flaviano, donde se indica que «llevó a cabo hechos sorprendentes» ("Antigüedades judías", XVIII, 63), aunque no puede asegurarse que no se trate de una interpolación cristiana posterior.

En líneas generales, la investigación actual no concede credibilidad histórica a los hechos maravillosos de Jesús que tienen que ver con alteraciones de las leyes de la Naturaleza, que se consideran proyección de la fe de los primeros cristianos y, como tales, requieren una interpretación simbólica, no literal. En gran medida los relatos de milagros pueden tener un origen helenístico: Rudolf Bultmann encontró paralelismos entre los relatos de los milagros de Jesús y otros similares de la tradición helenística, lo que le llevó a concluir que «parece probable que los relatos taumatúrgicos tienen generalmente un origen helenístico».

No obstante, se acepta en general que Jesús fue considerado por sus contemporáneos como capaz de curar ciertas enfermedades y de exorcizar demonios, lo que puede interpretarse a la luz de las creencias populares en la Palestina del siglo I. Los sinópticos, y especialmente el Evangelio de Marcos, ofrecen numerosos testimonios de este tipo de actividad, y no parece probable que se trate de adiciones posteriores. Estos testimonios coinciden además con los de las fuentes talmúdicas, donde se relata que Jesús fue ejecutado como hechicero. Algunos investigadores, como el estadounidense Morton Smith, han llegado a considerar este tipo de prácticas como las más importantes en el magisterio de Jesús, hasta el punto de identificarlo como un mago helenístico, similar a otros, aproximadamente contemporáneos, como Apolonio de Tiana.

La mayoría de las fuentes que hacen referencia a la muerte de Jesús concuerdan en que murió crucificado por orden del entonces prefecto romano en Judea, Poncio Pilato.

Que la orden de la ejecución de Jesús partió de la autoridad romana lo confirma lo que se sabe acerca de los procedimientos jurídicos en las provincias del Imperio romano. Las sentencias capitales eran competencia exclusiva del funcionario romano, que tenía el llamado "ius gladii" (‘derecho de espada’).
Solo los romanos, además, utilizaban la crucifixión como método de ejecución. Para la mayoría de los historiadores y biblistas, la referencia en los cuatro evangelios canónicos a la existencia de una inscripción o "titulus" ―tablilla que tenía por función especificar el motivo de la crucifixión― que contenía el cargo condenatorio de Jesús de Nazaret, constituye uno de los datos más sólidos del carácter histórico de su pasión.
Además, Raymond Edward Brown señala que no resulta verosímil que el cargo por el cual se condenó a Jesús de Nazaret («rey de los judíos») sea una invención, porque nunca se presentó como una confesión cristiana y porque se trató de una inscripción a la vista de todos.

Existen, sin embargo, discrepancias entre los investigadores a la hora de determinar algunas circunstancias de la ejecución. En primer lugar, en cuanto al delito del que fue acusado Jesús y por el cual fue condenado a la pena capital. En segundo lugar, en cuanto al grado de implicación de las autoridades judías de Jerusalén en el juicio y sentencia de Jesús.

Ninguna de las fuentes ofrece una fecha exacta para la muerte de Jesús. Sin embargo, tanto las fuentes sinópticas como el Evangelio de Juan coinciden en que Jesús murió un viernes. Según los sinópticos, este viernes coincidió con el primer día de la fiesta de Pésaj (Pascua judía), que se celebraba el día 15 del mes hebreo de nisán. El Evangelio de Juan, en cambio, indica que la muerte de Jesús ocurrió el día anterior a dicha fiesta (es decir, el 14 de nisán), la tarde en la que en el templo de Jerusalén se sacrificaban los corderos pascuales. Se ha indicado que la información dada por Juan puede estar motivada por su intención de identificar a Jesús como el verdadero Cordero de Dios, ya que su muerte, en el relato joánico, tiene lugar a la misma hora en que en el templo se sacrificaban los corderos para la fiesta de Pascua.

Todas las fuentes están de acuerdo en que la ejecución de Jesús tuvo lugar durante el mandato de Poncio Pilato (26-36). Si se acepta como cierta la información que aportan los sinópticos, la muerte de Jesús pudo haber ocurrido en el 27 o el 34, ya que en estos dos años el 15 de Nisán cayó en viernes. Si se cree, en cambio, que la información más fidedigna es la aportada por el Evangelio de Juan, las fechas posibles son el 30 y el 33, años en los que el 14 de nisán fue viernes.

Algunos autores han intentado armonizar los datos aportados por los sinópticos y por Juan, apelando al uso de dos calendarios diferentes (un calendario lunar oficial y otro solar, utilizado por los esenios). No hay indicios, sin embargo, de que Jesús siguiese otro calendario diferente del que regía las festividades oficiales.

Aunque la tradición cristiana considera generalmente que, en el momento de su muerte, Jesús tenía 33 años, es perfectamente posible que tuviera una edad superior, dado que, como se ha expresado, posiblemente nació antes del 4 a. C. (año de la muerte de Herodes el Grande).
El número 33 con el tiempo ha acabado adquiriendo un sentido simbólico y ha sido empleado por organizaciones como la masonería, que divide su escalafón en 33 grados (siendo el 33 el grado superior).






Algunos autores niegan de forma absoluta la validez histórica de las fuentes cristianas, y sostienen que la figura de Jesús es el resultado de una falsificación consciente por parte de los primeros cristianos.
Según esta teoría, Jesús no fue un personaje histórico, sino una entidad mítica, producto del sincretismo entre las religiosidades helenística y judía. En la actualidad, los principales defensores de esta teoría en medios académicos son George Albert Wells, Earl Doherty, Alvar Ellegård, Timothy Freke y Peter Gandy.

Los principales argumentos que apoyan esta postura son:



La mayoría de los estudiosos consideran esta teoría bastante inverosímil.
Según Antonio Piñero, desde la década de 1920 «no se considera científico negar la existencia histórica de Jesús debido a la cantidad de pruebas directas o indirectas de su existencia».
Como argumentos que hacen más verosímil la existencia histórica de Jesús, Piñero cita:

Murray J. Harris sugirió además «evidencias institucionales y algunas consideraciones psicológicas» en apoyo del carácter histórico de Jesús; entre estas últimas destacó la improbabilidad psicológica de que un grupo de judíos del siglo I, para quienes la crucifixión era una maldición (Dt 21, 23), inventara una religión cuyo fundador fue crucificado por los romanos, acusado de sedición y alboroto político, y que muriesen por sostener semejante engaño por ellos creado.

Es abismal la diferencia entre la mínima repercusión histórica que la predicación de Jesús alcanzó durante su vida y su influencia posterior en la historia universal. El movimiento religioso iniciado por Jesús, escindido del judaísmo, terminó convirtiéndose en una nueva religión, el cristianismo, que fue ganando adeptos por todo el ámbito del Mediterráneo durante los primeros siglos de nuestra era. A pesar de ser duramente criticada, e incluso perseguida, durante el siglo IV la religión cristiana llegó a ser la religión principal (oficialmente la única a partir del "Edicto de Tesalónica") del Imperio romano. La Iglesia cristiana alcanzó un enorme poder, y mantuvo su estructura fuertemente jerarquizada después de las invasiones bárbaras que marcaron el final del Imperio romano de Occidente. En Oriente, continuó siendo la religión oficial del Imperio bizantino hasta el final de este estado, a mediados del siglo XV, si bien en gran parte de los antiguos territorios orientales del Imperio romano se vio desplazada, a partir del siglo VII, por el avance del islam.

El cristianismo se incorporó a la herencia cultural de Europa, hasta el punto de ser considerado en la actualidad como uno de sus principales rasgos de identidad.El filosofo inglés sir Anthony Kenny declaró en su libro "Una nueva historia de la filosofía occidental" que para "el desarrollo a largo plazo de la filosofía el evento más importante en el siglo I fue la vida de Jesús de Nazaret". El impacto del cristianismo en la filosofía occidental tuvo dos grandes efectos: Primero, redujo el interés por la filosofía por considerarse doctrinas paganas; y segundo, la filosofía paso a ser "sierva" de la teología, siendo las conjeturas opuestas a los dogmas de fe rechazadas. Con la expansión de la cultura europea que comenzó en el siglo XV, esta religión se difundió por otros muchos lugares del mundo, especialmente por América, donde es hoy también la religión más importante. En la actualidad, la religión cristiana, en sus diferentes denominaciones, es la que cuenta con mayor número de seguidores en todo el mundo.

La historia de la Iglesia cristiana, tanto en Oriente como en Occidente, ha sido en gran medida la de la lucha entre diferentes concepciones del cristianismo, que desembocaron en varios cismas, con la consiguiente aparición de nuevas iglesias, por lo que en la actualidad no existe una sola, sino muy variadas confesiones cristianas. Todas estas variantes del cristianismo comparten, sin embargo, una visión de Jesús de Nazaret relativamente unitaria en lo esencial (véase más abajo la sección Jesús en el cristianismo).

El cristianismo, y especialmente la figura de Jesús de Nazaret, ha ejercido hasta la actualidad una enorme influencia en todos los aspectos de la cultura de Europa y de América (sobre algunos aspectos de la influencia de Jesús en la cultura, véanse las secciones Jesús en el arte, Jesús en la literatura, Jesús en el cine).

La figura de Jesús de Nazaret es el centro de todas las religiones denominadas cristianas, aunque existen diferentes interpretaciones acerca de su persona.
En general, para los cristianos, Jesús de Nazaret es el protagonista de un acto único e intransferible, por el cual el hombre adquiere la posibilidad de elevarse por encima de su naturaleza caída y alcanzar la salvación.
Dicho acto se consuma con la resurrección de Jesús de Nazaret. La resurrección es, por tanto, el hecho central del cristianismo y constituye su esperanza soteriológica. Como acto, es privativo de la divinidad e inasequible al hombre. De forma más precisa, la encarnación, la muerte y la resurrección compensan en tres actos sucesivos los tres obstáculos que separaban, según la doctrina cristiana, a Dios del hombre: la naturaleza, el pecado y la muerte.
Por la encarnación del Verbo, la naturaleza divina se hace humana.
Por la muerte de Cristo, se supera el pecado y por su resurrección, la muerte.

Históricamente, el núcleo de la doctrina cristiana quedó fijado en el Concilio de Nicea, con la formulación del símbolo niceno. Este concilio es reconocido por las principales denominaciones cristianas: católicos, ortodoxos y las diferentes iglesias protestantes.
El texto del credo niceno en lo referente a Jesús es el siguiente:

Existen, sin embargo, iglesias no trinitarias que no reconocieron la existencia de una Trinidad de personas en Dios (por ejemplo, el arrianismo, y posteriormente el unitarismo).

Jesús de Nazaret es también considerado la encarnación del Hijo, segunda persona o hipóstasis de la trinidad cristiana. Es Hijo por naturaleza y no por adopción, lo que quiere decir que su divinidad y su humanidad son inseparables. La relación entre la naturaleza divina y humana quedó fijada en el Concilio de Calcedonia en estos términos:

Existen algunas religiones cristianas minoritarias que no comparten las definiciones dogmáticas del Concilio de Nicea, del Concilio de Éfeso y del Concilio de Calcedonia.



Varios movimientos religiosos de filiación cristiana, surgidos a partir de la segunda mitad del siglo XIX, se apartan de las creencias tradicionales de las religiones cristianas mayoritarias en lo referente a la doctrina de la Trinidad, la naturaleza de Cristo y su misión. Por ello se discute por parte de los grupos tradicionales si estos movimientos pueden considerarse propiamente cristianos.

Los mormones (La Iglesia de Jesucristo de los Santos de los Últimos Días) creen que Jesucristo ofrece la salvación en dos aspectos diferentes, de la muerte física y de la muerte espiritual.
La iglesia mormona, fundada en Estados Unidos, también mantiene la creencia de que, después de su resurrección, Jesucristo visitó América y continuó allí su enseñanza.

Los testigos de Jehová consideran a Jesús como el único ser creado por Dios directamente y que actualmente no es un hombre ni el Dios todopoderoso, sino «una poderosa criatura espiritual» entronizado como rey.
También creen que Jesús no es parte de una trinidad, y que no resucitó por sí mismo, sino que Dios lo resucitó.
Los Testigos de Jehová afirman que Jesús no murió en una cruz sino en un madero y por ende no usan la cruz ni ningún otro símbolo.
Otro punto que caracteriza sus creencias es que Jesucristo se convirtió en Rey en el cielo en el año 1914 y el Arcángel Miguel es Jesucristo en su posición celestial.

Para la Ciencia Cristiana (Iglesia Científica de Cristo) de Mary Baker Eddy, Jesús el Cristo tiene una dualidad: uno es Jesús como hombre y la otra es Cristo como la idea divina. Jesús representó a Cristo, es decir la verdadera idea de Dios.
Este «Cristo-espíritu» gobernó al Jesús físico.
Con la ascensión desapareció Jesús pero la identidad espiritual o Cristo «continúa existiendo en el orden eterno de la Ciencia Divina, redimiendo los pecados del mundo
Jesús no es Dios sino el Hijo de Dios y uno con Dios en «calidad y no en cantidad».
Dios no es un salvador corpóreo sino un Principio salvador.
La salvación no se logra mediante el perdón sino una reforma y recurso de Espíritu.

Los adventistas del Séptimo Día hacen hincapié, como la mayoría de los grupos adventistas, en una escatología de signo milenarista que considera inminente la Parusía (segunda venida de Cristo), la cual se realizará de modo visible y tangible.

Otros movimientos se apartan bastante más de las creencias cristianas, ya que niegan de plano su misión salvadora.

El judaísmo, religión en cuyo marco se desarrolló la predicación de Jesús, rechaza la creencia de que Jesús es Dios, ya que resulta incompatible con su estricto monoteísmo. Igualmente rechaza su identificación con el Mesías o como profeta.

En líneas generales, puede decirse que el judaísmo prestó escasa atención a Jesús de Nazaret. Sin embargo, un personaje llamado Yeshu (alt: Jeshu, Yeishu, en hebreo: יש"ו) es mencionado en antiguos textos rabínicos, entre ellos el Talmud de Babilonia, redactado en fecha anterior al año 600, y la literatura midrásica, de entre 200 y 700. El nombre es similar, aunque no idéntico, a Yeshúa, que es considerado por muchos autores el nombre original de Jesús en arameo. Además, en varios manuscritos del Talmud de Babilonia aparece con el sobrenombre Ha-Notztri, que puede significar ‘el Nazareno’. Por este motivo, y por ciertas coincidencias entre la historia de Jesús conocida por los evangelios cristianos y la del Yeshu citado en el Talmud, algunos autores han identificado a ambos personajes. Existen, sin embargo, discrepancias sobre este punto, pero por otro lado también nombran a su madre María.

En los textos rabínicos, Jesús es caracterizado desde un punto de vista muy negativo y le atacan con vehemencia: aparece como un embaucador que empuja a los judíos a apostatar de su religión, se mofan de él y de sus enseñanzas, así como de su madre María.

El gnosticismo es un conjunto de religiones heterogéneas que florecieron cuando las religiones locales de Asia entraron en contacto con el helenismo. A pesar de su diversidad de contenidos, comparten algunos rasgos, a veces de estilo y, a veces, de contenido. Por ejemplo, era muy común en ellas atribuir al mundo un origen maligno o defectuoso. Para algunas religiones gnósticas, el mundo había sido creado por malignos demiurgos que tenían al hombre encerrado en la existencia terrenal e ignorante de su condición de prisionero. Para otras, el mundo era el fruto de un fracaso o tragedia creativos. Los que conocían (gnosis) esta verdad podían intentar escapar. En contacto con el cristianismo, aparecieron nuevas variantes gnósticas. Las más destacadas fueron:






Jesús, llamado en lengua árabe `Īsā o `Īsā ibn Maryam (‘Jesús, hijo de María’), es uno de los principales profetas del islam. Según el Corán, fue uno de los profetas más queridos por Dios y, a diferencia de lo que ocurre en el cristianismo, para los musulmanes no tiene carácter divino. Existen notables diferencias entre el relato de los evangelios y la narración coránica de la historia de Jesús.

La virginidad de María es plenamente reconocida (Corán, 3,41; 5,19; 19,22 y ss). Jesús es quien anunció la llegada de Mahoma como último profeta (Corán, 3,75; 61,6), aunque siguen su vida y prédica a través de los textos de los evangelios apócrifos. La muerte de Jesús es tratada de forma compleja, al no reconocer explícitamente su sacrificio, sino que antes de la muerte es sustituido por otro ser ―del que nada se dice―, mientras Jesús asciende con Dios y burla a los judíos (Corán, 3,48; 4,156). La muerte ignominiosa de Jesús no se contempla, aunque sí se afirma su regreso el día del Juicio Final (Corán, 4,157; 43,61) y el descubrimiento, en ese día, de que la obra de Jesús fue verdadera (en el sentido de enviado por Dios). El Corán rechaza la Trinidad (según el concepto del "tawhid"), teniéndola por falsa, y considera a Jesús por «Verbo de Dios», pero no hijo de él.

En un primer momento, el arte cristiano evitó representar a Jesús en forma humana, prefiriendo evocar su figura mediante símbolos, tales como el monograma formado por las letras griegas Χ y Ρ, iniciales del nombre griego Χριστός (Cristo), en unión a veces de Α y Ω, primera y última letras, respectivamente, del alfabeto griego, para indicar que Cristo es el principio y el fin; el símbolo del pez (ΙΧΘΥΣ, "ikhthýs" en griego, acróstico de Ἰησοῦς Χριστός, Θεοῦ Υἱός, Σωτήρ ("Iesoûs Khristós, Theoû Huiós, Sōtḗr:" ‘Jesús Cristo, hijo de Dios, Salvador’); el Cordero de Dios; o incluso mediante símbolos antropomórficos, como el del Buen Pastor.

Más tarde aparecieron representaciones de Cristo, primero presentado como un joven imberbe. A partir del siglo IV fue representado casi exclusivamente con barba. En el arte bizantino se hicieron habituales una serie de representaciones de Jesús, algunas de las cuales, como la imagen del Pantocrátor, tuvieron un amplio desarrollo en el arte europeo medieval.

Desde finales del siglo XIX, son numerosos los autores literarios que han dado su interpretación personal de la figura de Jesús. Entre las obras más destacadas que han tratado el tema pueden citarse:

La figura de Jesús ha sido también el tema de algunas obras de literatura de consumo, a veces en géneros como la ciencia ficción o la novela de misterio:

La vida de Jesús según los relatos del Nuevo Testamento, y generalmente desde una perspectiva cristiana, ha sido un tema frecuente en el cine desde su misma aparición. De hecho, es uno de los personajes más interpretados. Ya en 1898 su vida fue llevada a la pantalla por Georges Hatot y Louis Lumière en un filme titulado "La Vie et la Passion de Jésus-Christ".
En el cine mudo destaca la superproducción "Rey de reyes" (1927), de Cecil B. DeMille.

Posteriormente, ha sido representado en repetidas ocasiones, desde las superproducciones de Hollywood, como "Ben-Hur" (William Wyler, 1959), "Rey de reyes" (Nicholas Ray, 1961) y "La historia más grande jamás contada" (George Stevens, 1965) o la miniserie europea "Jesús de Nazaret" (Franco Zeffirelli, 1977) hasta visiones más austeras como la de Pier Paolo Pasolini ("El Evangelio según San Mateo", 1964). También dieron su personal interpretación de la figura de Jesús autores como Griffith ("Intolerancia", 1916), Wiene ("INRI", 1923), Morayta ("El mártir del Calvario", 1952), Dreyer ("Ordet", 1954), Dassin ("El que debe morir", 1957), Buñuel ("Nazarín", 1958, y "La Vía Láctea", 1969), Wajda ("Pilatus und andere", 1971), Rossellini ("El Mesías", 1975), Arcand ("Jesús de Montreal", 1989) o Cuerda ("Así en el cielo como en la tierra", 1995).

Algunas de las películas más recientes sobre su vida no han estado exentas de polémica. Es el caso de "Je vous salue, Marie" (1985) de Jean-Luc Godard o "La última tentación de Cristo" (1988), de Martin Scorsese, basada en la novela homónima de Nikos Kazantzakis y muy criticada en general por su interpretación de Jesús, apartada del punto de vista cristiano tradicional. El filme de Mel Gibson "La Pasión de Cristo" (2004) suscitó en cambio la aprobación de amplios sectores del cristianismo, pero fue tachado de antisemita por algunos miembros de la comunidad judía. En 2014 fue estrenada la película "Hijo de Dios".

El personaje de Jesús ha sido tratado en el cine desde muy variados ángulos.
No faltan, por ejemplo, aproximaciones paródicas a la figura del iniciador del cristianismo como "La vida de Brian" (Terry Jones, 1979), musicales como "Jesucristo Superstar" (Norman Jewison, 1973) o "Godspell" (David Greene, 1973) y filmes de animación como "The Miracle Maker" (Derek W. Hayes y Stanislav Sokolov, 2000).

La vida de Jesús también ha sido convertida en musical y llevada a los escenarios en lugares como Broadway. Entre las aproximaciones líricas a la vida y obra de Jesús destacan "Jesucristo Superstar", ópera rock con música de Andrew Lloyd Webber y libreto de Tim Rice, representada por primera vez en 1970. Mucho más alternativa es la obra "Godspell", con música de Stephen Schartz y libreto de John-Michael Tebelak, representada por primera vez en 1971.










</doc>
<doc id="1537" url="https://es.wikipedia.org/wiki?curid=1537" title="Juan Marsé">
Juan Marsé

Juan Marsé Carbó (Barcelona, 8 de enero de 1933-ib., 18 de julio de 2020) fue un novelista español de la llamada generación del 50, concretamente de la denominada Escuela de Barcelona, corriente que involucraba a sus amigos Jaime Gil de Biedma, Carlos Barral, Juan García Hortelano, Manuel Vázquez Montalbán, Juan Goytisolo, Terenci Moix y Eduardo Mendoza. 

Recibió el Premio Cervantes en 2008.

Nació el 8 de enero de 1933 en Barcelona con el nombre de Juan Faneca Roca, pero tras la muerte de su madre en el parto fue adoptado por un matrimonio, de quienes tomó sus apellidos, pasándose a llamar Juan Marsé Carbó.

Sin terminar sus estudios, se dedicó desde la adolescencia al oficio de joyero. Trabajó durante algún tiempo en la revista barcelonesa de cine "Arcinema", e inicia su carrera literaria en 1958 con unos relatos que aparecerían en las revistas "Ínsula" y "El Ciervo". En 1959 obtuvo su primer premio literario, el Sésamo de Cuentos, por su relato "Nada para morir" y dos años más tarde publicó su primera novela "Encerrados con un solo juguete". También en 1959 se instaló en París, ciudad en la que residió hasta 1962 y en la que desempeñó variadas actividades, incluidas las de profesor de español, traductor y mozo de laboratorio en el departamento de Bioquímica Celular del Instituto Pasteur.

Volvió a Barcelona, donde publicó, en 1962, "Esta cara de la luna", hoy repudiada por el autor y desterrada del catálogo de sus obras completas. También colaboró con el mundo publicitario, con el de la empresa editorial y fue guionista cinematográfico. Como periodista ha sido redactor jefe de la revista "Boccaccio" y colaborador de la revista "Por Favor", en la que llegó a ocupar el puesto de jefe de redacción.

Se casó en 1966 con Joaquina Hoyas. Tuvieron dos hijos: Alejandro, que nació en 1968, y Berta, en 1969. En 1970 publicó la novela "La oscura historia de la prima Montse", en la que se encuentran las claves del universo literario que ha seguido cultivando hasta su deceso.

Asimismo, durante los años 1988-1989 publicó quincenalmente un serial en el diario "El País" bajo el título "Aventuras del capitán Blay".

La década de los 90 supuso la consagración definitiva del escritor barcelonés. En 1990 recibió el Premio Ateneo de Sevilla por "El amante bilingüe"; en 1994 le conceden por "El embrujo de Shanghai" el Premio de la Crítica.

Su obra ha sido traducida a diversos idiomas (alemán, francés, húngaro, inglés, polaco, portugués, rumano, etc.) y varias de sus novelas han sido adaptadas al cine y al teatro, como "Últimas tardes con Teresa", "Si te dicen que caí", "La muchacha de las bragas de oro" y "El amante bilingüe", entre otras.

El 21 de abril de 2009, dos días antes de recibir el Premio Cervantes, se le concedió una urna en la Caja de las Letras.

Falleció en Barcelona el día 18 de julio de 2020, en el Hospital de Sant Pau, a los ochenta y siete años de edad.

Las obras de Marsé se sitúan en Barcelona, y más en concreto el barrio del Guinardó, o en barrios barceloneses próximos a éste, donde pasó su infancia, que coincidió con la posguerra, lo que ha influenciado el modo de escribir del autor a lo largo de toda su vida. En el contexto de la postguerra o durante el franquismo; en ellas, Marsé analiza la degradación moral y social de la misma, las diferencias de clase, la memoria de los vencidos, los enfrentamientos entre trabajadores y burgueses universitarios y la infancia perdida, casi siempre apelando a las técnicas del realismo social, pero experimentando a veces con otros mecanismos narrativos más vanguardistas, siempre con varios grados de ironía.






En la película "El cónsul de Sodoma" (Sigfrid Monleón, 2010) Juan Marsé es interpretado por el actor Àlex Brendemühl.




</doc>
<doc id="1540" url="https://es.wikipedia.org/wiki?curid=1540" title="Júpiter (planeta)">
Júpiter (planeta)

Júpiter es el quinto planeta del sistema solar. Forma parte de los denominados planetas exteriores o gaseosos. Recibe su nombre del dios romano Júpiter (Zeus en la mitología griega).

Se trata del planeta que ofrece un mayor brillo a lo largo del año dependiendo de su fase. Es, además, después del Sol, el mayor cuerpo celeste del sistema solar, con una masa casi dos veces y media la de los demás planetas juntos (con una masa 318 veces mayor que la de la Tierra y tres veces mayor que la de Saturno, además de ser, en cuanto a volumen, 1317 veces más grande que la Tierra). También es el planeta más antiguo del sistema solar, siendo incluso más antiguo que el sol; este descubrimiento fue realizado por investigadores de la universidad de Münster en Alemania. 

Júpiter es un cuerpo masivo gaseoso, formado principalmente por hidrógeno y helio, carente de una superficie interior definida. Entre los detalles atmosféricos es notable la Gran Mancha Roja (un enorme anticiclón situado en las latitudes tropicales del hemisferio sur), la estructura de nubes en bandas oscuras y zonas brillantes, y la dinámica atmosférica global determinada por intensos vientos zonales alternantes en latitud y con velocidades de hasta 140 m/s (504 km/h).

Júpiter es el planeta con mayor masa del sistema solar: equivale a unas 2,48 veces la suma de las masas de todos los demás planetas juntos. A pesar de ello, no es el planeta más masivo que se conoce: más de un centenar de planetas extrasolares que han sido descubiertos tienen masas similares o superiores a la de Júpiter. Júpiter también posee la velocidad de rotación más rápida de los planetas del sistema solar: gira en poco menos de diez horas sobre su eje. Esta velocidad de rotación se deduce a partir de las medidas del campo magnético del planeta. La atmósfera se encuentra dividida en regiones con fuertes vientos zonales con periodos de rotación que van desde las 9 h 50 min 30 s, en la zona ecuatorial, a las 9 h 55 min 40 s en el resto del planeta.

El planeta es conocido por una enorme formación meteorológica, la Gran Mancha Roja, fácilmente visible por astrónomos aficionados dado su gran tamaño, superior al de la Tierra. Su atmósfera está permanentemente cubierta de nubes que permiten trazar la dinámica atmosférica y muestran un alto grado de turbulencia.

Tomando como referencia la distancia al Sol, Júpiter es el quinto planeta del sistema solar. Su órbita se sitúa aproximadamente a 5 UA, unos 750 millones de kilómetros del Sol.

La masa de Júpiter es tal que su baricentro con el Sol se sitúa en realidad por encima de su superficie (1,068 de radio solar, desde el centro del Sol). A pesar de ser mucho más grande que la Tierra (con un diámetro once veces mayor), es considerablemente menos denso. El volumen de Júpiter es equivalente al de 1317 tierras, pero su masa es sólo 318 veces mayor. La unidad de masa de Júpiter (M) se utiliza para medir masas de otros planetas gaseosos, sobre todo planetas extrasolares y enanas marrones.

Si bien Júpiter necesitaría tener 80 veces su masa para provocar las reacciones de fusión de hidrógeno necesarias y convertirse en una estrella, la enana roja más pequeña que se conoce tiene solo un 30 % más de radio que Júpiter (aunque tiene mucha más masa). Júpiter irradia más calor del que recibe de la escasa luz solar que le llega hasta esa distancia. La diferencia de calor desencadenada es generada por la inestabilidad Kelvin-Helmholtz mediante contracción adiabática (encogimiento). La consecuencia de este proceso es la contracción del planeta unos dos centímetros al año. Después de su formación, Júpiter era mucho más caliente y tenía un diámetro casi el doble del actual.

Si fuese unas cuatro veces más masivo, el interior podría llegar a comprimirse mucho más a causa de fuerzas gravitacionales mayores, lo que podría dar lugar a una disminución de su volumen, independientemente de que su masa aumentase. Como resultado de ello, se especula que Júpiter podría alcanzar uno de los diámetros más amplios que un planeta de estas características y evolución puede lograr. El proceso de reducción del volumen con aumento de masa podría continuar hasta que se alcanzara una combustión estelar, como en las enanas marrones con una masa 50 veces la de Júpiter. Esto ha llevado a algunos astrónomos a calificarlo como “estrella fracasada”, aunque no queda claro si los procesos involucrados en la formación de planetas como Júpiter se asemejan a los procesos de creación de sistemas estelares múltiples.

La atmósfera de Júpiter no presenta una frontera clara con el interior líquido del planeta; la transición se va produciendo de una manera gradual.
Se compone en su mayoría de hidrógeno (87 %) y helio (13 %), además de contener metano, vapor de agua, amoníaco y sulfuro de hidrógeno, todas estas con < 0,1 % de la composición de la atmósfera total.

El astrónomo aficionado inglés A.S. Williams hizo el primer estudio sistemático sobre la atmósfera de Júpiter en 1896. La atmósfera de Júpiter está dividida en cinturones oscuros llamados bandas y regiones claras llamadas zonas, todos ellos alineados en la dirección de los paralelos. Las bandas y zonas delimitan un sistema de corrientes de viento alternantes en dirección con la latitud y en general de gran intensidad; por ejemplo, los vientos en el ecuador soplan a velocidades en torno a 100 m/s (360 km/h). En la Banda Ecuatorial Norte, los vientos pueden llegar a soplar a 140 m/s (500 km/h). La rápida rotación del planeta (9 h 55 min 30 s) hace que las fuerzas de Coriolis sean muy intensas, siendo determinantes en la dinámica atmosférica del planeta.

El científico inglés Robert Hooke observó en 1664 una gran formación meteorológica que podría ser la Gran Mancha Roja (conocida en inglés por las siglas GRS, del Great Red Stain). Sin embargo, no parecen existir informes posteriores de la observación de tal fenómeno hasta el siglo XX. En todo caso, varía mucho tanto de color como de intensidad. Las imágenes obtenidas por el Observatorio Yerkes a finales del siglo XIX muestran una mancha roja alargada, ocupando el mismo rango de latitudes pero con el doble de extensión longitudinal. A veces, es de un color rojo fuerte, y realmente muy notable, y en otras ocasiones palidece hasta hacerse insignificante. Históricamente, en un principio se pensó que la Gran Mancha Roja era la cima de una montaña gigantesca o una meseta que salía por encima de las nubes. Esta idea fue sin embargo desechada en el siglo XIX al constatarse espectroscópicamente la composición de hidrógeno y helio de la atmósfera y determinarse que se trataba de un planeta fluido. El tamaño actual de la Gran Mancha Roja es aproximadamente unas dos veces y media el de la Tierra. Meteorológicamente, la Gran Mancha Roja es un enorme anticiclón muy estable en el tiempo. Los vientos en la periferia del vórtice tienen una velocidad cercana a los 400 km/h.

En marzo de 2006 se anunció que se había formado una segunda mancha roja aproximadamente de la mitad del tamaño de la Gran Mancha Roja. Esta segunda mancha roja se formó a partir de la fusión de tres grandes óvalos blancos presentes en Júpiter desde los años 1940, denominados BC, DE y FA, y fusionados en uno solo entre los años 1998 y 2000, dando lugar a un único óvalo blanco denominado "Óvalo blanco BA",
cuyo color evolucionó hacia los mismos tonos que la Gran Mancha Roja a comienzos del 2006.
La coloración rojiza de ambas manchas puede producirse cuando los gases de la atmósfera interior del planeta se elevan en la atmósfera y sufren la interacción de la radiación solar. Las mediciones en el infrarrojo sugieren que ambas manchas se elevan por encima de las nubes principales. El paso, por tanto, de óvalo blanco a mancha roja podría ser un síntoma de que la tormenta está ganando fuerza. El 8 de abril de 2006, la cámara de seguimiento avanzada del Hubble tomó nuevas imágenes de la joven tormenta.

Las nubes superiores de Júpiter están formadas probablemente de cristales congelados de amoníaco. El color rojizo viene dado por algún tipo de agente colorante desconocido aunque se sugieren compuestos de azufre o fósforo. Por debajo de las nubes visibles Júpiter posee muy posiblemente nubes más densas de un compuesto químico llamado hidrosulfuro de amonio, NHHS. A una presión en torno a 5-6 Pa existe posiblemente una capa aún más densa de nubes de agua. Una de las pruebas de la existencia de tales nubes la constituye la observación de descargas eléctricas compatibles con tormentas profundas a estos niveles de presión. Tales tormentas convectivas pueden en ocasiones extenderse desde los 5 Pa hasta los 300-500 hPa, unos 150 km en vertical.

A finales de abril de 2010, diferentes astrónomos aficionados advirtieron que Júpiter había alterado el color del cinturón subecuatorial, tradicionalmente oscuro, apareciendo la parte sur completamente blanca y muy homogénea. El fenómeno tuvo lugar cuando Júpiter estaba en oposición con el Sol, siendo por lo tanto, observable desde la Tierra. Se barajan varias hipótesis para explicar este cambio, la considerada más probable es un cambio en la coloración de las nubes sin cambios sustanciales en la altura o cantidad de partículas que las forman. Este fenómeno de desaparición aparente de una banda ocurre de manera semi cíclica en Júpiter habiéndose observado con anterioridad en varias ocasiones, en particular en el año 1993 cuando fue estudiado en detalle.
Galería de imágenes de las nubes de Júpiter

En el interior del planeta el hidrógeno, el helio y el argón (gas noble que se acumula en la superficie de Júpiter) se comprimen progresivamente. El hidrógeno molecular se comprime de tal manera que se transforma en un líquido de carácter metálico a profundidades de unos 15 000 km bajo la superficie. Más abajo se espera la existencia de un núcleo rocoso formado principalmente por materiales helados y más densos, de unas siete masas terrestres (aunque un modelo reciente aumenta la masa del núcleo central de este planeta entre 14 y 18 masas terrestres, y otros autores piensan que puede no existir tal núcleo, además de existir la posibilidad de que el núcleo fuera mayor en un principio, pero que las corrientes convectivas de hidrógeno metálico caliente le habrían hecho perder masa). La existencia de las diferentes capas viene determinada por el estudio del potencial gravitatorio del planeta, medido por las diferentes sondas espaciales. De existir el núcleo interno, probaría la teoría de formación planetaria a partir de un disco de planetesimales. Júpiter es tan masivo que todavía no ha liberado el calor acumulado en su formación, y posee, por lo tanto, una importante fuente interna de energía calórica que ha sido medida de manera precisa y equivale a 5,4 W/m². Esto significa que el interior del planeta está mezclado de manera eficaz por lo menos hasta niveles cercanos a las nubes de agua a 5 bar.

El mismo modelo mencionado antes, que da una masa mayor al núcleo del planeta, considera que este tiene una estructura interna formada por cilindros concéntricos que giran a distinta velocidad —los ecuatoriales (que son los externos) más rápido que los internos—, de modo similar al Sol; se espera que la misión JUNO, que fue lanzada en 2011 y que entró en órbita alrededor del planeta el 4 de julio de 2016, pueda determinar con sus mediciones de la gravedad joviana la estructura interna del planeta.

Júpiter tiene una magnetosfera extensa formada por un campo magnético de gran intensidad. El campo magnético de Júpiter podría verse desde la Tierra ocupando un espacio equivalente al de la Luna llena a pesar de estar mucho más lejos. El campo magnético de Júpiter es de hecho la estructura de mayor tamaño en el sistema solar. Las partículas cargadas son recogidas por el campo magnético joviano y conducidas hacia las regiones polares donde producen impresionantes auroras. Por otro lado las partículas expulsadas por los volcanes del satélite Ío forman un toroide de rotación en el que el campo magnético atrapa material adicional que es conducido a través de las líneas de campo sobre la atmósfera superior del planeta.

Se piensa que el origen de la magnetosfera se debe a que en el interior profundo de Júpiter, el hidrógeno se comporta como un metal debido a la altísima presión. Los metales son, por supuesto, excelentes conductores de electrones, y la rotación del planeta produce corrientes, las cuales a su vez producen un extenso campo magnético.

Las sondas Pioneer confirmaron la existencia del campo magnético joviano y su intensidad, siendo más de 10 veces superior al terrestre conteniendo más de 20 000 veces la energía asociada al campo terrestre.
Los Pioneer descubrieron que la onda de choque de la magnetosfera joviana se extiende a 26 millones de kilómetros del planeta, con la cola magnética extendiéndose más allá de la órbita de Saturno.

Las variaciones del viento solar originan rápidas variaciones en tamaño de la magnetosfera. Este aspecto fue estudiado por las sondas Voyager. También se descubrió que átomos cargados eran expulsados de la magnetosfera joviana con gran intensidad y eran capaces de alcanzar la órbita de la Tierra. También se encontraron corrientes eléctricas fluyendo de Júpiter a algunos de sus satélites, particularmente Ío y también en menor medida Europa.

Los principales satélites de Júpiter fueron descubiertos por Galileo Galilei el 7 de enero de 1610, razón por la que se les llama satélites galileanos. Reciben sus nombres de la mitología griega si bien en tiempos de Galileo se los denominaba por números romanos dependiendo de su orden de cercanía al planeta. Originalmente, Galileo bautizó a los satélites como "Mediceos", en honor a Cosme de Médicis, duque de Florencia. El descubrimiento de estos satélites constituyó un punto de inflexión en la ya larga disputa entre los que sostenían la idea de un sistema geocéntrico, es decir, con la Tierra en el centro del universo, y la copernicana (o sistema heliocéntrico, es decir, con el Sol en el centro del sistema solar), en la cual era mucho más fácil explicar el movimiento y la propia existencia de los satélites naturales de Júpiter.

Los cuatro satélites principales son muy distintos entre sí. Ío, el más interior, es un mundo volcánico con una superficie en constante renovación y calentado por efectos de marea provocados por Júpiter y Europa. Europa, el siguiente satélite, es un mundo helado bajo el cual se especula la presencia de océanos líquidos de agua e incluso la presencia de vida. Ganímedes, con un diámetro de 5268 km, es el satélite más grande de todo el sistema solar. Está compuesto por un núcleo de hierro cubierto por un manto rocoso y de hielo. Calisto se caracteriza por ser el cuerpo que presenta mayor cantidad de cráteres producidos por impactos en todo el sistema solar.

Además de los mencionados satélites galileanos, las distintas sondas espaciales enviadas a Júpiter y observaciones desde la Tierra han ampliado el número total de satélites de Júpiter hasta 79. Estos satélites menores se pueden dividir en dos grupos:



Además de sus satélites, el campo gravitacional de Júpiter controla las órbitas de numerosos asteroides que se encuentran situados en los puntos de Lagrange precediendo y siguiendo a Júpiter en su órbita alrededor del Sol. Estos asteroides se denominan asteroides troyanos y se dividen en cuerpos griegos y troyanos para conmemorar la "Ilíada". El primero de estos asteroides en ser descubierto fue 588 Aquiles, por Max Wolf en 1906. En la actualidad se conocen cientos de asteroides troyanos. El mayor de todos ellos es el asteroide 624 Héctor.

Júpiter posee un tenue sistema de anillos que fue descubierto por la sonda Voyager 1 en marzo de 1979. El anillo principal tiene unos 6400 km de anchura, orbita el planeta a 122 800 km de distancia del centro y tiene un espesor vertical inferior a la decena de kilómetros. Su espesor óptico es tan reducido que solamente ha podido ser observado por las sondas espaciales Voyager 1 y 2 y Galileo.

Los anillos tienen tres segmentos: el más interno denominado halo (con forma de toro en vez de anillo), el intermedio que se considera el principal por ser el más brillante y el exterior, más tenue pero de mayor tamaño. Los anillos están formados por polvo en vez de hielo como los anillos de Saturno. El anillo principal está compuesto probablemente por material de los satélites Adrastea y Metis; este material se ve arrastrado poco a poco hacia Júpiter gracias a su fuerte gravedad. A su vez se va reponiendo por los impactos sobre estos satélites que se encuentran en la misma órbita que el anillo principal. Los satélites Amaltea y Tebas realizan una tarea similar, proveyendo de material al anillo exterior.

Las teorías de formación del planeta son de dos tipos: 

Ambos modelos tienen implicaciones muy distintas para los modelos generales de formación del sistema solar y de los sistemas de planetas extrasolares. En ambos casos los modelos tienen dificultades para explicar el tamaño y masa total del planeta, su distancia orbital de 5 ua, que parece indicar que Júpiter no se desplazó sustancialmente de la región de formación, y la composición química de su atmósfera, en particular de gases nobles, enriquecidos con respecto al Sol. El estudio de la estructura interna de Júpiter, y en particular, la presencia o ausencia de un núcleo interior permitiría distinguir ambas posibilidades.

Las propiedades del interior del planeta pueden explorarse de manera remota a partir de las perturbaciones gravitatorias detectadas por una sonda espacial cercana.

Actualmente existen propuestas de misiones espaciales para la próxima década que podrían responder a estos interrogantes.

En julio de 1994 el cometa Shoemaker-Levy 9 impactó contra la atmósfera de Júpiter. El cometa había sido disgregado por la acción de la gravedad de Júpiter en 20/22 fragmentos en un paso anterior y cercano por el planeta.

Numerosos observatorios realizaron campañas intensivas de observación del planeta con motivo de este suceso único incluyendo el telescopio espacial Hubble y la sonda Galileo que en aquel momento se encontraba acercándose todavía al planeta. Los impactos mostraron la formación de impresionantes bolas de fuego en los minutos posteriores a cada impacto de cuyo análisis se pudo deducir la masa de cada uno de los fragmentos del cometa. Los restos dejados en la atmósfera se observaron como nubes negras en expansión durante semanas propagándose como ondas de choque. Sus propiedades permitieron analizar tanto propiedades del cometa como de la atmósfera joviana y su interior profundo por métodos análogos a los de la sismología terrestre. Los restos del cometa pudieron ser detectados durante varios años en la alta atmósfera del hemisferio Sur de Júpiter, presentes como partículas finas oscuras y mediante una mayor concentración atmosférica de determinados compuestos químicos aportados por el cometa.

Se ha estimado que Júpiter, debido a su gran masa, perturba las regiones cometarias como la nube de Oort atrayendo la mayoría de los cometas que caen sobre el sistema solar interior. No obstante, también los acerca sobre sí mismo por lo que es difícil estimar la importancia que tiene Júpiter en la llegada de cometas a la Tierra.

El día 19 de julio de 2009 Anthony Wesley, un astrónomo aficionado australiano anunció el descubrimiento de una mancha negra de un tamaño similar al diámetro de la Luna que había aparecido en la atmósfera de Júpiter en la región subpolar sur. Esta mancha estaba causada posiblemente por un impacto asteroidal o cometario con el planeta. Científicos del Laboratorio de Propulsión (JPL) de Pasadena, confirmaron el impacto utilizando el telescopio infrarrojo de NASA (IRTF, NASA Infrared Telescope Facility) ubicado en la isla hawaiana de Mauna Kea.

El objeto causante del impacto, con un diámetro estimado de unos 500 metros, provocó un aumento de la temperatura en las capas altas de la atmósfera joviana en el lugar del impacto y una gran nube de partículas de polvo oscuras que forman la mancha de impacto de gran extensión y que continuó siendo observable durante varios meses de forma progresivamente más tenue al ser dispersados los restos del impacto por los vientos de la atmósfera de Júpiter. Por el momento se desconoce si el objeto que impactó con Júpiter era un asteroide o un cometa. El impacto, descubierto por casualidad, ocurrió 15 años después del impacto del cometa Shoemaker-Levy 9.

El 3 de junio de 2010, casi un año más tarde, Anthony Wesley y Christopher Go (astrónomo aficionado de Filipinas) observaron simultáneamente la aparición de un intenso flash de luz en Júpiter en una región muy localizada que se corresponde con el impacto de un cuerpo asteroidal o cometario de menor tamaño que en 2009. El flash, que duró unos pocos segundos, se produjo en latitudes ecuatoriales y por el momento no parece haber dejado ningún remanente de material observable en la atmósfera joviana.

Júpiter ha sido visitado por varias misiones espaciales de NASA desde 1973.

Las misiones Pioneer 10 y Pioneer 11 realizaron una exploración preliminar con sobrevuelos del planeta.
La sonda Pioneer 10 sobrevoló Júpiter por primera vez en la historia en diciembre de 1973. La sonda Pioneer 11 le siguió justo un año después. Se tomaron las primeras fotos cercanas de Júpiter y de los satélites galileanos, se estudió su atmósfera, se detectó su campo magnético y se estudiaron sus cinturones de radiación.
Las misiones Voyager 1 y Voyager 2 visitaron Júpiter en 1979 revolucionando el conocimiento que se tenía del planeta y sus satélites y descubriendo también su sistema de anillos. Se descubrió que Ío tenía una actividad volcánica extraordinaria y que Júpiter también poseía anillos.
En 1995 la misión Galileo, que constaba de una sonda y un orbitador, inició una misión de exploración del planeta de siete años. Aunque la misión tuvo importantes problemas con la antena principal que retransmitía los datos a la Tierra, consiguió enviar informaciones con una calidad sin precedentes sobre los satélites de Júpiter, descubriendo los océanos subsuperficiales de Europa y varios ejemplos de vulcanismo activo en Ío. La misión concluyó lanzando al orbitador contra el propio planeta para evitar una colisión futura con Europa que pudiera contaminar sus hielos.

En diciembre de 2000 la misión espacial Cassini/Huygens realizó un sobrevuelo lejano en su viaje con destino a Saturno obteniendo un conjunto de datos comparable en cantidad a los sobrevuelos realizados por las Voyager pero con una calidad de las observaciones mejor.
A finales de febrero de 2007 el planeta Júpiter fue visitado por la sonda New Horizons en su viaje a Plutón.

El 5 de julio de 2016 entró en órbita la sonda espacial Juno para estudiar la atmósfera, la magnetosfera y auroras de este planeta.

Están en estudio misiones dedicadas a la observación de Júpiter y su satélite Europa por parte de las agencias espaciales NASA y ESA.
Así como el resto de planetas más externos que la Tierra en su órbita con respecto al Sol, Júpiter puede ocupar cualquier parte de la eclíptica o encontrarse oculto detrás del Sol. No ocurre como con Venus y Mercurio, que por tener sus órbitas más cerca del Sol que la de la Tierra, solo los podemos localizar en dirección al astro. Dado su brillo, Júpiter es visible a simple vista, el cual aparece como una estrella redondeada y de color pálido, siendo el segundo planeta a simple vista más luminoso después de Venus. Con un telescopio, también se puede ver su atmósfera y sus satélites.





</doc>
<doc id="1541" url="https://es.wikipedia.org/wiki?curid=1541" title="Java">
Java

Java hace referencia a varios artículos:





</doc>
<doc id="1548" url="https://es.wikipedia.org/wiki?curid=1548" title="Jackson Day">
Jackson Day

Jackson Day, se celebra el 8 de enero en los Estados Unidos.
Este día rememora la Batalla de Nueva Orleans, la cual es un episodio de la lucha del pueblo norteamericano por lograr su independencia del gobierno británico.

En realidad, no está compuesta por una sola batalla, sino por una serie de ellas comprendidas en el período que abarca desde diciembre de 1814 hasta enero de 1815. La victoria americana en esta región forzó a los británicos a reconocer las pretensiones de los Estados Unidos de Norteamérica sobre Luisiana y la parte occidental de Florida, lo que da origen al fin de la Guerra de Independencia Americana y a la incorporación política del estado de Luisiana a la Unión. El comandante Andrew Jackson lideró las fuerzas norteamericanas durante esta campaña, llamada "del Golfo".


</doc>
<doc id="1549" url="https://es.wikipedia.org/wiki?curid=1549" title="Jamón">
Jamón

El jamón (o anca, pernil, pierna) es el nombre genérico del producto alimenticio obtenido de las patas traseras del cerdo.

En España, la preparación más habitual del jamón es salado en crudo y curado de forma natural. Las patas delanteras del cerdo, pese a tener un proceso idéntico de elaboración, reciben el nombre de "paleta" o "paletilla". También reciben el nombre de "lacón"; palabra que se aplica exclusivamente a la paleta o paletilla de cerdo. Las dos variedades más conocidas de jamón curado son el de España (jamón ibérico, jamón serrano) y el prosciutto italiano. En diversos países latinoamericanos el nombre de jamón hace referencia solamente al jamón York.

Las primeras noticias del jamón son del Imperio romano aunque los primeros cerdos ("Sus scrofa domestica") aparecieron a inicios del Neolítico. En Tarraco se encontró un jamón fosilizado de casi dos mil años. Las razas actuales de cerdo ibérico son el producto de largos procesos de selección y adaptación a las condiciones ambientales locales; aunque tampoco se debe descartar el papel jugado por la hibridación con jabalíes.

Este producto tradicionalmente es muy consumido en España, por lo que son distintas las elaboraciones y denominaciones que de él existen. A grandes rasgos se pueden distinguir dos tipos de jamones según la raza del cerdo del que procede, sea cerdo ibérico ("jamón ibérico") o alguna variedad de cerdo blanco ("jamón" o "jamón serrano").

El jamón ibérico procede del cerdo de raza ibérica. Las principales características que lo distinguen en su calidad derivan de la pureza de la raza de los animales, de la cría en régimen extensivo de libertad del cerdo ibérico en dehesas arboladas donde puedan moverse, de la alimentación y de la curación del jamón, que suele extenderse entre los 8 a 36 meses. El jamón ibérico se distingue del resto por su textura, aroma y sabor singulares y distinguibles aunque el sabor varía según el grado de bellota que haya comido el cerdo, y del ejercicio que haya hecho.

Se clasifica generalmente según la cantidad de bellota que haya consumido antes del sacrificio. La clasificación oficial permitida para los jamones ibéricos los agrupa en: Jamón Ibérico de Cebo, Jamón Ibérico de Cebo Campo, Jamón Ibérico de Recebo y Jamón Ibérico de Bellota.

Algunas regiones con tradición de elaboración de jamones crearon, junto con el Ministerio de Medio Ambiente y Medio Rural y Marino, las Denominaciones de Origen, que exigen y controlan que los jamones ibéricos cumplan unas determinadas características para poder llevar su sello de calidad. Las denominaciones de origen reconocidas del cerdo ibérico son: Jamón Ibérico D. O.P. Jamón de Guijuelo, Jamón Ibérico D. O.P. Jabugo, Jamón Ibérico D. O. P. Los Pedroches y Jamón Ibérico D.O. Dehesa de Extremadura. Las denominaciones de origen están protegidas legalmente por el Reglamento Europeo (CE) nº 1151/2012 del Consejo de la Unión Europea. Aparte de ello existen diferentes denominaciones comerciales conocidas por el consumidor español, pero frecuentemente confundidas por su ambigüedad, como serían las de "Jamón de Pata Negra", "Jamón de Jabugo" o "Jamón 5J" o "Valderado" o "Monte Regio" o "Joselito", estas cuatro últimas son marcas de reconocido prestigio en España. Para valorar su calidad sólo existe la clasificación oficial, que además debe quedar plasmada en la etiqueta identificativa de la pieza (vitola). En cuanto a la clasificación, reglamentación y aplicación de la norma en relación al Jamón Ibérico se puede consultar el Real Decreto 1083/2001 y modificaciones posteriores.
El jamón serrano o jamón blanco procede de alguna variedad de raza de cerdo blanco, y el jamón se distingue fácilmente por el color de la piel del pernil. Se le denomina "serrano" cuando se cura en clima de sierra, frío y seco. Actualmente está regulado por el Reglamento comunitario 2082/92, en el que se definen las características del proceso y del producto terminado. Este jamón diferencia tres calidades según su curación: jamón bodega, jamón reserva y jamón gran reserva. Los hay de Almería, Granada, de Salamanca, de Ávila, y de otras muchas regiones. Entre ellas cabe destacar diferentes Denominaciones de origen como el Jamón de Teruel, el Jamón de Trevélez además de otras producciones sin denominación pero con tradición jamonera como el Jamón de chato murciano o el Jamón de cerdo Duroc.

En toda la zona noroeste de España los jamones también se curan tradicionalmente ahumados. El ahumado es un recurso que se emplea en climas húmedos, donde no se puede secar un jamón (o cualquier otro embutido) solamente al aire. También en la parte seca de Castilla, cuando un invierno resulta húmedo las producciones familiares de chacina se ahuman.

El término «"prosciutto"» se refiere a un corte de la carne del cerdo correspondiente al miembro posterior. Aunque en ocasiones puede ser cocinado o ser servido fresco. El "prosciutto" italiano posee múltiples variedades como pueden ser el "prosciutto di Parma", "prosciutto di San Daniele", "prosciutto Sardo", "prosciutto di Carpegna", "prosciutto di Modena", "prosciutto toscano", "prosciutto veneto Berico-Euganeo", "Valle d’Aosta Jambon de Bosses", "prosciutto di Norcia", "prosciutto cotto"...)






</doc>
<doc id="1550" url="https://es.wikipedia.org/wiki?curid=1550" title="Jamón serrano">
Jamón serrano

El jamón serrano es un alimento obtenido a partir de la salazón y secado al aire de las patas traseras del cerdo. Este mismo producto recibe también el nombre de paleta o paletilla cuando se obtiene de las patas delanteras. El "jamón serrano" se contrapone al jamón cocido, también llamado "jamón de York" o "jamón dulce". Se llama "serrano" por la costumbre de curar el jamón en parajes altos de las sierras, donde las bajas temperaturas facilitan la curación.

El cerdo puede ser de raza blanca o bien de la raza llamada ibérica. El jamón de este último es llamado "jamón ibérico", y "jamón de bellota" cuando este último ha ingerido cierta cantidad de bellota durante el período de montanera (engorde). El cerdo blanco no se alimenta con bellota. El jamón y las paletas de cerdo Duroc son un tipo de jamón más infiltrado y con más grasa dorsal que el jamón de cerdo blanco.

En el lenguaje ordinario —especialmente en las cartas de los restaurantes— cuando se ofrece "jamón serrano" se sobreentiende que no se trata de jamón serrano de cerdo ibérico, sino de jamón serrano de cerdo blanco, más barato. Cuando se ofrece jamón cocido o de York se sobrentiende también que se trata de cerdo blanco, pues el jamón ibérico no se suele cocer. Excepcionalmente, sin embargo, algunos establecimientos ofrecen cerdo ibérico cocido, que no ha sido curado previamente.

En algunos países el nombre "jamón serrano" hace referencia por extensión al jamón curado para distinguirlo del jamón de York el cual se le conoce simplemente como "jamón". 

El jamón serrano curado tiene tres denominaciones: 

Estas denominaciones, son especificadas por el artículo 21, del Real Decreto 474/2014, de 13 de junio, por el que se aprueba la norma de calidad de derivados cárnicos.

La denominación "jamón serrano" está protegida como Especialidad Tradicional Garantizada (E.T.G.) por el Reglamento de la Unión Europea 2082/92, en el que se definen las características del proceso y del producto terminado dentro de esta denominación también hay tres categorías que tiene estipulada esta organización y que podía ser como la anterior del jamón curado de cerdo blanco "bronce para jamones de 9 a 12 meses de curación, plata para los de 12 a 15 meses y oro para los que tengan una curación superior a los 15 meses.




Es de resaltar que el 60 % de la producción española de jamón ibérico pertenece a la D.O. Jamón de Guijuelo.5​

En Portugal se utiliza la palabra "presunto" para denominar este tipo de jamón.
En Argentina se distingue el "jamón serrano" del jamón crudo por estar el primero recubierto de pimentón y por venderse más estacionado.

En el llamado proceso de curación se pueden encontrar tres factores imprescindibles que, al conjugarse, producen una maduración ideal en los jamones.


El pH no debe ser excesivamente alto (<5.8) para minimizar el crecimiento microbiano, no deben ser carnes PSE/DFD, preferible carnes más bien grasas, bien refrigeradas o congeladas, que no tengan fracturas ni hematomas, carnes de buena calidad, baja carga microbiana inicial y preferibles piezas grandes.

La materia prima se puede recepcionar congelada o refrigerada. El peso total de los jamones en sangre tendrán un peso mínimo de 9,5 kilos para aquellos que se presenten con pata y de 9,2 kilos para los jamones sin pata. Y, por último, se tendrá en cuenta la cantidad de contenido graso.

Eliminación de partes de la musculatura, grasa y piel para conferir a las piezas las proporciones y características de redondos, biselados o cortos.

Evitar que se quede sangre retenida en el interior del jamón aplicando presión.
Puede que sea la parte más importante de todo el proceso, ya que la calidad de los jamones curados, serranos e ibéricos, se basa en la mayor o menor actuación de la sal. La salazón de los jamones ayuda en la deshidratación y juega un papel importante en la conservación (agente bacteriostático).

¿En qué consiste? Las piezas se cubren con sal marina con el fin de que esta penetre homogéneamente en toda la masa muscular. La sal suele ser más gorda en el caso del jamón ibérico, y más fina si se trata de jamón serrano.

¿Cómo se hace? Los jamones se apilan en el suelo o en contenedores, alternando capa de sal–capa de jamón y así sucesivamente. La primera capa y la última son de sal. Como en la hilera que está abajo va a penetrar más la sal por la presión, a mitad del proceso se invierte la posición de las piezas.

La cámara de salazón se encuentra a 3-4 ºC y con una humedad relativa del 80-90%. Parece alta, pero hemos de tener en cuenta que las temperaturas son muy bajas. En definitiva, en esta fase los jamones pierden un 10% de su peso.

Su principal objetivo es la reducción de la aw (actividad de agua) para inhibir la proliferación de microorganismos y aumentar su vida útil, se lleva a cabo cubriendo las piezas en capas de sal:
El tiempo dependerá del peso en contenido graso, desde 0,65 días-2 días/kilo.
Distribución homogénea de la sal.

Cuando el jamón se saca de la pila de salazonado ya ha tomado toda la sal que va a tener hasta el final del proceso. Sin embargo, esta se encuentra concentrada en la superficie mientras que las regiones del interior prácticamente no contienen sal. Por ello es necesario un período de postsalado o equilibramiento, donde por proceso de difusión se tiende a una distribución uniforme de la concentración salina hasta alcanzar el punto exacto de sal. La duración mínima del equilibramiento es variable y va en función del contenido graso de cada pieza ya que la penetración salina por difusión está muy condicionada por la presencia de grasa. Aunque por lo general este proceso suele tener una duración entre los 50 y 90 días. Otro factor importante es que mientras se está produciendo la penetración de sal al interior del jamón, hay un proceso de salida de agua al exterior, con la consiguiente perdida de humedad desde la superficie. Por ello, es necesario tener un estrecho control de la humedad relativa de la cámara donde se mantengan los jamones, amen del propio control de la temperatura, que desde los 5 °C iniciales ha de evolucionar hasta los 16 o 20 °C en el momento en que se les traslada al secadero natural.

Se realiza para eliminar la sal superficial, para lo cual se introducen los jamones en un recipiente en el que existen cepillos, cuyas púas por frotamiento ayudan a este proceso. Actualmente existen máquinas automáticas para efectuar el lavado y frotamiento de las piezas. 

Es importante que la sal esté limpia y que el lavado sea correcto para evitar que el depósito de la sal en el exterior del jamón inhiba el crecimiento de la flora. 
Hasta aquí, se ha hecho un buen proceso del jamón que puede servir para cualquier tipo que se elabore; ahora empiezan los problemas, ya que el jamón va a quedar expuesto, sin nada que lo proteja, dado el escaso valor antiséptico que se puede asignar a la sal a las variaciones climáticas, contaminación bacteriana, agresiones del medio ambiente, parasitismo, etc.

El lavado también se puede realizar inmediatamente después de sacar la pierna de la sal. Si se hace esto, hay que dejar la pierna pocos días más (1,5 a 2 días por kg), para que la sal logre ingresar a los tejidos musculares. También se consigue que una vez hecho el lavado, se pueda inocular con el hongo especial, y no volver a intervenir la pierna hasta el final del proceso.

En esta etapa se trasladan los jamones a un secadero natural en el que la humedad y la temperatura se controlan principalmente mediante mecanismos de ventilación. La temperatura oscila entre los 15 º y los 30 ºC durante los 6 a 9 meses que dura el secado, la HR disminuye desde 80 % a 65 % desde 60-150 días (posible estufaje posterior: 25-35 ºC, acelera el secado). En este tiempo, el jamón continúa deshidratándose y también tiene lugar el sudado (difusión de la grasa entre las fibras musculares que permitirá retener el aroma una vez impregnadas).
El jamón sufre un procesos de proteólisis y lipólisis.

Después de una clasificación previa según su peso, calidad y conformación, los jamones y paletas pasan a la bodega donde concluye la última fase de curación, madurando lentamente. Permanecerán entre 6 y 18 meses según la clasificación anterior. En esta fase la temperatura oscila entre los 15 y 25 °C y con humedades relativas en torno al 40-65 %.

Tanto un buen secadero natural, como una buena bodega, deben permitir realizar todas estas operaciones de forma absolutamente natural, sin actuar por ningún procedimiento no consagrado por la tradición y la práctica. 
Es una cuestión de sensibilidad, pues el resultado final dependerá tanto de las características del propio secadero como de la habilidad de las gentes que en el trabajan, y que con una dedicación total y una experiencia manifiesta, han de combinar los factores de altitud, microclima, grado higrométrico, variaciones diarias de temperatura, y velocidad del aire, dirigiendo un proceso cuyo final es la obtención del jamón ibérico de bellota.


Desde el punto de vista nutricional, el proceso de modificación de sus proteínas y sus grasas durante su curación hacen del jamón un producto ligero, con más proteínas y menos grasas que el producto en fresco. Sus proteínas son de alta calidad, es decir, contiene todos los aminoácidos esenciales (100 g de jamón serrano equivalen al 33 % del consumo diario de proteínas recomendado).

Además, es un producto que no necesita colorantes. El jamón serrano es muy digestivo y sano. Contiene ácidos grasos insaturados y es un alimento rico en vitaminas B1 y B6, fósforo, hierro, potasio y zinc. De hecho, un estudio realizado por el "Centro Grand Forks de Investigación de Nutrición Humana", asegura que el serrano es muy recomendable para retrasar la aparición de la fatiga en los deportistas gracias a sus contenidos en vitaminas y minerales.

Posee un buen equilibrio de ácidos grasos, de similar naturaleza que las del aceite de oliva. Además, pese a que está curado en sal, apenas contiene este mineral.

España es el primer productor mundial de jamones y paletas curados. En 2003 superó los 41,5 millones de piezas, de las cuales el 86,5 % corresponde a jamones y el 13,5 % restante a las paletas. España es igualmente el primer consumidor con un consumo por habitante y año de 5 kg.

La Unión Europea es la zona en donde se desarrolla el mayor intercambio comercial de jamones y paletas curados. España ocupa un segundo puesto en el ranking exportador Europeo por detrás de Italia. Los países de la Unión Europea son los principales destinos de las exportaciones españolas de jamón curado. Francia, Alemania y Portugal, conjuntamente, concentran el 75,8% del volumen y el 70,6% del valor total de las expediciones.

El jamón es popular en España para comerlo como tapa en locales o en bocadillo.
Después del corte, la superficie del jamón suele cubrirse con la propia grasa para evitar que se seque. Para ello se cortan rebanadas amplias de los laterales colocándose sobre la superficie del corte "a la vista".


Real Decreto 474/2014, de 13 de junio, por el que se aprueba la norma de calidad de derivados cárnicos.


</doc>
<doc id="1552" url="https://es.wikipedia.org/wiki?curid=1552" title="Juglandales">
Juglandales

Las Juglandales eran un orden de plantas de flor utilizado en el sistema Cronquist. Se consideraban cercanas a las Fagales, porque tiene flores pequeñas, unisexuales, y agrupadas en amentos (las masculinas), además presenta igual distribución de brácteas y bracteolas; periantio pequeño; gineceo supero bicarpelar y fecumdación por chalazogamia. Sin embargo las plantas más parecidas, son las Julianaceae, que están dentro de Sapindales, se diferencia de las Fagales, por las hojas siempre compuestas, y por ser siempre plantas aromáticas. Gran controversia en la interpretación de las flores y frutos. Fruto en drupa procedente de un gineceo ínfero, otros lo interpretan como semiínfero, considerando que la envuelta carnosa es un hipanto.

En las clasificaciones modernas se considera parte de las Fagales.


</doc>
<doc id="1553" url="https://es.wikipedia.org/wiki?curid=1553" title="Juglandaceae">
Juglandaceae

Las juglandáceas (Juglandaceae) son una familia del orden Fagales. Agrupa unos 8 géneros de árboles caducifolios, monoicos, resinosos y olorosos, en total, unas 50 especies, la mayoría de regiones templadas del hemisferio norte. 

La familia está compuesta por árboles –en raras ocasiones arbustos, en especies extraibéricas–, unisexuales, monoicos, rara vez dioicos, de médula sólida o perforada, generalmente ricos en taninos, a menudo con pequeñas glándulas peltadas, de color amarillo pálido–que al secarse adquieren aspecto de escamas–, y pelos fasciculados o glandulíferos. Las yemas son desnudas o protegidas por catáfilos. Las hojas son caducas, rara vez perennes, alternas –rara vez opuestas o verticiladas–, compuestas, pari- o imparipinnadas, a veces ternadas, pecioladas o sésiles, olorosas con folíolos de enteros a serrados, sin estípulas. La inflorescencia masculina está en amento, solitario o agrupados en panícula, en general lateral, erecto o péndulo, en la base de las ramas del año anterior. La inflorescencia femenina también está en el amento, con numerosas flores y péndulo, o en racimo con pocas flores y erecto, al menos en la fructificación, terminal en las ramas del año –inflorescencia rara vez en panícula andrógina, con el amento central, espiciforme, con todas las flores femeninas (o solo algunas) y los laterales. Las flores masculinas son de brácteas enteras o trilobuladas, soldadas al pedicelo y más o menos soldadas al receptáculo; hay de 0 a 2 bractéolas, soldadas al pedicelo y más o menos soldadas al receptáculo y sépalos, de tal forma que todo el conjunto parecen partes del cáliz. El receptáculo es más o menos plano, corto o alargado; el cáliz tiene 0-4 sépalos, soldados al receptáculo y, en su caso, a brácteas y bractéolas, con 0-4 lóbulos apicales, más o menos irregulares; los estambres, en número de (2)3-50, son sésiles o casi, de anteras glabras o pubescentes dehiscentes longitudinalmente,; el polen tiene 3-9(-16)-poros y es foraminado o rugado; el gineceo es vestigial o inexistente. Las flores femeninas, de brácteas enteras o trilobuladas, y 2(3) bractéolas enteras o más o menos dentadas o lobuladas, todas soldadas solo a la base o hasta el ápice del receptáculo y cáliz; el receptáculo es más o menos cónico u ovoide y el cáliz tiene normalmente 4 sépalos –a veces inexistente–, soldados al receptáculo y, en su caso, a brácteas y bractéolas, normalmente con 4 dientes o lóbulos apicales, más o menos irregulares; los estambres están de ordinario inexistentes, rara vez con algunos vestigiales; el ovario es ínfero, unilocular en la parte superior, y con 2, 4(8) lóculos en la base; los carpelos de 2 –rara vez 3-4 en algunas flores–, están soldados y el estilo tiene 2-4 ramas estilares, a veces muy cortas con estigmas a lo largo de las ramas estilares o solo en su ápice, a veces pequeños y subglobosos; el primordio seminal es de placentación axilar. El fruto en nuez, en el cual, a lo largo de la maduración, normalmente la bráctea o bractéolas y en ocasiones los sépalos crecen, y además a veces engrosan, formando una estructura especializada con 1-3 alas (fruto samaroide); o la cáscara (fruto drupáceo, trima), indehiscente o dehiscente de forma más o menos irregular–, más o menos pétrea, bivalva, con 2, 4(8) lóculos en la base. Hay una sola semilla, en general sin endospermo, relativamente grande, con cotiledones cuadrilóbulados separados por un tabique normal a las 2 valvas y a su sutura.




</doc>
<doc id="1554" url="https://es.wikipedia.org/wiki?curid=1554" title="Juan de la Cierva">
Juan de la Cierva

Juan de la Cierva y Codorníu (Murcia, 21 de septiembre de 1895-Croydon, 9 de diciembre de 1936) fue un inventor y científico aeronáutico español, ingeniero de caminos, canales y puertos y aviador. Inventó el autogiro, aparato precursor del actual helicóptero.

Hijo del abogado criminalista, político y empresario Juan de la Cierva y Peñafiel, que llegó a ser ministro en varias ocasiones y alcalde de Murcia, y de María Codorníu Bosch. Su abuelo materno fue el destacado ingeniero de montes Ricardo Codorníu. Desde su infancia destacó su interés por el mundo de la aviación, y junto a su amigo Tomás de Martín-Barbadillo construyó pequeños modelos capaces de volar.

Al estallar la guerra civil, De la Cierva ayudó a las fuerzas sublevadas para que éstas consiguieran el avión De Havilland DH.89 Dragon Rapide en el que el general Franco voló desde Gando (Gran Canaria) a Tetuán (Marruecos español) para tomar el mando del ejército del norte de África.. Sin embargo, nunca habló directamente con el que luego sería el dictador Francisco Franco, sino que el contacto se produjo a través del corresponsal de ABC en Londres, sin que se haya confirmado nunca si Juan de la Cierva era conocedor del destino del avión, máxime cuando falleció en diciembre de 1936 y llevaba años viviendo en Londres y alejado de la política nacional. Su hermano Ricardo fue fusilado por milicias republicanas en las matanzas de Paracuellos.

En 1954 le fue otorgado, con carácter póstumo, el título de conde de la Cierva.

Junto con dos compañeros, José Barcala, antiguo compañero de estudios, y Pablo Díaz, hijo de un carpintero, fundó la sociedad B.C.D., cuyas siglas correspondían con las iniciales de sus tres apellidos, que fue pionera en el desarrollo aeronáutico dentro de España, y gracias a su capacidad, en 1912, contando sólo con dieciséis años, Juan de la Cierva logró construir y hacer volar un avión biplano, que recibió la designación BCD-1, y fue apodado "el Cangrejo", con piloto (el francés Mauvais) y pasajero a bordo.

Mientras que el avión es una aeronave de alas fijadas al fuselaje, el autogiro inventado por La Cierva tiene alas fijadas a un rotor. El autogiro hace su irrupción en el panorama de la aviación sólo veinte años después de la invención de los hermanos Wright.

Juan de la Cierva construyó en Madrid en 1920 su primer autogiro, el Cierva C.1, utilizando fuselaje, ruedas y estabilizador vertical de un monoplano francés Deperdussin de 1911, sobre el que montó dos rotores cuatripalas contrarrotatorios coronados por una superficie vertical destinada a proporcionar control lateral; la planta motriz era un motor Le Rhône de 60 CV. El aparato no llegó a volar, pues el rotor inferior giraba a menos velocidad de la prevista, y el efecto giroscópico y la asimetría de la sustentación hicieron volcar el aparato. A este primer autogiro siguieron dos construcciones también fallidas, el C.2 y el C.3, en las que el inventor intentó, infructuosamente, resolver el problema de la diferencia de sustentación entre la pala que avanza y la que retrocede. Sin embargo, en las pruebas del C.2 se consiguieron algunos saltos de unos dos metros, lo que apuntaba a la viabilidad del invento. El problema de la sustentación del rotor no se resolvería plenamente hasta el prototipo C.4, en el que La Cierva incluyó su revolucionaria idea de articular las palas del rotor en su raíz.

Los primeros ensayos del modelo C.4, construido en 1922 conforme a los nuevos principios, fueron infructuosos. Para su definitiva resolución, la Cierva realizó una completa serie de ensayos en el túnel de viento de circuito cerrado del aeródromo de Cuatro Vientos (obra de Emilio Herrera), por aquel entonces el mejor de Europa. El nuevo aparato corregido se probó exitosamente en enero de 1923 en el aeródromo de Getafe pilotado por el teniente Alejandro Gómez Spencer. Aunque dicho vuelo consistió únicamente en un «salto» de 183 m, demostró la validez del concepto. A finales del mes, el C.4 recorrió en cuatro minutos un circuito cerrado de 4 km en el aeródromo de Cuatro Vientos, a una altura de unos 30 m. La planta motriz del C.4 era un motor Le Rhône 9Ja de 110 CV. En julio de 1923 se utilizó el mismo motor en el C.5, que voló en Getafe. A partir de ese momento, La Cierva, que había financiado a sus expensas sus experimentos anteriores, contó para sus trabajos con una subvención del gobierno español. 

En 1926, con el apoyo financiero de James George Weir, industrial y aviador escocés, creó en el Reino Unido la sociedad Cierva Autogiro Company para el desarrollo del autogiro, produciendo varios modelos en ese país.

Falleció el 9 de diciembre de 1936 con cuarenta y un años de edad, al estrellarse en el despegue, en el aeropuerto de Croydon, el Douglas DC-2 de KLM en vuelo regular Londres-Ámsterdam en el que viajaba.

Desde el año 2001 el Ministerio de Educación y Ciencia de España otorga el Premio Nacional de Investigación Juan de la Cierva dedicado a la transferencia de tecnología. El objetivo de los Premios Nacionales de Investigación es el reconocimiento de los méritos de los científicos o investigadores españoles que realizan «una gran labor destacada en campos científicos de relevancia internacional, y que contribuyan al avance de la ciencia, al mejor conocimiento del hombre y su convivencia, a la transferencia de tecnología y al progreso de la Humanidad».

Además del premio nacional de investigación que lleva su nombre, en 2004 el Ministerio de Educación y Ciencia de España inició un programa de contratación de investigadores doctores bajo el nombre de Programa Juan de la Cierva, gracias al cual centenares de investigadores españoles y extranjeros desarrollan su actividad.

La Asamblea Regional de Murcia aprobó que el nuevo Aeropuerto Internacional de la Región de Murcia llevara el nombre de Juan de la Cierva con los votos a favor de PP y Ciudadanos y el voto en contra de PSOE y Podemos que aseguraron que se trataba de un colaborador de Franco. Esta oposición fue muy contestada por expertos y ciudadanía que defendían la imposibilidad de considerar franquista a quien había colaborado con la República, nunca tuvo contacto con Franco, no combatió durante la Guerra Civil ni vivía en España desde que estalló la Guerra hasta su fallecimiento en un accidente unos meses después. El 15 de enero de 2019 se inauguró el nuevo aeropuerto sin que pudiera llamarse oficialmente Juan de la Cierva al no haber sido aprobado todavía el citado nombre por parte de Aviación Civil.

La memoria de Juan de la Cierva se mantiene viva en varias ciudades con las que tuvo relación: 






</doc>
<doc id="1555" url="https://es.wikipedia.org/wiki?curid=1555" title="Juego">
Juego

En el caso de los seres humanos, un juego es toda aquella actividad que realiza uno o más personas (llamadas jugadores) que, independientemente de su edad, su profesión/ocupación o su estatus social, emplean su imaginación o herramientas para crear una situación con un número determinado de reglas, con el fin de obtener o proporcionar entretenimiento y diversión. Existen juegos competitivos, donde los jugadores tienen que lograr un objetivo, y juegos no competitivos, donde los jugadores buscan simplemente disfrutar del entretenimiento de la actividad y diversión. Los juegos habitualmente se diferencian de los trabajos por el objeto de su realización. Sin embargo, en muchos casos estos no tienen una diferencia demasiado clara. Asimismo, el juego se utiliza como herramienta educativa, pues en la mayoría de los casos funcionan estimulando habilidades prácticas psicológicas. Además, los juegos suelen llevarse a cabo entre personas tanto de la infancia como en la adolescencia o en cualquier otra etapa de la vida.

La primera referencia sobre juegos que existe es del año 3000 a. C. Los juegos se consideran parte de una experiencia humana y están presentes en todas las culturas. Probablemente, las cosquillas, combinadas con la risa, sean una de las primeras actividades lúdicas del ser humano, al tiempo que una de las primeras actividades comunicativas previas a la aparición del lenguaje.

El juego es una actividad inherente al ser humano. Sin embargo, no es una actividad exclusiva de este.

Etimológicamente, los investigadores refieren que la palabra "juego" procede de dos vocablos en latín: "iocum" y "ludus-ludere"; ambos hacen referencia a broma, diversión, chiste, y suelen usarse indistintamente junto con la expresión "actividad lúdica".

Existen multitud de definiciones sobre el juego. Según el diccionario de la Real Academia, es un ejercicio recreativo sometido a reglas en el cual se gana o se pierde.

Pero la propia polisemia de este y la subjetividad de los diferentes autores implican que cualquier definición no sea más que un acercamiento parcial al fenómeno lúdico. Se puede afirmar que el juego, como cualquier realidad sociocultural, es imposible de definir en términos absolutos, y por ello las definiciones describen algunas de sus características. Entre las conceptualizaciones más conocidas, se apuntan las siguientes:



En conclusión, estos y otros autores, como Roger Caillois, Moreno Palos y otros incluyen en sus definiciones una serie de características comunes a todas las visiones, de las cuales algunas de las más representativas son las siguientes:


Existen múltiples concepciones de deporte, según el autor que se tome como referencia. Autores como Coubertin, Demeny, Cagigal, Parlebas, García Ferrando y otros.

Sintetizando, se puede definir deporte y diferenciarlo del juego como sigue:

El deporte es un conjunto de situaciones motrices e intelectuales, diferenciado del juego en el hecho de que busca la competición con otros o consigo mismo, y que precisa reglas más concretas, además de estar institucionalizado.


El juego es útil y es necesario para el desarrollo infantil, en la medida en que niñas y niños son protagonistas.

La importancia de la utilidad del juego puede llevar a los adultos a robar el protagonismo, a querer dirigir el juego. La intervención del adulto en los juegos infantiles debe consistir en:


El juego permite:


El juego hace referencia implícita o explícita a las relaciones entre infancia, diversión y educación.

El juego es una actividad que tiene el fin en sí misma, es decir, la persona realiza la propia actividad para conseguir el objetivo, que es ser placentera. El juego tiene un carácter de finalidad intrínseca y es liberador de los conflictos, ya que ignora los problemas o los resuelve.
Una de sus principales características es la sobremotivación, la cual pretende hacer de una actividad ordinaria una actividad de motivación suplementaria.

El juego temprano y variado contribuye positivamente a todos los aspectos del crecimiento y está vinculado a las cuatro dimensiones básicas del desarrollo infantil que son el psicomotor, el intelectual, el social y finalmente el afectivo-emocional.

Funciones del juego infantil:





El juego social es una conducta sumamente corriente en la práctica totalidad de los mamíferos y algunas aves. Los mamíferos juegan para aprender. De hecho la principal función del juego es aprender. Los mamíferos se caracterizan por un cerebro evolucionado, infancia larga, cuidado parental, amamantamiento de las crías, cacería en grupo, división social y no genética de trabajo. Los mamíferos juegan a cazar en grupo, definir jerarquías, explorar, dividirse el trabajo, entre otros. El juego entre los mamíferos no humanos (caninos, felinos, acuáticos, primates) se basa en la imitación y en la exploración por ensayo y error. En estos mamíferos hay una ausencia total conocida de juego simbólico.

El juego simbólico se hace sobre representaciones y no sobre cosas reales. Las pinturas rupestres son el primer ejemplo de ¨juego¨ simbólico. Los seres humanos prehistóricos las utilizaban para actuar sobre los animales a través de sus representaciones. El juego simbólico está claramente presente entre casi todos o la mayoría de los niños y niñas a partir de los 2 años de edad. El juego simbólico está presente cuando un niño toma una piedra y juega con ella como si fuera un carro. Este niño está jugando con el carro, no con la piedra.

Los chimpancés y otros primates tienen la capacidad de utilizar representaciones, pueden por ejemplo usar algunas palabras, pero no aparece en ellos ninguna forma de juego simbólico. El juego de los chimpancés tiene las mismas características que el de todos los mamíferos. La aparición del juego simbólico se presenta exclusivamente en los niños humanos, junto con el lenguaje —intrínsecamente simbólico—.

El ser humano puede profundizar y divertirse más en el juego gracias a nuestro lóbulo frontal (también llamado neo-cortex) que es donde se encuentra la imaginación , el juego, el arte , matemáticas etc, lo cual nos diversifica de los demás mamíferos que también juegan y de algunos parientes ya extintos como el neandertal que como no tenían el lóbulo frontal tan desarrollado lo cual producía que no tuvieran una capacidad de resolución de problemas rápida 

En los seres humanos, luego de la aparición de juego simbólico, hacia los 2 años, comienza una etapa de juego social, en el que los niños juegan cada vez más entre sí y con los adultos, utilizando el lenguaje. Este juego social requiere cada vez más el establecimiento de acuerdos y finalmente termina en el juego formal, cuya característica esencial es que es un juego con reglas muy claras. Los juegos de canicas (bola uña) son un excelente ejemplo de juegos infantiles con reglas, hacia los 6 años de edad. Esto no desaparece gracias a la neotemia que es la capacidad de una especie de conservar rasgos de la infancia en la adultez , lo cual nos deja seguir divirtiendonos como niños En la historia de la especie humana es probable que el juego formal aparezca luego de la sedentarización resultado de la agricultura y la escritura. En el juego formal el objeto del juego son las reglas en sí mismas, no las representaciones. Gracias a esta capacidad para establecer reglas y jugar dentro de ellas la especie ha podido construir ¨juegos¨ claves como la democracia, la religión y la ciencia. Crear juegos con reglas es la esencia de la evolución de la civilización. A partir de los 5 años los niños pueden utilizar reglas para manipular los objetos, interactuar socialmente o para generar conocimiento, los tres usos fundamentales del juego y de las reglas.

Los juegos populares están muy ligados a las actividades del pueblo llano, y a lo largo del tiempo han pasado de padres a hijos. De la mayoría de ellos no se conoce el origen: simplemente nacieron de la necesidad que tiene el hombre de jugar, es decir, se trata de actividades espontáneas, creativas y muy motivadoras.

Su reglamento es muy variable, y puede cambiar de una zona geográfica a otra con facilidad; incluso pueden ser conocidos con nombres diferentes según donde se practique.

Los juegos populares suelen tener pocas reglas y normalmente sencillas, y en ellos se utiliza todo tipo de materiales, sin que tengan que ser específicos del propio juego. Todos ellos tienen sus objetivos y un modo determinado de llevarlos a cabo: perseguir, lanzar un objeto a un sitio determinado, conquistar un territorio, conservar o ganar un objeto, etc.
Su práctica no tiene una trascendencia más allá del propio juego, no está institucionalizado, y el gran objetivo del mismo es divertirse.

Con el tiempo, algunos se han ido convirtiendo en un apoyo muy importante dentro de las clases de Educación Física, para desarrollar las distintas capacidades físicas y cualidades motrices, o servir como base de otros juegos y deportes.

Los juegos populares pueden servir como herramienta educativa en el aula en diversas materias ya que en sus retailas, canciones o letras se observa características de cada una de las épocas. Esta tipología puede ser una estrategia divertida en la que las personas que los realizan aprenden al mismo tiempo que se divierten.

Son juegos más solemnes que también han sido transmitidos de generación en generación, pero su origen se remonta a tiempos muy lejanos.

No solamente han pasado de padres a hijos, sino que en su conservación y divulgación han tenido que ver mucho las instituciones y entidades que se han preocupado de que no se perdieran con el paso del tiempo.
Están muy ligados a la historia, cultura y tradiciones de un país, un territorio o una nación. Sus reglamentos son similares, independientemente de donde se desarrollen.

El material de los juegos es específico de los mismos, y está muy ligado a la zona, a las costumbres e incluso a las clases de trabajo que se desarrollaban en el lugar.

Sus practicantes suelen estar organizados en clubes, asociaciones y federaciones.
Existen campeonatos oficiales y competiciones más o menos regladas.

Algunos de estos juegos tradicionales con el tiempo se convirtieron en deportes, denominados tradicionales, de modo que la popularidad que tienen entre los habitantes de un territorio o país compite con la popularidad de otros deportes convencionales.
Algunos ejemplos: la petanca, el chito, los bolos, la rana, etc.

Entre estos, podríamos encontrar juegos que con el tiempo se han convertido en verdaderos deportes ligados a una región, y que solo se practican en ella, llegando a formar parte de las tradiciones culturales. El origen de los juegos y deportes tradicionales está ligado al propio origen de ese pueblo, por ello, los denominan "juegos o deportes autóctonos". Algunos ejemplos son: la Lucha canaria, el silbo, el palo canario, la soga tira, la pelota mano, el lanzamiento de barra, etc.

Los juegos infantiles exteriores se encuentran en parques o centros recreativos, estos juegos tienen la tarea de ser duraderos, divertidos, resistentes y sobre todo seguros debido al público al que van dirigidos, los cuales son niños menores de 10 años en su mayoría.

Estos existieron a partir de la necesidad de tener un entretenimiento más activo y seguro para los niños pequeños donde puedan entretener varios niños a la vez.

La mezcla de materiales es por lo general metal y plástico, pero dependiendo del diseño temático podría incluir otros materiales como madera así como los colores que este pudiera contener.

Una de las ventajas más notables de estos juegos se encuentran:
Estos juegos infantiles pueden tener la combinación de pequeñas resbaladillas así como columpios y otros aditamentos como red para escalar, túneles, etc.

Su tamaño y componentes dependerán siempre del tema bajo el que este diseñado. El principal objetivo de este juego es brindar la seguridad necesaria y la diversión deseada. Es por eso que su diseño debe ser funcional, atractivo para los niños y sobre todo resistente pero no solo a los niños sino también a los factores naturales tales como lluvia, vientos, granizos donde su estructura tiene que mantenerse sin daños graves y sobre todo sin grietas por impactos o resequedad por su larga exposición al sol.

Así los juegos infantiles tienen garantía de que gracias a su calidad y diseño prometen duran varios años y brindar diversión a una gran cantidad de niños sin importar que tanto uso ellos le puedan dar y resistiendo las inclemencias del clima.

Los juegos con tablero, que utilizan como herramienta central un tablero en donde se sigue el estado, los recursos y el progreso de los jugadores usan símbolos físicos. Muchos también implican dados o naipes. La mayoría de los juegos que simulan batallas son de tablero, y este puede representa un mapa en el cual se mueven de forma simbólica los contendientes. Algunos juegos, como el ajedrez y el go son enteramente deterministas, basados solamente en la estrategia. Los juegos infantiles se basan en gran parte en la suerte, como la Oca, en el que apenas se toman decisiones, mientras que el parchís ("parqués" en Colombia, "ludo" en Chile), es una mezcla de suerte y estrategia. El Trivial es aleatorio en tanto que depende de las preguntas que cada jugador consiga.
Los juegos de mesa, son antiguos o tradicionales, pero son considerados de la nueva época o actuales debido a que han ido mejorando su diseño, complementaciones y características.

Los juegos de naipes utilizan como herramienta central una baraja. Esta puede ser española, de 40 ó 48 naipes o francesa de 52 cartas, y depende del juego el uso de una u otra. También hay algunos juegos de magia que utilizan naipes.

Los videojuegos son aquellos que controla un ordenador o computadora, que pueden crear las herramientas virtuales que se utilizarán en un juego, como naipes o dados o elaborados mundos que se pueden manipular.

Un videojuego utiliza unos o más dispositivos de entrada, bien una combinación de teclas y joystick, teclado, ratón, trackball o cualquier otro controlador. En los juegos de ordenador el desarrollo del juego depende de la evolución de las interfaces utilizadas.

A veces, hay una carencia de metas o de oposición, que ha provocado una discusión sobre si estos se deben considerar "juegos" o "juguetes".

Con la conexión a Internet han aparecido nuevos juegos; algunos necesitan un cliente mientras que otros requieren solamente un navegador. El juego de ordenador se ha distribuido por todos los sectores sociales, transformando la forma tradicional de jugar.

Los juegos de rol son un tipo de juego en el que los participantes asumen el papel de los personajes del juego. En su origen el juego se desarrollaba entre un grupo de participantes que inventaban un guion con lápiz y papel. Unidos, los jugadores pueden colaborar en la historia que implica a sus personajes, creando, desarrollando y explorando el escenario, en una aventura fuera de los límites de la vida diaria. Uno de los primeros juegos de rol en ser comercializados fue "Dungeons & Dragons".

Los juegos cooperativos son juegos en los cuales dos o más jugadores no compiten, sino más bien se esfuerzan por conseguir el mismo objetivo y por lo tanto ganan o pierden como un grupo. En otras palabras, son juegos donde grupos de jugadores pueden tomar comportamientos cooperativos, pues los juegos son una competición entre "coaliciones" de jugadores más que entre jugadores individuales. Es como un juego de coordinación, donde los jugadores escogen las estrategias por un proceso de toma de decisiones consensuadas.

El universo del juego popular/tradicional es tan versátil que origina numerosos y distintos intentos de clasificación. Entre las muchas formas de clasificación, queremos destacar en primer lugar la tipología de:

Los juegos pueden clasificarse según otro criterio, y fueron los griegos los que definieron cuatro tipos de juegos de los cuales salieron diversas variables a lo largo de la historia.

Estos cuatro grupos de juegos pueden situarse entre dos extremos, denominados “continuum”: son los conceptos de “paidia” (manifestaciones espontáneas del instinto lúdico) y “ludus” (una evolución de paidia en la que parecen convenciones y técnicas de actuación).

Es pionero en España su trabajo en 1974 sobre los juegos populares y deportes tradicionales de la península. En su estudio bibliográfico hace una clasificación pormenorizada en la que se distinguen las siguientes categorías:


Profesor del INEF de Madrid de la asignatura de Juegos y deportes populares, elaboró en 1992 la siguiente clasificación basada fundamentalmente en criterios asociados al ámbito de la educación física:
Clasifica en 2002 los juegos y deportes populares de Casilla León tomando como base los criterios utilizados por Moreno Palos, distinguiendo:

Revisando de forma crítica estas clasificaciones, afirma en 1996 que la complejidad morfológica y estructural del juego (popular-tradicional) se pone de manifiesto en los numerosos intentos de agrupación.

En la mayoría de las ocasiones las clasificaciones se construyen a partir de criterios superficiales, formales, sin elegir elementos realmente pertinentes y constitutivos de su estructura interna.

Estos criterios morfológicos, debido a las múltiples formas en que puede desarrollarse el juego, presentan excesivas categorías heterogéneas. En este sentido, una de las clasificaciones mostradas por Moreno Palos así lo demuestra. Por eso es preciso construir nuevas propuestas objetivas y rigurosas, edificadas sobre bases teóricas justificables. En esta línea tan solo Pierre Parlebas propone en 1986 algunos criterios objetivos, aunque no se centran de forma específica en clasificar los juegos populares y tradicionales.




</doc>
<doc id="1556" url="https://es.wikipedia.org/wiki?curid=1556" title="Juncaginaceae">
Juncaginaceae

Las juncagináceas (nombre científico Juncaginaceae) son hierbas perennes, acuáticas o palustres, de distribución cosmopolita pero de hábitats principalmente costeros. La familia es reconocida por sistemas de clasificación modernos como el sistema de clasificación APG III (2009) y el APWeb (2001 en adelante). Las juncagináceas se diferencian de otras familias por poseer hojas más o menos unifaciales, una inflorescencia en racimo o espiga, con escapo, y flores con todas sus piezas libres entre sí. 

La familia fue reconocida por el APG III (2009), el Linear APG III (2009) le asignó el número de familia 37. La familia ya había sido reconocida por el APG II (2003).

Los géneros, según el APWeb:


Sinónimos según el APWeb: Heterostylaceae Hutchinson, Lilaeaceae Dumortier, Maundiaceae Nakai, Triglochinaceae Chevalier



</doc>
<doc id="1557" url="https://es.wikipedia.org/wiki?curid=1557" title="Juncaceae">
Juncaceae

Las juncáceas (nombre científico Juncaceae) forman una familia de plantas monocotiledóneas parecidas a los pastos, con hojas lineales que poseen vaina y lámina pero no tienen lígula, inflorescencias normalmente condensadas en glomérulos terminales y se diferencian de los pastos porque las flores poseen tépalos obvios, las hojas son trísticas, y los frutos son cápsulas. Han colonizado todos los ambientes en especial los de las zonas templadas, y se polinizan por viento.

El nombre de la familia fue utilizado en sistemas de clasificación modernos como el sistema de clasificación APG III (2009) y el APWeb (2001 en adelante) en los que es asignado al clado ciperáceas-juncos del orden Poales. En la familia se encuentran los juncos y afines. La importancia económica es limitada, algunas son utilizadas como ornamentales, algunas utilizadas para tejer canastas o sillas.

Hábito: Hierbas, perennes (raramente anuales), sin cuerpos de sílice, cuando perennes usualmente sus tallos son rizomatosos, redondos y macizos.

Hojas alternas, espiraladas, usualmente trísticas (raramente dísticas), bifaciales o unifaciales (más o menos redondeadas, sin reconocer dos lados), basales o a lo largo de la porción más baja del tallo, delgadas, compuestas por vaina (hojas envainadoras) y lámina, la vaina usualmente abierta, la lámina simple, sin dividir, de margen entero, con venación paralela, lineal, plana o cilíndrica. Usualmente con aurículas. Con o sin lígula. Sin estípulas.

Inflorescencias básicamente determinadas, terminales, muy ramificadas, pero usualmente condensadas en un glomérulo, o también pueden ser de flores solitarias, o compuestas por 1-muchas cimas. 

Flores usualmente hermafroditas, pero ocasionalmente unisexuales (entonces plantas dioicas), inconspicuas, regulares, bracteadas, hipóginas.

6 tépalos dispuestos en 2 verticilos (raramente 3 en 1 verticilo, o 4 en 2 verticilos), separados, imbricados, generalmente de color verde, rojo-marrón o negro, pero a veces blancos o amarillentos, escariosos (delgados y como escamas), sin hipanto. Los tépalos externos y los internos están separados.

Androceo con 6 estambres en 2 verticilos (o a veces 3 estambres en 1 verticilo, o 4 en 2 verticilos), diplostémonos cuando en 2 verticilos (el verticilo externo opuesto a los tépalos externos y el interno a los tépalos internos), filamentos separados entre sí y de los tépalos. Anteras basifijas, de dehiscencia longitudinal.

Polen monoporado, en tétradas obvias.

Gineceo súpero, tricarpelar, carpelos connados, 3 o 1 lóculo, con placentación axilar o parietal (ocasionalmente basal), estilo usualmente en 3 ramas, 3 estigmas usualmente elongados, a veces retorcidos. óvulos numerosos (raramente 3 o 1), anátropos, bitégmicos. 

No hay nectarios.

El fruto es una cápsula loculicida (raramente indehiscente).

3 a numerosas semillas, con endosperma con almidón.

Familia cosmopolita, mayormente de regiones templadas y montanas. Muchas veces en hábitats húmedos, pero hay notables excepciones, como "Juncus trifidus". 

Las inconspicuas flores de Juncaceae son predominantemente polinizadas por viento, comúnmente el entrecruzamiento es favorecido por la protandria (en la misma planta las flores masculinas maduran antes), pero algunas especies son autopolinizadas. También puede haber especies polinizadas por insectos.

La dispersión de las pequeñas semillas la produce el viento, el agua, o también pueden ser transportadas por los animales en forma externa (sin consumirlas).

La monofilia de Juncaceae está sostenida por secuencias ITS (Kristiansen "et al." 2005, Roalson 2005), y por análisis de una combinación de genes (Jones "et al." 2007). La monofilia de Juncaceae no estuvo clara hasta hace poco, aun cuando ya se sabía que debía excluirse de ella a "Prionium" (ahora en Thurniaceae). Dos estudios encontraron que Juncaceae no era monofilética, ya que "Oxychloe" fue encontrado como embebido en Cyperaceae, o hermano del resto de Cyperaceae, por Plunkett "et al." 1995, y Muasya "et al." 1998. Según Soltis "et al." (2005), lo que debe haber pasado en los análisis de Plunkett "et al." (1995) y Muasya "et al." (1998), es que el primero puede haber utilizado una colección de hojas que era una mezcla de "Oxychloe" con una ciperácea, y casi seguramente secuenciaron la ciperácea, mientras que en el último la muestra debe haber estado contaminada.

No está claro cuál de los caracteres de la familia es sinapomórfico, muchos son caracteres generalizados en las monocotiledóneas. 

Juncaceae, Cyperaceae y Thurniaceae comparten dos caracteres que pueden ser sinapomorfías: las hojas trísticas y el polen en tétradas. Las 3 familias forman el clado ciperáceas-juncos, ver Poales para una discusión de este clado.

Análisis filogenéticos recientes (Drábková "et al." 2003, Roalson 2005) indican que "Juncus" no es monofilética, de él se desprendieron "Luzula" y un grupo de plantas de los Andes ("Oxychloë" y "Distichia"). El hecho de que "Juncus" es glabro sugiere que esta condición puede ser una sinapomorfía de la familia (aún si fuera homoplásica).

Muchos miembros de esta familia lucen superficialmente como pastos, pero las hojas trísticas, las flores con tépalos obvios, y los frutos capsulares hacen la distinción clara. En algunas especies de "Juncus", la larga bráctea debajo de la inflorescencia está vuelta hacia arriba de forma de parecer una continuación del tallo, y la inflorescencia parece lateral.

La familia fue reconocida por el APG III (2009), el Linear APG III (2009) le asignó el número de familia 98. La familia ya había sido reconocida por el APG II (2003).

6 géneros, cerca de 400 especies. Los géneros más representados son "Juncus" (300 especies) y "Luzula" (80 especies).

Lista de géneros y sus sinónimos, según el APWeb (visitado en enero de 2009): 


"Prionium" ahora pertenece a Thurniaceae.

La importancia económica es limitada.

"Juncus effusus" y "J. squarrosus" son usados para hacer canastas y sillas. 

Unas pocas especies de "Juncus" y "Luzula" son utilizadas como ornamentales.

"Distichia" es utilizada en Perú como combustible y sucedáneo del musgo de turbera "Sphagnum" para preparar mezclas de sustratos para plantas.



</doc>
<doc id="1558" url="https://es.wikipedia.org/wiki?curid=1558" title="Juego L">
Juego L

El juego L es un juego abstracto para dos jugadores creado por Edward de Bono en 1972. Se juega con un tablero de 4 x 4 casillas, una pieza en forma de L de dimensiones 3x2 para cada jugador y 2 piezas neutrales que no pertenecen a ninguno de ambos, pero que pueden ser movidas por cualquiera de los dos.

Cada jugador, por turnos, debe mover su pieza L hacia una nueva posición. La pieza puede levantarse, girarse, o volverse del revés y luego colocarse otra vez sobre el tablero en cualquier lugar o posición. Se considera que una posición es nueva si por lo menos una de las casillas cubiertas es diferente. La pieza puede colocarse en cualquier lugar del tablero siempre que cubra una configuración exacta de cuadros no ocupados por ninguna otra pieza. Después de mover la pieza L, el jugador puede, si lo desea, mover una cualquiera de las piezas neutrales a cualquier casilla desocupada.

El objeto del juego es forzar al oponente a una posición desde la cual no puede mover más. Se gana la partida cuando el oponente no puede cambiar la posición de su pieza L (Ésta debe moverse siempre antes de tocar ninguna pieza neutral).



</doc>
<doc id="1559" url="https://es.wikipedia.org/wiki?curid=1559" title="Juglans">
Juglans

Juglans es un género de árboles caducifolios llamados comúnmente nogales, de la familia de las juglandáceas. Lo componen una veintena de especies aceptadas, de las 150 descritas.

El término en latín "Juglans" deriva de "Jovis glans", "bellotas de Júpiter": figuradamente, una nuez apropiada para un dios.

Árboles –rara vez arbustos, en especies extraibéricas–, monoicos. Ramillas de médula perforada. Yemas terminales sésiles, con algunos catafilos en disposición valvar, densamente hirsutos. Hojas caducas, alternas, imparipinnadas; lámina, pecíolo y raquis con glándulas peltadas –que al secarse adquieren aspecto de escamas–; foliolos 5-31, de margen serrado o entero, con pelos no glandulíferos simples o fasciculados, a veces glabros; raquis áptero; peciólulos muy cortos o inexistentes. Inflorescencia masculina en amento, solitario –a menudo superpuestos–, lateral, sésil, péndulo. Inflorescencia femenina en racimo, de (1)2-25 flores, solitario, terminal, erecto en la fructificación. Flores masculinas de bráctea soldada al receptáculo excepto en el ápice, que es pequeño, ovado o lanceolado y entero; bractéolas 2, soldadas al receptáculo y a los sépalos, de ordinario algo más grandes que éstos y externos, de tal forma que en el conjunto hay hasta 6 lóbulos más o menos desiguales –en algunos casos hasta 8(-16); los adicionales se supone que son divisiones de los ápices calicinos–; sépalos 1-4; estambres 7-85(105); anteras glabras o escasamente pelosas. Flores femeninas de bráctea soldada al receptáculo excepto en el ápice, que es pequeño y entero; bractéolas 2, soldadas al receptáculo excepto en el ápice, que es más o menos dentado o lobulado; sépalos 4, soldados al receptáculo en más de 2/3 de su longitud; carpelos 2 –rara vez y en algunas flores 3-4–; estilo normalmente con 2 ramas estilares, recurvadas, con la zona estigmática hacia el interior. Fruto drupáceo (trima); epicarpio/mesocarpio rugoso o liso, indehiscente o dehiscente de forma más o menos irregular (tras la fructificación acaba secándose, se hace correosa y se desprende); nuez de pared más o menos pétrea, rugosa o áspera, con 2 o 4 lóculos en la base. Semillas de cotiledones carnosos, con 2 lóbulos cada uno.

Las veintena de especies aceptadas del género se distribuyen por todas las regiones septentrionales frías desde la Europa sudoriental hasta el este del Japón y más ampliamente en el continente americano, desde el sudeste de Canadá hasta el noreste de México y el sur de Argentina.

El género "Juglans" se divide en cuatro secciones.





El miembro más conocido del género es el nogal común ("J. regia", literalmente "nogal real"), originario de los Balcanes en el sudeste de Europa, sudoeste y centro de Asia hasta el Himalaya y el sudoeste de China. Las nueces son un rasgo tradicional de la cocina iraní; la nación tiene amplios huertos de frutales que son un importante elemento de la economía regional. Tan sólo en Kirguistán hay 230.700 hectáreas de bosques de nogales, donde "J. regia" es el piso dominante (Hemery y Popov 1998). 

El nogal negro americano ("J. nigra") es una especie común en su originario Este de Norteamérica, y también se cultiva ampliamente en otros lugares. Las nueces son comestibles, pero tienen un núcleo más pequeño y una cáscara extremadamente dura, y no se cultivan mucho para la producción de nueces. La madera es particularmente valiosa.

"Juglans hindisii" procede del norte de California, donde se ha usado comercialmente como una sustituta de los nogales comunes. Sus cáscaras no tienen profundas grietas que son características del nogal negro americano.

El "nogal de Japón" ("Juglans ailantifolia") es parecido al nogal blanco "(Juglans cinerea)", pero se distingue por tener hojas más grandes de hasta 90 cm de largo, y unas nueces redondeadas, no ovales. 

El nogal blanco ("J. cinerea") también es originario del este de Norteamérica, donde actualmente es una especie en peligro por una enfermedad causada por el hongo "Sirococcus clavigignenti". Sus hojas tienen 40–60 cm de largo, los frutos son ovalados, la cáscara muy alta, con bordes muy delgados, y el núcleo es especialmente alto en grasa.


Un estudio de ADN nuclear secuenciado del External Transcribed Spacer (ETS) de DNA ribosomal (rDNA), el Internal Transcribed Spacer (ITS) de rDNA, y el segundo intron del gen LEAFY tomado de al menos un individuo de la mayor parte de las especies de "Juglans" ha apoyado varias conclusiones:







En el informe sobre estos resultados no se publicó ningún nombre nuevo para las subdivisiones de las secciones  "Rhysocaryon", para cualquier combinación de las otras secciones, o para "J. olanchana" var. "standleyi".

Las dos especies comerciales más importantes son "J. regia" para madera y nueces, y "J. nigra" para madera. Ambas especies tienen similares exigencias de cultivo y son ampliamente cultivadas en zonas templadas.

Los nogales son especies heliófitas (que exigen luz) y se benefician de la protección contra el viento. También son muy resistentes a la sequía.

Las plantaciones de nogales, denominadas nocedales, con plantas que fijen el nitrógeno como "Elaeagnus × ebbingei" o "Elaeagnus umbellata", y varias especies de "Alnus" incrementan en un 30% la altura y grosor de los árboles (Hemery 2001).

Cuando los cultivos se dedican a la obtención de nueces, se deben seleccionar cultivares compatibles para propósitos de polinización; aunque algunos cultivares se venden como "auto-fértiles" generalmente fructificarán mejor con un compañero de polinización diferente. Existen muchos cultivares diferentes disponibles para los cultivadores que ofrecen diversos hábitos de crecimiento, florecimiento y hojas, sabor del fruto y grosor de la cáscara.



</doc>
<doc id="1560" url="https://es.wikipedia.org/wiki?curid=1560" title="Jürgen Habermas">
Jürgen Habermas

Jürgen Habermas (; Düsseldorf, 18 de junio de 1929) es un filósofo y sociólogo alemán reconocido en todo el mundo por sus trabajos en filosofía política, ética y teoría del derecho, así como en filosofía del lenguaje. Gracias a una actividad regular como profesor en universidades extranjeras, especialmente en Estados Unidos, así como por la traducción de sus trabajos más importantes a más de cuarenta idiomas, sus teorías son conocidas, estudiadas y discutidas en el mundo entero. Habermas es el miembro más eminente de la segunda generación de la Escuela de Fráncfort y uno de los exponentes de la Teoría crítica desarrollada en el Instituto de Investigación Social. Entre sus aportes destacan la construcción de la teoría de la acción comunicativa, la ética del discurso y la teoría de la democracia deliberativa.

Jürgen Habermas estudió filosofía, historia, psicología, literatura alemana y economía en las universidades de Gotinga, Zürich y Bonn. Nicolai Hartmann, Wilhelm Keller, Theodor Litt, Johannes Thyssen, Hermann Wein, y fueron algunos de sus profesores durante los estudios de licenciatura. En 1954, bajo la dirección de los dos últimos profesores citados, defendió en la Universidad de Bonn su tesis doctoral sobre el tema «El Absoluto y la historia: De las discrepancias en el pensamiento de Schelling», que aún hoy en día se mantiene inédita. Entre sus compañeros de estudios, trabó amistad con Karl-Otto Apel, una fructífera relación intelectual que se mantuvo hasta la muerte de Apel.

En 1953 publicó su primer artículo, una recensión crítica de la obra de Heidegger "Introducción a la metafísica", que tituló significativamente «Pensar con Heidegger contra Heidegger» ("Mit Heidegger gegen Heidegger denken"), artículo en el que critica a Heidegger por su postura frente al nacionalsocialismo. En los siguientes años siguió publicando artículos en prensa.

De 1954 a 1959 fue ayudante y colaborador de Adorno en el Instituto de Investigación Social de Fráncfort. En 1960 defendió en Marburgo (bajo la dirección de Wolfgang Abendroth) su escrito de habilitación, centrado en la transformación estructural de la «esfera pública» (titulado "Strukturwandel der Öffentlichkeit" en alemán, traducido al español como "Historia y crítica de la opinión pública"). Entre 1964 y 1971 ejerció como catedrático en la Universidad de Fráncfort, convirtiéndose en uno de los principales representantes de la segunda generación de la Teoría Crítica. En 1968 publicó "Conocimiento e interés", libro que le concedió una enorme proyección internacional.

De 1971 a 1983 fue director en el Instituto Max Planck para la «investigación de las condiciones de vida del mundo técnico-científico». En 1983 volvió a la Universidad de Fráncfort como catedrático de filosofía y sociología, donde permaneció hasta su jubilación en 1994. Se mantiene, no obstante, activo como docente, especialmente en calidad de «Permanent Visiting Professor» de la Northwestern University (Evanston, Illinois) y como «Theodor Heuss Professor» de The New School (Nueva York).

En 1986, recibió el Premio Gottfried Wilhelm Leibniz de la Deutsche Forschungsgemeinschaft, considerado como la máxima distinción en el ámbito alemán de investigación. En 2001 obtuvo el Premio de la Paz que conceden los libreros alemanes y en 2003, el Premio Príncipe de Asturias de Ciencias Sociales.

Es doctor "honoris causa" por las universidades, entre otras, de Jerusalén, Buenos Aires, Hamburgo, Northwestern University Evanston, Utrecht, Tel Aviv, Atenas y la New School for Social Research de Nueva York, y miembro de la Academia Alemana de la Lengua y la Poesía.

Si bien su pensamiento entronca con la Teoría Crítica de la Escuela de Fráncfort, su obra adopta perfiles propios que le conducen a profundas divergencias con sus maestros y predecesores. Su trabajo está orientado a poner los fundamentos de la teoría social con los que busca analizar las sociedades del capitalismo avanzado.

El pensamiento de Kant tiene un destacado lugar en la obra de Habermas, y el de Karl Marx desempeña un papel decisivo. El estrecho vínculo entre una filosofía de la razón muy ambiciosa en términos normativos y una teoría empírica de la sociedad es una característica del pensamiento de Marx que Habermas hace suya y que lo distingue de otros contemporáneos y, en particular, del sociólogo Niklas Luhmann y del filósofo John Rawls, con quienes, no obstante, comparte preocupaciones comunes.

La integración de filosofía y ciencia social en una teoría crítica de la sociedad es el rasgo distintivo de la obra habermasiana. Aunque Habermas se vale del concepto filosófico de razón y lo emplea explícitamente en términos de filosofía del lenguaje, lo hace para poder desarrollar una teoría social. Se apoya en la idea de una completa transformación de la crítica del conocimiento en crítica de la sociedad. De ahí que resulte unilateral entender a Habermas como mero filósofo de la fundamentación argumentativa y de la ética discursiva.

Su primera gran obra fue su escrito de habilitación (1962), traducido al español como "Historia y crítica de la opinión pública". En este análisis de la transformación estructural de la esfera pública se aproxima de forma crítica al concepto de opinión pública y recupera la visión eminentemente democrática del mismo, con su distinción entre opinión pública manipulada y opinión pública crítica.

En algunas de sus obras posteriores, Habermas tratará de reconstruir el materialismo histórico frente a las nuevas problemáticas de las sociedades del capitalismo tardío. En este sentido, la gran crítica que realizará a Karl Marx será que éste, en su opinión, reduce la praxis humana a una "techné", en el sentido de que Marx le otorga la importancia fundamental al trabajo como eje de la sociedad, en demérito del otro componente de la praxis humana que Habermas rescata como esencial: la interacción mediada por el lenguaje.

A diferencia de Marx, Habermas entiende que el cambio social debe darse en un ámbito simbólico, en el ámbito de la comunicación y el entendimiento entre los sujetos. De este modo, esta crítica se asemeja a la reflexión que realizan Theodor Adorno y Max Horkheimer. Luego de este momento inicial, Habermas repensará esta distinción entre trabajo e interacción como dos momentos irreductibles de la acción y tratará de incluir en la labor productiva (el trabajo) componentes de la interacción, por lo que dirá que es posible pensar un cambio social desde el campo del trabajo.

Habermas considera que existen tres crisis: la crisis de las filosofías de base teológica o metafísica, la crisis de la legitimación del Estado contemporáneo y la crisis del positivismo jurídico. Para superarlas, propone la teoría de la acción comunicativa, con base en la filosofía práctica de Kant, y en la que plantea, no imponer una ley, sino proponer una teoría con aspiración universal.

A partir de la publicación en 1981 de su obra fundamental, la "Teoría de la acción comunicativa", sus análisis y reflexiones se han orientado hacia la fundamentación de la ética discursiva, la defensa de la democracia deliberativa y de los principios del Estado de derecho, así como hacia las bases normativas requeridas para configurar una esfera pública trasnacional.

Entre sus obras más importantes figura también "Facticidad y validez", en la cual de algún modo aplica los principios de su teoría de la acción comunicativa a la teoría del derecho y la teoría de la democracia, delineando su propia teoría de la democracia deliberativa en contraposición a los modelos de democracia liberal y republicana. 

Los intereses teóricos de Habermas no están descontextualizadas y, como él mismo admite, tiene una profundas raíces biográficas:






</doc>
<doc id="1563" url="https://es.wikipedia.org/wiki?curid=1563" title="Jota">
Jota

Jota puede referirse a:





</doc>
<doc id="1564" url="https://es.wikipedia.org/wiki?curid=1564" title="Jota (música)">
Jota (música)

La jota es una danza y canto español extendido por gran parte de la geografía de España.

Varía según las regiones, existiendo por ejemplo jota de Aragón, la jota castellana, la jota manchega, la de León, la de Valencia, la de Navarra, la de La Rioja, la «montañesa» de Cantabria, la de Asturias, la de Galicia, la de Extremadura, la de la Alta Andalucía y la de Murcia. Entendida como representación escénica, la jota se canta y se baila acompañándose de castañuelas y los intérpretes suelen ir vestidos con trajes regionales. En Valencia, antiguamente, se bailaba la jota en la ceremonia de los entierros. También se bailaba —y se baila— en Cataluña, y especialmente en la zona de las Tierras del Ebro (Amposta, Tortosa, etc) y en el Campo de Tarragona (jota fogueada). También en Canarias las jotas y rondallas con características peculiares eran la parte del folclore más destacada, hoy día un tanto desplazadas por la protección hacia otros estilos considerados " más autóctonos". No obstante, en las islas existe la isa, una pieza musical que deriva de la jota. En Filipinas, los religiosos españoles trasmitieron la jota a los tagalos, que la interpretan en rondallas y acompañada de instrumentos nativos. Las variedades de jota de Aragón, La Rioja y Navarra están emparentadas entre sí y forman las llamadas Jotas del Ebro, siendo unas de las más características de este género. Se celebran concursos y certámenes de jotas del Ebro por todo el territorio español.

No se sabe su origen. Parecería provenir del mozárabe "*šáwta", salto, y este del latín "saltāre", bailar. Al norte de los Pirineos, se bailan danzas llamadas también s"auts, s"altos, en las provincias gascona-aquitanas, bearnesas y la Baja Navarra, derivadas directamente del Branle del Renacimiento (c.f. "Le saut de Béarn", "Les sept sauts", y "Le saut deu lapin").
Su ritmo suele ser compaseado en 3/4, aunque algunos autores sostienen que el 6/8 se adapta mejor a la estructura del ciclo coreográfico y estrófico. Las armonizaciones populares más habituales se ciñen a acordes de primera, cuarta y quinta del modo mayor con séptima dominante. Para su interpretación se utilizan guitarras, bandurrias y laúdes. Acordeón en el caso de la navarra, riojana y aragonesa, dulzaina y tamboriles en la castellana, y en el caso de la cántabra, leonesa, asturiana y gallega gaitas, pitu montañés, gaita charra, panderetas, tambores y bombo. 

Las cuerdas son los instrumentos que marcan el ritmo. 

Las versiones de exhibición se cantan y bailan con trajes regionales y castañuelas, lo que no es tan habitual cuando es practicada como diversión o baile social. El contenido de las canciones es muy diverso, desde el patriotismo, hasta la religión o las picardías sexuales. Prevalecen aquellas que tienen utilidad como generadoras de cohesión en el pueblo que las baila.

Los pasos que ejecutan los danzantes se parecen a los del vals, aunque en el caso de la jota hay mucha más variación. La letra, en cuanto a la forma, suele escribirse en cuartetos octosílabos, siendo asonantes el primer y el tercer versos.

Un buen número de compositores no españoles han utilizado el estilo de la jota en obras de inspiración española:

La jota aragonesa es la más conocida de las manifestaciones del folclore musical de Aragón. Su origen podría estar hacia finales del siglo XVIII, y tuvo su mayor esplendor durante el siglo XIX, adquiriendo gran auge tras la Guerra de la Independencia. Desde finales del siglo XIX ha sido llevada a los escenarios como espectáculo. La jota fue incluida en zarzuelas, películas, coreografiada para grandes festivales, y llevada a concursos y certámenes.

La jota aragonesa incluye tanto por baile como canto y rondalla.

El baile lo hacen mujeres y hombres de todas las edades. Posee gran dificultad sobre todo en los pasos. Se suelen bailar jotas de tres coplas, boleros, fandangos y todo ello se baila en parejas formando diferentes figuras grupales.

El canto es habitualmente solista, aunque también se puede cantar a dúo, compuesto por una voz que lleva la melodía y otra que lleva la octava, también llamada dúo. Se canta a modo grupal como pueden ser boleros, fandangos estribillos y cantos de bodega compuesto por hombres y mujeres. Respecto en el baile, los cantadores acompaña a los bailadores según el tema instrumental y por ello se forma un grupo de bailadores y cantadores que se adecúan al estilo musical. Los cantadores cantan las jotas comprendidas en los tonos mayores y menores desde DO hasta SI.

En cuanto a la formación de la rondalla no hay límite de edad. Las rondallas suelen estar formadas por los instrumentos más reconocibles como guitarra, bandurria, laúd y guitarrico (este se usa más para rondas), aparte también se pueden introducir nuevos instrumentos a esta formación como bajo eléctrico, viola o contrabajo. La rondalla juega un papel importante pero a la vez muy discreto, se encargan de acompañar a los bailadores en las jotas de baile y a los cantadores en sus jotas tanto solistas, como a dúo o grupales.

Los estilos de baile, llamados puros, por haberse conservado hasta nuestros días, son los correspondientes a las localidades de Calanda, Alcañiz, Andorra, Albalate del Arzobispo, Huesca, y Zaragoza. Entre las más populares en los repertorios se encuentran: "Jota de San Lorenzo" (Huesca), "Jota Repetida "(Teruel), "Jota vieja", "Aragón tierra bravía", "Gigantes y cabezudos", "La Dolores" (estas últimas pertenecen a las zarzuelas del mismo nombre), "La danza de la Olivera", etc.

Muy importantes son también otros bailes relacionados con la jota, como los boleros del siglo XVIII, destacando el de Alcañiz, el de Caspe, y el de Sallent de Gállego, que aunque hoy en día están muy influidos por la jota, en su día gozaron de gran popularidad, y se bailaban acompañados de dulzainas y tambores, como en la Jota Hurtada de Albarracín. Otras danzas singulares eran la Gitanilla de Andorra, con cintas, hoy coreografiada como Danza de Andorra, la danza de los pañuelos de Remolinos, o las danzas decimonónicas del Pirineo, tales como el Cadril, el Villano, la Canastera o el Tin tan.

Entre los cantantes destacan las figuras de Pedro Nadal «el Royo del Rabal», Mariano Malandía «el Tuerto de las Tenerías», Juanito Pardo, Cecilio Navarro, Jesús Gracia, José Iranzo Bielsa «el Pastor de Andorra» y del admirado José Oto, considerado el más importante «cantador» de jota aragonesa. Entre las voces femeninas se pueden señalar las de Asunción Delmás, Pilar Gascón, Jacinta Bartolomé, Pascuala Perié, Felisa Galé, Pilar de las Heras o María Blasco.

La jota castellana (tanto la de la parte castellana de Castilla y León, como la de Madrid y la castellano-manchega) se suele acompañar con guitarras, bandurrias, laúdes, dulzaina y tambor.

En Cataluña, la jota es parte del folklore tradicional de las tierras occidentales de la comunidad, y especialmente de las llamadas "Tierras del Ebro". La primera referencia escrita conocida es una condena por parte del obispo de Tortosa, de 1734, si bien se refiere a Calaceite, localidad aragonesa vecina a Cataluña. En los últimos tiempos se ha revalorizado este género musical en la comunidad gracias sobre todo al grupo tortosino "Quico el Célio, el Noi i el Mut de Ferreries"; el gobierno autonómico declaró en 2010 la jota "danza de interés nacional en Catalunya".

Extremadura conserva gran número de bailes y danzas tradicionales autóctonas. Las jotas toman en Extremadura gran variedad de formas y matices, también sobresale el fandango, la rondeña, la jota del triángulo, las paleos, el pindongo, el perantón, sones brincaos y sones llanos.

Los Instrumentos utilizados son la flauta de tres agujeros, la gaita extremeña y tamboril, guitarra, bandurria, laúd, rabel, acordeón, pandero, violín y otros instrumentos de percusión como almireces, castañuelas, sonajas, morteros, cencerros, botella de anís... Ejemplo:

En el caso de la jota leonesa es más frecuente el acompañamiento con gaita o flauta de tres agujeros y tamboril. Todo mientras la pareja de bailarines danza manteniendo las manos encima de la cabeza, ocasionalmente acompañados de castañuelas. Estos tipos de jotas se bailan con los característicos pasos saltados, un poco picadas, y son más sobrias y menos movidas y airosas que la de Aragón. La música va frecuentemente acompañada por canciones que reciben el nombre de coplas. Estas a veces tratan del amor, de las bodas (en las que se daban consejos y alabanzas a los novios), de la vida o de su religiosidad, pero casi siempre se caracterizan por su picaresca y gran sentido del humor.

La jota charra, típica de la provincia de Salamanca, tiene por instrumentos típicos la flauta de tres agujeros o gaita charra y el tamboril. También se da una tendencia castellanizante en el este de la provincia al introducirse recientemente el uso de la dulzaina castellana. El folclore charro constituye un puente entre la cultura leonesa al norte y la extremeña al sur.

La jota charra acostumbra a bailarse en pareja, aunque también es común hacerlo en grupo, especialmente en las fiestas de los pueblos. Este tipo de jota, igual que el resto del folclore charro, suele ser muy estático de cintura para arriba. 

Respecto a las canciones, las hay con letra y sin ella, debido a la cultura oral existen multitud de variedades de una misma letra, como ocurre con la Jota de la Clara.

La jota manchega, típica del lugar, tiene como característica propia rasgos de ronda. A muchas jotas manchegas se las conoce por «Jota del Mantecado», ya que era frecuente cantarlas y bailarlas en fechas cercanas a la Navidad (y también en otras fechas señaladas).

Se denomina jota montañesa a la variedad interpretada en algunas zonas de Cantabria, también conocida como baile "a lo altu y a lo baju" o "a lo ligeru y a lo pesau". Antiguamente interpretada al son de la pandereta para posteriormente entrar el pitu (clarinete en mi bemol) y tambor. En la actualidad se ha incorporado la gaita.

Junto con la aragonesa conforman las famosas jotas del Ebro. Los joteros y joteras de este tipo de cante visten con pantalón o falda blanca, alpargatas blancas con cintas rojas, faja roja, camisa blanca y pañuelo rojo.
Las letras de las canciones son versos populares, en algunos de los casos referidos a temas del día a día tradicional de las personas por los que fueron compuestas. Un ejemplo son las jotas a la vendimia o cantos a Navarra o a La Rioja en sí misma. Otros temas son los familiares, del campo, de tono satírico, de los ciclos agrícolas o del amor y desamor. Se cantaban en las fiestas populares o por los labradores para amenizar las faenas del campo. Normalmente la parte instrumental de la actuación está protagonizada por una rondalla o a veces por instrumentos de viento como la gaita de bota riojana o la dulzaina navarra, tocada en ambas regiones. También muy frecuentemente por un acordeón.

Existen escuelas de jota a lo largo de todo el valle del Ebro a su paso por La Rioja y Navarra, y también es muy popular en Miranda de Ebro, Tudela, entre otras muchas. Se realizan diversos concursos de este arte que es uno de los máximos exponentes de la cultura de esta zona.

El formato habitual consta de 4 versos de los cuales se repiten 3 para llegar a un total de 7 en este orden a, b, a, c, d, d, b. Ejemplo:

El más famoso jotero de la historia de la jota navarra fue Raimundo Lanas. Otros joteros de renombre son Faico y Josefina, Julián Arina, Hermanas Flamariqué Hermanos Anoz o Molviedro. Habitualmente se organizan en agrupaciones de joteros, y son los más conocidos Alma Navarra (con sus versiones de «No te vayas de Navarra», «Pamplona, perla del norte» o «himno de Osasuna»), Navarra Canta o Montaña y Ribera, entre otros muchos grupos. En el caso de la jota riojana cabe mencionar varios intérpretes y compositores de este estilo musical como Pepe Blanco , Teo Echaure , Purita Ugalde "La Riojanita", Antonio García, Ángel Sáez-Benito, Oscar Alesanco o Fidel Ibarra, que actuó ante el Rey Alfonso XIII en 1903 durante su primera visita a la capital riojana y composiciones como ""Riojano de pura cepa"" (1880), el pasodoble-jota ""En la Rioja nací"" (1957) , ""La jota de Logroño"" (1910) , ""En la Rioja los riojanos"" (1945), ""En La Rioja no hay tranvía"" (1953) etc... Este estilo musical también tuvo su repercusión en los teatros. Así sucedió con la zarzuela en obras como ""El postillón de La Rioja"" (1851), de autores no riojanos, que incluye una jota riojana en el primer acto, en ""Cameranas"" (1933) de José Eizaga" o en ""La Riojana"" (1898) de Florencio Bello. La jota riojana debido a su especificidad y singularidad ha sido declarada como bien de interés cultural de carácter inmaterial. Actualmente existen grupos que interpretan tanto jota navarra como riojana, por ejemplo "Voces del Ebro".

La jota valenciana recuerda a los bailes de salón por sus candenciosos movimientos.
Muchos pueblos tienen su jota, como la "valenciana" , la "Jota Vallera" (Vall de Uxó), la "cofrentina", la "moixentina" (Mogente), "del postiguet", "la de Carlet o u i dos", "la de Villena", etc.

Existe un patrimonio formado por 9 géneros distintos de música para el baile con sus variantes musicales y coreográficas. Todo ello, sin contar los bailes de plaza, ni las danzas rituales.










También existe una variante de la jota en la región del Chocó, Colombia, que ha sido estudiada por el musicólogo Andrés Pardo Tovar.





</doc>
<doc id="1565" url="https://es.wikipedia.org/wiki?curid=1565" title="Joint Photographic Experts Group">
Joint Photographic Experts Group

Joint Photographic Experts Group (JPEG), es el nombre de un comité de expertos que creó un estándar de compresión y codificación de archivos e imágenes fijas. Este comité fue integrado desde sus inicios por la fusión de varias agrupaciones en un intento de compartir y desarrollar su experiencia en la digitalización de imágenes. La ISO, tres años antes (abril de 1983), había iniciado sus investigaciones en el área.

Además de ser un método de compresión, es a menudo considerado como un formato de archivo. JPEG/Exif es el formato de imagen más común, utilizado por las cámaras fotográficas digitales y otros dispositivos de captura de imagen, junto con JPG/JFIF, que también es otro formato para el almacenamiento y la transmisión de imágenes fotográficas en la World Wide Web. Estas variaciones de formatos a menudo no se distinguen, y se llaman “JPEG”. Los archivos de este tipo se suelen nombrar con la extensión codice_1.

El formato JPEG utiliza habitualmente un algoritmo de compresión con pérdida para reducir el tamaño de los archivos de imágenes. Esto significa que al descomprimir o visualizar la imagen no se obtiene exactamente la misma imagen de la que se partía antes de la compresión. Existen también tres variantes del estándar JPEG que comprimen la imagen sin pérdida de datos: JPEG 2000, JPEG-LS y Lossless JPEG. 

El algoritmo de compresión JPEG se basa en dos fenómenos visuales del ojo humano: uno es el hecho de que es mucho más sensible al cambio en la luminancia que en la crominancia; es decir, capta más claramente los cambios de brillo que de color. El otro es que nota con más facilidad pequeños cambios de brillo en zonas homogéneas que en zonas donde la variación es grande, por ejemplo en los bordes de los cuerpos de los objetos.

Una de las características del JPEG es la flexibilidad a la hora de ajustar el grado de compresión. Un grado de compresión muy alto generará un archivo de pequeño tamaño, a costa de una pérdida significativa de calidad. Con una tasa de compresión baja se obtiene una calidad de imagen muy parecida a la del original, pero con un tamaño de archivo mayor.

La pérdida de calidad cuando se realizan sucesivas compresiones es acumulativa. Esto significa que si se comprime una imagen y se descomprime, se perderá calidad de imagen, pero si se vuelve a comprimir una imagen ya comprimida se obtendrá una pérdida todavía mayor. Cada sucesiva compresión causará pérdidas adicionales de calidad. La compresión con pérdida no es conveniente en imágenes o gráficos que tengan textos, líneas o bordes muy definidos, pero sí para archivos que contengan grandes áreas de colores sólidos.

Muchas de las opciones del estándar JPEG se usan poco. Esto es una descripción breve de uno de los muchos métodos usados comúnmente para comprimir imágenes cuando se aplican a una imagen de entrada con 24 bits por pixel (ocho por cada rojo, verde, y azul, o también dicho "8 bits por canal"). Esta opción particular es un método de compresión con pérdida.

Comienza convirtiendo la imagen desde su modelo de color RGB a otro llamado YUV o YCbCr. Este espacio de color es similar al que usan los sistemas de color para televisión PAL y NTSC, pero es mucho más parecido al sistema de televisión (Componentes Analógicas Multiplexadas).

Este espacio de color (YUV) tiene tres componentes:

Las ecuaciones que realizan este cambio de base de RGB a YUV son las siguientes:

Las ecuaciones para el cambio inverso se pueden obtener despejando de las anteriores y se obtienen las siguientes:

Si se analiza el primer trío de ecuaciones veremos que las tres componentes toman como valor mínimo el 16. El canal de luminancia (canal Y) tiene como valor máximo el 235, mientras que los canales de crominancia el 240. Todos estos valores caben en un byte haciendo redondeo al entero más próximo. Durante esta fase no hay pérdida significativa de información, aunque el redondeo introduce un pequeño margen de error imperceptible para el ojo humano.

Una opción que se puede aplicar al guardar la imagen es reducir la información del color respecto a la de brillo (debido al fenómeno visual en el ojo humano comentado anteriormente). Hay varios métodos: si este paso no se aplica, la imagen sigue en su espacio de color YUV (este submuestreo se entiende como ), con lo que la imagen no sufre pérdidas. Puede reducirse la información cromática a la mitad, (reducir en un factor de 2 en dirección horizontal), con lo que el color tiene la mitad de resolución (en horizontal) y el brillo sigue intacto. Otro método, muy usado, es reducir el color a la cuarta parte, , en el que el color se reduce en un factor de 2 en ambas direcciones, horizontal y vertical. Si la imagen de partida estaba en escala de grises (blanco y negro), puede eliminarse por completo la información de color, quedando como 4:0:0.

Algunos programas que permiten el guardado de imágenes en JPEG (como el que usa GIMP) se refieren a estos métodos con "1×1,1×1,1×1" para YUV 4:4:4 (no perder color), "2×1,1×2,1×1" para YUV 4:2:2 y "2×2,1×1,1×1" para el último método, YUV 4:2:0.

Las técnicas algorítmicas usadas para este paso (para su reconstrucción exactamente) suelen ser interpolación bilineal, vecino más próximo, convolución cúbica, Bezier, b-spline y Catmun-Roll.rh

Cada componente de la imagen se divide en pequeños bloques de 8×8 píxeles, que se procesan de forma casi independiente, lo que disminuye notablemente el tiempo de cálculo. De esto resulta la típica formación cuadriculada, que se vuelve visible en las imágenes guardadas con alta compresión. Si la imagen sufrió un submuestreo del color, los colores quedarían en la imagen final en bloques de 8×16 y 16×16 píxeles, según fuese 4:2:2 o 4:2:0.

Después, cada pequeño bloque se convierte al dominio de la frecuencia a través de la transformación discreta de coseno, abreviadamente llamada DCT.

Un ejemplo de uno de esos pequeños bloques de 8×8 inicial es este:

El siguiente proceso es restarles 128 para que queden números entorno al 0, entre -128 y 127.

Se procede a la transformación por DCT de la matriz, y el redondeo de cada elemento al número entero más cercano.

Nótese que el elemento más grande de toda la matriz aparece en la esquina superior izquierda; este es el coeficiente DC.

El ojo humano es muy bueno detectando pequeños cambios de brillo en áreas relativamente grandes, pero no cuando el brillo cambia rápidamente en pequeñas áreas (variación de alta frecuencia). Debido a esta condición, se puede eliminar las altas frecuencias, sin pérdida excesiva de calidad visual. Esto se realiza dividiendo cada componente en el dominio de la frecuencia por una constante para ese componente, y redondeándolo a su número entero más cercano. Este es el proceso en el que se pierde la mayor parte de la información (y calidad) cuando una imagen es procesada por este algoritmo. El resultado de esto es que los componentes de las altas frecuencias, tienden a igualarse a cero, mientras que muchos de los demás, se convierten en números positivos y negativos pequeños.

Una matriz de cuantificación típica es la matriz de Losheller que se usa opcionalmente en el estándar JPEG:

Dividiendo cada coeficiente de la matriz de la imagen transformada entre cada coeficiente de la matriz de cuantificación, se obtiene esta matriz, ya cuantificada:

Por ejemplo, cuantificando el primer elemento, el coeficiente DC, sería así:

La codificación entrópica es una forma especial de la compresión sin pérdida de datos. Para ello se toman los elementos de la matriz siguiendo una forma de zig-zag, poniendo grupos con frecuencias similares juntos, e insertando ceros de codificación, y usando la codificación Huffman para lo que queda. También se puede usar la codificación aritmética, superior a la de Huffman, pero que rara vez se usa, ya que está cubierta por patentes, esta compresión produce archivos un 5% menores, pero a costa de un mayor tiempo de codificación y decodificación, esta pequeña ganancia, puede emplearse también en aplicar un menor grado de compresión a la imagen, y obtener más calidad para un tamaño parecido.

En la matriz anterior, la secuencia en zig-zag, es esta:
−26, −3, 0, −3, −2, −6, 2, −4, 1 −4, 1, 1, 5, 1, 2, −1, 1, −1, 2, 0, 0, 0, 0, 0, −1, −1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0

JPEG tiene un código Huffman para cortar la cadena anterior en el punto en el que el resto de coeficientes sean ceros, y así, ahorrar espacio:
−26, −3, 0, −3, −2, −6, 2, −4, 1 −4, 1, 1, 5, 1, 2, −1, 1, −1, 2, 0, 0, 0, 0, 0, −1, −1, EOB

El resultado tras la compresión, puede variar, en función de la agresividad de los divisores de la matriz de cuantización, a mayor valor de esos divisores, más coeficientes se convierten en ceros, y más se comprime la imagen. Pero mayores compresiones producen mayor ruido en la imagen, empeorando su calidad. Una imagen con una fuerte compresión (1%-15%) puede tener un tamaño de archivo mucho menor, pero tendrá tantas imperfecciones que no será interesante, una compresión muy baja (98%-100%) producirá una imagen de muy alta calidad, pero, tendrá un tamaño tan grande que quizás interese más un formato sin pérdida como PNG.

La mayoría de personas que naveguen por Internet estarán familiarizadas con estas imperfecciones, que son el resultado de lograr una buena compresión. Para evitarlas, se tendrá que reducir el nivel de compresión o aplicar compresión sin pérdida, produciendo mayores ficheros después.

El proceso de decodificación es similar al seguido hasta ahora, solo que de forma inversa. En este caso, al haber perdido información, los valores finales no coincidirán con los iniciales.

Se toma la información de la matriz, se decodifica, y se pone cada valor en su casilla correspondiente. Después se multiplica cada uno de estos valores por el valor correspondiente de la matriz de cuantización usada, como muchos valores son ceros, sólo se recuperan ( y de forma aproximada) los valores de la esquina superior izquierda.

Después se deshace la transformación DCT:

Y finalmente se suma 128 a cada entrada:

Para comparar las diferencias entre el bloque original y el comprimido, se halla la diferencia entre ambas matrices, la media de sus valores absolutos, da una ligera idea de la calidad perdida:

Se puede observar que las mayores diferencias están cerca de la mancha, y por la parte inferior, entre la esquina izquierda y el centro, notándose más esta última, ya que corre una mancha clara que antes estaba más hacia la esquina. La media de los valores absolutos de las restas es 4.8125, aunque en algunas zonas es mayor.




</doc>
