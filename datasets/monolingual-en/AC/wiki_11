<doc id="24780" url="https://en.wikipedia.org/wiki?curid=24780" title="Five precepts">
Five precepts

The Five precepts ( pañcaśīla, ปญฺจสีล); or five rules of training ( pañcaśikṣapada, ปญฺจสิกฺขปท; ) is the most important system of morality for Buddhist lay people. They constitute the basic code of ethics to be undertaken by lay followers of Buddhism. The precepts are commitments to abstain from killing living beings, stealing, sexual misconduct, lying and intoxication. Within the Buddhist doctrine, they are meant to develop mind and character to make progress on the path to enlightenment. They are sometimes referred to as the Śrāvakayāna precepts in the Mahāyāna tradition, contrasting them with the "bodhisattva" precepts. The five precepts form the basis of several parts of Buddhist doctrine, both lay and monastic. With regard to their fundamental role in Buddhist ethics, they have been compared with the ten commandments in Abrahamic religions or the ethical codes of Confucianism. The precepts have been connected with utilitarianist, deontological and virtue approaches to ethics, though by 2017, such categorization by western terminology had mostly been abandoned by scholars. The precepts have been compared with human rights because of their universal nature, and some scholars argue they can complement the concept of human rights.

The five precepts were common to the religious milieu of 6th-century BCE India, but the Buddha's focus on awareness through the fifth precept was unique. As shown in Early Buddhist Texts, the precepts grew to be more important, and finally became a condition for membership of the Buddhist religion. When Buddhism spread to different places and people, the role of the precepts began to vary. In countries where Buddhism had to compete with other religions, such as China, the ritual of undertaking the five precepts developed into an initiation ceremony to become a Buddhist lay person. On the other hand, in countries with little competition from other religions, such as Thailand, the ceremony has had little relation to the rite of becoming Buddhist, as many people are presumed Buddhist from birth.

Undertaking and upholding the five precepts is based on the principle of non-harming (Pāli and ). The Pali Canon recommends one to compare oneself with others, and on the basis of that, not to hurt others. Compassion and a belief in karmic retribution form the foundation of the precepts. Undertaking the five precepts is part of regular lay devotional practice, both at home and at the local temple. However, the extent to which people keep them differs per region and time. People keep them with an intention to develop themselves, but also out of fear of a bad rebirth.


In modern times, traditional Buddhist countries have seen revival movements to promote the five precepts. As for the West, the precepts play a major role in Buddhist organizations. They have also been integrated in mindfulness training programs, though many mindfulness specialists do not support this because of the precepts' religious import. Lastly, many conflict prevention programs make use of the precepts.

Buddhist scriptures explain the five precepts as the minimal standard of Buddhist morality. It is the most important system of morality in Buddhism, together with the monastic rules. "Śīla" (Sanskrit; ) is used to refer to Buddhist precepts, including the five. But the word also refers to the virtue and morality which lies at the foundation of the spiritual path to enlightenment, which is the first of the three forms of training on the path. Thus, the precepts are rules or guidelines to develop mind and character to make progress on the path to enlightenment. The five precepts are part of the right speech, action and livelihood aspects of the Noble Eightfold Path, the core teaching of Buddhism. Moreover, the practice of the five precepts and other parts of "śīla" are described as forms of merit-making, means to create good karma. The five precepts have been described as social values that bring harmony to society, and breaches of the precepts described as antithetical to a harmonious society. On a similar note, in Buddhist texts, the ideal, righteous society is one in which people keep the five precepts.

Comparing different parts of Buddhist doctrine, the five precepts form the basis of the eight precepts, which are lay precepts stricter than the five precepts, similar to monastic precepts. Secondly, the five precepts form the first half of the ten or eleven precepts for a person aiming to become a Buddha ("bodhisattva"), as mentioned in the "Brahmajala Sūtra" of the Mahāyāna tradition. Contrasting these precepts with the five precepts, the latter were commonly referred to by Mahāyānists as the "śrāvakayāna" precepts, or the precepts of those aiming to become enlightened disciples (; ) of a Buddha, but not Buddhas themselves. The teneleven "bodhisattva" precepts presuppose the five precepts, and are partly based on them. The five precepts are also partly found in the teaching called the ten good courses of action, referred to in Theravāda () and Tibetan Buddhism (; ). Finally, the first four of the five precepts are very similar to the most fundamental rules of monastic discipline (), and may have influenced their development.

In conclusion, the five precepts lie at the foundation of all Buddhist practice, and in that respect, can be compared with the ten commandments in Christianity and Judaism or the ethical codes of Confucianism.

The five precepts were part of early Buddhism and are common to nearly all schools of Buddhism. In early Buddhism, the five precepts were regarded as an ethic of restraint, to restrain unwholesome tendencies and thereby purify one's being to attain enlightenment. The five precepts were based on the "pañcaśīla", prohibitions for pre-Buddhist Brahmanic priests, which were adopted in many Indic religions around 6th century BCE. The first four Buddhist precepts were nearly identical to these "pañcaśīla", but the fifth precept, the prohibition on intoxication, was new in Buddhism: the Buddha's emphasis on awareness () was unique.

In some schools of ancient Indic Buddhism, Buddhist devotees could choose to adhere to only a number of precepts, instead of the complete five. The schools that would survive in later periods, however, that is Theravāda and Mahāyāna Buddhism, were both ambiguous about this practice. Some early Mahāyāna texts allow it, but some do not; Theravāda texts do not discuss this practice at all.

The prohibition on killing had motivated early Buddhists to form a stance against animal sacrifice, a common ritual practice in ancient India. According to the Pāli Canon, however, early Buddhists did not adopt a vegetarian lifestyle.

In Early Buddhist Texts, the role of the five precepts gradually develops. First of all, the precepts are combined with a declaration of faith in the triple gem (the Buddha, his teaching and the monastic community). Next, the precepts develop to become the foundation of lay practice. The precepts are seen as a preliminary condition for the higher development of the mind. At a third stage in the texts, the precepts are actually mentioned together with the triple gem, as though they are part of it. Lastly, the precepts, together with the triple gem, become a required condition for the practice of Buddhism, as lay people have to undergo a formal initiation to become a member of the Buddhist religion. When Buddhism spread to different places and people, the role of the precepts began to vary. In countries in which Buddhism was adopted as the main religion without much competition from other religious disciplines, such as Thailand, the relation between the initiation of a lay person and the five precepts has been virtually non-existent. In such countries, the taking of the precepts has become a sort of ritual cleansing ceremony. People are presumed Buddhist from birth without much of an initiation. The precepts are often committed to by new followers as part of their installment, yet this is not very pronounced. However, in some countries like China, where Buddhism was not the only religion, the precepts became an ordination ceremony to initiate lay people into the Buddhist religion.

In China, the five precepts were introduced in the first centuries CE, both in their "śrāvakayāna" and "bodhisattva" formats. During this time, it was particularly Buddhist teachers who promoted abstinence from alcohol (the fifth precept), since Daoism and other thought systems emphasized moderation rather than full abstinence. Chinese Buddhists interpreted the fifth precept strictly, even more so than in Indic Buddhism. For example, the monk Daoshi ( 600–83) dedicated large sections of his encyclopedic writings to abstinence from alcohol. However, in some parts of China, such as Dunhuang, considerable evidence has been found of alcohol consumption among both lay people and monastics. Later, from the 8th century onward, strict attitudes of abstinence led to a development of a distinct tea culture among Chinese monastics and lay intellectuals, in which tea gatherings replaced gatherings with alcoholic beverages, and were advocated as such. These strict attitudes were formed partly because of the religious writings, but may also have been affected by the bloody An Lushan Rebellion of 775, which had a sobering effect on 8th-century Chinese society. When the five precepts were integrated in Chinese society, they were associated and connected with karma, Chinese cosmology and medicine, a Daoist worldview, and Confucian virtue ethics.

In the Theravāda tradition, the precepts are recited in a standardized fashion, using Pāli language. In Thailand, a leading lay person will normally request the monk to administer the precepts by reciting the following three times:

After this, the monk administering the precepts will recite a reverential line of text to introduce the ceremony, after which he guides the lay people in declaring that they take their refuge in the three refuges or triple gem.

He then continues with reciting the five precepts:

After the lay people have repeated the five precepts after the monk, the monk will close the ceremony reciting:

The format of the ceremony for taking the precepts occurs several times in the Chinese Buddhist Canon, in slightly different forms.

One formula of the precepts can be found in the "Treatise on Taking Refuge and the Precepts" ():


Similarly, in the Mūla-Sarvāstivāda texts used in Tibetan Buddhism, the precepts are formulated such that one takes the precepts upon oneself for one's entire lifespan, following the examples of the enlightened disciples of the Buddha ("arahant").

The five precepts can be found in many places in the Early Buddhist Texts. The precepts are regarded as means to building good character, or as an expression of such character. The Pāli Canon describes them as means to avoid harm to oneself and others. It further describes them as gifts toward oneself and others. Moreover, the texts say that people who uphold them will be confident in any gathering of people, will have wealth and a good reputation, and will die a peaceful death, reborn in heaven or as a human being. On the other hand, living a life in violation of the precepts is believed to lead to rebirth in an unhappy destination. They are understood as principles that define a person as human in body and mind.

The precepts are normative rules, but are formulated and understood as "undertakings" rather than commandments enforced by a moral authority, according to the voluntary and gradualist standards of Buddhist ethics. They are forms of restraint formulated in negative terms, but are also accompanied by virtues and positive behaviors, which are cultivated through the practice of the precepts. The most important of these virtues is non-harming (Pāli and ), which underlies all of the five precepts. Precisely, the texts say that one should keep the precepts, adhering to the principle of comparing oneself with others:
In other words, all living beings are alike in that they want to be happy and not suffer. Comparing oneself with others, one should therefore not hurt others as one would not want to be hurt. Ethicist Pinit Ratanakul argues that the compassion which motivates upholding the precepts comes from an understanding that all living beings are equal and of a nature that they are 'not-self' (). Another aspect that is fundamental to this is the belief in karmic retribution.

In the upholding or violation of the precepts, intention is crucial. In the Pāli scriptures, an example is mentioned of a person stealing an animal only to set it free, which was not seen as an offense of theft. In the Pāli commentaries, a precept is understood to be violated when the person violating it finds the object of the transgression (e.g. things to be stolen), is aware of the violation, has the intention to violate it, does actually act on that intention, and does so successfully.

Upholding the precepts is sometimes distinguished in three levels: to uphold them without having formally undertaken them; to uphold them formally, willing to sacrifice one's own life for it; and finally, to spontaneously uphold them. The latter refers to the "arahant", who is understood to be morally incapable of violating the first four precepts. A layperson who upholds the precepts is described in the texts as a "jewel among laymen". On the other hand, the most serious violations of the precepts are the five actions of immediate retribution, which are believed to lead the perpetrator to an unavoidable rebirth in hell. These consist of injuring a Buddha, killing an "arahant", killing one's father or mother, and causing the monastic community to have a schism.

Lay followers often undertake these training rules in the same ceremony as they take the refuges. Monks administer the precepts to the laypeople, which creates an additional psychological effect. Buddhist lay people may recite the precepts regularly at home, and before an important ceremony at the temple to prepare the mind for the ceremony.

The five precepts are at the core of Buddhist morality. In field studies in some countries like Sri Lanka, villagers describe them as the core of the religion. Anthropologist Barend Terwiel found in his fieldwork that most Thai villagers knew the precepts by heart, and many, especially the elderly, could explain the implications of the precepts following traditional interpretations.

Nevertheless, Buddhists do not all follow them with the same strictness. Devotees who have just started keeping the precepts will typically have to exercise considerable restraint. When they become used to the precepts, they start to embody them more naturally. Researchers doing field studies in traditional Buddhist societies have found that the five precepts are generally considered demanding and challenging. For example, anthropologist Stanley Tambiah found in his field studies that strict observance of the precepts had "little positive interest for the villager ... not because he devalues them but because they are not normally open to him". Observing precepts was seen to be mostly the role of a monk or an elderly lay person. More recently, in a 1997 survey in Thailand, only 13.8% of the respondents indicated they adhered to the five precepts in their daily lives, with the fourth and fifth precept least likely to be adhered to. Yet, people do consider the precepts worth striving for, and do uphold them out of fear of bad karma and being reborn in hell, or because they believe in that the Buddha issued these rules, and that they therefore should be maintained. Anthropologist Melford Spiro found that Burmese Buddhists mostly upheld the precepts to avoid bad karma, as opposed to expecting to gain good karma. Scholar of religion Winston King observed from his field studies that the moral principles of Burmese Buddhists were based on personal self-developmental motives rather than other-regarding motives. Scholar of religion Richard Jones concludes that the moral motives of Buddhists in adhering to the precepts are based on the idea that renouncing self-service, ironically, serves oneself.

In East Asian Buddhism, the precepts are intrinsically connected with the initiation as a Buddhist lay person. Early Chinese translations such as the "Upāsaka-śila Sūtra" hold that the precepts should only be ritually transmitted by a monastic. The texts describe that in the ritual the power of the Buddhas and "bodhisattvas" is transmitted, and helps the initiate to keep the precepts. This "lay ordination" ritual usually occurs after a stay in a temple, and often after a monastic ordination (); has taken place. The ordained lay person is then given a religious name. The restrictions that apply are similar to a monastic ordination, such as permission from parents.

In the Theravāda tradition, the precepts are usually taken "each separately" (), to indicate that if one precept should be broken, the other precepts are still intact. In very solemn occasions, or for very pious devotees, the precepts may be taken as a group rather than each separately. This does not mean, however, that only some of the precepts can be undertaken; they are always committed to as a complete set. In East Asian Buddhism, however, the vow of taking the precepts is considered a solemn matter, and it is not uncommon for lay people to undertake only the precepts that they are confident they can keep. The act of taking a vow to keep the precepts is what makes it karmically effective: Spiro found that someone who did not violate the precepts, but did not have any intention to keep them either, was not believed to accrue any religious merit. On the other hand, when people took a vow to keep the precepts, and then broke them afterwards, the negative karma was considered larger than in the case no vow was taken to keep the precepts.

Several modern teachers such as Thich Nhat Hanh and Sulak Sivaraksa have written about the five precepts in a wider scope, with regard to social and institutional relations. In these perspectives, mass production of weapons or spreading untruth through media and education also violates the precepts. On a similar note, human rights organizations in Southeast Asia have attempted to advocate respect for human rights by referring to the five precepts as guiding principles.

The first precept prohibits the taking of life of a sentient being. It is violated when someone intentionally and successfully kills such a sentient being, having understood it to be sentient and using effort in the process. Causing injury goes against the spirit of the precept, but does, technically speaking, not violate it. The first precept includes taking the lives of animals, even small insects. However, it has also been pointed out that the seriousness of taking life depends on the size, intelligence, benefits done and the spiritual attainments of that living being. Killing a large animal is worse than killing a small animal (also because it costs more effort); killing a spiritually accomplished master is regarded as more severe than the killing of another "more average" human being; and killing a human being is more severe than the killing of an animal. But all killing is condemned. Virtues that accompany this precept are respect for dignity of life, kindness and compassion, the latter expressed as "trembling for the welfare of others". A positive behavior that goes together with this precept is protecting living beings. Positive virtues like sympathy and respect for other living beings in this regard are based on a belief in the cycle of rebirththat all living beings must be born and reborn. The concept of the fundamental Buddha nature of all human beings also underlies the first precept.

The description of the first precept can be interpreted as a prohibition of capital punishment. Suicide is also seen as part of the prohibition. Moreover, abortion (of a sentient being) goes against the precept, since in an act of abortion, the criteria for violation are all met. In Buddhism, human life is understood to start at conception. A prohibition of abortion is mentioned explicitly in the monastic precepts, and several Buddhist tales warn of the harmful karmic consequences of abortion. Bioethicist Damien Keown argues that Early Buddhist Texts do not allow for exceptions with regard to abortion, as they consist of a "consistent' (i.e. exceptionless) pro-life position". Keown further proposes that a middle way approach to the five precepts is logically hard to defend. Asian studies scholar Giulo Agostini argues, however, that Buddhist commentators in India from the 4th century onward thought abortion did not break the precepts under certain circumstances.

Ordering another person to kill is also included in this precept, therefore requesting or administering euthanasia can be considered a violation of the precept, as well as advising another person to commit abortion. With regard to euthanasia and assisted suicide, Keown quotes the Pāli "Dīgha Nikāya" that says a person upholding the first precept "does not kill a living being, does not cause a living being to be killed, does not approve of the killing of a living being". Keown argues that in Buddhist ethics, regardless of motives, death can never be the aim of one's actions.

Interpretations of how Buddhist texts regard warfare are varied, but in general Buddhist doctrine is considered to oppose all warfare. In many "Jātaka" tales, such as that of Prince Temiya, as well as some historical documents, the virtue of non-violence is taken as an opposition to all war, both offensive and defensive. At the same time, though, the Buddha is often shown not to explicitly oppose war in his conversations with political figures. Buddhologist André Bareau points out that the Buddha was reserved in his involvement of the details of administrative policy, and concentrated on the moral and spiritual development of his disciples instead. He may have believed such involvement to be futile, or detrimental to Buddhism. Nevertheless, at least one disciple of the Buddha is mentioned in the texts who refrained from retaliating his enemies because of the Buddha, that is King Pasenadi (). The texts are ambiguous in explaining his motives though. In some later Mahāyāna texts, such as in the writings of Asaṅga, examples are mentioned of people who kill those who persecute Buddhists. In these examples, killing is justified by the authors because protecting Buddhism was seen as more important than keeping the precepts. Another example that is often cited is that of King Duṭṭhagāmaṇī, who is mentioned in the post-canonical Pāli Mahāvaṃsa chronicle. In the chronicle, the king is saddened with the loss of life after a war, but comforted by a Buddhist monk, who states that nearly everyone who was killed did not uphold the precepts anyway. Buddhist studies scholar Lambert Schmithausen argues that in many of these cases Buddhist teachings like that of emptiness were misused to further an agenda of war or other violence.

Field studies in Cambodia and Burma have shown that many Buddhists considered the first precept the most important, or the most blamable. In some traditional communities, such as in Kandal Province in pre-war Cambodia, as well as Burma in the 1980s, it was uncommon for Buddhists to slaughter animals, to the extent that meat had to be bought from non-Buddhists. In his field studies in Thailand in the 1960s, Terwiel found that villagers did tend to kill insects, but were reluctant and self-conflicted with regard to killing larger animals. In Spiro's field studies, however, Burmese villagers were highly reluctant even to kill insects.

Early Buddhists did not adopt a vegetarian lifestyle. Indeed, in several Pāli texts vegetarianism is described as irrelevant in the spiritual purification of the mind. There are prohibitions on certain types of meat, however, especially those which are condemned by society. The idea of abstaining from killing animal life has also led to a prohibition on professions that involve trade in flesh or living beings, but not to a full prohibition of all agriculture that involves cattle. In modern times, referring to the law of supply and demand or other principles, some Theravādin Buddhists have attempted to promote vegetarianism as part of the five precepts. For example, the Thai Santi Asoke movement practices vegetarianism.

Furthermore, among some schools of Buddhism, there has been some debate with regard to a principle in the monastic discipline. This principle states that a Buddhist monk cannot accept meat if it comes from animals especially slaughtered for him. Some teachers have interpreted this to mean that when the recipient has no knowledge on whether the animal has been killed for him, he cannot accept the food either. Similarly, there has been debate as to whether laypeople should be vegetarian when adhering to the five precepts. Though vegetarianism among Theravādins is generally uncommon, it has been practiced much in East Asian countries, as some Mahāyāna texts, such as the "Mahāparanirvana Sūtra" and the "Laṅkāvatāra Sūtra", condemn the eating of meat. Nevertheless, even among Mahāyāna Buddhistsand East Asian Buddhiststhere is disagreement on whether vegetarianism should be practiced. In the "Laṅkāvatāra Sūtra", biological, social and hygienic reasons are given for a vegetarian diet; however, historically, a major factor in the development of a vegetarian lifestyle among Mahāyāna communities may have been that Mahāyāna monastics cultivated their own crops for food, rather than living from alms. Already from the 4th century CE, Chinese writer Xi Chao understood the five precepts to include vegetarianism.
Apart from trade in flesh or living beings, there are also other professions considered undesirable. Vietnamese teacher Thich Nhat Hanh gives a list of examples, such as working in the arms industry, the military, police, producing or selling poison or drugs such as alcohol and tobacco.

In general, the first precept has been interpreted by Buddhists as a call for non-violence and pacifism. But there have been some exceptions of people who did not interpret the first precept as an opposition to war. For example, in the twentieth century, some Japanese Zen teachers wrote in support of violence in war, and some of them argued this should be seen as a means to uphold the first precept. There is some debate and controversy surrounding the problem whether a person can commit suicide, such as self-immolation, to reduce other people's suffering in the long run, such as in protest to improve a political situation in a country. Teachers like the Dalai Lama and Shengyan have rejected forms of protest like self-immolation, as well as other acts of self-harming or fasting as forms of protest.

Although capital punishment goes against the first precept, as of 2001, many countries in Asia still maintained the death penalty, including Sri Lanka, Thailand, China and Taiwan. In some Buddhist countries, such as Sri Lanka and Thailand, capital punishment was applied during some periods, while during other periods no capital punishment was used at all. In other countries with Buddhism, like China and Taiwan, Buddhism, or any religion for that matter, has had no influence in policy decisions of the government. Countries with Buddhism that have abolished capital punishment include Cambodia and Hong Kong.

In general, Buddhist traditions oppose abortion. In many countries with Buddhist traditions such as Thailand, Taiwan, Korea and Japan, however, abortion is a widespread practice, whether legal or not. Many people in these countries consider abortion immoral, but also think it should be less prohibited. Ethicist Roy W. Perrett, following Ratanakul, argues that this field research data does not so much indicate hypocrisy, but rather points at a "middle way" in applying Buddhist doctrine to solve a moral dilemma. Buddhists tend to take "both sides" on the pro-lifepro-choice debate, being against the taking of life of a fetus in principle, but also believing in compassion toward mothers. Similar attitudes may explain the Japanese "mizuko kuyō" ceremony, a Buddhist memorial service for aborted children, which has led to a debate in Japanese society concerning abortion, and finally brought the Japanese to a consensus that abortion should not be taken lightly, though it should be legalized. This position, held by Japanese Buddhists, takes the middle ground between the Japanese neo-Shinto "pro-life" position, and the liberationist, "pro-choice" arguments. Keown points out, however, that this compromise does not mean a Buddhist middle way between two extremes, but rather incorporates two opposite perspectives. In Thailand, women who wish to have abortion usually do so in the early stages of pregnancy, because they believe the karmic consequences are less then. Having had abortion, Thai women usually make merits to compensate for the negative karma.

The second precept prohibits theft, and involves the intention to steal what one perceives as not belonging to oneself ("what is not given") and acting successfully upon that intention. The severity of the act of theft is judged by the worth of the owner and the worth of that which is stolen. Underhand dealings, fraud, cheating and forgery are also included in this precept. Accompanying virtues are generosity, renunciation, and right livelihood, and a positive behavior is the protection of other people's property.

The second precept includes different ways of stealing and fraud. Borrowing without permission is sometimes included, as well as gambling. Psychologist Vanchai Ariyabuddhiphongs did studies in the 2000s and 2010s in Thailand and discovered that people who did not adhere to the five precepts more often tended to believe that money was the most important goal in life, and would more often pay bribes than people who did adhere to the precepts. On the other hand, people who observed the five precepts regarded themselves as wealthier and happier than people who did not observe the precepts.

Professions that are seen to violate the second precept include working in the gambling industry or marketing products that are not actually required for the customer.

The third precept condemns sexual misconduct. This has been interpreted in classical texts to include adultery with a married or engaged person, rape, incest, sex with a minor (or a person "protected by any relative"), and sex with a prostitute. In later texts, details such as intercourse at an inappropriate time or inappropriate place are also counted as breaches of the third precept. Masturbation goes against the spirit of the precept, though in the early texts it is not prohibited for laypeople.

The third precept is explained as leading to greed in oneself and harm to others. The transgression is regarded as more severe if the other person is a good person. Virtues that go hand-in-hand with the third precept are contentment, especially with one's partner, and recognition and respect for faithfulness in a marriage.

The third precept is interpreted as avoiding harm to another by using sensuality in the wrong way. This means not engaging with inappropriate partners, but also respecting one's personal commitment to a relationship. In some traditions, the precept also condemns adultery with a person whose spouse agrees with the act, since the nature of the act itself is condemned. Furthermore, flirting with a married person may also be regarded as a violation. Though prostitution is discouraged in the third precept, it is usually not actively prohibited by Buddhist teachers. With regard to applications of the principles of the third precept, the precept, or any Buddhist principle for that matter, is usually not connected with a stance against contraception. In traditional Buddhist societies such as Sri Lanka, pre-marital sex is considered to violate the precept, though this is not always adhered to by people who already intend to marry.

In the interpretation of modern teachers, the precept includes any person in a sexual relationship with another person, as they define the precept by terms such as "sexual responsibility" and "long-term commitment". Some modern teachers include masturbation as a violation of the precept, others include certain professions, such as those that involve sexual exploitation, prostitution or pornography, and professions that promote unhealthy sexual behavior, such as in the entertainment industry.

The fourth precept involves falsehood spoken or committed to by action. Avoiding other forms of wrong speech are also considered part of this precept, consisting of malicious speech, harsh speech and gossip. A breach of the precept is considered more serious if the falsehood is motivated by an ulterior motive (rather than, for example, "a small white lie"). The accompanying virtue is being honest and dependable, and involves honesty in work, truthfulness to others, loyalty to superiors and gratitude to benefactors. In Buddhist texts, this precept is considered second in importance to the first precept, because a lying person is regarded to have no shame, and therefore capable of many wrongs. Untruthfulness is not only to be avoided because it harms others, but also because it goes against the Buddhist ideal of finding the truth.

The fourth precept includes avoidance of lying and harmful speech. Some modern teachers such as Thich Nhat Hanh interpret this to include avoiding spreading false news and uncertain information. Work that involves data manipulation, false advertising or online scams can also be regarded as violations. Terwiel reports that among Thai Buddhists, the fourth precept is also seen to be broken when people insinuate, exaggerate or speak abusively or deceitfully.

The fifth precept prohibits intoxication through alcohol, drugs or other means, and its virtues are mindfulness and responsibility, applied to food, work, behavior, and with regard to the nature of life. Awareness, meditation and heedfulness can also be included here. Medieval Pāli commentator Buddhaghosa writes that whereas violating the first four precepts may be more or less blamable depending on the person or animal affected, the fifth precept is always "greatly blamable", as it hinders one from understanding the Buddha's teaching and may lead one to "madness". In ancient China, Daoshi described alcohol as the "doorway to laxity and idleness" and as a cause of suffering. Nevertheless, he did describe certain cases when drinking was considered less of a problem, such as in the case of a queen distracting the king by alcohol to prevent him from murder. However, Daoshi was generally strict in his interpretations: for example, he allowed medicinal use of alcohol only in extreme cases. Early Chinese translations of the Tripitaka describe negative consequences for people breaking the fifth precept, for themselves and their families. The Chinese translation of the "Upāsikaśila Sūtra", as well as the Pāli version of the Sigālovāda Sutta, speak of ill consequences such as loss of wealth, ill health, a bad reputation and "stupidity", concluding in a rebirth in hell. The "Dīrghāgama" adds to that that alcohol leads to quarreling, negative states of mind and damage to one's intelligence. The Mahāyāna "Brahmajāla Sūtra" describes the dangers of alcohol in very strong terms, including the selling of alcohol. Similar arguments against alcohol can be found in Nāgārjuna's writings. The strict interpretation of prohibition of alcohol consumption can be supported by the "Upāli Sūtra"<nowiki>'</nowiki>s statement that a disciple of the Buddha should not drink any alcohol, "even a drop on the point of a blade of grass". However, in the writing of some Abhidharma commentators, consumption was condemned or condoned, depending on the intention with which alcohol was consumed.

The fifth precept is regarded as important, because drinking alcohol is condemned for the sluggishness and lack of self-control it leads to, which might lead to breaking the other precepts. In Spiro's field studies, violating the fifth precept was seen as the worst of all the five precepts by half of the monks interviewed, citing the harmful consequences. Nevertheless, in practice it is often disregarded by lay people. In Thailand, drinking alcohol is fairly common, even drunkenness. Among Tibetans, drinking beer is common, though this is only slightly alcoholic. Medicinal use of alcohol is generally not frowned upon, and in some countries like Thailand and Laos, smoking is usually not regarded as a violation of the precept. Thai and Laotian monks have been known to smoke, though monks who have received more training are less likely to smoke. On a similar note, as of 2000, no Buddhist country prohibited the sale or consumption of alcohol, though in Sri Lanka Buddhist revivalists unsuccessfully attempted to get a full prohibition passed in 1956. Moreover, pre-Communist Tibet used to prohibit smoking in some areas of the capital. Monks were prohibited from smoking, and the import of tobacco was banned.

Thich Nhat Hanh also includes mindful consumption in this precept, which consists of unhealthy food, unhealthy entertainment and unhealthy conversations, among others.

In modern times, adherence to the precepts among Buddhists is less strict than it traditionally was. This is especially true for the third precept. For example, in Cambodia in the 1990s and 2000s, standards with regard to sexual restraint were greatly relaxed. Some Buddhist movements and communities have tried to go against the modern trend of less strict adherence to the precepts. In Cambodia, a millenarian movement led by Chan Yipon promoted the revival of the five precepts. And in the 2010s, the Supreme Sangha Council in Thailand ran a nationwide program called "The Villages Practicing the Five Precepts", aiming to encourage keeping the precepts, with an extensive classification and reward system.

In many Western Buddhist organizations, the five precepts play a major role in developing ethical guidelines. Furthermore, Buddhist teachers such as Philip Kapleau, Thich Nhat Hanh and Robert Aitken have promoted mindful consumption in the West, based on the five precepts. In another development in the West, some scholars working in the field of mindfulness training have proposed that the five precepts be introduced as a component in such trainings. Specifically, to prevent organizations from using mindfulness training to further an economical agenda with harmful results to its employees, the economy or the environment, the precepts could be used as a standardized ethical framework. As of 2015, several training programs made explicit use of the five precepts as secular, ethical guidelines. However, many mindfulness training specialists consider it problematic to teach the five precepts as part of training programs in secular contexts because of their religious origins and import.

Peace studies scholar Theresa Der-lan Yeh notes that the five precepts address physical, economical, familial and verbal aspects of interaction, and remarks that many conflict prevention programs in schools and communities have integrated the five precepts in their curriculum. On a similar note, peace studies founder Johan Galtung describes the five precepts as the "basic contribution of Buddhism in the creation of peace".

Studying lay and monastic ethical practice in traditional Buddhist societies, Spiro argued ethical guidelines such as the five precepts are adhered to as a means to a higher end, that is, a better rebirth or enlightenment. He therefore concluded that Buddhist ethical principles like the five precepts are similar to Western utilitarianism. Keown, however, has argued that the five precepts are regarded as rules that cannot be violated, and therefore may indicate a deontological perspective in Buddhist ethics. On the other hand, Keown has also suggested that Aristotle's virtue ethics could apply to Buddhist ethics, since the precepts are considered good in themselves, and mutually dependent on other aspects of the Buddhist path of practice. Philosopher Christopher Gowans disagrees that Buddhist ethics are deontological, arguing that virtue and consequences are also important in Buddhist ethics. Gowans argues that there is no moral theory in Buddhist ethics that covers all conceivable situations such as when two precepts may be in conflict, but is rather characterized by "a commitment to and nontheoretical grasp of the basic Buddhist moral values". As of 2017, many scholars of Buddhism no longer think it is useful to try to fit Buddhist ethics into a Western philosophical category.

Keown has argued that the five precepts are very similar to human rights, with regard to subject matter and with regard to their universal nature. Other scholars, as well as Buddhist writers and human rights advocates, have drawn similar comparisons. For example, the following comparisons are drawn:

Keown describes the relationship between Buddhist precepts and human rights as "look[ing] both ways along the juridical relationship, both to what one is due to do, and to what is due to one". On a similar note, Cambodian human rights advocates have argued that for human rights to be fully implemented in society, the strengthening of individual morality must also be addressed. Buddhist monk and scholar Phra Payutto sees the Human Rights Declaration as an unfolding and detailing of the principles that are found in the five precepts, in which a sense of ownership is given to the individual, to make legitimate claims on one's rights. He believes that human rights should be seen as a part of human development, in which one develops from moral discipline (), to concentration () and finally wisdom (). He does not believe, however, that human rights are natural rights, but rather human conventions. Buddhism scholar Somparn Promta disagrees with him. He argues that human beings do have natural rights from a Buddhist perspective, and refers to the "attūpanāyika-dhamma", a teaching in which the Buddha prescribes a kind of golden rule of comparing oneself with others. ("See §Principles, above.") From this discourse, Promta concludes that the Buddha has laid down the five precepts in order to protect individual rights such as right of life and property: human rights are implicit within the five precepts. Academic Buntham Phunsap argues, however, that though human rights are useful in culturally pluralistic societies, they are in fact not required when society is entirely based on the five precepts. Phunsap therefore does not see human rights as part of Buddhist doctrine.




</doc>
<doc id="24782" url="https://en.wikipedia.org/wiki?curid=24782" title="Pente">
Pente

Pente is a strategy board game for two or more players, created in 1977 by Gary Gabrel, a dishwasher at Hideaway Pizza, in Stillwater, Oklahoma. Customers played Pente at Hideaway Pizza on checkerboard tablecloths while waiting for their orders to arrive. Thirty years later, patrons are still playing Pente at Hideaway Pizza, although now with roll-up Pente boards. Pente is based on the Japanese game ninuki-renju, a variant of renju or gomoku that is played on a Go board of 19x19 intersections with white and black stones. Like "ninuki-renju," Pente allows captures, but Pente added a new opening rule. In the nineteenth century, "gomoku" was introduced to Britain where it was known as "Go Bang" (this term is borrowed from Japanese "goban" 碁盤 meaning "go board").

Pente is a registered trademark of Hasbro for strategy game equipment. Pente (πέντε) is the number five in Greek.

Hasbro ceased distribution of Pente in 1993. It later licensed the name to Winning Moves, a classic games publisher that resurrected the game in 2004. The 2004 version includes 4 extra stones, called power stones, that can be played in the Pente Plus version.

The players alternate in placing stones of their color on free intersections, with White always assuming the opening move. The players aim to align five stones of the same color in vertical, horizontal or diagonal lines. Captures are obtained by flanking pairs of an opponent's stones in any same direction. Captures must consist of exactly two stones; flanking a single stone or three stones does not result in a capture. For example, if the stones are X O O _ and you place your stone so it becomes X O O X, then your opponent's stones are removed from the board, leaving X _ _ X. A stone may legally be placed on any empty intersection, even if it forms a pair between two enemy stones. For example, if the stones are X O _ X you may place your stone so it becomes X O O X. Your stones are NOT captured in this case. When playing with multiple players the inside stones can be different colors, but the two stones on the outside must be the same colors. 

A player wins by scoring five stones in a row. It can be horizontal, vertical, or diagonal. A player can also win by capturing five pairs of opponent stones. Pente can also be played by four people, with pairs of two acting as partners. It can also be played with multiple independent players when each player has their own different colored stones. 

In this common variation, the first player's second move is restricted — it must be at least three intersections away from the center of the board. The tournament rule was created by Tom Braunlich to reduce the advantage held by the first player.



</doc>
<doc id="24783" url="https://en.wikipedia.org/wiki?curid=24783" title="Pompatus">
Pompatus

Pompatus (or Pompitus) () is a nonce word coined by Steve Miller famously in his 1973 hit single "The Joker". The word is probably a corruption or imagined version of the word "puppetuse", an original coinage of the 14-year-old Vernon Green, and subsequently released in 1954 as the doo-wop song "The Letter" performed by him and The Medallions -- a song which also included another original coinage, "pismotality." In other songs, "Enter Maurice" and "The Conversation," Miller adds the word "epismetology" to "pompatus," one in spoken word, the style of "The Letter," in a likely homage to The Medallions' song. The oddness of the word "pompatus" occasioned some attention and further use, including being used in the title of a movie.

The lyrics of "The Joker" include the quatrain:

Each line references a track on a previous Miller album: "Space Cowboy" on "Brave New World" (1969); "Gangster of Love" on "Sailor" (1968); and "Enter Maurice" on "Recall the Beginning...A Journey from Eden" (1972), which includes the lines:

Although Miller claims he invented the words "epismetology" (a metathesis of the word epistemology) and "pompatus", both are variants of words which Miller most likely heard in a song by Vernon Green called "The Letter," which was recorded by the Los Angeles doo-wop group The Medallions in 1954.

Green's "The Letter" as performed by the Medallions had the lines:

Green describes the lyrics as a description of his dream woman. ""Pizmotality" described words of such secrecy that they could only be spoken to the one you loved", Green explained. He coined the term "puppetutes" "to mean a secret paper-doll fantasy figure who would be my everything and bear my children".

Because of its peculiarity, the word "pompatus" has secured a niche in 20th century pop culture. Wolfman Jack frequently referenced the phrase and there is a sound clip of him using the line within the song "Clap for the Wolfman" by The Guess Who. "The Pompatus of Love", a 1996 film starring Jon Cryer, featured four men discussing a number of assorted themes, including attempts to determine the meaning of the phrase. Jon Cryer was also a writer of the film, and describes finding out the meaning of the phrase during a phone call with Vernon Green in his autobiography "So That Happened" in chapter 22, page 217. The line has been mentioned in various television show gags, including "The Simpsons" and "South Park".

Humor columnist Dave Barry frequently refers to the song line as a source of comedic value, particularly in his 1997 book "Dave Barry's Book of Bad Songs". 'Pompatus' is used by Michael Ondaatje in his 2001 book "Anil's Ghost". Stephen King uses the word in his 2006 novel "Lisey's Story". Tim Dorsey uses the word in his 2010 novel, "Gator a-Go-Go". It was the subject of the October 9, 2011 "Over the Hedge" comic strip.



</doc>
<doc id="24787" url="https://en.wikipedia.org/wiki?curid=24787" title="UGM-27 Polaris">
UGM-27 Polaris

The UGM-27 Polaris missile was a two-stage solid-fueled nuclear-armed submarine-launched ballistic missile. As the United States Navy's first SLBM, it served from 1961 to 1996.

In the mid-1950s the Navy was involved in the Jupiter missile project with the U.S. Army, and had influenced the design by making it squat so it would fit in submarines. However, they had concerns about the use of liquid fuel rockets onboard ships, and some consideration was given to a solid fuel version, Jupiter S. In 1956, during an anti-submarine study known as Project Nobska, Edward Teller suggested that very small hydrogen bomb warheads were possible. A crash program to develop a missile suitable for carrying such warheads began as Polaris, launching its first shot less than four years later, in February 1960.

As the Polaris missile was fired underwater from a moving platform, it was essentially invulnerable to counterattack. This led the Navy to suggest, starting around 1959, that they be given the entire nuclear deterrent role. This led to new infighting between the Navy and the U.S. Air Force, the latter responding by developing the counterforce concept that argued for the strategic bomber and ICBM as key elements in flexible response. Polaris formed the backbone of the U.S. Navy's nuclear force aboard a number of custom-designed submarines. In 1963, the Polaris Sales Agreement led to the Royal Navy taking over the United Kingdom's nuclear role, and while some tests were carried out by the Italian Navy, this did not lead to use.

The Polaris missile was gradually replaced on 31 of the 41 original SSBNs in the U.S. Navy by the MIRV-capable Poseidon missile beginning in 1972. During the 1980s, these missiles were replaced on 12 of these submarines by the Trident I missile. The 10 - and SSBNs retained Polaris A-3 until 1980 because their missile tubes were not large enough to accommodate Poseidon. With beginning sea trials in 1980, these submarines were disarmed and redesignated as attack submarines to avoid exceeding the SALT II strategic arms treaty limits.

The Polaris missile program's complexity led to the development of new project management techniques, including the Program Evaluation and Review Technique (PERT) to replace the simpler Gantt chart methodology.

The Polaris missile replaced an earlier plan to create a submarine-based missile force based on a derivative of the U.S. Army Jupiter Intermediate-range ballistic missile. Chief of Naval Operations Admiral Arleigh Burke appointed Rear Admiral W. F. "Red" Raborn as head of a Special Project Office to develop Jupiter for the Navy in late 1955. The Jupiter missile's large diameter was a product of the need to keep the length short enough to fit in a reasonably-sized submarine. At the seminal Project Nobska conference in 1956, with Admiral Burke present, nuclear physicist Edward Teller stated that a physically small one-megaton warhead could be produced for Polaris within a few years, and this prompted Burke to leave the Jupiter program and concentrate on Polaris in December of that year. Polaris was spearheaded by the Special Project Office's Missile Branch under Rear Admiral Roderick Osgood Middleton, and is still under the Special Project Office. Admiral Burke later was instrumental in determining the size of the Polaris submarine force, suggesting that 40-45 submarines with 16 missiles each would be sufficient. Eventually, the number of Polaris submarines was fixed at 41.

The was the first submarine capable of deploying U.S. developed submarine-launched ballistic missiles (SLBM). The responsibility of the development of SLBMs was given to the Navy and the Army. The Air Force was charged with developing a land-based intermediate range ballistic missile (IRBM), while an IRBM which could be launched by land or by sea was tasked to the Navy and Army. The Navy Special Projects (SP) office was at the head of the project. It was led by Rear Admiral William Raborn.

On September 13, 1955, James R. Killian, head of a special committee organized by President Eisenhower, recommended that both the Army and Navy come together under a program aimed at developing an intermediate-range ballistic missile (IRBM). The missile, later known as Jupiter, would be developed under the Joint Army-Navy Ballistic Missile Committee approved by Secretary of Defense Charles E. Wilson in early November of that year. The first IRBM boasted a liquid-fueled design. Liquid fuel is compatible with aircraft; it is less compatible with submarines. Solid fuels, on the other hand, make logistics and storage simpler and are safer. Not only was the Jupiter a liquid fuel design, it was also very large; even after it was designed for solid fuel, it was still a whopping 160,000 pounds. A smaller, new design would weigh much less, estimated at 30,000 pounds. The Navy would rather develop a smaller, more easily manipulated design. Edward Teller was one of the scientists encouraging the progress of smaller rockets. He argued that the technology needed to be discovered, rather than apply technology that is already created. Raborn was also convinced he could develop smaller rockets. He sent officers to make independent estimates of size to determine the plausibility of a small missile; while none of the officers could agree on a size, their findings were encouraging nonetheless.

The U.S. Navy began work on nuclear-powered submarines in 1946. They launched the first one, the in 1955. Nuclear powered submarines were the least vulnerable to a first strike from the Soviet Union.The next question that led to further development was what kind of arms the nuclear-powered submarines should be equipped with. In the summer of 1956, the navy sponsored a study by the National Academy of Sciences on anti-submarine warfare at Nobska Point in Woods Hole, Massachusetts, known as Project NOBSKA. The navy's intention was to have a new missile developed that would be lighter than existing missiles and cover a range up to fifteen hundred miles. A problem that needed to be solved was that this design would not be able to carry the desired one-megaton thermonuclear warhead.

This study brought Edward Teller from the recently formed nuclear weapons laboratory at Livermore and J. Carson Mark, representing the Los Alamos nuclear weapons laboratory. Teller was already known as a nuclear salesman, but this became the first instance where there was a big betting battle where he outbid his Los Alamos counterpart. The two knew each other well: Mark was named head of the theoretical division of Los Alamos in 1947, a job that was originally offered for Teller. Mark was a cautious physicist and no match for Teller in a bidding war.

At the NOBSKA summer study, Edward Teller made his famous contribution to the FBM program. Teller offered to develop a lightweight warhead of one-megaton strength within five years. He suggested that nuclear-armed torpedoes could be substituted for conventional ones to provide a new anti-submarine weapon. Livermore received the project. When Teller returned to Livermore, people were astonished by the boldness of Teller's promise. It seemed inconceivable with the current size of nuclear warheads, and Teller was challenged to support his assertion. He pointed out the trend in warhead technology, which indicated reduced weight to yield ratios in each succeeding generation. When Teller was questioned about the application of this to the FBM program, he asked, ‘Why use a 1958 warhead in a 1965 weapon system?’

Mark disagreed with Teller's prediction that the desired one-megaton warhead could be made to fit the missile envelope within the timescale envisioned. Instead, Mark suggested that half a megaton would be more realistic and he quoted a higher price and a longer deadline. This simply confirmed the validity of Teller's prediction in the Navy's eyes. Whether the warhead was half or one megaton mattered little so long as it fitted the missile and would be ready by the deadline. Almost four decades later, Teller said, referring to Mark's performance, that it was “an occasion when I was happy about the other person being bashful.”
When the Atomic Energy Commission backed up Teller's estimate in early September, Admiral Burke and the Navy Secretariat decided to support SPO in heavily pushing for the new missile, now named Polaris by Admiral Raborn.

There is a contention that the Navy's "Jupiter" missile program was unrelated to the Army program. The Navy also expressed an interest in Jupiter as an SLBM, but left the collaboration to work on their Polaris. At first, the newly assembled SPO team had the problem of making the large, liquid-fuel Jupiter IRBM to work properly. Jupiter retained the short, squat shape intended to fit in naval submarines. Its sheer size and volatility of its fuel made it very unsuited to submarine launching and was only slightly more attractive for deployment on ships. The missile continued to be developed by the Army's German team in collaboration with their main contractor, Chrysler Corporation. SPO's responsibility was to develop a sea-launching platform with necessary fire control and stabilization systems for that very purpose. The original schedule was to have a ship-based IRBM system ready for operation evaluation by January 1, 1960, and a submarine-based one by January 1, 1965.
However, the Navy was deeply dissatisfied with the liquid fuel IRBM. The first concern was that the cryogenic liquid fuel was not only extremely dangerous to handle, but launch-preparations were also very time-consuming. Second, an argument was made that liquid-fueled rockets gave relatively low initial acceleration, which is disadvantageous in launching a missile from a moving platform in certain sea states. By mid-July 1956, the Secretary of Defense's Scientific Advisory Committee had recommended that a solid-propellant missile program be fully instigated but not using the unsuitable Jupiter payload and guidance system.
By October 1956, a study group comprising key figures from Navy, industry and academic organizations considered various design parameters of the Polaris system and trade-offs between different sub-sections. The estimate that a 30,000-pound missile could deliver a suitable warhead over 1500 nautical miles was endorsed. With this optimistic assessment, the Navy now decided to scrap the Jupiter program altogether and sought out the Department of Defense to back a separate Navy missile.
A huge surfaced submarine would carry four "Jupiter" missiles, which would be carried and launched horizontally. This was probably the never-built SSM-N-2 Triton program. However, a history of the Army's Jupiter program states that the Navy was involved in the Army program, but withdrew at an early stage.

Originally, the Navy favored cruise missile systems in a strategic role, such as the Regulus missile deployed on the earlier and a few other submarines, but a major drawback of these early cruise missile launch systems (and the Jupiter proposals) was the need to surface, and remain surfaced for some time, to launch. Submarines were very vulnerable to attack during launch, and a fully or partially fueled missile on deck was a serious hazard. The difficulty of preparing a launch in rough weather was another major drawback for these designs, but rough sea conditions did not unduly affect Polaris' submerged launches.

It quickly became apparent that solid-fueled ballistic missiles had advantages over cruise missiles in range and accuracy, and could be launched from a submerged submarine, improving submarine survivability.

The prime contractor for all three versions of Polaris was Lockheed Missiles and Space Company (now Lockheed Martin).

The Polaris program started development in 1956. , the first U.S. missile submarine, successfully launched the first Polaris missile from a submerged submarine on July 20, 1960. The A-2 version of the Polaris missile was essentially an upgraded A-1, and it entered service in late 1961. It was fitted on a total of 13 submarines and served until June 1974.(1). Ongoing problems with the W-47 warhead, especially with its mechanical arming and safing equipment, led to large numbers of the missiles being recalled for modifications, and the U.S. Navy sought a replacement with either a larger yield or equivalent destructive power. The result was the W-58 warhead used in a "cluster" of three warheads for the Polaris A-3, the final model of the Polaris missile.

One of the initial problems the Navy faced in creating an SLBM was that the sea moves, while a launch platform on land does not. Waves and swells rocking the boat or submarine, as well as possible flexing of the ship's hull, had to be taken into account to properly aim the missile.

The Polaris development was kept on a tight schedule and the only influence that changed this was the USSR's launching of SPUTNIK on October 4, 1957. This caused many working on the project to want to accelerate development. The launch of a second Russian satellite and pressing public and government opinions caused Secretary Wilson to move the project along more quickly.

The Navy favored an underwater launch of an IRBM, although the project began with an above-water launch goal. They decided to continue the development of an underwater launch, and developed two ideas for this launch: wet and dry. Dry launch meant encasing the missile in a shell that would peel away when the missile reached the water's surface. Wet launch meant shooting the missile through the water without a casing. While they Navy was in favor of a wet launch, they developed both methods as a failsafe. They did this with the development of gas and air propulsion of the missile out of the submerged tube as well.

The first Polaris missile tests were given the names “AX-#” and later renamed “A1X-#”. Testing of the missiles occurred:

Sept 24, 1958: AX-1, at Cape Canaveral from a launch pad; the missile was destroyed, after it failed to turn into the correct trajectory following a programming-error.

October 1958: AX-2, at Cape Canaveral from a launch pad; exploded on the launch pad.

December 30, 1958: AX-3, at Cape Canaveral from a launch pad; launched correctly, but was destroyed because of the fuel overheating.

January 19, 1959: AX-4, at Cape Canaveral from launch pad: launched correctly but began to behave erratically and was destroyed.

February 27, 1959: AX-5, at Cape Canaveral from launch pad: launched correctly but began to behave erratically and was destroyed.

April 20, 1959: AX-6, at Cape Canaveral from launch pad: this test was a success. The missile launched, separated, and splashed into the Atlantic 300 miles off shore.

It was in between these two tests that the inertial guidance system was developed and implemented for testing.

July 1, 1959: AX-11 at Cape Canaveral from a launch pad: this launch was successful, but pieces of the missile detached causing failure. It did show that the new guidance systems worked.

At the time that the Polaris project went live, submarine navigation systems were and at this time that standard was sufficient enough to sustain effective military efforts given the existing weapons systems in use by the Army, Air Force and Navy. Initially, developers of Polaris were set to utilize the existing 'Stable Platform' configuration of the inertial guidance system. Created at the MIT Instrumentation Laboratory, this Ships Inertial Navigation System (SINS) was supplied to the Navy in 1954. The developers of Polaris encountered many issues from the birth of the project, however, perhaps the most unsettling for them was the outdated technology of the gyroscopes they would be implementing.

This 'Stable Platform' configuration did not account for the change in gravitational fields that the submarine would experience while it was in motion, nor did it account for the ever-altering position of the Earth. This problem raised many concerns, as this would make it nearly impossible for navigational read outs to remain accurate and reliable. A submarine equipped with Ballistic Missiles was of little to no use if operators had no way to direct them. Polaris was thus forced to seek elsewhere and quickly found hope in a guidance system that had been abandoned by the U.S. Air Force. The Autonetics Division of North American Aviation had previously been faced with the task of developing a guidance system for the U.S. Air Force Navaho known as the XN6 Autonavigator. The XN6 was a system designed for air-breathing Cruise missiles, but by 1958 had proved useful for installment on submarines.

A predecessor to the GPS satellite navigation system, the Transit system (later called NAVSAT), was developed because the submarines needed to know their position at launch in order for the missiles to hit their targets. Two American physicists, William Guier and George Weiffenbach, at Johns Hopkins's Applied Physics Laboratory (APL), began this work in 1958. A computer small enough to fit through a submarine hatch was developed in 1958, the AN/UYK-1. It was used to interpret the Transit satellite data and send guidance information to the Polaris, which had its own guidance computer made with ultra miniaturized electronics, very advanced for its time, because there wasn't much room in a Polaris—there were 16 on each submarine. The Ship's Inertial Navigation System (SINS) was developed earlier to provide a continuous dead reckoning update of the submarine's position between position fixes via other methods, such as LORAN. This was especially important in the first few years of Polaris, because Transit was not operational until 1964. By 1965 microchips similar to the Texas Instruments units made for the Minuteman II were being purchased by the Navy for the Polaris. The Minuteman guidance systems each required 2000 of these, so the Polaris guidance system may have used a similar number. To keep the price under control, the design was standardized and shared with Westinghouse Electric Company and RCA. In 1962, the price for each Minuteman chip was $50, the price dropped to $2 in 1968.

This missile replaced the earlier A-1 and A-2 models in the U.S. Navy, and also equipped the British Polaris force. The A-3 had a range extended to and a new weapon bay housing three Mk 2 re-entry vehicles (ReB or Re-Entry Body in U.S. Navy and British usage); and the new W-58 warhead of 200 kt yield. This arrangement was originally described as a "cluster warhead" but was replaced with the term Multiple Re-Entry Vehicle (MRV). The three warheads, also known as "bomblets", were spread out in a "shotgun" like pattern above a single target and were not independently targetable (such as a MIRV missile is). The three warheads were stated to be equivalent in destructive power to a single one-megaton warhead due to their spread out pattern on the target. The first Polaris submarine outfitted with MRV A-3's was the USS "Daniel Webster" in 1964. Later the Polaris A-3 missiles (but not the ReBs) were also given limited hardening to protect the missile electronics against nuclear electromagnetic pulse effects while in the boost phase. This was known as the A-3T ("Topsy") and was the final production model.

The initial test model of the Polaris was referred to as the AX series and made its maiden flight from Cape Canaveral on September 24, 1958. The missile failed to perform its pitch and roll maneuver and instead just flew straight up, however the flight was considered a partial success (at that time, "partial success" was used for any missile test that returned usable data). The next flight on October 15 failed spectacularly when the second stage ignited on the pad and took off by itself. Range Safety blew up the errant rocket while the first stage sat on the pad and burned. The third and fourth tests (December 30 and January 9) had problems due to overheating in the boattail section. This necessitated adding extra shielding and insulation to wiring and other components. When the final AX flight was conducted a year after the program began, 17 Polaris missiles had been flown of which five met all of their test objectives.

The first operational version, the Polaris A-1, had a range of and a single Mk 1 re-entry vehicle, carrying a single W-47-Y1 600 kt nuclear warhead, with an inertial guidance system which provided a circular error probable (CEP) of . The two-stage solid propellant missile had a length of , a body diameter of , and a launch weight of .

Work on its W47 nuclear warhead began in 1957 at the facility that is now called the Lawrence Livermore National Laboratory by a team headed by John Foster and Harold Brown. The Navy accepted delivery of the first 16 warheads in July 1960. On May 6, 1962, a Polaris A-2 missile with a live W47 warhead was tested in the "Frigate Bird" test of Operation Dominic by in the central Pacific Ocean, the only American test of a live strategic nuclear missile.

The two stages were both steered by thrust vectoring. Inertial navigation guided the missile to about a 900 m (3,000-foot) CEP, insufficient for use against hardened targets. They were mostly useful for attacking dispersed military surface targets (airfields or radar sites), clearing a pathway for heavy bombers, although in the general public perception Polaris was a strategic second-strike retaliatory weapon.

The Polaris A-1 missile was developed to complement the limited number of medium-range systems deployed throughout Europe. As those systems lacked the range to attack major Soviet targets, Polaris was developed to increase the level of nuclear deterrence. At this time there was little threat of counterforce strikes, as few systems had the accuracy to destroy missile systems. The primary advantages of ballistic missile submarines was their ability to launch submerged, which offered improved survivability for the submarine while also (like their Regulus predecessors) keeping shorter ranged systems within range.

The USN had forward-basing arrangements for its Atlantic-based Polaris fleet with both the United Kingdom and Spain, permitting the use of bases at the Holy Loch in Scotland (established in 1961) and at Naval Station Rota (Polaris base established 1964) in the Bay of Cadiz. The forward deployment bases were much closer to patrol areas than U.S. East Coast bases, avoiding the necessity for lengthy transit times. In the Pacific, a Polaris base was also established at Guam in 1964. The Regulus missile program was deactivated with the advent of Polaris in the Pacific. The forward-basing arrangement was continued when Poseidon replaced Polaris, starting in 1972, in what by then were the 31 Atlantic Fleet SSBNs. The 10 older SSBNs that could not use Poseidon were assigned to the Pacific Fleet in the 1970s. Polaris was not accurate enough to destroy hardened targets, but would have been effective against dispersed surface targets, such as airfields, radar and SAM sites, as well as military and industrial centers of strategic importance. The military authorities, however, regarded Polaris as but one part of a nuclear triad including ICBMs and bombers, each with its own function. The task allotted to Polaris of 'taking out' peripheral defenses was well-suited to its characteristics and limitations.

The forward deployment strategy required some infrastructure. To allow quick establishment of bases and to minimize the impact on the host country, each base was centered around a submarine tender and a floating drydock, with minimal facilities on shore, mostly family support for the tender's crew. The first Polaris submarine tender was , a World War II tender that was refitted in 1959–60 with the insertion of a midships missile storage compartment and handling crane. "Proteus" established each of the three forward deployment bases. Four additional Polaris tenders (, , , and ) were commissioned 1962–65.

A two-crew concept was established for SSBNs, combined with forward deployment to maximize the time each submarine would spend on patrol. The crews were named Blue and Gold after the U.S. Naval Academy colors. The crews were deployed for 105 days and at their home bases for 95 days, with a 3-day turnover period on each end of the deployed period. Crews were flown from their home bases to and from the forward deployment bases. After taking over the boat, the crew would perform a 30-day refit assisted by the tender, followed by a 70-day deterrent patrol. Sometimes a port visit would be arranged in the middle of the patrol. The home bases for Atlantic Fleet crews were Groton, Connecticut and Charleston, South Carolina. Pacific Fleet crews were based at Pearl Harbor, Hawaii.

Two Polaris missile depots were established in the United States, Polaris Missile Facility Atlantic (POMFLANT) at Charleston, South Carolina in 1960 and later Strategic Weapons Facility Pacific (SWFPAC) at Bangor, Washington. To transport missiles and other supplies from the missile depots to the forward deployment bases, several cargo ships were converted to carry missiles and were designated as T-AKs, operated by the Military Sealift Command with a mostly-civilian crew.

The advent of the Trident I missile, refitted to 12 Atlantic Fleet SSBNs starting in 1979 and with a much greater range than Polaris or Poseidon, meant that SSBNs could be based in the United States. The 18 s, slated to replace the 41 older SSBNs, also started commissioning in 1981, initially carrying 24 Trident I missiles but later refitted with the much larger and more capable Trident II missile. In the late 1970s it was decided that Pacific Fleet "Ohio"-class SSBNs would be based at Bangor, WA, collocated with SWFPAC, and that the refitted Trident I SSBNs and additional "Ohio"-class SSBNs would be based at a new facility in King's Bay, Georgia. Also, a new missile depot, Strategic Weapons Facility Atlantic (SWFLANT), was constructed at King's Bay to replace POMFLANT. The SSBN facility at Rota was closed in 1979 as King's Bay began refitting submarines. As commenced sea trials in 1980, the 10 remaining Polaris submarines in the Pacific Fleet were disarmed and reclassified as SSNs to avoid exceeding SALT II treaty limits. The SSBN base at Guam was closed at this time. By 1992, the Soviet Union had collapsed, 12 "Ohio"-class SSBNs had been commissioned, and the START I treaty had gone into effect, so Holy Loch was closed and the remaining 31 original SSBNs disarmed. Most of these were decommissioned and later scrapped in the Ship-Submarine Recycling Program, but a few were converted to other roles. Two remain in service but decommissioned as nuclear power training vessels attached to Naval Nuclear Power School at Charleston, SC, and .

To meet the need for greater accuracy over the longer ranges the Lockheed designers included a reentry vehicle concept, improved guidance, fire control, and navigation systems to achieve their goals. To obtain the major gains in performance of the Polaris A3 in comparison to early models, there were many improvements, including propellants and material used in the construction of the burn chambers. The later versions (the A-2, A-3, and B-3) were larger, weighed more, and had longer ranges than the A-1. The range increase was most important: The A-2 range was , the A-3 , and the B-3 . The A-3 featured multiple re-entry vehicles (MRVs) which spread the warheads about a common target, and the B-3 was to have penetration aids to counter Soviet Anti-Ballistic Missile defenses.

The U.S. Navy began to replace Polaris with Poseidon in 1972. The B-3 missile evolved into the C-3 Poseidon missile, which abandoned the decoy concept in favor of using the C3's greater throw-weight for larger numbers (10–14) of new hardened high-re-entry-speed reentry vehicles that could overwhelm Soviet defenses by sheer weight of numbers, and its high speed after re-entry. This turned out to be a less than reliable system and soon after both systems were replaced by the Trident. A proposed Undersea Long-Range Missile System (ULMS) program outlined a long-term plan which proposed the development of a longer-range missile designated as ULMS II, which was to achieve twice the range of the existing Poseidon (ULMS I) missile. In addition to a longer-range missile, a larger submarine (Ohio-class) was proposed to replace the submarines currently being used with Poseidon. The ULMS II missile system was designed to be retrofitted to the existing SSBNs, while also being fitted to the proposed Ohio-class submarine.

In May 1972, the term ULMS II was replaced with Trident. The Trident was to be a larger, higher-performance missile with a range capacity greater than 6000 miles. Under the agreement, the United Kingdom paid an additional 5% of their total procurement cost of 2.5 billion dollars to the U.S. government as a research and development contribution.
In 2002, the United States Navy announced plans to extend the life of the submarines and the D5 missiles to the year 2040. This requires a D5 Life Extension Program (D5LEP), which is currently underway. The main aim is to replace obsolete components at minimal cost by using commercial off the shelf (COTS) hardware; all the while maintaining the demonstrated performance of the existing Trident II missiles.

STARS, a strategic targeting system, is a BMDO program managed by the U. S. Army Space and Strategic Defense Command (SSDC). It began in 1985 in response to concerns that the supply of surplus Minuteman I boosters used to launch targets and other experiments on intercontinental ballistic missile flight trajectories in support of the Strategic Defense Initiative would be depleted by 1988. SSDC tasked Sandia National Laboratories, a Department of Energy laboratory, to develop an alternative launch vehicle using surplus Polaris boosters. The Sandia National Laboratories developed two STARS booster configurations: STARS I and STARS II.

STARS I consisted of refurbished Polaris first and second stages and a
commercially procured Orbis I third stage. It can deploy single or multiple payloads, but the multiple payloads cannot be deployed in a manner that simulates the operation of a post-boost vehicle. To meet this specific need, Sandia developed an Operations and Deployment
Experiments Simulator (ODES), which functions as a PBV. When ODES was added to STARS I, the configuration is became known as STARS II. The development phase of the STARS program was completed in 1994, and BMDO provided about $192.1 million for this effort. The operational phase began in 1995. The first STARS I flight, a hardware check-out flight, was launched in February 1993, and the second flight, a STARS I reentry vehicle experiment, was launched in August 1993.

The third flight, a STARS II development mission, was launched in July 1994, with all three flights considered to be successful by BMDO. The Secretary of Defense conducted a comprehensive review in 1993 of the nation's defense strategy, which drastically reduced the number of STARS launches required to support National Missile Defense (NMD)2 and BMDO funding. Due to the launch and budget reductions, the STARS office developed a draft long-range plan for the STARS program. The study examined three options:
When the STARS program was started in 1985 it was perceived that there would be four launches per year. Because of the large number of anticipated launches and an unknown defect rate for surplus Polaris motors, the STARS office acquired 117 first-stage and 102 second-stage surplus motors. As of December 1994, seven first-stage and five second-stage refurbished motors were available for future launches. BMDO is currently evaluating STARS as a potential long-range system for launching targets for development tests of future Theater Missile Defense 3 systems. STARS I was first launched in 1993, and from 2004 onwards has served as the standard booster for trials of the Ground-Based Interceptor.

From the early days of the Polaris program, American senators and naval officers suggested that the United Kingdom might use Polaris. In 1957 Chief of Naval Operations Arleigh Burke and First Sea Lord Louis Mountbatten began corresponding on the project. After the cancellations of the Blue Streak and Skybolt missiles in the 1960s, under the 1962 Nassau Agreement that emerged from meetings between Harold Macmillan and John F. Kennedy, the United States would supply Britain with Polaris missiles, launch tubes, ReBs, and the fire-control systems. Britain would make its own warheads and initially proposed to build five ballistic missile submarines, later reduced to four by the incoming Labour government of Harold Wilson, with 16 missiles to be carried on each boat. The Nassau Agreement also featured very specific wording. The intention of wording the agreement in this manner was to make it intentionally opaque. The sale of the Polaris was malleable in how an individual country could interpret it due to the diction choices taken in the Nassau Agreement. For the United States of America, the wording allowed for the sale to fall under the scope of NATO's deterrence powers. On the other hand, for the British, the sale could be viewed as a solely British deterrent. The Polaris Sales Agreement was signed on April 6, 1963.

In return, the British agreed to assign control over their Polaris missile targeting to the SACEUR (Supreme Allied Commander, Europe), with the provision that in a national emergency when unsupported by the NATO allies, the targeting, permission to fire, and firing of those Polaris missiles would reside with the British national authorities. Nevertheless, the consent of the British Prime Minister is and has been always required for the use of British nuclear weapons, including SLBMs.

The operational control of the Polaris submarines was assigned to another NATO Supreme Commander, the SACLANT (Supreme Allied Commander, Atlantic), who is based near Norfolk, Virginia, although the SACLANT routinely delegated control of the missiles to his deputy commander in the Eastern Atlantic area, COMEASTLANT, who was always a British admiral.

Polaris was the largest project in the Royal Navy's peacetime history. Although in 1964 the new Labour government considered cancelling Polaris and turning the submarines into conventionally armed hunter-killers, it continued the program as Polaris gave Britain a global nuclear capacity—perhaps east of Suez—at a cost £150 million less than that of the V bomber force. By adopting many established, American, methodologies and components Polaris was finished on time and within budget. On 15 February 1968, , the lead ship of her class, became the first British vessel to fire a Polaris. All Royal Navy SSBNs have been based at Faslane, only a few miles from Holy Loch. Although one submarine of the four was always in a shipyard undergoing a refit, recent declassifications of archived files disclose that the Royal Navy deployed four boatloads of reentry vehicles and warheads, plus spare warheads for the Polaris A3T, retaining a limited ability to re-arm and put to sea the submarine that was in refit. When replaced by the Chevaline warhead, the sum total of deployed RVs and warheads was reduced to three boatloads.

The original U.S. Navy Polaris had not been designed to penetrate anti-ballistic missile (ABM) defenses, but the Royal Navy had to ensure that its small Polaris force operating alone, and often with only one submarine on deterrent patrol, could penetrate the ABM screen around Moscow. Britain's submarines featured the Polaris A3T missiles, a modification to the model of the Polaris used by the U.S. from 1968 to 1972. Similar concerns were present in the U.S. as well, resulting in a new American defense program.

The program became known as Antelope, and its purpose was to alter the Polaris. Various aspects of the Polaris, such as increasing deployment efficiency and creating ways to improve the penetrative power were specific items considered in the tests conducted during the Antelope program. The British's uncertainty with their missiles led to the examination of the Antelope program. The assessments of Antelope occurred at Aldermaston. Evidence from the evaluation of Antelope led to the British decision to undertake their program following that of the United States.

The result was a programme called "Chevaline" that added multiple decoys, chaff, and other defensive countermeasures. Its existence was only revealed in 1980, partly because of the cost overruns of the project, which had almost quadrupled the original estimate given when the project was finally approved in January 1975. The program also ran into trouble when dealing with the British Labour Party. Their Chief Scientific Adviser, Solly Zuckerman, believed that Britain no longer needed new designs for nuclear weapons and no more nuclear warhead tests would be necessary. Though the Labour party provided a clear platform on nuclear weapons, the Chevaline program found supporters. One such individual who supported modification to the Polaris was the Secretary of state for Defense, Denis Healey.

Despite the approval of the program, the expenses caused hurdles that augmented the time it took for the system to come to fruition. The cost of the project led to Britain's revisit of disbanding the program in 1977. The system became operational in mid-1982 on , and the last British SSBN submarine was equipped with it in mid-1987. Chevaline was withdrawn from service in 1996.

Though Britain adopted the Antelope program methods, no input on the design came from the United States. Aldermaston was solely responsible for the Chevaline warheads.

The British did not ask to extend the Polaris Sales Agreement to cover the Polaris successor Poseidon due to its cost. The Ministry of Defence upgraded its nuclear missiles to the longer-ranged Trident after much political wrangling within the Callaghan Labour Party government over its cost and whether it was necessary. The outgoing Prime Minister James Callaghan made his government's papers on Trident available to Margaret Thatcher's new incoming Conservative Party government, which took the decision to acquire the Trident C4 missile.

A subsequent decision to upgrade the missile purchase to the even larger, longer-ranged Trident D5 missile was possibly taken to ensure that there was missile commonality between the U.S. Navy and the Royal Navy, which was considerably important when the Royal Navy Trident submarines were also to use the Naval Submarine Base Kings Bay.

Even though the U.S. Navy initially deployed the Trident C4 missile in the original set of its "Ohio"-class submarines, it was always planned to upgrade all of these submarines to the larger and longer-ranged Trident D5 missile—and that eventually, all of the C4 missiles would be eliminated from the U.S. Navy. This change-over has been completely carried out, and no Trident C4 missiles remain in service.

The Polaris missile remained in Royal Navy service long after it had been completely retired and scrapped by the U.S. Navy in 1980–1981. Consequently, many spare parts and repair facilities for the Polaris that were located in the U.S. ceased to be available (such as at Lockheed, which had moved on first to the Poseidon and then to the Trident missile).

During its reconstruction program in 1957–1961, the was fitted with four Polaris missile launchers located in the aft part of the ship. The Italian usage of Polaris missiles was partially the result of the Kennedy administration. Prior to 1961, the Italian and Turkish fleets were outfitted with Jupiter missiles. Three factors were instrumental in the movement away from the Jupiter project in Italy and Turkey: the president's view of the project, new understanding about weapons systems and the diminished necessity of the Jupiter missile. The Joint Congressional Committee report on Atomic Energy accentuated the three previous factors in Italy's decision to switch to the Polaris missiles.Successful tests held in 1961–1962 induced the United States to study a NATO Multilateral Nuclear Force (MLF), consisting of 25 international surface vessels from the US, United Kingdom, France, Italy, and West Germany, equipped with 200 Polaris nuclear missiles, enabling European allies to participate in the management of the NATO nuclear deterrent.

The report advocated a change from the outdated Jupiter missiles, already housed by the Italians, to the newer missile, Polaris. The report resulted in Secretary of State Dean Rusk and Assistant Secretary of Defense Paul Nitze discussing the possibility of changing the warheads in the Mediterranean. The Italians were not swayed by the American's interest in modernizing their warheads. However, after the Cuban Missile Crisis, Kennedy met the Italian leader Amitore Fanfani in Washington. Fanfani conceded and went along with Kennedy's Polaris plan, despite the Italians hoping to stick with the Jupiter missile.

The MLF plan, as well as the Italian Polaris Program, were abandoned, both for political reasons (in consequence of the Cuban Missile Crisis) and the initial operational availability of the first SSBN , which was capable of launching SLBMs while submerged, a solution preferable to surface-launched missiles.

Italy developed a new domestic version of the missile, the SLBM-designated Alfa. That program was cancelled in 1975 after Italy ratified the Nuclear Non-Proliferation Treaty, with the final launch of the third prototype in 1976.

Two Italian Navy cruisers, commissioned in 1963–1964, were "fitted for but not with" two Polaris missile launchers per ship. All four launchers were built but never installed, and were stored at the La Spezia naval facility.

The , launched in 1969, was also "fitted for but not with" four Polaris missile launchers. During refit periods in 1980–1983, these facilities were removed and used for other weapons and systems.


Notes
Bibliography




</doc>
<doc id="24788" url="https://en.wikipedia.org/wiki?curid=24788" title="UGM-73 Poseidon">
UGM-73 Poseidon

The UGM-73 Poseidon missile was the second US Navy nuclear-armed submarine-launched ballistic missile (SLBM) system, powered by a two-stage solid-fuel rocket. It succeeded the UGM-27 Polaris beginning in 1972, bringing major advances in warheads and accuracy. It was followed by Trident I in 1979, and Trident II in 1990.

A development study for a longer range version of the Polaris missile—achieved by enlarging it to the maximum possible size allowed by existing launch tubes—started in 1963. Tests had already shown that Polaris missiles could be operated without problems in launch tubes that had their fiberglass liners and locating rings removed.

The project was given the title Polaris B3 in November, but the missile was eventually named Poseidon C3 to emphasize the technical advances over its predecessor. The C3 was the only version of the missile produced, and it was also given the designation UGM-73A.

Slightly longer and considerably wider and heavier than Polaris A3, Poseidon had the same range, greater payload capacity, improved accuracy, and multiple independently targetable reentry vehicle (MIRV) capability. MIRV capacity has been given as up to either ten or fourteen W68 thermonuclear warheads contained in Mark 3 reentry vehicles to multiple targets.

As with Polaris, starting a rocket motor when the missile was still in the submarine was considered very dangerous. Therefore, the missile was ejected from its launch tube using high pressure steam produced by a solid-fueled boiler. The main rocket motor ignited automatically when the missile had risen approximately above the submarine.

The first test launch took place on 16 August 1968, the first successful at-sea launch was from a surface ship, the (from July 1 to December 16, 1969), earning the ship the Meritorious Unit Commendation, and the first test launch from a submarine took place on the on 3 August 1970. The weapon officially entered service on 31 March 1971. It eventually equipped 31 -, -, and -class submarines.

The Royal Navy also considered adopting Poseidon in the 1970s as an upgrade to its Polaris A3T boats, and like the US this would have kept the existing hulls. Although the Navy's favoured option, the British government instead adopted Chevaline, a two warhead MRV system with decoys, on the existing Polaris airframes and later moved to the Trident D5 in new boats.

Beginning in 1979, 12 Poseidon-equipped SSBNs were refitted with Trident I. By 1992, the Soviet Union had collapsed, 12 Ohio-class submarines had been commissioned, and the START I treaty had gone into effect, so the 31 older Poseidon- and Trident I-armed SSBNs were disarmed, withdrawing Poseidon from service.




</doc>
<doc id="24789" url="https://en.wikipedia.org/wiki?curid=24789" title="Portuguese">
Portuguese

Portuguese may refer to:



</doc>
<doc id="24793" url="https://en.wikipedia.org/wiki?curid=24793" title="POTS">
POTS

Pots most commonly refers to pottery, the ceramic ware made by potters

POTS or Pots may also refer to:



</doc>
<doc id="24795" url="https://en.wikipedia.org/wiki?curid=24795" title="Private (rank)">
Private (rank)

A private is a soldier of the lowest military rank (equivalent to NATO Rank Grades OR-1 to OR-3 depending on the force served in).

In modern military writing, "private" is abridged to "Pte" in the United Kingdom and other Commonwealth of Nations countries and to "Pvt" in the United States.

The term derives from the medieval term "private soldiers" (a term still used in the British Army), denoting individuals who were either hired, conscripted, or mustered into service by a feudal nobleman commanding a battle group of an army. The usage of "private" dates from the 18th century.

In Indonesia, this rank is referred to as (specifically "Prajurit" which means, soldier), which is the lowest rank in the Indonesian National Armed Forces and special Police Force. In the Indonesian Army, Indonesian Marine Corps, and Indonesian Air Force, "Private" has three levels, which are: Private ("Prajurit Dua"), Private First Class ("Prajurit Satu"), and Master Private ("Prajurit Kepala"). After this rank, it is promoted the rank: Corporal.

In the Israel Defense Forces, ("private") refers to the lowest enlisted rank. After 7–10 months of service (7 for combatants, 8 for combat support and 10 for non-combatants) soldiers are promoted from private to corporal ( or ), if they performed their duties appropriately during this time. Soldiers who take a commander's course, are prisoner instructors or practical engineers become corporals earlier. An IDF private wears no uniform insignia and is sometimes described as having a "slick sleeve" for this reason.

The equivalent ranks to privates within the North and South Korean armies are "ilbyeong" (private first class) and "ibyeong" (private second class). The symbol for this rank is 1 line ( | ) or 2 lines ( || ). Private second class is known by 1 line, while private first class is 2 lines.

Once recruits complete their Basic Military Training (BMT) or Basic Rescue Training (BRT), they attain the rank of private (PTE). Privates do not wear ranks on their rank holder. PTEs who performed well are promoted to the rank of Lance Corporal (LCP). The PFC rank is rarely awarded nowadays by SAF. All private enlistees can be promoted directly to lance corporal should they meet the minimum qualifying requirements, conduct appraisal and work performance. Recruits who did not complete BMT but completed 2 years of National Service will be promoted to private.

In the Australian Army, a soldier of private rank wears no insignia. Like its British Army counterpart, the Australian Army rank of private (PTE) has other titles, depending on the corps and specification of that service member.

The following alternative ranks are available for privates in the Australian Army:


In the Bangladesh Army the lowest enlisted rank is "sainik" (সৈনিক), literally meaning "soldier".

In the Canadian Armed Forces, "private" is the lowest rank for members who wear army uniform. There are three levels of private: private (recruit), private (basic), and private (trained). All persons holding the rank of private are referred to as such and the qualifier shown in brackets is used on employment records only. The air force rank of aviator was formerly called "private", but this changed when traditional air force rank insignia were restored in 2014. The French-language equivalent of private is .

Canadian Army privates may be known by other titles, depending on their military trade and their unit’s tradition:

In the Indian Army and Pakistan Army, the lowest enlisted rank is sepoy (/ˈsiːpɔɪ/), literally meaning "soldier" derived from Persian. A sepoy does not wear any rank insignia on his uniform. They are commonly referred to as "jawans".

In the South African Army the lowest enlisted rank is Private. Privates don't wear insignia on their uniforms. In the different corps it is known with different titles.

In the British Army, a private (Pte) equates to both OR-1 and OR-2 on the NATO scale, although there is no difference in rank. Privates wear no insignia. Many regiments and corps use other distinctive and descriptive names instead of private, some of these ranks have been used for centuries, others are less than 100 years old. In the contemporary British Armed Forces, the army rank of private is broadly equivalent to able seaman in the Royal Navy, aircraftman, leading aircraftman and senior aircraftman in the Royal Air Force, and marine (Mne) or bandsman, as appropriate equivalent rank in the Royal Marines. In the Boys' Brigade the rank of private is used when a boy moves from the junior section to the company section.

Distinctive equivalents for private include:

In the Corps of Royal Marines, the rank structure follows that of British infantry regiments with the exception that the Royal Marines equivalent of private is Marine (Mne).

During the course of the First World War, some Royal Marines also took the rank of Sapper, this was usually found as part of the Royal Marine Divisional Engineers of the Royal Naval Division.

The lowest rank in the Austrian Armed Forces is the "Rekrut" (literally "Recruit"). For recruits in training to become non-commissioned or commissioned officers the rank bears an additional silver crossbar.

Up until 1998, the rank was called "Wehrmann". In 2017 the silver crossbar was removed, as the system of the 'officers career' changed.

The equivalent rank to private in the Spanish, Mexican, Colombian, Dominican and Argentinian army is the "soldado raso" meaning "rankless soldier" or simply "soldado".

Upon enlistment to the Belgian army, one is given the rank of (Dutch) or (French), whether one wishes to be a volunteer, non-commissioned officer or officer. Subsequent rank depends on the branch of the service: for example, at the Royal Military Academy (for officer training) one is soon promoted to the rank of (Dutch) or (French) i.e. "corporal". The insignia is a simple black mark or the simplified version of the Royal Military Academy's coat of arms for candidate officers.

"Soldado" is the rank equivalent to private in the Brazilian and Portuguese Armed Forces. "Soldado" means "soldier" in Portuguese.

The Finnish equivalent rank is "sotamies" (literally "war man"), although since 1973 this has been purely a paper term as all infantry troopers were renamed as "jääkäri" troops, previously reserved only to mobile light infantry. As in the British army, the various branches use different names:


In the Finnish Air Force, the basic rank is "lentosotamies" ("flight war man"). In the Finnish Navy, the basic rank is "matruusi" ("seaman") or "tykkimies" ("cannon man") in the marine infantry.

Special corps troopers may be referred by their function or unit, such as "kaartinjääkäri" (Guards jaeger), "panssarijääkäri" (panzer jaeger), "laskuvarjojääkäri" (paratroop jaeger), "rajajääkäri" (border jaeger) or "rannikkojääkäri" (coastal jaeger).

In the French army, "soldat de seconde classe" is the lowest military rank. This rank is also referred to as "recrue" ("recruit").

The German "Bundeswehr" modern-day equivalent of the private rank (NATO-standard code OR-2) is Gefreiter.

The equivalent of the lowest rank (NATO-standard code OR-1) is either "Schütze" (rifleman), "Kanonier" (gunner) or "Jäger" (light-infantryman otherwise ranger), and sometimes in general simply "Soldat" (soldier), as well as other unit-specific distinctions. Up until 1918 it was "Gemeine" (Ordinary [soldier]) as well as unit-specific distinctions such as "Musketier" (musketeer), "Infanterist" (infantryman), "Kürassier" (cuirassier), "Jäger" (light-infantryman otherwise ranger), "Füsilier" (fusilier) etc., until 1945 "Soldat" (soldier) and unit-specific distinctions such as "Schütze" (rifleman), "Grenadier" (grenadier) etc. The navy equivalent of the OR-1 rank is known as "Matrose" (sailor or seaman), and the German Air Force equivalent is "Flieger" (aviator or airman) which is also used by army aviators.

The name of the lowest rank in the Hungarian army ("Magyar Honvédség") is the "honvéd" which means "homeland defender". The word is also used informally for a soldier in general of any rank (i.e. "our "honvéds"" or an officer referred as a "honvédtiszt", "honvéd" officer). This is because Hungarian military traditions are strictly defensive, despite the Hungarian army participating in offensives on foreign soil in both world wars. The word "honvéd" has been in use since the Hungarian Revolution of 1848. The term is not used for soldiers of foreign armies: a foreign soldier with no rank is called "közlegény", literally "common lad" or "common man".

Private (Pte) ("saighdiúr singil" in Irish), is the lowest enlisted rank in the Irish Army. Soldiers enlist as recruits then undergo a basic course of instruction. There are three grades of private in the army. After basic training the soldier is upgraded (rather than promoted) from recruit to private 2 star (Pte 2*) ("saighdiúr singil, 2 réalta"). After more corps-specific training (usually lasting eight weeks) the soldier is upgraded to private 3 star (Pte 3*) ("saighdiúr singil, 3 réalta"). All are usually just addressed as "private", although before being upgraded, recruits may be addressed as "recruit".

In corps units, the rank designation changes. In the artillery, the rank is known as gunner (Gnr), but usually only after the completion of a gunners' course, and in the cavalry it is known as trooper (Tpr). Communications and Information Services privates are known as signalman or signalwoman. Medical orderlies are sometimes referred to as medic, although this can apply to privates and corporals.

In the Italian Army is the lowest military rank. This rank is also referred to as (meaning recruit).

In the Royal Netherlands Army, the "Landmacht", the equivalent ranks are "soldaat" (soldier), similar to the original French, with different classes:


Depending on where the "soldaat" serves, he may be deemed a "kanonnier" (gunner in the artillery), "huzaar" (hussar in the cavalry) or "fuselier" (rifleman in the rifles) as well as "commando", "jager" or "rijder". There is less differentiation than in other countries between different armed forces. A "soldaat" can be promoted to "korporaal" (corporal).

In the Swedish Armed Forces a recruit is given the rank of in the army and in the navy.

After basic training which is roughly 3 months other terms can be used such as ’’soldat’’ (soldier), ’’jägare’’, etc.

In the Swiss Armed Forces a recruit is given the rank of (equivalent to NATO OR-2), usually after completion of the first 12 weeks of basic training, also referred to as recruit school.

In the Turkish Land Forces, Turkish Air Force and Turkish Naval Forces; "Er" (Private) is the lowest rank possible. This rank does not have any insignia.

The rank is used by the National Bolivarian Armed Forces of Venezuela and has no insignia.

In the United States Army, private is used for the two lowest enlisted ranks, just below private first class (E-3) or PFC. The lowest rank is "Private (E-1)" or PV1, sometimes referred to as "recruit", but this rank can also be held by some soldiers after punishment through the Uniform Code of Military Justice, or prisoners after conviction and demotion until they are discharged. A PV1 wears no uniform rank insignia; since the advent of the Army Combat Uniform (ACU), the slang term "fuzzy" has come into vogue, referring to the blank velcro patch on the ACU where the rank would normally be placed. The second rank, "Private (E-2)" or PV2, wears a single chevron, known colloquially as "mosquito wings". Advancement to PV2 is automatic after six months' time in service, but may be shortened to four months by a waiver. A person who earned the Eagle Scout award, the Gold Award, or completed at least two years of JROTC may enlist at any time at the rank of PV2. The term of address, "Private," may be properly applied to any Army soldier E-1 (PV1) to E-3 (PFC). The abbreviation "PVT" may be used whenever the specific grade of private is immaterial (such as in Tables of Organization and Equipment).

In the United States Marine Corps, "private" (Pvt) refers only to the lowest enlisted rank, just below private first class. A Marine Corps private wears no uniform insignia and is sometimes described as having a "slick sleeve" for this reason. Most new, non-officer Marines begin their military career as a private. In the Marine Corps, privates first class are not referred to as "private"; it is more appropriate to use either "private first class" or "PFC".




</doc>
<doc id="24797" url="https://en.wikipedia.org/wiki?curid=24797" title="Proclus">
Proclus

Proclus Lycaeus (; 8 February 412 – 17 April 485 AD), called the Successor (Greek , "Próklos ho Diádokhos"), was a Greek Neoplatonist philosopher, one of the last major classical philosophers (see Damascius). He set forth one of the most elaborate and fully developed systems of Neoplatonism. He stands near the end of the classical development of philosophy and influenced Western medieval philosophy (Greek and Latin).

Proclus was born on February 8, 412 AD (his birth date is deduced from a horoscope cast by a disciple, Marinus) in Constantinople to a family of high social status in Lycia (his father Patricius was a high legal official, very important in the Eastern Roman Empire's court system) and raised in Xanthus. He studied rhetoric, philosophy and mathematics in Alexandria, with the intent of pursuing a judicial position like his father. Before completing his studies, he returned to Constantinople when his rector, his principal instructor (one Leonas), had business there.

Proclus became a successful practicing lawyer. However, the experience of the practice of law made Proclus realize that he truly preferred philosophy. He returned to Alexandria, and began determinedly studying the works of Aristotle under Olympiodorus the Elder. He also began studying mathematics during this period as well with a teacher named Heron (no relation to Hero of Alexandria, who was also known as Heron). As a gifted student, he eventually became dissatisfied with the level of philosophical instruction available in Alexandria, and went to Athens, the pre-eminent philosophical center of the day, in 431 to study at the Neoplatonic successor of the famous Academy founded 800 years earlier (in 387 BC) by Plato; there he was taught by Plutarch of Athens (not to be confused with Plutarch of Chaeronea), Syrianus, and Asclepigenia; he succeeded Syrianus as head of the Academy, and would in turn be succeeded on his death by Marinus of Neapolis.

He lived in Athens as a vegetarian bachelor, prosperous and generous to his friends, until the end of his life, except for a voluntary one-year exile, which was designed to lessen the pressure put on him by his political-philosophical activity, little appreciated by the Christian rulers; he spent the exile traveling and being initiated into various mystery cults. He was also instructed in the "theurgic" Neoplatonism, as derived from the Orphic and Chaldean Oracles. His house has been discovered recently in Athens, under the pavement of Dionysiou Areopagitou Street, south of Acropolis, opposite the theater of Dionysus. He had a great devotion to the goddess Athena, who he believed guided him at key moments in his life. Marinus reports that when Christians removed the statue of the goddess from the Parthenon, a beautiful woman appeared to Proclus in a dream and announced that the "Athenian Lady" wished to stay at his home. Proclus died aged 73, and was buried near Mount Lycabettus in a tomb. It is reported that he was writing 700 lines each day.

The majority of Proclus's works are commentaries on dialogues of Plato ("Alcibiades", "Cratylus", "Parmenides", "Republic", "Timaeus"). In these commentaries he presents his own philosophical system as a faithful interpretation of Plato, and in this he did not differ from other Neoplatonists, as he considered that "nothing in Plato’s corpus is unintended or there by chance", that "that Plato’s writings were divinely inspired" (ὁ θεῖος Πλάτων "ho theios Platon"—the divine Plato, inspired by the gods), that "the formal structure and the content of Platonic texts imitated those of the universe", and therefore that they spoke often of things under a veil, hiding the truth from the philosophically uninitiate. Proclus was however a close reader of Plato, and quite often makes very astute points about his Platonic sources. A number of his Platonic commentaries are lost.

Proclus, the scholiast to Euclid, knew Eudemus of Rhodes' "History of Geometry" well, and gave a short sketch of the early history of geometry, which appeared to be founded on the older, lost book of Eudemus. The passage has been referred to as "the Eudemian summary," and determines some approximate dates, which otherwise might have remained unknown. The influential commentary on the first book of Euclid's "Elements of Geometry" is one of the most valuable sources we have for the history of ancient mathematics, and its Platonic account of the status of mathematical objects was influential. In this work, Proclus also listed the first mathematicians associated with Plato: a mature set of mathematicians (Leodamas of Thasos, Archytas of Taras, and Theaetetus), a second set of younger mathematicians (Neoclides, Eudoxus of Cnidus), and a third yet younger set (Amyntas, Menaechmus and his brother Dinostratus, Theudius of Magnesia, Hermotimus of Colophon and Philip of Opus). Some of these mathematicians were influential in arranging the Elements that Euclid later published.

In addition to his commentaries, Proclus wrote two major systematic works. The "Elements of Theology" (Στοιχείωσις θεολογική) consists of 211 propositions, each followed by a proof, beginning from the existence of the One (divine Unity) and ending with the descent of individual souls into the material world. The "Platonic Theology" (Περὶ τῆς κατὰ Πλάτωνα θεολογίας) is a systematisation of material from Platonic dialogues, showing from them the characteristics of the divine orders, the part of the universe which is closest to the One.

We also have three essays, extant only in Latin translation: "Ten doubts concerning providence" ("De decem dubitationibus circa providentiam"); "On providence and fate" ("De providentia et fato"); "On the existence of evils" ("De malorum subsistentia").

He also wrote a number of minor works, which are listed in the bibliography below.

Proclus's system, like that of the other Neoplatonists, is a combination of Platonic, Aristotelian, and Stoic elements. In its broad outlines, Proclus's system agrees with that of Plotinus with a notable difference that unlike Plotinus, Proclus did not hold that matter was evil, an idea that caused contradictions in the system of Plotinus. However, following Iamblichus, Plutarch of Athens, and his master Syrianus, Proclus presents a much more elaborate universe than Plotinus, subdividing the elements of Plotinus's system into their logically distinct parts, and positing these parts as individual things. This multiplication of entities is balanced by the monism which is common to all Neoplatonists. What this means is that, on the one hand the universe is composed of hierarchically distinct things, but on the other all things are part of a single continuous emanation of power from the One. From this latter perspective, the many distinctions to be found in the universe are a result of the divided perspective of the human soul, which needs to make distinctions in its own thought in order to understand unified realities. The idealist tendency is taken further in John Scotus Eriugena.

There is a double motivation found in Neoplatonic systems. The first is a need to account for the origin and character of all things in the universe. The second is a need to account for how we can know this origin and character of things. These two aims are related: they begin from the assumption that we can know reality, and then ask the question of what reality must be like, in its origin and unfolding, so that we can know it. An important element in the Neoplatonic answer to these questions is its reaction to Scepticism. In response to the sceptical position that we only know the appearances presented by our senses, and not the world as it is, Plotinus placed the object of knowledge inside the soul itself, and accounted for this interior truth through the soul's kinship with its own productive principles.

The first principle in Neoplatonism is the One (Greek: "to Hen"). Being proceeds from the One. The One cannot itself be a being. If it were a being, it would have a particular nature, and so could not be universally productive. Because it is "beyond being" ("epekeina tes ousias", a phrase from Plato's "Republic" 509b), it is also beyond thought, because thinking requires the determinations which belong to being: the division between subject and object, and the distinction of one thing from another. For this reason, even the name "The One" is not a positive name, but rather the most non-multiple name possible, a name derived from our own inadequate conception of the simplicity of the first principle. The One causes all things by conferring unity, in the form of individuality, on them, and in Neoplatonism existence, unity, and form tend to become equivalent. The One causes things to exist by donating unity, and the particular manner in which a thing is one is its form (a dog and a house are individual in different manners, for example). Because the One makes things exist by giving them the individuality which makes them what they are as distinct and separate beings, the Neoplatonists thought of it also as the source of the good of everything. So the other name for the One is the Good. Despite appearances, the first principle is not double; all things have a double relation to it, as coming from them (One) and then being oriented back towards them to receive their perfection or completion (Good).

The particular characteristic of Proclus's system is his elaboration of a level of individual ones, called "henads," between the One which is before being and intelligible divinity. The henads exist "superabundantly", also beyond being, but they stand at the head of chains of causation ("seirai") and in some manner give to these chains their particular character. He identifies them with the Greek gods, so one henad might be Apollo and be the cause of all things apollonian, while another might be Helios and be the cause of all "sunny" things. Each henad participates in every other henad, according to its character. What appears to be multiplicity is not multiplicity at all, because any henad may rightly be considered the center of the polycentric system.

The principle which is produced below the level of the One and the Henads is the divine Intellect ("Nous"). The One cannot have a determinate nature if it is to be the source of all determinate natures, so what it produces is the totality of all determinate natures, or Being. By determination is meant existence within boundaries, a being "this" and not "that". The most important determinate natures are the "Greatest Kinds" from Plato's "Sophist" (Being, Same, Other, Rest, Motion) and Aristotle's ten categories (Quantity, Quality, etc.). In other words, the One produces what Plato called the Forms, and the Forms are understood to be the first determinations into which all things fall. The One produces the Forms through the activity of thinking. The One itself does not think, but instead produces a divine mind, Intellect, whose thoughts are themselves the Forms. Intellect is both Thinking and Being. It is a mind which has its own contents as its object. All things relate to the first principle as both One and Good. As Being, Intellect is the product of the One. But it also seeks to return to its cause, and so in Thinking it attempts to grasp the One as its Good. But because the simplicity of the One/Good does not allow Intellect to grasp it, what Intellect does is generate a succession of perspectives around its simple source. Each of these perspectives is itself a Form, and is how Intellect generates for itself its own content.

Plotinus speaks about the generation of Intellect from the One, and Intellect's attempt to return to the One in a thinking which is also a desiring. Proclus systematises this production through a threefold movement of remaining, procession, and return ("mone, proodos, epistrophe"). Intellect remains in the One, which means that it has the One as its origin. It proceeds from the One, which means that it comes to be as a separate entity. But it returns to the One, which means that it does not cut itself off from its source, but receives the good which is its identity from the One. This threefold motion is used by Proclus to structure all levels of his system below the One and above material reality, so that all things except those mentioned remain, proceed, and return.

Proclus also gives a much more elaborate account of Intellect than does Plotinus. In Plotinus we find the distinction between Being and Thinking in Intellect. Proclus, in keeping with his triadic structure of remaining, procession, and return, distinguishes three moments in Intellect: Intelligible, Intelligible-Intellectual, and Intellectual. They correspond to the object of thought, the power of the object to be grasped by the subject, and the thinking subject. These three divisions are elaborated further, so that the intelligible moment consists of three triads (Being, Eternity, and the Living Being or Paradigm from Plato's "Timaeus"). The intelligible-intellectual moment also consists of three triads, and the intellectual moment is a hebdomad (seven elements), among which is numbered the Demiurge from Plato's "Timaeus" and also the monad of Time (which is before temporal things). In this elaboration of Intellect as a whole, Proclus is attempting to give a hierarchical ordering to the various metaphysical elements and principles that other philosophers have discussed, by containing them within a single triadic logic of unfolding.

Proclus's universe unfolds according to the smallest steps possible, from unity to multiplicity. With Intellect emerges the multiplicity which allows one being to be different from another being. But as a divine mind, Intellect has a complete grasp of all its moments in one act of thought. For this reason, Intellect is outside of Time.

Intellect as the second principle also gives rise to individual intellects, which hold various places within Proclus's cosmos.

In terms of his sources, Intellect is like taking the Platonic Forms and placing them in the self-thinking thought which is Aristotle's Unmoved Mover.

Soul ("Psyche") is produced by Intellect, and so is the third principle in the Neoplatonic system. It is a mind, like Intellect, but it does not grasp all of its own content as one. Therefore, with Soul, Time comes to be, as a measure of Soul's movement from one object of thought to another. Intellect tries to grasp the One, and ends up producing its own ideas as its content. Soul attempts to grasp Intellect in its return, and ends up producing its own secondary unfoldings of the Forms in Intellect. Soul, in turn, produces Body, the material world.

In his commentary on Plato's "Timaeus" Proclus explains the role the Soul as a principle has in mediating the Forms in Intellect to the body of the material world as a whole. The Soul is constructed through certain proportions, described mathematically in the "Timaeus", which allow it to make Body as a divided image of its own arithmetical and geometrical ideas.

Individual souls have the same overall structure as the principle of Soul, but they are weaker. They have a tendency to be fascinated with the material world, and be overpowered by it. It is at this point that individual souls are united with a material body (i.e. when they are born). Once in the body, our passions have a tendency to overwhelm our reason. According to Proclus, philosophy is the activity which can liberate the soul from a subjection to bodily passions, remind it of its origin in Soul, Intellect, and the One, and prepare it not only to ascend to the higher levels while still in this life, but to avoid falling immediately back into a new body after death.

Because the soul's attention, while inhabiting a body, is turned so far away from its origin in the intelligible world, Proclus thinks that we need to make use of bodily reminders of our spiritual origin. In this he agrees with the doctrines of theurgy put forward by Iamblichus. Theurgy is possible because the powers of the gods (the "henads") extend through their series of causation even down to the material world. And by certain power-laden words, acts, and objects, the soul can be drawn back up the series, so to speak. Proclus himself was a devotee of many of the religions in Athens, considering that the power of the gods could be present in these various approaches.

For Proclus, philosophy is important because it is one of the primary ways to rescue the soul from a fascination with the body and restore it to its station. However, beyond its own station, the soul has Intellect as its goal, and ultimately has unification with the One as its goal. So higher than philosophy is the non-discursive reason of Intellect, and the pre-intellectual unity of the One. Philosophy is therefore a means of its own overcoming, in that it points the soul beyond itself.

Proclus can be considered as the spokesman of mature Neoplatonism. His works had a great influence on the history of western philosophy. The extent of this influence, however, is obscured by the channels through which it was exercised. An important source of Procline ideas was through the Pseudo-Dionysius. This late-5th- or early-6th-century Christian Greek author wrote under the pseudonym Dionysius the Areopagite, the figure converted by St. Paul in Athens. Because of this fiction, his writings were taken to have almost apostolic authority. He is an original Christian writer, and in his works can be found a great number of Proclus's metaphysical principles.

Another important source for the influence of Proclus on the Middle Ages is Boethius's "Consolation of Philosophy", which has a number of Proclus principles and motifs. The central poem of Book III is a summary of Proclus's "Commentary on the Timaeus", and Book V contains the important principle of Proclus that things are known not according to their own nature, but according to the character of the knowing subject.

A summary of Proclus's "Elements of Theology" circulated under the name "Liber de Causis" (the "Book of Causes"). This book is of uncertain origin, but circulated in the Arabic world as a work of Aristotle, and was translated into Latin as such. It had great authority because of its supposed Aristotelian origin, and it was only when Proclus's "Elements" were translated into Latin that Thomas Aquinas realised its true origin.

Proclus's works also exercised an influence during the Renaissance through figures such as Georgius Gemistus Pletho and Marsilio Ficino. Before the contemporary period, the most significant scholar of Proclus in the English-speaking world was Thomas Taylor, who produced English translations of most of his works, with commentaries.

His work inspired the New England Transcendentalists, including Ralph Waldo Emerson, who declared in 1843 that, in reading Proclus, "I am filled with hilarity & spring, my heart dances, my sight is quickened, I behold shining relations between all beings, and am impelled to write and almost to sing."

Modern scholarship on Proclus essentially begins with E. R. Dodds edition of the "Elements of Theology" in 1933. Since then he has attracted considerable attention, especially in the French-speaking world. Procline scholarship, however, still (2006) falls far short of the attention paid to Plotinus.

The following epigram is engraved on the tomb which houses Proclus and his master Syrianus:

The crater Proclus on the Moon is named after him.


A number of other minor works or fragments of works survive. A number of major commentaries have been lost.

The "Liber de Causis" (Book of Causes) is not a work by Proclus, but a summary of his work the "Elements of Theology", likely written by an Arabic interpreter. It was mistakenly thought in the Middle Ages to be a work of Aristotle, but was recognised by Aquinas not to be so.

A list of modern editions and translations of his surviving works is available at:


Monographs

Collections of essays

Studies on particular aspects of Proclus' philosophy

Bibliographic resources



</doc>
<doc id="24799" url="https://en.wikipedia.org/wiki?curid=24799" title="Production team">
Production team

A production team is the group of technical staff who produce a play, television show, recording, or film. Generally the term refers to all individuals responsible for the technical aspects of creating of a particular product, regardless of where in the process their expertise is required, or how long they are involved in the project. For example, in a theatrical performance, the production team includes not only the running crew, but also the theatrical producer, designers and theatre direction.

A production company in filmmaking is composed of a film crew and a television crew in video production.

In music, the term "production team" typically refers to a group of individuals filling the role of "record producer" usually reserved for one individual. Some examples of musical production teams include Matmos and D-Influence.



</doc>
<doc id="24801" url="https://en.wikipedia.org/wiki?curid=24801" title="Pinconning cheese">
Pinconning cheese

Pinconning cheese is an aged semi-hard whole cow's milk, Colby style cheese named after Pinconning, Michigan, where it was first developed and produced by Dan Horn in 1915. Since then and currently, Pinconning Cheese is made and distributed based on the original family traditional recipe by the originator's related companies, Pinconning Cheese Company and Wilson's (Horn) Cheese Shoppe in Pinconning, Michigan. It is available in mild and then aged many years to sharpness levels of medium mild, medium sharp, sharp, extra sharp, and super sharp (7 plus years old). Its hardness and texture change and sharpness increase with aging. Pinconning's flavor and texture are rich, creamy and open. It is unusual and a different experience than eating traditional Colby Cheese. It is often used as a replacement for Cheddar and Colby cheeses in dishes such as macaroni and soufflés." Pinconning was chosen as the ‘Cheese Capital of Michigan’ after the Pinconning brand of cheese where it was originated and still sold today.


</doc>
<doc id="24805" url="https://en.wikipedia.org/wiki?curid=24805" title="Prophet">
Prophet

In religion, a prophet is an individual who is regarded as being in contact with a divine being and is said to speak on that entity's behalf, serving as an intermediary with humanity by delivering messages or teachings from the supernatural source to other people. The message that the prophet conveys is called a prophecy.

Claims of prophethood have existed in many cultures throughout history, including Judaism, Christianity, Islam, in ancient Greek religion, Zoroastrianism, Manichaeism, and many others.

The English word "prophet" is a compound Greek word, from "pro" (in advance) and the verb "phesein" (to tell); thus, a προφήτης ("prophétés") is someone who foretells future events, and also conveys messages from the divine to humans; in a different interpretation, it means advocate or speaker.

In Hebrew, the word נָבִיא ("nāvî"), "spokesperson", traditionally translates as "prophet". The second subdivision of the Tanakh, (Nevi'im), is devoted to the Hebrew prophets. The meaning of "navi" is perhaps described in Deuteronomy 18:18, where God said, "...and I will put My words in his mouth, and he shall speak unto them all that I shall command him." Thus, the "navi" was thought to be the "mouth" of God. The root nun-bet-alef ("navi") is based on the two-letter root nun-bet which denotes hollowness or openness; to receive transcendental wisdom, one must make oneself "open".

In addition to writing and speaking messages from God, Israelite or Judean nevi'im ("spokespersons", "prophets") often acted out prophetic parables in their life. For example, in order to contrast the people's disobedience with the obedience of the Rechabites, God has Jeremiah invite the Rechabites to drink wine, in disobedience to their ancestor's command. The Rechabites refuse, for which God commends them. Other prophetic parables acted out by Jeremiah include burying a linen belt so that it gets ruined to illustrate how God intends to ruin Judah's pride. Likewise, Jeremiah buys a clay jar and smashes it in the Valley of Ben Hinnom in front of elders and priests to illustrate that God will smash the nation of Judah and the city of Judah beyond repair. God instructs Jeremiah to make a yoke from wood and leather straps and to put it on his own neck to demonstrate how God will put the nation under the yoke of Nebuchadnezzar, king of Babylon. In a similar way, the prophet Isaiah had to walk stripped and barefoot for three years to illustrate the coming captivity, and the prophet Ezekiel had to lie on his side for 390 days and eat measured food to illustrate the coming siege.

The prophetic assignment is not always portrayed as positive in the Hebrew Bible, and prophets were often the target of persecution and opposition. God's personal prediction for Jeremiah, "Attack you they will, overcome you they can't," was performed many times in the biblical narrative as Jeremiah warned of destruction of those who continued to refuse repentance and accept more moderate consequences. In return for his adherence to God's discipline and speaking God's words, Jeremiah was attacked by his own brothers, beaten and put into the stocks by a priest and false prophet, imprisoned by the king, threatened with death, thrown into a cistern by Judah's officials, and opposed by a false prophet. Likewise, Isaiah was told by his hearers who rejected his message, "Leave the way! Get off the path! Let us hear no more about the Holy One of Israel!" The life of Moses being threatened by Pharaoh is another example.

According to I Samuel 9:9, the old name for navi is "ro'eh", רֹאֶה, which literally means "Seer". That could document an ancient shift, from viewing prophets as seers for hire to viewing them as moral teachers. L.C. Allen (1971) comments that in the First Temple Era, there were essentially seer-priests, who formed a guild, divined, performed rituals and sacrifices, and were scribes, and then there were canonical prophets, who did none of these (and were against divination) and had instead a message to deliver. The seer-priests were usually attached to a local shrine or temple, such as Shiloh, and initiated others as priests in that priesthood: it was a mystical craft-guild with apprentices and recruitment. Canonical prophets were not organised this way.

Some examples of prophets in the Tanakh include Abraham, Moses, Miriam, Isaiah, Samuel, Ezekiel, Malachi, and Job. In Jewish tradition Daniel is not counted in the list of prophets.

A Jewish tradition suggests that there were twice as many prophets as the number which left Egypt, which would make 1,200,000 prophets. The Talmud recognizes the existence of 48 male prophets who bequeathed permanent messages to mankind. According to the Talmud there were also seven women who are counted as prophetesses whose message bears relevance for all generations: Sarah, Miriam, Devorah, Hannah (mother of the prophet Samuel), Abigail (a wife of King David), Huldah (from the time of Jeremiah), and Esther. The Talmudic and Biblical commentator Rashi points out that Rebecca, Rachel, and Leah were also prophets.
Isaiah 8:3-4 refers he married "the prophetess", which conceived and gave to him a son, named by God Mahèr-salàl-cash-baz. Her name isn't elsewhere specified.

Prophets in Tanakh are not always Jews. The story of Balaam in Numbers 22 describes a non-Jewish prophet. According to the Talmud, Obadiah is said to have been a convert to Judaism.

The last nevi'im ("spokespersons", "prophets") mentioned in the Jewish Bible are Haggai, Zechariah, and Malachi, all of whom lived at the end of the 70-year Babylonian exile. The Talmud (Sanhedrin 11a) states that Haggai, Zachariah, and Malachi were the last prophets, and nowadays only the "Bath Kol" (בת קול, lit. "daughter of a voice", "voice of God") exists.

In Christianity, a prophet (or seer) is one inspired by God through the Holy Spirit to deliver a message. Some Christian denominations limit a prophet's message to words intended only for the entire church congregation, excluding personal messages not intended for the body of believers; but in the Bible on a number of occasions prophets were called to deliver personal messages. The reception of a message is termed revelation and the delivery of the message is termed prophecy.

The term "prophet" applies to those who receive public or private revelation. Public revelation, in Catholicism, is part of the Deposit of faith, the revelation of which was completed by Jesus; whereas private revelation does not add to the Deposit. The term "deposit of faith" refers to the entirety of Jesus Christ's revelation, and is passed to successive generations in two different forms, sacred scripture (the Bible) and sacred tradition.

The Bible terms anyone who claims to speak God's words or to teach in his name without being a prophet a false prophet. One Old Testament text in Deuteronomy contains a warning against those who prophesy events which do not come to pass and says they should be put to death. Elsewhere a false prophet may be someone who is purposely trying to deceive, is delusional, under the influence of Satan or is speaking from his own spirit.

Some Christians believe that the Holy Spirit gives spiritual gifts to Christians. These may include prophecy, tongues, miraculous healing ability, and discernment (Matthew 12:32 KJV "Whosoever speaketh a word against the Son of Man, it shall be forgiven him: but whosoever speaketh against the Holy Ghost, it shall not be forgiven him, neither in this world, neither in the world to come."). Cessationists believe that these gifts were given only in New Testament times and that they ceased after the last apostle died.

New Testament passages that explicitly discuss prophets existing after the death and resurrection of Christ include Revelation 11:10, Matthew 10:40–41 and 23:34, John 13:20 and 15:20 and Acts 11:25–30, 13:1 and 15:32.

The "Didache" gives extensive instruction in how to distinguish between true and false prophets, as well as commands regarding tithes to prophets in the church. Irenaeus, wrote of 2nd-century believers with the gift of prophecy, while Justin Martyr argued in his "Dialogue with Trypho" that prophets were not found among the Jews in his time, but that the church had prophets. "The Shepherd of Hermas" describes revelation in a vision regarding the proper operation of prophecy in the church. Eusebius mentions that Quadratus and Ammia of Philadelphia were both prominent prophets following the age of the Twelve Apostles. Tertullian, writing of the church meetings of the Montanists (to whom he belonged), described in detail the practice of prophecy in the 2nd-century church.

A number of later Christian saints were claimed to have powers of prophecy, such as Columba of Iona (521-597), Saint Malachy (1094-1148) or Padre Pio (1887-1968). Marian apparitions like those at Fatima in 1917 or at Kibeho in Rwanda in the 1980s often included prophetic predictions regarding the future of the world as well as of the local areas they occurred in.

Prophetic movements in particular can be traced throughout the Christian Church's history, expressing themselves in (for example) Montanism, Novatianism, Donatism, Franciscanism, Anabaptism, Camisard enthusiasm, Puritanism, Quakerism, Quietism, Lutheranism and Pietism. Modern Pentecostals and Charismatics, members of movements which together comprised approximately 584 million people , believe in the contemporary function of the gift of prophecy, and some in these movements allow for idea that God may continue to gift the church with some individuals who are prophets.

Some Christian sects recognize the existence of a "modern-day" prophets. One such denomination is The Church of Jesus Christ of Latter-day Saints, which teaches that God still communicates with mankind through prophecy.

The Quran identifies a number of men as "Prophets of Islam" ( "nabī"; pl. "anbiyāʾ"). Muslims believe such individuals were assigned a special mission by God to guide humanity. Besides Muhammad, this includes prophets such as Abraham ("Ibrāhīm"), Moses ("Mūsā") and Jesus ("ʿĪsā").
Although only twenty-five prophets are mentioned by name in the Quran, a hadith (no. 21257 in "Musnad Ahmad ibn Hanbal") mentions that there were (more or less) 124,000 prophets in total throughout history. Other traditions place the number of prophets at 224,000. Some scholars hold that there are an even greater number in the history of mankind, and only God knows. The Quran says that God has sent a prophet to every group of people throughout time, and that Muhammad is the last of the prophets, sent for the whole of humankind. The message of all the prophets is believed to be the same. In Islam, all prophetic messengers are prophets (such as Adam, Noah, Abraham, Moses, Jesus, and Muhammad) though not all prophets are prophetic messengers. The primary distinction is that a prophet is required to demonstrate God's law through his actions, character, and behavior without necessarily calling people to follow him, while a prophetic messenger is required to pronounce God's law (i.e. revelation) and call his people to submit and follow him. Muhammad is distinguished from the rest of the prophetic messengers and prophets in that he was commissioned by God to be the prophetic messenger to all of mankind. Many of these prophets are also found in the texts of Judaism (The Torah, the Prophets, and the Writings) and Christianity.

Muslims often refer to Muhammad as "the Prophet", in the form of a noun. Jesus is the result of a virgin birth in Islam as in Christianity, and is regarded as a prophet.

Traditionally, four prophets are believed to have been sent holy books: the Torah ("Tawrat") to Moses, the Psalms ("Zābūr") to David, the Gospel to Jesus, and the Quran to Muhammad; those prophets are considered "Messengers" or "rasūl". Other main prophets are considered messengers or "nabī", even if they didn't receive a Book from God. Examples include the messenger-prophet Aaron ("Hārūn"), the messenger-prophet Ishmael ("Ismāʿīl") and the messenger-prophet Joseph ("Yūsuf").

Although it offers many incidents from the lives of many prophets, the Quran focuses with special narrative and rhetorical emphasis on the careers of the first four of these five major prophets. Of all the figures before Muhammad, the significance of Jesus in Islam is reflected in his being mentioned in the Quran in 93 verses with various titles attached such as "Son of Mary" and other relational terms, mentioned directly and indirectly, over 187 times. He is thus the most mentioned person in the Quran by reference; 25 times by the name Isa, third-person 48 times, first-person 35 times, and the rest as titles and attributes. Moses("Musa") and Abraham("ibrahim") are also referred to frequently in the Quran. As for the fifth, the Quran is frequently addressed directly to Muhammad, and it often discusses situations encountered by him. Direct use of his name in the text, however, is rare. Rarer still is the mention of Muhammad's contemporaries.

In modern times the term "prophet" can be somewhat controversial. Many Christians with Pentecostal or charismatic beliefs believe in the continuation of the gift of prophecy and the continuation of the role of prophet as taught in Ephesians 4. The content of prophecies can vary widely. Prophecies are often spoken as quotes from God. They may contain quotes from scripture, statements about the past or current situation, or predictions of the future. Prophecies can also 'make manifest the secrets' of the hearts of other people, telling about the details of their lives. Sometimes, more than one person in a congregation will receive the same message in prophecy, with one giving it before another.

Other movements claim to have prophets. In France, Michel Potay says he received a revelation, called "The Revelation of Arès", dictated by Jesus in 1974, then by God in 1977. He is considered a prophet by his followers, the Pilgrims of Arès.

The Bahá'í Faith refers to what are commonly called prophets as "Manifestations of God" who are directly linked with the concept of Progressive revelation. Bahá'ís believe that God expresses this will at all times and in many ways, including through a series of divine messengers referred to as "Manifestations of God" or "divine educators". In expressing God's intent, these Manifestations are seen to establish religion in the world. Thus they are seen as an intermediary between God and humanity.

The Manifestations of God are not seen as incarnations of God, and are also not seen as ordinary mortals. Instead, the Bahá'í concept of the Manifestation of God emphasizes simultaneously the humanity of that intermediary and the divinity in the way they show forth the will, knowledge and attributes of God; thus they have both human and divine stations.

In addition to the Manifestations of God, there are also minor prophets. While the Manifestations of God, or major prophets, are compared to the Sun (which produces its own heat and light), minor prophets are compared to the Moon (which receives its light from the sun). Moses, for example, is taught as having been a Manifestation of God and his brother Aaron a minor prophet. Moses spoke on behalf of God, and Aaron spoke on behalf of Moses (Exodus 4:14–17). Other Jewish prophets are considered minor prophets, as they are considered to have come in the shadow of the dispensation of Moses to develop and consolidate the process he set in motion.

A number of modern catholic saints have been claimed to have powers of prophecy, such as Padre Pio and Alexandrina Maria da Costa.

In addition to this many modern Marian apparitions included prophecies in them about the world and about the local areas. The Fátima apparition in 1917 included a prophecy given by Mary to three children, that on October 13, 1917 there would be a great miracle for all to see at Fátima, Portugal, and on that day tens of thousands of people headed to Fátima to see what would happen including newspaper journalists. Many witnesses, including journalists, claimed to see the sun "dance" in the sky in the afternoon of that day, exactly as the visionaries had predicted several months before. The Kibeho apparition in Rwanda in the 1980s included many prophecies about great violence and destruction that was coming, and the Rwandan genocide only ten years later was interpreted by the visionaries as the fulfilment of these prophecies 

Several miracles and a vision of the identity of the last 112 Popes were attributed to Saint Malachy, the Archbishop of Armagh (1095–1148).

Jehovah's Witnesses do not consider any single person in their modern-day organization to be a prophet. Their literature has referred to their organization collectively as God's "prophet" on earth; this is understood, however, in the sense of declaring their interpretation of God's judgments from the Bible along with God's guidance of His Holy Spirit. Their publishing company, Watch Tower, and official position magazine, "The Watchtower", have asserted: "Ever since "The Watchtower" began to be published in July 1879 it has looked ahead into the future... No, "The Watchtower" is no inspired prophet, but it follows and explains a Book of prophecy the predictions in which have proved to be unerring and unfailing till now. "The Watchtower" is therefore under safe guidance. It may be read with confidence, for its statements may be checked against that prophetic Book." They also claim that they are God's one and only true channel to mankind on earth, and used by God for this purpose.

They have made many eschatological forecasts, some of which have led people (including followers) to incorrect assumptions. One example is "The Watchtower's" assertions that the end of the "Gentile times" or "times of the nations" would occur in 1914; even prominent Watch Tower representatives such as A. H. Macmillan incorrectly concluded and overstated their expectations. As a result, "The Watchtower" has acknowledged that Jehovah's Witnesses "have made mistakes in their understanding of what would occur at the end of certain time periods." Concurrently with these exceptions, Jehovah's Witnesses in their literature and assemblies have taught their leadership was personally chosen by Jesus Christ in 1919 (a prophetic year in Jehovah's Witnesses eschatology) and that they are "God's sole channel on earth," and "Jehovah's spirit directed organization".

Joseph Smith, who established the Church of Christ in 1830, is considered a prophet by members of the Latter Day Saint movement, of which The Church of Jesus Christ of Latter-day Saints (LDS Church) is the largest denomination. Additionally, many churches within the movement believe in a succession of modern prophets (accepted by Latter Day Saints as "prophets, seers, and revelators") since the time of Joseph Smith. Russell M. Nelson is the current Prophet and President of The Church of Jesus Christ of Latter-day Saints.

Baptist preacher William Miller is credited with beginning the mid-19th century North American religious movement now known as Adventism. He announced a Second Coming, resulting in the Great Disappointment.

The Seventh-day Adventist Church, which was established in 1863, believes that Ellen G. White, one of the church's founders, was given the spiritual gift of prophecy.

The Branch Davidians are a religious cult which was founded in 1959 by Benjamin Roden as an offshoot of the Seventh-Day Adventist Church. David Koresh, who died in the well-known Waco Siege in 1993, claimed to be their final prophet and "the Son of God, the Lamb" in 1983.


The Ahmadiyya movement in Islam believes that Mirza Ghulam Ahmad was a non law-bearing Prophet, who claimed to be a fulfillment of the various Islamic prophecies regarding the spiritual second advent of Jesus of Nazareth near the end times.

Nathan of Gaza was a theologian and author who became famous as a prophet for the alleged messiah, Sabbatai Zevi.

Divination remains an important aspect of the lives of the people of contemporary Africa, especially amongst the usually rural, socially traditionalistic segments of its population. In arguably its most influential manifestation, the system of prophecy practiced by the Babalawos and Iyanifas of the historically Yoruba regions of West Africa have bequeathed to the world a corpus of fortune-telling poetic methodologies so intricate that they have been added by UNESCO to its official "intangible cultural heritage of the World list".

Tenrikyo's prophet, Nakayama Miki, is believed by Tenrikyoans to have been a messenger of God.


The Great Peacemaker (sometimes referred to as "Deganawida" or "Dekanawida") co-founded the Haudenosaunee league in pre-Columbian times. In retrospect, his prophecy of the boy seer could appear to refer to the conflict between natives and Europeans (white serpent).

From 1805 until the Battle of Tippecanoe that falsified his predictions in 1811, the "Shawnee prophet" Tenskwatawa lead an Indian alliance to stop Europeans to take more and more land going west. He reported visions he had. He is said to have accurately predicted a solar eclipse. His brother Tecumseh re-established the alliance for Tecumseh's War, that ended with the latter's death in 1813. Tecumseh fought together with British forces that, in the area of the Great Lakes, occupied essentially today's territory of Canada.

Francis the Prophet, influenced by Tecumseh and Tenskwatawa, was a leader of the Red Stick faction of the Creek Indians. He traveled to England in 1815 as a representative of the "four Indian nations" in an unsuccessful attempt to get Great Britain to help them resist the expansionism of the white settlers.

20 years later (1832), Wabokieshiek, the "Winnebago Prophet", after whom Prophetstown has been named, (also called "White Cloud") claimed that British forces would support the Indians in the Black Hawk War against the United States as 20 years earlier (based on "visions"). They did not, and no longer he was considered a "prophet".

In 1869, the Paiute Wodziwob founded the Ghost Dance movement. The dance rituals were an occasion to announce his visions of an earthquake that would swallow the whites. He seems to have died in 1872.

The Northern Paiute Wovoka claimed he had a vision during the solar eclipse of January 1, 1889, that the Paiute dead would come back and the whites would vanish from America, provided the natives performed Ghost Dances. This idea spread among other Native American peoples. The government were worried about a rebellion and sent troops, which lead to the death of Sitting Bull and to the Wounded Knee massacre in 1890.

Clifford Trafzer compiled an anthology of essays on the topic, American Indian Prophets. 

In the late 20th century the appellation of "prophet" has been used to refer to individuals particularly successful at analysis in the field of economics, such as in the derogatory "prophet of greed". Alternatively, social commentators who suggest escalating crisis are often called "prophets of doom."





</doc>
<doc id="24807" url="https://en.wikipedia.org/wiki?curid=24807" title="Pleading">
Pleading

In law as practiced in countries that follow the English models, a pleading is a formal written statement of a party's claims or defenses to another party's claims in a civil action. The parties' pleadings in a case define the issues to be adjudicated in the action.

The Civil Procedure Rules (CPR) govern pleading in England and Wales. Federal Rules of Civil Procedure govern pleading in United States federal courts. Each state in the United States has its own statutes and rules that govern pleading in the courts of that state.

In the United States, a "complaint" is the first pleading filed by a plaintiff which initiates a lawsuit. A complaint sets forth the relevant allegations of fact that give rise to one or more legal causes of action along with a prayer for relief and sometimes a statement of damages claimed (an ad quod damnum clause). In some situations, a complaint is called a "petition", in which case the party filing it is called the petitioner and the other party is the respondent. In equity, sometimes called chancery, the initial pleading may be called either a "petition" or a "bill of complaint in chancery".

In England and Wales, the first pleading is a Claim Form, issued under either Part 7 or Part 8 of the Civil Procedure Rules, which sets out the nature of the action and the relief sought, and may give brief particulars of the claim. The Claimant also has the option, under Practice Direction 7A.61 to serve Particulars of Claim (a document setting out the allegations which found the cause of action) within 14 days of issue of the Claim Form.

When used in civil proceedings in England and Wales, the term "complaint" refers to the mechanism by which civil proceedings are instituted in the magistrates' court and may be either written or oral.

A "demurrer" is a pleading (usually filed by a defendant) which objects to the legal sufficiency of the opponent's pleading (usually a complaint) and demands that the court rule immediately about whether the pleading is legally adequate before the party must plead on the merits in response. Since demurrer procedure required an immediate ruling like a motion, many common law jurisdictions therefore went to a narrower understanding of pleadings as framing the issues in a case but not being motions in and of themselves, and replaced the demurrer with the motion to dismiss for failure to state a cause of action or the application to strike out particulars of claim.

An "answer" is a pleading filed by a defendant which admits or denies the specific allegations set forth in a complaint and constitutes a general appearance by a defendant. In England and Wales, the equivalent pleading is called a Defence.

A defendant may also file a cross-complaint against another defendant named by the plaintiff, and may also file a "third-party complaint" bring other parties into a case by the process of impleader.

A defendant may file a "counter-claim" to raise a cause of action to defend, reduce or set off the claim of the plaintiff.

Common law pleading was the system of civil procedure used in England, which early on developed a strong emphasis on the form of action rather than the cause of action (as a result of the Provisions of Oxford, which severely limited the evolution of the common law writ system). The emphasis was on procedure over substance.

Law and equity evolved as separate judicial systems, each with its own procedures and remedies. Because the types of claims eligible for consideration was capped early during the development of the English legal system, claims that might have been acceptable to the courts' evolving sense of justice often did not match up perfectly with any of the established forms of action. Lawyers had to engage in great ingenuity to shoehorn their clients' claims into existing forms of action. The result was that at common law, pleadings were stuffed full of awkward legal fictions that had little to do with the actual "real-world" facts of the case. The placeholder name John Doe (still commonly used in American pleading to name unknown parties) is a remnant of this period.

In its final form in the 19th century, common law pleading was terribly complex and slow by modern standards. The parties would normally go through several rounds of pleadings before the parties were deemed to have clearly stated their controversy, so that the case was "at issue" and could proceed to trial. A case would begin with a complaint in which the plaintiff alleged the facts entitling him to relief, then the defendant would file any one of a variety of pleas as an answer, followed by a replication from the plaintiff, a rejoinder from the defendant, a surrejoinder from the plaintiff, a rebutter from the defendant, and a surrebutter from the plaintiff. At each stage, a party could file a demurrer to the other's pleading (essentially a request that the court immediately rule on whether the pleading was legally adequate before they had to file a pleading in response) or simply file another pleading in response.

Generally, a plea could be dilatory or peremptory. There were three kinds of dilatory plea: to the jurisdiction, in suspension, or in abatement. The first challenged the court's jurisdiction, the second asked the court to stay the action, and the third asked the court to dismiss the action without prejudice to the other side's right to bring the claims in another action or another court. A peremptory plea had only one kind: a plea in bar. A party making a plea in bar could either traverse the other side's pleading (i.e., deny all or some of the facts pleaded) or confess and avoid it (i.e., admit the facts pleaded but plead new ones that would dispel their effect). A traverse could be general (deny everything) or specific. Either side could plead imparlance in order to get more time to plead on the merits. Once the case was at issue, the defendant could reopen the pleadings in order to plead a newly discovered defense (and start the whole sequence again) by filing a plea puis darrein.

The result of all this complexity was that to ascertain what was "at issue" in a case, a stranger to the case (i.e., such as a newly appointed judge) would have to sift through a huge pile of pleadings to figure out what had happened to the original averments of the complaint and whether there was anything left to be actually adjudicated by the court.

Code pleading was first introduced in 1850 in New York and in 1851 in California, and eventually spread to 22 other states. Code pleading sought to abolish the distinction between law and equity. It unified civil procedure for all types of actions as much as possible. The focus shifted from pleading the right form of action (that is, the right procedure) to pleading the right cause of action (that is, a substantive right to be enforced by the law). 

Code pleading stripped out most of the legal fictions that had encrusted common law pleading by requiring parties to plead "ultimate facts." This means that to plead a cause of action, the pleader has to plead each element and also allege specific facts which, if proven with evidence at trial, would constitute proof of that element. Failure to provide such detail could lead to dismissal of the case if the defendant successfully demurred to the complaint on the basis that it merely stated "legal conclusions" or "evidentiary facts."

Code pleading also drastically shortened the pleading process. Most of the old common law pleadings were abolished. From now on, a case required only a complaint and an answer, with an optional cross-complaint and cross-answer, and with the demurrer kept as the standard attack on improper pleadings. Instead of piling layers and layers of pleadings and averments on top of each other, a pleading that was attacked by demurrer would either be completely superseded by an amended pleading or would proceed immediately "at issue" as to the validly pleaded parts. This meant that to determine what the parties were currently fighting about, a stranger to a case would no longer have to read the entire case file from scratch, but could (in theory) look "only" at the most recent version of the complaint filed by the plaintiff, the defendant's most recent answer to that complaint, and any court orders on demurrers to either pleading.

Code pleading was criticized because many lawyers felt that it was too difficult to fully research all the facts needed to bring a complaint "before" one had even initiated the action, and thus meritorious plaintiffs could not bring their complaints in time before the statute of limitations expired. Code pleading has also been criticized as promoting "hypertechnical reading of legal papers".

Notice pleading is the dominant form of pleading used in the United States today. In 1938, the Federal Rules of Civil Procedure were adopted to govern civil procedure in United States federal courts. One goal of the Federal Rules of Civil Procedure was to relax the strict rules of code pleading. However, each state also has its own rules of civil procedure, which may require different, looser, or stricter rules in state court.

Louisiana, a state that derives its legal tradition from the Spanish and French (as opposed to English common law), employs a system of fact pleading wherein it is only necessary to plead the facts that give rise to a cause of action. It is not necessary even for the petitioner to identify the cause of action being pleaded. Mere conclusory allegations such as "the defendant was negligent" are not, by themselves, sufficient to sustain a cause of action.

Other states, including Connecticut and New Jersey, are also fact-pleading jurisdictions. Illinois, for example, requires that a complaint "must assert a legally recognized cause of action and it must plead facts which bring the particular case within that cause of action."

In alternative pleading, legal fiction is employed to permit a party to argue two mutually exclusive possibilities, for example, submitting an injury complaint alleging that the harm to the plaintiff caused by the defendant was so outrageous that it must have either been intended as a malicious attack or, if not, must have been due to gross negligence.

The use of "pleaded" versus "pled" as the past tense version of "pleading" has been a subject of controversy among many of those that practice law. "Pled" is almost never used in Australian publications, while being somewhat common in American, British, and Canadian publications. In a 2010 search of the Westlaw legal database, "pled" is used in a narrow majority of cases over "pleaded". The AP stylebook and "The Chicago Manual of Style" call for "pleaded", and a Westlaw search shows the US Supreme Court has used pleaded in over 3,000 opinions and pled in only 26.




</doc>
<doc id="24808" url="https://en.wikipedia.org/wiki?curid=24808" title="Personal Communications Service">
Personal Communications Service

At the most basic level, Personal Communications Service (PCS) describes a set of communications capabilities which allows some combination of terminal mobility, personal mobility, and service profile management. More specifically, PCS refers to any of several types of wireless voice or wireless data communications systems, typically incorporating digital technology, providing services similar to advanced cellular mobile or paging services. In addition, PCS can also be used to provide other wireless communications services, including services which allow people to place and receive communications while away from their home or office, as well as wireless communications to homes, office buildings and other fixed locations. Described in more commercial terms, PCS is a generation of wireless-phone technology that combines a range of features and services surpassing those available in analog- and digital-cellular phone systems, providing a user with an all-in-one wireless phone, paging, messaging, and data service.

The International Telecommunication Union describes Personal Communications Services as a component of the IMT-2000 (3G) standard. PCS and the IMT-2000 standard of which PCS is a part do not specify a particular air interface and channel access method. Wireless service providers may deploy equipment using any of several air interface and channel access methods, as long as the network meets the service description characteristics described in the standard.

In Canada, Mexico and the United States, PCS are provided in the "1900 MHz band" (specifically 1850–1990 MHz). This frequency band was designated by the United States FCC and Industry Canada to be used for new wireless services to alleviate capacity caps inherent in the original AMPS and D-AMPS cellular networks in the "850 MHz band" (specifically 800–894 MHz). These frequency bands are particular to North America and other frequency bands may be designated in other regions.

In the United States, Sprint PCS was the first company to build and operate a PCS network, launching service in November 1995 under the "Sprint Spectrum" brand in the Baltimore-Washington metropolitan area. Sprint originally built out the network using GSM radio interface equipment. Sprint PCS later selected CDMA as the radio interface for its nationwide network and built out a parallel CDMA network in the Baltimore-Washington area, launching service in 1997. Sprint operated the two networks in parallel until finishing a migration of its area customers to the CDMA network. After completing the customer migration, Sprint PCS sold the GSM radio interface network equipment to Omnipoint Communications in January 2000. Omnipoint was later purchased by VoiceStream Wireless which subsequently became T-Mobile USA.




</doc>
<doc id="24809" url="https://en.wikipedia.org/wiki?curid=24809" title="PCS">
PCS

PCS may refer to:







</doc>
<doc id="24811" url="https://en.wikipedia.org/wiki?curid=24811" title="Puck">
Puck

Puck may refer to:






</doc>
<doc id="24815" url="https://en.wikipedia.org/wiki?curid=24815" title="Polaris Sales Agreement">
Polaris Sales Agreement

The Polaris Sales Agreement was a treaty between the United States and the United Kingdom which began the UK Polaris programme. The agreement was signed on 6 April 1963. It formally arranged the terms and conditions under which the Polaris missile system was provided to the United Kingdom.

The United Kingdom had been planning to buy the air-launched Skybolt missile to extend the operational life of the British V bombers, but the United States decided to cancel the Skybolt program in 1962 as it no longer needed the missile. The crisis created by the cancellation prompted an emergency meeting between the President of the United States, John F. Kennedy, and the Prime Minister of the United Kingdom, Harold Macmillan, which resulted in the Nassau Agreement, under which the United States agreed to provide Polaris missiles to the United Kingdom instead.

The Polaris Sales Agreement provided for the implementation of the Nassau Agreement. The United States would supply the United Kingdom with Polaris missiles, launch tubes, and the fire control system. The United Kingdom would manufacture the warheads and submarines. In return, the US was given certain assurances by the United Kingdom regarding the use of the missile, but not a veto on the use of British nuclear weapons. The British Polaris ballistic missile submarines were built on time and under budget, and came to be seen as a credible deterrent that enhanced Britain's international status.

Along with the 1958 US–UK Mutual Defence Agreement, the Polaris Sales Agreement became a pillar of the nuclear Special Relationship between Britain and the United States. The agreement was amended in 1982 to provide for the sale of the Trident missile system.

During the early part of the Second World War, Britain had a nuclear weapons project, codenamed Tube Alloys. In August 1943, the Prime Minister of the United Kingdom, Winston Churchill and the President of the United States, Franklin Roosevelt, signed the Quebec Agreement, which merged Tube Alloys with the American Manhattan Project. The British government trusted that the United States would continue to share nuclear technology, which it regarded as a joint discovery, but the 1946 McMahon Act ended cooperation. Fearing a resurgence of United States isolationism, and Britain losing its great power status, the British government restarted its own development effort, now codenamed High Explosive Research. The first British atomic bomb was tested in Operation Hurricane on 3 October 1952. The subsequent British development of the hydrogen bomb, and a favourable international relations climate created by the Sputnik crisis, led to the McMahon Act being amended in 1958, and the restoration of the nuclear Special Relationship in the form of the 1958 US–UK Mutual Defence Agreement (MDA), which allowed Britain to acquire nuclear weapons systems from the United States.

Britain's nuclear weapons armament was initially based on free-fall bombs delivered by the V bombers of the Royal Air Force (RAF), but the possibility of the manned bomber becoming obsolete by the late 1960s due to improvements in anti-aircraft defences was foreseen. In 1953, work began on a medium-range ballistic missile (MRBM) called Blue Streak, but by 1958, there were concerns about its vulnerability to a pre-emptive nuclear strike. To extend the effectiveness and operational life of the V bombers, an air-launched, rocket-propelled standoff missile called Blue Steel was developed, but it was anticipated that the air defences of the Soviet Union would improve to the extent that V bombers might still find it difficult to attack their targets. A solution appeared to be the American Skybolt missile, which combined the range of Blue Streak with the mobile basing of the Blue Steel, and was small enough that two could be carried on an Avro Vulcan bomber.

An institutional challenge to Skybolt came from the United States Navy, which was developing a submarine-launched ballistic missile (SLBM), the UGM-27 Polaris. The US Chief of Naval Operations, Admiral Arleigh Burke, kept the First Sea Lord, Lord Mountbatten, apprised of its development. By moving the deterrent out to sea, Polaris offered the prospect of a deterrent that was invulnerable to a first strike, and reduced the risk of a nuclear strike on the British Isles. The British Nuclear Deterrent Study Group (BNDSG) produced a study that argued that SLBM technology was as yet unproven, that Polaris would be expensive, and that given the time it would take to build the boats, it could not be deployed before the early 1970s. The Cabinet Defence Committee therefore approved the acquisition of Skybolt in February 1960. The Prime Minister, Harold Macmillan, met with the President, Dwight D. Eisenhower, in March 1960, and secured permission to buy Skybolt. In return, the Americans could base the US Navy's Polaris ballistic missile submarines in the Holy Loch in Scotland. The financial arrangement was particularly favourable to Britain, as the US was charging only the unit cost of Skybolt, absorbing all the research and development costs. With this agreement in hand, the cancellation of Blue Streak was announced in the House of Commons on 13 April 1960.

The subsequent American decision to cancel Skybolt created a political crisis in the UK, and an emergency meeting between Macmillan and President John F. Kennedy was called in Nassau, Bahamas. Macmillan rejected the US offers of paying half the cost of developing Skybolt, and of supplying the AGM-28 Hound Dog missile instead. This brought options down to Polaris, but the Americans would only supply it on condition that it be used as part of a proposed Multilateral Force (MLF). Kennedy ultimately relented, and agreed to supply Britain with Polaris missiles, while "the Prime Minister made it clear that except where Her Majesty's Government may decide that supreme national interests are at stake, these British forces will be used for the purposes of international defence of the Western Alliance in all circumstances." A joint statement to this effect, the Nassau Agreement, was issued on 21 December 1962.

With the Nassau Agreement in hand, it remained to work out the details. Vice Admiral Michael Le Fanu had a meeting with the United States Secretary of Defense, Robert S. McNamara, on 21 December 1962, the final day of the Nassau conference. He found McNamara eager to help, and enthusiastic about the idea of Polaris costing as little as possible. The first issue identified was how many Polaris boats should be built. While the Vulcans to carry Skybolt were already in service, the submarines to carry Polaris were not, and there was no provision in the defence budget for them. Some naval officers feared that their construction would adversely impact the hunter-killer submarine programme. The First Sea Lord, Admiral of the Fleet Sir Caspar John, denounced the "millstone of Polaris hung around our necks" as "potential wreckers of the real navy".

The number of missiles required was based on substituting for Skybolt. To achieve the same capability, the BNDSG calculated that this would require eight Polaris submarines, each of which would have 16 missiles, for a total of 128 missiles, with 128 one-megaton warheads. It was subsequently decided to halve this, based on the decision that the ability to destroy twenty Soviet cities would have nearly as great a deterrent effect as the ability to destroy forty. The Admiralty considered the possibility of hybrid submarines that could operate as hunter-killers while carrying eight Polaris missiles, but McNamara noted that this would be inefficient, as twice as many submarines would need to be on station to maintain the deterrent, and cautioned that the effect of tinkering with the US Navy's 16-missile layout was unpredictable. The Treasury costed a four-boat Polaris fleet at £314 million by 1972/73. A Cabinet Defence Committee meeting on 23 January 1963 approved the plan for four boats, with Thorneycroft noting that four boats would be cheaper and faster to build.

A mission led by Sir Solly Zuckerman, the Chief Scientific Adviser to the Ministry of Defence, left for the United States to discuss Polaris on 8 January 1963. It included the Vice Chief of the Naval Staff, Vice Admiral Sir Varyl Begg; the Deputy Secretary of the Admiralty, James Mackay; Rear Admiral Hugh Mackenzie; and physicist Sir Robert Cockburn and F. J. Doggett from the Ministry of Aviation. That the involvement of the Ministry of Aviation might be a complicating factor was foreseen, but it had experience with nuclear weapons development. Mackenzie had been the Flag Officer Submarines until 31 December 1962, when Le Fanu had appointed him the Chief Polaris Executive (CPE). As such, he was directly answerable to Le Fanu as Controller of the Navy. His CPE staff was divided between London and Foxhill, near Bath, Somerset, where Royal Navy had its ship design, logistics and weapons groups. It was intended as a counterpart to the United States Navy Special Projects Office (SPO), with whom it would have to deal.

The principal finding of the Zuckerman mission was that the Americans had developed a new version of the Polaris missile, the A3. With a range extended of , it had a new weapons bay housing three re-entry vehicles (REBs or Re-Entry Bodies in US Navy parlance) and a new W58 warhead to penetrate improved Soviet anti-missile defences expected to become available around 1970. A decision was therefore required on whether to purchase the old A2 missile or the new A3. The Zuckerman mission came out in favour of the new A3 missile, although it was still under development and not expected to enter service until August 1964, as the deterrent would remain credible for much longer. The decision was endorsed by the First Lord of the Admiralty, Lord Carrington, in May 1963, and was officially made by Thorneycroft on 10 June 1963.

The choice of the A3 created a problem for the Atomic Weapons Research Establishment (AWRE) at Aldermaston, for the Skybolt warhead that had recently been tested in the Tendrac nuclear test at the Nevada Test Site in the United States would require a redesigned Re-Entry System (RES) in order to be fitted to a Polaris missile, at an estimated cost of between £30 million and £40 million. The alternative was to make a British copy of the W58. While the AWRE was familiar with the W47 warhead used in the A2, it knew nothing of the W58. A presidential determination was required to release information on the W58 under the MDA, but with this in hand, a mission led by John Challens, the Chief of Warhead Development at the AWRE, visited the Lawrence Livermore Laboratory from 22 to 24 January 1963, and was shown details of the W58.
The Zuckerman mission found the SPO helpful and forthcoming, but there was one major shock. The British were expected to contribute to the research and development costs of the A3, backdated to 1 January 1963. These were expected to top $700 million by 1968. Skybolt had been offered to the UK at unit cost, with the US absorbing the research and development costs, but no such agreement had been reached at Nassau for Polaris. Thorneycroft baulked at the prospect of paying research and development costs, but McNamara pointed out that the United States Congress would not stand for an agreement that placed all the burden on the United States. Macmillan instructed the British Ambassador to the United States, Sir David Ormsby-Gore, to inform Kennedy that Britain was not willing to commit to an open-ended sharing of research and development costs, but, as a compromise, would pay an additional five per cent for each missile. He asked that Kennedy be informed that a breakdown of the Nassau Agreement would likely cause the fall of his government. Ormsby-Gore met with Kennedy that very day, and while Kennedy noted that the five per cent offer "was not the most generous offer he had ever heard of", he accepted it. McNamara, certain that the United States was being ripped off, calculated the five percent on top of not just the missiles, but their fire control and navigation systems as well, adding around £2 million to the bill. On Ormsby-Gore's advice, this formulation was accepted.

An American mission now visited the United Kingdom. This was led by Paul H. Nitze, the Assistant Secretary of Defense for International Security Affairs, and included Walt W. Rostow, the Director of Policy Planning at the State Department, and Admiral Ignatius J. Galantin, the head of the SPO. The Americans had ideas about how the programme should be organised. They foresaw the UK Polaris programme having project officers from both countries, with a Joint Steering Task Group that met regularly to provide advice. This was accepted, and would become part of the final agreement. However, a follow-up British mission under Leslie Williams, the Director General Atomic Weapons at the Ministry of Aviation, whose members included Challens and Rear Admiral Frederick Dossor, was given a letter by the SPO with a list of subjects that were off limits. These included penetration aids, which were held to be outside the scope of the Nassau Agreement.

One remaining obstacle in the path of the programme was how it would be integrated with the MLF. The British response to the MLF concept "ranged from unenthusiastic to hostile throughout the military establishment and in the two principal political parties". Apart from anything else, it was estimated to cost as much as £100 million over ten years. Nonetheless, the Foreign Office argued that Britain must support the MLF. The Nassau Agreement had invigorated the MLF effort in the United States. Kennedy appointed Livingston T. Merchant to negotiate the MLF with the European governments, which he did in February and March 1963. While reaffirming support for those parts of the Nassau Agreement concerning the MLF, the British were successful in getting them omitted from the Polaris Sales Agreement.
The British team completed drafting the agreement in March 1963, and copies were circulated for discussion. The contracts for their construction were announced that month. The Polaris boats would be the largest submarines built in Britain up to that time, and would be built by Vickers Armstrong Shipbuilders in Barrow-in-Furness and Cammell Laird in Birkenhead. For similar reasons to the US Navy, the Royal Navy decided to base the boats at Faslane, on the Gareloch, not far from the US Navy's base on the Holy Loch. The drawback of the site was that it isolated the Polaris boats from the rest of the navy. The Polaris Sales Agreement was signed in Washington, DC, on 6 April 1963 by Ormsby-Gore and Dean Rusk, the United States Secretary of State.

The two liaison officers were appointed in April; Captain Peter la Niece became the Royal Navy project officer in Washington, DC, while Captain Phil Rollings became the US Navy project officer in London. The Joint Steering Task Group held its first meeting in Washington on 26 June 1963. The shipbuilding programme would prove to be a remarkable achievement, with the four submarines built on time and within the budget. The first boat, was launched in September 1966, and commenced its first deterrent patrol in June 1968. The annual running costs of the Polaris boats came to around two per cent of the defence budget, and they came to be seen as a credible deterrent that enhanced Britain's international status. Along with the more celebrated 1958 US–UK Mutual Defence Agreement, the Polaris Sales Agreement became a pillar of the nuclear Special Relationship between Britain and the United States.

The Polaris Sales Agreement provided an established framework for negotiations over missiles and re-entry systems. The legal agreement took the form of amending the Polaris Sales Agreement through an exchange of notes between the two governments so that "Polaris" in the original now also covered the purchase of Trident. There were also some amendments to the classified annexes of the Polaris Sales Agreement to delete the exclusion of penetrating aids. Under the Polaris Sales Agreement, the United Kingdom paid a five per cent levy on the cost of equipment supplied in recognition of US research and development costs already incurred. For Trident, a payment of $116 million was substituted. The United Kingdom procured the Trident system from America and fitted them to their own submarines, which had only 16 missile tubes like Polaris rather than the 24 in the American . The first , , entered operational service in December 1994, by which time the Cold War had ended.



</doc>
<doc id="24818" url="https://en.wikipedia.org/wiki?curid=24818" title="Proto-Indo-Europeans">
Proto-Indo-Europeans

The Proto-Indo-Europeans were a hypothetical prehistoric ethnolinguistic group of Eurasia who spoke Proto-Indo-European (PIE), the ancestor of the Indo-European languages according to linguistic reconstruction.

Knowledge of them comes chiefly from that linguistic reconstruction, along with material evidence from archaeology and archaeogenetics. The Proto-Indo-Europeans likely lived during the late Neolithic, or roughly the 4th millennium BC. Mainstream scholarship places them in the Pontic–Caspian steppe zone in Eastern Europe (present day Ukraine and southern Russia). Some archaeologists would extend the time depth of PIE to the middle Neolithic (5500 to 4500 BC) or even the early Neolithic (7500 to 5500 BC), and suggest alternative location hypotheses.

By the early second millennium BC, descendants of the Proto-Indo-Europeans had reached far and wide across Eurasia, including Anatolia (Hittites), the Aegean (the ancestors of Mycenaean Greece), the north of Europe (Corded Ware culture), the edges of Central Asia (Yamnaya culture), and southern Siberia (Afanasievo culture).

Using linguistic reconstruction from old Indo-European languages such as Latin and Sanskrit, hypothetical features of the Proto-Indo-European language are deduced. Assuming that these linguistic features reflect culture and environment of the Proto-Indo-Europeans, the following cultural and environmental traits are widely proposed:

Researchers have made many attempts to identify particular prehistoric cultures with the Proto-Indo-European-speaking peoples, but all such theories remain speculative. 

The scholars of the 19th century who first tackled the question of the Indo-Europeans' original homeland (also called "Urheimat", from German), had essentially only linguistic evidence. They attempted a rough localization by reconstructing the names of plants and animals (importantly the beech and the salmon) as well as the culture and technology (a Bronze Age culture centered on animal husbandry and having domesticated the horse). The scholarly opinions became basically divided between a European hypothesis, positing migration from Europe to Asia, and an Asian hypothesis, holding that the migration took place in the opposite direction.

In the early 20th century, the question became associated with the expansion of a supposed "Aryan race", a fallacy promoted during the expansion of European empires and the rise of "scientific racism". The question remains contentious within some flavours of ethnic nationalism (see also Indigenous Aryans).

A series of major advances occurred in the 1970s due to the convergence of several factors. First, the radiocarbon dating method (invented in 1949) had become sufficiently inexpensive to be applied on a mass scale. Through dendrochronology (tree-ring dating), pre-historians could calibrate radiocarbon dates to a much higher degree of accuracy. And finally, before the 1970s, parts of Eastern Europe and Central Asia had been off limits to Western scholars, while non-Western archaeologists did not have access to publication in Western peer-reviewed journals. The pioneering work of Marija Gimbutas, assisted by Colin Renfrew, at least partly addressed this problem by organizing expeditions and arranging for more academic collaboration between Western and non-Western scholars.

The Kurgan hypothesis, the most widely held theory, depends on linguistic and archaeological evidence, but is not universally accepted. It suggests PIE origin in the Pontic-Caspian steppe during the Chalcolithic. A minority of scholars prefer the Anatolian hypothesis, suggesting an origin in Anatolia during the Neolithic. Other theories (Armenian hypothesis, Out of India theory, Paleolithic Continuity Theory, Balkan hypothesis) have only marginal scholarly support.

In regard to terminology, in the 19th and early 20th centuries, the term "Aryan" was used to refer to the Proto-Indo-Europeans and their descendants. However, "Aryan" more properly applies to the Indo-Iranians, the Indo-European branch that settled parts of the Middle East and South Asia, as only Indic and Iranian languages explicitly affirm the term as a self-designation referring to the entirety of their people, whereas the same Proto-Indo-European root (*aryo-) is the basis for Greek and Germanic word forms which seem only to denote the ruling elite of Proto-Indo-European (PIE) society. In fact, the most accessible evidence available confirms only the existence of a common, but vague, socio-cultural designation of "nobility" associated with PIE society, such that Greek socio-cultural lexicon and Germanic proper names derived from this root remain insufficient to determine whether the concept was limited to the designation of an exclusive, socio-political elite, or whether it could possibly have been applied in the most inclusive sense to an inherent and ancestral "noble" quality which allegedly characterized all ethnic members of PIE society. Only the latter could have served as a true and universal self-designation for the Proto-Indo-European people.

By the early twentieth century this term had come to be widely used in a racist context referring to a hypothesized white, blonde and blue eyed "master race", culminating with the pogroms of the Nazis in Europe. Subsequently, the term "Aryan" as a general term for Indo-Europeans has been largely abandoned by scholars (though the term "Indo-Aryan" is still used to refer to the branch that settled in Southern Asia).

According to some archaeologists, PIE speakers cannot be assumed to have been a single, identifiable people or tribe, but were a group of loosely related populations ancestral to the later, still partially prehistoric, Bronze Age Indo-Europeans. This view is held especially by those archaeologists who posit an original homeland of vast extent and immense time depth. However, this view is not shared by linguists, as proto-languages, like all languages before modern transport and communication, occupied small geographical areas over a limited time span, and were spoken by a set of close-knit communities—a tribe in the broad sense.

Researchers have put forward a great variety of proposed locations for the first speakers of Proto-Indo-European. Few of these hypotheses have survived scrutiny by academic specialists in Indo-European studies sufficiently well to be included in modern academic debate.

In 1956 Marija Gimbutas (1921–1994) first proposed the Kurgan hypothesis. The name originates from the "kurgans" (burial mounds) of the Eurasian steppes. The hypothesis suggests that the Indo-Europeans, a nomadic culture of the Pontic-Caspian steppe (now part of Eastern Ukraine and Southern Russia), expanded in several waves during the 3rd millennium BC. Their expansion coincided with the taming of the horse. Leaving archaeological signs of their presence (see battle-axe people), they subjugated the peaceful European neolithic farmers of Gimbutas' Old Europe. As Gimbutas' beliefs evolved, she put increasing emphasis on the patriarchal, patrilinear nature of the invading culture, sharply contrasting it with the supposedly egalitarian, if not matrilinear culture of the invaded, to a point of formulating essentially feminist archaeology. A modified form of this theory by JP Mallory (1945- ), dating the migrations earlier (to around 3500 BC) and putting less insistence on their violent or quasi-military nature, remains the most widely accepted view of the Proto-Indo-European expansion.

The Armenian hypothesis, based on the glottalic theory, suggests that the Proto-Indo-European language was spoken during the 4th millennium BC in the Armenian Highland. This Indo-Hittite model does not include the Anatolian languages in its scenario. The phonological peculiarities of PIE proposed in the glottalic theory would be best preserved in the Armenian language and the Germanic languages, the former assuming the role of the dialect which remained "in situ", implied to be particularly archaic in spite of its late attestation. Proto-Greek would be practically equivalent to Mycenean Greek and would date to the 17th century BC, closely associating Greek migration to Greece with the Indo-Aryan migration to India at about the same time (viz., Indo-European expansion at the transition to the Late Bronze Age, including the possibility of Indo-European Kassites). The Armenian hypothesis argues for the latest possible date of Proto-Indo-European ("sans" Anatolian), a full millennium later than the mainstream Kurgan hypothesis. In this, it figures as an opposite to the Anatolian hypothesis, in spite of the geographical proximity of the respective "Urheimaten" suggested, diverging from the time-frame suggested there by a full three millennia.

The Anatolian hypothesis proposes that the Indo-European languages spread peacefully into Europe from Asia Minor from around 7000 BC with the advance of farming ("wave of advance"). The leading propagator of the theory is Colin Renfrew. The culture of the Indo-Europeans as inferred by linguistic reconstruction raises difficulties for this theory, since early neolithic cultures had neither the horse, nor the wheel, nor metal, terms for all of which are securely reconstructed for Proto-Indo-European. Renfrew dismisses this argument, comparing such reconstructions to a theory that the presence of the word "café" in all modern Romance languages implies that the ancient Romans had cafés too. The linguistic counter-argument to this might state that whereas there can be no clear Proto-Romance reconstruction of the word "café" according to historical linguistic methodology, words such as "wheel" in the Indo-European languages clearly point to an archaic form of the protolanguage. Another argument against Renfrew is the fact that ancient Anatolia is known to have been inhabited by non-Indo-European Caucasian-speaking peoples, namely the Hattians, the Chalybes, and the Hurrians.

Following the publication of several studies on ancient DNA in 2015, Colin Renfrew has accepted the reality of migrations of populations speaking one or several Indo-European languages from the Pontic steppe towards Northwestern Europe.

The rise of archaeogenetic evidence which uses genetic analysis to trace migration patterns also added new elements to the origins puzzle.

The Kurgan hypothesis or steppe theory is the most widely accepted proposal to identify the Proto-Indo-European homeland from which the Indo-European languages spread out throughout Europe, Eurasia and parts of Asia. It postulates that the people of a Kurgan culture in the Pontic steppe north of the Black Sea were the most likely speakers of the Proto-Indo-European language (PIE). The term is derived from the Russian kurgan (курга́н), meaning tumulus or burial mound.

According to three autosomal DNA studies, haplogroups R1b and R1a, now the most common in Europe (R1a is also very common in South Asia) would have expanded from the Russian steppes, along with the Indo European languages; they also detected an autosomal component present in modern Europeans which was not present in Neolithic Europeans, which would have been introduced with paternal lineages R1b and R1a, as well as Indo European Languages. Studies which analysed ancient human remains in Ireland and Portugal suggest that R1b was introduced in these places along with autosomal DNA from the Eastern European steppes.

The subclade R1a1a (R-M17 or R-M198) is most commonly associated with Indo-European speakers, although the subclade R1b1a (P-297) has also been linked to the Centum branch of Indo-European. Data so far collected indicate that there are two widely separated areas of high frequency, one in Eastern Europe, around Poland and the Russian core, and the other in South Asia, around Indo-Gangetic Plain. The historical and prehistoric possible reasons for this are the subject of on-going discussion and attention amongst population geneticists and genetic genealogists, and are considered to be of potential interest to linguists and archaeologists also.

A large, 2014 study by Underhill et al., using 16,244 individuals from over 126 populations from across Eurasia, concluded there was compelling evidence, that R1a-M420 originated in the vicinity of Iran. The mutations that characterize haplogroup R1a occurred ~10,000 years BP. Its defining mutation (M17) occurred about 10,000 to 14,000 years ago. Pamjav et al. (2012) believe that R1a originated and initially diversified either within the Eurasian Steppes or the Middle East and Caucasus region.

Ornella Semino et al. propose a postglacial (Holocene) spread of the R1a1 haplogroup from north of the Black Sea during the time of the Late Glacial Maximum, which was subsequently magnified by the expansion of the Kurgan culture into Europe and eastward.

According to Jones et al. (2015) and Haak et al. (2015), Yamnaya culture was exclusively R1b, autosomic tests indicate that the Yamnaya-people were the result of admixture between "Eastern Hunter-Gatherers" from eastern Europe (EHG) and "Caucasus hunter-gatherers" (CHG).
Each of those two populations contributed about half the Yamnaya DNA. According to co-author Dr. Andrea Manica of the University of Cambridge: 
An analysis by David W. Anthony (2019) also suggests a genetic origin of proto-Indo-Europeans (the Yamnaya people) in the Eastern European steppe north of the Caucasus, derived from a mixture of Eastern European hunter-gatherers and hunter-gatherers from the Caucasus. Anthony also suggests that the proto-Indo-European language formed mainly from a base of languages spoken by Eastern European hunter-gathers with influences from languages of northern Caucasus hunter-gatherers, in addition to a possible later influence from the language of the Maikop culture to the south (which is hypothesized to have belonged to the North Caucasian family) in the later neolithic or bronze age involving little genetic impact.

According to Haak et al. (2015), "Eastern European hunter-gatherers" who inhabited Russia were a distinctive population of hunter-gatherers with high affinity to a ~24,000-year-old Siberian from Mal'ta-Buret' culture, or other, closely related Ancient North Eurasian (ANE) people from Siberia and to the Western Hunter Gatherers (WHG). Remains of the "Eastern European hunter-gatherers" have been found in Mesolithic or early Neolithic sites in Karelia and Samara Oblast, Russia, and put under analysis. Three such hunter-gathering individuals of the male sex have had their DNA results published. Each was found to belong to a different Y-DNA haplogroup: R1a, R1b, and J. R1b is also the most common Y-DNA haplogroup found among both the Yamnaya and modern-day Western Europeans.

The Near East population were most likely hunter-gatherers from the Caucasus (CHG) c.q. Iran Chalcolithic related people with a major CHG-component.

Jones et al. (2015) analyzed genomes from males from western Georgia, in the Caucasus, from the Late Upper Palaeolithic (13,300 years old) and the Mesolithic (9,700 years old). These two males carried Y-DNA haplogroup: J* and J2a. The researchers found that these Caucasus hunters were probably the source of the farmer-like DNA in the Yamnaya, as the Caucasians were distantly related to the Middle Eastern people who introduced farming in Europe. Their genomes showed that a continued mixture of the Caucasians with Middle Eastern took place up to 25,000 years ago, when the coldest period in the last Ice Age started.

According to Lazaridis et al. (2016), "a population related to the people of the Iran Chalcolithic contributed ~43% of the ancestry of early Bronze Age populations of the steppe." According to Lazaridis et al. (2016), these Iranian Chalcolithic people were a mixture of "the Neolithic people of western Iran, the Levant, and Caucasus Hunter Gatherers." Lazaridis et al. (2016) also note that farming spread at two places in the Near East, namely the Levant and Iran, from where it spread, Iranian people spreading to the steppe and south Asia.

Haak et al. (2015) studied DNA from 94 skeletons from Europe and Russia aged between 3,000 and 8,000 years old. They concluded that about 4,500 years ago there was a major influx into Europe of Yamnaya culture people originating from the Pontic-Caspian steppe north of the Black Sea and that the DNA of copper-age Europeans matched that of the Yamnaya.

A 2017 archaeogenetics study of Mycenaean and Minoan remains published in the journal "Nature" concluded that the Mycenaean Greeks were genetically closely related with the Minoans but unlike the Minoans also had a 13-18% genetic contribution from Bronze age steppe populations.

Luigi Luca Cavalli-Sforza and Alberto Piazza argue that Renfrew and Gimbutas reinforce rather than contradict each other. states that "It is clear that, genetically speaking, peoples of the Kurgan steppe descended at least in part from people of the Middle Eastern Neolithic who immigrated there from Turkey." Piazza and Cavalli-Sforza (2006) state that:
Spencer Wells suggests in a 2001 study that the origin, distribution and age of the R1a1 haplotype points to an ancient migration, possibly corresponding to the spread by the Kurgan people in their expansion across the Eurasian steppe around 3000 BC.

About his old teacher Cavalli-Sforza's proposal, states that "there is nothing to contradict this model, although the genetic patterns do not provide clear support either", and instead argues that the evidence is much stronger for Gimbutas' model:
David Reich (2018), noting the presence of some Indo-European languages (such as Hittite) in parts of ancient Anatolia, argues that "the most likely location of the population that first spoke an Indo-European language was south of the Caucasus Mountains, perhaps in present-day Iran or Armenia, because ancient DNA from people who lived there matches what we would expect for a source population both for the Yamnaya and for ancient Anatolians." Yet, Reich also notes that "...the evidence here is circumstantial as no ancient DNA from the Hittites themselves has yet been published." Kristian Kristiansen, in an interview with "Der Spiegel" in May 2018, stated that the Yamnaya culture may have had a predecessor at the Caucasus, where "proto-proto-Indo-European" was spoken.

Recent DNA-research has led to renewed suggestions of a Caucasian homeland for the 'proto-Indo-Europeans'. According to Kroonen et al. (2018), Damgaard et al. (2018) ancient Anatolia "show no indication of a large-scale intrusion of a steppe population." They further note that this lends support to the Indo-Hittite hypothesis, according to which both proto-Anatolian and proto-Indo-European split-off from a common mother language "no later than the 4th millennium BCE." Haak et al. (2015) states that "the Armenian plateau hypothesis gains in plausibility" since the Yamnaya partly descended from a Near Eastern population, which resembles present-day Armenians."

Wang et al. (2018) note that the Caucasus served as a corridor for gene flow between the steppe and cultures south of the Caucasus during the Eneolithic and the Bronze Age, stating that this "opens up the possibility of a homeland of PIE south of the Caucasus." However, Wang et al. also comment that the most recent genetic evidence supports an expansion of proto-Indo-Europeans through the steppe, noting: "but the latest ancient DNA results from South Asia also lend weight to a spread of Indo-European languages "via the steppe belt. The spread of some or all of the proto-Indo-European branches would have been possible via the North Caucasus and Pontic region and from there, along with pastoralist expansions, to the heart of Europe. This scenario finds support from the well attested and now widely documented 'steppe ancestry' in European populations, the postulate of increasingly patrilinear societies in the wake of these expansions (exemplified by R1a/R1b), as attested in the latest study on the Bell Beaker phenomenon."

However, David W. Anthony in a 2019 analysis, criticizes the "southern" or "Armenian" hypothesis (addressing Reich, Kristiansen, and Wang). Among his reasons being: that the Yamnaya lack evidence of genetic influence from the bronze age or late neolithic Caucasus (deriving instead from an earlier mixture of Eastern European hunter-gatherers and Caucasus hunter-gatherers) and have paternal lineages that seem to derive from the hunter-gatherers of the Eastern European Steppe rather than the Caucasus, as well as a scarcity in the Yamnaya of the Anatolian Farmer admixture that had become common and substantial in the Caucasus around 5,000 BC. Anthony instead suggests a genetic and linguistic origin of proto-Indo-Europeans (the Yamnaya) in the Eastern European steppe north of the Caucasus, from a mixture of these two groups (EHG and CHG). He suggests that the roots of Proto-Indo-European ("archaic" or proto-proto-Indo-European) were in the steppe rather than the south and that PIE formed mainly from a base of languages spoken by Eastern European hunter-gathers with some influences from languages of Caucasus hunter-gatherers.

The genetic basis of a number of physical features of the proto-Indo-European people were ascertained by the ancient DNA studies conducted by Haak "et al." (2015), Wilde "et al." (2014) and Mathieson "et al." (2015): they were genetically tall (phenotypic height is determined by both genetics and environmental factors), overwhelmingly dark-eyed (brown), dark-haired and had a skin colour that was moderately light, though somewhat darker than that of the average modern European.





</doc>
<doc id="24820" url="https://en.wikipedia.org/wiki?curid=24820" title="Peter Mark Roget">
Peter Mark Roget

Peter Mark Roget ( ; 18 January 1779 – 12 September 1869) was a British physician, natural theologian, lexicographer and founding Secretary of The Portico Library. He is best known for publishing, in 1852, the "Thesaurus of English Words and Phrases", a classified collection of related words. He also submitted a paper to the Royal Society documenting the phi phenomenon in 1824.

Peter Mark Roget was born in London, the son of Jean (John) Roget (1751–1783), a Genevan cleric, and his wife Catherine Romilly, sister of Samuel Romilly. After his father's death, the family moved to Edinburgh, in 1793, and he shortly began to study medicine at the University of Edinburgh, graduating in 1798. Samuel Romilly, who had supported his education, also introduced Roget into Whig social circles.

Roget then attended lectures at London medical schools. Living in Clifton, Bristol from 1798 to 1799, he knew Thomas Beddoes and Humphry Davy, and frequented the Pneumatic Institute.

Not making a quick start to a medical career, Roget in 1802 took a position as a tutor to the sons of John Leigh Philips, with whom he began a Grand Tour, during the Peace of Amiens, travelling with a friend Lovell Edgeworth, son of Richard Lovell Edgeworth. When the Peace abruptly ended, he was detained as a prisoner in Geneva. He was able to bring his pupils back to England, in late 1803, but Edgeworth was held in captivity until Napoleon's fall.

Roget became, with help from Samuel Romilly, private physician to William Petty, 1st Marquess of Lansdowne, who died in 1805. He then succeeded Thomas Percival at Manchester Infirmary, and began to lecture on physiology. He moved to London in 1808, and in 1809 became a licentiate of the Royal College of Physicians. After an extended period of dispensary work and lecturing, in particular at the Russell Institution and Royal Institution, he was taken onto the staff of the Queen Charlotte Hospital in 1817. He also lectured at the London Institution and the Windmill Street School.

Sir Samuel Romilly committed suicide, dying in Roget's presence, in 1818. Roget had been called in as adviser by the family, following the death of Lady Romilly.

In 1823 Roget and Peter Mere Latham were brought in to investigate disease at Millbank Penitentiary. In 1828 Roget, with William Thomas Brande and Thomas Telford, submitted a report on London's water supply. In 1834 he became the first Fullerian Professor of Physiology at the Royal Institution. One of those who helped found the University of London in 1837, he was an examiner in physiology there. He gave up medical practice in 1840.

Roget in later life became deaf, and was cared for by his daughter Kate. He died while on holiday in West Malvern, Worcestershire, aged 90, and is buried there in the cemetery of St James's Church.

Roget retired from professional life in 1840, and by 1846 was working on the book that perpetuates his memory today. It has been claimed that Roget struggled with depression for most of his life, and that the thesaurus arose partly from an effort to battle it. A biographer stated that his obsession with list-making as a coping mechanism was well established by the time Roget was eight years old. In 1805, he began to maintain a notebook classification scheme for words, organized by meaning. During this period he also moved to Manchester, where he became the first secretary of the Portico Library.

The catalogue of words was first printed in 1852, titled "Thesaurus of English Words and Phrases Classified and Arranged so as to Facilitate the Expression of Ideas and Assist in Literary Composition". During Roget's lifetime the work had twenty-eight printings. After his death it was revised and expanded by his son, John Lewis Roget (1828–1908), and later by John's son, the engineer Samuel Romilly Roget (1875–1953).

Roget was elected a Fellow of the Royal Society in 1815, in recognition of a paper on a slide rule with a loglog scale. He was a secretary of the Society from 1827 to 1848. On 9 December 1824, Roget presented a paper on a peculiar optical illusion to the "Philosophical Transactions", which was published in 1825, as "Explanation of an optical deception in the appearance of the spokes of a wheel when seen through vertical apertures." The paper was noted by Michael Faraday and by Joseph Plateau, who both mentioned it in their articles that presented new illusions with apparent motion. It has often been heralded as the basis for the persistence of vision theory, which has for a long time been falsely regarded as the principle causing the perception of motion in animation and film. In 1834, Roget claimed to have invented "the Phantasmascope or Phenakisticope" in the spring 1831, a few years before Plateau introduced this first device that demonstrated stroboscopic animation.

One of the promoters of the Medical and Chirurgical Society of London, which later became the Royal Society of Medicine, Roget was also a founder of the Society for the Diffusion of Useful Knowledge, writing a series of popular manuals for it. He wrote numerous papers on physiology and health, among them the fifth "Bridgewater Treatise", "Animal and Vegetable Physiology considered with reference to Natural Theology" (1834), and articles for the "Encyclopædia Britannica". He was hostile to phrenology, writing against it in a "Britannica" supplement in 1818, and devoting a two-volume work to it (1838).

A chess player, in an article in the "London and Edinburgh Philosophical Magazine" Roget solved the general open knight's tour problem. He composed chess problems, and designed an inexpensive pocket chessboard.


Canadian writer Keath Fraser published a story, "Roget's Thesaurus," in 1982, which is narrated in Roget's voice. He has Roget speak on his wife's death, from cancer.

Roget also appears in Shelagh Stephenson's "An Experiment with an Air Pump", set in 1799, as the only historical character. The play takes place in the fictional household of Joseph Fenwick, and Roget is one of Fenwick's assistants.

A picture book biography of Roget entitled "The Right Word: Roget and His Thesaurus" was published by Eerdmans Books in 2014. It was named a Caldecott Honor book for excellence in illustration and won the Sibert Medal for excellence in children's nonfiction.

In 1824 Roget married Mary Taylor (1795–1833), daughter of Jonathan Hobson. They had a son John Lewis (1828–1908), and a daughter Kate.



 


</doc>
<doc id="24823" url="https://en.wikipedia.org/wiki?curid=24823" title="Pterodactylus">
Pterodactylus

Pterodactylus (from Greek πτεροδάκτυλος, "pterodaktulos", meaning "winged finger") is an extinct genus of euctenochasmatian pterodactyloid pterosaur, whose members are commonly known as pterodactyls (). It is thought to contain only a single species, Pterodactylus antiquus, which was initially described as Ornithocephalus antiquus, but the generic name "Pterodactylus" had been considered the correct term for the animal, and therefore "P. antiquus" was designated as the type species of "Pterodactylus", and "O. antiquus" as an obsolete synonym of the former. "Pterodactylus" is also the first pterosaur genus to be named and identified as a flying reptile.

Fossil remains of "Pterodactylus" have primarily been found in the Solnhofen limestone of Bavaria, Germany, which dates back to the Late Jurassic period (early Tithonian stage), about 150.8 to 148.5 million years ago. More fragmentary remains of "Pterodactylus" have tentatively been identified from elsewhere in Europe, as well as in Africa.

Many studies conclude that "Pterodactylus" was a carnivore that probably preyed upon fish as well as other small animals. Like all pterosaurs, "Pterodactylus" had wings formed by a skin and muscle membrane stretching from its elongated fourth finger to its hind limbs. It was supported internally by collagen fibres and externally by keratinous ridges. "Pterodactylus" was a small pterosaur compared to other famous genera such as "Pteranodon" and "Quetzalcoatlus", and it also lived earlier, during the Late Jurassic period, while both "Pteranodon" and "Quetzalcoatlus" lived during the Late Cretaceous. "Pterodactylus" lived alongside other small pterosaurs such as the well-known "Rhamphorhynchus", as well as other genera such as "Scaphognathus", "Anurognathus" and "Ctenochasma". The classification of "Pterodactylus" has since been confusing to paleontologists. Some classify "Pterodactylus" within the clade Euctenochasmatia, while others just consider it as a basal member of the suborder Pterodactyloidea.

The type specimen of the animal now known as "Pterodactylus antiquus" was one of the first pterosaur fossils ever to be identified. The first "Pterodactylus" specimen was described by the Italian scientist Cosimo Alessandro Collini in 1784, based on a fossil skeleton that had been unearthed from the Solnhofen limestone of Bavaria. Collini was the curator of the "Naturalienkabinett", or nature cabinet of curiosities (a precursor to the modern concept of the natural history museum), in the palace of Charles Theodore, Elector of Bavaria at Mannheim. The specimen had been given to the collection by Count Friedrich Ferdinand zu Pappenheim around 1780, having been recovered from a lithographic limestone quarry in Eichstätt. The actual date of the specimen's discovery and entry into the collection is unknown however, and it was not mentioned in a catalogue of the collection taken in 1767, so it must have been acquired at some point between that date and its 1784 description by Collini. This makes it potentially the earliest documented pterosaur find; the "Pester Exemplar" of the species "Pterodactylus micronyx" was described in 1779 and possibly discovered earlier than the Mannheim specimen, but it was at first considered to be a fossilized crustacean, and it was not until 1856 that this species was properly described as a pterosaur by German paleontologist Hermann von Meyer.

In his first description of the Mannheim specimen, Collini did not conclude that it was a flying animal. In fact, Collini could not fathom what kind of animal it might have been, rejecting affinities with the birds or the bats. He speculated that it may have been a sea creature, not for any anatomical reason, but because he thought the ocean depths were more likely to have housed unknown types of animals. The idea that pterosaurs were aquatic animals persisted among a minority of scientists as late as 1830, when the German zoologist Johann Georg Wagler published a text on "amphibians" which included an illustration of "Pterodactylus" using its wings as flippers. Wagler went so far as to classify "Pterodactylus", along with other aquatic vertebrates (namely plesiosaurs, ichthyosaurs, and monotremes), in the class Gryphi, between birds and mammals.

The German/French scientist Johann Hermann was the one who first stated that "Pterodactylus" used its long fourth finger to support a wing membrane. Back in March 1800, Hermann alerted the prominent French scientist Georges Cuvier to the existence of Collini's fossil, believing that it had been captured by the occupying armies of Napoleon and sent to the French collections in Paris (and perhaps to Cuvier himself) as war booty; at the time special French political commissars systematically seized art treasures and objects of scientific interest. Hermann sent Cuvier a letter containing his own interpretation of the specimen (though he had not examined it personally), which he believed to be a mammal, including the first known life restoration of a pterosaur. Hermann restored the animal with wing membranes extending from the long fourth finger to the ankle and a covering of fur (neither wing membranes nor fur had been preserved in the specimen). Hermann also added a membrane between the neck and wrist, as is the condition in bats. Cuvier agreed with this interpretation, and at Hermann's suggestion, Cuvier became the first to publish these ideas in December 1800 in a very short description. However, contrary to Hermann, Cuvier was convinced the animal was a reptile.The specimen had not in fact been seized by the French. Rather, in 1802, following the death of Charles Theodore, it was brought to Munich, where Baron Johann Paul Carl von Moll had obtained a general exemption of confiscation for the Bavarian collections. Cuvier asked von Moll to study the fossil but was informed it could not be found. In 1809 Cuvier published a somewhat longer description, in which he named the animal "Petro-Dactyle", this was a typographical error however, and was later corrected by him to "Ptéro-Dactyle". He also refuted a hypothesis by Johann Friedrich Blumenbach that it would have been a shore bird. Cuvier remarked: "It is not possible to doubt that the long finger served to support a membrane that, by lengthening the anterior extremity of this animal, formed a good wing."

Contrary to von Moll's report, the fossil was not missing; it was being studied by Samuel Thomas von Sömmerring, who gave a public lecture about it on 27 December 1810. In January 1811, von Sömmerring wrote a letter to Cuvier deploring the fact that he had only recently been informed of Cuvier's request for information. His lecture was published in 1812, and in it von Sömmerring named the species "Ornithocephalus antiquus". The animal was described as being both a bat, and a form in between mammals and birds, i.e. not intermediate in descent but in "affinity" or archetype. Cuvier disagreed, and the same year in his "Ossemens fossiles" provided a lengthy description in which he restated that the animal was a reptile. It was not until 1817 that a second specimen of "Pterodactylus" came to light, again from Solnhofen. This tiny specimen was that year described by von Sömmerring as "Ornithocephalus brevirostris", named for its short snout, now understood to be a juvenile character (this specimen is now thought to represent a juvenile specimen of a different genus, probably "Ctenochasma"). He provided a restoration of the skeleton, the first one published for any pterosaur. This restoration was very inaccurate, von Sömmerring mistaking the long metacarpals for the bones of the lower arm, the lower arm for the humerus, this upper arm for the breast bone and this sternum again for the shoulder blades. Sömmerring did not change his opinion that these forms were bats and this "bat model" for interpreting pterosaurs would remain influential long after a consensus had been reached around 1860 that they were reptiles. The standard assumptions were that pterosaurs were quadrupedal, clumsy on the ground, furred, warmblooded and had a wing membrane reaching the ankle. Some of these elements have been confirmed, some refuted by modern research, while others remain disputed.

In 1815, the generic name "Ptéro-Dactyle" was latinized to "Pterodactylus" by Constantine Samuel Rafinesque. Unaware of Rafinesque's publication however, Cuvier himself in 1819 latinized the name "Ptéro-Dactyle" again to "Pterodactylus", but the specific name he then gave, "longirostris", has to give precedence to von Sömmerring's "antiquus". In 1888, English naturalist Richard Lydekker designated "Pterodactylus antiquus" as the type species of "Pterodactylus", and considered "Ornithocephalus antiquus" a synonym. He also designated specimen BSP AS.I.739 as the holotype of the genus.

"Pterodactylus" is known from over 30 fossil specimens, and though most belong to juveniles, many preserve complete skeletons. "Pterodactylus antiquus" was a relatively small pterosaur, with an estimated adult wingspan of about , based on the only known adult specimen, which is represented by an isolated skull. Other "species" were once thought to have been smaller. However, these smaller specimens have been shown to represent juveniles of "Pterodactylus", as well as its contemporary relatives including "Ctenochasma", "Germanodactylus", "Aurorazhdarcho", "Gnathosaurus", and hypothetically "Aerodactylus" if this genus is truly valid.

The skulls of adult "Pterodactylus" were long and thin, with about 90 narrow and conical teeth. The teeth extended back from the tips of both jaws, and became smaller farther away from the jaw tips, this was unlike the ones seen in most relatives, where teeth were absent in the upper jaw tip, and were relatively uniform in size. The teeth of "Pterodactylus" also extended farther back into the jaw compared to close relatives, and some were present below the front of the "nasoantorbital fenestra", which is the largest opening in the skull. Another autapomorphy that "Pterodactylus" has is that the skull and jaws were straight, which are unlike the upwardly curved jaws seen in the related ctenochasmatids.
"Pterodactylus", like related pterosaurs, had a crest on its skull composed mainly of soft tissues. In adult "Pterodactylus", this crest extended between the back edge of the antorbital fenestra and the back of the skull. In at least one specimen, the crest had a short bony base, also seen in related pterosaurs like "Germanodactylus". Solid crests have only been found on large, fully adult specimens of "Pterodactylus", indicating that this was a display structure that became larger and more well developed as individuals reached maturity. In 2013, pterosaur researcher S. Christopher Bennett noted that other authors claimed that the soft tissue crest of "Pterodactylus" extended backward behind the skull; Bennett himself, however, didn't find any evidence for the crest extending past the back of the skull. Two specimens of "P. antiquus" (the holotype specimen BSP AS I 739 and the incomplete skull BMMS 7, the largest known skull of "P. antiquus") have a low bony crest on their skulls; in BMMS 7 it is 47.5 mm long (1.87 inches, more or less 24% of the estimated total length of its skull) and has a maximum height of 0.9 mm (0.035 inches) above the orbit. Several specimens previously referred to "P. antiquus" preserved evidence of the soft tissue extensions of these crests, including an "occipital lappet", a flexible, tab-like structure extending from the back of the skull. Most of these specimens have been reclassified in the related species "Aerodactylus scolopaciceps", which may however be nothing more than a junior synonym. Even if "Aerodactylus" were valid, at least one specimen with these features is still considered to belong to "Pterodactylus", BSP 1929 I 18, which has an occipital lappet similar to the proposed "Aerodactylus" definition, and also possesses a small triangular soft tissue crest with the peak of the crest positioned above the eyes.

Like other pterosaurs (most notably "Rhamphorhynchus"), "Pterodactylus" specimens can vary considerably based on age or level of maturity. Both the proportions of the limb bones, size and shape of the skull, and size and number of teeth changed as the animals grew. Historically, this has led to various growth stages (including growth stages of related pterosaurs) being mistaken for new species of "Pterodactylus". Several detailed studies using various methods to measure growth curves among known specimens have suggested that there is actually only one valid species of "Pterodactylus", "P. antiquus".

The youngest immature specimens of "Pterodactylus antiquus" (alternately interpreted as young specimens of the distinct species "P. kochi") have a small number of teeth, as few as 15 in some, and the teeth have a relatively broad base. The teeth of other "P. antiquus" specimens are both narrower and more numerous (up to 90 teeth are present in several specimens).

"Pterodactylus" specimens can be divided into two distinct year classes. In the first year class, the skulls are only in length. The second year class is characterized by skulls of around long, but are still immature however. These first two size groups were once classified as juveniles and adults of the species "P. kochi", until further study showed that even the supposed "adults" were immature, and possibly belong to a distinct genus. A third year class is represented by specimens of the "traditional" "P. antiquus", as well as a few isolated, large specimens once assigned to "P. kochi" that overlap "P. antiquus" in size. However, all specimens in this third year class also show sign of immaturity. Fully mature "Pterodactylus" specimens remain unknown, or may have been mistakenly classified as a different genus.

The distinct year classes of "Pterodactylus antiquus" specimens show that this species, like the contemporary "Rhamphorhynchus muensteri", likely bred seasonally and grew consistently during its lifetime. A new generation of 1st year class "P. antiquus" would have been produced seasonally, and reached 2nd-year size by the time the next generation hatched, creating distinct 'clumps' of similarly-sized and aged individuals in the fossil record. The smallest size class probably consisted of individuals that had just begun to fly and were less than one year old. The second year class represents individuals one to two years old, and the rare third year class is composed of specimens over two years old. This growth pattern is similar to modern crocodilians, rather than the rapid growth of modern birds.

Comparisons between the scleral rings of "Pterodactylus antiquus" and modern birds and reptiles suggest that it may have been diurnal. This may also indicate niche partitioning with contemporary pterosaurs inferred to be nocturnal, such as "Ctenochasma" and "Rhamphorhynchus".

Specimens of "Pterodactylus" have been found mainly in the Solnhofen limestone (geologically known as the Altmühltal Formation) of Bavaria, Germany. The main composition of this formation is fine-grained limestone that originated mainly from the nearby towns Solnhofen and Eichstätt, which is formed by mud silt deposits. The Solnhofen Limestone is a diverse Lagerstätte that contains a wide range of different creatures, including highly detailed fossilized imprints of soft bodied organisms such as jellyfishes. Abundant specimens of pterosaurs similar to "Pterodactylus" were also found within the formation, these include the rhamphorhynchids "Rhamphorhynchus" and "Scaphognathus", several gallodactylids such as "Aerodactylus", "Ardeadactylus", "Aurorazhdarcho" and "Cycnorhamphus", the ctenochasmatids "Ctenochasma" and "Gnathosaurus", the anurognathid "Anurognathus", the germanodactylid "Germanodactylus", as well as the basal euctenochasmatian "Diopecephalus". Fossil remains of the dinosaurs "Archaeopteryx" and "Compsognathus" were also found within the limestone, these specimens were related to early evolution of feathers, since they were some of the only ones that had them during the Jurassic period. Various lizard remains were also found alongside those of "Pterodactylus", with several specimens assigned to "Ardeosaurus", "Bavarisaurus" and "Eichstaettisaurus". Crocodylomorph specimens were widely distributed within the fossil site, most were assigned to the metriorhynchid genera "Cricosaurus", "Dakosaurus", "Geosaurus" and "Rhacheosaurus". These genera are colloquially called as marine or sea crocodiles due to their similar built. The rhynchocephalian genera "Homoeosaurus" and "Pleurosaurus" were also found in the formation alongside several turtles such as "Eurysternum" and "Paleomedusa". Fossils of the ichthyosaur "Aegirosaurus" were also present in the site, as well as fish remains, with many specimens assigned to ray-finned fishes such as the halecomorphs "Lepidotes", "Propterus", "Gyrodus", "Mesturus", "Proscinetes", "Caturus", "Ophiopsis" and "Ophiopsiella", the pachycormids "Asthenocormus", "Hypsocormus" and "Orthocormus", as well as the aspidorhynchid "Aspidorhynchus", and the ichthyodectid "Thrissops".

Initial classifications for "Pterodactylus" started when paleontologist Hermann von Meyer used the name Pterodactyli to contain "Pterodactylus" and other pterosaurs known at the time. This was emended to the family Pterodactylidae by Prince Charles Lucien Bonaparte in 1838. However, this group has more recently been given several competing definitions.

Beginning in 2014, researchers Steven Vidovic and David Martill constructed an analysis in which several pterosaurs traditionally thought of as archaeopterodactyloids closely related to the ctenochasmatoids may have been more closely related to the more advanced dsungaripteroids, or in some cases, fall outside both groups. Their conclusion was published in 2017, in which they placed "Pterodactylus" as a basal member of the suborder Pterodactyloidea.
As illustrated below, the results of a different topology are based on a phylogenetic analysis made by Longrich, Martill, and Andres in 2018. Unlike the previous results above, they placed "Pterodactylus" within the clade Euctenochasmatia, resulting in a more derived position.

Numerous species have been assigned to "Pterodactylus" in the years since its discovery. In the first half of the 19th century any new pterosaur species would be named "Pterodactylus", which thus became a "wastebasket taxon". Even after clearly different forms had later been given their own generic name, new species would be created from the very productive sites, throughout Europe and North America, often based on only slightly different material.

The earliest reassignments of pterosaur species to "Pterodactylus" started in 1825, with the description of "Rhamphorhynchus"; fossil collector Georg Graf zu Münster alerted the German paleontologist Samuel Thomas von Sömmerring about several distinct fossil specimens, Sömmerring thought that they belonged to an ancient bird. Further fossil preparations had uncovered teeth, to which Graf zu Münster created a skull cast. He later sent the cast to Professor Georg August Goldfuss, who recognized it as a pterosaur, specifically a species of "Pterodactylus". At the time however, most paleontologists incorrectly consider the genus "Ornithocephalus" to be the valid name for "Pterodactylus", and therefore the specimen found was named as "Ornithocephalus Münsteri", which was first mentioned by Graf zu Münster himself. Another specimen was found and described by Graf zu Münster in 1839, he assigned this specimen to a new separate species called "Ornithocephalus longicaudus"; the specific name means "long tail", in reference to the animal's tail size. German paleontologist Hermann von Meyer in 1845 officially emended that the genus "Pterodactylus" had priority over "Ornithocephalus", so he reassigned the species "O. münsteri" and "O. longicaudus" into "Pterodactylus münsteri" and "Pterodactylus longicaudus". In 1846, von Meyer created the new species "Pterodactylus gemmingi" based on long-tailed remains; the specific name honors the fossil collector Carl Eming von Gemming. Later, in 1847, von Meyer finally erected the generic name "Rhamphorhynchus" (meaning "beak snout") due to the distinctively long tails seen in the specimens found, which are much longer than those seen in "Pterodactylus". He assigned the species "P. longicaudus" as the type species of "Rhamphorhynchus", which resulted in a new combination called "Rhamphorhynchus longicaudus". The species "R. münsteri" was later changed to "Rhamphorhynchus muensteri" by Lydekker in 1888, due to the ICZN rule that prohibits non-standard Latin characters, such as "ü", in scientific names.
Beginning in 1846, many pterosaur specimens were found near the village of Burham in Kent, England by British paleontologists James Scott Bowerbank and Sir Richard Owen. Bowerbank had assigned fossil remains to two new species; the first was named in 1846 as "Pterodactylus giganteus"; the specific name means "the gigantic one" in Latin, in reference to the large size of the remains, and the second species was named in 1851 as "Pterodactylus cuvieri", in honor of the French scientist Georges Cuvier. Later in 1851, Owen named and described new pterosaur specimens that have been found yet again in England. He assigned these specimens to a new species called "Pterodactylus compressirostris". In 1914 however, paleontologist Reginald Hooley redescribed "P. compressirostris", to which he erected the genus "Lonchodectes" (meaning "lance biter"), and therefore made "P. compressirostris" the type species, and created the new combination "L. compressirostris". In a 2013 review, "P. giganteus" and "P. cuvieri" were reassigned to new genera; "P. giganteus" was reassigned to a genus called "Lonchodraco" (meaning "lance dragon"), which resulted in a new combination called "L. giganteus", and "P. cuvieri" was reassigned to the new genus "Cimoliopterus" (meaning "chalk wing"), creating "C. cuvieri". Back in 1859, Owen had found remains the front part of a snout in the Cambridge Greensand, and assigned it into the species "Pterodactylus segwickii"; in honor of Adam Sedgwick, a British geologist. This species however, was reassigned to the genus "Camposipterus" in 2013, therefore creating the new combination "C. segwickii". Later, in 1861, Owen had uncovered multiple distinctively looking fossil remains yet again in the Cambridge Greensand, these were assigned to a new species named "Pterodactylus simus", though the British paleontologist Harry Govier Seeley had created a separate generic name called "Ornithocheirus", and reassigned "P. simus" as the type species, which created the combination "Ornithocheirus simus". Between the years 1869 and 1870, Seeley had reassigned many pterosaur species into "Ornithocheirus", while also creating several new species. Many if these species however, are now reclassified to other genera, or considered "nomina dubia". In 1874, further specimens were found in England, again by Owen, these ones were assigned to a new species called "Pterodactylus sagittirostris", this species however, was reassigned to the genus "Lonchodectes" in 1914 by Hooley, which resulted in an "L. sagittirostris". This conclusion was revised by Rigal "et al." in 2017, who disagreed with Hooley's reassignment, and therefore created the genus "Serradraco", which afterwards resulted in a new combination called "S. sagittirostris".
Assigning new pterosaur species to "Pterodactylus" was not only common in Europe, but also in North America; paleontologists such as Othniel Charles Marsh in 1871 for example, described several toothless pterosaur specimens, which were accompanied by teeth that belonged to the fish "Xiphactinus", which Marsh assumed that these teeth belonged to the pterosaur specimens he found, since all pterosaurs discovered at the time had teeth. He then assigned these specimens to a new species called ""Pterodactylus oweni"", but this was changed to "Pterodactylus occidentalis" because ""P. oweni"" was found to have been preoccupied by a pterosaur species described with the same name back in 1864 by Seeley. In 1872, American paleontologist Edward Drinker Cope also found various pterosaur specimens in North America, he assigned these to two new species known as "Ornithochirus umbrosus" and "Ornithochirus harpyia", Cope attempted to assign the specimens he found to the genus "Ornithocheirus", but misspelled forgetting the 'e'. In 1875 however, Cope reassigned the species "O. umbrosus" and "O. harpyia" into "Pterodactylus umbrosus" and "Pterodactylus harpyia", though these species had been considered "nomina dubia" ever since. Paleontologist Samuel Wendell Williston unearthed the first skull of the pterosaur, and found that the animal was toothless, this made Marsh create the genus "Pteranodon" (meaning "toothless wing"), and therefore reassigned all the American pterosaur species, including the ones that he named, from "Pterodactylus" to "Pteranodon".

Later, in the 1980s, subsequent revisions by Peter Wellnhofer had reduced the number of recognized species to about half a dozen. Many species assigned to "Pterodactylus" had been based on juvenile specimens, and subsequently been recognized as immature individuals of other species or genera. By the 1990s it was understood that this was even true for part of the remaining species. "P. elegans", for example, was found by numerous studies to be an immature "Ctenochasma". Another species of "Pterodactylus" originally based on small, immature specimens was "P. micronyx". However, it has been difficult to determine exactly of what genus and species "P. micronyx" might be the juvenile form. Stéphane Jouve, Christopher Bennett and others had once suggested that it probably belonged either to "Gnathosaurus subulatus" or one of the species belonging to "Ctenochasma", though after additional research Bennett assigned it to the genus "Aurorazhdarcho". Another species with a complex history is "P. longicollum", named by von Meyer in 1854, based on a large specimen with a long neck and fewer teeth. Many researchers, including David Unwin, have found "P. longicollum" to be distinct from "P. kochi" and "P. antiquus". Unwin found "P. longicollum" to be closer to "Germanodactylus" and therefore requiring a new genus name. It has sometimes been placed in the genus "Diopecephalus" because Harry Govier Seeley based this genus partly on the "P. longicollum" material. However, it was shown by Bennett that the type specimen later designated for "Diopecephalus" was a fossil belonging to "P. kochi", and no longer thought to be separate from "Pterodactylus". "Diopecephalus" is therefore a synonym of "Pterodactylus", and as such is unavailable for use as a new genus for ""P." longicollum". ""P." longicollum" was eventually made the type species of a separate genus "Ardeadactylus".

The only well-known and well-supported species left by the first decades of the 21st century were "P. antiquus" and "P. kochi". However, most studies between 1995 and 2010 found little reason to separate even these two species, and treated them as synonymous. More recent studies of pterosaur relationships have found anurognathids and pterodactyloids to be sister groups, which would limit the more inclusive group Caelidracones to just two clades. In 1996, Bennett suggested that the differences between specimens of "P. kochi" and "P. antiquus" could be explained by differences in age, with "P. kochi" (including specimens alternately classified in the species "P. scolopaciceps") representing an immature growth stage of "P. antiquus". In a 2004 paper, Jouve used a different method of analysis and recovered the same result, showing that the "distinctive" features of "P. kochi" were age-related, and using mathematical comparison to show that the two forms are different growth stages of the same species. An additional review of the specimens published in 2013 demonstrated that some of the supposed differences between "P. kochi" and "P. antiquus" were due to measurement errors, further supporting their synonymy.

By the 2010s, a large body of research had been developed based on the idea that "P. kochi" and "P. scolopaciceps" were early growth stages of "P. antiquus". However, in 2014, two scientists began publishing research that challenged this paradigm. Steven Vidovic and David Martill concluded that differences between specimens of "P. kochi", "P. scolopaciceps", and "P. antiquus", such as different lengths of neck vertebrae, thinner or thicker teeth, more rounded skulls, and how far the teeth extended back in the jaws, were significant enough to separate them into three distinct species. Vidovic and Martill also performed a phylogenetic analysis which treated all relevant specimens as distinct units, and found that the "P. kochi" type specimen did not form a natural group with that of "P. antiquus". They concluded that the genus "Diopecephalus" could be returned to use to distinguish ""P". kochi" from "P. antiquus". They named the new genus "Aerodactylus" for "P. scolopaciceps" as well. So, what Bennett considered early growth stages of one species, Vidovic and Martill considered representatives of new species.

In 2017, Bennett challenged this hypothesis, he claimed that while Vidovic and Martill had identified real differences between the these three groups of specimens, they had not provided any rationale that the differences were enough to distinguish them as species, rather than just individual variation, growth changes, or simply due to crushing and distortion during the fossilization process. Bennett pointed in particular to the data used to distinguish "Aerodactylus", which was so different from the data for related species, it might be due to an unnatural assemblage of specimens. As a result, Bennett continued to consider "Diopecephalus" and "Aerodactylus" simply as year-classes of immature "Pterodactylus antiquus".

During its over-200-year history, the various species of "Pterodactylus" have gone through a number of changes in classification and thus have acquired a large number of synonyms. Additionally, a number of species assigned to "Pterodactylus" are based on poor remains that have proven difficult to assign to one species or another and are therefore considered "nomina dubia" (meaning "doubtful names"). The following list includes names that were used to identify new pterosaur species that now have been reclassified, or until recently thought to be pertaining to "Pterodactylus" proper, and names based on other material that has as yet not been assigned to other genera. This list also includes species that are "nomina nuda" (meaning "naked names"), which are species that were not published formally. Species that are "nomina oblita" (meaning "forgotten names") are the ones that have been disused, and species that are "nomina rejecta" (meaning "rejected names") are the ones that have been rejected because a more preferable name had been accepted instead.

"Pterodactylus" is regarded as one of the most iconic prehistoric creatures, with multiple appearances in books, movies, as well as television series and several videogames. The informal name "pterodactyl" is sometimes used to refer to any kind of animal belonging to the order Pterosauria, though most of the times to "Pterodactylus", as its the most well-known member of the group. The popular aspect of "Pterodactylus" consists of an elongated head crest, and potentially large wings. Studies of "Pterodactylus" however, conclude that it may even lack a bony cranial crest, though several analysis have proven that "Pterodactylus" may in fact have a crest made up of soft tissue instead of bone.

"Pterodactylus" is the star character of the 2005 horror film "Pterodactyl", where it is identified with the informal name "pterodactyl", hence the name of the film. In the film, the "pterodactyls" resemble the aspect of the distantly related genus "Pteranodon" due to the elongated bony cranial crest, and their enormous size. One peculiar feature that "Pterodactylus" had in the film is the possession of teeth, while this is generally accurate for "Pterodactylus", the overall appearance of the creatures in the film is similar to that of "Pteranodon", as well as the large size, this makes them resemble some kind of pterosaur identical to "Pteranodon", but with the possession of teeth.

Another appearance of "Pterodactylus"-like creatures is in J. R. R. Tolkien's Middle-earth legendarium. In this novel, the Nazgûl, introduced as the Black Riders, are nine characters who rode flying monsters that looked similar in built to "Pterodactylus". Christopher Tolkien, the son of the author, described the flying monsters as "Nazgûl-birds"; his father described the appearance of the steeds as somewhat "pterodactylic", and acknowledged that these were obviously "new mythology".




</doc>
<doc id="24824" url="https://en.wikipedia.org/wiki?curid=24824" title="Pterosaur">
Pterosaur

Pterosaurs (; from Greek "pteron" and "sauros", meaning "wing lizard") were flying reptiles of the extinct clade or order Pterosauria. They existed during most of the Mesozoic: from the late Triassic to the end of the Cretaceous (228 to 66 million years ago). Pterosaurs are the earliest vertebrates known to have evolved powered flight. Their wings were formed by a membrane of skin, muscle, and other tissues stretching from the ankles to a dramatically lengthened fourth finger.

There were two major types of pterosaurs. Basal pterosaurs (also called 'non-pterodactyloid pterosaurs' or 'rhamphorhynchoids') were smaller animals with fully toothed jaws and, typically, long tails. Their wide wing membranes probably included and connected the hind legs. On the ground, they would have had an awkward sprawling posture, but their joint anatomy and strong claws would have made them effective climbers, and they may have lived in trees. Basal pterosaurs were insectivores or predators of small vertebrates. Later pterosaurs (pterodactyloids) evolved many sizes, shapes, and lifestyles. Pterodactyloids had narrower wings with free hind limbs, highly reduced tails, and long necks with large heads. On the ground, pterodactyloids walked well on all four limbs with an upright posture, standing plantigrade on the hind feet and folding the wing finger upward to walk on the three-fingered "hand". They could take off from the ground, and fossil trackways show at least some species were able to run and wade or swim. Their jaws had horny beaks, and some groups lacked teeth. Some groups developed elaborate head crests with sexual dimorphism. 

Pterosaurs sported coats of hair-like filaments known as pycnofibers, which covered their bodies and parts of their wings. Pycnofibers grew in several forms, from simple filaments to branching down feathers. These are homologous to the down feathers found on both avian and some non-avian dinosaurs, suggesting that early feathers evolved in the common ancestor of pterosaurs and dinosaurs, possibly as insulation. In life, pterosaurs would have had smooth or fluffy coats that did not resemble bird feathers. They were warm-blooded (endothermic) active animals. The respiratory system had efficient unidirectional "flow-through" breathing using air sacs, which hollowed out their bones to an extreme extent. Pterosaurs spanned a wide range of adult sizes, from the very small anurognathids to the largest known flying creatures of all time, including "Quetzalcoatlus" and "Hatzegopteryx", which reached wingspans of at least nine metres. The combination of endothermy, a good oxygen supply and strong muscles made pterosaurs powerful and capable flyers.

Pterosaurs are often referred to by popular media or the general public as "flying dinosaurs", but dinosaurs are defined as the descendants of the last common ancestor of the Saurischia and Ornithischia, which excludes the pterosaurs. Pterosaurs are nonetheless more closely related to birds and other dinosaurs than to crocodiles or any other living reptile, though they are not bird ancestors. Pterosaurs are also colloquially referred to as pterodactyls, particularly in fiction and by journalists. However, technically, "pterodactyl" only refers to members of the genus "Pterodactylus", and more broadly to members of the suborder Pterodactyloidea of the pterosaurs.

Pterosaurs had a variety of lifestyles. Traditionally seen as fish-eaters, the group is now understood to have included hunters of land animals, insectivores, fruit eaters and even predators of other pterosaurs. They reproduced by eggs, some fossils of which have been discovered.

The anatomy of pterosaurs was highly modified from their reptilian ancestors by the adaptation to flight. Pterosaur bones were hollow and air-filled, like those of birds. This provided a higher muscle attachment surface for a given skeletal weight. The bone walls were often paper-thin. They had a large and keeled breastbone for flight muscles and an enlarged brain able to coordinate complex flying behaviour. Pterosaur skeletons often show considerable fusion. In the skull, the sutures between elements disappeared. In some later pterosaurs, the backbone over the shoulders fused into a structure known as a notarium, which served to stiffen the torso during flight, and provide a stable support for the shoulder blade. Likewise, the sacral vertebrae could form a single synsacrum while the pelvic bones fused also.

Basal pterosaurs include the clades Dimorphodontidae ("Dimorphodon"), Campylognathididae ("Eudimorphodon", "Campyognathoides"), and Rhamphorhynchidae ("Rhamphorhynchus", "Scaphognathus"). 

Pterodactyloids include the clades Ornithocheiroidea ("Istiodactylus", "Ornithocheirus", "Pteranodon"), Ctenochasmatoidea ("Ctenochasma", "Pterodactylus"), Dsungaripteroidea ("Germanodactylus", "Dsungaripterus"), and Azhdarchoidea ("Tapejara", "Tupuxuara", "Quetzalcoatlus").

The two groups overlapped in time, but the earliest pterosaurs in the fossil record are basal pterosaurs, and the latest pterosaurs are pterodactyloids. 

The position of the clade Anurognathidae ("Anurognathus, Jeholopterus, Vesperopterylus") is debated. Anurognathids (frog-headed pterosaurs) were highly specialized. Small flyers with shortened jaws and a wide gape, some had large eyes suggesting nocturnal or crepescular habits, mouth bristles, and feet adapted for clinging. Parallel adaptations are seen in birds and bats that prey on insects in flight. 

Pterosaurs had a wide range of sizes. Generally they were rather large. Even the smallest species had a wingspan no less than . The most sizeable forms represent the largest known animals ever to fly, with wingspans of up to .

Standing, such giants could reach the height of a modern giraffe. Traditionally, it was assumed that pterosaurs were extremely light relative to their size. Later, it was understood that this would imply unrealistically low densities of their soft tissues. Some modern estimates therefore extrapolate a weight of up to for the largest species.

Compared to the other vertebrate flying groups, the birds and bats, pterosaur skulls were typically quite large. Most pterosaur skulls had elongated jaws. Their skull bones tend to be fused in adult individuals. Early pterosaurs often had heterodont teeth, varying in build, and some still had teeth in the palate. In later groups the teeth mostly became conical. Front teeth were often longer, forming a "prey grab" in transversely expanded jaw tips, but size and position were very variable among species. With the derived Pterodactyloidea, the skulls became even more elongated, sometimes surpassing the combined neck and torso in length. This was caused by a stretching and fusion of the front snout bone, the premaxilla, with the upper jaw bone, the maxilla. Unlike most archosaurs, the nasal and antorbital openings of pterodactyloid pterosaurs merged into a single large opening, called the "nasoantorbital fenestra". This feature likely evolved to lighten the skull for flight. In contrast, the bones behind the eye socket contracted and rotated, strongly inclining the rear skull and bringing the jaw joint forward. The braincase was relatively large for reptiles.

In some cases, fossilized keratinous beak tissue has been preserved, though in toothed forms, the beak is small and restricted to the jaw tips and does not involve the teeth. Some advanced beaked forms were toothless, such as the Pteranodontidae and Azhdarchidae, and had larger, more extensive, and more bird-like beaks. Some groups had specialised tooth forms. The Istiodactylidae had recurved teeth for eating meat. Ctenochasmatidae used combs of numerous needle-like teeth for filter feeding; "Pterodaustro" could have over a thousand bristle-like teeth. Dsungaripteridae covered their teeth with jawbone tissue for a crushing function. If teeth were present, they were placed in separate tooth sockets. Replacement teeth were generated behind, not below, the older teeth.

The public image of pterosaurs is defined by their elaborate head crests. This was influenced by the distinctive backward-pointing crest of the well-known "Pteranodon". The main positions of such crests are the front of the snout, as an outgrowth of the premaxillae, or the rear of the skull as an extension of the parietal bones in which case it is called a "supraoccipital crest". Front and rear crests can be present simultaneously and might be fused into a single larger structure, the most expansive of which is shown by the Tapejaridae. "Nyctosaurus" sported a bizarre antler-like crest. The crests were only a few millimetres thin transversely. The bony crest base would typically be extended by keratinous or other soft tissue.

Since the 1990s, new discoveries and a more thorough study of old specimens have shown that crests are far more widespread among pterosaurs than previously assumed. That they were extended by or composed completely of keratin, which does not fossilize easily, had misled earlier research. For "Pterorhynchus" and "Pterodactylus", the true extent of these crests has only been uncovered using ultraviolet photography. While fossil crests used to be restricted to the more advanced Pterodactyloidea, "Pterorhynchus" and "Austriadactylus" show that even some early pterosaurs possessed them.

Like the upper jaws, the paired lower jaws of pterosaurs were very elongated. In advanced forms, they tended to be shorter than the upper cranium because the jaw joint was in a more forward position. The front lower jaw bones, the dentaries or "ossa dentalia", were at the tip tightly fused into a central symphysis. This made the lower jaws function as a single connected whole, the mandible. The symphysis was often very thin tranversely and long, accounting for a considerable part of the jaw length, up to 60%. If a crest was present on the snout, the symphysis could feature a matching mandible crest, jutting out to below. Toothed species also bore teeth in their dentaries. The mandible opened and closed in a simple vertical or "orthal" up-and-down movement.

The vertebral column of pterosaurs numbered between thirty-four and seventy vertebrae. The vertebrae in front of the tail were "procoelous": the cotyle (front of the vertebral body) was concave and into it fitted a convex extension at the rear of the preceding vertebra, the condyle. Advanced pterosaurs are unique in possessing special processes projecting adjacent to their condyle and cotyle, the exapophyses, and the cotyle also may possess a small prong on its midline called a hypapophysis.

The neck of pterosaurs was relatively long and straight. In pterodactyloids, the neck is typically longer than the torso. This length is not caused by an increase of the number of vertebrae, which is invariably seven. Some researchers include two transitional "cervicodorsals" which brings the number to nine. Instead, the vertebrae themselves became more elongated, up to eight times longer than wide. Nevertheless, the cervicals were wider than high, implying a better vertical than horizontal neck mobility. Pterodactyloids have lost all neck ribs. Pterosaur necks were probably rather thick and well-muscled, especially vertically.

The torso was relatively short and egg-shaped. The vertebrae in the back of pterosaurs originally might have numbered eighteen. With advanced species a growing number of these tended to be incorporated into the sacrum. Such species also often show a fusion of the front dorsal vertebrae into a rigid whole which is called the notarium after a comparable structure in birds. This was an adaptation to withstand the forces caused by flapping the wings. The notarium included three to seven vertebrae, depending on the species involved but also on individual age. These vertebrae could be connected by tendons or a fusion of their neural spines into a "supraneural plate". Their ribs also would be tightly fused into the notarium. In general, the ribs are double-headed. The sacrum consisted of three to ten sacral vertebrae. They too, could be connected via a supraneural plate that, however, would not contact the notarium.

The tails of pterosaurs were always rather slender. This means that the caudofemoralis retractor muscle which in most basal Archosauria provides the main propulsive force for the hindlimb, was relatively unimportant. The tail vertebrae were amphicoelous, the vertebral bodies on both ends being concave. Early species had long tails, containing up to fifty caudal vertebrae, the middle ones stiffened by elongated articulation processes, the zygapophyses, and chevrons. Such tails acted as rudders, sometimes ending at the rear in a vertical diamond-shaped or oval vane. In pterodactyloids, the tails were much reduced and never stiffened, with some species counting as few as ten vertebrae.

The shoulder girdle was a strong structure that transferred the forces of flapping flight to the thorax. It was probably covered by thick muscle layers. The upper bone, the shoulder blade, was a straight bar. It was connected to a lower bone, the coracoid that is relatively long in pterosaurs. In advanced species, their combined whole, the scapulocoracoid, was almost vertically oriented. The shoulder blade in that case fitted into a recess in the side of the notarium, while the coracoid likewise connected to the breastbone. This way, both sides together made for a rigid closed loop, able to withstand considerable forces. A peculiarity was that the breastbone connections of the coracoids often were asymmetrical, with one coracoid attached in front of the other. In advanced species the shoulder joint had moved from the shoulder blade to the coracoid. The joint was saddle-shaped and allowed considerable movement to the wing. It faced sideways and somewhat upwards.

The breastbone, formed by fused paired "sterna", was wide. It had only a shallow keel. Via sternal ribs, it was at its sides attached to the dorsal ribs. At its rear, a row of belly ribs or gastralia was present, covering the entire belly. To the front, a long point, the "cristospina", jutted obliquely upwards. The rear edge of the breastbone was the deepest point of the thorax. Clavicles or interclavicles were completely absent.

Pterosaur wings were formed by bones and membranes of skin and other tissues. The primary membranes attached to the extremely long fourth finger of each arm and extended along the sides of the body. Where they ended has been very controversial but since the 1990s a dozen specimens with preserved soft tissue have been found that seem to show they attached to the ankles. The exact curvature of the trailing edge, however, is still equivocal.

While historically thought of as simple leathery structures composed of skin, research has since shown that the wing membranes of pterosaurs were highly complex dynamic structures suited to an active style of flight. The outer wings (from the tip to the elbow) were strengthened by closely spaced fibers called "actinofibrils". The actinofibrils themselves consisted of three distinct layers in the wing, forming a crisscross pattern when superimposed on one another. The function of the actinofibrils is unknown, as is the exact material from which they were made. Depending on their exact composition (keratin, muscle, elastic structures, etc.), they may have been stiffening or strengthening agents in the outer part of the wing. The wing membranes also contained a thin layer of muscle, fibrous tissue, and a unique, complex circulatory system of looping blood vessels. The combination of actinofibrils and muscle layers may have allowed the animal to adjust the wing slackness and camber.

As shown by cavities in the wing bones of larger species and soft tissue preserved in at least one specimen, some pterosaurs extended their system of respiratory air sacs into the wing membrane.

The pterosaur wing membrane is divided into three basic units. The first, called the "propatagium" ("fore membrane"), was the forward-most part of the wing and attached between the wrist and shoulder, creating the "leading edge" during flight. The "brachiopatagium" ("arm membrane") was the primary component of the wing, stretching from the highly elongated fourth finger of the hand to the hindlimbs. Finally, at least some pterosaur groups had a membrane that stretched between the legs, possibly connecting to or incorporating the tail, called the uropatagium; the extent of this membrane is not certain, as studies on "Sordes" seem to suggest that it simply connected the legs but did not involve the tail (rendering it a cruropatagium). A common interpretation is that non-pterodactyloid pterosaurs had a broader uro/cruropatagium stretched between their long fifth toes, with pterodactyloids, lacking such toes, only having membranes running along the legs.
There has been considerable argument among paleontologists about whether the main wing membranes (brachiopatagia) attached to the hindlimbs, and if so, where. Fossils of the rhamphorhynchoid "Sordes", the anurognathid "Jeholopterus", and a pterodactyloid from the Santana Formation seem to demonstrate that the wing membrane did attach to the hindlimbs, at least in some species. However, modern bats and flying squirrels show considerable variation in the extent of their wing membranes and it is possible that, like these groups, different species of pterosaur had different wing designs. Indeed, analysis of pterosaur limb proportions shows that there was considerable variation, possibly reflecting a variety of wing-plans.

The bony elements of the arm formed a mechanism to support and extend the wing. Near the body, the humerus or upper arm bone is short but powerfully built. It sports a large deltopectoral crest, to which the major flight muscles are attached. Despite the considerable forces exerted on it, the humerus is hollow or pneumatised inside, reinforced by bone struts. The long bones of the lower arm, the ulna and radius, are much longer than the humerus. They were probably incapable of pronation.

A bone unique to pterosaurs, known as the pteroid, connected to the wrist and helped to support the forward membrane (the propatagium) between the wrist and shoulder. Evidence of webbing between the three free fingers of the pterosaur forelimb suggests that this forward membrane may have been more extensive than the simple pteroid-to-shoulder connection traditionally depicted in life restorations. The position of the pteroid bone itself has been controversial. Some scientists, notably Matthew Wilkinson, have argued that the pteroid pointed forward, extending the forward membrane and allowing it to function as an adjustable flap. This view was contradicted in a 2007 paper by Chris Bennett, who showed that the pteroid did not articulate as previously thought and could not have pointed forward, but rather was directed inward toward the body as traditionally interpreted. David Peters in 2009 proposed that the pteroid articulated with the 'saddle' of the radiale (proximal syncarpal) and both the pteroid and preaxial carpal were migrated centralia. This seems to be confirmed by specimens of "Changchengopterus pani" and "Darwinopterus linglongtaensis" showing the pteroid in articulation with the proximal syncarpal.

The pterosaur wrist consists of two inner (proximal, at the side of the long bones of the arm) and four outer (distal, at the side of the hand) carpals (wrist bones), excluding the pteroid bone, which may itself be a modified distal carpal. The proximal carpals are fused together into a "syncarpal" in mature specimens, while three of the distal carpals fuse to form a distal syncarpal. The remaining distal carpal, referred to here as the medial carpal, but which has also been termed the distal lateral, or pre-axial carpal, articulates on a vertically elongate biconvex facet on the anterior surface of the distal syncarpal. The medial carpal bears a deep concave fovea that opens anteriorly, ventrally and somewhat medially, within which the pteroid articulates, according to Wilkinson.

In derived pterodactyloids like pteranodontians and azhdarchoids, metacarpals I-III are small and do not connect to the carpus, instead hanging in contact with the fourth metacarpal. With these derived species, the fourth metacarpal has been enormously elongated, typically equalling or exceeding the length of the long bones of the lower arm. The fifth metacarpal had been lost. In all species, the first to third fingers are much smaller than the fourth, the "wingfinger", and contain two, three and four phalanges respectively. The smaller fingers are clawed, with the ungual size varying among species. In nyctosaurids the forelimb digits besides the wingfinger have been lost altogether. The wingfinger accounts for about half or more of the total wing length. It normally consists of four phalanges. Their relative lengths tend to vary among species, which has often been used to distinguish related forms. The fourth phalanx is usually the shortest. It lacks a claw and has been lost completely by nyctosaurids. It is curved to behind, resulting in a rounded wing tip, which reduces induced drag. The wingfinger is also bent somewhat downwards.

When standing, pterosaurs probably rested on their metacarpals, with the outer wing folded to behind. In this position, the "anterior" sides of the metacarpals were rotated to the rear. This would point the smaller fingers obliquely to behind. According to Bennett, this would imply that the wingfinger, able to describe the largest arc of any wing element, up to 175°, was not folded by flexion but by an extreme extension. The wing was automatically folded when the elbow was bowed.

The pelvis of pterosaurs was of moderate size compared to the body as a whole. Often the three pelvic bones were fused. The ilium was long and low, its front and rear blades projecting horizontally beyond the edges of the lower pelvic bones. Despite this length, the rod-like form of these processes indicates that the hindlimb muscles attached to them were limited in strength. The, in side view narrow, pubic bone fused with the broad ischium into an ischiopubic blade. Sometimes, the blades of both sides were also fused, closing the pelvis from below and forming the pelvic canal. The hip joint was not perforated and allowed considerable mobility to the leg. It was directed obliquely upwards, preventing a perfectly vertical position of the leg.

The front of the pubic bones articulated with a unique structure, the paired prepubic bones. Together these formed a cusp covering the rear belly, between the pelvis and the belly ribs. The vertical mobility of this element suggests a function in breathing, compensating the relative rigidity of the chest cavity.

The hindlimbs of pterosaurs were strongly built, yet relative to their wingspans smaller than those of birds. They were long in comparison to the torso length. The thighbone was rather straight, with the head making only a small angle with the shaft. This implies that the legs were not held vertically below the body but were somewhat sprawling. The shinbone was often fused with the upper ankle bones into a tibiotarsus that was longer than the thighbone. It could attain a vertical position when walking. The calf bone tended to be slender, especially at its lower end that in advanced forms did not reach the ankle, sometimes reducing total length to a third. Typically it was fused to the shinbone. The ankle was a simple, "mesotarsal", hinge. The, rather long and slender, metatarsus was always splayed to some degree. The foot was plantigrade, meaning that during the walking cycle the sole of the metatarsus was pressed onto the soil.

There was a clear difference between early pterosaurs and advanced species regarding the form of the fifth digit. Originally, the fifth metatarsal was robust and not very shortened. It was connected to the ankle in a higher position than the other metatsarsals. It bore a long, and often curved, mobile clawless fifth toe consisting of two phalanges. The function of this element has been enigmatic. It used to be thought that the animals slept upside-down like bats, hanging from branches and using the fifth toes as hooks. Another hypothesis held that they stretched the brachiopatagia, but in articulated fossils the fifth digits are always flexed towards the tail. Later it became popular to assume that these toes extended an uropatagium or cruropatagium between them. As the fifth toes were on the outside of the feet, such a configuration would only have been possible if these rotated their fronts outwards in flight. Such a rotation could be caused by an abduction of the thighbone, meaning that the legs would be spread. This would also turn the feet into a vertical position. They then could act as rudders to control yaw. Some specimens show membranes between the toes, allowing them to function as flight control surfaces. The (cr)uroptagium would control pitch. When walking the toes could flex upwards to lift the membrane from the ground. In Pterodactyloidea, the fifth metatarsal was much reduced and the fifth toe, if present, little more than a stub. This suggests that their membranes were split, increasing flight manoeuvrability.

The first to fourth toes were long. They had two, three, four and five phalanges respectively. Often the third toe was longest; sometimes the fourth. Flat joints indicate a limited mobility. These toes were clawed but the claws were smaller than the hand claws.

The rare conditions that allowed for the fossilisation of pterosaur remains, sometimes also preserved soft tissues. Modern synchrotron or ultraviolet light photography has revealed many traces not visible to the naked eye. These are often imprecisely called "impressions" but mostly consist of petrifications, natural casts and transformations of the original material. They may include horn crests, beaks or claw sheaths as well as the various flight membranes. Exceptionally, muscles were preserved. Skin patches show small round non-overlapping scales on the soles of the feet, the ankles and the ends of the metacarpals. They covered pads cushioning the impact of walking. Scales are unknown from other parts of the body.

Most or all pterosaurs had hair-like filaments known as pycnofibers on the head and torso. The term "pycnofiber", meaning "dense filament", was coined by palaeontologist Alexander Kellner and colleagues in 2009. Pycnofibers were unique structures similar to, but not homologous (sharing a common origin) with, mammalian hair, an example of convergent evolution. A fuzzy integument was first reported from a specimen of "Scaphognathus crassirostris" in 1831 by Georg Augustus Goldfuss, but had been widely doubted. Since the 1990s, pterosaur finds and histological and ultraviolet examination of pterosaur specimens have provided incontrovertible proof: pterosaurs had pycnofiber coats. "Sordes pilosus" (which translates as "hairy demon") and "Jeholopterus ninchengensis" show pycnofibers on the head and body.

The presence of pycnofibers strongly indicates that pterosaurs were endothermic (warm-blooded). They aided thermoregulation, as is common in warm-blooded animals who need insulation to prevent excessive heat-loss. Pycnofibers were flexible, short filaments, about five to seven millimetres long and rather simple in structure with a hollow central canal. Pterosaur pelts might have been comparable in density to many Mesozoic mammals.

Pterosaur filaments could share a common origin with feathers, as speculated in 2002 by Czerkas and Ji. In 2009, Kellner concluded that pycnofibers were structured similarly to theropod proto-feathers. Others were unconvinced, considering the difference with the "quills" found on many of the bird-like maniraptoran specimens too fundamental.

A 2018 study of the remains of two small Jurassic-age pterosaurs from Inner Mongolia, China, found that pterosaurs had a wide array of pycnofiber shapes and structures, as opposed to the homogeneous structures that had generally been assumed to cover them. Some of these had frayed ends, very similar in structure to four different feather types known from birds or other dinosaurs but almost never known from pterosaurs prior to the study, suggesting homology.

Pterosaur fossils are very rare, due to their light bone construction. Complete skeletons can generally only be found in geological layers with exceptional preservation conditions, the so-called "Lagerstätten". The pieces from one such "Lagerstätte", the Late Jurassic Solnhofen Limestone in Bavaria, became much sought after by rich collectors. In 1784, the Italian naturalist Cosimo Alessandro Collini was the first scientist in history to describe a pterosaur fossil. At that time the concepts of evolution and extinction were only imperfectly developed. The bizarre build of the pterosaur was therefore shocking, as it could not clearly be assigned to any existing animal group. The discovery of pterosaurs would thus play an important role in the progress of modern paleontology and geology. If such creatures were still alive, only the sea was a credible habitat and Collini suggested it might be a swimming animal that used its long front limbs as paddles. A few scientists continued to support the aquatic interpretation even until 1830, when the German zoologist Johann Georg Wagler suggested that "Pterodactylus" used its wings as flippers and was affiliated with Ichthyosauria and Plesiosauria. 

In 1800, Johann Hermann first suggested that it represented a flying creature in a letter to Georges Cuvier. Cuvier agreed in 1801, understanding it was an extinct flying reptile. In 1809, he coined the name "Ptéro-Dactyle", "wing-finger". This was in 1815 Latinised to "Pterodactylus". At first most species were assigned to this genus and ultimately "pterodactyl" was popularly and incorrectly applied to all members of Pterosauria. Today, paleontologists limit the term to the genus "Pterodactylus" or members of the Pterodactyloidea.

In 1812 and 1817, Samuel Thomas von Soemmerring redescribed the original specimen and an additional one. He saw them as affiliated to birds and bats. Although he was mistaken in this, his "bat model" would be very influential during the 19th century. In 1843, Edward Newman thought pterosaurs were flying marsupials. As the bat model correctly depicted pterosaurs as furred and warm-blooded, it better approached the true physiology of pterosaurs than Cuvier's "reptile model". In 1834, Johann Jakob Kaup coined the term Pterosauria.

In 1828, Mary Anning in England found the first pterosaur genus outside Germany, by Richard Owen named as "Dimorphodon", also the first non-pterodactyloid pterosaur known. Later in the century, the Early Cretaceous Cambridge Greensand produced thousands of pterosaur fossils, that however, were of poor quality, consisting mostly of strongly eroded fragments. Based on these, nevertheless numerous genera and species would be named. Many were described by Harry Govier Seeley, at the time the main English expert on the subject, who also wrote the first pterosaur book, "Ornithosauria", and in 1901 the first popular book, "Dragons of the Air". Seeley thought that pterosaurs were warm-blooded and dynamic creatures, closely related to birds. Earlier, the evolutionist St. George Jackson Mivart had suggested pterosaurs were the direct ancestors of birds. Owen opposed the views of both men, seeing pterosaurs as cold-blooded "true" reptiles.

In the US, Othniel Charles Marsh in 1870 discovered "Pteranodon" in the Niobrara Chalk, then the largest known pterosaur, the first toothless one and the first from America. These layers too rendered thousands of fossils, also including relatively complete skeletons that were three-dimensionally preserved instead of being strongly compressed as with the Solnhofen specimens. This led to a much better understanding of many anatomical details, such as the hollow nature of the bones.

Meanwhile, finds from the Solnhofen had continued, accounting for the majority of complete high quality specimens discovered. They allowed to identify most new basal taxa, such as "Rhamphorhynchus", "Scaphognathus" and "Dorygnathus". This material gave birth to a German school of pterosaur research, which saw flying reptiles as the warm-blooded, furry and active Mesozoic counterparts of modern bats and birds. In 1882, Marsh and Karl Alfred Zittel published studies about the wing membranes of specimens of "Rhamphorhynchus". German studies continued well into the 1930s, describing new species such as "Anurognathus". In 1927, Ferdinand Broili discovered hair follicles in pterosaur skin, and paleoneurologist Tilly Edinger determined that the brains of pterosaurs more resembled those of birds than modern cold-blooded reptiles.

In contrast, English and American paleontologists by the middle of the twentieth century largely lost interest in pterosaurs. They saw them as failed evolutionary experiments, cold-blooded and scaly, that hardly could fly, the larger species only able to glide, being forced to climb trees or throw themselves from cliffs to achieve a take-off. In 1914, for the first time pterosaur aerodynamics were quantitatively analysed, by Ernest Hanbury Hankin and David Meredith Seares Watson, but they interpreted "Pteranodon" as a pure glider. Little research was done on the group during the 1940s and 1950s.

The situation for dinosaurs was comparable. From the 1960s onwards, a dinosaur renaissance took place, a quick increase in the number of studies and critical ideas, influenced by the discovery of additional fossils of "Deinonychus", whose spectacular traits refuted what had become entrenched orthodoxy. In 1970, likewise the description of the furry pterosaur "Sordes" began what Robert Bakker named a renaissance of pterosaurs. Especially Kevin Padian propagated the new views, publishing a series of studies depicting pterosaurs as warm-blooded, active and running animals. This coincided with a revival of the German school through the work of Peter Wellnhofer, who in 1970s laid the foundations of modern pterosaur science. In 1978, he published the first pterosaur textbook, the "Handbuch der Paläoherptologie, Teil 19: Pterosauria", and in 1991 the second ever popular science pterosaur book, the "Encyclopedia of Pterosaurs".

This development accelerated through the exploitation of two new "Lagerstätten". During the 1970s, the Early Cretaceous Santana Formation in Brazil began to produce chalk nodules that, though often limited in size and the completeness of the fossils they contained, perfectly preserved three-dimensional pterosaur skeletal parts. German and Dutch institutes bought such nodules from fossil poachers and prepared them in Europe, allowing their scientists to describe many new species and revealing a whole new fauna. Soon, Brazilian researchers, among them Alexander Kellner, intercepted the trade and named even more species.

Even more productive was the Early Cretaceous Chinese Jehol Biota of Liaoning that since the 1990s has brought forth hundreds of exquisitely preserved two-dimensional fossils, often showing soft tissue remains. Chinese researchers such as Lü Junchang have again named many new taxa. As discoveries also increased in other parts of the world, a sudden surge in the total of named genera took place. By 2009, when they had increased to about ninety, this growth showed no sign of levelling-off. In 2013, M.P. Witton indicated that the number of discovered pterosaur species had risen to 130. Over ninety percent of known taxa has been named during the "renaissance". Many of these were from groups the existence of which had been unknown. Advances in computing power allowed to determine their complex relationships through the quantitative method of cladistics. New and old fossils yielded much more information when subjected to modern ultraviolet light or roentgen photography, or CAT-scans. Insights from other fields of biology were applied to the data obtained. All this resulted in a substantial progress in pterosaur research, rendering older accounts in popular science books completely outdated.

Because pterosaur anatomy has been so heavily modified for flight, and immediate transitional fossil predecessors have not so far been described, the ancestry of pterosaurs is not fully understood. The oldest known pterosaurs were already fully adapted to a flying lifestyle. Since Seeley, it was recognised that pterosaurs were likely to have had their origin in the "archosaurs", what today would be called the Archosauromorpha. In the 1980s, early cladistic analyses found that they were Avemetatarsalians (archosaurs closer to dinosaurs than to crocodilians). As this would make them also rather close relatives of the dinosaurs, these results were seen by Kevin Padian as confirming his interpretation of pterosaurs as bipedal warm-blooded animals. Because these early analyses were based on a limited number of taxa and characters, their results were inherently uncertain. Several influential researchers who rejected Padian's conclusions offered alternative hypotheses. David Unwin proposed an ancestry among the basal Archosauromorpha, specifically long-necked forms ("protorosaurs") such as tanystropheids. A placement among basal archosauriforms like "Euparkeria" was also suggested. Some basal archosauromorphs seem at first glance to be good candidates for close pterosaur relatives due to their long-limbed anatomy; one example is "Sharovipteryx", a "protorosaur" with skin membranes on its hindlimbs likely used for gliding. A 1999 study by Michael Benton found that pterosaurs were avemetatarsalians closely related to "Scleromochlus," and named the group Ornithodira to encompass pterosaurs and dinosaurs"."

Two researchers, S. Christopher Bennett in 1996, and paleoartist David Peters in 2000, published analyses finding pterosaurs to be protorosaurs or closely related to them. However, Peters gathered novel anatomical data using an unverified technique called "Digital Graphic Segregation" (DGS), which involves digitally tracing over images of pterosaur fossils using photo editing software. Bennett only recovered pterosaurs as close relatives of the protorosaurs after removing characteristics of the hindlimb from his analysis, to test the possibility of locomotion-based convergent evolution between pterosaurs and dinosaurs. A 2007 reply by Dave Hone and Michael Benton could not reproduce this result, finding pterosaurs to be closely related to dinosaurs even without hindlimb characters. They also criticized David Peters for drawing conclusions without access to the primary evidence, that is, the pterosaur fossils themselves. Hone and Benton concluded that, although more basal pterosauromorphs are needed to clarify their relationships, current evidence indicates that pterosaurs are avemetatarsalians, as either the sister group of "Scleromochlus" or a branch between the latter and "Lagosuchus". An 2011 archosaur-focused phylogenetic analysis by Sterling Nesbitt benefited from far more data and found strong support for pterosaurs being avemetatarsalians, though "Scleromochlus" was not included due to its poor preservation. A 2016 archosauromorph-focused study by Martin Ezcurra included various proposed pterosaur relatives, yet also found pterosaurs to be closer to dinosaurs and unrelated to more basal taxa. Working from his 1996 analysis, Bennett published a 2020 study on "Scleromochlus" which argued that both "Scleromochlus" and pterosaurs were non-archosaur archosauromorphs, albeit not particularly closely related to each other.

A related problem is the origin of pterosaur flight. Like with birds, hypotheses can be ordered into two main varieties: "ground up" or "tree down". Climbing a tree would cause height and gravity provide both the energy and a strong selection pressure for incipient flight. Rupert Wild in 1983 proposed a hypothetical "propterosaurus": a lizard-like arboreal animal developing a membrane between its limbs, first to safely parachute and then, gradually elongating the fourth finger, to glide. However, subsequent cladistic results did not fit this model well. Neither protorosaurs nor ornithodirans are biologically equivalent to lizards. Furthermore, the transition between gliding and flapping flight is not well-understood. More recent studies on basal pterosaur hindlimb morphology seem to vindicate a connection to "Scleromochlus". Like this archosaur, basal pterosaur lineages have plantigrade hindlimbs that show adaptations for saltation.

It was once thought that competition with early bird species might have resulted in the extinction of many of the pterosaurs. Part of this is due to the fact it used to be thought that by the end of the Cretaceous, only large species of pterosaurs were present (no longer true; see below). The smaller species were thought to have become extinct, their niche filled by birds. However, pterosaur decline (if actually present) seems unrelated to bird diversity, as ecological overlap between the two groups appears to be minimal. In fact, at least some avian niches were reclaimed by pterosaurs prior to the KT event. At the end of the Cretaceous period, the Cretaceous–Paleogene extinction event, which wiped out all non-avian dinosaurs and most avian dinosaurs as well, and many other animals, seems also to have taken the pterosaurs.

In the early 2010s, several new pterosaur taxa were discovered dating to the Campanian/Maastrichtian, such as the ornithocheirids "Piksi" and ""Ornithocheirus"", possible pteranodontids and nyctosaurids, several tapejarids and the indeterminate non-azhdarchid "Navajodactylus". Small azhdarchoid pterosaurs were also present in the Campanian. This suggests that late Cretaceous pterosaur faunas were far more diverse than previously thought, possibly not even having declined significantly from the early Cretaceous.

Small-sized pterosaur species apparently were present in the Csehbánya Formation, indicating a higher diversity of Late Cretaceous pterosaurs than previously accounted for. The recent findings of a small cat-sized adult azhdarchid further indicate that small pterosaurs from the Late Cretaceous might actually have simply been rarely preserved in the fossil record, helped by the fact that there is a strong bias against terrestrial small sized vertebrates such as juvenile dinosaurs, and that their diversity might actually have been much larger than previously thought.

At least some non-pterodactyloid pterosaurs survived into the Late Cretaceous, postulating a Lazarus taxa situation for late Cretaceous pterosaur faunas.

In phylogenetic taxonomy, the clade Pterosauria has usually been defined as node-based and anchored to several extensively studied taxa as well as those thought to be primitive. One 2003 study defined Pterosauria as "The most recent common ancestor of the Anurognathidae, "Preondactylus" and "Quetzalcoatlus" and all their descendants." However, these types of definition would inevitably leave any related species that are slightly more primitive out of the Pterosauria. To remedy this, a new definition was proposed that would anchor the name not to any particular species but to an anatomical feature, the presence of an enlarged fourth finger that supports a wing membrane. A broader clade, Pterosauromorpha, has been defined as all ornithodirans more closely related to pterosaurs than to dinosaurs.

The internal classification of pterosaurs has historically been difficult, because there were many gaps in the fossil record. Starting from the 21st century, new discoveries are now filling in these gaps and giving a better picture of the evolution of pterosaurs. Traditionally, they were organized into two suborders: the Rhamphorhynchoidea, a "primitive" group of long-tailed pterosaurs, and the Pterodactyloidea, "advanced" pterosaurs with short tails. However, this traditional division has been largely abandoned. Rhamphorhynchoidea is a paraphyletic (unnatural) group, since the pterodactyloids evolved directly from them and not from a common ancestor, so, with the increasing use of cladistics, it has fallen out of favor among most scientists.

The precise relationships between pterosaurs is still unsettled. Many studies of pterosaur relationships in the past have included limited data and were highly contradictory. However, newer studies using larger data sets are beginning to make things clearer. The cladogram (family tree) below follows a phylogenetic analysis presented by Longrich, Martill and Andres in 2018.

The mechanics of pterosaur flight are not completely understood or modeled at this time.

Katsufumi Sato, a Japanese scientist, did calculations using modern birds and concluded that it was impossible for a pterosaur to stay aloft. In the book "Posture, Locomotion, and Paleoecology of Pterosaurs" it is theorized that they were able to fly due to the oxygen-rich, dense atmosphere of the Late Cretaceous period. However, both Sato and the authors of "Posture, Locomotion, and Paleoecology of Pterosaurs" based their research on the now-outdated theories of pterosaurs being seabird-like, and the size limit does not apply to terrestrial pterosaurs, such as azhdarchids and tapejarids. Furthermore, Darren Naish concluded that atmospheric differences between the present and the Mesozoic were not needed for the giant size of pterosaurs.

Another issue that has been difficult to understand is how they took off. Earlier suggestions were that pterosaurs were largely cold-blooded gliding animals, deriving warmth from the environment like modern lizards, rather than burning calories. In this case, it was unclear how the larger ones of enormous size, with an inefficient cold-blooded metabolism, could manage a bird-like takeoff strategy, using only the hind limbs to generate thrust for getting airborne. Later research shows them instead as being warm-blooded and having powerful flight muscles, and using the flight muscles for walking as quadrupeds. Mark Witton of the University of Portsmouth and Mike Habib of Johns Hopkins University suggested that pterosaurs used a vaulting mechanism to obtain flight. The tremendous power of their winged forelimbs would enable them to take off with ease. Once aloft, pterosaurs could reach speeds of up to and travel thousands of kilometres.

In 1985, the Smithsonian Institution commissioned aeronautical engineer Paul MacCready to build a half-scale working model of "Quetzalcoatlus northropi". The replica was launched with a ground-based winch. It flew several times in 1986 and was filmed as part of the Smithsonian's IMAX film "On the Wing".

A 2009 study showed that pterosaurs had a lung-and-air-sac system and a precisely controlled skeletal breathing pump, which supports a flow-through pulmonary ventilation model in pterosaurs, analogous to that of birds. The presence of a subcutaneous air sac system in at least some pterodactyloids would have further reduced the density of the living animal. Like modern crocodilians, pterosaurs appeared to have had a hepatic piston, seeing as their shoulder-pectoral girdles were too inflexible to move the sternum as in birds, and they possessed strong gastralia. Thus, their respiratory system had characteristics comparable to both modern archosaur clades.

An X-ray study of pterosaur brain cavities revealed that the animals ("Rhamphorhynchus muensteri" and "Anhanguera santanae") had massive flocculi. The flocculus is a brain region that integrates signals from joints, muscles, skin and balance organs. The pterosaurs' flocculi occupied 7.5% of the animals' total brain mass, more than in any other vertebrate. Birds have unusually large flocculi compared with other animals, but these only occupy between 1 and 2% of total brain mass.

The flocculus sends out neural signals that produce small, automatic movements in the eye muscles. These keep the image on an animal's retina steady. Pterosaurs may have had such a large flocculus because of their large wing size, which would mean that there was a great deal more sensory information to process. The low relative mass of the flocculi in birds is also a result of birds having a much larger brain overall; though this has been considered an indication that pterosaurs lived in a structurally simpler environment or had less complex behaviour compared to birds, recent studies of crocodilians and other reptiles show that it is common for sauropsids to achieve high intelligence levels with small brains. Studies on the endocast of "Allkaruen" show that brain evolution in pterodactyloids was a modular process.

Pterosaurs' hip sockets are oriented facing slightly upwards, and the head of the femur (thigh bone) is only moderately inward facing, suggesting that pterosaurs had an erect stance. It would have been possible to lift the thigh into a horizontal position during flight, as gliding lizards do.

There was considerable debate whether pterosaurs ambulated as quadrupeds or as bipeds. In the 1980s, paleontologist Kevin Padian suggested that smaller pterosaurs with longer hindlimbs, such as "Dimorphodon", might have walked or even ran bipedally, in addition to flying, like road runners. However, a large number of pterosaur trackways were later found with a distinctive four-toed hind foot and three-toed front foot; these are the unmistakable prints of pterosaurs walking on all fours.

Fossil footprints show that pterosaurs stood with the entire foot in contact with the ground (plantigrade), in a manner similar to many mammals like humans and bears. Footprints from azhdarchids and several unidentified species show that pterosaurs walked with an erect posture with their four limbs held almost vertically beneath the body, an energy-efficient stance used by most modern birds and mammals, rather than the sprawled limbs of modern reptiles. Indeed, erect-limbs may be omnipresent in pterosaurs.

Though traditionally depicted as ungainly and awkward when on the ground, the anatomy of some pterosaurs (particularly pterodactyloids) suggests that they were competent walkers and runners. Early pterosaurs have long been considered particularly cumbersome locomotors due to the presence of large cruropatagia, but they too appear to have been generally efficient on the ground.

The forelimb bones of azhdarchids and ornithocheirids were unusually long compared to other pterosaurs, and, in azhdarchids, the bones of the arm and hand (metacarpals) were particularly elongated. Furthermore, as a whole, azhdarchid front limbs were proportioned similarly to fast-running ungulate mammals. Their hind limbs, on the other hand, were not built for speed, but they were long compared with most pterosaurs, and allowed for a long stride length. While azhdarchid pterosaurs probably could not run, they would have been relatively fast and energy efficient.

The relative size of the hands and feet in pterosaurs (by comparison with modern animals such as birds) may indicate the type of lifestyle pterosaurs led on the ground. Azhdarchid pterosaurs had relatively small feet compared to their body size and leg length, with foot length only about 25%–30% the length of the lower leg. This suggests that azhdarchids were better adapted to walking on dry, relatively solid ground. "Pteranodon" had slightly larger feet (47% the length of the tibia), while filter-feeding pterosaurs like the ctenochasmatoids had very large feet (69% of tibial length in "Pterodactylus", 84% in "Pterodaustro"), adapted to walking in soft muddy soil, similar to modern wading birds. Though clearly forelimb-based launchers, basal pterosaurs have hindlimbs well adapted for hopping, suggesting a connection with archosaurs such as "Scleromochlus".

Tracks made by ctenochasmatoids indicate that these pterosaurs swam using their hindlimbs. In general, these have large hindfeet and long torsos, indicating that they were probably more adapted for swimming than other pterosaurs. Pteranodontians conversely have several speciations in their humeri interpreted to have been suggestive of a water-based version of the typical quadrupedal launch, and several like boreopterids must have foraged while swimming, as they seem incapable of frigatebird-like aerial hawking. These adaptations are also seen in terrestrial pterosaurs like azhdarchids, which presumably still needed to launch from water in case they found themselves in it. The nyctosaurid "Alcione" may display adaptations for wing-propelled diving like modern gannets and tropicbirds.

Traditionally, almost all pterosaurs were seen as surface-feeding piscivores or fish-eaters, a view that still dominates popular science. Today, many pterosaurs groups are thought to have been terrestrial carnivores, omnivores or insectivores.

Early-on it was recognised that the small Anurognathidae were nocturnal, aerial insectivores. With highly flexible joints on the wing finger, a broad, triangular wing shape, large eyes and short tail, these pterosaurs were likely analogous to nightjars or extant insectivorous bats, being capable of high manoeuvrability at relatively low speeds.

Interpretations of the habits of basal groups have changed profoundly. "Dimorphodon", envisioned as a puffin analogue in the past, is indicated by its jaw structure, gait, and poor flight capabilities, as a terrestrial/semiarboreal predator of small mammals, squamates, and large insects. Its robust dentition caused "Campylognathoides" to be seen as a generalist or a terrestrial predator of small vertebrates, but the highly robust humerus and high-aspect wing morphology, suggest it may have been capable of grabbing prey on the wing. The small insectivorous "Carniadactylus" and the larger "Eudimorphodon" were highly aerial animals and fast, agile flyers with long robust wings. "Eudimorphodon" has been found with fish remains in its stomach, but its dentition suggests an opportunistic diet. Slender-winged "Austriadactylus" and "Caviramus" were likely terrestrial/semiarboreal generalists. "Caviramus" likely had a strong bite force, indicating an adaptation towards hard food items that might have been chewed in view of the tooth wear.

Some Rhamphorhynchidae, such as "Rhamphorhynchus" itself or "Dorygnathus", were fish-eaters with long, slender wings, needle-like dentition and long, thin jaws. "Sericipterus", "Scaphognathus" and "Harpactognathus" had more robust jaws and teeth (which were ziphodont, dagger-shaped, in " Sericipterus"), and shorter, broader wings. These were either terrestrial/aerial predators of vertebrates or corvid-like generalists. Wukongopteridae like "Darwinopterus" were first considered aerial predators. Lacking a robust jaw structure or powerful flying muscles, they are now seen as arboreal or semiterrestrial insectivores. "Darwinopterus robustidens", in particular, seems to have been a beetle specialist.

Among pterodactyloids, a greater variation in diet is present. Pteranodontia contained many piscivorous taxa, such as the Ornithocheirae, Boreopteridae, Pteranodontidae and Nyctosauridae. Niche partitioning caused ornithocheirs and the later nyctosaurids to be aerial dip-feeders like today's frigatebirds (with the exception of the plunge-diving adapted "Alcione elainus"), while boreopterids were freshwater diving animals similar to cormorants, and pteranodonts pelagic plunge-divers akin to boobies and gannets. The istiodactylids were likely primarily scavengers. Archaeopterodactyloidea obtained food in coastal or freshwater habitats. "Germanodactylus" and "Pterodactylus" were piscivores, while the Ctenochasmatidae were suspension feeders, using their numerous fine teeth to filter small organisms from shallow water. "Pterodaustro" was adaptated for flamingo-like filter-feeding.

In contrast, Azhdarchoidea mostly were terrestrial pterosaurs. Tapejaridae were arboreal omnivores, supplementing seeds and fruits with small insects and vertebrates. Dsungaripteridae were specialist molluscivores, using their powerful jaws to crush the shells of molluscs and crustaceans. Thalassodromidae were likely terrestrial carnivores. "Thalassodromeus" itself was named after a fishing method known as "skim-feeding", later understood to be biomechanically impossible. Perhaps it pursued relatively large prey, in view of its reinforced jaw joints and relatively high bite force. Azhdarchidae are now understood to be terrestrial predators akin to ground hornbills or some storks, eating any prey item they could swallow whole. "Hatzegopteryx" was a robustly built predator of relatively large prey, including medium-sized dinosaurs. "Alanqa" may have been a specialist molluscivore.

Pterosaurs are known to have been eaten by theropods. In the 1 July 2004 edition of "Nature", paleontologist Eric Buffetaut discusses an Early Cretaceous fossil of three cervical vertebrae of a pterosaur with the broken tooth of a spinosaur, most likely "Irritator", embedded in it. The vertebrae are known not to have been eaten and exposed to digestion, as the joints are still articulated.

While very little is known about pterosaur reproduction, it is believed that, similar to all dinosaurs, all pterosaurs reproduced by laying eggs, though such findings are very rare. The first known pterosaur egg was found in the quarries of Liaoning, the same place that yielded feathered dinosaurs. The egg was squashed flat with no signs of cracking, so evidently the eggs had leathery shells, as in modern lizards. This was supported by the description of an additional pterosaur egg belonging to the genus "Darwinopterus", described in 2011, which also had a leathery shell and, also like modern reptiles but unlike birds, was fairly small compared to the size of the mother. In 2014 five unflattened eggs from the species "Hamipterus tianshanensis" were found in an Early Cretaceous deposit in northwest China. Examination of the shells by scanning electron microscopy showed the presence of a thin calcareous eggshell layer with a membrane underneath. A study of pterosaur eggshell structure and chemistry published in 2007 indicated that it is likely pterosaurs buried their eggs, like modern crocodiles and turtles. Egg-burying would have been beneficial to the early evolution of pterosaurs, as it allows for more weight-reducing adaptations, but this method of reproduction would also have put limits on the variety of environments pterosaurs could live in, and may have disadvantaged them when they began to face ecological competition from birds.

A "Darwinopterus" specimen showcases that at least some pterosaurs had a pair of functional ovaries, as opposed to the single functional ovary in birds, dismissing the reduction of functional ovaries as a requirement for powered flight.

Wing membranes preserved in pterosaur embryos are well developed, suggesting that pterosaurs were ready to fly soon after birth. However, tomography scans of fossilised "Hamipterus" eggs suggests that the young pterosaurs had well-developed thigh bones for walking, but weak chests for flight. It is unknown if this holds true for other pterosaurs. Fossils of pterosaurs only a few days to a week old (called "flaplings") have been found, representing several pterosaur families, including pterodactylids, rhamphorhinchids, ctenochasmatids and azhdarchids. All preserve bones that show a relatively high degree of hardening ("ossification") for their age, and wing proportions similar to adults. In fact, many pterosaur flaplings have been considered adults and placed in separate species in the past. Additionally, flaplings are normally found in the same sediments as adults and juveniles of the same species, such as the "Pterodactylus" and "Rhamphorhynchus" flaplings found in the Solnhofen limestone of Germany, and "Pterodaustro" flaplings from Argentina. All are found in deep aquatic environment far from shore.

For the majority of pterosaur species, it is not known whether they practiced any form of parental care, but their ability to fly as soon as they emerged from the egg and the numerous flaplings found in environments far from nests and alongside adults has led most researchers, including Christopher Bennett and David Unwin, to conclude that the young were dependent on their parents for a relatively short period of time, during a period of rapid growth while the wings grew long enough to fly, and then left the nest to fend for themselves, possibly within days of hatching. Alternatively, they may have used stored yolk products for nourishment during their first few days of life, as in modern reptiles, rather than depend on parents for food. Fossilised "Hamipterus" nests were shown preserving many male and female pterosaurs together with their eggs in a manner to a similar to that of modern seabird colonies. Due to how underdeveloped the chests of the hatchlings were for flying, it was suggested that "Hamipterus" may have practiced some form of parental care. However, this study has since been criticised. Most evidence currently leans towards pterosaur hatchlings being superprecocial, similar to that of megapode birds, which fly after hatching without the need of parental care.

Growth rates of pterosaurs once they hatched varied across different groups. In more primitive, long-tailed pterosaurs ("rhamphorhynchoids"), such as "Rhamphorhynchus", the average growth rate during the first year of life was 130% to 173%, slightly faster than the growth rate of alligators. Growth in these species slowed after sexual maturity, and it would have taken more than three years for "Rhamphorhynchus" to attain maximum size. In contrast, the more advanced, large pterodactyloid pterosaurs, such as "Pteranodon", grew to adult size within the first year of life. Additionally, pterodactyloids had "determinate growth", meaning that the animals reached a fixed maximum adult size and stopped growing.

Comparisons between the scleral rings of pterosaurs and modern birds and reptiles have been used to infer daily activity patterns of pterosaurs. The pterosaur genera "Pterodactylus", "Scaphognathus", and "Tupuxuara" have been inferred to be diurnal, "Ctenochasma", "Pterodaustro", and "Rhamphorhynchus" have been inferred to be nocturnal, and "Tapejara" has been inferred to be cathemeral, being active throughout the day for short intervals. As a result, the possibly fish-eating "Ctenochasma" and "Rhamphorhynchus" may have had similar activity patterns to modern nocturnal seabirds, and the filter-feeding "Pterodaustro" may have had similar activity patterns to modern anseriform birds that feed at night. The differences between activity patterns of the Solnhofen pterosaurs "Ctenochasma", "Rhamphorhynchus", "Scaphognathus", and "Pterodactylus" may also indicate niche partitioning between these genera.

Pterosaurs have been a staple of popular culture for as long as their cousins the dinosaurs, though they are usually not featured as prominently in films, literature or other art. While the depiction of dinosaurs in popular media has changed radically in response to advances in paleontology, a mainly outdated picture of pterosaurs has persisted since the mid-20th century.

The vague generic term "pterodactyl" is often used for these creatures. The animals depicted frequently represent either "Pteranodon" or (non-pterodactyloid) "Rhamphorhynchus", or a fictionalized hybrid of the two. Many children's toys and cartoons feature "pterodactyls" with "Pteranodon"-like crests and long, "Rhamphorhynchus"-like tails and teeth, a combination that never existed in nature. However, at least one pterosaur "did" have both the "Pteranodon"-like crest and teeth: "Ludodactylus", whose name means "toy finger" for its resemblance to old, inaccurate children's toys. Pterosaurs have sometimes been incorrectly identified as (the ancestors of) birds, though birds are theropod dinosaurs and not closely related to pterosaurs.

Pterosaurs were used in fiction in Sir Arthur Conan Doyle's 1912 novel "The Lost World" and its 1925 film adaptation. They appeared in a number of films and television programs since, including the 1933 film "King Kong", and 1966's "One Million Years B.C.". In the latter, animator Ray Harryhausen had to add inaccurate bat-like wing fingers to his stop motion models in order to keep the membranes from falling apart, though this particular error was common in art even before the film was made. Rodan, a fictional giant monster (or "kaiju") which first appeared in the 1956 film "Rodan", is portrayed as an enormous irradiated species of "Pteranodon". Rodan has appeared in multiple Japanese "Godzilla" films released during the 1960s, 1970s, 1990s, and 2000s, and also appeared in the 2019 American-produced film "".

After the 1960s, pterosaurs remained mostly absent from notable American film appearances until 2001's "Jurassic Park III". Paleontologist Dave Hone noted that the pterosaurs in this film had not been significantly updated to reflect modern research. Errors persisting were teeth while toothless "Pteranodon" was intended to be depicted, nesting behavior that was known to be inaccurate by 2001, and leathery wings, rather than the taut membranes of muscle fiber required for pterosaur flight.

In most media appearances, pterosaurs are depicted as piscivores, not reflecting their full dietary variation. They are also often shown as aerial predators similar to birds of prey, grasping human victims with talons on their feet. However, only the small anurognathid "Vesperopterylus" is known to possesses prehensile feet; all other pterosaurs have flat, plantigrade feet with no opposable toes, and the feet are generally proportionally small, at least in the case of the Pteranodontia.




</doc>
<doc id="24825" url="https://en.wikipedia.org/wiki?curid=24825" title="Pteranodon">
Pteranodon

Pteranodon (; from Greek πτερόν (pteron, "wing") and ἀνόδων (anodon, "toothless")) is a genus of pterosaur that included some of the largest known flying reptiles, with wingspans over 7 meters (23 feet). They lived during the late Cretaceous geological period of North America in present-day Kansas, Alabama, Nebraska, Wyoming, and South Dakota. More fossil specimens of "Pteranodon" have been found than any other pterosaur, with about 1,200 specimens known to science, many of them well preserved with nearly complete skulls and articulated skeletons. It was an important part of the animal community in the Western Interior Seaway.

"Pteranodon" was a pterosaur, meaning that it is not a dinosaur. By definition, all dinosaurs belong to one of the two groups within Dinosauria, i.e. Saurischia or Ornithischia. As such, this excludes pterosaurs. Nonetheless, "Pteranodon" is frequently featured in dinosaur media and are strongly associated with dinosaurs by the general public. While not dinosaurs, pterosaurs such as "Pteranodon" form a clade closely related to dinosaurs as both fall within the clade Avemetatarsalia.

"Pteranodon" was the first pterosaur found outside of Europe. Its fossils first were found by Othniel Charles Marsh in 1870, in the Late Cretaceous Smoky Hill Chalk deposits of western Kansas. These chalk beds were deposited at the bottom of what was once the Western Interior Seaway, a large shallow sea over what now is the midsection of the North American continent. These first specimens, YPM 1160 and YPM 1161, consisted of partial wing bones, as well as a tooth from the prehistoric fish "Xiphactinus", which Marsh mistakenly believed to belong to this new pterosaur (all known pterosaurs up to that point had teeth). In 1871, Marsh named the find ""Pterodactylus oweni"", assigning it to the well-known (but much smaller) European genus "Pterodactylus". Marsh also collected more wing bones of the large pterosaur in 1871. Realizing that the name he had chosen had already been used for Harry Seeley's European pterosaur species "Pterodactylus oweni" in 1864, Marsh re-named his giant North American pterosaur Pterodactylus occidentalis, meaning "Western wing finger," in his 1872 description of the new specimen. He also named two additional species, based on size differences: Pterodactylus ingens (the largest specimen so far), and Pterodactylus velox (the smallest).

Meanwhile, Marsh's rival Edward Drinker Cope also had unearthed several specimens of the large North American pterosaur. Based on these specimens, Cope named two new species, Ornithochirus umbrosus and Ornithochirus harpyia, in an attempt to assign them to the large European genus "Ornithocheirus", though he misspelled the name (forgetting the 'e'). Cope's paper naming his species was published in 1872, just five days after Marsh's paper. This resulted in a dispute, fought in the published literature, over whose names had priority in what obviously were the same species. Cope conceded in 1875 that Marsh's names did have priority over his, but maintained that "Pterodactylus umbrosus" was a distinct species (but not genus) from any that Marsh had named previously. Re-evaluation by later scientists has supported Marsh's case, and found that Cope's assertion that "P. umbrosus" was a larger, distinct species were incorrect.

While the first "Pteranodon" wing bones were collected by Marsh and Cope in the early 1870s, the first "Pteranodon" skull was found on May 2, 1876, along the Smoky Hill River in Wallace County (now Logan County), Kansas, USA, by Samuel Wendell Williston, a fossil collector working for Marsh. A second, smaller skull soon was discovered as well. These skulls showed that the North American pterosaurs were different from any European species, in that they lacked teeth and had bony crests on their skulls. Marsh recognized this major difference, describing the specimens as "distinguished from all previously known genera of the order Pterosauria by the entire absence of teeth." Marsh recognized that this characteristic warranted a new genus, and he coined the name "Pteranodon" ("wing without tooth") in 1876. Marsh reclassified all the previously named North American species from "Pterodactylus" to "Pteranodon". He considered the smaller skull to belong to "Pteranodon occidentalis", based on its size. Marsh classified the larger skull, YPM 1117, in the new species "Pteranodon longiceps", which he thought to be a medium-sized species in between the small "P. occidentalis" and the large "P. ingens". Marsh also named several additional species: Pteranodon comptus and "Pteranodon nanus" were named for fragmentary skeletons of small individuals, while "Pteranodon gracilis" was based on a wing bone that he mistook for a pelvic bone. He soon realized his mistake, and re-classified that specimen again into a separate genus, which he named "Nyctosaurus". "P. nanus" was also later recognized as a "Nyctosaurus" specimen.

In 1892, Samuel Williston examined the question of "Pteranodon" classification. He noticed that, in 1871, Seeley had mentioned the existence of a partial set of toothless pterosaur jaws from the Cambridge Greensand of England, which he named "Ornithostoma". Because the primary characteristic Marsh had used to separate "Pteranodon" from other pterosaurs was its lack of teeth, Williston concluded that "Ornithostoma" must be considered the senior synonym of "Pteranodon". However, in 1901, Pleininger pointed out that "Ornithostoma" had never been scientifically described or even assigned a species name until Williston's work, and therefore had been a "nomen nudum" and could not beat out "Pteranodon" for naming priority. Williston accepted this conclusion and went back to calling the genus "Pteranodon". However, both Williston and Pleininger were incorrect, because unnoticed by both of them was the fact that, in 1891, Seeley himself had finally described and properly named "Ornithostoma", assigning it to the species "O. sedgwicki". In the 2010s, more research on the identity of "Ornithostoma" showed that it was probably not "Pteranodon" or even a close relative, but may in fact have been an azhdarchoid, a different type of toothless pterosaur.

Williston was also the first scientist to critically evaluate all of the pteranodont species classified by Cope and Marsh. He agreed with most of Marsh's classification, with a few exceptions. First, he did not believe that "P. ingens" and "P. umbrosus" could be considered synonyms, which even Cope had come to believe. He considered both "P. velox" and "P. longiceps" to be dubious; the first was based on non-diagnostic fragments, and the second, though known from a complete skull, probably belonged to one of the other, previously-named species. In 1903, Williston revisited the question of "Pteranodon" classification, and revised his earlier conclusion that there were seven species down to just three. He considered both "P. comptus" and "P. nanus" to be specimens of "Nyctosaurus", and divided the others into small ("P. velox"), medium ("P. occidentalis"), and large species ("P. ingens"), based primarily on the shape of their upper arm bones. He thought "P. longiceps", the only one known from a skull, could be a synonym of either "P. velox" or "P. occidentalis", based on its size.

In 1910, Eaton became the first scientist to publish a more detailed description of the entire "Pteranodon" skeleton, as it was known at the time. He used his findings to revise the classification of the genus once again based on a better understanding of the differences in pteranodont anatomy. Eaton conducted experiments using clay models of bones to help determine the effects of crushing and flattening on the shapes of the arm bones Williston had used in his own classification. Eaton found that most of the differences in bone shapes could be easily explained by the pressures of fossilization, and concluded that no "Pteranodon" skeletons had any significant differences from each other besides their size. Therefore, Eaton was left to decide his classification scheme based on differences in the skulls alone, which he assigned to species just as Marsh did, by their size. In the end, Eaton recognized only three valid species: "P. occidentalis", "P. ingens", and "P. longiceps".

The discovery of specimens with upright crests, classified by Harksen in 1966 as the new species "Pteranodon sternbergi", complicated the situation even further, prompting another revision of the genus by Miller in 1972. Because it was impossible to determine crest shape for all of the species based on headless skeletons, Miller concluded that all "Pteranodon" species except the two based on skulls ("P. longiceps" and "P. sternbergi") must be considered "nomena dubia" and abandoned. The skull Eaton thought belonged to "P. ingens" was placed in the new species Pteranodon marshi, and the skull Eaton assigned to "P. occidentalis" was re-named Pteranodon eatoni. Miller also recognized another species based on a skull with a crest similar to that of "P. sternbergi"; Miller named this Pteranodon walkeri. To help bring order to this tangle of names, Miller created three categories or "subgenera" for them. "P. marshi" and "P. longiceps" were placed in the subgenus "Longicepia", though this was later changed to simply "Pteranodon" due to the rules of priority. "P. sternbergi" and "P. walkeri", the upright-crested species, were given the subgenus "Sternbergia", which was later changed to "Geosternbergia" because "Sternbergia" was already in use ("preoccupied"). Finally, Miller named the subgenus "Occidentalia" for "P. eatoni", the skull formerly associated with "P. occidentalis". Miller further expanded the concept of "Pteranodon" to include "Nyctosaurus" as a fourth subgenus. Miller considered these to be an evolutionary progression, with the primitive "Nyctosaurus", at the time thought to be crestless, giving rise to "Occidentalia" (with a small crest), which in turn gave rise to "Pteranodon" with its long backwards crest, finally leading to "Geosternbergia" with its large, upright crest. However, Miller made several mistakes in his study concerning which specimens Marsh had assigned to which species, and most scientists disregarded his work on the subject in their later research, though Wellnhofer (1978) followed Miller's species list. and Schoch (1984) somewhat oddly published another revision that essentially returned to Marsh's original classification scheme, most notably sinking "P. longiceps" as a synonym of "P. ingens".

During the early 1990s, S. Christopher Bennett also published several major papers reviewing the anatomy, taxonomy and life history of "Pteranodon".

Fragmentary fossils assigned to "Pteranodon" have also been discovered in Skåne, Sweden.

"Pteranodon" species are extremely well represented in the fossil record, allowing for detailed descriptions of their anatomy and analysis of their life history. Over 1,000 specimens have been identified, though less than half are complete enough to give researchers good anatomical information. Still, this is more fossils material than is known for any other pterosaur, and it includes both male and female specimens of various age groups and possibly species.

Adult "Pteranodon" specimens from the two major species can be divided into two distinct size classes. The smaller class of specimens have small, rounded head crests and very wide pelvic canals, even wider than those of the much larger size class. The size of the pelvic canal probably allowed the laying of eggs, indicating that these smaller adults are females. The larger size class, representing male individuals, have narrow hips and very large crests, which were probably for display.

Adult male "Pteranodon" were among the largest pterosaurs, and were the largest flying animals known until the late 20th century, when the giant azhdarchid pterosaurs were discovered. The wingspan of an average adult male "Pteranodon" was . Adult females were much smaller, averaging in wingspan. The largest specimen of "Pteranodon longiceps" from the Niobrara Formation measured from wingtip to wingtip. An even larger specimen is known from the Pierre Shale Formation, with a wingspan of , though this specimen may belong to the distinct genus and species "Geosternbergia maysei". While most specimens are found crushed, enough fossils exist to put together a detailed description of the animal.

Methods used to estimate the mass of large male "Pteranodon" specimens (those with wingspans of about 7 meters) have been notoriously unreliable, producing a wide range of estimates from as low as to as high as . In a review of pterosaur size estimates published in 2010, researchers Mark Witton and Mike Habib demonstrated that the latter, largest estimates are almost certainly incorrect given the total volume of a "Pteranodon" body, and could only be correct if the animal "was principally aluminium". Witton and Habib considered the methods used by researchers who obtained smaller mass estimates equally flawed. Most have been produced by scaling modern animals such as bats and birds up to "Pteranodon" size, despite the fact that pterosaurs have vastly different body proportions and soft tissue anatomy from any living animal.

Other distinguishing characteristics that set "Pteranodon" apart from other pterosaurs include narrow neural spines on the vertebrae, plate-like bony ligaments strengthening the vertebrae above the hip, and a relatively short tail in which the last few vertebrae are fused into a long rod. The entire length of the tail was about 3.5% as long as the wingspan, or up to in the largest males.

Unlike earlier pterosaurs, such as "Rhamphorhynchus" and "Pterodactylus", "Pteranodon" had toothless beaks, similar to those of birds. "Pteranodon" beaks were made of solid, bony margins that projected from the base of the jaws. The beaks were long, slender, and ended in thin, sharp points. The upper jaw, which was longer than the lower jaw, was curved upward; while this normally has been attributed only to the upward-curving beak, one specimen (UALVP 24238) has a curvature corresponding with the beak widening towards the tip. While the tip of the beak is not known in this specimen, the level of curvature suggests it would have been extremely long. The unique form of the beak in this specimen led Alexander Kellner to assign it to a distinct genus, "Dawndraco", in 2010.

The most distinctive characteristic of "Pteranodon" is its cranial crest. These crests consisted of skull bones (frontals) projecting upward and backward from the skull. The size and shape of these crests varied due to a number of factors, including age, sex, and species. Male "Pteranodon sternbergi", the older species of the two described to date (and sometimes placed in the distinct genus "Geosternbergia"), had a more vertical crest with a broad forward projection, while their descendants, "Pteranodon longiceps", evolved a narrower, more backward-projecting crest. Females of both species were smaller and bore small, rounded crests. The crests were probably mainly display structures, though they may have had other functions as well.

The wing shape of "Pteranodon" suggests that it would have flown rather like a modern-day albatross. This is based on the fact that "Pteranodon" had a high aspect ratio (wingspan to chord length) similar to that of the albatross — 9:1 for "Pteranodon", compared to 8:1 for an albatross. Albatrosses spend long stretches of time at sea fishing, and use a flight pattern called "dynamic soaring" which exploits the vertical gradient of wind speed near the ocean surface to travel long distances without flapping, and without the aid of thermals (which do not occur over the open ocean the same way they do over land). While most of a "Pteranodon" flight would have depended on soaring, like long-winged seabirds, it probably required an occasional active, rapid burst of flapping, and studies of "Pteranodon" wing loading (the strength of the wings vs. the weight of the body) indicate that they were capable of substantial flapping flight, contrary to some earlier suggestions that they were so big they could only glide.

Like other pterosaurs, "Pteranodon" probably took off from a standing, quadrupedal position. Using their long forelimbs for leverage, they would have vaulted themselves into the air in a rapid leap. Almost all of the energy would have been generated by the forelimbs. The upstroke of the wings would have occurred when the animal cleared the ground followed by a rapid down-stroke to generate additional lift and complete the launch into the air.

Historically, the terrestrial locomotion of "Pteranodon", especially whether it was bipedal or quadrupedal, has been the subject of debate. Today, most pterosaur researchers agree that pterosaurs were quadrupedal, thanks largely to the discovery of pterosaur trackways.

The possibility of aquatic locomotion via swimming has been discussed briefly in several papers (Bennett 2001, 1994, and Bramwell & Whitfield 1974).

The diet of "Pteranodon" is known to have included fish; fossilized fish bones have been found in the stomach area of one "Pteranodon", and a fossilized fish bolus has been found between the jaws of another "Pteranodon", specimen AMNH 5098. Numerous other specimens also preserve fragments of fish scales and vertebrae near the torso, indicating that fish made up a majority of the diet of "Pteranodon" (though they may also have taken invertebrates).

Traditionally, most researchers have suggested that "Pteranodon" would have taken fish by dipping their beaks into the water while in low, soaring flight. However, this was probably based on the assumption that the animals could not take off from the water surface. It is more likely that "Pteranodon" could take off from the water, and would have dipped for fish while swimming rather than while flying. Even a small, female "Pteranodon" could have reached a depth of at least with its long bill and neck while floating on the surface, and they may have reached even greater depths by plunge-diving into the water from the air like some modern long-winged seabirds. In 1994, Bennett noted that the head, neck, and shoulders of "Pteranodon" were as heavily built as diving birds, and suggested that they could dive by folding back their wings like the modern gannet.

"Pteranodon" was notable for its skull crest, though the function of this crest has been a subject of debate. Most explanations have focused on the blade-like, backward pointed crest of male "P. longiceps", however, and ignored the wide range of variation across age and sex. The fact that the crests vary so much rules out most practical functions other than for use in mating displays. Therefore, display was probably the main function of the crest, and any other functions were secondary.

Scientific interpretations of the crest's function began in 1910, when George Francis Eaton proposed two possibilities: an aerodynamic counterbalance and a muscle attachment point. He suggested that the crest might have anchored large, long jaw muscles, but admitted that this function alone could not explain the large size of some crests. Bennett (1992) agreed with Eaton's own assessment that the crest was too large and variable to have been a muscle attachment site. Eaton had suggested that a secondary function of the crest might have been as a counterbalance against the long beak, reducing the need for heavy neck muscles to control the orientation of the head. Wind tunnel tests showed that the crest did function as an effective counterbalance to a degree, but Bennett noted that, again, the hypothesis focuses only on the long crests of male "P. longiceps", not on the larger crests of "P. sternbergi" and very small crests that existed among the females. Bennett found that the crests of females had no counterbalancing effect, and that the crests of male "P. sternbergi" would, by themselves, have a negative effect on the balance of the head. In fact, side to side movement of the crests would have required more, not less, neck musculature to control balance.

In 1943, Dominik von Kripp suggested that the crest may have served as a rudder, an idea embraced by several later researchers. One researcher, Ross S. Stein, even suggested that the crest may have supported a membrane of skin connecting the backward-pointing crest to the neck and back, increasing its surface area and effectiveness as a rudder. The rudder hypothesis, again, does not take into account females nor "P. sternbergi", which had an upward-pointing, not backward-pointing crest. Bennett also found that, even in its capacity as a rudder, the crest would not provide nearly so much directional force as simply maneuvering the wings. The suggestion that the crest was an air brake, and that the animals would turn their heads to the side in order to slow down, suffers from a similar problem. Additionally, the rudder and air brake hypotheses do not explain why such large variation exists in crest size even among adults.

Alexander Kellner suggested that the large crests of the pterosaur "Tapejara", as well as other species, might be used for heat exchange, allowing these pterosaurs to absorb or shed heat and regulate body temperature, which also would account for the correlation between crest size and body size. There is no evidence of extra blood vessels in the crest for this purpose, however, and the large, membranous wings filled with blood vessels would have served that purpose much more effectively.

With these hypotheses ruled out, the best-supported hypothesis for crest function seems to be as a sexual display. This is consistent with the size variation seen in fossil specimens, where females and juveniles have small crests and males large, elaborate, variable crests.

Adult "Pteranodon" specimens may be divided into two distinct size classes, small and large, with the large size class being about one and a half times larger than the small class, and the small class being twice as common as the large class. Both size classes lived alongside each other, and while researchers had previously suggested that they represent different species, Christopher Bennett showed that the differences between them are consistent with the concept that they represent females and males, and that "Pteranodon" species were sexually dimorphic. Skulls from the larger size class preserve large, upward and backward pointing crests, while the crests of the smaller size class are small and triangular. Some larger skulls also show evidence of a second crest that extended long and low, toward the tip of the beak, which is not seen in smaller specimens.

The sex of the different size classes was determined, not from the skulls, but from the pelvic bones. Contrary to what may be expected, the smaller size class had disproportionately large and wide-set pelvic bones. Bennett interpreted this as indicating a more spacious birth canal, through which eggs would pass. He concluded that the small size class with small, triangular crests represent females, and the larger, large-crested specimens represent males.

Note that the overall size and crest size also corresponds to age. Immature specimens are known from both females and males, and immature males often have small crests similar to adult females. Therefore, it seems that the large crests only developed in males when they reached their large, adult size, making the sex of immature specimens difficult to establish from partial remains.

The fact that females appear to have outnumbered males two to one suggests that, as with modern animals with size-related sexual dimorphism, such as sea lions and other pinnipeds, "Pteranodon" might have been polygynous, with a few males competing for association with groups consisting of large numbers of females. Similar to modern pinnipeds, "Pteranodon" may have competed to establish territory on rocky, offshore rookeries, with the largest, and largest-crested, males gaining the most territory and having more success mating with females. The crests of male "Pteranodon" would not have been used in competition, but rather as "visual dominance-rank symbols", with display rituals taking the place of physical competition with other males. If this hypothesis is correct, it also is likely that male "Pteranodon" played little to no part in rearing the young; such a behavior is not found in the males of modern polygynous animals who father many offspring at the same time.

Specimens assigned to "Pteranodon" have been found in both the Smoky Hill Chalk deposits of the Niobrara Formation, and the slightly younger Sharon Springs deposits of the Pierre Shale Formation. When "Pteranodon" was alive, this area was covered by a large inland sea, known as the Western Interior Seaway. Famous for fossils collected since 1870, these formations extend from as far south as Kansas in the United States to Manitoba in Canada. However, "Pteranodon" specimens (or any pterosaur specimens) have only been found in the southern half of the formation, in Kansas, Wyoming, and South Dakota. Despite the fact that numerous fossils have been found in the contemporary parts of the formation in Canada, no pterosaur specimens have ever been found there. This strongly suggests that the natural geographic range of "Pteranodon" covered only the southern part of the Niobrara, and that its habitat did not extend farther north than South Dakota.

Some very fragmentary fossils belonging to pteranodontian pterosaurs, and possibly "Pteranodon" itself, have also been found on the Gulf Coast and East Coast of the United States. For example, some bone fragments from the Mooreville Formation of Alabama and the Merchantville Formation of Delaware may have come from "Pteranodon", though they are too incomplete to make a definite identification. Some remains from Japan have also been tentatively attributed to "Pteranodon", but their distance from its known Western Interior Seaway habitat makes this identification unlikely.
"Pteranodon longiceps" would have shared the sky with the giant-crested pterosaur "Nyctosaurus". Compared to "P. longiceps", which was a very common species, "Nyctosaurus" was rare, making up only 3% of pterosaur fossils from the formation. Also less common was the early toothed bird, "Ichthyornis".

It is likely that, as in other polygynous animals (in which males compete for association with harems of females), "Pteranodon" lived primarily on offshore rookeries, where they could nest away from land-based predators and feed far from shore; most "Pteranodon" fossils are found in locations which at the time, were hundreds of kilometres from the coastline.

Below the surface, the sea was populated primarily by invertebrates such as ammonites and squid. Vertebrate life, apart from basal fish, included sea turtles, such as "Toxochelys", the plesiosaur "Styxosaurus", and the flightless diving bird "Parahesperornis". Mosasaurs were the most common marine reptiles, with genera including "Clidastes" and "Tylosaurus". At least some of these marine reptiles are known to have fed on "Pteranodon". Barnum Brown, in 1904, reported plesiosaur stomach contents containing "pterodactyl" bones, most likely from "Pteranodon".

Fossils from terrestrial dinosaurs also have been found in the Niobrara Chalk, suggesting that animals who died on shore must have been washed out to sea (one specimen of a hadrosaur appears to have been scavenged by a shark).

"Pteranodon" fossils are known primarily from the Niobrara Formation of the central United States. Broadly defined, "Pteranodon" existed for more than four million years, during the late Coniacian to early Campanian stages of the Cretaceous period. The genus is present in most layers of the Niobrara Formation except for the upper two; in 2003, Kenneth Carpenter surveyed the distribution and dating of fossils in this formation, demonstrating that "Pteranodon sternbergi" existed there from 88 to 85 million years ago, while "P. longiceps" existed between 86 and 84.5 million years ago. A possible third species, which Kellner named "Geosternbergia maysei" in 2010, is known from the Sharon Springs member of the Pierre Shale Formation in Kansas, Wyoming, and South Dakota, dating to between 81.5 and 80.5 million years ago.

In the early 1990s, Bennett noted that the two major morphs of pteranodont present in the Niobrara Formation were precisely separated in time with little, if any, overlap. Due to this, and to their gross overall similarity, he suggested that they probably represent "chronospecies" within a single evolutionary lineage lasting about 4 million years. In other words, only one species of "Pteranodon" would have been present at any one time, and "P. sternbergi" (or "Geosternbergia") in all likelihood was the direct ancestor species of "P. longiceps".

Many researchers consider there to be at least two species of "Pteranodon". However, aside from the differences between males and females described above, the post-cranial skeletons of "Pteranodon" show little to no variation between species or specimens, and the bodies and wings of all pteranodonts were essentially identical.

Two species of "Pteranodon" are traditionally recognized as valid: "Pteranodon longiceps", the type species, and "Pteranodon sternbergi". The species differ only in the shape of the crest in adult males (described above), and possibly in the angle of certain skull bones. Because well-preserved "Pteranodon" skull fossils are extremely rare, researchers use stratigraphy (i.e. which rock layer of the geologic formation a fossil is found in) to determine species identity in most cases.

"Pteranodon sternbergi" is the only known species of "Pteranodon" with an upright crest. The lower jaw of "P. sternbergi" was long. It was collected by George F. Sternberg in 1952 and described by John Christian Harksen in 1966, from the lower portion of the Niobrara Formation. It was older than "P. longiceps" and is considered by Bennett to be the direct ancestor of the later species.

Because fossils identifiable as "P. sternbergi" are found exclusively in the lower layers of the Niobrara Formation, and "P. longiceps" fossils exclusively in the upper layers, a fossil lacking the skull can be identified based on its position in the geologic column (though for many early fossil finds, precise data about its location was not recorded, rendering many fossils unidentifiable).

Below is a cladogram showing the phylogenetic placement of this genus within Pteranodontia from Andres and Myers (2013).

Due to the subtle variations between specimens of pteranodontid from the Niobrara Formation, most researchers have assigned all of them to the single genus "Pteranodon", in at least two species ("P. longiceps" and "P. sternbergi") distinguished mainly by the shape of the crest. However, the classification of these two forms has varied from researcher to researcher. In 1972, Halsey Wilkinson Miller published a paper arguing that the various forms of "Pteranodon" were different enough to be placed in distinct subgenera. He named these "Pteranodon (Occidentalia) occidentalis" (for the now-disused species "P. occidentalis") and "Pteranodon (Sternbergia) sternbergi". However, the name "Sternbergia" was preoccupied, and in 1978 Miller re-named the species "Pteranodon (Geosternbergia) sternbergi", and named a third subgenus/species combination for "P. longiceps", as "Pteranodon (Longicepia) longiceps". Most prominent pterosaur researchers of the late 20th century however, including S. Christopher Bennett and Peter Wellnhofer, did not adopt these subgeneric names, and continued to place all pteranodont species into the single genus "Pteranodon".

In 2010, pterosaur researcher Alexander Kellner revisited H.W. Miller's classification. Kellner followed Miller's opinion that the differences between the "Pteranodon" species were great enough to place them into different genera. He placed "P. sternbergi" into the genus named by Miller, "Geosternbergia", along with the Pierre Shale skull specimen which Bennett had previously considered to be a large male "P. longiceps". Kellner argued that this specimen's crest, though incompletely preserved, was most similar to "Geosternbergia". Because the specimen was millions of years younger than any known "Geosternbergia", he assigned it to the new species "Geosternbergia maysei". Numerous other pteranodont specimens are known from the same formation and time period, and Kellner suggested they may belong to the same species as "G. maysei", but because they lack skulls, he could not confidently identify them.

A number of additional species of "Pteranodon" have been named since the 1870s, although most now are considered to be junior synonyms of two or three valid species. The best-supported is the type species, "P. longiceps", based on the well-preserved specimen including the first-known skull found by S. W. Williston. This individual had a wingspan of . Other valid species include the possibly larger "P. sternbergi", with a wingspan originally estimated at . "P. oweni" ("P. occidentalis"), "P. velox", "P. umbrosus", "P. harpyia", and "P. comptus" are considered to be "nomina dubia" by Bennett (1994) and others who question their validity. All probably are synonymous with the more well-known species.

Because the key distinguishing characteristic Marsh noted for "Pteranodon" was its lack of teeth, any toothless pterosaur jaw fragment, wherever it was found in the world, tended to be attributed to "Pteranodon" during the late nineteenth and early twentieth centuries. This resulted in a plethora of species and a great deal of confusion. The name became a wastebasket taxon, rather like the dinosaur "Megalosaurus", to label any pterosaur remains that could not be distinguished other than by the absence of teeth. Species (often dubious ones now known to be based on sexual variation or juvenile characters) have been reclassified a number of times, and several subgenera have in the 1970s been erected by Halsey Wilkinson Miller to hold them in various combinations, further confusing the taxonomy (subgenera include "Longicepia", "Occidentalia", and "Geosternbergia"). Notable authors who have discussed the various aspects of "Pteranodon" include Bennett, Padian, Unwin, Kellner, and Wellnhofer. Two species, "P. orogensis" and "P. orientalis", are not pteranodontids and have been renamed "Bennettazhia oregonensis" and "Bogolubovia orientalis" respectively.

Status of names listed below follow a survey by Bennett, 1994 unless otherwise noted.




</doc>
<doc id="24826" url="https://en.wikipedia.org/wiki?curid=24826" title="Passive voice">
Passive voice

A passive voice construction is a grammatical voice construction that is found in many languages. In a clause with passive voice, the grammatical subject expresses the "theme" or "patient" of the main verb – that is, the person or thing that undergoes the action or has its state changed. This contrasts with active voice, in which the subject has the agent role. For example, in the passive sentence "The tree was pulled down", the subject ("the tree") denotes the patient rather than the agent of the action. In contrast, the sentences "Someone pulled down the tree" and "The tree is down" are active sentences.

Typically, in passive clauses, what is usually expressed by the object (or sometimes another argument) of the verb is now expressed by the subject, while what is usually expressed by the subject is either deleted or is indicated by some adjunct of the clause. Thus, turning an active verb into a passive verb is a valence-decreasing process ("detransitivizing process"), because it turns transitive verbs into intransitive verbs. This is not always the case; for example in Japanese a passive-voice construction does not necessarily decrease valence.

Many languages have both an active and a passive voice; this allows for greater flexibility in sentence construction, as either the semantic agent or patient may take the syntactic role of subject. The use of passive voice allows speakers to organize stretches of discourse by placing figures other than the agent in subject position. This may be done to foreground the patient, recipient, or other thematic role; it may also be useful when the semantic patient is the topic of on-going discussion. The passive voice may also be used to avoid specifying the agent of an action.

Different languages use various grammatical forms to indicate passive voice.

In some languages, passive voice is indicated by verb conjugation, specific forms of the verb. Examples of languages that indicate voice through conjugation include Latin and North Germanic languages such as Swedish.

Norwegian (Nynorsk) and Icelandic have a similar system, but the usage of the passive is more restricted. The passive forms in Nynorsk are restricted to only be accompanied by an auxiliary verb, which is not the case in Swedish and Danish. 

In Latin, the agent of a passive sentence (if indicated) is expressed using a noun in the ablative case, in this case "servō" (the ablative of "servus"). Different languages use different methods for expressing the agent in passive clauses. In Swedish, the agent can be expressed by means of a prepositional phrase with the preposition "av" (equivalent here to the English "by").

The Austronesian language Kimaragang Dusun also indicates passive voice by verb conjugation using the infix, "-in-".
Other languages, including English, express the passive voice periphrastically, using an auxiliary verb.

English, like some other languages, uses a periphrastic passive. Rather than conjugating directly for voice, English uses the past participle form of the verb plus an auxiliary verb, either "be" or "get" (called linking verbs in traditional grammar), to indicate passive voice.

If the agent is mentioned, it usually appears in a prepositional phrase introduced by the preposition "by".

The subject of the passive voice usually corresponds to the direct object of the corresponding active-voice formulation (as in the above examples), but English also allows passive constructions in which the subject corresponds to an indirect object or preposition complement:
In sentences of the second type, a stranded preposition is left. This is called the "prepositional passive" or "pseudo-passive" (although the latter term can also be used with other meanings).

The active voice is the dominant voice used in English. Many commentators, notably George Orwell in his essay "Politics and the English Language" and Strunk & White in "The Elements of Style", have urged minimizing use of the passive voice, but this is almost always based on these commentators' misunderstanding of what the passive voice is. Contrary to common critiques, the passive voice has important uses, with virtually all writers using the passive voice (including Orwell and Strunk & White). 
There is general agreement that the passive voice is useful for emphasis, or when the receiver of the action is more important than the actor.

"Merriam–Webster's Dictionary of English Usage" refers to three statistical studies of passive versus active sentences in various periodicals, stating: "the highest incidence of passive constructions was 13 percent. Orwell runs to a little over 20 percent in "Politics and the English Language". Clearly he found the construction useful in spite of his advice to avoid it as much as possible".

In the field of linguistics, the term "passive" is applied to a wide range of grammatical structures. Linguists therefore find it difficult to define the term in a way that makes sense across all human languages. The canonical passive in European languages has the following properties:
The problem arises with non-European languages. Many constructions in these languages share at least one property with the canonical European passive, but not all. While it seems justified to call these constructions "passive" when comparing them to European languages' passive constructions, as a whole the passives of the world's languages do not share a single common feature.

R. M. W. Dixon has defined four criteria for determining whether a construction is a passive:
Dixon acknowledges that this excludes some constructions labeled as "passive" by some linguists.

In some languages, including several Southeast Asian languages, the passive voice is sometimes used to indicate that an action or event was unpleasant or undesirable. This so-called "adversative passive" works like the ordinary passive voice in terms of syntactic structure—that is, a theme or instrument acts as subject. In addition, the construction indicates adversative affect, suggesting that someone was negatively affected.

In Japanese, for example, the adversative passive (also called indirect passive) indicates adversative affect. The indirect or adversative passive has the same form as the direct passive. Unlike the direct passive, the indirect passive may be used with intransitive verbs.

Yup'ik, from the Eskimo-Aleut family, has two different suffixes that can indicate passive, "-cir-" and "-ma-". The morpheme "-cir-" has an adversative meaning. If an agent is included in a passive sentence with the "-cir" passive, the noun is usually in the allative (oblique) case.

In some languages, for example English, there is often a similarity between clauses expressing an action or event in the passive voice and clauses expressing a state. For example, the string of words "The dog is fed" can have the following two different meanings:
The additions in parentheses "force" the same string of words to clearly show only one of their two possible grammatical functions and the related meaning. In the first sentence, the combination of the auxiliary verb "is" and the past participle "fed" is a regular example of the construction of the passive voice in English. In the second sentence, "is" can however be interpreted as an ordinary copula and the past participle as an adjective.

Sentences of the second type are called "false passives" by some linguists, who feel that such sentences are simply confused with the passive voice due to their outward similarity. Other linguists consider the second type to be a different kind of passive – a "stative passive" (rarely called "statal", "static", or "resultative passive"), in contrast to the "dynamic" or "eventive" passive illustrated by the first sentence. Some languages express or can express these different meanings using different constructions.

The difference between dynamic and stative passives is more evident in languages such as German that use different words or constructions for the two. In German, the auxiliary verb "sein" marks static passive (German: "Zustandspassiv", rarely "statisches Passiv", in referring to German also called ""sein"-Passiv" or "Sein-Passiv"), while "werden" marks the dynamic passive ("Vorgangspassiv" or "Handlungspassiv", rarely "dynamisches Passiv", in referring to German also called ""werden"-Passiv" or "Werden-Passiv" or simply "Passiv" or "Passivum").
The English string of words "the lawn is mown" has two possible meanings corresponding to the example "the dog is fed" above. It can be used in the following two different senses:
German uses two different grammatical constructions for these sentences:

Further examples and explanations:

A number of German verbs such as "bedecken" ("cover"), "erfüllen" ("fill"), and "trennen" ("separate"), when used as stative verbs, usually only form static passives.

In English, the passive voice expressed with the auxiliary verb "get" rather than "be" ("get-passive") expresses a dynamic rather than a static meaning. But when the auxiliary verb "be" is used, the main verb can have either a dynamic or static meaning as shown below (including copies of some examples from above):

Verbs that typically express static meaning can show dynamic meaning when used in the passive formed with "get", for example "be known" (static) vs. "get known" (dynamic):


(https://wals.info/chapter/107)


</doc>
<doc id="24829" url="https://en.wikipedia.org/wiki?curid=24829" title="Primitive recursive function">
Primitive recursive function

In computability theory, a primitive recursive function is roughly speaking a function that can be computed by a computer program whose loops are all "for" loops (that is, an upper bound of the number of iterations of every loop can be determined before entering the loop). Primitive recursive functions form a strict subset of those general recursive functions that are also total functions. 

The importance of primitive recursive functions lies on the fact that most computable functions that are studied in number theory (and more generally in mathematics) are primitive recursive. For example, addition and division, the factorial and exponential function, and the function which returns the "n"th prime are all primitive recursive. In fact, for showing that a computable function is primitive recursive, it suffices to show that its computational complexity is bounded above by a primitive recursive function of the input size. It follows that it is difficult to devise a computable function that is "not" primitive recursive, although some are known (see the section on Limitations below).

The set of primitive recursive functions is known as PR in computational complexity theory.

The primitive recursive functions are among the number-theoretic functions, which are functions from the natural numbers (nonnegative integers) {0, 1, 2, ...} to the natural numbers. These functions take "n" arguments for some natural number "n" and are called "n"-ary.

The basic primitive recursive functions are given by these axioms:
More complex primitive recursive functions can be obtained by applying the operations given by these axioms:

Example. We take "f"("x") as the "S"("x") defined above. This f is a 1-ary primitive recursive function. And so is "g"("x") = "S"("x"). So "h"("x") defined as "f"("g"("x")) = "S"("S"("x")) is a primitive recursive 1-ary function too. Informally speaking, "h"("x") is the function that turns "x" into "x"+2.

Example. Suppose "f"("x") = "P"("x") = "x" and "g"("x","y","z")= "S"("P"("x","y","z")) = "S"("y"). Then "h"(0,"x") = "x" and "h"("S"("y"),"x") = "g"("y","h"("y","x"),"x") = "S"("h"("y","x")). Now "h"(0,1) = 1, "h"(1,1) = "S"("h"(0,1)) = 2, "h"(2,1) = "S"("h"(1,1)) = 3. This "h" is a 2-ary primitive recursive function. We can call it 'addition'.

Interpretation. The function "h" acts as a for loop from 0 up to the value of its first argument. The rest of the arguments for "h", denoted here with "x"’s ("i" = 1, ..., "k"), are a set of initial conditions for the For loop which may be used by it during calculations but which are immutable by it. The functions "f" and "g" on the right side of the equations which define "h" represent the body of the loop, which performs calculations. Function "f" is only used once to perform initial calculations. Calculations for subsequent steps of the loop are performed by "g". The first parameter of "g" is fed the “current” value of the For loop’s index. The second parameter of "g" is fed the result of the For loop’s previous calculations, from previous steps. The rest of the parameters for "g" are those immutable initial conditions for the For loop mentioned earlier. They may be used by "g" to perform calculations but they will not themselves be altered by "g".

The primitive recursive functions are the basic functions and those obtained from the basic functions by applying these operations a finite number of times.

The projection functions can be used to avoid the apparent rigidity in terms of the arity of the functions above; by using compositions with various projection functions, it is possible to pass a subset of the arguments of one function to another function. For example, if "g" and "h" are 2-ary primitive recursive functions then
is also primitive recursive. One formal definition using projection functions is

In some settings it is natural to consider primitive recursive functions that take as inputs tuples that mix numbers with truth values (that is "t" for true and "f" for false), or that produce truth values as outputs. This can be accomplished by identifying the truth values with numbers in any fixed manner. For example, it is common to identify the truth value "t" with the number 1 and the truth value "f" with the number 0. Once this identification has been made, the characteristic function of a set "A", which always returns 1 or 0, can be viewed as a predicate that tells whether a number is in the set "A". Such an identification of predicates with numeric functions will be assumed for the remainder of this article.

An example of a primitive recursive programming language is one that contains basic arithmetic operators (e.g. + and −, or ADD and SUBTRACT), conditionals and comparison (IF-THEN, EQUALS, LESS-THAN), and bounded loops, such as the basic for loop, where there is a known or calculable upper bound to all loops (FOR i FROM 1 TO n, with neither i nor n modifiable by the loop body). No control structures of greater generality, such as while loops or IF-THEN plus GOTO, are admitted in a primitive recursive language. Douglas Hofstadter's BlooP in "Gödel, Escher, Bach" is such a language. Adding unbounded loops (WHILE, GOTO) makes the language partially recursive, or Turing-complete; Floop is an example, as are almost all real-world computer programming languages.

Arbitrary computer programs, or Turing machines, cannot in general be analyzed to see if they halt or not (the halting problem). However, all primitive recursive functions halt. This is not a contradiction; primitive recursive programs are a non-arbitrary subset of all possible programs, constructed specifically to be analyzable.

Most number-theoretic functions definable using recursion on a single variable are primitive recursive. Basic examples include the addition and truncated subtraction functions.

Intuitively, addition can be recursively defined with the rules:

To fit this into a strict primitive recursive definition, define:

Here S("n") is "the successor of "n"" (i.e., "n"+1), "P" is the identity function, and "P" is the projection function that takes 3 arguments and returns the second one. Functions "f" and "g" required by the above definition of the primitive recursion operation are respectively played by "P" and the composition of "S" and "P".

Because primitive recursive functions use natural numbers rather than integers, and the natural numbers are not closed under subtraction, a truncated subtraction function (also called "proper subtraction") is studied in this context. This limited subtraction function sub("a", "b") [or "b" ∸ "a"] returns "b" - "a" if this is nonnegative and returns "0" otherwise.

The predecessor function acts as the opposite of the successor function and is recursively defined by the rules:

These rules can be converted into a more formal definition by primitive recursion:

The limited subtraction function is definable from the predecessor function in a manner analogous to the way addition is defined from successor:

Here sub("a", "b") corresponds to "b" ∸ "a"; for the sake of simplicity, the order of the arguments has been switched from the "standard" definition to fit the requirements of primitive recursion. This could easily be rectified using composition with suitable projections.

Exponentiation and primality testing are primitive recursive. Given primitive recursive functions "e", "f", "g", and "h", a function that returns the value of "g" when "e"≤"f" and the value of "h" otherwise is primitive recursive.

By using Gödel numberings, the primitive recursive functions can be extended to operate on other objects such as integers and rational numbers. If integers are encoded by Gödel numbers in a standard way, the arithmetic operations including addition, subtraction, and multiplication are all primitive recursive. Similarly, if the rationals are represented by Gödel numbers then the field operations are all primitive recursive.

In first-order Peano arithmetic, there are infinitely many variables (0-ary symbols) but no k-ary non-logical symbols with k>0 other than S, +, *, and ≤. Thus in order to define primitive recursive functions one has to use the following trick by Gödel.

By using a Gödel numbering for sequences, for example Gödel's β function, any finite sequence of numbers can be encoded by a single number. Such a number can therefore represent the primitive recursive function until a given n.

Let "h" be a 1-ary primitive recursion function defined by:
where C is a constant and "g" is an already defined function.

Using Gödel's β function, for any sequence of natural numbers (k, k, …, k), there are natural numbers b and c such that, for every i ≤ n, β(b, c, i) = k. We may thus use the following formula to define "h"; more precisely, "m"="h"("n") is a shorthand for the following:

and the equating to "g", being already defined, is in fact shorthand for some other already defined formula (as is β, whose formula is given here).

The generalization to any k-ary primitive recursion function is trivial.

The broader class of partial recursive functions is defined by introducing an unbounded search operator. The use of this operator may result in a partial function, that is, a relation with "at most" one value for each argument, but does not necessarily have "any" value for any argument (see domain). An equivalent definition states that a partial recursive function is one that can be computed by a Turing machine. A total recursive function is a partial recursive function that is defined for every input.

Every primitive recursive function is total recursive, but not all total recursive functions are primitive recursive. The Ackermann function "A"("m","n") is a well-known example of a total recursive function (in fact, provable total), that is not primitive recursive. There is a characterization of the primitive recursive functions as a subset of the total recursive functions using the Ackermann function. This characterization states that a function is primitive recursive if and only if there is a natural number "m" such that the function can be computed by a Turing machine that always halts within A("m","n") or fewer steps, where "n" is the sum of the arguments of the primitive recursive function.

An important property of the primitive recursive functions is that they are a recursively enumerable subset of the set of all total recursive functions (which is not itself recursively enumerable). This means that there is a single computable function "f"("m","n") that enumerates the primitive recursive functions, namely:
"f" can be explicitly constructed by iteratively repeating all possible ways of creating primitive recursive functions. Thus, it is provably total. One can use a diagonalization argument to show that "f" is not recursive primitive in itself: had it been such, so would be "h"("n") = "f"("n","n")+1. But if this equals some primitive recursive function, there is an "m" such that "h"("n") = "f"("m","n") for all "n", and then "h"("m") = "f"("m","m"), leading to contradiction.

However, the set of primitive recursive functions is not the "largest" recursively enumerable subset of the set of all total recursive functions. For example, the set of provably total functions (in Peano arithmetic) is also recursively enumerable, as one can enumerate all the proofs of the theory. While all primitive recursive functions are provably total, the converse is not true.

Primitive recursive functions tend to correspond very closely with our intuition of what a computable function must be. Certainly the initial functions are intuitively computable (in their very simplicity), and the two operations by which one can create new primitive recursive functions are also very straightforward. However, the set of primitive recursive functions does not include every possible total computable function—this can be seen with a variant of Cantor's diagonal argument. This argument provides a total computable function that is not primitive recursive. A sketch of the proof is as follows:

This argument can be applied to any class of computable (total) functions that can be enumerated in this way, as explained in the article Machine that always halts. Note however that the "partial" computable functions (those that need not be defined for all arguments) can be explicitly enumerated, for instance by enumerating Turing machine encodings.

Other examples of total recursive but not primitive recursive functions are known:

In the following we observe that primitive recursive functions can be of four types:

In the following the mark " ' ", e.g. a', is the primitive mark meaning "the successor of", usually thought of as " +1", e.g. a +1 = a'. The functions 16-20 and #G are of particular interest with respect to converting primitive recursive predicates to, and extracting them from, their "arithmetical" form expressed as Gödel numbers.

Similarly, many of the syntactic results in proof theory can be proved in PRA, which implies that there are primitive recursive functions that carry out the corresponding syntactic transformations of proofs.

In proof theory and set theory, there is an interest in finitistic consistency proofs, that is, consistency proofs that themselves are finitistically acceptable. Such a proof establishes that the consistency of a theory "T" implies the consistency of a theory "S" by producing a primitive recursive function that can transform any proof of an inconsistency from "S" into a proof of an inconsistency from "T". One sufficient condition for a consistency proof to be finitistic is the ability to formalize it in PRA. For example, many consistency results in set theory that are obtained by forcing can be recast as syntactic proofs that can be formalized in PRA.

Recursive definitions had been used more or less formally in mathematics before, but the construction of primitive recursion is traced back to Richard Dedekind's theorem 126 of his "Was sind und was sollen die Zahlen?" (1888). This work was the first to give a proof that a certain recursive construction defines a unique function.

Primitive recursive arithmetic was first proposed by Thoralf Skolem in 1923.

The current terminology was coined by Rózsa Péter (1934) after Ackermann had proved in 1928 that the function which today is named after him was not primitive recursive, an event which prompted the need to rename what until then were simply called recursive functions.




</doc>
<doc id="24830" url="https://en.wikipedia.org/wiki?curid=24830" title="Peisistratus (disambiguation)">
Peisistratus (disambiguation)

Peisistratus was a tyrant of Athens, Greece, three different times between 561 and 528 BC.

Peisistratus, Peisistratos or Pisistratus may also refer to:


</doc>
<doc id="24833" url="https://en.wikipedia.org/wiki?curid=24833" title="Prime Minister of Japan">
Prime Minister of Japan

The (informally referred to as PMOJ) is the head of government and chief executive of Japan as well as the commander-in-chief of the Japanese Armed Forces; he is appointed by the emperor of Japan after being designated by the National Diet and must enjoy the confidence of the House of Representatives to remain in office. He is the head of the Cabinet and appoints and dismisses the other ministers of state. The literal translation of the Japanese name for the office is "Minister for the Comprehensive Administration of ("or" the Presidency over) the Cabinet".

On 28 August 2020, Japanese prime minister Shinzō Abe announced his intention to resign due to his deteriorating health.

Before the adoption of the Meiji Constitution, Japan had in practice no written constitution. Originally, a Chinese-inspired legal system known as "ritsuryō" was enacted in the late Asuka period and early Nara period. It described a government based on an elaborate and rational meritocratic bureaucracy, serving, in theory, under the ultimate authority of the Emperor; although in practice, real power was often held elsewhere, such as in the hands of the Fujiwara clan, who intermarried with the Imperial Family in the Heian period, or by the ruling "shōgun". Theoretically, the last "ritsuryō" code, the Yōrō Code enacted in 752, was still in force at the time of the Meiji Restoration.

Under this system, the was the head of the "Daijō-kan" (Department of State), the highest organ of Japan's pre-modern Imperial government during the Heian period and until briefly under the Meiji Constitution with the appointment of Sanjō Sanetomi in 1871. The office was replaced in 1885 with the appointment of Itō Hirobumi to the new position of Prime Minister, four years before the enactment of the Meiji Constitution, which mentions neither the Cabinet nor the position of Prime Minister explicitly. It took its current form with the adoption of the Constitution of Japan in 1947.

To date, 62 people have served this position. Shinzō Abe is the current prime minister. He re-took the office on 26 December 2012. He is the first former prime minister to return to office since 1948, and the longest serving prime minister to date.

The prime minister is designated by both houses of the Diet, before the conduct of any other business. For that purpose, each conducts a ballot under the run-off system. If the two houses choose different individuals, then a joint committee of both houses is appointed to agree on a common candidate. Ultimately, however, if the two houses do not agree within ten days, the decision of the House of Representatives is deemed to be that of the Diet. Therefore, the House of Representatives can theoretically ensure the appointment of any prime minister it wants. The candidate is then presented with his or her commission, and formally appointed to office by the Emperor. 

In practice, the prime minister is almost always the leader of the majority party in the House of Representatives, or the leader of the senior partner in the governing coalition.




Unlike most of his counterparts in constitutional monarchies, the prime minister is both "de jure" and "de facto" chief executive. In most other constitutional monarchies, the monarch is nominal chief executive, while being bound by convention to act on the advice of the cabinet. In contrast, the Constitution of Japan explicitly vests executive power in the Cabinet, of which the prime minister is the leader. His countersignature is required for all laws and Cabinet orders. While most ministers in parliamentary democracies have some freedom of action within the bounds of cabinet collective responsibility, the Japanese Cabinet is effectively an extension of the prime minister's authority.

Located near the Diet building, the Office of the Prime Minister of Japan is called the . The original Kantei served from 1929 until 2002, when a new building was inaugurated to serve as the current Kantei. The old Kantei was then converted into the Official Residence, or . The Kōtei lies to the southwest of the Kantei, and is linked by a walkway.

The prime minister of Japan travels in a Lexus LS 600h L, the official transport for the head of government, or an unmodified Toyota Century escorted by a police motorcade of numerous Toyota Celsiors.

For long distance air travel, Japan maintains two Boeing 747-400 aircraft mostly for the prime minister of Japan, the emperor, empress and other members of the imperial family, operated by the Japan Air Self-Defense Force.

They have the radio callsigns Japanese Air Force One and Japanese Air Force Two when operating on official business, and Cygnus One and Cygnus Two when operating outside of official business (e.g., on training flights). The aircraft always fly together on government missions, with one serving as the primary transport and the other serving as a backup with maintenance personnel on board. The aircraft are officially referred to as .

The aircraft were constructed at the Boeing factory at the same time as the U.S. Air Force One VC-25s, though the U.S. aircraft were built to the 747-200 design, while the Japanese aircraft were built to the more contemporary 747-400 design. Both Japanese aircraft were delivered in 1990. The 747s will be replaced by new Boeing 777-300ER aircraft in fiscal year 2019.

Until the mid-1930s, the prime minister of Japan was normally granted a hereditary peerage ("kazoku") prior to leaving office if he had not already been ennobled. Titles were usually bestowed in the ranks of count, viscount or baron, depending on the relative accomplishments and status of the prime minister. The two highest ranks, marquess and prince, were only bestowed upon highly distinguished statesmen, and were not granted to a prime minister after 1928. The last prime minister who was a peer was Baron Kijūrō Shidehara, who served as Prime Minister from October 1945 to May 1946. The peerage was abolished when the Constitution of Japan came into effect in May 1947.

Certain eminent prime ministers have been awarded the Order of the Chrysanthemum, typically in the degree of Grand Cordon. The highest honour in the Japanese honours system, the Collar of the Order of the Chrysanthemum, has only been conferred upon select prime ministers and eminent statesmen; the last such award to a living prime minister was to Saionji Kinmochi in 1928. More often, the Order of the Chrysanthemum has been a posthumous distinction; the Collar of the order was last awarded posthumously to former prime minister Eisaku Satō in June 1975. The Grand Cordon has typically been posthumously awarded; the most recent such award was to Ryutaro Hashimoto in July 2006.

After relinquishing office, the prime minister is normally accorded the second or senior third rank in the court order of precedence, and is usually raised to the senior second rank posthumously. Certain distinguished prime ministers have been posthumously raised to the first rank; the last such award was to Sato Eisaku in 1975. Since the 1920s, following their tenure in office, Prime ministers have typically been conferred with the Grand Cordon of the Order of the Paulownia Flowers (until 2003 a special higher class of the Order of the Rising Sun), depending on tenure and eminence. However, honours may be withheld due to misconduct or refusal on the part of the prime minister (for example, Kiichi Miyazawa).





</doc>
<doc id="24834" url="https://en.wikipedia.org/wiki?curid=24834" title="Protein targeting">
Protein targeting

Protein targeting or protein sorting is the biological mechanism by which proteins are transported to their appropriate destinations in the cell or outside it. Proteins can be targeted to the inner space of an organelle, different intracellular membranes, plasma membrane, or to exterior of the cell via secretion. This delivery process is carried out based on information contained in the protein itself. Correct sorting is crucial for the cell; errors can lead to diseases.

Targeting signals are the pieces of information that enable the cellular transport machinery to correctly position a protein inside or outside the cell. This information is contained in the polypeptide chain or in the folded protein. The continuous stretch of amino acid residues in the chain that enables targeting are called signal peptides or targeting peptides. There are two types of targeting peptides, the presequences and the internal targeting peptides. The presequences of the targeting peptide are often found at the N-terminal extension and is composed of between 6-136 basic and hydrophobic amino acids. In case of peroxisomes the targeting sequence is on the C-terminal extension mostly. Other signals, known as signal patches, are composed of parts which are separate in the primary sequence. They become functional when folding brings them together on the protein surface. In addition, protein modifications like glycosylations can induce targeting.

In 1970, Günter Blobel conducted experiments on the translocation of proteins across membranes. He was awarded the 1999 Nobel prize for his findings. He discovered that many proteins have a signal sequence, that is, a short amino acid sequence at one end that functions like a postal code for the target organelle. The translation of mRNA into protein by a ribosome takes place within the cytosol. If the synthesized proteins "belong" in a different organelle, they can be transported there in either of two ways depending on the protein: Co-translational translocation (translocation during the process of translation), and post-translational translocation (translocation after the process of translation is complete).

Most proteins that are secretory, membrane-bound, or reside in the endoplasmic reticulum (ER), golgi or endosomes use the co-translational translocation pathway. This process begins with the N-terminal signal peptide of the protein being recognized by a signal recognition particle (SRP) "while the protein is still being synthesized on the ribosome". The synthesis pauses while the ribosome-protein complex is transferred to an SRP receptor on the ER in eukaryotes, and the plasma membrane in prokaryotes. There, the nascent protein is inserted into the translocon, a membrane-bound protein conducting channel composed of the Sec61 translocation complex in eukaryotes, and the homologous SecYEG complex in prokaryotes. In secretory proteins and type I transmembrane proteins, the signal sequence is immediately cleaved from the nascent polypeptide once it has been translocated into the membrane of the ER (eukaryotes) or plasma membrane (prokaryotes) by signal peptidase. The signal sequence of type II membrane proteins and some polytopic membrane proteins are not cleaved off and therefore are referred to as signal anchor sequences. Within the ER, the protein is first covered by a chaperone protein to protect it from the high concentration of other proteins in the ER, giving it time to fold correctly. Once folded, the protein is modified as needed (for example, by glycosylation), then transported to the Golgi for further processing and goes to its target organelles or is retained in the ER by various ER retention mechanisms.

The amino acid chain of transmembrane proteins, which often are transmembrane receptors, passes through a membrane one or several times. They are inserted into the membrane by translocation, until the process is interrupted by a stop-transfer sequence, also called a membrane anchor or signal-anchor sequence. These complex membrane proteins are at the moment mostly understood using the same model of targeting that has been developed for secretory proteins. However, many complex multi-transmembrane proteins contain structural aspects that do not fit the model. Seven transmembrane G-protein coupled receptors (which represent about 5% of the genes in humans) mostly do not have an amino-terminal signal sequence. In contrast to secretory proteins, the first transmembrane domain acts as the first signal sequence, which targets them to the ER membrane. This also results in the translocation of the amino terminus of the protein into the ER membrane lumen. This would seem to break the rule of "co-translational" translocation which has always held for mammalian proteins targeted to the ER. This has been demonstrated with opsin with in vitro experiments. A great deal of the mechanics of transmembrane topology and folding remains to be elucidated.

Even though most secretory proteins are co-translationally translocated, some are translated in the cytosol and later transported to the ER/plasma membrane by a post-translational system. In prokaryotes this requires certain cofactors such as SecA and SecB. This pathway is facilitated by Sec62 and Sec63, two membrane-bound proteins. The Sec63 complex is embedded in the ER membrane. The Sec63 complex causes hydrolysis of ATP, which allows chaperone proteins to bind to an exposed peptide chain and slide the polypeptide into the ER lumen. Once in the lumen the polypeptide chain can be folded properly. This occurs in only unfolded proteins that are in the cytosol. 

In addition, proteins targeted to other destinations, such as mitochondria, chloroplasts, or peroxisomes, use specialized post-translational pathways. Also, proteins targeted for the nucleus are translocated post-translation. They pass through the nuclear envelope via nuclear pores.

Most mitochondrial proteins are synthesized as cytosolic precursors containing uptake peptide signals. Cytosolic chaperones deliver preproteins to channel linked receptors in the mitochondrial membrane. The preprotein with presequence targeted for the mitochondria is bound by receptors and the General Import Pore (GIP) (Receptors and GIP are collectively known as Translocase of Outer Membrane or TOM) at the outer membrane. The preprotein is translocated through TOM as hairpin loops. The preprotein is transported through the intermembrane space by small TIMs (which also acts as molecular chaperones) to the TIM23 or 22 (Translocase of Inner Membrane) at the inner membrane. Within the matrix the targeting sequence is cleaved off by mtHsp70.

Three mitochondrial outer membrane receptors are known:
The TOM channel (TOM40) is a cation specific high conductance channel with a molecular weight of 410 kDa and a pore diameter of 21Å.

The presequence translocase23 (TIM23) is localized to the mitochondrial inner membrane and acts a pore forming protein which binds precursor proteins with its N-terminus. TIM23 acts a translocator for preproteins for the mitochondrial matrix, the inner mitochondrial membrane as well as for the intermembrane space. TIM50 is bound to TIM23 at the inner mitochondrial side and found to bind presequences. TIM44 is bound on the matrix side and found binding to mtHsp70. 
The presequence translocase22 (TIM22) binds preproteins exclusively bound for the inner mitochondrial membrane.

Mitochondrial matrix targeting sequences are rich in positively charged amino acids and hydroxylated ones.

Proteins are targeted to submitochondrial compartments by multiple signals and several pathways.

Targeting to the outer membrane, intermembrane space, and inner membrane often requires another signal sequence in addition to the matrix targeting sequence.

The preprotein for chloroplasts may contain a stromal import sequence or a stromal and thylakoid targeting sequence. The majority of preproteins are translocated through the Toc and Tic complexes located within the chloroplast envelope. In the stroma the stromal import sequence is cleaved off and folded as well as intra-chloroplast sorting to thylakoids continues. Proteins targeted to the envelope of chloroplasts usually lack cleavable sorting sequence.

Many proteins are needed in both mitochondria and chloroplasts. In general the targeting peptide is of intermediate character to the two specific ones. The targeting peptides of these proteins have a high content of basic and hydrophobic amino acids, a low content of negatively charged amino acids. They have a lower content of alanine and a higher content of leucine and phenylalanine. The dual targeted proteins have a more hydrophobic targeting peptide than both mitochondrial and chloroplastic ones.

All peroxisomal proteins are encoded by nuclear genes.

To date there are two types of known Peroxisome Targeting Signals (PTS):

Peroxisome targeting signal 1 (PTS1): a C-terminal tripeptide with a consensus sequence (S/A/C)-(K/R/H)-(L/A). The most common PTS1 is serine-lysine-leucine (SKL). Most peroxisomal matrix proteins possess a PTS1 type signal.

Peroxisome targeting signal 2 (PTS2): a nonapeptide located near the N-terminus with a consensus sequence (R/K)-(L/V/I)-XXXXX-(H/Q)-(L/A/F) (where X can be any amino acid).

There are also proteins that possess neither of these signals. Their transport may be based on a so-called "piggy-back" mechanism: such proteins associate with PTS1-possessing matrix proteins and are translocated into the peroxisomal matrix together with them.

Peroxisomal protein transport is defective in the following genetic diseases:

As discussed above (see protein translocation), most prokaryotic membrane-bound and secretory proteins are targeted to the plasma membrane by either a co-translation pathway that uses bacterial SRP or a post-translation pathway that requires SecA and SecB. At the plasma membrane, these two pathways deliver proteins to the SecYEG translocon for translocation. Bacteria may have a single plasma membrane (Gram-positive bacteria), or an inner membrane plus an outer membrane separated by the periplasm (Gram-negative bacteria). Besides the plasma membrane the majority of prokaryotes lack membrane-bound organelles as found in eukaryotes, but they may assemble proteins onto various types of inclusions such as gas vesicles and storage granules.

In gram-negative bacteria proteins may be incorporated into the plasma membrane, the outer membrane, the periplasm or secreted into the environment. Systems for secreting proteins across the bacterial outer membrane may be quite complex and play key roles in pathogenesis. These systems may be described as type I secretion, type II secretion, etc.

In most gram-positive bacteria, certain proteins are targeted for export across the plasma membrane and subsequent covalent attachment to the bacterial cell wall. A specialized enzyme, sortase, cleaves the target protein at a characteristic recognition site near the protein C-terminus, such as an LPXTG motif (where X can be any amino acid), then transfers the protein onto the cell wall. Several analogous systems are found that likewise feature a signature motif on the extracytoplasmic face, a C-terminal transmembrane domain, and cluster of basic residues on the cytosolic face at the protein's extreme C-terminus. The PEP-CTERM/exosortase system, found in many Gram-negative bacteria, seems to be related to extracellular polymeric substance production. The PGF-CTERM/archaeosortase A system in archaea is related to S-layer production. The GlyGly-CTERM/rhombosortase system, found in the Shewanella, Vibrio, and a few other genera, seems involved in the release of proteases, nucleases, and other enzymes.

Minimotif Miner is a bioinformatics tool that searches protein sequence queries for a known protein targeting sequence motifs.


 


</doc>
<doc id="24837" url="https://en.wikipedia.org/wiki?curid=24837" title="Pinochle">
Pinochle

Pinochle (), also called pinocle or penuchle, is a trick-taking, Ace-Ten card game typically for two to four players and played with a 48-card deck. It is derived from the card game bezique; players score points by trick-taking and also by forming combinations of cards into melds. It is thus considered part of a "trick-and-meld" category which also includes the game belote. Each hand is played in three phases: bidding, melds, and tricks. The standard game today is called "partnership auction pinochle".

Pinochle is thought to have two possible origins. One is that it is a cousin of binokel, with both games evolving from the game of bezique. A second alternative is that pinochle actually developed from the Swiss and, later, South German, game of binocle or binokel which in turn is a descendant of bezique. The word pinochle has several different potential derivations. It may come from the French word "binocle" meaning "eyeglasses" or "binoculars". There are suggestions that it comes from "bis" (until) and "knochle" (knuckle) because originally the game ended when a player rapped their knuckles on the table. The term may also be related to the French word "binage" for the combination of cards called "binocle". This latter pronunciation of the game was adopted by German speakers. German immigrants brought the game to America in the latter quarter of the 19th century, where it was mispronounced and misspelled "pinochle." Pinochle was the favorite card game of American Jewish and Irish immigrants, while skat was the preferred game of a majority of German immigrants.

Auction pinochle for three players has some similarities with the German game skat, although the bidding is more similar to that of bid whist.

During World War I, the city of Syracuse, New York, outlawed the playing of pinochle in a gesture of anti-German sentiment.

A pinochle deck consists of two copies of each of the 9, 10, jack, queen, king, and ace cards of all four suits, for 48 cards per deck. Aces are always considered high. Pinochle follows a nonstandard card ordering. The complete ordering from highest to lowest is A, 10, K, Q, J, 9. The game can also be played using standard ranking with a simple change to scoring.

Originally, the deck had to be composed by combining two poker, piquet or euchre decks and removing unneeded cards (a piquet deck does not have the 2–6, making it easier to modify, and a euchre deck is exactly half a pinochle deck), but with the game's popularity in the United States in the early 1900s, a single boxed deck with the necessary cards was marketed, and these specialized pinochle decks are now widely available in similar styles to common 52-card counterparts. Variants of pinochle can be played with five, six, eight or more players. These larger variations can combine two pinochle decks called a "double deck". The double deck can also be used when playing with four players; hand sizes, average scores and minimum bids are doubled.

The game is played with a deck of 48 cards and four players; one player is the dealer.

After the shuffle, the dealer will offer a cut to the player on their right, then distribute the cards. All the cards are dealt in partnership pinochle. In variations for odd numbers of players like three, a "widow's hand" (also called a "kitty", "talon", or "stock") of cards remain. Traditionally, the deal is done clockwise, dealing a packet of three or four cards at a time, starting with the player to the left (the eldest hand) and ending with the dealer. The deal rotates clockwise, so the dealer's left-hand opponent will deal next.

In auction pinochle, players bid for the points they predict their hand could earn. The highest bidder earns the right to declare the trump suit. One of the players, usually the player to the left of the dealer, or the dealer themselves, is obligated to open with a first bid. The size of bids is based on the point scale and number of decks used; traditionally, points are in multiples of 10, thus a minimum opening bid might be agreed to be 100 or 250. However, many alternate scoring rules drop the unnecessary trailing zero; in that case, bids of 10 and 25, respectively, have the same values. When a player has the turn to bid, the player may either bid or pass.

A popular variation for four (or three) player pinochle involves dealing a 4 card kitty (3 or 6 cards for three players), with the bid winner taking the kitty and discarding 4 (3 or 6) cards from his hand. The point value of the discards can sometimes be added to the bid winner's total trick count or not, depending on the pre-established rules. In three player games the 6 card kitty can often lead to very competitive and extravagant bidding.

Each bid must be greater than the previous one, and be a multiple of 10 or 25 (if playing without trailing zeroes, the bid must be one or two greater respectively). When a player passes, they can no longer bid. The auction ends when all subsequent players in rotation have passed after the last bid. The last bid becomes the "contract". The player that made this final bid will then declare trump in the suit that is desired. In some house rules, trump cannot be declared in any suit not containing a "run", "marriage" or "dix" meld.

In order for the winning bidder to win the hand, the combined total of melding and trick points must be equal to or greater than the winning bid. Thus bidding involves anticipating the points that will be accumulated from melds and from the points accumulated from winning tricks. If the combined score is lower than the bid, then the bidding team or player has been "set". This means that the total bid amount is subtracted from the total game score, often accompanied by losing the points scored in meld for that hand as well. This can result in a negative score.

A related though different style of bidding is for the players to bid individually, and partners' bids are then summed. The winning bid only decides trump; both (or all) teams' bids become their contract, meaning any team can score or be set. This creates a more balanced game.

In some versions of pinochle, after the bid has been taken and trump declared in a partnership game, the bid winning team exchanges cards. It may be two, three, or four cards, depending on the version of the game. The partner of the bid winner passes first. The objective of the partner is either to add to the total points in meld or to pass trick-winning cards. After receiving the cards, the bid winner examines what will create the strongest hand and then discards an equal number of cards back to their partner. Variations are for the bid winner and partner to exchange the designated number of cards simultaneously, or for no passing to occur.

Melding consists of displaying specific combinations of cards to all players. Typically this is done by placing the combination of cards face up on the playing surface until all players have had the opportunity to examine them. All players meld after the bid winner shows meld first. The types of melds include "arounds", "marriages", "flushes" and "pinochles". These melds are placed under "headings" where a card which is melded under a particular heading can be used again under another heading, but cannot be melded again under the same heading.

The group melds containing four of the same face cards – ace, king, queen or jack – must include one card from each of the different suits. They are scored as follows:

The marriages and flush are the "sequence melds":

A marriage in each suit is worth 240 or 24 total points, which is nothing more than the sum of the marriages, plus kings around and queens around. As a shortcut, this is called a "roundtable", "marriages around", "round house", or a "round robin".

The pinochle and dix are the "special melds".

In the most common form of the game (see variations below), any one card may be used in only one meld of each type. Thus, a queen can be used in one marriage with one king, regardless of if the player has the other king of the same suit. However, a queen can be used to score a marriage and a pinochle if the player also has the correct jack.

After the melds are displayed, the points are counted and each player totals their individual meld scores.
Because all of these values are multiples of ten, one can arrive at simplified values by removing the trailing zero from each point total. For instance, a pinochle has a simplified score of 4, a double Pinochle would score 30.

In playing cards for tricks, there are strict rules of forced play, which limit a player's ability to strategically retain high cards. The high bidder leads the play with the first card, which can be any card in the contract winner's hand, although some rules require the first card led to be a trump card. Then there are two variations of following suit depending if you are playing post-1945 or pre-1945 rules.

According to the pre-1945 rules, every player must follow the lead suit if possible. Usually every player must play a winning card against those played so far, if it is possible to do so, even when the current player expects a later player to win the hand with a better card. The only exception is if a player played a trump card when trump was not the suit led. In that case, those following that player may play any card of the lead suit, since they must follow the lead suit but are already losing to the player who played trump. Likewise, if a player cannot follow suit, but has trump, they must play trump. Again, if a player does not have any cards of the lead suit and can play a trump card higher than any other trump played so far, the player must do so, even if the player expects that a later player will beat the card. If another trump has already been played that a player cannot beat, then they can play any trump in their hand, but they still must play a trump card if they can. Only when a player has no cards in suit, and has no trump, can the player choose to play any card in their hand.

Most books of post-1945 rules say that unless trump is led, there is no requirement to try to win the trick. It is only when trump is led that "heading" the trick is mandatory. In pinochle circles and tournaments the post-1945 rules are played about half of the time according to Pagat and Hoyle.

If two identical cards are played, the first one outranks the second.

After the first trick, the winner of each trick leads the first card for the next trick, until all the cards are played.

Points are scored based on the tricks won in the hand. There are several ways to count up the points for play, but they always add up to 250 points. The last trick is always worth an additional 10 points added to any existing points in the actual trick cards. The classic counting system of pinochle is where aces are worth 11, tens are worth 10, kings are worth four, queens are worth three, jacks are worth two, and nines are worth zero. This method takes longer to count the score at the end of each hand.

A simpler method is to count aces and tens for 10 points, kings and queens for five points, and jacks and nines are worth zero.

An even simpler method has aces, tens, and kings worth 10 (and known as "counters"), and everything else zero ("garbage"). Since all points are multiples of ten in the third method, most players drop the redundant zero. Aces, tens, and kings won in tricks are worth one point. The meld scoring can also avoid the zero in the tenth place. Melds like 1,000 aces are thus worth 100. The terms "1,000 aces", "800 kings" and so on are often used, even though the point values are one-tenth.

Two-handed pinochle is the original pinochle game, while partnership, auction, and all other variants are derived from it. It is the game most similar to the original Bèzique game, whence pinochle was derived, via the German game of Binokel. The only significant difference in its rules from Bèzique is the scoring.

The original version of pinochle involves a partial deal of twelve cards to both players in packets of four, leaving a stock of 24 cards. A player can score one meld after each trick won of the first 12 tricks. Melded cards can even be used to win tricks. After each trick, players draw one card from the stock into their hand starting with the trick-winning player. For the last 12 tricks, melds are taken into each player's hand and are no longer announced by the player who wins the trick. The traditional trick-taking rules apply only for these last 12 tricks.

In variations of two-handed play, no cards are initially dealt, a distinction from all other variations. Instead, the entire deck is placed face-down on the playing surface between the two players to form the widow. One player begins the hand-building process by drawing the top card of the widow. The player can either keep that card for her or his hand or reject the card. If the player chooses to hold the initial card, the player then draws a second card from the widow, then places it face-down, without looking at it, creating a discard pile. If the player rejects the first card, the card becomes the first card in the discard pile. The second card drawn from the widow must be kept, regardless of whether she or he preferred the first card. Players alternate turns in this hand-building process until all cards are chosen.

With bidding, the player winning the bid declares trump, then lays all meld face-up on the table. The other player shows her or his melds as well. Meld points are tallied, and players return meld cards to their hands. Some varieties accept a "round house", kings and queens of each suit, and earn a bonus 10 points awarding a total of 250 points.

Trick-taking commences and continues until all held cards have been played. One variation has no "leading" requirement for the bid winner or subsequent trick winner to lead a specific card, however the rules of "following" are still observed.

When adding counters, cards from each player's discard pile are included in totals for a total of 240 counters per round, plus one counter for winning the final trick. One variation to make it more difficult for the bid-winning player, the discard pile created by drawing cards is used by the non-bidding player to score towards tricks.

In Three-handed pinochle, each player plays for him or herself. The dealer deals 15 cards to each player and three cards to the kitty—a separate pile in the middle.

All players review their cards and silently determine their bids. The player to the dealer's left initiates the bidding process. If the player has a meld, he or she is required to open the bidding; otherwise, they may pass or bid. If he or she passes, the obligation to bid passes to the next player, if meld is held. Once a player passes, he or she is out of the auction.

Bidding begins at 20, or as little as 19 if dealer, and increases in multiples of 1. The highest bidder wins the auction and turns up the three-card kitty for all to see. The three widow cards are placed in the bid winner's hand. The bid winner then declares trump and lays down meld. The other two players also lay meld face-up for count. After the appropriate points have been tallied the bid winner must set aside any three cards that have not been melded. This will reduce the bid winner's hand to 15 cards. For all three players, meld is now returned to each respective player's hand, and the round is played. During the round, a player must take at least one trick to "save one's meld", even if the trick contains no points; otherwise, no meld points will be counted for that player during that round.

After all tricks are taken, counters are tallied for each player. The three discards by the highest bidder count toward their counter score for the hand, so there is always a total of 25 points for the trick score among the three players. If the highest bidder fails to make their contract by adding meld points and trick points from the play, then their score is negative the amount of the bid for that hand. The meld count is cancelled.


The game is won when one player reaches 100 points. It is possible for two or all three players to go over 100 on the same hand. There are three methods of resolving ties:


Any time a player accidentally misplays during the play portion of the hand, it is called a renege. There are various forms of misplay:


If the bidder reneges, they automatically takes a double set and the amount of the bid is subtracted from their score. The two opposing players get to count their meld points and the remainder of the hand is thrown in.

If either of the two nonbidders misplay, the bidder automatically makes their bid. The bidder gets to score the amount of their bid and meld, the player that misplayed loses all meld and takes a single set, and the third player scores only their meld.

Card-fault misdeal
If at any point during melding or play it is determined that a non-standard deck is being used, any player may declare a card-fault misdeal. This results in the nullification of the entire hand including all meld and points obtained.

Similar to three-handed pinochle, cutthroat is a simple modification. The dealer deals the entire deck out (16 cards to each player), in packets of four. The player to the left of the dealer begins the bidding once meld has been silently determined by all players. Play continues normally in terms of scoring and trick taking. The only way to win in cutthroat pinochle, however, is to "bid and out", or to have taken the bid and surpassed the predetermined winning score. It is then possible for multiple players to go over the winning score, yet if none has taken a bid and met the resulting contract, a win has not happened and play continues. It is also possible for a person to lose with the high score if they do not take a winning bid.

Four-handed pinochle, or "partnership pinochle" is played with two teams of two players each. Partners are seated opposite from each other. Each player is dealt 12 cards. The opening bid is typically 150, but can be a higher agreed on value. All four players may bid. Both the bidder and his partner have their score count towards making the contract. High bidder names trump. There typically is no kitty. With a kitty, the four cards are distributed, one to each player, by the bid winner. Each hand must meld separately. As in the three-handed version, the first player is forced to bid when holding meld. Play is often to 1000 but can increase to 1500 during partnership.

Games with five hands or more typically modify partnership pinochle in a variety of ways. They are generally played with 1 1/2 or doubled decks, with extra dix added or withheld to make an even deal. With an odd number of players, the bidder asks for a desired card in the trump suit, with the first matching player being partner for that hand. Everyone else plays against the team. In larger groups, one or more players can sit out each hand allowing the remaining players to follow the appropriate rules for the respective number of players.

Check pinochle is a gambling variant of three-hand. It is the same as to 1000, except that players keep track of "checks". If playing for $1 stakes, each check gained means that the other two players owe a dollar. The following events cause a gain or loss of checks.


Today "double-deck" pinochle is a popular form of the game, exclusively played by the National Pinochle Association, the American Pinochle Association, the Cambridge Pinochle Association, and in the "World Series of Pinochle".

Double-deck pinochle is played with two pinochle decks, without the nines. This makes for an 80 card deck.

Play is similar to regular pinochle, except 20 cards are dealt to each person and minimum bid is increased to 500 points. In some variations, bids are made in increments of 10 or more points until 600 is reached, then by 50 points. This version often features "meld bidding", a bid made to let a partner know what is in the bidder's hand. The only communication during bidding should be a numerical number or "pass", any other way of communicating is called "talking across the table" and is forbidden.

There are occasionally different meld values for a run and a pinochle; a run being 250 or 150 points, and a pinochle being 150 or 40 points. All other aspects of the game generally remain the same.

Technical Misdeal

If a player is dealt 13 or more non-counters and no aces, the player may declare a technical misdeal. This must declared before he or she plays the first trick. A technical misdeal nullifies all points melded for all players. The hand is then re-dealt by the original dealer of that hand.

In triple-deck pinochle six play in two partnerships of three each; each player has an opponent at their right and left. Three pinochle decks with no nines are mixed together, making a pack of 120 cards. Each player is dealt 20 cards, and the rules of double deck pinochle apply, except that the minimum bid is 75, and the last trick is worth 3 points. most of the extra melds made possible by the triple pack do not count extra. i.e. if a player should hold twenty aces, five of each suit, the value would be that of double aces and triple aces combined.

Internet pinochle is almost always "double deck" except for a few applications for some smart phones. Today the Internet is host to many live professional cash tournaments, although many are still cautious about playing online because of potential cheating.

Note that this use of the term "racehorse" is inconsistent with the commonly understood meaning of the term when applied to Pinochle. As summarized by Dave LeVasseur: "Racehorse means that, after the winning bidder has named trump, that player's partner passes cards across the table"

Played much the same as "double deck" but to six hands, the point values are inflated.

Two teams are formed, 20 cards are then dealt to each player and four cards are dealt to the blind. Bidding commences with the person immediately to the left of the dealer automatically bidding 500. The winner of the bid includes the blind into their hand, calls trump and melds.

Note: all runs, double, triple, and quadruple, marriages must be in trump

The game continues with the standard rules of play. When the play is over each team adds up their points in the count with kings, 10s, and aces worth ten points, while queens and jacks are worth zero. If a team count plus meld does not equal their bid, they "go set". By going set the amount of the bid is subtracted from the team's score and their count is discarded. The other team retains both their meld and their count provided they took at least 10 points in the count.

Two full decks are dealt between eight players, forming four teams. Team members are spaced so that they are not able to see any other hands. The game is usually played to a score of 5,000 or higher. Other than this, the four player rules apply, and any variations may also be used. There is an increased possibility that when one team declares trump another team may have an equal number of trump also, which may lead to an interesting game. An optional scoring rule rewards 1,000 points for a quadruple pinochle—four jacks of diamonds and four queens of spades in a meld.

Alternate end games

One variation on winning allows a team or individual to win instantly from any score by taking all the tricks in a hand. To win in this fashion, the winning player or team must play very skillfully to prevent opposing players from taking even one lowly (even zero-point) trick. This victory is known as "pinochling". A player or team can play for this victory even if they are not the highest bidder. "pinochling" does not require a bidder to make their bid. They also can play for this victory even if their bid cannot be made with the maximum number of trick points available plus their meld. However, the highest bidding player or team can prevent other players from attempting this if they elect to "throw in" the hand before the first card is played.

When playing "bid-out" rules, a team can win without bidding if their score reaches (and remains above) the agreed upon game-ending score while their opponents fail to make their bid three times. This is known as a "slide-out".





</doc>
<doc id="24838" url="https://en.wikipedia.org/wiki?curid=24838" title="Peptidoglycan">
Peptidoglycan

Peptidoglycan or murein is a polymer consisting of sugars and amino acids that forms a mesh-like layer outside the plasma membrane of most bacteria, forming the cell wall. The sugar component consists of alternating residues of β-(1,4) linked "N"-acetylglucosamine (NAG) and "N"-acetylmuramic acid (NAM). Attached to the "N"-acetylmuramic acid is a peptide chain of three to five amino acids. The peptide chain can be cross-linked to the peptide chain of another strand forming the 3D mesh-like layer. Peptidoglycan serves a structural role in the bacterial cell wall, giving structural strength, as well as counteracting the osmotic pressure of the cytoplasm. Peptidoglycan is also involved in binary fission during bacterial cell reproduction.

The peptidoglycan layer is substantially thicker in Gram-positive bacteria (20 to 80 nanometers) than in Gram-negative bacteria (7 to 8 nanometers). Peptidoglycan forms around 90% of the dry weight of Gram-positive bacteria but only 10% of Gram-negative strains. Thus, presence of high levels of peptidoglycan is the primary determinant of the characterisation of bacteria as Gram-positive. In Gram-positive strains, it is important in attachment roles and serotyping purposes. For both Gram-positive and Gram-negative bacteria, particles of approximately 2 nm can pass through the peptidoglycan.

The peptidoglycan layer in the bacterial cell wall is a crystal lattice structure formed from linear chains of two alternating amino sugars, namely "N"-acetylglucosamine (GlcNAc or NAGA) and "N"-acetylmuramic acid (MurNAc or NAMA). The alternating sugars are connected by a β-(1,4)-glycosidic bond. Each MurNAc is attached to a short (4- to 5-residue) amino acid chain, containing -alanine, -glutamic acid, "meso"-diaminopimelic acid, and -alanine in the case of "Escherichia coli" (a Gram-negative bacterium) or -alanine, -glutamine, -lysine, and -alanine with a 5-glycine interbridge between tetrapeptides in the case of "Staphylococcus aureus" (a Gram-positive bacterium). Peptidoglycan is one of the most important sources of D-amino acids in nature.

Cross-linking between amino acids in different linear amino sugar chains occurs with the help of the enzyme DD-transpeptidase and results in a 3-dimensional structure that is strong and rigid. The specific amino acid sequence and molecular structure vary with the bacterial species.

The peptidoglycan monomers are synthesized in the cytosol and are then attached to a membrane carrier bactoprenol. Bactoprenol transports peptidoglycan monomers across the cell membrane where they are inserted into the existing peptidoglycan.

In the first step of peptidoglycan synthesis, glutamine, which is an amino acid, donates an amino group to a sugar, fructose 6-phosphate. This turns fructose 6-phosphate into glucosamine-6-phosphate. In step two, an acetyl group is transferred from acetyl CoA to the amino group on the glucosamine-6-phosphate creating "N"-acetyl-glucosamine-6-phosphate. In step three of the synthesis process, the "N"-acetyl-glucosamine-6-phosphate is isomerized, which will change "N"-acetyl-glucosamine-6-phosphate to "N"-acetyl-glucosamine-1-phosphate.

In step 4, the "N"-acetyl-glucosamine-1-phosphate, which is now a monophosphate, attacks UTP. Uridine triphosphate, which is a pyrimidine nucleotide, has the ability to act as an energy source. In this particular reaction, after the monophosphate has attacked the UTP, an inorganic pyrophosphate is given off and is replaced by the monophosphate, creating UDP-N-acetylglucosamine (2,4). (When UDP is used as an energy source, it gives off an inorganic phosphate.) This initial stage, is used to create the precursor for the NAG in peptidoglycan.

In step 5, some of the UDP-N-acetylglucosamine (UDP-GlcNAc) is converted to UDP-MurNAc (UDP-N-acetylmuramic acid) by the addition of a lactyl group to the glucosamine. Also in this reaction, the C3 hydroxyl group will remove a phosphate from the alpha carbon of phosphoenolpyruvate. This creates what is called an enol derivative that will be reduced to a “lactyl moiety” by NADPH in step six.

In step 7, the UDP–MurNAc is converted to UDP-MurNAc pentapeptide by the addition of five amino acids, usually including the dipeptide -alanyl--alanine. Each of these reactions requires the energy source ATP. This is all referred to as Stage one.

Stage two occurs in the cytoplasmic membrane. It is in the membrane where a lipid carrier called bactoprenol carries peptidoglycan precursors through the cell membrane. Bactoprenol will attack the UDP-MurNAc penta, creating a PP-MurNac penta, which is now a lipid. UDP-GlcNAc is then transported to MurNAc, creating Lipid-PP-MurNAc penta-GlcNAc, a disaccharide, also a precursor to peptidoglycan. How this molecule is transported through the membrane is still not understood. However, once it is there, it is added to the growing glycan chain. The next reaction is known as tranglycosylation. In the reaction, the hydroxyl group of the GlcNAc will attach to the MurNAc in the glycan, which will displace the lipid-PP from the glycan chain. The enzyme responsible for this is transglycosylase.
Some antibacterial drugs such as penicillin interfere with the production of peptidoglycan by binding to bacterial enzymes known as penicillin-binding proteins or DD-transpeptidases. Penicillin-binding proteins form the bonds between oligopeptide crosslinks in peptidoglycan. For a bacterial cell to reproduce through binary fission, more than a million peptidoglycan subunits (NAM-NAG+oligopeptide) must be attached to existing subunits. Mutations in genes coding for transpeptidases that lead to reduced interactions with an antibiotic are a significant source of emerging antibiotic resistance.

Lysozyme, which is found in tears and constitutes part of the body's innate immune system exerts its antibacterial effect by breaking the β-(1,4)-glycosidic bonds in peptidoglycan (see above).

Some archaea have a similar layer of pseudopeptidoglycan (also known as pseudomurein), in which the sugar residues are β-(1,3) linked "N"-acetylglucosamine and "N"-acetyltalosaminuronic acid. This makes the cell walls of such archaea insensitive to lysozyme.



</doc>
<doc id="24844" url="https://en.wikipedia.org/wiki?curid=24844" title="PDE">
PDE

PDE may refer to:



</doc>
<doc id="24845" url="https://en.wikipedia.org/wiki?curid=24845" title="Pope Sixtus IV">
Pope Sixtus IV

Pope Sixtus IV (21 July 1414 – 12 August 1484), born Francesco della Rovere, was head of the Catholic Church and ruler of the Papal States from 9 August 1471 to his death. His accomplishments as pope included the construction of the Sistine Chapel and the creation of the Vatican Archives. A patron of the arts, he brought together the group of artists who ushered the Early Renaissance into Rome with the first masterpieces of the city's new artistic age.

Sixtus founded the Spanish Inquisition through the bull "Exigit sincerae devotionis affectus" (1478), and he annulled the decrees of the Council of Constance. He was noted for his nepotism and was personally involved in the infamous Pazzi conspiracy.

Francesco was born to a family of modest means from Liguria, Italy, the son of Leonardo della Rovere and Luchina Monleoni. He was born in Celle Ligure, a town near Savona.

As a young man, Della Rovere joined the Franciscan Order, an unlikely choice for a political career, and his intellectual qualities were revealed while he was studying philosophy and theology at the University of Pavia. He went on to lecture at Padua and many other Italian universities.

In 1464, Della Rovere was elected Minister General of the Franciscan order at the age of 50. In 1467, he was appointed Cardinal by Pope Paul II with the titular church being the Basilica of San Pietro in Vincoli. Before his papal election, Cardinal della Rovere was renowned for his unworldliness and had written learned treatises, including "On the Blood of Christ" and "On the Power of God". His reputation for piety was one of the deciding factors that prompted the College of Cardinals to elect him Pope upon the unexpected death of Paul II at the age of fifty-four.

Upon being elected Pope, Della Rovere adopted the name Sixtus, which had not been used since the 5th century. One of his first acts was to declare a renewed crusade against the Ottoman Turks in Smyrna. However, after the conquest of Smyrna, the fleet disbanded. Some fruitless attempts were made towards unification with the Greek Church. For the remainder of his pontificate, Sixtus turned to temporal issues and dynastic considerations.

Sixtus IV sought to strengthen his position by surrounding himself with relatives and friends. In the fresco by Melozzo da Forlì, he is accompanied by his Della Rovere and Riario nephews, not all of whom were made cardinals; the protonotary apostolic Pietro Riario (on his right), the future Pope Julius II/ Giuliano Della Rovere standing before him; and Girolamo Riario and Giovanni della Rovere, behind the kneeling Platina, author of the first humanist history of the popes. His nephew Pietro Riario also benefited from his nepotism. Pietro became one of the richest men in Rome and was entrusted with Pope Sixtus' foreign policy. However, Pietro died prematurely in 1474, and his role passed to Giuliano Della Rovere.

The secular fortunes of the Della Rovere family began when Sixtus invested his nephew Giovanni with the lordship of Senigallia and arranged his marriage to the daughter of Federico III da Montefeltro, duke of Urbino; from that union came a line of Della Rovere dukes of Urbino that lasted until the line expired, in 1631. Six of the thirty-four cardinals that he created were his nephews.

In his territorial aggrandizement of the Papal States, his niece's son Cardinal Raffaele Riario, for whom the Palazzo della Cancelleria was constructed, was suspected of colluding in the failed Pazzi conspiracy of 1478 to assassinate both Lorenzo de' Medici and his brother Giuliano and replace them in Florence with Sixtus IV's other nephew, Girolamo Riario. Francesco Salviati, Archbishop of Pisa and a main organizer of the plot, was hanged on the walls of the Florentine Palazzo della Signoria. Sixtus IV replied with an interdict and two years of war with Florence.

According to the later published chronicle of the Italian historian Stefano Infessura, "Diary of the City of Rome", Sixtus was a "lover of boys and sodomites", awarding benefices and bishoprics in return for sexual favours and nominating a number of young men as cardinals, some of whom were celebrated for their good looks. However, Infessura had partisan allegiances to the Colonna and so is not considered to be always reliable or impartial. The English churchman and Protestant polemicist John Bale, writing a century later, attributed to Sixtus "the authorisation to practice sodomy during periods of warm weather" to the "Cardinal of Santa Lucia". Although such accusations are easily dismissed as anti-Catholic propaganda, they still prompted the noted historian of the Catholic Church, Ludwig von Pastor, to issue a firm rebuttal.

Sixtus continued a dispute with King Louis XI of France, who upheld the Pragmatic Sanction of Bourges (1438), which held that papal decrees needed royal assent before they could be promulgated in France. That was a cornerstone of the privileges claimed for the Gallican Church and could never be shifted as long as Louis XI manoeuvred to replace King Ferdinand I of Naples with a French prince. Louis was thus in conflict with the papacy, and Sixtus could not permit it.

On 1 November 1478, Sixtus published the papal bull "Exigit Sincerae Devotionis Affectus" through which the Spanish Inquisition was established in the Kingdom of Castile. Sixtus consented under political pressure from Ferdinand of Aragon, who threatened to withhold military support from his kingdom of Sicily. Nevertheless, Sixtus IV quarrelled over protocol and prerogatives of jurisdiction; he was unhappy with the excesses of the Inquisition and condemned the most flagrant abuses in 1482.

As a temporal prince who constructed stout fortresses in the Papal States, he encouraged the Venetians to attack Ferrara, which he wished to obtain for another nephew. Ercole I d'Este, Duke of Ferrara, was allied with the Sforzas of Milan, the Medicis of Florence along with the King of Naples, normally a hereditary ally and champion of the papacy. The angered Italian princes allied to force Sixtus IV to make peace to his great annoyance. For refusing to desist from the very hostilities that he himself had instigated and for being a dangerous rival to Della Rovere dynastic ambitions in the Marche, Sixtus placed Venice under interdict in 1483. He also lined the coffers of the state by unscrupulously selling high offices and privileges.

In ecclesiastical affairs, Sixtus promoted the dogma of the Immaculate Conception, which had been confirmed at the Council of Basle in 1439, and he designated 8 December as its feastday. In 1476, he issued the apostolic constitution "Cum Praeexcelsa", establishing a Mass and Office for the feast. He formally annulled the decrees of the Council of Constance in 1478.

The two papal bulls issued by Pope Nicholas V, "Dum Diversas" of 1452 and "Romanus Pontifex" of 1455, had effectively given the Portuguese the rights to acquire slaves along the African Coast by force or trade. Those concessions were confirmed by Sixtus in his own bull, "Aeterni regis", of 21 June 1481. Arguably the "ideology of conquest" expounded in those texts became the means by which commerce and conversion were facilitated.

In November 1476, Isabel and Fernando ordered an investigation into rights of conquest in the Canary Islands, and in the spring of 1478, they sent Juan Rejon with sixty soldiers and thirty cavalry to the Grand Canary, where the natives retreated inland.

Sixtus's earlier threats to excommunicate all captains or pirates who enslaved Christians in the bull "Regimini Gregis" of 1476 could have been intended to emphasise the need to convert the natives of the Canary Islands and Guinea and establish a clear difference in status between those who had converted and those who resisted. The ecclesiastical penalties were directed towards those who were enslaving the recent converts.

As a civic patron in Rome, even the anti-papal chronicler Stefano Infessura agreed that Sixtus should be admired. The dedicatory inscription in the fresco by Melozzo da Forlì in the Vatican Palace records: "You gave your city temples, streets, squares, fortifications, bridges and restored the Acqua Vergine as far as the Trevi..." In addition to restoring the aqueduct that provided Rome an alternative to the river water, which had made the city famously unhealthy, he restored or rebuilt over 30 of Rome's dilapidated churches such as San Vitale (1475) and Santa Maria del Popolo, and he added seven new ones. The Sistine Chapel was sponsored by Sixtus IV, as was the "Ponte Sisto", the Sistine Bridge (the first new bridge across the Tiber since Antiquity) and the building of "Via Sistina" (later named "Borgo Sant'Angelo"), a road leading from Castel Sant'Angelo to Saint Peter. All of that was done to facilitate the integration of the Vatican Hill and Borgo with the heart of Old Rome. That was part of a broader scheme of urbanization carried out under Sixtus IV, who swept the long-established markets from the Campidoglio in 1477 and decreed in a bull of 1480 the widening of streets and the first post-Roman paving, the removal of porticoes and other post-classical impediments to free public passage.
At the beginning of his papacy, in 1471, Sixtus had donated several historically important Roman sculptures that founded a papal collection of art, which would eventually develop into the collections of the Capitoline Museums. He also refounded, enriched and enlarged the Vatican Library. He had Regiomontanus attempt the first sanctioned reorganisation of the Julian calendar and increased the size and prestige of the papal chapel choir, bringing singers and some prominent composers (Gaspar van Weerbeke, Marbrianus de Orto and Bertrandus Vaqueras) to Rome from the north.

In addition to being a patron of the arts, Sixtus was a patron of the sciences. Before he became pope, he had spent time at the very liberal and cosmopolitan University of Padua, which maintained considerable independence from the Church and had a very international character. As Pope, he issued a papal bull allowing local bishops to give the bodies of executed criminals and unidentified corpses to physicians and artists for dissection. It was that access to corpses which allowed the anatomist Vesalius, along with Titian's pupil Jan Stephen van Calcar, to complete the revolutionary medical/anatomical text "De humani corporis fabrica".

The Pope created 34 cardinals in eight consistories held during his reign, among them three nephews, one grandnephew and one other relative, thus continuing the practice of nepotism that he and his successors would engage in during this period.

Sixtus IV named seven new saints with the most notable being Bonaventure (1482); he also beatified one person: John Buoni (1483).

In 1477, Sixtus IV issued a papal bull, authorizing the creation of Uppsala University - the first university in Sweden and in the whole of Scandinavia. The choice of this location for the university derived from the fact that the archbishopric of Uppsala had been one of the most important sees in Sweden proper since Christianity first spread to this region in the ninth century, as well as Uppsala being long-standing hub for regional trade. Uppsala's bull, which granted the university its corporate rights, established a number of provisions. Among the most important of these was that the university was officially given the same freedoms and privileges as the University of Bologna. This included the right to establish the four traditional faculties of theology, law (Canon Law and Roman law), medicine, and philosophy, and to award the bachelor's, master's, licentiate, and doctoral degrees. The archbishop of Uppsala was also named as the university's Chancellor, and was charged with maintaining the rights and privileges of the university and its members. This act of Sixtus IV had a profound long-term effect on the society and culture of Sweden, an effect which continues up to the present.

Sixtus IV became ill on 8 August 1484; this illness worsened on 10 August while the pope was attending an event in Rome. He felt unwell that evening and was forced to cancel a meeting he was to hold with his cardinals the following morning. The Pope grew weaker during the night of 11 August and he was unable to sleep. Pope Sixtus IV died the following evening - 12 August.
The envoy of the Medici family summed up Sixtus' reign in the announcement to his master 'Today at 5 o'clock His Holiness Sixtus IV departed this life-may God forgive him!' 

Pope Sixtus's tomb was destroyed in the Sack of Rome in 1527. Today, his remains, along with the remains of his nephew Pope Julius II (Giuliano della Rovere), are interred in St. Peter's Basilica, in the floor in front of the monument to Pope Clement X. A marble tombstone marks the site.

His bronze funerary monument, now in the basement Treasury of St. Peter's Basilica, made like a giant casket of goldsmith's work, is by Antonio Pollaiuolo. The top of the casket is a lifelike depiction of the Pope lying in state. Around the sides are bas-relief panels depicting allegorical female figures representing Grammar, Rhetoric, Arithmetic, Geometry, Music, Painting, Astronomy, Philosophy and Theology—the classical liberal arts, with the addition of painting and theology. Each figure incorporates the oak tree ("rovere" in Italian), symbol of Sixtus IV. The overall program of the panels, their beauty, complex symbolism, classical references and their relative arrangement are compelling and comprehensive illustrations of the Renaissance worldview. None of them actually states how he died.

Sixtus created an unusually large number of cardinals during his pontificate (23) who were drawn from the roster of the princely houses of Italy, France and Spain, thus ensuring that many of his policies continued after his death:


Pope Sixtus is portrayed by Arthur Grosser in the short film "", a prequel to the video game "Assassin's Creed II".

Pope Sixtus is portrayed by James Faulkner in the historical fantasy "Da Vinci's Demons" as having an identical twin, Alessandro. Shortly after the true Pope Sixtus, Francesco, was elected on conclave, Alessandro usurped the Holy See and had his brother locked up in Castel Sant'Angelo. The series implies that many of the more unsavoury parts of Sixtus' reign were really the work of his evil twin, who was out to gain power for himself.

Pope Sixtus is portrayed by Raul Bova in the second season, and John Lynch in the third season of the TV series "".





</doc>
<doc id="24849" url="https://en.wikipedia.org/wiki?curid=24849" title="Panama Canal">
Panama Canal

The Panama Canal () is an artificial waterway in Panama that connects the Atlantic Ocean with the Pacific Ocean. The canal cuts across the Isthmus of Panama and is a conduit for maritime trade. Canal locks are at each end to lift ships up to Gatun Lake, an artificial lake created to reduce the amount of excavation work required for the canal, 26 m (85 ft) above sea level, and then lower the ships at the other end. The original locks are 32.5 m (110 ft) wide. A third, wider lane of locks was constructed between September 2007 and May 2016. The expanded canal began commercial operation on June 26, 2016. The new locks allow transit of larger, neo-Panamax ships, capable of handling more cargo.

France began work on the canal in 1881, but stopped because of engineering problems and a high worker mortality rate. The United States took over the project in 1904 and opened the canal on August 15, 1914. One of the largest and most difficult engineering projects ever undertaken, the Panama Canal shortcut greatly reduced the time for ships to travel between the Atlantic and Pacific oceans, enabling them to avoid the lengthy, hazardous Cape Horn route around the southernmost tip of South America via the Drake Passage or Strait of Magellan and the even less popular route through the Arctic Archipelago and the Bering Strait.

Colombia, France, and later the United States controlled the territory surrounding the canal during construction. The US continued to control the canal and surrounding Panama Canal Zone until the 1977 Torrijos–Carter Treaties provided for handover to Panama. After a period of joint American–Panamanian control, in 1999, the canal was taken over by the Panamanian government. It is now managed and operated by the government-owned Panama Canal Authority.

Annual traffic has risen from about 1,000 ships in 1914, when the canal opened, to 14,702 vessels in 2008, for a total of 333.7 million Panama Canal/Universal Measurement System (PC/UMS) tons. By 2012, more than 815,000 vessels had passed through the canal. It takes 11.38 hours to pass through the Panama Canal. The American Society of Civil Engineers has ranked the Panama Canal one of the seven wonders of the modern world.

The earliest record related to a canal across the Isthmus of Panama was in 1534, when Charles V, Holy Roman Emperor and King of Spain, ordered a survey for a route through the Americas in order to ease the voyage for ships traveling between Spain and Peru. The Spanish were seeking to gain a military advantage over the Portuguese.

In 1668, the English physician and philosopher Sir Thomas Browne speculated in his encyclopaedic work, "Pseudodoxia Epidemica," that "some Isthmus have been eat through by the Sea, and others cut by the spade: And if policy would permit, that of Panama in America were most worthy the attempt: it being but few miles over, and would open a shorter cut unto the East Indies and China".

In 1788, American Thomas Jefferson, then Minister to France, suggested that the Spanish should build the canal, since they controlled the colonies where it would be built. He said that this would be a less treacherous route for ships than going around the southern tip of South America, and that tropical ocean currents would naturally widen the canal after construction. During an expedition from 1788 to 1793, Alessandro Malaspina outlined plans for construction of a canal.

Given the strategic location of Panama, and the potential of its narrow isthmus separating two great oceans, other trade links in the area were attempted over the years. The ill-fated Darien scheme was launched by the Kingdom of Scotland in 1698 to set up an overland trade route. Generally inhospitable conditions thwarted the effort, and it was abandoned in April 1700.

Numerous canals were built in other countries in the late 18th and early 19th centuries. The success of the Erie Canal through central New York in the United States in the 1820s, and the collapse of the Spanish Empire in Latin America resulted in growing American interest in building an inter-oceanic canal. Beginning in 1826, US officials began negotiations with Gran Colombia (present-day Colombia, Venezuela, Ecuador, and Panama), hoping to gain a concession to build a canal. Jealous of their newly gained independence and fearing domination by the more powerful United States, president Simón Bolívar and New Granada officials declined American offers. The new nation was politically unstable, and Panama rebelled several times during the 19th century.

Great Britain attempted to develop a canal in 1843. According to the "New York Daily Tribune", August 24, 1843, Barings of London and the Republic of New Granada entered into a contract for construction of a canal across the Isthmus of Darien (Isthmus of Panama). They referred to it as the Atlantic and Pacific Canal, and it was a wholly British endeavor. Projected for completion in five years, the plan was never carried out. At nearly the same time, other ideas were floated, including a canal (and/or a railroad) across Mexico's Isthmus of Tehuantepec. That did not develop, either.

In 1846, the Mallarino–Bidlack Treaty, negotiated between the US and New Granada, granted the United States transit rights and the right to intervene militarily in the isthmus. In 1848, the discovery of gold in California, on the West Coast of the United States, generated renewed interest in a canal crossing between the Atlantic and Pacific oceans. William H. Aspinwall, who had won the federal subsidy to build and operate the Pacific mail steamships at around the same time, benefited from the gold discovery. Aspinwall's route included steamship legs from New York City to Panama, and from Panama to California, with an overland portage through Panama. This route with an overland leg in Panama was soon frequently traveled, as it provided one of the fastest connections between San Francisco, California, and the East Coast cities, about 40 days' transit in total. Nearly all the gold that was shipped out of California went by the fast Panama route. Several new and larger paddle steamers were soon plying this new route, including private steamship lines owned by American entrepreneur Cornelius Vanderbilt that made use of an overland route through Nicaragua.

In 1850 the United States began construction of the Panama Railroad (now called the Panama Railway) to cross the isthmus; it opened in 1855. This overland link became a vital piece of Western Hemisphere infrastructure, greatly facilitating trade. The later canal route was constructed parallel to it, as it had helped clear dense forests.

An all-water route between the oceans was still the goal. In 1855 William Kennish, a Manx-born engineer working for the United States government, surveyed the isthmus and issued a report on a route for a proposed Panama Canal. His report was published as a book entitled "The Practicability and Importance of a Ship Canal to Connect the Atlantic and Pacific Oceans".

In 1877, Armand Reclus, an officer with the French Navy, and Lucien Napoléon Bonaparte Wyse, both engineers, surveyed the route and published a French proposal for a canal. The French had achieved success in building the Suez Canal in the Mideast. While it was a lengthy project, they were encouraged to plan for a canal to cross the Panamanian isthmus.

The first attempt to construct a canal through what was then Colombia's province of Panama began on January 1, 1881. The project was inspired by the diplomat Ferdinand de Lesseps, who was able to raise considerable funds in France as a result of the huge profits generated by his successful construction of the Suez Canal. Although the Panama Canal needed to be only 40 percent as long as the Suez Canal, it was much more of an engineering challenge due to the combination of tropical rain forests, debilitating climate, the need for canal locks, and the lack of any ancient route to follow.

De Lesseps wanted a sea-level canal (like the Suez), but he visited the site only a few times, during the dry season which lasts only four months of the year. His men were totally unprepared for the rainy season, during which the Chagres River, where the canal started, became a raging torrent, rising up to 10 m (35 ft). The dense jungle was alive with venomous snakes, insects, and spiders, but the worst challenges were yellow fever, malaria, and other tropical diseases, which killed thousands of workers; by 1884, the death rate was over 200 per month. Public health measures were ineffective because the role of the mosquito as a disease vector was then unknown. Conditions were downplayed in France to avoid recruitment problems, but the high mortality rate made it difficult to maintain an experienced workforce.

Workers had to continually widen the main cut through the mountain at Culebra and reduce the angles of the slopes to minimize landslides into the canal. Steam shovels were used in the construction of the canal, purchased from Bay City Industrial Works, a business owned by William L. Clements in Bay City, Michigan. Bucket chain excavators manufactured by both Alphonse Couvreux and Wehyer & Richemond and Buette were also used. Other mechanical and electrical equipment was limited in capabilities, and steel equipment rusted rapidly in the rainy climate.

In France, de Lesseps kept the investment and supply of workers flowing long after it was obvious that the targets were not being met, but eventually the money ran out. The French effort went bankrupt in 1889 after reportedly spending US$287,000,000; an estimated 22,000 men died from disease and accidents, and the savings of 800,000 investors were lost. Work was suspended on May 15, and in the ensuing scandal, known as the Panama affair, some of those deemed responsible were prosecuted, including Gustave Eiffel. De Lesseps and his son Charles were found guilty of misappropriation of funds and sentenced to five years' imprisonment. This sentence was later overturned, and the father, at age 88, was never imprisoned.

In 1894, a second French company, the Compagnie Nouvelle du Canal de Panama, was created to take over the project. A minimal workforce of a few thousand people was employed primarily to comply with the terms of the Colombian Panama Canal concession, to run the Panama Railroad, and to maintain the existing excavation and equipment in saleable condition. The company sought a buyer for these assets, with an asking price of US$109,000,000. In the meantime, they continued with enough activity to maintain their franchise. Phillipe Bunau-Varilla, the French manager of the New Panama Canal Company, eventually managed to persuade de Lesseps that a lock-and-lake canal was more realistic than a sea-level canal.

At this time, the President and the Senate of the United States were interested in establishing a canal across the isthmus, with some favoring a canal across Nicaragua and others advocating the purchase of the French interests in Panama. Bunau-Varilla, who was seeking American involvement, asked for $100 million, but accepted $40 million in the face of the Nicaraguan option. In June 1902, the US Senate voted in favor of the Spooner Act, to pursue the Panamanian option, provided the necessary rights could be obtained.

On January 22, 1903, the Hay–Herrán Treaty was signed by United States Secretary of State John M. Hay and Colombian Chargé Dr. Tomás Herrán. For $10 million and an annual payment, it would have granted the United States a renewable lease in perpetuity from Colombia on the land proposed for the canal. The treaty was ratified by the US Senate on March 14, 1903, but the Senate of Colombia did not ratify it. Bunau-Varilla told President Theodore Roosevelt and Hay of a possible revolt by Panamanian rebels who aimed to separate from Colombia, and hoped that the United States would support the rebels with US troops and money.

Roosevelt changed tactics, based in part on the Mallarino–Bidlack Treaty of 1846, and actively supported the separation of Panama from Colombia. Shortly after recognizing Panama, he signed a treaty with the new Panamanian government under terms similar to the Hay–Herrán Treaty.

On November 2, 1903, US warships blocked sea lanes against possible Colombian troop movements en route to put down the Panama rebellion. Panama declared independence on November 3, 1903. The United States quickly recognized the new nation. On November 6, 1903, Philippe Bunau-Varilla, as Panama's ambassador to the United States, signed the Hay–Bunau-Varilla Treaty, granting rights to the United States to build and indefinitely administer the Panama Canal Zone and its defenses. This is sometimes misinterpreted as the "99-year lease" because of misleading wording included in article 22 of the agreement. Almost immediately, the treaty was condemned by many Panamanians as an infringement on their country's new national sovereignty. This would later become a contentious diplomatic issue among Colombia, Panama, and the United States.

President Roosevelt famously stated, "I took the Isthmus, started the canal and then left Congress not to debate the canal, but to debate me." Several parties in the United States called this an act of war on Colombia: The "New York Times" described the support given by the United States to Bunau-Varilla as an "act of sordid conquest." The "New York Evening Post" called it a "vulgar and mercenary venture." The US maneuvers are often cited as the classic example of US gunboat diplomacy in Latin America, and the best illustration of what Roosevelt meant by the old African adage, "Speak softly and carry a big stick [and] you will go far." After the revolution in 1903, the Republic of Panama became a US protectorate until 1939.

In 1904, the United States purchased the French equipment and excavations, including the Panama Railroad, for US$40 million, of which $30 million related to excavations completed, primarily in the Culebra Cut, valued at about $1.00 per cubic yard. The United States also paid the new country of Panama $10 million and a $250,000 payment each following year.

In 1921, Colombia and the United States entered into the Thomson–Urrutia Treaty, in which the United States agreed to pay Colombia $25 million: $5 million upon ratification, and four-$5 million annual payments, and grant Colombia special privileges in the Canal Zone. In return, Colombia recognized Panama as an independent nation.

The US formally took control of the canal property on May 4, 1904, inheriting from the French a depleted workforce and a vast jumble of buildings, infrastructure, and equipment, much of it in poor condition. A US government commission, the Isthmian Canal Commission (ICC), was established to oversee construction; it was given control of the Panama Canal Zone, over which the United States exercised sovereignty. The commission reported directly to Secretary of War William Howard Taft and was directed to avoid the inefficiency and corruption that had plagued the French 15 years earlier.

On May 6, 1904, President Theodore Roosevelt appointed John Findley Wallace, formerly chief engineer and finally general manager of the Illinois Central Railroad, as chief engineer of the Panama Canal Project. Overwhelmed by the disease-plagued country and forced to use often dilapidated French infrastructure and equipment, as well as being frustrated by the overly bureaucratic ICC, Wallace resigned abruptly in June 1905. He was succeeded by John Frank Stevens, a self-educated engineer who had built the Great Northern Railroad. Stevens was not a member of the ICC; he increasingly viewed its bureaucracy as a serious hindrance, bypassing the commission and sending requests and demands directly to the Roosevelt administration in Washington, DC.

One of Stevens' first achievements in Panama was in building and rebuilding the housing, cafeterias, hotels, water systems, repair shops, warehouses, and other infrastructure needed by the thousands of incoming workers. Stevens began the recruitment effort to entice thousands of workers from the United States and other areas to come to the Canal Zone to work, and tried to provide accommodation in which the incoming workers could work and live in reasonable safety and comfort. He also re-established and enlarged the railway, which was to prove crucial in transporting millions of tons of soil from the cut through the mountains to the dam across the Chagres River.

Colonel William C. Gorgas had been appointed chief sanitation officer of the canal construction project in 1904. Gorgas implemented a range of measures to minimize the spread of deadly diseases, particularly yellow fever and malaria, which had recently been shown to be mosquito-borne following the work of Dr. Carlos Finlay and Dr. Walter Reed. Investment was made in extensive sanitation projects, including city water systems, fumigation of buildings, spraying of insect-breeding areas with oil and larvicide, installation of mosquito netting and window screens, and elimination of stagnant water. Despite opposition from the commission (one member said his ideas were barmy), Gorgas persisted, and when Stevens arrived, he threw his weight behind the project. After two years of extensive work, the mosquito-spread diseases were nearly eliminated. Even after all that effort, about 5,600 workers died of disease and accidents during the US construction phase of the canal.

In 1905, a US engineering panel was commissioned to review the canal design, which had not been finalized. The panel recommended to President Roosevelt a sea-level canal, as had been attempted by the French. But in 1906 Stevens, who had seen the Chagres in full flood, was summoned to Washington; he declared a sea-level approach to be "an entirely untenable proposition". He argued in favor of a canal using a lock system to raise and lower ships from a large reservoir above sea level. This would create both the largest dam (Gatun Dam) and the largest man-made lake (Gatun Lake) in the world at that time. The water to refill the locks would be taken from Gatun Lake by opening and closing enormous gates and valves and letting gravity propel the water from the lake. Gatun Lake would connect to the Pacific through the mountains at the Gaillard (Culebra) Cut. Stevens successfully convinced Roosevelt of the necessity and feasibility of this alternative scheme.

The construction of a canal with locks required the excavation of more than of material over and above the excavated by the French. As quickly as possible, the Americans replaced or upgraded the old, unusable French equipment with new construction equipment that was designed for a much larger and faster scale of work. 102 large, railroad-mounted steam shovels were purchased, 77 from Bucyrus-Erie, and 25 from the Marion Power Shovel Company. These were joined by enormous steam-powered cranes, giant hydraulic rock crushers, concrete mixers, dredges, and pneumatic power drills, nearly all of which were manufactured by new, extensive machine-building technology developed and built in the United States. The railroad also had to be comprehensively upgraded with heavy-duty, double-tracked rails over most of the line to accommodate new rolling stock. In many places, the new Gatun Lake flooded over the original rail line, and a new line had to be constructed above Gatun Lake's waterline.

In 1907, Stevens resigned as chief engineer. His replacement, appointed by President Theodore Roosevelt, was US Army Major George Washington Goethals of the US Army Corps of Engineers. Soon to be promoted to lieutenant colonel and later to general, he was a strong, West Point-trained leader and civil engineer with experience of canals (unlike Stevens). Goethals directed the work in Panama to a successful conclusion in 1914, two years ahead of the target date of June 10, 1916.

Goethals divided the engineering and excavation work into three divisions: Atlantic, Central, and Pacific. The Atlantic Division, under Major William L. Sibert, was responsible for construction of the massive breakwater at the entrance to Limon Bay, the Gatun locks, and their 3½ mi (5.6 km) approach channel, and the immense Gatun Dam. The Pacific Division, under Sydney B. Williamson (the only civilian member of this high-level team), was similarly responsible for the Pacific 3 mi (4.8 km) breakwater in Panama Bay, the approach channel to the locks, and the Miraflores and Pedro Miguel locks and their associated dams and reservoirs.

The Central Division, under Major David du Bose Gaillard of the United States Army Corps of Engineers, was assigned one of the most difficult parts: excavating the Culebra Cut through the continental divide to connect Gatun Lake to the Pacific Panama Canal locks.

On October 10, 1913, President Woodrow Wilson sent a signal from the White House by telegraph which triggered the explosion that destroyed the Gamboa Dike. This flooded the Culebra Cut, thereby joining the Atlantic and Pacific oceans via the Panama Canal. (a floating crane built by Lobnitz & Company and launched in 1887) was the first self-propelled vessel to transit the canal from ocean to ocean. This vessel crossed the canal from the Atlantic in stages during construction, finally reaching the Pacific on January 7, 1914. (a cargo and passenger ship built by Maryland Steel, and launched in 1902 as SS "Tremont") on August 3, 1914 was the first ship to transit the canal from ocean to ocean.

The construction of the canal was completed in 1914, 401 years after Panama was first crossed by Vasco Núñez de Balboa. The United States spent almost $500 million (roughly equivalent to $ billion in ) to finish the project. This was by far the largest American engineering project to date. The canal was formally opened on August 15, 1914, with the passage of the cargo ship .

The opening of the Panama Canal in 1914 caused a severe drop in traffic along Chilean ports due to shifts in maritime trade routes.

Throughout this time, Ernest "Red" Hallen was hired by the Isthmian Canal Commission to document the progress of the work.

By the 1930s, water supply became an issue for the canal, prompting construction of the Madden Dam across the Chagres River above Gatun Lake. Completed in 1935, the dam created Madden Lake (later Alajeula Lake), which provides additional water storage for the canal. In 1939, construction began on a further major improvement: a new set of locks large enough to carry the larger warships that the United States was building at the time and planned to continue building. The work proceeded for several years, and significant excavation was carried out on the new approach channels, but the project was cancelled after World War II.

After World War II, US control of the canal and the Canal Zone surrounding it became contentious; relations between Panama and the United States became increasingly tense. Many Panamanians felt that the Canal Zone rightfully belonged to Panama; student protests were met by the fencing-in of the zone and an increased military presence there. Demands for the United States to hand over the canal to Panama increased after the Suez Crisis in 1956, when the United States used financial and diplomatic pressure to force France and the UK to abandon their attempt to retake control of the Suez Canal, previously nationalized by the Nasser regime in Egypt. Panamanian unrest culminated in riots on Martyr's Day, January 9, 1964, when about 20 Panamanians and 3–5 US soldiers were killed.

A decade later, in 1974, negotiations toward a settlement began and resulted in the Torrijos–Carter Treaties. On September 7, 1977, the treaty was signed by President of the United States Jimmy Carter and Omar Torrijos, "de facto" leader of Panama. This mobilized the process of granting the Panamanians free control of the canal so long as Panama signed a treaty guaranteeing the permanent neutrality of the canal. The treaty led to full Panamanian control effective at noon on December 31, 1999, and the Panama Canal Authority (ACP) assumed command of the waterway. The Panama Canal remains one of the chief revenue sources for Panama.

Before this handover, the government of Panama held an international bid to negotiate a 25-year contract for operation of the container shipping ports located at the canal's Atlantic and Pacific outlets. The contract was not affiliated with the ACP or Panama Canal operations and was won by the firm Hutchison Whampoa, a Hong Kong–based shipping interest owned by Li Ka-shing.

While globally the Atlantic Ocean is east of the isthmus and the Pacific is west, the general direction of the canal passage from the Atlantic to the Pacific is from northwest to southeast, because of the shape of the isthmus at the point the canal occupies. The Bridge of the Americas () at the Pacific side is about a third of a degree east of the Colón end on the Atlantic side. Still, in formal nautical communications, the simplified directions "southbound" and "northbound" are used.

The canal consists of artificial lakes, several improved and artificial channels, and three sets of locks. An additional artificial lake, Alajuela Lake (known during the American era as Madden Lake), acts as a reservoir for the canal. The layout of the canal as seen by a ship passing from the Atlantic to the Pacific is:


Thus, the total length of the canal is 50 miles.

Artificially created in 1913 by damming the Chagres River, Gatun Lake is an essential part of the Panama Canal, providing the millions of litres of water necessary to operate the Panama Canal locks each time a ship passes through. At the time it was formed, Gatun Lake was the largest human-made lake in the world. The impassable rainforest around the lake has been the best defense of the Panama Canal. Today these areas remain practically unscathed by human interference and are one of the few accessible areas where various native Central American animal and plant species can be observed undisturbed in their natural habitat.

The largest island on Gatun Lake is Barro Colorado Island. It was established for scientific study when the lake was formed, and is operated by the Smithsonian Institution. Many important scientific and biological discoveries of the tropical animal and plant kingdom originated here. Gatun Lake covers about , a vast tropical ecological zone and part of the Atlantic Forest Corridor. Ecotourism on the lake has become an industry for Panamanians.

Gatun Lake also provides drinking water for Panama City and Colón. Fishing is one of the primary recreational pursuits on Gatun Lake. Non-native peacock bass were introduced by accident to Gatun Lake around 1967 by a local businessman, and have since flourished to become the dominant angling game fish in Gatun Lake. Locally called Sargento and believed to be the species "Cichla pleiozona", these peacock bass originate from the Amazon, Rio Negro, and Orinoco river basins, where they are considered a premier game fish.

The size of the locks determines the maximum size ship that can pass through. Because of the importance of the canal to international trade, many ships are built to the maximum size allowed. These are known as Panamax vessels. A Panamax cargo ship typically has a deadweight tonnage (DWT) of 65,000–80,000 tonnes, but its actual cargo is restricted to about 52,500 tonnes because of the draft restrictions within the canal. The longest ship ever to transit the canal was the "San Juan Prospector" (now "Marcona Prospector"), an ore-bulk-oil carrier that is long with a beam of .

Initially the locks at Gatun were designed to be wide. In 1908, the United States Navy requested that an increased width of at least to allow the passage of US naval ships. Eventually a compromise was made and the locks were built wide. Each lock is long, with the walls ranging in thickness from at the base to at the top. The central wall between the parallel locks at Gatun is thick and over high. The steel lock gates measure an average of thick, wide, and high. Panama Canal pilots were initially unprepared to handle the significant flight deck overhang of aircraft carriers. knocked over all the adjacent concrete lamp posts while passing through the Gatun Locks for the first time in 1928. It is the size of the locks, specifically the Pedro Miguel Locks, along with the height of the Bridge of the Americas at Balboa, that determine the Panamax metric and limit the size of ships that may use the canal.

The 2006 third set of locks project has created larger locks, allowing bigger ships to transit through deeper and wider channels. The allowed dimensions of ships using these locks increased by 25 percent in length, 51 percent in beam, and 26 percent in draft, as defined by New Panamax metrics.

As with a toll road, vessels transiting the canal must pay tolls. Tolls for the canal are set by the Panama Canal Authority and are based on vessel type, size, and the type of cargo.

For container ships, the toll is assessed on the ship's capacity expressed in twenty-foot equivalent units (TEUs), one TEU being the size of a standard intermodal shipping container. Effective April 1, 2016, this toll went from US$74 per loaded container to $60 per TEU capacity plus $30 per loaded container for a potential $90 per TEU when the ship is full. A Panamax container ship may carry up to . The toll is calculated differently for passenger ships and for container ships carrying no cargo ("in ballast"). , the ballast rate is US$60, down from US$65.60 per TEU.

Passenger vessels in excess of 30,000 tons (PC/UMS), known popularly as cruise ships, pay a rate based on the number of berths, that is, the number of passengers that can be accommodated in permanent beds. The per-berth charge since April 1, 2016 is $111 for unoccupied berths and $138 for occupied berths in the Panamax locks. Started in 2007, this fee has greatly increased the tolls for such ships. Passenger vessels of less than 30,000 tons or less than 33 tons per passenger are charged according to the same per-ton schedule as are freighters. Almost all major cruise ships have more than 33 tons per passenger; the rule of thumb for cruise line comfort is generally given as a minimum of 40 tons per passenger.

Most other types of vessel pay a toll per PC/UMS net ton, in which one "ton" is actually a volume of . (The calculation of tonnage for commercial vessels is quite complex.) , this toll is US$5.25 per ton for the first 10,000 tons, US$5.14 per ton for the next 10,000 tons, and US$5.06 per ton thereafter. As with container ships, reduced tolls are charged for freight ships "in ballast", $4.19, $4.12, $4.05 respectively.

On 1 April 2016, a more complicated toll system was introduced, having the neopanamax locks at a higher rate in some cases, natural gas transport as a new separate category and other changes.
As of October 1, 2017, there are modified tolls and categories of tolls in effect.
Small (less than 125 ft) vessels up to 583 PC/UMS net tons when carrying passengers or cargo, or up to 735 PC/UMS net tons when in ballast, or up to 1,048 fully loaded displacement tons, are assessed minimum tolls based upon their length overall, according to the following table (as of 29 April 2015):
Morgan Adams of Los Angeles, California, holds the distinction of paying the first toll received by the United States Government for the use of the Panama Canal by a pleasure boat. His boat "Lasata" passed through the Zone on August 14, 1914. The crossing occurred during a 6,000-mile sea voyage from Jacksonville, Florida, to Los Angeles in 1914.

The most expensive regular toll for canal passage to date was charged on April 14, 2010 to the cruise ship "Norwegian Pearl," which paid US$375,600. The average toll is around US$54,000. The highest fee for priority passage charged through the Transit Slot Auction System was US$220,300, paid on August 24, 2006, by the Panamax tanker "Erikoussa", bypassing a 90-ship queue waiting for the end of maintenance work on the Gatun Locks, and thus avoiding a seven-day delay. The normal fee would have been just US$13,430.

The lowest toll ever paid was 36 cents (), by American Richard Halliburton who swam the Panama Canal in 1928.

Opponents to the 1977 Torrijos-Carter Treaties feared that efficiency and maintenance would suffer following the US withdrawal from the Panama Canal Zone; however, this has been proven not to be the case. Capitalizing on practices developed during the American administration, canal operations are improving under Panamanian control. Canal Waters Time (CWT), the average time it takes a vessel to navigate the canal, including waiting time, is a key measure of efficiency; according to the ACP, since 2000, it has ranged between 20 and 30 hours. The accident rate has also not changed appreciably in the past decade, varying between 10 and 30 accidents each year from about 14,000 total annual transits. An official accident is one in which a formal investigation is requested and conducted.

Increasing volumes of imports from Asia, which previously landed on US West Coast ports, are now passing through the canal to the American East Coast. The total number of ocean-going transits increased from 11,725 in 2003 to 13,233 in 2007, falling to 12,855 in 2009. (The canal's fiscal year runs from October through September.) This has been coupled with a steady rise in average ship size and in the numbers of Panamax vessels passing through the canal, so that the total tonnage carried rose from 227.9 million PC/UMS tons in fiscal year 1999 to a then record high of 312.9 million tons in 2007, and falling to 299.1 million tons in 2009. Tonnage for fiscal 2013, 2014 and 2015 was 320.6, 326.8 and 340.8 million PC/UMS tons carried on 13,660, 13,481 and 13,874 transits respectively.
In the first decade after the transfer to Panamanian control, the Panama Canal Authority (ACP) invested nearly US$1 billion in widening and modernizing the canal, with the aim of increasing capacity by 20 percent. The ACP cites a number of major improvements, including the widening and straightening of the Gaillard Cut to reduce restrictions on passing vessels, the deepening of the navigational channel in Gatun Lake to reduce draft restrictions and improve water supply, and the deepening of the Atlantic and Pacific entrances to the canal. This is supported by new equipment, such as a new drill barge and suction dredger, and an increase of the tug boat fleet by 20 percent. In addition, improvements have been made to the canal's operating machinery, including an increased and improved tug locomotive fleet, the replacement of more than of locomotive track, and new lock machinery controls. Improvements have been made to the traffic management system to allow more efficient control over ships in the canal.

In December 2010, record-breaking rains caused a 17-hour closure of the canal; this was the first closure since the United States invasion of Panama in 1989.
The rains also caused an access road to the Centenario Bridge to collapse.

The canal is currently handling more vessel traffic than had ever been envisioned by its builders. In 1934 it was estimated that the maximum capacity of the canal would be around 80 million tons per year; as noted above, canal traffic in 2015 reached 340.8 million tons of shipping.

To improve capacity, a number of improvements have been made to the current canal system. These improvements aim to maximize the possible use of current locking system:
These improvements enlarged the capacity from 300 million PCUMS (2008) to 340 PCUMS (2012).
These improvements were started before the new locks project, and are complementary to it.

Despite having enjoyed a privileged position for many years, the canal is increasingly facing competition from other quarters. Because canal tolls have risen as ships have become larger, some critics have suggested that the Suez Canal is now a viable alternative for cargo en route from Asia to the US East Coast. The Panama Canal, however, continues to serve more than 144 of the world's trade routes and the majority of canal traffic comes from the "all-water route" from Asia to the US East and Gulf Coasts.

On June 15, 2013, Nicaragua awarded the Hong Kong-based HKND Group a 50-year concession to develop a canal through the country.

The increasing rate of melting of ice in the Arctic Ocean has led to speculation that the Northwest Passage or Arctic Bridge may become viable for commercial shipping at some point in the future. This route would save on the route from Asia to Europe compared with the Panama Canal, possibly leading to a diversion of some traffic to that route. However, such a route is beset by unresolved territorial issues and would still hold significant problems owing to ice.

Gatun Lake is filled with rainwater, and the lake accumulates excess water during wet months. The water is lost to the oceans at a rate of per downward lock cycle. Since a ship will have to go upward to Gatun Lake first and then descend, a single passing will cost double the amount; but the same waterflow cycle can be used for another ship passing in the opposite direction. The ship's submerged volume is not relevant to this amount of water. During the dry season, when there is less rainfall, there is also a shortfall of water in Gatun Lake.

As a signatory to the United Nations Global Compact and member of the World Business Council for Sustainable Development, the ACP has developed an environmentally and socially sustainable program for expansion, which protects the aquatic and terrestrial resources of the canal watershed. The expansion guarantees the availability and quality of water resources by using water-saving basins at each new lock. These water-saving basins diminish water loss and preserve freshwater resources along the waterway by reusing water from the basins into the locks. Each lock chamber has three water-saving basins, which reuse 60 percent of the water in each transit. There are a total of nine basins for each of the two lock complexes, and a total of 18 basins for the entire project.

The mean sea level at the Pacific side is about higher than that of the Atlantic side due to differences in ocean conditions such as water density and weather.

As demand is rising for efficient global shipping of goods, the canal is positioned to be a significant feature of world shipping for the foreseeable future. However, changes in shipping patterns —particularly the increasing numbers of larger-than-Panamax ships— necessitated changes to the canal for it to retain a significant market share. In 2006 it was anticipated that by 2011, 37 percent of the world's container ships would be too large for the present canal, and hence a failure to expand would result in a significant loss of market share. The maximum sustainable capacity of the original canal, given some relatively minor improvement work, was estimated at 340 million PC/UMS tons per year; it was anticipated that this capacity would be reached between 2009 and 2012. Close to 50 percent of transiting vessels were already using the full width of the locks.

An enlargement scheme similar to the 1939 Third Lock Scheme, to allow for a greater number of transits and the ability to handle larger ships, had been under consideration for some time, was approved by the government of Panama, The cost was estimated at , and the expansion allowed to double the canal's capacity, allowing more traffic and the passage of longer and wider Post-Panamax ships. The proposal to expand the canal was approved in a national referendum by about 80 percent on October 22, 2006. The canal expansion was built between 2007 and 2016, though completion was originally expected by the end of 2014.

The expansion plan had two new flights of locks built parallel to, and operated in addition to, the old locks: one east of the existing Gatun locks, and one southwest of the Miraflores locks, each supported by approach channels. Each flight ascends from sea level directly to the level of Gatun Lake; the existing two-stage ascent at Miraflores and Pedro Miguel locks was not replicated. The new lock chambers feature sliding gates, doubled for safety, and are long, wide, and deep. This allows the transit of vessels with a beam of up to , an overall length of up to and a draft of up to , equivalent to a container ship carrying around 12,000 containers, each in length (TEU).

The new locks are supported by new approach channels, including a channel at Miraflores from the locks to the Gaillard Cut, skirting Miraflores Lake. Each of these channels are wide, which will require post-Panamax vessels to navigate the channels in one direction at a time. The Gaillard Cut and the channel through Gatun Lake were widened to at least on the straight portions and at least on the bends. The maximum level of Gatun Lake was raised from to .

Each flight of locks is accompanied by nine water reutilization basins (three per lock chamber), each basin being about wide, long and deep. These gravity-fed basins allow 60 percent of the water used in each transit to be reused; the new locks consequently use 7 percent less water per transit than each of the existing lock lanes. The deepening of Gatun Lake and the raising of its maximum water level also provide capacity for significantly more water storage. These measures are intended to allow the expanded canal to operate without constructing new reservoirs.

The estimated cost of the project is . The project was designed to allow for an anticipated growth in traffic from 280 million PC/UMS tons in 2005 to nearly 510 million PC/UMS tons in 2025. The expanded canal will have a maximum sustainable capacity of about 600 million PC/UMS tons per year. Tolls will continue to be calculated based on vessel tonnage, and in some cases depend on the locks used.

An article in the February 2007 issue of "Popular Mechanics" magazine described the plans for the canal expansion, focusing on the engineering aspects of the expansion project. There is also a follow-up article in the February 2010 issue of "Popular Mechanics".

On September 3, 2007, thousands of Panamanians stood across from Paraíso Hill in Panama to witness a huge initial explosion and launch of the Expansion Program. The first phase of the project was the dry excavations of the wide trench connecting the Gaillard Cut with the Pacific coast, removing 47 million cubic meters of earth and rock. By June 2012, a 30 m reinforced concrete monolith had been completed, the first of 46 such monoliths which will line the new Pacific-side lock walls. By early July 2012, however, it was announced that the canal expansion project had fallen six months behind schedule, leading expectations for the expansion to open in April 2015 rather than October 2014, as originally planned. By September 2014, the new gates were projected to be open for transit at the "beginning of 2016."

It was announced in July 2009 that the Belgian dredging company Jan De Nul, together with a consortium of contractors consisting of the Spanish Sacyr Vallehermoso, the Italian Impregilo, and the Panamanian company Grupo Cusa, had been awarded the contract to build the six new locks for US$3.1 billion, which was one billion less than the next highest competing bid due to having a concrete budget 71 percent smaller than that of the next bidder and allotted roughly 25 percent less for steel to reinforce that concrete. The contract resulted in $100 million in dredging works over the next few years for the Belgian company and a great deal of work for its construction division. The design of the locks is a carbon copy of the Berendrecht Lock, which is 68 m wide and 500 m long, making it the second largest lock in the world after the Kieldrecht lock in the port of Antwerp, Belgium. Completed in 1989 by the Port of Antwerp, which De Nul helped build, the company still has engineers and specialists who were part of that project.

In January 2014, a contract dispute threatened the progress of the project. There was a delay of less than two months however, with work by the consortium members reaching goals by June 2014.

In June 2015, flooding of the new locks began: first on the Atlantic side, then on the Pacific; by then, the canal's re-inauguration was slated for April 2016. On March 23, 2016, the expansion inauguration was set for June 26, 2016.

The new locks opened for commercial traffic on 26 June 2016, and the first ship to cross the canal using the third set of locks was a modern New Panamax vessel, the Chinese-owned container ship "Cosco Shipping Panama". The original locks, now over 100 years old, allow engineers greater access for maintenance, and are projected to continue operating indefinitely.

The total cost is unknown since the expansion's contractors are seeking at least an addition from the canal authority due to excess expenses.

On July 7, 2014, Wang Jing, chairman of the HK Nicaragua Canal Development Investment Co. Ltd. (HKND Group) advised that a route for Nicaragua's proposed canal had been approved. The construction work was projected by HKND to begin in 2014 and take 5 years, although there has been little progress whilst a series of environmental impact assessments are being made. The Nicaraguan parliament has approved plans for the canal through Nicaragua, and according to the deal, the company will be responsible for operating and maintaining the canal for a 50-year period. The government of Nicaragua hopes this will boost the economy; the opposition is concerned with its environmental impact. According to the independent impact assessment by British firm ERM, some 30,000 local residents will be displaced by the canal, although opposition leaders and Amnesty International claim the figure will be in the hundreds of thousands. Supporters and the environmental impact study claim there will be net environmental benefits, but critics argue that nearly of delicate ecosystems will be destroyed by the time construction is completed.

China is investigating a proposal to construct a railway between Colombia's Pacific and Caribbean coasts.

Individuals, companies, and governments have explored the possibility of constructing deep water ports and rail links connecting coasts as a "dry canal" in Guatemala, Costa Rica, and El Salvador/Honduras. However, plans to construct these sea-rail-sea links have yet to materialize.

During the last one hundred years, the Panama Canal Authority has appointed a few "Panama Canal Honorary Pilots". The most recent of these were Commodore Ronald Warwick, a former Master of the Cunard Liners "Queen Elizabeth 2" and "RMS Queen Mary 2", who has traversed the Canal more than 50 times, and Captain Raffaele Minotauro, an Unlimited Master Senior Grade, of the former Italian governmental navigation company known as the "Italian Line". This service can be requested from the Panama canal authority at any time who will consider each request.






</doc>
<doc id="24850" url="https://en.wikipedia.org/wiki?curid=24850" title="Political fiction">
Political fiction

Political fiction employs narrative to comment on political events, systems and theories. Works of political fiction, such as political novels, often "directly criticize an existing society or present an alternative, even fantastic, reality". The political novel overlaps with the social novel, proletarian novel, and social science fiction.

Plato's "Republic", a Socratic dialogue written around 380 BC, has been one of the world's most influential works of philosophy and political theory, both intellectually and historically. The "Republic" is concerned with justice (), the order and character of the just city-state, and the just man. Other influential politically-themed works include Thomas More's "Utopia" (1516), Jonathan Swift's "Gulliver's Travels" (1726), Voltaire's "Candide" (1759), and Harriet Beecher Stowe's "Uncle Tom's Cabin" (1852).

Political fiction frequently employs satire, often in the utopian and dystopian genres.
This includes totalitarian dystopias of the early 20th century such as Jack London's "The Iron Heel", Sinclair Lewis' "It Can't Happen Here", and George Orwell's "Nineteen Eighty-Four".

The Greek playwright Aristophanes' plays are known for their political and social satire, particularly in his criticism of the powerful Athenian general, Cleon, in plays such as "The Knights". Aristophanes is also notable for the persecution he underwent. Aristophanes' plays turned upon images of filth and disease. His bawdy style was adopted by Greek dramatist-comedian Menander, whose early play, "Drunkenness", contains an attack on the politician, Callimedon.

Jonathan Swift's "A Modest Proposal" (1729) is an 18th-century Juvenalian satirical essay in which he suggests that the impoverished Irish might ease their economic troubles by selling their children as food for rich gentlemen and ladies. The satirical hyperbole mocks heartless attitudes towards the poor, as well as British policy toward the Irish in general.

George Orwell's "Animal Farm" (1945) is an allegorical and dystopian novella which satirises the Russian Revolution of 1917 and the Soviet Union's Stalinist era. Orwell, a democratic socialist, was a critic of Joseph Stalin and was hostile to Moscow-directed Stalinism—an attitude that had been shaped by his experiences during the Spanish Civil War. The Soviet Union, he believed, had become a brutal dictatorship, built upon a cult of personality and enforced by a reign of terror. Orwell described his "Animal Farm" as "a satirical tale against Stalin", and in his essay "Why I Write" (1946) he wrote that "Animal Farm" was the first book in which he tried, with full consciousness of what he was doing, "to fuse political purpose and artistic purpose into one whole."

Orwell's most famous work, however, is "Nineteen Eighty-Four" (published in 1949), many of whose terms and concepts, such as "Big Brother", "doublethink", "thoughtcrime", "Newspeak", "Room 101", "telescreen", "2 + 2 = 5", and "memory hole", have entered into common use. "Nineteen Eighty-Four" popularised the adjective "Orwellian", which describes official deception, secret surveillance, and manipulation of recorded history by a totalitarian or authoritarian state.

The poet Jan Kochanowski's play, "The Dismissal of the Greek Envoys" (1578), the first tragedy written in the Polish language, recounts an incident leading up to the Trojan War. Its theme of the responsibilities of statesmanship resonates to the present day.

The political comedy, "The Return of the Deputy" (1790), by Julian Ursyn Niemcewicz—Polish poet, playwright, statesman, and comrade-in-arms of Tadeusz Kościuszko—was written in about two weeks' time while Niemcewicz was serving as a deputy to the historic Four-Year Sejm of 1788–92. The comedy's premiere in January 1791 was an enormous success, sparking widespread debate, royal communiques, and diplomatic correspondence. As Niemcewicz had hoped, it set the stage for passage of Poland's epochal Constitution of 3 May 1791, which is regarded as Europe's first, and the world's second, modern written national constitution, after the United States Constitution implemented in 1789. The comedy pits proponents against opponents of political reforms: of abolishing the destabilizing free election of Poland's kings; of abolishing the legislatively destructive "liberum veto"; of granting greater rights to peasants and townspeople; of curbing the privileges of the mostly self-interested noble class; and of promoting a more active Polish role in international affairs, in the interest of stopping the depredations of Poland's neighbors, Russia, Prussia, and Austria (who will in 1795 complete the dismemberment of the Polish–Lithuanian Commonwealth). Romantic interest is provided by a rivalry between a reformer and a conservative for a young lady's hand—which is won by the proponent of reforms.

An early example of the political novel is "The Betrothed" (1827) by Alessandro Manzoni, an Italian historical novel. Set in northern Italy in 1628, during the oppressive years of direct Spanish rule, it has been seen sometimes as a veiled attack on the Austrian Empire, which controlled Italy at the time the novel was written. It has been called the most famous and widely read novel in the Italian language.

In the 1840s British politician Benjamin Disraeli wrote a trilogy of novels with political themes. With "Coningsby; or, The New Generation" (1844), Disraeli, in historian Robert Blake's view, "infused the novel genre with political sensibility, espousing the belief that England's future as a world power depended not on the complacent old guard, but on youthful, idealistic politicians." "Coningsby" was followed by "Sybil; or, The Two Nations" (1845), another political novel, which was less idealistic and more clear-eyed than "Coningsby"; the "two nations" of its subtitle referred to the huge economic and social gap between the privileged few and the deprived working classes. The last of Disraeli's political-novel trilogy, "Tancred; or, The New Crusade" (1847), promoted the Church of England's role in reviving Britain's flagging spirituality.

Ivan Turgenev wrote "Fathers and Sons" (1862) as a response to the growing cultural schism that he saw between Russia's liberals of the 1830s and 1840s, and the growing Russian nihilist movement among their sons. Both the nihilists and the 1830s liberals sought Western-based social change in Russia. Additionally, these two modes of thought were contrasted with the Slavophiles, who believed that Russia's path lay in its traditional spirituality. Turgenev's novel was responsible for popularizing the use of the term "nihilism", which became widely used after the novel was published.
The Polish writer Bolesław Prus' novel, "Pharaoh" (1895), is set in the Egypt of 1087–85 BCE as that country experiences internal stresses and external threats that will culminate in the fall of its Twentieth Dynasty and New Kingdom. The young protagonist Ramses learns that those who would challenge the powers that be are vulnerable to co-option, seduction, subornation, defamation, intimidation, and assassination. Perhaps the chief lesson, belatedly absorbed by Ramses as pharaoh, is the importance, to power, of knowledge. Prus' vision of the fall of an ancient civilization derives some of its power from the author's intimate awareness of the final demise of the Polish–Lithuanian Commonwealth in 1795, a century before he completed "Pharaoh". This is a political awareness that Prus shared with his 10-years-junior novelist compatriot, Joseph Conrad, who was an admirer of Prus' writings. "Pharaoh" has been translated into 20 languages and adapted as a 1966 Polish feature film. It is also known to have been Joseph Stalin's favourite book.

Joseph Conrad wrote several novels with political themes: "Nostromo (1904)", "The Secret Agent" (1907), and
"Under Western Eyes" (1911). "Nostromo" (1904) is set amid political upheaval in the fictitious South American country of Costaguana, where a trusted Italian-descended longshoreman, Giovanni Battista Fidanza—the novel's eponymous "Nostromo" (Italian for "our man")—is instructed by English-descended silver-mine owner Charles Gould to take Gould's silver abroad so that it will not fall into the hands of revolutionaries. The role of politics is paramount in "The Secret Agent", as the main character, Verloc, works for a quasi-political organisation. The plot to destroy Greenwich Observatory is in itself anarchistic. Vladimir asserts that the bombing "must be purely destructive" and that the anarchists who will be implicated as the architects of the explosion "should make it clear that [they] are perfectly determined to make a clean sweep of the whole social creation." However, the political form of anarchism is ultimately controlled in the novel: the only supposed politically motivated act is orchestrated by a secret government agency. Conrad's third political novel, "Under Western Eyes", is connected to Russian history. Its first audience read it against the backdrop of the failed Revolution of 1905 and in the shadow of the movements and impulses that would take shape as the revolutions of 1917. Conrad's earlier novella, "Heart of Darkness" (1899), also had political implications, in its depiction of European colonial depredations in Africa, which Conrad witnessed during his employ in the Belgian Congo.

John Steinbeck's novel "The Grapes of Wrath" (1939) is a passionate depiction of the plight of the poor. However, many of Steinbeck's contemporaries attacked his social and political views. Bryan Cordyack writes: "Steinbeck was attacked as a propagandist and a socialist from both the left and the right of the political spectrum. The most fervent of these attacks came from the Associated Farmers of California; they were displeased with the book's depiction of California farmers' attitudes and conduct toward the migrants. They denounced the book as a 'pack of lies' and labeled it 'communist propaganda'". Some accused Steinbeck of exaggerating camp conditions to make a political point. Steinbeck had visited the camps well before publication of the novel and argued that their inhumane nature destroyed the settlers' spirit.

"The Quiet American" (1955) by English novelist Graham Greene questions the foundations of growing American involvement in Vietnam in the 1950s. The novel has received much attention due to its prediction of the outcome of the Vietnam War and subsequent American foreign policy since the 1950s. Graham Greene portrays a U.S. official named Pyle as so blinded by American exceptionalism that he cannot see the calamities he brings upon the Vietnamese. The book uses Greene's experiences as a war correspondent for "The Times" and "Le Figaro" in French Indochina in 1951–54.

"The Gay Place" (1961) is a set of politically-themed novellas with interlocking plots and characters by American author Billy Lee Brammer. Set in an unnamed state identical to Texas, each novella has a different protagonist: Roy Sherwood, a member of the state legislature; Neil Christiansen, the state's junior senator; and Jay McGown, the governor's speech-writer. The governor himself, Arthur Fenstemaker, a master politician (said to have been based on Brammer's mentor Lyndon Johnson) serves as the dominant figure throughout. The book also includes characters based on Brammer, his wife Nadine,
Johnson's wife Ladybird, and his brother Sam Houston Johnson. The book has been widely acclaimed one of the best American political novels ever written.

The proletarian novel is written by workers, mainly for other workers. It overlaps and sometimes is synonymous with the working-class novel, socialist novel, social-problem novel (also problem novel, sociological novel, or social novel), propaganda or thesis novel, and socialist-realism novel. The intention of the writers of proletarian literature is to lift the workers from the slums by inspiring them to embrace the possibilities of social change or of a political revolution. As such, it is a form of political fiction.

The proletarian novel may comment on political events, systems, and theories, and is frequently seen as an instrument to promote social reform or political revolution among the working classes. Proletarian literature is created especially by communist, socialist, and anarchist authors. It is about the lives of the poor, and the period from 1930 to 1945, in particular, produced many such novels. However, proletarian works were also produced before and after those dates. In Britain, the terms "working-class" literature, novel, etc., are more generally used.

A closely related type of novel, which frequently has a political dimension, is the social novel – also known as the "social-problem" or "social-protest" novel – a "work of fiction in which a prevailing social problem, such as gender, race, or class prejudice, is dramatized through its effect on the characters of a novel". More specific examples of social problems that are addressed in such works include poverty, conditions in factories and mines, the plight of child labor, violence against women, rising criminality, and epidemics caused by overcrowding and poor sanitation in cities.

Charles Dickens was a fierce critic of the poverty and social stratification of Victorian society. Karl Marx asserted that Dickens "issued to the world more political and social truths than have been uttered by all the professional politicians, publicists and moralists put together". On the other hand, George Orwell, in his essay on Dickens, wrote: "There is no clear sign that he wants the existing order to be overthrown, or that he believes it would make very much difference if it were overthrown. For in reality his target is not so much society as 'human nature'."

Dickens's second novel, "Oliver Twist" (1839), shocked readers with its images of poverty and crime: it destroyed middle-class polemics about criminals, making any pretence to ignorance about what poverty entailed impossible. Charles Dickens's "Hard Times" (1854) is set in a small Midlands industrial town and particularly criticizes the effect of Utilitarianism on the lives of cities' working classes. John Ruskin declared "Hard Times" his favourite Dickens work due to its exploration of important social questions. Walter Allen characterised "Hard Times" as an unsurpassed "critique of industrial society",

"This is a list of a few of the early or notable examples; others belong on the main list"




</doc>
<doc id="24851" url="https://en.wikipedia.org/wiki?curid=24851" title="Potato chip">
Potato chip

Potato chips (often just chips), or crisps (in British and Irish English), are thin slices of potato that have been either deep fried or baked until crunchy. They are commonly served as a snack, side dish, or appetizer. The basic chips are cooked and salted; additional varieties are manufactured using various flavorings and ingredients including herbs, spices, cheeses, other natural flavors, artificial flavors, and additives. 
Potato chips form a large part of the snack food and convenience food market in Western countries. The global potato chip market generated total revenue of US$16.49 billion in 2005. This accounted for 35.5% of the total savory snacks market in that year ($46.1 billion).

The earliest known recipe for something similar to today's potato chips is in William Kitchiner's book "The Cook's Oracle" published in 1817, which was a bestseller in the United Kingdom and the United States. The 1822 edition's recipe for "Potatoes fried in Slices or Shavings" reads "peel large potatoes… cut them in shavings round and round, as you would peel a lemon; dry them well in a clean cloth, and fry them in lard or dripping". An 1825 British book about French cookery calls them "Pommes de Terre frites" (second recipe) and calls for thin slices of potato fried in "clarified butter or goose dripping", drained and sprinkled with salt. Early recipes for potato chips in the US are found in Mary Randolph's "Virginia House-Wife" (1824) and in N.K.M. Lee's "Cook's Own Book" (1832), both of which explicitly cite Kitchiner.

A legend associates the creation of potato chips with Saratoga Springs, New York decades later than the first recorded recipe. By the late nineteenth century, a popular version of the story attributed the dish to George Crum, a cook at Moon's Lake House who was trying to appease an unhappy customer on 24 August 1853. The customer kept sending back his French-fried potatoes, complaining that they were too thick, too "soggy", or not salted enough. Frustrated, Crum sliced several potatoes extremely thin, fried them to a crisp, and seasoned them with extra salt. To his surprise, the customer loved them. They soon came to be called "Saratoga Chips", a name that persisted into the mid-twentieth century. A version of this story was popularized in a 1973 national advertising campaign by St. Regis Paper Company which manufactured packaging for chips, claiming that Crum's customer was Cornelius Vanderbilt. Crum was already renowned as a chef at the time, and he owned a lakeside restaurant by 1860 which he called Crum's House. The "Saratoga Chips" brand name still exists today.

In the 20th century, potato chips spread beyond chef-cooked restaurant fare and began to be mass-produced for home consumption. The Dayton, Ohio-based Mikesell's Potato Chip Company, founded in 1910, identifies as the "oldest potato chip company in the United States". New England-based Tri-Sum Potato Chips, founded in 1908 as the Leominster Potato Chip Company, in Leominster, Massachusetts, claims to be America's first potato chip manufacturer.

In an idea originated by the Smiths Potato Crisps Company Ltd, formed in 1920, Frank Smith packaged a twist of salt with his chips in greaseproof paper bags, which were sold around London. The potato chip remained otherwise unseasoned until an innovation by Joe "Spud" Murphy, the owner of the Irish crisps company Tayto, who in the 1950s developed a technology to add seasoning during manufacture. After some trial and error, Murphy and his employee Seamus Burke produced the world's first seasoned chips: Cheese & Onion and Salt & Vinegar. Companies worldwide sought to buy the rights to Tayto's technique.

The first flavored chips in the United States, barbecue flavor, were being manufactured and sold by 1954. In 1958, Herr's was the first company to introduce barbecue-flavored potato chips in Pennsylvania.

Chips sold in markets were usually sold in tins or scooped out of storefront glass bins and delivered by horse and wagon. Early potato chip bags were wax paper with the ends ironed or stapled together. At first, potato chips were packaged in barrels or tins, which left chips at the bottom stale and crumbled.

In the 1920s, Laura Scudder, an entrepreneur in Monterey Park, California, started having her workers take home sheets of wax paper to iron into the form of bags, which were filled with chips at her factory the next day. This pioneering method reduced crumbling and kept the chips fresh and crisp longer. This innovation, along with the invention of cellophane, allowed potato chips to become a mass-market product. Today, chips are packaged in plastic bags, with nitrogen gas blown in prior to sealing to lengthen shelf life, and provide protection against crushing.

Chips were long made in a batch process, where the potato slices are rinsed with cold water to release starch, fried at a low temperature of , and continuously raked to prevent them from sticking together.

Industrial advances resulted in a shift to production by a continuous process, running the chips through a vat of hot oil and drying them in a conveyor process.

Some small producers continued to use a batch process, notably in Maui. In 1980, inspired by the Maui Chip, an entrepreneur started Cape Cod Potato Chips to produce thicker, batch-cooked "Hawaiian style" potato chips, which came to be known as kettle-style (US) or hand-cooked (UK) chips and became a premium, "gourmet" item. Kettle chips are thicker and the surface starch is not rinsed off, resulting in a style of chip called "hard bite".

Little consistency exists in the English-speaking world for the name of this food. North American English uses "chips", though Canadians may also call French fries, especially thick ones, "chips" as well. "Crisps" may be used for thin fried slices made from potato paste. An example of this type of snack is Pringles, which chooses to market their product as "potato crisps" even in the United States.

In the United Kingdom and Ireland, "crisps" are potato chips which are eaten at room temperature, whilst "chips" are similar to french fries (as in "fish and chips") and are served hot. In Australia, some parts of South Africa, New Zealand, India, and the West Indies, especially in Barbados, both forms of potato product are simply known as "chips", as are the larger "home-style" variety. In the north of New Zealand, they are sometimes known as "chippies", but they are marketed as "chips" throughout the country. In Australia and New Zealand, a distinction is sometimes made between "hot chips" (fried potatoes) and "chips" or "potato chips". In Bangladesh, they are generally known as "chip" or "chips", and much less frequently as "crisps" (pronounced "kirisp") and locally, "alu bhaja" (for their similarity to the fried potato dish, "bhajji").

In German-speaking countries (Austria, Germany: ""Kartoffelchips"", or colloquially "Pommes" or "Fritten"; Switzerland: ""Pommes Chips"") and in countries of the former SFR Yugoslavia, fried thin potato slices are known as "chips" (locally pronounced very similarly to the English pronunciation), with a clear distinction from French fries. In Brazil, "home-style" potato chips are known as ("Portuguese potatoes") if their sides are relatively smooth and ("Prussian potatoes") if their sides show a wafer biscuit-like pattern, whilst American-like industrial uniform potato chips made from a fried potato purée-based dough are known as "batata chips" ("potato chips"), or just .

Most potato chips contain high levels of sodium, from salt. This has been linked to health issues such as high blood pressure. However, researchers at Queen Mary University of London in 2004 have noted that a small "bag of ready-salted crisps" contains less salt than a serving of many breakfast cereals, including "every brand of cornflakes on sale in the UK."

Some potato chip companies have responded to the long-standing concerns by investing in research and development to modify existing recipes and create health-conscious products. PepsiCo research shows that about 80% of salt on chips is not sensed by the tongue before being swallowed. Frito-Lay spent $414 million in 2009 on product development, including development of salt crystals that would reduce the salt content of Lay's potato chips without adversely affecting flavor.

Unsalted chips are available, e.g. the longstanding British brand Salt 'n' Shake, whose chips are not seasoned, but instead include a small salt sachet in the bag for seasoning to taste. Many other popular brands in the United States, such as Frito-Lay, also offer such a product.

Another possible health concern related to potato chips is acrylamide, which is produced when potatoes are fried or baked at high temperatures. Studies show that laboratory animals exposed to high levels of acrylamide develop cancer; however, it is currently unclear whether a similar risk exists in humans. In August 2008, California Attorney General Jerry Brown announced a settlement with Frito-Lay, Kettle Foods, and Lance Inc. the makers of Cape Cod Potato Chips for violating the state's Safe Drinking Water and Toxic Enforcement Act. The state had alleged in 2005 that potato chips from these companies failed to document that they contained high levels of acrylamide, which is listed by California since the 1990s as a carcinogen. These companies paid fines and agreed to reduce acrylamide levels to be under 275 parts per billion. Many potato chip manufacturers attempt to remove burned and thus potentially acrylamide-rich chips before the packaging process. Large scanners are used to eliminate chips worst affected by heat.

In Canada, seasonings include the unique all dressed, as well as dill pickle, jalapeño, ketchup, barbecue, sour cream and onion, and salt and vinegar. In 2006, Lay's introduced wasabi chips in Toronto and Vancouver, but no longer offers them. Lays has recently released new Lay's Poppables which come in 3 flavours: Sea Salt and Vinegar, Honey BBQ, Sea Salt and White cheddar. Loblaw, Canada's largest food retailer, offers several unusual flavors under its President's Choice brand, including poutine, maple bacon, Jamaican jerk chicken, Greek feta and olive, ballpark hot dog, and barbecue baby back ribs.

In Hong Kong, the two prominent potato chips are the spicy "Ethnican" variety by Calbee, and barbecue by Jack 'n Jill. Lay's are also popular in Hong Kong.

In Indonesia, potato chips are commonly called as "kripik kentang", traditionally fell under "kripik" category. Indonesian potato chips market is mainly ruled by two brands; Indofood's Chitato (since 1990s) and Lay's (Frito-Lay). In 2014, Japan's Calbee and Indonesia's Wings Food formed Calbeewings, a joint venture and marketed Potabee potato chips in Indonesia.

Common potato chips flavors marketed in Indonesia include beef barbecue, spicy chicken, cheese and plain salted. 
Lay's potato chips sold in Indonesia is available in 6 flavors; honey butter, sour cream and onion, nori seaweed, beef barbecue, classic salty, and salmon teriyaki flavors. Potabee sold in Indonesia offers two flavors; beef BBQ and grilled seaweed. In 2018 Chitato launched "Do Us A Flavor" campaign that sell three unusual flavors; beef rendang, fried crab golden egg yolk, and mango sticky rice.

In Ireland, the two most popular flavors are cheese and onion, and salt and vinegar. However in Ireland, the word "Tayto" is synonymous with potato chips after the Tayto brand and can be used to describe all varieties of chips, including those not produced by Tayto. Hunky Dorys and King are other popular Irish brands. In November 2010, the Tayto company opened a theme park called "Tayto Park".

In Germany, Belgium and the Netherlands only two flavors were traditionally available, red paprika ("Paprika", sometimes also called "ungarisch" (from "Hungarian")) and salted ("gesalzen"). These are still by far the most common and popular types, but some vendors started to offer a number of other flavors such as sour cream and onion, cheese, oriental, or more exotic seasonings like "Chakalaka", "Currywurst", "Pommes" (french fries), ""Rot-weiss"" (red and white – french fries with tomato ketchup and mayonnaise). Potato chips made from ground potatoes are called "Stapelchips" rather than "Kartoffelchips" for legal reasons.

In Colombia, lemon, chicken, chorizo, and sirloin steak with mushroom sauce flavored potato chips are sold.

In Japan, flavors include norishio (nori and salt), "consommé", wasabi, soy sauce and butter, garlic, plum, barbecue, pizza, mayonnaise, and black pepper. Chili, scallop with butter, teriyaki, takoyaki, and yakitori chip flavors are also available. Major manufacturers are Calbee, Koikeya and Yamayoshi.

The market in the United Kingdom is led by Walkers, which held 56% of the British crisp market in 2013. Walkers is known for its wide variety of crisps with the most popular flavors being Cheese & Onion, Salt & Vinegar, Prawn Cocktail, Beef and Onion, Roast Chicken, Smoky Bacon, Worcester Sauce, Pickled Onion, Tomato Ketchup, and Salt & Shake – Original.

More exotic flavors are Thai sweet chili, roast pork and creamy mustard sauce, lime and Thai spices, chicken with Italian herbs, Spicy Sriracha, BBQ Pulled Pork, sea salt and cracked black pepper, sea salt and cider vinegar, spicy and aromatic curry, turkey and bacon, caramelized onion and sweet balsamic vinegar, Stilton and cranberry. Since 2008, Walkers has launched its "Do Us a Flavour" campaign, challenging the British public to think up unique flavors for their crisps. Six flavors were chosen from among the entries and released as special editions. In 2014 the public had to pick one of Walkers' base ingredients, which was made up of six flavors from around the UK – Somerset Cheddar, Devonshire Chicken, Norfolk Pork, Dorset Sour Cream, Vale of Evesham Tomatoes and Aberdeen Angus Beef – then add their own unique flavor. In 2018 Walkers launched six new flavors to celebrate the brand's 70th birthday, with each flavor representing a different decade.

In 1981, hedgehog flavored crisps were produced by the landlord of "The Vaults" in Welshpool, Philip Lewis, for his customers who kept asking for them as a joke. They became unexpectedly popular, but this led to controversy. There was concern that real hedgehogs were being slaughtered, but it proved that they were actually flavored with pork fat. This then caused concern about false advertising, and so a compromise was agreed with the trading standards authorities: the labelling was amended to "Hedgehog® Flavoured Crisps".

In the United States, potato chips are made by national chains like Frito-Lay, Pringles and Kettle Brand; major regional brands like Jay's of Chicago, Better Made of Detroit and Old Dutch of Minneapolis; and specialty brands with local or uneven distribution.

Potato chip flavorings include variations of barbecue, as well as sour cream and onion, sour cream and cheddar, salt and vinegar, ranch, jalapeno and cheese. "Hot" is a common flavor such as Jay's Hot Stuff and Better Made Red Hot. Better Made also make Rainbow chips, heavily cooked dark-colored chips which would be rejected by most processors. In the Gulf South, Zapp's of Gramercy, Louisiana, makes kettle-cooked chips using regional flavors such as Crawtator, Cajun dill, Voodoo, and Creole onion.

Pennsylvania leads the United States in potato chip production, and has been dubbed "the Potato Chip Capital" by several sources. Pennsylvania-based companies that produce potato chips include Utz Quality Foods, Herr's Snacks, Snyder's of Berlin, Snyder's of Hanover, Martin's Potato Chips, Wise Foods and Charles Chips.

Another type of potato chip, notably the Pringles and Lay's Stax brands, is made by extruding or pressing a dough made from dehydrated potato flour into the desired shape before frying. This makes chips that are uniform in size and shape, which allows them to be stacked and packaged in rigid cardboard or plastic canisters. Pringles are officially branded as "potato crisps" in the US. Pringles may be termed "potato chips" in Britain, to distinguish them from traditional "crisps". Munchos, another brand that uses the term "potato crisps", has deep air pockets in its chips that give it a curved shape, though the chips themselves resemble regular bagged chips.

An additional variant of potato chips exists in the form of "potato sticks", also called "shoestring potatoes". These are made as extremely thin (2 to 3 mm) versions of the popular French fry but are fried in the manner of regular salted potato chips. A hickory-smoke-flavored version is popular in Canada, going by the vending machine name "Hickory Sticks". Potato sticks are typically packaged in rigid containers, although some manufacturers use flexible pouches, similar to potato chip bags. Potato sticks were originally packed in hermetically sealed steel cans. In the 1960s, manufacturers switched to the less expensive composite canister (similar to the Pringles container). Reckitt Benckiser was a market leader in this category under the Durkee Potato Stix and French's Potato Sticks names but exited the business in 2008. In 2014, French's reentered the market.

A larger variant (about 1 cm thick) made with dehydrated potatoes is marketed as Andy Capp's Pub Fries, using the theme of a long-running British comic strip, which are baked and sold in a variety of flavors.
Walkers make a similar product (using the Smiths brand) called "Chipsticks" which are sold in ready-salted and salt and vinegar flavors.

Some companies have also marketed baked potato chips as an alternative with lower fat content. Additionally, some varieties of fat-free chips have been made using artificial, and indigestible, fat substitutes. These became well known in the media when an ingredient many contained, Olestra, was linked in some individuals to abdominal discomfort and loose stools.

Many other products might be called "crisps" in Britain, but would not be classed as "potato chips" because they are not made with potato or are not chipped (for example, Wotsits, Quavers, Skips, Hula Hoops, and Monster Munch).

Sweet potato chips are eaten in Korea, New Zealand, and Japan; parsnip, beetroot, and carrot crisps are available in the United Kingdom. India is famous for a large number of localized 'chips shops', selling not only potato chips, but also other varieties such as plantain chips, tapioca chips, yam chips, and even carrot chips. Plantain chips, also known as chifles or tostones, are also sold in the Western Hemisphere from Canada to Chile. In the Philippines, banana chips can be found sold at local stores. In Kenya, chips are made from arrowroot and cassava. In the United Kingdom, Sweden, Finland, and Australia, a new variety of Pringles made from rice has been released and marketed as lower in fat than its potato counterparts.


</doc>
<doc id="24856" url="https://en.wikipedia.org/wiki?curid=24856" title="Prohibition">
Prohibition

Prohibition is the act or practice of forbidding something by law; more particularly the term refers to the banning of the manufacture, storage (whether in barrels or in bottles), transportation, sale, possession, and consumption of alcoholic beverages. The word is also used to refer to a period of time during which such bans are enforced.

Some kind of limitation on the trade in alcohol can be seen in the Code of Hammurabi (c. 1772 BCE) specifically banning the selling of beer for money. It could only be bartered for barley: "If a beer seller do not receive barley as the price for beer, but if she receive money or make the beer a measure smaller than the barley measure received, they shall throw her into the water."

In the early twentieth century, much of the impetus for the prohibition movement in the Nordic countries and North America came from moralistic convictions of pietistic Protestants. Prohibition movements in the West coincided with the advent of women's suffrage, with newly empowered women as part of the political process strongly supporting policies that curbed alcohol consumption.

The first half of the 20th century saw periods of prohibition of alcoholic beverages in several countries:

After several years, prohibition failed in North America and elsewhere. Rum-running or bootlegging became widespread, and organized crime took control of the distribution of alcohol. Distilleries and breweries in Canada, Mexico and the Caribbean flourished as their products were either consumed by visiting Americans or illegally exported to the United States. Chicago became notorious as a haven for prohibition dodgers during the time known as the Roaring Twenties. Prohibition generally came to an end in the late 1920s or early 1930s in most of North America and Europe, although a few locations continued prohibition for many more years.

In some countries where the dominant religion forbids the use of alcohol, the production, sale, and consumption of alcoholic beverages is prohibited or restricted today. For example, in Saudi Arabia and Libya alcohol is banned; in Pakistan and Iran it is illegal with exceptions.

Generally, prohibition isn't completely effective, and tends to drive the market underground instead.

In the British colony of Nigeria, missionary forces demanded prohibition of liquor, which proved highly unpopular. Both Africans and Europeans found illegal supplies such as secret stills, obtaining colonial liquor permits, and smuggling. The experiment began in 1890 and was repealed in 1939.
During the coronavirus outbreak of 2020, alcohol sales, and even the transportation of alcohol outside of one's home, was made illegal. This order came into effect during the nationwide lockdown on 27 March 2020. The purpose of the ban was intended to prevent drunken fights, reduce domestic violence, stop drunk driving, and eliminate the weekend binge-drinking so prevalent across South Africa.

Police, medics, and analysts estimate—conservatively—that alcohol is involved in, or responsible for, at least 40% of all emergency hospital admissions. By reducing the number of people within hospitals, and of course within social gatherings, the goal of prohibition was to reduce the rate of transmission, and thus slow the spread of the virus.

Sale of alcohol is banned in Afghanistan.

In Bangladesh, alcohol is somewhat prohibited due to its proscription in the Islamic faith. The purchase and consumption is still allowed in the country. The Garo tribe consume a type of rice beer, and Christians in this country drink and purchase wine for their holy communion.

In India alcohol is a state subject and individual states can legislate prohibition, but currently most states do not have prohibition and sale/consumption is freely available in 25 out of 29 states. Prohibition is in force in the states of Gujarat, Bihar and Nagaland, parts of Manipur, and the union territory of Lakshadweep. All other States and union territories of India permit the sale of alcohol.

Election days and certain national holidays such as "Independence Day" are meant to be "dry days" when liquor sale is not permitted but consumption is allowed. Some Indian states observe dry days on major religious festivals/occasions depending on the popularity of the festival in that region.

The Maldives ban the import of alcohol, x-raying all baggage on arrival. Alcoholic beverages are available only to foreign tourists on resort islands and may not be taken off the resort.

Pakistan allowed the free sale and consumption of alcohol for three decades from 1947, but restrictions were introduced by Zulfikar Ali Bhutto just weeks before he was removed as prime minister in 1977. Since then, only members of non-Muslim minorities such as Hindus, Christians and Zoroastrians are allowed to apply for alcohol permits. The monthly quota is dependent upon one's income, but is actually about five bottles of liquor or 100 bottles of beer. In a country of 180 million, only about 60 outlets are allowed to sell alcohol. The Murree Brewery in Rawalpindi was once the only legal brewery, but today there are more. The ban officially is enforced by the country's Islamic Ideology Council, but it is not strictly policed. Members of religious minorities, however, often sell their liquor permits to Muslims as part of a continuing black market trade in alcohol.

In 1955 Sri Lanka passed a law prohibiting adult women from buying alcohol. In January 2018, Finance Minister Mangala Samaraweera announced that the law would be amended, allowing women to legally consume alcohol and work in venues that sell alcohol. The legalization was overruled by President Maithripala Sirisena several days later.

Since the 1979 Islamic Revolution, the sale and consumption of alcohol is banned in Iran. All people are banned from drinking alcohol but some people trade and sell it illegally.

The consumption, importation and brewing of, and trafficking in liquor is strictly against the law.

The sale, consumption, importation and brewing of, and trafficking in liquor is strictly against the law.

Alcohol is banned in Yemen.

In Brunei, alcohol consumption and sale is banned in public. Non-Muslims are allowed to purchase a limited amount of alcohol from their point of embarcation overseas for their own private consumption, and non-Muslims who are at least the age of 18 are allowed to bring in not more than two bottles of liquor (about two litres) and twelve cans of beer per person into the country.

Alcohol sales are banned in small shops and convenience stores.

Alcohol is banned only for Muslims in Malaysia due to its Islamic faith and sharia law. Nevertheless, alcoholic products can easily be found in supermarkets, specialty shops, and convenience stores all over the country. Non-halal restaurants also typically sell alcohol.

There are only restrictions during elections in the Philippines. Alcohol is prohibited from purchase two days prior to an election. The Philippine Commission on Elections may opt to extend the liquor ban. In the 2010 elections, the liquor ban was a minimum two days; in the 2013 elections, there was a proposal that it be extended to five days. This was overturned by the Supreme Court.

Other than election-related prohibition, alcohol is freely sold to anyone above the legal drinking age.

Alcohol is prohibited from being sold during election time, from 6 pm the day prior to voting, until the end of the day of voting itself. Alcohol is also prohibited on major Buddhist holy days, and sometimes on Royal Commemoration days, such as birthdays.

Thailand also enforces time-limited bans on alcohol on a daily basis. Alcohol can only be legally purchased in stores or restaurants between 11 am–2 pm and 5 pm–midnight. This law is enforced by all major retailers (most notably 7-Eleven) and restaurants but is frequently ignored by the smaller 'mom and pop' stores. Hotels and resorts are exempt from the rules.

The consumption of alcohol is also banned at any time within 200 meters of a filling station (where sale of alcohol is also illegal), schools, temples or hospitals as well as on board any type of road vehicle regardless of whether it is being consumed by the driver or passenger.

At certain times of the year – Thai New Year (Songkran) as an example – the government may also enforce arbitrary bans on the sale and consumption of alcohol in specific public areas where large scale festivities are due to take place and large crowds are expected.

On 14 September 2012, the government of the Czech Republic banned all sales of liquor with more than 20% alcohol. From this date on it was illegal to sell such alcoholic beverages in shops, supermarkets, bars, restaurants, gas stations, e-shops etc. This measure was taken in response to the wave of methanol poisoning cases resulting in the deaths of 18 people in the Czech Republic. Since the beginning of the "methanol affair" the total number of deaths has increased to 25. The ban was to be valid until further notice, though restrictions were eased towards the end of September. The last bans on Czech alcohol with regard to the poisoning cases were lifted on 10 October 2012, when neighbouring Slovakia and Poland allowed its import once again.

The Nordic countries, with the exception of Denmark, have had a strong temperance movement since the late 1800s, closely linked to the Christian revival movement of the late 19th century, but also to several worker organisations. As an example, in 1910 the temperance organisations in Sweden had some 330,000 members, which was about 6% of a population of 5.5 million. This heavily influenced the decisions of Nordic politicians in the early 20th century.

In 1907, the Faroe Islands passed a law prohibiting all sale of alcohol, which was in force until 1992. Very restricted private importation from Denmark was allowed from 1928 on.

In 1914, Sweden put in place a rationing system, the Bratt System, in force until 1955. A referendum in 1922 rejected an attempt to enforce total prohibition.

In 1915, Iceland instituted total prohibition. The ban for wine was lifted in 1922 and spirits in 1935, but beer remained prohibited until 1989 (circumvented by mixing light beer and spirits).

In 1916, Norway prohibited distilled beverages, and in 1917 the prohibition was extended to also include fortified wine and beer. The wine and beer ban was lifted in 1923, and in 1927 the ban of distilled beverages was also lifted.
In 1919, Finland enacted prohibition, as one of the first acts after independence from the Russian Empire. Four previous attempts to institute prohibition in the early 20th century had failed due to opposition from the tsar. After a development similar to the one in the United States during its prohibition, with large-scale smuggling and increasing violence and crime rates, public opinion turned against the prohibition, and after a national referendum where 70% voted for a repeal of the law, prohibition was ended in early 1932.

Today, all Nordic countries (with the exception of Denmark) continue to have strict controls on the sale of alcohol, which is highly taxed (dutied) to the public. There are government monopolies in place for selling spirits, wine, and stronger beers in Norway (Vinmonopolet), Finland (Alko), Sweden (Systembolaget), Iceland (Vínbúðin), and the Faroe Islands (Rúsdrekkasøla Landsins). Bars and restaurants may, however, import alcoholic beverages directly or through other companies.
Greenland, which is part of the Kingdom of Denmark, does not share its easier controls on the sale of alcohol. Greenland has (like Denmark) sales in food shops, but prices are high. Private import when traveling from Denmark is only allowed in small quantities.

In the Russian Empire, a limited version of a Dry Law was introduced in 1914. It continued through the turmoil of the Russian Revolution of 1917 and the Russian Civil War into the period of Soviet Russia and the Soviet Union until 1925.

Although the sale or consumption of commercial alcohol has never been prohibited by law in the United Kingdom, historically, various groups in the UK have campaigned for the prohibition of alcohol; including the Society of Friends (Quakers), The Methodist Church and other non-conformists, as well as temperance movements such as Band of Hope and temperance Chartist movements of the nineteenth century.

Formed in 1853 and inspired by the Maine law in the United States, the United Kingdom Alliance aimed at promoting a similar law prohibiting the sale of alcohol in the UK. This hard-line group of prohibitionists was opposed by other temperance organisations who preferred moral persuasion to a legal ban. This division in the ranks limited the effectiveness of the temperance movement as a whole. The impotence of legislation in this field was demonstrated when the Sale of Beer Act 1854, which restricted Sunday opening hours, had to be repealed, following widespread rioting. In 1859, a prototype prohibition bill was overwhelmingly defeated in the House of Commons.

On 22 March 1917, during the First World War at a crowded meeting in the Queen's Hall in London (chaired by Alfred Booth) many influential people including Agnes Weston spoke, or letters from them were read out, against alcohol consumption, calling for prohibition; General Sir Reginald Hart wrote to the meeting that "Every experienced officer knew that practically all unhappiness and crime in the Army is due to drink". At the meeting, Lord Channing said that it was a pity that the whole Cabinet did not follow the example of King George V and Lord Kitchener when in 1914 those two spoke calling for complete prohibition for the duration of the war.

Edwin Scrymgeour served as Member of Parliament for Dundee between 15 November 1922 and 8 October 1931. He remains the only person to have been elected to the House of Commons on a prohibitionist ticket. In 1922 he defeated incumbent Liberal member Winston Churchill; winning the seat for the 
Scottish Prohibition Party, which he had founded in 1901, and for which he had stood for election successfully as a Dundee Burgh Councillor in 1905 and unsuccessfully as a parliamentary candidate between 1908 and 1922.

Indigenous peoples in Canada were subject to prohibitory alcohol laws under the "Indian Act" of 1876. Sections of the "Indian Act" regarding liquor were not repealed for over a hundred years, until 1985.

An official, but non-binding, federal referendum on prohibition was held in 1898. Prime Minister Wilfrid Laurier's government chose not to introduce a federal bill on prohibition, mindful of the strong antipathy in Quebec. As a result, Canadian prohibition was instead enacted through laws passed by the provinces during the first twenty years of the 20th century, especially during the 1910s. Canada did, however, enact a national prohibition from 1918 to 1920 as a temporary wartime measure. Much of the rum-running during prohibition took place in Windsor, Ontario. The provinces later repealed their prohibition laws, mostly during the 1920s, although some local municipalities remain dry.

Some communities in the Chiapas state of southern Mexico are under the control of the radical leftist Zapatista Army of National Liberation, and often ban alcohol as part of what was described as "a collective decision". This prohibition has been used by many villages as a way to decrease domestic violence and has generally been favored by women. This prohibition, however, is not recognized by federal Mexican law as the Zapatista movement is strongly opposed by the federal government.

The sale and purchase of alcohol is prohibited on and the night before certain national holidays, such as "Natalicio de Benito Juárez" (birthdate of Benito Juárez) and "Día de la Revolución", which are meant to be dry nationally. The same "dry law" applies to the days before presidential elections every six years.

Prohibition in the United States focused on the manufacture, transportation, and sale of alcoholic beverages; exceptions were made for medicinal and religious uses. Alcohol consumption was never illegal under federal law. Nationwide Prohibition did not begin in the United States until January 1920, when the Eighteenth Amendment to the U.S. Constitution went into effect. The 18th amendment was ratified in 1919, and was repealed in December 1933 with the ratification of the Twenty-first Amendment.

Concern over excessive alcohol consumption began during the American colonial era, when fines were imposed for drunken behavior and for selling liquor without a license. In the eighteenth century, when drinking was a part of everyday American life, Protestant religious groups, especially the Methodists, and health reformers, including Benjamin Rush and others, urged Americans to curb their drinking habits for moral and health reasons. In particular, Benjamin Rush believed Americans were drinking hard spirits in excess, so he created "A Moral and Physical Thermometer," displaying the progression of behaviors caused by the consumption of various alcohols. By the 1840s the temperance movement was actively encouraging individuals to immediately stop drinking. Music (a completely new genre) was composed and performed in support of the efforts, both in social contexts and in response to state legislation attempts to regulate alcohol. Many took a pledge of total abstinence (teetotalism) from drinking distilled liquor as well as beer and wine. Nonetheless, the issue of slavery, and then the Civil War, overshadowed the temperance movement, and temperance groups petered out until they found new life in the 1870s.

Prohibition was a major reform movement from the 1870s until the 1920s, when nationwide prohibition went into effect. Prohibition was supported by evangelical Protestant churches, especially the Methodists, Baptists, Presbyterians, Disciples of Christ, Congregationalists, Quakers, and Scandinavian Lutherans. Opposition came from Catholics, Episcopalians, and German Lutherans. Kansas and Maine were early adopters of statewide prohibition. Following passage of the Maine law, Delaware, Ohio, Illinois, Rhode Island, Minnesota, Massachusetts, Connecticut, Pennsylvania, and New York, among others, soon passed statewide prohibition legislation; a number of these laws were, however, overturned.

Women served a special role in the temperance movement. Along with prostitution, alcohol was seen as a vice that kept men out of their homes and caused them to oppress their wives. Carrie Nation, a middle-aged woman living in Kansas in the early 1900s, grew tired of the moral protesting, and began a campaign destroying bars first in Kansas and later across the entire United States. She said once that "almost everyone who was in jail was directly or indirectly there from the influence of intoxicating drinks," which encapsulated people's negative attitudes towards alcohol at the time. Nation also said, after she destroyed a painting of a nude woman, "It is very significant that the pictures of naked women are in saloons. Women are stripped of everything by them. Her husband is torn from her, she is robbed of her sons, her home, her food, and her virtue, and then they strip her clothes off and hang her up bare of all things!"

As temperance groups continued to promote prohibition, other groups opposed increased alcohol restrictions. For example, Chicago's citizens fought against enforcing Sunday closings laws in the 1850s, which included mob violence. It was also during this time when patent medicines, many of which contained alcohol, gained popularity. During the American Civil War efforts at increasing federal revenue included imposition of taxes on liquor and beer. The liquor industry responded to the taxes by forming an industry lobby, the United States Brewers Association, that succeeded in reducing the tax rate on beer from $1 to 60 cents. The Women's Crusade of 1873 and the Woman's Christian Temperance Union (WCTU), founded in 1874, "marked the formal entrance of women into the temperance movement." Organizations such as the Women's Christian Temperance Movement were a venue through which certain women organized and demanded political action, well before they were granted the vote. The WCTU and the Prohibition Party, organized in 1869, remained major players in the temperance movement until the early twentieth century, when the Anti-Saloon League, formed in 1895, emerged as the movement's leader.

Between 1880 and 1890, although several states enacted local option laws that allowed counties or towns to go dry by referendum, only six states had statewide prohibition by state statute or constitutional amendment. The League, with the support of evangelical Protestant churches and other Progressive-era reformers continued to press for prohibition legislation. Opposition to prohibition was strong in America's urban industrial centers, where a large, immigrant, working-class population generally opposed it, as did Jewish and Catholic religious groups. In the years leading up to World War I, nativism, American patriotism, distrust of immigrants, and anti-German sentiment became associated with the prohibition movement. Through the use of pressure politics on legislators, the League and other temperance reformers achieved the goal of nationwide prohibition by emphasizing the need to destroy the moral corruption of the saloons and the political power of the brewing industry, and to reduce domestic violence in the home. By 1913, nine states had statewide prohibition and thirty-one others had local option laws in effect, which included nearly 50% of the U.S. population. At that time the League and other reformers turned their efforts toward attaining a constitutional amendment and grassroots support for nationwide prohibition.

In December 1917, Congress submitted a constitutional amendment on nationwide prohibition to the states for ratification. The new constitutional amendment prohibited "the manufacture, sale, or transportation of intoxicating liquors within, the importation thereof into, or the exportation thereof from the United States and all territory subject to the jurisdiction thereof for beverage purposes". It was ratified and became law on January 16, 1919, assuring its passage into law. On October 28, 1919, Congress passed the National Prohibition Act, also known as the Volstead Act, which provided enabling legislation to implement the Eighteenth Amendment. When the National Prohibition Act was passed on October 28, 1919, thirty-three of the forty-eight states were already dry. After a year's required delay, national prohibition began on January 16, 1920.

During the first years of Prohibition, the new law was enforced in regions such as the rural South and western states, where it had popular support; in large urban cities and small industrial or mining towns, however, residents defied or ignored the law. The Ku Klux Klan was a major supporter of Prohibition; once it was passed they helped with its enforcement. For example, in 1923, Klansmen traded pistol shots with bootleggers, burned down roadhouses, and whipped liquor sellers, and anybody else who broke the moral code. The Prohibition was effective in reducing per-capita consumption, and consumption remained lower for a quarter-century after Prohibition had been repealed.
Prohibition reduced alcohol consumption but did not stop it. Drinking itself was never illegal, although manufacturing and sale of alcoholic beverages was outlawed, so people who had bought alcohol before January 16, 1920, could and did continue to serve it privately. In addition, the illicit market soon grew to about two-thirds its pre-Prohibition levels. Illegal stills flourished in remote rural areas as well as city slums, and large quantities were smuggled from Canada. Bootlegging – and the related speakeasies – became a major business activity for organized crime groups, under leaders such as Al Capone in Chicago and Lucky Luciano in New York City. Indeed, Capone became a national symbol of Prohibition's violent side and was a top target for President Hoover.

Prohibition lost support during the Great Depression, which started in 1929. So-called "wets" – people in favor of repeal – argued that legal sales would reduce violent gang crime, increase employment and raise tax revenues. The repeal movement was initiated and financed by the Association Against the Prohibition Amendment, who worked to elect Congressmen who agreed to support repeal. The group's wealthy supporters included John D. Rockefeller, Jr., S. S. Kresge, and the Du Pont family, among others, who had abandoned the dry cause. Pauline Sabin, a wealthy Republican who founded the Women's Organization for National Prohibition Reform (WONPR), argued that Prohibition should be repealed because it made the United States a nation of hypocrites and undermined its respect for the rule of law. This hypocrisy and the fact that women had initially led the prohibition movement convinced Sabin to establish the WONPR. Their efforts eventually led to the repeal of prohibition. When Sabin's fellow Republicans would not support her efforts, she went to the Democrats, who switched their support of the dry cause to endorse repeal under the leadership of liberal politicians such as Fiorello La Guardia and Franklin D. Roosevelt. Sabin and her supporters emphasized that repeal would generate enormous sums of much-needed tax revenue, and weaken the base of organized crime.

Repeal of Prohibition was accomplished with the ratification of the Twenty-first Amendment on December 5, 1933. Under its terms, states were allowed to set their own laws for the control of alcohol.

Following repeal, public interest in an organized prohibition movement dwindled. The movement nonetheless survived for a while in a few southern and border states. To this day, there are still counties and parishes within the US known as "dry," where the sale of alcohol – liquor, and sometimes wine and beer – is prohibited. Some such counties/parishes/municipalities have adopted "Moist county" policies, however, in order to expand tax revenue. Some municipalities regulate when alcohol can be sold; an example is restricting or banning sales on Sunday, under the so-called "blue laws." Between 1832 and 1953, federal legislation prohibited the sale of alcohol to aboriginal Americans, with very limited success. After 1953, aboriginal American communities and reservations were permitted to pass their own local ordinances governing the sale of alcoholic beverages.

In Venezuela, twenty-four hours before every election, the government prohibits the sale and distribution of alcoholic beverages throughout the national territory, including the restriction to all dealers, liquor stores, supermarkets, restaurants, wineries, pubs, bars, public entertainment, clubs and any establishment that markets alcoholic beverages.

The same is done during Holy Week as a measure to reduce the alarming rate of road traffic accidents during these holidays.

The Australian Capital Territory (then the Federal Capital Territory) was the first jurisdiction in Australia to have prohibition laws. In 1911, King O'Malley, then Minister of Home Affairs, shepherded laws through Parliament preventing new issue or transfer of licences to sell alcohol, to address unruly behaviour among workers building the new capital city. Prohibition was partial, since possession of alcohol purchased outside of the Territory remained legal and the few pubs that had existing licences could continue to operate. The Federal Parliament repealed the laws after residents of the Federal Capital Territory voted for the end of them in a 1928 plebiscite.

Since then, some state governments and local councils have enacted dry areas. This is where the purchase or consumption of alcohol is only permitted in licensed areas such as liquor stores, clubs, cafes, bars, hotels, restaurants, and also private homes. In public places such as streets, parks, and squares, consumption is not permitted, but carrying bottles that were purchased at licensed venues is allowed. Almost all dry areas are small defined districts within larger urban or rural communities.

More recently, alcohol has been prohibited in many remote indigenous communities. Penalties for transporting alcohol into these "dry" communities are severe and can result in confiscation of any vehicles involved; in dry areas within the Northern Territory, all vehicles used to transport alcohol are seized.

In New Zealand, prohibition was a moralistic reform movement begun in the mid-1880s by the Protestant evangelical and Nonconformist churches and the Woman's Christian Temperance Union and after 1890 by the Prohibition League. It assumed that individual virtue was all that was needed to carry the colony forward from a pioneering society to a more mature one, but it never achieved its goal of national prohibition. Both the Church of England and the largely Irish Catholic Church rejected prohibition as an intrusion of government into the church's domain, while the growing labor movement saw capitalism rather than alcohol as the enemy.

Reformers hoped that the women's vote, in which New Zealand was a pioneer, would swing the balance, but the women were not as well organized as in other countries. Prohibition had a majority in a national referendum in 1911, but needed a 60% vote to pass. The movement kept trying in the 1920s, losing three more referenda by close votes; it managed to keep in place a 6 p.m. closing hour for pubs and Sunday closing. The Depression and war years effectively ended the movement. but their 6 p.m. closing hour remained until October 1967 when it was extended to 10 p.m.

For many years, referenda were held for individual towns or electorates, often coincident with general elections. The ballots determined whether these individual areas would be "dry" – that is, alcohol could not be purchased or consumed in public in these areas. One notable example was the southern city of Invercargill, which was dry from 1907 to 1943. People wanting alcohol usually travelled to places outside the city (such as the nearby township of Lorneville or the town of Winton) to drink in the local pubs or purchase alcohol to take back home. The last bastion of this 'dry' area remains in force in the form of a licensing trust that still to this day governs the sale of liquor in Invercargill. The city does not allow the sale of alcohol (beer and wine included) in supermarkets unlike the remainder of New Zealand, and all form of alcohol regardless of the sort can only be sold in bars and liquor stores.

Prohibition was of limited success in New Zealand as—like in other countries—it led to organised bootlegging. The most famous bootlegged alcohol in New Zealand was that produced in the Hokonui Hills close to the town of Gore (not coincidentally, the nearest large town to Invercargill). Even today, the term "Hokonui" conjures up images of illicit whisky to many New Zealanders.

In many countries in Latin America, the Philippines, Thailand, Turkey and several US states, the sale but not the consumption of alcohol is prohibited before and during elections.



</doc>
<doc id="24857" url="https://en.wikipedia.org/wiki?curid=24857" title="Phenothiazine">
Phenothiazine

Phenothiazine, abbreviated PTZ, is an organic compound that has the formula S(CH)NH and is related to the thiazine-class of heterocyclic compounds. Derivatives of phenothiazine are highly bioactive and have widespread use and rich history. The derivatives chlorpromazine and promethazine revolutionized the field of psychiatry and allergy treatment, respectively. An earlier derivative, methylene blue, was one of the first antimalarial drugs, and derivatives are under investigation as possible anti-infective drugs. Phenothiazine is a prototypical pharmaceutical lead structure in medicinal chemistry.

Phenothiazine itself is only of theoretical interest, but its derivatives revolutionized psychiatry, other fields of medicine, and pest management. Other derivatives have been studied for possible use in advanced batteries and fuel cells.

In 1876, methylene blue, a derivative of phenothiazine, was synthesized by Heinrich Caro at BASF. The structure was deduced in 1885 by Heinrich August Bernthsen. Bernthsen synthesized phenothiazine in 1883. In the mid 1880s, Paul Ehrlich began to use methylene blue in his cell staining experiments that led to pioneering discoveries about different cell types. He was awarded a Nobel Prize based in part on that work. He became particularly interested in its use to stain bacteria and parasites such as "Plasmodiidae" – the genus that includes the malaria pathogen – and found that it could be stained with methylene blue. He thought methylene blue could possibly be used in the treatment of malaria, tested it clinically, and by the 1890s methylene blue was being used for that purpose.

For the next several decades, research on derivatives lapsed until phenothiazine itself came to market as an insecticide and deworming drug. In the 1940s, chemists working with Paul Charpentier at Rhone-Poulenc Laboratories in Paris (a precursor company to Sanofi), began making derivatives. This work led to promethazine which had no activity against infective organisms, but did have good antihistamine activity, with a strong sedative effect. It went to market as a drug for allergies and for anesthesia. As of 2012 it was still on the market. At the end of the 1940s the same lab produced chlorpromazine which had an even stronger sedative and soothing effect, and Jean Delay and Pierre Deniker attempted to use it on their psychiatric patients, publishing their results in the early 1950s. The strong effects they found opened the door of the modern field of psychiatry and led to a proliferation of work on phenothiazine derivatives. The systematic research conducted by chemists to explore phenothiazine derivatives and their activity was a pioneering example of medicinal chemistry; phenothiazine is often discussed as a prototypical example of a pharmaceutical lead structure.

The term "phenothiazines" describes the largest of the five main classes of antipsychotic drugs. These drugs have antipsychotic and, often, antiemetic properties, although they may also cause severe side effects such as extrapyramidal symptoms (including akathisia and tardive dyskinesia), hyperprolactinaemia, and the rare but potentially fatal neuroleptic malignant syndrome, as well as substantial weight gain. Use of phenothiazines has been associated with antiphospholipid syndrome, but no causal relationship has been established.

Phenothiazine antipsychotics are classified into three groups that differ with respect to the substituent on nitrogen: the aliphatic compounds (bearing acyclic groups), the "piperidines" (bearing piperidine-derived groups), and the piperazine (bearing piperazine-derived substituents).

The synthetic dye methylene blue, containing the structure, was described in 1876. Many water-soluble phenothiazine derivatives, such as methylene blue, methylene green, thionine, and others, can be electropolymerized into conductive polymers used as electrocatalysts for NADH oxidation in enzymatic biosensors and biofuel cells.

Phenothiazine is used as an anaerobic inhibitor for acrylic acid polymerization, often used as an in-process inhibitor during the purification of acrylic acid.

Like many commercially significant compounds, phenothiazine has numerous trade names, including AFI-Tiazin, Agrazine, Antiverm, Biverm, Dibenzothiazine, Orimon, Lethelmin, Souframine, Nemazene, Vermitin, Padophene, Fenoverm, Fentiazine, Contaverm, Fenothiazine, Phenovarm, Ieeno, ENT 38, Helmetina, Helmetine, Penthazine, XL-50, Wurm-thional, Phenegic, Phenovis, Phenoxur, and Reconox.

Phenothiazine was formerly used as an insecticide and as a drug to treat infections with parasitic worms (anthelminthic) in livestock and people, but its use for those purposes has been superseded by other chemicals.

Phenothiazine was introduced by DuPont as an insecticide in 1935. About 3,500,000 pounds were sold in the US in 1944. However, because it was degraded by sunlight and air, it was difficult to determine how much to use in the field, and its use waned in the 1940s with the arrival of new pesticides like DDT that were more durable. As of July 2015 it is not registered for pesticide use in the US, Europe, or Australia.

It was introduced as anthelminthic in livestock in 1940 and is considered, with thiabendazole, to be the first modern anthelminthic. The first instances of resistance were noted in 1961. Uses for this purpose in the US are still described but it has "virtually disappeared from the market."

In the 1940s it also was introduced as antihelminthic for humans; since it was often given to children, the drug was often sold in chocolate, leading to the popular name, "worm chocolate." Phenothiazine was superseded by other drugs in the 1950s.

The central CSN ring is folded in phenothiazines.

The compound was originally prepared by Bernthsen in 1883 via the reaction of diphenylamine with sulfur, but more recent syntheses rely on the cyclization of 2-substituted diphenyl sulfides. Few pharmaceutically significant phenothiazines are prepared from phenothiazine, although some of them are.

Phenothiazines are electron donors, forming charge-transfer salts with many acceptors.



</doc>
<doc id="24861" url="https://en.wikipedia.org/wiki?curid=24861" title="Pale Fire">
Pale Fire

Pale Fire is a 1962 novel by Vladimir Nabokov. The novel is presented as a 999-line poem titled "Pale Fire", written by the fictional poet John Shade, with a foreword, lengthy commentary and index written by Shade's neighbor and academic colleague, Charles Kinbote. Together these elements form a narrative in which both fictional authors are central characters.

"Pale Fire" has spawned a wide variety of interpretations and a large body of written criticism, which Finnish literary scholar estimated in 1995 as more than 80 studies. The Nabokov authority Brian Boyd has called it "Nabokov's most perfect novel", and the critic Harold Bloom called it "the surest demonstration of his own genius ... that remarkable tour de force". It was ranked 53rd on the list of the Modern Library 100 Best Novels and 1st on the American literary critic Larry McCaffery's "."

Starting with the epigraph and table of contents, "Pale Fire" looks like the publication of a 999-line poem in four cantos ("Pale Fire") by the fictional John Shade with a foreword, extensive commentary, and index by his self-appointed editor, Charles Kinbote. Kinbote's commentary takes the form of notes to various numbered lines of the poem. Here and in the rest of his critical apparatus, Kinbote explicates the poem very little. Focusing instead on his own concerns, he divulges what proves to be the plot piece by piece, some of which can be connected by following the many cross-references. Espen Aarseth noted that "Pale Fire" "can be read either unicursally, straight through, or multicursally, jumping between the comments and the poem." Thus, although the narration is non-linear and multidimensional, the reader can still choose to read the novel in a linear manner without risking misinterpretation.

The novel's unusual structure has attracted much attention, and it is often cited as an important example of metafiction; it has also been called a poioumenon. The connection between "Pale Fire" and hypertext was stated soon after its publication; in 1969, the information-technology researcher Ted Nelson obtained permission from the novel's publishers to use it for a hypertext demonstration at Brown University. A 2009 paper also compares "Pale Fire" to hypertext.

The interaction between Kinbote and Shade takes place in the fictitious small college town of New Wye, Appalachia, where they live across a lane from each other, from February to July 1959. Kinbote writes his commentary from then to October 1959 in a tourist cabin in the equally fictitious western town of Cedarn, Utana. Both authors recount many earlier events, Shade mostly in New Wye and Kinbote in New Wye and in Europe, especially the "distant northern land" of Zembla.

Shade's poem digressively describes many aspects of his life. Canto 1 includes his early encounters with death and glimpses of what he takes to be the supernatural. Canto 2 is about his family and the apparent suicide of his daughter, Hazel Shade. Canto 3 focuses on Shade's search for knowledge about an afterlife, culminating in a "faint hope" in higher powers "playing a game of worlds" as indicated by apparent coincidences. Canto 4 offers details on Shade's daily life and creative process, as well as thoughts on his poetry, which he finds to be a means of somehow understanding the universe.

In Kinbote's editorial contributions he tells three stories intermixed with each other. One is his own story, notably including what he thinks of as his friendship with Shade. After Shade was murdered, Kinbote acquired the manuscript, including some variants, and has taken it upon himself to oversee the poem's publication, telling readers that it lacks only line 1000. Kinbote's second story deals with King Charles II, "The Beloved", the deposed king of Zembla. King Charles escaped imprisonment by Soviet-backed revolutionaries, making use of a secret passage and brave adherents in disguise. Kinbote repeatedly claims that he inspired Shade to write the poem by recounting King Charles's escape to him and that possible allusions to the king, and to Zembla, appear in Shade's poem, especially in rejected drafts. However, no explicit reference to King Charles is to be found in the poem. Kinbote's third story is that of Gradus, an assassin dispatched by the new rulers of Zembla to kill the exiled King Charles. Gradus makes his way from Zembla through Europe and America to New Wye, suffering comic mishaps. In the last note, to the missing line 1000, Kinbote narrates how Gradus killed Shade by mistake.

Towards the end of the narrative, Kinbote all but states that he is in fact the exiled King Charles, living incognito; however, enough details throughout the story, as well as direct statements of ambiguous sincerity by Kinbote towards the novel's end, suggest that King Charles and Zembla are both fictitious. In the latter interpretation, Kinbote is delusional and has built an elaborate picture of Zembla complete with samples of a constructed language as a by-product of insanity; similarly, Gradus was simply an unhinged man trying to kill Shade, and his backstory as a revolutionary assassin is also made up.

In an interview, Nabokov later claimed that Kinbote committed suicide after finishing the book. The critic Michael Wood has stated, "This is authorial trespassing, and we don't have to pay attention to it", but Brian Boyd has argued that internal evidence points to Kinbote's suicide. One of Kinbote's annotations to Shade's poem (corresponding to line 493) addresses the subject of suicide at some length.

As Nabokov pointed out himself, the title of John Shade's poem is from Shakespeare's "Timon of Athens:" "The moon's an arrant thief, / And her pale fire she snatches from the sun" (Act IV, scene 3), a line often taken as a metaphor about creativity and inspiration. Kinbote quotes the passage but does not recognize it, as he says he has access only to an inaccurate Zemblan translation of the play "in his Timonian cave", and in a separate note he even rails against the common practice of using quotations as titles.

Some critics have noted a secondary reference in the book's title to "Hamlet", where the Ghost remarks how the glow-worm "'gins to pale his uneffectual fire" (Act I, scene 5).

The title is first mentioned in the foreword: "I recall seeing him from my porch, on a brilliant morning, burning a whole stack of [index cards of drafts of the poem] in the pale fire of the incinerator...".

According to Norman Page, "Pale Fire" excited as diverse criticism as any of Nabokov's novels. Mary McCarthy's review was extremely laudatory; the Vintage edition excerpts it on the front cover. She tried to explicate hidden references and connections. Dwight Macdonald responded by saying the book was "unreadable" and both it and McCarthy's review were as pedantic as Kinbote. Anthony Burgess, like McCarthy, extolled the book, while Alfred Chester condemned it as "a total wreck".

Some other early reviews were less decided, praising the book's satire and comedy but noting its difficulty and finding its subject slight or saying that its artistry offers "only a kibitzer's pleasure". Macdonald called the reviews he had seen, other than McCarthy's, "cautiously unfavorable". "TIME" magazine's 1962 review stated that "Pale Fire does not really cohere as a satire; good as it is, the novel in the end seems to be mostly an exercise in agility – or perhaps in bewilderment", though this did not prevent "TIME" from including the book in its 2005 list of the 100 best English-language novels published since 1923.

The first Russian translation of the novel, one created by Véra Nabokov, its dedicatee, was published in 1983 by Ardis in Ann Arbor, Michigan (Alexei Tsvetkov initially played an important role in this translation).

After Nabokov's reputation was rehabilitated in the Soviet Union (his novels started being published there in 1986 and the first book composed entirely of Nabokov's works was printed in 1988), "Pale Fire" was published in 1991 in Sverdlovsk (in Sergei Ilyin's Russian translation).

Some readers concentrate on the apparent story, focusing on traditional aspects of fiction such as the relationship among the characters. In 1997, Brian Boyd published a much-discussed study arguing that the ghost of John Shade influenced Kinbote's contributions. He expanded this essay into a book in which he also argues that, in order to trigger Shade's poem, Hazel Shade's ghost induced Kinbote to recount his Zemblan delusions to Shade.

Some readers, starting with Mary McCarthy and including Boyd, Nabokov's annotator Alfred Appel, and D. Barton Johnson, see Charles Kinbote as an alter-ego of the insane Professor V. Botkin, to whose delusions John Shade and the rest of the faculty of Wordsmith College generally condescend. Nabokov himself endorsed this reading, stating in an interview in 1962 (the novel's year of publication) that "Pale Fire" "is full of plums that I keep hoping somebody will find. For instance, the nasty commentator is not an ex-King of Zembla nor is he professor Kinbote. He is professor Botkin, or Botkine, a Russian and a madman." The novel's intricate structure of teasing cross-references leads readers to this "plum". The Index, supposedly created by Kinbote, features an entry for a "Botkin, V.," describing this Botkin as an "American scholar of Russian descent"—and referring to a note in the Commentary on line 894 of Shade's poem, in which no such person is directly mentioned but a character suggests that "Kinbote" is "a kind of anagram of Botkin or Botkine". In this interpretation, "Gradus" the murderer is an American named Jack Grey who wanted to kill Judge Goldsworth, whose house "Pale Fire's" commentator—whatever his "true" name is—is renting. Goldsworth had condemned Grey to an asylum from which he escaped shortly before mistakenly killing Shade, who resembled Goldsworth.

Other readers see a story quite different from the apparent narrative. "Shadeans" maintain that John Shade wrote not only the poem, but the commentary as well, having invented his own death and the character of Kinbote as a literary device. According to Boyd, Andrew Field invented the Shadean theory and Julia Bader expanded it; Boyd himself espoused the theory for a time. In an alternative version of the Shadean theory, Tiffany DeRewal and Matthew Roth argued that Kinbote is not a separate person but is a dissociated, alternative personality of John Shade. (An early reviewer had mentioned that "a case might be made" for such a reading.)
"Kinboteans", a decidedly smaller group, believe that Kinbote invented the existence of John Shade. Boyd credits the Kinbotean theory to Page Stegner and adds that most of its adherents are newcomers to the book. Some readers see the book as oscillating undecidably between these alternatives, like the Rubin vase (a drawing that may be two profiles or a goblet).

Though a minority of commentators believe or at least accept the possibility that Zembla is as "real" as New Wye, most assume that Zembla, or at least the operetta-quaint and homosexually gratified palace life enjoyed by Charles Kinbote before he is overthrown, is imaginary in the context of the story. The name "Zembla" (taken from "Nova Zembla", a former latinization of Novaya Zemlya) may evoke popular fantasy literature about royalty such as "The Prisoner of Zenda". As in other Nabokov books, however, the fiction is an exaggerated or comically distorted version of his own life as a son of privilege before the Russian Revolution and an exile afterwards, and the central murder has resemblances (emphasized by Priscilla Meyer) to Nabokov's father's murder by an assassin who was trying to kill someone else.

Still other readers de-emphasize any sort of "real story" and may doubt the existence of such a thing. In the interplay of allusions and thematic links, they find a multifaceted image of English literature, criticism, or glimpses of a higher world and an afterlife.

The first two lines of John Shade's 999-line poem, "Pale Fire", have become Nabokov's most quoted couplet:

<poem>I was the shadow of the waxwing slain
By the false azure in the window pane</poem>

Like many of Nabokov's fictions, "Pale Fire" alludes to others of his. "Hurricane Lolita" is mentioned, and Pnin appears as a minor character. There are many resemblances to "Ultima Thule" and "Solus Rex", two short stories by Nabokov intended to be the first two chapters of a novel in Russian that he never continued. The placename Thule appears in "Pale Fire", as does the phrase "solus rex" (a chess problem in which one player has no pieces but the king).

The book is also full of references to culture, nature, and literature. They include:

See also "The Ambidextrous Universe", a later book referencing "Pale Fire" which in turn triggered a reciprocal response in a subsequent Nabokov novel ("", 1969).




</doc>
<doc id="24862" url="https://en.wikipedia.org/wiki?curid=24862" title="Preservative">
Preservative

A preservative is a substance or a chemical that is added to products such as food products, beverages, pharmaceutical drugs, paints, biological samples, cosmetics, wood, and many other products to prevent decomposition by microbial growth or by undesirable chemical changes. In general, preservation is implemented in two modes, chemical and physical. Chemical preservation entails adding chemical compounds to the product. Physical preservation entails processes such as refrigeration or drying. Preservative food additives reduce the risk of foodborne infections, decrease microbial spoilage, and preserve fresh attributes and nutritional quality. Some physical techniques for food preservation include dehydration, UV-C radiation, freeze-drying, and refrigeration. Chemical preservation and physical preservation techniques are sometimes combined.

Antimicrobial preservatives prevent degradation by bacteria. This method is the most traditional and ancient type of preserving—ancient methods such as pickling and adding honey prevent microorganism growth by modifying the pH level. The most commonly used antimicrobial preservative is lactic acid. Common antimicrobial preservatives are presented in the table. Nitrates and nitrites are also antimicrobial. The detailed mechanism of these chemical compounds range from inhibiting growth of the bacteria to the inhibition of specific enzymes. Water-based home and personal care products use broad-spectrum preservatives, such as isothiazolinones and formaldehyde releasers, which may cause sensitization, allergic skin reactions, and toxicity to aquatic life.

The oxidation process spoils most food, especially those with a high fat content. Fats quickly turn rancid when exposed to oxygen. Antioxidants prevent or inhibit the oxidation process. The most common antioxidant additives are ascorbic acid (vitamin C) and ascorbates. Thus, antioxidants are commonly added to oils, cheese, and chips. Other antioxidants include the phenol derivatives BHA, BHT, TBHQ and propyl gallate. These agents suppress the formation of hydroperoxides. Other preservatives include ethanol and methylchloroisothiazolinone.
A variety of agents are added to sequester (deactivate) metal ions that otherwise catalyze the oxidation of fats. Common sequestering agents are disodium EDTA, citric acid (and citrates), tartaric acid, and lecithin.

Citric and ascorbic acids target enzymes that degrade fruits and vegetables, e.g., mono/polyphenol oxidase which turns surfaces of cut apples and potatoes brown. Ascorbic acid and tocopherol, which are vitamins, are common preservatives. Smoking entails exposing food to a variety of phenols, which are antioxidants. Natural preservatives include rosemary and oregano extract, hops, salt, sugar, vinegar, alcohol, diatomaceous earth and castor oil.

Traditional preservatives, such as sodium benzoate have raised health concerns in the past. Benzoate was shown in a study to cause hypersensitivity in some asthma sufferers. This has caused reexamination of natural preservatives which occur in vegetables.

Preservatives have been used since prehistoric times. Smoked meat for example has phenols and other chemicals that delay spoilage. The preservation of foods has evolved greatly over the centuries and has been instrumental in increasing food security. The use of preservatives other than traditional oils, salts, paints, etc. in food began in the late 19th century, but was not widespread until the 20th century.

The use of food preservatives varies greatly depending on the country. Many developing countries that do not have strong governments to regulate food additives face either harmful levels of preservatives in foods or a complete avoidance of foods that are considered unnatural or foreign. These countries have also proven useful in case studies surrounding chemical preservatives, as they have been only recently introduced. In urban slums of highly populated countries, the knowledge about contents of food tends to be extremely low, despite consumption of these imported foods.

In ancient times the sun and wind naturally dried out foods. Middle Eastern and Oriental cultures started drying foods in 1,200 B.C. in the sun. The Romans used a lot of dry fruit. In the Middle Ages, people made “still houses” where fruits, vegetables, and herbs could dry out in climates that did not have strong sunlight. Sometimes fires were made to create heat to dry foods. Drying prevents yeasts and bread molds ("Rhizopus") from growing by removing moisture so bacteria cannot grow.

Cellars, caves, and cool streams were used for freezing. American estates had ice houses built to store ice and food on the ice. The icehouse was then converted to an “icebox”. The Icebox was converted in the 1800s to mechanical refrigeration. Clarence Birdseye found in the 1800s that freezing meats and vegetables at a low temperature made them taste better.

Fermenting was discovered when a few grains of barley were left in the rain and turned into beer. Microorganisms ferment the starch-derived sugars into alcohols. This is also how fruits are fermented into wine and cabbage into Kimchi or sauerkraut. Anthropologists believe that as early as 10,000 B.C people began to settle and grow barley. They began to make beer and believed that it was a gift from gods. It was used to preserve foods and to create more nutritious foods from less desirable ingredients. Vitamins are produced through fermentation by microorganisms making the end product more nutritious.

Pickling occurs when foods are placed in a container with vinegar or another acid. It is thought that pickling came about when people used to place food in wine or beer to preserve it due to them having a low pH. Containers had to be stoneware or glass (vinegar will dissolve metal from pots). After the food was eaten, the pickling brine had other uses. Romans would make a concentrated pickle sauce called “garum”. It was very concentrated and the dish that it would be used in would only need a few drops to get the fish taste. Due to new foods arriving from Europe in the 16th century, food preservation increased. Ketchup originated from Europe as an oriental fish brine and when it made it to America, sugar was added. Pickling sauces were soon part of many recipes such as chutneys, relish, piccalilli, mustard, and ketchup when different spices were added to them.

The beginning of curing was done through dehydration. Salting was used by early cultures to help desiccate foods. Many different salts were used from different places such as rock salt, sea salt, spiced salt, etc.. People began to experiment and found in the 1800s that some salts gave meat an appealing red color instead of the grey that they were used to. During their experimenting in the 1920s they realized this mixture of salts were nitrates (saltpeter) that prevented "Clostridium botulinum" growth.

Early cultures also used honey or sugar as a preservatives. Greece used a quince and honey mixture with a slight amount of drying and then tightly packed into jars. The Romans used the same technique but instead cooked the honey and quince mixture to make a solid texture. Indian and Oriental traders brought sugarcane to the northern climates where housewives were then able to make preservatives by heating fruit with the sugarcane.

Canning started in 1790 from a French confectioner, Nicolas Appert, when he found that by applying heat to food in sealed glass bottles, the food is free from spoilage. Appert's ideas were tried by the French Navy with meat, vegetables, fruit, and milk in 1806. An Englishman, Peter Durand decided to use Appert's method on tin cans in 1810. Even though Appert found a method that worked, he did not understand why it worked because many believed that the lack of air caused the preservation. In 1864 Louis Pasteur linked food spoilage/illness to microorganisms. Different foods are placed into jars or cans and heated to a microorganism and enzyme inactivating temperature. They are then cooled forming a vacuum seal which prevents microorganisms from contaminating the foods.

Public awareness of food preservatives is uneven. Americans have a perception that food-borne illnesses happen more often in other countries. This may be true, but the occurrence of illnesses, hospitalizations, and deaths are still high. It is estimated by the Centers for Disease Control (CDC) that each year there are 76 million illnesses, 325,000 hospitalizations, and 5,000 deaths linked to food-borne illness.

The increasing demand for ready-to-eat fresh food products has led to challenges for food distributors regarding the safety and quality of their foods. Artificial preservatives meet some of these challenges by preserving freshness for longer periods of time, but these preservatives can cause negative side-effects as well. Sodium nitrite is a preservative used in lunch meats, hams, sausages, hot dogs, and bacon to prevent botulism. It serves the important function of controlling the bacteria that cause botulism, but sodium nitrite can react with proteins, or during cooking at high heats, to form carcinogenic N-nitrosamines. It has also been linked to cancer in lab animals. The commonly used sodium benzoate has been found to extend the shelf life of bottled tomato paste to 40 weeks without loss of quality. However, it can form the carcinogen benzene when combined with vitamin C. Many food manufacturers have reformed their products to eliminate this combination, but a risk still exists. Consumption of sodium benzoate may also cause hyperactivity. For over 30 years, there has been a debate about whether or not preservatives and other food additives can cause hyperactivity. Studies have found that there may be increases in hyperactivity amongst children who consume artificial colorings and benzoate preservatives and who are already genetically predisposed to hyperactivity, but these studies were not entirely conclusive. Hyperactivity only increased moderately, and it was not determined if the preservatives, colorings, or a combination of the two were responsible for the increase.


</doc>
<doc id="24863" url="https://en.wikipedia.org/wiki?curid=24863" title="Proteobacteria">
Proteobacteria

Proteobacteria is a major phylum of Gram-negative bacteria. They include a wide variety of pathogenic genera, such as "Escherichia", "Salmonella", "Vibrio", "Helicobacter", "Yersinia", "Legionellales", and many others. Others are free-living (nonparasitic) and include many of the bacteria responsible for nitrogen fixation.

Carl Woese established this grouping in 1987, calling it informally the "purple bacteria and their relatives". Because of the great diversity of forms found in this group, it was named after Proteus, a Greek god of the sea capable of assuming many different shapes and is not named after the Proteobacteria genus "Proteus".

Some Alphaproteobacteria can grow at very low levels of nutrients and have unusual morphology such as stalks and buds. Others include agriculturally important bacteria capable of inducing nitrogen fixation in symbiosis with plants. The type order is the Caulobacterales, comprising stalk-forming bacteria such as "Caulobacter". The mitochondria of eukaryotes are thought to be descendants of an alphaproteobacterium.

The Betaproteobacteria are highly metabolically diverse and contain chemolithoautotrophs, photoautotrophs, and generalist heterotrophs. The type order is the Burkholderiales, comprising an enormous range of metabolic diversity, including opportunistic pathogens.

The Gammaproteobacteria are the largest class in terms of species with validly published names. The type order is the Pseudomonadales, which include the genera "Pseudomonas" and the nitrogen-fixing "Azotobacter".

The Deltaproteobacteria include bacteria that are predators on other bacteria and are important contributors to the anaerobic side of the sulfur cycle. The type order is the Myxococcales, which includes organisms with self-organising abilities such as "Myxococcus" spp.

The Epsilonproteobacteria are often slender, Gram-negative rods that are helical or curved. The type order is the Campylobacterales, which includes important food pathogens such as "Campylobacter" spp.

The Zetaproteobacteria are iron-oxidizing neutrophilic chemolithoautotrophs, distributed worldwide in estuaries and marine habitats. The type order is the Mariprofundales.

The Hydrogenophilalia are obligate thermophiles and include heterotrophs and autotrophs. The type order is the Hydrogenophilales.

The Acidithiobacillia contain only sulfur, iron, and uranium-oxidising autotrophs. The type order is the Acidithiobacillales, which includes economically important organisms used in the mining industry such as "Acidithiobacillus" spp.

The Oligoflexia are filamentous aerobes. The type order is the Oligoflexales, which contains the genus "Oligoflexus".

All "Proteobacteria" are Gram-negative (though some may stain Gram-positive or Gram-variable in practice), with an outer membrane mainly composed of lipopolysaccharides. Many move about using flagella, but some are nonmotile or rely on bacterial gliding. The latter include the myxobacteria, an order of bacteria that can aggregate to form multicellular fruiting bodies. Also, a wide variety in the types of metabolism exists. Most members are facultatively or obligately anaerobic, chemolithoautotrophic, and heterotrophic, but numerous exceptions occur. A variety of genera, which are not closely related to each other, convert energy from light through photosynthesis.

"Proteobacteria" are associated with the imbalance of microbiota of the lower reproductive tract of women. These species are associated with inflammation.

The group is defined primarily in terms of ribosomal RNA (rRNA) sequences. The "Proteobacteria" are divided into nine classes with validly published names, referred to by the Greek letters alpha through zeta, the Acidithiobacillia, Hydrogenophilalia, and Oligoflexia. These were previously regarded as subclasses of the phylum, but they are now treated as classes. 
These classes are monophyletic. The genus "Acidithiobacillus", part of the Gammaproteobacteria until it was transferred to class Acidithiobacillia in 2013, was previously regarded as paraphyletic to the "Betaproteobacteria" according to multigenome alignment studies. In 2017, the Betaproteobacteria was subject to major revisions and the class Hydrogenophilalia was created to contain the order Hydrogenophilales

Proteobacterial classes with validly published names include some prominent genera: e.g.:

Transformation, a process in which genetic material passes from bacterium to another, has been reported in at least 30 species of "Proteobacteria" distributed in the classes alpha, beta, gamma and epsilon. The best-studied "Proteobacteria" with respect to natural genetic transformation are the medically important human pathogens "Neisseria gonorrhoeae" (class beta), "Haemophilus influenzae" (class gamma) and "Helicobacter pylori" (class epsilon). Natural genetic transformation is a sexual process involving DNA transfer from one bacterial cell to another through the intervening medium and the integration of the donor sequence into the recipient genome. In pathogenic "Proteobacteria", transformation appears to serve as a DNA repair process that protects the pathogen's DNA from attack by their host's phagocytic defenses that employ oxidative free radicals.



</doc>
<doc id="24864" url="https://en.wikipedia.org/wiki?curid=24864" title="Professional wrestling">
Professional wrestling

Professional wrestling is a form of theatrical performance wherein athletic performers portray prizefighters competing in matches with predetermined, scripted outcomes. It is based on classical and "catch" wrestling, with modern additions of striking attacks, acrobatics, feats of strength, fast-moving athleticism and occasionally, improvised weaponry. The performances are all planned (if not rigidly choreographed) to maximize the entertainment value to the audience, and reduce the chances of the performers suffering real-life injuries. Professional wrestling also liberally incorporates melodrama. Much like some of the real prizefighters they imitate, the characters in professional wrestling have large egos, flamboyant personalities (often attached to a gimmick), and turbulent interpersonal relationships. These personas are generally scripted, the same as the matches. Performances mainly take place in a ring similar to the kind used in boxing (a sort of theater in the round). In the modern age of televised entertainment, many additional "backstage" scenes are also recorded to supplement the drama in the ring.

Professional wrestling in the United States began in the 19th century as a genuine competitive sport ("shoot matches", as insiders call them), but wrestlers began choreographing their matches ("worked matches") to make the matches less physically taxing, shorter in duration, and more entertaining for spectators. This allowed the wrestlers to perform more frequently and attracted larger audiences (and revenues) for promoters. This business model was very successful and was imitated in other countries, with particular success in Mexico and Japan. For a long time, those in the wrestling industry's notoriously insular community would not admit their "sport" was just theater, as the suspension of disbelief was crucial to the fans' enjoyment (and therefore, also crucial to performers' and promoters' livelihoods). Nowadays (in the United States, at least) it is normal for the wrestlers and promoters to either partially or completely acknowledge wrestling's essence as predetermined entertainment to the public. This development occurred upon promoters learning in the 1980s that the fans don't mind if the wrestlers break character "off-stage".

Originating as a popular form of entertainment in 19th-century Europe and later as a sideshow exhibition in North American traveling carnivals and vaudeville halls, professional wrestling grew into a standalone genre of entertainment with many diverse variations in cultures around the globe, and has become a billion-dollar entertainment industry. Since the 1980s, local forms have greatly declined in Europe; wrestling from North America has experienced several different periods of prominent cultural popularity during its century-and-a-half of existence and has been exported back to Europe to fill the cultural gap left by the aforementioned decline of local versions. The advent of television gave professional wrestling a new outlet, and wrestling (along with boxing) became instrumental in making pay-per-view a viable method of content delivery. In light of the growth of online video-on-demand, native professional wrestling promotions in markets all over the world have been able to circumvent traditional content-delivery and reach customers directly via social media and word-of-mouth marketing.

Show wrestling has become especially prominent in Central/North America, Japan and Europe (especially the United Kingdom). In Brazil, there was a very popular wrestling television program from the 1960s to the early 1980s called "Telecatch". High-profile figures in the sport have become celebrities or cultural icons in their native or adopted home countries.

Although professional wrestling started out as small acts in sideshows, traveling circuses and carnivals, today it is a billion-dollar industry. Revenue is drawn from ticket sales, network television broadcasts, pay-per-view broadcasts, branded merchandise and home video. Pro wrestling was instrumental in making pay-per-view a viable method of content delivery. Annual shows such as WrestleMania, Bound for Glory, Wrestle Kingdom and formerly Starrcade are among the highest-selling pay-per-view programming each year. In modern day, internet programming has been utilized by a number of companies to air web shows, internet pay per views (IPPVs) or on-demand content, helping to generate internet-related revenue earnings from the evolving World Wide Web.

Home video sales dominate the Billboard charts Recreational Sports DVD sales, with wrestling holding anywhere from 3 to 9 of the top 10 spots every week.

Due to its persistent cultural presence and to its novelty within the performing arts, wrestling constitutes a recurring topic in both academia and the media. Several documentaries have been produced looking at professional wrestling, most notably, "Beyond the Mat" directed by Barry W. Blaustein, and "" featuring wrestler Bret Hart and directed by Paul Jay. There have also been many fictional depictions of wrestling; the 2008 film "The Wrestler" received several Oscar nominations and began a career revival for star Mickey Rourke.

Currently, the largest professional wrestling company worldwide is the United States-based WWE, which bought out many smaller regional companies in the late 20th century, as well as its primary US competitors World Championship Wrestling (WCW) and Extreme Championship Wrestling (ECW) in early 2001. Other prominent professional wrestling companies worldwide include the US-based All Elite Wrestling (AEW), Impact Wrestling (formerly known as Total Nonstop Action Wrestling (TNA)), and Ring of Honor (ROH); Consejo Mundial de Lucha Libre (CMLL), and Lucha Libre AAA Worldwide (AAA) in Mexico; and the Japanese New Japan Pro-Wrestling (NJPW), All Japan Pro Wrestling (AJPW), and Pro Wrestling Noah leagues.

When talking about professional wrestling, there are two levels: the "in-show" happenings that are presented through the shows, and happenings which are outside the scope of performance (in other words, are real life) but have implications on the performance, such as performer contracts, legitimate injuries, etc. Because actual events are often co-opted by writers for incorporation into storylines for the performers, the lines are often blurred and become confused.

Special care must be taken when talking about people who perform under their own name. The actions of the character should be considered fictional events, wholly separate from the life of the performer. This is similar to other entertainers who perform with a persona that shares their own name (such as Kurt Angle and his fictional persona).

Some wrestlers would incorporate elements of their real-life personalities into their characters, even if they and their in-ring persona have different names.

Historians are unsure at what point wrestling changed from competitive catch wrestling into worked entertainment. However, documented accounts do exist: WWE Superstar Bret "Hitman" Hart recalls "a long and fascinating talk" he had in the summer of 1981 with the great Lou Thesz who told him that:
Those who participated felt that maintenance of a constant and complete illusion for all who were not involved was necessary to keep audience interest. For decades, wrestlers lived their public lives as though they were their characters.

The practice of keeping the illusion, and the various methods used to do so, came to be known as "kayfabe" within wrestling circles, or "working the marks". An entire lexicon of slang jargon and euphemism developed to allow performers to communicate without outsiders' knowledge of what was being said.

Occasionally a performer will deviate from the intended sequence of events. This is known as a shoot. Sometimes shoot-like elements are included in wrestling stories to blur the line between performance and reality. These are known as "worked shoots". However, the vast majority of events in professional wrestling are preplanned and improvised within accepted boundaries.

Gradually, the predetermined nature of professional wrestling became an open secret, as prominent figures in the wrestling business (including World Wrestling Entertainment owner Vince McMahon) began to publicly admit that wrestling was entertainment, not competition. This public reveal has garnered mixed reactions from the wrestling community, as some feel that exposure ruins the experience to the spectators as does exposure in illusionism. Despite the public admission of the theatrical nature of professional wrestling, many U.S. states still regulate professional wrestling as they do other professional competitive sports. For example, New York State still regulates "professional wrestling" through the New York State Athletic Commission (SAC). However, some states are considering removing, or have removed, professional wrestling from the purview of the state's athletic commissioners.

Professional wrestling shows can be considered a form of theater in the round, with the ring, ringside area, and entryway comprising a stage. However, there is a much more limited concept of a fourth wall than in most theatric performances, similar to pantomime involving audience participation. The audience is recognized and acknowledged by the performers as spectators to the sporting event being portrayed, and are encouraged to interact as such. This leads to a high level of audience participation; in fact, their reactions can dictate how the performance unfolds. Often, individual matches will be part of a longer story line conflict between "babyfaces" (often shortened to just "faces") and "heels". "Faces" (the "good guys") are those whose actions are intended to encourage the audience to cheer, while "heels" (the "bad guys") act to draw the spectators' ire.

Most forms of stage combat attempt to minimize all risk of pain and injury to the actors, and fans of theater typically accept that stage combat cannot look very real. But fans of professional wrestling demand a better illusion, and consequently the performers perform physical feats that often lead to real pain and injury. Many professional wrestlers over long careers develop lasting injuries and disabilities not too dissimilar from what is seen in real contact sport, and they tend to have shorter lifespans.

There is no governing authority for professional wrestling rules, although there is a general standard which has developed. Each promotion has its own variation, but all are similar enough to avoid confusion most of the time. Any rule described here is simply a standard, and may or may not correspond exactly with any given promotion's ruleset.

Due to the staged nature of wrestling, these are not actual "rules" in the sense that they would be considered in similar articles about actual sports like freestyle wrestling. Instead, the "rules" in this article are implemented and supposedly enforced for the sake of suspension of disbelief (known as kayfabe in the jargon of the business).

Matches are held between two or more sides ("corners"). Each corner may consist of one wrestler, or a team of two or more. Most team matches are governed by tag team rules (see below). Other matches are free-for-alls, with multiple combatants but no teams. In all variants, there can be only one winning team or wrestler.

Matches are held within a wrestling ring, an elevated square canvas mat with posts on each corner. A cloth apron hangs over the edges of the ring. Three horizontal ropes or cables surround the ring, suspended with turnbuckles which are connected to the posts. For safety, the ropes are padded at the turnbuckles and cushioned mats surround the floor outside the ring. Guardrails or a similar barrier enclose this area from the audience. Wrestlers are generally expected to stay within the confines of the ring, though matches sometimes end up outside the ring, and even in the audience, to add excitement.

The standard method of scoring is the "fall", which is accomplished by:
These are each explained in greater detail below. Typically, pinfalls and submissions must occur within the ring area, however there are times where it may be stipulated otherwise.

Most wrestling matches last for a set number of falls, with the first side to achieve the majority number of pinfalls, submissions, or countouts being the winner. Historically, matches were wrestled to 3 falls ("best 2 out of 3") or 5 falls ("best 3 out of 5"). The standard for modern matches is one fall. However, even though it is now standard, many announcers will explicitly say so, e.g. "The following contest is set for one fall with a 20-minute time limit." These matches are given a time limit; if not enough falls are scored by the end of the time limit, the match is declared a draw. Modern matches are generally given a 10- to 30-minute time limit for standard matches; title matches can go for up to one hour. British wrestling matches held under Admiral-Lord Mountevans rules are 2 out of 3 falls.

An alternative is a match set for a prescribed length of time, with a running tally of falls. The entrant with the most falls at the end of the time limit is declared the winner. This is usually for 20, 30 or 60 minutes, and is commonly called an Iron Man match. This type of match can be modified so that fewer types of falls are allowed.

In matches with multiple competitors, an elimination system may be used. Any wrestler who has a fall scored against them is forced out of the match, and the match continues until only one remains. However, it is much more common when more than two wrestlers are involved to simply go one fall, with the one scoring the fall, regardless of who they scored it against, being the winner. In championship matches, this means that, unlike one-on-one matches (where the champion can simply disqualify himself or get himself counted out to retain the title via the Champion<nowiki>'</nowiki>s Advantage), the champion does "not" have to be pinned or involved in the decision to lose the championship. However, heel champions often find advantages, not in Champion's Advantage, but in the use of weapons and outside interference, as these poly-sided matches tend to involve no holds barred rules.
Many modern specialty matches have been devised, with unique winning conditions. The most common of these is the ladder match. In the basic ladder match, the wrestlers or teams of wrestlers must climb a ladder to obtain a prize that is hoisted above the ring. The key to winning this match is that the wrestler or team of wrestlers must try to incapacitate each other long enough for one wrestler to climb the ladder and secure that prize for their team. As a result, the ladder can be used as a weapon. The prizes include but are not limited to any given championship belt (the traditional prize), a document granting the winner the right to a future title shot, or any document that matters to the wrestlers involved in the match (such as one granting the winner a cash prize). Another common specialty match is known as the battle royal. In a battle royal, all the wrestlers enter the ring to the point that there are 20–30 wrestlers in the ring at one time. When the match begins, the simple objective is to throw the opponent over the top rope and out of the ring with both feet on the floor to eliminate that opponent. The last wrestler standing is declared the winner. A variant on this type of match is the WWE's Royal Rumble where two wrestlers enter the ring to start the match and other wrestlers follow in 90 second intervals (previously 2 minutes) until 30–40 wrestlers have entered the ring. All other rules stay the same. For more match types, see Professional wrestling match types.

Every match must be assigned a rule keeper known as a referee, who is the final arbitrator. In multi-man lucha libre matches, two referees are used, one inside the ring and one outside.

Due to the legitimate role that referees play in wrestling of serving as liaison between the bookers backstage and the wrestlers in the ring (the role of being a final arbitrator is merely kayfabe), the referee is present, even in matches that do not at first glance appear to require a referee (such as a ladder match, as it is no holds barred, and the criteria for victory could theoretically be assessed from afar). Although their actions are also frequently scripted for dramatic effect, referees are subject to certain general rules and requirements to maintain the theatrical appearance of unbiased authority. The most basic rule is that an action must be seen by a referee to be declared for a fall or disqualification. This allows for heel characters to gain a scripted advantage by distracting or disabling the referee to perform some ostensibly illegal maneuver on their opponent. Most referees are unnamed and essentially anonymous, though some wrestling promotions, most notably in the present All Elite Wrestling, have made officials known by their names (and there are some cases where fans have called their name during matches).

Special guest referees may be used from time to time; by virtue of their celebrity status, they are often scripted to dispense with the appearance of neutrality and use their influence to unfairly influence the outcome of the match for added dramatic impact. Face special referees will often fight back against hostile heel wrestlers, particularly if the special referee is either a wrestler himself or a famous martial artist (such as Tito Ortiz at the main event at TNA Hard Justice 2005).

For heel special referees, common ways of assisting the heel wrestler to obtain victory include, but are not limited to, the following:

In some team matches, only one entrant from each team may be designated as the "legal" or "active" wrestler at any given moment. Two wrestlers must make physical contact (typically palm-to-palm) to transfer this legal status. This is known as a "tag", with the participants "tagging out" and "tagging in". Typically the wrestler who is tagging out has a 5-second count to leave the ring, whereas the one tagging in can enter the ring at any time, resulting in heels legally double-teaming a face.

The non-legal wrestlers must remain outside the ring or other legal area at all times (and avoid purposeful contact with the opposing wrestlers) or face reprimand from the referee. In most promotions, the wrestler to be tagged in must be touching the turnbuckle on his corner, or a cloth strap attached to the turnbuckle.

Some multi-wrestler matches allow for a set number of legal wrestlers, and a legal wrestler may tag out to any other wrestler, regardless of team. In these matches, the tag need not be a mutual effort, and this results in active wrestlers being tagged out against their will, or non-legal wrestlers forced to enter the battle.

Sometimes, poly-sided matches that pit every man for himself will incorporate tagging rules. Outside of kayfabe, this is done to give wrestlers a break from the action (as these matches tend to go on for long periods of time), and to make the action in the ring easier to choreograph. One of the most mainstream examples of this is the Four-Corner match, the most common type of match in the WWE before it was replaced with its equivalent Fatal Four-Way; four wrestlers, each for himself, fight in a match, but only two wrestlers can be in the match at any given time. The other two are positioned in the corner, and tags can be made between any two wrestlers.

In a Texas Tornado Tag Team match, all the competitors are legal in the match, and tagging in and out is not necessary. All matches fought under hardcore rules (such as no disqualification, no holds barred, ladder match, etc.) are all contested under "de facto" Texas Tornado rules, since the lack of ability of a referee to issue a disqualification renders any tagging requirements moot.

Regardless of rules of tagging, a wrestler cannot pin his or her own tag team partner, even if it is technically possible from the rules of the match (e.g. Texas Tornado rules, or a three-way tag team match). This is called the "Outlaw Rule" because the first team to attempt to use that (in an attempt to unfairly retain their tag team titles) was the New Age Outlaws.

To score by pinfall, a wrestler must pin both his opponent's shoulders against the mat while the referee slaps the mat three times (referred to as a "three count"). This is the most common form of defeat. The pinned wrestler must also be on his back and, if s/he is lying on his stomach, it usually does not count. A count may be started at any time that a wrestler's shoulders are down (both shoulders touching the mat), back-first and any part of the opponent's body is lying over the wrestler. This often results in pins that can easily be kicked out of, if the defensive wrestler is even slightly conscious. For example, an attacking wrestler who is half-conscious may simply drape an arm over an opponent, or a cocky wrestler may place his foot gently on the opponent's body, prompting a three-count from the referee.

Illegal pinning methods include using the ropes for leverage and hooking the opponent's clothing, which are therefore popular cheating methods for heels, unless certain stipulations make such an advantage legal. Such pins as these are rarely seen by the referee and are subsequently often used by heels and on occasion by cheating faces to win matches. Even if it is noticed, it is rare for such an attempt to result in a disqualification (see below) and instead it simply results in nullification of the pin attempt, so the heel wrestler rarely has anything to lose for trying it anyway.

Occasionally, there are instances where a pinfall is made where both wrestlers' shoulders were on the mat for the three-count. This situation will most likely lead to a draw, and in some cases a continuation of the match or a future match to determine the winner.

To score by submission, the wrestler must make his opponent give up, usually, but not necessarily, by putting him in a submission hold (e.g. figure four leg-lock, arm-lock, sleeper-hold).
A wrestler may voluntarily submit by verbally informing the referee (usually used in moves such as the Mexican Surfboard, where all four limbs are incapacitated, making tapping impossible). Also, since Ken Shamrock popularized it in 1997, a wrestler can indicate a voluntary submission by "tapping out", that is, tapping a free hand against the mat or against an opponent. Occasionally, a wrestler will reach for a rope (see rope breaks below), only to put his hand back on the mat so he can crawl towards the rope some more; this is not a submission, and the referee decides what his intent is. Submission was initially a large factor in professional wrestling, but following the decline of the submission-oriented catch-as-catch-can style from mainstream professional wrestling, the submission largely faded. Despite this, some wrestlers, such as Chris Jericho, Ric Flair, Bret Hart, Kurt Angle, Ken Shamrock, Dean Malenko, Chris Benoit, and Tazz, became famous for winning matches via submission. A wrestler with a signature submission technique is portrayed as better at applying the hold, making it more painful or more difficult to get out of than others who use it, or can be falsely credited as inventing the hold (such as when Tazz popularized the kata ha jime judo choke in pro wrestling as the "Tazzmission").

Since all contact between the wrestlers must cease if any part of the body is touching, or underneath, the ropes, many wrestlers will attempt to break submission holds by deliberately grabbing the bottom ropes. This is called a "rope break", and it is one of the most common ways to break a submission hold. Most holds leave an arm or leg free, so that the person can tap out if he wants. Instead, he uses these free limbs to either grab one of the ring ropes (the bottom one is the most common, as it is nearest the wrestlers, though other ropes sometimes are used for standing holds such as Chris Masters' Master Lock) or drape his foot across, or underneath one. Once this has been accomplished, and the accomplishment is witnessed by the referee, the referee will demand that the offending wrestler break the hold, and start counting to five if the wrestler does not. If the referee reaches the count of five, and the wrestler still does not break the hold, he is disqualified.

If a manager decides that his client wrestler should tap out, but cannot convince the wrestler himself to do so, he may "throw in the towel" (by literally taking a gym towel and hurling it into the ring where the referee can see it). This is the same as a submission, as in kayfabe the manager is considered the wrestlers agent and therefore authorized to make formal decisions (such as forfeiting a match) on the client's behalf.

Passing out in a submission hold constitutes a loss by knockout. To determine if a wrestler has passed out in WWE, the referee usually picks up and drops his hand. If it drops to the mat or floor three consecutive times without the wrestler having the strength to hold it up, the wrestler is considered to have passed out. At one point this was largely ignored. However, the rule is now much more commonly observed for safety reasons. If the wrestler has passed out, the opponent then scores by submission.

A wrestler can also win by knockout if he does not resort to submission holds, but stills pummels his opponent to the point that he is completely out cold. To check for a knockout in this manner a referee would wave his hand in front of the wrestlers' face and, if the wrestler does not react in any way, the referee would award the victory to the other wrestler.

A countout (alternatively "count-out" or "count out") happens when a wrestler is out of the ring long enough for the referee to count to ten (twenty in some promotions) and thus disqualified. The count is broken and restarted when a wrestler in the ring exits the ring. Playing into this, some wrestlers would "milk" the count by sliding in the ring and immediately sliding back out. As he was technically inside the ring for a split second before exiting again, it is sufficient to restart the count. This is often referred to by commentators as "breaking the count". Heels often use this tactic in order to buy themselves more time to catch their breath, or to attempt to frustrate their babyface opponents.

If all the active wrestlers in a match are down inside the ring at the same time, the referee would begin a count (usually ten seconds, twenty in Japan). If nobody rises to their feet by the end of the count, the match is ruled a draw. Any participant who stands up in time would end the count for everyone else, while in a Last Man Standing match this form of a countout is the only way that the match can end, so the referee would count when one or more wrestlers are down and one wrestler standing up before the 10-count does not stop the count for another wrestler who is still down.

In some promotions (and most major modern ones), Championships cannot change hands via a countout, unless the on-screen authority declares it for at least one match, although in others, championships may change hands via countout. Heels are known to take advantage of this and will intentionally get counted out when facing difficult opponents, especially when defending championships.

Disqualification (sometimes abbreviated as "DQ") occurs when a wrestler violates the match's rules, thus losing automatically. Although a countout can technically be considered a disqualification (as it is, for all intents and purposes, an automatic loss suffered as a result of violating a match rule), the two concepts are often distinct in wrestling. A no disqualification match can still end by countout (although this is rare). Typically, a match must be declared a "no holds barred" match, a "street fight" or some other term, in order for both disqualifications and countouts to be waived.

Disqualification from a match is called for a number of reasons:

In practice, not all rule violations will result in a disqualification as the referee may use his own judgement and is not obligated to stop the match. Usually, the only offenses that the referee will see and "immediately" disqualify the match on (as opposed to having multiple offenses) are low blows, weapon usage, interference, or assaulting the referee. In WWE, a referee must see the violation with his own eyes to rule that the match end in a disqualification (simply watching the video tape is not usually enough) and the referee's ruling is almost always final, although "dusty finishes" (named after, and made famous by, Dusty Rhodes) will often result in the referee's decision being overturned. It is not uncommon for the referees themselves to get knocked out during a match, which is commonly referred to by the term "ref bump". While the referee remains "unconscious", wrestlers are free to violate rules until he is revived or replaced. In some cases, a referee might disqualify a person under the presumption that it was that wrestler who knocked him out; most referee knockouts are arranged to allow a wrestler, usually a heel, to gain an advantage. For example, a wrestler may get whipped into a referee at a slower speed, knocking the ref down for short amount of time; during that interim period, one wrestler may pin his opponent for a three-count and would have won the match but for the referee being down (sometimes, another referee will sprint to the ring from backstage to attempt to make the count, but by then, the other wrestler has had enough time to kick out on his own accord). In most promotions, a championship title cannot normally change hands via disqualification; this rule is explicitly enforced in a title match under special circumstances.

If all participants in a match continue to breach the referee's instructions, the match may end in a double disqualification, where both wrestlers or teams (in a tag team match) have been disqualified. The match is essentially nullified, and called a draw or in some cases a restart or the same match being held at a pay-per-view or next night's show. Sometimes, however, if this happens in a match to determine the challenger for a heel champion's title, the champion is forced to face both opponents simultaneously for the title. Usually, the double disqualification is caused by the heel wrestler's associates in a match between two face wrestlers to determine his opponent.

Although extremely rare, a match can end in a forfeit if the opponent either does not show up for the match, or shows up but refuses to compete. Although a championship usually cannot change hands except by pinfall or submission, a forfeit victory is enough to crown a new champion. The most famous example of this happened on the December 8, 1997 episode of "Raw is War", when Stone Cold Steve Austin handed the WWE Intercontinental Championship to The Rock after refusing to defend the title.

Forfeit victories are extremely rare in wrestling. When a pay-per-view match is booked and one wrestler is unable to make it for one reason or another, it is usually customary to insert a last minute replacement rather than award a wrestler a victory by forfeit. Forfeit victories are almost always reserved for when the story the promotion is telling specifically requires such an ending. In addition to the aforementioned moment between Steve Austin and The Rock, other instance of this happening was in March 2009, when Triple H decided not to show up for a handicap match against Cody Rhodes and Ted Dibiase Jr., instead opting to attack Randy Orton in his own home.

Despite being, statistically, an extremely rare occurrence, Charles Wright is one wrestler who is famous for turning forfeit victories into his own gimmick. During the late 1990s, Wright called himself "The Godfather" and portrayed the gimmick of a pimp. He would often bring multiple women, who he referred to as "hos," to the ring with him, and would offer the sexual services of these women to his opponents in exchange for them forfeiting their matches against him.

A professional wrestling match can end in a draw. A draw occurs if both opponents are simultaneously disqualified (as via countout or if the referee loses complete control of the match and both opponents attack each other with no regard to being in a match, like Brock Lesnar vs. Undertaker at 2002 Unforgiven), neither opponent is able to answer a ten-count, or both opponents simultaneously win the match. The latter can occur if, for example, one opponent's shoulders touch the mat while maintaining a submission hold against another opponent. If the opponent in the hold begins to tap out at the same time a referee counts to three for pinning the opponent delivering the hold, both opponents have legally achieved scoring conditions simultaneously. Traditionally, a championship may not change hands in the event of a draw (though it may become vacant), though some promotions such as Total Nonstop Action Wrestling have endorsed rules where the champion may lose a title by disqualification. A variant of the draw is the time-limit draw, where the match does not have a winner by a specified time period (a one-hour draw, which was once common, is known in wrestling circles as a "Broadway").

Also if two wrestlers have been given a disqualification by either the referee or the chairman, this is a no contest and if there is a title on the line the champion keeps the championship.

A wrestling match may be declared a no contest if the winning conditions are unable to occur. This can be due to excessive interference, loss of referee's control over the match, one or more participants sustaining debilitating injury not caused by the opponent, or the inability of a scheduled match to even begin. A no contest is a state separate and distinct from a draw — a draw indicates winning conditions were met. Although the terms are sometimes used interchangeably in practice, this usage is technically incorrect.

While each wrestling match is ostensibly a competition of athletics and strategy, the goal from a business standpoint is to excite and entertain the audience. Although the competition is staged, dramatic emphasis draws out the most intense reaction. Heightened interest results in higher attendance, increased ticket sales, higher ratings on television broadcasts (greater ad revenue), higher pay-per-view buyrates, and sales of branded merchandise and recorded video footage. All of these contribute to the profit of the promotion company.

In Latin America and English-speaking countries, most wrestlers (and other on-stage performers) portray character roles, sometimes with personalities wildly different from their own. These personalities are a gimmick intended to heighten interest in a wrestler without regard to athletic ability. Some can be unrealistic and cartoon-like (such as Doink the Clown), while others carry more verisimilitude (such as Chris Jericho, The Rock, John Cena, Steve Austin, and CM Punk). In lucha libre, many characters wear masks, adopting a secret identity akin to a superhero, a near-sacred tradition.

An individual wrestler may use his real name, or a minor variation of it, for much of his career, such as Bret Hart, John Cena and Randy Orton. Others can keep one ring name for their entire career (Shawn Michaels, CM Punk and Ricky Steamboat), or may change from time to time to better suit the demands of the audience or company. Sometimes a character is owned and trademarked by the company, forcing the wrestler to find a new one when he leaves (although a simple typeset change, such as changing Rhyno to Rhino, can get around this), and sometimes a character is owned by the wrestler. Sometimes, a wrestler may change his legal name to obtain ownership of his ring name (Andrew Martin and Warrior). Many wrestlers (such as The Rock and The Undertaker) are strongly identified with their character, even responding to the name in public or between friends. It's actually considered proper decorum for fellow wrestlers to refer to each other by their stage names/characters rather than their birth/legal names, unless otherwise introduced. A character can become so popular that it appears in other media (Hulk Hogan and El Santo) or even gives the performer enough visibility to enter politics (Antonio Inoki and Jesse Ventura).

Typically, matches are staged between a protagonist (historically an audience favorite, known as a babyface, or "the good guy") and an antagonist (historically a villain with arrogance, a tendency to break rules, or other unlikable qualities, called a heel). In recent years, however, antiheroes have also become prominent in professional wrestling. There is also a less common role of a "tweener", who is neither fully face nor fully heel yet able to play either role effectively (case in point, Samoa Joe during his first run in TNA Wrestling from June 2005 to November 2006).

At times, a character may "turn", altering their face/heel alignment. This may be an abrupt, surprising event, or it may slowly build over time. It is almost always accomplished with a markable change in behavior. Some turns become defining points in a career, as when Hulk Hogan turned heel after being a top face for over a decade. Others may have no noticeable effect on the character's status. If a character repeatedly switches between face and heel, this lessens the effect of such turns, and may result in apathy from the audience. Vince McMahon is a good example of having more heel and face turns than anyone in WWE history.

As with personae in general, a character's face or heel alignment may change with time, or remain constant over its lifetime (the most famous example of the latter is Ricky Steamboat, a WWE Hall of Famer who remained a babyface throughout his entire career). Sometimes a character's heel turn will become so popular that eventually the audience response will alter the character's heel-face cycle to the point where the heel persona will, in practice, become a face persona, and what was previously the face persona, will turn into the heel persona, such as when Dwayne Johnson first began using "The Rock" persona as a heel character, as opposed to his original "Rocky Maivia" babyface persona. Another legendary example is Stone Cold Steve Austin, who was originally booked as a heel, with such mannerisms as drinking on the job, using profanity, breaking company property, and even breaking into people's private homes. However, much to WWF's surprise, the fans got such a charge out of Austin's antics that he effectively became one of the greatest antiheroes in the history of the business. He, along with the stable of D-Generation X, is generally credited with ushering in the Attitude Era of WWF programming.

While real exhibition matches are now not uncommon, most matches tell a story analogous to an episode of a serial drama: The face will from time to time win (triumph) or from time to time lose (tragedy), and longer story arcs can result from a couple of matches. Since most promotions have a championship title, opposition for the championship is a frequent impetus for stories. Also, whatever from a character's own hair to his job with the advertising can be wagered in a match.

Some matches are designed to further the story of only one participant. It could be intended to portray an unstoppable force, a lucky underdog, a sore loser, or any other characterization. Sometimes non-wrestling vignettes are shown to enhance a character's image without the need for matches.

Other stories result from a natural rivalry. Outside of performance, these are referred to as feuds. A feud can exist between any number of participants and can last from a few days to decades. The feud between Ric Flair and Ricky Steamboat lasted from the late 1970s into the early 1990s and allegedly spanned over two thousand matches (although most of those matches were mere dark matches). The career-spanning history between characters Mike Awesome and Masato Tanaka is another example of a long-running feud, as is the case of Steve Austin vs. Vince McMahon, one of the most lucrative feuds in the World Wrestling Federation during 1998 and 1999.

In theory, the longer a feud is built up, the more audience interest (aka heat) lasts. The main event of a wrestling show is generally the most heated. Commonly, a heel will hold the upper hand over a face until a final showdown, heightening dramatic tension as the face's fans desire to see him win.

Throughout the history of professional wrestling, many other elements of media have been utilized in professional wrestling storytelling: pre- and post-match interviews, "backstage" skits, positions of authority and worked behind-the-scenes feuds, division rankings (typically the #1-contendership spot), contracts, lotteries, news stories on websites, and in recent years social media.

Also, anything that can be used as an element of drama can exist in professional wrestling stories: romantic relationships (including love triangles and marriage), racism, classism, nepotism, favoritism, corporate corruption, family bonds, personal histories, grudges, theft, cheating, assault, betrayal, bribery, seduction, stalking, confidence tricks, extortion, blackmail, substance abuse, self-doubt, self-sacrifice; even kidnapping, sexual fetishism, necrophilia, misogyny, rape and death have been portrayed in wrestling. Some promotions have included supernatural elements such as magic, curses, the undead and Satanic imagery (most notably the Undertaker and his Ministry of Darkness, a stable that regularly performed evil rituals and human sacrifice in Satanic-like worship of a hidden power figure). Celebrities would also be involved in storylines.

Commentators have become important in communicating the relevance of the characters' actions to the story at hand, filling in past details and pointing out subtle actions that may otherwise go unnoticed.

A main part of the story-telling part of wrestling is a promo, short for promotional interview. Promos are performed, or "cut", in wrestling jargon, for a variety of reasons, including to heighten interest in a wrestler, or to hype an upcoming match.

Since the crowd is often too loud or the venue too large for promos to be heard naturally, wrestlers will use amplification when speaking in the ring. Unlike most Hollywood acting, large and highly visible handheld microphones are typically used and wrestlers often speak directly to the audience.

Professional wrestling mimics the structure of title match combat sports. Participants compete for a championship and must defend it after winning it. These titles are represented physically by a title belt that can be worn by the champion. In the case of team wrestling, there is a title belt for each member of the team.

Almost all professional wrestling promotions have one major title, and some have more. Championships are designated by divisions of weight, height, gender, wrestling style and other qualifications.

Typically, each promotion only recognizes the "legitimacy" of their own titles, although cross-promotion does happen. When one promotion absorbs or purchases another, the titles from the defunct promotion may continue to be defended in the new promotion or be decommissioned.

Behind the scenes, the bookers in a company will place the title on the most accomplished performer, or those the bookers believe will generate fan interest in terms of event attendance and television viewership. Lower ranked titles may also be used on the performers who show potential, thus allowing them greater exposure to the audience. However other circumstances may also determine the use of a championship. A combination of a championship's lineage, the caliber of performers as champion, and the frequency and manner of title changes, dictates the audience's perception of the title's quality, significance and reputation.

A wrestler's championship accomplishments can be central to their career, becoming a measure of their performance ability and drawing power. In general, a wrestler with multiple title reigns or an extended title reign is indicative of a wrestler's ability to maintain audience interest or a wrestler's ability to perform in the ring. As such, the most accomplished or decorated wrestlers tend to be revered as legends due to the amount of title reigns they hold. American wrestler Ric Flair has had multiple world heavyweight championship reigns spanning over three decades. Japanese wrestler Último Dragón once held and defended a record 10 titles simultaneously.

Often a match will take place under additional rules, usually serving as a special attraction or a climactic point in a feud or storyline. Sometimes this will be the culmination of an entire feud, ending it for the immediate future (known as a blowoff match).

Perhaps the most well-known non-standard match is the cage match, in which the ring is surrounded by a fence or similar metal structure, with the express intention of preventing escape or outside interference—and with the added bonus of the cage being a potentially brutal weapon or platform for launching attacks. The WWE has another provision where a standard cage match can end with one wrestler or wrestling team escaping the cage through the door or over the top.

Another example is the WWE's Royal Rumble match, which involves thirty participants in a random and unknown order. The Rumble match is itself a spectacle in that it is a once-yearly event with multiple participants, including individuals who might not interact otherwise. It also serves as a catalyst for the company's ongoing feuds, as well as a springboard for new storylines.

While the wrestling matches themselves are the primary focus of professional wrestling, a key dramatic element of the business can be entrances of the wrestlers to the arena and ring. It is typical for a wrestler to get their biggest crowd reaction (or "pop") for their ring entrance, rather than for anything they do in the wrestling match itself, especially if former main event stars are returning to a promotion after a long absence.

All notable wrestlers now enter the ring accompanied by music, and regularly add other elements to their entrance. The music played during the ring entrance will usually mirror the wrestler's personality. Many wrestlers, particularly in America, have music and lyrics specially written for their ring entrance. While invented long before, the practice of including music with the entrance gained rapid popularity during the 1980s, largely as a result of the huge success of Hulk Hogan and the WWF, and their Rock 'n' Wrestling Connection. When a match is won, the victor's theme music is usually also played in celebration.

Because wrestling is predetermined, a wrestler's entrance music will play as they enter the arena, even if they are, in kayfabe, not supposed to be there. For example, in 2012 through 2014, The Shield was a trio of wrestlers who were (in kayfabe) not at the time under contract with WWE (hence their gimmick of entering the ring through the crowd), but they still had entrance music which was played whenever they entered the arena, despite the fact that they were kayfabe invaders.

With the introduction of the Titantron entrance screen in 1997, WWF/WWE wrestlers also had entrance videos made that would play along with their entrance music.

Other dramatic elements of a ring entrance can include:
Another method of entry involves descending from the ceiling with a Zip-line or rappel line and stunt harness. This has been done by Shawn Michaels at WrestleMania XII, by Sting many times in WCW and TNA, gained major controversy over its role in the death of wrestler Owen Hart at Over the Edge.

Special ring entrances are also developed for big occasions, most notably the WrestleMania event. For example, WrestleMania III and VI both saw all wrestlers enter the arena on motorized miniature wrestling rings. Live bands are sometimes hired to perform live entrance music at special events. John Cena and Triple H are particularly notable in recent years for their highly theatrical entrances at WrestleMania.

The women's division of professional wrestling has maintained a recognized world champion since 1937, when Mildred Burke won the original World Women's title. She then formed the World Women's Wrestling Association in the early 1950s and recognized herself as the first champion, although the championship would be vacated upon her retirement in 1956. The NWA however, ceased to acknowledge Burke as "their" Women's World champion in 1954, and instead acknowledged June Byers as champion after a controversial finish to a high-profile match between Burke and Byers that year. Upon Byers' retirement in 1964, The Fabulous Moolah, who won a junior heavyweight version of the NWA World Women's Championship (the predecessor to the WWE Women's Championship) in a tournament back in 1958, was recognized by most NWA promoters as champion by default.

For most of its history, men and women would rarely compete against each other in professional wrestling, as it was deemed to be unfair and unchivalrous. Andy Kaufman used this to gain notoriety when he created an Intergender Championship and declared it open to any female challenger. This led to a long (worked) feud with Jerry Lawler.

In the 1980s, mixed tag team matches began to take place, with a male and female on each team and a rule stating that each wrestler could only attack the opponent of the same gender. If a tag was made, the other team had to automatically switch their legal wrestler as well. Despite these restrictions, many mixed tag matches do feature some physical interaction between participants of different genders. For example, a heel may take a cheap shot at the female wrestler of the opposing team to draw a negative crowd reaction. In lucha libre, cheap-shots and male-female attacks are not uncommon.

Intergender singles bouts were first fought on a national level in the 1990s. This began with Luna Vachon, who faced men in ECW and WWF. Later, Chyna became the first female to hold a belt that was not exclusive to women when she won the WWF Intercontinental Championship. While it is a rare feat in WWE, in TNA, ODB participates in singles intergender matches. Also, ODB's kayfabe husband and tag team partner Eric Young held the Knockouts tag team titles for a record 478 days before it was stripped by Brooke Hogan because Young was a male.

Midget wrestling can be traced to professional wrestling's carnival and vaudeville origins. In recent years, the popularity and prevalence of midgets in wrestling has greatly decreased due to wrestling companies depriving midget divisions of storyline or feud. However, WWE has made a few attempts to enter this market with their "minis" in the 1990s and the "junior's league" as recent as 2006. It is still a popular form of entertainment in Mexican wrestling, mostly as a "sideshow".

Some wrestlers may have their own specific "mini me", like Mascarita Sagrada, Alebrije has Quije, etc. There are also cases in which midgets can become valets for a wrestler, and even get physically involved in matches, like Alushe, who often accompanies Tinieblas, or KeMonito, who is portrayed as Consejo Mundial de Lucha Libre's mascot and is also a valet for Mistico. Dave Finlay was often aided in his matches by a midget known mainly as Hornswoggle while in WWE, who hid under the ring and gave a shillelagh to Finlay to use on his opponent. Finlay also occasionally threw him at his opponent(s). Hornswoggle has also been given a run with the WWE Cruiserweight Championship and feuded with D-X in 2009.

The U.S., Japan and Mexico are three countries where there is a huge market and high popularity for professional wrestling. But the styles of professional wrestling are different, given their independent development for a long period.

Professional wrestling in the U.S. tends to have a heavy focus on story building and the establishment of characters (and their personalities). There is a story for each match, and even a longer story for successive matches. The stories usually contain characters like faces and heels, and less often antiheroes and tweeners. It is a "triumph" if the face wins, while it is a "tragedy" if the heel wins. The characters usually have strong and sharp personalities. The opposition between faces and heels is very intense in the story, and the heels may even attack the faces during TV interviews. The relationship between different characters can also be very complex.
Although professional wrestling in Mexico (Lucha libre) also has stories and characters, they are less emphasized. Wrestlers in Mexico are traditionally more agile and perform more aerial maneuvers than professional wrestlers in the U.S. who, more often, rely on power moves and strikes to subdue their opponents. The difference in styles is due to the independent evolution of the sport in Mexico beginning in the 1930s and the fact that wrestlers in the cruiserweight division () are often the most popular wrestlers in Mexican lucha libre. Wrestlers often execute high flying moves characteristic of lucha libre by utilizing the wrestling ring's ropes to catapult themselves towards their opponents, using intricate combinations in rapid-fire succession, and applying complex submission holds. Lucha libre is also known for its tag team wrestling matches, in which the teams are often made up of three members, instead of two as is common in the U.S.

The style of Japanese professional wrestling (puroresu) is again different. With its origins in traditional American style of wrestling and still being under the same genre, it has become an entity in itself. Despite the similarity to its American counterpart in that the outcome of the matches remains predetermined, the phenomena are different in the form of the psychology and presentation of the sport. In most of the largest promotions, such as New Japan Pro-Wrestling, All Japan Pro Wrestling and Pro Wrestling Noah, it is treated as a full contact combat sport as it mixes hard hitting martial arts strikes with shoot style submission holds, while in the U.S. it is rather more regarded as an entertainment show. Wrestlers incorporate kicks and strikes from martial arts disciplines, and a strong emphasis is placed on submission wrestling, and unlike the use of involved storylines in the U.S., they are not as intricate in Japan, more emphasis is placed on the concept of "fighting spirit", meaning the wrestlers display of physical and mental stamina are valued a lot more than theatrics. Many of Japan's wrestlers including top stars such as Shinya Hashimoto, Riki Chōshū and Keiji Mutoh came from a legitimate martial arts background and many Japanese wrestlers in the 1990s began to pursue careers in mixed martial arts organizations such as Pancrase and Shooto which at the time retained the original look of puroresu but were actual competitions. Other companies, such as Michinoku Pro Wrestling and Dragon Gate, wrestle in a style similar to Mexican companies like AAA and CMLL. This is known as "Lucharesu".

Professional wrestling has developed its own cultures, both internal and external.

Those involved in producing professional wrestling have developed a kind of global fraternity, with familial bonds, shared language and passed-down traditions. New performers are expected to "pay their dues" for a few years by working in lower-profile promotions and working as ring crew before working their way upward. The permanent rosters of most promotions develop a backstage pecking order, with veterans mediating conflicts and mentoring younger wrestlers. For many decades (and still to a lesser extent today) performers were expected to keep the illusions of wrestling's legitimacy alive even while not performing, essentially acting in character any time they were in public. Some veterans speak of a "sickness" among wrestling performers, an inexplicable pull to remain active in the wrestling world despite the devastating effects the job can have on one's life and health.

Fans of professional wrestling have their own subculture, comparable to those of science fiction, video games, or comic books. Those who are interested in the backstage occurrences, future storylines and reasonings behind company decisions read newsletters written by journalists with inside ties to the wrestling industry. These "rags" or "dirt sheets" have expanded into the Internet, where their information can be dispensed on an up-to-the-minute basis. Some have expanded into radio shows.

Some fans enjoy a pastime of collecting tapes of wrestling shows from specific companies, of certain wrestlers, or of specific genres. The internet has given fans exposure to worldwide variations of wrestling they would be unable to see otherwise. Since the 1990s, many companies have been founded which deal primarily in wrestling footage. When the WWE purchased both WCW and ECW in 2001, they also obtained the entire past video libraries of both productions and have released many past matches online and on home video.

Like some other sports, fantasy leagues have developed around professional wrestling. Some take this concept further by creating E-feds (electronic federations), where a user can create their own fictional wrestling character, and role-playing storylines with other users, leading to scheduled "shows" where match results are determined by the organizers, usually based on a combination of the characters' statistics and the players' roleplaying aptitude, sometimes with audience voting.

From the first established world championship, the top professional wrestlers have garnered fame within mainstream society. Each successive generation has produced a number of wrestlers who extend their careers into the realms of music, acting, writing, business, politics or public speaking, and are known to those who are unfamiliar with wrestling in general. Conversely, celebrities from other sports or general pop culture also become involved with wrestling for brief periods of time. A prime example of this is The Rock 'n' Wrestling Connection of the 1980s, which combined wrestling with MTV.
Professional wrestling is often portrayed within other works using parody, and its general elements have become familiar tropes and memes in American culture.

Some terminology originating in professional wrestling has found its way into the common vernacular. Phrases such as "body slam", "sleeper hold" and "tag team" are used by those who do not follow professional wrestling. The term "smackdown", popularized by The Rock and "SmackDown!" in the 1990s, has been included in Merriam-Webster dictionaries since 2007.

Many television shows and films have been produced which portray in-character professional wrestlers as protagonists, such as "Ready to Rumble", "¡Mucha Lucha!", "Nacho Libre", and the Santo film series. At least two stage plays set in the world of pro wrestling have been produced: "The Baron" is a comedy that retells the life of an actual performer known as Baron von Raschke. "From Parts Unknown..." is an award-nominated Canadian drama about the rise and fall of a fictional wrestler. The 2009 "South Park" episode "W.T.F." played on the soap operatic elements of professional wrestling. One of the lead characters on the Disney Channel series "Kim Possible" was a huge fan of pro wrestling and actually featured it on an episode (with two former WWE wrestlers voicing the two fictitious wrestlers featured in the episode). The 2008 film "The Wrestler", about a washed-up professional wrestler, garnered several Oscar nominations.

The 1950 film noir "Night and the City", directed by Jules Dassin and starring Richard Widmark and Gene Tierney, told the story of a promoter in London trying to make it big, and featured a match involving real professional wrestler Stanislaus Zbyszko.

Wrestling has also gained a major following on YouTube with WWE being the being the most subscribed to Wrestling channel and sixth most subscribed to channel in the world. AEW also hosts it's AEW Dark show on YouTube.

With its growing popularity, professional wrestling has attracted attention as a subject of serious academic study and journalistic criticism. Many courses, theses, essays and dissertations have analyzed wrestling's conventions, content, and its role in modern society. It is often included as part of studies on theatre, sociology, performance, and media. The Massachusetts Institute of Technology developed a course of study on the cultural significance of professional wrestling, and anthropologist Heather Levi has written an ethnography about the culture of lucha libre in Mexico

This was not always the case. In the early 20th century, once it became apparent that the "sport" was worked, pro wrestling was looked down on as a cheap entertainment for the uneducated working class, an attitude that still exists to varying degrees today. The French theorist Roland Barthes was among the first to propose that wrestling was worthy of deeper analysis, in his essay "The World of Wrestling" from his book "Mythologies", first published in 1957. Barthes argued that it should be looked at not as a scamming of the ignorant, but as spectacle; a mode of theatric performance for a willing, if bloodthirsty, audience. Wrestling is described as performed art which demands an immediate reading of the juxtaposed meanings. The logical conclusion is given least importance over the theatrical performers of the wrestlers and the referee. According to Barthes, the function of a wrestler is not to win: it is to go exactly through the motions which are expected of him and to give the audience a theatrical spectacle. This work is considered a foundation of all later study.

While pro wrestling is often described simplistically as a "soap opera for males", it has also been cited as filling the role of past forms of literature and theatre; a of classical heroics, commedia dell'arte, revenge tragedies, morality plays, and burlesque. The characters and storylines portrayed by a successful promotion are seen to reflect the current mood, attitudes, and concerns of that promotion's society and can in turn influence those same things. Wrestling's high levels of violence and masculinity make it a vicarious outlet for aggression during peacetime.

Documentary filmmakers have studied the lives of wrestlers and the effects the profession has on them and their families. The 1999 theatrical documentary "Beyond the Mat" focused on Terry Funk, a wrestler nearing retirement; Mick Foley, a wrestler within his prime; Jake Roberts, a former star fallen from grace; and a school of wrestling student trying to break into the business. The 2005 release "" chronicled the development of women's wrestling throughout the 20th century. Pro wrestling has been featured several times on HBO's "Real Sports with Bryant Gumbel". MTV's documentary series "True Life" featured two episodes titled "I'm a Professional Wrestler" and "I Want to Be a Professional Wrestler." Other documentaries have been produced by The Learning Channel ("The Secret World of Professional Wrestling") and A&E (""). "Bloodstained Memoirs" explored the careers of several pro wrestlers, including Chris Jericho, Rob Van Dam and Roddy Piper.

Although professional wrestling is choreographed, there is a high chance of injury, and even death. Strikes are often stiff, especially in Japan and in independent wrestling promotions such as Combat Zone Wrestling and Ring of Honor. The ring is often made out of timber planks. There have been many brutal accidents, hits and injuries. Many of the injuries that occur in pro wrestling are shoulders, knee, back, neck, and rib injuries. Professional wrestler Davey Richards said in 2015, "We train to take damage, we know we are going to take damage and we accept that."

In April 2014, less than 25 years after the 1990 WrestleMania VI, one-third of its 36 competitors had died, including André the Giant and main event winner The Ultimate Warrior, with none of the deceased having reached the age of 64.









</doc>
<doc id="24868" url="https://en.wikipedia.org/wiki?curid=24868" title="Pauli matrices">
Pauli matrices

In mathematical physics and mathematics, the Pauli matrices are a set of three complex matrices which are Hermitian and unitary. Usually indicated by the Greek letter sigma (), they are occasionally denoted by tau () when used in connection with isospin symmetries. They are

These matrices are named after the physicist Wolfgang Pauli. In quantum mechanics, they occur in the Pauli equation which takes into account the interaction of the spin of a particle with an external electromagnetic field.

Each Pauli matrix is Hermitian, and together with the identity matrix (sometimes considered as the zeroth Pauli matrix ), the Pauli matrices form a basis for the real vector space of Hermitian matrices. 
This means that any Hermitian matrix can be written in a unique way as a linear combination of Pauli matrices, with all coefficients being real numbers.

Hermitian operators represent observables in quantum mechanics, so the Pauli matrices span the space of observables of the -dimensional complex Hilbert space. In the context of Pauli's work, represents the observable corresponding to spin along the th coordinate axis in three-dimensional Euclidean space .

The Pauli matrices (after multiplication by to make them anti-Hermitian) also generate transformations in the sense of Lie algebras: the matrices form a basis for the real Lie algebra formula_2, which exponentiates to the special unitary group SU(2). The algebra generated by the three matrices is isomorphic to the Clifford algebra of , and the (unital associative) algebra generated by is isomorphic to that of quaternions.

All three of the Pauli matrices can be compacted into a single expression:

where is the imaginary unit, and is the Kronecker delta, which equals +1 if and 0 otherwise. This expression is useful for "selecting" any one of the matrices numerically by substituting values of , in turn useful when any of the matrices (but no particular one) is to be used in algebraic manipulations.

The matrices are involutory:

where is the identity matrix.

The determinants and traces of the Pauli matrices are:

From which, we can deduce that the eigenvalues of each are .

With the inclusion of the identity matrix, (sometimes denoted ), the Pauli matrices form an orthogonal basis (in the sense of Hilbert–Schmidt) of the real Hilbert space of complex Hermitian matrices, formula_6, and the complex Hilbert space of all matrices, formula_7.

Each of the (Hermitian) Pauli matrices has two eigenvalues, and . Using a convention in which prior to normalization, the 1 is placed into the top and bottom positions of the + and – wavefunctions respectively, the corresponding normalized eigenvectors are:

An advantage of using this convention is that the + and – wavefunctions may be related to one another, using the Pauli matrices themselves, by formula_9, formula_10 and formula_10.

The Pauli vector is defined by

and provides a mapping mechanism from a vector basis to a Pauli matrix basis as follows,

using the summation convention. Further,

its eigenvalues being formula_15, and moreover (see completeness, below) 

Its normalized eigenvectors are 

The Pauli matrices obey the following commutation relations:

and anticommutation relations:

where the structure constant is the Levi-Civita symbol, Einstein summation notation is used, is the Kronecker delta, and is the identity matrix.

For example,

Pauli vectors elegantly map these commutation and anticommutation relations to corresponding vector products. Adding the commutator to the anticommutator gives
so that, 
Contracting each side of the equation with components of two -vectors and (which commute with the Pauli matrices, i.e., for each matrix and vector component (and likewise with ), and relabeling indices , to prevent notational conflicts, yields

Finally, translating the index notation for the dot product and cross product results in 
If formula_23 is identified with the pseudoscalar formula_24 then the right hand side becomes formula_25 which is also the definition for the product of two vectors in geometric algebra.

Following traces can be derived using the commutation and anticommutation relations.

If the matrix formula_27 is thrown into the mix, these relationships become

where greek indices formula_29 and formula_30 assume values from formula_31 and the notation formula_32 is used to denote the sum over the cyclic permutation of the included indices.

For 

one has, for even powers, formula_34

which can be shown first for the formula_36 case using the anticommutation relations. For convenience, the case formula_37 is taken to be formula_38 by convention.

For odd powers, formula_39

Matrix exponentiating, and using the Taylor series for sine and cosine,

In the last line, the first sum is the cosine, while the second sum is the sine; so, finally,
which is analogous to Euler's formula, extended to quaternions.

Note that

while the determinant of the exponential itself is just , which makes it the generic group element of SU(2).

A more abstract version of formula for a general matrix can be found in the article on matrix exponentials. A general version of for an analytic (at "a" and −"a") function is provided by application of Sylvester's formula,
A straightforward application of formula provides a parameterization of the composition law of the group . One may directly solve for in 

which specifies the generic group multiplication, where, manifestly, 

the spherical law of cosines. Given , then, 

Consequently, the composite rotation parameters in this group element (a closed form of the respective BCH expansion in this case) simply amount to 

It is also straightforward to likewise work out the adjoint action on the Pauli vector, namely rotation effectively by double the angle ,

An alternative notation that is commonly used for the Pauli matrices is to write the vector index in the superscript, and the matrix indices as subscripts, so that the element in row and column of the -th Pauli matrix is .

In this notation, the completeness relation for the Pauli matrices can be written
As noted above, it is common to denote the 2 × 2 unit matrix by "σ", so "σ" = "δ". The completeness relation can alternatively be expressed as

The fact that any 2 × 2 complex Hermitian matrices can be expressed in terms of the identity matrix and the Pauli matrices also leads to the Bloch sphere representation of 2 × 2 mixed states' density matrix, (2 × 2 positive semidefinite matrices with unit trace. This can be seen by first expressing an arbitrary Hermitian matrix as a real linear combination of as above, and then imposing the positive-semidefinite and trace conditions. 

For a pure state, in polar coordinates, formula_55, the idempotent density matrix 
acts on the state eigenvector formula_57 with eigenvalue 1, hence like a projection operator for it.

Let be the transposition (also known as a permutation) between two spins and living in the tensor product space ,

This operator can also be written more explicitly as Dirac's spin exchange operator,

Its eigenvalues are therefore 1 or −1. It may thus be utilized as an interaction term in a Hamiltonian, splitting the energy eigenvalues of its symmetric versus antisymmetric eigenstates.

The group SU(2) is the Lie group of unitary matrices with unit determinant; its Lie algebra is the set of all anti-Hermitian matrices with trace 0. Direct calculation, as above, shows that the Lie algebra formula_60 is the 3-dimensional real algebra spanned by the set }. In compact notation,

As a result, each can be seen as an infinitesimal generator of SU(2). The elements of SU(2) are exponentials of linear combinations of these three generators, and multiply as indicated above in discussing the Pauli vector. Although this suffices to generate SU(2), it is not a proper representation of, as the Pauli eigenvalues are scaled unconventionally. The conventional normalization is  , so that

As SU(2) is a compact group, its Cartan decomposition is trivial.

The Lie algebra is isomorphic to the Lie algebra , which corresponds to the Lie group SO(3), the group of rotations in three-dimensional space. In other words, one can say that the are a realization (and, in fact, the lowest-dimensional realization) of "infinitesimal" rotations in three-dimensional space. However, even though and are isomorphic as Lie algebras, and are not isomorphic as Lie groups. is actually a double cover of , meaning that there is a two-to-one group homomorphism from to , see relationship between SO(3) and SU(2).

The real linear span of is isomorphic to the real algebra of quaternions . The isomorphism from to this set is given by the following map (notice the reversed signs for the Pauli matrices):

Alternatively, the isomorphism can be achieved by a map using the Pauli matrices in reversed order,

As the set of versors "U" ⊂ ℍ forms a group isomorphic to , "U" gives yet another way of describing . The two-to-one homomorphism from to may be given in terms of the Pauli matrices in this formulation.

Quaternions form a division algebra—every non-zero element has an inverse—whereas Pauli matrices do not.

In classical mechanics, Pauli matrices are useful in the context of the Cayley-Klein parameters. The matrix "P" corresponding to the position formula_65 of a point in space is defined in terms of the above Pauli vector matrix, 

Consequently, the transformation matrix formula_67 for rotations about the "x"-axis through an angle "θ" may be written in terms of Pauli matrices and the unit matrix as

Similar expressions follow for general Pauli vector rotations as detailed above.

In quantum mechanics, each Pauli matrix is related to an angular momentum operator that corresponds to an observable describing the spin of a spin ½ particle, in each of the three spatial directions. As an immediate consequence of the Cartan decomposition mentioned above, are the generators of a projective representation (spin representation) of the rotation group SO(3) acting on non-relativistic particles with spin ½. The states of the particles are represented as two-component spinors. In the same way, the Pauli matrices are related to the isospin operator.

An interesting property of spin ½ particles is that they must be rotated by an angle of 4 in order to return to their original configuration. This is due to the two-to-one correspondence between SU(2) and SO(3) mentioned above, and the fact that, although one visualizes spin up/down as the north/south pole on the 2-sphere , they are actually represented by orthogonal vectors in the two dimensional complex Hilbert space.

For a spin ½ particle, the spin operator is given by , the fundamental representation of "SU(2)". By taking Kronecker products of this representation with itself repeatedly, one may construct all higher irreducible representations. That is, the resulting spin operators for higher spin systems in three spatial dimensions, for arbitrarily large "j", can be calculated using this spin operator and ladder operators. They can be found in Rotation group SO(3)#A note on Lie algebra. The analog formula to the above generalization of Euler's formula for Pauli matrices, the group element in terms of spin matrices, is tractable, but less simple.

Also useful in the quantum mechanics of multiparticle systems, the general Pauli group is defined to consist of all -fold tensor products of Pauli matrices.

In relativistic quantum mechanics, the spinors in four dimensions are 4 × 1 (or 1 × 4) matrices. Hence the Pauli matrices or the Sigma matrices operating on these spinors have to be 4 × 4 matrices. They are defined in terms of 2 × 2 Pauli matrices as

It follows from this definition that formula_70 matrices have the same algebraic properties as formula_71 matrices.

However, relativistic angular momentum is not a three-vector, but a second order four-tensor. Hence formula_70 needs to be replaced by formula_73, the generator of Lorentz transformations on spinors. By the antisymmetry of angular momentum, the formula_73 are also antisymmetric. Hence there are only six independent matrices.

The first three are the formula_75 The remaining three, formula_76, where the Dirac formula_77 matrices are defined as

The relativistic spin matrices formula_73 are written in compact form in terms of commutator of gamma matrices as

In quantum information, single-qubit quantum gates are "2" × "2" unitary matrices. The Pauli matrices are some of the most important single-qubit operations. In that context, the Cartan decomposition given above is called the "Z–Y decomposition of a single-qubit gate". Choosing a different Cartan pair gives a similar "X–Y decomposition of a single-qubit gate".




</doc>
<doc id="24869" url="https://en.wikipedia.org/wiki?curid=24869" title="Pie menu">
Pie menu

In user interface design, a pie menu (also known as a radial menu) is a circular context menu where selection depends on direction. It is a graphical control element. A pie menu is made of several "pie slices" around an inactive center and works best with stylus input, and well with a mouse. Pie slices are drawn with a hole in the middle for an easy way to exit the menu.

Pie menus work well with keyboard acceleration, particularly four and eight item menus, on the cursor keys and the number pad. A goal of pie menus is to provide a smooth, reliable gestural style of interaction for novices and experts. A slice can lead to another pie menu; selecting this may center the pointer in the new menu.

A marking menu is a variant of this technique that makes the menu less sensitive to variance in gesture size.

As a kind of context menu, pie menus are often context-sensitive, showing different options depending on what the pointer was pointing at when the menu was requested.

The first documented radial menu is attributed to a system called PIXIE in 1969. Some universities explored alternative visual layouts.

In 1986, Mike Gallaher and Don Hopkins together independently arrived at the concept of a context menu based on the angle to the origin where the exact angle and radius could be passed as parameters to a command, or the radius could be used to trigger a submenu.

The first performance comparison to linear menus was performed in 1988 showing an increase in performance of 15% less time and a reduction of selection errors.

The role-playing video game "Secret of Mana" featured an innovative icon-based radial menu system in 1993. Its ring menu system was adopted by later video games.

For novice users, pie menus are easy because they are a self-revealing gestural interface: They show what you can do and direct you how to do it. By clicking and popping up a pie menu, looking at the labels, moving the pointer in the desired direction, then clicking to make a selection, users learn the menu and practice the gesture to "mark ahead" ("mouse ahead" in the case of a mouse, "wave ahead" in the case of a dataglove). With a little practice, it becomes quite easy to mark ahead even through nested pie menus.

For the expert, the pie menus are more efficient. Because they might have built up the muscle memory for certain menu actions, and able to select the option they want without looking the pop up selections. In some cases, only when used more slowly like a traditional menu, does a pie menu pop up on the screen, to reveal the available selections. Moreover, novices can gradually become experts when they practice the same pie menu selection for many times and start to remember the menu and the motion. As Jaron Lanier of VPL Research has remarked, "The mind may forget, but the body remembers." Pie menus take advantage of the body's ability to remember muscle motion and direction, even when the mind has forgotten the corresponding symbolic labels.

Pie menus are faster and more reliable to select from than linear menus, because selection depends on direction instead of distance. The circular menu slices are large in size and near the pointer for fast interaction (see Fitts's law). Experienced users use muscle memory without looking at the menu while selecting from it. Nested pie menus can efficiently offer many options, and some pie menus can pop up linear menus, and combine linear and radial items in the same menu. Pie menus just like any popup menu are shown only when requested, resulting in less visual distraction and cognitive load than toolbars and menu bars that are always shown.

Pie menus show available options, in contrast to invisible mouse gestures. Pie menus, which delay appearance until the pointer is not moving, reduce intrusiveness to the same level as mouse gestures for experienced users. Pie menus take up more screen space than linear menus, and the number of slices in an individual menu must be kept low for effectiveness by using submenus. When using pie menus, submenus may overlap with the parent menu, but the parent menu may become translucent or hidden.

Pie menus are most suited for actions that have been laid out by humans, and have logical grouping choices. Linear menus are most suited for dynamic, large menus that have many possible options, without any logical grouping, since pie menus can only show a limited number of menu items. Around 3-12 items can be reasonably accommodated in a radial layout, but additional items past that tend to counteract the benefits of using pie menus in the first place. This can be overcome with related techniques that allow chaining commands in one single gesture through submenus.

However, using interaction techniques that are not pointer-based have proven problematic with both pie and linear menus for cluttered digital tabletop, where physical objects might occlude menu items.

Pie menus are unavailable as standard graphical control element in common commercial toolkits. Video games often require custom widget development, so pie menu cost is lower in that particular scenario.





</doc>
<doc id="24872" url="https://en.wikipedia.org/wiki?curid=24872" title="Pollution">
Pollution

Pollution is the introduction of contaminants into the natural environment that cause adverse change. Pollution can take the form of chemical substances or energy, such as noise, heat, or light. Pollutants, the components of pollution, can be either foreign substances/energies or naturally occurring contaminants. Pollution is often classed as point source or nonpoint source pollution. In 2015, pollution killed 9 million people worldwide.

Major forms of pollution include air pollution, light pollution, litter, noise pollution, plastic pollution, soil contamination, radioactive contamination, thermal pollution, visual pollution, and water pollution.

Air pollution has always accompanied civilizations. Pollution started from prehistoric times, when man created the first fires. According to a 1983 article in the journal "Science," "soot" found on ceilings of prehistoric caves provides ample evidence of the high levels of pollution that was associated with inadequate ventilation of open fires." Metal forging appears to be a key turning point in the creation of significant air pollution levels outside the home. Core samples of glaciers in Greenland indicate increases in pollution associated with Greek, Roman, and Chinese metal production.

The burning of coal and wood, and the presence of many horses in concentrated areas made the cities the primary sources of pollution. The Industrial Revolution brought an infusion of untreated chemicals and wastes into local streams that served as the water supply. King Edward I of England banned the burning of sea-coal by proclamation in London in 1272, after its smoke became a problem; the fuel was so common in England that this earliest of names for it was acquired because it could be carted away from some shores by the wheelbarrow.

It was the Industrial Revolution that gave birth to environmental pollution as we know it today. London also recorded one of the earlier extreme cases of water quality problems with the Great Stink on the Thames of 1858, which led to construction of the London sewerage system soon afterward. Pollution issues escalated as population growth far exceeded viability of neighborhoods to handle their waste problem. Reformers began to demand sewer systems and clean water.

In 1870, the sanitary conditions in Berlin were among the worst in Europe. August Bebel recalled conditions before a modern sewer system was built in the late 1870s:
The primitive conditions were intolerable for a world national capital, and the Imperial German government brought in its scientists, engineers, and urban planners to not only solve the deficiencies, but to forge Berlin as the world's model city. A British expert in 1906 concluded that Berlin represented "the most complete application of science, order and method of public life," adding "it is a marvel of civic administration, the most modern and most perfectly organized city that there is."

The emergence of great factories and consumption of immense quantities of coal gave rise to unprecedented air pollution and the large volume of industrial chemical discharges added to the growing load of untreated human waste. Chicago and Cincinnati were the first two American cities to enact laws ensuring cleaner air in 1881. Pollution became a major issue in the United States in the early twentieth century, as progressive reformers took issue with air pollution caused by coal burning, water pollution caused by bad sanitation, and street pollution caused by the 3 million horses who worked in American cities in 1900, generating large quantities of urine and manure. As historian Martin Melosi notes, the generation that first saw automobiles replacing the horses saw cars as "miracles of cleanliness". By the 1940s, however, automobile-caused smog was a major issue in Los Angeles.

Other cities followed around the country until early in the 20th century, when the short lived Office of Air Pollution was created under the Department of the Interior. Extreme smog events were experienced by the cities of Los Angeles and Donora, Pennsylvania in the late 1940s, serving as another public reminder.

Air pollution would continue to be a problem in England, especially later during the industrial revolution, and extending into the recent past with the Great Smog of 1952. Awareness of atmospheric pollution spread widely after World War II, with fears triggered by reports of radioactive fallout from atomic warfare and testing. Then a non-nuclear event – the Great Smog of 1952 in London – killed at least 4000 people. This prompted some of the first major modern environmental legislation: the Clean Air Act of 1956.

Pollution began to draw major public attention in the United States between the mid-1950s and early 1970s, when Congress passed the Noise Control Act, the Clean Air Act, the Clean Water Act, and the National Environmental Policy Act. 

Severe incidents of pollution helped increase consciousness. PCB dumping in the Hudson River resulted in a ban by the EPA on consumption of its fish in 1974. National news stories in the late 1970s – especially the long-term dioxin contamination at Love Canal starting in 1947 and uncontrolled dumping in Valley of the Drums – led to the Superfund legislation of 1980. The pollution of industrial land gave rise to the name brownfield, a term now common in city planning.

The development of nuclear science introduced radioactive contamination, which can remain lethally radioactive for hundreds of thousands of years. Lake Karachay – named by the Worldwatch Institute as the "most polluted spot" on earth – served as a disposal site for the Soviet Union throughout the 1950s and 1960s. Chelyabinsk, Russia, is considered the "Most polluted place on the planet".

Nuclear weapons continued to be tested in the Cold War, especially in the earlier stages of their development. The toll on the worst-affected populations and the growth since then in understanding about the critical threat to human health posed by radioactivity has also been a prohibitive complication associated with nuclear power. Though extreme care is practiced in that industry, the potential for disaster suggested by incidents such as those at Three Mile Island, Chernobyl, and Fukushima pose a lingering specter of public mistrust. Worldwide publicity has been intense on those disasters. Widespread support for test ban treaties has ended almost all nuclear testing in the atmosphere.

International catastrophes such as the wreck of the Amoco Cadiz oil tanker off the coast of Brittany in 1978 and the Bhopal disaster in 1984 have demonstrated the universality of such events and the scale on which efforts to address them needed to engage. The borderless nature of atmosphere and oceans inevitably resulted in the implication of pollution on a planetary level with the issue of global warming. Most recently the term persistent organic pollutant (POP) has come to describe a group of chemicals such as PBDEs and PFCs among others. Though their effects remain somewhat less well understood owing to a lack of experimental data, they have been detected in various ecological habitats far removed from industrial activity such as the Arctic, demonstrating diffusion and bioaccumulation after only a relatively brief period of widespread use.
A much more recently discovered problem is the Great Pacific Garbage Patch, a huge concentration of plastics, chemical sludge and other debris which has been collected into a large area of the Pacific Ocean by the North Pacific Gyre. This is a less well known pollution problem than the others described above, but nonetheless has multiple and serious consequences such as increasing wildlife mortality, the spread of invasive species and human ingestion of toxic chemicals. Organizations such as 5 Gyres have researched the pollution and, along with artists like Marina DeBris, are working toward publicizing the issue.

Pollution introduced by light at night is becoming a global problem, more severe in urban centres, but nonetheless contaminating also large territories, far away from towns.

Growing evidence of local and global pollution and an increasingly informed public over time have given rise to environmentalism and the environmental movement, which generally seek to limit human impact on the environment.

The major forms of pollution are listed below along with the particular contaminant relevant to each of them:

A pollutant is a waste material that pollutes air, water, or soil. Three factors determine the severity of a pollutant: its chemical nature, the concentration, the area affected and the persistence.

Pollution has a cost. Manufacturing activities that cause air pollution impose health and clean-up costs on the whole of society, whereas the neighbors of an individual who chooses to fire-proof his home may benefit from a reduced risk of a fire spreading to their own homes. A manufacturing activity that causes air pollution is an example of a negative externality in production. A negative externality in production occurs “when a firm’s production reduces the well-being of others who are not compensated by the firm." For example, if a laundry firm exists near a polluting steel manufacturing firm, there will be increased costs for the laundry firm because of the dirt and smoke produced by the steel manufacturing firm. If external costs exist, such as those created by pollution, the manufacturer will choose to produce more of the product than would be produced if the manufacturer were required to pay all associated environmental costs. Because responsibility or consequence for self-directed action lies partly outside the self, an element of externalization is involved. If there are external benefits, such as in public safety, less of the good may be produced than would be the case if the producer were to receive payment for the external benefits to others. However, goods and services that involve negative externalities in production, such as those that produce pollution, tend to be over-produced and underpriced since the externality is not being priced into the market.

Pollution can also create costs for the firms producing the pollution. Sometimes firms choose, or are forced by regulation, to reduce the amount of pollution that they are producing. The associated costs of doing this are called abatement costs, or marginal abatement costs if measured by each additional unit. In 2005 pollution abatement capital expenditures and operating costs in the US amounted to nearly $27 billion.

Society derives some indirect utility from pollution, otherwise there would be no incentive to pollute. This utility comes from the consumption of goods and services that create pollution. Therefore, it is important that policymakers attempt to balance these indirect benefits with the costs of pollution in order to achieve an efficient outcome.

It is possible to use environmental economics to determine which level of pollution is deemed the social optimum. For economists, pollution is an “external cost and occurs only when one or more individuals suffer a loss of welfare,” however, there exists a socially optimal level of pollution at which welfare is maximized. This is because consumers derive utility from the good or service manufactured, which will outweigh the social cost of pollution until a certain point. At this point the damage of one extra unit of pollution to society, the marginal cost of pollution, is exactly equal to the marginal benefit of consuming one more unit of the good or service.

In markets with pollution, or other negative externalities in production, the free market equilibrium will not account for the costs of pollution on society. If the social costs of pollution are higher than the private costs incurred by the firm, then the true supply curve will be higher. The point at which the social marginal cost and market demand intersect gives the socially optimal level of pollution. At this point, the quantity will be lower and the price will be higher in comparison to the free market equilibrium. Therefore, the free market outcome could be considered a market failure because it “does not maximize efficiency”.

This model can be used as a basis to evaluate different methods of internalizing the externality. Some examples include tariffs, a carbon tax and cap and trade systems.

Air pollution comes from both natural and human-made (anthropogenic) sources. However, globally human-made pollutants from combustion, construction, mining, agriculture and warfare are increasingly significant in the air pollution equation.

Motor vehicle emissions are one of the leading causes of air pollution. China, United States, Russia, India Mexico, and Japan are the world leaders in air pollution emissions. Principal stationary pollution sources include chemical plants, coal-fired power plants, oil refineries, petrochemical plants, nuclear waste disposal activity, incinerators, large livestock farms (dairy cows, pigs, poultry, etc.), PVC factories, metals production factories, plastics factories, and other heavy industry. Agricultural air pollution comes from contemporary practices which include clear felling and burning of natural vegetation as well as spraying of pesticides and herbicides

About 400 million metric tons of hazardous wastes are generated each year. The United States alone produces about 250 million metric tons. Americans constitute less than 5% of the world's population, but produce roughly 25% of the world's , and generate approximately 30% of world's waste. In 2007, China overtook the United States as the world's biggest producer of , while still far behind based on per capita pollution (ranked 78th among the world's nations).
In February 2007, a report by the Intergovernmental Panel on Climate Change (IPCC), representing the work of 2,500 scientists, economists, and policymakers from more than 120 countries, confirmed that humans have been the primary cause of global warming since 1950. Humans have ways to cut greenhouse gas emissions and avoid the consequences of global warming, a major climate report concluded. But to change the climate, the transition from fossil fuels like coal and oil needs to occur within decades, according to the final report this year from the UN's Intergovernmental Panel on Climate Change (IPCC).

Some of the more common soil contaminants are chlorinated hydrocarbons (CFH), heavy metals (such as chromium, cadmium – found in rechargeable batteries, and lead – found in lead paint, aviation fuel and still in some countries, gasoline), MTBE, zinc, arsenic and benzene. In 2001 a series of press reports culminating in a book called "Fateful Harvest" unveiled a widespread practice of recycling industrial byproducts into fertilizer, resulting in the contamination of the soil with various metals. Ordinary municipal landfills are the source of many chemical substances entering the soil environment (and often groundwater), emanating from the wide variety of refuse accepted, especially substances illegally discarded there, or from pre-1970 landfills that may have been subject to little control in the U.S. or EU. There have also been some unusual releases of polychlorinated dibenzodioxins, commonly called "dioxins" for simplicity, such as TCDD.

Pollution can also be the consequence of a natural disaster. For example, hurricanes often involve water contamination from sewage, and petrochemical spills from ruptured boats or automobiles. Larger scale and environmental damage is not uncommon when coastal oil rigs or refineries are involved. Some sources of pollution, such as nuclear power plants or oil tankers, can produce widespread and potentially hazardous releases when accidents occur.

In the case of noise pollution the dominant source class is the motor vehicle, producing about ninety percent of all unwanted noise worldwide.

Adverse air quality can kill many organisms, including humans. Ozone pollution can cause respiratory disease, cardiovascular disease, throat inflammation, chest pain, and congestion. Water pollution causes approximately 14,000 deaths per day, mostly due to contamination of drinking water by untreated sewage in developing countries. An estimated 500 million Indians have no access to a proper toilet, Over ten million people in India fell ill with waterborne illnesses in 2013, and 1,535 people died, most of them children. Nearly 500 million Chinese lack access to safe drinking water. A 2010 analysis estimated that 1.2 million people died prematurely each year in China because of air pollution. The high smog levels China has been facing for a long time can do damage to civilians' bodies and cause different diseases. The WHO estimated in 2007 that air pollution causes half a million deaths per year in India. Studies have estimated that the number of people killed annually in the United States could be over 50,000.

Oil spills can cause skin irritations and rashes. Noise pollution induces hearing loss, high blood pressure, stress, and sleep disturbance. Mercury has been linked to developmental deficits in children and neurologic symptoms. Older people are majorly exposed to diseases induced by air pollution. Those with heart or lung disorders are at additional risk. Children and infants are also at serious risk. Lead and other heavy metals have been shown to cause neurological problems. Chemical and radioactive substances can cause cancer and as well as birth defects.

An October 2017 study by the Lancet Commission on Pollution and Health found that global pollution, specifically toxic air, water, soils and workplaces, kills nine million people annually, which is triple the number of deaths caused by AIDS, tuberculosis and malaria combined, and 15 times higher than deaths caused by wars and other forms of human violence. The study concluded that "pollution is one of the great existential challenges of the Anthropocene era. Pollution endangers the stability of the Earth’s support systems and threatens the continuing survival of human societies."

Pollution has been found to be present widely in the environment. There are a number of effects of this:

The Toxicology and Environmental Health Information Program (TEHIP) at the United States National Library of Medicine (NLM) maintains a comprehensive toxicology and environmental health web site that includes access to resources produced by TEHIP and by other government agencies and organizations. This web site includes links to databases, bibliographies, tutorials, and other scientific and consumer-oriented resources. TEHIP also is responsible for the Toxicology Data Network (TOXNET) an integrated system of toxicology and environmental health databases that are available free of charge on the web.

TOXMAP is a Geographic Information System (GIS) that is part of TOXNET. TOXMAP uses maps of the United States to help users visually explore data from the United States Environmental Protection Agency's (EPA) Toxics Release Inventory and Superfund Basic Research Programs.

A 2019 paper linked pollution to adverse school outcomes for children.

A number of studies show that pollution has an adverse effect on the productivity of both indoor and outdoor workers.

To protect the environment from the adverse effects of pollution, many nations worldwide have enacted legislation to regulate various types of pollution as well as to mitigate the adverse effects of pollution.

Pollution control is a term used in environmental management. It means the control of emissions and effluents into air, water or soil. Without pollution control, the waste products from overconsumption, heating, agriculture, mining, manufacturing, transportation and other human activities, whether they accumulate or disperse, will degrade the environment. In the hierarchy of controls, pollution prevention and waste minimization are more desirable than pollution control. In the field of land development, low impact development is a similar technique for the prevention of urban runoff.



The earliest precursor of pollution generated by life forms would have been a natural function of their existence. The attendant consequences on viability and population levels fell within the sphere of natural selection. These would have included the demise of a population locally or ultimately, species extinction. Processes that were untenable would have resulted in a new balance brought about by changes and adaptations. At the extremes, for any form of life, consideration of pollution is superseded by that of survival.

For humankind, the factor of technology is a distinguishing and critical consideration, both as an enabler and an additional source of byproducts. Short of survival, human concerns include the range from quality of life to health hazards. Since science holds experimental demonstration to be definitive, modern treatment of toxicity or environmental harm involves defining a level at which an effect is observable. Common examples of fields where practical measurement is crucial include automobile emissions control, industrial exposure (e.g. Occupational Safety and Health Administration (OSHA) PELs), toxicology (e.g. ), and medicine (e.g. medication and radiation doses).

"The solution to pollution is dilution", is a dictum which summarizes a traditional approach to pollution management whereby sufficiently diluted pollution is not harmful. It is well-suited to some other modern, locally scoped applications such as laboratory safety procedure and hazardous material release emergency management. But it assumes that the diluent is in virtually unlimited supply for the application or that resulting dilutions are acceptable in all cases.

Such simple treatment for environmental pollution on a wider scale might have had greater merit in earlier centuries when physical survival was often the highest imperative, human population and densities were lower, technologies were simpler and their byproducts more benign. But these are often no longer the case. Furthermore, advances have enabled measurement of concentrations not possible before. The use of statistical methods in evaluating outcomes has given currency to the principle of probable harm in cases where assessment is warranted but resorting to deterministic models is impractical or infeasible. In addition, consideration of the environment beyond direct impact on human beings has gained prominence.

Yet in the absence of a superseding principle, this older approach predominates practices throughout the world. It is the basis by which to gauge concentrations of effluent for legal release, exceeding which penalties are assessed or restrictions applied. One such superseding principle is contained in modern hazardous waste laws in developed countries, as the process of diluting hazardous waste to make it non-hazardous is usually a regulated treatment process. Migration from pollution dilution to elimination in many cases can be confronted by challenging economical and technological barriers.

Carbon dioxide, while vital for photosynthesis, is sometimes referred to as pollution, because raised levels of the gas in the atmosphere are affecting the Earth's climate. Disruption of the environment can also highlight the connection between areas of pollution that would normally be classified separately, such as those of water and air. Recent studies have investigated the potential for long-term rising levels of atmospheric carbon dioxide to cause slight but critical increases in the acidity of ocean waters, and the possible effects of this on marine ecosystems.

Air pollution fluctuations have been
known to strongly depend on the weather dynamics.
A recent study developed a multi-layered network analysis and detected strong
interlinks between the geopotential height of the upper air ( 5 km) and surface air pollution
in both China and the USA. This study indicates that Rossby waves significantly affect air pollution fluctuations
through the development of cyclone and anticyclone systems, and further affect the
local stability of the air and the winds. The Rossby waves impact on air pollution
has been observed in the daily fluctuations in surface air pollution. Thus, the impact
of Rossby waves on human life is significant and rapid warming of
the Arctic could slow down Rossby waves, thus increasing human health risks.

The Pure Earth, an international non-for-profit organization dedicated to eliminating life-threatening pollution in the developing world, issues an annual list of some of the world's most polluting industries.

A 2018 report by the Institute for Agriculture and Trade Policy and GRAIN says that the meat and dairy industries are poised to surpass the oil industry as the world's worst polluters.

Pure Earth issues an annual list of some of the world's worst polluted places.



</doc>
<doc id="24873" url="https://en.wikipedia.org/wiki?curid=24873" title="Pole weapon">
Pole weapon

A pole weapon or pole arm is a close combat weapon in which the main fighting part of the weapon is fitted to the end of a long shaft, typically of wood, thereby extending the user's effective range and striking power. Because many pole weapons were adapted from agricultural implements or other tools in fairly large amount of abundance, and contain relatively little metal, they were cheap to make and readily available. When warfare breaks out and the belligerents have a poorer class who cannot pay for dedicated weapons made for war, military leaders often resort to the appropriation of tools as cheap weapons. The cost of training was minimal, since these conscripted farmers had spent most of their lives in the familiar use of these "weapons" in the fields. This made polearms the favored weapon of peasant levies and peasant rebellions the world over.

Pole arms can be divided into three broad categories: those designed for extended reach and thrusting tactics used in pike square or phalanx combat; those designed to increase leverage (thanks to hands moving freely on a pole) to maximize centrifugal force against cavalry; and those designed for throwing tactics used in skirmish line combat. Because their versatility, high effectiveness and cheap cost, polearms experimentation led to many variants and were the most frequently used weapons on the battlefield: bills, spears, glaives, guandaos, pudaos, poleaxes, halberds, harpoons, sovnyas, tridents, naginatas, war scythes and javelins are all varieties of pole arms.

Pole arms were common weapons on post-classical battlefields of Asia and Europe. Their range and impact force made them effective weapons against armored warriors on horseback, because they could be dismounted and/or penetrate said armor. The Renaissance saw a plethora of different varieties. Pole arms in modern times are largely constrained to ceremonial military units such as the Papal Swiss Guard or Yeomen of the Guard, or traditional martial arts. Chinese martial arts in particular have preserved a wide variety of weapons and techniques.

The classification of pole weapons can be difficult, and European weapon classifications in particular can be confusing. This can be due to a number of factors, including uncertainty in original descriptions, changes in weapons or nomenclature through time, mistranslation of terms, and the well-meaning inventiveness of later experts. For example, the word "halberd" is also used to translate the Chinese ji and also a range of medieval Scandinavian weapons as described in sagas, such as the atgeir. As well, all pole arms developed from three early tools (the axe, the scythe, and the knife) and one weapon, the spear.

In the words of the arms expert Ewart Oakeshott,

While men-at-arms may have been armed with custom designed military weapons, militias were often armed with whatever was available. These may or may not have been mounted on poles and described by one of more names. The problems with precise definitions can be inferred by a contemporary description of Royalist infantry which were engaged in the Battle of Birmingham (1643) during the first year of English Civil War (in the early modern period). The infantry regiment that accompanied Prince Rupert's cavalry were armed:


The dagger-axe, or "gee" (Chinese: 戈; pinyin: gē; Wade–Giles: ko; sometimes confusingly translated "halberd") is a type of weapon that was in use from Shang dynasty until at least Han dynasty China. It consists of a dagger-shaped blade made of bronze (or later iron) mounted by the tang to a perpendicular wooden shaft: a common Bronze Age infantry weapon, also used by charioteers. Some dagger axes include a spear-point. There is a (rare) variant type with a divided two-part head, consisting of the usual straight blade and a scythe-like blade. Other rarities include archaeology findings with 2 or sometimes 3 blades stacked in line on top of a pole, but were generally thought as ceremonial pole arms. Though the weapon saw frequent use in ancient China, the use of the dagger-axe decreased dramatically after the Qin and Han dynasties. The Ji combines the dagger axe with a spear. By the medieval Chinese dynasties, with the decline of chariot warfare, the use of the dagger-axe was almost nonexistent.

The ji (Chinese: 戟) was created by combining the dagger-axe with a spear. It was used as a military weapon at least as early as the Shang dynasty until the end of the Northern and Southern dynasties.

The ngao or ngau (ง้าว,ของ้าว) is a Thai pole arm that was traditionally used by elephant-riding infantry and is still used by practitioners of krabi krabong. Known in Malay as a "dap", it consists of a wooden shaft with a curved blade fashioned onto the end, and is similar in design to the Korean woldo. Usually, it also had a hook (ขอ) between the blade and shaft used for commanding the elephant. The elephant warrior used the ngao like a blade from atop an elephant or horse during battle.

The Danish Axe is a weapon with a heavy crescent-shaped head mounted on a haft in length. Originally a Viking weapon, it was adopted by the Anglo-Saxons and Normans in the 11th century, spreading through Europe in the 12th and 13th centuries. Variants of this basic weapon continued in use in Scotland and Ireland into the 16th century. A form of 'Long Axe'.

In the 13th century, variants on the Danish axe are seen. Described in English as a "sparth" (from the Old Norse ) or "pale-axe", the weapon featured a larger head with broader blade, the rearward part of the crescent sweeping up to contact (or even be attached to) the haft.

In Ireland, this axe was known as a "Sparr Axe". Originating in either Western Scotland or Ireland, the "sparr" was widely used by the galloglass. Although sometimes said to derive from the Irish for a joist or beam, a more likely definition is as a variant of sparth. Although attempts have been made to suggest that the sparr had a distinctive shaped head, illustrations and surviving weapons show there was considerable variation and the distinctive feature of the weapon was its long haft.

A fauchard is a type of pole arm which was used in medieval Europe from the 11th through the 14th centuries. The design consisted of a curved blade put atop a pole. The blade bore a moderate to strong curve along its length; however, unlike a bill or guisarme, the cutting edge was on the convex side.

A guisarme (sometimes gisarme, giserne or bisarme) was a pole weapon used in Europe primarily between 1000 and 1400. It was used primarily to dismount knights and horsemen. Like most pole arms it was developed by peasants by combining hand tools with long poles, in this case by putting a pruning hook onto a spear shaft. While hooks are fine for dismounting horsemen from mounts, they lack the stopping power of a spear especially when dealing with static opponents. While early designs were simply a hook on the end of a long pole, later designs implemented a small reverse spike on the back of the blade. Eventually weapon makers incorporated the usefulness of the hook in a variety of different pole arms and "guisarme" became a catch-all for any weapon that included a hook on the blade. Ewart Oakeshott has proposed an alternative description of the weapon as a crescent shaped socketed axe.

A glaive is a pole arm consisting of a single-edged tapering blade similar in shape to a modern kitchen knife on the end of a pole. The blade was around long, on the end of a pole long. However, instead of having a tang like a sword or naginata, the blade is affixed in a socket-shaft configuration similar to an axe head, both the blade and shaft varying in length. Illustrations in the 13th century Maciejowski Bible show a short staffed weapon with a long blade used by both infantry and cavalry. Occasionally glaive blades were created with a small hook or spike on the reverse side. Such glaives are named glaive-guisarme.

A voulge (occasionally called a pole cleaver) is a curved blade attached to a pole by binding the lower two-thirds of the blade to the side of the pole, to form a sort of axe. Looks very similar to a glaive.

A svärdstav (literally sword-staff) is a Swedish medieval pole arm that consists of a two-edged sword blade attached to a staff. The illustrations often show the weapon being equipped with sword-like quillons. The illustrations sometimes show a socket mount and reinforcing langets being used, but sometimes they are missing; it is possible this weapon was sometimes manufactured by simply attaching an old sword blade onto a long pole on its tang, not unlike the naginata.

A naginata (なぎなた or 薙刀) is a Japanese pole arm that was traditionally used by members of the samurai class. A naginata consists of a wood shaft with a curved blade on the end; it is descended from the Chinese guan dao. Usually it also had a sword-like guard (tsuba) between the blade and shaft. It was mounted with a tang and held in place with a pin or pins, rather than going over the shaft using a socket.

The Korean woldo was a variation of the Chinese guan dao. It was originally used by the medieval Shilla warriors. Wielding the woldo took time due to its weight, but in the hands of a trained soldier, the woldo was a fearsome, agile weapon famous for enabling a single soldier to cut down ranks of infantrymen. The woldo was continually in use for the military in Korea with various modifications made over the decades. Unlike the Chinese with the guan dao, the Koreans found the woldo unwieldy on horseback, and thus, it was specifically tailored to the needs of infantrymen. The Joseon government implemented rigorous training regimens requiring soldiers to be proficient with swordsmanship, and the use of the woldo. Though it was never widely used as a standard weapon, the woldo saw action on many fronts and was considered by many Korean troops to be a versatile weapon. Recently, a contemporary revival in various martial arts in Korea has brought interest into the application of the woldo and its history.

A guandao or kwan tou is a type of Chinese pole weapon. In Chinese, it is properly called a yanyue dao (偃月刀), 'reclining moon blade'. Some believed it comes from the late Han Era and was supposedly used by the late Eastern Han Dynasty general Guan Yu, but archaeological findings have shown that Han dynasty armies generally used straight, single-edged blades, and curved blades came several centuries later. There is no reason to believe their pole arms had curved blades on them. Besides, historical accounts of the Three Kingdoms era describe Guan Yu thrusting his opponents down (probably with a spear-like pole arm) in battle, not cutting them down with a curved blade. The guandao is also known as the "chun qiu da dao" ('spring autumn great knife'), again probably related to the depiction of Guan Yu in the Ming dynasty novel "Romance of the Three Kingdoms", but possibly a Ming author's invention. It consists of a heavy blade mounted atop a wooden or metal pole with a pointed metal counter weight used for striking and stabbing on the opposite end.

The blade is very deep and curved on its face, resembling a Chinese saber, or dao. Variant designs include rings along the length of the straight back edge, as found in the nine-ring guandao. The "elephant" guandao's tip curls into a rounded spiral, while the dragon head guandao features a more ornate design.

A "podao", 'long-handled sabre', is a Chinese pole arm, also known as the zhan ma dao ('horsecutter sabre'), which has a lighter blade and a ring at the end. A podao is an infantryman's weapon, mainly used for cutting the legs off oncoming charging horses to bring down the riders.

In the Song dynasty, several weapons were referred to as "ji", but they were developed from spears, not from ancient "ji". One variety was called the "qinglong ji" (), and had a spear tip with a crescent blade on one side. Another type was the "fangtian ji" (), which had a spear tip with crescent blades on both sides. They had multiple means of attack: the side blade or blades, the spear tip, plus often a rear counterweight that could be used to strike the opponent. The way the side blades were fixed to the shaft differs, but usually there were empty spaces between the pole and the side blade. The wielder could strike with the shaft, with the option of then pulling the weapon back to hook with a side blade; or, he could slap his opponent with the flat side of the blade to knock him off his horse.

A corseque has a three-bladed head on a haft which, like the partisan, is similar to the winged spear or spetum in the later Middle Ages. It was popular in Europe in the 16th and 17th centuries. Surviving examples have a variety of head forms but there are two main variants, one with the side blades (known as flukes or wings) branching from the neck of the central blade at 45 degrees, the other with hooked blades curving back towards the haft. The corseque is usually associated with the rawcon, ranseur and runka. Another possible association is with the "three-grayned staff" listed as being in the armoury of Henry VIII in 1547 (though the same list also features 84 rawcons, suggesting the weapons were not identical in 16th century English eyes). Another modern term used for particularly ornate-bladed corseques is the "chauve-souris".

A halberd (or Swiss voulge) is a two-handed pole weapon that came to prominent use during the 14th and 15th centuries but has continued in use as a ceremonial weapon to the present day. First recorded as "hellembart" in 1279, the word "halberd" possibly comes from the German words "Halm" (staff) or "Helm" (helmet), and "Barte" (axe). The halberd consists of an axe blade topped with a spike mounted on a long shaft. It always has a hook or thorn on the back side of the axe blade for grappling mounted combatants. Early forms are very similar in many ways to certain forms of voulge, while 16th century and later forms are similar to the pollaxe. The Swiss were famous users of the halberd in the medieval and renaissance eras, with various cantons evolving regional variations of the basic form.

In the 14th century, the basic long axe gained an armour-piercing spike on the back and another on the end of the haft for thrusting. This is similar to the pollaxe of 15th century. The poleaxe emerged in response to the need for a weapon that could penetrate plate armour and featured various combinations of an axe-blade, a back-spike and a hammer. It was the favoured weapon for men-at-arms fighting on foot into the sixteenth century.



</doc>
<doc id="24874" url="https://en.wikipedia.org/wiki?curid=24874" title="PHD">
PHD

PHD or PhD may refer to:




</doc>
<doc id="24875" url="https://en.wikipedia.org/wiki?curid=24875" title="Personal jurisdiction">
Personal jurisdiction

Personal jurisdiction is a court's jurisdiction over the "parties" to a lawsuit, as opposed to subject-matter jurisdiction, which is jurisdiction over the "law and facts" involved in the suit. If a court does not have "personal" jurisdiction over a party, its rulings or decrees cannot be enforced upon that party, except by comity; i.e., to the extent that the sovereign which has jurisdiction over the party allows the court to enforce them upon that party. A court that has "personal" jurisdiction has both the authority to rule on the law and facts of a suit and the power to enforce its decision upon a party to the suit. In some cases, territorial jurisdiction may also constrain a court's reach, such as preventing hearing of a case concerning events occurring on foreign territory between two citizens of the home jurisdiction.

Since there is no world government which all countries recognize to arbitrate disputes over jurisdiction, sovereign powers can find themselves in conflict over which is the more appropriate venue to hear a case, or which country's laws should apply. These conflicts are sometimes resolved "de facto" by physical factors, such as which country has physical possession of a defendant or property, or sometimes by use of physical police or military force to seize people or property. A country with loose rule of law – for example an absolute monarchy with no independent judiciary – may arbitrarily choose to assert jurisdiction over a case without citing any particular justification. Such assertion can cause problems, such as encouraging other countries to take arbitrary actions over foreign citizens and property, or even provoking skirmishes or armed conflict.

In practice, many countries operate by one or another principles, either in written law or in practice, which communicate when the country will and will not assert jurisdiction:

Different principles are applied by different countries, and different principles may be applied by the same country in different circumstances. Determination of whether or not a court has jurisdiction to hear a case is the first stage of a conflict of laws proceeding, potentially followed by choice of law to determine which jurisdiction's laws apply. Executive prosecutorial authority and foreign policy also play a role in scope and practical impact of jurisdiction choices.

Any assertion of jurisdiction based on anything other than the territorial principle is known as extraterritorial jurisdiction. Prosecution of a case against an out-of-territory defendant is known as assertion of long-arm jurisdiction.

When a person commits a crime in a foreign country against the laws of that country, usually the host country is responsible for prosecution. The Vienna Convention on Consular Relations requires that the host country notify the foreign embassy, potentially allowing the foreign country to assist in legal defense and monitor conditions of detention. (Most countries protect their citizens against foreign powers in general.)

Foreign diplomats enjoy diplomatic immunity in many countries based on the Vienna Convention on Diplomatic Relations or bilateral agreement, and foreign military personnel may be subject to the jurisdiction of their home country based on a status of forces agreement or Visiting Forces Agreement.

If a person is not physically present in the country which wishes to prosecute a case, that country may either wait until the person enters the national territory, or pursue extradition by legal or extralegal means, and with or without a general extradition treaty. Some countries (like China) prefer to prosecute their own citizens for crimes committed abroad rather than extradite them. Other countries defer to the host country.

When a crime is committed outside the territory of any country, such as in Antarctica, on watercraft in international waters, on aircraft in international airspace, and on spacecraft, jurisdiction is usually determined by the nationality of defendants or victims, or by the flag state of the vessel. This is determined by the admiralty law of the countries involved and in international agreements.

The concept of personal jurisdiction in English law has its origin in the idea that a monarch could not exercise power over persons or property located outside of his or her kingdom. To some degree, this was a "de facto" rule; the monarch's men could not arrest people or seize property outside the kingdom without risking physical conflict with the soldiers and police of other kingdoms. Slowly this principle was incorporated into written law, but problems arose in cases where property owners could not be sued because they had left the kingdom or had died and therefore were not present within the kingdom at the time they were being sued. To solve this problem, the courts created another type of jurisdiction, called "quasi in rem", that is, jurisdiction over the land itself, even if the person who owned the land was not in the country. However, this jurisdiction was limited to the settlement of debts owed by the owner of the land.

In the United States, the exercise of personal jurisdiction by a court must both comply with Constitutional limitations, and be authorized by a statute. In the United Kingdom, the exercise of personal jurisdiction does not need a statutory basis, since the United Kingdom does not have a written constitution.

The intersection of American federalism and the rules and theories of jurisdiction inherited from the common law of England has resulted in a highly complex body of law respecting personal jurisdiction in the United States. These rules limit both state and federal courts in their ability to hear cases.

Three fundamentals of personal jurisdiction constrain the ability of courts in the United States to bind individuals or property to its decisions: consent, power, and notice.

The United States legal system is an adversarial system. Civil suits cannot be initiated by third parties, but must be filed by the aggrieved party who seeks redress. Generally, the action is initiated in the jurisdiction where the event occurred, where the defendant can be served or where the parties have agreed to have the case located. The filing of a complaint or "prayer for relief" is a voluntary action by the person aggrieved, and as a necessity of this request, the person seeking relief consents to be bound by the judgment of the court. The doctrine of consent is also extended to defendants who attend and litigate actions without challenging the court's personal jurisdiction. Consent may also derive from a pre-litigation agreement by the parties, such as a forum selection clause in a contract (not to be confused with a choice of law clause). Doctrines such as claim preclusion prevent re-litigation of failed complaints in alternative forums. Claim preclusion does not, however, prevent the refiling of a claim that was filed in a court that did not have personal jurisdiction over the defendant.

In cases where a defendant challenges personal jurisdiction, a court may still exercise personal jurisdiction if it has independent power to do so. This power is founded in the inherent nature of the State: sovereignty over affairs within its territory.

The Fifth and Fourteenth Amendment to the United States Constitution preserve the right of the individual to "due process". Due process requires that notice be given in a manner "reasonably calculated" to inform a party of the action affecting him. Originally, "Notice" (and the power of the State) was often exercised more forcefully, the defendant in a civil case sometimes being seized and brought before the court under a writ of "capias ad respondendum". Notice in such a case is inferred from consent of the defendant to go with the officer. Nowadays, when exercising power over an individual without consent, notice is usually given by formal delivery of suitable papers to the defendant (service of process).

Originally, jurisdiction over parties in the United States was determined by strict interpretation of the geographic boundaries of each state's sovereign power. In "Pennoyer v. Neff", the Supreme Court discussed that though each state ceded certain powers (e.g. foreign relations) to the Federal Government or to no entity at all (e.g. the powers that are eliminated by the protections of the bill of rights), the states retained all the other powers of sovereignty, including the exclusive power to regulate the affairs of individuals and property within its territory. Necessarily following from this, one state's exercise of power could not infringe upon the sovereignty of another state. Thus, Constitutional limitations applied to the validity of state court judgments.

Three types of jurisdiction developed, collectively termed territorial jurisdiction because of their reliance upon territorial control: "in personam" jurisdiction, "in rem" jurisdiction, and "quasi in rem" jurisdiction. Some sources refer to all three types of territorial jurisdiction as personal jurisdiction, since most actions against property (in rem jurisdiction) bear, in the end, upon the rights and obligations of persons. Others continue to recognize the traditional distinction between personal jurisdiction and jurisdiction over property, even after "Shaffer v. Heitner" (discussed below).

In personam jurisdiction referred to jurisdiction over a particular person (or entity, such as a company). "In personam" jurisdiction, if held by a state court, permitted that court to rule upon any case over which it otherwise held jurisdiction. Under territorial jurisdiction, pure "in personam" jurisdiction could only be established by serving notice upon the individual while that individual was within the territory of the state.

In rem jurisdiction referred to jurisdiction over a particular piece of property, most commonly real estate or land. Certain cases, notably government suits for unpaid property taxes, proceed not against an individual but against their property directly. Under territorial jurisdiction, "in rem" jurisdiction could be exercised by the courts of a state by seizing the property in question. Since an actual tract of land could not literally be brought into a courtroom as a person could, this was effected by giving notice upon the real property itself. "In rem" jurisdiction was thus supported by the assumption that the owner of that property, having a concrete economic interest in the property, had a duty to look after the affairs of their property, and would be notified of the pending case by such seizure. "In rem" jurisdiction was limited to deciding issues regarding the specific property in question.

Quasi in rem jurisdiction involved the seizure of property held by the individual against whom the suit was brought, and attachment of that property to the case in question. This form of territorial jurisdiction developed from the rationale of "in rem" jurisdiction, namely that seizure of the property was reasonably calculated to inform an individual of the proceedings against them.

Once a valid judgment was obtained against an individual, however, the plaintiff could pursue recovery against the assets of the defendant regardless of their location, as other states were obligated by the Full Faith and Credit Clause of the Constitution to recognize such a judgment (i.e. had ceded their power to refuse comity to fellow states of the Union). Violations by a rogue state could be checked via collateral attack: when a plaintiff sought recovery against a defendant's assets in another state, that state could refuse judgment on the grounds that the original judgment was invalid.

Following "Pennoyer", extreme applications of territorial jurisdiction revealed imperfections in the doctrine, and societal changes began to present new problems as the United States' national economy became more integrated by increasingly efficient multi-state transportation technology and business practices.

While determining the physical location of an individual for the purposes of "in personam" jurisdiction was easy enough, applying the same principle to non-physical entities became difficult. Courts were presented with the question of where a company was present and amenable to service for the purpose of "in personam" jurisdiction over the company.

Extension of "quasi in rem" jurisdiction led to extreme results that threatened the justification for the jurisdiction. Bearing in mind that territorial jurisdiction existed in a pre-industrial society where transportation across the country was difficult, long, and potentially treacherous, and consider the hypothetical wherein Alice owes Bob money, and Bob owes Carmel, a resident of New York, money. Carmel seeks to recover on Bob's debt to Carmel, however cannot do so because Bob avoids Carmel by travelling to California. Alice, however, happens to travel through New York. Carmel serves notice upon Alice, and attaches Alice's debt to Bob (considered to be property within the state) to the proceeding. Alice can no more certainly provide notice to Bob in California than Carmel could provide, and the transient and involuntary exposure of Bob to being hauled into court in New York by this attachment seems to erode the original rationale of "quasi in rem" jurisdiction.

The US Supreme Court largely abolished the exercise of jurisdiction on the basis of "quasi in rem" in "Shaffer v. Heitner", except in exceptional circumstances, which sometimes would arise while dealing with real property such as land, and when the owner of the land cannot be found.

In the modern era, the reach of personal jurisdiction has been expanded by judicial re-interpretation and legislative enactments. Under the new and current doctrine, a state court may only exert personal jurisdiction over an individual or entity with "sufficient minimal contacts" with the forum state such that the particular suit "does not offend 'traditional notions of fair play and justice.'" The "minimum contacts" must be purposefully directed towards the state by the defendant. This jurisdiction was initially limited to the particulars of the "International Shoe Co. v. Washington" holding, that is to jurisdictional inquiries regarding companies, but was soon extended to apply to all questions of personal jurisdiction. When an individual or entity has no "minimum contacts" with a forum State, the Due Process Clause of the Fourteenth Amendment prohibits that State from acting against that individual, or entity. The lack of "minimum contacts" with the owner of property also constitutionally prohibits action against that property (in rem jurisdiction) even when the property is located within the forum state.

What constitutes sufficient "minimum contacts" has been delineated in numerous cases which followed the International Shoe decision. For example, in "Hanson v. Denckla", the Court proclaimed the "unilateral activity of those who claim some relationship with a nonresident cannot satisfy the requirement of contact with the forum State. The application of that rule will vary with the nature and quality of the defendant's activity, but it is essential in each case that there be some act by which the defendant purposefully avails itself of the privilege of conducting activities within the forum State, thus invoking the benefits and protection of its laws."

The additional requirement of "'purposeful availment' ensures that a defendant will not be hauled into a jurisdiction solely as a result of 'random,' 'fortuitous,' or 'attenuated' contacts, or of the unilateral activity of another party or a third person". Jurisdiction may, however, be exercised, under some circumstances, even though the defendant never physically entered the forum State.

In addition, the claim must arise from those contacts that the defendant had with the forum state. In addition to the minimum contacts test asserted in International Shoe, the assertion of specific personal jurisdiction must be reasonable. The Court in "World-Wide Volkswagen Corp. v. Woodson" asserted a five-part test for determining if the assertion of personal jurisdiction in a forum state was reasonable. This test considers: the burden on the defendant from litigating in the forum state; the interest of the forum state in having the case adjudicated there; the interests of the plaintiff in adjudicating in the forum state; the interests of the inter-state judiciary—that is, that a court's assertion of personal jurisdiction over an out-of state defendant would not overreach and preempt the interests and judicial sovereignty of another state; and the interests in preserving the judicial integrity of the several states—that is, ensuring one court's assertion of personal jurisdiction over an out of state defendant does not violate the Due Process Clause of the Fourteenth Amendment.

In another recent case of "Goodyear Dunlop Tires Operations, S. A. v. Brown", Justice Ginsburg held that for the exercise of general jurisdiction in personam, the defendant must be "essentially at home." This applies when the defendant has contacts with the forum state, but the claim that arises is not related to those contacts. For example, if Harrods (a British store) sets up an office in California to export and sell goods there, and because of that someone gets injured, it would be amenable to suit in California for that injury. On the other hand, if someone is injured in Harrods in London and for some reason finds that California law is more favorable and decides to sue in California, the suit would not be maintainable under general jurisdiction since the contacts that Harrods has is not continuous and systematic, and they are not "essentially at home" in California. However, there would be personal jurisdiction. By selling shoes in California, Harrod’s purposefully availed itself of the benefits of California law and the lawsuit arose out of that contact. 

This holding was reaffirmed in 2014 by the Supreme Court in "Daimler AG v. Bauman".

While the "Pennoyer" and later "Shoe" doctrines limit the maximum power of a sovereign state, courts must also have authorization to exercise the state's power; an individual state may choose to not grant its courts the full power that the state is Constitutionally permitted to exercise. Similarly, the jurisdiction of Federal courts (other than the Supreme Court) are statutorily-defined. Thus, a particular exercise of personal jurisdiction must not only be permitted by Constitutional doctrine, but be statutorily authorized as well. Under "Pennoyer", personal jurisdiction was authorized by statutes authorizing service of process, but these methods of service often lacked because they required such service to be effected by officers of the state, such as sheriffs – an untenable method for defendants located outside of the state but still subject to jurisdiction due to their contacts with the state. Subsequent to the development of the "Shoe" Doctrine, states have enacted so-called long-arm statutes, by which courts in a state can serve process and thus exercise jurisdiction over a party located outside the state. The doctrine of International Shoe applies only in cases where there is no presence in the forum state. For example, if A committed a tort in State X. He is sued by B and B serves him with process just before he leaves State X before the flight was took off, the service would be valid and State X would have jurisdiction over A. If A did not comply with the final judgement passed by the courts of State X, B could enforce that judgement in the state where A resides under the full faith and credit clause of the US Constitution. There was one case where a defendant was served while the airplane was in the air over the forum State, and the federal district court held that this was valid service, since at law the territory of a state includes the airspace above the State. 

Venue and personal jurisdiction are closely related for practical purposes. A lawyer should usually perform joint analysis of personal jurisdiction and venue issues. Personal jurisdiction is largely a constitutional requirement, though also shaped by state long-arm statutes and Rule 4 of the Federal Rules of Civil Procedure, while venue is purely statutory.

It is possible for either venue or personal jurisdiction to preclude a court from hearing a case. Consider these examples:



[ Official Website of the Supreme Court of the United States]


</doc>
<doc id="24877" url="https://en.wikipedia.org/wiki?curid=24877" title="Pell's equation">
Pell's equation

Pell's equation, also called the Pell–Fermat equation, is any Diophantine equation of the form

where "n" is a given positive nonsquare integer and integer solutions are sought for "x" and "y". In Cartesian coordinates, the equation has the form of a hyperbola; solutions occur wherever the curve passes through a point whose "x" and "y" coordinates are both integers, such as the trivial solution with "x" = 1 and "y" = 0. Joseph Louis Lagrange proved that, as long as "n" is not a perfect square, Pell's equation has infinitely many distinct integer solutions. These solutions may be used to accurately approximate the square root of "n" by rational numbers of the form "x"/"y".

This equation was first studied extensively in India starting with Brahmagupta, who found an integer solution to formula_2 in his "Brāhmasphuṭasiddhānta" in 628. Bhaskara II in the twelfth century and Narayana Pandit in the fourteenth century both found general solutions to Pell's equation and other quadratic indeterminate equations. Bhaskara II is generally credited with developing the "chakravala" method, building on the work of Jayadeva and Brahmagupta. Solutions to specific examples of Pell's equation, such as the Pell numbers arising from the equation with "n" = 2, had been known for much longer, since the time of Pythagoras in Greece and a similar date in India. The name of Pell's equation arose from Leonhard Euler mistakenly attributing Lord Brouncker's solution of the equation to John Pell.

As early as 400 BC in India and Greece, mathematicians studied the numbers arising from the "n" = 2 case of Pell's equation,

and from the closely related equation

because of the connection of these equations to the square root of 2. Indeed, if "x" and "y" are positive integers satisfying this equation, then "x"/"y" is an approximation of . The numbers "x" and "y" appearing in these approximations, called side and diameter numbers, were known to the Pythagoreans, and Proclus observed that in the opposite direction these numbers obeyed one of these two equations. Similarly, Baudhayana discovered that "x" = 17, "y" = 12 and "x" = 577, "y" = 408 are two solutions to the Pell equation, and that 17/12 and 577/408 are very close approximations to the square root of 2.

Later, Archimedes approximated the square root of 3 by the rational number 1351/780. Although he did not explain his methods, this approximation may be obtained in the same way, as a solution to Pell's equation.
Likewise, Archimedes's cattle problem — an ancient word problem about finding the number of cattle belonging to the sun god Helios — can be solved by reformulating it as a Pell's equation. The manuscript containing the problem states that it was devised by Archimedes and recorded in a letter to Eratosthenes, and the attribution to Archimedes is generally accepted today.

Around AD 250, Diophantus considered the equation

where "a" and "c" are fixed numbers and "x" and "y" are the variables to be solved for.
This equation is different in form from Pell's equation but equivalent to it.
Diophantus solved the equation for ("a", "c") equal to (1, 1), (1, −1), (1, 12), and (3, 9). Al-Karaji, a 10th-century Persian mathematician, worked on similar problems to Diophantus.

In Indian mathematics, Brahmagupta discovered that
a form of what is now known as Brahmagupta's identity. Using this, he was able to "compose" triples formula_7 and formula_8 that were solutions of formula_9, to generate the new triples
Not only did this give a way to generate infinitely many solutions to formula_12 starting with one solution, but also, by dividing such a composition by formula_13, integer or "nearly integer" solutions could often be obtained. For instance, for formula_14, Brahmagupta composed the triple (10, 1, 8) (since formula_15) with itself to get the new triple (192, 20, 64). Dividing throughout by 64 ('8' for formula_16 and formula_17) gave the triple (24, 5/2, 1), which when composed with itself gave the desired integer solution (1151, 120, 1). Brahmagupta solved many Pell equations with this method, proving that it gives solutions starting from an integer solution of formula_9 for "k" = ±1, ±2, or ±4.

The first general method for solving the Pell equation (for all "N") was given by Bhāskara II in 1150, extending the methods of Brahmagupta. Called the chakravala (cyclic) method, it starts by choosing two relatively prime integers formula_19 and formula_20, then composing the triple formula_21 (that is, one which satisfies formula_22) with the trivial triple formula_23 to get the triple formula_24, which can be scaled down to

When formula_26 is chosen so that formula_27 is an integer, so are the other two numbers in the triple. Among such formula_26, the method chooses one that minimizes formula_29, and repeats the process. This method always terminates with a solution (proved by Joseph-Louis Lagrange in 1768). Bhaskara used it to give the solution "x" = 1766319049, "y" = 226153980 to the "N" = 61 case.

Several European mathematicians rediscovered how to solve Pell's equation in the 17th century, apparently unaware that it had been solved almost five hundred years earlier in India. Pierre de Fermat found how to solve the equation and in a 1657 letter issued it as a challenge to English mathematicians. In a letter to Kenelm Digby, Bernard Frénicle de Bessy said that Fermat found the smallest solution for "N" up to 150, and challenged John Wallis to solve the cases "N" = 151 or 313. Both Wallis and William Brouncker gave solutions to these problems, though Wallis suggests in a letter that the solution was due to Brouncker.

John Pell's connection with the equation is that he revised Thomas Branker's translation of Johann Rahn's 1659 book "Teutsche Algebra" into English, with a discussion of Brouncker's solution of the equation. Leonhard Euler mistakenly thought that this solution was due to Pell, as a result of which he named the equation after Pell.

The general theory of Pell's equation, based on continued fractions and algebraic manipulations with numbers of the form formula_30 was developed by Lagrange in 1766–1769.

Let formula_31 denote the sequence of convergents to the regular continued fraction for formula_32. This sequence is unique. Then the pair ("x","y") solving Pell's equation and minimizing "x" satisfies "x" = "h" and "y" = "k" for some "i". This pair is called the "fundamental solution". Thus, the fundamental solution may be found by performing the continued fraction expansion and testing each successive convergent until a solution to Pell's equation is found.

As describes, the time for finding the fundamental solution using the continued fraction method, with the aid of the Schönhage–Strassen algorithm for fast integer multiplication, is within a logarithmic factor of the solution size, the number of digits in the pair ("x","y"). However, this is not a polynomial time algorithm because the number of digits in the solution may be as large as , far larger than a polynomial in the number of digits in the input value "n" .

Once the fundamental solution is found, all remaining solutions may be calculated algebraically from
expanding the right side, equating coefficients of formula_32 on both sides, and equating the other terms on both sides. This yields the recurrence relations

Although writing out the fundamental solution ("x", "y") as a pair of binary numbers may require a large number of bits, it may in many cases be represented more compactly in the form
using much smaller integers "a", "b", and "c".

For instance, Archimedes' cattle problem is equivalent to the Pell equation formula_38, the fundamental solution of which has 206545 digits if written out explicitly. However, the solution is also equal to
where
and formula_41 and formula_42 only have 45 and 41 decimal digits, respectively.

Methods related to the quadratic sieve approach for integer factorization may be used to collect relations between prime numbers in the number field generated by , and to combine these relations to find a product representation of this type. The resulting algorithm for solving Pell's equation is more efficient than the continued fraction method, though it still takes more than polynomial time. Under the assumption of the generalized Riemann hypothesis, it can be shown to take time
where "N" = log "n" is the input size, similarly to the quadratic sieve .

 showed that a quantum computer can find a product representation, as described above, for the solution to Pell's equation in polynomial time. Hallgren's algorithm, which can be interpreted as an algorithm for finding the group of units of a real quadratic number field, was extended to more general fields by .

As an example, consider the instance of Pell's equation for "n" = 7; that is,
The sequence of convergents for the square root of seven are

Therefore, the fundamental solution is formed by the pair (8, 3). Applying the recurrence formula to this solution generates the infinite sequence of solutions

The smallest solution can be very large. For example, the smallest solution to formula_45 is (32188120829134849, 1819380158564160), and this is the equation which Frenicle challenged Wallis to solve. Values of "n" such that the smallest solution of formula_46 is greater than the smallest solution for any smaller value of "n" are

The following is a list of the smallest solution (fundamental solution) to formula_47 with "n" ≤ 128. For square "n", there is no solution except (1, 0). The values of "x" are sequence and those of "y" are sequence in OEIS.

Pell's equation has connections to several other important subjects in mathematics.

Pell's equation is closely related to the theory of algebraic numbers, as the formula
is the norm for the ring formula_49 and for the closely related quadratic field formula_50. Thus, a pair of integers formula_51 solves Pell's equation if and only if formula_52 is a unit with norm 1 in formula_49. Dirichlet's unit theorem, that all units of formula_49 can be expressed as powers of a single fundamental unit (and multiplication by a sign), is an algebraic restatement of the fact that all solutions to the Pell equation can be generated from the fundamental solution. The fundamental unit can in general be found by solving a Pell-like equation but it does not always correspond directly to the fundamental solution of Pell's equation itself, because the fundamental unit may have norm −1 rather than 1 and its coefficients may be half integers rather than integers.

 mentions a connection between Pell's equation and the Chebyshev polynomials:
If "T" ("x") and "U" ("x") are the Chebyshev polynomials of the first and second kind, respectively, then these polynomials satisfy a form of Pell's equation in any polynomial ring "R"["x"], with "n" = "x" − 1:

Thus, these polynomials can be generated by the standard technique for Pell equations of taking powers of a fundamental solution:

It may further be observed that, if ("x","y") are the solutions to any integer Pell equation, then "x" = "T" ("x") and "y" = "y""U"("x") , chapter 3.

A general development of solutions of Pell's equation formula_46 in terms of continued fractions of formula_32 can be presented, as the solutions "x" and "y" are approximates to the square root of "n" and thus are a special case of continued fraction approximations for quadratic irrationals.

The relationship to the continued fractions implies that the solutions to Pell's equation form a semigroup subset of the modular group. Thus, for example, if "p" and "q" satisfy Pell's equation, then

is a matrix of unit determinant. Products of such matrices take exactly the same form, and thus all such products yield solutions to Pell's equation. This can be understood in part to arise from the fact that successive convergents of a continued fraction share the same property: If "p"/"q" and "p"/"q" are two successive convergents of a continued fraction, then the matrix

has determinant (−1).

Størmer's theorem applies Pell equations to find pairs of consecutive smooth numbers, positive integers whose prime factors are all smaller than a given value. As part of this theory, Størmer also investigated divisibility relations among solutions to Pell's equation; in particular, he showed that each solution other than the fundamental solution has a prime factor that does not divide "n".

The negative Pell equation is given by

It has also been extensively studied; it can be solved by the same method of continued fractions and will have solutions if and only if the period of the continued fraction has odd length. However it is not known which roots have odd period lengths and therefore not known when the negative Pell equation is solvable. A necessary (but not sufficient) condition for solvability is that "n" is not divisible by 4 or by a prime of form 4"k" + 3. Thus, for example, "x" − 3"ny" = −1 is never solvable, but "x" − 5"ny" = −1 may be.

The first few numbers "n" for which "x" − "ny" = −1 is solvable are

implies

The equation
is called the generalized (or general) Pell's equation. The equation formula_65 is the corresponding Pell's resolvent. A recursive algorithm was given by Lagrange in 1768 for solving the equation, reducing the problem to the case formula_66. Such solutions can be derived using the continued fractions method as outlined above.

If formula_67 is a solution to formula_64 and formula_69 is a solution to formula_70 then formula_71 such that formula_72 is a solution to formula_73, a principle named the "multiplicative principle". 

Solutions to the generalized Pell's equation are used for solving certain Diophantine equations and units of certain rings, and they arise in the study of SIC-POVMs in quantum information theory.

The equation

is similar to the resolvent formula_75 in that if a minimal solution to formula_74 can be found then all solutions of the equation can be generated in a similar manner to the case formula_77. For certain formula_78, solutions to formula_75 can be generated from those with formula_74, in that if formula_81 then every third solution to formula_74 has "x,y" even, generating a solution to formula_75.




</doc>
<doc id="24879" url="https://en.wikipedia.org/wiki?curid=24879" title="Telephone card">
Telephone card

A telephone card, calling card or phonecard for short, is a credit card-size plastic or paper card, used to pay for telephone services (often international or long-distance calling). It is not necessary to have the physical card except with a stored-value system; knowledge of the access telephone number to dial and the PIN is sufficient. Standard cards which can be purchased and used without any sort of account facility give a fixed amount of credit and are discarded when used up; rechargeable cards can be topped up, or collect payment in arrears. The system for payment and the way in which the card is used to place a telephone call vary from card to card.

Calling cards usually come equipped with PIN for user protection and security. Most companies require user to enter the PIN before granting access to the calling card's funds. PINs often are printed on a piece of paper found inside the calling card's packaging. Once the users makes their first call, some companies offer the option of eliminating the PIN altogether to speed up the calling process. Companies that sell virtual calling cards online typically PIN via email.

A stored-value phone card stores the available credit balance in a analog or digital memory physically embedded in the card. This balance can be read by a public payphone when the card is inserted into the card reader. This is superficially similar to a bank automated teller machine, but a stored-value card is more closely analogous to a change purse. While ATMs (as well as the remote memory systems discussed below) use the card merely to identify the associated account and record changes in a central database, stored-value systems make a physical alteration to the card, or write data to an embedded chip or magnetic stripe to reflect the new balance after a call.

Used primarily for payphones, stored-value systems avoid the time lag and expense of communication with a central database, which would have been technically complex before the 1990s. 

There are several ways in which the value can be encoded on the card:

The earliest system used a magnetic stripe as information carrier, similar to the technology of ATMs and key cards. The first magnetic strip phonecard, manufactured by SIDA, was issued in 1976 in Italy.
The next technology used optical storage. Optical phonecards get their name from optical structure embossed inside the cards. This optical structure is heated and destroyed after use of the units. Visible marks are left on the top of the cards, so that the user can see the balance of remaining units. Optical cards were produced by Landis+Gyr and Sodeco from Switzerland and were popular early phonecards in many countries with first optical phonecards successfully introduced in 1977 in Belgium. Such technology was very secure and not easily hackable but chip cards phased out the optical phone cards around the world and the last Landis+Gyr factory closed in May 2006 when optical phonecards were still in use in few countries like Austria, Israel and Egypt.

The third system of stored-value phone cards are smart cards and use an embedded microchip. These were first launched on a large scale in 1986 in Germany by Deutsche Bundespost after three years of testing, and in France by France Télécom. Many other countries followed suit, including Ireland in 1990 and the UK circa 1994–1995, which phased out the old green Landis+Gyr cards in favor of the chip (smart) cards. The initial microchips were easy to hack, typically by scratching off the programming-voltage contact on the card, which rendered the phone unable to reduce the card's value after a call. But by the mid-to-late 1990s, highly secure technology aided the spread of chip phonecards worldwide.

Making a remote memory prepaid or calling card call requires the user to make two calls. It is necessary to dial an access telephone number to connect to the calling card system. There are several methods. One is via a toll-free number, with larger companies offering this internationally. Access through a local number has become increasingly popular in recent years. Toll-free calls are paid for by the recipient (the calling card company), which passes on the cost through higher call charges; total cost of a call to the user is often lower using a local number. When travelling through several local areas a toll-free service may be preferable.

Once connected to the access number, the account is identified by keying in a PIN (the most popular method) or by swiping a card with embedded chip or magnetic stripe. After validation the balance remaining on the card may be announced, and the desired number may be keyed in. The available minutes may be announced, and the call is connected. Many cards make a verbal announcement if credit is running out.

Prepaid or calling cards are usually much cheaper than other telephone services, particularly for travelers who do not have easy access to other services. Hotel telephones can be very expensive, particularly for long-distance calls. Cellular services are flexible, but may attract high roaming charges away from the home area.
The second main technology of phonecards is remote memory, which uses a toll or toll-free access number to reach the database and check for balance on product.

The first public prepaid remote memory phonecard was issued in the United States in December 1980 by Phone Line. As telecom industries around the world became deregulated, remote memory cards were issued in various countries. Remote memory phonecards can be used from any tone-mode phone and do not require special card readers. Since remote memory cards are more accessible and have lower costs, remote memory phone cards have proliferated. However, the utility of these cards is reduced by the large number of digits that need to be entered during usage. To call a long-distance number, the user first dials the local access number, then keys in the secret code, followed by the actual long-distance number. Based on the long-distance number entered, the time remaining on the card is announced, and the call is finally processed through.

Remote memory phonecards are in essence text; requiring an access number, a unique PIN and instructions. Therefore, the instructions can be printed on virtually anything, or can be delivered via e-mail or the Internet. Currently many websites post phone card details through e-mail.

Phone cards are available in most countries in retail stores, retail chains and commonly post offices or corner stores. In general, remote memory phonecards can be issued by any company and come in countless varieties. They can focus on calling to certain countries or regions and have specific features such as rechargeability, pinless dial, speed dial and more. Phone cards may have connection fees, taxes and maintenance fees, all influencing the rates.

Since the early 2000s calling card service providers have introduced calling accounts not associated with a physical card. Calling accounts can be purchased over the Internet using credit cards and are instantly delivered to the customer via e-mail. This e-mail contains the PIN and instructions for using the service. The service may be prepaid, or may take payment from a credit card or by direct debit. Some prepaid card companies allow accounts to be recharged online manually or automatically via a method called auto-top-up.

Some virtual cards offer PIN<nowiki>less</nowiki> Dialing, either by dialling a number unique to the customer, or by recognising the telephone number which originated the call by Caller ID and relating it to the appropriate account. Some virtual phone cards allow customers to view their call detail reports (CDRs) online by logging into their account.

The virtual phonecard has become a multi-billion US dollar industry as of 2009, with a number of large corporations and smaller Dot Com companies. While long-distance inland calls have been offered by calling cards, by the mid-2000s conventional carriers reduced their rates to be competitive; however in many countries calling-card type indirect services can be much cheaper than normal calls.

Telecom companies have placed advertising on phonecards, or featured celebrity portraits, artwork, or attractive photography. As the supply of any one design is limited, this has led some people to collect disposable phonecards. Due to a large number of phonecards, collectors prefer to specialize and collect cards in a certain way. Some collect phonecards that have only one specific chip type or were issued in the same country, while others prefer to get one of everything. Online clubs and catalogs provide collectors with detailed information on phonecards. In addition, these clubs include forums to assist with discussions between collectors.

Most modern telephones, both mobile and fixed, have memory locations in which telephone numbers can be stored. Some telephones have facilities to make calls through a calling card service whose access details and PIN are also stored in the telephone's memory. This may be implemented in different ways, often by pressing one button before making a call; some telephones support "chain dialing", allowing additional numbers to be dialed when on a call (e.g., dial a PIN and a second number after connecting to an access number). So long as long enough sequences can be stored it is possible to store an access number, pause, PIN, and ultimate telephone number in a single normal phone memory location. Software applications which add calling card support are available for a small charge or free for some smartphones.



</doc>
<doc id="24883" url="https://en.wikipedia.org/wiki?curid=24883" title="CD-i">
CD-i

The Compact Disc-Interactive (CD-I, later CD-i) is a digital optical disc data storage format that was mostly developed and marketed by Dutch company Philips. It was created as an extension of CDDA and CD-ROM and specified in the "Green Book", co-developed by Philips and Sony, to combine audio, text and graphics. The two companies initially expected to impact the education/training, point of sale, and home entertainment industries, but CD-i eventually became best known for its video games.

CD-i media physically have the same dimensions as CD, but with up to 744 MiB of digital data storage, including up to 72 minutes of full motion video. CD-i players were usually standalone boxes that connect to a standard television; some less common setups included integrated CD-i television sets and expansion modules for personal computers. Most players were created by Philips; the format was licensed by Philips and Microware for use by other manufacturers, notably Sony who released professional CD-i players under the "Intelligent Discman" brand. Unlike CD-ROM drives, CD-i players are complete computer systems centered around dedicated Motorola 68000-based microprocessors and its own operating system called CD-RTOS, which is an acronym for ""Compact Disc – Real Time Operating System"".

Media released on the format included video games and "edutainment" and multimedia reference titles, such as interactive encyclopedias and museum tours – which were popular before public Internet access was widespread – as well as business software. Philips's CD-i system also implemented Internet features, including subscriptions, web browsing, downloading, e-mail, and online play. Philips's aim with its players was to introduce interactive multimedia content for the general public by combining features of a CD player and games console, but at a lower price than a personal computer with a CD-ROM drive.

Authoring kits for the format were released first in 1988, and the first player aimed for home consumers, Philips's CDI 910/205, at the end of 1991, initially priced around US$1,000 (), and capable of playing interactive CD-i discs, Audio CDs, CD+G (CD+Graphics), Karaoke CDs, Photo CDs and Video CDs (VCDs), though the latter required an optional "Digital Video Card" to provide MPEG-1 decoding. Initially marketed to consumers as "home entertainment systems", and in later years as a "gaming platform", CD-i did not manage to find enough success in the market, and was mostly abandoned by Philips in 1996. The format continued to be supported for licensees for a few more years after.

Development of the "Compact Disc-Interactive" format began in 1984 (two years after the launch of Compact Disc) and it was first publicly announced by Philips and Sony – two of the largest electronics companies of the time – at Microsoft's CD-ROM Conference in Seattle in March 1986. Microsoft's CEO Bill Gates had no idea beforehand that the format was under development. The "Green Book", formally known as the "CD-i Full Functional Specification", defined the format for interactive, multimedia compact discs designed for CD-i players. The "Green Book" specification also defines a whole hardware set built around the Motorola 68000 microprocessor family, and an operating system called CD-RTOS based on OS-9, a product of Microware. The standard was originally not freely available and had to be licensed from Philips. However, the 1994 version of the standard was eventually made available free by Philips.

CD-i discs conform to the "Red Book" specification of audio CDs (CD-DA). Tracks on a CD-i's program area can be CD-DA tracks or CD-i tracks, but the first track must always be a CD-i track, and all CD-i tracks must be grouped together at the beginning of the area. CD-i tracks are structured according to the CD-ROM XA specification (using either Mode 2 Form 1 or Mode 2 Form 2 modes), and have different classes depending on their contents ("data", "video", "audio", "empty" and "message"). "Message" sectors contain audio data to warn users of CD players that the track they are trying to listen to is a CD-i track and not a CD-DA track. The CD-i specification also specifies a file system similar to (but not compatible with) ISO 9660 to be used on CD-i tracks, as well as certain specific files that are required to be present in a CD-i compatible disc. Compared to the "Yellow Book" (specification for CD-ROM), the "Green Book" CD-i standard solves synchronisation problems by interleaving audio and video information on a single track.

The format quickly gained interest from large manufacturers, and received backing from many particularly Matsushita. Although a joint effort, Philips eventually took over the majority of CD-i development at the expense of Sony. Philips invested many millions in developing titles and players based on the CD-i specification. Initially branded "CD-I", the name was changed in 1991 to "CD-i" with a lowercase i.

The CD-i Ready format is a type of bridge format, also designed by Philips, that defines discs compatible with CD Digital audio players and CD-i players. This format puts CD-i software and data into the pregap of Track 1.

The CD-i Bridge format, defined in Philips' White Book, is a transitional format allowing bridge discs to be played both on CD-ROM drives and on CD-i players.

The CD-i Digital Video format was launched in 1993 containing movies that could be played on CD-i players with a Digital Video Cartridge add-on. The format was incompatible with Video CD (VCD), although a CD-i unit with the DVC could play both formats. Only about 20 movies were released on the format and it was stopped in 1994 in favor of VCD.

Applications were developed using authoring software produced by OptImage. This included OptImage's Balboa Runtime Libraries and MediaMogul. The second company that produced authoring software was Script Systems; they produced ABCD-I. Much of the CD-i software were promoted and/or published by American Interactive Media (AIM), a joint venture between Philips and its subsidiary PolyGram formed in Los Angeles in 1986, before its public debut, to publish CD-i based consumer software. Similarly in Europe, Philips Interactive Media was launched.

Philips at first marketed CD-i as a family entertainment product, and avoided mentioning video games to not compete against game consoles. Early software releases focused heavily on educational, music, and self-improvement titles, with only a few games, many of them adaptations of board games such as "Connect Four". However, the system was handily beaten in the market for multimedia devices by cheap low-end PCs, and the games were the best-selling software. By 1993 Philips encouraged MS-DOS and console developers to create games, introduced a $250 peripheral with more memory and support for full-motion video, and added to new consoles a second controller port for multiplayer games.

The attempts to develop a foothold in the games market were unsuccessful, as the system was designed strictly as a multimedia player and thus was under-powered compared to other gaming platforms on the market in most respects. Earlier CD-i games included entries in popular Nintendo franchises, although those games were not developed by Nintendo. Specifically, a "Mario" game (titled "Hotel Mario"), and three "Legend of Zelda" games were released: "", "" and "Zelda's Adventure". Nintendo and Philips had established an agreement to co-develop a CD-ROM enhancement for the Super Nintendo Entertainment System due to licensing disagreements with Nintendo's previous partner Sony (an agreement that produced a prototype console called the SNES-CD). While Philips and Nintendo never released such a CD-ROM add-on, Philips was still contractually allowed to continue using Nintendo characters.

As announced at CES 1992, large number of full motion video titles such as "Dragon's Lair" and "Mad Dog McCree" appeared on the system. One of these, "", is considered one of the stronger CD-i titles and was later ported to PC. The February 1994 issue of "Electronic Gaming Monthly" remarked that the CD-i's full motion video capabilities were its strongest point, and that nearly all of its best software required the MPEG upgrade card.

Philips also released several versions of popular TV game shows for the CD-i, including versions of "Jeopardy!" (hosted by Alex Trebek), "Name That Tune" (hosted by Bob Goen), and two versions of "The Joker's Wild" (one for adults hosted by Wink Martindale and one for kids hosted by Marc Summers). All CD-i games in North America (with the exception of "Name That Tune") had Charlie O'Donnell as announcer. The Netherlands also released its version of "Lingo" on the CD-i in 1994.

In 1993, American musician Todd Rundgren created the first music-only fully interactive CD, "No World Order", for the CD-i. This application allows the user to completely arrange the whole album in their own personal way with over 15,000 points of customization. Dutch eurodance duo 2 Unlimited released a CD-i compilation album in 1994 called "Beyond Limits" which contains standard CD tracks as well as CD-i-exclusive media on the disc.

CD-i has a series of learning games ("edutainment") targeted at children from infancy to adolescence. Those intended for a younger audience included "Busytown", "The Berenstain Bears" and various others which usually had vivid cartoon-like settings accompanied by music and logic puzzles.

By mid-1996 the U.S. market for CD-i software had dried up and Philips had given up on releasing titles there, but continued to publish CD-i games in Europe, where the system still held some popularity from a video gaming perspective. With the home market exhausted, Philips tried with some success to position the technology as a solution for kiosk applications and industrial multimedia.

Some homebrew developers have released video games on the CD-i format in later years, such as "Frog Feast" (2005) and "Super Quartet" (2018).

CD-i compatible models were released (as of April 1995) in the U.S., Canada, Benelux, France, Germany, the UK, Japan, Singapore and Hong Kong. It was reported to be released further in Brazil, India and Australia in the "coming months", with plans to also introduce it in China, South Africa, Indonesia and the Philippines.

In addition to consumer models, professional and development players were sold by Philips Interactive Media Systems and their VARs. The first CD-i system was produced by Philips in collaboration with Kyocera in 1988 – the Philips 180/181/182 modular system. Philips marketed several CD-i player models as shown below.


There also exist a number of hard-to-categorize models, such as the FW380i, an integrated mini-stereo and CD-i player; the 21TCDi30, a television with a built-in CD-i device; the CD-i/PC 2.0, a CD-i module with an ISA interface for IBM-compatible 486 PCs.

In addition to Philips, several manufacturers produced CD-i players some of which were still on sale years after Philips itself abandoned the format. Manufacturers included:

Before the actual commercial debut of the CD-i format, some other companies had interest in building players and some made prototypes, but were never released – this includes Panasonic (who were originally a major backer of the format), Pioneer, JVC, Toshiba, Epson, Ricoh, Fujitsu, Yamaha. In addition, Sanyo showed a prototype portable CD-i player in 1992.

Recognizing the growing need among marketers for networked multimedia, Philips partnered in 1992 with Amsterdam-based CDMATICS to develop TeleCD-i (also TeleCD). In this concept, the CD-i player is connected to a network such as PSTN or Internet, enabling data-communication and rich media presentation. Dutch grocery chain Albert Heijn and mail-order company were early adopters and introduced award-winning TeleCD-i applications for their home-shopping and home-delivery services. CDMATICS also developed the special Philips TeleCD-i Assistant and a set of software tools to help the worldwide multimedia industry to develop and implement TeleCD-i. TeleCD-i is the world's first networked multimedia application at the time of its introduction. In 1996, Philips acquired source code rights from CDMATICS.

Internet services on the CD-i devices were facilitated by the use of an additional hardware modem and "CD-Online" disc (renamed Web-i in the US), which Philips initially released in Britain in 1995 for $150 US. This service provided the CD-i with full internet access (with a 14.4k modem), including online shopping, email, and support for networked multiplayer gaming on select CD-i games. The service required a CD-i player with DV cartridge, and an "Internet Starter Kit" which initially retailed for £99.99. It was advertized as bringing "full Internet access to the living room on TV screens". Andy Stout, a writer for the official CD-i magazine, explained CD-Online: The CD-Online service went live in the UK on October 25, 1995 and in March 1996 in the Netherlands (for 399 guilders), and also released in Belgium. The system was reportedly scheduled to launch in the US as "Web-i" in August 1996. The domain cd-online.co.uk, which was used for the British CD-Online service, went offline in 2000.

Only one game was released that supported CD-Online, the First-person shooter game RAM Raid. RAM Raid was the first worldwide enabled online multiplayer game. Players from any country in the world could compete against each other as long as they had a copy of the game.

Philips had invested heavily in the CD-i format and system, and it was often compared with the Commodore CDTV as a single combination of computer, CD, and television. The product was touted as a single machine for home entertainment connected to a standard TV and controlled by a regular remote control – although the format was noted to have various non-entertainment business opportunities too, such as travel and tourism or the military. In 1990, Peugeot used CD-i for its point of sale application promoting its then-new 605 automobile, and it was also at the time used by fellow car manufacturer Renault for staff training programmes, and in Japan by the Ministry of Trade and Industry for an exhibition there. A Philips executive, Gaston Bastiaens, quoted in 1990 "CD-I will be 'the medium' for entertainment, education and information in the 90's.". Sony introduced its three portable CD-i players in June 1990, pitching them as "picture books with sound".

The ambitious CD-i format had initially created much interest after its 1986 announcement, both in the west and in Japan, buoyed by the success of the CD. However, after repeated delays (hardware were first intended to be ready and shipped by Christmas 1987) interest was slowly lost. Electronic Arts for instance was enthusiastic about CD-i and formed a division for the development of video game titles on the format, but it was eventually halted with the intention of resuming when CD-i players would reach the market. The company eventually never resumed CD-i software development when it was released. The delay also gave more attention to the hyped Digital Video Interactive (DVI) in 1987, which demonstrated full screen, full motion video (FMV) using a compression chip on an IBM PC/AT computer. Amid the attention around its potential rival DVI, Philips and Sony decided to find a way to add full screen FMV abilities to the CD-i standard, causing further delay. Meanwhile, the Microsoft-backed CD-ROM standard was improving and solved certain video playback issues that were present on the CD-i – CD-ROM format products were already on the market by 1987. At the end, CD-ROM standard benefited from the CD-i and DVI mishaps, and by the time CD-i players for consumers were released in 1991, CD-ROM had already become known and established. Ron Gilbert commented in early 1990 "The CD-I specifications look great, but where are the machines? If they'd come out four years ago, they'd have been hot, but now they're behind the times." Another reason that led to fading interest pre-launch was the fact CD-i players would not launch with FMV but instead receive it later through a purchasable add-on cartridge (it was originally expected to come built-in) – as well as the obsolete Motorola processor, OS-9 software, and a launch price considered high.

Although Philips had aggressively promoted their CD-i products in the U.S., by August 1993 "Computer Gaming World" reported that "skepticism persists about its long-term prospects" compared to other platforms like IBM PC compatibles, Apple Macintosh, and Sega Genesis. The magazine stated in January 1994 that despite Philips' new emphasis on games "CD-i is still not the answer for hardcore gamers", but the console "may yet surprise us all in the future". It recommended the CD-i with video cartridge for those needing to buy a new console as "The price is right and there is more software to support it", but 3DO Interactive Multiplayer was probably better for those who could wait a few months. The "Electronic Entertainment" August 1994 issue noted that the CD-i, along with the Atari Jaguar, neither have an "effective, let alone innovative" game library to compete against the then newly released Sega CD.

After being outsold in the market by cheaper multimedia PCs, in 1994 Philips attempted to emphasize CD-i as a game playing machine, but this did not help the situation. An early 1995 review of the system in "GamePro" stated that "inconsistent game quality puts the CD-i at a disadvantage against other high-powered game producers." A late 1995 review in "Next Generation" criticized both Philips's approach to marketing the CD-i and the hardware itself ("The unit excels at practically nothing except FMV, and then only with the addition of a $200 digital video cartridge"). The magazine noted that while Philips had not yet officially discontinued the CD-i, it was dead for all intents and purposes, citing as evidence the fact that though Philips had a large booth at the 1995 Electronic Entertainment Expo, there was no CD-i hardware or software on display. "Next Generation" scored the console one out of five stars. Another trouble for Philips in 1995 was the formation of HDCD, which promised better quality video compared to Video CD's (VCD) MPEG-1 compression method – Philips had heavily promoted the CD-i's VCD playing capabilities. Philips Media consolidated its CD-i activities from its Los Angeles office in March 1996. It was reported in October 1996 that Philips was ready to "call it quits" in the American market.

In October 1994, Philips claimed an installed base of one million units for the CD-i worldwide. In 1996, "The Wall Street Journal" reported that total US sales amounted to 400,000 units. In the Netherlands, about 60,000 CD-i players were sold by the end of December 1994.

Although extensively marketed by Philips, notably via infomercial, consumer interest in CD-i titles remained low. By 1994, sales of CD-i systems had begun to slow, and in 1998 the product line was dropped. Plans for a second generation CD-i system were certainly present and Argonaut Software was even designated to design chip sets for the successor to the CD-i. However, the then president Cor Boonstra saw no interest in the media area for Philips and so Philips sold everything, including the media subsidiary Polygram. The Dutch half of Philips Media was sold to Softmachine, which released "The Lost Ride" on the CD-i as the last product for the CD-i. Philips then also sold its French half of the gaming subsidiary, Philips Media BV, to French publisher Infogrames in 1997 along with the entire CD-i library. A CD-ROM add-on for the Super NES, which was announced for development with Nintendo in 1991, was never made. The very last CD-i game thus, was made by Infogrames who released Solar Crusade in 1999.

After its discontinuation, retrospectively, the CD-i was overwhelmingly panned by critics who blasted its graphics, games, and controls. Microsoft CEO Bill Gates admitted that initially he "was worried" about the CD-i due to Philips's heavy support for the device and its two-pronged attack on both the games console and PC markets, but that in retrospect "It was a device that kind of basically got caught in the middle. It was a terrible game machine, and it was a terrible PC." The CD-i's various controllers were ranked the fifth worst video game controller by IGN editor Craig Harris. "PC World" ranked it as fourth on their list of "The 10 Worst Video Game Systems of All Time". Gamepro.com listed it as number four on their list of "The 10 Worst-Selling Consoles of All Time." In 2008, CNET listed the system on its list of the worst game console(s) ever. In 2007, GameTrailers ranked the Philips CD-i as the fourth worst console of all time in its Top 10 Worst Console lineup.

In later retrospective years, the CD-i has become (unpopularly) best known for its video games, particularly those from the Nintendo-licensed "The Legend of Zelda" series, considered by many to be of poor taste. Games that were most heavily criticized include "Hotel Mario", "", "", and "Zelda's Adventure". EGM's Seanbaby rated "The Wand of Gamelon" as one of the worst video games of all time. However, "" was positively received by critics and has often been held up as the standout title for the CD-i.



</doc>
<doc id="24884" url="https://en.wikipedia.org/wiki?curid=24884" title="Peppered moth">
Peppered moth

The peppered moth ("Biston betularia") is a temperate species of night-flying moth. Peppered moth evolution is an example of population genetics and natural selection.

The caterpillars of the peppered moth not only mimic the form but also the colour of a twig. Recent research indicates that the caterpillars can sense the twig's colour with their skin and match their body colour to the background to protect themselves from predators.
The wingspan ranges from 45 mm to 62 mm (median 55 mm). It is relatively stout-bodied, with forewings relatively narrow-elongate. The wings are white, "peppered" with black, and with more-or-less distinct cross lines, also black. The black speckling varies in amount, in some examples it is almost absent, whilst in others it is so dense that the wings appear to be black sprinkled with white. The antennae of males are strongly bipectinate.

"Biston betularia" is found in China (Heilongjiang, Jilin, Inner Mongolia, Beijing, Hebei, Shanxi, Shandong, Henan, Shaanxi, Ningxia, Gansu, Qinghai, Xinjiang, Fujian, Sichuan, Yunnan,
Tibet), Russia, Mongolia, Japan, North Korea, South Korea, Nepal, Kazakhstan, Kyrgyzstan, Turkmenistan, Georgia, Azerbaijan, Armenia, Europe and North America.

In Great Britain and Ireland, the peppered moth is univoltine ("i.e.", it has one generation per year), whilst in south-eastern North America it is bivoltine (two generations per year). The lepidopteran life cycle consists of four stages: ova (eggs), several larval instars (caterpillars), pupae, which overwinter live in the soil, and imagines (adults). During the day, the moths typically rest on trees, where they are preyed on by birds.

The caterpillar is a twig mimic, varying in colour between green and brown. On a historical note, it was one of the first animals to be identified as being camouflaged with countershading to make it appear flat (shading being the main visual cue that makes things appear solid), in a paper by Edward Bagnall Poulton in 1887. Research indicates that the caterpillars can sense the twig's colour with their skin and match their body colour to the background to protect themselves from predators, an ability to camouflage themselves also found in cephalopods, chameleons and some fish, although this colour change is rather slower in the caterpillars.

It goes into the soil late in the season, where it pupates in order to spend the winter. The imagines emerge from the pupae between late May and August, the males slightly before the females (this is common and expected from sexual selection). They emerge late in the day and dry their wings before flying that night.

The males fly every night of their lives in search of females, whereas the females only fly on the first night. Thereafter, the females release pheromones to attract males. Since the pheromone is carried by the wind, males tend to travel up the concentration gradient, i.e., toward the source. During flight, they are subject to predation by bats. The males guard the female from other males until she lays the eggs. The female lays about 2,000 pale-green ovoid eggs about 1 mm in length into crevices in bark with her ovipositor.

A mating pair or a lone individual will spend the day hiding from predators, particularly birds. In the case of the former, the male stays with the female to ensure paternity. The best evidence for resting positions is given by data collected by the peppered moth researcher Michael Majerus, and it is given in the accompanying charts. These data were originally published in Howlett and Majerus (1987), and an updated version published in Majerus (1998), who concluded that the moths rest in the upper part of the trees. Majerus notes:

Creationist critics of the peppered moth have often pointed to a statement made by Clarke "et al". (1985): "... In 25 years we have only found two "betularia" on the tree trunks or walls adjacent to our traps, and none elsewhere". The reason now seems obvious. Few people spend their time looking for moths up in the trees. That is where peppered moths rest by day.

From their original data, Howlett and Majerus (1987) concluded that peppered moths generally rest in unexposed positions, using three main types of site. Firstly, a few inches below a branch-trunk joint on a tree trunk where the moth is in shadow; secondly, on the underside of branches and thirdly on foliate twigs. The above data would appear to support this.

Further support for these resting positions is given from experiments watching captive moths taking up resting positions in both males (Mikkola, 1979; 1984) and females (Liebert and Brakefield, 1987).

Majerus, "et al.", (2000) have shown that peppered moths are cryptically camouflaged against their backgrounds when they rest in the boughs of trees. It is clear that in human visible wavelengths, "typica" are camouflaged against lichens and "carbonaria" against plain bark. However, birds are capable of seeing ultraviolet light that humans cannot see. Using an ultraviolet-sensitive video camera, Majerus et al. showed that "typica" reflect ultraviolet light in a speckled fashion and are camouflaged against crustose lichens common on branches, both in ultraviolet and human-visible wavelengths. However, "typica" are not as well camouflaged against foliose lichens common on tree trunks; though they are camouflaged in human wavelengths, in ultraviolet wavelengths, foliose lichens do not reflect ultraviolet light.

During an experiment in Cambridge over the seven years 2001–2007 Majerus noted the natural resting positions of peppered moths, and of the 135 moths examined over half were on tree branches, mostly on the lower half of the branch, 37% were on tree trunks, mostly on the north side, and only 12.6% were resting on or under twigs.

There are several melanic and non-melanic morphs of the peppered moth. These are controlled genetically. A particular colour morph can be indicated in a standard way by following the species name in the form "morpha "morph name"". The use of "form" in the method of "Biston betularia" f. "formname" in detailing these variations is also a widespread practice.

These forms are often accidentally elevated to subspecies status when they appear in literature. Not adding the "f." (forma) or morpha implies that the taxon is a subspecies instead of a form, as in "Biston betularia carbonaria" instead of "Biston betularia f. carbonaria". Rarely, forms have been elevated to species status, as in "Biston carbonaria". Either of these two circumstances might lead to the erroneous belief that speciation was involved in the observed evolution of the peppered moth. This is not the case; individuals of each morph interbreed and produce fertile offspring with individuals of all other morphs; hence there is only one peppered moth species.

By contrast, different subspecies of the same species can theoretically interbreed with one another and will produce fully fertile and healthy offspring, but in practice do not, as they live in different regions or reproduce in different seasons. Full-fledged species are either unable to produce fertile and healthy offspring, or do not recognize each other's courtship signals, or both.

European breeding experiments have shown that in "Biston betularia betularia", the allele for melanism producing morpha "carbonaria" is controlled by a single locus. The melanic allele is dominant to the non-melanic allele. This situation is, however, somewhat complicated by the presence of three other alleles that produce indistinguishable morphs of morpha "medionigra". These are of intermediate dominance, but this is not complete (Majerus, 1998).

In continental Europe, there are three morphs: the white morph typica (syn. morpha/f. "betularia"), the dark melanistic morph carbonaria (syn. "doubledayaria"), and an intermediate form medionigra.

In Britain, the typical white morph is known as typica, the melanic morph is carbonaria, and the intermediate phenotype is named insularia.

In North America, the melanic black morph is morpha swettaria. In "Biston betularia cognataria", the melanic allele (producing morpha "swettaria") is similarly dominant to the non-melanic allele. There are also some intermediate morphs. In Japan, no melanic morphs have been recorded; they are all morpha "typica".

The evolution of the peppered moth over the last two hundred years has been studied in detail.
At the start of this period, the vast majority of peppered moths had light coloured wing patterns which effectively camouflaged them against the light-coloured trees and lichens upon which they rested. However, due to widespread pollution during the Industrial Revolution in England, many of the lichens died out, and the trees which peppered moths rested on became blackened by soot, causing most of the light-coloured moths, or "typica", to die off due to predation. At the same time, the dark-coloured, or melanic, moths, "carbonaria", flourished because they could hide on the darkened trees.

Since then, with improved environmental standards, light-coloured peppered moths have again become common, and the dramatic change in the peppered moth's population has remained a subject of much interest and study. This has led to the coining of the term "industrial melanism" to refer to the genetic darkening of species in response to pollutants. As a result of the relatively simple and easy-to-understand circumstances of the adaptation, the peppered moth has become a common example used in explaining or demonstrating natural selection to laypeople and classroom students through simulations.

The first "carbonaria" morph was recorded by Edleston in Manchester in 1848, and over the subsequent years it increased in frequency. Predation experiments, particularly by Bernard Kettlewell, established that the agent of selection was birds who preyed on the "carbonaria" morph. Subsequent experiments and observations have supported the initial evolutionary explanation of the phenomenon.

The evolution of the industrial melanism mutation has been shown to be due to the insertion of a transposable element into the first intron of the "cortex" gene, resulting in an increase in the abundance of the "cortex" transcript, which is expressed in developing wings.



</doc>
<doc id="24886" url="https://en.wikipedia.org/wiki?curid=24886" title="Power Macintosh">
Power Macintosh

The Power Macintosh, later Power Mac, is a discontinued family of personal computers designed, manufactured, and sold by Apple Computer, Inc. as part of the Macintosh brand from March 1994 until August 2006.

Described by MacWorld Magazine as "The most important technical evolution of the Macintosh since the Mac II debuted in 1987," the Power Macintosh was Apple's first computer to use a PowerPC processor. Software written for the Motorola 68030 and 68040 processors that were used in Macintoshes up to that point would not run on the PowerPC natively, so a Mac 68k emulator was included with System 7.1.2. While the emulator provided good compatibility with existing Macintosh software, performance was about one-third slower than comparable Macintosh Quadra machines.

The Power Macintosh replaced the Quadra in Apple's lineup, and were initially sold in the same enclosures. Over the next twelve years, the Power Macintosh evolved through a succession of enclosure designs, a rename to "Power Mac", five major generations of PowerPC chips, and a great deal of press coverage, design accolades, and controversy about performance claims. The Power Mac was discontinued as part of the Mac transition to Intel processors, making way for its replacement, the Mac Pro.

The first Power Macintosh models were released in March 1994, but the development of Power Macintosh technology dates back to mid-1988.

Jean-Louis Gassée, president of Apple's product division, started the "Jaguar" project with the goal of creating a computer that would not only be the fastest desktop computer on the market, but would also accept commands by talking to the computer. This was originally envisioned to be a new computer line altogether, not a Macintosh, and the Jaguar team was initially kept independent of the Macintosh team. This separation included operating system development, with the newly-conceived "Pink" being the platform for the new computer. Jaguar was also not intended to be a high-volume, mainstream system. Gassée's preference, as it was with the upcoming Macintosh IIfx, was to create a product that would compete in the high-end workstation market, previously not an area of strength for Apple. The decision to use RISC architecture was representative of a shift in the computer industry in 1987 and 1988, where RISC-based systems from Sun Microsystems, Hewlett-Packard and IBM were significantly outpacing the performance offered by systems based on Motorola's 68020 and 68030 processors and Intel's 80386 and 80486 CPUs. Initially, Apple invested considerable time and effort in an attempt to create their own RISC CPU in a project code-named "Aquarius", even to a point where a Cray-1 supercomputer was purchased to assist with designing the chip. The company lacked the financial and manufacturing resources to produce a working product and the project was cancelled in 1989.

By early 1990, Apple was in contact with a number of RISC vendors to find a suitable hardware partner. The team that had created the IIfx independently started experimenting with creating a new Macintosh product that would combine a Motorola 68030 processor with an AMD Am29000 (29k) RISC chip. Apple had already released a product built on the 29k called "Macintosh Display Card 8•24 GC", a so-called "Macintosh Toolbox accelerator" NuBus card that provided significantly faster drawing routines than those included on the Macintosh ROM. The team's experiments resulted in a 68020 emulator implemented in RISC, but the 29k project was dropped in mid-1990 due to financial infeasibility.

Apple had initially looked at processors such as those from MIPS Technologies, Sun, and Acorn Computers (whose ARM architecture RISC processors would end up being used in the 1993 Apple Newton, 2001 iPod, and 2007 iPhone), as well as the Intel i860. Negotiations with Sun included the condition that Sun would use the Macintosh interface for its SPARC workstation computers in exchange for Apple using Sun's SPARC processors in Macintosh workstations; the deal fell through due to Apple's concern that Sun could not produce enough processors. Negotiations with MIPS to use the R4000 processor also included the condition that the Macintosh interface would be available as an alternative to Advanced Computing Environment. This deal also fell through due to Microsoft being a major partner in the ACE Consortium, as well as concerns about manufacturing capability. The Intel i860 was eliminated from consideration due to its high complexity. Apple did not consider IBM's POWER1 processor as an option, believing that IBM would not be willing to license it to third parties.
In mid-1990, Apple chose the Motorola 88110, an as yet unfinished chip that combined the 88100 CPU and 88200 FPU into a single package. For the rest of the year, Apple's engineers developed a 68k emulator that would work with this future chip. This project became known as "RLC", short form "RISC LC", a play on the name of Apple's upcoming Macintosh LC computer. By January 1991, the engineering team had produced a prototype of a Macintosh LC with its 68020 CPU being swapped out for an 88100 and a 68020 emulator. This prototype was able to use an unmodified Macintosh Toolbox ROM and could boot into System 7. A few months later, a second prototype was created, utilizing a Macintosh IIsi case with the now-completed Motorola 88100 chip.

Jaguar wasn't initially intended to be a high-volume mainstream system. Instead, mass-market RISC systems would follow sometime later. After Gassée left Apple in early 1990, the goal of the Jaguar project was refocused to be a mainstream Macintosh system instead of a new platform. The Jaguar project was folded into the Macintosh team in early 1991. While the Jaguar project itself never came to fruition, and Taligent never resulted in a functional operating system, many of the elements originally developed by the Jaguar hardware and software teams were brought to market in mid-1993 with the Centris 660AV and Quadra 840AV, including the Apple Adjustable Keyboard, Apple AudioVision 14 Display, GeoPort, and PlainTalk. The new case designs introduced with the Centris 610 and Quadra 800 had also originated in the Jaguar team.

By mid-1991, there was internal concern at Apple that the 88100 may not be the correct processor to move forward with as no other computer manufacturers had committed to using the processor. Using IBM's POWER was again considered, but it was a seven-chip design at the time, which was not desirable from a cost perspective. Engineers from Apple and IBM's Advanced Workstations and Systems Division met in Austin, Texas to discuss creating a single-chip version of IBM's POWER1 RISC architecture. Motorola was also present at Apple's request. IBM had already been working on such a chip, called the RISC Single Chip (RSC), in an effort to reduce production cost of their entry-level RS/6000 workstation systems. In these meetings, a number of changes were proposed to RSC that would facilitate lower costs, lower power usage, and higher yield production suitable for both the Macintosh and future RS/6000 products.

In early July, executives at the three companies reached an agreement which was formally announced to the public in October. In addition to the new RISC architecture, which was given the name PowerPC, this "AIM alliance" had several goals, including creating an operating system based on Pink, an object-oriented scripting language called ScriptX, and a cross-platform media player called the Kaleida Media Player. Of the alliance, John Sculley said, "The Macintosh strategy paid off very well for us in the 1980s, but we didn't think we could establish the next generation of computing by using that model in the 1990s. Working with IBM, and making it available to everyone, we can have a much wider impact with these technologies than we did with the Macintosh."

Development of the PowerPC 601 chip started in October 1991 and was completed in 21 months, with volume production starting in July 1993. The first computers to ship with a PowerPC chip were a line of IBM RS/6000 workstations in September 1993. Many Macintosh application developers used these machines for development of the initial PowerPC ports of their products, as Macintosh-based PowerPC development tools were not ready. The PowerPC 603 (which focused on lowering power usage) and 604 (which focused on high performance) projects were also underway at the same time.

In July 1992, the decision was made to scale back the ambition of the initial system software release; instead of attempting to create a completely new kernel, Apple focused on producing a version of System 7 where portions of the existing Macintosh Toolbox ROM were rewritten to use native PowerPC code instead of emulating a 680x0. This provided a significant performance boost for certain highly utilized parts of the operating system, particularly QuickDraw.

The first public demonstration of the new Power Macintosh — specifically, a prototype of what would become the Power Macintosh 6100 – was at an Apple Pacific sales meeting in Hawaii in October 1992. The demo was a success, and in the following months, the product plan expanded to include three models: the entry-level 6100, a mid-range 7100 housed in the Macintosh IIvx's desktop case, and a high-end 8100 based on the Quadra 800's mini-tower case. A fourth project, the Macintosh Processor Upgrade Card, was started in July 1993 with the goal of providing a straightforward upgrade path to owners of Centris- and Quadra-based Macintosh computers. The importance of this was especially significant for the Quadra 700, 900 and 950, which were not going to receive full logic board replacements. Computers upgraded in this fashion received new names such as "Power Macintosh Q650" and "Power Macintosh 900".

The original plan was to release the first Power Macintosh machine on January 24, 1994, exactly ten years after the release of the first Macintosh. Ian Diery, who was EVP and general manager of the Personal Computer Division at the time, moved the release date back to March 14 in order to give manufacturing enough time to build enough machines to fill the sales channels, and to ensure that the Macintosh Processor Upgrade Card would be available at the same time. This was a departure from prior practice at Apple; they had typically released upgrade packages months after the introduction of new Macintoshes.

The Power Macintosh was formally introduced at the Lincoln Center for the Performing Arts in Manhattan on March 14. Pre-orders for the new Power Macintosh models were brisk, with an announced 150,000 machines already having been sold by that date. MacWorld's review of the 6100/60 noted that "Not only has Apple finally regained the performance lead it lost about eight years ago when PCs appeared using Intel's 80386 CPU, but it has pushed far ahead." Performance of 680x0 software is slower due to the emulation layer, but MacWorld's benchmarks showed noticeably faster CPU, disk, video and floating point performance than the Quadra 610 it replaced. By January 1995, Apple had sold 1 million Power Macintosh systems.

Speed-bumped versions of the Power Macintosh line were introduced at the beginning of 1995, followed in April by the first PowerPC 603 models: an all-in-one model called the Power Macintosh 5200 LC and a replacement for the Quadra 630 called the Power Macintosh 6200. Performa variants of these machines were sold as well, continuing the practice of re-branding other Macintosh models for sale in department stores and big-box electronics retailers. While the 5200 LC was well-received by critics for its design, performance, and cost, both it and the 6200 suffered from stability issues (and in the case of the 5200, display issues as well) that could only be solved by bringing the machine to an Apple dealer for replacement parts.

By mid-1995, the burgeoning Power Macintosh line had all but completely supplanted every prior Macintosh line, with only the high-end Quadra 950 and two low-cost education models (the all-in-one Macintosh LC 580 and desktop LC 630) remaining in production. The competitive marketplace for "accelerator cards" that had existed for earlier Macintosh systems largely disappeared due to the comparatively low price of Apple's Macintosh Processor Upgrade Card (US$600). DayStar Digital sold upgrade cards for the IIci and various Quadra models, and full motherboard replacements were available from Apple as well. Macintosh clones from companies like DayStar Digital and Power Computing were also coming to the market at this time, undercutting Apple's prices.

When the Power Macintosh was introduced, it included the same internal and external expansion connections as other Macintosh models, all of which (save for audio input and output) were either wholly proprietary to, or largely exclusive to Apple computers. Over the next five years, Apple replaced all these ports with industry-standard connectors.

The first generation of Power Macintoshes had shipped with NuBus, but by the end of 1993 it was becoming clear that Intel's PCI bus was going to be the widely adopted future of internal expansion. Apple's position as a relatively small player in the larger personal computer market meant that few device manufacturers invested in creating both NuBus- and PCI-compatible versions of their cards. The first PCI-based system was the range-topping Power Macintosh 9500, introduced in May 1995. This was followed shortly afterwards by the introduction of the "Power Surge" line of second-generation Power Macintosh systems – the Power Macintosh 7200, 7500 and 8500. The 8500 and 9500 were built around the new PowerPC 604, offering speeds starting at 120 MHz. InfoWorld's review of the 8500 showed a speed improvement in their "business applications suite" benchmark from 10 minutes with the 8100/100, to 7:37 for the 8500/120. They also noted that the 8500 runs an average of 24 to 44 percent faster than a similarly-clocked Intel Pentium chip, increasing to double on graphics and publishing tasks.

The transition to PCI continued into 1996, with the introduction of the all-in-one 5400, desktop 6300/160 (usually sold as a Performa 6360), and mini-tower 6400 models. The success of the Macintosh clone market also prompted Apple to produce its own inexpensive machine using parts and production techniques that were common in both the clone market and the Wintel desktop market at the time. The Power Macintosh 4400 (sold as a 7220 in Asia and Australia) employed bent sheet metal instead of plastic for its case internals, and included a standard ATX power supply.

Alongside the transition to PCI, Apple began a gradual transition away from SCSI hard disks to IDE as a cost-saving measure, both for themselves and for users who wanted to upgrade their hard drives. The low-end 5200 and 6200 were the first to adopt IDE internal drives, though Apple's proprietary 25-pin external SCSI connector remained. The beige Power Macintosh G3 models being the last to include SCSI drives as standard, and it was the last Macintosh to include the external SCSI connector. When the Power Macintosh G3 (Blue and White) was introduced in early 1999, the port was replaced by two FireWire 400 ports. The Blue and White G3 was also the last Macintosh to include Apple Desktop Bus ports, a proprietary technology created by Steve Wozniak to connect keyboards, mice and software protection dongles such as those from Avid Technology. Two USB ports were also included, making this the only Power Macintosh to include both ADB and USB.

Another port that was retired during this time is the Apple Attachment Unit Interface. This was a proprietary version of the industry-standard Attachment Unit Interface connector for 10BASE5 Ethernet that Apple had created to avoid confusion with the 15-pin connector that Apple used for connecting external displays. The AAUI port required a costly external transceiver to connect to a network. By the early 1990s, the networking industry was coalescing around the 10BASE-T connector, leading Apple to include this port alongside AAUI in mid-1995, starting with the Power Macintosh 9500. The Power Macintosh G3 excluded the AAUI port.

The Power Mac G4 (AGP Graphics) was released in the second half of 1999; it was the first Power Macintosh to include only industry-standard internal and external expansion. For some years afterwards, a number of third parties created dongles that provided backwards compatibility to users of newer Power Mac systems with old hardware. This included companies like Griffin Technology, MacAlly Perhiperals, Rose Electronics and many others. In some cases, these companies produced adapters that matched the aesthetic design of the Power Mac.

Shortly after Steve Jobs' return to Apple in 1997, Jony Ive was appointed senior vice president of industrial design. Building on the critical and commercial success of the iMac, Ive and his team created an entirely new case design for the Power Macintosh G3, combining many of the aesthetic principles of the iMac (curves, translucent plastics, use of color) with the ease-of-access characteristics of the company's popular "Outrigger" Macintosh models from previous years. The result was the Power Macintosh G3 (Blue and White), a machine that received considerable plaudits from reviewers, including PC Magazine's Technical Excellence Award for 1999. "The Power Mac provides the fastest access to the insides of a computer we've ever seen," they wrote. "Just lift a handle and a hinged door reveals everything inside." This case design, code-named "El Capitan", was retained through the entire lifetime of the Power Mac G4. The introduction of the Blue and White G3 mini-tower also marked the end of the desktop and all-in-one Power Macintosh case designs, the latter being replaced by the iMac.

A second model called the Power Mac G4 Cube was introduced in 2000, which fitted the specifications of a mid-range Power Mac G4 into a cube less than 9" in each axis. This model was on sale for about a year before being discontinued, and was not considered a sales success (150,000 units were sold, about one-third of Apple's projections), but the distinctive design of both the computer and its accompanying Harman Kardon speakers prompted the Museum of Modern Art in New York City to retain them in their collection.

The PowerPC chips in the G3 and G4 became a central part of Apple's branding and marketing for the Power Macintosh. For example, the Blue and White G3 features the letters "G3" on the side that are fully one-third the height of the entire case, a significant departure from the small labels typically used on prior Macintosh computers. And when the Power Mac G4 was introduced, print ads included pictures of the G4 chip and mentioned its AltiVec instruction set by its own marketing name, "Velocity Engine". A related element of Apple's marketing strategy, especially after mid-2001, was to highlight what they described as the "Megahertz myth", challenging the belief that a processor's clock speed is directly correlated with performance. This had become important with the introduction of Intel's Pentium 4, which featured significantly higher clock speeds than competing chips from Sun, IBM, and AMD, but without a corresponding performance benefit.

The company's public presentations -- Stevenotes in particular—often featured lengthy segments pitting a high-powered Compaq or Dell computer against the Power Macintosh in a series of benchmarks and scripted tasks, usually in Adobe Photoshop. These presentations often showed the Power Macintosh besting Intel's Pentium chips by margins significantly exceeding 50%, but independent benchmarks did not bear this out. InfoWorld reviewer Jennifer Plonka reported that the 400 MHz G3 was 11% slower than a comparably-specced Pentium II-450 in an Office applications suite test, while Photoshop 5.0 was faster by 26%. And in 2003, Maximum PC ran a variety of gaming, Photoshop and LightWave 3D benchmarks, and reported that the Dual 1.25 GHz G4 system was about half the speed of a dual-processor Intel Xeon Prestonia 2.8 GHz system. A related criticism leveled at Power Mac systems from this time, particularly the G4 Mirrored Drive Doors, was the increased fan noise level compared to older systems.

By the time the Power Mac G5 was unveiled at Apple's Worldwide Developers Conference in July 2003, Apple's desktop range had fallen significantly behind competing computers in performance. The G5 closed much of this gap by moving to the PowerPC 970 processor with clock speeds up to 2.0 GHz, and a full 64-bit architecture. It also introduced a significantly revised enclosure design, replacing the use of plastics with anodized aluminum alloy.

Reviews were generally positive. InfoWorld described the G5 as "Apple's best work yet", and said it "delivers on the present need for rapid computing, deep multitasking, and responsive user interfaces — as well as the future need for mainstream computers that rapidly process and analyze massive data sets." PC Magazine again awarded the Power Mac G5 with its Award for Technical Excellence for 2003. However, the G5's heavy weight (10 pounds more than the previous year's Quicksilver Power Mac G4), limited internal expansion options, issues with ground loop, and noise in the single-processor models' power supply units resulted in significant criticism of the product. Apple also continued to make unsubstantiated performance claims about the new Power Mac. This resulted in the Advertising Standards Authority for the United Kingdom banning Apple from using the phrase "the world's fastest, most powerful personal computer" to describe the Power Mac G5 after independent tests carried out by the Broadcast Advertising Clearance Centre determined the claim to be false. Another claim made by Steve Jobs at the 2003 Worldwide Developers Conference was that the company would be selling a 3 GHz G5 by mid-2004; this never happened.

Three generations of Power Mac G5 were released before it was discontinued during the Mac transition to Intel processors. The announcement of the transition came in mid-2005, but the third generation of G5 systems was introduced towards the end of 2005. Most notably in this generation was the introduction of a Quad-core 2.5 GHz system. Not only was this the first Apple computer with four processing cores, it was the first to incorporate PCI Express instead of PCI-X for internal expansion. It also required an IEC 60320 C19 power connector that was more common on rackmounted server hardware, instead of the industry-standard C13 connector used with personal computers.

The official end to the Power Macintosh line came at the 2006 Worldwide Developers Conference, where Phil Schiller introduced its replacement, the Mac Pro. The G5's enclosure design was retained for the Mac Pro and continued to be used for seven more years, making it among the longest-lived designs in Apple's history.

The Power Macintosh models can be broadly classified into two categories, depending on whether they were released before or after Apple introduced its "four quadrant" product strategy in 1998. Before the introduction of the Power Macintosh G3 (Blue and White) in 1999, Apple had shipped Power Macintosh-labelled machines in nine different form factors, some of which were carry-overs from pre-PowerPC product lines, such as the Quadra/Centris 610 and the IIvx. This was reduced to one model in the new product strategy, with the exception of the Power Mac G4 Cube in 2000 and 2001.

Apple named Power Macintosh models from this period after the first pre-PowerPC model of Macintosh to use a particular form factor, followed by a slash and the speed of the CPU. For example, the Power Macintosh 6300/120 uses the Quadra 630's form factor and has a CPU.

Machines with "AV" in their name denote variants that include extended audio-video capabilities.

Machines with "PC Compatible" in their name include a separate card with an x86-compatible CPU; these models are therefore capable of running MS-DOS and Microsoft Windows applications, typically Windows 3.1.

Machines with "MP" in their name denote machines that include two CPUs.

These early models had two distinct generations. The first generation uses the PowerPC 601 and 603 processors and used the old NuBus expansion slots, while the second generation uses the faster 603e, 604 and 604e chips as well as industry-standard PCI expansion slots. The second generation also makes use of Open Firmware, allowing them to more easily boot alternate operating systems (including OS X via XPostFacto), though use of various hacks was still necessary.

The PM 4400 is a desktop case with a height of , suitable for horizontal placement with a monitor on top.

The PM 5200 is an all-in-one form factor with specifications and internal designs similar to the Quadra 630. Collectively these machines are sometimes referred to as the "Power Macintosh/Performa 5000 series".

The Centris 610 form factor is a low-profile "pizza-box" design with a height of , intended to be placed on a desktop with a monitor on top.

The Quadra 630 form factor is a horizontally-oriented design with a height of , suitable for placing a monitor on top.

The Performa 6400 form factor is a mini-tower design, suitable for being placed beside a monitor.

The IIvx form factor is a horizontally-oriented desktop form factor with a height of , suitable for placing a monitor on top.

The PM 7500 form factor is a horizontally-oriented desktop design with a height of , suitable for placing a monitor on top.

The Quadra 800 form factor is a mini-tower design, with a width of .


The PM 9600 form factor is a mini-tower design with a width of .

Starting with the Power Macintosh G3, Apple changed its product naming to include the generation of PowerPC CPU, with the name of the form factor or a key feature afterwards in brackets. The Power Mac G5's name was changed to incorporate the time period in which the model was released. The all-in-one models would eventually be spun off into the iMac line, whilst the compact form factor models would be spun off into the Mac Mini.

The Power Mac brand name was used for Apple's high-end tower style computers, targeted primarily at businesses and creative professionals, in differentiation to their more compact "iMac" line (intended for home use) and the "eMac" line (for the education markets). They were usually equipped with Apple's newest technologies, and commanded the highest prices among Apple desktop models. Some Power Mac G4 and G5 models were offered in dual-processor configurations.

Prior to the "Power Mac" name change, certain "Power Macintosh" models were otherwise identical to their lower-cost re-branded siblings sold as the Macintosh LC and Macintosh Performa, as well as the dedicated Apple Workgroup Server and Macintosh Server G3 & G4 lines. Other past Macintosh lines which used PowerPC processors include the PowerBook 5300 and later models, iMac, iBook and Xserve as well as the Apple Network Server, which was technically not a Macintosh.

Apple positioned the Power Macintosh as a high-end personal computer aimed at businesses and creative professionals with an advertising campaign consisting of several television commercials and print ads. The television commercials used the slogan ""The Future Is Better Than You Expected"", featuring the first three Power Macintosh computers to showcase special features such as networking and MS-DOS compatibility.

In 1993 and 1994, a television advertising campaign created by BBDO aired with the slogan "It does more, it costs less, it's that simple."




</doc>
<doc id="24888" url="https://en.wikipedia.org/wiki?curid=24888" title="Promoter (genetics)">
Promoter (genetics)

In genetics, a promoter is a sequence of DNA to which proteins bind that initiate transcription of a single RNA from the DNA downstream of it. This RNA may encode a protein, or can have a function in and of itself, such as tRNA, mRNA, or rRNA. Promoters are located near the transcription start sites of genes, upstream on the DNA (towards the 5' region of the sense strand).
Promoters can be about 100–1000 base pairs long.

For transcription to take place, the enzyme that synthesizes RNA, known as RNA polymerase, must attach to the DNA near a gene. Promoters contain specific DNA sequences such as response elements that provide a secure initial binding site for RNA polymerase and for proteins called transcription factors that recruit RNA polymerase. These transcription factors have specific activator or repressor sequences of corresponding nucleotides that attach to specific promoters and regulate gene expression.


Promoters represent critical elements that can work in concert with other regulatory regions (enhancers, silencers, boundary elements/insulators) to direct the level of transcription of a given gene.
A promoter is induced in response to changes in abundance or conformation of regulatory proteins in a cell, which enable activating transcription factors to recruit RNA polymerase.

As promoters are typically immediately adjacent to the gene in question, positions in the promoter are designated relative to the transcriptional start site, where transcription of DNA begins for a particular gene (i.e., positions upstream are negative numbers counting back from -1, for example -100 is a position 100 base pairs upstream).

In the cell nucleus, it seems that promoters are distributed preferentially at the edge of the chromosomal territories, likely for the co-expression of genes on different chromosomes. Furthermore, in humans, promoters show certain structural features characteristic for each chromosome.


In bacteria, the promoter contains two short sequence elements approximately 10 (Pribnow Box) and 35 nucleotides "upstream" from the transcription start site.


The above promoter sequences are recognized only by RNA polymerase holoenzyme containing sigma-70. RNA polymerase holoenzymes containing other sigma factors recognize different core promoter sequences.

 for -10 sequence

Eukaryotic promoters are diverse and can be difficult to characterize, however, recent studies show that they are divided in more than 10 classes.

Gene promoters are typically located upstream of the gene and can have regulatory elements several kilobases away from the transcriptional start site (enhancers). In eukaryotes, the transcriptional complex can cause the DNA to bend back on itself, which allows for placement of regulatory sequences far from the actual site of transcription. Eukaryotic RNA-polymerase-II-dependent promoters can contain a TATA element (consensus sequence TATAAA), which is recognized by the general transcription factor TATA-binding protein (TBP); and a B recognition element (BRE), which is recognized by the general transcription factor TFIIB. The TATA element and BRE typically are located close to the transcriptional start site (typically within 30 to 40 base pairs).

Eukaryotic promoter regulatory sequences typically bind proteins called transcription factors that are involved in the formation of the transcriptional complex. An example is the E-box (sequence CACGTG), which binds transcription factors in the basic helix-loop-helix (bHLH) family (e.g. BMAL1-Clock, cMyc). Some promoters that are targeted by multiple transcription factors might achieve a hyperactive state, leading to increased transcriptional activity.

Bidirectional promoters are short (<1 kbp) intergenic regions of DNA between the 5' ends of the genes in a bidirectional gene pair. A “bidirectional gene pair” refers to two adjacent genes coded on opposite strands, with their 5' ends oriented toward one another. The two genes are often functionally related, and modification of their shared promoter region allows them to be co-regulated and thus co-expressed. Bidirectional promoters are a common feature of mammalian genomes. About 11% of human genes are bidirectionally paired.

Bidirectionally paired genes in the Gene Ontology database shared at least one database-assigned functional category with their partners 47% of the time. Microarray analysis has shown bidirectionally paired genes to be co-expressed to a higher degree than random genes or neighboring unidirectional genes. Although co-expression does not necessarily indicate co-regulation, methylation of bidirectional promoter regions has been shown to downregulate both genes, and demethylation to upregulate both genes. There are exceptions to this, however. In some cases (about 11%), only one gene of a bidirectional pair is expressed. In these cases, the promoter is implicated in suppression of the non-expressed gene. The mechanism behind this could be competition for the same polymerases, or chromatin modification. Divergent transcription could shift nucleosomes to upregulate transcription of one gene, or remove bound transcription factors to downregulate transcription of one gene.

Some functional classes of genes are more likely to be bidirectionally paired than others. Genes implicated in DNA repair are five times more likely to be regulated by bidirectional promoters than by unidirectional promoters. Chaperone proteins are three times more likely, and mitochondrial genes are more than twice as likely. Many basic housekeeping and cellular metabolic genes are regulated by bidirectional promoters.
The overrepresentation of bidirectionally paired DNA repair genes associates these promoters with cancer. Forty-five percent of human somatic oncogenes seem to be regulated by bidirectional promoters – significantly more than non-cancer causing genes. Hypermethylation of the promoters between gene pairs WNT9A/CD558500, CTDSPL/BC040563, and KCNK15/BF195580 has been associated with tumors.

Certain sequence characteristics have been observed in bidirectional promoters, including a lack of TATA boxes, an abundance of CpG islands, and a symmetry around the midpoint of dominant Cs and As on one side and Gs and Ts on the other. A motif with the consensus sequence of TCTCGCGAGA, also called the CGCG element, was recently shown to drive PolII-driven bidirectional transcription in CpG islands. CCAAT boxes are common, as they are in many promoters that lack TATA boxes. In addition, the motifs NRF-1, GABPA, YY1, and ACTACAnnTCCC are represented in bidirectional promoters at significantly higher rates than in unidirectional promoters. The absence of TATA boxes in bidirectional promoters suggests that TATA boxes play a role in determining the directionality of promoters, but counterexamples of bidirectional promoters do possess TATA boxes and unidirectional promoters without them indicates that they cannot be the only factor.

Although the term "bidirectional promoter" refers specifically to promoter regions of mRNA-encoding genes, luciferase assays have shown that over half of human genes do not have a strong directional bias. Research suggests that non-coding RNAs are frequently associated with the promoter regions of mRNA-encoding genes. It has been hypothesized that the recruitment and initiation of RNA polymerase II usually begins bidirectionally, but divergent transcription is halted at a checkpoint later during elongation. Possible mechanisms behind this regulation include sequences in the promoter region, chromatin modification, and the spatial orientation of the DNA.

A subgenomic promoter is a promoter added to a virus for a specific heterologous gene, resulting in the formation of mRNA for that gene alone. Many positive-sense RNA viruses produce these subgenomic mRNAs (sgRNA) as one of the common infection techniques used by these viruses and generally transcribe late viral genes. Subgenomic promoters range from 24 nucleotide (Sindbis virus) to over 100 nucleotides (Beet necrotic yellow vein virus) and are usually found upstream of the transcription start.

A wide variety of algorithms have been developed to facilitate detection of promoters in genomic sequence, and promoter prediction is a common element of many gene prediction methods. A promoter region is located before the -35 and -10 Consensus sequences. The closer the promoter region is to the consensus sequences the more often transcription of that gene will take place. There is not a set pattern for promoter regions as there are for consensus sequences.

Changes in promoter sequences are critical in evolution as indicated by the relatively stable number of genes in many lineages. For instance, most vertebrates have roughly the same number of protein-coding genes (about 20,000) which are often highly conserved in sequence, hence much of evolutionary change must come from changes in gene expression.

Given the short sequences of most promoter elements, promoters can rapidly evolve from random sequences. For instance, in "E. coli", ~60% of random sequences can evolve expression levels comparable to the wild-type lac promoter with only one mutation, and that ~10% of random sequences can serve as active promoters even without evolution.

Other recent studies suggest that promoters of genes may be the primary cause of diabetes. Promoters of genes associated with diabetes by Genome-wide association studies (GWAS) show specific DNA patterns for each phenotype. This observation indicates that the promoters of these genes use specific transcription factors for each diabetes phenotype.

The initiation of the transcription is a multistep sequential process that involves several mechanisms: promoter location, initial reversible binding of RNA polymerase, conformational changes in RNA polymerase, conformational changes in DNA, binding of nucleoside triphosphate (NTP) to the functional RNA polymerase-promoter complex, and nonproductive and productive initiation of RNA synthesis.

The promoter binding process is crucial in the understanding of the process of gene expression.

Although RNA polymerase holoenzyme shows high affinity to non-specific sites of the DNA, this characteristic does not allow us to clarify the process of promoter location. This process of promoter location has been attributed to the structure of the holoenzyme to DNA and sigma 4 to DNA complexes.

Most diseases are heterogeneous in cause, meaning that one "disease" is often many different diseases at the molecular level, though symptoms exhibited and response to treatment may be identical. How diseases of different molecular origin respond to treatments is partially addressed in the discipline of pharmacogenomics.

Not listed here are the many kinds of cancers involving aberrant transcriptional regulation owing to creation of chimeric genes through pathological chromosomal translocation. Importantly, intervention in the number or structure of promoter-bound proteins is one key to treating a disease without affecting expression of unrelated genes sharing elements with the target gene. Some genes whose change is not desirable are capable of influencing the potential of a cell to become cancerous.

In humans, about 70% of promoters located near the transcription start site of a gene (proximal promoters) contain a CpG island. CpG islands are generally 200 to 2000 base pairs long, have a C:G base pair content >50%, and have regions of DNA where a cytosine nucleotide is followed by a guanine nucleotide and this occurs frequently in the linear sequence of bases along its 5' → 3' direction.

Distal promoters also frequently contain CpG islands, such as the promoter of the DNA repair gene "ERCC1", where the CpG island-containing promoter is located about 5,400 nucleotides upstream of the coding region of the "ERCC1" gene. CpG islands also occur frequently in promoters for functional noncoding RNAs such as microRNAs.

In humans, DNA methylation occurs at the 5' position of the pyrimidine ring of the cytosine residues within CpG sites to form 5-methylcytosines. The presence of multiple methylated CpG sites in CpG islands of promoters causes stable silencing of genes. Silencing of a gene may be initiated by other mechanisms, but this is often followed by methylation of CpG sites in the promoter CpG island to cause the stable silencing of the gene.

Generally, in progression to cancer, hundreds of genes are silenced or activated. Although silencing of some genes in cancers occurs by mutation, a large proportion of carcinogenic gene silencing is a result of altered DNA methylation (see DNA methylation in cancer). DNA methylation causing silencing in cancer typically occurs at multiple CpG sites in the CpG islands that are present in the promoters of protein coding genes.

Altered expressions of microRNAs also silence or activate many genes in progression to cancer (see microRNAs in cancer). Altered microRNA expression occurs through hyper/hypo-methylation of CpG sites in CpG islands in promoters controlling transcription of the microRNAs.

Silencing of DNA repair genes through methylation of CpG islands in their promoters appears to be especially important in progression to cancer (see methylation of DNA repair genes in cancer).

The usage of the term canonical sequence to refer to a promoter is often problematic, and can lead to misunderstandings about promoter sequences. Canonical implies perfect, in some sense.

In the case of a transcription factor binding site, there may be a single sequence that binds the protein most strongly under specified cellular conditions. This might be called canonical.

However, natural selection may favor less energetic binding as a way of regulating transcriptional output. In this case, we may call the most common sequence in a population the wild-type sequence. It may not even be the most advantageous sequence to have under prevailing conditions.

Recent evidence also indicates that several genes (including the proto-oncogene c-myc) have G-quadruplex motifs as potential regulatory signals.

Some cases of many genetic diseases are associated with variations in promoters or transcription factors.

Examples include:

Some promoters are called constitutive as they are active in all circumstances in the cell, while others are regulated, becoming active in the cell only in response to specific stimuli.

When referring to a promoter some authors actually mean promoter + operator; i.e., the lac promoter is IPTG inducible, meaning that besides the lac promoter, the lac operator is also present. If the lac operator were not present the IPTG would not have an inducible effect.
Another example is the Tac-Promoter system (Ptac). Notice how tac is written as a tac promoter, while in fact tac is actually both a promoter and an operator.



</doc>
<doc id="24893" url="https://en.wikipedia.org/wiki?curid=24893" title="Adobe Photoshop">
Adobe Photoshop

Adobe Photoshop is a raster graphics editor developed and published by Adobe Inc. for Windows and macOS. It was originally created in 1988 by Thomas and John Knoll. Since then, the software has become the industry standard not only in raster graphics editing, but in digital art as a whole. The software's name has thus become a generic trademark, leading to its usage as a verb (e.g. "to photoshop an image", "photoshopping", and "photoshop contest") although Adobe discourages such use. Photoshop can edit and compose raster images in multiple layers and supports masks, alpha compositing and several color models including RGB, CMYK, CIELAB, spot color, and duotone. Photoshop uses its own PSD and PSB file formats to support these features. In addition to raster graphics, Photoshop has limited abilities to edit or render text and vector graphics (especially through clipping path for the latter), as well as 3D graphics and video. Its feature set can be expanded by plug-ins; programs developed and distributed independently of Photoshop that run inside it and offer new or enhanced features.

Photoshop's naming scheme was initially based on version numbers. However, in October 2002 (following the introduction of Creative Suite branding), each new version of Photoshop was designated with "CS" plus a number; e.g., the eighth major version of Photoshop was Photoshop CS and the ninth was Photoshop CS2. Photoshop CS3 through CS6 were also distributed in two different editions: Standard and Extended. With the introduction of the Creative Cloud branding in June 2013 (and in turn, the change of the "CS" suffix to "CC"), Photoshop's licensing scheme was changed to that of software as a service rental model. Historically, Photoshop was bundled with additional software such as Adobe ImageReady, Adobe Fireworks, Adobe Bridge, Adobe Device Central and Adobe Camera RAW.

Alongside Photoshop, Adobe also develops and publishes Photoshop Elements, Photoshop Lightroom, Photoshop Express, Photoshop Fix, Photoshop Sketch and Photoshop Mix. As of November 2019, Adobe has also released a full version of Photoshop for the iPad, and while initially limited, Adobe plans to bring more features to Photoshop for iPad. Collectively, they are branded as "The Adobe Photoshop Family".

Photoshop was developed in 1987 by two brothers Thomas and John Knoll, who sold the distribution license to Adobe Systems Incorporated in 1988. Thomas Knoll, a Ph.D. student at the University of Michigan, began writing a program on his Macintosh Plus to display grayscale images on a monochrome display. This program (at that time called Display) caught the attention of his brother John, an Industrial Light & Magic employee, who recommended that Thomas turn it into a full-fledged image editing program. Thomas took a six-month break from his studies in 1988 to collaborate with his brother on the program. Thomas renamed the program ImagePro, but the name was already taken. Later that year, Thomas renamed his program Photoshop and worked out a short-term deal with scanner manufacturer Barneyscan to distribute copies of the program with a slide scanner; a "total of about 200 copies of Photoshop were shipped" this way.

During this time, John traveled to Silicon Valley and gave a demonstration of the program to engineers at Apple and Russell Brown, art director at Adobe. Both showings were successful, and Adobe decided to purchase the license to distribute in September 1988. While John worked on plug-ins in California, Thomas remained in Ann Arbor writing code. "Photoshop" 1.0 was released on February 19, 1990 for Macintosh exclusively. The Barneyscan version included advanced color editing features that were stripped from the first Adobe shipped version. The handling of color slowly improved with each release from Adobe and Photoshop quickly became the industry standard in digital color editing. At the time Photoshop 1.0 was released, digital retouching on dedicated high-end systems (such as the Scitex) cost around $300 an hour for basic photo retouching. The list price of Photoshop 1.0 for Macintosh in 1990 was $895.

Photoshop was initially only available on Macintosh. In 1993, Adobe chief architect Seetharaman Narayanan ported Photoshop to Microsoft Windows. The Windows port led to Photoshop reaching a wider mass market audience as Microsoft's global reach expanded within the next few years.

Photoshop files have default file extension as .PSD, which stands for "PhotoShop Document". A PSD file stores an image with support for most imaging options available in Photoshop. These include layers with masks, transparency, text, alpha channels and spot colors, clipping paths, and duotone settings. This is in contrast to many other file formats (e.g., .JPG or .GIF) that restrict content to provide streamlined, predictable functionality. A PSD file has a maximum height and width of 30,000 pixels, and a length limit of two gigabytes.

Photoshop files sometimes have the file extension .PSB, which stands for "PhotoShop Big" (also known as "large document format"). A PSB file extends the PSD file format, increasing the maximum height and width to 300,000 pixels and the length limit to around 4 Exabytes. The dimension limit was apparently chosen arbitrarily by Adobe, not based on computer arithmetic constraints (it is not close to a power of two, as is 30,000) but for ease of software testing. PSD and PSB formats are documented.

Because of Photoshop's popularity, PSD files are widely used and supported to some extent by most competing software, including Open-source / Free software such as GIMP. The .PSD file format can be exported to and from Adobe's other apps like Adobe Illustrator, Adobe Premiere Pro, and After Effects.

Photoshop functionality can be extended by add-on programs called Photoshop plugins (or plug-ins). Adobe creates some plugins, such as Adobe Camera Raw, but third-party companies develop most plugins, according to Adobe's specifications. Some are free and some are commercial software.
Most plugins work with only Photoshop or Photoshop-compatible hosts, but a few can also be run as standalone applications.

There are various types of plugins, such as filter, export, import, selection, color correction, and automation. The most popular plugins are the filter plugins (also known as a 8bf plugins), available under the Filter menu in Photoshop.
Filter plugins can either modify the current image or create content. Below are some popular types of plugins, and some well-known companies associated with them:

Adobe Camera Raw (also known as ACR and Camera Raw) is a special plugin, supplied free by Adobe, used primarily to read and process raw image files so that the resulting images can be processed by Photoshop. It can also be used from within Adobe Bridge.

Upon loading Photoshop, a sidebar with a variety of tools with multiple image-editing functions appears to the left of the screen. These tools typically fall under the categories of drawing; painting; measuring and navigation; selection; typing; and retouching. Some tools contain a small triangle in the bottom right of the toolbox icon. These can be expanded to reveal similar tools. While newer versions of Photoshop are updated to include new tools and features, several recurring tools that exist in most versions are discussed below.

Photoshop includes a few versions of the "pen" tool. The pen tool creates precise paths that can be manipulated using anchor points. The "free form pen" tool allows the user to draw paths freehand, and with the "magnetic pen" tool, the drawn path attaches closely to outlines of objects in an image, which is useful for isolating them from a background.

The Clone Stamp tool duplicates one part of an image to another part of the same image by way of a brush. The duplication is either in full or in part depending on the mode. The user can also clone part of one layer to another layer. The Clone Stamp tool is useful for duplicating objects or removing a defect in an image.

Photoshop provides an array of shape tools including rectangles, rounded rectangles, ellipses, polygons and lines. These shapes can be manipulated by the pen tool, direct selection tool etc. to make vector graphics. In addition, Photoshop provides its own shapes like animals, signs and plants.

The "eyedropper" tool selects a color from an area of the image that is clicked, and samples it for future use. The "hand" tool navigates an image by moving it in any direction, and the "zoom" tool enlarges the part of an image that is clicked on, allowing for a closer view.

Selection tools are used to select all or any part of a picture to perform cut, copy, edit, or retouching operations.

The "crop" tool can be used to select a particular area of an image and discard the portions outside the chosen section. This tool assists in creating a focus point on an image and unnecessary or excess space. Cropping allows enhancement of a photo's composition while decreasing the file size. The "crop" tool is in the tools palette, which is located on the right side of the document. By placing the cursor over the image, the user can drag the cursor to the desired area. Once the Enter key is pressed, the area outside the rectangle will be cropped. The area outside the rectangle is the discarded data, which allows for the file size to be decreased. The "crop" tool can alternatively be used to extend the canvas size by clicking and dragging outside the existing image borders.

The "slice" and "slice select" tools, like the crop tool, are used in isolating parts of images. The "slice" tool can be used to divide an image into different sections, and these separate parts can be used as pieces of a web page design once HTML and CSS are applied. The "slice select" tool allows sliced sections of an image to be adjusted and shifted.

The move tool can be used to drag the entirety of a single layer or more if they are selected. Alternatively, once an area of an image is highlighted, the "move" tool can be used to manually relocate the selected piece to anywhere on the canvas.

The "marquee" is a tool that can make selections that are a single row, single column, rectangular and elliptical. An area that has been selected can be edited without affecting the rest of the image. This tool can also crop an image; it allows for better control. In contrast to the "crop" tool, the "marquee" tool allows for more adjustments to the selected area before cropping. The only "marquee" tool that does not allow cropping is the elliptical. Although the single row and column "marquee" tools allow for cropping, they are not ideal, because they only crop a line. The "rectangular marquee" tool is the preferred option. Once the tool has been selected, dragging the tool across the desired area will select it. The selected area will be outlined by dotted lines, referred to as "marching ants". To set a specific size or ratio, the tool options bar provides these settings. Before selecting an area, the desired size or ratio must be set by adjusting the width and height. Any changes such as color, filters, location, etc. should be made before cropping. To crop the selection, the user must go to the image tab and select crop.

The "lasso" tool is similar to the "marquee" tool, however, the user can make a custom selection by drawing it freehand. There are three options for the "lasso" tool – regular, polygonal, and magnetic. The regular "lasso" tool allows the user to have drawing capabilities. Photoshop will complete the selection once the mouse button is released. The user may also complete the selection by connecting the end point to the starting point. The "marching ants" will indicate if a selection has been made. The "polygonal lasso" tool will draw only straight lines, which makes it an ideal choice for images with many straight lines. Unlike the regular "lasso" tool, the user must continually click around the image to outline the shape. To complete the selection, the user must connect the end point to the starting point just like the regular lasso tool. "Magnetic lasso" tool is considered the smart tool. It can do the same as the other two, but it can also detect the edges of an image once the user selects a starting point. It detects by examining the color pixels as the cursor move over the desired area. Closing the selection is the same as the other two, which should also should display the "marching ants" once the selection has been closed.

The "quick selection" tool selects areas based on edges, similarly to the "magnetic lasso" tool. The difference between this tool and the "lasso" tool is that there is no starting and ending point. For this reason, the selected area can be added onto as much as possible without starting over. By dragging the cursor over the desired area, the "quick selection" tool detects the edges of the image. The "marching ants" allow the user to know what is currently being selected. Once the user is done, the selected area can be edited without affecting the rest of the image. One of the features that makes this tool especially user friendly is that the SHIFT key is not needed to add more to the selection; by default, extra mouse clicks will be added to the selection rather than creating a new selection.

The "magic wand" tool selects areas based on pixels of similar values. One click will select all neighboring pixels of similar value within a tolerance level set by the user. If the "eyedropper" tool is selected in the options bar, then the magic wand can determine the value needed to evaluate the pixels; this is based on the sample size setting in the "eyedropper" tool. This tool is inferior to the quick selection tool which works much the same but with much better results and more intuitive controls. The user must decide what settings to use or if the image is right for this tool.

The "Eraser" tool erases content based on the active layer. If the user is on the text layer, then any text across which the tool is dragged will be erased. The eraser will convert the pixels to transparent, unless the background layer is selected. The size and style of the eraser can be selected in the options bar. This tool is unique in that it can take the form of the paintbrush and pencil tools. In addition to the straight eraser tool, there are two more available options – background eraser and magic eraser. The "background eraser" deletes any part of the image that is on the edge of an object. This tool is often used to extract objects from the background. The "magic eraser" tool deletes based on similar colored pixels. It is very similar to the "magic wand" tool. This tool is ideal for deleting areas with the same color or tone that contrasts with the rest of the image.

In Adobe CS5 Extended edition, video editing is comprehensive and efficient with a broad compatibility of video file formats such as "MOV", "AVI" and "MPEG-4" formats and easy workflow. Using simple combinations of keys video layers can easily be modified, with other features such as adding text and creating animations using single images.

With the Extended version of Photoshop CS5, 2D elements of an artwork can easily become three-dimensional with the click of a button. Extrusions of texts, an available library of materials for three-dimensional, and even wrapping two-dimensional images around 3D geometry.

Third-party plugins have also been added to the most recent version of Photoshop where technologies such as the iPad have integrated the software with different types of applications. Applications like the Adobe Eazel painting app allows the user to easily create paintings with their fingertips and use an array of different paint from dry to wet in order to create rich color blending. In October 2018, it was announced that the full Photoshop engine will be released for iPad next year. The program will feature cloud syncing with other devices and a simpler interface than the desktop version.

With the Camera Raw plug-in, raw images can be processed without the use of Adobe Photoshop Lightroom, along with other image file formats such as "JPEG", "TIFF", or "PNG". The plug-in allows users to remove noise without the side-effect of over-sharpening, add grain, and even perform post-crop vignetting.

From version 14.1, users can create and edit designs for 3D printing. Artists can add color, adjust the shape or rotate the angles of imported models, or design original 3D models from scratch.

The Color Replacement Tool allows the user to change the color, while maintaining the highlights and shadows of the original image, of pieces of the image. By selecting Brushs and right clicking, the Color Replacement Tool is the third option down. What is important to note with this tool is the foreground color. The foreground color is what will be applied when painting along the chosen part of the image with the Color Replacement tool.

"Photoshop" and derivatives such as "Photoshopped" (or just "Shopped") have become verbs that are sometimes used to refer to images edited by Photoshop, or any image manipulating program. Such derivatives are discouraged by Adobe because, in order to maintain validity and protect the trademark from becoming generic, trademarks must be used as proper nouns.

Photoshop's naming scheme was initially based on version numbers, from version 0.07 (codename "Bond"; double-oh-seven), through version 0.87 (codename "Seurat" which was the first commercial version, sold as "Barneyscan XP"), version 1.0 (February 1990) all the way to version 7.0.1. Adobe published 7 major and many minor versions before the October 2003 introduction of version 8.0 which brought with it the Creative Suite branding.

Notable milestone features would be: Filters, Colour Separation, Virtual Memory (1.0), Paths, CMYK color (2.0), 16-bits-per-channel support, availability on Microsoft Windows (2.5), Layers, tabbed Palettes (3.0), Adjustments, Actions, Freeform Transform, PNG support (4.0), Editable Type, Magnetic Lasso and Pen, Freeform Pen, Multiple Undo, Layer Effects (5.0), Save For Web (5.5), Vector Shapes, revised User Interface (6.0), Vector Text, Healing Brush, Spell Check (7.0), Camera RAW (7.0.1).

In February 2013 Adobe donated the source code of the 1990 1.0.1 version of Photoshop to the Computer History Museum.
The first Photoshop CS was commercially released in October 2003 as the eighth major version of Photoshop. Photoshop CS increased user control with a reworked file browser augmenting search versatility, sorting and sharing capabilities and the Histogram Palette which monitors changes in the image as they are made to the document. Match Color was also introduced in CS, which reads color data to achieve a uniform expression throughout a series of pictures.
Photoshop CS2, released in May 2005, expanded on its predecessor with a new set of tools and features. It included an upgraded Spot Healing Brush, which is mainly used for handling common photographic problems such as blemishes, red-eye, noise, blurring and lens distortion. One of the most significant inclusions in CS2 was the implementation of Smart Objects, which allows users to scale and transform images and vector illustrations without losing image quality, as well as create linked duplicates of embedded graphics so that a single edit updates across multiple iterations.

Adobe responded to feedback from the professional media industry by implementing non-destructive editing as well as the producing and modifying of 32-Bit High Dynamic Range (HDR) images, which are optimal for 3D rendering and advanced compositing. FireWire Previews could also be viewed on a monitor via a direct export feature.

Photoshop CS2 brought the Vanishing Point and Image Warping tools. Vanishing Point makes tedious graphic and photo retouching endeavors much simpler by letting users clone, paint and transform image objects while maintaining visual perspective. Image Warping makes it easy to digitally distort an image into a shape by choosing on-demand presets or by dragging control points.

The File Browser was upgraded to Adobe Bridge, which functioned as a hub for productivity, imagery and creativity, providing multi-view file browsing and smooth cross-product integration across Adobe Creative Suite 2 software. Adobe Bridge also provided access to Adobe Stock Photos, a new stock photography service that offered users one-stop shopping across five elite stock image providers to deliver high-quality, royalty-free images for layout and design.

Camera Raw version 3.0 was a new addition in CS2, and it allowed settings for multiple raw files to be modified simultaneously. In addition, processing multiple raw files to other formats including JPEG, TIFF, DNG or PSD, could be done in the background without executing Photoshop itself.

Photoshop CS2 brought a streamlined interface, making it easier to access features for specific instances. In CS2 users were also given the ability to create their own custom presets, which was meant to save time and increase productivity.

CS2 activation servers' shutdown: In January 2013, Adobe Photoshop CS2 (9.0), with some other CS2 products, was released with an official serial number, due to the technical glitch in Adobe's CS2 activation servers (see Creative Suite 1 and 2).
CS3 improves on features from previous versions of Photoshop and introduces new tools. One of the most significant is the streamlined interface which allows increased performance, speed, and efficiency. There is also improved support for Camera RAW files which allow users to process images with higher speed and conversion quality. CS3 supports over 150 RAW formats as well as JPEG, TIFF and PDF. Enhancements were made to the Black and White Conversion, Brightness and Contrast Adjustment and Vanishing Point Module tools. The Black and White adjustment option improves control over manual grayscale conversions with a dialog box similar to that of Channel Mixer. There is more control over print options and better management with Adobe Bridge. The Clone Source palette is introduced, adding more options to the clone stamp tool. Other features include the nondestructive Smart Filters, optimizing graphics for mobile devices, Fill Light and Dust Busting tools. Compositing is assisted with Photoshop's new Quick Selection and Refine Edge tools and improved image stitching technology.

CS3 Extended includes everything in CS3 and additional features. There are tools for 3D graphic file formats, video enhancement and animation, and comprehensive image measurement and analysis tools with DICOM file support. The 3D graphic formats allow 3D content to be incorporated into 2D compositions. As for video editing, CS3 supports layers and video formatting so users can edit video files per frame.

CS3 and CS3 Extended were released in April 2007 to the United States and Canada. They were also made available through Adobe's online store and Adobe Authorized Resellers. Both CS3 and CS3 Extended are offered as either a stand-alone application or feature of Adobe Creative Suite. Both products are compatible with Intel-based Macs and PowerPCs, supporting Windows XP and Windows Vista. CS3 is the first release of Photoshop that will run natively on Macs with Intel processors: previous versions can only run through the translation layer Rosetta, and will not run at all on Macs running Mac OS X 10.7 or later.
CS4 features smoother panning and zooming, allowing faster image editing at a high magnification. The interface is more simplified with its tab-based interface making it cleaner to work with. Photoshop CS4 features a new 3D engine allowing the conversion of gradient maps to 3D objects, adding depth to layers and text, and getting print-quality output with the new ray-tracing rendering engine. It supports common 3D formats; the new Adjustment and Mask Panels; Content-aware scaling (seam carving); Fluid Canvas Rotation and File display options. The Content-aware scaling allows users to intelligently size and scale images, and the Canvas Rotation tool makes it easier to rotate and edit images from any angle.

Adobe released Photoshop CS4 Extended, which has the features of Adobe Photoshop CS4, plus capabilities for scientific imaging, 3D, motion graphics, accurate image analysis and high-end film and video users. The faster 3D engine allows users to paint directly on 3D models, wrap 2D images around 3D shapes and animate 3D objects. As the successor to Photoshop CS3, Photoshop CS4 is the first x64 edition of Photoshop on consumer computers for Windows. The color correction tool has also been improved significantly.

CS4 and CS4 Extended were released on October 15, 2008. They were also made available through Adobe's online store and Adobe Authorized Resellers. Both CS4 and CS4 Extended are offered as either a stand-alone application or feature of Adobe Creative Suite. Both products are compatible with Intel-based Mac OS X and PowerPCs, supporting Windows XP and Windows Vista.
Photoshop CS5 was launched on April 12, 2010. In a video posted on its official Facebook page, the development team revealed the new technologies under development, including three-dimensional brushes and warping tools.

In May 2011, Adobe Creative Suite 5.5 (CS5.5) was released, with new versions of some of the applications. Its version of Photoshop, 12.1, is identical to the concurrently released update for Photoshop CS5, version 12.0.4, except for support for the new subscription pricing that was introduced with CS5.5.

CS5 introduces new tools such as the Content-Aware Fill, Refine Edge, Mixer Brush, Bristle Tips and Puppet Warp. The community also had a hand in the additions made to CS5 as 30 new features and improvements were included by request. These include automatic image straightening, the Rule-of-Thirds cropping tool, color pickup, and saving a 16-bit image as a JPEG. Another feature includes the Adobe Mini Bridge, which allows for efficient file browsing and management.

CS5 Extended includes everything in CS5 plus features in 3D and video editing. A new materials library was added, providing more options such as Chrome, Glass, and Cork. The new Shadow Catcher tool can be used to further enhance 3D objects. For motion graphics, the tools can be applied to over more than one frame in a video sequence.

CS5 and CS5 Extended were made available through Adobe's online store, Adobe Authorized Resellers and Adobe direct sales. Both CS5 and CS5 Extended are offered as either a stand-alone application or a feature of Adobe Creative Suite 5. Both products are compatible with Intel-based Mac OS X and Windows XP, Windows Vista, and Windows 7.
Photoshop CS6, released in May 2012, added new creative design tools and provided a redesigned interface with a focus on enhanced performance. New features have been added to the Content-Aware tool such as the Content-Aware Patch and Content-Aware Move.

Adobe Photoshop CS6 brought a suite of tools for video editing. Color and exposure adjustments, as well as layers, are among a few things that are featured in this new editor. Upon completion of editing, the user is presented with a handful of options of exporting into a few popular formats.

CS6 brings the "straighten" tool to Photoshop, where a user simply draws a line anywhere on an image, and the canvas will reorient itself so that the line drawn becomes horizontal, and adjusts the media accordingly. This was created with the intention that users will draw a line parallel to a plane in the image, and reorient the image to that plane to more easily achieve certain perspectives.

CS6 allows background saving, which means that while another document is compiling and archiving itself, it is possible to simultaneously edit an image. CS6 also features a customizable auto-save feature, preventing any work from being lost.

With version 13.1.3, Adobe dropped support for Windows XP (including Windows XP Professional x64 Edition); thus, the last version that works on Windows XP is 13.0.1. Adobe also announced that CS6 will be the last suite sold with perpetual licenses in favor of the new Creative Cloud subscriptions, though they will continue to provide OS compatibility support as well as bug fixes and security updates as necessary.

Starting January 9, 2017, CS6 is no longer available for purchase, making a Creative Cloud license the only purchase option going forward.
Photoshop CC (14.0) was launched on June 18, 2013. As the next major version after CS6, it is only available as part of a Creative Cloud subscription. Major features in this version include new Smart Sharpen, Intelligent Upsampling, and Camera Shake Reduction for reducing blur caused by camera shake. Editable Rounded Rectangles and an update to Adobe Camera Raw (8.0) were also included.

Since the initial launch, Adobe has released two additional feature-bearing updates. The first, version 14.1, was launched on September 9, 2013. The major features in this version were Adobe Generator, a Node.js-based platform for creating plug-ins for Photoshop. Photoshop 14.1 shipped with two plug-ins, one to automatically generate image assets based on an extension in the layer name, and another to automatically generate assets for Adobe Edge Reflow.

Version 14.2 was released on January 15, 2014. Major features include Perspective Warp, Linked Smart Objects, and 3D Printing support.
Photoshop CC 2014 (15.0) was released on June 18, 2014. CC 2014 features improvements to content-aware tools, two new blur tools (spin blur and path blur) and a new focus mask feature that enables the user to select parts of an image based on whether they are in focus or not. Other minor improvements have been made, including speed increases for certain tasks.
Photoshop CC 2015 was released on June 15, 2015. Adobe added various creative features including Adobe Stock, which is a library of custom stock images. It also includes and have the ability to have more than one layer style. For example, in the older versions of Photoshop, only one shadow could be used for a layer but in CC 2015, up to ten are available. Other minor features like Export As, which is a form of the Save For Web in CC 2014 were also added. The updated UI as of November 30, 2015 delivers a cleaner and more consistent look throughout Photoshop, and the user can quickly perform common tasks using a new set of gestures on touch-enabled devices like Microsoft Surface Pro. CC 2015 also marks the 25th anniversary of Photoshop.
Photoshop CC 2017 was released on November 2, 2016. It introduced a new template selector when creating new documents, the ability to search for tools, panels and help articles for Photoshop, support for SVG OpenType fonts and other small improvements. In December 2016, a minor update was released to include support for the MacBook Pro Touch Bar.
Photoshop CC 2018 (version 19) was released on October 18, 2017. It featured an overhaul to the brush organization system, allowing for more properties (such as color and opacity) to be saved per-brush and for brushes to be categorized in folders and sub-folders. It also added brush stroke smoothing, and over 1000 brushes created by Kyle T. Webster (following Adobe's acquisition of his website, KyleBrush.com). A Curvature Pen tool, similar to the one in Illustrator, was added, allowing for faster creation of Bézier paths. Other additions were Lightroom Photo access, Variable font support, select subject, copy-paste layers, enhanced tooltips, 360 panorama and HEIF support, PNG compression, increased maximum zoom level, symmetry mode, algorithm improvements to Face-aware and selection tools, color and luminance range masking, improved image resizing, and performance improvements to file opening, filters, and brush strokes.
Photoshop CC 2019 was released on October 15, 2018. Beginning with Photoshop CC 2019 (version 20.0), the 32-bit version of Windows is no longer supported. This version Introduced a new tool called Frame Tool to create placeholder frames for images. It also added multiple undo mode, auto-commitment, prevent accidental panel moves with lock work-space. Live blend mode previews are added, allowing for faster scrolling over different blend mode options in the layers panel. Other additions were Color Wheel, Transform proportionally without Shift key, Distribute spacing like in Illustrator, ability to see longer layer names, match font with Japanese fonts, flip document view, scale UI to font, reference point hidden by default, new compositing engine, which provides a more modern compositing architecture is added which is easier to optimize on all platforms.
Photoshop 2020 was released on November 4, 2019. Version 21 has many new and enhanced features like the new object selection tool for better automate complex selections, new properties panel, enhanced transform warp, new keyboard shortcuts for paint & brush and background image removal option. It added several improvements to the new content-aware fill and to the new document tab. Also added were animated GIF support, improved lens blur performance and one-click zoom to a layer's contents. It introduced new swatches, gradients, patterns, shapes and stylistic sets for OpenType fonts. With this version users now can easily convert smart objects to layers and also can adjust 32-bit layers for brightness/contrast and curves. Presets are now more intuitive to use and easier to organize. 

With the February 2020 update (version 21.1) Photoshop now can iteratively fill multiple areas of an image without having to leave content-aware fill workspace. This version improved GPU based lens blur quality and provided performance improvements such as accelerate your workflow with smoother panning, zooming and navigating documents.

Version 21 was the first version where the iPad version was released. With Photoshop on the iPad, combined with the new Cloud PSD file format, a user can save cloud documents and work across Windows, Mac and iPad. Photoshop on the iPad does not have all the features of the desktop Photoshop. Adobe promises to update Photoshop on the iPad at "a much more aggressive pace than it has with its current Creative Cloud apps for the desktop". Adobe has provided a timeline for enhancing Photoshop on the iPad to have more of the features of desktop Photoshop.

With the desktop June 2020 update (version 21.2), Photoshop added faster portrait selection, Adobe Camera Raw improvements, auto-activated Adobe Fonts, rotatable patterns, and improved Match Font.

Photoshop Mix is an application designed as a replacement for Photoshop Touch specifically for tablets and touchscreen devices. It includes many of the features of the personal computer version, including layers, selection tools, adjustments, and filters. Edited files could be synced with Adobe Creative Cloud. Photoshop Mix is available on iOS and Android. It has 2 siblings, Photoshop Fix (a Photo Correction app), and Photoshop Sketch (a light drawing tool). All require iOS 9.0 or later. Android versions could be installed on any Android handset (4.0 and up) and tablets (3.1 and up).





</doc>
<doc id="24894" url="https://en.wikipedia.org/wiki?curid=24894" title="PaintShop Pro">
PaintShop Pro

PaintShop Pro (PSP) is a raster and vector graphics editor for Microsoft Windows. It was originally published by Jasc Software. In October 2004, Corel purchased Jasc Software and the distribution rights to Paint Shop Pro. PSP functionality can be extended by Photoshop-compatible plugins.

The X-numbered editions have been sold in two versions: PaintShop Pro, which is the basic editing program, and PaintShop Pro Ultimate, which bundles in other standalone programs, additional artistic tools and/or plugins. The particular bundled programs have varied with each numbered version and have not been sold by Corel as separate products.

PSP comes with an interface for automating tasks with scripts written in Python.

Originally called simply Paint Shop, the first version, 1.0, was a basic picture converter between BMP, GIF and PCX formats, conceived by Robert Voit and developed by Joel DeRider. It was released by Robert Voit in August 1990. Paint Shop was originally distributed as shareware and is still available at many download sites (4.12 being a popular version). Most newer versions are only commercially available although some have been distributed in the United Kingdom in computer magazine CDs after they became obsolete.

Paint Shop Pro 5 added support for layers as well as CMYK and HSL colour modes, included JASC Animation Shop for creating animations and in fact was marketed as "Paint Shop Pro 5.0 with Animation Shop". PaintShop Pro X6 was the first to be available as a native 64 bit version (purchase includes both versions). PaintShop Pro X7 includes content-aware features such as "Magic Fill" and "Smart Edge" as well as support for XMP sidecar files that preserve edit settings for raw formats.

From 2006 to 2011 (versions XI to X3), PaintShop Pro was marketed as "Corel Paint Shop Pro Photo". Having dropped the "Photo" part of the name in version X4, Paintshop Pro X5 was derived from Ulead Photo Explorer after Corel's acquisition of Ulead.

On November 28, 2007, Corel announced that the office in Eden Prairie, Minnesota, where Paint Shop Pro was created, would be shut down, with development moving to offices in California and China.

Picture tubes are graphic images with no background. They are often used as a starting point for complex images; that is, they are combined with other image elements to produce a final work. Tubes can also be regarded as graphic brushes based on a pre-created image; this was their original use. Instead of leaving a trace of color on the canvas, they would leave a trail of images. Popular tube subjects include alphabets, humans (also known as dollz), animal and toy figures, flowers, love messages and seasonal symbols.

The tube system originated with PSP Pro version 5. Native tube files may be in .tub, .psp, .pspimage, and .psptube formats. XnView, IrfanView, and TubeEx are separate graphics programs that can convert tube files (.tub) to .png.

PaintShop Pro Photo X2 Ultimate was released towards the end of life of PaintShop Pro Photo X2, in September 2008. It included 150 additional picture frames and Picture Tubes, the programs Background Remover, Corel Painter Photo Essentials 4, and Photorecovery, as well as RAW support for 250 cameras and a 2GB flash drive.

Subsequent Ultimate editions were released contemporaneously with the basic version. PaintShop Pro X4 Ultimate included Nik Color Efex Pro 3.0, a voucher for 21 images from Fotolia at high quality, and additional Picture Tubes. X5 Ultimate included Reallusion FaceFilter Studio 2.0, NIK Color Efex Pro 3.0, and "over 100 unique brushes, textures and royalty-free backgrounds". PaintShop Pro X6 Ultimate includes Athentech Imaging's Perfectly Clear and Reallusion's FaceFilter3 Standard. PaintShop Pro X7 Ultimate includes those same two items.

The bundled extras cannot be installed unless that version of the PaintShop program is already installed. However, once a bundled extra such as a plugin has been installed, the installed files can be copied to other versions, e.g., a plugin installed under X5 can be copied to X6 and even if X5 is then uninstalled, the plugin will continue to work under X6. Corel releases a new X version roughly annually, so this ability to copy means PSP users do not have to choose between updating or continued use of Ultimate add-ons from previous versions.


Versions X through to X8 install a third party program named PSIService.exe, a Windows service called ProtexisLicensing. Written by Protexis, this runs in the background and collects licensing information. This program communicates with a remote host. Manually disabling the Protexis Licensing service may cause Corel Paint Shop Pro Photo to cease functioning.



</doc>
<doc id="24897" url="https://en.wikipedia.org/wiki?curid=24897" title="Persuasion">
Persuasion

Persuasion is an umbrella term of influence. Persuasion can attempt to influence a person's beliefs, attitudes, intentions, motivations, or behaviors. 

In business,
persuasion is a process aimed at changing a person's (or a group's) attitude or behaviour toward some event, idea, object, or other person(s), by using written, spoken words or visual tools to convey information, feelings, or reasoning, or a combination thereof. Persuasion is also an often used tool in the pursuit of personal gain, such as election campaigning, giving a sales pitch, or in trial advocacy. Persuasion can also be interpreted as using one's personal or positional resources to change people's behaviors or attitudes.

Systematic persuasion is the process through which attitudes or beliefs are leveraged by appeals to logic and reason. Heuristic persuasion on the other hand is the process through which attitudes or beliefs are leveraged by appeals to habit or emotion.

Persuasion began with the Greeks, who emphasized rhetoric and elocution as the highest standard for a successful politician. All trials were held in front of the Assembly, and both the prosecution and the defense rested, as they often do today, on the persuasiveness of the speaker. Rhetoric was the ability to find the available means of persuasion in any instance.
The Greek philosopher Aristotle listed four reasons why one should learn the art of persuasion:
Aristotle's rhetorical proofs:

Humans attempt to explain the actions of others through either dispositional attribution or situational attribution.

Dispositional attribution, also referred to as internal attribution, attempts to point to a person's traits, abilities, motives, or dispositions as a cause or explanation for their actions. A citizen criticizing a president by saying the nation is lacking economic progress and health because the president is either lazy or lacking in economic intuition is utilizing a dispositional attribution.

Situational attribution, also referred to as external attribution, attempts to point to the context around the person and factors of his surroundings, particularly things that are completely out of his control. A citizen claiming that a lack of economic progress is not a fault of the president but rather the fact that he inherited a poor economy from the previous president is situational attribution.

A fundamental attribution error occurs when people wrongly attribute either a shortcoming or accomplishment to internal factors, and disregarding any external factors. In general, people tend to make dispositional attributions more often than situational attributions when trying to explain or understand a person's behavior. This happens when we are much more focused on the individual because we do not know much about their situation or context. When trying to persuade others to like us or another person, we tend to explain positive behaviors and accomplishments with dispositional attribution, but our own negative behaviors and shortcomings with situational attributions.

The theory of planned behaviour is the foremost theory of behaviour change. It has support from meta-analyses which reveals it can predict around 30% of behaviour. Theories, by nature however, prioritise internal validity, over external validity. They are coherent and therefore make for an easily reappropriated story. On the other hand, they will correspond more poorly with the evidence, and mechanics of reality, than a straightforward itemisation of the behaviour change interventions (techniques) by their individual efficacy. 
These behaviour change interventions have been categorised by behaviour scientists. A mutually exclusive, comprehensively exhaustive (MECE) translation of this taxonomy, in decreasing order of effectiveness are:


A typical instantiations of these techniques in therapy isexposure / response prevention for OCD.

Conditioning plays a huge part in the concept of persuasion. It is more often about leading someone into taking certain actions of their own, rather than giving direct commands. In advertisements for example, this is done by attempting to connect a positive emotion to a brand/product logo. This is often done by creating commercials that make people laugh, using a sexual undertone, inserting uplifting images and/or music etc. and then ending the commercial with a brand/product logo. Great examples of this are professional athletes. They are paid to connect themselves to things that can be directly related to their roles; sport shoes, tennis rackets, golf balls, or completely irrelevant things like soft drinks, popcorn poppers and panty hose. The important thing for the advertiser is to establish a connection to the consumer.

This conditioning is thought to affect how people view certain products, knowing that most purchases are made on the basis of emotion. Just like you sometimes recall a memory from a certain smell or sound, the objective of some ads is solely to bring back certain emotions when you see their logo in your local store. The hope is that repeating the message several times makes consumers more likely to purchase the product because they already connect it with a good emotion and positive experience.
Stefano DellaVigna and Matthew Gentzkow did a comprehensive study on the effects of persuasion in different domains. They discovered that persuasion has little or no effect on advertisement; however, there was a substantial effect of persuasion on voting if there was face-to-face contact.

Leon Festinger originally proposed the theory of cognitive dissonance in 1957. He theorized that human beings constantly strive for mental consistency. Our cognition (thoughts, beliefs, or attitudes) can be in agreement, unrelated, or in disagreement with each other. Our cognition can also be in agreement or disagreement with our behaviors. When we detect conflicting cognition, or dissonance, it gives us a sense of incompleteness and discomfort. For example, a person who is addicted to smoking cigarettes but also suspects it could be detrimental to his health suffers from cognitive dissonance.

Festinger suggests that we are motivated to reduce this dissonance until our cognition is in harmony with itself. We strive for mental consistency. There are four main ways we go about reducing or eliminating our dissonance:
Revisiting the example of the smoker, he can either quit smoking, reduce the importance of his health, convince himself he is not at risk, or that the reward of smoking is worth the cost of his health.

Cognitive dissonance is powerful when it relates to competition and self-concept. The most famous example of how cognitive dissonance can be used for persuasion comes from Festinger and Carlsmith's 1959 experiment in which participants were asked to complete a very dull task for an hour. Some were paid $20, while others were paid $1, and afterwards they were instructed to tell the next waiting participants that the experiment was fun and exciting. Those who were paid $1 were much more likely to convince the next participants that the experiment really was enjoyable than those who received $20. This is because $20 is enough reason to participate in a dull task for an hour, so there is no dissonance. Those who received $1 experienced great dissonance, so they had to truly convince themselves that the task actually was enjoyable to avoid feeling taken advantage of, and therefore reduce their dissonance.

Persuasion has traditionally been associated with two routes.

The Elaboration likelihood model (ELM) forms a new facet of the route theory. It holds that the probability of effective persuasion depends on how successful the communication is at bringing to mind a relevant mental representation, which is the elaboration likelihood. Thus if the target of the communication is personally relevant, this increases the elaboration likelihood of the intended outcome and would be more persuasive if it were through the central route. Communication which does not require careful thought would be better suited to the peripheral route.

Functional theorists attempt to understand the divergent attitudes individuals have towards people, objects or issues in different situations. There are four main functional attitudes:

When communication targets an underlying function, its degree of persuasiveness influences whether individuals change their attitude after determining that another attitude would more effectively fulfill that function.

A vaccine introduces a weak form of a virus that can easily be defeated to prepare the immune system should it need to fight off a stronger form of the same virus. In much the same way, the theory of inoculation suggests that a certain party can introduce a weak form of an argument that is easily thwarted in order to make the audience inclined to disregard a stronger, full-fledged form of that argument from an opposing party.

This often occurs in negative advertisements and comparative advertisements—both for products and political causes. An example would be a manufacturer of a product displaying an ad that refutes one particular claim made about a rival's product, so that when the audience sees an ad for said rival product, they refute the product claims automatically.

Narrative transportation theory proposes that when people lose themselves in a story, their attitudes and intentions change to reflect that story. The mental state of narrative transportation can explain the persuasive effect of stories on people, who may experience narrative transportation when certain contextual and personal preconditions are met, as Green and Brock postulate for the transportation-imagery model. Narrative transportation occurs whenever the story receiver experiences a feeling of entering a world evoked by the narrative because of empathy for the story characters and imagination of the story plot.

Social judgment theory suggests that when people are presented with an idea or any kind of persuasive proposal, their natural reaction is to immediately seek a way to sort the information subconsciously and react to it. We evaluate the information and compare it with the attitude we already have, which is called the initial attitude or anchor point.

When trying to sort incoming persuasive information, an audience evaluates whether it lands in their latitude of acceptance, latitude of non-commitment or indifference, or the latitude of rejection. The size of these latitudes varies from topic to topic. Our "ego-involvement" generally plays one of the largest roles in determining the size of these latitudes. When a topic is closely connected to how we define and perceive ourselves, or deals with anything we care passionately about, our latitudes of acceptance and non-commitment are likely to be much smaller and our attitude of rejection much larger. A person's anchor point is considered to be the center of his latitude of acceptance, the position that is most acceptable to him.

An audience is likely to distort incoming information to fit into their unique latitudes. If something falls within the latitude of acceptance, the subject tends to assimilate the information and consider it closer to his anchor point than it really is. Inversely, if something falls within the latitude of rejection, the subject tends to contrast the information and convince himself the information is farther away from his anchor point than it really is.

When trying to persuade an individual target or an entire audience, it is vital to first learn the average latitudes of acceptance, non-commitment, and rejection of your audience. It is ideal to use persuasive information that lands near the boundary of the latitude of acceptance if the goal is to change the audience's anchor point. Repeatedly suggesting ideas on the fringe of the acceptance latitude makes people gradually adjust their anchor points, while suggesting ideas in the rejection latitude or even the non-commitment latitude does not change the audience's anchor point.

Persuasion methods are also sometimes referred to as "persuasion tactics" or "persuasion strategies".

There is the usage of force in persuasion, which does not have any scientific theories, except for its use to make demands. The use of force is then a precedent to the failure of less direct means of persuasion. Application of this strategy can be interpreted as a threat since the persuader does not give options to his or her request.

Robert Cialdini, in "Influence", his book on persuasion, defined six "influence cues or weapons of influence": Influence is the process of changing.

The principle of reciprocity states that when a person provides us with something, we attempt to repay him or her in kind. Reciprocation produces a sense of obligation, which can be a powerful tool in persuasion. The reciprocity rule is effective because it can be overpowering and instill in us a sense of obligation. Generally, we have a dislike for individuals who neglect to return a favor or provide payment when offered a free service or gift. As a result, reciprocation is a widely held principle. This societal standard makes reciprocity extremely powerful persuasive technique, as it can result in unequal exchanges and can even apply to an uninvited first favor. Reciprocity applies to the marketing field because of its use as a powerful persuasive technique. The marketing tactic of "free samples" demonstrates the reciprocity rule because of the sense of obligation that the rule produces. This sense of obligation comes from the desire to repay the marketer for the gift of a "free sample."

Consistency is an important aspect of persuasion because it:
Consistency allows us to more effectively make decisions and process information. The concept of consistency states that someone who commits to something, orally or in writing, is more likely to honor that commitment. This is especially true for written commitments, as they appear psychologically more concrete and can create hard proof. Someone who commits to a stance tends to behave according to that commitment. Commitment is an effective persuasive technique, because once you get someone to commit, they are more likely to engage in self-persuasion, providing themselves and others with reasons and justifications to support their commitment in order to avoid dissonance. Cialdini notes Vietnamese brainwashing of American prisoners of war to rewrite their self-image and gain automatic unenforced compliance. Another example is children being made to repeat the Pledge of Allegiance each morning and why marketers make you close popups by saying "I’ll sign up later" or "No thanks, I prefer not making money".

We, as humans, are influenced by others around us; we want to do what everyone else is. People often base their actions and beliefs on what others around them are doing, how others act or what others believe.

"The power of the crowd" is very effective. We all want to know what others are doing around us. We are so obsessed with what others do and how others act, that we then try to be just like other people. Cialdini gives an example that is somewhat like this: In a phone–a–thon, the host says something like, "Operators are waiting, please call now." The only context you have from that statement is that the operators are waiting and not busy. Rather the host may say: "If operators are busy, please call again." This is the technique of social proof. Just by changing three words, it sounds like the lines are busy and other people are calling, so it must be a worthwhile organization.

Social proof is most effective when people are uncertain or when there are similarities in a situation. In uncertain or ambiguous situations, when multiple possibilities create choices we must make, people are likely to conform to what others do. We become more influenced by people around us in situations that present a decision. The other effective situation for social proofing is when there are similarities. We are more prone to change or conform around people who are similar to us. If someone who is similar to you is being controlling and a leader, you are more likely to listen and follow what they say.

This principle is simple and concise. People say "yes" to people that they like. Two major factors contribute to overall likeness. The first is physical attractiveness. People who are physically attractive seem more persuasive. They get what they want and they can easily change others' attitudes. This attractiveness is proven to send favorable messages/impressions of other traits that a person may have, such as talent, kindness, and intelligence. The second factor is similarity. We are more easily persuaded by people we see as similar to ourselves.

We have the tendency to believe that if an expert says something, then it must be true. People like to listen to those who are knowledgeable and trustworthy, so if you can be those two things, then you are already on your way to getting people to believe and listen to you.

In the Milgram study, a series of experiments begun in 1961, a "teacher" and a "learner" were placed in two different rooms. The "learner" was attached to an electric harness that could administer shock. The "teacher" was told by a supervisor, dressed in a white scientist's coat, to ask the learner questions and punish him when he got a question wrong. The teacher was instructed by the study supervisor to deliver an electric shock from a panel under the teacher's control. After delivery, the teacher had to up the voltage to the next notch. The voltage went up to 450 volts. The catch to this experiment was that the teacher did not know that the learner was an actor faking the pain sounds he heard and was not actually being harmed. The experiment was being done to see how obedient we are to authority. "When an authority tells ordinary people it is their job to deliver harm, how much suffering will each subject be willing to inflict on an entirely innocent other person if the instructions come 'from above'?." In this study the results show that most teachers were willing to give as much pain as was available to them. The conclusion was that people are willing to bring pain upon others when they are directed to do so by some authority figure.

Scarcity could play an important role in the process of persuasion. When something has limited availability, people assign it more value. According to Cialdini, "people want more of what they cannot have." When scarcity is an issue, the context matters. This means that within certain contexts, scarcity "works" better. To get people to believe that something is scarcer, marketers explain what about that certain product provides what no other product does. Marketers also get people to believe something is scarce by telling them what they will lose, not what they will gain—using statements like, "You will lose $5," rather than, "Save $5."
There are two major reasons why the scarcity principle works:
When this happens, we assign the scarce item or service more value simply because it is harder to acquire.

This principle is that we all want things that are out of our reach. If we see something is easily available, we do not want it as much as something that is very rare.

Individuals high on the Machiavellianism trait have tendencies to engage in manipulation and deceit to gain self benefits for themselves.

In their book "The Art of Woo", G. Richard Shell and Mario Moussa present a four-step approach to strategic persuasion. They explain that persuasion means to win others over, not to defeat them. Thus it is important to see the topic from different angles in order to anticipate the reaction others have to a proposal.


By appeal to reason:

By appeal to emotion:

Aids to persuasion:

Other techniques:

Coercive techniques, some of which are highly controversial or not scientifically proven effective:
It is through a basic cultural personal definition of persuasion that everyday people understand how others are attempting to influence them and then how they influence others. The dialogue surrounding persuasion is constantly evolving because of the necessity to use persuasion in everyday life. Persuasion tactics traded in society have influences from researchers, which may sometimes be misinterpreted.
To keep evolutionary advantage, in the sense of wealth and survival, you must persuade and not be persuaded. To understand cultural persuasion, researchers gather knowledge from domains such as "buying, selling, advertising, and shopping, as well as parenting and courting."

Methods of persuasion vary by culture, both in prevalence and effectiveness. For example, advertisements tend to appeal to different values according to whether they are used in collectivistic or individualistic cultures.

The Persuasion Knowledge Model (PKM) was created by Friestad and Wright in 1994. This framework allows the researchers to analyze the process of gaining and using everyday persuasion knowledge. The researchers suggest the necessity of including "the relationship and interplay between everyday folk knowledge and scientific knowledge on persuasion, advertising, selling, and marketing in general."

To educate the general population about research findings and new knowledge about persuasion, a teacher must draw on their pre-existing beliefs from folk persuasion to make the research relevant and informative to lay people, which creates "mingling of their scientific insights and commonsense beliefs."

As a result of this constant mingling, the issue of persuasion expertise becomes messy. Expertise status can be interpreted from a variety of sources like job titles, celebrity, or published scholarship.

It is through this multimodal process that we create concepts like, "Stay away from car salesmen, they will try to trick you." The kind of persuasion techniques blatantly employed by car salesmen creates an innate distrust of them in popular culture. According to Psychology Today, they employ tactics ranging from making personal life ties with the customer to altering reality by handing the customer the new car keys before the purchase.

Campbell proposed and empirically demonstrated that some persuasive advertising approaches lead consumers to infer manipulative intent on the marketer's part. Once consumers infer manipulative intent, they are less persuaded by the marketer, as indicated by attenuated advertising attitudes, brand attitudes and purchase intentions.Cambpell and Kirmani developed an explicit model of the conditions under which consumers use persuasion knowledge in evaluating influence agents such as salespersons.

An article showed that EEG measures of anterior prefrontal asymmetry might be a predictor of persuasion. Research participants were presented with arguments that favored and arguments that opposed the attitudes they already held. Those whose brain was more active in left prefrontal areas said that they paid the most attention to statements with which they agreed while those with a more active right prefrontal area said that they paid attention to statements that disagreed. This is an example of defensive repression, the avoidance or forgetting of unpleasant information. Research has shown that the trait of defensive repression is related to relative left prefrontal activation. In addition, when pleasant or unpleasant words, probably analogous to agreement or disagreement, were seen incidental to the main task, an fMRI scan showed preferential left prefrontal activation to the pleasant words.

One way therefore to increase persuasion would seem to be to selectively activate the right prefrontal cortex. This is easily done by monaural stimulation to the contralateral ear. The effect apparently depends on selective attention rather than merely the source of stimulation. This manipulation had the expected outcome: more persuasion for messages coming from the left.



</doc>
<doc id="24898" url="https://en.wikipedia.org/wiki?curid=24898" title="Prime Minister of Israel">
Prime Minister of Israel

The prime minister of Israel (, "Rosh HaMemshala", "lit." Head of the Government, Hebrew acronym: ; , "Ra'īs al-Ḥukūma") is the head of government and chief executive of Israel.

Israel is a republic with a president as head of state. However, the president's powers are largely ceremonial; the prime minister holds the executive power. The official residence of the prime minister, "Beit Aghion," is in Jerusalem. The current prime minister is Benjamin Netanyahu of Likud, the ninth person to hold the position (excluding caretakers).

Following an election, the president nominates a member of the Knesset to become prime minister after asking party leaders whom they support for the position. The nominee has 42 days to put together a viable coalition. He then presents a government platform and must receive a vote of confidence from the Knesset to become prime minister. In practice, the prime minister is usually the leader of the largest party in the governing coalition. Between 1996 and 2001, the prime minister was directly elected, separately from the Knesset.

Unlike most prime ministers in parliamentary republics, the prime minister is both "de jure" and "de facto" chief executive. This is because the Basic Laws of Israel explicitly vest executive power in the government, of which the prime minister is the leader.

The office of Prime Minister came into existence on 14 May 1948, the date of the Declaration of the Establishment of the State of Israel, when the provisional government was created. David Ben-Gurion, leader of Mapai and head of the Jewish Agency, became Israel's first prime minister. The position became permanent on 8 March 1949, when the first government was formed. Ben-Gurion retained his role until late 1953, when he resigned to settle in the Kibbutz of Sde Boker. He was replaced by Moshe Sharett. However, Ben-Gurion returned in a little under two years to reclaim his position. He resigned for a second time in 1963, breaking away from Mapai to form Rafi. Levi Eshkol took over as head of Mapai and prime minister. He became the first prime minister to head the country under the banner of two parties when Mapai formed the Alignment with Ahdut HaAvoda in 1965. In 1968 he also became the only party leader to command an absolute majority in the Knesset, after Mapam and Rafi merged into the Alignment, giving it 63 seats in the 120-seat Knesset.

On 26 February 1969, Eshkol became the first prime minister to die in office. He was temporarily replaced by Yigal Allon, whose stint lasted less than a month, as the party persuaded Golda Meir to return to political life and become prime minister in March 1969. Meir was Israel's first woman prime minister, and the third in the world (after Sirimavo Bandaranaike and Indira Gandhi).

Meir resigned in 1974 after the Agranat Commission published its findings on the Yom Kippur War, even though it had absolved her of blame. Yitzhak Rabin took over, though he also resigned towards the end of the eighth Knesset's term following a series of scandals. Those included the suicide of Housing Minister Avraham Ofer after police began investigating allegations that he had used party funds illegally, and the affair involving Asher Yadlin (the governor-designate of the Bank of Israel), who was sentenced to five years in prison for having accepted bribes. Rabin's wife, Leah, was also found to have had an overseas bank account, which was illegal in Israel at the time.

Menachem Begin became the first right-wing prime minister when his Likud won the 1977 elections, and retained the post in the 1981 elections. He resigned in 1983 for health reasons, passing the reins of power to Yitzhak Shamir.

After the 1984 elections had proved inconclusive with neither the Alignment nor Likud able to form a government, a national unity government was formed with a rotating prime ministership – Shimon Peres took the first two years, and was replaced by Shamir midway through the Knesset term. Although the 1988 elections produced another national unity government, Shamir was able to take the role alone. Peres made an abortive bid to form a left-wing government in 1990, but failed, leaving Shamir in power until 1992. Rabin became prime minister for the second time when he led Labour to victory in the 1992 elections. After his assassination on 4 November 1995, Peres took over as prime minister.

During the thirteenth Knesset (1992–1996) it was decided to hold a separate ballot for prime minister modeled after American presidential elections. This system was instituted in part because the Israeli electoral system makes it all but impossible for one party to win a majority. While only two parties—Mapai/Labour and Likud—had ever led governments, the large number of parties or factions in a typical Knesset usually prevents one party from winning the 61 seats needed for a majority.

In 1996, when the first such election took place, the outcome was a surprise win for Benjamin Netanyahu after election polls predicted that Peres was the winner. However, in the Knesset election held at the same time, Labour won more votes than any other party (27%). Thus Netanyahu, despite his theoretical position of power, needed the support of the religious parties to form a viable government.

Ultimately Netanyahu failed to hold the government together, and early elections for both prime minister and the Knesset were called in 1999. Although five candidates intented to run, the three representing minor parties (Benny Begin of Herut – The National Movement, Azmi Bishara of Balad and Yitzhak Mordechai of the Centre Party) dropped out before election day, and Ehud Barak beat Netanyahu in the election. However, the new system again appeared to have failed; although Barak's One Israel alliance (an alliance of Labour, Gesher and Meimad) won more votes than any other party in the Knesset election, they garnered only 26 seats, the lowest ever by a winning party or alliance. Barak needed to form a coalition with six smaller parties to form a government.

In early 2001, Barak resigned following the outbreak of the al-Aqsa Intifada. However, the government was not brought down, and only elections for prime minister were necessary. In the election itself, Ariel Sharon of Likud comfortably beat Barak, taking 62.4% of the vote. However, because Likud only had 21 seats in the Knesset, Sharon had to form a national unity government. Following Sharon's victory, it was decided to do away with separate elections for prime minister and return to the previous system.

The 2003 elections were carried out in the same manner as prior to 1996. Likud won 38 seats, the highest by a party for over a decade, and as party leader Sharon was duly appointed Prime Minister. However, towards the end of his term and largely as a result of the deep divisions within Likud over Israel's unilateral disengagement plan, Sharon broke away from his party to form Kadima, managing to maintain his position as prime minister and also becoming the first prime minister not to be a member of either Labour or Likud (or their predecessors). However, he suffered a stroke in January 2006, in the midst of election season, leading Ehud Olmert to become acting prime minister in the weeks leading to the elections. He was voted by the cabinet to be interim prime minister just after the 2006 elections, when Sharon had reached 100 days of incapacitation. He thus became Israel's third interim prime minister, only days before forming his own new government as the official Prime Minister of Israel.

In 2008, amid accusations of corruption and challenges from his own party, Olmert resigned. However his successor Tzipi Livni was unable to form a coalition government. In the election in the following year, while Kadima won the most seats, it was the Likud leader Benjamin Netanyahu who was given the task of forming a government. He was able to do so, thus beginning his second term as Prime Minister of Israel.

In the 2013 election, the Likud Yisrael Beiteinu alliance emerged as the largest faction. After forming a coalition, Netanyahu secured his third prime ministership.

If the prime minister dies in office, the cabinet chooses an interim prime minister to run the government until a new government is placed in power. Yigal Allon served as interim prime minister following Levi Eshkol's death, as did Shimon Peres following the assassination of Yitzhak Rabin.

According to Israeli law, if a prime minister is temporarily incapacitated rather than dies (as was the case following Ariel Sharon's stroke in early 2006), power is transferred to the acting prime minister, until the prime minister recovers (Ehud Olmert took over from Sharon), for up to 100 days. If the prime minister is declared permanently incapacitated, or that period expires, the president of Israel oversees the process of assembling a new governing coalition, and in the meantime the acting prime minister or other incumbent minister is appointed by the cabinet to serve as interim prime minister.

In the case of Sharon, elections were already due to occur within 100 days of the beginning of his coma; thus, the post-election coalition-building process pre-empted the emergency provisions for the selection of a new prime minister. Nevertheless, Olmert was appointed interim prime minister on 16 April 2006, after the elections, just days before he had formed a government on 4 May 2006, to become the official prime minister.

Aside from the position of Acting Prime Minister, there are also vice prime ministers and deputy prime ministers.

During his term of office, the prime minister lives in Jerusalem. Since 1974, the official residence of the prime minister is Beit Aghion, at the corner of Balfour and Smolenskin streets in Rehavia.





</doc>
<doc id="24899" url="https://en.wikipedia.org/wiki?curid=24899" title="President of France">
President of France

The president of France, officially the president of the French Republic (, ), is the head of state and chief executive of France as well as the commander-in-chief of the French Armed Forces. In French terms the presidency is the supreme magistracy of the country, in other words, the holder of the highest office in France.

The powers, functions and duties of prior presidential offices, as well as their relation with the prime minister and Government of France, have over time differed with the various constitutional documents since the French Second Republic. The president of the French Republic is also the "ex officio" co-prince of Andorra, grand master of the Legion of Honour and of the National Order of Merit. The officeholder is also honorary proto-canon of the Archbasilica of Saint John Lateran in Rome (although some have rejected the title in the past).

The current president of the French Republic is Emmanuel Macron, who succeeded François Hollande on 14 May 2017.

The presidency of France was first publicly proposed during the July Revolution of 1830, when it was offered to the Marquis de Lafayette. He demurred in favour of Prince Louis Phillipe, who became King of the French. Eighteen years later, during the opening phases of the Second Republic, the title was created for a popularly elected head of state, the first of whom was Louis-Napoléon Bonaparte, nephew of Emperor Napoleon. Bonaparte served in that role until he staged an auto coup against the republic, proclaiming himself Napoleon III, Emperor of the French.

Under the Third Republic and Fourth Republic, which were parliamentary systems, the office of president of the Republic was a largely ceremonial and powerless one. The Constitution of the Fifth Republic greatly increased the president's powers. A 1962 referendum changed the constitution, so that the president would be directly elected by universal suffrage and not by the Parliament.

In 2000, a referendum shortened the presidential term from seven years to five years. A maximum of two consecutive terms was imposed after the 2008 constitutional reform.

Since the referendum on the direct election of the president of the French Republic in 1962, the officeholder has been directly elected by universal suffrage; they were previously elected by an electoral college.

After the referendum in 2000 on the reduction of the mandate of the president of the French Republic, the length of the term was reduced to five years from the previous seven; the first election to a shorter term was held in 2002. President Jacques Chirac was first elected in 1995 and again in 2002. At that time there was no limit on the number of terms, so Chirac could have run again, but chose not to. He was succeeded by Nicolas Sarkozy on 16 May 2007.

Following a further change, the constitutional law of 2008 on the modernisation of the institutions of the Fifth Republic, a president cannot serve more than two consecutive terms. François Mitterrand and Jacques Chirac are the only presidents to date who have served a full two terms (14 years for the former, 12 years for the latter).

In order to be admitted as an official candidate, potential candidates must receive signed nominations (informally known as , for "sponsors") from more than 500 elected officials, mostly mayors. These officials must be from at least 30 "départements" or overseas collectivities, and no more than 10% of them should be from the same "département" or collectivity. Furthermore, each official may nominate only one candidate. There are exactly 45,543 elected officials, including 33,872 mayors.

Spending and financing of campaigns and political parties are highly regulated. There is a cap on spending (at approximately €20 million) and government public financing of 50% of spending if the candidate scores more than 5%. If the candidate receives less than 5% of the vote, the government funds €8,000,000 to the party (€4,000,000 paid in advance). Advertising on TV is forbidden, but official time is given to candidates on public TV. An independent agency regulates election and party financing.

French presidential elections are conducted using run-off voting, which ensures that the elected president always obtains a majority: if no candidate receives a majority of votes in the first round of voting, the two highest-scoring candidates arrive at a run-off. After a new president is elected, they go through a solemn investiture ceremony called a ("handing over of powers").

The French Fifth Republic is a semi-presidential system. Unlike many other European presidents, the French president is quite powerful. Although the prime minister of France, through their Government as well as the Parliament, oversees much of the nation's actual day-to-day affairs (especially in domestic issues), the French president wields significant influence and authority, especially in the fields of national security and foreign policy.

The president's greatest power is the ability to choose the prime minister. However, since the French National Assembly has the sole power to dismiss the prime minister's government, the president is forced to name a prime minister who can command the support of a majority in the assembly. They have also the duty of arbitrating the functioning of governmental authorities for efficient service, as the Head of State of France.


Since 2002, the mandate of the president and the Assembly are both five years, and the two elections are close to each other. Therefore, the likelihood of a is lower. Among the powers of the government:


All decisions of the president must be countersigned by the prime minister, except dissolving the French National Assembly, choice of prime minister, dispositions of Article 19.

The constitutional attributions of the president are defined in Title II of the Constitution of France.

Article 5: The president of the Republic shall see that the Constitution is observed. He shall ensure, by his arbitration, the proper functioning of the public authorities and the continuity of the State. He shall be the guarantor of national independence, territorial integrity and observance of treaties.

Article 8: The president of the Republic shall appoint the prime minister. He shall terminate the appointment of the prime minister when the latter tenders the resignation of the Government. On the proposal of the prime minister, he shall appoint the other members of the Government and terminate their appointments.

Article 9: The president of the Republic shall preside over the Council of Ministers.

Article 10: The president of the Republic shall promulgate Acts of Parliament within fifteen days following the final adoption of an Act and its transmission to the Government. He may, before the expiry of this time limit, ask Parliament to reconsider the Act or sections of the Act. Reconsideration shall not be refused. "While the president has to sign all acts adopted by parliament into law, he cannot refuse to do so and exercise a kind of right of veto; his only power in that matter is to ask for a single reconsideration of the law by parliament and this power is subject to countersigning by the Prime minister."

Article 11: The president could submit laws to the people in a referendum with advice and consent of the cabinet.

Article 12: The president of the Republic may, after consulting the prime minister and the presidents of the assemblies, declare the National Assembly dissolved. A general election shall take place not less than twenty days and not more than forty days after the dissolution. The National Assembly shall convene as of right on the second Thursday following its election. Should it so convene outside the period prescribed for the ordinary session, a session shall be called by right for a fifteen-day period. No further dissolution shall take place within a year following this election.

Article 13: The president of the Republic shall sign the ordinances and decrees deliberated upon in the Council of Ministers. He shall make appointments to the civil and military posts of the State. [...]

Article 14: The president of the Republic shall accredit ambassadors and envoys extraordinary to foreign powers; foreign ambassadors and envoys extraordinary shall be accredited to him.

Article 15: The president of the Republic shall be commander-in-chief of the armed forces. He shall preside over the higher national defence councils and committees.

Article 16: Where the institutions of the Republic, the independence of the Nation, the integrity of its territory or the fulfilment of its international commitments are under serious and immediate threat, and where the proper functioning of the constitutional public authorities is interrupted, the president of the Republic shall take the measures required by these circumstances, after formally consulting the prime minister, the presidents of the assemblies and the Constitutional Council. He shall inform the Nation of these measures in a message. The measures must stem from the desire to provide the constitutional public authorities, in the shortest possible time, with the means to carry out their duties. The Constitutional Council shall be consulted with regard to such measures. Parliament shall convene as of right. The National Assembly shall not be dissolved during the exercise of the emergency powers.

"Article 16, allowing the president a limited form of rule by decree for a limited period of time in exceptional circumstance, has been used only once, by Charles de Gaulle during the Algerian War, from 23 April to 29 September 1961."

Article 17: The president of the Republic has the right to grant pardon.

Article 18: The president of the Republic shall communicate with the two assemblies of Parliament by means of messages, which he shall cause to be read and which shall not be the occasion for any debate. He can also give an address in front of the Congress of France in Versailles. Outside sessions, Parliament shall be convened especially for this purpose.

Article 19: Acts of the president of the Republic, other than those provided for under articles 8 (first paragraph), 11, 12, 16, 18, 54, 56 and 61, shall be countersigned by the prime minister and, where required, by the appropriate ministers.

Article 49 Para 3 allows the president to adopt a law on his authority. To this end, the prime minister goes before the Lower and Upper houses, reads out the bill to the legislators and closes with "the administration engages its responsibility" on the foregoing. Deprived of Gaullist party support halfway into his seven-year term spanning 1974 to 1981, President Valéry Giscard d'Estaing relied heavily on this provision to stalemate Paris mayor Jacques Chirac's attempt to bring him back under Gaullist control.

There is a tradition of so-called "presidential amnesties", which are something of a misnomer: after the election of a president, and of a National Assembly of the same party, parliament traditionally votes a law granting amnesty for some petty crimes. This practice has been increasingly criticized, particularly because it is believed to inspire people to commit traffic offences in the months preceding the election. Such an amnesty law may also authorize the president to designate individuals who have committed certain categories of crimes to be offered amnesty, if certain conditions are met. Such individual measures have been criticized for the political patronage that they allow. Still, it is argued that such amnesty laws help reduce prison overpopulation. An amnesty law was passed in 2002; none have yet been passed .

The difference between an amnesty and a presidential pardon is that the former clears all subsequent effects of the sentencing, as though the crime had not been committed, while pardon simply relieves the sentenced individual from part or all of the remainder of the sentence.

Articles 67 and 68 organize the regime of criminal responsibility of the president. They were reformed by a 2007 constitutional act in order to clarify a situation that previously resulted in legal controversies.

The president of the Republic enjoys immunity during their term: they cannot be requested to testify before any jurisdiction, they cannot be prosecuted, etc. However, the statute of limitation is suspended during their term, and enquiries and prosecutions can be restarted, at the latest one month after they leave office.

The president is not deemed personally responsible for their actions in their official capacity, except where their actions are indicted before the International Criminal Court (France is a member of the ICC and the president is a French citizen as another following the Court's rules) or where impeachment is moved against them. Impeachment can be pronounced by the Republican High Court, a special court convened from both houses of Parliament on the proposal of either House, should the president have failed to discharge their duties in a way that evidently precludes the continuation of their term.

Upon the death, removal, or resignation of the president, the Senate's president takes over as acting president. Alain Poher is the only person to have served in this temporary position, and has done so twice: the first time in 1969 after Charles de Gaulle's resignation and a second time in 1974 after Georges Pompidou's death. In this situation, the president of the Senate becomes Acting President of the Republic; they do not become the new president of the Republic as elected and therefore do not have to resign from their position as President of the Senate. In spite of his title as Acting President of the Republic, Poher is regarded in France as a former president and is listed in the presidents' gallery on the official presidential website. This is in contrast to acting presidents from the Third Republic.

The first round of a new presidential election must be organized no sooner than twenty days and no later than thirty-five days following the vacancy of the presidency. Fifteen days can separate the first and second rounds of a presidential election; this means that the president of the Senate can only act as President of the Republic for a maximum period of fifty days. During this interim period, acting presidents are not allowed to dismiss the national assembly, nor are they allowed to call for a referendum or initiate any constitutional changes.

If there is no president of the Senate, the powers of the president of the republic are exercised by the , meaning the Cabinet. This has been interpreted by some constitutional academics as meaning first the prime minister and, if he is himself not able to act, the members of the cabinet in the order of the list of the decree that nominated them. This is in fact unlikely to happen, because if the president of the Senate is not able to act, the Senate will normally name a new president of the Senate, who will act as President of the Republic.

During the Third French Republic the president of the Council of Ministers acted as president whenever the office was vacant. According to article 7 of the Constitution, if the presidency becomes vacant for any reason, or if the president becomes incapacitated, upon the request of the , the Constitutional Council may rule, by a majority vote, that the presidency is to be temporarily assumed by the president of the Senate. If the Council rules that the incapacity is permanent, the same procedure as for the resignation is applied, as described above.

If the president cannot attend meetings, including meetings of the Council of Ministers, he can ask the prime minister to attend in his stead (Constitution, article 21). This clause has been applied by presidents travelling abroad, ill, or undergoing surgery.

During the Second French Republic, there was a vice president. The only person to ever hold the position was Henri Georges Boulay de la Meurthe.

Four French presidents have died in office:

The president of the Republic is paid a salary according to a pay grade defined in comparison to the pay grades of the most senior members of the French Civil Service ("out of scale", "hors échelle", those whose pay grades are known as letters and not as numeric indices). In addition he is paid a residence stipend of 3%, and a function stipend of 25% on top of the salary and residence indemnity. This gross salary and these indemnities are the same as those of the prime minister, and are 50% higher than the highest paid to other members of the government, which is itself defined as twice the average of the highest (pay grade G) and the lowest (pay grade A1) salaries in the "out of scale" pay grades. Using the 2008 "out of scale" pay grades, it amounts to a monthly pay of 20,963 euros, which fits the 19,000 euros quoted to the press in early 2008. Using the pay grades starting from 1 July 2009, this amounts to a gross monthly pay of €21,131.

The salary and the residence stipend are taxable for income tax.

The official residence and office of the president is the Élysée Palace in Paris. Other presidential residences include:


There are three living former French presidents:
According to French law, former presidents of the Republic have guaranteed lifetime pension defined according to the pay grade of the Councillors of State, a courtesy diplomatic passport, and, according to the French Constitution (Article 56), membership of the Constitutional Council.

They also get personnel, an apartment and/or office, and other amenities, though the legal basis for these is disputed. In 2008, according to an answer by the services of the prime minister to a question from René Dosière, a member of the National Assembly, the facilities comprised: a security detail, a car with a chauffeur, first class train tickets and an office or housing space, as well as a two people service the space. In addition, funds are available for seven permanent assistants.

President Hollande announced a reform of the system in 2016. Former presidents of France will no longer receive a car with chauffeur; the personnel in their living space were cut as well. Additionally, the number of assistants available for their use has been reduced, but a state flat or house remains available for former officeholders. Train tickets are also available if the trip is justified by the office of the former officeholder as part of official business. The security personnel around former presidents of France remained unchanged.

The most recent president of the French Republic to die was Jacques Chirac (served 1995–2007) on 26 September 2019, aged 86.




</doc>
<doc id="24900" url="https://en.wikipedia.org/wiki?curid=24900" title="Plastic explosive">
Plastic explosive

Plastic explosive is a soft and hand-moldable solid form of explosive material. Within the field of explosives engineering, plastic explosives are also known as putty explosives.

Plastic explosives are especially suited for explosive demolition. Common plastic explosives include Semtex and C-4. The first manufactured plastic explosive was gelignite in 1875, invented by Alfred Nobel.

Plastic explosives are especially suited for explosive demolition of obstacles and fortifications by engineers, combat engineers and criminals as they can be easily formed into the best shapes for cutting structural members and have a high enough velocity of detonation and density for metal cutting work.

An early use of plastic explosives was in the warhead of the Petard demolition mortar of the British Armoured Vehicle Royal Engineers (AVRE); said mortar was used to destroy concrete fortifications encountered during Operation Overlord (D-Day). The original use of Nobel 808 supplied by the SOE was for sabotage of German installations and railways in Occupied Europe.

They are generally not used for ordinary blasting as they tend to be significantly more expensive than other materials that perform just as well in this application. A common commercial use of plastic explosives is for shock hardening high manganese percentage steel, a material typically used for train rail components and earth digging implements.

Reactive armor in tanks uses plastic explosives sandwiched between two plates of steel. Incoming high explosive anti-tank rounds pierce the outer steel plate, then detonate the plastic explosive. This absorbs the energy from the incoming tank round and shields the tank.

The first plastic explosive was gelignite, invented by Alfred Nobel in 1875. Prior to World War I, the British explosives chemist Oswald Silberrad obtained British and U.S. patents for a series of plastic explosives called "Nitrols", composed of nitrated aromatics, collodion, and oxidising inorganic salts. The language of the patents indicate that at this time, Silberrad saw no need to explain to "those versed in the art" either what he meant by plasticity or why it may be advantageous, as he only explains why his plastic explosive is superior to others of that type.

One of the simplest plastic explosives was Nobel's Explosive No. 808, also known as "Nobel 808" (often just called "Explosive 808" in the British Armed Forces during the Second World War), developed by the British company Nobel Chemicals Ltd well before World War II. It had the appearance of green plasticine with a distinctive smell of almonds. During World War II it was extensively used by the British Special Operations Executive (SOE) at Aston House for sabotage missions. It is also the explosive used in HESH anti-tank shells and was an essential factor in the devising of the Gammon grenade. Captured SOE-supplied Nobel 808 was the explosive used in the failed 20 July plot assassination attempt on Adolf Hitler in 1944.

During and after World War II a number of new RDX-based explosives were developed, including Compositions C, C2, and eventually C3. Together with RDX, these incorporate various plasticizers to decrease sensitivity and make the composition plastic. The origin of the obsolete term "plastique" dates back to the Nobel 808 explosive introduced to the U.S. by the British in 1940. The samples of explosive brought to the U.S. by the Tizard Mission had already been packaged by the SOE ready for dropping via parachute container to the French Resistance and were therefore labeled in French, as "Explosif Plastique". It is still referred to by this name in France and also by some Americans.

The British used a plastic explosive during World War II as a demolition charge. The specific explosive, Composition C, was 88.3% RDX and 11.7% non-oily, non-explosive plasticizer. The material was plastic between 0 and 40 degrees C, but was brittle at colder temperatures and gummy at higher temperatures. Composition C was superseded by Composition C2, which used a mixture of 80% RDX and 20% plasticizer. Composition C2 had a wider temperature range at which it remained plastic, from −30 to 52 degrees C. Composition C2 was replaced by Composition C3, which was a mixture of 77% RDX and 23% explosive plasticizer. C3 was effective but proved to be too brittle in cold weather and was replaced with C4. There are three classes of C4, with varying amounts of RDX and polyisobutylene.




</doc>
<doc id="24902" url="https://en.wikipedia.org/wiki?curid=24902" title="Post-structuralism">
Post-structuralism

Post-structuralism is the literary and philosophical work that both builds upon and rejects ideas within structuralism, the intellectual project that preceded it. Though post-structuralists all present different critiques of structuralism, common themes among them include the rejection of the self-sufficiency of structuralism, as well as an interrogation of the binary oppositions that constitute its structures. Accordingly, post-structuralism discards the idea of interpreting media (or the world) within pre-established, socially-constructed structures.

"Structuralism" proposes that one may understand human culture by means of a structure modeled on language. This understanding differs from concrete reality and from abstract ideas, instead as "third order" that mediates between the two. Building upon structuralist conceptions of reality mediated by the interrelationship between signs, a post-structuralist critique might suggest that to build meaning out of such an interpretation one must (falsely) assume that the definitions of these signs are both valid and fixed, and that the author employing structuralist theory is somehow above and apart from these structures they are describing so as to be able to wholly appreciate them. The rigidity, tendency to categorize, and intimation of universal truths found in structuralist thinking is then a common target of post-structuralist thought.

Writers whose works are often characterised as post-structuralist include: Roland Barthes, Jacques Derrida, Michel Foucault, Gilles Deleuze, Judith Butler, Jean Baudrillard and Julia Kristeva, although many theorists who have been called "post-structuralist" have rejected the label.

Structuralism as an intellectual movement in France in the 1950s and 1960s studied underlying structures in cultural products (such astexts) and used analytical concepts from linguistics, psychology, anthropology, and other fields tointerpret those structures. Structuralism posits the concept of binary opposition, in which frequently-used pairs of opposite but related words (concepts) are often arranged in a hierarchy; for example: Enlightenment/Romantic, male/female, speech/writing, rational/emotional, signified/signifier, symbolic/imaginary.

Post-structuralism rejects the structuralist notion that the dominant word in a pair is dependent on its subservient counterpart and instead argues that founding knowledge either on pure experience (phenomenology) or on systematic structures (structuralism) is impossible, because history and culture condition the study of underlying structures and these are subject to biases and misinterpretations. Gilles Deleuze and others saw this impossibility not as a failure or loss, but rather as a cause for "celebration and liberation." A post-structuralist approach argues that to understand an object (a text, for example), one must study both the object itself and the systems of knowledge that produced the object. The uncertain boundaries between structuralism and post-structuralism become further blurred by the fact that scholars rarely label themselves as post-structuralists. Some scholars associated with structuralism, such as Roland Barthes and Michel Foucault, also became noteworthy in post-structuralism.

Some observers from outside the post-structuralist camp have questioned the rigour and legitimacy of the field. American philosopher John Searle
suggested in 1990: "The spread of 'poststructuralist' literary theory is perhaps the best-known example of a silly but non-catastrophic phenomenon." Similarly, physicist Alan Sokal in 1997 criticized "the postmodernist/poststructuralist gibberish that is now hegemonic in some sectors of the American academy."

Literature scholar Norman Holland in 1992 saw post-structuralism as flawed due to reliance on Saussure's linguistic model, which was seriously challenged by the 1950s and was soon abandoned by linguists:Saussure's views are not held, so far as I know, by modern linguists, only by literary critics and the occasional philosopher. [Strict adherence to Saussure] has elicited wrong film and literary theory on a grand scale. One can find dozens of books of literary theory bogged down in signifiers and signifieds, but only a handful that refers to Chomsky."David Foster Wallace wrote:
Post-structuralism emerged in France during the 1960s as a movement critiquing structuralism. According to J. G. Merquior, a love–hate relationship with structuralism developed among many leading French thinkers in the 1960s. The period was marked by the rebellion of students and workers against the state in May 1968.

In a 1966 lecture titled "Structure, Sign, and Play in the Discourse of the Human Sciences", Jacques Derrida presented a thesis on an apparent rupture in intellectual life. Derrida interpreted this event as a "decentering" of the former intellectual cosmos. Instead of progress or divergence from an identified centre, Derrida described this "event" as a kind of "play."

A year later, Roland Barthes published "The Death of the Author", in which he announced a metaphorical event: the "death" of the author as an authentic source of meaning for a given text. Barthes argued that any literary text has multiple meanings and that the author was not the prime source of the work's semantic content. The "Death of the Author," Barthes maintained, was the "Birth of the Reader," as the source of the proliferation of meanings of the text.
In "Elements of Semiology" (1967), Barthes advances the concept of the "metalanguage", a systematized way of talking about concepts like meaning and grammar beyond the constraints of a traditional (first-order) language; in a metalanguage, symbols replace words and phrases. Insofar as one metalanguage is required for one explanation of the first-order language, another may be required, so metalanguages may actually replace first-order languages. Barthes exposes how this structuralist system is regressive; orders of language rely upon a metalanguage by which it is explained, and therefore deconstruction itself is in danger of becoming a metalanguage, thus exposing all languages and discourse to scrutiny. Barthes' other works contributed deconstructive theories about texts.

The occasional designation of post-structuralism as a movement can be tied to the fact that mounting criticism of Structuralism became evident at approximately the same time that Structuralism became a topic of interest in universities in the United States. This interest led to a colloquium at Johns Hopkins University in 1966 titled "The Languages of Criticism and the Sciences of Man", to which such French philosophers as Jacques Derrida, Roland Barthes, and Jacques Lacan were invited to speak.

Derrida's lecture at that conference, "Structure, Sign, and Play in the Human Sciences", was one of the earliest to propose some theoretical limitations to Structuralism, and to attempt to theorize on terms that were clearly no longer structuralist.

The element of "play" in the title of Derrida's essay is often erroneously interpreted in a linguistic sense, based on a general tendency towards puns and humour, while social constructionism as developed in the later work of Michel Foucault is said to create play in the sense of strategic agency by laying bare the levers of historical change. Many see the importance of Foucault's work to be in its synthesis of this social/historical account of the operation of power.

The following are often said to be post-structuralists, or to have had a post-structuralist period:



</doc>
<doc id="24903" url="https://en.wikipedia.org/wiki?curid=24903" title="Peace process">
Peace process

A peace process is the set of sociopolitical negotiations, agreements and actions that aim to solve a specific armed conflict.

Prior to an armed conflict occurring, peace processes can include the prevention of an intra-state or inter-state dispute from escalating into military conflict. The United Nations Department of Peace Operations (UNDPO) terms the prevention of disputes from escalating into armed conflicts as "conflict prevention". In 2007, the United Nations Secretary-General's Policy Committee classed both initial prevention of an armed conflict and prevention of the repeat of a solved conflict as peacebuilding.

For peace processes to resolve an armed conflict, Izumi Wakugawa, advisor to the Japan-based International Peace Cooperation Program, suggests a definition of a peace process as "a mixture of politics, diplomacy, changing relationships, negotiation, mediation, and dialogue in both official and unofficial arenas", which he attributes to Harold H. Saunders of the United States Institute of Peace (USIP). Wakugawa categorises these processes into two stages: the ceasing of armed conflict and the processes of sociological reorganisation.

Non-military processes for stopping an armed conflict stage are generally classed as peacemaking. Military methods by globally organised military forces of stopping a local armed conflict are typically classed as peace enforcement.

The prevention of the repeat of a solved conflict (as well as the preventing of an armed conflict from occurring at all) is usually classed as peacebuilding. UNDPO defines peacebuilding to include "measures [that] address core issues that effect the functioning of society and the State". The use of neutral military forces to sustain ceasefires during this phase, typically by United Nations peacekeeping forces, can be referred to as peacekeeping.

The terms "peacemaking", "peacekeeping" and "peacebuilding" tend to be used broadly, with their meanings defined in terms of the phases of various peace process mechanisms blurring and overlapping in practice.

The construction of international institutions, especially during the twentieth century, has to a large degree been motivated by the desire to provide a broad global context of peacebuilding. This includes the League of Nations and the United Nations, and regional institutions such as the European Union. Institutions involved in encouraging or overseeing some of the steps in specific peace processes include the United Nations Department of Peace Operations.

Many specific can comprise the elements of peace processes. The Peace Accords Matrix of the Kroc Institute for International Peace Studies at the University of Notre Dame, United States, lists some of these as amnesties, ceasefires, arms embargoes, truth and reconciliation commissions and reforms of the constitution, or of military, police, judicial or educational institutions or of the media. Other mechanisms include prisoner exchanges, confidence-building measures, humanitarian corridors, peace treaties and transitional justice.

According to Neville Melvin Gertze of Namibia, speaking at an October 2019 meeting of the United Nations Security Council, peace agreements that are the result of negotiations including women are 35 percent more likely to last at least 15 years than those which are the result of men-only negotiations. At the same meeting, United Nations Secretary-General António Guterres stated that women were excluded from peace processes, attacks against women human rights defenders had increased, and only a "tiny percentage" of funding for peacebuilding was given to women's organisations.



</doc>
<doc id="24905" url="https://en.wikipedia.org/wiki?curid=24905" title="Peyton Randolph">
Peyton Randolph

Peyton Randolph (September 10, 1721 – October 22, 1775) was a planter and public official from the Colony of Virginia. He served as Speaker of the Virginia House of Burgesses, president of Virginia Conventions, and the first President of the Continental Congress.

Randolph was born in Tazewell Hall, Williamsburg, Virginia, to a prominent family. His parents were Sir John Randolph, the son of William Randolph, and Susanna Beverley, the daughter of Peter Beverley; his brother was John Randolph. Peyton Randolph was 16 when his father died.

Randolph attended the College of William & Mary, and later studied law at Middle Temple at the Inns of Court in London, becoming a member of the bar in 1743. He lived his adulthood in Williamsburg.

Randolph returned to Williamsburg and was appointed Attorney General of the Colony of Virginia the next year.

He served several terms in the Virginia House of Burgesses, beginning in 1748. It was Randolph's dual roles as attorney general and as burgess that would lead to an extraordinary conflict of interest in 1751.

The new governor, Robert Dinwiddie, had imposed a fee for the certification of land patents, which the House of Burgesses strongly objected to. The House selected Peyton Randolph to represent their cause to Crown authorities in London. In his role as attorney general, though, he was responsible for defending actions taken by the governor. Randolph left for London, over the objections of Governor Dinwiddie, and was replaced for a short time as attorney general by George Wythe. Randolph resumed his post on his return at the behest of Wythe as well as officials in London, who also recommended the Governor drop the new fee.

In 1765, Randolph found himself at odds with a freshman burgess, Patrick Henry, over the matter of a response to the Stamp Act. The House appointed Randolph to draft objections to the act, but his more conservative plan was trumped when Henry obtained passage of five of his seven Virginia Stamp Act Resolutions. This was accomplished at a meeting of the House in which most of the members were absent, and over which Randolph was presiding in the absence of the Speaker.

Randolph resigned as king's attorney (attorney general) in 1766, as fellow Burgesses elected him as their Speaker upon the death of his relative, the powerful Speaker John Robinson. Sitting as the General Court, they also appointed Randolph one of the executors (with George Wythe and Edmund Pendleton) of the former speaker's estate, which was a major financial scandal. As friction between Britain and the colonies progressed, Randolph grew to favor independence. In 1769 the House of Burgesses was dissolved by the Governor, Norborne Berkeley, 4th Baron Botetourt, in response to its actions against the Townshend Acts. In 1773, Randolph chaired the Virginia committee of correspondence. The next Governor, John Murray, 4th Earl of Dunmore, also dissolved the House of Burgesses in 1774 when it showed solidarity with Boston, Massachusetts, following the Boston Port Act. Afterwards, Randolph chaired meetings of the first of five Virginia Conventions of former House members, principally at a Williamsburg tavern, which worked toward responses to the unwelcome tax measures imposed by the British government. On March 21, 1775, he was president of the Second Virginia Convention in Richmond that debated independence (the site of Patrick Henry's famous "give me liberty" speech). In April, Randolph negotiated with Lord Dunmore for gunpowder removed from the Williamsburg arsenal during the Gunpowder Incident, which was a confrontation between the Governor's forces and Virginia militia, led by Patrick Henry. The House of Burgesses was called back by Lord Dunmore one last time in June 1775 to address British Prime Minister Lord North's Conciliatory Resolution. Randolph, who was a delegate to the Continental Congress, returned to Williamsburg to take his place as Speaker. Randolph indicated that the resolution had not been sent to the Congress (it had instead been sent to each colony individually in an attempt to divide them and bypass the Continental Congress). The House of Burgesses rejected the proposal, which was also later rejected by the Continental Congress. Randolph was thus the last Speaker of the House of Burgesses (their role was replaced by the Virginia Conventions and later the House of Delegates in 1776). Randolph also served as the president of the Third Virginia Convention in July 1775, which as a legislative body elected a Committee of Safety to act as the colony's executive since Lord Dunmore had abandoned the capital and took refuge on a British warship. Edmund Pendleton would succeed Randolph as president of the later conventions.

Virginia selected Randolph as one of its delegates to the Continental Congress in Philadelphia in 1774 and 1775. Fellow delegates elected him their president (Speaker) of both the First Continental Congress (which requested that King George III repeal the Coercive Acts) as well as Second Continental Congress (which extended the Olive Branch Petition as a final attempt at reconciliation). However, Randolph fell ill during each term. Henry Middleton of South Carolina succeeded him as president from his resignation on October 22, 1774, until his return on May 10, 1775. He was again elected President of Congress, but Randolph left for Virginia four days later and was succeeded as President by John Hancock. 

Randolph returned as a Virginia delegate but suffered a five-hour-long fit of apoplexy and died while dining with Thomas Jefferson in Philadelphia on October 22, 1775.

His remains were returned to Williamsburg and were interred at the chapel of the College of William and Mary. As the Continental Congress had assumed governmental duties for the colonies as a whole, such as appointing ambassadors, some consider Randolph to have been the first President of the United States, even though he died in 1775.

The Continental Congress honored Randolph by naming one of the first naval frigates as the USS "Randolph", as well by naming a fort at the junction of the Ohio and Kanawha Rivers as Fort Randolph.

Randolph County, North Carolina, Randolph, Massachusetts, and Randolph County, Indiana, were named to honor the colonial statesman.

During World War II, the early "Essex"-class aircraft carrier USS "Randolph" (CV-15) was named for him.

The Peyton Randolph House in Colonial Williamsburg was declared a National Historic Landmark in 1970.




</doc>
<doc id="24910" url="https://en.wikipedia.org/wiki?curid=24910" title="Product topology">
Product topology

In topology and related areas of mathematics, a product space is the Cartesian product of a family of topological spaces equipped with a natural topology called the product topology. This topology differs from another, perhaps more obvious, topology called the box topology, which can also be given to a product space and which agrees with the product topology when the product is over only finitely many spaces. However, the product topology is "correct" in that it makes the product space a categorical product of its factors, whereas the box topology is too fine; in that sense the product topology is the natural topology on the Cartesian product.

Given "X", also known as the product space, such that

is the Cartesian product of the topological spaces "X", indexed by formula_2, and the canonical projections "p" : "X" → "X", the product topology on "X" is defined to be the coarsest topology (i.e. the topology with the fewest open sets) for which all the projections "p" are continuous. The product topology is sometimes called the Tychonoff topology.

The open sets in the product topology are unions (finite or infinite) of sets of the form formula_3, where each "U" is open in "X" and "U" ≠ "X" for only finitely many "i". In particular, for a finite product (in particular, for the product of two topological spaces), the set of all Cartesian products between one basis element from each "X" gives a basis for the product topology of formula_4. That is, for a finite product, the set of all formula_3, where formula_6 is an element of the (chosen) basis of formula_7, is a basis for the product topology of formula_4.

The product topology on "X" is the topology generated by sets of the form "p"("U"), where "i" is in "I " and "U" is an open subset of "X". In other words, the sets {"p"("U")} form a subbase for the topology on "X". A subset of "X" is open if and only if it is a (possibly infinite) union of intersections of finitely many sets of the form "p"("U"). The "p"("U") are sometimes called open cylinders, and their intersections are cylinder sets.

In general, the product of the topologies of each "X" forms a basis for what is called the box topology on "X". In general, the box topology is finer than the product topology, but for finite products they coincide.

If one starts with the standard topology on the real line R and defines a topology on the product of "n" copies of R in this fashion, one obtains the ordinary Euclidean topology on R.

The Cantor set is homeomorphic to the product of countably many copies of the discrete space {0,1} and the space of irrational numbers is homeomorphic to the product of countably many copies of the natural numbers, where again each copy carries the discrete topology.

Several additional examples are given in the article on the initial topology.

The product space "X", together with the canonical projections, can be characterized by the following universal property: If "Y" is a topological space, and for every "i" in "I", "f" : "Y" → "X" is a continuous map, then there exists "precisely one" continuous map "f" : "Y" → "X" such that for each "i" in "I" the following diagram commutes:

This shows that the product space is a product in the category of topological spaces. It follows from the above universal property that a map "f" : "Y" → "X" is continuous if and only if "f" = "p" ∘ "f" is continuous for all "i" in "I". In many cases it is easier to check that the component functions "f" are continuous. Checking whether a map "f" : "Y" → "X" is continuous is usually more difficult; one tries to use the fact that the "p" are continuous in some way.

In addition to being continuous, the canonical projections "p" : "X" → "X" are open maps. This means that any open subset of the product space remains open when projected down to the "X". The converse is not true: if "W" is a subspace of the product space whose projections down to all the "X" are open, then "W" need not be open in "X". (Consider for instance "W" = R \ (0,1).) The canonical projections are not generally closed maps (consider for example the closed set formula_9 whose projections onto both axes are R \ {0}).

The product topology is also called the "topology of pointwise convergence" because of the following fact: a sequence (or net) in "X" converges if and only if all its projections to the spaces "X" converge. In particular, if one considers the space "X" = R of all real valued functions on "I", convergence in the product topology is the same as pointwise convergence of functions.

Any product of closed subsets of "X" is a closed set in "X".

An important theorem about the product topology is Tychonoff's theorem: any product of compact spaces is compact. This is easy to show for finite products, while the general statement is equivalent to the axiom of choice.


One of many ways to express the axiom of choice is to say that it is equivalent to the statement that the Cartesian product of a collection of non-empty sets is non-empty. The proof that this is equivalent to the statement of the axiom in terms of choice functions is immediate: one needs only to pick an element from each set to find a representative in the product. Conversely, a representative of the product is a set which contains exactly one element from each component.

The axiom of choice occurs again in the study of (topological) product spaces; for example, Tychonoff's theorem on compact sets is a more complex and subtle example of a statement that is equivalent to the axiom of choice, and shows why the product topology may be considered the more useful topology to put on a Cartesian product.



</doc>
<doc id="24913" url="https://en.wikipedia.org/wiki?curid=24913" title="Playdia">
Playdia

The (developed under the codename "BA-X") is a fifth-generation home video game console released exclusively in Japan in 1994 at the initial price of ¥24,800. It was intended for a young audience and, like many consoles of the era (e.g. the LaserActive and the 3DO Interactive Multiplayer), was marketed more as a multimedia home entertainment system than as a dedicated gaming console, with anime quiz software and edutainment making up most of the game library. The Playdia uses a single infrared joypad with simple controls. Bandai, the Playdia's manufacturer, was the only software publisher to support this console (except for VAP who published "Ie Naki Ko - Suzu no Sentaku" instead of Bandai).








</doc>
<doc id="24915" url="https://en.wikipedia.org/wiki?curid=24915" title="Pidgin">
Pidgin

A pidgin , or pidgin language, is a grammatically simplified means of communication that develops between two or more groups that do not have a language in common: typically, its vocabulary and grammar are limited and often drawn from several languages. It is most commonly employed in situations such as trade, or where both groups speak languages different from the language of the country in which they reside (but where there is no common language between the groups).

Fundamentally, a pidgin is a simplified means of linguistic communication, as it is constructed impromptu, or by convention, between individuals or groups of people. A pidgin is not the native language of any speech community, but is instead learned as a second language.

A pidgin may be built from words, sounds, or body language from a multitude of languages as well as onomatopoeia. As the lexicon of any pidgin will be limited to core vocabulary, words with only a specific meaning in lexifier language may acquire a completely new (or additional) meaning in the pidgin.

Pidgins have historically been considered a form of "patois", unsophisticated simplified versions of their lexifiers, and as such usually have low prestige with respect to other languages. However, not all simplified or "unsophisticated" forms of a language are pidgins. Each pidgin has its own norms of usage which must be learned for proficiency in the pidgin.

A pidgin differs from a creole, which is the first language of a speech community of native speakers that at one point arose from a pidgin. Unlike pidgins, creoles have fully developed vocabulary and patterned grammar. Most linguists believe that a creole develops through a process of nativization of a pidgin when children of acquired pidgin-speakers learn and use it as their native language.

"Pidgin" derives from a Chinese pronunciation of the English word "business", and all attestations from the first half of the nineteenth century given in the third edition of the "Oxford English Dictionary" mean 'business; an action, occupation, or affair' (the earliest being from 1807). The term "pidgin English" ("business English"), first attested in 1855, shows the term in transition to referring to language, and by the 1860s the term "pidgin" alone could refer to Pidgin English. The term was coming to be used in the more general linguistic sense represented by this article by the 1870s.

A popular false etymology for "pidgin" is English "pigeon", a bird sometimes used for carrying brief written messages, especially in times prior to modern telecommunications.

The word "pidgin", formerly also spelled "pigion", used to refer originally to Chinese Pidgin English, but was later generalized to refer to any pidgin. "Pidgin" may also be used as the specific name for local pidgins or creoles, in places where they are spoken. For example, the name of the creole language Tok Pisin derives from the English words "talk pidgin". Its speakers usually refer to it simply as "pidgin" when speaking English. Likewise, Hawaiian Creole English is commonly referred to by its speakers as "Pidgin".

The term "jargon" has also been used to refer to pidgins, and is found in the names of some pidgins, such as Chinook Jargon. In this context, linguists today use "jargon" to denote a particularly rudimentary type of pidgin; however, this usage is rather rare, and the term "jargon" most often refers to the words particular to a given profession.

Pidgins may start out as or become trade languages, such as Tok Pisin. Trade languages can eventually evolve into fully developed languages in their own right such as Swahili, distinct from the languages they were originally influenced by. Trade languages and pidgins can also influence an established language's vernacular, especially amongst people who are directly involved in a trade where that pidgin is commonly used, which can alternatively result in a regional dialect being developed.

Pidgins are usually less morphologically complex but more syntactically rigid than other languages, usually have fewer morphosyntactic irregularities than other languages.

Characteristics shared by most pidgins:


The initial development of a pidgin usually requires:


Keith Whinnom (in ) suggests that pidgins need three languages to form, with one (the superstrate) being clearly dominant over the others.

Linguists sometimes posit that pidgins can become creole languages when a generation of children learn a pidgin as their first language,
a process that regularizes speaker-dependent variation in grammar. Creoles can then replace the existing mix of languages to become the native language of a community (such as the Chavacano language in the Philippines, Krio in Sierra Leone, and Tok Pisin in Papua New Guinea). However, not all pidgins become creole languages; a pidgin may die out before this phase would occur (e.g. the Mediterranean Lingua Franca).

Other scholars, such as Salikoko Mufwene, argue that pidgins and creoles arise independently under different circumstances, and that a pidgin need not always precede a creole nor a creole evolve from a pidgin. Pidgins, according to Mufwene, emerged among trade colonies among "users who preserved their native vernaculars for their day-to-day interactions". Creoles, meanwhile, developed in settlement colonies in which speakers of a European language, often indentured servants whose language would be far from the standard in the first place, interacted extensively with non-European slaves, absorbing certain words and features from the slaves' non-European native languages, resulting in a heavily basilectalized version of the original language. These servants and slaves would come to use the creole as an everyday vernacular, rather than merely in situations in which contact with a speaker of the superstrate was necessary.

The following pidgins have Wikipedia articles or sections in articles. Many of these languages are commonly referred to by their speakers as "Pidgin". 






</doc>
<doc id="24916" url="https://en.wikipedia.org/wiki?curid=24916" title="Polish">
Polish

Polish may refer to:

Polish may refer to:



</doc>
<doc id="24918" url="https://en.wikipedia.org/wiki?curid=24918" title="People's Liberation Army Navy">
People's Liberation Army Navy

The People's Liberation Army Navy (, Pinyin: Zhōngguó rénmín jiěfàngjūn hǎijūn), also known as the Chinese Navy, PLA Navy or PLAN, is the naval warfare branch of the People's Liberation Army, the armed wing of the Communist Party of China and, by default, the national armed forces of the People's Republic of China. The PLAN can trace its lineage to naval units fighting during the Chinese Civil War and was established on 23 April 1949. Throughout the 1950s and early 1960s, the Soviet Union provided assistance to the PLAN in the form of naval advisers and export of equipment and technology. Until the late 1980s, the PLAN was largely a riverine and littoral force (brown-water navy). However, by the 1990s, following the fall of the Soviet Union and a shift towards a more forward-oriented foreign and security policy, the leaders of the Chinese military were freed from worrying over land border disputes. Having traditionally been subordinated to the PLA Ground Force, PLAN leaders were able to advocate for a renewed attention towards the seas.

In 2008, China confirmed plans to operate a small fleet of aircraft carriers in the near future, but for the purpose of regional defence as opposed to "global reach". By 2009, with the advancements in naval techonology, the PLAN was recognized to have reached the status of a green-water navy. Chinese military officials have also outlined plans to operate in the first and second island chains, and are working towards blue water capability. Chinese strategists term the development of the PLAN from a green-water navy into "a regional blue-water defensive and offensive navy." The People's Liberation Army Navy (PLAN) plans to have at least 6 aircraft carriers by 2035.

The People's Liberation Army Navy is composed of five branches; the Submarine Force, the Surface Force, the Coastal Defense Force, the Marine Corps and the Naval Air Force. With a personnel strength of 240,000 personnel, including 15,000 marines and 26,000 naval air force personnel, it is the second largest navy in the world in terms of tonnage, only behind the United States Navy, and has the largest number of major combatants of any navy.

The PLAN traces its lineage to units of the Republic of China Navy (ROCN) who defected to the People's Liberation Army towards the end of the Chinese Civil War. In 1949, Mao Zedong asserted that "to oppose imperialist aggression, we must build a powerful navy". During the Landing Operation on Hainan Island, the communists used wooden junks fitted with mountain guns as both transport and warships against the ROCN. The navy was established in 23 April 1949 by consolidating regional naval forces under Joint Staff Department command in Jiangyan (now in Taizhou, Jiangsu). The Naval Academy was set up at Dalian on 22 November 1949, mostly with Soviet instructors. It then consisted of a motley collection of ships and boats acquired from the Kuomintang forces. The Naval Air Force was added two years later. By 1954 an estimated 2,500 Soviet naval advisers were in China—possibly one adviser to every thirty Chinese naval personnel—and the Soviet Union began providing modern ships. With Soviet assistance, the navy reorganized in 1954 and 1955 into the North Sea Fleet, East Sea Fleet, and South Sea Fleet, and a corps of admirals and other naval officers was established from the ranks of the ground forces. In shipbuilding the Soviets first assisted the Chinese, then the Chinese copied Soviet designs without assistance, and finally the Chinese produced vessels of their own design. Eventually Soviet assistance progressed to the point that a joint Sino-Soviet Pacific Ocean fleet was under discussion.

Through the upheavals of the late 1950s and 1960s the Navy remained relatively undisturbed. Under the leadership of Minister of National Defense Lin Biao, large investments were made in naval construction during the frugal years immediately after the Great Leap Forward. During the Cultural Revolution, a number of top naval commissars and commanders were purged, and naval forces were used to suppress a revolt in Wuhan in July 1967, but the service largely avoided the turmoil affecting the country. Although it paid lip service to Mao and assigned political commissars aboard ships, the Navy continued to train, build, and maintain the fleets as well the coastal defense and aviation arms, as well as in the performance of its mission.

In the 1970s, when approximately 20 percent of the defence budget was allocated to naval forces, the Navy grew dramatically. The conventional submarine force increased from 35 to 100 boats, the number of missile-carrying ships grew from 20 to 200, and the production of larger surface ships, including support ships for oceangoing operations, increased. The Navy also began development of nuclear attack submarines (SSN) and nuclear-powered ballistic missile submarines (SSBN).

In the 1980s, under the leadership of Chief Naval Commander Liu Huaqing, the navy developed into a regional naval power, though naval construction continued at a level somewhat below the 1970s rate. Liu Huaqing was an Army Officer who spent most of his career in administrative positions involving science and technology. It was not until 1988 that the People's Liberation Army Navy was led by a Naval Officer. Liu was also very close to Deng Xiaoping as his modernization efforts were very much in keeping with Deng's national policies. While under his leadership Naval construction yards produced fewer ships than the 1970s, greater emphasis was placed on technology and qualitative improvement. Modernization efforts also encompassed higher educational and technical standards for personnel; reformulation of the traditional coastal defense doctrine and force structure in favor of more green-water operations; and training in naval combined-arms operations involving submarine, surface, naval aviation, and coastal defense forces. Examples of the expansion of China's capabilities were the 1980 recovery of an intercontinental ballistic missile (ICBM) in the Western Pacific by a twenty-ship fleet, extended naval operations in the South China Sea in 1984 and 1985, and the visit of two naval ships to three South Asian nations in 1985. In 1982 the navy conducted a successful test of an underwater-launched ballistic missile. The navy also had some success in developing a variety of surface-to-surface and air-to-surface missiles, improving basic capabilities.

In 1986 the Navy's order of battle included two "Xia"-class SSBNs armed with twelve CSS-N-3 missiles and three Han-class SSNs armed with six SY-2 cruise missiles. In the late 1980s, major deficiencies reportedly remained in antisubmarine warfare, mine warfare, naval electronics (including electronic countermeasures equipment), and naval aviation capabilities.

The PLA Navy was ranked in 1987 as the third largest navy in the world, although naval personnel had comprised only 12 percent of PLA strength. In 1987 the Navy consisted (as it does now) of the naval headquarters in Beijing; three fleet commands – the North Sea Fleet, based at Qingdao, Shandong; the East Sea Fleet, based at Ningbo; and the South Sea Fleet, based at Zhanjiang, Guangdong – and about 1,000 ships of which only approximately 350 are ocean going. The rest are small patrol or support craft. The 350,000-person Navy included Naval Air Force units of 34,000 men, the Coastal Defense Forces of 38,000, and the Marine Corps of 56,500. Navy Headquarters, which controlled the three fleet commands, was subordinate to the PLA General Staff Department. In 1987, China's 1,500 km coastline was protected by approximately 70 diesel-powered Romeo- and Whiskey-class submarines, which could remain at sea only a limited time. Inside this protective ring and within range of shore-based aircraft were destroyers and frigates mounting Styx anti-ship missiles, depth-charge projectors, and guns up to 130 mm. Any invader penetrating the destroyer and frigate protection would have been swarmed by almost 900 fast-attack craft. Stormy weather limited the range of these small boats, however, and curtailed air support. Behind the inner ring were Coastal Defense Force personnel operating naval shore batteries of Styx missiles and guns, backed by ground force units deployed in depth.

As the 21st century approached, the PLAN began to transition to an off-shore defensive strategy that entailed more out-of-area operations away from its traditional territorial waters. Between 1989 and 1993, the training ship "Zhenghe" paid ports visits to Hawaii, Thailand, Bangladesh, Pakistan, and India. PLAN vessels visited Vladivostok in 1993, 1994, 1995, and 1996. PLAN task groups also paid visits to Indonesia in 1995; North Korea in 1997; New Zealand, Australia, and the Philippines in 1998; Malaysia, Tanzania, South Africa, the United States, and Canada in 2000; and India, Pakistan, France, Italy, Germany, Britain, Hong Kong, Australia, and New Zealand in 2001. In March 1997, the "Luhu"-class guided missile destroyer "Harbin", the "Luda"-class guided missile destroyer "Zhuhai", and the replenishment oiler "Nancang" began the PLA Navy's first circumnavigation of the Pacific Ocean, a 98-day voyage with port visits to Mexico, Peru, Chile, and the United States, including Pearl Harbor and San Diego. The flotilla was under the command of Vice Admiral Wang Yongguo, the commander-in-chief of the South Sea Fleet.

The "Luhu"-class guided missile destroyer "Qingdao" and the replenishment oiler "Taicang" completed the PLA Navy's first circumnavigation of the world "(pictured)", a 123-day voyage covering between 15 May – 23 September 2002. Port visits included Changi, Singapore; Alexandria, Egypt; Aksis, Turkey; Sevastopol, Ukraine; Piraeus, Greece; Lisbon, Portugal; Fortaleza, Brazil; Guayaquil, Ecuador; Callao, Peru; and Papeete in French Polynesia. The PLA naval vessels participated in naval exercises with the French frigates "Nivôse" and "Prairial", as well as exercises with the Peruvian Navy. The flotilla was under the command of Vice Admiral Ding Yiping, the commander-in-chief of the North Sea Fleet, and Captain Li Yujie was the commanding officer of the "Qingdao". Overall, between 1985 and 2006, PLAN naval vessels visited 18 Asian-Pacific nations, 4 South American nations, 8 European nations, 3 African nations, and 3 North American nations. In 2003, the PLAN conducted its first joint naval exercises during separate visits to Pakistan and India. Bi-lateral naval exercises were also carried out with exercises with the French, British, Australian, Canadian, Philippine, and United States navies.

On 26 December 2008, the PLAN dispatched a task group consisting of the guided missile destroyer "Haikou" (flagship), the guided missile destroyer "Wuhan", and the supply ship "Weishanhu" to the Gulf of Aden to participate in anti-piracy operations off the coast of Somalia. A team of 16 Chinese Special Forces members from its Marine Corps armed with attack helicopters were on board. Since then, China has maintained a three-ship flotilla of two warships and one supply ship in the Gulf of Aden by assigning ships to the Gulf of Aden on a three monthly basis. Other recent PLAN incidents include the 2001 Hainan Island incident, a major submarine accident in 2003, and naval incidents involving the U.S. MSC-operated ocean surveillance ships and during 2009. At the occasion of the 60th anniversary of the PLAN, 52 to 56 vessels were shown in manoeuvres off Qingdao in April 2009 including previously unseen nuclear submarines. The demonstration was seen as a sign of the growing status of China, while the CMC Chairman, Hu Jintao, indicated that China is neither seeking regional hegemony nor entering an arms race. Predictions by Western analysts that the PLAN would outnumber the USN submarine force as early as 2011 have failed to come true because the PRC curtailed both imports and domestic production of submarines.

Beginning in 2009, China ordered 4 Zubr-class LCAC from Ukraine and bought 4 more from the Hellenic Navy (Greece). These hovercraft/LCACs are built to send troops and armored vehicles (tanks, etc.) onto beaches in a fast manner, acting as a landing craft, and were viewed to be a direct threat to Taiwan's pro-independence movement as well as the conflict over Senkaku Islands. China is continually shifting the power balance in Asia by building up Navy's Submarines, Amphibious warfare and surface warfare capabilities.

Between 5–12 July 2013, a seven-ship task force from the Northern Fleet joined warships from the Russian Pacific Fleet to participate in Joint Sea 2013, bilateral naval maneuvers held in the Peter the Great Bay of the Sea of Japan. To date, Joint Sea 2013 was the largest naval drills yet undertaken by the People's Liberation Army Navy with a foreign navy.

On 2 April 2015, during the violent aftermath of a coup d'état in Yemen and amid an international bombing campaign, the PLAN helped 10 countries get their citizens out of Yemen safely, evacuating them aboard a missile frigate from the besieged port city of Aden. The operation was described by Reuters as "the first time that China's military has helped other countries evacuate their people during an international crisis".

China's participation on international maritime excises is also increasing. In RIMPAC 2014, China was invited to send ships from their People's Liberation Army Navy; marking not only the first time China participated in a RIMPAC exercise, but also the first time China participated in a large-scale United States-led naval drill. On 9 June 2014, China confirmed it would be sending four ships to the exercise, a destroyer, frigate, supply ship, & hospital ship. In April 2016, the People's Republic of China was also invited to RIMPAC 2016 despite the tension in South China Sea.

PRC military expert Yin Zhuo has said that due to present weaknesses in the PLAN's ability to replenish their ships at sea, their future aircraft carriers will be forced to operate in pairs.
In a TV interview, Zhang Zhaozhong suggest otherwise, saying China is "unlikely to put all her eggs in one basket" and that the navy will likely rotate between carriers rather than deploy them all at once.

The PLAN is organized into several departments for purposes of command, control and coordination. Main operating forces are organized into fleets, each with its own headquarters, a commander (a Rear Admiral or Vice Admiral) and a Political Commisar. All PLAN headquarters are subordinate to the PLA Joint Staff Department and the Chairman of the Central Military Commission.

The People's Liberation Army Navy is divided into three fleets:

Each fleet consists of surface forces (destroyers, frigates, amphibious vessels etc.), submarine forces, coastal defence units, and aircraft.

The People's Liberation Army Surface Force consists of all surface warships in service with the PLAN. They are organised into flotillas spread across the three main fleets.

The People's Liberation Army Navy Submarine Force consists of all nuclear and diesel-electric submarines in service with the PLAN. They are organised into flotillas spread across the three main fleets.

The PRC is the last of the permanent members of the United Nations Security Council which has not conducted an operational ballistic missile submarine patrol, because of institutional problems. It operates a fleet of 68 submarines.

The PLAN Coastal Defence Force is a land-based branch of the PLAN in charge of coastal defence, with a strength of around 25,000 personnel. Also known as the coastal defense troops, they serve to defend China's coastal and littoral areas from invasion via amphibious landings or air attacks.

Between the 1950s and 1960s, the Coastal Defense Force was primarily assigned to repel any Kuomintang attempts to infiltrate, invade and harass the Chinese coastline. After the Sino-Soviet split and the abandonment of KMT's plans to recapture the Mainland, the Coastal Defense Force was focused on defending China's coast from a possible Soviet sea-borne invasion throughout the 1960s to 1980s. With the fall of the Soviet Union, the threat of an amphibious invasion of China has diminished and therefore the branch is often considered to no longer be a vital component of the PLAN, especially as the surface warships of the PLAN continue to improve in terms of anti-ship and air-defence capabilities and the PLAN's power projection begins to extend beyond the first island chain.

Today the primary weapons of the coastal defense troops are the HY-2, YJ-82 and C-602 anti-ship missiles.

The PLAN Marine Corps was originally established in the 1950s and then re-established in 1979 under PLAN organisation. It consists of around 12,000 marines organised into two 6000-man brigades, and is based in the South China Sea with the South Sea Fleet. The Marine Corps are considered elite troops, and are rapid deployment forces trained primarily in amphibious warfare and sometimes as paratroopers to establish a beachhead or act as a spearhead during assault operations against enemy targets. The marines are equipped with the standard Type 95 assault rifles as well as other small arms and personnel equipment, and a blue/littoral camouflage uniform as standard. The marines are also equipped with amphibious armoured fighting vehicles (including amphibious light tanks such as the Type 63, assault vehicles such as the ZTD-05 and IFVs such as ZBD-05), helicopters, naval artillery, anti-aircraft weapon systems and short range surface-to-air missiles.

With the PLAN's accelerating efforts to expand its capabilities beyond territorial waters, it would be likely for the Marine Corps to play a greater role in terms of being an offshore expeditionary force similar to the USMC and Royal Marines.

The People's Liberation Army Naval Air Force (PLANAF) is the naval aviation branch of the PLAN and has a strength of around 25,000 personnel and 690 aircraft. It operates similar hardwares to the People's Liberation Army Air Force, including fighter aircraft, bombers, attack aircraft, tankers, reconnaissance/early warning aircraft, electronic warfare aircraft, maritime patrol aircraft, transport aircraft and helicopters of various roles. The PLA Naval Air Force has traditionally operated from coastal air bases, and received older aircraft than the PLAAF with less ambitious steps towards mass modernization. Advancements in new technologies, weaponry and aircraft acquisition were made after 2000. With the introduction of China's first aircraft carrier, "Liaoning", in 2012, the Naval Air Force is conducting carrier-based operations for the first time with the goal of building carrier battle group-focused blue water capabilities.

The PLANAF naval air bases include:

The PLAN is complemented by paramilitary maritime services such as the China Coast Guard. The Chinese Coast Guard was previously not under an independent command, considered part of the armed police, under the local (provincial) border defense force command, prior to its reorganization and consolidation as an unified service. It was formed from the integration of several formerly separate services (such as China Marine Surveillance (CMS), Hai Guang, People's Armed Police and sea militia). The CMS performed mostly coastal and ocean search and rescue or patrols. The CMS received quite a few large patrol ships that significantly enhanced their operations, while Hai Guang, militia, police and other services operated hundreds of small patrol craft. For maritime patrol services, these craft are usually quite well armed with machine guns and 37mm antiaircraft guns. In addition, these services operated their own small aviation units to assist their maritime patrol capabilities, with Hai Guang and CMS operating a handful of Harbin Z-9 helicopters, and a maritime patrol aircraft based on the Harbin Y-12 STOL transport.

Every coastal province has 1 to 3 Coast Guard squadrons:

The ranks in the People's Liberation Army Navy are similar to those of the People's Liberation Army Ground Force. The current system of officer ranks and insignia dates from 1988 and is a revision of the ranks and insignia used from 1955 to 1965. The rank of Hai Jun Yi Ji Shang Jiang (First Class Admiral) was never held and was abolished in 1994. With the official introduction of the Type 07 uniforms all officer insignia are on either shoulders or sleeves depending on the type of uniform used. The current system of enlisted ranks and insignia dates from 1998.

The People's Liberation Army Navy has become more prominent in recent years owing to a change in Chinese strategic priorities. The new strategic threats include possible conflict with the United States and/or a resurgent Japan in areas such as the Taiwan Strait or the South China Sea. As part of its overall program of naval modernization, the PLAN has a long-term plan of developing a blue water navy. Robert D. Kaplan has said that it was the collapse of the Soviet Union that allowed China to transfer resources from its army to its navy and other force projection assets. China is constructing a major underground nuclear submarine base near Sanya, Hainan. In December 2007 the first Type 094 submarine was moved to Sanya.
The Daily Telegraph on 1 May 2008 reported that tunnels were being built into hillsides which could be capable of hiding up to 20 nuclear submarines from spy satellites. According to the Western news media the base is reportedly to help China project seapower well into the Pacific Ocean area, including challenging United States naval power.

During a 2008 interview with the BBC, Major General Qian Lihua, a senior Chinese defense official, stated that the PLAN aspired to possess a small number of aircraft carriers to allow it to expand China's air defense perimeter. According to Qian the important issue was not whether China had an aircraft carrier, but what it did with it. On 13 January 2009, Adm. Robert F. Willard, head of the U.S. Pacific Command, called the PLAN's modernization "aggressive," and that it raised concerns in the region. On 15 July 2009, Senator Jim Webb of the Senate Foreign Relations Committee declared that only the "United States has both the stature and the national power to confront the obvious imbalance of power that China brings" to situations such as the claims to the Spratly and Paracel islands.

Ronald O'Rourke of the Congressional Research Service wrote that the PLAN "continues to exhibit limitations or weaknesses in several areas, including capabilities for sustained operations by larger formations in distant waters, joint operations with other parts of China’s military, C4ISR systems, anti-air warfare (AAW), antisubmarine warfare (ASW), MCM, and a dependence on foreign suppliers for certain key ship components." In 1998 China purchased the discarded Ukrainian ship Varyag and began retrofitting it for naval deployment. On 25 September 2012, the People's Liberation Army Navy took delivery of China's first aircraft carrier, the Liaoning. The 60,000 ton ship can accommodate 33 fixed wing aircraft. It is widely speculated that these aircraft will be the J15 fighter (the Chinese version of Russia's SU-33).

In September 2015, satellite images showed that China may have started constructing its first indigenous Type 001A aircraft carrier. At the time, the layout suggested to be displacement 50,000 ton and a hull to have a length of about 240 m and a beam of about 35 m. The incomplete bow suggests a length of at least 270 m for the completed hull. In April 2017 the carrier was launched.

Japan has raised concerns about the PLAN's growing capability and the lack of transparency as its naval strength keeps on expanding. China has reportedly entered into service the world's first anti-ship ballistic missile called DF-21D. The potential threat from the DF-21D against U.S. aircraft carriers has reportedly caused major changes in U.S. strategy.

In June 2017 China launched a new type of large destroyer, the Type 055 destroyer. The new destroyer is, with its dimension of 180 meter and over 12,000 tons fully loaded, the second largest destroyer class in the world after the American Zumwalt-class destroyer.

The Spratly Islands dispute is a territorial dispute over the ownership of the Spratly Islands, a group of islands located in the South China Sea. States staking claims to various islands are Brunei, Malaysia, the Philippines, Taiwan, Vietnam, and People's Republic of China. All except Brunei occupy some of the islands in dispute. The People's Republic of China conducted naval patrols in the Spratly Islands and established a permanent base.

On 14 March 1988, Chinese and Vietnamese naval forces clashed over Johnson South Reef in the Spratly Islands, which involved three PLAN frigates/

In February 2011, the Chinese frigate "Dongguan" fired three shots at Philippine fishing boats in the vicinity of Jackson atoll. The shots were fired after the frigate instructed the fishing boats to leave, and one of those boats experienced trouble removing its anchor. In May 2011, the Chinese patrol boats attacked and cut the cable of Vietnamese oil exploration ships near Spratly islands. The incidence sparked several anti-China protests in Vietnam. In June, the Chinese navy conducted three days of exercises, including live fire drills, in the disputed waters. This was widely seen as a warning to Vietnam, which had also conducted live fire drills near the Spratly Islands. Chinese patrol boats fired repeated rounds at a target on an apparently uninhabited island, as twin fighter jets streaked in tandem overhead. 14 vessels participated in the maneuvers, staging antisubmarine and beach landing drills aimed at "defending atolls and protecting sea lanes."

In May 2013, the Chinese navy's three operational fleets deployed together for the first time since 2010. This combined naval maneuvers in the South China Sea coincided with the ongoing Spratly Islands dispute between China and the Philippines as well as deployment of the U.S. Navy's Carrier Strike Group Eleven to the U.S. Seventh Fleet.

The Senkaku Islands dispute concerns a territorial dispute over a group of uninhabited islands known as the Diaoyu Islands in China, the Senkaku Islands in Japan, and Tiaoyutai Islands in Taiwan. Aside from a 1945 to 1972 period of administration by the United States, the archipelago has been controlled by Japan since 1895. The People's Republic of China disputed the proposed U.S. handover of authority to Japan in 1971 and has asserted its claims to the islands since that time. Taiwan also has claimed these islands. The disputed territory is close to key shipping lanes and rich fishing grounds, and it may have major oil reserves in the area.

On some occasions, ships and planes from various Mainland Chinese and Taiwanese government and military agencies have entered the disputed area. In addition to the cases where they escorted fishing and activist vessels, there have been other incursions. In an eight-month period in 2012, over forty maritime incursions and 160 aerial incursions occurred. For example, in July 2012, three Chinese patrol vessels entered the disputed waters around the islands.

Military escalation continued in 2013. In February, Japanese Defense Minister Itsunori Onodera claimed that a Chinese frigate had locked weapons-targeting radar onto a Japanese destroyer and helicopter on two occasions in January. A Chinese Jiangwei II class frigate and a Japanese destroyer were three kilometers apart, and the crew of the latter vessel went to battle stations. The Chinese state media responded that their frigates had been engaged in routine training at the time. In late February 2013, U.S. intelligence detected China moving road-mobile ballistic missiles closer to the coast near the disputed islands, including medium-range DF-16 anti-ship ballistic missiles. In May, a flotilla of Chinese warships from its North Sea Fleet deployed from Qingdao for training exercises western North Pacific Ocean. It is not known if this deployment is related to the ongoing islands dispute between China and Japan.

On 22 July 2011, following its Vietnam port-call, the Indian amphibious assault vessel was reportedly contacted 45 nautical miles from the Vietnamese coast in the disputed South China Sea by a party identifying itself as the Chinese Navy and stating that the Indian warship was entering Chinese waters. According to a spokesperson for the Indian Navy, since there were no Chinese ships or aircraft were visible, the INS "Airavat" proceeded on her onward journey as scheduled. The Indian Navy further clarified that "[t]here was no confrontation involving the INS "Airavat". India supports freedom of navigation in international waters, including in the South China Sea, and the right of passage in accordance with accepted principles of international law. These principles should be respected by all."

On 11 July 2012, the Chinese frigate "Dongguan" ran aground on Hasa Hasa Shoal ("pictured") located 60 nmi west of Rizal, which was within the Philippines' 200 nmi-EEZ. By 15 July, the frigate had been refloated and was returning to port with no injuries and only minor damage. During this incident, the 2012 ASEAN summit took place in Phnom Penh, Cambodia, amid the rising regional tensions.

On 18 December 2008, Chinese authorities deployed People's Liberation Army Navy vessels to escort Chinese shipping in the Gulf of Aden. This deployment came after a series of attacks and attempted hijackings on Chinese vessels by Somali pirates. Reports suggest two destroyers (Type 052C 171 Haikou and Type 052B 169 Wuhan) and a supply ship are the ones being used. This move was welcomed by the international community as the warships complement a multinational fleet already operating along the coast of Africa. Since this operation PLAN has sought the leadership of the ‘Shared Awareness and Deconfliction (SHADE)' body, which would require an increase in the number of ships contributing to the anti-piracy fleet. This is the first time Chinese warships have deployed outside the Asia-Pacific region for a military operation since Zheng He's expeditions in the 15th century.

Since then more than 30 People's Liberation Army Navy ships has deployed to the Gulf of Aden in 18 Escort Task Groups.
In the lead-up to the Libyan Civil War, the "Xuzhou" (530) was deployed from anti-piracy operations in the Gulf of Aden to help evacuate Chinese nationals from Libya.

During the Yemen conflict in 2015, the Chinese Navy diverted their frigates carrying out anti-piracy operations in Somalia to evacuate at least 600 Chinese and 225 foreign citizens working in Yemen. The majority of non-Chinese evacuees were 176 Pakistani citizens, although there were smaller numbers from other countries, such as Ethiopia, Singapore, the UK, Italy and Germany. Despite the evacuations the Chinese embassy in Yemen continued to operate.

As of 2018, the Chinese navy operates over 496 combat ships and 232 various auxiliary vessels and counts 255,000 seamen in its ranks. The Chinese Navy also employ more than 710 naval aircraft including fighters, bombers and electronic warfare aircraft. China has large amount of artillery, torpedoes, and missiles included in their combat assets.

All ships and submarines currently in commission with the People's Liberation Army Navy were built in China, with the exception of the Sovremenny-class destroyers, Kilo-class submarines and the aircraft carrier Liaoning. Those vessels were either imported from, or originated from Russia or Ukraine. As of 2008, English-language official Chinese state media no longer uses the term "People's Liberation Army Navy", instead the term "Chinese Navy" along with the usage of the unofficial prefix "CNS" for "Chinese Navy Ship" is now employed.

China employs a wide range of Navy combatants including aircraft carriers, amphibious warfare ships and destroyers. The Chinese Navy is undergoing modernization rapidly with nearly half of Chinese Navy combat ships are modern and built after 2010. China's state-owned shipyards have built 83 ships in just eight years with unprecedented speed. China has its own independent maritime missile defense and naval combat system similar to US Aegis.

China operates carrier-based fighter aircraft to secure land, air and sea targets. Chinese Navy also operate wide range of helicopter for battlefield logistics, reconnaissance, patrol and medical evacuation.

The unique QBS-06 is an underwater assault rifle with 5.8x42 DBS-06, and is used by Naval frogmen. It is based on the Soviet APS.

Chinese is developing advanced naval weaponry such as railgun. In early February 2018, pictures of what is claimed to be a Chinese railgun were published online. In the pictures the gun is mounted on the bow of a Type 072III-class landing ship "Haiyangshan". Media is suggesting that the system is or soon will be ready for testing. In March 2018, it was reported that China had confirmed that it had begun testing its electromagnetic rail gun at sea.

The PLAN's ambitions include operating out to the first and second island chains, as far as the South Pacific near Australia, and spanning to the Aleutian islands, and operations extending to the Straits of Malacca near the Indian Ocean. The future PLAN fleet will be composed of a balance of combatant assets aimed at maximising the PLAN's fighting effectiveness. On the high end, there would be modern destroyers equipped with long-range air defense missiles (Type 052B, Type 052C, Type 052D, Type 051C and Type 055); destroyers armed with supersonic anti-ship missiles ("Sovremenny" class); advanced nuclear-powered attack and ballistic missile submarines (Type 093, Type 095, Type 094, Type 096); advanced conventional attack submarines ("Kilo" and "Yuan" classes); aircraft carriers (Type 001A, Type 002 and Type 003) and large amphibious warfare vessels (Type 071 and Type 075) capable of mobilizing troops at long distances. On the medium and low end, there would be more economical multi-role capable frigates and destroyers ("Luhu", "Jiangwei II" and "Jiangkai" classes); corvettes ("Jiangdao" class); fast littoral missile attack craft ("Houjian", "Houxin" and "Houbei" classes); various landing ships and light craft; and conventionally powered coastal patrol submarines ("Song" class). The obsolete combat ships (based on 1960s designs) will be phased out in the coming decades as more modern designs enter full production. It may take a decade for the bulk of these older ships to be retired. Until then, they will serve principally on the low end, as multi-role patrol/escort platforms. Their use could be further enhanced in the future by being used as fast transports or fire support platforms. This system of phasing out would see a reversal in the decline in quantity of PLAN vessels by 2015, and cuts in inventory after the end of the Cold War could be made up for by 2020.

During 2001–2006 there has been a rapid building and acquisition program. There were more than a dozen new classes of ships built in these last five years, totaling some 60 brand new ships (including landing ships and auxiliaries). Simultaneously, dozens of other ships have been either phased out of service or refitted with new equipment. Submarines play a significant role in the development of the PLAN's future fleet. This is made evident by the construction of a new type of nuclear ballistic missile submarine, the Type 094 and the Type 093 nuclear attack submarine. This will provide the PLAN with a more modern response for the need of a seaborne nuclear deterrent. The new submarines will also be capable of performing conventional strike and other special warfare requirements.

The European Union has provided much of the propulsion technology for the PLAN's modernization.

Ronald O'Rourke of the Congressional Research Service reported that the long-term goals of PLAN planning include:

During the military parade on the 60th anniversary of the People's Republic of China, the YJ-62 naval cruise missile made its first public appearance; the YJ-62 represents the next generation in naval weapons technology in the PLA.

Next indigenous Type 002 class aircraft carrier to be a 70,000 ton displacement. A Chinese website stated that the PLAN is going to build a 110,000 ton Type 003 aircraft carrier, essentially a larger version of the "Liaoning" and its pattern indigenous carriers.

The PLA Navy plans to establish three aircraft carrier battle groups by 2020. The "Liaoning" and China's first two domestically built carriers, currently under construction, will be part of the battle groups. One of the battle groups is to be deployed in the East China Sea, while the other two are to be deployed to the South China Sea.

The PLAN may also operate from Gwadar or Seychelles for anti-piracy missions and to protect vital trade routes which may endanger China's energy security in the case of a conflict. In 2016, China established her first overseas naval base in Djibouti, which provided necessary support for Chinese fleet and troops.

China has reportedly begun testing designs for arsenal ships.

Currently the U.S. Navy is defining PLAN as its main potential adversary. Part of the debate is fueled in the US by US Navy funding requirements. While U.S. Navy decided to build a new class of small, cheap, numerous Littoral Combat Ships (LCS), the Chinese Navy met the same requirement with small, cheap, numerous catamaran Type 022 missile boats.




</doc>
<doc id="24921" url="https://en.wikipedia.org/wiki?curid=24921" title="Patrick Macnee">
Patrick Macnee

Daniel Patrick Macnee (6 February 1922 – 25 June 2015) was a British-American film and television actor. He played the role of secret agent John Steed in the British television series "The Avengers."

The elder of two sons, Macnee was born in Paddington, London, England on 6 February 1922; to Daniel Macnee (1878−1952) and Dorothea Mabel Macnee (née Henry) (1896−1984). His father, who was a grandson of the Scottish artist Sir Daniel Macnee, trained race horses in Lambourn, and was known for his dress sense; he had served as an officer in the Yorkshire Dragoons in the First World War. His maternal grandmother was Frances Alice Hastings (1870−1945), who was the daughter of Vice-Admiral George Fowler Hastings and granddaughter of Hans Francis Hastings, 12th Earl of Huntingdon. His younger brother James, known as Jimmy, was born five years later.

Macnee's parents separated after his mother began to identify as a lesbian. His father later moved to India, and his mother began to live with her wealthy partner, Evelyn Spottswood, whose money came from the Dewar's whisky business. Macnee referred to her in his autobiography as "Uncle Evelyn", and she helped pay for his schooling. He was educated at Summer Fields School and Eton College, where he was a member of the Officer Training Corps and was one of the guard of honour for King George V at St George's Chapel in 1936. He was later expelled from Eton for selling pornography and being a bookmaker for his fellow students.

Macnee studied acting at the Webber Douglas Academy of Dramatic Art, but shortly before he was to perform in his first West End leading role, which would have had him acting alongside Vivien Leigh, he was called up for the United Kingdom Armed Forces. He joined the Royal Navy as an ordinary seaman in October 1942 and was commissioned a sub-lieutenant in June 1943, becoming a navigator on Motor Torpedo Boats in the English Channel and North Sea. Reassigned as first lieutenant on a second MTB, Macnee caught bronchitis just before D-Day; while he was recuperating in hospital, his boat and crew were lost in action. Two of the crew received the Distinguished Service Medal. He left the Navy in 1946 as a lieutenant.

Macnee nurtured his acting career in Canada early on, but he also appeared as an uncredited extra in the British films "Pygmalion" (1938), "The Life and Death of Colonel Blimp" (1943) and Laurence Olivier's "Hamlet" (1948), as well as some live TV dramas for the BBC, before graduating to credited parts in such films as "Scrooge" (US: "A Christmas Carol", 1951), as the young Jacob Marley, the Gene Kelly vehicle "Les Girls" (1957), as an Old Bailey barrister, and the war film "The Battle of the River Plate" (1956). Between these occasional movie roles, Macnee spent the better part of the 1950s working in dozens of small parts in American and Canadian television and theatre, including an appearance in an episode of "The Twilight Zone" in 1959 ("Judgment Night"). Disappointed in his limited career development, in the late 1950s Macnee was daily smoking 80 cigarettes and drinking a bottle of whisky.

Not long before his career-making role in "The Avengers", Macnee took a break from acting and served as one of the London-based producers for the classic documentary series "The Valiant Years", based on the Second World War memoirs of Winston Churchill.

While working in London on the Churchill series, Macnee was offered the part in "The Avengers" (1961−69), (originally intended to be known as "Jonathan Steed"), for which he became best known. The series was originally conceived as a vehicle for Ian Hendry, who played the lead role of Dr. David Keel in a sequel to an earlier series, "Police Surgeon" (1960), while John Steed was his assistant. Macnee, though, became the lead after Hendry's departure at the end of the first season. Macnee played opposite a succession of glamorous female partners; Honor Blackman, Diana Rigg, and Linda Thorson. Of the 161 completed episodes, Macnee appeared in all but two, both from the first season.

Although Macnee evolved in the role as the series progressed, the key elements of Steed's persona and appearance were there from very early on: the slightly mysterious demeanour and, increasingly, the light, suave, flirting tone with ladies (and always with his female assistants). Finally, from the episodes with Blackman onwards, the trademark bowler hat and umbrella completed the image. Though it was traditionally associated with London "city gents", the ensemble of suit, umbrella and bowler had developed in the post-war years as mufti for ex-servicemen attending Armistice Day ceremonies. Steed's sartorial style may also have been drawn from Macnee's father. Macnee, alongside designer Pierre Cardin, adapted the look into a style all his own, and he went on to design several outfits himself for Steed based on the same basic theme. Steed was also the central character of "The New Avengers" (1976–77), in which he was teamed with agents named Purdey (Joanna Lumley) and Mike Gambit (Gareth Hunt).

Macnee insisted on, and was proud of, never carrying a gun in the original series; when asked why, he explained, "I'd just come out of a World War in which I'd seen most of my friends blown to bits." Lumley later said she did all the gun-slinging in "The New Avengers" for the same reason. 

When asked in June 1982 which "Avengers" female lead was his favourite, Macnee declined to give a specific answer. "Well, I'd rather not say. To do so would invite trouble," he told "TV Week" magazine. Macnee did provide his evaluation of the female leads. Of Honor Blackman he said, "She was wonderful, presenting the concept of a strong-willed, independent and liberated woman just as that sort of woman was beginning to emerge in society." Diana Rigg was "One of the world's great actresses. A superb comedienne. I'm convinced that one day she'll be Dame Diana" (his prediction came true in 1994). Linda Thorson was "one of the sexiest women alive" while Joanna Lumley was "superb in the role of Purdey. An actress who is only now realising her immense potential."

Macnee co-wrote two original novels based upon "The Avengers" during the 1960s, titled "Dead Duck" and "Deadline." He hosted a documentary, "The Avengers: The Journey Back" (1998), directed by Clyde Lucas.

For the critically lambasted film version of "The Avengers" (1998), he lent his voice in a cameo as "Invisible Jones". The character of Steed was taken over by Ralph Fiennes.

Macnee's other significant roles included playing Sir Godfrey Tibbett opposite Roger Moore in the James Bond film "A View to a Kill" (1985), as Major Crossley in "The Sea Wolves" (again with Moore), guest roles in "Encounter," "Alias Smith and Jones" (for Glen Larson), "Magnum, P.I.", "Hart to Hart," "Murder, She Wrote," and "The Love Boat." Although his best known part was heroic, many of his television appearances were as villains; among them were his roles of both the demonic Count Iblis and his provision of the character voice of the Cylons' Imperious Leader in "Battlestar Galactica," also for Glen Larson, for which he also supplied the show's introductory voiceover. He also presented the American paranormal series "Mysteries, Magic and Miracles." Macnee appeared on Broadway as the star of Anthony Shaffer's mystery "Sleuth" in 1972–73. He subsequently headlined the national tour of that play.

Macnee reunited with Diana Rigg in her short-lived NBC sitcom, "Diana" (1973) in a single episode. Other television appearances include a guest appearance on "Columbo" in the episode "Troubled Waters" (1975); and playing Major Vickers in "For the Term of His Natural Life" (1983). He had recurring roles in the crime series "Gavilan" with Robert Urich and in the short-lived satire on big business, "Empire" (1984), as Dr. Calvin Cromwell. Macnee also narrated the documentary "Ian Fleming: 007's Creator" (2000).

Macnee featured prominently in two editions of the long-running British television series "This Is Your Life": in 1978, when he and host Eamonn Andrews, both dressed as Steed, surprised Ian Hendry, and in 1984 when he was the edition's unsuspecting subject.

He also appeared in several cult films: in "The Howling" (1981), as 'Dr George Waggner' (named whimsically after the director of "The Wolf Man", 1941) and as Sir Denis Eton-Hogg in the rockumentary comedy "This Is Spinal Tap" (1984). He played Dr. Stark in "The Creature Wasn't Nice" (1981), also called "Spaceship" and "Naked Space". Macnee played the role of actor David Mathews in the made-for-television movie "Rehearsal for Murder" (1982), which starred Robert Preston and Lynn Redgrave. The movie was from a script written by "Columbo" co-creators Richard Levinson and William Link. He took over Leo G. Carroll's role as the head of U.N.C.L.E. His character being Sir John Raleigh in "" (1983), produced by Michael Sloan. He was featured in the science fiction television movie "Super Force" (1990) as E. B. Hungerford (the series which followed only featured Macnee's voice as a Max Headroom-style computer simulation of his character), as a supporting character in the parody film "Lobster Man From Mars" (1989) as Prof. Plocostomos and in "The Return of Sam McCloud" (1989), a TV film, as Tom Jamison. He made an appearance in "Frasier" (2001), and several episodes of the American science-fiction series "Nightman" as Dr. Walton, a psychiatrist who would advise Johnny/Nightman. Macnee appeared in two episodes of the series "" (1993–94) and was a retired agent in a handful of instalments of "Spy Game" (1997–98).

Macnee made numerous TV commercials including one around 1990 for Swiss Chalet, the Canadian restaurant chain, and a year or so before, a commercial for the Sterling Motor Car Company. Over the James Bond theme, the car duels with a motorcycle assailant at high speed through mountainous territory, ultimately eludes the foe, and reaches its destination. Macnee steps out of the car and greets viewers with a smile, saying, "I suppose you were expecting someone else". Macnee was the narrator for several "behind-the-scenes" featurettes for the James Bond series of DVDs and recorded numerous audio books, including the releases of many novels by Jack Higgins. He also recorded the children's books "The Musical Life of Gustav Mole" and its sequel, "The Lost Music (Gustav Mole's War on Noise)," both written by Michael Twinn.

Macnee featured in two pop videos: as Steed in original "Avengers" footage in The Pretenders' video for their song "Don't Get Me Wrong" (1986) and in the promotion for Oasis's "Don't Look Back in Anger" (1996), as the band's driver, a role similar to that which he played in the James Bond film "A View To A Kill" (1985). In 1990 his recording with his "Avengers" co-star Honor Blackman, called "Kinky Boots" (1964), reached the UK Singles Chart after being played on Simon Mayo's BBC Radio One breakfast show.

Macnee appeared in "Magnum, P.I." (1984) as a retired, but delusional, British agent, who believed he was Sherlock Holmes, in a season four episode titled "Holmes Is Where the Heart Is". He played both Holmes and Dr. Watson on several occasions. He played Watson three times: once alongside Roger Moore's Sherlock Holmes in a TV film, "Sherlock Holmes in New York" (1976), and twice with Christopher Lee, first in "Incident at Victoria Falls" (1991), and then in "Sherlock Holmes and the Leading Lady" (1992). He played Holmes in another TV film, "The Hound of London" (1993), along with the 1996 TV film "Sherlock Holmes: The Case of the Temporal Nexus" . He is thus one of only a very small number of actors to have portrayed both Sherlock Holmes and Dr. Watson on screen.

Macnee married his first wife, Barbara Douglas (1921–2012), in 1942. They had two children, Rupert and Jenny, and a grandson, Christopher ("Kit"). After they were divorced in 1956, his second marriage (1965−1969) was to actress Katherine Woodville. His third marriage was to Baba Majos de Nagyzsenye, daughter of opera singer Ella Némethy. It lasted from 1988 until her death in 2007. Macnee became a US citizen in 1959. He dictated his autobiography, which he entitled "Blind in One Ear: The Avenger Returns" (1988), to Marie Cameron. Later in life, Macnee was an enthusiastic nudist.

On 25 June 2015, Macnee died at Rancho Mirage, California, his home for the previous four decades, at the age of 93.





</doc>
<doc id="24922" url="https://en.wikipedia.org/wiki?curid=24922" title="List of Polish proverbs">
List of Polish proverbs


</doc>
<doc id="24927" url="https://en.wikipedia.org/wiki?curid=24927" title="Pembroke College, Cambridge">
Pembroke College, Cambridge

Pembroke College (officially "The Master, Fellows and Scholars of the College or Hall of Valence-Mary") is a constituent college of the University of Cambridge, England. The college is the third-oldest college of the university and has over seven hundred students and fellows. Physically, it is one of the university's larger colleges, with buildings from almost every century since its founding, as well as extensive gardens. Its members are termed "Valencians".

Pembroke has a level of academic performance among the highest of all the Cambridge colleges; in 2013, 2014, 2016, and 2018 Pembroke was placed second in the Tompkins Table.

Pembroke is home to the first chapel designed by Sir Christopher Wren and is one of the six Cambridge colleges to have educated a British prime minister, in Pembroke's case William Pitt the Younger. The college library, with a Victorian neo-gothic clock tower, is endowed with an original copy of the first encyclopaedia to contain printed diagrams.

The college's current master is Chris Smith, Baron Smith of Finsbury.

Marie de St Pol, Countess of Pembroke (1303–1377), a member of the de Châtillon family of France, founded Pembroke College, Cambridge. On Christmas Eve 1347, Edward III granted Marie de St Pol, widow of the Earl of Pembroke, the licence for the foundation of a new educational establishment in the young university at Cambridge. The "Hall of Valence Mary" ("Custos & Scolares Aule Valence Marie in Cantebrigg'"), as it was originally known, was thus founded to house a body of students and fellows. The statutes were notable in that they both gave preference to students born in France who had already studied elsewhere in England, and that they required students to report fellow students if they indulged in excessive drinking or visited disreputable houses.

The college was later renamed Pembroke Hall, and finally became Pembroke College in 1856.

Marie was closely involved with College affairs in the thirty years up to her death in 1377. She seems to have been something of a disciplinarian: the original Foundation documents had strict penalties for drunkenness and lechery, required that all students' debts were settled within two weeks of the end of term, and gave strict limits on numbers at graduation parties.

In 2015, the college received a bequest of £34 million from the estate of American inventor and Pembroke alumnus Ray Dolby, thought to be the largest single donation to a college in the history of Cambridge University.

The first buildings comprised a single court (now called Old Court) containing all the component parts of a college – chapel, hall, kitchen and buttery, master's lodgings, students' rooms – and the statutes provided for a manciple, a cook, a barber and a laundress. Both the founding of the college and the building of the city's first college Chapel (1355) required the grant of a papal bull.

The original court was the university's smallest at only by , but was enlarged to its current size in the nineteenth century by demolishing the south range.

The college's gatehouse is the oldest in Cambridge.

The original Chapel now forms the Old Library and has a striking seventeenth-century plaster ceiling, designed by Henry Doogood, showing birds flying overhead. Around the Civil War, one of Pembroke's fellows and Chaplain to the future Charles I, Matthew Wren, was imprisoned by Oliver Cromwell. On his release after eighteen years, he fulfilled a promise by hiring his nephew Christopher Wren to build a great Chapel in his former college. The resulting Chapel was consecrated on St Matthew's Day, 1665, and the eastern end was extended by George Gilbert Scott in 1880, when it was consecrated on the Feast of the Annunciation.

An increase in membership over the last 150 years saw a corresponding increase in building activity. The Hall was rebuilt in 1875–6 to designs by Alfred Waterhouse after he had declared the medieval Hall unsafe. As well as the Hall, Waterhouse designed a new range of rooms, Red Buildings (1871–72), in French Renaissance style, designed a new Master's Lodge on the site of Paschal Yard (1873, later to become N staircase), pulled down the old Lodge and the south range of Old Court to open a vista to the Chapel, and finally designed a new Library (1877–78) in the continental Gothic style. The construction of the new library was undertaken by Rattee and Kett.

Waterhouse was dismissed as architect in 1878 and succeeded by George Gilbert Scott, who, after extending the Chapel, provided additional accommodation with the construction of New Court in 1881, with letters on a series of shields along the string course above the first floor spelling out the text from Psalm 127:1, ("Except the Lord build the house, their labour is but vain that build it").

Building work continued into the 20th century with W. D. Caröe as architect. He added Pitt Building (M staircase) between Ivy Court and Waterhouse's Lodge, and extended New Court with the construction of O staircase on the other side of the Lodge. He linked his two buildings with an arched stone screen, Caröe Bridge, along Pembroke Street in a late Baroque style, the principal function of which was to act as a bridge by which undergraduates might cross the Master's forecourt at first-floor level from Pitt Building to New Court without leaving the College or trespassing in what was then the Fellows' Garden.

In 1926, as the Fellows had become increasingly disenchanted with Waterhouse's Hall, Maurice Webb was brought in to remove the open roof, put in a flat ceiling and add two storeys of sets above. The wall between the Hall and the Fellows' Parlour was taken down, and the latter made into a High Table dais. A new Senior Parlour was then created on the ground floor of Hitcham Building. The remodelling work was completed in 1949 when Murray Easton replaced the Gothic tracery of the windows with a simpler design in the style of the medieval Hall.
In 1933 Maurice Webb built a new Master's Lodge in the south-east corner of the College gardens, on land acquired from Peterhouse in 1861. Following the war, further accommodation was created with the construction in 1957 of Orchard Building, so called because it stands on part of the Foundress's orchard. Finally, in a move to accommodate the majority of junior members on the College site rather than in hostels in the town, in the 1990s Eric Parry designed a new range of buildings on the site of the Master's Lodge, with a new Lodge at the west end. "Foundress Court" was opened in 1997 in celebration of the College's 650th Anniversary. In 2001 the Library was extended to the east and modified internally.

In 2017, Pembroke College launched a new campaign of extension called the "Time and the place" (or the Mill Lane project), on the other side of Trumpington Street. This project will enlarge the size of the College by a third, with new social spaces, rooms and offices.

Pembroke's enclosed grounds include garden areas. Highlights include "The Orchard" (a patch of semi-wild ground in the centre of the college), an impressive row of Plane Trees and a bowling green, re-turfed in 1996, which is reputed to be among the oldest in continual use in Europe.

The arms of Pembroke College were officially recorded in 1684. The formal blazon combines the arms of De Valence (bars), dimidiated with the arms of St. Pol (vair). It is described as :

Pembroke holds Formal Hall on every evening. Students of the college must wear gowns and arrive on time for Latin Grace, which starts the dinner. Like many Cambridge colleges, Pembroke also has its annual May Ball.

According to popular legends, Pembroke is inhabited by ghosts occupying the Ivy Court.

Pembroke College has both graduate and undergraduate students, termed Valencians, after the College's original name, and its recreational rooms named as "parlours" rather than the more standard "combination room". The undergraduate student body is represented by the Junior Parlour Committee (JPC). The graduate community is represented by the Graduate Parlour Committee (GPC). In March 2016, the Junior Parlour Committee was featured in national newspapers after it cancelled the theme of an "Around The World in 80 Days" dance party.

There are many clubs and societies organised by the students of the college, such as the boat club Pembroke College Boat Club and the college's dramatic society the Pembroke Players, which has been made famous by alumni such as Peter Cook, Eric Idle, Tim Brooke-Taylor, Clive James and Bill Oddie and is now in its 60th year.

Pembroke is the only Cambridge college to have an International Programmes Department, providing opportunities for international students to spend a semester (mid-January to mid-June), or part of the summer, in Cambridge. The Spring Semester Programme is a competitive programme for academically outstanding students who wish to follow a regular Cambridge degree course as fully matriculated members of the University. There are around thirty places each year.

In the summer the College offers the eight-week Pembroke-King's Programme (PKP). As well as the academic content, trips are made to locales such as London, and the programme has a series of formal halls, which are described as "three-course candlelit meals" serving "interesting" fare in Pembroke's historic dining hall. The Pembroke-King's Programme is also the programme for which the prestigious Thouron Prize is awarded, fully supporting nine American undergraduates from Harvard, Yale, and UPenn.

Pembroke College, the former women's college at Brown University in the United States, was named for the principal building on the women's campus, Pembroke Hall, which was itself named in honour of the Pembroke College (Cambridge) alumnus Roger Williams, a co-founder of Rhode Island.

In 1865 Pembroke College donated land for the formation of the Suffolk memorial to Prince Albert. The land at Framlingham in the county of Suffolk was used to build a school, The Albert Memorial College. The school today is known as Framlingham College and one of its seven houses is named Pembroke House in recognition of the contribution Pembroke College has made to the School.

In 1981, a decade after the merger of Pembroke College into Brown University, the Pembroke Center for Teaching and Research on Women was named in honour of Pembroke College and the history of women's efforts to gain access to higher education.




</doc>
<doc id="24928" url="https://en.wikipedia.org/wiki?curid=24928" title="Prime ideal">
Prime ideal

Primitive ideals are prime, and prime ideals are both primary and semiprime.

An ideal of a commutative ring is prime if it has the following two properties:


This generalizes the following property of prime numbers: if is a prime number and if divides a product of two integers, then divides or divides . We can therefore say










One use of prime ideals occurs in algebraic geometry, where varieties are defined as the zero sets of ideals in polynomial rings. It turns out that the irreducible varieties correspond to prime ideals. In the modern abstract approach, one starts with an arbitrary commutative ring and turns the set of its prime ideals, also called its spectrum, into a topological space and can thus define generalizations of varieties called schemes, which find applications not only in geometry, but also in number theory.

The introduction of prime ideals in algebraic number theory was a major step forward: it was realized that the important property of unique factorisation expressed in the fundamental theorem of arithmetic does not hold in every ring of algebraic integers, but a substitute was found when Richard Dedekind replaced elements by ideals and prime elements by prime ideals; see Dedekind domain.

The notion of a prime ideal can be generalized to noncommutative rings by using the commutative definition "ideal-wise". Wolfgang Krull advanced this idea in 1928. The following content can be found in texts such as Goodearl's and Lam's. If is a (possibly noncommutative) ring and is an ideal in other than itself, we say that is prime if for any two ideals and of :


It can be shown that this definition is equivalent to the commutative one in commutative rings. It is readily verified that if an ideal of a noncommutative ring satisfies the commutative definition of prime, then it also satisfies the noncommutative version. An ideal satisfying the commutative definition of prime is sometimes called a completely prime ideal to distinguish it from other merely prime ideals in the ring. Completely prime ideals are prime ideals, but the converse is not true. For example, the zero ideal in the ring of matrices over a field is a prime ideal, but it is not completely prime.

This is close to the historical point of view of ideals as ideal numbers, as for the ring formula_22 " is contained in " is another way of saying " divides ", and the unit ideal represents unity.

Equivalent formulations of the ideal being prime include the following properties:

Prime ideals in commutative rings are characterized by having multiplicatively closed complements in , and with slight modification, a similar characterization can be formulated for prime ideals in noncommutative rings. A nonempty subset is called an m-system if for any and in , there exists in such that "arb" is in . The following item can then be added to the list of equivalent conditions above:




Prime ideals can frequently be produced as maximal elements of certain collections of ideals. For example:



</doc>
<doc id="24929" url="https://en.wikipedia.org/wiki?curid=24929" title="PC-FX">
PC-FX

The is a 32-bit home video game console developed by both NEC and Hudson Soft and released in Japan in 1994. Powered by an NEC V810 CPU and using CD-ROMs, the PC-FX was intended as the successor to the PC Engine and its international counterpart the TurboGrafx-16, two successful video game consoles from the late 1980s. It is NEC's final foray into the home console market.

The console is shaped like a tower PC and was meant to be similarly upgradeable. However the PC-FX lacked a 3D polygon-based graphics chip which rendered the system underpowered in comparison to its competitors. It was also expensive and lacked developer support, and as a result it was unable to compete effectively with its fifth generation peers. The PC-FX was NEC's last home video game console, and was discontinued in February 1998. It was also a commercial failure.

Founded in 1899, the NEC Corporation—originally known as the Nippon Electric Company—was originally a distributor of electrical switches and telephones for the Japanese market. Following the events of World War II, NEC began production of personal computers and underwater cable systems. It introduced the PC-8000 line of computers in 1979, which became a popular platform in Japan for aspiring video game developers. In 1987, NEC partnered with game publisher Hudson Soft to create the PC Engine, and later its international counterpart the TurboGrafx-16. The PC Engine was widely-successful, outselling the Sega Mega Drive and directly competing with Nintendo's Family Computer and later the Super Famicom. When the TurboGrafx was released overseas in 1989, it struggled to gain sales due to the release of the Sega Genesis and Super Nintendo Entertainment System.

The success of the PC Engine created a strong relationship between NEC and Hudson, who began work on a true successor to both platforms as early as 1990. While NEC had already released a successor a year prior, the SuperGrafx, it attracted little attention and was a commercial flop. Both companies designed a prototype system known as "Tetsujin" ("Iron Man"), a 32-bit console that featured full-screen video playback, 2 megabytes of RAM, and utilized CD-ROMs for its games. While NEC designed the console itself based on its previous experience with electronics, Hudson provided the necessary custom chipset and co-processors. The prototype was announced in 1992 and presented to companies that expressed interest. To demonstrate the system's capabilities, Hudson created a version of "Star Soldier" that displayed 3D objects over pre-rendered backdrops. When its presentation garnered considerable support, NEC and Hudson began to move forward with the project.

The Tetsujin was set to launch in 1992, however the lack of completed games pushed the launch date to spring 1993. The console was not launched on this date either; publications speculated that the PC Engine's continued success in the market made NEC and Hudson reluctant to release a succeeding platform. The release of technologically-superior consoles, such as the Atari Jaguar and 3DO Interactive Multiplayer, made the Tetsujin's hardware look more dated by comparison. Publications grew skeptical on how well it would perform in the market due to its inferior hardware and the amount of competing platforms. The Tetsujin was scrapped in early 1994 as the two companies began work on designing an improvement that could compete with systems such as the Sega Saturn. While NEC and Hudson knew that the system's technology was unimpressive, time constraints prevented them from creating a new one from scratch, which was codenamed "FX". The system was redesigned to resemble a PC tower, with slots that allowed for future models to increase its capabilities. Very little of the hardware itself was changed from the Tetsujin prototype, although the custom processors was reduced from five to one. The system was renamed to the PC-FX, the "PC" believed to be a nod to the PC Engine brand. NEC chose not to implement a polygon graphics processor, as it believed these had insufficient power and lead to in-game characters having a more blocky appearance.

The PC-FX was showcased at the 1994 Tokyo Toy Show in June. In addition to being presented alongside several other competing systems—the PlayStation, Sega Saturn, Neo Geo CD, and Bandai Playdia—its PC tower design was met with ridicule from commentators. Hudson demonstrated "FX Fighter", a full-motion video fighting game created in response to Sega's "Virtua Fighter", to showcase the system's capabilities. Its smooth-shaded polygonal visuals were met with praise from publications, which contributed to the anticipated launch of the console. NEC intended for the PC-FX's target audience to be at least five years older than the PC Engine, as they hoped it would lure in PC Engine fans to the platform. The console was launched in Japan on December 23, 1994, three years after its intended release date. NEC showed interest in releasing the PC-FX outside Japan if non-video game uses were created for it.

The PC-FX was discontinued in early 1998. It sold only 400,000 units over its lifetime.

The PC-FX uses CD-ROMs as its storage medium, following on from the expansion released for its predecessor, which originally used HuCards. The game controller is virtually identical to a DUO-RX controller, but the rapid fire switches have been replaced with mode A/B switches. Peripherals include a PC-FX mouse, which is supported by strategy games like "Farland Story FX" and "Power DoLLS FX".

The shining quality of the PC-FX was the ability to decompress 30 JPEG pictures per second while playing digitally recorded audio (essentially a form of Motion JPEG). This resulted in the PC-FX having superior full motion video quality over all other fifth generation consoles.

The PC-FX's computer-like design was unusual for consoles at the time. It stands upright like a tower computer while other contemporary consoles lay flat. Another interesting feature is its three expansion ports. Also, similar to the 3DO, it featured a built in power supply.

The PC-FX includes an HU 62 series 32-bit system board, an LSI chip, and a 32-bit V-810 RISC CPU. The system can display 16.77 million colors (the same amount as the PlayStation).

Unusual for a fifth generation console, the PC-FX does not have a polygon graphics processor. NEC's reasoning for this was that polygon processors of the time were relatively low-powered, resulting in figures having a blocky appearance, and that it would be better for games to use pre-rendered polygon graphics instead.

There were 62 games released for the system. The launch titles were "", "Battle Heat" and "Team Innocent" on December 23, 1994 and the final game released was "First Kiss Story" on April 24, 1998. The system and all titles were only released in Japan. A number of demo discs were also released with publications which allowed the user to play the disc in a CD equipped PC-Engine or the PC-FX.

NEC directed Hudson Soft, with whom they continued their partnership over the PC Engine, to develop only games based on popular anime franchises and using prerendered animated footage. Though this policy played to the hardware's strengths, it barred Hudson Soft from bringing successful PC Engine series such as Bomberman and Bonk to the PC-FX.

The system has a reputation for having a higher percentage of adults-only video games than other home consoles, in part thanks to its small library of games.

In a special Game Machine Cross Review in May 1995, "Famicom Tsūshin" would score the PC-FX console an 18 out of 40.


</doc>
