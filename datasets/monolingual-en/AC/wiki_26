<doc id="26436" url="https://en.wikipedia.org/wiki?curid=26436" title="Rent (musical)">
Rent (musical)

Rent (stylized as RENT) is a rock musical with music, lyrics, and book by Jonathan Larson, loosely based on Giacomo Puccini's 1896 opera "La Bohème". It tells the story of a group of impoverished young artists struggling to survive and create a life in Lower Manhattan's East Village in the thriving days of bohemian Alphabet City, under the shadow of HIV/AIDS.

The musical was first seen in a workshop production at New York Theatre Workshop in 1993. This same off-Broadway theatre was also the musical's initial home following its official 1996 opening. The show's creator, Jonathan Larson, died suddenly of an aortic dissection, believed to have been caused by undiagnosed Marfan syndrome, the night before the off-Broadway premiere. The musical moved to Broadway's larger Nederlander Theatre on April 29, 1996.

On Broadway, "Rent" gained critical acclaim and won several awards, including the Pulitzer Prize for Drama and the Tony Award for Best Musical. The Broadway production closed on September 7, 2008, after 12 years, making it one of the longest-running shows on Broadway. The production grossed over $280 million.

The success of the show led to several national tours and numerous foreign productions. In 2005, it was adapted into a motion picture featuring most of the original cast members.

In 1988, playwright Billy Aronson wanted to create "a musical based on Puccini's "La Bohème", in which the luscious splendor of Puccini's world would be replaced with the coarseness and noise of modern New York." In 1989, Jonathan Larson, a 29-year-old composer, began collaborating with Aronson on this project, and the two composed together "Santa Fe", "Splatter" (later re-worked into the song "Rent"), and "I Should Tell You". Larson suggested setting the play "amid poverty, homelessness, spunky gay life, drag queens and punk" in the East Village neighborhood of Manhattan, which happened to be down the street from his Greenwich Village apartment. He also came up with the show's ultimate title (a decision that Aronson was unhappy with, at least until Larson pointed out that "rent" also means torn apart). In 1991, he asked Aronson if he could use Aronson's original concept and make "Rent" his own. Larson had ambitious expectations for "Rent"; his ultimate dream was to write a rock opera "to bring musical theater to the MTV generation". Aronson and Larson made an agreement that if the show went to Broadway, Aronson would share in the proceeds and be given credit for "original concept & additional lyrics".

Jonathan Larson focused on composing "Rent" in the early 1990s, waiting tables at the Moondance Diner to support himself. Over the course of years, Larson wrote hundreds of songs and made many drastic changes to the show, which in its final incarnation contained 42 songs. In the fall of 1992, Larson approached James Nicola, artistic director of New York Theatre Workshop, with a tape and copy of "Rent"s script. When "Rent" had its first staged reading at New York Theatre Workshop in March 1993, it became evident that, despite its very promising material and moving musical numbers, many structural problems needed to be addressed, including its cumbersome length and overly complex plot.

As of 1994, the New York Theatre Workshop version of "Rent" featured songs that never made it into the final version, such as:


This workshop version of "Rent" starred Anthony Rapp as Mark and Daphne Rubin-Vega as Mimi. Larson continued to work on "Rent", gradually reworking its flaws and staging more workshop productions.

On January 24, 1996, after the musical's final dress rehearsal before its off-Broadway opening, Larson had his first (and only) newspaper interview with music critic Anthony Tommasini of "The New York Times", attracted by the coincidence that the show was debuting exactly 100 years after Puccini's opera. Larson would not live to see "Rent"s success; he died from an undiagnosed aortic aneurysm (believed to have resulted from Marfan syndrome) in the early morning of January 25, 1996. Friends and family gathered at the New York Theatre Workshop, and the first preview of "Rent" became a sing-through of the musical in Larson's memory.

The show premiered as planned and quickly gained popularity fueled by enthusiastic reviews and the recent death of its composer. It proved extremely successful during its off-Broadway run, selling out all its shows at the 150-seat New York Theater Workshop. Due to such overwhelming popularity and a need for a larger theater, "Rent" moved to Broadway's then-under-renovation Nederlander Theatre on 41st Street on April 29, 1996. At the production's request, final touches on the theater's remodeling and renovation were put on hold before and during the run of "Rent" because the show's producers and creative team felt the unfinished look fit in well with the gritty setting of the show.

Larson's inspiration for "Rent"s content came from several different sources. Many of the characters and plot elements are drawn directly from Giacomo Puccini's opera "La Bohème", the world premiere of which was in 1896, a century before "Rent"s premiere. "La Bohème" was also about the lives of poor young artists. Tuberculosis, the plague of Puccini's opera, is replaced by HIV/AIDS in "Rent"; 1800s Paris is replaced by New York's East Village in the late 1980s or early 1990s. The names and identities of "Rent"s characters also heavily reflect Puccini's original characters, though they are not all direct adaptations. For example, Joanne in "Rent" represents the character of Alcindoro in "Bohème", but is also partially based on Marcello. Also, Joanne is the only "Rent" character whose predecessor in "La Bohème" is a different sex.

Other examples of parallels between Larson's and Puccini's work include Larson's song "Light My Candle", which draws melodic content directly from "Che gelida manina"; "Quando me'n vo'" ("Musetta's Waltz"), a melody taken directly from Puccini's opera; and "Goodbye Love", a long, painful piece that reflects a confrontation and parting between characters in both Puccini's and Larson's work. "Quando me'n vo'" is paralleled in the first verse of "Take Me or Leave Me", when Maureen describes the way people stare when she walks in the street. It is also directly referred to in the scene where the characters are celebrating their bohemian life. Mark says, "Roger will attempt to write a bittersweet, evocative song..." Roger plays a quick piece, and Mark adds, "...that "doesn't" remind us of 'Musetta's Waltz'." This part of "Musetta's Waltz" is also later used in "Your Eyes", a song Roger writes.

"Rent" is also a somewhat autobiographical work, as Larson incorporated many elements of his life into his show. Larson lived in New York for many years as a starving artist with an uncertain future. He sacrificed a life of stability for his art, and shared many of the same hopes and fears as his characters. Like his characters he endured poor living conditions, and some of these conditions (e.g. illegal wood-burning stove, bathtub in the middle of his kitchen, broken buzzer [his guests had to call from the pay phone across the street and he would throw down the keys, as in "Rent"]) made their way into the play. Part of the motivation behind the storyline in which Maureen leaves Mark for a woman (Joanne) is based on the fact that Larson's own girlfriend left him for a woman. The Mark Cohen character is based on Larson's friends, cinematographer and producer Jonathan Burkhart and documentary filmmaker Eddie Rosenstein.

Playwright Sarah Schulman alleged that "Rent" bore striking similarities to her novel "People in Trouble".

The line, "I'm more of a man than you'll ever be... and more of a woman than you'll ever get!", attributed to Angel Dumott Schunard at her funeral, was previously used by the character Hollywood Montrose, who appeared in the films "Mannequin" (1987) and "" (1991). Like Angel, Hollywood performs a song and dance number and sometimes wears women's clothing. This line was originally in the film "Car Wash" (1976), delivered by Antonio Fargas as a flamboyant homosexual cross dresser.

The earliest concepts of the characters differ largely from the finished products. Everyone except Mark had AIDS, including Maureen and Joanne; Maureen was a serious, angry character who played off Oedipus in her performance piece instead of Hey Diddle Diddle; Mark was, at one point, a painter instead of a filmmaker; Roger was named Ralph and wrote musical plays; Angel was a jazz philosopher, while Collins was a street performer; Angel and Collins were both originally described as Caucasian; and Benny had a somewhat enlarged role in the story, taking part in songs like "Real Estate", which was later cut.

Many actual locations and events are included in, or are the inspiration for, elements of the musical. Life Café, where the "La Vie Bohème" numbers are set, was an actual restaurant (closed 2013) on 10th Street and Avenue B in the East Village of New York City. The riot at the end of the first act is based on the East Village riot in 1988 that arose as a result of the city-imposed curfew in Tompkins Square Park.

"Will I?", a song which takes place during a Life Support meeting and expresses the pain and fear of living a life with AIDS, was inspired by a real event. Larson attended a meeting of Friends in Deed, an organization that helps people deal with illness and grief, much like Life Support. After that first time, Larson attended the meetings regularly. During one meeting, a man stood up and said that he was not afraid of dying. He did say, however, that there was one thing of which he was afraid: Would he lose his dignity? From this question stemmed the first line of this song. The people present at the Life Support meeting in the show, such as Gordon, Ali and Pam, carry the names of Larson's friends who died. In the Broadway show, the names of the characters in that particular scene (they introduce themselves) were changed nightly to honor the friends of the cast members who were living with or had died from AIDS.

The scene and song "Life Support" were also based on Friends in Deed, as well as on Gordon, Pam, and Ali. Originally, the members of Life Support had a solid block of the "forget regret" refrain, and they talked about remembering love. When Jonathan's HIV positive friends heard this scene, they told him that having AIDS was not so easy to accept: it made you angry and resentful too, and the song did not match that. Jonathan then added a part where Gordon says that he has a problem with this "credo...my T-cells are low, I regret that news, okay?" Paul, the leader of the meeting, replies, "Okay...but, Gordon, how do you feel today?" Gordon admits that he is feeling the best that he has felt all year. Paul asks, "Then why choose fear?" Gordon says, "I'm a New Yorker. Fear's my life."

Lynn Thomson was a dramaturg who was hired by New York Theatre Workshop to help rework "Rent". She claimed that between early May and the end of October 1995, she and Larson co-wrote a "new version" of the musical. She sued the Larson estate for $40 million and sought 16 percent of the show's royalties, claiming she had written a significant portion of the lyrics and the libretto of the "new version" of "Rent".

During the trial, Thomson could not recall the lyrics to the songs that she allegedly wrote, nor the structures of the libretto she claimed to have created. The judge ruled against her and gave the Jonathan Larson Estate full credit and right to "Rent". A federal appellate court upheld the original ruling on appeal. In August 1998, the case was settled out of court. The terms of the settlement were not disclosed.

On Christmas Eve in Manhattan's East Village, two roommates—Mark, a filmmaker, and Roger, a rock musician—struggle to stay warm and produce their art ("Tune Up #1"). Mark's mother leaves him a voicemail wishing him a merry Christmas and trying to comfort him since his ex-girlfriend Maureen dumped him ("Voice Mail #1"). Their friend Tom Collins, a gay anarchist professor of computer-age philosophy at New York University, calls and plans to surprise them at their apartment, but is mugged before entering. At the same time, Mark and Roger's former roommate and friend Benny, who has since become their harsh new landlord, has reneged on an earlier agreement and now demands last year's rent, before shutting down their electrical power ("Tune Up #2"). However, Mark and Roger rebel and resolve not to pay the rent they cannot pay and which they were promised would not be a problem ("Rent"). Meanwhile, Angel, a cross-dressing street drummer (presently out of drag), finds Collins wounded in an alley and tends to him ("You Okay Honey?") - the two are immediately attracted to each other, each learning that the other is HIV positive. It is revealed that Roger also has HIV, which he contracted from his last girlfriend, who committed suicide after learning of her diagnosis, causing Roger to fall into depression. Mark leaves the loft while Roger stays home ("Tune Up #3"), trying to compose on his guitar without success; he wishes desperately to write one last song to be remembered by before he dies ("One Song Glory"). An exotic dancer, junkie, and neighbor, Mimi, shows up at their apartment asking for help with lighting her candle, flirting with Roger in the process; however, he is clearly hesitant to return her affections ("Light My Candle"). Meanwhile, Joanne, a lawyer and Maureen's girlfriend, receives a voicemail from her parents ("Voice Mail #2").

At last, the missing Collins enters the apartment, presenting Angel, who is now in full drag and shares the money she made and the amusing story of how she killed a dog to earn it ("Today 4 U"). Mark comes home, and Benny arrives, speaking of Maureen's upcoming protest against his plans to evict the homeless from a lot where he is hoping to build a cyber arts studio. Benny offers that, if they convince Maureen to cancel the protest, then Mark and Roger can officially remain rent-free tenants. However, the two rebuff Benny's offer and he leaves ("You'll See"). Mark leaves the loft again to go help Maureen with the sound equipment for the protest, unexpectedly meeting Joanne at the stage. Initially hesitant with each other, the two eventually bond over their shared distrust of Maureen's "gaslighting" and promiscuous behaviours ("Tango: Maureen"). Mark then joins Collins and Angel to film their HIV support group meeting ("Life Support"), while Mimi attempts to seduce Roger alone in his apartment ("Out Tonight"). Roger is extremely upset by Mimi's intrusion, demanding she leave him alone and resisting any romantic feelings he may harbour for her ("Another Day"). After Mimi leaves, Roger reflects on his fear of dying an undignified death from AIDS, while the Life Support group echoes his thoughts ("Will I").

Collins, Mark, and Angel protect a homeless woman from police harassment, but she chastises them ("On the Street"). To lighten the mood, Collins talks about his dream of escaping New York City to open a restaurant in Santa Fe ("Santa Fe"). Soon, Mark leaves to check up on Roger; while alone, Collins and Angel confess their love for each other ("I'll Cover You"). Joanne hectically prepares for Maureen's show, trying to balance all of the people calling her at once ("We're Okay"). Before the performance, Roger apologizes to Mimi, inviting her to come to the protest and the dinner party his friends are having afterwards. At the same time, police, vendors, and homeless people prepare for the protest ("Christmas Bells"). Maureen begins her avant-garde, if not over the top, performance based on "Hey Diddle Diddle" ("Over the Moon"). At the post-show party at the Life Café, Benny arrives, criticizing the protest and the group's bohemian lifestyle. In response, Mark and all the café's bohemian patrons defiantly rise up to celebrate their way of living ("La Vie Bohème"). Mimi and Roger each discover that the other is HIV-positive and hesitantly decide to move forward with their relationship ("I Should Tell You"). Joanne explains that Mark and Roger's building has been padlocked and a riot has broken out; Roger and Mimi, unaware, share their first kiss. The celebration continues ("La Vie Bohème B").

The cast lines up to sing together before the plot of the second act begins, affirming that one should measure life "in love" ("Seasons of Love"). Afterwards, Mark and Roger gather to break back into their locked apartment with their friends ("Happy New Year"). A new voicemail reveals that Mark's footage of the riot has earned him a job offering at a tabloid news company called Buzzline ("Voice Mail #3"). The others finally break through the door just as Benny arrives, saying he wants to call a truce and revealing that Mimi––who used to be his girlfriend––convinced him to change his mind. Mimi denies rekindling her relationship with Benny, but Roger is upset, and although they apologize to each other, Mimi goes to her drug dealer for a fix ("Happy New Year B").

Around Valentine's Day, Mark tells the audience that Roger and Mimi have been living together, but they are tentative with each other. It is also told that Maureen and Joanne are preparing another protest; during rehearsal, Maureen criticizes Joanne's controlling behaviour, and Joanne criticizes Maureen's promiscuous mannerisms. They break up dramatically following an ultimatum ("Take Me or Leave Me"). Time progresses to spring ("Seasons of Love B"), but Roger and Mimi's relationship is strained by Mimi's escalating heroin usage and Roger's lasting jealousy and suspicion of Benny. Each alone, Roger and Mimi sing of love and loneliness, telling each other how they feel, as they watch Collins nurse Angel, whose health is declining due to AIDS ("Without You"). By the end of the summer, Mark continues to receive calls offering a corporate job at Buzzline ("Voice Mail #4"). A dance is performed representing all the couples' sex lives ("Contact"). At the climax of the number, the two former couples break up, and Angel suddenly dies. At the funeral, the friends briefly come together to share their memories, with Collins being the last to reminisce ("I'll Cover You [Reprise]"). Mark expresses his fear of being the only one left surviving when the rest of his friends die of AIDS, and he finally accepts the corporate job offer ("Halloween"). Roger reveals that he is leaving for Santa Fe, which sparks an argument about commitment between him and Mimi, and between Maureen and Joanne. Collins arrives and admonishes the entire group for fighting on the day of Angel's funeral, causing Maureen and Joanne to reconcile, but not Mimi and Roger. The group shares a sad moment, knowing that between deaths and leaving, their close-knit friendships will be breaking up. Everyone leaves except Mark and Roger, and so Mark tries to convince Roger to stay in New York. Roger, unable to handle Mimi's declining health, becomes angry with Mark and leaves. Mimi returns to say goodbye, overhears everything Roger says, and, terrified, agrees to go to rehab, which Benny pays for ("Goodbye Love"). Collins is forcibly removed from the church for being unable to pay for Angel's funeral; Benny shows compassion by paying and offering Mark and Collins drinks. Collins accepts, causing him and Collins to rekindle their old friendship, but Mark has to turn down the offer due to work commitments.

Some time later, both Mark and Roger simultaneously reach an artistic epiphany, as Roger finds his song in Mimi and Mark finds his film in Angel's memory; Roger decides to return to New York in time for Christmas, while Mark quits his job to devote his efforts to working on his own film ("What You Own"). The characters' parents, concerned and confused about their respective situations, leave several worried messages on their phones ("Voice Mail #5"). On Christmas Eve, exactly one year having passed, Mark prepares to screen his now-completed film to his friends. Roger has written his song, but no one can find Mimi for him to play it to. Benny's wife, discovering Benny's relationship with Mimi, has pulled Benny out of the East Village. The power suddenly blows and Collins enters with handfuls of cash, revealing that he reprogrammed an ATM at a grocery store to provide money to anybody with the code 'ANGEL'. Maureen and Joanne abruptly enter carrying Mimi, who had been homeless and is now weak and close to death. She begins to fade, telling Roger that she loves him ("Finale"). Roger tells her to hold on as he plays her the song he wrote for her, revealing the depth of his feelings for her ("Your Eyes"). Mimi appears to die, but abruptly awakens, claiming to have been heading into a white light before a vision of Angel appeared, telling her to go back and stay with Roger. The remaining friends gather together in a final moment of shared happiness and resolve to enjoy whatever time they have left with each other, affirming that there is "no day but today" ("Finale B").

Act 1
Act 2


There are also many other non-named roles such as Cops, Bohemians, Vendors, Homeless People.

"Rent" received several awards including a Pulitzer Prize and four Tony Awards.

Critical reception of "Rent" was positive not only for its acting and musical components, but for its representation of HIV-positive individuals. Many critics praised the portrayal of characters such as Angel and Collins as being happy, with positive outlooks on life, rather than being resigned to death. While critics and theatre patrons had largely positive reviews of the show, it was criticized for its stereotypically negative portrayal of lesbian characters and the "glamourization" of the East Village in the late 1980s.

Billy Aronson said, "For the record, although I was ambivalent about Jonathan’s ideas for "Rent" when we were working together on it, I have come to love the show. And as tragic as it is that he didn’t live to see his work become a huge success, I believe he knew it would be. In our last conversation I asked how the show was going and he said, with complete assurance, that it was incredible."

The song "Seasons of Love" became a successful pop song and often is performed on its own. Because of its connection to New Years and looking back at times past, it is sometimes performed at graduations or school holiday programs.

"Rent" gathered a following of fans who refer to themselves as "RENT-heads." The name originally referred to people who would camp out at the Nederlander Theater for hours in advance for the discounted $20 rush tickets to each show, though it generally refers to anyone who is obsessed with the show. These discounted tickets were for seats in the first two rows of the theater reserved for sale by lottery two hours prior to each show. Other Broadway shows have followed "Rent"s example and now also offer cheaper tickets in efforts to make Broadway theater accessible to people who would otherwise be unable to afford the ticket prices.

The term originated in "Rent"s first months on Broadway. The show's producers offered 34 seats in the front two rows of the orchestra for $20 each, two hours before the performance. Fans and others interested in tickets would camp out for hours in front of the Nederlander Theater – which is on 41st Street, just outside Times Square – to buy these tickets.

The television series "The Simpsons", "Family Guy", "Friends", "Will and Grace", "Scrubs", "Glee", "The Big Bang Theory", "Gilmore Girls", "Felicity", "Saturday Night Live", "The Office", "Franklin & Bash", "2 Broke Girls", "Girls", "Seinfeld", "The Neighbors", "Modern Family", "Smash", "Supernatural", "Superstore", and "Bob's Burgers" have included references to the show. The film "" includes a character who plays a lead role in "Lease", a Broadway musical parody of "Rent"; the finale song is "Everyone has AIDS!". In 2017, the song "Out Tonight" was covered by Ashleigh Murray, Asha Bromfield, Hayley Law and Camila Mendes in the episode "Chapter Eighteen: When a Stranger Calls" from the second season of the television series "Riverdale". In the film "Deadpool", Wade Wilson is seen wearing a "Rent" T-shirt. Stan Lee also referenced one of the songs ("Cover you") when he said as the DJ in the strip club "You can't buy love.." - "but you can rent it... " 

"Rent" has also been referenced in other musicals. Yitzhak in "Hedwig and the Angry Inch" wears a "Rent" T-shirt and speaks of his aspiration to play the role of Angel. The off-Broadway musical revue "Forbidden Broadway Strikes Back" includes parodies of "Rent" songs such as "Rant" ("Rent"), "Ouch! They're Tight" ("Out Tonight"), "Season of Hype" ("Seasons of Love"), "Too Gay 4 U (Too Het'ro 4 Me)" ("Today 4 U"), "Pretty Voices Singing" ("Christmas Bells") and "This Ain't Boheme" ("La Vie Bohème"). Lin-Manuel Miranda, the composer and writer of the Broadway show "Hamilton", has cited "Rent" as a main source of inspiration. He also referenced the show in a verse of the song "Wrote My Way Out" on "The Hamilton Mixtape" in the line "Running out of time like I'm Jonathan Larson's rent check".

"Rent" had its first staged reading at New York Theatre Workshop in March 1993. A further two-week New York Theatre Workshop version was performed in 1994 starring Anthony Rapp as Mark and Daphne Rubin-Vega as Mimi, and more workshops followed. The show opened on 1996, again at New York Theatre Workshop, and quickly gained popularity off-Broadway, receiving enthusiastic reviews. "The New York Times" theater critic Ben Brantley called it an "exhilarating, landmark rock opera" with a "glittering, inventive score" that "shimmers with hope for the future of the American musical." Another reviewer wrote, ""Rent" speaks to Generation X the way that the musical "Hair" spoke to the baby boomers or those who grew up in the 1960s," while the "New York Times" similarly called it "a rock opera for our time, a "Hair" for the 90s." The show proved extremely successful off-Broadway, selling out all of its performances at the 150-seat theatre.

Due to its overwhelming popularity and the need for a larger theater, "Rent" moved to Broadway's previously derelict Nederlander Theatre on 41st Street on April 29, 1996. On Broadway, the show achieved critical acclaim and word-of-mouth popularity. The production's ethnically diverse principal cast originally included Taye Diggs, Wilson Jermaine Heredia, Jesse L. Martin, Idina Menzel, Adam Pascal, Anthony Rapp, Daphne Rubin-Vega and Fredi Walker.

The production's controversial topics and innovative pricing, including same day-of-performance $20 tickets, helped to increase the popularity of musical theater amongst the younger generation. The production was nominated for ten Tony Awards in 1996 and won four: Best Musical, Best Book, Best Original Score and Best Performance by a Featured Actor in a Musical (Heredia)

On April 24, 2006, the original Broadway cast reunited for a one-night performance of the musical at the Nederlander Theatre. This performance raised over $2,000,000 for the Jonathan Larson Performing Arts Foundation, Friends In Deed and New York Theatre Workshop. Former cast members were invited, and many from prior tours and former Broadway casts appeared, performing an alternate version of "Seasons of Love" as the finale of the performance.

"Rent" closed on September 7, 2008, after a 12-year run and 5,123 performances, making it the eleventh-longest-running Broadway show. The production grossed over $280 million.

Original cast ensemble members Rodney Hicks and Gwen Stewart returned to the cast at the time of the Broadway closing. Hicks played Benny and Stewart played the role she created, the soloist in the song "Seasons of Love". In addition, actress Tracie Thoms joined the cast at the end of the run playing Joanne, the role she portrayed in the 2005 film version. The last Broadway performance was filmed and screened in movie theaters as "Rent: Filmed Live on Broadway" in September 2008. It was released on DVD and Blu-ray formats on February 3, 2009.

Successful United States national tours, the "Angel Tour" and the "Benny Tour", launched in the 1990s. Later, the non-Equity tour started its run. There was also a Canadian tour (often referred to as the "Collins Tour").

The Angel tour began in November 1996 in Boston. Anthony Rapp joined the cast for the Chicago run, and Daphne Rubin-Vega joined for the Los Angeles run. The tour finished in San Francisco in September 1999. Other members of the Angel cast included Carrie Hamilton, Amy Spanger, Luther Creek, Kristoffer Cusick, and Tony Vincent.

The Benny Tour began in July 1997 in San Diego, California, at the LaJolla Playhouse. Michael Grief, the original director of the Broadway show was also the artistic director of the LaJolla Playhouse and was instrumental in arranging for the Benny tour to begin in the smaller city of San Diego rather than Los Angeles, California. It originally featured Neil Patrick Harris in the role of Mark Cohen. The Benny tour generally played shorter stops and often-smaller markets than the Angel Tour did. Other cast members included Wilson Cruz and d'Monroe.

Tours ran each season from 2005 to 2008. Cast members throughout the run included Aaron Tveit, Ava Gaudet, Declan Bennett, Rebecca Naomi Jones, Constantine Maroulis, Dan Rosenbaum, Heinz Winckler, Anwar Robinson, Christine Dwyer, Caissie Levy and Karen Olivo. In 2009, a national tour starring Adam Pascal and Anthony Rapp, reprising their original Broadway roles, launched in Cleveland, Ohio. Original Broadway Cast member Gwen Steward also appeared, alongside Michael McElroy as Collins, The tour ended on February 7, 2010, in Sacramento, California. A 20th-anniversary non-Equity touring production of "Rent" began in Dallas on September 20, 2016, and is scheduled to run through May 10, 2020.

The show made its UK premiere on April 21, 1998, at the West End's Shaftesbury Theatre and officially opened on May 12, 1998. The original cast included Krysten Cummings as Mimi Marquez, Wilson Jermaine Heredia as Angel Schunard, Bonny Lockhart as Benny, Jesse L. Martin as Tom Collins, Adam Pascal as Roger Davis, Anthony Rapp as Mark Cohen, and Jessica Tezier as Maureen Johnson. The show closed on October 30, 1999, after one-and-a-half years. Limited revivals took place at the Prince of Wales Theatre from December 4, 2001, to January 6, 2002; December 6, 2002, to March 1, 2003 (featuring Adam Rickett as Mark and Caprice as Maureen). There was also a successful production for a limited run in Manchester in 2006 with an additional 'goodbye' performance in 2008 from the Manchester cast.

On October 16, 2007, the heavily revised production titled "Rent Remixed" opened at the Duke of York's Theatre in London's West End. Directed by William Baker, it was set in the present day. The cast included Oliver Thornton (Mark), Luke Evans (Roger), Craig Stein (Benny), Leon Lopez (Collins), Francesca Jackson (Joanne), Jay Webb (Angel), Siobhán Donaghy (Mimi), and Denise Van Outen (Maureen). From December 24, 2007, the role of Maureen was played by Jessie Wallace. The production received generally unfavorable reviews. The Guardian gave it only one out of five stars, writing, "They call this 'Rent Remixed'. I'd dub it 'Rent Reduced', in that the late Jonathan Larson's reworking of La Bohème, while never a great musical, has been turned into a grisly, synthetic, pseudo pop concert with no particular roots or identity." The production closed on February 2, 2008.

The production radically altered elements of the musical including defining the characters of Mimi, Angel and Mark as British. Songs were reordered (including Maureen's first appearance as the Act I finale). The rehaul of the score was masterminded by Steve Anderson and featured radically rearranged versions of Out Tonight, Today 4 U, Over the Moon and Happy New Year.

A one-off Rent - The 20th Anniversary Concert was held at the Blackpool Opera house Monday November 11, 2013 
A 20th anniversary tour opened at Theatr Clwyd in October 2016 before playing a two-month run at the St James Theatre, London. The cast included Layton Williams as Angel and Lucie Jones as Maureen. The production then continued to tour the UK.

In 2018 an immersive production of RENT premiered at Frogmore Paper Mill in Apsley, Hemel Hempstead. The Cast included Aran Macrae (Roger), Connor Dyer (Mark) and Lizzie Emery (Mimi). The show opened on July 10, 2018, and ran until July 28.

In 2020, the musical is set to be revived at Manchester's Hope Mill Theatre for a limited run from October 30 to December 19. The production was originally scheduled to begin in late July but was delayed due to the COVID-19 pandemic.

The show was revived off-Broadway at Stage 1 of New World Stages with previews starting July 14, 2011, and a scheduled opening of August 11, 2011. This was the first New York Revival of the show since the original production closed less than three years earlier. The production was directed by "Rent"'s original director Michael Greif. Almost the entire show was different from the original, yet the reinvention did not please the critics, who complained that the new actors did not have a feel for the characters they were playing and that it made the show feel contrived. The off-Broadway production of "Rent" closed on September 9, 2012.

In 1999, an Australian production featured Justin Smith as Mark, Rodger Corser as Roger and Christine Anu as Mimi. The tour began in Sydney and finished in Melbourne. A production in Perth, Western Australia was mounted in 2007 and featured Anthony Callea as Mark, Tim Campbell as Roger, Courtney Act as Angel and Nikki Webster as Maureen.

The Dublin production had an extended run at the Olympia Theatre, Dublin in 2000. It starred Sean Pol McGreevy as Mark, Rachel Tucker as Maureen and Allyson Brown as Mimi under the direction of Phil Willmot. The Swedish production premiered on May 15, 2002 at The Göteborg Opera in Gothenburg, Sweden, playing until June 8, 2003. Sarah Dawn Finer played Joanne.

"Rent" veteran Neil Patrick Harris directed a production at the Hollywood Bowl in Los Angeles, CA. The production played a three night engagement, August 6–8, 2010. The cast included Vanessa Hudgens as Mimi, Aaron Tveit as Roger, Skylar Astin as Mark, Wayne Brady as Collins, Telly Leung as Angel, Tracie Thoms as Joanne, Nicole Scherzinger as Maureen, Collins Pennie as Benny, and Gwen Stewart as Seasons of Love soloist (and additional roles).

In 2017, the first tour for the German speaking countries was mounted by Berlin theatrical producer . The leading German musical theatre magazine "musicals - Das Musicalmagazin" described the production as "in terms of vocal quality, the performance was one of the best that has ever been seen in Germany" (issue 188 of Dec 2017). The show travelled Germany, Austria and Switzerland and was directed by the British opera director Walter Sutcliffe.

In 2007, an abridged edition of "Rent" was made available to five non-professional acting groups in the United States for production, primarily adapted by Jennifer and Peter Jones of Stuart, Florida's Starstruck Theater. Billed as , this version omits the song "Contact" and eliminates some of the coarse language and tones down some public displays of affection in the original. Shorewood High School in Shorewood, Wisconsin, became the first high school to perform an early version of the adaptation in May 2006. The high school was selected to present a workshop performance as part of Music Theatre International's work to adapt the musical for younger actors and potentially more conservative audiences. As of 2008, Music Theatre International began licensing ""Rent" School Edition" for performances by schools and non-professional amateur theaters in the United States and around the world.

"Rent" has been performed in countries around the world, including Denmark, Estonia, Finland, Iceland, Norway, Sweden, Belgium, the Netherlands, Ireland, United Kingdom, France, Germany, Switzerland, Portugal, Spain, Italy, Hungary, Poland, Slovakia, Greece, Canada, the United States, Mexico, Panama, Bolivia, Brazil, Argentina, Russia, China, Hong Kong, South Korea, Taiwan, Japan, Philippines, Singapore, Thailand, South Africa, Australia, Guam, New Zealand, Israel, Puerto Rico, Austria, Peru, Trinidad and Tobago, Dominican Republic, Cuba, Czech Republic and Guatemala.

The musical has been performed in twenty-five languages: Danish, Estonian, Finnish, Icelandic, Norwegian, Swedish, Dutch, English, French, German, Portuguese, Spanish, Italian, Hungarian, Polish, Slovak, Greek, Russian, Mandarin Chinese, Cantonese Chinese, Korean, Japanese, Hebrew, Czech, and Catalan.

A cast recording of the original Broadway cast recording was released in 1996; it features all the music of the show on a double-disc "complete recording" collection along with a remixed version of the song "Seasons of Love" featuring Stevie Wonder. A second one-disc album was released in 1999 containing highlights from the original cast album.

The 2005 film version (see below) also resulted in a double-disc cast recording of the complete score used in the movie The two-disc soundtrack, contained 28 tracks, and was originally packaged in eight different slipcovers, each featuring one of the eight most prominent characters in the film.

There are also many foreign cast recordings of international productions of the show.

In 2005, "Rent" was adapted into a movie directed by Chris Columbus with a screenplay by Stephen Chbosky. With the exception of Daphne Rubin-Vega (who was pregnant at the time of filming) and Fredi Walker (who felt she was too old for her role), who played Mimi and Joanne respectively, the original Broadway cast members reprised the principal roles. Released on November 23, 2005, the film remained in the box office top ten for three weeks, receiving mixed reviews. Several plot elements were changed slightly, and some songs were changed to spoken dialogue or cut entirely for the film. The soundtrack was produced by Rob Cavallo, engineered by Doug McKean and features renowned session musicians Jamie Muhoberac, Tim Pierce and Dorian Crozier.

The final performance of the Broadway production of "Rent", which took place on September 7, 2008, was filmed live and, cut together with close-up footage from a day of filming in August of the same year, was released as "Rent: Filmed Live on Broadway" in cinemas with high definition digital projection systems in the U.S. and Canada between September 24 and 28, 2008. "Rent: Filmed Live on Broadway" was released on February 3, 2009, on DVD & Blu-ray formats.

In May 2017, Fox announced plans to air a of "Rent." It aired Sunday, January 27, 2019 and starred Jordan Fisher as Mark, Brennin Hunt as Roger, Tinashe as Mimi, Brandon Victor Dixon as Tom, Valentina as Angel, Vanessa Hudgens as Maureen, Kiersey Clemons as Joanne, and Mario as Benny.

Jeffrey Schwarz directed this 2006 documentary about the musical Rent, from Jonathan Larson's original idea to his tragic passing and, finally, to the adaptation of "Rent" into a major motion picture. The nearly two-hour documentary was included in a two-disc special edition of the DVD release of the 2005 film.

Filmmaker and "Rent" alum Andy Señor, Jr. produced this documentary, following his journey producing the musical in Cuba in late 2014. This production of "Rent" was the first Broadway musical to premiere in Cuba since diplomatic relations between the two countries became strained during the Cold War. The documentary was released March 13, 2020.



</doc>
<doc id="26437" url="https://en.wikipedia.org/wiki?curid=26437" title="Restaurant">
Restaurant

A restaurant (), or an eatery, is a business that prepares and serves food and drinks to customers. Meals are generally served and eaten on the premises, but many restaurants also offer take-out and food delivery services. Restaurants vary greatly in appearance and offerings, including a wide variety of cuisines and service models ranging from inexpensive fast food restaurants and cafeterias, to mid-priced family restaurants, to high-priced luxury establishments.

In Western countries, most mid-to high-range restaurants serve alcoholic beverages such as beer and wine. Some restaurants serve all the major meals, such as breakfast, lunch, and dinner (e.g., major fast food chains, diners, hotel restaurants, and airport restaurants). Other restaurants may serve only a single meal (for example, a pancake house may only serve breakfast) or they may serve two meals (e.g., lunch and dinner).

The word derives from the French verb "restaurer" ("to restore", "to revive") and, being the present participle of the verb, it literally means "that which restores". The term "restaurant" was defined in 1507 as a "restorative beverage", and in correspondence in 1521 to mean "that which restores the strength, a fortifying food or remedy".

The first use of the word to refer to a public venue where one can order food is believed to be in the 18th century. In 1765, a French chef by the name of A. Boulanger established a business selling soups and other "restaurants" ("restoratives"). Additionally, while not the first establishment where one could order food, or even soups, it is thought to be the first to offer a menu of available choices
The "first real restaurant" is considered to have been "La Grande Taverne de Londres" in Paris, founded by Antoine Beauvilliers in either 1782 or 1786. According to Brillat-Savarin, this was "the first to combine the four essentials of an elegant room, smart waiters, a choice cellar, and superior cooking".
In 1802 the term was applied to an establishment where restorative foods, such as bouillon, a meat broth, were served ("établissement de restaurateur").

Restaurants are classified or distinguished in many different ways. The primary factors are usually the food itself (e.g. vegetarian, seafood, steak); the cuisine (e.g. Italian, Chinese, Japanese, Indian, French, Mexican, Thai) or the style of offering (e.g. tapas bar, a sushi train, a tastet restaurant, a buffet restaurant or a yum cha restaurant). Beyond this, restaurants may differentiate themselves on factors including speed (see fast food), formality, location, cost, service, or novelty themes (such as automated restaurants). Some of these include fine dining, casual dining, contemporary casual, family style, fast casual, fast food, cafes, buffet, concession stands, food trucks, pop-up restaurants, and ghost restaurants.

Restaurants range from inexpensive and informal lunching or dining places catering to people working nearby, with modest food served in simple settings at low prices, to expensive establishments serving refined food and fine wines in a formal setting. In the former case, customers usually wear casual clothing. In the latter case, depending on culture and local traditions, customers might wear semi-casual, semi-formal or formal wear. Typically, at mid- to high-priced restaurants, customers sit at tables, their orders are taken by a waiter, who brings the food when it is ready. After eating, the customers then pay the bill. In some restaurants, such as workplace cafeterias, there are no waiters; the customers use trays, on which they place cold items that they select from a refrigerated container and hot items which they request from cooks, and then they pay a cashier before they sit down. Another restaurant approach which uses few waiters is the buffet restaurant. Customers serve food onto their own plates and then pay at the end of the meal. Buffet restaurants typically still have waiters to serve drinks and alcoholic beverages. Fast food restaurants are also considered a restaurant. In addition, food trucks are another popular option for people who want quick food service. 

Tourists around the world can enjoy dining services on railway cars and cruise ships dining rooms, which are essentially traveling restaurants. Many railways dining services cater to the needs of travelers by providing railway refreshment rooms at railway stations. Many cruise ships provide a variety of dining experiences including a main restaurant, satellites restaurants, room service, specialty restaurants, cafes, bars, and buffets to name a few. Some restaurants on these cruise ships required reservations and specific dress codes.

A restaurant's proprietor is called a "restaurateur", this derives from the French verb "restaurer", meaning "to restore". Professional cooks are called chefs, with there being various finer distinctions (e.g. sous-chef, chef de partie). Most restaurants (other than fast food restaurants and cafeterias) will have various waiting staff to serve food, beverages and alcoholic drinks, including busboys who remove used dishes and cutlery. In finer restaurants, this may include a host or hostess, a maître d'hôtel to welcome customers and to seat them, and a sommelier or wine waiter to help patrons select wines.
A new route to becoming a restaurateur, rather than working one's way up through the stages, is to operate a food truck. Once a sufficient following has been obtained, a permanent restaurant site can be opened. This trend has become common in the UK and the US.

A chef's table is a table located in the kitchen of a restaurant, reserved for VIPs and special guests. Patrons may be served a themed tasting menu prepared and served by the head chef. Restaurants can require a minimum party and charge a higher flat fee. Because of the demand on the kitchen's facilities, chef's tables are generally only available during off-peak times.

In China, food catering establishments that may be described as restaurants have been known since the 11th century in Kaifeng, China's capital during the first half of the Song dynasty (960–1279). Probably growing out of the tea houses and taverns that catered to travellers, Kaifeng's restaurants blossomed into an industry catering to locals as well as people from other regions of China. There is a direct correlation between the growth of the restaurant businesses and institutions of theatrical stage drama, gambling and prostitution which served the burgeoning merchant middle class during the Song dynasty. Restaurants catered to different styles of cuisine, price brackets, and religious requirements. Even within a single restaurant choice were available, and people ordered the entree from written menus. An account from 1275 writes of Hangzhou, the capital city for the last half of the dynasty:
The restaurants in Hangzhou also catered to many northern Chinese who had fled south from Kaifeng during the Jurchen invasion of the 1120s, while it is also known that many restaurants were run by families formerly from Kaifeng.

In Ancient Greece and Ancient Rome, thermopolia (singular "thermopolium") were small restaurant-bars that offered food and drinks to customers. A typical thermopolium had L-shaped counters in which large storage vessels were sunk, which would contain either hot or cold food. Their popularity was linked to the lack of kitchens in many dwellings and the ease with which people could purchase prepared foods. Furthermore, eating out was considered an important aspect of socializing.

In Pompeii, 158 thermopolia with service counters have been identified throughout the town. They were concentrated along the main axis of the town and the public spaces where they were frequented by the locals.

France has had a rich history with the development of various forms of inns and eateries, eventually to form many of the now-ubiquitous elements of the modern restaurant.

As far back as the thirteenth century, inns served a variety of food — bread, cheese, bacon, roasts, usually eaten at a common table. Parisians could buy what was essentially take-out food from "rôtisseurs", who prepared roasted meat dishes, and pastry-cooks, who could prepare meat pies and often more elaborate dishes. Municipal statutes stated that the official prices per item were to be posted at the entrance; this was the first official mention of menus.

Taverns also served food, as did cabarets. A cabaret, however, unlike a tavern, served food at tables with tablecloths, provided drinks with the meal, and charged by the customers' choice of dish, rather than by the pot. Cabarets were reputed to serve better food than taverns and a few, such as the Petit Maure, became well-known. A few cabarets had musicians or singing, but most, until the late 19th century, were simply convivial eating places. The first café opened in Paris in 1672 at the Saint-Germain fair. By 1723 there were nearly four hundred cafés in Paris, but their menu was limited to simpler dishes or confectionaries, such as coffee, tea, chocolate, ice creams, pastries, and liqueurs.

At the end of the 16th century, the guild of cook-caterers (later known as "traiteurs") was given its own legal status. The "traiteurs" dominated sophisticated food service, delivering or preparing meals for the wealthy at their residences. Taverns and cabarets were limited to serving little more than roast or grilled meats. Towards the end of the seventeenth century, both inns and then traiteurs began to offer "host's tables" ("tables d'hôte"), where one paid a set price to sit at a large table with other guests and eat a fixed menu meal.

The earliest modern-format "restaurants" to use that name in Paris were the establishments which served bouillon, a broth made of meat and egg which was said to restore health and vigor. The first restaurant of this kind opened in 1765 or 1766 by Mathurin Roze de Chantoiseau on rue des Poulies, now part of the Rue de Louvre. The name of the owner is sometimes given as Boulanger. Unlike earlier eating places, it was elegantly decorated, and besides meat broth offered a menu of several other "restorative" dishes, including macaroni. Chantoiseau and other chefs took the title "traiteurs-restaurateurs".

In June 1786 the Provost of Paris issued a decree giving the new kind of eating establishment official status, authorizing "restaurateurs" to receive clients and to offer them meals until eleven in the evening in winter and midnight in summer. Ambitious cooks from noble households began to open more elaborate eating places. The first luxury restaurant in Paris, the Taverne Anglaise, was opened at the Palais-Royal at the beginning of 1786, shortly before the French Revolution, by Antoine Beauvilliers, the former chef of the Count of Provence, It had mahogany tables, linen tablecloths, chandeliers, well-dressed and trained waiters, a long wine list and an extensive menu of elaborately prepared and presented dishes.

The French Revolution caused a mass emigration of nobles, and many of their cook chose to open restaurants. One restaurant was started in 1791 by Méot, the former chef of the Duke of Orleans, which offered a wine list with twenty-two choices of red wine and twenty-seven of white wine. By the end of the century there were a collection of luxury restaurants at the Grand-Palais: Huré, the Couvert espagnol; Février; the Grotte flamande; Véry, Masse and the Café de Chartres (still open, now Le Grand Vefour)

In the early 19th century traiteurs and restaurateurs, became known simply as "restaurateurs". The use of the term "restaurant" for the establishment itself only became common in the nineteenth century).
The first restaurant guide, called "Almanach des Gourmandes", written by Grimod de La Reyniére, was published in 1804. During the French Restoration period, the most celebrated restaurant was the Rocher de Cancale, frequented by the characters of Balzac. In the middle of the century, Balzac's characters moved to the Cafe Anglais, which in 1867 also hosted the famous Three Emperors Dinner hosted by Napoleon III in honor of Tsar Alexander II, Kaiser Wilhelm I and Otto von Bismarck during the Exposition Universelle in 1867 Other restaurants that occupy a place in French history and literature include Maxim's and Fouquet's. The restaurant of Hotel Ritz Paris, opened in 1898, was made famous by its chef, Auguste Escoffier. The 19th century also saw the appearance of new kinds of more modest restaurants, including the bistrot. The brasserie featured beer and was made popular during the 1867 Paris Exposition.

In Brazil, restaurants varieties mirrors the multitude of nationalities that arrived in the country: Japanese, Arab, German, Italian, Portuguese and many more.

In Colombia, a "piqueteadero" is a type of casual or rustic eatery. Meals are often shared, and typical offerings include dishes such as chorizo, chicharrón, fried organs, fried yuca, maduro and corn on the cob. Customers order the foods they want and the prepared foods are served together on a platter to be shared. The word "piquete" can be used to refer to a common Colombian type of meal that includes meat, yuca and potatoes, which is a type of meal served at a piqueteaderos. The verb form of the word piquete, piquetear, means to participate in binging, liquor drinking, and leisure activities in popular areas or open spaces.

In Peru, many indigenous, Spanish, and Chinese dishes are frequently found. Because of recent immigration from places such as China, and Japan, there are many Chinese and Japanese restaurants around the country, especially in the capital city of Lima.

In the United States, it was not until the late 18th century that establishments that provided meals without also providing lodging began to appear in major metropolitan areas in the form of coffee and oyster houses. The actual term "restaurant" did not enter into the common parlance until the following century. Prior to being referred to as "restaurants" these eating establishments assumed regional names such as "eating house" in New York City, "restorator" in Boston, or "victualing house" in other areas. Restaurants were typically located in populous urban areas during the 19th century and grew both in number and sophistication in the mid-century due to a more affluent middle class and to suburbanization. The highest concentration of these restaurants were in the West, followed by industrial cities on the Eastern Seaboard.<ref name="http://digital.library.unlv.edu/collections/menus/early-restaurants-america"></ref>

In the 1970s, there was one restaurant for every 7,500 persons. In 2016, there were 1,000,000 restaurants; one for every 310 people. The average person eats out five to six times weekly. 10% of the nation's workforce is composed of restaurant workers. According to a Gallup Poll in 2016, nearly 61% of Americans across the country eat out at a restaurant once a week or more, and this percent is only predicted to increase in future years.
Before the COVID-19 pandemic, The National Restaurant Association estimated restaurant sales of $899 billion in 2020. The association now projects that the pandemic will decrease that to $675 billion, a decline of $274 billion over their previous estimate.

Restaurant guides review restaurants, often ranking them or providing information to guide consumers (type of food, handicap accessibility, facilities, etc.). One of the most famous contemporary guides is the Michelin series of guides which accord from 1 to 3 stars to restaurants they perceive to be of high culinary merit. Restaurants with stars in the Michelin guide are formal, expensive establishments; in general the more stars awarded, the higher the prices.

The main competitor to the Michelin guide in Europe is the guidebook series published by Gault Millau. Its ratings are on a scale of 1 to 20, with 20 being the highest.

In the United States, the Forbes Travel Guide (previously the Mobil travel guides) and the AAA rate restaurants on a similar 1 to 5 star (Forbes) or diamond (AAA) scale. Three, four, and five star/diamond ratings are roughly equivalent to the Michelin one, two, and three star ratings while one and two star ratings typically indicate more casual places to eat. In 2005, Michelin released a New York City guide, its first for the United States. The popular Zagat Survey compiles individuals' comments about restaurants but does not pass an "official" critical assessment. FreshNYC recommends plausible New York City restaurants for busy New Yorkers and visitors alike.

The "Good Food Guide," published by the Fairfax Newspaper Group in Australia, is the Australian guide listing the best places to eat. Chefs Hats are awarded for outstanding restaurants and range from one hat through three hats. The "Good Food Guide" also incorporates guides to bars, cafes and providers. "The Good Restaurant Guide" is another Australian restaurant guide that has reviews on the restaurants as experienced by the public and provides information on locations and contact details. Any member of the public can submit a review.

Nearly all major American newspapers employ food critics and publish online dining guides for the cities they serve. Some news sources provide customary reviews of restaurants, while others may provide more of a general listings service.

More recently Internet sites have started up that publish both food critic reviews and popular reviews by the general public.

Many restaurants are small businesses, and franchise restaurants are common. There is often a relatively large immigrant representation, reflecting both the relatively low start-up costs of the industry (thus making restaurant ownership an option for immigrants with relatively few resources) and the cultural importance of food.

Indian restaurant industry is highly fragmented with more than 1.5 million outlets of which only around 3000 of them are from the organized segment. Organized segment includes Quick Service Restaurants (QSRs), Casual Dining, Cafes, Fine Dining and Pubs, Bars, Clubs and Lounges.

There are 86,915 commercial foodservice units in Canada, or 26.4 units per 10,000 Canadians. By segment, there are:

Fully 63% of restaurants in Canada are independent brands. Chain restaurants account for the remaining 37%, and many of these are locally owned and operated franchises.

The EU-27 has an estimated 1.6m businesses involved in 'accommodation & food services', more than 75% of which are small and medium enterprises.

As of 2006, there are approximately 215,000 full-service restaurants in the United States, accounting for $298 billion in sales, and approximately 250,000 limited-service (fast food) restaurants, accounting for $260 billion. Starting in 2016, Americans spent more on restaurants than groceries.
In October 2017, "The New York Times" reported there are 620,000 eating and drinking places in the United States, according to the Bureau of Labor Statistics. They also reported that the number of restaurants are growing almost twice as fast as the population.

One study of new restaurants in Cleveland, Ohio found that 1 in 4 changed ownership or went out of business after one year, and 6 out of 10 did so after three years. (Not all changes in ownership are indicative of financial failure.) The three-year failure rate for franchises was nearly the same.

Restaurants employed 912,100 cooks in 2013, earning an average $9.83 per hour. The waiting staff numbered 4,438,100 in 2012, earning an average $8.84 per hour.

Jiaxi Lu of the "Washington Post" reports in 2014 that, "Americans are spending $683.4 billion a year dining out, and they are also demanding better food quality and greater variety from restaurants to make sure their money is well spent."

Dining in restaurants has become increasingly popular, with the proportion of meals consumed outside the home in restaurants or institutions rising from 25% in 1950 to 46% in 1990. This is caused by factors such as the growing numbers of older people, who are often unable or unwilling to cook their meals at home and the growing number of single-parent households. It is also caused by the convenience that restaurants can afford people; the growth of restaurant popularity is also correlated with the growing length of the work day in the US, as well as the growing number of single parent households. Eating in restaurants has also become more popular with the growth of higher income households. At the same time, less expensive establishments such as fast food establishments can be quite inexpensive, making restaurant eating accessible to many.

The restaurant industry in the United States is large and quickly growing, with 10 million workers. 1 in every 12 U.S. residents work in the business, and during the 2008 recession, the industry was an anomaly in that it continued to grow. Restaurants are known for having low wages, which they claim are due to thin profit margins of 4-5%. For comparison, however, Walmart has a 1% profit margin.
As a result of these low wages, restaurant employees suffer from three times the poverty rate as other U.S. workers, and use food stamps twice as much.
Restaurants also employ marginalized groups. They are the largest employer of people of color. Restaurants rank as the second largest employer of immigrants. These workers statistically are concentrated in the lowest paying positions in the restaurant industry. In the restaurant industry, 39% of workers earn minimum wage or lower.

In many countries, restaurants are subject to inspections by health inspectors to maintain standards for public health, such as maintaining proper hygiene and cleanliness. As part of these inspections, cooking and handling practices of ground beef are taken into account to protect against the spread of E coli poisoning. The most common kind of violations of inspection reports are those concerning the storage of cold food at appropriate temperatures, proper sanitation of equipment, regular hand washing and proper disposal of harmful chemicals. Simple steps can be taken to improve sanitation in restaurants. As sickness is easily spread through touch, restaurants are encouraged to regularly wipe down tables, door knobs and menus.

Depending on local customs, legislation and the establishment, restaurants may or may not serve alcoholic beverages. Restaurants are often prohibited from selling alcoholic beverages without a meal by alcohol sale laws; such sale is considered to be activity for bars, which are meant to have more severe restrictions. Some restaurants are licensed to serve alcohol ("fully licensed"), or permit customers to "bring your own" alcohol (BYO / BYOB). In some places restaurant licenses may restrict service to beer, or wine and beer.

Food service regulations have historically been built around hygiene and protection of the consumer's health. However, restaurant workers face many health hazards such as long hours, low wages, minimal benefits, discrimination, high stress, and poor working conditions. Along with the COVID-19 pandemic, much attention has been drawn to the prevention of community transmission in restaurants and other public settings. To reduce airborne disease transmission, the Centers for Disease Control and Prevention recommends reduced dining capacity, face masks, adequate ventilation, physical barrier installments, disinfection, signage, and flexible leave policies for workers.






</doc>
<doc id="26438" url="https://en.wikipedia.org/wiki?curid=26438" title="Rolf Nevanlinna">
Rolf Nevanlinna

Rolf Herman Nevanlinna (né Neovius; 22 October 1895 – 28 May 1980) was a Finnish mathematician who made significant contributions to complex analysis.

Nevanlinna was born Rolf Herman Neovius, becoming Nevanlinna in 1906 when his father changed the family name.

The Neovius-Nevanlinna family contained many mathematicians: Edvard Engelbert Neovius (Rolf's grandfather) taught mathematics and topography at a military academy; Edvard Rudolf Neovius (Rolf's uncle) was a professor of mathematics at the University of Helsinki from 1883–1900; Lars Theodor Neovius-Nevanlinna (Rolf's uncle) was an author of mathematical textbooks; and Otto Wilhelm Neovius-Nevanlinna (Rolf's father) was a physicist, astronomer and mathematician.

After Otto obtained his Ph.D. in physics from the University of Helsinki, he studied at the Pulkovo Observatory with the German astronomer Herman Romberg, whose daughter, Margarete Henriette Louise Romberg, he married in 1892. Otto and Margarete then settled in Joensuu, where Otto taught physics, and there their four children were born: Frithiof (born 1894; also a mathematician), Rolf (born 1895), Anna (born 1896) and Erik (born 1901).

Nevanlinna began his formal education at the age of 7. Having already been taught to read and write by his parents, he went straight into the second grade but still found the work boring and soon refused to attend the school. He was then homeschooled before being sent to a grammar school in 1903 when the family moved to Helsinki, where his father took up a new post as a teacher at Helsinki High School. At the new school, Nevanlinna studied French and German in addition to the languages he already spoke: Finnish and Swedish. He also attended an orchestra school and had a love of music, which was encouraged by his mother:

Nevanlinna then progressed onto the Helsinki High School, where his main interests were classics and mathematics. He was taught by a number of teachers during this time but the best of them all was his own father, who taught him physics and mathematics. He graduated in 1913 having performed very well, although he was not the top student of his year. He then went beyond the school syllabus in the summer of 1913 when he read Ernst Leonard Lindelöf's "Introduction to Higher Analysis"; from that time on, Nevanlinna had an enthusiastic interest in mathematical analysis. (Lindelöf was also a cousin of Nevanlinna's father, and so a part of the Neovius-Nevanlinna mathematical family.)

Nevanlinna began his studies at the University of Helsinki in 1913, and received his Master of Philosophy in mathematics in 1917. Lindelöf taught at the university and Nevanlinna was further influenced by him. During his time at the University of Helsinki, World War I was underway and Nevanlinna wanted to join the 27th Jäger Battalion, but his parents convinced him to continue with his studies. He did however join the White Guard in the Finnish Civil War, but did not see active military action. In 1919, Nevanlinna presented his thesis, entitled "Über beschränkte Funktionen die in gegebenen Punkten vorgeschriebene Werte annehmen" ("On limited functions prescribed values at given points"), to Lindelöf, his doctoral advisor. The thesis, which was on complex analysis, was of high quality and Nevanlinna was awarded his Doctor of Philosophy on 2 June 1919.

When Nevanlinna earned his doctorate in 1919, there were no university posts available so he became a school teacher. His brother, Frithiof, had received his doctorate in 1918 but likewise was unable to take up a post at a university, and instead began working as a mathematician for an insurance company. Frithiof recruited Rolf to the company, and Nevanlinna worked for the company and as a school teacher until he was appointed a Docent of Mathematics at the University of Helsinki in 1922. During this time, he had been contacted by Edmund Landau and requested to move to Germany to work at the University of Göttingen, but did not accept.

After his appointment as Docent of Mathematics, he gave up his insurance job but did not resign his position as school teacher until he received a newly created full professorship at the university in 1926. Despite this heavy workload, it was between the years of 1922–25 that he developed what would become to be known as Nevanlinna theory.

From 1947 Nevanlinna had a chair in the University of Zurich, which he held on a half-time basis after receiving in 1948 a permanent position as one of the 12 salaried Academicians in the newly created Academy of Finland.

Rolf Nevanlinna's most important mathematical achievement is the "value distribution theory" of meromorphic functions. The roots of the theory go back to the result of Émile Picard in 1879, showing that a non-constant complex-valued function which is analytic in the entire complex plane assumes all complex values save at most one. In the early 1920s Rolf Nevanlinna, partly in collaboration with his brother Frithiof, extended the theory to cover meromorphic functions, i.e. functions analytic in the plane except for isolated points in which the Laurent series of the function has a finite number of terms with a negative power of the variable. Nevanlinna's value distribution theory or Nevanlinna theory is crystallised in its two "Main Theorems". Qualitatively, the first one states that if a value is assumed less frequently than average, then the function comes close to that value more often than average. The Second Main Theorem, more difficult than the first one, states roughly that there are relatively few values which the function assumes less often than average.

Rolf Nevanlinna's article "Zur Theorie der meromorphen Funktionen" which contains the Main Theorems was published in 1925 in the journal Acta Mathematica. Hermann Weyl has called it "one of the few great mathematical events of the [twentieth] century." Nevanlinna gave a fuller account of the theory in the monographs "Le théoreme de Picard – Borel et la théorie des fonctions méromorphes" (1929) and "Eindeutige analytische Funktionen" (1936).

Nevanlinna theory touches also on a class of functions called the Nevanlinna class, or functions of "bounded type".
When the Winter War broke out (1939), Nevanlinna was invited to join the Finnish Army's Ballistics Office to assist in improving artillery firing tables. These tables had been based on a calculation technique developed by General Vilho Petter Nenonen, but Nevanlinna now came up with a new method which made them considerably faster to compile. In recognition of his work he was awarded the Order of the Cross of Liberty, Second Class, and throughout his life he held this honour in especial esteem.

Among Rolf Nevanlinna's later interests in mathematics were the theory of Riemann surfaces (the monograph "Uniformisierung" in 1953) and functional analysis ("Absolute analysis" in 1959, written in collaboration with his brother Frithiof). Nevanlinna also published in Finnish a book on the foundations of geometry and a semipopular account of the Theory of Relativity. His Finnish textbook on the elements of complex analysis, "Funktioteoria" (1963), written together with Veikko Paatero, has appeared in German, English and Russian translations.

Rolf Nevanlinna supervised at least 28 doctoral theses. His first and most famous doctoral student was Lars Ahlfors, one of the first two Fields Medal recipients. The research for which Ahlfors was awarded the prize (proving the Denjoy Conjecture, now known as the Denjoy–Carleman–Ahlfors theorem) was strongly based on Nevanlinna's work.

Nevanlinna's work was recognised in the form of honorary degrees which he held from the universities of Heidelberg, the University of Bucharest, the University of Giessen, the Free University of Berlin, the University of Glasgow, the University of Uppsala, the University of Istanbul and the University of Jyväskylä. He was an honorary member of several learned societies, among them the London Mathematical Society and the Hungarian Academy of Sciences. — The 1679 Nevanlinna main belt asteroid is named after him.

From 1954, Rolf Nevanlinna chaired the committee which set about the first computer project in Finland. 

Rolf Nevanlinna served as President of the International Mathematical Union (IMU) from 1959 to 1963 and as President of the International Congress of Mathematicians (ICM) in 1962.

In 1964, Nevanlinna's connections with President Urho Kekkonen were instrumental in bringing about a total reorganization of the Academy of Finland.

From 1965 to 1970 Nevanlinna was Chancellor of the University of Turku.

Although Nevanlinna did not participate actively in politics, he was known to sympathise with the right-wing Patriotic People's Movement and, partly because of his half-German parentage, was also sympathetic towards Nazi Germany; with many mathematics professors fired in the 1930s due to the Nuremberg Laws, mathematicians sympathetic to the Nazi policies were sought as replacements, and Nevanlinna accepted a position as professor at the University of Göttingen in 1936 and 1937. His sympathy towards the Nazis led to his removal from his position as Rector of the University of Helsinki after Finland made peace with the Soviet Union in 1944.

In the spring of 1941, Finland contributed a Volunteer Battalion to the Waffen-SS. At the time, the battalion was a symbolic bond between Germany and Finland as both fought against the Soviet Union but without a formal alliance between the two nations. In 1942, a committee was established for the Volunteer Battalion to take care of the battalion's somewhat strained relations with its German commanders, and Nevanlinna was chosen to be the chairman of the committee, as he was a person respected in Germany but loyal to Finland. He stated in his autobiography that he accepted this role due to a "sense of duty".

Nevanlinna's political activities did not colour his relationships with his mathematical contacts; after World War II, the Soviet mathematical community was isolated from the Western mathematical community and the International Colloquium on Function Theory in Helsinki in 1957, directed by Nevanlinna, was the first post-war occasion when Soviet mathematicians could contact their Western colleagues in person. In 1965, Nevanlinna was an honorary guest at a function theory congress in Soviet Armenia.

When the IMU in 1981 decided to create a prize, similar to the Fields Medal, in theoretical computer science and the funding for the prize was secured from Finland, the Union decided to give Nevanlinna's name to the prize; the Rolf Nevanlinna Prize is awarded every four years at the ICM. In 2018, the General Assembly of the IMU approved a resolution to remove Nevanlinna's name from the prize.




</doc>
<doc id="26441" url="https://en.wikipedia.org/wiki?curid=26441" title="Red panda">
Red panda

The red panda ("Ailurus fulgens") is a mammal species native to the eastern Himalayas and southwestern China. It is listed as Endangered on the IUCN Red List because the wild population is estimated at fewer than 10,000 mature individuals and continues to decline due to habitat loss and fragmentation, poaching, and inbreeding depression. Despite its name, it is not closely related to the giant panda.

The red panda has reddish-brown fur, a long, shaggy tail, and a waddling gait due to its shorter front legs; it is roughly the size of a domestic cat, though with a longer body, and is somewhat heavier. It is arboreal and feeds mainly on bamboo, but also eats eggs, birds, and insects. It is a solitary animal, mainly active from dusk to dawn, and is largely sedentary during the day. It is also called the lesser panda, the red bear-cat, and the red cat-bear.

The red panda is the only living member of the genus "Ailurus" and the family Ailuridae. It has previously been placed in the raccoon and bear families, but the results of phylogenetic analysis provide strong support for its taxonomic classification in its own family, Ailuridae, which is part of the superfamily Musteloidea, along with the weasel, raccoon and skunk families. Traditionally it was thought to consist of two subspecies. However, results of genetic analysis indicate that there are probably two distinct red panda species, the Chinese red panda and the Himalayan red panda, which genetically diverged .

The red panda has long, soft, reddish-brown fur on the upper parts, blackish fur on the lower parts, and a light face with tear markings and white badges similar to those of a raccoon, but each individual can have distinctive markings. Its skull is roundish with medium-sized upright ears, its nose is black, and its eyes are blackish. Its teeth are robust. Its long, bushy tail with six alternating transverse ochre rings provide balance and excellent camouflage in a habitat with moss- and lichen-covered trees. The legs are black and short with thick fur on the soles of the paws. This fur serves as thermal insulation on snow-covered or icy surfaces and conceals scent glands, which are also present on the anus.

The head and body length of a red panda measures , and its tail is long. Males weigh and females .

The red panda is specialized as a bamboo feeder with strong, curved and sharp semi-retractile claws standing inward for grasping narrow tree branches, leaves, and fruit. Like the giant panda, it has a "false thumb", which is an extension of the wrist bone. When descending a tree head-first, the red panda rotates its ankle to control its descent, one of the few climbing species to do so.

The red panda is endemic to the temperate forests of the Himalayas, and ranges from the foothills of western Nepal to China in the east. Its easternmost limit is the Qinling Mountains of the Shaanxi Province in China. Its range includes southern Tibet, Sikkim and Assam in India, Bhutan, the northern mountains of Burma, and in south-western China, in the Hengduan Mountains of Sichuan and the Gongshan Mountains in Yunnan. It may also live in south-west Tibet and northern Arunachal Pradesh, but this has not been documented. Locations with the highest density of red pandas include an area in the Himalayas that has been proposed as having been a refuge for a variety of endemic species in the Pleistocene. The distribution range of the red panda should be considered disjunct, rather than continuous. A disjunct population inhabits the Meghalaya Plateau of north-eastern India.

The red panda lives between altitude, inhabiting areas of moderate temperature between with little annual change. It prefers mountainous mixed deciduous and conifer forests, especially with old trees and dense understories of bamboo.

During a survey in the 1970s, signs of red pandas were found in Nepal's Dhorpatan Hunting Reserve. Their presence was confirmed in spring 2007 when four red pandas were sighted at elevations ranging from . Its westernmost distribution is in Rara National Park. In 2018, red pandas were sighted at elevations of in Nepal's Lamjung District.

The red panda population in Sichuan Province is larger and more stable than the Yunnan population, suggesting a southward expansion from Sichuan into Yunnan in the Holocene.
The red panda has become extirpated from the Chinese provinces of Guizhou, Gansu, Shaanxi, and Qinghai.

The red panda is territorial; it is solitary except during mating season. It is generally quiet except for some twittering, tweeting, and whistling communication sounds. It has been reported to be both nocturnal and crepuscular, sleeping on tree branches or in tree hollows during the day and increasing its activity in the late afternoon and early evening hours. It sleeps stretched out on a branch with legs dangling when it is hot, and curled up with its tail over the face when it is cold. It is very heat-sensitive, with an optimal "well-being" temperature between .
Shortly after waking, red pandas clean their fur somewhat like a cat would, licking their front paws and then rubbing their backs, torsos, and sides. They also rub their backs and bellies along the sides of trees or rocks. Then they patrol their territories, marking with urine and a weak musk-smelling secretion from their anal glands. They search for food running along the ground or through the trees. Red pandas may use their forepaws alternately to bring food to their mouths or place food directly into their mouths.

Predators of the red panda include the snow leopard ("Panthera uncia"), mustelids, and humans. If they feel threatened or sense danger, they may try to escape by climbing a rock column or tree. If they can no longer flee, they stand on their hind legs to make themselves appear larger and use the sharp claws on their front paws to defend themselves. A red panda became a visitor attraction in Japan for his ability to stand upright for ten seconds at a time.

Red pandas are excellent climbers, and forage largely in trees. They eat mostly bamboo, and may eat small mammals, birds, eggs, flowers, and berries. In captivity, they were observed to eat birds, flowers, maple and mulberry leaves, and bark and fruits of maple, beech, and mulberry.

Like the giant panda, they cannot digest cellulose, so they must consume a large volume of bamboo to survive. Their diets consist of about two-thirds bamboo, but they also eat mushrooms, roots, acorns, lichens, and grasses. Occasionally, they supplement their diets with fish and insects. They do little more than eat and sleep due to their low-calorie diets.

Bamboo shoots are more easily digested than leaves, exhibiting the highest digestibility in summer and autumn, intermediate digestibility in the spring, and lowest digestibility in the winter. These variations correlate with the nutrient contents in the bamboo. Red pandas process bamboo poorly, especially the cellulose and cell wall components. This implies microbial digestion plays only a minor role in their digestive strategy. To survive on this poor-quality diet, they have to eat the high-quality sections of the bamboo plant, such as the tender leaves and shoots, in large quantities, over of fresh leaves and of fresh shoots daily. This food passes through the digestive tract fairly rapidly (about 2–4 hr) so as to maximize daily nutrient intake. Red pandas can taste artificial sweeteners, such as aspartame, and are the only nonprimates known to be able to do so.

Red pandas are able to reproduce at around 18 months of age, and are fully mature at two to three years. Adults rarely interact in the wild except to mate. Both sexes may mate with more than one partner during the mating season from mid-January to early March. A few days before birth, females begin to collect material, such as brushwood, grass, and leaves; to build a nest, which is normally located in a hollow tree or a rock crevice. After a gestation period of 112 to 158 days, the female gives birth in mid-June to late July to one to four (usually 1–2) blind and deaf cubs weighing each.

After birth, the mother cleans the cubs, and can then recognize each by their smell. At first, she spends 60% to 90% of her time with the cubs. After the first week, the mother starts spending more time outside the nest, returning every few hours to nurse and groom the cubs. She moves the young frequently among several nests, all of which she keeps clean. The cubs start to open their eyes at about 18 days of age. By about 90 days, they achieve full adult fur and coloring, and begin to venture out of the nest. They also start eating solid foods at this point, weaning at around six to eight months of age. The cubs stay with their mother until the next litter is born in the following summer. Males rarely help raise the young, and only if they live in pairs or in small groups.

A red panda's lifespan ranges between eight and 10 years, but individuals have been known to reach 15 years.

The primary threats to red pandas are direct harvest from the wild, live or dead, competition with domestic livestock resulting in habitat degradation, and deforestation resulting in habitat loss or fragmentation. The relative importance of these factors is different in each region, and is not well understood. For instance, in India, the biggest threat seems to be habitat loss followed by poaching, while in China, the biggest threat seems to be hunting and poaching. A 40% decrease in red panda populations has been reported in China over the last 50 years, and populations in western Himalayan areas are considered to be lower.

Deforestation can inhibit the spread of red pandas and exacerbate the natural population subdivision by topography and ecology, leading to severe fragmentation of the remaining wild population. Fewer than 40 animals in four separate groups share resources with humans in Nepal's Langtang National Park, where only 6% of is preferred red panda habitat. Although direct competition for food with domestic livestock is not significant, livestock can depress bamboo growth by trampling.

Small groups of animals with little opportunity for exchange between them face the risk of inbreeding, decreased genetic diversity, and even extinction. In addition, clearcutting for firewood or agriculture, including hillside terracing, removes old trees that provide maternal dens and decreases the ability of some species of bamboo to regenerate.

In south-west China, red pandas are hunted for their fur, especially for the highly valued bushy tails, from which hats are produced. In these areas, the fur is often used for local cultural ceremonies. In weddings, the bridegroom traditionally carries the hide. The "good-luck charm" red panda-tail hats are also used by local newly-weds. This practice may be quite old, as the red panda seems to be depicted in a 13th-century Chinese pen-and-ink scroll showing a hunting scene. Little or no mention of the red panda is made in the culture and folklore of Nepal.

In the past, red pandas were captured and sold to zoos. In an article appearing in the "International Zoo News" in 1969, one reported he personally had handled 350 red pandas in 17 years.

Due to CITES, this zoo harvest has decreased substantially in recent years, but poaching continues, and red pandas are often sold to private collectors at exorbitant prices. In some parts of Nepal and India, red pandas are kept as pets.

The red panda has a naturally low birth rate (usually one single or twin birth per year), and a high death rate in the wild.

The red panda is listed as endangered on the IUCN Red List since 2008 because the global population is estimated at about 10,000 individuals, with a decreasing population trend; only about half of the total area of potential habitat of is actually being used by the species. Due to its shy and secretive nature, and its largely nocturnal habits, observation of red pandas is difficult. Therefore, population figures in the wild are determined by population density estimates and not direct counts. It is protected in all range countries, and hunting is illegal. It is listed in CITES Appendix I.

Worldwide population estimates range from fewer than 2,500 to between 16,000 and 20,000 individuals. In 1999, the total population in China was estimated at between 3,000 and 7,000 individuals. In 2001, the wild population in India was estimated at between 5,000 and 6,000 individuals. Estimates for Nepal indicate only a few hundred individuals.
Reliable population numbers are hard to find, partly because other animals have been mistaken for the red panda. For instance, one report from Myanmar stated that red pandas were still fairly common in some areas; however, the accompanying photographic proof of the "red panda" was in fact a viverrid species.

Conservation efforts are highly variable between countries:

A community-managed forest in Ilam District of eastern Nepal is home to 15 red pandas which generate household income through tourism activities, including homestays. Villagers in the high-altitude areas of Arunachal Pradesh have formed the Pangchen Red Panda Conservation Alliance comprising five villages with a community-conserved forest area of at an altitude of to over .

The international red panda studbook is currently managed at Rotterdam Zoo in the Netherlands. In cooperation with the International Red Panda Management Group, they coordinate the Species Survival Plan in North America, the European Endangered Species Programme in Europe, and other captive-breeding programs in Australia, India, Japan, and China. As of 2006, more than 800 individuals were kept in zoos and parks around the world. Of these, 511 individuals of the Himalayan red panda were kept in 173 institutions and 306 individuals of Styan's red panda were kept in 81 institutions.
Since 2009, the North American Red Panda Species Survival Plan is coordinated at the Knoxville Zoo, which by 2011 had 101 red panda births. Only the Rotterdam Zoo has had more captive births worldwide.

The Padmaja Naidu Himalayan Zoological Park in Darjeeling successfully released four captive-bred red pandas to the wild in August and November 2003.<ref name="india/studbook"></ref>

The most often cited example of keeping red pandas as pets is the case of former Indian prime minister Indira Gandhi. Pandas were presented to her family as a gift, and they were then housed in "a special tree house".

"Ailurus fulgens" was the scientific name proposed by Frédéric Cuvier in 1825, who described a zoological specimen sent by Alfred Duvaucel "from the mountains north of India". He was the first to also use the vernacular name "panda". In the 19th and 20th centuries, the following specimens were described:
Pocock distinguished "A. f. styani" from "A. f. fulgens" by its longer winter coat and greater blackness of the pelage, bigger skull, more strongly curved forehead, and more robust teeth. His description is based on skulls and skins collected in Sichuan, Myitkyina District, close to the border of Yunnan, and Upper Burma.

Two subspecies are usually recognised, although results from a recent genomic study has suggested that these should be considered separate species:
The Brahmaputra River is often considered the natural barrier between the two subspecies, where it makes a curve around the eastern end of the Himalayas, although some authors suggest "A. f. fulgens" extends farther eastward into China.

The name "Ailurus fulgens refulgens" is sometimes incorrectly used for "A. f. styani". This stems from a lapsus made by Henri Milne-Edwards in 1874. making "A. f. refulgens" a "nomen nudum". This has been corrected in later publications.

At various times, the red panda was placed in the Procyonidae, Ursidae, with "Ailuropoda" (giant panda) in the Ailuropodinae (until this family was moved into the Ursidae), and into its own family, the Ailuridae. This uncertainty comes from difficulty in determining whether certain characteristics of "Ailurus" are phylogenetically conservative or are derived and convergent with species of similar ecological habits.

Evidence based on the fossil record, serology, karyology, behavior, anatomy, and reproduction reflect closer affinities with Procyonidae than Ursidae. However, ecological and foraging specializations and distinct geographical distribution in relation to modern procyonids support classification in the separate family Ailuridae.

Recent molecular systematic DNA research also places the red panda into its own family, Ailuridae, a part of the broad superfamily Musteloidea that also includes the mephitids (skunks), procyonids (raccoons), and mustelids (weasels). According to the most recent phylogenetic studies, the red panda's closest relatives within the Musteloidea superfamily are the procyonids and mustelids.

The red panda is considered a living fossil and only distantly related to the giant panda ("Ailuropoda melanoleuca"), as it is naturally more closely related to the other members of the superfamily Musteloidea to which it belongs. The common ancestor of both pandas (which also was an ancestor for all living bears; pinnipeds like seals and walruses; and members of the family Musteloidea like weasels and otters) can be traced back to the Paleogene period tens of millions of years ago, with a wide distribution across Eurasia.

Fossils of the extinct red panda "Parailurus anglicus" were excavated in sites from China in the east to Britain in the west. In 1977, a single tooth of "Parailurus" was discovered in the Pliocene Ringold Formation of Washington. This first North American record is almost identical to European specimens and indicates the immigration of this species from Asia. In 2004, a tooth from a red panda species never before recorded in North America was discovered at the Gray Fossil Site in Tennessee. The tooth dates from 4.5–7 million years ago. This species, described as "Pristinailurus bristoli", indicates that a second, more primitive ailurine lineage inhabited North America during the Miocene. Cladistic analysis suggests that "Parailurus" and "Ailurus" are sister taxa. Additional fossils of "Pristinailurus bristoli" were discovered at the Gray Fossil Site in 2010 and in 2012.
The discovery in Spain of the postcranial remains of "Simocyon batalleri", a Miocene relative to the red panda, supports a sister-group relationship between red pandas and bears. The discovery suggests the red panda's "false thumb" was an adaptation to arboreal locomotion — independent of the giant panda's adaptation to manipulate bamboo — one of the most dramatic cases of convergent evolution among vertebrates.

In 2020, results of a phylogenetic analysis of red panda samples showed that red pandas in China and the Himalayas were separated by a river about 250,000 years ago. Therefore, the two subspecies should be treated as distinct species. The analysed samples showed high levels of population structure across the red panda's range. However, the results of this research should be treated with caution because of the sampling gap of >500 km between the two proposed species, and the lack of isolation-by-distance and morphometric analyses. Additionally, the use of the phylogenetic species concept for species delimitation in mammals has been associated with the unnecessary splitting of subspecies into species.

"Ailurus" is adopted from the ancient Greek word (""), meaning "cat". The specific epithet "fulgens" is Latin for "shining, bright".

Panda is a Roman goddess of peace and travellers, who was called upon before starting a difficult journey.

The Lepcha call it "sak nam". In Nepal, it is called ' (bear-cat) and '. The Sherpa people of Nepal and Sikkim call it "ye niglva ponva" and "wah donka". The word "wậː" is Sunuwari meaning bear; in Tamang language, a small, red bear is called "tāwām". In the Kanchenjunga region of eastern Nepal, the Limbu people know red pandas as "kaala" (literally "dark") because of their underside pelage; villagers of Tibetan origin call them "hoptongar".

Additionally, Pocock lists the vernacular names "ye" and ' (Nepal); "thokya" and "thongwa" (Limbu); "oakdonga" or "wakdonka" and "woker" (Bhotia); "saknam sunam" (Lepcha). ' may originate from the Nepali word ' or ', a small bamboo, "Arundinaria intermedia", but also refers to a kind of small leopard, or cat-bear. The word ' may originate from the Nepali ' ("claw") or "" ("paw").
'Poonya' also means "eater of bamboo". The name panda could originate from "panjā".

In modern Chinese, the red panda is called "xiăoxióngmāo" ( and , lesser or small panda, or literally "little bear cat"), or / ("hóngxióngmāo", red panda or literally "red bear cat").

In English, the red panda is also called the "lesser panda", "true panda" and "common panda".
The first known written record of the red panda occurs in a 13th-century Chinese scroll depicting a hunting scene between hunters and the red panda.

The red panda was recognized as the state animal of Sikkim in the early 1990s, and was the mascot of the Darjeeling Tea Festival.

In 2005, Babu, a male red panda at Birmingham Nature Centre in Birmingham, England, escaped and briefly became a media celebrity, before being recaptured. He was subsequently voted "Brummie of the Year", the first animal to receive this honor.
Rusty, a male red panda at the National Zoo in Washington, DC, similarly attracted media attention when he briefly escaped in 2013.

The name of the open-source Firefox web browser is said to have been derived from a nickname of the red panda: "fire fox".

An anthropomorphic red panda was featured as Master Shifu, the kung fu teacher, in the 2008 film "Kung Fu Panda", and its sequels "Kung Fu Panda 2" in 2011 and "Kung Fu Panda 3" in 2016. The red panda Futa inspired the character of Pabu, the so-called "fire ferret" animal companion (primarily of Bolin), in the U.S. animated TV series "The Legend of Korra".

Jetstar Japan uses a red panda mascot character named "Jetta" (ジェッ太).

An anthropomorphic red panda, Retsuko, is the main character of the TV anime and Netflix original series "Aggretsuko".




</doc>
<doc id="26442" url="https://en.wikipedia.org/wiki?curid=26442" title="Roppongi">
Roppongi

The name "Roppongi", which appears to have been coined around 1660, literally means "six trees". Six very old and large zelkova trees used to mark the area; the first three were cleared, and the last were destroyed during World War II. Another legend has it that the name comes from the fact that six "daimyōs" lived nearby during the Edo period, each with the kanji character for "tree" or a kind of tree in their names. Roppongi was not extensively populated until after the Meiji Restoration, although the area was trafficked for centuries and served as the site of the cremation of Shōgun Tokugawa Hidetada's wife in 1626.

In 1890, the Third Imperial Guard of the Imperial Japanese Army was moved to a site near Roppongi (now home to the Pacific bureau of "Stars and Stripes"). The influx of soldiers led to the area's rise as a nightlife district, briefly interrupted by the Great Kanto earthquake which flattened the area in 1923. Roppongi was administratively part of Azabu Ward from 1878 to 1947.

After World War II, during which the area was again destroyed, this time by aerial bombing raids, the United States Army and Allied government officials occupied several facilities in the area, beginning Roppongi's reputation as a neighborhood with large numbers of non-Japanese. Several large US military installations were located in the nearby area, with Hardy Barracks probably the most significant (the US Embassy Housing Compound and Akasaka Press Center including Hardy Barracks Recreational Lodging, "Stars and Stripes" office and heliport are still there). Surrounding the military installations were many Japanese-owned restaurants, pool halls, bars, and brothels which catered to US military personnel but were also often frequented by Japanese customers.

Starting in the late 1960s, Roppongi became popular among Japanese people and foreigners alike for its disco scene, which attracted many of Tokyo's entertainment elites. Contributing to the international scene was the location of several foreign embassies and foreign corporate offices in the Roppongi area. However, many dance clubs shut down in the recession following the market crash of 1989.

The Roppongi area received a major economic boost in 2002–2003 when the Izumi Garden Tower and the Roppongi Hills high-rise complexes were completed. These projects brought high-end office and condominium space to Roppongi for the first time. The Tokyo Midtown project in neighbouring Akasaka, which was completed in 2006, and includes the first Tokyo Ritz-Carlton Hotel, continued this trend.

The area features numerous bars, nightclubs, strip clubs, restaurants, hostess clubs, cabarets, and other forms of entertainment. Among the expatriate community, the area tends to be favored by business people, students, and off-duty US military personnel. Overall, the neighborhood caters to a younger crowd.
Clubs can range from large, multi-level establishments, to smaller one-room clubs located in upper levels of buildings.
In more recent times some of the larger venues with known Yakuza connections have closed.

Restaurants in Roppongi vary from upscale Japanese fare to popular international restaurants.

In the past, Roppongi had a reputation as an area with high Yakuza presence, whether as customers at Roppongi establishments, conducting business, or managing or owning clubs and bars in the area. Although still exerting some influence in Roppongi, in recent times they appear to have shifted much of their presence to other districts in the Tokyo area.

In 2006, Nigerian immigrants to Japan began opening a number of bars and nightclubs in the area, following an earlier group of innovators who had been in business in Roppongi for many years. The Nigerians were noted for using visible, high-pressure tactics to draw customers to their bars. In 2009 and 2010 a series of drink-spiking incidents, in which customers reported being drugged and robbed, were linked to Nigerian-owned bars. The incidents resulted in the United States embassy in Japan warning US citizens to avoid certain bars and clubs in Roppongi. An investigation by "The Japan Times" in July 2011 found that though drink spiking occurred, most of the incidents did not involve criminal activity. Many customers claimed unusually severe hangovers after nights spent in Nigerian-run establishments. Similar complaints are often made about non-Nigerian bars in Roppongi that offer unlimited drink packages and often lace drinks with hard liquor to minimize customer consumption and increase profit.

Mori Building Company and The Pokémon Company have their headquarters in the Roppongi Hills Mori Tower.

Companies based in Roppongi include:


Public elementary and middle schools are operated by the Minato City (the Minato Ward) Board of Education. Roppongi Junior High School is located at Imoarai-Zaka, in Roppongi.

Public high schools are operated by the Tokyo Metropolitan Government Board of Education. Roppongi High School is located in Roppongi.

Toyo Eiwa Jogakuin is private girls school, also located at Torii-Zaka in the district.

The American School in Japan Early Learning Center is in Roppongi Hills.



</doc>
<doc id="26444" url="https://en.wikipedia.org/wiki?curid=26444" title="Robert Louis Stevenson">
Robert Louis Stevenson

Robert Louis Stevenson (born Robert Lewis Balfour Stevenson; 13 November 1850 – 3 December 1894) was a Scottish novelist, poet and travel writer, most noted for "Treasure Island", "Kidnapped", "Strange Case of Dr Jekyll and Mr Hyde", and "A Child's Garden of Verses".

Born and educated in Edinburgh, Stevenson suffered from serious bronchial trouble for much of his life, but continued to write prolifically and travel widely in defiance of his poor health. As a young man, he mixed in London literary circles, receiving encouragement from Andrew Lang, Edmund Gosse, Leslie Stephen and W. E. Henley, the last of whom may have provided the model for Long John Silver in "Treasure Island". In 1890, he settled in Samoa, where he died in 1894.

A celebrity in his lifetime, Stevenson's critical reputation has fluctuated since his death, though today his works are held in general acclaim. He is currently ranked as the 26th-most-translated author in the world.

Stevenson was born at 8 Howard Place, Edinburgh, Scotland on 13 November 1850 to Thomas Stevenson (1818–1887), a leading lighthouse engineer, and his wife Margaret Isabella (born Balfour, 1829–1897). He was christened Robert Lewis Balfour Stevenson. At about age 18, he changed the spelling of "Lewis" to "Louis", and he dropped "Balfour" in 1873.

Lighthouse design was the family's profession; Thomas's father (Robert's grandfather) was civil engineer Robert Stevenson, and Thomas's brothers (Robert's uncles) Alan and David were in the same field. Thomas's maternal grandfather Thomas Smith had been in the same profession. However, Robert's mother's family were gentry, tracing their lineage back to Alexander Balfour who had held the lands of Inchyra in Fife in the fifteenth century. His mother's father Lewis Balfour (1777–1860) was a minister of the Church of Scotland at nearby Colinton, and her siblings included physician George William Balfour and marine engineer James Balfour. Stevenson spent the greater part of his boyhood holidays in his maternal grandfather's house. "Now I often wonder what I inherited from this old minister," Stevenson wrote. "I must suppose, indeed, that he was fond of preaching sermons, and so am I, though I never heard it maintained that either of us loved to hear them."

Lewis Balfour and his daughter both had weak chests, so they often needed to stay in warmer climates for their health. Stevenson inherited a tendency to coughs and fevers, exacerbated when the family moved to a damp, chilly house at 1 Inverleith Terrace in 1851. The family moved again to the sunnier 17 Heriot Row when Stevenson was six years old, but the tendency to extreme sickness in winter remained with him until he was 11. Illness was a recurrent feature of his adult life and left him extraordinarily thin. Contemporaneous views were that he had tuberculosis, but more recent views are that it was bronchiectasis or even sarcoidosis.

Stevenson's parents were both devout Presbyterians, but the household was not strict in its adherence to Calvinist principles. His nurse Alison Cunningham (known as Cummy) was more fervently religious. Her mix of Calvinism and folk beliefs were an early source of nightmares for the child, and he showed a precocious concern for religion. But she also cared for him tenderly in illness, reading to him from John Bunyan and the Bible as he lay sick in bed and telling tales of the Covenanters. Stevenson recalled this time of sickness in "The Land of Counterpane" in "A Child's Garden of Verses" (1885), dedicating the book to his nurse.

Stevenson was an only child, both strange-looking and eccentric, and he found it hard to fit in when he was sent to a nearby school at age 6, a problem repeated at age 11 when he went on to the Edinburgh Academy; but he mixed well in lively games with his cousins in summer holidays at Colinton. His frequent illnesses often kept him away from his first school, so he was taught for long stretches by private tutors. He was a late reader, learning at age 7 or 8, but even before this he dictated stories to his mother and nurse, and he compulsively wrote stories throughout his childhood. His father was proud of this interest; he had also written stories in his spare time until his own father found them and told him to "give up such nonsense and mind your business." He paid for the printing of Robert's first publication at 16, entitled "The Pentland Rising: A Page of History, 1666". It was an account of the Covenanters' rebellion which was published in 1866, the 200th anniversary of the event.

In September 1857, Stevenson went to "Mr Henderson's School" in India Street, Edinburgh, but because of poor health stayed only a few weeks and did not return until October 1859. During his many absences, he was taught by private tutors. In October 1861, he went to Edinburgh Academy, an independent school for boys, and stayed there sporadically for about fifteen months. In the autumn of 1863, he spent one term at an English boarding school at Spring Grove in Isleworth in Middlesex (now an urban area of West London). In October 1864, following an improvement to his health, he was sent to Robert Thomson's private school in Frederick Street, Edinburgh, where he remained until he went to university. In November 1867, Stevenson entered the University of Edinburgh to study engineering. He showed from the start no enthusiasm for his studies and devoted much energy to avoiding lectures. This time was more important for the friendships he made with other students in the Speculative Society (an exclusive debating club), particularly with Charles Baxter, who would become Stevenson's financial agent, and with a professor, Fleeming Jenkin, whose house staged amateur drama in which Stevenson took part, and whose biography he would later write. Perhaps most important at this point in his life was a cousin, Robert Alan Mowbray Stevenson (known as "Bob"), a lively and light-hearted young man who, instead of the family profession, had chosen to study art. 

Each year during vacations, Stevenson travelled to inspect the family's engineering works—to Anstruther and Wick in 1868, with his father on his official tour of Orkney and Shetland islands lighthouses in 1869, and for three weeks to the island of Erraid in 1870. He enjoyed the travels more for the material they gave for his writing than for any engineering interest. The voyage with his father pleased him because a similar journey of Walter Scott with Robert Stevenson had provided the inspiration for Scott's 1822 novel "The Pirate". In April 1871, Stevenson notified his father of his decision to pursue a life of letters. Though the elder Stevenson was naturally disappointed, the surprise cannot have been great, and Stevenson's mother reported that he was "wonderfully resigned" to his son's choice. To provide some security, it was agreed that Stevenson should read Law (again at Edinburgh University) and be called to the Scottish bar. In his 1887 poetry collection "Underwoods", Stevenson muses on his having turned from the family profession:

Say not of me that weakly I declined
The labours of my sires, and fled the sea,
The towers we founded and the lamps we lit,
To play at home with paper like a child.
But rather say: "In the afternoon of time"
"A strenuous family dusted from its hands"
"The sand of granite, and beholding far"
"Along the sounding coast its pyramids"
"And tall memorials catch the dying sun,"
"Smiled well content, and to this childish task"
"Around the fire addressed its evening hours."

In other respects too, Stevenson was moving away from his upbringing. His dress became more Bohemian; he already wore his hair long, but he now took to wearing a velveteen jacket and rarely attended parties in conventional evening dress. Within the limits of a strict allowance, he visited cheap pubs and brothels. More importantly, he had come to reject Christianity and declared himself an atheist. In January 1873, his father came across the constitution of the LJR (Liberty, Justice, Reverence) Club, of which Stevenson and his cousin Bob were members, which began: "Disregard everything our parents have taught us". Questioning his son about his beliefs, he discovered the truth, leading to a long period of dissension with both parents:

What a "damned" curse I am to my parents! As my father said, "You have rendered my whole life a failure". As my mother said, "This is the heaviest affliction that has ever befallen me". O Lord, what a pleasant thing it is to have damned the happiness of (probably) the only two people who care a damn about you in the world.

Stevenson was visiting a cousin in England in late 1873 when he met two people who became very important to him: Sidney Colvin and Fanny (Frances Jane) Sitwell. Sitwell was a 34-year-old woman with a son, who was separated from her husband. She attracted the devotion of many who met her, including Colvin, who married her in 1901. Stevenson was also drawn to her, and they kept up a warm correspondence over several years in which he wavered between the role of a suitor and a son (he addressed her as "Madonna"). Colvin became Stevenson's literary adviser and was the first editor of his letters after his death. He placed Stevenson's first paid contribution in "The Portfolio", an essay entitled "Roads".

Stevenson was soon active in London literary life, becoming acquainted with many of the writers of the time, including Andrew Lang, Edmund Gosse and Leslie Stephen, the editor of "The Cornhill Magazine" who took an interest in Stevenson's work. Stephen took Stevenson to visit a patient at the Edinburgh Infirmary named William Ernest Henley, an energetic and talkative man with a wooden leg. Henley became a close friend and occasional literary collaborator, until a quarrel broke up the friendship in 1888, and he is often considered to be the model for Long John Silver in "Treasure Island".

Stevenson was sent to Menton on the French Riviera in November 1873 to recuperate after his health failed. He returned in better health in April 1874 and settled down to his studies, but he returned to France several times after that. He made long and frequent trips to the neighborhood of the Forest of Fontainebleau, staying at Barbizon, Grez-sur-Loing and Nemours and becoming a member of the artists' colonies there. He also traveled to Paris to visit galleries and the theatres. He qualified for the Scottish bar in July 1875, and his father added a brass plate to the Heriot Row house reading "R.L. Stevenson, Advocate". His law studies did influence his books, but he never practised law; all his energies were spent in travel and writing. One of his journeys was a canoe voyage in Belgium and France with Sir Walter Simpson, a friend from the Speculative Society, a frequent travel companion, and the author of "The Art of Golf" (1887). This trip was the basis of his first travel book "An Inland Voyage" (1878).

The canoe voyage with Simpson brought Stevenson to Grez in September 1876 where he met Fanny Van de Grift Osbourne (1840–1914), born in Indianapolis. She had married at age 17 and moved to Nevada to rejoin husband Samuel after his participation in the American Civil War. Their children were Isobel (or "Belle"), Lloyd and Hervey (who died in 1875). But anger over her husband's infidelities led to a number of separations. In 1875, she had taken her children to France where she and Isobel studied art.

Stevenson returned to Britain shortly after this first meeting, but Fanny apparently remained in his thoughts, and he wrote the essay "On falling in love" for "The Cornhill Magazine". They met again early in 1877 and became lovers. Stevenson spent much of the following year with her and her children in France. In August 1878, she returned to San Francisco and Stevenson remained in Europe, making the walking trip that formed the basis for "Travels with a Donkey in the Cévennes" (1879). But he set off to join her in August 1879, against the advice of his friends and without notifying his parents. He took second-class passage on the steamship "Devonia", in part to save money but also to learn how others traveled and to increase the adventure of the journey. He then traveled overland by train from New York City to California. He later wrote about the experience in "The Amateur Emigrant". It was good experience for his writing, but it broke his health. 

He was near death when he arrived in Monterey, California, where some local ranchers nursed him back to health. He stayed for a time at the French Hotel located at 530 Houston Street, now a museum dedicated to his memory called the "Stevenson House". While there, he often dined "on the cuff," as he said, at a nearby restaurant run by Frenchman Jules Simoneau, which stood at what is now Simoneau Plaza; several years later, he sent Simoneau an inscribed copy of his novel "Strange Case of Dr Jekyll and Mr Hyde" (1886), writing that it would be a stranger case still if Robert Louis Stevenson ever forgot Jules Simoneau. While in Monterey, he wrote an evocative article about "the Old Pacific Capital" of Monterey.

By December 1879, Stevenson had recovered his health enough to continue to San Francisco where he struggled "all alone on forty-five cents a day, and sometimes less, with quantities of hard work and many heavy thoughts," in an effort to support himself through his writing. But by the end of the winter, his health was broken again and he found himself at death's door. Fanny was now divorced and recovered from her own illness, and she came to his bedside and nursed him to recovery. "After a while," he wrote, "my spirit got up again in a divine frenzy, and has since kicked and spurred my vile body forward with great emphasis and success." When his father heard of his condition, he cabled him money to help him through this period.

Fanny and Robert were married in May 1880, although he said that he was "a mere complication of cough and bones, much fitter for an emblem of mortality than a bridegroom." He travelled with his new wife and her son Lloyd north of San Francisco to Napa Valley and spent a summer honeymoon at an abandoned mining camp on Mount Saint Helena (today designated Robert Louis Stevenson State Park). He wrote about this experience in "The Silverado Squatters". He met Charles Warren Stoddard, co-editor of the "Overland Monthly" and author of "South Sea Idylls", who urged Stevenson to travel to the South Pacific, an idea which returned to him many years later. In August 1880, he sailed with Fanny and Lloyd from New York to Britain and found his parents and his friend Sidney Colvin on the wharf at Liverpool, happy to see him return home. Gradually, his wife was able to patch up differences between father and son and make herself a part of the family through her charm and wit.

Stevenson searched in vain between 1880 and 1887 for a residence suitable to his health. He spent his summers at various places in Scotland and England, including Westbourne, Dorset, a residential area in Bournemouth. It was during his time in Bournemouth that he wrote the story "Strange Case of Dr Jekyll and Mr Hyde", naming the character Mr. Poole after the town of Poole which is situated next to Bournemouth. In Westbourne, he named his house "Skerryvore" after the tallest lighthouse in Scotland, which his uncle Alan had built (1838–44). A novel of Stevenson's life while residing in Westbourne was written by Adelaide A. Boodle, who had met him there. In the wintertime, Stevenson travelled to France and lived at Davos Platz and the Chalet de Solitude at Hyères, where he was very happy for a time. "I have so many things to make life sweet for me," he wrote, "it seems a pity I cannot have that other one thing—health. But though you will be angry to hear it, I believe, for myself at least, what is is best." In spite of his ill health, he produced the bulk of his best-known work during these years. "Treasure Island" was published under the pseudonym "Captain George North" and became his first widely popular book; he wrote it during this time, along with "Kidnapped", "Strange Case of Dr Jekyll and Mr Hyde" (which established his wider reputation), "", "A Child's Garden of Verses" and "Underwoods". He gave a copy of "Kidnapped" to his friend and frequent Skerryvore visitor Henry James.

His father died in 1887 and Stevenson felt free to follow the advice of his physician to try a complete change of climate, so he headed for Colorado with his mother and family. But after landing in New York, they decided to spend the winter in the Adirondacks at a cure cottage now known as Stevenson Cottage at Saranac Lake, New York. During the intensely cold winter, Stevenson wrote some of his best essays, including "Pulvis et Umbra". He also began "The Master of Ballantrae" and lightheartedly planned a cruise to the southern Pacific Ocean for the following summer.

Stevenson believed in Conservatism for most of his life. His cousin and biographer Sir Graham Balfour said that "he probably throughout life would, if compelled to vote, have always supported the Conservative candidate." In 1866, Stevenson voted for Benjamin Disraeli, future Conservative Prime Minister of the United Kingdom, over Thomas Carlyle for the Lord Rectorship of the University of Edinburgh. During his college years, he briefly identified himself as a "red-hot socialist". He wrote at age 26: "I look back to the time when I was a Socialist with something like regret…. Now I know that in thus turning Conservative with years, I am going through the normal cycle of change and travelling in the common orbit of men's opinions."

In June 1888, Stevenson chartered the yacht "Casco" and set sail with his family from San Francisco. The vessel "plowed her path of snow across the empty deep, far from all track of commerce, far from any hand of help." The sea air and thrill of adventure for a time restored his health, and for nearly three years he wandered the eastern and central Pacific, stopping for extended stays at the Hawaiian Islands, where he became a good friend of King Kalākaua. He befriended the king's niece Princess Victoria Kaiulani, who also had Scottish heritage. He spent time at the Gilbert Islands, Tahiti, New Zealand and the Samoan Islands. During this period, he completed "The Master of Ballantrae", composed two ballads based on the legends of the islanders, and wrote "The Bottle Imp". He preserved the experience of these years in his various letters and in his "In the South Seas" (which was published posthumously). He made a voyage in 1889 with Lloyd on the trading schooner "Equator", visiting Butaritari, Mariki, Apaiang and Abemama in the Gilbert Islands. They spent several months on Abemama with tyrant-chief Tem Binoka, whom Stevenson described in "In the South Seas".

Stevenson left Sydney, Australia, on the "Janet Nicoll" in April 1890 for his third and final voyage among the South Seas islands. He intended to produce another book of travel writing to follow his earlier book "In the South Seas", but it was his wife who eventually published her journal of their third voyage. (Fanny misnames the ship in her account "The Cruise of the Janet Nichol".) A fellow passenger was Jack Buckland, whose stories of life as an island trader became the inspiration for the character of Tommy Hadden in "The Wrecker" (1892), which Stevenson and Lloyd Osbourne wrote together. Buckland visited the Stevensons at Vailima in 1894.

In 1890, Stevenson purchased a tract of about in Upolu, an island in Samoa where he established himself on his estate in the village of Vailima after two aborted attempts to visit Scotland. He took the native name Tusitala (Samoan for "Teller of Tales"). His influence spread among the Samoans, who consulted him for advice, and he soon became involved in local politics. He was convinced that the European officials who had been appointed to rule the Samoans were incompetent, and he published "" after many futile attempts to resolve the matter. This was such a stinging protest against existing conditions that it resulted in the recall of two officials, and Stevenson feared for a time that it would result in his own deportation. He wrote to Colvin, "I used to think meanly of the plumber; but how he shines beside the politician!"

He also found time to work at his writing, although he felt that "there was never any man had so many irons in the fire". He wrote "The Beach of Falesa", "Catriona" (titled "David Balfour" in the US), "The Ebb-Tide" and the "Vailima Letters" during this period.

Stevenson grew depressed and wondered if he had exhausted his creative vein, as he had been "overworked bitterly" and that the best he could write was "ditch-water". He even feared that he might again become a helpless invalid. He rebelled against this idea: "I wish to die in my boots; no more Land of Counterpane for me. To be drowned, to be shot, to be thrown from a horse — ay, to be hanged, rather than pass again through that slow dissolution." He then suddenly had a return of energy and he began work on "Weir of Hermiston". "It's so good that it frightens me," he is reported to have exclaimed. He felt that this was the best work he had done.

On 3 December 1894, Stevenson was talking to his wife and straining to open a bottle of wine when he suddenly exclaimed, "What's that?", asked his wife "does my face look strange?", and collapsed. He died within a few hours, probably of a cerebral haemorrhage. He was 44 years old. The Samoans insisted on surrounding his body with a watch-guard during the night and on bearing him on their shoulders to nearby Mount Vaea, where they buried him on a spot overlooking the sea on land donated by British Acting Vice Consul Thomas Trood. Stevenson had always wanted his Requiem inscribed on his tomb:

Stevenson was loved by the Samoans, and his tombstone epigraph was translated to a Samoan song of grief.

Half of Stevenson's original manuscripts are lost, including those of "Treasure Island", "The Black Arrow" and "The Master of Ballantrae". His heirs sold his papers during World War I, and many Stevenson documents were auctioned off in 1918.

Stevenson was a celebrity in his own time, being admired by many other writers, including Jorge Luis Borges, Bertolt Brecht, Marcel Proust, Arthur Conan Doyle, Henry James, Cesare Pavese, Emilio Salgari, Ernest Hemingway, Rudyard Kipling, Jack London, Vladimir Nabokov, J. M. Barrie, and G. K. Chesterton, who said that Stevenson "seemed to pick the right word up on the point of his pen, like a man playing spillikins."

Stevenson was seen for much of the 20th century as a second-class writer. He became relegated to children's literature and horror genres, condemned by literary figures such as Virginia Woolf (daughter of his early mentor Leslie Stephen) and her husband Leonard Woolf, and he was gradually excluded from the canon of literature taught in schools. His exclusion reached its nadir in the 1973 2,000-page "Oxford Anthology of English Literature" where he was entirely unmentioned, and "The Norton Anthology of English Literature" excluded him from 1968 to 2000 (1st–7th editions), including him only in the 8th edition (2006).

The late 20th century brought a re-evaluation of Stevenson as an artist of great range and insight, a literary theorist, an essayist and social critic, a witness to the colonial history of the Pacific Islands and a humanist. He was praised by Roger Lancelyn Green, one of the Oxford Inklings, as a writer of a consistently high level of "literary skill or sheer imaginative power" and a pioneer of the Age of the Story Tellers along with H. Rider Haggard. He is now evaluated as a peer of authors such as Joseph Conrad (whom Stevenson influenced with his South Seas fiction) and Henry James, with new scholarly studies and organisations devoted to him. Throughout the vicissitudes of his scholarly reception, Stevenson has remained popular worldwide. According to the Index Translationum, Stevenson is ranked the 26th-most-translated author in the world, ahead of Oscar Wilde and Edgar Allan Poe.

On the subject of Stevenson's modern reputation, American film critic Roger Ebert wrote in 1996,

The Writers' Museum near Edinburgh's Royal Mile devotes a room to Stevenson, containing some of his personal possessions from childhood through to adulthood.

The Stevenson House at 530 Houston Street in Monterey, California, formerly the French Hotel, memorializes Stevenson's 1879 stay in "the Old Pacific Capital", as he was crossing the United States to join his future wife, Fanny Osbourne. The Stevenson House museum is graced with a bas-relief depicting the sickly author writing in bed.

The Robert Louis Stevenson Museum in St. Helena, California, is home to over 11,000 objects and artifacts, the majority of which belonged to Stevenson. Opened in 1969, the museum houses such treasures as his childhood rocking chair, writing desk, toy soldiers and personal writings among many other items. The museum is free to the public and serves as an academic archive for students, writers and Stevenson enthusiasts.

Stevenson's former home in Vailima, Samoa, is now a museum dedicated to the later years of his life. The museum collection includes several original items belonging to Stevenson and his family. The path to Stevenson's grave at the top of Mt Vaea commences from the museum.

A bronze relief memorial to Stevenson, designed by the American sculptor Augustus Saint-Gaudens in 1904, is mounted in the Moray Aisle of St Giles' Cathedral, Edinburgh. Saint-Gaudens' scaled-down version of this relief is in the collection of the Montclair Art Museum. Another small version depicting Stevenson with a cigarette in his hand rather than the pen he holds in the St. Giles memorial is displayed in the Nichols House Museum in Beacon Hill, Boston.

Another memorial in Edinburgh stands in West Princes Street Gardens below Edinburgh Castle; it is a simple upright stone inscribed with "RLS – A Man of Letters 1850–1894" by sculptor Ian Hamilton Finlay in 1987. In 2013, a statue of Stevenson as a child with his dog was unveiled by the author Ian Rankin outside Colinton Parish Church. The sculptor of the statue was Alan Herriot, and the money to erect it was raised by the Colinton Community Conservation Trust.

A plaque above the door of a house in Castleton of Braemar states "Here R.L. Stevenson spent the Summer of 1881 and wrote Treasure Island, his first great work".

A garden was designed by the Bournemouth Corporation in 1957 as a memorial to Stevenson, on the site of his Westbourne house, "Skerryvore", which he occupied from 1885 to 1887. A statue of the Skerryvore lighthouse is present on the site.

In 1966, the Canadian actor Lloyd Bochner played Stevenson in the episode "Jolly Roger and Wells Fargo" of the syndicated American television series, "Death Valley Days", hosted by Robert Taylor and directed by Denver Pyle. In an earlier "Death Valley Days" episode from 1958, "The Great Amulet", hosted by Stanley Andrews, the actor Don Reardon (died 2004) played the role of Stevenson. In the story line, Stevenson falls in love with Fanny Osbourne, played by Aline Towne (1919–1996), the mother of two children in a loveless marriage in San Francisco. The couple met in France where Stevenson was recuperating from health issues and moved to San Francisco, where Stevenson worked tirelessly despite lingering health matters in the production of his large volume of literary works. "The Great Amulet" is revealed at the conclusion of the episode.

In 1994, to mark the 100th anniversary of Stevenson's death, the Royal Bank of Scotland issued a series of commemorative £1 notes which featured a quill pen and Stevenson's signature on the obverse, and Stevenson's face on the reverse side. Alongside Stevenson's portrait are scenes from some of his books and his house in Western Samoa. Two million notes were issued, each with a serial number beginning "RLS". The first note to be printed was sent to Samoa in time for their centenary celebrations on 3 December 1994.

At least six US elementary schools are named after Stevenson, in the Upper West Side of New York City, in Fridley, Minnesota, in Burbank, California, in Grandview Heights, Ohio (suburb of Columbus), in San Francisco, California, and in Merritt Island, Florida. There is an R. L. Stevenson middle school in Honolulu, Hawaii and in Saint Helena, California. Stevenson School in Pebble Beach, California, was established in 1952 and still exists as a college preparatory boarding school. Robert Louis Stevenson State Park near Calistoga, California, contains the location where he and Fanny spent their honeymoon in 1880.

A street in Honolulu's Waikiki District, where Stevenson lived while in the Hawaiian Islands, was named after his Samoan moniker: Tusitala. This was also (until 2014) the name of a restaurant on Buckstone Terrace, Edinburgh on the route of a favourite walk that Stevenson often took to the village of Swanston in the Pentland Hills.

In 2011, Stevenson's open letter defending Father Damien from Rev. Dr. Charles McEwen Hyde influenced the founding of the Saint Damien Advocates in Hawaii.

The Chemin de Stevenson (GR 70) is a popular long-distance footpath in France that approximately follows Stevenson's route as described in "Travels with a Donkey in the Cévennes". There are numerous monuments and businesses named after him along the route, including a fountain in the town of Saint-Jean-du-Gard where Stevenson sold his donkey Modestine and took a stagecoach to Alès.

The Robert Louis Stevenson Memorial is an outdoor memorial in Portsmouth Square, San Francisco, California.

A memorial by Gutzon Borglum was unveiled, in 1915, at Baker Cottage, Saranac Lake, New York.



List of short stories sorted chronologically. Note: does not include collaborations with Fanny found in "More New Arabian Nights: The Dynamiter".




Although not well known, his island fiction and non-fiction is among the most valuable and collected of the 19th century body of work that addresses the Pacific area.





</doc>
<doc id="26446" url="https://en.wikipedia.org/wiki?curid=26446" title="Recreational mathematics">
Recreational mathematics

Recreational mathematics is mathematics carried out for recreation (entertainment) rather than as a strictly research and application-based professional activity or as a part of a student's formal education. Although it is not necessarily limited to being an endeavor for amateurs, many topics in this field require no knowledge of advanced mathematics. Recreational mathematics involves mathematical puzzles and games, often appealing to children and untrained adults, inspiring their further study of the subject.

The Mathematical Association of America (MAA) includes Recreational Mathematics as one of its seventeen Special Interest Groups, commenting:
Mathematical competitions (such as those sponsored by mathematical associations) are also categorized under recreational mathematics.

Some of the more well-known topics in recreational mathematics are Rubik's Cubes, magic squares, fractals, logic puzzles and mathematical chess problems, but this area of mathematics includes the aesthetics and culture of mathematics, peculiar or amusing stories and coincidences about mathematics, and the personal lives of mathematicians.

Mathematical games are multiplayer games whose rules, strategies, and outcomes can be studied and explained using mathematics. The players of the game may not need to use explicit mathematics in order to play mathematical games. For example, Mancala is studied in the mathematical field of combinatorial game theory, but no mathematics is necessary in order to play it.

Mathematical puzzles require mathematics in order to solve them. They have specific rules, as do multiplayer games, but mathematical puzzles don't usually involve competition between two or more players. Instead, in order to solve such a puzzle, the solver must find a solution that satisfies the given conditions.

Logic puzzles and classical ciphers are common examples of mathematical puzzles. Cellular automata and fractals are also considered mathematical puzzles, even though the solver only interacts with them by providing a set of initial conditions.

As they often include or require game-like features or thinking, mathematical puzzles are sometimes also called mathematical games.

Other curiosities and pastimes of non-trivial mathematical interest include:

There are many blogs and audio or video series devoted to recreational mathematics. Among them are the following:


Prominent practitioners and advocates of recreational mathematics have included:





</doc>
<doc id="26447" url="https://en.wikipedia.org/wiki?curid=26447" title="Resurrection">
Resurrection

Resurrection or anastasis is the concept of coming back to life after death. In a number of religions, a dying-and-rising god is a deity which dies and resurrects. Reincarnation is a similar process hypothesized by other religions, which involves the same person or deity coming back to live in a different body, rather than the same one.

The resurrection of the dead is a standard eschatological belief in the Abrahamic religions. As a religious concept, it is used in two distinct respects: a belief in the resurrection of individual souls that is current and ongoing (Christian idealism, realized eschatology), or else a belief in a singular resurrection of the dead at the end of the world. Some believe the soul is the actual vehicle by which people are resurrected.

The death and resurrection of Jesus is a central focus of Christianity. Christian theological debate ensues with regard to what kind of resurrection is factual – either a "spiritual" resurrection with a spirit body into Heaven, or a material resurrection with a restored human body. While most Christians believe Jesus' resurrection from the dead and ascension to Heaven was in a material body, a very small minority believes it was spiritual.

Resurrection, from the Latin noun "resurrectio -onis", from the verb "rego", "to make straight, rule" + preposition "sub", "under", altered to "subrigo" and contracted to "surgo, surrexi, surrectum" ("to rise", "get up", "stand up") + preposition "re-", "again", thus literally "a straightening from under again".

The concept of resurrection is found in the writings of some ancient non-Abrahamic religions in the Middle East. A few extant Egyptian and Canaanite writings allude to dying and rising gods such as Osiris and Baal. Sir James Frazer in his book "The Golden Bough" relates to these dying and rising gods, but many of his examples, according to various scholars, distort the sources. Taking a more positive position, Tryggve Mettinger argues in his recent book that the category of rise and return to life is significant for Ugaritic Baal, Melqart, Adonis, Eshmun, Osiris and Dumuzi.

In ancient Greek religion a number of men and women became physically immortal as they were resurrected from the dead. Asclepius was killed by Zeus, only to be resurrected and transformed into a major deity. Achilles, after being killed, was snatched from his funeral pyre by his divine mother Thetis and resurrected, brought to an immortal existence in either Leuce, the Elysian plains or the Islands of the Blessed. Memnon, who was killed by Achilles, seems to have received a similar fate. Alcmene, Castor, Heracles, and Melicertes, were also among the figures sometimes considered to have been resurrected to physical immortality. According to Herodotus's "Histories", the seventh century BC sage Aristeas of Proconnesus was first found dead, after which his body disappeared from a locked room. Later he found not only to have been resurrected but to have gained immortality.

Many other figures, like a great part of those who fought in the Trojan and Theban wars, Menelaus, and the historical pugilist Cleomedes of Astupalaea, were also believed to have been made physically immortal, but without having died in the first place. Indeed, in Greek religion, immortality originally always included an eternal union of body and soul. The philosophical idea of an immortal soul was a later invention, which, although influential, never had a breakthrough in the Greek world. As may be witnessed even into the Christian era, not least by the complaints of various philosophers over popular beliefs, traditional Greek believers maintained the conviction that certain individuals were resurrected from the dead and made physically immortal and that for the rest of us, we could only look forward to an existence as disembodied and dead souls.

Greek philosophers generally denied this traditional religious belief in physical immortality. Writing his "Lives of Illustrious Men" (Parallel Lives) in the first century, the Middle Platonic philosopher Plutarch in his chapter on Romulus gave an account of the mysterious disappearance and subsequent deification of this first king of Rome, comparing it to traditional Greek beliefs such as the resurrection and physical immortalization of Alcmene and Aristeas the Proconnesian, "for they say Aristeas died in a fuller's work-shop, and his friends coming to look for him, found his body vanished; and that some presently after, coming from abroad, said they met him traveling towards Croton". Plutarch openly scorned such beliefs held in traditional ancient Greek religion, writing, "many such improbabilities do your fabulous writers relate, deifying creatures naturally mortal."

Alcestis undergoes resurrection over a three-day period of time,
but without achieving immortality.

The parallel between these traditional beliefs and the later resurrection of Jesus was not lost on the early Christians, as Justin Martyr argued: "when we say ... Jesus Christ, our teacher, was crucified and died, and rose again, and ascended into heaven, we propose nothing different from what you believe regarding those whom you consider sons of Zeus." ("1 Apol." 21).

There are stories in Buddhism where the power of resurrection was allegedly demonstrated in Chan or Zen tradition. One is the legend of Bodhidharma, the Indian master who brought the Ekayana school of India that subsequently became Chan Buddhism to China.

The other is the passing of Chinese Chan master Puhua (Japanese:Jinshu Fuke) and is recounted in the Record of Linji (Japanese: Rinzai Gigen). Puhua was known for his unusual behavior and teaching style so it is no wonder that he is associated with an event that breaks the usual prohibition on displaying such powers. Here is the account from Irmgard Schloegl's "The Zen Teaching of Rinzai".

In Christianity, resurrection most critically concerns the resurrection of Jesus, but also includes the resurrection of Judgment Day known as the resurrection of the dead by those Christians who subscribe to the Nicene Creed (which is the majority or mainstream Christianity), as well as the resurrection miracles done by Jesus and the prophets of the Old Testament.

In the New Testament, Jesus is said to have raised several persons from death. These resurrections included the daughter of Jairus shortly after death, a young man in the midst of his own funeral procession, and Lazarus of Bethany, who had been buried for four days.

During the Ministry of Jesus on earth, before his death, Jesus commissioned his Twelve Apostles to, among other things, raise the dead.

Similar resurrections are credited to the apostles and Catholic saints. In the Acts of the Apostles, Saint Peter raised a woman named Dorcas (also called Tabitha), and Paul the Apostle revived a man named Eutychus who had fallen asleep and fell from a window to his death. According to the Gospel of Matthew, after Jesus's resurrection, many of those previously dead came out of their tombs and entered Jerusalem, where they appeared to many. Following the Apostolic Age, many saints were said to resurrect the dead, as recorded in Orthodox Christian hagiographies. St Columba supposedly raised a boy from the dead in the land of Picts.

Christians regard the resurrection of Jesus as the central doctrine in Christianity. Others take the incarnation of Jesus to be more central; however, it is the miracles – and particularly his resurrection – which provide validation of his incarnation. According to Paul, the entire Christian faith hinges upon the centrality of the resurrection of Jesus and the hope for a life after death. The Apostle Paul wrote in his first letter to the Corinthians:

Christianity started as a religious movement within 1st-century Judaism (late Second Temple Judaism), and it retains what the New Testament itself claims was the Pharisaic belief in the afterlife and resurrection of the dead. Whereas this belief was only one of many beliefs held about the world to come in Second Temple Judaism, and was notably rejected by the Sadducees, but accepted by the Pharisees (cf. Acts 23:6-8). Belief in the resurrection became dominant within Early Christianity and already in the Gospels of Luke and John included an insistence on the resurrection of the flesh. Most modern Christian churches continue to uphold the belief that there will be a final resurrection of the dead and world to come.

Belief in the resurrection of the dead, and Jesus' role as judge, is codified in the Apostles' Creed, which is the fundamental creed of Christian baptismal faith. The Book of Revelation also makes many references about the Day of Judgment when the dead will be raised.

The emphasis on the literal resurrection of the flesh remained strong in the medieval ages, and still remains so in Orthodox churches. In modern Western Christianity, especially "from the 17th to the 19th century, the language of popular piety no longer evoked the resurrection of the soul but everlasting life. Although theological textbooks still mentioned resurrection, they dealt with it as a speculative question more than as an existential problem."

In Platonic philosophy and other Greek philosophical thought, at death the soul was said to leave the inferior body behind. The idea that Jesus was resurrected spiritually rather than physically even gained popularity among some Christian teachers, whom the author of 1 John declared to be antichrists. Similar beliefs appeared in the early church as Gnosticism. However, in Luke 24:39, the resurrected Jesus expressly states "behold my hands and my feet, that it is I myself. Handle me and see, for a spirit does not have flesh and bones as you see I have."

There are folklore, stories, and extractions from certain holy texts that refer to resurrections. One major folklore is that of Savitri saving her husband's life from Yamraj. In the Ramayana, after Ravana was slayed by Rama in a great battle between good and evil, Rama requests the king of Gods, Indra, to restore the lives of all the monkeys who died in the great battle.

Belief in the "Day of Resurrection" ("Yawm al-Qiyāmah"; ) is also crucial for Muslims. They believe the time of "Qiyāmah" is preordained by God but unknown to man. The trials and tribulations preceding and during the "Qiyāmah" are described in the Quran and the hadith, and also in the commentaries of scholars. The Quran emphasizes bodily resurrection, a break from the pre-Islamic Arabian understanding of death.

There are three explicit examples in the Hebrew Bible of people being resurrected from the dead:

According to Herbert C. Brichto, writing in Reform Judaism's "Hebrew Union College Annual", the family tomb is the central concept in understanding biblical views of the afterlife. Brichto states that it is "not mere sentimental respect for the physical remains that is...the motivation for the practice, but rather an assumed connection between proper sepulture and the condition of happiness of the deceased in the afterlife".

According to Brichto, the early Israelites apparently believed that the graves of family, or tribe, united into one, and that this unified collectivity is to what the Biblical Hebrew term Sheol refers, the common grave of humans. Although not well defined in the Tanakh, Sheol in this view was a subterranean underworld where the souls of the dead went after the body died. The Babylonians had a similar underworld called Aralu, and the ancient Greeks had one known as Hades. According to Brichto, other biblical names for Sheol were Abaddon "ruin", found in Psalm 88:11, Job 28:22 and Proverbs 15:11; Bor "pit", found in Isaiah 14:15, 24:22, Ezekiel 26:20; and Shakhat "corruption", found in Isaiah 38:17, Ezekiel 28:8.

During the Second Temple period, there developed a diversity of beliefs concerning the resurrection. The concept of resurrection of the physical body is found in 2 Maccabees, according to which it will happen through re-creation of the flesh. Resurrection of the dead also appears in detail in the extra-canonical Book of Enoch, 2 Baruch, and 2 Esdras. According to the British scholar in ancient Judaism Philip R. Davies, there is “little or no clear reference … either to immortality or to resurrection from the dead” in the texts of the Dead Sea Scrolls. C.D. Elledge, however, argues that some form of resurrection may be referred to in the Dead Sea texts 4Q521, Pseudo-Ezekiel, and 4QInstruction.

Both Josephus and the New Testament record that the Sadducees did not believe in an afterlife, but the sources vary on the beliefs of the Pharisees. The New Testament claims that the Pharisees believed in the resurrection, but does not specify whether this included the flesh or not. According to Josephus, who himself was a Pharisee, the Pharisees held that only the soul was immortal and the souls of good people will “pass into other bodies,” while “the souls of the wicked will suffer eternal punishment.” Paul the Apostle, who also was a Pharisee, said that at the resurrection what is "sown as a natural body is raised a spiritual body." The Book of Jubilees seems to refer to the resurrection of the soul only, or to a more general idea of an immortal soul.

Cryonics is the low-temperature freezing (usually at ) of a human corpse or severed head, with the speculative hope that resurrection may be possible in the future. Cryonics is a pseudoscience. It is regarded with skepticism within the mainstream scientific community and has been widely characterized as quackery.

Russian Cosmist Nikolai Fyodorovich Fyodorov advocated resurrection of the dead using scientific methods. Fedorov tried to plan specific actions for scientific research of the possibility of restoring life and making it infinite. His first project is connected with collecting and synthesizing decayed remains of dead based on "knowledge and control over all atoms and molecules of the world". The second method described by Fedorov is genetic-hereditary. The revival could be done successively in the ancestral line: sons and daughters restore their fathers and mothers, they in turn restore their parents and so on. This means restoring the ancestors using the hereditary information that they passed on to their children. Using this genetic method it is only possible to create a genetic twin of the dead person. It is necessary to give back the revived person his old mind, his personality. Fedorov speculates about the idea of "radial images" that may contain the personalities of the people and survive after death. Nevertheless, Fedorov noted that even if a soul is destroyed after death, Man will learn to restore it whole by mastering the forces of decay and fragmentation.

In his 1994 book "The Physics of Immortality", American physicist Frank J. Tipler, an expert on the general theory of relativity, presented his Omega Point Theory which outlines how a resurrection of the dead could take place at the end of the cosmos. He posits that humans will evolve into robots which will turn the entire cosmos into a supercomputer which will, shortly before the Big Crunch, perform the resurrection within its cyberspace, reconstructing formerly dead humans (from information captured by the supercomputer from the past light cone of the cosmos) as avatars within its metaverse.

David Deutsch, British physicist and pioneer in the field of quantum computing, agrees with Tipler's Omega Point cosmology and the idea of resurrecting deceased people with the help of quantum computers but he is critical of Tipler's theological views.

Italian physicist and computer scientist Giulio Prisco presents the idea of "quantum archaeology", "reconstructing the life, thoughts, memories, and feelings of any person in the past, up to any desired level of detail, and thus resurrecting the original person via 'copying to the future'".

In his book "Mind Children", roboticist Hans Moravec proposed that a future supercomputer might be able to resurrect long-dead minds from the information that still survived. For example, this information can be in the form of memories, filmstrips, medical records, and DNA.

Ray Kurzweil, American inventor and futurist, believes that when his concept of singularity comes to pass, it will be possible to resurrect the dead by digital recreation.

In their science fiction novel "The Light of Other Days", Sir Arthur Clarke and Stephen Baxter imagine a future civilization resurrecting the dead of past ages by reaching into the past, through micro wormholes and with nanorobots, to download full snapshots of brain states and memories.

Both the Church of Perpetual Life and the Terasem Movement consider themselves transreligions and advocate for the use of technology to indefinitely extend the human lifespan.

A zombie (Haitian French: "", ) is a fictional undead being created through the reanimation of a human corpse. Zombies are most commonly found in horror and fantasy genre works. The term comes from Haitian folklore, where a "zombie" is a dead body reanimated through various methods, most commonly magic.

As knowledge of different religions has grown, so have claims of bodily disappearance of some religious and mythological figures. In ancient Greek religion, this was a way the gods made some physically immortal, including such figures as Cleitus, Ganymede, Menelaus, and Tithonus. After his death, Cycnus was changed into a swan and vanished. In his chapter on Romulus from Parallel Lives, Plutarch criticises the continuous belief in such disappearances, referring to the allegedly miraculous disappearance of the historical figures Romulus, Cleomedes of Astypalaea, and Croesus. In ancient times, Greek and Roman pagan similarities were explained by the early Christian writers, such as Justin Martyr, as the work of demons, with the intention of leading Christians astray.

In the Buddhist Epic of King Gesar, also spelled as Geser or Kesar, at the end, chants on a mountain top and his clothes fall empty to the ground. The body of the first Guru of the Sikhs, Guru Nanak Dev, is said to have disappeared and flowers left in place of his dead body.

Lord Raglan's Hero Pattern lists many religious figures whose bodies disappear, or have more than one sepulchre. B. Traven, author of "The Treasure of the Sierra Madre", wrote that the Inca Virococha arrived at Cusco (in modern-day Peru) and the Pacific seacoast where he walked across the water and vanished. It has been thought that teachings regarding the purity and incorruptibility of the hero's human body are linked to this phenomenon. Perhaps, this is also to deter the practice of disturbing and collecting the hero's remains. They are safely protected if they have disappeared.

The first such case mentioned in the Bible is that of Enoch (son of Jared, great-grandfather of Noah, and father of Methuselah). Enoch is said to have lived a life where he "walked with God", after which "he was not, for God took him" (Genesis 5:1–18). In Deuteronomy (34:6) Moses is secretly buried. Elijah vanishes in a whirlwind 2 Kings (2:11). In the Synoptic Gospels, after hundreds of years these two earlier Biblical heroes suddenly reappear, and are reportedly seen walking with Jesus, then again vanish. TIn the Gospel of Luke, the last time Jesus is seen (24:51) he leaves his disciples by ascending into the sky.





</doc>
<doc id="26449" url="https://en.wikipedia.org/wiki?curid=26449" title="Resurrected">
Resurrected

Resurrected or The Resurrected may refer to:




</doc>
<doc id="26451" url="https://en.wikipedia.org/wiki?curid=26451" title="Robert Parr">
Robert Parr

Robert Ghormley Parr (September 22, 1921 – March 27, 2017) was an American theoretical chemist who was a Professor of Chemistry at the University of North Carolina at Chapel Hill.

Parr received an A. B. degree "magna cum laude" from Brown University in 1942, and then entered the University of Minnesota, receiving a Ph.D. in physical chemistry in 1947. He joined the faculty at Minnesota upon receiving his Ph.D. and remained there one year. In 1948 he moved to the Carnegie Institute of Technology (now Carnegie Mellon University) in Pittsburgh, Pennsylvania, becoming a full professor in 1957. In 1962 he moved to Johns Hopkins University in Baltimore, Maryland, and in 1974 to the University of North Carolina at Chapel Hill, where he received appointment to an endowed professorship in 1990 and where he last taught.

Working with DuPont chemist Rudolph Pariser, Parr developed a method of computing approximate molecular orbitals for pi electron systems, published in 1953. Since an identical procedure was derived by John A. Pople the same year, it is generally referred to as the Pariser–Parr–Pople method or PPP method. The PPP method differed from existing structural chemistry thinking (which advocated "maximum overlap principle") by advancing the concept of "zero differential overlap approximation".

By 1978 Parr had realized that density functional theory (DFT) would be extremely useful in quantitative calculations of chemical and biological systems, especially those with high molecular weights. In 1988 Parr, Weitao Yang and Chengteh Lee produced an improved DFT method which could approximate the correlation energy of systems. The LYP functional theory is now one of the most-often cited papers in the chemical literature.

In 1963 Parr published "Quantum Theory of Molecular Electronic Structure", one of the first books to apply quantum theory to chemical systems.

In 1989 he and Yang published "Density Functional Theory of Atoms and Molecules", now considered the basic textbook on DFT.



</doc>
<doc id="26452" url="https://en.wikipedia.org/wiki?curid=26452" title="Riesz representation theorem">
Riesz representation theorem

Riesz representation theorem, sometimes called Riesz–Fréchet representation theorem, named after Frigyes Riesz and Maurice René Fréchet, establishes an important connection between a Hilbert space and its continuous dual space. If the underlying field is the real numbers, the two are isometrically isomorphic; if the underlying field is the complex numbers, the two are isometrically anti-isomorphic. The (anti-) isomorphism is a particular natural one as will be described next; a natural isomorphism.

Let "H" be a Hilbert space, and let "H*" denote its dual space, consisting of all bounded operators from "H" into the field formula_1 or formula_2. 

If formula_3 is an element of "H", then the function formula_4 for all formula_5 in "H" defined by

formula_6

where formula_7 denotes the inner product of the Hilbert space, is an element of "H*". The Riesz representation theorem states that "every" element of "H*" can be written uniquely in this form.

Let formula_8 be a Hilbert space and formula_9. Then there exists formula_10 such that for any formula_11, formula_12. Moreover formula_13

Let formula_14. Clearly formula_15 is closed subspace of formula_8. If formula_17, then we can trivially choose formula_18. Now assume formula_19. We claim that formula_20 is one-dimensional. To see this, let formula_21 be nonzero vectors in formula_22. Then formula_23, and there must be a nonzero real number formula_24, such that formula_25. Observe that formula_26 and formula_27, so formula_28. This means that formula_29. Now let formula_30 be a unit vector in formula_22. For arbitrary formula_11, let formula_33 be the orthogonal projection of formula_3 onto formula_22. Then formula_36 and formula_37 (from the properties of orthogonal projections), so that formula_38 and formula_39. Thus formula_40. Hence formula_41. We also see formula_42. From the Cauchy-Bunyakovsky-Schwartz inequality formula_43, thus for formula_3 with unit norm formula_45. This implies that formula_46.
Given any continuous linear functional "g" in "H*", the corresponding element formula_47 can be constructed uniquely by formula_48, where formula_49 is an orthonormal basis of "H", and the value of formula_50 does not vary by choice of basis. Thus, if formula_51, then formula_52

The mapping formula_53: "H" → "H*" defined by formula_54 = formula_55 is an isometric (anti-) isomorphism, meaning that:

The inverse map of formula_53 can be described as follows. Given a non-zero element formula_69 of "H*", the orthogonal complement of the kernel of formula_69 is a one-dimensional subspace of "H". Take a non-zero element "z" in that subspace, and set formula_71. Then formula_54 = formula_69.

Historically, the theorem is often attributed simultaneously to Riesz and Fréchet in 1907 (see references).

In the mathematical treatment of quantum mechanics, the theorem can be seen as a justification for the popular bra–ket notation. The theorem says that, every bra formula_74 has a corresponding ket formula_75, and the latter is unique.



</doc>
<doc id="26455" url="https://en.wikipedia.org/wiki?curid=26455" title="Romano Scarpa">
Romano Scarpa

Romano Scarpa (September 27, 1927, Venice – April 23, 2005, Málaga) was one of the most famous Italian creators of Disney comics.

Growing up in Venice he developed a particular love for American cartoons and Disney comics, that, at the time, were published in the big format of the Topolino Giornale which was then printing now classic Floyd Gottfredson's stories. In the Forties he opened an Animation Studio in Venice in which he produced his first works: some commercials, a short titled "E poi venne il diluvio" and another one titled "La piccola fiammiferaia" (1953, based on Hans Christian Andersen's "The Little Match Girl"), distributed in Italy together with Robert Aldrich's "Attack!" (1956).

Right after that he stopped working in animation for a while and dedicated wholly to creating Disney comics. When in 1956 Italian editors had no more new Floyd Gottfredson's stories to reprint, he was given the responsibility to continue Gottfredson's stories about Mickey Mouse. Also influenced by Carl Barks in the late Fifties and up to about 1963 he wrote and penciled stories like "Topolino e la collana Chirikawa" (1960) or "The Flying Scot" (1957) that have, later, been translated in many different languages throughout the world. Many of these stories have their backgrounds in movies, for example "Topolino nel favoloso regno di Shan Grillà" (1961) is based upon Frank Capra's "Lost Horizon" (1937); not to talk about all the stories starring Snow White or the Seven Dwarfs, obviously based on "Snow White and the Seven Dwarfs" (1937). Sometimes the exact opposite happened; the Italian movie "Riusciranno i nostri eroi a ritrovare l'amico misteriosamente scomparso in Africa?" (1968) is based on Scarpa's story "Topolino e il Pippotarzan" (1957).

Around 1963, Scarpa stopped writing for 6 or 7 years. In the seventies, he moved to Spain and started working for a different publisher. Among the last things he made while he was still in Italy, at the end of the Eighties and at beginning of the Nineties, there are the so-called "Paperolimpiadi" (a long story about the 1988 Seoul Olympic games) and some strip stories, the same kind of stories that he loved when he was a child. One of these, "Topolino e l'enigma di Brigaboom" (1989) was partially based on "Brigadoon" (1954).

In the meanwhile he has had time enough for some more animation, so we have "Aihnoo degli Icebergs" (1972), "The Fourth King" (1977) and a new TV series, "The Adventures of Marco and Gina" ("Sopra i tetti di Venezia") (2001).

Mainly Scarpa worked on Disney comics, but many years ago he used to do something non-Disney once in a while, so he did one (Rolf Kauka's) "Lupo" story and one (Hannah and Barbera's) "Yogi Bear" story. In the 1950s he also drew some "Angelino" story, and Italian character.

Since 1988 some of his comic stories have been published in the US by Gladstone Publishing; it was the first time that this happened to an Italian Disney author. Later, when Disney Comics took Gladstone's place, they published some more of his stories, and in 2003, the same happened with Gemstone Publishing, that is publishing his stories in the US at the moment.

He has influenced many younger creators (Giorgio Cavazzano was his inker during the Sixties) and many have attempted to imitate his style.

In his career Scarpa created many Disney characters that are now accepted by some as part of the Disney Universe. Those include, but are not limited to:


In 2017 Fantagraphics Books published a collection containing four stories of Scarpa's Snow White comics, titled "The Return of Snow-White and the Seven Dwarfs", ISBN .

In 2018 Fantagraphics Books began publishing a hardcover series titled "Disney Masters", in which Romano Scarpa has to date (October 2019) had three volumes dedicated to his Disney works.


This is an index of all Romano Scarpa comics published in the US. Only Duck universe and Mouse universe are listed. Chip and Dale comics are not listed.




</doc>
<doc id="26458" url="https://en.wikipedia.org/wiki?curid=26458" title="Rosa Parks">
Rosa Parks

Rosa Louise McCauley Parks (February 4, 1913 – October 24, 2005) was an American activist in the civil rights movement best known for her pivotal role in the Montgomery bus boycott. The United States Congress has called her "the first lady of civil rights" and "the mother of the freedom movement".

On December 1, 1955, in Montgomery, Alabama, Parks rejected bus driver James F. Blake's order to relinquish her seat in the "colored section" to a white passenger, after the whites-only section was filled. Parks was not the first person to resist bus segregation, but the National Association for the Advancement of Colored People (NAACP) believed that she was the best candidate for seeing through a court challenge after her arrest for civil disobedience in violating Alabama segregation laws. Parks' prominence in the community and her willingness to become a controversial figure inspired the black community to boycott the Montgomery buses for over a year, the first major direct action campaign of the post-war civil rights movement. Her case became bogged down in the state courts, but the federal Montgomery bus lawsuit "Browder v. Gayle" resulted in a November 1956 decision that bus segregation is unconstitutional under the Equal Protection Clause of the 14th Amendment to the U.S. Constitution.

Parks' act of defiance and the Montgomery bus boycott became important symbols of the movement. She became an international icon of resistance to racial segregation. She organized and collaborated with civil rights leaders, including Edgar Nixon, president of the local chapter of the NAACP; and Martin Luther King Jr., a new minister in Montgomery who gained national prominence in the civil rights movement and went on to win a Nobel Peace Prize.

At the time, Parks was employed as a seamstress at a local department store and was secretary of the Montgomery chapter of the NAACP. She had recently attended the Highlander Folk School, a Tennessee center for training activists for workers' rights and racial equality. She acted as a private citizen "tired of giving in". Although widely honored in later years, she also suffered for her act; she was fired from her job, and received death threats for years afterwards.

Shortly after the boycott, she moved to Detroit, where she briefly found similar work. From 1965 to 1988, she served as secretary and receptionist to John Conyers, an African-American US Representative. She was also active in the Black Power movement and the support of political prisoners in the US.

After retirement, Parks wrote her autobiography and continued to insist that the struggle for justice was not over and there was more work to be done. In her final years, she suffered from dementia. Parks received national recognition, including the NAACP's 1979 Spingarn Medal, the Presidential Medal of Freedom, the Congressional Gold Medal, and a posthumous statue in the United States Capitol's National Statuary Hall. Upon her death in 2005, she was the first woman to lie in honor in the Capitol Rotunda, becoming the thirty-first person to receive this honor. California and Missouri commemorate Rosa Parks Day on her birthday, February 4, while Ohio and Oregon commemorate the occasion on the anniversary of the day she was arrested, December 1.

Rosa Parks was born Rosa Louise McCauley in Tuskegee, Alabama, on February 4, 1913, to Leona (née Edwards), a teacher, and James McCauley, a carpenter. In addition to African ancestry, one of Parks' great-grandfathers was Scots-Irish and one of her great-grandmothers a part-Native American slave. She was small as a child and suffered poor health with chronic tonsillitis. When her parents separated, she moved with her mother to Pine Level, just outside the state capital, Montgomery. She grew up on a farm with her maternal grandparents, mother, and younger brother Sylvester. They all were members of the African Methodist Episcopal Church (AME), a century-old independent black denomination founded by free blacks in Philadelphia, Pennsylvania, in the early nineteenth century.

McCauley attended rural schools until the age of eleven. As a student at the Industrial School for Girls in Montgomery, she took academic and vocational courses. Parks went on to a laboratory school set up by the Alabama State Teachers College for Negroes for secondary education, but dropped out in order to care for her grandmother and later her mother, after they became ill.

Around the turn of the 20th century, the former Confederate states had adopted new constitutions and electoral laws that effectively disenfranchised black voters and, in Alabama, many poor white voters as well. Under the white-established Jim Crow laws, passed after Democrats regained control of southern legislatures, racial segregation was imposed in public facilities and retail stores in the South, including public transportation. Bus and train companies enforced seating policies with separate sections for blacks and whites. School bus transportation was unavailable in any form for black schoolchildren in the South, and black education was always underfunded.

Parks recalled going to elementary school in Pine Level, where school buses took white students to their new school and black students had to walk to theirs:

I'd see the bus pass every day ... But to me, that was a way of life; we had no choice but to accept what was the custom. The bus was among the first ways I realized there was a black world and a white world.

Although Parks' autobiography recounts early memories of the kindness of white strangers, she could not ignore the racism of her society. When the Ku Klux Klan marched down the street in front of their house, Parks recalls her grandfather guarding the front door with a shotgun. The Montgomery Industrial School, founded and staffed by white northerners for black children, was burned twice by arsonists. Its faculty was ostracized by the white community.

Repeatedly bullied by white children in her neighborhood, Parks often fought back physically. She later said: "As far back as I remember, I could never think in terms of accepting physical abuse without some form of retaliation if possible."

In 1932, Rosa married Raymond Parks, a barber from Montgomery. He was a member of the NAACP, which at the time was collecting money to support the defense of the Scottsboro Boys, a group of black men falsely accused of raping two white women. Rosa took numerous jobs, ranging from domestic worker to hospital aide. At her husband's urging, she finished her high school studies in 1933, at a time when less than 7% of African Americans had a high-school diploma.

In December 1943, Parks became active in the civil rights movement, joined the Montgomery chapter of the NAACP, and was elected secretary at a time when this was considered a woman's job. She later said, "I was the only woman there, and they needed a secretary, and I was too timid to say no." She continued as secretary until 1957. She worked for the local NAACP leader Edgar Nixon, even though he maintained that "Women don't need to be nowhere but in the kitchen." When Parks asked, "Well, what about me?", he replied: "I need a secretary and you are a good one."

In 1944, in her capacity as secretary, she investigated the gang-rape of Recy Taylor, a black woman from Abbeville, Alabama. Parks and other civil rights activists organized "The Committee for Equal Justice for Mrs. Recy Taylor", launching what the "Chicago Defender" called "the strongest campaign for equal justice to be seen in a decade."

Although never a member of the Communist Party, she attended meetings with her husband. The notorious Scottsboro case had been brought to prominence by the Communist Party.

In the 1940s, Parks and her husband were members of the League of Women Voters. Sometime soon after 1944, she held a brief job at Maxwell Air Force Base, which, despite its location in Montgomery, Alabama, did not permit racial segregation because it was federal property. She rode on its integrated trolley. Speaking to her biographer, Parks noted, "You might just say Maxwell opened my eyes up." Parks worked as a housekeeper and seamstress for Clifford and Virginia Durr, a white couple. Politically liberal, the Durrs became her friends. They encouraged—and eventually helped sponsor—Parks in the summer of 1955 to attend the Highlander Folk School, an education center for activism in workers' rights and racial equality in Monteagle, Tennessee. There Parks was mentored by the veteran organizer Septima Clark. In 1945, despite the Jim Crow laws and discrimination by registrars, she succeeded in registering to vote on her third try.

In August 1955, black teenager Emmett Till was brutally murdered after reportedly flirting with a young white woman while visiting relatives in Mississippi. On November 27, 1955, four days before she would make her stand on the bus, Rosa Parks attended a mass meeting at Dexter Avenue Baptist Church in Montgomery that addressed this case, as well as the recent murders of the activists George W. Lee and Lamar Smith. The featured speaker was T. R. M. Howard, a black civil rights leader from Mississippi who headed the Regional Council of Negro Leadership. Howard brought news of the recent acquittal of the two men who had murdered Till. Parks was deeply saddened and angry at the news, particularly because Till's case had garnered much more attention than any of the cases she and the Montgomery NAACP had worked on—and yet, the two men still walked free.

In 1900, Montgomery had passed a city ordinance to segregate bus passengers by race. Conductors were empowered to assign seats to achieve that goal. According to the law, no passenger would be required to move or give up their seat and stand if the bus was crowded and no other seats were available. Over time and by custom, however, Montgomery bus drivers adopted the practice of requiring black riders to move when there were no white-only seats left.

The first four rows of seats on each Montgomery bus were reserved for whites. Buses had "colored" sections for black people generally in the rear of the bus, although blacks composed more than 75% of the ridership. The sections were not fixed but were determined by placement of a movable sign. Black people could sit in the middle rows until the white section filled; if more whites needed seats, blacks were to move to seats in the rear, stand, or, if there was no room, leave the bus. Black people could not sit across the aisle in the same row as white people. The driver could move the "colored" section sign, or remove it altogether. If white people were already sitting in the front, black people had to board at the front to pay the fare, then disembark and reenter through the rear door.

For years, the black community had complained that the situation was unfair. Parks said, "My resisting being mistreated on the bus did not begin with that particular arrest. I did a lot of walking in Montgomery."

One day in 1943, Parks boarded a bus and paid the fare. She then moved to a seat, but driver James F. Blake told her to follow city rules and enter the bus again from the back door. When Parks exited the vehicle, Blake drove off without her. Parks waited for the next bus, determined never to ride with Blake again.

After working all day, Parks boarded the Cleveland Avenue bus, a General Motors Old Look bus belonging to the Montgomery City Lines, around 6 p.m., Thursday, December 1, 1955, in downtown Montgomery. She paid her fare and sat in an empty seat in the first row of back seats reserved for blacks in the "colored" section. Near the middle of the bus, her row was directly behind the ten seats reserved for white passengers. Initially, she did not notice that the bus driver was the same man, James F. Blake, who had left her in the rain in 1943. As the bus traveled along its regular route, all of the white-only seats in the bus filled up. The bus reached the third stop in front of the Empire Theater, and several white passengers boarded. Blake noted that two or three white passengers were standing, as the front of the bus had filled to capacity. He moved the "colored" section sign behind Parks and demanded that four black people give up their seats in the middle section so that the white passengers could sit. Years later, in recalling the events of the day, Parks said, "When that white driver stepped back toward us, when he waved his hand and ordered us up and out of our seats, I felt a determination cover my body like a quilt on a winter night."

By Parks' account, Blake said, "Y'all better make it light on yourselves and let me have those seats." Three of them complied. Parks said, "The driver wanted us to stand up, the four of us. We didn't move at the beginning, but he says, 'Let me have these seats.' And the other three people moved, but I didn't." The black man sitting next to her gave up his seat.

Parks moved, but toward the window seat; she did not get up to move to the redesignated colored section. Parks later said about being asked to move to the rear of the bus, "I thought of Emmett Till – a 14-year-old African American who was lynched in Mississippi in 1955, after being accused of offending a white woman in her family's grocery store, whose killers were tried and acquitted – and I just couldn't go back." Blake said, "Why don't you stand up?" Parks responded, "I don't think I should have to stand up." Blake called the police to arrest Parks. When recalling the incident for "Eyes on the Prize", a 1987 public television series on the Civil Rights Movement, Parks said, "When he saw me still sitting, he asked if I was going to stand up, and I said, 'No, I'm not.' And he said, 'Well, if you don't stand up, I'm going to have to call the police and have you arrested.' I said, 'You may do that.'"

During a 1956 radio interview with Sydney Rogers in West Oakland several months after her arrest, Parks said she had decided, "I would have to know for once and for all what rights I had as a human being and a citizen."

In her autobiography, "My Story", she said:
When Parks refused to give up her seat, a police officer arrested her. As the officer took her away, she recalled that she asked, "Why do you push us around?" She remembered him saying, "I don't know, but the law's the law, and you're under arrest." She later said, "I only knew that, as I was being arrested, that it was the very last time that I would ever ride in humiliation of this kind. ... "

Parks was charged with a violation of Chapter 6, Section 11 segregation law of the Montgomery City code, although technically she had not taken a white-only seat; she had been in a colored section. Edgar Nixon, president of the Montgomery chapter of the NAACP and leader of the Pullman Porters Union, and her friend Clifford Durr bailed Parks out of jail that evening.

Parks did not originate the idea of protesting segregation with a bus sit-in. Those preceding her included Bayard Rustin in 1942, Irene Morgan in 1946, Lillie Mae Bradford in 1951, Sarah Louise Keys in 1952, and the members of the ultimately successful "Browder v. Gayle" 1956 lawsuit (Claudette Colvin, Aurelia Browder, Susie McDonald, and Mary Louise Smith) who were arrested in Montgomery for not giving up their bus seats months before Parks.

Nixon conferred with Jo Ann Robinson, an Alabama State College professor and member of the Women's Political Council (WPC), about the Parks case. Robinson believed it important to seize the opportunity and stayed up all night mimeographing over 35,000 handbills announcing a bus boycott. The Women's Political Council was the first group to officially endorse the boycott.

On Sunday, December 4, 1955, plans for the Montgomery bus boycott were announced at black churches in the area, and a front-page article in the "Montgomery Advertiser" helped spread the word. At a church rally that night, those attending agreed unanimously to continue the boycott until they were treated with the level of courtesy they expected, until black drivers were hired, and until seating in the middle of the bus was handled on a first-come basis.

The next day, Parks was tried on charges of disorderly conduct and violating a local ordinance. The trial lasted 30 minutes. After being found guilty and fined $10, plus $4 in court costs (combined total ), Parks appealed her conviction and formally challenged the legality of racial segregation. In a 1992 interview with National Public Radio's Lynn Neary, Parks recalled:

On the day of Parks' trial—December 5, 1955—the WPC distributed the 35,000 leaflets. The handbill read,

We are ... asking every Negro to stay off the buses Monday in protest of the arrest and trial ... You can afford to stay out of school for one day. If you work, take a cab, or walk. But please, children and grown-ups, don't ride the bus at all on Monday. Please stay off the buses Monday.

It rained that day, but the black community persevered in their boycott. Some rode in carpools, while others traveled in black-operated cabs that charged the same fare as the bus, 10 cents (). Most of the remainder of the 40,000 black commuters walked, some as far as .

That evening after the success of the one-day boycott, a group of 16 to 18 people gathered at the Mt. Zion AME Zion Church to discuss boycott strategies. At that time, Parks was introduced but not asked to speak, despite a standing ovation and calls from the crowd for her to speak; when she asked if she should say something, the reply was, "Why, you've said enough."

The group agreed that a new organization was needed to lead the boycott effort if it were to continue. Rev. Ralph Abernathy suggested the name "Montgomery Improvement Association" (MIA). The name was adopted, and the MIA was formed. Its members elected as their president Martin Luther King Jr., a relative newcomer to Montgomery, who was a young and mostly unknown minister of the Dexter Avenue Baptist Church.

That Monday night, 50 leaders of the African-American community gathered to discuss actions to respond to Parks' arrest. Edgar Nixon, the president of the NAACP, said, "My God, look what segregation has put in my hands!" Parks was considered the ideal plaintiff for a test case against city and state segregation laws, as she was seen as a responsible, mature woman with a good reputation. She was securely married and employed, was regarded as possessing a quiet and dignified demeanor, and was politically savvy. King said that Parks was regarded as "one of the finest citizens of Montgomery—not one of the finest Negro citizens, but one of the finest citizens of Montgomery."

Parks' court case was being slowed down in appeals through the Alabama courts on their way to a Federal appeal and the process could have taken years. Holding together a boycott for that length of time would have been a great strain. In the end, black residents of Montgomery continued the boycott for 381 days. Dozens of public buses stood idle for months, severely damaging the bus transit company's finances, until the city repealed its law requiring segregation on public buses following the US Supreme Court ruling in "Browder v. Gayle" that it was unconstitutional. Parks was not included as a plaintiff in the Browder decision because the attorney Fred Gray concluded the courts would perceive they were attempting to circumvent her prosecution on her charges working their way through the Alabama state court system.

Parks played an important part in raising international awareness of the plight of African Americans and the civil rights struggle. King wrote in his 1958 book "Stride Toward Freedom" that Parks' arrest was the catalyst rather than the cause of the protest: "The cause lay deep in the record of similar injustices." He wrote, "Actually, no one can understand the action of Mrs. Parks unless he realizes that eventually the cup of endurance runs over, and the human personality cries out, 'I can take it no longer.'"

After her arrest, Parks became an icon of the Civil Rights Movement but suffered hardships as a result. Due to economic sanctions used against activists, she lost her job at the department store. Her husband quit his job after his boss forbade him to talk about his wife or the legal case. Parks traveled and spoke extensively about the issues.

In 1957, Raymond and Rosa Parks left Montgomery for Hampton, Virginia; mostly because she was unable to find work. She also disagreed with King and other leaders of Montgomery's struggling civil rights movement about how to proceed, and was constantly receiving death threats. In Hampton, she found a job as a hostess in an inn at Hampton Institute, a historically black college.

Later that year, at the urging of her brother and sister-in-law in Detroit, Sylvester and Daisy McCauley, Rosa and Raymond Parks and her mother moved north to join them. The City of Detroit attempted to cultivate a progressive reputation, but Parks encountered numerous signs of discrimination against African-Americans. Schools were effectively segregated, and services in black neighborhoods substandard. In 1964, Parks told an interviewer that, "I don't feel a great deal of difference here ... Housing segregation is just as bad, and it seems more noticeable in the larger cities." She regularly participated in the movement for open and fair housing.

Parks rendered crucial assistance in the first campaign for Congress by John Conyers. She persuaded Martin Luther King (who was generally reluctant to endorse local candidates) to appear with Conyers, thereby boosting the novice candidate's profile. When Conyers was elected, he hired her as a secretary and receptionist for his congressional office in Detroit. She held this position until she retired in 1988. In a telephone interview with CNN on October 24, 2005, Conyers recalled, "You treated her with deference because she was so quiet, so serene—just a very special person ... There was only one Rosa Parks." Doing much of the daily constituent work for Conyers, Parks often focused on socio-economic issues including welfare, education, job discrimination, and affordable housing. She visited schools, hospitals, senior citizen facilities, and other community meetings and kept Conyers grounded in community concerns and activism.

Parks participated in activism nationally during the mid-1960s, traveling to support the Selma-to-Montgomery Marches, the Freedom Now Party, and the Lowndes County Freedom Organization. She also befriended Malcolm X, who she regarded as a personal hero.

Like many Detroit blacks, Parks remained particularly concerned about housing issues. She herself lived in a neighborhood, Virginia Park, which had been compromised by highway construction and urban renewal. By 1962, these policies had destroyed 10,000 structures in Detroit, displacing 43,096 people, 70 percent of them African-American. Parks lived just a mile from the center of the riot that took place in Detroit in 1967, and she considered housing discrimination a major factor that provoked the disorder.

In the aftermath Parks collaborated with members of the League of Revolutionary Black Workers and the Republic of New Afrika in raising awareness of police abuse during the conflict. She served on a "people's tribunal" on August 30, 1967, investigating the killing of three young men by police during the 1967 Detroit uprising, in what came to be known as the Algiers Motel incident. She also helped form the Virginia Park district council to help rebuild the area. The council facilitated the building of the only black-owned shopping center in the country. Parks took part in the black power movement, attending the Philadelphia Black Power conference, and the Black Political Convention in Gary, Indiana. She also supported and visited the Black Panther school in Oakland.

In the 1970s, Parks organized for the freedom of political prisoners in the United States, particularly cases involving issues of self-defense. She helped found the Detroit chapter of the Joann Little Defense Committee, and also worked in support of the Wilmington 10, the RNA 11, and Gary Tyler. Following national outcry around her case, Little succeeded in her defense that she used deadly force to resist sexual assault and was acquitted. Gary Tyler was finally released in April 2016 after 41 years in prison.

The 1970s were a decade of loss for Parks in her personal life. Her family was plagued with illness; she and her husband had suffered stomach ulcers for years and both required hospitalization. In spite of her fame and constant speaking engagements, Parks was not a wealthy woman. She donated most of the money from speaking to civil rights causes, and lived on her staff salary and her husband's pension. Medical bills and time missed from work caused financial strain that required her to accept assistance from church groups and admirers.

Her husband died of throat cancer on August 19, 1977, and her brother, her only sibling, died of cancer that November. Her personal ordeals caused her to become removed from the civil rights movement. She learned from a newspaper of the death of Fannie Lou Hamer, once a close friend. Parks suffered two broken bones in a fall on an icy sidewalk, an injury which caused considerable and recurring pain. She decided to move with her mother into an apartment for senior citizens. There she nursed her mother Leona through the final stages of cancer and geriatric dementia until she died in 1979 at the age of 92.

In 1980, Parks—widowed and without immediate family—rededicated herself to civil rights and educational organizations. She co-founded the Rosa L. Parks Scholarship Foundation for college-bound high school seniors, to which she donated most of her speaker fees. In February 1987, she co-founded, with Elaine Eason Steele, the Rosa and Raymond Parks Institute for Self Development, an institute that runs the "Pathways to Freedom" bus tours which introduce young people to important civil rights and Underground Railroad sites throughout the country. Parks also served on the Board of Advocates of Planned Parenthood. Though her health declined as she entered her seventies, Parks continued to make many appearances and devoted considerable energy to these causes.

In 1992, Parks published "Rosa Parks: My Story", an autobiography aimed at younger readers, which recounts her life leading to her decision to keep her seat on the bus. A few years later, she published "Quiet Strength" (1995), her memoir, which focuses on her faith.

At age 81, Parks was robbed and assaulted in her home in central Detroit on August 30, 1994. The assailant, Joseph Skipper, broke down the door but claimed he had chased away an intruder. He requested a reward and when Parks paid him, he demanded more. Parks refused and he attacked her. Hurt and badly shaken, Parks called a friend, who called the police. A neighborhood manhunt led to Skipper's capture and reported beating. Parks was treated at Detroit Receiving Hospital for facial injuries and swelling on the right side of her face. Parks said about the attack on her by the African-American man, "Many gains have been made ... But as you can see, at this time we still have a long way to go." Skipper was sentenced to 8 to 15 years and was transferred to prison in another state for his own safety.

Suffering anxiety upon returning to her small central Detroit house following the ordeal, Parks moved into Riverfront Towers, a secure high-rise apartment building. Learning of Parks' move, Little Caesars owner Mike Ilitch offered to pay for her housing expenses for as long as necessary.

In 1994, the Ku Klux Klan applied to sponsor a portion of United States Interstate 55 in St. Louis County and Jefferson County, Missouri, near St. Louis, for cleanup (which allowed them to have signs stating that this section of highway was maintained by the organization). Since the state could not refuse the KKK's sponsorship, the Missouri legislature voted to name the highway section the "Rosa Parks Highway". When asked how she felt about this honor, she is reported to have commented, "It is always nice to be thought of."

In 1999, Parks filmed a cameo appearance for the television series "Touched by an Angel". It was her last appearance on film; Parks began to suffer from health problems due to old age.

In 2002, Parks received an eviction notice from her $1,800 per month () apartment for non-payment of rent. Parks was incapable of managing her own financial affairs by this time due to age-related physical and mental decline. Her rent was paid from a collection taken by Hartford Memorial Baptist Church in Detroit. When her rent became delinquent and her impending eviction was highly publicized in 2004, executives of the ownership company announced they had forgiven the back rent and would allow Parks, by then 91 and in extremely poor health, to live rent-free in the building for the remainder of her life. Elaine Steele, manager of the nonprofit Rosa and Raymond Parks Institute, told the newspaper that Parks got proper care, and that eviction notices were sent in error in 2002. Her heirs and various interest organizations alleged at the time that her financial affairs had been mismanaged.

In 2016, Parks's former residence in Detroit was threatened with demolition. A Berlin-based American artist, Ryan Mendoza, arranged to have the house disassembled, moved to his garden in Germany, and partly restored. It served as a museum honoring Rosa Parks. In 2018, the house was moved back to the USA. Brown University was planning to exhibit the house, but the display was cancelled. The house was exhibited during part of 2018 in an arts centre in Providence, Rhode Island. 

Parks died of natural causes on October 24, 2005, at the age of 92, in her apartment on the east side of Detroit. She and her husband never had children and she outlived her only sibling. She was survived by her sister-in-law (Raymond's sister), 13 nieces and nephews and their families, and several cousins, most of them residents of Michigan or Alabama.

City officials in Montgomery and Detroit announced on October 27, 2005, that the front seats of their city buses would be reserved with black ribbons in honor of Parks until her funeral. Parks' coffin was flown to Montgomery and taken in a horse-drawn hearse to the St. Paul African Methodist Episcopal (AME) church, where she lay in repose at the altar on October 29, 2005, dressed in the uniform of a church deaconess. A memorial service was held there the following morning. One of the speakers, United States Secretary of State Condoleezza Rice, said that if it had not been for Parks, she would probably have never become the Secretary of State. In the evening the casket was transported to Washington, D.C. and transported by a bus similar to the one in which she made her protest, to lie in honor in the rotunda of the U.S. Capitol.

Since the founding of the practice in 1852, Parks was the 31st person, the first American who had not been a U.S. government official, and the second private person (after the French planner Pierre L'Enfant) to be honored in this way. She was the first woman and the second black person to lie in honor in the Capitol. An estimated 50,000 people viewed the casket there, and the event was broadcast on television on October 31, 2005. A memorial service was held that afternoon at Metropolitan AME Church in Washington, D.C.

With her body and casket returned to Detroit, for two days, Parks lay in repose at the Charles H. Wright Museum of African American History. Her funeral service was seven hours long and was held on November 2, 2005, at the Greater Grace Temple Church in Detroit. After the service, an honor guard from the Michigan National Guard laid the U.S. flag over the casket and carried it to a horse-drawn hearse, which was intended to carry it, in daylight, to the cemetery. As the hearse passed the thousands of people who were viewing the procession, many clapped, cheered loudly and released white balloons. Parks was interred between her husband and mother at Detroit's Woodlawn Cemetery in the chapel's mausoleum. The chapel was renamed the Rosa L. Parks Freedom Chapel in her honor. Parks had previously prepared and placed a headstone on the selected location with the inscription "Rosa L. Parks, wife, 1913–".







Multimedia and interviews

Others


</doc>
<doc id="26459" url="https://en.wikipedia.org/wiki?curid=26459" title="Ringworld (role-playing game)">
Ringworld (role-playing game)

The Ringworld science fiction role-playing game was published by Chaosium in 1984, using the Basic Role-Playing system for its rules and Larry Niven's "Ringworld" novels as a setting.

The setting is a distant future based on extrapolation of as much hard science as Niven had available. Specifically, it's the 29th century. "Known Space" (also the commonly used title for Larry Niven's future history science fiction series) is about 80 light years in diameter with 10,000 stars, including Human Space (40 light years diameter, 524 stars in 357 systems, 30 billion humans, ⅔ on Earth), as well as neighbouring Alien civilisations. Important Alien civilisations include the Puppeteers, paranoid pacifist herbivore centaurs, and the Kzinti, carnivorous warlike felines, who fought multiple wars over hundreds of years against the Humans, being defeated each time. Human allies include intelligent dolphins and orcas.

"Known Space" only serves as a background for the game. The game is intended to be set on the Ringworld itself, an enormous single world discovered at the far reaches of Known Space, a ring around a sun at approximately the orbit of the Earth. It is 997,000 miles wide, about 125 Earth-diameters. The total inner surface of the ring is equal to that of 3 million Earths. The ring is spun at a speed to provide 0.992G of gravity on the innerside, while 20 giant shadow squares at about the orbit of Mercury occlude the Sun to provide night. It was constructed by the Pak Protectors, now mostly extinct, who had a common origin with humans. The Ringworld is home to some 30 trillion sentient inhabitants from up to 2000 hominid species. The world is described in a series of novels by Niven, "Ringworld", "The Ringworld Engineers", and, after the game's publication, "The Ringworld Throne" and "Ringworld's Children".

The role-playing game contains a great deal of technical details about the setting, more than the fiction the setting is based on. The game setting details are complete enough that some "Ringworld" fans not interested in role-playing buy the game just for the background material.

Information from the RPG, along with notes composed by RPG author Hewitt with Niven, were later used to form the "Bible" given to authors writing in the "Man-Kzin Wars" series. Niven himself recommended that Hewitt write one of the stories for the original two MKW books, although this never came to pass.

The players initially play explorers from Known Space, sent as scouts to the Ringworld. They can be anthropologists, artists, doctors, police, or even zealots, who will explore the mysteries of this huge artificial world and its inhabitants. Basic characters can be humans from a dozen planets of Human Space, Puppeteers, or Kzin. Later play can see characters from Ringworld species, such as the (so-called) Ghouls, Vampires, Giants, Sea People, and others.

This Ringworld focus has been a criticism of the game. The "Ringworld" role-playing game is not a 'full' science fiction RPG, like "Traveller", including, for example, rules for starship construction, space combat, travel to different planets and systems, and so forth. Instead, the game and rules focused on parties of characters exploring the Ringworld itself, and, despite its vast size (with a surface area larger than that of all of Known Space's inhabited planets put together), many who bought the game felt limited by this one world setting.

A character is initially defined by his species or world of origin, which affects characteristics (for example, by determining the gravity to which it is accustomed). Then the players roll randomly for a certain number of defects, character age, and characteristics. The system used is Chaosium's Basic Role-Playing, with eight basic characteristics: Strength, Constitution, Mass (equivalent to Size in other BRP games), Intelligence, Power, Dexterity, Appearance and Education determining secondary attributes such damage modifiers, hit points, and skill rolls.

At creation, each character gets to spend a number of points (based mainly on age, Education, and Intelligence) on skills determined by interests or career choice. Each of the three playable races has specific tables for the creation of characters. Character Skills are based on percentages. To succeed in a skill, the player must roll under the relevant skill with modifiers on percentile dice.

Another critique of the game system has been the large effect of character age on skills, usually considered the most important character attributes. In Niven's future world, the deterioration of age has been largely reversed, so humans live hundreds of years. Therefore, a 200-year-old character will have vastly more skill points than a 20-year-old, with little compensatory advantages for the younger one.

Only two publications were published, the "Ringworld" role-playing game box set itself, and the "Ringworld Companion", both in 1984 by Chaosium. The magazine "Different Worlds", issue 37, featured a "Ringworld" adventure, "Louis Wu & His Motley Crew." The article "The Dolphins of Known Space: A new race for the Ringworld Game" appeared in "Dragon Magazine" issue 95.

The "Ringworld" role-playing game box set was titled "Larry Niven's Ringworld: Roleplaying Adventure Beneath the Great Arch", referring to the way the Ringworld looked from its interior surface. The authors are credited as Greg Stafford, John Hewitt, Sherman Kahn, Lynn Willis, Sandy Petersen, Rudy Kraft, Charlie Krank, Ed Gore, and Jeff Okamoto. It came in a box set with four books: the Explorer Book, Technology Book, Gamemasters Book, and Creatures Book, a sheet of cardboard miniatures, reference and character sheets, and a set of dice: 2d20 (actually dice with two sets of digits 0 to 9), 1d8, and 2d6.

This book begins with a character sheet. It introduces role-playing games, then covers character creation, skill use, and combat. It presents a detailed history of humanity between the 20th and 29th centuries. It then describes eleven human worlds: Belt (the asteroid belt), Canyon, Down, Gummidgy, Home, Jinx, Margrave, Plateau, Silvereyes, "We Made It" and Wunderland. Finally, it gives rules for non-human, Kzin or Puppeteer, player characters, and a glossary.

The Gamemaster Book begins with technical essays on the Ringworld, from physical construction, to life on the ring, with diagrams. There is a section on the "City Builders"—a Ringworld race that dominated the Ringworld, built floating cities, and sent spaceships to explore other worlds, until a mysterious technological virus destroyed their empire. Another section lists unanswered questions about the Ringworld. There are suggestions for creating scenarios and campaigns, and information on technology of various humanoid species of the Ringworld, and additional rules, including gravity, Credit Rating, and psionics. There is also an introductory scenario ("The Journey of the Catseye") intended to begin a Ringworld campaign. The characters are hired by Captain Gregor Lopez, famous explorer, for a journey to the Ringworld that does not go completely as planned.

The Technology Book gives rules and descriptions of the equipment employed by the explorers of the 29th century, categorized into generators, computers, medical equipment, tools, vehicles, weapons and defenses.

The Creature Book gives rules and descriptions for creatures, divided into Aliens, Humanoids, Animals and Plants. Many races get specialized hit location tables, characteristic maxima and minima, skills and traits.

This supplement was published not long after the box set. The authors are credited as Greg Stafford, John Hewitt, Sherman Kahn, Lynn Willis, Sandy Petersen, Rudy Kraft, and Charlie Krank.

The book starts with a diagram of the Ringworld and its star, EC-1752, new humanoids, aliens, plants and animals, technological objects, and original errata. There is some information on spaceships (Human and City Builder), hyperspace, a map of Human Space, and statistics for vehicles used on the Ringworld. Then there is a new race, the "Agamans", desert nomads, and a scenario involving them, "The Sand Eaters". Finally, there is a three part scenario named "The Kaladians", about the defense of travelling merchants. Both scenarios can be integrated into the campaign given in the basic set. None of these three additional races appear in any of the "Ringworld" novels.

Phil Masters reviewed "Ringworld" for "White Dwarf" #59, giving it an overall rating of 6 out of 10, and stated that "This game takes a superb background idea, applies a good system of mechanics to it, and comes back with a disappointing result."

Steve Peterson reviewed "Ringworld" in "Space Gamer" No. 71. Peterson commented that "Niven fans should buy it for the essays and background materials. Role-players should be prepared to do some work on scenarios; but if you do, you'll have some terrific roleplaying in a beautifully detailed world. Science-fiction gamers who want to use it for source material probably won't get their money's worth."

Steve Nutt reviewed "Ringworld" for "Imagine" magazine, and stated that "Altogether, Ringworld's advantages and disadvantages stem from its campaign setting. The actual mechanics of the game are top quality, yet background and atmosphere are what make or break a campaign, and in Ringworld this aspect could be somewhat daunting to the uninitiated."




</doc>
<doc id="26461" url="https://en.wikipedia.org/wiki?curid=26461" title="Risus">
Risus

Risus: The Anything RPG is a rules-light generic role-playing game (RPG) written, designed and illustrated by S. John Ross of Cumberland Games and Diversions. "Risus" is available free on the web. It was first published online in 1993. Earlier versions of the game were titled GUCS: The Generic Universal Comedy System (a parody of "GURPS") and were distributed privately beginning in 1989.

"Risus" (Latin for “laughter”) is a comedy game (often described by its creator as a "joke game") and uses a cliché (character class) system inspired by the broad "career scale" skills in Greg Gorden's "DC Heroes RPG" (Mayfair Games), and later influenced by Atlas Games' "Over the Edge". The core systems of "Risus" owe their largest debt to the "Ghostbusters RPG" published by West End Games, and to "Tunnels and Trolls" by Ken St. Andre. The game itself also cites "GURPS" as an influence, along with "FUDGE", another free RPG released to the web a year earlier. Several more recent games have been, in turn, influenced by "Risus."

Despite the game's small size and admittedly joking nature, there are more than 30 fan-authored websites devoted to "Risus," some including several rules variants, simple worldbooks, and wholly rewritten adaptations of the game. "Risus" itself has been translated into Chinese, Croatian, Czech, Danish, Dutch, Esperanto, French, German, Italian, Japanese, Korean, Norwegian, Polish, Portuguese, Russian, and Spanish. In December, 2003, Cumberland Games began to support the free game with commercial supplements, beginning with the "Risus Companion" and the founding of the International Order of Risus. An example of another commercial product is "A Kringle in Time", "an adventure about saving Christmas from ancient evil."

"New Risus" won the 2001 inaugural RPGnet award for "Best Free RPG".

"The Risus Companion" is the first commercial supplement of "Risus". S. John Ross wrote and published the "Risus Companion" on the 10th anniversary of "Risus" on the World Wide Web, in order to provide a foundation for "Risus" as a commercial venture. "Risus" itself remains free of charge, allowing "Risus" fans the option to support "Risus" if they choose and be materially rewarded for doing so. The "Risus Companion" is an electronic document in PDF form, made available to all members of the International Order of Risus.

The International Order of Risus is the official fan club of "Risus". The Order is, according to their own charter, dedicated to promoting "Risus" and to "imposing our iron will upon an unsuspecting universe."



</doc>
<doc id="26463" url="https://en.wikipedia.org/wiki?curid=26463" title="Rigel">
Rigel

Rigel , designated β Orionis (Latinized to Beta Orionis, abbreviated Beta Ori, β Ori), is a blue supergiant star in the constellation of Orion, approximately from Earth. Rigel is the brightest and most massive component—and the eponym—of a star system of at least four stars that appear as a single blue-white point of light to the naked eye. A
star of spectral type B8Ia, Rigel is calculated to be anywhere from 61,500 to 363,000 times as luminous as the Sun, and 18 to 24 times as massive, depending on the method and assumptions used. Its radius is over 70 times that of the Sun, and its surface temperature is . Rigel's mass-loss due to its stellar wind is estimated to be 10 million times more than that of the Sun. With an estimated age of 7 to 9 million years, Rigel has exhausted its core hydrogen fuel, expanded and cooled to become a supergiant. It will end its life as a type II supernova.

Rigel varies slightly in brightness, its apparent magnitude ranging from 0.05 to 0.18. It is classified as an Alpha Cygni variable due to the amplitude and periodicity of its brightness variation, as well as its spectral type. Its intrinsic variability is caused by pulsations in its unstable atmosphere. Rigel is generally the seventh-brightest star in the night sky and the brightest star in Orion, though it is occasionally outshone by Betelgeuse, which varies over a larger range.

A triple-star system is separated from Rigel by . It has an apparent magnitude of 6.7, making it 1/400th as bright as Rigel. Two stars in the system can be resolved by large telescopes, and the brighter of the two is a spectroscopic binary. These three stars are all blue-white main sequence stars, each three to four times as massive as the Sun. Rigel and the triple system orbit a common center of gravity with a period estimated to be 24,000 years. The inner stars of the triple system orbit each other every 10 days, and the outer star orbits the inner pair every 63 years. A much fainter star, separated from Rigel and the others by nearly an arc minute, may be part of the same star system.

In 2016, the International Astronomical Union (IAU) included the name "Rigel" in the IAU Catalog of Star Names. According to the IAU, this proper name applies only to the primary component A of the Rigel system. In historical astronomical catalogs, the system is listed variously as H II 33, Σ 668, β 555, or ADS 3823. For simplicity, Rigel's companions are referred to as Rigel B, C, and D; the IAU describes such names as "useful nicknames" that are "unofficial". In modern comprehensive catalogs, the whole multiple star system is known as WDS 05145-0812 or CCDM 05145–0812. 

The designation of Rigel as β Orionis (Latinized to Beta Orionis) was made by Johann Bayer in 1603. The "beta" designation is commonly given to the second-brightest star in each constellation, but Rigel is almost always brighter than α Orionis (Betelgeuse). Astronomer James B. Kaler has speculated that Rigel was designated by Bayer during a rare period when it was outshone by the variable star Betelgeuse, resulting in the latter star being designated "alpha" and Rigel designated "beta". Bayer did not strictly order the stars by brightness, instead grouping them by magnitude. Rigel and Betelgeuse were both considered to be of the first magnitude class, and in Orion the stars of each class are thought to have been ordered north to south. Rigel is included in the General Catalogue of Variable Stars, but since it already has a Bayer designation it has no separate variable star designation.

Rigel has many other stellar designations taken from various catalogs, including the Flamsteed designation 19 Orionis (19 Ori), the Bright Star Catalogue entry HR 1713, and the Henry Draper Catalogue number HD 34085. These designations frequently appear in the scientific literature, but rarely in popular writing.

Rigel is an intrinsic variable star with an apparent magnitude ranging from 0.05 to 0.18. It is typically the seventh-brightest star in the celestial sphere, excluding the Sun, although occasionally fainter than Betelgeuse. It is fainter than Capella, which may also vary slightly in brightness. Rigel appears slightly blue-white and has a B-V color index of −0.06. It contrasts strongly with reddish Betelgeuse.

Culminating every year at midnight on 12 December, and at 9 pm on 24 January, Rigel is visible on winter evenings in the Northern Hemisphere and on summer evenings in the Southern Hemisphere. In the Southern Hemisphere, Rigel is the first bright star of Orion visible as the constellation rises. The star is a vertex of the "Winter Hexagon", an asterism that includes Aldebaran, Capella, Pollux, Procyon, and Sirius. Rigel is a prominent equatorial navigation star, being easily located and readily visible in all the world's oceans (the exception is the area north of the 82nd parallel north).

Rigel's spectral type is a defining point of the classification sequence for supergiants. The overall spectrum is typical for a late B class star, with strong absorption lines of the hydrogen Balmer series as well as neutral helium lines and some of heavier elements such as oxygen, calcium, and magnesium. The luminosity class for B8 stars is estimated from the strength and narrowness of the hydrogen spectral lines, and Rigel is assigned to the bright supergiant class Ia. Variations in the spectrum have resulted in the assignment of different classes to Rigel, such as B8 Ia, B8 Iab, and B8 Iae.

As early as 1888, the heliocentric radial velocity of Rigel, as estimated from the Doppler shifts of its spectral lines, was seen to vary. This was confirmed and interpreted at the time as being due to a spectroscopic companion with a period of about 22 days. The radial velocity has since been measured to vary by about around a mean of .

In 1933, the Hα line in Rigel's spectrum was seen to be unusually weak and shifted towards shorter wavelengths, while there was a narrow emission spike about to the long wavelength side of the main absorption line. This is now known as a P Cygni profile after a star that shows this feature strongly in its spectrum. It is associated with mass loss where there is simultaneously emission from a dense wind close to the star and absorption from circumstellar material expanding away from the star.

The unusual Hα line profile is observed to vary unpredictably. Around a third of the time it is a normal absorption line. About a quarter of the time it is a double-peaked line, that is, an absorption line with an emission core or an emission line with an absorption core. About a quarter of the time it has a P Cygni profile; most of the rest of the time the line has an inverse P Cygni profile, where the emission component is on the short wavelength side of the line. Rarely, there is a pure emission Hα line. The line profile changes are interpreted as variations in the quantity and velocity of material being expelled from the star. Occasional very high-velocity outflows have been inferred, and, more rarely, infalling material. The overall picture is one of large looping structures arising from the photosphere and driven by magnetic fields.

Rigel has been known to vary in brightness since at least 1930. The small amplitude of Rigel's brightness variation requires photoelectric or CCD photometry to be reliably detected. This brightness variation has no obvious period. Observations over 18 nights in 1984 showed variations at red, blue, and yellow wavelengths of up to 0.13 magnitudes on timescales of a few hours to several days, but again no clear period. Rigel's color index varies slightly, but this is not significantly correlated with its brightness variations.

From analysis of "Hipparcos" satellite photometry, Rigel is identified as belonging to the Alpha Cygni class of variable stars, defined as "non-radially pulsating supergiants of the Bep–AepIa spectral types". In those spectral types, the 'e' indicates that it displays emission lines in its spectrum, while the 'p' means it has an unspecified spectral peculiarity. Alpha Cygni type variables are generally considered to be irregular or have quasi-periods. Rigel was added to the General Catalogue of Variable Stars in the 74th name-list of variable stars on the basis of the Hipparcos photometry, which showed variations with a photographic amplitude of 0.039 magnitudes and a possible period of 2.075 days. Rigel was observed with the Canadian MOST satellite for nearly 28 days in 2009. Milli-magnitude variations were observed, and gradual changes in flux suggest the presence of long-period pulsation modes.

From observations of the variable Hα spectral line, Rigel's mass-loss rate due to stellar wind is estimated be solar masses per year (/yr)—around 10 million times more than the mass-loss rate from the Sun. More detailed optical and K band infrared spectroscopic observations, together with VLTI interferometry, were taken from 2006 to 2010. Analysis of the Hα and Hγ line profiles, and measurement of the regions producing the lines, show that Rigel's stellar wind varies greatly in structure and strength. Loop and arm structures were also detected within the wind. Calculations of mass loss from the Hγ line give in 2006-7 and in 2009–10. Calculations using the Hα line give lower results, around . The terminal wind velocity is . It is estimated that Rigel has lost around 3 solar masses () since beginning life as a star of 7 to 9 million years ago.

Rigel's distance from the Sun is somewhat uncertain, different estimates being obtained by different methods. The 2007 Hipparcos new reduction of Rigel's parallax is , giving a distance of with a margin of error of about 9%. Rigel B, usually considered to be physically associated with Rigel and at the same distance, has a Gaia Data Release 2 parallax of , suggesting a distance around . However, the measurements for this object may be unreliable.

Indirect distance estimation methods have also been employed. For example, Rigel is believed to be in a region of nebulosity, its radiation illuminating several nearby clouds. Most notable of these is the 5°-long IC 2118 (Witch Head Nebula), located at an angular separation of 2.5° from the star, or a projected distance of away. From measures of other nebula-embedded stars, IC 2118's distance is estimated to be .

Rigel is an outlying member of the Orion OB1 Association, which is located at a distance of up to from Earth. It is a member of the loosely defined Taurus-Orion R1 Association, somewhat closer at . Rigel is thought to be considerably closer than most of the members of Orion OB1 and the Orion Nebula. Betelgeuse and Saiph lie at a similar distance to Rigel, although Betelgeuse is a runaway star with a complex history and might have originally formed in the main body of the association.

The star system of which Rigel is a part has at least four components. Rigel (sometimes called Rigel A to distinguish from the other components) has a visual companion, which is likely a close triple-star system. A fainter star at a wider separation might be a fifth component of the Rigel system.

William Herschel discovered Rigel to be a visual double star on 1 October 1781, cataloguing it as star 33 in the "second class of double stars" in his Catalogue of Double Stars, usually abbreviated to H II 33, or as H 2 33 in the Washington Double Star Catalogue. Friedrich Georg Wilhelm von Struve first measured the relative position of the companion in 1822, cataloguing the visual pair as Σ 668. The secondary star is often referred to as Rigel B or β Orionis B. The angular separation of Rigel B from Rigel A is 9.5 arc seconds to its south along position angle 204°. Although not particularly faint at visual magnitude 6.7, the overall difference in brightness from Rigel A (about 6.6 magnitudes or 440 times fainter) makes it a challenging target for telescope apertures smaller than .

At Rigel's estimated distance, Rigel B's projected separation from Rigel A is over 2,200 astronomical units (AU). Since its discovery, there has been no sign of orbital motion, although both stars share a similar common proper motion. The pair would have an estimated orbital period of 24,000 years. Gaia Data Release 2 (DR2) contains a somewhat unreliable parallax for Rigel B, placing it at about , further away than the Hipparcos distance for Rigel, but similar to the Taurus-Orion R1 association. There is no parallax for Rigel in Gaia DR2. The Gaia DR2 proper motions for Rigel B and the Hipparcos proper motions for Rigel are both small, although not quite the same.

In 1871, Sherburne Wesley Burnham suspected Rigel B to be a binary system, and in 1878, he resolved it into two components. This visual companion is designated as component C (Rigel C), with a measured separation from component B that varies from less than to around . In 2009, speckle interferometry showed the two almost identical components separated by , with visual magnitudes of 7.5 and 7.6, respectively. Their estimated orbital period is 63 years. Burnham listed the Rigel multiple system as β 555 in his double star catalog or BU 555 in modern use.

Component B is a double-lined spectroscopic binary system, which shows two sets of spectral lines combined within its single stellar spectrum. Periodic changes observed in relative positions of these lines indicate an orbital period of 9.86 days. The two spectroscopic components Rigel Ba and Rigel Bb cannot be resolved in optical telescopes but are known to both be hot stars of spectral type around B9. This spectroscopic binary, together with the close visual component Rigel C, is likely a physical triple-star system, although Rigel C cannot be detected in the spectrum, which is inconsistent with its observed brightness.

In 1878, Burnham found another possibly associated star of approximately 13th magnitude. He listed it as component D of β 555, although it is unclear whether it is physically related or a coincidental alignment. Its 2017 separation from Rigel was , almost due north at a position angle of 1°. Gaia DR2 finds it to be a 12th magnitude sunlike star at approximately the same distance as Rigel. Likely a K-type main-sequence star, this star would have an orbital period of around 250,000 years, if it is part of the Rigel system. A spectroscopic companion to Rigel was reported on the basis of radial velocity variations, and its orbit was even calculated, but subsequent work suggests that the star does not exist and that observed pulsations are intrinsic to Rigel itself.

Rigel is a blue supergiant that has exhausted the hydrogen fuel in its core, expanded and cooled as it moved away from the main sequence across the upper part of the Hertzsprung–Russell diagram. When it was on the main sequence, its effective temperature would have been around . Rigel's complex variability at visual wavelengths is caused by stellar pulsations similar to those of Deneb. Further observations of radial velocity variations indicate that it simultaneously oscillates in at least 19 non-radial modes with periods ranging from about 1.2 to 74 days.

Estimation of many physical characteristics of blue supergiant stars, including Rigel, is challenging due to their rarity and uncertainty about how far they are from the Sun. As such, their characteristics are mainly estimated from theoretical stellar evolution models. Its effective temperature can be estimated from the spectral type and color to be around . A mass of at an age of million years has been estimated by comparing evolutionary tracks, while atmospheric modeling from the spectrum gives a mass of .

Although Rigel is often considered the most luminous star within 1,000 light-years of the Sun, its energy output is poorly known. Using the Hipparcos distance of , the estimated relative luminosity for Rigel is about 120,000 times that of the Sun (), but another recently published distance of suggests an even higher luminosity of . Other calculations based on theoretical stellar evolutionary models of Rigel's atmosphere give luminosities anywhere between and , while summing the spectral energy distribution from historical photometry with the Hipparcos distance suggests a luminosity as low as . A 2018 study using the Navy Precision Optical Interferometer measured the angular diameter as . After correcting for limb darkening, the angular diameter is found to be , yielding a radius of . An older measurement of the angular diameter gives , equivalent to a radius of at . These radii are calculated assuming the Hipparcos distance of ; adopting a distance of leads to a significantly larger size.

Due to their closeness to each other and ambiguity of the spectrum, little is known about the intrinsic properties of the members of the Rigel BC triple system. All three stars seem to be near equally hot B-type main-sequence stars that are 3 to 4 times as massive as the Sun.

Stellar evolution models suggest that the pulsations of Rigel are powered by nuclear reactions in a hydrogen-burning shell that is at least partially non-convective. These pulsations are stronger and more numerous in stars that have evolved through a red supergiant phase and then increased in temperature to again become a blue supergiant. This is due to the decreased mass and increased levels of fusion products at the surface of the star.

Rigel is likely to be fusing helium in its core. Due to strong convection of helium produced in the core while Rigel was on the main sequence and in the hydrogen-burning shell since it became a supergiant, the fraction of helium at the surface has increased from 26.6% when the star formed to 32% now. The surface abundances of carbon, nitrogen, and oxygen seen in the spectrum are compatible with a post-red supergiant star only if its internal convection zones are modeled using non-homogeneous chemical conditions known as the Ledoux Criteria.

Rigel is expected to eventually end its stellar life as a type II supernova. It is one of the closest known potential supernova progenitors to Earth, and would be expected to have a maximum apparent magnitude of around (about the same brightness as a quarter Moon or around 300 times brighter than Venus ever gets.)

The earliest known recording of the name "Rigel" is in the "Alfonsine tables" of 1521. It is derived from the Arabic name ', "the left leg (foot) of Jauzah" (i.e. "rijl" meaning "leg, foot"), which can be traced to the 10th century. "Jauzah" was a proper name for Orion; an alternative Arabic name was ', "the foot of the great one", from which stems the rarely used variant names "Algebar" or "Elgebar". The "Alphonsine tables" saw its name split into "Rigel" and "Algebar", with the note, "et dicitur Algebar. Nominatur etiam Rigel." . Alternate spellings from the 17th century include "Regel" by Italian astronomer Giovanni Battista Riccioli, "Riglon" by German astronomer Wilhelm Schickard, and "Rigel Algeuze" or "Algibbar" by English scholar Edmund Chilmead.

With the constellation representing the mythological Greek huntsman Orion, Rigel is his knee or (as its name suggests) foot; with the nearby star Beta Eridani marking Orion's footstool. Rigel is presumably the star known as "Aurvandil's toe" in Norse mythology. In the Caribbean, Rigel represented the severed leg of the folkloric figure "Trois Rois", himself represented by the three stars of Orion's Belt. The leg had been severed with a cutlass by the maiden "Bįhi" (Sirius). The Lacandon people of southern Mexico knew it as "tunsel" ("little woodpecker").

Rigel was known as "Yerrerdet-kurrk" to the Wotjobaluk koori of southeastern Australia, and held to be the mother-in-law of "Totyerguil" (Altair). The distance between them signified the taboo preventing a man from approaching his mother-in-law. The indigenous Boorong people of northwestern Victoria named Rigel as "Collowgullouric Warepil". The Wardaman people of northern Australia know Rigel as the Red Kangaroo Leader "Unumburrgu" and chief conductor of ceremonies in a songline when Orion is high in the sky. Eridanus, the river, marks a line of stars in the sky leading to it, and the other stars of Orion are his ceremonial tools and entourage. Betelgeuse is "Ya-jungin" "Owl Eyes Flicking", watching the ceremonies.

The Māori people of New Zealand named Rigel as "Puanga", said to be a daughter of "Rehua" (Antares), the chief of all-stars. Its heliacal rising presages the appearance of "Matariki" (the Pleiades) in the dawn sky, marking the Māori New Year in late May or early June. The Moriori people of the Chatham Islands, as well as some Maori groups in New Zealand, mark the start of their New Year with Rigel rather than the Pleiades. "Puaka" is a southern name variant used in the South Island.

In Japan, the Minamoto or Genji clan chose Rigel and its white color as its symbol, calling the star "Genji-boshi" (), while the Taira or Heike clan adopted Betelgeuse and its red color. The two powerful families fought the Genpei War; the stars were seen as facing off against each other and only kept apart by the three stars of Orion's Belt.

The MS "Rigel" was originally a Norwegian ship, built in Copenhagen in 1924. It was requisitioned by the Germans during World War II and sunk in 1944 while being used to transport prisoners of war. Two US Navy ships have borne the name USS "Rigel". The SSM-N-6 Rigel was a cruise missile program for the US Navy that was cancelled in 1953 before reaching deployment.

The Rigel Skerries are a chain of small islands in Antarctica, renamed after originally being called Utskjera. They were given their current name as Rigel was used as an astrofix. Mount Rigel, elevation , is in Antarctica.

1713


</doc>
<doc id="26464" url="https://en.wikipedia.org/wiki?curid=26464" title="Afghan Civil War (1928–1929)">
Afghan Civil War (1928–1929)

The Afghan Civil War was fought from 14 November 1928 to 13 October 1929. Rebelling, and subsequently governing Saqqawist forces under Habibullāh Kalakāni fought against various opposing tribes and rival monarchs in the Kingdom of Afghanistan, among whom Mohammed Nādir Khān eventually achieved a preponderant role. Despite early successes, such as the capture of Kabul and defeat of Amanullah Khan on 17 January 1929 or the capture of Kandahar on 3 June, the Saqqawists were eventually deposed by anti-Saqqawist forces led by Nadir on 13 October 1929, leading to Nadir's ascension as King of Afghanistan, who ruled until his assassination on 3 November 1933.

The war began when the Shinwari tribe revolted in Jalalabad and drew a manifesto of 10 grievances, 5 of which related to Amanullah's meddling with the status of women. Although this revolt was quelled by a force led by Ali Ahmad Khan, a concurrent Saqqawist uprising in the north managed to capture the besieged city of Jabal al-Siraj, before attacking Kabul on 14 December 1928. Although the first Saqqawist assault on Kabul was repulsed, the second Saqqawist assault succeeded at capturing Kabul on 17 January 1929. The government at that time was focused on social reforms, such as the expansion of women's rights and the adoption of a military draft, which had earlier led to the unsuccessful Alizai rebellion and Khost rebellion. Kalakani denounced his opponents as kuffar, while his forces committed acts of rape and looting.

After capturing Kabul, the Saqqawists defeated a rival government in Jalalabad led by Ali Ahmad Khan on 9 February. Despite a setback in the Battle of Shaykhabad in early March, the Saqqawists managed to extend their control to Kandahar in June after a short siege. However, they were unable to defeat Nadir Khan in the Logar valley, who had entered the area together with Amanullah in March, although the latter left the country on 23 May. After a months-long stalemate, Nadir Khan eventually managed to force the Saqqawists to retreat into Kabul in October 1929, and subsequently into the Arg. The capture of the Arg on 13 October 1929 marked the end of the civil war, although Saqqawist activity continued until 1931. The civil war was fought concurrently with a Soviet operation in northern Afghanistan to fight the Basmachi movement.

During the anti-Saqqawist capture of Kabul, Nadir's forces sacked the city against his orders. After the civil war, Nadir did not cede control of the Afghan throne back to Amanullah, and this led to several rebellions, including the Shinwari rebellion, the Kuhistan rebellion, the Ghilzai rebellion, and Mazrak's revolt. During World War II, Amanullah would unsuccessfully try to regain the throne with Axis help.

Amānullāh Khān reigned in Afghanistan from 1919, achieving full independence from the British Empire shortly afterwards. Before the Treaty of Rawalpindi was concluded in 1921, Afghanistan had already begun to establish its own foreign policy, including diplomatic relations with the Russian Soviet Federative Socialist Republic in 1919. During the 1920s, Afghanistan established diplomatic relations with most major countries.

The second round of Anglo–Afghan negotiations for final peace were inconclusive. Both sides were prepared to agree on Afghan independence in foreign affairs, as provided for in the previous agreement. The two nations disagreed, however, on the issue that had plagued Anglo-Afghan relations for decades and would continue to cause friction for many more — authority over Pashtun tribes on both sides of the Durand Line. The British refused to concede Afghan control over the tribes on the British side of the line while the Afghans insisted on it. The Afghans regarded the 1921 agreement as only an informal one.

The rivalry of the great powers in the region might have remained subdued had it not been for the dramatic change in government in Moscow brought about by the Bolshevik Revolution of 1917. In their efforts to placate Muslims within their borders, the new Soviet leaders were eager to establish cordial relations with neighboring Muslim states. In the case of Afghanistan, the Soviets could achieve a dual purpose: by strengthening relations with the leadership in Kabul, they could also threaten Britain, which was one of the Western states supporting counterrevolution in the Soviet Union. In his attempts to end British control of Afghan foreign policy, Amanullah sent an emissary to Moscow in 1919; Vladimir Lenin received the envoy warmly and responded by sending a Soviet representative to Kabul to offer aid to Amānullāh's government.

Throughout Amānullāh's reign, Soviet-Afghan relations fluctuated according to Afghanistan's value to the Soviet leadership at a given time; Afghanistan was either viewed as a tool for dealing with Soviet Muslim minorities or for threatening the British. Whereas the Soviets sought Amanullah's assistance in suppressing anti-Bolshevik elements in Central Asia in return for help against the British, the Afghans were more interested in regaining lands across the Amu Darya lost to Russia in the nineteenth century. Afghan attempts to regain the oases of Merv and Panjdeh were easily subdued by the Soviet Red Army.

In May 1921, the Afghans and the Soviets signed a Treaty of Friendship, Afghanistan's first international agreement since gaining full independence in 1919. The Soviets provided Amanullah with aid in the form of cash, technology and military equipment. Despite this, Amanullah grew increasingly disillusioned with the Soviets, especially as he witnessed the widening oppression of his fellow Muslims across the border.

Anglo-Afghan relations soured over British fear of an Afghan-Soviet friendship, especially with the introduction of a few Soviet planes into Afghanistan. British unease increased when Amanullah maintained contacts with Indian nationalists and gave them asylum in Kabul, and also when he sought to stir up unrest among the Pashtun tribes across the border. The British responded by refusing to address Amanullah as "Your Majesty," and imposing restrictions on the transit of goods through India.

Amānullāh's domestic reforms were no less dramatic than his foreign policy initiatives, but those reforms could not match his achievement of complete, lasting independence. Mahmud Tarzi, Amanullah's father-in-law and Foreign Minister, encouraged the monarch's interest in social and political reform but urged that it be gradually built upon the basis of a strong central government, as had occurred in Turkey under Kemal Atatürk. Socially, Amanullah enjoyed many of Mahmud Tarzi's thoughts at the time, such as giving women more rights and allowing freedom of press through publishing. Tarzi, being heavily influenced by the West, brought this influence to Afghanistan - Amanullah enjoyed Western dress and etiquette. His wife, Queen Soraya Tarzi, became the face of Amanullah Khan's reforms in regard to women.

Amānullāh's reforms touched on many areas of Afghan life. In 1921 he established an air force, albeit with only a few Soviet planes and pilots; Afghan personnel later received training in France, Italy and Turkey. Although he came to power with army support, Amanullah alienated many army personnel by reducing both their pay and size of the forces and by altering recruiting patterns to prevent tribal leaders from controlling who joined the service. Amanullah's Turkish advisers suggested the king retire the older officers, men who were set in their ways and might resist the formation of a more professional army. Amanullah's minister of war, General Muhammad Nadir Khan, a member of the Musahiban branch of the royal family, opposed these changes, preferring instead to recognize tribal sensitivities. The king rejected Nadir Khan's advice and an anti-Turkish faction took root in the army; in 1924 Nadir Khan left the government to become ambassador to France.

If fully enacted, Amānullāh's reforms would have totally transformed Afghanistan. Most of his proposals, however, died with his abdication. His transforming social and educational reforms included: adopting the solar calendar, requiring Western dress in parts of Kabul and elsewhere, discouraging the veiling and seclusion of women, abolishing slavery and forced labor, introducing secular education (for girls as well as boys); adult-education classes and educating nomads. His economic reforms included restructuring, reorganizing and rationalizing the entire tax structure, anti-smuggling and anti-corruption campaigns, a livestock census for taxation purposes, the first budget (in 1922), implementing the metric system (which did not take hold), establishing the Bank-i-Melli (National Bank) in 1928, and introducing the Afghani as the new unit of currency in 1923. The political and judicial reforms Amānullāh proposed were equally radical for the time and included the creation of Afghanistan's first constitution (in 1923), the guarantee of civil rights (first by decree and later constitutionally), national registration and identity cards for the citizenry, the establishment of a legislative assembly, a court system to enforce new secular penal, civil and commercial codes, prohibition of blood money, and abolition of subsidies and privileges for tribal chiefs and the royal family.

Although sharia (Islamic law) was to be the residual source of law, it regained prominence after the Khost rebellion of 1924–25. Religious leaders, who had gained influence under Habibullah Khan, were unhappy with Amānullāh's extensive religious reforms. Conventional wisdom holds that the tribal revolt that overthrew Amanullah grew out of opposition to his reform program, although those people most affected by his reforms were urban dwellers not universally opposed to his policies, rather than the tribes. Nevertheless, the king had managed to alienate religious leaders and army members.

According to a later British ambassador in Afghanistan, William Kerr Fraser-Tytler, the British empire, though officially neutral, was very concerned about the situation in Afghanistan and they "made up a set of rules to govern the situation. It was unneutral to refuse an Afghan entry into Afghanistan, but once he was in he became a contestant, and it would be unneutral to allow him to recross the border, seeking a brief asylum before plunging again into the fray. And so in a mixture of the rules of cricket and football it was ordained that a player might go on the field once, and play for the crown. But if he was forced into touch, and recrossed the line, whether voluntarily or not, he was 'out' and the referee would not let him back into the game."

Many commentators in Afghanistan and elsewhere hold the belief that Britain played a part in the fall of Amanullah in January 1929, and this is supported by Soviet Historiography. According to Encyclopædia Iranica, "While it can not be dismissed out of hand, the fact remains that no evidence to support it can be found in the copious British Indian archives pertaining to this period. There can be no doubt, however, that behind the stance of official neutrality which the British maintained throughout the crisis of 1929 lay an unwillingness to help Amān-Allāh to reconquer his throne and a benevolence toward the moves of Nāder Khan. While the Soviet authorities favored Amān-Allāh (though reluctantly) and aided a foray on his behalf by Ḡolām Nabī Čarḵī in the Balḵ region, the British authorities allowed Nāder Khan to reenter Afghanistan through India and to obtain a decisive addition of strength through his recruitment of thousands of armed Wazīr and Masʿūd frontier tribesmen. Also helpful was their decision to lift a restriction order, imposing residence at a fixed address in India, on Fażl ʿOmar Mojaddedī, who was to play an apparently decisive role in persuading the Naqšbandī "mollā"s of Afghanistan to change sides and later was to become Nāder Shah’s first minister of justice. In short, while all the evidence indicates that Bačča-ye Saqqā (Kalakani)’s rise was due solely to the internal disintegration of King Amān-Allāh’s régime, there can be no doubt that British policy, tacit rather than explicit, helped to bring about Bačča-ye Saqqā’s fall".

After coming to power in Afghanistan, the Saqqawists allowed Basmachi insurgents to operate in northern Afghanistan, who then had established themselves in parts of Kunduz, Takhar and Badakshshan provinces by March 1929. Repeated Basmachi incursions into Soviet territory eventually prompted the start of a Soviet operation in Afghanistan.

The Iranian military attache, Colonel Ali Khan, was under instruction by the Iranian Shah to protect the Shiite community of Afghanistan to the greatest possible extent that would not invite a Saqqawist attack on Iran.

While Germany itself was uninvolved in the war, the Afghan-German Trading Company was requested by Kalakani to assassinate Amanullah Khan on 15 April 1929, and were promised a large reward if they did so.

The unraveling began when Shinwari Pashtun tribesmen revolted and besieged Jalalabad on 14 
November 1928, cutting telegraph wires and cutting the road to the capital, after which they drew a manifesto of ten grievances, five of which related to what they saw as Amanullah's unsupportable meddling with the status of women. However, during the Shinwari rebellion two years later, the Shinwari claimed that this revolt was "not so much anti-Amanullah as against the local tax-collectors at Jelalabad". The initial response of the government was to send a small contingent to relieve Jalalabad, which was halted at Nimla, 20 miles (32 km) west of Jalalabad, before that force found itself surrounded and destroyed shortly after. Thereafter, Amanullah sent two representatives to suppress the uprising - His foreign minister, Ghulam Siddiq Khan, and the head of the National Council, Shayr Ahmad Khan. However, In late November, they had a falling out, and according to Fayz Muhammad, were negotiating separately with the tribes. Ghulam Siddiq is said to have incited some of the Shinwari to attack Shayr Ahmad Khan, the main consequence of which was that the Shinwari burned the Emir's winter palace in Jalalabad to the ground.

On 3 December 1928, Amanullah then decided to send his brother-in-law, Ali Ahmad Khan Luynab, to deal with the problem, and sent him off with regular troops, militia levies, and a sizable treasury with which to conciliate the tribal leaders. Ghulam Siddiq and Shayr Ahmad were ordered back to Kabul.

In the meantime, calls had gone out for tribal levies to assist the regular army in dealing with the Shinwari uprising, and armed tribesmen from the east, south and west, which included Waziri, Wardak, Ghilzai and Tajik tribesmen, but also more recently the Mangal tribesmen (who recently were at war with Amanullah's government) trickled into the capital to help. These men had no particular loyalty to the government and saw the situation simply as an opportunity for enrichment. As it turned out, there was no need to send them to Jalalabad, Ali Ahmad managed to conciliate the Shinwari leaders and put an end to the uprising, but as it took a while for this news to spread through the countryside, the levy tribesmen continued to arrive in the capital.

Amanullah presumably welcomed the news of the reconciliation. However, any feeling of relief would have been very temporary - forces led by a Tajik leader, Habibullah Kalakani, were moving toward Kabul from the north. Kalakani was a native of Kalakan, a village thirty kilometers north of Kabul. In late November, they besieged Jabal al-Siraj, north of Kabul, and on either 11 or 12 December, after 18 days of siege, Ahmad Ali Lodi peacefully surrendered the citadel, handing over all government funds as well as 18 machine guns, and an unspecified number of heavy weapons and rifles.

Emboldened by the victory, Kalakani attacked Kabul with 2000 men (only 200 of which were armed with rifles, and the rest armed with sticks and axes) on 14 December 1928. He and his forces entered the Murad Beg Fort on the northern slopes of the Kuh-i Kutal, nearby the village of Khayr Khanah. The rebels, feeling that deposing an emir would be against the shariah, performed a ritual and declared Kalakani the new emir, and then passed through the village of Dih-i Kupak at 3:00 PM. Around 3:15 PM, they reached the Bagh-i Bala park. They also occupied Bagh-i Bala palace, formerly the summer residence of Abdur Rahman Khan, which had now been turned into a military hospital for the Emir's personal guard and the residence of a Turkish physician, Bahjet Beg. After disarming and dismissing the guards and the embassy, they stationed their own guards, reassuring the employees of the embassy that they were guests of the nation and as such no harm would come to them.

The rebels also managed to enter the house and fortress tower of Shahr Ara, which was defended by Shawkat Beg, a Turkish officer who was the son of Muhammad Akbar Khan. His small force, as well as a group of cavalry officers, managed to prevent the Rebels from entering the old city.

As the battle continued, the whole city was filled the sounds of artillery and gunfire. However, only the cavalry of the Emir's personal guard and a few other loyal soldiers actually put up a fight against Kalakani's forces. The rest of the army was in a mutinous mood, as their officers had been appropriating the soldier's rations. Holding their commanders rather than the rebels to blame for the trouble, when ordered to shoot, the soldiers simply fired their weapons in the air. Tumult and confusion were now widespread. The emir was furious when he heard of the mutiny, and ordered all the weapons to be distributed to the residents of Kabul and to the tribesmen who had come into the city but had not yet left for Jalalabad to fight the Shinwari. However, the near-universal loathing of the Afghans for Amanullah led to the majority of them refusing to take up arms against Kalakani. To make matters worse for Amanullah, Some Waziri, Mangal and Ahmadzai tribesmen defected to Kalakani, took up positions on the Asmai Hill in the center of Kabul, and fired on the Emir's troops.

Ghulam Ghaws, Whose father, Malik Jahandad Ahmadzai, had been executed following a rebellion, headed towards his hometown costs, carrying with him more than 300 rifles, armed the people there, and rose up against the government. Other tribes acted similarly because there was no control over the distribution of weapons.

The battle took a drastic turn on 25 December, when Kalakani was wounded in the shoulder from an aerial bomb, causing him to retreat 20 kilometers north, to Murad Beg Fort, in the Kuhdaman region.

Kalakani's retreat gave Amanullah a chance to regroup. In late December, he began shelling Murad Beg Fort, and this shelling lasted until 13 January. However, the shelling failed to provide any results, and this disheartened the king. In the early morning of 14 January, Amanullah abdicated the throne to his oldest brother, Inayatullah Khan, who ruled for only three days before escaping into exile in British-India. Amanullah's efforts to recover power by leading a small, ill-equipped force toward Kabul failed. The deposed king crossed the border into British-India and went into exile in Italy and remained in Europe until his 1960 death in Zürich, Switzerland. At the time of his abdication, Amanullah's troops were fighting in the Khayr Khanah (Khirskhanah) pass, seven miles (11 km) north of Kabul.

After accessing to the Afghan throne, Inayatullah Khan sent a peace envoy to Kalakani. The envoys informed Kalakani that Inayatullah's accession had been illegal in accordance to the shariah, since Kalakani had ascended the throne in the Islamic month of Rajab, and Inayatullah's accession had taken place in the Islamic month of Sha'ban. Rejoiced, Kalakani and 28 armed men, accompanied by a group of unarmed Kuhdamanis passed through the village of Dih-i Afghanan and attacked the capital, shouting "ya chahar yar" and firing guns at the air. On the very first day of his reign, Inayatullah was forced to barricade himself in the Arg with several of his ministers.

On the 16th of January, while 80 Hazaras from Bihsud were defending the Qalah-i Buland Fortress, as well as the arsenal at Kulula Pasha, some officials declared their allegiance to Kalakani. These included Shayr Ahmad, head of the national council, Fayz Muhammad Khan, former minister of trade, Abd al-Hadi Khan, the minister of finance, and the sons of Abdur Rahman Khan: Mir Hashim, Sardar Amin Allah Khan, Muhammad Umar Khan, as well as a number of deputy ministers and heads of state bureaus.

On the 17th of January, Inayatullah, unnerved by the lack of support from the Kabulis, surrendered to Kalakani and abdicated the throne. Kalakani allowed him to peacefully leave Kabul with his family and 3000 rupees.

Having become King of Afghanistan, Kalakani appointed a number of people into office, including:


On 9 May, Kalakani passed a decree in Kabul which forbade citizens of Kabul from moving out of the city without permission, even into the government-controlled Bandar-i Arghandah, Charasya, Bini Hisar, Butkhak, Kutal-i Pay Manar, Kutal-i Khayr Khanah, Maydan, Jalriz, Logar, Khurd Kabul, Tangi Gharu or Dih Sabz.

On 31 May, Kalakani paid a visit to the shrine at Mazar-i Khwajah Musafir, which lies near the village of Chihil Tan above the village of Shaykh Muhammad Riza-yi Khurasani which lies in the Paghman District, 6 miles (9.6 km) west of Kabul

Following his takeover, Kalakani, fearful of a counterattack by the Amanullah loyalists, swiftly moved the treasury to Kudhaman.

The first concerted opposition to Kalakani came from Ali Ahmad Khan, who was still stationed in Jalalabad after suppressing the Shinwari revolt. There, the locals proclaimed Ali as the new Emir upon receiving the news of Kalakani's accession. Ali then marched his troops on Samucha-i Mulla Omar, Tangi Khurd Kabul, and Chanri, and took up positions there. At the head of a 2,000 men strong army and a tribal militia, he marched to Jagdalak, where he waited for a force of Mohmands who had promised to join him. Over the course of 23 to 29 January, Ali sent out proclamations of his new emirate to Kabul, Logar, the Hazarahjat, the Southern province, and elsewhere, and called on people to join him.
Malik Qays of the Khugyani tribe, who had initially allied himself with Ali, defected to Kalakani, captured Ali and brought Ali to Kalakani in exchange for 17,000 rupees and the rank of lieutenant general, ending Ali's reign on 9 February.

Sometime before 13 March, the Battle of Shaykhabad took place, 46 miles (74 km) from Kabul and halfway across the Kabul-Ghazni road.

It was here where Karim Khan Wardak, who refused to pledge allegiance to Kalakani, had made defensive preparations. Around this time, Abd al-Wakil Khan, who had earlier been appointed field marshal by Kalakani, was dispatched to Ghazni and Qandahar with a force of 3,000 men. When Abd al-Wakil reached the village of Bini Badam and Qalah-i Durrani, 30 miles (48 kilometres) from Kabul, he halted there to deal with Karim Khan Wardak's forces, only then to proceed. But Karim Khan, along with Wazir and Hazara leaders who had gathered in support of Aman Allah, sent a joint message to the field marshal that said:

Abd al-Wakil accepted this message at face value, and he sent the Model Battalion, which at the time numbered 1,800 men and was stationed at Qal ah-yi Durrani, to march on Shaykhabad along with 400 royal cavalry and 800 Kuhistani and Kuhdamani infantry militia which had halted near the village of Bini Badam. After an exhausting march through snow-covered hills, Abd al-Wakil's forces were ambushed near Zarani, at the edge of the Daht-i Tup waste land by Wardak tribesmen, who came thundering down the hills after a soldier's shot at a bird alerted them that Kalakani's troops were nearby. Many of Abd al-Wakil's troops were killed in the ambush; only 20 of 400 cavalrymen survived.

The people of Maydan, Jalriz and Sanglakh refused to offer allegiance to Kalakani, and formed an alliance with the Wardak and surrounded Kalakani's armies in Maydan, and defeated them in Qalah-i Durrani, before advancing to Arghandah, 14 miles (22.5 kilometres) west of Kabul, where some Kalakani's forced decided to retreat toward Qalah-i Qazi, Chardihi and Kuhdaman.

On 5:30 on 22 March, Kalakani personally headed from Kabul to Arghandah to bolster the spirits of his soldiers and managed to convince the soldiers to advance on Kutal-i Shaykh, a small village near the intersection with the road west to the Unay Pass. They accepted, and the battle of Kutal-i Shaykh lasted until the evening with a victory for Kalakani.

In the morning of 23 March, Kalakani ordered 500 militamen to be brought back to Kabul from Najrab, because they had been fighting against the Tagabis and Kalakani was worried that Najrab might defect. On 24 March, Kalakani ordered some Kuhdamanis, Kuhistanis, and people from the villages of Dih-i Nur, Maydan and Arghandah to cover the army rear which was then at Qalah-i Durrani and Pul-i Maydan and so deny those awaiting its defeat the chance to march on Chardihi and Kuhdaman. Later that same day, Kalakani's Field Marshall, Purdil Khan (who had since been named as Minister of Defense) shelled Maydan, which strengthened the resolve among the Maydan, Arghandah and Sanglakjh to fight Kalakani. On the 25th, Purdil Khan managed to capture Maydan, but the great casualties inflicted prevented him from advancing towards Wardak and Ghazni, and he withdrew to Arghandah and Qalah the following day.

At this time, Amanullah had supposedly returned to Afghanistan and was marching from Qandahar with an army made of Durrani, Khattak, Ghilzai, and Hazara fighters. Four days after entering Afghanistan, Amanullah learnt of a Saqqawist uprising in Herat. On 27 March, Habibullah Kalakani ordered his brother, Hamid Allah Kalakani, to lead a force of Panjshiris backed by 14 siege guns, to Maydan. At Kutal-i Shaykh, this force won a major victory which allowed it to continue advancing towards Maydan, where it took 25 prisoners and destroyed several forts. On the night of the 28th, anti-Saqqawist tribesmen ambushed Hamid Allah's force, and while they were able to deal vast casualties and capture many field guns and rifles, they were unable to disloge Hamid from his position. On the 30th, the anti-Saqqawist tribes renewed the battle, and this time they managed to almost completely expel Hamid Allah's forces from Maydan, except for a few detachments which were surrounded in the fortress known as Qalah-i Abd al-Ghani Khan Beg Samandi, about 14 miles (22.5 km) west of Shaykhabad. A large part of Hamid's defeated army retreated to Arghandah and Qalah-i Qazi.

On the 31st, Kalakani started another offensive on Maydan and made some progress. On 2 April, a force from Bihsuf occupied the Unay Pass and reached an agreement with the militias of the Surkh-i Parsa, Turkman, Bamyan, Balkhab and Shaykh Ali Hazarah for them to attack Kuhistan and Kuhdaman via the Ghurband Valley road while it simultaneously attacks Kabul via the road through Maydan. On 3 April, Kalakani's forces clashed in Shash Gaw, 13 miles (20.9 km) north of Ghazni. On 7 April they were defeated while advancing along the road not so far from Ghazni near Shiniz in Wardak. On 7 April, they clashed at Shiniz, and on the 9th they clashed in Shaykhabad and Jaghatu, northwest of Ghazni. Fayz Muhammed reports that Kalakani suffered a major defeat near Ghazni on 9 April and that his forces fled to Qalah-i Durrani, but historian Robert D. McChesney believes this to be false. By the 12th, there were rumours in Kabul that Ghazni was surrounded by anti-Saqqawist forces. In mid-March, Mohammed Nadir Shah, who had departed from France in January, arrived in Jalalabad to centralize the opposition to Kalakani. It was reported on 16 April that Ghazni had fallen to anti-Saqqawist forces, and that Kalakani's forces had been defeated at Shaykh Amir, near the Majid Pass. By the 20th, there were reports that anti-Saqqawist forces were on the doorstep of Paghman, just west of Kabul, and that Hazarah forces from Bihsud crossed the Unay pass and were heading on their way to Ghurband, while another force occupied positions there to prevent Kalakani from using it to cross to Hazarahjat. The force sent to Ghazni retreated to Shiniz-i Wardak. On the 21st, soldiers loyal to Kalakani left Kabul to reinforce Ghazni. At this time, Kalakani decided to reinforce the Qalah-i Durrani fort to prevent rebel tribes from advancing past it. On the 24th, Kalakani's forces were clashing in Shash Gaw, 13 miles (21 km) northwest of Ghazni. On the 26th, while laying siege to Ghazni, Amanullah had inexplicably given the order to retreat to Qandahar. On the 28th, it was reported that Kalakani's army had captured Ghazni. On 30 April, anti-Saqqawist forces re-entered Ghazni, renewing the battle. On the same day, a large anti-Saqqawist offensive managed to dislodge Kalakani's forces from positions in Shaykhabad, Takiya and Shash Gaw, forcing some of them to retreat towards Daht-i Tup. On 1 May, anti-Saqqawist forces continued their offensive, clashing in Dasht-i Tup and Shaykhabad, and on 2 May fighting was taking place in Shaykhabad, Dasht-i Tup and Qalah-yi Durrani. On 7 May, units were sent from Kabul to Mahtab and Arghandah to prepare defenses there. On 8 May, while there was fighting in Dasht-i Tup and Bini Badam, Saqqawist forces under Purdil Khan departed for Charikar. One of Kalakani's generals, Muhammad Unar Khan, died on 14 May. The next day, Kalakani sent units to Kuh-i Asmai and Shayr Darwazah. On the 19th, Amanullah was rumoured to be besieged at Kalat, 80 miles (128.75 km) north of Qandahar. On the 23rd, Amanullah Khan fled Afghanistan into the British Raj, leaving his brother Inayatullah Khan in charge of anti-Saqqawist resistance. By that time, Kalakani held control of the entire Ghazni region, and the road south of Ghazni as open. By 1 June, anti-Saqqawist forces who at this time were at Qarabagh decided to retreat Qandahar, while Kalakani's armies were able to take Kalat and had surrounded the city of Qandahar, which duly fell on 3 June or 31 May.

On 8 March, Nadir Khan crossed into Afghanistan just east of Matun in the Kurram Valley. On 16 March, Kalakani dispatched troops in two directions: along the route to Maydan through Qalah-i Mahtab Bagh, Qalah-i Durrani, Qalah-i Qazi, and Arghandah, and via Charasya and Musai to Logar. 129 troops were also dispatched by Kalakani to the Logar Valley, which were defeated at Waghjan Gorge (Between Kushi in Kulangar and Shikar Qalah), forcing them to retreat to Rishkhur, south of Kabul. On 23 March, heavy fighting was occurring in Najrab, north of Kabul. The next day, 500 of Kalakani's troops who were marching from Charasya to Kulangar were ambushed, with many killed or wounded.
By 31 March, there were some reversals for Kalakani on the Maydan front. On 23 March, 6000 Mangal tribesmen joined Nadir Khan at Khost. Four days later, he left for Urgun, which he reached on 5 April. A few days later, he took Baladah, and on the 15th he captured Gardez. On the 23rd, Nadir was residing in Safid Qalah, at the southern entrance of the Altamur (or Tirah) pass. On the 24th, he continued through the pass to Charkh, where he was confronted by a force sent by Kalakani. After initial success in capturing the village of Dabar in Charkh, he was ultimately forced to retreat to Sijinak, east of Gardiz on the 27th. On the 22nd, Kalakani sent troops to Logar to defend it against Nadir, whose forces captured Dubandi and the village of Kushi that same day. On the 23rd there were rumours in Kabul that Kalakani's armies had been defeated and forced to retreat to Qalah-i Durrani on the Maydan-Ghazni road. On the 23rd, Nadir reached the Waghjan Gorge. On the 24th, there were rumours in Kabul that Nadir's forces had entered the village of Aghujan, 22 miles (35.4 km) south of Kabul. On the 25th, Nadir reached Hisarak in the Logar valley, and on that same day it was rumoured that he had suffered a defeat in a battle at Tirah Pass. On 1 May, while a battle in the Southern province had been going on for three days, Kalakani's forces carried out a raid on Khushi in Logar and plundered its inhabitants. By 3 May, Nadir had established a fort at Surkhab and was harassing Kalakani's troops to prevent Kalakani from advancing into the Southern province. On the sixth, Kalakani sent new troops to Charikar. On the 11th there were rumours that Nadir arrived in Charkh in Logar. Robert D. McChesney believes this to be false, and says this was just wishful thinking. On 8 May, Hashim (Nadir Khan's brother) persuaded tribes of the Eastern province to unite against Kalakani, who agreed to raise 40,000 troops who would advance in three formations through Tagab, Tangi Gharu, Ghakari and Lataband to attack Kuhdaman, Kuhistan and Kabul. That same day, Nadir's forces reached the region of Pul-i Hashim Khayl in Gandamak and at Tagab made plans to continue further down the road. On 11 May pro-Nadir tribes moved on Kabul but were stopped by Saqqawist Shinwari at Surkhrud. On 12 May there were rumours that Nadir had inflicted a defeat upon Kalakani at Bidak. On 15 May Nadir crossed the Tirah Pass and began an incursion into the Logar valley, which continued the 16th, when Nadir pursued the local Saqqawist forces as far as Kulangar, Kutti Khayl and Muhammad Aghah, and was fighting over control of the Ghurband Valley. Also on the 16th, Nadir reached Khak-i Jabbar via the road through Hisarak. On the 23rd, when peace negotiations were ongoing, Kalakani sent a force of 300 men to Logar. On 26 June, Kalakani's forces recaptured Gardiz.

On 14 July, Nadir Khan's forces entered the Logar valley, won a victory at Padkhwab-i Rughani and from there, advanced on Surkhab where they surrounded and besieged one of Kalakani's forces at Kariz-i Darwish, which surrendered the next day. On 18 July, Kalakani's forces fought a battle with the Khugyani near Khurd Kabul. In order to get the upper hand in the battle, Kalakani confiscated all automobiles and horse carriages in Kabul, so that reinforcements could arrive more quickly. This plan worked, and on 19 July the situation was stabilized. On 18 August, Nadir moved his headquarters to Ali Khayl with the Jaji tribe, which had assured him of their unswerving loyalty.

Sometime before 17 March, anti-Saqqawist tribes from Tagab launched a surprise attack on Sarubi and Gugamandan, opening what Robert D. McChesney labels "The Tagab Front". This attack took the local garrisons by surprise and allowed the Tagabis to capture two cannons, weaponry and other military supplies. After this success, the Tagabis planned a northward assault on Jamal Afgha in Kuhistan, which was successfully undertaken on the 18th. On 23 March, people of Durnama, Sujnan and Bulaghin attacked the Tagabis, defeated them, and occupied their positions, which stabilized the Tagab Front. On 1 April, prisoners arrived from Tagab.

On 2 August, the Tagab front was re-opened following a local uprising. On 12 August, after days of skirmishes, Kalakani's forces launched a large counteroffensive and forced the Tagabis to surrender the next day. This ended the Tagab front.

On 2 April, there were rumours in Kabul that anti-Saqqawist Hazaras had occupied positions in Balkh, while others were able to march on Aqchah, Andkhuy, Maymanah and Mazar-i Sharif. On the 7th, anti-Saqqawist forces arrived in Siyahgird in Ghurband. On the 17th, Sayyid Hussayn had left for Charikar. anti-Saqqawist forces closed the road in the Ghurband valley leading to Kuhistan and Kuhdaman, and on the 18th they had reportedly reached Ghurband. On the 19th, a counteroffensive by Ghulam Rasul Khan against the Hazaras was called off by Kalakani, who wanted instead to focus on Charikar, which was reportedly under attack by local anti-Saqqawist partisans. On the 20th, Sayyid Husayn left for Charikar, where he ambushed and killed Ata Muhammed, whose fianceé Sayyid had taken as a wife in the years prior, for which Ata Muhammed had sworn to kill him. On the 26th, word spread in Kabul that Hazara units had reached Katan mountain, west of Shakar Dara, and from there captured the Khudamani villages of Shakar Darra, Farza, Ghaza, Saray Khwajah, and Charikar. On the 27th, anti-Saqqawist Hazaras reportedly attacked Farza, Shakar Darra and Istalif (towns in Kuhdaman). That same day, in response to Hazara advances, Kalakani sent Hamid Allah on a counteroffensive which succeeded forcing the Hazaras to pull back. However, the situation remained dire for Kalakani and on 3 May he withdrew troops and munitions from other fronts to reinforce the Ghurband front. On 4 May, on the same day which Amanullah withdrew from Wardak, there were rumours in Kabul that Sayyid Husayn, one of Kalakani's generals, had made a breakthrough in Ghurband, and on the next day he reportedly was marching on Mazar-i Sharif via the road through Qunduz. Before this march on Mazar-i Sharif, the city had earlier been the site of a mutiny by Kuhistani and Kuhdamani forces, which began in January after Kalakani captured Kabul, and was ended on 30 April by anti-Saqqawist forces. It's after this point that sources disagree - Faiz Mohammad records the mutineers of Mazar-i Sharif retreating to Herat and capturing it sometime before 15 May, while Ademec says that Herat was captured sometime after Saqqawist forces captured Mazar-i Sharif in June, after Amanullah left Afghanistan for the British Raj, and then gradually extended their control to Maymanah and then Herat.

On 10 May, word had spread in Kabul that Ghulam Jalani Khan had occupied Andarab and Khanabad in Qataghan and the governor of Qataghan-Badakhshan Province, Mir Baba Sahib Charikari had been killed. On 9 or 10 May, Sayyid Husayn suffered a severe setback in the Battle of Shibar Pass, where his 12,000-man strong army was routed by a local Hazara militia which sought revenge for destruction of cattle, which ended Sayyid's hopes of taking Mazar-i Sharif. On May 12, Sayyid found himself besieged in Kuhistan and was reportedly wounded. On that same day, one of Kalakani's generals, Abd Al-Wakil Khan captured Fayzabad in Badakhshan while some of his units reached Farjaghan (at the head of the Alishang Valley near Tagab and Najrab). Also on 12 May anti-Saqqawist forces won a victory in a battle near Pul-i Matak after marching on Tagab. On 13 May 900 men from Kalakani's army were captured in Ghurband after a brief battle. On the 14th, another 2000 Saqqawist soldiers were defeated and their weapons, materiel and ammunition was seized.

On the 15th, Sayyid Husayn began another offensive against anti-Saqqawist forces, but after taking the Pansjir Valley on the 15th he was stopped at the Khawak Pass on the 16th. On the 19th, there were rumours in Kabul that Sayyid Husayn had died and that anti-Saqqawist forces had marched on Charikar, which Robert D. McChesney believes to be either highly exaggerated or completely false. On the 26th, Sayyid Husayn returned to Kabul alive and well, dispelling rumours about his death, and by the beginning of June, the routes via the Ghurband Valley and the Salang and Khawak Passes were firmly in the hands of Kalakani. On 29 May, 2300 men were sent north to reinforce the Ghurband front. On 31 May, Kalakani's army, which had advanced as far as Bamyan en route to Mazar-i Sharif had been routed and forced to retreat to Jabal al-Siraj. On 11 April, Nadir arrived in Khushi in the Logar valley. On 20 April, the son of Abd Allah Khan Tukhi, whose brother, Ata Muhammad, had raised a rebellion in Mazar-i Sharif against Kalakani, was hanged in Kabul. On 7 May 12,000 anti-Saqqawist forces occupied the Unay Pass and the Safidkhak Pass, while others were positioned on the lower slopes of the Paghman and Shakar Darrah. At this time, various anti-Saqqawist tribes planned a coordinated assault on Kabul. However, ethnic differences and poor communications led the attack to never materialize. On 2 June, Kalakani sent troops to Sar-i Chashmah, where they were ordered not to fire on anyone who swears allegiance as long as they were unarmed. On 23 May, Amanullah left Afghanistan for a last time, never to return. That same day, Kalakani sent 6500 men to conquer the Hazarahjat. Sometime before 19 June, Kalakani's forces won a victory at Bamyan, where they at first found themselves encircled, before the commander of the besieging Hazara forces was bribed to retreat. As of 23 June, anti-Saqqawist forces continued to occupy the Unay pass. As of 27 June, anti-Saqqawist forces had advanced two miles (3.2 km) from the Unay Pass towards Sar-i Chashmah. On 28 June, Kalakani's forces fought an offensive battle against Hazara militias at Qalah-i Karim. After capturing the village and burning it to the ground, they were ambushed by Hazaras who were subsequently driven off with artillery fire and forced to retreat into the mountains. After this victory, Kalakani's forces took control of the Unay Pass. On 29 June, Kalakani's forces advanced on Qalah-i Yurt. On 30 June, Kalakani's forces advanced toward Qalah-i Yurt after getting as far as Jawqul. On 1 July, Kalakani's forces looted homes in Takana, Jalriz and Kuhnah Khumar. On 2 July, Kalakani's forces suffered a defeat at Jawqul and were forced to retreat to Sar-i Chashmah, and then to Chandawul through Bazar-i Sar-i Chawk, Baghban Kuchan and Chandawul. On 3 July, Hamid Allah renewed the offensive, but was beaten back after being surrounded by Hazara militias, and was then pursued on his retreat as far as Sar-i Chashmah. As of 8 July, the Hazaras continued to fight Kalakani's forces and attacked a 5,000-man regiment, forcing them to retreat to Jalriz. However, the Hazarahs did not follow up this victory with an attack on Kabul - Robert D. McChesney points out that politics in Afghanistan tend to be extremely local, and once the Hazarahs secured control of their own regions, they had little interest in fighting for more territory.

On 10 July, Umar Khan promised to Kalakani that he would take upon himself the task of either forcing the Hazara's submission or crushing them. Faiz Mohammad quotes him as saying "Purdil Khan has taken Ghazni and captured Qandahar; Major General Muhammad Siddiq and Abd al-Qayyum Ibrahim Khayl Paghmani have advanced toward the Southern Province; and Muhammad Umar General Sur-i Satranj has defeated the opposition in numerous battles. I don't want to lose ground to my peers here. I should be able to make short work of the Hazarahs and extract their submission." He set off for Jalriz and linked up with soldiers who had been recently been skirmishing with Hazaras, won a victory at Sar-i Chasmah and conducted operations as far as Takana. However, success soon stalled, and after being wounded in the leg, Umar was forced to retreat, leaving the Hazaras to re-occupy all lost territory.

On 17 July, Hazara militias attacked Saqqawist forces in the Unay Pass and Qalah-i Safid, routing them and pursuing them to Takana and Jalriz. From 25 to 29 July, fighting took place in Jalriz, however on 30 July the Hazaras withdrew from Jalriz back to the Hazarahjat after they heard that Nadir suffered setbacks in the eastern province, which, for the time being, ended the Hazara's hopes of joining Nadir in a multi-pronged offensive toward Kabul. On 1 August the Hazaras began another offensive, attacking Qalah-i Majid (near Siyah Baghal) and Qalah-i Safid, a fort in the Unay Pass, chasing Kalakani's forces as far as Jalriz once again. On 3 August, Kalakani's forces were reportedly defeated at Jalriz once again. On 15 August, Hazara militias launched an offensive against Turkmen tribes who had pledged allegiance to Kalakani on 31 July, occupying positions in Darrah-i Suf, Kuh-i Shadyan and Marmal, and besieged fort Dih Dadi (a garrison village midway between the site of ancient balkh and Mazar-i Sharif).

On 18 August, an anti-Saqqawist uprising took place in Bamyan, Ghuri and Baghlan, blocking Kalakani's force's route to Turkistan and forcing them to retreat to Ghurband. On 21 August, the Sayyid of Shaykh Ali launched an offensive against Kalakani, advancing as far as Khanabad, Andarab and Ghurband. On 26 August, there were rumours in Kabul that Hazara settlers successfully attacked Mazar-i Sharif. In early September, the Saqqawists won their last victory by taking Jalalabad. On 23 September, an pro-Nadir uprising in Kandahar succeeded at driving out Kalakani's forces from the city. On 29 September, a pro-Nadir force under Shah Wali crossed the Durand Line and occupied Khushi. On the 30th, he sent a 1000-man force ahead to Tangi Waghjan, the gorge on the road to the Logar Valley. On 3 October, after an intense battle, anti-Saqqawist forces captured the town of Muhammad Aghah, placing themselves within striking distance of Kabul. Kalakani himself took part in this battle, trying to lift his soldier's spirits, to no avail. anti-Saqqawist forces continued to slowly push towards Kabul, seizing Charasya, Chihil Tan and Chihil Sutun on 5 October. By 7 October, Kalakani's forces had retreated from almost all territory outside Kabul, and prepared for their last stand. On 9 October, after dozens of hours of street fighting in Kabul, the Arg was put under siege. On 13 October, after several days of bombardment, Nadir's forces entered the Arg, and after a short but fierce battle, captured it, ending the civil war. Upon hearing this news, a small contingent of Kalakani's army which was besieged at Jabal al-Siraj resolved to surrender that same day.

On 15 October, Mohammed Nadir Shah arrived in Kabul after hearing word of Kalakani's defeat. He considered pardoning Kalakani, but pressure from loyal tribes led him to execute Kalakani on 1 November 1929. Kalakani, his brother, and 9 others were lined up against the west wall of the arg and shot. During the reign of Nadir, the Saqqawists attempted another uprising, the Kuhistan rebellion (July 1930), which was crushed within a week. Saqqawist activity continued until 1930 in Kuhdaman, and 1931 in Herat.

Upon winning the civil war, Nadir did not cede control of the Afghan throne to Amanullah, and this led to several rebellions. The first of these, the Shinwari rebellion and the Kuhistan rebellion (February–April 1930), occurred in 1930. In 1938, there was also the Ghilzai rebellion. In the 1940s, Mohammed Zahir Shah faced several tribal revolts, and the leader of the Zadran revolt, Mazrak Zadran, sought to restore Amanullah. During World War II, western press reported that Amanullah Khan was working as an agent for Nazi Germany in Berlin. It is believed he was involved in plans to regain his throne with Axis help.

According to "Resort to war: a data guide to inter-state, extra-state, intra-state, and non-state wars, 1816-2007", both sides suffered 7500 combat deaths during the civil war.

During the Afghan Civil War, there were incidents of rape and looting among Saqqawist troops. One such incident took place on 28 June 1929, when Saqqawists attacked the Hazara settlement of Qalah-i Karim, looting anything movable and driving off livestock. Another incident, which took place on 23 July 1929, was described by contemporary Afghan historian Fayz Muhammad as follows:

Following the anti-Saqqawist capture of Kabul in October 1929, Kabul was sacked by Nadir's forces. Some sources state that this sacking had been authorized by Nadir, but this contested by historian Vartan Gregorian.




</doc>
<doc id="26469" url="https://en.wikipedia.org/wiki?curid=26469" title="General recursive function">
General recursive function

In mathematical logic and computer science, a general recursive function (often shortened to recursive function) or μ-recursive function, is a partial function from natural numbers to natural numbers that is "computable" in an intuitive sense. In computability theory, it is shown that the μ-recursive functions are precisely the functions that can be computed by Turing machines (this is one of the theorems that supports the Church–Turing thesis). The μ-recursive functions are closely related to primitive recursive functions, and their inductive definition (below) builds upon that of the primitive recursive functions. However, not every μ-recursive function is a primitive recursive function—the most famous example is the Ackermann function.

Other equivalent classes of functions are the functions of lambda calculus and the functions that can be computed by Markov algorithms.

The subset of all "total" recursive functions with values in is known in computational complexity theory as the complexity class R.

The μ-recursive functions (or general recursive functions) are partial functions that take finite tuples of natural numbers and return a single natural number. They are the smallest class of partial functions that includes the initial functions and is closed under composition, primitive recursion, and the μ operator.

The smallest class of functions including the initial functions and closed under composition and primitive recursion (i.e. without minimisation) is the class of primitive recursive functions. While all primitive recursive functions are total, this is not true of partial recursive functions; for example, the minimisation of the successor function is undefined. The primitive recursive functions are a subset of the total recursive functions, which are a subset of the partial recursive functions. For example, the Ackermann function can be proven to be total recursive, and to be non-primitive.

Primitive or "basic" functions:

Operators (the domain of a function defined by an operator is the set of the values of the arguments such that every function application that must be done during the computation provides a well-defined result):

The strong equality operator formula_31 can be used to compare partial μ-recursive functions. This is defined for all partial functions "f" and "g" so that
holds if and only if for any choice of arguments either both functions are defined and their values are equal or both functions are undefined.

In the equivalence of models of computability, a parallel is drawn between Turing machines that do not terminate for certain inputs and an undefined result for that input in the corresponding partial recursive function.
The unbounded search operator is not definable by the rules of primitive recursion as those do not provide a mechanism for "infinite loops" (undefined values).

A normal form theorem due to Kleene says that for each "k" there are primitive recursive functions formula_33 and formula_34 such that for any μ-recursive function formula_35 with "k" free variables there is an "e" such that
The number "e" is called an index or Gödel number for the function "f". A consequence of this result is that any μ-recursive function can be defined using a single instance of the μ operator applied to a (total) primitive recursive function.

Minsky (1967) observes (as does Boolos-Burgess-Jeffrey (2002) pp. 94–95) that the U defined above is in essence the μ-recursive equivalent of the universal Turing machine:

A number of different symbolisms are used in the literature. An advantage to using the symbolism is a derivation of a function by "nesting" of the operators one inside the other is easier to write in a compact form. In the following we will abbreviate the string of parameters x, ..., x as x:





Example: Kleene gives an example of how to perform the recursive derivation of f(b, a) = b + a (notice reversal of variables a and b). He starts with 3 initial functions 

He arrives at:






</doc>
<doc id="26470" url="https://en.wikipedia.org/wiki?curid=26470" title="Rex Ingram (director)">
Rex Ingram (director)

Rex Ingram (born Reginald Ingram Montgomery Hitchcock, 15 January 1892 – 21 July 1950) was an Irish film director, producer, writer and actor. Director Erich von Stroheim once called him "the world's greatest director".

Born in Dublin, Ireland, Ingram was educated at Saint Columba's College, near Rathfarnham, County Dublin. He spent much of his adolescence living in the Old Rectory, Kinnitty, Birr, County Offaly, where his father was the Church of Ireland rector. Ingram emigrated to the United States in 1911.

His brother Francis joined the British Army and fought during World War I, during which he was awarded the Military Cross and rose to the rank of Colonel.

Ingram studied sculpture at the Yale University School of Art, where he contributed to campus humor magazine "The Yale Record". He soon moved into film, first taking acting work from 1913 and then writing, producing and directing. His first work as producer-director was in 1916 on the romantic drama "The Great Problem". He worked for Edison Studios, Fox Film Corporation, Vitagraph Studios, and then MGM, directing mainly action or supernatural films.

He moved to Metro in 1920, where he was under the supervision of executive June Mathis. Mathis and Ingram would go on to make four films together: "Hearts are Trumps", "The Four Horsemen of the Apocalypse", "The Conquering Power", and "Turn to the Right". It is believed the two were romantically involved. Ingram and Mathis had begun to grow distant when her new find, Rudolph Valentino, began to overshadow his own fame. Their relationship ended when Ingram eloped with Alice Terry in 1921.

Ingram married twice, first to actress Doris Pawn in 1917; this ended in divorce in 1920. He then married Alice Terry in 1921, with whom he remained for the rest of his life. Both marriages were childless. He and Terry relocated to the French Riviera in 1923. They formed a small studio in Nice and made several films on location in North Africa, Spain, and Italy, for MGM and others.

Amongst those who worked for Ingram at MGM on the Riviera during this period was the young Michael Powell, who later went on to direct (with Emeric Pressburger) "The Red Shoes" and other classics, and technician Leonti Planskoy. By Powell's own account, Ingram was a major influence on him, especially in regard to the themes of illusion, dreaming, magic and the surreal. David Lean said he was indebted to Ingram. MGM studio chief Dore Schary listed the top creative people in Hollywood as D. W. Griffith, Ingram, Cecil B. DeMille and Erich von Stroheim (in declining order of importance).

Carlos Clarens writes: "As Rex Ingram's films became more esoteric, his career declined. The coming of sound forced him to relinquish his studios in Nice. Rather than equip them for talking pictures, he chose instead to travel and pursue a writing career." 

Ingram made only one talkie, "Baroud", filmed for Gaumont British Pictures in Morocco. The film was not a commercial success; he then left the movie business, returning to Los Angeles to work as a sculptor and writer.

Interested in Islam as early as 1927, he converted to the faith in 1933.

For his contribution to the motion picture industry, he has a star on the Hollywood Walk of Fame at 1651 Vine Street.

Ingram died of a cerebral hemorrhage in North Hollywood on 21 July 1950, aged 58. He was interred in the Forest Lawn Memorial Park Cemetery in Glendale, California.

Critic Carlos Clarens wrote of Ingram: "A full-blown Irishman fascinated by the bizarre and the grotesque (he once employed a dwarf as a valet), Ingram was also a writer of some talent. Frequently pedestrian and pretentious, Ingram's films nevertheless contain splendid flashes of macabre fantasy, such as the ride of the Four Horsemen in the Valentino epic, or the 'ghoul visions' that bring about the death of the miser in "The Conquering Power". His more or less mystical bent was apparent in "Mare Nostrum" and "The Garden of Allah", which he filmed in the Mediterranean and North Africa, respectively."

Ingram's complete filmography as a director:



</doc>
<doc id="26471" url="https://en.wikipedia.org/wiki?curid=26471" title="Rat">
Rat

Rats are various medium-sized, long-tailed rodents. Species of rats are found throughout the order Rodentia, but stereotypical rats are found in the genus "Rattus". Other rat genera include "Neotoma" (pack rats), "Bandicota" (bandicoot rats) and "Dipodomys" (kangaroo rats).

Rats are typically distinguished from mice by their size. Generally, when someone discovers a large muroid rodent, its common name includes the term "rat", while if it is smaller, its name includes the term "mouse". The common terms "rat" and "mouse" are not taxonomically specific.

The best-known rat species are the black rat ("Rattus rattus") and the brown rat ("Rattus norvegicus"). This group, generally known as the Old World rats or true rats, originated in Asia. Rats are bigger than most Old World mice, which are their relatives, but seldom weigh over in the wild.

The term "rat" is also used in the names of other small mammals that are not true rats. Examples include the North American pack rats (aka wood rats) and a number of species loosely called kangaroo rats. Rats such as the bandicoot rat ("Bandicota bengalensis") are murine rodents related to true rats but are not members of the genus "Rattus".

Male rats are called "bucks"; unmated females, "does", pregnant or parent females, "dams"; and infants, "kittens" or "pups". A group of rats is referred to as a "mischief".

The common species are opportunistic survivors and often live with and near humans; therefore, they are known as commensals. They may cause substantial food losses, especially in developing countries. However, the widely distributed and problematic commensal species of rats are a minority in this diverse genus. Many species of rats are island endemics, some of which have become endangered due to habitat loss or competition with the brown, black, or Polynesian rat.

Wild rodents, including rats, can carry many different zoonotic pathogens, such as "Leptospira", "Toxoplasma gondii", and "Campylobacter". The Black Death is traditionally believed to have been caused by the microorganism "Yersinia pestis", carried by the tropical rat flea ("Xenopsylla cheopis"), which preyed on black rats living in European cities during the epidemic outbreaks of the Middle Ages; these rats were used as transport hosts. Another zoonotic disease linked to the rat is foot-and-mouth disease.
Rats become sexually mature at age 6 weeks, but reach social maturity at about 5 to 6 months of age. The average lifespan of rats varies by species, but many only live about a year due to predation.

The black and brown rats diverged from other Old World rats in the forests of Asia during the beginning of the Pleistocene.

The characteristic long tail of most rodents is a feature that has been extensively studied in various rat species models, which suggest three primary functions of this structure: thermoregulation, minor proprioception, and a nocifensive-mediated degloving response. Rodent tails—particularly in rat models—have been implicated with a thermoregulation function that follows from its anatomical construction. This particular tail morphology is evident across the family Muridae, in contrast to the bushier tails of Sciuridae, the squirrel family. The tail is hairless and thin skinned but highly vascularized, thus allowing for efficient countercurrent heat exchange with the environment. The high muscular and connective tissue densities of the tail, along with ample muscle attachment sites along its plentiful caudal vertebrae, facilitate specific proprioceptive senses to help orient the rodent in a three-dimensional environment. Lastly, murids have evolved a unique defense mechanism termed "degloving" that allows for escape from predation through the loss of the outermost integumentary layer on the tail. However, this mechanism is associated with multiple pathologies that have been the subject of investigation.

Multiple studies have explored the thermoregulatory capacity of rodent tails by subjecting test organisms to varying levels of physical activity and quantifying heat conduction via the animals' tails. One study demonstrated a significant disparity in heat dissipation from a rat's tail relative to its abdomen. This observation was attributed to the higher proportion of vascularity in the tail, as well as its higher surface-area-to-volume ratio, which directly relates to heat's ability to dissipate via the skin. These findings were confirmed in a separate study analyzing the relationships of heat storage and mechanical efficiency in rodents that exercise in warm environments. In this study, the tail was a focal point in measuring heat accumulation and modulation.

On the other hand, the tail's ability to function as a proprioceptive sensor and modulator has also been investigated. As aforementioned, the tail demonstrates a high degree of muscularization and subsequent innervation that ostensibly collaborate in orienting the organism. Specifically, this is accomplished by coordinated flexion and extension of tail muscles to produce slight shifts in the organism's center of mass, orientation, etc., which ultimately assists it with achieving a state of proprioceptive balance in its environment. Further mechanobiological investigations of the constituent tendons in the tail of the rat have identified multiple factors that influence how the organism navigates its environment with this structure. A particular example is that of a study in which the morphology of these tendons is explicated in detail. Namely, cell viability tests of tendons of the rat's tail demonstrate a higher proportion of living fibroblasts that produce the collagen for these fibers. As in humans, these tendons contain a high density of golgi tendon organs that help the animal assess stretching of muscle in situ and adjust accordingly by relaying the information to higher cortical areas associated with balance, proprioception, and movement.

The characteristic tail of murids also displays a unique defense mechanism known as "degloving" in which the outer layer of the integument can be detached in order to facilitate the animal's escape from a predator. This evolutionary selective pressure has persisted despite a multitude of pathologies that can manifest upon shedding part of the tail and exposing more interior elements to the environment. Paramount among these are bacterial and viral infection, as the high density of vascular tissue within the tail becomes exposed upon avulsion or similar injury to the structure. The degloving response is a nocifensive response, meaning that it occurs when the animal is subjected to acute pain, such as when a predator snatches the organism by the tail.

Specially bred rats have been kept as pets at least since the late 19th century. Pet rats are typically variants of the species brown rat - but black rats and giant pouched rats are also sometimes kept. Pet rats behave differently from their wild counterparts depending on how many generations they have been kept as pets. Pet rats do not pose any more of a health risk than pets such as cats or dogs. Tamed rats are generally friendly and can be taught to perform selected behaviors.

In 1895, Clark University in Worcester, Massachusetts, established a population of domestic albino brown rats to study the effects of diet and for other physiological studies. Over the years, rats have been used in many experimental studies, adding to our understanding of genetics, diseases, the effects of drugs, and other topics that have provided a great benefit for the health and wellbeing of humankind.

The aortic arches of the rat are among the most commonly studied in murine models due to marked anatomical homology to the human cardiovascular system. Both rat and human aortic arches exhibit subsequent branching of the brachiocephalic trunk, left common carotid artery, and left subclavian artery, as well as geometrically similar, nonplanar curvature in the aortic branches. Aortic arches studied in rats exhibit abnormalities similar to those of humans, including altered pulmonary arteries and double or absent aortic arches. Despite existing anatomical analogy in the inthrathoracic position of the heart itself, the murine model of the heart and its structures remains a valuable tool for studies of human cardiovascular conditions.

The rat's larynx has been used in experimentations that involve inhalation toxicity, allograft rejection, and irradiation responses. One experiment described four features of the rat's larynx. The first being the location and attachments of the thyroarytenoid muscle, the alar cricoarytenoid muscle, and the superior cricoarytenoid muscle, the other of the newly named muscle that ran from the arytenoid to a midline tubercle on the cricoid. The newly named muscles were not seen in the human larynx. In addition, the location and configuration of the laryngeal alar cartilage was described. The second feature was that the way the newly named muscles appear to be familiar to those in the human larynx. The third feature was that a clear understanding of how MEPs are distributed in each of the laryngeal muscles was helpful in understanding the effects of botulinum toxin injection. The MEPs in the posterior
cricoarytenoid muscle, lateral cricoarytenoid muscle, cricothyroid muscle, and superior
cricoarytenoid muscle were focused mostly at the midbelly. In addition, the medial thyroarytenoid muscle were focused at the midbelly while the lateral thyroarytenoid muscle MEPs were focused at the anterior third of the belly. The fourth and final feature that was cleared up was how the MEPs were distributed in the thyroarytenoid muscle. 

Laboratory rats have also proved valuable in psychological studies of learning and other mental processes (Barnett 2002), as well as to understand group behavior and overcrowding (with the work of John B. Calhoun on behavioral sink). A 2007 study found rats to possess metacognition, a mental ability previously only documented in humans and some primates.

Domestic rats differ from wild rats in many ways. They are calmer and less likely to bite; they can tolerate greater crowding; they breed earlier and produce more offspring; and their brains, livers, kidneys, adrenal glands, and hearts are smaller (Barnett 2002).

Brown rats are often used as model organisms for scientific research. Since the publication of the rat genome sequence, and other advances, such as the creation of a rat SNP chip, and the production of knockout rats, the laboratory rat has become a useful genetic tool, although not as popular as mice. When it comes to conducting tests related to intelligence, learning, and drug abuse, rats are a popular choice due to their high intelligence, ingenuity, aggressiveness, and adaptability. Their psychology seems in many ways similar to that of humans.

Entirely new breeds or "lines" of brown rats, such as the Wistar rat, have been bred for use in laboratories. Much of the genome of "Rattus norvegicus" has been sequenced.

Early studies found evidence both for and against measurable intelligence using the "g factor" in rats. Part of the difficulty of understanding animal cognition generally, is determining what to measure. One aspect of intelligence is the ability to learn, which can be measured using a maze like the T-maze. Experiments done in the 1920s showed that some rats performed better than others in maze tests, and if these rats were selectively bred, their offspring also performed better, suggesting that in rats an ability to learn was heritable in some way.

Rat meat is a food that, while taboo in some cultures, is a dietary staple in others.

Rats have been used as working animals. Tasks for working rats include the sniffing of gunpowder residue, demining, acting and animal-assisted therapy.

Rats have a keen sense of smell and are easy to train. These characteristics have been employed, for example, by the Belgian non-governmental organization APOPO, which trains rats (specifically African giant pouched rats) to detect landmines and diagnose tuberculosis through smell.

Rats can serve as zoonotic vectors for certain pathogens and thus spread disease, such as bubonic plague, Lassa fever, leptospirosis, and Hantavirus infection.

They are also associated with human dermatitis because they are frequently infested with blood feeding rodent mites such as the tropical rat mite ("Ornithonyssus bacoti") and spiny rat mite ("Laelaps echidnina"), which will opportunistically bite and feed on humans, where the condition is known as rat mite dermatitis"."

Rats have long been considered deadly pests. Once considered a modern myth, the rat flood in India occurs every fifty years, as armies of bamboo rats descend upon rural areas and devour everything in their path. Rats have long been held up as the chief villain in the spread of the Bubonic Plague; however, recent studies show that rats alone could not account for the rapid spread of the disease through Europe in the Middle Ages. Still, the Centers for Disease Control does list nearly a dozen diseases directly linked to rats.

Most urban areas battle rat infestations. A 2015 study by the American Housing Survey (AHS) found that eighteen percent of homes in Philadelphia showed evidence of rodents. Boston, New York City, and Washington, D.C., also demonstrated significant rodent infestations. Indeed, rats in New York City are famous for their size and prevalence. The urban legend that the rat population in Manhattan equals that of its human population was definitively refuted by Robert Sullivan in his book "Rats" but illustrates New Yorkers' awareness of the presence, and on occasion boldness and cleverness, of the rodents. New York has specific regulations for eradicating rats; multifamily residences and commercial businesses must use a specially trained and licensed rat catcher.

Rats have the ability to swim up sewer pipes into toilets. Rats will infest any area that provides shelter and easy access to sources of food and water, including under sinks, near garbage, and inside walls or cabinets. 

When introduced into locations where rats previously did not exist, they can wreak an enormous degree of environmental degradation. "Rattus rattus", the black rat, is considered to be one of the world's worst invasive species. Also known as the ship rat, it has been carried worldwide as a stowaway on seagoing vessels for millennia and has usually accompanied men to any new area visited or settled by human beings by sea. The similar species "Rattus norvegicus", the brown rat or wharf rat, has also been carried worldwide by ships in recent centuries.

The ship or wharf rat has contributed to the extinction of many species of wildlife, including birds, small mammals, reptiles, invertebrates, and plants, especially on islands. True rats are omnivorous, capable of eating a wide range of plant and animal foods, and have a very high birth rate. When introduced to a new area, they quickly reproduce to take advantage of the new food supply. In particular, they prey on the eggs and young of forest birds, which on isolated islands often have no other predators and thus have no fear of predators. Some experts believe that rats are to blame for between forty percent and sixty percent of all seabird and reptile extinctions, with ninety percent of those occurring on islands. Thus man has indirectly caused the extinction of many species by accidentally introducing rats to new areas.

Rats are found in nearly all areas of Earth which are inhabited by human beings. The only rat-free continent is Antarctica, which is too cold for rat survival outdoors, and its lack of human habitation does not provide buildings to shelter them from the weather. However, rats have been introduced to many of the islands near Antarctica, and because of their destructive effect on native flora and fauna, efforts to eradicate them are ongoing. In particular, Bird Island (just off rat-infested South Georgia Island), where breeding seabirds could be badly affected if rats were introduced, is subject to special measures and regularly monitored for rat invasions.

As part of island restoration, some islands' rat populations have been eradicated to protect or restore the ecology. Hawadax Island, Alaska was declared rat free after 229 years and Campbell Island, New Zealand after almost 200 years. Breaksea Island in New Zealand was declared rat free in 1988 after an eradication campaign based on a successful trial on the smaller Hawea Island nearby.

In January 2015, an international "Rat Team" set sail from the Falkland Islands for the British Overseas Territory of South Georgia and the South Sandwich Islands on board a ship carrying three helicopters and 100 tons of rat poison with the objective of "reclaiming the island for its seabirds". Rats have wiped out more than 90% of the seabirds on South Georgia, and the sponsors hope that once the rats are gone, it will regain its former status as home to the greatest concentration of seabirds in the world. The South Georgia Heritage Trust, which organized the mission describes it as "five times larger than any other rodent eradication attempted worldwide". That would be true if it were not for the rat control program in Alberta (see below).

The Canadian province of Alberta is notable for being the largest inhabited area on Earth which is free of true rats due to very aggressive government rat control policies. It has large numbers of native pack rats, also called bushy-tailed wood rats, but they are forest-dwelling vegetarians which are much less destructive than true rats.

Alberta was settled relatively late in North American history and only became a province in 1905. Black rats cannot survive in its climate at all, and brown rats must live near people and in their structures to survive the winters. There are numerous predators in Canada's vast natural areas which will eat non-native rats, so it took until 1950 for invading rats to make their way over land from Eastern Canada. Immediately upon their arrival at the eastern border with Saskatchewan, the Alberta government implemented an extremely aggressive rat control program to stop them from advancing further. A systematic detection and eradication system was used throughout a control zone about long and wide along the eastern border to eliminate rat infestations before the rats could spread further into the province. Shotguns, bulldozers, high explosives, poison gas, and incendiaries were used to destroy rats. Numerous farm buildings were destroyed in the process. Initially, tons of arsenic trioxide were spread around thousands of farm yards to poison rats, but soon after the program commenced the rodenticide and medical drug warfarin was introduced, which is much safer for people and more effective at killing rats than arsenic.

Forceful government control measures, strong public support and enthusiastic citizen participation continue to keep rat infestations to a minimum. The effectiveness has been aided by a similar but newer program in Saskatchewan which prevents rats from even reaching the Alberta border. Alberta still employs an armed rat patrol to control rats along Alberta's borders. About ten single rats are found and killed per year, and occasionally a large localized infestation has to be dug out with heavy machinery, but the number of permanent rat infestations is zero.

Ancient Romans did not generally differentiate between rats and mice, instead referring to the former as "mus maximus" (big mouse) and the latter as "mus minimus" (little mouse).

On the Isle of Man, there is a taboo against the word "rat".

The rat (sometimes referred to as a mouse) is the first of the twelve animals of the Chinese zodiac. People born in this year are expected to possess qualities associated with rats, including creativity, intelligence, honesty, generosity, ambition, a quick temper and wastefulness. People born in a year of the rat are said to get along well with "monkeys" and "dragons", and to get along poorly with "horses".
In Indian tradition, rats are seen as the vehicle of Ganesha, and a rat's statue is always found in a temple of Ganesh. In the northwestern Indian city of Deshnoke, the rats at the Karni Mata Temple are held to be destined for reincarnation as Sadhus (Hindu holy men). The attending priests feed milk and grain to the rats, of which the pilgrims also partake.

European associations with the rat are generally negative. For instance, "Rats!" is used as a substitute for various vulgar interjections in the English language. These associations do not draw, "per se", from any biological or behavioral trait of the rat, but possibly from the association of rats (and fleas) with the 14th-century medieval plague called the Black Death. Rats are seen as vicious, unclean, parasitic animals that steal food and spread disease. However, some people in European cultures keep rats as pets and conversely find them to be tame, clean, intelligent, and playful.

Rats are often used in scientific experiments; animal rights activists allege the treatment of rats in this context is cruel. The term "lab rat" is used, typically in a self-effacing manner, to describe a person whose job function requires them to spend a majority of their work time engaged in bench-level research (such as postgraduate students in the sciences).

Rats are frequently blamed for damaging food supplies and other goods, or spreading disease. Their reputation has carried into common parlance: in the English language, "rat" is often an insult or is generally used to signify an unscrupulous character; it is also used, as a synonym for the term "nark", to mean an individual who works as a police informant or who has turned state's evidence. Writer/director Preston Sturges created the humorous alias "Ratskywatsky" for a soldier who seduced, impregnated, and abandoned the heroine of his 1944 film, "The Miracle of Morgan's Creek". It is a term (noun and verb) in criminal slang for an informant – "to rat on someone" is to betray them by informing the authorities of a crime or misdeed they committed. Describing a person as "rat-like" usually implies he or she is unattractive and suspicious.

Among trade unions, the word "rat" is also a term for nonunion employers or breakers of union contracts, and this is why unions use inflatable rats.

Depictions of rats in fiction are historically inaccurate and negative. The most common falsehood is the squeaking almost always heard in otherwise realistic portrayals (i.e. nonanthropomorphic). While the recordings may be of actual squeaking rats, the noise is uncommon – they may do so only if distressed, hurt, or annoyed. Normal vocalizations are very high-pitched, well outside the range of human hearing. Rats are also often cast in vicious and aggressive roles when in fact, their shyness helps keep them undiscovered for so long in an infested home.

The actual portrayals of rats vary from negative to positive with a majority in the negative and ambiguous. The rat plays a villain in several mouse societies; from Brian Jacques's "Redwall" and Robin Jarvis's "The Deptford Mice", to the roles of Disney's Professor Ratigan and Kate DiCamillo's Roscuro and Botticelli. They have often been used as a mechanism in horror; being the titular evil in stories like "The Rats" or H.P. Lovecraft's "The Rats in the Walls" and in films like "Willard" and "Ben". Another terrifying use of rats is as a method of torture, for instance in Room 101 in George Orwell's "Nineteen Eighty-Four" or "The Pit and the Pendulum" by Edgar Allan Poe.

Selfish helpfulness —those willing to help for a price— has also been attributed to fictional rats. Templeton, from E. B. White's "Charlotte's Web", repeatedly reminds the other characters that he is only involved because it means more food for him, and the cellar-rat of John Masefield's "The Midnight Folk" requires bribery to be of any assistance.

By contrast, the rats appearing in the Doctor Dolittle books tend to be highly positive and likeable characters, many of whom tell their remarkable life stories in the Mouse and Rat Club established by the animal-loving doctor.

Some fictional works use rats as the main characters. Notable examples include the society created by O'Brien's "Mrs. Frisby and the Rats of NIMH", and others include "Doctor Rat", and Rizzo the Rat from The Muppets. Pixar's 2007 animated film "Ratatouille" is about a rat described by Roger Ebert as "earnest... lovable, determined, [and] gifted" who lives with a Parisian garbage-boy-turned-chef.

"Mon oncle d'Amérique" (""My American Uncle""), a 1980 French film, illustrates Henri Laborit's theories on evolutionary psychology and human behaviors by using short sequences in the storyline showing lab rat experiments.

In Harry Turtledove's science fiction novel "Homeward Bound", humans unintentionally introduce rats to the ecology at the home world of an alien race which previously invaded Earth and introduced some of its own fauna into its environment. A. Bertram Chandler pitted the space-bound protagonist of a long series of novels, Commodore Grimes, against giant, intelligent rats who took over several stellar systems and enslaved their human inhabitants. "The Stainless Steel Rat" is nickname of the (human) protagonist of a series of humorous science fiction novels written by Harry Harrison.

Wererats, therianthropic creatures able to take the shape of a rat, have appeared in the fantasy or horror genre since the 1970s. The term is a neologism coined in analogy to werewolf. The concept has since become common in role playing games like "Dungeons & Dragons" and fantasy fiction like the "" series..

One of the oldest and most historic stories about rats is "The Pied Piper of Hamelin", in which a rat-catcher leads away an infestation with enchanted music. The piper is later refused payment, so he in turn leads away the town's children. This tale, traced to Germany around the late 13th century, has inspired adaptations in film, theatre, literature, and even opera. The subject of much research, some theories have intertwined the tale with events related to the Black Plague, in which black rats played an important role. Fictional works based on the tale that focus heavily on the rat aspect include Pratchett's "The Amazing Maurice and his Educated Rodents", and Belgian graphic novel "" ("The Ball of the Dead Rat").





</doc>
<doc id="26472" url="https://en.wikipedia.org/wiki?curid=26472" title="Adobe RoboHelp">
Adobe RoboHelp

Adobe RoboHelp is a help authoring tool (HAT) developed and published by Adobe Inc. for Windows. RoboHelp was created by Gen Kiyooka, and Blue Sky Software released version 1.0 in January 1992.

Blue Sky Software was founded in 1990 and changed its name to eHelp Corporation on 4 April 2000. Macromedia acquired eHelp Corporation on 24 October 2003. Macromedia was, in turn, acquired by Adobe Systems on 3 December 2005. Adobe Systems has developed and released nine successive versions of RoboHelp since 2007.

Adobe RoboHelp can generate help files in the following file formats:

The version numbering systems used by Blue Sky Software/eHelp Corporation, Macromedia, and Adobe Systems induced some head-scratching, especially among longtime RoboHelp users. For example, the first version of RoboHelp released by Adobe Systems in January 2007 was the 14th version of the software, but Adobe Systems decided to continue the numbering convention from Macromedia and thus gave this version the number 6...and dropped the X used in the previous version, RoboHelp X5. This decision caused confusion because Blue Sky Software released RoboHelp 6.0 in 1998. Adobe Systems continued with that numbering system and used versions 7 through 11 for successive versions of RoboHelp released from September 2007 to January 2014. With the introduction of Adobe RoboHelp 2015 in June 2015, Adobe Systems used a new numbering system with the release year instead of a version number and continues to use this convention with successive versions. This new version numbering system has removed any uncertainty about which version is the most recent. The current version, Adobe RoboHelp 2019, is the 22nd version of the software released in RoboHelp's 26-year history.
The network-specific version of Adobe RoboHelp, Adobe RoboHelp Server, is released on a separate schedule. Adobe RoboHelp Server, formerly RoboSource Control, provides version control for and deployment of online help systems on a network. The current version of Adobe RoboHelp Server, version 10, was released on 12 April 2016.


</doc>
<doc id="26473" url="https://en.wikipedia.org/wiki?curid=26473" title="Replicant">
Replicant

A replicant is a fictional bioengineered being in the 1982 film "Blade Runner", and in its 2017 sequel "Blade Runner 2049". The Nexus-series of replicants are virtually identical to adult humans but have superior strength, speed, agility, resilience, and intelligence, to varying degrees depending on the model. A replicant can only be detected by means of the fictional Voight-Kampff test, in which emotional responses are provoked and a replicant's nonverbal responses differ from those of a human. A version of the test, referred to as a Baseline, is taken by K in "Blade Runner 2049" to detect any mental or empathic damage, for which failure means retirement. Throughout the franchise the euphemism "retire" is used when referring to killing Replicants.

Nexus-6 replicants (e.g. Roy Batty) have a safety mechanism, namely a four-year lifespan, to prevent them from developing empathic abilities (and, therefore, immunity to the test). Nexus-7 replicants (e.g. Rachael) were limited experimental models by Tyrell Corporation with a capability to reproduce. Nexus-8 replicants (e.g. Sapper Morton, Freysa), also by Tyrell Corporation, have an open-ended lifespan; however, a rebellion resulting in the "Blackout of 2022" led them to be discontinued and hunted down for retirement. Nexus-9 replicants (e.g. K), by Wallace Corporation, are also open-ended but have increased compliance which makes them incapable of not following human orders, and are thus full slaves. Replicants are sometimes referred to by the slur "skin-job".

In his novel "Do Androids Dream of Electric Sheep?" (the inspiration for "Blade Runner"), Philip K. Dick used the term android (or "andy"), but director Ridley Scott wanted a new term that the audience would not have any preconceptions about. As David Peoples was re-writing the screenplay, he consulted his daughter, who was involved in microbiology and biochemistry. She suggested the term "replicating", the biological process of a cell making a copy of itself. From that, either Peoples or Scott—each would later recall it was the other—came up with "replicant", and it was inserted into Hampton Fancher's screenplay.

Prior to the events of the film, replicants became illegal on Earth after a bloody off-world mutiny by a band of Nexus-6 models. Two weeks before the starting point of the film, six Nexus-6 replicants escaped the off-world colonies, killing 23 people and taking a shuttle to Earth; the film focuses on the pursuit of the replicants by Rick Deckard, a category of police-officer bounty-hunter called a "Blade Runner", who investigates, tests, and retires replicants found on Earth.

Nexus-6 replicants had been designed to copy humans in every way except for their emotions. The Tyrell Corporation "began to recognize in them a strange obsession", and in order to be able to control them better, started to implant false memories into the replicants in order to give them the years of experiences that humans take for granted; these memories created "a cushion or pillow for their emotions".

Early in the film, Captain Bryant tells Deckard that the Nexus-6 units' possible eventual development of emotional responses was the reason the Tyrell Corporation designed them with a four-year lifespan. Dr Eldon Tyrell states in the film they were made as well as they could be with a limited lifespan. All attempts to increase a replicant's lifespan has resulted in death. The unsuccessful procedures they tried were:

Deckard had no experience with Nexus-6 replicants at the beginning of the film; he and Captain Bryant are puzzled as to why they have risked coming back to Earth and Deckard is unsure how effective the Voight-Kampff test would be on them, as they appeared to have developed human emotion.

Escaped replicants (all Nexus-6 models):

Other replicants (possible Nexus-7 models):

According to Deckard, a normal replicant can usually be discovered using the Voight-Kampff test, after being given 20–30 questions. Rachael answers over 100 questions before Deckard determines she is a replicant. The theatrical cut's voice-over ending said that, as an experimental replicant, Rachael did not have the four-year life but the Director's Cut did not address this. Scott said that he had wanted to cast a young actress in the role to emphasise Rachael's naivety and unworldliness.

The second film further developed Rachael's origin, and gave significantly more details about its radical design. It revealed most significantly that it was an experimental reproductive model of replicant (which ultimately produced a daughter with Deckard) with a high percentage of human organs in comparison to replicant parts. It has an internal human bone structure, natural eyes, hair, skin and reproductive organs, which explains its ability to pass as human. Thus, the film suggests it was only its brain and possibly other vital organs which were the replicant parts. As Rachael died during childbirth, its possible survival beyond the four years was undetermined. 

In "Do Androids Dream of Electric Sheep?", the android manufacturer, known as the Rosen Corporation, did not know how to manufacture an android capable of living beyond four years. The super-soldiers in "Soldier"—the spiritual successor to "Blade Runner"—are intended to be replicants in the film.

The dark, paranoid atmosphere of "Blade Runner", and its multiple versions, add fuel to the speculation and debate over this issue. In "Do Androids Dream of Electric Sheep?", Rick Deckard (the protagonist) is at one point tricked into following an android, whom he believes to be a police officer, to a fake police station. Deckard then escapes and retires some androids there before returning to his own police station. Deckard takes the Voight-Kampff test and passes, confirming that he is a human.

Harrison Ford, who played Deckard in the film, has said that he did not think Deckard is a replicant, and has said that he and director Ridley Scott had discussions that ended in the agreement that the character was human. According to several interviews with Scott, Deckard "is" a replicant. Deckard collects photographs which are seen on his piano, yet has no obvious family beyond a reference to his ex-wife (who called him a "cold fish"). The film's Supervising Editor Terry Rawlings remembers that Scott "purposefully put Harrison in the background of the shot, and slightly out of focus, so that you'd only notice his eyes were glowing if you were paying attention... Ridley himself may have definitely felt that Deckard is a replicant, but still, by the end of the picture, he intended to leave it up to the viewer."

Author Will Brooker has written that the dream may not be unique to Deckard and that unicorn dreams may be a personal touch added to some or all of the Nexus-6 replicants' brains. Since we are not privy to the dreams of the other replicants, this is unknown. From this, one could also derive that Gaff is a replicant and may share the same embedded memory.

Paul Sammon, author of "Future Noir: The Making of Blade Runner", has suggested in interviews that Deckard may be a Nexus-7, a new generation of replicant who possesses no superhuman strength or intelligence but does have neurological features that complete the illusion of humanity. Scott has mentioned Nexus-7 and Nexus-8 replicants as possibilities in a sequel to the film. Sammon also suggests that Nexus-7 replicants may not have a set lifespan (i.e., they could be immortal).

Sammon wrote that Scott thought it would be more provocative to imply that Deckard is a replicant. This ties back into the theme of "what is it to be human?" What is important is not whether Deckard is a replicant but that the ambiguity blurs the line between humans and replicants.

When Scott was asked about the possibility of a "Blade Runner" sequel in October 2012, he said, "It's not a rumor—it's happening. With Harrison Ford? I don't know yet. Is he too old? Well, he was a Nexus-6, so we don't know how long he can live. And that's all I'm going to say at this stage". 

The sequel "Blade Runner 2049" was released in October 2017, which revisited the question while leaving the answer deliberately ambiguous. The film reveals that Deckard was able to naturally conceive a child with Rachael, and this was possible because she was an experimental prototype (designated Nexus-7), the first and only attempt to design a replicant model capable of procreating on its own. The Tyrell Corporation eventually went bankrupt after several replicant rebellions and was bought out by Wallace Corporation, which took over replicant production, but it could not duplicate Tyrell's success with Rachael. Niander Wallace, the sinister CEO of the company, captures Deckard and muses to him about how he met her and fell in love: Wallace thinks it sounds too perfect, and ponders if Deckard himself was designed to fall in love with Rachael, as part of Tyrell's experiment to develop replicants that can procreate (in which case Deckard is a replicant) - but Wallace also admits that with Tyrell dead and the records destroyed, he'll never know, and it is equally possible that Tyrell never planned for Rachael and Deckard to fall in love (in which case, Deckard is probably human).

Although the press kit for the film explicitly defines a replicant as "A genetically engineered creature composed entirely of organic substance", the physical make-up of the replicants themselves is not clear. In the films's preamble, it is noted that replicants are said to be the result of "advanced robot evolution." The preamble also states that replicants were created by genetic engineers. Characters mention that replicants have eyes and brains like humans, and they are seen to bleed when injured. The only way of telling a replicant from a human is to ask a series of questions and analyze emotional responses, suggesting they might be entirely, or almost entirely, organic. The film also shows that at least certain body parts of a replicant are separately engineered and assembled, as shown with Hannibal Chew, a genetic engineer who specifically made replicant eyes. In a deleted scene, J.F. Sebastian was stated to have made replicant hands along with his own personal robotic toys.

During the creation process of a replicant, their physical and mental capacities are separately ranked on a A to C system and designated for each replicant with the C level representing below normal human ability, B level being equal to a normal human and A being above normal human ability, the latter of which leads to superhuman physicality or genius level intelligence. 

"Do Androids Dream of Electric Sheep?" makes mention of the biological components of the androids, but also alludes to mechanical aspects commonly found in other material relating to robots. It states that the bone marrow can be tested to prove whether it is from a human or replicant.

In May 2012, Scott confirmed that the replicants were biological in nature, and contrasted them to the androids in the "Alien" series: Roy Batty was an evolved... He wasn't an engine. If I cut him open, there wasn't metal, he was grown... and then within twenty years you get the first bill not passed in the Senate where they applied for replication of animals, sheep and goats and cattle and animals and they turned it down, but if you can do that, then you can do human beings. If you go deeper into it and say 'Yeah, but if you are going to grow a human being, does he start that big and I've got to see him through everything?'

I don't want to answer the question, because of course he does... Ash in "Alien" had nothing to do with Roy Batty, because Roy Batty is more humanoid, whereas Ash was more metal.

The sequel "Blade Runner 2049" was released in October 2017. In the intervening 30 years, several major events occurred and new replicant lines were introduced.

The sequel retroactively establishes that Rachael was part of a short-lived prototype line of replicants designated Nexus-7, which was not only intended as a test to make replicants more mentally stable with implanted memories, but to develop replicants capable of naturally conceiving children on their own (all other models before or since are sterile). Rachael died in childbirth in 2021, and the child was hidden by the replicant underground.

In 2020, Tyrell Corporation introduced the Nexus-8 replicant, built with open lifespans not limited to only four years. Tyrell himself had been killed during the events of the first movie in November 2019, and the secret of producing replicants that can procreate died with him. The Nexus-8 went into mass production, but a new wave of replicant rebellions occurred, culminating in rogue Nexus-8's detonating a nuclear weapon in orbit over the western United States, to create an electromagnetic pulse that wiped out all of the electronic records. The Blackout destroyed most records about replicants, making it difficult for humans to track them down on Earth, but the terrorist attack led to mass purges and complete shutdown of Nexus-8 production (though many existing units were able to go into hiding in the chaos). 

In 2036, however, genetic engineer Niander Wallace designed a new line of Nexus-9 replicants. They also have an open lifespan, but were designed to be unable to resist orders given by a human, even if that order is to commit suicide. Wallace Corporation had solved a global food crisis with genetically modified crops, which combined with the demonstrated effectiveness of Nexus-9 programming, allowed him to successfully push for the ban on replicant production to be lifted. 

By 2049, Nexus-9 replicants are extensively used across Earth and the off-world colonies, but they also necessitate special police units tasked with tracking down any that might go rogue, and any remaining Nexus-8's still in hiding (Nexus-7 was never mass-produced, and all the older models like Nexus-6 simply died of old age decades before). These police units are once again called Blade Runners, but are now openly composed of self-aware replicants (such as officer KD6-3.7), who are fully aware that they are replicants themselves. Like Nexus-7, Nexus-9 models also have implanted memories to aid their mental stability, though they are aware that these memories are fabrications. Additionally the use of real memories in replicants is illegal, all memories have to be original fabrications.



</doc>
<doc id="26474" url="https://en.wikipedia.org/wiki?curid=26474" title="Roman Jakobson">
Roman Jakobson

Roman Osipovich Jakobson (; October 11, 1896 – July 18, 1982) was a Russian-American linguist and literary theorist.

A pioneer of structural linguistics, Jakobson was one of the most celebrated and influential linguists of the twentieth century. With Nikolai Trubetzkoy, he developed revolutionary new techniques for the analysis of linguistic sound systems, in effect founding the modern discipline of phonology. Jakobson went on to extend similar principles and techniques to the study of other aspects of language such as syntax, morphology and semantics. He made numerous contributions to Slavic linguistics, most notably two studies of Russian case and an analysis of the categories of the Russian verb. Drawing on insights from C. S. Peirce's semiotics, as well as from communication theory and cybernetics, he proposed methods for the investigation of poetry, music, the visual arts, and cinema.

Through his decisive influence on Claude Lévi-Strauss and Roland Barthes, among others, Jakobson became a pivotal figure in the adaptation of structural analysis to disciplines beyond linguistics, including philosophy, anthropology, and literary theory; his development of the approach pioneered by Ferdinand de Saussure, known as "structuralism", became a major post-war intellectual movement in Europe and the United States. Meanwhile, though the influence of structuralism declined during the 1970s, Jakobson's work has continued to receive attention in linguistic anthropology, especially through the ethnography of communication developed by Dell Hymes and the semiotics of culture developed by Jakobson's former student Michael Silverstein. Jakobson's concept of underlying linguistic universals, particularly his celebrated theory of distinctive features, decisively influenced the early thinking of Noam Chomsky, who became the dominant figure in theoretical linguistics during the second half of the twentieth century.

Jakobson was born in Russia on 11 October 1896 to a well-to-do family of Jewish descent, the industrialist Osip Jakobson and chemist Anna Volpert Jakobson, and he developed a fascination with language at a very young age. He studied at the Lazarev Institute of Oriental Languages and then at the Historical-Philological Faculty of Moscow University. As a student he was a leading figure of the Moscow Linguistic Circle and took part in Moscow's active world of avant-garde art and poetry. The linguistics of the time was overwhelmingly neogrammarian and insisted that the only scientific study of language was to study the history and development of words across time (the diachronic approach, in Saussure's terms). Jakobson, on the other hand, had come into contact with the work of Ferdinand de Saussure, and developed an approach focused on the way in which language's structure served its basic function (synchronic approach) – to communicate information between speakers. Jakobson was also well known for his critique of the emergence of sound in film. Jakobson received a master's degree from Moscow University in 1918.

Although he was initially an enthusiastic supporter of the Bolshevik revolution, Jakobson soon became disillusioned as his early hopes for an explosion of creativity in the arts fell victim to increasing state conservatism and hostility. He left Moscow for Prague in 1920, where he worked as a member of the Soviet diplomatic mission while continuing with his doctoral studies. Then, in 1933, he took up a chair at Brno. Living in Czechoslovakia meant that Jakobson was physically close to the linguist who would be his most important collaborator during the 1920s and 1930s, Prince Nikolai Trubetzkoy, who fled Russia at the time of the Revolution and took up a chair at Vienna in 1922. In 1926 the Prague school of linguistic theory was established by the professor of English at Charles University, Vilém Mathesius, with Jakobson as a founding member and a prime intellectual force (other members included Nikolai Trubetzkoy, René Wellek and Jan Mukařovský). Jakobson immersed himself in both the academic and cultural life of pre-World War II Czechoslovakia and established close relationships with a number of Czech poets and literary figures. Jakobson received his Ph.D. from Charles University in 1930. He became a professor at Masaryk University in Brno in 1933. He also made an impression on Czech academics with his studies of Czech verse.

Jakobson escaped from Prague in early March 1939 via Berlin for Denmark, where he was associated with the Copenhagen linguistic circle, and such intellectuals as Louis Hjelmslev. He fled to Norway on 1 September 1939, and in 1940 walked across the border to Sweden, where he continued his work at the Karolinska Hospital (with works on aphasia and language competence). When Swedish colleagues feared a possible German occupation, he managed to leave on a cargo ship, together with Ernst Cassirer (the former rector of Hamburg University) to New York City in 1941 to become part of the wider community of intellectual émigrés who fled there.

In New York, he began teaching at The New School, still closely associated with the Czech émigré community during that period. At the École libre des hautes études, a sort of Francophone university-in-exile, he met and collaborated with Claude Lévi-Strauss, who would also become a key exponent of structuralism. He also made the acquaintance of many American linguists and anthropologists, such as Franz Boas, Benjamin Whorf, and Leonard Bloomfield. When the American authorities considered "repatriating" him to Europe, it was Franz Boas who actually saved his life. After the war, he became a consultant to the International Auxiliary Language Association, which would present Interlingua in 1951.

In 1949 Jakobson moved to Harvard University, where he remained until his retirement in 1967. His universalizing structuralist theory of phonology, based on a markedness hierarchy of distinctive features, achieved its canonical exposition in a book published in the United States in 1951, jointly authored by Roman Jakobson, C. Gunnar Fant and Morris Halle. In the same year, Jakobson's theory of 'distinctive features' made a profound impression on the thinking of young Noam Chomsky, in this also way influencing generative linguistics.

In his last decade, Jakobson maintained an office at the Massachusetts Institute of Technology, where he was an honorary Professor Emeritus. In the early 1960s Jakobson shifted his emphasis to a more comprehensive view of language and began writing about communication sciences as a whole. He converted to Eastern Orthodox Christianity in 1975.

Jakobson died in Cambridge, Massachusetts on 18 July 1982. His widow died in 1986. His first wife, who was born in 1908, died in 2000.

According to Jakobson's own personal reminiscences, the most decisive stage in the development of his thinking was the period of revolutionary anticipation and upheaval in Russia between 1912 and 1920, when, as a young student, he fell under the spell of the celebrated Russian futurist wordsmith and linguistic thinker Velimir Khlebnikov.
Offering a slightly different picture, the preface to the second edition of "The Sound Shape of Language" argues that this book represents the fourth stage in "Jakobson's quest to uncover the function and structure of sound in language." The first stage was roughly the 1920s to 1930s where he collaborated with Trubetzkoy, in which they developed the concept of the phoneme, and elucidated the structure of phonological systems. The second stage, from roughly the late 1930s to the 1940s, during which he developed the notion that "binary distinctive features" were the foundational element in language, and that such distinctiveness is "mere otherness" or differentiation. In the third stage in Jakobson's work, from the 1950s to 1960s, he worked with the acoustician C. Gunnar Fant and Morris Halle (a student of Jakobson's) to consider the acoustic aspects of distinctive features.

Influenced by the Organon-Model by Karl Bühler, Jakobson distinguishes six communication functions, each associated with a dimension or factor of the communication process [n.b. – Elements from Bühler's theory appear in the diagram below in yellow and pink, Jakobson's elaborations in blue]:

One of the six functions is always the dominant function in a text and usually related to the type of text. In poetry, the dominant function is the poetic function: the focus is on the message itself. The true hallmark of poetry is according to Jakobson "the projection of the principle of equivalence from the axis of selection to the axis of combination". Very broadly speaking, it implies that poetry successfully combines and integrates form and function, that poetry turns the poetry of grammar into the grammar of poetry, so to speak. Jakobson's theory of communicative functions was first published in "Closing Statements: Linguistics and Poetics" (in Thomas A. Sebeok, "Style In Language", Cambridge Massachusetts, MIT Press, 1960, pp. 350–377). Despite its wide adoption, the six-functions model has been criticized for lacking specific interest in the "play function" of language that, according to an early review by Georges Mounin, is "not enough studied in general by linguistics researchers".

Jakobson's three principal ideas in linguistics play a major role in the field to this day: linguistic typology, markedness, and linguistic universals. The three concepts are tightly intertwined: typology is the classification of languages in terms of shared grammatical features (as opposed to shared origin), markedness is (very roughly) a study of how certain forms of grammatical organization are more "optimized" than others, and linguistic universals is the study of the general features of languages in the world. He also influenced Nicolas Ruwet's paradigmatic analysis.

Jakobson has also influenced Friedemann Schulz von Thun's four sides model, as well as Michael Silverstein's metapragmatics, Dell Hymes's ethnography of communication and ethnopoetics, the psychoanalysis of Jacques Lacan, and philosophy of Giorgio Agamben.

Jakobson's legacy among researchers specializing in Slavics, and especially Slavic linguistics in North America, has been enormous, for example, Olga Yokoyama.






</doc>
<doc id="26475" url="https://en.wikipedia.org/wiki?curid=26475" title="Rudolph Pariser">
Rudolph Pariser

Rudolph Pariser (born December 8, 1923) is a physical and polymer chemist. He was born in Harbin, China to merchant parents, Ludwig Jacob Pariser and Lia Rubinstein. He attended the Von Hindenburg Schule in Harbin, an American Missionary School in Beijing and American School in Japan in Tokyo. He left for the United States just before World War II broke out.

He received his Bachelor of Science degree from the University of California, Berkeley in 1944, and his Ph. D. degree from the University of Minnesota in physical chemistry in 1950. From 1944 to 1946, during World War II and shortly afterward, he served in the United States Army. He became a naturalized citizen of the United States of America in 1944.

He spent most of his career as a polymer chemist working for DuPont in the Central Research Department at the Experimental Station. He rose to the level of Director of Polymer Sciences, leading it during a time of great innovation. After retiring from DuPont, he formed his own consulting company.

Pariser is best known for his work with Robert G. Parr on the method of molecular orbital computation now known (because it was independently developed by John A. Pople) as the Pariser–Parr–Pople method (PPP method), published both by Pariser and Parr and by Pople in almost simultaneous papers in 1953.

He married Margaret Louise Marsh on July 31, 1972.


</doc>
<doc id="26476" url="https://en.wikipedia.org/wiki?curid=26476" title="Rendezvous with Rama">
Rendezvous with Rama

Rendezvous with Rama is a science fiction novel by British writer Arthur C. Clarke first published in 1973. Set in the 2130s, the story involves a cylindrical alien starship that enters the Solar System. The story is told from the point of view of a group of human explorers who intercept the ship in an attempt to unlock its mysteries. The novel won both the Hugo and Nebula awards upon its release, and is regarded as one of the cornerstones in Clarke's bibliography. The concept was later extended with several sequels, written by Gentry Lee.

After an asteroid falls in Northeast Italy in 2077, creating a major disaster, the government of Earth sets up the Spaceguard system as an early warning of arrivals from deep space.

The "Rama" of the title is an alien starship, initially mistaken for an asteroid categorised as "31/439". It is detected by astronomers in the year 2131 while it is still outside the orbit of Jupiter. Its speed (100,000 km/h - 62,137 m/h) and the angle of its trajectory clearly indicate it is not on a long orbit around the sun, but is an interstellar object. The astronomers' interest is further piqued when they realise the asteroid has an extremely rapid rotation period of four minutes and is exceptionally large. It is named Rama after the Hindu god, and an unmanned space probe dubbed "Sita" is launched from the Mars moon Phobos to intercept and photograph it. The resulting images reveal that Rama is a perfect cylinder, in diameter and long, and almost completely featureless, making this humankind's first encounter with an alien spacecraft.

The solar survey vessel "Endeavour" is sent to study Rama, as it is the only ship close enough to do so in the brief period Rama will spend in the solar system. "Endeavour" manages to rendezvous with Rama one month after it first comes to Earth's attention, when the alien ship is already inside Venus's orbit. The crew, led by Commander Bill Norton, enters Rama through a dual safety system consisting of two sets of triple airlocks, and explores the 16-km wide by 50-km long cylindrical world of its interior, but the nature and purpose of the starship and its creators remain enigmatic throughout the book. Rama's inner surfaces hold "cities" of geometric structures that resemble buildings and are separated by streets with shallow trenches. A band of water, dubbed the Cylindrical Sea, stretches around Rama's central circumference. Massive cones, which are theorised as part of Rama's propulsion system, stand at its "southern" end. They also find that Rama's atmosphere is breathable.

One of the crew members, Jimmy Pak, who has experience with low gravity skybikes, rides a smuggled skybike along Rama's axis to the far end, otherwise inaccessible due to the cylindrical sea and the 500m high cliff on the opposite shore. Once at the massive metal cones on the southern end of Rama, Jimmy detects magnetic and electric fields coming from the cones, which increase, resulting in lightning. Due to his proximity to the spires, the concussion from a discharge damages his skybike causing him to crash on the isolated southern continent.

When Pak wakes up, he sees a crab-like creature picking up his skybike and chopping it into pieces. He cannot decide whether it is a robot or a biological alien, and keeps his distance while radioing for help. As Pak waits, Norton sends a rescue party across the cylindrical sea, using a small, improvised craft, constructed earlier for exploration of the sea's central island. The creature dumps the remains of the skybike into a pit, but ignores Pak himself, who explores the surrounding fields while waiting for the rescue party to arrive. Amongst the strange geometric structures, he sees an alien flower growing through a cracked tile in the otherwise sterile environment, and decides to take it as both a curiosity and for scientific research.

Pak jumps off the 500m cliff, his descent slowed by the low gravity and using his shirt as a drogue parachute, and is quickly rescued by the waiting boat. As they ride back, tidal waves form in the cylindrical sea, created by the movements of Rama itself as it makes course corrections. When the crew arrives at base, they see a variety of odd creatures inspecting their camp. When one is found damaged and apparently lifeless, the team's doctor/biologist Surgeon-Commander Laura Ernst inspects it, and discovers it to be a hybrid biological entity and robot—eventually termed a "biot". It, and by assumption the others, are powered by internal batteries (much like those of terrestrial electric eels) and possess some intelligence. They are believed to be the drones of Rama's still-absent builders.

The members of the Rama Committee and the United Planets, both based on the Moon, have been monitoring events inside Rama and giving feedback. The Hermian colonists have concluded that Rama is a potential threat and send a rocket-mounted nuclear bomb to destroy it should it prove to pose a threat. Lt. Boris Rodrigo takes advantage of the five minute transmission delay and uses a pair of wire cutters to defuse the bomb and its control.

As Rama approaches perihelion, and on their final expedition, the crew decide to visit the city closest to their point of entry, christened "London", and use a laser to cut open one of the "buildings" to see what it houses. They discover transparent pedestals containing holograms of various artefacts, which they theorise are used by the Ramans as templates for creating tools and other objects. One hologram appears to be a uniform with bandoliers, straps and pockets that suggests the size and shape of the Ramans. As the crew photographs some of the holograms, the biots begin returning to the cylindrical sea, where they are recycled by aquatic biots ('sharks') and the six striplights that illuminate Rama's interior start to dim, prompting the explorers to leave Rama and to re-board "Endeavour".

With "Endeavour" a safe distance away, Rama reaches perihelion and utilizes the Sun's gravitational field, and its mysterious "space drive", to perform a slingshot manoeuvre which flings it out of the solar system and towards an unknown destination in the direction of the Large Magellanic Cloud.

The book was meant to stand alone, although its final sentence suggests otherwise:

Clarke denied that this sentence was a hint that the story might be continued. In his foreword to the book's sequel, he stated that it was just a good way to end the first book, and that he added it during a final revision.

John Leonard of "The New York Times", while finding Clarke "benignly indifferent to the niceties of characterization," praised the novel for conveying "that chilling touch of the alien, the not-quite-knowable, that distinguishes sci-fi at its most technically imaginative." Other reviewers have also commented on Clarke's lack of character development and overemphasis on realism.

The novel was awarded the following soon after publication

The interior of Rama is essentially a large cylindrical landscape, dubbed "The Central Plain" by the crew, 16 kilometres in diameter and nearly 50 long, with artificial gravity provided by its 0.25 rpm spin. It is split into the "northern" and "southern" plains, divided in the middle by a 10-km wide expanse of water the astronauts dub the "Cylindrical Sea". In the center of the Cylindrical Sea is an island of unknown purpose covered in tall, skyscraper-like structures, which the astronauts name "New York" due to an imagined similarity to Manhattan. At each end of the ship are North and South "Poles". The North Pole is effectively the bow and the South Pole the stern, as Rama accelerates in the direction of the north pole and its drive system is at the South Pole.

The North Pole contains Rama's airlocks, and is where the "Endeavour" lands. The airlocks open into the hub of the massive bowl shaped cap at the North Pole, with three 8-kilometre long stair systems, called Alpha, Beta, and Gamma by the crew, leading to the plain.

The Northern plain contains several small "towns" interconnected by roads, dubbed London, Paris, Peking, Tokyo, Rome, and Moscow. The South Pole has a giant cone-shaped protrusion surrounded by six smaller ones, which are thought to be part of Rama's reactionless space drive.

Both ends of Rama are lit by giant trenches (three in the northern plain and three in the south), equidistantly placed around the cylinder, effectively functioning as giant strip lighting.

Clarke paired up with Gentry Lee for the remainder of the series. Lee wrote while Clarke read and made editing suggestions. The focus and style of the last three novels are quite different from those of the original with an increased emphasis on characterisation and clearly-portrayed heroes and villains, rather than Clarke's dedicated professionals. These later books did not receive the same critical acclaim and awards as the original.


Gentry Lee also wrote two further novels set in the same "Rama" Universe.


A graphic adventure computer game of the same name with a text parser based on the book was made in 1984 by Trillium and ported to other systems such as the Apple II, Commodore 64. Despite its primitive graphics, it had highly detailed descriptions, and it followed the book very closely along with having puzzles to solve during the game.

In Spain there was an official adaptation for the 2nd generation MSX computers called "Cita con Rama" that took advantage of the MSX's ability to produce (at the time) high-quality graphics. It was adapted from the Clarke novel in 1983 by Ron Martinez, who went on to design the massively multiplayer online game "10Six", also known as "Project Visitor".

Sierra Entertainment created "Rama" in 1996 as a point and click adventure game in the style of "Myst". Along with highly detailed graphics, Arthur C. Clarke also appeared in the game as the guide for the player. This game featured characters from the sequel book "Rama II".

In 2009, BBC Radio 4 produced a two-part radio adaptation of the book as part of a science-fiction season. It was adapted by Mike Walker, and was broadcast on 1 March 2009 (Part 1) and 8 March 2009 (Part 2).

In the early 2000s, actor Morgan Freeman expressed his desire to produce a film based on "Rendezvous with Rama." The film has been stuck in "development hell" for many years. In 2003, after initial problems procuring funding, it appeared the project would go into production. The film was to be produced by Freeman's production company, Revelations Entertainment. David Fincher, touted on Revelations' "Rama" web page as far back as 2001, stated in a late 2007 interview that he was still attached to helm.

By late 2008, David Fincher stated the movie was unlikely to be made. "It looks like it's not going to happen. There's no script and as you know, Morgan Freeman's not in the best of health right now. We've been trying to do it but it's probably not going to happen."

In 2010, Freeman stated in an interview that he was still planning to make the project but that it has been difficult to find the right script. He also stated that it should be made in 3D. In January 2011, Fincher stated in an interview with MTV that he was still planning to make the film after he had completed work on his planned remake of "20,000 Leagues Under the Sea" (which was scheduled to begin production in 2012 but has since been scrapped). He also reiterated Freeman's concerns about the difficulty of finding the right script.

In an interview with Neil deGrasse Tyson in February 2012, Freeman indicated an interest in playing the role of Commander Norton for the film, stating that "my fantasy of commanding a starship is commanding Endeavour". Tyson then asked, "So is this a pitch to be ... that person if they ever make that movie?" to which Freeman reaffirmed, "We ARE going to make that movie." In response to a plea to "make that come out sooner rather than later", Freeman reiterated that difficulty in authoring a high quality script is the primary barrier for the film, stating "... the only task you have that's really really hard in making movies, harder than getting money, is getting a script ... a good script".

Clarke invented the space study program which detects Rama, Project Spaceguard, as a method of identifying near-Earth objects on Earth-impact trajectories; in the novel it was initiated in 2077. A real project named Spaceguard was initiated in 1992, named after Clarke's fictional project and "with the permission and encouragement of Clarke". After interest in the dangers of asteroid strikes was heightened by a series of Hollywood disaster films, the United States Congress gave NASA authorisation and funding to support Spaceguard. By 2017, there were a number of different efforts to detect potentially dangerous asteroids—see figure on right. 

On 19 October 2017 an incoming interstellar object was discovered by Pan-STARRS, a system similar to Spaceguard. Like Rama, the object had an unusually elongated shape. Before the official Hawaiian name 'Oumuamua was selected by the International Astronomical Union, a popular choice was "Rama".




</doc>
<doc id="26477" url="https://en.wikipedia.org/wiki?curid=26477" title="Rust">
Rust

Rust is an iron oxide, a usually reddish brown oxide formed by the reaction of iron and oxygen in the presence of water or air moisture. Several forms of rust are distinguishable both visually and by spectroscopy, and form under different circumstances. Rust consists of hydrated iron(III) oxides FeO·"n"HO and iron(III) oxide-hydroxide (FeO(OH), Fe(OH)).

Given sufficient time, any iron mass, in the presence of water and oxygen, could eventually convert entirely to rust. Surface rust is commonly flaky and friable, and it provides no protection to the underlying iron, unlike the formation of patina on copper surfaces. Rusting is the common term for corrosion of iron and its alloys, such as steel. Many other metals undergo similar corrosion, but the resulting oxides are not commonly called rust.

Other forms of rust exist, like the result of reactions between iron and chloride in an environment deprived of oxygen. Rebar used in underwater concrete pillars, which generates green rust, is an example. Although rusting is generally a negative aspect of iron, a particular form of rusting, known as "stable rust", causes the object to have a thin coating of rust over the top, and if kept in low relative humidity, makes the "stable" layer protective to the iron below, but not to the extent of other oxides, such as aluminium.

Rust is a general name for a complex of oxides and hydroxides of iron, which occurs when iron or some alloys that contains iron are exposed to oxygen and moisture for a long period of time. Over time, the oxygen combines with the metal forming new compounds collectively called rust. Although rust may generally be termed as "oxidation", that term is much more general and describes a vast number of processes involving the loss of electrons or increased oxidation state, as part of a reaction. The best-known of these reactions involve oxygen, hence the name "oxidation". The terms "rust" and "rusting" only mean oxidation of iron and its resulting products. Many other oxidation reactions exist which do not involve iron or produce rust. But only iron or alloys that contain iron can rust. However, other metals can corrode in similar ways.

The main catalyst for the rusting process is water. Iron or steel structures might appear to be solid, but water molecules can penetrate the microscopic pits and cracks in any exposed metal. The hydrogen atoms present in water molecules can combine with other elements to form acids, which will eventually cause more metal to be exposed. If chloride ions are present, as is the case with saltwater, the corrosion is likely to occur more quickly. Meanwhile, the oxygen atoms combine with metallic atoms to form the destructive oxide compound. As the atoms combine, they weaken the metal, making the structure brittle and crumbly.

When iron is in contact with water and oxygen it rusts. If salt is present, for example in seawater or salt spray, the iron tends to rust more quickly, as a result of electrochemical reactions. Iron metal is relatively unaffected by pure water or by dry oxygen. As with other metals, like aluminium, a tightly adhering oxide coating, a passivation layer, protects the bulk iron from further oxidation. The conversion of the passivating ferrous oxide layer to rust results from the combined action of two agents, usually oxygen and water.

Other degrading solutions are sulfur dioxide in water and carbon dioxide in water. Under these corrosive conditions, iron hydroxide species are formed. Unlike ferrous oxides, the hydroxides do not adhere to the bulk metal. As they form and flake off from the surface, fresh iron is exposed, and the corrosion process continues until either all of the iron is consumed or all of the oxygen, water, carbon dioxide, or sulfur dioxide in the system are removed or consumed.

When iron rusts, the oxides take up more volume than the original metal; this expansion can generate enormous forces, damaging structures made with iron. See "economic effect" for more details.

The rusting of iron is an electrochemical process that begins with the transfer of electrons from iron to oxygen. The iron is the reducing agent (gives up electrons) while the oxygen is the oxidising agent (gains electrons). The rate of corrosion is affected by water and accelerated by electrolytes, as illustrated by the effects of road salt on the corrosion of automobiles. The key reaction is the reduction of oxygen:
Because it forms hydroxide ions, this process is strongly affected by the presence of acid. Likewise, the corrosion of most metals by oxygen is accelerated at low pH. Providing the electrons for the above reaction is the oxidation of iron that may be described as follows:

The following redox reaction also occurs in the presence of water and is crucial to the formation of rust:

In addition, the following multistep acid–base reactions affect the course of rust formation:

as do the following dehydration equilibria:

From the above equations, it is also seen that the corrosion products are dictated by the availability of water and oxygen. With limited dissolved oxygen, iron(II)-containing materials are favoured, including FeO and black lodestone or magnetite (FeO). High oxygen concentrations favour ferric materials with the nominal formulae Fe(OH)O. The nature of rust changes with time, reflecting the slow rates of the reactions of solids.

Furthermore, these complex processes are affected by the presence of other ions, such as Ca, which serve as electrolytes which accelerate rust formation, or combine with the hydroxides and oxides of iron to precipitate a variety of Ca, Fe, O, OH species.

The onset of rusting can also be detected in the laboratory with the use of ferroxyl indicator solution. The solution detects both Fe ions and hydroxyl ions. Formation of Fe ions and hydroxyl ions are indicated by blue and pink patches respectively.

Because of the widespread use and importance of iron and steel products, the prevention or slowing of rust is the basis of major economic activities in a number of specialized technologies. A brief overview of methods is presented here; for detailed coverage, see the cross-referenced articles.
Rust is permeable to air and water, therefore the interior metallic iron beneath a rust layer continues to corrode. Rust prevention thus requires coatings that preclude rust formation.

Stainless steel forms a passivation layer of chromium(III) oxide. Similar passivation behavior occurs with magnesium, titanium, zinc, zinc oxides, aluminium, polyaniline, and other electroactive conductive polymers.

Special "weathering steel" alloys such as Cor-Ten rust at a much slower rate than normal, because the rust adheres to the surface of the metal in a protective layer. Designs using this material must include measures that avoid worst-case exposures, since the material still continues to rust slowly even under near-ideal conditions.

Galvanization consists of an application on the object to be protected of a layer of metallic zinc by either hot-dip galvanizing or electroplating. Zinc is traditionally used because it is cheap, adheres well to steel, and provides cathodic protection to the steel surface in case of damage of the zinc layer. In more corrosive environments (such as salt water), cadmium plating is preferred. Galvanization often fails at seams, holes, and joints where there are gaps in the coating. In these cases, the coating still provides some partial cathodic protection to iron, by acting as a galvanic anode and corroding itself instead of the underlying protected metal. The protective zinc layer is consumed by this action, and thus galvanization provides protection only for a limited period of time.

More modern coatings add aluminium to the coating as "zinc-alume"; aluminium will migrate to cover scratches and thus provide protection for a longer period. These approaches rely on the aluminium and zinc oxides reprotecting a once-scratched surface, rather than oxidizing as a sacrificial anode as in traditional galvanized coatings. In some cases, such as very aggressive environments or long design life, both zinc and a coating are applied to provide enhanced corrosion protection.

Typical galvanization of steel products which are to be subjected to normal day-to-day weathering in an outside environment consists of a hot-dipped 85 µm zinc coating. Under normal weather conditions, this will deteriorate at a rate of 1 µm per year, giving approximately 85 years of protection.

Cathodic protection is a technique used to inhibit corrosion on buried or immersed structures by supplying an electrical charge that suppresses the electrochemical reaction. If correctly applied, corrosion can be stopped completely. In its simplest form, it is achieved by attaching a sacrificial anode, thereby making the iron or steel the cathode in the cell formed. The sacrificial anode must be made from something with a more negative electrode potential than the iron or steel, commonly zinc, aluminium, or magnesium. The sacrificial anode will eventually corrode away, ceasing its protective action unless it is replaced in a timely manner.

Cathodic protection can also be provided by using a special-purpose electrical device to appropriately induce an electric charge.

Rust formation can be controlled with coatings, such as paint, lacquer, varnish, or wax tapes that isolate the iron from the environment. Large structures with enclosed box sections, such as ships and modern automobiles, often have a wax-based product (technically a "slushing oil") injected into these sections. Such treatments usually also contain rust inhibitors. Covering steel with concrete can provide some protection to steel because of the alkaline pH environment at the steel–concrete interface. However, rusting of steel in concrete can still be a problem, as expanding rust can fracture or slowly "explode" concrete from within.

As a closely related example, iron bars were used to reinforce stonework of the Parthenon in Athens, Greece, but caused extensive damage by rusting, swelling, and shattering the marble components of the building.

When only temporary protection is needed for storage or transport, a thin layer of oil, grease, or a special mixture such as Cosmoline can be applied to an iron surface. Such treatments are extensively used when "mothballing" a steel ship, automobile, or other equipment for long-term storage.

Special antiseize lubricant mixtures are available, and are applied to metallic threads and other precision machined surfaces to protect them from rust. These compounds usually contain grease mixed with copper, zinc, or aluminium powder, and other proprietary ingredients.

Bluing is a technique that can provide limited resistance to rusting for small steel items, such as firearms; for it to be successful, a water-displacing oil is rubbed onto the blued steel and other steel.

Corrosion inhibitors, such as gas-phase or volatile inhibitors, can be used to prevent corrosion inside sealed systems. They are not effective when air circulation disperses them, and brings in fresh oxygen and moisture.

Rust can be avoided by controlling the moisture in the atmosphere. An example of this is the use of silica gel packets to control humidity in equipment shipped by sea.

Rust removal from small iron or steel objects by electrolysis can be done in a home workshop using simple materials such as a plastic bucket filled with an electrolyte consisting of washing soda dissolved in tap water, a length of rebar suspended vertically in the solution to act as an anode, another laid across the top of the bucket to act as a support for suspending the object, baling wire to suspend the object in the solution from the horizontal rebar, and a battery charger as a power source in which the positive terminal is clamped to the anode and the negative terminal is clamped to the object to be treated which becomes the cathode.

Rust may be treated with commercial products known as rust converter which contain tannic acid or phosphoric acid which combines with rust; removed with organic acids like citric acid and vinegar or the stronger hydrochloric acid; or removed with chelating agents as in some commercial formulations or even a solution of molasses.

Rust is associated with the degradation of iron-based tools and structures. As rust has a much higher volume than the originating mass of iron, its buildup can also cause failure by forcing apart adjacent parts — a phenomenon sometimes known as "rust packing". It was the cause of the collapse of the Mianus river bridge in 1983, when the bearings rusted internally and pushed one corner of the road slab off its support.

Rust was an important factor in the Silver Bridge disaster of 1967 in West Virginia, when a steel suspension bridge collapsed in less than a minute, killing 46 drivers and passengers on the bridge at the time. The Kinzua Bridge in Pennsylvania was blown down by a tornado in 2003, largely because the central base bolts holding the structure to the ground had rusted away, leaving the bridge anchored by gravity alone.

Reinforced concrete is also vulnerable to rust damage. Internal pressure caused by expanding corrosion of concrete-covered steel and iron can cause the concrete to spall, creating severe structural problems. It is one of the most common failure modes of reinforced concrete bridges and buildings.

Rust is a commonly used metaphor for slow decay due to neglect, since it gradually converts robust iron and steel metal into a soft crumbling powder. A wide section of the industrialized American Midwest and American Northeast, once dominated by steel foundries, the automotive industry, and other manufacturers, has experienced harsh economic cutbacks that have caused the region to be dubbed the "Rust Belt".

In music, literature, and art, rust is associated with images of faded glory, neglect, decay, and ruin.




</doc>
<doc id="26478" url="https://en.wikipedia.org/wiki?curid=26478" title="Real analysis">
Real analysis

In mathematics, real analysis is the branch of mathematical analysis that studies the behavior of real numbers, sequences and series of real numbers, and real functions. Some particular properties of real-valued sequences and functions that real analysis studies include convergence, limits, continuity, smoothness, differentiability and integrability.

Real analysis is distinguished from complex analysis, which deals with the study of complex numbers and their functions.

The theorems of real analysis rely intimately upon the structure of the real number line. The real number system consists of an uncountable set (formula_1), together with two binary operations denoted and , and an order denoted . The operations make the real numbers a field, and, along with the order, an ordered field. The real number system is the unique "complete ordered field", in the sense that any other complete ordered field is isomorphic to it. Intuitively, completeness means that there are no 'gaps' in the real numbers. In particular, this property distinguishes the real numbers from other ordered fields (e.g., the rational numbers formula_2) and is critical to the proof of several key properties of functions of the real numbers. The completeness of the reals is often conveniently expressed as the "least upper bound property" (see below).

There are several ways of formalizing the definition of the real numbers. Modern approaches consist of providing a list of axioms, and a proof of the existence of a model for them, which has above properties. Moreover, one may show that any two models are isomorphic, which means that all models have exactly the same properties, and that one may forget how the model is constructed for using real numbers. Some of these constructions are described in the main article.

The real numbers have various lattice-theoretic properties that are absent in the complex numbers. Also, the real numbers form an ordered field, in which sums and products of positive numbers are also positive. Moreover, the ordering of the real numbers is total, and the real numbers have the least upper bound property: "Every nonempty subset of formula_1 that has an upper bound has a least upper bound that is also a real number." These order-theoretic properties lead to a number of fundamental results in real analysis, such as the monotone convergence theorem, the intermediate value theorem and the mean value theorem.

However, while the results in real analysis are stated for real numbers, many of these results can be generalized to other mathematical objects. In particular, many ideas in functional analysis and operator theory generalize properties of the real numbers – such generalizations include the theories of Riesz spaces and positive operators. Also, mathematicians consider real and imaginary parts of complex sequences, or by pointwise evaluation of operator sequences.

Many of the theorems of real analysis are consequences of the topological properties of the real number line. The order properties of the real numbers described above are closely related to these topological properties. As a topological space, the real numbers has a "standard topology", which is the order topology induced by order formula_4. Alternatively, by defining the "metric" or "distance function" formula_5 using the absolute value function as formula_6, the real numbers become the prototypical example of a metric space. The topology induced by metric formula_7 turns out to be identical to the standard topology induced by order formula_4. Theorems like the intermediate value theorem that are essentially topological in nature can often be proved in the more general setting of metric or topological spaces rather than in formula_1 only. Often, such proofs tend to be shorter or simpler compared to classical proofs that apply direct methods.

A sequence is a function whose domain is a countable, totally ordered set. The domain is usually taken to be the natural numbers, although it is occasionally convenient to also consider bidirectional sequences indexed by the set of all integers, including negative indices.

Of interest in real analysis, a real-valued sequence, here indexed by the natural numbers, is a map formula_10. Each formula_11 is referred to as a term (or, less commonly, an element) of the sequence. A sequence is rarely denoted explicitly as a function; instead, by convention, it is almost always notated as if it were an ordered ∞-tuple, with individual terms or a general term enclosed in parentheses: formula_12.A sequence that tends to a limit (i.e., formula_13 exists) is said to be convergent; otherwise it is divergent. ("See the section on limits and convergence for details.") A real-valued sequence formula_14 is bounded if there exists formula_15 such that formula_16 for all formula_17. A real-valued sequence formula_14 is monotonically increasing or decreasing if formula_19 or formula_20holds, respectively. If either holds, the sequence is said to be monotonic. The monotonicity is strict if the chained inequalities still hold with formula_21 or formula_22 replaced by < or >.

Given a sequence formula_14, another sequence formula_24 is a subsequence of formula_14 if formula_26 for all positive integers formula_27 and formula_28 is a strictly increasing sequence of natural numbers.

Roughly speaking, a limit is the value that a function or a sequence "approaches" as the input or index approaches some value. (This value can include the symbols formula_29 when addressing the behavior of a function or sequence as the variable increases or decreases without bound.) The idea of a limit is fundamental to calculus (and mathematical analysis in general) and its formal definition is used in turn to define notions like continuity, derivatives, and integrals. (In fact, the study of limiting behavior has been used as a characteristic that distinguishes calculus and mathematical analysis from other branches of mathematics.)

The concept of limit was informally introduced for functions by Newton and Leibniz, at the end of the 17th century, for building infinitesimal calculus. For sequences, the concept was introduced by Cauchy, and made rigorous, at the end of the 19th century by Bolzano and Weierstrass, who gave the modern ε-δ definition, which follows.

Definition. Let formula_30 be a real-valued function defined on formula_31. We say that formula_32 tends to formula_33 as formula_34 approaches formula_35, or that the limit of formula_32 as formula_34 approaches formula_35 is formula_33 if, for any formula_40, there exists formula_41 such that for all formula_42, formula_43 implies that formula_44. We write this symbolically as formula_45, or formula_46.Intuitively, this definition can be thought of in the following way: We say that formula_47 as formula_48, when, given any positive number formula_49, no matter how small, we can always find a formula_50, such that we can guarantee that formula_32 and formula_33 are less than formula_49 apart, as long as formula_34 (in the domain of formula_30) is a real number that is less than formula_50 away from formula_35 but distinct from formula_35. The purpose of the last stipulation, which corresponds to the condition formula_59 in the definition, is to ensure that formula_46 does not imply anything about the value of formula_61 itself. Actually, formula_35 does not even need to be in the domain of formula_30 in order for formula_64 to exist.

In a slightly different but related context, the concept of a limit applies to the behavior of a sequence formula_14 when formula_66 becomes large.

Definition. Let formula_14 be a real-valued sequence. We say that formula_14 converges to formula_69 if, for any formula_40, there exists a natural number formula_71 such that formula_72 implies that formula_73. We write this symbolically as formula_74, or formula_75;if formula_14 fails to converge, we say that formula_14 diverges.

Generalizing to a real-valued function of a real variable, a slight modification of this definition (replacement of sequence formula_14 and term formula_79 by function formula_30 and value formula_32 and natural numbers formula_71 and formula_66 by real numbers formula_84 and formula_34, respectively) yields the definition of the limit of formula_32 as formula_34 increases without bound, notated formula_88. Reversing the inequality formula_89 to formula_90 gives the corresponding definition of the limit of formula_32 as formula_34 "decreases" "without bound", formula_93.

Sometimes, it is useful to conclude that a sequence converges, even though the value to which it converges is unknown or irrelevant. In these cases, the concept of a Cauchy sequence is useful.

Definition. Let formula_14 be a real-valued sequence. We say that formula_14 is a Cauchy sequence if, for any formula_40, there exists a natural number formula_71 such that formula_98 implies that formula_99.

It can be shown that a real-valued sequence is Cauchy if and only if it is convergent. This property of the real numbers is expressed by saying that the real numbers endowed with the standard metric, formula_100, is a complete metric space. In a general metric space, however, a Cauchy sequence need not converge.

In addition, for real-valued sequences that are monotonic, it can be shown that the sequence is bounded if and only if it is convergent.

In addition to sequences of numbers, one may also speak of "sequences of functions" "on" formula_101, that is, infinite, ordered families of functions formula_102, denoted formula_103, and their convergence properties. However, in the case of sequences of functions, there are two kinds of convergence, known as "pointwise convergence" and "uniform convergence", that need to be distinguished.

Roughly speaking, pointwise convergence of functions formula_104 to a limiting function formula_105, denoted formula_106, simply means that given any formula_42, formula_108 as formula_109. In contrast, uniform convergence is a stronger type of convergence, in the sense that a uniformly convergent sequence of functions also converges pointwise, but not conversely. Uniform convergence requires members of the family of functions, formula_104, to fall within some error formula_40 of formula_30 for "every value of formula_42", whenever formula_72, for some integer formula_71. For a family of functions to uniformly converge, sometimes denoted formula_116, such a value of formula_71 must exist for any formula_40 given, no matter how small. Intuitively, we can visualize this situation by imagining that, for a large enough formula_71, the functions formula_120 are all confined within a 'tube' of width formula_121 about formula_30 (that is, between formula_123 and formula_124) "for every value in their domain" formula_125.

The distinction between pointwise and uniform convergence is important when exchanging the order of two limiting operations (e.g., taking a limit, a derivative, or integral) is desired: in order for the exchange to be well-behaved, many theorems of real analysis call for uniform convergence. For example, a sequence of continuous functions (see below) is guaranteed to converge to a continuous limiting function if the convergence is uniform, while the limiting function may not be continuous if convergence is only pointwise. Karl Weierstrass is generally credited for clearly defining the concept of uniform convergence and fully investigating its implications.

Compactness is a concept from general topology that plays an important role in many of the theorems of real analysis. The property of compactness is a generalization of the notion of a set being "closed" and "bounded". (In the context of real analysis, these notions are equivalent: a set in Euclidean space is compact if and only if it is closed and bounded.) Briefly, a closed set contains all of its boundary points, while a set is bounded if there exists a real number such that the distance between any two points of the set is less than that number. In formula_1, sets that are closed and bounded, and therefore compact, include the empty set, any finite number of points, closed intervals, and their finite unions. However, this list is not exhaustive; for instance, the set formula_127 is a compact set; the Cantor ternary set formula_128 is another example of a compact set. On the other hand, the set formula_129 is not compact because it is bounded but not closed, as the boundary point 0 is not a member of the set. The set formula_130 is also not compact because it is closed but not bounded.

For subsets of the real numbers, there are several equivalent definitions of compactness.

Definition. A set formula_31 is compact if it is closed and bounded.

This definition also holds for Euclidean space of any finite dimension, formula_132, but it is not valid for metric spaces in general. The equivalence of the definition with the definition of compactness based on subcovers, given later in this section, is known as the Heine-Borel theorem.

A more general definition that applies to all metric spaces uses the notion of a subsequence (see above).

Definition. A set formula_125 in a metric space is compact if every sequence in formula_125 has a convergent subsequence.

This particular property is known as "subsequential compactness". In formula_1, a set is subsequentially compact if and only if it is closed and bounded, making this definition equivalent to the one given above. Subsequential compactness is equivalent to the definition of compactness based on subcovers for metric spaces, but not for topological spaces in general.

The most general definition of compactness relies on the notion of "open covers" and "subcovers", which is applicable to topological spaces (and thus to metric spaces and formula_1 as special cases). In brief, a collection of open sets formula_137 is said to be an "open cover" of set formula_138 if the union of these sets is a superset of formula_138. This open cover is said to have a "finite subcover" if a finite subcollection of the formula_137 could be found that also covers formula_138.

Definition. A set formula_138 in a topological space is compact if every open cover of formula_138 has a finite subcover.

Compact sets are well-behaved with respect to properties like convergence and continuity. For instance, any Cauchy sequence in a compact metric space is convergent. As another example, the image of a compact metric space under a continuous map is also compact.

A function from the set of real numbers to the real numbers can be represented by a graph in the Cartesian plane; such a function is continuous if, roughly speaking, the graph is a single unbroken curve with no "holes" or "jumps".

There are several ways to make this intuition mathematically rigorous. Several definitions of varying levels of generality can be given. In cases where two or more definitions are applicable, they are readily shown to be equivalent to one another, so the most convenient definition can be used to determine whether a given function is continuous or not. In the first definition given below, formula_144 is a function defined on a non-degenerate interval formula_145 of the set of real numbers as its domain. Some possibilities include formula_146, the whole set of real numbers, an open interval formula_147 or a closed interval formula_148 Here, formula_69 and formula_150 are distinct real numbers, and we exclude the case of formula_145 being empty or consisting of only one point, in particular.

Definition. If formula_152 is a non-degenerate interval, we say that formula_144 is continuous at formula_154 if formula_155. We say that formula_30 is a continuous map if formula_30 is continuous at every formula_154.

In contrast to the requirements for formula_30 to have a limit at a point formula_160, which do not constrain the behavior of formula_30 at formula_160 itself, the following two conditions, in addition to the existence of formula_163, must also hold in order for formula_30 to be continuous at formula_160: (i) formula_30 must be defined at formula_160, i.e., formula_160 is in the domain of formula_30; "and" (ii) formula_170 as formula_171. The definition above actually applies to any domain formula_125 that does not contain an isolated point, or equivalently, formula_125 where every formula_174 is a limit point of formula_125. A more general definition applying to formula_176 with a general domain formula_177 is the following:

Definition. If formula_138 is an arbitrary subset of formula_1, we say that formula_176 is continuous at formula_181 if, for any formula_40, there exists formula_41 such that for all formula_184, formula_185 implies that formula_186. We say that formula_30 is a continuous map if formula_30 is continuous at every formula_181.

A consequence of this definition is that formula_30 is "trivially continuous at any isolated point" formula_181. This somewhat unintuitive treatment of isolated points is necessary to ensure that our definition of continuity for functions on the real line is consistent with the most general definition of continuity for maps between topological spaces (which includes metric spaces and formula_1 in particular as special cases). This definition, which extends beyond the scope of our discussion of real analysis, is given below for completeness.

Definition. If formula_138 and formula_194 are topological spaces, we say that formula_195 is continuous at formula_181 if formula_197 is a neighborhood of formula_160 in formula_138 for every neighborhood formula_200 of formula_201 in formula_194. We say that formula_30 is a continuous map if formula_204 is open in formula_138 for every formula_206 open in formula_194.

Definition. If formula_138 is a subset of the real numbers, we say a function formula_176 is uniformly continuous on formula_138 if, for any formula_40, there exists a formula_41 such that for all formula_216, formula_217 implies that formula_218"."

Explicitly, when a function is uniformly continuous on formula_138, the choice of formula_50 needed to fulfill the definition must work for "all of" formula_138 for a given formula_49. In contrast, when a function is continuous at every point formula_181 (or said to be continuous on formula_138), the choice of formula_50 may depend on both formula_49 "and" formula_160. In contrast to simple continuity, uniform continuity is a property of a function that only makes sense with a specified domain; to speak of uniform continuity at a single point formula_160 is meaningless.

On a compact set, it is easily shown that all continuous functions are uniformly continuous. If formula_125 is a bounded noncompact subset of formula_1, then there exists formula_105 that is continuous but not uniformly continuous. As a simple example, consider formula_232 defined by formula_233. By choosing points close to 0, we can always make formula_234 for any single choice of formula_41, for a given formula_40.

Definition. Let formula_237 be an interval on the real line. A function formula_238 is said to be absolutely continuous on formula_145 if for every positive number formula_49, there is a positive number formula_50 such that whenever a finite sequence of pairwise disjoint sub-intervals formula_242 of formula_145 satisfies
then
Absolutely continuous functions are continuous: consider the case "n" = 1 in this definition. The collection of all absolutely continuous functions on "I" is denoted AC("I"). Absolute continuity is a fundamental concept in the Lebesgue theory of integration, allowing the formulation of a generalized version of the fundamental theorem of calculus that applies to the Lebesgue integral.

The notion of the "derivative" of a function or "differentiability" originates from the concept of approximating a function near a given point using the "best" linear approximation. This approximation, if it exists, is unique and is given by the line that is tangent to the function at the given point formula_69, and the slope of the line is the derivative of the function at formula_69.

A function formula_248 is differentiable at formula_69 if the limit

exists. This limit is known as the derivative of formula_30 at formula_69, and the function formula_253, possibly defined on only a subset of formula_1, is the derivative (or derivative function) of formula_30. If the derivative exists everywhere, the function is said to be differentiable.

As a simple consequence of the definition, formula_30 is continuous at formula_69 if it is differentiable there. Differentiability is therefore a stronger regularity condition (condition describing the "smoothness" of a function) than continuity, and it is possible for a function to be continuous on the entire real line but not differentiable anywhere (see Weierstrass's nowhere differentiable continuous function). It is possible to discuss the existence of higher-order derivatives as well, by finding the derivative of a derivative function, and so on.

One can classify functions by their differentiability class. The class formula_258 (sometimes formula_259 to indicate the interval of applicability) consists of all continuous functions. The class formula_260 consists of all differentiable functions whose derivative is continuous; such functions are called continuously differentiable. Thus, a formula_260 function is exactly a function whose derivative exists and is of class formula_258. In general, the classes "formula_263" can be defined recursively by declaring formula_258 to be the set of all continuous functions and declaring "formula_263" for any positive integer formula_27 to be the set of all differentiable functions whose derivative is in formula_267. In particular, "formula_263" is contained in formula_267 for every formula_27, and there are examples to show that this containment is strict. Class formula_271 is the intersection of the sets "formula_263" as "formula_27" varies over the non-negative integers, and the members of this class are known as the smooth functions. Class formula_274 consists of all analytic functions, and is strictly contained in formula_271 (see bump function for a smooth function that is not analytic).

A series formalizes the imprecise notion of taking the sum of an endless sequence of numbers. The idea that taking the sum of an "infinite" number of terms can lead to a finite result was counterintuitive to the ancient Greeks and led to the formulation of a number of paradoxes by Zeno and other philosophers. The modern notion of assigning a value to a series avoids dealing with the ill-defined notion of adding an "infinite" number of terms. Instead, the finite sum of the first formula_66 terms of the sequence, known as a partial sum, is considered, and the concept of a limit is applied to the sequence of partial sums as formula_66 grows without bound. The series is assigned the value of this limit, if it exists.

Given an (infinite) sequence formula_14, we can define an associated series as the formal mathematical object formula_279, sometimes simply written as formula_280. The partial sums of a series formula_280 are the numbers formula_282. A series formula_280 is said to be convergent if the sequence consisting of its partial sums, formula_284, is convergent; otherwise it is divergent. The sum of a convergent series is defined as the number formula_285.

The word "sum" is used here in a metaphorical sense as a shorthand for taking the limit of a sequence of partial sums and should not be interpreted as simply "adding" an infinite number of terms. For instance, in contrast to the behavior of finite sums, rearranging the terms of an infinite series may result in convergence to a different number (see the article on the "Riemann rearrangement theorem" for further discussion).

An example of a convergent series is a geometric series which forms the basis of one of Zeno's famous paradoxes:

In contrast, the harmonic series has been known since the Middle Ages to be a divergent series:

A series formula_280 is said to converge absolutely if formula_290 is convergent. A convergent series formula_280 for which formula_290 diverges is said to converge conditionally (or nonabsolutely). It is easily shown that absolute convergence of a series implies its convergence. On the other hand, an example of a conditionally convergent series is

The Taylor series of a real or complex-valued function "ƒ"("x") that is infinitely differentiable at a real or complex number "a" is the power series

which can be written in the more compact sigma notation as

where "n"! denotes the factorial of "n" and "ƒ"("a") denotes the "n"th derivative of "ƒ" evaluated at the point "a". The derivative of order zero "ƒ" is defined to be "ƒ" itself and and 0! are both defined to be 1. In the case that , the series is also called a Maclaurin series.

A Taylor series of "f" about point "a" may diverge, converge at only the point "a", converge for all "x" such that formula_296 (the largest such "R" for which convergence is guaranteed is called the "radius of convergence"), or converge on the entire real line. Even a converging Taylor series may converge to a value different from the value of the function at that point. If the Taylor series at a point has a nonzero radius of convergence, and sums to the function in the disc of convergence, then the function is analytic. The analytic functions have many fundamental properties. In particular, an analytic function of a real variable extends naturally to a function of a complex variable. It is in this way that the exponential function, the logarithm, the trigonometric functions and their inverses are extended to functions of a complex variable.

Fourier series decomposes periodic functions or periodic signals into the sum of a (possibly infinite) set of simple oscillating functions, namely sines and cosines (or complex exponentials). The study of Fourier series typically occurs and is handled within the branch mathematics > mathematical analysis > Fourier analysis.

Integration is a formalization of the problem of finding the area bound by a curve and the related problems of determining the length of a curve or volume enclosed by a surface. The basic strategy to solving problems of this type was known to the ancient Greeks and Chinese, and was known as the "method of exhaustion". Generally speaking, the desired area is bounded from above and below, respectively, by increasingly accurate circumscribing and inscribing polygonal approximations whose exact areas can be computed. By considering approximations consisting of a larger and larger ("infinite") number of smaller and smaller ("infinitesimal") pieces, the area bound by the curve can be deduced, as the upper and lower bounds defined by the approximations converge around a common value.

The spirit of this basic strategy can easily be seen in the definition of the Riemann integral, in which the integral is said to exist if upper and lower Riemann (or Darboux) sums converge to a common value as thinner and thinner rectangular slices ("refinements") are considered. Though the machinery used to define it is much more elaborate compared to the Riemann integral, the Lebesgue integral was defined with similar basic ideas in mind. Compared to the Riemann integral, the more sophisticated Lebesgue integral allows area (or length, volume, etc.; termed a "measure" in general) to be defined and computed for much more complicated and irregular subsets of Euclidean space, although there still exist "non-measurable" subsets for which an area cannot be assigned.

The Riemann integral is defined in terms of Riemann sums of functions with respect to tagged partitions of an interval. Let formula_297 be a closed interval of the real line; then a tagged partition formula_298 of formula_297 is a finite sequence

This partitions the interval formula_297 into formula_66 sub-intervals formula_303 indexed by formula_304, each of which is "tagged" with a distinguished point formula_305. For a function formula_30 bounded on formula_297, we define the Riemann sum of formula_30 with respect to tagged partition formula_298 as

where formula_311 is the width of sub-interval formula_312. Thus, each term of the sum is the area of a rectangle with height equal to the function value at the distinguished point of the given sub-interval, and width the same as the sub-interval width. The mesh of such a tagged partition is the width of the largest sub-interval formed by the partition, formula_313. We say that the Riemann integral of formula_30 on formula_297 is formula_316 if for any formula_40 there exists formula_41 such that, for any tagged partition formula_298 with mesh formula_320, we have

This is sometimes denoted formula_322. When the chosen tags give the maximum (respectively, minimum) value of each interval, the Riemann sum is known as the upper (respectively, lower) Darboux sum. A function is Darboux integrable if the upper and lower Darboux sums can be made to be arbitrarily close to each other for a sufficiently small mesh. Although this definition gives the Darboux integral the appearance of being a special case of the Riemann integral, they are, in fact, equivalent, in the sense that a function is Darboux integrable if and only if it is Riemann integrable, and the values of the integrals are equal. In fact, calculus and real analysis textbooks often conflate the two, introducing the definition of the Darboux integral as that of the Riemann integral, due to the slightly easier to apply definition of the former.

The fundamental theorem of calculus asserts that integration and differentiation are inverse operations in a certain sense.

Lebesgue integration is a mathematical construction that extends the integral to a larger class of functions; it also extends the domains on which these functions can be defined. The concept of a measure, an abstraction of length, area, or volume, is central to Lebesgue integral probability theory.

Distributions (or generalized functions) are objects that generalize functions. Distributions make it possible to differentiate functions whose derivatives do not exist in the classical sense. In particular, any locally integrable function has a distributional derivative.

Real analysis is an area of analysis that studies concepts such as sequences and their limits, continuity, differentiation, integration and sequences of functions. By definition, real analysis focuses on the real numbers, often including positive and negative infinity to form the extended real line. Real analysis is closely related to complex analysis, which studies broadly the same properties of complex numbers. In complex analysis, it is natural to define differentiation via holomorphic functions, which have a number of useful properties, such as repeated differentiability, expressability as power series, and satisfying the Cauchy integral formula.

In real analysis, it is usually more natural to consider differentiable, smooth, or harmonic functions, which are more widely applicable, but may lack some more powerful properties of holomorphic functions. However, results such as the fundamental theorem of algebra are simpler when expressed in terms of complex numbers.

Techniques from the theory of analytic functions of a complex variable are often used in real analysis – such as evaluation of real integrals by residue calculus.

Important results include the Bolzano–Weierstrass and Heine–Borel theorems, the intermediate value theorem and mean value theorem, Taylor's theorem, the fundamental theorem of calculus, the Arzelà-Ascoli theorem, the Stone-Weierstrass theorem, Fatou's lemma, and the monotone convergence and dominated convergence theorems.

Various ideas from real analysis can be generalized from the real line to broader or more abstract contexts. These generalizations link real analysis to other disciplines and subdisciplines. For instance, generalization of ideas like continuous functions and compactness from real analysis to metric spaces and topological spaces connects real analysis to the field of general topology, while generalization of finite-dimensional Euclidean spaces to infinite-dimensional analogs led to the concepts of Banach spaces and Hilbert spaces and, more generally to functional analysis. Georg Cantor's investigation of sets and sequence of real numbers, mappings between them, and the foundational issues of real analysis gave birth to naive set theory. The study of issues of convergence for sequences of functions eventually gave rise to Fourier analysis as a subdiscipline of mathematical analysis. Investigation of the consequences of generalizing differentiability from functions of a real variable to ones of a complex variable gave rise to the concept of holomorphic functions and the inception of complex analysis as another distinct subdiscipline of analysis. On the other hand, the generalization of integration from the Riemann sense to that of Lebesgue led to the formulation of the concept of abstract measure spaces, a fundamental concept in measure theory. Finally, the generalization of integration from the real line to curves and surfaces in higher dimensional space brought about the study of vector calculus, whose further generalization and formalization played an important role in the evolution of the concepts of differential forms and smooth (differentiable) manifolds in differential geometry and other closely related areas of geometry and topology.





</doc>
<doc id="26479" url="https://en.wikipedia.org/wiki?curid=26479" title="Richie Benaud">
Richie Benaud

Richard Benaud (; 6 October 1930 – 10 April 2015) was an Australian cricketer who, after his retirement from international cricket in 1964, became a highly regarded commentator on the game.

Benaud was a Test cricket all-rounder, blending leg spin bowling with lower-order batting aggression. Along with fellow bowling all-rounder Alan Davidson, he helped restore Australia to the top of world cricket in the late 1950s and early 1960s after a slump in the early 1950s. In 1958 he became Australia's Test captain until his retirement in 1964. He became the first player to reach 200 wickets and 2,000 runs in Test cricket, arriving at that milestone in 1963.

Gideon Haigh described him as "perhaps the most influential cricketer and cricket personality since the Second World War." In his review of Benaud's autobiography "Anything But", Sri Lankan cricket writer Harold de Andrado wrote: "Richie Benaud possibly next to Sir Don Bradman has been one of the greatest cricketing personalities as player, researcher, writer, critic, author, organiser, adviser and student of the game."

Benaud was born in Penrith, New South Wales, in 1930. He came from a cricket family, with his younger brother John Benaud also going on to become an Australian Test cricketer. His father Louis, a third generation Australian of French Huguenot descent, was a leg spinner who played for Penrith District Cricket Club in Sydney Grade Cricket, gaining attention for taking all twenty wickets in a match against St. Marys for 65 runs. Lou later moved to Parramatta region in western Sydney, and played for Cumberland. Benaud also used to live in Coraki, NSW.

It was here that Richie Benaud grew up, learning how to bowl leg breaks, googlies and topspinners under his father's watch. Educated at Parramatta High School, Benaud made his first grade debut for Cumberland at age 16, primarily as a batsman.

In November 1948, at the age of 18, Benaud was selected for the New South Wales Colts, the state youth team. He scored 47 not out and took 3/37 in an innings win over Queensland. As a specialist batsman, he made his first class debut for New South Wales at the Sydney Cricket Ground against Queensland in the New Year's match of the 1948–49 season. On a green pitch which was struck by a downpour on the opening day, Benaud's spin was not used by Arthur Morris and he failed to make an impression with the bat in his only innings, scoring only two. New South Wales were the dominant state at the time, and vacancies in the team were scarce, particularly as there were no Tests that season and all of the national team players were available for the whole summer.

Relegated to the Second XI after this match, he was struck in the head above the right eye by a ball from Jack Daniel while batting against Victoria in Melbourne, having missed an attempted hook. After 28 X-rays showed nothing, it was finally diagnosed that the crater in his forehead had resulted in a skull fracture and he was sidelined for the remainder of the season, since a second impact could have been fatal. He spent two weeks in hospital for the surgery. This was the only match he played for the second-string state team that summer.

In his early career, Benaud was a batting all-rounder, marked by a looping backlift which made him suspect against fast bowling but allowed him to have a wide attacking stroke range. At the start of the 1949–50 season, he was still in the Second XI, but when the Test players departed for a tour of South Africa soon afterwards, vacancies opened up. Benaud was recalled to the New South Wales First XI in late December for the Christmas and New Year's fixtures. With Ray Lindwall, Keith Miller and Ernie Toshack, three of Australia's leading four bowlers from the 1948 "Invincibles" tour of England unavailable, Benaud bowled heavily in some matches. However, he did not have much success in his five games, taking only five wickets at 54.00.

He took the wicket of Queensland batsman Bill Brown in his third match of the season. Benaud erroneously recalled in an autobiography that this was his maiden wicket—it was his fourth—and described the ball as "the worst I ever bowled". He had more success with the bat, scoring 93 and narrowly missing a century against South Australia. He added another fifty and ended with 250 runs at 31.25.

The next season, England toured Australia, and with the Test players back, Benaud was initially forced out of the team. He was recalled for a match against the Englishmen. He was attacked by the touring batsmen, taking 1/75 from 16.5 overs in his first outing against an international outfit. His only wicket was that of the all-rounder Trevor Bailey. He scored 20 not out and was not called on to bowl in the second innings.

In the next Shield match against Victoria, led by Australian captain Lindsay Hassett, Benaud came in for attack. Hassett was known for his prowess against spin bowling, being the only batsman to score centuries in a match against the leg-spin of Bill O'Reilly, regarded as the finest bowler of his age. Hassett struck 179 in four hours, and took 47 runs from Benaud's seven overs. The young leg spinner claimed Hassett in the second innings when a ball landed in a crack and skidded through onto his foot. He ended with 3/56, the first time he had taken three wickets in a match.

In the next match against South Australia, he made 48, took 4/93 and 1/29 and suffered three dropped catches by the wicketkeeper in successive balls. Benaud was cementing his position and was in the senior team for four consecutive matches even with the Test players available. He was selected for an Australian XI match against England, in what was effectively a trial for Test selection, but suffered a chipped bone in his thumb. This put him out of action until the last match of the season, leaving him with little opportunity to impress the national selectors for his rise to international cricket. Benaud returned and scored 37 and took a total of 2/68 in the final match, ending the season with 184 runs at 36.80 and 11 wickets at 34.63.

The 1951–52 season saw a tour to Australia by the West Indies. Benaud was given a chance against the visiting team when New South Wales played them in Sydney after the First Test. On a green pitch, Benaud came in at 7/96 and featured in a century partnership in only an hour, making 43 himself. The Caribbeans were skittled for 134 in reply and went on to lose the match, although they attacked the young leg-spinner, who took 1/130 in total from 36 overs. Benaud scored his maiden first-class century, 117 against South Australia, in the next match, two years after falling short of the milestone by seven runs. In the next four matches, Benaud passed 15 only once, scoring a 34, and took only seven wickets. Up to this point, in seven matches for the season, the young all-rounder had only scored 307 runs at 27.90 and taken ten wickets at 64.80.

Despite this, Benaud was chosen for his Test debut in the Fifth Test against the West Indies in 1951–52 in Sydney. At this point, Australia had already taken an unassailable 3–1 series lead and decided to try out some young players. Selected as a batsman, he scored 3 and 19. Hassett allowed him to bowl only in the second innings, when nine West Indian wickets had fallen and Australia were on the verge of an inevitable victory. Leading opposition batsman Everton Weekes edged Benaud in his first over, but Gil Langley dropped the catch. Benaud went on to dismiss tail-ender Alf Valentine for his first Test wicket, conceding 14 runs from 4.3 overs. Benaud ended his season with 97 and a total of 3/39 in an innings win over South Australia.

The following Australian season in 1952–53, Benaud started modestly and in the five first-class matches before the Tests, scored 208 runs at 26.00 including a 63 and 69, and 14 wickets at 38.64. This included figures of 2/70 and 4/90 against the touring
South Africa. However, this was not enough to ensure his selection in the First Test, where he was made 12th man. After scoring 60 and 37 and taking 1/60 in an Australian XI against the South Africans following the Test, he was selected for the Second Test. He suffered a smashed gum and a severely cut top lip when a square cut by John Waite in the Third Test against South Africa at the Sydney Cricket Ground hit him in the face while he was fielding at short gully.

Doctors told him he was lucky: it could have broken his cheekbones, jaw or removed his eyesight if it had hit any of the surrounding areas. It could have killed him if it had struck him where his skull was previously fractured. He married after the match and had to mumble his wedding vows through a swathe of bandages. Benaud went on to play in the final four Tests. He made 124 runs at 20.66, making double figures in four of seven innings, but was unable to capitalise on his starts, with a top score of 45. His leg spin yielded ten wickets at 30.60, with a best of 4/118 in the Fourth Test in Adelaide when he was given a heavy workload, totalling 58 overs, when Ray Lindwall and Keith Miller broke down during the match. In another match for New South Wales against the touring team, he took a total of 5/95.

Up to this point, his first-class batting average was below 30 and his bowling average close to 40, and he had never taken more than four wickets in an innings or six in a match.

The selectors persisted in Benaud despite his unproductive Test performances, selecting him for the squad for the 1953 Ashes tour of England. He had been seventh and eighth in the domestic runscoring and wicket-taking aggregates for the season, but was yet to convert this into international performance. He justified their decision prior to the team's departure, scoring 167 not out and taking match figures of 7/137 for the touring team against a Tasmania Combined XI, his wickets including Test batsmen Miller, Ian Craig and Neil Harvey. He also put on 167 in a partnership with Alan Davidson, the first collaboration between the pair, who would later go on to lead Australia's bowling in the last five years of their career. Benaud struck an unbeaten 100 and totalled 1/64 in the next match against Western Australia before the Australians departed for England.

On arrival in the British Isles, Benaud quickly made an impression with both bat and ball. After scoring 44 and taking 2/66 in the opening first-class match against Worcestershire, the all-rounder starred in his next match, against Yorkshire. He scored 97 in Australia's only innings and then took 7/46 in the hosts' first innings as the Australians took an innings win. Although his form with the willow dropped off in his remaining six matches before the Tests—a 35 was his only score beyond 20 in seven attempts—Benaud continued to strike regularly with the ball. He took 18 wickets in these matches, including 3/20 and 3/37 against Oxford University, 5/13 against Minor Counties and 4/38 against Hampshire. This was enough for him to gain selection for the start of the Tests.

He managed only eight runs in four innings in the first two Tests, and having taken only two wickets for 136 runs was dropped for the Third. This was part of a month-long run in which he made only 123 runs in eight innings and took only seven wickets in four matches. He was recalled immediately for the Fourth Test, but was dropped for the Fifth after managing seven runs in his only innings and going wicketless. He ended the Test series with 15 runs at 3.00 and two wickets at 87.00. It was thought that the surface at the Oval would favour pacemen, but Australia's selection proved to be a blunder as England's spinners took them to the only win of the series, allowing them to regain the Ashes.

He also showed his hitting ability in a tour match against T.N. Pearce's XI at Scarborough. Opening the batting, he struck 135 in 110 minutes in the second innings, including an Australian record of eleven sixes, four of them in one over. In eight first-class matches after his Test campaign was over, Benaud added a further half-century in addition to the century against Pearce's XI, and took 22 more wickets, including 4/20 against the Gentlemen of England.

After returning home from his first overseas tour, Benaud was prolific during the 1953–54 Australian season, which was purely domestic with no touring Test team. He contributed significantly with both bat and ball in New South Wales' Sheffield Shield triumph, the first of nine consecutive titles. In the opening match of the season, he struck 158 and took 5/88 and 1/65 against Queensland. He made another century in the return match, striking 144 not out and taking a total of 2/55. Midway through the season, he played in Morris's XI in a testimonial match for Hassett, who captained the other team. Benaud scored 78 and 68 and took a total of 5/238, his dismissals being Davidson and frontline Test batsmen in a 121-run win. He then finished the summer strongly, and ended the season with 811 runs at 62.38 and 35 wickets at 30.54. Benaud was the only bowler selected for all five Tests of the 1954–55 series when England visited Australia. He secured his place after scoring 125 against Queensland at the start of the season, although his lead-up form in two matches against England for his state and an Australian XI was not encouraging.

At this stage of his career, he had played 13 Tests with mediocre results. Selected as a batsman who could bowl, he had totalled 309 runs at 15.45 without passing 50, and taken 23 wickets at 37.87 with only two four-wicket innings hauls. Even so, he was promoted to vice-captain above several senior players when Ian Johnson and Keith Miller missed the 2nd Test at Sydney through injury and Arthur Morris was made temporary captain. He also made 113 against the touring side for the Prime Minister's XI.

Australia's selectors persisted and selected him for the squad to tour the West Indies in 1954–55. Their faith was rewarded by an improvement in performances. Benaud contributed 46 and match figures of 2/73 in a First Test victory at Kingston. After a draw in the Second Test, he took three wickets in four balls to end with 4/15 in the first innings at Georgetown, Guyana, before scoring 68 (his first Test half century) as Australia moved to a 2–0 series lead. In the Fifth Test at Kingston, he struck a century in 78 minutes, despite taking 15 minutes to score his first run. He ended with 121 and took four wickets in the match as Australia won by an innings and took the series 3–0. Benaud had contributed 246 runs at 41 and taken wickets steadily to total 18 at 26.94.

During the 1956 tour to England, he helped Australia to its only victory in the Lord's Test, when he scored a rapid 97 in the second innings in 143 minutes from only 113 balls. His fielding, in particular at gully and short leg, was consistently of a high standard, in particular his acrobatic catch to dismiss Colin Cowdrey. He was unable to maintain the standards he had set in the West Indies, contributing little apart from the Lord's Test. He ended the series with 200 runs at 25 and eight wickets at 42.5.

Benaud's bowling reached a new level on the return leg of Australia's overseas tour, when they stopped in the Indian subcontinent in 1956–57 en route back to Australia. In a one-off Test against Pakistan in Karachi, he scored 56 and took 1/36 as Australia fell to defeat. He claimed his Test innings best of 7/72 in the first innings of the First Test in Madras, allowing Australia to build a large lead and win by an innings. It was his first five-wicket haul in a Test innings. After taking four wickets in the drawn Second Test in Bombay,

Benaud bowled Australia to victory in the Third Test in Calcutta, sealing the series 2–0. He took 6/52 and 5/53, his best-ever match analysis, ending the series with 113 runs at 18.83 and 24 wickets at 17.66.

It was the first of his successes against India, against whom he took his wickets at an average of 18. This put him in a small group of spinners whose career averages were inferior to their performances against India, generally regarded as the best players of spin in the world. At this stage of his career, he had yet to perform consistently with bat and ball simultaneously, apart from his breakthrough series in the Caribbean. He had managed, in the 14 Tests since then, 559 runs at 27.95 and 67 wickets at 24.98.

After a break in the international calendar of a year, the 1957–58 tour to South Africa heralded the start of a phase of three international seasons when Benaud was at his peak. The tour saw his bowling talents come to the fore when he took 106 wickets, surpassing the previous record of 104 by England's Sydney Barnes. He scored 817 runs including four centuries, two of them in Test matches. The first of these came in the First Test at Johannesburg, where after conceding 1/115, Benaud struck 122, his highest Test score, to see Australia reach a draw.

In the Second Test at Cape Town, Benaud took 4/95 and then 5/49 in the second innings to secure an innings victory after the home team were forced to follow on. He followed this with 5/114 in a drawn Third Test, before a match-winning all round performance in the Fourth Test in Johannesburg. Benaud struck exactly 100 in the first innings, before taking 4/70 in South Africa's reply. When South Africa followed on, Benaud took 5/84, which left Australia needing only one run to win. He took 5/82 in the second innings of the Fifth Test, the fourth consecutive match in which he had taken five wickets in an innings, as Australia took a 3–0 series win. He had been a major contributor to the series win, scoring 329 runs at 54.83 and taking 30 wickets at 21.93, establishing himself as one of the leading leg spinners of the modern era.

When Ian Craig fell ill at the start of the 1958–59 season, Benaud was promoted to the captaincy ahead of vice-captain Neil Harvey. Harvey and Benaud had been captains of their respective states until Harvey moved in the same season for employment purposes from Victoria to New South Wales and became Benaud's deputy. Benaud had little prior leadership experience, and faced the task of recovering the Ashes from an England team which had arrived in Australia as favourites. He led from the front with his bowling, taking match figures of 7/112 in his debut as captain as Australia claimed the First Test in Brisbane. Benaud's men won the Second Test, before he took 5/83 and 4/94 in the drawn Third Test. Benaud produced an all-round performance of 46, 5/91 and 4/82 in the Fourth Test in Adelaide to take an unassailable 3–0 series lead and regain the Ashes, before scoring 64 and match figures of 5/57 to help take the Fifth Test and a 4–0 series result. Benaud contributed 132 runs at 26.4 and 31 wickets at the low average of 18.83, as well as his shrewd and innovative captaincy. According to Neil Harvey, he also was the first captain who started hosting team meetings, a procedure now followed by his successors after he retired.

Benaud then led Australia on its first full tour of the Indian subcontinent, playing three and five Tests against Pakistan and India respectively. Benaud took 4/69 and 4/42 in the First Test in Dacca (now in Bangladesh), sealing Australia's first win in Pakistan. He took four wickets in a Second Test in Lahore that sealed the series 2–0, the last time Australia would win a Test in Pakistan until Mark Taylor's men in 1998, 37 years later. Six further wickets in the drawn Third Test saw Benaud end the series with 84 runs at 28 and 18 wickets at 21.11. Benaud made a strong start to the series against India, taking 3/0 in the first innings of the First Test in Delhi, before a 5/76-second innings haul secured an innings victory. Benaud had less of an impact on the next two Tests, which Australia lost and drew, totaling 6/244. He returned to form with 5/43 and 3/43 as India were defeated by an innings after being forced to follow on in the Fourth Test in Madras. A further seven wickets from the captain in the Fifth Test saw Australia secure a draw and the series 2–1.

Benaud had contributed 91 runs at 15.16 and 29 wickets at 19.59. The first two seasons of the Benaud captaincy had been a resounding success, with Australia winning eight, drawing four and losing only one Test. Benaud's personal form was a major factor in this success. In the previous seasons when he and his team were at their peak, he had scored 636 runs at 31.8 with taken 108 wickets at 20.27 in eighteen Tests, averaging six wickets a match.

Benaud took over when Australian cricket was in a low phase with a young team. His instinctive, aggressive captaincy and daring approach to cricket – and his charismatic nature and public relations ability – revitalised cricket interest in Australia. This was exhibited in the 1960–61 Test series against the visiting West Indians, in which the grounds were packed to greater levels than they are today despite Australia's population doubling since then.

The First Test in Brisbane ended in the first tie in Test history, which came about after Benaud and Alan Davidson, rather than settle for a draw, decided to risk defeat and play an attacking partnership, which took Australia to the brink of victory. Australia had fallen to 6/92 on the final day chasing a target of 233 with Benaud and Davidson at the crease. Australia's chances of winning looked remote when they reached tea at 6/109 with 124 runs still required with only the tailenders to follow. Despite this, Benaud told chairman of selectors Don Bradman that he would still be going for an improbable victory in accordance with his policy of aggression. With an attacking partnership, the pair took Australia to within sight of the target.

Both men were noted for their hitting ability and viewed attack as their most effective chance of survival. Regular boundaries and quickly-run singles took the score to 226, a seventh-wicket partnership of 134. Only seven runs were required with four wickets in hand as time was running short. Benaud hit a ball into the covers and the pair attempted a quick single when a direct hit from Joe Solomon saw Davidson run out. Australia needed six runs from the final over, in which Benaud was caught and the last two wickets fell to run outs while attempting the winning run.

The Test was tied when Solomon ran out Ian Meckiff with a direct hit. Benaud had an unpenetrative match with the ball, taking 1/162. He took 4/107 in a seven-wicket victory in Melbourne, before the West Indies levelled the series with a 22-run win in Sydney. Benaud had a heavy load in the match taking 8/199 after Davidson tore a hamstring mid-match. In Adelaide, with Davidson absent, Benaud bowled long spells to take match figures of 7/207 in addition to a score of 77 in the first innings. With Davidson back, Australia won the final Test by two wickets, after a controversial incident in which Australian wicketkeeper Wally Grout was not given out hit wicket when a bail was dislodged and the umpires did not notice. Australia won the series 2–1, and although Benaud was below his best, scoring at 21.77 and taking 23 wickets at 33.87, the series was a success for cricket. The unprecedented public interest saw the Caribbean touring party farewelled with a ticker-tape parade by the Australian public. Along with the West Indian captain Frank Worrell, Benaud's bold leadership enlivened interest in Test cricket among a public who had increasingly regarded it as boring.

On his third and final tour to England in 1961, he was hampered by damaged tendons in his right shoulder, which forced him to miss the Second Test at Lord's known as the "Battle of the Ridge". In all he missed a third of the matches due to injury. Despite this impairment to his bowling shoulder, his team played with an aggressive strategy leading them to lose only one Test match and no other matches during the tour, honouring his pre-series pledge. The First Test at Edgbaston was drawn with Benaud taking three wickets. After Harvey led the team to victory at Lord's, Benaud had an unhappy return in the Third at Headingley scoring two runs in two innings and taking match figures of 2/108 as Australia lost within three days. With the series balanced at 1–1, the Fourth Test at Old Trafford initially brought no improvement, with Benaud scoring 2 and taking 0/80 in the first innings. He made 1 in the second before a last-wicket partnership between Davidson and Graham McKenzie of 98 yielded a defendable target.

During England's chase on the final afternoon it became apparent that, with Ted Dexter scoring quickly, Australia would lose the Test unless England were bowled out. Benaud went around the wicket and bowled into the footmarks, having Dexter caught behind and then Peter May bowled around his legs. Benaud's 5/13 in 25 balls instigated an English collapse which saw Australia retain the Ashes. He finished the innings with 6/70. Benaud then took four wickets in the drawn Fifth Test to end the series 2–1. Benaud had a poor series with the bat, scoring 45 runs at 9, but was more successful with the ball, taking 15 wickets at 32.53. He finished the first-class tour with 627 runs and 61 wickets at 23.54. He was appointed an OBE in that year and in 1962 was named as one of the "Wisden" Cricketers of the Year.

The 1961–62 Australian season was purely a domestic one, with no touring international team. Benaud led New South Wales throughout a dominant season, winning the Sheffield Shield with 64 of the 80 possible points. Benaud was the leading wicket-taker of the season with 47 at 17.97. His aggressive tactical style brought large crowds throughout the season, with almost 18,000 watching one match against South Australia.

In another match against Victoria, he ordered his team to attempt to score 404 on the final day to take an unlikely victory in accordance with a promise to score at 400 per day. At one stage, New South Wales were six wickets down with less than 150 runs scored, but Benaud refused to attempt to defend for a draw. He made 140, in a seventh-wicket partnership of 255 in just 176 minutes, an Australian record that still stands.

1962–63 saw an English team under Dexter visit Australia. Fred Trueman with 216 Test wickets and Brian Statham with 229 were poised to overtake the record of 236 Test wickets set by the assistant-manager Alec Bedser. Benaud was another contender with 219 wickets, but it was Statham who broke the record (only to be overtaken by Trueman in New Zealand) and Benaud had to be content with breaking Ray Lindwall's Australian record of 228 Test wickets. In an early tour match Benaud took his best first class innings haul of 18–10–18–7 for New South Wales against the MCC, which lost by an innings and 80 runs, the state's biggest win against the English team. Benaud started the series with seven wickets and a half century as the First Test in Brisbane was drawn. This was followed by three unproductive Tests which yielded only 5/360 and a win apiece. Benaud returned to form with match figures of 5/142 and 57 in the Fifth Test at Sydney, which ended in a draw when Benaud ordered Bill Lawry and Peter Burge to play out the last afternoon for a draw that would retain the Ashes. They were booed and heckled as they left the field and Benaud's reputation as a "go ahead" cricket captain was badly tanished. The draw meant that the series was shared 1–1, the first time he had drawn a series after five successive wins. It was another lean series with the ball, Benaud's 17 wickets costing 40.47, the third consecutive series where his wickets cost more than 30. His batting was reliable, with 227 runs at 32.47.

At the start of the 1963–64 season, Benaud announced that it would be his last at first-class level. The first Test of the season, against the touring South Africans, saw high drama as Australia's left arm paceman Ian Meckiff was called for throwing by Colin Egar and removed from the attack by Benaud after one over. Benaud did not bowl Meckiff from the other end, and at the end of the match Meckiff announced his retirement. Benaud took 5/72 and scored 43 in the First Test, but then injured himself in a grade match, so Bob Simpson captained the team for the Second Test and won the match in Benaud's absence.

Upon his return, Benaud advised the Australian Cricket Board that it would be in the better interests of the team if Simpson continued as captain for the remainder of the season. Benaud took 3/116 to complement scores of 43 and 90 on his return in the Third Test in Sydney. His final two Tests saw no fairytale finish, yielding only four wickets and 55 runs. His batting had been steady though with 231 runs at 33, but his bowling unpenetrative with 12 wickets at 37.42.

Benaud was awarded life membership by the New South Wales Cricket Association, but he returned it in protest in 1970 when his younger brother John was removed from the captaincy. In 1967–68 he captained a Commonwealth team against Pakistan, playing in his last five first-class fixtures.

During Benaud's captaincy, Australia did not lose a series, and became the dominant team in world cricket. His success was based on his ability to attack, his tactical boldness and his ability to extract more performance from his players, in particular Davidson. He was known for his unbuttoned shirt, and raised eyebrows with his on-field exuberance. Benaud embraced his players when opposition wickets fell, something that was uncommon at the time. Benaud's bold leadership coupled with his charismatic nature and public relations ability enlivened interest in Test cricket among a public who had increasingly regarded it as boring.

Benaud was not a large spinner of the ball, but he was known for his ability to extract substantial bounce from the surface. In addition to his accurate probing consistency, he possessed a well-disguised googly and topspinner which tricked many batsmen and yielded him many wickets. In his later career, he added the flipper, a combination of the googly and top spinner which was passed to him by Bruce Dooland. Coupled with his subtle variations in flight and angle of the delivery, he kept the batsman under constant pressure. Benaud had the tendency to bowl around the wicket at a time when he was one of the first players to do so; it had an influence on spin bowlers like Shane Warne and Ashley Giles. Benaud was regarded as one of the finest close-fielders of his era, either at gully or in a silly position. As a batsman, he was tall and lithe, known for his hitting power, in particular his lofted driving ability from the front foot.

Johnnie Moyes said "Certainly Benaud received a little help from the roughened patches, but he could do what the off-spinners could not do: he could turn the ball, mostly slowly, sometimes with more life. His control was admirable, and when Benaud gets a batsman in trouble he rarely if ever gives him a loose one. He keeps him pinned down, probing and probing until the victim is well and truly enmeshed."


After the 1956 England tour, Benaud stayed behind in London to take a BBC presenter training course. He took up a journalism position with the "News of the World", beginning as a police roundsman before becoming a sports columnist. In 1960 he made his first radio commentary in the United Kingdom at the BBC, after which he moved into television.

After retiring from playing in 1964, Benaud turned to full-time cricket journalism and commentary, dividing his time between Britain (where he worked for the BBC for many years before joining Channel 4 in 1999), and Australia (for the Nine Network). Overall he played in or commentated on approximately 500 Test matches, as he himself noted in one of his final interviews in Britain when asked if he would miss Test cricket.

He openly criticized the actions by the Chappell brothers (Trevor and Greg) in the post-match reaction to the underarm bowling incident of 1981, proving his moral integrity far outweighed his unconditional patriotism for Australia. He vacated the commentary booth when New Zealand was about to clinch a test victory at Lord's in 1999, allowing former New Zealand captain-turned-commentator Ian Smith to call the famous victory of his compatriots. Some of his other memorable moments he commentated on included Shane Warne's "Ball of the Century", Ian Botham's dominant all-round display during the 1981 Ashes, Dennis Lillee overtaking Benaud's record for most wickets, and subsequent 300th and 310th wickets, and Andrew Symonds' tackle on a streaker.

The idea for what became his trademark—wearing a cream or white jacket during live commentary—came from Channel 9 owner Kerry Packer, who suggested the look to help Benaud stand out from the rest of the commentary team.

He also helped to design a computer-based parody of himself available for download off Channel 4's website called "Desktop Richie". It was developed by the software company Turtlez Ltd. Having downloaded this, cricket fans would be treated to live Test match updates and weather reports from a cartoon version of Benaud with real voice samples such as "Got 'im!" and "That's stumps ... and time for a glass of something chilled". On Channel 4's live commentary, Benaud often made sarcastic comments regarding the advertisement of Desktop Richie.

In 2004, Benaud starred in a series of television advertisements for the Australian Tourism Commission, aimed at promoting Australia as a tourist destination. Benaud's ad featured him in various scenic locations uttering his signature comment, "Marvellous!". It was also emulated by New Zealand broadcaster John Campbell. He appeared in "Richie Benaud's Greatest XI", a video in which he chooses his own team.

Benaud became a staunch advocate of cricket being available on free-to-view TV. He chose to end his British commentary career, which spanned more than 42 years, when the rights to broadcast live Test match cricket were lost by Channel 4 to the subscription broadcaster British Sky Broadcasting. Thus, the 2005 Ashes series was the last that Benaud commentated on in Britain. His final commentary came near the end of the final day of the Fifth Test at the Oval. His last goodbye was interrupted by Glenn McGrath taking Kevin Pietersen's wicket; Benaud simply wove his description of the dismissal into what he was already saying. Benaud stated he would spend the Northern Hemisphere summer in Britain writing, and would continue working for the Nine Network in Australia.

Benaud commentated for the BBC TV highlights of the 2006–07 Ashes in Australia as part of his continuing commentary work for Australia's Nine Network.

Benaud's distinctive speaking style has been frequently parodied on the Australian comedy series "Comedy Inc." and "The Twelfth Man". In the case of the latter, comedian Billy Birmingham's impersonations of Benaud on The Twelfth Man comedy recordings have become very successful, spanning more than twenty years. Chris Barrie of "Red Dwarf" fame incorporated impressions of Benaud into his stand-up repertoire.

On 18 February 2009, during a radio interview, Benaud announced that he would be retiring from television commentary. Benaud said: "I'll be doing Australian cricket next year—2010—but I don't do any television at all anywhere else now and when I finish next year, then I'll be doing other things ... But that'll be no more television commentary".

It was announced on 15 November 2009, that Benaud had signed a three-year contract with the Nine Network to continue being part of their cricket coverage until 2013, although his role would change from that of ball-by-ball commentary. Benaud said: "I won't be doing live commentary any more." Someone asked me, "Does that mean you'll never again go into the commentary box?", "Well, the answer to that", Benaud replied, "If there is, as there always can be, some emergency or a sensational happening on or off the field where it would be quite ridiculous not to go into the commentary box, of course I'll be in there doing my job and doing it as professionally as I can. But I won't be on the live commentary roster. But I will be doing all sorts of, what I regard as, interesting things for Channel Nine on the cricket—special features on the cricket ...". Richie commentated regularly during the 2011–12 season and was part of Nine's commentating team/roster.

Benaud married Marcia Lavender in 1953 and had two sons, Greg and Jeffery, from this marriage; he divorced Marcia in 1967. In 1967, he married his second wife, Daphne Surfleet, who had worked for the English cricket writer E. W. Swanton. Benaud and Daphne often stayed at their holiday home in Beaulieu-sur-Mer on the French Riviera.

On 29 October 2008, Benaud's mother, Irene, died, aged 104. He said of her, "She improved my love of vegetables by introducing the phrase, 'You can't go out and play cricket until you have eaten all your vegetables.'"

In October 2013 Benaud crashed his vintage 1965 Sunbeam Alpine into a wall while driving near his home in Coogee, a beachside suburb in Sydney's east. He sustained a cracked sternum and shoulder injuries. Slow recovery meant he was unable to commentate for Australia's Channel Nine during the 2013–14 Ashes series.

Benaud had last handed "Baggy green" caps to Simon Katich and Mitchell Starc when they made their test debut, but Benaud's own was lost early in his test career, and former captain, now commentator and Director of Cricket Australia, Mark Taylor was to present the replacement cap to him at the semi-final of the 2015 Cricket World Cup between Australia and India at the SCG, but Benaud was too unwell to attend, and when the cap arrived at Channel 9 headquarters, it was the day before Benaud died. It was presented to his wife.

In November 2014, at age 84, Benaud announced that he had been diagnosed with skin cancer. He died in his sleep on 10 April 2015.
Prime Minister Tony Abbott offered his family a state funeral but his widow, Daphne, declined, respecting his wishes for a private funeral.

Benaud was buried on 15 April, in a private funeral ceremony attended only by his immediate family. Later that same day, there was a commemoration service officiated by former teammate turned lay preacher Brian Booth; attendees included his family and close friends, among them former players Shane Warne and Ian Chappell, and then Australian Test captain Michael Clarke.

Benaud was made an Officer of the Order of the British Empire (OBE) in 1961 for services to cricket. He was inducted into the Sport Australia Hall of Fame in 1985. In 1999 he was awarded a Logie Award for Most Outstanding Sports Broadcaster.

In 2007, he was inducted into the Australian Cricket Hall of Fame at the Allan Border Medal award evening and in 2009 he was inducted into the ICC Cricket Hall of Fame.

In November 2015, Benaud became an honouree at Bradman Foundation, having been a long-serving patron in his life. After rain interrupted the 2016 SCG Test against West Indies, the second day unofficially became Richie Benaud Day as 501 Benaud impersonators stayed at the SCG, which is a day before the annual Jane McGrath Day for Breast Cancer awareness and fundraising, which was again rained out.　

In 2017, the Australian Mint issued a 50-cent coin commemorating Benaud.

In October 2018, Benaud became the 40th Legend in the Sport Australia Hall of Fame.

Benaud wrote a number of books:




</doc>
<doc id="26480" url="https://en.wikipedia.org/wiki?curid=26480" title="Radio Research Project">
Radio Research Project

The Radio Research Project was a social research project funded by the Rockefeller Foundation to look into the effects of mass media on society.

In 1937, the Rockefeller Foundation started funding research to find the effects of new forms of mass media on society, especially radio. Several universities joined up and a headquarters was formed at the School of Public and International Affairs at Princeton University. 

Among the subjects of the Project's first studies were soap operas, known as radio dramas at the time.

The Radio Project also conducted research on the infamous Halloween broadcast of "The War of the Worlds" in 1938. Of the estimated six million people who heard this broadcast, they found that 25% accepted the program's reports of mass destruction. The majority of these did not think they were hearing a literal invasion from Mars, but rather an attack by Germany. The researchers determined that radio broadcasts from the Munich Crisis may have lent credence to this supposition.

A third research project was that of listening habits. Because of this, a new method was developed to survey an audience – this was dubbed the Little Annie Project. The official name was the Stanton-Lazarsfeld Program Analyzer. This allowed one not only to find out if a listener liked the performance, but how they felt at any individual moment, through a dial which they would turn to express their preference (positive or negative). This has since become an essential tool in focus group research.

Theodor Adorno produced numerous reports on the effects of "atomized listening" which radio supported and of which he was highly critical. However, because of profound methodological disagreements with Lazarsfeld over the use of techniques such as listener surveys and "Little Annie" (Adorno thought both grossly simplified and ignored the degree to which expressed tastes were the result of commercial marketing), Adorno left the project in 1941.


</doc>
<doc id="26484" url="https://en.wikipedia.org/wiki?curid=26484" title="Religious pluralism">
Religious pluralism

Religious pluralism is an attitude or policy regarding the diversity of religious belief systems co-existing in society. It can indicate one or more of the following:


Religious pluralism, to paraphrase the title of a recent academic work, goes beyond mere toleration. Chris Beneke, in "Beyond Toleration: The Religious Origins of American Pluralism", explains the difference between religious tolerance and religious pluralism by pointing to the situation in the late 18th century United States. By the 1730s, in most colonies religious minorities had obtained what contemporaries called religious toleration: "The policy of toleration relieved religious minorities of some physical punishments and some financial burdens, but it did not make them free from the indignities of prejudice and exclusion. Nor did it make them equal. Those 'tolerated' could still be barred from civil offices, military positions, and university posts." In short, religious toleration is only the absence of religious persecution, and does not necessarily preclude religious discrimination. However, in the following decades something extraordinary happened in the Thirteen Colonies, at least if one views the events from "a late eighteenth-century perspective". Gradually the colonial governments expanded the policy of religious toleration, but then, between the 1760s and the 1780s, they replaced it with "something that is usually called religious liberty". Mark Silka, in "Defining Religious Pluralism in America: A Regional Analysis", states that Religious pluralism "enables a country made up of people of different faiths to exist without sectarian warfare or the persecution of religious minorities. Understood differently in different times and places, it is a cultural construct that embodies some shared conception of how a country's various religious communities relate to each other and to the larger nation whole."

Religious pluralism can be defined as "respecting the otherness of others". Freedom of religion encompasses all religions acting within the law in a particular region. Exclusivist religions teach that theirs is the only way to salvation and to religious truth, and some of them would even argue that it is necessary to suppress the falsehoods taught by other religions. Some Protestant sects argue fiercely against Roman Catholicism, and fundamentalist Christians of all kinds teach that religious practices like those of Paganism and witchcraft are pernicious. This was a common historical attitude prior to the Enlightenment, and has appeared as governmental policy into the present day under systems like Afghanistan's Taliban regime, which destroyed the ancient Buddhas of Bamyan.

Giving one religion or denomination special rights that are denied to others can weaken religious pluralism. This situation was observed in Europe through the Lateran Treaty and Church of England. In modern era, many Islamic countries have laws that criminalize the act of leaving Islam to someone born in Muslim family, forbid entry to non-Muslims into Mosques, and forbid construction of Church, Synagogue or Temples inside their countries.

Relativism, the belief that all religions are equal in their value and that none of the religions give access to absolute truth, is an extreme form of inclusivism. Likewise, syncretism, the attempt to take over creeds of practices from other religions or even to blend practices or creeds from different religions into one new faith is an extreme form of inter-religious dialogue. Syncretism must not be confused with ecumenism, the attempt to bring closer and eventually reunite different denominations of one religion that have a common origin but were separated by a schism.

Cultural and religious pluralism has a long history and development that reaches from antiquity to contemporary trends in post-modernity.

German philosophers of religion Ludwig Feuerbach and Ernst Troeltsch concluded that Asian religious traditions, in particular Hinduism and Buddhism, were the earliest proponents of religious pluralism and granting of freedom to the individuals to choose their own faith and develop a personal religious construct within it (see also Relationship between Buddhism and Hinduism); Jainism, another ancient Indian religion, as well as Daoism have also always been inclusively flexible and have long favored religious pluralism for those who disagree with their religious viewpoints. The Age of Enlightenment in Europe triggered a sweeping transformation about religion after the French Revolution (liberalism, democracy, civil and political rights, freedom of thought, separation of Church and State, secularization), with rising acceptance of religious pluralism and decline of Christianity. According to Chad Meister, these pluralist trends in the Western thought, particularly since the 18th century, brought mainstream Christianity and Judaism closer to the Asian traditions of philosophical pluralism and religious tolerance.

Bahá'u'lláh, founder of Bahá'í Faith, a religion that developed in Persia, though not a sect of Islam, urged the elimination of religious intolerance. He taught that God is one, and has manifested himself to humanity through several historic messengers. Bahá'u'lláh taught that Bahá'ís must associate with peoples of all religions, showing the love of God in relations with them, whether this is reciprocated or not.

Bahá'í's refer to the concept of Progressive revelation, which means that God's will is revealed to mankind progressively as mankind matures and is better able to comprehend the purpose of God in creating humanity. In this view, God's word is revealed through a series of messengers: Abraham, Krishna, Moses, Buddha, Jesus, Muhammad, and Bahá'u'lláh (the founder of the Bahá'í Faith) among them. In the "Kitáb-i-Íqán" ("Book of Certitude"), Bahá'u'lláh explains that messengers of God have a twofold station, one of divinity and one of an individual. According to Bahá'í writings, there will not be another messenger for many hundreds of years. There is also a respect for the religious traditions of the native peoples of the planet who may have little other than oral traditions as a record of their religious figures.

The earliest reference to Buddhist views on religious pluralism in a political sense is found in the Edicts of Emperor Ashoka:

All religions should reside everywhere, for all of them desire self-control and purity of heart. Rock Edict Nb7 (S. Dhammika)

Contact (between religions) is good. One should listen to and respect the doctrines professed by others. Beloved-of-the-Gods, King Piyadasi, desires that all should be well-learned in the good doctrines of other religions. Rock Edict Nb12 (S. Dhammika)

When asked, "Don’t all religions teach the same thing? Is it possible to unify them?" the Dalai Lama said:
People from different traditions should keep their own, rather than change. However, some Tibetan may prefer Islam, so he can follow it. Some Spanish prefer Buddhism; so follow it. But think about it carefully. Don’t do it for fashion. Some people start Christian, follow Islam, then Buddhism, then nothing.

In the United States I have seen people who embrace Buddhism and change their clothes! Like the New Age. They take something Hindu, something Buddhist, something, something… That is not healthy.

For individual practitioners, having one truth, one religion, is very important. Several truths, several religions, is contradictory.

I am Buddhist. Therefore, Buddhism is the only truth for me, the only religion. To my Christian friend, Christianity is the only truth, the only religion. To my Muslim friend, [Islam] is the only truth, the only religion. In the meantime, I respect and admire my Christian friend and my Muslim friend. If by unifying you mean mixing, that is impossible; useless.
For the Romans, religion was part of the daily life. Each home had a household shrine at which prayers and libations to the family's domestic deities were offered. Neighborhood shrines and sacred places such as springs and groves dotted the city. The Roman calendar was structured around religious observances; in the Imperial Era, as many as 135 days of the year were devoted to religious festivals and games ("ludi)". Women, slaves, and children all participated in a range of religious activities. Some public rituals could be conducted only by women, and women formed what is perhaps Rome's most famous priesthood, the state-supported Vestal Virgins, who tended Rome's sacred hearth for centuries, until disbanded under Christian persecution and domination.

The Romans are known for the great number of deities they honored. The presence of Greeks on the Italian peninsula from the beginning of the historical period influenced Roman culture, introducing some religious practices that became as fundamental as the cult of Apollo. The Romans looked for common ground between their major gods and those of the Greeks, adapting Greek myths and iconography for Latin literature and Roman art. Etruscan religion was also a major influence, particularly on the practice of augury, since Rome had once been ruled by Etruscan kings.

Mystery religions imported from the Near East (Ptolemaic Egypt, Persia and Mesopotamia), which offered initiates salvation through a personal God and eternal life after the death, were a matter of personal choice for an individual, practiced in addition to carrying on one's family rites and participating in public religion. The mysteries, however, involved exclusive oaths and secrecy, conditions that conservative Romans viewed with suspicion as characteristic of "magic", conspiracy ("coniuratio"), and subversive activity. Sporadic and sometimes brutal attempts were made to suppress religionists who seemed to threaten traditional Roman morality and unity, as with the Senate's efforts to restrict the Bacchanals in 186 BC.
As the Romans extended their dominance throughout the Mediterranean world, their policy in general was to absorb the deities and cults of other peoples rather than try to eradicate them, since they believed that preserving tradition promoted social stability.

One way that Rome incorporated diverse peoples was by supporting their religious heritage, building temples to local deities that framed their theology within the hierarchy of Roman religion. Inscriptions throughout the Empire record the side-by-side worship of local and Roman deities, including dedications made by Romans to local Gods. By the height of the Empire, numerous international deities were cultivated at Rome and had been carried to even the most remote provinces (among them Cybele, Isis, Osiris, Serapis, Epona), and Gods of solar monism such as Mithras and Sol Invictus, found as far north as Roman Britain. Because Romans had never been obligated to cultivate one deity or one cult only, religious tolerance was not an issue in the sense that it is for competing monotheistic religions. The monotheistic rigor of Judaism posed difficulties for Roman policy that led at times to compromise and the granting of special exemptions, but sometimes to intractable conflict.

Some Christians have argued that religious pluralism is an invalid or self-contradictory concept.

Maximal forms of religious pluralism claim that all religions are equally true, or that one religion can be true for some and another for others. Most Christians hold this idea to be logically impossible from the Principle of contradiction. The two largest Christian branches, the Catholic Church and the Orthodox Church, both claim to be the "one true church" and that "outside the true Church there is no salvation"; Protestantism however, which has many different denominations, has no consistent doctrine in this regard, and has a variety of different positions regarding religious pluralism.

Other Christians have held that there can be truth value and salvific value in other faith traditions. John Macquarrie, described in the "Handbook of Anglican Theologians" (1998) as "unquestionably Anglicanism's most distinguished systematic theologian in the second half of the twentieth century", wrote that "there should be an end to proselytizing but that equally there should be no syncretism of the kind typified by the Baha'i movement" (p. 2). In discussing 9 founders of major faith traditions (Moses, Zoroaster, Lao-zu, Buddha, Confucius, Socrates, Krishna, Jesus, and Muhammad), which he called "mediators between the human and the divine", Macquarrie wrote that:

I do not deny for a moment that the truth of God has reached others through other channels - indeed, I hope and pray that it has. So while I have a special attachment to one mediator, I have respect for them all. (p. 12)
The Church of Jesus Christ of Latter-day Saints also teaches a form of religious pluralism, that there is at least some truth in almost all religions and philosophies.

Before the Great Schism, mainstream Christianity confessed "one holy catholic and apostolic church", in the words of the Nicene Creed. Roman Catholics, Orthodox Christians, Episcopalians and most Protestant Christian denominations still maintain this belief. Furthermore, the Catholic Church makes the claim that it alone is the one and only true Church founded by Jesus Christ, but the Eastern Orthodox and Oriental Orthodox Churches also make this claim in respect to themselves.

Church unity for these groups, as in the past, is something very visible and tangible, and schism was just as serious an offense as heresy. Following the Great Schism, Roman Catholicism sees and recognizes the Orthodox Sacraments as valid but illicit and without canonical jurisdiction. Eastern Orthodoxy does not have the concept of "validity" when applied to Sacraments, but it considers the "form" of Roman Catholic Sacraments to be acceptable, and there is some recognition of Catholic sacraments among some, but not all, Orthodox. Both generally mutually regard each other as "heterodox" and "schismatic", while continuing to recognize each other as Christian, at least secundum quid. (See ecumenicism).

Some other Protestants hold that only believers who believe in certain fundamental doctrines know the true pathway to salvation. The core of this doctrine is that Jesus Christ was a perfect man, is the Son of God and that he died and rose again for the wrongdoing of those who will accept the gift of salvation. They continue to believe in "one" church, an "invisible church" which encompasses different types of Christians in different sects and denominations, believing in certain issues they deem fundamental, while disunited on a variety of doctrines they deem non-fundamental. Some evangelical Protestants are doubtful if Roman Catholics or Eastern Orthodox can possibly be members of this "invisible church", and usually they reject religious (typically restorationist) movements rooted in 19th century American Christianity, such as Mormonism, Christian Science, or Jehovah's Witnesses as not distinctly Christian.

The Catholic Church, unlike some Protestant denominations, affirms "developmental theology," understood to mean that the "Holy Spirit, in and through the evolving and often confused circumstances of concrete history, is gradually bringing the Church to an ever more mature understanding of the deposit of faith (the saving truths entrusted by Jesus Christ to the Apostles--these as such cannot be changed or added to). The Church comes to recognize baptism of desire quite early in its history. Later, the Church realizes that Romans 2:14-16, for example, allows for the salvation of non-Christians who do not have unobstructed exposure to Christian teachings: "When Gentiles who have not the law do by nature what the law requires . . . . They show that what the law requires is written on their hearts . . . . Various forms of "implicit faith" come to hold standing, until at Vatican Council II, the Church declares: "Nor shall divine providence deny the assistance necessary for salvation to those who, without any fault of theirs, have not yet arrived at an explicit knowledge of God, and who, not without grace, strive to lead a good life" (#16). Vatican Council II in its Declaration Nostra aetate addresses the non-Christian religions with respect and appreciation, affirming the goodness found in them. Since Vatican Council II, Catholic dialogists in particular are working out the implications of John Paul II's statement, in Redemptor hominis #6 that Christians should recognize "the Holy Spirit operating outside the visible confines of the Mystical Body of Christ." Among these dialogists, Robert Magliola, an affiliate of the Italian community "Vangelo e Zen" ("The Gospel and Zen"), Desio and Milano, Italy, who taught in predominantly Buddhist cultures for years, and practiced Buddhist-Catholic dialogue there and in the West, and who is widely published in this dialogue, argues the following:

If God has willed that all persons be saved (see Catechism of the Catholic Church #851, quoting 1 Tim. 2:4) but has not sent the opportunity of Christian conversion to all, how can we not conclude that God wills those good Buddhists in this latter category to live, flourish, and die as good Buddhists? That God in His providence--at least for now--wants Buddhism to be the setting for millions of good and noble people in the world? (This does not mean that Catholics should not witness to the Catholic faith or even--on the proper occasions and in a courteous way--consider it their duty to preach Catholicism to Buddhists, and to teach it mightily. But it does mean that Catholics would do well to remember that God alone sends the grace of conversion when and to whom He wills.)

Hinduism is naturally a pluralistic. A well-known "Rig Vedic" hymn says: "Truth is One, though the sages know it variously" ("Ékam sat vipra bahudā vadanti"). Similarly, in the "Bhagavad Gītā" (4:11), God, manifesting as an incarnation, states: "As people approach me, so I receive them. All paths lead to me" ("ye yathā māṃ prapadyante tāṃs tathāiva bhajāmyaham mama vartmānuvartante manuṣyāḥ pārtha sarvaśaḥ"). The Hindu religion has no theological difficulties in accepting degrees of truth in other religions. According to Swami Bhaskarananda, Hinduism emphasizes that everyone actually worships the same God, whether one knows it or not.

While some claim that religious pluralism is controversial in Islam, Islamic civilizations have been characterized as one of the most religiously pluralist. The primary sources that guide Islam, namely Quran and hadiths, promote the fundamental right to practise an individual's belief, even though it may be a false belief. The acceptability of religious pluralism within Islam remains a topic of active debate, however the vast majority of Islamic scholars and historical evidences reveal Islam's commitment to no coercion in religion, supporting pluralism.

In several Surah, Quran asks Muslims to remain steadfast with Islam, and not yield to the vain desires of other religions and unbelievers. These verses have been interpreted to imply pluralism in religions. For example, Surah Al-Ma'idah verses 47 through 49 state:
Surah Al-Ankabut verse 45 through 47 state:
Surah Al-E-Imran verses 62 through 66 state:
Surah Al-Kafiroon verse 1 through 6 state:
Several verses of the Quran state that Islam rejects religious pluralism. For example, Surah Al-Tawba verse 1 through 5 seems to command the Muslim to slay the pagans (with verse 9.5 called the 'sword verse'): 
However, this verse has been explained.


</doc>
<doc id="26485" url="https://en.wikipedia.org/wiki?curid=26485" title="Calendar-based contraceptive methods">
Calendar-based contraceptive methods

Calendar-based methods are various methods of estimating a woman's likelihood of fertility, based on a record of the length of previous menstrual cycles. Various methods are known as the Knaus–Ogino method and the rhythm method. The standard days method is also considered a calendar-based method, because when using it, a woman tracks the days of her menstrual cycle without observing her physical fertility signs. The standard days method is based on a fixed formula taking into consideration the timing of ovulation, the functional life of the sperm and the ovum, and the resulting likelihood of pregnancy on particular days of the menstrual cycle. These methods may be used to achieve pregnancy by timing unprotected intercourse for days identified as fertile, or to avoid pregnancy by avoiding unprotected intercourse during fertile days.

The first formalized calendar-based method was developed in 1930 by John Smulders, a Roman Catholic physician from the Netherlands. It was based on knowledge of the menstrual cycle. This method was independently discovered by Hermann Knaus (Austria), and Kyusaku Ogino (Japan). This system was a main form of birth control available to Catholic couples for several decades, until the popularization of symptoms-based fertility awareness methods. A new development in calendar-based methods occurred in 2002, when Georgetown University introduced the Standard Days Method. The Standard Days Method is promoted in conjunction with a product called CycleBeads, a ring of colored beads which are meant to help the user keep track of her fertile and non-fertile days.

Some sources may treat the terms "rhythm method" and "fertility awareness" as synonymous. However, fertility awareness is usually used as a broad term that includes tracking basal body temperature and cervical mucus as well as cycle length. The World Health Organization considers the rhythm method to be a specific type of calendar-based method, and calendar-based methods to be only one form of fertility awareness.

More effective than calendar-based methods, systems of fertility awareness that track basal body temperature, cervical mucus, or both, are known as symptoms-based methods. Teachers of symptoms-based methods take care to distance their systems from the poor reputation of the rhythm method. Many consider the rhythm method to have been obsolete for at least 20 years, and some even exclude calendar-based methods from their definition of fertility awareness.

Some sources may treat the terms "rhythm method" and "natural family planning" as synonymous. In the early 20th century, the calendar-based method known as the "rhythm method" was promoted by members of the Roman Catholic Church as the only morally acceptable form of family planning. Methods accepted by this church are referred to as natural family planning (NFP): so at one time, the term "the rhythm method" was synonymous with NFP. Today, NFP is an umbrella term that includes symptoms-based fertility awareness methods and the lactational amenorrhea method as well as calendar-based methods such as rhythm. This overlap between uses of the terms "the rhythm method" and "natural family planning" may contribute to confusion.

The term "the rhythm method" is sometimes used, in error, to describe the behavior of any people who have unprotected vaginal intercourse, yet wish to avoid pregnancy.

The first day of bleeding is considered day one of the menstrual cycle.

It is not known if historical cultures were aware of what part of the menstrual cycle is most fertile. In the year 388, Augustine of Hippo wrote of periodic abstinence. Addressing followers of Manichaeism, his former religion, he said, "Is it not you who used to counsel us to observe as much as possible the time when a woman, after her purification, is most likely to conceive, and to abstain from cohabitation at that time...?" If the Manichaieans practiced something like the Jewish observances of menstruation, then the "time... after her purification" would have indeed been when "a woman... is most likely to conceive." Over a century previously, however, the influential Greek physician Soranus had written that "the time directly before and after menstruation" was the most fertile part of a woman's cycle; this inaccuracy was repeated in the 6th century by the Byzantine physician Aëtius. Similarly, a Chinese sex manual written close to the year 600 stated that only the first five days following menstruation were fertile. Some historians believe that Augustine, too, incorrectly identified the days immediately after menstruation as the time of highest fertility.

Written references to a "safe period" do not appear again for over a thousand years. Scientific advances prompted a number of secular thinkers to advocate periodic abstinence to avoid pregnancy: in the 1840s it was discovered that many animals ovulate during estrus. Because some animals (such as dogs) have a bloody discharge during estrus, it was assumed that menstruation was the corresponding most fertile time for women. This inaccurate theory was popularized by physicians Bischoff, Félix Archimède Pouchet, and Adam Raciborski. In 1854, an English physician named George Drysdale correctly taught his patients that the days near menstruation are the "least" fertile, but this remained the minority view for the remainder of the 19th century.

In 1905 Theodoor Hendrik van de Velde, a Dutch gynecologist, showed that women only ovulate once per menstrual cycle. In the 1920s, Kyusaku Ogino, a Japanese gynecologist, and Hermann Knaus, from Austria, working independently, each made the discovery that ovulation occurs about fourteen days before the next menstrual period. Ogino used his discovery to develop a formula for use in aiding infertile women to time intercourse to achieve pregnancy.

In 1930, Johannes Smulders, a Roman Catholic physician from the Netherlands, used Knaus and Ogino's discoveries to create a method for "avoiding" pregnancy. Smulders published his work with the Dutch Roman Catholic medical association, and this was the official rhythm method promoted over the next several decades. In 1932 a Catholic physician, Dr. Leo J Latz, published a book titled "The Rhythm of Sterility and Fertility in Women" describing the method, and the 1930s also saw the first U.S. Rhythm Clinic (founded by John Rock) to teach the method to Catholic couples.

In the first half of the 20th century, most users of the rhythm method were Catholic; they were following their church's teaching that all other methods of birth control were sinful. In 1968 the encyclical "Humanae vitae" included the statement, "It is supremely desirable... that medical science should by the study of natural rhythms succeed in determining a sufficiently secure basis for the chaste limitation of offspring." This is interpreted as favoring the then-new, more reliable symptoms-based fertility awareness methods over the rhythm method. Currently, many fertility awareness teachers consider the rhythm method to have been obsolete for at least 20 years.

New attention was drawn to calendar-based methods in 2002, when the Institute for Reproductive Health at Georgetown University introduced the Standard Days Method. Designed to be simpler to teach and use than the older rhythm method, the Standard Days Method is being successfully integrated into family planning programs worldwide.

Most menstrual cycles have several days at the beginning that are infertile (pre-ovulatory infertility), a period of fertility, and then several days just before the next menstruation that are infertile (post-ovulatory infertility). The first day of red bleeding is considered day one of the menstrual cycle. To use these methods, a woman is required to know the length of her menstrual cycles.

Imperfect use of calendar-based methods would consist of not correctly tracking the length of the woman's cycles, thus using the wrong numbers in the formula, or of having unprotected intercourse on an identified fertile day. The discipline required to keep accurate records of menstrual cycles, and to abstain from unprotected intercourse, makes imperfect use fairly common. The typical-use failure rate of calendar-based methods is 25% per year.

To find the estimated length of the pre-ovulatory infertile phase, nineteen (19) is subtracted from the length of the woman's shortest cycle. To find the estimated start of the post-ovulatory infertile phase, ten (10) is subtracted from the length of the woman's longest cycle. A woman whose menstrual cycles ranged in length from 30 to 36 days would be estimated to be infertile for the first 11 days of her cycle (30-19=11), to be fertile on days 12–25, and to resume infertility on day 26 (36-10=26). When used to avoid pregnancy, the rhythm method has a perfect-use failure rate of up to 9% per year.

Developed by Georgetown University's Institute for Reproductive Health, the Standard Days Method has a simpler rule set and is more effective than the rhythm method. A product called CycleBeads was developed alongside the method to help the user keep track of estimated high and low fertility points during her menstrual cycle. The Standard Days Method may only be used by women whose cycles are usually between 26 and 32 days in length. In this system:

When used to avoid pregnancy, the Standard Days Method has been claimed to have perfect-use efficacy of 95+% and typical-use efficacy of 88%. However, independent researchers have shown that these figures are probably too optimistic and its efficacy is likely to be much lower.

Several web-based implementations of the cycle method exist, as well as mobile apps such as Natural Cycles.

The Standard Days method (SDM) is increasingly being introduced as part of family planning programs in developing countries. The method is satisfactory for many women and men. The low cost of the method may also enable it to play a useful role in countries that lack funding to provide other methods of birth control.

One concern related to the use of calendar-based methods is their relatively high failure rate, compared to other methods of birth control. Even when used perfectly, calendar-based methods, especially the rhythm method, result in a high pregnancy rate among couples intending to avoid pregnancy. Of commonly known methods of birth control, only the cervical cap and contraceptive sponge have comparably high failure rates. This lower level of reliability of calendar-based methods is because their formulas make several assumptions that are not always true.

The postovulatory (luteal) phase has a normal length of 12 to 16 days, and the rhythm method formula assumes all women have luteal phase lengths within this range. However, many women have shorter luteal phases, and a few have longer luteal phases. For these women, the rhythm method formula incorrectly identifies a few fertile days as being in the infertile period.

Calendar-based methods use records of past menstrual cycles to predict the length of future cycles. However, the length of the pre-ovulatory phase can vary significantly, depending on the woman's typical cycle length, stress factors, medication, illness, menopause, breastfeeding, and whether she is just coming off hormonal contraception. If a woman with previously regular cycles has a delayed ovulation due to one of these factors, she will still be fertile when the method tells her she is in the post-ovulatory infertile phase. If she has an unusually early ovulation, calendar-based methods will indicate she is still in the pre-ovulatory infertile phase when she has actually become fertile.

Finally, calendar-based methods assume that all bleeding is true menstruation. However, mid-cycle or anovulatory bleeding can be caused by a number of factors. Incorrectly identifying bleeding as menstruation will cause the method's calculations to be incorrect.

It has been suggested that pregnancies resulting from method failures of periodic abstinence methods are at increased risk of miscarriage and birth defects due to aged gametes at the time of conception. Other research suggests that timing of conception has no effect on miscarriage rates, low birth weight, or preterm delivery.

Luc Bovens has suggested that unprotected intercourse in the infertile periods of the menstrual cycle may still result in conceptions, but create zygotes incapable of implanting. Bovens maintains that, if one defines abortion to include any destruction of fertilized eggs, then the use of the rhythm method probably results in a large number of abortions.


</doc>
<doc id="26487" url="https://en.wikipedia.org/wiki?curid=26487" title="Roulette">
Roulette

Roulette is a casino game named after the French word meaning "little wheel". In the game, players may choose to place bets on either a single number, various groupings of numbers, the colors red or black, whether the number is odd or even, or if the numbers are high (19–36) or low (1–18).

To determine the winning number, a croupier spins a wheel in one direction, then spins a ball in the opposite direction around a tilted circular track running around the outer edge of the wheel. The ball eventually loses momentum, passes through an area of deflectors, and falls onto the wheel and into one of 37 (single zero French/European style roulette) or 38 (double zero American style roulette) colored and numbered pockets on the wheel. The winnings are then paid to anyone who has placed a successful bet.

The first form of roulette was devised in 18th century France. Many historians believe Blaise Pascal introduced a primitive form of roulette in the 17th century in his search for a perpetual motion machine. The roulette mechanism is a hybrid of a gaming wheel invented in 1720 and the Italian game Biribi.

The game has been played in its present form since as early as 1796 in Paris. An early description of the roulette game in its current form is found in a French novel "La Roulette, ou le Jour" by Jaques Lablee, which describes a roulette wheel in the Palais Royal in Paris in 1796. The description included the house pockets, "There are exactly two slots reserved for the bank, whence it derives its sole mathematical advantage." It then goes on to describe the layout with, "...two betting spaces containing the bank's two numbers, zero and double zero". The book was published in 1801. An even earlier reference to a game of this name was published in regulations for New France (Québec) in 1758, which banned the games of "dice, hoca, faro, and roulette".

The roulette wheels used in the casinos of Paris in the late 1790s had red for the single zero and black for the double zero. To avoid confusion, the color green was selected for the zeros in roulette wheels starting in the 1800s.

In 1843, in the German spa casino town of Bad Homburg, fellow Frenchmen François and Louis Blanc introduced the single "0" style roulette wheel in order to compete against other casinos offering the traditional wheel with single and double zero house pockets.

In some forms of early American roulette wheels, there were numbers 1 through 28, plus a single zero, a double zero, and an American Eagle. The Eagle slot, which was a symbol of American liberty, was a house slot that brought the casino extra edge. Soon, the tradition vanished and since then the wheel features only numbered slots. According to Hoyle "the single 0, the double 0, and eagle are never bars; but when the ball falls into either of them, the banker sweeps every thing upon the table, except what may happen to be bet on either one of them, when he pays twenty-seven for one, which is the amount paid for all sums bet upon any single figure".
In the 19th century, roulette spread all over Europe and the US, becoming one of the most famous and most popular casino games. When the German government abolished gambling in the 1860s, the Blanc family moved to the last legal remaining casino operation in Europe at Monte Carlo, where they established a gambling mecca for the elite of Europe. It was here that the single zero roulette wheel became the premier game, and over the years was exported around the world, except in the United States where the double zero wheel had remained dominant.
In the United States, the French double zero wheel made its way up the Mississippi from New Orleans, and then westward. It was here, because of rampant cheating by both operators and gamblers, that the wheel was eventually placed on top of the table to prevent devices being hidden in the table or wheel, and the betting layout was simplified. This eventually evolved into the American-style roulette game. The American game was developed in the gambling dens across the new territories where makeshift games had been set up, whereas the French game evolved with style and leisure in Monte Carlo.

During the first part of the 20th century, the only casino towns of note were Monte Carlo with the traditional single zero French wheel, and Las Vegas with the American double zero wheel. In the 1970s, casinos began to flourish around the world. By 2008, there were several hundred casinos worldwide offering roulette games. The double zero wheel is found in the U.S., Canada, South America, and the Caribbean, while the single zero wheel is predominant elsewhere.

The sum of all the numbers on the roulette wheel (from 0 to 36) is 666, which is the "Number of the Beast".

Roulette players have a variety of betting options. Placing inside bets is either selecting the exact number of the pocket the ball will land in, or a small range of pockets based on their proximity on the layout. Players wishing to bet on the 'outside' will select bets on larger positional groupings of pockets, the pocket color, or whether the winning number is odd or evenThe payout odds for each type of bet are based on its probability.

The roulette table usually imposes minimum and maximum bets, and these rules usually apply separately for all of a player's inside and outside bets for each spin. For inside bets at roulette tables, some casinos may use separate roulette table chips of various colors to distinguish players at the table. Players can continue to place bets as the ball spins around the wheel until the dealer announces "no more bets" or "rien ne va plus".
When a winning number and color is determined by the roulette wheel, the dealer will place a marker, also known as a dolly, on that winning number on the roulette table layout. When the dolly is on the table, no players may place bets, collect bets, or remove any bets from the table. The dealer will then sweep away all other losing bets either by hand or rake, and determine all of the payouts to the remaining inside and outside winning bets. When the dealer is finished making payouts, the marker is removed from the board where players collect their winnings and make new bets. The winning chips remain on the board.

In 2004, California legalized a form of roulette known as California Roulette. By law, the game must use cards and not slots on the roulette wheel to pick the winning number.

The pockets of the roulette wheel are numbered from 0 to 36.

In number ranges from 1 to 10 and 19 to 28, odd numbers are red and even are black. In ranges from 11 to 18 and 29 to 36, odd numbers are black and even are red.

There is a green pocket numbered 0 (zero). In American roulette, there is a second green pocket marked 00. Pocket number order on the roulette wheel adheres to the following clockwise sequence in most casinos:


The cloth-covered betting area on a roulette table is known as the "layout". The layout is either single-zero or double-zero. The European-style layout has a single zero, and the American style layout is usually a double-zero. The American-style roulette table with a wheel at one end is now used in most casinos. The French style table with a wheel in the centre and a layout on either side is rarely found outside of Monte Carlo.

In roulette, bets can either be inside or outside bets.

Outside bets typically have smaller payouts with better odds at winning. Except as noted, all of these bets lose if a zero comes up.

In the United Kingdom, the farthest outside bets (low/high, red/black, even/odd) result in the player losing only half of his/her bet if a zero comes up.

The expected value of a $1 bet (except for the special case of Top line bets), for American and European roulette, can be calculated as

where "n" is the number of pockets in the wheel. The initial bet is returned in addition to the mentioned payout. It can be easily demonstrated that this payout formula would lead to a zero expected value of profit if there were only 36 numbers. Having 37 or more numbers gives the casino its edge.

Top line (0, 00, 1, 2, 3) has a different expected value because of approximation of the correct -to-1 payout obtained by the formula to 6-to-1. The values 0 and 00 are not odd or even, or high or low.

En prison rules, when used, reduce the house advantage.

The "house average" or "house edge or house advantage" (also called the expected value) is the amount the player loses relative for any bet made, on average. If a player bets on a single number in the American game there is a probability of that the player wins 35 times the bet, and a chance that the player loses his bet. The expected value is:

For European roulette, a single number wins and loses :

For triple-zero wheels, a single number wins and loses :

The presence of the green squares on the roulette wheel and on the table is technically the only house edge. Outside bets will always lose when a single or double zero comes up. However, the house also has an edge on inside bets because the pay outs (including the original player's bet) are always set at 36 to 1 when you mathematically have a 1 out of 38 (1 out of 37 for French/European roulette) chance at winning a straight bet on a single number. To demonstrate the house edge on inside bets, imagine placing straight $1 wagers on all inside numbers (including 0 and 00) to assure a win: you would only get back $36, having spent $38. The only exceptions are the five numbers bet where the house edge is considerably higher (7.89% on an American wheel), and the "even money" bets in some European games (French Roulette) where the house edge is halved because only half the stake is lost when a zero comes up. This is commonly called the "la partage" rule, and it is considered the main difference between European and French roulette. There is also a modification of this rule, which is called the "en prison" rule. These rules cut the house edge into half (1.35%) in French roulette, when playing even-money bets, as half of the even-money bets are given back to the player if the zero is drawn in the wheel.

The house edge should not be confused with the "hold". The hold is the average percentage of the money originally brought to the table that the player loses before he leaves—the actual "win" amount for the casino. The Casino Control Commission in Atlantic City releases a monthly report showing the win/hold amounts for each casino. The average win/hold for double zero wheels is between 21% to 30%, significantly more than the 5.26% house edge. This reflects the fact that the player is churning the same money over and over again. A 23.6% hold, for example, would imply that, on average, the player bets the total he brought to the table five times, as 23.6% is approximately equal to . For example, a player with $100 making $10 bets on red (which has a near 50/50 chance of winning) is highly unlikely to lose all his money after only 10 bets, and will most likely continue to bet until he has lost all of his money or decides to leave. A player making $10 bets on a single number (with only 1/38 chance of success) with a $100 bankroll is far more likely to lose all of his money after only 10 bets.

In the early frontier gambling saloons, the house would set the odds on roulette tables at 27 for 1. This meant that on a $1 bet you would get $27 and the house would keep your initial dollar. Today most casino odds are set by law, and they have to be either 34 to 1 or 35 to 1. This means that the house pays you $34 or $35 and you get to keep your original $1 bet.

As an example, we can examine the European roulette model, that is, roulette with only one zero. Since this roulette has 37 cells with equal odds of hitting, this is a final model of field probability formula_2, where formula_3, formula_4 for all formula_5.

Call the bet formula_6 a triple formula_7, where formula_8 is the set of chosen numbers, formula_9 is the size of the bet, and formula_10 determines the return of the bet.

The rules of European roulette have 10 types of bets. First we can examine the 'Straight Up' bet. In this case, formula_11, for some formula_12, and formula_13 is determined by
The bet's expected net return, or profitability, is equal to
Without details, for a bet, black (or red), the rule is determined as
and the profitability
For similar reasons it is simple to see that the profitability is also equal for all remaining types of bets. formula_18.

In reality this means that, the more bets a player makes, the more he is going to lose independent of the strategies (combinations of bet types or size of bets) that he employs:
Here, the profit margin for the roulette owner is equal to approximately 2.7%. Nevertheless, several roulette strategy systems have been developed despite the losing odds. These systems can not change the odds of the game in favor of the player.

It is worth noting that the odds for the player in American roulette are even worse, as the bet profitability is at worst formula_20, and never better than formula_21.

For a roulette wheel with formula_22 green numbers and 36 other unique numbers the chance of the ball landing on a given number is formula_23. For a betting option with formula_24 numbers that define a win, the chance of winning a bet is formula_25

For example, betting on "red", there are 18 red numbers, formula_26, the chance of winning is formula_27.

The payout given by the casino for a win is based on the roulette wheel having 36 outcomes and the payout for a bet is given by formula_28.

For example, betting on 1-12 there are 12 numbers that define a win, formula_29, the payout is formula_30, so the better wins 3 times their bet.

The average return on a player's bet is given by formula_31

For formula_32 the average return is always lower than 1 so on average a player will lose money.
With 1 green number formula_33 the average return is formula_34, that is, after a bet the player will on average have formula_34 of their original bet returned to them.
With 2 green numbers formula_36 the average return is formula_37.

This shows that the expected return is independent of the choice of bet.

Although most often named "call bets" technically these bets are more accurately referred to as "announced bets". The legal distinction between a "call bet" and an "announced bet" is that a "call bet" is a bet called by the player without him placing any money on the table to cover the cost of the bet. In many jurisdictions (most notably the United Kingdom) this is considered gambling on credit and is illegal. An "announced bet" is a bet called by the player for which he immediately places enough money to cover the amount of the bet on the table, prior to the outcome of the spin or hand in progress being known.

There are different number series in roulette that have special names attached to them. Most commonly these bets are known as "the French bets" and each covers a section of the wheel. For the sake of accuracy, zero spiel, although explained below, is not a French bet, it is more accurately "the German bet". Players at a table may bet a set amount per series (or multiples of that amount). The series are based on the way certain numbers lie next to each other on the roulette wheel. Not all casinos offer these bets, and some may offer additional bets or variations on these.

This is a name, more accurately "grands voisins du zéro", for the 17 numbers that lie between 22 and 25 on the wheel, including 22 and 25 themselves. The series is 22-18-29-7-28-12-35-3-26-0-32-15-19-4-21-2-25 (on a single-zero wheel).

Nine chips or multiples thereof are bet. Two chips are placed on the 0-2-3 trio; one on the 4-7 split; one on 12-15; one on 18-21; one on 19-22; two on the 25-26-28-29 corner; and one on 32-35.

Zero game, also known as zero spiel ("Spiel" is German for game or play), is the name for the numbers closest to zero. All numbers in the zero game are included in the voisins, but are placed differently. The numbers bet on are 12-35-3-26-0-32-15.

The bet consists of four chips or multiples thereof. Three chips are bet on splits and one chip straight-up: one chip on 0-3 split, one on 12-15 split, one on 32-35 split and one straight-up on number 26.

This type of bet is popular in Germany and many European casinos. It is also offered as a 5-chip bet in many Eastern European casinos. As a 5-chip bet, it is known as "zero spiel naca" and includes, in addition to the chips placed as noted above, a straight-up on number 19.

This is the name for the 12 numbers that lie on the opposite side of the wheel between 27 and 33, including 27 and 33 themselves. On a single-zero wheel, the series is 27-13-36-11-30-8-23-10-5-24-16-33. The full name (although very rarely used, most players refer to it as "tiers") for this bet is "le tiers du cylindre" (translated from French into English meaning one third of the wheel) because it covers 12 numbers (placed as 6 splits), which is as close to of the wheel as one can get.

Very popular in British casinos, tiers bets outnumber voisins and orphelins bets by a massive margin.

Six chips or multiples thereof are bet. One chip is placed on each of the following splits: 5-8, 10-11, 13-16, 23-24, 27-30, and 33-36.

The tiers bet is also called the "small series" and in some casinos (most notably in South Africa) "series 5-8".

A variant known as "tiers 5-8-10-11" has an additional chip placed straight up on 5, 8, 10, and 11m and so is a 10-piece bet. In some places the variant is called "gioco Ferrari" with a straight up on 8, 11, 23 and 30, the bet is marked with a red G on the racetrack.

These numbers make up the two slices of the wheel outside the tiers and voisins. They contain a total of 8 numbers, comprising 17-34-6 and 1-20-14-31-9.

Five chips or multiples thereof are bet on four splits and a straight-up: one chip is placed straight-up on 1 and one chip on each of the splits: 6-9, 14-17, 17-20, and 31-34.

A number may be backed along with the two numbers on the either side of it in a 5-chip bet. For example, "0 and the neighbors" is a 5-chip bet with one piece straight-up on 3, 26, 0, 32, and 15. Neighbors bets are often put on in combinations, for example "1, 9, 14, and the neighbors" is a 15-chip bet covering 18, 22, 33, 16 with one chip, 9, 31, 20, 1 with two chips and 14 with three chips.

Any of the above bets may be combined, e.g. "orphelins by 1 and zero and the neighbors by 1". The "...and the neighbors" is often assumed by the croupier.

Another bet offered on the single-zero game is "final", "finale" or "finals".

Final 4, for example, is a 4-chip bet and consists of one chip placed on each of the numbers ending in 4, that is 4, 14, 24, and 34. Final 7 is a 3-chip bet, one chip each on 7, 17, and 27. Final bets from final 0 (zero) to final 6 cost four chips. Final bets 7, 8 and 9 cost three chips.

Some casinos also offer split-final bets, for example final 5-8 would be a 4-chip bet, one chip each on the splits 5-8, 15-18, 25-28, and one on 35.

A complete bet places all of the inside bets on a certain number. Full complete bets are most often bet by high rollers as "maximum bets".

The maximum amount allowed to be wagered on a single bet in European roulette is based on a progressive betting model. If the casino allows a maximum bet of $1,000 on a 35-to-1 straight-up, then on each 17-to-1 split connected to that straight-up, $2,000 may be wagered. Each 8-to-1 corner that covers four numbers) may have $4,000 wagered on it. Each 11-to-1 street that covers three numbers may have $3,000 wagered on it. Each 5-to-1 six-line may have $6,000 wagered on it. Each $1,000 incremental bet would be represented by a marker that is used to specifically identify the player and the amount bet.

For instance, if a patron wished to place a full complete bet on 17, the player would call "17 to the maximum". This bet would require a total of 40 chips, or $40,000. To manually place the same wager, the player would need to bet:

The player calls his bet to the croupier (most often after the ball has been spun) and places enough chips to cover the bet on the table within reach of the croupier. The croupier will immediately announce the bet (repeat what the player has just said), ensure that the correct monetary amount has been given while simultaneously placing a matching marker on the number on the table and the amount wagered.

The payout for this bet if the chosen number wins is 392 chips, in the case of a $1000 straight-up maximum, $40,000 bet, a payout of $392,000. The player's wagered 40 chips, as with all winning bets in roulette, are still his property and in the absence of a request to the contrary are left up to possibly win again on the next spin.

Based on the location of the numbers on the layout, the number of chips required to "complete" a number can be determined.

Most typically (Mayfair casinos in London and other top-class European casinos) with these "maximum" or "full complete" bets, nothing (except the aforementioned maximum button) is ever placed on the layout even in the case of a win. Experienced gaming staff, and the type of customers playing such bets, are fully aware of the payouts and so the croupier simply makes up the correct payout, announces its value to the table inspector (floor person in the U.S.) and the customer, and then passes it to the customer, but only after a verbal authorization from the inspector has been received.

Also typically at this level of play (house rules allowing) the experienced croupier caters to the needs of the customer and will most often add the customer's winning bet to the payout, as the type of player playing these bets very rarely bets the same number two spins in succession. For example, the winning 40-chip / $40,000 bet on "17 to the maximum" pays 392 chips / $392,000. The experienced croupier would pay the player 432 chips / $432,000, that is 392 + 40, with the announcement that the payout "is with your bet down".

There are also several methods to determine the payout when a number adjacent to a chosen number is the winner, for example, player bets 40 chips on "23 to the maximum" and number 26 is the winning number. The most notable method is known as the "station" system or method. When paying in stations, the dealer counts the number of ways or stations that the winning number hits the complete bet. In the example above, 26 hits 4 stations - 2 different corners, 1 split and 1 six-line. The dealer takes the number 4, multiplies it by 30 and adds the remaining 8 to the payout: 4 × 30 = 120, 120 + 8 = 128. If calculated as stations, they would just multiply 4 by 36, making 144 with the players bet down.

In some casinos, a player may bet full complete for less than the table straight-up maximum, for example, "number 17 full complete by $25" would cost $1000, that is 40 chips each at $25 value.

Over the years, many people have tried to beat the casino, and turn roulette—a game designed to turn a profit for the house—into one on which the player expects to win. Most of the time this comes down to the use of betting systems, strategies which say that the house edge can be beaten by simply employing a special pattern of bets, often relying on the "Gambler's fallacy", the idea that past results are any guide to the future (for example, if a roulette wheel has come up 10 times in a row on red, that red on the next spin is any more or less likely than if the last spin was black).

All betting systems that rely on patterns, when employed on casino edge games will result, on average, in the player losing money. In practice, players employing betting systems may win, and may indeed win very large sums of money, but the losses (which, depending on the design of the betting system, may occur quite rarely) will outweigh the wins. Certain systems, such as the Martingale, described below, are extremely risky, because the worst-case scenario (which is mathematically certain to happen, at some point) may see the player chasing losses with ever-bigger bets until he runs out of money.

The American mathematician Patrick Billingsley said that no betting system can convert a subfair game into a profitable enterprise.
At least in the 1930s, some professional gamblers were able to consistently gain an edge in roulette by seeking out rigged wheels (not difficult to find at that time) and betting opposite the largest bets.

Whereas betting systems are essentially an attempt to beat the fact that a geometric series with initial value of 0.95 (American roulette) or 0.97 (European roulette) will inevitably over time tend to zero, engineers instead attempt to overcome the house edge through predicting the mechanical performance of the wheel, most notably by Joseph Jagger at Monte Carlo in 1873. These schemes work by determining that the ball is more likely to fall at certain numbers. If effective, they raise the return of the game above 100%, defeating the betting system problem.

Edward O. Thorp (the developer of card counting and an early hedge-fund pioneer) and Claude Shannon (a mathematician and electronic engineer best known for his contributions to information theory) built the first wearable computer to predict the landing of the ball in 1961. This system worked by timing the ball and wheel, and using the information obtained to calculate the most likely octant where the ball would fall. Ironically, this technique works best with an unbiased wheel though it could still be countered quite easily by simply closing the table for betting before beginning the spin.

In 1982, several casinos in Britain began to lose large sums of money at their roulette tables to teams of gamblers from the USA. Upon investigation by the police, it was discovered they were using a legal system of biased wheel-section betting. As a result of this, the British roulette wheel manufacturer John Huxley manufactured a roulette wheel to counteract the problem.

The new wheel, designed by George Melas, was called "low profile" because the pockets had been drastically reduced in depth, and various other design modifications caused the ball to descend in a gradual approach to the pocket area. In 1986, when a professional gambling team headed by Billy Walters won $3.8 million using the system on an old wheel at the Golden Nugget in Atlantic City, every casino in the world took notice, and within one year had switched to the new low-profile wheel.

Thomas Bass, in his book "The Eudaemonic Pie" (1985) (published as "The Newtonian Casino" in Britain), has claimed to be able to predict wheel performance in real time. The book describes the exploits of a group of University of California Santa Cruz students, who called themselves "the Eudaemons", who in the late 1970s used computers in their shoes to win at roulette. This is an updated and improved version of Edward O. Thorp's approach, where Newtonian
Laws of Motion are applied to track the roulette ball's deceleration; hence the British title.

In the early 1990s, Gonzalo Garcia-Pelayo believed that casino roulette wheels were not perfectly random, and that by recording the results and analysing them with a computer, he could gain an edge on the house by predicting that certain numbers were more likely to occur next than the 1-in-36 odds offered by the house suggested. This he did at the Casino de Madrid in Madrid, Spain, winning 600,000 euros in a single day, and one million euros in total. Legal action against him by the casino was unsuccessful, it being ruled that the casino should fix its wheel.

To defend against exploits like these, many casinos use tracking software, use wheels with new designs, rotate wheel heads, and randomly rotate pocket rings.

At the Ritz London casino in March 2004, two Serbs and a Hungarian used a laser scanner hidden inside a mobile phone linked to a computer to predict the sector of the wheel where the ball was most likely to drop. They netted £1.3m in two nights. They were arrested and kept on police bail for nine months, but eventually released and allowed to keep their winnings as they had not interfered with the casino equipment.

The numerous even-money bets in roulette have inspired many players over the years to attempt to beat the game by using one or more variations of a martingale betting strategy, wherein the gambler doubles the bet after every loss, so that the first win would recover all previous losses, plus win a profit equal to the original bet. The problem with this strategy is that, remembering that past results do not affect the future, it is possible for the player to lose so many times in a row, that the player, doubling and redoubling his bets, either runs out of money or hits the table limit. A large financial loss is certain in the long term if the player continued to employ this strategy. Another strategy is the Fibonacci system, where bets are calculated according to the Fibonacci sequence. Regardless of the specific progression, no such strategy can statistically overcome the casino's advantage, since the expected value of each allowed bet is negative.

The Labouchère System is a progression betting strategy like the martingale but does not require the gambler to risk his stake as quickly with dramatic double-ups. The Labouchere System involves using a series of numbers in a line to determine the bet amount, following a win or a loss. Typically, the player adds the numbers at the front and end of the line to determine the size of the next bet. When he wins, he crosses out numbers and continues working on the smaller line. If he loses, then he adds his previous bet to the end of the line and continues to work on the longer line. This is a much more flexible progression betting system and there is much room for the player to design his initial line to his own playing preference.

This system is one that is designed so that when the player has won over a third of his bets (less than the expected 18/38), he will win. Whereas the martingale will cause ruin in the event of a long sequence of successive losses, the Labouchère system will cause bet size to grow quickly even where a losing sequence is broken by wins. This occurs because as the player loses, the average bet size in the line increases.

As with all other betting systems, the average value of this system is negative.

The system, also called "montant et demontant" (from French, meaning upwards and downwards), is often called a pyramid system. It is based on a mathematical equilibrium theory devised by a French mathematician of the same name. Like the martingale, this system is mainly applied to the even-money outside bets, and is favored by players who want to keep the amount of their bets and losses to a minimum. The betting progression is very simple: After each loss, you add one unit to the next bet, and after each win, one unit is deducted from the next bet. Starting with an initial bet of, say, 1 unit, a loss would raise the next bet to 2 units. If this is followed by a win, the next bet would be 1 units.

This betting system relies on the gambler's fallacy—that the player is more likely to lose following a win, and more likely to win following a loss.

There are numerous other betting systems that rely on this fallacy, or that attempt to follow 'streaks' (looking for patterns in randomness), varying bet size accordingly.

Many betting systems are sold online and purport to enable the player to 'beat' the odds. One such system was advertised by Jason Gillon of Rotherham, UK, who claimed you could 'earn £200 daily' by following his betting system, described as a 'loophole'. As the system was advertised in the UK press, it was subject to Advertising Standards Authority regulation, and following a complaint, it was ruled by the ASA that Mr. Gillon had failed to support his claims you could earn £200 daily, and that he had failed to show that there was any loophole.








</doc>
<doc id="26488" url="https://en.wikipedia.org/wiki?curid=26488" title="Reformation (disambiguation)">
Reformation (disambiguation)

The Reformation, also known as the Protestant Reformation, was the 16th century schism within Western Christianity initiated by Martin Luther, John Calvin, and others

Reformation may also refer to:







</doc>
<doc id="26490" url="https://en.wikipedia.org/wiki?curid=26490" title="Reference counting">
Reference counting

In computer science, reference counting is a programming technique of storing the number of references, pointers, or handles to a resource, such as an object, a block of memory, disk space, and others.

In garbage collection algorithms, reference counts may be used to deallocate objects which are no longer needed.

The main advantage of the reference counting over tracing garbage collection is that objects are reclaimed "as soon as" they can no longer be referenced, and in an incremental fashion, without long pauses for collection cycles and with clearly defined lifetime of every object. In real-time applications or systems with limited memory, this is important to maintain responsiveness. Reference counting is also among the simplest forms of memory management to implement. It also allows for effective management of non-memory resources such as operating system objects, which are often much scarcer than memory (tracing garbage collection systems use finalizers for this, but the delayed reclamation may cause problems). Weighted reference counts are a good solution for garbage collecting a distributed system.
Tracing garbage collection cycles are triggered too often if the set of live objects fills most of the available memory; it requires extra space to be efficient. Reference counting performance does not deteriorate as the total amount of free space decreases.

Reference counts are also useful information to use as input to other runtime optimizations. For example, systems that depend heavily on immutable objects such as many functional programming languages can suffer an efficiency penalty due to frequent copies. However, if the compiler (or runtime system) knows that a particular object has only one reference (as most do in many systems), and that the reference is lost at the same time that a similar new object is created (as in the string append statement codice_1), it can replace the operation with a mutation on the original object.

Reference counting in naive form has two main disadvantages over the tracing garbage collection, both of which require additional mechanisms to ameliorate:

In addition to these, if the memory is allocated from a free list, reference counting suffers from poor locality. Reference counting alone cannot move objects to improve cache performance, so high performance collectors implement a tracing garbage collector as well. Most implementations (such as the ones in PHP and Objective-C) suffer from poor cache performance since they do not implement copying objects.

When dealing with garbage collection schemes, it is often helpful to think of the reference graph, which is a directed graph where the vertices are objects and there is an edge from an object A to an object B if A holds a reference to B. We also have a special vertex or vertices representing the local variables and references held by the runtime system, and no edges ever go to these nodes, although edges can go from them to other nodes.

In this context, the simple reference count of an object is the in-degree of its vertex. Deleting a vertex is like collecting an object. It can only be done when the vertex has no incoming edges, so it does not affect the out-degree of any other vertices, but it can affect the in-degree of other vertices, causing their corresponding objects to be collected as well if their in-degree also becomes 0 as a result.

The connected component containing the special vertex contains the objects that can't be collected, while other connected components of the graph only contain garbage. If a reference-counting garbage collection algorithm is implemented, then each of these garbage components must contain at least one cycle; otherwise, they would have been collected as soon as their reference count (i.e., the number of incoming edges) dropped to zero.

Incrementing and decrementing reference counts every time a reference is created or destroyed can significantly impede performance. Not only do the operations take time, but they damage cache performance and can lead to pipeline bubbles. Even read-only operations like calculating the length of a list require a large number of reads and writes for reference updates with naive reference counting.

One simple technique is for the compiler to combine a number of nearby reference updates into one. This is especially effective for references which are created and quickly destroyed. Care must be taken, however, to put the combined update at the right position so that a premature free can be avoided.

The Deutsch-Bobrow method of reference counting capitalizes on the fact that most reference count updates are in fact generated by references stored in local variables. It ignores these references, only counting references in data structures, but before an object with reference count zero can be deleted, the system must verify with a scan of the stack and registers that no other reference to it still exists.

Another technique devised by Henry Baker involves deferred increments, in which references which are stored in local variables do not immediately increment the corresponding reference count, but instead defer this until it is necessary. If such a reference is destroyed quickly, then there is no need to update the counter. This eliminates a large number of updates associated with short-lived references (such as the above list-length-counting example). However, if such a reference is copied into a data structure, then the deferred increment must be performed at that time. It is also critical to perform the deferred increment before the object's count drops to zero, resulting in a premature free.

A dramatic decrease in the overhead on counter updates was obtained by Levanoni and Petrank. They introduce the update coalescing method which coalesces many of the redundant reference count updates. Consider a pointer that in a given interval of the execution is updated several times. It first points to an object codice_2, then to an object codice_3, and so forth until at the end of the interval it points to some object codice_4. A reference counting algorithm would typically execute codice_5, codice_6, codice_7, codice_8, codice_9, ..., codice_10. But most of these updates are redundant. In order to have the reference count properly evaluated at the end of the interval it is enough to perform codice_5 and codice_10. The rest of the updates are redundant.

Levanoni and Petrank showed in 2001 how to use such update coalescing in a reference counting collector. When using update coalescing with an appropriate treatment of new objects, more than 99% of the counter updates are eliminated for typical Java benchmarks. In addition, the need for atomic operations during pointer updates on parallel processors is eliminated. Finally, they presented an enhanced algorithm that may run concurrently with multithreaded applications employing only fine synchronization.

Blackburn and McKinley's "ulterior reference counting" method in 2003 combines deferred reference counting with a copying nursery, observing that the majority of pointer mutations occur in young objects. This algorithm achieves throughput comparable with the fastest generational copying collectors with the low bounded pause times of reference counting.

Perhaps the most obvious way to handle reference cycles is to design the system to avoid creating them. A system may explicitly forbid reference cycles; file systems with hard links often do this. Judicious use of "weak" (non-counted) references may also help avoid retain cycles; the Cocoa framework, for instance, recommends using "strong" references for parent-to-child relationships and "weak" references for child-to-parent relationships.

Systems may also be designed to tolerate or correct the cycles they create in some way. Developers may design code to explicitly "tear down" the references in a data structure when it is no longer needed, though this has the cost of requiring them to manually track that data structure's lifetime. This technique can be automated by creating an "owner" object that does the tearing-down when it is destroyed; for instance, a Graph object's destructor could delete the edges of its GraphNodes, breaking the reference cycles in the graph. Cycles may even be ignored in systems with short lives and a small amount of cyclic garbage, particularly when the system was developed using a methodology of avoiding cyclic data structures wherever possible, typically at the expense of efficiency.

Computer scientists have also discovered ways to detect and collect reference cycles automatically, without requiring changes in the data structure design. One simple solution is to periodically use a tracing garbage collector to reclaim cycles; since cycles typically constitute a relatively small amount of reclaimed space, the collector can be run much less often than with an ordinary tracing garbage collector.

Bacon describes a cycle-collection algorithm for reference counting with similarities to tracing collectors, including the same theoretical time bounds. It is based on the observation that a cycle can only be isolated when a reference count is decremented to a nonzero value. All objects which this occurs on are put on a "roots" list, and then periodically the program searches through the objects reachable from the roots for cycles. It knows it has found a cycle that can be collected when decrementing all the reference counts on a cycle of references brings them all down to zero. An enhanced version of this algorithm by Paz et al.
is able to run concurrently with other operations and improve its efficiency by using the update coalescing method of Levanoni and Petrank.

Although it is possible to augment simple reference counts in a variety of ways, often a better solution can be found by performing reference counting in a fundamentally different way. Here we describe some of the variants on reference counting and their benefits and drawbacks.

In weighted reference counting, each reference is assigned a "weight", and each object tracks not the number of references referring to it, but the total weight of the references referring to it. The initial reference to a newly created object has a large weight, such as 2. Whenever this reference is copied, half of the weight goes to the new reference, and half of the weight stays with the old reference. Since the total weight does not change, the object's reference count does not need to be updated.

Destroying a reference decrements the total weight by the weight of that reference. When the total weight becomes zero, all references have been destroyed. If an attempt is made to copy a reference with a weight of 1, the reference has to "get more weight" by adding to the total weight and then adding this new weight to the reference, and then splitting it. An alternative in this situation is to create an "indirection" reference object, the initial reference to which is created with a large weight which can then be split.

The property of not needing to access a reference count when a reference is copied is particularly helpful when the object's reference count is expensive to access, for example because it is in another process, on disk, or even across a network. It can also help increase concurrency by avoiding many threads locking a reference count to increase it. Thus, weighted reference counting is most useful in parallel, multiprocess, database, or distributed applications.

The primary problem with simple weighted reference counting is that destroying a reference still requires accessing the reference count, and if many references are destroyed this can cause the same bottlenecks we seek to avoid. Some adaptations of weighted reference counting seek to avoid this by attempting to give weight back from a dying reference to one which is still active.

Weighted reference counting was independently devised by Bevan and Watson & Watson in 1987.

In indirect reference counting, it is necessary to keep track of from whom the reference was obtained. This means that two references are kept to the object: a direct one which is used for invocations; and an indirect one which forms part of a diffusion tree, such as in the Dijkstra-Scholten algorithm, which allows a garbage collector to identify dead objects. This approach prevents an object from being discarded prematurely.

As a collection algorithm, reference counting tracks, for each object, a count of the number of references to it held by other objects. If an object's reference count reaches zero, the object has become inaccessible, and can be destroyed.

When an object is destroyed, any objects referenced by that object also have their reference counts decreased. Because of this, removing a single reference can potentially lead to a large number of objects being freed. A common modification allows reference counting to be made incremental: instead of destroying an object as soon as its reference count becomes zero, it is added to a list of unreferenced objects, and periodically (or as needed) one or more items from this list are destroyed.

Simple reference counts require frequent updates. Whenever a reference is destroyed or overwritten, the reference count of the object it references is decremented, and whenever one is created or copied, the reference count of the object it references is incremented.

Reference counting is also used in file systems and distributed systems, where full non-incremental tracing garbage collection is too time consuming because of the size of the object graph and slow access speed. 

Microsoft's Component Object Model (COM) and WinRT makes pervasive use of reference counting. In fact, two of the three methods that all COM objects must provide (in the IUnknown interface) increment or decrement the reference count. Much of the Windows Shell and many Windows applications (including MS Internet Explorer, MS Office, and countless third-party products) are built on COM, demonstrating the viability of reference counting in large-scale systems.

One primary motivation for reference counting in COM is to enable interoperability across different programming languages and runtime systems. A client need only know how to invoke object methods in order to manage object life cycle; thus, the client is completely abstracted from whatever memory allocator the implementation of the COM object uses. As a typical example, a Visual Basic program using a COM object is agnostic towards whether that object was allocated (and must later be deallocated) by a C++ allocator or another Visual Basic component.

C++ does not perform reference-counting by default, fulfilling its philosophy of not adding functionality that might incur overheads where the user has not explicitly requested it. Objects that are shared but not owned can be accessed via a reference, raw pointer, or iterator (a conceptual generalisation of pointers).

However, by the same token, C++ provides native ways for users to opt-into such functionality: C++11 provides reference counted smart pointers, via the class, enabling automatic shared memory-management of dynamically allocated objects. Programmers can use this in conjunction with weak pointers (via ) to break cyclic dependencies. Objects that are dynamically allocated but not intended to be shared can have their lifetime automatically managed using a .

In addition, C++11's move semantics further reduce the extent to which reference counts need to be modified by removing the deep copy normally used when a function returns an object, as it allows for a simple copy of the pointer of said object.

Apple's Cocoa and Cocoa Touch frameworks (and related frameworks, such as Core Foundation) use manual reference counting, much like COM. Traditionally this was accomplished by the programmer manually sending codice_13 and codice_14 messages to objects, but Automatic Reference Counting, a Clang compiler feature that automatically inserts these messages as needed, was added in iOS 5 and Mac OS X 10.7. Mac OS X 10.5 introduced a tracing garbage collector as an alternative to reference counting, but it was deprecated in OS X 10.8 and removed from the Objective-C runtime library in macOS Sierra. iOS has never supported a tracing garbage collector.

One language that uses reference counting for garbage collection is Delphi. Delphi is mostly not a garbage collected language, in that user-defined types must still be manually allocated and deallocated. It does provide automatic collection, however, for a few built-in types, such as strings, dynamic arrays, and interfaces, for ease of use and to simplify the generic database functionality. It is up to the programmer to decide whether to use the built-in types or not; Delphi programmers have complete access to low-level memory management like in C/C++. So all potential cost of Delphi's reference counting can, if desired, be easily circumvented.

Some of the reasons reference counting may have been preferred to other forms of garbage collection in Delphi include:


The GObject object-oriented programming framework implements reference counting on its base types, including weak references. Reference incrementing and decrementing uses atomic operations for thread safety. A significant amount of the work in writing bindings to GObject from high-level languages lies in adapting GObject reference counting to work with the language's own memory management system.

The Vala programming language uses GObject reference counting as its primary garbage collection system, along with copy-heavy string handling.

Perl also uses reference counting, without any special handling of circular references, although (as in Cocoa and C++ above), Perl does support weak references, which allows programmers to avoid creating a cycle.

PHP uses a reference counting mechanism for its internal variable management. Since PHP 5.3, it implements the algorithm from Bacon's above mentioned paper. PHP allows you to turn on and off the cycle collection with user-level functions. It also allows you to manually force the purging mechanism to be run.

Python also uses reference counting and offers cycle detection as well (and can reclaim them).

Squirrel also uses reference counting and offers cycle detection as well.
This tiny language is relatively unknown outside the video game industry; however, it is a concrete example of how reference counting can be practical and efficient (especially in realtime environments).

Tcl 8 uses reference counting for memory management of values (Tcl Obj structs). Since Tcl's values are immutable, reference cycles are impossible to form and no cycle detection scheme is needed. Operations that would replace a value with a modified copy are generally optimized to instead modify the original when its reference count indicates it to be unshared. The references are counted at a data structure level, so the problems with very frequent updates discussed above do not arise.

Xojo also uses reference counting, without any special handling of circular references, although (as in Cocoa and C++ above), Xojo does support weak references, which allows programmers to avoid creating a cycle.

Many file systems maintain a count of the number of references to any particular block or file, for example the inode "link count" on Unix-style file systems. These references are usually called as hard links. When the count falls to zero, the file can be safely deallocated. In addition, while references can still be made from directories, some Unixes allow that the referencing can be solely made by live processes, and there can be files that do not exist in the file system hierarchy.



</doc>
<doc id="26491" url="https://en.wikipedia.org/wiki?curid=26491" title="Red-eye effect">
Red-eye effect

The red-eye effect in photography is the common appearance of red pupils in color photographs of the eyes of humans and several other animals. It occurs when using a photographic flash that is very close to the camera lens (as with most compact cameras) in ambient low light.

In flash photography the light of the flash occurs too fast for the pupil to close, so much of the very bright light from the flash passes into the eye through the pupil, reflects off the fundus at the back of the eyeball and out through the pupil. The camera records this reflected light. The main cause of the red color is the ample amount of blood in the choroid which nourishes the back of the eye and is located behind the retina. The blood in the retinal circulation is far less than in the choroid, and plays virtually no role. The eye contains several photostable pigments that all absorb in the short wavelength region, and hence contribute somewhat to the red eye effect. The lens cuts off deep blue and violet light, below 430 nm (depending on age), and macular pigment absorbs between 400 and 500 nm, but this pigment is located exclusively in the tiny fovea. Melanin, located in the retinal pigment epithelium (RPE) and the choroid, shows a gradually increasing absorption towards the short wavelengths. But blood is the main determinant of the red color, because it is completely transparent at long wavelengths and abruptly starts absorbing at 600 nm. The amount of red light emerging from the pupil depends on the amount of melanin in the layers behind the retina. This amount varies strongly between individuals. Light-skinned people with blue eyes have relatively low melanin in the fundus and thus show a much stronger red-eye effect than dark-skinned people with brown eyes. The same holds for animals. The color of the iris itself is of virtually no importance for the red-eye effect. This is obvious because the red-eye effect is most apparent when photographing dark-adapted subjects, hence with fully dilated pupils. Photographs taken with infrared light through night vision devices always show very bright pupils because, in the dark, the pupils are fully dilated and the infrared light is not absorbed by any ocular pigment.

The role of melanin in red-eye effect is demonstrated in animals with heterochromia: only the blue eye displays the effect. The effect is still more pronounced in humans and animals with albinism. All forms of albinism involve abnormal production and/or deposition of melanin.

Red-eye effect is seen in photographs of children also because children's eyes have more rapid dark adaption: in low light a child's pupils enlarge sooner, and an enlarged pupil accentuates the red-eye effect.

Theatrical followspot operators, positioned nearly coincidentally with a very bright light and somewhat distant from the actors, occasionally witness red-eye in actors on stage. The effect is not visible to the rest of the audience because it is reliant on the very small angle between the followspot operator and the light.

Similar effects, some related to red-eye effect, are of several kinds:


The red-eye effect can be prevented in a number of ways.

If direct flash must be used, a good rule of thumb is to separate the flash from the lens by 1/20 of the distance of the camera to the subject. For example, if the subject is 2 meters (6 feet) away, the flash head should be at least 10 cm (4 inches) away from the lens.

Professional photographers prefer to use ambient light or indirect flash, as the red-eye reduction system does not always prevent red eyes — for example, if people look away during the pre-flash. In addition, people do not look natural with small pupils, and direct lighting from close to the camera lens is considered to produce unflattering photographs.

Red-eye removal is built into many popular consumer graphics editing software packages, or is supported through red-eye reduction plug-ins; examples include Adobe Photoshop, Apple iPhoto, Corel Photo-Paint, GIMP, Google Picasa, Paint.NET and Microsoft Windows Photo Gallery. Some can automatically find eyes in the image and perform color correction, and can apply it to many photos at once. Others may require the operator to manually select the regions of the pupils to which correction is to be applied. When performed manually, correction may consist of simply converting the red area of pupils to grayscale (desaturating), leaving surface reflections and highlights intact.
In a photograph of a child's face, if there is red-eye in one eye but not the other, it may be leukocoria, which may be caused by the cancer retinoblastoma. The child's eyes should be examined by a general physician.


</doc>
<doc id="26492" url="https://en.wikipedia.org/wiki?curid=26492" title="Ramsay Hunt syndrome type 2">
Ramsay Hunt syndrome type 2

Ramsay Hunt syndrome type 2, also known as herpes zoster oticus, is a disorder that is caused by the reactivation of varicella zoster virus in the geniculate ganglion, a nerve cell bundle of the facial nerve.

Ramsay Hunt syndrome type 2 typically presents with inability to move many facial muscles, pain in the ear, taste loss on the front of the tongue, dry eyes and mouth, and a vesicular rash.

Symptoms include acute facial nerve paralysis, pain in the ear, taste loss in the front two-thirds of the tongue, dry mouth and eyes, and an erythematous vesicular rash in the ear canal, the tongue, and/or hard palate.

Since the vestibulocochlear nerve is in proximity to the geniculate ganglion, it may also be affected, and patients may also suffer from tinnitus, hearing loss, and vertigo. Involvement of the trigeminal nerve can cause numbness of the face.

Ramsay Hunt syndrome type 2 refers to shingles of the geniculate ganglion. After initial infection, varicella zoster virus lies dormant in nerve cells in the body, where it is kept in check by the immune system. Given the opportunity, for example during an illness that suppresses the immune system, the virus travels to the end of the nerve cell, where it causes the symptoms described above.

The affected ganglion is responsible for the movements of facial muscles, the touch sensation of a part of ear and ear canal, the taste function of the frontal two-thirds of the tongue, and the moisturization of the eyes and the mouth. The syndrome specifically refers to the combination of this entity with weakness of the muscles activated by the facial nerve. In isolation, the latter is called Bell's palsy.

However, as with shingles, the lack of lesions does not definitely exclude the existence of a herpes infection. Even before the eruption of vesicles, varicella zoster virus can be detected from the skin of the ear.

Ramsay Hunt Syndrome Type 2 can be diagnosed based on clinical features, however, in ambiguous cases PCR or direct immunofluorescent assay of vesicular fluid can help with the diagnosis. Laboratory studies such as WBC count, ESR and electrolytes should be obtained to distinguish infectious versus inflammatory etiologies.

On physical exam look for vesicular exanthema on the external auditory canal, concha and or pinna. Dry eyes with possible lower cornea epithelium damage due to incomplete closure of eyelids.

Ramsay Hunt Syndrome type 2 can usually be diagnosed based on clinical features. However, for suspected cases with unclear presentation, varicella zoster virus can be isolated from vesicle fluid. Tear culture PCR can have positive varicella zoster virus. However 25-35% of patients with Bell's palsy can have false positive varicellar zoster virus detected in tears. If central nervous system complications such as meningitis, ventriculitis or meningoencephalitis are suspected, prompt lumbar puncture with spinal fluid analysis and imaging (CT head) are recommended.

Shingles is prevented by immunizing against the causal virus, varicella zoster, for example through Shingrix, a stronger version of chickenpox vaccine.

Treatment with prednisone and the antiviral drug acyclovir 800 mg 5 times a day is controversial, with some studies showing complete recovery in patients if started within the first three days of facial paralysis. Chances of recovery appear to decrease when treatment is delayed. Delay of treatment may result in permanent facial nerve paralysis. However, some studies demonstrate that even when steroids are started promptly, only 22% of all patient achieve full recovery of facial paralysis.

Treatment apparently has no effect on the recovery of hearing loss. Diazepam is sometimes used to treat the vertigo.

The syndrome is named for James Ramsay Hunt, the eminent neurologist who first described it.



</doc>
<doc id="26494" url="https://en.wikipedia.org/wiki?curid=26494" title="Race and intelligence">
Race and intelligence

Discussions of race and intelligence, as well as claims of genetic differences in intelligence along racial lines, have appeared in both popular science and academic research since the inception of IQ testing in the early 20th century. The concept of "race" is a social construct, and "intelligence" has no agreed-upon definition; the validity of IQ tests as a metric for general intelligence is itself disputed. In particular, there is no scientific evidence that the average IQ scores of different racial or ethnic population groups can be attributed to any claimed genetic differences between those groups.

The first tests showing differences in IQ scores between different population groups in the United States were the tests of United States Army recruits in World War I. In the 1920s, groups of eugenics lobbyists argued that these results demonstrated that African-Americans and certain immigrant groups were of inferior intellect to Anglo-Saxon white people, and that this was due to innate biological differences; and they used such beliefs to justify policies of racial segregation. However, soon other studies appeared, contesting these conclusions and arguing instead that the Army tests had not adequately controlled for environmental factors, such as socio-economic and educational inequality between black people and white people. Later observations of phenomena such as the Flynn effect have also highlighted the ways that environmental factors affect group IQ differences.

Claims of differences in intelligence between races have been used to justify colonialism, slavery, racism, social Darwinism, and racial eugenics. Racial thinkers such as Arthur de Gobineau relied crucially on the assumption that black people were innately inferior to white people in developing their ideologies of white supremacy. Even Enlightenment thinkers such as Thomas Jefferson, a slave owner, believed black people to be innately inferior to white people in physique and intellect. At the same time, prominent examples of African-American genius such the autodidact and abolitionist Frederick Douglass, the pioneering sociologist W. E. B. Du Bois, and the poet Paul Lawrence Dunbar stood as high-profile counterexamples to widespread stereotypes of black intellectual inferiority.

The first practical intelligence test was developed between 1905 and 1908 by Alfred Binet in France for school placement of children. Binet warned that results from his test should not be assumed to measure innate intelligence or used to label individuals permanently. Binet's test was translated into English and revised in 1916 by Lewis Terman (who introduced IQ scoring for the test results) and published under the name Stanford–Binet Intelligence Scales. In 1916 Terman wrote that Mexican-Americans, African-Americans, and Native Americans have a mental "dullness [that] seems to be racial, or at least inherent in the family stocks from which they come.".

The US Army used a different set of tests developed by Robert Yerkes to evaluate draftees for World War I. Based on the Army's data, prominent psychologists and eugenicists such as Henry H. Goddard, Harry H. Laughlin, and Princeton professor Carl Brigham wrote that people from southern and eastern Europe were less intelligent than native-born Americans or immigrants from the Nordic countries, and that black Americans were less intelligent than white Americans. The results were widely publicized by a lobby of anti-immigration activists, including the conservationist and theorist of scientific racism Madison Grant, who considered the so-called Nordic race to be superior, but under threat because of immigration by "inferior breeds." In his influential work, "A Study of American Intelligence," psychologist Carl Brigham used the results of the Army tests to argue for a stricter immigration policy, limiting immigration to countries considered to belong to the "Nordic race".

In the 1920s, some US states enacted eugenic laws, such as Virginia's 1924 Racial Integrity Act, which established the one-drop rule (of 'racial purity') as law. Many scientists reacted negatively to eugenicist claims linking abilities and moral character to racial or genetic ancestry. They pointed to the contribution of environment (such as speaking English as a second language) to test results. By the mid-1930s, many psychologists in the US had adopted the view that environmental and cultural factors played a dominant role in IQ test results. The psychologist Carl Brigham repudiated his own earlier arguments, explaining that he had come to realize that the tests were not a measure of innate intelligence. 

Discussions of the issue in the United States, especially in the writings of Madison Grant, influenced German Nazi claims that the "Nordics" were a "master race." As American public sentiment shifted against the Germans, claims of racial differences in intelligence increasingly came to be regarded as problematic. Anthropologists such as Franz Boas, Ruth Benedict, and Gene Weltfish did much to demonstrate that claims about racial hierarchies of intelligence were unscientific. Nonetheless, a powerful eugenics and segregation lobby funded largely by textile-magnate Wickliffe Draper continued to use intelligence studies as an argument for eugenics, segregation, and anti-immigration legislation.

As the desegregation of the American South gained traction in the 1950s, debate about black intelligence resurfaced. Audrey Shuey, funded by Draper's Pioneer Fund, published a new analysis of Yerkes' tests, concluding that black people really were of inferior intellect to white people. This study was used by segregationists to argue that it was to the advantage of black children to be educated separately from the superior white children. In the 1960s, the debate was revived when William Shockley publicly defended the view that black children were innately unable to learn as well as white children. Arthur Jensen expressed similar opinions in his "Harvard Educational Review" article, "How Much Can We Boost IQ and Scholastic Achievement?," which questioned the value of compensatory education for African-American children. He suggested that poor educational performance in such cases reflected an underlying genetic cause rather than lack of stimulation at home or other environmental factors.

Another revival of public debate followed the appearance of "The Bell Curve" (1994), a book by Richard Herrnstein and Charles Murray that supported the general viewpoint of Jensen. A statement in support of Herrnstein and Murray titled "Mainstream Science on Intelligence," was published in "The Wall Street Journal" with 52 signatures. "The Bell Curve" also led to critical responses in a statement titled "" of the American Psychological Association and in several books, including "The Bell Curve Debate" (1995), "Inequality by Design" (1996) and a second edition of "The Mismeasure of Man" (1996) by Stephen Jay Gould.

Some of the authors proposing genetic explanations for group differences have received funding from the Pioneer Fund, which was headed by J. Philippe Rushton until his death in 2012. Arthur Jensen, who jointly with Rushton published a 2005 review article arguing that the difference in mean IQs between blacks and whites is partly due to genetics, received $1.1 million from the Pioneer Fund. According to Ashley Montagu, "The University of California's Arthur Jensen, cited twenty-three times in "The Bell Curve"'s bibliography, is the book's principal authority on the intellectual inferiority of blacks."

The Southern Poverty Law Center lists the Pioneer Fund as a hate group, citing the fund's history, its funding of race and intelligence research, and its connections with racist individuals. Other researchers have criticized the Pioneer Fund for promoting scientific racism, eugenics and white supremacy.

The concept of intelligence and the degree to which intelligence is measurable are matters of debate. There is no consensus about how to define intelligence; nor is it universally accepted that it is something that can be meaningfully measured by a single figure. A recurring criticism is that different societies value and promote different kinds of skills and that the concept of intelligence is therefore culturally variable and cannot be measured by the same criteria in different societies. Consequently, some critics argue that it makes no sense to propose relationships between intelligence and other variables.

Correlations between scores on various types of IQ tests led English psychologist Charles Spearman to propose in 1904 the existence of an underlying factor, which he referred to as ""g"" or "general intelligence". With regard to this ""g" factor", Spearman claimed that "a person can no more be trained to have it in higher degree than he can be trained to be taller." More recent proponents of this view include Arthur Jensen, who has argued that test score differences, especially in tasks considered to be particularly "g-loaded," reflect the test taker's innate capability. This view, however, has been contradicted by a number of studies showing that even when accounting for "g-loading", education and changes in environment can significantly improve IQ test results.

Other psychometricians have argued that, whether or not there is such a thing as a general intelligence factor, performance on tests relies crucially on knowledge acquired through prior exposure to the types of tasks that such tests contain. This means that comparisons of test scores between persons with widely different life experiences and cognitive habits do not reveal their relative innate potentials.

The majority of anthropologists today consider race to be a sociopolitical phenomenon rather than a biological one, a view supported by considerable genetics research. The current mainstream view in the social sciences and biology is that race is a social construction based on folk ideologies that construct groups based on social disparities and superficial physical characteristics. state, "Race is a socially constructed concept, not a biological one. It derives from people's desire to classify." The concept of human "races" as natural and separate divisions within the human species has also been rejected by the American Anthropological Association. The official position of the AAA, adopted in 1998, is that advances in scientific knowledge have made it "clear that human populations are not unambiguous, clearly demarcated, biologically distinct groups" and that "any attempt to establish lines of division among biological populations [is] both arbitrary and subjective." A more recent statement from the American Association of Physical Anthropologists (2019) declares that "Race does not provide an accurate representation of human biological variation. It was never accurate in the past, and it remains inaccurate when referencing contemporary human populations. Humans are not divided biologically into distinct continental types or racial genetic clusters."

In studies of human intelligence, race is almost always determined using self-reports rather than analyses of genetic characteristics. According to psychologist David Rowe, self-report is the preferred method for racial classification in studies of racial differences because classification based on genetic markers alone ignore the "cultural, behavioral, sociological, psychological, and epidemiological variables" that distinguish racial groups. Hunt and Carlson write that "Nevertheless, self-identification is a surprisingly reliable guide to genetic composition. applied mathematical clustering techniques to sort genomic markers for over 3,600 people in the United States and Taiwan into four groups. There was almost perfect agreement between cluster assignment and individuals' self-reports of racial/ethnic identification as white, black, East Asian, or Latino." Sternberg and Grigorenko disagree with Hunt and Carlson's interpretation of Tang's results as supporting the view that racial divisions are biological; rather, "Tang et al.'s point was that ancient geographic ancestry rather than current residence is associated with self-identification and not that such self-identification provides evidence for the existence of biological race."

Anthropologist C. Loring Brace and geneticist Joseph Graves disagree with the idea that cluster analysis and the correlation between self-reported race and genetic ancestry support the notion of biological races. They argue that while it is possible to find biological and genetic variation corresponding roughly to the groupings normally defined as races, this is true for almost all geographically distinct populations. The cluster structure of the genetic data is dependent on the initial hypotheses of the researcher and the populations sampled. When one samples continental groups, the clusters become continental; if one had chosen other sampling patterns, the clusters would be different. concludes that, while differences in particular allele frequencies can be used to identify populations that loosely correspond to the racial categories common in Western social discourse, the differences are of no more biological significance than the differences found between any human populations (e.g., the Spanish and Portuguese).

The study of human intelligence is one of the most controversial topics in psychology, in part because of difficulty reaching agreement about the meaning of "intelligence" and objections to the assumption that intelligence can be meaningfully measured by IQ tests. Claims that there are innate differences in intelligence between racial and ethnic groups—which go back at least to the 19th century—have been criticized both for relying on specious assumptions and research methods and for serving as an ideological framework for discrimination and racism.

In a 2012 study of tests of different components of intelligence, Hampshire "et al" expressed disagreement with the view of Jensen and Rushton that genetic factors must play a role in IQ differences between races, stating that "it remains unclear, however, whether population differences in intelligence test scores are driven by heritable factors or by other correlated demographic variables such as socioeconomic status, education level, and motivation. More relevantly, it is questionable whether they [population differences in intelligence test scores] relate to a unitary intelligence factor, as opposed to a bias in testing paradigms toward particular components of a more complex intelligence construct." According to Jackson and Weidman, There are a number of reasons why the genetic argument for race differences in intelligence has not won many adherents in the scientific community. First, even taken on its own terms, the case made by Jensen and his followers did not hold up to scrutiny. Second, the rise of population genetics undercut the claims for a genetic cause of intelligence. Third, the new understanding of institutional racism offered a better explanation for the existence of differences in IQ scores between the races.

In the US, generally individuals identifying themselves as Asian tend to score higher on IQ tests than Caucasians, who score higher than Hispanics, who score higher than African Americans. Nevertheless, greater variation in IQ scores exists within each ethnic group than between them. , in a review of the results of a total of 6,246,729 participants in other tests of cognitive ability or aptitude, found a difference in mean scores between black people and white people of 1.1 SD. Consistent results were found for college and university application tests such as the Scholastic Aptitude Test (N = 2.4 million) and Graduate Record Examination (N = 2.3 million), as well as for tests of job applicants in corporate settings (N = 0.5 million) and in the military (N = 0.4 million). 

In response to the controversial 1994 book "The Bell Curve", the American Psychological Association (APA) formed a task-force of eleven experts, which issued a report "" in 1996. Regarding group differences, the report reaffirmed the consensus that differences within groups are much wider than differences between groups, and that claims of ethnic differences in intelligence should be scrutinized carefully, as such claims had been used to justify racial discrimination. The report also acknowledged problems with the racial categories used, as these categories are neither consistently applied, nor homogeneous (see also race and ethnicity in the United States).

In the UK, some African groups have higher educational attainment and standardized test scores than the population on average. In 2010 - 2011, white British pupils were 2.3% less likely to have gained 5 A*–C grades at GCSE than the national average, whereas the likelihood was 21.8% above average for those of Nigerian and 5.5% for those of Ghanaian origin. In 2014, Black-African pupils of 11 language groups were more likely to pass Key Stage 2 Maths 4+ in England than the national average. While the White British average was 84.6%, there were four Black African groups (Yoruba, Igbo, Hausa and Amharic speakers) that had a pass rate of over 90%. In 2017/2018, percentage of pupils getting a strong pass (grade 5 or above) in English and maths GCSE (in Key Stage 4) was higher among Black-African pupils (44.3%) than white British pupils (42.67%)..

During the 20th century raw scores on IQ tests were rising; this score increase is known as the "Flynn effect," named after James R. Flynn. In the United States, the increase was continuous and approximately linear from the earliest years of testing to about 1998 when the gains stopped and some tests even showed decreasing test scores. For example, the average scores of black people on some IQ tests in 1995 were the same as the scores of white people in 1945. As one pair of academics phrased it, "the typical African American today probably has a slightly higher IQ than the grandparents of today's average white American."

Flynn has argued that, given that these changes took place between one generation and the next, it is highly unlikely that genetic factors could have accounted for the increasing scores, which must then have been caused by environmental factors. The importance of the Flynn effect in the debate over the causes of the black/white IQ gap lies in demonstrating that environmental factors may cause changes in test scores on the scale of 1 SD. This had previously been doubted.

A separate phenomenon from the Flynn effect has been the discovery that the IQ gap was gradually closing over the last decades of the 20th century, as black test-takers increased their average scores relative to white test-takers. For instance, Vincent reported in 1991 that the black–white IQ gap was decreasing among children, but that it was remaining constant among adults. Similarly, a 2006 study by Dickens and Flynn estimated that the difference between mean scores of black people and white people closed by about 5 or 6 IQ points between 1972 and 2002, a reduction of about one-third. In the same period, the educational achievement disparity also diminished. Reviews by Flynn and Dickens, Mackintosh, and Nisbett "et al" accept the gradual closing of the gap as a fact.

Environmental factors including childhood lead exposure, low rates of breast feeding, and poor nutrition can significantly affect cognitive development and functioning. For example, childhood exposure to lead, associated with homes in poorer areas causes an average IQ drop of 7 points, and iodine deficiency causes a fall, on average, of 12 IQ points. Such impairments may sometimes be permanent, sometimes be partially or wholly compensated for by later growth. The first two years of life is the critical time for malnutrition, the consequences of which are often irreversible and include poor cognitive development, educability, and future economic productivity. The African American population of the United States is statistically more likely to be exposed to many detrimental environmental factors such as poorer neighborhoods, schools, nutrition, and prenatal and postnatal health care. Mackintosh points out that for American black people infant mortality is about twice as high as for white people, and low birthweight is twice as prevalent. At the same time white mothers are twice as likely to breastfeed their infants, and breastfeeding is highly correlated with IQ for low birthweight infants. In this way a wide number of health related factors that influence IQ are unequally distributed between the two groups.

The Copenhagen consensus in 2004 stated that lack of both iodine and iron has been implicated in impaired brain development, and this can affect enormous numbers of people: it is estimated that one-third of the total global population are affected by iodine deficiency. In developing countries, it is estimated that 40% of children aged four and under suffer from anaemia because of insufficient iron in their diets.

Other scholars have found that simply the standard of nutrition has a significant effect on population intelligence, and that the Flynn effect may be caused by increasing nutrition standards across the world. James Flynn has himself argued against this view.

Some recent research has argued that the retardation caused in brain development by infectious diseases, many of which are more prevalent in non-white populations, may be an important factor in explaining the differences in IQ between different regions of the world. The findings of this research, showing the correlation between IQ, race and infectious diseases was also shown to apply to the IQ gap in the US, suggesting that this may be an important environmental factor.

A 2013 meta-analysis by the World Health Organization found that, after controlling for maternal IQ, breastfeeding was associated with IQ gains of 2.19 points. The authors suggest that this relationship is causal but state that the practical significance of this gain is debatable; however, they highlight one study suggesting an association between breastfeeding and academic performance in Brazil, where "breastfeeding duration does not present marked variability by socioeconomic position." Colen and Ramey (2014) similarly find that controlling for sibling comparisons within families, rather than between families, reduces the correlation between breastfeeding status and WISC IQ scores by nearly a third, but further find the relationship between breastfeeding duration and WISC IQ scores to be insignificant. They suggest that "much of the beneficial long-term effects typically attributed to breastfeeding, per se, may primarily be due to selection pressures into infant feeding practices along key demographic characteristics such as race and socioeconomic status." Reichman estimates that no more than 3 to 4% of the black–white IQ gap can be explained by black–white disparities in low birth weight.

Several studies have proposed that a large part of the gap can be attributed to differences in quality of education. Racial discrimination in education has been proposed as one possible cause of differences in educational quality between races. According to a paper by Hala Elhoweris, Kagendo Mutua, Negmeldin Alsheikh and Pauline Holloway, teachers' referral decisions for students to participate in gifted and talented educational programs were influenced in part by the students' ethnicity.

The Abecedarian Early Intervention Project, an intensive early childhood education project, was also able to bring about an average IQ gain of 4.4 points at age 21 in the black children who participated in it compared to controls. Arthur Jensen agreed that the Abecedarian project demonstrated that education can have a significant effect on IQ, but also declared his view that no educational program thus far had been able to reduce the black–white IQ gap by more than a third, and that differences in education are thus unlikely to be its only cause.

A series of studies by Joseph Fagan and Cynthia Holland measured the effect of prior exposure to the kind of cognitive tasks posed in IQ tests on test performance. Assuming that the IQ gap was the result of lower exposure to tasks using the cognitive functions usually found in IQ tests among African American test takers, they prepared a group of African Americans in this type of tasks before taking an IQ test. The researchers found that there was no subsequent difference in performance between the African-Americans and white test takers. Daley and Onwuegbuzie conclude that Fagan and Holland demonstrate that "differences in knowledge between black people and white people for intelligence test items can be erased when equal opportunity is provided for exposure to the information to be tested". A similar argument is made by David Marks who argues that IQ differences correlate well with differences in literacy suggesting that developing literacy skills through education causes an increase in IQ test performance.

A 2003 study found that two variables—stereotype threat and the degree of educational attainment of children's fathers—partially explained the black–white gap in cognitive ability test scores, undermining the hereditarian view that they stemmed from immutable genetic factors.

Different aspects of the socioeconomic environment in which children are raised have been shown to correlate with part of the IQ gap, but they do not account for the entire gap. According to a 2006 review, these factors account for slightly less than half of one standard deviation. 

Other research has focused on different causes of variation within low socioeconomic status (SES) and high SES groups.
In the US, among low SES groups, genetic differences account for a smaller proportion of the variance in IQ than among high SES populations. Such effects are predicted by the "bioecological" hypothesis—that genotypes are transformed into phenotypes through nonadditive synergistic effects of the environment. suggest that high SES individuals are more likely to be able to develop their full biological potential, whereas low SES individuals are likely to be hindered in their development by adverse environmental conditions. The same review also points out that adoption studies generally are biased towards including only high and high middle SES adoptive families, meaning that they will tend to overestimate average genetic effects. They also note that studies of adoption from lower-class homes to middle-class homes have shown that such children experience a 12 to 18 point gain in IQ relative to children who remain in low SES homes. A 2015 study found that environmental factors (namely, family income, maternal education, maternal verbal ability/knowledge, learning materials in the home, parenting factors, child birth order, and child birth weight) accounted for the black–white gap in cognitive ability test scores.

A number of studies have reached the conclusion that IQ tests may be biased against certain groups. The validity and reliability of IQ scores obtained from outside the United States and Europe have been questioned, in part because of the inherent difficulty of comparing IQ scores between cultures. Several researchers have argued that cultural differences limit the appropriateness of standard IQ tests in non-industrialized communities.

A 1996 report by the American Psychological Association states that intelligence can be difficult to compare across cultures, and notes that differing familiarity with test materials can produce substantial differences in test results; it also says that tests are accurate predictors of future achievement for black and white Americans, and are in that sense unbiased. The view that tests accurately predict future educational attainment is reinforced by Nicholas Mackintosh in his 1998 book "IQ and Human Intelligence", and by a 1999 literature review by .

James R. Flynn, surveying studies on the topic, notes that the weight and presence of many test questions depends on what sorts of information and modes of thinking are culturally valued.

According to a 2008 article in the journal "Intelligence", a survey found that most researchers in the field of intelligence measurement do not believe there is robust evidence for the claim that IQ tests are racially or culturally biased. This finding is similar to that of a 2003 survey.

Stereotype threat is the fear that one's behavior will confirm an existing stereotype of a group with which one identifies or by which one is defined; this fear may in turn lead to an impairment of performance. Testing situations that highlight the fact that intelligence is being measured tend to lower the scores of individuals from racial-ethnic groups who already score lower on average or are expected to score lower. Stereotype threat conditions cause larger than expected IQ differences among groups. Psychometrician Nicholas Mackintosh considers that there is little doubt that the effects of stereotype threat contribute to the IQ gap between black people and white people.

A large number of studies have shown that systemically disadvantaged minorities, such as the African American minority of the United States, generally perform worse in the educational system and in intelligence tests than the majority groups or less disadvantaged minorities such as immigrant or "voluntary" minorities. The explanation of these findings may be that children of caste-like minorities, due to the systemic limitations of their prospects of social advancement, do not have "effort optimism", i.e. they do not have the confidence that acquiring the skills valued by majority society, such as those skills measured by IQ tests, is worthwhile. They may even deliberately reject certain behaviors that are seen as "acting white." Research published in 1997 indicates that part of the black–white gap in cognitive ability test scores is due to racial differences in test motivation.

Some researchers have suggested that stereotype threat should not be interpreted as a factor in real-life performance gaps, and have raised the possibility of publication bias. Other critics have focused on correcting what they claim are misconceptions of early studies showing a large effect. However, numerous meta-analyses and systematic reviews have shown significant evidence for the effects of stereotype threat, though the phenomenon defies over-simplistic characterization. For instance, one meta-analysis found that with female subjects "subtle threat-activating cues produced the largest effect, followed by blatant and moderately explicit cues" while with minorities "moderately explicit stereotype threat-activating cues produced the largest effect, followed by blatant and subtle cues". 

Some researchers have argued that studies of stereotype threat may in fact systematically under-represent its effects, since such studies measure "only that portion of psychological threat that research has identified and remedied. To the extent that unidentified or unremedied psychological threats further undermine performance, the results underestimate the bias."

Although IQ differences between individuals have been shown to have a large hereditary component, it does not follow that mean group-level disparities (between-group differences) in IQ necessarily have a genetic basis. The current scientific consensus is that there is no evidence for a genetic component behind IQ differences between racial groups. Growing evidence indicates that environmental factors, not genetic ones, explain the racial IQ gap.

Geneticist Alan R. Templeton argues that the question about the possible genetic effects on the test score gap is muddled by the general focus on "race" rather than on populations defined by gene frequency or by geographical proximity, and by the general insistence on phrasing the question in terms of heritability. Templeton points out that racial groups neither represent sub-species nor distinct evolutionary lineages, and that therefore there is no basis for making claims about the general intelligence of races. From this point of view the search for possible genetic influences on the black–white test score gap is "a priori" flawed, because there is no genetic material shared by all Africans or by all Europeans. , however, argues that by using genetic cluster analysis to correlate gene frequencies with continental populations it might be possible to show that African populations have a higher frequency of certain genetic variants that contribute to an average lower intelligence. Such a hypothetical situation could hold without all Africans carrying the same genes or belonging to a single evolutionary lineage. According to Mackintosh, a biological basis for the gap thus cannot be ruled out on "a priori" grounds.

Intelligence is a polygenic trait. This means that intelligence is under the influence of several genes, possibly several thousand. The effect of most individual genetic variants on intelligence is thought to be very small, well below 1% of the variance in "g". Current studies using quantitative trait loci have yielded little success in the search for genes influencing intelligence. Robert Plomin is confident that QTLs responsible for the variation in IQ scores exist, but due to their small effect sizes, more powerful tools of analysis will be required to detect them. Others assert that no useful answers can be reasonably expected from such research before an understanding of the relation between DNA and human phenotypes emerges. Several candidate genes have been proposed to have a relationship with intelligence. However, a review of candidate genes for intelligence published in failed to find evidence of an association between these genes and general intelligence, stating "there is still almost no replicated evidence concerning the individual genes, which have variants that contribute to intelligence differences". In 2001, a review in the "Journal of Black Psychology" refuted eight major premises on which the hereditarian view regarding race and intelligence is based.

A 2005 literature review article by Sternberg, Grigorenko and Kidd stated that no gene has been shown to be linked to intelligence, "so attempts to provide a compelling genetic link of race to intelligence are not feasible at this time." concurs with this critique, noting that "The argument for genetic differences has been carried forward largely by circumstantial evidence. Of course, tomorrow afternoon genetic mechanisms producing racial and ethnic differences in intelligence might be discovered, but there have been a lot of investigations, and tomorrow has not come for quite some time now." concurs as well, noting that while several environmental factors have been shown to influence the IQ gap, the evidence for a genetic influence has been negligible. The 2012 review by concluded that "Almost no genetic polymorphisms have been discovered that are consistently associated with variation in IQ in the normal range." They consider the entire IQ gap to be explained by the environmental factors that have thus far been demonstrated to influence it, and Mackintosh finds this view to be reasonable.

Twin studies of intelligence have reported high heritability values. However, these studies have been criticized for being based on questionable assumptions. When used in the context of human behavior genetics, the term "heritability" can be misleading, as it does not necessarily convey information about the relative importance of genetic or environmental factors on the development of a given trait, nor does it convey the extent to which that trait is genetically determined. Arguments in support of a genetic explanation of racial differences in IQ are sometimes fallacious. For instance, hereditarians have sometimes cited the failure of known environmental factors to account for such differences, or the high heritability of intelligence within races, as evidence that racial differences in IQ are genetic.

Psychometricians have found that intelligence is substantially heritable within populations, with 30–50% of variance in IQ scores in early childhood being attributable to genetic factors in analyzed US populations, increasing to 75–80% by late adolescence. In biology heritability is defined as the ratio of variation attributable to genetic differences in an observable trait to the trait's total observable variation. The heritability of a trait describes the proportion of variation in the trait that is attributable to genetic factors within a particular population. A heritability of 1 indicates that variation correlates fully with genetic variation and a heritability of 0 indicates that there is no correlation between the trait and genes at all. In psychological testing, heritability tends to be understood as the degree of correlation between the results of a test taker and those of their biological parents. However, since high heritability is simply a correlation between child and parents, it does not describe the causes of heritability which in humans can be either genetic or environmental.

Therefore, a high heritability measure does not imply that a trait is genetic or unchangeable. In addition, environmental factors that affect all group members equally will not be measured by heritability, and the heritability of a trait may also change over time in response to changes in the distribution of genetic and environmental factors. High heritability does not imply that all of the heritability is genetically determined; rather, it can also be due to environmental differences that affect only a certain genetically defined group (indirect heritability). 

The figure to the right demonstrates how heritability works. In each of the two gardens the difference between tall and short cornstalks is 100% heritable, as cornstalks that are genetically disposed for growing tall will become taller than those without this disposition. But the difference in height between the cornstalks to the left and those on the right is 100% environmental, as it is due to different nutrients being supplied to the two gardens. Hence, the causes of differences within a group and between groups may not be the same, even when looking at traits that are highly heritable. In his criticism of "the Bell Curve", Noam Chomsky further illustrated this with the example of women wearing earrings:

Spearman's hypothesis states that the magnitude of the black–white difference in tests of cognitive ability depends entirely or mainly on the extent to which a test measures general mental ability, or "g". The hypothesis was first formalized by Arthur Jensen, who devised the statistical "method of correlated vectors" to test it. If Spearman's hypothesis holds true, then the cognitive tasks that have the highest "g"-load are the tasks in which the gap between black and white test takers are greatest. Jensen and Rushton take this to show that the cause of "g" and the cause of the gap are the same—in their view, genetic differences.

Flynn has criticized Jensen's basic assumption that confirmation of Spearman's hypothesis would support a partially genetic explanation for IQ differences. He argues that, no matter what the causes are of average group IQ differences, one would expect the differences to be greater for more complex tasks. Flynn thus sees the correlation between "g"-loading and the test score gap to offer no clue to the cause of the gap.

A number of IQ studies have been done on the effect of similar rearing conditions on children from different races. The hypothesis is that this can be determined by investigating whether black children adopted into white families demonstrated gains in IQ test scores relative to black children reared in black families. Depending on whether their test scores are more similar to their biological or adoptive families, that could be interpreted as supporting either a genetic or an environmental hypothesis. Critiques of such studies question whether the environment of black children—even when raised in white families—is truly comparable to the environment of white children. Several reviews of the adoption study literature have suggested that it is probably impossible to avoid confounding biological and environmental factors in this type of study. Another criticism by is that adoption studies on the whole tend to be carried out in a restricted set of environments, mostly in the medium-high SES range, where heritability is higher than in the low-SES range.

The Minnesota Transracial Adoption Study (1976) examined the IQ test scores of 122 adopted children and 143 nonadopted children reared by advantaged white families. The children were restudied ten years later. The study found higher IQ for white people compared to black people, both at age 7 and age 17. Acknowledging the existence of confounding factors, Scarr and Weinberg, the authors of the original study, did not consider that it provided support for either the hereditarian or environmentalist view.

Three other studies lend support to environmental explanations of group IQ differences: 

Frydman and Lynn (1989) showed a mean IQ of 119 for Korean infants adopted by Belgian families. After correcting for the Flynn effect, the IQ of the adopted Korean children was still 10 points higher than that of the Belgian children.

Reviewing the evidence from adoption studies, Mackintosh finds that environmental and genetic variables remain confounded and considers evidence from adoption studies inconclusive, and fully compatible with a 100% environmental explanation. Similarly, Drew Thomas argues that race differences in IQ that appear in adoption studies are in fact an artifact of methodology, and that East Asian IQ advantages and black IQ disadvantages disappear when this is controlled for.

Most people have ancestry from different geographical regions. In particular, African Americans typically have ancestors from both Africa and Europe, with, on average, 20% of their genome inherited from European ancestors. If racial IQ gaps have a partially genetic basis, one might expect black people with a higher degree of European ancestry to score higher on IQ tests than black people with less European ancestry, because the genes inherited from European ancestors would likely include some genes with a positive effect on IQ. Geneticist Alan Templeton has argued that an experiment based on the Mendelian "common garden" design, where specimens with different hybrid compositions are subjected to the same environmental influences, are the only way to definitively show a causal relation between genes and group differences in IQ. Summarizing the findings of admixture studies, he concludes that they have shown no significant correlation between any cognitive ability and the degree of African or European ancestry.

Studies have employed different ways of measuring or approximating relative degrees of ancestry from Africa and Europe. Some studies have used skin color as a measure, and others have used blood groups. surveys the literature and argues that the blood groups studies may be seen as providing some support to the genetic hypothesis, even though the correlation between ancestry and IQ was quite low. He finds that studies by , Willerman, Naylor & Myrianthopoulos (1970) did not find a correlation between degree of African/European ancestry and IQ. The latter study did find a difference based on the race of the mother, with children of white mothers with black fathers scoring higher than children of black mothers and white fathers. Loehlin considers that such a finding is compatible with either a genetic or an environmental cause. All in all Loehlin finds admixture studies inconclusive and recommends more research.

Reviewing the evidence from admixture studies considers it to be inconclusive because of too many uncontrolled variables. quotes a statement by to the effect that admixture studies have not provided a shred of evidence in favor of a genetic basis for the IQ gap.

Mental chronometry measures the elapsed time between the presentation of a sensory stimulus and the subsequent behavioral response by the participant. This reaction time (RT) is considered a measure of the speed and efficiency with which the brain processes information. Scores on most types of RT tasks tend to correlate with scores on standard IQ tests as well as with "g", and no relationship has been found between RT and any other psychometric factors independent of "g". The strength of the correlation with IQ varies from one RT test to another, but Hans Eysenck gives 0.40 as a typical correlation under favorable conditions. According to Jensen, individual differences in RT have a substantial genetic component, and heritability is higher for performance on tests that correlate more strongly with IQ. Nisbett argues that some studies have found correlations closer to 0.2, and that a correlation is not always found.

Several studies have found differences between races in average reaction times. These studies have generally found that reaction times among black, Asian and white children follow the same pattern as IQ scores. Black–white differences in reaction time, however, tend to be small (average effect size .18). have argued that reaction time is independent of culture and that the existence of race differences in average reaction time is evidence that the cause of racial IQ gaps is partially genetic. Responding to this argument in "Intelligence and How to Get It", Nisbett points to the study in which a group of Chinese Americans had longer reaction times than a group of European Americans, despite having higher IQs. Nisbett also mentions findings in and suggesting that movement time (the measure of how long it takes a person to move a finger after making the decision to do so) correlates with IQ just as strongly as reaction time, and that average movement time is faster for black people than for white people. considers reaction time evidence unconvincing and comments that other cognitive tests that also correlate well with IQ show no disparity at all, for example the habituation/dishabituation test. He further comments that studies show that rhesus monkeys have shorter reaction times than American college students, suggesting that different reaction times may not tell us anything useful about intelligence.

A number of studies have reported a moderate statistical correlation between differences in IQ and brain size between individuals in the same group. Some scholars have reported differences in average brain sizes between racial groups, although this is unlikely to be a good measure of IQ as brain size also differs between men and women, but without significant differences in IQ. At the same time newborn black children have the same average brain size as white children, suggesting that the difference in average size could be accounted for by differences in environment. Several factors that reduce brain size have been demonstrated to disproportionately affect black children.

Archaeological evidence does not support claims by Rushton and others that black people's cognitive ability was inferior to white people's during prehistoric times as a result of evolution.

The ethics of research on race and intelligence has long been a subject of debate: in a 1996 report of the American Psychological Association; in guidelines proposed by Gray and Thompson and by Hunt and Carlson; and in two editorials in "Nature" in 2009 by Steven Rose and by Stephen J. Ceci and Wendy M. Williams.

Steven Rose maintains that the history of eugenics makes this field of research difficult to reconcile with current ethical standards for science.
On the other hand, James R. Flynn has argued that had there been a ban on research on possibly poorly conceived ideas, much valuable research on intelligence testing (including his own discovery of the Flynn effect) would not have occurred.

Jensen and Rushton argued that what they believe to be biological differences in intelligence between races raises questions about the worthiness of policies such as affirmative action and promotion of diversity.

Many have argued for increased interventions in order to close the gaps. Flynn writes that "America will have to address all the aspects of black experience that are disadvantageous, beginning with the regeneration of inner city neighborhoods and their schools." Especially in developing nations, society has been urged to take on the prevention of cognitive impairment in children as a high priority. Possible preventable causes include malnutrition, infectious diseases such as meningitis, parasites, cerebral malaria, in utero drug and alcohol exposure, newborn asphyxia, low birth weight, head injuries, lead poisoning and endocrine disorders.





</doc>
<doc id="26495" url="https://en.wikipedia.org/wiki?curid=26495" title="Retirement">
Retirement

Retirement is the withdrawal from one's position or occupation or from one's active working life. A person may also semi-retire by reducing work hours.

Many people choose to retire when they are eligible for private or public pension benefits, although some are forced to retire when bodily conditions no longer allow the person to work any longer (by illness or accident) or as a result of legislation concerning their position. In most countries, the idea of retirement is of recent origin, being introduced during the late 19th and early 20th centuries. Previously, low life expectancy and the absence of pension arrangements meant that most workers continued to work until death. Germany was the first country to introduce retirement benefits in 1889.

Nowadays, most developed countries have systems to provide pensions on retirement in old age, funded by employers or the state. In many poorer countries there is no support for the old beyond that provided through the family. Today, retirement with a pension is considered a right of the worker in many societies; hard ideological, social, cultural and political battles have been fought over whether this is a right. In many western countries, this is a right embodied in national constitutions.

An increasing number of individuals are choosing to put off this point of total retirement, by selecting to exist in the emerging state of pre-tirement. 

Retirement, or the practice of leaving one's job or ceasing to work after reaching a certain age, has been around since around the 18th century. Prior to the 18th century, humans had an average life expectancy between 26 and 40 years.
In consequence, only a small percentage of the population reached an age where physical impairments began to be obstacles to working. Countries began to adopt government policies on retirement during the late 19th century and the 20th century, beginning in Germany under Otto von Bismarck.

A person may retire at whatever age they please. However, a country's tax laws or state old-age pension rules usually mean that in a given country a certain age is thought of as the standard retirement age. As life expectancy increases and more and more people live to an advanced age, in many countries the age at which a pension is awarded has been increased in the 21st century, often progressively.

The standard retirement age varies from country to country but it is generally between 50 and 70 (according to latest statistics, 2011). In some countries this age is different for men and women, although this has recently been challenged in some countries (e.g., Austria), and in some countries the ages are being brought into line. The table below shows the variation in eligibility ages for public old-age benefits in the United States and many European countries, according to the OECD.

"The retirement age in many countries is increasing, often starting in the 2010s and continuing until the late 2020s."

Notes: Parentheses indicate eligibility age for women when different. Sources: Cols. 1–2: OECD Pensions at a Glance (2005), Cols. 3–6: Tabulations from HRS, ELSA and SHARE. Square brackets indicate early retirement for some public employees.

In the United States, while the normal retirement age for Social Security, or Old Age Survivors Insurance (OASI) was age 65 to receive unreduced benefits, it is gradually increasing to age 67 by 2027. Public servants are often not covered by Social Security but have their own pension programs. Police officers in the United States may typically retire at half pay after 20 years of service, or three-quarter pay after 30 years, allowing retirement from the early forties. Military members of the US Armed Forces may elect to retire after 20 years of active duty. Their retirement pay (not a pension since they can be recalled to active duty at any time) is calculated on number of years on active duty, final pay grade and the retirement system in place when they entered service. Members awarded the Medal of Honor qualify for a separate stipend. Retirement pay for military members in the reserve and US National Guard is based on a point system. 

Recent advances in data collection have vastly improved our ability to understand important relationships between retirement and factors such as health, wealth, employment characteristics and family dynamics, among others. The most prominent study for examining retirement behavior in the United States is the ongoing Health and Retirement Study (HRS), first fielded in 1992. The HRS is a nationally representative longitudinal survey of adults in the U.S. ages 51+, conducted every two years, and contains a wealth of information on such topics as labor force participation (e.g., current employment, job history, retirement plans, industry/occupation, pensions, disability), health (e.g., health status and history, health and life insurance, cognition), financial variables (e.g., assets and income, housing, net worth, wills, consumption and savings), family characteristics (e.g., family structure, transfers, parent/child/grandchild/sibling information) and a host of other topics (e.g., expectations, expenses, internet use, risk taking, psychosocial, time use).

2002 and 2004 saw the introductions of the English Longitudinal Study of Ageing (ELSA) and the Survey of Health, Ageing and Retirement in Europe (SHARE), which includes respondents from 14 continental European countries plus Israel. These surveys were closely modeled after the HRS in sample frame, design and content. A number of other countries (e.g., Japan, South Korea) also now field HRS-like surveys, and others (e.g., China, India) are currently fielding pilot studies. These data sets have expanded the ability of researchers to examine questions about retirement behavior by adding a cross-national perspective.
Notes: MHAS discontinued in 2003; ELSA numbers exclude institutionalized (nursing homes). Source: Borsch-Supan et al., eds. (November 2008). Health, Ageing and Retirement in Europe (2004–2007): Starting the Longitudinal Dimension.

Many factors affect people's retirement decisions. Retirement funding education is a big factor that affects the success of an individual's retirement experience. Social Security clearly plays an important role because most individuals solely rely on Social Security as their only retirement option, when Social Security's both trust funds are expected to be depleted by 2034. Knowledge affects an individual's retirement decisions by simply finding more reliable retirement options such as, Individual Retirement Accounts or Employer-Sponsored Plans. In countries around the world, people are much more likely to retire at the early and normal retirement ages of the public pension system (e.g., ages 62 and 65 in the U.S.). This pattern cannot be explained by different financial incentives to retire at these ages since typically retirement benefits at these ages are approximately actuarially fair; that is, the present value of lifetime pension benefits (pension wealth) conditional on retiring at age "a" is approximately the same as pension wealth conditional on retiring one year later at age "a"+1. Nevertheless, a large literature has found that individuals respond significantly to financial incentives relating to retirement (e.g., to discontinuities stemming from the Social Security earnings test or the tax system).

Greater wealth tends to lead to earlier retirement, since wealthier individuals can essentially "purchase" additional leisure. Generally the effect of wealth on retirement is difficult to estimate empirically since observing greater wealth at older ages may be the result of increased saving over the working life in anticipation of earlier retirement. However, a number of economists have found creative ways to estimate wealth effects on retirement and typically find that they are small. For example, one paper exploits the receipt of an inheritance to measure the effect of wealth shocks on retirement using data from the HRS. The authors find that receiving an inheritance increases the probability of retiring earlier than expected by 4.4 percentage points, or 12 percent relative to the baseline retirement rate, over an eight-year period.

A great deal of attention has surrounded how the Financial crisis of 2007–2008 and subsequent Great Recession are affecting retirement decisions, with the conventional wisdom saying that fewer people will retire since their savings have been depleted; however recent research suggests that the opposite may happen. Using data from the HRS, researchers examined trends in defined benefit (DB) vs. defined contribution (DC) pension plans and found that those nearing retirement had only limited exposure to the recent stock market decline and thus are not likely to substantially delay their retirement. At the same time, using data from the Current Population Survey (CPS), another study estimates that mass layoffs are likely to lead to an increase in retirement almost 50% larger than the decrease brought about by the stock market crash, so that on net retirements are likely to increase in response to the crisis.

More information tells of how many who retire will continue to work, but not in the career they have had for the majority of their life. Job openings will increase in the next 5 years due to retirements of the baby boomer generation. The Over 50 population is actually the fastest growing labor groups in the US.

A great deal of research has examined the effects of health status and health shocks on retirement. It is widely found that individuals in poor health generally retire earlier than those in better health. This does not necessarily imply that poor health status leads people to retire earlier, since in surveys retirees may be more likely to exaggerate their poor health status to justify their earlier decision to retire. This justification bias, however, is likely to be small. In general, declining health over time, as well as the onset of new health conditions, have been found to be positively related to earlier retirement. Health conditions that can cause someone to retire include hypertension, diabetes mellitus, sleep apnea, joint diseases, and hyperlipidemia.

Most people are married when they reach retirement age; thus, spouse's employment status may affect one's decision to retire. On average, husbands are three years older than their wives in the U.S., and spouses often coordinate their retirement decisions. Thus, men are more likely to retire if their wives are also retired than if they are still in the labor force, and vice versa.

Researchers analyzed factors affecting retirement decisions in EU Member States:



Overall, income after retirement can come from state pensions, occupational pensions, private savings and investments (private pension funds, owned housing), donations (e.g., by children), and social benefits. In some countries an additional lump sum is granted, according to the years of work and the average pay; this is usually provided by the employer. On a personal level, the rising cost of living during retirement is a serious concern to many older adults. Health care costs play an important role.

Provision of state pensions is a significant drain on a government's budget. As life expectancy increases and the health of older people improves with medical advances, the age of entitlement to a pension has been increasing progressively since about 2010.

Older people have poorer health, and the cost of health care in retirement is large. Most countries provide universal health insurance coverage for seniors, although in the United States many people retire before they become eligible for Medicare health cover at age 65.

A useful and straightforward calculation can be done if it is assumed that interest, after expenses, taxes, and inflation is zero. Assume that in real (after-inflation) terms, one's salary never changes over "w" years of working life. During "p" years of pension, one has a living standard that costs a replacement ratio "R" times as much as one's living standard in working life. The working life living standard is one's salary minus the proportion of salary Z that should be saved. Calculations are per unit salary (e.g., assume salary = 1).

Then after "w" years work, retirement age accumulated savings = "wZ". To pay for pension for "p" years, necessary savings at retirement = "Rp(1-Z)"

Equate these: "wZ" = "Rp"("1-Z") and solve to give "Z" = "Rp" / ("w + Rp"). For example, if "w" = 35, "p" = 30 and "R" = 0.65, a proportion "Z" = 35.78% should be saved.

Retirement calculators generally accumulate a proportion of salary up to retirement age. This shows a straightforward case, which nonetheless could be practically useful for optimistic people hoping to work for only as long as they are likely to be retired.

For more complicated situations, there are several online retirement calculators on the Internet. Many retirement calculators project how much an investor needs to save, and for how long, to provide a certain level of retirement expenditures. Some retirement calculators, appropriate for safe investments, assume a constant, unvarying rate of return. Monte Carlo retirement calculators take volatility into account and project the probability that a particular plan of retirement savings, investments, and expenditures will outlast the retiree. Retirement calculators vary in the extent to which they take taxes, social security, pensions, and other sources of retirement income and expenditures into account.

The assumptions keyed into a retirement calculator are critical. One of the most important assumptions is the assumed rate of real (after inflation) investment return. A conservative return estimate could be based on the real yield of Inflation-indexed bonds offered by some governments, including the United States, Canada, and the United Kingdom. The TIP$TER retirement calculator projects the retirement expenditures that a portfolio of inflation-linked bonds, coupled with other income sources like Social Security, would be able to sustain. Current real yields on United States Treasury Inflation Protected Securities (TIPS) are available at the US Treasury site. Current real yields on Canadian 'Real Return Bonds' are available at the Bank of Canada's site. As of December 2011, US Treasury inflation-linked bonds (TIPS) were yielding about 0.8% real per annum for the 30-year maturity and a noteworthy slightly negative real return for the 7-year maturity.
Many individuals use "retirement calculators" on the Internet to determine the proportion of their pay they should be saving in a tax advantaged-plan (e.g., IRA or 401-K in the US, RRSP in Canada, personal pension in the UK, superannuation in Australia).
After expenses and any taxes, a reasonable (though arguably pessimistic) long-term assumption for a safe real rate of return is zero. So in real terms, interest does not help the savings grow. Each year of work must pay its share of a year of retirement. For someone planning to work for 40 years and be retired for 20 years, each year of work pays for itself and for half a year of retirement. Hence, 33.33% of pay must be saved, and 66.67% can be spent when earned. After 40 years of saving 33.33% of pay, we have accumulated assets of 13.33 years of pay, as in the graph. In the graph to the right, the lines are straight, which is appropriate given the assumption of a zero real investment return.

The graph above can be compared with those generated by many retirement calculators. However, most retirement calculators use nominal (not "real" dollars) and therefore require a projection of both the expected inflation rate and the expected nominal rate of return. One way to work around this limitation is to, for example, enter "0% return, 0% inflation" inputs into the calculator. The Bloomberg retirement calculator gives the flexibility to specify, for example, zero inflation and zero investment return and to reproduce the graph above. The MSN retirement calculator in 2011 has as the defaults a realistic 3% per annum inflation rate and optimistic 8% return assumptions; consistency with the December 2011 US nominal bond and inflation-protected bond market rates requires a change to about 3% inflation and 4% investment return before and after retirement.

Ignoring tax, someone wishing to work for a year and then relax for a year on the same living standard needs to save 50% of pay. Similarly, someone wishing to work from age 25 to 55 and be retired for 30 years till 85 needs to save 50% of pay if government and employment pensions are not a factor and if it is considered appropriate to assume a zero real investment return. The problem that the lifespan is not known in advance can be reduced in some countries by the purchase at retirement of an inflation-indexed life annuity.

To pay for pension, assumed for simplicity to be received at the end of each year, and taking discounted values in the manner of a net present value calculation, the ideal lump sum available at retirement should be:

Above is the standard mathematical formula for the sum of a geometric series. (Or if i =0 then the series in braces sums to p since it then has p equal terms). As an example, assume that S=60,000 per year and that it is desired to replace R=0.80, or 80%, of pre-retirement living standard for p=30 years. Assume for current purposes that a proportion z =0.25 (25%) of pay was being saved. Using i=0.02, or 2% per year real return on investments, the necessary lump sum is given by the formula as (1-0.25)*0.80*60,000*annuity-series-sum(30)=36,000*22.396=806,272 in the nation's currency in 2008–2010 terms. To allow for inflation in a straightforward way, it is best to talk of the 806,272 as being '13.43 years of retirement age salary'. It may be appropriate to regard this as being the necessary lump sum to fund 36,000 of annual supplements to any employer or government pensions that are available. It is common to not include any house value in the calculation of this necessary lump sum, so for a homeowner the lump sum pays primarily for non-housing living costs.

At retirement, the following amount will have been accumulated:

To make the accumulation match with the lump sum needed to pay pension:

Bring z to the left hand side to give the answer, under this rough and unguaranteed method, for the proportion of pay that should be saved:

Note that the special case i =0 = i means that the geometric series should be summed by noting that there are p or w identical terms and hence z = p/(w+p). This corresponds to the graph above with the straight line real-terms accumulation.

The result for the necessary z given by (Ret-03) depends critically on the assumptions made. As an example, one might assume that price inflation will be 3.5% per year forever and that one's pay will increase only at that same rate of 3.5%. If a 4.5% per year nominal rate of interest is assumed, then (using 1.045/1.035 in real terms) pre-retirement and post-retirement net interest rates will remain the same, i = 0.966 percent per year and i = 0.966 percent per year. These assumptions may be reasonable in view of the market returns available on inflation-indexed bonds, after expenses and any tax. Equation (Ret-03) is readily coded in Excel and with these assumptions gives the required savings rates in the accompanying picture.

Finally, a newer method for determining the adequacy of a retirement plan is Monte Carlo simulation. This method has been gaining popularity and is now employed by many financial planners. Monte Carlo retirement calculators allow users to enter savings, income and expense information and run simulations of retirement scenarios. The simulation results show the probability that the retirement plan will be successful.

Retirement is generally considered to be "early" if it occurs before the age (or tenure) needed for eligibility for support and funds from government or employer-provided sources. Early retirees typically rely on their own savings and investments to be self-supporting, either indefinitely or until they begin receiving external support. Early retirement can also be used as a euphemistic term for being terminated from employment before typical retirement age.

While conventional wisdom has it that one can retire and take 7% or more out of a portfolio year after year, this strategy would not have worked very often in the past.

The chart at the right shows the year-to-year portfolio balances after taking $35,000 (and adjusting for inflation) from a $750,000 portfolio every year for 30 years, starting in 1973 (red line), 1974 (blue line), or 1975 (green line). While the overall market conditions and inflation affected all three about the same (since all three experienced exactly the same conditions between 1975 and 2003), the chance of making the funds last for 30 years depended heavily on what happened to the stock market in the first few years.

Those contemplating early retirement will want to know if they have enough to survive possible bear markets such as the one that would cause the hypothetical 1973 retiree's fund to be exhausted after only 20 years.

The history of the US stock market shows that one would need to live on about 4% of the initial portfolio per year to ensure that the portfolio is not depleted before the end of the retirement; this rule of thumb is a summary of one conclusion of the Trinity study, though the report is more nuanced and the conclusions and very approach have been heavily criticized (see Trinity study for details). This allows for increasing the withdrawals with inflation to maintain a consistent spending ability throughout the retirement, and to continue making withdrawals even in dramatic and prolonged bear markets. (The 4% figure does not assume any pension or change in spending levels throughout the retirement.)

When retiring prior to age , there is a 10% IRS penalty on withdrawals from a retirement plan such as a 401(k) plan or a Traditional IRA. Exceptions apply under certain circumstances. At age 59 and six months, the penalty-free status is achieved and the 10% IRS penalty no longer applies.

To avoid the 10% penalty prior to age , a person should consult a lawyer about the use of IRS rule 72 T. This rule must be applied for with the IRS. It allows the distribution of an IRA account prior to age in equal amounts of a period of either 5 years or until the age of , whichever is the longest time period, without a 10% penalty. Taxes still must be paid on the distributions.

Although the 4% initial portfolio withdrawal rate described above can be used as a rough gauge, it is often desirable to use a retirement planning tool that accepts detailed input and can render a result that has more precision. Some of these tools model only the retirement phase of the plan while others can model both the savings or accumulation phase as well as the retirement phase of the plan. For example, an analysis by "Forbes" reckoned that in 90% of historical markets, a 4% rate would have lasted for at least 30 years, while in 50% of the historical markets, a 4% rate would have been sustained for more than 40 years.

The effects of making inflation-adjusted withdrawals from a given starting portfolio can be modeled with a downloadable spreadsheet that uses historical stock market data to estimate likely portfolio returns. Another approach is to employ a retirement calculator that also uses historical stock market modeling, but adds provisions for incorporating pensions, other retirement income, and changes in spending that may occur during the course of the retirement.

Retirement might coincide with important life changes; a retired worker might move to a new location, for example a retirement community, thereby having less frequent contact with their previous social context and adopting a new lifestyle. Often retirees volunteer for charities and other community organizations. Tourism is a common marker of retirement and for some becomes a way of life, such as for so-called grey nomads. Some retired people even choose to go and live in warmer climates in what is known as retirement migration.

It has been found that Americans have six lifestyle choices as they age: continuing to work full-time, continuing to work part-time, retiring from work and becoming engaged in a variety of leisure activities, retiring from work and becoming involved in a variety of recreational and leisure activities, retiring from work and later returning to work part-time, and retiring from work and later returning to work full-time. An important note to make from these lifestyle definitions are that four of the six involve working. America is facing an important demographic change in that the Baby Boomer generation is now reaching retirement age. This poses two challenges: whether there will be a sufficient number of skilled workers in the work force, and whether the current pension programs will be sufficient to support the growing number of retired people. The reasons that some people choose to never retire, or to return to work after retiring include not only the difficulty of planning for retirement but also wages and fringe benefits, expenditure of physical and mental energy, production of goods and services, social interaction, and social status may interact to influence an individual's work force participation decision.

Often retirees are called upon to care for grandchildren and occasionally aged parents. For many it gives them more time to devote to a hobby or sport such as golf or sailing. On the other hand, many retirees feel restless and suffer from depression as a result of their new situation. Although it is not scientifically possible to directly show that retirement either causes or contributes to depression, the newly retired are one of the most vulnerable societal groups when it comes to depression most likely due to confluence of increasing age and deteriorating health status. Retirement coincides with deterioration of one's health that correlates with increasing age and this likely plays a major role in increased rates of depression in retirees. Longitudinal and cross-sectional studies have shown that healthy elderly and retired people are as happy or happier and have an equal quality of life as they age as compared to younger employed adults, therefore retirement in and of itself is not likely to contribute to development of depression.

Many people in the later years of their lives, due to failing health, require assistance, sometimes in extremely expensive treatments – in some countries – being provided in a nursing home. Those who need care, but are not in need of constant assistance, may choose to live in a retirement home.






</doc>
<doc id="26501" url="https://en.wikipedia.org/wiki?curid=26501" title="Boeing RC-135">
Boeing RC-135

The Boeing RC-135 is a family of large reconnaissance aircraft built by Boeing and modified by a number of companies, including General Dynamics, Lockheed, LTV, E-Systems, and L3 Technologies, and used by the United States Air Force and Royal Air Force to support theater and national level intelligence consumers with near real-time on-scene collection, analysis and dissemination capabilities. Based on the C-135 Stratolifter airframe, various types of RC-135s have been in service since 1961. Unlike the C-135 and KC-135 which are recognized by Boeing as the Model 717, most of the current RC-135 fleet (with the exception of the RAF's RC-135Ws) is internally designated as the Model 739 by the company. Many variants have been modified numerous times, resulting in a large variety of designations, configurations, and program names.

The first RC-135 variant, the RC-135A, was ordered in 1962 by the United States Air Force to replace the Boeing RB-50 Superfortress. Originally nine were ordered but this was later reduced to four. Boeing allocated the variant the designation "Boeing 739-700" but they were a modified variant of the KC-135A then in production. They used the same Pratt & Whitney J57 turbojet engines as the tanker, but carried cameras in a bay just aft of the nose wheel well where the forward fuel tank was normally located. They had no in-flight refueling system and they were to be used for photographic and surveying tasks. Although the RC-135A was the first designation in the RC-135 family, it was not the first RC-135 in service. That distinction belongs to the RC-135S, which began operational reconnaissance missions in 1961, followed by the RC-135D in 1962.

The next variant ordered was the RC-135B, to be used as an electronic intelligence aircraft to replace the Boeing RB-47H Stratojet, a SIGINT platform. Unlike the earlier variants, the RC-135Bs had Pratt & Whitney TF33 turbofans rather than the older J57s. These ten aircraft were delivered directly to Martin Aircraft beginning in 1965 for installation of their operational electronics suite. By 1967, they emerged as RC-135Cs and all entered service that year. The refueling boom was not fitted and the boom operator station was used as a camera bay for a KA-59 camera. Externally, the aircraft were distinguished by the large “cheek” antenna fairings on the forward fuselage.

The RC-135Bs were the last of the new aircraft built. All further reconnaissance variants that followed were modified aircraft, either from earlier RC-135 variants or from tankers and transports.

In 2005, the RC-135 fleet completed a series of significant airframe, navigation and powerplant upgrades which include re-engining from the TF33 to the CFM International CFM-56 (F108) engines used on the KC-135R and T Stratotanker and upgrade of the flight deck instrumentation and navigation systems to the AMP standard. The AMP standard includes conversion from analog readouts to a digital "glass cockpit" configuration.

The current RC-135 fleet is the latest iteration of modifications to this pool of aircraft dating back to the early 1960s. Initially employed by Strategic Air Command for reconnaissance, the RC-135 fleet has participated in every armed conflict involving U.S. forces during its tenure. RC-135s supported operations in Vietnam War, the Mediterranean for Operation El Dorado Canyon, Grenada for Operation Urgent Fury, Panama for Operation Just Cause, the Balkans for Operations Deliberate Force and Allied Force, and Southwest Asia for Operations Desert Shield, Desert Storm, Enduring Freedom and Iraqi Freedom. RC-135s have maintained a constant presence in Southwest Asia since the early 1990s. They were stalwarts of Cold War operations, with missions flown around the periphery of the USSR and its client states in Europe and around the world.

Originally, all RC-135s were operated by Strategic Air Command. Since 1992 they have been assigned to Air Combat Command. The RC-135 fleet is permanently based at Offutt Air Force Base, Nebraska and operated by the 55th Wing, using forward operating locations worldwide. The 55th Wing operates 22 platforms in three variants: three RC-135S Cobra Ball, two RC-135U Combat Sent, and 17 RC-135V/W Rivet Joint.

On August 9, 2010, the Rivet Joint program recognized its 20th anniversary of continuous service in Central Command, dating back to the beginning of Desert Shield. This represents the longest unbroken presence of any aircraft in the Air Force inventory. During this time it has flown over 8,000 combat missions supporting air and ground forces of Operations Desert Storm, Desert Shield, Northern Watch, Southern Watch, Iraqi Freedom and Enduring Freedom, which continues to this day.

On 22 March 2010 the British Ministry of Defence announced that it had reached agreement with the US Government to purchase three RC-135W Rivet Joint aircraft to replace the Nimrod R1, which was subsequently retired in June 2011. The aircraft, to be styled as 'Airseeker', were scheduled to be delivered by 2017 at a total cost of around £650 million, including provision of ground infrastructure, training of personnel and ground supporting systems. In 2013, the UK government confirmed that crews from the RAF's 51 Squadron had been training and operating alongside their USAF colleagues since 2011, having achieved in excess of 32,000 flying hours and 1,800 sorties as part of the 55th Wing at Offutt AFB. The RAF received the first RC-135W in September 2013, which was deployed from July 2014 to support coalition action against combat Islamic State of Iraq and the Levant militants in Iraq. The second aircraft was delivered seven months ahead of schedule in September 2015, with over sixty improvements incorporated ranging from upgrades to the aircraft's mission systems to engine improvements providing increased fuel efficiency and durability. In due course, the first Airseeker will receive the same upgrades. The aircraft will be air-to-air refuelled in service by USAF tankers based in Europe, as the UK does not operate boom-equipped refueling aircraft and has no plans to adapt drogue-equipped aircraft.

At least four KC-135A tankers were converted into makeshift reconnaissance platforms with no change of Mission Design Series (MDS) designation. KC-135As 55–3121, 55–3127, 59–1465, and 59-1514 were modified beginning in 1961. That year the Soviet Union announced its intention to detonate a 100 megaton thermonuclear device on Novaya Zemlya, the so-called Tsar Bomba. A testbed KC-135A (55-3127) was modified under the Big Safari program to the SPEED LIGHT BRAVO configuration in order to obtain intelligence information on the test. The success of the mission prompted conversion of additional aircraft for intelligence gathering duties.

Not to be confused with the CFM F108-powered KC-135R tanker, the KC-135R MDS was applied in 1963 to the three KC-135A reconnaissance aircraft under the Rivet Stand program. The three aircraft were 55–3121, 59–1465, and 59–1514; a fourth, serial no. 58–0126, was converted in 1969 to replace 1465 which had crashed in 1967. Externally the aircraft had varied configurations throughout their careers, but generally they were distinguished by five "towel bar" antennas along the spine of the upper fuselage and a radome below the forward fuselage. The first three aircraft retained the standard tanker nose radome, while 58-0126 was fitted with the 'hog nose' radome commonly associated with an RC-135. A trapeze-like structure in place of the refueling boom which was used to trail an aerodynamic shape housing a specialized receiver array (colloquially known as a "blivet") on a wire was installed. This was reported to be used for "Briar Patch" and "Combat Lion" missions. There were four small optically flat windows on each side of the forward fuselage. On some missions a small wing-like structure housing sensors was fitted to each side of the forward fuselage, with a diagonal brace below it. With the loss of 59–1465, KC-135A 58-0126 was modified to this standard under the Rivet Quick operational name. All four aircraft have now been lost or converted to KC-135R tanker configuration. They are among the few KC-135 tankers equipped with an aerial refueling receptacle above the cockpit, a remnant of their service as intelligence gathering platforms.

KC-135R 55-3121 was modified in 1969 by Lockheed Air Services to the unique KC-135T configuration under the Cobra Jaw program name. Externally distinguished by the 'hog nose' radome, the aircraft also featured spinning "fang" receiver antennas below the nose radome, a large blade antenna above the forward fuselage, a single 'towel bar' antenna on the spine, teardrop antennas forward of the horizontal stabilizers on each side, and the trapeze-like structure in place of the refueling boom. The aircraft briefly carried nose art consisting of the Ford Cobra Jet cartoon cobra. It was later modified into an RC-135T Rivet Dandy.

Four RC-135As (63-8058 through 8061) were photo mapping platforms utilized briefly by the Air Photographic & Charting Service, based at Turner Air Force Base, Georgia and later at Forbes Air Force Base, Kansas as part of the 1370th Photographic Mapping Wing. The mission was soon assumed by satellites, and the RC-135As were de-modified and used in various other roles, such as staff transport and crew training. In the early 1980s they were further converted to tankers with the designation KC-135D (of the same basic configuration as the KC-135A and later E, plus some remaining special mission equipment). Due to delays in reinstalling their original equipment, the RC-135As were the last of the entire C-135 series delivered to the USAF. The Boeing model number for the RC-135A is 739–700.

The as-delivered version of the RC-135. The RC-135B was never used operationally, as it had no mission equipment installed by Boeing. The entire RC-135B production run of ten aircraft was delivered directly to Martin Aircraft in Baltimore, Maryland for modification and installation of mission equipment under the Big Safari program. Upon completion, the RC-135Bs were re-designated RC-135C. The Boeing model number for the RC-135B is 739-445B.

Modified and re-designated RC-135B aircraft used for strategic reconnaissance duties, equipped with the AN/ASD-1 electronic intelligence (ELINT) system. This system was characterized by the large 'cheek' pods on the forward fuselage containing the Automated ELINT Emitter Locating System (AEELS – not Side Looking Airborne Radar – SLAR, as often quoted), as well as numerous other antennae and a camera position in the refuelling pod area of the aft fuselage. The aircraft was crewed by two pilots, two navigators, numerous intelligence gathering specialists, inflight maintenance technicians and airborne linguists. When the RC-135C was fully deployed, SAC was able to retire its fleet of RB-47H Stratojets from active reconnaissance duties. All ten continue in active service as either RC-135V Rivet Joint or RC-135U Combat Sent platforms.

The RC-135Ds, originally designated KC-135A-II, were the first reconnaissance configured C-135s given the "R" MDS designation, although they were not the first reconnaissance-tasked members of the C-135 family. They were delivered to Eielson Air Force Base, Alaska in 1962 as part of the Office Boy Project. Serial numbers were 60–0356, 60–0357, and 60–0362. The aircraft began operational missions in 1963. These three aircraft were ordered as KC-135A tankers, but delivered without refueling booms, and known as "falsie C-135As" pending the delivery of the first actual C-135A cargo aircraft in 1961. The primary Rivet Brass mission flew along the northern border of the Soviet Union, often as a shuttle mission between Eielson and RAF Upper Heyford, Oxfordshire, and later RAF Mildenhall, Suffolk, UK. The RC-135D was also used in Southeast Asia during periods when the RC-135M (see below) was unavailable. In the late 1970s, with the expansion of the RC-135 fleet powered by TF33 turbofan engines, the RC-135Ds were converted into tankers, and remain in service as receiver-capable KC-135Rs.

Originally designated C-135B-II, project name Lisa Ann, the RC-135E Rivet Amber was a one-of-a-kind aircraft equipped with a large 7 MW Hughes Aircraft phased-array radar system. Originally delivered as a C-135B, 62-4137 operated from Shemya Air Force Station, Alaska from 1966 to 1969. Its operations were performed in concert with the RC-135S Rivet Ball aircraft (see below). The radar system alone weighed over 35,000 pounds and cost over US$35 million (1960 dollars), making Rivet Amber both the heaviest C-135-derivative aircraft flying and the most expensive Air Force aircraft for its time. This prevented the forward and aft crew areas from having direct contact after boarding the aircraft. The system could track an object the size of a soccer ball from a distance of , and its mission was to monitor Soviet ballistic missile testing in the reentry phase. The power requirement for the phased array radar was enormous, necessitating an additional power supply. This took the form of a podded Lycoming T55-L5 turboshaft engine in a pod under the left inboard wing section, driving a 350kVA generator dedicated to powering mission equipment. On the opposite wing in the same location was a podded heat exchanger to permit cooling of the massive electronic components on board the aircraft. This configuration has led to the mistaken impression that the aircraft had six engines. On June 5, 1969, Rivet Amber was lost at sea on a ferry flight from Shemya to Eielson AFB for maintenance, and no trace of the aircraft or its crew was ever found.

The RC-135M was an interim type with more limited ELINT capability than the RC-135C but with extensive additional COMINT capability. They were converted from Military Airlift Command C-135B transports, and operated by the 82d Reconnaissance Squadron during the Vietnam War from Kadena AB, gathering signals intelligence over the Gulf of Tonkin and Laos with the program name Combat Apple (originally Burning Candy). There were six RC-135M aircraft, 62–4131, 62–4132, 62–4134, 62–4135, 62-4138 and 62–4139, all of which were later modified to and continue in active service as RC-135W Rivet Joints by the early 1980s.

Rivet Ball was the predecessor program to Cobra Ball and was initiated with a single RC-135S (serial 59–1491, formerly a JKC-135A) on December 31, 1961. The aircraft first operated under the Nancy Rae project as an asset of Air Force Systems Command and later as an RC-135S reconnaissance platform with Strategic Air Command under project Wanda Belle. The name Rivet Ball was assigned in January 1967. The aircraft operated from Shemya AFB, Alaska. Along with most other RC-135 variants, the RC-135S had an elongated nose radome housing an S band receiving antenna. The aircraft was characterized by ten large optically flat quartz windows on the right side of the fuselage used for tracking cameras. Unlike any other RC-135S, Rivet Ball also had a plexiglass dome mounted top center on its fuselage for the Manual Tracker position. It holds the distinction of obtaining the very first photographic documentation of Soviet Multiple Reentry vehicle (MRV) testing on October 4, 1968. On January 13, 1969 Rivet Ball was destroyed in a landing accident at Shemya when it overran the runway with no fatalities.

The RC-135S Cobra Ball is a measurement and signature intelligence MASINT collector equipped with special electro-optical instruments designed to observe ballistic missile flights at long range. The Cobra Ball monitors missile-associated signals and tracks missiles during boost and re-entry phases to provide reconnaissance for treaty verification and theater ballistic missile proliferation. The aircraft are extensively modified C-135Bs. The right wing and engines are traditionally painted black to reduce sun glare for tracking cameras.

There are three aircraft in service and they are part of the 55th Wing, 45th Reconnaissance Squadron based at Offutt Air Force Base, Nebraska. Cobra Ball aircraft were originally assigned to Shemya and used to observe ballistic missile tests on the Kamchatka peninsula in conjunction with Cobra Dane and Cobra Judy. Two aircraft were converted for Cobra Ball in 1969 and following the loss of an aircraft in 1981 another aircraft was converted in 1983. The sole RC-135X was also converted into an RC-135S in 1995 to supplement the other aircraft.

KC-135T 55-3121 was modified to RC-135T Rivet Dandy configuration in 1971. It was used to supplement the RC-135C/D/M fleet, then in short supply due to ongoing upgrades requiring airframes to be out of service. It operated under the Burning Candy operational order. In 1973 the aircraft's SIGINT gear was removed and transferred to KC-135R 58–0126, resulting in 55-3121 assuming the role of trainer, a role which it fulfilled for the remainder of its operational existence. Externally the aircraft retained the 'hog nose' radome and some other external modifications, but the aerial refueling boom and trapeze below the tail were removed, and it had no operational reconnaissance role. In this configuration it operated variously with the 376th Strategic Wing at Kadena AB, Okinawa, the 305th AREFW at Grissom AFB, Indiana, and the 6th Strategic Wing at Eielson AFB, Alaska. In 1982 the aircraft was modified with Pratt & Whitney TF33-PW102 engines and other modifications common to the KC-135E tanker program, and returned to Eielson AFB. It crashed while on approach to Valdez Airport, Alaska on 25 February 1985 with the loss of three crew members. The wreckage was not found until August 1985, six months after the accident.

The RC-135U Combat Sent is designed to collect technical intelligence on adversary radar emitter systems. Combat Sent data is collected to develop new or upgraded radar warning receivers, radar jammers, decoys, anti-radiation missiles, and training simulators.

Distinctly identified by the antenna arrays on the fuselage chin, tailcone, and wing tips, three RC-135C aircraft were converted to RC-135U (63-9792, 64–14847, & 64-14849) in the early 1970s. 63-9792 was later converted into a Rivet Joint in 1978, and all aircraft remain in service based at Offutt Air Force Base, Nebraska. Minimum crew requirements are 2 pilots, 2 navigators, 3 systems engineers, 10 electronic warfare officers, and 6 area specialists.

The RC-135V/W is the USAF's standard airborne SIGINT platform. Missions flown by the RC-135s are designated either Burning Wind or Misty Wind. Its sensor suite allows the mission crew to detect, identify and geolocate signals throughout the electromagnetic spectrum. The mission crew can then forward gathered information in a variety of formats to a wide range of consumers via Rivet Joint's extensive communications suite. The crew consists of the cockpit crew, electronic warfare officers, intelligence operators, and airborne systems maintenance personnel. All Rivet Joint airframe and mission systems modifications are performed by L-3 Communications in Greenville, Texas, under the oversight of the Air Force Materiel Command.

All RC-135s are assigned to Air Combat Command. The RC-135 is permanently based at Offutt Air Force Base, Nebraska, and operated by the 55th Wing, using various forward deployment locations worldwide.

Under the "BIG SAFARI" program name, RC-135Vs were upgraded from the RC-135C "Big Team" configuration. RC-135Ws were originally delivered as C-135B transports, and most were modified from RC-135Ms. This is the only difference between the V and W variants; both carry the same mission equipment. For many years, the RC-135V/W could be identified by the four large disc-capped MUCELS antennas forward, four somewhat smaller blade antennae aft and myriad of smaller underside antennas. Baseline 8 Rivet Joints (in the 2000s) introduced the first major change to the external RC-135V/W configuration replacing the MUCELS antennas with plain blade antennas. The configuration of smaller underside antennas was also changed significantly.

The sole RC-135X Cobra Eye was converted during the mid-to-late-1980s from a C-135B Telemetry/Range Instrumented Aircraft, serial number 62–4128, with the mission of tracking ICBM reentry vehicles. In 1993, it was converted into an additional RC-135S Cobra Ball.

The United Kingdom bought three KC-135R aircraft for conversion to RC-135W Rivet Joint standard under the Airseeker project. Acquisition of the three aircraft was budgeted at £634m, with entry into service in October 2014. The aircraft formed No. 51 Squadron RAF, based at RAF Waddington along with the RAF's other ISTAR assets. They are expected to remain in service until 2045.

Previously, the Royal Air Force had gathered signals intelligence with three Nimrod R1 aircraft. When the time came to upgrade the maritime Nimrods to MRA4 standard, Project Helix was launched in August 2003 to study options for extending the life of the R1 out to 2025. The option of switching to Rivet Joint was added to Helix in 2008, and the retirement of the R1 became inevitable when the MRA4 was cancelled under the UK's 2010 budget cuts. The R1's involvement over Libya in Operation Ellamy delayed its retirement until June 2011.

Helix became Project Airseeker, under which three KC-135R airframes were converted to RC-135W standard by L-3 Communications. L-3 also provides ongoing maintenance and upgrades under a long-term agreement. The three airframes are former United States Air Force KC-135Rs, all of which first flew in 1964 but will be modified to the latest RC-135W standard before delivery. The three airframes on offer to the UK are the youngest KC-135s in the USAF fleet. As of September 2010 the aircraft had approximately 23,200 flying hours, 22,200 hours and 23,200 hours.

51 Sqn personnel began training at Offutt in January 2011 for conversion to the RC-135. The first RC-135W (ZZ664) was delivered ahead of schedule to the Royal Air Force on 12 November 2013, for final approval and testing by the Defence Support and Equipment team prior to its release to service from the UK MAA. The second one was once again delivered ahead of schedule on 4 September 2015 at RAF Mildenhall in Suffolk. The third was delivered in June 2017, and entered operational service in December 2017.

Three aircraft are in service for crew training, and lack fully functional mission equipment. One TC-135S (62-4133) provides training capability for the Cobra Ball mission, and is distinguishable from combat-ready aircraft by the lack of cheeks on the forward fuselage. It was converted from an EC-135B in 1985 following the crash of the former RC-135T 55–3121, which had been used as a trainer up to that point. In addition, two TC-135Ws (62-4127 and 4129) serve as training aircraft primarily for the Rivet Joint mission, but can also provide some training capability for RC-135U Combat Sent crews. They carry considerably fewer antennas than the fully equipped aircraft, but are otherwise similar in appearance to other Rivet Joint aircraft.

United States Air Force – Air Combat Command
Royal Air Force





</doc>
<doc id="26502" url="https://en.wikipedia.org/wiki?curid=26502" title="Rumiko Takahashi">
Rumiko Takahashi

Rumiko Takahashi was born in Niigata, Japan. Although she showed little interest in manga during her childhood, she was said to occasionally doodle in the margins of her papers while attending Niigata Chūō High School. Takahashi's interest in manga did not start until later. In an interview in 2000, Takahashi said that she had always wanted to become a professional comic author since she was a child. During her university years, she enrolled in Gekiga Sonjuku, a manga school founded by Kazuo Koike, author of "Crying Freeman" and "Lone Wolf and Cub". Under his guidance Takahashi began to publish her first "dōjinshi" creations in 1975, such as "Bye-Bye Road" and "Star of Futile Dust". Koike often urged his students to create well-thought out, interesting characters, and this influence would greatly impact Rumiko Takahashi's works throughout her career.

Takahashi's professional career began in 1978. Her first published work was the one-shot "Katte na Yatsura" ("Those Selfish Aliens"), which garnered her an honorable mention at that year's Shogakukan New Comics Contest. Later that same year, she began her first serialized story in "Weekly Shōnen Sunday"; "Urusei Yatsura", a comedic science fiction story. She had difficulty meeting deadlines to begin with, so chapters were published sporadically until 1980. During the run of the series, she shared a small apartment with two assistants, and often slept in a closet due to a lack of space. During the same year, she published "Time Warp Trouble", "Shake Your Buddha", and the "Golden Gods of Poverty" in "Weekly Shōnen Sunday" magazine, which would remain the home to most of her major works for the next twenty years.

During 1980, Takahashi started her second major series, "Maison Ikkoku", in "Big Comic Spirits" magazine. Written for an older audience, "Maison Ikkoku" is a romantic comedy, and Takahashi used her own experience living in an apartment complex to create the series. Takahashi managed to work on the series on and off simultaneously with "Urusei Yatsura". She concluded both series in 1987, with "Urusei Yatsura" ending at 34 volumes, and "Maison Ikkoku" at 15.

During the 1980s, Takahashi became a prolific writer of short story manga. Her stories "Laughing Target", "Maris the Chojo", and "Fire Tripper" all were adapted into original video animations (OVAs). In 1984, during the writing of "Urusei Yatsura" and "Maison Ikkoku", Takahashi took a different approach to storytelling and began the dark, macabre "Mermaid Saga". This series of short segments was published sporadically until 1994.

Another short work of Takahashi's to be published sporadically was "One-Pound Gospel". Takahashi concluded the series in 2007 after publishing chapters in 1998, 2001 and 2006. One-Pound Gospel was adapted into a live-action TV drama.

Later, in 1987, Takahashi began her third major series, "Ranma ½". Following the late 1980s and early 1990s trend of "shōnen" martial arts manga, "Ranma ½" features a gender-bending twist. The series continued for nearly a decade until 1996, when it ended at 38 volumes. "Ranma ½" and its anime adaption are cited as some of the first of their mediums to have become popular in the United States.

During the latter half of the 1990s, Rumiko Takahashi continued with short stories and her installments of "Mermaid Saga" and "One-Pound Gospel" until beginning her fourth major work, "Inuyasha". Unlike the majority of her works, "Inuyasha" has a darker tone more akin to "Mermaid Saga" and, having been serialized in "Weekly Shōnen Sunday" from 1996 to 2008, is her longest to date. On March 5, 2009, Rumiko Takahashi released her one-shot "Unmei No Tori". On March 16, 2009, she collaborated with Mitsuru Adachi, creator of "Touch" and "Cross Game", to release a one-shot called "My Sweet Sunday". Her next manga series, "Kyōkai no Rinne" started on April 22, 2009. This was Rumiko Takahashi's first new manga series since her previous manga series "Inuyasha" ended in June 2008. She concluded it on December 13th 2017, with a total of 398 chapters, collected in 40 volumes.

"Urusei Yatsura", "Maison Ikkoku", "Ranma ½","Inuyasha", and "RIN-NE" are all published in English in the United States by Viz Comics. Their 1989 release of "Urusei Yatsura" halted after only a few volumes were translated, but began to be reprinted in 2019 in a 2-in-1 omnibus format.

Rumiko Takahashi started a new manga series entitled "MAO" in "Weekly Shōnen Sunday" issue #23 released on May 8, 2019.

In 1981, "Urusei Yatsura" became the first of Takahashi's works to be animated. This series first aired on Japanese television on October 14, and went through multiple director changes during its run. Though the 195-episode TV series ended in March 1986, "Urusei Yatsura" was kept alive in anime form through OVA and movie releases through 1991. Most notable of the series directors was Mamoru Oshii, who made "Beautiful Dreamer", the second "Urusei Yatsura" movie. AnimEigo has released the entire TV series and all of the OVAs and movies except for "Beautiful Dreamer" (which was released by Central Park Media in the U.S.) in the United States in English-subtitled format, with English dubs also made for the first two TV episodes (as "Those Obnoxious Aliens") and for all of the movies.

Kitty Films, the studio that produced "Urusei Yatsura" with animation assistance from Studio Pierrot and then Studio Deen, continued their cooperation and adapted Rumiko Takahashi's second work, "Maison Ikkoku" in 1986; it debuted the week after the final TV episode of "UY". The TV series ran for 96 episodes, 3 OVAs, a movie and also a live-action movie. Studio Deen also provided animation duties on "Maison Ikkoku" and "Ranma".

"Maris the Chojo", "Fire Tripper", and "Laughing Target" were all made into OVAs during the mid-80s. Her stories "Mermaid's Forest" and "Mermaid's Scar" were also made as OVAs in Japan on 1991. They were all released, subtitled in English, in the U.S.

In 1989, Kitty Animation produced its last major series, "Ranma ½". The series went through ups and downs in ratings until Kitty Animation finally went out of business. "Ranma ½" was never concluded in animated form despite being 161 episodes and two movies in length. The TV series ended in 1992 amid internal turmoil within Kitty; Kitty and Studio Deen continued to produce "Ranma" OVAs until 1996.

Sunrise was the first studio after Kitty Animation to adapt a major Rumiko Takahashi series. "Inuyasha" debuted in 2000 and ended in 2004. The TV series went on for 167 episodes and spawned four major films. The first anime ended before the manga did, thus wrapping up inconclusively. However, a second Inuyasha anime series called "Inuyasha the Final Act" debuted in Japan in the fall of 2009 and ended in March 2010, finishing the series.

Viz Communications has released the anime of "Maison Ikkoku", "Ranma" and "Inuyasha" in English, in both subtitled and dubbed formats.

The year 2008 marked the 50th anniversary of "Weekly Shōnen Sunday" and the 30th anniversary of the first publication of "Urusei Yatsura", and Rumiko Takahashi's manga work was honoured in "It's a Rumic World", a special exhibition held from July 30 to August 11 at the Matsuya Ginza department store in Tokyo. Several new pieces of animation accompanied the exhibit, including new half-hour "Ranma ½" and "Inuyasha" ("Black Tetsusaiga") OVAs and an introductory sequence featuring characters from "Urusei Yatsura", "Ranma" and "Inuyasha" (starring the characters' original anime voice talents), which has become a popular video on YouTube. The "It's a Rumic World" exhibit was scheduled to re-open in Sendai in December 2008, at which time a new half-hour "Urusei Yatsura" OVA was scheduled to premiere. A special DVD release containing all three new OVAs was announced as coming out on January 29, 2010, with a trailer posted in September 2009. However, it is not known whether any of the new episodes will ever be released outside Japan.

"Rumiko Takahashi Anthology", animated by TMS Entertainment adapts many of her short stories from the 80s. It features her stories "The Tragedy of P", "The Merchant of Romance", "Middle-Aged Teen", "Hidden in the Pottery", "Aberrant Family F", "As Long As You Are Here", "One Hundred Years of Love", "In Lieu of Thanks", "Living Room Lovesong", "House of Garbage", "One Day Dream", "Extra-Large Size Happiness", and "The Executive's Dog". Also, a TV series of "Mermaid Saga" was produced in 2003, animating 8 of her stories.

Many of Takahashi's works have been translated into English, as well as other European languages. Takahashi said that she did not know why her works are relatively popular with English speakers. Takahashi said "Sure, there are cultural differences in my work. When I see an American comedy, even though the jokes are translated, there's always a moment when I feel puzzled and think, 'Ah, Americans would probably laugh at this more'. I suppose the same thing must happen with my books. It's inevitable. And yet, that doesn't mean my books can't be enjoyed by English-speaking readers. I feel confident that there's enough substance to them that people from a variety of cultural backgrounds can have a lot of fun reading them."

Artists that have cited Takahashi and her work as an influence include Canadian Bryan Lee O'Malley on his series "Scott Pilgrim", American Colleen Coover on her erotic series "Small Favors", Japanese Chihiro Tamaki on her manga "Walkin' Butterfly", Chinese-Australian Queenie Chan, and Thai Wisut Ponnimit. Scottish rock band Urusei Yatsura named themselves after her first work. Matt Bozon, creator of the "Shantae" video game series, cited "Ranma ½" as a big influence on his work.

Takahashi was one of the recipients of the Inkpot Award at the 1994 San Diego Comic-Con.

In 2016, ComicsAlliance listed Takahashi as one of twelve women cartoonists deserving of lifetime achievement recognition, stating that "Any one of her projects would be the career highlight of another talent." In 2017, Takahashi was inducted into the Science Fiction and Fantasy Hall of Fame as part of the 2016 class.

In July 2018, Takahashi was inducted into the Eisner Hall of Fame. She was previously nominated for entry in 2014, 2016 and 2017.

In January 2019, Takahashi won the Grand Prix de la ville d'Angoulême, becoming the second woman and second manga artist to win the award at the Angoulême International Comics Festival.



</doc>
<doc id="26509" url="https://en.wikipedia.org/wiki?curid=26509" title="Riverside">
Riverside

Riverside describes anything on the bank of or alongside a river. It may refer to:











</doc>
<doc id="26511" url="https://en.wikipedia.org/wiki?curid=26511" title="RPN">
RPN

RPN may refer to:





</doc>
<doc id="26513" url="https://en.wikipedia.org/wiki?curid=26513" title="Reverse Polish notation">
Reverse Polish notation

Reverse Polish notation (RPN), also known as Polish postfix notation or simply postfix notation, is a mathematical notation in which operators "follow" their operands, in contrast to Polish notation (PN), in which operators "precede" their operands. It does not need any parentheses as long as each operator has a fixed number of operands. The description "Polish" refers to the nationality of logician Jan Łukasiewicz, who invented Polish notation in 1924.

The reverse Polish scheme was proposed in 1954 by Arthur Burks, Don Warren, and Jesse Wright and was independently reinvented by Friedrich L. Bauer and Edsger W. Dijkstra in the early 1960s to reduce computer memory access and utilize the stack to evaluate expressions. The algorithms and notation for this scheme were extended by the Australian philosopher and computer scientist Charles L. Hamblin in the mid-1950s.

During the 1970s and 1980s, Hewlett-Packard used RPN in all of their desktop and hand-held calculators, and continued to use it in some models into the 2020s. In computer science, reverse Polish notation is used in stack-oriented programming languages such as Forth, STOIC, PostScript, RPL and Joy.

In reverse Polish notation, the operators follow their operands; for instance, to add 3 and 4, one would write rather than . If there are multiple operations, operators are given immediately after their second operands; so the expression written in conventional notation would be written in reverse Polish notation: 4 is first subtracted from 3, then 5 is added to it. An advantage of reverse Polish notation is that it removes the need for parentheses that are required by infix notation. While can also be written , that means something quite different from . In reverse Polish notation, the former could be written , which unambiguously means which reduces to (which can further be reduced to -17); the latter could be written (or , if keeping similar formatting), which unambiguously means .

In comparison testing of reverse Polish notation with algebraic notation, reverse Polish has been found to lead to faster calculations, for two reasons. The first reason is that reverse Polish calculators do not need expressions to be parenthesized, so fewer operations need to be entered to perform typical calculations. Additionally, users of reverse Polish calculators made fewer mistakes than for other types of calculators. Later research clarified that the increased speed from reverse Polish notation may be attributed to the smaller number of keystrokes needed to enter this notation, rather than to a smaller cognitive load on its users. However, anecdotal evidence suggests that reverse Polish notation is more difficult for users to learn than algebraic notation.

Edsger W. Dijkstra invented the shunting-yard algorithm to convert infix expressions to postfix expressions (reverse Polish notation), so named because its operation resembles that of a railroad shunting yard.

There are other ways of producing postfix expressions from infix expressions. Most operator-precedence parsers can be modified to produce postfix expressions; in particular, once an abstract syntax tree has been constructed, the corresponding postfix expression is given by a simple post-order traversal of that tree.

The first computers to implement architectures enabling reverse Polish notation were the English Electric Company's KDF9 machine, which was announced in 1960 and commercially available in 1963, and the Burroughs B5000, announced in 1961 and also delivered in 1963:

Presumably, the KDF9 designers draw ideas from Hamblin's GEORGE (General Order Generator), an autocode programming system written for a DEUCE computer installed at the University of Sydney, Australia, in 1957.

One of the designers of the B5000, Robert S. Barton, later wrote that he developed reverse Polish notation independently of Hamblin sometime in 1958 after reading a 1954 textbook on symbolic logic by Irving Copi, where he found a reference to Polish notation, which made him read the works of Jan Łukasiewicz as well, and before he was aware of Hamblin's work.

Friden introduced reverse Polish notation to the desktop calculator market with the EC-130, designed by Robert "Bob" Appleby Ragen, supporting a four-level stack in June 1963. The successor EC-132 added a square root function in April 1965. Around 1966, the Monroe Epic calculator supported an unnamed input scheme resembling RPN as well.

Hewlett-Packard engineers designed the 9100A Desktop Calculator in 1968 with reverse Polish notation with only three stack levels, a reverse Polish notation variant later referred to as "three-level RPN". This calculator popularized reverse Polish notation among the scientific and engineering communities. The HP-35, the world's first handheld scientific calculator, introduced the classical "four-level RPN" in 1972. HP used reverse Polish notation on every handheld calculator it sold, whether scientific, financial, or programmable, until it introduced the HP-10 adding machine calculator in 1977. By this time, HP was the leading manufacturer of calculators for professionals, including engineers and accountants.

Later calculators with LCD displays in the early 1980s, such as the HP-10C, HP-11C, HP-15C, HP-16C, and the financial HP-12C calculator also used reverse Polish notation. In 1988, Hewlett-Packard introduced a business calculator, the HP-19B, without reverse Polish notation, but its 1990 successor, the HP-19BII, gave users the option of using algebraic or reverse Polish notation.

Around 1987, HP introduced RPL, an object-oriented successor to reverse Polish notation. It deviates from classical reverse Polish notation by utilizing a stack only limited by the amount of available memory (instead of three or four fixed levels) and which can hold all kinds of data objects (including symbols, strings, lists, matrices, graphics, programs, etc.) instead of just numbers. It also changed the behaviour of the stack to no longer duplicate the top register on drops (since in an unlimited stack there is no longer a top register) and the behaviour of the key so that it no longer duplicates values into Y under certain conditions, both part of the specific ruleset of the so-called "automatic memory stack" or "operational (memory) stack" in classical reverse Polish notation in order to ease some calculations and to save keystrokes, but which had shown to also sometimes cause confusion among users not familiar with these properties. From 1990 to 2003 HP manufactured the HP-48 series of graphing RPL calculators, and in 2006 introduced the HP 50g.

As of 2011, Hewlett-Packard was offering the calculator models 12C, 12C Platinum, 17bII+, 20b, 30b, 33s, 35s, 48gII (RPL) and 50g (RPL) which support reverse Polish notation. While calculators emulating classical models continue to support classical reverse Polish notation, new reverse Polish notation models feature a variant of reverse Polish notation, where the key behaves as in RPL. This latter variant is sometimes known as "entry RPN". In 2013, the HP Prime introduced a "128-level" form of entry RPN called "advanced RPN". By late 2017, only the 12C, 12C Platinum, 17bii+, 35s and Prime remain active HP models supporting reverse Polish notation.

The community-developed calculators WP 31S and WP 34S, which are based on the HP 20b/HP 30b hardware platform, support Hewlett-Packard-style classical reverse Polish notation with either a four- or an eight-level stack. A seven-level stack had been implemented in the MITS 7400C scientific desktop calculator in 1972 and an eight-level stack was already suggested by John A. Ball in 1978.

In Britain, Clive Sinclair's Sinclair Scientific and Scientific Programmable models used reverse Polish notation.

In 1974 Commodore produced the Minuteman *6 (MM6) without key and the Minuteman *6X (MM6X) with key, both implementing a form of "two-level RPN". The SR4921 RPN came with a variant of "four-level RPN" with stack levels named X, Y, Z, and W (rather than T). In contrast to Hewlett-Packard's reverse Polish notation implementation, W filled with 0 instead of its contents being duplicated on stack drops.

Prinz and Prinztronic were own-brand trade names of the British Dixons photographic and electronic goods stores retail chain, later rebranded as Currys Digital stores, and became part of DSG International. A variety of calculator models was sold in the 1970s under the Prinztronic brand, all made for them by other companies.

Among these was the PROGRAM Programmable Scientific Calculator which featured reverse Polish notation.

The Aircraft Navigation Computer Heathkit OC-1401/OCW-1401 used "five-level RPN" in 1978.

Soviet programmable calculators (MK-52, MK-61, B3-34 and earlier B3-21 models) used reverse Polish notation for both automatic mode and programming. Modern Russian calculators MK-161 and MK-152, designed and manufactured in Novosibirsk since 2007 and offered by Semico, are backwards compatible with them. Their extended architecture is also based on reverse Polish notation.

Existing implementations using reverse Polish notation include:





</doc>
<doc id="26514" url="https://en.wikipedia.org/wiki?curid=26514" title="Roald Hoffmann">
Roald Hoffmann

Roald Hoffmann (born Roald Safran; July 18, 1937) is a Polish-American theoretical chemist who won the 1981 Nobel Prize in Chemistry. He has also published plays and poetry. He is the Frank H. T. Rhodes Professor of Humane Letters, Emeritus, at Cornell University, in Ithaca, New York.

Hoffmann was born in Złoczów, Second Polish Republic (now Zolochiv, Ukraine), to a Polish-Jewish family, and was named in honor of the Norwegian explorer Roald Amundsen. His parents were Clara (Rosen), a teacher, and Hillel Safran, a civil engineer. After Germany invaded Poland and occupied the town, his family was placed in a labor camp where his father, who was familiar with much of the local infrastructure, was a valued prisoner. As the situation grew more dangerous, with prisoners being transferred to extermination camps, the family bribed guards to allow an escape. They arranged with a Ukrainian neighbor named Mykola Dyuk for Hoffmann, his mother, two uncles and an aunt to hide in the attic and a storeroom of the local schoolhouse, where they remained for eighteen months, from January 1943 to June 1944, while Hoffmann was aged 5 to 7.

His father remained at the labor camp, but was able to occasionally visit, until he was tortured and killed by the Germans for his involvement in a plot to arm the camp prisoners. When she received the news, his mother attempted to contain her sorrow by writing down her feelings in a notebook her husband had been using to take notes on a relativity textbook he had been reading. While in hiding his mother kept Hoffmann entertained by teaching him to read and having him memorize geography from textbooks stored in the attic, then quizzing him on it. He referred to the experience as having been enveloped in a cocoon of love.

Most of the rest of the family perished in the Holocaust, though one grandmother and a few others survived. They migrated to the United States on the troop carrier "Ernie Pyle" in 1949.

Hoffmann married Eva Börjesson in 1960. They have two children, Hillel Jan and Ingrid Helena. Hoffmann visited Zolochiv with his adult son (by then a parent of a five-year-old) in 2006 and found that the attic where he had hidden was still intact, but the storeroom had been incorporated, ironically enough, into a chemistry classroom. In 2009, a monument to Holocaust victims was built in Zolochiv on Hoffmann's initiative. He is an atheist.

Hoffmann graduated in 1955 from New York City's Stuyvesant High School, where he won a Westinghouse science scholarship. He received his bachelor of arts degree at Columbia University (Columbia College) in 1958. He earned his master of arts degree in 1960 from Harvard University. He earned his doctor of philosophy degree from Harvard University while working under joint supervision of Martin Gouterman and subsequent 1976 Nobel Prize in Chemistry winner William N. Lipscomb, Jr. Hoffman worked on the molecular orbital theory of polyhedral molecules. Under Lipscomb's direction the Extended Hückel method was developed by Lawrence Lohr and by Roald Hoffmann. This method was later extended by Hoffmann. He went to Cornell in 1965 and has remained there, becoming professor emeritus.

Hoffmann's research and interests have been in the electronic structure of stable and unstable molecules, and in the study of transition states in reactions. He has investigated the structure and reactivity of both organic and inorganic molecules, and examined problems in organo-metallic and solid-state chemistry. Hoffman has developed semiempirical and nonempirical computational tools and methods such as the extended Hückel method which he proposed in 1963 for determining molecular orbitals.

With Robert Burns Woodward he developed the Woodward–Hoffmann rules for elucidating reaction mechanisms and their stereochemistry. They realized that chemical transformations could be approximately predicted from subtle symmetries and asymmetries in the electron orbitals of complex molecules. Their rules predict differing outcomes, such as the types of products that will be formed when two compounds are activated by heat compared with those produced under activation by light. For this work Hoffmann received the 1981 Nobel Prize in chemistry, sharing it with Japanese chemist Kenichi Fukui, who had independently resolved similar issues. (Woodward was not included in the prize, which is given only to living persons, although he had won the 1965 prize for other work.) In his Nobel Lecture, Hoffmann introduced the isolobal analogy for predicting the bonding properties of organometallic compounds.

Some of Hoffman's most recent work, with Neil Ashcroft and Vanessa Labet, examines bonding in matter under extreme high pressure.

In 1988 Hoffmann became the series host in a 26-program PBS education series by Annenberg/CPB, "The World of Chemistry", opposite with series demonstrator Don Showalter. While Hoffmann introduced a series of concepts and ideas, Showalter provided a series of demonstrations and other visual representations to help students and viewers to better understand the information.

Since the spring of 2001, Hoffmann has been the host of the monthly series "Entertaining Science" at New York City's Cornelia Street Cafe, which explores the juncture between the arts and science.

He has published books on the connections between art and science: "Roald Hoffmann on the Philosophy, Art, and Science of Chemistry" and "Beyond the Finite: The Sublime in Art and Science".

Hoffmann is also a writer of poetry. His collections include "The Metamict State" (1987, ), "Gaps and Verges" (1990, ), and "Chemistry Imagined", co-produced with artist Vivian Torrence.

He co-authored with Carl Djerassi the play "Oxygen", about the discovery of oxygen and the experience of being a scientist. Hoffman's play, "Should've" (2006) about ethics in science and art, has been produced in workshops, as has a play based on his experiences in the holocaust, "We Have Something That Belongs to You" (2009), later retitled "Something That Belongs to You.

In 1981, Hoffmann received the Nobel Prize in Chemistry, which he shared with Kenichi Fukui "for their theories, developed independently, concerning the course of chemical reactions".

Hoffmann has won many other awards, and is the recipient of more than 25 honorary degrees.


Hoffmann is a member of the International Academy of Quantum Molecular Science and the Board of Sponsors of The Bulletin of the Atomic Scientists.

In August 2007, the American Chemical Society held a symposium at its biannual national meeting to honor Hoffmann's 70th birthday.

In 2008, the Göttingen Academy of Sciences and Humanities awarded him its Lichtenberg Medal.

In August 2017, another symposium was held at the 254th American Chemical Society National Meeting in Washington DC, to honor Hoffmann's 80th birthday.


</doc>
<doc id="26515" url="https://en.wikipedia.org/wiki?curid=26515" title="Rhotic consonant">
Rhotic consonant

In phonetics, rhotic consonants, or "R-like" sounds, are liquid consonants that are traditionally represented orthographically by symbols derived from the Greek letter rho, including , in the Latin script and , in the Cyrillic script. They are transcribed in the International Phonetic Alphabet by upper- or lower-case variants of Roman , : , , , , , , , and .

This class of sounds is difficult to characterise phonetically; from a phonetic standpoint, there is no single articulatory correlate (manner or place) common to rhotic consonants. Rhotics have instead been found to carry out similar phonological functions or to have certain similar phonological features across different languages. Although some have been found to share certain acoustic peculiarities, such as a lowered third formant, further study has revealed that this does not hold true across different languages. For example, the acoustic quality of lowered third formants pertains almost exclusively to American varieties of English. Being "R-like" is an elusive and ambiguous concept phonetically and the same sounds that function as rhotics in some systems may pattern with fricatives, semivowels or even stops in others—for example, the alveolar tap is a rhotic consonant in many languages; but in American English it is an allophone of the stop phoneme /t/, as in "water". It is likely that rhotics, then, are not a phonetically natural class, but a phonological one instead.

Some languages have rhotic and non-rhotic varieties, which differ in the incidence of rhotic consonants. In non-rhotic accents of English, /r/ is not pronounced unless it is followed directly by a vowel.

The most typical rhotic sounds found in the world's languages are the following:


In broad transcription rhotics are usually symbolised as unless there are two or more types of rhotic in the same language; for example, most Australian Aboriginal languages, which contrast approximant and trill , use the symbols "r" and "rr" respectively. The IPA has a full set of different symbols which can be used whenever more phonetic precision is required: an "r" rotated 180° for the alveolar approximant, a small capital "R" for the uvular trill, and a flipped small capital "R" for the voiced uvular fricative or approximant.

The fact that the sounds conventionally classified as "rhotics" vary greatly in both place and manner in terms of articulation, and also in their acoustic characteristics, has led several linguists to investigate what, if anything, they have in common that justifies grouping them together. One suggestion that has been made is that each member of the class of rhotics shares certain properties with other members of the class, but not necessarily the same properties with all; in this case, rhotics have a "family resemblance" with each other rather than a strict set of shared properties. Another suggestion is that rhotics are defined by their behaviour on the sonority hierarchy, namely, that a rhotic is any sound that patterns as being more sonorous than a lateral consonant but less sonorous than a vowel. The potential for variation within the class of rhotics makes them a popular area for research in sociolinguistics.

English has rhotic and non-rhotic accents. Rhotic speakers pronounce a historical in all instances, while non-rhotic speakers only pronounce at the beginning of a syllable.

The rhotic consonant is dropped or vocalized under similar conditions in other Germanic languages, notably German, Danish and Dutch from the eastern Netherlands (because of Low German influence) and southern Sweden (possibly because of its Danish history). In most varieties of German (with the notable exception of Swiss Standard German), in the syllable coda is frequently realized as a vowel or a semivowel, or . In the traditional standard pronunciation, this happens only in the unstressed ending "-er" and after long vowels: for example "besser" , "sehr" . In common speech, the vocalization is usual after short vowels as well, and additional contractions may occur: for example "Dorn" ~ , "hart" ~ . Similarly, Danish after a vowel is, unless followed by a stressed vowel, either pronounced ("mor" "mother" , "næring" "nourishment" ) or merged with the preceding vowel while usually influencing its vowel quality ( and or are realised as long vowels and , and , and are all pronounced ) ("løber" "runner" , "Søren Kierkegaard" (personal name) ).

In Asturian, word final is always lost in infinitives if they are followed by an enclitic pronoun, and this is reflected in the writing; e.g. The infinitive form "dar" plus the 3rd plural dative pronoun "-yos" "da-yos" (give to them) or the accusative form "los" "dalos" (give them). This will happen even in southern dialects where the infinitive form will be "dare" , and both the and the vowel will drop (da-yos, not *dáre-yos). However, most of the speakers also drop the rhotics in the infinitive before a lateral consonant of a different word, and this doesn't show in the writing. e.g. "dar los dos" (give the two [things]). This doesn't occur in the middle of words. e.g. the name "Carlos" .

In some Catalan dialects, word final is lost in coda position not only in suffixes on nouns and adjectives denoting the masculine singular and plural (written as "-r", "-rs") but also in the "-"ar", -"er", -"ir"" suffixes of infinitives; e.g. "forner" "(male) baker", "forners" , "fer" "to do", "lluir" "to shine, to look good". However, rhotics are "recovered" when followed by the feminine suffix "-a" , and when infinitives have single or multiple enclitic pronouns (notice the two rhotics are neutralized in the coda, with a tap occurring between vowels, and a trill elsewhere); e.g. "fornera" "(female) baker", "fer-lo" "to do it (masc.)", "fer-ho" "to do it/that/so", "lluir-se" "to excel, to show off".

Final R is generally not pronounced in words ending in -er. The R in "parce que" (because) is not pronounced in informal speech in French.

In Indonesian, which is a form of Malay, the final is pronounced, it has varying forms of Malay spoken on the Malay Peninsula. In Indonesia, it is usually a tap version, but for some Malaysian, it is a retroflex r.

Historical final has been lost from all Khmer dialects but Northern.

In some dialects of Brazilian Portuguese, is unpronounced or aspirated. This occurs most frequently with verbs in the infinitive, which is always indicated by a word-final . In some states, however, it happens mostly with any when preceding a consonant. The "Carioca" accent (from the city of Rio de Janeiro) is notable for this.

Among the Spanish dialects, Andalusian Spanish, Caribbean Spanish (descended from and still very similar to Andalusian and Canarian Spanish), Castúo (the Spanish dialect of Extremadura), Northern Colombian Spanish (in cities like Cartagena, Montería, San Andrés and Santa Marta, but not Barranquilla, which is mostly rhotic) and the Argentine dialect spoken in the Tucumán province may have an unpronounced word-final , especially in infinitives, which mirrors the situation in some dialects of Brazilian Portuguese. However, in Antillean Caribbean forms, word-final in infinitives and non-infinitives is often in free variation with word-final and may relax to the point of being articulated as .

The native Thai rhotic is the alveolar trill. The English approximants /ɹ/ and /l/ are used interchangeably in Thai. That is, Thai speakers generally replace an English-derived R(ร) with an L(ล) and when they hear L(ล) they may write R (ร).

Among the Turkic languages, Turkish displays more or less the same feature, as syllable-final is dropped. For example, it is very common to hear phrases like "gidiyo" instead of "gidiyor", in spoken Turkish. In some parts of Turkey, e.g. Kastamonu, the syllable-final is almost never pronounced, e.g. "gidiya" instead of "gidiyor" (meaning "she/he is going"), "gide" instead of "gider" (meaning "she/he goes"). In "gide", the preceding vowel e is lengthened and pronounced somewhat between an e and a.

Among the Turkic languages, Uyghur displays more or less the same feature, as syllable-final is dropped, while the preceding vowel is lengthened: for example "Uyghurlar" ‘Uyghurs’. The may, however, sometimes be pronounced in unusually "careful" or "pedantic" speech; in such cases, it is often mistakenly inserted after long vowels even when there is no phonemic there.

Similarly in Yaqui, an indigenous language of northern Mexico, intervocalic or syllable-final is often dropped with lengthening of the previous vowel: "pariseo" becomes , "sewaro" becomes .

Lacid, whose exonyms in various literature include Lashi, Lachik, Lechi, and Leqi, is a Tibeto-Burman language spoken by the Lacid people. There are various reports of their population size ranging from 30,000 to 60,000 people. The majority are in Myanmar but there are also small groups located in China and Thailand. Noftz (2017) reports finding an example of a rhotic alveolar fricative in Lacid while doing phonological research at Payap University in Thailand in 2015. He was not able to continue his research and expressed the need for further examination of the segment to verify his results. It is postulated that the segment is a remnant of the rhotic fricative in Proto-Tibeto-Burman.

The Shekaki accent of the Kurmanji dialect of Kurdish is non-rhotic, that is the postvocalic flap "r" is not pronounced but the trill "R" is. When r is omitted, a "compensatory lengthening" of the preceding vowel takes place. For example:
Shekaki retains morphological syllables instead of phonological syllables in non-rhotic pronunciation.



</doc>
<doc id="26517" url="https://en.wikipedia.org/wiki?curid=26517" title="Richard Hell">
Richard Hell

Richard Lester Meyers (born October 2, 1949), better known by his stage name Richard Hell, is an American singer, songwriter, bass guitarist and writer.

Richard Hell was an innovator of punk music and fashion. He was one of the first to spike his hair and wear torn, cut and drawn-on shirts, often held together with safety pins.

Malcolm McLaren, manager of the Sex Pistols, credited Hell as a source of inspiration for the Sex Pistols' look and attitude, as well as the safety-pin and graphics accessorized clothing that McLaren sold in his London shop, Sex.
Hell was in several important, early punk bands, including Neon Boys, Television and The Heartbreakers, after which he formed Richard Hell & the Voidoids. Their 1977 album "Blank Generation" influenced many other punk bands. Its title track was named "One of the 500 Songs That Shaped Rock" by music writers in the Rock and Roll Hall of Fame listing and is ranked as one of the all-time Top 10 punk songs by a 2006 poll of original British punk figures, as reported in the "Rough Guide to Punk".

Since the late 1980s, Hell has devoted himself primarily to writing, publishing two novels and several other books. He was the film critic for "BlackBook" magazine from 2004 to 2006.

Richard Lester Meyers was born in Lexington, Kentucky in 1949. His father, a secular Jew, was an experimental psychologist, researching animal behavior. He died when Hell was 7 years old. Hell was then raised by his mother, who came from Methodists of Welsh and English ancestry. After her husband's death, she returned to school and became a professor.

Hell attended the Sanford School in Delaware for one year, where he became friends with Tom Miller, who later changed his name to Tom Verlaine. They ran away from school together and a short time later were arrested in Alabama for arson and vandalism.

Hell never finished high school, instead moving to New York City to make his way as a poet. In New York he met fellow young poet David Giannini, and moved to Santa Fe, New Mexico for several months, where Giannini and Meyers co-founded "Genesis:Grasp". They used an AM VariTyper with changeable fonts to publish the magazine. They began publishing books and magazines, but decided to go their separate ways in 1971, after which Hell created and published Dot Books.

Before he was 21, his own poems were published in numerous periodicals, ranging from "Rolling Stone" to the New Directions "Annual"s. In 1971, along with Verlaine, Hell also published under the pseudonym Theresa Stern, a fictional poet whose photo was actually a combination of both his and Verlaine's faces in drag, superimposed over one another to create a new identity. A book of poems credited to "Stern", "Wanna Go Out?", was released by Dot in 1973.

In 1972, Verlaine joined Hell in New York and formed the Neon Boys. In 1974, the band added a second guitarist, Richard Lloyd, and changed their name to Television.

Television's performances at CBGB helped kick-start the first wave of punk bands, inspiring a number of different artists including Patti Smith, who wrote the first press review of Television for the "SoHo Weekly News" in June 1974. She formed a highly successful band of her own, the Patti Smith Group. Television was one of the early bands to play at CBGB because their manager, Terry Ork, persuaded owner Hilly Kristal to book them alongside the Ramones. They also built the club's first stage. Hell started playing his punk rock anthem "Blank Generation" during his time in Television. In early 1975, Hell parted ways with Television after a dispute over creative control. Hell claimed that he and Verlaine had originally divided the songwriting evenly but that later Verlaine sometimes refused to play Hell's songs. Verlaine remained silent on the subject.

Hell left Television the same week that Jerry Nolan and Johnny Thunders quit the New York Dolls. In May 1975, the three of them formed the Heartbreakers (not to be confused with Tom Petty's band, which adopted the same name the following year). After one show, Walter Lure joined the Heartbreakers as a second guitarist. Four Heartbreakers demo tracks, recorded while Hell was still in the band, were later released on that band's "L.A.M.F. Definitive Edition" reissue. A live album recorded with Hell in 1975 was released as "What Goes Around..." in 1991.

In early 1976, Hell quit the Heartbreakers and started Richard Hell and the Voidoids with Robert Quine, Ivan Julian and Marc Bell. The band released two albums, though the second, "Destiny Street", retained only Quine from the original group, with Naux (Juan Maciel) on guitar and Fred Maher on drums. Hell's best known songs with the Voidoids included "Blank Generation", "Love Comes in Spurts", "The Kid With the Replaceable Head" and "Time". In 2009, the guitar tracks on "Destiny Street" were re-recorded and released as "Destiny Street Repaired", with guitarists Julian, Marc Ribot and Bill Frisell playing to the original rhythm tracks.
Also in 2009, Hell gave his blessing to the public access program Pancake Mountain to create an animated music video for "The Kid with the Replaceable Head". It was the Voidoids' first and only official music video. The cut used for the animation appears on Hell's 2005 retrospective album, "Spurts, The Richard Hell Story".

Hell's only other album release was as part of the band Dim Stars, for which he came out of retirement for a month in the early 1990s. Dim Stars featured guitarist Thurston Moore and drummer Steve Shelley from Sonic Youth, Gumball's guitarist Don Fleming, and Quine. They formed only to record a 1991 EP and a 1992 album, both titled "Dim Stars", and played one show in public, a WFMU benefit at The Ritz in Manhattan. Hell played bass, sang lead vocals and wrote the lyrics for the album.

Hell also guested on the 1993 "Roller Coaster" album by Shotgun Rationale, and co-wrote and sang lead vocals on the song "Never Mind" by the Heads, a 1996 collaborative effort between three former members of Talking Heads.

"The Voidoid", a novella written in 1973, was finally published by CodeX in 1993. It was reissued in 2009 by 38th Street Publishers with illustrations by Kier Cooke Sandvik.

Early poetry collections by Hell include "I Was a Spiral on the Floor" (1988) and "Across the Years" (1992), both published by Soyo Publications.

"Artifact: Notebooks from Hell 1974–1980", a collection of Hell's punk-era journals, was released in 1990 by Hanuman Books.

In 1996, Scribner published Hell's first full-length novel, "Go Now", set in 1980 and drawn largely from his own experiences.

Hell released a collection of short pieces (poems, essays and drawings) called "Hot and Cold" in 2001. His second novel, "Godlike", was published in 2005 by Akashic Books as part of Dennis Cooper's Little House on the Bowery Series. Also published in 2005 was "Rabbit Duck", a book of 13 poems written in collaboration with David Shapiro. More recent works include "Psychopts" (2008), a collaboration with artist Christopher Wool, as well as "Disgusting" (2010) and "I Dreamed I Was a Very Clean Tramp" (2013).

Hell's nonfiction has been widely anthologized, including a number of appearances in "best music writing" collections. "The Toilet Paper Columns" (2007) compiled his columns for the Colorado alternative magazine "Toilet Paper", while "Massive Pissed Love: Nonfiction 2001-2014" was issued by Soft Skull Press in 2015.

Hell's archive of his manuscripts, tapes, correspondence (written and email), journals and other documents of his life was purchased for $50,000 by New York University's Fales Library in 2003.

A mural in Hell's hometown of Lexington, Kentucky, created by students from Lexington Montessori High School, was completed in June 2019. The mural, located in the city's North Limestone neighborhood, has three parts: two profiles of Hell, and a quote from his autobiography, "I Dreamed I Was a Very Clean Tramp". "This was in Lexington, Ky. when everybody was a kid. I looked for caves and birds and ran away from home. My favorite thing to do was to run away. The words ‘let’s run away’ still sounds magical to me."

Hell has appeared in several low-budget films, most notably Susan Seidelman's "Smithereens". Other acting appearances include Ulli Lommel's "Blank Generation", Nick Zedd's "Geek Maggot Bingo", Rachel Amadeo's "What About Me?" and Rachid Kerdouche's "Final Reward". Hell had a non-speaking cameo role as Madonna's murdered boyfriend in Seidelman's 1985 "Desperately Seeking Susan".

Hell was married to Scandal's Patty Smyth for two years during 1985–86, and they had a daughter, Ruby. Hell married Sheelagh Bevan in 2002.











</doc>
<doc id="26520" url="https://en.wikipedia.org/wiki?curid=26520" title="Rob Roy (cocktail)">
Rob Roy (cocktail)

The Rob Roy is a cocktail consisting primarily of whisky and vermouth, created in 1894 by a bartender at the Waldorf Astoria in Manhattan, New York City. The drink was named in honor of the premiere of "Rob Roy", an operetta by composer Reginald De Koven and lyricist Harry B. Smith loosely based upon Scottish folk hero Rob Roy MacGregor.

A Rob Roy is similar to a Manhattan, but is made exclusively with Scotch whisky, while the Manhattan is traditionally made with rye and today commonly made with bourbon or Canadian whisky.

Like the Manhattan, the Rob Roy can be made "sweet", "dry", or "perfect". The standard Rob Roy is the sweet version, made with sweet vermouth, so there is no need to specify a "sweet" Rob Roy when ordering. A "dry" Rob Roy is made by replacing the sweet vermouth with dry vermouth. A "perfect" Rob Roy is made with equal parts sweet and dry vermouth.

The Rob Roy includes a dash of Angostura bitters (mostly for color) and is usually served in a cocktail glass and garnished with two maraschino cherries on a skewer (for the standard version) or a lemon twist (for the perfect and dry versions).



</doc>
<doc id="26521" url="https://en.wikipedia.org/wiki?curid=26521" title="Rob Roy">
Rob Roy

Rob Roy most often refers to the Scottish hero Rob Roy MacGregor (, 1671–1734).

Rob Roy may also refer to:







</doc>
<doc id="26524" url="https://en.wikipedia.org/wiki?curid=26524" title="Rogue">
Rogue

A rogue is a person or entity that flouts accepted norms of behavior. 

Rogue or rogues may also refer to:













</doc>
<doc id="26526" url="https://en.wikipedia.org/wiki?curid=26526" title="Referential transparency">
Referential transparency

Referential transparency and referential opacity are properties of parts of computer programs. An expression is called referentially transparent if it can be replaced with its corresponding value without changing the program's behavior. This requires that the expression be pure, that is to say the expression value must be the same for the same inputs and its evaluation must have no side effects. An expression that is not referentially transparent is called referentially opaque.

In mathematics all function applications are referentially transparent, by the definition of what constitutes a mathematical function. However, this is not always the case in programming, where the terms procedure and method are used to avoid misleading connotations. In functional programming only referentially transparent functions are considered. Some programming languages provide means to guarantee referential transparency. Some functional programming languages enforce referential transparency for all functions.

The importance of referential transparency is that it allows the programmer and the compiler to reason about program behavior as a rewrite system. This can help in proving correctness, simplifying an algorithm, assisting in modifying code without breaking it, or optimizing code by means of memoization, common subexpression elimination, lazy evaluation, or parallelization.

The concept seems to have originated in Alfred North Whitehead and Bertrand Russell's "Principia Mathematica" (1910–13). It was adopted in analytical philosophy by Willard Van Orman Quine. In §30 of "Word and Object" (1960) Quine gives this definition:

A mode of containment φ is referentially transparent if, whenever an occurrence of a singular term t is purely referential in a term or sentence ψ(t), it is purely referential also in the containing term or sentence φ(ψ(t)).

The term appeared in its contemporary computer science usage, in the discussion of variables in programming languages, in Christopher Strachey's seminal set of lecture notes "Fundamental Concepts in Programming Languages" (1967). The lecture notes referenced Quine's "Word and Object" in the bibliography.

If all functions involved in the expression are pure functions, then the expression is referentially transparent.

Consider a function that returns the input from some source. In pseudocode, a call to this function might be codice_1 where codice_2 might identify a particular disk file, the keyboard, etc. Even with identical values of codice_2, the successive return values will be different. Therefore, function codice_4 is neither deterministic nor referentially transparent.

A more subtle example is that of a function that has a free variable, i.e., depends on some input that is not explicitly passed as a parameter. This is then resolved according to name binding rules to a non-local variable, such as a global variable, a variable in the current execution environment (for dynamic binding), or a variable in a closure (for static binding). Since this variable can be altered without changing the values passed as parameter, the results of subsequent calls to the function may differ even if the parameters are identical. However, in pure functional programming, destructive assignment is not allowed, and thus if the free variable is statically bound to a value, the function is still referentially transparent, as neither the non-local variable nor its value can change, due to static binding and immutability, respectively.

Arithmetic operations are referentially transparent: codice_5 can be replaced by codice_6, for instance. In fact, all functions in the mathematical sense are referentially transparent: codice_7 is transparent, since it will always give the same result for each particular codice_8.

Assignments are not transparent. For instance, the C expression codice_9 changes the value assigned to the variable codice_8. Assuming codice_8 initially has value codice_12, two consecutive evaluations of the expression yield, respectively, codice_13 and codice_14. Clearly, replacing codice_9 with either codice_13 or codice_14 gives a program with different meaning, and so the expression is not referentially transparent. However, calling a function such as "is" transparent, as it will not implicitly change the input x and thus has no such side effects.

codice_18 is not transparent, as if you evaluate it and replace it by its value (say, "Jan 1, 2001"), you don't get the same result as you will if you run it tomorrow. This is because it depends on a state (the date).

In languages with no side-effects, like Haskell, we can substitute equals for equals: i.e. if codice_19 then codice_20. This is a property also known as indistinguishable identicals, see Identity of indiscernibles. Such properties need not hold in general for languages with side-effects. Even so it is important to limit such assertions to so-called judgmental equality, that is the equality of the terms as tested by the system, not including user-defined equivalence for types. For instance, if codice_21 and the type codice_22 has overridden the notion of equality, e.g. making all terms equal, then it is possible to have codice_19 and yet find codice_24. This is because systems like Haskell do not verify that functions defined on types with user-defined equivalence relations be well-defined with respect to that equivalence. Thus the referential transparency is limited to types without equivalence relations. Extending referential transparency to user-defined equivalence relations can be done for example with a Martin-Lof identity type, but requires a dependently typed system such as in Agda, Coq or Idris.

If the substitution of an expression with its value is valid only at a certain point in the execution of the program, then the expression is not referentially transparent. The definition and ordering of these sequence points are the theoretical foundation of imperative programming, and part of the semantics of an imperative programming language.

However, because a referentially transparent expression can be evaluated at any time, it is not necessary to define sequence points nor any guarantee of the order of evaluation at all. Programming done without these considerations is called purely functional programming.

One advantage of writing code in a referentially transparent style is that given an intelligent compiler, static code analysis is easier and better code-improving transformations are possible automatically. For example, when programming in C, there will be a performance penalty for including a call to an expensive function inside a loop, even if the function call could be moved outside of the loop without changing the results of the program. The programmer would be forced to perform manual code motion of the call, possibly at the expense of source code readability. However, if the compiler is able to determine that the function call is referentially transparent, it can perform this transformation automatically.

The primary disadvantage of languages that enforce referential transparency is that they make the expression of operations that naturally fit a sequence-of-steps imperative programming style more awkward and less concise. Such languages often incorporate mechanisms to make these tasks easier while retaining the purely functional quality of the language, such as definite clause grammars and monads.

As an example, let's use two functions, one which is referentially transparent, and the other which is referentially opaque:
int g = 0;

int rt(int x) {

int ro(int x) {

The function codice_25 is referentially transparent, which means that if codice_19 then codice_27. For instance, codice_28. However, we cannot say any such thing for codice_29 because it uses a global variable that it modifies.

The referential opacity of codice_29 makes reasoning about programs more difficult. For example, say we wish to reason about the following statement:
int i = ro(x) + ro(y) * (ro(x) - ro(x));
One may be tempted to simplify this statement to:
int i = ro(x) + ro(y) * 0;
int i = ro(x) + 0;
int i = ro(x);
However, this will not work for codice_29 because each occurrence of codice_32 evaluates to a different value. Remember that the return value of codice_29 is based on a global value that is not passed in and which gets modified on each call to codice_29. This means that mathematical identities such as formula_1 no longer hold.

Such mathematical identities "will" hold for referentially transparent functions such as codice_25.

However, a more sophisticated analysis can be used to simplify the statement to:
int tmp = g; int i = x + tmp + 1 + (y + tmp + 2) * (x + tmp + 3 - (x + tmp + 4)); g = g + 4;
int tmp = g; int i = x + tmp + 1 + (y + tmp + 2) * (x + tmp + 3 - x - tmp - 4)); g = g + 4;
int tmp = g; int i = x + tmp + 1 + (y + tmp + 2) * (-1); g = g + 4;
int tmp = g; int i = x + tmp + 1 - y - tmp - 2; g = g + 4;
int i = x - y - 1; g = g + 4;
This takes more steps and requires a degree of insight into the code infeasible for compiler optimization.

Therefore, referential transparency allows us to reason about our code which will lead to more robust programs, the possibility of finding bugs that we couldn't hope to find by testing, and the possibility of seeing opportunities for optimization.





</doc>
<doc id="26529" url="https://en.wikipedia.org/wiki?curid=26529" title="Reaganomics">
Reaganomics

Reaganomics (; a portmanteau of "[Ronald] Reagan" and "economics" attributed to Paul Harvey), or Reaganism, refers to the economic policies promoted by U.S. President Ronald Reagan during the 1980s. These policies are commonly associated with and characterized as supply-side economics, trickle-down economics, or voodoo economics by political opponents, while Reagan and his political advocates preferred to call it free-market economics.

The four pillars of Reagan's economic policy were to reduce the growth of government spending, reduce the federal income tax and capital gains tax, reduce government regulation, and tighten the money supply in order to reduce inflation.

The results of Reaganomics are still debated. Supporters point to the end of stagflation, stronger GDP growth, and an entrepreneur revolution in the decades that followed. Critics point to the widening income gap, what they described as an atmosphere of greed, and the national debt tripling in eight years which ultimately reversed the post-World War II trend of a shrinking national debt as percentage of GDP.

Prior to the Reagan administration, the United States economy experienced a decade of high unemployment and persistently high inflation (known as stagflation). Attacks on Keynesian economic orthodoxy as well as empirical economic models such as the Phillips Curve grew. Political pressure favored stimulus resulting in an expansion of the money supply. President Richard Nixon's wage and price controls were phased out. The federal oil reserves were created to ease any future short term shocks. President Jimmy Carter had begun phasing out price controls on petroleum while he created the Department of Energy. Much of the credit for the resolution of the stagflation is given to two causes: a three-year contraction of the money supply by the Federal Reserve Board under Paul Volcker, initiated in the last year of Carter's presidency, and long-term easing of supply and pricing in oil during the 1980s oil glut.

In stating that his intention was to lower taxes, Reagan's approach was a departure from his immediate predecessors. Reagan enacted lower marginal tax rates as well as simplified income tax codes and continued deregulation. During Reagan's eight year presidency, the annual deficits averaged 4.0% of GDP, compared to a 2.2% average during the preceding eight years. The real (inflation adjusted) average rate of growth in federal spending fell from 4% under Jimmy Carter to 2.5% under Ronald Reagan. GDP per employed person increased at an average 1.5% rate during the Reagan administration, compared to an average 0.6% during the preceding eight years. Private sector productivity growth, measured as real output per hour of all persons, increased at an average rate of 1.9% during Reagan's eight years, compared to an average 1.3% during the preceding eight years. Federal net outlays as a percent of GDP averaged 21.4% under Reagan, compared to 19.1% during the preceding eight years.

During the Nixon and Ford Administrations, before Reagan's election, a combined supply and demand side policy was considered unconventional by the moderate wing of the Republican Party. While running against Reagan for the Presidential nomination in 1980, George H. W. Bush had derided Reaganomics as "voodoo economics". Similarly, in 1976, Gerald Ford had severely criticized Reagan's proposal to turn back a large part of the Federal budget to the states.

In his 1980 campaign speeches, Reagan presented his economic proposals as a return to the free enterprise principles, free market economy that had been in favor before the Great Depression and FDR's New Deal policies. At the same time he attracted a following from the supply-side economics movement, which formed in opposition to Keynesian demand-stimulus economics. This movement produced some of the strongest supporters for Reagan's policies during his term in office.

The contention of the proponents, that the tax rate cuts would more than cover any increases in federal debt, was influenced by a theoretical taxation model based on the elasticity of tax rates, known as the Laffer curve. Arthur Laffer's model predicts that excessive tax rates actually reduce potential tax revenues, by lowering the incentive to produce; the model also predicts that insufficient tax rates (rates below the optimum level for a given economy) lead directly to a reduction in tax revenues.

Ronald Reagan also cited the 14th-century Arab scholar Ibn Khaldun as an influence on his supply-side economic policies, in 1981. Reagan paraphrased Ibn Khaldun, who said that "In the beginning of the dynasty, great tax revenues were gained from small assessments," and that "at the end of the dynasty, small tax revenues were gained from large assessments." Reagan said his goal is "trying to get down to the small assessments and the great revenues."

Reagan lifted remaining domestic petroleum price and allocation controls on January 28, 1981, and lowered the oil windfall profits tax in August 1981. He ended the oil windfall profits tax in 1988. During the first year of Reagan's presidency, federal income tax rates were lowered significantly with the signing of the Economic Recovery Tax Act of 1981, which lowered the top marginal tax bracket from 70% to 50% and the lowest bracket from 14% to 11%. This act slashed estate taxes and trimmed taxes paid by business corporations by $150 billion over a five-year period. In 1982 Reagan agreed to a rollback of corporate tax cuts and a smaller rollback of individual income tax cuts. The 1982 tax increase undid a third of the initial tax cut. In 1983 Reagan instituted a payroll tax increase on Social Security and Medicare hospital insurance. In 1984 another bill was introduced that closed tax loopholes. According to tax historian Joseph Thorndike, the bills of 1982 and 1984 "constituted the biggest tax increase ever enacted during peacetime".

With the Tax Reform Act of 1986, Reagan and Congress sought to simplify the tax system by eliminating many deductions, reducing the highest marginal rates, and reducing the number of tax brackets. In 1983, Democrats Bill Bradley and Dick Gephardt had offered a proposal; in 1984 Reagan had the Treasury Department produce its own plan. The 1986 act aimed to be revenue-neutral: while it reduced the top marginal rate, it also cleaned up the tax base by removing certain tax write-offs, preferences, and exceptions, thus raising the effective tax on activities previously specially favored by the code. Ultimately, the combination of the decrease in deductions and decrease in rates raised revenue equal to about 4% of existing tax revenue.
Federal revenue share of GDP fell from 19.6% in fiscal 1981 to 17.3% in 1984, before rising back to 18.4% by fiscal year 1989. Personal income tax revenues fell during this period relative to GDP, while payroll tax revenues rose relative to GDP. Reagan's 1981 cut in the top regular tax rate on unearned income reduced the maximum capital gains rate to only 20% – its lowest level since the Hoover administration. The 1986 act set tax rates on capital gains at the same level as the rates on ordinary income like salaries and wages, with both topping out at 28%.

Reagan significantly increased public expenditures, primarily the Department of Defense, which rose (in constant 2000 dollars) from $267.1 billion in 1980 (4.9% of GDP and 22.7% of public expenditure) to $393.1 billion in 1988 (5.8% of GDP and 27.3% of public expenditure); most of those years military spending was about 6% of GDP, exceeding this number in 4 different years. All these numbers had not been seen since the end of U.S. involvement in the Vietnam War in 1973. In 1981, Reagan significantly reduced the maximum tax rate, which affected the highest income earners, and lowered the top marginal tax rate from 70% to 50%; in 1986 he further reduced the rate to 28%. The federal deficit under Reagan peaked at 6% of GDP in 1983, falling to 3.2% of GDP in 1987 and to 3.1% of GDP in his final budget. The inflation-adjusted rate of growth in federal spending fell from 4% under Jimmy Carter to 2.5% under Ronald Reagan. This was the slowest rate of growth in inflation adjusted spending since Eisenhower. However, federal deficit as percent of GDP was up throughout the Reagan presidency from 2.7% at the end of (and throughout) the Carter administration. As a short-run strategy to reduce inflation and lower nominal interest rates, the U.S. borrowed both domestically and abroad to cover the Federal budget deficits, raising the national debt from $997 billion to $2.85 trillion. This led to the U.S. moving from the world's largest international creditor to the world's largest debtor nation. Reagan described the new debt as the "greatest disappointment" of his presidency.

According to William A. Niskanen, one of the architects of Reaganomics, "Reagan delivered on each of his four major policy objectives, although not to the extent that he and his supporters had hoped", and notes that the most substantial change was in the tax code, where the top marginal individual income tax rate fell from 70.1% to 28.4%, and there was a "major reversal in the tax treatment of business income", with effect of "reducing the tax bias among types of investment but increasing the average effective tax rate on new investment". Roger Porter, another architect of the program, acknowledges that the program was weakened by the many hands that changed the President's calculus, such as Congress.

Spending during the years Reagan budgeted (FY 1982–89) averaged 21.6% GDP, roughly tied with President Obama for the highest among any recent President. Each faced a severe recession early in their administration. In addition, the public debt rose from 26% GDP in 1980 to 41% GDP by 1988. In dollar terms, the public debt rose from $712 billion in 1980 to $2.052 trillion in 1988, a roughly three-fold increase. The unemployment rate rose from 7% in 1980 to 11% in 1982, then declined to 5% in 1988. The inflation rate declined from 10% in 1980 to 4% in 1988.

Some economists have stated that Reagan's policies were an important part of bringing about the third longest peacetime economic expansion in U.S. history. During the Reagan administration, real GDP growth averaged 3.5%, compared to 2.9% during the preceding eight years. The annual average unemployment rate declined by 1.7 percentage points, from 7.2% in 1980 to 5.5% in 1988, after it had increased by 1.6 percentage points over the preceding eight years. Nonfarm employment increased by 16.1 million during Reagan's presidency, compared to 15.4 million during the preceding eight years, while manufacturing employment declined by 582,000 after rising 363,000 during the preceding eight years. Reagan's administration is the only one not to have raised the minimum wage. The inflation rate, 13.5% in 1980, fell to 4.1% in 1988, in part because the Federal Reserve increased interest rates (prime rate peaking at 20.5% in August 1981). The latter contributed to a recession from July 1981 to November 1982 during which unemployment rose to 9.7% and GDP fell by 1.9%. Additionally, income growth slowed for middle- and lower-class (2.4% to 1.8%) and rose for the upper-class (2.2% to 4.83%).

The misery index, defined as the inflation rate added to the unemployment rate, shrank from 19.33 when he began his administration to 9.72 when he left, the greatest improvement record for a President since Harry S. Truman left office. In terms of American households, the percentage of total households making less than $10,000 a year (in real 2007 dollars) shrank from 8.8% in 1980 to 8.3% in 1988 while the percentage of households making over $75,000 went from 20.2% to 25.7% during that period, both signs of progress.

The job growth (measured for non-farm payrolls) under the Reagan administration averaged 168,000 per month, versus 216,000 for Carter, 55,000 for H.W. Bush, and 239,000 for Clinton. Measuring the number of jobs created per month is limited for longer time periods as the population grows. To address this, we can measure annual job growth percentages, comparing the beginning and ending number of jobs during their time in office to determine an annual growth rate. Jobs grew by 2.0% annually under Reagan, versus 3.1% under Carter, 0.6% under H.W. Bush, and 2.4% under Clinton.

The unemployment rate averaged 7.5% under Reagan, compared to an average 6.6% during the preceding eight years. Declining steadily after December 1982, the rate was 5.4% the month Reagan left office.

The average real hourly wage for production and nonsupervisory workers continued the decline that had begun in 1973, albeit at a slower rate, and remained below the pre-Reagan level in every Reagan year.

The labor force participation rate increased by 2.6 percentage points during Reagan's eight years, compared to 3.9 percentage points during the preceding eight years.

Some commentators have asserted that over one million jobs were created in a single month — September 1983. Although official data support that figure, it was caused by nearly 700,000 AT&T workers going on strike and being counted as job losses in August 1983, with a quick resolution of the strike leading workers to return in September, then being counted as job gains.

Following the 1981 recession, the unemployment rate had averaged slightly higher (6.75% vs. 6.35%), productivity growth lower (1.38% vs. 1.92%), and private investment as a percentage of GDP slightly less (16.08% vs. 16.86%). In the 1980s, industrial productivity growth in the United States matched that of its trading partners after trailing them in the 1970s. By 1990, manufacturing's share of GNP exceeded the post-World War II low hit in 1982 and matched "the level of output achieved in the 1960s when American factories hummed at a feverish clip".

Real GDP grew over one-third during Reagan's presidency, an over $2 trillion increase. The compound annual growth rate of GDP was 3.6% during Reagan's eight years, compared to 2.7% during the preceding eight years. Real GDP per capita grew 2.6% under Reagan, compared to 1.9% average growth during the preceding eight years.

In nominal terms, median household income grew at a compound annual growth rate (CAGR) of 5.5% during the Reagan presidency, compared to 8.5% during the preceding five years (pre-1975 data are unavailable). Real median family income grew by $4,492 during the Reagan period, compared to a $1,270 increase during the preceding eight years. After declining from 1974 through 1980, real mean personal income rose $4,708 by 1988. Nominal household net worth increased by a CAGR of 8.4%, compared to 9.3% during the preceding eight years.

The percentage of the total population below the poverty level increased from 13.0% in 1980 to 15.2% in 1983, then declined back to 13.0% in 1988. During Reagan's first term, critics noted homelessness as a visible problem in U.S. urban centers. In the closing weeks of his presidency, Reagan told David Brinkley that the homeless "make it their own choice for staying out there," noting his belief that there "are shelters in virtually every city, and shelters here, and those people still prefer out there on the grates or the lawn to going into one of those shelters". He also stated that "a large proportion" of them are "mentally impaired", which he believed to be a result of lawsuits by the ACLU (and similar organizations) against mental institutions. His policies became widely known as "trickle-down economics", due to the significant cuts in the upper tax brackets, as that extra money for the wealthy could trickle along to low-income groups.

During the Reagan administration, fiscal year federal receipts grew from $599 billion to $991 billion (an increase of 65%) while fiscal year federal outlays grew from $678 billion to $1144 billion (an increase of 69%). According to a 1996 report of the Joint Economic Committee of the United States Congress, during Reagan's two terms, and through 1993, the top 10% of taxpayers paid an increased share of income taxes (not including payroll taxes) to the Federal government, while the lowest 50% of taxpayers paid a reduced share of income tax revenue. Personal income tax revenues declined from 9.4% GDP in 1981 to 8.3% GDP in 1989, while payroll tax revenues increased from 6.0% GDP to 6.7% GDP during the same period.

Both CBO and the Reagan Administration forecast that individual and business income tax revenues would be lower if the Reagan tax cut proposals were implemented, relative to a policy baseline without those cuts, by about $50 billion in 1982 and $210 billion by 1986.According to a 2003 Treasury study, the tax cuts in the Economic Recovery Tax Act of 1981 resulted in a significant decline in revenue relative to a baseline without the cuts, approximately $111 billion (in 1992 dollars) on average during the first four years after implementation or nearly 3% GDP annually. Other tax bills had neutral or, in the case of the Tax Equity and Fiscal Responsibility Act of 1982, a (~+1% of GDP) increase in revenue as a share of GDP. The study did not examine the longer-term impact of Reagan tax policy, including sunset clauses and "the long-run, phased-in effect of the tax bills". The fact that tax receipts "as a percentage of GDP" fell following the Economic Recovery Tax Act of 1981 shows a decrease in tax burden as share of GDP and a commensurate increase in the deficit, as spending did not fall relative to GDP. Total federal tax receipts increased in every Reagan year except 1982, at an annual average rate of 6.2% compared to 10.8% during the preceding eight years.

The effect of Reagan's 1981 tax cuts (reduced revenue relative to a baseline without the cuts) were at least partially offset by phased in Social Security payroll tax increases that had been enacted by President Jimmy Carter and the 95th Congress in 1977, and further increases by Reagan in 1983 and following years, also to counter the uses of tax shelters. An accounting indicated nominal tax receipts increased from $599 billion in 1981 to $1.032 trillion in 1990, an increase of 72% in current dollars. In 2005 dollars, the tax receipts in 1990 were $1.5 trillion, an increase of 20% above inflation.

Reagan was inaugurated in January 1981, so the first fiscal year (FY) he budgeted was 1982 and the final year was 1989. 
Nominal after-tax corporate profits grew at a compound annual growth rate of 3.0% during Reagan's eight years, compared to 13.0% during the preceding eight years. The S&P 500 Index increased 113.3% during the 2024 trading days under Reagan, compared to 10.4% during the preceding 2024 trading days. The business sector share of GDP, measured as gross private domestic investment, declined by 0.7 percentage points under Reagan, after increasing 0.7 percentage points during the preceding eight years.

The federal government's share of GDP increased 0.2 percentage points under Reagan, while it decreased 1.5 percentage points during the preceding eight years. The number of federal civilian employees increased 4.2% during Reagan's eight years, compared to 6.5% during the preceding eight years.

As a candidate, Reagan asserted he would shrink government by abolishing the Cabinet-level departments of energy and education. He abolished neither, but elevated veterans affairs from independent agency status to Cabinet-level department status.

Continuing a trend that began in the 1970s, income inequality grew and accelerated in the 1980s. "The Economist" wrote in 2006: "After the 1973 oil shocks, productivity growth suddenly slowed. A few years later, at the start of the 1980s, the gap between rich and poor began to widen." According to the CBO: 

According to a 1996 study by the Cato Institute, a libertarian think tank, on 8 of the 10 key economic variables examined, the American economy performed better during the Reagan years than during the pre- and post-Reagan years. The study asserted that real median family income grew by $4,000 and during the eight Reagan years and experienced a loss of almost $1,500 in the post-Reagan years. Interest rates, inflation, and unemployment fell faster under Reagan than they did immediately before or after his presidency. The only economic variable that was lower during period than in both the pre- and post-Reagan years was the savings rate, which fell rapidly in the 1980s. The productivity rate was higher in the pre-Reagan years but lower in the post-Reagan years. The Cato study was dismissive of any positive effects of tightening, and subsequent loosening, of Federal Reserve monetary policy under "inflation hawk" Paul Volcker, whom President Carter had appointed in 1979 to halt the persistent inflation of the 1970s.

Economic analyst Stephen Moore stated in the Cato analysis, "No act in the last quarter century had a more profound impact on the U.S. economy of the eighties and nineties than the Reagan tax cut of 1981." He argued that Reagan's tax cuts, combined with an emphasis on federal monetary policy, deregulation, and expansion of free trade created a sustained economic expansion, the greatest American sustained wave of prosperity ever. He also claims that the American economy grew by more than a third in size, producing a $15 trillion increase in American wealth. Consumer and investor confidence soared. Cutting federal income taxes, cutting the U.S. government spending budget, cutting useless programs, scaling down the government work force, maintaining low interest rates, and keeping a watchful inflation hedge on the monetary supply was Ronald Reagan's formula for a successful economic turnaround.

Milton Friedman stated, "Reaganomics had four simple principles: Lower marginal tax rates, less regulation, restrained government spending, noninflationary monetary policy. Though Reagan did not achieve all of his goals, he made good progress."

The Tax Reform Act of 1986 and its impact on the alternative minimum tax (AMT) reduced nominal rates on the wealthy and eliminated tax deductions, while raising tax rates on lower-income individuals. The across the board tax system reduced marginal rates and further reduced bracket creep from inflation. The highest income earners (with incomes exceeding $1,000,000) received a tax break, restoring a flatter tax system. In 2006, the IRS's National Taxpayer Advocate's report characterized the effective rise in the AMT for individuals as a problem with the tax code. Through 2007, the revised AMT had brought in more tax revenue than the former tax code, which has made it difficult for Congress to reform.

Economist Paul Krugman argued the economic expansion during the Reagan administration was primarily the result of the business cycle and the monetary policy by Paul Volcker. Krugman argues that there was nothing unusual about the economy under Reagan because unemployment was reducing from a high peak and that it is consistent with Keynesian economics for the economy to grow as employment increases if inflation remains low. Krugman has also criticized Reaganomics from the standpoint of wealth and income inequality. He argues that the Reagan era tax cuts ended the post-World War II "Great Compression" of wealth held by the rich.

The CBO Historical Tables indicate that federal spending during Reagan's two terms (FY 1981–88) averaged 22.4% GDP, well above the 20.6% GDP average from 1971 to 2009. In addition, the public debt rose from 26.1% GDP in 1980 to 41.0% GDP by 1988. In dollar terms, the public debt rose from $712 billion in 1980 to $2,052 billion in 1988, a three-fold increase. Krugman argued in June 2012 that Reagan's policies were consistent with Keynesian stimulus theories, pointing to the significant increase in per-capita spending under Reagan.

William Niskanen noted that during the Reagan years, privately held federal debt increased from 22% to 38% of GDP, despite a long peacetime expansion. Second, the savings and loan problem led to an additional debt of about $125 billion. Third, greater enforcement of U.S. trade laws increased the share of U.S. imports subjected to trade restrictions from 12% in 1980 to 23% in 1988.

Economists Raghuram Rajan and Luigi Zingales pointed out that many deregulation efforts had either taken place or had begun before Reagan (note the deregulation of airlines and trucking under Carter, and the beginning of deregulatory reform in railroads, telephones, natural gas, and banking). They stated, "The move toward markets preceded the leader [Reagan] who is seen as one of their saviors." Economists Paul Joskow and Roger Noll made a similar contention.

Economist William A. Niskanen, a member of Reagan's Council of Economic Advisers wrote that deregulation had the "lowest priority" of the items on the Reagan agenda given that Reagan "failed to sustain the momentum for deregulation initiated in the 1970s" and that he "added more trade barriers than any administration since Hoover." By contrast, economist Milton Friedman has pointed to the number of pages added to the Federal Register each year as evidence of Reagan's anti-regulation presidency (the Register records the rules and regulations that federal agencies issue per year). The number of pages added to the Register each year declined sharply at the start of the Ronald Reagan presidency breaking a steady and sharp increase since 1960. The increase in the number of pages added per year resumed an upward, though less steep, trend after Reagan left office. In contrast, the number of pages being added each year increased under Ford, Carter, George H. W. Bush, Clinton, George W. Bush, and Obama. The number of pages in Federal Register is however criticized as an extremely crude measure of regulatory activity, because it can be easily manipulated (e.g. font sizes have been changed to keep page count low). The apparent contradiction between Niskanen's statements and Friedman's data may be resolved by seeing Niskanen as referring to "statutory" deregulation (laws passed by Congress) and Friedman to "administrative" deregulation (rules and regulations implemented by federal agencies). A 2016 study by the Congressional Research Service found that Reagan's average annual number of final federal regulatory rules published in the Federal Register was higher than during the Clinton, George W. Bush or Obama's administrations, even though the Reagan economy was considerably smaller than during those later presidents. Another study by the QuantGov project of the libertarian Mercatus Center found that the Reagan administration added restrictive regulations — containing such terms as "shall," "prohibited" or "may not" — at a faster average annual rate than did Clinton, Bush or Obama.

Greg Mankiw, a conservative Republican economist who served as chairman of the Council of Economic Advisors under President George W. Bush, wrote in 2007:
I used the phrase "charlatans and cranks" in the first edition of my principles textbook to describe some of the economic advisers to Ronald Reagan, who told him that broad-based income tax cuts would have such large supply-side effects that the tax cuts would raise tax revenue. I did not find such a claim credible, based on the available evidence. I never have, and I still don't ... My other work has remained consistent with this view. In a paper on dynamic scoring, written while I was working at the White House, Matthew Weinzierl and I estimated that a broad-based income tax cut (applying to both capital and labor income) would recoup only about a quarter of the lost revenue through supply-side growth effects. For a cut in capital income taxes, the feedback is larger — about 50 percent — but still well under 100 percent. A chapter on dynamic scoring in the 2004 Economic Report of the President says about the same thing.

Glenn Hubbard, who preceded Mankiw as Bush's CEA chair, also disputed the assertion that tax cuts increase tax revenues, writing in his 2003 Economic Report of the President: "Although the economy grows in response to tax reductions (because of higher consumption in the short run and improved incentives in the long run), it is unlikely to grow so much that lost tax revenue is completely recovered by the higher level of economic activity."

In 1986, Martin Feldstein — a self-described "traditional supply sider" who served as Reagan's chairman of the Council of Economic Advisors from 1982 to 1984 — characterized the "new supply siders" who emerged circa 1980:

What distinguished the new supply siders from the traditional supply siders as the 1980s began was not the policies they advocated but the claims that they made for those policies ... The "new" supply siders were much more extravagant in their claims. They projected rapid growth, dramatic increases in tax revenue, a sharp rise in saving, and a relatively painless reduction in inflation. The height of supply side hyperbole was the "Laffer curve" proposition that the tax cut would actually increase tax revenue because it would unleash an enormously depressed supply of effort. Another remarkable proposition was the claim that even if the tax cuts did lead to an increased budget deficit, that would not reduce the funds available for investment in plant and equipment because tax changes would raise the saving rate by enough to finance the increased deficit ... Nevertheless, I have no doubt that the loose talk of the supply side extremists gave fundamentally good policies a bad name and led to quantitative mistakes that not only contributed to subsequent budget deficits but that also made it more difficult to modify policy when those deficits became apparent.







</doc>
<doc id="26531" url="https://en.wikipedia.org/wiki?curid=26531" title="Roland Corporation">
Roland Corporation

Roland has manufactured numerous instruments that have had lasting impacts on music, such as the Juno-106 synthesizer, TB-303 bass synthesizer, and TR-808 and TR-909 drum machines. Roland was also instrumental in the development of MIDI, a standardized means of synchronizing electronic instruments manufactured by different companies. In 2016, "Fact" wrote that Roland "arguably did more to shape electronic music than any other [company] in history".

Having created Ace Electronic Industries Inc in 1960, Ikutaro Kakehashi founded Roland in Osaka on April 18, 1972. While rival companies Moog and ARP targeted professional musicians and academics, Kakehashi, who had no musical training, wanted to appeal to amateurs and hobbyists, and focused on miniaturization, affordability, and simplicity.

The "Roland" name was selected for export purposes, as Kakehashi was interested in a name that was easy to pronounce for his worldwide target markets. The name was found in a telephone directory, and Kakehashi was satisfied with the simple two-syllable word and its soft consonants. The letter "R" was chosen because it was not used by many other music equipment companies, and would therefore stand out in trade show directories and industry listings. Kakehashi did not learn of the French epic poem "The Song of Roland" until later.

With seven employees from his former company, a rented shed, and $100,000, Kakehashi built on his experience at Ace, introducing a drum machine, the TR-77 or Rhythm 77, as Roland's first product, followed by the TR-33 and TR-55 released that same year. In 1973, Roland introduced the first compact synthesizer produced in Japan and the first synthesizer produced by Roland, the SH-1000, as well as their first non-preset synthesizer, the SH-3.

The company was also manufacturing effects pedals, introducing the RE-201 Space Echo in 1974, and expanding into guitar amplifiers the following year with the JC-60 and JC-120 Jazz Chorus, whose chorus circuit would become the first Boss Corporation product, the CE-1 Chorus Ensemble, the following year. In 1976, Roland introduced the semi-modular System 100 and the modular System 700 synthesizers.

In 1977, the company introduced one of the earliest microprocessor-driven music sequencers, the MC-8 MicroComposer, and the first guitar synthesizer, the GR-500. Just one year later, they introduced the CompuRhythm CR-78, the first drum machine that enabled users to program and store their own drum patterns.

During the 1980s and 1990s, Roland released several instruments that have had a lasting influence on popular music. After Kakehashi realized microprocessors could be used to program drum machines, Roland launched the TR-808 drum machine, its first programmable drum machine, in 1980. Although it was not an immediate commercial success, the 808 was eventually used on more hit records than any other drum machine and became a cornerstone of the emerging electronic and hip hop genres. It has been described as hip hop's equivalent to the Fender Stratocaster guitar, which dramatically influenced the development of rock music. The 808 was followed in 1983 by the TR-909, which, alongside the TB-303 synthesizer, influenced the development of dance music such as techno, house and acid. Roland released the Roland Jupiter-8 in 1981. 

Roland played a key role in the development of MIDI, a standardized means of synchronizing electronic musical instruments manufactured by different companies. Kakehashi proposed developing a standard with representatives from Oberheim Electronics, Sequential Circuits, Yamaha, Korg and Kawai. He and Dave Smith of Sequential Circuits unveiled MIDI in 1983. It remains the industry standard.

In 1994, Kakehashi founded the Roland Foundation and became Chairman. In 1995 he was appointed the chairman of Roland Corporation. In 2001 he resigned from the position and was appointed as Special Executive Adviser of Roland Corporation. In 2002, Kakehashi published an autobiography, "I Believe in Music." His second book, "An Age Without Samples: Originality and Creativity in the Digital World", was published in 2017.

Roland markets products under a number of brand names, each of which are used on products geared toward a different niche.




</doc>
<doc id="26532" url="https://en.wikipedia.org/wiki?curid=26532" title="Rhys ap Gruffydd">
Rhys ap Gruffydd

Rhys ap Gruffydd or ap Gruffudd (often anglicised to "Griffith"; 1132 – 28 April 1197) was the ruler of the kingdom of Deheubarth in south Wales from 1155 to 1197. Today, he is commonly known as The Lord Rhys, in Welsh "Yr Arglwydd Rhys", although this title may have not been used in his lifetime. He usually used the title "Proprietary Prince of Deheubarth" or "Prince of South Wales", but two documents have been discovered in which he uses the title "Prince of Wales" or "Prince of the Welsh". Rhys was one of the most successful and powerful Welsh princes, and, after the death of Owain Gwynedd of Gwynedd in 1170, the dominant power in Wales.

Rhys's grandfather, Rhys ap Tewdwr, was king of Deheubarth, and was killed at Brecon in 1093 by Bernard de Neufmarché. Following his death, most of Deheubarth was taken over by the Normans. Rhys's father, Gruffydd ap Rhys, eventually was able to become ruler of a small portion, and more territory was won back by Rhys's older brothers after Gruffydd's death. Rhys became ruler of Deheubarth in 1155. He was forced to submit to King Henry II of England in 1158. Henry invaded Deheubarth in 1163, stripped Rhys of all his lands and took him prisoner. A few weeks later he was released and given back a small part of his holdings. Rhys made an alliance with Owain Gwynedd and, after the failure of another invasion of Wales by Henry in 1165, was able to win back most of his lands.

In 1171 Rhys made peace with King Henry and was confirmed in possession of his recent conquests as well as being named Justiciar of South Wales. He maintained good relations with King Henry until the latter's death in 1189. Following Henry's death Rhys revolted against Richard I and attacked the Norman lordships surrounding his territory, capturing a number of castles. In his later years Rhys had trouble keeping control of his sons, particularly Maelgwn and Gruffydd, who maintained a feud with each other. Rhys launched his last campaign against the Normans in 1196 and captured a number of castles. The following year he died unexpectedly and was buried in St David's Cathedral.

Rhys was the fourth son of Gruffydd ap Rhys, ruler of part of Deheubarth, by his wife Gwenllian ferch Gruffydd, daughter of Gruffudd ap Cynan, king of Gwynedd. His next older brother was Maredudd ap Gruffydd, and there were older brothers, Morgan and Maelgwn, who were killed in battle with their mother in 1136. He also had two older half-brothers, Anarawd and Cadell, from his father's first marriage. Rhys married Gwenllian ferch Madog, daughter of Madog ap Maredudd, the last Prince of all Powys.
His grandfather, Rhys ap Tewdwr, had been king of all Deheubarth until his death in 1093. Rhys ap Tewdwr was killed in Brycheiniog, and most of his kingdom was taken over by Norman lords. Gruffydd ap Rhys was forced to flee to Ireland. He later returned to Deheubarth and ruled a portion of the kingdom, but was forced to flee to Ireland again in 1127. When Rhys was born in 1132, his father held only the commote of Caeo in Cantref Mawr.

The death of King Henry I of England, and the ensuing Anarchy arising from the rival claims of Stephen and Matilda to the English throne, gave the Welsh the opportunity to rise against the Normans. A revolt spread through south Wales in 1136, and Gruffydd ap Rhys, aided by his two eldest sons, Anarawd and Cadell, defeated the Normans in a battle near Loughor, killing over five hundred. After driving Walter de Clifford out of Cantref Bychan, Gruffydd set off to Gwynedd to enlist the help of his father-in-law, Gruffudd ap Cynan. In the absence of her husband, Gwenllian led an army against the Norman lordship of Cydweli (Kidwelly), taking along her two oldest sons, Morgan and Maelgwn. She was defeated and killed by an army commanded by Maurice de Londres of Oystermouth Castle. Morgan was also killed and Maelgwn captured.

Gruffydd formed an alliance with Gwynedd, and later in 1136 the sons of Gruffudd ap Cynan, Owain Gwynedd and Cadwaladr ap Gruffydd, led an army to Ceredigion. Their combined forces won a decisive victory over the Normans at the Battle of Crug Mawr. Ceredigion was reclaimed from the Normans, but was annexed by Gwynedd as the senior partner in the alliance. Gruffydd ap Rhys continued his campaign against the Normans in 1137, but died later that year. The leadership of the family now passed to Rhys's half-brother Anarawd ap Gruffydd. In 1143, when Rhys was eleven, Anarawd was murdered, a death arranged for by Cadwaladr ap Gruffydd, brother of Owain Gwynedd, king of Gwynedd. Owain punished Cadwaladr by depriving him of his lands in Ceredigion.

Anarawd's brother, Cadell ap Gruffydd, took over as head of the family. Gilbert de Clare, Earl of Pembroke, rebuilt Carmarthen castle in 1145 then began a campaign to reclaim Ceredigion. He built a castle in the commote of Mabudryd, but Cadell, aided by Hywel ab Owain Gwynedd who held Ceredigion for Gwynedd, destroyed it in 1146. Rhys appears in the annals for the first time in 1146, fighting alongside his brothers Cadell and Maredudd in the capture by assault of Llansteffan Castle. This was followed by the capture of Wiston in 1147, Carmarthen in 1150 and Loughor in 1151. In 1151 Cadell was attacked while out hunting by a group of Norman and Flemish knights from Tenby, and left for dead. He survived, but suffered injuries which left him unable to play an active role, and in 1153 he left on a pilgrimage to Rome.

Maredudd became ruler of Deheubarth and continued a campaign, begun in 1150, aimed at recovering Ceredigion, which had been held by Gwynedd since 1136. Maredudd and Rhys were able to drive Hywel ab Owain Gwynedd from Ceredigion by 1153. The same year Rhys is recorded as an independent commander for the first time, leading an army to capture the Norman castle of St Clears. Maredudd and Rhys also destroyed the castles at Tenby and Aberafan that year. Maredudd died in 1155 at the age of twenty-five and left Rhys as ruler of Deheubarth. Around this time he married Gwenllian ferch Madog, daughter of Madog ap Maredudd, prince of Powys.

Shortly after becoming ruler of Deheubarth, Rhys heard rumours that Owain Gwynedd was planning to invade Ceredigion in order to reclaim it for Gwynedd. Rhys responded by building a castle at Aberdyfi in 1156. The threatened invasion did not take place, and Turvey claims that Owain's intention may have been to test the resolve of the new ruler.

King Stephen had died in October 1154, bringing to an end the long dispute with the Empress Matilda which had helped Anarawd, Cadell and Maredudd to extend their rule in Deheubarth. With disunity within the realm no longer a problem, the new king of England, Henry II, soon turned his attention to Wales. He began with an invasion of Gwynedd in 1157. This invasion was not entirely successful, but Owain Gwynedd was induced to seek terms and to give up some territory in the north-east of Wales.

The following year, Henry prepared an invasion of Deheubarth. Rhys made plans to resist, but was persuaded by his council to meet the king to discuss peace terms. The terms were much harsher than those offered to Owain: Rhys was stripped of all his possessions apart from Cantref Mawr, though he was promised one other cantref. The other territories were returned to their Norman lords.

Among the Normans who returned to their holdings was Walter de Clifford, who reclaimed Cantref Bychan, then invaded Rhys's lands in Cantref Mawr. An appeal to the king produced no response, and Rhys resorted to arms, first capturing Clifford's castle at Llandovery then seizing Ceredigion. King Henry responded by preparing another invasion, and Rhys submitted without resistance. He was obliged to give hostages, probably including his son Hywel.

The king was absent in France in 1159, and Rhys took the opportunity to attack Dyfed and then to lay siege to Carmarthen, which was saved by a relief force led by Earl Reginald of Cornwall. Rhys retreated to Cantref Mawr, where an army led by five earls, the Earls of Cornwall, Gloucester, Hertford, Pembroke and Salisbury, marched against him. The earls were assisted by Cadwaladr, brother of Owain Gwynedd, and Owain's sons, Hywel and Cynan. However they were forced to withdraw and a truce was arranged. In 1162, Rhys again attempted to recover some of his lost lands, and captured Llandovery castle. The following year Henry II returned to England after an absence of four years and prepared for another invasion of Deheubarth. Rhys met the king to discuss terms and was obliged to give more hostages, including another son, Maredudd. He was then seized and taken to England as a prisoner. Henry appears to have been uncertain what to do with Rhys, but after a few weeks decided to free him and allow him to rule Cantref Mawr. Rhys was summoned to appear before Henry at Woodstock to do homage together with Owain Gwynedd and Malcolm IV of Scotland.

In 1164 all the Welsh princes united in an uprising. Warren suggests that when Rhys and Owain were obliged to do homage to Henry in 1163 they were forced to accept a status of dependent vassalage instead of their previous client status, and that this led to the revolt. Rhys had other reasons for rebellion, for he had returned to Deheubarth from England to find that the neighbouring Norman lords were threatening Cantref Mawr. His nephew, Einion ab Anarawd, who was the captain of his bodyguard, had been murdered at the instigation of Roger de Clare, Earl of Hertford. The murderer had been given the protection of the Clares in Ceredigion. Rhys first appealed to the king to intercede; when this failed, he invaded Ceredigion and recaptured all of it apart from the town and castle of Cardigan. The Welsh revolt led to another invasion of Wales by King Henry in 1165. Henry attacked Gwynedd first, but instead of following the usual invasion route along the north coast he attacked from the south, following a route over the Berwyn hills. He was met by the united forces of the Welsh princes, led by Owain Gwynedd and including Rhys. According to "Brut y Tywysogion":

Torrential rain forced Henry's army to retreat in disorder without fighting a major battle, and Henry vented his spleen on the hostages, having Rhys's son Maredudd blinded. Rhys's other son, Hywel, was not among the victims. Rhys returned to Deheubarth where he captured and burned Cardigan Castle. He allowed the garrison to depart, but held the castellan, Robert Fitz-Stephen, as a prisoner. Shortly afterwards Rhys captured Cilgerran castle.

In 1167 he joined Owain Gwynedd in an attack on Owain Cyfeiliog of southern Powys, and spent three weeks helping Owain besiege the Norman castle of Rhuddlan. In 1168 he attacked the Normans at Builth, destroying its castle. Rhys benefited from the Norman invasion of Ireland in 1169 and 1170, which was largely led by the Cambro-Norman lords of south Wales. In 1167 the King of Leinster, Diarmait Mac Murchada, who had been driven out of his kingdom, had asked Rhys to release Robert Fitz-Stephen from captivity to take part in an expedition to Ireland. Rhys did not oblige at the time, but released him the following year and in 1169 Fitz-Stephen led the vanguard of a Norman army which landed in Wexford. The leader of the Norman forces, Richard de Clare, 2nd Earl of Pembroke, known as "Strongbow", followed in 1170. According to Warren:

The departure of the Norman lords enabled Rhys to strengthen his position, and the death of Owain Gwynedd in late 1170 left him as the acknowledged leader of the Welsh princes.

In 1171 King Henry II arrived in England from France, on his way to Ireland. Henry wished to ensure that Richard de Clare, who had married Diarmait's daughter and become heir to Leinster, did not establish an independent Norman kingdom in Ireland. His decision to try a different approach in his dealings with the Welsh was influenced by the events in Ireland, although Warren suggests that "it seems likely that Henry began rethinking his attitude to the Welsh soon after the débâcle of 1165". Henry now wished to make peace with Rhys, who came to Newnham to meet him. Rhys was to pay a tribute of 300 horses and 4,000 head of cattle, but was confirmed in possession of all the lands he had taken from Norman lords, including the Clares. They met again in October that year at Pembroke as Henry waited to cross to Ireland. Rhys had collected 86 of the 300 horses, but Henry agreed to take only 36 of them and remitted the remainder of the tribute until after his return from Ireland. Rhys's son, Hywel, who had been held as a hostage for many years, was returned to him. Henry and Rhys met once more at Laugharne as Henry returned from Ireland in 1172, and shortly afterwards Henry appointed Rhys "justice on his behalf in all Deheubarth". According to A. D. Carr:

The agreement between Henry and Rhys was to last until Henry's death in 1189. When Henry's sons rebelled against him in 1173 Rhys sent his son Hywel Sais to Normandy to aid the king, then in 1174 personally led an army to Tutbury in Staffordshire to assist at the siege of the stronghold of the rebel Earl William de Ferrers. When Rhys returned to Wales after the fall of Tutbury, he left a thousand men with the king for service in Normandy. King Henry held a council at Gloucester in 1175 which was attended by a large gathering of Welsh princes, led by Rhys. It appears to have concluded with the swearing of a mutual assistance pact for the preservation of peace and order in Wales. In 1177 Rhys, Dafydd ab Owain, who had emerged as the main power in Gwynedd, and Cadwallon ap Madog from Rhwng Gwy a Hafren swore fealty and liege homage to Henry at a council held at Oxford. At this council the king gave Meirionnydd, part of the kingdom of Gwynedd, to Rhys. There was some fighting in Meirionnydd the following year, but Rhys apparently made no serious attempt to annex it.

Rhys built a number of stone castles, starting with Cardigan castle, which was the earliest recorded native-built stone castle in Wales. He also built Carreg Cennen castle near Llandeilo, a castle set in a spectacular position on a mountain top. He held a festival of poetry and song at his court at Cardigan over Christmas 1176. This is generally regarded as the first recorded Eisteddfod. The festival was announced a year in advance throughout Wales and in England, Scotland, Ireland and possibly France. Two chairs were awarded as prizes, one for the best poem and the other for the best musical performance. J. E. Caerwyn Williams suggests that this event may be an adaptation of the similar French "puys". R.R. Davies suggests that the texts of Welsh law, traditionally codified by Hywel Dda at Whitland, were first assembled in book form under the aegis of Rhys.
Rhys founded two religious houses during this period. Talley Abbey was the first Premonstratensian abbey in Wales, while Llanllyr was a Cistercian nunnery, only the second nunnery to be founded in Wales and the first to prosper. He became the patron of the abbeys of Whitland and Strata Florida and made large grants to both houses. Giraldus Cambrensis, who was related to Rhys, gives an account of his meetings with Rhys in 1188 when Giraldus accompanied Archbishop Baldwin around Wales to raise men for the Third Crusade. Some Welsh clerics were not happy about this visit, but Rhys was enthusiastic and gave the Archbishop a great deal of assistance. Giraldus says that Rhys decided to go on crusade himself and spent several weeks making preparations, but was eventually persuaded to change his mind by his wife Gwenllian, "by female artifices".

Henry II died in 1189 and was succeeded by Richard I. Rhys considered that he was no longer bound by the agreement with King Henry and attacked the Norman lordships surrounding his territory. He ravaged Pembroke, Haverfordwest, and Gower and captured the castles of St. Clear's, Laugharne, and Llansteffan. Richard's brother, Prince John (later King John), came to Wales in September and tried to make peace. He persuaded Rhys to raise the siege of Carmarthen and accompany him to Oxford to meet Richard. Rhys arrived at Oxford to discover that Richard was not prepared to travel there to meet him, and hostilities continued.

In his later years Rhys had trouble keeping control of his sons, particularly Maelgwn and Gruffydd. In 1189 Gruffydd persuaded Rhys to imprison Maelgwn, and he was given into Gruffydd's keeping at Dinefwr. Gruffydd handed him over to his father-in-law, William de Braose. Gruffydd is also said to have persuaded his father to annex the lordship of Cemais and its chief castle of Nevern, held by William FitzMartin, in 1191. This action was criticized by Giraldus Cambrensis, who describes Gruffydd as "a cunning and artful man". William FitzMartin was married to Rhys's daughter Angharad, and, according to Giraldus, Rhys "had solemnly sworn, by the most precious relics, that his indemnity and security should be faithfully maintained". Rhys had also annexed the Norman lordships of Cydweli and Carnwyllion in 1190. In 1192 Rhys secured Maelgwn's release, but by now Maelgwn and Gruffydd were bitter enemies. In 1194 Rhys was defeated in battle by Maelgwn and Hywel, who imprisoned him in Nevern castle, though Hywel later released his father without Maelgwn's consent. Giraldus suggests that Rhys's incarceration in Nevern castle was divine vengeance for the dispossession of William FitzMartin. In 1195 two other sons, Rhys Gryg and Maredudd, seized Llanymddyfri and Dinefwr, and Rhys responded by imprisoning them. Rhys launched his last campaign against the Normans in 1196. He captured a number of castles, including Carmarthen, Colwyn, Radnor and Painscastle, and defeated an army led by Roger de Mortimer and Hugh de Say near Radnor, with forty knights among the dead. This was Rhys' last battle. William de Braose offered terms, and Painscastle was returned to him.

Rhys died on 28 April 1197, unexpectedly, and was buried in St David's Cathedral. The chronicler of "Brut y Tywysogion" records for 1197:

Rhys died excommunicate, having quarreled with the Bishop of St. David's, Peter de Leia, over the theft of some of the bishop's horses some years previously. Before he could be buried in the cathedral, the bishop had his corpse scourged in posthumous penance.

Rhys had nominated his eldest legitimate son, Gruffydd ap Rhys, as his successor, and soon after his father's death Gruffydd met the Justiciar, Archbishop Hubert Walter, on the border and was confirmed as heir. Maelgwn, the eldest son but illegitimate, refused to accept this and was given military assistance by Gwenwynwyn ab Owain of Powys. Maelgwn took the town and castle of Aberystwyth and captured Gruffydd, whom he handed over to the custody of Gwenwynwyn. Gwenwynwyn later handed him over to the king, who imprisoned him at Corfe Castle. Gruffydd was set free the following year and regained most of Ceredigion. In 1201 Gruffydd died, but this did not end the fighting between rival claimants. In 1216 Llywelyn the Great of Gwynedd held a council at Aberdyfi where he allocated parts of Deheubarth to several sons and grandsons of Rhys.

Giraldus Cambrensis frequently mentions Rhys in his writings and describes him as "a man of excellent wit and quick in repartee". Gerald tells the story of a banquet at Hereford in 1186 where Rhys sat between two members of the Clare family. What could have been a tense affair, since Rhys had seized lands in Ceredigion previously held by the Clare family, passed off with an exchange of courteous compliments, followed by some good-natured banter between Rhys and Gerald about their family connections. Rhys gave Gerald and Archbishop Baldwin a great deal of assistance when they visited Wales to raise troops for the crusade in 1188, and Gerald several times refers to his "kindness" and says that Rhys accompanied them all the way from Cardigan to the northern border of Ceredigion "with a liberality peculiarly praiseworthy in so illustrious a prince".

Another contemporary writer also wrote of Rhys if Roger Turvey is correct in stating that Walter Map's piece "Of the King Appollonides" deals with Rhys under a pseudonym. Map was less favourably disposed toward Rhys, describing him as "This king I have seen and know, and hate", but goes on to say "I would not have my hatred blacken his worth; it is not my wish ever to suppress any man's excellence through envy". He tells the following story about Apollonides/Rhys:

Davies provides the following assessment of Rhys:

Davies also notes two flaws in Rhys's achievement. One was the personal nature of his accord with Henry II, which meant that it did not survive Henry's death. The other was his inability to control his sons and to force the other sons to accept Gruffydd as his successor.

Rhys had at least nine sons and eight daughters. Confusingly, three of the sons were named Maredudd and two of the daughters were named Gwenllian.






</doc>
<doc id="26534" url="https://en.wikipedia.org/wiki?curid=26534" title="Rachel Summers">
Rachel Summers

Rachel Anne Summers (also known as Rachel Grey) is a fictional superheroine appearing in American comic books published by Marvel Comics. The character was created by writer Chris Claremont and artist/co-writer John Byrne.

In her first appearance, the character's surname was not revealed; later publications and retcons further expanded her backstory to involve central characters of mainstream continuity. She is the daughter of the alternate future counterparts to Cyclops (Scott Summers) and Jean Grey-Summers from a harsh dystopia, the sister of Nate Grey and half sister of Cable, a niece of Havok and Vulcan, and a powerful mutant in her own right. She inherited her mother's vast telepathic and telekinetic talents, and code names Phoenix and Marvel Girl before later adopting her own code name Prestige. Although the character is considered unique to the Marvel Comics "multiverse", her name has been used to designate the mother of Marvel characters Hyperstorm and Dream Richards in respective timelines.

Rachel first appeared in "The Uncanny X-Men" #141 (January 1981) and has since been affiliated with several comic book superhero teams including the X-Men and Excalibur.

Rachel Anne Summers comes from an alternate future Earth known as Earth-811, as seen in the "Days of Future Past" storyline from "The Uncanny X-Men" #141–142. In this reality, the assassination of Senator Robert Kelly provoked the ratification of the Mutant Registration Act, leading to a dystopian future where the mutant-hunting Sentinel robots rule North America. Rachel was abducted by operatives working for Ahab, who used drugs and hypnotherapy to turn Rachel into a "Hound", a mutant who tracks down other mutants. She fulfilled her duties, but her psychic powers linked her to her victims; fueling her grief and despair until she attacked Ahab and scarred him. In return, he sent her to the mutant concentration camps. There, she befriended the surviving mutant rebels, including Wolverine, Magneto, Colossus, Storm, Kate Pryde, and her lover, the adult Franklin Richards.

Rachel managed to send Kate's consciousness into the past to her younger self to prevent the assassination, but it did not change their time. Rachel sent her astral form into the past to find out why and discovered she had sent Kate into an alternate past. On the way back, she encountered the disembodied Phoenix Force and it followed her to her present. Rachel passed out from the strain of astral projection and the Phoenix Force revealed itself to Kate, who asked it to give Rachel a fresh start.

When Rachel and Kate broke into "Project: Nimrod" on a suicide mission to destroy a new model of Sentinel, they became trapped. When Kate spoke the words "Dark Phoenix," the Phoenix Force ripped Rachel from her timeline and sent her body back to the alternate past to which she had sent Kate's consciousness. This was a past where she learned Jean Grey was dead and that her father was married to someone else. Rachel experienced additional heartache and displacement trauma when she discovered that her father's new wife, Madelyne Pryor, was pregnant with a son (Nathan Summers), because in her timeline she was the first-born child of Scott Summers.

Rachel had a brief membership in the X-Men before finding a Shi'ar holoempathic crystal at her grandparents' home. The crystal was imprinted with a portion of Rachel's mother's essence inside it as a tribute to the family shortly after Jean Grey's death. After Rachel took a vow to remember her mother with the uniform and name of Phoenix, the Phoenix Force fully bonded with her. She was granted access to its power on a cosmic magnitude, albeit in a much more limited fashion than the Dark Phoenix. Soon after, the grudge which she had begun with Selene boiled over when Rachel secretly invaded the Hellfire Club. She did this with the intention of taking vengeance on Selene for the murders she had committed, particularly that of nightclub owner Nicholas Damiano, who had previously taken Rachel into his home after Selene had attacked her. Selene proved to be no match for Rachel's newly increased powers, but just as she was about to finish Selene, Wolverine arrived and was forced to stab Rachel in the chest. Critically injured, Rachel was lured into Spiral's "Body Shoppe."

Months later, while recuperating from injuries on Muir Island, Shadowcat and Nightcrawler both had the same dream, where they were actors on a weird set and helped Rachel, who was trapped there, escape. Shortly thereafter, Rachel escaped from the alternate reality of Mojoworld. Rachel has once been cited having a flashback to her time there where she is held in chains and tortured. The three former X-Men were joined by Captain Britain and Meggan and founded the British superhero team Excalibur. While part of the team, she discovered that this universe's version of her mother, Jean Grey, was alive. She attempted to bond with Jean, but Jean, upon discovering Rachel was the present host for the Phoenix, rejected any contact with her. Jean still resented the Phoenix Force for stealing a portion of her life. She also rejected Rachel because she felt that Rachel's existence was a constant reminder of the dystopian future she feared could still come to pass. Eventually, however, Jean moved past those feelings and formally welcomed Rachel into her life.

Rachel remained with Excalibur until an incident caused Captain Britain to be lost in the timestream. She exchanged places with the time-lost Captain Britain and emerged two thousand years in the future, in a world conquered by Apocalypse and crushed under his iron fist. She gathered together a group of rebels and founded the Askani. She trained one of her followers to travel back in time and bring her "brother" Nathan forward in time when he was infected with a techno-organic virus. The Askani cloned Nathan in case he was not able to survive the virus. Apocalypse's followers attacked the Askani and took the clone (who would later become the supervillain Stryfe), leaving Rachel critically injured. Hooked up to life support, she drew the minds of Scott and Jean into the future, as "Slym" and "Redd", to raise Nathan and tutor him in the use of his powers. Rachel finally died ten years later and sent Scott and Jean back to their original bodies seconds after they had left.

After Nathan, now known as Cable, had finally defeated Apocalypse, he went into the timeline to retrieve Rachel. There, he discovered a Rachel "sans" Phoenix Force. With the premature death of Apocalypse, the Askani timeline had been diverged from the mainstream Marvel Universe, Earth-616. As a result, she had been flung into the far future, yet subjectively a short time after she had been lost in the timestream, as the slave of a creature called "Gaunt", who had used her to lead Cable there for a "battle of the ages". Cable defeated Gaunt in the battle and Rachel, now free, was able to use her residual Phoenix Force to return them both to the present. She then decided to take a break from superheroics and enrolled in college after she made Cable promise he would not tell anyone she was back. Despite her efforts to live a normal life, however, she was kidnapped by the telepath Elias Bogan and subsequently rescued by the X-Men.

She decided to rejoin the X-Men, taking the name "Marvel Girl" to honor her mother (who had recently died yet again) and wearing a costume her mother had designed but never worn; a variation on Jean's first green costume. She also changed her last name to "Grey", possibly to express disapproval at her father's betrayal of Jean, as well as his continuing relationship with Emma Frost; though she and Emma made a truce of sorts during one of the team's missions in Hong Kong. Rachel and Nightcrawler began to have an attraction towards each other, kissing at one point, but nothing came of it as Nightcrawler also had an attraction to Storm at the time, who was in somewhat of a romantic "friendship" with Wolverine. Her stint with this team also included a visit to the Savage Land. In the storyline "World's End", which was heavily criticized by readers, Rachel was subjected to the mind-control of a tribe of advanced dinosaur people, the Hauk'ka, causing her to believe she belonged to their species. Afterward, she subconsciously used her telekinesis to change her own genome in their image. This was eventually reverted. After "House of M" and "Decimation", where most of the world's mutants lost their powers, the government had Sentinels instituted at the X-Mansion to protect the mutants in case any enemies used this low point to attack. Though their intentions were good this time, it reminded Rachel too much of the previous timeline when Sentinels herded mutants into concentration camps.

Rachel had a short stint with newly re-formed Excalibur, reminiscent of the former team, shortly after the "House of M" events. She assisted the team in battling Shadow-X and the Shadow King (in the guise of Professor X).

Rachel spent some time with her grandparents, bonding with her grandfather. At a family reunion with all her relatives, a commando unit under the order of the Shi'ar attacked the party, killing everyone in an effort to wipe out the Grey genome. The commando unit was unable to kill Rachel; instead, one member was able to graft a "deathmark" on her back that would allow them to find her wherever she went. It is assumed that the only remaining member of the Grey family now left on Earth besides Rachel is Cable. Afterward, at the graves of the Grey family, Rachel vowed a terrible vengeance on the Shi'ar and was quoted as saying, "I'm not my mom. I'm not the Phoenix. I'm my own woman. And by the time I'm done... they'll wish I "was" the Phoenix."

The Death Commandos later tracked Rachel to the psychiatry office of Dr. Maureen Lyszinski. Rachel, with the help of Psylocke, Nightcrawler, Bishop, and Cannonball, saved the doctor and took down the Death Commandos. She decided to imprison them, instead of killing them, by telling them, "I mean to find destiny in a way that brings us both [Jean Grey] honor." She is also sometimes referenced as "Starchilde" in this series.

After Rachel was kidnapped, along with Cyclops, by her paternal uncle Vulcan, he freed Darwin from inside him. Later, Professor X recruited Rachel, along with Havok, Nightcrawler, Warpath, Darwin, and Polaris, for a space mission to stop Vulcan from laying waste to the Shi'ar empire. Xavier, who recently was stripped of his powers, recruited Rachel to serve as his telepathic "eyes and ears" during their mission. Aware of Rachel's vendetta against the Shi'ar, Xavier agreed to use their trip into space to find out who in the Shi'ar Empire gave the order to wipe out all members of the Grey family, and he warned Rachel that they will deal with the people responsible for her recent losses Xavier's way.

While in space, the team was attacked by Korvus, a Shi'ar warrior sent to kill Rachel. Korvus' ancestor, Rook'shir, was a previous host of the Phoenix Force, and a small portion of the Phoenix's power was left behind in his sword, the Blade of the Phoenix. With this power, Korvus made short work of the other X-Men, but when Rachel blocked the sword, their minds were involuntarily linked. Through this link, Rachel learned that Korvus' family was also murdered by the Shi'ar government because of their connection to the Phoenix. The remaining echo of the Phoenix power from the sword was then transferred to Rachel. Rachel claimed that rather than having taken the power, the power chose to go to her, saying, "The Phoenix knows me, remember? It likes me." When this happened, Rachel's normally gold energy aura turned blue, the same color as the Blade of the Phoenix. She then telekinetically disabled an explosive implant that the Shi'ar chancellor was using to force Korvus' obedience.

Due to Rachel's connection to Korvus through the sword, she discovers the Phoenix Force formerly in the blade is just an echo, a "blue shadow", of the Force. The shadow of the Phoenix begins influencing Rachel's behavior, causing her to design a new darker uniform and begin a romance with Korvus. She soon breaks off the relationship after she realizes their bond is only because of the residual Phoenix Force.

Leading up to the fight with Vulcan, Rachel is shown using her powers to kill the guards who stand in her way. Havok warns her not to, but Rachel tells him that they deserve to die after what they did to her family. When it comes to the big fight, Rachel shows just how powerful she is by protecting Korvus from one of Vulcan's blasts. Rachel is one of the X-Men stranded in Shi'ar space when their ship is sent back to Earth.

After the death of her other grandfather, Corsair, at the hands of Vulcan, she, along with Havok, Polaris, Korvus, Ch'od, and Raza, become the new Starjammers. They elect to remain in Shi'ar space and restore Lilandra to the throne or die trying. As her uncle states, "If they fail, he has no doubt that Vulcan will head for Earth."

During the conflict, the Starjammers find another threat in the form of the Scy'ar Tal (translates as "Death to the Shi'ar"). Rachel makes contact with the eldest Scy'ar Tal and discovers their true origin. The Scy'ar Tal were originally called the M'Kraan. Early in their history, the Shi`ar attacked them, killing a great number of their people and making the rest flee for their lives. Eventually, the Shi'ar settled on their planet, took the M'Kraan Crystal as their own, and passed down the legend of the M'Kraan Crystal as a sacred gift from their deities, Sharra and K'ythri. The M'Kraan then changed their name to Scy'ar Tal and devoted their culture and society to the destruction of the Shi`ar Empire. With their first attack, they destroyed Feather's Edge by transporting a star to obliterate it. After which, Vulcan made contact with the Starjammers to call a temporary ceasefire.

During the ceasefire, Rachel comes into contact with the Death Commandos again and attempts to kill them to avenge the deaths of her relatives; however, she is deterred by Polaris. At the end, all the Starjammers are captured by the Shi'ar except Rachel, Korvus, and Lilandra.

Rachel and the Starjammers play a large role in the sequel to the "Emperor Vulcan" miniseries called "X-Men: Kingbreaker". She is also seen prominently in the "War of Kings" storyline, which features Vulcan, the Inhumans, Nova, and the Guardians of the Galaxy.

While with the Starjammers, in battle with Vulcan's new guard, the fragment of the "blue" Phoenix within her and Korvus' blade mysteriously leaves them. After the Phoenix echo leaves Rachel, she says "please... not now... Mom." From this frame onward, the "hound" markings reappear on Rachel's face.

In agreement with the Inhumans, the Starjammers and the Guardians of the Galaxy assault a Shi'ar vessel in order to free Lilandra, hoping to end the conflict while restoring her to the throne. Even without her Phoenix powers, Rachel is powerful enough to entrap Gladiator in an illusion in order to keep him distracted from battle. Their gambit pays off and the group is able to free Lilandra.

Rachel is next seen as Lilandra's bodyguard along with the rest of the Starjammers. On the home planet of the Shi'ar, Lilandra assumes her throne, but while making a ceremonial gesture is killed by the murderer known as Razor, who possesses the Darkhawk armor. The only person who perceives this is Rachel, since Razor is shielded from the perceptions of others.

After Lilandra is assassinated, Rachel fights alongside the Starjammers against the Shi'ar Guard and Araki, who has summoned the same Shi'ar commandos that killed Rachel's family and branded her with the Shi'ar death mark. Rachel uses her powers to implode Black Cloak's head, saying, "He was the one... He killed my family," though killing him does not make her feel happier. Gladiator finishes the job by killing Araki himself. Rachel, along with the rest of the Starjammers, regroup later on and mourn the Shi'ar, as they doubt that they will recover from this war.

It is known through Ch'od, and apparently due to the incident where she and Korvus both lost the connection to the Phoenix Force, that Rachel and Korvus, along with Havok and Polaris, have departed for Earth.

While on the way back to Earth, Rachel attempted to contact Professor Xavier or Emma Frost with a message. However at that moment, Moira (a powerful alternate personality of the mutant Legion) warped reality taking Rachel's mind with it creating the amnesic Revenant. Once reality was restored, Rachel's mind is separated from her body which according to her is "half a universe away". Because of Moira's actions, Rachel no longer remembers the message and her mind retains the form of her Age of X counterpart. Scott promised her that they would return her home.

Being actually a mental manifestation, Rachel soon began fading. She asks Rogue to connect with her to see what will happen. When the two of them touch, Rogue sees a vision of where Rachel, Havok and Polaris are as Rachel then returns to her body. When she awakens she is met by an unseen villain holding a gun and telling her he has killed her friends.

Borrowing one of Legion's manifold powers, Rogue teleports alongside Gambit, Magneto and Frenzy to rescue their teammates on the other side of the galaxy. Once there, Rachel is retrieved from a band of pirates as Rogue becomes their new leader. The remaining X-Men discover they've arrived at a space station called Gul Damar which is in a state of upheaval due to the rebellion of insectoid creatures called Grad Nan Holt against their Shi'ar enslavers. They are also being pulled into an exploding sun and the entire civil war is revealed to be orchestrated by a powerful Grad Nan Holt telepath known as "Friendless." A number of battles with the creature proves unsuccessful for Rachel, but with the combined efforts of Rogue and the X-Men they are able to defeat him and return home via the wormhole that was created from the collapsing star.

Rachel as part of a team of Wolverine's X-Men attempted to psychically battle Exodus in an attempt to prevent the assassination of Cyclops. The team is eventually beaten and the X-Men are saved by Generation Hope.

Rachel is then invited to hold a position as senior staff member of the "Jean Grey School for Higher Learning," which was rebuilt from the Xavier Institute and has Wolverine as acting Headmaster and Kitty Pryde as Headmistress.

During the events of AVX, when the X-Men on Utopia escape from the invading Avengers, Rachel contacts Cyclops to provide Hope's location. Afterwards, Rachel states that she knows the Phoenix Force better than anyone else on Earth and that she is living proof that it can be controlled. She also says that if the Phoenix has chosen her and that is the destiny that Hope wants, she will do everything in her power to help her. She and Iceman tell Wolverine at the school that they are going to help Cyclops in the battle. However, when Cyclops and Emma Frost begin to be corrupted by the Phoenix's power, she, like the other X-Men, decide to oppose their rule. Rachel then battled against Cyclops and helped both the Avengers and X-Men in the final battle.

In 2013, Marvel revealed an all new all female series simply named "X-Men". Written by Brian Wood with art by Olivier Coipel, "X-Men" will feature an all female cast including Storm, Jubilee, Rogue, Kitty Pryde, Rachel Grey and Psylocke.

The X-Men are in pursuit of Arkea who has attempted to revive the X-Men's long lost enemies. The X-Men are attacked by the newly formed Sisterhood and Rachel is telepathically locked down by Madelyne Pryor. Storm strikes a deal for Rachels freedom allowing Madelyne and Selene to walk free.

In the AXIS story arc, Storm sends the entire student body against the Red Onslaught in an attempt to save Earth. Rachel is shown to be reverted to her hound form by Dr. Doom and Wanda Maximoffs spell.

Rachel is part of Storm's team of Amazing X-Men who attempts to stop the Living Monolith from becoming the new Juggernaut.

Rachel Grey is distrusting of Spider-Man's newly appointed position as Jean Grey School guidance counseller. Using her telepathy she seeks to expose his secret identity only to lose that memory by being mind-wiped by Martha Johansson.

Rachel is shown as a teacher at the Jean Grey Institute in the battle against Kenji.

When Kitty Pryde returns from space to lead the X-Men, Rachel joins her team in "X-Men Gold" and adopts the unique, new code name Prestige.

Rachel possesses various psionic abilities, generally exhibited through telepathy, psychometry, telekinesis, and limited time manipulation.

Marvel Girl's "virtually unlimited" telepathy allows her to receive, broadcast, and manipulate cognitive processes (such as thoughts) in an intricate manner. Examples of Rachel's aptitudes for this include creating durable mind-links across distances, projecting blasts of psionic energy that disrupt aspects of brain functioning, shielding her mind from other telepaths, creating illusions, and rendering someone imperceptible to the five senses. In addition, Rachel has demonstrated the ability to telepathically suppress superpowers; control, repair, and exchange minds; as well as safely editing memories. Rachel has also harnessed her telepathy to sense, locate, and track other sentient beings based on their thought patterns, but has a moral apprehension about using this skill due to her experiences as a Hound.

It has been suggested that Rachel's telepathy, although immeasurable in raw power, is mitigated by her limited training and finesse. Emma Frost was able to outflank an incredulous Rachel in a contest on the astral plane. In the same issue, Emma offered her educative services; and later still, Rachel received training from Professor Charles Xavier (while he was depowered), giving her access to his vast knowledge and expertise in telepathy.

By using telekinesis, Marvel Girl can remotely manipulate matter even on a sub-atomic level. She can channel this ability to create protective force fields and blasts of concussive force. By using her telekinesis to levitate herself, Marvel Girl can fly at incredible speeds. Rachel has been able to create a micro black hole, levitate an entire city for a time, sustain shields that withstood Jovian atmospheric pressures, and direct blows from Thor's hammer, Mjolnir. Moreover, Rachel's telekinetic fine-motor control has allowed her to alter molecular valences, mentally alter clothing with ease, create a telekinetic/psionic sword (much like Psylocke's telekinetic katana), a telekinetic hammer powerful enough to knock Thor off his feet, and even rewrite human genomes.

While all depictions portray Rachel as an extremely powerful telekinetic, the limitations of her hard-psi capabilities have been somewhat inconsistent. Some instances have depicted Rachel's telekinetic potential to be nigh-unlimited, whereas others have shown her struggling against, and even outmatched by, lesser developed telekinetics such as Psylocke.

Marvel Girl utilizes her psionic talents in conjunction with her ability to manipulate time in a variety of ways. "Chronoskimming" describes her ability to temporarily transplant a person's mind and send it through time into a younger/older version, a close ancestor/descendant, or as a disembodied astral form.
Rachel unconsciously emanates a fourth dimensional pulse, effectively creating a chrono-shield that protects her from changes in the timeline. She can also sense and manipulate residual psychic energy in the form of psychometry.

When Rachel was bonded to the cosmic entity known as the Phoenix Force, she demonstrated heightened psi-powers, the ability to manipulate energy and life-forces, and limited cosmic awareness. Rachel's connection to the Phoenix power was lost in the distant future and did not return with her when she traveled back to the early 21st century (present) of Earth-616 (Marvel's mainstream universe).

Most recently, Marvel Girl absorbed a residual echo of the Phoenix Force left in the sword of a previous host, a Shi'ar named Rook'shir. It was revealed that this energy source was a less powerful (but easier to wield) form of the Phoenix Force. The echo was powerful enough to allow Rachel to survive in and fly through the vacuum of space without the need for additional protection, as well as being able to hold her own in combat against the tremendous physical power of Gladiator. These demonstrations were short lived, however, due to its disappearance, which Rachel attributes to Jean Grey. She now exhibits her standard power levels.

As a host for the Phoenix Force, Rachel manifested the cosmic firebird in displays of great power. During her 2000s "Uncanny X-Men" appearances, Marvel Girl also exhibited a Phoenix emblem over her left eye whenever she demonstrated psionic feats. It was at first accompanied by a "shadow form" (similar to the one Jean Grey manifested when she absorbed the telepathic powers of Psylocke). However, the illustration of this shadow form ceased without explanation. After regaining a small portion of the Phoenix Force (echo), the emblem over her eye changed from a gold Phoenix shape to a static version made of electric blue flame. Her display of power was once more altered in "X-Men: Emperor Vulcan" #3, where she produced the familiar fiery raptor with which the Phoenix Force is commonly associated (see profile image).

At times, Rachel has been shown to learn new skills extremely quickly. For example, she mastered a set of "demon ninja" sword skills simply by watching her teammate Shadowcat perform them. Along with sword fighting, Rachel has experience in lock-picking, vehicular repair (such as engines), and use of advanced technology and weaponry. However, these abilities have not been evident in her more recent appearances.

Rachel's power level and scope of abilities have been inconsistently described by writers over the years. However, she is usually depicted with "virtually unlimited" potential in her dual psionic talents. In most cases, she displayed greater feats as the Phoenix and even matched Gladiator's strength with the aid of a "Phoenix echo". Rachel is considered by many to be an Omega-level mutant (like her mother), but the only literary reference to this attribute is when the future Sentinel, Nimrod, classified Rachel as an "Omega class subject" several years before the term was established in Marvel canon.

Even with the omnipotent strength of the Phoenix, magic and magical objects are able to resist Rachel's powers. When the Soulsword appeared near the Excalibur lighthouse headquarters seeking Kitty Pryde to become its new wielder, Rachel attempted to remove it from bedrock to alleviate her friend's apprehension. Despite using the full extent of power permitted by the Phoenix Force, Rachel was unable to remove the sword, surmising that only Kitty could remove it.

In the very first issue of the "Uncanny X-Men" story arc "Season of the Witch", Rachel and Psylocke were transported to the White Hot Room as an indirect result of the reality-shift performed by a mentally unstable Scarlet Witch. While there, it was established that the Rachel appearing in Earth-616 (originally from Earth-811) has no true alternate counterparts within the Marvel multiverse. Rather, all other incarnations of "Rachel Summers" that exist in parallel timelines (see below) are linked only by having the same name, or attributes.

The subsequent issues had Rachel and Psylocke return to their dimension and thus be engrossed in the Scarlet Witch's reconstruction of the world. In this reality, Rachel was the bodyguard and traveling companion to Psylocke, who was crowned British royalty after her brother, Brian, became ruler of all England. Rachel then became involved with Captain Britain's mission to seal the breach in reality (rift) that was created by the Scarlet Witch's manipulations.

In at least three alternate future timelines derived from "Days of Future Past", a Rachel Summers married Franklin Richards and procreated mutant children. One such child was the time-traveling supervillain Hyperstorm (Jonathan Richards). Hyperstorm was responsible for causing the Fantastic Four to think that Mister Fantastic (Jonathan's grandfather) and Doctor Doom were dead; he was only defeated when he was trapped in another dimension by Galactus. The second child was Dream Summers, who possessed empathic superpowers. She was a superhero who appeared in the "Spider-Man/X-Men: Time's Arrow" trilogy of novels (although Marvel Comics novels tend to be considered non-canon). In a third reality, they produced a child named David Richards, who was rescued from a concentration camp by the interdimensional traveling Exiles and raised by the "Age of Apocalypse" version of Sabretooth. David's traumatic experiences at the camp motivated him to become a fanatical murderer.

In another variation of the "Days of Future Past", shown in "Weapon X: Days of Future Now", a Rachel Summers was captured by Weapon X and detained in the "Neverland" concentration camp.

In the so-called "Legacy Earth" reality, in which the Legacy Virus mutated into a techno-organic plague, a Rachel Summers was a member of the Avengers, the last superhero group. At Morph's behest, she contacted Thor and the Asgardians to help them against the Vi-Locks, a race of beings infected with the techno-organic virus.

The miniseries "" (written by Chris Claremont) details the last adventures of the X-Men in a possible future. In this reality, Rachel played a central role, and was the political campaign manager of Kitty Pryde (Chicago mayoral candidate). However, she abandoned this position after Cassandra Nova led a series of attacks on the X-Men and their allies. She traveled alongside Cable into Shi'ar space. After a Professor X was taken hostage by Nova, and she entered his psyche in order to free him. However, Nova traps her and Lilandra within. She seemingly kills them both, but Rachel used the power of the Phoenix to save herself and incapacitates Nova. They leave Xavier's mind and continue the battle in Rachel's mind, where Rachel is overpowered. Cassandra, using Rachel's body, kills Jean Grey and Cyclops, leaving Rachel forced to watch the ordeal. Nova then leaves Rachel's body, stealing the Phoenix force. The Phoenix being the only thing keeping her alive after her Cassandra destroyed her mental form, she simply died.






</doc>
<doc id="26535" url="https://en.wikipedia.org/wiki?curid=26535" title="Richard of Saint Victor">
Richard of Saint Victor

Richard of Saint Victor (died 1173) was a Medieval Scottish philosopher and theologian and one of the most influential religious thinkers of his time. A canon regular, he was a prominent mystical theologian, and was prior of the famous Augustinian Abbey of Saint Victor in Paris from 1162 until his death in 1173.

Very little is known about the origins and upbringing of Richard of Saint Victor. John of Toulouse wrote a short "Vita" of Richard in the seventeenth century. He said that Richard came from Scotland. John added that Richard was received into the Abbey of St Victor by Abbot Gilduin (1114–1155) and was a student under Hugh of St Victor, the most influential of all Victorine teachers (implying that Richard entered the community before Hugh's death in 1141). This account of Richard's early life is not accepted by all modern scholars, however, and some have suggested that Richard entered the abbey after Hugh's death in 1141.

All scholarship agrees, however, that Richard was a magister during the 1150s, and was then promoted to subprior in 1159 (as stated by a document found at the abbey). He served under Achard of St. Victor's elected successor Ernisius, who was unworthy of the position. Richard's life was then burdened by the frustrations of working under a man who was ill-suited for his responsibilities. Ernisius wasted the abbey's resources on overly ambitious building projects and persecuted those who attempted to resist him. Richard was allowed to keep his office but his influence was restricted. Things became so unbearable that an appeal was made to the Pope, who then visited Saint Victor in 1162. Through a multitude of transactions, Ernisius was eventually removed from his position and the Pope commended Richard for his continued involvement in the matter. Letters from England written to Richard show that he was in constant touch with English affairs and give evidence of the international character of intellectual life at this time.

He was then promoted to prior in 1162, a position he held until his death on 10 March 1173.

Richard wrote extensively (Migne's "Patrologia Latina" contains 34 works attributed to him, and this is not Richard's full corpus). There are some problems with establishing the chronology of Richard's works. The earliest ones come before 1153, and the latest were written one or two years before his death. His earlier works are similar to the general teaching and writing of the period. His writing develops from basic exegesis, theology and philosophy to more of a study of purely spiritual questions. In his early writings he relies on the moral interpretations of previous theologians such as Augustine of Hippo, Bede, Pope Gregory I and Hugh. He later became more independent and strayed from Hugh's influence. There is some debate between historians about which of Richard's texts are the most influential and important. Because Richard's work covers many spheres of thought it is somewhat difficult to categorise his work.

"The Book of the Twelve Patriarchs", sometimes titled "Benjamin Minor", is one of Richard of Saint Victor's great works on contemplation. It is not exactly known when it was written, but it would seem to date before 1162. Richard specifies that this work is not a treatise on contemplation but rather prepares the mind for contemplation. 
"The Mystical Ark", sometimes called "Benjamin Major" or "The Grace of Contemplation" completes this with the study of the mind in relation to prayer. However, in the last chapters of "Benjamin Major", written later than the Minor, Richard almost abandons his topic and the discussion of the teaching of mystical theology takes up a good portion of every remaining chapter. He is still attempting to instruct his followers on a text but he has also engaged himself in creating a system of mystical theology.

One of Richard's greatest works was the "De Trinitate" which was probably written while Richard was prior, between 1162 and 1173. This is known because it incorporates pieces of theological text which editors are now finding in earlier works. "De Trinitate" is Richard's most independent and original study on dogmatic theology. It stems from the desire to show that dogmatic truths of Christian revelation are ultimately not against reason. Richard's theological approach stems from a profoundly mystical life of prayer, which in the Spirit seeks to involve the mind, in continuation with the Augustinian and Anselmian tradition.

Owing to the fact that until recently this masterpiece has not been available in any English translation, its diffusion has been limited and its influence has seldom gone beyond 'Book III', condemning serious enquiry to an understanding of Richard's argument that is only partial. Finally, in 2011, through the efforts of Ruben Angelici's scholarship, the first, full translation of Richard's 'De Trinitate' has been released for publication in English and now this scholastic masterpiece is readily available to a wider audience to be appreciated in its entirety.

Richard wrote a massive handbook of biblical education entitled "Liber Exceptionum" ("Book of Selections/Book of Notes"), important scriptural commentaries, and many treatises.

"The Four Degrees of Violent Charity", composed about 1170, with its description of how vehement love leads to union with God and more perfect service of neighbour, has been of interest to writers interested in Christian mysticism.

Richard's other treatises are a number of short works which mainly deal with textual difficulties and theological issues. Many of them can be grouped together with larger works. Some of them are correspondence between Richard and his students while others seem to have been written at the request of friends. Although short, they are often interesting because they allow the modern reader to see the mentality of the students and the discussions and issues of the time.

Richard of Saint Victor's "Commentary on Ezekiel" is of special interest in the field of art history because the explanations laid out by the author are accompanied by illustrations. A number of copies have come down to us, none of which are dated, but they are written in a style attributable to the second half of the twelfth century.

What makes Richard of Saint-Victor stand out from other theologians of his time is that he approaches theological problems as more of a psychologist, contributing to 'a careful analysis of contemplative experiences.'





</doc>
<doc id="26537" url="https://en.wikipedia.org/wiki?curid=26537" title="Rose">
Rose

A rose is a woody perennial flowering plant of the genus Rosa, in the family Rosaceae, or the flower it bears. There are over three hundred species and tens of thousands of cultivars. They form a group of plants that can be erect shrubs, climbing, or trailing, with stems that are often armed with sharp prickles. Flowers vary in size and shape and are usually large and showy, in colours ranging from white through yellows and reds. Most species are native to Asia, with smaller numbers native to Europe, North America, and northwestern Africa. Species, cultivars and hybrids are all widely grown for their beauty and often are fragrant. Roses have acquired cultural significance in many societies. Rose plants range in size from compact, miniature roses, to climbers that can reach seven meters in height. Different species hybridize easily, and this has been used in the development of the wide range of garden roses.

The name "rose" comes from French, itself from Latin "rosa", which was perhaps borrowed from Oscan, from Greek ρόδον "rhódon" (Aeolic βρόδον "wródon"), itself borrowed from Old Persian "wrd-" ("wurdi"), related to Avestan "varəδa", Sogdian "ward", Parthian "wâr".

The leaves are borne alternately on the stem. In most species they are long, pinnate, with (3–) 5–9 (–13) leaflets and basal stipules; the leaflets usually have a serrated margin, and often a few small prickles on the underside of the stem. Most roses are deciduous but a few (particularly from Southeast Asia) are evergreen or nearly so.

The flowers of most species have five petals, with the exception of "Rosa sericea", which usually has only four. Each petal is divided into two distinct lobes and is usually white or pink, though in a few species yellow or red. Beneath the petals are five sepals (or in the case of some "Rosa sericea", four). These may be long enough to be visible when viewed from above and appear as green points alternating with the rounded petals. There are multiple superior ovaries that develop into achenes. Roses are insect-pollinated in nature.

The aggregate fruit of the rose is a berry-like structure called a rose hip. Many of the domestic cultivars do not produce hips, as the flowers are so tightly petalled that they do not provide access for pollination. The hips of most species are red, but a few (e.g. "Rosa pimpinellifolia") have dark purple to black hips. Each hip comprises an outer fleshy layer, the hypanthium, which contains 5–160 "seeds" (technically dry single-seeded fruits called achenes) embedded in a matrix of fine, but stiff, hairs. Rose hips of some species, especially the dog rose ("Rosa canina") and rugosa rose ("Rosa rugosa"), are very rich in vitamin C, among the richest sources of any plant. The hips are eaten by fruit-eating birds such as thrushes and waxwings, which then disperse the seeds in their droppings. Some birds, particularly finches, also eat the seeds.

The sharp growths along a rose stem, though commonly called "thorns", are technically prickles, outgrowths of the epidermis (the outer layer of tissue of the stem), unlike true thorns, which are modified stems. Rose prickles are typically sickle-shaped hooks, which aid the rose in hanging onto other vegetation when growing over it. Some species such as "Rosa rugosa" and "Rosa pimpinellifolia" have densely packed straight prickles, probably an adaptation to reduce browsing by animals, but also possibly an adaptation to trap wind-blown sand and so reduce erosion and protect their roots (both of these species grow naturally on coastal sand dunes). Despite the presence of prickles, roses are frequently browsed by deer. A few species of roses have only vestigial prickles that have no points.

The genus "Rosa" is subdivided into four subgenera:

Roses are best known as ornamental plants grown for their flowers in the garden and sometimes indoors. They have been also used for commercial perfumery and commercial cut flower crops. Some are used as landscape plants, for hedging and for other utilitarian purposes such as game cover and slope stabilization.

The majority of ornamental roses are hybrids that were bred for their flowers. A few, mostly species roses are grown for attractive or scented foliage (such as "Rosa glauca" and "Rosa rubiginosa"), ornamental thorns (such as "Rosa sericea") or for their showy fruit (such as "Rosa moyesii").

Ornamental roses have been cultivated for millennia, with the earliest known cultivation known to date from at least 500 BC in Mediterranean countries, Persia, and China. It is estimated that 30 to 35 thousand rose hybrids and cultivars have been bred and selected for garden use as flowering plants. Most are double-flowered with many or all of the stamens having morphed into additional petals.

In the early 19th century the Empress Josephine of France patronized the development of rose breeding at her gardens at Malmaison. As long ago as 1840 a collection numbering over one thousand different cultivars, varieties and species was possible when a rosarium was planted by Loddiges nursery for Abney Park Cemetery, an early Victorian garden cemetery and arboretum in England.

Roses are a popular crop for both domestic and commercial cut flowers. Generally they are harvested and cut when in bud, and held in refrigerated conditions until ready for display at their point of sale.

In temperate climates, cut roses are often grown in greenhouses, and in warmer countries they may also be grown under cover in order to ensure that the flowers are not damaged by weather and that pest and disease control can be carried out effectively. Significant quantities are grown in some tropical countries, and these are shipped by air to markets across the world.

Some kind of roses are artificially coloured using dyed water, like rainbow roses.

Rose perfumes are made from rose oil (also called attar of roses), which is a mixture of volatile essential oils obtained by steam distilling the crushed petals of roses. An associated product is rose water which is used for cooking, cosmetics, medicine and religious practices. The production technique originated in Persia and then spread through Arabia and India, and more recently into eastern Europe. In Bulgaria, Iran and Germany, damask roses ("Rosa" × "damascena" 'Trigintipetala') are used. In other parts of the world "Rosa" × "centifolia" is commonly used. The oil is transparent pale yellow or yellow-grey in colour. 'Rose Absolute' is solvent-extracted with hexane and produces a darker oil, dark yellow to orange in colour. The weight of oil extracted is about one three-thousandth to one six-thousandth of the weight of the flowers; for example, about two thousand flowers are required to produce one gram of oil.

The main constituents of attar of roses are the fragrant alcohols geraniol and L-citronellol and rose camphor, an odorless solid composed of alkanes, which separates from rose oil. β-Damascenone is also a significant contributor to the scent.

Rose hips are occasionally made into jam, jelly, marmalade, and soup or are brewed for tea, primarily for their high vitamin C content. They are also pressed and filtered to make rose hip syrup. Rose hips are also used to produce rose hip seed oil, which is used in skin products and some makeup products.

Rose water has a very distinctive flavour and is used heavily in Middle Eastern, Persian, and South Asian cuisine—especially in sweets such as barfi, baklava, halva, gulab jamun, gumdrops, kanafeh, nougat, and Turkish delight.

Rose petals or flower buds are sometimes used to flavour ordinary tea, or combined with other herbs to make herbal teas.

In France, there is much use of rose syrup, most commonly made from an extract of rose petals. In the Indian subcontinent, Rooh Afza, a concentrated squash made with roses, is popular, as are rose-flavoured frozen desserts such as ice cream and kulfi.

Rose flowers are used as food, also usually as flavouring or to add their scent to food. Other minor uses include candied rose petals.

Rose creams (rose-flavoured fondant covered in chocolate, often topped with a crystallised rose petal) are a traditional English confectionery widely available from numerous producers in the UK.

Under the American Federal Food, Drug, and Cosmetic Act, there are only certain "Rosa" species, varieties, and parts are listed as generally recognized as safe (GRAS).

The rose hip, usually from "R. canina", is used as a minor source of vitamin C. The fruits of many species have significant levels of vitamins and have been used as a food supplement. Many roses have been used in herbal and folk medicines. "Rosa chinensis" has long been used in Chinese traditional medicine. This and other species have been used for stomach problems, and are being investigated for controlling cancer growth. In pre-modern medicine, diarrhodon (Gr διάρροδον, "compound of roses", from ῥόδων, "of roses") is a name given to various compounds in which red roses are an ingredient.

The long cultural history of the rose has led to it being used often as a symbol. In ancient Greece, the rose was closely associated with the goddess Aphrodite. In the "Iliad", Aphrodite protects the body of Hector using the "immortal oil of the rose" and the archaic Greek lyric poet Ibycus praises a beautiful youth saying that Aphrodite nursed him "among rose blossoms". The second-century AD Greek travel writer Pausanias associates the rose with the story of Adonis and states that the rose is red because Aphrodite wounded herself on one of its thorns and stained the flower red with her blood. Book Eleven of the ancient Roman novel "The Golden Ass" by Apuleius contains a scene in which the goddess Isis, who is identified with Venus, instructs the main character, Lucius, who has been transformed into a donkey, to eat rose petals from a crown of roses worn by a priest as part of a religious procession in order to regain his humanity.

Following the Christianization of the Roman Empire, the rose became identified with the Virgin Mary. The color of the rose and the number of roses received has symbolic representation. The rose symbol eventually led to the creation of the rosary and other devotional prayers in Christianity.

Roses symbolised the Houses of York and Lancaster in a conflict known as the Wars of the Roses.

Roses are a favored subject in art and appear in portraits, illustrations, on stamps, as ornaments or as architectural elements. The Luxembourg-born Belgian artist and botanist Pierre-Joseph Redouté is known for his detailed watercolours of flowers, particularly roses.

Henri Fantin-Latour was also a prolific painter of still life, particularly flowers including roses. The rose 'Fantin-Latour' was named after the artist.

Other impressionists including Claude Monet, Paul Cézanne and Pierre-Auguste Renoir have paintings of roses among their works.

In 1986 President Ronald Reagan signed legislation to make the rose the floral emblem of the United States.

Wild roses are host plants for a number of pests and diseases. Many of these affect other plants, including other genera of the Rosaceae.

Cultivated roses are often subject to severe damage from insect, arachnid and fungal pests and diseases. In many cases they cannot be usefully grown without regular treatment to control these problems.




</doc>
<doc id="26538" url="https://en.wikipedia.org/wiki?curid=26538" title="Roman Curia">
Roman Curia

The Roman Curia () comprises the administrative institutions of the Holy See and the central body through which the affairs of the Catholic Church are conducted. It acts in the Pope's name and with his authority for the good and for the service of the particular churches and provides the central organization for the church to advance its objectives.

The structure and organization of responsibilities within the Curia are at present regulated by the apostolic constitution "Pastor bonus", issued by Pope John Paul II on 28 June 1988, which Pope Francis has decided to revise.

Other bodies that play an administrative or consulting role in ecclesial affairs are sometimes mistakenly identified with the Curia, such as the Synod of Bishops and regional conferences of bishops. Cardinal Gerhard Müller, former prefect of the Congregation for the Doctrine of the Faith, wrote in 2015 that "the Synod of Bishops is not a part of the Roman Curia in the strict sense: it is the expression of the collegiality of bishops in communion with the Pope and under his direction. The Roman Curia instead aids the Pope in the exercise of his primacy over all the Churches."

"Curia" in medieval and later Latin usage means "court" in the sense of "royal court" rather than "court of law". The Roman Curia is sometimes anglicized as the Court of Rome, as in the 1534 Act of Parliament that forbade appeals to it from England. It is the papal court and assists the Pope in carrying out his functions. The Roman Curia can be loosely compared to cabinets in governments of countries with a Western form of governance, but the only sections that can be directly compared with specific ministries of a civil government are the Second Section of the Secretariat of State, known also as the Section for Relations with States, the Pontifical Commission for Vatican City State (established in 1939 by Pius XII), and the Congregation for Catholic Education, 

It is normal for every Latin Catholic diocese to have its own "curia" for its administration. For the Diocese of Rome, these functions are "not" handled by the Roman Curia, but by the Vicariate General of His Holiness for the City of Rome, as provided by the apostolic constitution "Ecclesia in Urbe". The pope has, going back to St. Peter, been the bishop of Rome. There is also the Vicar General of Rome, traditionally a cardinal, and his deputy the vicegerent, who holds the personal title of archbishop, supervise the governance of the diocese by reference to the Pope himself, but with no more dependence on the Roman Curia, as such, than other Catholic dioceses throughout the world. A distinct office, the Vicar General for Vatican City, administers the portion of the Diocese of Rome in Vatican City.

Until recently, there still existed hereditary officers of the Roman Curia, holding titles denominating functions that had ceased to be a reality when the Papal States were lost to the papacy. A reorganization, ordered by Pope Pius X, was incorporated into the 1917 Code of Canon Law. Further steps toward reorganization were begun by Pope Paul VI in the 1960s. Among the goals of this curial reform were the modernization of procedures and the internationalization of the curial staff. These reforms are reflected in the 1983 Code of Canon Law. The offices of the Vatican City State are not part of the Roman Curia, which is composed only of offices of the Holy See. , the Curia comprises the offices listed in the sections below. All members of the Curia except the Cardinal Camerlengo and the Major Penitentiary resign their office immediately after a papal death or resignation. See "sede vacante".

The principal departments of the Roman Curia are called dicasteries. The constitution of the church "Pastor bonus" (1988) provided this definition: "By the word "dicasteries" are understood the Secretariat of State, Congregations, Tribunals, Councils and Offices". Those remain the five principal categories of departments, with the noteworthy change in that there is now more than a single Secretariat. Two new departments that began functioning on 1 August 2016 and 1 January 2017 were identified only as dicasteries – Dicastery for the Laity, Family, and Life and Dicastery for Promoting Integral Human Development. Both are headed by a prefect.

The Secretariat of State is the oldest dicastery in the Roman Curia, the government of the Roman Catholic Church. It is headed by the Secretary of State, since 15 October 2013 by Cardinal Pietro Parolin, who is responsible for all the political and diplomatic functions of the Holy See. The Secretariat is divided into two sections, the Section for General Affairs and the Section for Relations with States, known as the First Section and Second Section, respectively. The Secretariat of State was created in the 15th century and is now the department of the curia most involved in coordinating the Holy See's activities. Matters not clearly within the competence of another dicastery are dealt with by the Secretariat of State.

The Secretariat for the Economy was established by Pope Francis in 2014, with the Australian Cardinal George Pell, formerly the Archbishop of the Roman Catholic Archdiocese of Sydney, as its Cardinal Prefect (2014 - 12 December 2018).

Two departments of the Roman Curia established by Pope Francis in 2016 have been identified simply as "dicasteries" rather than as one of the traditional department types. A third dicastery was named on 23 June 2018.

Pope Francis announced on 15 August 2016 the creation of the Dicastery for the Laity, Family and Life, effective 1 September 2016. It took over the responsibilities of the Pontifical Council for the Laity and the Pontifical Council for the Family. As its first Prefect, Francis named Bishop Kevin Farrell of Dallas, Texas,

Pope Francis announced the erection of the Dicastery for Promoting Integral Human Development on 31 August 2016, effective 1 January 2017. He named Cardinal Peter Turkson its first prefect. Combining the work of four Pontifical Councils established following the Second Vatican Council, Pope Francis gave it responsibility for "issues regarding migrants, those in need, the sick, the excluded and marginalized, the imprisoned and the unemployed, as well as victims of armed conflict, natural disasters, and all forms of slavery and torture". The Pope announced that "temporarily" he would personally direct the department's work on behalf of migrants and refugees.

Pope Francis established the Secretariat for Communications on 27 June 2015, incorporating the Pontifical Council for Social Communications; the Press Office of the Holy See (Vatican Press Office); the Vatican Internet Service (VIS); Vatican Radio; Vatican Television Center; the L'Osservatore Romano newspaper; Tipografia Vaticana; Servizio Fotografico; and the Libreria Editrice Vaticana. Monsignor Dario Edoardo Viganò, formerly the Director of the Vatican Television Center, was named the first Prefect. Viganò resigned on 21 March 2018.

The "Secretariat" was renamed Dicastery for Communications on 23 June 2018, and on 5 July 2018 Pope Francis appointed award-winning lay journalist Paolo Ruffini, as Prefect.

There are nine Roman Congregations in the Roman Curia, the central administrative organisation of the Catholic Church. They are the second highest-ranking departments and are a type of dicastery (department with a jurisdiction) of the Roman Curia. Each Congregation is led by a prefect, who is a cardinal.

The Congregation for the Doctrine of the Faith (CDF), previously known as the Supreme Sacred Congregation of the Roman and Universal Inquisition, and sometimes simply called the Holy Office, is the oldest of the nine congregations of the Roman Curia. Among the most active of these major Curial departments, it oversees Catholic doctrine. Its most familiar name for most of its history was the Holy Office of the Inquisition. Cardinal Luis Ladaria Ferrer has served as its prefect since 1 July 2017.

The Congregation for the Oriental Churches, established by Pope Benedict XV on 1 May 1917, is responsible for contact with the Eastern Catholic Churches for the sake of assisting their development, protecting their rights and also maintaining whole and entire in the one Catholic Church, alongside the liturgical, disciplinary and spiritual patrimony of the Latin Church, the heritage of the various Oriental Christian traditions. It has exclusive authority over the following regions: Egypt and the Sinai Peninsula, Eritrea and northern Ethiopia, southern Albania and Bulgaria, Cyprus, Greece, Israel, Iran, Iraq, Lebanon, Palestine, Syria, Jordan, Turkey, and Ukraine. Its members include all Eastern Catholic patriarchs and major archbishops, as well as the President of the Pontifical Council for Promoting Christian Unity. Cardinal Leonardo Sandri has served as its prefect since his appointment on 9 June 2007.

The Congregation for Divine Worship and the Discipline of the Sacraments handles most affairs relating to liturgical practices of the Latin Catholic Church as distinct from the Eastern Catholic Churches and also some technical matters relating to the Sacraments. It has been headed by Cardinal Robert Sarah as prefect since his appointment on 23 November 2014.

The Congregation for the Causes of Saints oversees the process that leads to the canonization of saints, passing through the steps of a declaration of "heroic virtues" and beatification. After preparing a case, including the approval of miracles, the case is presented to the pope, who decides whether or not to proceed with beatification or canonization. , the prefect is Cardinal Giovanni Angelo Becciu.

The Congregation for the Evangelization of Peoples is responsible for missionary work and related activities. It is perhaps better known by its former title, the Congregation for the Propagation of the Faith. Pope John Paul II renamed it in 1982 without altering its mission. Sr. Luzia Premoli, superior general of the Combonian Missionary Sisters, was appointed a member of the Congregation for the Evangelization of Peoples in 2014, becoming the first woman to be appointed a member of a Vatican congregation. , Cardinal Luis Antonio Tagle is the prefect. 

The Congregation for the Clergy is the department of the Roman Curia responsible for overseeing matters regarding priests and deacons not belonging to institutes of consecrated life or societies of apostolic life, as well as for the seminaries (except those regulated by the Congregations for the Evangelization of Peoples and for the Oriental Churches), and houses of formation of religious and secular institutes. The Congregation for the Clergy handles requests for dispensation from active priestly ministry, as well as the legislation governing presbyteral councils and other organizations of priests around the world. The Congregation does not deal with clerical sexual abuse cases, as those are handled exclusively by the Congregation for the Doctrine of the Faith.

Beniamino Stella of Italy has served as its prefect since 2013.

The Congregation for Institutes of Consecrated Life and Societies of Apostolic Life is the congregation of the Roman Curia responsible for everything which concerns institutes of consecrated life (religious institutes and secular institutes) and societies of apostolic life, both of men and of women, regarding their government, discipline, studies, goods, rights, and privileges. João Braz de Aviz of Brazil has served as its prefect since 2011.

The Congregation for Catholic Education is responsible for:

Giuseppe Versaldi has headed it since 2015.

The Congregation for Bishops oversees the selection of new bishops that are not in mission territories or those areas that come under the jurisdiction of the Congregation for the Oriental Churches who deal with the Eastern Catholics, pending papal approval. It consequently holds considerable sway over the evolution of the church. It also schedules the papal audiences required for bishops every five years and arranges the creation of new dioceses. This office is headed by Cardinal Marc Ouellet, PSS.

The Apostolic Penitentiary, more formally the Supreme Tribunal of the Apostolic Penitentiary, is one of the three tribunals of the Roman Curia. The Apostolic Penitentiary is responsible for issues relating to the forgiveness of sins in the Roman Catholic Church. The Apostolic Penitentiary has jurisdiction only over matters in the internal forum. Its work falls mainly into these categories:

The Tribunal of the Roman Rota is the highest appellate tribunal. While usually trying cases in appeal in third instance (as is normally the case in the Eastern Catholic Churches), or even in second instance if appeal is made to it directly from the sentence of a tribunal of first instance, it is also a court of first instance for cases specified in the law and for others committed to the Rota by the Roman Pontiff. It fosters the unity of jurisprudence and, through its own sentences, is a help to lower tribunals.

The greater part of its decisions concern the nullity of marriage. In such cases its competence includes marriages between two Catholics, between a Catholic and non-Catholic, and between two non-Catholic parties whether one or both of the baptized parties belongs to the Latin or an Eastern Rite.

The court is named "Rota" (Latin for: wheel) because the judges, called "auditors", originally met in a round room to hear cases.

The Supreme Tribunal of the Apostolic Signatura is the highest judicial authority in the Catholic Church besides the Pope himself, who is the supreme ecclesiastical judge. In addition, it is an administrative office for matters pertaining to the judicial activity of the whole church.

Appeals in standard judicial processes, if appealed to the Apostolic See, normally are not handled by the Signatura. Those go to the Roman Rota, which is the ordinary appellate tribunal of the Apostolic See. The Supreme Tribunal handles some of the more specialized kinds of cases, including the following:

Although a Rotal decision can be appealed, if not "res judicata", to a different panel ("turnus") of the Rota, there is no right of appeal from a decision of the Signatura, although a complaint of nullity on formal grounds is possible. As an administrative office, it exercises jurisdiction (vigilance) over all the tribunals of the Catholic Church. It can also extend the jurisdiction of tribunals, grant dispensations for procedural laws, establish interdiocesan tribunals, and correct advocates.

The Pontifical Council for Promoting Christian Unity is dedicated chiefly to the promotion of dialogue and unity with other Christian churches and ecclesial communities, but also, through a closely linked specific commission, to advancing religious relations with Jews.

The Pontifical Council for Legislative Texts has responsibility for interpreting church law.

The Pontifical Council for Interreligious Dialogue is the central office of the Catholic Church for promoting of interreligious dialogue in accordance with the spirit of the Second Vatican Council, in particular the declaration "Nostra aetate". It has the following responsibilities: 


The Pontifical Council for Culture () has as its mission oversight of the relationship of the Catholic Church with different cultures. The Pontifical Council for Dialogue with Non-Believers was merged with the Pontifical Council for Culture in 1993. On 30 July 2012, Pope Benedict XVI united the Council with the Pontifical Commission for the Cultural Goods of the Church.

The Pontifical Council for Promoting the New Evangelization is a pontifical council of the Roman Curia dedicated to catechetics and promoting the faith in parts of the world ("the West") where Christianity is well-established but is being affected by secularism.

The Holy See's financial authorities consist of two offices.

The Apostolic Camera was the central board of finance in the Papal administrative system, which at one time was of great importance in the government of the States of the Church and in the administration of justice, led by the Camerlengo of the Holy Roman Church.

The Administration of the Patrimony of the Apostolic See deals with the "properties owned by the Holy See in order to provide the funds necessary for the Roman Curia to function". It was established by Pope Paul VI on 15 August 1967 and composed of two sections. The Ordinary Section continued the work of the Administration of the Property of the Holy See, a commission to which Pope Leo XIII entrusted the administration of the property remaining to the Holy See after the complete loss of the Papal States in 1870. On 8 July 2014, the Ordinary Section was transferred to the newly established Secretariat for the Economy. The Extraordinary Section administers the funds given by the Italian government to implement the Financial Convention attached to the Lateran Treaty of 1929. These funds were previously managed by the Special Administration of the Holy See.

The Prefecture for the Economic Affairs of the Holy See was erected on 15 August 1967 and was entrusted with overseeing all the offices of the Holy See that managed finances, regardless of their degree of autonomy. It did not manage finances itself, but instead audited the balance sheets and budgets of the offices that did. It then prepared and published annually a general financial report. It was consulted on all projects of major importance undertaken by the offices in question. On 31 March 2015, Pope Francis transferred its operations into the Secretariat for the Economy.

The Pontifical Commission for the Cultural Heritage of the Church was established in 1988 by Pope John Paul II, with the purpose of guarding the historical and artistic patrimony of the entire church which included works of art, historical documents, books, everything kept in museums as well as the libraries and archives. On 30 July 2012, Pope Benedict XVI merged the Commission into the Pontifical Council for Culture.

The Pontifical Commission "Ecclesia Dei" was established by Pope John Paul II on 2 July 1988 for the care of those former followers of Archbishop Marcel Lefebvre who broke with him as a result of his consecration of four priests of his Society of St. Pius X as bishops on 30 June 1988, an act the Holy See deemed illicit and schismatic. On 2 July 2009 this commission was closely placed under the auspice of the Congregation for the Doctrine of the Faith, whose Prefect was ex officio President of the Commission while maintaining its separate identity. On 17 January 2019, Pope Francis merged the Commission into the Congregation for the Doctrine of the Faith.

The Pontifical Commission for Latin America is a dicastery of the Roman Curia. Established by Pope Pius XII on 19 April 1958, it is charged with providing assistance to and examining matters pertaining to the church in Latin America. The Commission operates under the auspices of the Congregation for Bishops.

The Pontifical Commission for the Protection of Minors () was instituted by Pope Francis on 22 March 2014 for the safeguarding of minors. It is headed by Boston's Cardinal Archbishop, Seán Patrick O'Malley.

The Pontifical Commission for Sacred Archaeology was created by Pius IX on 6 January 1852 "to take care of the ancient sacred cemeteries, look after their preventive preservation, further explorations, research and study, and also safeguard the oldest mementos of the early Christian centuries, the outstanding monuments and venerable Basilicas in Rome, in the Roman suburbs and soil, and in the other Dioceses in agreement with the respective Ordinaries". Pius XI made the Commission pontifical and expanded its powers.

The Pontifical Biblical Commission, established 30 October 1902 by Pope Leo XIII, is a consultative body of scholars placed under the authority of the Congregation for the Doctrine of the Faith. The commission's duties include:

The International Theological Commission (ITC) consists of 30 Catholic theologians from around the world. Its function is to advise the Congregation for the Doctrine of the Faith (CDF) of the Roman Catholic Church. The Prefect of the CDF is "ex officio" the president of the ITC, which is based in Rome.

A temporary commission is sometimes established to deal with a matter involving the work of several departments of the Roman Curia.

The Interdicasterial Commission for the Catechism of the Catholic Church was created in 1993 to prepare the definitive text in Latin of the Catechism of the Catholic Church. It produced the authoritative Latin text ("editio typica") of the Catechism in 1997.

Others exist for longer periods. The Standing Interdicasterial Commission for the Church in Eastern Europe, set up by Pope John Paul II on 15 January 1993, as of 2012 is presided over by the Cardinal Secretary of State. Its membership includes the Secretary and the Undersecretary for Relations with States, and the Secretaries of the Congregations for the Eastern Churches, for the Clergy, and for Institutes of Consecrated Life and Societies of Apostolic Life, and of the Pontifical Council for Promoting Christian Unity.

Since 1506, the "Corps of the Pontifical Swiss Guard" or "Swiss Guard", a small armed force, has been responsible for the safety of the Pope, including the security of the Apostolic Palace and access to Vatican City. It originated as a military combat unit and quickly evolved into a police force with responsibility for border control. Its official language is Swiss German. , it consisted of 134 professional soldiers.

The Labour Office of the Apostolic See is responsible for labor relations of the Holy See with its employees. The office also settles labor issues which arise. It was instituted by Pope John Paul II on 1 January 1989 by an apostolic letter in the form of a "motu proprio".




</doc>
<doc id="26540" url="https://en.wikipedia.org/wiki?curid=26540" title="Romano Mussolini">
Romano Mussolini

Romano Mussolini (26 September 1927 – 3 February 2006) was an Italian jazz pianist, painter and film producer. He was the fourth and youngest son of Benito Mussolini, who was the fascist dictator of Italy from 1922 until 1943.

A native of Villa Carpena, Forlì (Emilia-Romagna), Romano Mussolini studied music as a child, playing classical pieces with his father on the violin.

After World War II, he started playing jazz under the assumed name "Romano Full" and by the mid-1950s, he had formed a trio. Mussolini released a self-titled record (featuring Lilian Terry on vocals and trumpeter Nunzio Rotondo) through RCA Records in 1956. By the 1960s, he had formed the "Romano Mussolini All Stars", which became one of Italy's foremost jazz bands.

The All Stars recorded a well-received record "Jazz Allo Studio 7" in 1963 with "At the Santa Tecla" following a year later. Mussolini's band toured internationally with artists including Dizzy Gillespie, Duke Ellington, Helen Merrill and Chet Baker. In the 1990s, Mussolini recorded two more albums, "Perfect Alibi" and "Soft and Swing".

His playing style has been described as "...like a slightly melancholic Oscar Peterson. Occasionally inspired, he was always efficient; he made the refrains run on time."

In 1962, Mussolini married Maria Scicolone, the younger sister of actress Sophia Loren. They had two daughters, Elisabetta and her elder sister Alessandra Mussolini, who was a member of the European Parliament, and leads an Italian neofascist party, "Alternativa Sociale". Romano Mussolini composed the party's official anthem, "The Pride of Being Italian".

With his second wife, the actress Carla Maria Puccini, he had a third daughter, Rachele, named after his mother Rachele Mussolini.

Mussolini was very reserved about his family history. It was only in 2004 that he published a book, entitled "Il Duce, mio padre" ("The Leader, my father"), followed by a similar book in 2005, collecting personal memories and accounts of private confidences and discussions with his father.

Romano Mussolini died in 2006, aged 78, in a hospital in Rome from heart problems.




</doc>
<doc id="26541" url="https://en.wikipedia.org/wiki?curid=26541" title="Repo Man (film)">
Repo Man (film)

Repo Man is a 1984 American science fiction black comedy film written and directed by Alex Cox in his directorial debut. It stars Harry Dean Stanton and Emilio Estevez, with Tracey Walter, Olivia Barash, Sy Richardson, Vonetta McGee, Fox Harris and Dick Rude among the supporting cast. Set in Los Angeles, the plot concerns a young punk rock enthusiast (Estevez) who is recruited by a car repossession agency and gets caught up in the pursuit of a mysterious Chevrolet Malibu that might be connected to extraterrestrials.

A satire of America under the Reagan administration, consumerism and the Atomic Age, "Repo Man" was developed by Cox in partnership with his fellow film school graduates from UCLA, independent producers Jonathan Wacks and Peter McCarthy. His inspiration for the film came from his own experiences working with repossession agent Mark Lewis. Originally conceiving of it as a road movie, Cox reconfigured the story to take place mostly in Los Angeles to maintain its budget. Michael Nesmith of The Monkees came on board the project as an executive producer, and secured a negative pickup deal with Universal Pictures. Principal photography ran through summer 1983, during which Cox encouraged improvisation from the cast; the film's ending notably differed from what had originally been written. The soundtrack, headlined by a main theme composed and performed by Iggy Pop, is noted as a snapshot of early hardcore punk; Cox wanted the music to underscore the life of repo men.

Despite a troubled initial release due to Universal's scepticism towards the film's commercial viability, "Repo Man" received widespread acclaim, and was deemed by critics to be one of the best films of 1984. It has since gained a cult following, particularly surrounding Cox's re-edited version of the film for television due to its deliberate inclusion of surreal overdubs to replace profanity. A stand-alone sequel based on an unproduced screenplay by Cox, "Waldo's Hawaiian Holiday", was published as a graphic novel in 2008, while a spiritual successor, "Repo Chick", was released in 2009.

In the Mojave Desert, a policeman pulls over a 1964 Chevrolet Malibu driven by J. Frank Parnell. The policeman opens the trunk, sees a blinding flash of white light, and is instantly vaporized, leaving only his boots behind.

Otto Maddox, a young punk rocker in L.A., is fired from his job as a supermarket stock clerk. His girlfriend leaves him for his best friend. Depressed and broke, Otto is wandering the streets when a man named Bud drives up and offers him $25 to drive a car out of the neighborhood.

Otto follows Bud in the car to the Helping Hand Acceptance Corporation, where he learns that the car he drove was being repossessed. He refuses to join Bud as a "repo man," and goes to his parents' house. He learns that his burned-out ex-hippie parents have donated the money that they promised him as a reward for graduating from high school to a televangelist. He decides to take the repo job.

After repossessing a flashy red Cadillac, Otto sees a girl named Leila running down the street. He gives her a ride to her workplace, the United Fruitcake Outlet. On the way, Leila shows Otto pictures of aliens that she says are in the trunk of a Chevy Malibu. She claims that they are dangerous because of the radiation that they emit. Meanwhile, Helping Hand is offered a $20,000 bounty notice for the Malibu. Most assume that the car is drug-related, because the bounty is far above the actual value of the car.

Parnell arrives in L.A. driving the Malibu, but he is unable to meet his waiting UFO compatriots because of a team of government agents led by a woman with a metal hand. When Parnell pulls into a gas station, Helping Hand's competitors, the Rodriguez brothers, take the Malibu. They stop for sodas because the car's trunk is hot. While they are out of the car, a trio of Otto's punk friends, who are on a crime spree, steal the Malibu.

After they visit a night club, Parnell appears and tricks the punks into opening the trunk, killing one of them and scaring the other two away. Later, he picks up Otto and drives aimlessly, before collapsing and dying from radiation exposure. After surviving a convenience store shootout with the punks that leaves Bud wounded and punk Duke dead, Otto takes the Malibu back to Helping Hand and leaves it in the lot. The car is stolen from the lot, and a chase ensues. By this time, the car is glowing bright green.

Eventually, the Malibu reappears at the Helping Hand lot with Bud behind the wheel, but he ends up being shot. The various groups trying to acquire the car soon show up; government agents, the UFO scientists, and the televangelist. Anyone who approaches it bursts into flames, even those in flame-retardant suits. Only Miller, an eccentric mechanic at Helping Hand who had explained earlier to Otto that aliens exist and can travel through time in their spaceships, is able to enter the car. He slides behind the wheel and beckons Otto into the Malibu. After Otto settles into the passenger seat, the Malibu lifts straight up into the air and flies away, first through the city's skyline and later into space.

"Repo Man" garnered widespread praise upon its release, and is widely considered to be one of the best films of 1984. The review aggregator Rotten Tomatoes gives the film a 98% approval rating based on 44 reviews, with an average rating of 8/10. The site's critical consensus reads, ""Repo Man" is many things: an alien-invasion film, a punk-rock musical, a send-up of consumerism. One thing it isn't is boring." In 2008, the film was voted by a group of "Los Angeles Times" writers and editors as the eighth-best film set in Los Angeles in the last 25 years. "Entertainment Weekly" ranked the film seventh on their list of "The Top 50 Cult Films".

Roger Ebert gave the film 3 stars out of a possible 4, and wrote:

Academy of Science Fiction, Fantasy & Horror Films

Boston Society of Film Critics Awards

Mystfest

American Film Institute Lists

The soundtrack features songs by various punk rock bands such as The Plugz, Black Flag, the Circle Jerks, Suicidal Tendencies, Iggy Pop and others. The film score was created by Tito Larriva, Steven Hufsteter, Charlie Quintana and Tony Marsico of The Plugz. Iggy Pop volunteered to write the title song after his manager viewed a screening of the film.

According to the documentary "A Texas Tale of Treason", Cox wrote a sequel to "Repo Man" which, though filming started, was never finished.

Chris Bones saw the script on Cox's website and asked, and received, permission to adapt the script into a graphic novel. The book, "Waldo's Hawaiian Holiday", was released in March 2008 by Gestalt Publishing.

On December 3, 2008, a sequel was reported to be going into development with the working title "Repo Chick". The story would be set in 2008 and the resulting boom in repossession that extends far beyond cars and homes. On February 13, 2009, Cox announced on his blog that shooting had finished and the film was in post-production. The bulk of the film was shot in front of a green screen, with backgrounds filmed and composited-in during post-production. Universal sent Cox a cease-and-desist notice because he does not possess the rights to do an official sequel, but he ignored it since his film uses none of the characters from the original. The film premiered on September 8 at the Venice Film Festival. It was released to DVD in the United Kingdom on February 7, 2011, and in North America on the following day.



</doc>
<doc id="26542" url="https://en.wikipedia.org/wiki?curid=26542" title="Ruth Benedict">
Ruth Benedict

Ruth Fulton Benedict (June 5, 1887 – September 17, 1948) was an American anthropologist and folklorist.

She was born in New York City, attended Vassar College and graduated in 1909. After studying anthropology at the New School of Social Research under Elsie Clews Parsons, she entered graduate studies at Columbia University in 1921, where she studied under Franz Boas. She received her PhD and joined the faculty in 1923. Margaret Mead, with whom she shared a romantic relationship, and Marvin Opler, were among her students and colleagues.

Benedict was President of the American Anthropological Association and was also a prominent member of the American Folklore Society. She became the first woman to be recognized as a prominent leader of a learned profession. She can be viewed as a transitional figure in her field, redirecting both anthropology and folklore away from the limited confines of culture-trait diffusion studies and towards theories of performance as integral to the interpretation of culture. She studied the relationships between personality, art, language and culture, insisting that no trait existed in isolation or self-sufficiency, a theory which she championed in her 1934 book "Patterns of Culture".

Benedict was born Ruth Fulton in New York City on June 5, 1887, to Beatrice (Shattuck) and Frederick Fulton. Her mother worked in the city as a school teacher, while her father was a homeopathic doctor and surgeon. Although Mr. Fulton loved his work and research, it eventually led to his premature death, as he acquired an unknown disease during one of his surgeries in 1888. Due to his illness the family moved back to Norwich, New York to the farm of Ruth's maternal grandparents, the Shattucks. A year later he died, ten days after returning from a trip to Trinidad to search for a cure.

Mrs. Fulton was deeply affected by her husband's passing. Any mention of him caused her to be overwhelmed by grief; every March she cried at church and in bed. Ruth hated her mother's sorrow and viewed it as a weakness. For her, the greatest taboos in life were crying in front of people and showing expressions of pain. She reminisced, "I did not love my mother; I resented her cult of grief". Because of this, the psychological effects on her childhood were profound, for "in one stroke she [Ruth] experienced the loss of the two most nourishing and protective people around her—the loss of her father at death and her mother to grief".

As a toddler, she contracted measles which left her partially deaf, which was not discovered until she began school. Ruth also had a fascination with death as a young child. When she was four years old her grandmother took her to see an infant that had recently died. Upon seeing the dead child's face, Ruth claimed that it was the most beautiful thing she had ever seen.

At age seven Ruth began to write short verses and read any book she could get her hands on. Her favorite author was Jean Ingelow and her favorite readings were "A Legend of Bregenz" and "The Judas Tree". Through writing she was able to gain approval from her family. Writing was her outlet, and she wrote with an insightful perception about the realities of life. For example, in her senior year of high school, she wrote a piece called, "Lulu's Wedding (A True Story)" in which she recalled the wedding of a family serving girl. Instead of romanticizing the event, she revealed the true, unromantic, arranged marriage that Lulu went through because the man would take her, even though he was much older.

Although Ruth Benedict's fascination with death started at an early age, she continued to study how death affected people throughout her career. In her book "Patterns of Culture", Benedict studied the Pueblo culture and how they dealt with grieving and death. She describes in the book that individuals may deal with reactions to death, such as frustration and grief, differently. Societies all have social norms that they follow; some allow more expression when dealing with death, such as mourning, while other societies are not allowed to acknowledge it.

After high school, Margery (her sister) and Ruth were able to enter St Margaret's School for Girls, a college preparatory school, with help from a full-time scholarship. The girls were successful in school and entered Vassar College in September 1905 where Ruth thrived in an all-female atmosphere. During this time period stories were circulating that going to college led girls to become childless and never be married. Nevertheless, Ruth explored her interests in college and found writing as her way of expressing herself as an "intellectual radical" as she was sometimes called by her classmates. Author Walter Pater was a large influence on her life during this time as she strove to be like him and live a well-lived life. She graduated with her sister in 1909 with a major in English Literature. Unsure of what to do after college, she received an invitation to go on an all-expense-paid tour around Europe by a wealthy trustee of the college. Accompanied by two girls from California that she'd never met, Katherine Norton and Elizabeth Atsatt, she traveled through France, Switzerland, Italy, Germany, and England for one year, having the opportunity of various home stays throughout the trip.

Over the next few years, Ruth took up many different jobs. First she tried paid social work for the Charity Organization Society and later she accepted a job as a teacher at the Westlake School for Girls in Los Angeles, California. While working there she gained her interest in Asia that would later affect her choice of fieldwork as a working anthropologist. However, she was unhappy with this job as well and, after one year, left to teach English in Pasadena at the Orton School for Girls. These years were difficult, and she suffered from depression and severe loneliness. However, through reading authors like Walt Whitman and Jefferies that stressed a worth, importance and enthusiasm for life she held onto hope for a better future.

The summer after her first year teaching at the Orton School she returned home to the Shattucks' farm to spend some time in thought and peace. There Stanley Rossiter Benedict, an engineer at Cornell Medical College, began to visit her at the farm. She had met him by chance in Buffalo, New York around 1910. That summer Ruth fell deeply in love with Stanley as he began to visit her more, and accepted his proposal for marriage. Invigorated by love, she undertook several writing projects in order to keep busy besides the everyday housework chores in her new life with Stanley. She began to publish poems under different pseudonyms—Ruth Stanhope, Edgar Stanhope, and Anne Singleton. She also began work on writing a biography about Mary Wollstonecraft and other lesser-known women that she felt deserved more acknowledgement for their work and contributions. By 1918 the couple began to drift apart. Stanley suffered an injury that made him want to spend more time away from the city, and Benedict was not happy when the couple moved to Bedford Hills far away from the city.

In her search for a career, she decided to attend some lectures at the New School for Social Research while looking into the possibility of becoming an educational philosopher. While at the school, she took a class called "Sex in Ethnology" taught by Elsie Clews Parsons. She enjoyed the class and took another anthropology course with Alexander Goldenweiser, a student of noted anthropologist Franz Boas. With Goldenweiser as her teacher, Ruth's love for anthropology steadily grew. As close friend Margaret Mead explained, "Anthropology made the first 'sense' that any ordered approach to life had ever made to Ruth Benedict". After working with Goldenweiser for a year, he sent her to work as a graduate student with Franz Boas at Columbia University in 1921. She developed a close friendship with Boas, who took on a role as a kind of father figure in her life – Benedict lovingly referred to him as "Papa Franz".

Boas gave her graduate credit for the courses that she had completed at the New School for Social Research. Benedict wrote her dissertation "The Concept of the Guardian Spirit in North America", and received the PhD in anthropology in 1923. Benedict also started a friendship with Edward Sapir who encouraged her to continue the study of the relations between individual creativity and cultural patterns. Sapir and Benedict shared an interest in poetry, and read and critiqued each other's work, both submitting to the same publishers and both being rejected. They also were both interested in psychology and the relation between individual personalities and cultural patterns, and in their correspondences, they frequently psychoanalyzed each other. However, Sapir showed little understanding for Benedict's private thoughts and feelings. In particular, his conservative gender ideology jarred with Benedict's struggle for emancipation. While they were very close friends for a while, it was ultimately the differences in worldview and personality that led their friendship to strand.

Benedict taught her first anthropology course at Barnard college in 1922 and among the students there was Margaret Mead. Benedict was a significant influence on Mead.

Boas regarded Benedict as an asset to the anthropology department, and in 1931 he appointed her as Assistant Professor in Anthropology, something impossible until her divorce from Stanley Benedict that same year.

One student who felt especially fond of Ruth Benedict was Ruth Landes. Letters that Landes sent to Benedict state that she was enthralled by the way in which Benedict taught her classes and with the way that she forced the students to think in an unconventional way.

When Boas retired in 1937, most of his students considered Ruth Benedict to be the obvious choice for the head of the anthropology department. However, the administration of Columbia was not as progressive in its attitude towards female professionals as Boas had been, and the university President Nicholas Murray Butler was eager to curb the influence of the Boasians whom he considered to be political radicals. Instead, Ralph Linton, one of Boas's former students, a World War I veteran and a fierce critic of Benedict's "Culture and Personality" approach, was named head of the department. Benedict was understandably insulted by Linton's appointment and the Columbia department was divided between the two rival figures of Linton and Benedict, both accomplished anthropologists with influential publications, neither of whom ever mentioned the work of the other.

Margaret Mead and Ruth Benedict are considered the two most influential and famous anthropologists of their time. One of the reasons why Mead and Benedict got along well was the fact that they both shared a passion for their work and they each felt a sense of pride in the fact that they were successful working women during a time when this was uncommon. They were frequently known to critique each other's work; they entered into a companionship which began through their work, but during its early period, it also had an erotic character. Both Benedict and Mead wanted to dislodge stereotypes about women which were widely believed during their time and show people that working women could also be successful even though working society was seen as a man's world. In her memoir about her parents, "With a Daughter's Eye", Margaret Mead's daughter implies that the relationship between Benedict and Mead was partly sexual. In 1946, Benedict received the Achievement Award from the American Association of University Women. After Benedict died of a heart attack in 1948, Mead kept the legacy of Benedict's work going by supervising projects that Benedict would have looked after, and editing and publishing notes from studies that Benedict had collected throughout her life.

Before World War II began, Benedict was giving lectures at the Bryn Mawr College for the Anna Howard Shaw Memorial Lectureship. These lectures were focused around the idea of synergy. Yet, WWII made her focus on other areas of concentration of anthropology and the lectures were never presented in their entirety. After the war was over, she focused on finishing her book "The Chrysanthemum and the Sword". Her original notes for the synergy lecture were never found after her death. She was elected a Fellow of the American Academy of Arts and Sciences in 1947. She continued her teaching after the war, advancing to the rank of full professor only two months before her death, in New York on September 17, 1948.

Benedict's "Patterns of Culture" (1934) was translated into fourteen languages and for years, it was published in many editions and used as standard reading material for anthropology courses in American universities.

The essential idea in "Patterns of Culture" is, according to the foreword by Margaret Mead, "her view that human cultures are 'personality writ large. As Benedict wrote in that book, "A culture, like an individual, is a more or less consistent pattern of thought and action" (46). Each culture, she held, chooses from "the great arc of human potentialities" only a few characteristics which become the leading personality traits of the persons living in that culture. These traits comprise an interdependent constellation of aesthetics and values in each culture which together add up to a unique gestalt.

For example, she described the emphasis on "restraint" in Pueblo cultures of the American southwest, and the emphasis on "abandon" in the Native American cultures of the Great Plains. She used the Nietzschean opposites of "Apollonian" and "Dionysian" as the stimulus for her thought about these Native American cultures. She describes how, in ancient Greece, the worshipers of Apollo emphasized order and calm in their celebrations.

In contrast, the worshipers of Dionysus, the god of wine, emphasized wildness, abandon, letting go, as did Native Americans. She described in detail the contrasts between rituals, beliefs, personal preferences amongst people of diverse cultures to show how each culture had a "personality" that was encouraged in each individual.

Other anthropologists of the "culture and personality" school also developed these ideas, notably Margaret Mead in her "Coming of Age in Samoa" (published before "Patterns of Culture") and "Sex and Temperament in Three Primitive Societies" (published just after Benedict's book came out). Benedict was a senior student of Franz Boas when Mead began to study with them, and they had extensive and reciprocal influence on each other's work. Abram Kardiner was also affected by these ideas, and in time, the concept of "modal personality" was born: the cluster of traits most commonly thought to be observed in people of any given culture.

Benedict, in "Patterns of Culture," expresses her belief in cultural relativism. She desired to show that each culture has its own moral imperatives that can be understood only if one studies that culture as a whole. It was wrong, she felt, to disparage the customs or values of a culture different from one's own. Those customs had a meaning to the people who lived them which should not be dismissed or trivialized. We should not try to evaluate people by our standards alone. Morality, she argued, was "relative" to the values of the culture in which one operated.

As she described the Kwakiutl of the Pacific Northwest (based on the fieldwork of her mentor Boas), the Pueblo of New Mexico (among whom she had direct experience), the nations of the Great Plains, the Dobu culture of New Guinea (regarding whom she relied upon Mead and Reo Fortune's fieldwork), she gave evidence that their values, even where they may seem strange, are intelligible in terms of their own coherent cultural systems and should be understood and respected. This also formed a central argument in her later work on the Japanese following World War II.

Critics have objected to the degree of abstraction and generalization inherent in the "culture and personality" approach. Some have argued that particular patterns she found may be only a part or a subset of the whole cultures. For example, David Friend Aberle writes that the Pueblo people may be calm, gentle, and much given to ritual when in one mood or set of circumstances, but they may be suspicious, retaliatory, and warlike in other circumstances.

In 1936, she was appointed an associate professor at Columbia University. However, by then, Benedict had already assisted in the training and guidance of several Columbia students of anthropology including Margaret Mead and Ruth Landes.

Benedict was among the leading cultural anthropologists who were recruited by the US government for war-related research and consultation after the US entry into World War II.

One of Benedict's lesser-known works was a pamphlet "The Races of Mankind" which she wrote with her colleague at the Columbia University Department of Anthropology, Gene Weltfish. This pamphlet was intended for American troops and set forth, in simple language with cartoon illustrations, the scientific case against racist beliefs.

"The world is shrinking," begin Benedict and Weltfish. "Thirty-four nations are now united in a common cause—victory over Axis aggression, the military destruction of fascism" (p. 1).

The nations united against fascism, they continue, include "the most different physical types of men."

And the writers explicate, in section after section, the best evidence they knew for human equality. They want to encourage all these types of people to join together and not fight amongst themselves. "[A]ll the peoples of the earth", they point out, "are a single family and have a common origin." We all have just so many teeth, so many molars, just so many little bones and muscles—so we can only have come from one set of ancestors no matter what our color, the shape of our head, the texture of our hair. "The races of mankind are what the Bible says they are—brothers. In their bodies is the record of their brotherhood."

Benedict is known not only for her earlier "Patterns of Culture" but also for her later book "The Chrysanthemum and the Sword", the study of the society and culture of Japan that she published in 1946, incorporating results of her war-time research.

This book is an instance of "Anthropology at a Distance." Study of a culture through its literature, through newspaper clippings, through films and recordings, etc., was necessary when anthropologists aided the United States and its allies in World War II. Unable to visit Nazi Germany or Japan under Hirohito, anthropologists made use of the cultural materials to produce studies at a distance. They were attempting to understand the cultural patterns that might be driving their aggression and hoped to find possible weaknesses, or means of persuasion that had been missed.

Benedict's war work included a major study, largely completed in 1944, aimed at understanding Japanese culture. Americans found themselves unable to comprehend matters in Japanese culture. For instance, Americans considered it quite natural for American prisoners of war to "want" their families to know they were alive, and to keep quiet when asked for information about troop movements, etc., while Japanese POWs, apparently, gave information freely and did not try to contact their families. Why was that? Why, too, did Asian peoples neither treat the Japanese as their liberators from Western colonialism, nor accept their own supposedly just place in a hierarchy that had Japanese at the top?

Benedict played a major role in grasping the place of the Emperor of Japan in Japanese popular culture, and formulating the recommendation to President Franklin D. Roosevelt that permitting continuation of the Emperor's reign had to be part of the eventual surrender offer.

Other Japanese who have read this work, according to Margaret Mead, found it on the whole accurate but somewhat "moralistic". Sections of the book were mentioned in Takeo Doi's book, "The Anatomy of Dependence", though Doi is highly critical of Benedict's concept that Japan has a 'shame' culture, whose emphasis is on how one's moral conduct appears to outsiders in contradistinction to America's (Christian) 'guilt' culture, in which the emphasis is on individual's internal conscience. Doi stated that this claim clearly implies the former value system is inferior to the latter one.

The American Anthropology Association awards an annual prize named after Benedict. The 'Ruth Benedict Prize' has two categories, one for monographs by one writer and one for edited volumes. The prize recognizes 'excellence in a scholarly book written from an anthropological perspective about a lesbian, gay, bisexual, or transgender topic'.

A U.S. 46¢ Great Americans series postage stamp in her honor was issued on October 20, 1995.
Benedict College in Stony Brook University has been named after her.

In 2005 Ruth Fulton Benedict was inducted into the National Women's Hall of Fame.





</doc>
<doc id="26543" url="https://en.wikipedia.org/wiki?curid=26543" title="Rosmalen">
Rosmalen

Rosmalen () is a town in the province of North Brabant, in the south of the Netherlands. The town is located 6 kilometers east of the city of 's-Hertogenbosch (Den Bosch) and has been part of that municipality since 1996. Its population is around 35,000. In 2005 the town began construction of a new neighbourhood, (named after the large kolks in the area created by flood water), to include 5,000 homes and other buildings.

Rosmalen has a significant and locally well known football club, OJC Rosmalen. Many players from OJC have played for professional football clubs, like FC Den Bosch, RKC Waalwijk, Willem II. Rosmalen is also the home of the second-largest basketball club in the Netherlands: The Black Eagles. Well-known players like Kees Akerboom, Jr., Thijs Vermeulen and Rob van Mil demonstrate the success of the club in developing talented players.

Rosmalen is the location of the , formerly a car museum/attraction park and now a convention center. The park hosts an annual international tennis tournament in the summer, the Rosmalen Grass Court Championships. The park is located about 7 km east of 's-Hertogenbosch and can be reached via the A59.




</doc>
<doc id="26544" url="https://en.wikipedia.org/wiki?curid=26544" title="Reichstag">
Reichstag

 is the specific German word for parliamentary buildings, often shortened to Reichstag, and may refer to:

Historic legislative bodies in German-speaking countries have been referred to as Reichstag, including:




</doc>
<doc id="26546" url="https://en.wikipedia.org/wiki?curid=26546" title="Ruslan Khasbulatov">
Ruslan Khasbulatov

Ruslan Imranovich Khasbulatov (, ) (born November 22, 1942) is a Russian economist and politician and the Chairman of Parliament of Russia of Chechen descent who played a central role in the events leading to the 1993 constitutional crisis in the Russian Federation.

Khasbulatov was born in Tolstoy-yurt, a village near Grozny, the capital of Chechnya, on November 22, 1942. In February 1944, he was deported to Central Asia during the Chechen deportations.

After studying in Almaty, Khasbulatov moved to Moscow in 1962, where he studied law at the prestigious Moscow State University. After graduating in 1966, he joined the Communist Party of the Soviet Union. He continued his studies, focusing on the political, social and economic development of capitalist countries, and received several higher degrees between 1970 and 1980. During the 1970s and 1980s, he published a number of books on international economics and trade.

In the late 1980s, Khasbulatov began to work closely with rising maverick in the Communist Party Boris Yeltsin. He was elected to the Congress of People's Deputies of the Russian SFSR in 1990. He followed Yeltsin in the successful resistance to the putsch attempt in 1991. He quit the Communist Party in August 1991, and on October 29, 1991 he was elected speaker of the Supreme Soviet of RSFSR.

Khasbulatov had been an ally of Yeltsin in this period, and played a key role in leading the resistance to the 1991 coup attempt. However, he and Yeltsin drifted apart following the collapse of the Soviet Union at the end of 1991. 

After the collapse of the USSR, Khasbulatov consolidated his control over the Russian parliament and became the second most powerful man in Russia after Yeltsin himself. Among other factors, the escalating clash of egos between Khasbulatov and Yeltsin led to the Russian constitutional crisis of 1993, in which Khasbulatov (along with Vice-President Aleksandr Rutskoy) led the Supreme Soviet of Russia in its power struggle with the president, which ended with Yeltsin's violent assault on and subsequent dissolution of the parliament in October 1993.

Khasbulatov was arrested along with the other leaders of the parliament. In 1994, the newly elected Duma pardoned him along with other key leaders of the anti-Yeltsin resistance.

Following the end of his political career, Khasbulatov returned to his earlier profession as a teacher of economics as founder and head of the Department of International Economy at the Plekhanov Russian Academy of Economics (REA). He continues to comment on political developments in Russia. 

 


</doc>
<doc id="26547" url="https://en.wikipedia.org/wiki?curid=26547" title="Six Nations Championship">
Six Nations Championship

The Six Nations Championship (known as the Guinness Six Nations for sponsorship reasons) is an annual international men's rugby union competition between the teams of England, France, Ireland, Italy, Scotland, and Wales. The current champions are Wales, who won the 2019 tournament.

The Six Nations is the successor to the Home Nations Championship (1883–1909 and 1932–39), played between teams from England, Ireland, Scotland, and Wales, which was the first international rugby union tournament. With the addition of France, this became the Five Nations Championship (1910–31 and 1947–99), which in turn became the Six Nations Championship with the addition of Italy.

Wales hold the overall record, with 39 victories (27 outright and 12 shared) to England's 38 (10 shared victories). England hold the record for outright wins with 28. Since the Six Nations era started in 2000, only Italy and Scotland have failed to win the Six Nations title.

The women's tournament started as the Women's Home Nations in the 1996 season.

The tournament was first played in 1883 as the Home Nations Championship among the four Home Nations — England, Ireland, Scotland, and Wales. However, England was excluded from the 1888 and 1889 tournaments due to their refusal to join the International Rugby Football Board. The tournament then became the Five Nations Championship in 1910 with the addition of France. The tournament was expanded in 2000 to become the Six Nations Championship with the addition of Italy.

Following the relative success of the Tier 2 nations in the 2015 Rugby World Cup, there were calls by Octavian Morariu, the president of Rugby Europe, to let Georgia and Romania join the Six Nations due to their consistent success in the European Nations Cup and ability to compete in the Rugby World Cup.

The tournament begins on the first weekend in February and culminates with Super Saturday on the second or third Saturday in March. The format of the Championship is simple: each team plays every other team once (making a total of 15 matches), with home ground advantage alternating from one year to the next. Prior to the 2017 tournament, two points were awarded for a win, one for a draw and none for a loss. Unlike many other rugby union competitions the bonus point system had not previously been used.

On 30 November 2016, the Six Nations Committee announced that a bonus point system would be trialled in the 2017 Championship. The system is similar to the one used in most rugby championships (0 points for a loss, 2 for a draw, 4 for a win, 1 for scoring four or more tries in a match, and 1 for losing by 7 points or fewer), with the only difference being that a Grand Slam winner will be given 3 extra points to ensure they finish top of the table.

Prior to 1994, teams equal on match points shared the championship. Since then, ties have been broken by considering the points difference (total points scored minus total points conceded) of the teams. The rules of the championship further provide that if teams tie on both match points and points difference, the team that scored the most tries wins the championship. Were this decider to be a tie, the tying teams would share the championship. To date, however, match points and points difference have been sufficient to decide the championship.

Also, the team that finishes at the bottom of the league table is said to have won the Wooden Spoon, although no actual trophy is given to the team. A team that has lost all five matches is said to have been whitewashed. Since the inaugural Six Nations tournament in 2000, only England and Ireland have avoided the Wooden Spoon award. Italy are the holders of the most Wooden Spoon awards in the Six Nations era with 14, and have been whitewashed nine times. However, each of the other five nations has accumulated more than that through competing in previous eras.

The winners of the Six Nations are presented with the Championship Trophy. This was originally conceived by the Earl of Westmorland, and was first presented to the winners of the 1993 championship, France. It is a sterling silver trophy, designed by James Brent-Ward and made by a team of eight silversmiths from the London firm William Comyns.

It has 15 side panels representing the 15 members of the team and with three handles to represent the three officials (referee and two touch judges). The cup has a capacity of 3.75 litres – sufficient for five bottles of champagne. Within the mahogany base is a concealed drawer which contains six alternative finials, each a silver replica of one of the team emblems, which can be screwed on the detachable lid.

A new trophy was introduced for the 2015 Championship. 
The new trophy was designed and crafted by Thomas Lyte silversmiths and replaces the 1993 edition, which is being retired as it represented the nations that took part in the Five Nations Championship. Ireland were the last team to win the old trophy, and coincidentally, the first team to win the new one.

A team that wins all its games wins the 'Grand Slam'.

The Triple Crown may only be won by one of the Home Nations of England, Ireland, Scotland or Wales, when one nation wins all three of their matches against the others. The Triple Crown dates back to the original Home Nations Championship, but the physical Triple Crown Trophy has been awarded only since 2006, when the Royal Bank of Scotland (the primary sponsor of the competition) commissioned Hamilton & Inches to design and create a dedicated Triple Crown Trophy. It has since been won four times by Ireland, three times by Wales and three times by England.

Several individual competitions take place under the umbrella of the tournament. Some of these trophies are also awarded for other matches between the two teams outside the Six Nations.
As of the 2020 competition, Six Nations matches are held in the following stadia:

The opening of Aviva Stadium in May 2010 ended the arrangement with the Gaelic Athletic Association (GAA) that allowed the all-Ireland governing body for rugby union, the Irish Rugby Football Union, to use the GAA's flagship stadium, Croke Park, for its international matches. This arrangement was made necessary by the 2007 closure and subsequent demolition of Ireland's traditional home at Lansdowne Road; Aviva Stadium was built on the former Lansdowne Road site. During this construction, Croke Park was the largest of the Six Nations grounds, with a capacity of 82,300.

In 2012 Italy moved their home games from the 32,000 seat Stadio Flaminio, to Stadio Olimpico, also in Rome, with a capacity of 72,000.

The French Rugby Federation (FFR) had planned to build a new stadium of its own, seating 82,000 in the southern suburbs of Paris, because of frustrations with their tenancy of Stade de France. However the project was cancelled in December 2016. France played their 2018 match against Italy at Stade Vélodrome in Marseille.

Bold indicates that the team did not win any matches.

Bold indicates that the team did not win any matches.

Ronan O'Gara of Ireland holds the career scoring record with 557 points. England's Jonny Wilkinson currently holds the records for individual points in one match (35 points against Italy in 2001) and one season with 89 (scored in 2001).

The record for tries in a match is held by Scotsman George Lindsay who scored five tries against Wales in 1887. England's Cyril Lowe and Scotland's Ian Smith jointly hold the record for tries in one season with 8 (Lowe in 1914, Smith in 1925). Ireland's Brian O'Driscoll has the Championship record for tries with 26.

The record for appearances is held by Sergio Parisse of Italy, with 69 appearances, since his Six Nations debut in 2004.

The most points scored by a team in one match was 80 points, scored by England against Italy in 2001. England also scored the most ever points in a season in 2001 with 229, and most tries in a season with 29. Wales hold the record for fewest tries conceded during a season in the Six Nations era, conceding only 2 in 5 games in 2008, but the 1977 Grand Slam-winning France team did not concede a try in their four matches. Wales hold the record for the longest time without conceding a try, at 358 minutes in the 2013 tournament.

The Championship is run from headquarters in Dublin, Ireland by Six Nations Rugby Ltd, which also takes responsibility for the British and Irish Lions tours. Benjamin Morel became the CEO of the Six Nations Championship as of 5 November 2018, replacing John Feehan, who stepped down on 20 April 2018.

The BBC has long covered the tournament in the United Kingdom, broadcasting all matches apart from England home matches between 1997 and 2002, which were shown live by Sky Sports with highlights on the BBC. Between 2003 and 2015, the BBC covered every match live on BBC Sport either on BBC One or BBC Two with highlights also on the BBC Sport website and either on the BBC Red Button or late at night on BBC Two. In 2011, it was announced that the BBC's coverage of the tournament on TV, radio and online would be extended to 2017. 

On 9 July 2015, in reaction to bids by Sky for the rights beginning in 2018, the BBC ended its contract two seasons early, and renegotiated a joint contract with ITV Sport for rights to the Six Nations from 2016 through 2021. ITV acquired rights to England, Ireland and Italy home matches, while the BBC acquired rights to France, Scotland and Wales home matches. By ending its contract early, the BBC saved around £30 million, while the new contract generated £20 million in additional revenue for the Six Nations. With the end of the contract nearing, speculation once again emerged in 2020 that Sky was pursuing rights to the Six Nations from 2022 onward; under the Ofcom "listed events" rules, rights to the tournament can be held by a pay television channel if delayed broadcasts or highlights are made available on free-to-air television. It was reported that a bid for CVC Equity Partners to purchase a stake in the Six Nations was being hindered by a desire for a more lucrative broadcast contract; a call for the Six Nations to be moved to Category A (which requires live coverage to air free-to-air) was rejected.

In Ireland, RTÉ have broadcast the championship since RTÉ's inception and continued to do so until 2017, while TG4 televised highlights. However, in late 2015 RTÉ's free-to-air rival TV3 was awarded the rights for every game from the Six Nations on Irish television from 2018–2021.

France Télévisions covered the competition in France.

In Italy, from 2014 to 2017 DMAX of Discovery Communications broadcast all matches, and will do so until 2021.

In the United States, NBC Sports broadcasts matches in English and TV5 Monde airs matches in French. In Wales, S4C also broadcasts matches featuring the Welsh team shown by the BBC in Welsh.

Until 1998, the Championship had no title sponsor. Sponsorship rights were sold to Lloyds TSB Group for the 1999 tournament and the competition was titled the Lloyds TSB 5 Nations and Lloyds TSB 6 Nations until 2002.

The Royal Bank of Scotland Group took over sponsorship from 2003 until 2017, with the competition being branded the RBS 6 Nations. A new title sponsor was sought for the 2018 tournament and beyond. However, after struggling to find a new sponsor, organisers agreed a one-year extension at a reduced rate. As the RBS brand was being phased out, the tournament was named after the NatWest banking subsidiary, becoming the NatWest 6 Nations.

On 7 December 2018, Guinness was announced as the Championship's new title sponsor, with the competition to be named the Guinness Six Nations from 2019 to 2024.





</doc>
<doc id="26550" url="https://en.wikipedia.org/wiki?curid=26550" title="Reconquista">
Reconquista

The (Spanish and Portuguese), (English reconquest) was a period in the history of the Iberian Peninsula of about 780 years between the Umayyad conquest of Hispania in 711, the expansion of the Christian kingdoms throughout Hispania, and the fall of the Nasrid kingdom of Granada in 1492.

The beginning of the "" is traditionally marked with the Battle of Covadonga (718 or 722), the first known victory in Hispania by Christian military forces since the 711 military invasion undertaken by combined Arab-Berber forces. In that battle, a group led by Visigoth nobleman Pelagius and consisting of Hispano-Visigoth refugees, the remnants of their Hispano-Gothic aristocracy, and mountain tribes, including mainly Astures, Galicians, Cantabri and Basques, defeated a Muslim army in the mountains of northern Hispania and established the independent Christian Kingdom of Asturias. In the late 10th century, the Umayyad vizier Almanzor waged military campaigns for 30 years to subjugate the northern Christian kingdoms. His armies ravaged the north, even sacking the great shrine of Santiago de Compostela.

When the government of Córdoba disintegrated in the early 11th century, a series of petty successor states known as "taifas" emerged. The northern kingdoms took advantage of this situation and struck deep into Al-Andalus; they fostered civil war, intimidated the weakened "taifas", and made them pay large tributes ("parias") for protection. After a Muslim resurgence in the 12th century, the great Moorish strongholds in the south fell to Christian forces in the 13th century after the decisive battle of Navas de Tolosa (1212) —Córdoba in 1236 and Seville in 1248—leaving only the Muslim enclave of Granada as a tributary state in the south. After 1491, the entire peninsula was controlled by Christian rulers. The conquest was followed by a series of edicts (1499–1526) which forced the conversions of Muslims in Spain, and later were expelled from the Iberian peninsula by the decrees of King Philip III in 1609.

Beginning in the 19th century, traditional historiography has used the term "Reconquista" for what was earlier thought of as a restoration of the Visigothic Kingdom over conquered territories. The concept of Reconquista, consolidated in Spanish historiography in the second half of the 19th century, was associated with the development of a Spanish national identity, emphasizing nationalistic and romantic aspects.

Since the 19th century traditional historiography has stressed the existence of the "Reconquista", a continuous phenomenon by which the Christian Iberian kingdoms opposed and conquered the Muslim kingdoms, understood as a common enemy who had militarily seized territory from native Iberian Christians.

The concept of a Christian reconquest of the peninsula first emerged at the end of the 9th century. A landmark was set by the Christian "Chronica Prophetica" (883–884), a document stressing the Christian and Muslim cultural and religious divide in Hispania and the necessity to drive out the Muslims, considered as a restoration of the Visigothic Kingdom in the conquered territories.
Both Christian and Muslim rulers fought amongst themselves. Alliances between Muslims and Christians were not uncommon. Blurring distinctions even further were the mercenaries from both sides who simply fought for whoever paid the most. The period is seen today to have had long episodes of relative religious tolerance. However, this idea has been challenged by scholars today. 

The Crusades, which started late in the 11th century, bred the religious ideology of a Christian reconquest, confronted at that time with a similarly staunch Muslim jihad ideology in Al-Andalus by the Almoravids, and to an even greater degree by the Almohads. In fact, previous documents from the 10th and 11th centuries are mute on any idea of "reconquest". Accounts of Muslim-Christian hostility came into being to support that idea, most notably the "Chanson de Roland", a fictitious 11th-century French version of the Battle of Roncevaux Pass (778) dealing with the Iberian "Saracens" ("Moors"), and taught as historical fact in the French educational system since 1880.

In 711, North African Berber soldiers with some Arabs commanded by Tariq ibn Ziyad crossed the Strait of Gibraltar, engaging a Visigothic force led by King Roderic at the Battle of Guadalete in a moment of serious in-fighting and division across the Visigothic Kingdom of Hispania.

After Roderic's defeat, the Umayyad governor of Ifrikiya Musa ibn-Nusayr joined Tariq, directing a campaign against different towns and strongholds in Hispania. Some, like Mérida, Cordova, or Zaragoza in 712, probably Toledo, were taken, but many agreed to a treaty in exchange for maintaining autonomy, in Theodemir's dominion (region of Tudmir), or Pamplona, for example. The invading Islamic armies did not exceed 60,000 men.

After the establishment of a local Emirate, Caliph Al-Walid I, ruler of the Umayyad Caliphate, removed many of the successful Muslim commanders. Tariq ibn Ziyad was recalled to Damascus and replaced with Musa ibn-Nusayr, who had been his former superior. Musa's son, Abd al-Aziz ibn Musa, apparently married Egilona, Roderic's widow, and established his regional government in Seville. He was suspected of being under the influence of his wife and was accused of wanting to convert to Christianity and of planning a secessionist rebellion. Apparently a concerned Al-Walid I ordered Abd al-Aziz's assassination. Caliph Al-Walid I died in 715 and was succeeded by his brother Sulayman ibn Abd al-Malik. Sulayman seems to have punished the surviving Musa ibn-Nusayr, who very soon died during a pilgrimage in 716. In the end, Abd al-Aziz ibn Musa's cousin, Ayyub ibn Habib al-Lakhmi became the "wali" (governor) of Al-Andalus.

A serious weakness amongst the Muslim conquerors was the ethnic tension between Berbers and Arabs. The Berbers were indigenous inhabitants of North Africa who had only recently converted to Islam; they provided most of the soldiery of the invading Islamic armies but sensed Arab discrimination against them. This latent internal conflict jeopardized Umayyad unity. The Ummyyad forces arrived and crossed the Pyrenees by 719. The last Visigothic king Ardo resisted them in Septimania, where he fended off the Berber-Arab armies until 720.

After the Islamic Moorish conquest of most of the Iberian Peninsula in 711–718 and the establishment of the emirate of Al-Andalus, an Umayyad expedition suffered a major defeat at the Battle of Toulouse and was halted for a while on its way north. Odo of Aquitaine had married his daughter to Uthman ibn Naissa, a rebel Berber and lord of Cerdanya, in an attempt to secure his southern borders in order to fend off Charles Martel's attacks on the north. However, a major punitive expedition led by Abdul Rahman Al Ghafiqi, the latest emir of Al-Andalus, defeated and killed Uthman, and the Muslim governor mustered an expedition north across the western Pyrenees, looted areas up to Bordeaux, and defeated Odo in the Battle of the River Garonne in 732.

A desperate Odo turned to his archrival Charles Martel for help, who led the Frankish and remaining Aquitanian armies against the Umayyad armies and defeated them at the Battle of Tours in 732, killing Abdul Rahman Al Ghafiqi. While Moorish rule began to recede, it would remain in parts of the Iberian peninsula for another 760 years.

A drastic increase of taxes by the emir Anbasa ibn Suhaym Al-Kalbi provoked several rebellions in Al-Andalus, which a series of succeeding weak emirs were unable to suppress. Around 722, a Muslim military expedition was sent into the north in late summer to suppress a rebellion led by Pelagius of Asturias (Pelayo in Spanish, Pelayu in Asturian). Traditional historiography has hailed Pelagius' victory at Covadonga as the beginning of the "Reconquista". 

Two northern realms, Navarre and Asturias, despite their small size, demonstrated an ability to maintain their independence. Because the Umayyad rulers based in Córdoba were unable to extend their power over the Pyrenees, they decided to consolidate their power within the Iberian peninsula. Arab-Berber forces made periodic incursions deep into Asturias, but this area was a "cul-de-sac" on the fringes of the Islamic world fraught with inconveniences during campaigns and little interest.

It comes then as no surprise that, besides focusing on raiding the Arab-Berber strongholds of the Meseta, Alphonse I centred on expanding his domains at the expense of the neighbouring Galicians and Basques at either side of his realm just as much. During the first decades, Asturian control over part of the kingdom was weak, and for this reason it had to be continually strengthened through matrimonial alliances and war with other peoples from the north of the Iberian Peninsula. After Pelayo's death in 737, his son Favila of Asturias was elected king. Favila, according to the chronicles, was killed by a bear during a trial of courage. Pelayo's dynasty in Asturias survived and gradually expanded the kingdom's boundaries until all of northwest Hispania was included by roughly 775. However, credit is due to him and to his successors, the "Banu Alfons" from the Arab chronicles. Further expansion of the northwestern kingdom towards the south occurred during the reign of Alfonso II (from 791–842). A king's expedition arrived in and pillaged Lisbon in 798, probably concerted with the Carolingians.

The Asturian kingdom became firmly established with the recognition of Alfonso II as king of Asturias by Charlemagne and the Pope. During his reign, the bones of St. James the Great were declared to have been found in Galicia, at Santiago de Compostela. Pilgrims from all over Europe opened a channel of communication between the isolated Asturias and the Carolingian lands and beyond, centuries later.

After the Umayyad conquest of the Iberian heartland of the Visigothic kingdom, the Muslims crossed the Pyrenees and gradually took control of Septimania, starting in 719 with the conquest of Narbonne through 725 when Carcassonne and Nîmes were secured. From the stronghold of Narbonne, they tried to conquer Aquitaine but suffered a major defeat at the Battle of Toulouse (721).

Ten years after halting their advance north, Odo of Aquitaine married his daughter to Uthman ibn Naissa, a rebel Berber and lord of Cerdanya (perhaps all of contemporary Catalonia as well), in an attempt to secure his southern borders to fend off Charles Martel's attacks on the north. However, a major punitive expedition led by Abdul Rahman Al Ghafiqi, the latest emir of Al-Andalus, defeated and killed Uthman.

After expelling the Muslims from Narbonne in 759 and driving their forces back over the Pyrenees, the Carolingian king Pepin the Short conquered Aquitaine in a ruthless eight-year war. Charlemagne followed his father by subduing Aquitaine by creating counties, taking the Church as his ally and appointing counts of Frankish or Burgundian stock, like his loyal William of Gellone, making Toulouse his base for expeditions against Al-Andalus. Charlemagne decided to organize a regional subkingdom the Spanish March, which included part of contemporary Catalonia, in order to keep the Aquitanians in check and to secure the southern border of the Carolingian Empire against Muslim incursions. In 781, his three-year-old son Louis was crowned king of Aquitaine, under the supervision of Charlemagne's trustee William of Gellone, and was nominally in charge of the incipient Spanish March.

Meanwhile, the takeover of the southern fringes of Al-Andalus by Abd ar-Rahman I in 756 was opposed by Yusuf ibn Abd al-Rahman, autonomous governor ("wāli") or king ("malik") of al-Andalus. Abd ar-Rahman I expelled Yusuf from Cordova, but it took still decades for him to expand to the north-western Andalusian districts. He was also opposed externally by the Abbasids of Baghdad who failed in their attempts to overthrow him. In 778, Abd al-Rahman closed in on the Ebro valley. Regional lords saw the Umayyad emir at the gates and decided to enlist the nearby Christian Franks. According to Ali ibn al-Athir, a Kurdish historian of the 12th century, Charlemagne received the envoys of Sulayman al-Arabi, Husayn, and Abu Taur at the Diet of Paderborn in 777. These rulers of Zaragoza, Girona, Barcelona, and Huesca were enemies of Abd ar-Rahman I, and in return for Frankish military aid against him offered their homage and allegiance.

Charlemagne, seeing an opportunity, agreed upon an expedition and crossed the Pyrenees in 778. Near the city of Zaragoza Charlemagne received the homage of Sulayman al-Arabi. However the city, under the leadership of Husayn, closed its gates and refused to submit. Unable to conquer the city by force, Charlemagne decided to retreat. On the way home the rearguard of the army was ambushed and destroyed by Basque forces at the Battle of Roncevaux Pass. "The Song of Roland", a highly romanticized account of this battle, would later become one of the most famous of the Middle Ages. Around 788 Abd ar-Rahman I died and was succeeded by Hisham I. In 792 Hisham proclaimed a jihad, advancing in 793 against the Kingdom of Asturias and Carolingian Septimania (Gothia). They defeated William of Gellone, Count of Toulouse, in battle, but William led an expedition the following year across the eastern Pyrenees. Barcelona, a major city, became a potential target for the Franks in 797, as its governor Zeid rebelled against the Umayyad emir of Córdoba. An army of the emir managed to recapture it in 799, but Louis, at the head of an army, crossed the Pyrenees and besieged the city for two years until it finally capitulated in 801.

The main passes in the Pyrenees were Roncesvalles, Somport and La Jonquera. Charlemagne established across them the vassal regions of Pamplona, Aragon, and Catalonia respectively. Catalonia was itself formed from a number of small counties, including Pallars, Girona, and Urgell; it was called the "Marca Hispanica" by the late 8th century. They protected the eastern Pyrenees passes and shores and were under the direct control of the Frankish kings. Pamplona's first king was Iñigo Arista, who allied with his Muslim kinsmen the Banu Qasi and rebelled against Frankish overlordship and overcame a Carolingian expedition in 824 that led to the setup of the Kingdom of Pamplona. Aragon, founded in 809 by Aznar Galíndez, grew around Jaca and the high valleys of the Aragon River, protecting the old Roman road. By the end of the 10th century, Aragon, which then was just a county, was annexed by Navarre. Sobrarbe and Ribagorza were small counties and had little significance to the progress of the "Reconquista".

In the late 9th century under Count Wilfred, Barcelona became the "de facto" capital of the region. It controlled the other counties' policies in a union, which led in 948 to the independence of Barcelona under Count Borrel II, who declared that the new dynasty in France (the Capets) were not the legitimate rulers of France nor, as a result, of his county. These states were small and, with the exception of Navarre, did not have the capacity for attacking the Muslims in the way that Asturias did, but their mountainous geography rendered them relatively safe from being conquered, and their borders remained stable for two centuries.

In the High Middle Ages, the fight against the Moors in the Iberian Peninsula became linked to the fight of the whole of Christendom. It only later underwent a significant shift in meaning toward a religiously justified war of liberation (see the Augustinian concept of a Just War). The papacy and the influential Abbey of Cluny in Burgundy not only justified the acts of war but actively encouraged Christian knights to seek armed confrontation with Moorish "infidels" instead of with each other..

The military orders such as the Order of Santiago, Montesa, Order of Calatrava, and the Knights Templar were founded or called to fight in Hispania. The Popes called the knights of Europe to join the effort to destroy the Muslim states of the peninsula. After the so-called Disaster of Alarcos, French, Navarrese, Castilian, Portuguese and Aragonese armies united against the Muslim forces in the massive "battle of Las Navas de Tolosa" (1212). The large territories awarded to military orders and nobles were the origin of the latifundia in today's Andalusia and Extremadura in Spain, and Alentejo in Portugal.

Medieval Christian armies mainly comprised two types of forces: the cavalry (mostly nobles, but including commoner knights from the 10th century on) and the infantry, or "peones" (peasants). Infantry only went to war if needed, which was not frequent.
In an atmosphere of constant conflict, warfare and daily life were strongly intertwined during this period. These armies reflected the need for society to be on constant alert during the first chapters of the Reconquista. These forces were capable of moving long distances in short times.

Cavalry tactics in Hispania involved knights approaching the enemy, throwing javelins, then withdrawing to a safe distance before commencing another assault. Once the enemy formation was sufficiently weakened, the knights charged with thrusting spears (lances did not arrive in Hispania until the 11th century). There were three types of knights ("caballeros"): royal knights, noble knights ("caballeros hidalgos"), and commoner knights ("caballeros villanos", or "mounted soldier from a villa"). Royal knights were mainly nobles with a close relationship with the king, and thus claimed a direct Gothic inheritance.

Royal knights in the early stages of the Reconquista were equipped in the same manner as their Gothic ancestors.: mail hauberk, kite shield, a long sword (designed to fight from the horse), javelins, spears and a Visigothic axe. Noble knights came from the ranks of the "infanzones" or lower nobles, whereas the commoner knights were not noble but were wealthy enough to afford a horse. Uniquely in Europe, these horsemen comprised a militia cavalry force with no feudal links, being under the sole control of the king or the count of Castile because of "fueros" (charters) with the crown. Both noble and common knights wore padded armour and carried javelins, spears and round-tasselled shield (influenced by Moorish shields), as well as a sword.

The "peones" were peasants who went to battle in service of their feudal lord. Poorly equipped, with bows and arrows, spears and short swords, they were mainly used as auxiliary troops. Their function in battle was to contain the enemy troops until the cavalry arrived and to block the enemy infantry from charging the knights. The longbow, the composite bow, and the crossbow were the basic types of bows and were especially popular in the infantry.

In the early Middle Ages in Hispania, armour was typically made of leather, with iron scales. Head protections consisted of a round helmet with nose protector (influenced by the designs used by Vikings, who attacked during the 8th and 9th centuries) and a chain mail headpiece. Shields were often round or kidney-shaped, except for the kite-shaped designs used by the royal knights. Usually adorned with geometric designs, crosses or tassels, shields were made out of wood and had a leather cover.

Steel swords were the most common weapon. The cavalry used long double-edged swords and the infantry short, single-edged ones. Guards were either semicircular or straight, but always highly ornamented with geometrical patterns. Spears and javelins were up to 1.5 metres long and had an iron tip. The double-axe – made of iron, 30 cm long, and possessing an extremely sharp edge – was designed to be equally useful as a thrown weapon or in close combat. Maces and hammers were not common, but some specimens have remained and are thought to have been used by members of the cavalry.

Finally, mercenaries were an important factor, as many kings did not have enough soldiers available. Norsemen, Flemish spearmen, Frankish knights, Moorish mounted archers, and Berber light cavalry were the main types of mercenaries available and used in the conflict.

This style of warfare remained dominant in the Iberian Peninsula until the late 11th century, when lance tactics entered from France, although the traditional horse javelin-shot techniques continued to be used. In the 12th and 13th centuries, soldiers typically carried a sword, a lance, a javelin, and either bow and arrows or crossbow and darts/bolts. Armor consisted of a coat of mail over a quilted jacket, extending at least to the knees, a helmet or iron cap, and bracers protecting the arms and thighs, either metal or leather.

Shields were round or triangular, made of wood, covered with leather, and protected by an iron band; the shields of knights and nobles would bear the family's coat of arms. Knights rode in both the Muslim style, "a la jineta" (i.e. the equivalent of a modern jockey's seat), a short stirrup strap and bended knees allowed for better control and speed, or in the French style, "a la brida", a long stirrup strap allowed for more security in the saddle (i.e. the equivalent of the modern cavalry seat, which is more secure) when acting as heavy cavalry. Horses were occasionally fitted with a coat of mail as well.

Around the 14th and 15th centuries heavy cavalry gained a predominant role, where knights used to wear full plate armors.

The northern principalities and kingdoms survived in their mountainous strongholds (see above). However, they started a definite territorial expansion south at the turn of the 10th century (Leon, Najera). The fall of the Caliphate of Cordova (1031) heralded a period of military expansion for the northern kingdoms, now divided into several mighty regional powers after the division of the Kingdom of Navarre (1035). A myriad of autonomous Christian kingdoms emerged thereafter.

The Kingdom of Asturias was located in the Cantabrian Mountains, a wet and mountainous region in the north of the Iberian Peninsula. It was the first Christian power to emerge. The kingdom was established by a Visigothic nobleman, named Pelagius ("Pelayo"), who had possibly returned after the Battle of Guadalete in 711 and was elected leader of the Asturians, and the remnants of the "gens Gothorum" ( The Hispano-Gothic aristocracy and the Hispano-Visigothic population who took refuge in the North ). Historian Joseph F. O'Callaghan says an unknown number of them fled and took refuge in Asturias or Septimania. In Asturias they supported Pelagius's uprising, and joining with the indigenous leaders, formed a new aristocracy. The population of the mountain region consisted of native Astures, Galicians, Cantabri, Basques and other groups unassimilated into Hispano-Gothic society, laying the foundations for the Kingdom of Asturias and starting the Astur-Leonese dynasty that spanned from 718 to 1037 and led the initial efforts in the Iberian peninsula to take back the territories then ruled by the Moors. Although the new dynasty first ruled in the mountains of Asturias, with the capital of the kingdom established initially in Cangas de Onís, and was in its dawn mostly concerned with securing the territory and settling the monarchy, the latest kings (particularly Alfonso III of Asturias) emphasized the nature of the new kingdom as heir of that in Toledo and the restoration of the Visigothic nation in order to vindicate the expansion to the south. However, such claims have been overall dismissed by modern historiography, emphasizing the distinct, autochthonous nature of the Cantabro-Asturian and Vasconic domains with no continuation to the Gothic Kingdom of Toledo.

Pelagius' kingdom initially was little more than a gathering point for the existing guerrilla forces. During the first decades, the Asturian dominion over the different areas of the kingdom was still lax, and for this reason it had to be continually strengthened through matrimonial alliances with other powerful families from the north of the Iberian Peninsula. Thus, Ermesinda, Pelagius' daughter, was married to Alfonso, Dux Peter of Cantabria's son. Alfonso's son Fruela married Munia, a Basque from Álava, after crushing a Basque uprising (probably resistance). Their son is reported to be Alfonso II, while Alfonso I's daughter Adosinda married Silo, a local chief from the area of Flavionavia, Pravia.

Alfonso's military strategy was typical of Iberian warfare at the time. Lacking the means needed for wholesale conquest of large territories, his tactics consisted of raids in the border regions of Vardulia. With the plunder he gained further military forces could be paid, enabling him to raid the Muslim cities of Lisbon, Zamora, and Coimbra. Alfonso I also expanded his realm westwards conquering Galicia.

During the reign of King Alfonso II (791–842), the kingdom was firmly established, and a series of Muslim raids caused the transfer of the Asturian capital to Oviedo. The king is believed to have initiated diplomatic contacts with the kings of Pamplona and the Carolingians, thereby gaining official recognition for his kingdom and his crown from the Pope and Charlemagne.

The bones of St. James the Great were proclaimed to have been found in Iria Flavia (present day Padrón) in 813 or probably two or three decades later. The cult of the saint was transferred later to Compostela (from Latin "campus stellae", literally "the star field"), possibly in the early 10th century when the focus of Asturian power moved from the mountains over to Leon, to become the Kingdom of Leon or Galicia-Leon. Santiago's were among many saint relics proclaimed to have been found across north-western Hispania. Pilgrims started to flow in from other Iberian Christian realms, sowing the seeds of the later Way of Saint James (11–12th century) that sparked the enthusiasm and religious zeal of continental Christian Europe for centuries.

Despite numerous battles, neither the Umayyads nor the Asturians had sufficient forces to secure control over these northern territories. Under the reign of Ramiro, famed for the highly legendary Battle of Clavijo, the border began to slowly move southward and Asturian holdings in Castile, Galicia, and Leon were fortified, and an intensive program of re-population of the countryside began in those territories. In 924 the Kingdom of Asturias became the Kingdom of Leon, when Leon became the seat of the royal court (it didn't bear any official name).

Alfonso III of Asturias repopulated the strategically important city Leon and established it as his capital. King Alfonso began a series of campaigns to establish control over all the lands north of the Douro river. He reorganized his territories into the major duchies (Galicia and Portugal) and major counties (Saldaña and Castile), and fortified the borders with many castles. At his death in 910 the shift in regional power was completed as the kingdom became the Kingdom of Leon. From this power base, his heir Ordoño II was able to organize attacks against Toledo and even Seville.

The Caliphate of Córdoba was gaining power, and began to attack Leon. King Ordoño allied with Navarre against Abd-al-Rahman, but they were defeated in Valdejunquera in 920. For the next 80 years, the Kingdom of Leon suffered civil wars, Moorish attack, internal intrigues and assassinations, and the partial independence of Galicia and Castile, thus delaying the reconquest and weakening the Christian forces. It was not until the following century that the Christians started to see their conquests as part of a long-term effort to restore the unity of the Visigothic kingdom.

The only point during this period when the situation became hopeful for Leon was the reign of Ramiro II. King Ramiro, in alliance with Fernán González of Castile and his retinue of "caballeros villanos", defeated the Caliph in Simancas in 939. After this battle, when the Caliph barely escaped with his guard and the rest of the army was destroyed, King Ramiro obtained 12 years of peace, but he had to give González the independence of Castile as payment for his help in the battle. After this defeat, Moorish attacks abated until Almanzor began his campaigns. Alfonso V finally regained control over his domains in 1002. Navarre, though attacked by Almanzor, remained intact.

The conquest of Leon did not include Galicia which was left to temporary independence after the withdrawal of the Leonese king. Galicia was conquered soon after (by Ferdinand, son of Sancho the Great, around 1038). However, this brief period of independence meant that Galicia remained a kingdom and fief of Leon, which is the reason it is part of Spain and not Portugal. Subsequent kings titled themselves kings of Galicia and Leon, instead of merely king of Leon as the two were united personally and not in union.

Ferdinand I of Leon was the leading king of the mid-11th century. He conquered Coimbra and attacked the taifa kingdoms, often demanding the tributes known as parias. Ferdinand's strategy was to continue to demand parias until the taifa was greatly weakened both militarily and financially. He also repopulated the Borders with numerous "fueros". Following the Navarrese tradition, on his death in 1064 he divided his kingdom between his sons. His son Sancho II of Castile wanted to reunite the kingdom of his father and attacked his brothers, with a young noble at his side: Rodrigo Díaz, later known as El Cid Campeador. Sancho was killed in the siege of Zamora by the traitor Bellido Dolfos (also known as Vellido Adolfo) in 1072. His brother Alfonso VI took over Leon, Castile and Galicia.

Alfonso VI the Brave gave more power to the "fueros" and repopulated Segovia, Ávila and Salamanca. Once he had secured the Borders, King Alfonso conquered the powerful Taifa kingdom of Toledo in 1085. Toledo, which was the former capital of the Visigoths, was a very important landmark, and the conquest made Alfonso renowned throughout the Christian world. However, this "conquest" was conducted rather gradually, and mostly peacefully, during the course of several decades. It was not until after sporadic and consistent population resettlements had taken place that Toledo was decisively conquered.

Alfonso VI was first and foremost a tactful monarch who chose to understand the kings of taifa and employed unprecedented diplomatic measures to attain political feats before considering the use of force. He adopted the title "Imperator totius Hispaniae" ("Emperor of all Hispania", referring to all the Christian kingdoms of the Iberian Peninsula, and not just the modern country of Spain). Alfonso's more aggressive policy towards the taifas worried the rulers of those kingdoms, who called on the African Almoravids for help.

The Kingdom of Pamplona primarily extended along either side of the Pyrenees on the Atlantic Ocean. The kingdom was formed when local leader Íñigo Arista led a revolt against the regional Frankish authority and was elected or declared King in Pamplona (traditionally in 824), establishing a kingdom inextricably linked at this stage to their kinsmen, the muwallad Banu Qasi of Tudela.

Although relatively weak until the early 11th century, Pamplona took a more active role after the accession of Sancho the Great (1004–1035). The kingdom expanded greatly under his reign, as it absorbed Castile, Leon, and what was to be Aragon, in addition to other small counties that would unite and become the Principality of Catalonia. This expansion also led to the independence of Galicia, as well as gaining overlordship over Gascony.

In the 12th century, however, the kingdom contracted to its core, and in 1162 King Sancho VI declared himself king of Navarre. Throughout its early history, the Navarrese kingdom engaged in frequent skirmishes with the Carolingian Empire, from which it maintained its independence, a key feature of its history until 1513.

The Kingdom of Aragon started off as an offshoot of the Kingdom of Navarre. It was formed when Sancho III of Navarre decided to divide his large realm among all his sons. Aragon was the portion of the realm which passed to Ramiro I of Aragon, an illegitimate son of Sancho III. The kingdoms of Aragon and Navarre were several times united in personal union until the death of Alfonso the Battler in 1135.

In 1137 the heiress of the kingdom married the count of Barcelona, and their son Alfonso II ruled from 1162 the combined possessions of his parents, resulting in what modern historians call the Crown of Aragon.

In the following centuries, the Crown of Aragon conquered a number of territories in the Iberian peninsula and the Mediterranean, including the kingdom of Valencia and the kingdom of Mallorca. James I of Aragon, also known as James the Conqueror, expanded his territories to the north, south and east. James also signed the Treaty of Corbeil (1258), which released him from the nominal suzerainty of the King of France.

Early in his reign, James attempted to reunite the Aragonese and Navarrese crowns through a treaty with the childless Sancho VII of Navarre. But the Navarrese nobles rejected him, and chose Theobald IV of Champagne in his stead.

Later on, Ferdinand II of Aragon, married Isabella of Castile, leading to a dynastic union which eventually gave birth to modern Spain, after the conquest of Upper Navarre (Navarre south of the Pyrenees) and the kingdom of Granada.

In 1139, after an overwhelming victory in the Battle of Ourique against the Almoravids, Afonso Henriques was proclaimed the first King of Portugal by his troops. According to the legend, Christ announced from heaven Afonso's great deeds, whereby he would establish the first Portuguese Cortes at Lamego and be crowned by the Primate Archbishop of Braga. In the Treaty of Zamora in 1143, Alfonso VII of Leon and Castile recognized Portuguese independence from the Kingdom of Leon.

In 1147, Portugal captured Santarém, and seven months later the city of Lisbon was also brought under Portuguese control after the Siege of Lisbon. By the papal bull Manifestis Probatum, Pope Alexander III recognized Afonso Henriques as King of Portugal in 1179.

With Portugal finally recognized as an independent kingdom by its neighbours, Afonso Henriques and his successors, aided by Crusaders and the military monastic orders the Knights Templar, the Order of Aviz or the Order of Saint James, pushed the Moors to the Algarve on the southern coast of Portugal. After several campaigns, the Portuguese part in the "Reconquista" came to an end with the definitive capture of the Algarve in 1249. With all of Portugal now under the control of Afonso III of Portugal, religious, cultural and ethnic groups became gradually homogenized.

After the completion of the "Reconquista", the Portuguese territory was a Roman Catholic realm. Nonetheless, Denis of Portugal carried out a short war with Castile for possession of the towns of Serpa and Moura. After this, Denis avoided war; he signed the Treaty of Alcanizes with Ferdinand IV of Castile in 1297, establishing the present-day borders.

During the suppression of the Knights Templar all over Europe, under the influence of Philip IV of France and Pope Clement V requesting its annihilation by 1312, King Denis reinstituted the Templars of Tomar as the Order of Christ in 1319. Denis believed that the Order's assets should by their nature stay in any given Order instead of being taken by the King, largely for the Templars' contribution to the "Reconquista" and the reconstruction of Portugal after the wars.

The experience gained during the battles of the "Reconquista" was fundamental to Conquest of Ceuta, the first step to the establishment of the Portuguese Empire. Likewise, the contact with Muslim's navigation techniques and sciences enabled the creation of Portuguese nautical innovations such as the caravel – the principal Portuguese ship during their voyages of exploration in the Age of Discovery.

Minor Christian realms were the Kingdom of Viguera (970–1005), the Lordship of Albarracín (1167–1300) and the (1094–1102).

Clashes and raids on bordering Andalusian lands did not keep the Christian kingdoms from battling among themselves or allying with Muslim kings. Some Muslim kings had Christian-born wives or mothers. Some Christian warriors, like El Cid, were contracted by taifa kings to fight against their neighbours. Indeed, El Cid's first battle experience was gained fighting for a Muslim state against a Christian state. At the Battle of Graus in 1063, he and other Castilians fought on the side of al-Muqtadir, Muslim sultan of Zaragoza, against the forces of Ramiro I of Aragon. There is even an instance of a crusade being declared against another Christian king in Hispania.

After the defeat of Alfonso VIII, King of Castile, at Alarcos, Kings Alfonso IX of Leon and Sancho VII of Navarre entered an alliance with the Almohads and invaded Castile in 1196. By the end of the year Sancho VII had dropped out of the war under Papal pressure. Early in 1197, at the request of Sancho I, King of Portugal, Pope Celestine III declared a crusade against Alfonso IX and released his subjects from their responsibilities to the king, declaring that "the men of his realm shall be absolved from their fidelity and his dominion by authority of the apostolic see." Together the Kings of Portugal, Castile, and Aragon invaded Leon. In the face of this onslaught combined with pressure from the Pope, Alfonso IX was finally forced to sue for peace in October 1197.

In the late years of "Al-Andalus", Castile had the might to conquer the remnants of the kingdom of Granada, but the kings preferred to wait and claim the tribute of the Muslim "parias"The trade of Granadan goods and the parias were a major means by which African gold entered medieval Europe.

The "Reconquista" was a process not only of war and conquest, but also of repopulation. Christian kings moved their own people to locations abandoned by Muslims in order to have a population capable of defending the borders. The main repopulation areas were the Douro Basin (the northern plateau), the high Ebro valley (La Rioja) and central Catalonia. The repopulation of the Douro Basin took place in two distinct phases. North of the river, between the 9th and 10th centuries, the "pressure" (or "presura") system was employed. South of the Douro, in the 10th and 11th centuries, the "presura" led to the "charters" ("forais" or "fueros"). "Fueros" were used even south of the Central Range.

The "presura" referred to a group of peasants who crossed the mountains and settled in the abandoned lands of the Douro Basin. Asturian laws promoted this system, for instance granting a peasant all the land he was able to work and defend as his own property. Of course, Asturian and Galician minor nobles and clergymen sent their own expeditions with the peasants they maintained. This led to very feudalised areas, such as Leon and Portugal, whereas Castile, an arid land with vast plains and harsh climate, only attracted peasants with no hope in Biscay. As a consequence, Castile was governed by a single count, but had a largely non-feudal territory with many free peasants. "Presuras" also appear in Catalonia, when the count of Barcelona ordered the Bishop of Urgell and the count of Gerona to repopulate the plains of Vic.

During the 10th century and onwards, cities and towns gained more importance and power, as commerce reappeared and the population kept growing. "Fueros" were charters documenting the privileges and usages given to all the people repopulating a town. The "fueros" provided a means of escape from the feudal system, as "fueros" were only granted by the monarch. As a result, the town council was dependent on the monarch alone and, in turn, was required to provide "auxilium" – aid or troops – for their monarch. The military force of the towns became the "caballeros villanos". The first "fuero" was given by count Fernán González to the inhabitants of Castrojeriz in the 940's. The most important towns of medieval Hispania had "fueros", or "forais". In Navarre, "fueros" were the main repopulating system. Later on, in the 12th century, Aragon also employed the system; for example, the "fuero" of Teruel, which was one of the last fueros, in the early 13th century.

From the mid-13th century on, no more charters were granted, as the demographic pressure had disappeared and other means of re-population were created. "Fueros" remained as city charters until the 18th century in Aragon, Valencia and Catalonia and until the 19th century in Castile and Navarre. "Fueros" had an immense importance for those living under them, who were prepared to go to war to defend their rights under the charter. In the 19th century, the abolition of the "fueros" in Navarre would be one of the causes of the Carlist Wars. In Castile, disputes over the system contributed to the war against Charles I (Castilian War of the Communities).

During the 9th century the Berbers returned to North Africa in the aftermath of revolts. Many governors of large cities distant from the capital, Córdoba, had planned to establish their independence. Then, in 929, the Emir of Córdoba (Abd-ar-Rahman III), the leader of the Umayyad dynasty, declared himself Caliph, independent from the Abbasids in Baghdad. He took all the military, religious, and political power and reorganised the army and the bureaucracy.

After regaining control over the dissident governors, Abd-ar-Rahman III tried to conquer the remaining Christian kingdoms of the Iberian peninsula, attacking them several times and forcing them back beyond the Cantabrian Mountains. Abd-ar-Rahman's grandson later became a puppet in the hands of the great Vizier Almanzor ("al-Mansur", "the victorious"). Almanzor waged several campaigns attacking and sacking Burgos, Leon, Pamplona, Barcelona, and Santiago de Compostela before his death in 1002.

Between Almanzor's death and 1031, Al-Andalus suffered many civil wars, which ended in the division into the Taifa kingdoms. The taifas were small kingdoms, established by the city governors. The result was many (up to 34) small kingdoms, each centered upon its capital. Their governors had no larger-scale vision of the Moorish presence in the Iberian peninsula and had no qualms about attacking their neighbouring kingdoms whenever they could gain advantage by doing so.

The split into the taifa states weakened the Islamic presence, and the Christian kingdoms further advanced as Alfonso VI of Leon and Castile conquered Toledo in 1085. Surrounded by enemies, taifa rulers sent a desperate appeal to the Berber chieftain Yusuf ibn Tashfin, leader of the Almoravids.

The Almoravids were a Muslim militia composed of Berber, and unlike previous Muslim rulers, they were not so tolerant towards Christians and Jews. Their armies entered the Iberian peninsula on several occasions (1086, 1088, 1093) and defeated King Alfonso at the Battle of Sagrajas in 1086, but initially their purpose was to unite all the taifas into a single Almoravid Caliphate. Their actions halted the southward expansion of the Christian kingdoms. Their only defeat came at Valencia in 1094, due to the actions of El Cid.

Meanwhile, Navarre lost all importance under King Sancho IV, for he lost Rioja to Sancho II of Castile, and nearly became the vassal of Aragon. At his death, the Navarrese chose as their king Sancho Ramírez, King of Aragon, who thus became Sancho V of Navarre and I of Aragon. Sancho Ramírez gained international recognition for Aragon, uniting it with Navarre and expanding the borders south, conquering "Wasqa" Huesca deep in the valleys in 1096 and building a fort, El Castellar, 25 km from "Saraqusta" Zaragoza.

Catalonia came under intense pressure from the taifas of Zaragoza and Lérida, as well as from internal disputes, as Barcelona suffered a dynastic crisis that led to open war among the smaller counties. But by the 1080s, the situation had calmed down, and the dominion of Barcelona over the smaller counties was restored.

After a brief period of disintegration (the second Taifa period), the Almohads, the rising power in North Africa, took over most of "Al-Andalus". However they were decisively defeated at the Battle of Las Navas de Tolosa (1212) by a Christian coalition, losing almost all the remaining lands of "Al-Andalus" in the following decades. By 1252 only the Kingdom of Granada remained intact but as a vassal state of Castile.

Ferdinand and Isabella completed the "Reconquista" with a war against the Emirate of Granada that started in 1482 and ended with Granada's surrender on January 2, 1492. The Moors in Castile previously numbered "half a million within the realm". By 1492 some 100,000 had died or been enslaved, 200,000 had emigrated, and 200,000 remained in Castile. Many of the Muslim elite, including Granada's former Emir Muhammad XII, who had been given the area of the Alpujarras mountains as a principality, found life under Christian rule intolerable and emigrated to Tlemcen in North Africa.

In 1497 Spanish forces took Melilla, west of Oran, and the island of Djerba, south of Tunis, and went on to more important gains, with the bloody seizure of Oran in 1509, and the capture of Bougie and Tripoli in 1510. The Spanish capture of Tripoli cost them some 300 men, while the inhabitants suffered between 3,000 and 5,000 killed and another 5,000–6,000 carried off as slaves. Soon thereafter, however, they faced competition from the rapidly expanding Ottoman Empire in the east and were pushed back.

As elsewhere in the Muslim world, Christians and Jews were allowed to retain their religions, with their own legal systems and courts, by paying a tax, the "jizya". The penalty for not paying it was imprisonment and death.

The new Christian hierarchy demanded heavy taxes from non-Christians and gave them rights, such as in the Treaty of Granada (1491) only for Moors in recently Islamic Granada. On July 30, 1492, all the Jewish community – some 200,000 people – were forcibly expelled. The next year the Alhambra decree ordered the expulsion of practicing Jews, leading many to convert to Catholicism. In 1502, Queen Isabella I declared conversion to Catholicism compulsory within the Kingdom of Castile. King Charles V did the same to Moors in the Kingdom of Aragon in 1526, forcing conversions of its Muslim population during the Revolt of the Germanies. Many local officials took advantage of the situation to seize property.

Most of the descendants of those Muslims who submitted to conversion to Christianity – rather than exile – during the early periods of the Spanish and Portuguese Inquisition, the Moriscos, were later expelled from Spain after serious social upheaval, when the Inquisition was at its height. The expulsions were carried out more severely in eastern Spain (Valencia and Aragon) due to local animosity towards Muslims and Moriscos where they were seen as economic rivals by local workers who saw them as cheap labor undermining their bargaining position with the landlords. Exactions imposed on the Moriscos paved the way to a major Morisco revolt happening in 1568, with the final expulsion of the Moriscos from Castile taking place in 1609; they were driven from Aragon at about the same time.

Making things more complex were the many former Muslims and Jews known as "Moriscos", "Marranos", and "Conversos", who shared ancestors in common with many Christians, especially among the aristocracy, causing much concern over loyalty and attempts by the aristocracy to hide their non-Christian ancestry. Some – the numbers are debated – continued to secretly practice their religions and use their languages well into the sixteenth century. Those that the Spanish Inquisition found to be secretly practicing Islam or Judaism were executed, imprisoned, or exiled. Nevertheless, all those deemed to be "New Christians" were repeatedly suspected of illegally continuing in secret to practice their religions various crimes against the Spanish state including continued practice of Islam or Judaism. New Christians were subject to many discriminatory practices starting in the sixteenth century.

The many advances and retreats created several social types:

Real, legendary, and fictional episodes from the "Reconquista" are the subject of much of medieval Galician-Portuguese, Spanish, and Catalan literature such as the "cantar de gesta".

Some noble genealogies show the close, though not numerous, relations between Muslims and Christians. For example, Al-Mansur Ibn Abi Aamir, whose rule is considered to have marked the peak of power for Moorish "Al-Andalus" Hispania, married Abda, daughter of Sancho Garcés II of Navarra, who bore him a son, named Abd al-Rahman and commonly known in a pejorative sense as Sanchuelo ("Little Sancho"; in Arabic: "Shanjoul").

After his father's death, Sanchuelo/Abd al-Rahman, as a son of a Christian princess, was a strong contender to take over the ultimate power in Muslim al-Andalus. A hundred years later, King Alfonso VI of Castile, regarded as one of the greatest medieval Spanish kings, designated his son (also named Sancho) by the Muslim princess refugee Zaida of Seville, as his heir.

The "Reconquista" was a war with long periods of respite between the adversaries, partly for pragmatic reasons and also due to infighting among the Christian kingdoms of the North spanning over seven centuries. Some populations practiced Islam or Christianity as their own religion during these centuries, so the identity of contenders changed over time.

Currently, festivals called "moros y cristianos" (Castilian), "moros i cristians" (Catalan), "mouros e cristãos" (Portuguese) and "mouros e cristiáns" (Galician), which all mean "Moors and Christians", recreate the fights as colorful parades with elaborate garments and many fireworks, especially on the central and southern towns of the Land of Valencia, like Alcoi, Ontinyent or Villena.

A 2016 study found that the "rate of Reconquest"—how rapidly the Christian frontier was expanded—has persistent effects on the Spanish economy to this day. After an initial phase of military conquest, Christians states incorporated the conquered land. When large frontier regions were incorporated at once, the land was mostly given to the nobility and the military orders, with negative effects on long-term development. The incorporation of small regions, on the other hand, generally allowed for the participation of individual settlers and was more likely to fall under the auspices of the crown. This led to a more equitable distribution of land and greater social equality, with positive effects on long-term development.

On the conclusion of Iberian victory over the Moors, the Iberian powers, Spain and Portugal didn't stop their warring against the Muslims solely in their homelands—they extended the conflict against Islam overseas. The Spanish under the Habsburg dynasty soon became the champions of Roman Catholicism in Europe and the Mediterranean against the encroaching threat of the Ottoman Empire. In a similar vein, the Portuguese also extended the Reconquista, this time against Muslim states overseas. The conquest of Ceuta marked the beginning of Portuguese expansion into Muslim Africa. Soon, the Portuguese also went into conflict with the Ottoman Caliphate in the Mediterranean, Indian Ocean and Southeast Asia as the Portuguese conquered the Ottomans' allies: the Sultanate of Adal in East Africa, the Sultanate of Delhi in South Asia and the Sultanate of Malacca in Southeast Asia. Meanwhile, the Spanish also went to war against the Sultanate of Brunei in Southeast Asia. The Spanish sent expeditions from New Spain (Mexico) to conquer and Christianize the Philippines, then a territory of the Sultanate of Brunei. Brunei itself was assaulted during the Castilian War. Spain also went to war against the Sultanates of Sulu, Maguindanao, and Lanao in the Spanish-Moro Conflict. The primary inspiration for these wars against Muslim states overseas was the Reconquista.





</doc>
<doc id="26551" url="https://en.wikipedia.org/wiki?curid=26551" title="Raku ware">
Raku ware

The Western version of raku was developed in the 20th century by studio potters. Typically wares are fired at a high temperature, and after removing pieces from the kiln, the wares are placed in an open-air container filled with combustible material, which is not a traditional Raku practice in Japan. The Western process can give a great variety of colors and surface effects, making it very popular with studio and amateur potters.

"Raku" means "enjoyment".

In the 16th century, Sen no Rikyū, the Japanese tea master, was involved with the construction of the Jurakudai and had a tile-maker, named Chōjirō, produce hand-moulded tea bowls for use in the wabi-styled tea ceremony that was Rikyū's ideal. The resulting tea bowls made by Chōjirō were initially referred to as "ima-yaki" ("contemporary ware") and were also distinguished as Juraku-yaki, from the red clay (Juraku) that they employed. Hideyoshi presented Jokei, Chōjirō's son, with a seal that bore the Chinese character for "raku". Raku then became the name of the family that produced the wares. Both the name and the ceramic style have been passed down through the family (sometimes by adoption) to the present 15th generation (Kichizaemon). The name and the style of ware has become influential in both Japanese culture and literature.

In Japan, there are "branch kilns" ("wakigama"), in the raku-ware tradition, that have been founded by Raku-family members or porters who apprenticed at the head family's studio. One of the most well-known of these is Ōhi-yaki (Ōhi ware).

After the publication of a manual in the 18th century, raku ware was also made in numerous workshops by amateur potters and tea practitioners in Kyoto, and by professional and amateur potters around Japan.

Raku ware marked an important point in the historical development of Japanese ceramics, as it was the first ware to use a seal mark and the first to focus on close collaboration between potter and patron. Other famous Japanese clay artists of this period include Dōnyū (grandson of Chōjirō, also known as Nonkō; 1574–1656), Hon'ami Kōetsu (1556–1637) and Ogata Kenzan (1663–1743).

It influenced Hōraku ware from Nagoya, Owari province in the later Edo period.

Bernard Leach is credited with bringing Raku to the west. In 1911 he attended a garden party in Tokyo which included a traditional tea ceremony and Raku firing. This was his first experience of ceramics. Although he continued to experimenting with Raku firing for a few years following his returned to England in 1920 - the technique was largely forgotten after the 1930s. 

Raku became popular with American potters in the late 1950s with the help of Paul Soldner. Americans kept the general firing process, that is, heating the pottery quickly to high temperatures and cooling it quickly, but continued to form their own unique style of raku.

Raku's unpredictable results and intense color attracts modern potters. These patterns and color result from the harsh cooling process and the amount of oxygen that is allowed to reach the pottery. Depending on what effect the artist wants, the pottery is either instantly cooled in water, cooled slowly in the open air, or placed in a barrel filled with combustible material, such as newspaper, covered, and allowed to smoke. Water immediately cools the pottery, stopping the chemical reactions of the glaze and fixing the colors. The combustible material results in smoke, which stains the unglazed portions of the pottery black. The amount of oxygen that is allowed during the firing and cooling process affects the resulting color of the glaze and the amount of crackle.

Unlike traditional Japanese raku, which is mainly hand built bowls of modest design, western raku tends to be vibrant in color, and comes in many shapes and sizes. Western raku can be anything from an elegant vase, to an eccentric abstract sculpture. Although some do hand build, most western potters use throwing wheels while creating their raku piece. Western culture has even created a new sub branch of raku called horse hair raku. These pieces are often white with squiggly black lines and smoke-like smudges. These effects are created by placing horse hair, feathers, or even sugar on the pottery as it is removed from the kiln and still extremely hot.

Amongst some of the western raku artists are the French ceramist Claude Champy, who received the Suntory Museum Grand Prix. Jane Malvisi is a British artist making raku figurines.

The first Japanese-style kiln in the west was built by Tsuronosuke Matsubayashi at Leach Pottery, St Ives in 1922.

The type and the size of kilns that are used in raku are crucial in the outcome. One aspect that can affect the results is the use of electric versus gas kilns. Electric kilns allow easy temperature control. Gas kilns, which comprise brick or ceramic fibers, can be used in either oxidation or reduction firing and use propane or natural gas. Gas kilns also heat more quickly than electric kilns, but it is more difficult to maintain temperature control. There is a note-worthy difference when using an updraft kiln rather than a downdraft kiln. An updraft kiln has shelves that trap heat. This effect creates uneven temperatures throughout the kiln. Conversely, a downdraft kiln pulls air down a separate stack on the side and allows a more even temperature throughout and allows the work to be layered on shelves.

It is important for a kiln to have a door that is easily opened and closed, because, when the artwork in the kiln has reached the right temperature (over 1000 degrees Celsius), it must be quickly removed and put in a metal or tin container with combustible material, which reduces the pot and leaves certain colors and patterns.

The use of a reduction chamber at the end of the raku firing was introduced by the American potter Paul Soldner in the 1960s to compensate for the difference in atmosphere between wood-fired Japanese raku kilns and gas-fired American kilns. Typically, pieces removed from the hot kiln are placed in masses of combustible material (e.g., straw, sawdust, or newspaper) to provide a reducing atmosphere for the glaze and to stain the exposed body surface with carbon.

Western raku potters rarely use lead as a glaze ingredient, due to its serious level of toxicity, but may use other metals as glaze ingredients. Japanese potters substitute a non-lead frit. Although almost any low-fire glaze can be used, potters often use specially formulated glaze recipes that "crackle" or craze (present a cracked appearance), because the crazing lines take on a dark color from the carbon.

Western raku is typically made from a stoneware clay body, bisque fired at and glost or glaze fired (the final firing) between , which falls into the cone 06 firing temperature range. The process is known for its unpredictability, particularly when reduction is forced, and pieces may crack or even explode due to thermal shock. Pots may be returned to the kiln to re-oxidize if firing results do not meet the potter's expectations, although each successive firing has a high chance of weakening the overall structural integrity of the pot. Pots that are exposed to thermal shock multiple times can break apart in the kiln, as they are removed from the kiln, or when they are in the reduction chamber.

The glaze firing times for raku ware are short: an hour or two as opposed to up to 16 hours for high-temperature cone 10 stoneware firings. This is due to several factors: raku glazes mature at a much lower temperature (under , as opposed to almost for high-fire stoneware); kiln temperatures can be raised rapidly; and the kiln is loaded and unloaded while hot and can be kept hot between firings.

Because temperature changes are rapid during the raku process, clay bodies used for raku ware must be able to cope with significant thermal stress. The usual way to add strength to the clay body and to reduce thermal expansion is to incorporate a high percentage of quartz, grog, or kyanite into the body before the pot is formed. At high additions, quartz can increase the risk of dunting or shivering. Therefore, kyanite is often the preferred material, as it contributes both mechanical strength and, in amounts up to 20%, significantly reduces thermal expansion. Although any clay body can be used, white stoneware clay bodies are unsuitable for the western raku process unless some material is added to deal with thermal shock. Porcelain, however, is often used but it must be thinly thrown.

Aesthetic considerations include clay color and fired surface texture, as well as the clay's chemical interaction with raku glazes.

In a craft conference in Kyoto in 1979, a heated debate sprang up between Western raku artists Paul Soldner and the youngest in the dynastic raku succession, Kichiemon, (of the fourteenth generation of the "Raku" family of potters) concerning the right to use the title "raku". The Japanese artists maintain that any work by other craftsman should hold their own name, (i.e., Soldner-ware, Hirsh-ware), as that was how "raku" was intended.

Raku in the west has been abstracted and is now a more philosophical approach with the emphasis on the spontaneity of surface pattern creation rather than purely a firing technique. Consequently, this has expanded its application from pots to sculptural ceramics.

Reduction firing is when the kiln atmosphere, which is full of combustible material, is heated up. "Reduction is incomplete combustion of fuel, caused by a shortage of oxygen, which produces carbon monoxide" (Arbuckle, 4) Eventually, all of the available oxygen is used. This then draws oxygen from the glaze and the clay to allow the reaction to continue. Oxygen serves as the limiting reactant in this scenario because the reaction that creates fire needs a constant supply of it to continue; when the glaze and the clay come out hardened, this means that the oxygen was subtracted from the glaze and the clay to accommodate the lack of oxygen in the atmosphere. Consequently, the Raku piece appears black or white, which depends upon the amount of oxygen that was lost from each area of the piece. The empty spaces that occur from the reduction of oxygen are filled in by carbon molecules in the atmosphere of the container, which makes the piece blacker in spots where more oxygen was retracted.

In the western style of raku firing, the aluminium container acts as a reduction chamber, which is a container that allows the carbon dioxide to pass through a small hole. A reduction atmosphere is created by closing the container. A reduction atmosphere induces a reaction between oxygen and the clay minerals, which affects the color. It also affects the metal elements of the glaze. Reduction is a decrease in oxidation number. Closing the can reduces the oxygen content after the combustible materials such as sawdust catch fire and forces the reaction to pull oxygen from the glazes and the clay minerals. For example, luster gets its color from deprivation of oxygen. The reduction agent is a substance from which electrons are being taken by another substance. The reaction uses oxygen from the atmosphere within the reduction tube, and, to continue, it receives the rest of the oxygen from the glazes. This leaves ions and iridescent luster behind. This creates a metallic effect. Pieces with no glaze have nowhere to get the oxygen from, so they take it from clay minerals. This atmosphere will turn clay black, making a matte color.

Raku is a unique form of pottery making; what makes it unique is the range of designs that can be created by simply altering certain variables. These variables—which include wax resist, glazes, slips, temperature, and timing—ultimately determine the outcome when firing a piece of clay.

Wax resist: which is painted over the bare untainted clay, results in the suspension of wax in water before the raku glaze goes on. This is done so that the glaze does not cover the area where the wax resist was applied, thus creating a design. When in the kiln, the wax melts off and the carbon, that results from oxygen reduction, replaces the wax. This is the result of the combustion reaction. Raku glazes contain alumina, which has a very high melting point. Therefore, carbon will not replace the glaze as it does the melted wax. Any unglazed areas turn black due to the carbon given off from the reduction of oxygen. Next, the clay is moved from the kiln to a container, usually a trashcan, which contains combustible organic materials such as leaves, sawdust, or paper.

Crackle glazes: is a glaze with a clear base that contain metallic compounds to add color. Metals such as copper, iron, and cobalt; which produce different colors. After the glaze has reached a certain temperature, the metal in the glaze reacts taking on a specific color. For example, cobalt produces dark-blue, and copper produces green but can also produce a red when the oxygen in the glaze is completely gone. Once the lid of the container is closed, the reduction oxidation (redox) process begins. The temperature change from the kiln to the container is where the magic of raku occurs. The change in temperature and in the redox sometimes cause cracking or crazing. Crazing is a consistent cracking in the glaze of a piece, as is seen on the white crackle glaze. This either enhances or detracts from the design. The timing of removal and placement in water directly affects the shades of each color.

Copper glazes: are treated completely different than crackle glazes. While with the crackle glazes you want the piece to go through an oxidation process and to cool so the glaze will crackle while transferring from the kiln to the reduction chamber, the copper glazes should soak up as little oxygen as possible, you want the piece to go from the kiln to the reduction chamber as quickly as possible. This causes the glaze to have as much reduction as possible and can pull out vibrant flashes of color from the glaze and end with either a matte or glossy depending on the type of glaze that you use colorful look.

Naked Raku is done by coating a section of the exterior of the piece with the slip taping off anywhere on the piece that you want to turn black after reduction. Then you place the piece directly into the kiln and slowly heat up to about until the slip has dried. Once dry continue heating until . When you reach temperature you can pull the piece from the kiln and place the piece into the reduction chamber. In reduction the carbon will soak into the clay where the slip has cracked and turn black, but where the slip is stuck on the clay will keep its natural color. Once the piece has cooled enough you can use your finger nails or a credit card to chip off the slip and reveal the design.

Horse hair: Horse hair decoration is a process where the piece is left without glaze and brought up to temperature in the kiln and when removed from the kiln it is not placed into the reduction chamber; instead it is placed in the open where horse hair is strategically arranged on the piece. The horse hair will immediately burn and leave thin linear markings on the pottery.

Hiroshi Teshigahara made the film "Rikyu", which is a nearly documentary story showing how Sen no Rikyu met Chojiro, who made the first genuine Raku tea bowl (chawan) and how Rikyu trained the shogun Toyotomi Hideyoshi in the tea ceremony with Raku chawans.(Ashton D 1997).




</doc>
<doc id="26552" url="https://en.wikipedia.org/wiki?curid=26552" title="Roy Orbison">
Roy Orbison

Roy Kelton Orbison (April 23, 1936 – December 6, 1988) was an American singer, songwriter, and musician known for his impassioned singing style, complex song structures, and dark, emotional ballads. His music was described by critics as operatic, earning him the nicknames "the Caruso of Rock" and "the Big O". Many of his songs conveyed vulnerability at a time when most male rock-and-roll performers chose to project defiant masculinity. He was known for his shyness and stage fright, countering these by wearing dark sunglasses.

Orbison began singing in a rockabilly and country-and-western band at high school. He was contracted by Sam Phillips of Sun Records in 1956, but enjoyed his greatest success with Monument Records. From 1960 to 1966, 22 of his singles reached the "Billboard" Top 40, and he wrote or co-wrote almost all that entered the Top 10, including "Only the Lonely" (1960), "Running Scared" (1961), "Crying" (1961), "In Dreams" (1963), and "Oh, Pretty Woman" (1964). From the mid-1960s he suffered a number of personal tragedies and his career faltered amidst declining record sales.

In the 1980s, Orbison experienced a resurgence in popularity following the success of several cover versions of his songs. In 1988, he co-founded the Traveling Wilburys, a rock supergroup with George Harrison, Bob Dylan, Tom Petty, and Jeff Lynne. Orbison died of a heart attack in December that year at age 52. One month later, his song "You Got It" (1989) was released as a solo single and became his first hit to reach the U.S. Top 10 in nearly 25 years.

Orbison's honours include inductions into the Rock and Roll Hall of Fame and Nashville Songwriters Hall of Fame in 1987, the Songwriters Hall of Fame in 1989, and the Musicians Hall of Fame and Museum in 2014. "Rolling Stone" placed him at number 37 on their list of the "Greatest Artists of All Time" and number 13 on their list of the "100 Greatest Singers of All Time". In 2002, "Billboard" magazine listed him at number 74 in the Top 600 recording artists.

Orbison was born on April 23, 1936 in Vernon, Texas, the middle son of Orbie Lee Orbison (1913–1984), an oil well driller and car mechanic, and nurse Nadine Vesta Shults (July 25, 1913 – May 12, 1992). The family moved to Fort Worth in 1942 to find work in the aircraft factories.

Roy attended Denver Avenue Elementary School until a polio scare prompted the family to return to Vernon, and they moved again to Wink, Texas in 1946. Orbison described life in Wink as "football, oil fields, oil, grease, and sand" and expressed relief that he was able to leave the desolate town. All the Orbison children had poor eyesight; Roy used thick corrective lenses from an early age. He was self-conscious about his appearance and began dyeing his nearly-white hair black when he was still young. He was quiet, self-effacing, and remarkably polite and obliging. He was always keen to sing, however. He considered his voice memorable, but not great.

Roy's father gave him a guitar on his sixth birthday. He recalled, "I was finished, you know, for anything else" by the time he was 7, and music became the focus of his life. His major musical influence as a youth was country music. He was particularly moved by Lefty Frizzell's singing, with its slurred syllables, and he adopted the name "Lefty Wilbury" during his time with the Traveling Wilburys. He also enjoyed Hank Williams, Moon Mullican and Jimmie Rodgers. One of the first musicians that he heard in person was Ernest Tubb, playing on the back of a truck in Fort Worth. In West Texas, he was exposed to rhythm and blues, Tex-Mex, the orchestral arrangements of Mantovani, and Cajun music. The cajun favourite "Jole Blon" was one of the first songs that he sang in public. He began singing on a local radio show at age 8, and he became the show's host by the late 1940s.

In high school, Orbison and some friends formed the band Wink Westerners. They played country standards and Glenn Miller songs at local honky-tonks and had a weekly radio show on KERB in Kermit, Texas. They were offered $400 to play at a dance, and Orbison realised that he could make a living in music. He enrolled at North Texas State College in Denton, planning to study geology so that he could secure work in the oil fields if music did not pay. He then heard that his schoolmate Pat Boone had signed a record deal, and it further strengthened his resolve to become a professional musician. He heard a song called "Ooby Dooby" while in college, composed by Dick Penner and Wade Moore, and he returned to Wink with "Ooby Dooby" in hand and continued performing with the Wink Westerners after his first year. He then enrolled in Odessa Junior College. Two members of the band quit and two new members were added, and the group won a talent contest and obtained their own television show on KMID-TV in Midland, Texas. The Wink Westerners kept performing on local TV, played dances at the weekends, and attended college during the day.

While living in Odessa, Orbison saw a performance by Elvis Presley. Johnny Cash toured the area in 1955 and 1956, appearing on the same local TV show as the Wink Westerners, and he suggested that Orbison approach Sam Phillips at Sun Records. Orbison did so and was told, "Johnny Cash doesn't run my record company!" The success of their KMID television show got them another show on KOSA-TV, and they changed their name to the Teen Kings. They recorded "Ooby Dooby" in 1956 for the Odessa-based Je–Wel label. Record store owner Poppa Holifield played it over the telephone for Sam Phillips, and Phillips offered the Teen Kings a contract.

The Teen Kings went to Sun Studio in Memphis, where Phillips wanted to record "Ooby Dooby" again, in his studio. The song was released on Sun 242 in May 1956 and broke into the "Billboard" Hot 100, peaking at number 59 and selling 200,000 copies. The Teen Kings toured with Sonny James, Johnny Horton, Carl Perkins, and Cash. Much influenced by Elvis Presley, Orbison performed frenetically, doing "everything we could to get applause because we had only one hit record". The Teen Kings also began writing songs in a rockabilly style, including "Go! Go! Go!" and "Rockhouse". The band ultimately split over disputed writing credits and royalties, but Orbison stayed in Memphis and asked his 16-year-old girlfriend, Claudette Frady, to join him there. They stayed in Phillips' home, sleeping in separate rooms. In the studio, Orbison concentrated on the mechanics of recording. Phillips remembered being much more impressed with Orbison's mastery of the guitar than with his voice. A ballad Orbison wrote, "The Clown", met with a lukewarm response; after hearing it, Sun Records producer Jack Clement told Orbison that he would never make it as a ballad singer.

Orbison was introduced to Elvis Presley's social circle, once going to pick up a date for Presley in his purple Cadillac. Orbison wrote "Claudette"—about Claudette Frady, whom he married in 1957—and the Everly Brothers recorded it as the B-side of "All I Have to Do Is Dream". The first, and perhaps only, royalties Orbison earned from Sun Records enabled him to make a down payment on his own Cadillac. Increasingly frustrated at Sun, he gradually stopped recording. He toured music circuits around Texas and then quit performing for seven months in 1958.

For a brief period in the late 1950s, Orbison made his living at Acuff-Rose, a songwriting firm concentrating mainly on country music. After spending an entire day writing a song, he would make several demonstration tapes at a time and send them to Wesley Rose, who would try to find musical acts to record them. Orbison attempted to sell to RCA Victor his recordings of songs by other writers, working with and being in awe of Chet Atkins, who had played guitar with Presley. One song he tried was "Seems to Me", by Boudleaux Bryant. Bryant's impression of Orbison was of "a timid, shy kid who seemed to be rather befuddled by the whole music scene. I remember the way he sang then—softly, prettily but almost bashfully, as if someone might be disturbed by his efforts and reprimand him."

Playing shows at night and living with his wife and young child in a tiny apartment, Orbison often took his guitar to his car to write songs. The songwriter Joe Melson, an acquaintance of Orbison's, tapped on his car window one day in Texas in 1958, and the two decided to write some songs together. In three recording sessions in 1958 and 1959, Orbison recorded seven songs at RCA Nashville. Only two singles were judged worthy of release by RCA. Wesley Rose brought Orbison to the attention of the producer Fred Foster at Monument Records.

Orbison was one of the first recording artists to popularise the "Nashville sound", with a group of session musicians known as The Nashville A-Team. The Nashville sound was developed by producers Chet Atkins, Owen Bradley (who worked closely with Patsy Cline), Sam Phillips, and Fred Foster. In his first session for Monument in Nashville, Orbison recorded a song that RCA had refused, "Paper Boy", backed by "With the Bug", but neither charted.

According to musician and author Albin Zak, the studio (with sound engineer Bill Porter, who experimented with close miking the doo-wop backing singers), the production by Foster, and the accompanying musicians gave Orbison's music a "polished, professional sound ... finally allow[ing] Orbison's stylistic inclinations free rein". Orbison requested a string section and with it, he recorded three new songs, the most notable of which was "Uptown", written with Joe Melson. Impressed with the results, Melson later recalled, "We stood in the studio, listening to the playbacks, and thought it was the most beautiful sound in the world." "The Rolling Stone Illustrated History of Rock and Roll" states that the music Orbison made in Nashville "brought a new splendour to rock", and compared the melodramatic effects of the orchestral accompaniment to the musical productions of Phil Spector.

"Uptown" reached only number 72 on the "Billboard" Top 100, and Orbison set his sights on negotiating a contract with an upscale nightclub somewhere. His initial success came just as the '50s rock-and-roll era was winding down. Starting in 1960, the charts in the United States came to be dominated by teen idols, novelty acts, and Motown girl groups.

Experimenting with a new sound, Orbison and Joe Melson wrote a song in early 1960 which, using elements from "Uptown", and another song they had written called "Come Back to Me (My Love)", employed strings and the Anita Kerr doo-wop backing singers. It also featured a note hit by Orbison in falsetto that showcased a powerful voice which, according to biographer Clayson, "came not from his throat but deeper within". The song was "Only the Lonely (Know the Way I Feel)". Orbison and Melson tried to pitch it to Elvis Presley and the Everly Brothers, but were turned down. They instead recorded the song at RCA's Nashville studio, with sound engineer Bill Porter trying a completely new strategy, building the mix from the top down rather than from the bottom up, beginning with close-miked backing vocals in the foreground, and ending with the rhythm section soft in the background. This combination became Orbison's trademark sound.

"Only the Lonely" shot to number two on the "Billboard" Hot 100 and hit number one in the UK and Australia. According to Orbison, the subsequent songs he wrote with Melson during this period were constructed with his voice in mind, specifically to showcase its range and power. He told "Rolling Stone" in 1988, "I liked the sound of [my voice]. I liked making it sing, making the voice ring, and I just kept doing it. And I think that somewhere between the time of "Ooby Dooby" and "Only the Lonely", it kind of turned into a good voice." Its success transformed Orbison into an overnight star and he appeared on Dick Clark's "Saturday Night Beechnut Show" out of New York City. When Presley heard "Only the Lonely" for the first time, he bought a box of copies to pass to his friends. Melson and Orbison followed it with the more complex "Blue Angel", which peaked at number nine in the US and number 11 in the UK. "I'm Hurtin'", with "I Can't Stop Loving You" as the B-side, rose to number 27 in the US, but failed to chart in the UK.

Orbison was now able to move to Nashville permanently with his wife Claudette and two sons Roy DeWayne and Anthony King. Back in the studio, seeking a change from the pop sound of "Only the Lonely" and "I'm Hurtin'", Orbison worked on a new song, "Running Scared", based loosely on the rhythm of Ravel's "Boléro"; the song was about a man on the lookout for his girlfriend's previous boyfriend, whom he feared would try to take her away. Orbison encountered difficulty when he found himself unable to hit the song's highest note without his voice breaking. He was backed by an orchestra in the studio and Porter told him he would have to sing louder than his accompaniment because the orchestra was unable to be softer than his voice. Fred Foster then put Orbison in the corner of the studio and surrounded him with coat racks forming an improvised isolation booth to emphasise his voice. Orbison was unhappy with the first two takes. In the third, however, he abandoned the idea of using falsetto and sang the final high 'A' naturally, so astonishing everyone present that the accompanying musicians stopped playing. On that third take, "Running Scared" was completed. Fred Foster later recalled, "He did it, and everybody looked around in amazement. Nobody had heard anything like it before." Just weeks later "Running Scared" reached number one on the "Billboard" Hot 100 chart and number 9 in the UK. The composition of Orbison's following hits reflected "Running Scared": a story about an emotionally vulnerable man facing loss or grief, with a crescendo culminating in a surprise climax that employed Orbison's dynamic voice.

"Crying" followed in July 1961 and reached number two; it was coupled with an up-tempo R&B song, "Candy Man", written by Fred Neil and Beverley Ross, which reached the "Billboard" Top 30, staying on the charts for two months. While Orbison was touring Australia in 1962, an Australian DJ referred to him affectionately as "The Big O", partly based on the big finishes to his dramatic ballads, and the moniker stuck with him thereafter. Orbison's second son was born the same year, and Orbison hit number four in the United States and number two in the UK with "Dream Baby (How Long Must I Dream)", an upbeat song by country songwriter Cindy Walker. (Orbison's producer later formed the Candymen quintet, which was Orbison's backing band from 1965 to 1970 and released a few singles and two albums of its own). Also in 1962, he charted with "The Crowd", "Leah", and "Workin' for the Man", which he wrote about working one summer in the oil fields near Wink. His relationship with Joe Melson, however, was deteriorating over Melson's growing concerns that his own solo career would never get off the ground.

Orbison eventually developed an image that did not reflect his personality. He had no publicist in the early 1960s, therefore he had little presence in fan magazines, and his single sleeves did not feature his picture. "Life" called him an "anonymous celebrity". After leaving his thick eyeglasses on an aeroplane in 1963, while on tour with the Beatles, Orbison was forced to wear his prescription Wayfarer sunglasses on stage and found that he preferred them. His biographers suggest that although he had a good sense of humour and was never morose, Orbison was very shy and suffered from severe stage fright; wearing sunglasses helped him hide somewhat. The sunglasses led some people to assume he was blind. His black clothes and song lyrics emphasised the image of mystery and introversion. His dark and brooding persona, combined with his tremulous voice in lovelorn ballads marketed to teenagers, made Orbison a star in the early 1960s. His string of top-40 hits continued with "In Dreams" (US number seven, UK number six), "Falling" (US number 22, UK number 9), and "Mean Woman Blues" (US number five, UK number three) coupled with "Blue Bayou" (US number 29, UK number three). According to the official Roy Orbison U.S. discography by Marcel Riesco, a rare alternative version of "Blue Bayou" was released in Italy. Orbison finished 1963 with a Christmas song written by Willie Nelson, "Pretty Paper" (US number 15 in 1963, UK number six in 1964).

As "In Dreams" was released in April 1963, Orbison was asked to replace Duane Eddy on a tour of the UK in top billing with the Beatles. When he arrived in Britain, however, he realised he was no longer the main draw. He had never heard of the Beatles, and annoyed, asked rhetorically, "What's a Beatle, anyway?" to which John Lennon replied, after tapping his shoulder, "I am". On the opening night, Orbison opted to go onstage first, although he was the more established act. The Beatles stood dumbfounded backstage as Orbison sang through 14 encores. Finally, when the audience began chanting "We want Roy!" again, Lennon and McCartney physically held Orbison back. Starr later said, "In Glasgow, we were all backstage listening to the tremendous applause he was getting. He was just standing there, not moving or anything." Through the tour, however, the two acts quickly learned to get along, a process made easier by the fact that the Beatles admired his work. Orbison felt a kinship with Lennon, but it was Harrison with whom he would later form a strong friendship.

Touring in 1963 took a toll on Orbison's personal life. His wife Claudette had an affair with the contractor who built their home in Hendersonville, Tennessee. Friends and relatives attributed the breakdown of the marriage to her youth and her inability to withstand being alone and bored. When Orbison toured Britain again in the autumn of 1963, she joined him. He was immensely popular wherever he went, finishing the tour in Ireland and Canada. Almost immediately, he toured Australia and New Zealand with the Beach Boys and returned again to Britain and Ireland, where he was so besieged by teenaged girls that the Irish police had to halt his performances to pull the girls off him. He travelled to Australia again, this time with the Rolling Stones. Mick Jagger later remarked, referring to a snapshot he took of Orbison in New Zealand, "a fine figure of a man in the hot springs, he was."

Orbison also began collaborating with Bill Dees, whom he had known in Texas. With Dees, he wrote "It's Over", a number-one hit in the UK and a song that would be one of his signature pieces for the rest of his career. When Claudette walked in the room where Dees and Orbison were writing to say she was heading for Nashville, Orbison asked if she had any money. Dees said, "A pretty woman never needs any money". Just 40 minutes later, "Oh, Pretty Woman" was completed. A riff-laden masterpiece that employed a playful growl he got from a Bob Hope movie, the epithet "mercy" Orbison uttered when he was unable to hit a note, it rose to number one in the autumn of 1964 in the United States and stayed on the charts for 14 weeks. It rose to number one in the UK, as well, spending a total of 18 weeks on the charts. The single sold over seven million copies. Orbison's success was greater in Britain; as "Billboard" magazine noted, "In a 68-week period that began on August 8, 1963, Roy Orbison was the "only" American artist to have a number-one single in Britain. He did it twice, with 'It's Over' on June 25, 1964, and 'Oh, Pretty Woman' on October 8, 1964. The latter song also went to number one in America, making Orbison impervious to the current chart dominance of British artists on both sides of the Atlantic."

Claudette and Orbison divorced in November 1964 over her infidelities, but reconciled 10 months later. His contract with Monument was expiring in June 1965. Wesley Rose, at this time acting as Orbison's agent, moved him from Monument Records to Metro-Goldwyn-Mayer (MGM) (though in Europe he remained with Decca's London Records) for $1 million and with the understanding that he would expand into television and films, as Elvis Presley had done. Orbison was a film enthusiast, and when not touring, writing, or recording, he dedicated time to seeing up to three films a day.

Rose also became Orbison's producer. Fred Foster later suggested that Rose's takeover was responsible for the commercial failure of Orbison's work at MGM. Engineer Bill Porter agreed that Orbison's best work could only be achieved with RCA Nashville's A-Team. Orbison's first collection at MGM, an album titled "There Is Only One Roy Orbison", sold fewer than 200,000 copies. With the onset of the British Invasion in 1964–65, the direction of popular music shifted dramatically, and most performers of Orbison's generation were driven from the charts.

While on tour again in the UK in 1966, Orbison broke his foot falling off a motorcycle in front of thousands of screaming fans at a race track; he performed his show that evening in a cast. Claudette travelled to England to accompany Roy for the remainder of the tour. It was now made public that the couple had happily re-married and were back together (they had re-married in December 1965).

Orbison was fascinated with machines. He was known to follow a car that he liked and make the driver an offer on the spot.

Orbison and Claudette shared a love for motorcycles; she had grown up around them, but Roy claimed Elvis Presley had introduced him to motorcycles. On June 6, 1966, when Orbison and Claudette were riding home from Bristol, Tennessee, she struck the door of a pickup truck which had pulled out in front of her on South Water Avenue in Gallatin, Tennessee and died instantly.

A grieving Orbison threw himself into his work, collaborating with Bill Dees to write music for "The Fastest Guitar Alive", a film that MGM had scheduled for him to star in as well. It was initially planned as a dramatic Western but was rewritten as a comedy. Orbison's character was a spy who stole and had to protect and deliver a cache of gold to the Confederate Army during the American Civil War and was supplied with a guitar that turned into a rifle. The prop allowed him to deliver the line, "I could kill you with this and play your funeral march at the same time," with, according to biographer Colin Escott, "zero conviction". Orbison was pleased with the film, although it proved to be a critical and box office failure. While MGM had included five films in his contract, no more were made.

He recorded an album dedicated to the songs of Don Gibson and another of Hank Williams covers, but both sold poorly. During the counterculture era, with the charts dominated by artists like Jimi Hendrix, Jefferson Airplane, the Rolling Stones, and the Doors, Orbison felt lost and directionless, later saying: "[I] didn't hear a lot I could relate to, so I kind of stood there like a tree where the winds blow and the seasons change, and you're still there and you bloom again."

During a tour of England and playing Birmingham on Saturday, September 14, 1968, he received the news that his home in Hendersonville, Tennessee, had burned down, and his two eldest sons had died. The property was sold to Johnny Cash, who demolished the building and planted an orchard on it. On March 25, 1969, Orbison married German teenager Barbara Jakobs, whom he had met several weeks before his sons' deaths. Wesley (born 1965), his youngest son with Claudette, was raised by Orbison's parents. Orbison and Barbara had a son (Roy Kelton) in 1970 and another (Alexander) in 1975.

Orbison continued recording albums in the 1970s, but none of them sold well. He went an entire decade by 1976 without an album reaching the charts. He also failed to produce any popular singles after the 1960s, except for a few in Australia. His fortunes sank so low that he began to doubt his own talents, and several of his 1970s albums were not released internationally due to low US sales. He left MGM Records in 1973 and signed a one-album deal with Mercury Records. Peter Lehman observed that Orbison's absence was a part of the mystery of his persona: "Since it was never clear where he had come from, no one seemed to pay much mind to where he had gone; he was just gone." His influence was apparent, however, as several artists released popular covers of his songs. Orbison's version of "Love Hurts" was remade by Gram Parsons and Emmylou Harris, again by hard rock band Nazareth, and by blues artist Jim Capaldi. Sonny James' version of "Only the Lonely" reached number one on the country music charts. Bruce Springsteen ended his concerts with Orbison songs, and Glen Campbell had a minor hit with a remake of "Dream Baby".

A compilation of Orbison's greatest hits reached number one in the UK in January 1976, and Orbison began to open concerts for the Eagles that year, who started as Linda Ronstadt's backup band. Ronstadt herself covered "Blue Bayou" in 1977, her version reaching number three on the "Billboard" charts and remaining in the charts for 24 weeks. Orbison credited this cover in particular for reviving his memory in the popular mind, if not his career. He signed again with Monument in 1976 and recorded "Regeneration" with Fred Foster, but it proved no more successful than before.

In late 1977, Orbison was not feeling well and decided to spend the winter in Hawaii. He checked in to a hospital there where testing discovered that he had severely obstructed coronary arteries. He underwent a triple coronary bypass on January 18, 1978. He had suffered from duodenal ulcers since 1960 and had been a heavy smoker since adolescence. He felt revitalised following the surgery, but he continued to smoke, and his weight fluctuated for the remainder of his life.

In 1980, Don McLean recorded "Crying" and it went to the top of the charts, first in the Netherlands then reaching number five in the US and staying on the charts for 15 weeks; it was number one in the UK for three weeks and also topped the Irish Charts. Orbison was all but forgotten in the US, yet he reached popularity in unlikely places such as Bulgaria in 1982. He was astonished to find that he was as popular there as he had been in 1964, and he was forced to stay in his hotel room because he was mobbed on the streets of Sofia. In 1981, he and Emmylou Harris won a Grammy Award for their duet "That Lovin' You Feelin' Again" from the comedy film "Roadie", in which Orbison also had a cameo role, and things were picking up. It was his first such award, and he felt hopeful of making a full return to popular music, though it was several years until this came to fruition. In the meantime, Van Halen released a hard-rock cover of "Oh, Pretty Woman" on their 1982 album "Diver Down", again further exposing a younger generation to Orbison's music.

Orbison originally declined David Lynch's request to allow the use of "In Dreams" for the film "Blue Velvet" (1986). Lynch used it anyway (although his first choice was "Crying"); the song served as one of several obsessions of a psychopathic character named Frank Booth (played by Dennis Hopper). It was lip-synched by an effeminate drug dealer played by Dean Stockwell, after which Booth demanded the song be played over and over, once beating the protagonist while the song played. During filming, Lynch asked for the song to be played repeatedly to give the set a surreal atmosphere. Orbison was initially shocked at its use: he saw the film in a theatre in Malibu and later said, "I was mortified because they were talking about the 'candy-coloured clown' in relation to a dope deal ... I thought, 'What in the world ...?' But later, when I was touring, we got the video out and I really got to appreciate what David gave to the song, and what the song gave to the movie—how it achieved this otherworldly quality that added a whole new dimension to 'In Dreams'."

By 1987, Orbison's career was fully revived. He released an album of his re-recorded hits, titled "". "Life Fades Away", a song he co-wrote with his friend Glenn Danzig and recorded, was featured in the film "Less Than Zero" (1987). He and k.d. lang performed a duet of "Crying" for inclusion on the soundtrack to the film "Hiding Out" (1987); the pair received a Grammy Award for Best Country Collaboration with Vocals after Orbison's death.

Also in 1987, Orbison was inducted into the Nashville Songwriters Hall of Fame and was initiated into the Rock and Roll Hall of Fame by Bruce Springsteen, who concluded his speech with a reference to his own album "Born to Run": "I wanted a record with words like Bob Dylan that sounded like Phil Spector—but, most of all, I wanted to sing like Roy Orbison. Now, everyone knows that no one sings like Roy Orbison." In response, Orbison asked Springsteen for a copy of the speech, and said of his induction that he felt "validated" by the honour. A few months later, Orbison and Springsteen paired again to film a concert at the Cocoanut Grove nightclub in Los Angeles. They were joined by Jackson Browne, T Bone Burnett, Elvis Costello, Tom Waits, Bonnie Raitt, Jennifer Warnes, James Burton, and k.d. lang. Lang later recounted how humbled Orbison had been by the display of support from so many talented and busy musicians: "Roy looked at all of us and said, 'If there is anything I can ever do for you, please call on me'. He was very serious. It was his way of thanking us. It was very emotional." The concert was filmed in one take and aired on Cinemax under the title ""; it was released on video by Virgin Records, selling 50,000 copies.

It was also in 1988 that Orbison began collaborating seriously with Electric Light Orchestra bandleader Jeff Lynne on a new album. Lynne had just completed production work on George Harrison's "Cloud Nine" album, and all three ate lunch together one day when Orbison accepted an invitation to sing on Harrison's new single. They subsequently contacted Bob Dylan, who, in turn, allowed them to use a recording studio in his home. Along the way, Harrison made a quick visit to Tom Petty's residence to obtain his guitar; Petty and his band had backed Dylan on his last tour. By that evening, the group had written "Handle with Care", which led to the concept of recording an entire album. They called themselves the Traveling Wilburys, representing themselves as half-brothers with the same father. They gave themselves stage names; Orbison chose his from his musical hero, calling himself "Lefty Wilbury" after Lefty Frizzell. Expanding on the concept of a traveling band of raucous musicians, Orbison offered a quote about the group's foundation in honour: "Some people say Daddy was a cad and a bounder. I remember him as a Baptist minister."

Lynne later spoke of the recording sessions: "Everybody just sat there going, 'Wow, it's Roy Orbison!' ... Even though he's become your pal and you're hanging out and having a laugh and going to dinner, as soon as he gets behind that [mic] and he's doing his business, suddenly it's shudder time." Orbison was given one solo track, "Not Alone Any More", on the album. His contributions were highly praised by the press. "Traveling Wilburys Vol. 1" spent 53 weeks on the US charts, peaking at number three. It reached No. 1 in Australia and No. 16 in the UK. The album won a Grammy for Best Rock Performance by a Duo or Group. "Rolling Stone" included it in the top 100 albums of the decade.

Orbison was in high demand for concerts and interviews once again, and was seemingly ecstatic about it. He began writing songs and collaborating with many musicians from his past and newer fans, to develop a solo album, "Mystery Girl".

"Mystery Girl" was co-produced by Jeff Lynne, whom Orbison considered the best producer he had ever collaborated with. Elvis Costello, Orbison's son Wesley and others offered their songs to him. The biggest hit from the album was "You Got It", written with Lynne and Tom Petty. It posthumously rose to No. 9 in the US and No. 3 in the UK.

In 2014, a demo of Orbison's "The Way Is Love" was released as part of the 25th-anniversary deluxe edition of "Mystery Girl". The song was originally recorded on a stereo cassette player around 1986. Orbison's sons contributed instrumentation on the track along with Roy's vocals; it was produced by John Carter Cash.

Although the video for the Wilburys' "Handle with Care" was filmed with Orbison, the video for "End of the Line" was filmed and released posthumously. During Orbison's vocal parts in "End of the Line", the video shows a guitar in a rocking chair, next to Orbison's framed photo.

Orbison determinedly pursued his second chance at stardom, but he expressed amazement at his success: "It's very nice to be wanted again, but I still can't quite believe it." He lost some weight to fit his new image and the constant demand of touring, as well as the newer demands of making videos. In the final three months of his life, he gave "Rolling Stone" magazine extensive access to his daily activities; he intended to write an autobiography and wanted Martin Sheen to play him in a biopic. In November 1988, "Mystery Girl" was completed, and "Traveling Wilburys Vol. 1" was rising up the charts. Around this time, Orbison confided in Johnny Cash that he was having chest pains. He went to Europe, was presented with an award there, and played a show in Antwerp, where footage for the video for "You Got It" was filmed. He gave several interviews a day in a hectic schedule. A few days later, a manager at a club in Boston was concerned that he looked ill, but Orbison played the show, to another standing ovation.

Orbison performed at the Front Row Theater in Highland Heights, Ohio, on December 4. Exhausted, he returned to his home in Hendersonville to rest for several days before flying again to London to film two more videos for the Traveling Wilburys. On December 6, 1988, he spent the day flying model aeroplanes with his sons and ate dinner at his mother's home in Hendersonville. Later that day, he died of a heart attack, at the age of 52.

A memorial for Orbison was held in Nashville, and another was held in Los Angeles. He was buried at Westwood Village Memorial Park Cemetery in an unmarked grave. On April 8, 1989, Orbison became the first deceased musician since Elvis Presley to have two albums in the US Top Five at the same time, with the Traveling Wilburys album at number 4 and his own "Mystery Girl" at number 5. In the United Kingdom, he achieved even greater posthumous success, with two solo albums in the Top 3 in the chart dated February 11, 1989, "Mystery Girl" at number 2 and the compilation "The Legendary Roy Orbison" at number 3.

Rock and roll in the 1950s was defined by a driving backbeat, heavy guitars, and lyrical themes that glorified youthful rebellion. Few of Orbison's recordings have these characteristics. The structure and themes of his songs defied convention, and his much-praised voice and performance style were unlike any other in rock and roll. Many of his contemporaries compared his music with that of classically trained musicians, although he never mentioned any classical music influences. Peter Lehman summarised it, writing, "He achieved what he did not by copying classical music but by creating a unique form of popular music that drew upon a wide variety of music popular during his youth." Orbison was known as "the Caruso of Rock" and "the Big O".

Roys Boys LLC, a Nashville-based company founded by Orbison's sons to administer their father's catalog and safeguard his legacy, announced a November 16, 2018, release of "Unchained Melodies: Roy Orbison with the Royal Philharmonic Orchestra" album as well as an autumn 2018 Roy Orbison Hologram tour called "In Dreams: Roy Orbison in Concert".

Music critic Dave Marsh wrote that Orbison's compositions "define a world unto themselves more completely than any other body of work in pop music". Orbison's music, like the man himself, has been described as timeless, diverting from contemporary rock and roll and bordering on the eccentric, within a hair's breadth of being weird. Peter Watrous, writing for the "New York Times", declared in a concert review, "He has perfected an odd vision of popular music, one in which eccentricity and imagination beat back all the pressures toward conformity".

In the 1960s, Orbison refused to splice edits of songs together and insisted on recording them in single takes with all the instruments and singers together. The only convention Orbison followed in his most popular songs is the time limit for radio fare in pop songs. Otherwise, each seems to follow a separate structure. Using the standard 32-bar form for verses and choruses, normal pop songs followed the verse-chorus-verse-chorus-bridge-verse-chorus structure. Where A represents the verse, B represents the chorus, and C the bridge, most pop songs can be represented by A-B-A-B-C-A-B, like "Ooby Dooby" and "Claudette". Orbison's "In Dreams" was a song in seven movements that can be represented as Intro-A-B-C-D-E-F; no sections are repeated. In "Running Scared", however, the entire song repeats to build suspense to a final climax, to be represented as A-A-A-A-B. "Crying" is more complex, changing parts toward the end to be represented as A-B-C-D-E-F-A-B'-C'-D'-E'-F'. Although Orbison recorded and wrote standard structure songs before "Only the Lonely", he claimed never to have learned how to write them:

Elton John's songwriting partner and main lyricist Bernie Taupin wrote that Orbison's songs always made "radical left turns", and k.d. lang declared that good songwriting comes from being constantly surprised, such as how the entirety of "Running Scared" eventually depends on the final note, one word. Some of the musicians who worked with Orbison were confounded by what he asked them to do. The Nashville session guitarist Jerry Kennedy stated, "Roy went against the grain. The first time you'd hear something, it wouldn't sound right. But after a few playbacks, it would start to grow on you."

Critic Dave Marsh categorises Orbison's ballads into themes reflecting pain and loss, and dreaming. A third category is his uptempo rockabilly songs such as "Go! Go! Go!" and "Mean Woman Blues" that are more thematically simple, addressing his feelings and intentions in a masculine braggadocio. In concert, Orbison placed the uptempo songs between the ballads to keep from being too consistently dark or grim.

In 1990, Colin Escott wrote an introduction to Orbison's biography published in a CD box set: "Orbison was the master of compression. Working the singles era, he could relate a short story, or establish a mood in under three minutes. If you think that's easy—try it. His greatest recordings were quite simply perfect; not a word or note surplus to intention." After attending a show in 1988, Peter Watrous of "The New York Times" wrote that Orbison's songs are "dreamlike claustrophobically intimate set pieces". Music critic Ken Emerson writes that the "apocalyptic romanticism" in Orbison's music was well-crafted for the films in which his songs appeared in the 1980s because the music was "so over-the-top that dreams become delusions, and self-pity paranoia", striking "a post-modern nerve". Led Zeppelin singer Robert Plant favoured American R&B music as a youth, but beyond the black musicians, he named Elvis and Orbison especially as foreshadowing the emotions he would experience: "The poignancy of the combination of lyric and voice was stunning. [Orbison] used drama to great effect and he wrote dramatically."

The loneliness in Orbison's songs that he became most famous for, he both explained and downplayed: "I don't think I've been any more lonely than anyone else ... Although if you grow up in West Texas, there are a lot of ways to be lonely." His music offered an alternative to the postured masculinity that was pervasive in music and culture. Robin Gibb of the Bee Gees stated, "He made emotion fashionable, that it was all right to talk about and sing about very emotional things. For men to sing about very emotional things ... Before that no one would do it." Orbison acknowledged this in looking back on the era in which he became popular: "When ["Crying"] came out I don't think anyone had accepted the fact that a man should cry when he wants to cry."

Orbison admitted that he did not think his voice was put to appropriate use until "Only the Lonely" in 1960, when it was able, in his words, to allow its "flowering". Carl Perkins, however, toured with Orbison while they were both signed with Sun Records and recalled a specific concert when Orbison covered the Nelson Eddy and Jeanette MacDonald standard "Indian Love Call", and had the audience completely silenced, in awe. When compared to the Everly Brothers, who often used the same session musicians, Orbison is credited with "a passionate intensity" that, according to "The Rolling Stone Illustrated History of Rock and Roll", made "his love, his life, and, indeed, the whole world [seem] to be coming to an end—not with a whimper, but an agonised, beautiful bang".

Bruce Springsteen and Billy Joel both commented on the otherworldly quality of Orbison's voice. Dwight Yoakam stated that Orbison's voice sounded like "the cry of an angel falling backward through an open window". Barry Gibb of The Bee Gees went further to say that when he heard "Crying" for the first time, "That was it. To me that was the voice of God." Elvis Presley stated Orbison's voice was the greatest and most distinctive he had ever heard. Orbison's music and voice have been compared to opera by Bob Dylan, Tom Waits, and songwriter Will Jennings, among others. Dylan marked Orbison as a specific influence, remarking that there was nothing like him on radio in the early 1960s:

Likewise, Tim Goodwin, who conducted the orchestra that backed Orbison in Bulgaria, had been told that Orbison's voice would be a singular experience to hear. When Orbison started with "Crying" and hit the high notes, Goodwin stated: "The strings were playing and the band had built up and, sure enough, the hair on the back of my neck just all started standing up. It was an incredible physical sensation." Bassist Jerry Scheff, who backed Orbison in his "" concert, wrote about him, "Roy Orbison was like an opera singer. His voice melted out of his mouth into the stratosphere and back. He never seemed like he was trying to sing, he just did it."

His voice ranged from baritone to tenor, and music scholars have suggested that he had a three- or four-octave range.

Orbison's severe stage fright was particularly noticeable in the 1970s and early 1980s. During the first few songs in a concert, the vibrato in his voice was almost uncontrollable, but afterward, it became stronger and more dependable. This also happened with age. Orbison noticed that he was unable to control the tremor in the late afternoon and evenings, and chose to record in the mornings when it was possible.

Orbison often excused his motionless performances by saying that his songs did not allow instrumental sections so he could move or dance on stage, although songs like "Mean Woman Blues" did offer that. He was aware of his unique performance style even in the early 1960s when he commented, "I'm not a super personality—on stage or off. I mean, you could put workers like Chubby Checker or Bobby Rydell in second-rate shows and they'd still shine through, but not me. I'd have to be prepared. People come to hear my music, my songs. That's what I have to give them."

Lang compared Orbison to a tree, with passive but solid beauty. This image of Orbison as immovable was so associated with him it was parodied by John Belushi on "Saturday Night Live", as Belushi dressed as Orbison falls over while singing "Oh, Pretty Woman", and continues to play as his bandmates set him upright again. However, Lang quantified this style by saying, "It's so hard to explain what Roy's energy was like because he would fill a room with his energy and presence but not say a word. Being that he was so grounded and so strong and so gentle and quiet. He was just there."

Orbison attributed his own passion during his performances to the period when he grew up in Fort Worth while the US was mobilising for World War II. His parents worked in a defence plant; his father brought out a guitar in the evenings, and their friends and relatives who had just joined the military gathered to drink and sing heartily. Orbison later reflected, "I guess that level of intensity made a big impression on me, because it's still there. That sense of 'do it for all it's worth and do it now and do it good.' Not to analyse it too much, but I think the verve and gusto that everybody felt and portrayed around me has stayed with me all this time."

"Rolling Stone" placed him at number 37 on their list of the "Greatest Artists of All Time" and number 13 on their list of the "100 Greatest Singers of All Time'. In 2002, "Billboard" magazine listed Orbison at number 74 in the Top 600 recording artists.


Video and televised feature performances:




</doc>
<doc id="26553" url="https://en.wikipedia.org/wiki?curid=26553" title="Ragtime">
Ragtime

Ragtime – also spelled rag-time or rag time – is a musical style that enjoyed its peak popularity between 1895 and 1919. Its cardinal trait is its syncopated or "ragged" rhythm.

The style has its origins in African-American communities in cities such as St. Louis.

Ben Harney, a Kentucky native, wrote "You've Been a Good Old Wagon But You Done Broke Down" and helped popularize the style. The composition was published in 1896, a few months after Ernest Hogan's "La Pas Ma La".

Ragtime was also a modification of the march style popularized by John Philip Sousa, with additional polyrhythms coming from African music. Ragtime composer Scott Joplin ("ca." 1868–1917) became famous through the publication of the "Maple Leaf Rag" (1899) and a string of ragtime hits such as "The Entertainer" (1902), although he was later forgotten by all but a small, dedicated community of ragtime aficionados until the major ragtime revival in the early 1970s. For at least 12 years after its publication, "Maple Leaf Rag" heavily influenced subsequent ragtime composers with its melody lines, chord progressions or metric patterns.

In a 1913 interview published in the black newspaper "New York Age", Scott Joplin asserted that there had been "ragtime music in America ever since the Negro race has been here, but the white people took no notice of it until about twenty years ago [in the 1890s]."

Ragtime quickly established itself as a distinctly American form of popular music. Ragtime became the first African-American music to have an impact on mainstream popular culture. Piano "professors" such as Jelly Roll Morton played ragtime in the "sporting houses" (bordellos) of New Orleans. Polite society embraced ragtime as disseminated by brass bands and "society" dance bands. Bands led by W. C. Handy and James R. Europe were among the first to crash the color bar in American music. The new rhythms of ragtime changed the world of dance bands and led to new dance steps, popularized by the show-dancers Vernon and Irene Castle during the 1910s. The growth of dance orchestras in popular entertainment was an outgrowth of ragtime and continued into the 1920s. Ragtime also made its way to Europe. Shipboard orchestras on transatlantic lines included ragtime music in their repertoire. James R. Europe's 369th Regiment band generated great enthusiasm during its 1918 tour of France.

Ragtime was an influence on early jazz; the influence of Jelly Roll Morton continued in the Harlem stride piano style of players such as James P. Johnson and Fats Waller. Dance orchestras started evolving away from ragtime towards the big band sounds that predominated in the 1920s and 1930s when they adopted smoother rhythmic styles.

There have been numerous revivals since newer styles supplanted ragtime in the 1920s. First in the early 1940s, many jazz bands began to include ragtime in their repertoire and put out ragtime recordings on 78 rpm records. A more significant revival occurred in the 1950s as a wider variety of ragtime genres of the past were made available on records, and new rags were composed, published, and recorded. In 1971 Joshua Rifkin released a compilation of Joplin's work which was nominated for a Grammy Award.

In 1973 The New England Ragtime Ensemble (then a student group called The New England Conservatory Ragtime Ensemble) recorded "The Red Back Book", a compilation of some of Joplin's rags in period orchestrations edited by conservatory president Gunther Schuller. It won a Grammy for Best Chamber Music Performance of the year and was named Top Classical Album of 1974 by "Billboard" magazine. The movie "The Sting" (1973) brought ragtime to a wide audience with its soundtrack of Joplin tunes. The film's rendering of "The Entertainer", adapted and orchestrated by Marvin Hamlisch, was a Top 5 hit in 1975.

Ragtime – with Joplin's work at the forefront – has been cited as an American equivalent of the minuets of Mozart, the mazurkas of Chopin, or the waltzes of Brahms. Ragtime also influenced classical composers including Erik Satie, Claude Debussy, and Igor Stravinsky.

Ragtime originated in African American music in the late 19th century and descended from the jigs and march music played by African American bands, referred to as "jig piano" or "piano thumping".

By the start of the 20th century, it became widely popular throughout North America and was listened and danced to, performed, and written by people of many different subcultures. A distinctly American musical style, ragtime may be considered a synthesis of African syncopation and European classical music, especially the marches made popular by John Philip Sousa.

Some early piano rags are entitled marches, and "jig" and "rag" were used interchangeably in the mid-1890s. Ragtime was also preceded by its close relative the cakewalk. In 1895, black entertainer Ernest Hogan composed two of the earliest sheet music rags, one of which ("All Coons Look Alike to Me") eventually sold a million copies. The other composition was called "La Pas Ma La", and it was also a hit.

As black musician Tom Fletcher said, Hogan was the "first to put on paper the kind of rhythm that was being played by non-reading musicians." While the song's success helped introduce the country to ragtime rhythms, its use of racial slurs created a number of derogatory imitation tunes, known as "coon songs" because of their use of racist and stereotypical images of blacks. In Hogan's later years, he admitted shame and a sense of "race betrayal" from the song, while also expressing pride in helping bring ragtime to a larger audience.

The emergence of mature ragtime is usually dated to 1897, the year in which several important early rags were published. In 1899, Scott Joplin's "Maple Leaf Rag" was published and became a great hit and demonstrated more depth and sophistication than earlier ragtime. Ragtime was one of the main influences on the early development of jazz (along with the blues). Some artists, such as Jelly Roll Morton, were present and performed both ragtime and jazz styles during the period the two styles overlapped. He also incorporated the Spanish Tinge in his performances, which gave a habanera or tango rhythm to his music. Jazz largely surpassed ragtime in mainstream popularity in the early 1920s, although ragtime compositions continue to be written up to the present, and periodic revivals of popular interest in ragtime occurred in the 1950s and the 1970s.

The heyday of ragtime occurred before sound recording was widely available. Like classical music, and unlike jazz, classical ragtime had and has primarily a written tradition, being distributed in sheet music rather than through recordings or by imitation of live performances. Ragtime music was also distributed via piano rolls for player pianos. A folk ragtime tradition also existed before and during the period of classical ragtime (a designation largely created by Scott Joplin's publisher John Stillwell Stark), manifesting itself mostly through string bands, banjo and mandolin clubs (which experienced a burst of popularity during the early 20th century) and the like.

A form known as novelty piano (or novelty ragtime) emerged as the traditional rag was fading in popularity. Where traditional ragtime depended on amateur pianists and sheet music sales, the novelty rag took advantage of new advances in piano-roll technology and the phonograph record to permit a more complex, pyrotechnic, performance-oriented style of rag to be heard. Chief among the novelty rag composers is Zez Confrey, whose "Kitten on the Keys" popularized the style in 1921.

Ragtime also served as the roots for stride piano, a more improvisational piano style popular in the 1920s and 1930s. Elements of ragtime found their way into much of the American popular music of the early 20th century. It also played a central role in the development of the musical style later referred to as Piedmont blues; indeed, much of the music played by such artists of the style as Reverend Gary Davis, Blind Boy Fuller, Elizabeth Cotten, and Etta Baker could be referred to as "ragtime guitar."

Although most ragtime was composed for piano, transcriptions for other instruments and ensembles are common, notably including Gunther Schuller's arrangements of Joplin's rags. Ragtime guitar continued to be popular into the 1930s, usually in the form of songs accompanied by skilled guitar work. Numerous records emanated from several labels, performed by Blind Blake, Blind Boy Fuller, Lemon Jefferson, and others. Occasionally ragtime was scored for ensembles (particularly dance bands and brass bands) similar to those of James Reese Europe or as songs like those written by Irving Berlin. Joplin had long-standing ambitions of synthesizing the worlds of ragtime and opera, to which end the opera "Treemonisha" was written. However, its first performance, poorly staged with Joplin accompanying on the piano, was "disastrous" and was never performed again in Joplin's lifetime. The score was lost for decades, then rediscovered in 1970, and a fully orchestrated and staged performance took place in 1972. An earlier opera by Joplin, "A Guest of Honor", has been lost.

The rag was a modification of the march made popular by John Philip Sousa, with additional polyrhythms coming from African music. It was usually written in 2/4 or 4/4 time with a predominant left-hand pattern of bass notes on strong beats (beats 1 and 3) and chords on weak beats (beat 2 and 4) accompanying a syncopated melody in the right hand. According to some sources the name "ragtime" may come from the "ragged or syncopated rhythm" of the right hand. A rag written in 3/4 time is a "ragtime waltz."

Ragtime is not a meter in the same way that marches are in duple meter and waltzes are in triple meter; it is rather a musical style that uses an effect that can be applied to any meter. The defining characteristic of ragtime music is a specific type of syncopation in which melodic accents occur between metrical beats. This results in a melody that seems to be avoiding some metrical beats of the accompaniment by emphasizing notes that either anticipate or follow the beat ("a rhythmic base of metric affirmation, and a melody of metric denial"). The ultimate (and intended) effect on the listener is actually to accentuate the beat, thereby inducing the listener to move to the music. Scott Joplin, the composer/pianist known as the "King of Ragtime", called the effect "weird and intoxicating." He also used the term "swing" in describing how to play ragtime music: "Play slowly until you catch the swing...".

The name swing later came to be applied to an early style of jazz that developed from ragtime. Converting a non-ragtime piece of music into ragtime by changing the time values of melody notes is known as "ragging" the piece. Original ragtime pieces usually contain several distinct themes, four being the most common number. These themes were typically 16 bars, each theme divided into periods of four four-bar phrases and arranged in patterns of repeats and reprises. Typical patterns were AABBACCC, AABBACCDD and AABBCCA, with the first two strains in the tonic key and the following strains in the subdominant. Sometimes rags would include introductions of four bars or bridges, between themes, of anywhere between four and 24 bars.

In a note on the sheet music for the song "Leola" Joplin wrote, "Notice! Don't play this piece fast. It is never right to play 'ragtime' fast." E. L. Doctorow used the quotation as the epigraph to his novel "Ragtime".

Ragtime pieces came in a number of different styles during the years of its popularity and appeared under a number of different descriptive names. It is related to several earlier styles of music, has close ties with later styles of music, and was associated with a few musical fads of the period such as the foxtrot. Many of the terms associated with ragtime have inexact definitions and are defined differently by different experts; the definitions are muddled further by the fact that publishers often labelled pieces for the fad of the moment rather than the true style of the composition. There is even disagreement about the term "ragtime" itself; experts such as David Jasen and Trebor Tichenor choose to exclude ragtime songs from the definition but include novelty piano and stride piano (a modern perspective), while Edward A. Berlin includes ragtime songs and excludes the later styles (which is closer to how ragtime was viewed originally). The terms below should not be considered exact, but merely an attempt to pin down the general meaning of the concept.


European Classical composers were influenced by the form. The first contact with ragtime was probably at the Paris Exposition in 1900, one of the stages of the European tour of John Philip Sousa. The first notable classical composer to take a serious interest in ragtime was Antonín Dvořák. French composer Claude Debussy emulated ragtime in three pieces for piano. The best-known remains the "Golliwog's Cake Walk" (from the 1908 Piano Suite "Children's Corner"). He later returned to the style with two preludes for piano: "Minstrels", (1910) and "General Lavine-excentric" (from his 1913 Préludes), which was inspired by a Médrano circus clown.

Erik Satie, Arthur Honegger, Darius Milhaud, and the other members of The Group of Six in Paris never made any secret of their sympathy for ragtime, which is sometimes evident in their works. Consider, in particular, the ballet of Satie, "Parade (Ragtime du Paquebot)," (1917) and "La Mort de Monsieur Mouche", an overture for piano for a drama in three acts, composed in the early 1900s in memory of his friend J.P. Contamine de Latour. In 1902 the American cakewalk was very popular in Paris and Satie two years later wrote two rags, "La Diva de l'empire" and "Piccadilly". Despite the two Anglo-Saxon settings, the tracks appear American-inspired. "La Diva de l'empire", a march for piano soloist, was written for Paulette Darty and initially bore the title "Stand-Walk Marche"; it was later subtitled "Intermezzo Americain" when Rouarts-Lerolle reprinted it in 1919. "Piccadilly", another march, was initially titled "The Transatlantique"; it presented a stereotypical wealthy American heir sailing on an ocean liner on the New York–Europe route, going to trade his fortune for an aristocratic title in Europe. There is a similar influence in Milhaud's ballets "Le boeuf sur le toite" and "Creation du Monde", which he wrote after a visit to Harlem during his trip in 1922. Even the Swiss composer Honegger wrote works in which the influence of African American music is pretty obvious. Examples include "Pacific 231", "Prélude et Blues" and especially the "Concertino" for piano and orchestra.

Igor Stravinsky wrote a solo piano work called "Piano-Rag-Music" in 1919 and also included a rag in his theater piece "L'Histoire du soldat" (1918).

In the early 1940s, many jazz bands began to include ragtime in their repertoire, and as early as 1936 78 rpm records of Joplin's compositions were produced. Old numbers written for piano were rescored for jazz instruments by jazz musicians, which gave the old style a new sound. The most famous recording of this period is Pee Wee Hunt's version of Euday L. Bowman's "Twelfth Street Rag."

A more significant revival occurred in the 1950s. A wider variety of ragtime styles of the past were made available on records, and new rags were composed, published, and recorded. Much of the ragtime recorded in this period is presented in a light-hearted novelty style, looked to with nostalgia as the product of a supposedly more innocent time. A number of popular recordings featured "prepared pianos", playing rags on pianos with tacks on the hammers and the instrument deliberately somewhat out of tune, supposedly to simulate the sound of a piano in an old honky tonk.

Four events brought forward a different kind of ragtime revival in the 1970s. First, pianist Joshua Rifkin released a compilation of Scott Joplin's work, "", on Nonesuch Records, which was nominated for a Grammy Award in the Best Classical Performance – Instrumental Soloist(s) without Orchestra category in 1971. This recording reintroduced Joplin's music to the public in the manner the composer had intended, not as a nostalgic stereotype but as serious, respectable music. Second, the New York Public Library released a two-volume set of "The Collected Works of Scott Joplin" which renewed interest in Joplin among musicians and prompted new stagings of Joplin's opera "Treemonisha". Next came the release and Grammy Award for The New England Ragtime Ensemble's recording of Joplin's "Red Back Book." Finally, with the release of the motion picture "The Sting" in 1973, which had a Marvin Hamlisch soundtrack of Joplin tunes edited by Gunther Schuller, ragtime was brought to a wide audience. Hamlisch's rendering of Joplin's 1902 rag "The Entertainer" won an Academy Award, and was an American Top 40 hit in 1974, reaching No. 3 on May 18. Ragtime news and reviews publications during this period included "The Ragtime Review" (1962–1966), "The Rag Times" (bimonthly/sporadic, 1962–2003), and "The Mississippi Rag" (monthly, 1973–2009).

Many modern musicians have again begun to find ragtime and incorporate it into their musical repertoires; such acts include Jay Chou, Curtains for You, Baby Gramps, and Bob Milne., and Tom Brier

In 1980, an adaption of E. L. Doctorow's historical novel "Ragtime" was released on screen. Randy Newman composed its music score, which was all original. In 1998, a stage version of "Ragtime" was produced on Broadway. With music by Stephen Flaherty and lyrics by Lynn Ahrens, the show featured several rags as well as songs in other musical styles.





</doc>
<doc id="26555" url="https://en.wikipedia.org/wiki?curid=26555" title="Rashi">
Rashi

Shlomo Yitzchaki (; ; , 22 February 1040 – 13 July 1105), today generally known by the acronym Rashi (see below), was a medieval French rabbi and author of a comprehensive commentary on the Talmud and commentary on the "Tanakh". Acclaimed for his ability to present the basic meaning of the text in a concise and lucid fashion, Rashi appeals to both learned scholars and beginner students, and his works remain a centerpiece of contemporary Jewish study. His commentary on the Talmud, which covers nearly all of the Babylonian Talmud (a total of 30 out of 39 tractates, due to his death), has been included in every edition of the Talmud since its first printing by Daniel Bomberg in the 1520s. His commentary on Tanakh—especially on the Chumash ("Five Books of Moses")—serves as the basis for more than 300 "supercommentaries" which analyze Rashi's choice of language and citations, penned by some of the greatest names in rabbinic literature.

Rashi's surname, Yitzhaki, derives from his father's name, Yitzhak. The acronym is sometimes fancifully expanded as Rabban Shel YIsrael which means the "Rabbi of Israel", or as Rabbenu SheYichyeh (Our Rabbi, may he live). He may be cited in Hebrew and Aramaic texts as (1) "Shlomo son of Rabbi Yitzhak", (2) "Shlomo son of Yitzhak", (3) "Shlomo Yitzhaki", and myriad similar highly respectful derivatives.

In older literature, Rashi is sometimes referred to as "Jarchi" or "Yarhi" (), his abbreviated name being interpreted as Rabbi Shlomo Yarhi. This was understood to refer to the Hebrew name of Lunel in Provence, popularly derived from the French "lune" "moon", in Hebrew , in which Rashi was assumed to have lived at some time or to have been born, or where his ancestors were supposed to have originated. Later Christian writers Richard Simon and Johann Christoph Wolf claimed that only Christian scholars referred to Rashi as Jarchi, and that this epithet was unknown to the Jews. Bernardo de Rossi, however, demonstrated that Hebrew scholars also referred to Rashi as Yarhi. In 1839, Leopold Zunz showed that the Hebrew usage of Jarchi was an erroneous propagation of the error by Christian writers, instead interpreting the abbreviation as it is understood today: Rabbi Shlomo Yitzhaki. The evolution of this term has been thoroughly traced.

Rashi was an only child born at Troyes, Champagne, in northern France. His mother's brother was Simon the Elder, Rabbi of Mainz. Simon was a disciple of Gershom ben Judah, who died that same year. On his father's side, Rashi has been claimed to be a 33rd-generation descendant of Johanan HaSandlar, who was a fourth-generation descendant of Gamaliel, who was reputedly descended from the Davidic line. In his voluminous writings, Rashi himself made no such claim at all. The main early rabbinical source about his ancestry, Responsum No. 29 by Solomon Luria, makes no such claim either. 

His fame later made him the subject of many legends. One tradition contends that his parents were childless for many years. Rashi's father, Yitzhak, a poor winemaker, once found a precious jewel and was approached by non-Jews who wished to buy it to adorn their idol. Yitzhak agreed to travel with them to their land, but en route, he cast the gem into the sea. Afterwards he was visited by either the Voice of God or the prophet Elijah, who told him that he would be rewarded with the birth of a noble son "who would illuminate the world with his Torah knowledge."

Another legend also states that Rashi's parents moved to Worms, Germany while Rashi's mother was pregnant. As she walked down one of the narrow streets in the Jewish quarter, she was imperiled by two oncoming carriages. She turned and pressed herself against a wall, which opened to receive her. This miraculous niche is still visible in the wall of the Worms Synagogue.

According to tradition, Rashi was first brought to learn Torah by his father on Shavuot day at the age of five. His father was his main Torah teacher until his death when Rashi was still a youth. At the age of 17 he married and soon after went to learn in the yeshiva of Rabbi Yaakov ben Yakar in Worms, returning to his wife three times yearly, for the Days of Awe, Passover and Shavuot. When Rabbi Yaakov died in 1064, Rashi continued learning in Worms for another year in the yeshiva of his relative, Rabbi Isaac ben Eliezer Halevi, who was also chief rabbi of Worms. Then he moved to Mainz, where he studied under another of his relatives, Rabbi Isaac ben Judah, the rabbinic head of Mainz and one of the leading sages of the Lorraine region straddling France and Germany.

Rashi's teachers were students of Rabbeinu Gershom and Rabbi Eliezer Hagadol, leading Talmudists of the previous generation. From his teachers, Rashi imbibed the oral traditions pertaining to the Talmud as they had been passed down for centuries, as well as an understanding of the Talmud's unique logic and form of argument. Rashi took concise, copious notes from what he learned in yeshiva, incorporating this material in his commentaries. He was also greatly influenced by the exegetical principles of Menahem Kara. 

He returned to Troyes at the age of 25, after which time his mother died, and he was asked to join the Troyes "Beth din" (rabbinical court). He also began answering halakhic questions. Upon the death of the head of the "Bet din", Rabbi Zerach ben Abraham, Rashi assumed the court's leadership and answered hundreds of halakhic queries.

In around 1070 he founded a yeshiva which attracted many disciples. It is thought by some that Rashi earned his living as a vintner since Rashi shows an extensive knowledge of its utensils and process, but there is no evidence for this. Most scholars and a Jewish oral tradition contend that he was a vintner. The only reason given for the centuries-old tradition that he was a vintner being not true is that the soil in all of Troyes is not optimal for wine growing grapes, claimed by the research of Rabbi Haym Soloveitchik. Earlier references such as a reference to an actual seal from his vineyard are said not to prove that he sold wine but just that fermented his grapes for his own use.

Although there are many legends about his travels, Rashi likely never went further than from the Seine to the Rhine; the utmost limit of his travels were the yeshivas of Lorraine.

In 1096, the People's Crusade swept through the Lorraine, murdering 12,000 Jews and uprooting whole communities. Among those murdered in Worms were the three sons of Rabbi Isaac ben Eliezer Halevi, Rashi's teacher. Rashi wrote several "Selichot" (penitential poems) mourning the slaughter and the destruction of the region's great yeshivot. Seven of Rashi's "Selichot" still exist, including "Adonai Elohei Hatz'vaot"", which is recited on the eve of Rosh Hashanah, and "Az Terem Nimtehu", which is recited on the Fast of Gedalia.

Rashi died on July 13, 1105 (Tammuz 29, 4865) at the age of 65. He was buried in Troyes. The approximate location of the cemetery in which he was buried was recorded in "Seder Hadoros", but over time the location of the cemetery was forgotten. A number of years ago, a Sorbonne professor discovered an ancient map depicting the site of the cemetery, which now lay under an open square in the city of Troyes. After this discovery, French Jews erected a large monument in the center of the square—a large, black and white globe featuring the three Hebrew letters of רשי artfully arranged counterclockwise in negative space, evoking the style of Hebrew microcalligraphy. The granite base of the monument is engraved: "Rabbi Shlomo Yitzchaki — Commentator and Guide".

In 2005, Yisroel Meir Gabbai erected an additional plaque at this site marking the square as a burial ground. The plaque reads: ""The place you are standing on is the cemetery of the town of Troyes. Many Rishonim are buried here, among them Rabbi Shlomo, known as Rashi the holy, may his merit protect us"".

Rashi had no sons, but his three daughters, Yocheved, Miriam and Rachel, all married Talmudic scholars. Legends exist that Rashi's daughters wore tefillin. While some women in medieval Ashkenaz did wear tefillin, there is no evidence that Rashi's daughters did or did not do so.

Rashi's commentary on the Tanakh—and especially his commentary on the Chumash—is the essential companion for any study of the Bible at any level. Drawing on the breadth of Midrashic, Talmudic and Aggadic literature (including literature that is no longer extant), as well as his knowledge of Hebrew grammar and halakhah, Rashi clarifies the "simple" meaning of the text so that a bright child of five could understand it. At the same time, his commentary forms the foundation for some of the most profound legal analysis and mystical discourses that came after it. Scholars debate why Rashi chose a particular Midrash to illustrate a point, or why he used certain words and phrases and not others. Rabbi Shneur Zalman of Liadi wrote that "Rashi's commentary on Torah is the 'wine of Torah'. It opens the heart and uncovers one's essential love and fear of G-d."

Scholars believe that Rashi's commentary on the Torah grew out of the lectures he gave to his students in his yeshiva, and evolved with the questions and answers they raised on it. Rashi completed this commentary only in the last years of his life. It was immediately accepted as authoritative by all Jewish communities, Ashkenazi and Sephardi alike.

The first dated Hebrew printed book was Rashi's commentary on the Chumash, printed by Abraham ben Garton in Reggio di Calabria, Italy, 18 February 1475. (This version did not include the text of the Chumash itself.) 

Rashi wrote commentaries on all the books of Tanakh except Chronicles I & II. Scholars believe that the commentary which appears under Rashi's name in those books was compiled by the students of Rabbi Saadiah of the Rhine, who incorporated material from Rashi's yeshiva. Rashi's students, Rabbi Shemaya and Rabbi Yosef, edited the final commentary on the Torah; some of their own notes and additions also made their way into the version we have today.

Today, tens of thousands of men, women and children study "Chumash with Rashi" as they review the Torah portion to be read in synagogue on the upcoming Shabbat. According to halakha, a man may even study the Rashi on each Torah verse in fulfillment of the requirement to review the Parsha twice with Targum (which normally refers to Targum Onkelos) This practice is called in Hebrew: "Shnayim mikra ve-echad targum". Since its publication, Rashi's commentary on the Torah is standard in almost all Chumashim produced within the Orthodox Jewish community.

Rabbi Mordechai Leifer of Nadvorna said that anyone who learns the weekly Parsha together with the commentary by Rashi every week, is guaranteed to sit in the Yeshiva (school) of Rashi in the Afterlife.

Rashi wrote the first comprehensive commentary on the Talmud. Rashi's commentary, drawing on his knowledge of the entire contents of the Talmud, attempts to provide a full explanation of the words and of the logical structure of each Talmudic passage. Unlike other commentators, Rashi does not paraphrase or exclude any part of the text, but elucidates phrase by phrase. Often he provides punctuation in the unpunctuated text, explaining, for example, "This is a question"; "He says this in surprise", "He repeats this in agreement", etc.

As in his commentary on the Tanakh, Rashi frequently illustrates the meaning of the text using analogies to the professions, crafts, and sports of his day. He also translates difficult Hebrew or Aramaic words into the spoken French language of his day, giving latter-day scholars a window into the vocabulary and pronunciation of Old French.

Rashi exerted a decisive influence on establishing the correct text of the Talmud. Up to and including his age, texts of each Talmudic tractate were copied by hand and circulated in yeshivas. Errors often crept in: sometimes a copyist would switch words around, and other times incorporate a student's marginal notes into the main text. Because of the large number of merchant-scholars who came from throughout the Jewish world to attend the great fairs in Troyes, Rashi was able to compare different manuscripts and readings in Tosefta, Jerusalem Talmud, Midrash, Targum, and the writings of the Geonim, and determine which readings should be preferred. However, in his humility, he deferred to scholars who disagreed with him. For example, in Chulin 4a, he comments about a phrase, "We do not read this. But as for those who do, this is the explanation..."

Rashi's commentary, which covers nearly all of the Babylonian Talmud (a total of 30 tractates), has been included in every version of the Talmud since its first printing in the fifteenth century. It is always situated towards the middle of the opened book display; i.e., on the side of the page closest to the binding.

Some of the other printed commentaries which are attributed to Rashi were composed by others, primarily his students. Akiva Eger stated that the commentary on Nazir was not in fact by Rashi, while Zvi Hirsch Chajes states that the commentary on Taanit was not by Rashi. In some editions of the Talmud, the text indicates that Rashi died before completing the tractate, and that it was completed by a student. This is true of Makkot (the end of which was composed by his son-in-law, Rabbi Judah ben Nathan), and of Bava Batra (finished, in a more detailed style, by his grandson the Rashbam). The commentary attributed to Rashi on Horayot was thought by some to have been written by his son in law Judah ben Nathan but evidence was uncovered indicating that the commentary on Horayot was from the school of Gershom ben Judah. There is a legend that the commentary on Nedarim, which is clearly not his, was actually composed by his daughters. Another legend states that Rashi died while writing a commentary on Talmud, and that the very last word he wrote was 'tahor,' which means pure in Hebrew - indicating that his soul was pure as it left his body.

About 300 of Rashi's responsa and halakhic decisions are extant. Although some may find contradictory to Rashi's intended purpose for his writings, these responsa were copied, preserved, and published by his students, grandchildren, and other future scholars. "Siddur Rashi", compiled by an unknown student, also contains Rashi's responsa on prayer. Many other rulings and responsa are recorded in Mahzor Vitry. Other compilations include "Sefer Hapardes", edited by Rabbi Shemayah, Rashi's student, and "Sefer Haorah", prepared by Rabbi Nathan Hamachiri.

Rashi's writing is placed under the category of post-Talmudic, for its explanation and elaboration on the Talmud; however, he not only wrote about the meaning of Biblical and Talmudic passages, but also on liturgical texts, syntax rules, and cases regarding new religions emerging. Some say that his responsa allows people to obtain "clear pictures of his personality," and shows Rashi as a kind, gentle, humble, and liberal man. They also showed the great deal of common sense and intelligence he had.

Rashi's responsa not only addressed some of the different cases and questions regarding Jewish life and law, but it shed light into the historical and social conditions which the Jews were under during the First Crusade. He covered the following topics and themes in his responsa: linguistic focus on texts, law related to prayer, food, and the Sabbath, wine produced by non-Jews, oaths and excommunications, sales, partnerships, loans and interest, bails, communal affairs, and civil law. Rashi's responsa can be broken down into three genres: questions by contemporary sages and students regarding the Torah, the law, and other compilations.

For example, in his writing regarding relations with the Christians, he provides a guide for how one should behave when dealing with martyrs and converts, as well as the "insults and terms of [disgrace] aimed at the Jews." Stemming from the aftermath of the Crusades, Rashi wrote concerning those who were forced to convert, and the rights women had when their husbands were killed.

A main characteristic of Rashi's writing was his focus on grammar and syntax. His primary focus was on word choice, and "essentially [he acts] as a dictionary where he defines unusual Hebrew words." He searches for things that may not be clear to the reader and offers clarification on the inconsistency that may be present. Rashi does so by "filling in missing information that [helps] lead to a more complete understanding" of the Torah. Rashi focused the majority of his responsa, if not all, on a "meticulous analysis of the language of the text." A portion of his writing is dedicated to making distinctions between the peshat, or plain and literal meaning of the text, and the aggadah or rabbinic interpretation. One of Rashi's grandchildren, Rabbi Samuel B. Meir or Rashbam, heavily critiqued his response on his "commentary on the Torah [being] based primarily on the classic midrashim (rabbinic homilies)."

Rashi also influenced non-Jewish circles. His commentaries on the Bible, especially those on the Pentateuch, circulated in many different communities. In the 12th–17th centuries, Rashi's influence spread from French and German provinces to Spain and the east. He had a tremendous influence on Christian scholars. The French monk Nicolas de Lyre of Manjacoria, who was known as the "ape of Rashi", was dependent on Rashi when writing the 'Postillae Perpetuate' on the Bible. He believed that Rashi's commentaries were the "official repository of Rabbinical tradition" and significant to understanding the Bible. De Lyre also had great influence on Martin Luther. Rashi's commentaries became significant to humanists at this time who studied grammar and exegesis. Christian Hebraists studied Rashi's commentaries as important interpretations "authorized by the Synagogue".

Rashi's influence grew the most in the 15th century; from the 17th century onwards, his commentaries were translated into many other languages. Rashi's commentary on the Pentateuch was known as the first printed Hebrew work. Rashi on the Torah was translated into English by M. Rosenbaum and A.M. Silbermann from 1929 to 1934 ( Pentateuch with Rashi's Commentary Translated into English). Although Rashi had an influence on communities outside of Judaism, his lack of connection to science prevented him from entering the general domain and he remained more popular among the Jewish community.

Although Rashi's interpretations were widely respected, there were some who criticized his work. After the 12th century, criticism on Rashi's commentaries became common on Jewish works such as the Talmud. The criticisms mainly dealt with difficult passages. In general, Rashi provides the "pshat" or literal meaning of Jewish texts, while his disciples known as the Tosafot ("additions"), criticized his work and gave more interpretative descriptions of the texts. The Tosafot's commentaries can be found in the Talmud opposite Rashi's commentary. The Tosafot added comments and criticism in places where Rashi had not added comments. The Tosafot went beyond the passage itself in terms of arguments, parallels, and distinctions that could be drawn out. This addition to Jewish texts was seen as causing a "major cultural product" which became an important part of Torah study.

Although often disagreeing with his interpretations, the Tosafot always speak of Rashi with great respect.

Rashi's commentary on the Talmud continues to be a key basis for contemporary rabbinic scholarship and interpretation. Without Rashi's commentary, the Talmud would have remained a closed book. With it, any student who has been introduced to its study by a teacher can continue learning on his own, deciphering its language and meaning with the aid of Rashi.

The Schottenstein Edition Elucidated translation of the Talmud bases its English-language commentary primarily on Rashi’s, and describes his continuing importance as follows: 

In 2006, the Jewish National and University Library at Hebrew University put on an exhibit commemorating the 900th anniversary of Rashi's death (2005), showcasing rare items from the library collection written by Rashi, as well as various works by others concerning Rashi.

Voluminous supercommentaries have been published on Rashi's commentaries on the Bible and Talmud, including "Gur Aryeh" by Rabbi Judah Loew (the Maharal), "Sefer ha-Mizrachi" by Rabbi Elijah Mizrachi (the Re'em), and "Yeri'ot Shlomo" by Rabbi Solomon Luria (the Maharshal). Almost all rabbinic literature published since the Middle Ages discusses Rashi, either using his view as supporting evidence or debating against it.

Rashi's explanations of the Chumash were also cited extensively in "Postillae Perpetuae" by Nicholas de Lyra (1292–1340), a French Franciscan. De Lyra's book was one of the primary sources that was used in Luther's translation of the Bible.

The semi-cursive typeface in which Rashi's commentaries are printed both in the Talmud and Tanakh is often referred to as "Rashi script." This does not mean that Rashi himself used such a script: the typeface is based on a 15th-century Sephardic semi-cursive hand. What would be called "Rashi script" was employed by early Hebrew typographers such as the Soncino family and Daniel Bomberg, a Christian printer in Venice, in their editions of commented texts (such as the Mikraot Gedolot and the Talmud, in which Rashi's commentaries prominently figure) to distinguish the rabbinic commentary from the primary text proper, for which a square typeface was used.





</doc>
<doc id="26558" url="https://en.wikipedia.org/wiki?curid=26558" title="Redmond, Washington">
Redmond, Washington

Redmond is a city in King County, Washington, United States, located east of Seattle. The population was 54,144 at the 2010 census and an estimated 71,929 in 2019. Redmond is commonly recognized as the home of Microsoft and Nintendo of America. With an annual bike race on city streets and the state's only velodrome, Redmond is also known as the "Bicycle Capital of the Northwest".

Native Americans have lived in the Redmond area for over 10,000 years, based on artifacts discovered at the Redmond Town Center archaeological site and Marymoor Prehistoric Indian Site. The first European settlers arrived in the 1870s. Luke McRedmond filed a Homestead Act claim for land next to the Sammamish Slough on September 9, 1870, and the following year Warren Perrigo took up land adjacent to him. The rivers and streams had so many salmon that the settlement was initially named Salmonberg. More settlers came, and with the establishment of the first post office in 1881, the name of the community was changed to Melrose. The new name was derived from the Perrigos' successful inn, Melrose House, which upset McRedmond. After becoming postmaster, he successfully petitioned to have the name changed to Redmond in 1883.

The abundant forests and fish of Redmond provided jobs for loggers and fishermen, and with those jobs came demand for goods and services, bringing in merchants. The logging industry expanded significantly in 1889 when the Seattle, Lake Shore and Eastern Railway built a station in the center of town. The first plat for Redmond was filed on May 11, 1891, encompassing much of the area now known as downtown. After reaching the necessary population of 300, Redmond was incorporated on December 31, 1912.

Redmond experienced an economic downturn in the 1920s. Prohibition forced saloons to close, cutting off a large portion of the city's tax base. The forests were declining after heavy logging, causing lumber mills to shut down. The deforested land was suitable for farming. Agriculture became Redmond's primary business, keeping residents fed during the Great Depression. When the U.S. entered World War II, shipyard jobs and other wartime work came to Redmond.

After the war, Redmond's expansion began in earnest. The city expanded over thirty times larger in area through annexations between 1951 and 1967. From 1956 to 1965, Redmond was bordered by the town of East Redmond, which was formed by rural homeowners and later dissolved by the Washington Supreme Court. The completion of the Evergreen Point Floating Bridge across Lake Washington in 1963 allowed Redmond to flourish as a suburb of Seattle. In 1978, the U.S. Census Bureau proclaimed Redmond the fastest growing city in the state. Many technology companies made the city their home, and the increasing population demanded more retail shops. By the late 1980s, Downtown Redmond had become "a series of strip centers surrounded by parking lots", sparking plans for a mixed-use revitalized downtown.

Redmond underwent a commercial boom during the 1990s, culminating in 1997 with the opening of Redmond Town Center, a major regional shopping center on the site of a long-defunct golf course. In recent years the city has been experiencing growing pains as a result of its rapid expansion, particularly in the areas of urban sprawl and traffic congestion. During rush hour it can take upwards of two hours to travel from the beginning of SR-520 at Avondale Road to downtown Seattle, a mere away. These problems are being mitigated by the expansion of SR-520 and the Evergreen Point Floating Bridge, as well as the planned light rail service via the East Link Extension from Seattle to Redmond to open in 2023.

Redmond is bordered by Kirkland to the west, Bellevue to the southwest, and Sammamish to the southeast. Unincorporated King County lies to the north and east. The city's urban downtown lies just north of Lake Sammamish; residential areas lie north and west of the lake. Overlake, the city's second urban center, is to the west of Lake Sammamish. The Sammamish River runs north from the lake along the west edge of the city's downtown.

Redmond is located at .

According to the United States Census Bureau, the city has a total area of , of which are land and are water.

Redmond, like most of the Pacific Northwest, has a mild climate for its latitude, but still gets all four seasons. Summers tend to be warm and dry, with low rainfall and sunny or partly sunny from June to September. Winters tend to be cool and wet, with November being the rainiest month. Snowfall is uncommon, with the most common cold air being in a form of a high pressure system, driving out the rains from the area. However, snowfall is not as rare as in other cities like Seattle near the moderating effects of Puget Sound. The average warmest month is August. The highest recorded temperature was on July 29, 2009. On average, the coolest month is January. The lowest recorded temperature was in January 1950. The maximum average precipitation occurs in December.

According to a 2015 estimate, the annual median income for a household in the city was $99,586. The average home value in 2014 was $649,000.

As of the census of 2010, there were 54,144 people, 22,550 households, and 13,890 families residing in the city. The population density was . There were 24,177 housing units at an average density of . The racial makeup of the city was 65.2% White, 1.7% African American, 0.4% Native American, 25.4% Asian, 0.2% Pacific Islander, 3.2% from other races, and 4.0% from two or more races. Hispanic or Latino of any race were 7.8% of the population.

There were 22,550 households, of which 32.4% had children under the age of 18 living with them, 51.4% were married couples living together, 6.9% had a female householder with no husband present, 3.3% had a male householder with no wife present, and 38.4% were non-families. 29.6% of all households were made up of individuals, and 7% had someone living alone who was 65 years of age or older. The average household size was 2.39 and the average family size was 2.98.

The median age in the city was 34.1 years. 22.7% of residents were under the age of 18; 7.5% were between the ages of 18 and 24; 38.7% were from 25 to 44; 21.6% were from 45 to 64; and 9.5% were 65 years of age or older. The sex ratio of the city was 50.9% male and 49.1% female.

As of the census of 2000, there were 45,256 people, 19,102 households, and 11,346 families residing in the city. The population density was 2,848.8 people per square mile (1,099.7/km). There were 20,248 housing units at an average density of 1,274.6 per square mile (492.0/km). The racial makeup of the city was 79.3% White, 13.0% Asian, 1.5% African American, 0.5% Native American, 0.2% Pacific Islander, 2.5% from other races, and 3.1% from two or more races. Hispanic or Latino of any race were 5.6% of the population.

There were 19,102 households, out of which 28.5% had children under the age of 18 living with them, 48.9% were married couples living together, 7.6% had a female householder with no husband present, and 40.6% were non-families. 30.4% of all households were made up of individuals, and 6.1% had someone living alone who was 65 years of age or older. The average household size was 2.33 and the average family size was 2.95.

In the city, the population was spread out, with 21.5% under the age of 18, 9.5% from 18 to 24, 37.9% from 25 to 44, 21.9% from 45 to 64, and 9.3% who were 65 years of age or older. The median age was 34 years. For every 100 females, there were 100.4 males. For every 100 females age 18 and over, there were 99.5 males.

The median income for a household in the city was $66,735, and the median income for a family was $78,430. Males had a median income of $58,112 versus $37,200 for females. The per capita income for the city was $36,233. About 3.3% of families and 5.3% of the population were below the poverty line, including 6.3% of those under age 18 and 6.5% of those age 65 or over.

Several companies in the high-tech industry are based in Redmond. The largest employer in the city by far is Microsoft Corporation, which moved its headquarters to Redmond in 1986. Microsoft has over 40,000 blue badge FTEs (full-time employee), 45,000 orange badge contractors (as of June 2012, there are over 94,000 workers, and over half are contractors), and more than 8 million square feet (750,000 square meters) of office space in the Seattle area Eastside region, primarily in Redmond, with additional offices in Bellevue and Issaquah (90,000 employees worldwide). In June 2006, Microsoft purchased former Safeco's Redmond campus at 4515–5069 154th Place NE for $220.5 million.

Other companies with headquarters in Redmond include Nintendo of America, Genie Industries, Physio-Control (now part of Stryker), Visible.net, WildTangent, Solstice (acquired by Samsung) and Data I/O.

In 2015, SpaceX and Hyperloop Genesis announced of opening a facility in Redmond. Their focus will be R&D and manufacturing for a proposed internet communications satellite constellation and new transport systems.

Unlike Bellevue and other neighboring cities, the city of Redmond does not have a business and occupation tax on income. However, to help offset the costs of road improvements for businesses, a business license fee of $55 per employee was approved in 1996. , the fee is $107 per employee.

According to Redmond's Comprehensive Annual Financial Reports, the top employers in the city are:

Redmond Derby Days is an annual community festival held the second full weekend of July and celebrated its 75th anniversary in 2015. It began as a race around Lake Sammamish called the Redmond Bicycle Derby in 1939, and since then has become a multi-day event including a bicycle criterium, parade, entertainment stages, beer garden, local food offerings and activities. It also includes a carnival with rides and attractions and a fireworks display at dusk on Saturday.

Performing arts in Redmond include the Eastside Symphony and the Second Story Repertory theater company, as well as artists who play at the Redmond Performing Arts Center. Redmond has a collection of outdoor sculptures throughout its streets and parks, many of which are part of a rotating sculpture exhibition.

Redmond Lights is an annual community festival held the first Saturday of December. It features a special guest each year, a tree-lighting conducted by the mayor on city hall campus, a luminary walk on the Sammamish Trail and Redmond Central Connector with musical and light stations along the way to Redmond Town Center where there are many special attractions such as a carousel, skating rink and food sampling.

The Old Redmond Firehouse is a center for local teens. It has become a hub in the thriving Eastside independent music scene. Local bands perform here with concert style speakers.

Since 2010, by city ordinance, Redmond has appointed a poet laureate. The inaugural laureate was Rebecca Meredith (2010–2012), followed by Jeannine Hall Gailey (2012–2013), Michael Dylan Welch (2013–2015), Shin Yu Pai (2015–2017), Melanie Noel (2018–2019), and Raul Sanchez (2019-2021).

The Concerts at Marymoor is an annual summer series of concerts held at the amphitheater in Marymoor Park. The venue has been host to artists as diverse as Norah Jones, Peter, Paul & Mary, Rob Thomas and Duran Duran. When visiting the Seattle area, Cirque du Soleil has set up in Marymoor since the 2004 tour of Varekai when a concrete base was built for them to set up on. Since then, tours of Corteo (2006), Kooza (2010), Amaluna (2013), Kurios (2015) and Luzia (2017) have played in this spot. Other notable events include the Warped Tour and Cavalia in 2012 and 2014.

Redmond Saturday Market is the oldest farmer's market in the Seattle area's east side. This market is held on Saturdays from May through October on approximately 8,000 square feet of land near the Redmond Town Center. The City of Redmond has approved an ordinance that the current market site be preserved for its community and historic significance.

Redmond has designated the following landmarks:

According to the city's website, Redmond has 47 public parks totaling over . Many of these are neighborhood parks with picnic tables and sports fields or courts. The largest park within the city is not owned by the city – it is King County's Marymoor Park, one of the most popular in King County. It features a climbing rock, a model airplane flying field, a 48-acre off-leash dog park, an outdoor theater, sports fields such as baseball and soccer, a playground, tennis courts, a community garden, cricket pitch, and a velodrome, which hosts the FSA Star Crossed – Redmond cyclo-cross competition in September.

The city offers over of public trails for hiking, bicycling, and horseback riding. The Sammamish River Trail connects to the Puget Power trail, the Burke-Gilman Trail (in Bothell), and the East Lake Sammamish Trail.

60 Acres Park is known for its soccer in the spring through fall and RC electric airplanes and gliders in the winter time.

In 2004, Redmond North Little League won the Northwest region and participated in the Little League World Series in South Williamsport, PA. With Redmond North claiming the Northwest, it is the third team from Washington to claim the Northwest since its inception in 2001. Previous Washington champions were Bainbridge Island (2001), Richland (2003).

Redmond has a non-partisan mayor–council form of government, with the mayor and seven council members elected at large for staggered four-year terms. The city council authorized a ballot measure in March 2003 that would have changed Redmond to a council-manager government. However, it was rejected by the electorate, receiving less than 30% of the vote.

Redmond is part of the Lake Washington School District, which also encompasses Kirkland, and parts of Sammamish and Woodinville. The public schools in Redmond include ten elementary schools, eight middle schools, and two high schools. The district also offers "choice" schools at all levels for alternative schooling needs. The city's two high schools are Redmond High School and Nikola Tesla STEM High School, a choice school.

Three private schools in Redmond offer secondary education: The Overlake School (secular), The Bear Creek School (Christian – primary and secondary), and the Conservatory High School (for performing arts students).

The English Hill neighborhood in North Redmond (unincorporated King County) is served by the Northshore School District and Sunrise Elementary. The far east side of Redmond is known as Redmond Ridge. Redmond Ridge and Redmond Ridge East communities are part of the Lake Washington school district. East of 248th to West Snoqualmie Valley Road is served by the Riverview School District.

DigiPen Institute of Technology and the secondary campus of Lake Washington Technical College are located in Redmond.

The city is home to Redmond Regional Library, the second-largest branch in the King County Library System.





</doc>
